title,year,conference
 An optimistic perspective on offlinereinforcement learning,2020, In International Conference on Machine Learning
 Learning to pokeby poking: Experiential learning of intuitive physics,2016, In NeurIPS
 On evaluation of embodied navigation agents,2018, arXiv preprint arXiv:1807
 Pattern recognition and machine learning,2006, springer
 Semantic visual navigation by watching youtubevideos,2020, In NeurIPS
 Perceptual values from observation,2019, CoRR
 Imitating latentpolicies from observation,2019, In ICML
 Unsupervised learning for physical interactionthrough video prediction,2016, arXiv preprint arXiv:1605
 D4RL: Datasets for deepdata-driven reinforcement learning,2020, arXiv preprint arXiv:2004
 Off-policy deep reinforcement learning withoutexploration,2019, In ICML
 Equivalence notions and model minimization inmarkov decision processes,2003, Artificial Intelligence
 Acme: A researchframework for distributed reinforcement learning,2020, arXiv preprint arXiv:2006
 Learning navigation subroutines by watchingvideos,2020, In CoRL
 A workflow foroffline model-free robotic reinforcement learning,2021, In CoRL
 Batch reinforcement learning,2012, In Reinforce-ment learning
 IRIS: implicit reinforcement without interaction at scale for learning control from offlinerobot manipulation data,2013, In ICRA
 Policy invariance under reward transformations:Theory and application to reward shaping,1999, In ICML
 Action-conditionalvideo prediction using deep networks in atari games,2015, arXiv preprint arXiv:1507
 State-only imitation learningfor dexterous manipulation,2004, CoRR
 Habitat: Aplatform for embodied AI research,2019, In ICCV
 Unsupervised perceptual rewards for imitationlearning,2020, In RSS
 Reinforcement Learning: An Introduction,262, A BradfordBook
 Bounding performance loss in approximatemdp homomorphisms,2008, Advances in Neural Information Processing Systems
 Behavioral cloning from observation,2018, In IJCAI
 Learning from delayed rewards,1989,1989
 Few-shot goal inference for visuomotorlearning and planning,2016, In Conference on Robot Learning
