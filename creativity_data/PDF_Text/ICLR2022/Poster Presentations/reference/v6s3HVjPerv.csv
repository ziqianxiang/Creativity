title,year,conference
 Augmented reality meets computer vision: Efficient data generation for urban drivingscenes,2018, International Journal of Computer Vision
 Evaluat-ing saliency map explanations for convolutional neural networks: A user study,2020, In Proceedings ofthe 25th International Conference on Intelligent User Interfaces
 Towards better understanding ofgradient-based attribution methods for deep neural networks,2018, In International Conference on Learn-ing Representations
 Clevr-xai: A benchmark dataset for the groundtruth evaluation of neural network explanations,1566, Information Fusion
 On pixel-wise explanations for non-linear classifier decisions by layer-wiserelevance propagation,2015, PLoS ONE
 Approximating cnns with bag-of-local-features models workssurprisingly well on imagenet,2018, In International Conference on Learning Representations
 The effects of example-based explanations in amachine learning interface,9781, In Proceedings of the 24th International Conference on IntelligentUser Interfaces
 Explaining image classifiersby counterfactual generation,2019, In ICLR
 This lookslike that: deep learning for interpretable image recognition,2019, In Advances in neural informationprocessing systems
 Near-optimal machineteaching via explanatory teaching sets,1970, In Amos Storkey and Fernando Perez-Cruz (eds
 Nice: Non-linear independent componentsestimation,2015, CoRR
 Density estimation using real nvp,2016, arXivpreprint arXiv:1605
 Diffeomorphic explanations with normal-izing flows,2021, In ICML Workshop on Invertible Neural Networks
 Towards automatic concept-basedexplanations,2019, In Advances in Neural Information Processing Systems
 i-revnet: Deep invertiblenetworks,2018, In International Conference on Learning Representations
 Interpreting interpretability: Understanding data scientists¡¯ use of interpretabil-ity tools for machine learning,9781, In Proceedings of the 2020 CHI Conference on Human Fac-tors in Computing Systems
 Glow: Generative flow with invertible 1x1 convolutions,2018, ArXiv
 Trust in Automation: Designing for Appropriate Reliance,18, HumanFactors
 Generative classifiers as abasis for trustworthy computer vision,2020, arXiv preprint arXiv:2007
 Feature visualization,2017, Distill
 ¡±why should i trust you?¡±: Explaining thepredictions of any classifier,2016, Proceedings of the 22nd ACM SIGKDD International Conference onKnowledge Discovery and Data Mining
 How Useful Are the Machine-Generated Interpretationsto General Users? A Human Evaluation on Guessing the Incorrectly Predicted Labels,2020, InProceedings of the Eighth AAAI Conference on Human Computation and Crowdsourcing (HCOMP-20)
 Explanation byprogressive exaggeration,2020, In International Conference on Learning Representations
 Dice in the Black Box: User Experiences withan Inscrutable Algorithm,2017, AAAI Spring Symposium Series
 Axiomatic attribution for deep networks,3319, InProceedings ofthe 34th International Conference on Machine Learning-Volume 70
 Counterfactual explanations without openingthe black box: Automated decisions and the gdpr,2018, Harvard Journal of Law & Technology
