title,year,conference
 Why bigger is not always better: on finite and infinite neural networks,2020, InInternational Conference on Machine Learning
 A statistical theory of cold posteriors in deep neural networks,2020, arXiv preprintarXiv:2008
 Deep kernel processes,2020, arXiv preprintarXiv:2010
 The deepweight prior,2018, arXiv preprint arXiv:1810
 An essay towards solving a problem in the doctrine of chances,1763, Philosophicaltransactions of the Royal Society of London
 The Lindeberg-Levy theorem for martingales,1961, Proceedings of the AmericanMathematical Society
 Pattern recognition and machine learning,2006, Springer
 Neural networks for pattern recognition,1995, Oxford university press
 Weight uncertainty inneural network,2015, In Proceedings of the 32nd International Conference on Machine Learning
 Jug: Software for parallel reproducible computation in Python,2017, Journal of OpenResearch Software
 Informative Gaussian scale mixture priors forBayesian neural networks,2020, arXiv preprint arXiv:2002
 Efficient and scalable Bayesian neural nets with rank-1factors,2020, arXiv preprint arXiv:2005
 Radial Bayesian neural networks: Robustvariational inference in big models,2019, arXiv preprint arXiv:1907
 On the expressiveness ofapproximate inference in Bayesian neural networks,2019, arXiv preprint arXiv:1909
 Priors in Bayesian deep learning: A review,2021, arXiv preprint arXiv:2105
 Dropout as a Bayesian approximation: Representing modeluncertainty in deep learning,1050, In International Conference on Machine Learning
 Correlated weights in infinite limits of deep ConVolU-tional neural networks,2021, arXiv preprint arXiv:2101
 Deep convolutional net-works as shallow Gaussian processes,2019, In 7th International Conference on Learning Representations
 PAC-Bayesian theorymeets Bayesian inference,2016, arXiv preprint arXiv:1605
 Model selection in Bayesian neural networks via horseshoepriors,2017, arXiv preprint arXiv:1705
 Practical variational inference for neural networks,2011, In J
 The SacredInfrastructure for Computational Research,2017, In Katy Huff
 Noise contrastivepriors for functional uncertainty,2020, In Uncertainty in Artificial Intelligence
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Bayesian inference for large scale image classification,2019, arXivpreprint arXiv:1908
 Uber die Berechnung des Wahrscheinlichen Fehlers aus einer endlichenAnzahl wahrer Beobachtungsfehler,1875, Z
 Probabilistic backpropagation for scalable learningof Bayesian neural networks,1861, In International Conference on Machine Learning
 Subspace inference for Bayesian deep learning,2020, In Uncertainty in ArtificialIntelligence 
 Hierarchical Gaussian process priors for Bayesian neuralnetwork weights,2020, arXiv preprint arXiv:2002
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations
 Auto-encoding variational bayes,2014, In International Conferenceon Learning Representations
 Variational dropout and the local reparam-eterization trick,2015, In Proceedings of the 28th International Conference on Neural InformationProcessing Systems-Volume 2
 Learning multiple layers of features from tiny images,2009, Technical report
 ArviZ a unified library forexploratory analysis of Bayesian models in Python,2019, Journal of Open Source Software
 Memoire sur la Probabilite de causes par les Cvenements,1774, Memoire del¡¯Academie Royale des Sciences
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Deep neural networks as Gaussian processes,2017, arXiv preprint arXiv:1711
 Rational Construction of Stochastic Numerical Methodsfor Molecular Sampling,2012, Applied Mathematics Research eXpress
 Multiplicative normalizing flows for variational Bayesian neuralnetworks,2017, arXiv preprint arXiv:1703
 Vergleichung Von zwei Werthen des WahrSCheinliChen Fehlers,1876, Astronomische Nachrichten
 Variational implicit processes,2019, InInternational Conference on Machine Learning
 A practical Bayesian framework for backpropagation networks,1992, Neuralcomputation
 The ridgelet prior: A covariance functionapproach to prior specification for Bayesian neural networks,2020, arXiv preprint arXiv:2010
 Variational dropout sparsifies deep neuralnetworks,2017, In International Conference on Machine Learning
 Obtaining well calibratedprobabilities using Bayesian binning,2015, In Proceedings of the
 On priors for Bayesian neural networks,2018, PhD thesis
 A scale mixture perspective of multi-plicative noise in neural networks,2015, arXiv preprint arXiv:1506
 Bayesian deep convolutional networks with many channelsare Gaussian processes,2019, In International Conference on Learning Representations
 Global inducing point variational posteriors for Bayesianneural networks and deep Gaussian processes,2020, arXiv preprint arXiv:2005
 The promises and pitfalls of deepkernel learning,2021, arXiv preprint arXiv:2102
 Practical deep learning with Bayesian principles,2019, In Advancesin neural information processing systems
 Can you trust your model¡¯s uncertainty?Evaluating predictive uncertainty under dataset shift,2019, In Advances in Neural Information ProcessingSystems
 Interpretable outcome prediction with sparse Bayesian neuralnetworks in intensive care,2019, arXiv preprint arXiv:1905
 Expressivepriors in Bayesian neUral networks: Kernel combinations and periodic fUnctions,2020, In Uncertainty inArtificial Intelligence
 Stable behavioUr of infinitely wide deep neUralnetworks,1137, In International Conference on Artificial Intelligence and Statistics
 Stochastic backpropagation andapproximate inference in deep generative models,2014, In International Conference on MachineLearning
 PAC-Bayes analysisbeyond the usual bounds,2020, arXiv preprint arXiv:2006
 PACOH: Bayes-optimal meta-learning WithPAC-guarantees,2020, arXiv preprint arXiv:2002
 Evidence optimization techniques for estimating stimulus-response functions,2003, Advances in neural information processing systems
 Capturing visual image properties With probabilistic models,2009, In The EssentialGuide to Image Processing
 On advances in statistical modeling ofnatural images,2003, Journal of mathematical imaging and vision
 The probable error of a mean,1908, Biometrika
 Functional variational Bayesianneural netWorks,2019, arXiv preprint arXiv:1903
 Uniqueness of the weights for minimal feedforward nets with a given input-outputmap,1992, Neural networks
 The k-tied normaldistribution: A compact parameterization of Gaussian mean field posteriors in Bayesian neuralnetworks,2020, arXiv preprint arXiv:2002
 Regression shrinkage and selection via the lasso,1996, Journal of the Royal StatisticalSociety: Series B (Methodological)
 All you need is a goodfunctional prior for Bayesian deep learning,2020, arXiv preprint arXiv:2011
 Overpruning in variational Bayesian neural networks,2018, arXivpreprint arXiv:1801
 Richer priors for infinitely wide multi-layerperceptrons,2019, arXiv preprint arXiv:1911
 Hyperparameter ensembles forrobustness and uncertainty quantification,2020, In Advances in Neural Information Processing Systems
 Fashion-MNIST: a novel image dataset for bench-marking machine learning algorithms,2017, arXiv preprint arXiv:1708
 Improving the computational efficiency offully Bayes inference and assessing the effect of misspecification of hyperparameters in whole-genome prediction models,2015, Genetics Selection Evolution
 Cyclicalstochastic gradient MCMC for Bayesian deep learning,2019, arXiv preprint arXiv:1902
