title,year,conference
 Hidden trigger backdoor attacks,2020, In AAAI
 Towards evaluating the robustness of neural networks,2017, In 2017 IEEESymposium on Security and Privacy (SP)
 Deepinspect: A black-box trojan detection and miti-gation framework for deep neural networks,2019, In Proceedings of the Twenty-Eighth InternationalJoint Conference on Artificial Intelligence
 Targeted backdoor attacks on deep learning systemsusing data poisoning,2017, https://arxiv
 An analysis of single layer networks in unsupervised featurelearning,2011, In AISTATS
 Adam: A method for stochastic optimization,2015, In ICLR
 Black-box detection of back-door attacks with limited information and data,2021, In Proceedings of the IEEE/CVF InternationalConference on Computer Vision (ICCV)
 Robust anomaly detection and backdoor attack detection via differentialprivacy,2020, In Proc
 Model inversion attacks that exploit confidence informationand basic countermeasures,2015, CCS
 STRIP: A defence against trojanattacks on deep neural networks,2019, In Proc
 Target-dependent sentiment classification with bert,2019, IEEEAccess
 Badnets: Evaluating backdooring attacks on deepneural networks,2019, IEEE Access
 TABOR: A highly accurate approach to inspectingand restoring Trojan backdoors in AI systems,2019, https://arxiv
 Deep residual learning for image recognition,2016, In Proc
 Universal litmus patterns: Revealing backdoorattacks in cnns,2020, In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition(CVPR)
 Gradient-based learning applied to document recog-nition,1998, Proceedings of the IEEE
 Deep learning based imaging datacompletion for improved brain disease diagnosis,2014, In Medical Image Computing and Computer-Assisted Intervention - MICCAI 2014
 Neural Attention Distillation: Erasing BackdoorTriggers from Deep Neural Networks,2021, In Proc
 Fine-pruning: Defending against backdoor attacks on deepneural networks,2018, In Proc
 Trojaning attack on neural networks,2018, In Proc
 Abs: Scanning neural networks forback-doors by artificial brain stimulation,2019, In CCS
 DeepFool: a simple and accurate method to fool deepneural networks,2016, In Proc
 Towards deep learning modelsresistant to adversarial attacks,2018, In Proc
 Adversarial learning in statistical classification: A compre-hensive review of defenses against attacks,2020, Proceedings of the IEEE
 Very deep convolutional networks for large-scale image recogni-tion,2015, In ICLR
 Intriguingproperties of neural networks,2014, In Proc
 Spectral signatures in backdoor attacks,2018, In Proc
 Neural cleanse: Identi-fying and mitigating backdoor attacks in neural networks,2019, In Proc
 Practical detection of trojan neuralnetworks: Data-limited and data-free cases,2020, In Proc
 A benchmark study of backdoor data poisoning defenses fordeep neural network classifiers and a novel defense,2019, In Proc
 Detection of backdoors in trained classifiers without access tothe training set,2020, IEEE Transactions on Neural Networks and Learning Systems
 A backdoor attack against 3d point cloud clas-sifiers,2021, In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)
 Reverse engineering imperceptible backdoor attacks on deepneural networks for detection and training set cleansing,2021, Computers and Security
 Detecting Scene-Plausible Perceptible Backdoorsin Trained DNNs Without Access to the Training Set,2021, Neural Computation
 Detecting AI Trojans Using MetaNeural Analysis,2021, In Proc
 Backdoor embedding in convolutionalneural network models via invisible perturbation,2020, In Proc
