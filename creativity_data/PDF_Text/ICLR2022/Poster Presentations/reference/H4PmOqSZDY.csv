title,year,conference
 Universally Quantized Neural Compression,2020, In Advances in NeuralInformation Processing Systems 33
 Scale-space flow for end-to-end optimized video compression,2020, In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition
 Fixing abroken ELBO,2018, In International Conference on Machine Learning
 End-to-end Optimized Image Compression,2017, In InternationalConference on Learning Representations
 VariationalImage Compression with a Scale Hyperprior,2018, ICLR
 IEEE Trans,2021, on Special Topics in Signal Processing
 Lossy source coding,1998, IEEE Transactions on Information Theory
 Computation of channel capacity and rate-distortion functions,1972, IEEE Transactions onInformation Theory
 Large scale gan training for high fidelity naturalimage synthesis,2019, arXiv preprint arXiv:1809
 Importance weighted autoencoders,2015, arXivpreprint arXiv:1509
 Mode-finding for mixtures of gaussian distributions,2000, IEEE Transactionson Pattern Analysis and Machine Intelligence
 Gaussian mean-shift is an em algorithm,2007, IEEE Transactions on PatternAnalysis and Machine Intelligence
 Learned image compression withdiscretized gaussian mixture likelihoods and attention modules,2020, arXiv preprint arXiv:2001
 Geometric programming duals of channel capacity and ratedistortion,2004, IEEE Transactions on Information Theory
 On an extremum problem of information theory,1974, Studia Scientiarum MathematicarumHungarica
 A course in large sample theory,2017, Routledge
 Efficient stochastic source coding and an application to abayesian network source model,1997, The Computer Journal
 Rate distortion functions and rate distortion function lower bounds for real-worldsources,2017, Entropy
 Entropy and information theory,2011, Springer Science & Business Media
 Estimation of the rate-distortion function,18, IEEETransactions on Information Theory
 beta-vae: Learning basic visual concepts with aconstrained variational framework,2017, Iclr
 Integer discrete flows andlossless compression,2019, In Advances in Neural Information Processing Systems
 Evaluating lossy compressionrates of deep generative models,2020, International Conference on Machine Learning
 Categorical reparameterization with gumbel-softmax,2016, arXivpreprint arXiv:1611
 Auto-encoding variational Bayes,2014, In International Conference onLearning Representations
 Normalizing flows: An introductionand review of current methods,1939, IEEE Transactions on Pattern Analysis and Machine Intelligence
 Pointwise redundancy in lossy data compression and universal lossy datacompression,2000, IEEE Transactions on Information Theory
 A tutorial on energy-basedlearning,2006, Predicting structured data
 Microsoft coco: Common objects in context,2014, In Europeanconference on computer vision
 The concrete distribution: A continuousrelaxation of discrete random variables,2016, arXiv preprint arXiv:1611
 Rationale for a large text compression benchmark,2009, Retrieved (Oct
 Envelope theorems for arbitrary choice sets,2002, Econometrica
 Joint Autoregressive and Hierarchical Priors for LearnedImage Compression,2018, In Advances in Neural Information Processing Systems 31
 Masked autoregressive flow for densityestimation,2017, In Advances in Neural Information Processing Systems
 Lecture notes on information theory,2014,2014
 On vari-ational bounds of mutual information,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov(eds
 The intrin-sic dimension of images and its impact on learning,2021, In International Conference on LearningRepresentations
 Rate-distortion theory for general sets andmeasures,2018, arXiv preprint arXiv:1804
 PixelCNN++: A pixelcnn implementationwith discretized logistic mixture likelihood and other modifications,2017, In International Conferenceon Learning Representations
 A Mathematical Theory of Communication,1948, Bell System Technical Journal
 Coding theorems for a discrete source with a fidelity criterion,1959, IRE Nat
 Algorithms for the communication of samples,2021, preprint
 The information bottleneck method,2000, arXivpreprint physics/0004057
 Hierarchical autoregressive modelingfor neural video compression,2020, In International Conference on Learning Representations
 Variational Bayesian Quantization,2020, In InternationalConference on Machine Learning
 An introduction to neural data compression,2022, arXivpreprint arXiv:2202
 A universal algorithm for sequential data compression,1977, IEEETransactions on information theory
