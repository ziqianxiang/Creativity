title,year,conference
 A convergence theory for deep learning via over-parameterization,2019, In International Conference on Machine Learning (ICML)
 Square at-tack: a query-efficient black-box adversarial attack via random search,2020, In European Conferenceon Computer Vision (ECCV)
 Stronger generalization bounds fordeep nets via a compression approach,2018, In International Conference on Machine Learning (ICML)
 A closer lookat memorization in deep netWorks,2017, In International Conference on Machine Learning (ICML)
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning (ICML)
 Spectrally-normalized margin bounds forneural netWorks,2017, In Advances in Neural Information Processing Systems (NIPS)
 Reconciling modern machine-learning practice and the classical bias-variance trade-off,2019, Proceedings of the National Academyof Sciences
 Adversarial examples from com-putational constraints,2019, In International Conference on Machine Learning (ICML)
 Generalization bounds of stochastic gradient descent for wide anddeep neural networks,2019, In Advances in Neural Information Processing Systems (NeurIPS)
 Towards evaluating the robustness of neural networks,2017, In IEEESymposium on Security and Privacy (SP)
 Unlabeleddata improves adversarial robustness,2019, In Advances in Neural Information Processing Systems(NeurIPS)
 Robust overfittingmay be mitigated by properly learned smoothening,2021, In International Conference on LearningRepresentations (ICLR)
 Cat: Customized adver-sarial training for improved robustness,2020, arXiv preprint arXiv:2002
 Parsevalnetworks: Improving robustness to adversarial examples,2017, In International Conference on MachineLearning (ICML)
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning (ICML)
 Minimally distorted adversarial examples with a fast adaptiveboundary attack,2020, In International Conference on Machine Learning (ICML)
 Benchmark-ing adversarial robustness on image classification,2020, In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition (CVPR)
 Does learning require memorization? a short tale about a long tail,2020, In Proceedingsof the 52nd Annual ACM SIGACT Symposium on Theory of Computing
 What neural networks memorize and why: Discoveringthe long tail via influence estimation,2020, In Advances in Neural Information Processing Systems(NeurIPS)
 Convergenceof adversarial training in overparametrized neural networks,2019, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations (ICLR)
 Uncoveringthe limits of adversarial training against norm-bounded adversarial examples,2020, arXiv preprintarXiv:2010
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, InAdvances in Neural Information Processing Systems (NeurIPS)
 Deep residual learning for image recog-nition,2016, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Using pre-training can improve model robustnessand uncertainty,2019, In International Conference on Machine Learning (ICML)
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Self-adaptive training: beyond empirical riskminimization,2020, In Advances in Neural Information Processing Systems (NeurIPS)
 Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels,2018, In International Conferenceon Machine Learning (ICML)
 Fantas-tic generalization measures and where to find them,2020, In International Conference on LearningRepresentations (ICLR)
 A new measure of rank correlation,1938, Biometrika
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations (ICLR)
 Learning multiple layers of features from tiny images,2009, Tech-nical report
 Adversarial machine learning at scale,2017, InInternational Conference on Learning Representations (ICLR)
 Temporal ensembling for semi-supervised learning,2017, In InternationalConference on Learning Representations (ICLR)
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 On the loss landscapeof adversarial training: Identifying challenges and how to overcome them,2020, In Advances in NeuralInformation Processing Systems (NeurIPS)
 Bad global minima exist and sgdcan reach them,2020, In Advances in Neural Information Processing Systems (NeurIPS)
 Learning withnoisy labels,2013, In Advances in Neural Information Processing Systems (NIPS)
 Readingdigits in natural images with unsupervised feature learning,2011, In NIPS Workshop on Deep Learningand Unsupervised Feature Learning
 Norm-based capacity control in neuralnetworks,2015, In Conference on Learning Theory (COLT)
 Rethinking softmax cross-entropy loss for adversarial robustness,2020, In International Conference on Learning Representations(ICLR)
 Bag of tricks for adversarialtraining,2021, In International Conference on Learning Representations (ICLR)
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Adversarial robustness through locallinearization,2019, In Advances in Neural Information Processing Systems (NeurIPS)
 Learning to reweight examples forrobust deep learning,2018, In International Conference on Machine Learning (ICML)
 Overfitting in adversarially robust deep learning,2020, InInternational Conference on Machine Learning (ICML)
 Adver-sarially robust generalization requires more data,2018, In Advances in Neural Information ProcessingSystems (NeurIPS)
 Confidence-calibrated adversarial training: Gener-alizing to unseen attacks,2020, In International Conference on Machine Learning (ICML)
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations (ICLR)
 On theconvergence and robustness of adversarial training,2019, In International Conference on MachineLearning (ICML)
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In International Conference onLearning Representations (ICLR)
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning (ICML)
 Adversarial weight perturbation helps robust gen-eralization,2020, In Advances in Neural Information Processing Systems (NeurIPS)
 Intriguing properties of adversarial training,2020, In International Confer-ence on Learning Representations (ICLR)
 Feature denoisingfor improving adversarial robustness,2019, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR)
 Rademacher complexity for adversariallyrobust generalization,2018, In International Conference on Machine Learning (ICML)
 Deep layer aggregation,2018, In Proceed-ings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Wide residual networks,2016, In Proceedings of the BritishMachine Vision Conference (BMVC)
 Adversariallyrobust generalization just requires more unlabeled data,2019, arXiv preprint arXiv:1906
 Understandingdeep learning requires rethinking generalization,2017, In International Conference on Learning Rep-resentations (ICLR)
 You only propagateonce: Painless adversarial training using maximal principle,2019, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Over-parameterized adversarial training: An analysis overcoming the curse of dimensionality,2020, In Ad-vances in Neural Information Processing Systems (NeurIPS)
 Generalized cross entropy loss for training deep neural networkswith noisy labels,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Gradient descent optimizes over-parameterized deep relu networks,2020, Machine Learning
