title,year,conference
 Lambdanetworks: Modeling long-range interactions without attention,2021, In InternationalConference on Learning Representations
 Attention augmentedconvolutional networks,2019, In Proceedings of the IEEE/CVF International Conference on ComputerVision
 Is Space-Time Attention All You Need forVideo Understanding? arXiv,2021,org
 High-Performance Large-ScaleImage Recognition Without Normalization,2021, arXiv
 CrossViT: Cross-Attention Multi-Scale VisionTransformer for Image Classification,2021, arXiv
 Visformer: TheVision-friendly Transformer,2021, arxiv
 Twins: Revisiting Spatial Attention Design in Vision Transformers,2021, arXiv
 RandAugment: Practical AutomatedData Augmentation with a Reduced Search Space,1861, In H Larochelle
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 BERT: Pre-training of deepbidirectional transformers for language understanding,4171, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Ap-cnn: Weakly supervised attention pyramid convolutional neural network forfine-grained visual classification,2021, IEEE Transactions on Image Processing
 The”something something” video database for learning and evaluating visual common sense,2017, In ICCV
 Transformer intransformer,2021, arXiv preprint arXiv:2103
 Mask r-cnn,2017, In Proceedings of theIEEE International Conference on Computer Vision (ICCV)
 Augmentyour batch: Improving generalization through instance repetition,2020, In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition (CVPR)
 Squeeze-and-excitation networks,2018, In 2018 IEEE/CVF Conference onComputer Vision and Pattern Recognition
4% Top-1 Accuracy Vision Transformer with 56M Parameters onImageNet,2021, arxiv
 3d object representations for fine-grainedcategorization,2013, In 4th International IEEE Workshop on 3D Representation and Recognition(3dRR-13)
 Learning multiple layers of features from tiny images,2009, 2009
 LocalViT: Bringing Localityto Vision Transformers,2021, arXiv
 Microsoft COCO: Common Objects in Context,2014, In DavidFleet
 Sgdr: Stochastic gradient descent with warm restarts,2017, In Interna-tional Conference on Learning Representations
 Decoupled weight decay regularization,2019, In International Confer-ence on Learning Representations
 Cats and dogs,2012, In IEEEConference on Computer Vision and Pattern Recognition
 Stand-alone self-attention in vision models,2019, arXiv preprint arXiv:1906
 Revisiting unreasonable effectiveness of data in deeplearning era,2017, In 2017 IEEE International Conference on Computer Vision (ICCV)
 Rethinking theinception architecture for computer vision,2016, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 EfficientNet: Rethinking Model Scaling for Convolutional NeuralNetworks,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Training data-efficient image transformers & distillation through attention,2020, arXiv preprintarXiv:2012
 Goingdeeper with Image Transformers,2021, arXiv
 Attention is All you Need,2017, In I Guyon
 Non-local neural networks,2018, InProceedings of the IEEE conference on computer vision and pattern recognition
 Pytorch image models,2019, https://github
 Cbam: Convolutional blockattention module,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 CvT:Introducing Convolutions to Vision Transformers,2021, arXiv
 ConTNet: Why notuse convolution and transformer at the same time? arXiv,2021,org
 mixup: Beyond empiricalrisk minimization,2018, In International Conference on Learning Representations
 Aggregating Nested Trans-formers,2021, arXiv
 Exploring self-attention for image recognition,2020, InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
 Learning Rich Part HierarchiesWith Progressive Attention Networks for Fine-Grained Image Recognition,1057, IEEE Transactions onImage Processing
 Sceneparsing through ade20k dataset,2017, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition (CVPR)
