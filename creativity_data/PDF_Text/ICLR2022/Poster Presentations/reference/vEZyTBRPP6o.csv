title,year,conference
 Maximum a posteriori policy optimisation,2018, arXiv preprint arXiv:1806
 Reinforcement learning: Theory and al-gorithms,2021, https://rltheorybook
 Covariant policy search,2003,2003
 A finite time analysis of temporal differencelearning with linear function approximation,2018, arXiv preprint arXiv:1806
 Linear least-squares algorithms for temporal differencelearning,1996, Machine learning
 Convex optimization: Algorithms and complexity,2015, Foundations and Trends inMachine Learning
 Neural temporal-difference and q-learningprovably converge to global optima,2019, arXiv preprint arXiv:1905
 Fast global convergence ofnatural policy gradient methods with entropy regularization,2020, arXiv preprint arXiv:2007
 Implicit bias of gradient descent for wide two-layer neural networkstrained with the logistic loss,2020, arXiv preprint arXiv:2002
 Global convergence of policy gradi-ent methods for the linear quadratic regulator,2018, In International Conference on Machine Learning
 A theory of regularized markov decisionprocesses,2019, In International Conference on Machine Learning
 Conductance and the rapid mixing property for markov chains:The approximation of permanent resolved,1988, In STOC
 Risk and parameter convergence of logistic regression,2018, arXiv preprintarXiv:1803
 Polylogarithmic width suffices for gradient descent to achieve arbi-trarily small test error with shallow relu networks,2019,2019
 Provably efficient reinforcementlearning with linear function approximation,2137, In Conference on Learning Theory
 A natural policy gradient,2001, Advances in neural information processing systems
 Finite sample anal-ysis of two-time-scale natural actor-critic algorithm,2021, arXiv preprint arXiv:2101
 Actor-critic algorithms,2000, In Advances in neural informationprocessing systems
 Bandit Algorithms,2020, Cambridge University Press
 Markov chains and mixing times,2006, AmericanMathematical Society
 Q-learning with linear function approximation,2007, In Interna-tional Conference on Computational Learning Theory
 Asynchronous methods for deep reinforcementlearning,2016, In International conference on machine learning
 On convergence proofs on perceptrons,1962, In Proceedings of the Symposium onthe Mathematical Theory of Automata
 Natural actor-critic,2008, Neurocomputing
 Online learning and online convex optimization,2011, Foundations and trends inMachine Learning
 Gradient methods never overfit on separable data,2020, arXiv:2007
 Adaptive trust region policy optimization: Globalconvergence and faster rates for regularized mdps,2020, In Proceedings of the AAAI Conference onArtificial Intelligence
 The im-plicit bias of gradient descent on separable data,2017, arXiv preprint arXiv:1710
 Finite-time error bounds for linear stochastic approximation and TD learn-ing,2019, In COLT
 Reinforcement learning: An introduction,2018, MIT press
 Policy gradientmethods for reinforcement learning with function approximation,2000, In Advances in neural informa-tion processing Systems
 Optimal Transport: Old and New,2008, Springer Science & Business Media
 Neural policy gradient methods: Globaloptimality and rates of convergence,2019, arXiv preprint arXiv:1909
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
 Function optimization using connectionist reinforcement learningalgorithms,1991, Connection Science
 Boosting with early stopping: Convergence and consistency,2005, The Annalsof Statistics
 Online learning in episodic markovian decision processes byrelative entropy policy search,2013, In NIPS
 Finite-sample analysis for SARSA with linearfunction approximation,2019, Advances in neural information processing systems
