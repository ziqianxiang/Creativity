title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning
 Lower bounds on adversarial robustnessfrom optimal transport,2019, In NeurIPS
 The Brunn-Minkowski inequality in Gauss space,1975, Inventiones mathematicae
 Adversarial examples fromcomputational constraints,2019, In International Conference on Machine Learning
 Unlabeleddata improves adversarial robustness,2019, In NeurIPS
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In International Conference on Machine Learning
 Generalized no free lunch theorem for adversarial robustness,2019, In InternationalConference on Machine Learning
 The VC dimension of k-fold union,2007, Information ProcessingLetters
 Adversarial vulnerability for any classifier,2018, InNeurIPS
 Deep label distribution learningwith label ambiguity,2017, IEEE Transactions on Image Processing
 Adversarial spheres,2018, arXiv:1801
 Explaining and harnessing adversarialexamples,2015, In ICLR
 Scalable verified training forprovably robust image classification,2019, In International Conference on Computer Vision
 Countering adversarialimages using input transformations,2018, In ICLR
 O2U-Net: A simple noisy label detectionapproach for deep neural networks,2019, In International Conference on Computer Vision
 Certified adversarial robustness withadditive noise,2019, In NeurIPS
 Detecting and correcting for label shift withblack box predictors,2018, In International Conference on Machine Learning
 The curse of concentration inrobust learning: Evasion and poisoning attacks from concentration of measure,2019, In AAAI Conferenceon Artificial Intelligence
 Empirically measuringconcentration: Fundamental limits on intrinsic robustness,2019, In NeurIPS
 Learning Withnoisy labels,2013, In NeurIPS
 Pervasive label errors in test sets destabilizemachine learning benchmarks,2021, In NeurIPS (Datasets and Benchmarks Track)
 Confident learning: Estimating uncertainty in datasetlabels,2021, Journal of Artificial Intelligence Research
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In IEEE Symposium on Securityand Privacy
 Humanuncertainty makes classification more robust,2019, In International Conference on Computer Vision
 Improved estimation of concentration under `p-normdistance metrics using half spaces,2021, In ICLR
 Certified defenses against adversarialexamples,2018, In ICLR
 Extremal properties of half-spaces for sphericallyinvariant measures,1974, Zapiski Nauchnykh Seminarov Leningrad Otdel Mathematical Institute Steklov(LOMI)
 Intriguing properties of neural networks,2014, In ICLR
 On adaptive attacks toadversarial example defenses,2020, In NeurIPS
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Scaling provable adversarialdefenses,2018, In NeurIPS
 Adversarial weight perturbation helps robust general-ization,2020, In NeurIPS
 Mitigating adversarial effectsthrough randomization,2018, In ICLR
 Towards stable and efficient training of verifiably robust neural networks,2020, InICLR
 Understanding the intrinsic robustness ofimage distributions using conditional generative models,2020, In International Conference on ArtificialIntelligence and Statistics (AISTATS)
