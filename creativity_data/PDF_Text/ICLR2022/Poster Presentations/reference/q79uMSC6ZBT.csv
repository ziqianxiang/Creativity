title,year,conference
 The adverse effects of code duplication in machine learning models of code,2019, InProceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas
 Mining idioms from source code,2014, In Proceedings of theInternational Symposium on Foundations of Software Engineering (FSE)
 PHOG: Probabilistic model for code,2016, In Pro-ceedings of the International Conference on Machine Learning (ICML)
 Studying the difference between natural andprogramming language corpora,2019, Empirical Software Engineering
 Evaluatinglarge language models trained on code,2021, arXiv preprint arXiv:2107
 Spectral learningof latent-variable PCFGs,2012, In Proceedings of the 50th Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers)
 Coarse-to-fine decoding for neural semantic parsing,2018, arXiv preprintarXiv:1805
 CodeBERT: A pre-trained model for programming andnatural languages,2020, arXiv preprint arXiv:2002
 The importance ofgeneration order in language modeling,2018, arXiv preprint arXiv:1808
 Copilot - your ai pair programmer,2021, https://copilot
 Levenshtein transformer,2019, arXiv preprintarXiv:1905
 Globalrelational models of source code,2019, In International conference on learning representations
 On the natu-ralness of software,2012, In Proceedings of the International Conference on Software Engineering(ICSE)
 Bigcode!= big vocabulary: Open-vocabulary models for source code,2020, In Proceedings of the Interna-tional Conference on Software Engineering (ICSE)
