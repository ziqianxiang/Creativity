title,year,conference
 Gradient `1 regularization for quantization robustness,2020, In International Conference onLearning Representations
 The state of sparsity in deep neUral networks,2019, arXivpreprint arXiv:1902
 Bootstrap yoUr own latent - anewapproach to self-sUpervised learning,2127, In H
 Second order derivatives for network prUning: Optimal brainsUrgeon,1993, In Advances in neural information processing systems
 Batch normalization: Accelerating deep network training byredUcing internal covariate shift,2015, In Francis Bach and David Blei (eds
 NeUral network prUning forbiomedical image segmentation,2021, In Medical Imaging 2021: Image-Guided Procedures
 Optimal brain damage,1990, In Advances in neuralinformation processing Systems
 Snip: Single-shot network pruningbased on connection sensitivity,2018, arXiv preprint arXiv:1810
 Pruning convolutionalneural networks for resource efficient inference,2016, In International Conference on Learning Repre-sentations
 U-net: Convolutional networks for biomedi-cal image segmentation,2015, In International Conference on Medical image computing and computer-assisted intervention
 Pruning neural networkswithout any data by iteratively conserving synaptic flow,2020, In H
 Picking winning tickets before training bypreserving gradient flow,2020, In International Conference on Learning Representations
 Semi-supervised learning with meta-gradient,2021, In Arindam Banerjee and Kenji Fukumizu (eds
 Drawing early-bird tickets: Toward more efficienttraining of deep networks,2020, In International Conference on Learning Representations
 Fast con-text adaptation via meta-learning,2019, In ICML 2019: Proceedings of the Thirty-Sixth InternationalConference on Machine Learning
