title,year,conference
 Practical Gauss-Newton optimisation fordeep learning,2017, In Doina Precup and Yee Whye Teh (eds
 The tradeoffs of large scale learning,2008, In J
 A stochastic quasi-newtonmethod for large-scale optimization,2016, SIAM Journal on Optimization
 Libsvm: a library for support vector machines,2011, ACM trans-actions on intelligent systems and technology (TIST)
 Averaged least-mean-squares: Bias-variance trade-offs andoptimal sampling distributions,2015, In Artificial Intelligence and Statistics
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Convergence rates of sub-sampled new-ton methods,2015, In C
 Competing with the empirical riskminimizer in a single pass,2015, In Conference on learning theory
 On convergence rates of subgradient optimization methods,1977, Mathematical pro-gramming
 A kronecker-factored aPProximate fisher matrix for convo-lution layers,2016, In Maria Florina Balcan and Kilian Q
 Span: A stochasticprojected approximate newton method,2020, In Proceedings of the AAAI Conference on ArtificialIntelligence
 Par-allelizing stochastic approximation through mini-batching and tail-averaging,2016, arXiv preprintarXiv:1610
 SGDR: stochastic gradient descent with warm restarts,2017, In 5thInternational Conference on Learning Representations
 Building a large annotatedcorpus of English: The Penn Treebank,1993, Computational Linguistics
 Iterate averaging as regularization for stochastic gradient de-scent,2018, In Conference On Learning Theory
 A stochastic approximation method,1951, The annals of mathemati-cal statistics
 Is averaging needed for strongly convex stochastic gradient descent,2012, Open problempresented at COLT
 Last iteraterisk bounds of sgd with decaying stepsize for overparameterized linear regression,2021, arXiv preprintarXiv:2110
 Enhance curvatureinformation by structured stochastic quasi-newton methods,2021, In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition (CVPR)
5rate curve of three cosine-power schedulers,2022, Top: original scale; Bottom: log18Published as a conference paper at ICLR 2022A
