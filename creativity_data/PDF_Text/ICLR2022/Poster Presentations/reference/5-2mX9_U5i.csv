title,year,conference
 Tensorflow: A system for large-scalemachine learning,2016, In 12th USENIX Symposium on Operating Systems Design and Implementation(OSD116)
 An introduction tomcmc for machine learning,2003, Machine learning
 A unified particle-optimizationframework for scalable bayesian sampling,2018, In The Conference on Uncertainty in Artificial Intelli-gence
 Convergence of langevin mcmc in kl-divergence,2018, PMLR 83
 Sharp convergence rates for langevin dynamics in the nonconvex setting,2018, arXiv preprintarXiv:1805
 Underdamped langevinmcmc: A non-asymptotic analysis,2018, Proceedings of the 31st Conference On Learning Theory
 On the global convergence of gradient descent for over-parameterizedmodels using optimal transport,2018, In Advances in neural information processing systems
 Further and stronger analogy between sampling and optimization: Langevinmonte carlo and gradient descent,2017, Conference on Learning Theory
 Theoretical guarantees for approximate sampling from smooth and log-concavedensities,2017, Journal of the Royal Statistical Society: Series B (Statistical Methodology)
 On sampling from a log-concave density using kineticLangevin diffusions,2020, Bernoulli
 Nonasymptotic convergence analysis for the unadjusted langevinalgorithm,2017, Annals of Applied Probability
 High-dimensional bayesian inference via the unadjusted langevinalgorithm,2019, Bernoulli
 Analysis of langevin monte carlo viaconvex optimization,2019, Journal ofMachine Learning Research
 On the convergence of langevin monte carlo: The interplaybetween tail growth and smoothness,2021, COLT
 Approximate inference with wasserstein gradient flows,2020, InInternational Conference on Artificial Intelligence and Statistics
 The variational formulation of the fokker-planckequation,1998, SIAM journal on mathematical analysis
 Numerical solution of stochastic differential equations,1992, Springer
 The langevin monte carlo algorithm in the non-smooth log-concave case,2021, arXivpreprint arXiv:2101
 Hessian-free high-resolution nesterov acceleration forsampling,2020, arXiv preprint arXiv:2006
 The mirror langevin algorithmconverges with vanishing bias,2021, arXiv preprint arXiv:2109
 Stochastic Runge-Kutta acceleratesLangevin Monte Carlo and beyond,2019, NeurIPS
 Monte Carlo strategies in scientific computing,2008, Springer Science & Business Media
 Stein variational gradient descent: A general purpose bayesian inferencealgorithm,2016, In Advances in neural information processing systems
 Stochastic gradient descent as approximatebayesian inference,2017, Journal of Machine Learning Research
 Improved boundsfor discretization of langevin diffusions: Near-optimal rates without convexity,2019, arXiv preprintarXiv:1907
 High-orderlangevin diffusion yields an accelerated mcmc algorithm,2021, Journal of Machine Learning Research
 Monte Carlo statistical methods,2013, Springer Science & BusinessMedia
 Optimal scaling of discrete approximations to langevindiffusions,1998, Journal of the Royal Statistical Society: Series B (Statistical Methodology)
 Exponential convergence of langevin distributions andtheir discrete approximations,1996, Bernoulli
 RUnge-kutta methods for the strong approximation of solutions of stochasticdifferential equations,2010, SIAM Journal on Numerical Analysis
 Numerical treatment of stochastic differential equations,1982, SIAM Journal on NumericalAnalysis
 The randomized midpoint method for log-concave sampling,2019, InAdvances in Neural Information Processing Systems
 Rapid convergence of the unadjusted langevin algorithm:Isoperimetry suffices,2019, In Advances in Neural Information Processing Systems
 Sampling as optimization in the space of measures: The langevin dynamics as acomposite optimization problem,2018, In Conference On Learning Theory
 Policy optimization as wassersteingradient flows,2018, In International Conference on Machine Learning
