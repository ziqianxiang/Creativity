title,year,conference
 On the Cross-lingual Transferability ofMonolingual Representations,2020, In Proceedings of ACL 2020
 Synthetic and Natural Noise Both Break Neural MachineTranslation,2018, In Proceedings of ICLR 2018
 Nuancedmetrics for measuring unintended bias with real data for text classification,2019, CoRR
 RethinkingEmbedding Coupling in Pre-trained Language Models,2021, In Proceedings of ICLR 2021
 TyDi QA: ABenchmark for Information-Seeking Question Answering in Typologically Diverse Languages,2020, InTransactions of the ACL
 Canine: Pre-training an efficienttokenization-free encoder for language representation,2021, arXiv preprint arXiv:2103
 XNLI: Evaluating Cross-lingual Sentence Representations,2018, InProceedings of EMNLP 2018
 Un-supervised cross-lingual representation learning at scale,8440, In Proceedings of the 58th AnnualMeeting of the Association for Computational Linguistics
 Sharp models on dull hardware: Fast and accurate neural machine translation decodingon the cpu,2017, arXiv preprint arXiv:1705
 BERT: Pre-training of DeepBidirectional Transformers for Language Understanding,2019, In Proceedings of NAACL 2019
 CharacterBERT: Reconciling ELMo and BERT for word-level open-vocabularyrepresentations from characters,2020, In Proceedings of the 28th International Conference on Com-putational Linguistics
 FRAGE: Frequency-Agnostic Word Representation,2018, In Proceedings of NIPS 2018
 Generating sequences with recurrent neural networks,2013, arXiv preprint arXiv:1308
 Dynamic programming encoding forsubword segmentation in neural machine translation,2020, In Proceedings of the 58th Annual Meeting ofthe Association for Computational Linguistics
 Optimiz-ing word segmentation for downstream task,2020, In Findings of the Association for Computa-tional Linguistics: EMNLP 2020
 Joint Optimizationof Tokenization and Downstream Model,2021, In Findings of ACL-IJCNLP 2021
 Character-level language modeling with hierarchical recurrentneural networks,2017, In 2017 IEEE International Conference on Acoustics
 Exploring thelimits of language modeling,2016, arXiv preprint arXiv:1602
 Character-aware neural languagemodels,2016, In Proceedings of the AAAI conference on artificial intelligence
 Subword regularization: Improving neural network translation models with mul-tiple subword candidates,2018, In Proceedings of the 56th Annual Meeting of the Associationfor Computational Linguistics (Volume 1: Long Papers)
 SentencePiece: A simple and language independent subwordtokenizer and detokenizer for neural text processing,2018, In Proceedings of the 2018 Conferenceon Empirical Methods in Natural Language Processing: System Demonstrations
 Cross-lingual Language Model Pretraining,2019, In Proceedingsof NeurIPS 2019
 The relative contribution of consonants andvowels to word identification during reading,2001, Journal of Memory and Language
 Fully character-level neural machine transla-tion without explicit segmentation,2017, Transactions of the Association for Computational Linguis-tics
 MLQA: EvaluatingCross-lingual Extractive Question Answering,2020, In Proceedings of ACL 2020
 CharBERT: Character-aware pre-trained language model,2020, In Proceedings of the 28th International Conference onComputational Linguistics
 Distributed Representations of Wordsand Phrases and their Compositionality,2013, In Advances in Neural Information Processing Systems
 Image transformer,2018, In International Conference on Machine Learning
 Deep contextualized word representations,2018, In Proceedings of NAACL-HLT2018
 BPE-dropout: Simple and effective subwordregularization,2020, In Proceedings of the 58th Annual Meeting of the Association for ComputationalLinguistics
 Combating adversarial misspellingswith robust word recognition,2019, In Proceedings of the 57th Annual Meeting of the Associationfor Computational Linguistics
 Exploring the Limits of Transfer Learning with a UnifiedText-to-Text Transformer,2020, Journal of Machine Learning Research
 Xtreme-r: Towards more challenging andnuanced multilingual evaluation,2021, arXiv preprint arXiv:2104
 Japanese and korean voice search,2012, In 2012 IEEE InternationalConference on Acoustics
 Neural machine translation of rare wordswith subword units,2016, In Proceedings of the 54th Annual Meeting of the Association for Com-putational Linguistics (Volume 1: Long Papers)
 Glu variants improve transformer,2020, arXiv preprint arXiv:2002
 Mesh-tensorflow: Deeplearning for supercomputers,2018, arXiv preprint arXiv:1811
 Long range arena: A benchmark for efficienttransformers,2020, arXiv preprint arXiv:2011
 Efficient transformers: A survey,2020, arXivpreprint arXiv:2009
 Attention is all you need,2017, In I
 Linformer: Self-attention withlinear complexity,2020, arXiv preprint arXiv:2006
 Multi-view Subword Regularization,2021, InProceedings of NAACL 2021
 A broad-coverage challenge corpusfor sentence understanding through inference,2018, In Proceedings of the 2018 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human Lan-guage Technologies
 Google¡¯s NeuralMachine Translation System: Bridging the Gap between Human and Machine Translation,2016, arXivpreprint arXiv:1609
 Ex machina: Personal attacks seen at scale,9781, InProceedings of the 26th International Conference on World Wide Web
 PAWS-X: A Cross-lingual AdversarialDataset for Paraphrase Identification,2019, In Proceedings of EMNLP 2019
 Big bird: Transformers for longersequences,2020, arXiv preprint arXiv:2007
 Character-level Convolutional Networks for TextClassification,2015, Advances in Neural Information Processing Systems
