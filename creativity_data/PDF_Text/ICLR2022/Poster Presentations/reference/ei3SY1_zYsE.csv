title,year,conference
 The impact of reinitialization ongeneralization in convolutional neural networks,2021, arXiv preprint arXiv:2109
 A closer look at memorization in deep netWorks,2017, In Proceedings of the 34thInternational Conference on Machine Learning
 Deep learning through the lens ofexample difficulty,2021, arXiv preprint arXiv:2106
 Forgetting as the friend of learning: implications forteaching and self-regulated learning,2019, Advances in Physiology Education
 Understanding linguistic evolution by visualizing the emergenceof topographic mappings,2006, Artificial life
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 What neural netWorks memorize and Why: Discovering thelong tail via influence estimation,2020, arXiv preprint arXiv:2008
 Learning tocommunicate With deep multi-agent reinforcement learning,2016, In Advances in neural informationprocessing systems
 Sharpness-aWare minimiza-tion for efficiently improving generalization,2021, In International Conference on Learning Represen-tations
 Stabilizing thelottery ticket hypothesis,2019, arXiv preprint arXiv:1903
 Catastrophic forgetting in connectionist networks,1999, Trends in Cognitive Sciences
 Shortcut learning in deep neural networks,2020, NatureMachine Intelligence
 The importance of forgetting,2019, Nature
 Iterative back-translation for neural machine translation,2018, In NMT@ACL
 Long short-term memory,1997, Neural Computation
 Densely connectedconvolUtional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Categorical reparameterization with gUmbel-softmax,2017, In 5thInternational Conference on Learning Representations
 Fantas-tic generalization measUres and where to find them,2020, In International Conference on LearningRepresentations
 SGD on neUral networks learns fUnctions of increasing complexity,2019, Ad-vances in Neural Information Processing Systems
 Novel dataset for fine-grained image categorization,2011, In First Workshop on Fine-Grained Visual Categorization
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 SpontaneoUs evolUtion of lingUistic strUctUre-an iterated learning model of the emer-gence of regUlarity and irregUlarity,2001, IEEE Transactions on Evolutionary Computation
 Overcom-ing catastrophic forgetting in neUral networks,2017, Proceedings of the national academy of sciences
 Emergence of lin-guistic communication from referential games with symbolic and pixel input,2018, arXiv preprintarXiv:1804
 Tiny imagenet visual recognition challenge,2015,2015
 Convention: A philosophical study,2008, John Wiley & Sons
 Ease-of-teaching and language structure from emergent commu-nication,2019, arXiv preprint arXiv:1906
 Rifle: Backpropagationin depth for deep transfer learning through re-initializing the fully-connected layer,2020, In Interna-tional Conference on Machine Learning
 SGDR: stochastic gradient descent with warm restarts,2017, In 5thInternational Conference on Learning Representations
 Counteringlanguage drift with seeded iterated learning,2020, In International Conference on Machine Learning
 The concrete distribution: A continuous relax-ation of discrete random variables,2017, In 5th International Conference on Learning Representations
 Fine-grainedvisual classification of aircraft,2013, arXiv preprint arXiv:1306
 Automated flower classification over a large numberof classes,2008, In 2008 Sixth Indian Conference on Computer Vision
 Learning explanations that are hard to vary,2021, In International Conference on LearningRepresentations
 Towards understanding knowledge distillation,2019, In Interna-tional Conference on Machine Learning
 Recognizing indoor scenes,2009, In 2009 IEEE Conferenceon Computer Vision and Pattern Recognition
 Connectionist models of recognition memory: constraints imposed by learning andforgetting functions,1990, Psychological review
 Compositional lan-guages emerge in a neural iterated learning model,2020, In International Conference on LearningRepresentations
 Opening the black box of deep neural networks via informa-tion,2017, arXiv preprint arXiv:1703
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Under-standing and improving knowledge distillation,2020, arXiv preprint arXiv:2002
 Deep learning generalizes becausethe parameter-function map is biased towards simple functions,2019, In International Conference onLearning Representations
 Iterated learningfor emergent systematicity in VQA,2021, In International Conference on Learning Representations
 Microglia mediate forgetting viacomplement-dependent synaptic elimination,2020, Science
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine Learning
 Self-training with noisy studentimproves imagenet classification,2020, In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition
 Forgetting enhances episodic control with struc-tured memories,2021, bioRxiv
 Regularizing class-wise predictions viaself-knowledge distillation,2020, In Proceedings of the IEEE/CVF conference on computer vision andpattern recognition
 Wide residual networks,2016, arXiv preprintarXiv:1605
 Non-vacuous gen-eralization bounds at the imagenet scale: a PAC-bayesian compression approach,2019, In InternationalConference on Learning Representations
