title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning
 Unrestricted adversarialexamples via semantic manipulation,2020, In International Conference on Learning Representations
 Anomalousexample detection in deep learning: A survey,2020, IEEE Access
 Towards evaluating the robustness of neural networks,2017, In 2017ieee symposium on security and privacy (sp)
 The use of confidence or fiducial limits illustrated in the caseof the binomial,1934, Biometrika
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 Why do adversarial attacks transfer? explaining transferabilityof evasion and poisoning attacks,2019, In 28th {USENIX} Security Symposium ({USENIX} Security19)
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Bert: Pre-training of deepbidirectional transformers for language understanding,2019, In NAACL-HLT (1)
 A framework for robustness certification of smoothedclassifiers using f-divergences,2019, In International Conference on Learning Representations
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Maxi-min margin machine: learninglarge margin classifiers locally and globally,2008, IEEE Transactions on Neural Networks
 Limitations of the lipschitz constant as adefense against adversarial examples,2018, In Joint European Conference on Machine Learning andKnowledge Discovery in Databases
 Consistency regularization for certified robustness of smoothedclassifiers,2020, In H
 Improving adversarial robustness of ensembles withdiversity training,2019, arXiv preprint arXiv:1901
 Certifying confidence viarandomized smoothing,2020, In H
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Certifiedrobustness to adversarial examples with differential privacy,2019, In 2019 IEEE Symposium on Securityand Privacy (SP)
 Certified adversarial robustness withadditive noise,2019, In Advances in Neural Information Processing Systems
 Sok: Certified robustness for deep neural networks,2020, arXiv preprintarXiv:2009
 Boosting the robustness of capsule networks withdiverse ensemble,2020, In 2020 10th International Conference on Information Science and Technology(ICIST)
 Enhancing certified robustness ofsmoothed classifiers via weighted model ensembling,2020, arXiv preprint arXiv:2005
 Higher-order certification for randomized smoothing,2020, Advances in Neural Information Processing Systems
 Popular ensemble methods: An empirical study,1999, Journal ofartificial intelligence research
 Improving adversarial robustness viapromoting ensemble diversity,4970, In International Conference on Machine Learning
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Ensemble-based classifiers,2010, Artificial intelligence review
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, InAdvances in Neural Information Processing Systems
 Black-box smoothing: Aprovable defense for pretrained classifiers,2020, arXiv preprint arXiv:2003
 Second-order provable defenses against adversarial attacks,2020, InInternational Conference on Machine Learning
 Certifying some distributional robustness withprincipled adversarial training,2018, In International Conference on Learning Representations
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 On adaptive attacks toadversarial example defenses,2020, arXiv preprint arXiv:2002
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Uber die analytische darstellbarkeit sogenannter willkurlicher functionen einerreellen VerdnderliChen,1885, Sitzungsberichte der Koniglich Preufiischen Akademie der Wissenschaftenzu Berlin
 Towards fast computation of certified robustness for relu networks,2018, InInternational Conference on Machine Learning
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Generating adversarialexamples with adversarial networks,2018, arXiv preprint arXiv:1801
 Spatially transformedadversarial examples,2018, In International Conference on Learning Representations
 Automatic perturbation analysis for scalable certifiedrobustness and beyond,2020, In Advances in Neural Information Processing Systems
 Randomizedsmoothing of all shapes and sizes,2020, In International Conference on Machine Learning
 Dverge: Diversifying vulnerabilities forenhanced robust generation of ensembles,2020, Advances in Neural Information Processing Systems
 Trs: Transferability reduced ensemble via promoting gradient diversity andmodel smoothness,2021, In Advances in Neural Information Processing Systems
 Boosting the certified robustness of l-infinitydistance nets,2022, In International Conference on Learning Representations
 Black-box certifica-tion with randomized smoothing: A functional optimization based framework,2020, arXiv preprintarXiv:2002
 Efficient neural networkrobustness certification with general activation functions,2018, In Advances in neural informationprocessing systems
 Enhancing certifiable robustness via a deep modelensemble,2019, arXiv preprint arXiv:1910
