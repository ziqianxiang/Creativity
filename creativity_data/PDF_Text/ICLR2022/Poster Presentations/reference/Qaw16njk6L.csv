title,year,conference
 Generalisation guarantees for continuallearning with orthogonal gradient descent,2020, arXiv preprint arXiv:2006
 Once-for-all: Train one networkand specialize it for efficient deployment,2019, arXiv preprint arXiv:1908
 End-to-end object detection with transformers,2020, In European Conference on ComputerVision
 Autoformer: Searching transformersfor visual recognition,2021, In Proceedings of the IEEE/CVF International Conference on ComputerVision
 Chasing sparsity invision transformers: An end-to-end exploration,2021, arXiv preprint arXiv:2106
 Mobile-former: Bridging mobilenet and transformer,2021, arXiv preprint arXiv:2108
 Per-pixel classification is not all youneed for semantic segmentation,2021, arXiv preprint arXiv:2107
 The cityscapes dataset for semantic urbanscene understanding,2016, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Autoaugment:Learning augmentation strategies from data,2019, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Randaugment: Practical automateddata augmentation with a reduced search space,2020, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition Workshops
 Fbnetv3: Joint architecture-recipe search using neuralacquisition function,2020, arXiv e-prints
 Coatnet: Marrying convolution andattention for all data sizes,2021, arXiv preprint arXiv:2106
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Cswin transformer: A general vision transformer backbone with cross-shapedwindows,2021, arXiv preprint arXiv:2107
 Nas-bench-201: Extending the scope of reproducible neural architecturesearch,2020, arXiv preprint arXiv:2001
 Animage is worth 16x16 words: Transformers for image recognition at scale,2020, arXiv preprintarXiv:2010
 Adapting auxiliary losses using gradient similarity,2018, arXiv preprintarXiv:1812
 Multiscale vision transformers,2021, arXiv preprint arXiv:2104
 Orthogonal gradient descent for continuallearning,3762, In International Conference on Artificial Intelligence and Statistics
 Levit: a vision transformer in convnet’s clothing for faster inference,2021, arXivpreprint arXiv:2104
 Transformer intransformer,2021, arXiv preprint arXiv:2103
 Searching for mobilenetv3,2019, InProceedings of the IEEE/CVF International Conference on Computer Vision
 Squeeze-and-excitation networks,2018, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Reformer: The efficient transformer,2020, arXivpreprint arXiv:2001
 Darts: Differentiable architecture search,2018, arXivpreprint arXiv:1806
 Swin transformer: Hierarchical vision transformer using shifted windows,2021, arXiv preprintarXiv:2103
 Cream of the crop: Distillingprioritized paths for one-shot neural architecture search,2020, arXiv preprint arXiv:2010
 Efficient neural architecturesearch via parameter sharing,2018, arXiv preprint arXiv:1802
 Dynamicvit:Efficient vision transformers with dynamic token sparsification,2022, arXiv preprint arXiv:2106
 Large-scale evolution of image classifiers,2017, In International Conferenceon Machine Learning
 Regularized evolution for imageclassifier architecture search,2019, In Proceedings of the aaai conference on artificial intelligence
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Single-path nas: Designing hardware-efficient convnets in less than 4hours,2019, arXiv preprint arXiv:1904
 Vision transformer architecture search,2021, arXiv preprint arXiv:2106
 Revisiting unreasonableeffectiveness of data in deep learning era,2017, In Proceedings of the IEEE international conference oncomputer vision
 Mnasnet: Platform-aware neural architecture search for mobile,2019, In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition
 Training data-effiCient image transformers & distillation through attention,2020, arXiv preprintarXiv:2012
 Goingdeeper with image transformers,2021, arXiv preprint arXiv:2103
 Attention is all you need,2017, arXiv preprint arXiv:1706
 Fbnetv2: Differentiable neural architecture search forspatial and channel dimensions,2020, In Proceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition
 Regularization of neuralnetworks using dropconnect,1058, In International conference on machine learning
 Alphanet: Improved trainingof supernet with alpha-divergence,2021, arXiv preprint arXiv:2102
 Attentivenas: Improving neuralarchitecture search via attentive sampling,2021, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Cvt:Introducing convolutions to vision transformers,2021, arXiv preprint arXiv:2103
 Earlyconvolutions help transformers see better,2021, arXiv preprint arXiv:2106
 Seg-former: Simple and efficient design for semantic segmentation with transformers,2021, arXiv preprintarXiv:2105
 Tokens-to-token vit: Training vision transformers from scratch onimagenet,2021, arXiv preprint arXiv:2101
 Volo: Vision outlooker for visualrecognition,2021, arXiv preprint arXiv:2106
 mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
 Multiobjective evolutionary algorithms: A survey of the state of the art,2011, Swarm andevolutionary computation
 Sceneparsing through ade20k dataset,2017, In Proceedings of the IEEE conference on computer vision andpattern recognition
 Deformable detr:Deformable transformers for end-to-end object detection,2020, arXiv preprint arXiv:2010
 Neural architecture search with reinforcement learning,2016, arXiv preprintarXiv:1611
 Learning transferable architecturesfor scalable image recognition,2018, In Proceedings of the IEEE conference on computer vision andpattern recognition
 It often targets atsearching for the best model in a search space under given efficiency-related constraints,2021, Earlier NASsolutions often build on reinforcement learning (e
 In Du et al,2021, (2018)
 LeViT proposes to expand the dimension of V,2019, We followLeViT’s design which expand the dimension of V by an expansion ratio 4
g Touvron et al,2021,
