title,year,conference
 Knowledge graph prediction of unknown adversedrug reactions and validation in electronic health records,2017, Scientific reports
 Generating moleculesvia chemical reactions,2019, In Deep Generative Models for Highly Structured Data
 Chemberta: Large-scale self-supervised pretraining for molecular property prediction,2020, arXiv preprint arXiv:2010
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Topology adaptivegraph convolutional networks,2017, arXiv preprint arXiv:1710
 Molecular representation learning with language models and domain-relevant auxiliary tasks,2020, arXiv preprint arXiv:2011
 A survey of graph edit distance,2010, PatternAnalysis and applications
 Neuralmessage passing for quantum chemistry,2017, In Proceedings of the 34th International conference onmachine learning
 word2vec explained: deriving mikolov et al,2014,â€™s negative-samplingword-embedding method
 Inductive representation learning on largegraphs,2017, In Proceedings of the 31st International Conference on Neural Information ProcessingSystems
 Smiles transformer: Pre-trained molecular fingerprintfor low data drug discovery,2019, arXiv preprint arXiv:1911
 Graph neural networkswith multiple feature extraction paths for chemical property estimation,2021, Molecules
 Mol2vec: unsupervised machine learning approachwith chemical intuition,2018, Journal ofchemical information and modeling
 A survey on contrastive self-supervised learning,2021, Technologies
 Predicting organic reactionoutcomes with weisfeiler-lehman network,2017, In Proceedings of the 31st International Conferenceon Neural Information Processing Systems
 Molecular graphconvolutions: moving beyond fingerprints,2016, Journal of computer-aided molecular design
 Adam: A method for stochastic optimization,2015, In The 3rdInternational Conference on Learning Representations
 Semi-supervised classification with graph convolutional net-works,2017, In Proceedings of The 5th International Conference on Learning Representations
 Infor-mation retrieval and text mining technologies for chemistry,2017, Chemical reviews
 Settransformer: A framework for attention-based permutation-invariant neural networks,2019, In Interna-tional Conference on Machine Learning
 Extraction of chemical structures and reactions from the literature,2012, PhD thesis
 Masked graph model-ing for molecule generation,2021, Nature communications
 Automatic generation of complementary descriptorswith molecular graph networks,2005, Journal of chemical information and modeling
 Distributed represen-tations of words and phrases and their compositionality,2013, In Advances in neural information pro-cessing systems
 A generative model for molecule generation based on chemicalreaction trees,2021, arXiv preprint arXiv:2106
 Scikit-learn:Machine learning in python,2011, the Journal of machine Learning research
 Reaction classification and yield pre-diction using the differential reaction fingerprint drfp,2021, 2021
 Learning transferable visualmodels from natural language supervision,2021, In Proceedings of the 38th International Conferenceon Machine Learning
 Extended-connectivity fingerprints,2010, Journal of chemical informa-tion and modeling
 Development of anovel fingerprint for chemical reactions and its application to large-scale reaction classificationand similarity,2015, Journal of chemical information and modeling
 Mapping the space of chemical reactions using attention-based neuralnetworks,2021, Nature Machine Intelligence
 Neural-symbolic machine learning for retrosynthesis andreaction prediction,2017, Chemistry-A European Journal
 Planning chemical syntheses with deep neuralnetworks and symbolic ai,2018, Nature
 Self-attention based molecule repre-sentation for predicting drug-target interaction,2019, In Machine Learning for Healthcare Conference
 Visualizing data using t-sne,2008, Journal of machinelearning research
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Graph attention networks,2018, In Proceedings of The 6th International Conference on Learn-ing Representations
 Smiles-bert: largescale unsupervised pre-training for molecular property prediction,2019, In Proceedings of the 10thACM international conference on bioinformatics
 Generalizing from a few examples:A survey on few-shot learning,2020, ACM Computing SUrveys (CSUR)
 Learning continuous anddata-driven molecular descriptors by translating equivalent chemical representations,2019, Chemicalscience
 Moleculenet: a benchmark for molecular machine learn-ing,2018, ChemiCaIsCience
 Self-supervised graph-levelrepresentation learning with local and global structure,2021, arXiv preprint arXiv:2106
 Graphcontrastive learning with augmentations,2020, Advances in Neural Information Processing Systems
 An end-to-end deep learningarchitecture for graph classification,2018, In Thirty-Second AAAI Conference on Artificial Intelligence
 Mg-bert: leveraging unsupervised atomic representationlearning for molecular property prediction,2021, Briefings in Bioinformatics
 Predicting retrosyn-thetic reactions using self-corrected transformer neural networks,2019, Journal of Chemical Informa-tion and Modeling
 Identifying structure-property relationshipsthrough smiles syntax analysis with self-attention mechanism,2019, Journal of chemical informationand modeling
