title,year,conference
 Layer normalization,2016, arXiv preprintarXiv:1607
 Adaptive input representations for neural language modeling,2019, InICLR (Poster)
 End-to-end object detection with transformers,2020, In ECCV
 Generating long sequences with sparsetransformers,2019, CoRR
 Generating long sequences with sparsetransformers,2019, CoRR
 Rethinking attention with per-formers,2021, In ICLR
 R-FCN: object detection via region-based fUllyconvolutional networks,2016, In NIPS
 DeformableconvolUtional networks,2017, In ICCV
 Imagenet: A large-scalehierarchical image database,2009, In CVPR
 Deep residUal learning for image recog-nition,2016, In CVPR
 Mask R-CNN,2017, In ICCV
 Bridging nonlinearities and stochastic regUlarizers with gaUssianerror linear Units,2016, CoRR
 Axial attention in mUltidi-mensional transformers,2019, CoRR
 Transformers arernns: Fast aUtoregressive transformers with linear attention,2020, In ICML
 Deeply-Supervised Nets,2015, In Guy Lebanon and S
 Microsoft coco: Common objects in context,2014, In ECCV
 Image transformer,2018, In ICML
 DynamicViT:efficient vision transformers with dynamic token sparsification,2021, arXiv preprint arXiv:2106
 Faster R-CNN: towards real-timeobject detection with region proposal networks,2015, In NIPS
 Spatilly consistent representationlearning,2021, In CVPR
 Attention is all you need,2017, In NeurIPS
 PnP-DETR: towards efficientvisual analysis with transformers,2021, In ICCV
 Efficient DETR: improving end-to-end objectdetector with dense prior,2021, arXiv preprint arXiv:2104
 Deformable DETR:deformable transformers for end-to-end object detection,2021, In ICLR
