Published as a conference paper at ICLR 2022
Optimal Representations for Covariate Shift
Yangjun Ruan* 12, Yann Dubois*2, Chris J. Maddison12
1University of Toronto & 2Vector Institute
{yjruan,yanndubois,cmaddis}@cs.toronto.edu
Ab stract
Machine learning systems often experience a distribution shift between training
and testing. In this paper, we introduce a simple variational objective whose optima
are exactly the set of all representations on which risk minimizers are guaranteed to
be robust to any distribution shift that preserves the Bayes predictor, e.g., covariate
shifts. Our objective has two components. First, a representation must remain
discriminative for the task, i.e., some predictor must be able to simultaneously
minimize the source and target risk. Second, the representation’s marginal support
needs to be the same across source and target. We make this practical by designing
self-supervised objectives that only use unlabelled data and augmentations to train
robust representations. Our objectives give insights into the robustness of CLIP, and
further improve CLIP’s representations to achieve SOTA results on DomainBed.
1	Introduction
It is hard to build machine learning (ML) systems that are robust to distribution shifts between a
source (train) and target (test) domain. One promising approach to domain generalization (DG)
is learning robust representations from which predictors trained on source must perform well on
target. In practice, however, no current DG methods for learning representation uniformly outperform
empirical source-risk minimizers (ERM) (Gulrajani & Lopez-Paz, 2021). Furthermore, our theoretical
understanding of DG is still lacking. Specifically, while previous work have studied properties that
would or would not imply robust representations (Ben-David et al., 2007; 2010a; Zhao et al., 2019;
Johansson et al., 2019), the minimal set of achievable requirements for perfect DG is not yet known.
We introduce the first, simple, variational objective whose optima are exactly the set of all represen-
tations on which source risk minimizers are guaranteed to generalize across distribution shifts that
preserve the Bayes predictor. We work in an idealized DG (IDG) setting; we assume that a learner has
access to the source population risk. Our variational characterization implies that it is both sufficient
and necessary for optimal IDG that a representation: (a) remains discriminative for the learning task,
i.e., there must exist predictors from the representation to the labels that can simultaneously minimize
both source and target risk; and (b) keeps the support of its marginal distribution invariant to shifts.
This means that any optimal representation learning method must seek discriminative information
about the target. Even worse, we prove that without access to some knowledge about the target, any
representation learning algorithm cannot uniformly (over all target domains) outperform a constant
representation, which may explain why DG methods struggle to outperform ERM.
We show, in theory and practice, how to overcome these challenges using only a large set of unlabeled
examples and particular data augmentations that retain all discriminative information but minimal
domain-specific information. Text descriptions of images are examples of such augmentations, as they
are informative for many downstream classification tasks, but they remove a lot of domain-specific
information. With such augmentations, we design practical self-supervised learning (SSL) objectives
for learning robust representations. Our objectives give insights into the robustness of CLIP (Radford
et al., 2021) over other SSL methods, and lead to improved CLIP-based representations that achieve
state-of-the-art (SOTA) results on DomainBed (Gulrajani & Lopez-Paz, 2021). To summarize, we:
•	provide minimal sufficient objectives whose optima achieve optimal DG under covariate shift;
•	prove that it is impossible to learn useful representations without accessing target information;
• provide practical objectives to learn optimally robust representations using specific augmentations;
• obtain SOTA results on typical domain generalization benchmarks.* 1
* Authors contributed equally.
1Our implementation is released at https://github.com/ryoungj/optdom.
1
Published as a conference paper at ICLR 2022
2	Background: domain generalization and representations
We are interested in predictions that are robust across distribution shifts. We formalize this using
domain generalization (DG) language. Given a distribution pX,Y | ds over inputs x ∈ X and labels
y ∈ Y from the source domain ds ∈ D, we select a predictor f : X → Γ. The predictions γ ∈ Γ
could for example be labels or distributions over labels. Despite being selected on the source domain,
we would like f to achieve a small expected risk with respect to a loss function ` : Y × Γ → R≥0,
Rf [Y IX]：= Epχ,γ∣d['(Y,f(X))],	⑴
on a distribution pX,Y | d from a target domain d = dt ∈ D, which is somehow related to ds.
A common strategy for DG is to learn robust representations, which splits the problem into two.
First, learn an encoder pZ | X, which maps inputs X to representations Z. Then, learn a predictor
h : Z → Γ from representations Z to labels Y using standard risk minimization. The goal is to
design a robust representation Z, so that predictors h trained to minimize the source risk Rdhs [Y | Z]
also achieve low target risk Rdht [Y | Z]. Many methods have been proposed to try to learn such Z,
e.g., by enforcing domain invariance of the marginal pZ | d (e.g., Ganin et al., 2016). Still, many of
these proposals are not sound (Zhao et al., 2019; Johansson et al., 2019). Furthermore, they rarely
outperform source empirical risk minimization (ERM) in practice (Gulrajani & Lopez-Paz, 2021).
3	Optimal representations for domain generalization
To separate domain generalization from finite sample generalization, we consider an idealized DG
(IDG), where the predictor h is selected on the source population risk rather than empirical risk. We
assume sample spaces X, Z, Y, D are discrete; formal statements and proofs are in Appxs. A and B.
3.1	Defining Optimal Representations for Idealized Domain Generalization
We want to evaluate the quality of a representation Z of X . In our IDG, the learner is given a random
source Ds ; she selects any source risk minimizer; and is scored according to her risk on a random
target domain Dt . To give uniform guarantees while reflecting the uncertainty over the source-target
pair (Ds, Dt), we measure the quality of Z as the expected risk of the learner’s worst-case choice.
Definition. The idealized domain generalization risk (IDG risk) of an encoder pZ | X is the expected
(over domains) worst-case (over source risk minimizers) target risk, i.e.,
RIDG[Y|Z] := EpDs,Dt	sup RhDt [Y|Z]	(2)
h∈HDs	_
where HDs := argminh RDs [Y | Z] are the source risk minimizers, and PDsDt is any joint distribu-
tion that has full support over D×D. We call a representation Z* (or its encoder) optimalfor IDG if
it minimizes the IDG risk.
3.2	Characterizing optimal representations for IDG under covariate shift
The IDG risk is useful to evaluate representations, but gives few insights into IDG and is impractical to
optimize due to the supremum in Eq. (2). Under mild assumptions, we provide a simplified, equivalent
objective, which is easier to optimize. For convenience, we assume that there is a unique Bayes pre-
dictor f*, which minimizes the expected risk over domains, i.e., f* = arg minf EpDt [RfDt [Y | X]].
This is satisfied by standard ML tasks pY,X and losses `. More importantly, we assume the following
domain structure, which ensures the existence of optimal encoders and allows our simplification.
Assumptions. All domains d ∈ D we consider are related by the following assumptions:
1.	Generalized covariate shift. All domain-specific risk minimizers f ∈ arg minf [Rfd [Y | X]] are
equal to the Bayes predictor f* on their support, i.e., f(x) = f* (x) for all x ∈ supp(pX | d).
2.	Invariance of Bayes predictions. The set of Bayes predictions is the same for all domains, i.e.,
{f *(x) I X ∈ Supp(PX | d)} = {f *(x) I X ∈ X}.
2
Published as a conference paper at ICLR 2022
Figure 1: (a) Optimal representations for IDG must have invariant supports while being simultaneously
discriminative on all domains: (b) without the discriminative requirement, a source-risk minimizer
can mispredict the target, and (c) without support match, some risk minimizer will perform poorly.
Generalized covariate shift (GCS) ensures that f * is simultaneously optimal on all domains. For
log-loss ` it recovers standard covariate shift, i.e., pY | x,d = pY | x. For other losses, GCS is weaker,
e.g., it only requires invariance of most likely labels for 0-1 loss, and of conditional expectations for
MSE. Invariance of Bayes predictors is necessary to learn useful predictors using a single domain.
For example, for 0-1 loss it ensures that each label is seen at least once in each domain.
The intuition behind our objective is that under GCS any source risk minimizer will make optimal
predictions on target samples x that are also in the source. Thus, IDG optimal representations are
exactly those that (a) have the same support in Z for all domain, and (b) retain GCS from Z without
sacrificing the ability to predict Y , which can be ensured by minimizing the risk from Z . See Fig. 1.
Theorem 1. Under our assumptions, an encoder pz* ∣ X is optimalfor IDG ifand only ifit minimizes
the risk R [Y | Z] := infh EpDt RhDt [Y | Z] while matching the support of Z across domains, i.e.,
pZ* |X ∈ arg min R[Y | Z]	s.t. ∀d ∈ D, supp(pZ|d) = supp(pZ)	(3)
pZ | X
Moreover, such encoders exist and their IDG risk is the Bayes risk RIDG [Y | Z*] = R [Y | X].
Theorem 1 provides an objective to learn representations on which performing risk minimization
using a single domain and Z * is as good as performing risk minimization on the target domain
from inputs X. Other sufficient conditions have previously been hinted towards, e.g., matching
the marginal pZ | d instead of its support (e.g., Ben-David et al., 2010a) which is the focus of most
DG methods (e.g., Ganin et al., 2016). Note that previous conditions are nevertheless generally
not necessary and could be too stringent to be achievable. To our knowledge, Thm. 1 is the first
characterization of necessary and sufficient conditions, which gives better insights into the essential
goal for optimal IDG and provides a guide for deriving the least stringent objectives in practice.
The risk minimization (Eq. (3)) shows that one must have some knowledge about the target domains
to learn optimal representations for IDG. Access to targets might seem unrealistic, but without such
knowledge or additional assumptions it is provably impossible to beat even constant representations.
Proposition 1 (No free lunch for IDG). Let ds be any source domain, Zds be any representation
chosen on source ds, and C ∈ Z be a constant representation. Under minor assumptions, for every
“good” target domain outside the source’s support on which Zds outperforms C for IDG, there are
many “bad” target domains on which Zds is strictly worse than C. Formal statement in Appx. B.3.
Proposition 1 shows that target knowledge is necessary for learning useful representations in IDG.
This may explain why previous DG methods have been unable to outperform ERM in standard
benchmarks (Gulrajani & Lopez-Paz, 2021): the knowledge they have access to is insufficient to
generalize. Taken together, Prop. 1 and Thm. 1 say that either you have access to target domains dt ,
in which case you can achieve an IDG risk that matches supervised learning, or you do not access dt,
in which case any representation learning algorithm can achieve worse IDG risk than a constant.
4	Learning representations under c ovariate shift
4.1	Self-supervised learning using domain-agnostic augmentations
Our characterization of optimal representations for IDG (Thm. 1) requires labeled data from all
domains, which is impractical. We show how this can be overcome with self-supervised learning
3
Published as a conference paper at ICLR 2022
(a) standard augmentations
(b) supervised augmentations
(c) image-text augmentations
Figure 2: Image-text augmentations are practical domain-agnostic augmentations. Arrows denote
augmenters. Bubbles denote inputs that have the same representations, as induced by predicting the
augmentations. (a) Standard augmentations are not domain-agnostic. (b) Supervised augmentations
uniformly augment inputs inside their label class, irrespective of domains. (c) Image-text augmenta-
tions are (nearly) domain-agnostic as they map images across domains to similar descriptions.
(SSL), which is a technique for training representations without direct access to labels, and a particular
class of data augmentations. E.g, in CLIP, images are augmented with alt-text collected on the internet
and invariance is enforced between the representations of the image and its text pair (Radford et al.,
2021). Representations learned like this preserve discriminative information about all downstream
tasks Y whose label information is preserved by the augmentation (e.g., Dubois et al., 2021).
More precisely, an augmentation A is a random variable sampled conditionally from the input X . The
key requirement is that augmentations retain task information. Specifically, if any samples x, x0 ∈ X
have the same augmentation conditional pA | x = pA | x0, then their Bayes predictions must be the
same f * (x) = f * (χ0). With such A, one can learn an encoder that minimizes the risk R [Y | Z] by
instead maximizing mutual information I[A; Z]. Intuitively, if Z has all augmentation information,
then it must have information about the conditional pA | X, and thus the Bayes prediction f* (X).
This suggests learning optimal representations for IDG by replacing Eq. (3) with a maximiza-
tion of I[A; Z]. Unfortunately, fully optimizing I[A; Z] w.r.t. pZ | X is not generally possible un-
der the support constraint Eq. (3). This can be overcome under a domain-agnostic assumption,
which requires that the set of possible augmentation distributions is the same across domains, i.e.,
pA|x | x ∈ supp(pX|d) = pA|x | x ∈ X .
Proposition 2. Let PA ∣ X be a domain-agnostic augmenter. Then any optimal solution pz* ∣ X ofthe
following objective is optimal for IDG:
pZ* |X ∈ arg max I[A; Z]	s.t. ∀ d ∈ D, supp(pZ | d) = supp(pZ)	(4)
pZ | X
Proposition 2 shows that we can still learn IDG optimal representations without labels if we have
access to the right augmentations. How realistic are those augmentations? For 0-1 loss `, the most
likely label should be preserved, which is satisfied by standard image augmentations like rotations
and color jittering. Those augmentations are nevertheless not domain-agnostic for typical domains
(e.g. sketches and photos), since outputs A are correlated with the input’s domain D. See Fig. 2a.
A practical choice of augmentation that is nearly domain-agnostic, is a mapping from images to
text descriptions, as with CLIP (Radford et al., 2021) which uses text-image pairs. Image-text
augmentations have many advantages. First, text augmentations preserve label information for many
downstream tasks. Second, they are close to being domain-agnostic, since images from different
domains (e.g., sketches and photos) but similar semantics are often mapped to similar descriptions.2
(Fig. 2c). This gives insights into the open question (Radford et al., 2021) about why CLIP’s
representations are so robust compared to other SSL methods. Finally, image-text pairs are easy to
access in practice given their abundance on the internet. Many other multi-modal augmentations, e.g.,
audio-video (Wang et al., 2021), are also likely domain-agnostic and can be explored in practice.
In practice, even the domain information D is usually unknown. One can nevertheless still optimize
(Eq. (4)) by replace the support constraint with a stronger one that does not rely on D e.g., minimizing
I[Z; X] (see Sec. 4.2.2), . This highlights the potential of Prop. 2: if one can find a large source of
inputs X and domain-agnostic augmentations A (e.g., the 400M image-text pairs of CLIP) then one
can, in principle, learn optimal representations for IDG on any downstream task Y that A preserves.
2Although text descriptions might contain domain information (e.g., referring to “sketch”), they are still
much better than standard augmentations that rarely map together images from different domains.
4
Published as a conference paper at ICLR 2022
4.2	Practical objectives
We now design practical objectives for learning optimal representations without labels. Proposition 2
does provide an objective but it is impractical as it involves constrained optimization. We can
nevertheless convert it to the following unconstrained objective by using a Lagrangian relaxation and
introducing a domain bottleneck B[Z, D] that enforces support match,
arg min	- I[A; Z] + λ B[Z, D] ,	(5)
pZ | X
Eq. (5) is a valid reformulation of Prop. 2 as long as minimizing B[Z, D] while maximizing I[A; Z]
enforces the support constraint in Eq. (4). Below, we provide different choices of such B[Z, D]
each of which results in a different SSL objective. In practice, however, terms in Eq. (5) are hard to
estimate from finite samples. We now discuss two variational bounds that can be efficiently estimated
and optimized with stochastic gradient descent (Bottou, 2010). For simplicity, we use a deterministic
encoder 已中:X → Z for the rest of the paper. Detailed derivations are in Appx. C.
For both practical objectives we use a contrastive variational lower bound on I[A; Z] based on
InfoNCE (Oord et al., 2018), which is standard in SSL. Specifically, for a sample X, we first obtain
the augmented ‘positive’ A by sampling from pA | X. We then obtain n augmented ‘negatives’
Ai- in=1 i.i.d. from the marginal pA by first independently sampling X := Xi- in=1 from pX and
then sampling Ai- from pA | Xi- . We denote A := A, A1-, . . . , An- . InfoNCE then uses a critic sψ
to score how likely each A0 ∈ A is to be positive, resulting in the following variational bound,
I[A; Z] ≥ log(n +1) + EPA,X,Z [log P expesψ(A, 2	1 .	⑹
A0∈A exp sψ (A , Z)
When A = X, one can tie the parameters of the critic and the encoder by passing augmentations
through the encoder and taking an inner product, i.e., sψ(A, Z) := eφ(Λ)τZ.
Many previous DG regularizers (e.g., Ganin et al., 2016; Li et al., 2018b;a) could be valid domain
bottlenecks. In the following, we discuss two possible B[Z, D] , the first of which is novel.
4.2.1	Contrastive Adversarial Domain Bottleneck (CAD)
Our first domain bottleneck minimizes B[Z, D] =
I[Z; D], which enforces support match using a KL
divergence. Dropping constants w.r.t. Z we thus
aim to maximize H[D | Z]. Domain-adversarial
neural network (DANN, Ganin et al., 2016) does
so by ensuring that a domain classifier qφ cannot
predict domains from representations, i.e., it max-
imizes EpD,Z [- log qφ(D | Z)] ≥ H[D | Z] w.r.t.
encoder parameter 夕 but minimizes it w.r.t. φ.
However, DANN suffers from two issues: (i) it
maximizes an upper bound on the desired term;
(ii) it requires adversarial training, which is chal-
lenging in practice.
Algorithm 1 CAD objective
Require: eφ,sψ,D,X,n
1: Z 4— e+(X)
2: A — sample (pa ∣ X)
3: { (D-,X-,AD}n=1 * 1 2 3 4- 5 6 7 8 SamPle(PD,X,A)
4:χ, A -{χ-}n=ι,{A}∪{A-}n=ι
5: XD 4	Xi- | Di- 6=D,i∈ [n]}
6: LaUB - — log P exp sψ(A,Z)0八	.-I[A; Z]
aug	g A0∈A exp sψ(A0,Z)	;
7: Lsupp - — log pχ0∈x-D exp%X;)7 . I[Z; D]
pp	O ∑2χ00∈χ exp e°(X00)T Z L ，」
8: return LCAD = Laug + λLsupp
To overcome these issues, we construct q(D | Z) without introducing additional parameters and with
a bound that is tight with enough samples. In short, using the equality pD | Z = EpX | Z pD | X , we
set our variational distribution to q(D | Z) = EqRX [p^(D | X)], where qφ,χ(X | Z) is a contrastive
variational distribution of PX ∣ Z constructed with samples X and a critic e干(X)τZ tied with the
encoder, P is a count estimate of PD ∣ X. Detailed derivations and explanations are in Appx. C.3. The
resulting contrastive adversarial domain (CAD) objective is in Algorithm 1. First, sample domains
D := {Di-}in=1 for each X0 ∈ X. Then collect inputs associated with a different domain from the
current domain D, i.e., XD := {Xi- | Di- 6= D, i ∈ [n]}. Ignoring constants, the final loss is
LCAD(^, ψ) := EPD,X,A,Z
exp Sψ (A,Z)
θg PA0∈A exP sΨ(A0, Z)
-λ log( X q，,X(X0 | Z))
∖X0∈X-D	，」
(7)
In Appx. C.4, we also derive a conditional variation of CAD that minimizes I[Z; D | Y], which can
be used when labels are available and supervised augmentations are used.
5
Published as a conference paper at ICLR 2022
4.2.2	Entropy Bottleneck (Ent)
Our second domain bottleneck is the entropy bottleneck (Ent) that minimizes H[Z] = I[Z; X] ≥
I[Z; D], where the first equality uses the encoder’s determinism. Ent enforces support match by
removing all information that is not needed to maximize I[Z; A]. In particular, minimizing I[Z; X] is
more stringent than I[Z; D], as it also matches the representations inside a domain. The advantage of
Ent is that it does not require domain samples D, which are rarely accessible in SSL. We consider
the standard variational bound used in neural compression (Band et al., 2016; Theis et al., 2017),
H[Z] ≤ EpZ [- log qθ(Z)], where an entropy model qθ(Z) is used. This leads to
LEnt(ψ, ψ, θ) := Epχ,A,Z - log P MPS(A，ZA0 Z∖ - λ log 9。(Z) .	(8)
A0 ∈A exp sψ (A , Z)
5	Related work
Provably robust representations under covariate shift. Previous work mostly focuses on domain
generalization bounds for robust representations. Ben-David et al. (2007; 2010a) bound the target
risk using the source risk, a divergence between source and target distributions, and the joint optimal
risk over source and target domains. Mansour et al. (2009) generalizes these results from 0-1 loss to
more general losses. Johansson et al. (2019) takes this further by deriving a support-based bound.
In our setting, these bounds only hint towards a sufficient condition for optimality, i.e., matching
the marginal pZ | d or its support while minimizing R [Y | Z]. However, these bounds can often be
loose and the implied sufficient conditions are neither necessary nor generally achievable. Ben-David
et al. (2010b) suggests that separately minimizing R [Y | Z] or matching the marginal is not sufficient,
while Zhao et al. (2019) also proves minimizing only the source risk Rds [Y | Z] is not sufficient; but
none of them proves the desired necessary condition. Our work distinguishes from previous work on
three key aspects: (i) we are the first to study and formalize optimally robust representations, and
provide the achievable sufficient and necessary conditions; (ii) we prove that one can practically
learn optimal Z* with SSL using domain-agnostic augmentations; (iii) We consider a more general
framework with any standard losses and a less stringent generalized covariate shift assumption, Still,
our work is more specific than others, as we consider idealized DG and unrestricted predictors H.
Practical objectives for DG. The most popular DG methods aim to learn domain-invariant represen-
tation by minimizing various divergernces between the marginal distributions pZ | d and pZ (Long
et al., 2015; Ganin et al., 2016; Sun & Saenko, 2016; Long et al., 2017; Li et al., 2018a; Shen et al.,
2018; Nguyen et al., 2021). Others propose matching the conditional pZ | y,d across domains instead
(Gong et al., 2016; Li et al., 2018b; Tachet des Combes et al., 2020). These regularizers would all be
valid domain bottlenecks B[Z, D] . Another line of work aims at learning Z with invariant predictors
pY | z,d across domains (e.g., Arjovsky et al., 2019; Krueger et al., 2021; Li et al., 2021). However,
none of these methods outperform ERM with fair model selections (Gulrajani & Lopez-Paz, 2021).
6	Experiments
In our experiments, we aimed to: (i) verify our theoretical results in practice; (ii) investigate our
proposed representation learning objectives in practical DG; (iii) take advantage of pretrained SSL
models (in particular, CLIP) to achieve powerful models for DG. Unless stated otherwise, we consider
a two-stage training setup. First, the representation learner (“the representor”) trains an encoder pZ | X
using a specified objective and freezes it. Then, the person performing predictions (“the learner”)
trains her predictor h from Z by minimizing the risk on source data. Finally, the representation Z
and predictor h are evaluated on target data. In all experiments, the learner uses a linear classifier
for h. For the Ent bottleneck, we used Balld et al.’s (2018) entropy model. For the CAD bottleneck
we used its conditional version whenever labels were available. When a model contains no domain
bottleneck, we label it as “Base”. For experimental details and additional results see Appxs. E and F.
6.1	Scientific setting: exploring optimal representations for worst-case DG
To validate our theory, we studied optimal representations in a scientific setup that is as close to our
IDG framework as possible with log-loss `. In particular, we used the PACS dataset (Li et al., 2017)
6
Published as a conference paper at ICLR 2022
R[Y |Z]
-5.1±0.3
-0.4±0.1 -0.7±0.1
H[A∣Z]
-3.5±0.1
-0.0±0.0
-0.8±0.2
Base
Ent
CAD
(b) Effect of λ
Augmentation type
(c) Effect of augmentations
(a) Effect of different objectives
Figure 3: (a) Adding bottlenecks significantly improves the worst-case DG performance and using
domain-agnostic (DA) augmentations (H[A | Z]) performs as well as with labels (R [Y | Z]). (b) In-
creasing the domain bottleneck weight λ will improve target performance until it decreases source
performance. (c) DA augmentations are crucial but approx. DA aug. might be also be sufficient.
and approximated the idealized DG by treating the dataset as the population distribution, i.e., we
did not split datasets into train and test sets. To approximate the worst-case source predictor, we
followed Dubois et al. (2020) by incorporating the wrongly labeled target data to the source domain.
The experimental setup goes as follows: (i) the representor trains a ResNet-18 (He et al., 2016) to
minimize the objective on labeled data from all domains; (ii) the learner trains a worst-case source
classifier h on every possible pair of (source, target); (iii) the negative target risk (log likelihood)
for each h is evaluated. We reported the log likelihood averaged over 5 seeds. For more realistic
scenarios (i.e. non-idealized average-case DG) see Appx. F.2 which replicates the following results.
Do our domain bottlenecks improve worst-case DG? In Fig. 3a, we compare IDG performance
of representations trained with (Ent, CAD) and without (Base) domain bottlenecks. We see that
both bottlenecks significantly improve the worst-case DG, and nearly achieve the source-domain
performance (0 log likelihood). This shows the importance of support match (Thm. 2) and the
effectiveness of our bottlenecks to enforce it. In Appx. F.2, we show that bottlenecks also helps in
practical scenarios, i.e., non-idealized average-case DG evaluated with accuracy (95.9% → 96.7%).
What is the effect of λ? Fig. 3b shows the effect of the bottleneck weight λ on the worst-case
target and source performance. We see that increasing λ will decrease the DG gap. As a result the
target performance improves until λ ≈ 102, where source performance starts to decrease.
What if the representor has access to domain-agnostic augmentations instead of labels? In
Sec. 4.2, we provide a contrastive objective for using augmentations. To show the effectiveness of the
objective, we compared minimizing H[A | Z] using Eq. (6) to standard supervised risk minimization
R [Y | Z] and used the domain-agnostic supervised augmentations (Fig. 2b). The 1st and 2nd row of
Fig. 3a show that our objective performs similarly to direct label prediction.
How important is the choice of augmentations? Prop. 2 shows that domain-agnostic (DA) aug-
mentations are sufficient for achieving IDG, but it does not give necessary conditions. Here we
investigate the effect of using our loss with different choices of augmentations. Specifically, we used
LCAD with five augmentations. The first two are DA. ‘Supervised’: augment inputs inside the label
class across all domains as in Fig. 2b; ‘SingleDom’: augment inputs to same label samples from a
fixed domain. The second two are not DA. ‘Standard’: standard SSL augmentations (Chen et al.,
2020) as in Fig. 2a; ‘IntraDom’: augment inputs to same label and same domain samples. Finally, we
consider ‘ApproxDA’, which is approximately DA by augmenting 10% of the time with ‘Supervised‘
and 90% of the time with ‘IntraDom‘. Fig. 3c shows that the non-DA augmentations give terrible
results compared to DA. Interestingly, ‘ApproxDA’ also performs very well, which suggests that
approximately DA augmentations might be sufficient to learn optimal representations in practice.
What if the representor does not have access to target domains? Prop. 1 shows that DG without
access to target domains is generally impossible. We empirically verified this by excluding a
predefined target dt domain from the representor’s training set, i.e., LCAD is optimized on 3 of the 4
domains. The learner then trains a predictor h on each source. We finally evaluate each h on the target
domain dt, and average over choices of dt. The resulting worst-case log likelihood was -4.2 ± 0.2,
which is significantly worse than when the representor had access to all domains (-0.8 ± 0.2).
7
Published as a conference paper at ICLR 2022
6.2	Approximating optimal representations by exploiting pretrained SSL
As discussed in Sec. 4.1, one can learn optimal representations for IDG by performing SSL with
a domain bottleneck on a large sample of inputs X and domain-agnostic augmentations A. This
is nearly how CLIP was pretrained (SSL with 400M image-text pairs) except it did not include a
domain bottleneck. In this section, we investigate how to take advantage of CLIP to approximate
optimal representations for IDG. We did so in two simple steps. First, we froze the pretrained CLIP
and added a multi-layer perceptron (MLP) that could effectively finetune CLIP’s representations.
Then, we trained the MLP by minimizing our CAD bottleneck and R [Y | Z] on the available data.
In all experiments, we used the standard DomainBed benchmark (with non-MNIST datasets) and
protocol (Gulrajani & Lopez-Paz, 2021). In particular, we left out a target domain for evaluation
and used the union of other domains for training both the encoder and the classifier. Contrary to our
scientific setting, the representor does not get access to the target domain. All our representations
were evaluated by fitting a linear classifier on source domains with source validation selection. As
in DomainBed we selected the encoder based on ‘oracle selection’ over 10 hyperparameters, and
reported the target accuracy averaged over all choices of targets and 5 random seeds with standard
errors. Note that using ‘oracle selection’ is more consistent with our theory since it gets access to the
necessary target information (for model selection), as discussed in Appx. F.3. Due to space limit,
we only included as baselines ‘ERM’ and ‘DomainBed SOTA’ which for each dataset is the best
result over all baselines. The extended results and baselines are in Table 4. Details in Appx. E.3. We
investigated two pretrained CLIP models with different number of parameters. The larger ViT-B/32
denoted ‘CLIP L’ and the smaller ResNet-50 denoted ‘CLIP S’.
Table 1: CLIP significantly outperforms the previous SOTA result on DomainBed, as supported
by our theoretical analysis. Finetuning CLIP with our CAD bottleneck consistently improves the
robustness of its representations and achieves SOTA performance.
Algorithm	VLCS	PACS	OfficeHome	TerraIncognita	DomainNet
ERM	77.6 ± 0.3	86.7 ± 0.3	66.4 ± 0.5	53.0 ± 0.3	41.3 ±0.1
DomainBed SOTA	79.9 ± 0.2	87.2 ± 0.1	68.4 ± 0.2	54.4 ± 0.3	41.8 ± 0.1
DINO + CAD	69.6 ± 0.6	76.1 ± 0.1	56.9 ± 0.5	25.9 ± 1.2	33.6 ± 0.1
CLIPS	81.1 ±0.5	90.3 ± 0.2	70.6 ± 0.1	29.6 ± 0.8	47.7 ± 0.0
CLIP S + Base	81.3 ±0.5	91.2 ± 0.3	70.6 ± 0.1	36.4 ± 0.7	46.8 ± 0.2
CLIP S + CAD	82.3 ± 0.3	92.0 ± 0.2	71.9 ± 0.2	36.2 ± 0.8	48.8 ± 0.1
CLIPL	80.7 ± 0.4	93.7 ± 0.8	79.6 ± 0.1	36.9 ± 0.6	52.8 ± 0.1
CLIP L + CAD	81.6 ± 0.1	94.9 ± 0.3	80.0 ± 0.2	40.6 ± 1.1	53.7 ± 0.1
Approx. Optimal Z*	86.8 ± 0.6	97.2 ± 0.6	86.3 ± 1.6	76.5 ± 4.1	66.7 ± 0.2
Can we approximate optimal representations by exploiting pretrained CLIP? The row ‘CLIP
L + CAD’ in Table 1 shows that finetuning a large pretrained CLIP model with our CAD achieves
SOTA on nearly all DomainBed benchmarks by a very large margin (see 2nd row). Note that the
poor performance on TerraIncognita is likely because CLIP’s dataset does not cover such images
(camera traps monitoring animals). The last row essentially shows an optimal representation, which
we approximate by finetuning CLIP L with our CAD on all domains including the target. The gap
between CLIP L + CAD and the upper-bound suggests that one can still learn better representations.
We hypothesize that end-to-end training of our objective would greatly shrink this gap.
Are gains due to the architectural differences? DomainBed’s baselines finetuned an ImageNet
pretrained ResNet-50. In contrast, CLIP L pretrained a larger ViT. To decouple gains due to our
objective from architectural gains, we evaluated ResNet-50 pretrained CLIP S. Table 1 shows that
CLIP S + CAD still significantly outperforms DomainBed baselines. Note that our theory does not
constrain the encoder and so we expect larger encoders to be better as seen in Table 1.
What is the effect of domain bottlenecks? In the “CLIP” rows of Table 1, we investigated the
effect of finetuning CLIP with our CAD bottleneck. We see that for both CLIP L and CLIP S, it
consistently improves results by around 1 〜2%. These gains are due to the bottleneck, rather than
finetuning on source data as seen by ‘CLIP S + Base’. We believe the gains could potentially be much
larger if CLIP was trained end-to-end with our bottleneck. Note that raw CLIP S already significantly
8
Published as a conference paper at ICLR 2022
outperforms baselines. We hypothesize that this is because SGD acts as an information bottleneck
that naturally favors support match (Shwartz-Ziv & Tishby, 2017).
Which pretrained SSL model to use? Our theory suggests that we can exploit pretrained SSL
models as long as their augmentations are domain-agnostic and their training set covers desired
domains. We investigated adaption of SSL models that do not satisfy those properties by finetuning
DINO (Caron et al., 2021), the current SOTA on SSL ImageNet. DINO is pretraiend using standard
augmentations. As a result, Table 1 shows that the finetuned DINO + CAD significantly underper-
forms compared to CLIP S and DomainBed baselines. This supports our hypothesis that CLIP is
much more robust than other SSL methods due to its domain-agnostic augmentations.
6.3	Towards generic robust representations with SSL
In the previous section, we finetuned CLIP in a task specific fashion by optimizing R [Y | Z] and our
CAD bottleneck. To get generic (task agnostic) robust representations, one should instead directly
use our objectives on a sufficiently large dataset with image-text augmentations. Unfortunately, we
cannot fully train CLIP with our bottlenecks as we do not have access to CLIP’s original dataset and
sufficient compute. In this section, we aim to emulate such training of generic robust representations.
To do so we used LAION-400M (Schuhmann et al., 2021) that is a public dataset that contains 400M
web-crawled image-text pairs. Due to our computational budget, we again froze the pretrained CLIP
L and only finetuned an additional MLP with our LEnt. We used LEnt as it only requires access to paired
image X and text A but no prior information about domain D. As in CLIP’s paper, we evaluated the
learned representation Z in Taori et al.’s (2020) realistic setting, where a linear classifier h from Z is
trained on ImageNet and tested on 7 natural distribution shift datasets. Details in Appx. E.4.
Would training CLIP with a bottleneck have improved its robustness? As shown in the last
2 rows of Table 2, finetuning CLIP L on LAION with LEnt (Tuned w/ Ent) outperforms finetuning
without bottleneck (Tuned w/o Ent) on all 7 distribution shift datasets. This suggests that directly
training CLIP with our Ent bottleneck would improve the robustness of learned representations. We
hypothesize that the gains could be larger if SSL models trained LEnt end-to-end. In Appx. F.4, we
show similar results on DomainBed. Note that both models underperform the original CLIP L, likely
due to non-end-to-end training and LAION data with (possibly) lower quality than CLIP’s data.
Table 2: Finetuning CLIP L on LAION with an entropy bottleneck improves its robustness compared
to finetuning without on 7 distribution shift datasets. The pretrained CLIP L is still better likely due
to end-to-end training with higher quality data. IN denotes ImageNet.
	IN	IN-V2	IN-S	YT-BB	IN-Vid	ObjectNet	IN-A	IN-R	Avg.
	 CLIP L	75.2	64.2	41.0	58.4	71.6	42.8	27.5	62.9	52.6
Tuned w/o Ent	73.8	62.1	37.0	56.9	68.8	41.3	26.0	58.1	50.0
Tuned w/ Ent	74.2	62.7	38.9	58.1	70.1	42.1	26.2	60.8	51.3
7	Conclusion
We gave a simple variational characterization of all representations on which source-risk minimizers
are guaranteed to generalize to target domains that preserve the Bayes predictor. Similar to previous
work, our theory strongly implies the need for target information when learning representations for
domain generalization. Nevertheless, we identified a domain-agnostic property of data augmentations
that make it possible to learn optimal representations from unlabelled data. Thus, we showed that it is
possible to learn robust representations using only large sources of inputs X and augmentations A.
There are caveats that need to be addressed in future work. First, we studied an idealized DG,
which assumes access to the population distributions. This gives insights into the challenges that are
specific to DG, rather than finite sample challenges faced throughout ML. Second, we considered risk
minimizers from an unconstrained hypothesis class. The support constraint can likely be weakened,
if the hypothesis class is constrained. Finally, we focus only on optimal representations, but it would
be interesting to characterize approximately optimal representations. Nevertheless, in this idealized
setting, our characterization is a springboard from which all future objectives can be derived, and, in
general, it brings us closer to the goal of robust machine learning systems.
9
Published as a conference paper at ICLR 2022
Acknowledgement We would like to thank Elliot Creager, Roger Grosse, Elan Rosenfeld, Guodong
Zhang, Han Zhao, and anonymous reviewers for their helpful feedbacks and encouragements. Re-
sources used in preparing this research were provided, in part, by the Province of Ontario, the
Government of Canada through CIFAR, and companies sponsoring the Vector Institute. We acknowl-
edge the support of the Natural Sciences and Engineering Research Council of Canada (NSERC),
RGPIN-2021-03445.
Reproducibility For our theoretical results, we include formal assumptions, statements, and proofs
in Appxs. A and B. We include the detailed derivations of our algorithms in Appx. C. For our
experiments, we include experimental details for reproducing our results in Appx. E and have
released our code at https://github.com/ryoungj/optdom.
References
Alexander A Alemi, Ian Fischer, Joshua V Dillon, and Kevin Murphy. Deep variational information
bottleneck. arXiv preprint arXiv:1612.00410, 2016.
Martin Arjovsky, Leon Bottou,Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization.
arXiv preprint arXiv:1907.02893, 2019.
Johannes Balle, Valero Laparra, and Eero P Simoncelli. End-to-end optimized image compression.
arXiv preprint arXiv:1611.01704, 2016.
Johannes Balle, David Minnen, Saurabh Singh, Sung Jin Hwang, and Nick Johnston. Variational
image compression with a scale hyperprior. arXiv preprint arXiv:1802.01436, 2018.
Andrei Barbu, David Mayo, Julian Alverio, William Luo, Christopher Wang, Danny Gutfreund,
Joshua Tenenbaum, and Boris Katz. Objectnet: A large-scale bias-controlled dataset for pushing
the limits of object recognition models. 2019.
Sara Beery, Grant Van Horn, and Pietro Perona. Recognition in terra incognita. In Proceedings of the
European conference on computer vision (ECCV), pp. 456-473, 2018.
Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, et al. Analysis of representations
for domain adaptation. Advances in neural information processing systems, 19:137, 2007.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman
Vaughan. A theory of learning from different domains. Machine Learning, 79(1):151-175, 2010a.
Shai Ben-David, Tyler Lu, Teresa Luu, and David Pal. Impossibility theorems for domain adaptation.
In Yee Whye Teh and Mike Titterington (eds.), Proceedings of the Thirteenth International
Conference on Artificial Intelligence and Statistics, volume 9 of Proceedings of Machine Learning
Research, pp. 129-136, Chia Laguna Resort, Sardinia, Italy, 13-15 May 2010b. PMLR. URL
https://proceedings.mlr.press/v9/david10a.html.
Leon Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of
COMPSTAT’2010, pp. 177-186. Springer, 2010.
Mathilde Caron, Hugo Touvron, Ishan Misra, Herve Jegou, Julien Mairal, Piotr Bojanowski, and
Armand Joulin. Emerging properties in self-supervised vision transformers. arXiv preprint
arXiv:2104.14294, 2021.
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for
contrastive learning of visual representations. In International conference on machine learning, pp.
1597-1607. PMLR, 2020.
Yann Dubois, Douwe Kiela, David J Schwab, and Ramakrishna Vedantam. Learning optimal repre-
sentations with the decodable information bottleneck. In H. Larochelle, M. Ranzato, R. Hadsell,
M. F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33,
pp. 18674-18690. Curran Associates, Inc., 2020. URL https://proceedings.neurips.
cc/paper/2020/file/d8ea5f53c1b1eb087ac2e356253395d8-Paper.pdf.
Yann Dubois, Benjamin Bloem-Reddy, Karen Ullrich, and Chris J. Maddison. Lossy compression for
lossless prediction. arXiv preprint arXiv:2106.10800, 2021.
10
Published as a conference paper at ICLR 2022
Chen Fang, Ye Xu, and Daniel N Rockmore. Unbiased metric learning: On the utilization of multiple
datasets and web images for softening bias. In Proceedings of the IEEE International Conference
on Computer Vision, pp. 1657-1664, 2013.
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Frangois
Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks.
The journal of machine learning research, 17(1):2096-2030, 2016.
Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation.
Journal of the American statistical Association, 102(477):359-378, 2007.
Mingming Gong, Kun Zhang, Tongliang Liu, Dacheng Tao, Clark Glymour, and Bernhard Scholkopf.
Domain adaptation with conditional transferable components. In International conference on
machine learning, pp. 2839-2848. PMLR, 2016.
Ian Goodfellow. Nips 2016 tutorial: Generative adversarial networks. arXiv preprint
arXiv:1701.00160, 2016.
Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. In International
Conference on Learning Representations, 2021. URL https://openreview.net/forum?
id=lQdXeXDoWtI.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770-778, 2016.
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul
Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robustness: A critical
analysis of out-of-distribution generalization. arXiv preprint arXiv:2006.16241, 2020.
Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song. Natural adver-
sarial examples. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, pp. 15262-15271, 2021.
Fredrik D Johansson, David Sontag, and Rajesh Ranganath. Support and invertibility in domain-
invariant representations. In The 22nd International Conference on Artificial Intelligence and
Statistics, pp. 527-536. PMLR, 2019.
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron
Maschinot, Ce Liu, and Dilip Krishnan. Supervised contrastive learning. arXiv preprint
arXiv:2004.11362, 2020.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Naveen Kodali, Jacob Abernethy, James Hays, and Zsolt Kira. On convergence and stability of gans.
arXiv preprint arXiv:1705.07215, 2017.
David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai
Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapola-
tion (rex). In International Conference on Machine Learning, pp. 5815-5826. PMLR, 2021.
Bo Li, Yifei Shen, Yezhen Wang, Wenzhen Zhu, Colorado J Reed, Jun Zhang, Dongsheng Li, Kurt
Keutzer, and Han Zhao. Invariant information bottleneck for domain generalization. arXiv preprint
arXiv:2106.06333, 2021.
Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Deeper, broader and artier domain
generalization. In Proceedings of the IEEE international conference on computer vision, pp.
5542-5550, 2017.
Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with adver-
sarial feature learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pp. 5400-5409, 2018a.
11
Published as a conference paper at ICLR 2022
Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, and Dacheng Tao.
Deep domain generalization via conditional invariant adversarial networks. In Proceedings of the
European Conference on Computer Vision (ECCV), pp. 624-639, 2018b.
Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with
deep adaptation networks. In International conference on machine learning, pp. 97-105. PMLR,
2015.
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Deep transfer learning with joint
adaptation networks. In International conference on machine learning, pp. 2208-2217. PMLR,
2017.
Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds
and algorithms. arXiv preprint arXiv:0902.3430, 2009.
A Tuan Nguyen, Toan Tran, Yarin Gal, Philip HS Torr, and Atilim GUneS Baydin. Kl guided domain
adaptation. arXiv preprint arXiv:2106.07780, 2021.
Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive
coding. arXiv preprint arXiv:1807.03748, 2018.
Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching
for multi-source domain adaptation. In Proceedings of the IEEE/CVF International Conference on
Computer Vision, pp. 1406-1415, 2019.
Ben Poole, Sherjil Ozair, Aaron Van Den Oord, Alex Alemi, and George Tucker. On variational
bounds of mutual information. In International Conference on Machine Learning, pp. 5171-5180.
PMLR, 2019.
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal,
Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.
Learning transferable visual models from natural language supervision. In Marina Meila and Tong
Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning, volume
139 of Proceedings of Machine Learning Research, pp. 8748-8763. PMLR, 18-24 Jul 2021. URL
https://proceedings.mlr.press/v139/radford21a.html.
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classifiers
generalize to imagenet? In International Conference on Machine Learning, pp. 5389-5400. PMLR,
2019.
Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust
neural networks for group shifts: On the importance of regularization for worst-case generalization.
arXiv preprint arXiv:1911.08731, 2019.
Nikunj Saunshi, Orestis Plevrakis, Sanjeev Arora, Mikhail Khodak, and Hrishikesh Khandeparkar.
A Theoretical Analysis of Contrastive Unsupervised Representation Learning. In Kamalika
Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference
on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97
of Proceedings of Machine Learning Research, pp. 5628-5637. PMLR, 2019. URL http:
//proceedings.mlr.press/v97/saunshi19a.html.
Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton Mullis,
Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran Komatsuzaki. Laion-400m: Open dataset of
clip-filtered 400 million image-text pairs. arXiv preprint arXiv:2111.02114, 2021.
Ohad Shamir, Sivan Sabato, and Naftali Tishby. Learning and generalization with the information
bottleneck. Theor. Comput. Sci., 411(29-30):2696-2711, 2010. doi: 10.1016/j.tcs.2010.04.006.
URL https://doi.org/10.1016/j.tcs.2010.04.006.
Vaishaal Shankar, Achal Dave, Rebecca Roelofs, Deva Ramanan, Benjamin Recht, and Ludwig
Schmidt. Do image classifiers generalize across time? arXiv preprint arXiv:1906.02168, 2019.
Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu. Wasserstein distance guided representation
learning for domain adaptation. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018.
12
Published as a conference paper at ICLR 2022
Ravid Shwartz-Ziv and Naftali Tishby. Opening the black box of deep neural networks via information.
CoRR, abs/1703.00810, 2017. URL http://arxiv.org/abs/1703.00810.
Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In
European conference on computer vision, pp. 443-450. Springer, 2016.
Remi Tachet des Combes, Han Zhao, Yu-Xiang Wang, and Geoffrey J Gordon. Domain adaptation
with conditional distribution matching and generalized label shift. Advances in Neural Information
Processing Systems, 33, 2020.
Rohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht, and Ludwig
Schmidt. Measuring robustness to natural distribution shifts in image classification. arXiv
preprint arXiv:2007.00644, 2020.
Lucas Theis, Wenzhe Shi, Andrew Cunningham, and Ferenc Husz虹 Lossy image compression with
compressive autoencoders. arXiv preprint arXiv:1703.00395, 2017.
Naftali Tishby, Fernando C Pereira, and William Bialek. The information bottleneck method. arXiv
preprint physics/0004057, 2000.
Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep
hashing network for unsupervised domain adaptation. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pp. 5018-5027, 2017.
Haohan Wang, Songwei Ge, Eric P Xing, and Zachary C Lipton. Learning robust global representa-
tions by penalizing local predictive power. arXiv preprint arXiv:1905.13549, 2019.
Luyu Wang, Pauline Luc, Adria Recasens, Jean-Baptiste Alayrac, and Aaron van den Oord. Multi-
modal self-supervised learning of general audio representations. arXiv preprint arXiv:2104.12807,
2021.
Aolin Xu and Maxim Raginsky. Minimum excess risk in bayesian learning. arXiv preprint
arXiv:2012.14868, 2020.
Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain
adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020.
Han Zhao, Remi Tachet Des Combes, Kun Zhang, and Geoffrey Gordon. On learning invariant
representations for domain adaptation. In International Conference on Machine Learning, pp.
7523-7532. PMLR, 2019.
13
Published as a conference paper at ICLR 2022
Appendix
Table of Contents
A	Preliminaries	15
A.1 Notation ............................................................ 15
A.2 Definitions ......................................................... 15
A.3 Assumptions ......................................................... 17
B	Proofs	19
B.1	Lemmas for general losses .......................................... 19
B.2	Proof of Theorem 1 ................................................. 19
B.3	Impossibility results .............................................. 23
B.4	Augmentations ...................................................... 25
C	Practical objectives	27
C.1	Mutual information bottleneck B[Z, X, Y, D]	=	I[Z; X] .............. 27
C.2 Entropy bottleneck B[Z, X, Y, D] = H[Z] ............................. 28
C.3	Contrastive adversarial domain bottleneck B[Z,	X, Y, D] = I[Z; D] .. 29
C.4	Conditional CAD	B[Z, X, Y, D]	= I[Z;D |Y]	.......................... 30
D	Extended Related Work	32
E	Experimental Details	32
E.1	Scientific ......................................................... 32
E.2	Bridge ............................................................. 33
E.3	DomainBed .......................................................... 34
E.4	LAION .............................................................. 35
F	Additional Experimental Results	36
F.1	Scientific ......................................................... 36
F.2	Bridge ............................................................. 36
F.3	DomainBed .......................................................... 37
F.4	LAION .............................................................. 38
14
Published as a conference paper at ICLR 2022
A	Preliminaries
A. 1 Notation
For the most part, we will assume that all spaces are discrete probability spaces. A full list of
assumptions is found at Appx. A.3.
General The image of a set A ⊆ X under a function f : X → Y is denoted f→ (A) =
{f (x) | X ∈ A}. Thepre-image is denoted f J(B) = {x ∈ X | f (x) ∈ B} for B ⊆ Y.
Probability Random variables (r.v.) are denoted by uppercase letters (e.g., X), and their sam-
ple space and realizations are denoted by the corresponding calligraphic (e.g., X) and lowercase
letters (e.g., x) respectively. The probability mass function (pmf) of a random variable X is
denoted as pX . We use capital P instead of p to denote the measure under p. The support
supp(pX) of a discrete distribution is the set of all points x ∈ X with positive probability, i.e.,
supp(pX) = {x ∈ X | pX (x) > 0}. The space of all probability distributions on X is denoted
P(X) = {pχ 1 Px(X) ≥ 0 and Pχ∈χPx(X) = 1}.
When it is necessary to be explicit, we will denote ‘X is distributed as pX’ using the notation
X & pχ. Expectations are written as: EpX [f (X)], independence of two r.v. as ∙⊥⊥∙, conditional
independence as ∙⊥⊥ ∙ | ∙.
For jointly distributed random variables (X, Y ) taking value in (t.v.i.) X × Y, the conditional
distribution is denoted as PY ∣ X : Y ×X → [0,1]. For convenience, let PY ∣ X = PY ∣ X(∙ | x) be the
conditional distribution of Y given X. All random variables are independently distributed, unless an
explicit joint distribution or coupling is given.
A.2 Definitions
We are interested in prediction problems with domain shift. There are three random variables: the
target domain Dt, the input X, the label Y . They have the following joint distribution:
(Dt,χ,γ) & PDt ∙ Pχ,γ | Dt	⑼
where we drop the arguments of the probability densities for clarity. We make a variety of convenience
assumptions on these random variables (Assumption 6). Crucially, we will be making the Bayes
invariance assumption on PDt,X,Y that can be thought of as a generalized covariate shift assumption
(Assumption 4).
We will be studying the effect of changing the representation of the data. This is done by “encoding”
X into a representation Z using a conditional distribution PZ | X .
Definition 1 (Encoder). An encoder is a conditional distribution PZ | X : Z × X → [0, 1] from the
input space X to the representation space Z .
The data together with the representation has the following joint:
(Dt,x,y, Z) & PDt ∙ pχ,γ | Dt ∙ Pz | X	(IO)
The key thing to notice here is that Z is conditionally independent of Y, Dt given X . In particular,
the same encoder is used across all domains.
A.2. 1 Risk minimization
Our ultimate goal is to predict Y from the representation Z of X in a manner that is robust to changes
in the domain.
We formalize this in the standard way by making predictions γ ∈ Γ in a space of predictions or
actions. For example the prediction space may be the set of all possible labels Γ = Y, in which case
we would be predicting deterministic labels. Or we may predict a distribution over labels, in which
case the prediction space would be the set of all probability distributions on Y, i.e. Γ = P(Y).
A predictor is a function mapping inputs to predictions, i.e., f : X → Γ, or representations to
predictions, i.e., h : Z → Γ. For example, f may be a neural network that takes as input a sample x
and outputs a vector of logits that parameterize a softmax distribution over finitely many labels.
15
Published as a conference paper at ICLR 2022
We select predictors according to the risk defined via a loss function ` : Y × Γ → R≥0 ∪ {∞}:
Rf [Y IX] ：= Epχ,γ['(Y,f(x))].	(11)
In particular, we are interested in the Bayes (minimum) risk over all predictors:
R[Y |X] := inff Rf [Y |X] ,	(12)
We denote the set of all optimal predictors from X as
F*:= {f | Rf [Y [ X ] = R[Y∣ X ]}	(13)
Similarly, we define the risk Rh [Y | Z], the Bayes risk R [Y | Z], and the set of optimal predictors
HZ* :={h| Rh[Y|Z] =R[Y|Z]}	(14)
from Z, all of which vary as a function of the encoder pZ | X . Note, in the main body of the paper,
we omitted the subscript Z from H*Z for clarity, but we will keep it in the Appendices. We assume
that together our loss and prediction space always admit optima (Item 2 of Assumption 2), and thus
F* , H*Z are always non-empty.
We will be assuming that the risk admits unique optimal prediction when predicting from X (Item 3
of Assumption 2). Thus it makes sense to define the following:
Definition 2 (The Bayes predictor). The Bayes predictor f* : X → Γ is the unique predictor that is
optimal for all x ∈ X :
f * (x) = arg min EpY ∣。['(Y, γ)]	(15)
γ∈Γ
Definition 3 (The Bayes image). The image of all the inputs under the Bayes predictor will be
denoted as Γ* = f*→(X) and called the Bayes image.
Note that F* becomes a singleton {f*}, but it is not necessarily the case for HZ* since we will not be
making any uniqueness assumption on optimal prediction from Z .
A.2.2 Domain generalization
We are interested in controlling the risk in a domain generalization setting, and so we define the
domain-conditional risk,
Rf [Y IX]：= Epx,γ∣d['(Y,f (X))].	(16)
Rd [Y | X] , Fd* are defined as Eqs. (12) and (13), respectively, but with respect to Rfd. Similarly,
define the Bayes image for domain d as
Γd := f*→(supp(pχ |d)).	(17)
We also define domain-conditional quantities for prediction from a representation Z . The most
important term which we will be investigating is an idealization of the domain generalization worst-
case risk.
Definition 4 (IDG risk). Given an encoder pZ | X and a distribution pDt,Ds over a target domain Dt
and source domain Ds, the idealized domain generalization worst-case risk, IDG risk for short, is the
expected worst-case target risk taken over source minimizers, i.e.,
RIDG [Y I Z] := EpDt,D
「hwZ]
(18)
s
Note that the IDG risk is well-defined because HZ*,Ds is non-empty by Assumption 2. The desired
optimal representations, are then those that minimize the IDG risk.
Definition 5 (Optimal representations for IDG). An encoder pz* ∣ X is optimal for idealized domain
generalization if and only if it minimizes the IDG risk, i.e.,
RIDG[YIZ*]= inf RIDG[YIZ]
pZ | X
(19)
16
Published as a conference paper at ICLR 2022
A.3 Assumptions
We make a the following assumptions throughout the paper. All these assumptions should hold for
practical settings.
Assumption 1 (Convenience: discrete probability spaces). All data spaces (D, X , Y, Z, A) are
discrete spaces. Because the distributions of X, Y, D are fixed, we assume for convenience that
supp(pX) = X, supp(pY) = Y, and supp(pDt) = D.
Assumption 1 is a convenience assumption to avoid measure theory for the sake of clarity. It always
holds in practice due to finiteness of computers, i.e., all spaces will be finite but arbitrarily large. We
believe that our claims can nevertheless be generalized to typical continuous spaces with some minor
technical assumptions.
Assumption 2 (Losses admit optima). We assume that our risk always admits optimal predictions:
1.	∣Γ∣ > 1.
2.	For all PY ∈ P (Y), there exists γ* ∈ Γ, such that
Epγ['(Υ,Y*)] ≤ Epγ['(Υ,γ)]	∀ Y ∈ Γ.	(20)
3.	For all X ∈ X, there exist γ* ∈ Γ, such that
Epγ∣x['(Y,γ*)] < Epγ∣χ['(Y,γ)]	∀ γ = γ*.	(21)
Note that for log-loss '(y, Y) = - log Y(y) and finite Y, these assumptions are satisfied if Γ = P(Y)
where the optimal prediction for Item 3 is Y* = PY ∣ X by strict properness (Gneiting & Raftery,
2007). If We consider the 0-1 loss (reverse accuracy) '(y, γ) = 1 - 1[y = γ] with Γ = Y and a finite
label space where the optimal prediction for Item 3 is Y* = arg maxy∈Y PY | x(y), this assumption is
mostly satisfied, except we assume that PY | x has a unique mode.
Assumption 2 serves two purposes: Item 2 ensures that for any representation the optimal predictors
from Z exists such that the IDG risk is well-defined as in Def. 5; Item 3 ensures a unique Bayes
predictor from X , which simplifies the analysis and is satisfied by common losses as described above.
Assumption 3 (Cardinalities). We assume that
|Z| ≥∣r*∣≥ 2	(22)
Assumption 3 is very weak and ensures that optimal representations always exists (Prop. 3).
Assumption 4 (Generalized covariate shift). The Bayes predictor is optimal for all domains. I.e., for
all (x, d) ∈ supp(PX,Dt), Y ∈ Γ such that Y 6= f* (x), we have
Epγ∣x,d ['(Y,f *(x))] < Epγ∣χ,d['(Y,γ)].	(23)
For example, in the case of strictly proper scoring rules, e.g. log loss, covariate shift PY | X,D = PY | X
is equivalent to the invariance of the Bayes predictor. For the 0-1 loss, this is guaranteed by invariance
of the most likely label. For MSE it is guaranteed by the invariance of the expected label. In the latter
two cases, Assumption 4 is less stringent than the typical covariate shift assumption.
Assumption 4 is the core assumption for our theoretical results. It ensures that source and target
domains are related in a useful way that can be utilized by the representation.
Assumption 5 (Constant Bayes image). The Bayes image is invariant across domains, i.e., for all
d∈D,
Γ*d = Γ* .	(24)
For the case of 0-1 loss, this simply means that the label set for all domains is the same, which is
trivial. For log-loss, this means that the set of possible conditional distributions Γd* = {PY | x | x ∈
supp(PX | d)} is the same across domains.
17
Published as a conference paper at ICLR 2022
Assumption 5 is crucial to be able to learn. Without it, in the extreme case, one could set each domain
to be all examples associated with a single element from the label set (or the Bayes image set) in
which case it is impossible to generalize across different domains. Assumption 5 is also necessary to
guarantee the existence of optimal representations as in Prop. 3.
Assumption 6 (Domain joint). pDt,Ds is any distribution such that supp(pDt,Ds) = D × D.
In a simplified scenario, one could define the source Ds and target Dt as i.i.d. r.v. from pDt, where
PDtDs = PDt ∙ PDs = PDt ∙ PDt and Assumption 6 is trivially satisfied.
18
Published as a conference paper at ICLR 2022
B Proofs
B.1 Lemmas for general losses
An important result that we will be using is the generalized data processing inequality of Bayes risk
(Xu & Raginsky, 2020; Dubois et al., 2021). We include it here for completeness.
Lemma 1 (Generalized DPI (Xu & Raginsky, 2020; Dubois et al., 2021)). Let Z - X - Y be a
Markov chain of random variables. For any loss function `,
R[Y |X] ≤ R[Y |Z] .	(25)
For the case of strictly proper losses (Assumption 2) we can go one step further.
Lemma 2. Let Z - X - Y be a Markov chain of random variables. Then, under Assumptions 1
and 2 we have that
R[Y | Z]	= R[Y	| X]	o	∀h*	∈HZ,∀(χ,z)	∈ Supp(px,z),	h*(z)	= f *(x).	(26)
Proof. Suppose that for all h ∈ HZ We have h (Z) = f * (x) on the support of PXZ. Then,
R[Y I X]= Epx,γ['(Y,f *(x))]	(27)
= EpX,Y pZ |X ['(Y,f *(X))]	(28)
= EpX,Y pZ |x ['(Y,h*(Z))]	(29)
=Epz,γ ['(Y,h*(Z))]	(30)
=R[Y|Z].	(31)
NoW suppose there exists a h* ∈ H*Z and a pair (x0, z0) ∈ supp(pX,Z) such that h* (z0) 6= f*(x0).
Then
R[Y |Z]	(32)
=Epx,z pγ∣x ['(Y,h*(Z))]	(33)
=PX,Z(x0,z0) EpY | xo['(γ,h*(ZO))] +	E	PXZ(x, Z)EpY | x['(Y,h*(Z))]	(34)
(x,z)6=(x0,z0)
≥ PX,Z (x0,zO)EpY | xo['(γ,h* (ZO))] +	X	PX,Z (x,Z)EpY | χ['(γ,f *(x))]	(35)
(x,z)6=(x0,z0)
>PX,Z(x',zO)EpY | xo['(γ,f *(x0))]+	X	Px,z(x, Z)EpY ∣χ['(γ,f *(x))]	(36)
(x,z)6=(x0,z0)
= R [Y | X]	(37)
Eq. (35) folloWs by Item 3 of Assumption 2 along With the definition of f*. Eq. (36) folloWs by Item 3
of Assumption 2 and the fact that h* (ZO) 6= f* (xO). This completes the proof, because Lemma 1
prevents R[Υ ∣ Z] < R[Y ∣ X].	□
B.2 Proof of Theorem 1
First We Will shoW that the desired representation exists by taking all inputs for Which the Bayes
predictor predicts similarly and “bucketing” them to the same representation. This is a direct extension
of the example from Dubois et al.’s (2020) Proposition 6, to the case of proper losses.
Proposition 3 (Existence of optimal representations). Under Assumptions 1 to 5, there exists an
encoder pz* ∣ X that is optimalforEq. (3), i.e.,
Pz* | x ∈ arg min R[Y I Z ] s.t. ∀ d ∈D, Supp(PZ | d) = Supp(PZ).	(38)
pZ | X
Moreover, we have that
R[YIX] =R[YIZ*].	(39)
19
Published as a conference paper at ICLR 2022
Proof. Because we assume arbitrary encoders pZ | X, the essence of this construction is simple: we
embed the Bayes image into Z. Indeed, let φ : Γ* → Z be any one-to-one function, which exists due
to Assumption 3 (here we use deterministic one-to-one function for simplicity, the construction can
be easily extended to stochastic case). Then let Z* = φ(f * (X)). We now verify the properties of
Pz* I X.
1.	Z* satisfies R [Y | X] = R [Y | Z*]. Indeed,
R[Y IX ] = Epχ,γ['(Y,f *(X))]	(40)
= EpX,YpZ* |X ['(Y,f *(X))]	(41)
=Epz*,γ['(Y,φ-1(Z *))]	(42)
≥ R[Y | Z*] .	(43)
Eq. (42) is by our construction of Z* and Eq. (43) is by the definition of the Bayes risk.
Due to the data processing inequality of Bayes risk (Lemma 1) we also have R [Y | X] ≤
R [Y | Z*], from which we conclude that R [Y | X] = R [Y | Z*] and that Eq. (39) holds.
2.	Recall that Γ* = f *→(X) and Γ3 = f *→(supp(pχ ∣d)). Now let us compute the desired
support for all d ∈ D:
supp(pZ* | d) = φ→(Γd*)	(44)
= φ→(Γ*)	(45)
= supp(pZ* ).	(46)
Eq. (45) is by Assumption 5.
Because R [Y | X] is the minimum achievable risk by any encoder regardless of constraint (this is by
Lemma 1), this implies that pz* ∣ X is an optimal encoder for Eq.(3).	□
The following lemma essentially says that when R [Y | Z] is minimized, then the optimal predictors
for each domain all agree on the intersection of their support.
Lemma 3. Let pZ | X be an encoder such that R [Y | Z] = R [Y | X]. Under Assumptions 1 and 2,
we have that for all z ∈ supp(pZ), there exists γ* ∈ Γ such that
Epγ∣z['(Y,Y*)] < Epγ∣z['(Y,γ)]	∀ Y = γ*.	(47)
In other words, the restriction of any h* ∈ H*Z to supp(pZ ) is unique. If, in addition, Assumption 4
holds, then for all (z, d) ∈ supp(pZ,Dt), γ ∈ Γ such that γ 6= h* (z),
Epγ∣z,d ['(Y,h*(z)] < Epγ∣z,d['(Y,Y)].	(48)
In other words, the restriction of any h ∈ H*Z,d to supp(pZ | d) is unique and equal to h*.
Proof. For the first result, let z ∈ supp(pZ) and consider x ∈ supp(pX | z). By Lemma 2, it must be
the case that f* is constant on supp(pX | z). Thus, we can pick γ* = f*(x). Now, let γ 6= γ*. We
have that,
EpY । z ['(Y, Y*)]= EpX । ZpY । x ['(Y,Y *)]	(49)
=EpxizPYix ['(K/ *(X ))]	(50)
< EpX | z pY |X ['(Y,Y)]	(51)
=Epγ∣z['(Y,γ)].	(52)
Eq. (49) is due to the conditional independence ofY and Z given X. Eq. (51) is due to Assumption 2
and the definition of the Bayes predictor. Let h* : supp(pZ) → Γ be the unique Bayes predictor
from Z .
Now, for the second result, note that
R[Y|X]=Rf*[Y|X]
(53)
20
Published as a conference paper at ICLR 2022
=EpDt (d)Rd*[Y∣ X ]	(54)
d∈D
= X pDt (d) Rd [Y | X] ,	Assumption 4	(55)
d∈D
and
R[Y | Z] = Rh* [Y | Z]	(56)
=X PDt (d)Rh*[Y∣Z]	(57)
d∈D
≥ XpDt(d)Rd[Y|Z],	(58)
d∈D
where Eq. (58) is due to the definition of (domain-conditional) Bayes risk. Then
R[Y|Z]-R[Y|X] ≥ XpDt(d)	Rd[Y|Z]-Rd[Y|X]	(59)
d∈D
≥ 0.	Lemma 1 conditioned on d
(60)
Thus, any encoder that achieves R [Y | Z] = R [Y | X] also satisfies Rd [Y | Z] = Rd [Y | X] for
all d ∈ D since we assume that supp(pDt) = D in Assumption 1. Now, let d ∈ D. An argument
analogous to Lemma 2 gives us,
∀h ∈ HZ,d,∀(x,z) ∈ Supp(Px,z | d), h(z)= f *(x) = h*(z).	(61)
Eq. (61) is derived from Rd [Y | Z] = Rd [Y | X] using Assumption 4 in place of Item 3 of As-
sumption 2 for a specific domain d. Let Z ∈ Supp(PZ ∣ d) and Y ∈ Γ such that Y = h*(z). Since
Supp(PX । z,d) ⊆ Supp(PX । Z), f * is a constant on Supp(PX ∣ z,d) and equal to h*. Now, as above,
we have that
EpY | z,d ['(Y, h*(z))] = EpX 1 z,dPY | X,d ['(Y, h*(z))]	(62)
=Epx∣z,dpγ∣x,d ['(Y,f *(X))]	(63)
< EpX | z,dpY | X,d ['(Y, Y)]	(64)
= EpY | z,d ['(Y, Y)] .	(65)
Eq. (64) is due to Assumption 4.	口
Corollary 1. Let PZ | X be an encoder such that R [Y | Z] = R [Y | X]. Under Assumptions 1, 2
and 4 we have that H*Z ⊆ H*Z,d for all d ∈ D and that for all ds, dt ∈ D
in*f	Rdt [Y | Z]=Rdt [Y | Z]
h∈HZ,ds
(66)
Proof. HZ ⊆ HZd is immediate from Lemma 3. Now, we have that Rf [Y [ Z] ≥ Rdt [Y | Z]. So,
the result follows by taking any h ∈ HZ ⊆ HZd in the inf ofEq. (66).	口
Theorem 2 (Characterizing optimal representations for IDG, equiv. Theorem 1). Under Assump-
tions 1 to 6, an encoder PZ | X is optimal for idealized domain generalization if and only if it minimizes
the Bayes risk while matching the support of PZ | d and PZ for all d ∈ D, i.e.,
PZ | X ∈ arg min R [Y | Z]	(67)
pZ | X
S.t. ∀ d ∈ D, Supp(PZ | d) = Supp(PZ)	(68)
Proof. The IDG risk is lower bounded by R [Y | X]:
RIDG [Y | Z ] ≥ EpDs,DtJIJnf RDt [Y I Z ]	(69)
h∈HZ,Ds
21
Published as a conference paper at ICLR 2022
≥ EpDs,Dt RDt [Y |Z]	(70)
≥ EpDs,Dt RDt [Y | X]	Lemma 1	(71)
= R [Y | X]	Assumption 4	(72)
We will now show that this lower bound is achieved by an encoder if and only if it satisfies Eqs. (67)
and (68), which exist by Prop. 3.
Sufficiency ( U= ): Let PZ ∣ X be an encoder that satisfies Eqs. (67) and (68). Note that R [Y | Z]=
R[Y | X] by Prop. 3. Let h ∈ HZ, then We have the following IDG risk
RIDG[Y|Z]	(73)
=EpDs,Dt	SUp Epz,γ∣Dt ['(Y,h(Z))]	(74)
h∈HZ,Ds	_
= EpDs,Dt	SUp Epz γ । D∣'(Y,h*(Z))]	Lemma 3 under matching support (75)
h∈HZ,Ds	_
=EpDthEpz,γ∣ Dt['(Y,h"(Z))]]	constant w.r.t Ds	(76)
= R [Y | Z] = R [Y | X]	(77)
Necessity ( =⇒ ): If the IDG risk is R [Y | X], then it must be the case that
R [Y | Z] = R [Y | X]	(78)
SUp	Rhdt	[Y|Z]	=Rdt	[Y|Z]	∀(ds,dt)	∈SUpp(pDs,Dt)	(79)
h∈HZ,ds
We will prove by contrapositive that Eq. (79) implies support match (Eq. (68)). Suppose that the
support match does not hold. Since SUpp(pZ) = ∪d∈DSUpp(pZ | d) and SUpp(pDs,Dt) = D × D
(Assumption 6), there must exist (ds, dt) ∈ SUpp(pDs,Dt) such that SUpp(pZ | ds ) 6= SUpp(pZ | ds ).
Define the set S = SUpp(PZ | ds) ∩ SUpp(PZ | dt) and S = SUpp(PZ | dt) \ SUpp(PZ | ds), let P =
PZ । dt (S), and let h ∈ HZ. Then,
SUp Rdht [Y | Z]	(80)
h∈HZ,ds
=SUp PEργ,z | S,dt ['(Y,h(Z))] + (1 - ρ) Epγ,z | S,dt ['(Y,h(Z))]	(81)
h∈HZ,ds
=SUp P Epγ,z | S,dt ['(Y,h*(Z ))] + (1 — ρ) EpYZ | S dt['(Y,h(Z))]	Lem.3 (82)
h∈HZ,ds
=P Epγ,z | S,dt ['(Y,h*(Z))]+ (1 — ρ) SUp EpYZ | S dt['(Y,h(Z))]	(83)
h∈HZ,ds
= Rdt [Y | Z] + (1 — ρ) SUp EpYZ	['(Y,h(Z))-'(Y,h*(Z))]	(84)
h∈HZ,ds	, । , t
> Rdt [Y | Z]	Lem. 3	(85)
Eq. (85) uses the following reasoning. 1 一 ρ > 0 due to support mismatch. For any h ∈ HZ,ds such
that h = h on S (such an h exists by Item 1 of Assumption 2), we have that
Epγ,Z∣s,dt ['(Y,h(Z)) — '(Y,h*(Z))] > 0	(86)
by Lemma 3.	□
As a corollary from the proof strategy we directly have that the optimal DG risk is simply R [Y | X].
This means that using the optimal encoder one can actually perform just as well by training on the
source as if you were to directly train on the target using the raw data.
Corollary 2 (Optimal IDG Risk). Under Assumptions 1 to 6, inf pZ | X RIDG [Y | Z] = R [Y | X].
22
Published as a conference paper at ICLR 2022
B.3	Impossibility results
As a direct corollary of Thm. 2 we know that it is impossible to learn an optimal representation
without knowledge or assumptions on the target domain. We can actually prove the following much
stronger negative result, which essentially states that it is impossible to find a useful representation
without having some information about the target domain. Specifically, we prove that if there exists a
non-trivial target domain on which the representation is advantageous then there exists an infinite
amount of target domains on which it is disadvantageous compared to predicting from a constant.
For clarity, we will focus on the proof for the standard accuracy (0-1 loss) which is much shorter
and simpler to understand, but note that we can generalize the proof to all losses with the right
assumptions.
The key is that outside of the source domain, the label distribution is unconstrained because general-
ized covariate shift has no effect. In other words, for any domain which gives some probability mass
on an example that has not been seen during training, then all possible labels for that example gives
a valid domain. Furthermore, if there exists one domain on which the representation is good, then
one can construct a domain on which the representation is bad simply by labelling this point as the
constant prediction.
Proposition 4 (No free lunch for learning representations for IDG, equiv. Proposition 1). Let ` be
the 0-1 loss with prediction space Γ = Y. Let Rep : P(X, Y) → P(Z|X) be any algorithm for
choosing an encoder pZ | X from the data distribution pX,Y, C be any constant r.v. that t.v.i. Z, and
pX,Y | ds be any desired source distribution such that
•	there is a unique constant prediction YC = arg miny∈γ Epγ ∣ ds ['(K y)],
•	and |X \ supp(pX | ds)| > 1.
Let pZds | X := Rep(pX,Y | ds ) be the chosen source encoder. If there exists a target domain pX,Y | dtg
such that
•	(Non-trivial support) 0 = SUpp(PX ∣ dg) ⊆ X \ SUpp(PX ∣ d,)；
•	(Satisfies Bayes image invariance) Γjg = Y, i.e., there is at least one example for every
possible label;
•	(Source encoder is useful) PZds | X performs better than a constant representation,
sup	Rhdtg [Y |Zds] <
h∈HZ,
SUp Rdhtg [Y | C] ,
h∈HC,ds
(87)
Then there exist multiple target domains dtb such that PZds | X underperforms a constant encoder,
SUp	Rdhtb [Y |Zds] > SUp Rhdtb [Y |C].	(88)
h∈HZds,ds	h∈HC,ds
Proof. Let h ∈ HZd d be any source Bayes predictor corresponding to our encoder. Partition Z
according to whether h predicts like the constant or not:
Zc ：= {z ∈Z∣ h*(z) = γc}	Z=c ：= Z \ Zc.	(89)
We know by assumption that dtg is s.t.
SUp	Rdhtg	[Y	|Zds]	< SUp	Rhdtg	[Y	|C],	(90)
h∈HZds,ds	h∈HC,ds
which is clearly only possible if
PZds | dtg (Z6=C) > 0.	(91)
In other words, there exists some input x6=C ∈ X \ SUpp(PX | ds ) that will get represented outside of
the constant region, i.e.,
PZds | x6=C (Z6=C) > 0.	(92)
23
Published as a conference paper at ICLR 2022
We will now construct the desired bad domain dtb by giving nearly all mass to this x6=C, specifically,
let pX | dtb (x6=C) = 1 - δ for some 0 < δ < 1. We assign this example to the constant label, i.e.,
pY | x C,dtb (γC) = 1. The rest of the target domain mass δ is distributed as with the source domain,
i.e., Pχ,γ । db (x, y) = δ ∙ pχ,γ∖ds (x, y) for all χ,y ∈ Supp(Px,y ∣ ds). Importantly, the constructed
domain dtb is valid. Indeed, the Bayes image is the same as the source’s (Assumption 5), because
we removed no prediction γ from the source’s Bayes image (δ > 0). We added no new prediction γ,
because f * (X=C) = YC ∈ Y which must already have been in Γ* due to the validity of dg.
Now let us compute the desired risk for that “bad” domain and show that the desired encoder performs
worse than a constant encoder.
sup	Rdhtb [Y | Zds]	(93)
h∈HZds,ds
= sup (1-δ)EpZd |x C[1-1[γC=h(Zds)]]+δRhds [Y |Zds]	(94)
h∈HZds,ds	ds =C
≥ (1 - δ)(1 - PZds | x6=C (ZC))
= (1 - δ)PZds | x6=C (Z6=C)
(95)
(96)
In contrast, it is easy to show that suph∈H*	R? [Y | C] ≤ δ because the constant predictor would
C,ds
be perfect for x6=C. So any choice of 0 < δ <
IPZds | X=C (Z=C∖, would satisfy Eq. (88). We
1+PZds | x6=C (Z 6=C)
conclude the proof by noting that there are infinitely many such choices of δ, and any choice of those
would result in a different valid bad domain dtb .
□
Note that representations can often be much worse than using a constant r.v. Specifically, if an
encoder pZ | X maps an x outside of the source support then there exists an infinite number of target
domains where that representation is the worst possible representation.
Proposition 5 (Worst representation). Let Rep,pY,X | ds , pZds | X, ` be as in Prop. 4, and > 0. If
there exists an example xb ∈ X \ supp(pX | ds ) that is mapped outside of the source support, i.e.,
Supp(PZds | Xb) ∩ Supp(PZ | ds) = 0, then there exist many target domainspχγ ∣ dt s.t. PZds ∣ X is E
close to the worst possible loss, i.e.,
Sup	Rdht [Y | Zds] ≥ 1 - E.	(97)
h∈H*Zds,ds
Proof. By assumption there exists an xb whose support is outside the source support. Then similarly
to Prop. 4 we construct a bad target domain dt by giving nearly all mass to that example PX | dt (xb) =
1 - δ where δ > 0 and assign with probability 1 to some label that is in the source Bayes image,
i.e., PY | xb,dt (γb) = 1 for some γb ∈ Γ*ds . The rest of the target domain mass δ is distributed as in
Prop. 4 to the source inputs. As in Prop. 4, such a target domain dt satisfies our assumptions. Now let
us compute the risk for that dt and show that the desired encoder performs arbitrarily bad.
Sup	Rhdt [Y|Zds]	(98)
h∈H*Zds,ds
=Sup (1 - δ)Eρz	[1 - 1[γb = h(Zds)]]+ δRhs [Y | Zds]	Eq. (94)	(99)
h∈H*Zds,ds	ds b
≥ sup (1 — δ)Eρzd ∣χb [1 — 1[Yb = h(Zds)]]	(100)
h∈H*Zds,ds	ds b
= 1 - δ	(101)
Eq. (101) uses the fact that H*Zd ,ds is unconstrained outside of the source support and that by
assumption Supp(PZds | xb) ∩ Supp(PZds | ds ) = 0. To achieve the sup 1 - δ it then suffices to predict
an γ 6= γb ∈ Γ. We thus see that Eq. (97) holds for dt as long as 0 < δ < E. We conclude the
proof by noting that there is an infinite possible choices of δ each of which give rise to a bad target
domain.	□
24
Published as a conference paper at ICLR 2022
B.4	Augmentations
Proposition 2 shows that the optimal representations for IDG can be learned with augmentations in a
self-supervised fashion. Here, we provide formal definitions, assumptions, and proofs.
Definition 6 (Augmenter). An augmenter is a conditional distribution pA | X : A × X → [0, 1] from
the input space X to an augmentation space A. For example, in CLIP X is the space of images and A
is the space of text. In standard SSL, A is typically the same as X (e.g., both X and A are the space
of images).
Definition 7 (Augmentation conditional set). Given an augmenter pA | X, define the augmentation
conditional set as the set of conditionals of A given X :
P*(A|X):= {pa∖x |X ∈X}	(102)
Similarly, we can define the augmentation conditional set for domain d:
Pd(A | X) := {pa | X | X ∈ SUpp(PX | d)}	(103)
These sets are clearly countable. Note that the augmentation conditional set can be seen as a special
case of the Bayes image (Def. 3) if we view the augmentation A as the label and consider the log-loss
where the conditional distribution is the Bayes optimal predictor due to its strict properness (Gneiting
& Raftery, 2007).
Assumption 7 (Finite augmentation entropy). We consider the augmenter pA | X such that the entropy
of the augmentation A is finite, i.e., H[A] < ∞.
Assumption 8 (Cardinalities). We assume that
|Z| ≥ |P*(A | X)|	(104)
This is a similar assumption as Assumption 3, which ensures the existence of optimal representations.
Assumption 9 (Domain-agnostic augmentation). We assume that the augmentation A is domain-
agnostic, i.e., the augmentation conditional set is invariant across domains,
Pd(A | X) = P*(A | X), ∀d ∈ D	(105)
This assumption is generalized from the constant Bayes image assumption (Assumption 5), which
guarantees the existence of optimal representations.
Domain-agnostic augmentations essentially ensures that each augmentation conditional pA | x ∈
P* (A | X) is seen at least once in all domains. If We introduce an equivalence relation 〜as X 〜χ0
iff PA । χ = PA । χ0 and the equivalence class [x] := {χ0 ∈ X | χ0 〜x}. Under this relation, it is
easy to see that the above assumption is satisfied if and only if, for all possible equivalence classes
[X] ∈ {[X0] | X0 ∈ X}, We have that [X] has intersections With all domains:
[x] ∩ SUpp(PX | d) = 0, ∀d ∈ D	(106)
Not all augmentations are domain-agnostic. In particular, the standard image augmentations used by
typical SSL models like SimCLR are not domain-agnostic, but the text-image augmentations of CLIP
nearly are, as discussed in the main body (Sec. 4).
Assumption 10 (Bayes-preserving augmentation). We assume that the augmentation A is Bayes-
preserving, i.e., ∀X, X0 ∈ X,
PA | x = PA | x0 =⇒ f* (X) = f*(X0).	(107)
Under the notion of equivalence relation in Assumption 9, this means that for each equivalence class
[X], all X0 ∈ [X] have the same Bayes prediction. Note that most augmentations used in practice like
standard image augmentations are Bayes-preserving.
Next, We shoW that under the above assumptions, We can learn optimal representations by maximizing
the mutual information I[A; Z] (in the case of log-loss `) under the support match constraint. We use
log-loss simply because it is typically the loss used for training in practice. Note that the learned
representations are optimal for any strict proper losses.
25
Published as a conference paper at ICLR 2022
Proposition 6 (Learning optimal representations without labels, equiv. Proposition 2). Let pA | X be
an augmenter. Under Assumptions 1 to 10, any encoder pZ | X such that
pZ | X ∈ arg max I[A; Z]	(108)
pZ | X
s.t. ∀d ∈ D, supp(pZ|d) = supp(pZ)	(109)
is optimal for idealized domain generalization.
Proof. The support match constraint Eq. (109) is equivalent to the support match constraint Eq. (68).
Thus, Prop. 3 and Thm. 2 state that we only need to prove that maximizing the mutual information of
A and Z under the support constraint implies that
R[Y |Z] = R[Y |X] .	(110)
We will prove this by constructing an optimal predictor h*.
Since H[A] < ∞ (Assumption 7) we have that
arg pmZaXx I[A; Z] = arg pmZ inX H[A | Z] .	(111)
Note the fact that the conditional entropy is the Bayes risk under the log-loss (Gneiting & Raftery,
2007), i.e., H[A | Z] = R [A | Z]. By construction, A satisfies covariate shift w.r.t. X (thus Bayes
invariant) since A - X - D forms a Markov chain. Together with Assumptions 1 and 7 to 9, it means
that the optimization problem in Eqs. (108) and (109) satisfies the assumptions of Prop. 3, with A in
place of Y . Thus, an optimal encoder satisfies R [A | Z] = R [A | X], which leads to
H[A|Z] = H[A|X].	(112)
By Assumption 7, we can invoke Lemma 2 with the fact that A - X - Z forms a Markove chain to
show that for all (x, z) ∈ supp(pX,Z)
pA | z = pA | x,	(113)
as the conditional distributions are the Bayes optimal predictors due to strict properness of log-loss.
Now, define the following equivalence relation on X ,
X 〜X0	^⇒ PA∣ X = PA∣ χ0.	(114)
Because the number of equivalence classes under 〜is countable, there exists a maximal invariant
M : X → N from X to the natural numbers (for our definition of a maximal invariant see Definition
2, Dubois et al., 2021). By Assumption 10, f * is invariant on the equivalence classes [x] ：= {χ0 ∈
X | χ0 〜χ} for all X ∈ X. Thus, there exists a function g : N → A such that f * = g ◦ M
(Lemma 5, Dubois et al., 2021). Given z ∈ supp(pZ), we construct h* in the following way. Let
Xz ∈ supp(pX | z) be any input point that could have led to this representation z and define
h*(z) = g(M(Xz)).	(115)
By Eq. (113) we are guaranteed that all X ∈ supp(pX | z) share the same value for f* since they are
in the same equivalence class. Thus, by the definition of M we have that
M(XZ) = M(X) for (X,Z)〜Px,z ∙	(116)
Therefore,
Rh* [Y | Z] = Epγ,z ['(Y,h*(Z)]	(117)
=Epγ∣χ pχ,z ['(Y,h*(Z)]	(118)
=Epγ∣χpχ,z ['(Y,g(M(XZ)))]	Eq. (115)	(119)
=Epγ∣xpx,z ['(Y,g(M(X)))]	Eq. (116)	(120)
=EpY | X px,z ['(Y,f * (X))] = R[Y IX ].	(121)
□
26
Published as a conference paper at ICLR 2022
C	Practical objectives
Proposition 6 provides an objective to obtain the desired optimal representations, compared to
Thm. 2 it is more practical in that it does not require direct access to the labels and in that it can use
augmentations under appropriate assumptions. There are nevertheless multiple remaining issues for
deriving objectives that can be trained with in practice. Specifically, (i) the support constraint is hard
to satisfy in practice; (ii) mutual information I[A; Z] is hard to estimate from samples (Poole et al.,
2019); (iii) the objective is constrained which is harder to optimize. We will now show different
objectives and variational bounds of them that do not suffer from these issues, and could still recover
the desired encoders in their optima. In contrast to the proofs of main theoretical results (previous
section), here the derivations will be less formal.
As we have seen in Proposition 6, the optimal representation achieves I[A; Z] = I[A; X]. In the
following, we will rewrite the objective as the constrained optimization:
pZ | X ∈ arg min B[Z, X, Y, D]
pZ | X
(122)
s.t.	I[A; Z] = I[A; X]
(123)
where we introduce the domain bottleneck B[Z, X, Y, D] as the objective for enforcing support
match (which we denote as B[Z, D] in the main body for simplicity). The requirement on the domain
bottleneck objective is that minimizing Eq. (122) under Eq. (123) implies that the support match
constraint holds (and can be achieved by some encoder), which leads to optimal representations for
IDG. Different domain bottlenecks will be derived later this section. We can then use Lagrangian
relaxation to get the following unconstrained objectives.
arg min -I[A;Z] +λB[Z,X,Y,D]
pZ | X
(124)
The first term can be easily optimized using variational bounds on MI. Throughout the paper, we will
use a contrastive variational lower bound which is based on InfoNCE (Oord et al., 2018). Namely, let
X be the input sample and A be the ‘positive’ augmentation sampled from pA | X. We then obtain n
‘negative’ augmentations Ai- in=1 by first independently sampling Xi- in=1 from the marginal pX
and then sampling Ai- from pA | Xi- . It is easy to see that the negatives Ai- follow the marginal pA .
We construct A := A, A1-, . . . , An- . Let Z be the representation of X by passing it through the
encoder Ip中:=PZ ∣ X parameterized by 夕 and sψ the critic function parametrized by ψ used to score
which A0 ∈ A is the positive augmentation. Then we have the following variational lower bound
(Poole et al., 2019):
I[A;Z] ≥ log(n + 1) + EpA,X,Z
l	exp Sψ (A, Z) 一
.og ∑A0∈A exp sψ(A0,Z) _
(125)
In the case of unconstrained variational families sψ,pφ and infinite samples (n → ∞), the above
variational bound recovers I[A; Z] up to a constant (see Oord et al. (2018); Dubois et al. (2021)).
Typically the critic is separable, i.e., sψ(A, Z) := gψ(A)Thψ(Z). As discussed in the main body, it
can be tied with the encoder Pf when A = X.
In the following we focus on the second term B[Z, X, Y, D] and discuss several choices.
Throughout this section, the function M : X → N is the maximal invariant defined in Prop. 6 via the
equivalence relation defined in Eq. (114).
C.1 MUTUAL INFORMATION BOTTLENECK B[Z, X, Y, D] = I[Z; X]
The first bottleneck we consider is so called mutual information (MI) bottleneck B[Z, X, Y, D] =
I[Z; X], which was introduced by Tishby et al. (2000) to achieve a tradeoff between the predictive
power and the complexity of representations. Intuitively, it tries to remove all information of Z that
is not needed for maximizing I[Z; A]. In particular, using the fact that Z - X - D forms a Markov
chain and the chain rule of MI, we have I[Z; X] = I[Z; X, D] = I[Z; D] + I[Z; X | D]. Thus, it
not only minimizes I[Z; D], i.e., matches the representations’ distribution across domains, but also
minimizes I[Z; X | D], i.e., matches the representations’ distribution inside domains.
27
Published as a conference paper at ICLR 2022
Why The key to show is that minimizing Eq. (122), i.e., arg minpZ | X I[Z; X] under I[A; Z] =
I[A; X], implies the support match constraint. This can be seen as a specific subcase of Dubois
et al.’s (2021) Corollary 15 with A in place of Y and M(X) induced by pA | X as in the proof of
Prop. 6. From the corollary, we know that minpZ | X I[Z; X] = H[M (X)] which can be achieved
by any Z s.t. PZ ∣ X = PZ ∣ χo ^⇒ M(x) = M(x0). With the assumption of domain-agnostic
augmentations (Assumption 9), we have that the set of maximal invariant {M (x) | x ∈ supp(pX | d)}
is invariant across domains. Then we directly have supp(PZ | d) = ∪x∈supp(pX | d)supp(PZ | x) =
∪x∈supp(pX)supp(PZ | x) = supp(PZ), where we use the fact that x within the same equivalence
class has the the same PZ | x.
How Essentially, we can use any variational upper bound of mutual information. We consider the
one used by Variational Information Bottelenck (Alemi et al., 2016), i.e.,
I[Z; X] = EpX,Z	Γ1 PP(Z IX)[ I^Zr		(126)
=	EpX,Z	1 PP(Z IX) ^Zr	- DKL[PZ(Z)kqe(Z)]	(127)
≤ EpX,Z	[log Pp≡)] qe(Z)		(128)
=EpX[DKL[PP(Z|X)kqe(Z)]]			(129)
where a variational distribution qe is used to approximate PZ and is jointly optimized with P中 to
minimize the bound. The approximation gap of the bound is DKL[PZ(Z)kqθ(Z)]. Ignoring the
constant, the final loss becomes
LMI(ψ, “、:= EpXAZ [- log P expEA彳 力 + λDKLM(Z | X)kqθ(Z)]]	(130)
A0∈A exp sψ(A , Z)
which recovers the optimal encoder in the case of unconstrained variational families for pφ, qe, sψ,
infinite samples n → ∞, and any λ > 1 (Dubois et al., 2021).
C.2 ENTROPY BOTTLENECK B[Z, X, Y, D] = H[Z]
The entropy (Ent) bottleneck introduced in the main body is a special case of the MI bottleneck,
where the encoder is a deterministic mapping, i.e., PP(Z | x) is a dirac delta function for all X ∈ X
and We denote by e^(x) the deterministic encoder s.t. Pφ(eφ(x) | x) = 1.
Why In the deterministic case, the MI bottleneck becomes the entropy bottleneck because I[X; Z] =
H[Z] - H[Z | X] = H[Z], where we use the fact that H[Z | X] = 0. Importantly, considering only
deterministic encoders does not constrain our ability to learning optimal encoders. Indeed, just as
with the MI bottleneck optimizing the objective with the entropy bottleneck under I[A; Z] = I[A; X]
will recover encoders s.t. e^(x) = e∕x0) ^⇒ M(x) = M(x0), which also satisfies the support
match constraint as discussed before.
How Using the same derivation as the MI bottleneck, we can derive the variational upper bound on
entropy
H[Z] ≤ EpZ[-logqe(Z)]	(131)
which is the standard variational bound used in neural compression (Bane et al., 2016; Theis et al.,
2017). Putting all together, we have
Ln∖(ψ,9,s := Epx,a,z [- log P expS(A，ZA0 Z1 - λ log qθ(Z)]	(132)
A0 ∈A exp sψ(A , Z)
which also recovers the optimal encoder with unconstrained variational families, infinite samples, and
λ > 1 as with the MI bottleneck. The detialed algorithm is provided in Algorithm 2. Note that the
discreteness of Z could lead to difficulty of gradient-based optimization, and we follow Balle et al.
(2016) to add uniform noise to Z as a differentiable substitute for rounding during training. In our
experiments, we will mostly use the Ent bottleneck instead of the MI bottleneck to avoid introducing
stochastic encoders.
28
Published as a conference paper at ICLR 2022
Algorithm 2 Ent objective
Require: £钓£砂,9@,X,n
1:	Z J eJX)
2:	A J SamPle(PA ∣ X)
3:	{(Xi-,Ai-)}in=1 Ji.-i.d-. sample(pX,A)
4:	AJ{A}∪{Ai-}in=1
5:	Laug J - log P exp sψ(AZo 八.—I[A; Z]
aug	A0∈A expsψ(A0,Z)
6:	LsuPP J - log qθ (Z)	. H[Z]
7:	return LEnt = Laug + λLsuPP
C.3 CONTRASTIVE ADVERSARIAL DOMAIN BOTTLENECK B[Z, X, Y, D] = I[Z; D]
The Previous two bottlenecks require removing the information of Z (about X) as much as Possible,
which seems to be unnecessary since our ultimate goal is to match the suPPort of Z across domains.
Now we introduce a bottleneck B[Z, X, Y, D] = I[Z; D] which we only seek to remove the informa-
tion of Z about the domain D. This is very related to the work on invariant rePresentation learning
for domain generalization/adaPtation (e.g., Ganin et al., 2016; Li et al., 2018a). We derive a new
variational bound called the contrastive adversarial domain (CAD) bottleneck that is more stable to
train and leads to better emPirical Performance. For simPlicity we consider the deterministic encoder
e^(x) as with the main body.
Why Similar to the Previous analysis, we aim to show that arg minpZ | X I[Z; D] under I[A; Z] =
I[A; X] leads to the suPPort match constraint. Using Eq. (116) we have I[Z; D] = I[Z, M(XZ); D] =
I[Z, M(X); D] = I[M (X); D] + I[Z; D | M(X)] where the last equality uses the chain rule of
mutual information. Due to the non-negativity of (conditional) mutual information, we have that
the minimum of I[Z; D] under I[A; Z] = I[A; X] is I[M (X); D]. Then we show the minimum is
achievable by constructing the same optimal encoder e^(X) as the Ent bottleneck which clearly
satisfies I[Z; D | M(X)] = 0. It is then easy to show that the suPPort match constraint has to hold
when I[Z; D | M(X)] = 0 by contrapositive. Indeed, suppose that the support constraint does not
hold then it must be true that I[Z; D | M(X)] > 0 and so the encoder cannot be optimal.
How The typical way of minimizing I[Z; D] is to derive the variational bound as
I[Z;D] = H[D] - H[D | Z]	(133)
= (const) - EpD,Z -logpD|Z(D | Z)	(134)
≥ (const) - EpD,Z [- log qφ(D | Z)]	(135)
where a variational distribution (or domain classifier) qφ is used to approximate pD |Zand jointly
trained to maximize the bound. This recovers the domain-adversarial training method as introduced
in Ganin et al. (2016). However, this has two potential issues: 1) it gives a lower bound instead of
the desired upper bound on I[Z; D]; 2) it requires adversarial training which is not stable in practice
(Goodfellow, 2016; Kodali et al., 2017).
We propose the contrastive adversarial domain (CAD) bottleneck, which is based on the above explicit
version but uses a variational distribution qφ(D | Z) that is tied with other parts of the model, thus no
need to learn a domain classifier. Suppose we have access to a set of inputs X, we first introduce a
contrastive variational distribution qφ,χ(X | Z) of PX ∣ Z as
q+,X(X | Z):
exp sφ(X, Z)
Pχo∈x exp I(X0, Z)
(136)
where s^(X, Z) := e干(X)tZ is tied with the encoder e^. Note that qφ,χ has support over X, and
equals PX ∣ Z when S中(X, Z) a log PXZ (X, Z) and X recovers X. In practice, we use a variety of
crude approximations. Our first crude approximation is that we use the minibatch of samples, i.e., the
independently sampled Xi- in=1 as X. Now, since PD |Zcan be rewritten as EpX | Z PD | X using
the fact that D - X - Z forms a Markov chain, we obtain the following variational distribution:
qψ,χ(D I Z) = Eq,,x[PD∣X(D I X)]	(137)
29
Published as a conference paper at ICLR 2022
which recovers PD ∣ Z when q^,x = PX ∣ Z. Note that PD ∣ X is still not available. For our second
crude approximation, We use a count estimate Pd,x. In particular, We obtain a collection D by taking
each X0 ∈ X and independently sampling D0 from PD | X0 to get D := {Di-}in=1. In other words,
{(Di-, Xi-)}in=1 are all i.i.d. sampled from PD,X. Then we use a count estimate
pD,x(d | x)
Pi=1 I (Xi = x,Di = d)
-Pn=1 I (X- = X)-
(138)
which is an accurate estimate with infinite samples. This leads to our final variational distribution:
9ax,d(D | Z) = E qψ,χ(X01 Z)Pd,x(D | X0)	(139)
X0∈X
Putting all together we get that the loss:
LCAD (ψ, ψ) := EPD,X,A,Z
-logP expEA, ZA Z) + λ log( X q，，x(x 01 z )Pd,x(d IX 力]
A0∈A exp sψ(A , Z)	X0∈x
(140)
In practice, Pd,x(D ∣ X) is typically a dirac delta function since it is rare to have the same samples
in a minibatch. Thus, in Eq. (139) we only need to sum qφ,x(X01 Z) over those associated with
the same domain label D as X, i.e., XD := {Xi- | Di- = D, i ∈ [n]} where [n] := {1, . . . , n}. This
leads to the simplified loss:
LCAD(2,ψ) := EPD,X,A,Z
exp Sψ (A,Z)
θg PA0∈A exP sΨ(A0,Z)
+ λlog( X q+,X(X0 | Z))
X0∈xD
(141)
In practice, we find that the second term that minimizes the log probability leads to numerical
instability. Intuitively, this could be seen by the exploding gradient of the function log(P) when
P → 0. We thus replace it with - log(1 - P) which has the same optima. I.e. in practice we
maximize the log of the probablity summed over XD := X \ XD. This reduces Eq. (141) to Eq. (7)
described in the main body with a detailed algorithm in Algorithm 1. Note that it is easy to generalize
Algorithm 1 to parallel computation within a batch of samples. Indeed, for each sample in the batch,
we can view all other samples in the batch as negatives and compute the loss efficiently in parallel.
C.4 CONDITIONAL CAD B[Z, X, Y, D] = I[Z;D |Y]
The analysis of the CAD bottleneck also implies that we can minimize the conditional mutual
information I[Z; D | M (X)] if we have access to M(X). However, since M(X) is typically not
available in practice, we consider the special case where M(X) = Y . In particular, this is the case
where the labels are available and the supervised augmentations are used (see Fig. 2b). This reduces
the bottleneck to B[Z, X, Y, D] = I[Z; D | Y ] which is related to the conditional version of the
domain-adversarial neural network (Li et al., 2018b). In practice, minimizing I[Z; D | Y] could be
easier for optimization than I[Z; D], as it does not require to remove the information that D has about
Y . In the following, we derive the conditional CAD (C2AD) bottleneck using a similar idea as CAD.
How In this case, we want to minimize
I[Z;D|Y] = H[D|Y] -H[D|Z,Y]	(142)
= (conSt) -H[D |Z,Y]	(143)
≥ (conSt) -EpD,Z,Y[-logq(D|Z,Y)]	(144)
where q(D | Z, Y ) is a variational distribution of PD | Z,Y . Similar to the unconditional case, we
also aim to use a non-parametric approximation that is tied with other parts of the model, and we
obtain it using the fact PD | Z,Y = EpX |Z,Y PD | X . Specifically, let Y be the label of input X
sampled from PY | X and Y := {Y1-, . . . , Yn-} be the collection of labels obtained by independently
sampling the label from PY | X 0 for each X0 ∈ X. We collect samples associated with the label Y ,
i.e., XY := {Xi- | Yi- = Y, i ∈ [n]} and obtain a variational distribution ofPX | Z,Y :
qF,X,Y (X | z,y) :
exp s<X, Z)
Pχ0∈Xγ exp Sv(X0，Z)
(145)
30
Published as a conference paper at ICLR 2022
where We use the same critic S中(X, Z) := e^ (X)TZ that is tied with the encoder e^ as before, but
only take softmax over those samples with the same label Y . For the term pD | X , we use the same
count estimatep^d,x in Eq. (138). Then we obtain the variational distribution of PD ∣ z,γ:
qψ,χD,γ(D | Z,Y)= E q，,x,Y(X01 Z,Y)Pd,x(D | X0)	(146)
X0 ∈XY
Putting all together we get that the final loss:
LC2AD(^, ψ) := EPD,X,A,Y,Z
exp Sψ (A, Z)
θg PA0∈A exP sΨ (A0,Z)
+ λ log
X0∈XY
qψ,χ,γ(X0I Z,Y)Pd,x(D | X0)
(147)
Again, since in practice PDX(D ∣ X) is typically a dirac delta function, the summation in Eq. (146)
can be done only over those associated with the same label Y and the same domain label D as X ,
i.e., XY,D := {Xi- | Yi- = Y, Di- = D, i ∈ [n]}. Similarly, instead of minimizing the log of the
probability summed over Xy,d , we maximize the log of the probability summed over Xy,-d :=
XY \ XY,D = {Xi- | Yi- = Y, Di- 6= D, i ∈ [n]}. Finally we obtaine the simplified loss:
))
LCB3,ψy∙= epd,x,a,y,z Tog P exp"A,ZAO Z) - λlog X	q.,χ,γ(X01 z,y)
2-A0∈Aexp sψ (A，Z)	∖X 0∈Xy-d	)
(148)
A detailed algorithm is in Algorithm 3.
Algorithm 3 conditional CAD (C2AD) objective
Require: eφ,Sψ,D,X,Y,n
1:	Z — e4X)
2:	A — SamPle(PA | X)
3:	{ (D-,x-,A-,γ-)}n=1 心 SamPle(PD,χ,A,γ)
4:χ, A -{χ-}n=ι,{A}∪{A-}n=ι
5:	XY J {X- I Yi- = Y,i ∈ [n]}
6:	Xy,-d - {X- I Yi- = Y, D- = D,i ∈ [n]}
7:	LauB — — log P exp S(A,Z)0 7∖	. - I[A; Z]
aug	A0∈A exp sψ(A0 ,Z)
o, C	1 PXyXY-D exp ev(XO产Z τ“ niv】
8:	LSupp J log pχθ0∈χγ exp e^(X00)τZ . I[Z; D 1 Y]
9:	return LC2 AD = Laug + λLsupp
31
Published as a conference paper at ICLR 2022
D	Extended Related Work
Provably optimal representations. Many previous work have theoretically studied advantages of
representations in various two-stage settings (representation learning followed by standard training of
predictors) by bounding downstream performance (e.g., Ben-David et al., 2007; Shamir et al., 2010;
Saunshi et al., 2019). As learning theoretical bounds can be loose, it is hard to know whether they give
the right insights into the problem. Our work instead proves the properties of optimal representations,
which ensure best downstream performance. Those properties need to be approximated but give the
right insights into what to aim for. This perspective and our proofs were inspired by Dubois et al.
(2020) who gives sufficient conditions for optimal representations in supervised learning.
E Experimental Details
E.1	Scientific
In both the scientific setting and the following bridge setting, we consider rather unrealistic setups
for verifying our theory where we have access to labels from all domains. We can choose to directly
minimize the risk R [Y | Z] with the cross-entropy loss (denoted as CE henceafter), or minimize
H[A | Z] (i.e., maximize I[A; Z]) with supervised augmentations as in Fig. 2b detailed below.
Implementation of supervised augmentations When using supervised augmentations, for each
sample we obtain its augmentations from within its label class across all domains. A constrastive
loss with such augmentations will essentially reduce to the supervised contrast loss (SupCon, Khosla
et al., 2020). In particular, for a single sample in a batch, all samples in the batch with the same
labels can be used as the positives (could come from the same domain or different domains) and
others as the negatives. In Khosla et al. (2020), two variants of SupCon loss were introduced for
solving the issue of multi-positives depending on whether the summation over multi-positives was
located inside (SupCon-In, Eq. (3) in Khosla et al. (2020)) or outside (SupCon-Out, Eq. (2) in Khosla
et al. (2020)) the log. Though Khosla et al. (2020) chose SupCon-Out because it worked better
than SupCon-In, we hypothesized that this is because SupCon-Out has an implicit bottleneck effect.
Intuitively, SupCon-Out upper bounds SupCon-In and achieves its optima only if the logits with
positive samples are all the same by Jensen’s inequality, which may encourage positive samples from
different domains to get clustered. Since this might confound with the effect of our bottlenecks,
we chose to use SupCon-In though it performed slightly worse in out initial experiments. For the
implementation of SupCon, we followed Khosla et al. (2020) except that no projection was used.
Specifically, the temperature was set to 0.1, and normalization was applied when computing the
logits.
In the scientific setting, we tried to simulate our theory to the greatest extent. In particular, we had
two special considerations as detailed below:
Eliminating empirical generalization As our theory focuses on the idealized domain generaliza-
tion that assumes access to population distribution, we considered the setup where the empirical
generalization was eliminated. Specifically, we treated the dataset as the population distribution and
used the same dataset for training the encoder and training/evaluating the predictor. The ResNet-18
encoder was trained to 300 epochs without any regularization, using the Adam optimizer (Kingma &
Ba, 2014) with a learning rate of 5e-5, a batch size of 192 (48 for each domain), and a cosine learning
rate decay schedule.
Worst-case approximation To approximate the worst-case source predictor, we included the target
data with randomly assigned wrong labels to the training set for training the source predictor. The
target data samples were down-weighted with a sample weight that maximizes the target risk while
keeping the source risk close to optima (which is 0). We selected the sample weight by sweeping
over [10-10 , 1] with a logarithmic scale using CE-Base and SupCon-Base, as shown in Fig. 4. As
the sample weight increases, the target log likelihood (neg. risk) first decreases and then increases.
We hypothesized that the increasing trend was due to that the source performance was already not
optimal (though not visible from the figure), thus we selected the weight close to the turning point and
10-5 seemed to be reasonable for both CE-Base and SupCon-Base. Although we did not adaptively
select the sample weight for each setup due to the computational cost, the pre-specified sample turned
32
Published as a conference paper at ICLR 2022
0 2 4
POOqlΦ⅛I §
-5
0 12 3 4
- - - -
POOqlΦ⅛I §
sample weight
sample weight
(a) CE-Base
(b) SupCon-Base
Figure 4: Sweeping the sample weight using CE-Base and SupCon-Base. We selected 10-5 which
seemed to be reasonble for both cases.
out to be reasonable for all other losses and different λ combinations. Furthermore, we also removed
regularization when training the linear classifier and initialized the linear weight i.i.d. from N (0, 1).
Next, we provide other experimental details for reproducibility:
Implementation of standard augmentations We followed SimCLR (Chen et al., 2020) for imple-
menting standard image augmentations. For a fair comparison between the cases when using standard
augmentations (SimCLR) and supervised augmentations (SupCon), we kept the total batch size the
same and also used the same configurations for computing the SupCon loss, i.e., temperature set to
0.1, no projection, and normalization applied.
Details of Fig. 3c In Fig. 3c, we considered different choices of augmentations. The ‘Standard‘
augmentation implementation is described above (Appx. E.1). The ‘Supervised’ augmentation was
essentially implemented using the SupCon loss as described in Appx. E.1. For other augmentations
considered, we implemented them by dropout inter-domain supervised augmentations in SupCon.
Specifically, for each sample in the batch, we randomly masked the samples from different domains
(i.e., both inter-domain positives and negatives) i.i.d. with the specified dropout probability, while
samples within the same domain were always kept. ‘IntraDom’ and ‘ApproxDA’ correspond to
dropout probability 1 and 0.9, respectively. ‘SingleDom’ were implemented by dropout all inter-
domain samples with probability 1 except for a fixed domain (the ‘A’ domain of PACS in our
case).
E.2 Bridge
In the bridge setting (see Appx. F.2), we aimed to bridge the gap between our theoretical setup to the
practical setup. The main differences from the scientific setups are that the empirical generalization
gap is considered and the average-case source predictor is used, as detailed below:
Incorporating empirical generalization In practice, empirical-generalization gap should also be
considered besides the source-target generalization gap. Thus, we randomly split the PACS dataset
to 80% training and 20% validation splits for each domain. The training splits were used to train
both the encoder and the source predictor, and the validation splits were used for encoder and source
predictor selection as well as evaluation on target domains. We used the ResNet-50 model as the
encoder and initialized it from ImageNet pretrained model. The encoder was trained to a maximum of
50 epochs with a 1e-5 weight decay, using the Adam optimizer (Kingma & Ba, 2014) with a learning
rate of 5e-5, a batch size of 112 (28 for each domain), and a cosine learning rate decay schedule.
Using average-case source predictor Instead of approximating the worst-case source predictor in
the scientific setting, we considered the average-case3 source predictor which is closer to the common
practice. Specifically, we freezed the encoder and trained a SVM classifier with L2 regularization on
3Here we have a slight abuse use of the phrase ‘average-case’ to distinguish from the ‘worst-case’ that we
use in the scientific setting. In fact, the source predictor could be close to the ‘best-case’ since the max-margin
classifier (SVM) was used.
33
Published as a conference paper at ICLR 2022
the source training split. The regularization parameter was tuned over {1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1,
1e2, 1e3} with the source validation accuracy.
Next, we provide other experimental details for reproducibility:
Selection of λ For all different setups considered in bridge settings, the CAD bottleneck was used
and the λ was tuned over {1e-3, 1e-2, 1e-1, 1, 1e1} independently for each.
E.3 DomainBed
Datasets We used non-MNIST datasets on DomainBed that were non-synthetic, including VLCS
(Fang et al., 2013), PACS (Li et al., 2017), OfficeHome (Venkateswara et al., 2017), TerraIncognita
(Beery et al., 2018), and DomainNet (Peng et al., 2019). For each dataset, we split it to 80%/20%
training/validation set according to DomainBed.
SSL-based models & Training For all models based on pretrained SSL models (either CLIP-based
or DINO-based) with finetuning in this experiment, we freezed the pretrained SSL model and added
on top a 1-layer MLP with hidden size 1024, and residual connection. We used CLIP ResNet-50
(CLIP S) to obtain the best possible fair comparison with baselines from DomainBed, and CLIP
ViT-B/32 (CLIP L) to achieve the best results. Note that the ResNet-50 model of CLIP S was
modified as described in Radford et al. (2021) and contained 38M parameters (more than 23M of
the original CLIP). The model was trained to 300 epochs for DomainNet and 50 epochs on other
datasets (an epoch is defined as a single pass over the smallest domain according to DomainBed). No
data augmentation was used and the temperature for scaling the logits in CAD was fixed to 0.05. We
used the Adam optimizer with a 1e-5 weight dacay, and a cosine learning rate decay schedule. The
hyperparameter search space is:
•	Learning rate: discrete set {1e-4, 3e-4, 1e-3, 3e-3}
•	Batch size: discrete set {128, 256, 512} for DomainNet and OfficeHome, and {64, 128,
256} for other datasets
•	MLP dropout: discrete set {0., 0.1, 0.5}
•	Learning rate warmup: discrete set {True, False}
End-to-end models & Training In Table 1, we also included an end-to-end trained model without
any pretrained SSL models. We used exactly the same model architecture (the original ResNet-
50, initialized from ImageNet pretrained model), training procedure and evaluation protocal as
baselines on DomainBed. Importantly, the linear classifier was jointly trained with the encoder, and
no refitting was applied. The model was trained to a maximum of 5000 steps on each dataset, and
data augmentations were applied. The Adam optimizer was used without any particular learning
rate schedule. The hyperparameter search space is (same as DomainBed except we added the
temperature):
•	Learning rate: log-uniform over [1e-5, 1e-3.5]
•	Batch size: log-uniform over [8, 64] for DomainNet, and [8, 25.5] for other datasets
•	MLP dropout: discrete set {0., 0.1, 0.5}
•	Weight decay: log-uniform over [1e-6, 1e-2]
•	Temperature: discrete set {0.05, 0.1}
Linear Probe Evaluation In all the experiments except for the end-to-end training setup, we
always followed the procedure of two-stage training, where we first trained the encoder with specified
objectives, and then refit the classifier. For datasets except DomainNet, we fitted the SVM classifier
and tuned the regularization parameter over {1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3} with source
validation selection. Since DomainNet was too large and SVM cannot fit it efficiently, we used the
logistic regression classifier which was trained with a batch size 512, the Adam optimizer with a
learning rate 5e-4 and early stopping. Note that an alternative was to just use the linear head fitted
when training the representor (as we used CE loss with source labels), and we found this could work
better than refitting since the classifier was less overfitted to the source domain. However, we didn’t
do that since we wanted to stick to the representation learning protocol with two-stage training. We
34
Published as a conference paper at ICLR 2022
did that in our end-to-end training setup since we wanted it to be compeletely comparable to baselines
on DomainBed (which did not do refitting).
Selection of λ In our experiments, we treated λ as a special hyperparamter. For each model, we
used the same λ selected on PACS on all datasets except DomainNet, because our bottleneck is fairly
robust to the choice of λ. For the large-scale DomainNet dataset, we selected its λ individually. The
λ values chosen for each model were:
•	CLIP S: 1 on DomainNet and 1e-2 on other datasets
•	CLIP L: 1e-1 on DomainNet and 1e-2 on other datasets
•	DINO: 1e-1 on all datasets
•	End-to-end ResNet-50: 1e-5 on all datasets
E.4 LAION
Model We used the CLIP L model (i.e., CLIP ViT-B/32) with an additional network on top for
finetuning. The additional network were two blocks of 2-layer MLP, each with hidden size 2048,
pre-activation batch normalization, residual connection, and dropout probability 0.1. Note that the
original CLIP L model was frozen and only the additional network was trained.
Dataset We used the LAION-400M dataset which contained 400 million image-text pairs for
training. Though the dataset might not be as clean as the original CLIP training data (as evidenced by
our experimental results), it was the largest publicly available image-text-pair dataset that we could
get access to. As we froze the CLIP L model and only did finetuning, we used the 1TB preprocessed
embeddings provided by LAION-400M4. No further preprocessing was applied.
Training We used the image-text contrastive loss as introduced in Radford et al. (2021) for training
model. The temperature was learnable which was initialized as 0.07 and clipped with a minimum
0.01. The model was trained for 1 epoch using the Adam optimizer with a batch size of 16384 and a
cosine learning rate decay schedule. The learning rate was tuned over the set {3e-5, 1e-4, 3e-4, 1e-3,
3e-3, 1e-2} and the λ value for the Ent bottleneck was tuned over {1e-3, 1e-2, 1e-1, 1, 1e1}.
Evaluation For the evaluation on the ImageNet-related datasets, we followed a similar procedure in
Radford et al. (2021), where a linear classifier was fitted on ImageNet using the model representations
and evaluated on 7 natural distribution shift datasets. In particular, we fitted a logistic regression
classifier with 1e-5 L2 regularization on ImageNet training set which was trained with a batch size
512, the Adam optimizer with a learning rate 3e-4 and early stopping. Note that this was different
from Radford et al. (2021), where a logistic regression classifier was fitted using full-batch data
with decent hyperparameter tuning, due to our computational budget. For evaluation on natural
distribution shift datasets, we followed Taori et al. (2020) and used their released testbed5. The
evaluation datasets and their abbreviations used in Table 2 were: ImageNetV2 (IN-V2, Recht et al.,
2019), ImageNet-Sketch (IN-S, Wang et al., 2019), Youtube-BB (YT-BB, Shankar et al., 2019),
ImageNet-Vid (IN-Vid, Shankar et al., 2019), ObjectNet (Barbu et al., 2019), ImageNet Adversarial
(IN-A, Hendrycks et al., 2021), and ImageNet Rendition (IN-R Hendrycks et al., 2020).
4See https://laion.ai/laion-400-open-dataset/ for details.
5https://github.com/modestyachts/imagenet-testbed
35
Published as a conference paper at ICLR 2022
F Additional Experimental Results
F.1 Scientific
POOqlΦ⅛I §
(a) CE (R [Y | Z]) objectives
0 12 3 4
- - - -
PooqlIφM= §
■
n>尸
E .
O2
O4
(b) SupCon (H[A | Z]) objectives
B
e
2
-
O
λ
Figure 5: The worst-case DG performance of Ent bottleneck is more sensitive to λ than CAD
What’s the effect of λ for different objectives on the worst-case DG performance? In Fig. 5,
the worst-case target log likelihood versus λ values for different objectives is shown. We found that
Ent is much more sensitive to the choice of λ than CAD, which was part of the reason why we used
the latter in most of our experiments. Note that for SupCon-Ent with small λ values, it was worse
than SupCon-Base because of the discretization introduced by the Ent bottleneck, which we verified
by observing that setting λ = 0 lead to similar results.
F.2 Bridge
The scientific setup is closer to our theory than what we do in practice in that worst-case predictor
was considered and empirical generalization gap was ignored. Here we bridged these gaps with a
more practical setup. In particular, we split the PACS dataset to training and validation splits for each
domain and considered the setting: the representor trains the encoder on all-domain training splits
with a validation loss selection; the learner trains the SVM predictor (average-case) on the source
training split which is selected over the source validation split, and evaluates on the validation splits
of other target domains. The target validation accuracy averaged over all (source, target) setups was
reported. For simplicity, we will use CE to denote the objective with the cross-entropy loss that uses
labels to minimize R [Y | Z], and SupCon for the contrastive loss that uses supervised augmentations
to minimize H[A | Z]. We will use CAD in following experiments unless otherwise specified (chosen
with initial experiments). Details in Appx. E.2.
Table 3: We repeated most empirical analysis (in the scientific setting) in the more practical bridge
setting and observed similar results.
Setup	Avg. target acc.
CE-Base	95.9 ± 0.5
CE-CAD	96.7 ± 0.2
CE-CAD (partial domains)	82.6 ± 0.5
SUPCon-CAD	96.7 ± 0.4
SupCon-CAD (SingleDom)	96.7 ± 0.3
SUPCon-CAD (APProxDA)	96.6 ± 0.3
SUPCon-CAD (IntraDom)	96.2 ± 0.7
SimCLR-CAD	61.7 ± 0.8
36
Published as a conference paper at ICLR 2022
Does domain bottleneck improve the average-case DG performance? Though our theory fo-
cuses on the worst-case DG, we empirically showed that adding bottlenecks to enforce support match
can also improve the average-case DG performance by comparing CE-Base and CE-CAD in Table 3.
What if the representor only has access to source domains? Similar to what we did in the
scientific setting, we considered the setup where one single domain is specified as the target domain
and excluded from the training set of the representor and used for evaluation with source predictors
trained on other domains. This is denoted as CE+CAD (partial domains) in Table 3, which is much
worse then CE-CAD. This shows the necessity of getting access to target domain information for DG.
What if the representor only has access to domain-agnostic augmentations? In Table 3, we
also compared SupCon-CAD which used supervised augmentations through the labels with CE-
CAD and they achieved the same performance. This shows that the representor can still learn good
representations without labels but only domain-agnostic augmentations in practice.
Can we use standard augmentations? In Fig. 2, we point out that standard augmentations are not
domain-agnostic and thus not suitable for SSL with our objectives. We empirically showed this by
using augmentations of SimCLR (see Appx. E.1 for details) with our objectives (SimCLR-CAD). In
Table 3, we indeed observed that using standard augmentations performed much worse than using
desired augmentations (SupCon-CAD).
How do augmentations matter? Besides investigating the ‘Supervised’ augmentations (SupCon-
CAD) and ‘Standard’ augmentations (SimCLR-CAD) above, we also compared other three aug-
mentations as in the scientific section. Specifically, we considered the ‘SingleDom’, ‘IntraDom’,
and ‘ApproxDA’ augmentations. As shown in Table 3, SupCon-CAD (SingleDom) and (ApproxDA)
maintained the DG performance but SupCon-CAD (IntraDom) was slightly worse (0.5 accuracy
drop). We assumed the small gap was due to the specific dataset that we used (PACS). We did
the same analysis on VLCS, and SupCon-CAD with ‘Supervised’, ‘SingleDom’, and ‘IntraDom’
augmentations gave 84.7 ± 0.4, 83.2 ± 0.3, and 77.5 ± 2.3, respectively. This shows the importance
of using domain-agnostic augmentations in practice.
Do standard augmentations affect source performance? Previously, we showed that using stan-
dard augmentations hurt the DG performance measured by the average target accuracy. It is natural to
ask whether using standard augmentations also hurt the source performance since we should also be
interested in the ‘effective robustness’ (Taori et al., 2020). Thus we also reported the average source
accuracy of SupCon-CAD and SimCLR-CAD which were 96.9 ± 0.2 and 90.1 ± 0.2, respectively.
The source performance using standard augmentations was indeed worse, but if we consider the
source-target gap which was 0.2 for SupCon-CAD and 28.4 for SimCLR-CAD, which still verified
that the non-domain-agnostic standard augmentations were harder to force support match. To be
even more convincing, we did the same analysis on VLCS, and the average source accuracy of
SupCon-CAD and SimCLR-CAD were 86.6 ± 0.1 and 84.6 ± 0.5 which were fairly close, but the
average target accuracy were 84.7 ± 0.4 and 57.5 ± 1.7, respectively.
F.3 DomainBed
Full result of Table 1 We included the full result of Table 1 with all baselines on DomainBed as in
Table 4. We considered most representative baselines from DomainBed, most of which considered
learning invariant representations or optimal classifiers across domains. Specifically, we included
IRM (Arjovsky et al., 2019), GroupDRO (Sagawa et al., 2019), Mixup (Yan et al., 2020), CORAL
(Sun & Saenko, 2016), MMD (Li et al., 2018a), DANN (Ganin et al., 2016), CDANN (Li et al.,
2018b), and VREx (Krueger et al., 2021). We also included the result pretrained CLIP S model with
a zero-shot classifier using text representations (CLIP S Zero Shot), which demonstrated better DG
performance than CLIP S with linear probe. But we observed that it was outperformed by our CLIP
S + CAD.
What is the impact of CLIP pretraining? To ensure that our gains are not only due to a novel
CAD bottleneck, but the synergy between enforcing support constraint and using desired SSL models,
we investigated CAD using the standard DomainBed protocol denoted as CAD in the table. It
shows that CAD on its own performs similarly with DomainBed baselines (see Table 4 for a full
comparison).
37
Published as a conference paper at ICLR 2022
Table 4: Full results on DomainBed with ‘oracle selection’ method.
Algorithm	VLCS	PACS	OfficeHome	TerraIncognita	DomainNet
ERM	77.6 ± 0.3	86.7 ± 0.3	66.4 ± 0.5	53.0 ± 0.3	41.3 ± 0.1
IRM	76.9 ± 0.6	84.5 ± 1.1	63.0 ± 2.7	50.5 ± 0.7	28.0 ± 5.1
GroupDRO	77.4 ± 0.5	87.1 ± 0.1	66.2 ± 0.6	52.4 ± 0.1	33.4 ± 0.3
Mixup	78.1 ± 0.3	86.8 ± 0.3	68.0 ± 0.2	54.4 ± 0.3	39.6 ± 0.1
CORAL	77.7 ± 0.2	87.1 ± 0.5	68.4 ± 0.2	52.8 ± 0.2	41.8 ± 0.1
MMD	77.9 ± 0.1	87.2 ± 0.1	66.2 ± 0.3	52.0 ± 0.4	23.5 ± 9.4
DANN	79.7 ± 0.5	85.2 ± 0.2	65.3 ± 0.8	50.6 ± 0.4	38.3 ± 0.1
CDANN	79.9 ± 0.2	85.8 ± 0.8	65.3 ± 0.5	50.8 ± 0.6	38.5 ± 0.2
VREx	78.1 ± 0.2	87.2 ± 0.6	65.7 ± 0.3	51.4 ± 0.5	30.1 ± 3.7
CAD	78.0 ± 0.1	87.3 ± 0.2	67.0 ± 0.5	53.5 ± 0.9	41.5 ± 0.1
DINO + CAD	69.6 ± 0.6	76.1 ± 0.1	56.9 ± 0.5	25.9 ± 1.2	33.6 ± 0.1
CLIP S	81.1 ± 0.5	90.3 ± 0.2	70.6 ± 0.1	29.6 ± 0.8	47.7 ± 0.0
CLIP S (Zero-Shot)	80.9 ± 0.1	91.8 ± 0.1	70.4 ± 0.2	19.1 ±0.1	46.9 ± 0.0
CLIP S + Base	81.3 ± 0.5	91.2 ± 0.3	70.6 ± 0.1	36.4 ± 0.7	46.8 ± 0.2
CLIP S + CAD	82.3 ± 0.3	92.0 ± 0.2	71.9 ± 0.2	36.2 ± 0.8	48.8 ± 0.1
CLIP L	80.7 ± 0.4	93.7 ± 0.8	79.6 ± 0.1	36.9 ± 0.6	52.8 ± 0.1
CLIP L + CAD	81.6 ± 0.1	94.9 ± 0.3	80.0 ± 0.2	40.6 ± 1.1	53.7 ± 0.1
Why ‘oracle’ selection? In the main body, we provided the results with ‘oracle selection’ which
was the closest to our theory among the model selection methods in DomainBed (in the sense that
we needed target domain information to achieve IDG). Here, we also provided results with ‘source
validation’ selection in Table 5. Source validation selection relies on the assumption that source
and target data follow similar distributions (Gulrajani & Lopez-Paz, 2021) thus source and target
accuracy are highly correlated, which is not really true in practice. We found some issues with source
validation selection results:
•	The selected model with the highest source validation accuracy tends to overfit the source
domain, thus possibly leads to worse performance on the target domain. This can be probed
by the fact that the finetuned CLIP models (CLIP + Base or CLIP + CAD) were generally
worse than the original CLIP model;
•	Selecting model with source validation accuracy tends to diminish the effect of bottlenecks.
This can be seen by the fact that the gap between CLIP + Base and CLIP + CAD of source
validation selection is much smaller than that of oracle selection;
•	The source accuracy is not a good indicator of target accuracy thus its result has a larger
variance.
F.4 LAION
Evaluation results on DomainBed We included the evaluation results of trained models on Do-
mainBed in Table 6, where we followed exactly the same linear evaluation protocal discussed in
Appx. E.3. We observed similar results as Table 2: the CLIP L model trained with the Ent bottle-
neck on LAION (Tuned w/ Ent) outperformed the one without (Tuned w/o Ent) on all DomainBed
datasets, but slightly underperformed the original CLIP L model (which might be due to quality of
the LAION-400M dataset).
38
Published as a conference paper at ICLR 2022
Table 5: Results on DomainBed with ‘source validation’ selection. Source validation selected model
tends to overfit more to the source domain and diminish the effect of bottlenecks.
Algorithm	VLCS	PACS	OfficeHome	TerraIncognita	DomainNet
ERM	77.5 ± 0.4	85.5 ± 0.2	66.5 ± 0.3	46.1 ± 1.8	40.9 ± 0.1
IRM	78.5 ± 0.5	83.5 ± 0.8	64.3 ± 2.2	47.6 ± 0.8	33.9 ± 2.8
GroupDRO	76.7 ± 0.6	84.4 ± 0.8	66.0 ± 0.7	43.2 ± 1.1	33.3 ± 0.2
Mixup	77.4 ± 0.6	84.6 ± 0.6	68.1 ± 0.3	47.9 ± 0.8	39.2 ± 0.1
CORAL	78.8 ± 0.6	86.2 ± 0.3	68.7 ± 0.3	47.6 ± 1.0	41.5 ± 0.1
MMD	77.5 ± 0.9	84.6 ± 0.5	66.3 ± 0.1	42.2 ± 1.6	23.4 ± 9.5
DANN	78.6 ± 0.4	83.6 ± 0.4	65.9 ± 0.6	46.7 ± 0.5	38.3 ± 0.1
CDANN	77.5 ± 0.1	82.6 ± 0.9	65.8 ± 1.3	45.8 ± 1.6	38.3 ± 0.3
VREx	78.3 ± 0.2	84.9 ± 0.6	66.4 ± 0.6	46.4 ± 0.6	33.6 ± 2.9
CAD	78.0 ± 0.5	85.2 ± 0.9	67.4 ± 0.2	47.3 ± 2.2	41.0 ± 0.1
DINO + CAD	68.9 ± 0.9	75.4 ± 0.5	56.4 ± 0.7	23.6 ± 1.2	31.0 ± 2.3
CLIP S	81.1 ± 0.5	90.3 ± 0.2	70.6 ± 0.1	29.6 ± 0.8	47.7 ± 0.0
CLIP S (Zero-Shot)	80.9 ± 0.1	91.8 ± 0.1	70.4 ± 0.2	19.1 ± 0.1	46.9 ± 0.0
CLIP S + Base	81.4 ± 0.4	89.6 ± 0.7	70.4 ± 0.2	30.9 ± 2.2	44.6 ± 1.6
CLIP S + CAD	81.2 ± 0.6	90.0 ± 0.6	70.5 ± 0.3	30.3 ± 0.9	45.5 ± 2.1
CLIP L	80.6 ± 0.7	93.5 ± 0.8	79.4 ± 0.2	37.5 ± 0.7	50.1 ± 1.1
CLIP L + CAD	80.8 ± 0.7	93.5 ± 0.7	79.7 ± 0.2	37.4 ± 1.2	51.7 ± 1.4
Table 6: Finetuning CLIP L on LAION with an entropy bottleneck performs better on DomainBed
than finetuning without.
Algorithm	VLCS	PACS	OfficeHome	TerraIncognita	DomainNet
CLIPL	80.7 ± 0.4	93.7 ± 0.8	79.9 ± 0.1	36.9 ± 0.6	52.8 ± 0.1
Tuned w/o Ent	79.2 ± 0.7	93.4 ± 0.3	77.2 ± 0.5	36.1 ± 0.4	51.2 ± 0.1
Tuned w/ Ent	80.7 ± 0.4	94.3 ± 0.8	78.2 ± 0.2	36.8 ± 0.4	52.2 ± 0.1
39