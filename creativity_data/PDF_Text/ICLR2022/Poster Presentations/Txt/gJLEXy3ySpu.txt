Published as a conference paper at ICLR 2022
Almost Tight L0-norm Certified Robustness of
TOP-k PREDICTIONS AGAINST ADVERSARIAL PERTUR-
BATIONS
Jinyuan Jia
Duke University
jinyuan.jia@duke.edu
Binghui Wang
Illinois Institute of Technology
bwang70@iit.edu
Xiaoyu Cao
Duke University
xiaoyu.cao@duke.edu
Hongbin Liu
Duke University
hongbin.liu@duke.edu
Neil Zhenqiang Gong
Duke University
neil.gong@duke.edu
Ab stract
Top-k predictions are used in many real-world applications such as machine learn-
ing as a service, recommender systems, and Web searches. 'o-norm adversarial
perturbation characterizes an attack that arbitrarily modifies some features of an
input such that a classifier makes an incorrect prediction for the perturbed input.
'o-norm adversarial perturbation is easy to interpret and can be implemented in
the physical World. Therefore, certifying robustness of top-k predictions against
'o-norm adversarial perturbation is important. However, existing studies either
focused on certifying 'o-norm robustness of top-1 predictions or '2-norm robust-
ness of top-k predictions. In this work, we aim to bridge the gap. Our approach is
based on randomized smoothing, which builds a provably robust classifier from an
arbitrary classifier via randomizing an input. Our major theoretical contribution is
an almost tight 'o-norm certified robustness guarantee for top-k predictions. We
empirically evaluate our method on CIFAR10 and ImageNet. For instance, our
method can build a classifier that achieves a certified top-3 accuracy of 69.2% on
ImageNet when an attacker can arbitrarily perturb 5 pixels of a testing image.
1	Introduction
Adversarial example is a well-known severe security vulnerability of classifiers. Specifically, given a
classifier f and a testing input x, an attacker can carefully craft a human-imperceptible perturbation
δ such that f (x) 6= f (x + δ). The perturbation δ is called adversarial perturbation, while the input
x + δ is called an adversarial example. Many empirical defenses (Goodfellow et al., 2015; Na et al.,
2018; Metzen et al., 2017; Svoboda et al., 2019; Buckman et al., 2018; Ma et al., 2018; Guo et al.,
2018; Dhillon et al., 2018; Xie et al., 2018; Song et al., 2018) have been developed to defend against
adversarial examples in the past several years. However, these empirical defenses were often soon
broken by strong adaptive adversaries (Carlini & Wagner, 2017; Athalye et al., 2018; Uesato et al.,
2018; Athalye & Carlini, 2018). To end this cat-and-mouse game, many certified defenses (Scheibler
et al., 2015; Carlini et al., 2017; Ehlers, 2017; Katz et al., 2017; Cheng et al., 2017; Lomuscio &
Maganti, 2017; Fischetti & Jo, 2018; Bunel et al., 2018; Wong & Kolter, 2018; Wong et al., 2018;
Raghunathan et al., 2018a;b; Dvijotham et al., 2018a;b; Gehr et al., 2018; Mirman et al., 2018; Singh
et al., 2018; Weng et al., 2018; Zhang et al., 2018; Gowal et al., 2018; Wang et al., 2018; Lecuyer
et al., 2019; Li et al., 2019; Cohen et al., 2019; Lee et al., 2019; Salman et al., 2019; Wang et al.,
2020; Jia et al., 2020; Zhai et al., 2020) have been proposed. In particular, a classifier f is said to be
certifiably robust for an input x if it provably predicts the same top-1 label (i.e.,f (x) = f(x + δ))
when the adversarial perturbation δ is bounded, e.g., the `p-norm of δ is smaller than a threshold. The
threshold is also called certified radius. In this work, we focus on 'o-norm adversarial perturbation,
which arbitrarily manipulates some features of a testing input and can be implemented in the physical
world.
1
Published as a conference paper at ICLR 2022
However, most existing certified defenses focus on top-1 predictions. In many applications, top-k
predictions that return the k most likely labels are more relevant. For instance, when a classifier
is deployed as a cloud service (also called machine learning as a service) (Google Cloud Vision;
Microsoft; Amazon AWS; Clarifai), top-k labels for a testing input are often returned to a customer
for more informed decisions; in recommender systems and web searches, top-k items/webpages are
recommended to a user. Despite the importance and relevance of top-k predictions, their certified
robustness against adversarial perturbations is largely unexplored. One exception is the recent work
from Jia et al. (2020), which derived a tight `2 -norm certified robustness for top-k predictions. Such
'2-norm certified robustness can be transformed to 'o-norm certified robustness via employing the
inequality between 'o-norm and '2-norm. However, the 'o-norm certified robustness derived from
such transformations is suboptimal.
Our work: We aim to develop '0-norm certified robustness of top-k predictions. Our approach
is based on randomized smoothing (Cao & Gong, 2017; Liu et al., 2018; Lecuyer et al., 2019; Li
et al., 2019; Cohen et al., 2019; Lee et al., 2019; Jia et al., 2020; Levine & Feizi, 2019), which can
build a certifiably robust classifier from any base classifier via randomizing the input. We adopt
randomized smoothing because it is applicable to any classifier and scalable to large neural networks.
In particular, we use a randomized smoothing method called randomized ablation (Levine & Feizi,
2019), which achieves state-of-the-art '0-norm certified robustness for top-1 predictions. Unlike other
randomized smoothing methods (Cao & Gong, 2017; Lecuyer et al., 2019; Li et al., 2019; Cohen
et al., 2019) that randomize an input via adding additive noise (e.g., Gaussian, Laplacian, or discrete
noise) to it, randomized ablation randomizes an input via subsampling its features. Specifically, given
an arbitrary classifier (called base classifier) and a testing input x, randomized ablation creates an
ablated input via retaining some randomly selected features in x and setting the remaining features
to a special value, e.g., median of the feature value, mean of the feature value, or a special symbol.
When the testing input is an image, the features are the image’s pixels. Then, we feed the ablated
input to the base classifier. Since the ablated input is random, the output of the base classifier is also
random. Specifically, we denote by pj the probability that the base classifier outputs a label j for the
random ablated input. The original randomized ablation method builds a smoothed classifier that
outputs the label with the largest label probability pj for a testing input x. In our work, the smoothed
classifier returns the k labels with the largest label probabilities for x.
Our major theoretical contribution is an almost tight '0-norm certified robustness guarantee of top-k
predictions for the smoothed classifier constructed by randomized ablation. Specifically, we first
derive an '0-norm certified robustness guarantee of top-k predictions for the smoothed classifier. Our
results show that a label l is provably among the top-k labels predicted by the smoothed classifier for a
testing input x when the attacker arbitrarily perturbs at most rl features of x, where rl is the '0-norm
certified radius. Moreover, we prove that our certified radius is tight when k = 1 and is almost tight
when k > 1. In particular, if no assumptions on the base classifier are made, it is impossible to derive
a certified radius that is larger than rl + I(k 6= 1). In other words, when an attacker manipulates
at least rl + 1 + I(k 6= 1) features of a testing input, there exists a base classifier from which the
smoothed classifier’s top-k predicted labels do not include l or there exist ties.
Our work has several technical differences with Levine & Feizi (2019). First, we derive the '0-norm
certified radius of top-k predictions for randomized ablation, while Levine & Feizi (2019) only
derived the certified radius of top-1 predictions. Second, our certified radius is the same as or
larger than that in Levine & Feizi (2019) for top-1 predictions, because we leverage the discrete
property of the label probabilities to derive our certified radius. Third, we prove the (almost) tightness
of the certified radius, while Levine & Feizi (2019) didn’t. Our work also has several technical
differences with Jia et al. (2020), which derived a tight '2-norm certified radius of top-k predictions
for randomized smoothing with Gaussian additive noise. Since they add additive Gaussian noise to a
testing input, the space of randomized inputs is continuous. However, our space of ablated inputs is
discrete, as we randomize a testing input via subsampling its features. As a result, Jia et al. and our
work use substantially different techniques to derive the '2/'0-norm certified radiuses and prove their
(almost) tightness. In particular, when deriving the '2/'0-norm certified radiuses, our work needs
to construct different regions in the discrete space of ablated inputs such that the Neyman-Pearson
Lemma (Neyman & Pearson, 1933) can be applied. When proving the (almost) tightness, we use
a completely different approach from Jia et al.. First, Jia et al. relies on the Intermediate Value
Theorem, which is not applicable to our discrete data. Second, since Gaussian noise is not uniform,
Jia et al. need to prove the results via Mathematical Induction. However, Mathematical Induction is
2
Published as a conference paper at ICLR 2022
unnecessary in our case because the ablated inputs that can be derived from an input are uniformly
distributed in the space of ablated inputs.
We evaluate our method on CIFAR10 and ImageNet. Our results show that our method substantially
outperforms state-of-the-art for top-k predictions. For instance, our method achieves a certified top-3
accuracy of 69.2% on ImageNet when an attacker arbitrarily perturbs 5 pixels of a testing image.
Under the same setting, Jia et al. (2020) achieves a certified top-3 accuracy of only 9.0%, when
transforming their '2-norm certified robustness to 'o-norm certified robustness.
Our contributions can be summarized as follows:
•	We derive an `0 -norm certified radius of top-k predictions for randomized ablation.
•	We prove that our certified radius is tight when k = 1 and almost tight when k > 1.
•	We empirically evaluate our method on CIFAR10 and ImageNet.
2	Theoretical Results
In this section, we show our core theoretical contributions.
2.1	Building a smoothed classifier via randomized ablation
Suppose we have a base classifier f, which classifies a testing input X to one of C classes {1,2,…，c}
deterministically. For simplicity, we assume x is an image with d pixels. Given an input x, randomized
ablation (Levine & Feizi, 2019) creates an ablated input as follows: we first randomly subsample e
pixels from X without replacement and keep their values. Then, we set the remaining pixel values
in the ablated input to a special value, e.g., median of the pixel value, mean of the pixel value, or a
special symbol. When the image is a color image, we set the values of the three channels of each
pixel separately. Note that an ablated input has the same size with X. We use h(X, e) to denote the
randomly ablated input for simplicity. Given h(X, e) as input, the output of the base classifier f is also
random. We use pj to denote the probability that the base classifier f predicts class j when taking
h(x, e) as input, i.e., Pj = Pr(f (h(x, e)) = j). Note that Pj is an integer multiple of (d), which we
will leverage to derive a tighter certified robustness guarantee. We build a smoothed classifier g that
outputs the k labels with the largest label probabilities Pj’s for X. Moreover, we denote by gk(X) the
set of k labels predicted for X.
2.2	Deriving the certified radius for the smoothed classifier
Defining two random variables: Suppose an attacker adds a perturbation δ to an input X, where
kδ k0 is the number of pixels perturbed by the attacker. We define the following two random variables:
U = h(X, e), V = h(X + δ, e),	(1)
where the random variables U and V denote the ablated inputs derived from X and its perturbed
version X + δ, respectively. We use S to denote the joint space of U and V , i.e., S is the set of ablated
inputs that can be derived from X or X + δ. Given the definition of U and V , Pr(f (U) = j) and
Pr(f (V ) = j) respectively represent the label probabilities of the input X and its perturbed version
X + δ predicted by the smoothed classifier.
Derivation goal: Intuitively, an ablated input h(X, e) is very likely to not include any perturbed pixel
if kδ k0 is bounded and e is relatively small, and thus the predicted labels of the smoothed classifier
are not influenced by the perturbation. Formally, our goal is to show that a label l ∈ {1,2,…，c}
is provably in the top-k labels predicted by the smoothed classifier for an input X when the number
of perturbed pixels is no larger than a threshold. In other words, we aim to show that l ∈ gk(X + δ)
when kδk0 ≤ rl, where rl is the certified radius. Our key idea to derive the certified radius is to
guarantee that, when taking V as input, the label probability for label l is larger than the smallest one
among the label probabilities of any k labels from all labels except l. We let Γ = {1, 2, ∙∙∙ ,c}\ {l},
i.e., Γ denotes the set of all labels except l. We use Γk to denote a set of k labels in Γ. Then, we aim
to find a maximum certified radius rl such that:
Pr(f (V ) = l) > max min Pr(f (V ) = j).	(2)
Γk ⊂Γ j∈Γk
3
Published as a conference paper at ICLR 2022
Roughly speaking, the above equation means that: to ensure l exists in the set of top-k labels,
Pr(f (V ) = l) should be larger than the minimum probability observed by taking any set of k labels
Γk excluding l. To reach the goal, we derive a lower bound of Pr(f (V ) = l) and an upper bound of
maxΓk⊂Γ minj∈Γk Pr(f (V ) = j). In particular, we derive a lower bound and an upper bound using
the probabilities that V is in certain regions of the discrete space S, and such probabilities can be
efficiently computed for ∀ kδk0 = r. Then, we can leverage binary search to find the maximum r
such that the lower bound is larger than the upper bound and treat the maximum r as the certified
radius rl . Next, we respectively introduce how to derive lower and upper bounds and use them to
compute certified radius.
Deriving a lower bound of Pr(f (V ) = l) and an upper bound of maxΓk⊂Γ minj∈Γk Pr(f (V ) =
j ): We show our intuition to derive the upper and lower bounds. Our formal analysis is shown in the
proof of Theorem 1. Our idea to derive the bounds is to divide the discrete space S in an innovative
way such that we can leverage the Neyman-Pearson Lemma (Neyman & Pearson, 1933). Suppose for
the random variable U, we have a lower bound of the label probability for l and an upper bound of
the label probability for every other label. Formally, We havepι,Pι •…Pι-ι,Pι, ∙∙∙ ,Pc that satisfy
the following:
Pl ≤ Pr(f(U)= l),Pj ≥ PMf(U) = j),∀j = l,	(3)
where P and p denote the lower and upper bounds of p, respectively. Multiplying each term in
Equation (3) by g), we have pr(d) ≤ Pr(f(U) = l)∙(d),Pj∙g) ≥ Pr(f (U) = j)∙(d), ∀j = l∙ Since
Pi andpj (∀j = l) are integer multiples of 由,we have「竺∙ (；)] ≤ Pr(f (U) = l) ∙ (d), ∖pj ∙ (；)[ ≥
Pr(f (U) = j) ∙ (j), ∀j = l. Therefore, we have the following:
p , dpl(d)ɔe ≤ Pr(f (U) = l),pj , ∖pj(d)e)c ≥ Pr(f (U) = j), ∀j = l.
ee
(4)
Let Pak ≥ Pak-I …≥ Pa1 be the k largest ones among {pι,…，p1,P1+1,…，P°}, where ties
are broken uniformly at random. We denote Yt = {aι, a2,…，at} as the set of t labels with the
smallest label probability upper bounds in the k largest ones and denote by PY==Pj∈γ= Pj the sum
of the t label probability bounds, where t = 1,2,…，k.
We define regions A, B, and C in S as the sets of ablated inputs that can be derived only from x,
only from x + δ, and from both x and x + δ, respectively. In particular, the region A is a set of
ablated inputs that can only be obtained via sampling e features (pixels) from x. The region B is
a set of ablated inputs that can only be obtained via sampling e features from the perturbed x + δ,
and the region C is a set of ablated inputs that can be obtained via sampling e features from both
x and x + δ. Then, we can find a region A0 ⊆ C such that Pr(U ∈ A0 ∪ A) = P0i . Note that we
assume we can find such a region A0 since we aim to find sufficient condition. Similarly, we can
find HYt ∈ C such that we have Pr (U ∈ HYt) = PYt. Then, we can apply the Neyman-Pearson
Lemma (Neyman & Pearson, 1933) to derive a lower bound of Pr(f (V ) = l) and an upper bound
of maxΓk⊂Γ minj∈Γk Pr(f (V ) = j) by leveraging the probabilities of V in regions A0 ∪ A and
HYt ∪ B. Formally, we have the following:
k Pr(V ∈ HY ∪ B)
Pr(f (V) = l) ≥ Pr(V ∈ A ∪ A), max min Pr(f (V) = j) ≤ min--------t-----.	(5)
Γk⊂Γj∈Γk	t=1	t
Computing certified radius: Given the lower and upper bounds, we can find the maximum r = kδk0
such that the lower bound Pr(V ∈ A0 ∪ A) is larger than the upper bound mink=ι Pr(V∈HYt ∪B). The
maximum r is the certified radius. Formally, we have the following theorem:
Theorem 1 ('o-norm Certified Radius for Top-k Predictions). Suppose we have an input X with d
features, a deterministic base classifier f, an integer e, a smoothed classifier g where gk (x) is a set
of k labels predicted for X, an arbitrary label l ∈ {1, 2, ∙∙∙ , c}, P1,P1, ∙∙∙ ,P1-1,P1+1, ∙∙∙ ,Pc that
satisfy Equation (3), andPi, Pj (∀j = l) that are defined in Equation (4). IfthefoUowing optimization
problem has a solution r:
d-r
(d-r)	k PYt + (1 --(ey)
r = arg max r s.t. Pi — (1 —、j ) > min------------------——
r≥0	一	Q)	t=1	t
(6)
4
Published as a conference paper at ICLR 2022
Then, we have the following:
l ∈ gk(x+δ),∀kδk0 ≤ rl.	(7)
Proof. Please refer to Appendix A.	□
Next, we show that our derived certified radius is (almost) tight. In particular, when using randomized
ablation and no further assumptions are made on the base classifier, it is impossible to certify an
'o-norm radius that is larger than r + I(k = 1) for top-k predictions.
Theorem 2 (Almost Tightness of our Certified Radius). Assuming we have d-er-l1-2 ≥ 1, p0l +
Ej∈Υk pj ≤ 1, and pl + Ej=I Pj ≥ 1. Ifno assumption on the base classifier is made, then, for any
perturbation ∣∣δko > r + I(k = 1), there exists a base classifier f * consistent with Equation (3) but
we have l ∈/ gk(x + δ) or there exist ties.
Proof. Please refer to Appendix B.	□
Comparing with Levine & Feizi (2019) when k = 1: Our certified radius reduces to the maximum
—	(d-r)
r that satisfies p 一 p0,aγ > 2 ∙ (1 一 K) when k = 1. In contrast, the certified radius in Levine
(e)
d-r
& Feizi (2019) is the maximum r that satisfies pi 一 Pal > 2 ∙ (1 一，(e/). Since pl ≥ pi and
Pak ≤ Pak, our certified radius is the same as or larger than that in Levine & Feizi (2019). Note
that the method by Levine & Feizi (2019) cannot be extended in a straightforward way to derive the
certified robustness for top-k predictions. The reason is that they consider each label independently
in their derivation. In particular, they use the probability that the base classifier predicts label i for an
ablated clean input (i.e., Pr(f (U) = i)) to bound the probability that the base classifier predicts label
i for an ablated adversarial input (i.e., Pr(f (V ) = i)). However, to derive the certified robustness for
top-k predictions, we need to jointly derive the bounds for multiple label probabilities (i.e., Equation
(5)). Moreover, because of the difference in deriving label-probability bounds, our techniques are
significantly different. In particular, Levine & Feizi only need the law of total probability while we
leverage Neyman-Pearson Lemma. Moreover, Levine & Feizi (2019) did not analyze the tightness of
the certified radius for top-1 predictions.
Comparing with Jia et al. (2020): Jia et al. (2020) proved the exact tightness of their '2-norm
certified radius for randomized smoothing with Gaussian noise. We highlight that our techniques
to prove our almost tightness are substantially different from those in Jia et al.. First, they proved
the existence of a region via the Intermediate Value Theorem, which relies on the continuity of
Gaussian noise. However, our space of ablated inputs is discrete. Therefore, given a probability
upper/lower bound, it is challenging to find a region whose probability measure exactly equals to the
given value, since the Intermediate Value Theorem is not applicable. As a result, we cannot prove
the exact tightness of the 'o-norm certified radius when k > 1. To address the challenge, we find a
region whose probability measure is slightly smaller than the given upper bound, which enables us to
prove the almost tightness of our certified radius. Second, since Gaussian noise is not uniform, they
need to iteratively construct regions via leveraging Mathematical Induction. However, Mathematical
Induction is unnecessary in our case because the ablated inputs that can be derived from an input are
uniformly distributed in the space of ablated inputs.
Computing rl in practice: When applying our Theorem 1 to calculate the certified radius rl
in practice, we need the probability bounds pl and PYt and solve the optimization problem in
Equation (6). We can leverage a Monte Carlo method developed by Jia et al. (2020) to estimate
the probability bounds (pi andpj, ∀j = l) with probabilistic guarantees. Then, we can use them to
estimate PI and PY=.Moreover, given the probability bounds pl and PY=,we can use binary search to
solve Equation (6) to find the certified radius r.
Specifically, the probabilities P1,P2, ∙∙∙ ,Pc can be viewed as a multinomial distribution over the
label set {1, 2,…,c}. Given h(x, e) as input, f (h(x, e)) can be viewed as a sample from the
multinomial distribution. Therefore, estimating Pi and Pi for i = l is essentially a one-sided
simultaneous confidence interval estimation problem. In particular, we leverage the simultaneous
5
Published as a conference paper at ICLR 2022
confidence interval estimation method called SimuEM (Jia et al., 2020) to estimate these bounds
with a confidence level at least 1 - α. Specifically, given an input x and parameter e, we randomly
create n ablated inputs, i.e., e1, e2, ∙∙∙ , en. We denote by n7- the frequency of the label j predicted
by the base classifier for the n ablated inputs. Formally, we have nj = Pin=1 I(f(i) = j), where
j ∈ {1,2,…，c} and I is the indicator function. According to JiaetaL (2020), we have the following
probability bounds with a confidence level at least 1 - α:
Pl = B(C； nι,n - nι + 1),p = B(1 - C; n + 1,n - n), ∀j = l,	(8)
where B(q; ξ, ζ) is the qth quantile of a beta distribution with shape parameters ξ and ζ. Then,
We can compute Pl and pj, ∀j = l based on Equation (4). Finally, We estimate PYt as PYt =
min(Pj∈Yt Pj,1 - Pl).
3 Evaluation
3.1	Experimental Setup
Datasets and models: We use CIFAR10 (Krizhevsky et al., 2009) and ImageNet (Deng et al., 2009)
for evaluation. We normalize pixel values to be in the range [0,1]. We use the publicly available
implementation1 of randomized ablation to train our models. In particular, we use ResNet-110 and
RestNet-50 as the base classifiers for CIFAR10 and ImageNet, respectively. Moreover, as in Lee
et al. (2019), we use 500 testing examples for both CIFAR10 and ImageNet.
Parameter setting: Unless otherwise mentioned, we adopt the following default parameters. We
set e = 50 and e = 1, 000 for CIFAR10 and ImageNet, respectively. We set k = 3, n = 100, 000,
and α = 0.001. We will study the impact of each parameter while fixing the remaining ones to their
default values.
Evaluation metric: We use the certified top-k accuracy as an evaluation metric. Specifically, given
a number of perturbed pixels, certified top-k accuracy is the fraction of testing images, whose true
labels have `0 -norm certified radiuses for top-k predictions that are no smaller than the given number
of perturbed pixels. Note that our 'o-norm certified radius corresponds to the maximum number of
pixels that can be perturbed by an attacker.
Compared methods: We compare six randomized smoothing based methods. The first four are only
applicable for top-1 predictions, while the latter two are applicable for top-k predictions.
•	Cohen et al. (2019). This method adds Gaussian noise to a testing image and derives a
tight '2-norm certified radius for top-1 predictions. In particular, considering the three color
channels and each pixel value is normalized to be in the range [0,1], an 'o-norm certified
number of perturbed pixels rl can be obtained from an '2-norm certified radius √3rl.
•	Lee et al. (2019). This method derives an '0-norm certified radius for top-1 predictions. This
method is applicable to discrete features. Like Lee et al. (2019), we treat the pixel values
as discrete in the domain {0,1/256, 2/256,…，255/256}. Since their 'o-norm certified
radius is for pixel channels (each pixel has 3 color channels), a certified number of perturbed
pixels rl can be obtained from their '0-norm certified radius 3rl.
•	Levine & Feizi (2019). This method derives an '0-norm certified number of perturbed
pixels for top-1 predictions in randomized ablation. This method requires a lower bound of
the largest label probability and an upper bound of the second largest label probability to
calculate the certified number of perturbed pixels. They estimated the lower bound using
the Monte Carlo method in Cohen et al. (2019) and the upper bound as 1 - the lower bound.
Note that our certified radius is theoretically no smaller than that in Levine & Feizi (2019)
when k = 1. Therefore, we use our derived certified radius when evaluating this method.
We also found that the top-1 certified accuracies based on our derived certified radius and
their derived certified radius have negligible differences on CIFAR10 and ImageNet, and
thus we do not show the differences for simplicity.
1https://github.com/alevine0/randomizedAblation/
6
Published as a conference paper at ICLR 2022
Table 1: Certified top-k accuracies of the compared methods on CIFAR10.
#Perturbed pixels		1	2	3	4	5
Certified top-1 accuracy	Cohen etal. (2019)	0.118	0.056	0.018	0.0	0.0
	Lee et al. (2019)	0.188	0.018	0.004	0.002	0.0
	LeVine & Feizi (2019)	0.704	0.680	0.670	0.646	0.610
	Levine & Feizi (2019) + SimuEM (Jia et al.,2020)	0.746	0.718	0.690	0.660	0.636
	Our method	0.746	0.718	0.690	0.660	0.636
Certified top-3 accuracy	Jia et al. (2020)	0.244	0.124	0.070	0.028	0.004
	Our method	0.886	0.860	0.838	0.814	0.780
Table 2: Certified top-k accuracies of the compared methods on ImageNet.
#Perturbed pixels		1	2	3	4	5
Certified top-1 accuracy	Cohen et al. (2019)	0.226	0.152	0.120	0.088	0.0
	Lee et al. (2019)	0.338	0.196	0.104	0.092	0.070
	Levine & Feizi (2019)	0.602	0.600	0.596	0.588	0.586
	Levine & Feizi (2019) + SimUEM (Jia et al.,2020)	0.634	0.628	0.618	0.616	0.608
	Our method	0.634	0.628	0.618	0.616	0.608
Certified top-3 accuracy	Jia et al. (2020)	0.326	0.232	0.160	0.120	0.090
	Our method	0.740	0.730	0.712	0.698	0.692
•	Levine & Feizi (2019) + SimuEM (Jia et al., 2020). This is the Levine & Feizi (2019)
method with the lower/upper bounds of label probabilities estimated using the simultaneous
confidence interval estimation method called SimuEM. Again, we use our derived certified
radius for top-1 predictions in this method.
•	Jia et al. (2020). This work extends Cohen et al. (2019) from top-1 predictions to top-k
predictions. In detail, they derive a tight `2 -norm certified radius of top-k predictions for
randomized smoothing with Gaussian noise. An 'o-norm certified number of perturbed
pixels ri for top-k predictions can be obtained from an '2-norm certified radius √3r∣.
•	Our method. Our method produces an almost tight 'o-norm certified number of perturbed
pixels of top-k predictions.
Note that we compare with Cohen et al. (2019) and Jia et al. (2020) because we aim to show that it is
suboptimal to derive 'o-norm certified robustness for top-k predictions by leveraging the relationship
between '2-norm and 'o-norm.
3.2	Experimental Results
Comparison results: Table 1 and 2 respectively show the certified top-k accuracies of the compared
methods on CIFAR10 and ImageNet when an attacker perturbs a certain number of pixels. The
Gaussian noise in Cohen et al. (2019) and Jia et al. (2020) has mean 0 and standard deviation σ. We
obtain the certified top-k accuracies for different σ, i.e., we explored σ = 0.1, 0.12, 0.25, 0.5, 1.0.
Lee et al. (2019) has a noise parameter β. We obtain the certified top-1 accuracies for different β . In
particular, we explored β = 0.1, 0.2, 0.3, 0.4, 0.5, which were also used by Lee et al. (2019). Then,
we report the largest certified top-k accuracies of Cohen et al. (2019), Lee et al. (2019), and Jia et al.
(2020) for each given number of perturbed pixels. We use the default values of e for Levine & Feizi
(2019) and our method.
We have two observations from Table 1 and 2. First, our method substantially outperforms Jia et al.
(2020) for top-k predictions, while Levine & Feizi (2019) substantially outperforms Cohen et al.
(2019) and Lee et al. (2019) for top-1 predictions. Since our method and Levine & Feizi (2019) use
randomized ablation, while the remaining methods use additive noise (Gaussian or discrete noise)
to randomize a testing input, our results indicate that randomized ablation is superior to additive
noise at certifying '0-norm robustness. Second, Levine & Feizi (2019) + SimuEM (Jia et al., 2020)
7
Published as a conference paper at ICLR 2022
8 6 4 2
a a a a
PJn。。，*0p33D
Number of Perturbed Pixels
- - - - -.'
8 6 4 2 0
a a a a a
PJn。。，*0P33
.
25	5 0	75	100	1 25	150
Number of Perturbed Pixels
(a) CIFAR10	(b) ImageNet
Figure 1: Impact of k on certified top-k accuracy.
8 6 4 2
a a a a
PJn。。，*0P33
&PJn。。，*i0HP3∙se3°
25	5 0	75	100	1 25	150
Number of Perturbed Pixels
.
・比
Number of Perturbed Pixels
(a) CIFAR10	(b) ImageNet
Figure 2: Impact of e on certified top-3 accuracy.
0	25	5 0	75	100	1 25	150
Number of Perturbed Pixels
(b) ImageNet
0	5	10	15	20	25	30
Number of Perturbed Pixels
(a) CIFAR10
Figure 3:	Impact of n on certified top-3 accuracy.
8 6 4 2
a a a a
PJn。。，*，d。P33
(a) CIFAR10
&PJn。。，'doHP3∙se3°
----α=0.01
----α=0.001
----α=0.0001
Number of Perturbed Pixels
(b) ImageNet
Figure 4:	Impact of α on certified top-3 accuracy.
outperforms Levine & Feizi (2019). This is because SimuEM can more accurately estimate the label
probability bounds via simultaneous confidence interval estimations.
Impact of k, e, n, and α: Figure 1, 2, 3 and 4 show the certified top-k accuracy of our method
vs. number of perturbed pixels for different k, e, n, and α, respectively. Naturally, the certified
top-k accuracy increases as k increases. For instance, when 5 pixels are perturbed, the certified
top-1 and top-3 accuracies are 63.6% and 78.0% on CIFAR10, respectively. We observe that e
provides a tradeoff between accuracy under no attacks and robustness. Specifically, when e is larger,
the accuracy under no attacks (i.e., certified accuracy with 0 perturbed pixels) is higher, while the
certified accuracy decreases to 0 more quickly as the number of perturbed pixels increases. As n
becomes larger, the curve of the certified accuracy may become higher. The reason is that a larger
n makes the estimated label probability bounds pi and PYt tighter and thus the '0 -norm certified
radius may be larger, which result in a larger certified accuracy. Theoretically, as the confidence level
1 - α decreases, the curve of the certified accuracy may become higher. This is because a smaller
confidence level leads to tighter estimated label probability bounds pi and PYt, and thus the certified
accuracy may be larger. However, We observe the differences between different confidence levels are
negligible when the confidence levels are high enough (i.e., α is small enough).
8
Published as a conference paper at ICLR 2022
4	Related Work
Many certified defenses have been proposed to defend against adversarial perturbations. These
defenses leverage various techniques including satisfiability modulo theories (Scheibler et al., 2015;
Carlini et al., 2017; Ehlers, 2017; Katz et al., 2017), interval analysis (Wang et al., 2018), linear
programming (Cheng et al., 2017; Lomuscio & Maganti, 2017; Fischetti & Jo, 2018; Bunel et al.,
2018; Wong & Kolter, 2018; Wong et al., 2018), semidefinite programming (Raghunathan et al.,
2018a;b), dual optimization (Dvijotham et al., 2018a;b), abstract interpretation (Gehr et al., 2018;
Mirman et al., 2018; Singh et al., 2018), and layer-wise relaxation (Weng et al., 2018; Zhang et al.,
2018; Gowal et al., 2018; Chiang et al., 2020). However, these defenses suffer from one or two
limitations: 1) they are not scalable to large neural networks and/or 2) they are only applicable to
specific neural network architectures. Randomized smoothing addresses the two limitations. Next,
We review randomized smoothing based methods for certifying non-'o-norm and 'o-norm robustness.
Randomized smoothing for non-'o-norm robustness: Randomized smoothing was first proposed
as an empirical defense (Cao & Gong, 2017; Liu et al., 2018). In particular, Cao & Gong (2017)
proposed to use uniform random noise from a hypercube centered at a testing example to smooth its
predicted label. Lee et al. (2019) derived certified robustness for such uniform random noise. Lecuyer
et al. (2019) was the first to derive formal '2 and '∞-norm robustness guarantee of randomized
smoothing with Gaussian or Laplacian noise via differential privacy techniques. Subsequently, Li
et al. (2019) leveraged information theory to derive a tighter '2-norm robustness guarantee. Cohen
et al. (2019) leveraged the Neyman-Pearson Lemma (Neyman & Pearson, 1933) to obtain a tight
'2-norm certified robustness guarantee for randomized smoothing with Gaussian noise. Other studies
include Pinot et al. (2019); Carmon et al. (2019); Salman et al. (2019); Zhai et al. (2020); Dvijotham
et al. (2019); Blum et al. (2020); Levine & Feizi (2020); Kumar et al. (2020); Yang et al. (2020);
Zhang et al. (2020); Salman et al. (2020); Zheng et al. (2020). All these studies focused on top-1
predictions. Jia et al. (2020) derived the first '2 -norm certified robustness of top-k predictions against
adversarial perturbations for randomized smoothing with Gaussian noise and proved its tightness.
Randomized smoothing for 'o-norm robustness: All the above randomized smoothing based
provable defenses were not (specifically) designed to certify 'o-norm robustness. They can be
transformed to 'o-norm robustness via leveraging the relationship between 'p norms. However, such
transformations lead to suboptimal 'o-norm certified robustness. In response, multiple studies (Lee
et al., 2019; Levine & Feizi, 2019; Dvijotham et al., 2019; Bojchevski et al., 2020; Jia et al., 2020;
Zhang et al., 2021; Wang et al., 2021; Liu et al., 2021) proposed new randomized smoothing schemes
to certify 'o-norm robustness. For instance, Lee et al. (2019) derived an 'o-norm certified robustness
for classifiers with discrete features using randomized smoothing. In particular, for each feature,
they keep its value with a certain probability and change it to a random value in the feature domain
with an equal probability. Levine & Feizi (2019) proposed randomized ablation, which achieves
state-of-the-art 'o-norm certified robustness. However, their work focused on top-1 predictions and
they did not analyze the tightness of the certified robustness guarantee for top-1 predictions. We
derive an almost tight 'o-norm certified robustness guarantee of top-k predictions for randomized
ablation.
5	Conclusion
In this work, we derive an almost tight 'o-norm certified robustness guarantee of top-k predictions
against adversarial perturbations for randomized ablation. We show that a label l is provably among
the top-k labels predicted by a classifier smoothed by randomized ablation for a testing input when an
attacker arbitrarily modifies a bounded number of features of the testing input. Moreover, we prove
our derived bound is almost tight. Our empirical results show that our 'o-norm certified robustness is
substantially better than those transformed from '2-norm certified robustness. Interesting future works
include exploring other noise to certify 'o-norm robustness for top-k predictions and incorporating
the information of the base classifier to derive larger certified radiuses.
Acknowledgments
We thank the anonymous reviewers for insightful reviews. This work was supported by the National
Science Foundation under Grants No. 1937786 and 2125977, as well as the Army Research Office
under Grant No. W911NF2110182.
9
Published as a conference paper at ICLR 2022
References
Amazon AWS. https://aws.amazon.com/rekognition/. April 2021.
Anish Athalye and Nicholas Carlini. On the robustness of the cvpr 2018 white-box adversarial
example defenses. arXiv, 2018.
Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of
security: Circumventing defenses to adversarial examples. In ICML, 2018.
Avrim Blum, Travis Dick, Naren Manoj, and Hongyang Zhang. Random smoothing might be unable
to certify '∞ robustness for high-dimensional images. arXiv preprint arXiv:2002.03517, 2020.
Aleksandar Bojchevski, Johannes Klicpera, and Stephan Gunnemann. Efficient robustness certificates
for discrete data: Sparsity-aware randomized smoothing for graphs, images and more. In ICML,
2020.
Jacob Buckman, Aurko Roy, Colin Raffel, and Ian Goodfellow. Thermometer encoding: One hot
way to resist adversarial examples. In ICLR, 2018.
Rudy R Bunel, Ilker Turkaslan, Philip Torr, Pushmeet Kohli, and Pawan K Mudigonda. A unified
view of piecewise linear neural network verification. In NeurIPS, 2018.
Xiaoyu Cao and Neil Zhenqiang Gong. Mitigating evasion attacks to deep neural networks via
region-based classification. In ACSAC, 2017.
Nicholas Carlini and David Wagner. Adversarial examples are not easily detected: Bypassing ten
detection methods. In AISec, 2017.
Nicholas Carlini, Guy Katz, Clark Barrett, and David L Dill. Provably minimally-distorted adversarial
examples. arXiv, 2017.
Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John C Duchi, and Percy S Liang. Unlabeled
data improves adversarial robustness. In Advances in Neural Information Processing Systems, pp.
11192-11203,2019.
Chih-Hong Cheng, Georg NUhrenberg, and Harald Ruess. Maximum resilience of artificial neural
networks. In ATVA, 2017.
Ping-yeh Chiang, Renkun Ni, Ahmed Abdelkader, Chen Zhu, Christoph Studer, and Tom Goldstein.
Certified defenses for adversarial patches. arXiv preprint arXiv:2003.06693, 2020.
Clarifai. https://www.clarifai.com/demo. April 2021.
Jeremy M Cohen, Elan Rosenfeld, and J Zico Kolter. Certified adversarial robustness via randomized
smoothing. In ICML, 2019.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale
hierarchical image database. In CVPR, 2009.
Guneet S Dhillon, Kamyar Azizzadenesheli, Zachary C Lipton, Jeremy Bernstein, Jean Kossaifi, Aran
Khanna, and Anima Anandkumar. Stochastic activation pruning for robust adversarial defense. In
ICLR, 2018.
Krishnamurthy Dvijotham, Sven Gowal, Robert Stanforth, Relja Arandjelovic, Brendan O’Donoghue,
Jonathan Uesato, and Pushmeet Kohli. Training verified learners with learned verifiers. arXiv,
2018a.
Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy A Mann, and Pushmeet Kohli. A
dual approach to scalable verification of deep networks. In UAI, 2018b.
Krishnamurthy Dj Dvijotham, Jamie Hayes, Borja Balle, Zico Kolter, Chongli Qin, Andras Gyorgy,
Kai Xiao, Sven Gowal, and Pushmeet Kohli. A framework for robustness certification of smoothed
classifiers using f-divergences. In International Conference on Learning Representations, 2019.
10
Published as a conference paper at ICLR 2022
Ruediger Ehlers. Formal verification of piece-wise linear feed-forward neural networks. In ATVA,
2017.
Matteo Fischetti and Jason Jo. Deep neural networks and mixed integer linear optimization. Con-
straints, 2018.
Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, and Martin
Vechev. Ai2: Safety and robustness certification of neural networks with abstract interpretation. In
IEEES&P, 2018.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. In ICLR, 2015.
Google Cloud Vision. https://cloud.google.com/vision/. April 2021.
Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan
Uesato, Timothy Mann, and Pushmeet Kohli. On the effectiveness of interval bound propagation
for training verifiably robust models. arXiv, 2018.
Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens Van Der Maaten. Countering adversarial
images using input transformations. In ICLR, 2018.
Jinyuan Jia, Binghui Wang, Xiaoyu Cao, and Neil Zhenqiang Gong. Certified robustness of com-
munity detection against adversarial structural perturbation via randomized smoothing. In WWW,
2020.
Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer. Reluplex: An efficient
smt solver for verifying deep neural networks. In CAV, 2017.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
Technical report, Citeseer, 2009.
Aounon Kumar, Alexander Levine, Tom Goldstein, and Soheil Feizi. Curse of dimensionality on
randomized smoothing for certifiable robustness. In ICML, 2020.
Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified
robustness to adversarial examples with differential privacy. In IEEE S & P, 2019.
Guang-He Lee, Yang Yuan, Shiyu Chang, and Tommi S Jaakkola. Tight certificates of adversarial
robustness for randomly smoothed classifiers. In NeurIPS, 2019.
Alexander Levine and Soheil Feizi. Robustness certificates for sparse adversarial attacks by random-
ized ablation. arXiv preprint arXiv:1911.09272, 2019.
Alexander Levine and Soheil Feizi. Wasserstein smoothing: Certified robustness against wasserstein
adversarial attacks. In International Conference on Artificial Intelligence and Statistics, pp.
3938-3947. PMLR, 2020.
Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Second-order adversarial attack and
certifiable robustness. In NeurIPS, 2019.
Hongbin Liu, Jinyuan Jia, and Neil Zhenqiang Gong. Pointguard: Provably robust 3d point cloud
classification. In CVPR, 2021.
Xuanqing Liu, Minhao Cheng, Huan Zhang, and Cho-Jui Hsieh. Towards robust neural networks via
random self-ensemble. In ECCV, 2018.
Alessio Lomuscio and Lalit Maganti. An approach to reachability analysis for feed-forward relu
neural networks. arXiv, 2017.
Xingjun Ma, Bo Li, Yisen Wang, Sarah M Erfani, Sudanthi Wijewickrema, Grant Schoenebeck,
Dawn Song, Michael E Houle, and James Bailey. Characterizing adversarial subspaces using local
intrinsic dimensionality. In ICLR, 2018.
11
Published as a conference paper at ICLR 2022
Jan Hendrik Metzen, Tim Genewein, Volker Fischer, and Bastian Bischoff. On detecting adversarial
perturbations. In ICLR, 2017.
Microsoft. https://aidemos.microsoft.com/computer-vision. April 2021.
Matthew Mirman, Timon Gehr, and Martin Vechev. Differentiable abstract interpretation for provably
robust neural networks. In ICML, 2018.
Taesik Na, Jong Hwan Ko, and Saibal Mukhopadhyay. Cascade adversarial machine learning
regularized with a unified embedding. In ICLR, 2018.
Jerzy Neyman and Egon Sharpe Pearson. Ix. on the problem of the most efficient tests of statistical
hypotheses. Philosophical Transactions of the Royal Society of London. Series A, Containing
Papers ofa Mathematical or Physical Character, 231(694-706):289-337,1933.
Rafael Pinot, LaUrent Meunier, Alexandre Araujo, Hisashi Kashima, Florian Yger, Cedric GoUy-
Pailler, and Jamal Atif. Theoretical evidence for adversarial robustness through randomization. In
NeurIPS, 2019.
Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets
for 3d classification and segmentation. In Proceedings of the IEEE conference on computer vision
and pattern recognition, pp. 652-660, 2017.
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Certified defenses against adversarial
examples. In ICLR, 2018a.
Aditi Raghunathan, Jacob Steinhardt, and Percy S Liang. Semidefinite relaxations for certifying
robustness to adversarial examples. In NeurIPS, 2018b.
Hadi Salman, Jerry Li, Ilya Razenshteyn, Pengchuan Zhang, Huan Zhang, Sebastien Bubeck, and
Greg Yang. Provably robust deep learning via adversarially trained smoothed classifiers. In
NeurIPS, 2019.
Hadi Salman, Mingjie Sun, Greg Yang, Ashish Kapoor, and J Zico Kolter. Black-box smoothing: A
provable defense for pretrained classifiers. arXiv preprint arXiv:2003.01908, 2020.
Karsten Scheibler, Leonore Winterer, Ralf Wimmer, and Bernd Becker. Towards verification of
artificial neural networks. In MBMV, 2015.
Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus PUscheL and Martin Vechev. Fast and
effective robustness certification. In NeurIPS, 2018.
Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, and Nate Kushman. Pixeldefend:
Leveraging generative models to understand and defend against adversarial examples. In ICLR,
2018.
Jan Svoboda, Jonathan Masci, et al. Peernets: Exploiting peer wisdom against adversarial attacks. In
ICLR, 2019.
Jonathan Uesato, Brendan O’Donoghue, Pushmeet Kohli, and Aaron Oord. Adversarial risk and the
dangers of evaluating against weak attacks. In ICML, 2018.
Binghui Wang, Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong, et al. On certifying robustness against
backdoor attacks via randomized smoothing. CVPR 2020 Workshop on Adversarial Machine
Learning in Computer Vision, 2020.
Binghui Wang, Jinyuan Jia, Xiaoyu Cao, and Neil Zhenqiang Gong. Certified robustness of graph
neural networks against adversarial structural perturbation. In KDD, 2021.
Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. Formal security analysis
of neural networks using symbolic intervals. In USENIX Security Symposium, 2018.
Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Duane Boning, Inderjit S
Dhillon, and Luca Daniel. Towards fast computation of certified robustness for relu networks. In
ICML, 2018.
12
Published as a conference paper at ICLR 2022
Eric Wong and J Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. In ICML, 2018.
Eric Wong, Frank Schmidt, Jan Hendrik Metzen, and J Zico Kolter. Scaling provable adversarial
defenses. In NeurIPS, 2018.
Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong
Xiao. 3d shapenets: A deep representation for volumetric shapes. In Proceedings of the IEEE
conference on computer vision and pattern recognition, pp. 1912-1920, 2015.
Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, and Alan Yuille. Mitigating adversarial effects
through randomization. In ICLR, 2018.
Greg Yang, Tony Duan, Edward Hu, Hadi Salman, Ilya Razenshteyn, and Jerry Li. Randomized
smoothing of all shapes and sizes. In ICML, 2020.
Runtian Zhai, Chen Dan, Di He, Huan Zhang, Boqing Gong, Pradeep Ravikumar, Cho-Jui Hsieh,
and Liwei Wang. Macer: Attack-free and scalable robust training via maximizing certified radius.
In ICLR, 2020.
Dinghuai Zhang, Mao Ye, Chengyue Gong, Zhanxing Zhu, and Qiang Liu. Black-box certifica-
tion with randomized smoothing: A functional optimization based framework. arXiv preprint
arXiv:2002.09169, 2020.
Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efficient neural network
robustness certification with general activation functions. In NeurIPS, 2018.
Zaixi Zhang, Jinyuan Jia, Binghui Wang, and Neil Zhenqiang Gong. Backdoor attacks to graph
neural networks. In SACMAT, 2021.
Tianhang Zheng, Di Wang, Baochun Li, and Jinhui Xu. Towards assessment of randomized mecha-
nisms for certifying adversarial robustness. arXiv preprint arXiv:2005.07347, 2020.
13
Published as a conference paper at ICLR 2022
A Proof of Theorem 1
We define the following two random variables:
U = h(x, e), V = h(x + δ, e).	(9)
where U and V denote the ablated inputs derived from x and its perturbed version x + δ with
parameter e, respectively. We use S to denote the domain space of U and V .
Our proof is based on the Neyman-Pearson Lemma (Neyman & Pearson, 1933), and we present it as
follows:
Lemma 1 (Neyman-Pearson Lemma). Suppose U and V are two random variables in the space
S with probability distributions ρu and ρv, respectively. Let F : S -→ {0, 1} be a random or
deterministic function. Then, we have the following:
•	If Zi = {s ∈ S : ρu(s) > μ ∙ Pv (s)} and Z2 = {s ∈ S : Pu(S) = μ ∙ Pv (s)} for some
μ > 0. Let Z = Zi ∪ Z3, where Z3 ⊆ Z2. Ifwe have Pr (F (U) = 1) ≥ Pr(U ∈ Z) ,then
Pr(F(V) = 1) ≥ Pr(V ∈ Z).
•	If Zi = {s ∈ S : Pu(S) < μ ∙ ρv(s)} and Z2 = {s ∈ S : Pu(S) = μ ∙ Pv(s)} for some
μ > 0. Let Z = Zi ∪ Z3, where Z3 ⊆ Z2. Ifwe have Pr (F (U) = 1) ≤ Pr(U ∈ Z), then
Pr(F (V) = 1) ≤ Pr(V ∈ Z).
Proof. We show the proof of the first part, and the second part can be proved similarly. For simplicity,
we use F (1|S) and F (0|S) to denote the conditional probabilities that F(S) = 0 and F(S) = 1,
respectively. We use Zc to denote the complement of Z, i.e., Zc = S \ Z. We have the following:
Pr(F(V) = 1) - Pr(V ∈ Z)	(10)
=X F(1|s) ∙ Pv (S)- X Pv(S)	(11)
s∈S	s∈Z
=X F(IIS) ∙ Pv(S) + X F(IIS) ∙ Pv(S)- X F(IIS) ∙	Pv(S)-	X F(0|S)	∙	Pv(S)	(12)
=X F(1∣s) ∙ Pv(S) - X F(0∣s) ∙ Pv(S)	(13)
≥1 ∙ ( X F(1∣S) ∙ Pu(S) - X F(0∣S) ∙ Pu(S))	(14)
μ s∈Zc	s∈Z
=1 ∙ ( X F(1∣S) ∙ Pu(S) + X F(1∣S) ∙ Pu(S) - X F(1∣s) ∙ Pu(S)	- X F(0∣s) ∙ Pu(S))	(15)
2 s∈Zc	s∈Z	s∈Z	s∈Z
= L(X F (1∣S) ∙ Pu(S) - X Pu(S))	(16)
μ s∈S	s∈Z
= L(Pr(F(U) = 1) - Pr(U ∈ Z))	(17)
μ
≥0.	(18)
We obtain (14) from (13) because Pu(S) ≥ μ ∙ Pv(s), ∀s ∈ Z and Pu(S) ≤ μ ∙ Pv(s), ∀s ∈ Zc. We
have the last inequality because Pr(F (U) = 1) ≥ Pr (U ∈ Z).	□
Next, We will derive our certified robustness guarantee. For simplicity, We denote Γ = {1,2, ∙∙∙ ,c}\
{l}, i.e., Γ denotes the set of all labels except l. We use Γk to denote a set of k labels in Γ.
Calibrating the lower and upper bounds: Recall that pl and pj , ∀j 6= l are integer multiple of
Then, given the probability loWer and upper bounds in Equation (3), We have the folloWing:
i
CJ .
Pi , dpl∕d'e ≤ Pr(f (U) = l),Pj , ⅛Pc ≥ Pr(f (U) = j), ∀j = l (19)
—C)	C)
14
Published as a conference paper at ICLR 2022
Deriving a lower bound of Pr(f (V ) = l): We will derive a lower bound of the probability
Pr(f (V ) = l). For simplicity, we define the following regions:
A =	{s	∈ S |s	x, s	6 x + δ}, B = {s	∈ S |s 6	x, s	x + δ}, C =	{s ∈ S |s	x, s	x + δ},
(20)
where we say s x if Pr(h(x, e) = s) > 0, and we say s 6 x if Pr(h(x, e) = s) = 0. Intuitively,
the notations and 6 mean that an ablated input can or cannot be derived from an input, respectively.
For instance, region A contains ablated inputs that can be derived from x but cannot be derived from
x + δ, region B contains ablated inputs that can be derived from x + δ but cannot be derived from x,
and region C contains ablated inputs that can be derived from both x and x + δ. Suppose we have
r = ∣∣δ∣∣o. Then, the size of C would be (d-r) since d 一 r features are the same for X and X + δ.
Similarly, we know the size of A and B would be de - d-er . Since we keep e features randomly
sampled from X or X + δ without replacement and set the remaining features to a special value, we
have the following probability mass functions:
Pr(U = s)
Pr(V = s)
(0(d)
if s ∈ A ∪ C
otherwise.
if s ∈ B ∪ C
otherwise.
(21)
(22)
Since we know the size of A, B, and C, as well as the probability mass functions of the random
variables U and V in these regions, we have the following probabilities:
Pr(U ∈ C)
Pr(V ∈ C)
(d-r)
丁
Pr(U ∈ A) = 1 一
(d-r
Pr(U ∈ B) = 0,
/d-r)	/d-r)
iτd)2, Pr(V ∈ B) = 1 - %,Pr(V ∈ A) = 0.
ee
(23)
(24)
(d-r)
We consider the case of Pl ≥ 1 - )e∕. Note that We can do this because We aim to find a sufficient
condition. We let A0 ⊆ C such that it satisfies the following:
Pr(U ∈ A0)= p∣ 一 Pr(U ∈ A).	(25)
Given region A0, We construct the folloWing region:
E = A0 ∪A.	(26)
Then, We have the folloWing probability based on Equation (25):
Pr(U ∈ E) = Pr(U ∈ A) + Pr(U ∈ A0) = PL.	(27)
We define a binary function F (s) = I(f (s) = l). Then, We have the folloWing:
Pr(F(U) = 1)=Pr(f(U) =l) ≥p0l=Pr(U∈E).	(28)
The middle inequality is based on Equation (19) and the right-hand equality is from Equation (27).
Furthermore, we have Pr (U = S) > 1∙Pr(V = S) if and only if S ∈ A, and Pr (U = S) = 1∙Pr(V = S)
if s ∈ A0 . Therefore, We can apply Lemma 1 and We have the folloWing:
Pr(F (V) = 1) = Pr(f(V) = l) ≥ Pr(V ∈ E).	(29)
Therefore, we have the following lower bound for Pr(f (V) = l):
Pr(V ∈ E)	(30)
=Pr(V ∈ A0) + Pr(V ∈ A)	(31)
=Pr(V ∈ A0)	(32)
=Pr(U ∈ A0)	(33)
15
Published as a conference paper at ICLR 2022
(d-r)
=pl-(I- τJτ).
(34)
Note that we have Equation (34) from (33) based on Equation (25).
Deriving an upper bound of maxΓk⊂Γ minj∈Γk Pr(f (V ) = j): We use Λ to denote an arbitrary
subset of Γk, i.e., Λ ⊆ Γk. We denote pΛ = Pj∈Λ Pj，which is the SUm of the upper bound of the
probability for the labels in Λ. We assume pΛ ≤ Pr(U ∈ C). We can make this assumption because
we aim to find a sufficient condition. Given pΛ, We can find a region Hλ ⊆ C such that we have the
following:
PΛ = Pr(U ∈Hλ).	(35)
Given the region HΛ , we construct the following region:
IΛ = HΛ ∪ B.	(36)
Then, we have the following probability:
Pr(U ∈ Iλ) = Pr(U ∈ Hλ) + Pr(U ∈B)=下Λ∙	(37)
Furthermore, for any given Λ, we define a binary function G(s) = I(f(s) ∈ Λ). Then, we have the
following:
Pr(G(U) = 1)= Pr(f(U) ∈ Λ) = EPrf(U) = j) ≤ pΛ = Pr(U ∈ Iλ).	(38)
j∈Λ
We have ∑j∈Λ Pr(f (U) = j) ≤ PΛ based on Equation (19) and we have rightmost equality from
Equation (37). Then, we can apply Lemma 1 and we have the following:
Pr(G(V) = 1) ≤ Pr(V ∈ IΛ).
The value of Pr(V ∈ IΛ) can be computed as follows:
Pr(V ∈ IΛ)
=Pr(V ∈ HΛ) + Pr(V ∈ B)
(d-r)
=Pr(U ∈Hλ) + (1-咨)
e
(d-r)
=PEI- V),
where the last equality is from Equation (35). Therefore, we have the following:
(39)
(40)
(41)
(42)
(43)
Pr(f(V) =j)	(44)
j∈Λ
=Pr(f(V) ∈Λ)	(45)
=Pr(G(V) = 1)	(46)
≤Pr(V ∈ IΛ)	(47)
(d-r)
=Pλ + (I- ʌ(lp).	(48)
Moreover, we have the following:
min Pr(f(V) =j) ≤ minPr(f(V) =j) ≤
j∈Γk	j∈Λ
∑j∈λ Pr(f(V )= j ) = Pr(f(V) ∈ Λ)
∣Λ∣	=	∣Λ∣
(49)
We have the leftmost inequality because Λ ⊆ Γk, and we have the middle inequality because the
smallest value in a set is no larger than the average value of the set. Taking all possible Λ into
consideration and we have the following:
min Pr(f (V) = j)
j∈Γk
(50)
16
Published as a conference paper at ICLR 2022
≤ min
Λ⊆Γk
Prf(V) ∈ Λ)
∣Λ∣
k
min min
t=1 Λ⊆Γk,∣Λ∣ = t
Prf(V) ∈ Λ
∣Λ∣
k
min
t=1
Prf(V) ∈ Yt)
t
k
≤ min
t=1
PYt + (1-詈)
t
(51)
(52)
(53)
(54)
where Υt is the set of t labels in Γk whose probability upper bounds are the smallest, where ties
are broken uniformly at random. The upper bound of Pr(f(V) ∈ Yt) is increasing as PYt increases.
Therefore, the upper bound of Prf(V)∈Yt) reaches the maximum value when Γ = {a1,a2,…，ak},
i.e., Γk is the set of labels in Γ with the largest probability upper bounds. In other words, we have the
following:
k PYt + (1 - (7ψ)
max min Pr(f (V) = j) ≤ min--------——,	(55)
Γk⊂Γ j∈Γk	t=1	t
where Yt = {a1,a2,…,at}.
Deriving the certified radius: Our goal is to make Pr(f (V) = l) > maxΓk⊂Γ minj∈Γk Pr(f(V)
j ). Therefore, it is sufficient to satisfy the following:
(7-r)
(d-r)	k PYt +(I --(dp)
Pl - (1 - ʌɪʌ) > min-----------——
-	0	t=1	t
(56)
where Yt = {a1,a2,…，at}. Therefore, we can find the maximum r that satisfies the above
condition. Formally, we can solve the following optimization problem to find rl :
rl = arg max r
r
(d—r)
(d-r)	PYt + (I - ^7dV)
s.t. Pl - (1 - ' e ) > min-------------------——
-	¢) t	t
(57)
(58)
where Yt = {a1, a2,…，at}. Note that we make two assumptions in our derivation, i.e., P0l ≥ (1 -
7 d—r)	7 d — r)	7 d—r)
'，7「) and PYt ≤ ' 认 .In particular, when Equation (58) is satisfied, we must have Pl ≥ (1- 1(7、)
(e)	(e)	—	(e)
since the left-hand side of Equation (58) is non-negative. In addition, we have Pl + PY ≤ 1 in
—	(d-r)
practice. Therefore, we have PYt ≤ 1 - Pl ≤ \d、.
(	(e)
Technical differences with Jia et al. (2020): Our technical contribution in proving the theorem is
the construction of new discrete regions such that the Neyman-Pearson Lemma can be used. Our
proof of Theorem 1 has the following differences with Jia et al. First, the construct of the regions
A/B/C (Eq 18) are different from Jia et al. due to the discrete space. Second, deriving the lower
bound of Pr(f (V) = l) faces two new challenges in our case. The first challenge is that we need
to find two regions A and A0 while Jia et al. just need to find one region. The second challenge is
how to find these regions. To address the challenge, we first take into consideration of whether A0
exists or not. If A0 exists, we need to shrink region A0 because our space is discrete. These two
challenges do not exist in the continuous case considered by Jia et al. Third, similar to deriving the
lower bound of Pr(f(V) = l), our work is also different from Jia et al. at deriving the upper bound
of maxΓk∈Γ minj∈Γk Pr(f(V) = j).
B Proof of Theorem 2
We consider two scenarios: k = 1 and k 6= 1. In particular, we first consider the scenario where
k = 1. We have Γ1 = {a1} when k = 1. We consider two cases.
17
Published as a conference paper at ICLR 2022
(d-rl-1)
Case I:	In this case, We consider Pl < (1 -卜 /). We let Al ⊆ A be the region that satisfies the
—	(e)
folloWing:
Pl = Pr(U ∈ Al).
(59)
We can find such region because Pl is an integer multiple of 嵩.We let Dl = Al and we have the
—	(e)
following:
Pl = Pr(U ∈Dl), Pr(V ∈Dl) = 0.	(60)
Then, we can divide the remaining region (A ∪ C ) \ Dl into c - 1 disjoint regions such that we have
the following:
∀j ∈{1,2,…，c}∖{l},Pr(U ∈Dj) ≤ Pj.	(61)
We can find these regions because we have Pl + Ps=l Ps ≥ 1. Moreover, we have the following:
∀j ∈{1, 2,…，c}∖{l}, Pr(V ∈Dj) ≥ 0.	(62)
Given these regions, we construct the following base classifier:
f *(z)=j, if Z ∈Dj.	(63)
Note that f * is well defined and is consistent with Equation (3). It is easy to see that label l is not the
predicted label by the corresponding smoothed classifier g* when ∣∣δk0 > rl.
d-rl -1
Case II: In this case, we consider Pl ≥ (1 - 1 J). Since r is the maximum value that satisfies
—	(e)
Equation (6), we have the following condition when ∣δ∣0 = rl + 1:
(d-rl-1)	(d-rl-1)
Pl- (I —(I)-) ≤ IpaI +(I —(d)-).
We let Al = A and we can find Cl ∈ C such that the following equation holds:
(64)
Pr(U ∈Cl)= Pl-(I-
("rl-1))
"ɪ).
(65)
Then, we let Dl = Cl ∪ Al and we have the following:
Pr(U ∈ Dl) =
Pl.
(66)
Furthermore, we have the following:
Pr(V ∈ Dl)
=Pr(V∈Cl)+Pr(V∈Al)
=Pr(U ∈ Cl) +0
(d-rl-I)
=Pl-(I- SdT),
(67)
(68)
(69)
(70)
where the last equality is from Equation (65). Since we have Pl + Pa1 ≤ 1, we can find region
Cai ∈ C \Cl such that we have the following:
Pr(U ∈Caι )= P'αι.	(71)
We define Daγ = Cai ∪ B. Then, we have Pr (U ∈ Daγ) = Pr (U ∈ Cai) = P；i. Similarly, we have
the following:
Pr(V ∈ Dai)
=Pr(V∈Cai)+Pr(V∈ B)
=P'aι +(1-
(dT1))
ιeτ).
(72)
(73)
(74)
18
Published as a conference paper at ICLR 2022
Finally, we can divide the remaining region A ∪ C \ (Dl ∪ Ca1) into c - 2 disjoint regions such that
we have the following:
∀j ∈{1, 2,…，c}\ ({l} ∪{aι}), Pr(U ∈ Dj) ≤ pj.	(75)
We can find these region because Pl + P§= Ps ≥ 1. Given these regions, We construct the following
base classifier:
f*(z)= j, if Z ∈Dj
(76)
Note that f * is well defined and is consistent with Equation (3). Next, we show that label l is not in
the top-1 predicted labels by the smoothed classifier or there exist ties when the `0 perturbation is
larger than rl . In particular, we have the following:
Pr(f*(V) = aι∣kδko > rl)
=Pr(V ∈Daιlkδko >rι)
∕d-ri-1λ
=Pai + (1-	(J)	)
(d-r-1)
≥p0-(I-Sjt )
=Pr(V ∈Dι∣kδko >rι)
=Pr(f *(V) = l| kδk0 >rl).
(77)
(78)
(79)
(80)
(81)
(82)
We have Equation (80) from (79) based on Equation (64). Therefore, the label l is not predicted by
the corresponding smoothed classifier g * or there exist ties. Combining the two cases, we reach the
conclusion.
Next, we will show our bound is almost tight when k 6= 1. In particular, we will show we can
construct a classifier f* such that the label l is not among the top-k predicted labels or there exist ties
when the adversarial perturbation is larger than rι + 1. Similarly, we consider two cases.
(d-rl -2)
Case I: In this case, we consider Pl < (1 -1	/). We let Aι ⊆ A be the region that satisfies the
—	(e)
following:
Pl = Pr(U ∈Aι).	(83)
We can find such region because Pl is an integer multiply of V = 嵩.We let Dι = Aι and we have
—	(e)
the following:
P0ι =Pr(U∈Dι),Pr(V∈Dι) =0.
(84)
Then, we can divide the remaining region (A ∪ C ) \ Dι into c - 1 disjoint regions such that we have
the following:
∀j ∈{1,2,…，c}\ {l}, Pr(U ∈ Dj) ≤ Pj.	(85)
We can find these regions because we have Pl + Ps= Ps ≥ 1. Moreover, we have the following:
∀j ∈{1, 2,…，c}\ {l}, Pr(V ∈ Dj) ≥ 0.	(86)
Given these regions, we construct the following base classifier:
f*(z)=j, ifz∈Dj.	(87)
Note that f* is well defined and is consistent with Equation (3). It is easy to see that label l is not
among the top-k predicted labels or there exist ties when kδk0 > rι + 1.
(d-rl -2)
Case II:	In this case, we consider Pl ≥ (1 -1	/). For simplicity, we denote the following
—	(e)
quantity:
ν
1
(J).
(88)
19
Published as a conference paper at ICLR 2022
Since rι is the maximum value that satisfies Equation (6), We have the following condition:
pl - (1 - i
d-rι-1
. e .
(e)
(d —rl —1)
PYt + (1 - TTJ)
)≤ min------
tt
(89)
In other words, the left-hand side of Equation (6) is no larger than its right-hand side when r = rι +1.
Based on the recurrence relation of the binomial coefficient, we have the following:
d - rι - 1
e
d - rι - 2) + (d - rι - 2
(90)
Combining with the condition (d^--2) ≥ 1, we have the following:
pl - (1 --
('
=pl - (1 - i
d-rι-1)
：-e—L )
¢)	)
d-rl -2)
---7--- -
¢)
(d-rι-2
(d-rl -2)	(
/ ,k e-1 ) (λ \
=PL +飞厂Ti
¢)
d-rι-2
. e .
(91)
(92)
(93)
—
)
)
(d-rl -2)
≥p1+V - (1 —宿一).
(94)
Similarly, we have the following:
min
t
(d— rl—1)
PYt + (1 - 1τ¾u)
PYt
min
t
t
("2) U1	(f
FT + (1-Fn)
(95)
PY
≤ min ——
t
t
(
t - V + (I ——
d-ri-2)
^τ1^)
(96)
(97)
—
t
Then, based on Equation (89), we have the following:
(d—rl—2)
d-rl-2)	pYt- V + (I - I (e) J)
P + V - (1--τk-1) ≤ min-------7----e——
一	(Jt	t
(98)
(d-rl -2
f(1-
pΥ
)V min ——
t
d d — r1 — 2、
t- V -1 ∙V+(I —Frl)
,	C	—/
(d-ri-2、	PYt
PPL - (1--------dk-1) < mjn —
For simplicity, we denote the following:
t
(d-ri—2)
-1 ■ν+(1 - fJ)
(99)
(100)
t
d d — r1 — 2、
PYt-1 ∙V+(I —Fyu)
k
w = arg min
t=1
(101)
t
where ties are broken uniformly at random. Then, based on Equation (100), we have the following:
PI-(I -
(d-rl -2)
ʌ——e——-)<
(d)	)
d—rl —2
pYw - W ∙V+(I —否」)
w
(102)
20
Published as a conference paper at ICLR 2022
Given Equation (101), we have the following if w < k:
(d-rl-2)	(d-rl-2)
pΥw+ι - (W +I) ∙ V + (1---(dy^)	PYw - W ∙ V + (1----(dy^)
w+1	w
(d-rl-2)	(d-rl-2)
PYw+1 + (1- SdrJ)	PYw + (1- ⅛j)
^⇒---------------(e)——≥--------------(e)——
W+1	W
r
OpYw+ι + (1 ——
(d-rl -2)
d-rι-2)	PYw + (I------(d] ')
") ≥(W+1)-----------------wɪ
OpYw+1 - PYw
_	PYw
y⇒paw+ι ≥ ——
d-rl -2
PYw+(1 - FJ)
一	W
(d-rl -2)
+(1-3)
,
W
where Yw = {a1,a2, ∙∙∙ ,aw}. Similarly, We have the following if w > 1:
(d-rl -2)	(d-rl -2)
pYw-i - (W - 1) ∙ V + (I--------(dy^)	AYw - WV + (I---------(dy^)
W-1
(d-rl -2)	(d-rl -2)
EYW-I + (1- ⅛j)	PYw + (1- LTdTJ)
^⇒-------------(e)——≥-----------(e)——
W-1	W
(d-rl -2)
(d-rι-2∖	ETw +(1------Tdr^)
OpYw-I +(1 -	) ≥ (W - 1)----------W	(°)
d-rι -2
PYw + (1 - fj)
^⇒P,a ≤----------------——.
aw	W
(103)
(104)
(105)
(106)
(107)
(108)
(109)
(110)
(111)
Note that the Equation (111) also holds when W = 1. Next, we will show we can build a base
classifier f * SUCh that the label l is not in the top-k predicted labels or there exist ties when the
adversarial perturbation is larger than rl + 1. Our proof relies on constructing disjoint regions for
label l, Yk, and {1, 2, ∙ ∙ ∙ , c} \ ({l} ∪ Yk), respectively.
We let Al = A and we can find Cl ∈ C sUch that the following eqUation holds:
(d—ri—2、
Pr(U ∈Cι)= P - (1 - k-τdr^).
e
(112)
Then, we let Dl = Cl ∪ Al and we have the following:
Pr(U ∈ Dl) = P0l .
(113)
FUrthermore, we have the following:
Pr(V ∈ Dl)
=Pr(V ∈Cl)+Pr(V ∈Al)
=Pr(U ∈ Cl) +0
(114)
(115)
(116)
=Pl - (1 -i
d-rι -2
e) )
(0),
(117)
W
where the last eqUality is from EqUation (112). For simplicity, we denote the following valUe:
d-rι -2
_PYw + (1 - FJ)
W
(118)
21
Published as a conference paper at ICLR 2022
Next, we will construct the region for ∀j ∈ Υw. Based on Equation (112), we have the following:
Pr(U ∈ C\Cl)	(119)
=Pr(U ∈ C) - Pr(U ∈ Cl)	(120)
(d-ri-2、	(d-ri-2、
=(1-	)- (pi -(1-彳L))	(121)
=1 - M.	(122)
For ∀j ∈ Υw , we can find disjoint region Cj ⊆ C \ Cl such that we have the following:
Pr(U ∈Cj) = pj.	(123)
We can find these regions because the summation of the probability of U in these regions is less than
the probability of U in C \ Cl, i.e., we have the following:
Epj= pΥw ≤ 1 - pl = Pr(U ∈C∖Cι),	(124)
j∈Υw
where the middle inequality is from the condition p1 + Ps∈γ^ pS ≤ 1, and the right equality is based
on Equation (119) - (122). Given these regions, we have the following:
∀j ∈ Yw, Pr(V ∈Cj )= pj.	(125)
Based on Equation (111), definition of T in Equation (118), and ∀j ∈ Yw, pj ≤ Ipaj we have the
following:
∀j ∈ Yw,pj≤ Paw ≤ τ.	(126)
Then, for ∀j ∈ Yw, we can find disjoint region Bj ∈ B such that we have the following:
τ - V - Pj ≤ Pr(V ∈ Bj) ≤ τ - Pj.	(127)
We can construct these regions for three reasons: 1) the value of T - PjiS no smaller than 0 based on
Equation (126), 2) ∀j ∈ Yw, there exists a number in the range [τ - V - pj, T - pj] that is an integer
multiple of 击,and 3) the summation of the probability of V in these regions is no larger than the
probability of V in B, i.e., we have the following:
Pr(V∈Bj)	(128)
j∈Υw	
≤ X(T-Pj)	(129)
j∈Υw	
(d-ri-2、	
=pΥw + (1- k-^dp) - PYw	(130)
(d-rι-2)	
≤(1 - ʌ-e-)) ¢)	(131)
=Pr(V ∈ B).	(132)
For ∀j ∈ Yw , we let Dj = Cj ∪ Bj . Then, we have the following:	
Pr(V ∈ Dj)	(133)
=Pr(V∈Cj)+Pr(V∈Bj)	(134)
≥pj + T - v - pj	(135)
=T - V,	(136)
where the Equation (135) from (134) is based on Equation (123) and (127). Next, we will construct
the regions for the labels in Yk ∖ Yw. In particular, for ∀j ∈ {aw+1,aw+2,…,ak}, we can find
disjoint region Dj ∈ C ∖ (Cι ∪ (∪s∈ΥwCs)) such that we have the following:
Pr(U ∈Dj) = pj.	(137)
22
Published as a conference paper at ICLR 2022
Note that We can find these regions because p0 + 52s∈τfc Ps ≤ 1. Similarly, We have the following
for ∀j ∈ Υk \ Yw:	一
Pr(V ∈Dj )= Pj ≥ τ.	(138)
We have the left inequality because ∀j ∈ Yk \ Yw, pj ≥ T based on Equation (107). Finally, We can
divide the remaining region Dj ⊆ C ∪ A \ (Dl ∪ (∪s∈Υk Cs )) into c - k - 1 disjoint regions such
that We have the folloWing:
∀j ∈{1, 2,…，c}\ ({l} ∪ Yk), Pr(U ∈ Dj) ≤ pj.	(139)
We can find these region because Pl + Ps=I Ps ≥ 1. Given these regions, we construct the following
base classifier:
f*(z)= j, if Z ∈Dj
(140)
Note that f * is well defined and is consistent with Equation (3). Next, we show that label l is not in
the top-k predicted labels by the smoothed classifier when the `0 perturbation is larger than rl + 1. In
particular, for ∀j ∈ Yk, we have the following:
Pr(f*(V)=j∣kδko >rι + 1)
=Pr(V ∈Djlkδko >rl + 1)
≥τ - ν
(d-rl-2)
PYw - W ∙V+(I -(dy^^)
w
(d-r-2∖
应 -(I- Sdr)
≥Pr(V ∈Dl∣∣∣δ∣∣0 >rl + 1)
=Pr(f*(V) = l| kδk0 >rl+1).
(141)
(142)
(143)
(144)
(145)
(146)
(147)
We have Equation (145) from (144) based on Equation (102). Therefore, the label l is not among the
top-k predicted labels by the corresponding smoothed classifier g* . Combining the two cases, we
reach the conclusion.
Takeaway: The key challenge in proving the tightness of certified robustness guarantee is that we
are not able to find regions in the discrete space that satisfy certain conditions. The reason is that
we cannot arbitrarily divide the discrete space into different regions. To address the challenge, we
propose to relax the conditions in finding the regions to prove that the certified robustness guarantee is
almost tight. The idea in our proof is very general and we hope our proof can inspire future research
in proving the (almost) tightness for 'o-norm certified robustness guarantee.
C Other applications
In this paper, we focus on image classification. However, our method is also applicable for other
applications such as graph neural networks and 3D deep learning. For example, we conduct experi-
ments for 3D deep learning. In particular, we evaluate our methods on the ModelNet40 (Wu et al.,
2015) benchmark dataset and use PointNet (Qi et al., 2017) as the base classifier. We set e = 16,
n = 10, 000, and α = 0.001. When the number of modified points is 10, 20, 30, 40, and 50, the
certified accuracies for top-1 prediction are 0.779, 0.743, 0.700, 0.649, and 0.570; and the certified
accuracies for top-3 prediction are 0.901, 0.867, 0.829, 0.803, and 0.775.
D Comparing with Chiang et al. (2020)
We also compare with our method with Chiang et al. (2020). We note that the method in Chiang et al.
is only applicable for top-1 prediction. We compare with the method on the CIFAR10 dataset for
top-1 predictions using the publicly available code. The results are as follows. When the number of
perturbed pixels is 1, 2, 3, 4, and 5, the certified accuracies for our method are respectively 0.746,
23
Published as a conference paper at ICLR 2022
0.718, 0.690, 0.660, and 0.636. In contrast, the certified accuracies of Chiang et al. are 0.400, 0.369,
0.342, 0.312, 0.308. As the results show, our method is better than Chiang et al. (2020). We note that
our certified robustness guarantee is probabilistic while Chiang et al. (2020) can give a deterministic
certified robustness guarantee.
24