Published as a conference paper at ICLR 2022
Towards Building A Group-based Unsupervised
Representation Disentanglement Framework
Yang Tao1*, Xuanchi Ren2, YuWang Wang3L Wenjun Zeng4 , Nanning Zheng1
1Xi’an Jiaotong University, 2HKUST, , 3Microsoft Research Asia, 4EIT
Ab stract
Disentangled representation learning is one of the major goals of deep learning, and
is a key step for achieving explainable and generalizable models. A well-defined
theoretical guarantee still lacks for the VAE-based unsupervised methods, which
are a set of popular methods to achieve unsupervised disentanglement. The Group
Theory based definition of representation disentanglement mathematically connects
the data transformations to the representations using the formalism of group. In
this paper, built on the group-based definition and inspired by the n-th dihedral
group, we first propose a theoretical framework towards achieving unsupervised
representation disentanglement. We then propose a model, based on existing VAE-
based methods, to tackle the unsupervised learning problem of the framework. In
the theoretical framework, we prove three sufficient conditions on model, group
structure, and data respectively in an effort to achieve, in an unsupervised way,
disentangled representation per group-based definition. With the first two of the
conditions satisfied and a necessary condition derived for the third one, we offer
additional constraints, from the perspective of the group-based definition, for the
existing VAE-based models. Experimentally, we train 1800 models covering the
most prominent VAE-based methods on five datasets to verify the effectiveness
of our theoretical framework. Compared to the original VAE-based methods,
these Groupified VAEs consistently achieve better mean performance with smaller
variances.
1 Introduction
Learning independent and semantic representations of which individual dimension has interpretable
meaning, usually referred to as disentangled representations learning, is critical for artificial intelli-
gence research (Bengio et al., 2013). Such disentangled representations are useful for many tasks:
domain adaptation (Li et al., 2019; Zou et al., 2020), zero-shot learning (Lake et al., 2017), and
adversarial attacks (Alemi et al., 2016), etc. Intuitively, a disentangled representation should reflect
the factors of variations behind the observed data of the world, and one latent unit is only sensitive to
changes of an individual factor.
Due to the facts that obtaining the ground-truth labels requires significant human effort and humans
can learn those factors unsupervisedly, unsupervised representation disentanglement draws much
attention from researchers recently. A lot of methods are proposed base on some intuitions. Most of
the state-of-the-art methods (Higgins et al., 2017; Burgess et al., 2018; Kim & Mnih, 2018; Chen et al.,
2018; Kumar et al., 2017) are based on Variational Autoencoder (VAE) (Kingma & Welling, 2013).
These methods are fully unsupervised and can be applied to a variety of complex datasets (Lee et al.,
2020). However, these methods suffer from the unidentifiability problem (Locatello et al., 2019b)
due to a lack of theoretical guarantee. Another stream of works (Chen et al., 2016; Lin et al., 2020;
Khrulkov et al., 2021; Lee et al., 2020) leverage generative adversarial network (GAN) (Goodfellow
et al., 2014) to achieve disentanglement but are not interpretable. In general, a well-defined theoretical
guarantee is needed for those methods.
The research of symmetry in physics demonstrates that infinitesimal transformations that conform
to some symmetry groups on physical objects can reflect their nature (Anderson, 1972; Noether,
*Work done during internships at Microsoft Research Asia.
,Corresponding author
1
Published as a conference paper at ICLR 2022
1915). Recently, inspired by this research on symmetry, Higgins et al. (2018) proposed a group-based
definition of disentangled representation. They argue that the symmetries, i.e., the transformations that
change certain aspects of data and keep other aspects unchanged, ideally reflect the underlying data
structure. The group-based definition is a formal and rigorous mathematical definition of faithful and,
ideally, interpretable representation of the generative factors of data, which is widely accepted (Greff
et al., 2019; Mathieu et al., 2019; Khemakhem et al., 2020). Subsequently, due to the fact that the
definition is defined by the world state (i.e., Ground Truth) and based on the assumption (Caselles-
DuPre et al., 2019) that this definition should be useful for downstream tasks such as a Reinforcement
Learning, Caselles-Dupre et al. (2019), Quessard et al. (2020), Painter et al. (2020) propose
environment-based (to Provide world state) methods to learn such disentangled rePresentations in
Reinforcement Learning settings. These inspire us to ask the following question: how would the
definition benefit unsupervised representation disentanglement, and how to learn such a disentangled
representation conforming to the definition in the setting of unsupervised representation learning?
In Group Theory1, the n-th dihedral group (Judson, 2020) is a set of all permutations of polygons
vertices, forming a permutation group under the operation of composition (Miller, 1973). The
generators in an n-th dihedral group, i.e., flip and rotation, can be regarded as the disentangled factors
and also transformations. In this paper, inspired by the n-th dihedral group, we answer the above
questions and address the challenge by proposing a theoretical framework to make the definition
practically applicable for unsupervised representation disentanglement. We then propose a model to
tackle the learning problem of the framework and verify its effectiveness. We theoretically prove in
Section 3.2 the three sufficient conditions towards achieving disentangled representation per group-
based definition, which are referred to as model, group structure, and data constraint, respectively.
With these conditions, we offer additional constraints from the perspective of the definition. The
additional constraints encourage existing VAE-based models to satisfy the symmetry requirement
that comes from the nature of factors. Finally, we provide a learning model based on the existing
VAE-based methods in an effort to fulfill the three conditions (with the model and group structure
constraint and a necessary condition for the data constraint satisfied). As an intuitive understanding,
we introduce the additional constraints to reorganize the latent space to restrict its symmetry in an
unsupervised way. These additional constraints indeed narrow down the solution space of VAE-
based models. Detailed discussion in Sec. 5.4. Our model consistently achieves statistically better
performance in prominent metrics (higher means and lower variances) than corresponding existing
VAE-based models on five datasets, demonstrating that the group-based definition together with our
proposed framework further encourages disentanglement.
Our main contributions are summarized as follows:
•	To our best knowledge, we are the first to provide a theoretical framework to make the
formal group-based mathematical definition of disentanglement practically applicable to
unsupervised representation disentanglement.
•	Our theoretical framework provides additional constraints from the perspective of group-
based definition for the existing VAE-based methods.
•	We propose a learning model of the framework by deriving and integrating additional loss
into existing VAE-based models, in an effort to make the learned representation conform to
the group-based definition without relying on the environment (as done in Caselles-Dupre
et al. (2019); Quessard et al. (2020); Painter et al. (2020)).
2	Related Works
Different definitions have been proposed for disentangled representation (Bengio et al., 2013; Higgins
et al., 2018; Suter et al., 2019). However, only the group-based definition proposed by Higgins et al.
(2018) focuses on the disentangled representation itself and is mathematically rigorous, which is well
accepted (Caselles-Dupre et al., 2019; Quessard et al., 2020; Painter et al., 2020; Diane Bouchacourt,
2021). Nevertheless, Higgins et al. (2018) do not propose a specific learning method based on their
definition. Before this rigorous definition was proposed, there had been some success in identifying
generative factors in static datasets (without interaction with environment), e.g., β-VAE (Higgins et al.,
1We assume some basic familiarity with the fundamentals of Group Theory and Group Representation
Theory. Please refer to Appendix A for some basic concepts.
2
Published as a conference paper at ICLR 2022
2017), Anneal-VAE (Burgess et al., 2018), β-TCVAE (Chen et al., 2018), and FactorVAE (Kim &
Mnih, 2018). More recent works (Srivastava et al., 2020; Shao et al., 2020; Kim et al., 2019; Lezama,
2018; Rezende & Viola, 2018) also do not consider the group-based definition. Therefore, how
group-based definition will facilitate these methods is still an open question. Besides, all these works
suffer from the unidentifiability problem (Locatello et al., 2019b), which is a challenging problem
in this literature. From group-based definition, our framework points out that, the unidentifiability
problem could be solved once the data constraint is satisfied. However, in this work, we can only get
a necessary condition for data constraint, and we still can not solve this challenging problem.
As pointed out in Quessard et al. (2020), it is not straightforward to reconcile the probabilistic infer-
ence methods with the group-based definition framework. Caselles-DUPre et al. (2019), QUessard
et al. (2020), Painter et al. (2020) leverage the interaction with the environment (assuming it is
available) as sUpervision instead of minimizing the total correlation as the VAE-based methods do.
ConseqUently, the effectiveness of these methods is limited to the datasets with the environment
available. Our framework learns a representation conforming to the group-based definition without
relying on the environment. PfaU et al. (2020) propose a non-parametric method to UnsUpervisedly
learn linear disentangled planes in data manifold Under a metric. However, as pointed oUt by the aU-
thors, the method does not generalize to held-oUt data and performs poorly when trying to disentangle
directly from pixels.
To sUmmarize, the existing probabilistic inference methods lack theoretical sUpport, while the
application scope of existing methods based on the groUp-based mathematical definition Higgins
et al. (2018) is very limited. To the best of oUr knowledge, our work is the first to reconcile the
probabilistic generative methods with the inherently deterministic group-based definition framework
of Higgins et al. (2018).
3	The Group-based Framework For Unsupervised Representation
Disentanglement
OUr goal is to explore the benefit of the groUp-based definition for unsupervised representation
disentanglement and learn sUch a disentangled representation. The backgroUnd of the groUp-based
definition is provided in Section 3.1. Section 3.2 presents the theoretical framework towards achieving
unsupervised disentanglement, in which we derive three sUfficient conditions on the model, groUp
strUctUre, and data, respectively. The conditions on the model and groUp strUctUre provide additional
constraints for the existing VAE-based models.
3.1	Group-based Definition
We briefly review the groUp-based definition of disentangled representation Higgins et al. (2018).
Considering a groUp G acting on world state space W (can be Understood as groUnd-trUth) of data
space O and representation space Z via group action ∙w and group action ∙z respectively. For a
mapping f = b ◦ h, where b and h denote the data generative process and encoding, we state: the
mapping f is equivariant between the actions on W and Z if
g ∙ f (w) = f(g ∙ w), ∀g ∈ G, ∀w ∈ W.	(1)
Definition 1 Assume Gcan be decomposed as G = Gi X G2 ×∙∙∙× Gm. The set Z is disentangled
with respect to G if: (i) groUp action of G on Z exits. (ii) the mapping f is equivariant between the
actions on W and Z. (iii) There is a decomposition Z = Zi × Z2 ×∙∙∙× Zm such that each Zi is
affected only by the corresponding Gi.
It is challenging to apply the groUp-based definition to an unsupervised disentanglement setting in
practice becaUse the definition refers to the world state space W, the groUp action of G on W, and
mapping b which are typically inaccessible in practice. We tackle the challenge by re-framing the
definition in a new framework in the following section.
3.2	Proposed Theoretical Framework
Since when the representation is disentangled, one latent Unit in the representation space is only
sensitive to changes of an individUal generative factor, we make the following assUmptions: G
3
Published as a conference paper at ICLR 2022
is a direct product of m cyclic groups (as suggested by Higgins et al. (2018) and for simplicity):
G = (Z∕nZ)m = Z/nZ X Z/nZ ×∙∙∙× Z/nZ, where n is the assumed total number of possible
values for a factor and m is the total number of factors; we further assume Z is a set with the same
elements in G. Therefore, the group actions of G on Z can be set to be element-wise addition, i.e.,
g ∙ Z = g + Z, ∀z ∈ Z,g ∈ G. For the generator of dimension i of G, gi = (0,..., 1,..., 0), gi
only affects the i-th dimension of Z by gi + Z. In addition, the action of each generator gi on W only
affects a single dimension of w.
As we can seen from Equation 1 above, the group action is defined on w, which is often not accessible,
making it difficult to apply the definition in practice. Therefore, for the unsupervised setting, we
would like to use permutations on the data space O (which only provides data without labels) to
substitute the group actions on W . Specifically, inspired by the n-th dihedral group (Dummit &
Foote, 1991), we construct a permutation group Φ, serving the role of an “agent” of G. The actions
of G on W can be performed by Wg ∈ Φ on O, which can be formulated as
f(g ∙ W) = h(Wg ∙ b(w)) = h(Wg ∙ o), ∀w ∈ W,g ∈ G,	(2)
where o denotes the data (e.g., image) corresponding to the world state w through the mapping
function b. If the above equation holds, we state that the “agent” permutation group Φ exists. We first
give the conditions for the existence of this “agent” permutation group Φ, then derive the additional
condition to achieve such disentanglement. We accomplish these two objectives in Theorem 1 with
the proof provided in Appendix B. Theorem 1 states that a general permutation group Φ on O can
serve as an agent group (agent group exists) if and only if both (i) and (ii) are satisfied. If the agent
group exists, and its permutations (actions on O) can be defined by an autoencoder-like model as
shown in the equation in (iii), then Z is disentangled with respect to G.
Theorem 1 For the group G = (Z/nZ)m, a permutation group Φ on O, a representation space Z,
a World State space W, and mapping b and h, Equation 2 holds if and only if (i) Φ is isomorphic to
G, and (ii) For each generator of dimension i of G, gi, there exists a Wi ∈ Φ, i = 1, . . . , m, such
that Wi ∙ b(w) = b(gi ∙ w), ∀w ∈ W, and Wi is a generator of Φ; Further, ifEquation 2 holds and
(iii) Wg ∙ b(w) = h-1(g ∙ f(w)) ∀w ∈ W,Wg ∈ Φ ,then Z is disentangled with respect to G, where
Wg is the corresponding element in Φ of g under the isomorphism.
In Theorem 1, (i) states that the relation between the elements (i.e., group structure) is preserved
between Φ and G, and we denote it as the group structure constraint; (ii) actually indicates a data
constraint that all variations in the data can be generated by compositions of some basic permutation
generators {Wi}i=1,...,m. We denote it as the data constraint; (iii) states that the permutations in
the agent group Φ are defined by encoding, action, and decoding, which is referred to as the model
constraint. Note that in Theorem 1, only the data constraint refers to the world state W.
Here is a sketch of the proof: data constraint is a special case of Equation 2 for a generator, and
group structure constraint is a relation-preserving constraint on compositions of generators, and
satisfying both constraints will thus result in that Equation 2 holds for any general element in Φ, and
vice versa. Moreover, we can derive Equation 1 for disentanglement when combining the model
constraint and Equation 2.
The model constraint specifies the way to permute the data. When the data is permuted, its world
state changes. Therefore, how the world states transit between each other is modeled by the model
constraint applied on the data. The isomorphism between Φ and G ensures that the world state space
W and data space O have the same symmetry. In this way, the model applied on the data learns the
transition of the world states. Note that we aim to bring this group-based definition, which requires
ground truth by default, into the unsupervised setting. Now only the data constraint refers to the
world states, and it seems almost impossible to derive a sufficient condition for it without the labels.
We thus make a trade-off in which we use a necessary condition in the next section.
4	Groupified VAE: a learning method of the framework
Let’s look closer into the three constraints, respectively. Firstly, we consider the model constraint,
Wg ∙ o = h-1(g ∙ h(o)) ∀o ∈ O, Wg ∈ Φ, which suggests that the action of Φ on O can be
implemented using an autoencoder-like network that performs encoding, action on its representation
space, and decoding. Given an autoencoder-like network with an encoder h and a decoder d, since d
4
Published as a conference paper at ICLR 2022
-{■■■■}
A.
■ WZ
Decoder
d
,rzɔ.
N +伊
{ffl∣}
个+/
={■■■■} LHl 川}M{咖}
h 2 rf z_
ι+.¾
= {■■■■}	DecOder	*
(a)
z + 9j
以
(b)
O
O
Figure 1: Overview of the implementation (Groupified VAE).(a) Illustration of permutation group
Φ = {夕g |g ∈ G} defined on a VAE-based model, where G = (Z∕nZ)m. The generators 夕i, Wj ∈
Φ are permutations on O. Specifically, when optimized, Wi and Wj are horizontal and vertical
movements. Wi is defined as the solid orange arrows illustrate: encode an image o to representation z,
perform η on Z to get z, add gi to z, and decode back to the image. This process can be regarded as an
exchange of images in dataset (permutation), as the dashed orange arrow shows. These permutations
form a group Φ. (b) The Isomorphism Loss, which guarantees that Φ is isomorphic to G, includes
Abel Loss La constraining the commutativity, and Order Loss Lo constraining the cyclicity.
is approximately the inversion of h, the model constraint can be formulated as
Wg ∙ o = h-1(g ∙ h(o)) = d(g ∙ h(o)),∀o ∈ O,g ∈ G,
(3)
together with further implementation of Φ as described in Section 4.1, the model constraint can be
fulfilled. Secondly, The data constraint requires that all variations in the data can be generated by
compositions of some basic permutations generators. Previous VAE-based works (Higgins et al.,
2017; Burgess et al., 2018; Kim & Mnih, 2018; Chen et al., 2018; Kumar et al., 2017) aim to generate
the data with independent generative factors, which is in line with the data constraint. Intuitively, if
the VAE-based model can generate the data from statistical independent basic latent units and each
unit corresponds to the basic permutation generator, the data constraint may be satisfied. Based
on the intuition above, we prove that if the world state is independently sampled per dimension, the
minimization of total correlation is a necessary condition for the data constraint (see Appendix E).
Therefore, we can leverage existing VAE-based models to fulfill the data constraint to some extent for
the unsupervised setting. Lastly, to satisfy the group structure constraint, we derive a self-supervised
Isomorphism Loss which can be incorporated into the VAE-based model as described in Section 4.2.
4.1	IMPLEMENTATION OF GROUP Φ
The key is to implement the group actions of G on Z into the VAE-based models, we need to map
the representation z to a group that is isomorphic to G (cyclic representation space). Therefore, we
construct a function η to achieve this mapping. Moreover, this mapping is required to be differentiable,
in order for back-propagation to be adopted for optimization. According to Group Theory, there
is an isomorphism between G and the n-th root unity group: {exp((2πiz)∕n)∣z ∈ Zm}, where
n, m are the same as in G. Therefore, the representation Z can be mapped to Z by the function η as
Z = η(z) = exp((2∏iz)∕n) (see Figure 1 (a)). However, Z can not be mapped to directly as it has
complex numbers, but we can use Euler,s formula: exp((2πiz)∕n) = sin((2πz)∕n) + i cos((2πz)∕n)
to map z to its real and imaginary part, i.e., vector sin((2πz)∕n) and cos((2πz)∕n). The two vectors
are concatenated and fed to the decoder.
For ease of implementation, the permutation group Φ can be approximately generated by compositions
of generators, i.e., Φ =< wι, W2,∙∙ ∙, Wm >. Recall that the generator Wi of group Φ is defined as
Wi ∙ o = d(gi ∙ h(o)) = d(h(o) + gi), ∀o ∈ O, where gi is generator of dimension i in G, as shown
in Figure 1 (a). For Wi, We implement gi ∙ h(o) by adding 1 (without loss of generality) to the i-th
dimension of h(o), then make it cyclic by function η. Similarly, for Wi-1, we add the value of n - 1.
5
Published as a conference paper at ICLR 2022
4.2	Implementation of the Isomorphism
In this section, to satisfy the group structure constraint (isomorphism), we derive two equivalent
constraints, which are then converted into an Isomorphism Loss LI . Many groups are uniquely
determined by the properties of the generators, e.g., group G =< a, b|a2 = b2 = e, ab = ba >. In
addition, since the group Φ is isomorphic to G, Φ is also expected to be commutative and cyclic. In
light of this, we derive two constraints on generators that are equivalent to the isomorphism condition,
as described in Theorem 2. Please refer to Appendix C for the proof.
Theorem 2 The defined permutation group Φ =< 夕 1,夕 2,...,夕 m > is isomorphic to G =
(Z∕nZ)m ifand only if: (i) for ∀ generators ψi,夕j ∈ Φ, 1 ≤ i,j ≤ m, we have ψiψj 二 夕j夕i, and
(ii) ∀φi ∈ Φ, 1 ≤ i ≤ m, we have 夕？ = e, where e is the identity element ofgroup Φ.
The first constraint requires the group Φ to be an abelian group (Judson, 2020). Therefore, we denote
it as Abel constraint and the loss derived from it as the Abel Loss La . The second is a constraint on
the order of elements. We thus denote it as the Order constraint and the loss derived from it as the
Order Loss Lo . See Appendix F for a more detailed implementation.
Abel Loss. For the Abel constraint: ∀%,夕j ∈ Φ, 1 ≤ i,j ≤ m, We have WiWj = Wj夕i. We
minimize ∣∣Wi ∙ (Wj ∙ o) - Wj ∙ (Wi ∙ o)k, ∀o ∈ O to meet the Abel constraint, as shown in Figure 1
(b). The Abel Loss is the sum of the losses of all combinations of tWo generators. Denote the set of
combinations as C = {(i, j)|1 ≤ i, j ≤ m}. The Abel Loss is defined as follows
La = ΣS ΣS	l∣Wi	∙ (Wj ∙	o)	- Wj	∙	(Wi	∙	o)k.	(4)
o∈O (i,j)∈C
Order Loss. For the Order constraint: ∀Wi ∈ Φ, 1 ≤ i ≤ m, we have Win = e, where e is the identity
element in group Φ (identity mapping). Note that with n times composition of Wi, it is difficult for the
gradient to back-propagate. We thus use an approximation that uses 2 times of composition instead.
When the autoencoder can do the reconstruction well, this approximation holds, see appendix E
for details. Similar to Abel Loss, we minimize ∣∣Wi ∙(Wn—1 ∙ o) 一 o∣, ∀o ∈ O to satisfy the Order
constraint. The whole process is illustrated in Figure 1 (b). However, the equation is not symmetrical
and leads to bias. Therefore, we use the following symmetrical form instead:
Lo = XX	(kWi∙(Wn-1∙	o) -	ok	+ kWn-1∙(Wi∙ o) -	ok) .	(5)
o∈O 1≤i≤m
With the above two loss functions optimized, the isomorphism condition is satisfied, which can be
illustrated by Theorem 3. Please refer to Appendix D for the proof.
Theorem 3 The following two conditions are equivalent: (i) ∀Wi, Wj ∈ Φ, 1 ≤ i, j ≤ m, we have
WiWj = WjWi and ∀Wi ∈ Φ, 1 ≤ i ≤ m, we have Win = e (ii) the Abel Loss function (Equation 4)
and the Order Loss function (Equation 5) are optimized.
Since the Abel Loss and Order Loss are equally important for satisfying the isomorphism condition,
we assign equal weight to them. Thus, the Isomorphism Loss is LI = Lo + La . With the
implementation of group Φ, the model constraint is satisfied. We optimize the Isomorphism Loss to
satisfy the group structure constraint. To further satisfy the data constraint to some extent as described
in Section 4, we leverage VAE-based models and optimize their original loss (that minimizes the total
correlation), denoted as LVAE. Therefore, the Total Loss is L = LVAE + γILI, where γI is the
weight of Isomorphism Loss. We denote the above VAE-based implementation as Groupified VAE. 5
5	Experiments
We first verify the effectiveness of Groupified VAE quantitatively in learning disentangled representa-
tions on several datasets and several VAE-based models. Then, we show its effectiveness qualitatively
on two typical datasets. After that, we perform a case study on the dSprites dataset to analyze the
effectiveness, and conduct ablation studies on the losses and hyperparameters. For the performance
comparison of two downstream tasks (abstract reasoning Van Steenkiste et al. (2019) and fairness
evaluation Locatello et al. (2019a)), and more comprehensive results, please see Appendix I.
6
Published as a conference paper at ICLR 2022
5.1	Datasets and Baseline Methods
To evaluate our method, we consider several datasets: dSprites (Higgins et al., 2017), Shapes3D (Kim
& Mnih, 2018), Cars3D (Reed et al., 2015), and the variants of dSprites introduced by Locatello et
al. (Locatello et al., 2019b): Color-dSprites and Noisy-dSprites. Please refer to Appendix G for the
details of the datasets.
We choose the following four baseline methods as representatives of the existing VAE-based models,
which are denoted as Original VAEs. We verify the effectiveness of our implementation based on
those methods. β-VAE (Higgins et al., 2017) introduces a hyperparameter β in front of the KL
regularizer of the VAE loss. It constrains the VAE information capacity to learn the most efficient
representation. AnnealVAE (Burgess et al., 2018) progressively increases the bottleneck capacity
so that the encoder learns new factors of variation while retaining disentanglement in previously
learned factors. FactorVAE (Burgess et al., 2018) and β-TCVAE (Chen et al., 2018) both penalize
the total correlation (Watanabe, 1960), but estimate it with adversarial training (Nguyen et al., 2010;
Sugiyama et al., 2012) and Monte-Carlo estimator respectively.
dSprits _____________DCI________________________BetaVAE_______________________MIG_______________________FaetorVAE_________
	Original	GroUPified	Original	Groupified	Original	Groupified	Original	Groupified
β-VAE	0.23 ± 0.10	0.46 ± 0.085	0.75 ± 0.083	0.86 ± 0.051	0.14 ± 0.097	0.37 ± 0.089	0.51 ± 0.098	0.63 ± 0.089
AnnealVAE	0.28 ± 0.10	0.39 ± 0.056	0.84 ± 0.050	0.87 ± 0.0067	0.23 ± 0.10	0.34 ± 0.061	0.70 ± 0.094	0.68 ± 0.058
FactorVAE	0.38 ± 0.10	0.41 ± 0.074	0.89 ± 0.040	0.89 ± 0.020	0.27 ± 0.092	0.31 ± 0.061	0.74 ± 0.068	0.75 ± 0.075
β-TCVAE	0.35 ± 0.065	0.36 ± 0.11	0.86 ± 0.026	0.861 ± 0.038	0.17 ± 0.067	0.24 ± 0.093	0.68 ± 0.098	0.70 ± 0.098
Cars3d	DCI		BetaVAE		MIG		FactorVAE	
	Original	Groupified	Original	Groupified	I Original	Groupified	I Original	Groupified
β-VAE	0.18 ± 0.059	0.24 ± 0.041	0.99±1.6e-3	1.0 ± 0.0	0.071 ± 0.032	0.11 ± 0.032	0.81 ± 0.066	0.93 ± 0.034
AnnealVAE	0.22 ± 0.046	0.25 ± 0.046	0.99 ± 4e - 4	0.99 ± 1.5e - 4	0.074 ± 0.016	0.10 ± 0.014	0.82 ± 0.062	0.87 ± 0.028
FactorVAE	0.21 ± 0.054	0.25 ± 0.040	0.99 ± 1e-4	1.0 ± 0.0	0.098 ± 0.027	0.11 ± 0.033	0.90 ± 0.039	0.93 ± 0.034
β-TCVAE	0.24 ± 0.049	0.26 ± 0.046	1.0 ± 0.0	1.0 ± 0.0	0.10 ± 0.021	0.11 ± 0.033	0.88 ± 0.040	0.93 ± 0.034
Shapes3d	DCI	BetaVAE	MIG	FactorVAE Original ,Groupified	Original	,Groupified	Original	,Groupified	Original	,Groupified
β-VAE	0.44 ± 0.176	0.56 ± 0.10	0.91 ± 0.072	0.90 ± 0.045	0.28 ± 0.18	0.42 ± 0.15	0.82 ± 0.098	0.82 ± 0.043
AnnealVAE	0.52 ± 0.051	0.60 ± 0.078	0.82 ± 0.076	0.89 ± 0.086	0.48 ± 0.047	0.50 ± 0.052	0.75 ± 0.074	0.83 ± 0.066
FactorVAE	0.47 ± 0.10	0.49 ± 0.065	0.86 ± 0.055	0.80 ± 0.075	0.33 ± 0.13	0.43 ± 0.11	0.81 ± 0.056	0.79 ± 0.066
β-TCVAE	0.66 ± 0.10	0.72 ± 0.061	0.97 ± 0.039	0.96 ± 0.042	0.40 ± 0.18	0.47 ± 0.090	0.89 ± 0.064	0.90 ± 0.046
Table 1: Performance (mean ± std) on different datasets and different models with different metrics.
We evaluate β-VAE, AnnealVAE, FactorVAE, and β-TCVAE on dSprites, Cars3d, Shapes3d, Noisy-
dSprites, and Color-dSprites for 1800 settings. These settings include different random seeds and
hyperparameters, refer to Appendix G for the details. We only show the first three datasets here. For
more results, please refer to Appendix I.
5.2	Quantitative Evaluations
This section performs quantitative evaluations on the datasets and models introduced with different
random seeds and different hyperparameters. Then, we evaluate the performance of the Original
and Groupified VAEs in terms of several popular metrics: BetaVAE score (Higgins et al., 2017),
DCI disentanglement Eastwood & Williams (2018) (DCI in short), MIG (Chen et al., 2018), and
FactorVAE score (Kim & Mnih, 2018). We assign three or four hyperparameter settings for each
model on each dataset. We run it with ten random seeds for each hyperparameter setting to minimize
the influence of random seeds. Therefore, we totally run ((3 × 10 × 3 + 10 × 3 × 3) × 2) × 5 = 1800
models. We evaluate each metric’s mean and variance for each model on each dataset to demonstrate
the effectiveness of our method. As shown in Table 1, these Groupified VAEs have better performance
(numbers marked bold in Table 1) than the Original VAEs on almost all the cases.
On Shapes3d, the Groupified VAEs outperform the Original ones on all the metrics except for
BetaVAE scores, suggesting some disagreement between BetaVAE scores and other metrics. Similar
disagreement is also observed between the variances of MIG and other metrics on Cars3d. Note that
the qualitative evaluation in Appendix J shows that the disentanglement ability of Groupified VAEs is
better on Shapes3d and Cars3d.
7
Published as a conference paper at ICLR 2022
lanigirO
(a) Original	(b) Groupified
defiipuor
Figure 3: Traversal results of two factors (floor
color, scale) of Original and Groupified β-
TCVAE. The traversal results of Groupified
VAEs are cyclic.
Figure 2: Visual traversal comparison between
Original and Groupified β-TCVAE. The traversal
results of Groupified VAEs are less entangled.
5.3	Qualitative Evaluations
We qualitatively show the Groupified VAEs achieve better disentanglement than the Original ones.
As shown in Figure 2, the traversal results of Groupified β-TCVAE on Shape3d and Car3d are less
entangled. For more qualitative evaluation, please refer to Appendix J. To verify that the Groupified
VAEs learn a cyclic representation space (where n = 10), we provide the traversal results of [0,18]
with a step of 2 for both the Groupified and Original β-TCVAE on Shape3d in Figure 3. We observe
that the traversal results of Groupified VAEs are of high quality with a period of 10 (equal to n).
However, the Original VAEs generate low-quality images without cyclicity. For the comparison of
the results on CelebA (real-world datasets), please see appendix J.
5.4	Visualization of the Learned Representation Space
To understand how our theoretical framework helps the existing VAE-based models to improve the
disentanglement ability, we take dSprites as an example, visualize the learned representation space,
and show the typical score distributions of the metrics. First, we visualize the space spanned by the
three most dominant factors (x position, y position, and scale).
As shown in Figure 5 (for more results, please refers to Appendix L), the spaces learned by the Original
VAEs collapse, while the spaces of the Groupified VAEs only bend a little bit. The main reason
is that the Isomorphism Loss, serving as a self-supervision signal, suppresses the representation
space distortion and encourages the disentanglement of the learned factors. As Figure 4 shows,
the Groupified VAEs consistently achieve better mean performance with smaller variances. The
isomorphism reduces the search space of the network so that the Groupified VAEs converge to the
ideal disentanglement solution.
(a) BetaVAE score (b) DCI disentanglement	(c) MIG
(d) FactorVAE score
Figure 4: Performance distribution of Original and Groupified AnnealVAE on dSprites (demonstrated
by the Violin Plot (Hintze & Nelson, 1998)). Variance is due to different hyperparameters and random
seeds. We observe that Groupified AnnealVAE improves the average performance with smaller
variance in terms of BetaVAE score (a), DCI disentanglement (b), and MIG (c), and has a comparable
mean performance with smaller variance in terms of FactorVAE score (d).
	Original	Groupified			Factor Size n =		10
		n=5	n = 10	n = 15	w/o Abel	w/o Order	GroUPified
DCI	0.27 ± 0.10	0.34 ± 0.062	0.38 ± 0.055	0.38 ± 0.064	0.28 ± 0.11	0.34 ± 0.056	-0.38 ± 0.055
Table 2: Ablation study on the factor size n and Isomorphism Loss. DCI disentanglement is listed
(mean ± std).
8
Published as a conference paper at ICLR 2022
(a) C = 10, Groupified
(b) C = 20, Groupified
(c) C = 25, Groupified
(d) C = 30, Groupified
Latent space visualization
(e) C = 10, Original
(f) C = 20, Original
(g) C = 25, Original
(h) C = 30, Original
Figure 5: The representation space spanned by the learned factors by Original (bottom row) and
Groupified AnnealVAE (top row). The position of each point is the disentangled representation of the
corresponding image. An ideal result is all the points form a cube and color variation is continuous.
The increase of C (a hyperparameter of AnnealVAE) results in a collapse of representation space
of the Original VAE. The collapse is suppressed by the Isomorphism Loss, which leads to better
disentanglement.
5.5	Ablation Study
We perform an ablation study on the assumed total number of possible values for a factor (factor size)
n, Abel Loss La , and Order Loss Lo . We take the AnnealVAE trained on dSprites as an example.
We only consider the DCI disentanglement metric here. We investigate the influence of factor size n.
Besides, to evaluate the effectiveness of the two constraints, the models with the Abel Loss alone or
Order Loss alone added are also evaluated. In this setting, we fix n to 10. We compute the mean and
variance of the performance for 30 settings of hyperparameters and random seeds. Table 2 shows
that the isomorphism plays a role of cycle consistency in the representation space, leading to better
disentanglement. The performance is robust to the factor size n, as the models learn to adapt to
different n in the training process. The models with only the Abel Loss or Order Loss applied have
improved performance compared to the originals. The former (Abel Loss) performs better than the
latter, suggesting that commutativity plays a more important role. Note that the number of factors m
can be learned and is not a hyperparameter. See Appendix F for details. γI is empirically set to 1.
6 Conclusion
In this paper, we have opened the possibility of applying group-based definition to unsupervised
disentanglement by proposing a theoretical framework. The group structure and model constraint
in the framework are effective for existing VAE-based unsupervised disentanglement methods. In
addition, by establishing the feasibility of learning the representation conforming to the definition
in unsupervised settings, we have exhibited the consistently better mean performance with lower
variance attributed to the definition. We believe our work constitutes a promising step towards
unsupervised disentanglement with theoretical guarantee. As to the limitation, we only provide
a necessary condition for the data constraint, as a result, we can not address the unidentifiability
problem. Tackling the unidentifiability problem with the group-based definition is beyond the scope
of this work, we will leave it as future work. In addition, a natural extension of our framework is to
use lie group Hall (2015) (which is also a manifold) to extend our framework.
9
Published as a conference paper at ICLR 2022
References
Alexander A Alemi, Ian Fischer, Joshua V Dillon, and Kevin Murphy. Deep variational information
bottleneck. arXiv preprint arXiv:1612.00410, 2016.
Philip W Anderson. More is different. Science,177(4047):393-396,1972.
Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new
perspectives. TPAMI, 35(8):1798-1828, 2013.
Christopher P Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick Watters, Guillaume Des-
jardins, and Alexander Lerchner. Understanding disentangling in beta -vae. arXiv preprint
arXiv:1804.03599, 2018.
Hugo Caselles-Dupre, Michael Garcia Ortiz, and David Filliat Symmetry-based disentangled
representation learning requires interaction with environments. In NeurIPS, pp. 4606-4615, 2019.
Ricky TQ Chen, Xuechen Li, Roger B Grosse, and David K Duvenaud. Isolating sources of
disentanglement in variational autoencoders. In NeurIPS, pp. 2610-2620, 2018.
Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan:
interpretable representation learning by information maximizing generative adversarial nets. In
NeurPIS, 2016.
Stephane Deny Diane Bouchacourt, Mark Ibrahim. Addressing the topological defects of disentan-
glement, 2021. URL https://openreview.net/forum?id=cbdp6RLk2r7.
David S Dummit and Richard M Foote. Abstract algebra, volume 1999. Prentice Hall Englewood
Cliffs, NJ, 1991.
Cian Eastwood and Christopher KI Williams. A framework for the quantitative evaluation of
disentangled representations. In ICLR, 2018.
Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron C. Courville, and Yoshua Bengio. Generative adversarial networks. CoRR, abs/1406.2661,
2014. URL http://arxiv.org/abs/1406.2661.
Klaus Greff, Raphael Lopez Kaufman, Rishabh Kabra, Nick Watters, Chris Burgess, Daniel Zoran,
Loic Matthey, Matthew Botvinick, and Alexander Lerchner. Multi-object representation learning
with iterative variational inference. arXiv preprint arXiv:1903.00450, 2019.
Brian Hall. Lie groups, Lie algebras, and representations: an elementary introduction, volume 222.
Springer, 2015.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick,
Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a
constrained variational framework. ICLR, 2017.
Irina Higgins, David Amos, David Pfau, Sebastien Racaniere, Loic Matthey, Danilo Rezende,
and Alexander Lerchner. Towards a definition of disentangled representations. arXiv preprint
arXiv:1812.02230, 2018.
Jerry L Hintze and Ray D Nelson. Violin plots: a box plot-density trace synergism. The American
Statistician, 52(2):181-184, 1998.
Thomas W Judson. Abstract algebra: theory and applications. Virginia Commonwealth University
Mathematics, 2020.
Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen. Variational autoencoders
and nonlinear ica: A unifying framework. In AISTATS, pp. 2207-2217, 2020.
Valentin Khrulkov, Leyla Mirvakhabova, Ivan Oseledets, and Artem Babenko. On disentangled
representations extracted from pretrained gans, 2021. URL https://openreview.net/
forum?id=VCAXR34cp59.
10
Published as a conference paper at ICLR 2022
Hyunjik Kim and Andriy Mnih. Disentangling by factorising. In ICML, 2018.
Minyoung Kim, Yuting Wang, Pritish Sahu, and Vladimir Pavlovic. Bayes-factor-vae: Hierarchical
bayesian deep auto-encoder models for factor disentanglement. In Proceedings of the IEEE/CVF
International Conference on Computer Vision, pp. 2979-2987, 2019.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114, 2013.
Abhishek Kumar, Prasanna Sattigeri, and Avinash Balakrishnan. Variational inference of disentangled
latent concepts from unlabeled observations. arXiv preprint arXiv:1711.00848, 2017.
Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building
machines that learn and think like people. Behavioral and brain sciences, 40, 2017.
Wonkwang Lee, Donggyun Kim, Seunghoon Hong, and Honglak Lee. High-fidelity synthesis with
disentangled representation. In ECCV, 2020.
Jose Lezama. Overcoming the disentanglement Vs reconstruction trade-off viajacobian supervision.
In International Conference on Learning Representations, 2018.
Yu-Jhe Li, Ci-Siang Lin, Yan-Bo Lin, and Yu-Chiang Frank Wang. Cross-dataset person re-
identification via unsupervised pose disentanglement and adaptation. In ICCV, 2019.
Zinan Lin, Kiran Thekumparampil, Giulia Fanti, and Sewoong Oh. Infogan-cr and modelcentrality:
Self-supervised model training and selection for disentangling gans. In ICML, 2020.
Francesco Locatello, Gabriele Abbati, Thomas Rainforth, Stefan Bauer, Bernhard Scholkopf, and
Olivier Bachem. On the fairness of disentangled representations. In NeurIPS, pp. 14611-14624,
2019a.
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Scholkopf,
and Olivier Bachem. Challenging common assumptions in the unsupervised learning of disentan-
gled representations. In ICML, pp. 4114-4124, 2019b.
Emile Mathieu, Tom Rainforth, N Siddharth, and Yee Whye Teh. Disentangling disentanglement in
variational autoencoders. In ICML, pp. 4402-4412, 2019.
Willard Miller. Symmetry groups and their applications. Academic Press, 1973.
Alexander McFarlane Mood. Introduction to the Theory of Statistics. McGraw-hill, 1950.
XuanLong Nguyen, Martin J Wainwright, and Michael I Jordan. Estimating divergence functionals
and the likelihood ratio by convex risk minimization. IEEE Transactions on Information Theory,
56(11):5847-5861, 2010.
Emmy Noether. Der endlichkeitssatz der invarianten endlicher gruppen. Mathematische Annalen, 77
(1):89-92, 1915.
Matthew Painter, Adam Prugel-Bennett, and Jonathon Hare. Linear disentangled representations and
unsupervised action estimation. NeurIPS, 33, 2020.
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in
pytorch. NeurIPS 2017 workshop, 2017.
David Pfau, Irina Higgins, Alex Botev, and SebaStien RaCaniere. Disentangling by subspace diffusion.
NeurIPS, 33, 2020.
Robin Quessard, Thomas D Barrett, and William R Clements. Learning group structure and disentan-
gled representations of dynamical environments. arXiv preprint arXiv:2002.06991, 2020.
Scott E. Reed, Yi Zhang, Yuting Zhang, and Honglak Lee. Deep visual analogy-making. In NeurIPS,
2015.
11
Published as a conference paper at ICLR 2022
Danilo Jimenez Rezende and Fabio Viola. Taming vaes. arXiv preprint arXiv:1810.00597, 2018.
Huajie Shao, Shuochao Yao, Dachun Sun, Aston Zhang, Shengzhong Liu, Dongxin Liu, Jun Wang,
and Tarek Abdelzaher. Controlvae: Controllable variational autoencoder. In International Confer-
ence on Machine Learning, pp. 8655-8664. PMLR, 2020.
Akash Srivastava, Yamini Bansal, Yukun Ding, Cole Hurwitz, Kai Xu, Bernhard Egger, Prasanna
Sattigeri, Josh Tenenbaum, David D Cox, and Dan Gutfreund. Improving the reconstruction of
disentangled representation learners via multi-stage modelling. arXiv preprint arXiv:2010.13187,
2020.
Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. Density-ratio matching under the bregman
divergence: a unified framework of density-ratio estimation. Annals of the Institute of Statistical
Mathematics, 64(5):1009-1044, 2012.
Raphael Suter, Djordje Miladinovic, Bernhard Scholkopf, and Stefan Bauer. Robustly disentangled
causal mechanisms: Validating deep representations for interventional robustness. In ICML, pp.
6056-6065. PMLR, 2019.
Sjoerd Van Steenkiste, Francesco Locatello, Jurgen Schmidhuber, and Olivier Bachem. Are dis-
entangled representations helpful for abstract visual reasoning? In NeurIPS, pp. 14245-14258,
2019.
Satosi Watanabe. Information theoretical analysis of multivariate correlation. IBM Journal of research
and development, 4(1):66-82, 1960.
Nicholas Watters, Loic Matthey, Christopher P Burgess, and Alexander Lerchner. Spatial broadcast
decoder: A simple architecture for learning disentangled representations in vaes. arXiv preprint
arXiv:1901.07017, 2019.
Xinqi Zhu, Chang Xu, and Dacheng Tao. Commutative lie group vae for disentanglement learning.
arXiv preprint arXiv:2106.03375, 2021.
Yang Zou, Xiaodong Yang, Zhiding Yu, BVK Kumar, and Jan Kautz. Joint disentangling and
adaptation for cross-domain person re-identification. In ECCV, 2020.
12
Published as a conference paper at ICLR 2022
A Preliminaries
Group: A set G together with a binary operation ◦ as: ◦ : G × G → G satisfying the following
properties:
•	Associativity: ∀a, b, c ∈ G, s.t.(a ◦ b) ◦ c = a ◦ (b ◦ c).
•	Identity: ∃ e ∈ G, s.t. ∀ a ∈ G, e ◦ a = a ◦ e = a.
•	Inverse: ∀ a ∈ G, ∃ a-1 ∈ G : a ◦ a-1 = a-1 ◦ a = e.
It is customary to represent a group with a set G and the binary operation ◦ as a pair (G, ◦). When
the binary operation is clear, we represent group (G, ◦) as G and use multiplication to represent the
binary operation ◦, i.e., a ◦ b = ab, ∀ a, b ∈ G.
Group Action: Let (G, ◦) be a group and P be a set. By the group actions of (G, ◦) on P, we mean a
mapping:
・P : G X P → P,	(6)
such that
•	∀a, b ∈ G,p ∈ P, (a ◦ b) ∙ P = a ∙ (b ∙ p).
•	e ∙ p = p, where e is the identity element of G.
Symmetry Group and Permutation Group: Let Σ be a nonempty set, the bijections from Σ to itself
are called Permutations. S(Σ) denotes the set containing all the permutations on Σ. S(Σ) forms a
group under the binary operation: composition of functions, which is called Symmetry Group. A
subgroup of S(Σ) is called Permutation Group.
Abelian Group: If the commutative law (∀ a, b ∈ G, a ◦ b = b ◦ a) holds in a group (G, ◦), such a
group is called an abelian group.
Subgroup: If a subset H of a group G is itself a group under the operation of G, we say that H is a
subgroup of G.
Figure 6: 4-th Dihedral Group (D4): The groups of symmetries for square. Note that permutation
(123) means 1 → 2,2 → 3, 3 → 1.
(12)(34) =产 N	(13) = ∕iγ3
Equivalence Relation: An equivalence relation on a set B is a subset U ⊂ B × B satisfying: (It is
customary to represent (a, b) ∈ U as a 〜b)
•	Reflexive: ∀ a ∈ B, (a, a) ∈ U.
•	Symmetric: (a, b) ∈ U q⇒ (b, a) ∈ U.
•	Transitive: (a, b) ∈ U and (b, c) ∈ U ⇒ (a, c) ∈ U.
13
Published as a conference paper at ICLR 2022
Equivalence Class: Let 〜be an equivalence relation on a set B. We take an a ∈ B, and then the
equivalence class containing a is the subset a = {b ∈ C|b 〜a} ⊂ B.
Homomorphism Let (G, ∙) and (H, Q) be two groups. A homomorphism f, from G to H, is a
mapping f : G → H, such that f (X ∙ y) = f (x) ◦ f (y), ∀x, y ∈ G.
Isomorphism: A homomorphism f : G → H which is bijective is called an isomorphism. Two
groups are said to be isomorphic if there exists an isomorphism between them.
Related Groups:
(i)	Additive group of integers modulo n: Let n denote a positive integer. We define an equivalence
relation on Z as a 〜b ⇔ a = b (mod n) (a and b have the same remainder modulo n). The relation
divides Z into n equivalent classes: 0,1,...,n — Lwhere i represents the equivalent class containing
i, i.e., i = {m ∈ Z|m = i (mod n)}. Let Zn = {0,1,...,n 一 1}, and Zn forms a group under the
binary operation: a + b = a + b, denoted by Z/nZ.
(ii)	Group of n-th root unity: Let n denote a positive integer and Cn = {e^πnia |0 ≤ a ≤ n 一 1, a ∈
Z} be n roots of xn = 1, and then Cn forms a group under complex multiplication. For the mapping:
f : Cn → (Zn, 十) defined by f (e2i~) = a, we have
2 2πia	2πib、	2 2ni(a + b)、	-----	_ —	2 2πia、	2 2πib
f I e n ∙ e n i = f I e n l = a + b = a + b = f l e n ι ∙ f l e n
(7)
Therefore, f is a homomorphism, and thus is an isomorphism.
Congruence Class: Let n denote a positive integer, and we define an equivalence relation on Z as
a 〜b ⇔ a = b (mod n). The relation divides Z into n equivalent classes: 0,1,...,n — 1, which
are congruence classes and the elements of the additive group of integers modulo n.
Subgroup Generated by B: If B is a nonempty subset of the group (G, ◦), the set defined by
< B >= {a ∈ G|a = aι ◦ a2 ◦•••◦ anι with either a% ∈ B or a-1 ∈ B} forms a subgroup of G,
which is called the subgroup generated by B, e.g., G =< a, b|a2 = e, ab = ba > in the toy example
of Section 1. Here a1, . . . an are called Generators, e.g., a, b in G.
Cyclic Group A group G is called cyclic if there is an element a ∈ G such that G = {an|n ∈ Z} =<
a >, e.g., Z/nZ. Such an element a is called a generator of G.
Symmetry: A symmetry of a geometric figure is a rearrangement of the figure preserving the
arrangement of its sides and vertices as well as its distances and angles.
Dihedral Group: The permutation group formed by the symmetries of a regular n-sided polygon,
denoted by Dn .
D4 as an example: The vertices of a square are numbered by {1, 2, 3, 4}, which is analogous to
an image dataset, the symmetries are analogous to image transformations. We often abbreviate
permutation 1 → 2, 2 → 3, 3 → 4, 4 → 1 as (1234). The elements of group D4 are shown in Figure
6, from which we know that all of the transformations are compounded by two basic permutations:
horizontal flip f and rotate 90 degrees clockwise r. Please note that f and r are analogous to
disentangled factors. What’s more, the Group can be generated by these basic permutations f, r with
some properties, i.e., D4 =< f, r|f2 = 1, r4 = 1, fr = r-1f >. The constraints f2 = 1, r4 =
1, fr = r-1f are analogous to the group constraints in this paper.
B Proof for Theorem 1
In our setting, the group-based definition is equivalent to the equivariant condition g ∙ f (W) = f (g ∙ W)
for the following reason. Since the group actions of G on Z is the element wise addition, (a) the
group action of G on Z exists and (b) group actions of Gi only affect Zi (refer to Section 3.2). These
two conditions of the group-based definition thus hold.
Proof. In the following, we prove in Step 1 that the necessary and sufficient conditions of Φ playing
the “agent” role , i.e., f (g ∙ W) = h(夕∙ b(w)), are (i) Φ is isomorphic to G, and (ii) there exist
夕i ∈ Φ, s.t.夕i ∙ b(w) = b(gi ∙ w), i = 1,2,...,m. We then prove in Step 2 that if equation
f (g ∙ W) = h(φ ∙ b(w)) and the definition of 夕 ∈ Φ hold, then Z is disentangled per group-based
definition.
14
Published as a conference paper at ICLR 2022
Step 1: In the following, we prove that the necessary and sufficient conditions of f (g∙w) = h(夕∙b(w))
are (i) and (ii) above. Note that this holds even without a specific definition of Φ.
⇒) For a general permutation group Φ on O, We assume there exist 中i such that ψi ∙ b(w)=
b(gi ∙ w),i = 1,2,...,m. Assume that there exists an isomorphism T : G → Φ, where group
G = (Z∕nZ)m. From Group Theory, we know that there exists μ ∈ Aut(Φ) such that the following
equation holds, where Aut(Φ) denotes the group of automorphisms of Φ, i.e., μ is an isomorphism
μ : Φ → Φ. We denote the composition of μ, T as σ, and have
σ(gi) = μ(τ(gi))=2i, i = 1, 2,...,m.	(8)
Since we have 夕i ∙ b(w) = b(gi ∙ w), i = 1,2,...,m, the following equation holds,
σ(gi) ∙ b(w)=2i ∙ b(w) = b(gi ∙ w), i = 1, 2,...,m.	(9)
Since both μ, T are isomorphism, σ = μ ◦ T is also an isomorphism, which indicates that ψi is
a generator of Φ. For ∀夕 ∈ Φ, since σ is a bijection, there exists g ∈ G = (Z∕nZ)m, such that
σ(g)=2 and g = Pi kigi, k ∈ Z, where gi,i = 1,2,...,m denotes the generators in G. In order
to calculate 夕∙ b(w), we consider a specific example σ(gι + g2).
σ(gι +g2)∙b(w) = σ(g1)∙(σ(g2)∙b(w)) = σ(g1)∙b(g2∙w) = b(g1∙(g2∙w)) = b((gι +g2)∙w). (10)
Therefore, for the general element 夕，we have
夕∙ b(w) =。(£ kigi) ∙ b(w) = b(£ kigi ∙ W) = b(g ∙ w).	(11)
ii
In general, we have 夕∙ b(w) = b(g ∙ W) and thus we have h ◦ b(g ∙ W) = f (g ∙ W) = h(夕∙ b(w))
when taking h on both sides.
U) Here we prove that (i) G is isomorphic to Φ and (ii) there exists ψi such that ψi ∙ b(w) =
b(gi ∙ w),i = 1, 2,...,m are two necessary conditions of equation f (g ∙ w) = h(夕∙ b(w)) = h(夕∙ x).
We take f T on both sides of the equation. For convenience, we rewrite g ∙ w,夕∙ b(w) as g(w) and
夕(b(w)), then we have
g(w) = f-1 ◦ h ◦ φ ◦ b(w) = b-1 ◦ φ ◦ b(w).	(12)
Note that the notation ◦ here denotes the composition of functions. We define the mapping T between
Φ and G as follows:
τ(¢) = g = b-1 ◦ φ ◦ b.	(13)
Note that b is a bijection, thus T is a bijection. We take 夕i, Wj ∈ Φ and we have
τ(Wi ◦ Wj) = b-1 ◦ Wi ◦ Wj ◦ b
= (b-1 ◦ Wi ◦ b) ◦ (b-1 ◦ Wj ◦ b)	(14)
= T(Wi) ◦ T(Wj).
Therefore, T is a homomorphism and thus is an isomorphism. i.e., Φ is isomorphic to G. Recall that
group G has the form of G = (Z/nZ)m, where it is a direct product of m cyclic groups. For ∀W ∈ Φ,
we have
W ∙ b(w) = h-1 ◦ f (g(w)) = b(g(w)).	(15)
For generators gi ∈ G, i = 1, 2, . . . , m and the corresponding Wi = T-1(gi), we have a specific one
derived from the above equation:
Wi ∙ b(w) = b(gi(w)) = b(gi ∙ w).	(16)
Q.E.D.
Step 2: As discussed in Section 1 and Section 3, we define W as W ∙ X = W ∙ b(w) = h-1(σ-1(W) ∙
h(x)) = h-1(g ∙ f (w)), where σ isthe same as in Step 1. Since σ is a bijection, for ∀w ∈ Φ, σ-1(W)
uniquely exists, and thus W is well-defined. We bring it into f (g ∙ w) = h(W ∙ b(w)), and derive
f (g ∙ w) = g ∙ f (w), i.e.,the representation space Z is disentangled with respect to G. Specifically, for
the existing Wi, i = 1, 2,...,m, from equation 8, we have σ-1(Wi) = gi and Wi ∙ X = h-1(gi ∙ f (w)).
Q.E.D.
15
Published as a conference paper at ICLR 2022
C	Proof for Theorem 2
In order to easily distinguish a general element and a generator, we use φ to stand for the general
element in Φ and ψi to stand for generators in Φ. In addition, for mapping T : G → Φ, notation
ker(τ) is generally the inverse image of e, i.e., ker(τ) = {g ∈ G∣τ(g) = e}, where e is the identity
element in Φ.
Proof. Note that Section 3.4 describes the implementation of the elements in Φ, but there is no guaran-
tee that Φ is a group. Therefore, here we first prove in Step 1 that set Φ =< 夕 1,夕2,..., ψm∣ψi夕j =
Wj ψi, φn = e, i = 1,2,...,m and j = 1, 2,...,m > forms a group under the composition of
functions, where e satisfies that eψi = Wi, then prove in Step 2 the necessary and sufficient condition
for the isomorphism is to meet both the Abel constraint and the Order constraint.
Step 1: To prove a set forms a group under some operation, we only need to verify that the elements
of the set satisfy the following three properties: 1. Associativity 2. Identity 3. Inverse.
1.	We first verify the Associativity property: ∀ φs, φt, Wl ∈ Φ, s.t. (φsφt)φl = φs(φtφl).
Recall that in Section 3.2, the representation space is a set with the same elements in G. The
group action of G on Z is the addition. We have g ∙ Z ∈ Z, ∀g ∈ G,z ∈ Z, and then we have
d(g ∙ Z) ∈ O, ∀g ∈ G,z ∈ Z. Therefore, Wi is a permutation: Wi : O → O, i.e., Wi ∈ S(O), where
S(O) is the symmetry group on images set O, then for ∀Wi, Wj, Wk ∈ {W1, W2, . . . Wm}, we have
(WiWj)Wk = Wi(WjWk),	(17)
the generators of Φ thus satisfy the Associativity property. However, whether the general elements of
Φ satisfy the Associativity property is unknown. We take ∀ φs, φt, φl ∈ Φ, where φt = Qi Witi , φs =
Qi Wisi, φl = Qi Wlii andti,si, li ∈ Z, and we have
(φtφs)φl =	YWiti	YWisi	YWlii	= YWiti	YWisi	YWlii	=	φt(φsφl).	(18)
Therefore, the set of mappings Φ satisfies the Associativity property under the composition of
functions.
2.	We then verify the Identity property: ∃ e ∈ Φ, s.t. ∀ φ ∈ Φ, eφ = φe = φ.
For generators Wi, Wj ∈ {W1, W2, . . . Wm} , we have WinWj = eWj = Wj. Therefore, for general
elements, we take ∀φ ∈ Φ, φ = Qi Wiki, and we have:
Winφ = eYWiki	=	(eWj)Wjkj-1	Y	Wiki	=	Wjkj	Y	Wiki	= YWiki	= φ. (19)
i	i{i6=j}	i{i6=j}	i
This states that the identity element of Φ is e = Win ∈ Φ. Therefore, the set of mappings Φ satisfies
the Identity property.
3.	We finally verify the Inverse property: ∀ φ ∈ Φ, ∃ φ-1 ∈ G : φφ-1 = φ-1φ = e.
For the generators Wi ∈ {W1, W2, . . . Wm}, we have WikWin-k = Win = e, 1 ≤ k ≤ n, k ∈ Z. For any
general element φ ∈ Φ, φ = Qi Wiki, we have:
φ Y Wn-ki = Y Wki(Wkj Wn-kj) Y Wn-ki =…=e,	QO)
i	i{i6=j}	i{i6=j}
we denote Qi Win-ki as φ-1 and have φφ-1 = e. Similarly, we also have φ-1φ = e. These
two equations state that for any general element φ ∈ Φ, φ = Qi Wiki, we have an inverse element
φ-1 = Qi Win-ki in Φ. Therefore, the set of mappings Φ satisfies the Inverse property.
To summarize, Φ is a group.
Q.E.D.
Step 2: In this step, we prove that the necessary and sufficient condition for the isomorphism
(Z∕nZ)m 〜< W1,W2,..., Wm > is the satisfaction of WiWj = WjWi, i = 1, 2,...,m and j =
1, 2, . . . , m, and Win = e, i = 1, 2, . . . , m.
16
Published as a conference paper at ICLR 2022
⇒) Assume the isomorphism is T : G = (Z∕nZ)m → Φ =< 夕 1,夕2,...,夕m >, for generators
ψi,ψj ∈ {2 1,夕2,...ψm}, there exist gα = Pi aigi,gg = Pi βigi ∈ G, s.t.τ(gɑ)=2i,τ(gβ)=
ψj, where gi,i = 1,2,...,m denotes the generators in G, which is the m-dimenSiOnal one-hot vector
(0,..., 1,..., 0) ∈ G with 1 in position i and 0 elsewhere, and ai, βi ∈ Z. Since G is an Abelian
group, we have
ψi Wj = T (gɑ)τ (gβ ) = T (gɑgβ ) = T (gβ gα ) = T (g β )τ (gα) = Wj 中 i∙	QI)
For generators Wi ∈ {W1,W2,... Wm}, We have ga = Ei αigi ∈ G, s.t. T(ga) = Wi, the n times
composition of itself is
Win = T(gα)n = T(ngα) = T(	αingi) = T(	αieG) = T(eG) = e,	(22)
ii
where eG, e are identity elements of G and Φ respectively. In Equation 22, T(eG) = e holds because
T is an isomorphism, and ker(T) = {eG}. The sufficiency is proven.
U) In the following, We prove that when two conditions are satisfied simultaneously, the mapping T
we define is an isomorphism. Considering the mapping T : Φ → G, defined as
T : Wi 7→ gi;
T : WiWj 7→ gi + gj.
(23)
For general elements φt, φs ∈ Φ, where φt = Qi Witi, φs = Qi Wisi and ti, si ∈ Z, we have
T(φtφs) = T YWiti YWisi = T YWiti+si = X(ti + si)gi.	(24)
Note that these terms can be merged since WiWj = Wj Wi . The summation on the right side of
Equation 24 is partitioned into two parts as follows
X(ti + si)gi = Xtigi + Xsigi = T Y Witi +T Y Wisi = T(φt) + T(φs).	(25)
Consequently, we have T(φtφs) = T(φt) + T(φs), which states that T is a homomorphism. Then, we
only need to prove that mapping T is bijective. First, we prove T is injective, i.e., ker(T) = {eG},
after that, we prove T is surjective, i.e., one can find the inverse image of any element.
Since it is not hard to obtain T(φ) = T(e ∙ φ) = T(e) + T(φ), we have T(e) = (0,..., 0) = eg, i.e.,
e ∈ T-1(eG). Assume there is φl = Qi Wlii, s.t. T(φl) = eG, we have
T (φl ) = X ligi = eG ⇒ li |n (li are divisible by n) ⇒ φl = Y Wii = Y e = e. (26)
i	ii
The equation above states that T-1(eG) = {e} (T : Φ → Φ) and mapping T is injective. We take
∀g ∈ G, g = (k1,k1,..., km) ∈ (Z∕nZ)m, and have
g = (k1,..., 0) +----H0,..∙, km) = X kigi = T (Y Wki) .	(27)
Hence, we have T -1(g) = Qi Wiki ∈ Φ, which indicates that mapping T is surjective. Since mapping
T is bijective and homomorphism, T is an isomorphism.
Q.E.D.
D	Proof for Theorem 3
Proof. In the following, we prove that the necessary and sufficient condition for satisfying Abel and
Order constraints is that both Abel and Order Loss are minimized.
⇒) For the condition: ∀ Wi, Wj ∈ Φ, 0 ≤ i, j ≤ m, we have WiWj = WjWi. The constraint on any
image o ∈ O can be obtained by
Wi(Wj (o)) = Wj (Wi(o)) ⇒ Wi(Wj (o)) - Wj(Wi(o)) = 0.	(28)
17
Published as a conference paper at ICLR 2022
For the set of combinations of factors C = {(i,j)|1 ≤ i,j ≤ m} and the set containing images O,
we have
La=	Ilgi •(夕j ∙ o) - ψj ∙ (ψi ∙ o)k is minimized.	(29)
o∈O (i,j)∈C
We obtain the Abel loss. For the Order loss, we first consider n times composition of the same
mapping gi , we have
gin = e ⇒ gin-1gi = gigin-1 = e.	(30)
Therefore, we then have gi-1 = gin-1. For a single image o ∈ O, we have
gi(gin-1(o)) = gi(gi-1(o)) = o ⇒ gi(gi-1(o)) - o = 0.	(31)
Thus, for the set of factors and the set containing all images O, we have
XX
kgi ∙(夕-1 ∙ o) — o∣ is minimized.	(32)
o∈O 0≤i≤m
To eliminate the bias of optimization, we optimize the symmetry form of the Order Loss, and we have
Lo = XX (k" W-1 ∙ o) - ok + kψ-1 ∙ (ψi ∙ o)- ok) isOPtimized.	(33)
o∈O 0≤i≤m
The Order Loss is obtained.
U)When the Abel Loss La is optimized, for ∀ o ∈ O, We have
gi(gj(o)) - gj(gi(o)) = 0 ⇒ gi(g(o)) = gj (gi(o)).	(34)
Therefore, for ∀gi, gj ∈ Φ, i = 1, 2, . . . , m and j = 1, 2, . . . , m, We have gigj = gjgi, and We
obtain the Abel constraint. When the Order Loss Lo is minimized, for ∀ o ∈ O, We have
gi(gi-1(o)) - o = 0 ⇒ gi(gi-1(o)) = o.	(35)
This implies that
gin = gi ◦ gin-1 = gi ◦ gi-1 = e.	(36)
Therefore, We obtain the Order constraint. The Group constraints are satisfied.
18
Published as a conference paper at ICLR 2022
E The Data Constraint
In this section, we prove that if each dimension of the world state is independently sampled (p(w) =
Πip(wi), where p denotes the probability mass function (for discrete random variable) or probability
density function (for continuous random variable)), then the minimization of total correlation (p(z) =
Πip(zi)) is a necessary condition to satisfy the data constraint (see Theorem 4 and Theorem 5 below).
Our goal is to learn a representation z conforming to the group-based definition of disentanglement
with an encoder h and a decoder d. Then the data constraint can be formulated as follows. For a
generator gi ∈ G, We have b(gi ∙ W)= 夕i ∙ b(w) = h-1(gi ∙ z), where Z = f (W) and ψi is the
corresponding permutation of gi under the isomorphism between G and Φ. We reorganize the formula
and have h ◦ b(gi ∙ W) = f (gi ∙ W)= gi ∙ z.
Theorem 4 Assume that the action ofgenerator gi on Z is gi ∙ Z = z + gi (element-wise addition),
and the action of each generator gi on W only affects a single dimension of W (see the assumptions in
Section 3.2). Then the equation f (gi ∙ W)= gi ∙ z, ∀w ∈ W is equivalent to: for each i = 1, 2,...,n,
there exists a bijective function γi s.t. zi = γi(Wj) for some j.
Proof. ⇒) Without loss of generality, we assume gi only affects the j-th dimension of W. If the
equation f (gi ∙ W)= gi ∙ z, ∀w ∈ W holds, it's obvious that, for each i, there exists a bijective
function γi s.t. zi = γi (Wj ).
^) In the following, weuse (gi ∙ w) ((gi ∙ z)i) to denote the i-th dimension of vector gi ∙ W (gi ∙ z). If
for i = 1, . . . , n, the functions zi = γi(Wj) hold for some j, by using an index permutation j = π(i)
we can rewrite the function as zi = γi (Wπ(i)). Therefore, z can be formulated as follows
f(W1, . . . , Wn) = z = (z1, . . . , zn) = (γ1 (Wπ(1)), . . . ,γn(Wπ(n))).	(37)
Please note that how the world state transits on dimension i dose not affect how disentangled the
representation is. Therefore, we define action of generator gi on W as follows.
gi ∙ W = gi ∙ (Wl,...,Wn) = (wi,..., (gi ∙ W)j ,...,Wn) = (wi,...,Y-'((gi ∙ z)),...,Wn), (38)
Then, we take f on both sides of the above equation, and apply Equation 37, and have
f (gi ∙	w)	= f (w1, ...,γ-1((gi	∙	z)i), ...,Wn)	=	(YI(Wn(1)), ...,Yi(γ-1((gi	∙	z)i)),..∙,Yn(W∏(n)))
=(zi,...,(gi ∙ z)i,...,Zn) = gi ∙ Z
(39)
Q.E.D.
Note that it is obvious that the following theorem (Theorem 5) holds for discrete random variables
and bijective functions. However, since the world state space is dense and the encoder h and decoder
d are differentiable in general, we also prove for the case where W and z are treated as continuous
random variables. Theorem 5 states that the minimization of total correlation (p(z) = Πip(zi)) is a
necessary condition to make equations zi = Yi (Wπ(i)) satisfied, where i = 1, 2, . . . , n and π(i) is an
index permutation.
Theorem 5 For the independent random variables W1 , W2 , . . . , Wn, considering the functions zi =
δi(W1, W2, . . . , Wn), where i = 1, 2, . . . , n and each δi is a bijective, differentiable function. For
i = 1,...,n, ifthere exists an index permutation π(i) s.t., we have dfWi^ = 0 and dz詈 =0, where
k = 1, 2 . . . , n but k 6= i, then the new random variables z1, z2, . . . , zn are independent.
Proof. We treat the random variables W1 , W2 , . . . , Wn as an n-dimensional random vector W =
(W1, W2, . . . , Wn). Similarly, we write Z = (zπ(1), zπ(2), . . . , zπ(n)) , which is rearranged by index
permutation π(i). According to Change of Variable Theorem For Random Vectors (Mood, 1950), we
have
p(Z)|J(W)| = p(W) =Πip(Wi)	(40)
where J(W) is the jacobian matrix of Z w.r.t. W, the (i,j)-th entry of it is d∂wi). Since for each
i = 1,...,n,we have dz∏(i) = 0 and dz∏(i) = 0, where k = 1,2 ...,n but k = i, then the jacobian
∂wi	∂wk
19
Published as a conference paper at ICLR 2022
matrix can be formulated as follows
J (W…筌L
According to Change of Variable Theorem For Random Variable ( Mood (1950)), we have
(41)
P(z∏(i))1 .π(" | = P(Wi)	(42)
∂wi
Bring Equation 41 and Equation 42 into Equation 40, we have
πiP(Wi)	πip(Znei))πi | ~∂(λ |
P(Z) = π 产⑸ | = ~π 产(i) |---------------= πip(z∏(i)) = nip(zi)	(43)
Q.E.D.
Please note that the inverse proposition of the theorem above does not hold. As a counterexample, for
zero mean independent gaussian random variables w1,w2 with common variance σ2, new random
variables zι = W2+ + w22 (the norm of vector (w1,w2)), z2 = tan-1(w2∕w1) (the angle between
vector (wι, w2) and (0,1)) are independent (Mood, 1950) but ddwi = 0 for all i,j ∈ {1,2}. In
addition, the sufficiency would be satisfied for some specific settings, e.g., there are only two
independent uniformly distributed random variables w1, w2, and the functions z1, z2 are linear
functions.
Combining Theorems 4 and 5, we have that the minimization of total correlation (P(z) = ΠiP(zi)) is
a necessary condition to satisfy the data constraint.
F	Details of Implementation
F.1 Abel Loss Details
As mentioned in the main paper, the Abel Loss of the VAE-based models is as follows:
La = XX	k。•(夕j	∙	O)- Ψj	∙	(Ψi	∙	O) k,	(44)
o∈O (i,j)∈C
where 夕i ∙(夕j ∙ o)= 夕i(夕j(o)) represents the top path of Figure 7 (a), and 夕j ∙(夕i ∙ o) = Wj(夕i(o))
represents the bottom path of Figure 7 (a). For better optimization, we constrain such consistency on
their representation (straight dotted double arrow in Figure 7 (a)) instead of the reconstructed images.
Besides, we constrain the consistency between the representations of intermediate images (curved
dotted double arrow in Figure 7 (a)).
+9i
(a) Abel Loss
Figure 7: Overview of the Isomorphism Loss. The Abel Loss and Order Loss constrain the commuta-
tivity and cyclicity of permutation group Φ, respectively. The dotted lines in the figure represents
reconstruction loss.
F.2 Order Loss Details
(b) Order Loss
As mentioned in the main paper, the Order Loss of VAE-based models is as follows:
Lo = XX(IS ∙ (w-1 ∙o)-ok + kw-1 ∙ (Wi ∙O)-Ok),	(45)
o∈O i∈I
20
Published as a conference paper at ICLR 2022
where 夕i ∙(夕-1 ∙ o) represents the lower path of Figure 7 (b), and 夕-1 •(夕i ∙ o) represents the
upper path of Figure 7 (b). Similar to the Abel Loss, we do not constrain such consistency on the
reconstructed images for better optimization but on their representations instead (the long curved
dotted line in Figure 7 (b)). Besides, we constrain the consistency between the representations of
intermediate images (short curved dotted lines in Figure 7 (b)).
F.3 THE NUMBER OF FACTORS m
For the given VAE-based models, dimensional KL divergence (indicating the meaningful dimensions)
increases during the training process. Therefore, we use m dimensions of which the corresponding
dimensional KL divergence KLi ≥ T, where T is a hyperparameter, which is empirically set to 30
in our experiments.
21
Published as a conference paper at ICLR 2022
G Details of Experiments
G.	1 Dataset details
In all the experiments, we resize the images to 64 × 64 resolution. We introduce all the datasets used
in our paper in detail.
dSprites Higgins et al. (2017): dSprites contains 737,280 binary 2D shapes (heart, oval and square)
images with five ground truth factors: shape (3 values), scale (6 values), orientation (40 values),
x-position (32 values), y-position (32 values). Then we introduce the variants of dSprites (Color
dSprites and Noisy dSprites) created by Locatello et al. Locatello et al. (2019b).
Color dSprites, the shapes of the images in dSprites are randomly colored.
Noisy dSprites, the background of the images in dSprites is noise.
Shapes3D Kim & Mnih (2018): Shapes3D contains 480,000 images of 3D shapes with 6 ground
truth factors: shape (4 values), scale (8 values), orientation (15 values), floor color (10 values), wall
color (15 values), object color (10 values).
Cars3D Reed et al. (2015): This dataset consists of 183 car CAD models, each rendered from 24
azimuth directions and 4 elevations.
Encoder	Decoder
Input: 64×64 × number of channels 4 × 4 conv, 32 ReLU, stride 2 4 × 4 conv, 32 ReLU, stride 2 4 × 4 conv, 32 ReLU, stride 2 4 × 4 conv, 32 ReLU, stride 2 FC 256 ReLU FC 256 ReLU FC 2× 10	Input: 10or20 FC, 256 ReLU FC, 256 ReLU FC, 4 × 4 × 32 ReLU 4 × 4 deconv, 32 ReLU, stride 2 4 × 4 deconv, 32 ReLU, stride 2 4 × 4 deconv, 32 ReLU, stride 2 4 × 4 deconv, number of channels, stride 2
Table 3: Architecture of the encoder and decoder of VAEs. For Original VAE, the dimension of input
of the decoder is 10. For Groupified VAE, the dimension is 20. Note that the number of representation
dimensions of Groupified VAE is still 10, which is the same as Original VAE, the comparison with
Original VAE is fair Watters et al. (2019).
G.2 Architecture for encoder and decoder
We follow Locatello et al. Locatello et al. (2019b) to use the same architecture of VAEs in all of the
experiments: the activation function used is ReLU except for the last layer of decoder, as shown in
Table 3. For the details of the Discriminator in FactorVAE, please refer to Table 5 (a) and (c).
Model	Parameter	Value
β-VAE		[10; 20; 30;]
AnnealedVAE	C	[10; 20; 30;]
	start	[3e4; 4e4; 5e4;]
	end	[2e4; 3e4; 4e4;]
FactorVAE	γ	[5; 10; 15]
β-TCVAE	β	[6; 9; 12]
	random seed	[1; 2; 3; 4; 5; 6; 7; 8; 9;]
	group	[True; False]
Table 4: Hyperparameters and random seeds for every model.
22
Published as a conference paper at ICLR 2022
(c) Architecture of Dis-
(a) Optimizer for Discriminator (b) General hyperparameters for VAE	criminator
Parameter	Values	Parameter	Values	Discriminator
Batch size	64	Batch size	64	FC, 1000 LReLU
Optimizer	Adam	Representation dimension	10	FC, 1000 LReLU
Adam: beta1	0.9	Optimizer	Adam	FC, 1000 LReLU
Adam: beta2	0.999	Adam: beta1	0.9	FC, 1000 LReLU
Adam: epsilon	1.0e-8	Adam: beta2	0.999	FC, 1000 LReLU
Adam: learning rate	0.0001	Adam: epsilon	1.0e-8	FC, 1000 LReLU
		Adam: learning rate	0.0001	FC, 2
		Decoder type	Bernoulli	
Table 5: Shared hyperparameters in all experiments. LReLU stands for leaky ReLU.
G.3 Experiment settings
We run using different hyperparameters and random seeds for every VAE-based model implemented
by Pytorch Paszke et al. (2017). As shown in Table 4, for β-VAE, we assign 3 choices for β and 10
random seeds for both the Original and Groupified VAEs: 3 × 10 × 2 = 60 settings for each dataset.
Similarly, we also assign 60 settings for FactorVAE and β-TCVAE. For AnnealVAE, we assign three
choices for C and 3 choices for the start and end pair, also assign 10 random seeds. In summary,
for all 5 datasets, we run (((3 × 10 × 2) × 3) + 3 × 3 × 10 × 2) × 5 = 1800 models. For other
hyperparameters, please refer to Table 5 (b).
H Relation to some previous works
H.	1 symmetry-based disentanglement
Caselles-DUPre et al. (2019) argue that the symmetry-based disentanglement requires interaction
with the environments. Specifically, for a given disentangled representation z w.r.t. a world with
some grouP action on W, there are multiPle other worlds (same world states and symmetry) of
a static dataset that have different grouP actions on each dimension of W . For those worlds, the
rePresentation z is not disentangled, Per the grouP-based definition. However, in our work, we do
not assume that a static dataset has a world equiPPed with some sPecific fixed grouP action on W in
advance, instead we use Permutation grouP Φ as an agent to learn a world with ProPer grouP actions.
For this learned world, there is only one rePresentation that satisfies the definition. Therefore, we
do not need an environment to Provide grouP actions on W to determine which world it is. Please
see our Proof in Theorem 1. In the testing Phase, since we inPut the images to the model directly
to derive their rePresentation, the disentanglement of the rePresentation does not rely on how the
world state transitions between each other (i.e., as a result of grouP actions on W). Therefore, our
framework can learn such a disentangled rePresentation without interaction with the environments.
H.2 Lie group VAE
Zhu et al. (2021) argue that the rePresentation sPace being a vector sPace is sub-oPtimal since it
requires the model to learn to discard different scales of variations. They ProPose to use lie grouP
as the rePresentation sPace instead and use Hessian Penalty to encourage disentanglement. Our
framework is comPlimentary to their ProPosed method. The lie grouP rePresentation can be aPPlied
to extend our framework. Here we leave it for future work. In addition, our ProPosed rePresentation
mapped by the sine and cosine function (exp((2πiz)∕n) for a real vector z) is also alie group.
23
Published as a conference paper at ICLR 2022
I More Quantitative Results and Score Distribution
I.1	Quantitative Results
The performance of the Original and Groupified VAEs on all five datasets is shown in Table 6. Our
method outperforms the original one on most of the datasets in terms of nearly all the metrics.
dSprits	DCI		BetaVAE		MIG		FactorVAE	
	Original	Groupified	Original	Groupified	Original	Groupified	Original	Groupified
β-VAE	0.23 ± 0.10	0.46 ± 0.085	0.75 ± 0.083	0.86 ± 0.051	0.14 ± 0.097	0.37 ± 0.089	0.51 ± 0.098	0.63 ± 0.089
AnnealVAE	0.28 ± 0.10	0.39 ± 0.056	0.84 ± 0.050	0.87 ± 0.0067	0.23 ± 0.10	0.34 ± 0.061	0.70 ± 0.094	0.68 ± 0.058
FactorVAE	0.38 ± 0.10	0.41 ± 0.074	0.89 ± 0.040	0.89 ± 0.020	0.27 ± 0.092	0.31 ± 0.061	0.74 ± 0.068	0.75 ± 0.075
β-TCVAE	0.35 ± 0.065	0.36 ± 0.11	0.86 ± 0.026	0.861 ± 0.038	0.17 ± 0.067	0.24 ± 0.093	0.68 ± 0.098	0.70 ± 0.098
Cars3d ______________DCI__________________________BetaVAE_________________________MG________________________FactorVAE
	Original	Groupified	Original	Groupified	Original	Groupified	Original	Groupified
β-VAE	0.18 ± 0.059	0.24 ± 0.041	0.99±1.6e-3	-1.0 ± 0.0-	0.071 ± 0.032	0.11 ± 0.032	0.81 ± 0.066	0.93 ± 0.034
AnnealVAE	0.22 ± 0.046	0.25 ± 0.046	0.99 ± 4e - 4	0.99 ± 1.5e - 4	0.074 ± 0.016	0.10 ± 0.014	0.82 ± 0.062	0.87 ± 0.028
FactorVAE	0.21 ± 0.054	0.25 ± 0.040	0.99 ± 1e-4	1.0 ± 0.0	0.098 ± 0.027	0.11 ± 0.033	0.90 ± 0.039	0.93 ± 0.034
β-TCVAE	0.24 ± 0.049	0.26 ± 0.046	1.0 ± 0.0	1.0 ± 0.0	0.10 ± 0.021	0.11 ± 0.033	0.88 ± 0.040	0.93 ± 0.034
Noisy	DCI	betaVAE	MIG	FactorVAE
dSprits	Original	Groupified	Original	Groupified	Original	Groupified	Original	Groupified
BetaVAE	0.056 ± 0.018	0.087 ± 0.051	0.624 ± 0.090	0.647 ± 0.055	0.030 ± 0.022	0.065 ± 0.055	0.355 ± 0.093	0.407 ± 0.071
Anneal VAE	0.053 ± 0.013	0.060 ± 0.022	0.631 ± 0.036	0.644 ± 0.031	0.035 ± 0.027	0.047 ± 0.032	0.434 ± 0.080	0.481 ± 0.087
FactorVAE	0.114 ± 0.062	0.099 ± 0.057	0.682 ± 0.081	0.684 ± 0.070	0.077 ± 0.046	0.066 ± 0.046	0.437 ± 0.098	0.468 ± 0.098
β-TCVAE	0.081 ± 0.036	0.111 ± 0.053	0.605 ± 0.053	0.635 ± 0.050	0.040 ± 0.030	0.068 ± 0.042	0.353 ± 0.091	0.431 ± 0.097
Shapes3d	DCI	BetaVAE	MIG	FactorVAE Original	^IGrOUPified	Original	,Groupified	Original	^IGrOUPified	Original	^IGrOUPified
β-VAE	0.44 ± 0.176	0.56 ± 0.10	0.91 ± 0.072	0.90 ± 0.045	0.28 ± 0.18	0.42 ± 0.15	0.82 ± 0.098	0.82 ± 0.043
AnnealVAE	0.52 ± 0.051	0.60 ± 0.078	0.82 ± 0.076	0.89 ± 0.086	0.48 ± 0.047	0.50 ± 0.052	0.75 ± 0.074	0.83 ± 0.066
FactorVAE	0.47 ± 0.10	0.49 ± 0.065	0.86 ± 0.055	0.80 ± 0.075	0.33 ± 0.13	0.43 ± 0.11	0.81 ± 0.056	0.79 ± 0.066
β-TCVAE	0.66 ± 0.10	0.72 ± 0.061	0.97 ± 0.039	0.96 ± 0.042	0.40 ± 0.18	0.47 ± 0.090	0.89 ± 0.064	0.90 ± 0.046
Color
DCI
betaVAE
MIG
FactorVAE
dSprits	Original	Groupified	Original	Groupified	Original	Groupified	Original	Groupified
BetaVAE	0.174 ± 0.097	0.328 ± 0.130	0.798 ± 0.094	0.844 ± 0.050	0.103 ± 0.058	0.243 ± 0.118	0.591 ± 0.148	0.648 ± 0.092
Anneal VAE	0.268 ± 0.103	0.337 ± 0.114	0.843 ± 0.038	0.856 ± 0.031	0.219 ± 0.084	0.252 ± 0.104	0.718 ± 0.065	0.692 ± 0.094
FactorVAE	0.294 ± 0.101	0.322 ± 0.104	0.861 ± 0.038	0.862 ± 0.029	0.203 ± 0.080	0.236 ± 0.091	0.739 ± 0.068	0.730 ± 0.080
β-TCVAE	0.338 ± 0.052	0.395 ± 0.082	0.876 ± 0.024	0.881 ± 0.031	0.169 ± 0.040	0.269 ± 0.090	0.711 ± 0.086	0.786 ± 0.050
Table 6: Performance (mean ± std) on different datasets and different models with different metrics.
We evaluate β-VAE, AnnealVAE, FactorVAE, and β-TCVAE on dSprites, Cars3d, Shapes3d, Noisy-
dSprites, and Color-dSprites for 1800 settings. These settings include different random seeds and
hyperparameters.
I.2	Abstract Reasoning & Fairness
As pointed out by Locatello et al. Locatello et al.
(2019b), the disentangled representation’s down-
stream tasks should also be verified. There-
fore, we verify the effectiveness of the repre-
sentations learned by the Groupified VAEs on
Shapes3d in two downstream tasks: abstract rea-
Abstract reasoning↑	Unfairness SCoreSJ
Original	0.948 ± 0.031	0.023 ± 0.007
Groupified	0.954 ± 0.028	0.018 ± 0.008
Table 7: Downstream task performance on the
models trained on the representation learned by
original and groupified FactorVAE.
soning Van Steenkiste et al. (2019) and fairness evaluation Locatello et al. (2019a). As Table 7
shows, the performance of the abstract reasoning models fine-tuned on the representation learned by
the Groupified FactorVAEs is better than the original ones. In terms of fairness evaluation, we can
observe that the unfairness scores of the representation learned by the Groupified FactorVAEs are
lower than the Original ones.
I.3	Score Distribution
The detailed distribution of the performance is shown in this section (demonstrated by the Violin
Plot Hintze & Nelson (1998)). The performance distributions on dSprits, Car3d, Noisy dSprites,
24
Published as a conference paper at ICLR 2022
Color-dSprites, and Shapes3d are shown in Figure 8, Figure 9, Figure 10, Figure 11 and Figure 12,
respectively.
I.4	Comparison with method interaction with the environment
Our work considers an unsupervised setting, which is a more practical one. To understand the price
to pay, we compare our unsupervised Groupified models to the methods that use the interaction with
the environment as supervision. Here we provide the comparison between RGrVAE (Painter et al.,
2020) and our Groupified β-TCVAE on dSprites, Shapes3D, and Color dSprites as shown in Table 8.
Datasets
dSprites
Shapes3D
Color dSprites
DCI		BetaVAE		MIG		FactorVAE	
RGrVAE	GroUPified	RGrVAE	Groupified	RGrVAE	Groupified	RGrVAE	Groupified
0.52 ± 0.058	0.36 ± 0.110	0.97 ± 0.039	0.86 ± 0.038	0.08 ± 0.042	0.24 ± 0.093	0.86 ± 0.073	0.70 ± 0.098
0.83 ± 0.056	0.72 ± 0.061	1.00 ± 0.000	0.96 ± 0.042	0.25 ± 0.031	0.47 ± 0.090	0.98 ± 0.032	0.90 ± 0.046
0.11 ± 0.072	0.40 ± 0.082	0.53 ± 0.294	0.88 ± 0.031	0.03 ± 0.028	0.27 ± 0.090	0.31 ± 0.309	0.79 ± 0.050
Table 8: Performance (mean ± variance) on different datasets of RGrVAE and Groupified β-TCVAE
with different metrics. These settings include different random seeds and hyperparameters.
Since there are no results reported on Shapes3D and Color dSprites, we conduct experiments on
these two datasets with the official implementation2 using the recommended hyper-parameters. In
addition, the results reported in Painter et al. (2020) are of models trained with 16 latent units and
3 random seeds. We also conduct experiments on dSprites with 10 latent units and 10 random
seeds, which is our setting. From Table 8, we observe that there is still a gap between RGrVAE and
Groupified β-TCVAE, especially on Shapes3D. However, the latent learned by RGrVAE is not as
pure as Groupified β-TCVAE (lower MIG). Additionally, RGrVAE performs poorly because a factor
(color) is not modeled in the environment of Color dSprites.
I.5	Comparison with ControlVAE
In this section, we provide a comparison between Original and Groupified ControlVAE (Shao
et al., 2020). For ControlVAE, we use the official implementation3 and follow the default setting,
Cmax = 25. We follow Locatello et al. (2019b) to set the hyperparameter interval to 10. For other
parameters, we follow Shao et al. (2020). The results on dSprites, Shapes3D, and Color dSprites are
presented in Table 9.
Datasets
DCI
BetaVAE
MIG
FactorVAE
	Original	Groupified	Original	Groupified	Original	Groupified	I Original	Groupified
dSprites	0.31 ± 0.093	0.46 ± 0.115	0.83 ± 0.084	0.92 ± 0.061	0.16 ± 0.062	0.27 ± 0.123	0.62 ± 0.087	0.74 ± 0.110
Shapes3D	0.59 ± 0.144	0.85 ± 0.165	0.86 ± 0.142	0.97 ± 0.149	0.21 ± 0.212	0.72 ± 0.151	0.59 ± 0.174	0.88 ± 0.171
Color dSprites	0.47 ± 0.111	0.54 ± 0.055	0.94 ± 0.045	0.96 ± 0.024	0.28 ± 0.095	0.35 ± 0.055	0.80 ± 0.070	0.84 ± 0.022
Table 9: Performance (mean ± variance) on different datasets of ControlVAE and Groupified Con-
trolVAE with different metrics. These settings include different random seeds and hyperparameters.
From Table 9, we observe that our method consistently improved the performance of ControlVAE
under the same hyper-parameters, especially on Shapes3D.
I.6	Detailed results under different hyper-parameters
In order to provide a more convincing comparison, we compare our method and the original one at
different levels of regularization parameters. We take β-TCVAE as an example. As Table 10, 11, and
12 show, our method consistently improves the performance of the original methods on most of the
metrics, especially on MIG and DCI.
2
https://github.com/MattPainter01/UnsupervisedActionEstimation
3
https://github.com/shj1987/ControlVAE- ICML2020
25
Published as a conference paper at ICLR 2022
Regulize strength	DCI	BetaVAE	MIG	FactorVAE Original	.Groupified	Original .Groupified	Original .Groupified	Original	.Groupified
β=6 β=9 β=12	0.33 ± 0.079	0.34 ± 0.106	0.86 ± 0.025	0.85 ± 0.032	0.15 ±	0.042	0.20 ±	0.093	0.68	±	0.100	0.68	±	0.105 0.37 ± 0.051	0.36 ± 0.103	0.85 ± 0.028	0.87 ± 0.026	0.17 ±	0.053	0.24 ±	0.097	0.63	±	0.092	0.70	±	0.072 0.35 ± 0.057	0.38 ± 0.114	0.87 ± 0.024	0.86 ± 0.051	0.20 ±	0.071	0.30 ±	0.098	0.71	±	0.084	0.71	±	0.104
Table 10: Performance (mean ± variance) on dSprites of Original and Groupified β-TCVAE with
different metrics. The results under different regularize strength are reported.
Regulize strength	DCI		BetaVAE		MIG		FactorVAE	
	Original	Groupified	Original	Groupified	Original	Groupified	Original	Groupified
β=6	0.56 ± 0.080	0.68 ± 0.071	0.98 ± 0.028	0.97 ± 0.036	0.31 ± 0.123	0.42 ± 0.098	0.88 ± 0.046	0.90 ± 0.052
β=9	0.67 ± 0.089	0.76 ± 0.048	0.97 ± 0.037	0.96 ± 0.048	0.38 ± 0.196	0.51 ± 0.084	0.90 ± 0.078	0.89 ± 0.045
β=12	0.75 ± 0.053	0.73 ± 0.026	0.96 ± 0.044	0.93 ± 0.048	0.51 ± 0.151	0.51 ± 0.082	0.92 ± 0.059	0.90 ± 0.040
Table 11: Performance (mean ± variance) on Shapes3D of Original and Groupified β-TCVAE with
different metrics. The results under different regularize strength are reported.
Regulize strength	DCI		BetaVAE		MIG		FactorVAE	
	Original	Groupified	Original	Groupified	Original	Groupified	Original	Groupified
β=6	0.35 ± 0.051	0.43 ± 0.073	0.89 ± 0.009	0.89 ± 0.016	0.17 ± 0.038	0.29 ± 0.073	0.73 ± 0.094	0.82 ± 0.027
β=9	0.36 ± 0.019	0.40 ± 0.077	0.89 ± 0.013	0.88 ± 0.019	0.17 ± 0.037	0.27 ± 0.104	0.74 ± 0.077	0.79 ± 0.048
β=12	0.31 ± 0.061	0.35 ± 0.081	0.86 ± 0.031	0.87 ± 0.020	0.16 ± 0.044	0.24 ± 0.083	0.66 ± 0.060	0.75 ± 0.051
Table 12: Performance (mean ± variance) on Color dSprites of Original and Groupified β-TCVAE
with different metrics. The results under different regularize strength are reported.
(a)	BetaVAE score
(b)	DCI disentanglement
(c) MIG
(d)	FactorVAE score
(e)	BetaVAE score
(f)	DCI disentanglement
(g) MIG
(h) FactorVAE score
(i)	BetaVAE score
(j)	DCI disentanglement
(k) MIG
(l) FactorVAE score
Figure 8: Performance distribution on dSprites. Variance is due to different hyperparameters and
random seeds. We consider four metrics: BetaVAE score, DCI disentanglement, MIG, and FactorVAE
score. We observe that Groupified VAEs outperform the original ones.
26
Published as a conference paper at ICLR 2022
①nra>
HVAlBOuuv
14121008)
0.10.10.10.0(
① nro>
①n_e>
(e) BetaVAE score (f) DCI disentanglement	(g) MIG
(j) DCI disentanglement	(k) MIG
(h) FactorVAE score
(l) FactorVAE score
(i) BetaVAE score
Bn-e>
HVAJO-。出
(m) BetaVAE score (n) DCI disentanglement	(o) MIG	(p) FactorVAE score
Figure 9: Performance distribution on Cars3d. Variance is due to different hyperparameters and
random seeds. We observe that Groupified models outperform the Original ones.
27
Published as a conference paper at ICLR 2022
P-TCVAE	FactorVAE	AnnealVAE	户-VAE
∖∕nlι g	' ,- 1 ' - -	∖∕alι ið	∖∕-⅛ 11 ι<~<
0.70-
(h) FactorVAE score
(e) BetaVAE score
(g) MIG
(f) DCI disentanglement
(m) BetaVAE score
(n) DCI disentanglement
(o) MIG
(p) FactorVAE score
Figure 10: Performance distribution on Noisy dSprites. Variance is due to different hyperparameters
and random seeds. We observe that Groupified VAEs outperform the Original ones.
28
Published as a conference paper at ICLR 2022
(d) FactorVAE score
(c) MIG
(a) BetaVAE score
P-TCVAE	FactorVAE	AnnealVAE	BNAE
(b) DCI disentanglement
(i) BetaVAE score
Figure 11: Performance distribution on Color dSprites. Variance is due to different hyperparameters
and random seeds. We observe that Groupified VAEs outperform the Original ones.
29
Published as a conference paper at ICLR 2022
P-TCVAE	FactorVAE	AnnealVAE	户-VAE
' ,-l- - -	X∕*3∣ι m	∖∕ohιc	∖∕nlιι0
(f) DCI disentanglement
(h) FactorVAE score
(e) BetaVAE score
(g) MIG
(m) BetaVAE score
(n) DCI disentanglement
(o) MIG
(p) FactorVAE score
Figure 12: Performance distribution on Shapes3d. Variance is due to different hyperparameters and
random seeds. We observe that Groupified models outperform the Original ones.
30
Published as a conference paper at ICLR 2022
J More Qualitative Results
We evaluate our methods qualitatively on two typical datasets: Cars3d and Shapes3d. We visualize
the traversal results of the Original and Groupified FactorVAE and β-TCVAE. For every factor, we
traverse five randomly sampled representations. As shown in Figure 13 and Figure 14, the traversal
results of the Groupified FactorVAE and β-TCVAE show that these models learn less entangled
representations on Shapes3D (e.g., Orientation of FactorVAE and Scale and Shape of β-TCVAE).
Similarly, as shown in Figure 15 and Figure 16, the Groupified FactorVAE and β-TCVAE achieve
better disentanglement ability on Car3d (e.g., Rotation of FactorVAE and Yaw of β-TCVAE).
For the real-world dataset, we show the qualitative comparison of the Groupified and original
AnnealVAE trained on CelebA. As Figure 17 shows, for most of the factors, our model can extract
cleaner semantics than the original model. For example, the hair color is entangled with the face
shape in the original model, but cleaner in the Groupified model.
M∙s∙-JO posdnoj0
(a) Orientation (b) Wall color (c) Object color (d) Floor color (e) Scale (f) Shape
Figure 13: Learned latent variables using Original and Groupified FactorVAE on Shapes3d dataset.
The traversal range is (-2, 2).
(a) Orientation (b) Wall color (c) Object color (d) Floor color (e) Scale (f) Shape
Figure 14: Learned latent variables using Original and Groupified β-TCVAE on Shapes3d dataset.
The traversal range is (-2, 2).
31
Published as a conference paper at ICLR 2022
IeU∙ayo PS 汨 dnojo
(a) Yaw
(b) Color
(c) Whiten
=qq
(d) Rotation
Figure 15: Learned latent variables using Original and Groupified FactorVAE
traversal range is (-2, 2).
on Car3d dataset. The
lanigirO
defiipuorG
AJR aκS≡> Cw⅛
(e) Rotation
(a) Azimuth (b) Yaw	(c) Color (d) Whiten
Figure 16:	Learned latent variables using Original and Groupified β-TCVAE on Car3d dataset. The
traversal range is (-2, 2).
(a) Original
(b) Groupified
hair length
gender
skin color
azimuth
hair style
-gl-fflffi'勤 ⅝⅛
L ⑥& t⅛∕
1
-∙ Jl fc J
Mkfi-li仟
J 仔，，∙
IFj ■ » J IIJ
t⅛fiq∙fl
?«£,周
∙f]ffiffi,w
skin color2
face shape
_56
-*V0
■
le
s
s
e
s
s
la
gl
-HKf¾
e Hui tlκl*0 Ilkc管 .
3ffl倒»ffj«l«wffi
MIfftBi*fff3eff
WwewXVAWffSVeSff
■0JtWI ∙yw U⅛<¾IE.
?:剧il⅜fl副»1£引
1 Iu 4 〜 ^11^Λ 1 ■ I
Svkvwvh-Wvwwotvvvav


■■♦«∙<◎♦--
■ • ∙
Figure 17:	Learned latent variables using Original and Groupified AnnealVAE on CeleBa dataset.
The traversal range is (-2, 2). The factors learned by Groupified model are less entangled.
32
Published as a conference paper at ICLR 2022
K	Meaningful Dimension Visualizations
When we assign some dimensions to Isomorphism Loss for Groupified AnnealVAEs, e.g., the first-5
dimensions, we have an interesting observation that the assigned dimensions are meaningful in
Groupified AnnealVAEs. The KL divergence increases continuously on these assigned dimensions
after the Isomorphism Loss is applied to them. Note that the KL divergence loss in AnnealVAE
indicates the amount of information encoded. As Figure 18 shows, the KL divergence of assigned
dimensions increases at the beginning of training, which means Isomorphism Loss results in that
the assigned dimensions become meaningful. Finally, the assigned first-five dimensions learn to
encode the semantics of x position, y position, scale, and orientations. The possible reason is that
the latent factors are learned and disentangled in the assigned dimensions due to the punishment of
the Isomorphism Loss. To illustrate that controllable dimensions in Groupified AnnealVAE are not
an exception, we provide more visualizations. The results of covering all hyperparameters settings
with two random seeds are shown in Figure 18 to Figure 26, suggesting that their dimensions are
controllable.
(a) Dimensional KL in training
KL divergence in all dimensions
(b) Dimensional KL in 3e5 steps
(c) Images traversal of dimensions
Figure 18: Meaningful dimensions visualization for C = 10, end = 30000 (different random seeds).
The KL divergences of target dimensions (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.
33
Published as a conference paper at ICLR 2022
(a) Dimensional KL in training
(b) Dimensional KL in 4e5 steps
(c) Images traversal of dimensions
(d) Dimensional KL in training
(e) Dimensional KL in 4e5 steps
(f) Images traversal of dimensions
Figure 19: Meaningful dimensions visualization for C = 10, end = 40000 (different random seeds).
The KL divergences of target dimensions (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different amounts after training (b). As the image
traversal results (c) show, the meaningful dimensions are learned in 0-4 dims. So as (d), (e), and (f),
which are results of a run with a different random seed.
(c) Images traversal of dimensions
(d) Dimensional KL in training
(e) Dimensional KL in 5e5 steps
(f) Images traversal of dimensions
Figure 20: Meaningful dimensions visualization for C = 10, end = 50000 (different random seeds).
The KL divergences of target dimensions (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.
34
Published as a conference paper at ICLR 2022
(a) Dimensional KL in training
(b) Dimensional KL in 3e5 steps
(c) Images traversal of dimensions
(d) Dimensional KL in training
(e) Dimensional KL in 3e5 steps
Figure 21: Meaningful dimensions visualization for C = 20, end = 30000 (different random seeds).
The KL divergences of the target dimension (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different amounts after training (b). As the image
traversal results (c) show, the meaningful dimensions are learned in 0-4 dims. So as (d), (e), and (f),
which have a different random seed.
(f) Images traversal of dimensions
(a) Dimensional KL in training
(b) Dimensional KL in 4e5 steps
(c) Images traversal of dimensions
(d) Dimensional KL in training
(e) Dimensional KL in 4e5 steps
(f) Images traversal of dimensions
Figure 22: Meaningful dimensions visualization for C = 20, end = 40000 (different random seeds).
The KL divergences of target dimensions (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.
35
Published as a conference paper at ICLR 2022
(a) Dimensional KL in training
(c) Images traversal of dimensions
(d) Dimensional KL in training
(f) Images traversal of dimensions
Figure 23:	Meaningful dimensions visualization for C = 20, end = 50000 (different random seeds).
The KL divergences of the target dimension (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.
(a) Dimensional KL in training
KL divergence in all dimensions
(b) Dimensional KL in 3e5 steps
(c) Images traversal of dimensions
Dimension wise KL divergence in training process
(d) Dimensional KL in training
5000	10000 15000 20000 25000 30000
Training steps
(f) Images traversal of dimensions
Figure 24:	Meaningful dimensions visualization for C = 30, end = 30000 (different random seeds).
The KL divergences of the target dimension (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.
36
Published as a conference paper at ICLR 2022
(a) Dimensional KL in training
(b) Dimensional KL in 4e5 steps
(c) Images traversal of dimensions
(d) Dimensional KL in training
(e) Dimensional KL in 4e5 steps
(f) Images traversal of dimensions
Figure 25:	Meaningful dimensions visualization for C = 30, end = 40000 (different random seeds).
The KL divergences of the target dimension (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.
(a) Dimensional KL in training
(b) Dimensional KL in 5e5 steps
(c) Images traversal of dimensions
(e) Dimensional KL in 5e5 steps
(f) Images traversal of dimensions
Figure 26:	Meaningful dimensions visualization for C = 30, end = 50000 (different random seeds).
The KL divergences of target dimensions (0-4 dimension) increase one by one during training (a).
The KL divergences in different dimensions are different after training (b). As the image traversal
results (c) show, the meaningful dimensions are learned in 0-4 dims. So are (d), (e), and (f), which
are results of a run with a different random seed.
37
Published as a conference paper at ICLR 2022
L	More Representation Space Visualizations
To illustrate that the Isomorphism Loss suppresses the representation space collapse in VAE-based
methods is not an exception, we provide more visualizations of the representation space visualization
of Groupified VAEs. The Original and Groupified β-VAEs, AnnealVAEs, FactorVAEs, and β-
TCVAEs are shown in Figure 27, Figure 28, Figure 29, and Figure 30, respectively, which implies
that the representation space of Groupified VAEs are organized better than the original ones.
(a) β = 10, Groupified
(b) β = 10, Original
(c) β = 10, Groupified
(d) β = 10, Original
(e) β = 20, Groupified
(f) β = 20, Original
(g) β = 20, Groupified
(h) β = 20, Original
(i) β = 30, Groupified
(j) β = 30, Original
(k) β = 30, Groupified
Figure 27: The representation space span by the Groupified and Original β-VAE. We train the
models with the same hyperparameter but different random seeds for different runs. The 3D location
of each point is the disentangled representation of the corresponding image. Moreover, an ideal result
is that all the points form a cube, and color variation is continuous. Higher hyper-parameter β results
in the collapse of representation space. The collapse is suppressed by the Isomorphism Loss, which
leads to better disentanglement.
(l) β = 30, Original
38
Published as a conference paper at ICLR 2022
(d) C = 10, Original
(a) C = 10, Groupified
(b) C = 10, Original
(c) C = 10, Groupified
(h) C = 20, Original
(e) C = 20, Groupified (f) C = 20, Original	(g) C = 20, Groupified
(i) C = 30, Groupified
(j) C = 30, Original
(k) C = 30, Groupified
(l) C = 30, Original
Figure 28:	The representation space span by the Groupified and Original AnnealVAE. We train the
models with the same hyperparameter but different random seeds for different runs. The 3D location
of each point is the disentangled representation of the corresponding image. Moreover, an ideal result
is that all the points form a cube, and color variation is continuous. Higher hyper-parameter C results
in the collapse of representation space. The collapse is suppressed by the Isomorphism Loss, which
leads to better disentanglement.
39
Published as a conference paper at ICLR 2022
(a) γ = 5, Groupified
(b) γ = 5, Original (c) γ = 5, Groupified (d) γ = 5, Original
(e) γ = 10, Groupified
(f) γ = 10, Original
(g) γ = 10, Groupified	(h) γ = 10, Original
(i) γ = 15, Groupified
(j) γ = 15, Original
(k) γ = 15, Groupified
(l) γ = 15, Original
Figure 29:	The representation space span by the Groupified and Original FactorVAE. We train the
models with the same hyperparameter but different random seeds for different runs. The 3D location
of each point is the disentangled representation of the corresponding image. Moreover, an ideal result
is that all the points form a cube, and color variation is continuous. The collapse is suppressed by the
Isomorphism Loss, which leads to better disentanglement.
40
Published as a conference paper at ICLR 2022
(a) β = 6, Groupified
(b) β = 6, Original (c) β = 6, Groupified	(d) β = 6, Original
(h) β = 9, Original
(e) β = 9, Groupified	(f) β = 9, Original	(g) β = 9, Groupified
(i) β = 12, Groupified
(j) β = 12, Original
(k) β = 12, Groupified
(l) β = 12, Original
Figure 30:	The representation space span by the Groupified and Original β-TCVAE. We train the
models with the same hyperparameter but different random seeds for different runs. The 3D location
of each point is the disentangled representation of the corresponding image. Moreover, an ideal result
is that all the points form a cube, and color variation is continuous. Higher hyper-parameter C results
in the collapse of representation space. The collapse is suppressed by the Isomorphism Loss, which
leads to better disentanglement.
41