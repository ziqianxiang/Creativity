Figure 1: (a) The training framework of the proposed ICE. Different images sampled from differentsource datasets are used to mimic randomly encountered images and are simultaneously fed intoUθ. By maximizing the prediction entropy of model U for the input images, we obtain adversarialimages. To evaluate how confusing the generated adversarial images are, we feed them into thesource models and measure the cross-entropy loss. Finally, we optimize U by maximizing the sourcemodels, cross-entropy losses. (b) The testing pipeline of the proposed ICE.
Figure 2: Inference pipeline of PGD-based baselines.
Figure 3: All experiments in this figure use Cifar-10 andResNet-18 as the source dataset and the source model. (a):ICE’s GTA results on six target models trained on Cifar-100with different output dimensions. (b): ICE’s GTA results onsix target models trained on Cifar-100 with different numbersof T in the training phase.
Figure 4: (a) The network architecture of the proposed ICE. It is composed of four cascaded residualblocks, one convolutional layer, and one softmax layer. (b) The inner structure of the residual block.
Figure 5: Some adversarial examples for clean images from TieredT84. The adversarial examplesare generated via PGD, ML DL TI-DIM, AEG, MTA, and the proposed ICE with e = 15.
