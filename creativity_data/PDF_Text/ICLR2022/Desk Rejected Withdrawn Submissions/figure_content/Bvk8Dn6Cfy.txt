Figure 1: Domain translation towards remove source domain discrepancies. The top row shows orig-inal source Magnetic Resonance (MR) images. The bottom row shows corresponding DaSeGANinvariant translations.
Figure 2: Open M&Ms data splitting method. Each colored square represents 10 subjects of thedataset (a CMR cine sequence).
Figure 3: DaSeGAN framework overview. By only using the signals of the task network, we canmaintain the consistency of the structures of interest between the initial source domain images andtheir translated version. Given a source domain image, the translation network learns to translate itto a random source domain, pushing the generator to learn a mapping that removes the discrepanciesbetween these domains.
Figure 4: Qualitative results. Comparison of the segmentation results with baseline task net-work (Baseline), and when incorporating it to DaSeGAN approach evaluating the source image(DaSeGAN-S) and their translated version (DaSeGAN-T).
