Figure 1: Method Overview: At session t, the model starts with the state at last session. It observesincoming images and map them into unit hyper-sphere in the feature space. For the classes in theincoming categories like c1 in the figure, we first expand the mixture model for each incomingclass, followed by the learning with an EM framework. In E-step, we perform a cluster assignmentby choosing the component with the closest mean μ. In M-step, We update both the embeddingnetwork and mixture models with overall loss. After the learning, we perform a mixture modelreduction to reduce the redundant components for each class.
Figure 2:	Performances w.r.t sessions on iCIFAR-20 benchmark with three splits4.1	Experiment SetupWe compare previous methods with our approach on three benchmarks, including iCIFAR-20, iDo-mainNet and iDigits:•	iCIFAR-20: It is based on CIFAR-100 (Krizhevsky & Hinton, 2009), which consists of 20super classes and each super class has 5 subclasses. We take these subclasses as differ-ent domains of the same class and require the model to predict super class labels for therecognition task.
Figure 3:	t-SNE Visualization on all data so far seen of DER w/ ours across sessions for iDigits NCsplit. Different colors represent class label for the left and domain label for the right.
Figure 4: Performances w.r.t sessions on iDigits benchmark with three splitsiDomainNet-NCER	PODNet T- GeoDLiDomainNet-NDMeta-DR →- UCIR -→- DERFigure 5: Performances w.r.t sessions on iDomainNet benchmark with three splitsiDomainNet-NCDUCIR w/our τ- DERw/ourA More Implementation DetailsWe use Nvidia Titan XP, Nvidia RTX 2080 and Nvidia Titan RTX as the computation platformswith CUDA 10.1. Our python is 3.7 and PyTorch is 1.71. We use seed 1993 for all the experiments.
Figure 5: Performances w.r.t sessions on iDomainNet benchmark with three splitsiDomainNet-NCDUCIR w/our τ- DERw/ourA More Implementation DetailsWe use Nvidia Titan XP, Nvidia RTX 2080 and Nvidia Titan RTX as the computation platformswith CUDA 10.1. Our python is 3.7 and PyTorch is 1.71. We use seed 1993 for all the experiments.
Figure 6: t-SNE visualization of digits 1.
Figure 7: t-SNE visualization of digits 3.
Figure 8: t-SNE visualization of digits 5.
Figure 9: t-SNE visualization of digits 7.
