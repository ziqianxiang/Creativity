Figure 1: Motivation for Objectness Constraints: Shows two examples of an image, its ground-truth (GT)segmentation label, its prediction from a source-initialized model and the confidence of prediction (brighter re-gions are more confident). The blue dashed-circles highlight the high confidence regions that are mis-classifiedby the model. The goal of the our objectness constraints is to implicitly penalize such mis-classifiationsthe source data. The target labels are assigned only if the model predictions exceed a predefinedthreshold. Training the model further with source data augmented with the pseudo-labelled targetdata ultimately improves target domain accuracy.
Figure 2: Superpixel generation: Overall pipeline for generating multi-modal superpixels (middle-column,bottom two rows) from image and depth. Each type of unsupervised segmentation map (middle-row) is ac-companied with a corresponding boundary map (bottom-row) overlayed on the image for clear comparison.
Figure 3: Qualitative evaluations: We observe that our regularised model (CAG+PAC) makes fewer mistakes.
