Figure 1: An example of how the proposed method works. Networks predictions on unseen data arecompared with a given knowledge (in the form of FOL formulas). Knowledge violation is used as ametric to select samples (figure on the right) which require annotations in an active learning strategy.
Figure 2: A visual example on the XOR-like problem, showing the principles of the KAL strategy.
Figure 3: A comparison of the sample selection process on the XOR task (starting from the samepoints as in Figure 2). The proposed method mostly selects data along the decision boundaries, sim-ilarly to the supervised one. Notice how the uncertainty-based strategy is not capable of discoveringnovel data distribution (right-bottom quadrant).
Figure 4: a), b), c) Performance growth on the three experiments when increasing the number oflabelled samples. d) Scatter plot of the model supervision loss vs the knowledge violation loss onthe Animalsâ€™s problem at the 50th iteration. In orange, the point selected by the KAL strategy.
Figure 5: A visual example on the XOR-like problem, showing how the training evolves in each ofthe compared strategy. We depict network predictions with different colour degrees (light coloursnegative predictions, dark colours positive prediction). In blue, we depict the points selected inprevious iterations, in orange those selected at the current iteration. Black lines at x1 = 0.5 andx2 = 0.5 are reported only for visualization purposes. From left to right, the situation at the 1st,10th and 100th iteration.
