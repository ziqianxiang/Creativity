Figure 1: Invariance exists in both imageand text, e.g., image is invariant to trans-lation (top), and text is robust to manyforms of edits (bottom).
Figure 2: Sensitivity of CE and EISL loss w.r.t different types of text edits as the amount of editsincreases (x-axis). We use a fixed machine translation model, synthesize different types of edits onthe target text, and measure the CE and EISL losses, respectively. The edit types include shuffle(changing the word order), repetition (words being selected are repeated), and word blank (wordsbeing replaced with a special blank token). The CE loss tends to increase drastically once a smallamount of edits is applied. In contrast, our EISL loss increases much more slowly, showing itsrobustness.
Figure 3: Inspired by the ConvNet convolution which applies a convolution kernel to differentpositions in an image and aggregate (left), we devise similar n-gram matching and convolution,which is robust to sequence edits (noises, shuffle, repetition, etc) (right).
Figure 4: As convolution is a common operation for translation invariance in image, we adopt aconvolution to achieve the translation invariance in text. The input is the distribution from the modeloutput in log domain, kernel represents the convolution kernel and * is the convolution operation. Inthis 3-gram example, there are 5 kernels, which correspond to the 5 rows on the right.
Figure 5: Results of Translation with Noisy Target on German-to-English(de-en) from Multi30k.
Figure 6: Results of Translationon German-to-English(de-en) fromWMT18 raw corpus. BLEU scores arecomputed against clean and paralleltest data. The x-axis is the number ofsamples. 0k represents the performanceof the pretrained model.
Figure 7: Results of iterative NAT on different decoding iterations.
Figure 8: The percentage of repeated tokens under different iteration steps.
Figure 9: Results of training and inference time. EISL-n represents n-gram EISL loss and EISL-12represents the combination of 1-gram and 2-gram EISL loss.
Figure 10:	Results of Translation with Noisy Target on German-to-English(de-en) from Multi30k.
Figure 11:	The change of loss values during training. The x-axis represents the training step. a) givesthe loss curve of exact implementation; b) gives the loss curve of efficient approximate implementationas we discussed in section 3.2; and c) gives the absolute difference between the two implementations.
