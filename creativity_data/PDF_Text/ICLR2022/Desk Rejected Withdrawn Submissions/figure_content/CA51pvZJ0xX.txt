Figure 1: The architecture of sparse centroid-encoder. This is similar to that of a centroid-encoderexcept the sparse layer in-between the input layer and first hidden layer. Unlike centroid-encoder,the SCE doesnâ€™t use a bottleneck architecture.
Figure 2: Sparsity plot of the weight of WSPL shown for MNIST (a) and GSE73072 (b). The l1penalty sets the weight of most of the features to near zero and those features were ignored. TheElbow method picked 113 and 117 features from the two data sets. The red dot indicates the locationof the elbow.
Figure 3: Locations of selected features of MNIST image shown in a 28 x 28 grid. The selectedpixels are marked in white, and the ignored pixels are marked in black.
Figure 4: Comparison of classification accuracy using SCE and SSVM features.
