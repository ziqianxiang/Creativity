Figure 1: Block-diagram of the proposed approach: (a) source-specific model training is done in-dependently for each source domain, potentially using different data storage (b) each latent sourcedomain distribution is estimated via a GMM, (c) the source-trained network is adapted on the targetdomain by performing pairwise domain alignment between the GMM distribution and the unlabeledtarget data, and by minimizing conditional-entropy for the model target predictions (d) the finaltarget domain predictions are obtained via a convex combinations of logits for each adapted modelFor adaptation,network isinitialized withsource weightsAdaptation ontarget domainPrototypicalGMMdistributionΛ Adaptation∖viaLwz+Le∙tFor adaptation,network isinitialized with
Figure 2: Performance of our algorithm under different numbers of latent projections used in thecomputation of the Sliced Wasserstein Distance. Results reported on the Office-31 tasks.
Figure 3: Effect of the adaptation process on the Office-home dataset: from left to right, we considerArt, Clipart and Product as the source domains, and Real World as the target domain.
Figure 4: Prediction accuracy on the target domain for different levels of source model confidence,and our choice of λ. Tasks from the Office-home dataset are used in this experiments.
Figure 5: UMAP visualization of data representations in the embedding space for Office-caltech withAmazon as the target domain. From left to right: Caltech, DSLR, and Webcam as source domains.
Figure 6: Source and GMM embeddings forthe Image-clef dataset with Imagenet as thetarget and Pascal and Caltech as sources.
