Figure 1: Comparison of predictor training setups: (a) conventional, space-dependent neural predic-tors; (b) the proposed general-purpose, space-agnostic predictor. Best viewed in color.
Figure 2: Example depicting the key graphical features extracted from compute graphs and howthey are encoded as node features for the GNN.
Figure 3: Contrastive lossThis framework learns a base encoder, that,given an image, outputs its vector represen-tation. To train the base encoder, a projec-tion head projects representations into a lower-dimensional space where a contrastive lossfunction is then optimized. The projectionhead, Proj(*), is an MLP that maps vectorsin Rm to vectors into the sphere of Rp , wherep < m. The contrastive loss is designed toforce representations of similar images to bealigned. For images, similar images should be-long to the same class. In addition to the con-trastive loss function and the notion of similar-ity, data augmentation is also crucial for train-ing the base encoder. The augmentation pro-cess occurs during training for each batch. For each batch element, a new data point is added to thebatch before assembling the contrastive loss function. The new data point is just a slight randomperturbation of the image. The idea here is that this pair, the image and its augmentation, constitutethe only positive pair, that is, since the images are similar their corresponding vector representations
