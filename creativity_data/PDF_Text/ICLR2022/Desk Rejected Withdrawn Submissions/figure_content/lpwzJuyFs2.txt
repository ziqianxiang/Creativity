Figure 1: Embedding function fθ, parametrizedby θ is Z ≡ fθ(x(R)), i.e., a feature sample ofdimension k ≤ 3N, as X may be as large as R, isreduced to a latent sample of dimension d《k.
Figure 2: Low-dimensional embedding calculated for the UCI handwritten digits data set (https：//archive.ics.uci.edu/ml/machine-learning-databases/Optdigits/). The data Setconsists of 1797 digit images, each of size 8 X 8 pixels.
Figure 3: Low-dimensional embedding of the alanine tetrapeptide data set consisting of 105 featuresamples where each sample is of 12 dimensions. The sines and cosines of the Φ and Ψ dihedralangles are used to describe each sample. The data set comes from a biased simulation run that en-hances the fluctuations of the Φ dihedral angles using well-tempered metadynamics. The learnedCVS are subsequently used to enhance sampling during a 100-ns well-tempered metadynamics sim-ulation. This setup enables us to see several metastable states in the free energy surface embeddedin the latent space. As We bias only two CVs, the simulation takes less computational time thansampling the Φ dihedral angles.
