Figure 1: Structure of PRM for learning task t. PRM follows almost the same procedure as HAT,except for part of the backward path. In dissimilar task detection (DTD), the model uses al≤t-1 toblock all the parameters. In learning with partially relaxed masks (LwPRM), it uses pl≤t-1 instead,which blocks only the parameters that are important for the previous dissimilar tasks.
Figure 2: Proposed networks that are used in the experiments. Only the forward path is shown.
Figure 3: Computation times for one sequence of #6. The right figure is plotted in log scale. CAT,HYP and ACL take more time, while PRM requires less time.
