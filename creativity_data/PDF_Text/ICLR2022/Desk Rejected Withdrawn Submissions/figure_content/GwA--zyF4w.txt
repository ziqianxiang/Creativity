Figure 1: Original Shape and its Flipped version from Surreal datasetLet ΦX and ΦXf denote the matrices, whose rows can be interpreted as embeddings of the pointsof X and Xf . In the functional map framework, there exists a functional map CXXf that alignsthe corresponding embeddings. Given a self symmetry ground truth pointwise map TXXf , we canestimate CXXf by solving the following optimization problem:CXXf = arg min kΦXCT - TXXf ΦXf k2	(2)CThe optimal symmetry map CXXf is given by: CXXf = (Φ+XTXXf ΦXf)T, that is differentiableusing the closed-form expression of derivatives of matrix inverses, as also mentioned in Section 3.
Figure 2:Figure 3:8Under review as a conference paper at ICLR 20226	Conclusion and Future WorkIn shape correspondence literature, partial shape matching and complete shape matching are gen-erally tackled by two different sets of methods which obtain impressive results in one of the tworespective domains. We presented a simple, general but effective method that reduces shape match-ing to a nearest neighbour search problem in a canonical embedding and apply it to both partial andcomplete shape matching. Our key idea is to learn an embedding of each shape that would make thegiven self-symmetry map linear in some higher-dimensional space. Our idea of injecting symme-try into the learning pipeline also serves as a regularizer and provides competitive performance onmultiple shape matching benchmarks in comparison to all recent learning based methods.
Figure 3:8Under review as a conference paper at ICLR 20226	Conclusion and Future WorkIn shape correspondence literature, partial shape matching and complete shape matching are gen-erally tackled by two different sets of methods which obtain impressive results in one of the tworespective domains. We presented a simple, general but effective method that reduces shape match-ing to a nearest neighbour search problem in a canonical embedding and apply it to both partial andcomplete shape matching. Our key idea is to learn an embedding of each shape that would make thegiven self-symmetry map linear in some higher-dimensional space. Our idea of injecting symme-try into the learning pipeline also serves as a regularizer and provides competitive performance onmultiple shape matching benchmarks in comparison to all recent learning based methods.
