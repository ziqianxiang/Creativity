Figure 1: Overall Workflow of D2ULO.
Figure 3: True Utiltiy vs Es-timated Utility. (Spearman’scorrelation coefficient is 0.96.)7Under review as a conference paper at ICLR 2022—D2ULO ---------- Random -Φ- Optimal FASS BADGE GLISTER ----------------------------- AADAFigure 2: Performance of D2ULO on various adaptation shifts. The first row gives the results ofTrain-from-Scratch, where ‘SVM’, ‘Logistic’ and ‘SmallCNN’ indicate the model used for obtainingutilities. The second row give the results of Fine-tune, and the start points are the classifier accuracyon target validation set after domain adaptation.
Figure 2: Performance of D2ULO on various adaptation shifts. The first row gives the results ofTrain-from-Scratch, where ‘SVM’, ‘Logistic’ and ‘SmallCNN’ indicate the model used for obtainingutilities. The second row give the results of Fine-tune, and the start points are the classifier accuracyon target validation set after domain adaptation.
Figure 4: Performance of existing AL ap-proaches with 100 initially labeled datapoints selected randomly or by D2ULO(warm start, denoted by ‘_ws’).
Figure 5: VISDA-2017 result: synthetic ⇒ real. (a) gives the results of Train-from-Scratch, (b)and (c) give the result of Fine-tune. One interesting finding is that, all the strategies achieve a largeperformance improvement on classification accuracy. This indicates the needs to select data pointsfrom the target domain.
Figure 6: Performance of D2ULO on domains that haveinconsistent label space.
Figure 7: Example images in VISDA2017. The left is an image of source domain (synthetic) whilethe right is an image of target domain (real).
