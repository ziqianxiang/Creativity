Figure 2: The architecture of our proposed framework, which consists of three components: Visualencoder, Cross Modal Transformer and Text encoder (ObjectGroundedBERT). The pretraining tasksare Masked Visual Feature Prediction, Image-Text Matching and Masked Language Modeling.
Figure 3: ObjectGroundedBERT comprises two components: Language encoder and Text-grounding.
Figure 4: Illustration of the Attention map of Cross modal layers.
