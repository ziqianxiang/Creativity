Figure 1: The effectiveness of domain loss and weak-strong augmentation on pseudo labelingby Teacher model. The figure shows the true positive and false positive ratio on the entire train-ing set of Clipart1k (target) with PASCAL VOC as source. Due to inherent domain shift in theTeacher model, the Teacher model without domain loss generates noisy pseudo labels. The weakaugmentation is able to stabilize pseudo labeling.
Figure 2: Overview of our proposed Adaptive Unbiased Teacher (AUT). Our model consists oftwo modules: 1) target-specific Teacher model for taking weakly-augmented images from target do-main and 2) cross-domain Student model for taking strongly-augmented images from both domains.
Figure 3: Qualitative ablation studies on pseudo labels generated on the image from the train-ing set of Clipart1k. This figure show the importance of adversarial loss Ldis and weak-strongaugmentation on pseudo labeling.
Figure 4: Qualitative results and comparisons on Foggy Cityscapes.
Figure 5: Qualitative results and comparisons on Clipart1k.
Figure 6: Qualitative results and comparisons on Watercolor2k.
Figure 7: Mutual Learning curve on Clipart1k dataset. Increasing weights of Î»dis can achieveimproved performance and stable learning curve.
