Figure 1: An illustration of the ASLframework. The auxiliary data pointsUi are generated from Xi by the en-coder Pχ∣u(χ∣u), forming the paireddata (Xi, Ui). Marginal distributionpu (u) is estimated from the Ui data,and generator distribution px|u(x|u) islearned in a supervised fashion basedon (Xi, Ui). New data points of Xare generated by simulation of U * 〜Pu(U), followed by the generator X * 〜px|u(x|U*).
Figure 2: True samples of six synthetic data sets and randomly generated data points by ASL.
Figure 3: Quantitative evaluation of three generative models on the synthetic data sets. Each boxplotshows the distribution of the 1-Wasserstein distance between the true and generated data points.
Figure 4:	t-SNE visualization of the auxiliary data points generated by the VAE-based and MI-basedencoders, respectively.
Figure 5:	True and reconstructed images from the Fashion-MNIST data. Left: true images from thetesting set. Middle: images reconstructed by VAE-ASL. Right: images reconstructed by MI-ASL.
Figure 6: Randomly generated samples from various deep generative models.
Figure 7: True images from the CelebA data and model-generated images based on ASL.
Figure 8: Randomly generated samples of synthetic data by VAE and normalizing flow.
Figure 9: Randomly generated images trained from the CIFAR-10 data set.
Figure 10: Randomly generated face images by ASL using two different encoders.
Figure 11: Interpolation of generated images in the latent space.
Figure 12: Loss function values of ASL in the training of encoder, regression function, and densityestimation, respectively.
