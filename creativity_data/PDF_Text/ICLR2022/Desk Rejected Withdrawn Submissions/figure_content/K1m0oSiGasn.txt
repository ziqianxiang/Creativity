Figure 1: Concept of Adaptive Re-gion Pooling. We compare threeoperations to downsample the fea-ture into half size: (a) pooling withstride = 2, (b) our Adaptive RegionPooling (ARP), and (c) cropping op-eration. ARP smoothly bridges twowidely used operations by automat-ically sampling the feature from themost critical region (red box) with awell-estimated cropping scale. Fur-thermore, as in two cases of (b),users can manually balance the scaleof receptive field and the granular-ity of downsampled feature througha controllable trade-off mechanism.
Figure 2:	Overall workflow of Adaptive Region Pooling.
Figure 3:	Architecture of Multiple Scale and Granularity Network.
Figure 4: Learning progress of MSGN or STN on VeRi-776. We evaluate the network using STmodule (Jaderberg et al., 2015) or ARP as the downsampling operation and respectively show thelearning curves in (a) and the projections of learned downsamplings to the input images in (b).
Figure 5: Visualization on CUB-200-2011. The firstand second rows respectively show the input imagesand the keypoint confidence maps C with the croppedregions (red box). DSRadp is also listed at the bottom.
Figure 6: Study of k on VeRi-776. Thesecond to fourth columns show the croppedregions (red box) determined by ARP withdifferent k. The corresponding validationresults are also listed at the bottom.
Figure 7: Visualization of the cropped regions on the simulated keypoints distributions. Foreach sub-figure, x-axis indicates different locations and y-axis represents the accumulated keypointconfidences at each location (i.e., Equation 5). The blue line is the simulated 1-D keypoints distri-bution while the color under the line means whether each location is within the cropped region ornot (red means yes while blue means no).
Figure 8: Visualization of the cropped regions from two-branches MSGN. The green and redboxes respectively represent the cropped regions by different branches of MSGN.
