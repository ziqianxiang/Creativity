Figure 1: Supervised vs. self-supervised network for pruning (Alg. 1) with fewer iterations: test accuracy(mean±std) of pruned models with 200 and 250 pruning iterations for 310 tasks drawn from CIFAR-100 (LEFT)and Tiered-ImageNet (RIGHT).
Figure 2: Absolute difference (`1 -distance) of modelweights (mean±std) between two consecutive pruningiterations on CIFAR-100.
Figure 3: IoU (mean±std) measuring filter sharing between two tasks of different similarity∈ {0, 1, 2, 3, 4}in each layer of their pruned models, for all the layers from input to output (left to right).
Figure 4: (LEFT) The odds b`,e(a) of a filter being selected in a target task,s model if it is selected by a out of10 similar tasks: a vs. b`,e(a) (mean±std) over all layers ' ∈ [L — 1] and task similarities c ∈ [4]; (RIGHT)Histogram shows how many filters in the target task’s model are selected by a out of 10 similar tasks: a vs.
Figure 5: Test accuracy, memory and computational costs of MVP and IFP in the experiments.
Figure 6: Test-set accuracy of pruned models produced by different methods (MVH IFH uniform pruning) usingdifferent number of iterations ( Group-L Top plots), different amount of training data ( Group-II, Middleplots), and training tasks with prototype similarity ( Group-III, Bottom plots).
