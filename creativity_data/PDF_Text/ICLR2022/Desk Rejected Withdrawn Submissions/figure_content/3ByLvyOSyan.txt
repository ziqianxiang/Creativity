Figure 1: Architectures of Residual Blocks. For both pictures the grey arrow marks the easiest pathto propagate the information.
Figure 2: Signal propagation plots representing the variance of the forward activations (on theleft) and the backward gradients variance (on the right) under our proposed initialization scheme:both values refer to residual block output. Both signals depict the behaviour for a ResNet-50 withconvolutional shortcuts. The x-axis is the residual layer depth, while on the y-axis the variance of thesignal is reported in a logarithmic scale.
Figure 3: Test and Train accuracies of ResNet-50 under different combinations of residual block mod-ifications and initialization: standard ResNet with BatchNorm and IdShort, LearnScalar, ConvShortusing both Brock et al. (2020) and ours initialization. Each experiment has been run three times: thesolid line is the mean value while the surrounding shadowed area represents the standard deviation.
Figure 4: Signal propagation plots representing the variance of the forward activations (on theleft) and the backward gradients variance (on the right) under our proposed initialization scheme:both values refer to residual block output. Both signals depict the behaviour for a ResNet-18 withconvolutional shortcuts. The x-axis is the residual layer depth, while on the y-axis the variance of thesignal is reported in a logarithmic scale.
Figure 5: Signal propagation plots representing the variance of the forward activations (on the left)and the backward gradients variance (on the right) under our proposed initialization scheme: bothvalues refer to residual block output. Both signals depict the behaviour for a ResNet-101 withconvolutional shortcuts. The x-axis is the residual layer depth, while on the y-axis the variance of thesignal is reported in a logarithmic scale.
Figure 6: Test and Train accuracies of ResNet-18 under different combinations of residual blockmodifications and initialization: standard ResNet with BatchNorm and IdShort, LearnScalar, Con-vShort using both Brock et al. and ours initialization. Each experiment has been run three times: thesolid line is the mean value while the surrounding shadowed area represents the standard deviation.
Figure 7: Test and Train accuracies of ResNet-101 under different combinations of residual blockmodifications and initialization: standard ResNet with BatchNorm and IdShort, LearnScalar, Con-vShort using both Brock et al. and ours initialization. Each experiment has been run three times: thesolid line is the mean value while the surrounding shadowed area represents the standard deviation.
