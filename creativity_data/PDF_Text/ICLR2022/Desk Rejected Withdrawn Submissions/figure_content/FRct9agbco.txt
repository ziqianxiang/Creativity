Figure 1: Our method (CMSF): We augment an image twice and pass through online encoder andtarget encoder followed by `2 normalization to get u and v. We want v to be close to not only u, butalso the nearest neighbors (NN) of u to perform mean-shift. We constrain the NN pool using someextra knowledge, e.g., image labels, to improve the purity of the NNs. In supervised setting, we useimages from the same category only (yellow points) to do NN search. We show that the constraincan come from noisy labels or NN search using a pre-trained SSL embedding on another modality.
Figure 2: top-10 vs. random 10 on ImageNet100 with 50% noisy labels: We show NN searchresults (sorted from left to right) for a query on the set of images that share the same label with thequery. When the query is correctly labeled (Row 1), most NN results are from the same categorywhich is good. When the query is not correctly labeled (Row 2), the few top results are still from theactual category of the query which is good. However, on Row 3, almost half of random results arenot from the correct category. This is not surprising, but shows why CMSF with top-k (Rows 1 and2) performs better than CMSF with top-all and standard cross-entropy supervised learning (Row 3).
Figure 3: Noisy supervised setting on ImageNet-100: Our method is more robust to noisy anno-tation compared to Xent. Also, using top-all results in degradation since all images from a singlecategory are not guaranteed to be semantically related. Mean Transfer Accuracy is average accuracyof each model over 10 transfer dataset in our settings.
