Figure 1: A task is created by randomly picking m classes from a set C, and belongs to a taskdistribution P(T) (e.g. Ttrain 〜PErain) : classify between “horse” and “bicycle”). Training,validation and target tasks are made of different classes. Few-Shot Learning : target inputs (e.g.
Figure 2:	(Left) Early-stopping based0	20	40	60	80	100 120	140	160t (1k training iterations)on validation accuracy is problematic inMeta-Learning as there can be an arbi-trarily large time gap between the opti-mal stopping time t* for the target taskdistribution and t*alid. This can lead tosub optimal target generalization. Forexample, on the (Right) we show accu-racy vs. training interations for a CNNtrained with MAML on the Birds datasetwith multiple target datasets, each accu-racy is averaged over 500 tasks (5-way1-shot). Markers represent t* (black);tv*alid (red). More settings in App.***.
Figure 3:	Neural Activation Dynamics : A neural net-work f composed of a feature extractor φ (light blue) ofL hidden-layers, followed by a classifier g. For a set Xof input vectors xi the activation vectors at the l-th layerare denoted as φl (X). The set of activations of all layersfrom 1 to L constitute the neural activations Φ(X) of themodel and their evolution through learning time constitutethe neural activation dynamics Φ(X, t). See Eq. 3, 4.
Figure 4:	Average target task accuracy as a function of trainingiteration: Acctarget(t). Observation 1: The variation of gen-eralization (Acctarget), for a deep neural network, frequentlycorrelates with simple statistics characterizing how its featureextractor 夕 responds to the target input distribution P(Xtarget).
Figure 5: Observation 2: Simplestatistics of neural activation dynamicswhich best correlate to generalizationmay be observed at different layers ofthe feature extractor. We therefore con-sider the neural activation dynamics ofall layers in a network in our work here.
Figure 6: Observation 3: Generalization may correlate to different properties of the neural activation dynamics,depending on the setting. While Acctarget may correlate to ψ1 (Eq.2) in some settings, in other settings itmay instead correlate to ψ2, ψ3 or ψ4 (Eq.7,6,8) measured on the activation dynamics at depth l of the featureextractor. See App.B.2.3 for full experiments across multiple settings.
Figure 8: Our framework : Learning the relation function ψ between the neural activation dynamicsΦ(Xtarget , t) and the generalization to a novel task distribution p(Ttarget)). Having defined an hypothe-Sis function space Ψ, We search, given a meta-learning setting, the optimal function ψ* in Ψ which minimize thetrue objective d or equivalently, achieve high generalization Acctarget. Since we don’t have access to Acctarget,*we optimize an empirical objective d to find ψ .
Figure 9: a) In few-shot transfer learning if overfitting on the target domain happens at a different time thenon the source domain (e.g. t* < tVaIid) then the validation and target accuracies “diverge” at t* : Acctarget(t)and Accvaiid(t) are correlated positively on [to,t*] and negatively on [t*, t*aiid]. b) Assuming that the neuralactivation dynamics can characterize the generalization behavior, there might be a function under which thetarget dynamics diverge from the validation dynamics at t* .
Figure 10: Inferring when to stop in few-shot transfer learning. Setting shown: MAML, CNN, Quickdraw toOmniglot, 5-way 1-shot. a) The optimal function ψ * and layer l* are those where the neural activation dynamicsof the target inputs diverge the most from those of the source domain, i.e. where the objective of Eq.12 isminimized. b) Once we have identified ψ* and l*, we stop at £FSTL ofEq.13, i.e. when the Pearson correlationof ψ*arget and ψVαiid flips from positive to negative. Here £FSTL drastically outperforms 心血.
Figure 11: Illustrating the issue of using meta-validation for early-stopping in Meta-Learning: MAML,Matching Network and Prototypical Network, trained on both MiniImagenet and CU Birds, withvarious target datasets from the Meta-Dataset benchmark. The validation early-stopping time t↑jaiid(red dashed line) leads to sub-optimal generalization performances for the various target datasets(from the Meta-Dataset benchmark), each having their own optimal early-stopping time "。”t(blackdashed lines) at different times. We also observe t↑arget ≤ t↑jaιid across the different settings.
Figure 12:	Comparison between average inner product between representation vectors, and averagetarget accuracy on target tasks in few-shot learning, for different regimes of MAML and First-Order MAML on MiniImagenet. Here the expression [hiT hj] is the expected inner product betweenrepresentations for the target inputs, i.e. ψ1 defined in Eq.2.
Figure 13:	Measuring the expected representational inner product in Few-Shot Transfer Learning.
Figure 14: Strong negative correlation between generalization and metrics on the representationspace, where the minimum of the metric coincides with the maximum of generalization : Few-ShotLearning settings with MiniImagenet, 5-way 1-shot, with a ResNet-18. The metric is the expectedinner product (left subfigures, represented by E[hi Thj] where hi stands for the representation vectorfor an input example xi). The metric is measured at the output of the feature extractor (6th block ofthe ResNet), and we show its measurement on 5 distinct tasks. The generalization (right subfigures)is averaged over 50 tasks.
Figure 15: Different metrics of the representation space may have strong correlation with generaliza-tion, other than the expected inner product of Eq. 2). a) Prototypical, VGG Flower, 5-way 1-shot: out of three metrics which in other cases may be related with generalization (as in b), c), d) andSec. ??), here only the expected l2 dispersion has a strong relation with generalization. b) Expectedl2 norm (Eq. 6); c) Expected square l2 dispersion (Eq. 7, Prototypical Network, VGG Flower; d)Expected feature-wise variance (Eq. 8), Prototypical Network, Omniglot to Quickdraw. These resultsmotivate our approach of considering a family of functions Ψ in which we must find the optimalfunction ψ* given the setting, rather than trying to discover a single universal metric that wouldcorrelate to generalization in all scenarios. Even if such metric exists, it may not be estimated withenough efficiency to satisfy the requirement of using only a single support set to estimate t*.
Figure 16: Task-wise variance : The maximum of the true average target accuracy (generalization) isat 57.7% with optimal early-stopping time t* at t = 14. a) Displaying the query accuracy of 50 targettasks. The estimated early-stopping time t}w-shot from the query accuracy of a single task has atask-wise standard deviation of 17.3 and a mean at t = 26.3. The resulting average generalizationis 54.5%; b) expected square l2 norm, 50 tasks. The metric exhibits very low task-wise standarddeviation of its estimated early-stopping time t*ψ (3.7) and a mean at t = 15.6. Resulting averagegeneralization is 57.4%, outperforming validation-based early-stopping. c) Histogram : HeW-ShOtshows high variance while t*ψ is mostly concentrated near t*. Setting used : MAML, CNN, Aircraft,5-way 1-shot.
Figure 17: Generalization can correlate to a metric at different levels of neural activations. Here thecritical layer l* (squared in red) is identified by searching for the highest divergence between thevalidation and target neural activation dynamics.
Figure 18: Divergence of the neural activation dynamics as an indication for early-stopping : MAML,Quickdraw to Omniglot, 5-way 1-shot. For 50 pairs of target and validation tasks, we measure allthe four metrics (expected inner product; expected square l2 norm; expected square l2 dispersion;feature-wise variance), at all the layers of the feature extractor. For each measurement (layer andmetric), we plot the divergence D (ψtarget, ψvalid) = 1 - r(ψtarget, ψvalid) (where r is the samplePearson correlation through time) against the obtained generalization performance (here for thisexample We simply use tψ = argmaxt ψtarget). a) while functions with low divergence may leadfrom very poor to very good performance, functions showing high divergence between the validationand target dynamics very likely lead to good performance; b) We illustrate this by dividing the pointsinto 10 bins along the divergence axis, and in each bin we average the divergence and performance,and plot the averages from the bins (blue curve) along with the standard deviations (blue dashed area).
