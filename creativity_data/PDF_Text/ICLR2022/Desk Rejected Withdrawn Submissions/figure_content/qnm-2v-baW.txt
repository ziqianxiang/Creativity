Figure 1: Our Poly-CAM process: the upsampled version of the saliency map in layer l is tunedbased on the class activation map of layer l - 1. Image samples correspond to the ’cat’ class, andare computed from VGG16.
Figure 2: Multiple classes on Poly-CAM. The different classes as correctly determined by the threevariants. We can note that PCAM- is less specific than the other methods (part of the mountain isattributed to the barn), while PCAM+ is the most specific.
Figure 3: Visual comparison of methods (see Figure 5 in appendix for full version). The comparedmethods are our three variants of Poly-CAM (PCAM+, PCAM-, PCAM±), Zoom-CAM (Shi et al.,2021), Layer-CAM(Jiang et al., 2021), Grad-CAM (Selvaraju et al., 2017), IntegratedGradient (Sun-dararajan et al., 2017), SmoothGrad (Smilkov et al., 2017), Occlusion (Zeiler & Fergus, 2014) andRISE (Petsiuk et al., 2018). A description of this figure is available in Section 4.3.2related to the class of interest. This is in line with the above observation that PCAM-, and abit lessPCAM±, are stronger in highlighting contextual information (see more examples in Appendix C).
Figure 4: Misclassification explanations. From right to left: original image, attention map, maskedimage, and their zoomed versions. (a) Image is misclassified as strawberry. The saliency mapexplains the wrong classification by highlighting a visual stimuli looking like a strawberry. (b)Image is missclassified as chainsaw, as explained by the saliency map.
Figure 5: Visual comparison of methods. The compared methods are the three Poly-CAM variantsproposed in this paper (PCAM+, PCAM-, PCAM±), Zoom-CAM (Shi et al., 2021), Layer-CAM(Jiang et al., 2021), Grad-CAM (Selvaraju et al., 2017), Grad-CAM++ (Chattopadhay et al., 2018),Smooth Grad-CAM++ (Omeiza et al., 2019), Score-CAM (Wang et al., 2020b), SS-CAM (Wanget al., 2020a), IS-CAM (Naidu et al., 2020), Input X Gradient (Shrikumar et al., 2016), Integrat-edGradient (Sundararajan et al., 2017), SmoothGrad (Smilkov et al., 2017), Occlusion (Zeiler &Fergus, 2014), RISE (Petsiuk et al., 2018).
Figure 11: Comparison of metrics as a function of the layer index for Poly-CAM vs CAM on isolatedlayers - VGG16. Last to first layer is represented left to right. This show that using CAM saliencymaps on early layers performs poorly.
Figure 12: Comparison of metrics as a function of the layer index for Poly-CAM vs CAM on isolatedlayers - ResNet50. Last to first layer is represented left to right. This show that using CAM saliencymaps on early layers performs poorly.
Figure 13: Visual comparison of PCAM± with and without LNorm. Without LNorm the visualisa-tion tends to concentrate on very focal elements of the images like eyes, mouth,... Sometime someelements of the image that are not in object of the target class become also highlighted, like an objectbehind the elephant, or the diver next to the shark.
Figure 15: Comparison of multiple classes on an image with two different cats and a carton forthe three Poly-CAM variants. The three methods correctly identify the two cats as different whenusing the Tabby cat and Persian cat classes, PCAM+ correctly separate the carton while PCAM-and PCAM± fail for this class.
Figure 16: Visualization of a Class Activation Map (Zhou et al., 2016) for the pathological labelon two bone X-Ray images from MURA dataset (Rajpurkar et al., 2017). Both images are labeledas pathological by the model, but only the left image show a bone fracture (manually annotated ingreen), the right image is clean of any fracture. The model seems to rely mostly on the plaster ratherthan on the absence of fracture to make a decisions. The model is a ResNet50 (He et al., 2016)initialised on ImageNet, trained on the MURA dataset (Rajpurkar et al., 2017) for 50 epochs withAdam optimizer, an initial learning rate of 6e-5 with a cosine Annealing scheduler without restart,weight decay at 1e-5. Images are resized to 320x320 with random rotation up to 15° during training.
Figure 17: Visual comparison of Class Activation Map (Zhou et al., 2016) and PCAM± on a XRayof a bone fracture from MURA dataset (Rajpurkar et al., 2017), for the pathological class label. Thebottom row is a zoom on the fracture area. Manual annotations for cortical irregularities and bonefragments (the main signs of the presence of a fracture on this XRay) are shown in red and greenovals. The Class Activation Map is not precise, it seems to include the bone fragment and the rightcortical irregularity but due to the low resolution, the highlighted area is very large and go far fromthe fracture. In comparison, PCAM± highlight smaller structures and seems to identify correctlythe cortical irregularities and the bone fragment on this image, being probably a greater help for aphysician. The model is a ResNet50 (He et al., 2016) initialised on ImageNet, trained on the MURAdataset (Rajpurkar et al., 2017) for 50 epochs with Adam optimizer, an initial learning rate of 6e-5 with a cosine Annealing scheduler without restart, weight decay at 1e-5. Images are resized to320x320 with random rotation up to 15° during training.
Figure 18: Faithfulness curves for Poly-CAM methods with VGG16 on the 2012 ILSVRC validationset. Comparison of the three variants of Poly-CAM.
Figure 20: Faithfulness curves for CAM-based methods with VGG16 on the 2012 ILSVRC vali-dation set. Comparison of our Poly-CAM methods with Grad-CAM (Selvaraju et al., 2017), Grad-CAM++ (Chattopadhay et al., 2018), Score-CAM (Wang et al., 2020b), SS-CAM (Wang et al.,2020a), IS-CAM (Naidu et al., 2020), Smooth Grad-CAM++ (Omeiza et al., 2019)Figure 19: Faithfulness curves for CAM-based methods with VGG16 on the 2012 ILSVRC vali-dation set. Comparison of our Poly-CAM methods with Grad-CAM (Selvaraju et al., 2017), Grad-CAM++ (Chattopadhay et al., 2018), Score-CAM (Wang et al., 2020b), IS-CAM (Naidu et al.,2020), Smooth Grad-CAM++ (Omeiza et al., 2019). SS-CAM (Wang et al., 2020a) was excluded inthis graph for ease of view26Under review as a conference paper at ICLR 2022Figure 21: Faithfulness curves for gradient and perturbation methods with VGG16 on the 2012ILSVRC validation set. Comparison of our PCAM± methods with gradient methods: Input XGradient (Shrikumar et al., 2016), Integrated Gradient (Sundararajan et al., 2017), SmoothGrad(Smilkov et al., 2017), and perturbation methods: Occlusion (Zeiler & Fergus, 2014) and RISE(Petsiuk et al., 2018)Figure 22: Faithfulness curves for Poly-CAM methods with ResNet50 on the 2012 ILSVRC valida-tion set. Comparison of the three variants of Poly-CAMFigure 23: Faithfulness curves for CAM-based methods with ResNet50 on the 2012 ILSVRC vali-dation set. Comparison of our Poly-CAM methods with Grad-CAM (Selvaraju et al., 2017), Grad-
Figure 19: Faithfulness curves for CAM-based methods with VGG16 on the 2012 ILSVRC vali-dation set. Comparison of our Poly-CAM methods with Grad-CAM (Selvaraju et al., 2017), Grad-CAM++ (Chattopadhay et al., 2018), Score-CAM (Wang et al., 2020b), IS-CAM (Naidu et al.,2020), Smooth Grad-CAM++ (Omeiza et al., 2019). SS-CAM (Wang et al., 2020a) was excluded inthis graph for ease of view26Under review as a conference paper at ICLR 2022Figure 21: Faithfulness curves for gradient and perturbation methods with VGG16 on the 2012ILSVRC validation set. Comparison of our PCAM± methods with gradient methods: Input XGradient (Shrikumar et al., 2016), Integrated Gradient (Sundararajan et al., 2017), SmoothGrad(Smilkov et al., 2017), and perturbation methods: Occlusion (Zeiler & Fergus, 2014) and RISE(Petsiuk et al., 2018)Figure 22: Faithfulness curves for Poly-CAM methods with ResNet50 on the 2012 ILSVRC valida-tion set. Comparison of the three variants of Poly-CAMFigure 23: Faithfulness curves for CAM-based methods with ResNet50 on the 2012 ILSVRC vali-dation set. Comparison of our Poly-CAM methods with Grad-CAM (Selvaraju et al., 2017), Grad-CAM++ (Chattopadhay et al., 2018), Score-CAM (Wang et al., 2020b), IS-CAM (Naidu et al.,2020), Smooth Grad-CAM++ (Omeiza et al., 2019). SS-CAM (Wang et al., 2020a) was excluded inthis graph for ease of view27
Figure 21: Faithfulness curves for gradient and perturbation methods with VGG16 on the 2012ILSVRC validation set. Comparison of our PCAM± methods with gradient methods: Input XGradient (Shrikumar et al., 2016), Integrated Gradient (Sundararajan et al., 2017), SmoothGrad(Smilkov et al., 2017), and perturbation methods: Occlusion (Zeiler & Fergus, 2014) and RISE(Petsiuk et al., 2018)Figure 22: Faithfulness curves for Poly-CAM methods with ResNet50 on the 2012 ILSVRC valida-tion set. Comparison of the three variants of Poly-CAMFigure 23: Faithfulness curves for CAM-based methods with ResNet50 on the 2012 ILSVRC vali-dation set. Comparison of our Poly-CAM methods with Grad-CAM (Selvaraju et al., 2017), Grad-CAM++ (Chattopadhay et al., 2018), Score-CAM (Wang et al., 2020b), IS-CAM (Naidu et al.,2020), Smooth Grad-CAM++ (Omeiza et al., 2019). SS-CAM (Wang et al., 2020a) was excluded inthis graph for ease of view27Under review as a conference paper at ICLR 2022Figure 24: Faithfulness curves for CAM-based methods with ResNet50 on the 2012 ILSVRC vali-dation set. Comparison of our Poly-CAM methods with Grad-CAM (Selvaraju et al., 2017), Grad-CAM++ (Chattopadhay et al., 2018), Score-CAM (Wang et al., 2020b), SS-CAM (Wang et al.,2020a), IS-CAM (Naidu et al., 2020), Smooth Grad-CAM++ (Omeiza et al., 2019)Figure 25: Faithfulness curves for gradient and perturbation methods with ResNet50 on the 2012ILSVRC validation set. Comparison of our PCAM± methods with gradient methods: Input X
Figure 22: Faithfulness curves for Poly-CAM methods with ResNet50 on the 2012 ILSVRC valida-tion set. Comparison of the three variants of Poly-CAMFigure 23: Faithfulness curves for CAM-based methods with ResNet50 on the 2012 ILSVRC vali-dation set. Comparison of our Poly-CAM methods with Grad-CAM (Selvaraju et al., 2017), Grad-CAM++ (Chattopadhay et al., 2018), Score-CAM (Wang et al., 2020b), IS-CAM (Naidu et al.,2020), Smooth Grad-CAM++ (Omeiza et al., 2019). SS-CAM (Wang et al., 2020a) was excluded inthis graph for ease of view27Under review as a conference paper at ICLR 2022Figure 24: Faithfulness curves for CAM-based methods with ResNet50 on the 2012 ILSVRC vali-dation set. Comparison of our Poly-CAM methods with Grad-CAM (Selvaraju et al., 2017), Grad-CAM++ (Chattopadhay et al., 2018), Score-CAM (Wang et al., 2020b), SS-CAM (Wang et al.,2020a), IS-CAM (Naidu et al., 2020), Smooth Grad-CAM++ (Omeiza et al., 2019)Figure 25: Faithfulness curves for gradient and perturbation methods with ResNet50 on the 2012ILSVRC validation set. Comparison of our PCAM± methods with gradient methods: Input XGradient (Shrikumar et al., 2016), Integrated Gradient (Sundararajan et al., 2017), SmoothGrad(Smilkov et al., 2017), and perturbation methods: Occlusion (Zeiler & Fergus, 2014) and RISE(Petsiuk et al., 2018)28Under review as a conference paper at ICLR 2022
Figure 23: Faithfulness curves for CAM-based methods with ResNet50 on the 2012 ILSVRC vali-dation set. Comparison of our Poly-CAM methods with Grad-CAM (Selvaraju et al., 2017), Grad-CAM++ (Chattopadhay et al., 2018), Score-CAM (Wang et al., 2020b), IS-CAM (Naidu et al.,2020), Smooth Grad-CAM++ (Omeiza et al., 2019). SS-CAM (Wang et al., 2020a) was excluded inthis graph for ease of view27Under review as a conference paper at ICLR 2022Figure 24: Faithfulness curves for CAM-based methods with ResNet50 on the 2012 ILSVRC vali-dation set. Comparison of our Poly-CAM methods with Grad-CAM (Selvaraju et al., 2017), Grad-CAM++ (Chattopadhay et al., 2018), Score-CAM (Wang et al., 2020b), SS-CAM (Wang et al.,2020a), IS-CAM (Naidu et al., 2020), Smooth Grad-CAM++ (Omeiza et al., 2019)Figure 25: Faithfulness curves for gradient and perturbation methods with ResNet50 on the 2012ILSVRC validation set. Comparison of our PCAM± methods with gradient methods: Input XGradient (Shrikumar et al., 2016), Integrated Gradient (Sundararajan et al., 2017), SmoothGrad(Smilkov et al., 2017), and perturbation methods: Occlusion (Zeiler & Fergus, 2014) and RISE(Petsiuk et al., 2018)28Under review as a conference paper at ICLR 2022F RobustnessTable 5: Sensitivity max table
Figure 24: Faithfulness curves for CAM-based methods with ResNet50 on the 2012 ILSVRC vali-dation set. Comparison of our Poly-CAM methods with Grad-CAM (Selvaraju et al., 2017), Grad-CAM++ (Chattopadhay et al., 2018), Score-CAM (Wang et al., 2020b), SS-CAM (Wang et al.,2020a), IS-CAM (Naidu et al., 2020), Smooth Grad-CAM++ (Omeiza et al., 2019)Figure 25: Faithfulness curves for gradient and perturbation methods with ResNet50 on the 2012ILSVRC validation set. Comparison of our PCAM± methods with gradient methods: Input XGradient (Shrikumar et al., 2016), Integrated Gradient (Sundararajan et al., 2017), SmoothGrad(Smilkov et al., 2017), and perturbation methods: Occlusion (Zeiler & Fergus, 2014) and RISE(Petsiuk et al., 2018)28Under review as a conference paper at ICLR 2022F RobustnessTable 5: Sensitivity max tableMethod	Sensitivity max		VGG16	ResNet50IntegratedGradient	0.3576	0.5299-InputXGrad	0.6132	0.7225SmoothGrad	5.6824	7.7777RISE	0.7864	0.7841-Occlusion	2.5176	3.4378
Figure 25: Faithfulness curves for gradient and perturbation methods with ResNet50 on the 2012ILSVRC validation set. Comparison of our PCAM± methods with gradient methods: Input XGradient (Shrikumar et al., 2016), Integrated Gradient (Sundararajan et al., 2017), SmoothGrad(Smilkov et al., 2017), and perturbation methods: Occlusion (Zeiler & Fergus, 2014) and RISE(Petsiuk et al., 2018)28Under review as a conference paper at ICLR 2022F RobustnessTable 5: Sensitivity max tableMethod	Sensitivity max		VGG16	ResNet50IntegratedGradient	0.3576	0.5299-InputXGrad	0.6132	0.7225SmoothGrad	5.6824	7.7777RISE	0.7864	0.7841-Occlusion	2.5176	3.4378GradCAM	0.0625	0.0212-GradCAM++	0.0525	0.0199SmoothGradCAM++	0.5451	0.1594ScoreCAM	0.0466	0.0193
Figure 26: Cascading randomization of VGG16. Sanity check on Poly-CAM methods (Adebayoet al., 2018). Progression from left to right show a complete randomization of the VGG16 model,starting by the last layer up to the first layer. The methods are sensible to model randomization,which mean they pass this sanity check. Itis interesting to note that the class specificity is lost rapidlyafter randomising the first classifier layer, then more and more features are lost while randomizationprogress up to the first layer of the networkFigure 27: Cascading randomization of VGG16. Sanity check on Poly-CAM methods (Adebayoet al., 2018). Progression from left to right show a complete randomization of the VGG16 model,starting by the last layer up to the first layer.
Figure 27: Cascading randomization of VGG16. Sanity check on Poly-CAM methods (Adebayoet al., 2018). Progression from left to right show a complete randomization of the VGG16 model,starting by the last layer up to the first layer.
Figure 28: Cascading randomization of VGG16. Sanity check on Poly-CAM methods (Adebayoet al., 2018). Progression from left to right show a complete randomization of the VGG16 model,starting by the last layer up to the first layer.
