Figure 1: Attacking an image classification model using the CIFAR10 dataset. Left: the victimmodel’s performance and the corresponding attack accuracy as functions of the training time. Right:the attack accuracy as a function of the order of the batches in the history of training.
Figure 2: RNN vs. feed-forward neural networks in deep reinforcement learning. Top left: trainingperformance vs. training time. Top right: validation performance vs. training time. Bottom left:attack accuracy vs. training time. Bottom right: attack accuracy as a function of the environmentseed when the agents are sequentially trained form seed 1 to 16.
Figure 3: Attacking a machine translation model using the Multi30K dataset. Left: the victimmodel’s performance and the corresponding attack accuracy as functions of training time whenusing the entirety of the dataset. Right: the attack accuracy as a function of the order of the batchesin the history of training. In comparison with the image classification agent in Figure 1, the earlybatches of the machine translation model are more vulnerable to the MIA than the early batches ofthe image classification model.
Figure 4: Benchmarking PVMIA against PRMIA using the SATED dataset. The victim model wastrained for 20 epochs at every training dataset size.
Figure 5: Benchmarking PVMIA against PRMIA using the Multi30K dataset. The victim modelwas trained for 20 epochs at every training dataset size.
Figure 6:	Benchmarking PVMIA against PRMIA using the SATED dataset.
Figure 7:	Benchmarking PVMIA against PRMIA using the Multi30K dataset.
