Figure 1: Illustration of the loss prediction pipeline (Kim et al., 2020). (a) Loss prediction forwhich transformation T to take on the corrupted image of "chiton" during testing. τa,b indicates thepredefined transformation of type a with its magnitude b. (b) Training algorithm of the loss predictorθLP. During the training, an input image x is transformed into all of the predefined transformationsτ to produce loss values yloss (τ (x)) by making predictions with the target network θtarget. Theseloss values are given to the loss predictor θLP as target values after softmax normalization and asSpearman correlation ranking loss (Engilberge et al., 2019). The loss predictor intakes the resizedinput image to learn the correlation between the target network results from the transformed imagesand the downsized original image condition.
Figure 2: Top: Comparison between the previous method (left) and the cyclic (right) loss predictionpipeline. Tt indicates the suggested transformation at iteration t. Bottom: Expanded illustration ofthe cyclic loss prediction. The input image of a "king snake" is corrupted with snow corruption. Theimage goes through iterative loss prediction cycles until it meets the exit signal. tτidentity indicatesthe iteration when the loss predictor suggests identity transformation, which is an exit signal.
Figure 3: Illustration of the 12 predefined transformations on an image of a bulbul from ImageNet.
Figure 4: Demonstration of the conventional TTA policies. The cost (number of input images)increases from 1 to 2, 5, and 10 as goes from center crop to horizontal flip, “5 crops", and “10 crops".
Figure 5: Illustration of the 19 different types of corruptions from ImageNet-C with a picture of aneagle.
Figure 6: Illustration of exemplary cases of the loss prediction pipeline.
Figure 7: Demonstration of EWM on two images from ImageNet-C with 10 crops TTA policy.
Figure 8: Demonstration of EWM on two images from ImageNet-C with baseline loss predictionTTA policy Kim et al. (2020) with single iteration of transformation prediction. 3 augmentationswere used as hyper parameter, resulting in 3 input images in total. Numerical value below the eachimage refers to relative entropy, calculated by the target network. Top: With a symmetrical padding,the zoom out transformation has presented more coherent level of feature in bird’s facial structure(i = 3), as it had minor cut by the border of the image. Bottom: An image of a yawl is also aided byzoom out transformation (i = 1), the padding has created the fake reflection of the yawl to the water,resulting in less entropy (uncertainty). The set of predefined transformation from previous methodwas used.
Figure 9: Demonstration of EWM on an images from ImageNet-C with our cyclic TTA method. 3augmentations were used as hyper parameter, resulting in 3 input images in total. Each image hastried to remove the Gaussian noise by performing blurring and zoom out. The entropy among theimages show somewhat relatively uniform values.
