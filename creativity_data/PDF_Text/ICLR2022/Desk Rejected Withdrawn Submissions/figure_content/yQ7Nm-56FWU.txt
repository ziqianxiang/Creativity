Figure 1: Construction of the objective LRR in Eq. (4)for training the RR module, which is the binary cross-entropy (BCE) loss between T-Con and R-Con.
Figure 2: PGD-10 examples filtered by confi-dence value of 2-ξ for each ξ. R-Con can sepa-rate correctly and wrongly classified examples.
Figure 3: The PGD-10 examples crafted on 10,000 test samples on CIFAR-10, and filtered by 1^2-ξconfidence threshold for each ξ. Here log2 τ = 0 (i.e., τ = 1) is the case shown in Fig. 2. Simplylower down the temperature τ can involve more samples into the area of certified separability.
Figure 4: We quantify the effects of temperature τ. The model is adversarially trained on CIFAR-10(no RR module used) and evaded by PGD-10. Left: TPR-95 accuracy with respect to confidence andT-Con. Right: Averaged confidence / T-Con value on correct / misclassified PGD-10 inputs.
Figure 5: Confidence values w.r.t. ξ-error values ofResNet-18 trained by PGD-AT+RR on CIFAR-10.
Figure 6: Accuracy (%) under adaptive PGD-500 (10 restarts)on CIFAR-10. The ResNet-18 is trained by PGD-AT+RR.
Figure 7: t-SNE visualization of the learned fea-tures on CIFAR-10. The irregular distributionsof adversarially learned features make previousstatistic-based detection methods less effective.
Figure 8: Reliability diagrams for an adversari-ally trained ResNet-18 on CIFAR-10, and the ex-pected calibration error (ECE) (Guo et al., 2017).
