Figure 1: (a) Sketch for the multi-variate interaction. The feature representation of a DNN can bedecomposed into interaction utilities of different visual concepts. (b) The cloud, as an entire object,is regarded as a cognitive concept, but the detailed textures inside the cloud are non-cognitive andforgettable. (c) Difference between boosting saliency and boosting cognition. Boosting saliencychanges the color of the flower to attract more attention, while boosting cognition makes flowersredder to be recognized more easily. Please see Appendix A for the detailed difference betweensaliency and cognitive concepts.
Figure 3: Cone-shaped templates for image revi-sion.
Figure 4: Comparisons between original images xori, images xc+og revised by strengthening cognitiveconcepts (minθ Loss2 (θ)), images xc-og revised by discarding cognitive concepts (maxθ Loss2 (θ)),and images X revised by strengthening cognitive concepts and weakening non-cognitive concepts(minθ Loss1(θ) + Loss2(θ)). We revised images from the ImageNet dataset and the MIT-Adobe 5Kdataset based on the VGG-16 model and the ResNet-18 model, respectively. Please see Appendix Gfor more results.
Figure 6: Difference between boosting saliency and boosting cognition. Boosting saliency changesthe color of the flower to make it more distinctive and attract more attention. In comparison, boostingthe cognition makes flowers redder to be recognized much more easily. xori represents the originalimage.
Figure 7: Visualization of the original image xori, the image xc+og revised by strengthening cognitiveconcepts (minθ Loss2(θ)), the image x- revised by Weakening concepts (minθ Loss1(θ) - Loss2 (θ)).
Figure 8: Comparisons between original images xori, images xc+og revised by strengthening cognitiveconcepts (minθ Loss2 (θ)), images xc-og revised by discarding cognitive concepts (maxθ Loss2 (θ)),and images X revised by strengthening cognitive concepts and weakening non-cognitive concepts(minθ Loss1(θ) + Loss2(θ)). We revised images from the ImageNet dataset based on the VGG-16model and the ResNet-18 model, respectively.
Figure 9: Comparisons between original images xori, images xc+og revised by strengthening cognitiveconcepts (minθ Loss2 (θ)), images xc-og revised by discarding cognitive concepts (maxθ Loss2 (θ)),and images X revised by strengthening cognitive concepts and weakening non-cognitive concepts(minθ Loss1 (θ) + Loss2(θ)). We revised images from the MIT-Adobe 5K dataset based on theVGG-16 model.
Figure 10: An example for the human measure of the cognitive difficulty. We asked each humanparticipant to sort thelcognitive difficulty of three images, including one original image, the imagerevised by strengthening cognitive concepts, and the image revised by weakening cognitive concepts.
Figure 11: (a) Aesthetic images usually contained more cognitive concepts than not so aestheticimages. (b) non-cognitive concepts in the smoothed images were weakened.
