Figure 1: Histograms and PDFs of the first two SPoSE dimensions after training.
Figure 2: Sample suit-flamingo-car triplet for the odd-one-out task. (Creative Commons; Authors:Janderk1968, Charles J. Sharp, and Wally Gobetz, respectively)2.2	SPOSESparse Positive object Similarity Embedding (SPoSE) (Zheng et al., 2019) is an approach for findinginterpretable item dimensions from an odd-one-out task. It does so by finding an embedding vectorxi = (xi1, . . . , xip) for every item ci. The similarity Sij of two items (e.g. ci and cj) is computedby the dot product of the corresponding embeddings (i.e. xi and xj), Sij = hxi, xji From thesesimilarities, the probability of choosing (yi1 , yi2) as the most similar pair of items given the itemtriplet {ci1 , ci2 , ci3} and given embedding vectors {xi1 , xi2 , xi3} is computed as:p((yi1 ,yi2)l{ci1 ,ci2,ci3}, {xi1 ,xi2,xi31) = exp(Siι,i2) + eXP(S：；j + exp(Si2.).	⑴SPoSE uses a maximum a posterori (MAP) estimation to find the most likely embedding given thetraining data and a prior:argmaxlogp(X|Dtrain) = argmaxlogp(Dtrain|X) +logp(X),	(2)XX1Link to anonymous GitHub repository: https://anonymous.4open.science/r/VICE- 59F03Under review as a conference paper at ICLR 2022where X is a matrix containing the embedding vectors for all of the items and p(X) is a prior for theembeddings, and p(Dtrain,j |X) is defined in (7). To induce sparsity in the embeddings, SPoSE usesa mean-field Laplace prior, leading to this objective:
Figure 3: KL divergences to empirical human probability distributions (left) and odd-one-out pre-diction accuracies (right) of VICE and SPoSE, each trained on differently sized subsamples of thetraining data. Error bands depict 95% CIs across the different splits of the data subsets.
Figure 4: Top six images in four sample VICE dimensions ("animal", categorical, "fire; smoke",functional, "wood; made of wood", structural, and "colorful", visual).
