Figure 1: By learning from a large amount of seen compositions and samples as references, AIsystems can extract the visual invariants to understand What is “red”, and use the learned knowledgeto recognize unseen compositional concepts. However, referential compositions and samples areusually insufficient when learning in realistic scenarios, making it more difficult to learn novel ele-ments from limited compositions. While humans can rapidly generalize to unknown pairs of novelprimitives in real-world environments, whether the artificial compositional learners can achieve suchhuman-level compositional generalization ability is still a question. In this paper, we propose a re-alistic and untouched task to explore whether existing learning algorithms can still generalize welldespite the limitations of few-shot and few referential compositions.
Figure 2: Left: Episodic baselines on RLCL. Middle: Non-episodic baselines on RLCL. We useL to denote the loss, fθ to denote the backbone, and kφ to denote two independent primitive classi-fiers or a joint compatibility classifier for compositions, depending on the specific method. Right:our refined-ProtoNet utilizes the class description Wp to adaptively separate features related to thecorresponding primitive p, which can be regarded as a rectification to the initial prototype v.
Figure 3: Left: HM (%) of different Ksc on the two datasets. Right: HM (%) of different seen-unseen composition ratios on RLCL-ATTR. As both the few-shot and few referential compositionschallenges become more extreme, the overall performance of these methods generally weakens.
Figure 4: Examples taken from each dataset forming RLCL-ATTR and RLCL-ACT.
Figure 5: Metrics of refined-ProtoNet on validation and test episodes as the training progresses. Weincreased the transparency of the original lines to highlight the smoothed version.
Figure 6:	Metrics of SymNet, CGE and our refined-ProtoNet when using different class descriptionson the two datasets.
Figure 7:	UA, SA and HM results (%) of different backbones on the two datasets. Methods usingside information take a pentagram (★) as the marker, and the methods not using side informationtake a dot (•) as the marker. Our refined-ProtoNet is marked with a red line.
