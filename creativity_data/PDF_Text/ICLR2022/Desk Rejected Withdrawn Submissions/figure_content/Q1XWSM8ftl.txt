Figure 1: Example of the effects of different learning rates for a simple model. Image Source:(Jordan, 2018)1Under review as a conference paper at ICLR 2022The selection of an appropriate learning rate is therefore a very important factor in the final perfor-mance of a model. Despite this, the traditional method for learning rate selection is either throughtrial and error based on prior knowledge, or through a more thorough “grid search”, whereby a rangeof learning rates are systematically tested. This methodology is inherently slow and imprecise, andcan occupy a significant amount of development time.
Figure 2: The loss achieved by the method of slowly increasing learning rates over a single trainingcycle of a model. The figure on the left shows the actual loss achieved by each batch, while thefigure on the right shows a weighted average of those weights. Image Source: (Gugger, 2018)In Smith (2015) this window was used to establish a cyclic learning rate scheduler, but it was laterused in Gugger (2018) to select an optimal learning rate. In that approach, they choose the pointin that window where the loss stops improving, then select a learning rate an order of magnitudebelow that point. This is the approach implemented in the popular machine learning library fast-ai(Howard et al.).
Figure 3: An example result of learning rates vs the loss achieved on a validation set. Learning rateis shown on the x axis, and loss is shown on the y axis.
Figure 4: The curvature for the graph shown in Figure 3, with learning rates shown on the x axis, andcurvature shown on the y axis. The vertical line is at mindr, the learning rate where first minimumof the curvature occurs.
Figure 5: Method 1 for selecting an optimal learning rate, at the log-midpoint of the viable learningrate window.
Figure 6: Method 2 for selecting an optimal learning rate, at the point where half of the possible lossreduction is achieved.
Figure 7: Selection process for method 3, choosing the point where the derivative of the loss is ata minimum. The graph on the left shows the first derivative of the loss curve, and the graph on theright shows where the point with a minimum derivative lies on the original curve.
Figure 8: An example of the learning rate/loss curve, when learning rates are evaluated in a strategicway, focusing on our points of interest.
Figure 9: Results of the learning rate search on 3 models, shown on a grid search graph, trainingeaCh learning rate to ConvergenCe. Method 1 is shown in orange, method 2 in blue, and method 3 ingreen. The viable window is indiCated by the orange dots.
