Figure 1: (a) Test accuracy vs. training rounds comparison. (b) The tuned learning rates and thecorresponding number of clients that use them. Derived after hand-tuning all clients. (c) Scalabilityof the number of training iterations that must be run to tune hyperparameters with varying number ofclients in the system.
Figure 2: (a) Hand-tuned vs. estimated learning rate (LR) under different heterogeneity index.
Figure 3: FedTune system design. Shows the major steps involved in the tuning process.
Figure 5: (a) Test accuracy of the global model achieved with hyperparameters derived at differentstages of tuning for the FEMNIST dataset. (b) Tuning iterations comparison across different datasets.
Figure 6: Final test accuracy comparison between global, FedTune with transferred dataset andFedTune on original dataset.
Figure 7: Final test accuracy comparison between global and FedTune when using LEAFâ€™s ( Caldaset al. (2018)) default distribution (LEAF Distr.) and when used with and without FedTune.
Figure 8: Sensitivity analysis of the hyperparameter search space as a function of HRT cells againsttest accuracy and cost using FEMNIST.
