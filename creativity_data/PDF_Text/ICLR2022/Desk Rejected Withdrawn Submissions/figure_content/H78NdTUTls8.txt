Figure 1: Schematic structure of receptorial andganglionic layers in retinaThe ganglionic activation pattern, however, isquite different from the hemiretinal receptorsone (1):〜〜	〜	C二 二	_ 二，， ，、	I	一一/	X — Z	X ,	.一	一 ,	、	, , 八R : E -→ R, R(x0, y0) =	K(u, v)R(u, v) dudv with G(x, y) = (x0, y0)Uρ(x,y)	(2)whereUP(χ,y) = {(u, V) ∈ R2 ： (u - χ)2 + (v - y)2 ≤ P},，±1 if (U — x)2 + (v — y)2 ≤ (ρ — e)2K(x, y) =、干1	if	(ρ	— e)2	<	(U	— x)2	+	(v	— y)2 ≤	ρ2The identification between E and E given by G is not a manifold morphism: in fact the corre-spondence between functions follows (4), which is an integral transform with kernel K(x, y). Thismodels effectively the mechanism of firing of hemiretinal receptors: for each activation disc we al-ways have an inhibition crown around it. This is the key mechanism, responsible for the border andcontrast enhancement, that we shall implement with our precortical module in Sec. 5.
Figure 2: Border percepts fora non continuous imageWe now come to the last portion of the visual pathway: the primary visual hemicortex, that we shallstill denote with V 1. The retinotopic map is a distance preserving homeomorphism between thehemiretinal receptorial layer and the primary visual hemicortex (see Adams & Horton (2003) for aconcrete realization). We can therefore identify V 1 with a compact domain V in R2 .
Figure 4: RetiLeNetstructure; n = imagecolor channels-X→ XXiXi Jσwith X the mean pixel value in the image. In this fashion Weobtain a modification in the image contrast.
Figure 5: New samples generated by contrast reduction via σ (left) and light dimming via μ (right).
Figure 6: Accuracy for μ, σ variations in MNISTFashionMNlST accuracy versus μ sweepFigure 7: Accuracy for μ, σ variations in FashionMNISTFashionMNIST accuracy versus σ sweep1.00.80.60.4SVHN accuracy versus μ sweepSVHN accuracy versus σ sweep1.00.80.60.4LeNet_5RetiLeNetLeNet_5RetiLeNet0.0 j~~I--1----1----1----1----1---1~~OCICCG-2.0 -1.5 -1.0 -0.5	0.0	0.5	1.0	1.5	2.0
Figure 7: Accuracy for μ, σ variations in FashionMNISTFashionMNIST accuracy versus σ sweep1.00.80.60.4SVHN accuracy versus μ sweepSVHN accuracy versus σ sweep1.00.80.60.4LeNet_5RetiLeNetLeNet_5RetiLeNet0.0 j~~I--1----1----1----1----1---1~~OCICCG-2.0 -1.5 -1.0 -0.5	0.0	0.5	1.0	1.5	2.00.0 -l.--------1--------1-------1--------1-------1--------1-------1--------Γj0.0	0.5	1.0	1.5	2.0	2.5	3.0	3.5	4.0
Figure 8: Accuracy for μ, σ variations in SVHN6 ConclusionsOur simple mathematical model of the low visual pathway of mammals retains the descriptive accu-racy of more complicated models and it is better suited to elucidate the similarities between visualphysiological structures and CNNs. The precortical neuronal module, inspired by our mathematicalmodeling, when added to a popular CNN (LeNet 5 ), gives a CNN RetiLeNet that mimics the borderand contrast enhancing effect as well as the mean light decorrelation action of horizontal-bipolarcells, retinal ganglions and LGN neurons. Hence such addition, which performed extremely wellon datasets with large variations of light intensity and contrasts, improves the CNN robustness withrespect to such variations in generated input images, strongly improving its inferential power ondata not belonging to the training statistics (Fig. 6, 7, 8). We believe that this strong improvement isdirectly correlated with the stabilizing action performed by the first precortical convolutional layer,in complete analogy with the behaviour of bipolar cells in the retina. We validate our hypothesesobtaining our results on MNIST, FashionMNIST and SVHN datasets.
Figure 9: Pixel value distributions before (red) and after (green) first precortical convolutional layerfor μ, σ variations in MNIST. (whiskers 1.5, violin kernel bandwidth 1.06)Figure 10: Pixel value distributions before (red) and after (green) first precortical convolutional layerfor μ, σ variations in FashionMNIST. (whiskers 1.5, violin kernel bandwidth 1.06)SVHN example	Bipolar cell hidden outputFigure 11: Pixel value distributions before (red) and after (green) first precortical convolutional layerfor μ, σ variations in SVHN. (whiskers 1.5, violin kernel bandwidth 1.06)9Under review as a conference paper at ICLR 2022ReferencesAlessandro Achille, Matteo Rovere, and Stefano Soatto. Critical learning periods in deep neuralnetworks. ArXiv, abs/1711.08856, 2017.
Figure 10: Pixel value distributions before (red) and after (green) first precortical convolutional layerfor μ, σ variations in FashionMNIST. (whiskers 1.5, violin kernel bandwidth 1.06)SVHN example	Bipolar cell hidden outputFigure 11: Pixel value distributions before (red) and after (green) first precortical convolutional layerfor μ, σ variations in SVHN. (whiskers 1.5, violin kernel bandwidth 1.06)9Under review as a conference paper at ICLR 2022ReferencesAlessandro Achille, Matteo Rovere, and Stefano Soatto. Critical learning periods in deep neuralnetworks. ArXiv, abs/1711.08856, 2017.
Figure 11: Pixel value distributions before (red) and after (green) first precortical convolutional layerfor μ, σ variations in SVHN. (whiskers 1.5, violin kernel bandwidth 1.06)9Under review as a conference paper at ICLR 2022ReferencesAlessandro Achille, Matteo Rovere, and Stefano Soatto. Critical learning periods in deep neuralnetworks. ArXiv, abs/1711.08856, 2017.
