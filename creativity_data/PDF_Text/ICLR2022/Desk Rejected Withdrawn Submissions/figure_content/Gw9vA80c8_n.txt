Figure 1: Comparison between our HyperCube approach and the state-of-the-art implicit field methodbased on the IM-NET Chen & Zhang (2019). IM-NET takes as an input 3D points sampled withinvoxels, while HyperCube leverages an interval arithmetic to process the entire voxels. As a result,HyperCube offers a high quality 3D object rendering without missing important parts of object closeto the implicit decoderâ€™s decision boundary, as done by IM-NET.
Figure 2: Comparison of the network architectures: (a) IM-NET, (b) HyperCube and (c) HyperCube-Interval. (a) IM-NET uses a binary classifier that takes a point coordinate (x, y, z) concatenated witha feature vector encoding a shape and outputs a value which indicates whether the point is outside theshape or not. IM-NET is a single neural network dedicated to all object from the training dataset. (b)HyperCube takes feature vectors and produce a new network, dubbed target network which classifiespoints sampled from voxel into one of two categories: inside or outside. For object reconstruction,only a target network run on a 3D cube is needed, which makes this solution significantly faster.
Figure 3: Interpolations produce by HyperCube. We take two 3d objects and obtain a smoothtransition between them.
Figure 4: Illustration of IntervalNet 3D interval (illustrated in 2D for clarity) is propagated throughMLP. At each layer, the 3D cube is deformed by linear transformation (FC layer). Then we constructinterval bound (marked by gray color) and use the ReLU activation function. Interval bound (in gray)is propagated to the next layer. In logit space, it becomes easy to compute an upper bound on theworstcase violation. Interval bound (in gray) is moved on one side of the decision boundary andconsequently transformed 3D cube (in green) is correctly classified. The figure is inspired by Fig. 2from (Gowal et al., 2018).
Figure 5: Comparison of training times and GPU memory used by IM-NET and HyperCube. OurHyperCube method offers over an order of magnitude decrease in both training time and memory.
Figure 6: Competition between models between architectures working on points (HyperCube) andinterval architecture (HyperCube-Interval). As we can see, IntervalNet can fill some empty spaces inmeshes.
Figure 7: We calculate the number of connected components produced by mesh obtained byarchitecture with intervals and without. Our HyperCube-Interval approach provides better models forclasses Airplane, Rifle, Car.
