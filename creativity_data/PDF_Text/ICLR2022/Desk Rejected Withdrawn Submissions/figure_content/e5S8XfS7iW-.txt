Figure 1: Overview of the proposed methodology. A set of neural units U is semantically alignedwith an ontology O through a pixel-level annotated dataset X, whose labels are in a two-way rela-tionship with the ontology concepts C. The relations S enable the retrieval of subgraphs composedof architecturally connected and semantically related units. Different colors stand for different visualconcepts, while grey units account for semantically unaligned neurons.
Figure 2: Example of mask generation for the higher-level concept of “animal” using ontologicalinformation. The induced taxonomy, built over the WordNet hypernymy (is-a) relation, enables theretrieval of the mask by exploiting the directly annotated masks for “dog” and “cat” from the Brodendataset.
Figure 3: Semantic alignment of unit 196 in the last residual block of ResNet-18. The examplesreported in (a) are the top ten images producing the maximum activations for the unit. Top-5 alignedconcepts in (b) and (c) are presented in increasing order, respectively for IoU and our probabilisticmeasure. While IoU captures concepts that are undoubtedly representative of the unit, our scoreidentifies visual concepts that describe the examples more precisely. As in the quantitative results,considering the average distance from the root of the retrieved concepts, the top-5 results using IoU,with depth 6.4, are more general than those obtained by our measure, with depth 8.0.
Figure 4: Importance analysis of circuit n. 105 from AlexNet, containing 105 distinct units and 12unique visual concepts. The circuit consists of units aligned to various concepts relative to clothingand commodities: subfigure (a) reports the aligned concepts within the WordNet taxonomy. Italicconcepts are not directly aligned, but we include them for visualization purposes. When ablating thecircuit, the accuracy drop significantly affects only a small number of classes. Subfigure (b) depictsthe histogram of categories of the Places-365 dataset as a function of accuracy drop (on the x-axis).
