Figure 1: OGN vs SOTA T-GNNs on Red-dit (+500k interactions). The horizontalaxis shows the relative training time for eachmethod as a multiple of OGNâ€™s runningtime. The vertical axis shows average pre-cision. OGN clearly outperforms the SOTAbut runs approximately 10 times faster thanTGN (Rossi et al., 2020) and 374 times fasterthan CAW1 (Wang et al., 2021).
Figure 2: T-GNNs: general framework to compute temporal node representations. For clarity,we illustrate an example for node u with L = 2. For an event with node v at time t, T-GNNs (i)iteratively sample a L-hop temporal neighborhood ofu (Sample), (ii) encode the continuous times-tamps (TimeEnc), (iii) iteratively aggregate the neighborhood information (Aggregate), and (iv)compute the final embedding of the resulting neighborhood information of node u (Readout).
Figure 3: Online Graph Nets (OGN). OGN maintains a state vector and a neighborhood summaryfor each node. For a node u, to predict for a new event with node v, OGN updates the state vectorof u using the neighborhood summary ru(n-1) and the information of the event (e(n) and t(n)), thenupdates its neighborhood information using the updated state vector of v . OGN performs this updatefor both nodes, and uses the resulting state vectors for inference.
Figure 4: Time/epoch vs average precision. We normalize the running time per epoch (train-ing+validation) of all models with respect to the execution time of OGN. In all cases, OGN nearlymatches or surpasses the SOTA. Also, OGN is the fastest method overall. For instance, OGN is twoorders of magnitude faster than CAW and at least one order of magnitude faster than TGAT.
Figure 5: (a) Effect of using regularly spaced timestamps (U -time) on TGAT, TGN and CAW.
Figure 6: Removing timestamps can hurt theperformance of T-GNNs. Both TGN (no-time) and TGAT (no-time) experience a sig-nificant performance drop on the UCI dataset.
