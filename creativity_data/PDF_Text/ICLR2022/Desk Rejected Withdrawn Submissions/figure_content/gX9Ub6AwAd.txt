Figure 1: Proposed Anomaly Detection NetworkThe end-to-end anomaly detection network shown in Fig. 1 has the following contributions:(1)	The video group composed of consecutive multiple frames is the basic processing unit to extractexpressive features with the designed group feature extractor. On the one hand, the spatial-temporalinformation could be retained comparing with single-image processing. On the other hand, the1Under review as a conference paper at ICLR 2022abnormality score of a single frame can be easily obtained without the access of the whole video,which can copy with the situation where video streams are the input.
Figure 2: The Group-Feature ExtractorSince the frame-group contains multiple continuous frames, in order not to destroy the time informa-tion within consecutive frames, we use a trainable convolution kernel to extract spatial informationof each single-frame in the time dimension. Then batch normalization Ioffe & Szegedy (2015) isused to prevent the gradient dispersion and accelerate the model convergence. Activation functionhelps to make the model nonlinear. Two sets of ”convolution-regular-activation” structures are usedin the experiments. The first group uses 128 convolution kernels with size of 5 × 5 and step size of3, and the second one uses 64 convolution kernels with size of 3 × 3 and step size of 2.
Figure 3: The map from group-features to group-scoresThe implicit vector method based attention mechanism assigns different weights to different featuresin order that the key features have a more important impact on the result and the interference ofnoise can be suppressed. The trainable transformation matrix will be used to project the originalgroup feature into the implicit space, and then the weight vector will be obtained by an inversetransformation matrix. Different from the attention mechanism aiming at multiple instances in Ilseet al. (2018), this paper focus on the attention of the group-feature. To be specific, the implicitvector is used to generate a weight vector of the original group, which has a dimension of 128 in theexperiment. Fgrp is the flattened Outt0 with length =1444. T represents transposition operation.
Figure 4: The models in training stageFig. 4 (a) shows changes of parameters during training stage. The train_loss represents the value ofthe compound loss function introduced in Section 3.3. The train_aCCUraCy is the ratio of the numberof correctly classified samples to the total number of samples. We end the training stage when thetrain_loss stays basically unchanged in 5 iterations. The accuracy rate basically does not changeafter the 12th epoch, so the best model occur after the 12th epoch.
Figure 5: The ROC curve frame-level and segment-level metrics of different algorithmsFig. 5 shows the metrics of different algorithms on the testing set using the threshold selected every0.01 between 0 and 1. accuracy is the proportion of samples that are detected correctly. Themaximum accuracy of the GRP is the best of all algorithms, followed by the ENC. While whenthe threshold is low, the ASH of ENC is indeed higher than GRP, but it should be noted that eachnetwork model has a different focus on abnormality scores, that is the threshold to classify a score asanomaly is different. It can be found that the optimal thresholds of the two networks are basically inthe high threshold area, where the ASH of GRP is greater than that of ENC, which is the reason whyGRP is superior in other metrics. It is worth noting that the ASH of VAE is ladder-shaped and isrelatively less affected by the threshold, which means that the score set of VAE is relatively sparse.
Figure 6: The detection result of different algorithms(c) AvenueThe threshold corresponding to the maximum point of the accuracy in Fig. 5 is used as the hyper-parameter of the algorithm to determine whether an abnormal event occurs in each frame. Thethreshold of spatio-temporal autoencoder is 0.68, and its corresponding accuracy is 0.725; thethreshold of our algorithm is 0.6, and its corresponding accuracy is 0.746. We use Fβ score toevaluate the performance of the algorithms under the specified threshold. The definition of Fβ scoreis shown in Equation (9).
Figure 7: The confusion matrix of different algorithmsThe numbers in Fig. 7 indicate the number of frames in the corresponding case. It can be seen fromFig. 7 that the GRP detects more abnormal frames with a higher number of both correct and wrongdetection than that of the ENC. Hence, the calculation of F1 score is necessary. The F1 score of theGRP is 0.577, while that of the ENC is 0.463. Therefore, when precision and recall are consideredtogether with a same weight, the performance of the GRP is slightly better than that of the ENC.
