Figure 1: The framework of proposed knowledge distillation for few-show image generation. Wetreat the source model as teacher and the target model as student. Two novel distillation modules areintroduced into the generator and discriminator respectively.
Figure 2: An illustration of the proposed Momentum Relation Distillation. Combined with theSSIM-A metric, the queue of instances generated by momentum model helps to capture more usefulinformation.
Figure 3: An illustration of the proposed Source Discrimination Distillation. The patch-discriminator of the target model is trained on both the source and target domain to enhance dis-crimination.
Figure 4: Visual results of 10-shot image adaptation, compared between CDC and our method. Withthe same latent code, our method can preserve more details from source domain with higher quality.
Figure 5: Patch Discriminator outputs of with and without SDD. The patch discriminator of withSDD has better discrimination than that of without SDD.
Figure 6: Results with different sizes of training set.
Figure 7: Generalization on different domains.
Figure 8: Experiments on FFHQ to other human face domains.
Figure 9: Experiments on face domains.
