Figure 1:	Extraneousness-Aware Imitation Learning. Overview figure of EIL. The overallframework contains 3 components: (a) encodes the state action pairs into representation throughcycle-consistency loss. (b) takes in the embeddings and process them with unsupervised voting-based alignment (UVA) algorithms. (c) performs visual imitation learning for the aligned stateaction pairs. We note that (b) can be a simple filtering algorithm when reference trajectories areavailable.
Figure 2:	Conceptual illustrations of the unsupervised voting-based alignment (UVA) algorithm.
Figure 3: The continuous control environments (a)(b)(c) and the “learning-from-slides” environment(d). Reach(a) and Push(b) are goal conditioned environments where success is declared when targetobject is close enough to destination. In Stir(c), success is declared if the end-effector trajectory issimilar to a target trajectory. The discrete control environment “learning-from-slides” (d) containsslides that demonstrates how to escape a maze but also contains completely irrelevant slides.
Figure 4:	Alignment plots for continuous control tasks. The x-axis is a test-time reference frames.
Figure 5:	Visualized result of our Unsupervised Voting-based Frame Alignment (UVA) method. Theextraneous frames in the video are successfully skipped and improves training results.
