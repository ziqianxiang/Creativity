Figure 1: (a) Learning settings comparison which differ by whatkind of information about target data is accessible. (b) Algorithmsensitivity in terms of the precision of feedbacksis viewed related to the setting of source-free Unsupervised Domain Adaptation (UDA) (Sahoo et al.,2020; Li et al., 2020a; Liang et al., 2020; Wang et al., 2020). As all these works do not considerdata privacy, target data would be easily extracted by back-doors model even tuning process is notobserved by model provider (Song et al., 2017). Federated Learning (FL) (Shokri & Shmatikov,2015) allows global model to fit local data by asking the derived gradients instead of uploading dataexternally. This thought is therefore used to fine-tune the general model to user private data (Popovet al., 2018). Although studied in a one-to-many sense, this setting seems as a workaround for our2Under review as a conference paper at ICLR 2022challenge. Unfortunately, data extraction can benefit from high-dimensional gradients, and the cleangradients promote the gradient inversion technique (Yin et al., 2021) as well. Notably, the proposedFTFB neither accesses target data features nor the corresponding labels; it instead only requireslimited evaluation performances of candidate models as feedbacks, such as test error or accuracy.
Figure 2: Example of FTFB optimized by PPS.
Figure 3: Performance comparison on (a) Adult and (b-c) Amazon. Note that ’good INI’ and ’badINI’ correspond to the different selections of vocabulary.
Figure 4: (a) Comparison of different model adaptation methods on CIFAR-10-C dataset for thehighest severity. (b) Performance of LCPS and Tent on CIFAR-10-C in terms of various corruptions.
Figure 5: Discrimination level reduction formodel fairness tuning.
Figure 6: Ablation study on three factors: batch size, support size, and layer importance (K queries).
Figure 7:	Overfitting problem when tuning the whole network on Amazon.
Figure 8:	Toy examples of FTFB without antithetic sampling for candidate model crafting. In (a)-(c),the batch size b is 80, 160, and 320, respectively, with the query budget of 8,000. In (d), the batchsize is 80 with the query budget of 16,000.
Figure 9: Random search results for high-dimensional parameters tuning.
