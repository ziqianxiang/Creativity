Figure 1: Illustration of the interactive neural process (INP). Given simulation parameters and data,INP trains a Neural Process model to infer the latent process. The inferred latent process allowsprediction and uncertainty quantification. The uncertainty is used to select the next set of parametersto query the simulator, and simulate more data.
Figure 2: Graphical model comparison: Neural Process, Sequential Neural Process and our Spa-tiotemporal Neural Process. The key difference lies in the inference of the latent variable zt . Thedistributions of zt for NP, SNP and STNP are q(zt |xt-1, xt, θt, A), q(zt|xt-1, xt, θt, z1:t-1, A), andq(zt |xo：t, θi:t, A) respectively. A is the adjacency matrix for the spatial graph, which is omitted inthe figure for simplicity. ht is the encoder hidden state and Ht is the decoder hidden state.
Figure 3: Neural Processes vs. Gaussian Processes for Bayesian active learning in SEIR compart-mental model. Left: uncertainty quantification comparison with the truth. Right: MAE loss versusthe percentage of data for both NP and GP using different acquisition functions.
Figure 4: NP Acquisition functions behavior visualization in 2D. For each iteration, top row representsthe current MAE mesh in infectious population for all (β, ε) candidates. Bottom row is the scoreevaluated by the acquisition function. Yellow dots are existing parameters. Red stars are the newlyselected parameters.
Figure 5: Left: INP predictions for the number of individuals in Infectious and Removed compart-ments in LEAM-US model. Right: acquisition function comparisons on the LEAM-US simulator.
Figure 6: Visualization of the STNP model architecture. For both the encoder and the decoder, weuse a diffusion convolutional GRU (DCGRU) Li et al. (2018) to capture spatiotemporal dependency.
Figure 7: MAE loss versus the percentage of data for SNL, NP and GP using different acquisitionfunctions.
Figure 8: Batch size comparisons for LIG on the LEAM-US simulator. MAE loss versus thepercentage of samples for INP during Bayesian active learning.
