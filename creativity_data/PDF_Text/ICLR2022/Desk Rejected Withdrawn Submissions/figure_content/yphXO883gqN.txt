Figure 1: Comparison of DGD and VAE methods in their simplest setups on CIFAR10. AModel search test learning curves of single Gaussian DGD (left) and VAE (right) trained on a CI-FAR10 subset (100 samples per class) for 50 epochs. Colors indicate individual models. B Violinplot of final test losses from models in A. Color-split shows train and test losses. Dashed linesindicate mean and standard deviations. C-F Reports on 4 out of 10 best models from A for eachmethod. VAEs are split into VanillaVAE and βVAE. Model information and results are shown insupplementaries A.4. C Final test reconstruction losses (MSE). D Latent space evaluation relativeto the prior Gaussian distribution. The left presents the normality statistics from the Shapiro Wilktest. Values close to 1 indicate no rejection of the null hypothesis. The right plots the ratio of latentspace values overlapping with values from a standard Gaussian (a in aL = L ∩ G) against the ratioof Gaussian space covered by the unique latent values (b in bG = L ∩ G). L represents latent space,G Gaussian space. E Distance preservation in latent space presented as correlation coefficients be-tween class-wise euclidean distances of latent class means and input data means. F FID scores asimage generation performance metric.
Figure 2: Test image reconstructions and generated images from DCGAN, DGD and VAE. Eachimage class is represented by its first sample in the CIFAR10 test split. All models were trained for500 epochs and saved every 50 epochs. The best stages were selected based on test reconstructionloss and quality of generated images. These stages are indicated in table 1. Generated imageswere achieved by randomly sampling from a standard Gaussian and fed into the decoder/generatormodules.
Figure 3: Representation space and samples from models trained with 20, 30, and 50 mix-ture components. The top row shows the two-dimensional representation space with the learnedrepresentations of the training samples and the means of the mixture components. Colors indicatethe class (numbers from 0 to 9). The bottom row shows 100 randomly sampled images from eachmodel. The models only differ in the number of components in the GMM.
Figure 4: A model trained with labelled mixture components. The top shows the learned repre-sentations of the training data (left) and 100 randomly sampled images (right). The bottom showsthe output images of the means of the mixture components. All images are binarized.
Figure 5: Relationship between latent dimension and scale of latent space Log-scaled standarddeviations of triplet (different random seeds) models are plotted against the log-scaled dimensional-ity of the latent space.
Figure 6: Generated images from class-specific latent spaced of the DGD.
