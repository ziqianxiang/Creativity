Figure 1: With the iterative generation of adversar-ial perturbations, the degree of LS decreases with apiecewise linear function.
Figure 2: (a) Prediction confidence difference of SSAT. Compared with other AT-based methods(e.g.
Figure 4: Accuracy with training epoch(Fig. 4(a)) and prediction confidence of clean and adversarialexamples based on Madry and SSAT(Fig. 4(b) and Fig. 4(c)). The example in Fig. 4(b) and Fig. 4(c)is randomly selected from CIFAR10 and its adversarial examples are generated by PGD and CWattacks.
Figure 3: The different loss trends for Madry andSSAT by varying the perturbation of PGD andCW attacks. Each row represents one defensemodel, and each column means one type of theattack. Each figure represents one attack appliedon one defense model with different perturbations.
Figure 5: Frequency of DLR defined inEq. 10 which is used to distinguish thetargeted or untargeted attack.
Figure 6: Robust accuracy under CW and PGD attacks for ablation study. SSAT is compared withSSAT model without considering subset dividend(w/o DB), without adaptive label(w/o Adap LS),without both DB and adaptive LS(Free AT), and with target regularization by varying the labelsmoothing degree.
Figure 7: (a) t-SNE results of PGD-based transfer and white-box attacks on Madry. Yellow and bluedots mean transfer attacks generated by other AT models and green star represents the white-boxattacks based on Madry. For each kind of attack, 2000 data points are randomly sampled over thewhole dataset CIFAR-10. (b) t-SNE results of white-box attacks on Madry with the same data pointsas (b). Adversarial data points with different labels are colored differently for clarity.
Figure 8: Frequency histogram of untargeted and targeted attack over different metrics.Note all theabove methods Can roughly distinguish targeted attaCks and untargeteded attaCks. We adopt votingstrategy to improve the distiguishment.
