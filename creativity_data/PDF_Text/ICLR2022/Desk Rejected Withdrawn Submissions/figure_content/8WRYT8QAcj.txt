Figure 1: COMBO learns a conservative value functionby utilizing both the offline dataset as well as simu-lated data from the model. Crucially, COMBO does notrequire uncertainty quantification, and the value func-tion learned by COMBO is less conservative on thetransitions seen in the dataset than CQL. This enablesCOMBO to steer the agent towards higher value statescompared to CQL, which may steer towards more opti-mal states, as illustrated in the figure.
Figure 2: Our image-based environments: The observations are 64 × 64 and 128 × 128 raw RGB images forthe walker-walk and sawyer-door tasks respectively. The sawyer-door-close environment usedin in Section 5.1 also uses the sawyer-door environment.
Figure 3: We visualize the fitted linear regression line between the modelerror and two uncertainty quantification methods maximum learned vari-ance over the ensemble (denoted as Max Var) on two tasks that test thegeneralization abilities of offline RL algorithms (halfcheetah-jumpand ant-angle). We show that Max Var struggles to predict the truemodel error. Such visualizations indicates that uncertainty quantificationis challenging with deep neural networks and could lead to poor perfor-mance in model-based offline RL in settings where out-of-distributiongeneralization is needed. In the meantime, COMBO addresses this issueby removing the burden of performing uncertainty quantification.
