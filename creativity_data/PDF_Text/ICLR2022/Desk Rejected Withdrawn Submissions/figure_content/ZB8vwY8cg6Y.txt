Figure 1: Plots of linear model performance by layer, organized by target variable (row) and sourcevariable (column). Orange and red dots are from linear models trained on the single-valued sourceprediction and source variable value, respectively.
Figure 3: Comparison of performance on all source tasks for a given target task. Each line representsone source task. Color is based on the best performance of that source task as a target task - blueis highest performance, red is lowest. Dotted lines show the performance when the source variableis the same as the target. Observe that for ‘height’ representations from other source tasks (in thiscase, self-reported sex and blood testosterone) are better predictors.
Figure 4: Cross-comparison of all tasks for layer 11. This layer was chosen as it was close to thebest layer for most models, and showed the most interesting variation between variables. Tasks areordered by hierarchical clustering. The bolded source task is a random baseline, where the sourceCNN was trained on labels drawn from the standard uniform distribution.
Figure 5: Network diagram of layer 11, connecting pairs of tasks with particularly good perfor-mance. The thickness of each line is determined by the ratio between the performance of a taskpair on this layer (see Fig 4), and the performance of that pair when the ”source” is the ground truthvalues. Lines are only shown if the ratio is above a threshold.
Figure 6: Shapes and size mixes used in synthetic image datasets.
Figure 7:	Cross-comparison heatmap of all tasks for layer 16.
Figure 8:	Best-performing layers for each task pair.
Figure 9:	Difference between shapes as a source and target task on layer 16. Each point is theperformance of a [source, target] pair where both source and target are aligned squares, minus thesame pair where both source and target are rotated squares (i.e. quadrant I - quadrant III from Fig7).
Figure 10: For each task pair, the layer of the source model that provided the best performance on thetarget task. 0 is earliest (closest to input), 18 is latest. Tasks are ordered by hierarchical clustering.
Figure 11: For each task pair, the layer of the source model that provided the best performance onthe target task. 0 is earliest (closest to input), 18 is latest. See main paper for task legend.
Figure 12: Cross-comparison of all tasks for linear models trained on the ground truth values foreach ”source task” (similar to simply calculating the correlation between the two tasks’ ground truthvalues, except that we used a train/test split like we did for the other figures. Tasks are ordered byhierarchical clustering.)15Under review as a conference paper at ICLR 2022Figure 13: Cross-comparison of all tasks for different layers of the source model. Tasks are orderedby hierarchical clustering, which is done separately for each layer.
Figure 13: Cross-comparison of all tasks for different layers of the source model. Tasks are orderedby hierarchical clustering, which is done separately for each layer.
Figure 14: Cross-comparison of all tasks for different layers of the source model. Tasks are orderedby hierarchical clustering, which is done separately for each layer.
Figure 15: Cross-comparison of all tasks for different layers of the source model. Tasks are orderedby hierarchical clustering, which is done separately for each layer.
