Figure 1: (a) Visualization of Non-IID data. (b) Normalized structural hamming distance (SHD)S(1)of learned DAG, where MCSL(SeP) (Ng et al., 2019) separately trains model on local datasetwhile MCSL(All) trains one model on all data, which however is forbidden in FL.
Figure 2: An overview of DS-FCD. Each solid-line box includes CD on each local client. For clientck, the CGL part includes a continuous proxy UCk and gτ(∙), the GUmbel-Sigmoid function, whichmaps Uck to approximate the binary causal graph. The CMA part uses Φck, a neural network, toapproximate the causal mechanisms. XCk represents observations on Ck and XCk is the predicteddata. X ck firstly goes through the CGL part to select the parental variables and then the CMA partto get XCk. The server coordinates the FL procedures by leveraging U among clients.
Figure 3: The sensitivity analysis of hyper-parametersTable 6 work well in our method. Our method also adopts a `1 sparsity term on gτ (U), where thesparsity coefficient λ'ι is chosen as 0.01 for all settings.
Figure 4: Comparisons with NOTEARS on linear data (IID).
Figure 5: Anatomical causal-effect relationships of fMRI Hippocampus datasetTable 18: Empirical results on fMRI Hippocampus dataset (Part 2).
Figure 6: The visualization of simulated Non-IID data with 10 variables, where 6 variables arerandomly selected and two of them are chosen for one subfigure.
Figure 7: Normalized distribution of real data used in this paper.
