Figure 1: Demonstration of our overall framework for learning an object detector from noisy cap-tions (best viewed in color). In pre-training (A), we learn an explicit region-token alignment alongwith other auxiliary objectives that require multimodal understanding. We transfer learned visualbackbone along with the projection weights that are used for region-token alignment into down-stream task (B), and perform cross-modal instance discrimination utilizing randomly-sampled cap-tions to force our backbone not to forget the region-token alignment learned during pre-training.
Figure 2: Distribution of Î² values in MS COCO.
