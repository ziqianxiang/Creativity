Figure 1: An overview of meta-learning training. Yellow nodes are inputs to the meta-model, greennodes are outputs by the meta-model, and black nodes represent intermediate variables. (a) Theworkflow of meta-learning, where a set of meta-training tasks are sampled from p(T), and a task-specific model φi is updated by the support set si , then meta-knowledge θ is optimized on thelikelihood of query sets {qi}iN=1. (b) The causal graph of meta-learning, where θ0 and θ are theinitialization learned from last step and current step, respectively.
Figure 2: Simplified causal graphs of meta-training and deconfounded methods. (a) simplifiedcausal graph among Y , θ0 and θ. (b) deconfounded meta-knowledge. (c) simplified causal graphamong Y , θ0, Φ and θ. (d) deconfounded by frontdoor adjustment. See Figure 4 in Appendix A.2for complete causal graphs.
Figure 3: Ablation study.
Figure 4: Complete causal graph of Figure 2b and Figure 2d. (a) The complete causal graph ofaugmentation-based methods. (b) The complete causal graph of the frontdoor adjustment.
Figure 5: Hyperparameter analysis in (a - b) Bins Number (c - d) Dropout Rate.
