Figure 1: Architecture of our multi-task learning algorithm. It has three stages. In Candidate Generation Stage, it makessure the candidates are related to their source videos. In Multi-objective Learning Stage, it uses CFs with ALS to learnlinear relationship, and uses Two-tower DNNs to learn non-linear relationship. And the Coordinating Networks control thetraining flow. In Merging and Ranking Stage, firstly for each objective, it uses the maximum of non-linear and linear score,and let a module learn weights of multiple objectives, then get the final ranking score by weighted sum.
Figure 2: calculating the similarity score between two videos4.2 Multitask Learning StageFor multiple objectives learning stage, there are multiple CFs with ALS algorithm and 2-tower DNNs executingparallel training tasks, each of them is optimizing one single objective. Before they start to train, there is amodule called Coordinating Networks, which control a sample goes to which CF or 2-tower DNN. The structureof CN is shown in Figure 3. The CN is a multiple classifier with 2 hidden layers. And the number of output neuronequals the number of ranking objectives. Each output neuron represents the probability that the input samplebelongs to this class. A sample only with a probability higher than t to a certain objective can go its subsequentCF or 2-tower DNN. CN uses data from all classes for training, so it can reduce noises for multi-task learning.
Figure 3: Structure of Coordinating NetworksNext are CFs and 2-tower DNNs. CF looks into the set of items uses have rated, but unlike UCF and ICF,as a matrix factorization technique, ALS learns the latent factors which can represent both users and items.
Figure 4: ALS Collaborative Filtering ComputationNext we need to define a loss function of U and V, which is the root mean square error (RSME), and minimizeit to get the optimized matrices. Therefore,RMSE = √1∑u,v∖(ou,v-Pu,v)2∖ ,	(3)where , and , are observed and predicted clicks for user u and video v respectively [24]. Andpredicted value can be computed by:Puv = < ui, R > ,	(4)Therefore in order to minimize RMSE, we formulate this problem to obtain the optimized latent factor vectors(%,必):(Ui, Vj) = min∑(ij)∈κ(θij - PiJ)2 + "||%||2 + 陋『)，(5)where the lambda part is a Tikhonov regularization to solve overfitting.
Figure 5: get latent factors of items by ALS trainingMeanwhile, we construct a two-tower DNN for each objective as shown in Figure 6. We revised the Youtubeversion to make it more suitable for our scenario [8]. After building each tower, we use Cosine function tocompute the similarity between User Tower and Candidate Tower:similarity = cos(θ)_ u∙c-MIlCl∑⅛1%×QJ∑k(uM×J∑ 匕(CM(6)AND we use the typical Log Loss function for minimizing.
Figure 6: Revised Two-tower DNN4.3 Merging and Ranking StageThe merging stage is to generate the final result. Firstly, we use the maximum of their linear and non-linearsimilarity score because CF and DNN are two different solutions, and either of them with a high score is a strongrelationship indicator. Secondly, there is a weights learning module. The detail is a Logistic Regression, usingmulti-classes outputs from CN, and use users’ one week retention as label. In other words, we use whether auser stay or not as label to train and get weights of different objectives. Thirdly, We also keep an a^ whichindicates the manually set weight by domain expertise. For example, if you consider the Likes more important,you can give it a higher weight. After all, given a source Uideoi, the final ranking score with UideOj can beformulated as:Ranking scorei,j = ∑αzz the ObejCtiVeS ak*wk* si,j ,	(7)We can define the following generative process:1.	Given a source video and a target video for objective 1, get maximum of their linear and non-linearsimilarity score, as shown in Figure 7.
Figure 7: Combine linear and non-linear relationships5	EXPERIMENT RESULTSIn this section, we introduce the A/B experiments of our proposed multi-objective learning algorithm torecommend related videos on one of the largest video sharing platforms, BiliBili. By using historical user-videointeractions including click, played time, rating, comment, dislike and so on, we train our MTL algorithm, andconduct both offline and live experiments.
Figure 8: Recommending related videos on BiliBili5.1	Experiment SetupWe use TensorFlow2 to build the training and predicting of the model. We train both our MTL and baselinemodels.
