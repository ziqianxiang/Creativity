Figure 1:	The comparisons of margin distribution and loss curves. CIFAR-10 (ResNet20): a) and b)show the curves for batch size 128 and 8,192. CIFAR-100 (WRN28-10): c) and d) show the curvesfor batch size 128, and 8,192. The left axis is margin and right axis is loss. The dotted vertical linesindicate the epoch in which the loss plateaus (no improvement for 10 epochs).
Figure 2:	Simplified example illustrations of two possible cases in which the training loss increasestogether with the principal Hessian Eigenvalue: a) The model jumps to the opposite side in the samevalley or b) the model jumps out of the current valley and moves to another sharper valley.
Figure 3: A principle Hessian Eigenvalue comparison between large-batch and two-phase.
Figure 4: CIFAR-10 (ResNet20) learning curves comparison. The hyper-parameters are shown inTable 2.
Figure 6: SVHN (WideReSNet16-8) learning curves comparison. The hyper-parameters are shownin Table 4.
Figure 5: CIFAR-100 (WideResNet28-10) learning curves comparison. The hyper-parameters areshown in Table 3.
Figure 7: ImageNet (ResNet50) learning curves comparison. The hyper-parameters are shown inTable 5.
