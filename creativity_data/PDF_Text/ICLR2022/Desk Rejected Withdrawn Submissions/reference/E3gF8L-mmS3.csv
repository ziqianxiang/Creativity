title,year,conference
 Tensorflow: A system for large-scale machine learning,2016, In 12th {USENIX} Symposium on Operating Systems Design and Imple-mentation ({OSDI} 16)
 Adversarial Attack Vulnerability of Medical ImageAnalysis Systems: Unexplored Factors,2021, Medical Image Analysis
 Decision-Based Adversarial Attacks: Reli-able Attacks Against Black-Box Machine Learning Models,2018, arXiv:1712
 Albumentations: Fast and flexible image augmentations,2078, Information-an International Interdisciplinary Journal
 Adversarial Examples Are Not Easily Detected: Bypassing TenDetection Methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Se-curity
 Towards Evaluating the Robustness of Neural Networks,2017, In2017 IEEE Symposium on Security and Privacy (SP)
 On Evaluating AdversarialRobustness,2019, arXiv:1902
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, arXiv:2003
 Improved Regularization of Convolutional Neural Net-works with Cutout,2017, arXiv:1708
 Deep Learning,2016, Adaptive Computation andMachine Learning
 Explaining and Harnessing AdversarialExamples,2015, arXiv:1412
 Enhancing Transformation-Based Defenses Against Adversarial Attacks with a Distribution Classifier,2020, In Eighth Interna-tional Conference on Learning Representations
 A compact network learning model fordistribution regression,893, Neural Networks
 Certified Adversarial Robustness withAdditive Noise,2019, arXiv:1809
 Focal Loss for DenseObject Detection,2017, arXiv:1708
 Under-standing adversarial attacks on deep learning based medical image analysis systems,31, PatternRecognition
 DeepFool: A Simple andAccurate Method to Fool Deep Neural Networks,2016, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Adversarial robustness toolbox v1,2018,2
 Explaining Adversarial Vulnerability with a Data SparsityHypothesis,2021, arXiv:2103
 Clev-erhans v2,2016,0
 Distillation asa Defense to Adversarial Perturbations against Deep Neural Networks,2016, arXiv:1511
 Practical Black-Box Attacks against Machine Learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 DeflectingAdversarial Attacks with Pixel Deflection,2018, In 2018 IEEE/CVF Conference on Computer Visionand Pattern Recognition
 Defense-GAN: Protecting ClassifiersAgainst Adversarial Attacks Using Generative Models,2018, arXiv:1805
 Intriguing properties of neural networks,2014, arXiv:1312
 Mitigating AdversarialEffects Through Randomization,2018, arXiv:1711
 Feature Denoisingfor Improving Adversarial Robustness,2019, In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition
 A SurveyOn Universal Adversarial Attack,2021, arXiv:2103
 Confusing and Detecting ML Adversarial At-tacks with Injected Attractors,2021, arXiv:2003
