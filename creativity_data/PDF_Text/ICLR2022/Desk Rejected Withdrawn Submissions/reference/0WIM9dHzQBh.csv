title,year,conference
 The security of machinelearning,0885, Mach
 Detecting backdoor attacks on deep neural networks byactivation clustering,2018, arXiv preprint arXiv:1811
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, arXiv preprint arXiv:1712
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv preprint arXiv:1708
 The algorithmic foundations of differential privacy,2014, Foundationsand Trends in Theoretical Computer Science
 Witchesâ€™ brew: Industrial scale data poisoning via gradient matching,2020, arXivpreprint arXiv:2009
 Maxup: A simple way to improvegeneralization of neural network training,2020, arXiv preprint arXiv:2002
 Badnets: Identifying vulnerabilities in themachine learning model supply chain,2017, arXiv preprint arXiv:1708
 Metapoison: Practicalgeneral-purpose clean-label data poisoning,2020, arXiv preprint arXiv:2004
 InstaHide: Instance-hiding Schemes forPrivate Distributed Learning,4507, In International Conference on Machine Learning
 Stronger data poisoning attacks break datasanitization defenses,2018, arXiv preprint arXiv:1811
 Synthesizingdifferentially private datasets using random mixing,2019, In 2019 IEEE International Symposium onInformation Theory (ISIT)
 Deep partition aggregation: Provable defense against generalpoisoning attacks,2020, arXiv preprint arXiv:2006
 Data poisoning against differentially-private learners:Attacks and defenses,2019, arXiv preprint arXiv:1903
 Towards poisoning of deep learning algorithms with back-gradientoptimization,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 How to break anonymity of the netflix prize dataset,2006, arXivpreprint cs/0610105
 Label sanitization against label flippingpoisoning attacks,2018, In Joint European Conference on Machine Learning and Knowledge Discoveryin Databases
 Justhow toxic is data poisoning? a unified benchmark for backdoor and data poisoning attacks,2020, arXivpreprint arXiv:2006
 Poison frogs! targeted clean-label poisoning attacks on neural networks,2018, arXivpreprint arXiv:1804
 Spectral signatures in backdoor attacks,2018, arXivpreprint arXiv:1811
 Spectral signatures in backdoor attacks,2018, arXivpreprint arXiv:1811
 Clean-label backdoor attacks,2018, arXiv
 Subsampled renyi differentialprivacy and analytical moments accountant,2019, In The 22nd International Conference on ArtificialIntelligence and Statistics
 Rab: Provable robustness againstbackdoor attacks,2020, arXiv preprint arXiv:2003
 mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
