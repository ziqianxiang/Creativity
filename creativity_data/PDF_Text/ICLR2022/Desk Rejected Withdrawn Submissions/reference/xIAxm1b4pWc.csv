title,year,conference
 Arabert: Transformer-based model for arabic lan-guage understanding,2020, arXiv preprint arXiv:2003
 Sentiment classifi-cation in bangla textual content: A comparative study,2020, arXiv e-prints
 BERT: pre-training of deepbidirectional transformers for language understanding,2018, CoRR
 Cross-culturalpolarity and emotion detection using sentiment analysis and deep learning on covid-19 relatedtweets,2020, IEEEAccess
 Supervised multimodalbitransformers for classifying images and text,2019, arXiv preprint arXiv:1909
 RoBERTa: A ro-bustly optimized BERT pretraining approach,2019,	CoRR
 Transformer based deepintelligent contextual embedding for twitter sentiment analysis,2020, Future Generation ComputerSystems
 Tweetbert: A pretrained language representationmodel for twitter text analysis,2020, arXiv preprint arXiv:2010
 Languagemodels are unsupervised multitask learners,2019, 2019
 Hybrid model using stack-based ensemble classifier and dic-tionary classifier to improve classification accuracy of twitter sentiment analysis,2020, InternationalJournal
 CARER: Con-textualized affect representations for emotion recognition,2018, In Proceedings of the 2018 Confer-ence on Empirical Methods in Natural Language Processing
 Polarity classification of tweets considering the postersemotional change by a combination of naive bayes and lstm,2019, In International Conference onComputational Science and Its Applications
 Attention is all you need,2017, CoRR
 Research on text sen-timent analysis based on attention c_mgu,2020, In Jing Liu
 Huggingfaceâ€™s trans-formers: State-of-the-art natural language processing,2019, ArXiv
 XLNet: generalized autoregressive pretraining for language understanding,2019, CoRR
 Sentibert: A transferable transformer-based architecturefor compositional sentiment semantics,2020, arXiv preprint arXiv:2005
 The state-of-the-art in twittersentiment analysis: A review and benchmark evaluation,2018, ACM Transactions on ManagementInformation Systems (TMIS)
