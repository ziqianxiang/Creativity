title,year,conference
 The lottery ticket hypothesis for pre-trained bert networks,2020, arXiv preprintarXiv:2007
 Imagenet: A large-scalehierarchical image database,2009, In Computer Vision and Pattern Recognition
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Stabilizing thelottery ticket hypothesis,2019, arXiv preprint arXiv:1903
 Linear modeconnectivity and the lottery ticket hypothesis,2020, In International Conference on Machine Learning
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Filter pruning via geometric median fordeep convolutional neural networks acceleration,2019, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Acceleratedsparse neural training: A provable and efficient method to find n: m transposable masks,2021, arXivpreprint arXiv:2102
 Packing sparse convolutional neural networks forefficient systolic array implementations: Column combining under joint optimization,2019, 24th ACMInternational Conference on Architectural Support for Programming Languages and OperatingSystems
 Optimal brain damage,1990, In Advances in neuralinformation processing systems
 Snip: Single-shot network pruningbased on connection sensitivity,2018, arXiv preprint arXiv:1810
 Pruning filters forefficient convnets,2016, International Conference on Learning Representations
 Rethinking the value ofnetwork pruning,2018, arXiv preprint arXiv:1810
 Decoupled weight decay regularization,2017, arXiv preprintarXiv:1711
 Autopruner: An end-to-end trainable filter pruning method for efficientdeep model inference,2020, Pattern Recognition
 Pruning convolutionalneural networks for resource efficient inference,2016, arXiv preprint arXiv:1611
 One ticket to win them all: general-izing lottery ticket initializations across datasets and optimizers,2019, arXiv preprint arXiv:1906
 Comparing rewinding and fine-tuning in neuralnetwork pruning,2020, arXiv preprint arXiv:2003
 Movement pruning: Adaptive sparsity byfine-tuning,2020, arXiv preprint arXiv:2005
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Glue:A multi-task benchmark and analysis platform for natural language understanding,2018, arXiv preprintarXiv:1804
 Picking winning tickets before training bypreserving gradient flow,2020, arXiv preprint arXiv:2002
 Learning structured sparsity indeep neural networks,2016, In Advances in Neural Information Processing Systems
 Rethinking the smaller-norm-less-informativeassumption in channel pruning of convolution layers,2018, arXiv preprint arXiv:1802
 Drawing early-bird tickets: Towards more efficient trainingof deep networks,2019, arXiv preprint arXiv:1909
 Learning n:m fine-grained structured sparse neural networks from scratch,2021, InInternational Conference on Learning Representations
 Discrimination-aware channel pruning for deep neural networks,2018, arXiv preprintarXiv:1810
