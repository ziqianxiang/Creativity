title,year,conference
 Post-training 4-bit quantization ofconvolution networks for rapid-deployment,2018, arXiv preprint arXiv:1810
 Estimating or propagating gradients through stochasticneurons for conditional computation,2013, In arXiv:1308
 Eyeriss: An energy-efficient re-configurable accelerator for deep convolutional neural networks,2016, IEEE Journal of Solid-StateCircuits
 Pact: Parameterized clipping activation for quantizedneural networks,2018, In arXiv
 ImageNet: A large-scalehierarchical image database,2009, In CVPR
 Hawq: Hessianaware quantization of neural networks with mixed-precision,2019, In arXiv
 Releq: A reinforcement learning approach for deep quantization of neuralnetworks,2018, In NeurIPS Workshop on ML for Systems
 Learned step sizequantization,2020, In ICLR
 Rate distortion for model compression:From theory to practice,2102, In International Conference on Machine Learning
 Vector quantization and signal compression,1991, In Kluwer Academic Pub-lishers
 Learning both weights and connections forefficient neural networks,2015, arXiv preprint arXiv:1506
 Deep residual learning for image recognition,2016, In CVPR
 Neural network quantization with scale-adjusted training,2020, BMVC
 In-datacenter performance analysis of a tensor processing unit,2017, In Proceedings ofthe 44th Annual International Symposium on Computer Architecture
 Learning to quantize deep networks by optimizing quantiza- tion intervalswith task loss,2019, In CVPR
 ImageNet classification with deep convolutional neuralnetworks,2012, In NIPS
 Deep learning,2015, In Nature
 Additive powers-of-two quantization: An efficient non-uniform discretization for neural networks,2020, In ICLR
 Autoq: Automated kernel-wise neuralnetwork quantizations,2020, In ICLR
 Adaptive loss-aware quantization formulti-bit networks,2020, In arXiv
 Scale-sim: Systolic CNN accelerator,2018, CoRR
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In arXiv
 Reinforcement learning: An introduction,2018, MIT press
 Mixed precision dnns: All you need is a goodparametrization,2019, arXiv preprint arXiv:1905
 HAQ: Hardware-aware automatedquantization with mixed precision,2019, In CVPR
 Mixedprecision quantization of convnets via differentiable neural architecture search,2019, In ICLR
 Fracbits: Mixed precision quantization via fractional bit-widths,2020, arXivpreprint arXiv:2007
 Lq-nets: learned quantization for highly accurate and compactdeep neural networks,2018, In ECCV
 Distribution-aware adaptive multi-bit quantization,2021, In CVPR
 Linear symmetric quantizationof neural networks for low-precision integer hardware,2020, ICLR
 Optimizing the bit allocation for com-pression of weights and activations of deep neural networks,2019, In ICIP
 Dorefa-net: Training low bitwidth convolu-tional neural networks with low bitwidth gradients,2016, In arXiv preprint arXiv:1606
 Adaptive quanti-zation for deep neural network,2018, In AAAI
 Towards effective low-bitwidth convolutional neural networks,2018, In cvpr
 Training quantized neuralnetworks with a full-precision auxiliary module,2020, In CVPR
