title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th Interna-tional Conference on Machine Learning
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Boost-ing adversarial attacks with momentum,2018, In IEEE Conference on Computer Vision and PatternRecognition
 Evading defenses to transferable adversarialexamples by translation-invariant attacks,2019, In IEEE Conference on Computer Vision and PatternRecognition
 Patch-wise attack forfooling deep neural network,2020, In European Conference on Computer Vision
 Explaining and harnessing adversarialexamples,2015, In 3rd International Conference on Learning Representations
 Countering adversarialimages using input transformations,2018, In 6th International Conference on Learning Representa-tions
 Deep residual learning for image recog-nition,2016, In IEEE Conference on Computer Vision and Pattern Recognition
 Certified robustness for top-k predictions against adversarial perturbations via randomized smoothing,2020, In 8th InternationalConference on Learning Representations
 ComDefend: An efficient imagecompression model to defend adversarial examples,2019, In IEEE Conference on Computer Vision andPattern Recognition
 Accelerating stochastic gradient descent using predictive variancereduction,2013, In Advances in Neural Information Processing Systems 26: 27th Annual Conferenceon Neural Information Processing Systems 2013
 Adversarial machine learning at scale,2017, In5th International Conference on Learning Representations
 Defenseagainst adversarial attacks using high-level representation guided denoiser,2018, In IEEE Conferenceon Computer Vision and Pattern Recognition
 Nesterov acceleratedgradient and scale invariance for adversarial attacks,2020, In 8th International Conference on LearningRepresentations
 Delving into transferable adversarial exam-ples and black-box attacks,2017, In 5th International Conference on Learning Representations
 Feature distillation:Dnn-oriented JPEG compression against adversarial examples,2019, In IEEE Conference on ComputerVision and Pattern Recognition
 Universaladversarial perturbations,2017, In IEEE Conference on Computer Vision and Pattern Recognition
 A self-supervised approach for adversarial robustness,2020, In IEEE Conference on Computer Vision andPattern Recognition
 The limitations of deep learning in adversarial settings,2016, In 2016 IEEE European Sympo-sium on Security and Privacy (EuroS&P)
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia conference on computer and communications security
 Improving the generalization ofadversarial training with domain adaptation,2019, In 7th International Conference on Learning Repre-sentations
 Robust local features forimproving the generalization of adversarial training,2020, In 8th International Conference on LearningRepresentations
 Intriguing properties of neural networks,2014, In 2nd International Conferenceon Learning Representations
 Re-thinking the inception architecture for computer vision,2016, In IEEE Conference on Computer Visionand Pattern Recognition
 Ensemble adversarial training: Attacks and defenses,2018, In 6th International Conferenceon Learning Representations
 On adaptive attacks toadversarial example defenses,2020, Advances in Neural Information Processing Systems
 Enhancing the transferability of adversarial attacks through variancetuning,2021, In IEEE Conference on Computer Vision and Pattern Recognition
 Mitigating adversarialeffects through randomization,2018, In 6th International Conference on Learning Representations
 Feature denois-ing for improving adversarial robustness,2019, In IEEE Conference on Computer Vision and PatternRecognition
 Feature squeezing: Detecting adversarial examples in deepneural networks,2018, In The Network and Distributed System Security
 Adversar-ially robust generalization just requires more unlabeled data,2019, CoRR
