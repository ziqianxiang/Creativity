title,year,conference
 Sparsely-connected neural networks: To-wards efficient VLSI implementation of deep neural networks,2017, In 5th International Conferenceon Learning Representations
 Cer-tifying geometric robustness of neural networks,2019, In Annual Conference on Neural InformationProcessing Systems
 Enhancing robustness ofmachine learning systems via data transformations,2018, In 52nd Conference on Information Sciencesand Systems
 Unrestricted adversarialexamples via semantic manipulation,2020, In 8th International Conference on Learning Representa-tions
 Aunified view of piecewise linear neural network verification,2018, In Advances in Neural InformationProcessing Systems 31
 Adversarial examples are not easily detected: Bypassingten detection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Enabling certification of verification-agnostic networks via memory-efficient semidefiniteprogramming,2020, In Advances in Neural Information Processing Systems (NeurIPS)
 Imagenet: A large-scalehierarchical image database,2009, In IEEE conference on computer vision and pattern recognition
 Formal verification of piece-wise linear feed-forward neural networks,2017, In DeepakDâ€™Souza and K
 An abstraction-based framework forneural network verification,2020, In Shuvendu K
 Ef-ficient and accurate estimation of lipschitz constants for deep neural networks,2019, In Advances inNeural Information Processing Systems 32
 AI2: safety and robustness certification of neural networks with abstract interpre-tation,2018, In IEEE Symposium on Security and Privacy
 Explaining and harnessing adversarialexamples,2015, In 3rd ICLR
 Unravellingrobustness of deep learning based face recognition against adversarial attacks,2018, In Proceedings of34th AAAI
 Scalable verified trainingfor provably robust image classification,2019, In IEEE/CVF International Conference on ComputerVision
 Deep residual learning for image recog-nition,2016, In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Semantic adversarial examples,2018, In IEEE Conference onComputer Vision and Pattern Recognition Workshops
 Semantic adversarialattacks: Parametric transformations that fool deep classifiers,2019, In International Conference onComputer Vision
 Reluplex: Anefficient SMT solver for verifying deep neural networks,2017, In 29th Computer Aided VerificationConference
 Learning multiple layers of features from tiny images,2009, CoRR
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in Neural Information Processing Systems 25
 Gradient-based learning applied to document recog-nition,1998, In Proceedings of the IEEE 1998;86(11):2278e324
 Differentiable abstract interpretation forprovably robust neural networks,2018, In Proceedings of the 35th International Conference on MachineLearning ICML
 Scalingpolyhedral neural network verification on gpus,2021, In Proceedings of Machine Learning and Systems3
 Towards verifying ro-bustness of neural networks against A family of semantic perturbations,2020, In IEEE/CVF Conferenceon Computer Vision and Pattern Recognition
 An abstraction-refinement approach to verification of artificialneural networks,2010, In Computer Aided Verification
 Challenging SMT solvers to verify neural networks,2012, In AICommun
 Semidefinite relaxations for certifying robust-ness to adversarial examples,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Scalable polyhedral verification of recurrent neural networks,2021, In Computer AidedVerification - 33rd International Conference
 In Proc,2019, ACM Program
 Second-order Provable defenses against adversarial attacks,2020, In Pro-ceedings of the 37th International Conference on Machine Learning
 Strivingfor simPlicity: The all convolutional net,2015, In 3rd International Conference on Learning Represen-tations
 Evaluating robustness of neural networks with mixedinteger Programming,2019, In 7th International Conference on Learning Representations
 Efficient formal safetyanalysis of neural networks,2018, In 31th Advances in Neural Information Processing Systems
 Formal security analysisof neural networks using symbolic intervals,2018, In 27th USENIX Security Symposium
 Feature-guided black-box safety testingof deeP neural networks,2018, In 24th Tools and Algorithms for the Construction and Analysis ofSystems TACAS
 Parallelization techniques forverifying neural networks,2020, In In Formal Methods in Computer Aided Design
 Automatic Perturbation analysis for scalable certifiedrobustness and beyond,2020, In Advances in Neural Information Processing Systems 33
 Black-box certificationwith randomized smoothing: A functional oPtimization based framework,2020, In Advances in NeuralInformation Processing Systems 33
 Scalable certified seg-mentation via randomized smoothing,2021, In Proceedings of the 38th International Conference onMachine Learning
