title,year,conference
 Transformer models for textcoherence assessment,2021, ArXiv
 Modeling local coherence: An entity-based approach,2008, Computa-tional Linguistics
 Modeling local coherence: An entity-based approach,2005, InProceedings of the 43rd Annual Meeting on Association for Computational Linguistics
 Languagemodels are few-shot learners,2020, ArXiv
 Deep communicating agents forabstractive summarization,2018, In Proceedings of the 2018 Conference of the North American Chap-ter of the Association for Computational Linguistics: Human Language Technologies
 A simple frameworkfor contrastive learning of visual representations,2020, ArXiv
 Transformer-xl:Attentive language models beyond a fixed-length context,2019, In ACL
 Extending the entity grid with entity-specific features,2011, In Pro-ceedings of the 49th Annual Meeting of the Association for Computational Linguistics: HumanLanguage Technologies: Short Papers - Volume 2
 Summeval: Re-evaluating summarization evaluation,2020, arXiv preprintarXiv:2007
 Hierarchical neural story generation,2018, In Proceedingsof the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Pa-pers)
 Extending the entity-based coherence model with multipleranks,2012, In Proceedings of the 13th Conference of the European Chapter of the Association forComputational Linguistics
 The impact of deep hierarchical discourse struc-tures in the evaluation of text coherence,2014, In COLING
 Centering: A framework for modeling the local coherence ofdiscourse,1995, Comput
 Noise-contrastive estimation: A new estimation principlefor unnormalized statistical models,2010, In Yee Whye Teh and Mike Titterington (eds
 Achieving human parity onautomatic chinese to english news translation,2018, ArXiv
 Momentum contrast forunsupervised visual representation learning,2019, arXiv preprint arXiv:1911
 Teaching machines to read and comprehend,2015, In NIPS
 Dense passage retrieval for open-domain question answering,2020, ArXiv
 Computing krippendorffâ€™s alpha-reliability,2011, 2011
 Has machine translation achieved human parity? acase for document-level evaluation,2018, In EMNLP
 Neural net models of open-domain discourse coherence,2017, In Proceedingsof the 2017 Conference on Empirical Methods in Natural Language Processing
 Automatically evaluating text coherence using dis-course relations,2011, In Proceedings of the 49th Annual Meeting of the Association for ComputationalLinguistics: Human Language Technologies - Volume 1
 Generative adversarialnetwork for abstractive text summarization,2017, ArXiv
 Rethinking coherencemodeling: Synthetic vs,2021, downstream tasks
 A unified neural coherencemodel,2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Process-ing and the 9th International Joint Conference on Natural Language Processing
 A deep reinforced model for abstractive summa-rization,2018, ArXiv
 Deep contextualized word representations,2018, In Proc
 Better language models and their implications,2019, OpenAI Blog
 A structured review of the validity of BLEU,2018, Computational Linguistics
 An entity-driven framework for abstractivesummarization,2019, In Proceedings of the 2019 Conference on Empirical Methods in Natural Lan-guage Processing and the 9th International Joint Conference on Natural Language Processing(EMNLP-IJCNLP)
 Tackling the story ending biasesin the story cloze test,2018, In ACL
 EvaluatingDocument Coherence Modeling,2307, Transactions of the Association for Computational Linguistics
 Representation learning with contrastive predictivecoding,2018, ArXiv
 Attention is all you need,2017, In I
 On mutual informationin contrastive learning for visual representations,2020, ArXiv
 Approximate nearest neighbor negative contrastive learning for dense textretrieval,2020, ICLR
 A cross-domain transferable neural coherence model,2019, In Proceedings ofthe 57th Annual Meeting of the Association for Computational Linguistics
 Xlnet: Gener-alized autoregressive pretraining for language understanding,2019, In NeurIPS
 Dialogpt: Large-scale generative pre-training for conversationalresponse generation,2020, In ACL
