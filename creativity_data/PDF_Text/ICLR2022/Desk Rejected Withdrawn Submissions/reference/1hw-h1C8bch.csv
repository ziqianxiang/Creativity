title,year,conference
 Deep learning with differential privacy,2016, In Proceedings of the 2016ACM SIGSAC conference on computer and communications security
 Obfuscated gradients give a false senseof security: Circumventing defenses to adversarial examples,2018, In International conferenceon machine learning
 Gradient masking and theunderestimated robustness threats of differential privacy in deep learning,2021, arXiv preprintarXiv:2105
 Deep learning with gaussian differentialprivacy,2020, Harvard data science review
 Fast and memory efficient differentially private-sgd via jl pro-jections,2021, arXiv preprint arXiv:2102
 On the convergence of deep learning withdifferential privacy,2021, arXiv preprint arXiv:2106
 The secretsharer: Evaluating and testing unintended memorization in neural networks,2019, In 28th{USENIX} Security Symposium ({USENIX} Security 19)
 Ex-tracting training data from large language models,2020, arXiv preprint arXiv:2012
 Certified adversarial robustness via ran-domized smoothing,1310, In International Conference on Machine Learning
 Reliable evaluation of adversarial robustness withan ensemble of diverse parameter-free attacks,2020, In International conference on machinelearning
 Gaussian differential privacy,2021, Journal of theRoyal Statistical Society
 Trends Theor,2014, Comput
 Explaining and harnessingadversarial examples,2014, arXiv preprint arXiv:1412
 Numerical composition of differentialprivacy,2021, arXiv preprint arXiv:2106
 On calibration of modern neuralnetworks,2017, In International Conference on Machine Learning
 Understanding the interplay betweenprivacy and robustness in federated learning,2021, arXiv preprint arXiv:2106
 Using pre-training can improve modelrobustness and uncertainty,2019, In International Conference on Machine Learning
 Certified adversarial robustnesswith additive noise,2019, Advances in Neural Information Processing Systems
 Towards deep learning models resistant to adversarial attacks,2017, arXiv preprintarXiv:1706
 Learning differentiallyprivate recurrent language models,2017, arXiv preprint arXiv:1710
 How to break anonymity of the netflix prizedataset,2006, arXiv preprint cs/0610105
 Scalable differen-tial privacy with certified robustness in adversarial learning,2020, In International Conferenceon Machine Learning
 Membership infer-ence attacks against machine learning models,2017, In 2017 IEEE Symposium on Security andPrivacy (SP)
 Privacy risks of securing machine learningmodels against adversarial examples,2019, In Proceedings of the 2019 ACM SIGSAC Confer-ence on Computer and Communications Security
 One pixel attack for foolingdeep neural networks,2019, IEEE Transactions on Evolutionary Computation
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprintarXiv:1705
 Robustness threats of dif-ferential privacy,2020, arXiv preprint arXiv:2012
 Optimal accounting of differential privacyvia characteristic function,2021, arXiv preprint arXiv:2106
