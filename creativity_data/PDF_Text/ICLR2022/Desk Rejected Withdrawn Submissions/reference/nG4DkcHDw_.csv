title,year,conference
 A smart healthcare monitoring system for heart disease prediction basedon ensemble deep learning and feature fusion,2020, Information Fusion
 Unlabeleddata improves adversarial robustness,2019, In NeurIPS
 Detecting backdoor attacks on deep neural networks byactivation clustering,2018, arXiv preprint arXiv:1811
 Deepinspect: A black-box trojandetection and mitigation framework for deep neural networks,2019, In IJCAI
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, arXiv preprint arXiv:1712
 Refit:a unified watermark removal framework for deep learning systems with limited data,2021, In AsiaCCS
 BERT: pre-training of deepbidirectional transformers for language understanding,2019, In NAACL
 Trojan attack on deepgenerative models in autonomous driving,2019, In International Conference on Security and Privacyin Communication Systems
 Explaining and harnessing adversarialexamples,2015, In ICLR
 Badnets: Identifying vulnerabilities in themachine learning model supply chain,2017, arXiv preprint arXiv:1708
 Tabor: A highly accurate approachto inspecting and restoring trojan backdoors in ai systems,2019, arXiv preprint arXiv:1908
 Deep residual learning for image recog-nition,2016, In CVPR
 Membership inference attacks onmachine learning: A survey,2021, arXiv preprint arXiv:2103
 On the effectiveness of adversar-ial training against common corruptions,2021, arXiv preprint arXiv:2103
 Backdoor attack withsample-specific triggers,2020, arXiv preprint arXiv:2012
 Fine-pruning: Defending against back-dooring attacks on deep neural networks,2018, In International Symposium on Research in Attacks
 Removing backdoor-based watermarks in neuralnetworks with limited data,2021, In ICPR
 Input-aware dynamic backdoor attack,2020, In NeurIPS
 Invisible poison: A blackbox clean labelbackdoor attack to deep neural networks,2021, In INFOCOM
 Sok: Security andprivacy in machine learning,2018, In EuroS&P
 Deep k-nn defense against clean-label data poisoning attacks,2020, In ECCV
 A taxonomy and survey of attacks against machine learning,2019, Computer ScienceReview
 Adversarial robustness through locallinearization,2019, In NeurIPS
 Hidden trigger backdoor at-tacks,2020, In AAAI
 Poison frogs! targeted clean-label poisoning attacks on neural networks,2018, InNeurIPS
 Masteringthe game of go with deep neural networks and tree search,2016, nature
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Certified defenses for data poisoning attacks,2017, InNeurIPS
 Intriguing properties of neural networks,2014, In ICLR
 Spectral signatures in backdoor attacks,2018, In NeurIPS
 Neural cleanse: Identifying and mitigating backdoor attacks in neural networks,2019, In IEEES&P
 Practicaldetection of trojan neural networks: Data-limited and data-free cases,2020, In ECCV
 On theconvergence and robustness of adversarial training,2019, In ICML
 On the trade-off between adversar-ial and backdoor robustness,2020,2020
 Adversarial weight perturbation helps robust gener-alization,2020, In NeurIPS
 Adversarialexamples improve image recognition,2020, In CVPR
 Attacks which do not kill training make adversarial learning stronger,2020, In ICML
 Understanding the interaction of adversarial training with noisylabels,2021, arXiv preprint arXiv:2102
