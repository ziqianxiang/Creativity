title,year,conference
 Spinning sequence-to-sequence models with meta-backdoors,2021, arXiv preprint arXiv:2107
 How tobackdoor federated learning,2020, In International Conference on Artificial Intelligence and Statistics
 Detecting backdoor attacks on deep neural networks byactivation clustering,2018, arXiv preprint arXiv:1811
 Mitigating backdoor attacks in lstm-based text classificationsystems by backdoor keyword identification,2021, Neurocomputing
 Poisonink: Robust and invisible backdoor attack,2021, arXiv preprint arXiv:2108
 Deepinspect: A black-box trojandetection and mitigation framework for deep neural networks,2019, In IJCAI
 Badnl: Backdoorattacks against nlp models,2020, arXiv preprint arXiv:2006
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, arXiv preprint arXiv:1712
 Sentinet: Detecting localized universalattacks against deep learning systems,2020, In 2020 IEEE Security and Privacy Workshops (SPW)
 Characterizations of an empirical influence function fordetecting influential cases in regression,1980, Technometrics
 A backdoor attack against lstm-based text classifica-tion systems,2019, IEEE Access
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Februus: Input purification defenseagainst trojan attacks on deep neural network systems,2020, In Annual Computer Security ApplicationsConference
 Quantum entropy scoring for fast robust mean estimationand improved outlier detection,2019, Advances in Neural Information Processing Systems
 Robust anomaly detection and backdoor attack detection viadifferential privacy,2019, arXiv preprint arXiv:1911
 Defending against backdoor attacks in natural language generation,2021, arXiv preprintarXiv:2106
 Badnets: Identifying vulnerabilities in themachine learning model supply chain,2017, arXiv preprint arXiv:1708
 Badnets: Evaluating backdooringattacks on deep neural networks,2019, IEEE Access
 Spectre: Defending againstbackdoor attacks using robust statistics,2021, arXiv preprint arXiv:2104
 Badencoder: Backdoor attacks to pre-trainedencoders in self-supervised learning,2021, arXiv preprint arXiv:2108
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Understanding black-box predictions via influence functions,2017, InInternational Conference on Machine Learning
 Universal litmus patterns:Revealing backdoor attacks in cnns,2020, In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition
 Invisible backdoorattacks on deep neural networks via steganography and regularization,2020, IEEE Transactions onDependable and Secure Computing
 Backdoor embedding inconvolutional neural network models via invisible perturbation,2018, arXiv preprint arXiv:1808
 Composite backdoor attack for deep neuralnetwork by mixing existing benign features,2020, In Proceedings of the 2020 ACM SIGSAC Conferenceon Computer and Communications Security
 Fine-pruning: Defending against back-dooring attacks on deep neural networks,2018, In International Symposium on Research in Attacks
 Trojaning attack on neural networks,2017, 2017
 Abs:Scanning neural networks for back-doors by artificial brain stimulation,2019, In Proceedings of the2019 ACM SIGSAC Conference on Computer and Communications Security
 Pair the dots: Jointly exam-ining training history and test stimuli for model interpretability,2020, arXiv preprint arXiv:2010
 Input-aware dynamic backdoor attack,2020, arXiv preprintarXiv:2010
 Bleu: a method for automaticevaluation of machine translation,2002, In Proceedings of the 40th annual meeting of the Associationfor Computational Linguistics
 Onion: A simple and effectivedefense against textual backdoor attacks,2020, arXiv preprint arXiv:2011
 Hidden killer: Invisible textual backdoor attacks with syntactic trigger,2021, arXiv preprintarXiv:2105
 Turn the combination lock:Learnable textual backdoor attacks via word substitution,2021, arXiv preprint arXiv:2106
 Defending neural backdoors via generative distributionmodeling,2019, arXiv preprint arXiv:1910
 Backdooring and poisoning neural networks with image-scalingattacks,2020, In 2020 IEEE Security and Privacy Workshops (SPW)
 Hidden trigger backdoor at-tacks,2020, In Proceedings of the AAAI Conference on Artificial Intelligence
 Baaan:Backdoor attacks against autoencoder and gan-based machine learning models,2020, arXiv preprintarXiv:2010
 Recursive deep models for semantic compositionality over a sentimenttreebank,2013, In Proceedings of the 2013 conference on empirical methods in natural language pro-cessing
 Spectral signatures in backdoor attacks,2018, arXivpreprint arXiv:1811
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Confoc: Content-focus protection against trojanattacks on neural networks,2020, arXiv preprint arXiv:2007
 Concealed data poisoning attacks on nlpmodels,2020, arXiv preprint arXiv:2010
 On certifying robustness against backdoorattacks via randomized smoothing,2020, arXiv preprint arXiv:2002
 Neural cleanse: Identifying and mitigating backdoor attacks in neural networks,2019, In 2019IEEE Symposium on Security and Privacy (SP)
 Rab: Provable robustness againstbackdoor attacks,2020, arXiv preprint arXiv:2003
 Backdoor attackagainst speaker verification,2021, In ICASSP 2021-2021 IEEE International Conference on Acoustics
 Character-level convolutional networks for textclassification,2015, In NIPS
 Trojaning language models for fun andprofit,2020, arXiv preprint arXiv:2008
 Clean-label backdoor attacks on video recognition models,2020, In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition
 Gangsweep: Sweep out neu-ral backdoors by gan,2020, In Proceedings of the 28th ACM International Conference on Multimedia
