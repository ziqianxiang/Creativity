title,year,conference
 Fairnessin representation: quantifying stereotyping as a representational harm,2019, In Proceedings of the 2019SIAM International Conference on Data Mining
 Differential tweet-ment: Mitigating racial dialect bias in harmful tweet detection,2021, In Proceedings of the 2021 ACMConference on Fairness
 Aifairness 360: An extensible toolkit for detecting and mitigating algorithmic bias,2019, IBM Journal ofResearch and Development
 Saying goodbye to Civil Comments,2017, https://medium
 Curran Associates Inc,9781, ISBN 9781510838819
 Nuancedmetrics for measuring unintended bias with real data for text classification,2019, In Companion ofThe 2019 World Wide Web Conference
 The frontiers of fairness in machine learning,2018, arXivpreprint arXiv:1810
 Lever-aging labeled and unlabeled data for consistent fair binary classification,2019, Advances in NeuralInformation Processing Systems
 ELECTRA: pre-training text encoders as discriminators rather than generators,2020, In 8th International Conferenceon Learning Representations
 The trouble with bias,2017, https://www
 Funnel-transformer: Filter-ing out sequential redundancy for efficient language processing,2020, In Hugo Larochelle
 Stereotype and skew: Quantifying gender bias in pre-trained and fine-tuned languagemodels,2021, In Proceedings of the 16th Conference of the European Chapter of the Associationfor Computational Linguistics: Main Volume
 Bert: Pre-training of deep bidi-rectional transformers for language understanding,2019, In NAACL-HLT
 Fairnessthrough awareness,2012, In Proceedings of the 3rd innovations in theoretical computer science confer-ence
 A confidence-based approach for balancing fair-ness and accuracy,2016, In Proceedings of the 2016 SIAM International Conference on Data Mining
 Intrinsic bias metrics do not correlate with application bias,2021, In Proceedings of the59th Annual Meeting of the Association for Computational Linguistics
 On calibration of modern neuralnetworks,2017, In Doina Precup and Yee Whye Teh (eds
 Equality of opportunity in supervised learning,2016, Advancesin neural information processing systems
 DeBERTa: decoding-enhancedBERT with disentangled attention,2021, In 9th International Conference on Learning Representations
 Characterisingbias in compressed models,2020, ArXiv
 Social biases in NLP models as barriers for persons with disabilities,2020, In Proceedingsof the 58th Annual Meeting of the Association for Computational Linguistics
 Wasserstein fairclassification,2020, In Uncertainty in Artificial Intelligence
 Decision theory for discrimination-awareclassification,2012, In 2012 IEEE 12th International Conference on Data Mining
 Multiaccuracy: Black-box post-processing forfairness in classification,2019, In Proceedings of the 2019 AAAI/ACM Conference on AI
 Confronting abusive language on-line: A survey from the ethical and human rights perspective,2021, Journal of Artificial IntelligenceResearch
 ALBERT: A lite BERT for self-supervised learning of language representations,2020, In8th International Conference on Learning Representations
 Inferring which medical treat-ments work from reports of clinical trials,2019, In Proceedings of the North American Chapter of theAssociation for Computational Linguistics (NAACL)
 Hatexplain: A benchmark dataset for explainable hate speech detection,2021, In Thirty-Fifth AAAI Conference on Artificial Intelligence
 Right for the wrong reasons: Diagnosing syntacticheuristics in natural language inference,2019, In Proceedings of the 57th Annual Meeting of the Asso-ciation for Computational Linguistics
 Bertweet: A pre-trained language modelfor english tweets,2020, In Qun Liu and David Schlangen (eds
 The limits of abstract evalua-tion metrics: The case of hate speech detection,2017, In Peter Fox
 Comparison of Methods to Reduce Bias From Clinical Prediction Models ofPostpartum Depression,2574, JAMA Network Open
 Carbon emissions and large neural network training,2021, arXivpreprint arXiv:2104
 Using Machine Learning to Reduce Toxicity Online,2021, https://perspectiveapi
 On fairnessand calibration,2017, arXiv preprint arXiv:1709
 LanguageModels are Unsupervised Multitask Learners,2019,2019
 A primer in bertology: What we know abouthow bert works,2021, Transactions of the Association for Computational Linguistics
 Mapping the space of chemical reactions using attention-based neural networks,2021, Nature Machine Intelligence
 A natural language processing system for extractingevidence of drug repurposing from scientific publications,2020, Proceedings of the AAAI Conferenceon Innovative Applications of Artificial Intelligence
 Mitigating gender bias in natural lan-guage processing: Literature review,2019, In Proceedings of the 57th Annual Meeting of the Associationfor Computational Linguistics
 Mobilebert:a compact task-agnostic BERT for resource-limited devices,2020, In Dan Jurafsky
 Fairness definitions explained,9781, In Proceedings of the InternationalWorkshop on Software Fairness
 The State of Online Harassment,2021, https://www
 SuperGLUE: A stickier benchmark for general-purpose languageunderstanding systems,2019, arXiv preprint 1905
 Measuring and reducing gendered correlations in pre-trained models,2020, CoRR
 Optimized score trans-formation for fair classification,2020, In Silvia Chiappa and Roberto Calandra (eds
 Transformers: State-of-the-artnatural language processing,2020, In Proceedings of the 2020 Conference on Empirical Methods inNatural Language Processing: System Demonstrations
 Learning non-discriminatory predictors,2017, In Conference on Learning Theory
 Fairness with overlapping groups; aprobabilistic perspective,2020, Advances in Neural Information Processing Systems
