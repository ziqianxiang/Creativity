title,year,conference
 Deep learning for ai,0001, Commun
 Calibration of Pre-trained Transformers,2020, In Proceedings of theConference on Empirical Methods in Natural Language Processing (EMNLP)
 Learning and development in neural networks: the importance of start-ing small,0010,	Cognition
 Multi-modal curriculum learning for semi-supervised image classification,2016, IEEE Transactions on ImageProcessing
 Auto-mated curriculum learning for neural networks,2017, In Doina Precup and Yee Whye Teh (eds
 On calibration of modern neuralnetworks,2017, In Proceedings of the 34th International Conference on Machine Learning - Volume70
 Curriculumnet: Weakly supervised learning from large-scale web images,2018, InEuropean Conference on Computer Vision (ECCV)
 Calibration of neural networks using splines,2021, In International Conferenceon Learning Representations
 On the power of curriculum learning in training deep net-works,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Deep residual learning for image recog-nition,2016, In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Why relu networks yield high-confidence predictions far away from the training data and how to mitigate the problem,2019, 2019IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
 Benchmarking neural network robustness to common cor-ruptions and perturbations,2019, Proceedings of the International Conference on Learning Represen-tations
 Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels,2018, In ICML
 Calibrating predictive modelestimates to support personalized medicine,2012, Journal of the American Medical Informatics Asso-Ciation : JAMIA
 Exploring the memorization-generalization continuum in deep learning,2020, CoRR
 Calibrated lan-guage model fine-tuning for in- and out-of-distribution data,2020, In Proceedings of the 2020 Confer-ence on Empirical Methods in Natural Language Processing (EMNLP)
 Improving model calibration with accuracy versus uncer-tainty optimization,2020, Advances in Neural Information Processing Systems
 Learning multiple layers of features from tiny images,2009, Tech-nical Report 0
 Beyond temperature scaling: Obtaining well-calibrated multiclass probabili-ties with dirichlet calibration,2019, In NeurIPS
 Verified uncertainty calibration,2019, In NeurIPS
 Trainable calibration measures for neural networksfrom kernel mean embeddings,2018, In Jennifer Dy and Andreas Krause (eds
 Self-paced learning for latent vari-able models,2010, In J
 Deep learning,2015, Nature
 Training confidence-calibrated classifiers fordetecting out-of-distribution samples,2018, In International Conference on Learning Representations
 Confidence-aware learningfor deep neural networks,2020, In International Conference on Machine Learning
 Calibrating deep neural networks using focal loss,2020, 2020
 Class-wise calibration: a case study on covid-19 hate speech,2021, In The 34th Canadian Conference on Artificial Intelligence
 Can you trust your modelâ€™s uncertainty? evaluatingpredictive uncertainty under dataset shift,2019, In NeurIPS
 Probabilistic outputs for support vector machines and comparisons to regularizedlikelihood methods,1999, In ADVANCES IN LARGE MARGIN CLASSIFIERS
 Guided curriculum model adaptation anduncertainty-aware evaluation for semantic nighttime image segmentation,2019, 2019 IEEE/CVF Inter-national Conference on Computer Vision (ICCV)
 On mixup training: Improved calibration and predictive uncertainty for deep neural net-works,2019, In H
 A survey on curriculum learning,1939, IEEE Transactions on PatternAnalysis & Machine Intelligence
 Obtaining calibrated probability estimates from decision treesand naive bayesian classifiers,2001, In ICML
 Transforming classifier scores into accurate multiclass proba-bility estimates,2002, In KDD
 mixup: Beyond em-pirical risk minimization,2018, In International Conference on Learning Representations
 Robust curriculum learning: from clean label detectionto noisy label self-correction,2021, In ICLR
