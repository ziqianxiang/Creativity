title,year,conference
 Sparse Networks from Scratch: Faster Training without LosingPerformance,2019, (1):1-14
 Rigging the Lot-tery: Making All Tickets Winners,2019, pp
 The State of Sparsity in Deep Neural Networks,2019, 2019
 Deep Residual Learning for ImageRecognition,1664, 2015
 Filter pruning via geometric medianfor deep convolutional neural networks acceleration,2019, Proceedings of the IEEE Computer SocietyConference on Computer Vision and Pattern Recognition
 QuantizedNeural Networks: Training Neural Networks with Low Precision Weights and Activations,2016, 2016
 Efficientneural audio synthesis,2018, 35th International Conference on Machine Learning
 Soft threshold weight reparameterization for learnable sparsity,2331, arXiv
 The Two Regimes of Deep Network Training,2020, 2020
 Layer-Adaptive Sparsity forthe Magnitude-Based Pruning,2021, International Conference on Learning Representations
 SnIP: Single-shot network pruningbased on connection sensitivity,2019, In 7th International Conference on Learning Representations
 Pruning filters forefficient convnets,2017, 5th International Conference on Learning Representations
 Rethinking the valueof network pruning,2019, 7th International Conference on Learning Representations
 Ternary Neural Networks with Fine-Grained Quantization,2017, 2017
 Scalable training of artificial neural networks with adaptive sparse connec-tivity inspired by network science,2041, Nature Communications
 Comparing Rewinding and Fine-tuning in Neu-ral Network Pruning,2020, (2019):1-31
 Very Deep Convolutional Networks for Large-Scale Image Recog-nition,2014, CoRR
 Drawing early-bird tickets: Towards more efficient trainingof deep networks,2019, (2019):1-13
