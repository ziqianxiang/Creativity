title,year,conference
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Audio adversarial examples: Targeted attacks on speech-to-text,2018, In 2018 IEEE Security and Privacy Workshops (SPW)
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In ICML
 On the Con-nection between adversarial robustness and saliency map interpretability,2019, arXiv preprintarXiv:1905
 Detecting adversarialsamples from artifacts,2017, arXiv preprint arXiv:1703
 Adversarialexamples for semantic image segmentation,2017, In arXiv preprint arXiv:1703
 Learning to forget: Continual predictionwith lstm,1999, IET
 Explaining and harnessing adversarialexamples,2014, In arXiv:1412
 Adversarial logit pairing,2018, InarXiv:1803
 Determinantal point processes for machine learning,2012, arXiv preprintarXiv:1207
 Fortified networks: Improving the robustness of deep networksby modeling the manifold of hidden representations,2018, In arXiv:1804
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Metric learningfor adversarial robustness,2019, In Advances in Neural Information Processing Systems
 On detecting adversarialperturbations,2017, In arXiv preprint arXiv:1702
 Virtual adversarial training: aregularization method for supervised and semi-supervised learning,2017, In arXiv:1704
 Exploring gener-alization in deep learning,2017, In arXiv preprint arXiv:1706
 Robust deep learning via reverse cross-entropy training andthresholding test,2017, arXiv preprint arXiv:1706
 Rethinking softmaxcross-entropy loss for adversarial robustness,2019, arXiv preprint arXiv:1905
 Improving adversarial robustness viapromoting ensemble diversity,4970, In International Conference on Machine Learning
 Improvingmodel robustness with latent distribution locally and globally,2021, arXiv preprint arXiv:2107
 Overfitting in adversarially robust deep learning,2020, arXivpreprint arXiv:2002
 Adversarial training is a form of data-dependentoperator norm regularization,2020, Advances in Neural Information Processing Systems
 Adver-sarially robust generalization requires more data,2018, In Advances in Neural Information ProcessingSystems
 Harnessing the vulnerability of latent layers in adversarially trained mod-els,2019, In arXiv:1905
 Certifying some distributionalrobustness with principled adversarial training,2017, arXiv preprint arXiv:1710
 Robust local features forimproving the generalization of adversarial training,2019, In arXiv preprint arXiv:1909
 Weak Convergence and Empirical Processes,2000, Springer
 Bilateral adversarial training: Towards fast training of morerobust models against adversarial attacks,2019, In Proceedings of the IEEE International Conferenceon Computer Vision
 Adversarial weight perturbation helps robust gener-alization,2020, In Advances in Neural Information Processing Systems
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
 Greedy at-tack and gumbel attack: Generating adversarial examples for discrete data,2020, Journal of MachineLearning Research
 A closer look at accuracy vs,2020, robustness
 Me-net: Towards effective adversarial robustnesswith matrix estimation,2019, arXiv preprint arXiv:1905
 Rademacher complexity for adversariallyrobust generalization,2019, In International Conference on Machine Learning
 Adversarial noise layer:Regularize neural network by adding noise,2019, In 2019 IEEE International Conference on ImageProcessing (ICIP)
 Adversariallyrobust generalization just requires more unlabeled data,2019, In arXiv preprint arXiv:1906
 You only propagateonce: Accelerating adversarial training via maximal principle,2019, arXiv preprint arXiv:1905
 Defense against adversarial attacks using feature scattering-basedadversarial training,2019, In Advances in Neural Information Processing Systems
 Theoretically principled trade-off between robustness and accuracy,2019, arXiv preprintarXiv:1901
 Attacks which do not kill training make adversarial learning stronger,2020, In arXiv preprintarXiv:2002
 Manifold adversarial training for super-vised and semi-supervised learning,2021, Neural Networks
 Freelb: Enhancedadversarial training for natural language understanding,2019, arXiv preprint arXiv:1909
