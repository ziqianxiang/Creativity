title,year,conference
 An optimistic perspective on offlinereinforcement learning,2020, In International Conference on Machine Learning
 Opal: Offline prim-itive discovery for accelerating offline reinforcement learning,2021, In International Conference onLearning Representations
 Abstract dynamic programming,2018, Athena Scientific Nashua
 Conservative safety critics for exploration,2021, In International Conference on LearningRepresentations
 Convex Optimization,2004, Cambridge University Press
 The importance of pessimism in fixed-dataset policy optimization,2021, In International Conference on Learning Representations
 Multinomial logistic regression algorithm,1992, Annals of the Institute of StatisticalMathematics
 On the global convergence of imitationlearning: A case for linear quadratic regulator,2019, arXiv preprint arXiv:1901
 Bullet physics simulation,2015, In ACM SIGGRAPH
 Leave no trace: Learning toreset for safe and autonomous reinforcement learning,2018, In International Conference on LearningRepresentations
 Addressing function approximation error in actor-critic methods,2018, In International Conference on Machine Learning
 Off-policy deep reinforcement learning withoutexploration,2019, In International Conference on Machine Learning
 On the properties of the softmax function with application in gametheory and reinforcement learning,2017, arXiv preprint arXiv:1704
 Off-policy deep reinforcement learning by bootstrapping thecovariate shift,2019, In AAAI Conference on Artificial Intelligence
 Emaq: Expected-max q-learning operator for simple yet effective offline and online rl,2021, International Conferenceon Machine Learning
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, In International Confer-ence on Machine Learning
 Deep q-learning from demonstrations,2018, InThirty-second AAAI conference on artificial intelligence
 From importance sampling to doubly robust policy gradient,2020, InInternational Conference on Machine Learning
 Scalable deep reinforce-ment learning for vision-based robotic manipulation,2018, In Conference on Robot Learning
 Variational learning for latent Gaussian model of discrete data,2012, PhD thesis
 Morel: Model-based offline reinforcement learning,2020, In Neural Information Processing Systems
 Offline reinforcement learning with implicit q-learning,2021, arXiv preprint arXiv:2110
 Stabilizing off-policy q-learning via bootstrapping error reduction,2019, In Neural Information Processing Systems
 Discor: Corrective feedback in reinforcementlearning via distribution correction,2020, In Neural Information Processing Systems
 Conservative q-learning for offlinereinforcement learning,2020, In Neural Information Processing Systems
 Implicit under-parameterizationinhibits data-efficient deep reinforcement learning,2021, In International Conference on Learning Rep-resentations
 A workflow foroffline model-free robotic reinforcement learning,2021, In 5th Annual Conference on Robot Learning
 Batch reinforcement learning,2012, In Reinforce-ment learning
 Off-policy policy gradient withstationary distribution correction,2020, In Uncertainty in Artificial Intelligence
 Provably good batch off-policyreinforcement learning without great exploration,2020, In Neural Information Processing Systems
 How to avoid machine learning pitfalls: a guide for academic researchers,2021, arXivpreprint arXiv:2108
 On a test of whether one of two random variables is stochas-tically larger than the other,1947, Annals of Mathematical Statistics
 Reg-ularized policy iteration with nonparametric function spaces,2016, Journal of Machine Learning Re-Search
 Evaluating agents without rewards,2020, arXivpreprint arXiv:2012
 Self-distillation amplifies regularization inhilbert space,2020, In Neural Information Processing Systems
 Machine Learning: A Probabilistic Perspective,2012, The MIT Press
 Algaedice:Policy gradient from arbitrary experience,2019, arXiv preprint arXiv:1912
 Over-coming exploration in reinforcement learning with demonstrations,2018, In 2018 IEEE InternationalConference on Robotics and Automation (ICRA)
 Numerical Optimization,2006, Springer
 Deep exploration viabootstrapped dqn,2016, In Neural Information Processing Systems
 The uncertainty bellmanequation and exploration,2018, In International Conference on Machine Learning
 Advantage-weighted regression:Simple and scalable off-policy reinforcement learning,2019, arXiv preprint arXiv:1910
 On variationalbounds of mutual information,2019, In International Conference on Machine Learning
 Toward the fundamentallimits of imitation learning,2020, arXiv preprint arXiv:2009
 Learning complex dexterous manipulation with deep reinforcementlearning and demonstrations,2018, In Proceedings of Robotics: Science and Systems
 Chainingbehaviors from data with model-free reinforcement learning,2020, In Conference on Robot Learning
 S4RL: Surprisingly simple self-supervision foroffline reinforcement learning in robotics,2021, In 5th Annual Conference on Robot Learning
 Reinforcement learning: An introduction,2018, MIT press
 Visualizing data using t-SNE,2008, Journal of MachineLearning Research
 Deep reinforcement learning with double q-learning,2016, In Proceedings of the AAAI conference on artificial intelligence
 Uncertainty weighted actor-critic for offline reinforcement learning,2021, arXiv preprintarXiv:2105
 On the optimality of batch policy optimization algorithms,2021, arXiv preprintarXiv:2104
 Latent skillplanning for exploration and transfer,2021, In International Conference on Learning Representations
 Imitation learning with stability and safety guar-antees,2021, IEEE Control Systems Letters
 Near-optimal provable uniform convergence in offline pol-icy evaluation for reinforcement learning,2021, In International Conference on Artificial Intelligenceand Statistics
 Conservative data sharing for multi-task offline reinforcement learning,2021, arXiv preprintarXiv:2109
 Plas: Latent action space for offline reinforce-ment learning,2020, In Conference on Robot Learning
 Offline learning from demonstrations andunlabeled experience,2020, arXiv preprint arXiv:2011
