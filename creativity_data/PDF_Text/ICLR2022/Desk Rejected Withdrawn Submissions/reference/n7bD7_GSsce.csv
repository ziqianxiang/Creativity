title,year,conference
 Learning is planning: near bayes-optimal reinforcement learning viamonte-carlo tree search,2012, arXiv preprint arXiv:1202
 Efficient exploration through Bayesian deepq-networks,2018, IEEE Information Theory and Applications Workshop
 Unifying count-basedexploration and intrinsic motivation,2016, Advances in Neural Information Processing Systems
 A conceptual introduction to Hamiltonian Monte Carlo,2017, arXiv preprintarXiv:1701
 Offline meta learning of exploration,2020, arXiv preprintarXiv:2008
 Rl2: Fast reinforcementlearning via slow reinforcement learning,2016, arXiv preprint arXiv:1611
 Dual control theory,1960, I
 Dual control theory,1960, II
 Dual control theory III,1961, Avtomatika i Telemekhanika
 Survey of adaptive dual control methods,2000, IEEE Proceedings-ControlTheory and Applications
 Noisy networks for exploration,2018, International Conference onLearning Representations
 Curiosity driven reinforcementlearning for motion planning on humanoids,2014, Frontiers in Neurorobotics
 Efficient bayes-adaptive reinforcement learning using sample-basedsearch,2012, Advances in Neural Information Processing Systems
 Scalable and efficient bayes-adaptive reinforcement learning basedon monte-carlo tree search,2013, Journal of Artificial Intelligence Research
 Meta-reinforcement learning of structuredexploration strategies,2018, Advances in Neural Information Processing Systems
 Learning in pomdps with monte carlo tree search,2017, InternationalConference on Machine Learning
 Decoupling exploration and exploitation formeta-reinforcement learning without sacrifices,2021, International Conference on Machine Learning
 Bootstrapped thompson sampling and deep exploration,2015, arXiv preprintarXiv:1507
 Deep exploration via bootstrapped dqn,2016, Advancesin Neural Information Processing Systems
 Count-based exploration with neural densitymodels,2017, International Conference on Machine Learning
 Intrinsic motivation systems for autonomous mentaldevelopment,2007, IEEE Transactions on Evolutionary Computation
 Bayesian dynamic programming,1975, Advances in Applied Probability
 Bayes-adaptive POMDPs,2007, Neural Information ProcessingSystems
 A new heuristic approach for dual control,1997, AAAI Technical Report
 Bayesianfiltering and smoothing,2013, Cambridge University Press
 A possibility for implementing curiosity and boredom in model-building neuralcontrollers,1991, International Conference on Simulation of Adaptive Behavior: From Animals toAnimats
 Incentivizing exploration in reinforcement learning with deeppredictive models,2015, arXiv preprint arXiv:1507
 Learning to reinforcement learn,2016, arXiv preprint arXiv:1611
 A learning gapbetween neuroscience and reinforcement learning,2021, arXiv preprint arXiv:2104
 Advances in variational inference,2018, IEEETransactions on Pattern Analysis and Machine Intelligence
 Curiosity-driven experience prioritization via density estimation,2019, arXivpreprint arXiv:1902
 Curiosity-driven exploration for maplessnavigation with deep reinforcement learning,2018, arXiv preprint arXiv:1804
 Varibad: A verygood method for bayes-adaptive deep rl via meta-learning,2020, International Conference on LearningRepresentations
 Explorationin approximate hyper-state space for meta reinforcement learning,2021, International Conference onMachine Learning
