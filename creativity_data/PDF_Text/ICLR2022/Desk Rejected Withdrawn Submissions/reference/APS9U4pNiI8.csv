title,year,conference
 Byzantine stochastic gradient descent,2018, In Advances inNeural Information Processing Systems
 How tobackdoor federated learning,2020, In International Conference on Artificial Intelligence and Statistics
 Machine learning with adversaries: Byzantinetolerant gradient descent,2017, In Advances in Neural Information Processing Systems
 Practical secure aggregation for privacy-preserving machine learning,2017, In Proceedings of the 2017 ACM SIGSAC Conference on Computerand Communications Security
 Draco: Byzantine-resilient distributed training via redundant gradients,2018, arXiv preprint arXiv:1803
 High-dimensional robust mean estimation in nearly-linear time,2019, In Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms
 List-decodable robust mean estimationand learning mixtures of spherical gaussians,2018, In Proceedings of the 50th Annual ACM SIGACTSymposium on Theory of Computing
 Local model poisoning attacksto byzantine-robust federated learning,2019, arXiv preprint arXiv:1911
 Model inversion attacks that exploit confidenceinformation and basic countermeasures,2015, In Proceedings of the 22nd ACM SIGSAC Conference onComputer and Communications Security
 Attack-resistant federated learning with residual-based reweighting,2019, arXiv preprint arXiv:1912
 Mitigating sybils in federated learningpoisoning,2018, arXiv preprint arXiv:1808
 The limitations of federated learning insybil settings,2020, In 23rd International Symposium on Research in Attacks
 Source inferenceattacks in federated learning,2021, arXiv preprint arXiv:2109
 Advancesand open problems in federated learning,2019, arXiv preprint arXiv:1912
 Feature inference attack on modelpredictions in vertical federated learning,2021, In 2021 IEEE 37th International Conference on DataEngineering (ICDE)
 Threats to federated learning: A survey,2020, arXiv preprintarXiv:2003
 Federated learning: Collaborative machine learning withoutcentralized training data,2017, Google Research Blog
 The hidden vulnerability ofdistributed learning in byzantium,2018, arXiv preprint arXiv:1802
 Secureml: A system for scalable privacy-preserving machinelearning,2017, In 2017 IEEE Symposium on Security and Privacy (SP)
 Comprehensive privacy analysis of deep learning:Passive and active white-box inference attacks against centralized and federated learning,2019, In 2019IEEE symposium on security and privacy (SP)
 Preventing backdoors in federatedlearning by adjusting server-side learning rate,2020, 2020
 Membership inference attacksagainst machine learning models,2017, In 2017 IEEE Symposium on Security and Privacy (SP)
 Robust learning: Information theory and algorithms,2018, PhD thesis
 Data poisoning attacks on federatedmachine learning,2020, arXiv preprint arXiv:2004
 Beyond inferringclass representatives: User-level privacy leakage from federated learning,2019, In IEEE INFOCOM2019-IEEE Conference on Computer Communications
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, arXiv preprint arXiv:1708
 Dba: Distributed backdoor attacks against federatedlearning,2019, In International Conference on Learning Representations
 Federated machine learning: Concept andapplications,2019, ACM Transactions on Intelligent Systems and Technology (TIST)
 Byzantine-robust distributedlearning: Towards optimal statistical rates,2018, arXiv preprint arXiv:1803
 Defending against saddle pointattack in byzantine-robust distributed learning,2019, In International Conference on Machine Learning
