title,year,conference
 Classification from pairwise similarity and unlabeleddata,2018, In ICML
 Rademacher and gaussian complexities: Risk bounds andstructural results,2001, In COLT
 LOF: Identifyingdensity-based local outliers,2000, In SIGMOD
 Learning fromsimilarity-confidence data,2021, CoRR
 Unbiased risk estimators canmislead: A case study of learning with complementary labels,2020, In ICML
 Deep learning for classical japanese literature,2018, CoRR
 Learning frompartial labels,2011, J
 Analysis of learning frompositive and unlabeled data,2014, In NeurIPS
 Convex formulation for learningfrom positive and unlabeled data,2015, In ICML
 Learning classifiers from only positive and unlabeled data,2008, In KDD
 Learning from multiplecomplementary labels,2020, In ICML
 Provablyconsistent partial-label learning,2020, In ICML
 Size-independent sample complexity ofneural networks,2018, In COLT
 Towards understanding deep learning from noisylabels with small-loss criterion,2021, In IJCAI
 Record: Resource constrained semi-supervised learningunder distribution shift,2020, In KDD
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, InNeurIPS
 Deep residual learning for imagerecognition,2016, In CVPR
 Densely connectedconvolutional networks,2017, In CVPR
 Binary classification from positive-confidencedata,2018, In NeurIPS 2018
 Complementary-labellearning for arbitrary losses and models,2019, In ICML
 Bridging ordinary-label learning and complementary-labellearning,2020, In ACML
 Adam: A method for stochastic optimization,2015, In ICLR
 Learning multiple layers of features from tiny images,2009,2009
 Gradient-based learning applied to documentrecognition,1998, Proceedings of the IEEE
 Safe semi-supervised learning: A brief introduction,2019, FrontiersComput
 Towards making unlabeled data never hurt,2015, IEEE Trans
 On the minimal supervision fortraining any binary classifier from only unlabeled data,2019, In ICLR
 Progressive identificationof true labels for partial-label learning,2020, In ICML
 A vector-contraction inequality for rademacher complexities,2016, In Ronald Ortner
 On the method of bounded differences,1989, Surveys in Combinatorics
 Lower bounds for the empirical minimization algorithm,2008, IEEE Trans
 Learning withnoisy labels,2013, In NeurIPS
 Squared-lossmutual information regularization: A novel information-theoretic approach to semi-supervisedlearning,2013, In ICML
 Semi-supervisedclassification based on classification from positive and unlabeled data,2017, In ICML
 Efficient training for positiveunlabeled learning,2019, IEEE Trans
 Binary classification from positive datawith skewed confidence,2020, In IJCAI
 Density Ratio Estima-tion in Machine Learning,2012, Cambridge University Press
 Support vector domain description,1999, Pattern Recognit
 Statistical Learning Theory,1998, Wiley
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, CoRR
 Multi-positive and unlabeled learning,2017, In IJCAI
 Learning with biased complementarylabels,2018, In ECCV
 Learning from noisy labels with no change to thetraining process,2021, In ICML
 Learning from incomplete and inaccuratesupervision,2019, In KDD
 A brief introduction to weakly supervised learning,2018, National Science Review
 Introduction to Semi-Supervised Learning,2009, Synthesis Lectureson Artificial Intelligence and Machine Learning
