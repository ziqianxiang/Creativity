title,year,conference
 Pattern recognition and machine learning,2006, springer
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In Proceedings of the thirteenth international conference on artificial intelligence andstatistics
 A survey of deep learningtechniques for autonomous driving,2020, Journal of Field Robotics
 Learning both weights and connections forefficient neural network,2015, Advances in Neural Information Processing Systems
 Second order derivatives for network pruning: Optimal brainsurgeon,1993, Morgan Kaufmann
 Optimal brain surgeon:Extensions and performance comparison,1994, Advances in Neural Information Processing Systems
 Improving neural networks by preventing co-adaptation of feature detectors,2012, arXiv preprintarXiv:1207
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Optimalbrain damage,1989, In NIPs
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 SNIP: SINGLE-SHOT NETWORKPRUNING BASED ON CONNECTION SENSITIVITY,2019, In International Conference on Learn-ing Representations
 Pruning filters forefficient convnets,2016, arXiv preprint arXiv:1608
 Rethinking the value ofnetwork pruning,2019, In International Conference on Learning Representations
 Decoupled weight decay regularization,2018, In International Confer-ence on Learning Representations
 All you need is a good init,2016, arXiv preprint arXiv:1511
 Deep learning applications and challenges in big data analytics,2015, Journalof Big Data
 Languagemodels are unsupervised multitask learners,2019, OpenAI blog
 Neuronal mechanisms of developmental plasticity in the cat¡¯s visual system,1984, Hu-man neurobiology
 Learning representation by back-propagating errors,1986, Nature
 Regularization of neuralnetworks using dropconnect,1058, In International conference on machine learning
 Picking winning tickets before training bypreserving gradient flow,2020, In International Conference on Learning Representations
 One-shot pruning of recurrent neural networks byjacobian spectrum evaluation,2019, arXiv preprint arXiv:1912
