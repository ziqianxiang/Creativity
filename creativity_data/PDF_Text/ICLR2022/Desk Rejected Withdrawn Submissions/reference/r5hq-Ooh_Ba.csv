title,year,conference
 Learning with pseudo-ensembles,2014, In Advancesin Neural Information Processing Systems 27
 Mixmatch: A holistic approach to semi-supervised learning,2019, In Advances in NeuralInformation Processing Systems
 Remixmatch: Semi-supervised learning with distribution matching and augmenta-tion anchoring,2020, In Eighth International Conference on Learning Representations
 Randaugment: Practical automateddata augmentation with a reduced search space,2020, In Advances in Neural Information ProcessingSystems
 Learning from complementarylabels,2017, In Advances in Neural Information Processing Systems
 Dual student: Breaking thelimits of the teacher in semi-supervised learning,2019, In IEEE International Conference on ComputerVision
 Nlnl: Negative learning for noisylabels,2019, In 2019 IEEE International Conference on Computer Vision
 Temporal ensembling for semi-supervised learning,2016, arXiv preprintarXiv:1610
 Pseudo-label: The simple and efficient semi-supervised learning method fordeep neural networks,2013, In Workshop on challenges in representation learning
 Comatch: Semi-supervised learning with con-trastive graph regularization,2020, arXiv preprint arXiv:2011
 Sgdr: Stochastic gradient descent with warm restarts,2017, In FifthInternational Conference on Learning Representations
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In IEEE Conference onComputer Vision and Pattern Recognition
 Transductivesemi-supervised deep learning using min-max features,2018, In Proceedings of the European Confer-ence on Computer Vision
 Fixmatch: Simplifying semi-supervised learningwith consistency and confidence,2020, arXiv preprint arXiv:2001
 Mean teachers are better role models: Weight-averaged consis-tency targets improve semi-supervised deep learning results,2017, In Advances in neural informationprocessing systems
 Interpolation con-sistency training for semi-supervised learning,2019, In Proceedings of the Twenty-Eighth InternationalJoint Conference on Artificial Intelligence
 Unsupervised data augmentationfor consistency training,2020, Advances in Neural Information Processing Systems
 Learning with biased complementarylabels,2018, In Proceedings of the European Conference on Computer Vision
 Wide residual networks,2016, In British Machine VisionConference
 mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
