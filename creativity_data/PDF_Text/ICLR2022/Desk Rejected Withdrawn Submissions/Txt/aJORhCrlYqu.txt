Under review as a conference paper at ICLR 2022
ARMCMC: Online Bayesian Density Estima-
tion of Model Parameters
Anonymous authors
Paper under double-blind review
Ab stract
Although the Bayesian paradigm provides a rigorous framework to estimate the
full probability distribution over unknown parameters, its online implementation
can be challenging due to heavy computational costs. This paper proposes Adap-
tive Recursive Markov Chain Monte Carlo (ARMCMC) which estimates full
probability density of model parameters while alleviating shortcomings of con-
ventional online approaches. These shortcomings include: being solely able to
account for Gaussian noise, being applicable to systems with linear in the param-
eters (LIP) constraint, or having requirements on persistence excitation (PE). In
ARMCMC, we propose a variable jump distribution, which depends on a tempo-
ral forgetting factor. This allows one to adjust the trade-off between exploitation
and exploration, depending on whether there is an abrupt change to the parame-
ter being estimated. We prove that ARMCMC requires fewer samples to achieve
the same precision and reliability compared to conventional MCMC approaches.
We demonstrate our approach on two challenging benchmarks: the estimation of
parameters in a soft bending actuator and the Hunt-Crossley dynamic model. Our
method shows at-least 70% improvement in parameter point estimation accuracy
and approximately 55% reduction in tracking error of the value of interest com-
pared to recursive least squares and conventional MCMC.
1	Introduction
Bayesian methods are powerful tools to not only obtain a numerical estimate of a parameter but also
to give a measure of confidence (KU´mierCzyk et al., 2019; Bishop, 2006; Joho et al., 2013). By
calculating the probability distribution of parameters rather than a point estimate, which is prevalent
in frequentist paradigms (Tobar, 2018). One of the main advantages of probabilistic frameworks is
that they enable decision making under uncertainty (Noormohammadi-Asl & Taghirad, 2019). In
addition, knowledge fusion is significantly facilitated in probabilistic frameworks; different sources
of data or observations can be combined according to their level of certainty in a principled manner
(Agand & Shoorehdeli, 2019). Nonetheless, Bayesian inference requires high computational effort
for obtaining the whole probability distribution and require prior general knowledge about the noise
distribution.
One of the most effective methods for Bayesian inferences is Markov Chain Monte Carlo (MCMC).
In the field of system identification, MCMC variants such as the one recently proposed by Green
(2015) are mostly focused on offline system identification. This is partly due to computational chal-
lenges which prevent its real-time use (Kuindersma et al., 2012). The standard MCMC algorithm is
not suitable for multi mode system since different candidates do not share the same parameter set.
Green (1995) first introduced reversible jump Markov chain Monte Carlo (RJMCMC) as a method
to address the model selection problem. In this method, an extra pseudo-random variable is defined
to address dimension mismatch. There are further extensions of MCMC in the literature, however,
there is a lack of variants suitable for online estimation.
Motion filtering and force prediction of robotic manipulators are important fields of study with inter-
esting challenges suitable for Bayesian inference to address (Saar et al., 2018). Here, measurements
are inherently noisy, which is not desirable for control purposes. Likewise, inaccuracy, inacces-
sibility, and costs are typical challenges that make force measurement not ideal for practical use
(Agand et al., 2016). Different environmental identification methods have been proposed in the lit-
1
Under review as a conference paper at ICLR 2022
erature for linear and Gaussian noise (Wang et al., 2018); however, in cases of nonlinear models like
Hunt-Crossley that does not have Gaussian noise (e.g. impulsive disturbance), there is no optimal
solution for the identification problem. Diolaiti et al. (2005) proposed a double-stage bootstrapped
method for online identification of the Hunt-Crossley model, which is sensitive to parameter initial
conditions. Carvalho & Martins (2019) proposed a method to determine the damping term in the
Hunt-Crossley model. A neural network-based approach was introduced to control the contact/non-
contact Hunt-Crossley model by Bhasin et al. (2008)
This paper proposes a new technique, Adaptive Recursive Markov Chain Monte Carlo (ARMCMC),
to address several weaknesses of traditional online identification methods, such as only being ap-
plicable to systems Linear in Parameters (LIP), having Persistent Excitation (PE) requirements, and
assuming Gaussian noise. ARMCMC is an online method that takes advantage of the previous pos-
terior distribution, whenever there is no sudden change in the parameter distribution. To achieve
this, we define a new variable jump distribution that accounts for the degree of model mismatch
using a temporal forgetting factor. The temporal forgetting factor is computed from a model mis-
match index and determines whether ARMCMC employs modification or reinforcement to either
restart or refine the estimated parameter distribution. As this factor is a function of the observed data
rather than a simple user-defined constant, it can effectively adapt to the underlying dynamics of the
system. We demonstrate our method using two different examples: a soft bending actuator and the
Hunt-Crossley model. We show favorable performance compared to state-of-the-art baselines.
The rest of this paper is organized as follows: In Sec. 2, introductory context about the Bayesian ap-
proach and MCMC is presented. Sec. 3 is devoted to presenting the proposed ARMCMC approach
and providing a step-by-step algorithm. Simulation results for the soft bending actuator and em-
pirical results for a reality-based model of a soft contact environment capturing the Hunt-Crossley
dynamic are presented in Sec. 4. Lastly, the final remarks and future directions are presented in Sec.
5.
2	Preliminaries
2.1	Problem Statement
In the Bayesian paradigm, estimates of parameters are given in the form of the posterior probabil-
ity density function (pdf); this pdf can be continuously updated as new data points are received.
Consider the following general model:
Y =F(X,θ)+ν,
(1)
where Y , X, θ, and ν are concurrent output, input, model parameters and noise vector, respectively.
To calculate the posterior pdf, the observed data (input/output pairs) along with a prior distribution
are combined via Bayes’ rule (Khatibisepehr et al., 2013). We will be applying updates to the
posterior pdf using batches of data points; hence, it will be convenient to partition the data as follows:
D = {(X, Y )tm , (X, Y )tm+1 ,…，(X, Y )tm + Ns + l},
(2)
where Ns = Ts/T is the number of data points in each data pack with T, Ts being the data and
algorithm sampling times, respectively. This partitioning is convenient for online applications, as
Dt-1 should have been previously collected so that the algorithm can be executed from tm to tm +
Ns+1 an interval which we will define as algorithm time step t. Ultimately, inferences are completed
at tm + Ns + 2. Fig. 1 illustrates the timeline for the data and the algorithm. It is worth mentioning
that the computation can be done in parallel with the task done in the adjacent algorithm step (e.g.
phase A of algorithm t, phase B of algorithm t - 1 and phase C of algorithm t - 2 can all be done
simultaneously)
According to Bayes’ rule and assuming data points are independent and identically distributed (
i.i.d.) in Eq. (1), we have
P(Dt∣θt,Dt-1) P (θtDt-1)
P (θt∣[Dt-1,Dt])=
∕P(D1∣θt,Dt-1) P (θt∣Dt-1)dθt
(3)
where θt denotes the parameters at current algorithm time step. P(θt∣Dt-1) is the prior distribu-
tion over parameters, which is also the posterior distribution at the previous algorithm time step.
2
Under review as a conference paper at ICLR 2022
Phase:
Algorithm Data
Interval Interval time
・	t - 1
A ►
t?n	…	tm + Ns + 1	…
I B	I	C
Figure 1: Data timeline and different phases of
ARMCMC algorithm. For algorithm at time
t: Phase (A) Data collection [we pack Ns data
points for the next algorithm time step], Phase
(B) Adjusting [the method is applying to the most
recent data pack], (C) Execution [after the min
evaluation of algorithm, the results will be up-
dated on parameters posterior distribution and
any byproduct value of interest].
Figure 2: Kmin with respect to λ for some values
of , δ in ARMCMC. (for λ = 1 evaluation for
ARMCMC is equivalent to MCMC)
P(Dt ∣θt, DtT) is the likelihood function which is obtained by sampling from the one-step-ahead
prediction:
Ytlt-1 = F (Dt-1,θt),	(4)
where Yt|t-1 is a sample from the prediction of the output in (1). If the model in (4) is accurate, then
the difference between the real output and predicted should be measurement noise, (i.e., Y t|t-1 -
Yt|t-1 = ν). Therefore, the model parameter may be updated as follows:
tm +Ns +1
P(Dt∣θt,Dt-1) =	Y	PV(ΥtltT- Yt1t-1),	(5)
t=tm+1
where Pν is the probability distribution of noise. Note that there is no restriction on the type of noise
probability distribution.
Remark 1: As it was mentioned before, there is no need to know the exact probability distribution
of noise. This probability distribution can be simply substituted with a Gaussian distribution, mean
and variance of the data (Bishop, 2006).
2.2	Markov Chain Monte Carlo (MCMC)
MCMC is often employed to compute the posterior pdf numerically. The multidimensional integral
in (3) is approximated by samples drawn from the posterior pdf. The samples are first drawn from
a different distribution called proposal distribution, denoted q(∙), which can be sampled more easily
compared to the posterior. Brooks et al. (2011) discuss different types of MCMC implementations
which may employ various proposal distributions and corresponding acceptance criteria. The main
steps of the Metropolis-Hastings algorithm are listed as follows (Ninness & Henriksen, 2010):
1.	Set initial guess θ0 while P(θ0 |Y) > 0 for iteration k = 1,
2.	Draw candidate parameter θe, at iteration k, from the proposal distribution, q(θcnd∣θk-ι)
3.	Compute the acceptance probability,
P(θcnd|D)q(θk — 1|θcnd) ∖
α(θcnMτ)=mm[1,P(θk-1D)q(θcnd∣θk-1)卜	⑹
4.	Generate a uniform random number γ in [0, 1],
5.	‘Accept’ candidate ifγ ≤ α and ‘ignore’ it ifγ > α,
6.	Set iteration to k + 1 and go to step 2.
3
Under review as a conference paper at ICLR 2022
2.3	Precision and reliability
Two important notions in probabilistic frameworks to compare results are precision () and reliability
(δ). The former represents the proximity of a sample to the ground truth, and the latter represents
the probability that an accepted sample lies within of the ground truth.
Lemma: Let Pk be k samples from MCMC, and E(Pk) denote their expected value. According to
Chernoff bound by Tempo et al. (2012), to achieve the given precision and reliability given , δ ∈
[0, 1], if the minimum number of samples (k) satisfies
12
k ≥ 否 log(T-7)，	⑺
then Prn{Pk- E(Pk)} ≤ o ≥δ.
3 ARMCMC algorithm
At each algorithm time interval, ARMCMC recursively estimates the posterior pdf by drawing sam-
ples. The number of samples drawn is constrained by the desired precision and reliability, and the
real time requirement. On the other hand, the maximum number of data points in each data pack,
Ns, is limited by the frequency of model variation, and the minimum is confined by the shortest
required time such that the algorithm is real-time.
We propose a variable jump distribution that enables both exploiting and exploring. This will ne-
cessitate the definition of the temporal forgetting factor as a model mismatch measure to reflect
current underlying dynamics of the data. We also prove that ARMCMC achieves the same precision
and reliability with fewer samples compared to the traditional MCMC. Algorithm 1 summarizes
ARMCMC.
3.1	Variable jump distribution
We propose a variable jump distribution (also known as a proposal distribution) to achieve faster
convergence, thereby enabling real-time parameter estimation:
qk"kj{N(μt;σDt-1)	λk ≤ λt,	⑻
where θkt -1 is the (k- 1)-th parameter sample which is given by the t-th data pack throughout the
MCMC evaluation. In each algorithm time sample, average of the second half of this quantity will
construct θt. P(θt-1∣Dt-1) is the posterior Pdf of the parameters at the previous algorithm time
step, and N (μ0 ,σν) is a Gaussian distribution with its mean and variance μ0 ,σν computed using
the empirical mean and variance of Dt-1.
The hyperparameter λt (temporal forgetting factor), is an adaptive threshold for the t-th pack that
takes inspiration from classical system identification; it regulates how previous knowledge affects
the posterior pdf. A smaller value of λt intuitively means that there may be a large sudden change
in ground truth value of θ, and thus more exploration is needed. Conversely, a larger value of λt is
appropriate when θ is changing slowly, and thus previous knowledge should be exploited. Exploiting
this knowledge will lead to better precision and reliability.
3.2	Temporal forgetting factor
Depending on whether the distribution of the parameter θ has changed significantly, a new sample
can be drawn according to the modification or the reinforcement mode. Reinforcement is employed
to make the identified probability distribution more precise when it is not undergoing sudden change.
Modification is employed otherwise to re-identify the distribution ‘from scratch’. Therefore, we
define a model mismatch index, denoted ζt, such that when it surpasses a predefined threshold (ζt >
ζth), modification is applied. Otherwise ζt is used to determine λt as follows:
λt = e-lμν-ζt |,	(9)
4
Under review as a conference paper at ICLR 2022
Algorithm 1 ARMCMC
Assumptions: 1) roughly noise mean (μν) 2) roughly noise variance (σν) 3) desired precision and
reliability (0, δ0) 4) desired threshold for model mismatch (ζth)
Goal: Online calculation of parameters posterior distribution given the consecutive t-th pack of
data (P(θtDt))
Initialization: Prior knowledge for θ10 , n = 0
Consider desire precision and reliability (, δ)
repeat
Put to = n * Ns + 1 from (2), n + +
Add new data pack to dataset Dt
Model mismatch index: ζ t from (10)
if ζt < ζth then
Reinforcement: set prior knowledge equal to the latest posterior of previous pack
Temporal forgetting factor: λt from (9)
else
Modification: set prior knowledge θ1n
Temporal forgetting factor: λt = 0
end if
Set minimum iteration kmin from (12)
for k = 1 to kmin do
Proposal distribution:
•	draw λk 〜U(0,1)
•	Variable jump distribution: qkt (.) from (8)
Draw θtk 〜qk(J
Acceptance rate: α(.) from (6)
Draw Y 〜U(0,1)
if γ ≤ α then
‘Accept’ the proposal
end if
end for
Wait to build Dkk0m+Ns+1 (algorithm sample time)
until No data is obtained
where μν is an estimation of the noise mean, by calculation of the expected value in Eq. (1). Note
that employing modification is equivalent to setting λk = 0. The model mismatch index ζk itself is
calculated by averaging the errors of the previous model given the current data:
Ns
ζk= 1/Ns X ynk -	E (F (Dk(n), θ)) ,ζ0 =∞	(10)
n=1	θ∈θt-1
Remark 2: The model mismatch index accounts for all sources of uncertainty in the system. To
calculate ζkh, one needs to precalculate the persisting error between the predicted and measured
data. In other words, ζkh is basically an upper bound for the unmodeled dynamics, disturbances,
noises, and any other source of uncertainty in the system.
Remark 3: To avoid numerical issues, the summation of probability logarithms are calculated. In
addition, each data pair in the algorithm time sample is weighted based on its temporal distance to
the current time. Therefore Eq. (5) is modified as
(11)
km +Ns +1
log (P(∙)) = X	logPν(et),
km +1
where ρ ∈ [0, 1] is a design parameter that reflects the volatility of the model parameters, and
ek = [ek1, ..., ekn, ..., ekN ]. For systems with fast-paced parameters, ρ should take larger values.
5
Under review as a conference paper at ICLR 2022
3.3 Minimum required evaluation
Theorem 3.1. Let and δ be the desired precision and reliability. Furthermore, assume that the
initial sample has enough number of evaluations (as in (7)). To satisfy the inequality in Eq. (7), the
minimum number of samples k in ARMCMC is calculated using this implicit relation:
12
kmin = 212 log(λt(1 - δ) + 2(1 - λt)e-2e2(i-λt)kmin ).
(12)
Proof. Samples from previous pdf: According to the variable jump distribution in (8), given k sam-
ples, the expected number of samples drawn from the previous posterior Pdf (P(θ∣Dt)) is λtk. By
assumption, the algorithm has already drawn at least k samples in the previous algorithm time-step.
Consequently, by (7), the expected number of samples with distances less than from E(Pk) drawn
from a previous distribution is at least λkδ.
Samples from Gaussian: By (8), there are k0 = (1 - λt)k samples drawn in expectation. According
to (13), we have Pr {Pk - E(Pk)} ≤	≥ δ0, where δ0 is given by rearranging (7):
δ0 = 1 - 2e-22 k0 .
(13)
Thus, the expected number of samples with distances less than from E(Pk) are at least δ0(1 -λt)k.
Overall reliability: The total expected number of samples with distances less than from E(Pk) is
the summation of the two parts mentioned above. Hence it is obtained through dividing by k:
δ1
(λtkδ) + (δo(1 - λt)k)
k
(14)
Given the new obtained reliability, which is greater than the desired one, helps us decrease the
number of evaluations. For the sake of illustration, Fig. 2 presents the minimum required number of
evaluations with respect to λ for different precisions and reliabilities. As it can be seen, the MCMC
is equal to ARMCM if λ is always set to one. The number of evaluations in ARMCMC mitigates as
the validity of the previous model increases.	口
4 Results
In this section, we demonstrate the performance of the proposed approach on two examples. First,
we employ the proposed method to identify parameters in the soft bending actuator model and
compare the results with identification using Recursive Least Squares (RLS). In the second example,
we evaluate our method on the Hunt-Crossley model given reality-based model and compare it with
simple MCMC and RLS. All the results/code are available on GitHub.
4.1	Fluid soft bending actuator
Consider the dynamic model of a fluid soft bending actuator, given by Wang et al. (2019):
α = qi(p - Patm) - qi& - q3α,
Uc Sign(Ps - P) v⅜s - p| =q4p + q5pp, Ud = 0,	(15)
Ud Sign(P - Patm) V∣P - Patml = Q6p + Q7pP, Uc = 0,
where α is the angle of the actuator, Uc , Ud are the control inputs for retraction and contraction,
respectively. Also P, Ps, Patm are the current, compressor and atmosphere pressure respectively. For
this example, we assume q1 = 1408.50, q2 = 132.28, q3 = 3319.40 are known and Patm = 101.3
kPa, Ps = 800 kPa. We are trying to identify the four other parameters (q4, ..., q7). The true
parameters are q5 = -2.14 × 10-4, q6 = 6.12 × 10-9, q7 = -9.76 × 10-5, q8 = -1.90 × 10-9.
To this end, we assume the hybrid model below:
U sign(∆P)√∣Δp∣ = θιP + θ2PP, U = {uc,Ud},	(16)
where ∆P is either (Ps -P) for retraction or (P - Patm) for contraction. As the range of parameters
are small, we scale the input vector by the factor of 107 for RLS. Given the input (Uc, Ud) and the
6
Under review as a conference paper at ICLR 2022
Figure 3: Parameter variation for RLS and AR-
MAPS
Figure 4: Angle of the actuator comparison of
RLS and AR-MAPS for soft bending actuator.
output (p,p), We want to identify the parameter and estimate the current angle of actuator assuming
that its initial position at the origin. The data sample time is T = 1 ms and each data pack includes
100 samples which results in an algorithm sample time equal to Ts = 0.1 sec. Point estimation ob-
tained by considering the mode at the modification phase and the median during the reinforcement
phase; this estimate is denoted as AR-MAPS. The point estimate results for the parameter estima-
tion are shown in Fig. 3. The estimation errors are 0.0235, 6.0053 × 10-7 for θ1, θ2 in RLS and
0.0089, 1.1840 × 10-7 in AR-MAPS, respectively. Moreover, the estimation of the angle is plotted
in Fig. 4.
4.2	Hunt-Crossley model
In this section, we demonstrate ARMCMC by identifying parameters of the Hunt-Crossley model,
which represents an environment involving a needle contacting soft material. The needle is mounted
as an end-effector on a high-precision robotic arm, which switches between two modes: free motion
and contact. Due to abrupt changes in the model parameters when the contact is established or lost,
online estimation of the force is extremely challenging.
4.2	. 1 Contact dynamic model
Consider the dynamics of contact as described by the Hunt-Crossley model, which is more consistent
with the physics of contact than classical linear models such as Kelvin-Voigt (Haddadi & Hashtrudi-
Zaad, 2012). In order to overcome the shortcomings of linear models, Hunt & Crossley (1975)
proposed the following hybrid nonlinear model:
fe(x(t)) =
∫Ke xp (t) + Be xp(t)X(t)
0
x(t) ≥ 0
x(t) < 0,
(17)
in which Ke , Bexp denote the nonlinear elastic and viscous force coefficients, respectively. The
parameter p is typically between 1 and 2, depending on the material and the geometric properties
of contact. Also, x(t), X(t), fe are the current position, velocity (as input X) and contact force (as
output (Y in Eq. (1)) of a needle near or inside the soft material, with x ≥ 0 representing the needle
being inside. This needle can move freely in open space or penetrate the soft contact; the forces
on this needle are modeled using the Hunt-Crossley model. The practical problem we consider
is to estimate the force at the tip of the needle by identifying the model parameters. Ke , Be , p
are three unknown parameters (θ in Eq. (1)) that needs to be estimated. An online estimate of
contact force plays a pivotal role in the stable interaction between robotic manipulators and unknown
environments.
lθg(fe )=lθg(K XP + Be X S XP ),
lθg(fe) =P lθg(Xs) + lθg(Ke + BeXS).
(18)
7
Under review as a conference paper at ICLR 2022
For RLS, We also need to make the assumption that Be/KXS << 1. Note that the vector of
parameters (θ) in the following relation are not independent, which may lead to divergence. With
this assumption, We have
lθg(1 + Be/KeXS) ≈ Be/KeXs,
lθg(fe) = P lθg(Xs)+lθg(Ke) + Be/KeXs∙
Φ =[1,X s,lθg(Xs)],
θ =[log(Ke),Be/Ke,p]T.
(19)
(20)
4.2.2	Setup
The data structure is same as previous simulation. Prior distribution of all three parameters
(Ke,Be,p) are initialized to N(1,0.1) (a normal distribution with μ = 1 and σ = 0.1) More-
over, as more data is collected, the spread of the posterior pdf decreases. A bit after 5 seconds, the
needle goes outside of the soft material, and experiences zero force; this is equivalent to all param-
eters being set to zero. The color-based visualization of probability distribution over time is used
for the three parameters in Fig. 5. During the period of time that the whole space is blue (zero
probability density), there is no contact and the parameter values are equal to zero.
Since we are taking a Bayesian approach, we are able to estimate the entire posterior pdf. However,
for the sake of illustration, the point estimates are computed from the ARMCMC algorithm by using
AR-MAPS method. The results are shown in Fig. 6 for the time-varying parameters θ1 = Ke , θ2 =
Be , θ3 = p. During the times that RLS results are chattering due to the use of saturation (if not,
the results would have diverged), the needle is transitioning from being inside the soft material to
the outside or vice versa. In addition, due to the assumption (19), performance can deteriorate even
when there is no mode transition. Furthermore, in the RLS approach, estimated parameters suddenly
diverged during free motion, since the regression vectors are linearly dependent. In contrast, with
ARMCMC this is not an issue we need to consider. The result of ARMCMC is presented in Fig. 7,
which shows the force estimation with two different identification approaches. This probability of
interest can be easily obtained by deriving the parameter density at one’s disposal.
4.2.3	Quantitative Comparison
Quantitative details of comparing a naive point estimate of the ARMCMC algorithm by averaging
the particles (denoted as AR-APS) and the RLS method are listed in Table 1. This reveals more
than a 70% improvement in the precision of all model parameters throughout the study by using
the Mean Absolute Error (MAE) criteria and also more than a 55% improvements in the force
estimation error. Among parameters, the viscose (Be) has the largest error in the RLS method since
it is underestimated due to the restrictive assumption in Eq. (19). The AR-MAPS approach uplifts
the performance of the parameter identification and the force estimation.
We also compare ARMCMC to MCMC. For the algorithm to run in real-time, MCMC requires more
time to converge. For this example, with λ = 0.7, the value of kmin is 15000 for MCMC but only
6000 for ARMCMC with = 0.01, δ = 0.9. Two possible ways to address this drawback in MCMC
are to reduce the number of samples to 5000 per algorithm iteration (denoted MCMC-1 in Table 1),
which results in worse precision and reliability compared to ARMCMC, or to increase the algorithm
sample time to 0.2 (denoted MCMC-2 in Table 1) which would cause more delay in the estimation
result and slower responses to changes in the parameter.
5 Conclusions
This paper presented an adaptive recursive MCMC (ARMCMC), algorithm for an online identifica-
tion of full probability distribution of model parameters in a Bayesian paradigm. When applied to
systems involving abrupt changes of model parameters which can occur when contact with a soft
environment is established or lost, conventional approaches suffer from low performance. Empiri-
cal results on the Hunt-Crossley model as a nonlinear hybrid dynamic model was compared with a
well-known conventional identification approaches and revealed proficiency of the proposed algo-
rithm. The proposed method adapts quickly to abrupt changes which relaxes the pre-requirement
8
Under review as a conference paper at ICLR 2022
Time (Sec)
Figure 5: Probability distribution of parameters (θ1 = Ke , θ2 = Be , θ3 = p) using ARMCMC.
0	2	4	6	8	10	12	14	16	18	20
Time (Sec)
Figure 6: Model parameters (θ1 = Ke ,θ2 =
Be, θ3 = P) point estimation in AR-MAPS.
—MCMC (N=5∞0}
MCMC (T=2∞ms)
RLS
AR-MAPS
O 2	4	6	8	10	12	14	16	18	20
Time (Sec)
Figure 7: Force prediction error in RLS, AR-
APS, and MCMC.
Table 1: Comparison of RLS (Haddadi & Hashtrudi-Zaad, 2012) and point estimate of ARMCMC
and MCMC for environment identification.
ERRORS (MAE)	Ke	Be	p	Fe (MN)
RLS	0.5793	0.9642	0.3124	51.745
MCMC- 1	0.6846	0.8392	0.3783	76.695
MCMC-2	0.7294	0.9964	0.4195	101.88
AR-APS	0.0774	0.0347	0.0945	33.774
AR-MAPS	0.0617	0.0316	0.0756	31.659
conditions in the parameters. As future work, deploying a fully probabilistic framework from iden-
tification to control and a decision-making stage is considered to exploit the full potentials of the
Bayesian optimization. Additionally, employing a method to compensate the delay will be taken
into consideration.
9
Under review as a conference paper at ICLR 2022
References
Niki Abolhassani, Rajni Patel, and Mehrdad Moallem. Needle insertion into soft tissue: A survey.
Medical Engineering and Physics, 29(4):413-431, 2007.
Pedram Agand and Mahdi Aliyari Shoorehdeli. Adaptive model learning of neural networks with
uub stability for robot dynamic estimation. In 2019 International Joint Conference on Neural
Networks (IJCNN), pp. 1-6. IEEE, 2019.
Pedram Agand, Hamid D Taghirad, and Ali Khaki-Sedigh. Particle filters for non-gaussian hunt-
crossley model of environment in bilateral teleoperation. In 4th International Conference on
Robotics and Mechatronics (ICROM), pp. 512-517. IEEE, 2016.
S Bhasin, K Dupree, PM Patre, and WE Dixon. Neural network control of a robot interacting with an
uncertain hunt-crossley viscoelastic environment. In Dynamic Systems and Control Conference,
volume 43352, pp. 875-882, 2008.
Christopher M Bishop. Pattern recognition. Machine Learning, 128, 2006.
Steve Brooks, Andrew Gelman, Galin Jones, and Xiao-Li Meng. Handbook of markov chain monte
carlo. CRC press, 2011.
Andre S Carvalho and Jorge M Martins. Exact restitution and generalizations for the hunt-crossley
contact model. Mechanism and Machine Theory, 139:174-194, 2019.
Noah J Cowan, Ken Goldberg, Gregory S Chirikjian, Gabor Fichtinger, Ron Alterovitz, Kyle B
Reed, Vinutha Kallem, Wooram Park, Sarthak Misra, and Allison M Okamura. Robotic needle
steering: Design, modeling, planning, and image guidance. In Surgical Robotics, pp. 557-582.
Springer, 2011.
Nicola Diolaiti, Claudio Melchiorri, and Stefano Stramigioli. Contact impedance estimation for
robotic systems. IEEE Transactions on Robotics, 21(5):925-935, 2005.
Peter J Green. Reversible jump markov chain monte carlo computation and bayesian model deter-
mination. Biometrika, 82(4):711-732, 1995.
Peter L Green. Bayesian system identification of a nonlinear dynamical system using a novel variant
of simulated annealing. Mechanical Systems and Signal Processing, 52:133-146, 2015.
Amir Haddadi and Keyvan Hashtrudi-Zaad. Real-time identification of hunt-crossley dynamic mod-
els of contact environments. IEEE transactions on robotics, 28(3):555-566, 2012.
KH Hunt and FRE Crossley. Coefficient of restitution interpreted as damping in vibroimpact. Jour-
nal of applied mechanics, 42(2):440-445, 1975.
Dominik Joho, Gian Diego Tipaldi, Nikolas Engelhard, Cyrill Stachniss, and Wolfram Burgard.
Nonparametric bayesian models for unsupervised scene analysis and reconstruction. Robotics:
Science and Systems VIII, pp. 161, 2013.
Shima Khatibisepehr, Biao Huang, and Swanand Khare. Design of inferential sensors in the process
industry: A review of bayesian methods. Journal of Process Control, 23(10):1575-1596, 2013.
Scott Kuindersma, Roderic Grupen, and Andrew Barto. Variational bayesian optimization for run-
time risk-sensitive control. Robotics: Science and Systems VIII, 2012.
TomaSz KU6mierczyk, Joseph Sakaya, and Arto Klami. Variational bayesian decision-making for
continuous utilities. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d Alche-Buc, E. Fox, and
R. Garnett (eds.), Advances in Neural Information Processing Systems 32, pp. 6392-6402. Curran
Associates, Inc., 2019.
Brett Ninness and Soren Henriksen. Bayesian system identification via markov chain monte carlo
techniques. Automatica, 46(1):40-51, 2010.
Ali Noormohammadi-Asl and Hamid D Taghirad. Multi-goal motion planning using traveling sales-
man problem in belief space. Information Sciences, 471:164-184, 2019.
10
Under review as a conference paper at ICLR 2022
Kaur Aare Saar, Fabio Giardina, and Fumiya Iida. Model-free design optimization of a hopping
robot and its comparison with a human designer. IEEE Robotics and Automation Letters, 3(2):
1245-1251,2018.
Roberto Tempo, Giuseppe Calafiore, and Fabrizio Dabbene. Randomized algorithms for analysis
and control of uncertain systems: with applications. Springer Science & Business Media, 2012.
Felipe Tobar. Bayesian nonparametric spectral estimation. In S. Bengio, H. Wallach, H. Larochelle,
K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing
Systems 31, pp. 10127-10137. Curran Associates, Inc., 2018.
Beilun Wang, Arshdeep Sekhon, and Yanjun Qi. A fast and scalable joint estimator for integrat-
ing additional knowledge in learning multiple related sparse Gaussian graphical models. In
Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th International Conference on
Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 5161-5170,
Stockholmsmassan, Stockholm Sweden, 10-15 Jul 2018. PMLR.
Tao Wang, Yunce Zhang, Zheng Chen, and Shiqiang Zhu. Parameter identification and model-
based nonlinear robust control of fluidic soft bending actuators. IEEE/ASME Transactions on
Mechatronics, 24(3):1346-1355, 2019.
A Appendix
According to Abolhassani et al. (2007), a nonlinear hybrid model based on a reality-based soft
environment is considered as follows:
fe = fst(x,t,tp) + ffr(x,X) + fct(x,t,tp),
(21)
where x is the needle tip position and tp is the latest time of puncture. Initial position of the envi-
ronment is assumed to be at the origin. The stiffness of the force (fst) belongs to a pre-puncture and
the friction (ffr) and cutting forces (fct) belong to a post-puncture. The stiffness force is modeled
using a nonlinear Hunt-Crossley model:
(0	x < 0
fst(x, t, tp) = Kexp (t)	0 ≤ x ≤ x1, t < tp	(22)
(0	X > X2,t ≥ tp
where Ke,p are the same parameters defined in (17). The maximum depth that the soft environment
yields before the puncture and its position after it is denoted by x1, x2, respectively (0 < x2 < x1).
In this study, the needle can insert up to 16.65, 10.21 mm before and after penetration. A friction
model is inspired from modified Karnopp model.
ffr(x,x)
Cnsgn(X) + Bexpx
max(Dn, Fa)
max(Dp, Fa)
Cpsgn(X) + Bexpx
X ≤ —∆v∕2
-∆v∕2 <x ≤ 0
0 < x < ∆v∕2
x ≥ ∆v∕2
(23)
where Cn = —11.96 × 10-3 and Cp = 10.57 × 10-3 are negative and positive values of dynamic
friction, Dn = —0.01823 and Dp = 0.01845 are negative and positive values of static friction, and
Be,P are same as Eq. (17). The relative velocity between the needle and tissue is denoted by x, and
∆v∕2 = 0.005 is the value below where the velocity is considered to be zero, and Fa is the sum of
non-frictional applied forces. The cutting force is considered as a static force constant for the tissue
and the needle geometry if soft tissues are not inhomogeneous and anisotropic (Cowan et al., 2011)
fct (x, t, tp )
00.94
x ≤ x1 , t < tp
x > x2 , t ≥ tp
(24)
According to the previous relations, the system is considered as a hybrid model while providing
both free motion and in-contact environment. The manipulator is a translational mechanism with
a friction, slip, and hysteresis loop for the actuator. To present the superiority of the proposed
algorithm, the results are compared with the RLS method presented by Haddadi & Hashtrudi-Zaad
(2012). To prevent the results of RLS from divergence in model mismatch sequences, saturation is
applied in the outputs of the identifier.
11