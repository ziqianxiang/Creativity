Under review as a conference paper at ICLR 2022
Larger Model Causes Lower Classification
Accuracy Under Differential Privacy: Reason
and Solution
Anonymous authors
Paper under double-blind review
Ab stract
Differential privacy (DP) is an essential technique for privacy-preserving, which
works by adding random noise to the data. In deep learning, DP-stochastic gra-
dient descent (SGD) is a popular technique to build privacy-preserving models.
With a small noise, however, the large model (such as ResNet50) trained by DP-
SGD cannot perform better than the small model (such as ResNet18). To bet-
ter understand this phenomenon, we study high dimensional DP learning from
the viewpoint of generalization. Theoretically, we first demonstrate that for the
Gaussian mixture model with even small DP noise, if excess features are used,
classification can be as bad as the random guessing since the noise accumulation
for the estimation in high dimensional feature space. Then we propose a robust
measure to select the important features, which trades off the model accuracy and
privacy preserving. Moreover, the conditions under which important features can
be selected by the proposed measure are established. Simulation on the real data
(such as CIFAR-10) supports our theoretical results and reveals the advantage of
the proposed classification and privacy preserving procedure.
1	Introduction
Deep neural networks have made a series of remarkable achievements in the field of image recog-
nition and classification, natural language processing. But training deep neural networks typically
requires large and representative data to achieve high-performance Gheisari et al. (2017). Since
the datasets often contain some sensitive information, such as medical records, location, purchase
history, when we use these sensitive data to train a model without specific measures to the secret in-
formation, individual privacy can be leaked Fung et al. (2010). Thus, privacy-preserving is a crucial
issue in deep learning.
One of the most popular techniques for privacy-preserving is (ε, δ)-DP that was first proposed by
Dwork et al. (2014). DP works by adding noise or adding randomness to the data while it provides
a rigorous mathematical framework for preserving privacy, then many works with DP have been
proposed to protect individual privacy Chen and Lin (2014); Goodfellow et al. (2016).
Recently, deep neural networks with millions of parameters have proven to outperform smaller mod-
els (such as GPT-3 Brown et al. (2020)), although the deeper neural networks are more difficult to
train. In He et al. (2016), they present a network called ResNet to overcome this problem and it can
gain accuracy from the considerably increased depth of networks.
When we consider privacy-preserving, DP-SGD (Abadi et al. (2016)) adding Gaussian noise to
gradient is popular to train the neural network (Dupuy et al. (2021)). Then we use DP-SGD to
train ResNet50 and ResNet18, respectively. In Fig. 1, we observe that a degradation problem has
been exposed by adding noise. However, ResNet50 has lower test accuracy than ResNet18. Similar
phenomena on MNIST for CNN is presented in Appendix (see Fig. ??, Fig. ??).
The above observation motivates us to ask the following question:
Why do the larger models cause lower classification accuracy under DP?
1
Under review as a conference paper at ICLR 2022
(a) Accuracy in training set
Figure 1: The performance of ResNet on CIFAR-10 by DP-SGD with ε = 2, δ = 0.0001. (a) is
the result in the training set, we see that both the ResNet 18 and ResNet 50 with noise or without
noise obtain 98% classification accuracy, respectively. (b) is the result in the test set, we see that
the performance of ResNet 50 and ResNet 18 under noiseless condition is the same but ResNet50
causes much lower test accuracy than ResNet18.
(b) Accuracy in test set
We answer this question from the generalization aspects of differential private learning since the
larger model leads to higher test error rather than training error. In addition, we propose to select a
subset of features to trade off the classification accuracy and privacy-preserving.
1.1	Our contributions
•	Generalization bound. We first analyze generalization in a simple GMM model under
DP. By focusing on specific Gaussian noise, we can establish information-theoretic upper
bounds of the classification error, which depends on the size of dimension and noise. With
the increasing of dimension, noise can accumulate on dimension to cause classification er-
ror increase, finally, the classifier performs nearly the same as random guessing. It implies
that the larger model with high dimension cause lower classification accuracy under DP.
•	Feature selection. Since models have increasing classification error with an increasing
number of features, we use the feature selection technique to reduce the dimension. A
novel filter feature selection method is proposed, which uses a distance measure to assign
a scoring to each feature. Comparing with t-statistic, the proposed method can obtain the
stable and important features under DP.
•	Experiment. We perform simulation based on synthetic data and common real data such as
RCV1 (Lewis et al. (2004)), CIFAR-10. After using the proposed feature selection method,
we show that ResNet50 performs better than ResNet18 on CIFAR-10 in terms of DP.
1.2	Outline of the paper
In the next section, we give some definitions and preliminaries. In Section 3, we analyze a simple
GMM model and prove that larger models lead to higher error under DP. Then we proposed a feature
selection algorithm for dimension reduction in differential privacy. The simulation in Section 4
reveals that feature selection can improve the performance and the proposed method performs better
in some real dataset including RCV1 and CIFAR10.
2	Basic Definitions
In this section, we first define (ε, δ)-DP. Moreover, we consider a simple Gaussian mixture model
(GMM) under DP. Then, We will analyze a Fisher classifier for this GMM model.
Definition 1. ( Differential Privacy Dwork (2008)) A randomized algorithm M with domain dataset
D is (ε, δ)-differential private if for all S ⊆ Range (M) and for all x, y ∈ D that kx - yk1 ≤ 1 :
Pr[M(x) ∈ S] ≤ exp(ε) Pr[M(y) ∈ S] + δ.	(1)
2
Under review as a conference paper at ICLR 2022
Since Definition 1 imposes no limitations on randomized algorithm M, we use the following Gaus-
sian mechanism that adding Gaussian noise, which we can create a DP algorithm for function f with
sensitivity ∆f , max kf(di) - f(dj)k1, where the maximum is over all pairs of datasets di and dj
in dataset D differing in at most one element and ∣∣ ∙ ∣∣ι denotes the '1 norm.
Definition 2. (Gaussian Mechanism Dwork et al. (2014)) Given any function f : D → Rk, the
(, δ)-Gaussian mechanism is defined as:
ML(x,f(∙),ε) = f(x) + (Yι,...,Yk)
(2)
where Yi are i.i.d. random variables drawnfrom N(0, σ2) where σ = ∆f ∙ ln(1∕δ)∕e.
Consider the p-dimensional classification problem between two classes C1 and C2 . Suppose our
clean data comes from the Gaussian mixture model (GMM). To analyze the impact of DP, based on
the Gaussian mechanism, we can use GMM adding Gaussian noise to achieve (, δ)-DP.
Definition 3. (Private GMM) Let μk ∈ Rp, k = 1, 2, be the Per-Class mean vector and
Σ , diag(σ12, ...,σp2)
(3)
be the variance Parameter. (, δ)-Private Gaussian mixture model is defined by the following dis-
tribution over (Xk, k) ∈ Rp X {1, 2}: First, draw a label k from {1, 2} uniformly at random, then
sample the data point Xk ∈ Rp from N(μk, Σ). Then we get a non-private dataset {xk, k}, k = 1, 2,
i = 1,... ,nk. Finally, according Gaussian mechanism to obtain dataset {Xk, k}, where
xk = xk + 2CpIn(I∕δ”~ (ηι,…,ηP),	(4)
where η are i.i.dvariables η 〜N (0,1) and Cp，maxk∈{i,2},i≤nk IlXk kι is a constant depending
on dimension p.
From private GMM, We can obtain some training data {Xk, k}, k = 1, 2, i = 1,..., n. Let
n = nι + n2. Using these training data, the parameters μk and Σ can be estimated by
ʌ 1 答八一	ʌ 1 f (S2j + Sj	1
μk = - ∑xk,k = 1,2, ς = diag ɪ-2----, j = 1,.. .,p∖ ,
(5)
where Stkj = ⑺乙)PnkI (Xkj — Xk7J is the sample variance of the j-th feature in class k and
x,. = ɪ Pnk Xi
Xkj = nk 乙i=1 Xkj.
Consider the following classification rule.
Definition 4. (Fisher Classifier Hart et al. (2000)) The Fisher classifier is defined as:
Sn(X) = (x — μ)∑-1α,	(6)
1
where μ = 2 (μι + α2), α = μι 一 “2.
From Definition 4, it shows that if δn(X) > 0, which classifies sample X into class C1. Let us denote
the parameter by θ = (μι, μ2, Σ), we define the following classification error.
Definition 5. (Classification Error) If we have a new observation X from class C1, then the classi-
fication error W(δn, θ) of the Fisher classifier is defined by
___, ʌ	Λ 一 , ʌ	.	■	,	_ ,	,
W(6n, θ) , P(δn (X) ≤ 0|Xk, k = 1, 2, i =1, . . . ,nk ) = 1— φ(ψ),	⑺
where
Ψ =	(μ1 - μ) 0*一 (μ1 - μ2)
{(μι - μk) oςT (μι 一 μk)
and Φ(∙) is the Standard Gaussian distribution function.
(8)
3
Under review as a conference paper at ICLR 2022
3 Theoretical Results
In this section, we first prove that with added noise, the error increases as the dimension increases.
The intuition is that noise for different features can accumulate to cause large classification error.
Then we focus on a criterion suitable for feature selection under DP to reduce dimension. Finally,
we give an algorithm to realize our criterion for a dataset.
3.1 Impact of High Dimension Under DP-Mechanism
In this part, we first give an upper bound for the classification error. Without loss of generality, the
sample data are assumed to be balanced.
Theorem 6. Suppose the training data comes from private GMM (Definition 2) and n1 = n2. In
addition, assume logp = o(n), n = o(p). Then the classification error W(δn, θ) is bounded by
Wi ≤1 - φ (2 [4p++1+Z)Γ]1),	⑼
where δ, G Cp are defined in equation 4, respectively; α = μι 一 μ2 and μι and μ? are the Per-Class
mean vectors; op(1) is a variable decreasing when p increasing;
Γ
XX__________α2
J σj + (2Cp ln(1∕δ)∕e)2
j=1
(10)
where αj is j-th of α and σj2 is defined in equation 3.
Remark 1. The condition logp = o(n), n = o(p) means that n grows much slower than p while
logp grows much slower than n. It is one of the common assumptions to study the high dimensional
learning with low sample size Tsybakov (2003).
Let τ , ln(1∕δ)∕ and p → ∞, we derive an upper bound for Γ defined in equation 10.
γ ‹ (⅛‰
ɪ	Pj= ®∙ι2	≤ ɪ Pj= I。,∣2 ≤ ɪ
T 2 maxa≤nι ,b≤n |用 一 x2k2 — T2 (Pp=I |ai|)2 - T 2
(11)
where the second inequality dues to the definition of Cp . Since Cp is the largest norm of data, the
norm of distance between two classes should not be huger than 2Cp . The third inequality caused by
the maximum distance between two classes is no less than the distance of true means of each class
with probability 1, i.e., P (maxa≤m,b≤n2 IIxa — x§ ∣∣ι ≥ Pj=ι ∣α, ɔ -→ 1.
Note that Γ can be controlled by an upper-bound without p.
Remark 2. We can see two aspects from this theorem. First, for fixed noise with given , δ, when
p→ ∞, denominator in the right side of equation 9 towards infinity. Thus the classification error is
11
W(^n,θ) → 1 — Φ(O(-)) → -,	(12)
√p	2
where O(d) means that it grows at the order of d. According to equation 12, it shows the Fisher
classifier with high dimension performs nearly the same as random guessing, which is similar to the
result in Fan and Fan (2008).
However, when we consider perturbation in equation 9 with fixed p and n. When and δ decrease
to 0, i.e., , T → ∞, which means the noise is large enough. Thus the classification error is
11
W(^n,θ) → 1 — Φ(O(τ2)) → -,	(13)
which is merely random guessing without any ability to classify. Moreover, when p → ∞ and → 0
at the same time, then the classification error is
11
w(6n,θ) → 1 - φ(O( p==4 )) → 2 .	(14)
Compared equation 14 with equation 12, it reveals that the larger noise can speed up the rate of
model degradation.
4
Under review as a conference paper at ICLR 2022
From Theorem 6 and the above remark, it shows that the larger model with high dimension leads
to lower classification accuracy under DP. To trade off the classification accuracy and privacy-
preserving, we use the feature selection technique to reduce the dimension.
3.2	Feature selection
In this subsection, we use filter feature selection methods, which assign a score (often a statistical
measure) to each feature. One typical statistical measure is t-statistics Hua et al. (2009), which is
defined as follows
Tj =	/ x1j	Xx2	j = 1,…，p,	(15)
S12j /n1 + S22j /n2
where Xkj and Skj are defined in equation 5. After computing the values of t-statistic for each
feature, we sort these values in descending order and select the important feature. Moreover, under
the DP setting, we hope the feature selection result is independent of the perturbation.
When there exists a significant difference between the means of two classes, t-statistic can perform
well for finding important features. However, when we add noise to the data, the selected feature
using t-statistic is susceptible to perturbation, since the formulation of t-statistic relies on sample
variance. Specifically, according to the definition of Sk,j defined in equation 5, we calculate the
expectation of Σ as E(∑) = ∑ + (2Cp ln(1∕δ)∕e)2 * Ip. It shows that the DP budget E and δ can
influence the value of t-statistic. Here we also give an example to show it.
Example 1. Consider a binary classification problem based on private GMM (Definition 3). The
variance and mean vector set Σ = diag(1,10) and μι = [0, 0] μx = [5,10] (Fig.2a), respectively.
We sample n1 = n2= 200 for each class.
Firstly, if we use the clean data without adding noise in private GMM, the value of t-statistic, D =
μx 一 μι, S2 and Sx are calculated as thefollowing table.
feature	1	2
D	"ɪ	10
variance	1	10 .
t-statistics	50	31.62
The above table shows that feature 1 has a bigger t-statistics, thus we select feature 1 if we only
require one feature.
Secondly, when we add noise with DP budget of E = 3 in private GMM (Fig.2b), the results are
presented as follows
feature	1	2
D	5	~∏0-
variance perturbed	10	19
t-statistics	15.82	22.94
Thus feature 2 is a better result to be selected.
This example shows the best feature or the sort of t-statistic is not stable to perturbation, which
means a small noise on data may create a new rank and it is harmful for feature selection in DP.
However, numerator of t-statistics is stable since E(μk) = μk regardless of perturbation (see the
first row of the above tables). It suggests us to consider the following distance criterion for selecting
the important feature.
Definition 7. Distance criterion is defined as follow:
D 2 = Xι2 — Xxj,	(16)
where Xkj is the average of class k, feature j.
This is a stable criterion since E(D) = μι — μx whether the data has noise or not. Next, We give
a theorem to show that the proposed distance criterion can distinguish those useful features with
probability one.
Assumption 1.
5
Under review as a conference paper at ICLR 2022
-IO-
N alp!"巴
-2024
feature 1
—Class 1
Class 2
Z alp!"①J
-10
-10	-5	0	5	10	15
feature 1
(a) Feature distribution before perturbation (b) Feature distribution after perturbation
Figure 2: Distribution for classes in different situations. For the left figure, feature 1 of two distribu-
tions is almost no overlap which means this feature is powerful to distinguish class while feature 2
is not so powerful. For the right, both features have overlap. But feature 2 is merely over 1/2 while
feature 1 is about 3/4, so feature 2 is more powerful now.
1.	Assume that distance vector α = μι 一 μ2 is sparse and without loss ofgenerality, only the
first s entries are nonzero.
2.	Assume that the elements of both diagonal matrices Σ1 and Σ2 are bounded with upper
bound v.
In high dimension learning with low size data, sparsity is always a consideration (Grcar et al.
(2005)). Also, variance is normal to be seen as finite, otherwise, estimation of variance will not
be close to true value with a low size of data.
The following theorem describes that all important features can be selected by distance criterion.
Recall that n = n1 + n2 and nk represents sample size of class k.
Theorem 8. Let c1 ≤ n1/n2 ≤ c2, s be a value such that log(p 一 s) = o (nγ) and log s =
o (n2-Yβn) for some βn → ∞ and 0 < γ < 1. Suppose that minj=ι,…,p ∣α,∣ = vn-γβn. Then
under Assumption 1,for y = Cvn(Y-1)/2 with C some positive constant, we have
P (嘤口 Wj J ≥ y and max ∣DDj ∣ < y) → 1.	(17)
Remark 3. From Theorem 8, we observe that the proposed distance criterion can distinguish the
non-zero feature with probability one. When these important features are selected, then the dimen-
sion can be reduced. Thus, combing with Theorem 6, classification accuracy and privacy-preserving
can be traded off by feature selection.
3.3	DP Feature Selection algorithm (DFS)
Based on the proposed distance criterion, we design an integral algorithm to select the important
feature under DP.
Since we clip feature from p to m (m < p), Cp and p in Theorem 6 will become smaller, thus
classification error would be reduced.
Remark 4. This algorithm bases on our private GMM. When we consider a neural network with
inputs of image and text which are not vectors, we will use their latent layer of a neural network as
features to utilize our algorithm.
4 Experiment
In this section, we check our theoretical results by performing experiments on multiple com-
mon datasets, including synthetic data, RCV1 (Lewis et al. (2004)) and CIFAR-10. For all DP-
6
Under review as a conference paper at ICLR 2022
Algorithm 1: DP Feature Selection Algorithm
1 Input:: [[X11],…,[Xin1]]and[[X21 ],...,[X2n2]]
2 Calculate average of features: μι = [a11,…，aip] and μ2 = [a21,…，02p]
3	Calculate distance of features: D = l^ι - μ2∣
4	Rank features with distance: Xr = [[x1[1] ,...,x1[p]],...,[xn[1] ,...,xn[p]]]
5	Cut the first m features: Xc = [[x1[1],...,x1[m]],...,[xn[1] ,...,xn[m]]]
6	Calculate the maximum norm in Xc: Nmax , maxi≤n,Xi∈Xc kXik1
7	Generate noise: n X m matrix ε with i.i.d. εj 〜N(0, 2Nmaχ ln(l∕δ)∕e)
8	Add noise to feature: X = Xc + ε
9	Output: feature with noise X, Label
mechanism, choose normal distribution and set δ = 0.0001. Then for different data set, we choose
different DP budget of e to protect the data.
4.1	synthetic data
For synthetic data, consider two high dimensional Gaussian distributions N(μo, ∑0) and
N(μι, ∑ι), where ∑k = diag(aik,…，apk) with P = 3000 and a% 〜exp(0.1). In addition,
μo = 0 ∈ Rp, μι is a (1 - c)δo + 2Cexp(-2∣x∣), where δo means equals to 0 and C = 0.88.
Using the GMM parameters above, we generate 30 training data and 200 testing data for each class.
To protect privacy, we add some Gaussian noise with e = 5 and e = 10 to all data except labels
basing on private GMM definition3. The Fisher classifier is used to separate these two classes. Fig.
3 presents the test accuracy.
0
20
60
80
IM
feature size(×10)
Figure 3: Comparison for different DP parameters and selection. For our algorithm, only 20 features
can generate a model with the highest accuracy in all DP settings while no selection model cannot
reach the best with noise.

In Fig.3, we observe that the proposed algorithm performs well in feature selection under differ-
ent noise levels. In noiseless condition, the performance of feature selection and without feature
selection is the same. However, within 20 features selected by DFS, our algorithm converges to 0
test error while feature without selection needs more than 1000 features. Moreover, DFS can select
features to maintain the best accuracy for more than 500 features. Also, without feature selection,
result is not smooth since some perturbing data influence the performance.
In Fig.4a, a comparison of proposed algorithms with t-statistic in terms of test error has been pre-
sented. It shows that the increase of dimension leads to the decrease of performance, which is
consistent with Theorem 6. However, the curve of the proposed method is below that of t-statistic,
thus the proposed method can reduce the influence of high dimension. Since the larger ε means the
smaller noise, Fig. 4b shows the test error decreasing with the increasing the ε while the proposed
method can reduce the test error much more. In addition, in both figures, our curves maintain paral-
7
Under review as a conference paper at ICLR 2022
α	zα	to	∞	so	wo
feature selected
(a) fixed ε = 4 with increasing p
β.aα
0.25
-----DFS
-----t-statistics
」0J」①φjs①φj
2	«	6	«	10
ε-DP
(b) fixed p = 70 with increasing ε
Figure 4: Results for the numerical dataset. The left figure shows that our DFS maintains stable
for p < 30 while t-statistic climbing all the time. Right shows that for fixed p, comparing with
t-statistic, DFS obtain higher accuracy with the same DP budget ε.
lel for a long time, which means the proposed method is more resilient to dimension increasing and
noise accumulation.
4.2	RCV1
RCV1 dataset is a famous embedding set. So we can regard it as features after extractor. Then we
set it into a binary classification problem by choosing random 2 classes and draw 40 data each for
training and 200 for the test.
」0J」①φjs①φj
O	10	20	30	4a	5β
feature selected
(a) fixed ε = 6 with increasing p
2	4	6	«	W
ε-DP
(b) fixed p = 20 with increasing ε
Figure 5: Results for RCV1. The left figure shows when the dimension of feature comes to 9, both
algorithm reaches the best accuracy while DFS gets 0.06 test error. Right shows for DP budget ε
from 1 to 6, test error of DFS is much smaller than that of t-statistic.
For Fig.5a and 5b, it also shows the test error of DFS is smaller than that of t-statistic. Itis convinced
that our algorithm can outperform traditional selection methods by t-statistic in the DP condition.
Thus the proposed method provides a solution for the issue in the introduction.
4.3	CIFAR 1 0
Recall our original problem in the introduction that ResNet50 draws back more due to noise ac-
cumulation, our selection rule helps to reduce this tendency. (Algorithm for multiple classes and
details in this experiment is listed in the appendix.)
In this experiment, we use the last but one layer data of ResNet to represent the input data in our
algorithm. Then adding perturbation on data according to the largest norm with the definition of
8
Under review as a conference paper at ICLR 2022
DFS. For a fair comparison, since ResNet18 has 512 features, we select 512 features from 2048 in
ResNet50. Then we use multi-layer perceptrons (MLP) to train it with SGD without noise.
CIFAR-10
Model	Min	Max	Median
ResNet50	75.5	79.2	77.0
ResNet18	83.6	85.3	84.5
ResNet50+t-sta	78.4	81.3	80.1
ResNet50+DFS	84.8	86.4	85.7
Table 1: Result for features on CIFAR10 with ResNet18/50 under DP condition. We select 512
features from ResNet50 by DFS, then we see ResNet50 performs better than ResNet18. But the test
accuracy of ResNet50 by t-statistics is less than that of ResNet18.
In table 1, beyond that our algorithm can raise accuracy for ResNet50, we also show that our method
is better than the classic approaches which consider variance like t-statistics.
5	Conclusions
This paper has studied the phenomenon that the larger model causes lower classification accuracy
under DP. To illustrate our idea, we have considered a simple model for analysis. When noise or
dimension tends to infinity, the classifier using all features performs nearly the same as random
guessing. Hence it is necessary to find a method to reduce the dimension of the data. Based on
a robust distance criterion, we can select the important features with probability one. Finally, we
propose DFS algorithm to trade off the classification accuracy and privacy-preserving. Simulation
reveals that the proposed DFS algorithm enjoys better performance on the real data.
6	Related Work
Differential Privacy: In Xu et al. (2019), it considers both input-DP which adds noise on data pro-
cessing, and output-DP which perturbs the answer of questions, and propose practical algorithms
to show how to deal with two DP mechanisms. For the complicated situation like neural network,
DP-SGD has been proved in utility (Chen et al. (2020)) with bounds for convergence after clip-
ping gradient. Considering dimensions, Bassily et al. (2014) points that under assumptions of loss
function and parameters, empirical risk can degenerate with dimension increment under differential
privacy. Recently on neural network, Tramer and Boneh (2021) shows that linear models trained on
handcrafted features significantly outperform neural networks for moderate privacy budgets. How-
ever, they did not consider and set experiment for the affect of the dimension for the same type of
model with accuracy instead of empirical risk.
High Dimension Low Sample Size Data: In low sample size n and high dimension p, Hall et al.
(2005) studies the impact of the increasing n with fixed p, and they propose a geometric repre-
sentation method for high-dimension data. For a linear model, Tsybakov (2003) propose a similar
assumption with our condition and achieve a risk bound. For a neural network, Liu et al. (2017)
propose DNP network to train on low sample by dropouts. DNP trains model by dropping neutrons
randomly to minimize model size to increase model stability. Their works are powerful but in clean
data, not concerning about privacy which people concerns.
Feature Selection: There are many traditional methods like wrapper and filter (Hart et al. (2000)) to
select ‘important’ features for the clean data. Also, for neural network, an approach named pruning
(Han et al. (2015)) come out for cutting neurons in network for maintaining low dimension of a
model. Considering utility, the robustness of selection has been considered in Ilyas et al. (2019).
They propose an algorithm to separate features with robustness in a certain model by adversary per-
turbation: changing labels for classes. However, their work either bases on clean data or adversary
perturbation, which is not suitable for DP.
9
Under review as a conference paper at ICLR 2022
References
Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and
Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC
Conference on Computer and Communications Security, pages 308-318, 2016.
R. Bassily, A. Smith, and A. Thakurta. Differentially private empirical risk minimization: Efficient
algorithms and tight error bounds. Computer Science, 2014.
Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are
few-shot learners. arXiv preprint arXiv:2005.14165, 2020.
Xiangyi Chen, Steven Z Wu, and Mingyi Hong. Understanding gradient clipping in private sgd: a
geometric perspective. Advances in Neural Information Processing Systems, 33, 2020.
Xue-Wen Chen and Xiaotong Lin. Big data deep learning: Challenges and perspectives. IEEE
Access, 2:514-525, 2014.
Christophe Dupuy, Radhika Arava, Rahul Gupta, and Anna Rumshisky. An efficient dp-sgd mech-
anism for large scale nlp models. arXiv preprint arXiv:2107.14586, 2021.
Cynthia Dwork. Differential privacy: A survey of results. In International Conference on Theory
and Applications of Models of Computation, pages 1-19. Springer, 2008.
Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. Foundations
and Trends in Theoretical Computer Science, 9(3-4):211-407, 2014.
Jianqing Fan and Yingying Fan. High dimensional classification using features annealed indepen-
dence rules. Annals of Statistics, 36(6):2605, 2008.
Benjamin CM Fung, Ke Wang, Rui Chen, and Philip S Yu. Privacy-preserving data publishing: A
survey of recent developments. ACM Computing Surveys (Csur), 42(4):1-53, 2010.
Mehdi Gheisari, Guojun Wang, and Md Zakirul Alam Bhuiyan. A survey on deep learning in big
data. In 2017 IEEE International Conference on Computational Science and Engineering (CSE)
and IEEE International Conference on Embedded and Ubiquitous Computing (EUC), volume 2,
pages 173-180. IEEE, 2017.
Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep learning. MIT press, 2016.
Miha Grcar, DUnja Mladenic, Blaz Fortuna, and Marko Grobelnik. Data sparsity issues in the
collaborative filtering framework. In International Workshop on Knowledge Discovery on the
Web, pages 58-76. Springer, 2005.
Peter Hall, James Stephen Marron, and Amnon Neeman. Geometric representation of high di-
mension, low sample size data. Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 67(3):427-444, 2005.
Song Han, Jeff Pool, John Tran, and William J Dally. Learning both weights and connections for
efficient neural networks. arXiv preprint arXiv:1506.02626, 2015.
Peter E Hart, David G Stork, and Richard O Duda. Pattern classification. Wiley Hoboken, 2000.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE Conference on Computer vVision and Pattern Recognition,
pages 770-778, 2016.
Jianping Hua, Waibhav D Tembe, and Edward R Dougherty. Performance of feature-selection meth-
ods in the classification of high-dimension data. Pattern Recognition, 42(3):409-424, 2009.
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and Aleksander
Madry. Adversarial examples are not bugs, they are features. arXiv preprint arXiv:1905.02175,
2019.
10
Under review as a conference paper at ICLR 2022
David D Lewis, Yiming Yang, Tony Russell-Rose, and Fan Li. Rcv1: A new benchmark collection
for text categorization research. Journal ofMachine Learning Research, 5:361-397, 2004.
Bo Liu, Ying Wei, Yu Zhang, and Qiang Yang. Deep neural networks for high dimension, low
sample size data. In International Joint Conference on Artificial Intelligence, pages 2287-2293,
2017.
Florian Tramer and Dan Boneh. Differentially private learning needs better features (or much more
data). In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event,
Austria, May 3-7, 2021. OpenReview.net, 2021.
A. B. Tsybakov. Optimal rates of aggregation. Digital Bibliography & Library Project, 2003.
Yahong Xu, Geng Yang, and Shuangjie Bai. Laplace input and output perturbation for differentially
private principal components analysis. Security and Communication Networks, 2019, 2019.
11