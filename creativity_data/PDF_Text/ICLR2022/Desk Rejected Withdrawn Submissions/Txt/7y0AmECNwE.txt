Under review as a conference paper at ICLR 2022
Parameter Estimation for the SEIR Model
Using Recurrent Nets
Anonymous authors
Paper under double-blind review
Ab stract
The standard way to estimate the parameters ΘSEIR (e.g., the transmission rate β)
of an SEIR model is to use grid search, where simulations are performed on each
set of parameters, and the parameter set leading to the least L2 distance between
predicted number of infections and observed infections is selected. This brute-force
strategy is not only time consuming, as simulations are slow when the population
is large, but also inaccurate, since it is impossible to enumerate all parameter
combinations. To address these issues, in this paper, we propose to transform
the non-differentiable problem of finding optimal ΘSEIR to a differentiable one,
where we first train a recurrent net to fit a small number of simulation data. Next,
based on this recurrent net that is able to generalize SEIR simulations, we are
able to transform the objective to a differentiable one with respect to ΘSEIR, and
straightforwardly obtain its optimal value. The proposed strategy is both time
efficient as it only relies on a small number of SEIR simulations, and accurate as
we are able to find the optimal ΘSEIR based on the differentiable objective. On two
COVID-19 datasets, we observe that the proposed strategy leads to significantly
better parameter estimations with a smaller number of simulations.
1 Introduction
The SEIR model (Kermack & McKendrick, 1927; Bj0rnstad et al., 2002; Harko et al., 2014; Kendall,
2020) is a widely-used epidemiological model to predict the macroscopic behavior of disease spread
through a population, e.g., the spread of COVID-19 among different populations at different locations
over time (Estrada, 2020; Prem et al., 2020; Godio et al., 2020; Aleta et al., 2020; Chang et al.,
2021; Grimm et al., 2021). A typical SEIR model models the spread dynamics of disease using
four states of populations: susceptible (S), exposed (E), infectious (I) and recovered (R), where
susceptible individuals can be transformed into the exposed, and later to the infectious and finally to
the recovered. Each transition is associated with corresponding parameter(s), forming the parameter
set ΘSEIR for the model: transmission rate for S → E, infection rate for E → I and recovery rate
for I → R. ΘSEIR captures the spreading pattern of the disease, the learning of which is thus crucial
for understanding the disease spread, and developing social-distancing or interventions policies.
Existing SEIR models relies on grid search to estimate ΘSEIR via simulations. Model simulations
are performed on different sets of parameters, and the set that has the smallest L2 distance between
the predicted number of infections and the observed number of infections is selected as the best
parameter combination. This is because of the non-differentiable nature of the L2 objective with
respect to ΘSEIR: predicted number of infections are obtained from discrete simulations. This learning
process is (1) high time-intensive: the simulation process can be slow when the population is large,
which gives a time complexity of O(MNT) where M is the number of simulations performed, N
is total number of individuals and T is maximum time steps; besides, the search space will grow
exponentially with respect to the number of parameters we need to estimate; and (2) inaccurate:
because it is impractical to enumerate all possible combinations of parameters in the continuous
space, the resulting parameter combination would be sub-optimal given a limited amount of trials.
To address these issues, in this paper, we propose to transform the original non-differentiable
simulation problem into a differentiable one using neural recurrent nets for parameter estimation
in SEIR models. The basic idea is that neural recurrent nets are differentiable with respect to the
input learnable parameters, so that they are able to automatically learn these parameters via gradient
1
Under review as a conference paper at ICLR 2022
Mobility network at time step t
Mobility network at time step t + 1
Figure 1: An overview of a standard SEIR model (left) the mobility network (right: from time t to
time t + 1, person p3 moved from location lι to l3, and pi moved from lι to l2).
descent and backpropagation (Rumelhart et al., 1986). Another advantage neural recurrent nets offer
is that they intrinsically model the temporal changes of observations, and have the potentials to make
accurate predictions about the number of individuals at each time step. To train the recurrent net, we
first harvest the training data by running a few SEIR simulations, leading to a collection of simulated
data under different parameter combinations. Next, a recurrent net is trained to fit these simulations.
Then with model parameters of the the recurrent net ΘLSTM fixed, the observation data are used to
train the net with respect to the SEIR parameters ΘSEIR via gradient descent, leading to the optimal
parameter values ΘSeir.
The proposed strategy is both time efficient in that it only relies on a small number of SEIR simulations,
and accurate because we are able to find the optimal parameters ΘSeir based on the differentiable
objective. Through experiments on two COVID-19 datasets, we observe that the proposed strategy
leads to more accurate parameter estimates with significantly better time efficiency.
2 Background and Problem S tatement
This work focuses on estimating the parameters ΘSEIR in the SEIR mode. A standard SEIR model
is formulated in terms of 4 populations of individuals: the susceptible population (S), the exposed
population (E), the infectious population (I) and the recovered population (R), which are respectively
comprised of all individuals susceptible to the infection,all individuals that have contacted infected
patients but are currently during their incubation period, infected individuals that can transmit the
disease to susceptible population, and recovered individuals that cannot become infected again and
cannot transmit the disease to others. Given a mobility network Gt = ({P, L}, E)t at time step
t(t = 1,2,…，T) where P is the set of person nodes, L is the set of location nodes and E is the
set of edges linking persons to locations, the SEIR model needs to predict, what the numbers of
individuals for these populations are in different locations at time step t, according to the preceding
populations progress, the current mobility network and a set of parameters controlling the probability
of transferring from one state of population to the next state.
Formally, we use the superscript l to represent a specific location l and use the subscript t to represent
the time point t, e.g., Stl is the number of individuals for state S in location l at time step t. The
number for all populations in location l at time step t is denoted by Ntl = Stl + Etl + Itl + Rlt , and
St = Pl Stl is the population for all locations at time t (the same for Et, It, Rt). We further assume a
constant overall population N = Nt = St + Et + It + Rt , ∀t. There are three sets of parameters β, κ
and γ controlling how likely that a person currently at one particular state would transfer to the next
state. β controls the probability of transferring from S to E, and κ and γ are respectively responsible
for tranferring from E to I and I to R. β can be a set of values, representing the transmission rate for
different location categories or cities. κ and γ can also be a set of values, representing the infection
and recovery rates for different population groups. With a fixed set of parameters and the mobility
network, the SEIR model can simulate the disease spread process and predict the numbers of these
four populations at each time step for a location. The probability of an individual transferring from
2
Under review as a conference paper at ICLR 2022
one state to the next at location l for time step t can be formulated as:
卜t(S → E)= βN
plt(E → I) = κ	(1)
[pt(I → R)= Y
During simulations, the state for each individual is sampled. An illustration is shown in Figure 1. The
sum of the L2 distances between the observed infections and the predicted infections over all time
steps is the simulation error for a particular set of parameters, and the best parameter combination is
selected to minimize the simulation error:
ΘSeir = β*,κ*,γ* = arg min X ∣∣It - It∣∣2	⑵
β,κ,γ t
We use the hat notation ^ to represent the prediction made by the model. Towards finding the (near)
optimal parameter combination in Eq.(2), the SEIR models needs to run Eq.(1) over all individuals
for T time steps, which gives a total time complexity of O(NT ).
3	Modeling the SEIR Process Using Recurrent Nets
3.1	Overview
The core idea of the proposed framework is that, instead of using the brute force grid search strategy
to obtain the parameter set that leads to the least L2 distance between predictions and observations,
we train a recurrent net to fit the time-series data of SEIR based on a small number of simulations
using different sets of parameters. The trained recurrent net can then be used to directly find the
optimal value of ΘSeir, which denotes the parameter set for SEIR that leads to the optimal predictions.
We employ the widely used Long Short-Term Memory network (LSTM) (Hochreiter & Schmidhuber,
1997) as the recurrent net model backbone.
3.2	Simulation Dataset Construction
The first step of the proposed framework is to generate smiulation data, which will be used to train
the recurrent LSTM net. We first use different sets of ΘSEIR to perform simulations on the predefined
network, as in Eq.(1). We perform M0 simulations with M0 different sets of ΘSEIR, denoted by
{Θ(SmEIR)}mM00=1. At each time step t, we iterate over all individuals, assign the previous state (i.e., S,
E, I or R) of an individual, and sample its current state based on the SEIR model. Then, we sum up
all individuals belonging to the same states, and obtain {St(m ), Et(m ), It(m ), Rt(m )} for time step t.
3.3	Training the Recurrent Nets
Next, we train an recurrent net to fit {St(m0), Et(m0), It(m0), Rt(m0)}. Our goal is to use LSTM to predict
the values of {St(m ), Et(m ), It(m ), Rt(m )} for each time step t for each parameter combination in
{Θ(SmEI0R) }mM00=1. Specifically, for each time step t, the input to the LSTM model is denoted by
x(tm0) = {St(-m10), Et(-m10), It(-m10), Rt(-m10)}, the populations of the four states at the previous time step.
(m0)
The model should also be aware of the value of ΘSEIR and the mobility network structure at time
step t because they directly decide the number of individuals for the four states for the next time
step. To serve this propose, we also feed Θ(SmEIR) as input to the LSTM model at time step t. For the
time-varying mobility network Gt , we map it to a vector representation hGt , which is able to capture
its mobility structure and be conveniently fed to the LSTM network.
Mapping Gt to hGt We use the DIFFPOOL model (Ying et al., 2018) to map the mobility network
Gt at time step t to its high-dimensional representation hGt . DIFFPOOL is a differentiable pooling
model that can generate hierarchical representations of graphs by progressively clustering nodes into a
coarser graph. Specifically, at each layer l, DIFFPOOL learns an assignment matrix S(l) ∈ Rnl×nl+1
to assign each node at layer l to a cluster in the next layer l + 1, where nl is the number of nodes
3
Under review as a conference paper at ICLR 2022
(clusters) at layer l. Given node embeddings Z(l) ∈ Rnl ×d and the adjacency matrix A(l) ∈ Rnl ×nl
at layer l, DIFFPOOL generates the new node embeddings Z(l+1) ∈ Rnl+1 ×d, the new adjacency
matrix A(l+1) ∈ Rnl+1 ×nl+1 and the new assignment matrix S(l+1) ∈ Rnl+1 ×nl+2 by applying the
following equations:
Z(l+1) =GNNl,embed(A(l+1),X(l+1)), S(l+1) =softmaxGNNl,pool(A(l+1),X(l+1))
X (l+1) = S(l)>Z(l), A(l+1) = S(l) >A(l) S(l)
GNNl,embed and GNNl,pool are two distinctly parameterized GNN, and are respectively responsible
for generating new embeddings and producing a distribution over next-layer clusters. Setting the
number of clusters at the last layer L to 1, DIFFPOOL outputs a single high-dimensional graph
representation. We train DIFFPOOL to classify the graph Gt at time step t to the category label t, and
use the extracted graph representation hGt as input to the LSTM.
Training LSTMs ΘLSTM Given ht(-m10), xt(m0), Θ(SmEI0R) and hGt, we are able to obtain the hidden
vector representation ht(m0) for the time step t:
itftotl
σ
σ
σ
tanh
h(m0)
ht-1
τ(m0)
Xt
hGt
Θ(m0)
ΘSEIR
(4)
W ∙
Ct = ft ∙ ct-1 + it Tt
h(m ) = θt∙ tanh(ct)
(5)
(6)
where Wi, Wf, Wo, Wl ∈ 肽仆(2仆4+回加)where K is the dimensionality of hm0 and hgt.
h(m ) is then passed to a fully connected layer to obtain h(m ), which is mapped to scalars to predict
{St(m0),Et(m0),It(m0),R(tm0)}:
Stm) = h> × h(m0)
E(m0) = h> × h(m0)
I(m0) = h> × h(m0)
RRmO = h> × h(m0)
(7)
where hS, hE, hI, hR ∈ RK×1. The training objective is minimizing the distance between simula-
tion outputs {S(m ),E(m ),Itm ),R(m )} andLSTM predictions {Stm ),Etm ),Itm ), RRtm )}:
ΘLstm = arg min X[kS(m0)-S(m0)k2 + kE(m0)-E(m0)∣∣2 + kl(m0)-I(m0)k2 + kR(m0)-R(m0)∣∣2] (8)
ΘLSTM
t,m0
Eq. 8 can be trained in an end-to-end fashion to obtain optimal ΘLSTM.
3.4	FINDING OPTIMAL ΘSEIR
The LSTM model with ΘLstm is able to generalize the behavior of the SEIR model with a specific
tm0)
value of Θseir. When training the LSTM to learn ΘLstm, Θseir is set to a fixed value of ΘSeiR and
fed as input to LSTMs at each time step. Due to the fact that ΘSEIR can also be viewed as parameters
in LSTMs, i.e., the input to each time step, we can fix ΘLstm and relax Θseir, treating Θseir as
learnable parameters, to minimize Eq.(2) which we write down here for reference:
θSeir = β*,κ*,γ* = arg min 1 X kIt - Itk2	⑵
β,κ,γ T t
where It is the output from LSTM, and It is the observation data rather than the simulation data used
to train the LSTM. Eq.(2) is differentiable with respect to ΘSEiR and can be trained in an end-to-end
4
Under review as a conference paper at ICLR 2022
fashion based on SGD (Kiefer et al., 1952; Rumelhart et al., 1986). To this end, we learn the optimal
values of ΘSEIR that minimize the L2 distance between predicted infections and observations.
In the case where we have prior knowledge about the values ΘSEIR, e.g., all values in ΘSEIR should be
larger than 0, the value of β is usually smaller than 0.1 based on clinical observations for COVID-19
(Chang et al., 2021), we can incorporate regularizers as side objectives:
θSeIR = argmin = X 1 kIt - Itk2 + λllθSEIR - PrioKθsEIR) ||2	⑼
ΘSEIR	t T
where Prior(ΘSEIR ) denotes the human Prior knowledge regarding the values of ΘSEIR, and λ controls
the trade-off. We will exPlore the effects of Prior(ΘSEIR) and λ in exPeriments.
4	Experiments
4.1	Datasets and Corresponding SEIR Models
We use two Public datasets for evaluations: the infection network of Covid-19 in China (Covid-China)
(Sun et al., 2021; Liu et al., 2021), and the infection network of Covid-19 in the US (Covid-US)
(Chang et al., 2021).
Covid-China consists of infection networks for 31 Provinces in China from APr 2020 to Feb 2021,
extracted from action tracking rePorts of Covid-19 Patients. The network of Covid-China consists
of two tyPes of nodes: Patient and location. Time-varying edges are constructed between a Patient
node and a location node if the Patient visited the location at time t. Each location takes an at-
tribute from 11 categories of locations: households, workplaces, hotels, supermarkets,
banks, restaurants, parks,barber shops/hairdressers, trains, buses, and
airplanes, and the economic city tier (first, second or third) that it belongs to. A Patient node is
characterized by features of age (taking the value of children, youths, adults or seniors) and gender
(taking the value of male and female). Each attribute for gender, age, city-tier and location tyPe is
associated with a sPecific transmission rate β. The transmission rate for a certain Person node of
gender s, age a in location of tyPe c in a city of tier t is the additive combination of corresPonding β :
β (s, a, t, c) = βs + βa + βt + βc	(10)
β = {βs, βa, βt, βc}, along with γ and κ are Parameters to learn. The network for each city is sliced
into consecutive time sniPPets, with the size of stride set to two weeks. For each city, we have daily
gold number of infections, Public by Chinese CDC. These gold numbers of infections are used to
learn ΘSEIR. SniPPets without any infection are removed. Each time steP of each city is labeled
with gold number of infections, which is used to train the SEIR Parameters. SniPPets are divided to
80%/10%/10% for training, dev and test.
Covid-US consists of networks that caPture hourly visits from each PoPulation grouP to each location
in 10 metro areas in the US. The network is extracted from mobility data Provided by the SafeGraPh
aPPlication. The network consists of two tyPes of nodes: PoPulation grouP and location. A time-
varying edge with weight wi,j is constructed, if at time t, the number of PeoPle from PoPulation grouP
i visiting location j is wi,j. wi,j is column-normalized. Each location is associated with a location
category (e.g., full-service restaurants, grocery stores, etc), and each PoPulation
grouP is associated with its race and median income. For the SEIR model, transmissions can haPPen
within grouPs or across PoPulation grouPs when two PeoPle from two grouPs visit the same location.
Simulations are Performed at the PoPulation grouP level. Each category location c is associated with
a sPecific transmission rate βc, which caPtures the inter-grouP transmissions across grouPs in the
locations. For each PoPulation grouP with race r and income decile (i), the intra-grouP transmission
is set to β = βr + βi . Each area is associated with gold number of infections Published by the The
New York Times1. Each sniPPet consists of the network for a single city and lasts a week. We divided
sniPPets to 80%/10%/10% for training, dev and test.
4.2	Experimental Details
Generating Simulated Data We first need to samPle ΘSEIR. We limit the value of each β to the
scoPe of [0, 0.1], and we randomly samPle its value within the scoPe. For κ and γ, based on Previous
1https://github.com/nytimes/covid-19-data
5
Under review as a conference paper at ICLR 2022
# Simulations	Vanilla	LSTM	BayesOpt	Regression-ABC	ABC-MCMC
			Covid-China		
20	34.2	22.2	275	25.4	29.1
100	30.1	13.1	17.0	16.2	18.3
500	18.7	9.9	13.2	12.9	14.0
1000	15.2	9.2	11.7	11.1	12.4
5000	13.5	8.6	9.5	9.3	10.4
			Covid-US		
20	1870	1250	1491	1371	1538
100	1530	1130	1289	1275	1438
500	1320	930	1035	1004	1175
1000	1120	824	965	932	1013
5000	970	674	780	776	812
Table 1: Average square L2 distances for vanilla grid search simulation, recurrent LSTMs, Bayesian
optimization, regression-ABC and ABC-MCMC on Covid-China and Covid-US.
clinical observations (Kucharski et al., 2020) where κ-1 is around 96 hours and γ-1 is around 84
hours, we sample κ and γ from a normal distribution with expectation set to 96 and 84. Given a
sampled set of ΘSEIR, we run simulations on the training datasets to obtain the simulation data, i.e.,
the number of individuals for all four states for each time step. For each episode, we take K samples
of Θseir, leading to a total number of K * |train| training sequences, where |train| denotes the number
of training episodes.
Learning LSTMs ΘLSTM to Fit Simulated Data We split the simulated data to 90/10 for training
and validation. We train a three-layer LSTM with residual connections (He et al., 2016; Kim et al.,
2017) to fit the simulated time-series data using for training, based on Eq.(8). Then size of hidden
states is set to 128. The value of batch size is set to 256, and SGD is used for optimization. LSTM
parameters and embeddings are initialized from a uniform distribution in [-0.08,008]. Gradient
clipping is adopted by scaling gradients when the norm exceeds a threshold of 1. Dropout rate,
learning rate and the number of training epochs are treated as hyper-parameters to be tuned on the
dev set.
Learning ΘSEIR We optimize ΘSEIR based on Eq.(9) on the number of gold daily infections, using
the daily reported infections as labels. We use AdaGrad (Duchi et al., 2011) for optimization. Dropout
rate, learning rate, the number of training epochs, and the hyper-parameter λ are tuned on the dev set.
4.3	Results
For the first baseline, we search the optimal ΘSEIR using vanilla grid search SEIR simulations. For
each set of ΘSEIR, simulations are performed on all training episodes, and the parameter set that
leads to the minimum L2 loss is selected as the final value. Suppose that we conduct K explorations
for ΘSEIR. This means we need to perform K simulations on each training episode. The K is
here thus comparable to and the same as the K for simulation data generation. We also implement
the BayesOpt algorithm using the open-sourced package,2 along with the regression-ABC model
described in (Saulnier et al., 2017) and the ABC-MCMC model (Sunnaker et al., 2013).
We report the average of the square of L2 distance between the predicted number and reported
number of infections on the test episodes with varying number of simulations K on the test set.
Lower values indicate superior models. Results are shown in Table 1. As can be seen, the proposed
LSTM model performs better than BayesOpt , regression-ABC and ABC-MCMC, which in turn
performs better than the vanilla model, showing the superiority of the proposed model over BayesOpt.
The explanation is that (1) the neural network-based LSTM provides with better expressivity than
the Bayesian baselines; and (2) the neural model has better capacity of capturing the pattern in the
time-series data of the SEIR model, leading to better performances in general. Comparing the vanilla
simulation and recurrent LSTM, we have the following observations: (1) as the number of simulations
2https://github.com/rmcantin/bayesopt
6
Under review as a conference paper at ICLR 2022
Figure 2: Daily reported cases, predictions made by the vanilla SEIR model, and the predictions
made by LSTM for three cities in China - Shijiazhuang, Harbin and Suihua. Curves are smoothed by
5-day average.
log10(λ)	0	1	2	3	4	5	6	7
Covid-China	10.4	9.9	9.6	9.4	10.1	11.4	13	23.5
Covid-US	890	866	861	842	832	824	899	1423
Table 2: The effect of different values of λ on Covid-China and Covid-US. We show the logarithm
with base 10 for λ. The average square L2 distances are reported.
K increases, the performances for both the vanilla model and the proposed model improve. This is
in accord with our expectations: for the vanilla model, a larger number of simulations means that
the model is able to explore the search space more thoroughly to obtain the optimal value; for the
proposed LSTM model, the model learns better with more training data and avoids overfitting; (2)
with the same number of K, the proposed LSTM model performs significantly better than the vanilla
brute-force search model. This is due to the generalization ability of proposed framework: the vanilla
model can only select the optimal parameters from the set it tries, while the proposed framework can
generalize to the un-tried parameter set; and (3) notably, the proposed framework is able to achieve
comparable performance to the vanilla search model with significantly smaller number of simulations.
Specifically, for Covid-China, the performance obtained with 100 simulations (13.1) is comparable
to the vanilla model with 5,000 simulations (13.5); for Covid-US, the performance obtained with
500 simulations (930) is comparable to the vanilla model with 5,000 simulations (970). This further
illustrates the superiority of the proposed framework.
Figure 2 shows simulations performed on the four test episodes in Covid-China dataset using
parameters learned from the proposed model and the vanilla SEIR model . As can be seen, the
proposed framework offers more accurate predictions.
4.4	Ablation Studies
In this subsection, we explore the effect of different modules, along with hyper-paremeters in the
proposed framework to explore their influence.
The effect of λ The hyper-parameter controls the trade-off between observations and external
prior knowledge. The effect of λ is shown in Table 2. As can be seen, model performance first
improves and then declines as the value of λ grows. Finding the sweep spot for the balance between
observations and prior knowledge leads to the best performance.
The effect of Recurrent Structures We also conduct experiments using other recurrent net struc-
tures, including vanilla recurrent net (RNN), Gated Recurrent Unit (GRU) (Cho et al., 2014), and
Simple Recurrent Units (SRU) (Lei et al., 2017). Results for different recurrent structures are shown
in Table 3. As can be seen, the LSTM structure performs comparable to GRU (slightly worse than
GRU on Covid-China and slightly better on Covid-US), better than the vanilla recurrent net and SRU.
How to incorporate ΘSEIR into LSTMs We explore the effects of different ways to incorporate
ΘSEIR in the LSTM model, including the current strategy of (1) ΘSEIR being concatenated with the
input xt at each time step (Each); (2) ΘSEIR being incorporated only at the first time step (First); and
(3) ΘSEIR element-wise multiplies (Hadamard product) the input for each time step (Hadamard).
7
Under review as a conference paper at ICLR 2022
	CN	US	CN	US	CN	US
LSTM	9.4	824	Each	9.4	824	w/o Graph 24.2	2531
GRU	9.1	831	First	13.5	1007	Constant	18	2013
RNN SRU	12.1 11.5	890 872	Hadamard 9.1	821	Varying	9.4	824
						
			Table 4: The effect of using		Table 5: The effect of graph	
Table 3: The effect of recur-			different strategies to incorpo-		representations.	
rent structures.			rate SEIR parameters.			
For (3), since the dimensionalities of ΘSEIR and xt are different, xt is first passed to an FFN, the
output of which has the same dimensionality with ΘSEIR. Results for the three strategies are shown in
Table 4. As can be seen, ΘSEIR incorporated only at the first time step significantly underperforms
the strategy that incorporates ΘSEIR at every time step. This is because of the gradient vanishing
effect of recurrent nets: reminding the model of ΘSEIR at each time leads to better performances. The
concatenation strategy obtains comparable performances to the Hadamard product strategy.
The Effect of Graph Representation The time-varying location-population network is captured
by the graph representations through DIFFPOOL. This is critical since the number of infections
highly relies on the spreading network for each time. We explore its necessity by comparing it with
other variants: (1) no network (w/o Graph): where no time-varying graph embedding is incorporated;
(2) constant graph representation (Constant): the graph embedding is not time-varying, where we
use the graph embedding of the first time step for all time steps; (3) time-varying graph representation
(Varying): the strategy adopted in this work where time-varying representations are incorporated.
Results are shown in Table 5. As can be seen, when no network information is incorporated, the
model nearly fails to learn anything. Constant networks perform slightly better than no network,
but still significantly worse than the time-vary graph representations. This is in accord with our
expectations since the time-varying network decides the number of infections and the disease spread
patterns at each time.
5	Related Works
The classical compartmental models simplify the mathematical modeling of disease spread by
simulating the population transitions between different states in the disease spread process. Since the
outbreak of Covid-19, the SEIR model has been widely used to model the Covid-19 spread around
the world (Estrada, 2020; Godio et al., 2020; Grimm et al., 2021) and provide important insights
regarding isolation policies (Endo et al., 2020; Carcione et al., 2020; Chang et al., 2021) and vaccine
delivery strategies (Bubar et al., 2021; Ghostine et al., 2021). To achieve a faster simulation speed
and better simulation results, recent works have proposed to leverage deep neural networks in place
of SEIR models to predict pandemic dynamics over time. For example, (Yang et al., 2020) used the
LSTM model to predict the numbers of new infections given the contact statistics and the pre-selected
transmission/incubation/recovery/death rates. (Gao et al., 2021) incorporated sequential network
structures and graph attention to predict the number of infections upon a temporal and spatial mobility
graph. These works aim at taking advantage of SEIR models to inform effective strategies in response
to the disease spread.
With regard to the estimation of the parameters in SEIR models, a simple approach is to enumerate
parameter combinations, run the SEIR model with each combination and select the one with the
smallest error. An alternative to grid search is to use approximate Bayesian computation (ABC)
(Sunnaker et al., 2013; SaUlnier et al., 2017; Raynal et al., 2019), a technique that maintains a small
fraction of simulations that are close to the target statistics in the light of the computed distance.
These simulations are treated as posterior distributions of the SEIR parameters, which are then used
to infer the optimal parameters. Another approach to estimating parameters is to view the process
of population transitions between states as a problem of ordinary differentiable equations (ODEs)
(Kermack & McKendrick, 1927; Hethcote, 2000; Harko et al., 2014). However, ODEs can only give
approximate numerical solutions, which could be inaccurate for real-world modeling.
The most relevant work is from (Tessmer et al., 2018), who proposed to make direct use of existing
neural networks to predict the basic reproduction number (R0), the number of secondary cases
8
Under review as a conference paper at ICLR 2022
generated by an infectious individual in a fully susceptible host population. This work is different
from (Tessmer et al., 2018) in that (1) they sought to estimate the basic reproduction number R0 and
we estimate the parameters in SEIR (or other SEIR variants) models; and more importantly (2) they
propose to directly output the number to estimate given inputs, whereas we propose to automatically
learn the parameters through neural network gradient descent and back-propagation. The proposed
method can be extended to other fields that require time-consuming simulations to estimate necessary
parameters.
6	Conclusion
In this work, we propose to transform the original non-differentiable simulation problem of SEIR
parameter estimation into a differentiable one by leveraging neural recurrent nets. The recurrent net
is first trained to fit a small number of simulation data, and then trained on the observation data to
derive the optimal SEIR parameters. This strategy bypasses the needs of time-consuming simulations,
and automatically induces the optimal parameters via gradient descent, leading to both accuracy and
efficiency gains.
References
Alberto Aleta, David Martin-Corral, Ana Pastore y Piontti, Marco Ajelli, Maria Litvinova, Matteo
Chinazzi, Natalie E Dean, M Elizabeth Halloran, IraM Longini Jr, Stefano Merler, et al. Modelling
the impact of testing, contact tracing and household quarantine on second waves of covid-19.
Nature Human Behaviour, 4(9):964-971, 2020.
Ottar N Bj0rnstad, Barbel F Finkenstadt, and Bryan T Grenfell. Dynamics of measles epidemics:
estimating scaling of transmission rates using a time series sir model. Ecological monographs, 72
(2):169-184, 2002.
Kate M Bubar, Kyle Reinholt, Stephen M Kissler, Marc Lipsitch, Sarah Cobey, Yonatan H Grad,
and Daniel B Larremore. Model-informed covid-19 vaccine prioritization strategies by age and
serostatus. Science, 371(6532):916-921, 2021.
Jose M Carcione, Juan E Santos, Claudio Bagaini, and Jing Ba. A simulation of a covid-19 epidemic
based on a deterministic seir model. Frontiers in public health, 8:230, 2020.
Serina Chang, Emma Pierson, Pang Wei Koh, Jaline Gerardin, Beth Redbird, David Grusky, and Jure
Leskovec. Mobility network models of covid-19 explain inequities and inform reopening. Nature,
589(7840):82-87, 2021.
Kyunghyun Cho, Bart Van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for
statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.
John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and
stochastic optimization. Journal of machine learning research, 12(7), 2011.
Akira Endo et al. Estimating the overdispersion in covid-19 transmission using outbreak sizes outside
china. Wellcome Open Research, 5, 2020.
Ernesto Estrada. Covid-19 and sars-cov-2. modeling the present, looking at the future. Physics
Reports, 2020.
Junyi Gao, Rakshith Sharma, Cheng Qian, Lucas M Glass, Jeffrey Spaeder, Justin Romberg, Jimeng
Sun, and Cao Xiao. Stan: spatio-temporal attention network for pandemic prediction using
real-world evidence. Journal of the American Medical Informatics Association, 28(4):733-743,
2021.
Rabih Ghostine, Mohamad Gharamti, Sally Hassrouny, and Ibrahim Hoteit. An extended seir model
with vaccination for forecasting the covid-19 pandemic in saudi arabia using an ensemble kalman
filter. Mathematics, 9(6):636, 2021.
9
Under review as a conference paper at ICLR 2022
Alberto Godio, Francesca Pace, and Andrea Vergnano. Seir modeling of the italian epidemic of sars-
cov-2 using computational swarm intelligence. International Journal of Environmental Research
and Public Health, 17(10):3535, 2020.
Veronika Grimm, Friederike Mengel, and Martin Schmidt. Extensions of the seir model for the
analysis of tailored social distancing and tracing approaches to cope with covid-19. Scientific
Reports,11(1):1-16, 2021.
Tiberiu Harko, Francisco SN Lobo, and MK Mak. Exact analytical solutions of the susceptible-
infected-recovered (sir) epidemic model and of the sir model with equal death and birth rates.
Applied Mathematics and Computation, 236:184-194, 2014.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770-778, 2016.
Herbert W Hethcote. The mathematics of infectious diseases. SIAM review, 42(4):599-653, 2000.
SePP Hochreiter and Jurgen Schmidhuber. Long short-term memory. Neural computation, 9(8):
1735-1780, 1997.
David G Kendall. Deterministic and stochastic ePidemics in closed PoPulations. In Contributions to
Biology and Problems of Health, PP. 149-166. University of California Press, 2020.
William Ogilvy Kermack and Anderson G McKendrick. A contribution to the mathematical theory
of ePidemics. Proceedings of the royal society of london. Series A, Containing papers of a
mathematical and physical character, 115(772):700-721, 1927.
Jack Kiefer, Jacob Wolfowitz, et al. Stochastic estimation of the maximum of a regression function.
The Annals of Mathematical Statistics, 23(3):462-466, 1952.
Jaeyoung Kim, Mostafa El-Khamy, and Jungwon Lee. Residual lstm: Design of a deeP recurrent
architecture for distant sPeech recognition. arXiv preprint arXiv:1701.03360, 2017.
Adam J Kucharski, Timothy W Russell, Charlie Diamond, Yang Liu, John Edmunds, Sebastian Funk,
Rosalind M Eggo, Fiona Sun, Mark Jit, James D Munday, et al. Early dynamics of transmission
and control of covid-19: a mathematical modelling study. The lancet infectious diseases, 20(5):
553-558, 2020.
Tao Lei, Yu Zhang, Sida I Wang, Hui Dai, and Yoav Artzi. SimPle recurrent units for highly
Parallelizable recurrence. arXiv preprint arXiv:1709.02755, 2017.
Xiao Fan Liu, Xiao-Ke Xu, and Ye Wu. Mobility, exPosure, and ePidemiological timelines of
covid-19 infections in china outside hubei Province. Scientific data, 8(1):1-7, 2021.
Kiesha Prem, Yang Liu, Timothy W Russell, Adam J Kucharski, Rosalind M Eggo, Nicholas Davies,
Stefan Flasche, Samuel Clifford, Carl AB Pearson, James D Munday, et al. The effect of control
strategies to reduce social mixing on outcomes of the covid-19 ePidemic in wuhan, china: a
modelling study. The Lancet Public Health, 5(5):e261-e270, 2020.
Louis Raynal, Jean-Michel Marin, Pierre Pudlo, Mathieu Ribatet, Christian P Robert, and Arnaud
EstouP. Abc random forests for bayesian Parameter inference. Bioinformatics, 35(10):1720-1728,
2019.
David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning rePresentations by
back-ProPagating errors. nature, 323(6088):533-536, 1986.
Emma Saulnier, Olivier Gascuel, and Samuel Alizon. Inferring ePidemiological Parameters from
Phylogenies using regression-abc: A comParative study. PLoS computational biology, 13(3):
e1005416, 2017.
Xiaofei Sun, Tianjia Guan, Tao Xue, Chun Fan, Meng Yang, Yuxian Meng, Tianwei Zhang, Bahabaike
Jiangtulu, Fei Wu, and Jiwei Li. Analysis on action tracking rePorts of covid-19 informs control
strategies and vaccine delivery in Post-Pandemic era. medRxiv, 2021.
10
Under review as a conference paper at ICLR 2022
Mikael Sunnaker, Alberto Giovanni Busetto, Elina Numminen, Jukka Corander, Matthieu Foil, and
Christophe Dessimoz. Approximate bayesian computation. PLoS Comput Biol, 9(1):e1002803,
2013.
Heidi L Tessmer, Kimihito Ito, and Ryosuke Omori. Can machines learn respiratory virus epidemi-
ology?: A comparative study of likelihood-free methods for the estimation of epidemiological
dynamics. Frontiers in microbiology, 9:343, 2018.
Zifeng Yang, Zhiqi Zeng, Ke Wang, Sook-San Wong, Wenhua Liang, Mark Zanin, Peng Liu, Xudong
Cao, Zhongqiang Gao, Zhitong Mai, et al. Modified seir and ai prediction of the epidemics trend of
covid-19 in china under public health interventions. Journal of thoracic disease, 12(3):165, 2020.
Rex Ying, Jiaxuan You, Christopher Morris, Xiang Ren, William L Hamilton, and Jure Leskovec. Hier-
archical graph representation learning with differentiable pooling. arXiv preprint arXiv:1806.08804,
2018.
11