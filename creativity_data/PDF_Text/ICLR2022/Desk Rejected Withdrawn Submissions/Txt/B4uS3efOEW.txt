Under review as a conference paper at ICLR 2022
Confidence Adaptive Regularization for Deep
Learning with Noisy Labels
Anonymous authors
Paper under double-blind review
Ab stract
Recent studies on the memorization effects of deep neural networks on noisy
labels show that the networks first fit the correctly labeled training samples before
memorizing the mislabeled samples. Motivated by this early-learning phenomenon,
we propose a novel method to prevent memorization of the mislabeled samples.
Unlike the existing approaches which use confidence (captured by winning score
from model prediction) to identify or ignore the mislabeled samples, we introduce
an indicator branch to the original model and enable the model to produce a new
confidence (i.e. indicates whether a sample is clean or mislabeled) for each sample.
The confidence values are incorporated in the proposed loss function which is
learned to assign large values to correctly-labeled samples and small values to
mislabeled ones. We also discuss the limitation of our approach and propose an
auxiliary regularization term to enhance the robustness of the model in challenging
cases. Our empirical analysis shows that the model predicts correctly for both clean
and mislabeled samples in the early learning phase. Based on the predictions in each
iteration, we correct the noisy labels to steer the model towards corrected targets.
Further, we provide the theoretical analysis and conduct numerous experiments
on synthetic and real-world datasets, demonstrating that our approach achieves
comparable and even better results to the state-of-the-art methods.
1	Introduction
With the emergence of highly-curated datasets such as ImageNet (Deng et al., 2009) and CIFAR-10
(Krizhevsky et al., 2009), deep neural networks have achieved remarkable performance on many
classification tasks. However, it is extremely time-consuming and expensive to label a new large-scale
dataset with high-quality annotations. Alternatively, we may obtain the dataset with lower quality
annotations efficiently through online keywords queries (Li et al., 2017a) or crowdsourcing (Yu
et al., 2018), but noisy labels are inevitably introduced consequently. Previous studies (Arpit et al.,
2017; Zhang et al., 2018) demonstrate that noisy labels are problematic for overparameterized neural
networks, resulting in overfitting and performance degradation. Therefore, it is essential to develop
noise-robust algorithms for deep learning with noisy labels.
The authors of (Arpit et al., 2017; Li et al., 2020b; Liu et al., 2020) have observed that deep neural
networks learn to correctly predict the true labels for all training samples during early learning
stage, and begin to make incorrect predictions in memorization stage as it gradually memorizes
the mislabeled samples (in Figure 1 (a) and (b)). In this paper, we introduce a novel regularization
approach to prevent the memorization of mislabeled samples (in Figure 1 (c)). Our contributions are
summarized as follows:
•	We introduce an indicator branch to estimate the ‘confidence’ of model prediction and propose
a novel loss function called confidence adaptive loss (CAL) to exploit the early-learning phase.
According to the intrinsic property of early learning procedure, a large confidence value is likely to
be associated with a clean sample and a small confidence value with a mislabeled one.
•	We explore the limitation of CAL and propose an auxiliary regularization term forming confidence
adaptive regularization (CAR) to further segregate the mislabeled samples from the clean samples
in challenging cases. We develop a strategy to iteratively correct the noisy labels instead of using
the noisy labels directly, allowing the model to suppress the influence of the mislabeled samples.
1
Under review as a conference paper at ICLR 2022
Clean labels
°,0,gn,
sdEes Jo uo-e
Incorrect
Clean labels
s-dules Jo u~tiet
False labels
Clean labels
0sa0^C
s∙-dE"s=uo=uet
False labels
sc,-dEesJO uocu,0t
(a) Cross Entropy
with MultiStep learning rate scheduler
s-dujes JO u~tiet
0 IGO 200	3Q0	400	500
Epoch
(b) Cross Entropy
with Cosine Annealing learning rate scheduler
s-dujes JO UO-t≈et
Epoch
False labels
0	100	200	300	400	500
Epoch
(c) Confidence Adaptive Regularization
with Cosine Annealing learning rate scheduler
Figure 1: We conduct the experiments on the CIFAR-10 dataset with 40% symmetric label noise
using ResNet34 (He et al., 2016). The top row shows the fraction of samples with clean labels
that are predicted correctly (purple) and incorrectly (black). In contrast, the bottom row shows
the fraction of samples with false labels that are predicted correctly (purple), memorized (i.e. the
prediction equals the false label, shown in blue), and incorrectly predicted as neither the true nor the
labeled class (black). For samples with clean labels, all three models predict them correctly with the
increasing of epochs. However, for false labels in (a), the model trained with cross-entropy loss first
predicts the true labels correctly, but eventually memorizes the false labels. With the cosine annealing
learning rate scheduler (Loshchilov & Hutter, 2017) in (b), the model only slows down the speed of
memorizing the false labels. However, our approach shown in (c) effectively prevents memorization,
allowing the model to continue learning the correctly-labeled samples to attain high accuracy on
samples with both clean and false labels.
•	We derive the gradients of the proposed loss functions and compare them with cross-entropy
loss. Most importantly, we demonstrate that CAL has a similar effect to existing regularization
approaches. It neutralizes the influence of the mislabeled samples on the gradient, and ensure the
contribution from correctly labeled samples to the gradient remains dominant. We also prove the
noise robustness of the auxiliary term to complete the proof for noise robustness of our approach.
•	We show that the proposed approach achieves comparable and even better performance to the
state-of-the-art methods on four benchmarks with different types and levels of label noise. We
also perform an ablation study to evaluate the influence of different components and conduct
experiments to evaluate the reliability of iterative label correction.
2 Related work
We briefly discuss the related noise-robust methods that do not require a set of clean training data (as
opposed to (Xiao et al., 2015; Vahdat, 2017; Li et al., 2017b; Hendrycks et al., 2018)) and assume the
label noise is instance-independent (as opposed to (Cheng et al., 2020; Xia et al., 2020)).
Loss correction These approaches focus on correcting the loss function explicitly by estimating the
noise transition matrix (Goldberger & Ben-Reuven, 2016; Patrini et al., 2017; Tanno et al., 2019).
Robust loss functions These studies develop loss functions that are robust to label noise, including
LDMI (Xu et al., 2019), MAE (Ghosh et al., 2017), GCE (Zhang & Sabuncu, 2018), SL (Wang et al.,
2019) NCE (Ma et al., 2020) and TCE (Feng et al., 2020). Above two categories of methods do not
utilize the early learning phenomenon.
2
Under review as a conference paper at ICLR 2022
Sample selection During the early learning stage, the samples with smaller loss values are more
likely to be the correctly-labeled samples. Based on this observation, MentorNet (Jiang et al., 2018)
pre-trains a mentor network for selecting small-loss samples to guide the training of the student
network. Co-teaching related methods (Han et al., 2018; Yu et al., 2019; Wei et al., 2020; Lu et al.,
2021) maintain two networks, and each network is trained on the small-loss samples selected by
its peer network. However, their limitation is that they may eliminate numerous useful samples
for robust learning. Label correction Tanaka et al. (2018) and Yi & Wu (2019) replace the noisy
labels with soft (i.e. model probability) or hard (i.e to one-hot vector) pseudo-labels. Bootstrap
(Reed et al., 2015) corrects the labels by using a convex combination of noisy labels and the model
predictions. SAT (Huang et al., 2020) weigh the sample with its winning score in cross-entropy loss
and updates the labels with model predictions. Arazo et al. (2019) weigh the clean and mislabeled
samples by fitting a two-component Beta mixture model to loss values, and corrects the labels via
convex combination as in (Reed et al., 2015). Similarly, DivideMix (Li et al., 2020a) trains two
networks to separate the clean and mislabeled samples via a two-component Gaussian mixture model,
and further uses MixMatch (Berthelot et al., 2019) to enhance the performance. Regularization Li
et al. (2020b) observe that when the model parameters remain close to the initialization, gradient
descent implicitly ignores the noisy labels. Based on this observation, they prove the gradient descent
early stopping is an effective regularization to achieve robustness to label noise. Hu et al. (2019)
explicitly add the regularizer based on neural tangent kernel (Jacot et al., 2018) to limit the distance
between the model parameters to initialization. ELR (Liu et al., 2020) estimates the target probability
by temporal ensembling (Laine & Aila, 2017) and adds a regularization term to cross entropy loss
to avoid memorization. Other regularization techniques, such as mixup augmentation (Zhang et al.,
2018b), label smoothing (Szegedy et al., 2016) and weight averaging (Tarvainen & Valpola, 2017),
can enhance the performance.
Our approach is related to regularization and label correction. Compared with existing approaches
(Hu et al., 2019; Liu et al., 2020), where a regularization term in loss function is necessary to resist
mislabeled samples, we propose a new loss function CAL which implicitly boosts the gradients
of correctly labeled samples and diminishes the gradients of mislabeled samples. The auxiliary
regularization term in our approach is an add-on component to further enhance the robustness in
challenging cases. To the best of our knowledge, our approach is the first work to obtain the confidence
through an extra branch and provide the gradient analysis of it. In addition, our approach is simpler
and yields comparable performance without combining other regularization techniques.
3	Methodology
This section presents a framework called confidence adaptive regularization (CAR) for robust learning
from noisy labels. Our approach consists of three key elements: (1) We introduce an indicator
branch to the original deep neural networks and estimate the confidence of the model predictions by
exploiting the early-learning phenomenon through a confidence adaptive loss (CAL). (2) We observe
the limitation of our approach and propose an auxiliary regularization term explicitly designed to
further separate the confidence of clean samples and mislabeled samples in challenging cases. (3) We
iteratively correct the noisy labels by incorporating the model predictions through an exponential
moving average strategy.
3.1	Preliminary
In this paper, we assume the label noise is instance-independent. Consider the K-class classification
problem in noisy-label scenario, the ground truth label y is unavailable. We have a training set
DD = {(x[i], y[i])}N=ι, where x[i] is an input and y[i] ∈ Y = {1,..., K} is the corresponding noisy
label. We denote y[i] ∈ {0,1}K as one-hot vector of noisy label y[i]. A deep neural network model
Nθ (i.e. prediction branch in Figure 2 (a)) maps an input x[i] to a K-dimensional logits and then
feeds the logits to a softmax function S(∙) to obtain p[i] of the conditional probability of each class
given x[i], thus p[i] = S(z[i]), z[i] = Nθ(x[i]). θ denotes the parameters of the neural network and
z [i] ∈ RK ×1 denotes the K-dimensional logits (i.e. pre-softmax output). z[i] is calculated by the
fully connected layer from penultimate layer H[i] ∈ RM×1. z[i] = WH[i] + b, where W ∈ RK×M
denotes the weights and b ∈ RK ×1 denotes the bias in penultimate layer. Usually, the cross-entropy
3
Under review as a conference paper at ICLR 2022
Figure 2: In (a), we introduce an indicator branch in addition to the prediction branch. Given an input
image x[i], the indicator branch produces a single scalar value τ[i] to indicate ‘confidence’ and the
prediction branch produces the softmax prediction probability p[i] . (b) and (c) show the distribution
of confidence τ on the CIFAR-10 and CIFAR-100 with 40% symmetric label noise respectively.
(CE) loss reflects how well the model fits the training set DD:
1N
Lce = - NN X(y[i])T iog(p[i]).	(1)
N i=1
However, as noisy label y[i] is likely to be wrong, the model gradually memorizes the samples with
false labels when minimizing Lce (in Figure 1 (a) and (b)).
3.2	Confidence adaptive loss
In addition to the prediction branch, we introduce an indicator branch just after the penultimate layer
of the original model (in Figure 2 (a)). The M -dimensional penultimate layer H[i] is shared in both
branches. For each input x[i], the prediction branch produces the softmax prediction p[i] as usual.
The indicator branch contains one or more fully connected layers to produce a single scalar value
h[i], and sigmoid function is applied to scale it between 0 to 1. Assume we use one fully connected
layer, h[i] = W0H[i] + b0, where W0 ∈ R1×M denotes the weights and b0 ∈ R denotes the bias in
the penultimate layer of the indicator branch. Thus, we have
τ[i] = sigmoid(h[i] ), τ[i] ∈ (0, ),
(2)
where τ[i] denotes the confidence value of model prediction given input x[i] . The early-learning
phenomenon reveals that the deep neural networks memorize the correctly-labeled samples before
the mislabeled samples. Thus, we assume that, a sample with a clean label in expectation has a
larger confidence value than a mislabeled sample in the early learning phase. However, DNN model
trained with CE can easily overfits to noisy labels, making the confidence (traditionally obtained by
maxj pj , j ∈ [1, K]) fail to capture it. To let our confidence value τ capture the above assumption,
we propose the confidence adaptive cross entropy (CACE) loss
1N
Lcace = - N X(t[i])T log(T [i] (p[i] - t[i])+ t[i]),	⑶
N i=1
where t[i] is the one-hot vector of corrected label for each sample x[i] . Generally, one can directly set
t[i] = y[i]. However, it is less effective as y[i] can be wrong, so we propose a strategy to calculate t[i]
in Section 3.4. Intuitively, Lcace can be explained in two-fold: 1) In the early-learning phase, the
model does not overfit the mislabeled samples. Therefore, their p - t remain large. By minimizing
Lcace , it forces τ of mislabeled samples toward 0 as desired. 2) As for correctly-labeled samples,
the model memorizes them first, resulting in the small p - t. Thus, it makes τ have no influence on
minimizing Lcace in the case of correctly-labeled samples. As a result, by only minimizing Lcace,
we may obtain a trivial optimization that the model always produces τ → 0 for any inputs. To avoid
this lazy learning circumstance, we introduce a penalty loss Lp as a cost.
1N
Lp = -nn Xlog(τ[i]),	(4)
i=1
4
Under review as a conference paper at ICLR 2022
wherein the target value of τ is always 1 for all inputs. By adding a term Lp to Lcace , τ of correctly
labeled samples are pushed to 1, and τ of mislabeled samples tend to 0 as expected. Hence, we define
the confidence adaptive loss as
LCAL = Lcace + λLp,	(5)
where λ controls the strength of penalty loss. As we can see in Figure 2 (b) and (c), the confidence
value τ successfully segregates the mislabeled samples from correctly-labeled samples.
3.3	Auxiliary regularization term
We observe that the early learning phenomenon is not obvious when a dataset contains too many
classes (e.g. CIFAR100), i.e, the mean of τ distributions for clean samples and mislabeled samples
are close to each other as shown in Figure 2 (c). Then LCAL is likely to be reduced to Lce (all τ → 1).
To enhance the performance in this situation, we need to make τ of mislabeled samples closer to 0.
Hence we propose a reverse confidence adaptive cross entropy as an auxiliary regularization term.
N
Lr-Cace = - N X(T [i] (p[i] — 叫+ t[i])Tlθg(t[i]).
i=1
(6)
As one-hot vector t[i] is inside of the logarithm in Lr-cace, this could cause computational problem
when t[i] contains zeros. Similar to clipping operation, we solve it by defining log(0) = A (where
A is a negative constant), which will be proved important for the theoretical analysis in Section 4.
Putting all together, the confidence adaptive regularization (CAR) is
LCAR
LCAL + βLr-cace = Lcace + λLp + βLr-
cace,
(7)
where β controls the strength of regularization carried by Lr-cace . In summary, Lcace is designed for
learning confidence by exploiting the early-learning phenomenon. Lp is adopted for avoiding trivial
solution. Lr-cace makes CAR robust to label noise even in challenging cases.
3.4	Iterative Label Correction
CAR requires a target probability t for each sample in the training set. Directly using the given noisy
label y) as the target is less effective, since the model easily overfits to noisy labels under extreme
label noise. To yield better performance, ELR (Liu et al., 2020) and SELF (Nguyen et al., 2020)
use temporal ensembling (Laine & Aila, 2017) based solely on model predictions to estimate the
target t. However, it may lose the information of the original training set, and the predictions can be
ambiguous when model overfits to noisy labels.
In this paper, we seek to iteratively correct the noisy labels for mitigating the influence of noisy labels.
As shown in Figure 1, the model predicts correctly for both clean and mislabeled samples in the early
learning phase. Base on this obervation, we develop a strategy to estimate the target by utilizing the
noisy label y, model prediction P and confidence value T. The target t[i] of given x[i] in iteration E
is calculated by
(y[i]	if E < Ec
t[E = < αt[E-i]+ (1 — α)p[E] ifE ≥ Ec and τ[E] ≥δ	(8)
[t[E-i]	otherwise,
where Ec is the iteration that starts performing label correction and 0 ≤ α < 1 is the momentum. We
set Ec = 60 by default as performance is not sensitive to the choice of Ec . Threshold δ is used to
exclude ambiguous predictions with low confidence. Since we have verified that CAR only learns
from the correctly labeled samples, our strategy not only enhances the stability of model predictions
but also facilitates the model to learn more from clean samples. We analyze the reliability of iterative
label correction and evaluate the performance with different estimation strategies in Appendix E.
4	Theoretical analysis
This section consists of two parts: 1) We illustrate the noise robustness of CAL by analyzing how it
adjusts the gradient accordingly to achieve regularization effect. 2) We prove the robustness of the
auxiliary term Lr-cace under instance-independent label noise as Lr-cace may be added to CAL.
5
Under review as a conference paper at ICLR 2022
(a) Cross Entropy
with MultiStep learning rate scheduler
IU∙ape,Jω
(b) Cross Entropy
with Cosine Annealing learning rate scheduler
(c) Confidence Adaptive Loss
with Cosine Annealing learning rate scheduler
dean labels
⅛lse labels
Figure 3: On CIFAR-10 with 40% symmetric label noise using ResNet34, we observe that in (a), the
gradient of clean labels dominates in early learning stage, but afterwards it vanishes and the gradient
of false labels dominates. In (b), it only slows down this effect with cosine annealing learning rate
scheduler. In (c), CAL effectively keeps the gradient of clean labels dominant and diminishes the
gradient of false labels when epoch increases, preventing memorization of mislabeled samples.

4.1	Gradient analysis
For sample-wise analysis, we denote the true label of sample x as y ∈ {1, ..., K}. The ground-truth
distribution over labels for sample x is q(y|x), and PkK=1 q(k|x) = 1. Consider the case of a single
ground-truth label y, then q(y|x) = 1 and q(k|x) = 0 for all k 6= y. We denote the prediction
probability as p(k|x) and PkK=1 p(k|x) = 1. For notation simplicity, we denote pk, qk, py, qy, pj,
qj as abbreviations for p(k|x), q(k|x), p(y|x), q(y|x), p(j|x) and q(j|x). Besides, we assume no
label correction is performed in the following analysis.
We first explain how the cross-entropy loss Lce (Eq. (1)) fails in noisy-label scenario. The gradient
of sample-wise cross entropy loss Lce with respect to zj is
∂Lce	pj - 1 ≤ 0, qj = qy = 1
dzj	Pj Pj ≥ 0,	qj = 0
(9)
In this case, if j is true class and equals y, but qj = 0 due to the label noise, the contribution of x to
the gradient is reversed. The entry corresponding to the impostor class j0 , is also reversed because
qj0 = 1, causing the gradient of mislabeled samples dominates (in Figure 3 (a) and (b)). Thus,
performing stochastic gradient descent eventually results in memorization of the mislabeled samples.
Lemma 1. For the loss function LCAL given in Eq. (5) and LCAR in Eq. (7), the gradient of
sample-wise LCAL and LCAR (β = 1) with respect to the logits zj can be derived as
∂Lcal
dzj
Py
Pj Py - 1 + 1∕τ
1)——弘--
p P— - 1 + 1/t
≤ 0,
qj = qy = 1 (j is the true class for x) (10a)
≥ 0,
qj = 0 (j is not the true class for x)	(10b)
and
∂LCAR 			=	I (Pj- I)Pj-P+1∕T -ATPj(Pj- I) ≤ 0,	qj	qy	1	(11a)
dzj	i PjPy-1y+ι∕τ -ATPjPy ≥0,	qj	0		(11b)
respectively, where A is a negative constant defined in Section 3.3.
The proof of Lemma 1 is based on gradient derivation in two cases. We defer it in Appendix A.2.
Gradient of LCAL in Eq. (10). Compared to the gradient of Lce in Eq. (9), the gradient of LCAL
has an adaptive multiplier. We denote Q = .._'+ 小.It is monotonically increasing on T. We have
limτ→1 Q = 1, and limτ →0 Q = 0. For the samples with the true class j in Eq. (10a), the cross
entropy gradient term Pj - 1 of correctly-labeled samples tends to vanish after early learning stage
6
Under review as a conference paper at ICLR 2022
because their pj is close to qj = 1, leading mislabeled samples to dominate the gradient. However,
by multiplying Q (note that Q → 0 for mislabeled samples and Q → 1 for correctly-labeled samples
due to property of τ as we discussed in Section 3.2), it counteracts the effect of gradient dominating
by mislabeled samples. For the samples that j is not the true class in Eq. (10b), the gradient term pj is
positive. Multiplying Q < 1 effectively dampens the magnitudes of coefficients on these mislabeled
samples, thereby diminishing their effect on the gradient (in Figure 3 (c)).
Gradient of LCAR in Eq. (11). Compared to the gradient of LCAL, an extra term derived from
auxiliary regularization term Lr-cace is added. In the case of qj = qy = 1 in Eq. (11a), the extra term
-Aτ pj (pj - 1) < 0 for 0 ≤ pj ≤ 1 and it is a convex quadratic function whose vertex is at pj = 0.5.
It means the extra term -Aτ pj (pj - 1) provides the largest acceleration in learning around pj = 0.5
where the most ambiguous scenario occurs. Intuitively, the term -Aτ pj (pj - 1) pushes apart the
peaks of confidence distribution for correctly-labeled samples and mislabeled samples. In the case
of qj = 0 in Eq. (11b), the extra term -Aτ pj py > 0 is added. For correctly-labeled samples, py
is larger, adding -Aτ pj py leads the residual probabilities of other unlabeled classes reduce faster.
For mislabeled samples, py is close to 0, no acceleration needed. Overall, adding Lr-cace amplifies
the effect of confidence learning in CAL, resulting in the confidence values of mislabeled samples
become smaller. The empirical results of the influence of confidence distribution on CIFAR-100 with
different strengths of Lr-cace are in Appendix F.
4.2	Label noise robustness
Here we prove that the Lr-cace is robust to label noise following (Ghosh et al., 2017). We assume
that the noisy sample (x, y) is drawn from distribution Dn(x, y), and the ordinary sample (x, y) is
drawn from D(x, y). We have y = i(y = i) with probability ηɑ = (1 - η) and y = j(y = i) with
probability ηj for all j = i and Pj=i ηij = η. If ηij = K-I for all j = i, then the noise is uniform
or symmetric, otherwise, the noise is class-conditional or asymmetric. Given any classifier f and loss
function L, we define the risk of f under clean labels as RL(f) = ED(x,y) [L(f (x, y))], and the risk
under label noise rate η as RL(f) = ED(x,y)[L(f (x, y))]. Let f * and f be the global minimizers
of RL(f) and RηL(f) respectively. Then, the empirical risk minimization under loss function L is
defined to be noise-tolerant if f* is a global minimum of the noisy risk RηL(f).
Theorem 1.	Under Symmetric or uniform label noise with noise rate η < KK1, we have
0 ≤ RLr-Cace (f^ - RLr-Cace (f	< KAn-K--2	Q2)
and
Aη<RηLr-cace(fη*)-RηLr-cace(f*)≤0	(13)
where f* and fη* be the global minimizers ofRLr-cace(f) and RηL	(f) respectively.
Theorem 2.	Under class-dependent label noise with ηij < 1 - ηi , ∀j 6= i, ∀i, j ∈ [K], where
nij = p(y = j|y = i),∀j = i and(I - ni) = p(y = i|y = i), ifRLr-cace(f *) = 0, then
0≤RηLr-cace(f*)-RηLr-cace(fη*)<G,	(14)
where G = A(1 - K)ED(x,y) (1 - ny) > 0, f* and fη* be the global minimizers of RLr-cace (f) and
RηL	(f) respectively.
Due to the space constraints, we defer the proof of Theorem 1 and Theorem 2 to the Appendix A.2.
Theorem 1 and Theorem 2 ensure that by minimizing Lr-cace under symmetric and asymmetric label
noise, the difference of the risks caused by the derived hypotheses fη* and f* are always bounded.
The bounds are related to the negative constant A. Since A is the approximate of log(0) which is
actually -∞. A larger A (closer to 0) leads to a tighter bound but introduces a larger approximation
error in implementation. A reasonable Awe set is -4 in our experiments. For clarity, we also compare
Lr-cace with existing noise-robust loss functions in Appendix A.3.
5	Experiments
Comparison with the state-of-the-art methods We evaluate our approach on two benchmark
datasets with simulated label noise, CIFAR-10 and CIFAR-100 (Krizhevsky et al., 2009), and
7
Under review as a conference paper at ICLR 2022
Table 1: Test Accuracy (%) on CIFAR-10 and CIFAR-100 with various levels of label noise injected
to the training set. We compare with previous works under the same backbone ResNet34. The results
are averaged over 3 trials. Results are taken from their original papers. The best results are in bold.
Note that SAT, ELR and CAR use cosine annealing learning rate scheduler.
Dataset Noise type Method/Noise ratio	CIFAR-10					CIFAR-100				
	symm				asymm	symm				asymm
	20%	40%	60%	80%	40%	20%	40%	60%	80%	40%
Cross Entropy	86.98 ± 0.12	81.88 ± 0.29	74.14 ± 0.56	53.82 ± 1.04	80.11 ± 1.44	58.72 ± 0.26	48.20 ± 0.65	37.41 ± 0.94	18.10 ± 0.82	42.74 ± 0.61
Forward T (Patrini et al., 2017)	87.99 ± 0.36	83.25 ± 0.38	74.96 ± 0.65	54.64 ± 0.44	83.55 ± 0.58	39.19 ± 2.61	31.05 ± 1.44	19.12 ± 1.95	8.99 ± 0.58	34.44 ± 1.93
Bootstrap (Reed et al., 2015)	86.23 ± 0.23	82.23 ± 0.37	75.12 ± 0.56	54.12 ± 1.32	81.21 ± 1.47	58.27 ± 0.21	47.66 ± 0.55	34.68 ± 1.10	21.64 ± 0.97	45.12 ± 0.57
GCE (Zhang & Sabuncu, 2018)	89.83 ± 0.20	87.13 ± 0.22	82.54 ± 0.23	64.07 ± 1.38	76.74 ± 0.61	66.81 ± 0.42	61.77 ± 0.24	53.16 ± 0.78	29.16 ± 0.74	47.22 ± 1.15
Joint Opt (Tanaka et al., 2018)	92.25	90.79	86.87	69.16		58.15	54.81	47.94	17.18	
NLNL (Kim et al., 2019)	94.23	92.43	88.32		89.86	71.52	66.39	56.51		45.70
SL (Wang et al., 2019)	89.83 ± 0.20	87.13 ± 0.26	82.81 ± 0.61	68.12 ± 0.81	82.51 ± 0.45	70.38 ± 0.13	62.27 ± 0.22	54.82 ± 0.57	25.91 ± 0.44	69.32 ± 0.87
DAC (Thulasidasan et al., 2019)	92.91	90.71	86.30	74.84		73.55	66.92	57.17	32.16	
SELF (Nguyen et al., 2020)		91.13		63.59			66.71		35.56	
SAT (Huang et al., 2020)	94.14	92.64	89.23	78.58		75.77	71.38	62.69	38.72	
ELR (Liu et al., 2020)	92.12 ± 0.35	91.43 ± 0.21	88.87 ± 0.24	80.69 ± 0.57	90.35 ± 0.38	74.68 ± 0.31	68.43 ± 0.42	60.05 ± 0.78	30.27 ± 0.86	73.73 ± 0.34
CAR (Ours)	94.37 ± 0.04	93.49 ± 0.07	90.56 ± 0.07	80.98 ± 0.27	92.09 ± 0.12	77.90 ± 0.14	75.38 ± 0.08	69.78 ± 0.69	38.24 ± 0.55	74.89 ± 0.20
Table 2: Comparison with state-of-the-art methods trained on Clothing1M. Results of other methods
are taken from original papers. All methods use an ResNet-50 architecture pretrained on ImageNet.
CE	Forward (Patrini et al., 2017)	GCE (Zhang & Sabuncu, 2018)	SL (Wang et al., 2019)	Joint-Optim (Tanaka et al., 2018)	DMI (Xu et al., 2019)	ELR (Liu et al., 2020)	ELR+ (Liu et al., 2020)	DivideMix (Li et al., 2020a)	CAR
69.21	69.84	69.75	71.02	72.16	72.46	72.87	74.81	74.76	73.19
two real-world datasets, Clothing1M (Xiao et al., 2015) and WebVision (Li et al., 2017a). More
information of datasets, label noise injection and training details can be found in Appendix C.
Table 1 shows the performance of CAR on CIFAR-10 and CIFAR-100 with different levels of
symmetric and asymmetric label noise. All methods use the same backbone (ResNet34). We compare
CAR to the state-of-the-art approaches that only modify the training loss without extra regularization
techniques, such as mixup data augmentation, two networks, and weight averaging. CAR obtains
the highest performance in most cases and achieves comparable results in the most challenging
cases (e.g. under 80% symmetric noise). We describe the hyperparameters sensitivity of CAR in
Appendix C.4. Table 2 compares CAR to state-of-the-art methods trained on the Clothing1M dataset.
Note that DivideMix and ELR+ may not be completely comparable to ours as they use mixup data
augmentation, two networks, and weight averaging to boost the performance, while CAR is a pure
regularization method. Except for DivideMix and ELR+, CAR outperforms other methods.
Table 3: Comparison with state-of-the-art methods trained on WebVision. Results of other methods
are taken from Li et al. (2020a); Liu et al. (2020). All methods use an InceptionResNetV2 architecture.
D2L Ma et al. (2018) MentorNet Jiang et al. (2018) Co-teaching Han et al. (2018) Iterative-CV Chen et al. (2019) ELR Liu et al. (2020) DivideMix Li et al. (2020a) ELR+ Liu et al. (2020) CAR
,	topi	62.68	63.00	63.58	65.24	76.26	77.32	77.78	77.41
WebVision	top5	84.00	81.40	85.20	85.34	91.26	91.64	91.68	92.25
ςvnn..)	topi	57.80	57.80	61.48	61.60	68.71	75.20	70.29	74.09
ILSVRC12	top5	81.36	79.92	84.70	84.98	87.84	90.84	89.76	92.09
Table 3 compares CAR to state-of-the-art methods trained on the mini WebVision dataset and
evaluated on both WebVision and ImageNet ILSVRC12 validation sets. On WebVision, CAR
outperforms others on top5 accuracy, even better than DivideMix and ELR+. On top1 accuracy, CAR
is slightly superior to DivideMix and achieves comparable performance to ELR+. On ILSVRC12,
DivideMix achieves superior performance in terms of top1 accuracy, while CAR achieves the best
top5 accuracy even without using extra techqniues to boost the performance.
Ablation study Table 4 reports the influence of three individual components in CAR: auxiliary
regularization term Lr-cace , iterative label correction and indicator branch. Removing Lr-cace does
not hurt the performance on CIFAR-10. However, adding the reverse term Lr-cace does improve the
performance on CIFAR-100. The larger the noise is, the more improvement we obtain. Removing the
8
Under review as a conference paper at ICLR 2022
Table 4: Influence of three components in our approach. • means the model fails to converge.
Dataset Noise type Noise ratio	CIFAR-10			CIFAR-100		
	symm		asymm	symm		asymm
	40%	80%	40%	40%	80%	40%
CAR	93.49 ± 0.07	80.98 ± 0.27	92.09 ± 0.12	75.38 ± 0.08	38.24 ± 0.55	74.89 ± 0.20
-LT-Cace	93.49 ± 0.07	80.98 ± 0.27	92.09 ± 0.12	74.65 ± 0.09	34.79 ± 0.71	74.73 ± 0.12
-label correction	89.47 ± 0.50	76.91 ± 0.22	88.23 ± 0.22	69.91 ± 0.21	31.33 ± 0.38	55.68 ± 0.17
-indicator branch	90.94 ± 0.28	•	91.55 ± 0.07	•	•	•
False labels
Corrected labels
Figure 5: Confusion matrix of corrected la-
bels w.r.t clean labels on CIFAR-10 with 40%
symmetric label noise.
Figure 4: Average confidence values τ of
false labels w.r.t clean labels on CIFAR-10
with 40% symmetric label noise.
iterative label correction leads to a significant performance drop. This suggests that correcting the
noisy labels by properly using model predictions is crucial for avoiding memorization. To validate
the effect of adding the indicator branch, we conduct another way to calculate confidence value
without using indicator branch: using the highest probability as the confidence value, which means
τ[i] = maxj p[ji],j ∈ [1, K]. Without using the indicator branch, the model only converges in two
easy cases. Hence, directly calculating the confidence by model output does interfere with the original
prediction branch, while adding an extra indicator branch solves this problem.
Identification of mislabeled samples When exploiting the progress of the early learning phase by
CAL, we have observed that the correctly-labeled samples have larger confidence values than the
mislabeled samples. We report the average confidence values of samples in Figure 4. The (i, j)-th
block represents the average confidence value of samples with clean label i and false label j . We
observe that the confidence values on the diagonal blocks are higher than those on non-diagonal
blocks, which means that our confidence value has an effect similar to the probability of extra class in
DAC (Thulasidasan et al., 2019) and AUM (Pleiss et al., 2020). The key difference is that DAC and
AUM identify the mislabeled samples based on probability generated by K+1 class and drop the most
likely mislabeled samples to perform second stage classification, while we incorporate the confidence
values in loss function and implicitly achieve the regularization effect to avoid memorization of
mislabeled samples. Confidence values on other levels of label noise can be found in Appendix D.
Reliability of Label correction Recall that we perform iterative label correction in Section 3.4.
Since the target is calculated by a moving average between noisy labels and model predictions, our
approach is able to gradually correct the false labels. The correction accuracy can be calculated
by N PN 1{argmax y[i] = argmax t[i]}, where y[i] is the clean label of x[i]. We evaluate the
correction accuracy on CIFAR-10 and CIFAR-100 with 40% symmetric label noise. CAR obtains
correction accuracy of 95.1% and 86.4%, respectively. The confusion matrix of corrected labels w.r.t
the clean labels on CIFAR-10 is shown in Figure 5. We observe that CAR corrects the false labels
impressively well for all classes. Results of various levels of label noise and real-world datasets can
be found in Appendix D. The evaluation for stability of iterative label correction is in Appendix G.
6 Conclusion
Based on the early learning and memorization phenomenon of deep neural networks in the presence
of noisy labels, we propose an adaptive regularization method that implicitly adjusts the gradient to
prevent memorization on noisy labels. Through extensive experiments across multiple datasets, our
approach yields comparable and even superior results to the state-of-the-art methods.
9
Under review as a conference paper at ICLR 2022
References
Eric Arazo, Diego Ortego, Paul Albert, Noel O’Connor, and Kevin Mcguinness. Unsupervised
label noise modeling and loss correction. In Proceedings of the 36th International Conference on
Machine Learning, pp. 312-321, 2019.
Devansh Arpit, StanislaW Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, MaXinder S
Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. A closer look at
memorization in deep netWorks. In Proceedings of the 34th International Conference on Machine
Learning-Volume 70, pp. 233-242. JMLR. org, 2017.
David Berthelot, Nicholas Carlini, Ian GoodfelloW, Nicolas Papernot, Avital Oliver, and Colin A
Raffel. MiXmatch: A holistic approach to semi-supervised learning. In Advances in Neural
Information Processing Systems, pp. 5050-5060, 2019.
Pengfei Chen, Ben Ben Liao, Guangyong Chen, and Shengyu Zhang. Understanding and utilizing
deep neural netWorks trained With noisy labels. In International Conference on Machine Learning,
pp. 1062-1070, 2019.
Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamohanarao, and Dacheng Tao. Learning With bounded
instance and label-dependent label noise. In International Conference on Machine Learning, pp.
1789-1799. PMLR, 2020.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale
hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition,
pp. 248-255. Ieee, 2009.
Lei Feng, Senlin Shu, Zhuoyi Lin, Fengmao Lv, Li Li, and Bo An. Can cross entropy loss be robust
to label noise. In Proceedings of the 29th International Joint Conferences on Artificial Intelligence,
pp. 2206-2212, 2020.
Aritra Ghosh, Himanshu Kumar, and PS Sastry. Robust loss functions under label noise for deep
neural netWorks. In Thirty-First AAAI Conference on Artificial Intelligence, 2017.
Jacob Goldberger and Ehud Ben-Reuven. Training deep neural-netWorks using a noise adaptation
layer. 2016.
Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi
Sugiyama. Co-teaching: Robust training of deep neural netWorks With eXtremely noisy labels. In
Advances in neural information processing systems, pp. 8527-8537, 2018.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770-778, 2016.
Dan Hendrycks, Mantas Mazeika, Duncan Wilson, and Kevin Gimpel. Using trusted data to train
deep netWorks on labels corrupted by severe noise. In NeurIPS, 2018.
Wei Hu, Zhiyuan Li, and Dingli Yu. Simple and effective regularization methods for training on
noisily labeled data With generalization guarantee. In International Conference on Learning
Representations, 2019.
Lang Huang, Chao Zhang, and Hongyang Zhang. Self-adaptive training: beyond empirical risk
minimization. Advances in Neural Information Processing Systems, 33, 2020.
Arthur Jacot, Franck Gabriel, and Clement Hongler. Neural tangent kernel: convergence and
generalization in neural netWorks. In Proceedings of the 32nd International Conference on Neural
Information Processing Systems, pp. 8580-8589, 2018.
Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. Mentornet: Learning data-
driven curriculum for very deep neural netWorks on corrupted labels. In International Conference
on Machine Learning, pp. 2304-2313. PMLR, 2018.
10
Under review as a conference paper at ICLR 2022
Youngdong Kim, Junho Yim, Juseung Yun, and Junmo Kim. Nlnl: Negative learning for noisy labels.
In Proceedings ofthe IEEE International Conference on Computer Vision, pp. 101-110, 2019.
Alex Krizhevsky et al. Learning multiple layers of features from tiny images. 2009.
Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. ICLR, 2017.
Junnan Li, Richard Socher, and Steven CH Hoi. Dividemix: Learning with noisy labels as semi-
supervised learning. International Conference on Learning Representation, 2020a.
Mingchen Li, Mahdi Soltanolkotabi, and Samet Oymak. Gradient descent with early stopping is
provably robust to label noise for overparameterized neural networks. In International Conference
on Artificial Intelligence and Statistics, pp. 4313-4324. PMLR, 2020b.
Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van Gool. Webvision database: Visual
learning and understanding from web data. CoRR, 2017a.
Yuncheng Li, Jianchao Yang, Yale Song, Liangliang Cao, Jiebo Luo, and Li-Jia Li. Learning from
noisy labels with distillation. In Proceedings of the IEEE International Conference on Computer
Vision, pp. 1910-1918, 2017b.
Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Early-learning
regularization prevents memorization of noisy labels. Advances in Neural Information Processing
Systems, 33, 2020.
Ilya Loshchilov and Frank Hutter. Sgdr: Stochastic gradient descent with warm restarts. ICLR, 2017.
Yangdi Lu, Yang Bo, and Wenbo He. Co-matching: Combating noisy labels by augmentation
anchoring. arXiv preprint arXiv:2103.12814, 2021.
Xingjun Ma, Yisen Wang, Michael E Houle, Shuo Zhou, Sarah M Erfani, Shu-Tao Xia, Sudanthi
Wijewickrema, and James Bailey. Dimensionality-driven learning with noisy labels. arXiv preprint
arXiv:1806.02612, 2018.
Xingjun Ma, Hanxun Huang, Yisen Wang, Simone Romano, Sarah Erfani, and James Bailey. Normal-
ized loss functions for deep learning with noisy labels. In International Conference on Machine
Learning, pp. 6543-6553. PMLR, 2020.
Tam Nguyen, C Mummadi, T Ngo, L Beggel, and Thomas Brox. Self: learning to filter noisy labels
with self-ensembling. In International Conference on Learning Representations (ICLR), 2020.
Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making
deep neural networks robust to label noise: A loss correction approach. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recognition, pp. 1944-1952, 2017.
Geoff Pleiss, Tianyi Zhang, Ethan R Elenberg, and Kilian Q Weinberger. Identifying mislabeled data
using the area under the margin ranking. arXiv preprint arXiv:2001.10528, 2020.
Scott E Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew
Rabinovich. Training deep neural networks on noisy labels with bootstrapping. In ICLR (Workshop),
2015.
Hwanjun Song, Minseok Kim, Dongmin Park, and Jae-Gil Lee. Prestopping: How does early
stopping help generalization against label noise? 2019.
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking
the inception architecture for computer vision. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pp. 2818-2826, 2016.
Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, and Kiyoharu Aizawa. Joint optimization framework
for learning with noisy labels. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pp. 5552-5560, 2018.
11
Under review as a conference paper at ICLR 2022
Ryutaro Tanno, Ardavan Saeedi, Swami Sankaranarayanan, Daniel C Alexander, and Nathan Silber-
man. Learning from noisy labels by regularized estimation of annotator confusion. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 11244-11253,
2019.
Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency
targets improve semi-supervised deep learning results. In Proceedings of the 31st International
Conference on Neural Information Processing Systems, pp. 1195-1204, 2017.
Sunil Thulasidasan, Tanmoy Bhattacharya, Jeff Bilmes, Gopinath Chennupati, and Jamal Mohd-
Yusof. Combating label noise in deep learning using abstention. In International Conference on
Machine Learning, pp. 6234-6243. PMLR, 2019.
Arash Vahdat. Toward robustness against label noise in training deep discriminative neural networks.
In Advances in Neural Information Processing Systems, pp. 5596-5605, 2017.
Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey. Symmetric cross
entropy for robust learning with noisy labels. In Proceedings of the IEEE/CVF International
Conference on Computer Vision, pp. 322-330, 2019.
Hongxin Wei, Lei Feng, Xiangyu Chen, and Bo An. Combating noisy labels by agreement: A joint
training method with co-regularization. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pp. 13726-13735, 2020.
Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu,
Dacheng Tao, and Masashi Sugiyama. Parts-dependent label noise: Towards instance-dependent
label noise. arXiv preprint arXiv:2006.07836, 2020.
Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive noisy
labeled data for image classification. In Proceedings of the IEEE conference on computer vision
and pattern recognition, pp. 2691-2699, 2015.
YilUn Xu, Peng Cao, YUqing Kong, and YizhoU Wang. L_dmi: A novel information-theoretic loss
function for training deep nets robust to label noise. In NeurIPS, pp. 6222-6233, 2019.
KUn Yi and Jianxin WU. Probabilistic end-to-end noise correction for learning with noisy labels. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7017-7025,
2019.
XingrUi YU, Bo Han, Jiangchao Yao, Gang NiU, Ivor Tsang, and Masashi SUgiyama. How does
disagreement help generalization against label corrUption? In International Conference on Machine
Learning, pp. 7164-7173. PMLR, 2019.
XiyU YU, Tongliang LiU, Mingming Gong, and Dacheng Tao. Learning with biased complementary
labels. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 68-83, 2018.
C Zhang, S Bengio, M Hardt, B Recht, and O Vinyals. Understanding deep learning reqUires
rethinking generalization, 2018.
Hongyi Zhang, MoUstapha Cisse, Yann N DaUphin, and David Lopez-Paz. mixUp: Beyond empirical
risk minimization. In International Conference on Learning Representations, 2018b.
ZhilU Zhang and Mert SabUncU. Generalized cross entropy loss for training deep neUral networks
with noisy labels. In Advances in neural information processing systems, pp. 8778-8788, 2018.
12
Under review as a conference paper at ICLR 2022
A Theoretical analysis
A.1 GRADIENT DERIVATION OF LCAL AND LCAR
Assume the target t equals to ground truth distribution. The sample-wise LCAL can be rewrite as:
K
LCAL = Lcace + λLp = - qk log(τ (pk - qk) + qk) - λlogτ.	(1)
k=1
The derivation of the LCAL with respect to the logits is as follows:
∂Lcal = ∂Lcace = _ X	Tqk	∂pk
∂zj	∂zj	匕 T (Pk - qk) + qk ∂zj .
Since Pk = S(Z)=PKNzkeNj, We have
∂(「KN')	R (PK ezj) - ezz d( PK=IeNj)
dpk _ 'Pj=ι e j ' _ ∂zj (乙j=1 e )	∂zj
-....=------：------=----------------77----------------
∂zj	∂zj	(PjK=1 ezj )2
(2)
(3)
In the case of k = j :
∂Pk	dezk (PK _ ezz ) - ezz d( PK=Ief) _ ∂zz (乙 k=1 e ) e	∂zz	_	_ ezk(PK=1 ezk) - ezk ∙ ezk	
dzj	=	(PK=1 ezk )2	二	(PNI ezk )2	
	ezk	e	ezk	∖ 2	2	(4)
	=P=^ -⅛ek) =Pk - P	k.	
In the case of k 6= j :
∂Pk	0 ∙ (PK=ι ezj) — ezk ∙ ezj	ezk	ezj	-PkPj .	(5)
dzj	=	(PK=1 ezj )2	二	二	77	77	二 Pj=I ezj Pj=I ezj		
Combining Eq. (4) and (5) into Eq. (2), We obtain:
∂LCAL —		= dzj	K -X k=1	Tqk	∂Pk T(Pk - qk) + qk ∂zj
	- T(P	Tqj	∂Pj _ XX	Tqk	dpk j - qj) + qj dzj J T(Pk - qk) + qk dzj k6=j
		K
	- T(P	7-j+-qj S- P2) - X T (Pk；k) + qk (-Pk Pp) k6=j
K
=-	TqjPj	+ p.X	Tqk Pk
T(Pj - qj) + qj	j k=11 T(Pk - qk) + qk
Therefore, if qj = qy = 1, then
d LCAL =	一	TPj	+υ-	TqjPj	=(	PL 1) Tt+ = (	PL 1) Pj-j/T
dzj .	-	-+ Pj TPj - T + 1	T (	pt - 1) + 1		
(7)
If qj = 0, then
dLCAL =P	Tqy Py	= P	Py
∂zj	jT T (Py - qy) + qy jP Py - 1 + 1/t
(8)
13
Under review as a conference paper at ICLR 2022
The sample-wise LCAR can be rewrite as (assume β = 1):
	K LCAR = LCAL + βLr-cace = LCAL -	(T (pk - qk) + qk) logqk.	(9) k=1
Since we have obtain the gradient of LCAL, we now only analyze the gradient of Lr-cace with respect
to the logits as follows:
	dLr-cace = - XX T∂pk log qk.	(10) zj	k=1 zj
Combining Eq. (4) and (5), into Eq. (10), we have
	∂L	K ʒ——=-T(pj - p2)log qj - T X(-pkpj)log qk ∂zj	k6=j K = - Tpj log qj + T	pkpj log qk.	(11) k=1
We denote log 0 = A, thus if qj = qy = 1, then
∂Lr-cace dzj	一	K -Tpjlog 1 + Tpj (pj log1 + pk log 0) = Tpj(1 -pj)A = -AT pj (pj - 1). (12) k6=j
If qj = 0, then
∂Lr cace
—∂Zj- = -TPj log 0 + Tpj (Py Iθg1 + (1 - Py )lθg0) = -ATpj + Tpj (1 - Py )A = -ATpjpy .
j	(13)
Therefore, the gradients of LCAR is
	dL	f	(pj-1)Pj-p+ ι∕τ	-	ATPj(pj-1),	qj-	=	qy	=1 -LCAR = ∖	(14) Zj	〔 pjPy-p+ι∕τ - ATPjpy,	qj = 0
A.2 Formal proof for Lemma 1, Lemma2, Theorem 1 and Theorem 2
Lemma 1. For the loss function LCAL given in Eq. (5) and LCAR in Eq. (7), the gradient of
sample-wise LCAL and LCAR (β = 1) with respect to the logits zj can be derived as
-L皿= -Zj	((pj — 1) P .-P+1*	≤ 0,	qj	= qy	= 1	(j'	is	the true classfor sample x) (Pj P -P+ι∕τ ≥ O,	qj	= 0	('	is	not the true Classfor sample	x)
and	-LCAR	/	(pj-1) Pj-I+ ι∕τ- ATpj (pj-1) ≤0,	qj = qy	= 1 -zj	∖	Pjpy-p+ι∕τ - ATpjpy ≥ 0,	qj = 0
respectively.
Proof. From the Appendix A.1, we obtain the gradient of the sample-wise LCAL with respect to the
logits zj is
	-LCAL = -LCaCe = - X	Tqk	-Pk	(⑸ -Zj	-Zj	k=1 T (pk - qk) + qk -Zj
14
Under review as a conference paper at ICLR 2022
where 毅 Can be further derived base on whether k = j by follows:
pk - p2k
-pj pk
k=j
k 6= j
According to Eq. (15) and (16), the gradient of LCAL can be derived as:
∂LCAL _] (Pj- 1) Pj-p+ι∕τ, qj = qy = 1
dzj I n___________P—	=-o
p Pj Py -1+1∕T，	% = 0
(16)
(17)
Since Pj ≤ 1, we havePj - 1 ≤ 0. As T < 1,the term P -P+ι∕τ > 0,wehave (Pj - 1) P -P+ι∕τ ≤ 0
and pj P -p+1∕τ ≥ 0. Similarly, the gradient of simplified LCAR (β = 1) can be derived as:
∂LCAR -	∂Lcal	+ ∂Lr-cace	= I(Pj- 1) jp+1∕ - ATPp(Pj- 1)，qj	- qy	= 1	(18)
dzj	dzj dzj I	Pjpy⅛7Γ - ATPjPy，	qj	=0
Since A is a negative constant, we obtain -AT Pj (Pj - 1) ≤ 0. Thus, in the case of qj = qy = 1,
dLCAR ≤ 0 and in the case of qj- = 0, dLCAR ≥ 0 as claimed. Complete derivations can be found in
the Appendix A.1.	□
The result in Lemma 1 ensures that, during the gradient decent, learning continues on true classes
when trained with LCAL and LCAR. We then prove the noise robustness of Lr-cace.
Recall that noisy label of X is y ∈ {1,…，K} and its true label is y ∈ {1,…，K}. We assume
that the noisy sample (x, y) is drawn from distribution Dn(x, y), and the ordinary sample (x, y) is
drawn from D(x, y). Note that this paper follows the most common setting where label noise is
instance-independent. Then we have y = i(y = i) with probability ηn = (1 — η) and y = j(y = i)
with probability ηj for all j = i and Pj= ηj = η. If ηj = K-ι for all j = i, then the noise is
said to be uniform or symmetric, otherwise, the noise is said to be class-conditional or asymmetric.
Given any classifier f and loss function L, we define the risk of f under clean labels as RL (f) =
Eo(χ,y)[L(f (x, y))], and the risk under label noise rate η as RL(f) = ED(x,y)[L(f (x, y))]. Let
f* and f* be the global minimizers of Rl(f) and RL(f) respectively. Then, the empirical risk
minimization under loss function L is defined to be noise-tolerant if f * is a global minimum of the
noisy risk RηL (f).
Lemma 2. For any x, the sum of Lr-cace with respect to all the classes satisfies:
K
0 < Xj=1 Lr-cace(f(x), j) <A(1 -K),	(19)
where A = log(0) is a negative constant that depends on the clipping operation.
Proof. By the definition of Lr-cace, we can rewrite the sample-wise Lr-cace as
K
Lr-cace = -E (T(P(k∣x) - q(k∣x)) + q(k∣x)) log q(k∣x)
k=1
=-(τ(P(y∣χ) - q(y∣χ)) + q(y∣χ)) logq(y∣χ) - £k=#(丁(P(k∣χ) - q(k∣χ)) + q(k∣χ)) log q(k∣χ)
= - T P(y|x) - T + 1 log1 - AT	k6=yP(k|x)
= -AT (1 - P(y|x)).	(20)
Therefore, we have
KK	K
XLr-cace(f(x),j) = X -AT (1 - P(j |x)) = -ATK+ ATXP(j|x) = AT(1 - K)
j=1	j=1	j=1
15
Under review as a conference paper at ICLR 2022
As τ ∈ (0, 1), A is a negative constant, K is a constant, hence
K
0 < X Lr-cace(f(x), j) < A(1 - K),
j=1
which concludes the proof.	□
Theorem 1. Under Symmetric or uniform label noise with noise rate η < K—, we have
0 ≤ RLr-Cace (m-RLr-Cace (f	< KAn-K--2
and
An< RLcace (坨-RLcace(f ^ W 0
where f * and f be the global minimizers of RLr-cace(f) and RLTCαce(f) respectively.
Proof. For symmetric noise, we have, for any f 1
RLr-cace(f )= EDn(X 助[£"。。6 ( f 3,0)]
=ExED(y∣χ)ED(y∣χ,y) [Lr-cace(f(χ),y)]
= ED(x,y) (1 - η)Lr
-cace(f(x),y) + K-1 Xj 6=y Lr-cace (f (x), j )
K
=(1 - n)RLr-sace (f ) + K-I (X Lr-Cace (f (X ) ,j ) — 冗£ —。。(/
K- 1 j=1
ηK	η K
=(I -	----^)RLr-cace(f ) +	----^X Lr-cace(f (X),j)
K-1	K-1
j=1
From Lemma 2, for all f , we have:
ψRLr-cace(f) < RηLr-cace(f) < -Aη + ψRLr-cace (f)
where ψ = (1 一 KKI). Since n < K—, we have ψ > 0. Thus, we can rewrite the inequality in
terms of RLr-cace (f):
ψ(RLr-cace(f)+ An) < R。— (f) < ^ RLr-9(f)
Thus, for fη*,
RLr-cace(Λ*) - RLr-cace(f B < I(RLr-caceO - RLr-cac"" ) -An)
or equivalently,
RηLr-cace(fη*)-RηLr-cace(f*)>ψ(RLr-cace(fη*)-RLr-cace(f*))+An
Since f* is the global minimizer of RLr-cace (f) and fη* is the global minimizer of RηL	(f), we
have
0 ≤ RLr-cace(f*) - RLr-cace(f', ) < -An = -An(K- I)
r-cace η	r-cace	ψ	K(1 - n) - 1
and
An< RLr-cace(f*)- RLr-cace(fW 0
which concludes the proof.	□
1In the following, note that Ex Ey|x = Ex,y = ED(x,y), which denote expectation with respect to the
corresponding conditional distributions.
16
Under review as a conference paper at ICLR 2022
Theorem 2. Under class-dependent label noise with ηij < 1 - ηi , ∀j 6= i, ∀i, j ∈ [K], where
Inij = p(y = j|y = i),∀j = i and(I - ηi) = p(y = i|y = i), ifRLr-Cacef *) = 0, then
0 ≤RLr-cace(f C-RL-cacef <G,
where G = A(1 一 K)ED(x,y)(1 一 n) > 0, f* and f be the global minimizers ofRLr-cace(f) and
RηL	(f ) respectively.
Proof. For asymmetric or class-dependent noise, we have
RtLr-cace(f ) = EDn(x,y)[Lr-Cace(f (X)，y)]
= ExED(y|x) (1 一 ny)Lr-cace(f(x), y) + X nyj Lr-cace(f (x), j)
j6=y
ED(x,y)
K
(1 一 ny) X Lr-cace(f(x), j) 一 X Lr-cace(f (x), j)
j=1	j 6=y
+ ED(X,y) h X nyj Lr-cace(f(x),j)
j6=y
< ED(X,y) h(1 - ny)A(1 - K) - X Lr-cace(f(x), j)i
j6=y
+ ED(X,y) h X nyj Lr-cace(f(x),j)
j6=y
= A(1 - K)ED(X,y) (1 - ny) - ED(X,y) X(1 - ny - nyj)Lr-cace(f (x), j) .
j6=y
On the other hand, we also have
RLr-cace(f) > -ED(χ,y) [X(I - ny 一 nyj)Lr-cace(f(x), j)i
j6=y
Hence, we obtain
RLr-cace(f ) - RLr-Cace (用	A(I- K)ED(X ,y) (1 一 3)
+ ED(x,y) X(1 一 ny 一 nyj ) Lr-cace (fη (x), j) 一 Lr-cace (f (x), j )
j6=y
Next, we prove the bound. First, (1 一 ny 一 nyj) > 0 as per the assumption that nyj < 1 一 ny.
Second, our assumption has Rr-cace(f *) = 0, We have Lr-cace(f *(x), y) = 0. This is only satisfied
iff fj (x) = 1 when j = y, and fʃ (x) = 0 when j = y. According to the definition of Lr-cace, We
have Lr-cace(f j(x), j) = -Aτ, ∀j = y, and Lr-cace(fj(x),j) ≤ -Aτ, ∀j ∈ [K]. We then obtain
ED(x,y)hX(1 一 ny 一 nyj)Lr-cace(fηj(x), j) 一 Lr-cace(fj(x), j)i ≤ 0
j6=y
Therefore, we have
RLr-cace(f ^^ ) -RLr-Cace ⑺ < A(I- K ) ED(X ,y ) (1 一 3)
Since f is the global minimizers of RLrCαce(f), we have RLrCace(f j) -RLrCace(f9j) ≥ 0, which
concludes the proof.	□
A.3 Comparison with existing noise-robust loss functions
According to the definition in Section 4, we obtain the sample-wise
K
Lr-cace = -E (T(p(k∣x) - q(k∣x)) + q(k∣x)) log q(k∣x)
k=1
=-(T(p(y∣χ) - q(y∣χ)) + q(y∣χ)) logq(y∣χ) - £k=#(丁(p(k∣χ) - q(k∣χ)) + q(k∣χ)) logq(k∣χ)
= - τ p(y|x) - τ + 1 log1 - Aτ	k6=yp(k|x)
= -AT (1 - p(y|x)). where T ∈ (0, 1) and A is a negative constant .	(21)
17
Under review as a conference paper at ICLR 2022
Similarly, we have sample-wise Lmae Ghosh et al. (2017), Lrce Wang et al. (2019), Lgce Zhang &
Sabuncu (2018) and Ltce Feng et al. (2020) as follows
K
Lmae = X |p(k|x) - q(k|x)| = (1 - p(y|x)) + Xp(k|x) = 2(1 - p(y|x));
k=1	k6=y
K
Lrce = -	p(k|x) log q(k|x) = -p(y|x) log1 -	p(k|x) log 0 = -A(1 - p(y|x));
k=1	k6=y
Lgce = XX q(k1x)「=q(y|x)「T-pg)* ∈ (0，1]；
t
Ltce = X
i=1
(1- p(y|x))i
ʌ-----)	"，t ∈ N+ denotes the order of Taylor Series.
i
We observe that when τ = 1 (even though itis impossible), Lr-cace is reduced to Lrce. IfA =-2 and
τ = 1, Lr-cace is further reduced to Lmae. Since confidence τ is various for different samples, Lr-cace
is more like a dynamic version of Lmae. As for Lgce, limρ→o Lgce = Lce and Lgce = 1 Lmae When
P = 1. Similarly, limt→∞ Ltce = Lce and Ltce = 2Lmae when t = 1. Therefore, both Lgce and
Ltce can be interpreted as the generalization of MAE and CE, Which benefits the noise robust from
MAE and training efficiency from CE. However, parameters P andt are fixed before training, so it is
hard to tell what is the best parameter for the certain dataset. Instead, combined with LCAL, Lr-cace
contains a dynamic confidence value τ for each sample that automatically learned from dataset,
facilitating the learning from correctly-labeled samples.
B Algorithm
Algorithm 1 provides detail pseudocode for CAR. Note that for Cosine Annealing learning rate
scheduler, the condition line 8 becomes e ≥ Ec and τ [i] ≥ δ and e%Ep == 0, where Ep is the
number of epochs in each period, we fix Ep = 10 in all experiments.
Algorithm 1: Confidence adaptive regularization (CAR)
Input: Deep neural network Nθ with trainable parameters θ; λ is the parameter for penalty term Lp ; β is the
parameter for regularization term Lr-cace ; Ec is the epoch that starts to estimate target; α is the
momentum in target estimation; training set D, batch size B, total epoch Emax;
1
2
3
4
5
6
7
8
9
10
11
12
t = y
. Initialize the target by noisy labels;
for e = 1, 2, . . . , Emax do
Shuffle D into 1D- mini-batches ;
for n = 1,2,..., 1D| do
for i in each mini-batch Dn do
p[i] = S(Nθ (x[i] ))	. Obtain model predictions;
τ[i] = sigmoid(h[i] )	. Obtain corresponding confidence;
if e ≥ Ec and τ [i] ≥ δ then
t[i] = αt[i] + (1 — α)p[i]	. Iterative label correction;
Calculate the loss LCAR = Lcace + λLp + βLr-cace = — B PB=1 (t[i])T log (T[i] (p[i] — t[i]) +
t[i]) — λ Pi1 log(τ[i]) — β P3 (τ[i](p[i]- t[i])+ t[i])T log(t[i]);
Update θ using stochatic gradient descent;
Output θ.
18
Under review as a conference paper at ICLR 2022
Table 5: Detail information of experiment.
(a) Description of the datasets used in the experiments. (b) Description of the hyperparameters used in our
approach.
Dataset	# of train # of val # of test		# of classes	input size	Noise rate (%)
Datasets with clean annotation					
CIFAR-10	50K	-	10K	10	32 × 32	≈ 0.0
CIFAR-100	50K	-	10K	100	32 × 32	≈ 0.0
Datasets with real world noisy annotation					
Clothing1M	1M	14K	10K	14	224 × 224	≈ 38.5
Webvision 1.0	66K	-	2.5K	50	256 × 256	≈ 20.0
Hyperparameter	Description
λ	Control the strength of penalty loss in LCAL .
β	Control the strength of regularization term Lr-cace.
Ec	The epoch starts to estimate target.
α	The momentum in target estimation.
δ	The threshold of confidence in target estimation.
C Detail description of experiments
Source code for the experiments is available in the zip file. All experiments are implemented in
PyTorch and run in a single Nvidia GTX 1080 GPU. For CIFAR-10 and CIFAR-100, we do not
perform early stopping since we don’t assume the presence of clean validation data. All test accuracy
are recorded from the last epoch of training. For Clothing1M, it provides 50k, 14k, 10k refined
clean data for training, validation and testing respectively. Note that we do not use the 50k clean
data. We report the test accuracy when the performance on validation set is optimal. All tables of
CIFAR-10/CIFAR-100 report the mean and standard deviation from 3 trails with different random
seeds. As for larger datasets, we only perform a single trail.
C.1 Dataset description and preprocessing
The information of datasets are described in Table 5a. CIFAR-10 and CIFAR-100 are clean datasets,
we describe the label noise injection in Appendix C.2. Clothing1M consists of 1 million training
images from 14 categories collected from online shopping websites with noisy labels generated
from surrounding texts. Its noise level is estimated as 38.5% (Song et al., 2019). Following (?Chen
et al., 2019), we use the mini WebVision dataset which contains the top 50 classes from the Google
image subset of WebVision, which results in approximate 66 thousand images. The noise level of
WebVision is estimated at 20% (Li et al., 2017a).
As for data preprocessing, we apply normalization and regular data augmentation (i.e. random crop
and horizontal flip) on the training sets of all datasets. The cropping size is consistent with existing
works (Liu et al., 2020; Li et al., 2020a). Specifically, 32 for CIFAR-10 and CIFAR-100, 224 × 224
for Clothing 1M (after resizing to 256 × 256), and 227 × 227 for Webvision.
C.2 Simulated label noise injection
Since the CIFAR-10 and CIFAR-100 are initially clean, we follow Tanaka et al. (2018); Patrini et al.
(2017) for symmetric and asymmetric label noise injection. Specifically, symmetric label noise is
generated by randomly flipping a certain fraction of the labels in the training set following a uniform
distribution. Asymmetric label noise is simulated by flipping their class to another certain class
according to the mislabel confusions in the real world. For CIFAR-10, the asymmetric noisy labels
are generated by mapping truck → automobile, bird → airplane, deer → horse and cat 什 dog. For
CIFAR-100, the noise flips each class into the next, circularly within super-classes.
C.3 Training procedure
CIFAR-10/CIFAR-100: We use a ResNet-34 and train it using SGD with a momentum of 0.9, a
weight decay of 0.001, and a batch size of 64. The network is trained for 500 epochs for both
CIFAR-10 and CIFAR-100. We use the cosine annealing learning rate Loshchilov & Hutter (2017)
where the maximum number of epoch for each period is 10, the maximum and minimum learning
rate is set to 0.02 and 0.001 respectively. As for cross entropy with MultiStep learning rate scheduler
in Figure 1 and Figure 3 in the paper, we set the initial learning rate as 0.02, and reduce it by a factor
of 10 after 100 and 200 epochs. The reason that we train the model 500 epochs in total is to fully
evaluate whether the model will overfit mislabeled samples, which avoids the interference caused by
early stopping Li et al. (2020b) (i.e. the model may not start overfitting mislabeled samples when
19
Under review as a conference paper at ICLR 2022
0 9 8 7
9 8 8 8
(求)Auajn34
86
0.5	10.0
penaltystrengthΛ
《％) Auejnuu<
regularization strength β
9190β988β7
(求)Aue,Jn84
60
Epoch Ec
90β9B8a7
(东)AuaJr□u4
0.90
momentum a
(％) AUeJnJV
0.00	0.35	0.65	0.95
confidence threshold δ
Figure 6: Test accuracy on CIFAR-10 with 60% symmetric label noise. The mean accuracy over
three runs is reported, along with bars representing one standard deviation from the mean. In each
experiment, the rest of hyperparameters are fixed to the values reported in Section C.4.
the number of training epochs is small, especially when learning rate scheduler is cosine annealing
Loshchilov & Hutter (2017)).
Clothing1M: Following Xiao et al. (2015); Wang et al. (2019), we use a ResNet-50 pretrained
on ImageNet. We train the model with batch size 64. The optimization is done using SGD with a
momentum 0.9, and weight decay 0.001. We use the same cosine annealing learning rate as CIFAR-10
except the minimum learning rate is set to 0.0001 and total epoch is 400. For each epoch, we sample
2000 mini-batches from the training data ensuring that the classes of the noisy labels are balanced.
Webvision: Following Li et al. (2020a); Liu et al. (2020), we use an InceptionResNetV2 as the
backbone architecture. All other optimization details are the same as for CIFAR-10, except for the
weight decay (0.0005) and the batch size (32).
C.4 Hyperparameters selection and sensitivity
Table 5b provides a detailed description of hyperparameters in our approach. We perform hyper-
parameter tuning via grid search: λ = [0.5, 10, 50], β = [0.0, 0.1, 0.3, 0.5], Ec = [20, 60, 100],
α = [0.7, 0.9, 0.99] andδ = [0, 0, 0.35, 0.65, 0.95]. For CIFAR-10, the selected value are λ = 0.5,
β = 0.0, Ec = 60, α = 0.9 and δ = 0.0. For CIFAR-100 with 40% asymmetric label noise, the
selected value are λ = 10,β = 0.1, Ec = 20, α = 0.9, δ = 0.0. For CIFAR-100 with 20%/40%/60%
symmetric label noise, we set λ = 10, β = 0.1, Ec = 60, α = 0.9, δ = 0.95 and λ = 50, β = 0.1,
Ec = 60, α = 0.9, δ = 0.0 for 80% symmetric label noise. For Webvision, we set λ = 50, β = 0.1,
Ec = 200, α = 0.9, δ = 0.0. For Clothing1M, we set λ = 50, β = 0.1, Ec = 60, α = 0.8, δ = 0.0.
Figure 6 and Figure 7 shows the hyperparameters sensitivity of CAR on CIFAR-10 and CIFAR-100
with 60% symmetric label noise respectively. The coefficient of penalty loss λ needs to be large
than 0 to avoid trivial solution but also cannot be too large for CIFAR-10, avoiding neglecting Lcace
term in the loss. As the CIFAR-10 is an easy dataset, no additional regularization requires by Lr-cace
term. Therefore, the regularization coefficient β should be 0 and large β may cause model to underfit.
The performance is robust to Ec and α, as long as the momentum α is large enough (e.g. larger
than 0.7). The choice of confidence threshold δ depends on the difficulty of dataset. A larger δ will
slightly slow down the speed of label correction but helps exclude ambiguous predictions with low
confidence values. Overall, the sensitivity to hyperparameters is quite mild and the performance is
quite robust, unless the parameter is set to be very large or very small, resulting in neglecting Lcace
term or underfitting. We can observe the similar results of CIFAR-100 in Figure 7.
20
Under review as a conference paper at ICLR 2022
0 5 0 O O
7 6 6 4 2
(％) AUaJnUUV
penalty strength λ
O 5
6 4
(％) Aue」nu4
regularization strength β
60
Epoch Ec
(％) >UE3UU<
0.90
momentum a
(％) Aue-Jnu<
0.00	0.35	0.65	0.95
confidence threshold δ
Eft salamander
Figure 7: Test accuracy on CIFAR-100 with 60% symmetric label noise. The mean accuracy over
three runs is reported, along with bars representing one standard deviation from the mean. In each
experiment, the rest of hyperparameters are fixed to the values reported in Section C.4.
Tiger shark
Loggerhead turtle
WhiPtailliZard
Tiger shark
Tiger shark
Stinggray	Komodo dragon
Stinggray

Figure 8: Label correction of Webvision images. Given noisy labels are shown above in red and the
corrected labels are shown below in green.
D More results of label correction and confidence value
We report the label correction accuracy for various level of label noise on CIFAR-10 and CIFAR-100
in Table 6. Figure 10 displays the confusion matrix of corrected label w.r.t. the clean labels on
CIFAR-10 with 60% symmetric, 80% symmetric and 40% asymmetric label noise respectively. We
also show the corrected labels for real-world datasets in Figure 8 and Figure 9.
21
Under review as a conference paper at ICLR 2022
DoWnCoat	Chiffon	Shirt Underwear	Dress
Figure 9: Label correction of Clothing1M images. Given noisy labels are shown above in red and the
corrected labels are shown below in green.
We report the confidence value for high level of label noise on CIFAR-10 in Figure 11 and Figure 12.
As we can see, the confidence values on the diagonal blocks remain higher than those non-diagonal
blocks.
Table 6: Correction accuracy (%) on CIFAR-10 and CIFAR-100 with various levels of label noise
injected to training set.
Dataset		CIFAR-10			CIFAR-100			
Noise ratio	20%	symm 40%	60%	80%	asymm 40%	20%	symm 40%	60%	80%	asymm 40%
Correction accuracy	97.3	95.1	91.1	81.1	93.8	92.6	86.4	76.5	42.4	87.1
E Performance with different estimation strategies
We compare the performance of CAR with three strategies: 1) our strategy in Section 3.4. 2) temporal
ensembling (Laine & Aila, 2017) that adopted in ELR (Liu et al., 2020). 3) directly using the noisy
labels y without label correction. The temporal ensembling calculate the target by
{0	if E<Ec
αt[[iE] -1] +(1 - α)p[[iE]]	ifE ≥ Ec
t[[iE] -1]	otherwise,
(22)
where the target t solely depends on model prediction. Table 7 shows the results. As we can see,
compared to CAR without label correction, CAR with temporal ensembling does not improve much
22
Under review as a conference paper at ICLR 2022
s"q-αs-u
ship-I
ASymmetiIC-40%
Corrected labels
//
Figure 10: Confusion matrix of corrected labels w.r.t clean labels on CIFAR-10 with 60% symmetric,
80% symmetric and 40% asymmetric label noise respectively.
airplane 0.52
0.5B 0.56 0.56 0-40
0.54 0.57 0.53
0.49 047 0.45 0.45
0-46 0.47 0.55
0.63
0.57
0.56
0.50 0.50
cat-0.54 0.51
0.63
0.57
0.52 0.53
deer - 0.54 0.47
0.64
0.59
0.47 0.50
dog - 0.51 0.48
56
0.54
0.47 0.50
frog - 0.51 0.46
0.56
0
53
0.45 0.47 047
horse - 0.53 0.50 0.52
0
58
0.54
0.47
0.54
bird - 0-5β 0.47
Ship - 0.63 0.51 0.50 0.50 0.48 0.48
0.9
0.54
0.β
0.59
0.54
0.55
0.7
0.4g
-0.6
0.47
-0.5
0.4B 0.49
Figure 11: Average confidence values τ of
false labels w.r.t clean labels on CIFAR-10
with 60% symmetric label noise.
automobile-049
0
0.60
0.55
truck-0.58 0.56 0.48 0.50 0.48 0.47
airplane		0.4 B	0∙5β	0.50 0.55 0.52	0.49	0.49	0.50 0.54	0.80
automobile	-0.49	0.53	0.45	0.45 0.47 0.4S	0.46	0.46	0.4β 0.51	-0.75
bird	-0.55	0.4 B		0.50 0.60 0.59	0.50	0.49	0.46 0.49	-0.70
cat	-0.54	0.4 B	0.58	0.59	0.55	0.54	0.50 0.52	
deer	-0.4B	0.47	0.55	0.49	0.59	0.49	0.52	0.46 0.48	0.65
dog	-0.49	0.49	0.57	0.54 0.56	0.53	0.54	0.49 0.53	-0.60
frog	-0.45	0.46	0.51	0.48 0.55 0.51	0.58	0.44	0.46 0.46	
horse ship	-0.4B 0-57	0.47 0.49	0.50 0.4 B	0.47 0.56 0.55 0.46 0.48 0.47	0.46 0.47	0.46	0.45 0.51 0.48	-0.55 0.50
truck	-0.52	0.49	0.47	0.46 0.49 0.50	0.46	0.49	0.50	-0.45
Figure 12: Average confidence values τ of
false labels w.r.t clean labels on CIFAR-10
with 80% symmetric label noise.
performance in easy cases (e.g. 40% symmetric label noise), and it even gets worse performance in
hard cases (e.g. 80% symmetric label noise). However, CAR with our strategy achieves much better
performance. We also conduct the experiments that use CE with different target estimation strategies.
Surprisingly, CE with our strategy can achieve better performance to CAR in CIFAR-10 with 40%
asymmetric noise. However, the overall performance is worse than the performance of using CAR,
due to the reason that CE will memorize noisy labels after early learning phase.
Figure 13: The empirical density of confidence value τ on CIFAR-100 with 40% symmetric label
noise. The mean confidence values of mislabeled samples become smaller with the increasing of β.
F	INFLUENCE OF Lr-cace ON CONFIDENCE DISTRIBUTION
The empirical results of the influence of confidence distribution on CIFAR-100 with different strengths
of Lr-cace are shown in Figure 13. We can observe that with the larger coefficient β on Lr-cace, the
averge confidence of mislabeled samples is closer to 0. Add the different strengths auxililary term
Lr-cace to CAL does further segregate the mislabeled samples from the clean samples.
23
Under review as a conference paper at ICLR 2022
Table 7: The test accuracy of CAR and CE with different target estimation strategies. All the following
experiments use Cosine Annealing learning rate scheduler (Loshchilov & Hutter, 2017).
Dataset Noise type Noise ratio	CIFAR-10			CIFAR-100		
	symm		asymm	symm		asymm
	40%	80%	40%	40%	80%	40%
CAR with our strategy	93.49 ± 0.07	80.98 ± 0.27	92.09 ± 0.12	75.38 ± 0.08	38.24 ± 0.55	74.89 ± 0.20
CAR with temporal ensembling	89.52 ± 0.30	64.07 ± 2.04	80.52 ± 2.21	70.80 ± 0.38	10.28 ± 1.67	63.91 ± 1.65
CAR w/o label correction	89.47 ± 0.50	76.91 ± 0.22	88.23 ± 0.22	69.91 ± 0.21	31.33 ± 0.38	55.68 ± 0.17
CE with our strategy	92.64 ± 0.21	75.51 ± 0.38	92.21 ± 0.11	68.53 ± 0.47	32.36 ± 0.44	73.01 ± 0.90
CE with temporal ensembling	92.12 ± 0.16	72.87 ± 1.98	89.71 ± 1.43	70.45 ± 0.22	9.34 ± 0.78	66.38 ± 0.57
CE w/o label correction	78.26 ± 0.74	56.42 ± 2.49	86.55 ± 1.06	46.34 ± 0.56	11.55 ± 0.35	48.86 ± 0.04
Oooo
8 6 4 2
(％) AQraJΓDQrauoltəɪloɔ
O
O	IOO 200	300	400	500
Epoch
Figure 14: Label correction accuracy vs.
epochs on CIFAR-10 with different levels of
label noise.
IoQQQ 9
0 8 6 4 2
1
(％) >U2T-Uura uɑt①」」0。
O	IOO 200	300	400	500
Epoch
Figure 15: Label correction accuracy vs.
epochs on CIFAR-100 with different levels of
label noise.
G Stability of Iterative label correction
We plot the CIFAR-10 and CIFAR-100 label correction accuracy vs. epochs in Figure 14 and Figure
15 respectively. In both datasets, our iterative label correction strategy achieves a stable correction
effect and the correction accuracy does not drop with the increasing of training epochs. In summary,
iterative label correction does not only recovers the noisy labels back to clean labels but also achieves
high correction accuracy. In addition, the correction accuracy remains stable, which demonstates that
incorporating a certain percentage of prediction to update the noisy labels is an efficient and reliable
way to correct noisy labels.
24