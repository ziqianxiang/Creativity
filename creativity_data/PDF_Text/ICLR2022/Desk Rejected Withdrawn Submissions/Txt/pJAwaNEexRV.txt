Under review as a conference paper at ICLR 2022
Gradient Assisted Learning
Anonymous authors
Paper under double-blind review
Ab stract
In distributed settings, collaborations between different entities, such as financial
institutions, medical centers, and retail markets, are crucial to providing improved
service and performance. However, the underlying entities may have little interest
in sharing their private data, proprietary models, and objective functions. These
privacy requirements have created new challenges for collaboration. In this work,
we propose Gradient Assisted Learning (GAL), a new method for various entities
to assist each other in supervised learning tasks without sharing data, models, and
objective functions. In this framework, all participants collaboratively optimize the
aggregate of local loss functions, and each participant autonomously builds its own
model by iteratively fitting the gradients of the objective function. Experimental
studies demonstrate that Gradient Assisted Learning can achieve performance close
to centralized learning when all data, models, and objective functions are fully
disclosed.
1	Introduction
One of the main challenges in harnessing the power of big data is the fusion of knowledge from
numerous decentralized organizations that may have proprietary data, models, and objective functions.
Due to various ethical and regulatory constraints, it may not be feasible for decentralized organizations
to centralize their data and fully collaborate to learn a shared model. Thus, a large-scale autonomous
decentralized learning method that can avoid data, models, and objective functions transparency may
be of critical interest.
Cooperative learning may have various scientific and business applications (Roman et al., 2013). As
illustrated in Figure 1, a medical institute may be helped by multiple clinical laboratories and pharma-
ceutical entities to improve clinical treatment and facilitate scientific research (Farrar et al., 2014; Lo,
2015). Financial organizations may collaborate with universities and insurance companies to predict
loan default rates (Zhu et al., 2019). The organizations can match the correspondence with common
identifiers such as user identification associated with the registration of different online platforms,
timestamps associated with different clinics and health providers, and geo-locations associated with
map-related traffic and agricultural data. With the help of our framework, they can form a community
of shared interest to provide better Machine-Learning-as-a-Service (MLaaS) (Ribeiro et al., 2015;
Wang et al., 2021) without transmitting their private data, proprietary models, and objective functions.
The main idea of Gradient Assisted Learning (GAL) is outlined below. In the training stage, the
organization to be assisted, denoted by Alice, will calculate a set of ‘residuals’ and broadcast these to
other organizations. These residuals approximate the fastest direction of reducing the training loss
in hindsight. Subsequently, other organizations will fit the residuals using their local data, models,
and objective functions and send the fitted values back to Alice. Alice will then assign weights to
each organization to best approximate the fastest direction of learning. Next, Alice will line search
for the optimal gradient assisted learning rate along the calculated direction of learning. The above
procedure is repeated until Alice accomplishes a sufficient level of learning. In the inference stage,
other organizations will send their locally predicted values to Alice, who will then assemble them
to generate the final prediction. We show that the number of assistance rounds needed to approach
the centralized performance is often small (e.g., fewer than ten). That is practically appealing, as
GAL is primarily developed for large organizations with rich computation resources. A limited
number of interactions with others will reduce the communications and networking costs. Our main
contributions are summarized below.
1
Under review as a conference paper at ICLR 2022
®国
国
昌
Private
Data
Proprietary
MOdel
Figure 1: Decentralized organizations form a community of shared interest to provide better Machine-
Learning-as-a-Service.
•	We propose a Gradient Assisted Learning (GAL) algorithm that is suitable for large-scale
autonomous decentralized learning and can effectively exploit task-relevant information
preserved by vertically decentralized organizations. Our method enables simultaneous
collaboration between multiple organizations without centralized sharing of a model, ob-
jective function, or data. Additionally, GAL does not need frequent synchronization of
organizations. Moreover, GAL has low communication and networking costs. It typically
requires fewer than ten rounds of assistance in our experiments.
•	Interestingly, for the particular case of vertically distributed data, GAL generalizes the
classical Gradient Boosting algorithms. We also provide asymptotic convergence analysis
of the GAL algorithm.
•	Our proposed framework can significantly outperform learning baselines and achieve near-
oracle performance on various benchmark datasets while producing lower communications
overhead compared with the state-of-the-art techniques.
2	Related work
Multimodal Data Fusion Vertically distributed data can be viewed as multimodal data with modali-
ties provided in a distributed manner to different learners/organizations. Standard multimodal data
fusion methods include the early, intermediate, and late data fusions (Khaleghi et al., 2013; Lahat
et al., 2015). These methods concatenate different modes of data at the input, intermediate represen-
tation, and final prediction levels. However, these data fusion methods in decentralized settings often
require organizations to share the task labels to train their local models synchronously. In contrast,
our method presented below only requires that organizations asynchronously fit some task-related
statistics named pseudo-residuals to approximate the direction of reducing the global training loss in
hindsight.
Gradient Boosting We are inspired by Gradient Boosting (Mason et al., 1999; Friedman, 2001),
where weak learners are sequentially trained from the same dataset and aggregated into a strong
learner. In our learning context, each organization uses side-information from heterogeneous data
sources to improve a particular learner’s performance. Our method can be regarded as a generalization
of Gradient Boosting to address decentralized learning with vertically distributed data.
Federated Learning Federated learning (Shokri & Shmatikov, 2015; Konecny et al., 2016; McMa-
han et al., 2017; Diao et al., 2021) is a popular distributed learning framework developed for edge
devices. Its main idea is to learn a joint model by averaging locally learned model parameters.
It avoids the need for the transmission of local training data. Conceptually, the goal of Federated
Learning is to exploit the resources of edge devices with communication efficiency. Vertical Federated
Learning methods split sub-networks for local clients to jointly optimize a global model (Vepakomma
et al., 2018; Yang et al., 2019; Liu et al., 2019; Hamer et al., 2020; Thapa et al., 2020; Chen et al.,
2
Under review as a conference paper at ICLR 2022
2020). These methods can be viewed as federated learning with an intermediate data fusion method,
and the central server will have access to the true labels. In order to converge, these methods typically
require frequent synchronization of backward gradients and a significant number of communication
rounds (Chen et al., 2020). Such synchronization is critical as each client contributes to part of the
globally shared model, and a client,s local update may not decrease the overall loss. In contrast,
our proposed method trains multiple local models with pseudo-residuals, each contributing to a
small portion of the overarching loss. Each round of updates will decrease the loss, and it does not
require frequent synchronizations. Consequently, our method can achieve desirable performance with
significantly fewer communication rounds without a global transparent model.
Assisted Learning Assisted Learning (AL) (Xian et al., 2020) is a decentralized collaborative
learning framework for organizations to improve their learning quality. In that context, neither the
organization being assisted nor the assisting organizations share their private local models and data.
Prior work on AL is limited to mean squared loss regression with only two organizations using a
sequential exchange of information. Inspired by Gradient Boosting, our proposed Gradient Assisted
Learning (GAL) is a general method for multiple organizations to assist each other in supervised
learning scenarios. Our technical novelties include 1) generalization from squared loss to any
differentiable loss for supervised learning, 2) allowing for private loss functions at each organization,
3) generalization from a sequential protocol between two organizations to parallel aggregation across
multiple organizations, and 4) introduction of the assisted learning rate for fast convergence.
The outline of this paper is given next. In Section 3, we introduce and formulate GAL. In Section 4,
we provide extensive experimental studies of GAL under various settings. We provide conclusions
and final remarks in Section 5.
3	Gradient Assisted Learning
3.1	Notation
Suppose that there are N data observations independently drawn from a joint distribution pxy =
pxpy|x, where y ∈ Y and x ∈ Rd respectively represent the task label and feature variables, and
d is the number of features. For regression tasks, we have Y = R. For K-class classification
tasks, Y = {e1, . . . , eK}, where ek is the canonical vector representing the class k, k = 1, . . . , K.
Let E and EN denote the expectation and empirical expectation, respectively. Thus, EN g(y, x) =∆
N -1 PiN=1 g(yi , xi) for any measurable function g, where (yi , xi) are i.i.d. observations from pxy .
Suppose that there are M organizations. Each organization m only holds Xm, a sub-vector of
X (illustrated in Figure 2). In general, we assume that the variables in X1, . . . , XM are disjoint in the
presentation of our algorithm, although our method also allows for the sharing of some variables. For
example, one organization may observe demographic features for a mobile user cohort, and another
organization holds health-related features of that cohort. Without loss of generality, we suppose
that Alice, the organization to be assisted, has local data xi and task label yι, while other M - 1
organizations are collaborators which assist Alice and have local data χ2... XM.
f features
≡ Xi X2 ∙ ∙ ∙ Xm
Figure 2: An illustration of the organizations’ vertically distributed data.
3.2 Problem formulation
For m = 1, . . . , M, let {xi,m}iN=1 denote the available data to the organization m. Thus, N objects
are simultaneously observed by M organizations, each observing a subset of features from the
x ∈ Rd. Alice also has private task labels {yi,1}iN=1 for training purposes.
Let Fm and Lm respectively denote supervised function class (such as generalized linear functions
or neural networks) and the private objective function of organization m. We will assume that
Lm is differentiable. Without loss of generality, we assume that Alice denotes organization 1,
who will be assisted. Without assistance from other organizations, Alice would learn a model that
minimizes the following empirical risk, (FAlone = arg mins∈Fι ENL1(y1, F1(x1)), Note that the
3
Under review as a conference paper at ICLR 2022
above formulation only involves Alice’s local data x1 and local model (as represented by F1 and L1).
Without privacy concerns, Alice would be able to operate on other organizations’ data x2 , . . . , xM as
well. Recall that X represents the ensemble of all the available data variables. In general, the most ideal
case for Alice is to minimize the following empirical risk, FJOint = arg minp∈f ENL1(y1,F(x)),
where F is a supervised function class defined on the space of x.
In reality, Alice has no access to the complete data and model resources of other organizations. In
this light, she shall be happy to outsource the learning task to other organizations to cooperatively
build a model in hindsight, without the need to share any organization’s local data or models. In the
prediction stage, Alice can collect the pieces of information needed to form a final prediction, to
hopefully achieve a performance that significantly improves over her single-organization performance.
To this end, we will develop a solution for Alice to achieve such a goal.
We will include detailed derivations and discussions of our solution in Subsection 3.3. For readability,
we summarize notations that will be frequently used in the exposition below. Our method will require
Alice to occasionally send a continuous-valued vector ri = [ri,ι]N=ι ∈ RN×K to each organization
m at each communication round. These residuals, to be elaborated in the next subsection, approx-
imate the fastest direction of reducing the training loss in hindsight, namely a sample version of
∂L1(y1, F(X))/∂F(x) given Alice,s estimation of F at a particular time (round). Upon the input of
these residual vectors, the organization m will locally learn a supervised function fm that maps from
its feature space to the residual space. With a slight abuse of notation, we also refer to fm as the
learned model. To this end, organization m will perform the empirical risk minimization
1N
fm = arg min EN'm(ri,f(Xm)) = arg min ʊ £'m (ri,i,f (xi,m))
f∈Fm	f∈Fm N i=i
(1)
to obtain a locally trained model fm. Here, Fm and'm respectively denote the supervised function
class and loss function of the organization m. We note that'm are private local regression loss
functions for fitting the pseudo-residual ri and may not necessarily be the same as Li for fitting true
labels. For example, Li may be the cross-entropy loss for classification of label y, while '1：M could
be the squared loss for regression of the response ri . The above local training (optimization) is often
performed using the stochastic gradient descent (SGD) algorithm. In our assisted learning context,
Li , Fm , and 'm are proprietary local resources that cannot be shared across organizations.
3.3 The GAL algorithm
We first introduce the derivation of the GAL algorithm from a functional gradient descent perspective.
Then, we cast the algorithm into pseudocode and discuss each step. Consider the unrealistic case that
Alice has all the data X needed for a centralized supervised function F : X 7→ F (X). Recall that the
goal of Alice is to minimize the population loss Epx,yLi(y, F (X)) over a data distribution px,y. If
px,y is known, starting with an initial guess F0 (X), Alice would have performed a gradient descent
step in the form of
∂∂
F J F - η ∙ ∂FEPχ,y * L Lii(y, F(X)) |F=F0 = F - η ∙ EPχ,y ∂FLi(y, F(X)) |F=F0, (2)
where the equality holds under the standard regularity conditions of exchanging integration and
differentiation. Note that the second term in (2) is a function on Rd . However, because Alice only
has access to her own data Xi , the expectation Epx,y cannot be realistically evaluated. Therefore,
we need to approximate it with functions in a pre-specified function set. In other words, we will
find f from FM that ‘best' approximates Epx,y ∂FLi(y, F(x)). We will show that this is actionable
without requiring the organizations to share proprietary data, models, and objective functions.
Recall that Fm is the function set locally used by the organization m, and Xm is correspondingly
observed portion of X. The function class that we propose to approximate the second term in (2) is
M
FM = f ： X→ Ewmfm(Xm), ∀fm ∈Fm,X ∈ Rd,W ∈ PM ,	(3)
m=i
where PM = {w ∈ RM : PmM=i wm = 1, wm ≥ 0} denotes the probability simplex. The gradient
assistance weights wm’s are interpreted as the contributions of each organization at a particular greedy
4
Under review as a conference paper at ICLR 2022
i



8
End User
Service
Receiver
Collaborator
Private
Data
I≤O⅞ Proprietary
UD Model
update step. The gradient assistance weights are constrained to sum to one to ensure the function
space is compact, and the solutions exist.
We propose the following solution so that each organization can operate on its own local data, model,
and objective function. Alice initializes with a startup model, denoted by F0(x) = F0(x1, y1), based
only on her local data and labels. Alice broadcasts r1 (named ‘pseudo residuals’) to each organization
m, m = 2,…，M, Who will then fit a local model fm using ri. Each organization will then send the
fitted values from fm to Alice, who will train suitable gradient assistance weights wm . Subsequently,
Alice finds the η in (2) that minimizes her current empirical risk. The above procedure is iterated
for a finite number of rounds until Alice obtains a satisfactory performance (e.g., on validation data).
The validation will be based on the same technique as the prediction stage to be described below.
This training stage is described under the ‘learning stage’ of Algorithm 1. Note that the pseudocode
is from the perspective of Alice, the service receiver. For each organization m, it will only need to
perform the empirical risk minimization using the label r1t sent by Alice at each round t.
In the Prediction/Inference stage (given above in Algorithm 1), other organizations send prediction
results generated from their local models to Alice, who will calculate a prediction result FT (x) that
is implicitly operated on x, where T is the number of iteration steps.
We note that the idea of approximating functional derivatives with regularized functions was histori-
cally used to develop the seminal work of gradient boosting (Mason et al., 1999; Friedman, 2001).
Interestingly, when there is only one organization, the above method reduces to the standard gradient
boosting algorithm (Mason et al., 1999; Friedman, 2001).
Organizations in our learning framework form a shared community of interest. Each service-
providing organization can provide end-to-end assistance for an organization without sharing anyone’s
proprietary data, models, and objective functions. In practice, the participating organizations may
receive financial rewards from the one to assist. Moreover, every organization in this framework
can provide its own task and seek help from others. As a result, all organizations become mutually
beneficial to each other. We provide a realistic example in Figure 3 to demonstrate each step of
Algorithm 1. We elaborate on the learning and prediction procedures in the Appendix.
We also provide an asymptotic convergence analysis for a simplified and abstract version of the GAL
algorithm, where the goal is to minimize a loss f 7→ L(f) over a function class through step-wise
function aggregations. Because of the greedy nature of GAL, we consider the function class to be
the linear span of organization-specific Fm . The following result states that the GAL can produce a
solution that attains the infimum of L(f).
Theorem (Informal): Under suitable assumptions of the loss function and learning rates, the GAL
produces anFt that satisfies limt→∞L(Ft) = inff∈span(F1,...,FM) L(f).
4	Experimental Studies
Datasets We experiment with several different types of data introduced below. 1) UCI datasets
downloadable from the scikit-learn package (Pedregosa et al., 2011), including Diabetes (Efron et al.,
2004), Boston Housing (Harrison Jr & Rubinfeld, 1978), Blob (Pedregosa et al., 2011), Iris (Fisher,
1936), Wine (Aeberhard et al., 1994), Breast Cancer (Street et al., 1993), and QSAR (Mansouri
et al., 2013) datasets, where we randomly partition the features into 2, 4, or 8 subsets, each for
an organization. 2) MNIST (LeCun et al., 1998) and CIFAR10 (Krizhevsky et al., 2009) image
5
Under review as a conference paper at ICLR 2022
Algorithm 1 GAL: Gradient Assisted Learning (from the perspective of the service receiver, Alice)
Input: M decentralized organizations, each holding data {xi,m }iN=1 (local) corresponding to N
objects, the task label {yi,1}iN=1 initially held by the service receiver (Alice local) , model
class Fm (local), gradient assistance weights W (Alice local), assistance rate η (Alice local),
overarching loss function Li (Alice local), regression loss function 'm, to fit pseudo-residual
(local), number of assistance rounds T.
Learning Stage:
Intialization:
I Let t = 0, and initialize F0(x) = EN(yi)
for assistance round t from 1 to T do
Compute pseudo-residual
Irt _ _ jdLι(yι,Ft-1(X))
r 1 = -	∂F t-1(x)
Broadcast pseudo-residual r1t to other organizations
for organization m from 1 to M in parallel do
I fm = argminfm∈Fm EN'm (r1 ,fm(Xm))
end
Gather predictions fmt (xm), m = 1, . . . M, from all the organizations
Optimize the gradient assistance weights
Wt = argminw∈pm EN'i 't, Pm=I Wmfm(Xm))
Line search for the gradient assisted learning rate
n=argminη∈R ENLl(yi,F JI(X) + η PM=I Wmfm〉(Xm))
F t(χ) = F t-1(χ)+ηt PM=I Wm fm (Xm)
end
Prediction Stage:
For each data observation x*, of which Xm is held by organization m:
Gather predictions fm (Xmm), t = 1,...,T from each organization m, m = 1,...,M
Predict with FT(X*)= FO(Xm)+PT=I ηt PM=I Wmfm(Xm)
datasets, where we split each image into image patches as depicted in Figure 5. We do not adopt data
augmentation such as horizontal flipping. 3) MIMIC3 (Johnson et al., 2016) dataset, where the task
aims to predict the length-of-stay with in-hospital data. We split the time series features of MIMIC3
for 4 organizations. 4) ModelNet40 (Wu et al., 2015) dataset, which contains 2D camera views of 3D
object data for 12 organizations (following (Su et al., 2015)). For all the datasets, we train on 80% of
the available data and test on the remaining for UCI datasets. The summary statistics of each dataset
are elaborated in Table 4 of the Appendix. We conduct four random experiments for all datasets with
different seeds, and the standard deviation is shown in the brackets.
Model settings We use Linear models for the UCI datasets, convolution neural networks (CNN)
for the MNIST, CIFAR10, and ModelNet40 datasets, and long short-term memory (LSTM) for the
MIMIC3 dataset. Although we have used the same model architecture for every organization in
the experiments, our algorithm does not require the organizations to have the same local learning
algorithms and models. Details of the architectures are given in the Appendix.
Learning For regression tasks on datasets such as the Diabetes, Boston Housing, and MIMIC3,
we train with l1 for the residual loss `m and the overarching loss L1 , and evaluate using the mean
absolute deviation (MAD). For classification tasks on the remaining datasets, we train with '2-loss for
the residual loss `m and cross-entropy loss for the overarching loss L1 , and evaluate using accuracy.
We use the SGD optimizer for Linear and CNN with a learning rate of 10-1 and the Adam optimizer
for LSTM with a learning rate of 10-4. The number of local epochs E is 100 for UCI datasets and
10 for the rest. The number of assistance rounds T is 10 in our experiments.
To optimize gradient assistance weights, we use the Adam optimizer with a learning rate of 10-1
and enforce the parameters to sum to 1 by using the softmax function. Furthermore, we perform a
line search for the gradient assisted learning rate with the Limited-Memory BFGS optimizer using
6
Under review as a conference paper at ICLR 2022
a learning rate of 1. In the experiments, we found that using the quasi-newton method greatly
improves the convergence rates due to better estimation of gradient assisted learning rates compared
with SGD and Adam. The cost to optimize the gradient assistance weights W and gradient assisted
learning rate η is often negligible compared with the cost to fit the pseudo-residuals since the number
of parameters involved in W ∈ RM and η ∈ R1 is small. Details of learning hyper-parameters are
included in Table 6 in the Appendix.
4.1	Baselines
Our experiments are performed with four baselines, including ‘Interm’, ‘Late’, ‘Joint’, and ‘Alone’.
‘Interm’ and ‘Late’ refer to intermediate and late data fusions (Khaleghi et al., 2013; Lahat et al.,
2015), respectively. ‘Interm’ works for deep learning models such as CNN and LSTM by averaging
the hidden representation of each local model. ‘Late’ also works for Linear models as it averages
the output of each local model. ‘Joint’ is the oracle case where all the data are held by Alice and
trained with the Gradient Boosting reduced from GAL. ‘Alone’ is the single-agent scenario, where
only Alice’s data are used for learning and prediction.
The experimental results are shown in Tables 1 and 2. We also visualize the performance of CIFAR10
and MIMIC3 at each assistance round in Figure 4(a,d). Our method significantly outperforms the
bottom line ‘Alone’ in all the settings. This is expected since the first organization holds partial data
and does not receive any assistance under ‘Alone’. Interestingly, the performance of MNIST for
M = 8 drops significantly under ‘Alone’ because the organization only holds the left upper image
patch, which is usually completely dark (shown in Figure 5 of the Appendix). The results demonstrate
that with GAL, an organization with little informative data can leverage other organizations’ private
data and models and even achieve near-oracle performance (the ‘Joint’ case). Moreover, we found
that the number of assistance rounds needed to approach the centralized performance is small (e.g.,
often within ten).We point out that although ‘Interm’, ‘Late’, and ‘Joint’ marginally outperform our
method, they require training of centralized data. Our GAL algorithm replaces the true label used in
‘Interm’, ‘Late’, and ‘Joint’ oracle case with pseudo-residual to enhance privacy (in terms of data,
model, and objective). The results from both regression and classification datasets lead to similar
conclusions. More results for different numbers of organizations can be found in the Appendix.
Table 1: Results on the UCI datasets (M = 8). The Diabetes and Boston Housing (regression) are
evaluated with MAD, and the rest (classification) are evaluated with Accuracy (in percentage).
Dataset	Diabetes	BostonHousing	Blob	Wine	BreastCancer	QSAR
Late	136.2(0.1)	8.0(0)	100(0)	100(0)	96.9(0.4)	76.9(0.8)
Joint	43.4(0.3)	3.0(0)	100(0)	100(0)	98.9(0.4)	84(0.2)
Alone	59.7(9.2)	5.8(0.9)	41.3(10.8)	63.9(15.6)	92.5(3.4)	68.8(3.4)
AL	51.5(4.6)	4.7(0.6)	97.5(2.5)	95.1(3.6)	98.7(1.3)	70.6(5.2)
GAL	42.7(0.6)	3.2(0.2)	100(0)	96.5(3)	98.5(0.7)	82.5(0.8)
Table 2: Results on the MNIST (M = 8), CIFAR10 (M = 8), MIMIC3, and ModelNet40 datasets.
The MIMIC3 (regression) is evaluated with MAD, and the rest (classification) are evaluated with
Accuracy. Note that the ‘Joint’ of ModelNet40 does not perform well because of the known fact that
a joint model cannot take into account multiple orientations (Su et al., 2015).
Dataset	MNIST	CIFAR10	MIMIC3	ModelNet40
Interm	98.8(0.1)	78.2(0.2)	92.4(0.3)	85.8(0.2)
Late	98(0.1)	74.4(0.3)	94.3(0.1)	86.6(0.2)
Joint	99.4(0)	80.1(0.2)	96.2(2.2)	46.3(1.4)
Alone	24.2(0.1)	46.3(0.3)	103.2(0.8)	76.4(1.1)
AL	34.3(0.1)	51.1(0.2)	104.1(0.1)	77.3(2.8)
GAL	96.3(0.6)	74.3(0.2)	96.4(1.8)	83.0(0.2)
4.2	Comparison with the state-of-the-art
We perform experiments with the MIMIC3 and ModelNet40 data to compare our method with
the related works, including Assisted Learning (AL) (Xian et al., 2020) and vertical asynchronous
Federated Learning (VAFL) (Chen et al., 2020). The results and comparison of computation and
communication cost are shown in Table 3. We also provide benchmark results where all the data are
held by Alice (Harutyunyan et al., 2019; Su et al., 2015). We provide some discussions below.
7
Under review as a conference paper at ICLR 2022
—Joint
…♦… Alone
•一• ALm = I)
■ ■» - AL(η = η)
GAL(O = I)
T- GALm = h)
；4	5	6	7	8	9 10
Assistance rounds
(b)
Irlll
—Joint
-…♦…Alone
∙∙A∙ ALm = I)
— ■ -» - AL(η = η)
GAL(〃 = 1)
iiipəm<υuu Bs-Sse luə-pe-lel
・•士- AL(η = 1)
■ ■» - AL(∕7 = η)
一 GALs = I)
T- GAL(η = ηy)
0.225
0.200
0.175
0.150
0.125
0.100
0.075
23456789 10
Assistance rounds
(c)
0123456789 10	0123456789 10	0123456789 10
Assistance rounds	Assistance rounds	Assistance rounds
(d)	(e)	⑴
Figure 4: Results from the CIFAR10 (a-c) (M = 8) and MIMIC3 (d-f) (M = 4) datasets. GAL
significantly outperforms 'Alone' and performs close to the centralized case 'Joint.’ The gradient
assisted learning rate diminishes to zero as the overarching loss converges. A constant gradient
assisted learning rate (η = 1) converges much slower. The gradient assistance weights of the central
image patches (m = {2, 3, 6, 7}) are larger than the boundary ones in the first few rounds.
GAL vs. AL Compared with AL, our method GAL 1) generalizes from the squared loss to any
differentiable loss function. 2) introduces the gradient assisted learning rate to reduce the number of
communication rounds to achieve satisfactory performance, as discussed in Section 4.3. 3) optimizes
multiple organizations in parallel with the help of gradient assistance weights, while AL is restricted
to sequential training of data from each organization. We also note that the original AL only applies
to regression tasks with η = 1. We extend it to tackle classification problem with pseudo-residuals
for comparison as demonstrated in Tables 1 and 2. Compared with AL under the constraint of the
same communication cost, our method requires MT communication rounds. It is due to that AL
trains local models one after another in a sequential manner. In particular, one assistance round of AL
requires M communication rounds to traverse M organizations once. However, one assistance round
of our method only requires one communication round because we can train every organization and
aggregate their outputs in parallel. Moreover, our method outperforms AL in all of our experiments in
terms of prediction. Thus, compared with AL, GAL can significantly generalize the problem scope,
reduce the computation time and number of communication rounds, significantly outperforms AL,
and performs close to the oracle case.
Table 3: Comparison between GAL and state-of-the-art methods. In the table, M represents the num- ber of organizations. The performance metrics are MAD for MIMIC3 and Accuracy for ModelNet40. AL requires M times more computation time and communication rounds because it sequentially trains each organization. VAFL requires far more communication rounds because it requires batch-wise		
updates from the server. The	communication cost	is O(d ∙ Ei) for VAFL and O(K ∙ T) for GAL,
where d, Em, K, T represent the size of feature embeddings, the total number of training epochs of organization m, the size of target labels, and the number of assistance rounds, respectively. Here, d is typically greater than K, and Em is greater than T because GAL allows more local training. Training Epochs Computation Computation Communication Communication DataSet	MethOd	MT	EmP	Time	SpaCe	Round	Cost	ReSUIt Benchmark (Harutyunyan et al., 2019)	1	N/A	100	1 ×	1	×	0	0	×	94.7 MIMIC3	AL (Xian et al., 2020)	4	10	100	4	×	10	×	40	1	×	104.1 GAL	4	10	100	1	×	10	×	10	1	×	96.4 MVCNN (Suetal., 2015)	1	N/A	100	1 ×	1	×	0	0	×	88.1 ModelNet40	VAFL (Chen et al., 2020)	4	N/A	100	1	×	1	×	10000	128	×	81.0 AL (Xian et al., 2020)	12	10	100	12 ×	10	×	120	1	×	77.3 GAL	12	10	100	1	×	10	×	10	1	×	83.0		
8
Under review as a conference paper at ICLR 2022
GAL vs. VAFL Vertical federated learning method such as VAFL (Chen et al., 2020) and
SplitFed (Thapa et al., 2020) can be viewed as federated learning with intermediate data fusion. They
typically require frequent synchronized communications of hidden representations and gradients
to optimize a global model in hindsight. In particular, VAFL allocates separate convolution layers
for each organization and transmits hidden representations to the server. Compared with vAfl,
our method GAL outperforms VAFL in the following aspects. VAFL computes and transmits the
(gradients of) hidden representations for every batch-wise update between server and clients. The
batch size of VAFL is 0.01 of the whole dataset. Consequently, 100 training epochs would result in
10000 communication rounds for each organization. On the contrary, GAL trains one local model for
multiple epochs at each communication round. Each model solves a small part of the overarching
loss function (namely, the pseudo-residual multiplied by the gradient assisted learning rate). 1) GAL
allows each participant to use its own local model architecture autonomously, while VAFL requires
all participants to fit with deep learning model architecture. 2) Under the constraint of the same
number of local training epochs, GAL requires a much fewer number of communication rounds than
VAFL to achieve satisfactory performance. 3) GAL avoids sharing true labels and objective functions,
while the VAFL server will have access to both. GAL is also robust against noise injection-based
privacy mechanisms, with the help of the gradient assistance weights, as discussed in Section 4.3.
4.3	Gradient assisted learning rate
We show the gradient assisted learning rate of CIFAR10 and MIMIC3 datasets at each assistance round
in Figure 4(b,e). More results are included in the Appendix. Recall that we adopt a quasi-newton
method to line search for the gradient assistance rate. Standard first-order optimization methods
usually fail to produce accurate line search results and require more assistance rounds to converge.
We perform an ablation study of using a constant gradient assisted learning rate (η = 1). As shown in
Figure 4(a,d), the constant gradient assisted learning rate leads to a convergence much slower than line
search method. Fast convergence is desirable since the computation and communication cost increases
with the number of assistance rounds. To determine the maximum number of assistance rounds
T for the service receiver, we can run the GAL procedure until the gradient assisted learning rate
becomes small. When the gradient assistance rate is small as shown in Figure 4(e), the overarching
loss converges to zero. In this light, an organization may stop receiving assisted learning when the
gradient assisted learning rate is below a threshold.
4.4	Gradient assistance weights
We show the gradient assistance weights of CIFAR10 and MIMIC3 datasets at each assistance round
in Figure 4(c,f). More results can be found in the Appendix. The results of MIMIC3 show that the
contributing organization with the largest assistance weight may change from one round to another.
For image datasets MNIST and CIFAR10, it is interesting that the image patches with dominant
contributions are m = (2, 3, 6, 7) (colored in red). These image patches correspond to the center of
the original image, which matches our intuition appealingly.
We also perform an ablation study of the gradient assistance weights by adding noises (Gaussian with
zero mean and σ2 variance, σ ∈ {1, 5}) to the transmitted pseudo-residuals to a (randomly chosen)
half of the clients during learning and prediction. The purpose of adding noises is to mimic realistic
scenarios where some assisting organizations are uninformative, add a moderate amount of noise
to enhance data privacy (Dong et al., 2019), or inject adversarial pseudo-residuals. We summarize
the results of this ablation study in Table 13 and Figure 6. The results show that the GAL equipped
with gradient assistance weights is more robust than the GAL with direct average. We note that as
the number of participating organizations becomes large, the gradient assistance weights can also be
used for organization (meta-feature) selection.
5	Conclusion
In this paper, we proposed Gradient Assisted Learning, a decentralized learning method for multiple
organizations to collaborate without sharing proprietary data, models, or labels. The proposed
solution can significantly outperform the learning baselines, state-of-the art methods, and achieve
near-oracle performance (as if data were centralized) on various datasets. Our approach enables
organizations to form a shared community of interest without compromising their private data and
models while achieving near-oracle full collaboration performance. Moreover, this is achieved
without any constraints on the models selected by the collaborating organizations.
9
Under review as a conference paper at ICLR 2022
References
Stefan Aeberhard, Danny Coomans, and Olivier De Vel. Comparative analysis of statistical pattern
recognition methods in high dimensional settings. Pattern Recognition, 27(8):1065-1077, 1994.
Tianyi Chen, Xiao Jin, Yuejiao Sun, and Wotao Yin. Vafl: a method of vertical asynchronous
federated learning. arXiv preprint arXiv:2007.06081, 2020.
Enmao Diao, Jie Ding, and Vahid Tarokh. HeteroFL: Computation and communication efficient feder-
ated learning for heterogeneous clients. In International Conference on Learning Representations,
2021.
Jinshuo Dong, Aaron Roth, and Weijie J Su. Gaussian differential privacy. arXiv preprint
arXiv:1905.02383, 2019.
Bradley Efron, Trevor Hastie, Iain Johnstone, Robert Tibshirani, et al. Least angle regression. Ann.
Stat., 32(2):407-499, 2004.
John T Farrar, Andrea B Troxel, Kevin Haynes, Ian Gilron, Robert D Kerns, Nathaniel P Katz, Bob A
Rappaport, Michael C Rowbotham, Ann M Tierney, Dennis C Turk, et al. Effect of variability in
the 7-day baseline pain diary on the assay sensitivity of neuropathic pain randomized clinical trials:
an acttion study. Pain®, 155(8):1622-1631, 2014.
Ronald A Fisher. The use of multiple measurements in taxonomic problems. Annals of eugenics, 7
(2):179-188, 1936.
Jerome H Friedman. Greedy function approximation: a gradient boosting machine. Ann. Stat., pp.
1189-1232, 2001.
Jenny Hamer, Mehryar Mohri, and Ananda Theertha Suresh. Fedboost: A communication-efficient
algorithm for federated learning. In Proc. ICML, pp. 3973-3983, 2020.
David Harrison Jr and Daniel L Rubinfeld. Hedonic housing prices and the demand for clean air. J.
Environ. Econ. Manag., 5(1):81-102, 1978.
Hrayr Harutyunyan, Hrant Khachatrian, David C Kale, Greg Ver Steeg, and Aram Galstyan. Multitask
learning and benchmarking with clinical time series data. Sci. Data, 6(1):1-18, 2019.
Alistair EW Johnson, Tom J Pollard, Lu Shen, H Lehman Li-wei, Mengling Feng, Mohammad
Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii, a
freely accessible critical care database. Sci. Data, 3:160035, 2016.
Bahador Khaleghi, Alaa Khamis, Fakhreddine O Karray, and Saiedeh N Razavi. Multisensor data
fusion: A review of the state-of-the-art. Information fusion, 14(1):28-44, 2013.
Jakub Konecny, H Brendan McMahan, Felix X Yu, Peter Richtdrik, Ananda Theertha Suresh, and
Dave Bacon. Federated learning: Strategies for improving communication efficiency. arXiv
preprint arXiv:1610.05492, 2016.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
Dana Lahat, Tulay Adali, and Christian Jutten. Multimodal data fusion: an overview of methods,
challenges, and prospects. Proceedings of the IEEE, 103(9):1449-1477, 2015.
Yann LeCun, L6on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Yang Liu, Yan Kang, Xinwei Zhang, Liping Li, Yong Cheng, Tianjian Chen, Mingyi Hong, and
Qiang Yang. A communication efficient vertical federated learning framework. arXiv preprint
arXiv:1912.11187, 2019.
Bernard Lo. Sharing clinical trial data: maximizing benefits, minimizing risk. JAMA, 313(8):793-794,
2015.
10
Under review as a conference paper at ICLR 2022
Kamel Mansouri, Tine Ringsted, Davide Ballabio, Roberto Todeschini, and Viviana Consonni.
Quantitative structure-activity relationship models for ready biodegradability of chemicals. J.
Chem. Inf. Model., 53(4):867-878, 2013.
Llew Mason, Jonathan Baxter, Peter Bartlett, and Marcus Frean. Boosting algorithms as gradient
descent in function space. 1999.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Proc. AISTATS,
pp. 1273-1282, 2017.
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Pretten-
hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research,
12:2825-2830, 2011.
Mauro Ribeiro, Katarina Grolinger, and Miriam AM Capretz. Mlaas: Machine learning as a service.
In Proc. ICMLA, pp. 896-902. IEEE, 2015.
Rodrigo Roman, Jianying Zhou, and Javier Lopez. On the features and challenges of security and
privacy in distributed internet of things. Comput. Netw., 57(10):2266-2279, 2013.
Reza Shokri and Vitaly Shmatikov. Privacy-preserving deep learning. In Proc. CCS, pp. 1310-1321,
2015.
W Nick Street, William H Wolberg, and Olvi L Mangasarian. Nuclear feature extraction for breast
tumor diagnosis. In Biomedical image processing and biomedical visualization, volume 1905, pp.
861-870. International Society for Optics and Photonics, 1993.
Hang Su, Subhransu Maji, Evangelos Kalogerakis, and Erik Learned-Miller. Multi-view convolutional
neural networks for 3d shape recognition. In Proceedings of the IEEE international conference on
computer vision, pp. 945-953, 2015.
Chandra Thapa, Mahawaga Arachchige Pathum Chamikara, and Seyit Camtepe. Splitfed: When
federated learning meets split learning. arXiv preprint arXiv:2004.12088, 2020.
Praneeth Vepakomma, Otkrist Gupta, Tristan Swedish, and Ramesh Raskar. Split learning for health:
Distributed deep learning without sharing raw patient data. arXiv preprint arXiv:1812.00564,
2018.
Xinran Wang, Yu Xiang, Jun Gao, and Jie Ding. Information laundering for model privacy. Proc.
ICLR, 2021.
Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong
Xiao. 3d shapenets: A deep representation for volumetric shapes. In Proceedings of the IEEE
conference on computer vision and pattern recognition, pp. 1912-1920, 2015.
Xun Xian, Xinran Wang, Jie Ding, and Reza Ghanadan. Assisted learning: A framework for
multi-organization learning. Advances in Neural Information Processing Systems, 33, 2020.
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept and
applications. in Proc. TIST, 10(2):12, 2019.
Tong Zhang and Bin Yu. Boosting with early stopping: Convergence and consistency. The Annals of
Statistics, 33(4):1538-1579, 2005.
Lin Zhu, Dafeng Qiu, Daji Ergu, Cai Ying, and Kuiyi Liu. A study on predicting loan default based
on the random forest algorithm. Procedia Computer Science, 162:503-513, 2019.
11
Under review as a conference paper at ICLR 2022
Appendix for “Gradient Assisted Learning”
We describe the application scenario, further experimental results, and theoretical analysis in the
Appendix.
A	Application scenario
As shown in Figure 1, Alice, the service receiver (bank) squared in red dashed line, is the or-
ganization to be assisted. Before learning, it broadcasts identification (ID) to locate and align
vertically distributed data held by other organizations. At the beginning of the Learning Stage, the
bank deterministically initializes the values of F0(x) to be the unbiased estimate of y1, namely
F0(x) = EN(y10). For the regression task, F0(x) is a single scalar. For classification task, F0(x) is
a point in the K-dimensional simplex PK.
During the first assistance round in the Learning Stage, the bank computes pseudo-residual r11
and broadcasts it to other organizations (e.g., hospital, mall, and insurance company). Then, all
the organizations, including the bank, will fit a new local model with 1) their local data, 2) the
pseudo-residual r1, and 3) their local regression loss function'm (e.g., '2-loSS) to fit the pseudo-resid-
ual. We note that organizations have complete autonomy on model fitting. In particular, they can
choose their own learning algorithms and models by considering their resources (e.g., computation
power). Next, the bank will aggregate all the predictions from each organization’s local models by
optimizing a weight vector w1:M referred to as gradient assistance weights. As previously discussed
in Equation (3), we approximate the oracle gradient (operated on centralized data, in hindsight)
with a weighted average of those predictions from organizations. We then numerically search for
the learning rate η . This process can be iterated multiple times until the learning rate is low or the
validation loss is satisfactory.
During the Prediction Stage, organizations will predict with trained models at every assistance round
and transmit their predictions to the bank. Similar to the Learning Stage, the synchronization of each
organization is unnecessary. The bank computes the final prediction with gradient assistance weights,
learning rates, and received predictions.
B Further experimental results
In Table 4, we illustrate the statistics of datasets used in our experiments. In Figure 5, we show
how MNIST and CIFAR10 images are split into 2, 4, and 8 image patches. The left upper image
patch (labeled [1]) of MNIST image is less informative which demonstrates that an organization
with little informative data can leverage other organizations’ private data and models. The central
image patches (labeled [2, 3, 6, 7]) of MNIST and CIFAR10 images are more informative than others,
which leads to larger corresponding gradient assistance weights. Table 5 summarizes the deep neural
network architecture used for the MNIST, CIFAR10, and ModelNet40 datasets. Table 6 shows
the hyperparameters used in our experiments. In Tables 7 and 8, we demonstrate the results of
our experiments for M = 2. In Tables 9 and 10, we demonstrate the results of our experiments
for M = 4. In Tables 11 and 12, we include ablation studies of the noise injection to half of the
organizations for M = 2 and M = 4, respectively.
From Figures 7 to 17, we show the results from the Diabetes, Boston Housing, Blob, Iris, Breast
Cancer, Wine, QSAR, MNIST, CIFAR10, MIMIC3, and ModelNet40 datasets, respectively. All the
results indicate that the proposed GAL algorithm allows all the participants to collaboratively and
efficiently optimize the objective by the iterative fitting of pseudo-residuals.
12
Under review as a conference paper at ICLR 2022
Table 4: Detailed statistics used in each data experiment. The variables d and K respectively
denote the number of features (or the shape of the image) and the length of the prediction vector (or
equivalently, the number of classes in the classification task).
Dataset	Ntrain	NteSt	d	K	M
Diabetes	353	89	10	1	{2, 4, 8}
BostonHousing	404	102	13	1	{2, 4, 8}
Blob	80	20	10	10	{2, 4, 8}
Iris	120	30	4	3	{2, 4}
Wine	142	36	13	3	{2, 4, 8}
BreastCancer	455	114	30	2	{2, 4, 8}
QSAR	844	211	41	2	{2, 4, 8}
MNIST	60000	10000	(1,28,28)	10	{2, 4, 8}
CIFAR10	50000	10000	(3,32,32)	10	{2, 4, 8}
ModelNet40	3163	800	(12,3,32,32,32)	40	{12}
MIMIC3	16000	8000	76	1	{4}
Service
Receiver
Collaborator
(a)
(b)
Figure 5: An illustration of (a) MNIST and (b) CIFAR10 data split into 2, 4, and 8 image patches.
The left upper image patch (labeled [1]) of MNIST images is less informative in general. In contrast,
the central image patches (labeled [2, 3, 6, 7]) of MNIST and CIFAR10 images are more informative.
(a)
(C)
Figure 6: Ablation study results on CIFAR10 (a-b) (M = 8) and MIMIC3 (c-d) (M = 4) datasets.
Plots (a,c) show that the GAL equipped with gradient assistance weight significantly outperforms
the GAL with direct average under noise injections (N (0, σ2) , σ = {1, 5}) to the transmitted
pseudo-residual to half of the organizations during learning and prediction. Plots (b,d) show the
gradient assistance weight of noisy (in orange, σ = 1) and noise-free organizations (in red).
13
Under review as a conference paper at ICLR 2022
Table 5: The model architecture of Convolutional Neural Networks (CNN) used in our experiments
of the MNIST, CIFAR10, and ModelNet40 datasets. The nc, H, W represent the shape of images,
namely the number of image channels, height, and width, respectively. K is the number of classes in
the classification task. The BatchNorm and ReLU layers follow Conv(output channel size, kernel
size, stride, padding) layers. The MaxPool(output channel size, kernel size) layer reduces the height
and width by half.	Image X ∈ Rnc×H×W Conv(64, 3,1,1) MaxPool(64, 2) Conv(128, 3,1,1) MaxPool(128, 2) Conv(256, 3, 1, 1) MaxPool(256, 2) Conv(512, 3, 1, 1) MaxPool(512, 2) Global Average Pooling Linear(512, K)
Table 6: Hyperparameters used in our experiments for training local models, gradient assisted learning
rates, and gradient assistance weights.
Model		UCI MNIST	CIFAR10	ModelNet40	MIMIC3
Architecture		Linear	CNN		LSTM
Local	Epoch Batch size Optimizer Learning rate Weight decay	100 1024	512 SGD 1.0E-01 5.0E-04	10 512	64 Adam 1.0E-04
Gradient assited learning rates	Epoch Batch size Optimizer Learning rate		10 Full L-BFGS 1		
Gradient assistance weights	Epoch Batch size Optimizer Learning rate Weight decay		100 1024 Adam 1.0E-01 5.0E-04		
Assistance rounds			10		
Table 7: Results from the UCI datasets (M = 2). Diabetes and Boston Housing (regression) are
evaluated with MAD and the rest (classification) are evaluated with Accuracy.
Dataset	Diabetes	BostonHousing	Blob	Wine	BreastCancer	QSAR
Late	120.2(0.1)	3.6(0.1)	100(0)	100(0)	100(0)	99.3(0.4)
Joint	43.4(0.3)	3.0(0)	100(0)	99.2(1.4)	100(0)	98.9(0.4)
Alone	46.8(3.5)	4.1(0.7)	100(0)	92.5(6)	93.1(6.4)	99.1(0.6)
AL	63.7(1.5)	3.9(0.6)	98.8(2.2)	95(2.9)	95.1(2.3)	97.6(0.7)
GAL	43.2(0.8)	2.9(0.1)	100(0)	99.2(1.4)	96.5(2.3)	98.9(0.4)
14
Under review as a conference paper at ICLR 2022
Table 8: Results from the MNIST (M = 2) and CIFAR10 (M = 2) datasets.
Dataset	MNIST	CIFAR10
Interm	99.4(0)	81.1(0.3)
Late	99.0(0)	81.0(0.2)
Joint	99.4(0)	80.1(0.2)
Alone	96.7(0.2)	72.7(0.2)
AL	96.4(0.1)	74.7(0.3)
GAL	98.5(0.2)	78.7(0.4)
Table 9: Results from the UCI datasets (M = 4). Diabetes and Boston Housing (regression) are
evaluated with MAD and the rest (classification) are evaluated with Accuracy.
Dataset	Diabetes	BostonHousing	Blob	Wine	BreastCancer	QSAR
Late	129.5(0.1)	4.7(0)	100(0)	100(0)	100(0)	98.5(0.7)
Joint	43.4(0.3)	3.0(0)	100(0)	99.2(1.4)	100(0)	98.9(0.4)
Alone	56.6(8.2)	4.8(0.6)	80.0(6.1)	79.2(13)	84.7(1.4)	97.1(1)
AL	58.3(2.4)	5.2(0.3)	100(0)	88.3(8.3)	92.4(2.3)	98.9(1.1)
GAL	43.3(1.1)	3.0(0.1)	100(0)	100(0)	97.9(2.3)	99.1(0.6)
Table 10: Results from the MNIST (M = 4) and CIFAR10 (M = 4) datasets.
Dataset	MNIST	CIFAR10
Interm	99.1(0)	79.8(0.1)
Late	98.4(0.1)	77.5(0.2)
Joint	99.4(0)	80.1(0.2)
Alone	81.2(0.1)	60.0(0.4)
AL	82.5(0.1)	64.8(0.3)
GAL	96.6(0.2)	77.3(0.2)
Table 11: Ablation study (M = 2) of gradient assistance weights by adding noises to the transmitted
pseudo-residuals to half of the organizations. The evaluation metrics are the same as Tables 1 and 2.
Dataset		Weight	Diabetes	Boston Housing	Blob	Iris	Wine	Breast Cancer	QSAR	MNIST	CIFAR10
σ	1	x	50.1(1.9)	4.4(0.2)	62.5(2.5)	80.8(6.4)	86.8(2.3)	89.9(3.1)	73.2(1.3)	79.7(0.3)	48.8(0.3)
		✓	47.8(2.4)	3.5(0.5)	97.5(4.3)	95(3.7)	96.5(3.0)	98.7(1.0)	80.2(0.5)	96.8(0.1)	71.4(0.1)
σ	5	x	58.8(1.3)	6.1(0.2)	25.0(9.4)	52.5(10.9)	63.9(3.4)	73.2(1.0)	63.3(0.5)	34.8(0.5)	22.0(0.2)
		✓	46.5(3.1)	4.1(0.8)	83.8(7.4)	90(4.1)	93.1(4.2)	97.6(1.1)	78.3(1)	96.3(0.1)	65.9(0.3)
Table 12: Ablation study (M = 4) of gradient assistance weights by adding noises to the transmitted
pseudo-residuals to half of the organizations. The evaluation metrics are the same as Tables 1 and 2.
Dataset	Weight	Diabetes	Boston Housing	Blob	Iris	Wine	Breast Cancer	QSAR	MNIST	CIFAR10
σ=1	x	46.7(1.0)	4.1(0.1)	46.3(6.5)	80.0(5.3)	85.4(3.0)	91.2(1.4)	72.6(2.2)	78.7(0.1)	47.6(0.3)
	✓	45(2.8)	3.7(0.5)	90.0(5.0)	95.8(4.3)	94.4(3.4)	97.8(1.0)	79.1(1.1)	94.1(0.1)	65.4(0.3)
σ=5	x	59.4(1.1)	5.7(0.4)	13.8(4.1)	54.2(7.6)	61.1(7.1)	75.9(2.9)	64.1(1.8)	38.4(0.3)	22.6(0.5)
	✓	49.6(3.7)	4.1(0.7)	66.3(9.6)	93.3(2.4)	93.7(3.6)	97.8(0.4)	76.7(1.6)	93.0(0.2)	59.9(0.6)
Table 13: Ablation study (M = 8) of gradient assistance weights by adding noises to the transmitted
pseudo-residuals to half of the organizations. The evaluation metrics are the same as Tables 1 and 2.
Dataset		Weight	Diabetes	Boston Housing	Blob	Wine	Breast Cancer	QSAR	MNIST	CIFAR10	MIMIC3	ModelNet40
	1	x	49.0(1.6)	4.3(0.2)	46.3(6.5)	81.2(5.3)	90.8(2.5)	73.2(1.0)	75.1(0.4)	45.4(0.3)	99.3(0.8)	55.8(1.0)
σ=		✓	46.4(2.3)	4.0(0.2)	78.8(8.2)	88.9(2.0)	96.7(1.0)	78.9(1.2)	92.7(0.1)	61.0(0.4)	94.9(1.2)	78.3(0.9)
σ=	5	x	61.0(2.4)	5.8(0.2)	12.5(2.5)	54.2(6.9)	78.5(2.0)	61.8(0.5)	33.8(0.3)	23.3(0.6)	110.5(0.6)	24.5(0.4)
		✓	49.7(3.1)	4.7(0.5)	62.5(9.0)	84.7(1.4)	96.9(1.3)	77.1(0.8)	92.1(0.2)	57.3(0.3)	96.4(0.8)	77.5(0.4)
15
Under review as a conference paper at ICLR 2022
(a)
Ooooo
8 6 4 2
3％」6u-∈p ①-P3sωsp-l->u ①-P(UJ5
(b)
Figure 7: Results from the Diabetes (M = 8) dataset.
(a)
(b)
Figure 8: Results from the Boston Housing (M = 8) dataset.
0123456789 10
Assistance rounds
Joint
Alone
AL(η = l)
AL(η = η)
GAL(A7 = 1)
GALs =力
0123456789 10
Assistance rounds
0123456789 10
Assistance rounds

(b)
(C)
Figure 9: Results from the Blob (M = 8) dataset.
(a)
…♦… Alone
- -⅛ - ALs=I)
■ ■» - AL(η = η)
GAL(O = I)
GAL(η = η)
5 0 5 0 5c
2 2 11
£更 6u⊂Je ①一 P2sωse Lu①一pe」D
(b)
Figure 10: Results from the Iris (M = 4) dataset.
050505050
099887766
1
ADe.JnDUV
(a)
Alone
ALs=I)
AL(O = η)
GAL(∕7=l)
GAL(η = n)
-→- Joint
…♦… Alone
・•A• ALs = I)
■ ■* - ALm =吊
→- GAL(O=I)
GAL(∕7 = η)
0123456789 10
Assistance rounds
(b)
Figure 11: Results from the Breast Cancer (M = 8) dataset.
16
Under review as a conference paper at ICLR 2022
AL(∕7 = l)
AL(∕7 ="
GALS=I)
G∕XL(η = η)
0123456789 10
Assistance rounds
(b)
(a)
Figure 12: Results from the Wine (M = 8) dataset.
(c)
5 0 5 0 5 0
8 8 7 7 6 6
(b)
Figure 13: Results from the QSAR (M = 8) dataset.
AL(Z7 = I)
AL(η = n)
7 6 5 4 3 2 1
若」①-P2sωse IU ①-pe」。

▲ ■ AL(η = 1)
w - AL(I =力)
T- GAL(∕7≡1)
T- GAL(η = ∏)
-→- Joint
…♦… Alone
• ・▲ ∙ AL(∕7 = 1)
■ ■* - AL(∕7 = ∕7)
- - GALS = I)
GAL(η = η)
—Joint
…♦… Alone
•	・▲ " ALm = 1)
•	∙∙ - AL(η = η)
GAL(η = l)
T- GAL(η = η)
JO 5 0 5cz
Xl 2 Il
əw 6u 一 Ee ①-pss∞sp IU①
(b)
(a)
Figure 14: Results from the MNIST (M = 8) dataset.
0123456789 10
Assistance rounds
(c)
(a)
3E」CTC-EroO- P3sωse-l-luə一 pe」o
(b)
(C)
AL(η = l)
■» - AL(η = η)
+- GAL(O=I)
GAL(η = η)
Figure 15: Results from the CIFAR10 (M = 8) dataset.
(b)
Figure 16: Results from the MIMIC3 (M = 4) dataset.

(C)
17
Under review as a conference paper at ICLR 2022
Figure 17: Results from the ModelNet40 (M = 12) dataset.
Algorithm 2 Abstract form of GAL (for theoretical analysis)
Learning Stage:
Intialization:
I Let t = 0, and initialize F0 ∈ F1
for assistance round t from 1 to T do
for organization m from 1 to M in parallel do
Optimize each local model by solving
(αt,fmt ) =	arg min	L(F t-1 + αfm)	(4)
α∈[-at ,at],fm ∈Fm
end
Gather predictions fmt , m = 1, . . . M, from all the organizations
Optimize the gradient assistance weights and learning rate by solving
(W t,ηt )=	arg min	L(F t-1 + η X Wm f^n)	⑸
w∈PM,η∈[-at,at]	m=1
Let F t = F t-1+ηt Pm=I Wm fm
end
18
Under review as a conference paper at ICLR 2022
C	Theoretical analysis
To develop a convergence analysis of the GAL algorithm, we consider an abstract form of the GAL
training procedure as described in Algorithm 2. In particular, we use the following notations. We
still let Fm (for each m = 1, . . . , M) denote a set of real-valued functions defined on organization
m’s data xm . For notational simplicity, for each fm ∈ Fm, we also treat it as a function of the
(artificially) extended variable x = [x1, . . . , xM]. So, we may write a function in the form of f1 + f2,
which basically means [x1, x2] 7→ f1(x1) + f2(x2). Let L denote the overarching loss function to
minimize (for the agent to assist), and PM the probability simplex.
At round t = 0, we initialize with any F0 ∈ F1. At each round t, each organization first runs a
greedy boosting step to obtain (αt, fmt ). The fmt will be sent to us (the organization to assist). Then,
We run another greedy step to optimize the assistance weights Wt and learning rate τ^t, with fixed fm,
m = 1, . . . , M. The weighted function will be added to Ft-1 to generate the latest Ft.
For each m, we let
Km
SPan(Fm) = £〃jfj : 〃j ∈ R,fj ∈ Fm, Km ∈ N+ ,
which is the function space formed from linear combinations of elements in Fm . Let
M
span(F1 , . . . , FM ) =	wm fm : wm ∈ R, fm ∈ span(Fm )
m=1
denote the linear span of the union of F1, . . . , FM. An equivalent way to write it is span(∪mM=1Fm).
We will show the following convergence result. With a suitable choice of step parameters at and
regularity conditions of the loss L, the abstract form of GAL can produce Ft that asymptotically
attains the minimum loss within the function class span(F1, . . . , FM). We make the following
technical assumptions.
(A1) The loss (functional) f → L(f) is convex and differentiable on F, with gradient VL. Also,
for all f ∈ span(F1, . . . , FM) and g ∈ ∪mM=1Fm, the function u 7→ L(f + ug) has a second order
derivative ∂2L(f + ug)∕∂u2, and it is upper bounded by a fixed constant C.
(A2) The ranges of learning rates {at}t=1,2,... satisfy Pt∞=1 at = ∞, Pt∞=1 at2 < ∞.
Theorem 1 Under Assumptions (A1) and (A2), the GAL solution in Algorithm 2 satisfies L(Ft) →
inf f ∈span(F1 ,...,FM) L(f) as t → ∞.
Remarks on Theorem 1: The result says that with suitable control of the learning rates, the greedy
procedure in Algorithm 2 can converge to the oracle one could obtain within span(F1, . . . , FM). Sup-
pose that an organization, say the one indexed by m = 1, does not collaborate with others. Likewise,
we have the convergence for that particular organization, limt→∞ L(Ft) = inff*∈span(Fι) L(f *). It
can be seen that the GAL will produce a significant gain for this organization as long as
inf	L(f*) < inf	L(f*).	(6)
f * ∈span(F1,...,FM)	f * ∈span(F1)
It is conceivable that (6) is easy to meet in many practical scenarios since each Fm is operated on
a particular modality of data that belongs to organization m. On the other hand, a skeptical reader
may wonder how the GAL solution compares with a function learned from the pulled data. It is
possible that the global minimum of L (over functions that operate on the pulled data) does not
belong to span(F1, . . . , FM). If that is the case, the best we can do is to find f that attains the limit
inf f ∈span(F1,...,FM) L(f). This is a limitation due to the constraint that organizations cannot share
data and the additive structure of span(F1, . . . , FM). Fortunately, in various real-data experiments
we performed, the GAL often performs close to the centralized learning within only a few assistance
rounds.
In the technical result, we could allow the approximate minimization of (4) and (5), meaning that the
loss of the produced solution is δt-away from the optimal loss. In that case, it can be verified that
Pt∞=1 δt < ∞ is sufficient to derive the same asymptotic result in Theorem 1.
19
Under review as a conference paper at ICLR 2022
The proof of Theorem 1 uses the same technique as was used in (Zhang & Yu, 2005). The technical
result here is nontrivial, because fmt (m = 1, . . . , M) in each round t are not jointly minimized with
Wt and ηt in (5), and thus their linear combination may not be the most greedy solution of minimizing
L(F t-1 + f) within f ∈ span(F1, . . . , FM).
A limitation of our theoretical result is that it does not explain our experimental observations that
GAL requires only a few rounds of assistance to obtain excellent performance. We leave a more
sophisticated convergence analysis as future work.
Proof of Theorem 1:
Let f * ∈ SPan(Fι,..., FM) be an arbitrary fixed function. It is introduced for technical convenience
and can be treated as the function that (approximately) attains the infimum of L(f).
For every f ∈ sPan(F1, . . . , FM), we define the following norm with resPect to the basis functions,
M Km
kfkι =inf kμkι : £ £μm,j fm,j : μm,j ∈ R, fm,j ∈ Fm, Km ∈ N*
m=1 j=1
where ∣∣μkι denotes the abstract sum of its entries, namely Pm=ι	M j=ι Km ∣μm,j |.
For each t, let St ⊂ ∪mM=1Fm denote the finite set of functions such that
1)	fmτ ∈ St for all 0 < τ < t, and
2)	f* = Pg∈st μf*g (μg ∈ R), with ∣∣μ∕* kι ≤ kf*kι + ε.
Note that St exists due to the definition of ∣∙∣ι and the construction of each fmn. Suppose that F t-1
admits the representation Ft-1 = Pg∈s= μFt-ιg.
From (5), we have
L(Ft) ≤L(Ft-1 + ηtfm), ∀m =1,...,M.	(7)
Meanwhile, it follows from (4) that for each m, and each g ∈ St ∩ Fm ,
L(Ft-1 + ηtfm) ≤L(Ft-1+ atsgg).	(8)
where Sg = sign(μf* — μ9pt-ι). Combining (7) and (8), We obtain
L(Ft) ≤ L(Ft-1 + ats9g), ∀g ∈ St.	(9)
Applying Taylor expansion to f 7→ L(f) at f = Ft-1, and invoking (9) and Assumption (A1), we
have
C
L(Ft)- L(Ft-1) ≤ L(Ft-1 + ats9g) - L(Ft-1) ≤ ats9VL(Ft-1)τg +	a；	(10)
for all sufficiently small at > 0. Let ∣∣μf* 一 μpt-i ∣1 = Pg∈st ∣μf * 一 μFt-i |. Multiplying both
sides by ∣μf * 一 μF 1 |, and add up all the g ∈ St, We have
C
∣μf* - μFt-i ∣1 ∙{L(Ft) - L(Ft-1)}≤ atVL(Ft-1)τ(f* 一 Ft-1) + Ea；
C
≤ at{L(f*)-L(Ft-1)} + ~2a；	(11)
where the last inequality is due to the convexity of L. If ∣μf* — μpt-i ∣∣1 = 0, Ft-1 already converges
to f*. Otherwise, we rearrange (11) to obtain
L(Ft) 一 L(f*) ≤
≤
1一
1一
_______at________
kμf* 一 μF t-111
C
{L(F ~1)一£(/*)} + -2 a；
___________at__________
kμf* k1 + 1 + PT=0 aτ
2
{L(F t-1)—L(f*)} + 3 a；,
(12)
(13)
20
Under review as a conference paper at ICLR 2022
where the last inequality is due to the triangle inequality, the way Ft-1 is constructed, and the fact
that ε can be arbitrarily chosen. Here, we defined a0 =∆ 0. Let a1:t = Ptτ =1 aτ for each t ≥ 1.
Applying (13) and the Lemma 4.2 in (Zhang & Yu, 2005), we have
max(0, L(Ft) -L(f *)) ≤ 叫1 ^1 + C XX pf*±*.	(14)
kμf*∣∣ι + ai：t	2 τ=ι kμf*kι + ai：t
Since f * is arbitrarily chosen, it can be seen from (14) and Assumption (A2) that limt→∞ L(Ft)=
inff*∈span(Fι,…,Fm) L(f ).
21