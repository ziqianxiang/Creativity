Under review as a conference paper at ICLR 2022
Personalized Federated Learning with
Clustered Generalization
Anonymous authors
Paper under double-blind review
Ab stract
The prevalent personalized federated learning (PFL) usually pursues a trade-off
between personalization and generalization by maintaining a shared global model
to guide the training process of local models. However, the sole global model
may easily transfer deviated knowledge (e.g., biased updates) to some local mod-
els when rich statistical diversity exists across the local datasets. Thus, we argue
it is of crucial importance to maintain the diversity of generalization to provide
each client with fine-grained common knowledge that can better fit the local data
distributions and facilitate faster model convergence. In this paper, we propose a
novel concept called clustered generalization (CG) to handle the challenge of sta-
tistical heterogeneity, and properly design a CG-based framework of PFL, dubbed
CGPFL. Concretely, we maintain K global (i.e., generalized) models in the server
and each local model is dynamically associated with the nearest global model to
conduct ‘push’ and ‘pull’ operations during the iterative algorithm. We conduct
detailed theoretical analysis, in which the convergence guarantee is presented and
O(√K) speedup over most existing methods is granted. To quantitatively study
the generalization-personalization trade-off, we introduce the ‘generalization er-
ror’ measure and prove that the proposed CGPFL can achieve a better trade-
off than existing solutions. Moreover, our theoretical analysis further inspires a
heuristic algorithm to find a near-optimal trade-off in CGPFL. Experimental re-
sults on multiple real-world datasets show that our approach surpasses the state-
of-the-art methods on test accuracy by a significant margin.
1	Introduction
Recently, personalized federated learning (PFL) has emerged as an alternative to conventional fed-
erated learning (FL) to cope with the statistical heterogeneity of local datasets (a.k.a., Non-I.I.D.
data). Different from conventional FL that focuses on training a shared global model to explore the
global optima of the whole system, i.e., minimizing the averaged loss of clients, the PFL aims at
developing a personalized model (distinct from the individually trained local model which usually
fail to work due to the insufficient local data and the limited diversity of local dataset) for each client
to properly cover diverse data distributions. Personalized models maintain the personaliztion of lo-
cal data distributions and meanwhile are able to avoid overfitting with the guaidance of the shared
global model. During the PFL training, the personalization usually requires personalized models to
fit local data distributions as well as possible, while the generalization needs to exploit the common
knowledge among clients by collaborative training. Thus, the PFL is indeed pursuing a trade-off
between them to achieve better model accuracy than the traditional FL. The state-of-the-art works
usually adopt a bi-level architecture to achieve the trade-off (Hanzely & Richtarik, 2020; Hanzely
et al., 2020; T Dinh et al., 2020; Fallah et al., 2020; Li et al., 2021). More specifically, the server-
side model is trained by aggregating local model updates from each client and hence can obtain the
common knowledge covering diverse data distributions. Such knowledge can then be offloaded to
each client and contributes to the generalization of personalized models.
Despite the recent PFL approaches have reported better performance against conventional FL meth-
ods, they may still be constrained in personalization by using sole global model as the guidance
during the training process. Concretely, our intuition is that: If the feature space is of significant
diversity across local data distributions, then multiple generalization directions can provide fine-
grained common knowledge and further facilitate the personalized models toward better recognition
1
Under review as a conference paper at ICLR 2022
accuracy and faster model convergence. We thus argue one potential bottleneck of current PFL
methods is the loss of generalization diversity with only one global model. Worse still, the global
model may also easily degrade the overall performance of PFL models due to negative transfers in
a highly heterogeneous scenario (Wang et al., 2019). In this paper, we design a novel PFL train-
ing framework, dubbed CGPFL, by involving the proposed concept, i.e., clustered generalization
(CG), to handle the challenge of rich statistical heterogeneity. More specifically, we suppose the
participating clients can be clustered into several groups based on their statistical characteristics and
each group can be corresponded to a generalized model maintained in the server. The personalized
models are dynamically associated with the nearest generalized model and guided by it sub-globally
with fine-grained generalizaation in an iterative manner. We formulate the process as a bi-level op-
timization problem considering both the global models with clustered generalization maintained in
the server and the personalized models trained locally in clients.
The main contributions of this work are summarize as follows:
•	To the best of our knowledge, we are the first to propose the concept of clustered gener-
alization (CG) to provide fine-grained generalization and seek a better trade-off between
personalization and generalization in PFL, and further formulate the training as a bi-level
optimization problem that can be solved effectively by our designed CGPFL algorithm.
•	We conduct detailed theoretical analysis to provide the convergence guarantee and prove
that CGPFL can obtain a O(√K) times acceleration over the convergence rate of most
existing algorithms for non-convex and smooth case. We further derive the generalization
bound of CGPFL and demonstrate that the proposed clustered generalization can con-
stantly help reach a better trade-off between personaliztion and generalization in terms of
generalization error against the state-of-the-arts.
•	We provide a heuristic improvement of CGPFL, dubbed CGPFL-Heur, by minimizing the
generalization bound in the theoretical analysis, to find a near-optimal trade-off between
personalization and generalization. CGPFL-Heur can achieve a near-optimal accuracy with
negligible additional computation in the server, while retaining the same convergence rate
as that of CGPFL.
•	Experimental results on multiple real-world datasets demonstrate that our proposed meth-
ods, i.e., CGPFL and CGPFL-Heur, can achieve higher model accuracy than the state-of-
the-art PFL methods in both convex and non-convex cases.
2	Related Work
Considering that one shared global model can hardly fit the heterogeneous data distributions, some
recent FL works (Ghosh et al., 2020; Sattler et al., 2020; Briggs et al., 2020; Ghosh et al., 2019;
Mansour et al., 2020) try to cluster the participating clients into multiple groups and develop cor-
responding number of shared global models by aggregating the local updates. After the training
process, the obtained global models are offloaded to the corresponding clients for inference. Since
these methods only reduce the FL training into several sub-groups, of which each global model is
still shared by their in-group clients, the personalization is scarce and the offloaded models can still
hardly cover the heterogeneous data distributions across the in-group clients. Specifically, IFCA
(Ghosh et al., 2020) requires each client to calculate the losses on all global models to estimate its
cluster identity during each iteration, and result in significantly higher computation cost. CFL (Sat-
tler et al., 2020) demonstrates that the conventional FL even cannot converge in some Non-I.I.D.
settings and provides intriguing perspective for clustered FL with bi-partitioning clustering. How-
ever, it can only work for some special Non-I.I.D. case described as ‘same feature & different labels’
(Hsieh et al., 2020). FL+HC (Briggs et al., 2020) divides the clients clustering and the model train-
ing processes separately, and only conducts the clustering once at a manually defined step, while the
training remains the same as conventional FL. Differently, robust FL against the Byzantine machine
in Non-I.I.D. case is studied in (Ghosh et al., 2019), where the k-Means algorithm is utilized to
cluster the clients and then find out the outlier (Byzantine) machines. Last, three effective PFL ap-
proaches are proposed in (Mansour et al., 2020), of which the user clustering method is very similar
to IFCA (Ghosh et al., 2020).
2
Under review as a conference paper at ICLR 2022
Most recently, the PFL approaches have attracted increasing attention (Tan et al., 2021; Kairouz
et al., 2019; Li et al., 2020; Kulkarni et al., 2020). Among them, a branch of works (Hanzely &
Richtarik, 2020; Hanzely et al., 2020; Deng et al., 2020) propose to mix the global model on the
server with local models to acquire the personalized models. Specifically, Hanzely et al. (Hanzely
et al., 2020; Hanzely & Richtarik, 2020) formulate the mixture problem as a combined optimization
of the local and global models, while APFL (Deng et al., 2020) straightforwardly mixes them with
an adaptive weight. FedMD (Li & Wang, 2019) exploits the knowledge distillation (KD) to transfer
the generalization information to local models and allows the training of heterogeneous models in
FL setting. Differently, FedPer (Arivazhagan et al., 2019) splits the personalized models into two
separate parts, of which the base layers are shared by all the clients and trained on the server, and the
personalization layers are trained to adapt to individual data and maintain the privacy properties on
local devices. MOCHA (Smith et al., 2017) considers the model training on the clients as relevant
tasks and formulate this problem as a distributed multi-task learning objective. Jiang et al. (Jiang
et al., 2019) and Fallah et al. (Fallah et al., 2020) make use of the model agnostic meta learning
(MAML) (Finn et al., 2017) to implement the PFL, of which the obtained meta-model contains the
generalization information and can be utilized as a good initialization point of training.
3	Problem Formulation
We start by formalizing the FL task and then introduce our proposed method. Given N clients
and the their Non-I.I.D. datasets D1, ..., Di, ..., DN that subject to the underlying distributions as
D1, ..., Di, ..., DN (Di ∈ Rd×ni and i ∈ [N]). Every client i has mi instances zi,j = (xi,j, yi,j),
j ∈ [mi], where x is the data features and y denotes the label. Hence, the objective function of the
conventional FL can be described as (Li et al., 2021):
mind {G(ω) := G(fι(ω; Dι),…,fN(ω; DN))},	(1)
where ω is the global model and fi : Rd → R, i ∈ [N] denotes the expected loss function over
the data distribution of client i: fi(ω; Di) = Eζ*j∈d [fi(ω; zi,j)]. G(∙) denotes the aggregation
method to obtain the global model ω. For example, FedAvg (McMahan et al., 2017) applies G(ω) =
PN=I mmifi(ω) to do the aggregation, where m is the total number of instances on local devices.
To handle the challenge of rich statistical diversities in PFL, especially in the cases where the local
datasets pose cluster structure, our CGPFL propose to maintain K generalized models in the server
to guide the training of personalized models on the clients. During training, the local training process
based on its local dataset can push the personalized model to fit its local data distribution as well
as possible. Meanwhile, the regularizer will dynamically pull the personalized model as close as
possible to its nearest generalized model during the iterative algorithm, from which the fine-grained
common knowledge can be transferred to each personalized model to better balance the general-
ization and personalization. Hence, the overall objective function of CGPFL can be described as a
bi-level optimization problem as:
1N
min - X {Fi(θi) := fi(θi) + λr(θi,ωk)},i ∈ Ck,
Θ∈Rd×N N
i=1
s.t. Ω*,CK = arg min G(ωι,...,ωκ; CK),
Ω∈Rd×K ,Ck
where θi (i ∈ [N]) denotes the personalized model on client i and Θ = [θ1, ..., θN ]. The generalized
models are denoted by Ω = [ωι,…,ωκ]. λ is a hyper-parameter and Ck denotes the corresponding
cluster that client i belongs to.
In general, there exists two alternative strategies to generate the global models. The intuitive one is
to solve the inner-level objective minΩ∈d×κ G(ωι,…，ωκ) based on local datasets, which is similar
to IFCA (Ghosh et al., 2020). However, the computation overhead is high in the local devices while
their available computation resources are usually limited. Worse still, uploading the original local
gradients is also accompanied with higher risk of privacy leakage (Lyu et al., 2020; Zhu & Han,
2020). Comparing the local objective that trains a generalized model ωk based on local dataset,
i.e., ω* = arg min fi(ω; Di), with that of the personalized model, i.e., θi = arg min{fi (θ%; Di) +
ω	θi
λr(θi, ω1)}, We notice that the locally obtained θ* can be regarded as the distributed estimation of
ωk. In this way, the regularizer r(θ*,ω^) can be used to evaluate the estimation error, and We can
3
Under review as a conference paper at ICLR 2022
further derive the generalized models by minimizing the average estimation error. In this paper,
We use L2-norm i.e., r® ωk) = 11 怛-ωk ∣∣2 as the regularizer, which is also adopted in various
prevalent PFL methods (Hanzely & Richtarik, 2020; Hanzely et al., 2020; T Dinh et al., 2020;
Li et al., 2021) and has empirically demonstrated to be superior over other regularizers, e.g., the
symmetrized KL divergence in (Li et al., 2021). Hence, we formulate our overall objective as:
1N	λ
min N 刀 X .B) ：= f，⑸)+ 可 1四 — 〃：『),i ∈ CK
Θ∈Rd×N N	2
i=1
K
s.t.	Ω*,CK = arg min qk	pk,jkθj - ωkk2,
ω∈r4×k,Ck k=ι	j∈ck
(2)
We adopt pk,j = ∣^ and qk = lCkl in this paper, where Ck (k ∈ K) denotes the disjoint cluster k,
and |Ck | is the number of clients that belong to the cluster k. Intriguingly, the inner-level objective
is exactly the classic objective of k-Means clustering (Lloyd, 1982; Arthur & Vassilvitskii, 2006).
We notice that when K = 1, the above objective is equivalent to the overall objective in (T Dinh
et al., 2020), which means that the objective in (T Dinh et al., 2020) can be regarded as a special
case (K = 1) of ours.
4 DESIGN OF CGPFL
In this section, we introduce our proposed CGPFL in detail. The key idea is to dynamically cluster
the clients into K disjoint groups based on their uploaded local model updates, and then develop a
generalized model for each group by aggregating the updates in each clusters. These generalized
models are utilized to guide the training directions of personalized models and transfer fine-grained
generalization to them. Both the personalized models and the group models are trained in parallel,
so we can denote the model parameters in matrix form. The generalized models can be written as
Ωk = [ωι,..., ωk,..., ωκ] ∈ Rd×K, and the corresponding local approximations are Ωi,r =
[ω1,R, . . . , ωi,R, . . . , ωN,R], where R is the number of local iterations and ωi,R, ωk ∈ Rd, ∀i ∈
[N], k ∈ [K]. In this paper, we use capital characters to represent matrices unless stated otherwise.
4.1 CGPFL: ALGORITHM
We design an effective alternating optimization framework to minimize the overall objective in equa-
tion 2. Specifically, the upper-level problem can be decomposed into N separate sub-problems with
fixed generalized models and to be solved on local devices in parallel. Next, we can further set-
tle the inner-level problem to derive the generalized models with fixed personalized models. Since
the solution to the sub-problems of the upper-level objective has been well-explored in recent PFL
methods (T Dinh et al., 2020; Li et al., 2021; Hanzely et al., 2020), we hereby mainly focus on the
inner-level problem. We alternately update the generalized models Ωk and the cluster indicator CK
to obtain the optimal generalized models. We view the personalized models, i.e., ΘI = [θi, ..., θN ],
as private data, and distributionally update the generalized models Ωk on clients with fixed cluster
indicator CK. During each server round, the server conducts k-Means clustering on uploaded local
parameters Ω∖ R to cluster each client into K disjoint groups, and the clustering results CK are re-
arranged to the matrix form as Pt ∈ RN ×K. For example, if client i, i ∈ [N] is clustered into the
group Cj, j ∈ [K] (where Cj, j ∈ [K] are sets, the union Sj∈[K] Cj and intersection Tj∈[K] Cj are
the set [N] and empty set, respectively), the element (Pt)i,j is defined as ∣c1q, or set 0 otherwise. In
this way, the elements of every column in Pt amount to 1, i.e. PiN=1(Pt)i,j = 1, ∀j, t.
When considering the relationship between the consecutive Pt, we can formulate the iterate as
Pt+1 = P tQt, where Qt ∈ RK×K is a square matrix. We can find that to maintain the above
property of Pt (∀t), the matrix Qt must satisfies that:
K
X(Qt)j,k = 1, ∀k, t	and
j=1
K
X(Qt)j,k = 1, ∀j, t.
k=1
(3)
It is noticed that the clustering is based on the latest model parameters Ω∣+1 that depends on Ω∖,
and the latest gradient updates given by clients. Hence, Pt+1 is determined by and only by Pt and
4
Under review as a conference paper at ICLR 2022
Algorithm 1 CGPFL: Personalized Federated Learning with Clustered Generalization
Input: Θ0, ΩK, P 0 ,T, R,S,K,λ,η,α,β.
1:	for t = 0 to T - 1 do
2:	Server sends ΩK to clients according to Pt.
3:	for local device i = 1 to N in parallel do
4:	Initialization: Ωl,o = ΩK Jt.
5:	Local update for the sub-problem of G(Θi, Ωk):
6:	for r = 0 to R - 1 do
7:	for s = 0 to S - 1 do
8:	Update the personalized model: θS+1 = θs — ηVFi(θS).
9:	end for
10:	Local update: ωt,r+ι = ωt,r — βVω⅛G(θi(ωt,r),ωt,r).
11:	end for
12:	end for
13:	Clients send back ωt,R and server conducts (k-means++) clustering on models ΩI,r to obtain Pt+1.
14:	Global aggregation: Ω]1 = ΩK — α(ΩK — ΩI,rPt+1).
15:	end for
16:	return The personalized models ΘIT .
Qt . Then we can consider this global iteration as a discrete-time Markov chain and Qt corresponds
the transition probability matrix.
During each local round, the clients need to first utilize local datasets to solve the regu-
larized optimization objective, i.e., the upper-level objective in equation 2 with fixed ωit,r
to obtain a δ-approximate solution θi (ωit,r). Then, each client is required to calculate the
gradients VωiG(θi(ω1t,r),ω[r) with fixed θi(ωt,r) and update the model using ①匕+] =
ωit,r - βVωiG(θi(ωit,r), ωit,r) , where β is the learning rate and VωiG(θi(ωit,r), ωit,r) =
N2Vrei(ωt,r),ω[r). To reduce the communication overhead, our CGPFL allows the clients to
process several iterations before uploading the latest model parameters to the server. The details of
CGPFL is given in algorithm 1, from which we can summarize the parameters update process as:
Ω— -→→ ΩK J Ωl,0 H ΩI,r→ Ωt+1,	(4)
where Pt+1 = PtQt and JtPt = IK (Jt ∈ RK×N and IK is an identity matrix), ∀t.
4.2 Convergence Analysis
Since the inner-level objective in equation 2 is non-convex, we focus on analyzing the convergence
rate under the smooth case. Based on the parameters update process given in equation 4, we can
write the local updates as:
ωi,r = ωI,0 - βRHI,	⑸
where HI = R PR-I Htt,r and H% = N (。:/ 一 Θ/(。:/)).Based on equation 5 and the update
process in equation 4, we can obtain the global updates as:
ΩtK+1 = (1 — α)ΩK + αΩ^I,Rp2 = ωK [(1 — α)Iκ + αQt] — αβRHl P tQt.	(6)
Definition 1 (L-smooth) (i.e., L-Lipschitz gradient) If a function f satisfies kVf (ω) 一 Vf(ω0)k ≤
Lkω 一 (ω)0k, ∀ω, ω0, we say f is L-smooth.
Assumption 1 (smoothness) The loss functions fi is L-smooth and G(ωk) is LG-smooth, ∀i, k.
Assumption 2 (bounded intra-cluster diversity) The variance of local gradients to the corresponding
generalized models is upper bounded by:
ɪ X kVGi(ωk) — VGk(ωk)k2 ≤ δG, Vk ∈ [K ].
|Ck| i∈Ck
(7)
Assumption 3 (bounded parameters and gradients) The generalized model parameters ΩK and the
gradients VGK (ΩK) are upper bounded by pω and Pg, respectively.
∣∣ΩK∣∣2 ≤ ρΩ	and	IIVGK(ΩK)『≤ Pg, Vt	(8)
5
Under review as a conference paper at ICLR 2022
where p。and Pg are finite non-negative constants.
Proposition 1 (T Dinh et al., 2020) The deviation between the δ-approximate and the optimal solu-
tion is upper bounded by δ. That is:
e[∣∣Θι(Ωl,r) - ΘI(Ωl,r)∣∣2i ≤ Nδ2,∀r,t,
.^
(9)
〜
where ΘI is the δ-approximate solution and ΘI is the matching optimal solution.
Assumption 1 provides typical conditions for convergence analysis, and assumption 2 is common
in analyzing algorithms that are built on SGD. As for assumption 3, the model parameters are
easily bounded by using projection during the model training process, while the gradients can be
bounded with the smooth condition and bounded model parameters. To evaluate the convergence of
the proposed CGPFL, we adopt the technique used in (T Dinh et al., 2020) to define that:
T-1
Eh.∣RGκ(QK)∣∣2i ：= T XEhSMGK(QK)∣∣2i,
t=0
where t* is uniformly sampled from the set {0,1,...,T - 1}.
Theorem 1 (The convergence of CGPFL) Suppose Assumption 1, 2 and 3 hold. If β ≤
2,r(r+1)L2 , ∀R ≥ 1,α ≤ 1, and αo := min n ⅛⅛, q4 αρρΩ, q 4i⅛ α}, where δg is de-
fined as Δg := EhK P3 Gk(ω0) - K £3 Gkk城)] , we have:
•	The convergence of the generalized models:
1 lffhNvr fθt∣ ∖∣∣2i V c(4802(ρΩ∕K) , 80(26(ρΩ∕K)LGδ2)1 , 52δ2∖
KElIMGK(OK并 J ≤O(	α2T	+ —√NKRT— + KN)
•	The convergence of the personalized models:
N2
NXEh∣∣θI - OKJt ∣∣ i ≤o(KKEhIRGK(CK)∣∣ D + o(λ + δ2).
i=1
Remark 1 Theorem 1 shows that the proposed CGPFL can achieve a convergence rate of
O11NKNRT), which is O(√K) times faster than most of the state-of-the-art works (Karim-
ireddy et al., 2020; Deng et al., 2020; Reddi et al., 2020) achieved (i.e., O(1∕√NRT)) in non-
convex FL setting. The detailed proof of convergence is given in the Appendix of this paper.
4.3 Generalization Error
We analyse the generalization error of CGPFL in this section. Before starting the analysis, we first
introduce two important definitions as follows.
Definition 2 (Complexity) Let H be a hypothesis class (correspanding to ω ∈ Rd in neural net-
work), and |D| be the size of dataset D, the complexity of H can be expressed by the maximum
disagreement between two hypotheses on a dataset D:
λH(D) = SUp ɪ X ∣hι(x) - h2(x)∣.	(10)
h1,h2∈H |D| (x,y)∈D
Definition 3 (Label-discrepancy) Consider a hypothesis class H, the label-discrepancy between two
data distributions D1 and D2 is given by:
discH(D1,D2) = sUp |LD1 (h) - LD2 (h)|,	(11)
h∈H
where LD (h) = E(x,y)∈D [l (h(x), y)].
Theorem 2 (The generalization error of CGPFL) When Assumption 1 is satisfied, with probability
at least 1 - δ, the following holds:
N
X ≡i {Ln(K) - mn 版(叫
i=1
≤ 2√iom^+JdK log em+X m 回入似。,)+凄皿,力,))+@+刍缶*®*,。*； K),
i=1
6
Under review as a conference paper at ICLR 2022
where B is a positive constant with ILD (hi) -LD (h2)∣ ≤ Bλγ(D), ∀hι, h2 ∈H. Besides, h * =
argmin {LDi (h(θi)) + ιιθi- ω*k2} and cost(θ*, ω*; K) = PN=I m mink∈[κ] kθ* -ωkk2.
θi	i
Remark 2 Theorem 2 gives the generalization error bound of CGPFL. When K = 1, it yields
the error bound of PFL with single global model (Li et al., 2021; T Dinh et al., 2020; Hanzely &
Richtarik, 2020; Hanzely et al., 2020). As the number of clusters increases, the second terms become
larger, while the last term get smaller. Hence, our CGPFL can alwalys reach better personalization-
generalization trade-off by adjusting the number of clusters K, and further achieve higher accuracy
than the existing PFL methods. The detailed proof of generalization error is given in the Appendix
of this paper.
4.4 CGPFL-Heur: HEURISTIC IMPROVEMENT OF CGPFL
As discussed, Theorem 2 indicates that there exists a optimal K* (K* ∈ [K]) to achieve the minimal
generalization error that corresponds to the highest model accuracy. Theoretically, the optimal K*
can be obtained by minimizing the generalization bound in Theorem 2. We can find that the first and
the third term have no relationship with the clustering, that is, they are irrelevant to K. Therefore,
we can obtain an optimal K* by minimizing the following expression:
e(K) :=
dK log em + μ ∙ cost(Θ*, Ω*; K),
md
(12)
where μ is a hyper-parameter which is induced by the unknown constant L. The above objective
can be solved in the server along with the clustering. In the down-to-earth experiments, we notice
that the cluster structure can be learned efficiently in the first few rounds. Based on this observation,
We believe that CGPFL-Heur can efficiently figure out a near-optimal solution K by operating the
solver of equation 12 only in the first few rounds (in the experimental part, we only operate the solver
in the first global round), and after that, the obtained K will no longer be updated. In this way,
CGPFL-Heur can reach a near-optimal trade-off (corresponding to the near-optimal K) between
generalization and personalization with negligible additional computation in the server. Moreover,
in view of the fact that we only need to operate the solver in the first few rounds, CGPFL-Heur can
retain the same convergence rate as CGPFL.
5	Experiments
5.1	Experimental Setup
Dataset Setup: Three datasets including MNIST (LeCun et al., 1998), CIFAR10 (Krizhevsky et al.,
2009), and Fashion-MNIST (FMNIST) (Xiao et al., 2017) are used in our experiments. To generate
Non-I.I.D. datasets for each client, we split the whole dataset as follows. 1) MNIST: we distribute the
train-set containing 60, 000 digital instances into 40 clients, and each of them is only provided with
2 classes out of total 10. The number of instances obtained by each client is randomly chosen from
the range of [400, 5000], of which 75% are used for training and the remaining 25% for testing. 2)
CIFAR10: We distribute the whole dataset containing 60, 000 instances into 40 clients, and each of
them is also provided with 2 classes out of total 10. The number of instances obtained by each client
is randomly chosen from the range of [400, 5000]. The train/test remains 75%/25%. 3) Fashion-
MNIST: a more challenging replacement of MNIST, the Non-I.I.D. splitting is the same as MNIST.
Competitors: We compare our CGPFL and CGPFL-Heur with 7 state-of-the-art works: 1 tradi-
tional FL method, FedAvg (McMahan et al., 2017); 1 cluster-based FL method, IFCA (Ghosh et al.,
2020); and 5 most recent PFL models, APFL (Deng et al., 2020), Per-FedAvg (Fallah et al., 2020),
L2SGD (Hanzely & Richtarik, 2020), PFedMe (T Dinh et al., 2020), and Ditto (Li et al., 2021).
Model Architectures: 1) For the non-convex case, we apply a neural network with one hidden
layer of size 128 and a softmax layer at the end (DNN) for evaluation; 2) For strongly convex case,
we use a l2-regularized multinomial logistic regression model (MLR) with the softmax and cross-
entropy loss, in line with (T Dinh et al., 2020). Specifically, we apply a CNN that has two convolu-
tional layers and two fully connected layers for the CIFAR10. All competitors and our CGPFL and
CGPFL-Heur are based on the same configuration and fine-tuned to their best performance.
7
Under review as a conference paper at ICLR 2022
Table 1: Comparison of test accuracy. We set N = 40, α = 1, λ = 12, S = 5, lr = 0.005 and T = 200
for MNIST and Fashion-MNIST (FMNIST), and T = 300, lr = 0.03 for CIFAR10, Where lr denotes the
learning rate.
Method	MNIST		FMNIST		CIFAR10
	MLR	DNN	MLR	DNN	CNN
FedAvg (McMahan et al., 2017)	88.63	91.05	82.44	83.45	46.34
IFCA (K = 4) (Ghosh et al., 2020)	95.27	96.19	91.55	92.56	60.22
L2SGD (Hanzely & Richtarik, 2020)	89.46	92.48	88.59	90.64	58.68
APFL (Deng et al., 2020)	92.69	95.59	92.60	93.76	72.12
pFedMe (PM) (T Dinh et al., 2020)	91.90	92.20	85.49	86.87	68.88
Per-FedAvg (HF) (Fallah et al., 2020)	92.44	93.54	87.17	87.57	71.46
Ditto (Li et al., 2021)	89.96	92.85	88.62	90.56	69.56
CGPFL (K = 4) (Ours)	95.65	96.55	92.65	93.56	72.78
CGPFL-Heur (Ours)	97.41	98.03	95.18	96.00	74.75
5.2 OVERALL PERFORMANCE OF CGPFL AND CGPFL-Heur
The comprehensive comparison results of our CGPFL and CGPFL-Heur are shoWn in Table 1. It can
be observed that our methods outperform the competitors With large margins for both non-convex
and convex cases on all datasets, even if IFCA Works With a good initialization. Besides, although
We only provide the proof of convergence rate under non-convex case, as shoWn in Figure 1 and
Figure 2, the extensive experiments further demonstrate that our methods constantly obtain better
performance against multiple state-of-the-art PFL metohds (pFedMe, Ditto, and Per-FedAvg) With
faster convergence rate under both strongly-convex and non-convex cases. Specifically, the figures
in Figure 1 shoW the results for MNIST dataset on MLR and DNN model, While the figures in
Figure 2 give the results for Fashion-MNIST dataset on MLR and DNN model.
(a) acc-MNIST-MLR
(b) acc-MNIST-DNN
(c) loss-MNIST-MLR
(d) loss-MNIST-DNN
Figure 1: Performance on MNIST for different K With N = 40, α = 1, λ = 12, R = 10, S = 5.
Accuracy: FMNISTM LR____________ _________________________Accuracy: FMNIST-DNN_____________ ___________________________LOSs: FMNISTM LR______________ ___________________________LoSs: FMNISTDNN
(a) acc-FMNIST-MLR
(b) acc-FMNIST-DNN (c) loss-FMNIST-MLR	(d) loss-FMNIST-DNN
Figure 2: Performance on FMNIST for different K with N = 40, α = 1, λ = 12, R = 10, S = 5.
5.3	FURTHER EVALUATION ON CGPFL-Heur
To further evaluate the performance of CGPFL-Heur, on the one hand, we conduct the CGPFL
training with different number of clusters (i.e., K) varying form 1 to N/2 on MINST and FMNIST,
respectively. Specifically, we set the maximal value of K no more than N/2 to avoid overfitting. By
collating the model accuracy with different K, we can find out the optimal K which corresponds
to the optimal personalization-generalization trade-off in CGPFL. The results are demonstrated in
Figure 3(a).On the other hand, We conduct the CGPFL-Heur training With an appropriate μ and
keep other parameters same as that of the above evaluation. As shown in Figure 3(a), we under-
line the results of CGPFL-Heur using red-star points. Besides, We make comparisons betWeen the
performance of a state-of-the-art PFL algorithm, pFedMe (T Dinh et al., 2020) With our proposed
CGPFL and CGPFL-Heur in Figure 3(b). The results in Figure 3(a) and Figure 3(b) demonstrate
8
Under review as a conference paper at ICLR 2022
Figure 3: Further evaluation on CGPFL-Heur on MNIST and FMNIST datasets
that our designed heuristic algorithm CGPFL-Heur can effectively reach a near-optimal trade-off
and consequently achieve the near-optimal model accuracy.
5.4	THE EFFECTS OF λ
As mentioned that the hyper-parameter λ can balance the weight of personalization and generaliza-
tion in several state-of-the-art PFL algorithms (T Dinh et al., 2020; Hanzely et al., 2020; Li et al.,
2021), we also conduct experiments to compare the performance of our CGPFL and CGPFL-Heur
with a typical PFL algorithm, pFedMe (T Dinh et al., 2020), on different values of λ. Specifically, the
range of λ is properly chosen to avoid that divergence occurs in pFedMe. The experimental results
in Table 2 show that our methods can constantly achieve better performance than pFedMe despite λ
varies, which demonstrates that CGPFL can constantly reach better personalization-generalization
trade-off against the state-of-the-art PFL methods.
Table 2: Comparisons with various λ. We set N = 40, α = 1, R = 10, S = 5, lr = 0.005 and T = 200 for
MNIST and Fashion-MNIST (FMNIST), where lr denotes the learning rate.
	λ	11	12	13	14	15	16	17	18	19
	pFedMe (PM)	91.46	91.90	92.19	92.54	92.80	93.00	93.15	93.16	93.04
MNIST-MLR	CGPFL (K=2)	93.43	93.34	93.62	93.88	94.16	93.69	93.52	93.52	93.31
	CGPFL (K=4)	95.49	95.65	95.19	95.47	95.60	95.77	96.49	94.85	94.53
	CGPFL-Heur	97.46	97.41	96.27	96.32	96.34	96.33	96.32	96.33	96.25
	λ	9	10	11	12	13	14	15	16	17
	pFedMe (PM)	91.21	91.54	91.86	92.21	92.43	92.79	93.05	93.30	93.24
MNIST-DNN	CGPFL (K=2)	94.11	94.42	94.71	93.90	94.14	94.36	94.49	93.34	93.36
	CGPFL (K=4)	96.17	96.37	96.57	96.55	95.87	95.99	96.01	95.45	95.49
	CGPFL-Heur	97.69	97.86	98.00	98.03	97.95	97.96	98.20	98.14	98.16
	λ	9	10	11	12	13	14	15	16	17
	pFedMe (PM)	85.03	85.26	85.42	85.49	85.49	85.28	85.16	84.76	84.22
FMNIST-MLR	CGPFL (K=2)	90.29	87.70	87.93	88.00	87.72	87.53	87.65	86.94	85.19
	CGPFL (K=4)	92.50	92.84	92.94	92.65	92.63	92.44	92.42	92.17	92.20
	CGPFL-Heur	95.46	95.44	95.45	95.36	94.61	94.40	94.35	94.41	94.19
	λ	7	8	9	10	11	12	13	14	15
	pFedMe (PM)	84.65	85.20	85.86	86.28	86.70	86.87	87.09	87.10	86.66
FMNIST-DNN	CGPFL (K=2)	87.69	88.15	88.72	89.13	89.59	89.75	91.15	89.25	88.93
	CGPFL (K=4)	92.26	92.89	92.71	92.86	93.03	93.56	93.21	93.44	92.83
	CGPFL-Heur	95.60	95.73	95.84	95.94	95.98	96.00	95.98	95.95	95.83
6	Conclusion
In this paper, we propose a novel personalized federated learning framework, dubbed CGPFL, to
handle the challenge of statistical heterogeneity (Non-I.I.D.) in the federated setting. To the best of
our knowledge, we are the first to propose the concept of clustered generalization (CG) for person-
alized federated learning and further formulate it to a bi-level optimization problem that is solved
effectively. Our method provides fine-grained generalization for personalized models which can
prompt higher test accuracy and facilitate faster model convergence. Experimental results on real-
world datasets demonstrate the effectiveness of our method over the state-of-the-art works.
9
Under review as a conference paper at ICLR 2022
References
Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and Sunav Choudhary. Fed-
erated learning with personalization layers. arXiv preprint arXiv:1912.00818, 2019.
Yossi Arjevani, Ohad Shamir, and Nathan Srebro. A tight convergence analysis for stochastic gra-
dient descent with delayed updates. In Algorithmic Learning Theory,pp.111-132. PMLR, 2020.
David Arthur and Sergei Vassilvitskii. k-means++: The advantages of careful seeding. Technical
report, Stanford, 2006.
Christopher Briggs, Zhong Fan, and Peter Andras. Federated learning with hierarchical clustering
of local updates to improve training on non-iid data. In 2020 International Joint Conference on
Neural Networks (IJCNN),pp.1-9.IEEE, 2020.
Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Adaptive personalized federated
learning. arXiv preprint arXiv:2003.13461, 2020.
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning with the-
oretical guarantees: A model-agnostic meta-learning approach. Advances in Neural Information
Processing Systems, 33, 2020.
Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation
of deep networks. In International Conference on Machine Learning, pp. 1126-1135. PMLR,
2017.
Avishek Ghosh, Justin Hong, Dong Yin, and Kannan Ramchandran. Robust federated learning in a
heterogeneous environment. arXiv preprint arXiv:1906.06629, 2019.
Avishek Ghosh, Jichan Chung, Dong Yin, and Kannan Ramchandran. An efficient framework for
clustered federated learning. Advances in Neural Information Processing Systems, 33, 2020.
Filip Hanzely and Peter Richtarik. Federated learning of a mixture of global and local models. arXiv
preprint arXiv:2002.05516, 2020.
Filip Hanzely, Slavomlr Hanzely, Samuel Horvath, and Peter Richtarik. Lower bounds and opti-
mal algorithms for personalized federated learning. Advances in Neural Information Processing
Systems, 33, 2020.
Kevin Hsieh, Amar Phanishayee, Onur Mutlu, and Phillip Gibbons. The non-iid data quagmire of
decentralized machine learning. In International Conference on Machine Learning, pp. 4387-
4398. PMLR, 2020.
Yihan Jiang, Jakub Konecny, Keith Rush, and Sreeram Kannan. Improving federated learning per-
sonalization via model agnostic meta learning. arXiv preprint arXiv:1909.12488, 2019.
Peter Kairouz, H Brendan McMahan, Brendan Avent, AUrelien Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances
and open problems in federated learning. arXiv preprint arXiv:1912.04977, 2019.
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In
International Conference on Machine Learning, pp. 5132-5143. PMLR, 2020.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
2009.
Viraj Kulkarni, Milind Kulkarni, and Aniruddha Pant. Survey of personalization techniques for
federated learning. In 2020 Fourth World Conference on Smart Trends in Systems, Security and
Sustainability (WorldS4), pp. 794-797. IEEE, 2020.
Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
10
Under review as a conference paper at ICLR 2022
Daliang Li and Junpu Wang. Fedmd: Heterogenous federated learning via model distillation. arXiv
preprint arXiv:1910.03581, 2019.
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges,
methods, and future directions. IEEE Signal Processing Magazine, 37(3):50-60, 2020.
Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. Ditto: Fair and robust federated
learning through personalization. In International Conference on Machine Learning, pp. 6357-
6368. PMLR, 2021.
Stuart Lloyd. Least squares quantization in pcm. IEEE transactions on information theory, 28(2):
129-137, 1982.
Lingjuan Lyu, Han Yu, and Qiang Yang. Threats to federated learning: A survey. arXiv preprint
arXiv:2003.02133, 2020.
Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. Three approaches for
personalization with applications to federated learning. arXiv preprint arXiv:2002.10619, 2020.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial intelli-
gence and statistics, pp. 1273-1282. PMLR, 2017.
Sashank J Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konecny,
Sanjiv Kumar, and Hugh Brendan McMahan. Adaptive federated optimization. In International
Conference on Learning Representations, 2020.
Felix Sattler, Klaus-Robert Muller, and Wojciech Samek. Clustered federated learning: Model-
agnostic distributed multitask optimization under privacy constraints. IEEE Transactions on Neu-
ral Networks and Learning Systems, 2020.
Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet Talwalkar. Federated multi-task
learning. In Proceedings of the 31st International Conference on Neural Information Processing
Systems, pp. 4427-4437, 2017.
Canh T Dinh, Nguyen Tran, and Tuan Dung Nguyen. Personalized federated learning with moreau
envelopes. Advances in Neural Information Processing Systems, 33, 2020.
Alysa Ziying Tan, Han Yu, Lizhen Cui, and Qiang Yang. Towards personalized federated learning.
arXiv preprint arXiv:2103.00710, 2021.
Zirui Wang, Zihang Dai, Barnabas Poczos, and Jaime Carbonell. Characterizing and avoiding neg-
ative transfer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, pp. 11293-11302, 2019.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmark-
ing machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.
Ligeng Zhu and Song Han. Deep leakage from gradients. In Federated learning, pp. 17-31.
Springer, 2020.
11
Under review as a conference paper at ICLR 2022
A Analysis of Convergence
A. 1 The Iterates of Model Parameters
The local update is given as follows:
ωt,r+1 = ωt,r - βVGi(ωt,r) = ωt,r
2t	t
-β N (ωi,r - θi(ωi,r )),
X----------{-
:=hit,r
}
Suming the local iterats, we can get
R-1	R-1
β X hit,r = X(ωit,r - ωit,r+1) = ωit,0 - ωit,R.
r=0	r=0
According to the algorithm, we have
ωK+1 - ωK = -α(CK - ωI,rp t+1).
Therefore, we can get the model parameters of the global models as follows:
Ωt+1 = (1 - α)Ωtκ + αΩl,RPt+1
R-1
= (I- q)ωK + Q(ωI,0 - βR R X HI,r)Pt+1
r=0
'----{---}
:=HIt
=(1 - α)ΩK + αΩtκ JtPt+1 - αβRHItPt+1
x{z}
:=^
=(1 - α)Ωtκ + αΩtκ JtPtQt - &H；Pt+1
=(1 - α)ΩK + αΩtκQt - &H；Pt+1
=ΩK [(1 - α)Iκ + αQt] - &H；PtQt
That is
ΩK - ΩK+1 = αΩK(Iκ - Qt) + αHlPt+1.	(13)
It’s noted that
Gk(ωk) ：= [Gκ(ΩKW，
where [Gκ(ΩK)]k denotes the k-th element of the row vector GK(ΩK).
A.2 Review of Useful Propositions and Lemmas
Assumption 1
∣∣ΩK∣∣2 ≤ ρΩ	and	IIVGK(ΩK)∣∣2 ≤ ρg,
where both ρΩ and Pg are finite non-negative constants.
12
Under review as a conference paper at ICLR 2022
A.3 Convergence
Proof:
KK
E XGk(ωkt+1)-XGk(ωkt)
k=1	k=1
KK
e[X[Gi(ΩK+1)Pt+1]k - X[Gi(ΩK)Pt]k]
k=1	k=1
K
E[X[Gi(ΩK+1)Pt+1 - GI(ΩK)Pt]k]
k=1
KK
E[X [(GI(ΩK+1) - GI(Ωκ))Pt]k + X [GI(ΩK+1)Pt(Qt - Ik)]J
k=1	k=1
≤ EhyGK(ΩK), ΩK+1 - ΩK〉] + L2GE[∣∣ΩK+1 - ΩK∣∣[
X---------------------------------------------------
{z
A
∣+ e[ X[GI (ΩK1F(Qt - Ik )]J
' ^1--------------------
{z
B
}
where we assume that LG := maxk∈[K] LGk. We first deal with the part A in above inequation.
According to the above derivation, we have
a = Eh〈VGk(ΩK), Ωt+1 - ΩK〉] + L2Ge[∣∣ΩK^ - ΩK∣∣2]
=-αE[(VGκ(ΩK),^(ΩK - ΩK+1) - VGk(ωK) + VGK(ωK))] + 与e]∣∣ωK^ - ΩK∣∣2]
=-αE[∣∣VGκ(ΩK)∣∣2] - &e[(VGk(ΩK),ɪ(ΩK - Ω^) - VGK(ΩK川
+ ^2G Eh^K+1 - ωk∣∣2]
α	α1	2
≤-αE[∣VGκ(ΩK)∣∣[ + 2e]∣∣VGk(ΩK)∣∣2] + 2e[∣∣α∙(ΩK - ΩK+1) -VGK(ΩK)∣∣ ]
+ ^2G Eh^K+1 - ωk∣∣2]
=-2EhIIVGK(ΩK)∣∣2] + -GEEh∣∣ωK+1 -ωK∣∣2] + 2Eh∣∣α^(OK - ωK+1 )- vgk(ΩK)∣∣ ]
X-----------------------------------' X----------------------------'
^SZ
A2
Ai
Plugging equation equation 13 into above inequation, we can get
Al = l2ge["K(IK - Qt) + αHIPt+1∣∣2i
=L2GE[∣∣αΩK(IK - Qt) + αHIPt+1 - aVGI(ΩI,0)Pt+1 + αVGI(ΩI,o)PtQt∣∣2i
≤ 3α2LGe[∣∣ωK(IK - Qt)∣∣2i + 3a2LGE[∣∣VGκ(ωK)Qt∣∖2]
+ 3α2LGE[∣∣(HI -VGI(ΩI,0))Pt+1∣∣2]
and
A2 = ^ e[∣∣ ^ΩK (IK - Qt) + HI Pt+1 - VGI (ΩI,0)Pt+1 + VGI (ΩI,o)P tQt - VGK (噩)∣∣2]
≤ 3αe[∣∣ωK(IK-Qt)∣∣2] + 3αE[∣∣(Ht - VGI(ΩI,0))Pt+1∣∣2]
+ ɪ EhIIVGK (ΩK)(IK - Qt)∣∣2]
13
Under review as a conference paper at ICLR 2022
Proposition 1 For any vector xi ∈ Rd, i = 1, 2, . . . , M, according to Jensen’s inequality, we have
XMxi2≤MXM kxik2.
i=1	i=1
And because the real function 夕(y) = y2,y ∈ R is convex, if some constants satisfy that λi ≥
0, ∀i = 1, 2, . . . , M, and PiM=1 λi = 1, we have
M	2M
Xλiyi	≤Xλikyik2.
i=1	i=1
Lemma 1 Wecan obtain that EhX P t+1 2i ≤ EhX 2 i, and EhY Qt2i ≤ EhY 2i for any
matrices X ∈ Rd×N and Y ∈ Rd×K, as long as the Pt+1 and Qt satisfy that PiN=1 Pit,+k 1 =
1, PjK=1 Qtj,k = 1∀k,t, and PkK=1 Qtj,k = 1, ∀j, t. Especialy in this paper, we have Pit,+k 1 =
I ∣Ck∣,
0,
Proof:
if i ∈ Ck
otherwise
dK
EhXPt+12i =XX(XPt+1)l,k2
l=1 k=1
dK N	2
= XXhXXl,iPit,+k1i2
dKN	dNK
≤XXXXl,i2Pit,+k1=XXXXl,i2Pit,+k1
l=1 k=1 i=1	l=1 i=1 k=1
dN	K
= XXXl,i2XPit,+k1
dN
≤ X X Xl,i2 = EkXk2
l=1 i=1
Similiarly,
dK
EkYQtk2 =XX(YQt)l,k2
l=1 k=1
dK K	2
=XXhXYl,jQtj,ki2
l=1 k=1 j=1
dKK	dKK
≤XXXYl,j2Qtj,k=XXXYl,j2Qtj,k
l=1 k=1 j=1	l=1 k=1 j=1
dN	K
= XXYl,j2XQtj,k
dN
=XXYl,j2 = EkY k2
[Httι -^Gi(ΩI,0)∣∣[
In the next part, we will first cope with E
14
Under review as a conference paper at ICLR 2022
e[∣∣(G∣-NFI (ΩI,o))P t+1∣∣2]
r 1 R-1	2-|
=E IlRXMLyGIgI,o))pt+ι∣∣
L r=0	」
R-1
≤ 五 X E[ I I (HI,r-VGI ⑼,0))P t+1I∣2]
r=0
R-1
=五 X e[∣∣ (HI,r - VGI(ΩI,r) + VGI(ΩI,r) - VGI(ΩI,0))Pt+1∣∣2]
r=0
2 R-1	2 R-1
≤ 互 X e[∣∣ WI,r- VGI (% ))p t+1I∣2] + 互 X e[∣∣ (VGI (%) - VGI (ωI,0))p t+1 II2]
r=0
r=0
2 R-1	2 R-1
≤ 互 X E[∣∣HI,r - VGI(ΩI,r)∣∣2] + - X E[II (VGI(ΩI,r) - VGI(ΩI,0))Pt+1∣∣2]
r=0	r=0
≤ 2 X E[ I I N(S ZI,r ) - 8(% )) I I 2] +2⅞
r=0
≤ +2 + # X e[ I I (%-ωI,0)p t+1I∣2]
r=0
2 R-1
-X E[ I I (%- ωI,0)p t+1I∣2 ]
r=0
Because
e[ I I (%- ωI,0)p t+1I∣2]
=e[ I I (ΩI,r-1- ΩI,0 - βHI,r-1)Pt+1∣∣2]
=e[ I I (ΩI,r-1 - ΩI,0 - βVGI(ΩI,0) + βVGI(ΩI,0) - βHI,r-1)Pt+11∣2]
≤ (1 + ⅛e[ I I (ΩI,r-1 - ΩI,0 - βVGI(ΩI,0))Pt+1∣∣2]
+ (1 + R)β2e[ I I (VGI(ΩI,0) - Ht,r-1)Pt+1∣∣2]
≤ (1 + ɪ)(l + 2Rr)e[ I I (ΩI,r-1 - ΩI,0)Pt+1∣∣2] +(1 + ɪ)(l + 2R)β2E[∣∣VGI(ΩI,0)PtQt∣∣2]
+ β2(1 + R) (Nδ2 + 2Lg2e[I I (ΩI,r-1 - ΩI,0)Pt+1 II2])
= (1 + R)(1 + 2R + 2(1 + R)β2LG 2)e[ I I (ΩI,r-1 - ΩI,0)P t+1∣∣2]
+ (1 + R)(1 + 2R)β2E[ I I VGK (ΩK )Qt∣∣2] + 8(I +R)β2 δ2
≤ (1+R)2 e[ i i (%-1-ωi,0)p t+1∣ι2 ]
+ (1 + R)(1 + 2R)β2E[ I I VGk (ΩK) ∣ ∣ 2] + 8(I +R)β2 δ2
with β2 ≤ 4r(1+R)Lg2, which implies that 2(1 + R)β2Lg2 ≤ +.By unrolling the above result
recursively, we can get
15
Under review as a conference paper at ICLR 2022
E[||(%- ωI,o)p t+^∣2]
≤ {(1 + RR)(1 + 2R)β2e[∣∣vGk(ΩK)∣∣2i + 8(1 +Rββδ20X (1 + R)2r
r=o
n f (↑	I	1 Wi	I oDλzo2κ h∣∣∖7C	Ωtt	)∣∣2i * 8(1 + R)β2	广 O (1 + RR)2(r	1)	- 1
≤ V1 + R)(1 + 2R)β EIJIVGK(ωk)∣ J +--N----δ ʃ (1 + 1 )2 - 1
n f (↑	I	1 Wi	I 2E>h∣^ h∣∣∖7C	Ωtt	)∣∣2i * 8(1 + R)β2	δ2θ (1 + RR)2(r	1)
≤ V1 + R)(1 + 2R)β e[∣∣vgk(ωk川]+ ----N----δ ʃ (1 + 1 )2 - 1
and then
EbI(Ht-VGI (QI,。))Pt+1∣∣2]
≤ Nδ+2LG2 X 却也厂 ωi,o)p t+1∣2i
r=0
Q	9∕θ2 t 2，	1	r	Cr 0/1 _|_ R- R R-1 门 _| 1、2(r —1)
≤ Wδ2+1 {(1+R)(1+2R)Eh∣∣vGκ gκ )∣∣ i+-lNj δ2o X ((1+R12 - 1
r=0	R
8 2	2β2LG2 {	1	密 FhIIO )∣∣2 i , 8(1 + R)⑶ (1 + R )2R - 1
≤ Nδ +	V1 + R)(1 + 2R)E[∣∣VGK(ωk)∣∣ ] +	δ) (1 + RR)2 - 1
“8 2 I 2β2LG2 (∩	1 M] , cp、IFh∣∣v7λ, (Ct ∖∣∣2i I 8(1 + R)⑶ e2 - 1
≤N +	V1 + R)(1 + 2R)E[∣∣VGK(ωk)∣∣ ]十δ )(1 + R)2- 1
≤ N+2β2LG- {(1+R)(1+2R)EhIIVGK MK )∣∣2i+*) δ2o 工
=Nδ + 128T + ReNGG 2δ +16(1 + R)β 2LG2EhII VGK (ωK )∣∣2i
≤ Nδ2 + 128RNLG2δ2 + 32Rβ2LG2E[∣∣VGK(ΩK)∣∣2i
Therefore, we can obtain
A = - α^ e[∣∣VGk (ΩK )∣∣2i + Ai + A2
≤ (- ^ + 3α2LG)e[∣∣VGk(ΩK)∣∣2i + (3α2LG + 3a)E[∣∣(HI - VGI(ΩI,o))Pt+1∣∣2i
+ (3∖£G + ^2^) EhIICK (IK - Qt)∣∣2i +ɪ EhIIVGK (CK )(IK - Qt)∣∣2i
X----------------} X--------------------------}
^Z
B1
^Z
B2
16
Under review as a conference paper at ICLR 2022
That is,
A ≤ -a^(1 - 3aLa)E[∣∣VGκ(ΩK)『]+ 32^(1 + &乙&回||(用-VGI闾,0)0+1『]
+3a2
C	3&C
Bi + ɪ B2
1
α
≤ -2(1 一 3CLg)e[∣∣VGk(ΩK)∣∣2i + ^2- (LG + C^)bi + ɪB2
+^a(I+αLG){Nδ2+
128Rβ2LG2δ2
+ 32Rβ2LG2E[„VGκ (ΩK )『
-a (1 - 3^Lg - 96Rβ2LG2(1 + aLG))E[∣∣VGκ (ΩK )『]
+ 3a2 (LG + ^ )Bi + 3c^ B2 +
192α3δ2LG2(1 + &Lg) + 12a(1 + 6Lg)6：
NRα2
C、(1 - 3CLg - 96Rβ2LG2(1 + CLg)), e[∣∣VGk(ΩK)∣∣2]
&	'-----------------{-----------------} L	」
≥ 2 when β , α and LG satisfy β2Lg2≤ 臬(IR2 and α≤1
+ 3a2 (LG + ^ )B1 + 3c^ B2 +
192α3δ2LG2(1 + &Lg) + 12a(1 + 6Lg)6：
NRα2
≤ - 4 EhlIVGK (ωK )『]+
192a3δ2LG2(1 + &Lg) + 12a(1 + 0刀3)6：
NRα2
3a2 / 一	r3a ŋ
+	(c^Lg + 1)Bi + —B2
2a	2
≤- a e[∣∣VGk (ΩK )∣∣2i
2a2 -	36 —
+ -ɪ B1 + τ B2 +
3ɑ
208a3δ2LG2
NRa2+
13aδ2
N
N
N
—
N
2
2
2
N
with β2LG2 ≤ 416R2 ≤ 8R2 ≤ 4R(⅛R), ∀r ≥ 1 and a ≤ 1∙
Because of the above conditions we have
and
Therefore,
c^Lg = RaeLG ≤	, R
√416R2
96R	1
96Re LG (1 + aLG) ≤ 416R2 (1 + 12)
1
≤
一 12,
1
4R
1, ∀R ≥ 1.
4, 一
(14)
(15)
(1 — 3^Lg — 96Rβ?Lg2(1 + aLg)) ≥ 1 —-
-ɪ ≥ 1.
4R — 2
≤
Lemma 2 With Assumption 1 held, we can get
(1)
1 T-1
Tiimo T X EMK (Qt- Iκ )∣ι2]
t=0 |
^{z
B1
= 0 ⇔ lim ∣∣QT - IK ∣∣ = 0
}
and
T-1
T X e[∣∣ωK (Qt- IK )∣∣2i =O( T).
T t=0	T
1 T-1
⑵	Tlimo T X EbIVGK(ΩK)(Qt-IK)∣∣2]
t=0 |
{z^
B2
= 0 ⇔ lim ∣∣QT - IK ∣∣ = 0
}
17
Under review as a conference paper at ICLR 2022
and
T-1
T X EhIlVGK (ΩK)(Qt-IK )『i = O( T).
T t=0	T
Proof: (1)
1a) ” =⇒ ”:	We have
1 T-1
Tι→m∞ T X e[i∣ωk (Qt-IK )∣2] =0.
∞ T t=0
Assuming that limT →∞ iiQT - IK ii2 6= 0, we have
∃j, k ∈ [K], Tlimo I (QT - IK)j,k∣ = 0.
That is
∀T, ∃jτ, kτ ∈ [K] and δτ > 0, ∣ (Qt - IK)jτ,kJ > δτ.
Because We can always find some ΩK making that
KK
∣ X(CK )ι,j (Qt-IK j,k∣ = X I(CK )ι,j (Qt-IK )j,k∣,
j=1	j=1
we can get
τ-1
∣X∣∣ωK (Qt - IK )∣∣2∣
t=0
τ-1 d K
=XXX [ΩK (Qt- IK )]j,fc 2
t=0 l=1 k=1
τ-1 d K K	2
=XXX[X(ΩK )ι,j (Qt - IK )j,k]
t=0 l=1 k=1 j=1
τ-1 d K K
≥ XXX[X(ΩK)ι,j2(Qt-IK)j,k2]
t=0 l=1 k=1 j=1
τ-1 d
≥ XX (ΩK)ι,jt2(Qt- IK)jt,kt2
τ-1
≥ X : δΩmax δt
t=0
where δΩmaχ2 = mint∈[τ] maxι∈[d] {(ΩK)ι,jj} and δΩmax2 > 0 (Otherwise, (ΩK)ι,jt = 0,∀l.
Thus, the jt-th global model is invalid). Then we have
τ-1	τ-1
T X EIjICK (Qt- IK )∣∣[ ≥ T X δΩmax IISt > 0.
t=0	t=0
That is
τ-1	τ-1
∀T, ∃δ= T X δΩmaχ2δt2 > 0, T X e[∣∣ΩK (Qt - IK )∣∣2] >δ,
t=0	t=0
which means that
1 τ -1
TmT X e[i∣ωk (Qt - IK )∣∣[ =0.
→o T t=0
18
Under review as a conference paper at ICLR 2022
It contradicts the assumption. The proof of ” =⇒ ” ends.
1b) " b ”:
We have
Tl→im∞ QT - IK 2 = 0,
which indicates that
∀j, k and ε0 > 0, ∃T0 > 0, making ∀T > T0, (QT - IK)j,k < ε0 .
We know that
Iim T1 =0, ∀Tι,
T→∞ T
which means that
∀ει > 0, ∃T1 22, making ∀T > T⅛, T0 + 1 < ε>
When T3 = max{T0 , T2 }, ∀T > T3, we have
T0
T X∣∣ΩK(Qt- Ik)『
T t=0
T0 d K K
T XXX[X(ΩK)ι,j(Qt- Ik)j,k]
t=0 l=1 k=1 j=1
T0	d K K	K	2
T XXX [X (ΩK)ι,j(Qt)j,k - X (ΩK)ι,j(IK)j,k]
t=0 l=1 k=1 j=1	j=1
≤
T0	d K K	2 K	2
T XXX{[X (ΩK )ι,j (Qt)j,k] + [X (ΩK )ι,j (IK )j,k] }
t=0 l=1 k=1	j=1
j=1
T0 d K K
≤ T XXX{X (ΩK )ι,j 2(Qt)j,k + (ΩK )ι,k2}
t=0 l=1 k=1 j=1
T0 d K	K	T -1 d K
=T XXX (ΩK )ι,j2 X(Qt)j,k + T XXX (ΩK )ι,k2
t=0 l=1 j=1	k=1	t=0 l=1 k=1
T0 d K
≤ T XXX (ΩK )ι,k2
t=0 l=1 k=1
≤ 4ρΩ(TO+1)
≤ T
So, we can get
T-1
IT X IIωk (Qt-IK )∣∣2∣
t=0
1 T0	1 T-1
=TX ∣∣ωk(Qt-Iκ)∣∣2 + T X i∣ωk(Qt-IK)∣∣2
t=0	t=T0+1
2	T-1 d K K
≤4*	+ T X XXKhX(ΩK)ι,j2(Qt-IK)j,k2i
t=T0+1 l=1 k=1	j=1
2	T-1 d K	K
≤ 4吗 + 1) + T X XX Kε02 X (ΩK)ι,j2
t=T0 +1 l=1 k=1	j=1
≤ PΩ(矍八 + T-T二1 K2εo2)
< ρΩ(4ει + K2ε02)
、	—一一	J
19
Under review as a conference paper at ICLR 2022
That is
∀ε > 0, ∃T3 = max{T0 , T2 }, making ∀T > T3,
T-1
It X IIωK (Qt- IK )ll2∣ <ε,
t=0
which is the definition of
1 T-1
Tι→mτ X e[∣∣ωk (Qt-IK )∣∣[ =0.
→∞ T t=0
Thus, the proof of” ^= " ends.
From the analysis of the algorithm CGPFL, we know the iterates of the global models are
ΩK -→--------› ΩK -→ Ωt+1
At any global round t, we consider a client i which belongs to the cluster k at current round, i.e.,
i ∈ Ckt . At the next round t + 1, we focus on any cluster j, where j ∈ [K]. According to the
definition of P t, we have
K
Pit,+j 1 =XPit,p(Qt)p,j	(16)
p=1
十	f 小,if i ∈ Ck
Since we focus on the disjoint cluster structure, i.e., Pitk = |Ck|	k , we can get that
,	0, otherwise
Pt+1 = ∣⅛ (Qt')k,j. We know that the k-means clustering partitions the data points into different
groups according to the distances between the data points and the centers of the clusters, i.e., Pit,k =
Probability(k = argminp∈[K] ∣∣ωt-1 - ωp∣∣2). Because the global models are initialized from
a same point, under the non-IID case, the distances between these models will necessarily become
larger than certain tiny positive constants δd2 after one global steps. Then the models can be separated
into different clusters, and gradually the cluster structure will remain invariant since the updates of
model parameters become smaller and smaller as the learning rate shrinks. Therefore, as long as
the index of the selected initialization centroid points in k-means clustering keeps unchange (e.g.,
k-means++. This is the reason why we adopt k-means++ in our algorithm to conduct clustering)
during the algorithm, Qt will keep equal to IK after the first few global rounds. And we can get
T X E[∣∣ΩK(Qt - IK)∣∣2i ≤o(4Tω)	(17)
T t=0	T
Similarly, we can obtain
TX e[∣∣VGκ(ΩK)(Qt - IK)∣∣2i ≤ O(4pg)	(18)
T t=0	T
In the next part, We will first deal with B = EhPK=1 [Gι(ΩK+1)Pt(Qt - IK九]
proof of B = 0.
and give the
K
X[Gi(ΩK-1)Pt(Qt - IK)]k
k=1
KK
XX [Gi(ΩK-1)Pt]j(Qt - IK)j,k
k=1 j=1
KK
X[Gι(ΩK+1)Pt]j X(Qt- IK )j,k
K	KK
X [GI(MI)Pt]j [X(Qt)j,k - X(IK)j,k] ≡ 0,
j=1	k=1	k=1
20
Under review as a conference paper at ICLR 2022
no matter What value GI(Ω^+1)Pt takes. Therefore,
K
B = E[ X [GI]ΩKbptq - Ik)]k] = 0.	(19)
k=1
In conclusion,
KK
E XGk(ωkt+1)-XGk(ωkt)
k=1	k=1
ɑŋ rnπ^ 、u2]	2α2c 3a^	208α3δ2LG2	13αδ2
≤ - 4E WVGK WK 升]+-F BI+ H B2+ -NπO2g- + -N-
Reformulating it, We can get
T-1
T X Eh KHVGK (ωk)『]
t=0
T-1	K	K
≤ OT X Eh κ X Gk (ωk)- κ X Gk (ωk+1)i
t=0	k=1	k=1
802 T-1	6 T-1	832α2 δ2LG2	52δ2
+ KO2T	1 + KT 2_y 2 +	KNRO2 + KN
t=0	t=0
< 4EhK1 PK=I Gk(ωk) - K PK=I Gk(ωk )i	32Ο2ρΩ	24ρ2	832O2δ2LG2	52δ2
≤	OT	+ KO2T + KTΓ + KNRO2	+ KN
Wedefinethat Δg := E[ɪ PK=I Gk(ω0) - ɪ PK=I Gk(ωf)]
value, Ci := 32Kω, C2 := 24ρg and C3 := 83KNG2, then we get
Which is a constant With finite
ɪXlEhɪIIVGK(ΩK)∣∣2i ≤ 4^∆G + CO2 + 号 + 学 + 黑.
T K	OT	O2T	T O2 KN
t=0
With Oo := min {C⅛, /¾o, q416⅛G2o}
Arjevani et al., 2020; T Dinh et al., 2020) do.
, we consider two cases as (Karimireddy et al., 2020;
If Oo ≤ o( cc3t)
we choose O = Oo. Thus we have
T-1
2T XEhNHVGKMK)∣∣2i ≤
t=o
3C1O2 (C1C3)1 26δ2
2O2T +	2√T + KN.
(20)
(21)
1	1
If Oo ≥ o (CCT) 4, we choose O = o (CCT) 4. ThUs we have
2TXEhK∣∣VGK(QK)∣∣2i ≤ 3CT + COr + K¾∙
t=o
_ 2(C1C3)2	26δ2
=√T	+ KN.
Combining these two cases, we can obtain
ɪXlEh-1 ∣∣VGk(Ωκ)∣∣2i ≤ 3C02 + 5(C1C3)1 +空
t ± Lk11 K( K川 J ≤ 202t +	2√T	+ KN
< 3C102	80，2662几2区/衣)	52δ2
≤ 202T +	√KNRT	+ KN
21
Under review as a conference paper at ICLR 2022
Proof ends.
As regard to the relationship between the personalized models and the global models, we adpot the
process of the correspanding proof in (T Dinh et al., 2020), and can get that
N T-1	T-1	2
NT XX Eh 照-ωj∣∣2i ≤O( T X Eh SlVGK (ωK )『])+ o( λ2 + δ2)	(24)
i=1 t=0	t=0
B Proof of Generalization B ound
Before we start the proof of the generalization bound, we first give some definitions which will be
used in the following proof.
h = h(θ), g = g(ω)
h = hi(θi) = argmin {LDi (hR)) + λ kθi- ωkk2}
θi	i	2
h = hi(θi) = argmin {乩(h(θi)) + λ kθi - ωkk2}
θi	2
h,,loc = hi,loc(θtloc) = arg min {Lt)i (hR,loC))}
θi,loc	i
hi,loc = hi,loc(θi,loc) = arg min {LDi (h(θi,locS)}
θi,loc
(25)
We Can bound the generalization error of the obtained personalized models θ*, i ∈ [N] by
N
X 踪{LDR)- miHLD"h)}
i=1
N
=X ~m {LDi(h" - LDi (htιoc)}
i=1
N
=X ^mi {LDi (h i) - LDi (Ok) + LDi(Ok)-LD i (gk) + ld i (Ok)- LDi(h"
i=1 m
+ LD i(hi ) - LDi (hi ) + LDi (hi ) - LDi (hi,loc)}
NN
=X ɪmi {LDi(gk) -LDi (ok)} + X ɪmi {% (Ok)-LD i (hi)}
i=1	i=1
NN
+X m {LDi (h i) -LDi (或)}+X ~m {D^f( i (hi) - LDi (h↑,ιoc)}
i=1 m	i=1 m
The above function is divided into four parts. In the following section, we will bound them sequen-
tially. To deal with the first part, we define that k = ψ(i), where i ∈ [N] and k ∈ [K ].
N
X ~mi {LDi (g^)-LD i (gk)}
i=1
N
≤ ,maXKX q max {LDi (gψ Q-CD i (gψ (i))}
i=1
N
≤ max gιm.aXκX 詈{LDi(gψ (i)) -LD i (gψ (i))}
i=1
Since the results of k-means++ depend on the selection of the first initialization centroid, the possible
number of clustering results is N. By the McDiarmid’s inequality, with probability at least 1 - δ,
22
Under review as a conference paper at ICLR 2022
we have
N
gιmaXκ X 詈{Ln (gψ (Q-LD i (gψ (i))}
i=1
N
≤ ELmaxK X 詈(LDi 囱 Ci))-LD i (gψ ⑴川
i=1
Utilizing the results in (Mansour et al., 2020), we can get
N
E LmaxK X 詈(LDE (i)) -LD i (端⑴))]
i=1
1K
≤ mE{ X max [mCk 仅DCk (Ok)-LDCJgk))] }
k=1
K
≤ X mCkRRDCk ,mCk (H) ≤
k=1
Therefore, we can get
N
X m {LDi (gk) - LD i(疏)}
i=1
(26)
When Assumption 1 is satisfied, We know that LDa (h(ω)) is L-LiPschitz smooth. Thus, We have
LDi (^k) -LD i (h ：) ≤ NLD i (hi(θi)),ωk - θ力 + 2∣∣θ* - ωk∣∣2	(27)
Because h* (θ*) is obtained by solving hi(θ*) = arg min {LD∙ (h(θi)) + 2 ∣∣θi - ωk∣∣2}, we can
θi	2
_ .	, Λ ,	. . .	. ,	.	. .	_ .	, Λ ,	. . .	. , _ .	..	.
get that VLD. (hi(θ*)) + λ(θ* - ω*) = 0, that is RLDii (hi(θ*)) = -λ(θ* - ω*) Thus, we have
NN
X m nLD i (Ok)-LD i (h*)} ≤ (λ+2) X ɪmiuθ* -ω*∣∣2	(28)
i=1	i=1
Finally, according to the definitions of Complexity and Label-discrepancy, we can know that
NN
X m nLDi (h*) - LDi (g*)o+X m nLDD。(h*) - LDi(%∞)}
i=1 m	i=1 m
NN
≤ 2B X^ U λχ(Di) + ^X U disc(Di, Di)
i=1 m	i=1 m
N
=X 詈{2B λχ(Di) + disc(Di ,D i) }
i=1
where the constant B satisfies that LD(h1) - LD(h2) ≤ B λH(D) for h1, h2 ∈ H. Summarizing
the obtained results, we can get
N
+ ^X ^^{2B λH(Di) + disc(Di, Di) }
i=1 m
23
Under review as a conference paper at ICLR 2022
C More Experimental Details
The dataset can be found via the following link:
https://drive.google.com/file/d/1XqiMmJ9pI7apNfFlPwQFcW67rWvfD_aF/
view?usp=sharing.
C.1
Convergence
Figure 4: Convergence of the clustering results on model parameters.
Finally, we provide some experimental results that support the convergence of the transition prob-
ability matrix Qt and show the overhead caused by k-Means clustering at the server. Figure 5(a)
demonstrates that the Euclidean distances between the models’ parameters converge to a stable
value as the training proceeds, which guarantees the convergence of the transition matrix Qt (the
details can be found in the supplemental materials). Figure 4 shows the convergence of Qt, where
the horizontal axis indicate the iterations at the server, while each pixel in the vertical axis represents
a client. The clients clustered into the same group at each iteration are painted the same color. We
can see that the clustering result converges because the color map between clients gradually remains
unchanged.
(a) The average distance among model parameters (b) The overhead of K-means clustering at the
converges as the training proceeds.	server.
The classic k-Means is a heuristic algorithm, of which the computation overhead is an unavoidable
concern. In our method, on the one hand, the k-Means clustering is executed at the server which is
usually considered having sufficient computing power. On the other hand, it can be observed from
Figure 5(b) that the the k-Means clustering can converge very fast with only few iterations after
several global rounds. Therefore, the computation overhead caused by k-Means clustering is not a
bottleneck in our method.
24