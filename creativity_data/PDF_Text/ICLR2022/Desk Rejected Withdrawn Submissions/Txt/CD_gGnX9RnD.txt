Under review as a conference paper at ICLR 2022
Early-stopping for Meta-learning: Estimating
GENERALIZATION FROM ACTIVATION DYNAMICS
Anonymous authors
Paper under double-blind review
Ab stract
Early-stopping, a fundamental element of machine learning practice, aims to halt
the training of a model when it reaches optimal generalization to unseen examples,
right before the overfitting regime on the training data. Meta-Learning algorithms
for few-shot learning aim to train neural networks capable of adapting to novel
tasks using only a few labelled examples, in order to achieve good generalization.
However, current early-stopping practices in meta-learning are problematic since
there may be an arbitrary large distributional shift between the meta-validation set
coming from the training data, and the meta-test set. This is even more critical in
few-shot transfer learning where the meta-test set comes from a different target
dataset. To this end, we empirically show that as meta-training progresses, a
model’s generalization behaviour on a target distribution of novel tasks can be
estimated by analysing the dynamics of its neural activations. We propose a method
for estimating optimal early-stopping time from the neural activation dynamics
of just a few unlabelled support examples from the target distribution, and we
demonstrate its performance with various meta-learning algorithms, few-shot
datasets and transfer regimes.
1	Introduction
Deep Learning research has been successful at producing algorithms and models that, when optimized
on a distribution of training examples, generalize well to previously unseen examples drawn from
that same distribution. Meta-Learning is in a way, a natural extension of this aim, where the model
has to generalize to not only new data points, but entirely new tasks. Important practical progress has
been made in this direction over the past few years. Yet it remains sparsely understood what are the
underlying phenomena behind the transitioning of a neural network’s generalization to novel tasks,
from the underfitting to the overfitting regime, with the optimal generalization happening in between.
Early-stopping, a fundamental element of machine learning practice, maximizes generalization by
aiming to halt the training at the frontier between those two regimes, when generalization is optimal.
It is computed on a validation set, made of held out examples from the training data, which serves as
a proxy for the test data. As a regularizer, ”Early-stopping should almost be used universally. [...] It
is probably the most commonly used form of regularization in deep learning. [...] a very unobtrusive
form of regularization, in that it requires almost no change in the underlying training procedure”
(Goodfellow et al., 2016). However in meta-learning, implementing early-stopping is problematic
since there may be an arbitrarily large distributional shift between the meta-validation tasks (drawn
from the training data) and the meta-test tasks. Moreover, meta-learning typically involves learning a
new task from very few labelled examples, too few to allow constituting a validation set from it.
In this work, we study the relation between generalization in Meta-Learning and neural activation
dynamics : Given a neural network and a set of input examples, the network’s responses measured
at all of its hidden-layers are what we define as the neural activations, and the evolution of those
responses during the learning time (meta-training) is what we define as the neural activation dynamics.
The main contributions of our work can be summarized as follows :
1.	We empirically show that in Meta-Learning, a simple function of the neural activation
dynamics, for just a few unlabelled target examples, can reveal the variation of generalization
to a distribution of novel target tasks (Sec.2.2), and how this function can be learned (Sec.3).
1
Under review as a conference paper at ICLR 2022
2.	We propose a novel method for early-stopping in Meta-Learning, applied in many settings
of Few-Shot Learning and Few-Shot Transfer Learning (Sec.5).
2	Meta-Learning and Few- S hot Classification
Meta-Learning algorithms generally aim to train a model f(x; θ) on a set of source problems, often
presented as a distribution over tasks p(Ttrain), in such away that the model is capable of generalizing
to new, previously unseen tasks from a target distribution p(Ttarget). When applied to classification,
meta-learning has often been formulated in the past by defining a task T that involves the m-way
classification of input examples x among m distinct classes. The tasks from p(Ttrain) and p(Ttarget)
are made of classes drawn from two disjoint sets Ctrain and Ctarget . A novel task thus involves new
classes not seen during training.
In few-shot learning, the inputs x of the training and target tasks come from a same input distribution
p(x) (e.g., an image dataset) but conditioned on their respective classes, i.e. p(xtrain) = p(x|y ∈
Ctrain) and p(xtarget) = p(x|y ∈ Ctarget). The few-shot aspect means that for a given novel task
Ttarget , only a very few labelled examples are available, typically k examples per class, and the
model uses this support set of examples S = {(x, y)}1..k to adapt its parameters θ to the task, then
its accuracy is evaluated on new query examples from Ttarget . The meta-learning generalization
Acctarget, for a model f (x; θt) at time t (after t training iterations) to a distribution p(Ttarget), is
thus the query accuracy averaged over multiple target tasks:
Acctarget = ETi 〜P(Ttarget ) [E(x,y)-Ti \Si [1 {argmax(f (x； θt)) = y}]]	⑴
where for each new task Ti the adapted solution θti is often obtained by performing T steps of gradient
descent (full-batch) on the cross-entropy loss L(f, Si) with respect to θt.
In few-shot transfer learning, not only are the class sets Ctrain and Ctarget disjoint, but the marginal
p(xtarget) can be arbitrarily different from p(xtrain) (e.g. from a different image dataset).
validation classes
target classes
Figure 1: A task is created by randomly picking m classes from a set C, and belongs to a task
distribution P(T) (e.g. Ttrain 〜PErain) : classify between “horse” and “bicycle”). Training,
validation and target tasks are made of different classes. Few-Shot Learning : target inputs (e.g.
images) come from the same distribution (dataset) as for training, but conditioned on different classes.
Few-Shot Transfer Learning : Different target classes, and target inputs come from a different dataset.
2.1	Early- S topping based on validation set performance can lead to sub
optimal generalization in Meta-Learning
In a standard supervised learning setup, a subset of examples is held out from the training data
to constitute a validation set. Since the validation accuracy is a good proxy for the test accuracy,
early-stopping is performed by halting training when the validation accuracy reaches its maximum.
In Meta-Learning for few-shot classification, the validation set is made of held out classes from
the training data to constitute the validation task distribution P(Tvalid), and early-stopping happens
at Valid=argmaxtAccvalid. But this can lead to a sub-optimal generalization (see Fig.2) because
of the potential distributional shift between P(Ttarget) and P(Tvalid) especially in few-shot transfer
learning where it can be arbitrarily large. Estimating the out-of-distribution generalization Acctarget
in Meta-Learning thus requires some minimal amount of information about P(Ttarget). However, the
2
Under review as a conference paper at ICLR 2022
few-shot paradigm severely restricts the availability of data from p(Ttarget). The support examples
from target tasks are accessible, but the model doesn’t control how many new tasks will actually be
presented, there could be several thousands or very few. However, if there is a need to early-stop and
generalize to some target task distribution p(Ttarget), then the model will need to solve, at the very
least, a single task from p(Ttarget), and thus has access to at least a single support set S. We thus
propose to only use a few examples, typically the support set of a single new task (e.g. 5 images).
This also implies that any algorithm estimating the optimal early-stopping time t* should have a very
low sample-wise (and task-wise) variance for its estimate of t*.
Figure 2:	(Left) Early-stopping based
0	20	40	60	80	100 120	140	160
t (1k training iterations)
on validation accuracy is problematic in
Meta-Learning as there can be an arbi-
trarily large time gap between the opti-
mal stopping time t* for the target task
distribution and t*alid. This can lead to
sub optimal target generalization. For
example, on the (Right) we show accu-
racy vs. training interations for a CNN
trained with MAML on the Birds dataset
with multiple target datasets, each accu-
racy is averaged over 500 tasks (5-way
1-shot). Markers represent t* (black);
tv*alid (red). More settings in App.***.
2.2 Can neural activation dynamics for a few target inputs allow us to make
inferences about generalization?
Figure 3:	Neural Activation Dynamics : A neural net-
work f composed of a feature extractor φ (light blue) of
L hidden-layers, followed by a classifier g. For a set X
of input vectors xi the activation vectors at the l-th layer
are denoted as φl (X). The set of activations of all layers
from 1 to L constitute the neural activations Φ(X) of the
model and their evolution through learning time constitute
the neural activation dynamics Φ(X, t). See Eq. 3, 4.
In this work we search for an observable property of deep neural networks that can help us make
inferences about meta-learning generalization to a given target problem as training time t pro-
gresses. We thus hypothesize the existence of a function ψ of f(x; θt) and p(Ttarget) such that
Ψ(f,p(Ttarget),t) Y Acctarget(t), and set on to find ψ. More specifically, we want to estimate
t* = argmaxt Acctarget(t) using only a few target examples (a single support set) when approximat-
ing ψ . To support a general statement on generalization in Meta-Learning and the nature of ψ, we
conduced experiments across a wide range of meta-learning settings. We used different meta-learning
algorithms, three of the most pivotal ones of the field : MAML (Finn et al., 2017), Prototypical
Networks (Snell et al., 2017), and Matching Networks (Vinyals et al., 2016). We considered both
the few-shot learning and few-shot transfer learning regimes, with 1-shot and 5-shot experiments,
and various few-shot datasets for p(Ttrain) and p(Ttarget), such as MiniImagenet and Omniglot,
but also many others included in Meta-Dataset (Triantafillou et al., 2020). We also used different
architectures : the standard 4-layer CNN proposed by (Vinyals et al., 2016), as well as a ResNet
as used in (Triantafillou et al., 2020). For full experimental details, refer to Appendix A. Here we
present the experimental results that progressively suggest that variation of generalization can be
efficiently estimated from simple metrics on the neural activation dynamics :
Observation 1: For a deep neural network, the variation of target generalization, as a function of
training time, frequently correlates with simple statistics characterizing how its feature extractor
responds to the target input distribution: In many meta-learning settings we observed that Acctarget
is proportional to relatively simple metrics (denoted as ψ1). One such metric is the expected inner
product between representations:
ψι (B(X)) = Exi ,χj~p(χ)二(Xi )T B(Xj)],
(2)
3
Under review as a conference paper at ICLR 2022
where ψ1 is measured at the output of the feature extractor 夕,where f (x) = g(φ(x)), and captures
both the similarity among representation vectors and their norm. Moreover, we measure ψ1 on the
representations of the target inputs Xtarget , before adapting the model to new tasks. This relation
seems approximately independent of the target class identities Ytarget , and predominantly depends
on how the feature extractor represents the marginal distribution over the input Xtarget of the target
problem, i.e. ψ1 (D(Xtarget), t) Y Acctarget (t). Example in Fig.4, complete results in App.B.2.1.
Figure 4:	Average target task accuracy as a function of training
iteration: Acctarget(t). Observation 1: The variation of gen-
eralization (Acctarget), for a deep neural network, frequently
correlates with simple statistics characterizing how its feature
extractor 夕 responds to the target input distribution P(Xtarget).
For example, here we show ψ1 , which is simply the expected
inner product between individual representation vectors, which
follows the same trend as Acctarget(t) and peaks roughly at the
same time. Here ψ1 is vertically rescaled to match the range of
the target accuracy. See App.B.2.1 for full experiments across
multiple settings.
Observation 2: A simple statistic on the neural activations, if
computed at the right layer of a network, can often strongly cor-
relate with generalization, but this layer may change depending
on the setting. In a deep neural network a feature extractor is
composed of L hidden-layers:0(x)=(夕L◦夕L-I ◦...◦ φ1 )(x).
In many settings, ψ1 measured at the last layer 夕L isn,t propor-
tional to Acctarget , but the relation instead occurs at a lower
layer 夕l. Thus, rather than just examining the last layer rep-
resentation dynamics, we often need to consider the neural
activations of the whole feature extractor (See Fig. 3 and Eq.
3). More precisely, we shall consider the evolution through-
out time or the neural activation dynamics of a network, i.e.:
ψ(Φ(Xtarget, t)) Y Acctarget(t), or expressed in the form of
Eq. 4. See an example at Fig.5, or App.B.2.2 for full experi-
ments across multiple settings.
Φ(X) = {01 (X) | l ∈ [1..L]}	(3)
Φ(X,t)=. Φ(X | θt)	(4)
Observation 3: Simple statistics of the activations correlate to
Figure 5: Observation 2: Simple
statistics of neural activation dynamics
which best correlate to generalization
may be observed at different layers of
the feature extractor. We therefore con-
sider the neural activation dynamics of
all layers in a network in our work here.
generalization, but they may change. One needs to find the right statistic depending on the setting. In
our experiments we observe that for many settings Acctarget(t) doesn’t consistently correlate with
ψ1 (Pl(Xtarget)) at any specific layer l. From this we conjectured that perhaps ψ1 is a special case in
a more general function space Ψ, a hypothesis space or set of functions that predict generalization, or
more formally : Ψ = {ψ | ψ(Φ(Xtarget,t)) Y Acctarget(t)} where ∣Ψ∣ > 1. From this perspective
we ultimately care about finding the function ψ in Ψ that, given the meta-learning setting involved,
minimizes the true objective d defined below :
d = mtax(Acctarget(t)) - Acctarget(argmax ψ(Φ(Xtarget, t)))	(5)
The natural question that follows is, what may be the chat racteristics of such function space Ψ ?
We address this by formulating a few inductive biases and assumptions which then inform our
subsequent experiments. We first note that the complexity of Ψ must be large enough so that, in most
meta-learning settings in the few-shot regime, Ψ contains a good solution function ψ* such that d
is low. The complexity shouldn,t be too large either, since to find ψ* we will optimize an indirect
empirical objective d (Sec.3). This is especially important in few-shot transfer learning. Furthermore,
since Φ(Xtarget) itself has a probability distribution, our hypothesis space Ψ should be a set of
functions ψ that are sample estimators of some population statistics of the distribution of Φ(Xtarget).
However, since we only have access to a very few samples, those statistics should be relatively
simple so as to keep down the standard error of their estimators. We propose to use descriptive
statistics based on moments, and limit them up to the second-order (higher-order moments are harder
to estimate accurately). Finally, since we ultimately need to find a one-dimensional curve ψ* (t) to
4
Under review as a conference paper at ICLR 2022
compare to Acctarget (t), our hypothesis space Ψ should contain scalar-valued functions, which we
get by computing moments on norms of the activation vectors. In our experiments we observe that
when Acctarget(t) doesn't consistently correlate with ψι(夕ι (Xtarget)) at any specific layer l, it does
typically correlate with one of the following alternative metrics : the norm of activations ψ2 ; the
dispersion of activations ψ3; or the feature-wise variance of activations ψ4. We have observed that
generalization sometimes actually correlate with the negative (i.e. -ψ) of either of ψ1 to ψ4.
Ψ2 = Eχ[k∕(x)k2]	(6) ψ3 = Eχ[∣S(xi)-口(Xj)k2]⑺ ψ4 = Eχ[VarkS(xi,k))] (8)
(a) Generalization here correlates
with ψ2 - the norm of activations.
MAML, CNN, Aircraft
(b) Generalization here correlates (c) Generalization here correlates
with ψ3 - dispersion of activations. with ψ4 - feature-wise variance.
ProtoNet, CNN, VGG Flower Matching Net,CNN,MiniImagenet
Figure 6: Observation 3: Generalization may correlate to different properties of the neural activation dynamics,
depending on the setting. While Acctarget may correlate to ψ1 (Eq.2) in some settings, in other settings it
may instead correlate to ψ2, ψ3 or ψ4 (Eq.7,6,8) measured on the activation dynamics at depth l of the feature
extractor. See App.B.2.3 for full experiments across multiple settings.
All the metrics ψ1 to ψ4 and their negatives can actually be expressed by a linear combination of the
following moments (assuming ReLU activation functions) :
1n	1n	1 n n
mi = nXk∕(χi)k2 m2 = nXιs(χi)k2	m3 = nXXkψι(Xi)-中I(Xj)k2 ⑼
such that those moments define the function space Ψ = {ψ(夕ι (X); W) | W ∈ R3, l ∈ [1..L]} where
ψ(φι(X); w) = wimi + w2m2 + w3m3 and W = [w1,w2,w3] ∈ R3. This parametric function
space Ψ, while being relatively simple, can express a variety of properties of activations, such
as their norm, dispersion, feature-wise variance, inner product, positively or negatively, or even
a combination of properties. In Tab.3 of App. B.3 we have experimentally verified that Ψ has
enough complexity to contain a good solution function ψ*, for many meta-learning settings, both
in few-shot learning and few-shot transfer learning.Observation 4: The Variation of generalization
can be estimated by using just afew target input examples: Given a function ψ(φι (Xtarget)) which
correlates with generalization Acctarget (t). when ψ is measured on the activation dynamics for just
a single unlabelled support set S, the estimated early-stopping time tψ = argmaxt ψ(t) typically
shows very low variance with respect to which task is used for the estimation (Fig. 7). We conjecture
that this might be due lack of dependency of ψ on Ytarget , where ψ a more general property of the
activations for p(xtarget). This makes early-stopping from such function ψ practical.
5
Under review as a conference paper at ICLR 2022
3	Inferring which function of the neural activation dynamics
correlates to generalization, and at which layer to measure it
Our results in Sec.2.2 suggest that in Meta-Learning there exists a function ψ that, when measured on
the neural activation dynamics Φ(Xtarget, t), closely relates to the target generalization Acctarget (t).
However since this function is not unique and depends on the meta-learning setting involved (meta-
learning algorithm, neural architecture, training and target distributions, etc), we propose to cast the
discovery of ψ as a machine learning problem. See Fig. 8, which schematizes our framework.
Figure 8: Our framework : Learning the relation function ψ between the neural activation dynamics
Φ(Xtarget , t) and the generalization to a novel task distribution p(Ttarget)). Having defined an hypothe-
Sis function space Ψ, We search, given a meta-learning setting, the optimal function ψ* in Ψ which minimize the
true objective d or equivalently, achieve high generalization Acctarget. Since we don’t have access to Acctarget,
*
we optimize an empirical objective d to find ψ .
At this point we know that, given a meta-learning setting, our function space Ψ should contain a good
solution ψ* such the true objective d is low. Now we need a way to actually find ψ*. We can do so by
optimizing an indirect, empirical objective d, defined below.
3.1	Few-Shot Learning (FSL): Inferring ψ* and l* from the validation dynamics and accuracy
In few-shot learning, novel tasks from p(Ttarget) involve previously unseen classes but the input
domain of Xtarget can be assumed to be similar to that of Xtrain, and therefore to that of Xvalid. We
thus use the dynamics Φ(Xvalid, t) and the validation accuracy Accvalid (as a proxy for Acctarget)
in order to learn the optimal function ψ* and the layer l* where it should be measured, and We do so
by minimizing the empirical objective dFSL (Eq.10). We then compute our actual early-stopping
time estimate £FSL when ψ*(4ι*(Xtarget,t)), measured on the few support input examples of a
single target tasks, reaches its peak (Eq.11).
dFSL = max Accvalid(t) - Accvalid(argmaxψ(g(Xvaiid,t); W)))	(10)
tt
£FSL = argmaxψ(2l* (Xtarget,t); w*) where w*,l* = argmin(Ifsl	(11)
3.2	Few-shot transfer learning (FSTL) : Meta-overfitting often happens when the target dynamics
diverge from those of the source input domain
When the target problem is from an entirely new dataset, we can’t use Accvalid as a proxy for
Acctarget, and we need another objective function to learn ψ*. However, we can learn ψ* by
analyzing Φ(Xtarget, t), the neural activation dynamics of the target domain, and comparing them
with Φ(Xvalid, t). Assume that for a given target problem, optimal generalization doesn’t happen
at the same time as for the source domain, i.e., t* 6= tv*alid, and more precisely, assume t* < t*valid.
Typically, a generalization curve is generally increasing between t0 and its maximum, whereas it is
generally decreasing after the maximum. This implies that the curves of Acctarget(t) and Accvalid (t)
are positively correlated between t0 and t*, as they are both increasing, whereas they are negatively
correlated between t* and tv*alid, since Acctarget (t) is decreasing while Accvalid(t) is still increasing.
In a sense, the two generalization behaviors “diverge” at t*, since at that moment their correlation
goes from positive to negative (See Fig.9a). Since here we assume the neural activation dynamics can
characterize the generalization behavior of a model, we conjecture that Φ(Xtarget, t) and Φ(Xvalid, t)
might also “diverge” at t*, under some function ψ(夕l* (X, t); w*), such that the sample Pearson
6
Under review as a conference paper at ICLR 2022
correlation r, of ψ(Φ(Xtarget, t), w*) and ψ(Φ(Xvaiid, t), w*) also goes from positive to negative
near t* (See Fig.9b).
>'')l'x')v
(a)	(b)
Figure 9: a) In few-shot transfer learning if overfitting on the target domain happens at a different time then
on the source domain (e.g. t* < tVaIid) then the validation and target accuracies “diverge” at t* : Acctarget(t)
and Accvaiid(t) are correlated positively on [to,t*] and negatively on [t*, t*aiid]. b) Assuming that the neural
activation dynamics can characterize the generalization behavior, there might be a function under which the
target dynamics diverge from the validation dynamics at t* .
Our experiments indeed suggest that functions ψ exhibiting more divergence are more likely to
capture generalization to the target problem. This analysis can be found in App.***. We thus search
for the weights W and hidden-layer l* so as to observe the most negative correlation between
ψ(φι(Xtarget,t); W) and ψ(wι(Xvaiid,t); w) in the time interval『。，"。^] (Eq.12). Wethen esti-
mate t* by finding the time £FSTL when ψtɑrget(t) and ΨVaiid(t) diverge (Eq.13). See Fig.10a,10b
for a demonstration.
3
dFSTL
r(ψtarget (t), ψvaiid(t))
PPt (ψtarget(t) ― ψtarget (t))(ψvalid (t) ― ψvalid(t))
Pt(ψtarget(t) — ψtarget(t))2 Pt(ψvalid() - ψvalid(t))2
(12)
tpSTL = argmax ∖t × r "target, ψ*alid, [t0,t < t
(13)
with shorthand notations ψ target (t = ψ(φι(Xtarget,t); w) and ψvaiid(t) = ψ(φι(Xvaiid ,t); w)
and ψ(t) denotes an average over t, and ψ* = ψ(夕i* (∙); w*). Here again we minimize an empirical
objective, and w* , l* = argminw,i .dFSTL.
0	10 20 30 40	50 60
t (iters)
0.50
05050505
9cς0?77∙6∙65
Oooooooo
AeJn<
(b)
(a)
Figure 10: Inferring when to stop in few-shot transfer learning. Setting shown: MAML, CNN, Quickdraw to
Omniglot, 5-way 1-shot. a) The optimal function ψ * and layer l* are those where the neural activation dynamics
of the target inputs diverge the most from those of the source domain, i.e. where the objective of Eq.12 is
minimized. b) Once we have identified ψ* and l*, we stop at £FSTL ofEq.13, i.e. when the Pearson correlation
of ψ*arget and ψVαiid flips from positive to negative. Here £FSTL drastically outperforms 心血.
7
Under review as a conference paper at ICLR 2022
4	Related Work
In recent years, some works have started to analyze theoretical aspects of gradient-based meta-
learning. (Finn et al., 2019) examine the online Meta-Learning setting, where in online learning the
agent faces a sequence of tasks, and they provide a theoretical upper bound for the regret of MAML.
(Denevi et al., 2019) study meta-learning through the perspective of biased regularization, where the
model adapts to new tasks by starting from a biased parameter vector, which we refer in this work as
the meta-training solution. For simple tasks such as linear regression and binary classification, they
prove the advantage of starting from the meta-training solution, when learning new tasks via SGD.
They use an assumption on the task similarity where the weight vectors parameterizing the tasks are
assumed to be close to each other. Working in the framework for Online Convex Optimization where
the model learns from a stream of tasks, (Khodak et al., 2019) make an assumption that the optimal
solution for each task lies in a small subset of the parameter space and use this assumption to design
an algorithm such that the “Task-averaged-regret (TAR)” scales with the diameter of this small subset
of the parameter space, when using Reptile (Nichol et al., 2018), a first-order meta-learning algorithm.
Bearing a stronger relation to our approach, (Guiroy et al., 2019) empirically study the objective
landscapes of gradient-based meta-learning, with a focus on few-shot classification. They notably
observed that average generalization to new tasks appears correlated with the average inner product
between their gradient vectors. In other words, as gradients appear more similar in inner product,
the model will, on average, better generalize to new tasks, after following a step of gradient descent.
More recently, a few works have studied the properties of the feature extractor 夕 in the context of
Meta-Learning. Notably, the authors of (Raghu et al., 2019) showed empirically that when neural
networks adapting to novel task, in the few-shot setting with MAML and MiniImagenet, the feature
extractor network is approximately invariant, while the final linear classifier undergoes significant
functional changes. They then performed experiments where 夕 is frozen at meta-test time, while only
the classifier g is fine-tuned, and observed very similar generalization performance to the regular
fine-tuning procedure. Intuitively, these results suggest that the variation, of generalization along
meta-training time t, might be predominantly driven by some evolving but unknown property of the
feature extractor. The authors of (Goldblum et al., 2020) observed that generalization in few-shot
learning was related to how tightly embeddings from new tasks were clustered around their respective
classes. However, the authors of (Dhillon et al., 2019) observed that the embeddings at the output of
夕L were poorly clustered around their classes, but that clustering was important when measuring the
logit outputs ofg. This is similar to what the authors (Frosst et al., 2019) observed when dealing with
new Out-of-Distribution examples. This suggests that if generalization is related to a property of the
feature extractor, this property might be class agnostic. This is also something that we observed in our
very early experiments (expected inner product between representation vectors strongly correlated
with generalization, irrespective of taking the class identities into account). But in our work we
observed that this property might not only depend on the output of the feature extractor. Earlier works
demonstrated that in transfer learning, intermediate layers of 夕 might be critical in the ability of the
model to transfer knowledge (Yosinski et al., 2014).
5	Early- S topping for Meta-Learning by Analyzing the Neural
Activation Dynamics of a few target input examples
Here we present experimental results on the performance of our early-stopping method. For each
experiment, we only use the unlabelled input examples from the support set of a single target task to
evaluate the neural activation dynamics. At the beginning of an experiment, we thus randomly sample
a task Ti from p(Ttarget) and only keep its set of support input examples. We repeat the experiment
for multiple (50) independently and identically distributed support sets from p(Ttarget), and take the
average performance. Each such experiment is then repeated for 5 independent training runs. As
a baseline for comparison, we use the validation early-stopping approach. Since ψ1 to ψ4 work in
practice, we will use them as our function space Ψ but the method that we develop applies as well to
the continuous function space defined above, and we present some experimental results in App.B.5
where we apply our early-stopping method with the continuous function space.
We begin by demonstrating our proposed early-stopping method in few-shot transfer learning, across
various target dataset, and present the results in Tab.1. We use the standard 4-layer CNN architecture,
with MAML, trained on MiniImagenet 5-way 1-shot. When the target dataset is Omniglot, the
8
Under review as a conference paper at ICLR 2022
performance of the validation baseline (51%) is significantly lower than the optimal generalization
(76%) presumably because of the distributional shift between MiniImagenet and Omniglot. In such
scenario our method appears to offer a significant advantage over the baseline, since we obtain
75% in target accuracy, quite close to the optimal generalization. In scenarios where the target
domain is arguably more similar to that of the source domain, e.g. transfer from MiniImagenet
to Imagenet, the early-stopping from the validation accuracy yields a performance (35.0%) closer
to the optimal generalization (35.6%), and in such case our method performs only slightly worse
(34.8%) than the validation baseline. We observe a similar trend when the model is trained on the
Quickdraw dataset : When transferring to Omniglot, the validation baseline leads to sub-optimal
generalization, but estimating the target accuracy from the neural activation dynamics allows us to
halt the training close to the optimal time. When transferring to Traffic Sign, the baseline performance
yields reasonable performance, and our method is roughly on par with it. From this point, we will
focus on settings where there is a significant gap in performance between the validation baseline
and optimal generalization, for example the transfer from Birds to Quickdraw, the present in our
illustration of Sec.2.1. Next we present similar experiments with two other meta-learning algorithms :
Prototypical Networks and Matching Networks, which are shown in Tab.2.
Source dataset	MiniImagenet		Quickdraw		Birds
Target dataset	Omniglot	Imagenet	Omniglot	Traffic Sign	Quickdraw
Optimal Generalization	76%	35.6%	86.7%	40.6%	：	52.7%
Validation Baseline	-51%-	35.0%	77.7%	-384%-	-38.8%-
Our method	75%	34.8%	84.8%	38.6% 一	50.7%
Table 1: MAML based early-stopping using neural activation dynamics : Few-Shot Transfer Learning 5-way
1-shot, CNN based classifications. Optimal Generalization is the maximum of the target accuracy averaged over
50 target tasks, each task accuracy being averaged over query 15 shots (75 labelled examples). The performance
of the Validation Baseline is the target accuracy evaluated when the validation accuracy is maximum, itself
computed in the same fashion as for the target accuracy, but here using the validation data.
Meta-Learning algorithm	Matching Networks		Prototypical Networks	
Training dataset	MiniImagenet	MiniImagenet	MiniImagenet	Omniglot
Target dataset	Omniglot	Birds	Omniglot	Quickdraw
Optimal Generalization	77.3% =	39.8% =	69.3% =	56.4%
Validation Baseline	729%	37.9%	644%	-53.2%-
Our method	76.0% 一	38.3% 一	65.8% 一	54.8%
Table 2: Early-Stopping based on the neural activation dynamics : Results with other meta-learning
algorithms : Matching Networks, Prototypical Networks.
6	Conclusion
In this work we have presented empirical evidence that the overfitting point of Meta-Learning for
deep neural networks for few-shot classification can often be estimated from simple statistics of
neural activations and how they evolve throughout meta-training time. Our results suggest that key
properties, or statistics of how feature extractors respond to the target input distribution can be found
which are simple enough to be estimated from just a few unlabelled target input examples. However,
the specific function of the activations, and the layer at which to measure them, need to be inferred.
We demonstrate that these functions and layers of interest can be inferred and used to guide early
stopping - leading to a new, and effective method for early stopping which represents a significant
departure for the de facto standard practice of using a validation set. In few-shot learning these
ingredients can be inferred from how the neural activation dynamics of the validation data relate to
the validation accuracy. In few-shot transfer learning, they are inferred through searching for which
function (in a given function space) and at which layer, that the activation dynamics of the target input
domain “diverge” the most from those of the source domain. Finally, we have demonstrated how this
approach can be used to optimize for target generalization in practice to perform early-stopping and
thus improve overall generalization to distributions of novel few-shot classification tasks, while only
using unlabelled support examples from a single target task.
9
Under review as a conference paper at ICLR 2022
References
Giulia Denevi, Carlo Ciliberto, Riccardo Grazzi, and Massimiliano Pontil. Learning-to-learn stochas-
tic gradient descent with biased regularization. In International Conference on Machine Learning,
pp.1566-1575. PMLR, 2019.
Guneet S. Dhillon, Pratik Chaudhari, Avinash Ravichandran, and Stefano Soatto. A baseline for
few-shot image classification. CoRR, abs/1909.02729, 2019. URL http://arxiv.org/abs/
1909.02729.
Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation
of deep networks. CoRR, abs/1703.03400, 2017. URL http://arxiv.org/abs/1703.
03400.
Chelsea Finn, Aravind Rajeswaran, Sham M. Kakade, and Sergey Levine. Online meta-learning.
CoRR, abs/1902.08438, 2019. URL http://arxiv.org/abs/1902.08438.
Nicholas Frosst, Nicolas Papernot, and Geoffrey Hinton. Analyzing and Improving Representations
with the Soft Nearest Neighbor Loss. arXiv e-prints, art. arXiv:1902.01889, February 2019.
Micah Goldblum, Steven Reich, Liam Fowl, Renkun Ni, Valeriia Cherepanova, and Tom Goldstein.
Unraveling meta-learning: Understanding feature representations for few-shot tasks. CoRR,
abs/2002.06753, 2020. URL https://arxiv.org/abs/2002.06753.
Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http:
//www.deeplearningbook.org.
Simon Guiroy, Vikas Verma, and Christopher J. Pal. Towards understanding generalization in
gradient-based meta-learning. CoRR, abs/1907.07287, 2019. URL http://arxiv.org/abs/
1907.07287.
Mikhail Khodak, Maria-Florina Balcan, and Ameet Talwalkar. Provable guarantees for gradient-
based meta-learning. CoRR, abs/1902.10644, 2019. URL http://arxiv.org/abs/1902.
10644.
Alex Nichol, Joshua Achiam, and John Schulman. On first-order meta-learning algorithms. CoRR,
abs/1803.02999, 2018. URL http://arxiv.org/abs/1803.02999.
Aniruddh Raghu, Maithra Raghu, Samy Bengio, and Oriol Vinyals. Rapid Learning or Feature
Reuse? Towards Understanding the Effectiveness of MAML. arXiv e-prints, art. arXiv:1909.09157,
September 2019.
Jake Snell, Kevin Swersky, and Richard S. Zemel. Prototypical networks for few-shot learning.
CoRR, abs/1703.05175, 2017. URL http://arxiv.org/abs/1703.05175.
Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Utku Evci, Kelvin Xu, Ross
Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine Manzagol, and Hugo Larochelle. Meta-
dataset: A dataset of datasets for learning to learn from few examples. In International Confer-
ence on Learning Representations, 2020. URL https://openreview.net/forum?id=
rkgAGAVKPr.
Oriol Vinyals, Charles Blundell, Timothy P. Lillicrap, Koray Kavukcuoglu, and Daan Wierstra.
Matching networks for one shot learning. CoRR, abs/1606.04080, 2016. URL http://arxiv.
org/abs/1606.04080.
Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. How transferable are features in
deep neural networks? CoRR, abs/1411.1792, 2014. URL http://arxiv.org/abs/1411.
1792.
10
Under review as a conference paper at ICLR 2022
A Experimental details
CNN : We use the architecture proposed by Vinyals et al. (2016) which is used by Finn et al.
(2017), consisting of 4 modules stacked on each other, each being composed of 64 filters of of 3
× 3 convolution, followed by a batch normalization layer, a ReLU activation layer, and a 2 × 2
max-pooling layer. With Omniglot, strided convolution is used instead of max-pooling, and images
are downsampled to 28 × 28. With MiniImagenet, we used fewer filters to reduce overfitting, but
used 48 while MAML used 32. As a loss function to minimize, we use cross-entropy between the
predicted classes and the target classes.
ResNet-18 : We use the same implementation of the Residual Network as in (Triantafillou et al.,
2020).
For most of the hyperparameters, we follow the setup of (Triantafillou et al., 2020), but we set the
main few-shot learning hyperparameters so as to follow the original MAML setting more closely,
and in each setting, we consider a single target dataset at a time, with a fixed number of shots
and classification ways. We use 5 steps of gradient descent for the task adaptations, 15 shots of
query examples to evaluate the test accuracy of tasks. We don’t use any learning rate decay during
meta-training, and step-size of 0.01 when finetuning the models to new tasks.
Datasets : We use the MiniImagenet and Omniglot datasets, as well as the many datasets included in
the Meta-Dataset benchmark (Triantafillou et al., 2020).
11
Under review as a conference paper at ICLR 2022
B Complete experimental results
B.1	The issue of using a validation set for early-stopping in meta-learning
X9ajrv7v%l∙
Meta-Leamlng: marrɪl, Train data： CU birds
20∞O WXO «XX» XX»« IlXXXO 12IXXW MWW lββ∞O
Training l½ratiorβ
Meta-LeamIng： matching, TraIn data： cu blnis
⅛ok*⅛raw
"WtOt
IBWJ2SN
EfflaP⅛.
ak%reft
→- 0∣jxmα
mlrtjrt⅛a⅛ι⅛t
5«X»	1«XX»	ISWOO	JIXXWO
Training Iteratiore
Meta-Leamlng; prototypical. Train data: cu binds
SXXW	iwxv	isxx»	2wm
Training Iterations
(a) MAML - CU Birds	(b) Matching Network - CU Birds (c) Prototypical Network - CU Birds
Meta-LearnIng： maml. Tralndata： mlnl」magenet
—rtiM∣-⅛aaw⅛t
→- 8j⅛ω
-*- OElaet
--<-"3
t →- v⅛⅛nβw⅛-
→- IHw⅜2012
gmjβ⅛ 如
-∙- ∙k%mft
Meta-Leamlrw: matehlnɑ, Train data: mini lmaqer⅛t
→- mlrtjmaa⅞n
e⅛∣jxmα
-Λ- OMHaet
-*- 0B
，VWjm
→- IHw⅞2012
ak%reft
ιmlng: prototypical, Train data： nl Imagenet
SwOo i«»«o	150∞0	2∞<xw	Xm vmn ImoD	2 wow	ιxw>	2, Vn SwOo KVn ιo∞oo 1250∞ ISwOo IK«» 20∞∞
Training ItBratiohS	Knm Iterations	Tialnlng ftβratk>r>s
(d) MAML - MiniImagenet	(e) Matching Network - MiniImagenet(f) Prototypical Network - MiniIma-
genet
Figure 11: Illustrating the issue of using meta-validation for early-stopping in Meta-Learning: MAML,
Matching Network and Prototypical Network, trained on both MiniImagenet and CU Birds, with
various target datasets from the Meta-Dataset benchmark. The validation early-stopping time t↑jaiid
(red dashed line) leads to sub-optimal generalization performances for the various target datasets
(from the Meta-Dataset benchmark), each having their own optimal early-stopping time "。”t(black
dashed lines) at different times. We also observe t↑arget ≤ t↑jaιid across the different settings.
B.2	The relation between the neural activation dynamics and generalization
TO NOVEL TASKS
B.2	. 1 Relation between the representation space of the feature extractor and
TARGET GENERALIZATION
Here we present experimental results to support the observation 1 that we make in 2.2, showing that
the variation of generalization along meta-training time can be captured by a function of the neural
activation dynamics that is independent of class labels.
12
Under review as a conference paper at ICLR 2022
AuEnu∂vi,6Je1-
IOOO
800
⅞ 600'
400
200
50 75 100 125 150 175 200
Epoch
(b) 5-way, 1-shot, 1-step
(a) 5-way 1-shot 5-step
(c) 5-way, 5-shot, 1-step
Figure 12:	Comparison between average inner product between representation vectors, and average
target accuracy on target tasks in few-shot learning, for different regimes of MAML and First-
Order MAML on MiniImagenet. Here the expression [hiT hj] is the expected inner product between
representations for the target inputs, i.e. ψ1 defined in Eq.2.
ASeJny UnVH
0	50∞0 IOOOOO 150∞0	200000	250000
Training iterations
ASeJny-səɪ
O 50000 IOOOOO 150∞0	200000	250∞0
Training iterations
(a) Quickdraw to Quickdraw	(b) Quickdraw to Omniglot	(c) Quickdraw to Imagenet
Figure 13:	Measuring the expected representational inner product in Few-Shot Transfer Learning.
MAML, 5-way 1-shot, training dataset : Quickdraw. The estimated early-stopping time of the metric
tψ shows coincides well with the true optimal early-stopping time t* and measuring the correlation
(Pearson) between tψ and t* gives R = 0.925 with a p-value near 0. Considering the gap between 1)
the average performance of validation early-stopping across the three settings (58.69%); and 2) the
maximum generalization across the three settings (61%), the average performance of the metric is at
59.7%, closing nearly half of the gap (43.74% of the gap).
B.2.2	Neural Activation Dynamics : Different levels of the feature extractor
CAN REVEAL THE VARIATION OF GENERALIZATION
B.2.3	Different functions of the neural activation dynamics can reveal the
VARIATION OF GENERALIZATION
By expending the experimental setup further, we observed instances where a given metric had
strong correlation with generalization but in a negative sense, i.e. that it was actually its argmin that
coincided with optimal early-stopping time t*. See Fig. 14 for examples of this phenomenon.
13
Under review as a conference paper at ICLR 2022
(a) Matching Network, ResNet-18, 5-way 5-shot
(b) Prototypical Network, ResNet-18, 5-way 1-shot
Figure 14: Strong negative correlation between generalization and metrics on the representation
space, where the minimum of the metric coincides with the maximum of generalization : Few-Shot
Learning settings with MiniImagenet, 5-way 1-shot, with a ResNet-18. The metric is the expected
inner product (left subfigures, represented by E[hi Thj] where hi stands for the representation vector
for an input example xi). The metric is measured at the output of the feature extractor (6th block of
the ResNet), and we show its measurement on 5 distinct tasks. The generalization (right subfigures)
is averaged over 50 tasks.
We later observed that other statistical estimators can correlate with generalization.
(a) Exclusive correlation be- (b) Expected l2 Norm (c) Expected l2 Dispersion (d) Expected Feature-Wise
tween a specific metric and	Variance
generalization
Figure 15: Different metrics of the representation space may have strong correlation with generaliza-
tion, other than the expected inner product of Eq. 2). a) Prototypical, VGG Flower, 5-way 1-shot
: out of three metrics which in other cases may be related with generalization (as in b), c), d) and
Sec. ??), here only the expected l2 dispersion has a strong relation with generalization. b) Expected
l2 norm (Eq. 6); c) Expected square l2 dispersion (Eq. 7, Prototypical Network, VGG Flower; d)
Expected feature-wise variance (Eq. 8), Prototypical Network, Omniglot to Quickdraw. These results
motivate our approach of considering a family of functions Ψ in which we must find the optimal
function ψ* given the setting, rather than trying to discover a single universal metric that would
correlate to generalization in all scenarios. Even if such metric exists, it may not be estimated with
enough efficiency to satisfy the requirement of using only a single support set to estimate t*.
B.2.4	Functions of the neural activation dynamics : Task-wise variance of the
ESTIMATE tψ
Here we present empirical results on the task-wise variance as discussed in the observation 4 of
Sec. 2.2. We begin by showing the task-wise variance for few-shot accuracy when evaluated with a
single target task and assuming access to the query examples (15 shots). Few-shot accuracy exhibits
a high variance as different tasks will peak at much different times, making it unfit to estimate t*. On
the other hand, for the metrics from Sec. 2.2, which are based on small order statistics (mean and
variance) the estimated early-stopping time exhibits drastically lower variance. See Fig. 16 for an
example, where we use MAML in few-shot learning (5-way 1-shot) with the Aircraft dataset, and
where we use the expected square l2 norm for the metric. As we can see, in Fig. 16, measuring the
metric on different tasks merely offsets the response curve but bears almost no change on the trend
of the curve itself. This also relates to our assumption that the variation of target generalization in
Meta-Learning might be linked to a function of the neural activation dynamics that is class agnostic.
14
Under review as a conference paper at ICLR 2022
(a) Few-Shot Accuracy
(b) Expected Square l2 Norm	(c) Histogram of tfew-Shot vs. tψ
Figure 16: Task-wise variance : The maximum of the true average target accuracy (generalization) is
at 57.7% with optimal early-stopping time t* at t = 14. a) Displaying the query accuracy of 50 target
tasks. The estimated early-stopping time t}w-shot from the query accuracy of a single task has a
task-wise standard deviation of 17.3 and a mean at t = 26.3. The resulting average generalization
is 54.5%; b) expected square l2 norm, 50 tasks. The metric exhibits very low task-wise standard
deviation of its estimated early-stopping time t*ψ (3.7) and a mean at t = 15.6. Resulting average
generalization is 57.4%, outperforming validation-based early-stopping. c) Histogram : HeW-ShOt
shows high variance while t*ψ is mostly concentrated near t*. Setting used : MAML, CNN, Aircraft,
5-way 1-shot.
B.3	CAPACITY OF THE CONTINUOUS FUNCTION SPACE Ψ (DEFINED BY THE THREE MOMENTS
OF EQ.9) TO CONTAIN GOOD SOLUTIONS ψ*
The moments mi, m2 and m3 of Eq.9 define the parametric function space Ψ = {ψ(夕 ι(X); W) | W ∈
R3, l ∈ [1..L]} where ψ(夕ι(X); w) = w1m1 + w2m2 + w3m3 and W = [w1, w2, w3] ∈ R3. This
parametric function space Ψ. Here we have experimentally observed that Ψ has enough complexity
to contain a good solution function ψ*, for different meta-learning settings, both in few-shot learning
and few-shot transfer learning, as shown in Tab.3.
d / max Acctarget	Omniglot	VGG Flower	Birds	Aircraft	Quickdraw
MAML	0%	0%	0%	0%	0%
Matching Net	0%	0%	0.17%	0.41%	—
Proto Net	0.17%	0% 一	1.03%	0.43%	—
(a) Few-Shot Learning
train algo	MAML	Prototypical Network	Matching Network	Matching Network
p(Ttrain )	Quickdraw	Omniglot	Omniglot	MiniImagenet
p(Ttarget )	Omniglot	Quickdraw	Quickdraw	Omniglot
d / max Acctarget	0%	0%	0.07%	0.66%
(b) Few-Shot Transfer Learning
Table 3: Our function space Ψ is rich enough to contain good solution functions, both in few-shot
learning and few-shot transfer learning. For multiple settings, we present the relative minimal gap
maxt Acctarget (t) - Acctarget(t*ψ)/ maxt Acctarget (t) achieved by ψ*.
B.4	LEARNING ψ* IN FEW-SHOT TRANSFER LEARNING
B.4.1	FINDING W* AND l* WHERE ψtarget (t) AND ψvalid(t) “DIVERGE” THE MOST
As we added more experimental settings for Few-Shot Transfer Learning, we observed instances
where, for a given metric measured at the representation space 夕l, there was no strong link with
generalization, but when measuring the metric at lower hidden-layers than 夕l, then We observed a
strong correlation with generalization. We illustrate this in Fig. 17. Theses results motivated our
15
Under review as a conference paper at ICLR 2022
approach of considering the whole neural activation dynamics (all layers), rather than only those the
final layer of the feature extractor alone, in our search for functions linked to generalization. Then in
Fig.18 we conducted a more systematic analysis, but concerned with identifying the right functions
ψ*, with results suggesting that functions ψ showing stronger “divergence”(negative correlation)
between the target and validation dynamics, will more likely lead to a higher target accuracy if we
stop at their peak time.
(a) Transfer : Omniglot to MiniImagenet, MAML. The critical depth, i.e. the one where measuring the expected
inner product (here marked as RIP) predicts generalization on the target domain, is at layer 1, even though the
critical depth for the source domain was at layer 4.
(b) Transfer : MiniImagenet to Omniglot, MAML. The critical depth for the target domain is at layer 4, the same
as for the source domain.
Figure 17: Generalization can correlate to a metric at different levels of neural activations. Here the
critical layer l* (squared in red) is identified by searching for the highest divergence between the
validation and target neural activation dynamics.
Correlation between D(ψtarget, ψtarget。and Generalization		
MAML Quickdraw J Omniglot	Prototypical Network Omniglot J Quickdraw	Matching Network MiniImagenet J Omniglot
0.82	0.75	0.81
Table 4: Correlation between D(ψtarget, ψtarget, ) and Generalization, for different few-shot learning
settings. The correlation is computed as in the analysis of Fig. 18c. The results show that functions
exhibiting high divergence between the validation and target neural activation dynamics are likely to
lead to good generalization performance on the target distribution.
B.5	Evaluating the performance of our early-stopping method when using the
CONTINUOUS FUNCTION SPACE Ψ DEFINED BY THE THREE MOMENTS OF EQ.9
Here we present a few experimental results where we apply our early-stopping methof in the
continuous function space Ψ. Since there are only three weights to tune, namely w1, w2 and w3, we
don’t suffer from the curse of dimensionality, which is the classic motivation for using gradient-based
optimization of neural networks with many parameters. This allows for a search based optimization
of w.
16
Under review as a conference paper at ICLR 2022
(a) Functions with high
divergence between valid
and target dynamics are
more likely to achieve
higher generalization
(b) Average divergence vs.
average performance
(c) Strong correlation be-
tween average divergence
and average performance
(d) Solution function mea-
sured on the valid and tar-
get examples
Figure 18: Divergence of the neural activation dynamics as an indication for early-stopping : MAML,
Quickdraw to Omniglot, 5-way 1-shot. For 50 pairs of target and validation tasks, we measure all
the four metrics (expected inner product; expected square l2 norm; expected square l2 dispersion;
feature-wise variance), at all the layers of the feature extractor. For each measurement (layer and
metric), we plot the divergence D (ψtarget, ψvalid) = 1 - r(ψtarget, ψvalid) (where r is the sample
Pearson correlation through time) against the obtained generalization performance (here for this
example We simply use tψ = argmaxt ψtarget). a) while functions with low divergence may lead
from very poor to very good performance, functions showing high divergence between the validation
and target dynamics very likely lead to good performance; b) We illustrate this by dividing the points
into 10 bins along the divergence axis, and in each bin we average the divergence and performance,
and plot the averages from the bins (blue curve) along with the standard deviations (blue dashed area).
c) correlation between the bin averaged divergences and performances d) We display ψ* that achieved
the highest divergence, which we can observe by its two response curves on its pair of validation and
target tasks.
Algorithm		MAML		
Source dataset	Quickdraw	MiniImagenet
Target dataset	Omniglot	Omniglot
Baseline	-77.9%-	54.6%
Our method	81%	75%	—
Table 5: Performance of our method - Few-Shot Transfer Learning, MAML
Algorithm	Prototypical Network	
Source dataset	Omniglot	MiniImagenet
Target dataset	QUiCkdraW	Omniglot
Baseline	-53.2%-	601%
Our method	54.6%	63.3% 一
Table 6: Performance of our method - Few-Shot Transfer Learning, Prototypical Network
Algorithm	Matching Network
Source dataset	MiniImagenet
Target dataset	Omniglot
Baseline	73.75%
Our method	75%
Table 7: Performance of our method - Few-Shot Transfer Learning, Matching Network
17