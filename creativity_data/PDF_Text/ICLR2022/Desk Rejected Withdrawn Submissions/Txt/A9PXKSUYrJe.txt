Under review as a conference paper at ICLR 2022
Robust Learning with Adaptive Sample Credi-
bility Modeling
Anonymous authors
Paper under double-blind review
Ab stract
Training deep neural network (DNN) with noisy labels is practically challenging
since inaccurate labels severely degrade the generalization ability of DNN. Previ-
ous efforts tend to handle part or full data in a unified denoising flow to mitigate
the noisy label problem, while they lack the consideration of intrinsic difference
among difficulties of various noisy samples. In this paper, a novel and adap-
tive end-to-end robust learning method, called CREMA, is proposed. The insight
behind is that the credibility of a training sample can be estimated by the joint
distribution of its data-label pair, thus to roughly separate clean and noisy samples
from original samples, which will be processed with different denoising process in
a divide-and-conquer manner. For the clean set, we deliberately design a memory-
based modulation scheme to dynamically adjust the contribution of each sample
in terms of its historical credibility sequence during training, thus to alleviate the
effect from potential hard noisy samples in clean set. Meanwhile, for those sam-
ples categorized into noisy set, we try to correct their labels in a selective manner
to maximize data utilization and further boost performance. Extensive experi-
ments on mainstream benchmarks, including synthetic (noisy versions of MNIST,
CIFAR-10 and CIFAR-100) and real-world (Clothing1M and Animal-10N) noisy
datasets demonstrate superiority of the proposed method.
1	Introduction
Deep learning has achieved significant progress in the field of computer vision and language pro-
cessing. The key to its success is the availability of large scale dataset with reliable annotations.
Collecting such dataset, however, is time-consuming and expensive. Easy ways to obtain labeled
data, such as web crawling (Xiao et al., 2015a), inevitably yield samples with noisy label, which is
not apporiate to be directly utilized to train DNN since these complex models can easily memorizing
noisy labels (Arpit et al., 2017; Zhang et al., 2017).
To handle this problem, classical Learning with Noisy Label (LNL) approaches focus on either
identifying and dropping noisy samples (i.e., sample selection) (Han et al., 2018b; Jiang et al., 2018)
or adjusting the objective term of each sample during training (i.e., loss adjustment) (Patrini et al.,
2017; Yi & Wu, 2019). The former usually make use of small-loss trick to select clean samples, and
then take them to update DNNs. However, the procedure of sample selection cannot guarantee that
the selected clean samples are completely clean. In contrast, as indicated in Fig. 1, division relied
on statistic metric can still involve some hard noisy samples into training set, which will be treated
equally as other normal samples in following training stages. Thus the negative impact brought
by wrongly grouped noisy samples can still confuse the optimization process and lower the test
performance of DNNs (Yu et al., 2019). On the other hand, the latter schemes reweight loss values or
update labels by estimating the confidence of each sample being clean. Typical methods include loss
correction via estimated noise transition matrix (a small set of clean samples are usually required to
obtain more accurate noise transition matrix) (Hendrycks et al., 2018). However, estimating accurate
noise transition matrix is still challenging and the assumption of availability of a small clean dataset
cannot be fulfilled in many real-world scenarios. Recently, there are approaches directly correcting
the labels of all training samples (Tanaka et al., 2018; Yi & Wu, 2019). However, we empirically find
that unconstrained label correction in full data can do harm to clean samples and reversely hinder
the model performance.
1
Under review as a conference paper at ICLR 2022
Clean Sample
Noisy Sample
20	40	60	80	100
Epoch
(a)
Hard
noisy
samples
Clean Samples
Noisy Samples
Clean Samples
H Noisy Samples
JpQ-I-e3μ-dlu 山 1
0.4	0.6	0.8	1.0
Normalized standard deviation of loss value
Easy noisy samples
^0.0	0.2	0.4	0.6	0.8	1.0
Normalized loss value
(b)	(c)
Figure 1: Training on MNIST with 50% symmetric noise. (a) Compared with noisy samples, clean samples
yield relatively smaller loss value and more consistent prediction. (b) Empirical pdf of loss values and (c)
their stand deviation justify above conclusion. That is, clean and noisy samples possess distinctive statistical
properties. However, noisy samples can not be completely identified via a simple threshold filter strategy (blue
dotted line in (b) and (c)) with these statistical metrics. The existence of easy and hard noisy samples requiring
different ways to handle them accordingly.
Towards the problems above, we propose a simple but effective method called CREMA (sample
CREdibility Modeling and Adaptive loss reweighting), which adaptively reduces the impact of noisy
labels via modeling the credibility (i.e., quality) of each sample. With the estimated sample credibil-
ity, clean and noisy samples can be separated and handled in a divide-and-conquer manner. Since it
is practically impossible to separate these samples perfectly, for the selected clean samples, we take
their historical credibility sequences to adjust contribution of each sample to their objective, thus to
mitigate the negative impact of hard noisy samples. As for the separated noisy samples, some of
them are actually clean (i.e., hard samples) and can be useful. Thus instead of discarding them as in
previous sample selection methods (Han et al., 2018b; Wei et al., 2020), we make use of them via a
selective label correction scheme.
Our insight is from the observation on the loss value during training on noisy data (illustrated in
Fig 1), it can be found that clean and noisy samples manifest distinctive statistical properties
during training, where clean samples yield relatively smaller loss value (Reed et al., 2015) and
more consistent prediction. Hence these statistical features can be utilized to model the sample
credibility. However, Fig 1 also shows that the full data can not be perfectly separated by simple
statistical metrics. This inspires us to adaptively cope with noises of different difficulty levels.
For easily recognized noisy samples, we can directly apply certain label correction scheme while
avoiding erroneous correction on normal samples. For samples fall into the confused area and hybrid
with clean ones, since estimated credibility in current epoch is not informative enough to identify
noisy samples, CREMA resorts to a historical sequence of sample credibility to infer the likelihood
of being noisy data-label pair. This is implemented by maintaining a historical memory-bank along
with the training process and estimating the likelihood function through a consistency metric and
assumption of markov property of the sequence.
CREMA is built upon a classic co-training framework (Wei et al., 2020; Han et al., 2018b). The
sample credibility estimated by one network is used to adjust the loss term of credible samples
for the other network. Extensive experiments conducted on mainstream benchmarks, including
synthetic (noisy versions of MNIST, CIFAR-10 and CIFAR-100) and real-world (Clothing1M and
Animal-10N) noisy datasets demonstrate superiority of the proposed method. In a nutshell, the key
contributions of this paper include:
•	CREMA: a novel LNL algorithm that combating noisy labels via separating clean and noisy sam-
ples and making use of them respectively, in spirit of the idea of divide-and-conquer. Easily recog-
nized noisy samples are handled via a selective label update strategy;
•	In CREMA, likelihood estimation of historical credibility sequence is proposed to help distinguish
hard noisy samples, which naturally plays as the dynamical weight to modulate loss term of each
training sample;
•	CREMA is tested on five synthetic and real-world noisy datasets across various types and levels of
label noise. Extensive ablation studies and qualitative analysis are provided to verify the effective-
ness of each component.
The source code and supporting materials of our work will be published online upon acceptance.
2
Under review as a conference paper at ICLR 2022
Model2
Sample Credibility
Modeling Module2
Wl
W2
•	Xc: Samples with credible label. • W: Sample credibility Weight
•	Xu: Samples requiring label updating.
Figure 2: The pipeline of CREMA. CREMA trains two parallel networks simultaneously. Clean
samples (mostly clean) Xc and noisy samples (mostly noisy) Xu are separated via estimating the
credibility of each training data. A selective label distribution learning scheme is applied for easily
distinguishable noisy samples in Xu. As for the clean set Xc, likelihood estimation of historical
credibility sequence is proposed to handle the hard noisy samples via adaptively modulate their loss
term during training.
2	Related Works
The existing LNL approaches can be mainly categorized into three groups: loss adjustment, la-
bel correction and noisy sample detection. Next we will introduce and discuss existing works for
training DNN with noisy labels.
Loss Adjustment. Adjusting the loss values of all training samples is able to reduce the negative
impact of noisy labels. To do this, many approaches seek to robust loss function, such as Ro-
bust MAE (Ghosh et al., 2017), generalized cross entropy (Zhang & Sabuncu, 2018), symmetric
cross entropy (Wang et al., 2019) and curriculum loss (Lyu & Tsang, 2020). Rather than treat all
samples equally, some methods rectify the loss of each sample through estimating label transition
matrix (Hendrycks et al., 2018; Patrini et al., 2017; Goldberger & Ben-Reuven, 2017; Han et al.,
2018a; Xiao et al., 2015b) or imposing different importance to each sample to formulate a weighted
training procedure (Wang et al., 2017; Liu & Tao, 2015; Chang et al., 2017). The noise transition
matrix, however, is relatively hard to be estimated and many approaches (Hendrycks et al., 2018;
Veit et al., 2017; Litany & Freedman, 2018; Zhang et al., 2020b; Jiang et al., 2018; Li et al., 2017;
Dehghani et al., 2017b;a; Ren et al., 2018; Shu et al., 2019; Zhang et al., 2020b;a) make assump-
tions that a small clean-labeled dataset exists. In real-world scenarios, such condition is not always
fulfilled, thus limiting the applications of these approaches.
Label correction. Label correction methods seek to refurbish the ground-truth of noisy samples,
thus preventing DNN overfits to false labels. The most common ways to obtain the updated label
includes bootstrapping (i.e., a convex combination of the noisy label and the DNN prediction) (Reed
et al., 2015; Han et al., 2019; Arazo et al., 2019) and label replacing (Tanaka et al., 2018; Yi & Wu,
2019; Song et al., 2019; Zhang et al., 2021). One critical problem of label correction methods
is to define the confidence of each label being clean, that is, samples with high clean probability
should keep their labels almost unchanged, and vice versa. Previous solutions including cross-
validation (Reed et al., 2015), fitting a two-component mixture model (Arazo et al., 2019), local
intrinsic dimensionality measurement (Houle, 2017; Ma et al., 2018) and leveraging the prediction
consistency of DNN models (Song et al., 2019). However, updating the labels of all training set is
challenging, and well-designed regularization terms are important to prevent DNN from falling into
trivial solutions (Tanaka et al., 2018; Yi & Wu, 2019).
Noisy sample detection. One commonly knowledge used to discover noisy samples is the memo-
rization effects (i.e., DNN fits clean samples first and then noisy ones). As a result, after a warm-up
training stage with all noisy samples, DNN is able to identify the clean samples by taking the small-
loss ones. The small-loss trick is exploited by many sample selection methods (Han et al., 2018b;
Yu et al., 2019; Malach & Shalev-Shwartz, 2017; Jiang et al., 2018; Wei et al., 2020; Nguyen et al.,
2020; Song et al., 2019; Yao et al., 2020). After separating the noisy samples from the clean ones,
Co-teaching (Han et al., 2018b) and it’s many variants (Han et al., 2018b; Yu et al., 2019; Wei et al.,
2020; Yao et al., 2020) updates two parallel network’s parameters with the clean samples and aban-
doned the noisy ones. The idea of training two deep networks simultaneously is effective to avoid
3
Under review as a conference paper at ICLR 2022
(a) Global label learning.	(b) Selective label learning in CREMA.
Figure 3: Training on MNIST with 50% symmetric noise, warm up (i.e., training on all samples with original
noisy labels) for T epochs. (a) Global learning procedure requires updating all training samples’ label, causes
relatively large gradient values even on clean samples (areas within blue dotted lines), making it hard to focus on
correcting noisy labels. (b) Training on CREMA can effectively identify noisy samples and focus on correcting
noisy labels with reletively large gradient values.
the confirmation bias problem (i.e., a model would accumulate its error trough the self-training pro-
cess) (Han et al., 2018b; Jiang et al., 2018; Li et al., 2020). Discarding the noisy samples however,
means that valuable data may be lost, which leads to slow convergence of DNN models (Chang
et al., 2017). Instead, there are methods that utilize both clean and noisy samples to formulate a
semi-supervised learning problem, by discarding only the labels of noisy samples. Thus converting
LNL problem into a semi-supervised learning ones, for which powerful semi-supervised learning
methods can be leveraged to boost performance (Li et al., 2020; Zheltonozhskii et al., 2021; Zhang
et al., 2018; Berthelot et al., 2019).
The proposed method CREMA, is a hybrid method that takes advantages of loss adjustment, label
correction and sample selection. As shown in Fig. 2, CREMA splits training data into clean and
noisy set and proceeds a divide-and-conquer strategy. Label correction scheme is utilized to handle
the easily recognizable noisy samples, while for hard noisy ones, loss adjustment plays important
roles to modulate contribution of each sample via a novel sample credibility modeling method.
3 Method
In this section, we introduce CREMA, an end-to-end approach for LNL problem. The pipeline of the
approach is shown in Fig. 2. Our training process is built upon a classic co-training framework (Han
et al., 2018b; Wei et al., 2020) to avoid confirmation bias and separate credible samples (mostly
clean) and noisy samples (mostly noisy) via per-sample loss values.
Formally, for multi-class classification problem, letD = {(xi, yi)}iN=1 denote the training data, where
xi is an image and yi ∈ {0, 1}C is the one-hot label over C classes. f (xi; θ) denotes image feature
extracted by DNN model. With the loss from the DNN model, clean set Xc and noisy set Xu
are separated via the widely used low-loss criterion (Han et al., 2018b; Wei et al., 2020), where
a dynamic memory rate R(t) ∈ [0, 1] is set for DNN to gradually distinguish (1 - R(t)) data
with highest loss value as noisy samples while keeping other samples as clean set. Note that this
simple separation criterion can not strictly eliminate noisy samples (see Fig. 1). Hence we choose
to handle them respectively, where Xc update DNN parameters via sample credibility guided loss
adjustment (3.1), and Xu is leveraged via another label learning scheme( 3.2). A detailed algorithm
pipeline can be found at Appendix A.1.
3.1	Sequential credibility modeling
Sequential credibility analysis. Previous works prefer to assess the data reliability purely based on
its statistical property on a single point of time (e.g. the loss value in current epoch) during training
process, i.e. they regard the credibility w(x, y) of the i-th data sample (x, y) proportional to the joint
distribution of its data-label pair,
w(x,y) X P(x,y).	(1)
However, as shown in Fig. 1, the training curve of normal and noisy samples usually yield different
statistic information, where noisy samples usually have relatively larger loss values and poorer pre-
diction consistency compared with clean ones, therefore the historical record of data training is also
informative enough to help distinguish noisy and clean data.
4
Under review as a conference paper at ICLR 2022
This observation inspires us to estimate the data credibility in a sequential manner. To be specific,
we define a sequence with length n as:
Ln = [ft, ft-1, ∙∙∙ , ft-n+ι],	ft = f(x; θt).	(2)
Eq (2) illustrates a sliding window covering the feature snapshot of data from previous n epochs to
current time point, where θt denotes the model parameters at the t-th epoch, and we model the data
credibility with the likelihood and consistency of this historical sequences,
w(x, y) H C (Ln, y)log P (Lf∣ft-n, y).	(3)
The Eq (3) can be decoupled with two items, where C(Ltn, y) measures the stability of training
sequence given its label y, while log P (Ltn|ft-n, y) denotes log-likelihood of sequence generated
from the (t - n)-th data observation of neural network training process. To estimate the sequential
log-likelihood, we further assume that the observation in sequence Ltn conforms to a certain markov
property as:
ft ⊥ fi|(ft-1, y) ∀ i <t- 1.	(4)
The assumption in Eq (4) is reasonable since in most iterative learning algorithm like SGD, the data
feature distribution is only decided by last observation and its label. With this assumption, we can
further derive the likelihood as:
log P (Ln∣ft-n, y) = log P (ftL-ι, y) + log P(Ln-I‰, y)
n-1
=X log P(ft-i ∖Lrn-Lι ,y)	-
i=0	(5)
n-1
= XlogP (ft-i|ft-i-1,y).
i=0
With Eq (5), we can represent the sequential likelihood as the summation of conditional likelihood
of data observation at each iteration within a sliding window of length n. In implementation, we
can apply a normalized mixture model like GMM or BMM (Arazo et al., 2019; Li et al., 2020)
as estimator to estimate the conditional probability P (ft-i|ft-i-1, y) in Eq (5). Meanwhile, with
the conditional probability estimation, the stability measurement C(Ltn, y) is further designed as a
modulator to suppress loss on training sequence with intense fluctuation,
u n-1
C(Ln,y) = 1-t - χ(P (ft-i∣ft-i-ι,y) - P(Lky))).	(6)
n-1
P(Ln ,y) = - X P(fι∖ft-i-ι,y).	⑺
Adaptively loss adjustment. The sequential likelihood P(Ln) and stability measurement C(Ln,y)
reflects how confident of the sample being clean. With the estimated credibility we reweight loss to
update DNN as:
θt+ι = Ot- nV (iχ1-∣ X w(χ, y)L(f (x; θt), y)).	⑻
c (x,y)∈Xc
Where L is the objective function. w(x, y) is the sample credibility and it modulates the contribution
of each sample through gradient descending algorithm. Note that Eq. 8 is only applied on clean set
Xc, in this way, negative impact of hard noisy samples within Xc can be mitigated.
Objective function. Inspired by the design of symmetric cross entropy (SCE) function (Wang et al.,
2019), a symmetric JS-divergence function with a co-regularization term is leveraged in CREMA as:
L = Djs(y∣∣h(fι(χ; θ))) + Djs(y∣∣h(f)(χ; θ))) + DJS (h(fι(χ; θ))∣∣h(f)(x; θ))),
(9)
5
Under review as a conference paper at ICLR 2022
Where, h(x) is the softmax probabilities produced by model. The reason we choose JS-divergence
instead of cross entropy (CE) as loss function is that, CE tend to over-fit noisy samples as these
samples cause relatively large gradient values during training. JS-divergence mitigates this problem
via using predictions as supervising signals as well. Since for noisy samples, DNN predictions are
usually more reliable that its label. Following previous work (Tanaka et al., 2018), a prior label
distribution term and a negative entropy term are included to regularize training and further alleviate
the over-fitting problem.
3.2 Selective label distribution learning
Following the divide-and-conquer idea, we attempt to leverage the separated noisy samples Xu as
well. Some hard clean samples are blended with the separated noisy ones. Thus instead of discarding
these wrongly labeled data as in sample detection methods (Han et al., 2018b; Wei et al., 2020), we
resort to label correction approaches (Tanaka et al., 2018; Yi & Wu, 2019) to exploit them with
gradually corrected labels and further boost performance.
Specifically, labels of Xu are treated as extra parameters, and updated through back-propagation
to optimize a certain objective, this means both the network parameters and labels are updated
simultaneously during training process, where original one-hot labels y will turn into a soft la-
bel distribution y = h(y) after updating. Formally, y is updated as y J y - λ(∂Lι/∂y).
Where λ is learning rate and Ll is the objective to supervise the label correction process as
Ll = Djs(h(fι(χ; θ)l∣y) + Djs(h(f2(χ; θ)l∣y).
Empirical insight. In our experiments. we find that global label learning strategy (i.e., correct-
ing labels of all training data) suffers from correction error in clean data. This can be observed
from Fig. 3 (a), large gradient value will also be imposed on lots of correctly-labeled samples, con-
sequently labels for these clean samples are unnecessarily updated. Compared with global label
correction manners, we choose to only update the separated noisy samples Xu (mostly noisy). As
shown in Fig. 3 (b), the proposed selective label correction strategy focuses more on learning noisy
labels. The number of correctly-labeled samples with large gradient value is way less than a global
correction scheme. Experiments in Sec 4.3 also quantitatively verify the effectiveness of the selec-
tive label learning strategy over global label learning manner.
4	Experiments
4.1	Datasets and Implementation Details
Datasets. To validate the effectiveness of the proposed method, we experimentally investigate on
three synthetic noisy datasets, i.e., MNIST, CIFAR-10, CIFAR-100 (Krizhevsky et al., 2009) and
two real-world label noise datasets, i.e., Clothing1M (Xiao et al., 2015a), and Animal10N (Song
et al., 2019). MNIST consists of 70,000 images of size 28 × 28 for 10 classes, in which 60,000
images for training and the left 10,000 images for testing. Both CIFAR-10 and CIFAR100 contain
50,000 training images and 10,000 testing images of size 32 × 32 × 3. Differently, the former has 10
classes, while CIFAR-100 has 100 classes. For the Clothing1M, it is a large-scale real-world noisy
dataset which is collected from multiple online shopping websites. It contains 1 million training
images and clean training subsets (47K for training, 14K for validation and 10K for test) with 14
classes. Noise rate for this dataset is around 38.5%. Animal-10N contains 55,000 human labeled
online images for 10 confusing animals. It contains approximately 8% noisy samples. Following
previous works (Song et al., 2019; Zhang et al., 2021), 50,000 images are exploited as a training set
while the left for testing.
Implementation Details. For the three synthetic noisy datasets, we follow the setting in previous
works (Han et al., 2018b; Yu et al., 2019; Wei et al., 2020), experiments with three kind of noise
type are considered, i.e., symmetric noise (uniformly random), asymmetric noise and pairflip noise.
Specifically, symmetric noise is generated by replacing labels in each class with labels of other
classes uniformly. Asymmetric noise simulates fine-grained classification (for example, lynx and
cat in Animal-10N (Song et al., 2019) with noisy labels, where labels are corrupted to a set of
similar classes. Pairflip noise is generated by flipping each class to its adjacent class. Varying noise
rates τ are conducted to fully evaluate the proposed method, where τ ∈ {20%, 50%, 80%} for
symmetric label noise , τ = 40% for asymmetric noise and τ ∈ {40%, 45%} for pairflip label noise.
6
Under review as a conference paper at ICLR 2022
Table 1: Average test accuracy (%) on MNIST over the last ten epochs.
Noise rates T I	Standard I	PENCIL I	Co-teaching I	Co-teaching+ I	JoCoR I	CREMA (ours)
Symmetry-20% ∣	79.94 ± 0.10 I	97.20 ± 0.53 I	97.40 ± 0.09 I	97.81 ± 0.03 I	97.98 ± 0.02 I	98.40 ± 0.14
Symmetry-50% ∣	52.92 ± 0.21 I	96.22 ± 0.13 I	92.47 ± 0.14 I	95.80 ± 0.09 I	96.35 ± 0.02 I	98.07 ± 0.24
Symmetry-80% ∣	23.95 ± 0.18 I	87.64 ± 0.25 I	82.04 ± 0.43 I	58.92 ± 0.37 I	85.51 ± 0.08 I	92.02 ± 0.54
Asymmetry-40% ∣	78.80 ± 0.09 I	94.39 ± 0.37 I	90.57 ± 0.04 I	93.28 ± 0.43 I	94.14 ± 0.12 I	97.15 ± 0.26
Pairflip-40% ∣	58.51 ± 0.29 I	94.06 ± 0.09 I	90.73 ± 0.22 I	89.91 ± 0.31 I	93.47 ± 0.10 I	95.80 ± 0.51
Pairflip-45% ∣	54.54 ± 0.30 I	90.73 ± 0.29 I	89.42 ± 0.22 I	85.81 ± 0.30 I	91.30 ± 0.25 I	94.12 ± 0.58
Table 2: Average test accuracy (%) on CIFAR-10 over the last ten epochs.						
Noise rates T ∣	Standard ∣	PENCIL I	Co-teaching ∣	Co-teaching+ ∣	JoCoR I	CREMA (ours)
Symmetry-20% ∣	68.67 ± 0.11 I	78.78 ± 0.15 I	82.56 ± 0.24 I	82.27 ± 0.21 I	85.73 ± 0.19 I	86.32 ± 0.16
Symmetry-50% ∣	42.31 ± 0.18 I	64.71 ± 0.27 I	72.97 ± 0.22 I	63.01 ± 0.33 I	79.53 ± 0.10 I	81.63 ± 0.13
Symmetry-80% ∣	15.94 ± 0.07 I	26.96 ± 0.37 I	24.03 ± 0.18 I	17.96 ± 0.06 I	27.30 ± 0.08 I	29.66 ± 0.16
Asymmetric-40% ∣	70.04 ± 0.08 I	70.06 ± 0.28 I	75.96 ± 0.15 I	72.21 ± 0.43 I	76.31 ± 0.21 I	82.49 ± 0.13
Pairflip-40% ∣	51.66 ± 0.11 I	75.26 ± 0.18 I	75.10 ± 0.23 I	57.59 ± 0.45 I	68.56 ± 0.16 I	85.00 ± 0.13
Pairflip-45% ∣	45.78 ± 0.13 I	71.18 ± 0.28 I	70.68 ± 0.23 I	49.60 ± 0.23 I	57.68 ± 0.21 I	82.94 ± 0.12
Table 3: Average test accuracy (%) on CIFAR-100 over the last ten epochs.						
Noise rates T ∣	Standard ∣	PENCIL I	Co-teaching ∣	Co-teaching+ ∣	JoCoR I	CREMA (ours)
Symmetry-20% ∣	34.72 ± 0.07 I	52.11 ± 0.21 I	50.48 ± 0.24 I	49.27 ± 0.03 I	53.41 ± 0.09 I	57.21 ± 0.25
Symmetry-50% ∣	16.86 ± 0.09 I	39.89 ± 0.30 I	38.24 ± 0.26 I	40.04 ± 0.70 I	43.37 ± 0.09 I	43.95 ± 0.42
Symmetry-80% ∣	4.60 ± 0.12 I	16.08 ± 0.15 I	11.78 ± 0.12 I	13.44 ± 0.37 I	12.33 ± 0.13 I	17.10 ± 0.19
Asymmetric-40% ∣	26.93 ± 0.10 I	32.81 ± 0.23 I	33.36 ± 0.28 I	33.62 ± 0.39 I	32.66 ± 0.13 I	38.61 ± 0.25
Pairflip-40% ∣	27.48 ± 0.12 I	33.83 ± 0.52 I	33.94 ± 0.18 I	33.80 ± 0.25 I	33.89 ± 0.12 I	38.06 ± 0.34
Pairflip-45% ∣	24.21 ± 0.11 I	29.01 ± 0.28 I	29.57 ± 0.15 I	26.93 ± 0.34 I	28.83 ± 0.10 I	32.50 ± 0.29
For real-world noisy Clothing1M dataset, following Yi & Wu (2019); Zhang et al. (2021), we do
not use the 50K clean data, and a randomly sampled pseudo-balanced subset includes about 260K
images is leveraged as training data.
For the network structure, a 9-layer CNN with Leaky-ReLU activation function (Han et al., 2018b)
is used for MNIST, CIFAR-10 and CIFAR-100, while ResNet-50 is adopted for Clothing1M and
Animal-10N datasets. The batch size is set as 64 for all the datasets. For fair comparisons, we
train our model for 200 epochs in total and choose the average test accuracy of last 10 epochs as
the final result in three synthetic noisy datasets. Total training epochs for Clothing1M and Animal-
10N are 80 and 150 respectively. Additionally, all the methods are implemented in PyTorch and
run on NVIDIA Tesla V100 GPUs. Moreover, we use Adam optimizer for all the experiments
and set the initial learning rate as 0.001, then it is degraded by a factor of 5 every 30 epochs for
Clothing1M and 50 epochs for Animal-10N. The two classifiers in our methods are two networks
with the same structure but different initialization parameters. Following Han et al. (2018b), R(t)
is linearly decreased along with training until reach a lower bound value σ, for Clothing1M and
Animal-10N, we empirically set lower bound σ as 0.8 and 0.92 respectively.
4.2	Comparison with state-of-the-art methods
Results on synthetic noisy datasets. Table 1, Table 2, and Table 3 show the detailed results of the
proposed CREMA and other methods in multiple synthetic noisy cases on three widely used datasets,
i.e., MNIST, CIFAR-10, CIFAR-100. Specifically, four state-of-the-art LNL methods are chosen for
comparison: PENCIL (Yi & Wu, 2019), Co-teaching (Han et al., 2018b), Co-teaching+ (Yu et al.,
2019), JoCoR (Wei et al., 2020). Standard DNN training with cross entropy is also included as
baseline. All the results of these methods are reproduced with their public code and suggested
hyper-parameters for fair comparison. From these tables, we can observe that all these methods
show better performance than Standard in the most natural Symmetry-20% case, which verifies
7
Under review as a conference paper at ICLR 2022
Table 4: Comparison with state-of-the-art methods in test accuracy on Clothing1M. “LA”, “LC” and
“ND” denote “Loss Adjustment”, “Label Correction” and “Noisy sample Detection” respectively.
Results for baselines are quoted from original papers.
Method	Category LA LC ^D-	Test Accuracy (%)
Cross-Entropy GCE (Zhang & Sabuncu, 2018)	X	69.21 69.75
SCE (Wang et al., 2019)	X	71.02
F-correction (Patrini et al., 2017)	X	69.84
M-correction (Arazo et al., 2019)	X	71.00
Masking (Han et al., 2018a)	X	71.10
Joint-Optim (Tanaka et al., 2018)	X	72.23
PENCIL (Yi & Wu, 2019)	X	73.49
PLC (Zhang et al., 2021)	X	74.02
Self-Learning (Han et al., 2019)	X	74.45
Co-teaching (Han et al., 2018b)	X	70.15
JoCoR (Wei et al., 2020)	X	70.30
C2D (Zheltonozhskii et al., 2021)	X	74.30
DivideMix (Li et al., 2020)	X	74.76
CREMA (Ours)	XXX	74.53
Table 5: Comparison with state-of-the-art methods in test accuracy on Animal-10N. short for cat-
egory is the same as Table 4. Results for baselines approaches are quoted from Song et al. (2019)
and Zhang et al. (2021).				
Method	Category			Test Accuracy (%)
	LA	LC	ND	
Cross-Entropy				79.4
ActiveBias (Chang et al., 2017)	X			80.5
PLC (Zhang et al., 2021)		X		83.4
Co-teaching (Han et al., 2018b)			X	80.2
SELFIE (Song et al., 2019)		X	X	81.8
CREMA (Ours)		X	X	84.2
their robustness. Among them, JoCoR and PENCIL perform much better over other methods. How-
ever, when it comes to Pairflip-40% and Pairflip-45% cases, their performance drops significantly.
On the contrary, the proposed CREMA can achieve consistent improvements over other methods
on three benchmarks across various noise settings. In the Pairflip-40% and Pairflip-45% cases, the
proposed method outperforms other baselines by a large margin. Specifically, CREMA can achieve
16.44% and 25.26% improvement in accuracy over JoCoR on CIFAR-10. When dealing with ex-
tremely noisy scenario, e.g. Symmetry-80%, CREMA can also perform generally better than other
methods.The result demonstrates the superiority of the proposed method across various types and
levels of label noise.
Results on real-world noisy datasets. Experiments on real-word noisy datasets Clothing1M (Xiao
et al., 2015a), Animal-10N (Song et al., 2019) are also conducted to verify the effectiveness of the
proposed method. The baseline methods are chosen from recently proposed LNL methods. Specifi-
cally, several loss adjustment methods, including GCE (Zhang & Sabuncu, 2018), SCE (Wang et al.,
2019), F-correction (Patrini et al., 2017), M-correction (Arazo et al., 2019), Masking (Han et al.,
2018a), ActiveBias (Chang et al., 2017), label correction methods, including Joint-Optim (Tanaka
et al., 2018), PENCIL (Yi & Wu, 2019), Self-Learning (Han et al., 2019), PLC (Zhang et al.,
2021), noisy sample detection approaches, including Co-teaching (Han et al., 2018b), JoCoR (Wei
et al., 2020), C2D (Zheltonozhskii et al., 2021), DivideMix (Li et al., 2020) and a hybrid method
SELFIE (Song et al., 2019) are compared with the proposed method. Table 4 and Table 5 show re-
sults on two real-world noisy datasets respectively. On large-scale Clothing1M dataset, CREMA out-
performs all compared methods and achieves comparable performance with DivideMix. Note that
DivideMix requires more training time, since it involves multiple rounds of forward computations
within a single training iteration. While CREMA follows the standard DNN training procedure, and
is similar to other co-training methods (Han et al., 2018b; Yu et al., 2019; Wei et al., 2020) in terms
8
Under review as a conference paper at ICLR 2022
Table 6: Ablation studies of each component
within CREMA on Clothing1M dataset.
Method	Test Accuracy (%)
Baseline	72.81
+ Selective label update	73.25
+ Sequential likelihood	74.00
+ Stability measurement	74.53
Table 7: Investigations on different mixture
models on ClothingIM dataset.
Estimator ∣ Test Accuracy (%)
BMM	74.09
GMM	74.53
Table 8: Investigations on length of sequence n on ClOthingIM dataset.
Length of sequence n ∣ Il 2∣3∣4∣5∣6
Test Accuracy (%)	∣ 73.25 ∣ 73.99 ∣ 74.53 ∣ 74.40 ∣ 74.27 ∣ 73.96
of training time, since the time cost for sample credibility modeling is negligible compared with
DNN update. State-of-the-art result is achieved by CREMA in Animal-10N as well. This indicates
that the proposed CREMA can work well on high noise level (i.e., Clothing1M) and fine-grained
(i.e., Animal-10N) real-world noisy datasets across various noise levels.
4.3 Ablation studies
•	Component Analysis. CREMA contains several important components, including selective label
learning strategy, sequential likelihood logP (Ltn|ft-n, y) and stability measurement C(Ltn, y). To
verify the effectiveness of each component, we conduct experiments on large-scale noisy dataset
Clothing1M. The baseline method is built upon a simple co-teaching framework (Wei et al., 2020)
combined with global label correction scheme (as in Yi & Wu (2019)), without the credibility guided
loss adjustment strategy. The results are shown in Table 6, we can see that, conform to the observa-
tion on Fig. 3, the proposed selective label learning strategy achieves better result compared with the
global correction counterpart. The sequential likelihood and stability measurement further boost the
model performance with 0.75% and 0.53% accuracy gain, this indicate that the proposed sequential
sample credibility modeling can effectively combat hard noisy samples mixed with clean ones. With
all the three key components above, CREMA can achieve 74.53% test accuracy on Clothing1M.
•	Length of sequence n. We also conduct experiments to investigate how the length of sequence n
affects the performance. Table 8 shows results on Clothing1M with various values of n. It can be
observed that increasing the length of sequence helps achieve higher accuracy at first but turn poor
after hitting the peak value. Intuitively, no temporal information is provided when n = 1, CREMA
can not utilize consistency metric, thus leading to a inferior result. When n is larger than 4, we
also notice that performance degrades, this is probably due to unreliable model inside the very long
sequence can do harm to sample credibility modeling and reversely hinder the final result.
•	Effect of different estimators. Normalized mixture model plays the roles of estimating the condi-
tional probability P (ft|ft-1, y) in Eq (5). We compare two different estimators, Gaussian Mixture
Model (GMM) (Permuter et al., 2006) and Beta Mixture Model (BMM) (Arazo et al., 2019) on
Clothing1M. Table 7 shows the results. We can see that GMM obtain a relatively higher test ac-
curacy, but BMM can also achieve good result (74.09%) as well. This indicate that the choice of
probabilistic model is not sensitive to the final result.
5 Conclusion
In this paper, we propose a novel end-to-end robust learning method, called CREMA. Towards the
problem that previous works lack the consideration of intrinsic difference among difficulties of noisy
samples. CREMA follows the idea of divide-and-conquer that separate clean and noisy samples via
estimating the credibility of each training sample. Two different branches are designed to handle
the imperfectly separated samples respectively. For easily recognizable noisy samples, we apply a
selective label correction scheme that avoiding erroneous label update on clean samples. For hard
noisy samples that blended with clean ones, likelihood estimation of historical credibility sequence
adaptively modulate the loss term of each sample during training. Extensive experiments conducted
on synthetic and real-world noisy datasets demonstrate the superiority of the proposed method.
9
Under review as a conference paper at ICLR 2022
References
Eric Arazo, Diego Ortego, Paul Albert, Noel E O’Connor, and Kevin McGuinness. Unsupervised
label noise modeling and loss correction. In Proc. International Conference on Machine Learning
(ICML), 2019. 3, 5, 8, 9
Devansh Arpit, StanislaW Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxin-
der S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. A closer
look at memorization in deep netWorks. In Proc. International Conference on Machine Learning
(ICML), pp. 233-242, 2017. 1
David Berthelot, Nicholas Carlini, Ian J. GoodfelloW, Nicolas Papernot, Avital Oliver, and Colin
Raffel. Mixmatch: A holistic approach to semi-supervised learning. Proc. Advances in Neural
Information Processing Systems (NeurIPS), 2019. 4
HaW-Shiuan Chang, Erik Learned-Miller, and AndreW McCallum. Active Bias: Training more
accurate neural netWorks by emphasizing high variance samples. In Proc. Advances in Neural
Information Processing Systems (NeurIPS), pp. 1002-1012, 2017. 3, 4, 8
Mostafa Dehghani, Aliaksei Severyn, Sascha Rothe, and Jaap Kamps. Avoiding your teacher’s
mistakes: Training neural netWorks With controlled Weak supervision. arXiv preprint
arXiv:1711.00313, 2017a. 3
Mostafa Dehghani, Aliaksei Severyn, Sascha Rothe, and Jaap Kamps. Learning to learn from Weak
supervision by full supervision. In Proc. Advances in Neural Information Processing Systems
Workshop (NeurIPSW), 2017b. 3
Aritra Ghosh, Himanshu Kumar, and PS Sastry. Robust loss functions under label noise for deep
neural netWorks. In Proc. Association for the Advancement of Artificial Intelligence (AAAI), 2017.
3
Jacob Goldberger and Ehud Ben-Reuven. Training deep neural-netWorks using a noise adaptation
layer. In Proc. International Conference on Learning Representations (ICLR), 2017. 3
Bo Han, Jiangchao Yao, Gang Niu, Mingyuan Zhou, Ivor Tsang, Ya Zhang, and Masashi Sugiyama.
Masking: A neW perspective of noisy supervision. In Proc. Advances in Neural Information
Processing Systems (NeurIPS), pp. 5836-5846, 2018a. 3, 8
Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi
Sugiyama. Co-teaching: Robust training of deep neural netWorks With extremely noisy labels. In
Proc. Advances in Neural Information Processing Systems (NeurIPS), pp. 8527-8537, 2018b. 1,
2, 3, 4, 6, 7, 8, 13
Jiangfan Han, Ping Luo, and Xiaogang Wang. Deep self-learning from noisy labels. In Proc. IEEE
International Conference on Computer Vision (ICCV), pp. 5138-5147, 2019. 3, 8
Dan Hendrycks, Mantas Mazeika, Duncan Wilson, and Kevin Gimpel. Using trusted data to train
deep netWorks on labels corrupted by severe noise. In Proc. Advances in Neural Information
Processing Systems (NeurIPS), pp. 10456-10465, 2018. 1, 3
Michael E Houle. Local intrinsic dimensionality I: An extreme-value-theoretic foundation for sim-
ilarity applications. In Proc. International Conference on Similarity Search and Applications
(SISAP), pp. 64-79, 2017. 3
Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. MentorNet: Learning data-
driven curriculum for very deep neural netWorks on corrupted labels. In Proc. International
Conference on Machine Learning (ICML), 2018. 1, 3, 4
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
2009. 6
Junnan Li, Richard Socher, and Steven CH Hoi. Dividemix: Learning With noisy labels as semi-
supervised learning. arXiv preprint arXiv:2002.07394, 2020. 4, 5, 8
10
Under review as a conference paper at ICLR 2022
Yuncheng Li, Jianchao Yang, Yale Song, Liangliang Cao, Jiebo Luo, and Li-Jia Li. Learning
from noisy labels with distillation. In Proc. IEEE International Conference on Computer Vision
(ICCV),pp.1910-1918,2017. 3
Or Litany and Daniel Freedman. Soseleto: A unified approach to transfer learning and training with
noisy labels. arXiv preprint arXiv:1805.09622, 2018. 3
Tongliang Liu and Dacheng Tao. Classification with noisy labels by importance reweighting. IEEE
Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 38(3):447-461, 2015. 3
Yueming Lyu and Ivor W Tsang. Curriculum loss: Robust learning and generalization against label
corruption. In Proc. International Conference on Learning Representations (ICLR), 2020. 3
Xingjun Ma, Yisen Wang, Michael E Houle, Shuo Zhou, Sarah M Erfani, Shu-Tao Xia, Sudanthi
Wijewickrema, and James Bailey. Dimensionality-driven learning with noisy labels. In Proc.
International Conference on Machine Learning (ICML), 2018. 3
Eran Malach and Shai Shalev-Shwartz. Decoupling” when to update” from” how to update”. In
Proc. Advances in Neural Information Processing Systems (NeurIPS), pp. 960-970, 2017. 3
Duc Tam Nguyen, Chaithanya Kumar Mummadi, Thi Phuong Nhung Ngo, Thi Hoai Phuong
Nguyen, Laura Beggel, and Thomas Brox. SELF: Learning to filter noisy labels with self-
ensembling. In Proc. International Conference on Learning Representations (ICLR), 2020. 3
Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making
deep neural networks robust to label noise: A loss correction approach. In Proc. IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), pp. 1944-1952, 2017. 1, 3, 8
H. Permuter, J. M. Francos, and I. Jermyn. A study of gaussian mixture models of color and texture
features for image classification and segmentation. Pattern Recognition (PR)., 39:695-706, 2006.
9
Scott Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew
Rabinovich. Training deep neural networks on noisy labels with bootstrapping. In Proc. Interna-
tional Conference on Learning Representations (ICLR), 2015. 2, 3
Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples for
robust deep learning. In Proc. International Conference on Machine Learning (ICML), 2018. 3
Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou, Zongben Xu, and Deyu Meng. Meta-
Weight-Net: Learning an explicit mapping for sample weighting. In Proc. Advances in Neural
Information Processing Systems (NeurIPS), pp. 1917-1928, 2019. 3
Hwanjun Song, Minseok Kim, and Jae-Gil Lee. SELFIE: Refurbishing unclean samples for robust
deep learning. In Proc. International Conference on Machine Learning (ICML), pp. 5907-5915,
2019. 3,6, 8
Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, and Kiyoharu Aizawa. Joint optimization frame-
work for learning with noisy labels. In Proc. IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 5552-5560, 2018. 1, 3, 6, 8
Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin, Abhinav Gupta, and Serge Belongie. Learning
from noisy large-scale datasets with minimal supervision. In Proc. IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), July 2017. 3
Ruxin Wang, Tongliang Liu, and Dacheng Tao. Multiclass learning with partially corrupted labels.
IEEE Transactions on Neural Networks and Learning Systems, 29(6):2568-2580, 2017. 3
Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey. Symmetric cross en-
tropy for robust learning with noisy labels. In Proc. IEEE International Conference on Computer
Vision (ICCV), pp. 322-330, 2019. 3, 5, 8
Hongxin Wei, Lei Feng, Xiangyu Chen, and Bo An. Combating noisy labels by agreement: A
joint training method with co-regularization. In Proc. IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), pp. 13726-13735, 2020. 2, 3,4, 6, 7, 8, 9
11
Under review as a conference paper at ICLR 2022
Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive noisy
labeled data for image classification. In Proc. IEEE Conference on Computer Vision and Pattern
Recognition (CVPR),pp. 2691-2699, 2015a. 1, 6, 8
Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive noisy
labeled data for image classification. In Proc. IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 2691-2699, 2015b. 3
Quanming Yao, Hansi Yang, Bo Han, Gang Niu, and J. Kwok. Searching to exploit memorization
effect in learning with noisy labels. In Proc. International Conference on Machine Learning
(ICML), 2020. 3
Kun Yi and Jianxin Wu. Probabilistic end-to-end noise correction for learning with noisy labels.
In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 7017-7025,
2019. 1,3,6,7, 8,9
Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor W Tsang, and Masashi Sugiyama. How does
disagreement help generalization against label corruption? In Proc. International Conference on
Machine Learning (ICML), 2019. 1, 3, 6, 7, 8
Chiyuan Zhang, Samy Bengio, Moritz Hardt, B. Recht, and Oriol Vinyals. Understanding deep
learning requires rethinking generalization. In Proc. International Conference on Learning Rep-
resentations (ICLR), 2017. 1
Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, and David Lopez-Paz. mixup: Beyond empir-
ical risk minimization. In Proc. International Conference on Learning Representations (ICLR),
2018. 4
Yikai Zhang, Songzhu Zheng, Pengxiang Wu, Mayank Goswami, and Chao Chen. Learning with
feature-dependent label noise: A progressive approach. In Proc. International Conference on
Learning Representations (ICLR), 2021. 3, 6, 7, 8
Zhilu Zhang and Mert Sabuncu. Generalized cross entropy loss for training deep neural networks
with noisy labels. In Proc. Advances in Neural Information Processing Systems (NeurIPS), pp.
8778-8788, 2018. 3, 8
Zizhao Zhang, Han Zhang, Sercan O Arik, Honglak Lee, and Tomas Pfister. Distilling effective
supervision from severe label noise. In Proc. IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 9294-9303, 2020a. 3
Zizhao Zhang, Han Zhang, Sercan O Arik, Honglak Lee, and Tomas Pfister. Distilling effective
supervision from severe label noise. In Proc. IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 9294-9303, 2020b. 3
Evgenii Zheltonozhskii, Chaim Baskin, Avi Mendelson, Alex M Bronstein, and Or Litany. Con-
trast to divide: Self-supervised pre-training for learning with noisy labels. arXiv preprint
arXiv:2103.13646, 2021. 4, 8
12
Under review as a conference paper at ICLR 2022
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
Algorithm 1: CREMA. Line 5-9: sequential credibility modeling; Line 10-12: selective label update.
Input: network parameters θ(1) and θ(2), training dataset D, dynamic memory rate R(t), soft label
distribution y, memory sequence Lft and Lζ,t.
while t < MaxEpoch do
Fetch mini-batch Dn from D;
Divide Dn into Xc and Xu based on R(t); // divide samples into clean and noisy
set based on low-loss criterion
for xc ∈ Xc do
Calculate w(xc, yc) based on Eq (6) and Eq (7);	// sample credibility modeling
Update θ(1) and θ(2) based on Eq. (8);	// adaptive loss adjustment
end
for xu ∈ Xu do
Update y, θ(1),and θ(2) through gradient descent;	/ / update soft label
distribution and model parameters
end
Update R(t);
Update L1n,t and L2n,t;	// enqueue feature snapshot of current epoch
end
Output: θ(1) andθ(2).
A Appendix
A.1 Algorithm details
Algorithm 1 delineates the proposed CREMA. As illustrated in Sec. 3, CREMA is built on a divide-
and-conquer framework. Firstly, clean set Xc and noisy set Xu are separated based on low-loss
criterion (Han et al., 2018b). For Xc, we compute the likelihood of historical credibility sequence,
which helps to adaptively modulate the loss term of each training sample. As for Xu, a selective label
correction scheme is leveraged to update label distribution and model parameters simultaneously.
After each training epoch, memory sequence L1n,t and L2n,t are updated with the feature snapshot of
most current epoch.
13