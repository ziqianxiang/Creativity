Under review as a conference paper at ICLR 2022
Sublinear Least- S quares Value Iteration via
Locality Sensitive Hashing
Anonymous authors
Paper under double-blind review
Ab stract
We present the first provable Least-Squares Value Iteration (LSVI) algorithm that
achieves runtime complexity sublinear in the number of actions. We formulate
the value function estimation procedure in value iteration as an approximate max-
imum inner product search problem and propose a locality sensitive hashing (LSH)
type data structure to solve this problem with sublinear time complexity. More-
over, we build the connections between the theory of approximate maximum inner
product search and the regret analysis of reinforcement learning. We prove that,
with our choice of approximation factor, our Sublinear LSVI algorithms maintain
the same regret as the original LSVI algorithms while reducing the runtime com-
plexity to sublinear in the number of actions. To the best of our knowledge, this
is the first work that combines LSH with reinforcement learning that resulting in
provable improvements. We hope that our novel way of combining data structures
and iterative algorithm will open the door for further study into the cost reduction
in optimization.
1	Introduction
Reinforcement learning (RL) is an essential problem in machine learning that targets maximizing
the cumulative reward when an agent is taking actions within an unknown environment Sutton &
Barto (2018). RL is a trending topic over the last few years. We have seen a remarkable growth
of RL applications in Go Silver et al. (2016), robotics Kober et al. (2013), dialogue systems Li
et al. (2016) and recommendation Zheng et al. (2018). In practical RL, most approaches Watkins &
Dayan (1992); Silver et al. (2014); Jin et al. (2018) perform iterative-type algorithms that modify the
choice of actions at each step based on the agent iteration with the environment. This iterative nature
causes the training of RL algorithms to be expensive. For instance, it takes around three weeks to
train the agent in AlphaGo Silver et al. (2016). Moreover, the training is conducted on 50 GPUs,
which means the training of RL on limited computational resources is almost infeasible.
Given the efficiency bottleneck of RL algorithms, it is natural to ask the following question.
Are there some TCS techniques that could apply to iterative-type RL algorithms and improve their
running time efficiency?
The practical success of a typical TCS technique, Locality sensitive hashing (LSH), shed lights on
answering the question. LSH is a randomized data structure with provable efficiency in approxi-
mate nearest neighbor search (ANN) Indyk & Motwani (1998); Charikar (2002); Datar et al. (2004);
Shakhnarovich et al. (2005); Andoni & Indyk (2008); Andoni (2009); Andoni et al. (2014); An-
doni & Razenshteyn (2015); Andoni et al. (2015; 2017b); Christiani (2017); Razenshteyn (2017);
Andoni et al. (2018); Wei (2019); Dong et al. (2020). Meanwhile, LSH could also be extended to
maximum inner product search (Max-IP) Shrivastava & Li (2014). Moreover, in practical machine
learning (ML), LSH has been widely used in many fundamental learning problems to improve the
practical running time of iterative-type algorithms such as gradient descents Chen et al. (2019), back-
propagation Chen et al. (2020); Daghaghi et al. (2021); Chen et al. (2021) and MCMC sampling Luo
& Shrivastava (2019). However, the current empirical combination of LSH with iterative-type algo-
rithms does not have theoretical support. It is unknown to give a provable guarantee for the impact
of LSH over the total number of iterations and per cost iteration of iterative-type algorithms.
1
Under review as a conference paper at ICLR 2022
Inspired by a large number of successes about using LSH to tackle efficiency bottlenecks in practice,
it is natural to ask the following question.
Is there an interesting regime (e.g., some iterative-type algorithms) where we can apply LSH to give
provable improvement?
In this work, we answer both questions by proposing a theoretical framework that combines LSH
with RL. We focus on Q-learning Watkins & Dayan (1992), a simple and flexible type of RL frame-
work that directly optimizes the maximum expected reward based on the outcome of actions that the
agent taken at each step. Theoretical analysis also suggests that Q-learning is proved to be sample ef-
ficient Jin et al. (2018). However, the running time efficiency of Q-learning requires improvement in
practical scenarios. We identify that the runtime complexity of Q-learning is dominated by the value
function estimation procedure. Value function estimation requires a linear scan over all the actions
at each step, which is unscalable in real RL tasks. For instance, in news recommendation systems,
the action of an RL agent is recommending an article to the users. The iterative-type Q-learning al-
gorithm scan over all articles at each iteration to find the action that maximizes the expected reward.
In practice, this search space is too large so that linear scan is prohibitive. Therefore, reducing the
enormous overhead in value function estimation over the large action space becomes a significant
research problem in Q-learning.
We focus on applying LSH techniques to reduce this value function estimation overhead in the
iterative-type Q-learning algorithm. However, combing LSH with any iterative-type algorithm in
Q-learning is challenging due to four major reasons: (1) It remains unknown whether the linear scan
over all possible actions in Q-learning could be formulated as an ANN or Max-IP problem (2) LSH
accelerate this linear scan by introducing an error in estimating value function. This approximation
error would accumulate in the value iteration and break the current upper bound for regret. (3)
Although LSH has demonstrated success in practical ML, its theoretical efficiency guarantee in RL
remains unknown. (4) The Q-learning algorithm would query LSH at each step. As the query in
each step depends on the previous step, the total failure probability of LSH over this adaptive query
sequence could not be union bounded due to correlations.
In this work, we solve these challenges affirmatively by presenting a Q-learning algorithm that
uses LSH type approximate Max-IP data structure. We focus on the Least-Squares Value Iteration
(LSVI) Bradtke & Barto (1996) and its extensions with UCB exploration (LSVI-UCB Jin et al.
(2020)). We also discuss LSVI-UCB under policy switch limitation Gao et al. (2021) or model-
free setting Wang et al. (2020a). We connect the theory of Max-IP with reinforcement learning by
formulating the value function estimation in LSVI and LSVI-UCB as an approximate Max-IP prob-
lem. Then, we propose Sublinear LSVI and Sublinear LSVI-UCB, two algorithms with LSH that
have value iteration running time sublinear in the number of actions. For LSVI-UCB, we extend
the LSH type Max-IP data structure to approximate maximum matrix norm search so that Sublinear
LSVI-UCB could also enjoy the sublinear value iteration complexity over actions. Moreover, we
theoretically prove that, with our choice of approximation factor, both Sublinear LSVI and Sublinear
LSVI-UCB achieve the same regret with their original versions. Furthermore, we identify the po-
tential risks of LSH type approximate Max-IP data structure in iterative-type algorithm and propose
a series of techniques to reduce them.
2	Related Work
Approximate Maximum Inner Product Search Maximum Inner Product Search (Max-IP) is a
fundamental yet challenging problem in theoretical computer science Williams (2005); Abboud et al.
(2017); Chen (2018); Chen & Williams (2019); Williams (2018). Given a query x ∈ Rd and a dataset
Y ⊂ Rd with n vectors, the goal of Max-IP is to retrieve a z ∈ Y so that x>z = arg maxz∈Y x>y.
The brute-force algorithm solves Max-IP in O(dn) time for x by linear scanning over all elements
in Y . To improve the Max-IP efficiency in practice, approximation methods are proposed to achieve
sublinear query time complexity by returning point with a multiplicative approximation ratio to the
Max-IP solution.
Chen Chen (2018) show that for bichromatic Max-IPi with two sets of n vectors from {0, 1}d, there
is a n2-Q(I) time algorithm with (d/ log n)Q(1)approximation ratio. Moreover, Chen Chen (2018) i *
iGiven two n-point set A ∈ Rd and B ∈ Rd, the goal of bichromatic Max-IP is to find b ∈ B that maximize
inner product for every a ∈ A.
2
Under review as a conference paper at ICLR 2022
show that this algorithm is conditional optimal as such a (d/ log n)o(1) approximation algorithm
would refute Strong Exponential Time Hypothesis (SETH) Impagliazzo & Paturi (2001)ii.
Most previous approximate Max-IP approaches reduce the Max-IP to nearest neighbor (NN) search
problem and apply approximate nearest neighbor (ANN) data structures such as locality sensitive
hashing (LSH) Shrivastava & Li (2014; 2015a); Neyshabur & Srebro (2015); Shrivastava & Li
(2015b); Yan et al. (2018). Given a query x ∈ Rd and a dataset Y ⊂ Rd with n vectors, the goal of
(c, r)-ANN with C > 1 is to retrieve a Z ∈ Y so that k X - z∣∣2 ≤ C ∙ r if there miny∈γ ∣∣x - y∣∣2 ≤ r.
The LSH solves this problem with query time in O(d∙ nρ+o(1)). Here, ρ < 1 and it depends on C. For
randomized LSH that is independent of data, Antoni, Indyk and Razenshteyn Andoni et al. (2018)
show that P ≥ 1/C2. To further reduce ρ, Antoni and Razenshteyn Andoni & Razenshteyn (2015)
proposes a data-dependent LSH that achieves P = 1∕(2c2 - 1) with preprocessing time and space
in O(n1+ρ + dn). Andoni, Laarhoven, Razenshteyn and Waingarten Andoni et al. (2017a) propose
a improved proposes a data-dependent LSH that solves (C, r)-ANN with query time O(d ∙ nρq+o(1)),
space O(n1+ρu+o(1) + dn) and preprocessing time O(dn1+ρu+o(1)). Andoni, Laarhoven, Razen-
shteyn and Waingarten Andoni et al. (2017a) also states that for C > 1, r > 0, Pu ≥ 0 and Pq ≥ 0,
We have C2√ρq + (C2 - 1)√ρU ≥ v 2C2 - 1. Moreover, if We achieve ρu = 0, We could reduce the
preprocessing overhead to O(n1+o⑴ + dn) while achieving Pq = C2 - C4. These LSH approaches
have concise theoretical guarantees on the trade-off between search quality and query time. Thus,
they could solve approximate Max-IP efficiently.
Meanwhile, other non-reduction approximate Max-IP approaches build efficient data structures such
as quantization codebooks Guo et al. (2016; 2020), trees Yu et al. (2017), alias tables Ding et al.
(2019) and graphs Morozov & Babenko (2018); Zhou et al. (2019); Tan et al. (2019). However,
there exists no theoretical guarantee on these non-reduction approaches so that their evaluation is
totally empirical.
Locality Sensitive Hashing Applications In practice, well-implemented LSH algorithms are de-
veloped Lv et al. (2007); Andoni et al. (2015) and have demonstrated their superiority in tackling
efficiency bottlenecks in practical applications. In optimization, Chen et al. (2019) proposes a LSH
based approach to estimate gradients in large scale linear models. Moreover, this idea has been
extended to neural network training Chen et al. (2020; 2021). Further more, Besides deep learning,
Luo & Shrivastava (2019) also proposes a LSH method for efficient MCMC sampling. Charikar &
Siminelakis (2017); Backurs et al. (2018); Siminelakis et al. (2019); Backurs et al. (2019); Charikar
et al. (2020) use LSH for efficient kernel density estimation. Zandieh et al. (2020) proposes a LSH
based approach for kernel ridge regression. Yang et al. (2021) proposes an LSH algorithm for effi-
cient linear bandits.
Provable Efficient Reinforcement Learning The theoretical analysis on the efficiency of modern
reinforcement learning (RL) approaches has drawn a lot of attention recently Jin et al. (2018); Bai
et al. (2019); Song & Sun (2019); Jin et al. (2020); Yang & Wang (2020); Cai et al. (2020); Wang
et al. (2020b); Zhang et al. (2020); Wang et al. (2020a); Du et al. (2020); Feng et al. (2020); Du
et al. (2021); Xiong et al. (2021). Jin et al. (2018) presents the first Q-learning with UCB explo-
ration algorithm with provable sublinear regret. Jin et al. (2020) proposes a provable RL algorithm
with linear function approximation that achieves both polynomial runtime and polynomial sample
complexity. There also exist other works that benefit the community with theoretical analysis on
efficient RL Du et al. (2020); Yang & Wang (2020); Cai et al. (2020).
Speedup Cost Per Iteration Recently, there have been many works discussing how to improve
the cost per iteration for optimization problems (e.g., linear programming, cutting plane method,
maximum matching, training neural networks) while maintaining the total number of iterations in
achieving the same final error guarantees. However, most of these algorithms are built on sketching
Lee et al. (2019); Jiang et al. (2020; 2021); Song & Yu (2021); Brand et al. (2021), sampling Cohen
et al. (2019); Brand et al. (2020b); Dong et al. (2021), vector-maintenance Brand (2020); Jiang et al.
(2021), sparse recovery Brand et al. (2020b;a) techniques, none of them have used LSH. We hope
that our novel combination of data structures and iterative algorithms will open the door for further
study into cost reduction in optimization. ii
iiSETH (Strong Exponential Time Hypothesis) states that for every > 0 there is a k such that k-SAT
cannot be solved in O((2 - )n) time.
3
Under review as a conference paper at ICLR 2022
3	Background
3.1	Locality Sensitive Hashing
We present a well-known data structure called locality sensitive hashing Indyk & Motwani (1998)
for approximate nearest neighbor search and approximate maximum inner produce search.
Definition 3.1 (Locality Sensitive Hashing). Let C denote a parameter such that c > 1. Let r denote
a parameter. Let p1,p2 denote two parameters such that 0 < p2 < p1 < 1. A function family H is
(r, c ∙ r,p1,p2)-sensitive ifand only if, for any two vector x,y ∈ Rd, a function h chosen uniformly
from family H has the following properties: (1) if ∣∣x 一 y∣∣2 ≤ r, then Prh〜χ[h(x) = h(y)] ≥ pi,
(2) if kx - y∣∣2 ≥ C ∙ r, then Prh〜χ[h(x) = h(y)] ≤ p2.
We want to remark that the original LSH definition supports more general distance function than
`2 distance. In our application, `2 distance is sufficient, therefore we only define LSH based on `2
distance. It is well-known that an efficient LSH family implies data structure (C, r)-ANN which can
be defined as
Definition 3.2 (Approximate Near Neighbor (ANN)). Let C > 1. Let r ∈ (0, 2). Given an n-
vector dataset P ⊂ Sd-i on the sphere, (c, r)-Approximate Near Neighbor Search (ANN) aims at
constructing a data structure such that, for a query q ∈ Sd-1 with the promise that there exists a
data vector p ∈ P with kp 一 q k2 ≤ r, the data structure reports a data vector p0 ∈ P with distance
less than C ∙ r from q.
In the iterative-type reinforcement learning algorithm, we care about the dual version of the problem
(Definition 3.3),
Definition 3.3 (Approximate Max-IP). Let C ∈ (0, 1). Let τ ∈ (0, 1). Given an n-vector dataset
P ⊂ Sd-1 on the sphere, the (C, τ)-Maximum Inner Product Search (Max-IP) aims at building a
data structure such that, for a query q ∈ Sd-1 with the promise that there exists a datapoint p ∈ P
with hp, q ≥ T, the data structure reports a datapoint p0 ∈ P with similarity hp ,q ≥ C ∙ τ.
We briefly discuss the connection. Let us consider the distance function as Euclidean distance and
similarity function as inner product. We also assume all the points are from unit sphere. In this
setting, the relationship between two problems are primal vs dual. For any two points x, y with
kxk2 = kyk2 = 1, we have kx 一 y k22 = 2 一 2hx, yi. This implies that r2 = 2 一 2τ. Further, if
We have a data structure for (C, r)-ANN, it automatically becomes a data structure for (c, T)-Max-IP
with parameters T = 1 一 0.5r2 and C = 1-00¾2. ThiS implies that C2 = 1-c(150.5r ) = 1-cT∙
Our algorithmic result is mainly built on this data structure.
Theorem 3.4 (Andoni and Razenshteyn Andoni & Razenshteyn (2015)). Let C > 1. Let r ∈ (0, 2).
Let P = 2c21-ι + o(1). The (C, r) - ANN (see Definition 3.2) on the unit sphere SdT Can be solved
by a data structure using O(d ∙ nρ) query time and O(n1+ρ + dn) space.
Using the standard reduction, we can derive the following.
Corollary 3.5. Let C ∈ (0, 1). Let T ∈ (0, 1). The (C, T)-Max-IP (see Definition 3.3) on a unit
sphere SdT can be solved in preprocessing time/space O(n1+ρ + dn) and query time O(d ∙ nρ),
where p = ι-2-T+τ +o(1).
Using Andoni et al. (2017a), we can improve the preprocessing time and space to n1+o(1) +dn while
having a slightly weaker P in query. We provide a detailed and formal version of Corollary 3.5 in
Theorem B.2. We present our main result based on that. Moreover, it is reasonable for us to regard
d = no(1) using Johnson-Lindenstrauss Lemma Johnson & Lindenstrauss (1984).
Finally, to combine the maximum inner product search with reinforcement learning algorithm to get
sublinear time cost per iteration, we still need to deal with many issues, such as the inner product
can be negative, T is arbitrarily close to 0, and T can arbitrarily close to 1. We will explain how to
handle these challenges in later section.
4
Under review as a conference paper at ICLR 2022
3.2	Reinforcement Learning
In this section, we introduce some backgrounds about reinforcement learning. We start with defining
the episodic Markov decision process. LetMDP(S, A, H, P, r) denote the episodic Markov decision
process, where S denotes the set of available states, A denotes the set of available actions, H ∈
N denotes the total number of steps in each episode, P = {Ph}hH=1 with Ph[s0|s, a] denotes the
probability of transition from state s ∈ S to state s0 ∈ S when take actions a ∈ A at step h,
r = {rh}hH=1 denotes the reward obtained at each step. Here the reward rh is a function that maps
S × A to [0.55, 1]iii In practice, we build an agent in MDP(S, A, H, P, r) and play K episodes.
In this work, we focus on the linear Markov decision process (linear MDP). In this setting, each
pair of state and action is represented as an embedding vector φ(s, a), where φ : S × A → Rd.
Moreover, the probability Ph[s0|s, a] for state transition and function rh for reward are linear in this
embedding vector.
In the MDP framework, a policy ∏ = {∏ι, ∙∙∙ , ∏h} is defined as sequence such that ∏h : S → A
for each step h. πh (s) = a represents the action taken when we are at step h and state s. Next, we
represent the Bellman equation with policy π as
Qπh(s,a) = [rh +PhVhπ+1](s,a),	Vhπ(s) = Qπh(s,πh(s)),	VHπ+1(s) = 0.
where Qπ (s, a) denotes the Q function for policy π when taking action a at state s and step h and
V π(s) denotes the value function of state s at step h. We use [PhVh+1](s, a) to represent the expect
value functions when taking action a at state s at step h. For more detailed definitions, please refer
to Section A.
4	Our Results
We present the results in this section. We start with summarizing all of our main results in Table 1.
According to Table 1, we reduce the value iteration complexity of LSVI Bradtke & Barto (1996),
LSVI-UCB Jin et al. (2020), LSVI-UCB under policy switch limitation Gao et al. (2021) and model-
free version of LSVI-UCB Wang et al. (2020a) from linear to sublinear in action space. Meanwhile,
the total regret is preserved as same as before. To achieve this, we pay tolerable time to preprocess
pairs of state-action into LSH type approximate Max-IP data structure. In the following section, we
would elaborate on the details for these main results.
4.1	Sublinear Least-Squares Value Iteration
In LSVI Bradtke & Barto (1996) with large action space, the runtime in each value iteration step is
dominated by computing the estimated value function as below:
Vh(s) = max hwbh, φ(s, a)i	(1)
where wbh is computed by solving the least-squares problem, Acore is the core action set and φ(s, a)
is the embedding for state-action pair. Eq. (1) is a standard Max-IP problem and thus, takes O(Ad)
to obtain the exact solution. In this work, we relax Eq. (1) into an (c, τ)-Max-IP problem, where
c ∈ (0, 1) is the approximation parameter and τ is close to the maxa∈Acore hwbh, φ(s, a)i. Then, we
apply LSH type data structure to retrieve Vh(S) ≥ C ∙ maxα∈Acorehwh, φ(s, a))in o(A) ∙ O(d) time
complexity.
Next, We present our main theorem for Sublinear LSVI in Theorem 4.1, which gives the same
O(LH2 ,∣∕n) regret as LSVI Bradtke & Barto (1996) and reduce the value iteration complexity
from O(HSdA) to O(HSd) ∙ o(A).
Theorem 4.1 (Main result, convergence result of Sublinear Least-Squares Value Iteration (Sublinear
LSVI), an informal version of Theorem C.2). Let MDP(S, A, H, P, r) denote a linear MDP. Let p
denote a fixed probability. Let ∣ = Iog(Hd∕p). If we set approximate MaX-IP parameter C =
1 一 Θ( ∙∖∕ι∕n), then Sublinear LSVI has regret at most O(H2 ∙vzι∕n) with probability at least 1 一 p.
Moreover, with SA1+o(1) + SdA preprocessing time and space, the value iteration complexity of
Sublinear LSVI is O(HSdAρ) where ρ = 1 一 Θ(ι∕n).
iiiNote that in standard reinforcement learning, we assume reward is [0, 1], but it is completely reasonable to
do a shift. We will provide more discussion in Section 5.1.
5
Under review as a conference paper at ICLR 2022
Note that We could improve the value iteration complexity to with P = 1 - Θ(，i/n) by increasing
the preprocessing time and space to O(SA1+ρ + SdA) using Theorem A.14. We provide a detailed
and formal version of Theorem 4.1 in Theorem C.2.
	Statement	Preprocess	#Regret	V. Iter. C.
LSVI	Bradtke & Barto (1996)	0	H2 Pι∕n	HSdA
Ours	Theorem 4.1	SA1+o ⑴ + SdA	H2 Pι∕n	HSdAP
LSVI-UCB	Jin et al. (2020)	0	√H 4Kd3ι2	HKd2A
Ours	Theorem 4.3	KA1+o ⑴ + Kd2A	√H4Kd3ι2 .	HKd2Ap
LGSC	Gao et al. (2021)	0	√H4Kd3ι2 .	HKd2A
Ours	Corollary 4.4	KA1+o ⑴ + Kd2A	√H4Kd3ι2 .	HKd2Ap
MF	-	Wang et al. (2020a)	0	√H4Kd3ι2 .	HKd2A
Ours	Corollary 4.4	KA1+o ⑴ + Kd2A	√H4Kd3ι2 .	HKd2Ap
Table 1: Comparison between our algorithms with previous results such as LSVI, LSVI-UCB, LGSC and MF.
We compare our algorithm with: (1) LSVI denotes the Least-Square Value Iteration algorithm Bradtke & Barto
(1996) (2) LSVI-UCB denotes the Least-Square Value Iteration algorithm with UCB in Jin et al. (2020). (3)
LGSC denotes the LSVI-UCB with low global switching cost Gao et al. (2021). (4) MF denotes the model free
LSVI-UCB presented in Wang et al. (2020a). Note that “V. Iter. C.” denotes the Value iteration complexity.
Let S denote the number of available states. Let A denote the number of available actions. Let d denote the
dimension of φ(s, a). Let H denote the number of steps per episode. Let K denote the total number of episodes.
Let n be the quantity of times played for each core pair of state-action. Let ι = log(H d/p) andp is the failure
probability. We ignore the big-Oh notation “O” in the table. Let ρ ∈ (0, 1) denote a parameter determined
by data structure. In fact, the preprocessing time for Sublinear LSVI-UCB is O(SA1+o(1) + Sd2A). Since
K > S, we write the preprocessing time as O(K A1+o(1) + Kd2A). This table is a union of simplified version
of Table 3 (both our algorithm and LSVI have the exact dependence on another L, we omit here and discuss
this dependence in Section C.), Table 4 and Table 5.
4.2	Sublinear Least-Squares Value Iteration with UCB
We extend the Sublinear LSVI with UCB exploration in this section. In LSVI-UCB Jin et al. (2020)
with large action space, the runtime in each value iteration step is dominated by computing the
estimated value function as below:
τ	kτ	τ
Vh(sh+1) = max min{hw⅛ ,φ(sh+1 ,a)i + β ∙ kφ(sh+1,a)kΛ-i ,H}	⑵
a∈A	h
where whk is computed by solving the least-squares problem, φ(sτh+1, a) is the embedding for state-
action pair and Ah = Pk= 1 φ(s^h, ah)φ(sh, ah)> + λ ∙ Id. The complexity for Eq. (2) is O(Ad2)
The key challenge of Sublinear LSVI-UCB here is that Eq. (2) cannot be formulated as a Max-IP
problem. First, to deal with this issue, we propose a value function estimation approach as below:
ττ
Vh(sτh+1) = ma∈aAx min{kφ(sτh+1, a)k2β2Λh-1+2whkwhk>, H}	(3)
where llφ(sh+1,a)k2β2Λ-i+2wk wk> isthe upper boundof hwh ,φ(sh+1,a)'i + β ∙ kφ(sh+1,a)kΛ-i.
Next, we relax this maximum matrix norm search as a (c, τ)-Max-IP problem, where c ∈ (0, 1) is
the approximation parameter and τ is the maximum inner product for Eq. (3). Then, we apply LSH
type data structure to retrieve Vh(Sh+1) ≥ C ∙ maxa∈A min{∣φ(sh+1, a)k2β2Λ-1+2wkwk>,H} m
o(A) ∙ O(d2) time complexity.
Using LSH data structure for maximum matrix norm search, we present our main theorem for Sub-
linear LSVI-UCB in Theorem 4.3, which gives the same O(√d3H4Kι2) regret as LSVI-UCB Jin
et al. (2020) and reduce the value iteration complexity from O(HKd2A) to O(HKd2A) ∙ o(A). We
start with the setting up the parameters for our algorithm.
Definition 4.2 (Sublinear LSVI-UCB Parameteres). Let MDP(S, A, H, P, r) denote a linear MDP.
For this MDP, we set LSVI-UCB parameter λ = 1. Let C = 1 —春 denote the approximate MaX-IP
parameter. Let p denote a fixed probability. Let ι = log(2dT /p).
6
Under review as a conference paper at ICLR 2022
Then, we present the Theorem.
Theorem 4.3 (Main result, convergence result of Sublinear Least-Squares Value Iteration with UCB
(Sublinear LSVI-UCB), an informal version of Theorem D.12). With parameters defined in Defini-
tion 4.2, Sublinear LSVI-UCB (Algorithm 4) has total regret at most O( Vd3H4Kι2) with Probabil-
ity at least 1 - p. Moreover, with O(K A1+o(1) + Kd2A) preprocessing time and space, the value
iteration complexity of Sublinear LSVI-UCB is O(HKd2Aρ), where ρ = 1 - 1/K.
Similarly, We could improve the value iteration complexity to with P = 1 - √K by increasing the
preprocessing time and space to O(KA1+ρ + KdA) using Theorem A.14. We provide a detailed
and formal version of Theorem 4.3 in Theorem D.12.
Next, we extend the results in Theorem 4.3 to two LSVI-UCB variations. The first algorithm is the
LSVI-UCB under constraints on the switch of the policy Gao et al. (2021). We denote this algorithm
as LGSC. The second algorithm is the model-free version of LSVI-UCB Wang et al. (2020a). We
denote this algorithm as MFiv. We propose sublinear version of two algorithms with statement as:
Corollary 4.4 (Main result, informal versions of Corollary E.2 and Corollary E.1). With parameters
defined in Definition 4.2, LGSC and MF have total regret at most O(Vd3H4Kι2) with probability
at least 1 - p. Further more, with O(K A1+o(1) + Kd2A) preprocessing time and space, the value
iteration complexity of LGSC and MF is O(HKd2Aρ), where P = 1 - 1/K.
5 Our Techniques
As mentioned in Section 3.1, we need to tackle five major issues to use LSH based approximate
Max-IP algorithm for sublinear runtime time LSVI and LSVI-UCB in RL.
•	How to prevent the maximum inner product between query and data from being negative
or arbitrary close to 0? If the maximum inner product is negative, Max-IP data structures
cannot be applied to solve this problem with theoretical guarantee. If the maximum inner
product is arbitrary close to 0, the query time of (c, τ)-Max-IP would be close to O(dn).
•	How to prevent the maximum inner product between query and data from being close to
one? If τ is close to one, the time cost would also be O(dn) so that (c, τ)-Max-IP cannot
reduce the time cost from linear to sublinear.
•	How to apply (c, τ)-Max-IP for LSVI with UCB exploration? The estimated value function
with an additional UCB bonus term could not be written as an inner product, which prevents
Max-IP techniques from accelerating the runtime efficiency.
•	How to generalize the Max-IP data structure to support maximum matrix norm search? Is
Max-IP equivalent to maximum matrix norm search?
•	How to improve the running time while preserving the regret? Although approximate
Max-IP could accelerate the computation for estimated value function, it brings errors to
the value function estimation and thus, affects the total regret. Therefore, a key challenge
is quantifying the relationship between regret and the approximation factor c in (c, τ)-
Max-IP.
•	How to handle the adaptive queries? The weight wbh in Eq. (1) and whk in Eq. (2) are
dependent to h - 1 step. Therefore, the queries for (c, τ)-Max-IP during the Q-learning are
adaptive but not arbitrary. Thus, we could not union bound the failure probability of LSH
for (c, τ)-Max-IP.
Next, we provide details on how we handle these problems.
5.1	AVOID NEGATIVE INNER PRODUCT OR INNER PRODUCT CLOSE TO 0
In our setting, we assume the reward function r lies in [0.55, 1]v. This shift on the reward function
would not affect the convergence results of our Sublinear LSVI and Sublinear LSVI-UCB. More-
over, it would benefits the Max-IP by generating acceptable maximum inner product. For Sublinear
ivWe discuss the policy switch cost of LGSC in Section E.1 and number of explorations ofMF in Section E.2
vNote that for any reward range [a,b], there exists a shift C and scaling α so that (a + c)∕α = 0.55 and
(b + c)∕α = 1.
7
Under review as a conference paper at ICLR 2022
LSVL as rh(s, a) ∈ [0.55,1], the optimal value function Vh=(S) ≥ 0.55. Then according to Theo-
rem 4.1 the estimated Vh(s) = maxa∈Ahwh, ψ(s, a)i satisfies |Vh=(s) - Vh(s)| ≤ ifwe query each
pair of state-action from span matrix for n = O(-2L2H4ι) times. In this way, we could assure
the maximum inner product is greater than 0.5 if we set ≤ 0.05. For Sublinear LSVI-UCB, the
Max-IP is applied on Vbh(s) = maxa∈A Qkh(s, a), where Qkh(s, a) is a Q function with additional
UCB term. From Jin et al. (2020), we know that for all pair of state-action ,Qkh(s, a) ≥ Q=h(s, a).
Therefore, the maximum inner product for Sublinear LSVI-UCB is always greater than 0.5.
5.2	AVOID INNER PRODUCT CLOSE TO 1
In the optimization problem that could be accelerated by Max-IP, the query and data vectors are
usually not unit vectors. To apply results in Section 3.1, we demonstrate how to transform both
query and data vectors into unit vectors. Moreover, we also modify the transformation to avoid the
inner product from being too close to 1.
Given two vector x, y ∈ Rd with ky k2 ≤ 1 and kxk2 ≤ Dx , we apply the following transformations
P(y)= [y> Pr-O2 0]> Q(X)= [0¾x>	0 Ji - 0⅛2xk2j >	(4)
Using this transformations, we transform x, y into unit vectors P(y) and Q(x). Therefore,
the Max-IP of Q(x) with respect to P(Y ) is equivalent to the ANN problem of Q(x) with
respect to P(Y ), which could be solved via LSH. Moreover, we show that Q(x)>P(y) =
0'8χ>y ≤ 0-8'kDk2kyk2 = 0.8. Further more, it is sufficient to show that argmaxy Q(x)>P(y)=
0.8-xτ y	>
argmaxy -D-y = argmaxy X 1 y.
If we perform maximum inner product search on Q(x) and P(y) using the LSH data structures
described in Section 3.1, we have τ = maxy Q(X)>P (y) ≤ 0.8. In this way, we could assure τ
is not close to 1 so that we could reduce the runtime complexity of value function estimation to be
sublinear over actions.
5.3	APPROXIMATE Max-IP DATA STRUCTURE FOR LSVI-UCB
As shown in Section 4.2, Eq. (2) cannot be formulated as a Max-IP problem. To overcome this
barrier, we bound the term Qh(sh+ι, a) = {whΦ(sh+ι,a) + β ∙ kΦ(sh+ι,。州人一，H} by matrix
norms. Then, we perform the maximum matrix norm search for value function estimation.
We start with the upper bound of w>φ(sh+ι, a) + β ∙ ∣∣φ(sh+ι, α)∣∣A-ι. AS both {w£, φ(sh+ι, a))
and kφ(sτh+1, a)kΛ-1 are non-negative, we have
h
hwk, φ(sh+ι,a)i + β ∙ kφ(sh+ι, a)kΛ-i ≤ ∖∕2(w>φ(Sh+ι,a))2 +2万2 ∙ kφ(sh+ι,a)kΛτ
hh
= kφ(Sτh+1, a)k2β2Λh-1+2whk(whk)τ
where the first step follows from a + b ≤ √2a2 + 2b2.
Next, We lower bound the wh>φ(sh+ι, a) + β ∙ ∣∣φ(sh+ι, a)h-ι as
w>φ(sh+ι,a) + β ∙ kφ(sh+ι,a)kΛ-1 ≥ ∖/(w>φ(sh+ι,a))2 + β2 ∙ kφ(sh+ι,a)kΛ-ι
hh
= kφ(sτh+1, a)kβ2Λh-1+whk(whk)τ
where the first step follows from the fact that both wh>φ(sτh+1, a) and kφ(sτh+1, a)kΛ-1 are non-
negative and a + b ≥ √a2 + b2 if a, b ≥ 0, the second step is an reorganization.
After We lower and upper bound w>φ(shh+ι, a) + β ∙ ∣∣φ(sh+ι, a)∣∣A-ι ,we could also lower bound
the term {w>φ(sh+ι,a) + β ∙ kφ(sh+ι,a)kΛ-i,h} with min{kφ(sh+ι,a)kβ2Λ-i+wk(wQτ,H}
and upper bound it with min{∣φ(sτh+1, a)∣2β2Λ-1+2wk(wk)τ, H}.
8
Under review as a conference paper at ICLR 2022
Next we use this lower and upper bound and propose a modified value function estimation shown in
Eq. (3). Therefore, our problem becomes designing an approximate maximum matrix norm search
data structure. We will discuss this in the following section and propose our Sublinear LSVI-UCB
algorithm.
5.4	GENERALIZE THE APPROXIMATE Max-IP DATA STRUCTURE FOR Max-MatNorm
We demonstrate how to extend Max-IP to maximum matrix norm search for Sublinear LSVI-UCB in
this section. We first define the approximate Maximum Matrix Norm. Let c ∈ (0, 1) and τ ∈ (0, 1).
Given an n-point dataset Y ⊂ Rd, the goal of the (c, τ)-Maximum Matrix Norm (Max-MatNorm)
is to construct a data structure that, given a query matrix x ∈ Rd×d with the promise that there exists
a datapoint y ∈ Y with ∣∣ykχ ≥ T, it reports a datapoint Z ∈ Y with ∣∣zkχ ≥ C ∙ T.
We solve the approximate maximum matrix norm by transform it into a Max-IP problem. We start
with showing the relationship between Max-MatNorm and Max-IP as
Max-MatNorm(X, Y)2 = max y>xy = maxhvec(x), vec(yy>)
y∈Y	y∈Y
where vec vectorizes d × d matrix x into a d2 vector.
Next, we show that if we obtain z ∈ Y by (c2, T2)-Max-IP so that hvec(x), vec(zz>)i ≥ c2T2,
We use z and obtain ∣∣z∣χ =，(vec(x), Vec(Zz>))≥ cτ. In other words, Z is the candidate for
(c, T)-Max-MatNorm. In this way, we could build an efficient data-structure for (c2, T 2)-Max-IP to
solve (c, T)-Max-MatNorm. In this way, we summarize our approach for Max-MatNorm as three
steps: (1) transform matrix x into vec(x) and y into vec(yy>), (2) transform vec(x) and vec(yy>)
into unit vectors following Eq. (4), (3) use LSH to solve the Max-IP with respect to dataset on the
unit sphere.
5.5	Preserving Regret While Reducing the Runtime
In our work, we maintain the same regret with LSVI Bradtke & Barto (1996) and LSVI-UCB Jin
et al. (2020) by carefully setting the approximation parameter c ∈ (0, 1) in Max-IP. For Sublinear
LSVL we set C = 1 一 Θ(,∣∕n) so that the final regret is as same as LSVI Bradtke & Barto (1996).
In Sublinear LSVI-UCB, we set C = 1 一 √= so that the final regret is as same as LSVI-UCB Jin
et al. (2020). Because K, ι and nare global parameter, we could set C in the preprocessing step
before value iteration. In this way, we show that our two algorithms are novel demonstration of
combining LSH with reinforcement learning without losing on the regret.
5.6	HANDLE ADAPTIVE QUERIES IN (C, T)-Max-IP
We use a quantization method to handle adaptive queries. We denote Q as the convex hull of all
queries for (C, T)-Max-IP. Our method contains two steps: (1) Preprocessing: we quantize Q to
a lattice Q with quantization error λ∕d. In this way, each coordinate would be quantized into the
multiples of λ∕d. (2) Query: given a query q in the adaptive sequence X ⊂ Q, we first quantize it to
the nearest qb ∈ Q and perform (C, T)-Max-IP. As each qb∈ Q is independent, we could union bound
the failure probability of adaptive queries. On the other hand, this would generate an λ additive
error in the returned inner product. Our analysis indicates that the additive error λ could be handled
without breaking the regret.
6	Conclusion
In this paper, we propose the first provable Least-Squares Value Iteration (LSVI) algorithms with
runtime complexity sublinear in the number of actions. By formulating the value function estimation
procedure in LSVI as an approximate maximum inner product search problem, we bridge the gap
between the regret analysis in reinforcement learning and the theory of locality sensitive hashing
(LSH) type data structure. The theoretical analysis indicates that with our choice of approximation
factor, there exists a LSVI algorithm that has the same order of regret as the original LSVI algorithm
while reducing runtime complexity to sublinear in the number of actions. Moreover, we show that
our techniques could be extended to different LSVI variants. We hope our novel combination of data
structures and the iterative algorithm will inspire further study into cost reduction in optimization.
9
Under review as a conference paper at ICLR 2022
Ethics S tatement
We present a theoretical analysis on Least-Squares Value Iteration. We believe this paper does not
raise potential ethic concerns.
Reproducibility S tatement
We make clear explanations of the assumptions required in this paper. We also provide a complete
proof of our claims in the appendix.
References
Amir Abboud, Aviad Rubinstein, and Ryan Williams. Distributed pcp theorems for hardness of
approximation in p. In 2017 IEEE 58th Annual Symposium on Foundations of Computer Science
(FOCS),pp. 25-36. IEEE, 2017.
Alexandr Andoni. Nearest neighbor search: the old, the new, and the impossible. PhD thesis,
Massachusetts Institute of Technology, 2009.
Alexandr Andoni and Piotr Indyk. Near-optimal hashing algorithms for approximate nearest neigh-
bor in high dimensions. Communications of the ACM, 51(1):117, 2008.
Alexandr Andoni and Ilya Razenshteyn. Optimal data-dependent hashing for approximate near
neighbors. In Proceedings of the forty-seventh annual ACM symposium on Theory of computing
(STOC), pp. 793-801, 2015.
Alexandr Andoni, Piotr Indyk, Huy L Nguyen, and Ilya Razenshteyn. Beyond locality-sensitive
hashing. In Proceedings of the twenty-fifth annual ACM-SIAM symposium on Discrete algorithms
(SODA), pp. 1018-1028. SIAM, 2014.
Alexandr Andoni, Piotr Indyk, TMM Laarhoven, Ilya Razenshteyn, and Ludwig Schmidt. Practical
and optimal lsh for angular distance. In Advances in Neural Information Processing Systems
(NIPS), pp. 1225-1233. Curran Associates, 2015.
Alexandr Andoni, Thijs Laarhoven, Ilya Razenshteyn, and Erik Waingarten. Optimal hashing-based
time-space trade-offs for approximate near neighbors. In Proceedings of the Twenty-Eighth An-
nual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 47-66. SIAM, 2017a.
Alexandr Andoni, Ilya Razenshteyn, and Negev Shekel Nosatzki. Lsh forest: Practical algorithms
made theoretical. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Dis-
crete Algorithms (SODA), pp. 67-78. SIAM, 2017b.
Alexandr Andoni, Piotr Indyk, and Ilya Razenshteyn. Approximate nearest neighbor search in high
dimensions. In Proceedings of ICM, volume 7, 2018.
Arturs Backurs, Moses Charikar, Piotr Indyk, and Paris Siminelakis. Efficient density evaluation
for smooth kernels. In 2018 IEEE 59th Annual Symposium on Foundations of Computer Science
(FOCS), pp. 615-626. IEEE, 2018.
Arturs Backurs, Piotr Indyk, and Tal Wagner. Space and time efficient kernel density estimation
in high dimensions. Annual Conference on Neural Information Processing Systems (NeurIPS),
2019.
Yu Bai, Tengyang Xie, Nan Jiang, and Yu Xiang Wang. Provably efficient q-learning with low
switching cost. Advances in Neural Information Processing Systems (NeurIPS), 32, 2019.
Omri Ben-Eliezer, Rajesh Jayaram, David P Woodruff, and Eylon Yogev. A framework for adver-
sarially robust streaming algorithms. In Proceedings of the 39th ACM SIGMOD-SIGACT-SIGAI
Symposium on Principles of Database Systems (PODS), pp. 63-80, 2020.
Steven J Bradtke and Andrew G Barto. Linear least-squares algorithms for temporal difference
learning. Machine learning, 22(1):33-57, 1996.
10
Under review as a conference paper at ICLR 2022
Jan van den Brand. A deterministic linear program solver in current matrix multiplication time. In
Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA),
pp. 259-278. SIAM, 2020.
Jan van den Brand, Yin-Tat Lee, Danupon Nanongkai, Richard Peng, Thatchaphol Saranurak, Aaron
Sidford, Zhao Song, and Di Wang. Bipartite matching in nearly-linear time on moderately dense
graphs. In 2020 IEEE 61st Annual Symposium on Foundations of Computer Science (FOCS), pp.
919-930. IEEE, 2020a.
Jan van den Brand, Yin Tat Lee, Aaron Sidford, and Zhao Song. Solving tall dense linear programs
in nearly linear time. In Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of
Computing (STOC), pp. 775-788, 2020b.
Jan van den Brand, Binghui Peng, Zhao Song, and Omri Weinstein. Training (overparametrized)
neural networks in near-linear time. In 12th Innovations in Theoretical Computer Science Con-
ference (ITCS), 2021.
Qi Cai, Zhuoran Yang, Chi Jin, and Zhaoran Wang. Provably efficient exploration in policy op-
timization. In International Conference on Machine Learning (ICML), pp. 1283-1294. PMLR,
2020.
Moses Charikar and Paris Siminelakis. Hashing-based-estimators for kernel density in high dimen-
sions. In 2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS), pp.
1032-1043. IEEE, 2017.
Moses Charikar, Michael Kapralov, Navid Nouri, and Paris Siminelakis. Kernel density estimation
through density constrained near neighbor search. In 2020 IEEE 61st Annual Symposium on
Foundations of Computer Science (FOCS), pp. 172-183. IEEE, 2020.
Moses S Charikar. Similarity estimation techniques from rounding algorithms. In Proceedings of
the thiry-fourth annual ACM symposium on Theory of computing (STOC), pp. 380-388, 2002.
Beidi Chen, Yingchen Xu, and Anshumali Shrivastava. Lsh-sampling breaks the compu-
tation chicken-and-egg loop in adaptive stochastic gradient estimation. arXiv preprint
arXiv:1910.14162, 2019.
Beidi Chen, Tharun Medini, James Farwell, sameh gobriel, Charlie Tai, and Anshumali Shrivastava.
Slide : In defense of smart algorithms over hardware acceleration for large-scale deep learning
systems. In Proceedings of Machine Learning and Systems (MLSys), volume 2, pp. 291-306,
2020.
Beidi Chen, Zichang Liu, Binghui Peng, Zhaozhuo Xu, Jonathan Lingjie Li, Tri Dao, Zhao Song,
Anshumali Shrivastava, and Christopher Re. MONGOOSE: A learnable LSH framework for effi-
cient neural network training. In International Conference on Learning Representations (ICLR),
2021.
Lijie Chen. On the hardness of approximate and exact (bichromatic) maximum inner product. In
33rd Computational Complexity Conference (CCC), 2018.
Lijie Chen and Ryan Williams. An equivalence class for orthogonal vectors. In Proceedings of
the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 21-40. SIAM,
2019.
Tobias Christiani. A framework for similarity search with space-time tradeoffs using locality-
sensitive filtering. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Dis-
crete Algorithms (SODA), pp. 31-46. SIAM, 2017.
Michael B Cohen, Yin Tat Lee, and Zhao Song. Solving linear programs in the current matrix
multiplication time. In Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of
Computing (STOC), 2019.
Shabnam Daghaghi, Nicholas Meisburger, Mengnan Zhao, and Anshumali Shrivastava. Accelerat-
ing slide deep learning on modern cpus: Vectorization, quantizations, memory optimizations, and
more. Proceedings of Machine Learning and Systems, 3, 2021.
11
Under review as a conference paper at ICLR 2022
Mayur Datar, Nicole Immorlica, Piotr Indyk, and Vahab S Mirrokni. Locality-sensitive hashing
scheme based on p-stable distributions. In Proceedings of the twentieth annual symposium on
Computational geometry (SOCG),pp. 253-262, 2004.
Qin Ding, Hsiang-Fu Yu, and Cho-Jui Hsieh. A fast sampling algorithm for maximum inner product
search. In The 22nd International Conference on Artificial Intelligence and Statistics (AISTATS),
pp. 3004-3012. PMLR, 2019.
Sally Dong, Yin Tat Lee, and Guanghao Ye. A nearly-linear time algorithm for linear programs
with small treewidth: A multiscale representation of robust central path. In Proceedings of
the 53rd Annual ACM SIGACT Symposium on Theory of Computing (STOC). arXiv preprint
arXiv:2011.05365, 2021.
Yihe Dong, Piotr Indyk, Ilya Razenshteyn, and Tal Wagner. Learning space partitions for nearest
neighbor search. In International Conference on Learning Representations (ICLR). arXiv preprint
arXiv:1901.08544, 2020.
Simon S Du, Sham M Kakade, Ruosong Wang, and Lin F Yang. Is a good representation sufficient
for sample efficient reinforcement learning? In International Conference on Learning Represen-
tations (ICLR), 2020.
Simon S Du, Sham M Kakade, Jason D Lee, Shachar Lovett, Gaurav Mahajan, Wen Sun, and
Ruosong Wang. Bilinear classes: A structural framework for provable generalization in rl. In
ICML, 2021.
Fei Feng, Ruosong Wang, Wotao Yin, Simon S Du, and Lin Yang. Provably efficient exploration for
reinforcement learning using unsupervised learning. Advances in Neural Information Processing
Systems (NeurIPS), 33, 2020.
Minbo Gao, Tianle Xie, Simon S Du, and Lin F Yang. A provably efficient algorithm for linear
markov decision process with low switching cost. arXiv preprint arXiv:2101.00494, 2021.
Ruiqi Guo, Sanjiv Kumar, Krzysztof Choromanski, and David Simcha. Quantization based fast
inner product search. In Artificial Intelligence and Statistics (AISTATS), pp. 482-490. PMLR,
2016.
Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng, David Simcha, Felix Chern, and Sanjiv Ku-
mar. Accelerating large-scale inference with anisotropic vector quantization. In International
Conference on Machine Learning (ICML), pp. 3887-3896. PMLR, 2020.
Wassily Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the
American Statistical Association, 58(301):13-30, 1963.
Russell Impagliazzo and Ramamohan Paturi. On the complexity of k-sat. Journal of Computer and
System Sciences, 62(2):367-375, 2001.
Piotr Indyk and Rajeev Motwani. Approximate nearest neighbors: towards removing the curse of
dimensionality. In Proceedings of the thirtieth annual ACM symposium on Theory of computing
(STOC), pp. 604-613, 1998.
Haotian Jiang, Yin Tat Lee, Zhao Song, and Sam Chiu-wai Wong. An improved cutting plane
method for convex optimization, convex-concave games and its applications. In Proceedings of
the 52nd Annual ACM SIGACT Symposium on Theory of Computing (STOC), 2020.
Shunhua Jiang, Zhao Song, Omri Weinstein, and Hengjie Zhang. Faster dynamic matrix inverse for
faster lps. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing
(STOC). arXiv preprint arXiv:2004.07470, 2021.
Chi Jin, Zeyuan Allen-Zhu, Sebastien Bubeck, and Michael I Jordan. Is q-learning provably effi-
cient? Advances in Neural Information Processing Systems (NeurIPS), 2018:4863-4873, 2018.
Chi Jin, Zhuoran Yang, Zhaoran Wang, and Michael I Jordan. Provably efficient reinforcement
learning with linear function approximation. In Conference on Learning Theory (COLT), pp.
2137-2143. PMLR, 2020.
12
Under review as a conference paper at ICLR 2022
William B Johnson and Joram Lindenstrauss. Extensions of lipschitz mappings into a hilbert space.
Contemporary mathematics, 26(189-206):1, 1984.
Jens Kober, J Andrew Bagnell, and Jan Peters. Reinforcement learning in robotics: A survey. The
International Journal ofRobotics Research (IJRR), 32(11):1238-1274, 2013.
Frangois Le Gall. Powers of tensors and fast matrix multiplication. In Proceedings of the 39th
international symposium on symbolic and algebraic computation (ISSAC), pp. 296-303. ACM,
2014.
Yin Tat Lee, Zhao Song, and Qiuyi Zhang. Solving empirical risk minimization in the current matrix
multiplication time. In International Conference on Computational Learning Theory (COLT),
2019.
Jiwei Li, Will Monroe, Alan Ritter, Dan Jurafsky, Michel Galley, and Jianfeng Gao. Deep rein-
forcement learning for dialogue generation. In Proceedings of the 2016 Conference on Empirical
Methods in Natural Language Processing (EMNLP-IJCNLP), pp. 1192-1202, 2016.
Chen Luo and Anshumali Shrivastava. Scaling-up split-merge mcmc with locality sensitive sampling
(lss). In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), volume 33, pp.
4464-4471, 2019.
Qin Lv, William Josephson, Zhe Wang, Moses Charikar, and Kai Li. Multi-probe lsh: efficient
indexing for high-dimensional similarity search. In 33rd International Conference on Very Large
Data Bases (VLDB), pp. 950-961. Association for Computing Machinery, Inc, 2007.
Francisco S Melo and M Isabel Ribeiro. Q-learning with linear function approximation. In Interna-
tional Conference on Computational Learning Theory (COLT), pp. 308-322. Springer, 2007.
Stanislav Morozov and Artem Babenko. Non-metric similarity graphs for maximum inner product
search. Advances in Neural Information Processing Systems (NeurIPS), 31:4721-4730, 2018.
Vasileios Nakos, Zhao Song, and Zhengyu Wang. (nearly) sample-optimal sparse fourier transform
in any dimension; ripless and filterless. In 2019 IEEE 60th Annual Symposium on Foundations of
Computer Science (FOCS), pp. 1568-1577. IEEE, 2019.
Behnam Neyshabur and Nathan Srebro. On symmetric and asymmetric lshs for inner product search.
In International Conference on Machine Learning (ICML), pp. 1926-1934. PMLR, 2015.
Ilya Razenshteyn. High-dimensional similarity search and sketching: algorithms and hardness.
PhD thesis, Massachusetts Institute of Technology, 2017.
Gregory Shakhnarovich, Trevor Darrell, and Piotr Indyk. Nearest-neighbor methods in learning and
vision. In Neural Information Processing, 2005.
Anshumali Shrivastava and Ping Li. Asymmetric lsh (alsh) for sublinear time maximum inner prod-
uct search (mips). Advances in Neural Information Processing Systems (NIPS), pp. 2321-2329,
2014.
Anshumali Shrivastava and Ping Li. Improved asymmetric locality sensitive hashing (alsh) for max-
imum inner product search (mips). In Proceedings of the Thirty-First Conference on Uncertainty
in Artificial Intelligence (UAI), pp. 812-821, 2015a.
Anshumali Shrivastava and Ping Li. Asymmetric minwise hashing for indexing binary inner prod-
ucts and set containment. In Proceedings of the 24th international conference on world wide web
(WWW), pp. 981-991, 2015b.
David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra, and Martin Riedmiller. De-
terministic policy gradient algorithms. In International conference on machine learning (ICML),
pp. 387-395. PMLR, 2014.
David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche,
Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. Mastering
the game of go with deep neural networks and tree search. nature, 529(7587):484-489, 2016.
13
Under review as a conference paper at ICLR 2022
Paris Siminelakis, Kexin Rong, Peter Bailis, Moses Charikar, and Philip Levis. Rehashing kernel
evaluation in high dimensions. In International Conference on Machine Learning (ICML), pp.
5789-5798. PMLR, 2019.
Zhao Song and Wen Sun. Efficient model-free reinforcement learning in metric spaces. arXiv
preprint arXiv:1905.00475, 2019.
Zhao Song and Zheng Yu. Oblivious sketching-based central path method for solving linear pro-
gramming problems. In 38th International Conference on Machine Learning (ICML), 2021.
Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018.
Shulong Tan, Zhixin Zhou, Zhaozhuo Xu, and Ping Li. On efficient retrieval of top similarity vectors.
In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),
pp. 5239-5249, 2019.
Roman Vershynin. Introduction to the non-asymptotic analysis of random matrices. arXiv preprint
arXiv:1011.3027, 2010.
Ruosong Wang, Simon S Du, Lin Yang, and Russ R Salakhutdinov. On reward-free reinforcement
learning with linear function approximation. In Advances in Neural Information Processing Sys-
tems (NeurIPS), volume 33, pp. 17816-17826. Curran Associates, Inc., 2020a.
Ruosong Wang, Peilin Zhong, Simon S Du, Russ R Salakhutdinov, and Lin F Yang. Planning
with general objective functions: Going beyond total rewards. In Annual Conference on Neural
Information Processing Systems (NeurIPS), 2020b.
Christopher JCH Watkins and Peter Dayan. Q-learning. Machine learning, 8(3-4):279-292, 1992.
Alexander Wei. Optimal las vegas approximate near neighbors in `p . In Proceedings of the Thirtieth
Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 1794-1813. SIAM, 2019.
Ryan Williams. A new algorithm for optimal 2-constraint satisfaction and its implications. Theoret-
ical Computer Science, 348(2-3):357-365, 2005.
Ryan Williams. On the difference between closest, furthest, and orthogonal pairs: Nearly-linear vs
barely-subquadratic complexity. In Proceedings of the Twenty-Ninth Annual ACM-SIAM Sympo-
sium on Discrete Algorithms (SODA), pp. 1207-1215. SIAM, 2018.
Virginia Vassilevska Williams. Multiplying matrices faster than coppersmith-winograd. In Proceed-
ings of the forty-fourth annual ACM symposium on Theory of computing (STOC), pp. 887-898.
ACM, 2012.
Zhihan Xiong, Ruoqi Shen, and Simon S Du. Randomized exploration is near-optimal for tabular
mdp. arXiv preprint arXiv:2102.09703, 2021.
Xiao Yan, Jinfeng Li, Xinyan Dai, Hongzhi Chen, and James Cheng. Norm-ranging lsh for maxi-
mum inner product search. Advances in Neural Information Processing Systems (NeurIPS), 31:
2952-2961, 2018.
Lin Yang and Mengdi Wang. Reinforcement learning in feature space: Matrix bandit, kernels, and
regret bound. In International Conference on Machine Learning (ICML), pp. 10746-10756, 2020.
Shuo Yang, Tongzheng Ren, Sanjay Shakkottai, Eric Price, Inderjit S Dhillon, and Sujay Sanghavi.
Linear bandit algorithms with sublinear time complexity. arXiv preprint arXiv:2103.02729, 2021.
Hsiang-Fu Yu, Cho-Jui Hsieh, Qi Lei, and Inderjit S Dhillon. A greedy approach for budgeted
maximum inner product search. In Proceedings of the 31st International Conference on Neural
Information Processing Systems (NIPS), pp. 5459-5468, 2017.
Amir Zandieh, Navid Nouri, Ameya Velingker, Michael Kapralov, and Ilya Razenshteyn. Scaling
up kernel ridge regression via locality sensitive hashing. In International Conference on Artificial
Intelligence and Statistics (AISTATS), pp. 4088-4097. PMLR, 2020.
14
Under review as a conference paper at ICLR 2022
Zihan Zhang, Yuan Zhou, and Xiangyang Ji. Almost optimal model-free reinforcement learn-
ingvia reference-advantage decomposition. Advances in Neural Information Processing Systems
(NeurIPS), 33, 2020.
Guanjie Zheng, Fuzheng Zhang, Zihan Zheng, Yang Xiang, Nicholas Jing Yuan, Xing Xie, and
Zhenhui Li. Drn: A deep reinforcement learning framework for news recommendation. In Pro-
Ceedings ofthe 2018 World Wide Web Conference (WWW),pp.167-176, 2018.
Zhixin Zhou, ShUlong Tan, ZhaozhUo Xu, and Ping Li. Mobius transformation for fast inner product
search on graph. Advances in Neural Information Processing Systems (NeurIPS), 32, 2019.
15
Under review as a conference paper at ICLR 2022
Contents
1	Introduction	1
2	Related Work	2
3	Background	4
3.1	Locality Sensitive Hashing ................................................... 4
3.2	Reinforcement Learning ....................................................... 5
4	Our Results	5
4.1	Sublinear Least-Squares Value Iteration ...................................... 5
4.2	Sublinear Least-Squares Value Iteration with UCB ............................. 6
5	Our Techniques	7
5.1	Avoid Negative Inner Product or Inner Product Close to 0 ..................... 7
5.2	Avoid Inner Product Close to 1 ............................................... 8
5.3	Approximate Max-IP Data Structure for LSVI-UCB ............................... 8
5.4	Generalize the Approximate Max-IP Data Structure for Max-MatNorm ............. 9
5.5	Preserving Regret While Reducing the Runtime ................................. 9
5.6	Handle Adaptive Queries in (c, τ)-Max-IP ..................................... 9
6	Conclusion	9
A	Preliminaries	18
A.1	Basic Notations ............................................................. 18
A.2	Notations and Definitions ................................................... 18
A.3 Standard Properties of Linear MDP ............................................ 20
A.4	Locality Sensitive Hashing .................................................. 20
A.5	Probabilistic Tools ......................................................... 22
A.6	Inequalities ................................................................ 22
B Data Structures	22
B.1	Existing Transformation from Primal to Dual ................................. 22
B.2	Sublinear Max-IP Data Structure ............................................. 23
B.3	Sublinear Max-IP Data Structure for Maximum Matrix Norm Search .............. 24
B.4	Transformation for Efficient Query .......................................... 25
B.5	Sublinear Query Time: Part 1 ................................................ 26
B.6	Sublinear Query Time: Part 2 ................................................ 27
C	Sublinear Least-Squares Value Iteration	29
C.1	Algorithm ................................................................... 29
16
Under review as a conference paper at ICLR 2022
C.2	Value Difference .......................................................... 29
C.3	Regret Analysis ........................................................... 31
C.4	Running Time Analysis ..................................................... 34
C.5	Comparison ................................................................ 36
D Sublinear Least-Squares Value Iteration with UCB	37
D.1	Algorithm ................................................................. 37
D.2	Notations for Proof of Convergence ........................................ 38
D.3	Upper Bound on Weights in Sublinear LSVI-UCB .............................. 39
D.4	Our Net Argument .......................................................... 40
D.5	Upper Bound on Fluctuations ............................................... 41
D.6	Upper Bound of Difference of Q Function ................................... 42
D.7	Q Function Difference by Induction ........................................ 43
D.8	Recursive Formula ......................................................... 45
D.9	Regret Analysis ........................................................... 46
D.10	Running Time Analysis .................................................... 47
D.10.1 LSVI-UCB ........................................................... 47
D.10.2 Sublinear LSVI-UCB ................................................. 48
D.11 Comparison ................................................................ 49
E Extension of Sublinear LSVI-UCB	49
E.1 LSVI-UCB Under Switch	Limitation ........................................... 49
E.2 Model-free LSVI-UCB ........................................................ 50
E.3 Comparison ................................................................. 51
F More Data Structures: Adaptive Max-IP Queries	51
F.1 Sublinear LSVI with Adaptive Max-IP Queries ................................ 51
F.2 Sublinear LSVI-UCB with Adaptive Max-MatNorm Queries ....................... 53
17
Under review as a conference paper at ICLR 2022
Contents
Roadmap. Section A introduces the preliminaries of this work, including notations and defini-
tions, Section B introduces the LSH data structure in detail, Section C presents the results for Sublin-
ear LSVI, Section D presents the results for Sublinear LSVI-UCB, Section E presents the extension
of Sublinear LSVI-UCB to different RL settings, Section F shows how to process adaptive queries
in Max-IP.
A	Preliminaries
This section introduces the preliminaries for our work.
•	In Section A.1, we present the basic notations used in our work.
•	In Section A.2, we introduce several reinforcement learning.
•	In Section A.3, we list the standard properties of linear MDP.
•	In Section A.4, we introduces the definitions of locality sensitive hashing data structures
and their applications in nearest neighbor search.
•	In Section A.5, we list the probabilistic tools used in our work.
•	In Section A.6, we list the inequalities to help the proof.
A. 1 Basic Notations
We use Pr[] to denote probability and E[] to denote expectation if it exists.
For a matrix A, we use kAkF := (Pi,j Ai2,j)1/2 to denote the Frobenius norm ofA, we use kAk1 :=
Pi,j |Ai,j | to denote the entry-wise `1 norm ofA, we use kAk to denote the spectral norm of A. We
say matrix A ∈ Rd×d is a positive semidefinite matrix if for all x ∈ Rd, x>Ax ≥ 0. We say matrix
A ∈ Rd×d is a positive definite matrix if for all x ∈ Rd, x>Ax > 0.
For a vector x, we use kxk2 := (Pi xi2)1/2 to denote the `2 norm of x, we use kxk1 := Pi |xi| to
denote the '1 norm of x, We use ∣∣χ∣∣∞ to denote the '∞ norm.
For a vector x ∈ Rd and a psd matrix A ∈ Rd×d, we use kxkA := (x>Ax)1/2 to denote the matrix
norm of x over A.
We use Sd-1 to denote the unit sphere.
A.2 Notations and Definitions
In this section, We present the notation and definitions for reinforcement learning. We summarize
our notations in Table 2.
We start With the definition of the Episodic Markov decision process.
Definition A.1 (Episodic Markov decision process (episodic MDP)). Let MDP(S, A, H, P, r) de-
note the episodic Markov decision process, Where S denotes the set of available states, A denotes
the set of available actions, H ∈ N denotes the total number of steps in each episode, P = {Ph}hH=1
With Ph[s0|s, a] denotes the probability of transition from state s ∈ S to state s0 ∈ S When take
actions a ∈ A at step h, r = {rh}hH=1 denotes the reWard obtained at each step. Here the reWard rh
is a function that maps S × A to [0.55, 1]vi
Note that for any reward range [a, b], there exists a shift C and scaling α so that (a + c)∕α = 0.55
and (b + c)∕α = 1 The shift in reward is designed for sublinear runtime in maximum inner product
search. We will provide more discussion in Section B.5.
viNote that in standard reinforcement learning, we assume reward is [0, 1], but it is completely reasonable to
do a shift. We will provide more discussion in Section 5.1.
18
Under review as a conference paper at ICLR 2022
In this work, we focus on linear Markov decision process (linear MDP). In this setting, each pair of
state-action is represented as an embedding vector. Moreover, the transition probability Ph[s0|s, a]
and reward function rh are linear in this embedding vector.
Notation	Meaning
飞	states space
A	action space
Score		core state set
Acore	core action set
~s	# states
-A	# actions
F	number of steps per episode
-K	number of episodes
~s	next state of state S
P	state transition probability
Ph[s0∣s, a]	transition probability when we take action a ∈ A at step h ∈ [H] from state S ∈ S.
rh(s,a) 一	reward at step h given state S and action a
r	{rh}H=I	〃
φ(S,a)	feature map Φ(s, a) ∈ Rd
μh(s)	UnknOWnmeaSurethat Ph [S0∣S,a] = hφ(S,a),μh(S)∖
θh	unknown measure that rh(S, a) = hφ(S, a), θh
Φ		Φ ∈ Rd×M
n	number of samples played given from each φj.
Table 2: Notations related to reinforcement learning.
Definition A.2 (Linear MDP Bradtke & Barto (1996); Melo & Ribeiro (2007)). The
MDP(S, A, H, P, r) becomes a linear MDP if there exists a function φ : S × A → Rd
and an unknown signed measure set μhr = (μh1,... ,μhd) over S such that the transi-
tion probability Ph[s0∣s, a] = hφ(s,a),μh(s0)i at any step any h ∈ [H]. Here we assume
max(s,a)∈S×A kφ(S, a)k2 ≤ 1. Moreover, there exists a hidden vector θh ∈ Rdso that rh(S, a) =
hΦ(s, a), θhi. Here we assume maXh∈[H]{∣∣μh(S)k2,∣∣θh∣∣2} ≤ √d.
In the MDP framework, we define the policy π as a sequence of functions that map state to actions.
Definition A.3 (Policy). Given a MDP Withform MDP(S, A, H, P, r), a policy π = {∏ι,…，∏h}
is defined as sequence such that πh : S → A for each step h. πh(S) = a represents the action taken
when we are at state S and step h.
Moreover, We use Vhπ(s) : S → R to define the value of cumulative reWards in expectation if the
agent folloWs received under a given policy π When the start state is s and the start step is h.
Definition A.4 (Value function). Given a MDP with form MDP(S, A, H, P, r), We let the value
function be:
H
Vhπ(S) := E X rh(S0h,πh(S0h))
sh = s
∀s ∈ S, h ∈ [H].
h0=h
Further more, We define the Q function Qhπ(s, a) : S × A → R as the expected cumulative reWards
if a agent folloWs policy π and starts from takeing action a at state s and step h. This representation
of Qhπ(s, a) is also associated With the Well-knoWn Bellman equation Sutton & Barto (2018).
Definition A.5 (Q-Learning). Let MDP(S, A, H, P, r) denote an episodic MDP. We use a simplified
notation [Ph,Vh+ι](s, a) := Es，〜胖,同⑶。][Vh+ι(s0)]. Then, We represent the Bellman equation with
policy π as
Qhπ(s,a) = [rh +PhVhπ+1](s,a),
Similarly, for optimal policy π*, We have
Qh(s,a) = [rh + PhVh+ι](S,a),
Vhπ(s) =Qπh(s,πh(s)),
VHπ+1 (s) = 0.
Vh(S) = maχQh(S, a),
a∈A
VH +ι(s) = 0.	(5)
19
Under review as a conference paper at ICLR 2022
Note that as rh ∈ [0, 1]. All Qhπ and Vhπ are upper bounded by H + 1 - h.
After formulate the MDP and its value functions, we start listing conditions on the space of state
and action for the convenience of our Sublinear LSVI and Sublinear LSVI-UCB. We first present
the definition for the convex hull.
Definition A.6 (Convex hull). Given a set {x1,x2, ∙一，xn} ⊂ Rd that denotes as a matrix A ∈
Rd×n,
we define its convex hull B(A) to be the collection of all finite linear combinations y that
satisfies y = En=I αi ∙ Xi, Where a ∈ [0,1] for all i ∈ [n] and £记网电=L
In this work, we focus on the Sublinear LSVI under continuous state and action space. Given the
action space A and state space S, we formulate φ((S × A)) as the convex hull of φ(Score × Acore),
where Score is core state set and Acore is core action set.
Definition A.7 (Core state and core action sets). Given a linear MDP with form
MDP(S, A, H, P, r), we define set Score ⊂ S as the core states set and Acore ⊂ A as the
core action set. We denote cardinality of Score and Acore as S and A. Specifically, we have
B(φ(Score × Acore)) = φ(S × A). Without loss of generality, we let A ≥ d.
In LSVI Bradtke & Barto (1996), the value iteration procedure requires a span matrix that contains
state-action embeddings. Moreover, there also exists a series of assumptions on the span matrix. We
provide these assumptions as below:
Definition A.8 (Span matrix). Given a linear MDP with form MDP(S, A, H, P, r), we define the
span matrix Φ ∈ Rd×M as follows: in total M ≤ d columns, the jth column is denoted as φj =
φ(sj,aj), where (sj, o7∙) ∈ S × A. Moreover, {φ1,φ2,…,Φm} is the linear span of φ(S X A).
Specifically, Φ satisfies:
•	φ(s, a) = PjM=1 wjφj, wj ∈ R for all (s, a) ∈ S × A,
•	rank(Φ) = M,
•	max(s,a)∈S×A kΦ-1φ(s, a)k1 ≤ L.
Next, we follow Jin et al. (2020) and making assumptions for Sublinear LSVI-UCB. Given a linear
MDP with form MDP(S, A, H, P, r), we assume S is finite with cardinally S and A is finite with
cardinally A.
A.3 S tandard Properties of Linear MDP
We list the tools for analyzing linear MDPs properties from Jiang et al. (2021) in this section.
Lemma A.9 (Proposition 2.3 Jin et al. (2020)). The Q function with form Qhπ (s, a) in linear MDP
could be represented it as a inner product Qπh (s, a) = hφ(s, a), whπ i, where whπ ∈ Rd is a weight
vector.
Next, we show the upper bound of weight whπ for any policy π .
Lemma A.10 (Lemma B.2 Jin et al. (2020)). Given a linear MDP, let whπ denote the weight that
achieves Qhπ (s, a) = hφ(s, a), whπi for all (s, a) ∈ S × A at step h ∈ [H]. We show that for
IlWn∣∣2 ≤ 2H√dfor any h ∈ [H],
A.4 Locality Sensitive Hashing
We define locality sensitive hashing (LSH). These definitions are very standard, e.g., see Indyk and
Motwani Indyk & Motwani (1998).
Definition A.11 (Locality Sensitive Hashing). Let dist denote a metric distance. Let C denote a
parameter such that C > 1. Let p1,p2 denote two parameters such that 0 < p2 < pi < 1. A family
H is called (r, C ∙ r,p1,p2)-sensitive if and only if, for any two point x,y ∈ Rd, a function h ChOSen
uniformly from the family H has the following properties:
•	if dist(x, y) ≤ r, then Prh〜H [h(x) = h(y)] ≥ pi,
20
Under review as a conference paper at ICLR 2022
•	if dist(x, y) ≥ C ∙ r,, then Prh〜H[h(x) = h(y)] ≤ p2.
We focus on situations where dist is `2 or cosine distance.
LSH is designed to accelerate the runtime of the Approximate Nearest Neighbor (ANN) problem.
We start with define the exact NN problem as:
Definition A.12 (Exact Nearest Neighbor (NN)). Given an n-point dataset Y ⊂ Sd-1 on the sphere,
the goal of the Nearest Neighbor (NN) problem is to find a datapoint y ∈ Y for a query x ∈ Sd-1
such that
NN(x, Y ) := min kx - yk2.
y∈Y
Indyk & Motwani (1998) relax the NN problem in Definition A.12 as with approximation and define
the Approximate Nearest Neighbor (ANN) problem.
Definition A.13 (Approximate Nearest Neighbor (ANN)). Let C > 1. Let r ∈ (0, 2). Given an
n-point dataset P ⊂ SdT on the sphere, the (C, r)-Approximate NearNeighbor Search (ANN) aims
at developing a data structure that, given a query q ∈ Sd-1 with the promise that there exists a
datapoint p ∈ P with kp - qk2 ≤ r, the data structure reports a datapoint p0 ∈ P with distance less
than C ∙ r from q.
Then, the query complexity of ANN is reduced to sublinear by LSH following Theorem A.14 and
Theorem A.15. Note that here We write O(1∕√logn) as o(1).
Theorem A.14 (AndOni and Razenshteyn AndOni & Razenshteyn (2015)). Let C > 1 and r ∈ (0, 2).
The (C, r)-ANN on a unit sphere SdT can be Solved by a data structure with query time O(d ∙ nρ),
space O(n1+ρ + dn) and preprocessing time O(dn1+ρ), where P = 2=2-1 + o(1).
Theorem A.15 (Andoni, Laarhoven, Razenshteyn and Waingarten Andoni et al. (2017a)). Let C >
1. Let r ∈ (0, 2). There exists a data structure that solves (C, r) - ANN on the unit sphere SdT
with query time O(d ∙ nρ), space O(n1+o(I) + dn) and preprocessing time O(dn1+o(1)), where
P = C - =4 + O(I).
In this work, we focus on the Max-IP, which is a well-known problem in the field of computational
complexity, we follow the standard notation in this work Chen (2018). We define the exact and
approximate Max-IP problem as follows:
Definition A.16 (Exact Max-IP). Given a data set Y ⊆ Rd, we define Max-IP for a query point
x ∈ Rd with respect to Y as follows:
Max-IP(x, Y ) := maxhx, yi.
y∈Y
Definition A.17 (Approximate Max-IP). Let C ∈ (0, 1) and τ ∈ (0, 1). Given an n-point dataset
Y ⊂ Sd-1, the (C, τ)-Max-IP aims at building a data structure that, given a query x ∈ Sd-1 with the
promise that there exists a datapoint y ∈ Y with hx, yi ≥ τ, the data structure reports a datapoint
Z ∈ Y with similarityhx, Zi greater than C ∙ Max-IP(x, Y).
To solve (C, τ)-Max-IP, we define a dual version of LSH data structure (Shrivastava and Li Shrivas-
tava & Li (2014) call it asymmetric LSH):
Definition A.18 (Locality Sensitive Hashing for similarity). Let C denote a parameter such that
C ∈ (0, 1). Let τ denote a parameter such that τ > 0. Letp1,p2 denote two parameters such that
0 < p2 < p1 < 1. Let sim(x, y) denote a binary similarity function between x
H is called (τ, C ∙ τ,p1,p2) -sensitive if and only if, for any query point X ∈ R
y ∈ Rd, h chosen uniformly from H has the following properties:
, y ∈ Rd. A family
d and a data point
•	if sim(x, y) ≥ T then Prh〜H [h(x) = h(y)] ≥ p1,
•	if sim(x, y) ≤ C ∙ T then Prh〜H[h(x) = h(y)] ≤ p2.
It is shown from Shrivastava & Li (2014) that LSH type data structure with asymmetric transforma-
tions could achieve sublinear runtime complexity of (C, T)-Max-IP.
21
Under review as a conference paper at ICLR 2022
A.5 Probabilistic Tools
Lemma A.19 (Hoeffding bound Hoeffding (1963)). Let xι, ∙∙∙ , Xn ben independent bounded Vari-
ables in [ai, bi]. Let , then we show the Hoeffding bound over x =	in=1 xi as:
Pr[|x - E[x]| ≥ t] ≤ 2 exp -
2t2
Pi=I (bi- a"
A.6 Inequalities
In this sections, we present the supporting inequalities for our work.
Fact A.20 (Lemma D.1 in Jin et al. (2020)). Given a matrix Λt = λId + Pit=1 φi φi> with φi ∈ Rd
and λ > 0, we show that:
t
X φi>(Λt)-1φi ≤ d.
i=1
Lemma A.21 (Lemma D.4 in Jin et al. (2020)). Let V denote a function family that
maxV ∈V,x∈S |V (x)| ≤ H. Let G denote the -covering number of V. Let S denote a state space.
Let {Fτ }τ∞=0 denote the filtration of S. Let {xτ }τ∞=1 denote a random process defined on S. Let
{φτ}τ∞=0 denote a real valued random process in Rd. Moreover, φτ ∈ Fτ-1 and we have upper
bound kφτ k2 ≤ 1. Given a matrix Λk ∈ Rd×d so that Λk = λId + Pτk=1 φτφτ>, for any δ > 0, for
any k ≥ 0, for any V ∈ V, we have
Il XXΦτ(V(xτ) — E[V(Xτ) | FT-i])∣∣2-1 ≤ 4H2(dlog(1 + k∕λ) + log(G"δ)) + 8k2e2∕λ,
τ=1	Λk
B	Data S tructures
This section presents the data Structures for our work.
•	In Section B.1, we introduce the transformations that build primal-dual connections be-
tween approximate Max-IP and ANN.
•	In Section B.2, we present our data structure that achieves sublinear query time in approx-
imate Max-IP.
•	In Section B.3, we show how to perform approximate Max-MatNorm via approximate
Max-IP data structure.
•	In Section B.4, we present our efficient transformations for Max-IP in optimization.
•	In Section B.5, we formally provide the theoretical results of sublinear approximate Max-IP
using one LSH data structure.
•	In Section B.6, we provide the theoretical results of sublinear approximate Max-IP using
another LSH data structure.
B.1 Existing Transformation from Primal to Dual
In this section, we show a transformation that builds the connection between Max-IP and NN. Under
this asymmetric transformation, NN is formulated as a dual problem of Max-IP.
We start with presenting the asymmetric transformation.
Definition B.1 (Asymmetric transformation Neyshabur & Srebro (2015)). Let Y ∈ Rd and ky k2 ≤
1 for all y ∈ Y . Let x ∈ Rd and kxk2 ≤ Dx. We define the following asymmetric transform:
P(V) =	[y> pi — kyk2 0]>	⑹
Q(X) =	[(χD-1)> 0 qi-kχD-1k2i>
22
Under review as a conference paper at ICLR 2022
Therefore, we have
kQ(x) - P (y)k22 = 2 - 2Dx-1hx,yi, arg maxhx, yi = arg min kQ(x) - P(y)k2.
y∈Y	y∈Y
In this way, we regard Max-IP as the primal problem and NN as a dual problem.
B.2 SUBLINEAR Max-IP DATA STRUCTURE
In this section, we show the theorem that provides sublinear query time for Max-IP problem using
LSH type data structure.
Theorem B.2 (Formal statement of Corollary 3.5). Let c ∈ (0, 1) and τ ∈ (0, 1). Given a set of
n-points Y ⊂ Sd-1 on the sphere, one can build a data structure with preprocessing time Tinit and
space SsPaCe so that for any query X ∈ S d-1, we take O(d ∙ nρ) query time:
•	if Max-IP(x, Y ) ≥ τ, then we output a vector in Y which is a (c, τ)-Max-IP with respect
to (x, Y ) with probability at least 0.9vii, where ρ := f(c, τ) + o(1).
•	otherwise, we output fail.
Further,
•	If Tnit = O(dn1+ρ) and SsPaCe = O(n1+ρ + dn), then f(c,τ) = 1-2-T+τ∙
•	If Tinit = O(dn1+o⑴)and SsPaCe = O(n1+o⑴ + dn), then f(c,τ)=((二)2 - ((II-T)
Proof. We start with showing that for any two points x, y with kxk2 = kyk2 = 1, we have kx -
yk2 = 2 一 2(x, yi. This implies that r2 = 2 一 2τ for a (c, r)-ANN and a (c, τ)-Max-IP on x, Y.
Further, if We have a data structure for (c, r)-ANN, it automatically becomes a data structure for
(c, T)-Max-IP with parameters T = 1 一 0.5r2 and C = 1-00⅞2. This implies that
1 一 c(1 一 0.5r2)	1 一 cτ
0.5r2
1 - τ
Next, we show how to solve (c, T)-Max-IP by solving (c, r)-ANN using two different data structures.
Part 1.	Ifwe initialize the data-structure following Theorem A.14, we show that the (c, τ)-Max-IP
on a unit sphere Sd-1 can be solved by solving (c, r)-ANN with query time O(d ∙ nρ), space
O(nI+ρ + dn) and preprocessing time O(dnI+ρ), where
1
1
1 — τ
P = 2c2 - 1
+ o(1)
1-cτ
1-τ
+ o(1)
1 一 2cτ + τ
+ o(1).
Thus,f (C,τ) = ι-2-T+τ
Part 2.	Ifwe initialize the data-structure following Theorem A.15, we show that the (C, τ)-Max-IP
on a unit sphere Sd-1 can be solved by solving (c, r)-ANN with query time O(d ∙ nρ), space
O(nI+o(I) + dn) and preprocessing time O(dnI+o(I)), where
21
P = C2 - C4 + o(1)
2(1 - τ)2	(1 - τ)4
(1 - Cτ )2	(1 - Cτ )4
+ o(1).
Thus, f(c,τ) = ⅞a≡)2 - (T-τ4
In practice, we tune parameter τ close to Max-IP(x, Y) to achieve higher C. Moreover, Theorem B.2
could be applied to general Max-IP problem. To do this, we first apply asymmetric transformation
viiIt is obvious to boost probability from constant to δ by repeating the data structure log(1 /δ) times.
23
Under review as a conference paper at ICLR 2022
in Definition B.1 and transfer it to a (c, τ)-Max-IP problem over Q(x) and Q(Y ). Then, we solve
this (c, T)-Max-IP problem by solving its dual problem, which is (c, r)-ANN. Finally, the solution
tothe (c, r)-ANN would be the approximate solution to the original MaX-IP(x,Y). Meanwhile, it is
reasonable for us to regard d = no(1)
using Johnson-Lindenstrauss Lemma Johnson & Lindenstrauss
(1984).
B.3 SUBLINEAR Max-IP DATA STRUCTURE FOR MAXIMUM MATRIX NORM SEARCH
In this section, we extend LSH type Max-IP data structure for maximum matrix norm search.
Definition B.3 (Exact Maximum Matrix Norm (Max-MatNorm)). Given a data set Y ⊆ Rd and a
query matrix x ∈ Rd×d, we define Maximum Matrix Norm as follows:
Max-MatNorm(x, Y) := max kykx.
y∈Y
Next, we define the approximate version of the Maximum Matrix Norm.
Definition B.4 (Approximate Max-MatNorm). Let c ∈ (0, 1) and τ ∈ (0, 1). Let vec denote the
vectorization of d × d matrix into a d2 vector. Given an n-point dataset Y ⊂ Rd and yy> ∈ Sd2 -1
for all y ∈ Y, the goal of the (c, τ)-Max-MatNorm is to cosntruct a data structure that, given a
query matrix x ∈ Rd×d and vec(x) ∈ Sd2 -1 with the promise that there exists a datapoint y ∈ Y
with kykx ≥ τ, it reports a datapoint Z ∈ Y with ∣∣zkχ ≥ C ∙ Max-MatNorm(x,Y).
Next, we show the relationship between Max-MatNorm and Max-IP
Lemma B.5 (Relation between Max-MatNorm and Max-IP). We show that
Max-MatNorm(X, Y)2 = maxhvec(x), vec(yy>)
y∈Y
where vec vectorizes d × d matrix x into a d2 vector.
Proof. We show that
Max-MatNorm(x, Y)2 = max ∣y∣2x
y∈Y	x
= max y>xy
y∈Y
= maxhvec(x), vec(yy>)i
y∈Y
where the first step follows the definition of Max-MatNorm, the second step follows from the defi-
nition of ∣y ∣2x, the third step decomposes the quadratic form into a inner product.
□
Next, we present our main theorem for Max-MatNorm(x, Y).
Theorem B.6. Let c denote a parameter such that c ∈ (0, 1). Let τ denote a parameter such that
τ ∈ (0, 1). Let vec denote the vectorization of d × d matrix into a d2 vector. Given a n-points set
Y ⊆ Rd and yy> ∈ Sd2-1 for all y ∈ Y, one can construct a data structure with Tinit preprocessing
time and Sspace so that for any query matrix x ∈ Rd×d with vec(x) ∈ Sd2-1, we take query time
complexity O(d2nρ ∙ log(1∕δ)):
•	if Max-MatNorm(x, Y) ≥ τ, then we output a vector in Y which is a (c, τ)-Max-MatNorm
with respect to (x, Y) with probability at least 1 - δ, where ρ := f(c, τ) + o(1).
•	otherwise, we output fail.
Further,
•	If Tnit = O(d2n1+ρ ∙ log(1∕δ)) and SsPaCe = O((n1+ρ + d2n) ∙ log(1∕δ)), then f(c,τ)=
1-τ 2
1 —c2τ2+τ2 .
24
Under review as a conference paper at ICLR 2022
• If Tnit = O(d2n1+o⑴∙ log(1∕δ)) and SsPaCe = O((n1+o⑴ + d2n) ∙ log(1∕δ)), then
2(1-τ2)2	(1-τ2)4
f (c，T) = (1-c2τ2)2 — (1-c2τ2)4 '
Proof. We start with showing that ifwe have a (c2, τ2)-Max-IP data structure over vec(x) and every
vec(yy>), y ∈ Y , we would obtain a z ∈ Y such that
hvec(x), vec(zz>)i ≥ c2 maxhvec(x), vec(yy>)i,
y∈Y
we could use it and derive the following propriety for z :
(7)
kzkx =	hvec(x), vec(zz> )i
≥ Jc2 maxhvec(x), vec(yy›)i
= c max	hvec(x), vec(yy>)i
= cmax kykx
y∈Y
where the second step follows from Eq. (7).
Therefore, z is the solution for (c, T)-Max-MatNorm(x, Y ).
Next, we show how to retrieve z via two data structures used for (c, T)-Max-IP(x, Y ) in Theo-
rem B.2.
Part 1.	If we initialize the data structure following Theorem A.14, we can construct a data structure
with O((n1+ρ+d2n)∙log(1∕δ)) preprocessing time and O((n1+ρ+d2n)∙log(1∕δ)) space so that for
any query matrix X ∈ Rd×d with Vec(X) ∈ Sd2-1 ,we take query time complexity O(d2nρ ∙log(1∕δ))
to retrieve z. Here P = ι-1-T+τ2 + o(1) and We are able to improve the failure probability to δ by
repeating the LSH for log(1∕δ) times.
Part 2.	Ifwe initialize the data structure following Theorem A.15, we can construct a data structure
with O((n1+o⑴ + d2n) ∙ log(1∕δ)) preprocessing time and O((n1+o⑴ + dn) ∙ log(1∕δ)) space
so that for any query matrix X ∈ Rd×d with vec(X) ∈ Sd2-1, we take query time complexity
2(1-τ 2)2	(1-τ 2)4
O(d2nρ ∙ log(1∕δ)) to retrieve z. Here P = ʊ--T^ — ((—-2T始 + o(1) and we also improve the
failure probability to δ by repeating the LSH for log(1∕δ) times.
□
Moreover, Theorem B.6 could be applied to general Max-MatNorm problem. To do this, we first
apply transform (c, T)-Max-MatNorm problem into a (c2, T 2)-Max-IP problem using Lemma B.5.
Next, we apply transformations in Definition B.1 and transfer the (c2, T 2)-Max-IP problem to a
(c2, T2)-Max-IP problem over Q(X) and Q(Y ). Then, we solve this (c2, T 2)-Max-IP problem by
solving its dual problem, which is (c, r)-ANN. Finally, the solution to the (c, r)-ANN would be the
approximate solution to the original Max-MatNorm(X, Y ).
B.4	Transformation for Efficient Query
In the optimization problem that could be accelerated by (c, T)-Max-IP, the query and data vectors
are usually not unit vectors so that we apply transformations in Definition B.1 to map both query
and data vectors into unit vectors. However, if the mapped inner product is too close to 1. The
formulation of P would break and the time complexity would be linear. To avoid this, we propose a
new set of asymmetric transformations:
Definition B.7 (Efficient asymmetric transformation). Let Y ∈ Rd and kyk2 ≤ 1 for all y ∈ Y. Let
X ∈ Rd and kXk2 ≤ Dx. We define the following asymmetric transform:
P(y) = [yτ Pr-IyI o]τ, Q(X) = [0Dx> 0 √ι — 0⅜2xk2i>.
25
Under review as a conference paper at ICLR 2022
Next, we use Lemma B.8 to show how to enforce τ to be away from 1 via our efficient asymmetric
transformation.
Lemma B.8. Given the transformation P and Q defined in Definition B.7, we show that both
Max-IP(Q(x), P(Y )) and NN(Q(x), P(Y )) are equivalent to Max-IP(x, Y ). Moreover,
Max-IP(Q(x), P (Y)) ≤ 0.8.
Proof. Using transformations in Definition B.7, for all y ∈ Y , we have
Q(x)>P(y) = 0.8∙x>y ≤ 0.8 ∙ kxk2kyk2 ≤ 0.8
Dx	Dx
where the third step follows from kxk2 ≤ Dx and kyk2 ≤ 1.
Next, we show that Max-IP(Q(x), P(Y )) is equivalent to Max-IP(x, Y ).
arg max Q(x)>P (y)
y∈Y
arg max
y∈Y
。8 ∙(χ,y>
-Dx-
arg maxhx, y i.
y∈Y
Further more, NN(Q(x), P(Y )) (see Definition A.12) is equivalent to Max-IP(x, Y ).
kQ(x) - P (y)k22 = 2 - 1.6Dx-1hx,yi, arg min kQ(x) - P (y)k2 = arg maxhx, yi.
y∈Y	y∈Y
□
B.5	Sublinear Query Time: Part 1
In this section, we show that ρ is strictly less than 1 using LSH in Andoni & Razenshteyn (2015).
Lemma B.9. If LSH data structure’s parameters c and τ satisfy that c ∈ [0.5, 1) and τ ∈ [0.5, 1)
then, we could upper bound ρ as:
ρ < 1 - γ + O(1∕plog n)
where γ = 1 - c.
Proof. We can upper bound ρ as follows:
ρ
1 — T
1 — 2 cτ + τ
+ o(i/VZIogn)
=1-，T1- 2cτ + O(I/pIogn)
1 — 2cτ + τ
,	2τ	_ ,,匚----.
=1 - (I - C) - 1 - 2cτ + T + OQl√logn)
≤ 1 - (I - C) -:I~~1—— + O(I∕plogn)
1 — 2cT + T
< 1 — (1 — c) • 1 + O(1∕plogn)
=1 — γ+O(1∕ριogn)
by T ≥ 0.5
by T < 1
where the second and third steps are reorganizations, the forth step follows from T ≥ 0.5, the fifth
step follows from T < 1 and C ≥ 0.5, the last step is a reorganization.
Therefore, we complete the proof.
For Sublinear LSVL we set C = 1 — CoLyfIpn and and T ≥ 0.5 by shifting the reward function. In
this way, we have
□
ρ < 1 —
/+O( √⅛)< 1 - 4C0L"
(8)
26
Under review as a conference paper at ICLR 2022
where the first step follows from Y = 1 - C = C0L，i/n, the second step follows from
4 CoLP1Tn >。( √⅛).
For Sublinear LSVI-UCB, we set C = 1 -春 and τ ≥ 0.5 by shifting the reward function. In this
way, we have
P < 1----^j= + O(-；===) < 1------j=	(9)
2 √K	√10gA	4 √K
where the first step follows from Y = 1 - C = √=, the second step follows from ^√^ > Ω(√0gA).
Therefore, we show that sublinear value iteration can be achieved while preserving the same regret.
B.6 Sublinear Query Time: Part 2
In this section, we show that P is strictly less than 1 using LSH in Andoni et al. (2017a).
Using Andoni et al. (2017a), the P for LSH based Max-IP data structure with parameters C and τ
becomes
2(1-τ )2
(1 — cτ )2
(1-τ )4
(1 — cτ )4
o(1)
—
where is a function over C and τ .
To upper bound the P, we start with showing that it is decreasing as τ increase when C ∈ [0.5, 1) and
τ ∈ [0.5, 1).
Lemma B.10. Let C ∈ [0.5, 1) and τ ∈ [0.5, 1). We show that function
f (C T) := 2(1 - T)2 - (I - T)4
“'):= (1 - CT)2	(1 - CT)4
is decreasing as T increase.
Proof. We take the derivative of f(C, T) in T and get
S T) = -4(C- 1)2(T - I)T(Ct + T- 2) < 0
∂T	(1 - CT )5
where the second step follows from C ∈ [0.5, 1) and T ∈ [0.5, 1).
Thus, f(C, T) is decreasing as T increase when C ∈ [0.5, 1) and T ∈ [0.5, 1).
□
Next, we have our results in upper bounding P.
Lemma B.11. If LSH data structure’s parameters C and T satisfy that C ∈ [0.5, 1) and T ∈ [0.5, 1)
then, we could upper bound P as:
γ 2	〜，J--------、
P < 1 - -4 + O(1/Vzlogn)
where Y = 1 - C.
Proof. Let Y = 1 - C, we have
2	1	r——、
P = C2 - C4 + O(1//log n)
2(1-T)2
(1 - CT)2
(⅛⅛T)44 + O(1∕k)
/	0.5
≤ (1 - 0.5c)2
0.0625
(1-0.5c)4 +O(1/Po痴)
—
27
Under review as a conference paper at ICLR 2022
0.5
(0.5 + 0.5γ)2
0.0625
(0.5 + 0.5γ )4
+ O(1//log n)
2
(i + τ7
-(1； γ)4 + O(1/piogn)
2 + 4γ + 2γ2 - 1	C p / p-、
—(1+^)4— + O(1/Vlog n)
=1+14+ +)2γ + O(1/Piogn)
=1 - 4γ2(++γY)+ Y4 +O(1∕k)
4Y2
<	1 - (1+ γ )4 + O(I/ VZlog n)
γ2	,____
<	1 - W + O(1/VZlog n)
by γ > 0
by γ < 1
where the second step follows from C2 = FTT, the third step follows from that P is monotonic
decrease as τ increase and τ ≥ 0.5, the forth to eighth steps are reorganizations, the ninth step
follows from γ = 1 - c > 0, the tenth step follows from γ = 1 - c < 1.
For Sublinear LSVL we set C = 1 - CoLyfIpn and and T ≥ 0.5 by shifting the reward function. In
this way, we have
ρ<1-
空+O( √⅛ )< 1 -1 …
(10)
where the first step follows from γ
ω( √⅛a )
1-c = CoLʌ/i/n, the second step follows from 1C2L2i/n >
—
□
For Sublinear LSVI-UCB, we set C = 1 -春 and T ≥ 0.5 by shifting the reward function. In this
way, we have
ρ < 1 - 3 + O( /iɪ^) < 1 -U	(ID
4K	log A	8K
where the first step follows from Y = 1 - C = √=, the second step follows from 康 > Ω( √^1g-A).
Therefore, we show that sublinear value iteration can be achieved while preserving the same regret.
28
Under review as a conference paper at ICLR 2022
C Sublinear Least-Squares Value Iteration
This section presents the Sublinear Least-Squares Value Iteration (Sublinear LSVI)
•	In Section C.1, we introduce the Sublinear LSVI algorithm.
•	In Section C.2, we provide the upper bound of the difference between the optimal value
function and the estimated value function.
•	In Section C.3, we present the regret analysis of Sublinear LSVI.
•	In Section C.4, we perform a runtime analysis on the building blocks of Sublinear LSVI to
analyze its efficiency.
•	In Section C.5, we compare Sublinear LSVI with LSVI Bradtke & Barto (1996) in regret
and value iteration complexity.
C.1 Algorithm
We present our Sublinear LSVI algorithm in Algorithm 1. We summarize our algorithm as several
steps: (1) sample collection: we query a pair of state and action in the span matrix for n times at
each step and observe its reward and next state, (2) data structure construction, we preprocess the
embeddings for state and action pairs and build a nearest neighbor data structure, (3) we perform
least-squares solver to estimate the weight in the linear MDP model, (4) we use LSH for value
function estimation, (5) we construct policy based on the estimated value function.
C.2 Value Difference
In this section, we provide the tools for regret analysis. The goal of this section is to prove
Lemma C.1.
Lemma C.1. Let MDP(S, A, H, P, r) denote a linear MDP. Let %* (s) be the optimal value function
defined in Definition A.5. Let V1 (s) be the estimated value function defined in Definition A.5. We
show that via Algorithm 1, the difference %* (s) - VI(S) is UPPer bounded by:
H1
V*(s)-V1(s) ≤ E [X[(Ph - Ph)Vh+1](sh,ah)∣s1 = s] +---c ∙ H(H +1)	(12)
π h=1
where c is the Parameter for Max-IP.
τ-> e 5T	∙ ,ι i	1	τ -r^> / ∖
Proof. We start with lower bounding Vh(s) as
Vh(S) ≥ C ∙ max hwh,φ(s,a)i
a∈A
core
= cmax Qh(S, a)
a∈A
(13)
where the first steP follows from Theorem B.2, the second steP follows from the definition of
Qh(S, a) in Definition A.5 and the definition of convex hull.
■‰ T	1	FT 7∙*∕∖ T> /	∖
Next, We upper bound Vh=(S) - Vh(S) as
______ . ʌ , . . . , . ^ ,.
Vh= (S) - Vbh(S) = max Q=h(S, a) - Vbh(S)
a∈A
=
≤ max Q=h(S, a) - cmax Qh(S, a)
≤Q=h(S,π=(S)) -
≤Q=h(S,π=(S)) -
= cQ=h(S, π=(S))
cmax Qh(S, a)
a∈A
^ ,,,,
cQbh (S, π = (S))
- Qbh(S, π=(S)) + (1 - c)Q=h(S, π=(S))
29
Under review as a conference paper at ICLR 2022
Algorithm 1 Sublinear LSVI
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:
36:
37:
38:
39:
40:
41:
42:
43:
44:
data structure LSH	. Theorem B.2
INIT(S ⊂ Rd, n ∈ N, d ∈ N, c ∈ [0.5, 0.8), τ ∈ [0.5, 0.8))
. |S| = n, c, τ is the approximate Max-IP parameter and d is the dimension of data
QUERY(x ∈ Rd)
end data structure
procedure SUBLINEARLSVI(Score, Acore, N ∈ N, H ∈ N, cLSH ∈ [0.5, 0.8], τLSH ∈
[0.5, 0.8])
. Score and Acore are in Definition A.7
/*Collect Samples*/
for step h ∈ [H] do
Dh — 0
for j = 1,…，M do . For each column in the span matrix defined in Definition A.8
for l = 1,… ,n do	. Play n times
Query (sj , aj) at step h, observe the next state s0jl .
. sj , aj defined in Definition A.8
Dh JDh ∪{(sj, aj, sjι)}	. |Dh| = Mn
end for
end for
end for
/*Preprocess data and build a nearest neighbor data structure*/
.This step takes O(S ∙ (A1+ρ + dA))
for s ∈ Score do
Φs J {φ(s, a)| ∀a ∈ Acore}
static LSH LSHs
LSHs.INIT(Φs, A, d, cLSH, τLSH)
end for
/*Precompute Λ matrix*/	. This step takes O(M d2 + dω)
Λ J n PjM=1 φ(sj, aj)φ(sj,aj)>
Compute Λh-1
/*Update value function*/	. This step takes O(H(d2 + Md + Mn + SdAρ))
for step h = H, . . . , 1 do
Wh — AT P(s,a,sl0)∈Dh φ(s, a) (rh(s, a + Vh+ι(SlO))
for all s ∈ Score do
a J LSHs.QUERY(wbh)
Vh(s) J hwbh, φ(s, a)i
end for
end for
/*Construct policy*/	. This step takes O(HSdA)
policy πb J 0
for step h = 1, . . . , H do
πbh(s) J argmaxa∈Acorehwbh, φ(s, a)i for all
s ∈ Score
end for
return πb
end procedure
≤ C(Qh(S,∏*(s)) - Qh(S, Π*(s))) +(1 -C)(H + 1 - h)
≤ (Qh(s,∏*(s)) - Qh(s,∏*(S))) +(1 -C)(H +1 - h)
(14)
where the first step follows from Vh= (s) = max。*/ Qh(s, a), the second step follows from Eq. (13),
the third step follows from max。*/ Qh(s, a) = Qh(s, π*(s)) and the forth step follows from
max。*/ Qh(S, a) ≥ Qh(S, π=(S)), the fifth step is an reorganization, the sixth step follows the
upper bound for Q=h in Definition A.5, the seventh step follows from C ∈ (0, 1) and C is close to 1.
30
Under review as a conference paper at ICLR 2022
Next, We can write the difference Qh(s, a) - Qh(s, a) as,
Qh(s, a) — Qh(s, a) = [rh + PhVh+ι](s, a) — Vh + PhVh+ι](s, a)
=[PhVh+ι](s, a) - [PhVh+ι](s,a)
= [Ph Vh+1](s, a) - [PhVbh+1](s, a) + [PhVbh+1](s, a) - [PbhVbh+1](s, a)
=[Ph(琮+1 - ⅝+ι)](s, a) + [(Ph - Ph)⅝+1 ](s, a)	(15)
where the first step follows from the definition of Qh (s, a) in Definition A.5, the second step follows
from eliminating the common term rh(s, a), the third step follows from inserting an additional term
[PhVh+1](s, a), and the last step is a reorganization.
Combining Eq. (14) and Eq. (15), we have
... ^ ..
Vns)- Vh(S)
≤(Qh(s，∏*(s)) - Qh(s, ∏*(s))) +(1 -C)(H +1 - h)
一 , ^ . , . . . . . 一. ^ . ^ , . . . . . . .
=[Ph(Vh+ι - Vh+ι)](s, ∏*(s)) + [(Ph - Ph)Vh+ι](s, ∏*(s)) + (1 -C)(H +1 - h)
=E [(Vh+ι - Vh+1)(sh+1) I sh = si + E [[(Ph - Ph)Vh+ι](sh, ah) Ish = s]
+(1-C)(H+1-h)
=(Vh+1 - Vh+1)+ E [[(Ph - Ph)Vh+l](sh, ah) I sh = Si
+(1-C)(H+1-h)
where the first step follows the Eq. (14), the second step follows the Eq. (15), the third step rewrites
both terms into an expectation over ∏*, and the last step follows the definition of V^1 and Vh+ι.
Using induction from 1 to H, we have
HH
V*(s)- Vbι(s) ≤ E [X[(Ph - Ph)Vh+ι](sh, ah) I S1 = s] +(1 - C) X(H +1 - h)
π	h=1	h=1
H1
=E [X[(Ph - Ph)Vh+ι](sh, ah) I S1 = s] +=P ∙ H (H + 1)
π	h=1
where the second step is a reorganization.
□
C.3 Regret Analysis
The goal of this section is to prove Theorem C.2.
Theorem C.2 (Convergence Result of Sublinear Least-Squares Value Iteration (Sublinear LSVI), a
formal version of Theorem 4.1). Given a linear MDP with form MDP(S, A, H, P, r) with core sets
Score, Acore defined in Definition A.7, if we chose n = O(C0 ∙ e-2L2H4ι), where ι = log(Hd∕p)
and C is a constant, the Sublinear LSVI (Algorithm 1) with approximate MaX-IP parameter C =
1 - Θ(L ∙ ,ι∕n) has regret at most O(LH2 ,ι∕n) with probability at least 1 - p.
T->	八 5 Tl	,	FC	A /	∖ El C , 1 r∙ ∙ .∙	∙	∙	1 ʃʌ	∙ , ∙	AY ♦,
Proof. We have two definitions for Qh(s, a). The first definition is given by Definition A.1, it says
Qh(s, a) = rh(s, a) + [Ph ∙ Vh+ι](s, a).
The second definition is given by Definition A.2, it says
Qbh(s, a) = φ(s, a)>wbh .
(16)
(17)
Given the second definition, our
goal is to derive Pbh .
31
Under review as a conference paper at ICLR 2022
To do this, we write Qh(s, a) as
Qh(s, a)
=φ(s,α)丁通 h
=φ(s, a)τΛ-1	X	φ(S, a) "(s, a) + %+ι(S∕))
(S,a ,s'z0)∈Dh
=Φ(s, a)τΛ-1	X	Φ(s, a) (φ(s, a)τθh + Vbh+ι(s/))
(s,a,s ιl)∈rDh
=φ(s,	a)τΛ-1	E	φ(s, a)φ(s,	a)τθh	+	φ(s,	a)τΛ-1	E	φ(s, a)Vh+ι(s∕)
(s,a,s ι0)∈Dh	(s,a,s 10)∈Dh
=φ(s, a)τθh + φ(s, a)τΛ-1	X	φ(S, a)‰1(szz)
(s,a,sι0)∈Dh
=φ(s,a)τθh + / ^φ(s,a)τΛ-1	X	φ(S,a)δ(s0,s'/))Vh+ι(s0)ds0
(s,a,sι0)∈Dh
=rh(s,a)+ / ^φ(s,a)τΛ-1	X	φ(s,a)δ(s0,s∕))%+ι(s0)ds0	(18)
(s,a,s ι0)∈Dh
where the first step follows the definition of Qh(s, a) in Definition A.5, the second step follows the
definition of Wh in Algorithm 4, the third step follows the definition of reward rh in Definition A.2,
the forth step is an reorganization, the fifth step follows from Λ-1 P(S a sj)∈D, Φ(s, a)φ(s, a)τ =
Id, the sixth step rewrites the second term in a integral format, where δ(x, y) is a Dirichlet function,
the last step follows the definition of reward rh in Definition A.2.
By comparing Eq. (18) with Eq. (16), we should define Ph(Sls, a) as
Wh(SlS,a) = φ(s,a)Λ-1	X	φ(s,a)δ(s0 ,s'/).	(19)
(s,a,s ι0)∈Dh
_	.	.	........	-	.	.	.	.	^	r，	、.	...
Combining Eq. (19) with the definition of [PhVh+ι](s, a) in Definition A.5.
[Ph‰ι](s,a) = φ(s,a)τΛ-1	X	φ(S,a)‰1(S /).	(20)
(s,a,s ι0)∈Dh
In the next a few paragraphs, we will explain how to rewrite [(Ph - Ph)Vh+ι](s, a).
—
/
/
^
^ ^
=φ(s,a)τ
=φ(s,a)τ
‰1(s,)dμ(s,) - [Ph‰ι](s,a)
E	Φ(s,a)区+ι (s√)
(s,a,sι0 )∈Dh
Vh+ι(s0)dμ(s0)
⅝+1(sz)dμ(sz) - φ(s, a)τΛ-1
=φ(s,a)τΛ-1	^X	φ(s,a)φ(s,a)τ I
(s,a,s ι0)∈Dh
-φ(s, a)τΛ-1	E	φ(S, a)%+ι(S∕)
(s,a,sι0)∈Dh
=φ(s,a)TAT X φ(s,a)(φ(s, a)τ /
(s,a,s ι0)∈Dh
^
^
‰1(s,)dμ(s,) - 14+ι(s7)
=φ(s, a)τΛ-1	X	φ(S, a) ( / Vbh+ι(s0)φ(S, a)τdμ(s0) - ‰ι(sz0)
(s,a,s ι0)∈Dh
=φ(s,a)TAT	X φ(s,a)(/
(s,a,s ι0)∈Dh
^
^
‰1(s,)Ph[s,∣S,a]ds, - ‰1 (s√)
32
Under review as a conference paper at ICLR 2022
=φ(s, a)>Λ-1	X	φ(s, a)(E[Vbh+i(s0)|S, a] - Vbh+ι(si
(s,a ,Sι0)∈Dh
(21)
where the first step follows the definition of Ph [s0∣si, a4 = φ(si, a%)μh(s0), the second step follows
Eq. (20), the third step adds the AT P(S & gj)∈D, Φ(S, a)Φ(S, a)> = Id to the left term, the forth
and fifth steps are reorganizations, the sixth step follows the definition of Ph in Definition A.2, the
last step follows the definition of expectation.
Next, we rewrite P(s,a,sl0)∈Dh φ(s, a) as
X φ(s, a) =
(s,a ,sι 0)∈Dh
MM
n	φ(sj, aj) = n	φj	(22)
j=1	j=1
where the first steps follows from Algorithm 1 that for each φ(sj, aj), we query it n times and put all
{(sj,aj, sjι),…，(sj, aj, sjn)} in Dh, the second step follows by φj = φ(sj,aj) in Definition A.7.
Next, we rewrite A as
a = E	φ(s,a)φ(s,a)>
(s,a ,sι0)∈Dh
M
= n	φ(sj, aj)φ(sj, aj)>
j=1
= nΦΦ>	(23)
where the first steps follows by the definition of A in Algorithm 1,the second steps follows from
Algorithm 1 that for each φ(sj, aj), We query it n times and put all {(sj, aj, sjj,…，(sj, aj, sjn)}
in Dh, the third step follows from the definition of Φ in Definition A.7.
Combining Eq. (23) with Eq. (21), we get
[(Ph - Ph)B+ι](s, a) = φ(s, a)>(nΦΦ>)-1	X	φ(s, a) (E[Vh+1(s0)∣S, a] - Vbh+ι(si))
(s,a ,sι0 )∈Dh
(24)
Next, we further bound [(Ph - Ph)Vh+1](s, a) as:
[(Ph - Pbh)Vbh+1](s, a)
=φ(s,a)>(nφφ>)T	X	φ(s,a)( E[Vbh+1(s0)|S, a] - Vbh+1(Si))
(s,a ,sι0)∈Dh
Mn
= φ(S,a)>(nΦΦ>)-1nXφ(Sj, aj) X E[Vbh+1(S0)|Sj,aj] - Vbh+1(S0jl)
j=1	l=1
Mn
=φ(s, a)>(φφ>)τ X φ(sj ,aj) (E[Vh+ι(s0 )ιsj, aj]- n X Vbh+ι(Sjl))
Mn
=φ(s,a)>(φφ>)τ X Oj(E[Vbh+i(s0)|sj ,aj]- n X Vbh+ι(Sjl))
where the first step follows from Eq. (24), the second steps follows from Algorithm 1 that for each
φ(sj,aj), We query it n times and put all {(sj∙, aj, sjι), •一，(sj, aj, sjn)} in Dh, the third step is
an reorganization, the last step follows the definition of φj in Definition A.7.
For each j ∈ [M], we define random variable
n
1
zj := EM+1(s )lφj] - nEVh+1(Sjl)
l=1
33
Under review as a conference paper at ICLR 2022
By Hoefding Inequality in Lemma A.19, we can show
∣zj i ≤ Co ∙ H ∙ pρ∣∕n
For convenient, We define vector Z ∈ RM to be Z := [zι,…，ZM].
NoW, We can upper bound [(Ph - Ph)Vh+1](s, a) as folloWs:
[(Ph - Pbh)Vbh+1](s, a) =φ(s,a)>(ΦΦ>)-1ΦZ
=φ(s,a)>(φt)>z
=(φtφ(s,a)) z
≤kΦtφ(s,a)kι ∙kzk∞
≤ L ∙ CO ∙ H ∙ pι∕n	(25)
Where the first step folloWs the PjM=1 φj Zj = ΦZ, the second step is an reorganization, the third step
folloWs the holders inequality, the last step uses the bound for kΦ-1φ(s, a)k1 in Definition A.7 and
kZjk2.
Combining Eq. (25) with Lemma C.1, we could upper bound %* (S) - VI(S)
H	1c
V*(s) - VI(S) ≤ E [X[(Ph - Ph)Vh+ι](sh,ah)∣sι = s] +--- ∙ H(H + 1)
π	h=1
__ _ 一 一	>——	1 — C ____ .
≤	H ∙ L ∙ C0 ∙ H ∙ √l∕n + -- ∙ H (H + 1)
=	L ∙ Co ∙ H2 ∙ p/n + --c ∙ H (H + 1)
≤	L ∙ C0 ∙ H2 ∙ √l∕n + (1 - c)H2
≤	2c0lh 2√ι∕n
≤
where the first step follows from Lemma C.1, the second step follows the upper bound of [(Ph -
Ph)Vh+1](S, a) in Eq. 25, the third step is an reorganization, the forth step follows from H ≥ 1
so that H2 ≥ H, the fifth step follows from 1 - C = COLyI/n, the sixth step follows from
n = O(C2 ∙ e-2L2H4ι).
□
C.4 Running Time Analysis
Lemma C.3. The running time of pre-computing Λ-1 takes
O(Md2 +dω)
Proof. It takes O(Md2 ) to sum up every φ(Sj , aj )φ(Sj , aj )> . It takes O(d) constant to multiply
the sum results by n. Computing the inverse matrix of Λ takes O(dω). Combining the complexity
together, we obtain the pre-computing complexity O(Md + dω).	□
Lemma C.4. The running time of updating value takes
O(H ∙ (d2 + Md + Mn + SdAP))
Further more,
If initialize the LSH data-structure using Theorem A.14, ρ = 1 -
34
Under review as a conference paper at ICLR 2022
Algorithm 2 LSVI Bradtke & Barto (1996)
1:	procedure LSVI(S, A, N ∈ N, H ∈ N)	. S and A are in Definition A.2
2:	/*Collect Samples*/
3:	for h ∈ [H] do
4:	Dh — 0
5: 6: 7:	for j = 1,…，M do	. For each element in the span set defined in Definition A.8 for l = 1,…,n do	. Play n times Query (Sj , aj ) at step h, observe the next state S0jl .
8:	. Sj , aj defined in Definition A.8
9:	Dh -Dh ∪{(sj, aj, Sjl)}	. |Dh| = Mn
10:	end for
11:	end for
12:	end for
13:	/*Precompute A matrix*/	. This step takes O(M d2 + dω)
14:	A - n PjM=1 φ(Sj, aj)φ(Sj, aj)>	. A ∈ Rd×d
15:	Compute A-1
16:	/*Update value function*/	. This step takes O(H(d2 + Md + Mn + SAd))
17:	for h = H, . . . , 1 do
18:	Wh — AT P(s,a,sl0)∈Dh (Ks, a) (rh(s, a) + Vbh+ι(sl0))
19:	for all S ∈ Score do
20:	Vh(S) - maxa∈Acore hWbh, φ(S, a)i
21:	end for
22:	end for
23:	/*Construct policy*/	. This step takes O(HSAd)
24:	policy πb - 0
25:	for h = 1, . . . , H do
26:	πbh(S) - arg maxa∈Acore hWbh, φ(S, a)i for all S ∈ S
27:	end for
28:	return πb
29:	end procedure
•	Ifinitialize the LSH data-Structure using TheoremA.15, P = 1 一 1 C2L2ι∕n.
Proof. We can rewrite wbh as follows:
Wh = AT	X	Φ(s,a) "(s,a) + Vbh+ι(Sι0))
(s,a ,sι0)∈Dh
M	1n
=ATnE φ(sj ,aj )(rh(sj ,aj) + n£Vbh+1(s0jl ))
j=1	n l=1
where the second step follows the definition of Dh .
For each of the H step,
•	It takes O(SdAρ) to compute Vh(s0jl) for each state sj ∈ Score. If we initialize the
LSH data-strUctUre using Theorem A.14, We determine P = 1 一 4CoLy/TPn using
Lemma B.9. If we initialize the LSH data-structure using Theorem A.15, we determine
ρ = 1 一 8C0L2ι∕n using Lemma B.10.
n
•	It takes O(Mn) to compute rh(sj, aj) + ( El=I Vh+ι(sjι) for the total n number of Sjl
observed by (sj, aj ).
•	It takes O(M d) to sum up the M dimensional vector φ(sj , aj )(rh(sj, aj) +
n Pn=ι -+1(Sjl)).
35
Under review as a conference paper at ICLR 2022
•	It takes O(d2) to multiply Λ with the sum of vectors.
•	All other operations take O(d).
Combining the complexity together and multiply by H steps, We finish the proof.	□
Lemma C.5. The running time of constructing policy takes
O(HSdA)
Proof. For each step, it takes O(SdA) to find the optimal action. Thus, it takes O(HSdA) for
inference.	□
C.5 Comparison
In this section, We shoW the comparison betWeen our Sublinear LSVI With LSVI Bradtke & Barto
(1996).
We start With presenting the LSVI algorithm in Algorithm 2.
Next, We shoW the comparison results in Table 3.
Algorithm	Preprocess	#Value Iteration	Regret
Ours	O(SdA1+ρ1)	O(HSdAPI)	O(C0LH 2Pl∕n)
Ours	O(SdA1+o(1))	O(HSdAρ)	O(COLH 2Pι∕n)
LSVI	0	—	O(HSdA)	O(COLH 2p∕n)
Table 3: Comparison betWeen Our Sublinear LSVI With LSVI. Let S and A denote the cardinality
of Score and Acore. Let d denote the dimension of φ(s, a). Let H be the number of steps played
in each episode. Let n denote the quantity of times played for each pair of core state-action. Let
L denote the constant in Definition A.8. Let ι = log(H d/p) and p is the failure probability. Let
Pi = 1 - 4CoLy∕Tpnj be the parameter of data structures in Theorem A.14 and ρ2 = 1 - 8 C2 L2 i/n
be the parameter of data structure Theorem A.15. This table is a detailed version of corresponding
part of Table 1.
36
Under review as a conference paper at ICLR 2022
D	Sublinear Least-Squares Value Iteration with UCB
This section extend the Sublinear LSVI with UCB exploration.
•	In Section D.1, we present the Sublinear LSVI-UCB algorithm.
•	In Section D.2, we define several simplified notations for the convenience of proof.
•	In Section D.3, we provide the upper bound of weight estimated by Sublinear LSVI-UCB.
•	In Section D.4, we introduce a modified version of net argument for Sublinear LSVI-UCB.
•	In Section D.5, we upper bound the fluctuation on the value function when performing
Sublinear LSVI-UCB Algorithm.
•	In Section D.6, we provide the upper bound on the difference between the estimated Q
function and the actual Q function.
•	In Section D.7, we given the upper bound on the difference between the estimated Q func-
tion and the actual Q function at the first step using induction.
•	In Section D.8, we introduce the recursion formula for the regret analysis.
•	In Section D.9, we formally provide the regret analysis of LSVI-UCB.
•	In Section D.10, we analyze the runtime Sublinear LSVI-UCB by calculating the time
complexity for each block.
•	In Section D.11, we compare Sublinear LSVI-UCB with LSVI-UCB Jin et al. (2020) in
terms of regret and value iteration complexity.
In the following sections we show how to tackle the problem and provide our Sublinear LSVI-UCB.
Moreover, we provide the regret analysis of our Sublinear LSVI-UCB.
D.1 Algorithm
In LSVI-UCB Jin et al. (2020) with large action space, the runtime in each value iteration step is
dominated by by computing the estimated value function as below:
τ	kτ	τ
Vh(sh+1) = max min{hw⅛ ,φ(sh+1 ,a)i + β ∙ kφ(sh+1,a)kΛ-i ,H}	(26)
a∈A	h
where whk is computed by solving the least-squares problem and φ(sτh+1, a) is the embedding for a
pair of state-action. The complexity for Eq. (26) is O(d2A)
The key challenge of Sublinear LSVI-UCB here is that Eq. (2) cannot be formulated as a Max-IP
problem.
To handle this, we demonstrate how to develop Sublinear LSVI-UCB algorithm. We start with
bounding the Q function in Jin et al. (2020) as
Lemma D.1. We show that
min{kφ(sτh+1, a)kβ2Λh-1+whk(wkh)> , H} ≤ Qh(sτh+1, a) ≤ min{kφ(sτh+1, a)k2β 2 Λh-1 +2wkh (whk)> , H}.
Proof. We start with rewriting Qh(sτh+1, a),
Qh(Sh+1,a = min{w>φ(sh+ι ,a) + β ∙ kφ(sh+1,a)kΛ-1 ,H}.
Next, we show that
w>φ(Sh+1, a) + β ∙ kφ(sh+ι,a)kΛ-i ≤ q2(w>φ(sh+ι,a))2 + 2β2 ∙ kφ(sh+ι,a)kΛ-ι
hh
= kφ(Sτh+1, a)k2β2Λh-1+2whk(whk)>
37
Under review as a conference paper at ICLR 2022
where the first step follows from Cauchy-Schwartz inequality, the second step is an reorganization.
Next, we show that
w>φ(sh+ι,a) + β ∙ kφ(sh+ι,a)kΛ-1 ≥ ∖/(w>φ(sh+ι,a))2 + β2 ∙ kφ(sh+ι,a)kΛ-ι
hh
= kφ(sτh+1, a)kβ 2 Λh-1 +whk (whk)>
where the first step follows from the fact that both wh>φ(sτh+1, a) and kφ(sτh+1, a)kΛ-1 are non-
negative, the second step is an reorganization.
Finally, consider the propriety of min function, we finish the proof of the lemma.
□
Algorithm 3 Modified LSVI-UCB
1	: for k = 1, . . . , K do
2	:	Initialize the state to s1k.
3	:	for h = H, . . . , 1 do
4	:	/*ComPUte Λh-1*/	. This steP takes O(Kd2 + dω)
5	λh J P：=1 φ(Sh, ah)φ(sh, ah)> + λ ∙ Id.
6	:	ComPUte Λh-1
7	:	/* ValUe Iteration*/	. This takes O(AKd2 )
8	Wk — λ-1 Pk=I φ(sh, ah) ∙ (rh(sh, ah) + Vh+ι(sh+ι))
9	for τ = 1,…，k 一 1 do
10	:	for a ∈ A do
11	:	Qh(sτh+1, a) J min{∣φ(sτh+1, a)∣2β2Λh-1+2wkhwhk> , H}.
12	:	end for
13	:	Vh(sτh) J maxa∈AQh(sτh,a)
14	:	aτh J arg maxa∈A Qh(s, a)	. aτh is the maximUm valUe action taken at state sτh.
15	:	end for
16	:	end for
17	:	/* ConstrUct Policy*/
18	:	for h = 1, . . . , H do
19	:	Given state skh, take action akh, and observe skh+1.
20	:	end for
21	: end for
Next, we present a modified version of LSVI-UCB in Algorithm 3. The major difference between
our modified version of LSVI-UCB and Jin et al. (2020) lies in in Line 11 of Algorithm 3. Here
We choose Qh(sh+ι, a) - min{kΦ(sh+1,a)k2β2Λ-1+2wk(wk)>,H}，which is the UPPerboUndof
min{w>φ(sh+ι,a) + β ∙ ∣∣φ(sh+ι, a)∣∣AT,H} according toLemmaD.1.
Based on Algorithm 3, we ProPose oUr SUblinear LSVI-UCB in Algorithm 4, which redUce the valUe
iteration comPlexity to sUblinear in actions. Note that to let ρ strict less than 1, we set c2 ∈ [0.5, 0.8]
and τ2 ∈ [0.5, 0.8]) following Lemma B.9.
D.2 Notations for Proof of Convergence
Next, we start the regret analysis of oUr SUblinear LSVI-UCB. We first define a series of notations.
At ePisode k, we first estimate the weight whk and matrix Λkh . Next, we Use them to estimate Q
fUnction Qkh. Then, Using oUr LSH data strUctUres, we obtain the valUe fUnction Vhk (s) following
line 13 of Algorithm 1. We also obtain the corresPonding action associated with the valUe fUnction
and form the Polity πk following Line 14 of Algorithm 1. We also simPlify φ(skh, akh) as φkh.
38
Under review as a conference paper at ICLR 2022
Algorithm 4 Sublinear LSVI-UCB
1:	data structure MATRIXLSH	. Theorem B.6
2:	INIT(S ⊂ Rd,n ∈ N, d ∈ N, c ∈ (0.72, 0.9), τ ∈ (0.72, 0.9))
3:	. |S| = n, c, τ is the approximate Max-MatNorm parameter and d is the dimension of data
4:	QUERY(x ∈ Rd)
5:	end data structure
6:
7:	procedure SUBLINEARLSVI-UCB(S, A, N ∈ N, H ∈ N, cMatLSH ∈ (0.72, 0.9), τMatLSH ∈
(0.72, 0.9))
8:	/*Preprocess φ(s, a) and build a LSH data structure*/	. This step takes
O(S ∙ (A1+p + d2A))
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
for s ∈ S do
Φs4-{φ(s, a) | ∀a ∈ A}
static MATRIXLSH MATLSHs
MATLSHs.INIT(Φs, A, d, cMatLSH, τMatLSH)
end for
for k = 1, . . . , K do
Initialize state to s1k .
for h = H, . . . , 1 do
/*Compute Λh-1*/	. This step takes O(Kd2 + dω)
λ% J Pk=1 φ(sh, ah)φ(sh, ah )> + λ ∙ Id.
Compute Λh-1
/* Value Iteration*/	. This takes O(Kd2Aρ)
wk — λ-1 Pk-I φ(sh, ah) Yrh(Sh, ah) + Vbh+ι(sh+ι))
for T =1,…，k 一 1 do
aτh J MATLSHs.QUERY(2β2Λh-1 + 2whkwhk>)
Vh(Sh) J min{kφ(Sh+1, ah)k2β2Λh-1+2whkwhk> , H}
end for
end for
/* Construct Policy*/
for step h = 1, . . . , H do
Take action akh at Skh, and observe Skh+1.
end for
end for
end procedure
D.3 Upper B ound on Weights in Sublinear LSVI-UCB
In this section, we show how to bound the weights whk in Algorithm 4 using Lemma D.2. The weight
we would like to bound is different from Jin et al. (2020). But the bound inequalities is very standard
and similar to the proof in Jin et al. (2020).
Lemma D.2. The weight whk in Algorithm 4 at episode k ∈ [K] and step h ∈ [H] satisfies:
kwkk2 ≤ 2HPdk∕λ.
Proof. If we perform v>whk where v ∈ Rd could be any vector in Rd, we could bound |v>whk| as
k-1
|v>whk| = v>(Λkh)-1Xφτh r(Sτh, aτh) + Vbh+1(Sτh+1)
τ =1
k-1
≤ v>(Λkh)-1 Xφτh r(Sτh, aτh) +ma∈aAxQh+1(Sτh+1,a)
τ =1
k-1
≤ 2H ∙∣v> (AIk)T X φh∣
τ=1
39
Under review as a conference paper at ICLR 2022
k-1
=2H ∙ X∣v>(Λh)-1φh∣
τ=1
≤ 2H ∙ ((X v>(Λh)-1v) ∙ (X(Φh)>(Λh)Tφh))1/2
τ=1	τ=1
≤ 2HIIvIl2Pdk∕λ,
where the first step follows from the definition of whk in Algorithm 4, the second step follows from
the definition of Vh+1 in Algorithm 4, the third step follows from Definition A.2 that r(s, a) +
Vh+1 (s) ≤ 2H for all s ∈ S and a ∈ A, the forth step is a reorganization, the fifth step follows
CaUchy-SchWarz inequality, the last step follows from Lemma A.20.
Next, we rewrite Iwhk I2 = maxv:kvk2=1 |v>whk |, in this way,
kwh ι∣2 = max 1 ιv>wkk | ≤ 2H√dk∕λ
v:kvk2=1
where the last step follows from ∣v>wh | ≤ 2H√dk∕λ.
□
D.4 Our Net Argument
We present our net argument to support the proof in the this section. We start with defining the
covering number of euclidean ball.
Lemma D.3. Let B denote a Euclidean ball in Rd. B has radius greater than 0. For any > 0, we
upper bound the -covering number of B by (1 + 2R∕)d.
This is a standard statement. We reder readers to Vershynin (2010) for more details.
Next, we upper bound the covering number of a function V(s) = min Iφ(s, a)Iβ2Λ-1+ww> , H .
The V we would like to bound is different from Jin et al. (2020). But the net argument is very
standard and similar to proof in Jin et al. (2020).
Lemma D.4 (Our Net Argument). Let Λ ∈ Rd×d denote a invertible matrix whose minimum eigen-
value is greater than a constant λ. Let w denote a vector such that IwI2 ≤ L. Let β ∈ [0, B]. Let
max(s,a)∈S×A Iφ(s, a)I2 ≤ 1. Let V denote a famility of functions such that V : S → R for any
V ∈ V Let N denote the -covering number of V. The -covering number is defined on distance
dist(V, V 0) = maxs∈S |V (s) - V 0(s)|. If for any V ∈ V, we have the form
V(s) =min Iφ(s, a)Iβ2Λ-1+ww> , Ho
(27)
Then we have
logNe ≤ dlog(1 + 4L∕e) + d2 log(1 + 8d1∕2B2∕(λe2)).
Proof. For given two arbitrary functions V1 , V2 ∈ V, we have
dist(V1,V2) ≤ sup Iφ(s,a)Iβ12Λ1-1w1w1> - Iφ(s,a)Iβ22Λ2-1+w2w2>
s,a
≤
Φ,SUP≤1 (kφkβ2A-1+wιw>
- IφIβ22Λ2-1+w2w2>
≤ sup
φ"∣φk2≤1
√∣φ>(β2 λ-1 + wlw> 一 β2Λ-1 — w2w2)φ∣
≤ Φ,SUP≤1 ((w1 — wG>φ)+φ 湍 p≤ι GλZT-I^
40
Under review as a conference paper at ICLR 2022
=kw1 - w2k + J||e2A-1 - e2A-1k2
≤ kw1 - w2k + qke2A-1 - e2A-1kF,	(28)
where the first step follows the definition of V1 and V2 in Eq. (27), the second step follows from
the fact that kφ(s, a)k2 ≤ 1 in Definition A.2, the third step step follows from the fact that for any
x,y ≥ 0, We have |√x — √y∣ ≤，|x - y|, the forth step follows from √x + y ≤ √x + √y for any
x, y ≥ 0, the fifth step follows from the fact that the Frobenius norm of matrix is greater than the `2
norm.
Next, we denote Cw as the (/2)-cover of a ball {w ∈ Rd | kwk2 ≤ L}. Using Lemma D.3, we
show that it can be upper bound as: |Cw | ≤ (1 + 4L/)d.
Similarly, we denote Cλ as the (e2∕4) -cover of a ball {β2Λ-1 ∈ Rd×d | kβ2Λ-1kF ≤ d1∕2B2λT}.
Here we define the ball in k ∙ ∣∣f. Using Lemma D.3, we show that it can be upper bound as:
∣Cλ∣ ≤ (1 + 8d1∕2B2∕(λe2))d2.
Using, Eq. (28), we know that given any V1 ∈ V, we could find a V2 ∈ V with form V2 (s) =
min kφ(s, a)kβ2Λ-1+w2w>, H where w2 ∈ Cw and β22Λ2-1 ∈ CΛ, such that dist(V1, V2) ≤ e.
Therefore, Ne ≤ |Cw | ∙ |Ca|. Using this inequality, we have
log N ≤ log |CA| + log |Cw|
≤ dlog(1 + 4L∕e) + d2 log(1 + 8d1∕2B2∕(λe2)).
Thus, we conclude the proof.	□
D.5 Upper B ound on Fluctuations
We present a concentration lemma so that the fluctuations in LSVI-UCB is upper bounded in this
section. The analysis is very standard and similar to proof in Jin et al. (2020). However, we improve
the proof of Jin et al. (2020) with more detailed constant dependence.
Lemma D.5. Let Ce > 1 denote a fixed ConStant Let β = Ce ∙ dH√l. Let ι = log(2dT∕p). We
show that for any probability p ∈ [0, 1] that is fixed, if we have an ξ event satisfying that for all
k ∈ [K] andh ∈ [H]:
k-1	____________
U X φh(Vk+ι(sh+ι) - [phV∕k+ι](sh, ah)) ∣[Ak)-i ≤ 30 ∙ dHJι + log(5Ce),
Then, we have
Pr[ξ] ≥ 1 - p∕2.
Proof. We show that any fixed e > 0, we have
k-1	2
UXΦh(Cι(sh+ι) - [PhVk+ι](sh,ah))UMk一
τ=1	(Λh)
2	8H √dk∖	2	8d1∕2β2	8k2e2
≤ 4H2 f d log(1 + k∕λ) + d log M +-√=- + + d2 log M +——e2λ ) +log(2∕p)j +———
≤ 4H2(dlog(1 + k) + dlog(1 + 8,k3∕d) + d2 log(1 + 8C2d0.5K2ι) + log(2∕p)) + 8d2H2
≤ 30 ∙ d2H2 log(10CedT∕p)
=30 ∙ d2H2(∣ + log(5Ce)),	(29)
where the first step follows from combining Lemmas A.21 and D.4,the second step follows from
λ = 1, e = dH∕K, and β = Ce ∙ dH√ι, the third step follows from Ce ≥ 1 and ι = log(2dT∕p),
the last step follows from ι = log(2dT ∕p).
Thus, we complete the proof.	□
41
Under review as a conference paper at ICLR 2022
D.6 Upper B ound of Difference of Q Function
In this section, we bound like to bound the difference between the Q function Qkh (see Section A.1)
selected by Algorithm 4 and the value function Qπh (see Definition A.4) of any policy π. We bound
the their difference by bounding hφ(s, a), whki - Qhπ(s, a). The analysis is very standard and similar
to proof in Jin et al. (2020). However, we improve the proof of Jin et al. (2020) with more detailed
constant dependence.
Lemma D.6. Let λ = 1 in Algorithm 4. Let ι = log(2dT /p). We show that for any policy π that is
fixed, for all s ∈ S, a ∈ A, h ∈ [H] and k ∈ [K], on the event ξ defined in Lemma D.5, we show
that exists an absolute constant Cβ ≥ 100 such that
hΦ(s, a), Wki- Qh(s, a) - [Ph(Vk+ι - j](s, a) ≤ CedH√l ∙∣∣φ(s, a)k(Ah)-i
Proof. We start with rewriting Qhπ(s, a) as
Qhπ(s, a) := hφ(s, a), whπ i = rh(s, a) + [PhVhπ+1](s,a).
where the first step follows from Proposition A.9, and the second step follows from Eq. (5).
Next, we show that
k-1
whk - whπ = (Λkh)-1 X φτh(rhτ + Vhk+1(sτh+1)) - whπ
τ=1
k-1
=(Λh)-1 ( - λw∏ + X φh(Vk+1(sh+1) - [PhVh+1](sh, ah)))
τ =1
= p1 + p2 + p3 .
where the first step follows from the definition of whk , the second step follows from the definition of
whπ . the last step follows from
p1 := - λ(Λkh)-1whπ
k-1
P2 ：= (Λh)-1 XΦh(Vk+1(sh+1) - [PhVk+ι](sh,ah))
τ=1
k-1
P3 =(Λh)-1 XΦh[Ph(Vk+ι- Vh+ι)](sh,ah)
τ=1
Next, we upper bound p1 , p2 and p3 separately.
We upper bound p1 as,
KφGa),qiil = λ ∙ Kφ(S,a), (Ah)TwniI
≤ λ ∙ kwπ l∣2 ∙ kφ(s,a)k(Λh)-ι
≤ 2H√dλ ∙ kΦ(s, a)k(AQτ
≤ 2H√d ∙kΦ(s,a)k(Λh)-ι,	(30)
where the second step follows from |〈a,b)| ≤ k a k 2 'k b k 2, and the third SteP follows from k w∏ k 2 ≤
2H,d∕λ (see Lemma D.2), and the last step follows from λ = 1.
We upper bound p2 as,
lhφ(s,a),q2il ≤ 30 ∙ dH q + log(5Cβ) kφ(s, a)k(Λh)-ι	(31)
where the first step follows from Lemma D.5 on the event ξ.
42
Under review as a conference paper at ICLR 2022
We upper bound q3 as,
hφ(S, a), p3i = φ(S, a), (Λkh)-1kX-1φτh[Ph(Vhk+1-Vhπ+1)](Sτh, aτh)
= φ(S, a), (Ah)-1 X φh(φh)> /(Vhk+ι — Vf∏+ι)(S0)dμh(S0)
= q1 + q2
where the first step is a reorganization, the second step decomposes the right hand side as:
qι := (φ(S, a), J(Vk+ι - Vh+I)(SO)dμh(SO))
q2 := - λ(φ(S, a), (Ah)T Z(Vh+ι - Vh+I)(SO)dμh(SO))
Then, we rewrite q1 = Ph(Vhk+1 - Vhπ+1)(S, a) following Definition A.2.
Next, we upper bound q2 as
∣q21 ≤ 2H√dkΦ(S,a)k(Λh)-ι	(32)
where the first step follows from Lemma D.2.
Finally, because hφ(S,	a),	whki	-	Qπh(S,	a)	= hφ(S,	a),	p1 + p2	+ p3i, we have
lhΦ(S,a), Whi- Qn(S,a) - Ph(Vh+1 - Vh+ι)(S, a)l
= hφ(S, a), p1 + p2 + q2 i
≤ (2H√d + 30 ∙ dH/ι + log(5Cβ) + 2H√d) ∙ ||0(5,叫|(纯)-1
≤ dH(30,∣ + log(5Cβ) +4) ∙kΦ(S,a)k(Λh)-ι,
where the second step follows from combining Eq. (30), Eq. (31) and Eq. (32), the third step follows
from d ≥ 1, H ≥ 1.
Finally, we choose an absolute constant Cβ that satisfies:
30('ι + log(5Cβ) +4) ≤ Ce√l,	(33)
Note that ι = log(2dT /p) ≥ 4, as long as Cβ ≥ 100 the above inequality holds
Finally, with this choice of Ce, we finish the proof.	□
D.7 Q Function Difference by Induction
In this section, We build a connection between Qk (s, a) selected by Algorithm 4 and Q； (s, a). We
show in Lemma D.7 that Q；(s, a) is upper bounded by Qk (s, a) plus an error term related to the
parameter c for approximate Max-MatNorm in Algorithm 4.
Lemma D.7. Let Q1k(S, a) denote the estimated Q function for state S when taking action a at the
first step. Let Q；1(S, a) denote the optimal Q function for state S when taking action a at the first
step. Let H denote the total steps. Let c is the parameter for approximate Max-MatNorm. We show
that using Sublinear LSVI-UCB (see Algorithm 4), we have
1	cH
QI(S, a) ― QI (S, a) ≤ H ― c—
1-c
Proof. We start with bounding on the relationship between Qkh(S, a) and Q；h(S, a).
hφ(S,	a),	whki+βkφ(S,	a)k(Λkh)-1	≥	Q；h(S,	a)+[Ph(Vhk+1-Vh；+1)](S,	a)	(34)
43
Under review as a conference paper at ICLR 2022
where the first step follows Lemma D.5.
Next, when h = H, as the value functions are all zero in H + 1 step, we have
QkH (s, a) ≥ hφ(s, a), wHk i + βkφ(s,a)k(ΛkH)-1
≥ QH(s,a)	(35)
where the first step follows from Lemma D.1, the second step follows from Lemma D.6.
Next, we have
max QH(s,a) ≥ max QH(s,a)
a∈A	a∈A
≥ VH(S)	(36)
where the first step follows from Eq. (35), the second step follows from the definition of VH(s) in
Definition A.4.
Next, when h = H - 1, we bound [Ph(VH - VH)](s, a) as
[Ph(VH - VH)](s, a) ≥ [Ph(cmaχQH(s, a) — VH)](s, a)
a∈A
≥ c[Ph(maχ QH(S,a) — VH)](s, a) -(I - C)[PhVH](s, a)
a∈A
≥ c[Ph(maχ QH(S, a)- VH)](S, a) - (I - C) ∙1
a∈A
≥ - (1 - c) ∙ 1	(37)
where the first step comes from the property of data structure MatrixLS H in Algorithm 4, the
second step is an reorganization, the third step follows the definition of VH (s) in Definition A.4, the
last step follows the Eq. (36).
Next, we have
QkH-1(S,a) ≥ hφ(S, a), wHk -1i +βkφ(S,a)k(ΛkH-1)-1
≥ QH-I(S,a) + [Ph(VH - VH)](s,a)
≥ QH-I(S,a)-(1-c) ∙ 1	(38)
where the first step follows from the Lemma D.1, the second step follows from Eq. (34) ,and the
third step follows Eq. (37).
Next, we have
maxQH-i(s, a) ≥ maxQH-i(s, a) — (1 — C) ∙ 1
a∈A H-1	a∈A H-1
≥ VH-i(s) - (1 - c) ∙ 1	(39)
where the first step follows from Eq. (38), and the second step follows the definition of QH_1 (s, a)
in section A.1.
b
Next, when h = H - 2, we lower bound [Ph(VH-ι - VH-I)](s, a) as
[Ph(VH-I - VH-I)](s, a) ≥ [Ph(Cmax QH-I(S, a) - VH-1)](S, a)
a∈A
≥ c[Ph(max QH-I(S, a) - VH-1)](S, a) - (I-C) ∙ [PhVH-1)](S, a)
a∈A
≥ C[Ph(max QH-I(S, a) - VH-I)](s, a) - (I - C) ∙ 2
a∈A
≥ - c(1 - c) ∙ 1 - (1 - c) ∙ 2	(40)
where the first step comes from the MatrixLSH in Algoritm 4, the second step is an reorganization,
the third step follows the definition of VH(s) in section A.1, the last step follows the Eq. (39).
44
Under review as a conference paper at ICLR 2022
Next, we have
QkH-2(s,a) ≥ hφ(s, a), wHk -2i + βkφ(s, a)k(ΛkH-2)-1
≥ QH-2(s,a) + [Ph(VH-i - VH-I)](s,a)
≥ QH-2(s, a) - C(I - C) ∙ 1 -(I - C) ∙ 2	(41)
where the first step follows from the Lemma D.1, the second step follows from Eq. (34) ,and the
third step follows Eq. (40).
using induction from H to 1, we have
H
QI(S,a) ≥ Q；(S,a)- (I - C)〉：Ch 1 (H + 1- h)
h=1
H - CH - C + CH+1
=Ql(s,a) - (1 - C) ——∩ɪ——
1	(1 - C)2
=Ql(s, a) -
=Qι(s, a) -
H - CH - c + ch+1
1 — c
H-CH	-C + CH+1
1-
=Ql(s, a) -(H -
+
C
C-C
1-C
H+1
=Qι(s, a) - (H -
1-C
1 - CH
Cn---)
1-C
(42)
)
where the first step follows the induction rule, the remain steps are reorganizations.
□
We notice from Lemma D.7 that there exists a term H - CI-CH. Here We use Fact D.8to bound this
term.
Fact D.8. Let H ∈ N. Let C = 1 - γ, for any γ ∈ (0, 1/(10H)), then we have
1	CH
H - c------ ≤ 2γH2.
1-C
Proof. First, by definition γ = 1 - C ∈ (0, 1), then We can reWrite LHS as
1 CH
H - c∏— = H - (1 - Y)(1 - (1 - Y)H)/Y
1-C
≤ H - (1 - Y)(1-e-HY)/Y
≤H-(1-γ)(H-0.5(H2γ))
= H(1 - (1 - γ)(1 - 0.5(H γ)))
≤ H ∙ (2Hγ) = 2γH2
where the second step follows from (1 - Y)1/Y ≤ e-1, the third step follows from 1 - e-x ≥
x - 0.5x2, ∀x ∈ [0, 1/10].
□
D.8 Recursive Formula
In this section, we bound the difference between Qkh(Skh, a) and Qhπk (Skh, a) in a recursive formula.
Lemma D.9 (Recursion).	Let	δhk	denote the difference	Qkh(Skh,	a)	-	Qhπk (Skh, a).	Let	ζhk+1	=
E[δk+ι∣sh, a] — δk+ι denote the error between expectation and observed difference. Let β =
45
Under review as a conference paper at ICLR 2022
CβdH√ι. Given the event ξ defined in Lemma D.5, we bound δk — δkk+ι for any k ∈ [K] and
h ∈ [H] as
δhk — δhk+1 ≤ ζhk+1 + 2βkφ(skh, a)k(Λkh)-1 .
Proof. We bound the δhk as
δh = Qh(Ja)- Qnk (s,a)
≤ [Ph(Vhh+ι — V∏+ι)](s, a) + 2CβdH√l∣∣φ(s, a)k(Λh)-ι.
= ζhk+1 + δhk+1 + 2βkφ(s, a)k(Λkh)-1
where the second step follows from Lemma D.6, the third step follows from [Ph(Vhk+1 —
Vhπ+k1)](s, a) = ζhk+1 + δhk+1.
Thus, we finish the proof.
□
As our algorithm have the same upper bound on recursion with Jin et al. (2020), the upper bound on
ζhk+1 in Jin et al. (2020) could also be used in our analysis. We state the bound as
Lemma D.10 (Jin et al. (2020)). Let ζhk+1 = E[δhk+1 |skh, a] — δhk+1. With probability at least 1 — p/2,
we show that
K H
XXZh ≤ 2H√τι,
k=1 h=1
We could also upper bound PK=I PH=IIlφ(sk,a『)∣∣(λQt following Jin et al.(2020).
Lemma D.11 (Jin et al. (2020)). Let αh ∈ A denote the optimal action at state sh ∈ S. Given, Ah
estimated in each step, we have
K H
XX kφ(sh ,αh*)k(Λh)-ι ≤ H ∙ √2dKι
=1 h=1
D.9 Regret Analysis
In this section, we prove main theorem in Theorem D.12.
Theorem D.12 (Convergence Result of Sublinear Least-Squares Value Iteration with UCB (Sublin-
ear LSVI-UCB), a formal version of Theorem 4.3). In a linear MDP in Definition A.2, we set λ = 1.
Let Cβ ≥ 100 denote a fixed constant andι = log(2dT /p). Ifwe set approximate Max-MatNorm
parameter C = 1 — √K, then for any P ∈ (0,1) that is fixed, with probability 1 — P, Sublinear
LSVI-UCB (Algorithm 4) has the cumulative regret at most O(Cβ ∙ vd3H3Tι2).
Proof. We start with upper bounding the regret as:
K
Regret(K)= X (%*因)-V* (Sh))
k=1
K
=I maxQι(sh, a) — maxQnk(Sh, a)
a∈A	a∈A
h=1
K
≤ ∑ maχ Q1(sh ,ah*) - Qlk (sf,af*)
a∈A
h=1
46
Under review as a conference paper at ICLR 2022
K
≤ X(Qk(Sk, a1*) - Q∏k (Sk, ak*) + 2γH2)
k=1
K
= 2γKH2 + X δ1k
k=1
KH	KH
≤ 2γKH2 + XX Zh +2βXX kΦ(sk, ak*)k(Λh)-ι	(43)
where the first step follows the definition of regret, the second steps follows from the defini-
tion of value function in Definition A.4, the third step follows from that maxa∈A Q1πk (S1k, a) ≥
Qnk(sk,ak*), where ak* is the optimal action chosen at state Sk, the forth step follows from
Lemma D.7, the fifth step is a follows the definition of δhk and ζhk as in Lemma D.9, the sixth
step follows from Lemma D.9.
Next, with probability 1 - p, we show that
KH	KH
Regret(K) ≤ 2γKH2 + XXZh +2βXX kφ(sf,。口||勾『
k=1 h=1	k=1 h=1
K H
≤ 2γKH2 + 2H√TI + 2βXX kφ(sk,ak*)I(Ah)-I
k=1 h=1
≤ 2KγH2 + 2H√Tl + βH√2dKι
=2KγH2 + 2H√TI + Ce ∙ √2d3H4Kι2
≤ 2√H4Kι2 + 2√H3Kl + Ce ∙ √2d3H4Kι2
≤ 2Ce √d3H4 Kι2	(44)
where the second step follows from Lemma D.10, the third step follows from Lemma D.11, the forth
step from β = Ce ∙ dH√l, the fifth step follows from Y =春,the sixth step is a reorganizationm
the seventh step follows from Ce ≥ 100.
Thus, we finish our proof.
□
D.10 Running Time Analysis
We present the running time analysis of our Sublinear LSVI-UCB. We first introduce the running
time of each procedure of LSVI-UCB in Section D.10.1. Next, we introduce the running time of
Sublinear LSVI-UCB in Section D.10.2. Therefore, we could compare their efficiency in the next
section.
D.10.1 LSVI-UCB
First, we show the LSVI-UCB algorithm in Algorithm 5
Lemma D.13. The running time of pre-computing Λ-1 in Algorithm 5 takes time
O(Kd2 +dω)
where ω ≈ 2.373 is the exponent of matrix multiplication Williams (2012); Le Gall (2014).
Proof. It takes O(Kd2) to compute and sum up every φ(Sτh, aτh)φ(Sτh, aτh)>. Computing the inverse
matrix of Λ takes O(dω). All other operations take O(d). Combining the complexity together, we
obtain the pre-computing complexity O(Kd2 + dω).	□
Lemma D.14. The running time of value iteration in Algorithm 5 takes
O(HKd2A)
47
Under review as a conference paper at ICLR 2022
Algorithm 5 LSVI-UCB Jin et al. (2020)
1	: for k = 1, . . . , K do
2	:	Initialize the state s1k .
3	:	for h = H, . . . , 1 do
4	:	/*Compute Λh-1*/	. This step takes O(Kd2 + dω)
5	λ% J PT=1 φ(Sh, ah)φ(sh, ah)> + λ ∙ Id.
6	:	Compute Λh-1
7	:	/* Value Iteration*/	. This step takes O(Kd2A)
8	wk — λ- Pk=I φ(sh, αh) ∙ (rh(sh, ah) + Vh+1(sh+ι))
9	for τ = 1,…，k - 1 do
10	:	for a ∈ A do
11	Qh(Sh+ι,a) - min{hwk ,φ(sh+ι,a)i + β ∙ kφ(sh+1 ,a)kΛk-ι ,H}.
12	:	end for
13	:	Vh(Sτh) J maxa Qh(Sτh, a)
14	:	aτh J arg maxa Qh(S, a)	. aτh is the maximum value action taken at state Sτh.
15	:	end for
16	:	end for
17	:	/* Construct Policy*/
18	:	for h = 1, . . . , H do
19	:	Take action akh, and observe Skh+1.
20	:	end for
21	: end for
Proof. For each of the H step,
•	It takes O(Kd2A) to compute Vbh+1(sτh+1) for each state sτh+1.
•	It takes O(Kd) to sum up Φ(sh,ah) ∙ (r%(sh,ah)+ Vh+1(sh+1)).
•	It takes O(d2) to multiply Λ with the sum of vectors.
•	All other operations take O(d).
Combining them together, we have O(HKd2A).
□
D.10.2 Sublinear LSVI-UCB
In this section, we show the runtime analysis of our Sublinear LSVI-UCB in Algorithm 4.
Lemma D.15. The running time of pre-computing Λ-1 in Algorithm 4 takes
O(Kd2 +dω)
where ω ≈ 2.373 is the exponent of matrix multiplication Williams (2012); Le Gall (2014).
Proof. It takes O(Kd2) to compute and sum up every φ(sτh, aτh)φ(sτh, aτh)>. Computing the inverse
matrix of Λ takes O(dω). All other operations take O(d). Combining the complexity together, we
obtain the pre-computing complexity O(Kd2 + dω).	□
Lemma D.16. The running time of value iteration in Algorithm 4 takes
O(HKd2Aρ)
Further more,
If initialize the LSH data-structure using Theorem A.14, ρ
1---1=
4√K *
•	Ifinitialize the LSH data-Structure using Theorem A.15, P = 1 一 康.
48
Under review as a conference paper at ICLR 2022
Proof. For each of the H step,
•	It takes O(Kd2Aρ) to compute Vh+1(sτh+1) for each state sτh+1. If we initialize the LSH
data-strUcture using Theorem A.14, We determine P = 1 - 4√1κ using Lemma B.9. If We
initialize the LSH data-structure using Theorem A.15, we determine P = 1 - 8k using
Lemma B.10.
•	Ittakes O(Kd) to sum up φ(sh,ah) ∙ (rκ(SKah) + Vh+ι(sh+ι)).
•	It takes O(d2) to multiply Λ With the sum of vectors.
•	All other operations take O(d).
□
D.11 Comparison
In this section, We shoW the comparison betWeen our Sublinear LSVI-UCB With LSVI-UCB Jin
et al. (2020). We shoW the comparison results in Table 4.
Algorithm	Preprocess	#ValUe Iteration	Regret
Ours	O(Kd2A1+pι)	O(HKd2Aρι)~	O(Ce √d3H4 Kι2)
Ours	θ(κd2A1+o (I))	O(HKd2 Aρ)-	O(Ce √d3H4 Kι2)
LSVI	0	O(HKd2 A)	O(Ce √d3H4 Kι2)
Table 4: Comparison betWeen Our Sublinear LSVI-UCB With LSVI-UCB Jin et al. (2020). Let S
denote the quantity of available states and A denote the quantity of available actions. Let d denote
the dimension of φ(s, a). Let H denote the number of steps per episode. Let K denote the total
number of episodes. Let ∣ = log(2Hd∕p) and P is the failure probability. Let ρι = 1 - ^√1^ be
the parameter determined by data structure in Theorem A.14 and ρ2 = 1 - 8k be the parameter
determined by data structure Theorem A.15. Since K > S, We Write the preprocessing time as
O(Kd2A1+o(1)). This table is a detailed version of corresponding part of Table 1.
E Extension of Sublinear LSVI-UCB
This section extends the Sublinear LSVI-UCB With different settings.
•	In Section E.1, We introduce our Sublinear LSVI-UCB algorithm in the setting that the
policy sWitch is limited.
•	In Section E.2, We present the model-free version of Sublinear LSVI-UCB algorithm.
•	In Section E.3, We shoW that comparison of our algorithm With tWo LSVI-UCB extensions
in terms of regret and value iteration complexity.
E.1 LSVI-UCB Under Switch Limitation
In the limited sWitch setting, the number of modifications on the policy in reinforcment learning
should not exceed a certain threshold. Therefore, We are required to bound the number of sWitches
to achieve the optimal policy. Gao et al. (2021) proposes an approach to do it via LSVI-UCB. We
denote this variantion as LGSC. The only different betWeen the LGSC algorithm in Gao et al. (2021)
and the LSVI-UCB algorithm in Jin et al. (2020) is that is rejects the updated policy if the change Λkh
is beloW a threshold. Therefore, We could directly modify LGSC using the same Way in Algorithm 4
and propose Sublinear LGSC. Moreover, We obtain the statement as folloWs:
Corollary E.1 (Convergence result of Sublinear LSVI-UCB-LGSC, an formal version of Corol-
lary 4.4). Let MDP(S, A, H, P, r) denote a linear MDP. Given a fixed probability p ∈ (0, 1), if We
set LSVI-UCB parameter λ = 1, approximate MaX-IP parameter C = 1 ——X and ∣ = log(2dT∕p),
49
Under review as a conference paper at ICLR 2022
Sublinear LGSC cost has regret at most O(√d3H3Ti2) in total then with probability at least 1 - p.
Moreover, with O(KA1+o(1) +Kd2A) preprocessing time and space, the value iteration complexity
of Sublinear LGSC is O(HKd2Aρ), where ρ = 1 - 1/K. Moreover, the cost of global switching
is at most O(dH log K).
Proof. As the limitation on the policy switch does not affect the upper bound of regret, Sublinear
LGSC have the same upper bound of regret as Sublinear LSVI-UCB. We write the regret of LGSC
following Eq. (44) in O(Vd3H4Ki2). Meanwhile, the upper bound the cost of global switching
is independent of the LSH based Max-IP data structure. Therefore, Sublinear LGSC have the same
upper bound in the cost of global switching, which is O(dH log K). Moreover, as the value iteration
of Sublinear LGSC is indentical to Sublinear LSVI-UCB, the query time, preprocessing time and
space complexity could be determined.	□
E.2 Model-free LSVI-UCB
The major difference of model-free LSVI-UCB and model based LSVI-UCB is that the reward
function r remains to be estimated. We denote this method as MF. Therefore, MF in Wang
et al. (2020a) contains two procedures. In the first procedure, MF performs the similar algo-
rithm as Algorithm 5 except the reward function at each step of each episode is estimated by
min{kφ(sτh+1, a)k(λk)-1 , H}. Then, in the second procedure, the MF performs the same algorithm
as LSVI-UCB based on the estimated reward. Accordingly, we could also propose a Sublinear MF.
The Sublinear MF alternates the LSVI-UCB algorithm in the second procedure with the Sublinear
LSVI-UCB. Threfore, we have the following statement.
Corollary E.2 (Main result, convergence result of Model-free Sublinear LSVI-UCB (MF), an formal
version of Corollary 4.4). Let MDP(S, A, H, P, r) denote a linear MDP. Given a fixed probability
P ∈ (0,1), if We set LSVI-UCB parameter λ = 1, approximate MaX-IP parameter C = 1 - √K
and β = Θ(dH√ι) with ι = log(2dT∕p), then using O(KH2 log(√d-3H-4K)∕ι2) episodes for
exploration, MF has regret at most O(√d3H4Ki2) in total with probability at least 1 - p. Further
more, with O(KA1+o(1) + Kd2A) preprocessing time and space, the value iteration complexity of
MF is O(HKd2Aρ), where ρ = 1 - 1/K.
Proof. We start with several definitions. We denote r* : S×A→ R as the original reward function.
We denote r1 : S × A → R as the reward function estimated by the in the exploration phase of
MF. Let V1*(sι,r*) denote the optimal value function π using reward r*. Let %*(sι, r1) denote the
optimal value functionπ using reward r1 . From Wang et al. (2020a), we know that for any error
e > 0, with O(d3H6 log(dHpTe-1)∕e2) episodes in exploration, V*(sk, r*) — V*(sk,r1) ≤ e
for any episode k. Therefore if we pay O(KH2 log(√d-3H-4K)/i2) episodes, the would have
e ≤ Ce√d3H4ι2/√K, where Ce ≥ 100.
Next, we upper bound the regret as:
K
Regret(K) = £(埒因)-V∏k(Sk))
k=1
K
=X (V*(sk,r*) - Vι*(sk,r1) + V；⑻,r1) - Vfk(Sk))
k=1
KK
=X M(sk,r1) - Vιπk(sk)) + X (Vι*(sk,r*) - V*(sk,r1))
k=1	k=1
K
=2Ce√d3H4Ki2 + X (VI*(sk,r*) - V*(sk,r1))
k=1
=2Ce √d3H 4Ki2 + Ke
=3Ce √d3H 4Ki2
(45)
50
Under review as a conference paper at ICLR 2022
where the second and third step are reorganizations, the forth step follows from Eq. (44), the fifth
step follows from %*(Sk,r*) - %* (Sk,r1) ≤ e, the last step follows from e ≤ Ce√d3H412/√K.
Therefore, we show that Sublinear MF achieves the same regret as LSVI-UCB and MF. Moreover,
the preprocessing time, space and value iteration complexity ofMF is as same as LSVI-UCB.
E.3 Comparison
In this section, we show the comparison between our Sublinear LSVI-UCB with LGSC Gao et al.
(2021) and MF Wang et al. (2020a). We show the comparison results in Table 5.
Algorithm	Preprocess	#ValUe Iteration	Regret
Ours	O(Kd2A1+ρ1)	O(HKd2 Aρ)	O(Ce √d3H4 Kι2)
Ours	o(κd2Aι+o(ι)y~	O(HKd2 Aρ)	O(Ce √d3H4 Kι2)
LGSC	0	O(HKd2 A)	O(Ce √d3H4 Kι2)
OUrS		O(Kd2A1+ρι)	O(HKd2 Aρ)	O(Ce √d3H4 Kι2)
OUrS		θ(κd2A1+o(1)T	O(HKd2 Aρ2)	O(Ce √d3H4 Kι2)
MF	0	θ'(HKd2A)	O(Ce √d3H4 Kι2)
Table 5: Comparison between Our Sublinear LSVI-UCB with LGSC Gao et al. (2021) and MF Wang
et al. (2020a). Let S denote the quantity of available states and A denote the quantity of available
actions. Let d denote the dimension of φ(S, a). Let H denote the number of steps per episode. Let
K denote the total number of episodes. Let ι = log(2Hd/p) and p is the failure probability. Let
ρι = 1 - -√^ be the parameter determined by data structure in Theorem A.14 and ρ2 = 1 - 8k be
the parameter determined by data structure Theorem A.15. Since K > S, we write the preprocessing
time as O(Kd2A1+o(1)). This table is a detailed version of corresponding part of Table 1.
□
F MORE DATA S TRUCTURES: ADAPTIVE Max-IP QUERIES
In this section, we show how to tackle the adaptive Max-IP queries in RL. In both Sublinear LSVI
and Sublinear LSVI-UCB, the queries for (c, τ)-Max-IP during the value iteration are adaptive but
not arbitrary. Thus, we could not union bound the failure probability of LSH for (c, τ)-Max-IP.
In this work, we present a quantization method to union bound the failure probability of adaptive
Max-IP queries. This section is organized as:
•	In Section F.1, we introduce the LSH data structure for adaptive Max-IP queries and theo-
retical guarantee of Sublinear LSVI with this data structure.
•	In Section F.2, we present the LSH data structure for adaptive Max-MatNorm queries and
theoretical guarantee of Sublinear LSVI-UCB with this data structure.
F.1 SUBLINEAR LSVI WITH ADAPTIVE Max-IP QUERIES
In this section, we show how to tackle adaptive Max-IP queries in Sublinear LSVI. We start with
defining the quantized approximate Max-IP.
Definition F.1 (Quantized approximate Max-IP). Let c ∈ (0, 1) and τ ∈ (0, 1). Let λ ≥ 0. Given
an n-point dataset Y ⊂ Sd-1, the goal of the (c, τ, λ)-Max-IP is to build a data structure that, given
a query x ∈ Sd-1 with the promise that there exists a datapoint y ∈ Y with hx, yi ≥ τ, it reports a
datapoint Z ∈ Y with similarity〈x, z)≥ C ∙ Max - IP(x, Y) 一 λ.
Next, we show a standard way of performing approximate Max-IP via LSH. We denote Q as the
convex hull of all queries for (c, τ)-Max-IP and denote its maximum diameter in `2 distance as DX.
iii
Our quantization methodviii contains two steps: (1) Preprocessing: we quantize Q to a lattice Q with
viiiThis is a standard trick in the field of sketching and streaming Nakos et al. (2019); Ben-Eliezer et al. (2020).
51
Under review as a conference paper at ICLR 2022
quantization error λ∕d. In this way, each coordinate would be quantized into the multiples of λ∕d.
(2) Query: given a query x ∈ Q, we first quantize itto the nearest qb ∈ Q and perform (c, τ)-Max-IP.
As each qb ∈ Q is independent, we could union bound the failure probability of adaptive queries. On
the other hand, this would generate an λ additive error in the returned inner product.
Next, we show our theorem for (c, τ, λ)-Max-IP over adaptive queries in Theorem F.2.
Theorem F.2 (A modified version of Theorem B.2). Letc ∈ (0, 1), τ ∈ (0, 1) and λ ∈ (0, 1). Given
a set of n-points Y ⊂ Sd-1 on the sphere, one can construct a data structure with preprocessing
time Tinit ∙ K and space SsPaCe ∙ K so that for every X ∈ Sd-1 in an adaptive query Sequence X 二
{xι, X2, ∙∙∙ , xτ}, we take O(dnρ ∙ K) query time:
•	if Max-IP(x, Y ) ≥ τ, then we output a vector in Y which is a (c, τ, λ)-Max-IP with respect
to (x, Y ) with probability at least 1 - δ, where ρ = f (c, τ) + o(1).
•	otherwise, we output fail.
where K := d log(ndDX ∕(λδ)) and ρ ∈ (0, 1). We use DX to represent maximum diameter in `2
distance of all queries in X.
Further more,
•	If Tinit = O(dn1+ρ) and SsPaCe = O(n1+ρ + dn), then f (c,τ) = 丁;+二∙
•	If Tinit = O(dn1+o⑴)and SsPaCe = O(n1+o⑴ + dn), then f(c,τ) = ((二T)2 -(11-Tj ∙
Proof. The failure probability for an adaptive sequence X is equivalent to the probability that at least
one query qb ∈ Q fail in solving all K number of (c, τ)-Max-IP. We bound this failure probability as
dDX 1
Pr[∃b∈ Q s.tall (c,τ)-Max-IPfail]= n ∙(-ɪ)d ∙ ( —)κ ≤ δ
where the last step follows from K := dlog(nD /).
For the success queries, it introduces a λ error in the inner product. Thus, the results is (c, τ, λ)-
MaX-I P. Then, following Theorem B.2, we finish the proof.	□
Next, we show a modified Version of Theorem C.2 with (c, τ, λ)-Max-IP.
Theorem F.3 (Modified Version of Theorem C.2). Let MDP(S, A, H, P, r) denote a linear MDP
with core sets Score , Acore (see Definition A.7) and span matrix Φ (see Definition A.8). If we
query each φ(sj, aj) in the jth row of Φ for n = O(-2L2H 4ι) times, where ι = log(H d/p),
the output policy of Sublinear LSVI with (c, τ, λ)-Max-IP parameter c = 1 - CoL ∙ ,ι∕n and
λ = CoLH ∙ ,ι∕n would be e-optimal with probability at least 1 - p. In other words, the regret
of Sublinear LSVI is at most O(COLH2 ,ι∕n). Moreover, with Tnit ∙ K preprocessing time and
SsPaCe ∙ K space, the value iteration complexity of Sublinear LSVI is O(HSdAP ∙ k), where K :=
dlog(ndDX∕(λδ)), DX is the maximum diameter of weight.
Further more,
•	If Tnit = O(SdA1+ρ) and SsPaCe = O(SA1+ρ + SdA), then P = 1 - COL产.
•	If Tnit =O(SdA1+o⑴)and SsPaCe =O(SA1+o⑴ + SdA), then P = 1 - ClnI.
Proof. We start with showing the modified version of value difference. Because the quantization
transforms (c, τ)-Max-IP into a (c, τ, λ)-Max-IP with a λ additive error, we rewrite the value differ-
ence as:
HH
V*(s) - V1(s) ≤ E [X[(Ph - Ph)Vh+1](sh, ah) I s1 = s] +(1 - C) X(H + 1 - h) + λ ∙ H
π h=1	h=1
52
Under review as a conference paper at ICLR 2022
=E [X[(Ph - Ph)Vh+ι](sh, ah) I si = s] + W ∙ H (H +1)+ λ ∙ H (46)
π	h=1
where the first step adds λ error over each step based on Lemma C.1, and the second step is a
reorganization.
Next, We bound the V* (s) — VI(S) as：
H1
V*(s)-V1 (S) ≤ E [X[(Ph - Ph)Vl+ι](sh,ah)∣sι = s] +ɪ ∙ H (H +1)+ λ ∙ H
π h=1
1 — c
≤ H ∙ L ∙ C0 ∙ H ∙ √l∕n + -- ∙ H (H + 1) + λ ∙ H
C	,——	1 — c
=L ∙	C0	∙	H2	∙	√!∕n +	--~ ∙ H (H + 1) +	λ ∙ H
≤ L ∙	C0	∙	H2	∙	√!∕n +	(1 — c)H2 + λ ∙ H
≤ 2C0LH2√l∕n + λ ∙ H
≤ 3C0 LH 2√ι∕n
≤
Where the first step folloWs from Eq. (46), the second step folloWs the upper bound of [(Ph -
Ph)Vh+1](s, a) in Eq. (25), the third step is an reorganization, the forth step folloWs from H ≥ 1
So that H2 ≥ H, the fifth step follows from 1 — C = CoL,ι∕n, the sixth step follows from
λ = CoLH ∙ ,ι∕n, the seventh step follows from n = O(C2 ∙ e-2L2H4ι).
Using Theorem F.2, we derive the preprocessing time, space and query time for value iteration in
Sublinear LSVI. Because the value iteration complexity dominates Sublinear LSVI, the final runtime
complexity is O(HSdAP ∙ κ) with P strictly smaller than 1.	□
F.2 SUBLINEAR LSVI-UCB WITH ADAPTIVE Max-MatNorm QUERIES
In this section, we show how to tackle adaptive Max-MatNorm queries in sublinear LSVI-UCB.
We start with defining the quantized approximate Max-MatNorm.
Definition F.4 (Quantized Approximate Max-MatNorm). Let c ∈ (0, 1) and τ ∈ (0, 1). Let λ ≥ 0.
Given an n-point dataset Y ⊂ Sd-1, the goal of the (c, τ, λ)-Max-MatNorm is to build a data
structure that, given a query x ∈ Sd-1 with the promise that there exists a datapoint y ∈ Y with
〈x, yi ≥ T, it reports a datapoint Z ∈ Y with similarity〈x, z)≥ C ∙ Max-MatNorm(x, Y) — λ.
Next, we present how to extend quantized approximate Max-IP to approximate Max-MatNorm.
Theorem F.5 (A modified version of Theorem B.6). Let c ∈ (0, 1), τ ∈ (0, 1) and λ ∈ (0, 1).
Let vec denote the vectorization of d × d matrix into a d2 vector. Given a set of n-points Y and
yy> ∈ Sd2 -1 for all y ∈ Y, one can construct a data structure with with Tnit ∙ K preprocessing time
and SsPaCe ∙ κ space so thatfor ^very query X ∈ Rd×d with Vec(X) ∈ Sd2-i in an adaptive sequence
X = {xι, X2, ∙一,XT}, we take query time O(d2nρ ∙ κ):
• if Max-MatNorm(x, Y) ≥ τ, then we output a vector in Y which is a (c, τ, λ)-
Max-MatNorm with respect to (X, Y) with probability at least δ, where P := f(c, τ)+o(1).
• otherwise, we output fail.
where κ := d log(ndDX ∕(λδ)) and P ∈ (0, 1). We use DX to represent maximum diameter in `2
distance of all queries in X after vectorization.
Further more,
• If Tinit = O(d2n1+ρ) and SsPaCe = O(n1+ρ + d2n), then f (c,τ)=—海+产.
53
Under review as a conference paper at ICLR 2022
•	If Tinit = O(d2n1+o(1)) and Sspace = O(n1+o ⑴ + d2n) ,then f(c,τ) = :--二小
(i-τ 2)4
(1-c2τ2)4 .
—
Proof. We start with applying (c2, τ2, λ)-Max-IP data structure over vec(x) and vec(Y Y >). Then,
we would obtain a z ∈ Y that
hvec(x), vec(zz>)i ≥ c2 maxhvec(x), vec(yy>) - λi
y∈Y
we could use it and derive the following propriety for z :
(47)
kzkx =	hvec(x), vec(zz>)i
≥ «C maxhvec(x), vec(yy>)i — λ
≥	C max<vec(x), vec(yy>)i — √λ
y∈Y
≥ cmax hvec(x), vec(yy> )i - λ
= cmax kykx - λ
y∈Y
where the second step follows from Eq. (47), the third step follows from Cauchy-Schwartz inequal-
ity, the forth follows from λ ∈ (0, 1), the last step is a reorganization.
Thus, z is the solution for (c, τ, λ)-Max-MatNorm(x, Y ). Next, applying Theorem F.2 , we finish
the proof.
□
Theorem F.6 (Modified Version of Theorem D.12). Let MDP(S, A, H, P, r) denote a linear MDP.
For any probability p ∈ (0, 1) that is fixed, ifwe set approximate Max-MatNorm parameter c = 1 -
√^, quantization error λ ≤ λ∕H2K and Sublinear LSVI-UCB parameter β = Θ(dH√ι) with ι =
log(2dT∕p), then the Sublinear LSVI-UCB (Algorithm 4) has regret at most O(Ce ∙ √d3H4K∣2)
with probability 1 - p. Moreover, with Tinit ∙ K preprocessing time and Sspace ∙ K space, the value
iteration complexity of Sublinear LSVI-UCB is O(HKd2Aρ ∙ κ), where K := dlog(ndDX/(λδ)),
DX is the maximum diameter of weight.
Further more
•	If Tinit = O(Kd2A1+ρ) and Sspace = O(KA1+ρ + Kd2A), then P =1 -±.
•	If Tinit = O(Kd2A1+o(1)) and Sspace = O(KA1+o(1) + Kd2A), then P =1 -羲.
Proof. We start with showing the modified version of Q-function difference Q；(s, a) - Qf(s, a).
Because the quantization transforms (c, τ)-Max-IP into a (c, τ, λ)-Max-IP with a λ additive error,
we rewrite the Q；(s,a) - Qk (s,a) as:
1 cH
Qi(s,a) — Qi(s,a) ≤ (H — c~.-) + Hλ
1-c
Next, we could upper bound the regret with probability 1 - p as:
Regret(K) ≤ 2KγH2 + 2H√Tl + βH√2dKι + Hλ
=2KγH2 + 2H√Tl + Ce ∙ √2d3H4Ki2 + Hλ
=2√H4Ki2 + 2√H3Ki + Ce ∙ √2d3H4Ki2 + Hλ
54
Under review as a conference paper at ICLR 2022
=3√H4K + 2√H3Kι + Ce ∙ √2d3H4Kι2
≤ 2Cβ√d3H4Kι2
where the first step follows from Eq. (44), the second step follows from β = Ce ∙ dH√l, the third
step follows from Y =春,the forth step is a reorganization follows from λ ≤ λ∕H2K, the last step
follows from Ce ≥ 100.
Using Theorem F.5, we derive the preprocessing time, space and query time for value iteration
in Sublinear LSVI-UCB. Because the value iteration complexity dominates LSVI-UCB, the final
runtime complexity is O(HKd2 Aρ ∙ K) with P strictly smaller than 1. We alternate the S in prepro-
cessing and space by K since K > S. Note that to let ρ strict less than 1. We set c2 ∈ [0.5, 1) and
τ2 ∈ [0.5,1).	□
55