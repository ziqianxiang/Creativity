Under review as a conference paper at ICLR 2022
Progressive Domain Generalization
Anonymous authors
Paper under double-blind review
Ab stract
Domain generalization aims to learn a predictive model from multiple different
but related source tasks that can generalize well to a target task without the need
of accessing any target data. Existing domain generalization methods ignore the
relation between tasks, implicitly assuming that all the tasks are sampled from
a stationary environment. Therefore, they can fail when deployed in an evolv-
ing environment. To this end, we formulate and study the progressive domain
generalization (PDG) scenario, which exploits not only the source data but also
their evolving pattern to generate a model for the unseen task. Our theoretical
result reveals the benefits of modeling the relation between two consecutive tasks
by learning a globally consistent directional mapping function. In practice, our
analysis also suggest solving the PDG problem in a meta-learning manner, which
leads to directional prototypical network, the first method for the PDG problem.
Empirical evaluation on both synthetic and real-world data sets validates the ef-
fectiveness of our approach.
1	Introduction
Modern machine learning techniques have achieved unprecedented success over the past decades
in various areas. However, one fundamental limitation of most existing techniques is that a model
trained on one data set cannot generalize well on another data set if it is sampled from a different
distribution. Domain generalization (DG) aims to alleviate the prediction gap between the observed
source domains and an unseen target domain by leveraging the knowledge extracted from multiple
source tasks (Ganin & Lempitsky, 2015; Arjovsky et al., 2019; Li et al., 2018b).
Existing DG methods can be roughly categorized into three groups: data augmentation/generation,
disentangled/domain-invariant feature learning, and meta-learning (Wang et al., 2021). One intrin-
sic problem with these methods is that they treat all the domains equally and ignore the relationship
between them, implicitly assuming that they are all sampled from a stationary environment. How-
ever, in many real-world applications, the data are usually collected sequentially and the learning
tasks can vary in an evolving manner. For example, geological exploration is often carried out pe-
riodically and the distribution of data collected can change from year to year due to environmental
changes. Medical data are also often collected with age or other indicators as intervals, and there
is an evolving trend in the data of different groups. As a more concrete example, Fig. 1(a) shows
several instances from the rotated MNIST (RMNIST) data set, a widely used benchmark in the DG
literature, where the digit images of each subsequent domain are rotated by 15。. Fig. 1(b) reports the
generalization performances of several state-of-the-art DG algorithms on the data set, from which
it can be clearly observed that the performances drop when deploying the models on outer domains
(i.e., tasks of 0 and 75 degrees). The results indicate that the algorithms ignore the evolving pat-
tern between the domains properly. As a consequence, they are good at “interpolation” but not at
“extrapolation”.
In this paper, we formulate this learning scenario as progressive domain generalization (PDG),
which aims to capture and exploit the evolving patterns in the environment. In contrast to most
existing DG methods, which produce models that are isotropic with respect to all the domains, PDG
can generalize to a target domain along a specific direction by extracting and leveraging the rela-
tions between source tasks. Specifically, we develop a novel theoretical analysis that highlights the
importance of modeling the relation between two consecutive tasks to extract the evolving pattern
of the environment. Moreover, our analysis also suggests learning a globally consistent directional
mapping function via meta-learning. Inspired the theoretical results, we slightly modify prototypical
1
Under review as a conference paper at ICLR 2022
Figure 1: (a) Evolving manner among RMNIST domains. (b) Accuracy of traditional DG methods
on evolving domains. These methods cannot generalize well on outer domains (0° and 75°). (c)
Comparison between the performance of our method and baselines on outer domains. The proposed
method outperforms all the baselines.
networks (Snell et al., 2017) and propose directional prototypical networks (DPNets), a simple and
efficient PDG algorithm that adapts to the environment shift and generalizes well on the evolving
target domain. As a comparison, Fig. 1(c) shows the performance improvement of DPNets over the
other algorithms on RMNIST data set. It can be observed that the performance gap between DPNets
and the other baseline algorithms has widened as the domain distance increases. More details can
be found in Section 4.
Here, we would like to emphasize the key difference between PDG and domain adaptation in evolv-
ing domains (LiU et al., 2020; Wang et al., 2020; Kim et al., 2020). While both learning paradigms
aim to tackle the issue of evolving domain shifts, the latter still requires unlabeled instances from
the target domain. In this sense, PDG is more challenging and existing theoretical and algorithmic
results cannot be applied to this problem directly.
2	Related WORK
Domain Generalization (DG). Domain generalization aims to train a model which generalizes
on all domains. Existing DG methods can be classified into three categories. The first and most pop-
ular category is representation learning, which focus on learning a common representation across
domains. It can be achieved by domain-invariant representation learning (Blanchard et al., 2011;
Ghifary et al., 2015; Ganin & Lempitsky, 2015; Arjovsky et al., 2019) and feature disentanglement
(XU et al., 2014; Ilse et al., 2020). The former focuses on aligning latent features across domains, and
the later tries to distill domain-shared features. Secondly, data manipulation can also empower the
model with generalization capability. Data manipulating techniques include data augmentation (Yue
et al., 2019; Shankar et al., 2018b), which usually extend the dataset by applying specific transfor-
mations on existing samples, and data generation (Rahman et al., 2019), which often applies neural
networks to generate new samples. Nguyen et al. (2021) convert DG to an infinite-dimensional
constrained statistical learning problem under a natural model of data generation. The theoretically
grounded method proposed in Nguyen et al. (2021) leverages generating model among domains
to learn domain-invariant representation. The last part are meta-learning. As a widely applicable
method, meta-learning framework (Li et al., 2018b; BaIaji et al., 2018; Li et al., 2019) is used to im-
prove the generalizing capability by simulating the shift among domains. Apart from the above three
categories, there are some other learning strategies that help to improve the generalization ability of
the model. Mancini et al. (2018) tries to ensemble multiple models into a unified one which can gen-
eralize across domains. The DRO-based methods (Rahimian & Mehrotra, 2019) which aim to learn
a model at worst-case distribution scenario also match the target of DG well. Besides, gradient op-
eration (Huang et al., 2020b), self-supervision (Carlucci et al., 2019) and random forest (Ryu et al.,
2019) are also exploited to improve generalizing capability. Different from the existing DG methods
that focus on learning one unified model for all domains, our approach tries to train prediction model
for the target domain specifically by leveraging the evolving pattern among domains.
2
Under review as a conference paper at ICLR 2022
Evolving Domain Adaptation (EDA). Many previous work in domain adaptation area notice the
evolving pattern of domains and leverage it to improve the performance in different settings. Liu
et al. (2020) proposes a meta-adaptation framework which enables the learner to adapt from one sin-
gle source domain to continually evolving target domains without forgetting. Kim et al. (2020) tries
to adapt to multiple target domains sequentially without forgetting, while the most important differ-
ence is that there is no assumption about the evolving pattern between these domains. Kumar et al.
(2020) focuses on adapting from source domain to the target domain with large shifts by leveraging
the unlabeled intermediate samples. Wang et al. (2020) combines the traditional adversarial adap-
tation strategy with a novel regression discriminator that models the encoding-conditioned domain
index distribution. Chen & Chao (2021) investigate how to discover the sequence of intermediate
domains without index information then adapt to the final target. The experimental results and the-
oretical analysis demonstrate the value of leveraging index information when working on evolving
domains. These studies fully demonstrate that leveraging evolving pattern between domains is ben-
eficial and worth more exploration. However, there are two significant limitation in previous works.
The first one is the requirements for accessing unlabeled data in the target domain. The second one
is that all previous theoretical results are base on the assumption that distance between sequential
domains is small, which would become vacuous as the environment evolves. This is contrary to
the fact that more domains provide more evolving information which can help to improve the per-
formance. In this paper, the evolving information is leveraged without accessing any samples from
the target domain. Also, our theoretical results are based on proposed λ-consistency, a intuitive and
realistic measurement of evolving level in the environments.
3	Theoretical Analysis and methodology
Let {D1 (x, y), D2(x, y), ..., Dm(x, y)} be m observed source domains sampled from an environ-
ment E where x ∈ X and y ∈ Y are, respectively, the data point and its corresponding label. The
goal of DG is to learn a hypothesis h ∈ H so that it can have a low risk on an unseen but related
target domain Dt :
RDt(h) , E(χ,y)〜Dt['(h(χ),y)]
where ` : Y×Y → R+ is a non-negative loss function, andH is a hypothesis class that maps X to the
set Y . In the setting of traditional DG, as there is no relation exploited between the source domains
and the target domain, most existing techniques essentially either “enlarge” the input space X along
all possible directions (Volpi et al., 2018; Shankar et al., 2018a; Qiao et al., 2020) or learn a domain-
invariant feature representation via domain alignment (Li et al., 2018c; Arjovsky et al., 2019; Zhao
et al., 2020). In contrast, the objective of PDG is to generalize the model on Dt along a specific
direction when there is underlying evolving pattern between the source domains and Dt = Dm+1.
3.1	Theoretical Motivations
In order to leverage the evolving pattern in E , it is reasonable to assume that such a pattern can
be captured by a globally consistent mapping function g ∈ G : Dig+1 , g(Di) in a way such that
the synthetic domain Dig+1 is close to Di+1 as much as possible, where G is the class of mapping
functions. We first obtain the following bound of the risk on the target domain Dt with respect to
Dtg , as shown in Lemma 1.
Lemma 1. Let Dtg (h) = g(Dm) be the synthetic target domain, and suppose the loss function ` is
bounded within an interval G : G = max(') — min('). Then, for any h ∈ H, its target risk RDt (h)
can be upper bounded by:
RDt(h) ≤ RDg(h) + √2qdJS(Dg UdJ,
where dJS(Dtg||Dt) is the Jensen-Shannon (JS) divergence between Dtg and Dt (Fuglede & Topsoe,
2004).
Remark 1. To achieve a low risk on Dt, Lemma 1 suggests (1) learning h and g to minimize the
risk over the synthetic domain Dtg and (2) learning g to minimize the JS divergence between Dtg
and Dt. While in practice RDg (h) can be approximated by the empirical risk, Lemma 1 still cannot
3
Under review as a conference paper at ICLR 2022
provide any practical guidelines for learning g since Dt is unavailable. Moreover, note that Dtg can
be replaced by g(Di) for any other source domain i in E and the bound still holds. Thus, Lemma 1
does not provide any theoretical insight into how to discover and leverage the evolving pattern in E .
Intuitively, capturing the evolving pattern in E is hopeless if it varies arbitrarily. On the other hand,
if the underlying pattern is consistent over domains, it is reasonable to assume that there exists
g* ∈ G would perform consistently well over all the domain pairs. For example, given numbers
100, 202, 301, one would expect that the numbers increase by around 100 and the next number will
be around 400, but it is challenging to guess the number if the first three numbers are -20, 1300, 4.
To formulate the this intuition, we first introduce the notion of consistency of an environment E
below.
Definition 1 (Consistency). Let g* = argming∈g maxDi∈E djs(Dg∣∣Di) be the ideal mapping
function in the worst-case domain. Then, an evolving environment E is λ-consistent if the following
holds:
∣djs (Dg*∣∣Di)- djs (Dg*∣∣Dj )| ≤ λ,	∀Di, Dj ∈E.
Note that λ does not characterize how fast E evolves, but if there exists a global mapping function
that can model the evolving pattern consistently well in E.
Given the definition of consistency, we can bound the target risk in terms of dJS(Dig ||Di) in the
source domains.
Theorem 1. Let {D1, D2, ..., Dm} be m observed source domains sampled sequentially from an
evolving environment E, and Dt be the next unseen target domain: Dt = Dm+1. Then, if E is
λ-consistent, we have
RDt (h) ≤ RDg* (h) +
P2(G - 1) (∖
m
X djs(Dg*l∣Di) + P(m — 1)λ .
i=2
Remark 2. (1) Theorem 1 highlights the role of the mapping function and λ-consistency in PDG.
Given g*, the target risk RDt (h) can be upper bounded by in terms of loss on the synthetic target
*
domain RDg* (h), λ, and the JS divergence between Di and Dig in all observed source domains.
When g* can properly capture the evolving pattern of E, we can train the classifier h over the
synthetic domain Dtg generated from Dm and can still expect a low risk on Dt. (2) λ is unobservable
and is determined by E and G. Intuitively, a small λ suggests high predictability ofE, which indicates
that it is easier to predict the target domain Dt . On the other hand, a large λ indicates that there
does not exist a global mapping function that captures the evolving pattern consistently well over
domains. Consequently, generalization to the target domain could be challenging and we cannot
expect to learn a good hypothesis h on Dt . (3) In practice, g* is not given, but can be learned by
minimizing dj s (Dig ||Di) in source domains. Besides, aligning Dig and Di is usually achieved by
representation learning: that is, learning g : X → Z to minimize dj s (Dig ||Di), ∀z ∈ Z.
In addition, we can decompose D(x, y) into marginal and conditional distributions to motivate more
practical PDG algorithms. For example, when it is decomposed into class prior D(y) and semantic
conditional distribution D(x|y), we have the following Corollary.
Corollary 1. Following the assumptions of Theorem 1, the target risk can be bounded by
RDt (h) ≤ RDg* (h) +
G
P2(m — 1)
∖
I
m
X djs (Dg* (y)l∣Di(y))+P(m — 1)λ
i=2
_ - /
{z
I
+
∖
I
m
X Ey 〜Dg*(y)djs(Di* (XIy) ||Di(XIy)) +
i=2
____________________ - /
{^^^^^^^^^^^^^^^^^^^^^^^
m
X Ey〜Di(y)dJS(Di* (XIy) ||Di(XIy))
i=2
__________________ - /
{^^^^^^^^^^^^^^^^^^^^^^^
II	III
\
I
Remark 3. To generalize well to Dt , Corollary 1 suggests that a good mapping function should
capture both label shifts (term I) and semantic conditional distribution shifts (terms II & III). If we
4
Under review as a conference paper at ICLR 2022
further assume that the label distribution does not evolve over domains1, we will have I = 0 and II =
III, and the upper bound can be simplified as
RDt (h) ≤ Rd，* (h) +	/ I、( 2\
Dt	√2(m - 1) V \
m
X Ey〜Di(y)dJS(Dg* (XIy) ||Di(XIy)) + p(m - I)λ 卜
i=2
Finally, we note two key theoretical differences between PDG and previous studies of DA in evolv-
ing environments (Ben-David et al., 2010; Liu et al., 2020). (1) In DA, the target risk is bounded
in terms of source and target domains (e.g., H∆H-divergence), while our analysis relies on the
distance between synthetic and real domains. (2) DA theories are built upon the assumption that
there exists an ideal joint hypothesis that achieves a low combined error on both domains, while our
assumption is the λ-consistency of E . These differences eventually lead to fundamentally different
guidelines for PDG, as shown in Section 3.2.
3.2	Practical Implementations
Our analysis reveals several general strategies to follow when designing an algorithm for PDG.
(i)	Learning the mapping function g to capture the evolving pattern by minimizing the distance
between the distributions of synthetic and real domains.
(ii)	Learning g and hto minimize the risk on the synthetic target domain Dtg .
(iii)	Note that Dig+1 = g(Di) is produced from Di, but its quality is evaluated on Di+1. Thus,
minimizing dJ S (Dig IIDi) naturally suggests a meta-learning strategy for learning g.
In practice, mapping the samples from Di to Di+1 is not necessarily performed in the original data
space since our ultimate goal is making predictions rather than generating instances themselves.
Thus, we minimize the distance between Dig+1 and Di+1 in a representation space. Based on these
ideas, we slightly modify prototypical networks (Snell et al., 2017) and propose directional proto-
typical networks (DPNets) for PDG. Specifically, the mapping function g of DPNets consists of two
different embedding functions: fφ for Di and fψ for Di+1, where φ and ψ are learnable parameters.
The key idea of DPNets is to learn g = {fφ, fψ } to capture the evolving pattern of E by estimat-
ing the prototypes of fψ(Di+1) using fφ(Di). As each prototype can be viewed as the centroid
of instances of each class, which is an approximation of the semantic conditional distribution of
each class (Xie et al., 2018; Shui et al., 2021a), DPNets essentially minimizes the distance between
Dig+1(XIy) and Di+1(XIy), as suggested by Corollary 1 Remark 3.
Let Si = {(Xin, yni )}nN=i 1 be the data set of size Ni sampled from Di, and Sik be the subset ofSi with
class k ∈ {1, ..., K}, where K is the total number of classes. Then, the prototype of domain i is the
mean vector of the support instances belonging to Sik :
Ck =两 X	fφ(xn)
i (xin,yni )∈Sik
In (Snell et al., 2017), the prototype is used to produce a distribution D(y = kIX) to make a predic-
tion for a query instance X in the context of few-shot learning, and the support and query instances
are sampled from the same domain. By contrast, in DPNets, the prototypes are computed from the
support set Si through the embedding function fφ , but the query instances are from Si+1 and are
passed through another function fψ. Then, the predictive distribution for Di+i is given by
Dφ,ψ(yi+1 = kIXi+1)
exp(-d(fψ (xi+1),ck))
PK= exp(-d(fψ (Xi+1),，。
(1)
where d : Z × Z → [0, +∞) is a distance function of embedding space, and we adopt squared
Euclidean distance in our implementation, as suggested in (Snell et al., 2017). During the training
1 When label shifts exist, term I can be minimized by reweighting/resampling the instances according to the
class ratios between domains (Shui et al., 2021a).
5
Under review as a conference paper at ICLR 2022
Algorithm 1 The loss computation for DPNets (one episode)
Input: {S1, S2, ..., Sm}: m data sets from consecutive domains. NB: the number of support and
query instances for each class. RANDOMSAMPLE(S, N): a set ofN instances sampled uniformly
from the set S without replacement.
Output: The loss Jφ,ψ for a randomly generated training episode.
t J RANDOMSAMPLE({1,..., m})
for k in {1, ..., K } do
Sk J RANDOMSAMPLE(Sik, NB)
Q J RANDOMSAMPLE(Sik+1, NB)
Ck = |S1k| P(Xj,yj )∈Sk fφ(xj )	. Compute prototypes
end for
J(φ, ψ) J 0
for k in {1, ..., K } do
for (x, y) in Q do
Jφ,ψ J Jφ,ψ + KN B [d(fψ (X), Ck) + log Pk0 exp(-d(fψ (X), Ck )]
end for
end for
stage, at each step, we randomly choose the data sets Si , Si+1 from two consecutive domains as
support and query sets, respectively. Then, we sample NB samples from each class k in Si , which
is used to compute prototype Cik for the query data in Si+1 . Model optimization proceeds by
minimizing the negative log-probability: Jφ,ψ = - log Dφ,ψ (yi+1 = k|Xi+1). The pseudocode
to compute Jφ,ψ for a training episode is shown in Algorithm 1. In the testing stage, we pass the
instances from Sm and St through fφ and fψ respectively as support and query sets, and then make
predictions for the instances in Dt using Eq. (1).
4	Experiments
4.1	Experimental Setup
We evaluate our algorithm on an extensive collection of five data sets, including two synthetic
data sets (Envolving Circle (Wang et al., 2020) and Rotated Plate and three real-world data sets
(RMNIST (Ghifary et al., 2015), Portrait (Kumar et al., 2020; Chen & Chao, 2021), and Cover Type
(Kumar et al., 2020)).
(1)	Evolving Circle (EvolCircle, Fig. 2) consists of 30 evolving domains, where the instances are
generated from 30 2D Gaussian distributions with the same variances but different centers uniformly
distributed on a half-circle. (2) Rotated Plate (RPlate, Fig. 3) consists of 30 domains, where the
instances of each domain is generated by the same Gaussian distribution but the decision boundary
rotates from 0° to 348° with an interval of 12°. (3) Rotated MNIST (RMNIST) WerandomIy select
only 2400 instances in raw MNIST dataset and split them into 12 domains equally. Then we apply
the rotations with degree of θ = {0°, 10°, ..., 110°} on each domain respectively. The amount of
samples in each domain is only 200, which makes this task more challenging. (4) Portrait This task
is to classify gender based on the photos of high school seniors across different decades (Ginosar
et al., 2015). We divided the dataset into 12 domains by year. (5) Cover Type data set aims to
predict cover type (the predominant kind of tree cover) from 54 strictly cartographic variables. To
generate evolving domains, we sort the samples by the ascending order of the distance to the water
body, as proposed in (Kumar et al., 2020). Then we equally divided the data set into 10 domains
by distance. (5) FMoW A large satellite image dataset with target detection and classification tasks
(Christie et al., 2018) . We select 5 common classes to compose a classfication task. The dataset is
divided into 19 domains by time.
We compared the proposed method with the following baselines: (1) GroupDRO (Sagawa et al.,
2019); (2) MLDG (Li et al., 2018a); (3) MMD (Li et al., 2018c); (4) SagNet (Nam et al., 2021);
(5) VREx (Krueger et al., 2021); (6) SD (Pezeshki et al., 2020); (7) IRM (Arjovsky et al., 2019);
(8) Mixup (Yan et al., 2020); (9) CORAL (Sun & Saenko, 2016); (10) MTL (Blanchard et al.,
2021); (11) RSC (Huang et al., 2020a); (12) DIRL (Nguyen et al., 2021); (13) Original Proto-
6
Under review as a conference paper at ICLR 2022
(a) Domains
(b) Ground Truth
(e) DPNets-Global
(c) ERM
(d) DPNets-Target
Figure 2: Visualization of the EvolCircle data set. (a) 30 domains indexed by different colors, where
the left bottom one is target domain. (b) Positive and negative instances are denoted by red and
blue dots respectively. (c) The decision boundaries learned by ERM. (d) Decision boundaries of
last model on all domains. (e) Decision boundaries of models in each domain. (the results of first
domain are missing due to the lack of prototypes.
SOUrCePOInainS
TargetDomain
Evolving P(y IX)
(a) Domains and Ground Tnxth
Figure 3: Visualization of the RPlate data set. (a) The true decision boundaries evolves over do-
mains. (b) & (c) The decision boundaries learned by ERM and DPNets on the target domain.
。30
(b)ERM
(c) DPNets
Table 1: Comparison of accuracy (%) among different methods.
Algorithm	EvolCircle	RPlate	RMNIST	Portrait	Cover Type	FMoW	Average
GroupDRO	75.5 ± 1.0	70.0 ± 4.9	76.5 ± 0.2	94.8 ± 0.1	66.4 ± 0.5	57.3 ± 0.1	73.4
MLDG	91.5 ± 2.0	66.9 ± 1.8	75.0 ± 0.3	66.2 ± 1.7	68.4 ± 0.7	43.8 ± 0.0	68.6
MMD	86.7 ± 5.7	59.9 ± 1.4	35.4 ± 0.0	95.4 ± 0.1	69.8 ± 0.4	60.0 ± 0.0	67.8
SagNet	78.7 ± 3.2	63.8 ± 2.9	79.4 ± 0.1	95.3 ± 0.1	65.3 ± 2.2	56.2 ± 0.1	73.1
VREx	82.9 ± 6.6	61.1 ±2.6	79.4 ± 0.1	94.3 ± 0.2	66.0 ± 0.9	61.2 ± 0.0	73.3
SD	81.7 ± 4.3	65.3 ± 1.4	78.8 ± 0.1	95.1 ± 0.2	69.1 ± 0.9	55.2 ± 0.0	74.2
IRM	86.2 ± 3.0	67.2 ± 2.1	47.5 ± 0.4	94.4 ± 0.3	66.0 ± 1.0	58.8 ± 0.0	70.0
Mixup	91.5 ± 2.6	66.8 ± 1.8	81.3 ± 0.2	96.4 ± 0.2	69.7 ± 0.6	59.5 ± 0.0	77.5
CORAL	86.8 ± 5.1	61.9 ± 1.4	78.4 ± 0.1	95.1 ± 0.1	68.1 ± 1.3	56.1 ± 0.0	74.4
MTL	77.7 ± 2.4	66.0 ± 1.2	77.2 ± 0.0	95.4 ± 0.1	69.2 ± 0.9	51.7 ± 0.0	72.9
RSC	91.5 ± 2.1	67.9 ± 4.2	74.7 ± 0.1	95.5 ± 0.1	69.4 ± 0.3	55.7 ± 0.1	75.8
DIRL	53.3 ± 0.2	56.3 ± 0.4	76.3 ± 0.3	93.2 ± 0.2	61.2 ± 0.3	43.4 ± 0.3	64.0
Prototypical	93.6 ± 0.5	66.3 ± 0.4	85.2 ± 0.4	96.2 ± 0.3	66.5 ± 0.4	53.3 ± 0.2	76.9
ERM	72.7 ± 1.1	63.9 ± 0.9	79.4 ± 0.0	95.8 ± 0.1	71.8 ± 0.2	54.6 ± 0.1	74.7
DPNets (Ours)	94.2 ± 0.9	95.0 ± 0.5	87.5 ± 0.1	96.4 ± 0.0	72.5 ± 1.0	66.8 ± 0.1	85.4
typical Network (Snell et al., 2017); (14) ERM (Vapnik, 1998). All the baselines and experiments
were implemented with DomainBed package (Gulrajani & Lopez-Paz, 2020) under the same set-
ting, which guarantees extensive and sufficient comparisons. Specifically, for each algorithm and
data set, we conduct a random search (Bergstra and Bengio, 2012) of 20 trials over the hyperparam-
eter distribution, and for each hyperparameter, five independent experiments with different random
seeds are repeated to reduce the variances. Other details of hyperparameters and experimental setup
are provided in the appendix.
4.2	Results and Analysis
Overall Evaluation The performances of our proposed method and baselines are reported in Table
4. It can be observed that DPNets consistently outperforms other baselines over all the data sets,
7
Under review as a conference paper at ICLR 2022
Table 2: Comparison of accuracy (%) of different methods on RMNIST data set with different
number of domains.
# Domains	3	5	7	9	11	13	15	17	19
Mixup	82.3 ± 0.3	83.3 ± 0.3	83.8 ± 0.6	83.3 ± 0.3	80.0 ± 0.3	78.3 ± 0.3	80.0 ± 0.3	77.3 ± 0.3	72.5 ± 0.3
IRM	46.0 ± 0.2	44.0 ± 0.0	35.6 ± 0.3	46.5 ± 0.3	40.4 ± 0.4	49.6 ± 0.3	46.0 ± 0.1	46.9 ± 0.3	41.3 ± 0.1
MLDG	85.0 ± 0.2	81.9 ± 0.4	82.7 ± 0.3	80.0 ± 0.6	79.0 ± 0.1	74.2 ± 0.1	77.9 ± 0.3	71.7 ± 0.1	68.8 ± 0.3
ERM	80.0 ± 0.3	81.6 ± 0.3	81.3 ± 0.1	79.7 ± 0.2	79.7 ± 0.3	75.6 ± 0.3	77.8 ± 0.3	69.1 ± 0.3	74.4 ± 0.1
DPNets (Ours)	83.4 ± 0.1	83.1 ± 0.3	81.1 ± 0.1	82.8 ± 0.3	88.1 ± 0.3	87.3 ± 0.5	86.6 ± 0.1	85.6 ± 0.3	86.3 ± 0.3
and achieves 89.1% on average which is significantly higher the other algorithms (≈ 8% - 20%).
The results indicate that existing DG methods cannot deal with domain shifts well while DPNets
can properly capture the evolving patterns in the environments. It is also worth noting that directly
employing Prototypical Network on our problem setting does not receive good result (81.5%), which
further illustrates the effectiveness of our architectural design.
To further investigate the learning behaviors in evolving environments, we study the synthetic data
sets, where the evolving pattern can be manually controlled. Here, we studied two typical evolving
scenarios P(X) and P(Y |X), corresponding to the EvolCircle and RPlate data sets respectively.
Evolving P (X) (EvolCircle). The decision boundaries on the unseen target domain D30 learned
by ERM and DPNets are shown in Fig. 2(c) and Fig. 2(d) respectively. We can observe that DPNets
fits the ground truth significantly better than that of ERM. This indicates that our approach can
capture the evolving pattern of P (X) according to source domains and then learn a better classifier
for the target domain. Furthermore, it can also be observed that the decision boundary learned
by ERM achieves better performance on the observed source domains. This is because it focuses
on improving generalization ability on all source domains, which leads the poor performance on
the outer target domain D30 . On the contrary, DPNets can “foresee” the prototypes for the target
domain, which guarantees a good generalization performance even though it may not perform well
on tge source domains.
Evolving P(Y |X) (RPlate). By visualizing the data sets, we can observe that the predicted bound-
ary of DPNets better approximates the ground-truth, compared with the result of ERM. This in-
dicates that our approach can also capture the P(Y |X) evolving pattern. Existing DG methods
perform poorly on this data set because the ground truth labeling function varies. Under the evolv-
ing labeling functions, even the same instance can have different labels in different domains. Thus,
there does not exist a single model that can perform well across all the domains. For this situa-
tion, learning a model specifically for one domain instead of all domains can be a possible solution.
DPNets can capture the evolving pattern and produce a model specifically for the target domain.
When to apply DPNets? Existing DG methods assume
that the distances among observed and unseen domains
does not very large. However, the dissimilarity between
domains is a crucial factor which can fundamentally in-
fluence the possibility and performance of generalization.
To investigate the impact of variances of the environment,
we create a series of variations on the raw RMNST data
by jointly varying the number of domains (Table 2) and
the degree interval (Table 3) between two consecutive do-
mains. The performance improvement of DPNets over
the baseline ERM (AccDPNets - AccERM) is shown in Fig.
4. Experimental results indicate that DPNets performs
better when the number of domains and the distance be-
tween domains increase On one hand, greater number of
domains and larger distance between them lead to more
significant difference across domains. This makes tradi-
Figure 4: Performance of RMNIST
w.r.t. different domain numbers and dis-
tances.
tional DG methods harder to train one model from all domains, but oppositely more domains benefit
our DPNets to learn the evolving pattern to achieve better performance. On the other hand, we ob-
served that the DPNets significantly outperforms other baselines when the number of domains and
the distance between domains increase.
8
Under review as a conference paper at ICLR 2022
Table 3: Comparison of accuracy (%) of different methods on RMNIST data set with different
distance between domains.
Domain Distance	3。	5。	7。	10。	15。	20。
Mixup	92.5 ± 0.1	91.9 ± 0.3	88.4 ± 0.3	81.3 ± 0.2	73.1 ± 0.1	59.4 ± 0.3
IRM	69.4 ± 0.2	63.4 ± 0.1	49.7 ± 0.0	47.5 ± 0.4	35.6 ± 0.3	31.3 ± 0.3
MLDG	90.9 ± 0.1	87.5 ± 0.2	85.0 ± 0.2	75.0 ± 0.3	71.9 ± 0.1	56.9 ± 0.3
ERM	92.2 ± 0.1	88.8 ± 0.0	82.8 ± 0.1	79.4 ± 0.0	66.3 ± 0.1	53.1 ± 0.3
DPNets (Ours)	91.9 ± 0.3	91.3 ± 0.3	88.4 ± 0.3	87.5 ± 0.1	85.6 ± 0.3	83.8 ± 0.3
In Table 2 and Table 3, we respectively analyzed the affect of the domain distance and the number of
domains on the generalization ability of different models. We can observe that, with the increasing
complexity of source domains, the DPNets benefits a lot from the evolving information and the
performance gap between our method and baselines increase. In addition, from Table 2 we can find
that the performance of traditional DG methods fluctuates when the number of domains increases.
As for the DPNets , its performance continuously improves when the domain number increases,
since it easily learns the evolving manners from more domains. Please refer Section more discussion
about this. From Table 3, we can see that when the domain distance increases, the performance of
DG methods decreases severely while the performance of DPNets drops slightly.
In conclusion, the experimental results imply that it is hard for traditional DG methods to solve
the PDG problem when the number of domains and distance between domains increase, while our
DPNets can still perform well in such a scenario.
(a) ERM	(b) Prototypical Network	(c) DPNets
Figure 5: T-SNE Visualization of embedded RMNIST data learned by ERM and DPNets.
T-SNE visualization over evolving domains. In this part, we investigate the ability of DPNets and
DG methods in distilling domain evolving information. Most domain generalization approaches
aim to learn an invariant representation across all domains. While in the PDG scenario, we need to
leverage the evolving pattern to improve the generalization process. Here, we use t-SNE to visualize,
respectively, the representations learned from the second-to-last layer by ERM, DPNets, and original
Prototypical Network in Fig. 5. The colors from red to blue correspond to the domains index from
1 to 30. The feature visualizations demonstrate that DPNets can keep the domain evolving even in
the last layer of the network, which makes it possible to leverage that knowledge. On the contrary,
the evolving pattern learned by Prototypical Network and ERM is less obvious. The results further
prove that ERM and original Prototypical Network can not leverage evolving information well.
5	Conclusions
In this paper, we study the problem of domain generalization in an evolving environment, and pro-
pose progressive domain generalization (PDG) as a general framework to address it. Our theoretical
analysis highlights the role of learning a mapping function to capture the evolving pattern over do-
mains. Based on our analysis, we propose directional prototypical networks (DPNets), a simple and
efficient algorithm for PDG. Experiments on both synthetic and real-world data sets validate the
effectiveness of our method.
9
Under review as a conference paper at ICLR 2022
Ethics S tatement
This paper presents an algorithm that can exploit evolving information in a continuously changing
environment to improve the performance of the model in target domains where data are not available.
the proposed approach may also introduce the potential negative impact: the Portrait dataset we use
is only intended to demonstrate algorithm’s superior performance on classification tasks.
References
Martin Arjovsky, Leon BottoU,Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization.
arXiv preprint arXiv:1907.02893, 2019.
Yogesh Balaji, Swami Sankaranarayanan, and Rama Chellappa. Metareg: Towards domain gen-
eralization using meta-regularization. Advances in Neural Information Processing Systems, 31:
998-1008,2018.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wort-
man Vaughan. A theory of learning from different domains. Machine learning, 79(1):151-175,
2010.
Gilles Blanchard, Gyemin Lee, and Clayton Scott. Generalizing from several related classification
tasks to a new unlabeled sample. Advances in neural information processing systems, 24:2178-
2186, 2011.
Gilles Blanchard, Aniket Anand Deshmukh, Urun Dogan, Gyemin Lee, and Clayton Scott. Domain
generalization by marginal transfer learning. J. Mach. Learn. Res., 22:2-1, 2021.
Fabio M Carlucci, Antonio D’Innocente, Silvia Bucci, Barbara Caputo, and Tatiana Tommasi. Do-
main generalization by solving jigsaw puzzles. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 2229-2238, 2019.
Hong-You Chen and Wei-Lun Chao. Gradual domain adaptation without indexed intermediate do-
mains. Advances in Neural Information Processing Systems, 34, 2021.
Gordon Christie, Neil Fendley, James Wilson, and Ryan Mukherjee. Functional map of the world.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6172-
6180, 2018.
Bent Fuglede and Flemming Topsoe. Jensen-shannon divergence and hilbert space embedding. In
International Symposium onInformation Theory, 2004. ISIT 2004. Proceedings., pp. 31. IEEE,
2004.
Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In
International conference on machine learning, pp. 1180-1189. PMLR, 2015.
Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang, and David Balduzzi. Domain generaliza-
tion for object recognition with multi-task autoencoders. In Proceedings of the IEEE international
conference on computer vision, pp. 2551-2559, 2015.
Shiry Ginosar, Kate Rakelly, Sarah Sachs, Brian Yin, and Alexei A. Efros. A century of portraits: A
visual historical record of american high school yearbooks. CoRR, abs/1511.02575, 2015. URL
http://arxiv.org/abs/1511.02575.
Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization.	CoRR,
abs/2007.01434, 2020. URL https://arxiv.org/abs/2007.01434.
Zeyi Huang, Haohan Wang, Eric P Xing, and Dong Huang. Self-challenging improves cross-domain
generalization. In Computer Vision-ECCV 2020: 16th European Conference, Glasgow, UK,
August23-28, 2020, Proceedings, PartII16, pp. 124-140. Springer, 2020a.
Zeyi Huang, Haohan Wang, Eric P Xing, and Dong Huang. Self-challenging improves cross-domain
generalization. In Computer Vision-ECCV 2020: 16th European Conference, Glasgow, UK,
August 23-28, 2020, Proceedings, Part II 16, pp. 124-140. Springer, 2020b.
10
Under review as a conference paper at ICLR 2022
Maximilian Ilse, Jakub M Tomczak, Christos Louizos, and Max Welling. Diva: Domain invariant
variational autoencoders. In Medical Imaging with Deep Learning, pp. 322-348. PMLR, 2020.
Joonhyuk Kim, Sahng-Min Yoo, Gyeong-Moon Park, and Jong-Hwan Kim. Continual unsupervised
domain adaptation with adversarial learning. CoRR, abs/2010.09236, 2020. URL https://
arxiv.org/abs/2010.09236.
David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai
Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapo-
lation (rex). In International Conference on Machine Learning, pp. 5815-5826. PMLR, 2021.
Ananya Kumar, Tengyu Ma, and Percy Liang. Understanding self-training for gradual domain
adaptation. In International Conference on Machine Learning, pp. 5468-5479. PMLR, 2020.
Bo Li, Yezhen Wang, Shanghang Zhang, Dongsheng Li, Kurt Keutzer, Trevor Darrell, and Han
Zhao. Learning invariant representations and risks for semi-supervised domain adaptation. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.
1104-1113, 2021.
Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Learning to generalize: Meta-
learning for domain generalization. In Thirty-Second AAAI Conference on Artificial Intelligence,
2018a.
Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Learning to generalize: Meta-
learning for domain generalization. In Thirty-Second AAAI Conference on Artificial Intelligence,
2018b.
Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with adver-
sarial feature learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pp. 5400-5409, 2018c.
Yiying Li, Yongxin Yang, Wei Zhou, and Timothy Hospedales. Feature-critic networks for heteroge-
neous domain generalization. In International Conference on Machine Learning, pp. 3915-3924.
PMLR, 2019.
Hong Liu, Mingsheng Long, Jianmin Wang, and Yu Wang. Learning to adapt to evolving do-
mains. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (eds.), Ad-
vances in Neural Information Processing Systems, volume 33, pp. 22338-22348. Curran As-
sociates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/
fd69dbe29f156a7ef876a40a94f65599- Paper.pdf.
Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. Conditional adversarial
domain adaptation. arXiv preprint arXiv:1705.10667, 2017.
Massimiliano Mancini, Samuel Rota Bulo, Barbara Caputo, and Elisa Ricci. Best sources forward:
domain generalization through source-specific nets. In 2018 25th IEEE international conference
on image processing (ICIP), pp. 1353-1357. IEEE, 2018.
Hyeonseob Nam, HyunJae Lee, Jongchan Park, Wonjun Yoon, and Donggeun Yoo. Reducing do-
main gap by reducing style bias. In Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pp. 8690-8699, 2021.
A. Tuan Nguyen, Toan Tran, Yarin Gal, and Atilim Gunes Baydin. Domain invariant repre-
sentation learning with domain density transformations. In Thirty-Fifth Conference on Neu-
ral Information Processing Systems, 2021. URL https://openreview.net/forum?id=
l3vp7IDY6PZ.
Mohammad Pezeshki, Sekou-Oumar Kaba, YoshUa Bengio, Aaron Courville, Doina Precup, and
Guillaume Lajoie. Gradient starvation: A learning proclivity in neural networks. arXiv preprint
arXiv:2011.09468, 2020.
Fengchun Qiao, Long Zhao, and Xi Peng. Learning to learn single domain generalization. In 2020
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 12553-12562.
IEEE, 2020.
11
Under review as a conference paper at ICLR 2022
Hamed Rahimian and Sanjay Mehrotra. Distributionally robust optimization: A review. arXiv
preprint arXiv:1908.05659, 2019.
Mohammad Mahfujur Rahman, Clinton Fookes, Mahsa Baktashmotlagh, and Sridha Sridharan.
Multi-component image translation for deep domain generalization. In 2019 IEEE Winter Con-
ference on Applications ofComputer Vision (WACV), pp. 579-588. IEEE, 2019.
Jongbin Ryu, Gitaek Kwon, Ming-Hsuan Yang, and Jongwoo Lim. Generalized convolutional for-
est networks for domain generalization and visual recognition. In International Conference on
Learning Representations, 2019.
Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust
neural networks for group shifts: On the importance of regularization for worst-case generaliza-
tion. arXiv preprint arXiv:1911.08731, 2019.
Shiv Shankar, Vihari Piratla, Soumen Chakrabarti, Siddhartha Chaudhuri, Preethi Jyothi, and Sunita
Sarawagi. Generalizing across domains via cross-gradient training. In International Conference
on Learning Representations, 2018a.
Shiv Shankar, Vihari Piratla, Soumen Chakrabarti, Siddhartha Chaudhuri, Preethi Jyothi, and
Sunita Sarawagi. Generalizing across domains via cross-gradient training. arXiv preprint
arXiv:1804.10745, 2018b.
Changjian Shui, Zijian Li, Jiaqi Li, Christian Gagne, Charles X Ling, and BoyU Wang. Aggregating
from multiple target-shifted sources. In Proceedings of the 38th International Conference on
Machine Learning, pp. 9638-9648, 2021a.
Changjian Shui, Boyu Wang, and Christian Gagne. On the benefits of representation regularization
in invariance based domain generalization. arXiv preprint arXiv:2105.14529, 2021b.
Jake Snell, Kevin Swersky, and Richard S. Zemel. Prototypical networks for few-shot learning.
CoRR, abs/1703.05175, 2017. URL http://arxiv.org/abs/1703.05175.
Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In
European conference on computer vision, pp. 443-450. Springer, 2016.
Vladimir N. Vapnik. Statistical Learning Theory. Bantam, 1998.
Riccardo Volpi, Hongseok Namkoong, Ozan Sener, John Duchi, Vittorio Murino, and Silvio
Savarese. Generalizing to unseen domains via adversarial data augmentation. In Proceedings
of the 32nd International Conference on Neural Information Processing Systems, pp. 5339-5349,
2018.
Martin J Wainwright. High-dimensional statistics: A non-asymptotic viewpoint, volume 48. Cam-
bridge University Press, 2019.
Hao Wang, Hao He, and Dina Katabi. Continuously indexed domain adaptation. arXiv preprint
arXiv:2007.01807, 2020.
Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, and Tao Qin. Generalizing to unseen
domains: A survey on domain generalization. CoRR, abs/2103.03097, 2021. URL https:
//arxiv.org/abs/2103.03097.
Shaoan Xie, Zibin Zheng, Liang Chen, and Chuan Chen. Learning semantic representations for
unsupervised domain adaptation. In International conference on machine learning, pp. 5423-
5432. PMLR, 2018.
Zheng Xu, Wen Li, Li Niu, and Dong Xu. Exploiting low-rank structure from latent domains for
domain generalization. In European Conference on Computer Vision, pp. 628-643. Springer,
2014.
Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain
adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020.
12
Under review as a conference paper at ICLR 2022
Xiangyu Yue, Yang Zhang, Sicheng Zhao, Alberto Sangiovanni-Vincentelli, Kurt Keutzer, and Bo-
qing Gong. Domain randomization and pyramid consistency: Simulation-to-real generalization
without accessing target domain data. In Proceedings of the IEEE/CVF International Conference
on Computer Vision, pp. 2100-2110, 2019.
Shanshan Zhao, Mingming Gong, Tongliang Liu, Huan Fu, and Dacheng Tao. Domain generaliza-
tion via entropy regularization. Advances in Neural Information Processing Systems, 33, 2020.
13
Under review as a conference paper at ICLR 2022
A	Proofs
A.1 Lemma 1
We first prove an intermediate lemma:
Lemma 2. Let z ∈ Z = X × Y be the real valued integrable random variable, let P and Q are two
distributions on a common space Z such that Q is absolutely continuous w.r.t. P. If for any function
f and λ ∈ R such that EP [eλ(f(z)-EP (f(z))] < ∞, then we have:
λ(EQf(z) -EPf(z)) ≤ DKL(QkP) + log EP [eλ(f(z)-EP (f(z))],
where DKL(QkP) is the Kullback-Leibler divergence between distribution Q and P, and the equal-
ity arrives when f(z) = EP f(z) + 1 log(黑).
Proof. We letgbe any function such that EP [eg(z)] < ∞, then we define a random variable Zg(z) =
EJeeX)]，then We Can verify that EP (Zg) = 1. We assume another distribution Q such that Q (with
distribution density q(z)) is absolutely continuous w.r.t. P (with distribution density p(z)), then we
have:
EQ [log Zg] = EQ [log -ʃʒ + Iog(Zg
p(z)
DKL(QkP) + EQ[log(Zg
≤ DKL(QkP)+logEq[TZg] = DKL(QkP)+logEp[Zg]
q(z)
Since EP[Zg] = 1 and according to the definition we have EQ[log Zg] = EQ[g(z)] -
EQ log EP [eg(z)] = EQ[g(z)] - log EP [eg(z)] (since EP [eg(z)] is a constant w.r.t. Q) and we there-
fore have:
EQ[g(z)] ≤ log EP [eg(z)] + DKL(QkP)
(2)
Since this inequality holds for any function g with finite moment generation function, then we let
g(z) = λ(f(z) - EPf(z)) such that EP[ef(z)-EPf(z)] < ∞. Therefore we have ∀λ and f we have:
EQλ(f(z) - EPf(z)) ≤ DKL(QkP) + log EP [eλ(f(z)-EP f(z)]
Since we have EQλ(f(z) - EPf(z)) = λEQ(f(z) - EPf(z))) = λ(EQf (z) - EPf(z)), therefore
we have:
λ(EQf (z) - EP f (z)) ≤ DKL(QkP) + log EP[eλ(EQf(z)-EPf(z))]
As for the attainment in the equality of Eq.(2), we can simply set g(z) = log(Pp(Z)), then we can
compute EP [eg(z)] = 1 and the equality arrives. Therefore in Lemma 1, the equality reaches when
λ(f(z)- EPf (z))=log(器).
In the classification problem, we define the observation pair z = (x, y). We also define the loss
function `(z) = L ◦ h(z) with deterministic hypothesis h and prediction loss function L. Then for
abuse of notation, we simply denote the loss function `(z) in this part.
Given Lemma 2, we are ready to prove Lemma 1.
Proof. According to Lemma 2, ∀λ > 0 we have:
EQf(Z)- EPf(z) ≤ 1(logEP e[i(f(Z)-Epf(Z))] + DKL(QkP))
λ
(3)
And ∀λ < 0 we have:
EQf(Z)- EPf(z) ≥ 1(logEP e[i(f(Z)-Epf(Z))] + DKL(QkP))
λ
(4)
Then we introduce an intermediate distribution M(Z) = 2(D(z) + D0(z)), then SUPP(D) ⊆
supp(M) and supp(D0) ⊆ supp(M), and let f = `. Since the random variable ` is bounded
14
Under review as a conference paper at ICLR 2022
through G = max(') - min('), then according to WainWright (2019) (Chapter 2.1.2), ' - EP' is
SUb-GaUssian with parameter at most σ = G, then We can apply SUb-GaUssian property to bound
the log moment generation function:
log EP eR'(z)-Ep'(z))]
1	λ2σ2	λ2G2
≤ log e -ɪ ≤ —∣p
In Eq.(3), we let Q = D0 and P = M, then ∀λ > 0 we have:
G2λ 1
ED0 '(Z)- EM '(Z) ≤ ~8--+ λDKL(D kM)	(5)
In Eq.(4), we let Q = D and P = M, then ∀λ < 0 we have:
G2λ	1
ED '(Z)- EM '(Z) ≥ -8-+ λDKL(DkM)
(6)
In Eq.(5), we denote λ = λ0 > 0 and λ = -λ0 < 0 in Eq.(6). Then Eq.(5), Eq.(6) can be
reformUlated as:
Edo '(z) - EM '(z) ≤ G2λ0 + ɪDKL(DOkM)
28	λ0	(7)
EM '(z) - ED '(z) ≤ —J-0 + bDKL(DkM)
8	λ0
Adding the two ineqUalities in Eq.(7), we therefore have:
Edo '(z) ≤ ED '(z) + ɪ(DKL(DkM) + DKL(DOkM)) + λ0G2	(8)
λ0	4
Since the inequality holds for ∀λ0, then by taking λ0 = G PDKL(DkM) + DKL(DOkM) We finally
have:
―—_	.. . G - 一 .一
Edo '(z) ≤ Ed '⑺ + 不 VzDJS(DOkD)	(9)
Let D0 = Dt and D = Dg, we complete our proof.	□
A.2 Theorem 1
Proof. According to Definition of λ-consistency, we have:
djs(Dg*∣∣Dt) ≤ djs(Dg*∣∣D2) + ∣djs(Dg*∣∣Dt) - djs(Dg*∣∣D2)∣ ≤ djs(Dg*∣∣D2)+ λ
Similarly, we have the followings:
djs(Dg*∣∣Dt) ≤ djs(Dg*∣∣Di) + ∣djs(Dg*∣∣Dt) - djs(Dg*||A)| ≤ djs(Dg*∣Di) + λ
djs(Dg* ||Dt) ≤ djs(Dg； ||Dm) + |djs(Dg* ||Dt) - djs(Dg； ∣∣Dm)∣ ≤ djs(Dg: ||Dm) + λ,
which gives us
djs(Dtg*||Dt) ≤
1
m-1
m
Xdjs(Dig*||Di) + λ
i=2
Then, according to Lemma 1, we have
RDt (h) ≤ RDg* (h) + √2 Jdjs(Dg* ||Dt)
≤ RDg* (h) +
G u 1 m
√2t m-ι Xdjs(Di ||Di)+λ
≤ RDg* (h) +
G
P2(m - 1)
m
X djs(Dg*∣∣Di) + P(m - 1)λ
i=2
□
15
Under review as a conference paper at ICLR 2022
A.3 Corollary 1
We first introduce the upper bound for Jensen Shannon (JS) Divergence decomposition:
Lemma 3. Let D(x, y) and D0(x, y) be two distributions over X × Y, D(y) and D0 (y) be the
corresponding marginal distribution of y, D(x|y) and D0(x|y) be the corresponding conditional
distribution given y, then we can get the following bound,
dJS(D(x, y)||D0(x, y)) ≤
djs (D(y)∣∣D0(y)) + Ey 〜D(y)djs (D(χ∣y)∣∣D0(χ∣y)) + Ey⑺(y)djs (D(χ∣y)∣∣D0(χ∣y))
Proof. Let M(x,y) = 2(D(x, y) + D0(x, y)), then we have
2 ∙ djs(D(x,y)∣∣D0(x,y)) = dκL(D(x,y)∣∣M(x,y)) + dκL(D0(x,y)∣∣M(x,y))
=dKL(D(J)IM(J)) + Ey 〜D(y) dKL (D(XIy)IM (XIy))
+ dKL(DO(y)|M(y))+ Ey 〜D0(y)dKL(D(XIy)IM(XIy))
=2 ∙ djs(D(y)IID0(y)) + Ey-D(y)dκL(D(xIy)IIM(xIy))
+ Ey 〜do (y)dκL(D(χIy)IIM(χIy))
To bound the last two terms with JS divergence, we have:
dKL(D(XIy)IIM(XIy)) ≤ dKL(D(XIy)IIM(XIy)) + dKL(D0(XIy)IIM(XIy))	(10)
=2 ∙ djs (D(XIy)MDO(X〔y)).
Also,
dKL(DO(XIy)IIM(XIy)) ≤ dKL(D(XIy)IIM(XIy)) + dKL(DO(XIy)IIM(XIy))	(11)
=2 ∙ djs (D(XIy)HDO(XIy))∙
Combining (10) and (11) gives us
djs(D(X, y)IIDO(X, y)) ≤
djs (D(y)IID0(y))+ Ey 〜D(y)djs (D(XIy)IID0 3y)) + Ey 〜D，(y)djs (D(XIy)IID0 (XIy)),
which concludes the proof.	□
Given Lemma 3, we are ready to prove Corollary 1.
Proof.
≤ RDtg*
RDt (h) ≤ RDg* (h) +
m
Xdjs(Dig*IIDi)+G
i=2
(h) + G
G
√2(m - 1)
∖
m
X djs(Dg* (y)IIDi(y)) + Ey 〜Di(y)djs(Dg* (XIy) UDi(XIy)) + Ey 〜Dg*(y)djs(Dg* (XIy) HDi(XIy))
i=2
≤ RDg* (h) +
G
√2(m - 1)
m
X djs(Dg* (y)IIDi(y)) + P(m - 1)λ
i=2
+
∖
m
X Ey 〜Dg* (y)djs(Dg* (XIy) iiDi(XIy)) +
i=2
m
X Ey〜Di(y)djs(Dg* (XIy) 11Di(XIy))
i=2
∖
]
□
16
Under review as a conference paper at ICLR 2022
A.4 Comparison to the Assumptions of Existing Studies
Learning in a non-stationary environment is impossible if no assumption is imposed on the environ-
ment. Existing theoretical studies of evolving domain adaptation have made various assumptions
on the evolving pattern of the environment to obtain meaningful results. Specifically, Kumar et al.
(2020) assumes that ρ(Dt, Dt+ι) < e, where ρ(∙, ∙) is some distance measurement of distribution,
and the assumption in Liu et al. (2020) is dH∆H①t`, Dt2) ≤ α∣tι - t2∣. In other words, they both
assume that the distance between two consecutive domains is small. Although such an assumption
seems intuitive and reasonable, there are two fundamental issues:
1.	Too restrictive for real-world scenarios. In many problems, the distance between two
domains can be much larger than the difference of domain indices. For example, a small
angular rotation may result in a large difference of the pixel-level data distribution. Existing
assumptions will fail to characterize such a scenario since both ρ and dH∆H can be quite
large, but this problem is still learnable in practice.
2.	Not taking the algorithm into account. Both ρ and dH∆H are algorithm-independent in
the sense that they only characterize the nature ofan environment itself but does not involve
any specific learning algorithm. Consequently, these assumptions cannot directly motivate
any concrete strategies for learning the evolving pattern.
g*	g*
In contrast, our notion of λ-consistency: |dJ S (Dig ||Di) - dJ S (Djg ||Dj)| ≤ λ offers natural solu-
tions to these issues:
1.	It reveals that what really matters is not the distance between two consecutive domains
but the stability (predictability) of the evolving pattern of an environment. Specifically, if
the evolving pattern of an environment is stable (not necessarily slow), there will exist a
mapping function such that λ is small. In other words, our notion indicates that generaliza-
tion performance can still be guaranteed even though the distance between two consecutive
domains is large, as long as λ is small.
2.	It also highlights the role of the mapping function g. Since g* is unknown in practice,
one primary objective of a PDG algorithm is essentially to minimize the distance between
the real and mapped domains. In our implementation (i.e., DPNets), this objective is real-
ized by estimating the prototypes of the next domain by leveraging the instances from the
previous domain. Other realizations are also possible, which opens up avenues for future
work.
B	Additional Experiments
B.1	Further Investigation of Interpolation and Extrapolation
In Table 2, we can observe that the performances of ERM are not improved as the number of domains
increases, which is counter-intuitive. We speculate that this is due to the “extrapolation” nature of
PDG. To further investigate its impact on the generalization performance on the target domain, we
compare the following three settings on the RMNIST dataset:
1.	DPNets-Evolving (Extrapolation). Same as DPNets in Section 4, where the target domain
Dt = Di+1.
2.	ERM-Evolving (Extrapolation). Same as ERM in Section 4, where the target domain
Dt = Di+1.
3.	ERM-Interpolation. The ERM approach using the domain in the middle as the target
domain, and the rest domains as the source domains.
Note that (1) and (2) are different algorithms with the same problem setup, and (2) and (3) use the
same algorithm but with different problem setups.
We vary the the numbers of domain numbers and domain distances, and the results are reported in
Fig. 6, from which we have the following observations:
17
Under review as a conference paper at ICLR 2022
(a) Distance = 3°	(b) Distance = 7°	(C) Distance = 11°	(d) Average
Figure 6: Performance of algorithms when numbers of domains changes.
1.	The overall trend of the DPNets is going up as the number of domains increases.
2.	The performances of ERM-Evolving do not increase as a function of the number of domain
distance, which is consistent with the results in Table 2.
3.	The performances of ERM-Interpolation increase as a function of the number of domain
distance
4.	The improvements of DPNets and ERM-Interpolation are not obvious once having suffi-
cient amount of domains (e.g., # of domains = 7 for ERM-Interpolation). We conjecture
that it is because the evolving pattern of RMNIST is relatively simple. Thus, a small num-
ber of domains are sufficient to learn such a pattern, and increasing the number of domains
may not necessarily improve the performances of DPNets and ERM-Interpolation anymore.
The results indicate for extrapolation, having more domains does not necessarily help learn an in-
variant representation if we do not leverage the evolving pattern. Intuitively, as the target domain
is on the “edge” of the domains, having more domains also indicates that it is further away from
the “center” of the source domains, which may even make the generalization even more challeng-
ing. On the other hand, if the target domain is “among” the source domains (i.e., when we perform
“interpolation”), the source domains may act as augmented data which improve the generalization
performance. In other words, if the more source domains will be beneficial for “interpolation” but
not necessarily for “extrapolation” if the evolving pattern is not properly exploited.
B.2	Incorporating Domain Information into ERM.
The ERM in Section 4 does not leverage the index information of the source domains. In order
to make a more fair comparison, we incorporate the index information into ERM. Specifically, we
investigate three strategies for incorporating the index information used in the literature: (1) Index
Concatenation (Fig. 7a), where the domain index is directly concatenated as a one-dimension feature
(Li et al., 2021); (2) One-hot Concatenation (Fig. 7b), where the domain index is first one-hot
encoded and then concatenated to the original features (Long et al., 2017); (3) Outer product (Fig.
7c), where flattened the outer product of original features and the one-hot indexes is used as the final
input (Shui et al., 2021b).
Feature Dimension
(a) Index Concatenation
Domain
FeatUreS	IIIdeX
(c) Outer Product
(b) One-hot Concatenation
Figure 7: Three domain index information incorporation strategies.
18
Under review as a conference paper at ICLR 2022
Table 4: Performance of the traditional DG algorithms with domain index information incorporated.
Strategy	EVolCircle	RPlate	AVerage
ERM	72.7 ± 1.1	63.9 ± 0.9	68.3
ERM + One-Dimension	73.6 ± 0.6	64.9 ± 0.8	69.3
ERM + One-Hot	74.6 ± 0.3	64.0 ± 0.3	69.3
ERM + Outer Product	74.6 ± 0.4	65.3 ± 0.2	70.0
DPNets (Ours)	94.2 ± 0.9	95.0 ± 0.5	92.2
We evaluate the algorithms on the EvolCircle and RPlate datasets and the results are reported in
Table 4. The experimental results verify the advantage of our algorithm in exploiting evolving
information. We can observe that the improvements induced by incorporating domain index is
marginal, which indicates that it cannot properly leverage the evolving pattern of the environment.
C Implementation Details
We implement our algorithm based on Gulrajani & Lopez-Paz (2020). To justify algorithm compar-
ison between baselines and our algorithm, we adopted a random search of 20 trials for the hyper-
parameter distribution. For each parameter combination, 5 repeated experiments are conducted.
Then, we report the highest average performance for each algorithm-dataset pair. In this way, all
parameters are automatically selected without human intervention, making the comparison of ex-
perimental results of different algorithms on different data fair and reliable. Almost all backbone
and setting are following Gulrajani & Lopez-Paz (2020) except the followings. In one singe experi-
ment, the model structure of fφ and fψ keeps the same. For EvolCircle and RPlate, we only use one
single layer network to make the classifier linear for all algorithms. For other dataset, network are
randomly chose based on the random search algorithm.
19