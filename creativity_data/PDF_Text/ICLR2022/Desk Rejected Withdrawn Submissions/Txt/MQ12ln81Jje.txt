Under review as a conference paper at ICLR 2022
RankedDrop: Enhancing Deep Graph Convolu-
tional Networks Training
Anonymous authors
Paper under double-blind review
Ab stract
Graph Neural Networks (GNNs) are playing a more and more important role for
analyzing unstructured data from the complex real world. Introducing random
edge dropping from the input graph at training epochs could reduce over-fitting
and over-smoothing phenomenon and increase the depth of GNNs. However,
such method relies strongly on the chosen randomness. It makes the accuracy
depend on the initialization of the randomness, which lets the selection of hyper-
parameters be even more difficult. We propose in this paper RankedDrop a novel
method with a spatial-aware dropping-edge selection. The selection takes into
account the graph global information using PageRank, and graph local neighbor-
hood information with node degree. RankedDrop provides a more stable training
results comparing to the state-of-the-art solution, by maintaining the advantages
of random edge dropping. Furthermore, RankedDrop is a general method that can
be deployed on a deep learning framework for enhancing performance of GNNs.
1	Introduction & Context
Convolutional Neural Networks (CNNs) demonstrated a great success in our today’s daily life for
image classification and many other applications. However in the real world there are still many
non-Euclidean (graph) data like social networks or reference systems that cannot be handled by
CNNs. After Defferrard et al. (2016) introducing Graph Neural Networks (GNNs), Defferrard et al.
(2016) generalized CNNs to graph to exploit their potential for classification problems on non-
Euclidean data structure. The computation of Graph Convolutional Neural Networks (GCNs) can
be summarized as iterative neighborhood aggregations with a message passing schema (Huan et al.
(2021)).
He et al. (2016) showed that deeper CNN has higher potential to achieve better precision. However,
modern GCNs (Kipf & Welling (2017); Pei et al. (2021); Hamilton et al. (2017)) can work with very
limited number of layers, because training deep neural networks is a very complex task (Claesen &
De Moor (2015)), the complexity of the computed function grows exponentially with depth (Raghu
et al. (2017)), and the deeper the networks are, the more they are subject to over-smoothing (Li
et al. (2018); Chen et al. (2020)). Meanwhile, deeper GCN and/or small graph datasets could lead
to over-fitting, where a model could fit well the training data but poorly the testing data.
Dropout (Hinton et al. (2012); Srivastava et al. (2014)) is a promising regularization techniques to
reduce over-fitting. In the field of GCN, DropEdge introduced by Rong et al. (2019), which ran-
domly removes a certain proportion of edges from the input graph at each epoch, showed promising
results to reduce the convergence speed of over-fitting and over-smoothing. Moreover, the random
dropping happened on the message passing schema of most of GCNs. Therefore such method could
be applied for many GCN backbone models like GCN (Kipf & Welling (2017)), ResGCN (Pei et al.
(2021)), GraphSage (Hamilton et al. (2017) ), IncepGCN (szegedy2016rethinking) and JKNet (Xu
et al. (2018)).
However, the accuracy obtained by DropEdge depends on how the randomness of dropping is ini-
tialized. Moreover, the only parameter that can be adjusted in DropEdge is the percentage of edges
that will be dropped. Missing of control on the way of how dropping edges be selected, may limit
possibilities to optimize GCN training according to application domain and chosen backbone ar-
chitecture. Furthermore, a graph structure includes a lot of useful information (Newman (2003)).
1
Under review as a conference paper at ICLR 2022
Random dropping may destroy graph structure information and again limits the potential of opti-
mizing GCN training.
This paper proposes RankedDrop a novel method with a spatial-aware dropping-edge selection. The
selection takes into account the graph global information using PageRank, and graph local neighbor-
hood information with node degree. Graph structure information is extracted to reduce the impact
of randomness in the selection and also to improve the final accuracy after training. RankedDrop
provides a more stable training results comparing to the state-of-the-art solution, by maintaining the
advantages of random edge dropping including over-fitting and over-smoothing reduction and being
a general method for different GCN backbones. Shown by our experiments, the accuracies of deep
GCNs on semi-supervised learning are significantly improved by using RankedDrop.
2	RankedDrop method with data selection
RankedDrop is a general method, and it is applied on the input graph of a GCN training before each
epoch. It first extracts a score based on graph analysis for each node (Sec 2.2); after that the nodes
are reordered to control the selection probability then selected according to the computed score (Sec
2.3); at the end the edges of selected nodes are selected and we drop the selected edges to create the
new input graph (Sec 2.4).
2.1	Notations and preliminaries
We use an adjacency matrix A to represent the original input graph G, and nnz the number of
non-zero value of A, a.k.a. the number of edges of the graph G. We denote p the proportion
of edges from G that will be dropped. Therefore, after dropping, the new input graph Gdrop has
(1 - p) × nnz edges. We denote the resulting adjacency matrix Adrop for Gdrop , and we use A0 to
denote the matrix of p × nnz dropped edges. The relation between the above three matrices is:
Adrop = A - A0	(1)
The theorem 1 introduced in the paper (Rong et al. (2019)) proved that training GCN on Gdrop
instead of G allows to reduce the speed of convergence of the over-smoothing and to reduce the
loss of information. The idea is based on the concept of mixing time in the random walk theory
(Lovasz (1993)), and the proof is based on the work of Oono & Suzuki (2019). LUo et al. (2021)
demonstrated again the effectiveness of such dropping method.
In the following parts of the paper, we focus on the methods of selection of edges to drop, which
are the main contributions of RankedDrop. RankedDrop ranks the nodes in order to assign a weight
during the selection. Different from Sparsification (Eppstein et al. (1997)) or DropEdge (Rong et al.
(2019)), the goal of RankedDrop is to control the randomness with several parameters, but not to
completely control the choice of the drop edges, to create at each iteration a sub-graph in a more
intelligent way. It means that we bias the probability (greater or lesser) of being selected of each
edge according to our graph analysis, to create dropping strategy by reducing the dependency on
full randomness.
2.2	Graph information extraction
Most GCN architectures are mainly oriented on inter-neighbor communication (Huan et al. (2021)).
The information propagates through edges w.r.t. GCN layers. The shorter the path between two
nodes, the more they will influence each other. Removing the most impactful neighbors limits such
over-influence and reserves space for taking into account the information from other neighbors for
each epoch and among the epochs in a training. With the above idea, we propose here a node
ranking strategy in order to prepare a better dropping selection for the next steps. Two kinds of
graph structure information are extracted and used in the node selection step:
Local structure information The degrees of each node, which reflects the local impact of the
node on its neighborhood. Higher degree reflects stronger influence from a local point of view in the
2
Under review as a conference paper at ICLR 2022
graph. If a node has a lot of neighbors, it will have an impact at each layer on them and therefore
the information it contains will be strongly taken into account at the local level. The degrees are
extracted from the adjacency matrix A. Consider that A is an n × n matrix and that its number of
nonzero elements is nnz . A vector of size n is used to store the degrees of the nodes of the graph.
Global structure information Different graph node ranking algorithms (Agarwal & Chakrabarti
(2007)) could be used here to judge importance of each node on the global graph. We use in the
paper the PageRank algorithm (Page et al. (1999)) to generate the score of importance, because
(1) PageRank is the most studied algorithms of the last decades, by our knowledge it can be easily
implemented in a distributed way to accelerate its computation; (2) It was already used in GNNs
to reduce the over-smoothing (Bojchevski et al. (2019)). From the adjacency matrix A, a vector
of size n will be returned and will contain the score of each node. The algorithm 1 represents the
implementation of PageRank used in RankedDrop. It shows that the main operation of each iteration
of the PageRank is a matrix-vector multiplication where the output vector is used to perform the
next iteration multiplication. By considering A as sparse, the cost of this sequence of sparse matrix-
vector multiplications is reduced and can be executed efficiently in a distributed way (Hugues &
Petiton (2010)), which allows to optimize the extra computations that PageRank requires. This
iterative method stops when the convergence has reached the expected precision. The result vector
of the last iteration contains then the scores of each node of the graph and all elements are between
0 and 1. The higher the score, the more important the node is in the global graph. A β coefficient
is also introduced during the PageRank. It is an optimization allowing to redistribute a part of the
scores of each node among all the other nodes. In this way, the convergence of the result vector
is faster and avoids that all the score is distributed only within the strongly connected component.
Conventionally, the β coefficient is fixed around 0.85, this value was used for the experiments in the
section 3.
The local and global structure information is used to rank the nodes of the graph to determinate the
overall importance of each node in the graph. The importance of the nodes in the global and/or local
structure of the graph gives a score to each node so that the nodes with a higher score are more often
included in the matrix Adrop . Thus, the structure of the graphs Gdrop that will be generated at each
iteration will be closer to the structure of the graph G than when the dropping is done randomly. We
note s the vector of size n which stores the final score of the associated nodes. The computation
of this score is flexible. There are many possibilities to compute the values of s by taking the
information of the local and/or global structure, and potentially other information. At the end, the
goal is to have a vector such that ∀i ∈ [1, n], 0 ≤ Si ≤ 1 and Pin=1 Si = 1.
2.3	Node selection with probability control
After getting the score vector s, we sort the nodes according to their scores in a decreasing order.
The permutations performed during the sorting are stored in memory in order to keep the association
information between the nodes and the scores.
After the sorting, we create a probability scale from the sorted score vector by applying a Scan-With-
Add (SWA) algorithm (a.k.a prefix sum, Blelloch (1990)). SWA will generate an interval between
0 and 1 for each node. Therefore, the node selection is no more in a fully random way but the
randomness is limited in the interval. The resulting vector is of size n where the values are more
and more ordered. The resulting vector is such that SWAs [n] = 1. In addition, SWA could help
visualize the inequalities of score between the nodes in the graph, like the Lorenz curve used in
economics (Lorenz (1905)).
The node selection is performed with the SWA vector. The SWA value of each node corresponds
to the probability of the node being selected. Formatting the score vector as a SWA accelerates the
selection of nodes. For each node selection, we take a random number between 0 and 1 and find the
node associated with this value in the vector SWAs. A binary search (Knuth (1998)) on the SWA
vector can find the node with a O(log n) complexity, where it is necessary to browse element by
element the vector of s scores at each node selection. We will discuss the selection of nodes from
the SWA vector in more detail in the next section.
3
Under review as a conference paper at ICLR 2022
Algorithm 1 Algorithm to get the PageRank
score from adjacency matrix
Algorithm 2 Node selection from the score
vector
Input: A the adjacency (sparse) matrix, δ pre-
cision, β coefficient
Output: v vector of PageRank score of size n
Initialisation :
1:	sum - 0
2:	err — INF
3:	new vector tmp of size n
4:	assign 1 to each element in V
START LOOP
5:	while err > δ do
6:	reset all element of tmp to 0
7:	tmp J SPMV between A and V
8:	for each elem in tmp do
9:	elem J β * elem +(1 — β) * 1
10:	end for
11:	err J norm between tpm and V
12:	V J tmp
13:	end while
14:	return V
Input: SWAs the Scan-With-Add final score
vector, sumS cor e the sum of the remain-
ing nodes’ scores, malus the vector of
malus aPPlied to each node.
Output: ind the index of the node to Perform
the droP edge
Initialisation :
1:	r J randomin]0, 1[
2:	r J r * sumS cor e
3:	m J 0
4:	a J 0
5:	b J size of SWAs
6:	while b-a != 1 do
7:	c J (a + b)/2
8:	m J m+ malus on c node
9:	if SWA_S of C — m — sB<r then
10:	a J c
11:	else
12:	b J c
13:	add (c + b)/2 on the Potential malus
node list
14:	add c in the exPlored nodes list
15:	end if
16:	end while
17:	return b
2.4	Dropping edge selection
The last steP is to select the exact edges to droP. Different from the Previous stePs that can be
Performed only once in the beginning of training, the edge selection is Performed for each ePoch to
generate a different subgraPh. At each ePoch, p × nnz edges are chosen from the selected nodes
and are removed.
Different edge selection algorithms could be aPPlied here. For examPle, the selection could be
based on the tail, on the head, or directly removing all edges of a selected node (a.k.a DroPNode).
For the exPeriments Presented in the section 3, we randomly select edges from the selected node.
This adds randomness to the selection Process. To select a node, we took our insPiration from the
bisection method (Burden & Faires (1985)). By randomly Pulling in a uniform way a number r
between 0 and 1, we obtain the index of the node i that checks SWAs [i] < r < SWAs [i + 1] by
Performing a dichotomy. The selection of edges and nodes is based on the SWA des scores SWAs,
, the imPortance of the node in the graPh will influence its Probability to be selected at each ePoch.
Thus, the randomness is controlled but the selection Probabilities are different for each node so that
the randomness takes into account the global structure of the graPh. Itis Possible from the PageRank
results and/or degrees vector to create subgraPhs that keeP the key nodes of the graPh so that at each
ePoch the graPh generated is consistent with the structure of the initial graPh.
It is useful to keeP an efficient selection method because it is Performed a large number of times.
This is why we have tried to oPtimize the imPlementation of this selection (see the algorithm 2) by
adding a malus system when exPloring the SWA vector to avoid selecting a node from which all
edges have already been selected. When all the edges associated to a node have been droPPed, there
is no more interest to select this node again. Our oPtimization is based on the fact that the bisection
method can be rePresented as a tree. At each steP of the dichotomy, there is the Possibility to move
either the lower or the uPPer bound. To be sure not to select a node i, it is Possible to aPPly a malus
(equal to the score of the node i) to the exPlored branches when the uPPer bound is moved in the Path
to access the SWAs [i] (because all these Paths lead to nodes further in the SWAs vector). Thus,
4
Under review as a conference paper at ICLR 2022
it is enough to modify at most log n malus value instead of modifying a large number of values in
SWAs.
3	Experiments and discussions
RankedDrop is a general method that could equip different algorithms for the node selection and
edge selection, and can be applied for different GNN architectures. In the experiments of this paper,
we used the classic PageRank to compute scores for the node selection; we used basic random selec-
tion for the edge selection; and we used mostly the standard GCN as the training architecture, since
Rong et al. (2019) and Luo et al. (2021) have already demonstrated the genericity of these Dropping
methods for other GNN architecture. We believe such standard configuration could provide a clear
and general idea of the potential offered by RankedDrop.
3.1	Datasets and environment
Three standard citation datasets were used in our experiments: Cora, Citeseer and Pubmed. These
datasets represent collections of scientific articles that are classified according to the paper’s main
research topic (Sen et al. (2008)). More information of these datasets can be found in the table x. We
notice that these graphs are very sparse, since their number of edges per node is very low: in average
about two edges per node. However, if we see closely, the highest degree nodes of those datasets
have more than 100 edges (99 for Citeseer and up to 171 for Pubmed). This means that a very large
number of nodes have a very low degree (≤ 2). Therefore, only few important nodes propagate
their information very widely; the information of other low degree notes are quickly drowned. For
example in Cora, the node with the highest degree is directly connected to more than 6% of the
nodes in the graph.
Table 1: Datasets global informations
Cora		Citeseer	Pubmed
Number of nodes	2 707	3 327	197l7
Number of edges	5 429	4 732	44 338
edges by node (mean)	2.01	1.42	2.25
Max node degree	168	99	171
Min node degree	1	1	1
Oriented	Yes	Yes	Yes
Max score PageRank	4, 92 * 10-02	4,01 * 10-02	6,10 * 10-03
The extraction of graph data, the score computation until edge selection and dropping were done
before the GCN training on Intel Xeon Processor E5-2690 with 8 cores. The result was used to
build Gdrop. The trainings with Gdrop were done on Nvidia Tesla V100 PCIe 16GB GPUs. The
original GCN, the state of the art DropEdge and our RankedDrop were compared in this section to
validate our solution.
3.2	How Scan-With-Add helps node selection
The values of the SWA of PageRank and Degree are represented graphically in figure 1. We can see
that PageRank allows to put forward a small number of nodes; these curves increase very quickly.
The distribution of the scores is very unequal: for all the datasets, 10% of the best ranked nodes
share more than 80% of the total score, because PageRank highlights the most important nodes in
an exponential way. Therefore if the nodes are randomly selected, there is an 80% chance to choose
one of the 10% high ranked nodes. By using SWA-PageRank, the best rated nodes of the G graph
will be very often integrated to the G0 graph, because they are the nodes that have the most impact
in the global structure of the graph. On the other hand, the scores of SWA-Degree rise more slowly.
The inequality between the nodes is thus less important. The highest degree nodes are privileged in
terms of scores but they are not too much highlighted compared to SWA-PageRank. Therefore, we
can choose the most adapted SWA and decide to select either the most or the less important nodes
to prepare the edge selection.
5
Under review as a conference paper at ICLR 2022
Figure 1: Variation of the Scan-With-Add vectors for Cora, Citeseer and Pubmed datasets for local
structure with degrees and global structure with PageRank.
3.3	Impact of RankedDrop on over-fitting
(a) Cora
(b) Citeseer
(c) Pubmed
Figure 2: Loss payout curve for datasets with the GCN 4 layers architecture in full-supervised
learning. Comparaison between the original methode, DropEdge (DE) and RankedDrop (RD).
The figures 2 and 3 show the training and validation loss curves in full-supervised and semi-
supervised learning, respectively. All curves for the same dataset were obtained with the same hyper-
parameters, only the percentage of dropping edges is different between DropEdge and RankedDrop.
We can observe that, the two dropping methods in general have the similar behavior, both have bet-
ter loss convergence than the original GCN, and in some cases, the validation loss of RankedDrop
converges again better than the one of DropEdge. These experiments show that RankedDrop is the
best method to reduce the over-fitting phenomenon and to stabilize the loss. RankedDrop has also
the same behavior on over-smoothing reduction as DropEdge, so we will not discuss here.
3.4 Impact of dropping control
The accuracies after training with different proportion of non-drop edges are shown in figure 4.
The accuracies were obtained with the best hyper-parameters for each cases with GCN in the semi-
6
Under review as a conference paper at ICLR 2022
2.5-
2.0-
1.5-
1.0-
0.5-
0.0-
0	100	200	300	400
Epochs
(a) Cora	(b) Citeseer	(c) Pubmed
Figure 3:	Loss payout curve for datasets with the GCN 4 layers architecture in semi-supervised
learning. Comparaison between the original methode, DropEdge (DE) and RankedDrop (RD).
supervised learning. We can observe that for all three datasets the best accuracies are all from
RankedDrop. Moreover, the best accuracy obtained by RankedDrop preserve more edges than the
best one by DropEdge. For example, for the Citeseer dataset, the best accuracy subgraphs by DropE-
dge using 20% edges of the original graph, whereas the best accuracy subgraphs by RankedDrop
maintain 60% of the edges. We believe the fewer edges was dropped, the more information of the
original graph is kept, and we have more chance to achieve a better accuracy.
(a) Cora
(b) Citeseer
(c) Pubmed
Figure 4:	Graphical representation of accuracy results for DropEdge and RankedDrop methods
according to the percentage of preserved edges each datasets.
3.5 Overall performance results
3.5.1	Semi-supervised
Table 2: Accuracy comparaison for full-supervised learning methods for GCN architecure
Dataset	Method	2 Layers	4 Layers	8 Layers
B J O O	Original	-8∏0^^	78.5	-^3∏0-
	DroPEdge	82.80	78.8	53.1
	RankedDroP	82.90	82.00	63.90
Citeseer	Original	-70.80^^	61.2	^^30:20-
	DroPEdge	72.30	68.8	33.20
	RankedDrop	73.20	71.30	45.50
Pubmed	Original	-7900^^	78.30	-^6120-
	DropEdge	79.60	77.7	54.50
	RankedDrop	79.90	79.40	77.1
7
Under review as a conference paper at ICLR 2022
We first compare the accuracy between original GCN, GCN with DropEdge and GCN with Ranked-
Drop in the semi-supervised learning, with 2, 4 and 8 layers (Table 2). The hyper-parameters for
2 layers are from the paper of DropEdge, and the one for 4 and 8 layers are the best one that we
found. The parameters used for the selection of the nodes with RankedDrop are available in the ap-
pendix A. The accuracies obtained with RankedDrop are all higher than with DropEdge. Moreover,
the deeper the GCN is, the better accuracy improvement RankedDrop offers comparing to DropE-
dge. The accuracy obtained with RankedDrop for the 8-layer GCN is 20% better than the one with
DropEdge. Even for the 2-layer GCN, the accuracies of RankedDrop are equivalent or superior to
those well-tuned by DropEdge. This is particularly true with the Citeseer dataset where the 2-layer
GCN with RankedDrop obtained 1% higher accuracy than with DropEdge.
3.5.2	Full-supervised
Table 3: Accuracy comparaison for full-supervised learning methods
Dataset	Type	Original method	DropEdge	RankedDrop
E J O U	4GCN	85:50	85.70	87:60
	8 IncepGCN	86.70	87.70	87.90
	16JKNet	86.20	87.30	88.40
Citeseer	-4GCN-	7670	79.20	79:90
	8 IncepGCN	79.20	80.5	80.30
	8JKNet	79.60	80.20	79.8
Pubmed	-4GCN-	8870	90.5	9070
	4 IncepGCN	89.90	91.10	91.80
	16JKNet	90.40	91.40	88.30
The accuracies of full-supervised learning are presented in the table 3. For each of the datasets,
we evaluated with three different backbones: GCN, IncepGCN and JKNet. The number of layers
for each backbone was chosen from the best accuracy declared by DropEdge. We used the same
hyper-parameters given by Rong et al. (2019), only the edge dropping percentage is modified for
RankedDrop. The accuracies are globally equivalent between RankedDrop and DropEdge; and
RankedDrop achieved better accuracies than DropEdge for Cora the smallest dataset. It again show
that RankedDrop reduce better the over-fitting phenomenon. Moreover, the hyper-parameters used
here are not specifically adapted to RankedDrop, but RankedDrop can still achieve good accuracies.
We believe there are still space to increase accuracies with RankedDrop by optimizing the hyper-
parameters.
4 Conclusion & perspective
The RankedDrop method that we proposed in this paper provided more control on the selection
of dropping edges and allows to customize the dropping step for various neural network architec-
tures. Thanks to a personalized score system and the addition of several parameters, the control of
the edges to drop is personalized. RankedDrop keeps the advantages of DropEdge concerning the
reduction of over-smoothing and over-fitting as well as the possibility to use it on different architec-
tures, while allowing to take into account information on the graph structure. RankedDrop add more
control on randomness and a new degree of freedom for dropping selection. We have shown that
the results given by RankedDrop are very encouraging and are more stable. The degree of freedom
brought by taking into account the structure of the graph allows to project the construction of deeper
GNNs.
It is also possible to imagine using this method to better control the training of neural networks on
denser graphs. The computations that are performed to extract the data from the graph representation
matrix can be executed in distributed computing. The choice of edges to drop at each epoch is more
complex to do in distributed computing and will be the subject of future work.
8
Under review as a conference paper at ICLR 2022
References
Alekh Agarwal and Soumen Chakrabarti. Learning random walks to rank nodes in graphs. In
Proceedings ofthe 24th international conference on Machine learning, pp. 9-16, 2007.
Guy E Blelloch. Vector models for data-parallel computing, volume 2. MIT press Cambridge, 1990.
Aleksandar Bojchevski, Johannes Klicpera, Bryan Perozzi, Martin Blais, Amol Kapoor, Michal
Lukasik, and StePhan Gunnemann. Is pagerank all you need for scalable graph neural networks?
In ACM KDD, MLG Workshop, 2019.
Richard L Burden and J Douglas Faires. 2.1 the bisection algorithm. Numerical analysis, pp. 46-52,
1985.
Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, and Xu Sun. Measuring and relieving the over-
smoothing problem for graph neural networks from the topological view. In AAAI, pp. 3438-3445,
2020.
Marc Claesen and Bart De Moor. Hyperparameter search in machine learning. In Proc. of the 11th
Metaheuristics International Conference, pp. 1-5, 2015.
Michael Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on
graphs with fast localized spectral filtering. Advances in neural information processing systems,
29:3844-3852, 2016.
David Eppstein, Zvi Galil, Giuseppe F Italiano, and Amnon Nissenzweig. Sparsification—a tech-
nique for speeding up dynamic graph algorithms. Journal of the ACM (JACM), 44(5):669-696,
1997.
Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs.
In Advances in neural information processing systems, pp. 1024-1034, 2017.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R Salakhutdi-
nov. Improving neural networks by preventing co-adaptation of feature detectors. NIPS 2012
Workshop: Perturbations, Optimization, and Statistics, 2012.
ZHAO Huan, YAO Quanming, and TU Weiwei. Search to aggregate neighborhood for graph neural
network. In 2021 IEEE 37th International Conference on Data Engineering (ICDE), pp. 552-563.
IEEE, 2021.
Maxime R Hugues and Serge G Petiton. Sparse matrix formats evaluation and optimization on a
gpu. In 2010 IEEE 12th International Conference on High Performance Computing and Commu-
nications (HPCC), pp. 122-129. IEEE, 2010.
Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional net-
works. Proceedings of the 5th International Conference on Learning Representations, 2017.
Donald Knuth. Sorting and searching. The art of computer programming, 3:513, 1998.
Qimai Li, Zhichao Han, and Xiao-Ming Wu. Deeper insights into graph convolutional networks for
semi-supervised learning. In Thirty-Second AAAI conference on artificial intelligence, 2018.
Max O Lorenz. Methods of measuring the concentration of wealth. Publications of the American
statistical association, 9(70):209-219, 1905.
Laszlo Lovasz. Random walks on graphs. Combinatorics, Paul erdos is eighty, 2(1-46):4, 1993.
Dongsheng Luo, Wei Cheng, Wenchao Yu, Bo Zong, Jingchao Ni, Haifeng Chen, and Xiang Zhang.
Learning to drop: Robust graph neural network via topological denoising. In Proceedings of the
14th ACM International Conference on Web Search and Data Mining, pp. 779-787, 2021.
9
Under review as a conference paper at ICLR 2022
Mark EJ Newman. The structure and function of complex networks. SIAM review, 45(2):167-256,
2003.
Kenta Oono and Taiji Suzuki. On asymptotic behaviors of graph cnns from dynamical systems
perspective. 2019.
Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. The pagerank citation ranking:
Bringing order to the web. Technical report, Stanford InfoLab, 1999.
Yulong Pei, Tianjin Huang, Werner van Ipenburg, and Mykola Pechenizkiy. Resgcn: attention-
based deep residual modeling for anomaly detection on attributed networks. Machine Learning,
pp.1-23,2021.
Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, and Jascha Sohl-Dickstein. On the ex-
pressive power of deep neural networks. In international conference on machine learning, pp.
2847-2854. PMLR, 2017.
Yu Rong, Wenbing Huang, Tingyang Xu, and Junzhou Huang. Dropedge: Towards deep graph
convolutional networks on node classification. In International Conference on Learning Repre-
sentations, 2019.
Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad.
Collective classification in network data. AI magazine, 29(3):93-93, 2008.
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.
Dropout: a simple way to prevent neural networks from overfitting. The journal of machine
learning research,15(1):1929-1958, 2014.
Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie
Jegelka. Representation learning on graphs with jumping knowledge networks. In International
Conference on Machine Learning, pp. 5453-5462. PMLR, 2018.
A Appendix: Hyperparameters in experiments
In the table 4 are gathered the parameters used to generate the accuracys that have been presented in
the paper. There are both the hyperparameters of the models that are used for the execution of the
backbones, and also the few parameters that we used to control the selection of the edges to drop. We
have implemented three ways to take into account the information from the structure of the graph.
This is the parameter which is named score. Either we have used only the degree information or
the PageRank information, which is respectively indicated by Deg and PR, or we have used both at
the same time to build the score vector and it is noted PRxD. In addition to this parameter, we have
influenced the choice of edges to remove from the graph with the following parameters:
•	dd: It is a boolean that removes the edge in the opposite direction of the selected edge
when the dataset is symmetric. Vertices are removed in pairs, and this allows to keep a
undirected graph.
•	reverse: It is a boolean that allows to reverse the adjacency matrix. By doing this, each
edge is no longer associated with the tail node but with the head node, and if the scores
of the two nodes associated with that edge are not the same, it changes the probability of
selecting that particular edge.
•	lowest: It is a boolean that reverses the ranking of the nodes of the graph using the
reciprocal of the score associated to each node.
10
UnderreVieW as a ConferenCe PaPersICLR 2022
Ref	Backbone	Dataset	nlayers	Hyper-parameters
Table 2	GCN	Cora	2	lr:θ,θθl, weight-decay:le-4, sampling-percent:0.7, SCOre:PRXD, dd:false, reverse:true, lowest:true, niter:400
Table 2	GCN	Citeseer	2	lr:0.007, weight-decay: le-4, sampling-percent:0.6, score:PR, dd:false, reverse:false, lowest:true, niter:400
Table 2	GCN	Pubmed	2	lr:0.009, weight-decay: le-2, SamPIiIIg-PerCeiIt:0.8, score:PR, dd:true, reverse:false, lowest:true, niter:400
Table 2	GCN	Cora	4	lr:0.004, weight-decay: le-4, sampling -percent: 0.3, SCOre:PRXD, dd:false, reverse:true, lowest:true, niter :400
Table 2	GCN	Citeseer	4	lr:0.008, weight-decay: le-3, sampling-percent: 0.1, seore:ɔeg, dd:false, reverse:true, lowest:false, niter:400
Table 2	GCN	Pubmed	4	lr:0.008, weight-decay: le-2, SamPIiIIg-PerCeiIt:0.9, seore:ɔeg, dd:false, reverse:true, lowest:false, niter:400
Table 2	GCN	Cora	8	lr:0.003, weight-decay: le-5, sampling-percent:0.7, score:PR, dd:true, reverse:true, lowest:false, niter: 1000
Table 2	GCN	Citeseer	8	lr:θ,θθl, weight-decay: le-5, sampling -percent: 0.5, SCOre:PRXD, dd:false, reverse:true, lowest:false, niter: 1000
Table 2	GCN	Pubmed	8	lr:0.006, weight-decay: le-4, sampling -percent: 0.5, SCOre:PRXD, dd:true, reverse:true, lowest:true, niter: 1000
Table 3	GCN	Cora	4	lr:θ,θl, weight-decay:0.005, sampling-pereent:θ,ð, seore:ɔeg, dd:true, reverse:true, lowest:true, niter:400
Table 3	GCN	Citeseer	4	lr:0.009, weight-decay: le-3, sampling-percent: 0.1, seore:ɔeg, dd:true, reverse: true, lowest: false, niter:400
Table 3	GCN	Pubmed	4	lr:θ,θl, weight-decay: 1 e-3, SamPIiIIg-PerCeiIt:0.2, score:PRxD, dd:true, reverse:true, lowest:false, niter:400
Table 3	IncepGCN	Cora	8	lr:θ,θl, weight-decay: 1 e-3, sampling-pereent:θ. 1, score:PR, dd:true, reverse:false, lowest:true, niter:400
Table 3	IncepGCN	Citeseer	8	lr:0.002, Weight-decay:。.005, sampling-percent: 0.1, score: Deg, dd:true, reverse:true, lowest:false, niter :400
Table 3	IncepGCN	Pubmed	4	lr:0.002, weight-decay: le-5, sampling -percent: 0.3, SCOre:PRXD, dd:false, reverse:true, lowest:true, niter :400
Table 3	-JKNet-	Cora	-16-	lr:0.008, weight-decay: 5e-4, sampling-percent: 0.1, score:PR, dd:true, reverse:true, lowest:true, niter:400
Table 3	JKNet	Citeseer	8	lr:0.004, weight-decay:5e-5, SamPIiIIg-PerCeiIt:0.8, score:PR, dd:true, reverse:true, lowest:true, niter:400
Table 3	JKNet	Pubmed	64	lr:0.005, weight-decay: le-4, SamPIiIIg-PerCeiIt:0.9, seore:ɔeg, dd:false, reverse:false, lowest:false, niter:400
Table 4: Hyper-parameters used to obtain the accuracy presented in this paper with the RankedDrop method.