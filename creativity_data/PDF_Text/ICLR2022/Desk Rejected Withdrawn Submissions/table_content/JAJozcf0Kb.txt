Table 1: Quantitative comparison on CUB bird: Frechet inception distance (FID) and R-Precision(R-psr) of StackGAN++ (Zhang et al., 2018), AttnGAN (Xu et al., 2018), ControlGAN (Li et al.,2019a), DM-GAN (Zhu et al., 2019), DF-GAN(Tao et al., 2020), and our method. For FID, lower isbetter, while for R-precision, alignment, and realism, higher is better.
Table 2: Quantitative comparison on COCO. Note that we also compare our method with OP-GAN (Hinz et al., 2019), where OP-GAN adopts bounding box in their method.
Table 3: Ablation studies: “Ours w/o Feature” de-notes without feeding image features into the gen-erator, “Ours w/o Disen.” denotes without usingthe fully connected layers to disentangle imagefeatures v, “Ours w/o Disen.*” is for mismatchedpairs, “Ours w/o Content” denotes without incor-porating the content information into the discrimi-nator, “Ours w/o Reg.” denotes without using theregularization in the discriminator, “Ours w/ Max”denotes using the maximum pooling to extractcontent information, and “Ours w/ Aver” denotesusing the average pooling.
Table 4: Quantitative comparison between different matching algorithms on CUB. Sent. representssentence, and ReW represents we reweighting word embeddings and (or) image features based onimportance. For FID, lower is better, while for R-precision, higher is better.
Table 5: Quantitative comparison between different matching algorithms on COCO. For FID, lower is better, while for R-precision, higher is better.		Matrix Sent. & Sent. Sent. & Image Word & Word Word & Word & ReW	Word & Image	Word & Image & ReWFID	20.87	20.76	19.98	20.03	20.12	19.47R-psr	86.76	86.34	89.02	89.23	88.98	90.32Here, we show the quantitative comparison between different matching algorithms, shown in Tables 4and 5. As we can see, the algorithm word image matching with reweighting based on importanceachieves the best FID and R-psr scores on CUB and COCO datasets. Therefore, the algorithm wordimage matching with reweighting is adopted in our method.
Table 6: Quantitative comparison: Structural Similarity Index (SSIM) of StackGAN++ (Zhang et al.,2018), AttnGAN (Xu et al., 2018), ControlGAN (Li et al., 2019a), DM-GAN (Zhu et al., 2019), andour method on the CUB and COCO datasets. For SSIM, higher means synthetic and ground-truthimages are more similar, which indicates that there may exist a copy-and-paste problem and thenetwork has a worse diversity.
Table 7: Quantitative comparison: Frechet inception distance (FID) and R-Precision (R-Psr) ofStackGAN++ (Zhang et al., 2018), AttnGAN (Xu et al., 2018), ControlGAN (Li et al., 2019a),DM-GAN (Zhu et al., 2019), OP-GAN (Hinz et al., 2019), and our method on the COCO dataset.
