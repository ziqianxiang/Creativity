Table 1: Comparison of the first set of algorithms in Section 3. we separate the pre-computation of the multinomialkernel function from the main loop and also estimate the training set inner products instead of computing themexactly, which can improve the time complexity of the computation of the kernel function. For all algorithms, weindicate the general result without using the learning setting in Definition 8. For ALPHATRON_with_Approx_Preand ALPHATRON_with_Q_Pre, the relevant kernel functions are estimated to accuracy EK with failure probabilityδκ. To obtain the weak p-concept learning result of Theorem 1 for all these algorithms, take the concept class definedin Definition 8 and the parameter settings for the algorithms of Definition 9. Also, set EK = L√e∕T and δκ = δ. Wedo not further evaluate the formulas (using, e.g., the expressions for T and m1) as the main focus of this table is onthe dependency on n which dominates all other parameters.
Table 2: Comparison of the second set of algorithms Atron_with_Kernel_and_Sampling and Quan-tum_Alphatron, which are discussed in Section 4, to ALPHATRON_with_Kernel. These algorithms change themain loop part by using an inner product estimation. The inner product estimation is performed to accuracy EI andthe total success probability of the algorithm is 1 - δ. Here, we indicate the general result without the learning settingin Definition 8.
Table 3: Comparison of the algorithms ALPHATron_with_Kernel and QUANTUM_Alphatron for the learningsetting in Definition 8. Only in the first case a quantum advantage is obtained.
