Table 1: Illustrative table of interventions, or-dered by the percent of time that they wereinvolved in a high magnitude δ intervention.
Table 2: Results for MLM and Random asset in-tervention strategies, ordered by the percent oftimes that they were involved in a high magni-tude δ random event. While the top three are thesame, Random flubbed the dividing line by plac-ing a) Cybertruck above Kawasaki and b) CarlaCola well ahead of both. Its failure rate for theeasy cars was much higher and, in general, posited3% more failures than MLM. All told, its resultsthe differences between Random and MLM be-cause these interventions are continuous forcreated more need for human verification and test-ing and reduced the degree of automation that wecould employ to find hard groups.
Table 3: Table of notationA.2 Dataset detailsCARLA refuses to spawn agents that collide with the environment, including the ground. To ensureagents are grounded, for any asset that causes a spawn collision, we increase its Z coordinate andtry to spawn again . This approach allows us to place every agent on the map, albeit some of theconflicting agents have to ‘drop’ from above, and consequently we wait for 50 timesteps so thoseagents can settle. In that duration, the autopilot policy guides the agents to satisfactory positions.
