Table 1: Detailed data statistics on three benchmark datasets. Ntrain and Ntest refer to the numberof examples in the training and test sets. L is the number of distinct labels within the datasets. Llpsand Lspl refers to the average number of labels per sample and the average number of samples perlabel respectively. |D| refers to the average number of tokens within the datasets.
Table 2: Performance comparison TailMix between other competitive XMC methods. *, f indicatethe results reported in XMC repository (Bhatia et al., 2016) and its publication, respectively. âˆ£ ismarked as ensemble of baseline and a model trained with TailMix.
Table 3: Performance comparison on EURLex-4K, Wiki10-31K, and AmazonCat-13K dataset withdifferent Mixup methods. Each Mixup methods are applied on two different model architectures:AttentionXML (You et al., 2019) and LaRoBERTa (Zhang et al., 2020).
Table 4: Results of different sample selection strategies running on AttentionXML. Sim, LPG referto the "similarity" and "label proximity graph" module, respectively. "-" means that the module isomitted, and "+" refers that the following module was used in the model.
