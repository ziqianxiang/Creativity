Table 1: Layers selection results	1st Layer	2nd Layer	3rd Layer	4th Layer	1+2+3	1,2,3Textures classes	0.7606	0.881	0.9486	0.8376	0.9438	0.9614	0.711	0.8588	0.9304	0.7968	0.9122	0.9428Objects classes	0.7534	0.811	0.9134	0.9204	0.8562	0.9126	0.717	0.8912	0.9716	0.9572	0.9538	0.9772Total	0.757	0.846	0.931	0.879	0.900	0.937	0.714	0.875	0.951	0.877	0.933	0.960have been resized to (256, 256) and center-cropped to (224, 224), as performed in Defard et al.
Table 2: Architectures selection results	RN-18	WRN-50	EN-B5 26	EN-B6 30	EN-B7 37Textures classes	0.9486	0.9798^^	0.9854	0.9922	0.9888	0.9304	0.9554	0.943	0.949	0.9576Objects classes	0.9134	0.9342^^	0.9206	0.9198	0.9432	0.9716	0.9726	0.947	0.955	0.9404Total	0.931	0.957	0.953	0.956	0.966	0.951	0.964	0.945	0.952	0.9492019), (Sandler et al., 2018). As said before, they all have the same spatial dimensions while slightlydifferent channels numbers (176, 200, 220). The main difference is the layers’ depth and the subse-quent different representation power of the architectures.
Table 5: Comparison with related methods over BeanTech Anomaly Detection Dataset	AE MSE+SSIM VT-ADL PatchCore PaDiM PSDL EN-B6 (Ours)Total 0.79	0.90	0.97	0.98	0.97the-art performance, even if being sub-optimal with respect to the best methods: PaDiM e PatchCore.
Table 6:	Comparison with related methods over Magnetic Tile Defects DatasetPaDiM	DifferNet	PatchCore	PSDL	EN-B6 (ours) PSDL	EN-B7 (ours)0.872	0.977	0.979	0.979	0.988Table 7:	Comparison with related methods over Kolektor Surface Defect DatasetPaDiM	PatchCore	PSDL EN-B7 (ours)T 1 ^^0.863	0.961	0.963Total 0.963	0.815	0.981our implementation, with Wide-ResNet-50 as backbone network. The results shown confirm thestrength of our approach, able to overcome the state-of-the-art performance in terms of AUC-ROC.
Table 7:	Comparison with related methods over Kolektor Surface Defect DatasetPaDiM	PatchCore	PSDL EN-B7 (ours)T 1 ^^0.863	0.961	0.963Total 0.963	0.815	0.981our implementation, with Wide-ResNet-50 as backbone network. The results shown confirm thestrength of our approach, able to overcome the state-of-the-art performance in terms of AUC-ROC.
Table 8: Dictionary selection results	DCT No-Learning	DCT	Haar	RandomTextures classes	0.6742	0.9486	0.9568	0.947	0.527	0.9304	0.9326	0.9278Objects classes	0.4978	0.9134	0.9092	0.921	0.551	0.9716	0.9674	0.9642Total	0.586	0.931	0.933	0.934	0.539	0.951	0.950	0.946Table 9: Iterations selection results	10 iterations	20 iterations	50 iterationsTextures classes	0.9512	0.9486	0.9472	0.929	0.9304	0.9342Objects classes	0.9128	0.9134	0.9088	0.965	0.9716	0.9678Total	0.932	0.931	0.928	0.947	0.951	0.951We have tested the pipeline with 10, 20, and 50 as iteration numbers and reported results in Tab. 9.
Table 9: Iterations selection results	10 iterations	20 iterations	50 iterationsTextures classes	0.9512	0.9486	0.9472	0.929	0.9304	0.9342Objects classes	0.9128	0.9134	0.9088	0.965	0.9716	0.9678Total	0.932	0.931	0.928	0.947	0.951	0.951We have tested the pipeline with 10, 20, and 50 as iteration numbers and reported results in Tab. 9.
Table 10: Sparsity level selection results	64	128	192Textures classes	0.9486^^0.892^^0.6846 0.9304 0.8662 0.4952Objects classes	0.9134^^0.836^^0.6094 0.9716 0.9258 0.7168Total	0.931	0.864~~0.647 0.951	0.896	0.60615Under review as a conference paper at ICLR 2022JeUJ山 uolunɪjMUOU 也出qj6ej0j><0.30-0.25 -0.20-0.15 -0.10 -0.05 -0.00-Spatial Location IndexFigure 4: The graph shows the average reconstruction error for each spatial location of the activationmap, over the training dataset. The increased sparsity level is causing a higher reconstruction error.
