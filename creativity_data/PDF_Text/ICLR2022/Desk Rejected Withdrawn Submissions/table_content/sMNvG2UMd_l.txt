Table 1: Anomaly detection performance (mean ROC-AUC %, ours is averaged over five runs)Dataset	Self-supervised				Pre-trained		DeepSVDD	MHRot	DROC	CSI	PANDA	OursCIFAR-10	64.8	90.1	92.5	94.3	96.2	97.2±0.1CIFAR-100	67.0	80.1	86.5	89.6	94.1	96.4±0.1CatsVsDogs	50.5	86.0	89.6	86.3	97.3	99.3±0.0(Krizhevsky et al., 2009), and CatsVsDogs (Elson et al., 2007). Following standard protocol, multi-class dataset are converted to anomaly detection by setting a class as normal and all other classesas anomalies. This is performed for all classes, in practice turning a single dataset with C classesinto C datasets. Full dataset descriptions are in Appendix A.1.1 We compare our approach with thetop current self-supervised and pre-trained feature adaptation methods (Ruff et al., 2018; Hendryckset al., 2019; Tack et al., 2020; Sohn et al., 2020; Reiss et al., 2021). Results that were reported in theoriginal papers were copied. When the results were not reported, we ran the experiments ourselves.
Table 2: Anomaly detection accuracy (mean ROC-AUC %) on small dataset. Self-supervised methodsfail while adapting pre-trained features achieves strong results. Bold denotes the best results.
Table 3: Training objective ablation study (CIFAR-10, mean ROC-AUC %).
Table 4: Multi-Modal Anomaly detection accuracy (mean ROC-AUC %).
Table 5: CIFAR-10 Anomaly detection accuracy with K-means (mean ROC-AUC %)k=1	k=5	k =10	k = 100	Full train set94.2	95.8	96.1	97.0	97.26	ConclusionWe presented a novel feature adaptation approach for deep anomaly detection. First, we conducteda thorough analysis of the standard contrastive loss and showed that it poorly initialized for OCCfeature adaptation. Second, we introduced an alternative objective, the Mean-Shifted ContrastiveLoss, that overcomes the limitations of the standard contrastive loss. Finally, we performed extensiveexperiments demonstrating that our method achieves the top anomaly detection performance.
Table 6: CIFAR-10 anomaly detection performance (mean ROC-AUC %). Bold denotes the bestresults. ________________________________________________________________	DeepSVDD	MHRot	DROC	CSI	PANDA	Ours0	61.7	77.5	90.9	89.9	97.4	97.01	65.9	96.9	98.9	99.1	98.4	98.72	50.8	87.3	88.1	93.1	93.9	94.83	59.1	80.9	83.1	86.4	90.6	94.34	60.9	92.7	89.9	93.9	97.5	96.95	65.7	90.2	90.3	93.2	94.4	97.26	67.7	90.9	93.5	95.1	97.5	98.27	67.3	96.5	98.2	98.7	97.5	98.38	75.9	95.2	96.5	97.9	97.6	98.59	73.1	93.3	95.2	95.5	97.4	98.3Mean	64.8	90.1	92.5	94.3	96.2	97.2Table 7: CIFAR-100 coarse-grained version anomaly detection performance (mean ROC-AUC %).
Table 7: CIFAR-100 coarse-grained version anomaly detection performance (mean ROC-AUC %).
Table 8: CatsVsDogs anomaly detection performance (mean ROC-AUC %). Bold denotes the bestresults. _________________________________________________________________	DeepSVDD	MHRot	DROC	CSI	PANDA	OursCat	49.2	87.7	91.7	85.7	99.2	99.4Dog	51.8	84.2	87.5	86.9	95.4	99.2Mean	50.5	86.0	89.6	86.3	97.3	99.313Under review as a conference paper at ICLR 2022u∩vuoH ⊂s≥EpochFigure 6: CIFAR-10 Mean ROC-AUC %. Catastrophic collapse of various objective functions.
