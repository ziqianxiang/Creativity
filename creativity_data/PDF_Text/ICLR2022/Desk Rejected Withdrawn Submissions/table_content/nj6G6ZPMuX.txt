Table 1: Test average and worst accuracy results on Colored-MNIST, 3dShapes and MPI3D. Bold,Black: best resultModels	Colored-MNIST Avg Acc Worst Acc		3dShapes Avg Acc Worst Acc		MPI3D Avg Acc Worst Acc	Baseline	0.9512	0.6617	0.9887	0.9689	0.9012	0.8789β-VAE	0.9265	0.5879	0.9866	0.9577	0.8698	0.8489VFAE	0.9312	0.6554	0.9772	0.9334	0.8669	0.8243CAI	0.9356	0.6317	0.9762	0.9432	0.8663	0.8216CVIB	0.9331	0.7012	0.9711	0.9446	0.8704	0.8561UAI	0.9474	0.7425	0.9713	0.9521	0.8789	0.8301Our model	0.9796	0.9043	0.9852	0.9763	0.9132	0.8917Since our method aims at achieving both disentanglement and invariance at the same time, we cate-gorize the baseline state-of-the-art models into two groups according their goals.
Table 2: Test average accuracy and worst accuracy results on Rotation-Colored-MNIST with differ-ent rotation angles. Bold, Black: best resultModels	Avg Acc	Worst Acc -75	Avg Acc	Rotation-Colored-MNIST			Avg Acc Worst Acc +75					Worst Acc -65	Avg Acc Worst Acc +65			Baseline	0.770	0.623	0.897	0.775	0.858	0.658	0.683	0.499β-VAE	0.771	0.612	0.852	0.750	0.834	0.630	0.687	0.472VFAE	0.722	0.589	0.858	0.744	0.841	0.646	0.717	0.48CAI	0.749	0.593	0.865	0.773	0.842	0.678	0.647	0.429CVIB	0.761	0.592	0.886	0.791	0.856	0.688	0.722	0.534UAI	0.780	0.611	0.888	0.800	0.854	0.682	0.702	0.511Our model	0.810	0.753	0.908	0.857	0.873	0.823	0.732	0.633•	Representation Disentanglement: The following state-of-the-art model are used to com-pare performance of disentangled representation — (1) β-VAE (Higgins et al., 2017), (2)AnnealedVAE (Burgess et al., 2018), (3) FactorVAE (Kim & Mnih, 2018), (4) DIP-VAE-I (Kumar et al., 2018), (5) DIP-VAE-II (Kumar et al., 2018), (6) β-TCVAE (Chen et al.,2019) and (7) Ada-VAE (Locatello et al., 2020a).
Table 3: Disentanglement metrics on 3dShapes and MPI3D. Bold, Black: best resultModels	MIG	SAP	3dShapes IRS	FVAE	DCI	MIG	SAP	MPI3D IRS	FVAE	DCIUnsupervised Disentanglement Leanring										β-VAE	0.194	0.063	0.473	0.847	0.246	0.135	0.071	0.579	0.369	0.317AnnealedVAE	0.233	0.087	0.545	0.864	0.341	0.098	0.038	0.490	0.397	0.228FactorVAE	0.224	0.0440	0.630	0.792	0.304	0.092	0.031	0.529	0.379	0.164DIP-VAE-I	0.143	0.026	0.491	0.761	0.137	0.104	0.073	0.476	0.491	0.223DIP-VAE-II	0.137	0.020	0.424	0.742	0.083	0.131	0.075	0.509	0.544	0.244β-TCVAE	0.364	0.096	0.594	0.970	0.601	0.189	0.146	0.636	0.430	0.322β-FactorTCVAE	0.071	0.021	0.496	0.612	0.131	0.066	0.034	0.493	0.464	0.217Weakly-Supervised Disentanglement Learning										Ada-ML-VAE	0.509	0.127	0.620	0.996	0.940	0.240	0.074	0.576	0.476	0.285Ada-GVAE	0.569	0.150	0.708	0.996	0.946	0.269	0.215	0.604	0.589	0.401Our model	0.716	0.156	0.784	0.996	0.919	0.486	0.225	0.615	0.565	0.5604.3	Ablation StudyEffectiveness of training strategies in disentanglement learning: To prove the effectiveness ofthe training strategies illustrated in Figure 4, we compare results of three situations: (1) none ofthose strategies is used, (2) only warmup by amount strategy is used, and (3) both strategies areused. As shown in Table 4, using both training strategies clearly outperforms the others.
Table 4: Disentanglement metrics of with different training strategies applied to 3dShapeswarmup by amount	warmup by difficulty	MIG	SAP	IRS	FVAE	DCI		0.492	0.096	0.661	0.902	0.697X		0.512	0.126	0.674	0.944	0.781X	X	0.716	0.156	0.784	0.996	0.919Table 5: Performance of different scheme on Colored-MNIST and Rotation-Colored-MNISTTraining Scheme	Colored-MNIST		Rotation-Colored-MNIST (65)		avg acc	worst acc	avg acc	worst accLCE	0.932	^^0.680	0.821	0.653LCE + Lcontrastive	0.935	0.732	0.842	0.678LCE K~→ Lcontrastive	0.980	0.904	0.873	0.8235	ConclusionIn this work, we extend the ideas of representation disentanglement and representation invarianceby combining them to achieve both goals at the same time. Further, we propose a new frameworkfor weakly supervised disentanglement representation learning and achieve better performance thanstate-of-the-art disentangled learning methods. By introducing contrastive loss and new invariantregularization loss, we make predictive factor zp to be more invariant to nuisance and increase bothaverage and worst accuracy on invariant learning tasks.
Table 5: Performance of different scheme on Colored-MNIST and Rotation-Colored-MNISTTraining Scheme	Colored-MNIST		Rotation-Colored-MNIST (65)		avg acc	worst acc	avg acc	worst accLCE	0.932	^^0.680	0.821	0.653LCE + Lcontrastive	0.935	0.732	0.842	0.678LCE K~→ Lcontrastive	0.980	0.904	0.873	0.8235	ConclusionIn this work, we extend the ideas of representation disentanglement and representation invarianceby combining them to achieve both goals at the same time. Further, we propose a new frameworkfor weakly supervised disentanglement representation learning and achieve better performance thanstate-of-the-art disentangled learning methods. By introducing contrastive loss and new invariantregularization loss, we make predictive factor zp to be more invariant to nuisance and increase bothaverage and worst accuracy on invariant learning tasks.
