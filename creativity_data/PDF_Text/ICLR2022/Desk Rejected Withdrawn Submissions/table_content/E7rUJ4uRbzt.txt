Table 1: Different tasks used to evaluate EIL. Each task also has its specific extraneousness actionsin the imperfect demo dataset, designed to reflect deviations in real-world scenarios.
Table 2: Success rate of different tasks.
Table 3: Average and standard deviation of minimum distances for different tasksTask	Oracle	EIL (Ours)	Behavior Cloning	TCNReach	0.0638 ± 0.0446	0.0684 ± 0.0543	0.0874 ± 0.0722	0.1327 ± 0.0990Push	0.0491 ± 0.0682	0.0786 ± 0.0865	0.1023 ± 0.0797	-Stir	5.5282 ± 4.7377	12.78 ± 7.46	31.61 ± 50.13	-Table 4: Success rate of different tasks without reference demonstration.
Table 4: Success rate of different tasks without reference demonstration.
Table 5: Ablation results on camera set-tings. Lower is better.
Table 6: Hyperparameters in representation learning.		Table 7: alignment.	Extraneous	Frame	Fraction	forHyperparameters for unsupervised voting-based alignment (UVA). We also ablate importanthyperparameters for of the alignment algorithms UVA. In table 7, we find that “tolerance” will in-fluence the resulted virtual embedding length. In practice, we found that UVA sometimes tends toselect towards the end of videos too soon. To overcome this shortcoming, we choose from the kth(tolerance) nearest neighbors to virtual reference, instead of one. We choose next alignment framewith smallest frame index among them. We choose 2 as the hyperparameter which best balancesperformance and chosen frames. We note there are some design choices of how to calculate the vir-tual embedding, such as using median instead of mean, or using weighted average proportion to thevotes each frame get. However, we find these variations don’t outperform vanilla mean significantly.
Table 8: Hyperparameters for Representation LearningHyperparameters	ValueBatch Size	4Frame Stride	3Optimizer	ADAMLearning Rate	1e-4Weight Decay	1e-3Frames per second	30Table 9: Hyperparameters for imitation learningHyperparameters ValueBatch Size	10Optimizer	ADAMLearning Rate	3e-4Weight Decay	0Data augmentation We use data augmentation during training imitation learning. For each image,we resize it to a 224 × 224 image.
Table 9: Hyperparameters for imitation learningHyperparameters ValueBatch Size	10Optimizer	ADAMLearning Rate	3e-4Weight Decay	0Data augmentation We use data augmentation during training imitation learning. For each image,we resize it to a 224 × 224 image.
