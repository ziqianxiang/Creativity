Table 1: Triple-input CNN precisionType	precision (%)	recall (%)	f1-score (%)	supportExc	98.78	2 Class Validation Set 98.78	98.78	490Inh	98.52	98.52	98.52	406weighted avg	98.66	98.66	98.66	896Exc	97.28	2 Class Test Set 99.51	98.38	611Inh	99.42	96.80	98.10	532weighted avg	98.28	98.25	98.25	1143Exc	96.27	5 Class Validation Set 99.79	98.00	466Ndnf	84.62	95.65	89.80	46Pvalb	99.17	98.76	98.96	241Sst	88.24	87.21	87.72	86Vip	87.50	46.67	60.87	45weighted avg	95.23	95.36	94.94	884Exc	94.93	5 Class Test Set 98.76	96.80	644Ndnf	57.63	89.47	70.10	38Pvalb	93.08	93.08	93.08	260Sst	77.54	82.31	79.85	130Vip	70.59	16.67	26.97	72weighted avg	89.76	90.12	88.75	1144
Table 2: Transfer learning precisionType	3:7	5:5	8:2Exc	97.65	98.08	94.60Ndnf	96.59	89.43	90.00Pvalb	80.99	79.93	91.25Sst	71.76	72.26	84.13Vip	44.65	51.70	45.65weighted avg	86.87	87.46	89.226Published as a conference paper at ICLR 20225 Conclusion and Future WorkWe presented in this paper a solution to the neuron classification problem that avoids using imper-fect, non-standardized, and cumbersome electrophysiological classification schemes. In turn, theconstructed neural network maps the pool of neurons based on their activity into less ambiguousgenetic classification that is normally not widely accessible or practical in experimental pipelines.
