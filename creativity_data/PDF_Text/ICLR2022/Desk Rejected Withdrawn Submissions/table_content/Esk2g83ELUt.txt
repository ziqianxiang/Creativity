Table 1: ImageNet top-1 accuracy of different operator combinations. T and M refer to transformer				block and mlp-mixer block respectively. Different block numbers are used to keep them comparable.				In this paper, we search the combination of convolution, transformer, and MLP operators, tryingto assemble those operators to create novel and high-performance visual network architectures. Tothe best of our knowledge, we are the first to automatically search the assembly of all types ofoperators to form novel network architectures. As different operators have distinct characteristics, itis non-trivial to merge them into a super-net that can achieve superior performance.
Table 2: UniNet performance on ImageNet. All UniNet models are trained with ImageNet datasetwith 1.28m images. C, T, and H denotes convolution, transformer, and hybrid architecture respec-tively. âˆ£: all EficientNetV2 models are trained with progressive learning.
Table 3: UniNet-B0 architecture. GOP and DSMrepresent General Operators and down-samplingmodule respectively. DWConv and Transformerare are described in Section 3.2.
Table 4: Object detection, instance segmentation, and semantic segmentation performance on theCOCO val2017 and ADE20K val set. All UniNet models are pretrained on the ImageNet-1K dataset.
Table 5: Performance on ImageNet of UniNet with different search settings. Conv-Only representssearch UniNet with convolution operator only.
Table 6: Performance on ImageNet of UniNet with different DSMs. To note that, the result of traditional strided-conv based down-sampling				Table 7: Performance comparison on Ima- geNet of different backbones when equipped with our proposed DSMs.			module is shown in row 2.
