Table 1: Performance of different models on CIFAR-10 datasetModels	Parameters	Size (MB)	Top-1 Accuracy	Top-5 Accuracy	GPU (GB)ViT	0.53 M	209.39	57:39	94.98	14.1Hybrid ViN	0.61 M	88.38	75.26	98.39	5.0FNet	0.27 M	60.12	51.54	93.84	1.6MLP Mixer	8.53 M	90.59	60.33	95.79	1.4WaveMix	0.57 M	6.24	78.55	98.72	0.4Table 2: Performance of different WaveMix models on CIFAR-10 dataset				Models	Parameters	Size (MB)	Top-1 Accuracy	GPU (GB)WaveMix-16	0.16 M	309	75.74	0.2WaveMix-32	0.57 M	6.24	78.55	0.4WaveMix-64	2.3 M	16.86	83.63	0.7WaveMix-128	9.2 M	51.22	85.21	0.84	ResultsTable 1 shows the performance of 4-layer WaveMix compared to other 4-layer architectures forCIFAR-10 classification using supervised learning. We choose a WaveMix model having al-most the same number of parameters as ViT for a better comparison of performance. We cansee that WaveMix outperforms all other models, especially the ViT by 37% and Hybrid VisionNystromformer (ViN) by 4%. This shows that in the low data regime, WaveMix is a good alter-native to attention-based architectures. It performs 53% better than FNet since we use the wavelet
Table 2: Performance of different WaveMix models on CIFAR-10 dataset				Models	Parameters	Size (MB)	Top-1 Accuracy	GPU (GB)WaveMix-16	0.16 M	309	75.74	0.2WaveMix-32	0.57 M	6.24	78.55	0.4WaveMix-64	2.3 M	16.86	83.63	0.7WaveMix-128	9.2 M	51.22	85.21	0.84	ResultsTable 1 shows the performance of 4-layer WaveMix compared to other 4-layer architectures forCIFAR-10 classification using supervised learning. We choose a WaveMix model having al-most the same number of parameters as ViT for a better comparison of performance. We cansee that WaveMix outperforms all other models, especially the ViT by 37% and Hybrid VisionNystromformer (ViN) by 4%. This shows that in the low data regime, WaveMix is a good alter-native to attention-based architectures. It performs 53% better than FNet since we use the waveletinstead of the Fourier transform, where the former is better suited for multi-resolution modeling ofthe image data and does not need unrolling the images as a sequence of pixels.
Table 3: Performance of different models on Tiny ImageNet datasetModels	Parameters	Size (MB)	Top-1 Accuracy	GPU (GB)ViT	0.55 M	-^209.59^^	26.43	14.1WaveMix ConvStride-2	0.58 M	6.30	31.57	0.4WaveMix Top-4 DWT	0.58 M	6.30	31.90	0.4WaveMix All-5 DWT	1.1M	8.41	30.54	0.4The comparison of performance of the three approaches are shown in Table 3, where we used a4-layered WaveMix-32 to train on Tiny ImageNet. We see that removing the 2×2 resolution leveldoes not affect the performance, and also does not increase the model size. All 3 models consumedthe same amount of GPU RAM but the model which used all 5 levels of 2D DWT had almost twicethe number of parameters and used slightly more memory than the others. For tasks involving higherresolution images of sizes 256×256 or 512×512, we recommend using at least 6 level 2D DWT.
