Table 1: Test accuracy (%) of ResNet-18.
Table 2: TPR-95 accuracy (%) and ROC-AUC scores of the ResNet-18 models trained on CIFAR-10,evaluated by PGD-10 attacks. Here GDA* indicates using class-conditional covariance matrices.
Table 3: TPR-95 accuracy (%) under common corruptions in CIFAR-10-C. The model architectureis ResNet-18, and the reported accuracy under each corruption is averaged across five severity.
Table 4: TPR-95 accuracy (%) on CIFAR-10,under multi-target attack and GAMA attacks.
Table 5: Ablation studies on the effect of tem-perature τ for RR. Note that in the objectiveEq. (5), τ is only tuned in the term of LRR,while the temperature for LT is kept to be 1.
Table 6: Ablation studies on rectified construc-tion of R-Con in Eq. (3). Here 'fθ(x)[ym]' and'Aφ(χ)' indicate using confidence and auxiliaryfunction to substitute R-Con in LRR, respectively.
Table 7: Minimal perturbations required by successful evasions, searched by CW attacks. Here ‘Normal (Nor.)’ refers to fooling the classifier, and ‘Adaptive (Ada.)’ refers to adaptively fooling both the classifier and rejector.					Table 8: Classification accuracy (%) and ROC-AUC scores under PGD-1000 attacks, where the step size is 2/255 and the perturbation constraint is 8/255 under '∞ threat model.				Rej.	CIFAR-10		CIFAR-100							CW-'∞ Nor. Ada.	CW-'2 Nor. Ada.	CW-'∞ Nor. Ada.	CW-'2 Nor. Ada.	Rej.	CIFAR-10		CIFAR-100							TPR-95	AUC	TPR-95	AUCSNet	14.30 30.48	0.84 2.70	8.20 23.05	0.56 2.37	SNet	55.83	^0725	32.69	■0744EBD	14.70 37.54	0.85 2.42	8.58 25.69	0.60 1.81	EBD	56.12	0.763	33.35	0.769RR	14.99 38.58	0.87 3.28	8.53 28.67	0.61 3.21	RR	57.57	0.773	34.48	0.776harder to distinguish misclassified inputs from correctly classified ones. In practice, we can trade-offbetween the learning difficulty and the effectiveness of R-Con by tuning τ . Namely, in Table 5we study the effects of tuning temperature values for fθ(x)[y] and fθ(x)[ym] in LRR. We find thatmoderately lower down the temperature can benefit model robustness but sacrifice clean accuracy,while overly low temperature degenerates both clean and robust performance.
Table 9: Results of different hyperparametersfor the KD and LID methods on CIFAR-10,under ('∞, 8/255) threat model. For KD, Werestore the features on 1, 000 correctly classifiedtraining samples in each class. For LID, Werestore the features on totally 10, 000 correctlyclassified training samples.
Table 10: Results of different hyperparametersfor the KD and LID methods on CIFAR-100.
Table 11: Results of different hyperparameters for the SelectiveNet and EBD methods on CIFAR-10.
Table 12: Classification accuracy (%) and the ROC-AUC scores on CIFAR-10. The AT framework isPGD-AT and the model architecture is WRN-34-10. For KD, we restore 1, 000 correctly classifiedtraining features in each class and use σ = 10-3. For LID, we restore totally 10, 000 correctlyclassified training features and use K = 600. We calculate mean and covariance matrix on allcorrectly classified training samples for GDA and GMM. For SNet, the λ = 8 and coverage is 0.7.
Table 13: Classification accuracy (%) and the ROC-AUC scores on CIFAR-100 under PGD-10 attacks.
