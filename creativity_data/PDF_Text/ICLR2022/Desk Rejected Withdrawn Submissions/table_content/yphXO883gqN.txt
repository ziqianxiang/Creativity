Table 1: Image generation on CIFAR10Model	Train epochs	Test MSE loss	FIDDCGAN	50	^^A	35.84DGD	500	0.0052	90.77VAE	500	0.0293	322.64βVAE	100	0.0080	150.37interpretation for DGD and VAE can be found in A.5. In Figure 2, we show CIFAR10 test imagereconstructions next to randomly generated images from DCGAN, DGD, VAE and βVAE. We cansee that while the VAE achieves better image reconstructions with decreasing β , generated imagesremain blurry. Our DGD model, however, generates sharper and more contrastive images, similarto those generated by DCGAN. This is reflected in the FID scores in table 1. Of course none ofthese models achieve recognizable images at this point and fall short compared to state-of-the-artimage generators. We also concede that the VAEs reported here surely do not represent the bestthis method could do under these circumstances and that we are not experts in the field of VAEs.
Table 2: Architecture and hyperparametersModel ID	Architecture	Latent dimension	Learning rates (decoder, representation)	Weight decayDGD 1	decoder (shallow): capacity 32	1024	1e-3,1e-2	0DGD 2	decoder (shallow): capacity 16	512	1e-3,1e-2	1e- 5DGD 3	decoder: capacity 64	256	1e-4, 1e-2	1e-5DGD 4	decoder (linear): capacity 64	200	1e-3,1e-2	1e-5βVAE 1	VAE (shallow): capacity 32, beta	1024	1e-3	0	1e-2			βVAE 2	VAE (shallow): capacity 16, beta	512	1e-2	0	1e-2			βVAE 3	VAE (shallow): capacity 8, beta	256	1e-2	0	1e-2			βVAE 4	VAE (shallow, linear): capacity 16,	200	1e-3	1e-5	beta 1e - 2			VanillaVAE 1	VAE (shallow): capacity 16	512	1e-4	0VanillaVAE 2	VAE (shallow, linear): capacity 32	200	1e-3	1e-5VanillaVAE 3	VAE: capacity 32	128	1e-3	0VanillaVAE 4	VAE (shallow, encoder linear): ca-	64	1e-3	1e- 5	pacity 16			Table 3: Experimental results
Table 3: Experimental resultsModel ID	MSE loss	FID score	Shapiro Wilk test Statistic	Intersection ratio a in aL = L ∩ G	Intersection ratio b in bG = L ∩ G	Class distance correlationDGD 1	0.0017	197.35	1.0005	1.0000	0.0515	0.9737DGD 2	0.0028	186.48	0.9972	1.0000	0.0619	0.9873DGD 3	0.0040	119.47	0.9991	1.0000	0.0515	0.9840DGD 4	0.0037	126.54	0.9984	1.0000	0.0619	0.9728βVAE 1	0.0036	175.55	0.9127	0.9573	0.9897	0.9421βVAE 2	0.0044	189.00	0.8770	0.8711	0.9794	0.9697βVAE 3	0.0056	212.00	0.9150	0.6514	0.9588	0.9721βVAE 4	0.0072	159.15	0.8822	0.6113	0.9691	0.9193VanillaVAE 1	0.0343	260.26	0.9968	0.9995	1.0000	0.9755VanillaVAE 2	0.0254	225.58	0.9943	0.9993	0.9691	0.9993VanillaVAE 3	0.0351	308.63	0.9705	0.9967	0.9794	0.9833VanillaVAE 4	0.0283	269.27	0.9695	0.9948	0.9381	0.973413Under review as a conference paper at ICLR 2022A.5 DCGAN implementationThe DCGAN model is implemented in Pytorch according to Radford et al. (2016) with some devia-tions. To the best of our knowledge, deviations are found in the input size and first layer (we kept theimage size of 32x32x3 and performed a 1x1 convolution) and the negative slope of the LeakyReLU
Table 4: Training parameters for MNIST experimentsLearning rate Momentum Weight decay OptimizerDecoder	0.001	NA	0.00001	Adam (Pytorch)Representation	0.01	0.9	0	Stochastic gradient descentGMM parameters	0.1	NA	0	Adam (Pytorch)Priors on the GMM:For the mixture weights we used Dirichlet prior with parameter 1 for all components.
