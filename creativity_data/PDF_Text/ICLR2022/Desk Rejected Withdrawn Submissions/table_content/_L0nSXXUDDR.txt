Table 1: Baseline and oracle comparison. Classification accuracy is reported on the mini-ImageNet-{Blue, Red} datasets with the ResNet-18 architecture. The accuracy is reported for each individual noiseratio (0%, 20%, 40%, 80%). We present the mean accuracy and standard deviation from five trials. Theoracle model is trained on only the known, clean examples in the training set using a cross-entropy loss.
Table 2: State-of-the-art comparison. We compare NCR and our baseline impl ementation to othermethods on mini-WebVision, Clothing1M, CIFAR-10 and CIFAR-100. We report the mean accuracyand standard deviation from five trials. The symbols denote: * result obtained using IncePtion-ResNetinstead of ResNet-50, ?result obtained from a publication other than the original. CIFAR results forGJS, LDMI and the original ELR PaPer were not included because they use ResNet-34 instead of -18.
Table 3: List of network hyperparameters used to train the network in our experiments.
Table 4: List of NCR hyperparameters used to train the network in our experiments.
Table 5: Baseline and oracle comparison. Classification accuracy is reported on the mini-ImageNet-Purple with the ResNet-18 architecture. The accuracy is reported for each individual noise ratio (0%,20%, 40%, 80%). We present the mean accuracy and standard deviation from five trials. The oraclemodel is trained on only the known, clean examples in the training set using a cross-entropy loss.
