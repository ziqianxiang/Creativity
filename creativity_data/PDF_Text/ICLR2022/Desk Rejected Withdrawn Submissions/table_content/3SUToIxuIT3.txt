Table 1: Consistency scores of the pro-posed efficient point transformer (EPT) andMinkOWSkiNet42∣ on different transforma-tion sets, namely, rotation only (R), trans-lation only (t), and both (R and t). The sizeof voxel is set to 10cm, 5cm, and 2cm in aScanNet dataset. EPT relieves the predic-tion inconsistency occurred by voxelizationartifact.
Table 2: Results of semantic segmentation on the S canNet (Dai et al., 2017) dataset (left) andS3DIS (Armeni et al., 2016) dataset (right). Note that the score denoted by ∣ is the reproducedperformance of MinkowskiNet42 (Choy et al., 2019) with the official source code.
Table 3: Ablation studies on the proposed positional encoding layers.
Table 4: The theoretical time complexity of neighbor search and per-scene wall-time latency of eachnetwork on S3DIS Area 5. N is the number of dataset points, M is the number of query points,and K is the number of neighbors to search. Note that both M and N are much larger than K in alarge-scale point cloud. The mIoU score denoted by * is the performance of PAConv that uses anefficient implementation of k-NN search algorithm, and PointTransformer also uses the same.
Table 5: 3D object detection results of VoteNet (Qiet al., 2019) with various backbones on ScanNetdataset (Dai et al., 2017). Numbers except that ofMinkoWskiNett and EPT are taken from Chatonet al. (2020).
