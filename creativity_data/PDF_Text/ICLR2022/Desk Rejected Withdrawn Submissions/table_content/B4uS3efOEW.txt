Table 1: Test Accuracy (%) on CIFAR-10 and CIFAR-100 with various levels of label noise injectedto the training set. We compare with previous works under the same backbone ResNet34. The resultsare averaged over 3 trials. Results are taken from their original papers. The best results are in bold.
Table 2: Comparison with state-of-the-art methods trained on Clothing1M. Results of other methodsare taken from original papers. All methods use an ResNet-50 architecture pretrained on ImageNet.
Table 3: Comparison with state-of-the-art methods trained on WebVision. Results of other methodsare taken from Li et al. (2020a); Liu et al. (2020). All methods use an InceptionResNetV2 architecture.
Table 4: Influence of three components in our approach. â€¢ means the model fails to converge.
Table 5: Detail information of experiment.
Table 6: Correction accuracy (%) on CIFAR-10 and CIFAR-100 with various levels of label noiseinjected to training set.
Table 7: The test accuracy of CAR and CE with different target estimation strategies. All the followingexperiments use Cosine Annealing learning rate scheduler (Loshchilov & Hutter, 2017).
