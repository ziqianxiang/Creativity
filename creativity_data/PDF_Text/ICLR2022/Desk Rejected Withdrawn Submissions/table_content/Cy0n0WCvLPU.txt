Table 1: Basic statistics of the datasets in this paper: In the attributes, #Z denotes thenumber of topics and #K is the number for the encoder to refer to in #Z.
Table 2: Comparison of topic coherence: N is #ranked words. The dimensionality of theembedding space for Topic2Vec, CLM and TAN is set to 100(Amazon)/200(Yelp), the skiplength, and #negative sampling is set to 5, and 5, respectively. The values in bold showbest performance, where the bold value denotes the statistical significance for p < 0.01,compared to the best baseline.
Table 3: Comparison and Ablation analysis of various unconditional text generation models:In this table, F, P, D, B and M denotes Frequency, Dist, BLEU, and METEOR respectively.
Table 4: Case study of texts generated from models with Amazon: We gave seed words ”Iam disappointed in this purchase”，and show the generated text from each model.
