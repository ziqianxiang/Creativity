Table 1: Comparing to coreset selection and training set synthesis methods. We first learn the synthetic dataand then evaluate them by training neural networks from scratch and testing on real testing data. The testingaccuracies (%) are reported. Img/Cls: image(s) per class. Ratio (%): the ratio of condensed set size to thewhole training set size. Note: DDt and LDt Use different architectures i.e. LeNet for MNIST and AlexNet forCIFAR10. The rest methods all use ConvNet.
Table 2: 50 images/class learning with BatchNormalization.
Table 3: Cross-architecture testing performance (%).
Table 4: The performance of synthetic data learned on CIFAR10 dataset with different network distributions.
Table 5: We implement neural architecture search on CIFAR10 dataset with the search space of 720 ConvNets.
