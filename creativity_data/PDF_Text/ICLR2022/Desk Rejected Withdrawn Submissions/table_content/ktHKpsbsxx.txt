Table 1: Average fairness scores (1) and the success rate of stable matching (↑) at N = 20. Boldand underlined scores shows the best and second best ones, respectively. The success rates in stablematching are colored in red if it is less than 95%.
Table 2: Average fairness scores Q) and success rate of stable matching (↑) at N = 30.
Table 3: Comparison of the models trained with different size of instances.
Table 4: Generalizability of WeaveNet against differencein distribution type (N = 30).
Table 5: Demonstration at N = 100.
Table 6: Comparison in parameter efficiency among different shape architectures. Deep achievedthe best success rate in stable matching despite its smallest architecture.
Table 7: Architecture of each model. D0 represents the output channels of φ1 for the set-encoderand the length of key and query features for self-attention. Since MLP and GIN parameters differfor N , we show here cases with N = 5.
Table 8: Numbers of blocking pairs in the estimated matching with U at N = 100. Fail countsoutputs that are not a one-to-one matching.
Table 9: Architecture of each model. D0 represents the output channels of φ1 for the set-encoderand the length of the key and query vectors for self-attention.
