Table 1: A detailed comparison between SAU activation and other baseline activations in MNIST,Fashion MNIST, and SVHN datasets for image classification problem on AlexNet architecture. Wereport top-1 test accuracy (in %) for the mean of 10 different runs. mean±std is reported in the table.
Table 2: A detailed comparison between SAU activation and other baseline activations in the CI-FAR10 dataset for image classification problem on different popular network architectures. Wereport top-1 test accuracy (in %) for the mean of 10 different runs. mean±std is reported in thetable.
Table 3: A detailed comparison between SAU activation and other baseline activations in the CI-FAR100 dataset for image classification problem on different popular network architectures. Wereport top-1 test accuracy (in %) for the mean of 10 different runs. mean±std is reported in thetable.
Table 4: A detailed comparison between SAU activation and other baseline activations in TinyImageNet dataset for image classification problem on WideResNet 28-10 architecture. We reporttop-1 test accuracy (in %) for the mean of 6 different runs. mean±std is reported in the table.
Table 5: A detailed comparison between SAU activation and other baseline activations in PascalVOC dataset for object detection problem on SSD300 network architecture. We report mAP for themean of 6 different runs. mean±std is reported in the table.
Table 6: A detailed comparison between SAU activation and other baseline activations in CityScapesdataset for semantic segmentation problem on U-NET model. We report pixel accuracy and mIOUfor the mean of 6 different runs. mean±std is reported in the table.
Table 7: A detailed comparison between SAU activation and other baseline activations in WMT-2014 dataset for machine translation problem on transformer model. We report BLEU score for themean of 6 different runs. mean±std is reported in the table.
Table 8: Baseline table for SAU. In the table, we report the total number of cases in which SAUunderperforms, equal, or outperforms when we compare with the baseline activation functions6 ConclusionIn this paper, we propose a new novel smooth activation function using approximate identity, and wecall it a smooth activation unit (SAU). The proposed function can approximate ReLU or its differentvariants (like Leaky ReLU etc.) quite well. For our experiments, we consider SAU as a trainableactivation function, and we show that on a wide range of experiments on different deep learningproblems, the proposed functions outperform the known activations like ReLU, Leaky ReLU orSwish in most cases which shows that replacing the hand-crafted activation functions by SAU canbe beneficial in deep networks.
Table 9: A detailed comparison between SAU activation and other baseline activations in MNIST,Fashion MNIST, and SVHN datasets for image classification problem on VGG16 architecture. Wereport top-1 test accuracy (in %) for the mean of 10 different runs. mean±std is reported in the table.
Table 10: A detailed comparison between SAU activation and other baseline activations in MNIST,Fashion MNIST, and SVHN datasets for image classification problem on LeNet architecture. Wereport top-1 test accuracy (in %) for the mean of 10 different runs. mean±std is reported in the table.
Table 11: A detailed comparison between SAU activation and other baseline activations in MNIST,Fashion MNIST, and SVHN datasets for image classification problem on Custom-designated archi-tecture. We report top-1 test accuracy (in %) for the mean of 10 different runs. mean±std is reportedin the table.
Table 12: Experimental results for baseline activations in CIFAR100 dataset for image classificationproblem on different popular network architectures. We report top-1 test accuracy (in %) for themean of 10 different runs. mean±std is reported in the table.
Table 13: Experimental results for baseline activations in CIFAR10 dataset for image classificationproblem on different popular network architectures. We report top-1 test accuracy (in %) for themean of 10 different runs. mean±std is reported in the table.
Table 14: Experimental results for baseline activations in CIFAR100 dataset for image classificationproblem on different popular network architectures. We report top-1 test accuracy (in %) for themean of 10 different runs. mean±std is reported in the table.
Table 15: Experimental results for baseline activations in CIFAR100 dataset for image classificationproblem on different popular network architectures. We report top-1 test accuracy (in %) for themean of 10 different runs. mean±std is reported in the table.
