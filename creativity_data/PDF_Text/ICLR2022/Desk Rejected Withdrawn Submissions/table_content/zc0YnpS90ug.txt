Table 1: Summary of node drop pooling models in our framework.
Table 2: MID performance across four backbone models and seventeen datasets in graph classifica-tion task. The reported results are mean and standard deviation over 10 different runs. Red: the bestperformance. Blue: the second best performance. Hyphen(-) denotes out-of-resources.
Table 3: Ablation study results.
Table 4: Training time per epoch.
Table 5: Commonly used notations and their descriptions.
Table 6: Node classification results on four benchmark heterophily datasets.
Table 7: Generalization study results.
Table 8: Dataset statistics and model hyperparameters for our generalized experiments.
Table 9: Score correctness.
Table 10: Statistics and properties of benchmark datasets	# graphs	# classes	Avg # nodes	Avg # edgesDD	1,178	2	284.32	715.66PROTEINS	1,113	2	39.06	72.82NCI1	4,110	2	29.87	32.30MUTAG	188	2	17.93	19.79PTC-MR	344	2	14.30	14.69NCI109	4,127	2	29.68	32.13TU Datasets ENZYMES	600	6	32.63	124.20Mutagenicity	4,337	2	30.32	30.77FRANKENSTEIN	4,337	2	16.90	17.88REDDIT-B	2,000	2	429.63	497.75IMDB-B	1,000	2	19.77	96.53IMDB-M	1,500	3	13.00	65.94COLLAB	5,000	3	74.49	2457.78HIV	41,127	2	25.51	27.52Tox21	7,831	12	18.57	19.3OGB Datasets				ToxCast	8,576	617	18.78	19.3BBBP	2,039	2	24.06	26.0
Table 11: Hyperparameter settings for TU expriments. The layer is the type of graph convolution;batch is the training batch size; drop is the ratio of dropout between linear layers; lr is the learningrate; weight is the weight decay; patience is the training patience.
