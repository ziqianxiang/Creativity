Table 1: Quantitative comparison on real-world super-resolution datasets AIM19 and NTIRE20.
Table 2: Quantitative comparison on real-world image denoising dataset SIDD benchmark (top) andSIDD Vandation (bottom)._____________________________________________________________________	AWGN	MCWNNM	N2S	DeFIoW-NP	LUD-VAE	DeFloW	DnCNNPSNR ↑	32.12	33.37	29.56	33:54	34.63	33.81	36.54SSIM ↑	0.868	0.875	0.808	0.875	0.915	0.897	0.927PSNR ↑	32.06	33.40	30.72	3353	34.64	33.82	36.83SSIM ↑	0.809	0.815	0.787	0.817	0.868	0.846	0.870training dataset, we use the real-world super-resolution model ESRGAN (Wang et al., 2018) to getthe final super-resolution results for all methods. We use the training code from Impressionism andtrain the ESRGAN model for 60k iterations, then choose the final model with the best LPIPS scoreon the validation dataset every 5k iterations. We also compare with a recently proposed unsupervisedsuper-resolution model CinCGAN (Yuan et al., 2018).
Table 3: Ablation study of LUD-VAE model. Left: Different generation methods on SIDD bench-mark (top) and SIDD validation (bottom) datasets. Right: Validate inference invariant condition onAIM19 dataset._____________________ ___________________________________________________________	Method 2	Method 3				PSNR ↑	SSIM ↑	LPIPS JPSNR ↑	-33.96^^	34.63	No blur h(x) = x			21.51	0.5208	0.476SSIM ↑	0.902	0.915	Kernel size s =	9, σ =	2	21.16	0.4631	0.460PSNR ↑	-34.08^^	34.64	Kernel size s =	9, σ =	4	22.13	0.6165	0.377SSIM ↑	0.856	0.868	Kernel size s =	9, σ =	6	21.45	0.5874	0.3614.4	Real-world image denoisingWe compare LUD-VAE with the unsupervised denoising method MCWNNM (Xu et al., 2017), thedataset-based denoising method N2S (Batson & Royer, 2019), the degradation modeling methodDeFlow/DeFlow-NP (Wolf et al., 2021), and the fully supervised method DnCNN (Zhang et al.,2017). We also set up a baseline method for Additive White Gaussian Noise degradation, denotedas AWGN. Since the SIDD dataset contains images with different noise levels, we synthetic thedegraded images with random noise levels using different degradation methods. For AWGN, werandomly apply Gaussian noise with zero mean and standard deviation σ ∈ [0.05, 0.5] to eachimage; for DeFLow/DeFlow-NP and LUD-VAE we randomly apply synthetic noise with the noiselevel parameter t ∈ [1, 4] to each image. For AWGN, LUD-VAE, and DeFlow/DeFlow-NP, we usethe DnCNN (Zhang et al., 2017) for downstream denoising tasks for 50k iterations with an initiallearning rate 1e - 4 and halved in 25k iteration. We test each method on the validation set every 500
