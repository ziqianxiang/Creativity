Table 1: Results on Pascal VOC 2007 test set. For all the semi-supervised methods, Pascal VOC 2012 trainset is treated as unlabeled data. AP50 is reported. LR is the learning rate, and Iter means the total trainingiterations. C indicates the Color transformation augmentation, G is the Geometric transformation augmentation,and Mosaic is randomly performing horizontal mixing and vertical mixing two images. Mixup (Zhang et al.,2017) and DropBlock (Ghiasi et al., 2018) are strong regularization operations.
Table 2: Results on MS-COCO 2017 val set. For 5% and 10% protocols, the results are the mean over 5 datafolds. Stages are the training phases. For example, STAC has two stages: train a teacher model first to hardpseudo-label and train a student model with both labeled and pseudo-labeled data. - means that the results ortraining details are missing in the original paper. For 180k training schedule, the learning rate is set to 0.01 with5% and 10% data protocol, to 0.02 with 100% data protocol.
Table 3: Results on MS-COCO 2014 minival set. DD is Data Distillation (Radosavovic et al., 2018). Oraclemeans treating all the 115k images as labeled data.
Table 4: The ablative results on MS-COCO 2017 val set. The models are trained with 10% labeled and 90%unlabeled MS-COCO train 2017 split.
Table 5: Multi-Scale Testing on MS-COCO 2017 val set. The ensemble results show the gain from multi-scaletesting, which means the model detects instances in one size while is blind to them in the other size. Thesmall gain indicates that the detector consistently predicts images in different sizes, which means robust scaleinvariance.
Table 6: Resultson COCO val set.
Table 7: Results on COCO val set.
Table 8: Details of data augmentations.
