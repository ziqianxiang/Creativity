Table 1: Hyperparameters in Homogeneous LearningML TASK MODELRL MODELEpoch	1	Episode	120Batch size	32	Future reward discount	0.9Learning rate	0.001	Epsilon decay	0.02Optimization function	Adam	Epoch	1Maximum step	35 (MNIST)/100 (Fashion-MNIST)	Batch size	16		Learning rate	0.001For each episode, we computed the step rewards and the episode reward for the model training toachieve the performance goal. With the advancement of episodes, the communication policy evolvedto improve the episode reward thus benefiting better decision-making of the next-node selection.
