Table 1: Results and comparisons for networks trained on ImageNet-1K. α denotes the hyperpa-rameter that controls the amount of gradient tampering at softmax, eq. (1). Rows with α 6= 1 areexperiments conducted using the proposed method. α = 1.0 denotes no tampering.
Table 2: Results for non-Batch Normalized ResNets on ImageNet-1K. α denotes the hyperparameterthat controls the amount of gradient tampering at softmax, eq. (1). Rows with α 6= 1 are experimentsconducted using the proposed method. α = 1.0 denotes no tampering.
Table 3: Ablation study for ResNet-50 on ImageNet-1K. LS column denotes whether label smooth-ing has been applied. A smoothing hyperparameter value of 0.1 has been used. α denotes thehyperparameter that controls the amount of gradient tampering at softmax, eq. (1). Rows withα 6= 1 are experiments conducted using the proposed method. α = 1.0 denotes no tampering.
