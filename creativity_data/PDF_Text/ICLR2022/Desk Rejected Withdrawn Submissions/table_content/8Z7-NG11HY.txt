Table 1: Performances are averaged across language pairs. We bold numbers that significantlyoutperform others according to paired t-test (Fisher, 1935). Joint-Align uses 100k parallel dataper language pair; others only use 20k parallel data. InfoXLM uses 42GB parallel data in totalbut lacks Czech/Latvian/Finish-to-English. We exclude validation criteria for Rotation, GBDD andNormalization, as they have closed-form solutions. VecMaP needs 〜500 epochs to reach convergence.
Table 2: Correlation statistics: last three columns denote intervals used to split Pearson’s ρ range.
Table 3: Comparison of XLM-R (original) and its variant after alignments. InfoXLM-42GB has beentrained for 150K training steps, while Real-NVP-20k uses semantic criterion for model selection. Webold numbers that significantly outperform others according to paired t-test (Fisher, 1935). Real-NVPthat uses our criteria performs comparable with InfoXLM; the latter uses much larger parallel databut lacks validation criteria. This confirms the effectiveness of our approaches.
Table 4: Full results of baselines and our alignments. Real-NVP and GAN-Real-NVP are denoted by NVP and GNVP. [Method]÷P∕C∕G denotes the integration inthe Procrustes refinement (P), or in our bootstrapping procedure constrained with cross-correlation (C) and with graph structure (G).
