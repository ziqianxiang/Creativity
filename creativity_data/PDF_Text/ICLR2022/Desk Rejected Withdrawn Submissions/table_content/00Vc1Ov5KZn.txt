Table 1: Different Video mixing strategies (at left) areevaluated on downstream action classification and re-trieval tasks. All the models are trained on training sam-ples of UCF101 for 200 epochs with RGB input andtested on the validation set of UCF101 and HMDB51.
Table 2: Comparison of different Cross-Modal manifold mixing strategies. Random CV mix layer indicatesif the feature map from the other modality is obtained from the same layer as the primary modality or not.
Table 3: Comparison to the state-of-the-art methods for downstream action classification on UCF101 andHMDB51 for different combination of modalities - video (V ), audio (A), text (T) and flow (F). For a faircomparison with SOTA, we group the results based on the dataset used for pre-training. ’Frozen X’ indicateslinear probe evaluation and 'Frozen × 'indicates end-to-end finetuning of the encoders.
Table 4: Comparison to the state-of-the-art methods on Nearest-Neighbour video retrieval on UCF101 andHMDB51. Testing set clips are used to retrieve training set videos and R@k is reported for k ∈ {1, 5, 10, 20}.
Table 5: Comparison to the state-of-the-art methods on NTU-60 for action action classification using differentmodalities. We indicate the type of pretext task used in the SOTA methods. * indicates that results reproducedon our settings.
