Table 1: Statistics of the citation network datasets.					Datasets	Nodes	Edges	Attributes	Classes	SparsityCora	2, 708	5, 429	1, 433	7	0.07%ACM	3, 025	13, 128	1, 870	3	0.14%citepseer	3, 312	4, 715	3, 703	6	0.04%Pubmed	19, 717	44, 324	500	3	0.01%Baselines. We implement our proposed SpikingGCN and the following competitive baselines:GCNs (Kipf & Welling, 2016), SGC (Wu et al., 2019), FastGCN (Chen et al., 2018), GAT(VelickoVic et al., 2017), DAGNN (LiU et al., 2020a). We also conduct the experiments onSpikingGCN-N, a variant of SpikingGCN, which uses a refined Heaviside activation function (8)instead. For a fair comparison, we partition the data using two different ways. The first is as same as(Yang et al., 2016), which is adopted by many existing baselines in the literature. In this split method(i.e., Split I), 20 instances from each class are sampled as the training datasets. In addition, 500 and1000 instances are sampled as the Validation and testing datasets respectiVely. For the second datasplit (i.e., Split II), the ratio of training and testing is diVided into 8:2, and 20% of training samplesis further used for Validation.
Table 2: Test accuracy (%) comparison of different methods. The results from the literature andour experiments are proVided. The literature statistics of ACM datasets are taken from (Wang et al.,2020). The experimental scores are all aVeraged oVer 10 runs. The top 2 results are boldfaced.
Table 3: The Area under the Learning Curve (ALC) on Cora and ACM datasets.
Table 4: Operations comparisonmodels	Cora	ACM	citepseer	PubmedGCN	67.77K	63.71K	79.54K	414.16KSGC	10.03K	5.61K	22.22K	1.50KFastGCN	67.54K	71.97K	141.69K	94.88KGAT	308.94K	349.91K	499.16K	1.53MDAGNN	281.73K	210.63K	436.11K	623.71KSpikingGCN	1.39K	0.59K	1.19K	0.59KTable 5: Energy consumption comparisonGCN on TITANPower (W)	GFLOPS	Nodes	FLOPS	∣	Energy(J)280	16,310	10,000	4.14E+09	∣	0.07SpikingGCN on ROLLsVoltage (V)	Energy/spike (pJ)	Nodes Spikes ∣ Energy1.8	3.7	10,000	2.73E+07 ∣	1.01E-04However, the energy consumption measured by SOPs may be biased, e.g., the zero spikes would alsoresult in the voltage descending changes, which don’t cost energy in neuromorphic chips. Hencecalculating energy only based on operations might result in an incorrect conclusion. We further pro-vide an alternative estimation approach as follow. Neuromorphic designs could provide event-basedcomputation by transmitting one-bit spikes between neurons. This characteristic contributes to the
Table 5: Energy consumption comparisonGCN on TITANPower (W)	GFLOPS	Nodes	FLOPS	∣	Energy(J)280	16,310	10,000	4.14E+09	∣	0.07SpikingGCN on ROLLsVoltage (V)	Energy/spike (pJ)	Nodes Spikes ∣ Energy1.8	3.7	10,000	2.73E+07 ∣	1.01E-04However, the energy consumption measured by SOPs may be biased, e.g., the zero spikes would alsoresult in the voltage descending changes, which don’t cost energy in neuromorphic chips. Hencecalculating energy only based on operations might result in an incorrect conclusion. We further pro-vide an alternative estimation approach as follow. Neuromorphic designs could provide event-basedcomputation by transmitting one-bit spikes between neurons. This characteristic contributes to theenergy efficiency of SNNs because they consume energy only when needed (Esser et al., 2016). Forexample, during the inference phase, the encoded sparse spike trains act as a low-precision synapseevent, which costs the computation memory once spikes are sent from a source neuron. Consideringthe above hardware characteristics and the deviation of SOPs in consumption calculation, we followthe spike-based approach utilized in (Cao et al., 2015) and count the overall spikes during inferencefor 4 datasets, to estimate the SNN energy consumption. We list an example of energy consumptionwhen inferring 10,000 nodes in the Pubmed dataset, as shown in Table 5.
Table 6: Test accuracy (%) comparison on MNIST dataset. The best results are boldfaced.
Table 7: Test accuracy comparison on MNISTdataset. The best results are boldfaced. Baselinenumbers are taken from Fey et al. (2018).
Table 8: Test RMSE scores with MovieLens100K datasets. Baselines numbers are taken from(van den Berg et al., 2017).
