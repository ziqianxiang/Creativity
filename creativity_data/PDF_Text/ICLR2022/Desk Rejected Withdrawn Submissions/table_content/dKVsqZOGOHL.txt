Table 1: Robust accuracy (%) of student models against 40-step PGD attack with different radii andclean accuracy (%) on the ImageNet dataset. Robust accuracy of the teacher models are shown inbrackets. The pre-trained student model is denoted with “*” where the distillation is conducted asa fine-tuning process. Other students are all trained from scratch. “ST” means the model is trainedfollowing the standard approach without distillation nor adversarial training. “AT” means the modelis obtained by adversarial training.
Table 2: Robust accuracy (%) of student models against AutoAttack with different radii and cleanaccuracy (%) on the ImageNet dataset. Robust accuracy of the teacher models are shown in brackets.
Table 3: Robust accuracy (%) of student models against 20-step PGD attack with different radii andclean accuracy (%) on the CIFAR-10 dataset. All students are trained from scratch. “ST” meansthe model is trained following the standard approach without distillation nor adversarial training.
Table 4: Bounds for adversarial robustness (as defined in Proposition 2) of different models onCIFAR-10. llme is defined by Definition 2 where e is the radius of perturbations. /。石 is the Cross-entropy loss. kgs - gt k2 calculates the l2-norm of input gradient alignment term. “ST” meansthe model is trained following the standard approach without distillation nor adversarial training.
