Table 1: Comparison between different unsupervised Re-ID tasks.
Table 2: Comparison with state-of-the-arts on fully supervised setting.
Table 3: Experimental results on the direct transfer setting. (The numbers in parentheses denote theimprovement over BoT(fast-reid). Random erasing is turned off due to its negative effect.)Methods	Duke-Market		Market-Duke		Market-MSMT		Duke-MSMT		mAP	Rank-1	mAP	Rank-1	mAP	Rank-1	mAP	Rank-1BoT(Paper)	25.50	54.30	25.70	41.40	-	-	-	-BoT(fast-reid)	24.43	52.46	24.40	41.29	4.90	14.31	6.03	18.84BoT + CBR (ours)	24.87	52.58	26.11	43.36	5.26	15.02	6.63^^	19.89	(+0.44)	(+0.12)	(+1.71)	(+2.07)	(+0.36)	(+0.71)	(+060)	(+1.05)Impact of data size Figure 4a shows the accuracy w.r.t data percentage. CBR shows significantimprovement over BoT when the amount of data is small. It also indicates that the conventionaltraining requires more cross-camera labeled data to alleviate the camera bias problem, while oursneeds less. Similar results can also be obtained on Duke and MSMT datasets in Appendix A.1.
Table 4: Ablation study of cross-camera DBSCAN (CC) and camera bias regularization (CBR).
Table 5: Comparison with state-of-the-arts on purely unsupervised setting.
Table 6: Comparison with state-of-the-arts on unsupervised domain adaptation setting.
