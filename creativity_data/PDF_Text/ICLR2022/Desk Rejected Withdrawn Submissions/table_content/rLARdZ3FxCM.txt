Table 1: Pose estimation from complete point clouds. Left: a comparison of methods by mean,median, and 5° accuracy of (geodesic) errors after 30k training steps. Middle: mean test errorat different points along with the training progression. Right: test error percentiles after trainingcompletes. The legend on the right applies to both plots.
Table 2: Pose estimation from depth point clouds. We report the same metricsntas in Table 1;IQ0∙IOk40k0.1°seethe caption there, All models are trained for 50K iterations,««Ablation Study We change different regularization coefficients λ and different τ to show the influ-ence of these two hyperparameters on 6D representation, Our simplest method MG, which directlyuses X - X as the gradient, can outperform the vanilla L2 loss but is worse than those with smallλ, which is consistent with the discussion in Sec3,3, And we can find that λ = 0.01 is better thanλ = 0 from the failures of PMG which only uses X - Xgp as gradient, We show the length vanish-ing problem without regularization and stablized length with regularization in Figure 3, As for theprecise value of λ, our experiments show that different choices will lead to similar performances,which implies the robustness of this hyperparameter, For the choices of τ , we also get a similarconclusion as λ: it is not sensitive in a reasonable range, but it shouldn’t be too large or too small,just as discussed in Sec 3,3,
Table 3: Ablation study of pose estimation from point clouds. We report the same metrics as inTable 1; see the caption there. We set τinit = 0.05, τsaf e = 0.25. τsaf e means the upper bound ofτ to make sure the Rg will be closer to R than Rgt . Refer to appendix for more details.
Table 4:	Pose estimation from PASCAL3D+ sofa images. Left: a comparison of methods by 10o/ 15o / 20o accuracy of (geodesic) errors and median errors after 60k training steps. Middle: mediantest error at different points along with the training progression. Right: test error percentiles aftertraining completes. The legend on the right applies to both plots.
Table 5:	Pose estimation from PASCAL3D+ bicycle images. We report the same metrics as Table4; see the caption there.
Table 6: Rotation estimation without ground truth rotation supervision We report the samemetrics as in Table 1; see the caption there. All models are trained for 30K iterations. Left: Flowloss for rotation estimation. Right: Self-supervised instance-level rotation estimation.
Table 7: Pose estimation from ModelNet chair images. We report the same metrics as in Table 1;see the caption there. All models are trained for 600K iterations.
Table 8: Pose estimation from ModelNet sofa images. We report the same metrics as in Table 1;see the caption there. All models are trained for 600K iterations.
Table 9: Camera relocalization on Cambridge Landscape dataset. We report the median errorof translation and rotation of the best checkpoint, which is chosen by minimizing the median ofrotation.
Table 10: Unit vector estimation from ModelNet bottle complete and depth point clouds. Wereport the same metrics as in Table 1 except replace 5° Acc by 1° Acc; see the caption there. Allmodels are trained for 30K iterations.
