Table 1: Regular time-series	Method	Sines	Stocks	Energy	MuJoCoDiscriminative Score	IIT-GAN	.012±.014	.077±.031	.221±.068	.245±.029	TimeGAN	.011±.008	.102±.021	.236±.012	.409±.028	RCGAN	.022±.008	.196±.027	.336±.017	.436±.012	C-RNN-GAN	.229±.040	.399±.028	.499±.001	.412±.095	T-Forcing	.495±.001	.226±.035	.483±.004	.499±.000	P-ForCing	.430±.227	.257±.026	.412±.006	.500±.000	WaVeNet	.158±.011	.232±.028	.397±.010	.385±.025	WaveGAN	.277±.013	.217±.022	.363±.012	.357±.017	IIT-GAN	.097±.000	.040±.000	.312±.002	.055±.000Predictive Score	TimeGAN	.093±.019	.038±.001	.273±.004	.082±.006	RCGAN	.097±.001	.040±.001	.292±.005	.081±.003	C-RNN-GAN	.127±.004	.038±.000	.483±.005	.055±.004	T-Forcing	.150±.022	.038±.001	.315±.005	.142±.014	P-Forcing	.116±.004	.043±.001	.303±.006	.102±.013	WaveNet	.117±.008	.042±.001	.311±.005	.333±.004	WaveGAN	.134±.013	.041±.001	.307±.007	.324±.006	-Original-	.094±.001	.036±.001	.250±.003	.031±.003Table 2: Irregular time-series (30% dropped)
Table 2: Irregular time-series (30% dropped)	Method	Sines	Stocks	Energy	MuJoCo	-IIT-GAN-	.363±.063	.251±.097	.333±.063	.249±.035Disc. Score	TimeGAN-D	.496±.008	.411±.040	.479±.010	.463±.025	RCGAN-D	.500±.000	.500±.000	.500±.000	.500±.000	C-RNN-GAN-D	.500±.000	.500±.000	.500±.000	.500±.000	T-Forcing-D	.408±.087	.409±.051	.347±.046	.494±.004	P-Forcing-D	.500±.000	.480±.060	.491±.020	.500±.000Predictive Score	-IIT-GAN-	.099±.004	.021±.003	.066±.001	.048±.001	TimeGAN-D	.192±.082	.105±.053	.248±.024	.098±.006	RCGAN-D	.388±.113	.523±.020	.409±.020	.361±.073	C-RNN-GAN-D	.664±.001	.345±.002	.440±.000	.457±.001	T-Forcing-D	.100±.002	.027±.002	.090±.001	.100±.001	P-Forcing-D	.154±.004	.079±.008	.147±.001	.173±.002	Original	.071±..004	.011±.002	.045±.001	.041±.002OriginalIrT-GANOriginalTimeGAN5 4 3 2 1-
Table 3: Irregular time-series (50% dropped)Method	Sines	Stocks	Energy-IIT-GAN-	.372±.128	.265±.073	.317±.010TimeGAN-D	.500±.000	.477±.021	.473±.015RCGAN-D	.500±.000	.500±.000	.500±.000C-RNN-GAN-D	.500±.000	.500±.000	.500±.000T-Forcing-D	.430±.101	.407±.034	.376±.046P-Forcing-D	.499±.000	.500±.000	.500±.000-IIT-GAN-	.101±.010	.018±.002	.064±.001TimeGAN-D	.169±.074	.254± .047	.339±.029RCGAN-D	.519±.046	.333±.044	.250±.010C-RNN-GAN-D	.754±.000	.273±.000	.438±.000T-Forcing-D	.104±.001	.038±.003	.090±.000P-Forcing-D	.190±.002	.089±.010	.198±.005Original	.071±.004	.011±.002	.045±.001MUJoCo.270±.016.500±.000.500±.000.500±.000
Table 4: Irregular time-series (70% dropped)	Method	Sines	Stocks	Energy	MUJoCo	-IIT-GAN-	.278±.022	.230±.053	.325±.047	.275±.023	TimeGAN-D	.498±.006	.485±.022	.500±.000	.492±.009	RCGAN-D	.500±.000	.500±.000	.500±.000	.500±.000Disc.	C-RNN-GAN-D	.500±.000	.500±.000	.500±.000	.500±.000	T-Forcing-D	.436±.067	.404±.068	.336±.032	.493±.005	P-Forcing-D	.500±.000	.449±.150	.494±.011	.499±.000Predictive Score	-IIT-GAN-	.088±.005	.020±.005	.076±.001	.051±.001	TimeGAN-D	.752±.001	.228±.000	.443±.000	.372±.089	RCGAN-D	.404±.034	.441±.045	.349±.027	.420±.056	C-RNN-GAN-D	.632±.001	.281±.019	.436±.000	.479±.001	T-Forcing-D	.102±.001	.031±.002	.091±.000	.114±.003	P-Forcing-D	.278±.045	.107±.009	.193±.006	.191±.005	Original	.071±..004	.011±.002	.045±.001	.041±.002(a) Stocks(b) EnergyFigUre 6: VisUalizations of the irregUlar time-series synthesized by IIT-GAN and T-Forcing-D (the 1strow is for a dropping rate of 30%, and the 2nd row for a rate of 50%)experiments in oUr paper. All baselines do not work well becaUse of the high dropping rate. T-Forcing-
Table 5: Ablation stUdy. See Appendix E for otherablation stUdies.
Table 6: Dataset StatisticsDataset	# of Samples	dim(x)	Average of N	LinkSines	10,000	5	24 time-points	-Stocks	3,773	6	24 days	LinkEnergy	19,711	28	24 hours	LinkMuJoCo	4,620	14	24 time-points	LinkB	ODE/CDE FUNCTIONS IN IIT-GANB.1	EncoderOur encoder based on NCDEs has the following CDE function f.
Table 7: The architecture of the network f in the encoderLayer	Design	Input Size	Output Size1	ReLU(Linear)	N X dim(x)	N × 4dim(x)2	ReLU(Linear)	N × 4dim(x)	N × 4dim(x)3	ReLU(Linear)	N × 4dim(x)	N × 4dim(x)4	Tanh(Linear)	N × 4dim(x)	N × dim(x)B.2	Decoder, DiscriminatorOur decoder and discriminator based on GRU-ODEs have the following ODE functions. They havethe same architecture but their parameters are separated.
Table 8: The architecture of the network g in the decoderLayer	Design	Input Size	Output Size1	rt = Sigmoid(Linear) Zt = Sigmoid(Linear) Ut =Tanh(Linear) dh = (1 - Zt) * (Ut - ht)	N × dim(h) N × dim(h) N × dim(h) N × dim(h)	N × dim(h) N × dim(h) N × dim(h) N × dim(h)Table 9: The architecture of the network q in the discriminatorLayer	Design	Input Size	Output Size1	rt = Sigmoid(Linear) Zt = Sigmoid(Linear) Ut =Tanh(Linear) dh = (1 - Zt) * (Ut - ht)	N × dim(x) N × dim(x) N × dim(x) N × dim(x)	N × dim(x) N × dim(x) N × dim(x) N × dim(x)B.3	GeneratorOur generator has the following ODE function f in Table 10.
Table 9: The architecture of the network q in the discriminatorLayer	Design	Input Size	Output Size1	rt = Sigmoid(Linear) Zt = Sigmoid(Linear) Ut =Tanh(Linear) dh = (1 - Zt) * (Ut - ht)	N × dim(x) N × dim(x) N × dim(x) N × dim(x)	N × dim(x) N × dim(x) N × dim(x) N × dim(x)B.3	GeneratorOur generator has the following ODE function f in Table 10.
Table 10: The architecture of the network r in the generatorLayer	Design	Input Size	Output Size-1~	Softplus(Linear)	N X dim(h + 1)	N × dim(h)2	Softplus(Linear)	N × dim(h + 1)	N × dim(h)3	Softplus(Linear)	N × dim(h + 1)	N × dim(h)(a)	How to calculate the predictivescore for the regular time-series syn-thesis in TimeGAN(b)	How to calculate the predictivescore for the irregular and intermittenttime-series in this paperFigure 9:	Predictive task according to the data typeC BaselinesFor the regular time-series baseline models, i.e., TimeGAN, RCGAN, C-RNN-GAN, T-forcing, andP-forcing, we use the 3-layer GRU-based neural network architecture with a hidden size that is 4times larger than the input size. We use or modify the following accessible source codes to run.
Table 11: Ablation study of model architecture in SinesSines	IIT-GAN (w.。AE)		IIT-GAN (FloW only)		IIT-GAN (AE only)		IIT-GAN (Full model)	Metric	Disc.	Pred.	Disc.	Pred.	Disc.	Pred.	Disc.	Pred.
Table 12: Ablation study of model architecture in StocksStocks	IIT-GAN (w.。AE)		IIT-GAN (FloW only)		IIT-GAN (AE only)		IIT-GAN (Full model)	Metric	Disc.	Pred.	Disc.	Pred.	Disc.	Pred.	Disc.	Pred.
Table 13: Ablation study of model architecture in EnergyEnergy	IIT-GAN (w.o. AE)		IIT-GAN (FloW only)		IIT-GAN (AE only)		IIT-GAN (Full model)	Metric	Disc.	Pred.	Disc.	Pred.	Disc.	Pred.	Disc.	Pred.
Table 14: Ablation study of model architecture in MuJoCoMuJoCo	IIT-GAN (w.。AE)		IIT-GAN (FloW only)		IIT-GAN (AE only)		IIT-GAN (Full model)	Metric	Disc.	Pred.	Disc.	Pred.	Disc.	Pred.	Disc.	Pred.
Table 15: Irregular time-series (30% dropped) ablation studyMetric	Method	Sines	Stocks	Energy	MuJoCoDiscriminative	IIT-GAN	.363	.251	.333	.249Score	w/o Eq. 8	.498	.266	.392	.303(Lower the Better)	w/o pre-training	.499	.305	.345	.241Predictive	IIT-GAN	.099	.021	.066	.048Score	w/o Eq. 8	.241	.015	.064	.061(Lower the Better)	w/o pre-training	.273	.022	.061	.049Table 16: Irregular time-series (50% dropped) ablation studyMetric	Method	Sines	Stocks	Energy	MuJoCoDiscriminative	IIT-GAN	.372	.265	.317	.270Score	w/o Eq. 8	.500	.323	.381	.274(Lower the Better)	w/o pre-training	.500	.209	.325	.270Predictive	IIT-GAN	.101	.018	.064	.056Score	w/o Eq. 8	.277	.018	.063	.051(Lower the Better)	w/o pre-training	.103	.017	.071	.051Table 17: Irregular time-series (70% dropped) ablation studyMetric	Method	Sines	Stocks	Energy	MuJoCoDiscriminative	IIT-GAN	.278	.230	.325	.275Score	w/o Eq. 8	.319	.274	.382	.290
Table 16: Irregular time-series (50% dropped) ablation studyMetric	Method	Sines	Stocks	Energy	MuJoCoDiscriminative	IIT-GAN	.372	.265	.317	.270Score	w/o Eq. 8	.500	.323	.381	.274(Lower the Better)	w/o pre-training	.500	.209	.325	.270Predictive	IIT-GAN	.101	.018	.064	.056Score	w/o Eq. 8	.277	.018	.063	.051(Lower the Better)	w/o pre-training	.103	.017	.071	.051Table 17: Irregular time-series (70% dropped) ablation studyMetric	Method	Sines	Stocks	Energy	MuJoCoDiscriminative	IIT-GAN	.278	.230	.325	.275Score	w/o Eq. 8	.319	.274	.382	.290(Lower the Better)	w/o pre-training	.408	.311	.345	.249Predictive	IIT-GAN	.088	.020	.076	.052Score	w/o Eq. 8	.082	.025	.066	.051(Lower the Better)	w/o pre-training	.104	.020	.085	.04916Under review as a conference paper at ICLR 2022F Sensitivity AnalysesWe provide performance (discriminative score and predictive score) depending on hyperparameters
Table 17: Irregular time-series (70% dropped) ablation studyMetric	Method	Sines	Stocks	Energy	MuJoCoDiscriminative	IIT-GAN	.278	.230	.325	.275Score	w/o Eq. 8	.319	.274	.382	.290(Lower the Better)	w/o pre-training	.408	.311	.345	.249Predictive	IIT-GAN	.088	.020	.076	.052Score	w/o Eq. 8	.082	.025	.066	.051(Lower the Better)	w/o pre-training	.104	.020	.085	.04916Under review as a conference paper at ICLR 2022F Sensitivity AnalysesWe provide performance (discriminative score and predictive score) depending on hyperparameters(i.e. atol (absolute tolerance), rtol (relative tolerance) and PMLE (the period of the MLE training forthe generator.)) for each different datasets.
Table 18: The best hyperparametersmethod Data atol rtol PMLE KAE d-layer r-acti reg-reConreg-kineticreg-jaCobianreg-direct	Sines 1e-2 1e-3	1	5000	1	softplus	0.01	0.05	0.1	0.1IIT-GAN	Stocks 1e-2 1e-3	2	10000	1	softplue	0.01	0.01	0.05	0.01(Regular)	Energy 1e-3 1e-2	2	5000	2	sigmoid	0.01	0.5	0.1	0.01	MuJoCo 1e-3 1e-2	2	5000	2	sigmoid	0.01	0.05	0.01	0.01	Sines 1e-2 1e-3	2	5000	~Γ~	softplus	0.01	0.05	0.01	0.01IIT-GAN	Stocks 1e-2 1e-3	2	10000	1	softplue	0.01	None	None	0.05(Dropped 30%)	Energy 1e-3 1e-2	2	5000	2	sigmoid	0.01	0.5	0.1	0.01	MuJoCo 1e-3 1e-2	2	2500	2	sigmoid	0.01	0.5	0.1	0.01	Sines 1e-2 1e-3	2	5000	~1Γ	softplus	0.01	0.05	0.01	0.01IIT-GAN	Stocks 1e-3 1e-3	2	10000	1	softplue	None	0.05	0.01	0.05(Dropped 50%)	Energy 1e-3 1e-2	2	5000	2	sigmoid	0.01	0.5	0.1	0.01	MuJoCo 1e-3 1e-2	2	1500	2	sigmoid	0.1	0.1	0.01	0.01	Sines 1e-2 1e-3	2	5000	~τ~	softplus	0.01	0.05	0.01	0.01IIT-GAN	Stocks 1e-2 1e-3	1	10000	1	softplue	None	0.05	0.01	0.05(Dropped 70%)	Energy 1e-3 1e-2	2	2500	2	sigmoid	0.01	0.5	0.1	0.01	MuJoCo 1e-3 1e-2	2	2500	2	sigmoid	0.01	0.5	0.1	0.0118Under review as a conference paper at ICLR 2022
Table 19: Comparison of model size and training time	Sines		Stocks		Energy		MuJoCo	Model	IIT-GAN	TimeGAN	IIT-GAN	TimeGAN	IIT-GAN	TimeGAN	IIT-GAN	TimeGANParameter	41,913	34,026	41,776	48,775	57,104	1,043,179	47,346	264,447Memory (MB)	1,675	1,419	1,653	1,423	1,839	1,611	1,655	1,546Training Time (HH:MM)	1。12	2:56	12:20	2:59	10:39	3:37	13:12	3:10H Model Size & Training Time ComparisonIn Table 19, we report the model size and training time of our method and TimeGAN, one of the bestperforming baseline. As shown, our model has much smaller numbers of parameters than TimeGAN.
