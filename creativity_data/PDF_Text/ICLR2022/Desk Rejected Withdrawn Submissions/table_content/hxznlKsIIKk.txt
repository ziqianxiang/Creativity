Table 1: Contradictory Article Contentin the input dataset in order to train the model to be agnostic to input text length. We evaluatethese approaches on baseline abstractive multi document summarization architectures in order toobserve improvements in the output consistency evaluated through ROGUE metrics and throughhuman annotations for fluency, informativeness and consistency. Our approach consists of individualcomposable elements, each of which we further evaluate independently through ablation studies.
Table 2: Evaluation results for MDS graph with conditional weighting evaluated on the MultiNewsdataset with ROUGE scores. Stared numbers are reproduced from the original papers.
Table 3: Evaluation results from a human annotation study over 182 randomly selected output MDSsummaries shows strong improvements over the baseline model with respect to fluency, informative-ness and repetitive content on a scale of 1 to 5.
Table 4: Ablation study comparing each of the approaches against baseline BART andBART+Longformer modelsAdditionally we conducted a qualitative analysis of how well each approach was able to conditionfor polarity and sentiment in the output summaries by evaluating the summaries through the trainedattribute conditioning module as shown in Table 5. This shows strong out of domain analysis resultsas the attribute conditioning module for polarity was trained on a different dataset, AllTheNews,and evaluated on the MultiNews dataset for MDS. This ablation study shows that This analysisshowed that MDS with future discriminators is the strongest attribute conditioning model. Sincethe sentiment and polarity of articles as determined by the XlNet classifiers are used to compute theopinion of an article, we used these models to analyze the MultiNews dataset.
Table 5: MDS with attribute future discriminators shows the highest mean polarity score andnarrowest standard deviation.
