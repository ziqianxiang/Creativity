Table 1: Comparison to original BERT. IDs describe the types of tests: O := original transformer,T := includes tokens, C := concatenated emotions to output layer, M := mix of T and C, and EN :=ensembles. Bold results are all of the models that contribute to EN. EN+Distil include DistilBERT(from Table 2 in bold) with the EN models. Underlined are the result with a P-value lower thanalpha=0.10. Columns in order: Test method-ID#, number of output layers, # of tokens used, concatprobability format, test accuracy, F1, F1 difference to original, and finally P value.
Table 2: Comparison to original DistilBERT. Columns follow the same format as table 1. The results							in bold contribute to the ensemble of DistilBERT models. lower than alpha=0.10.					Underlined are the result with a P-value		ID	Classifier Layers	Tokens	Concat Style	Accuracy	F1	Improvement over Original	t-test P-valueOriginal	2	—	—	0.86870	0.86863	N/A	N/ATokens	2	20	—	0.87221	0.87263	0.400%	1.18e-20Concat	2	—	(0-100)	0.87217	0.87226	0.363%	1.80e-03Mixed	2	20	(0-100)	0.87218	0.87231	0.368%	1.76e-04Ensemble	—	—	—	0.87479	0.87505	0.642%	1.48e-113.3	Incorporating Generated Emotions Into TransformersIn this section we describe the model designs which incorporate the generated emotion information.
Table 3: Results for the Sentiment140 dataset using the 0-shot HuggingFace pipeline where weuse the predictions of the individual emotion to classify the dataset. Highlighted in bold are directpositive and negative sentiment predictions and their softmax result.
Table 4: Tests on small training sets randomly selected from Sentiment140. The samples columnshas the number of training samples used. The F1 score is provided for each test, one without the useof tokens and the other with tokens using a range of 20.
Table 5: Tests performed by reducing number of emotions for the Sentiment140 dataset. We used atoken range of 20 for these tests.
Table 6: US Airline results using original BERT (ID O), BERT using the 2 token approach (IDT), BERT using concatenated classifier inputs (ID C), and BERT using a mix between the 2 tokenapproach and concatenated classifier inputs (ID M). The ”Improv.” column is the improvement inF1 over the original BERT score. Underlined are the result with a P-value lower than alpha=0.10.
