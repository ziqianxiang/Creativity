Table 1: Ablation study in the testing accuracy loss on 18 datasets by removing each module at atime while leaving others the same. Each experiment is conducted 5 times with different randomseeds. The results are shown in the format of mean and standard deviation. Column 2 shows theaccuracy of the full model with all modules included. Columns 3 to 10 represent the accuracy whenthe module in that column is removed from the model. The order of modules follow the networkarchitecture in Figure 1. Bold indicates that the module contributes most to the loss in accuracy andunderlining indicates that the module contributes least to the loss in accuracy when the module isremoved.
Table 2: Module-wise pruning results over all datasets. The results from Column 3 (MHA) to Col-umn 10 (AF) with regard to accuracy represent that the module in that column is removed from themodel architecture. Experiments are conducted 5 times with different random seeds. The accuracyresults are shown in the format of mean and standard deviation. Bold represents that the modulebrings about much accuracy loss compared to the unpruned model. Following MHA, the accuracydecreasing trend remains stable.
Table 3: Summary of the 18 UCR/UEA datasets used in experimentation.
Table 4: Hyperparameter search space of the model on each dataset. If the number of layers of amodule is equal to 0, then this module is removed in the pruned model.
Table 5: Module-by-module pruning results over all datasets. The results from Column 4 (MHA) toColumn 11 (AF) with regard to number of parameters, and the average training time per epoch rep-resent that the module in that column is removed from the model architecture. For fair comparison,the training time and the amount of parameters are reported when each module has only one layer(if exists).
