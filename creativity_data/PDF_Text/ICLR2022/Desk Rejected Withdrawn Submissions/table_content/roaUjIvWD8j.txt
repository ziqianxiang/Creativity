Table 1: A small image patch super-resolved by the 16 pretrained SISR models (top) and a sampleof 18 custom-trained SISR models (bottom). All custom-trained models shown were trained withthe DIV2K dataset, with random seed 1. Best viewed zoomed in.
Table 2: Accuracy (%) ofour custom model attributionclassifier grouped by differenthyperparameters. For exam-ple, the average accuracy ofour classifier on SISR modelswhose scale is 2x is 92.6%.
Table 3: single-image/10-image test accuracy (%) of 19 parameter classifiers. The “chance baseline”column shows the percent chance of predicting the parameter correctly by random guess. We do nottrain any parsers to predict the test hyperparameter value, hence the dashes.
Table 4: 12 papers which provide the 16 pretrained super-resolution models we use in our dataset(some papers provide both 2x and 4x models).
Table 5: Main Characteristics of SR Datsets: number of images, pixels per image (ppi), bits perpixel using PNG compression (bpp PNG), and shannon-entropy of the images’ greyscale histograms(entropy). for We report average (±standard deviation).
Table 6: Comparison of pretrained vs. custom-trained model performance by PSNR (higher isbetter) and LPIPS (lower is better) All models are 4x scale. Rows of the form {architecture}/{loss}are averaged across all custom-trained models with that combination of architecture and loss.
Table 7: Accuracy (%) of the parameter classification achieved using acutance as the only feature,and k-nearest neighbors as the classification scheme.
Table 8: Accuracies of different classifier backbones.
Table 9: Size and shape of the smaller versions of XceptionNet.
