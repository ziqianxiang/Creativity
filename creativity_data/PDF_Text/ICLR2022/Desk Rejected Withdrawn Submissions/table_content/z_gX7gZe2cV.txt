Table 1: Accuracies of current attacks on CIFAR-10	Original	Gaussian(σ)		Adversarial		JPEG(q)		Scaling(r)		Filtering		Rotation(δ)			[0,0.1]	[0,0.3]	1-step	loss=10	50	1	0.5	10	Clarendon	Moon	[0。, 10。]	[0。, 30。]CC	65.64%	66.21%	63.48%	78.89%	50.22%	66.68%	56.15%	58.65%	67.97%	66.72%	64.41%	66.10%	60.09%LT	80.47%	77.32%	64.78%	62.63%	50.02%	74.13%	51.98%	53.46%	70.32%	72.78%	60.56%	69.51%	59.03%ST	78.32%	75.84%	64.57%	64.86%	50.10%	73.40%	52.06%	53.64%	70.38%	72.04%	60.69%	68.99%	58.97%ET	77.58%	76.44%	65.50%	68.49%	50.03%	75.59%	52.93%	54.94%	73.11%	73.81%	63.20%	71.32%	60.51%NN	79.46%	76.33%	63.14%	54.23%	53.25%	73.10%	51.37%	51.90%	68.33%	72.18%	59.75%	67.94%	58.14%Table 1 shows the results of current attacks. When the transformations are small, we can see that allthese attacks can still achieve a decent performance without considering data transformations dueto the model’s robustness to small transformations. However, when the transformation is large oradversarially designed, current attacks’ accuracy would drop significantly. One observation worth6Under review as a conference paper at ICLR 2022mentioning is that the classification correctness attack’s accuracy gets better when the transformationsare small, especially for adversarial noises. It directly results from the robustness difference oftraining and testing examples: a small adversarial noise can cause more misclassifications in thetesting set than the training set, which is aligned with our intuition. The attack results of 10-stepPGD (omitted) and fixed-loss PGD are nearly the same and very close to 50%, indicating that currentattacks are ineffective in such cases.
Table 2: Accuracies and coverage difference rates ω of our attacks on CIFAR-10(a) Gaussian noise, σ- range of standard deviation							(b) Adversarial noise						σ		[0,0.1]		[0, 0.3]			PGD		1-step	loss=10			LTT		77.34%			65.68%		LTT		78.87%			56.17%	e	0.1	0.01	0.001	0.1	0.01	0.001		0.1	0.01	0.001	0.1	0.01	0.001RT	71.02%	75.04%	77.35%	65.58%	64.14%	65.91%	RT	79.20%	79.19%	77.92%	64.45%	61.30%	55.57%ω	8.37%	6.96%	1.35%	7.63%	2.52%	8.51%	ω	2.49%	5.62%	10.33%	42.47%	42.90%	47.45%CA		77.32%			65.50%		CA		78.89%			53.25%		(c) JPEG compression, q-compression quality								(d) Scaling, r-scaling factor				q		50			1		r		0.5			10.0	LTT		75.43%			57.00%		LTT		58.87%			73.78%		0.1	0.01	0.001	0.1	0.01	0.001	e	0.1	0.01	0.001	0.1	0.01	0.001RT	71.10%	74.68%	75.31%	57.31%	57.51%	56.95%	RT	61.09%	61.46%	61.09%	71.98%	73.88%	74.28%ω	9.02%	5.62%	2.17%	10.97%	18.88%	23.11%	ω	13.53%	18.68%	23.41%	7.11%	1.23%	6.00%CA		75.59%			56.15%		CA		58.65%			73.11%				(e) Filtering					(f) Rotation, δ-range of rotation degree					Filter		Clarendon			Moon		δ		[0。，10。]			[0。,30。]	LTT		74.49%			65.49%		LTT		70.73%			60.93%		0.1	0.01	0.001	0.1	0.01	0.001	e	0.1	0.01	0.001	0.1	0.01	0.001RT	71.00%	74.03%	74.15%	65.51%	65.56%	64.85%	RT	69.13%	72.26%	77.32%	61.52%	66.44%	75.57%
Table 3: Accuracies of current attacks on Purchase-100γ	0.00	0.05	0.10	0.15	0.20	0.25	0.30	0.35	0.40CC	63.33%	61.72%	57.54%	53.74%	51.61%	50.54%	50.18%	50.17%	50.13%LT	70.68%	61.15%	55.47%	52.42%	51.11%	50.37%	50.20%	50.12%	50.10%ST	59.36%	56.51%	53.78%	52.26%	51.30%	50.64%	50.32%	50.39%	50.21%ET	70.99%	61.46%	55.62%	52.47%	51.09%	50.38%	50.20%	50.11%	50.09%NN	65.65%	60.58%	56.01%	52.93%	51.37%	50.63%	50.28%	50.16%	50.09%the -robust area. Finally, we define d(S) = |S|, which is the number of features flipped during thereverse transformation process, as the distance metric for membership inference.
Table 4: Accuracies and coverage difference rates ω of our attacks on Purchase-100γ	0.05	0.10	0.15	0.20	0.25	0.30	0.35	0.40LTT	64.09%	58.03%	55.40%	52.79%	51.96%	50.70%	50.11%	49.83%RT	61.94%	57.27%	55.49%	53.70%	52.90%	52.02%	50.57%	50.41%ω	21.08%	24.27%	25.06%	24.44%	24.85%	22.93%	20.64%	19.09%CA	61.72%	57.54%	53.74%	51.61%	50.64%	50.32%	50.39%	50.21%5	DiscussionCombination of attacks: From the coverage difference rate shown in Section 4, we find that themembers successfully inferred by the two attacks are not highly overlapped sometimes. Specifically,the reverse transformation attacks can find some transformed training examples with relatively highloss. The finding indicates that real-world attackers may combine different attack strategies toincrease their attack success rate in the future.
Table 5: Accuracies of current attacks on CIFAR-10	Original	Gaussian(σ)			Adversarial			JPEG(q)			Scaling(r)			Filtering			Rotation(δ)				[0,0.1]	[0,0.2]	[0,0.3]	1-step	10-SteP	loss=10	50	10	1		0.5	1.5	10	Clarendon	Gingham	Moon	[0。，10。]	[0。, 20。]	[0。, 30。]CC	65.64%	66.21%	65.53%	63.48%	78.89%	50.22%	50.22%	66.68%	66.07%	56.15%	58.65%	68.02%	67.97%	66.72%	63.60%	64.41%	66.10%	63.11%	60.09%LT	80.47%	77.32%	69.66%	64.78%	62.63%	50.02%	50.02%	74.13%	61.13%	51.98%	53.46%	69.54%	70.32%	72.78%	59.13%	60.56%	69.51%	62.78%	59.03%ST	78.32%	75.84%	69.19%	64.57%	64.86%	50.10%	50.10%	73.40%	61.42%	52.06%	53.64%	69.61%	70.38%	72.04%	59.29%	60.69%	68.99%	62.63%	58.97%ET	77.58%	76.44%	70.33%	65.50%	68.49%	50.03%	50.03%	75.59%	64.41%	52.93%	54.94%	72.30%	73.11%	73.81%	61.50%	63.20%	71.32%	64.67%	60.51%NN	79.46%	76.33%	68.87%	63.14%	54.23%	48.71%	53.25%	73.10%	59.48%	51.37%	51.90%	67.56%	68.33%	72.18%	57.56%	59.75%	67.94%	61.63%	58.14%13Under review as a conference paper at ICLR 2022Table 6: Accuracies and coverage difference rates ω of our attacks on CIFAR-10(a) Gaussian noise, σ- range of standard deviationσ		[0, 0.1]		[0,0.2]				[0, 0.3]	LTT		77.34%			71.13%			65.68%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	71.02%	75.04%	77.35%	68.92%	70.00%	70.93%	65.58%	64.14%	65.91%ω	8.37%	6.96%	1.35%	9.27%	4.14%	3.81%	7.63%	2.52%	8.51%(b) Adversarial noise									PGD		1-step			10-step			loss=10	LTT		78.87%			64.32%			56.17%	
Table 6: Accuracies and coverage difference rates ω of our attacks on CIFAR-10(a) Gaussian noise, σ- range of standard deviationσ		[0, 0.1]		[0,0.2]				[0, 0.3]	LTT		77.34%			71.13%			65.68%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	71.02%	75.04%	77.35%	68.92%	70.00%	70.93%	65.58%	64.14%	65.91%ω	8.37%	6.96%	1.35%	9.27%	4.14%	3.81%	7.63%	2.52%	8.51%(b) Adversarial noise									PGD		1-step			10-step			loss=10	LTT		78.87%			64.32%			56.17%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	79.20%	79.19%	77.92%	60.26%	55.37%	52.81%	64.45%	61.30%	55.57%ω	2.49%	5.62%	10.33%	38.28%	42.76%	44.85%	42.47%	42.90%	47.45%(C) JPEG compression, q-compression qualityq		50	10			1			LTT		75.43%			66.37%			57.00%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	71.10%	74.68%	75.31%	66.57%	67.08%	66.81%	57.31%	57.51%	56.95%ω	9.02%	5.62%	2.17%	1.66%	7.47%	12.46%	10.97%	18.88%	23.11%(d) Scaling, r-scaling factor									
Table 7: Accuracies of current attacks on SVHN	Original	Gaussian(σ)			Adversarial			JPEG(q)			Scaling(r)			Filtering			Rotation(δ)				[0,0.1]	[0,0.2]	[0,0.3]	1-step	10-step	loss=10	50	10	1		0.5	1.5	10	Clarendon	Gingham	Moon	[0。, 10。]	[0。, 20。]	[0。, 30。]CC	55.65%	55.82%	55.99%	55.68%	63.90%	50.29%	50.29%	55.71%	56.14%	50.99%	56.40%	55.75%	55.72%	56.08%	55.58%	55.72%	55.84%	54.43%	52.55%LT	65.21%	63.24%	60.02%	58.38%	52.96%	49.99%	49.99%	63.39%	56.27%	50.47%	59.39%	64.11%	64.23%	61.77%	56.85%	59.74%	59.30%	55.10%	53.05%ST	64.54%	62.90%	59.97%	58.39%	53.26%	49.99%	49.99%	62.94%	56.39%	50.49%	59.24%	63.70%	63.80%	61.44%	57.17%	59.59%	59.07%	55.10%	53.10%ET	65.39%	63.43%	60.14%	58.44%	53.01%	49.99%	49.99%	63.53%	56.33%	50.47%	59.47%	64.25%	64.38%	61.90%	56.87%	59.86%	59.37%	55.13%	53.12%NN	65.89%	64.37%	60.45%	58.11%	50.46%	50.84%	50.59%	64.27%	56.25%	50.41%	59.48%	65.32%	65.13%	62.76%	55.50%	60.10%	59.97%	56.03%	53.73%Table 8:	Accuracies and coverage difference rates ω of our attacks on SVHN(a) Gaussian noise, σ- range of standard deviationσ		[0, 0.1]		[0, 0.2]				[0, 0.3]	LTT		63.49%			61.65%			60.09%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	58.38%	61.50%	65.06%	58.29%	60.49%	62.45%	57.47%	59.25%	60.03%ω	21.33%	21.35%	19.31%	22.93%	19.67%	14.82%	20.52%	15.31%	7.32%(b) Adversarial noise									PGD		1-step			10-step			loss=10	LTT		61.39%			52.03%			50.72%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	63.33%	61.52%	62.10%	56.02%	53.18%	51.35%	56.76%	56.98%	55.51%
Table 8:	Accuracies and coverage difference rates ω of our attacks on SVHN(a) Gaussian noise, σ- range of standard deviationσ		[0, 0.1]		[0, 0.2]				[0, 0.3]	LTT		63.49%			61.65%			60.09%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	58.38%	61.50%	65.06%	58.29%	60.49%	62.45%	57.47%	59.25%	60.03%ω	21.33%	21.35%	19.31%	22.93%	19.67%	14.82%	20.52%	15.31%	7.32%(b) Adversarial noise									PGD		1-step			10-step			loss=10	LTT		61.39%			52.03%			50.72%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	63.33%	61.52%	62.10%	56.02%	53.18%	51.35%	56.76%	56.98%	55.51%ω	11.86%	1.29%	8.15%	25.55%	32.16%	39.61%	40.71%	43.60%	45.09%(C) JPEG compression, q-compression qualityq		50		10			1		LTT		63.55%			57.47%			50.92%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	58.28%	61.44%	65.22%	57.69%	58.74%	58.67%	51.62%	52.21%	52.68%ω	21.52%	21.42%	19.89%	27.25%	21.69%	11.78%	6.09%	9.94%	13.56%(d) Scaling, r-scaling factor									
Table 9: Accuracies of current attacks on defended models(a) Weight decay	Original	[0,0.1]	Gaussian(σ) [0,0.2]	[0,0.3]	Adversarial			JPEG(q)			Scaling(r)			Filtering			Rotation(δ)							1-step	10-SteP	loSS=10	50	10	1		0.5	1.5	10	Clarendon	Gingham	Moon	[0。, 10。]	[0。, 20。]	[0。, 30。]CC	60.98%	60.50%	58.59%	57.03%	58.54%	50.13%	50.13%	58.60%	54.54%	51.17%	52.55%	59.16%	59.35%	60.67%	59.54%	59.73%	58.63%	56.16%	54.60%LT	61.33%	60.53%	58.19%	56.34%	56.01%	50.11%	50.11%	57.94%	53.52%	50.78%	51.86%	58.61%	58.90%	61.11%	59.31%	59.26%	58.32%	55.81%	54.23%ST	61.35%	60.55%	58.20%	56.34%	56.06%	50.12%	50.12%	57.92%	53.52%	50.78%	51.90%	58.63%	58.90%	61.02%	59.30%	59.27%	58.32%	55.78%	54.23%ET	61.33%	60.55%	58.19%	56.32%	56.02%	50.11%	50.11%	57.95%	53.54%	50.79%	51.86%	58.63%	58.89%	61.11%	59.33%	59.24%	58.33%	55.81%	54.23%NN	57.81%	57.21%	55.41%	53.53%	46.96%	49.86%	49.89%	54.76%	51.14%	49.88%	50.32%	54.83%	55.26%	57.26%	55.71%	55.73%	55.09%	53.23%	52.29%(b) DP																				Original		Gaussian(σ)			AdverSarial			JPEG(q)			Scaling(r)			Filtering			Rotation(δ)			[0,0.1]	[0,0.2]	[0,0.3]	1-step	10-step	loSS=10	50	10	1	0.5	15	10	Clarendon	Gingham	Moon	[0。, 10。]	[0。, 20。]	[0。, 30。]CC	50.67%	50.70%	50.62%	50.48%	50.15%	50.00%	50.00%	50.63%	50.50%	50.24%	50.34%	50.59%	50.58%	50.70%	50.52%	50.62%	50.63%	50.70%	50.51%LT	50.79%	50.72%	50.79%	50.53%	50.18%	50.01%	50.01%	50.72%	50.46%	50.30%	50.27%	50.70%	50.74%	50.88%	50.68%	50.68%	50.70%	50.66%	50.53%ST	50.55%	50.54%	50.45%	50.32%	50.17%	50.04%	50.04%	50.31%	50.26%	50.08%	50.25%	50.61%	50.65%	50.59%	50.43%	50.50%	50.46%	50.28%	50.19%ET	50.86%	50.73%	50.82%	50.53%	50.23%	50.00%	50.00%	50.72%	50.49%	50.28%	50.35%	50.79%	50.81%	50.94%	50.69%	50.69%	50.74%	50.68%	50.57%NN	49.82%	49.93%	50.10%	50.14%	49.63%	50.07%	50.17%	49.90%	50.05%	50.18%	49.97%	50.23%	50.09%	49.92%	50.01%	50.08%	50.13%	50.14%	50.18%16Under review as a conference paper at ICLR 2022Table 10:	Accuracies and coverage difference rates ω of our attacks on CIFAR-10 models trained
Table 10:	Accuracies and coverage difference rates ω of our attacks on CIFAR-10 models trainedwith large weight decay rate(a) Gaussian noise, σ- range of standard deviationσ		[0, 0.1]		[0,0.2]				[0, 0.3]	LTT		60.57%			58.50%			56.88%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	50.08%	50.07%	50.09%	49.91%	50.02%	50.08%	50.27%	50.06%	50.07%ω	49.40%	49.66%	49.83%	48.86%	49.82%	50.28%	49.33%	50.43%	50.12%(b) Adversarial noise									PGD		1-step			10-step			loss=10	LTT		60.33%			50.75%			50.75%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	50.06%	49.82%	50.04%	50.05%	50.06%	50.10%	50.04%	49.77%	49.74%ω	48.98%	50.19%	50.26%	50.04%	49.98%	50.21%	50.30%	50.34%	49.82%(C) JPEG compression, q-compression qualityq		50		10			1		LTT		58.50%			54.65%			51.39%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	50.26%	50.27%	49.74%	49.90%	50.17%	49.95%	50.27%	50.11%	50.07%ω	48.94%	50.48%	49.82%	48.97%	49.64%	49.72%	49.81%	50.17%	50.10%
Table 11:	Accuracies and coverage difference rates ω of our attacks on CIFAR-10 models trainedwith DP(a) Gaussian noise, σ- range of standard deviationσ		[0, 0.1]		[0,0.2]				[0, 0.3]	LTT		50.76%			50.64%			50.61%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	50.22%	50.25%	50.02%	49.95%	50.01%	50.37%	50.19%	49.96%	50.04%ω	47.32%	50.06%	49.92%	47.61%	50.18%	49.62%	48.22%	50.05%	49.99%(b) Adversarial noise									PGD		1-step			10-step			loss=10	LTT		50.76%			50.67%			50.67%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	50.14%	50.06%	49.96%	50.04%	50.11%	49.79%	50.08%	49.96%	50.07%ω	47.98%	49.57%	49.79%	49.47%	49.93%	50.07%	49.05%	49.86%	49.76%(C) JPEG compression, q-compression qualityq		50	10			1			LTT		50.70%			50.50%			50.27%		0.1	0.01	0.001	0.1	0.01	0.001	0.1	0.01	0.001RT	49.96%	50.08%	50.05%	50.17%	50.05%	50.28%	49.98%	50.11%	50.12%ω	46.91%	49.38%	50.12%	47.48%	50.05%	49.52%	47.81%	50.25%	49.71%
