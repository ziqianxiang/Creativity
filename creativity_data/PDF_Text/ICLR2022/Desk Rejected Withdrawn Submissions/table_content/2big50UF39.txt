Table 1: Notations with DescriptionsNotation	DescriptionX	Set of training bag instancesY	Binary random variable denoting bag labelsXi	ith instance present in a bag BX+	ithinstancepresentiπapositivebag∏PosX-	jth instance present in a negative bag BnegH	Entropyt	Binary label of the lth labeled instancetB	Binary value indicating bag typen	Total number of instances in a bag BBpos	A positive bags in the training setBneg	A negative bags in the training setW	Network ParametersVrn	Empirical Varianceσ2	Population VariancePn	Uncertainty setP	n-dimensional vector weights associated with each bag instancesDf	f-divergence indicating the distance between two distributionsf	Functional mapping of the Network parameterized by W
Table 2: Bag level distributions on different datasetsSplit	20NewsGroup		Cifar10		Cifar100		Pascal VOC		Positive	Negative	Positive	Negative	Positive	Negative	Positive	NegativeTrain	30	30	-500-	-500-	-500-	500	-124-	-124-Test	20	20	100	100	100	100	84	847570⅛65≡6055(b) β = 1StePFigure 7: Impact of key model parameters: (a-b) Cifar10; (c-d) 20NewsGroupE Additional Experimental ResultsIn this section, we first give a detailed description of the datasets. We then present additional ablationstudy results that complement the ones presented in the main paper. Finally, we demonstrate somequalitative examples where our approach is able to sample the true positive instance from the bagcontaining outlier but Maximum-Entropy can not.
