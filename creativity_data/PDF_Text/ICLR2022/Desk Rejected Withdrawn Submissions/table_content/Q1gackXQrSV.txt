Table 1: Results on language grounding in 3D point clouds. We evaluate top-1 accuracy usingground-truth (GT) or detected (Det) boxes under 0.25 threshold. * denotes method uses extra 2Dimage features. t denotes evaluation with detected boxes using the authors' code and checkpoints. ^denotes re-training using the authorsâ€™ code.
Table 2: Results on language grounding in Flickr30k 2D images using Recall@k metric and com-putational efficiency. All training times are computed using same V100 GPU machines. Trainingepochs and GPU Hours are written as x + y where x = number of pre-training epochs or GPU hoursand y = number of fine-tuning epochs or GPU Hours.
Table 3: Results on language grounding in 2D RefCOCO Dataset on accuracy metric usingstandard val/testA/testB splits. All training times are computed using same V100 GPU machines.
Table 4: Ablation of design choices for our model on 2D RefCOCO dataset and 3D SR3Ddatasets: Note that in these results our model is trained only on RefCOCO and not pre-trained onmultiple datasets.
Table 5: Performance Analysis on SR3D. Accuracy on SR3D for our model and ablative variantsdepending on whether the detector did (3rd column) or failed (4th column) to detect the target. Wemention the number of training epochs needed for each model to converge to optimal performancein the validation set.
