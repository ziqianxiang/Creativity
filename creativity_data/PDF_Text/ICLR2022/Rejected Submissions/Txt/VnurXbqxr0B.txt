STRIC: Stacked Residuals of Interpretable Compo-
nents for Time Series Anomaly Detection
Anonymous authors
Paper under double-blind review
Ab stract
We present a residual-style architecture for interpretable forecasting and anomaly detection in mul-
tivariate time series. Our architecture is composed of stacked residual blocks designed to separate
components of the signal such as trends, seasonality, and linear dynamics. These are followed by
a Temporal Convolutional Network (TCN) that can freely model the remaining components and
can aggregate global statistics from different time series as context for the local predictions of each
time series. The architecture can be trained end-to-end and automatically adapts to the time scale of
the signals. After modeling the signals, we use an anomaly detection system based on the classic
CUMSUM algorithm and a variational approximation of the f -divergence to detect both isolated
point anomalies and change-points in statistics of the signals. Our method outperforms state-of-
the-art robust statistical methods on typical time series benchmarks where deep networks usually
underperform. To further illustrate the general applicability of our method, we show that it can be
successfully employed on complex data such as text embeddings of newspaper articles.
1	Introduction
Time series data is being generated in increasing volumes from industrial, medical, commercial and scientific appli-
cations. Such growth is fueling demand for anomaly detection algorithms that are general enough to be applicable
across domains, yet reliable enough to operate on real-world time series data (Munir et al., 2019; Geiger et al., 2020;
Su et al., 2019). While recent developments have focused on deep neural networks (DNNs), simple linear models
still outperform DNNs in applications that require robustness (Braei & Wagner, 2020) and interpretable failure modes
(Geiger et al., 2020; Su et al., 2019).
To harvest the flexibility and interpretability of engineered modules while enabling end-to-end differentiable training,
we introduce STRIC: Stacked Residuals of Interpretable Components. We follow standard practice and consider a two
stage anomaly detection pipeline comprising a model of the normal time series and an anomaly detector based on the
prediction residuals (Munir et al., 2019). In particular, STRIC is composed of three modules: An interpretable local
predictor, a non-linear predictor and a novel non-parametric anomaly detector.
More specifically, STRIC uses a parametric model implemented by a sequence of residuals blocks with each layer
capturing the prediction residual of previous layers. The first layer models trends, the second layer models quasi-
periodicity/seasonality at multiple temporal scales, the third layer is a general linear predictor, and the last is a general
non-linear model in the form of a Temporal Convolution Network (TCN). While the first three layers are local (i.e.
applied to each component of the time series separately), the last integrates global statistics from additional time series
(covariates). Thanks to the residual structure the interpretable linear blocks do not reduce the representative power
of our non-linear architecture: any component of the input time-series which cannot be modeled by the interpretable
blocks is processed deeper into our architecture by the non-linear module (see Section 4). The model is trained end-to-
end with a prediction loss and we automatically select its complexity using an upper bound of the marginal likelihood
which, to the best of our knowledge, has never been applied to TCNs before.
Anomalies are detected by checking for time instants in which the prediction residual is not stationary. To avoid any
unrealistic assumption on the prediction residuals distribution, we use a likelihood ratio test that we derive from a
variational upper bound of f -divergences and that can be computed directly from the data points.
To summarize, our contributions are:
1
1.	We introduce STRIC, a stacked residual model that explicitly isolates interpretable factors such as slow
trends, quasi-periodicity, and linearly predictable statistics (Oreshkin et al., 2019; Cleveland et al., 1990), and
incorporates statistics from other time series as context/side information.
2.	We introduce a novel regularization that is added to the prediction loss and is used for automatic model
complexity selection according to the Empirical Bayes framework (Rasmussen & Williams, 2006).
3.	We introduce a non-parametric extesion of the CUMSUM algorithm which entails a tunable parameter corre-
sponding to the length of observation and enables anomaly detection in the absence of knowledge about the
pre- and post-distributions.
4.	We test our method on standard anomaly detection benchamrks and show it merges both the advantages of
simple and interpretable linear models and the flexibility of non-linear ones while discounting their major
drawbacks: lack of flexibility of linear models and lack of interpretability and overfitting of non-linear ones.
2	Related work
A time series is an ordered sequence of data points. We focus on discrete and regularly spaced time indices, and thus
we do not include literature specific to asynchronous time processes in our review. Different methods for time series
anomaly detection (TSAD) can be taxonomized by their choice of (i) discriminant function, (ii) continuity criterion,
and (iii) optimization method to determine the tolerance threshold. It is common to use statistics of the prediction
error as the discriminant (Braei & Wagner, 2020), and the likelihood ratio between the distribution of the prediction
error before and after a given time instant as the continuity criterion (Yashchin, 1993). Recent methods compute the
discriminant using deep neural network architectures and euclidean distance as continuity criterion (Munir et al., 2019;
Geiger et al., 2020; Su et al., 2019; Bashar & Nayak, 2020).
Our method follows a similar line but introduces novel elements both in (i) and (ii): (i) the discriminant function is
the prediction error residual of a novel regularized stacked residual architecture; (ii) the decision function is based on
a novel non-parametric extension of the CUMSUM algorithm. The resulting method, STRIC, has the advantage of
separating interpretable components due to trends and seasonality, without reducing the representative power of our
architecture. At initialization, the system is approximately equivalent to a multi-scale SARIMA model (Adhikari &
Agrawal, 2013), which can be reliably applied out-of-the-box on most time series. However, as more data is acquired,
any part of the system can be further fine-tuned in an unsupervised end-to-end fashion.
Munir et al. (2019) argue that anomaly detection can be solved by exploiting a flexible model provided a proper
inductive bias is introduced (e.g. TCN). In Appendix A.7.2 we show that TCN alone might overfit simple time series.
We therefore take their direction a step further, and, differently from previous works (Bai et al., 2018; Munir et al.,
2019; Sen et al., 2019; Geiger et al., 2020), we provide our temporal model with an interpretable structure, similar to
Oreshkin et al. (2019). Moreover, unlike previous works on interpretability of DNNs (Tsang et al., 2018; Guen et al.,
2020), our architecture explicitly imposes both an inductive bias and a regularization which are designed to expose
the user both a STL-like decomposition (Cleveland et al., 1990) and the relevant time scale of the signals. Since
TCNs tend to overfit if not properly regularized (Appendix A.7.2), we constrain our TCN’s representational power by
enforcing fading memory (Zancato & Chiuso, 2021) while retaining what is needed to predict future values.
Our method outperforms both classical statistical methods (Braei & Wagner, 2020) and deep networks (Munir et al.,
2019; Geiger et al., 2020; Su et al., 2019; Bergman & Hoshen, 2020; Bashar & Nayak, 2020) on different anomaly
detection benchmarks (Laptev & Amizadeh, 2020; Lavin & Ahmad, 2015) (Section 6). Moreover, we show it can be
employed to detect anomalous patterns on complex data such as text embeddings of newspaper articles (Figure 4).
3	Notation
We denote vectors with lower case and matrices with upper case. In particular y is multi-variate time series {y(t)}t∈Z,
y(t) ∈ Rn; we stack observations from time t to t + k - 1 and denote the resulting matrix as Ytt+k-1 := [y(t), y(t +
1), ..., y(t + k - 1)] ∈ Rn×k. The row index refers to the dimension of the time series while the column index refers
to the temporal dimension. We denote the i-th component of the time series y as yi and its evaluation at time t ad as
yi (t) ∈ R. We refer to {y(s), s > t} as the test/future and to {y(s), s ≤ t} as the reference/past intervals. At time t,
sub-sequences containing the np past samples up to time t - np + 1 are given by Ytt-n +1 (note that we include the
2
(a) STRIC predictor architecture.
Layer inputs
Z ∈ { XTREND, XSEAS，XLIN }
Layer filters banks
φ ∈ { ^^TREND，箔SEAS，箔LIN }
=H
φ =H
Layer features selectors
A ∈ {^TREND，^SEAS，凶LIN}	卜1
A = ∖τl
Layer predictors
耳一
For each
i = 1,..., n
Time Features
Future Predictor
φ 1* Zi
φ 2* Zi
Φι * Zi
Gi
碎Gi
OTGibi ∈
以 l× nP
(b) Interpretable blocks structure. Time features are
extracted independently for each time series (see Ap-
pendix A.1 for more details).
a
B ∈ { WTREND，砥SEAS，WLIN}
B = bT
∈
∈
以1× n
鼠
present data into the past data), while future samples up to time t + nf are Ytt++1nf . We will use past data to predict
future ones, where the length of past and future intervals is an hyper-parameter that is up to the user to design.
4	Temporal Residual Architecture
Our architecture is depicted in Figure 1a. Its basic building blocks are causal convolutions (Bai et al., 2018), with
a fixed-size 1-D kernel with input elements from time t and earlier. Rather than initializing the convolutional filter
randomly, as commonly done in deep learning, we initialize the weights so that each layer is biased to attend at
different components of the signal, as explained in the following.
Linear module. The first (linear) module is interpretable and captures local statistics of a given time series by means
of a cascade of learnable linear filters. Its first layer models and removes slow-varying components in the input
data. We initialize the filters to mimic a causal Hodrick Prescott (HP) filter (Ravn & Uhlig, 2002). The second layer
models and removes periodic components: it is initialized to have a periodic impulse response. Finally, the third layer
implements a linear stationary filter bank.
We treat the impulse responses parameters of the linear filters as trainable parameters. To allow our model to work on
a wide variety of time scales, we initialize the trend layer with different HP smoothness degrees, while we initialize
the periodic and linear-stationary layers with randomly chosen poles (Farahmand et al., 2017) both on the unit circle
and within the unit circle, thus allowing to capture different periodicities.
Non-linear module. The second (non-linear) module aggregates global statistics from different time series using
a TCN model (Sen et al., 2019). It takes as input the prediction residual of the linear module and outputs a matrix
G(Ytt-np+1) ∈ Rl×np where l is the number of output features extracted by the TCN model. The column G(Ytt-np+1)j
with j = 1, ..., np of the non-linear features is computed using data up to time t - np + j (due to the internal structure
of a TCN network (Bai et al., 2018)). We build a linear predictor on top of G(Ytt-n +1) for each single time series
independenty: the predictor for the i-th time series is given by: yτcN(t + 1)i := af G(Yt-np+ι)bi where a% ∈ Rl and
bi ∈ Rnp . Since ai combines features (uniformly in time) we can interpret it as a feature selector. While bi aggregates
relevant features across time indices to build the one-step ahead predictor (see Appendix A.1).
Note that the third layer of the linear module is a superset of preceding ones, and the non-linear module is a superset
of the whole linear module. While this makes the model redundant, we show that this design, coupled with proper
initialization and regularization, improves the reliability and intepretability of the final model. We improve filters
optimization by sharing their kernel parameters among different time series so that global information (e.g., common
trend shapes, periodicities) can be extracted. In Appendix A.1, we describe each component of the model in detail.
3
4.1	Automatic Complexity Determination
Consider the TCN-based future predictor be yτcN(t + 1) ：= aτG(Yt-np+ι)b = XTCNb where XTCN ∈ R1×np is the
output of the TCN block which depends on the the past window Ytt-np+1 of length np (the memory of the predictor).1
Ideally, np should be large enough to capture the “true” memory of the time series, but should not be too large if not
necessary (i.e. bias variance trade-off). In practice however, flexible feature extractors (such as TCNs or plain DNNs)
are prone to overfitting. Therefore, some regularization is needed to control model complexity and benefit from having
a large memory window. In this section, we introduce a novel regularized loss inspired by Bayesian arguments which
allows us to use an architecture with a “large enough” past horizon np (i.e., larger than the true system memory)
and automatically select the relevant past to avoid overfitting. Such information is exposed to the user through an
interpretable parameter λ that directly measures the relevant time scale of the signal.
Bayesian learning formulation: We model the innovations (optimal prediction errors) as Gaussian, so that y(t + 1) |
Y-np+ι 〜N (F *(Y-np+1)),η2) where F * is the optimal predictor of the future values given the past. Note that this
modeling assumption does not restrict our framework and is used only to justify the use of the squared loss to learn
the regression function of the predictor. In practice, we do not know F* and we approximate it with our parametric
model. For ease of exposition, we group all the architecture parameters except b in W (linear filters parameters, TCN
kernel parameters etc.) and write the conditional likelihood of the future given the past data of our parametric model
as p(Ytt++1nf | b, W, Ytt-np+1) = Qkn=f 1 p(y(t + k) |b,W,Ytt++kk--n1p).
To make the notation simpler, we shall denote with Yf ：= Ytt++1nf ∈ Rnf the set of future outputs over which the
predictor is computed and We shall use Yb,w ∈ Rnf as the predictor,s outputs.
In a Bayesian framework, the optimal set of parameters can be found maximizing the posterior p(b, W | Yf) over the
model parameters. We model b and W as independent random variables:
p(b, W | Yf) H P(Yf | b, W)p(b)p(W)	(1)
where p(b) is the prior associated to the predictor coefficients andp(W) is the prior on the remaining parameters. The
prior p(b) should encode our belief that the prediction model should not be too complex and should depend only on the
most relevant past. We model this by assuming that the components of b have zero mean and exponentially decaying
variances: Eb2n -j-1 = κλj for j = 0, ..., np - 1, where κ ∈ R+ and λ ∈ (0, 1). The corresponding maximum
entropy prior Pλ,κ(b) (Cover & Thomas, 1991) under such constraints is log(pλ,κ(b)) h 一 ∣∣b∣∣Λ-ι — log(∣Λ∣) where
Λ ∈ Rnp is a diagonal matrix with elements Λj,j = κλj with j = 0, ..., np. Here, λ represents how fast the output
of the predictor “forgets” the past. Therefore, λ regulates the complexity of the predictor: the smaller λ, the lower the
complexity.
In practice, λ has to be estimated from the data. One would be tempted to estimate jointly b, W, λ, κ (and possibly η)
by minimizing the negative log of the joint posterior (see Appendix A.2.1). Unfortunately, this leads to a degeneracy
since the joint negative log posterior goes to -∞ when λ → 0. Indeed, typically the parameters describing the prior
(such as λ) are estimated by maximizing the marginal likelihood, i.e., the likelihood of the data once the parameters
(b, W) have been integrated out. Since computing (or even approximating) the marginal likelihood in this setup is
prohibitive, we now introduce a variational upper bound to the marginal likelihood which is easier to estimate.
Variational upper bound to the marginal likelihood: The model structure we consider is linear in b and we can
therefore stack the predictions of each available time index t to get the following linear predictor on the whole future
data available: Yb,w = FWb where F ∈ Rnf ×np is obtained by stacking XTCN(Yi-“+ι) for i = t,...,t + nf 一 1.
Proposition 4.1. Consider a model on the form: Yb,w = FW b (linear in b and possibly non-linear in W) and its
posterior in Equation (1). Assume the prior on the parameters b is given by the maximum entropy prior and W is
fixed. Then the following is an upper bound on the marginal likelihood associated to the posterior in Equation (1)
with marginalization taken only w.r.t. b:
Ub,W,Λ = n2 UY/ 一 Yb,w]l + b>A - 1b + logdet(FWλfW + η2I).	⑵
This (proved in Appendix A.2) provides an alternative loss function to the negative log posterior which does not suffer
of the degeneracy alluded above while optimizing over b, W, λ and κ.
1For simplicity we consider scalar time series, but our approach easily generalizes to multivariate time series (Appendix A.2.2).
4
Remark: We use batch normalization (Ioffe & Szegedy, 2015) to normalize the output of FW along its rows so that
features have comparable scales, this avoids the TCN network to counter the fading regularization by increasing its
output scales (see Appendix A.2.3).
5 Anomaly detector
In this section, we present our anomaly detection method based on a variational approximation of the likelihood ratio
between two windows of model residuals. Our temporal residual architecture model produces the prediction residual
after removing trends, periodicity, and stationary (linear) components, as well as considering global covariates. Such a
prediction residual is used to test the hypothesis that the time instant t is anomalous by comparing its statistics before
t on temporal windows of length np and nf . The detector is based on the likelihood ratios aggregated sequentially
using the classical CUMSUM algorithm (Page, 1954; Yashchin, 1993). CUMSUM, however, requires knowledge
of the distributions, which we do not have. Unfortunately, the problem of estimating the densities is hard (Vapnik,
1998) and generally intractable for high-dimensional time series (Liu et al., 2012). We circumvent this problem by
directly estimating the likelihood ratio with a variational characterization of f -divergences (Nguyen et al., 2010) which
involves solving a convex risk minimization problem in closed form.
In Section 5.1, we summarize the standard material necessary to derive our new estimator and the resulting anomaly
test. The overall method is entirely unsupervised, and users can tune the scale parameter (corresponding to the window
of observation when computing the likelihood ratios) and the coefficient of CUMSUM (depending on the application
and desired operating point in the tradeoff between missed detection and false alarms).
5.1	Likelihood Ratios and CUMSUM
CUMSUM (Page, 1954) is a classical Sequential Probability Ratio Test (SPRT) (Basseville & Nikiforov, 1993; Liu
et al., 2012) of the null hypothesis H0 that the data after the given time c comes from the same distribution as before,
against the alternative hypothesis Hc that the distribution is different. We denote the distribution before c as pp and
the distribution after the anomaly at time c as pf .
If the density functions pp and pf were known (we shall relax this assumption later), the optimal statistic to decide
whether a datum y(i) is more likely to come from one or the other is the likelihood ratio s(y(i)). According to the
Neyman-Pearson lemma, H0 is accepted if the likelihood ratio s(y(i)) is less than a threshold chosen by the operator,
otherwise Hc is chosen. In our case, the competing hypotheses are H0 = “no anomaly has happened” and Hc = “an
anomaly happened at time c”. We denote with pH0 and pHc the p.d.f.s under H0 and Hc so that: pH0 (Y1K) = pp(Y1K)
and pHc (Y1c-1) = pp(Y1c-1), pHc (YcK | Y1c-1) = pf (YcK | Y1c-1). Therefore the likelihood ratio is:
Qt .= PHc(Yt) = Pp(YcT)Pf(Yt | YcT) = Pf (Yt | Yc-1) = YtT Pf (y(i) | YiT)
c PHo(Yt)	Pp(Yt)	Pp(YtIYcT) L pp(y(i | Yi-1)
(3)
To determine the presence of an anomaly, We can compute the cumulative sum Sc := logΩc of the (log) likelihood
ratios, which depends on the time c, and estimate C using a maximum likelihood criterion, corresponding to the
detection function ht = max1≤c≤t Sct. The first instant at Which We can confidently assess the presence of a change
point (a.k.a. stopping time) is: cstop = min{t : ht ≥ τ} where τ is a design parameter that modulates the sensitivity
of the detector depending on the application. The final estimate C of the true change point C after the detection 々top
is simply given by the timestamp c at which the maximum of ht = max1≤c≤t Sct is achieved. In Appendix A.3,
we provide an alternative derivation that shows that CUMSUM is a comparison of the test statistic with an adaptive
threshold that keeps complete memory of past ratios. The next step is to relax the assumption of known densities,
which we bypass in the next section by directly approximating the likelihood ratios to compute the cumulative sum.
5.1.1	Likelihood ratio estimation with Pearson divergence
The goal of this section is to tackle the problem of estimating the likelihood ratio of two general distributions Pp and
Pf given samples. To do so, we leverage a variational approximation of f -divergences (Nguyen et al., 2010) whose
optimal solution is directly connected to the likelihood ratio. For different choices of divergence function, different
estimators of the likelihood ratio can be built. We focus on a particular divergence choice, the Pearson divergence,
since it provides a closed form estimate of the likelihood ratio (see Appendix A.4).
5
Proposition 5.1. (Nguyen et al., 2010; Liu et al., 2012) Let φ := pf /pp be the likelihood ratio of the unknown
distributions Pf and pp. Let F := {f : f 〜Pf, i = 1,…，nf} and H := {hi : hi 〜pp,i = 1,…，np} be two sets
containing nf and np samples i.i.d. from Pf and Pp respectively. An empirical estimator φ of the likelihood ratio φ is
given by the solution to the following convex optimization problem:
φ) = arg min ɪ X φ(hi)2 — — X φ(fi)	(4)
φ	2np i=1	nf i=1
Proposition 5.2. (Liu et al., 2012; Kanamori et al., 2009) Letφ in Equation (4) be chosen in the family of Reproducing
Kernel Hilbert Space (RKHS) functions Φ induced by the kernel k. Let the kernel sections be centered on the set of
data Str := {F, H} and let the kernel matrices evaluated on the data from Pf and Pp be Kf := K(F, Str) and
Kp := K(H, Str). The optimal regularized empirical likelihood ratio estimator on a new datum e is given by:
φ(e) = n K(e, Str )(KT Kp + npγInp+nj-1 KTK	(5)
Remark: The estimator in Equation (5) is not constrained to be positive. Nonetheless, the positivity constraints can
be enforced. In this case, the closed form solution is no longer valid but the problem remains convex.
5.2 Subspace likelihood ratio estimation and CUMSUM
In this section, we present our anomaly detector estimator. We test for an anomaly in the data Y1t by looking at the
prediction residuals E1t , which provide a sufficient representation of Y1t (see Appendix A.5). We therefore assume
we are given the prediction errors E1t obtained from our time series predictor (the predictor should model the normal
behaviour). This guarantees that the sequence E1t is white in each of its normal subsequences. On the other hand, if
the model is applied to a data subsequence which contains the abnormal condition, the residuals are correlated.
We estimate the likelihood ratio of Pf and Pp on a datum et as φt(et). φt is obtained by applying Equation (5)
on the past window of size np + nf. At each time instant t, we compute the necessary kernel matrices as
Kf(Ett-nf+1,Ett-np-nf+1)andKp(Ett--nnpf-nf+1, Et-np -nf +1 ).
Remark: At time t, the likelihood ratio is estimated assuming i.i.d. data. This assumption holds if no anomaly
happened but does not hold in the abnormal situation since residuals are not i.i.d. In Appendix A.5, we prove that
treating correlated variables as uncorrelated provides a lower bound on the actual cumulative sum of likelihood ratios.
For a fixed threshold, this means the detector cumulates less and therefore requires more time to reach the threshold.
Finally, We compute the detector function by aggregating the estimated likelihood ratios: Sc := Pt=Clog φi(ei).
Remark: The choice of the windows length (np and nf ) is fundamental and highly influences the likelihood estimator.
Using small WindoWs makes the detector highly sensible to point outliers, While larger WindoWs are better suited to
estimate sequential outliers (see Appendix A.5).
6	Experimental Results
In this section, We shoW STRIC can be successfully applied to detect anomalous behaviours on different anomaly
detection benchmarks. In particular, We test our novel residual temporal structure, the automatic complexity regu-
larization and the anomaly detector on the folloWing datasets: Yahoo (Laptev & Amizadeh, 2020), NAB (Lavin &
Ahmad, 2015), CO2 Dataset (see Appendix A.6). In addition, to shoW the general applicability and flexibility of our
method, We test STRIC on the challenging task of detecting anomalous events in time series generated from embed-
dings of articles from the NeW York Times. See Appendix A.7 for the experimental setup and data normalization.
Anomaly detection: While recent Works shoW deep learning models are not Well suited to solve AD on standard
anomaly detection benchmarks (Braei & Wagner, 2020), We prove deep models can be effective provided they are used
With a proper inductive bias and regularization. In Table 1, We compare STRIC against statistical and deep learning
based anomaly detection methods. Our experiments folloW the experimental setup and evaluation criteria used in Braei
& Wagner (2020) and Munir et al. (2019). Note no other method performs consistently (across different datasets) as
good as STRIC. In particular, STRIC achieves the best F1 score on Yahoo A3, in Appendix A.7 We shoW this is mainly
6
Table 1: Comparison with SOTA anomaly detectors: We compare STRIC with other anomaly detection methods
(see Appendix A.8) on the experimental setup and the same evaluation metrics proposed in (Braei & Wagner, 2020;
Munir et al., 2019). The baseline models are: MA, ARIMA, LOF (Shen et al., 2020), LSTM (Braei & Wagner,
2020; Munir et al., 2019), Wavenet (Braei & Wagner, 2020) , Yahoo EGADS (Munir et al., 2019) , GOAD (Bergman
& Hoshen, 2020), OmniAnomaly (Su et al., 2019), Twitter AD (Munir et al., 2019), TanoGAN (Bashar & Nayak,
2020), TadGAN (Geiger et al., 2020) , DeepAR (Flunkert et al., 2017) and DeepAnT (Munir et al., 2019) . STRIC
outperforms most of the other methods based on statistical models and based on DNNs. See Table 6 for the same table
obtained by looking at the relative performance w.r.t. STRIC.
F1-score	Yahoo A1	Yahoo A2	Yahoo A3	Yahoo A4	NAB Tweets	NAB Traffic
ARIMA	0.35	0.83	0.81	0.70	0.57	0.57
LSTM	0.44	0.97	0.72	0.59		
Yahoo EGADS	0.47	0.58	0.48	0.29		
OmniAnomaly	0.47	0.95	0.80	0.64	0.69	0.70
Twitter AD	0.48	0	0.26	0.31		
TanoGAN	0.41	0.86	0.59	0.63	0.54	0.51
TadGAN	0.40	0.87	0.68	0.60	0.61	0.49
DeepAR	0.27	0.93	0.47	0.45	0.54	0.60
DeepAnT	0.46	0.94	0.87	0.68		
STRIC (ours)	0.48	0.98	0.89	0.68	0.71	0.73
AUC	Yahoo A1	Yahoo A2	Yahoo A3	Yahoo A4	NAB Tweets	NAB Traffic
MA	0.868	0.994	0.994	0.986		
ARIMA	0.873	0.989	0.990	0.971		
LOF	0.904	0.901	0.641	0.640	0.491	0.428
Wavenet	0.824	0.761	0.580	0.592		
LSTM	0.812	0.735	0.578	0.589		
GOAD	0.893	0.921	0.888	0.866	0.572	0.641
DeepAnT	0.898	0.961	0.928	0.860	0.554	0.637
STRIC (ours)	0.931	0.999	0.999	0.935	0.658	0.685
due to STRIC’s predictor. In fact, most of the time series in Yahoo A3 are characterized by trend components and
seasonalities which STRIC’s interpretable predictor can easily model (see Appendix A.7.2). In Appendix A.7, we
show some ablation studies on the effects of STRIC’s hyper-parameters on its performance. In particular, we find that
STRIC is highly affected by the choice of the length of the windows used to estimate the likelihood ratio, while not
being much sensitive to the choice of the memory of the predictor (Appendix A.7.1). Interestingly, STRIC does not
achieve the optimal F1/AUC compared to linear models on Yahoo A4. The ability of linear models to outperform non-
linear ones on Yahoo A4 is known in the literature (e.g. in Geiger et al. (2020) any non-linear model is outperformed
by AR/MA models of the proper complexity). The main motivation for this is that modern (non-linear) methods tend
to overfit on Yahho A4 and therefore generalization is usually low. Instead, thanks to fading regularization and model
architecture, STRIC does not exhibit overfitting despite having larger complexity than SOTA linear models used in
A4. To conclude, we believe that STRIC merges both the advantages of simple and interpretable linear models and the
flexibility of non-linear ones while discounting their major drawbacks: lack of flexibility of linear models and lack of
interpretability and overfitting of non-linear ones (see Appendix A.8 for a more in depth discussion).
STRIC interpretable time series decomposition: In Figure 2, we show STRIC’s interpretable decomposition. We
report predicted signals (first row), estimated trends (second row) and seasonalities (third row) for different datasets.
For all experiments, we plot both training data (first 40% of each time series) and test data. Note the interpretable
components of STRIC generalize outside the training data, thus making STRIC work well on non-stationary time
series (e.g. where the trend component is non negligible and typical non linear models overfit, see Appendix A.7.2).
Ablation study: We now compare the prediction performance of a general TCN model with our STRIC method in
which we remove the interpretable module and the fading regularization one at the time. In Table 2, we report the test
RMSE prediction errors and the RMSE generalization gap (i.e. difference between test and training RMSE prediction
errors) for different datasets while keeping all the training parameters the same (e.g. training epochs, learning rates
etc.) and model parameters (e.g. nb = 100). The addition of the linear interpretable model before the TCN slightly
improves the test error. We note this effect is more visible on A2, A3, A4, mainly due to the non-stationary nature of
these datasets and the fact that TCNs do not easily approximate trends (Braei & Wagner, 2020) (we further tested this
7
C02 Dataset
Yahoo A3 Dataset
2
0
-2
660	680	700	720	740	760	780	800
NAB Dataset
100	150	200	250	300	350 400 450	500
350	400	450	500	550	600	650	700
X4=euose∂s
200	220	240	260	280	300	320	340	650 675	700 725	750 775	800 825	850	300	350 400 450	500	550	600	650	700
Timestamps	Timestamps	Timestamps
Figure 2: We test STRIC time series intepretability on different datasets (columns). In each panel, we show both
training data and test data (see colors). First row: STRIC time series predictor (output of non-linear module). Second
row: Trend components extracted by the interpretable blocks. Third row: Seasonal components extracted by the
interpretable blocks.
Table 2: Ablation study on the RMSE of prediciton errors: We compare Test error and Generalization Gap (Gap.) of
a standard TCN model with our STRIC predictor and some variation of it (using the same training hyper-parameters).
Standard deviations are given in Table 4.
TCN	TCN + Linear	TCN + Fading	STRIC pred
Test Gap. Test Gap. Test Gap. Test Gap.
-ωsπJπɑ
Yahoo A1	0.92	0.82	0.88	0.78	0.92	0.48	0.62	0.19
Yahoo A2	0.82	0.71	0.35	0.22	0.71	0.50	0.30	0.16
Yahoo A3	0.43	0.30	0.22	0.06	0.40	0.25	0.22	0.03
Yahoo A4	0.61	0.46	0.35	0.16	0.55	0.38	0.24	0.01
CO2 Dataset	0.62	0.48	0.45	0.30	0.61	0.43	0.41	0.08
NAB Traffic	1.06	1.03	1.00	0.96	0.93	0.31	0.74	0.11
NAB Tweets	1.02	0.84	0.98	0.78	0.83	0.36	0.77	0.07
in Appendix A.7.1). While STRIC generalization is always better than a standard TCN model and STRIC’s ablated
components, we note that applying Fading memory regularization alone to a standard TCN does not always improve
generalization (but never decreases it): this highlights that the benefits of combining the linear module and the fading
regularization together are not a trivial ‘sum of the parts’. Consider for example Yahoo A1: STRIC achieves 0.62 test
error, the best ablated model (TCN + Linear) 0.88, while TCN + Fading does not improve over the baseline TCN. A
similar observation holds for the CO2 Dataset. Fading regularization might not be beneficial (nor detrimental) for time
series containing purely periodic components which correspond to infinite memory systems (systems with unitary
fading coefficient). In such cases the interpretable module is essential in removing the periodicities and providing
the regularized non-linear module (TCN + Fading) with an easier to model residual signal. We refer to Figure 2 (first
column) for a closer look on a typical time series in CO2 dataset, which contains a periodic component that is captured
by the seasonal part of the interpretable model. To conclude, our proposed fading regularization has (on average) a
beneficial effect in controlling the complexity of a standard TCN model and reduces its generalization gap (≈ 40%
reduction). Moreover, coupling fading regularization with the interpretable module guarantees the best generalization.
Automatic complexity selection: In Figure 3, we test the effects of our automatic complexity selection (fading mem-
ory regularization) on STRIC. We compare STRIC with a standard TCN model and STRIC without regularization as
the memory of the predictor increases. The test error of STRIC is uniformly smaller than a standard TCN (without in-
terpretable blocks nor fading regularization). Adding interpretable blocks to a standard TCN improves generalization
for a fixed memory w.r.t. standard TCN but gets worse (overfitting occurs) as soon as the available past data horizon
increases. On the other hand, the generalization gap of STRIC does not deteriorate as the memory of the predictor
increases (see Appendix A.7.1 for a comparison with other metrics).
8
1.0
Figure 3: Automatic complexity selec-
tion: Fading memory regularization pre-
serves generalization gap as the memory
of the predictor np increases on NAB
Tweets.
----2000 election
——9/11 attack
----Iraq occupation
--2004 election
----Indian Ocean tsunami
----Housing bubble
--Saddam Hussein's death
Figure 4: Anomaly score on the New York Times dataset. Our
method finds anomalies in a complex time series consisting of the
BERT embedding of articles from the New York Times. Peaks in
the anomaly score correspond to historical events that sensibly
changed the content of the news cycle.
Anomaly detection on the New York Times dataset: We qualitatevly test STRIC on a time series consisting of
BERT embeddings (Devlin et al., 2019) of New York Times articles (Sandhaus, 2008) from 2000 to 2007. We set
np = nf = 30 days, to be able to detect change-point anomalies that altered the normal distribution of news articles
for a prolonged period of time. Without any human annotation, STRIC is able to detect major historical events such
as the 9/11 attack, the 2004 Indian Ocean tsunami, and U.S. elections (Figure 4). Note that we do not carry out a
quantitative analysis of STRIC’s predictions, as we are not aware of any ground truth or metrics for this benchmark,
see for example Rayana & Akoglu (2015). Additional details and comparison with a baseline model built on PCA are
given in Appendix A.8.1.
7	Discussion and conclusions
We have shown that our interpretable stacked residual architecture and our unsupervised estimation of the likelihood
ratio are well suited to solve AD for multivariate time series data. Unlike purely DNN-based methods (Geiger et al.,
2020; Munir et al., 2019; Bashar & Nayak, 2020), STRIC exposes to the user both an interpretable STL-like time series
decomposition (Cleveland et al., 1990) and the relevant time scale of the time series. Both the interepretable module
and the fading memory regularization are important in building a successful model (see Table 2). In particular, the
interpretable module helps STRIC generalize correctly on non-stationary time series on which standard deep models
(such as TCNs) may overfit (Braei & Wagner, 2020). Moreover, we showed that our novel fading regularization alone
can improve the generalization error of TCNs up to ≈ 40% over standard TCNs, provided the periodic components
of the time series are captured by the interpretable module (Section 6). We highlight that the overall computational
complexity and memory requirement of our method remains the same as standard TCNs, so that our approach can
easily scale to large scale time series datasets.
An anomaly is a time instant: at that time instant, either we receive an isolated observation that is inconsistent with
normal operation (outlier measurement), or a discrete change occurs in the mechanism that generates the data (change-
point) that persists beyond that time instant (Geiger et al., 2020; Basseville & Nikiforov, 1993). Our method treats
these two phenomena in a unified manner, without the need to differentiate between outliers and setpoint changes,
with specialized detectors for each. Once the predictor is built, our method can be used online to detect anomalies
soon after occurrence without waiting for the entire data stream to be observed and without requiring any knowledge
on the prediction error distribution (nominal and faulty).
Making the non-parametric anomaly detector fully adaptive to the data is an interesting research direction: While our
fading window regularizer automatically tunes the predictor’s window length by exploiting the self-supervised nature
of the prediction task, methods to automatically tune the detector’s window lengths (an unsupervised problem) are
an interesting research direction. Moreover, designing statistically optimal rules to calibrate our detector’s threshold
τ depending on the desired operating point in the tradeoff between missed detection and false alarms would further
enhance the out-of-the-box robustness of our method.
9
Reproducibility Statement: Our method has been tested on publicly available datasets: Yahoo (Laptev & Amizadeh,
2020), NAB (Lavin & Ahmad, 2015), CO2 Dataset (see Appendix A.6) and NYT (Sandhaus, 2008). We described the
data splitting and the data processing steps in Appendix A.7. We describe the major details regarding the implemen-
tation of our novel method in Appendix A.1 while in Appendix A.7 we describe both the model structure and training
hyper-parameters we used in the experimental section. We do not include the model structures and hyper-parameters
of SOTA methods we used as baselines and refer to related literature (referenced in our work) for the implementation
details. To further foster reproducibility we shall make our code available.
References
Ratnadip Adhikari and R. K. Agrawal. An introductory study on time series modeling and forecasting. CoRR,
abs/1302.6613, 2013. URL http://arxiv.org/abs/1302.6613.
Shaojie Bai, J Zico Kolter, and Vladlen Koltun. An empirical evaluation of generic convolutional and recurrent
networks for sequence modeling. arXiv preprint arXiv:1803.01271, 2018.
Md Abul Bashar and Richi Nayak. Tanogan: Time series anomaly detection with generative adversarial networks. In
2020 IEEE Symposium Series on Computational Intelligence (SsCI), pp. 1778-1785. IEEE, 2020.
Michele Basseville and Igor V. Nikiforov. Detection OfAbruPt Changes: Theory andApplication. Prentice-HalL Inc.,
USA, 1993. ISBN 0131267809.
Liron Bergman and Yedid Hoshen. Classification-based anomaly detection for general data. In International Confer-
ence on Learning Representations, 2020. URL https://openreview.net/forum?id=H1lK_lBtvS.
Ane Biazquez-Garcia, Angel Conde, UsUe Mori, and Jose A Lozano. A review on outlier/anomaly detection in time
series data. arXiv preprint arXiv:2002.04236, 2020.
Mohammad Braei and Sebastian Wagner. Anomaly detection in univariate time-series: A survey on the state-of-the-art.
CoRR, abs/2004.00433, 2020. URL https://arxiv.org/abs/2004.00433.
Robert B. Cleveland, William S. Cleveland, Jean E. McRae, and Irma Terpenning. Stl: A seasonal-trend decomposition
procedure based on loess (with discussion). Journal of Official Statistics, 6:3-73, 1990.
T. M. Cover and J. A. Thomas. Elements of Information Theory. Series in Telecommunications and Signal Processing.
Wiley, 1991.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirectional trans-
formers for language understanding. In Jill Burstein, Christy Doran, and Thamar Solorio (eds.), Proceedings of
the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human
Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short
Papers), pp. 4171-4186. Association for Computational Linguistics, 2019. doi: 10.18653/v1/n19-1423. URL
https://doi.org/10.18653/v1/n19-1423.
Amir-massoud Farahmand, Sepideh Pourazarm, and Daniel Nikovski. Random projection filter bank
for time series data. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vish-
wanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 30.
Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/
ca3ec598002d2e7662e2ef4bdd58278b- Paper.pdf.
Valentin Flunkert, David Salinas, and Jan Gasthaus. Deepar: Probabilistic forecasting with autoregressive recurrent
networks. CoRR, abs/1704.04110, 2017. URL http://arxiv.org/abs/1704.04110.
Alexander Geiger, Dongyu Liu, Sarah Alnegheimish, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni. Tadgan:
Time series anomaly detection using generative adversarial networks. arXiv preprint arXiv:2009.07769, 2020.
Vincent Le Guen, Yuan Yin, Jeremie Dona, Ibrahim Ayed, Emmanuel de Bezenac, Nicolas Thome, and Patrick
Gallinari. Augmenting physical models with deep networks for complex dynamics forecasting. arXiv preprint
arXiv:2010.04456, 2020.
10
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal
covariate shift. CoRR, abs/1502.03167, 2015. URL http://arxiv.org/abs/1502.03167.
Takafumi Kanamori, Shohei Hido, and Masashi Sugiyama. A least-squares approach to direct importance estimation.
Journal of Machine Learning Research, 10(48):1391-1445, 2009. URL http://jmlr.org/papers/v10/
kanamori09a.html.
Nikolay Laptev and Saeed Amizadeh. Yahoo! webscope dataset ydata-labeled-time-series-anomalies-v1_0. CoRR,
2020. URL https://webscope.sandbox.yahoo.com/catalog.php?datatype=s&did=70.
Alexander Lavin and Subutai Ahmad. Evaluating real-time anomaly detection algorithms - the numenta anomaly
benchmark. CoRR, abs/1510.03336, 2015. URL http://arxiv.org/abs/1510.03336.
Song Liu, Makoto Yamada, Nigel Collier, and Masashi Sugiyama. Change-point detection in time-series data by
relative density-ratio estimation. In Structural, Syntactic, and Statistical Pattern Recognition, pp. 363-372, Berlin,
Heidelberg, 2012. Springer Berlin Heidelberg. ISBN 978-3-642-34166-3.
Mohsin Munir, Shoaib Ahmed Siddiqui, Andreas Dengel, and Sheraz Ahmed. Deepant: A deep learning approach
for unsupervised anomaly detection in time series. IEEE Access, 7:1991-2005, 2019. doi: 10.1109/ACCESS.2018.
2886457.
XuanLong Nguyen, Martin J. Wainwright, and Michael I. Jordan. Estimating divergence functionals and the likelihood
ratio by convex risk minimization. IEEE Transactions on Information Theory, 56(11):5847-5861, Nov 2010. ISSN
1557-9654. doi: 10.1109/tit.2010.2068870. URL http://dx.doi.org/10.1109/TIT.2010.2068870.
Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, and Yoshua Bengio. N-BEATS: neural basis expansion analysis
for interpretable time series forecasting. CoRR, abs/1905.10437, 2019. URL http://arxiv.org/abs/1905.
10437.
Ewan S Page. Continuous inspection schemes. Biometrika, 41(1/2):100-115, 1954.
CE. Rasmussen and CKI. Williams. Gaussian Processes for Machine Learning. Adaptive Computation and Machine
Learning. MIT Press, Cambridge, MA, USA, January 2006.
Morten Ravn and Harald Uhlig. On adjusting the hodrick-prescott filter for the frequency of observations. The Review
of Economics and Statistics, 84:371-375, 02 2002. doi: 10.1162/003465302317411604.
Shebuti Rayana and Leman Akoglu. Less is more: Building selective anomaly ensembles with application to event
detection in temporal graphs. In Suresh Venkatasubramanian and Jieping Ye (eds.), Proceedings of the 2015 SIAM
International Conference on Data Mining, Vancouver, BC, Canada, April 30 - May 2, 2015, pp. 622-630. SIAM,
2015. doi: 10.1137/1.9781611974010.70. URL https://doi.org/10.1137/1.9781611974010.70.
Evan Sandhaus. The new york times annotated corpus ldc2008t19. web download. Linguistic Data Consortium,
Philadelphia, 6(12):e26752, 2008.
Rajat Sen, Hsiang-Fu Yu, and Inderjit S Dhillon. Think globally, act locally: A deep neural network
approach to high-dimensional time series forecasting. In H. Wallach, H. Larochelle, A. Beygelzimer,
F. d'Alche-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems, vol-
ume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/
3a0844cee4fcf57de0c71e9ad3035478- Paper.pdf.
Lifeng Shen, Zhuocong Li, and James Kwok. Timeseries anomaly detection using temporal hi-
erarchical one-class network. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and
H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 13016-13026.
Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/
97e401a02082021fd24957f852e0e475-Paper.pdf.
Ya Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, and Dan Pei. Robust anomaly detection for multivariate
time series through stochastic recurrent neural network. In Proceedings of the 25th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining, KDD ’19, pp. 2828-2837, New York, NY, USA, 2019.
Association for Computing Machinery. ISBN 9781450362016. doi: 10.1145/3292500.3330672. URL https:
//doi.org/10.1145/3292500.3330672.
11
Michael E Tipping. Sparse bayesian learning and the relevance vector machine. Journal of machine learning research,
1(Jun):211-244, 2001.
Michael Tsang, Hanpeng Liu, Sanjay Purushotham, Pavankumar Murali, and Yan Liu. Neural interaction transparency
(nit): Disentangling learned interactions for improved interpretability. In S. Bengio, H. Wallach, H. Larochelle,
K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems, vol-
ume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper/2018/file/
74378afe5e8b20910cf1f939e57f0480-Paper.pdf.
Vladimir N. Vapnik. Statistical Learning Theory. Wiley-Interscience, 1998.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim
Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick Von Platen, Clara Ma, Yacine Jernite,
Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush.
Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing: System Demonstrations, pp. 38T5, Online, October 2020. Association
for Computational Linguistics. URL https://www.aclweb.org/anthology/2020.emnlp-demos.6.
Emmanuel Yashchin. Performance of cusum control schemes for serially correlated observations. Technometrics, 35
(1):37-52, 1993. ISSN 00401706. URL http://www.jstor.org/stable/12 692 8 8.
Luca Zancato and Alessandro Chiuso. A novel deep neural network architecture for non-linear system identification.
IFAC-PapersOnLine, 54(7):186-191, 2021. ISSN 2405-8963. doi: https://doi.org/10.1016/j.ifacol.2021.08.356.
URL https://www.sciencedirect.com/science/article/pii/S2405896321011307. 19th
IFAC Symposium on System Identification SYSID 2021.
A	Appendix
A. 1 Implementation
Given two scalar time series X and φ, we denote their time convolution g as: g(t):=(夕 *χ)(t) := P∞=-∞ 夕(i)χ(t-i).
We say that g is the causal convolution of X and 夕 if 夕(t) = 0 for t < 0, so that the output g(t) does not depend
on future values of x (w.r.t. current time index t). In the following, we shall give a particular interpretation to the
signals X and 夕：X will be the input signal to a filter parametrized by an impulse response 夕(kernel of the filter). Note
any (causal) convolution is defined by an infinite summation for each given time t. Therefore it is customary, when
implementing convolutional filters, to consider a truncated sum of finite length. In practice, this is obtained assuming
the filter impulse response is non-zero only in a finite window. The truncation is indeed an approximation of the
complete convolution, nonetheless it is possible to prove that the approximation errors incurred due to truncation are
guaranteed to be bounded under simple assumptions. To summarize, in the following we shall write g(t):=(夕 * χ)(t)
and mean that the impulse response of the causal filter 夕 is truncated on a window of a given length.
A.1.1 Architecture
Let Ytt-np+1 ∈ Rn×np be the input data to our architecture at time step t (a window of np past time instants). The
main blocks of the architecture are defined to encode trend, seasonality, stationary linear and non-linear part. In the
following we shall denote each quantity related to a specific layer using either the subscripts {TREND, SEAS, LIN,
TCN} or {0, 1, 2, 3}.
We shall denote the input of each block as Xk ∈ Rn×np and the output as Xk ∈ Rn×np for k = 0,1,2,3. The residual
architecture we propose is defined by the following: X。= Yt_rLp+r and Xk = Xk-ι — Xk-ι for k = 1, 2, 3. At each
layer we extract lk temporal features from the input Xk. We denote the temporal features extracted from the input of
the k-th block as: Gk := Gk(Xk) ∈ Rlk×rp. The i-th column of the feature matrix Gk is a feature vector (of size lk)
extracted from the input Xk up to time t - np - i. To do so, we use causal convolutions of the input signal Xk with a
set of filter banks (Bai et al., 2018).
12
A∙l∙2 INTERPRETABLE RESlDUAL TCN Oz SCALAR TIME SERlES
Modenng InterPretabIe blocks 二 n this SeCtwe Sha= describe the madesign Criteria Ofthe linear modulFol-
each interpretabie Iayer (TRENDy SEALINwe COnVVe the input Signal With a filter bank designed to extract
specific COmPOIIeIltS Ofthe input∙
For exam门 COlISiderthe trend IayeL denoting its SCalar input time SerieS by 七 and its OUtPUt by gτREND∙ Then
9trend is defined as a multidimensIIal time SerieS (Of dimension ZTREND 可) ObtaiIled by StaCkgtime SerieS
given by the COIlVOIUtiOIl Of 七 WithCaUSaIHIlear filter 沼 弋 TRENDM *for QUO::7— LlIl Other word9TREND
TRENDl 弋 TREND2 *七；二弋 TRENDh *WedelIOtethe SetOfHllearfnterS 弋 TRENEH foUO ::0 — 1 as /CTREND
and ParametriZe each inter《TREND With its truncated impulse response (in，kemel) oengthU 亨 REND∙
We interpret each time SerieSiIl ^TREND as an approximation Ofthe trend COmPOlIent Of 七 COmPUted With thethter
We design each 弋 TRENEH SO that each filter extracts the trend Ofthe input SigOn diKerent time SCaIeS (RaVIl 浮 Uhli
2002) (Lee each filter OUtPUtS a Signal With a different SmOothIIeSS degreeWe estimate the trend Ofthe input Signal by
recombining the extracted trend COmPOlIentSiIl ^TREND With the HIlear map QTREND，MOreoVeLWe PrediC二he future
trend Ofthe input SigIlal (OIl the IleX 二 imetamp) With the linear map bτREND∙
We COlIStrUCtthe blocks that extract SeaSOIIaHty and Hllear PartiIl a SimiIar way∙
ImPlementing InterPretable blocksiThe input Of each Iayer is given by a WiIldOW Of measurements OfIeIlgth np.
We zero—Pad the input SigIlal SO that the COIIVOiUtiOIl Ofthe input SigIlal With the Q—th filter is a SigIlaI OfIeIlgth s⅛ (IIote
thistroduces a SPUriOUS transient WhOSe Iength is the Iength Ofthe filter kernelWe therefore have the flling
temporal feature matrice 沼 GOU GTREND m 冠OX 好GlU GSEAS m 冠1X0 andG2 H GLIN m 冠2>⅛∙
The OUtPUt Of eachyeris an estimate Ofthe tre∏a SeaSOIIaI S StatiOIlary linear COmPOIIent Ofthe input SigIIaI on
the PaStiIlterVaI OfIeIlgth np.SO that We have xm 如(Same dimension as the input xOIl the Other handy the
linear PrediCtOrCOmPUted at each IayeriS a SCaIarIntUitiVely"andShoUId be COIISidered as the best Hllear
approximation Ofthe tre∏a SeaSOnaHty oinear Part given blocks filter bank in the PaSt and future，OUr architecture
PerfOnnS the following COmPUtatiOIlE..口舄Gk and ek.l xbfor RUO" L 2 Where J m 为冢 a^d bm 为好 p∙
NOte <⅜ COmbilIeSfeatUreS (UllifonnIytime) SO that We Can interpret it as a feature SeleCtorWhiIe F aggregates
relevant features across different time indices to build the One—step ahead PrediCtOrDePendilIg Onthe time SCaIe Of
the SigIIalSitiS POSSibIe to ChoOSe F depending Onthe time hideX (SimiIarly to the fading memory regularization
We experimented both the ChOiCe to make F canonical avecrq and dense vectorWe found that ChOOSing F as
canonical vectorWhoSe IIOl1—zero entry is associated to the CIOSeSttO the PreSenttime instat PrOVideS good empirical
results on most case
NonLinear module The IIOlI—linear module is based OIla StaIldard TCN IletWOrk∙ Itsinput is defined as X3 H
κp+l — X。— Xi — X2" WhiCh is to be COIISidered as a Signal WhoSe linearly predictable COmPOlIenthaS been
removed，The TCN extracts a Set Of 才 IIOII—linear features G3(X3) m 冠3x∕ WhiCh We COmbe With HIlear maps
as done for the PreViOUSlayerTheth column Ofthe IIOll—linear features G3 is COmPUted USg data UP to time
什——∏p + j (due to the internal StrUCtUre Of a TCN IletWOrk (Bai et a - 2018)The HIlear PrediCtOr OIltOP Of Gd is
QTCN UG3bWhere Q3 m ¾ω æid S m0∙
na=y=he OUtPUt Of OUrtime model is given b
33 3
E + 1) U, HXA⅛ H'Gk(XkW k.
=0=0=0
A∙l∙3 INTERPRETABLE RESlDUAL TCN Oz MULTl—DIMENSIONAL TIME SERlES
We extend OUr architecture to muldimensnal time SerieS according to the following PriIlCie 沼 PreSerVe inter—
PretabiHty (first module) and exploit global information to make IOCal PrediCtiOIlS (SeCOIld module
In this SeCtiOI‰ the input data to OUrmodeIiS YL目十一 m (a WiIldOW OfIeIlgth s⅛ from an Tzldimensional time
series
InterPretabIe module EaCh time SerieS UlIdergOeS the SeqUenCe Of 3 interpretable blocksdependently from Other
time SerieS二he filter banks are applied to each time SerieS independently Therefor尸 each time SerieSiS PrOCeSSed by
13
the same filter banks: KTREND, KSEAS and KLIN. For ease of notation we shall now focus only on the trend layer. Any
other layer is obtained by substituting ‘TREND’ with the proper subscript (‘SEAS’ or ‘LIN’).
We denote by GTREND, i ∈ Rl0×np the set of time features extracted by the trend filter bank KTREND from the i-th
time series. Each feature matrix is then combined as done in the scalar setting using linear maps, which we now index
by the time series index i: aTRENDi and bTRENDi . The rationale behind this choice is that each time series can exploit
differently the extracted features. For instance, slow time series might need a different filter than faster ones (chosen
using aTRENDi) or might need to look at values further in the past (retrieved using bTRENDi). We stack the combination
vectors aTRENDi and bTRENDi into the following matrices: ATREND = [aTREND1, aTREND2, ..., aTRENDn]T ∈ Rn×l0 and
BTREND = [bTREND1, bTREND2, ..., bTRENDn]T ∈ Rn×np.
Non-linear module: The second (non-linear) module aggregates global statistics from different time series (Sen
et al., 2019) using a TCN model. It takes as input the prediction residual of the linear module and outputs a matrix
GTREND(Ytt-np+1) ∈ Rl3×np where l3 is the number of output features that are extracted by the TCN model (which
is a design parameter). The j-th column of the non-linear features GTREND(Ytt-n +1) is computed using data up to
time t - p + j , where p is the “receptive” field of the TCN (p < np). This is due to the internal structure of a TCN
network (Bai et al., 2018) which relies on causal convolutions and typically scales as O(2h) where h is the number of
TCN hidden layers (the deeper the TCN the longer its receptive field). As done for the time features extracted by the
interpretable blocks, we build a linear predictor on top of GTREND(Ytt-np+1) for each single time series independenty:
the predictor for the i-th time series is given by: yτcN(t + 1)i := aτGTREND(Y-n +ι)bi where a ∈ Rl3 and b ∈ Rnp.
We stack the combination vectors aTCNi and bTCNi into the following matrices: ATCN = [aTCN1, aTCN2, ..., aTCNn]T ∈
Rn×l3 and BTCN = [bTCN1, bTCN2, ..., bTCNn]T ∈ Rn×np.
Finally, the outputs of the predictor on the i-th time series are given by:
y(t + 1)i =	ɪ2 akT Gkibki + aTCNTGTCNbTCNi.
k∈{TREND,SEAS,LIN}
A.1.4 Block structure and initialization
In this section, we shall describe the internal structure and the initialization of each block.
Structure: Each filter is implemented by means of depth-wise causal 1-D convolutions (Bai et al., 2018). We call the
tensor containing the k-th block’s kernel parameters Kk ∈ Rlk ×Nk, where lk and Nk are the block’s number of filters
and block’s kernel size, respectively (without loss of generality, we assume all filters have the same dimension). Each
filter (causal 1D-convolution) is parametrized by the values of its impulse response parameters (kernel parameters).
When we learn a filter bank, we mean that we optimize over the kernel values for each filter jointly. For multidimen-
sional time series, we apply the filter banks to each time series independently (depth-wise convolution) and improve
filter learning by sharing kernel parameters across different time series.
Initialization: The first block (trend) is initialized using l0 causal Hodrick Prescott (HP) filters (Ravn & Uhlig, 2002)
of kernel size N0. HP filters are widely used to extract trend components of signals (Ravn & Uhlig, 2002). In general
a HP filter is used to obtain from a time series a smoothed curve which is not sensitive to short-term fluctuations and
more sensitive to long-term ones (Ravn & Uhlig, 2002). In general, a HP filter is parametrized by a hyper-parameter
λHP which defines the regularity of the filtered signal (the higher λHP, the smoother the output signal). We initialize
each filter with λHP chosen uniformly in log-scale between 103 and 109. Note the impulse response of these filters
decays to zero (i.e., the latest samples from the input time series are the most influential ones). When we learn the
optimal set of trend filter banks, we do not consider them parametrized by λHP and search for the optimal λHP. Instead,
we optimize over the impulse response parameters of the kernel which we do not assume live in any manifold (e.g.,
the manifold of HP filters). Since this might lead to optimal filters which are not in the class of HP filters, we impose
a regularization which penalizes the distance of the optimal impulse response parameters from their initialization.
The second block (seasonal part) is initialized using l1 periodic kernels which are obtained as linear filters whose poles
(i.e., frequencies) are randomly chosen on the unit circle (this guarantees to span a range of different frequencies). Note
the impulse responses of these filters do not go to zero (their memory does not fade away). Similarly to the HP filter
bank, we do no optimize the filters over frequencies, but rather we optimize them over their impulse response (kernel
parameters). This optimization does not preserve the strict periodicity of filters. Therefore, in order to keep the optimal
impulse response close to initialization values (purely periodic), we exploit weight regularization by penalizing the
distance of the optimal set of kernel values from initialization values.
14
The third block (stationary linear part) is initialized using l2 randomly chosen linear filters whose poles lie inside
the unit circle, as done in (Farahmand et al., 2017). As the number of filters l2 increases, this random filter bank is
guaranteed to be a universal approximator of any (stationary) linear system (see (Farahmand et al., 2017) for details).
Remark: This block could approximate any trend and periodic component. However, we assume to have factored out
both trend and periodicities in the previous blocks.
The last module (non-linear part) is composed by a randomly initialized TCN model. We employ a TCN model due to
its flexibility and capability to model both long-term and short-term non-linear dependencies. As is standard practice,
we exploit dilated convolutions to increase the receptive field and make the predictions of the TCN (on the future
horizon) depend on the most relevant past (Bai et al., 2018).
Remark: Our architecture provides an interpretable justification of the initialization scheme proposed for TCN in
(Sen et al., 2019). In particular our convolutional architecture allows us to handle high-dimensional time series data
without a-priori standardization (e.g., trend or seasonality removal).
A.2 Automatic Complexity Determination (fading memory regularization)
In this section, we shall introduce a regularization scheme called fading regularization, to constrain TCN representa-
tional capabilities.
The output of the TCN model is G(Ytt-n +1) ∈ Rl3×np where l3 is the number of output features extracted by the
TCN model. The predictor build from TCN features is given by: aTCNiTGTCN(Ytt-np+1)bTCNi, where the predictor
bTCNi ∈ Rnp takes as input a linear combination of the TCN features (weighted by aTCNi). The j-th column of the
non-linear features G(Ytt-np+1) is computed using data up to time t - np + j (due to causal convolutions used in the
internal structure of the TCN network (Bai et al., 2018)). One expects that the influence on the TCN predictor as j
increases should increase too (in case j = np, the statistic is the one computed on the closest window of time w.r.t.
present time stamp). Clearly, the exact relevance on the output is not known a priori and needs to be estimated. In
other words, the predictor should be less sensitive to statistics (features) computed on a far past, a property which is
commonly known as fading memory. Currently, this property is not built in the predictor bTCNi , which treats each
time instant equally and might overfit while trying to explain the future by looking into far and possibly non-relevant
past. In order to constrain model complexity and reduce overfitting, we impose the fading memory property on our
predictor by employing a specific regularization which we now describe.
A.2.1 Fading memory in scalar time series
We now follow the same notation and assumptions used in Section 4.1 which we now repeat for completeness.
We consider a scalar time series so that the TCN-based future predictor given the past np measures can be written
as: yTCN(t + I) = aTGTCN(Ttt-np + 1)b = Xk b. We shall assume that innovations (optimal prediction errors) are
Gaussian, so that y(t + 1) | Yt-诋+1 〜 N (F *(Yt-np+1)),η2), where F * is the optimal predictor of the future
values given the past. Note that this assumption does not restrict our framework and is used only to justify the use
of the squared loss to learn the regression function of the predictor. In practice, we do not know the optimal F*
and we approximate it with our parametric model. For ease of exposition, we group all the architecture parameters
except b in the weight vector W (linear filters parameters KTREND, KSEAS, KLIN, linear module recombination weights
ATREND, ASEAS , ALIN, BTREND , BSEAS , BLIN, and TCN kernel parameters and recombination coefficients ATCN etc.).
We write the conditional likelihood of the future given the past data of our parametric model as:
nf
p(Ytt++1nf | b, W, Ytt-np+1) = Yp(y(t+k) |b,W,Ytt++kk--n1p)	(6)
k=1
To make the notation simpler, we shall denote by Yf := Ytt++1nf ∈ Rnf the set of future outputs over which the predictor
is computed and We shall use Yb,w ∈ Rnf as the predictor,s outputs. Moreover, We shall drop the dependency on the
conditioning past Ytt-np+1 (which is present in any conditional distribution). Equation (6) becomes: p(Yf | b, W) =
Qkn=f 1 p(y(t + k) | b, W). The optimal set of parameters b* and W* in a Bayesian frameWork is computed by
maximizing the posterior on the parameters given the data:
p(b, W | Yf) H P(Yf | b, W)p(b)p(W)	(7)
15
where p(b) is the prior on the predictor and p(W) is the prior on the remaining parameters. We encode in p(b) our
prior belief that the complexity of the predictor should not be too high and therefore it should only depend on the most
relevant past.
Remark: The prior does not induce hard constraints. It rather biases the optimal predictor coefficients towards the
prior belief. This is clear by looking at the negative log-posterior which can be directly interpreted as the loss function
to be minimized: - log p(b, W | Yf) = - log p(Yf | b, W) - log p(b) - log p(W). In particular, the first term
log p(Yf | b, W) is the data fitting term (only influenced by the data). Both log p(b) and log p(W) do not depend on
the available data and can be interpreted as regularization terms that bound the complexity of the predictor function.
The main idea is to reduce the sensitivity of the predictor on time instants that are far in the past. We therefore enforce
the fading memory assumption on p(b) by assuming that the components of b ∈ Rnp have zero mean and exponentially
decaying variances:
Ebj = 0 and Eb2n -j-1 = κλj forj = 0, ..., np - 1
(8)
where κ ∈ R+ and λ ∈ (0, 1). Note the larger variance (larger scale) is associated to temporal indices close to the
present time t.
Remark: To specify the prior, we need a density function p(b) but up to now we only specified constraints on the first
and second order moments. We therefore need to constrain the parametric family of prior distributions we consider.
Any choice on the class of prior distributions lead to different optimal estimators. Among all the possible choices of
prior families we choose the maximum entropy prior (Cover & Thomas, 1991). Under constraints on first and second
moment, the maximum entropy family of priors is the exponential family (Cover & Thomas, 1991). In our setting, we
can write it as:
logPλ,κ(b) « - ∣b∣Λ-ι - log ∣Λ∣
where Λ ∈ Rnp×np is a diagonal matrix whose elements are Λj,j = κλj forj = 0, ..., np - 1.
(9)
The parameter λ represents how fast the predictor’s output ‘forgets’ the past: the smaller λ, the lower the complexity.
In practice, we do not have access to this information and indeed we need to estimate λ from the data.
One would be tempted to estimate jointly W, b, λ, κ (and possibly η) by minimizing the negative log of the joint
posterior:
argmin g ∣∣Yf — Yb,w∣∣ +log(η2) — log(pλ,κ(B)) — log(p(W)).
b,W,λ,κ η2
(10)
Unfortunately, this leads to a degeneracy since the joint negative log posterior goes to -∞ when λ → 0.
Bayesian learning formulation for fading memory regularization:
The parameters describing the prior (such as λ) are typically estimated by maximizing the marginal likelihood, i.e., the
likelihood of the data once the parameters (b, W) have been integrated out. Unfortunately, the task of computing (or
even approximating) the marginal likelihood in this setup is prohibitive and one would need to resort to Monte Carlo
sampling techniques. While this is an avenue worth investigating, we preferred to adopt the following variational
strategy inspired by the linear setup.
Indeed, the model structure we consider is linear in b and we can therefore stack the predictions of each available time
index t to get the following linear predictor on the whole future data: Yb,w = FWb where FW ∈ Rnf ×np and its rows
are given by XTCN(Yii-np+1) fori = t, ..., t + nf - 1.
We are now ready to find an upper bound to the marginal likelihood associated to the posterior given by Equation (7)
with marginalization taken only w.r.t. b.
Proposition A.1 (from (Tipping, 2001)). The optimal value of a regularized linear least squares problem with feature
matrix F and parameters b is given by the following equation:
argmin 3∣∣Yf - Fb∣∣2 + b>Λ-1 b = YfrΣ-1 Yf
(11)
with Σ := FΛF>AT + η2I.
Equation (11) guarantees that
"∣Yf - Fbk2 + brΛ-1b + log ∣∑∣ ≥ Y>∑-1Yf + log ∣∑∣,
16
where the right hand side is (proportional to) the negative marginal likelihood with marginalization taken only w.r.t. b.
Therefore, for fixed a W ,
η2 IIYf - Yb,w I + b>A-1b + log |FwAFW + η2I|
is an upper bound of the marginal likelihood with marginalization over b and does not suffer of the degeneracy alluded
at before.
With this considerations in mind, and inserting back the optimization over W , the overall optimization problem we
solve is
arg min 3∣∣Yf - Yb,w∣∣ + Wk：-1 + log ∣FwAFw + η2I| + logP(W)	(12)
b,W,λ∈(0,1),κ>0 η2	Λ
Remark: log p(W) defines the regularization applied on the remaining parameters of our architecture. In particular,
we induce sparsity by applying L1 regularization on ATREND, ASEAS, ALIN and ATCN. Also, we constrain filters
parameters to stay close to initialization by applying L2 regularization on KTREND , KSEAS and KLIN.
A.2.2 Fading memory in multivariate time series
In the case of multivariate time series, fading regularization can be applied either with a single fading coefficient λ
for all the time series or with different fading coefficients for each time series. In all the experiments in this paper,
we chose to keep one single λ for all the time series. In practice, this choice is sub-optimal and might lead to more
overfitting than treating each time series separately: the ‘dominant’ (slower) time series will highly influence the
optimal λ.
A.2.3 Features normalization
We avoid the non-identifiability of the product FWb by exploiting batch normalization: we impose that different
features have comparable means and scales across time indices i = 0, ..., np -1. Non-identifiability occurs due to
the product FWb, if features have different scales across time indices (i.e., columns of the matrix FW) the benefit of
fading regularization might reduced since it can happen that features associated with small bi have large scale so that
the overall contribution of the past does not fade. Hence we use batch normalization to normalize time features. Then
we use an affine transformation (with parameters to be optimized) to jointly re-scale all the output blocks before the
linear combination with b.
A.3 Alternative CUMSUM Derivation and Interpretation
In this section, we describe an equivalent formulation of the CUMSUM algorithm we derived in the main paper.
Before a change point, by construction We are under the distribution of the past. Therefore, log pf(y) ≤ 0 ∀y, which
pp (y)
in turn means that the cumulative sum S1t will decrease as t increases (negative drift). After the change, the situation is
opposite and the cumulative sum starts to show a positive drift, since we are sampling y(i) from the future distribution
pf . This intuitive behaviour shows that the relevant information to detect a change point can be obtained directly from
the cumulative sum (along timestamps). In particular, all we need to know is the difference between the value of the
cumulative sum of log-likelihood ratios and its minimum value.
The CUMSUM algorithm can be expressed using the following equations:	vt :=	S1t	-	mt, where mt	:=
minj,1≤j≤t Sjt. The stopping time is defined as: tstop = min{t : vt ≥ τ} =	min{t :	S1t	≥	mt + τ}. With	the
last equation, it becomes clear that the CUMSUM detection equation is simply a comparison of the cumulative sum of
the log likelihood ratios along time with an adaptive threshold mt +τ. Note that the adaptive threshold keeps complete
memory of the past ratios. The two formulations are equivalent because S1t - mt = ht .
A.4 Variational Approximation of the Likelihood Ratio
In this section, we present some well known facts on f -divergences and their variational characterization. Most of the
material and the notation is from (Nguyen et al., 2010). Given a probability distribution P and a random variable f
measurable w.r.t. P, we use fdP to denote the expectation of f under P. Given samples x(1), ..., x(n) from P, the
17
empirical distribution Pn is given by Pn = 1 PZi δχ(i). We use f fdPn as a convenient shorthand for the empirical
expectation 1 pn=ι f (χ(i)).
Consider two probability distributions P and Q, with P absolutely continuous w.r.t. Q. Assume moreover that both
distributions are absolutely continuous with respect to the Lebesgue measure μ, with densities po and qo, respectively,
on some compact domain X ⊂ Rd .
Variational approximation of the f-divergence: Thef -divergence between P and Q is defined as (Nguyen et al.,
2010)
Df (P, Q)
:= p0f
dμ
(13)
where f : R → R is a convex and lower semi-continuous function. Different choices off result in a variety of
divergences that play important roles in various fields (Nguyen et al., 2010). Equation (13) is usually replaced by the
variational lower bound:
Df(P,Q)≥ sup
φ∈Φ
/ [φdQ — f *(Φ)dP]
(14)
and equality holds iff the subdifferential ∂f (pq0) contains an element of Φ. Here f * is defined as the convex dual
function off .
In the following, we are interested in divergences whose conjugate dual function is smooth (which in turn defines
commonly used divergence measures such as KL and Pearson divergence), so that we shall assume that f is convex
and differentiable. Under this assumption, the notion of subdifferential is not required and the previous statement reads
as: equality holds iff ∂f (pq0) = φ for some φ ∈ Φ.
Remark: The infinite-dimensional optimization problem in Equation (14) can be written as Df (P, Q) =
supφ∈ΦEQφ-EPf*(φ).
In practice, one can have an estimator of any f -divergence restricted to a functional class Φ by solving Equation (14)
(Nguyen et al., 2010). Moreover, when P and Q are not known one can approximate them using their empirical
counterparts: Pn and Qn. Then an empirical estimate of the f -divergence is: Df (P, Q) = supφ∈Φ EQnφ -EPnf*(φ).
Approximation of the likelihood ratio: An estimate of the likelihood ratio can be directly obtained from the varia-
tional approximation of f -divergences. The key observation is the following: equality on Equation (14) is achieved iff
φ = ∂f (qp0). This tells us that the optimal solution to the variational approximation provides us with an estimator of
the composite function ∂f (qP0) of the likelihood ratio p0. As long as We can invert ∂f, We can uniquely determine the
likelihood ratio.
In the following, we shall get an empirical estimator of the likelihood ratio in two separate steps. We first solve the
following:
φn ：= arg max EQn φ - EPn f*(φ)	(15)
φ∈Φ
which returns an estimator of ∂f (pq0), not the ratio itself. And then We apply the inverse of ∂f to φn We therefore
have a family of estimation methods for the likelihood function by simply ranging over choices of f.
Remark: If f is not differentiable, then we cannot invert ∂f but we can obtain estimators of other functions of the
likelihood ratio. For instance, we can obtain an estimate of the thresholded likelihood ratio by using a convex function
whose subgradient is the sign function centered at 1.
A.4. 1 Likelihood ratio estimation with Pearson divergence
In this section, we show how to estimate the likelihood ratio when the Pearson divergence is used. With this choice,
many computations simplify and we can write the estimator of the likelihood ratio in closed form. Other choices (such
as the Kullback-Leibler divergence) are possible and legitimate, but usually do not lead to closed form expressions
(see (Nguyen et al., 2010)).
18
The Pearson, or χ2, divergence is defined by the following choice: f (t)
function is :
f *(v) = sup nuv —
u∈R
∙= (t-1)2
:=	2
+ v.
The associated convex dual
Therefore the Pearson divergence is characterized by the following:
PE(P||Q) :
∕p0 (p0 - 1) dμ ≥ sup Eqφ - 2Epφ2 - Epφ.
(16)
Solving the lower bound for the optimal φ provides Us an estimator of ∂f (pq0) = pq0 - 1. For the special case of
the Pearson divergence, we can apply a change of variables which preserves convexity of the variational optimization
problem Equation (16) and provides a more straightforward interpretation. Let the new variable be z := φ + 1 with
z ∈ Z, which in this case is nothing but the inverse function of ∂f. We get
sup EqΦ -	1 Epφ2	- Epφ =	sup EQz -	1 Epz2	- 1	(17)
φ∈Φ	2	z∈Z	2	2
It is now trivial to see that z is a ‘direct’ approximator of the likelihood ratio (i.e., it does not estimate a composite
map of the likelihood ratio). Therefore for simplicity, we shall employ
12
arg min -Epφ2 — Eqφ	(18)
φ∈Φ 2
to build our ‘direct’ estimator of the likelihood ratio.
Let the samples from P and Q be, respectively, xp (i) with i = 1, ..., np and xq(i) with i = 1, ..., nq. We define the
empirical estimator of the likelihood ratio φn
1 np	1 nq
Φn = arg min — fφ(xp(i))2-----------fφ(xf(i)).	(19)
φ∈Φ 2np i=1	nq i=1
A closed form solution: Up to now we have not defined in which class of functions our approximator φ lives. As
done in (Nguyen et al., 2010; Liu et al., 2012), we choose φ ∈ Φ where Φ is a RKHS induced by the kernel k.
We exploit the representer theorem to write a general function within Φ as:
ntr
φ() =k(x,xtr (i))αi ,
i=1
where we use ntr data which are the centers of the kernel sections used to approximate the unknown likelihood ratio
(how to choose these centers is important and determines the approximation properties of φn). For now, we do not
specify which data should be used as centers (we can use either data from Pn or from Qn or from both or simply use
user specified locations).
Let us define the following kernel matrices: Kp := K(Xp , Xtr) ∈ Rnp×ntr, Kq := K(Xq, Xtr) ∈ Rnq ×ntr, where
Xp := {xp(i)}, Xq:= {xq(i)} and Xtr :={xtr(i)}.
We therefore have:
Φn = arg min 21- X φ(xp(i))2 - j X φ(xf (i))
φ∈Φ	p i=1	q i=1
arg min —ɪ- Xp (Xtr
k(xp (i),xtr(j))αj)2
α,α≥0 2np i=1 j=1
-ɪ X Xk(xf (i),xtr(j))αj
nf
f i=1 j=1
arg min —ɪ-ατKTKpa--- ITKf α
α,α≥0 2np	nf
19
Remark: We impose the recombination coefficients α to be non negative since the likelihood ratio is a non negative
quantity. The resulting optimization problem is a standard convex optimization problem with linear constraints which
can be efficiently solved with Newton methods, nonetheless in general it does not admit any closed form solution.
We now relax the positivity constraints so that the optimal solution can be obtained in closed form. Moreover we add a
quadratic regularization term as done in (Nguyen et al., 2010) which lead us to the following regularized optimization
problem:
arg min
α
whose solution is trivially given by:
α= np (KTKp + npγIntr)-1KTl ：= npHTKTI	(20)
α-aTKpKPa-----ITKfα + ka llallΦ
2np	nf	2
The estimator of the likelihood ratio for an arbitrary location x is given by the following:
Pq (χ) ≈ φn (X) = K(X, Xtr )a = npK(X, Xtr ) (KTKp + npYInt)	KTI
(21)
Remark: In the following we shall exploit RBF kernels which are defined by the length scales σ.
A.5 Subspace likelihood ratio estimation and CUMSUM
In this section we describe our subspace likelihood ratio estimator and its relation to the CUMSUM algorithm. The
CUMSUM algorithm requires to compute the likelihood ratio Pf (y(t)%—) for each time t. We denote PP as the
pp(y(t)|Yct-1)	p
normal density and Pf as the abnormal one (after the anomaly has occurred).
We shall proceed to express the conditional probability P(y(t) | Y1t-1) using our predictor. In particular it is always
possible to express the optimal (unknown) one-step ahead predictor as:
yt∣t-1 = F *(Y-K+1)= E[y(t) | Y-K+1]	(22)
which is a deterministic function given the past of the time series (whose length is K). So that the data density
distribution can be written in innovation form (based on the optimal prediction error) as:
y(t) =F*(Ytt-K+1)+e(t)	(23)
where e(t) := y(t) - F*(Ytt-K+1) is, by definition, the one step ahead prediction error (or innovation sequence) of
y(t) given its past. We therefore have: P(y(t) | Ytt-K+1) = P(e(t) | Ytt-K+1). Where e(t) is the optimal prediction
error for each time t and is therefore indipendent on each time t.
Remark: In practice we do not know F * and we use our predictor learnt from normal data as a proxy. This implies
the prediction residuals are approximately independent on normal data (the predictor can explain data well), while the
prediction residuals are, in general, correlated on abnormal data.
To summarize: under normal conditions the joint distribution of Yct can be written as:
tt
P(Yct) = Y P(y(i) | Yci-1) = Y P(e(i))	normal conditions	(24)
i=c	i=c
tt
P(Yct) = Y P(y(i) | Yci-1) = Y P(e(i) | Eci-1)	abnormal conditions	(25)
i=c	i=c
These two conditions in turn influence the log likelihood ratio test as follows: under H =⇒ Qt=C /，(：(：)) while
under HC =⇒ Qt=C Pf (^((?怖；)).The main issue here is the numerator under Hc: the distribution of residuals
changes at each time-stamp (it is a conditional distribution) and Pf (e(i) | Eci-1) is difficult to approximate (it requires
the model of the fault). In the following we show that replacing Pf (e(i) | ECi-1) with Pf (e(i)) allows us to compute a
20
lower bound on the cumulative sum. Such an approximation is necessary to estimate the likelihood ratio in abnormal
conditions, the main downside of this approximation is that the detector becomes slower (it needs more time to reach
the stopping time threshold).
Applying the independent likelihood test in a correlated setting: We now show that treating pf (e(i) | Eci-1) as
independent random variables Pf (e(i)) for i = 1,…，t allows Us to compute a lower bound on the log likelihood log ΩC
(i.e. the cumulative sum). We denote the cumulative sum of the log likelihood ratio using independent variables as
W c = P=C log Ppgig
Proposition A.2. Assume a change happens at time c so that Hc is true and the following log likelihood ratio holds
true: log ΩC = Pt=c log Pf ；](；E)I) .Then it holds log Ω[ ≥ log Ω C.
Proof. By simple algebra we can write:
Pf(e(i | ECT) = Pf(e(i | ECT) Pf (Ki))	∀i
Pp(e(i))	Pf(Hi))	Pp(Hi))
Now recall the cumulative sum of the log-likelihood ratios taken under the current data generating mechanism Pf (E1t)
provides an estimate of the expected value of the log-likelihood ratio. Due to the correlated nature of data E1t the
samples are drawn from a multidimensional distribution of dimension t (a sample from this distribution is an entire
trajectory from c to t).
We now take the expectation of previous formula w.r.t. the ‘true’ distribution Pf (E1t):
K CtK IcoYY Pf(e(i) | ECT)
EPf(Et)Cc = EPf(Et) logIl —PP(e(i))一
—E lctʃrrPf(e(i) | ECT) i E	lnOYYPf(e(i))
=EPf (Ec) log 口	Pf(e(i))	+/"Ft) log 口 PPW
t	tt
=MI Pf(ECt);Y Pf(e(i)) +KL Y Pf (e(i)) Y PP(e(i))
C=C	C=C	C=C
tt
≥ KL Y Pf (e(i)) Y PP(e(i))
C=C	C=C
where we used the fact the mutual information is always non negative.
□
How to approximate pre and post fault distributions: Both PP and Pf are not known and their likelihood ratio
need to be estimated from available data. From Section 5.1.1 we know how to approximate the likelihood ratio
given two set of data without estimating the densities. In our anomaly detection setup we define these two sets as:
EP := Ett--nnf-n +1 and Ef := Ett-n +1. So that given current time t we look back at a window of length nP + nf.
The underlying assumption is that under HC normal data are present in EP and abnormal ones in Ef. We estimate the
likelihood ratio 楙，(：(；))at each time t by assuming both EP and Ef data are independent (see Proposition A.2) and
cumulate their log as t increases.
How do nP and nf affect our detector? The choice of the windows length (nP and nf) is fundamental and highly
influences the likelihood estimator. Using small windows makes the detector highly sensible to both point and sequen-
tial outliers, while larger windows are better suited to estimate only sequential outliers. We now assume nP = nf and
study how small and large values affect the behaviour of our detector in simple working conditions.
In Figure 5 and Figure 6 we compute the cumulative sum of log likelihood ratios estimated from data on equally sized
windows. Intuitively any local minimum after a ‘large’ (depending on the threshold τ) increase of the cumulative sum
is a candidate abnormal point.
In Figure 7 and Figure 8 we compare the cumulative sum of estimated likelihood ratios on data in which both sequential
and point outliers are present. In particular we highlight that large window sizes nP and nf are usually not able to
capture point anomalies Figure 7 while using small window sizes allow to detect both (at the expenses of a more
sensitive detector) Figure 8.
21
sφ-e>
—cumsum
Data
—change point
3.5
3.0
2.5
Figure 5: Change point: Cumulative sum (blue) ob-
tained with our method in a synthetic example. We use
the cumulative sum of estimated likelihood ratios on data
in which a change point is present at t = 60. We use
np = nf = 20 and kernel length scale=0.2
6
5
4
50
Tim
O
6
80
90
Figure 6: Point anomaly: Cumulative sum (blue) ob-
tained with our method in a synthetic example. We use
the cumulative sum of estimated likelihood ratios on data
in which a point outlier is present at t = 60. We use
np = nf = 2 and kernel length scale=2.
Figure 7: Large np and nf : Cumulative sum (blue)
obtained with our method in a synthetic example. We
use the cumulative sum of estimated likelihood ratios
on data which contain both change points (t = 60 and
t = 200) and point outliers (t = 80 and t = 160). We
use np = nf = 20 and kernel length scale=1.
Figure 8: Small np and nf : Cumulative sum (blue)
obtained with our method in a synthetic example. We
use the cumulative sum of estimated likelihood ratios
on data which contain both change points (t = 60 and
t = 200) and point outliers (t = 80 and t = 160). We
use np = nf = 3 and kernel length scale=5.
S ①-e>
W
A.6 Datasets
A.6.1 Yahoo Dataset
Yahoo Webscope dataset (Laptev & Amizadeh, 2020) is a publicly available dataset containing 367 real and synthetic
time series with point anomalies, contextual anomalies and change points. Each time series contains 1420-1680
time stamps. This dataset is further divided into 4 sub-benchmarks: A1 Benchmark, A2 Benchmark, A3 Benchmark
and A4 Benchmark. A1Benchmark is based on the real production traffic to some of the Yahoo! properties. The
other 3 benchmarks are based on synthetic time series. A2 and A3 Benchmarks include point outliers, while the
A4Benchmark includes change-point anomalies. All benchmarks have labelled anomalies. We use such information
only during evaluation phase (since our method is completely unsupervised).
22
A.6.2 NAB Dataset
NAB (Numenta Anomaly Benchmark) (Lavin & Ahmad, 2015) is a publicly available anomaly detection benchmark.
It consists of 58 data streams, each with 1,000 - 22000 instances. This dataset contains streaming data from different
domains including read traffic, network utilization, on-line advertisement, and internet traffic. As done in (Geiger
et al., 2020) we choose a subset of NAB benchmark, in particular we focus on the NAB Traffic and NAB Tweets
benchmarks.
A.6.3 CO2 DATASET
We test the prediction and interpretability capabilities of our model on the CO2 dataset from kaggle 2. The main goal
here is to predict both trend and periodicity of CO2 emission rates on different years. Note this is not an Anomaly
detection task.
Table 3: Datasets summaries. We report some properties of the datasets used (see (Geiger et al., 2020) for mode
details).
	Yahoo				NAB		Kaggle
	A1	A2	A3	A4	Traffic	Tweets	CO2
# signals	67	100	100	100	7	10	9
# anomalies	178	200	939	835	14	33	
point	68	33	935	833	0	0	
sequential	110	167	4	2	14	33	
# anomalous	1669	466	943	837	1560	15651	
points							
(% tot)	1.8%	0.32%	0.56%	0.5%	9.96%	9.87%	
# data points	94866	142100	168000	168000	15662	158511	4323
A.6.4 NYT DATASET
The New York Times Annotated Corpus3 (Sandhaus, 2008) contains over 1.8 million articles written and published by
the New York Times between January 1, 1987 and June 19, 2007. We pre-processed the lead paragraph of each article
with a pre-trained BERT model (Devlin et al., 2019) from the HuggingFace Transformers library (Wolf et al., 2020)
and extracted the 768-dimensional hidden state of the [CLS] token (which serves as an article-level embedding). For
each day between January 1, 2000 and June 19, 2007, we took the mean of the embeddings of all articles from that
day. Finally, we computed a PCA and kept the first 200 principal components (which explain approximately 95% of
the variance), thus obtaining a 200-dimensional time series spanning 2727 consecutive days. Note that we did not use
any of the dataset’s annotations, contrary to prior work such as Rayana & Akoglu (2015).
A.7 Experimental setup
In this section, we shall describe the experimental setup we used to test STRIC.
Data preprocessing: Before learning the predictor we standardize each dataset to have zero mean and standard de-
viation equals to one. As done in (Braei & Wagner, 2020) we note standardization is not equal to normalization,
where data are forced to belong to the interval (0, 1). Normalization is more sensitive to outliers, thus it would be
inappropriate to normalize our datasets, which contain outliers.
We do not apply any deseasonalizing or detrending pre-processing.
Data splitting: We split each dataset into training and test sets preserving time ordering, so that the first data are used
as train set and the following ones are used as test set. The data used to validate the model during optimization are last
10% of the training dataset. Depending on the experiment, we choose a different percentage in splitting train and test.
When comparing with (Braei & Wagner, 2020) we used 30% as training data, while when comparing to (Munir et al.,
2019) we use 40%. Such a choice is dictated by the particular (non uniform) experimental setup reported in (Braei &
2https://www.kaggle.com/txtrouble/carbon-emissions
3https://catalog.ldc.upenn.edu/LDC2008T19
23
Wagner, 2020; Munir et al., 2019) and has been chosen to produce comparable results with state of the art methods
present in literature.
Evaluation metrics: We compare different predictors by means of the RMSE (root mean squared error) on the one-
step ahead prediction errors. Given a sequence of data YIN and the one-step ahead predictions YIN the RMSE is
defined as: q-N Pi=1 ky(i) - y(i)k2.
As done in (Braei & Wagner, 2020) we compare different anomaly detection methods taking into account several
metrics. We use F1-Score which is defined as the armonic mean of Precision and Recall (see (Braei & Wagner, 2020;
Munir et al., 2019)) and another metric that is often used is receiver operating characteristic curve, ROC-Curve, and
its associated metric area under the curve (AUC). The AUC is defined as the area under the ROC-Curve. This metric
is particularly useful in our anomaly detection setting since it describes with an unique number true positive rate and
false positive rate on different threshold values. We now follow (Braei & Wagner, 2020) to describe how AUC is
computed. Let the true positive rate and false positive rate be defined, respectively, as: TPR = TPP and FPR = FNP,
where TP stands for true positive, P for positive, FP for false positive and N for negative. To copute the ROC-Curve
we use different thresholds on our anomaly detection method. We therefore have different pairs of TPR and FPR
for each threshold. These values can be plotted on a plot whose x and y axes are, respectively: FPR and TPR.
The resulting curve starts at the origin and ends in the point (1,1). The AUC is the area under this curve. In anomaly
detection, the AUC expresses the probability that the measured algorithm assigns a random anomalous point in the
time series a higher anomaly score than a random normal point.
Hardware: We conduct our experiments on the following hardware setup:
•	Processor: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz
•	RAM: 128 Gb
•	GPU: Nvidia TITAN V 12Gb and Nvidia TITAN RTX 24Gb
Hyper-parameters: All the experiments we carried out are uniform on the optimization hyper-parameters. In partic-
ular we fixed the maximum number of epochs to 300, the learning rate to 0.001 and batch size to 100. We optimize
each model using Adam and early stopping.
We fix STRIC’s first module hyper-parameters as follows:
•	number of filter per block: l0 = 10, l1 = 100, l2 = 200
•	linear filters kernel lengths (N0, N1 , N2): half predictor’s memory
In all experiments we either use a TCN composed of 3 hidden layers with 300 nodes per layer or a TCN with 8 layers
and 32 nodes per layer. Moreover we chose N3 = 5 (TCN kernels’ lengths) and relu activation functions (Bai et al.,
2018).
Comparison with SOTA methods: We tested our model against other SOTA methods (Table 1) in a comparable
experimental setup. In particular, we chose comparable window lengths and architecture sizes (same order of mag-
nitude of the number of parameters) to make the comparison as fair as possible. For the hyper-parameters details
of any SOTA method we used we refer the relative cited reference. We point out that while the window length is a
critical hyper-parameter for the accuracy of many methods, our architecture is robust w.r.t. choice of window length:
thanks to our fading regularization, the user is required only to choose a window length larger than the optimal one
and then our automatic complexity selection is guaranteed to find the optimal model complexity given the available
data Section 4.1.
Anomaly scores: When computing the F-score we use the predictions of the CUMSUM detector which we collect as
a binary vector whose length is the same as the number of available data. Ones are associated to the presence of an
anomalous time instants while zeros are associated to normality.
When computing the AUC we need to consider a continuous anomaly score, therefore the zero-one encoded vector
from the CUMSUM is not usable. We compute the anomaly scores for each time instant as the estimated likelihood
ratios. Since We write the likelihood ratio as f, it is large when data does not come from PP (which We consider the
reference distribution).
24
Test Error
Train Error
Generalization Gap
20	«	«	80	100 0	2Q	«	60	80	100 0	2Q	4«	60	80	100
Memory
Memory
Memory
Train Error
Generalization Gap
Test Error
IV OOileA co 山SWa ZV OOUeA co 山SWa
100
4 StandsreiTCN
4 STRIC No Fading
4 STRIC
20
80
« «
Memory
ttss2α zouco 山 s=≈
Figure 9: Ablation studies on different datasets: Effects of interpretable blocks and fading regularization on model’s
forecasting as the available window of past data increases (memory). Left Panel: Train error. Center Panel: Test
error. Right Panel: Generalization Gap. The test error of STRIC is uniformiy smaller than a standard TCN (without
interpretable blocks nor fading regularization). Adding interpretable blocks to a standard TCN improves generalization
for fixed memory w.r.t. Standard TCN but get worse (overfitting occurs) as soon as the available past data horizon
increase. Fading regularization is effective: STRIC generalization GAP is almost constant w.r.t. past horizon.
25
A.7.1 Ablation study
In Figure 9 we show different metrics based on the predictor’s RMSE (training, test and generalization gap) as a
function of the memory of the predictor. We test our fading regularization on a variety of different datasets. In all
situations fading regularization helps improving test generalization and preserving the generalization gap (by keeping
it constant) as the model complexity increases. All plots show confidence intervals around mean values evaluated on
10 different random seeds.
In Table 4 we extend the results we show in the main paper by adding uncertainties (measured by standard deviations
on 10 different random seeds) to the values of train and test RMSE on different ablations of STRIC. Despite the high
variability across different datasets STRIC achieves the most consistent results (smaller standard deviations both on
training and testing).
Finally, in Table 5 we show the effects on different choices of the predictor’s memory npred and length of the anomaly
detectors windows ndet on the detection performance of STRIC. Note both F-score and AUC are highly sensible to the
choice of ndet: the best results are achieve for small windows. On the other hand when ndet is large the performance
drops. This is due to the type of anomalies present in the Yahoo benchmark: most of the them can be considered to be
point anomalies. In fact, as we showed in Appendix A.5, our detector is less sensible to point anomalies when a large
window ndet is chosen.
In Table 5 we also report the reconstruction error of the optimal predictor given it’s memory npred. Note small memory
in the predictor introduce modelling bias (higher training error) while a large memory does not (thanks to fading
regularization). As we observed in Appendix A.5 better predictive models provide the detection module with more
discriminative residuals: the downstream detection module achieves better F-scores and AUC.
Table 4: Ablation study on the RMSE of prediciton errors with standard deviation on 10 different seeds: We
compare a standard TCN model with our STRIC predictor and some variation of it (using the same train hyper-
parameters). The effect of adding a linear interpretable model before a TCN improves generalization error. Fading
regularization has a beneficial effect in controlling the complexity of the TCN model and reducing the generalization
gap.
TCN	TCN + Linear	TCN + Fading	STRIC pred
Train	Test	Train	Test
Train	Test	Train	Test
S3SeJea
Yahoo A1	0.10 ± 0.06	0.92 ± 0.06	0.10 ± 0.03	0.88 ± 0.03	0.44 ± 0.03	0.92 ± 0.03	0.43 ± 0.02	0.62 ± 0.02
Yahoo A2	0.11 ± 0.02	0.82 ± 0.02	0.13 ± 0.01	0.35 ± 0.02	0.20 ± 0.01	0.71 ± 0.01	0.14 ± 0.01	0.30 ± 0.01
Yahoo A3	0.13 ± 0.01	0.43 ± 0.01	0.16 ± 0.01	0.22 ± 0.01	0.15 ± 0.01	0.40 ± 0.01	0.19 ± 0.01	0.22 ± 0.01
Yahoo A4	0.15 ± 0.01	0.61 ± 0.01	0.19 ± 0.01	0.35 ± 0.01	0.17 ± 0.01	0.55 ± 0.01	0.23 ± 0.01	0.24 ± 0.01
CO2 Dataset	0.14 ± 0.02	0.62 ± 0.02	0.15 ± 0.02	0.45 ± 0.02	0.18 ± 0.03	0.61 ± 0.03	0.33 ± 0.01	0.41 ± 0.01
NAB Traffic	0.03 ± 0.01	1.06 ± 0.02	0.04 ± 0.01	1.00 ± 0.02	0.62 ± 0.01	0.93 ± 0.01	0.63 ± 0.02	0.74 ± 0.02
NAB Tweets	0.18 ± 0.05	1.02 ± 0.05	0.20 ± 0.05	0.98 ± 0.05	0.47 ± 0.02	0.83 ± 0.02	0.70 ± 0.01	0.77 ± 0.01
Table 5: Sensitivity of STRIC to hyper-parameters: We compare STRIC on different anomaly detection benchmarks
datasets using different hyper-parameters: memory of the predictor npred and length of anomaly detector windows
np = nf = ndet.
Yahoo A1	Yahoo A2	Yahoo A3	Yahoo A4
F1	AUC	F1	AUC	F1	AUC	F1	AUC
SwPOW SwPOW
npred =	10, ndet =	2	0.45	0.89	0.63	0.99	0.87	0.99	0.64	0.89
npred =	100, ndet	=2	0.48	0.9308	0.98	0.9999	0.99	0.9999	0.68	0.9348
npred =	10, ndet =	20	0.10	0.58	0.63	0.99	0.47	0.83	0.37	0.72
npred =	100, ndet	= 20	0.10	0.55	0.98	0.9999	0.49	0.86	0.35	0.76
			Yahoo A1		Yahoo A2		Yahoo A3		Yahoo A4	
			Train	Test	Train	Test	Train	Test	Train	Test
npred =	10		0.44	0.62	0.16	0.31	0.22	0.23	0.25	0.26
npred =	100		0.42	0.61	0.14	0.30	0.19	0.22	0.23	0.24
A.7.2 Comparison TCN vs STRIC
In this section we show standard non-linear TCN without regularization and proper inductive bias might not generalize
on non-stationary time series (e.g. time series with non zero trend component) and TCN architecture. In Figure 10 we
26
compare the prediciton errors of a standard TCN model against our STRIC on the A3 Yahoo dataset. We train both
models using the same optimization hyper-parameters (as described in previous section). Note a plain TCN does not
necessarily capture the trend component in the test set.
"n->
200	400
600	800	1000	1200	1400	1600
Timestamps
200	400
600	800	1000	1200	1400	1600
Timestamps
Figure 10: We compare an off-the-shelf TCN against STRIC (time series predictor) on the Yahoo dataset A3 Bench-
mark. Note the standard TCN overfits compared to STRIC: the standard TCN does not handle correctly the trend
component of the signal (First row). If we consider a time series without trend, the standard TCN model performs
better but overfitting is still present. In particular the generalization gap (measured using squared reconstruction error)
for the two models is: Standard TCN 0.3735 and STRIC 0.0135.
PIainTCN
"n->
500
600
700
800	900
Timestamps
1000	1100	1200	500
STRlC
600	700
800	900
Tmestamps
1000	1100	1200
Figure 11: Zoom on the second row of panels in Figure 10. We show the interface between train and test data both on
a plain TCN and on our STRIC predictor. A plain TCN overfits w.r.t. STRIC also when not trend is present.
A.8 STRIC vs SOTA Anomaly Detectors
In this section we further expand the discussion on the main differences between STRIC and other SOTA anomaly
detectors by commenting results obtained in Table 1 and Table 6. Table 6 is used to highlight the relative performance
of STRIC when the peformance are nearly saturated (e.g. Yahoo A2 and A3): we report the relative performance
indeces against TRAID for all the models we tested in Table 6. Both for F1 and AUC we report the following for each
comparing SOTA method:
AUC method - AUC STRIC
1-AUCSTRIC
100 (similarly for F1).
To begin with, STRIC outperforms ‘traditional’ methods (LOF and One-class SVM) which are considered as baselines
models for comparing time series anomaly detectors.
27
Table 6: Comparison with SOTA anomaly detectors: We compare STRIC with other anomaly detection methods
on the experimental setup and the same evaluation metrics proposed in (Braei & Wagner, 2020; Munir et al., 2019).
The baseline models are: MA, ARIMA, LOF (Shen et al., 2020), LSTM (Braei & Wagner, 2020; Munir et al., 2019),
Wavenet (Braei & Wagner, 2020) , Yahoo EGADS (Munir et al., 2019) , GOAD (Bergman & Hoshen, 2020), Om-
niAnomaly (Su et al., 2019), Twitter AD (Munir et al., 2019), TanoGAN (Bashar & Nayak, 2020), TadGAN (Geiger
et al., 2020) , DeepAR (Flunkert et al., 2017) and DeepAnT (Munir et al., 2019) . STRIC outperforms most of the other
methods based on statistical models and based on DNNs. Same as Table 1, here we report the relative improvements
w.r.t. STRIC (the higher the better).
Relative	F1-score		Yahoo A1	Yahoo A2	Yahoo A3	Yahoo A4	NAB Tweets	NAB Traffic
improvement STRIC in %	over						
ARIMA		-20	-88	-42	6	-33	-37
LSTM		-7	-33	-60	- 21		
Yahoo EGADS		-1	-95	-78	-54		
OmniAnomaly		-1	-60	-45	-11	-6	-10
Twitter AD		0	-98	-85	-53		
TanoGAN		-11	-85	-73	-13	-36	-44
TadGAN		-13	-85	-65	-20	-25	-47
DeepAR		-29	-72	-79	-41	-37	-32
DeepAnT		-4	-67	-15	0		
STRIC (ours)		0	0	0	0	0	0
Relative AUC	im-	Yahoo A1	Yahoo A2	Yahoo A3	Yahoo A4	NAB Tweets	NAB Traffic
provement	over						
STRIC in %							
MA		-47	-98	-98	379		
ARIMA		-45	-99	-99	124		
LOF		-28	-99	-99	-81	-32	-44
Wavenet		-60	-99	-99	-84		
LSTM		-63	-99	-99	-84		
GOAD		-37	-99	-99	-51	-19	-12
DeepAnT		-32	-99	-99	-53	-23	-13
STRIC (ours)		0	0	0	0	0	0
Comparison with other Deep Learning based methods: STRIC outperforms most of the SOTA Deep Learning
based methods reported in Table 1: TadGAN, TAnoGAN, DeepAnT and DeepAR (the last one is a SOTA time se-
ries predictor). Note the relative improvement of STRIC is higher on the Yahoo dataset where statistical models
outperforms deep learning based ones. We believe this is due to both fading regularization and the seasonal-trend
decomposition performed by STRIC.
Despite the general applicability of GOAD (Bergman & Hoshen, 2020) this method has not been designed to handle
time series, but images and tabular data. “Geometric” transformations which have been considered in GOAD and
actually have inspired it (rotations, reflections, translations) might not be straightforwardly applied to time series.
Nevertheless, while we have not been able to find in the literature any direct and principled extension of this work
to the time series domain, we have implemented and compared against (Bergman & Hoshen, 2020) by extending the
main design ideas of GOAD to time-series. So that we applied their method on lagged windows extracted from time
series (exploiting the same architectures proposed for tabular data case with some minor modifications). We report the
results we obtained by running the GOAD’s official code on all our benchmark datasets. Overall, STRIC performs (on
average) 70% better than GOAD on the Yahoo dataset and 15% better on the NAB dataset.
A.8.1 Details on the NYT experiment
Figure 4 shows the normalized anomaly score computed by STRIC on the NYT dataset, following the setup described
in Appendix A.6.4. Some additional insights can be gained by zooming in around some of the detected change-points.
In Figure 12 (left), we see that the anomaly score (blue line) rapidly increases immediately after the 9/11 attack and
reaches its peak some days later. Such delay is inherently tied to our choice of time scale, that privileges the detection
of prolonged anomalies as opposed to single-day anomalies (which are not meaningful due to the high variability of
28
Figure 12: A closer look at some of the change-points detected by STRIC. Left: Normalized anomaly score (blue
line) and normalized frequency of the “Terrorism” descriptor (orange line) around the 9/11 attack. Right: Normalized
anomaly score (blue line) and normalized frequency of the “Earthquakes” descriptor (orange line) in the second half of
2004 and beginning of 2005. The 2004 U.S. election causes an increase in the anomaly score, but the most significant
change-point occurs after the Indian Ocean tsunami.
the news content). The change-point which occurs the day after the 9/11 attack is reflected by a sudden increase of
the relative frequency of article descriptors such as “Terrorism” (orange line). Article descriptors are annotated in the
NYT dataset, but they are not given as input to STRIC so that we do not rely on any human annotations. However,
they can help interpreting the change-points found by STRIC.
In Figure 12 (right), we can observe that the anomaly score (blue line) is higher in the months around the 2004 U.S.
election and immediately after the inauguration day. However, the highest values for the anomaly score occur around
the end of 2004, shortly after the Indian Ocean tsunami. Indeed, this is reflected by an abrupt increase of the frequency
of descriptors like “Earthquakes” (orange line) and “Tsunami”.
We note this experiment is qualitative and unfortunately we are not aware of any ground truth or metrics (e.g., in
Rayana & Akoglu (2015) a similar qualitative result has been reported on the NYT dataset). We therefore tested
STRIC against a simple baseline which uses PCA on BERT features and a threshold to detect anomalies. Despite being
a simple baseline, this method ProoVed to be highly applied in practice due to its simplicity (Blazquez-GarCIa et al.,
2020). The PCA + threshold baseline is able to pick up some events (2000 election, 9/11 attack, housing bubble) but
is otherwise more noisy than STRIC’s anomaly score. This is likely due to the lack of a modeling of seasonal/periodic
components. For instance, the anomaly score of the simple baseline contains many false alarms which are related to
normal weekly periodicity that is not easily modeled by the baseline. This does not affect STRIC’s predictions, since
normal weekly periodicity is directly modeled and identified as normal behaViour.
29