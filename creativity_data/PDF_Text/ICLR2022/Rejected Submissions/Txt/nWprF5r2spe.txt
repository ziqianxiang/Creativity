Under review as a conference paper at ICLR 2022
On the Generalization of Wasserstein Robust
Federated Learning
Anonymous authors
Paper under double-blind review
Ab stract
In Federated Learning (FL), participating clients typically possess non-i.i.d. data,
posing a significant challenge to generalization to unseen distributions. To address
this, we propose a Wasserstein distributionally robust optimization scheme called
WAFL. Leveraging its duality, we frame WAFL as an empirical surrogate risk
minimization problem, and solve it using a novel local SGD-based algorithm with
convergence guarantees. We show that the robustness of WAFL is more general
than related approaches, and the generalization bound is robust to all adversarial
distributions inside the Wasserstein ball (ambiguity set). Since the center loca-
tion and radius of the Wasserstein ball can be suitably modified, WAFL shows its
applicability not only in robustness but also in domain adaptation. Through em-
pirical evaluation, we demonstrate that WAFL generalizes better than the vanilla
FedAvg in non-i.i.d. settings, and is more robust than other related methods in
distribution shift settings. Further, using benchmark datasets we show that WAFL
is capable of generalizing to unseen target domains.
1	Introduction
Federated Learning (FL) (Konecny et al., 2016; McMahan et al., 2017) has emerged as a CUtting-
edge technique in distributed and privacy-preserving machine learning. The nature of highly non-
independent and identically distribUted (non-i.i.d.) data in clients’ devices poses an important chal-
lenge to FL commonly called statistical heterogeneity. The global model trained on this data Using
the de facto FedAvg algorithm (McMahan et al., 2017) has been shown to generalize poorly to
individUal clients’ data, and fUrther to unseen distributions on new clients as they enter the network.
Several solUtions to data heterogeneity have been proposed. Personalized FL (Fallah et al., 2020;
Deng et al., 2020a; Dinh et al., 2021; Li et al., 2021) and mUlti-task FL (Smith et al., 2018) are
client-adaptive approaches, where a personalized model is adapted to each client. From another
perspective, distribUtionally robUst FL trains a model Using a worst-case objective over an ambiguity
set (Mohri et al., 2019; DU et al., 2020; Reisizadeh et al., 2020; Deng et al., 2020b). This approach
is client-uniform becaUse a single global model is jUdicioUsly learned to deliver Uniformly good
performance not only for all training clients bUt also for new/Unseen clients with Unknown data dis-
tribUtions. It is specifically UsefUl when test distribUtions drift away from the training distribUtions.
A natUral qUestion when designing distribUtionally robUst FL frameworks is generalization: how can
minimizing the training error also boUnd the test error (generalization bounds)? In FL, Mohri et al.
(2019) proposed agnostic FL where a model is designed to be robUst against any ambigUity set as a
convex combination of the clients’ distribUtions. Reisizadeh et al. (2020) applied the general affine
Covariate shift - used in the standard adversarial robust training - into FL training. In characterizing
the generalization boUnds, while Mohri et al. (2019) relied on the standard Rademacher complexity,
Reisizadeh et al. (2020) use the margin-based technique developed by Bartlett et al. (2017).
In this work, we take a different approach called WAsserstein distributionally robust FL (WAFL for
short). The ambiguity set in WAFL is a Wasserstein ball of all adversarial distributions in close
proximity to the nominal data distribution at the center. Our main contributions are:
•	We propose a distributionally robust optimization problem to address statistical heterogene-
ity in FL. By controlling the center and radius of the Wasserstein ball, we show that WAFL
is robust to a wider range of adversarial distributions than is agnostic or adversarial FL.
1
Under review as a conference paper at ICLR 2022
•	To make WAFL more amenable to distributed optimization, we transform the original prob-
lem into a minimization of the empirical surrogate risk. We propose a local SGD-based al-
gorithm to solve this surrogate problem. With additional Lipschitz smoothness conditions,
standard techniques can be applied to find the convergence rate for the proposed algorithm.
•	We show how WAFL’s output can reduce the test error by bounding its excess risk. We call
this the robust generalization bound as it is applicable to all adversarial distributions inside
the Wasserstein ball. By scaling the Wasserstein radius based on local data sizes, we show
this bound is applicable to the true (unknown) data distribution among all clients.
•	We show WAFL’s extra flexibility in controlling the location of the Wasserstein ball by
adjusting the nominal distribution. This enables applications such as multi-source domain
adaptation and robustness to all clients’ unknown distributions with minimal Wasserstein
radius.
•	Experimentally, we discuss how to control this radius for a given center location by fine-
tuning a robust hyperparameter. We show that WAFL generalizes better than FedAvg in
non-i.i.d. settings and further outperforms existing robust methods in distribution shift set-
tings. We finally explore WAFL’s capability in transferring knowledge from multi-source
domains to related target domains with much less data and/or without labels.
2	Related Work
Federated Learning was introduced in response to three challenges of machine learning at scale:
massive data quantities at the edge, communication-critical networks of participating devices, and
privacy-preserving learning without central data storage (Konecny et al., 20l6; McMahan et al.,
2017). The de facto federated optimization algorithm - FedAvg (McMahan et al., 2017) - is based
on local stochastic gradient descent (SGD) and averaging and is often considered a baseline in FL.
Most challenges of FL are categorized into systems heterogeneity and statistical heterogeneity. The
former focuses on communication problems such as connection loss and bandwidth minimization.
This motivated some prior works to design more communication-efficient methods (Konecny et al.,
2016; 2017; Suresh et al., 2017). On the other hand, statitical heterogeneity is concerned with
clients’ non-i.i.d. data, which is the main cause behind aggregating very different models leading to
one which does not perform well on any data distribution. To address this, many ideas have been
introduced. Li et al. (2020) provided much theoretical analysis ofFL non-i.i.d. settings. Zhao et al.
(2018) proposed an FL framework which globally shares a small subset of data among clients to train
the model with non-i.i.d. data. Smith et al. (2018) introduced a multi-task FL framework in which
each client individually learns its own data pattern while borrowing information from other clients.
Mansour et al. (2020) proposed three approaches to adapt the FL model to enable personalization, in
reponse to distribution shift. Several personalized FL models have also been developed, including
Fallah et al. (2020); Deng et al. (2020a); Dinh et al. (2021); Li et al. (2021).
Wasserstein Distributionally Robust Optimization (WDRO) aims to lean a robust model against
adversarially manipulated data. The unknown data distribution is assumed to lie within a Wasserstein
ball centered around the empirical distribution (Kuhn et al., 2019). WDRO has received attention as
a promising tool for training parametric models, both in centralized and federated learning settings.
In centralized learning, many studies have proposed solutions based on WDRO problems for cer-
tain machine learning tasks (Shafieezadeh Abadeh et al., 2015; Gao & Kleywegt, 2016; Esfahani
& Kuhn, 2017; Chen & Paschalidis, 2018; Sinha et al., 2020; Blanchet et al., 2019; Shafieezadeh-
Abadeh et al., 2019; Gao et al., 2020). For instance, Shafieezadeh Abadeh et al. (2015) considered
a robust logistic regression model under the assumption that the probability distributions lie in a
Wasserstein ball. Chen & Paschalidis (2018); Blanchet et al. (2019); Gao et al. (2020) leveraged
WDRO to recover regularization formulations in classification and regression. Gao & Kleywegt
(2016) proposed a minimizer based on a tractable approximation of the local worst-case risk. Es-
fahani & Kuhn (2017) used WDRO to formulate the search for the largest perturbation range as an
optimization problem and solve its dual problem. Sinha et al. (2020) introduced a robustness certifi-
cate based on a Lagrangian relaxation of the loss function which provably robust against adversarial
input distributions within a Wasserstein ball centered around the original input distribution.
2
Under review as a conference paper at ICLR 2022
In FL, only a few works have explored the Wasserstein distance (Reisizadeh et al., 2020; Diamandis
et al., 2021). Specially, Reisizadeh et al. (2020) proposed FedRobust based on adversarial robust
training to enhance robustness. Regarding distributionally robust learning, Deng et al. (2020b) pro-
posed DRFA, a communication efficient distributed algorithm. Besides, based on the agnostic FL
framework suggested by Mohri et al. (2019), Du et al. (2020) introduced AgnosticFair, a two-player
adversarial minimax game between the learner and the adversary, to achieve fairness.
3	Wasserstein Robust Federated Learning
3.1	Expected Risk and Empirical Risk Minimization in Federated Learning
In a federated setting, there are m clients, and each client i ∈ [m] := {1, . . . , m} has its data gen-
erating distribution Pi supported on domain Zi := (Xi , Yi). Consider the parametrized hypothesis
class H = hθ | θ ∈ Rd , where each member hθ is a mapping from Xi to Yi parametrized by
θ. With Zi := (xi, yi) ∈ Zi, We use '(zi, hθ), shorthand for '(yi, hθ(Xi)), to represent the cost of
predicting hθ(xi) when the ground-truth label is yi. For example, if hθ(xi) = θTxi and yi ∈ R, a
square loss '(zi, hθ) = '(y%, hθ (Xi)) = (θTXi-yi)2 can be considered. In FL, all clients collaborate
With a server to find a global model θ such that the folloWing sum Weighted risk is minimized:
m
min X λiEzi_pi ['(Zi, hθ)],	(1)
∈ i=1
where Ezi^1pi ['(Zi, hθ)] is client i's expected risk and λ% ≥ 0 represents the relative “weight”
of client i and Pim=1 λi = 1. Therefore, λ := [λ1, . . . , λm]> belongs to a simplex ∆ :=
{λ ∈ Rm : λ < 0 and λ> 1m = 1}. Define by Pλ := Pm=I λiPi the mixed clients, distribution
over m domains Z := {Zι,..., ZmJ. We denote by Z 〜 Pλ a random data point Z generated by
Pλ, which means that the domain of client i is chosen with probability P(Z = Zi) = λi first, then
a data point Zi ∈ Zi is selected with probability P(Zi = Zi), Zi 〜Pi.
While the underlying distributions Pi are unknown, clients have access to finite observations zi ∈
[ni]〜Pλ. We abuse the notation [ni] to denote the set of client i,s both observable data points and
their indexes. Let Pni := / Pza∈[n.] δzi be the empirical distribution of Pi, where δzi is the Dirac
point mass at Zi . In general, we use the notation b for quantities that are dependent on the training
data. Define by Pbλ := Pim=1 λiPbni the mixed empirical distribution of n = Pim=1 ni training data
from m clients. The empirical risk minimization (ERM) problem of (1) is as follows:
mind IEZ 〜Pλ ['(Z,hθ )] =	X λiEZi 〜Pn ['(Zi,hθ)]	= X ni fɪ X	'(Zi,hθ))),	(2)
θ∈Rd	i=1	i	i=1 n ni	zi∈[ni]
where λi = ni/n is often chosen in ERM of the standard FL (McMahan et al., 2017).
3.2	Wasserstein Robust Risk in Federated Learning
Models resulting from (2) have been shown to be vulnerable to adversarial attacks and to lack of
robustness to distribution shifts. We consider a robust variant of the ERM framework, involving the
worst-case risk with respect to the p-Wasserstein distance between two probability measures. Given
a set Z, define d : Z × Z → [0, ∞) to be the cost of “transportation” between its two points.1
Suppose P and Q are two distributions on Z. Let Π(P, Q) be the set of probability measures π on
Z × Z whose marginals are P and Q, called their couplings. In other words, π(A, Z) = P(A) and
π(Z, A) = Q(A), ∀A ⊂ Z. The p-Wasserstein distance between P and Q is defined as
Wp(P,Q)=	inf、(E(z,zo)〜∏ [dp(Z,Z0)]产p.	⑶
π∈Π(P,Q)
This distance represents the minimum cost of transporting one distribution to another, where the
cost of moving a unit point mass is determined by the ground metric on the space of uncertainty
realizations. In this work, we mainly work with p = 2. Let Bp(P, ρ) := {Q : Wp(P, Q) ≤ ρ}
1The function d must satisfy non-negativity, lower semi-continuity and d(z, z) = 0, ∀z ∈ Z.
3
Under review as a conference paper at ICLR 2022
denote the Wasserstein ball centered at P (i.e., nomimal distribution) and having radius ρ ≥ 0. We
modify (2) into the following Wasserstein robust risk minimization in FL problem:
WAFL:	miRd卜uPQ∈B(Pλ,ρ) EZ0~Q ['(Z0, hθH }∙
.ʌ
(4)
There are several merits to this framework. First, the ambiguity set Bp (Pλ , ρ) contains all (contin-
uous or discrete) distributions Q that can be converted from the (discrete) nominal distribution Pλ
at a bounded transportation cost ρ. Second, Wasserstein distances can be approximated from the
samples. Based on the non-asymptotic convergence results of Fournier & Guillin (2015), we can
specify a suitable value for ρ to probabilistically bound Wp(P, Q) by the distance between their
empirical distributions Wp(P, Q) (e.g., for multi-source domain adaptation).
In any robust optimization problem, the ambiguity set is a key ingredient to defining the level of
robustness. We will compare WAFL in (4) with other approaches in terms of their ambiguity set.
Agnostic FL. Using this approach, existing tech-
niques (Mohri et al., 2019; Deng et al., 2020b) minimize the
worst-case loss
ma∆ EZ~Pλ['(Z hθ)],
hence its distributional ambiguity set is Q∆ := Pbλ : λ ∈
∆ . While Agnostic FL’s ambiguity set is the static convex
hull of {Pni }i∈[m], WAFL,s ambiguity set B(Pλ,ρ) can be
adjusted by controlling the robustness level ρ and by position-
ing the ball center using λ, which is useful for domain adapta-
tion. Therefore, B(Pλ , ρ) can cover Q∆ by using appropriate
values for ρ and λ (see Fig. 1).
Adversarial robust FL. Using this approach, Reisizadeh
et al. (2020) combines a general affine covariate shift in stan-
dard adversarial robust training with FL. Most existing tech-
niques using this approach (Goodfellow et al., 2015; Kurakin
et al., 2017; Carlini & Wagner, 2017; Madry et al., 2019;
Tramer et al., 2020) define an adversarial perturbation U at
Figure 1: Example of four FL clients
with data distributions P1 , . . . , P4. The
shaded area (Agnostic FL’s ambiguity
set) is covered by the blue ball with ra-
dius ρ and centered at Pbλ (Wasserstein
ambiguity set). For domain adaptation
with Q as a target domain, the nom-
inal distribution (multi-source domain)
.	..C r	J	YY	L / J	N
is shifted to Pλ0 such that W2 (Pλ0 , Q)
is minimal.
ʌ
ʌ
a data point Z, and minimize the worst-case loss over all perturbations: maxu∈U EZ~户入['(Z +
u, hθ) , where the ambiguity set is U := u ∈ Rd+1 : kuk ≤	. In Appendix A, we show that
the Wasserstein ambiguity set also contains the perturbation points induced by the solution to this
adversarial robust training problem.
3.3	WAFL: ALGORITHM DESIGN AND CONVERGENCE ANALYSIS
The original form of WAFL in (4) is not friendly for distributed algorithm design. Fortunately, the
Wasserstein robust risk (or B(Pλ , ρ)-worst-case risk) has its dual formulation as follows (Gao &
Kleywegt, 2016; Sinha et al., 2020)
sup	EZ0~Q ['(Z0, hθ)] = inf {γρ2 + EZ~pλ [φγ(Z,θ)]},	⑸
Q∈B(Pbλ ,ρ)	γ≥0
where φγ(Zi,θ) := sup《∈z ['(Z, ho) - γd2(Z,zi)], and d2(z,z0) = ∣∣x - x0k2 + κ∣y - y0∣2,κ >
0. The crux of using the dual is that the inner supremum problem (finding φγ) is easily solvable
when its objective is well-conditioned: if ' is L-smooth and d is 1-strongly convex, setting γ > L
ensures that ζ 7→ '(ζ, ho) - γd2 (ζ, z) is strongly concave, and using gradient ascent for the inner
supremum problem (for finding φγ) ensures linear convergence. For each Zi let Zi be the solution to
supζ∈z ['(Z, ho) — γd2(Z, zi)]. Then, Voφγ(zi, θ) = Vo'(z*, ho) (Sinha et al., 2020, Lemma 1).
Rather than find the optimal γ in (5), we consider γ as a control parameter, and instead solve the
following client-decomposable problem, which is amenable to distributed algorithm design.
mRd 卜 Z ~Pλ[Φγ (Z,θ)] = XX λiEZi -Pni[Φγ (Zi ,θ)]}.	⑹
4
Under review as a conference paper at ICLR 2022
Algorithm 1: Local SGD for WAFL
1:
2:
3:
4:
5:
6:
7:
8:
9:
for t = 0, 1, ..., T - 1 do
Sample a subset of clients St ⊂ m
for client i ∈ St in parallel do
Set local parameters: θi(t,0) = θt
for k = 0, 1, ..., K - 1 do
Sample a mini-batch Di from client i’s dataset
θ(t,k+1) = θ(t,k) -岛 P Vθφ(zi,θ(t,k))
i zi∈Di
Send θi(t,K) to server
Server: update θ(t+1) = Pi∈st λiθit,K/Pi∈st λi
// Global rounds
// Communication
// Local rounds
// Communication
This motivates the development of Algorithm 1 for solving (6). The structure of WAFL is similar
to FedAvg with T communication rounds. We further note three key components of Algorithm 1
common to FL methods. First, client sampling (line 2) refers to the partial participation of clients
in each global round. Second, each client performs K local steps (line 5) before sending its local
model to the server,. Finally, stochastic approximation of a client’s gradient using a mini-batch
(lines 6 and 7) is necessary when the data size is large. The main difference between WAFL and
FedAvg is that WAFL aims to minimize the risk with respect to the surrogate loss φγ , rather than `.
We show that the convergence of WAFL can be similarly characterized as that of FedAvg, the de
facto FL algorithm based on local SGD updates (McMahan et al., 2017). In FedAvg optimization,
we seek to establish the convergence when using the original loss function `. On the other hand, in
WAFL the convergence is with respect to the surrogate loss φγ , through which the local and global
risks are defined by Fi(θ) := EZi 〜pi [φγ (Zi, θ)] and F (θ) ：= EZ 〜Pλ [φγ (Z, θ)] ,respectively.
We first make the following assumptions, common to analyses of Wasserstein-robust optimiza-
tion (Sinha et al., 2020). Unless stated otherwise, all norms are the Euclidean norm.
Assumption 1. The function d : Z × Z → R+ is continuous, and d(∙, z0) is 1 -strongly convex,
∀z0 ∈ Z.
Assumption 2. The loss function ` : Z × H → R is Lipschitz continuous as follows
(a)k`(z, hθ) - `(z0, hθ)k ≤ Lz kz - z0k,	(b)k`(z, hθ) - `(z, hθ0)k ≤ Lθkθ - θ0k.
Assumption 3. The loss function ` : Z × H 7→ R is Lipschitz smooth as follows
kVθ'(z, hθ)	- Vθ'(z, hθo)k ≤	Lθθkθ -	θ0k,	∣Nz'(z,	hθ)	- Vz'(z0, hθ)k ≤	LzzIlz -	z0k,
kVθ'(z, hθ)	- Vθ'(z0, hθ)k ≤	Lθzkz -	z0k,	kVz'(z,	hθ)	- Vz'(z, hθo)k ≤	Lzθ∣θ -	θ0∣∣.
Given Assumption 3, it has been shown that the mapping θ → φγ(∙, θ) is L-Smooth with L =
Lθθ + LLθLzθ ,γ > Lzz (Sinha et al., 2020) (more detail in Appendix Lemma 2). In addition, We
γ-L
zz
make the following assumptions common to FL analysis (Wang et al., 2021).
Assumption 4. The unbiased stochastic approximation of VFi (θ), denoted by gφi (θ)
Vθφγ (zi, θ), zi
Pi, has σ2-uniformly bounded variance, i.e., E
Igφi(θ)-VFi(θ)I2
≤ σ2.
〜
Assumption 5. The difference between the local gradient VFi(θ) and the global gradient VF (θ)
is Ω-uniformly bounded, i.e., maxi sup&∣∣VFi(θ) 一 VF(θ)k ≤ Ω.
Assuming complete participation of clients in every round (St = m, ∀t), using standard techniques
in Wang et al. (2021), we have:
Theorem 1 (WAFL’s convergence for convex loss function). Let Assumptions 1-5 hold and the
mapping θ → '(z,hθ) be convex. Denote by 仇t,k) the “shadow” sequence, defined as θ(t,k) =
Pm=I λiθ(t,k) and by θ* the optimal solution to minj∈Rd F(θ). Ifthe client learning rate satisfies
.ʃ ɪ D___________d2_________D 3
η ≤ mɪnl 3L, 2√KTΛσ, 48 1 K2T3L 1 Ω3,401 KT3L3 Ω3
5
Under review as a conference paper at ICLR 2022
then we have
T-1 K-1
E KT XX F (θ(Q) - F (θ*)
t=0 k=0
≤o( LD2 + 半丝 +
—K κτ √kt
(7)
L1Ω 2 D 3
K 3 T 3
L 3 Ω 3 D 4、
-T3-)
+
where σ2 := ∣^, D := ∣∣θ(0) — θ*k and Λ := Pm=I λ2.
We provide a proof of Theorem 1 in Appendix C.
4 Robust Generalization Bounds
We show the generalization and robustness properties of WAFL’s output by bounding its excess risk.
Denote the loss class by F := ` ◦ H := {z 7→ `(z, h), h ∈ H}, where we use f (resp. fθ) ∈ F to
represent a generic loss (resp. a loss function parametrized by θ).
Definition 1. Denote the expected risk and surrogate of Wasserstein robust risk of an arbitrary f,
respectively, as follows
L(Pλ,f ):= EZ〜Pλ ['(Z, h)]	and LY(Pλ,f) ：= EZ〜p“ 限(Z,f)] + γρ2.
Then their excess risks are defined respectively as follows
E(Pλ,f ):= L(Pλ, f) — /f L(Pλ, f0)	and	EY(Pλ, f) := LY(Pλ, f) - /f LY(pλ, f0)∙
Ifa distribution Q is in the ambiguity set B(Pλ, ρ), we can bound its excess risk E(Q, f) as follows.
Lemma 1. Let Assumption 2 (a) holds and γ ≥ Lz /ρ. For all f ∈ F and for all Q ∈ B(Pλ, ρ),
EY(Pλ,f) — g(ρ, γ) ≤ E(Q,f) ≤ EY(Pλ, f) + g(ρ, Y),
where g(ρ, γ) := 2LzP + ∣γ — Y*∣ρ2, and Y* := argminY0≥0LρY0(Pλ,f).
We provide a proof of Lemma 1 in Appendix D.
Remark 1. Lemma 1 shows that the lower and upper bounds for E(Q, f) can be analyzed using
EρY (Pλ, f) and a two-component error term g(ρ, Y). The first component, 2Lzρ, says that when ρ
is increased - to allow for larger Wasserstein distance between the nominal Pλ and any worst-case
distribution Q - the difference between the excess risks E(Q, f) and EP(Pλ, f) increases, and this
error is amplified at most by the Lipschitz constant Lz of the mapping Z → '(z, ∙). The second
component, ∣γ — γ*∣ρ2, addresses the sub-optimality error of a chosen value of γ, which is amplified
when γ is drifted away from the optimal Y*. Note that LCY(Pλ, f) is the same as B(Pλ, ρ)-worst-
case risk thanks to the strong duality (5), which is obtained with ρ > 0.
Denote by θb ∈ Θ an ε-minimizer to the surrogate ERM, i.e., EZ〜P入[。)(Z, fε)]	≤
infθ∈θ EZ〜ρλ [φ(Z, fθ)] + ε, where Θ ⊂ Rd is a parameter class, we obtain the following result.
Theorem 2 (Robust Generalization Bounds). LetAssumptions 2 and 3 hold, Y ≥ maxLLzz, Lz/ρ},
and |'(z, h)| ≤ m` . We have thefollowing result for all Q ∈ B(Pλ, P)
E(Qf) ≤ X λi" ,2M'S 2”# + ε + g(ρ,Y)
i=1	ni	ni
with probability at least 1 — δ, where C(Θ) := Lθ f∞ ʌ/log N (Θ, k ∙ kθ,e)de and N (Θ, k ∙ ∣∣θ , e)
denotes the E-covering number of Θ w.r.t a metric ∣∣∙∣∣θ as the norm on Θ.
We provide a proof of Theorem 2 in Appendix E. We sketch the proof as follows: first bound
EρY (Pλ , fθbε ) using standard excess risk decomposition and uniform convergence with Rademacher
complexity. Then leverage the upper-bound of Lemma 1 to bound E(Q, f), ∀Q ∈ B(Pλ, P), based
on the bound of EYρ(Pλ, fθbε ). The result shows that using WAFL to minimize the surrogate of
Wasserstein robust empirical risk also controls the robustness and generalization. As an example
6
Under review as a conference paper at ICLR 2022
H = {<θ, ∙i, θ ∈ Θ} with Θ = {θ ∈ Rd : ∣∣θ∣∣2 ≤ C}. The diameter of Θ is supθ,θo∈θ∣∣Θ - θ0k =
2C, thus N(Θ, k ∙ k2, e) = (1 + 2C∕e)d, and C(Θ) ≤ 3CLθ√d∕2 (Lee & Raginsky, 2018).
Generally, the radius of Wasserstein ball P can be considered hyperparameter that needs fine-tuning
(e.g., through cross-validation). In principle, P should not be too large to become over-conservative,
which can hurt the empirical average performance, but also not too small to become similar to the
ERM, and thus can lack robustness. From a statistical standpoint, we are interested in learning how
to scale P w.r.t. the sample size ni, i ∈ [m], such that the generalization of the WAFL solution
θbε w.r.t the true distribution Pλ is guaranteed, while still ensuring robustness w.r.t all distributions
inside the Wasserstein ball. Using the result from Fournier & Guillin (2015), which shows that Pbni
converges in Wasserstein distance to the true Pi at a specific rate, we obtain the following
Corollary 1. With all assumptions as in Theorem 2, defining Pn := JPm=I 入间7,we have
…) ≤X λi" 48≡+2M4
2 log(4m∕δ)
ni
+ g(ρn, γ) + ε
with probability at least 1 - δ, where ρbδn :
log(ci∕δ)
c2n
log(ci∕δ)
c2n
min{2/d,1/2}
ifn≥
1∕ɑ
ifn<
log(ci∕δ)
C2
log(ci∕δ)
C2
We provide a proof of Corollary 1 in Appendix F.
5 CHOOSING λ: APPLICATIONS
We focus on two applications: multi-source domain adaptation and generalization to all client dis-
tributions. We provide insights about choosing the client weights λ for these applications.
Multi-source domain adaptation: Consider the multi-source domain distribution Pλ (Mansour
et al., 2021). Lee & Raginsky (2018) show that solving the minimax risk with the Wasserstein
ambiguity set can help transfer data/knowledge from the source domain Pλ to a different, but related,
target domain Q. They bound the distance Wp(Pλ, Q) using the triangle inequality
Wp(Pλ,Q) ≤ Wp(Pλ, Pbλ) + Wp(Pbλ, Qb) + Wp(Qb, Q),
(8)
.	A	1 公	..	.♦ I	Cn	1 八	..1	……T" f A 、	1
where Pλ and Q are the empirical versions of Pλ and Q, respectively. While Wp(Pλ, Pλ) and
Wp(Q, Q) can be probabilistically bounded with a confidence parameter δ ∈ (0, 1) according to
Fournier & Guillin (2015), Wp(Pλ, Q) can be deterministically computed using linear or convex
programming (Peyre & Cuturi, 2019).
In FL context, in order to have a better bound for W2 (Pλ , Q) similar to (8), it is straightforward to
choose λ = arg minλ0∈∆ W2 (Pλ0 , Q). To relax this problem into a form solvable using existing
approaches, observe that W2 (Pbλ, Q) ≤ Pim=1 λiW2 (Pbni, Q) due to the convexity of Wasserstein
distance. We then consider the following upper-bound to minλ∈∆ W2(Pλ, Q):
m
λm∈i∆n	i=1λiW2(Pbni,Qb ) =: P?,
(9)
which is a linear program, considering each W2 (Pni, Q) can be found by efficiently solving convex
programs especially with entropic regularization and the Sinkhorn algorithm (Cuturi, 2013).
Corollary 2. Denote the solution to (9) by λ?, and assume that domain Q generates nQ i.i.d. data
points. With probability at least 1 - δ, we have
m
W2(Pλ*,Q) ≤ W2(Pλ*,Pλ*) + W2(Pλ*,Q) + W2(Q,Q) ≤ ME
i=1
x?pn/m+ρ?+濡
The proof of this corollary is similar to that of Corollary 3 in Appendix B.
Covering all client distributions in the Wasserstein ball: Suppose we want to cover all client
distributions inside a Wassertein ball so that the generalization and robustness result by WAFL in
Theorem 2 is applicable to all clients’ distributions. We show in Appendix B that this is a problem
of finding λ such that the Wasserstein distance between Pλ and Pj , ∀j, is as small as possible.
7
Under review as a conference paper at ICLR 2022
6 Experiments
We first show how to change the level of worst-case perturbations by varying the robust parameter
γ. To show the generalizability and robustness of WAFL, we evaluate WAFL under non-i.i.d. and
distribution shift settings. We compare WAFL with baseline robust methods and non-robust FedAvg.
Finally, in Appendix G.4, we show WAFL’s capability in domain adaptation.
Experimental settings. We use two datasets in two non-i.i.d. settings. We distribute the first dataset
-MNIST (LecUn et al., 1998) - to 100 clients and use a multinomial logistic regression model to
model a convex setting. For the second dataset - CIFAR-10 (Krizhevsky, 2009) - we use 20 clients
and a CNN model employed in McMahan et al. (2017) to model a non-convex setting. We set
λi = ni/n as the client weights. In optimization, we randomly sample St = 10 clients to participate
in training at each communication round. More detail can be found in Appendix G.1.
Effect of γ on the worst-case risk perturbations. We
first examine the relationship between the robust parameter γ
and the average worst-case perturbations ρ, defined as p2 =
2
EZ〜P入[d2(Z,Z), where Z is the adversarial perturbation of
Z. As shown in Fig. 2, smaller values of γ correspond to larger
worst-case perturbations ρ on both the MNIST and CIFAR-10
datasets. For the rest of the experiment, rather than control ρ di-
rectly, we set γ on the opposite direction to control the level of
robustness.
Average worst-case perturbation
Figure 2: Varying ρ by Y.
♦	Tl,	CuALl -c-r τ	♦ F	•!会	,1	∙ ∙	1 T , ∙1	i~
Generalization and robustness of WAFL. We consider Pλ and Q as the empirical distribution of
the training samples and test samples of all clients, respectively. By varying γ, we aim to train a
global model robust to any empirical test distribution Q. To show the generalization and robustness
of WAFL, we train and evaluate it in two different scenarios. First, in the clean data scenario, the
global robust model is trained with different values ofγ and then evaluated on given clients’ test data
(similar to traditional FL). Second, in the distribution shift setting, the training process is similar;
however, the global robust model is evaluated when there are distribution shifts at the clients’ test
data. To obtain these shifts, we use the common PGD attack method in Madry et al. (2019) under
l∞-norm to generate an -level perturbation on clients’ test data. We choose the l∞-norm as it
shows benefits in adversaries and gives large perturbations. Following Madry et al. (2019), we fix
the number of gradient steps to generate adversarial examples with tavd = 40, = 0.3, α = 0.01
for MNIST and tavd = 10, = 8/255, α = 2/255 for CIFAR-10 with a batch size of 64. We note
that this setting is similar to the adversarial poisoning attacks and the main purpose of this setting is
1	7~»	•!公 ，1	1	∙ i' ∙	, 1	1	C1A，ALl
between Pλ and Q, thereby verifying the robustness of WAFL.
to increase the Wasserstein distance
The performance of WAFL in both scenarios on MNIST and CIFAR-10 is shown in Fig. 3. When
the clients’ data is clean, the Wasserstein distance between Pλ and Q is relatively small, and training
WAFL with small Y (large ρ) gives the worse performance on the test set. With a sufficiently large Y,
WAFL is less robust and has the same generalization with FedAvg. By carefully fine-turning γ in the
range [0.5, 1] for MNIST and [10, 20] for CIFAR-10, WAFL shows an improvement over FedAvg.
Y in this scenario plays the same role as a regularization parameter to handle non-i.i.d. data.
By adding distribution shifts, we increase the Wasserstein distance between
and Q. By vary-
ing Y, we train a global robust model with different levels of worst-case perturbation to handle the
distribution shifts. Small values of Y generate larger ambiguity sets B(Pλ, P) and increase the ro-
bustness of WAFL, thus increase the chance Q lies inside B(Pλ, ρ). In Fig. 3, WAFL shows better
performance with smaller Y values. However, as in mentioned in Sec. 4, when P is much larger or
smaller than the level of distribution shifts (Y ≤ 0.01 or Y ≥ 1 for MNIST and Y ≤ 0.1 or Y > 10
for CIFAR-10), WAFL performs inefficiently: too small Y hurts the empirical performance, while
too large Y makes WAFL lack robustness. For every scenario, Y needs to be tuned correspondingly.
In our experiments, by carefully choosing Y, WAFL not only handles distribution shifts or com-
mon data poisoning attacks but also provides better performance than FedAvg in non-i.i.d. data and
heterogeneous settings. Specifically, we set Y = 0.5 for MNIST and Y = 10 for CIFAR-10.
Comparison with other robust methods. We compare WAFL with three baselines: two
common robust methods in FL called FedPGM and FedFGSM, and one non-robust method Fe-
8
Under review as a conference paper at ICLR 2022
MNIST	MNIST
0.01 0.05 0.1 0.5 1	5 10 50
0.01 0.05 0.1 0.5
5 10 50
WAFL: Clean data —FedAvg: Clean data
CIFAR
0.01 0.05 0.1 0.5
WAFL Distribution shifts
5 10 50
CIFAR
-R-O-O
5 10 50
0.01 0.05 0.1 0.5
Y
FedAvg: Distribution shifts
Figure 3:	Global accuracy and loss of with different values of γ on MNIST and CIFAR-10 under clean data
and distribution shifts (40% of clients are affected by PGD attack). The blue vertical line indicates the value of
γ giving the same level of PGD attack(γ = 0.05 for MNIST and γ = 0.5 for CIFAR-10).
MNIST	、λ	MNIST
>umc3uu4-H-O-O
0.2	0.4	0.6	0.8
Proportion of attacked clients
5 0 5 0
75 2 Q
Ssσlqq9
0.35
0.30
0	0.2	0.4	0.6	0.8
Proportion of attacked clients
-WAFL -→- FedPGM
0.65
O 0.40
0.60
S0∙55
*∙50
s 0.45
0	0.2	0.4	0.6	0.8
Proportion of attacked clients
FedFGSM →- FedAvg
CIFAR	` „	CIFAR
r c
Ssσl"qq9
0	0.2	0.4	0.6	0.8
Proportion of attacked clients
Figure 4:	Comparison with other robust methods on MNIST and CIFAR-10 at different proportion of attacked
clients (clients are affected by distribution shifts).
dAvg. FedPGM and FedFGSM are FedAvg with adversarial training using the projected gradi-
ent method PGD (Madry et al., 2019) and the fast-gradient method FGSM (Goodfellow et al.,
2015), respectively. In FedPGM and FedFGSM, in each local update, all clients solve δ* =
arg maxkδk ≤ `(hθ(z + δ), y) using projection onto an l∞-norm to find the worst-case per-
turbation δ. While FedPGD uses t0jvd gradient steps to find δ*, FedFGSM uses only one gradient
step. We use the same values of and α from the distribution shifts setting for projection. For a
fair comparison, both WAFL and FedPGM have the same value tavd and all algorithms have the
same number of local updates K. We also train WAFL with the value of γ generating the same
level perturbation of in FedPGM and FedFGSM. We study different proportions of clients having
distribution shifts in Fig. 4. The robust accuracy of all methods decreases when the percentage of
clients having distribution shifts increases. Especially, the FedAvg’s performance drops dramati-
cally when the percentage of attacked clients reaches 80%. For all scenarios, WAFL outperforms
all the baselines. Specifically, in the case of 80% attacked clients, the improvements in accuracy of
WAFL over FedPGM, FedFGSM, and FedAvg are 7%, 8%, and 33% for MNIST and 2.5%, 4.5%,
and 18% for CIFAR-10, respectively.
7 Conclusion
In this paper, we present WAFL, a Wasserstein distributionally robust optimization framework, to
tackle the issue of statistical heterogeneity in federated learning. We first remodel the duality of
the worst-case risk to an empirical surrogate risk minimization problem, then solve it using a local
SGD-based algorithm with convergence analysis. We show that WAFL is more general in terms
of robustness compared to related approaches, and obtains an explicit robust generalization bound
with respect to all unknown distributions in the Wasserstein ambiguity set. Through numerical
experiments, we demonstrate that WAFL generalizes better than the standard FedAvg baseline in
non-i.i.d. settings, and outperforms related methods with respect to robustness to distribution shifts.
Moreover, WAFL reveals its capability in generalizing to unseen data distributions.
9
Under review as a conference paper at ICLR 2022
References
Peter Bartlett, Dylan J. Foster, and Matus Telgarsky. Spectrally-normalized margin bounds for neural
networks. arXiv:1706.08498 [cs, stat], December 2017. URL http://arxiv.org/abs/1706.08498.
arXiv: 1706.08498.
Jose Blanchet, Yang Kang, and Karthyek Murthy. Robust Wasserstein Profile Inference and Appli-
cations to Machine Learning. Journal of Applied Probability, 56(3):830-857, September 2019.
ISSN 0021-9002, 1475-6072. doi: 10.1017/jpr.2019.49. URL http://arxiv.org/abs/1610.05627.
arXiv: 1610.05627.
Nicholas Carlini and David Wagner. Towards Evaluating the Robustness of Neural Networks.
arXiv:1608.04644 [cs], March 2017. URL http://arxiv.org/abs/1608.04644. arXiv: 1608.04644.
Ruidi Chen and Ioannis Ch Paschalidis. A Robust Learning Approach for Regression Models Based
on Distributionally Robust Optimization. Journal of Machine Learning Research, 19(13):1-48,
2018. ISSN 1533-7928. URL http://jmlr.org/papers/v19/17-295.html.
Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. In Proceed-
ings of the 26th International Conference on Neural Information Processing Systems - Volume
2, NIPS’13, pp. 2292-2300, Red Hook, NY, USA, 2013. Curran Associates Inc.
Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Adaptive Personalized Feder-
ated Learning. arXiv:2003.13461 [cs, stat], November 2020a. URL http://arxiv.org/abs/2003.
13461. arXiv: 2003.13461.
Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Distributionally Robust Feder-
ated Averaging. In Advances in Neural Information Processing Systems, volume 33, pp. 15111-
15122. Curran Associates, Inc., 2020b. URL https://proceedings.neurips.cc/paper/2020/hash/
ac450d10e166657ec8f93a1b65ca1b14-Abstract.html.
Theo Diamandis, Yonina C. Eldar, Alireza Fallah, Farzan Farnia, and Asuman Ozdaglar. A Wasser-
stein Minimax Framework for Mixed Linear Regression. arXiv:2106.07537 [cs, math, stat], June
2021. URL http://arxiv.org/abs/2106.07537. arXiv: 2106.07537.
Canh T. Dinh, Nguyen H. Tran, and Tuan Dung Nguyen. Personalized Federated Learning with
Moreau Envelopes. arXiv:2006.08848 [cs, stat], March 2021. URL http://arxiv.org/abs/2006.
08848. arXiv: 2006.08848.
Wei Du, Depeng Xu, Xintao Wu, and Hanghang Tong. Fairness-aware Agnostic Federated Learning.
arXiv:2010.05057 [cs], October 2020. URL http://arxiv.org/abs/2010.05057. arXiv: 2010.05057.
Peyman Mohajerin Esfahani and Daniel Kuhn. Data-driven Distributionally Robust Optimiza-
tion Using the Wasserstein Metric: Performance Guarantees and Tractable Reformulations.
arXiv:1505.05116 [math, stat], June 2017. URL http://arxiv.org/abs/1505.05116. arXiv:
1505.05116.
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized Federated Learning with The-
oretical Guarantees: A Model-Agnostic Meta-Learning Approach. In Advances in Neural Infor-
mation Processing Systems, volume 33, pp. 3557-3568. Curran Associates, Inc., 2020. URL https:
//proceedings.neurips.cc/paper/2020/hash/24389bfe4fe2eba8bf9aa9203a44cdad-Abstract.html.
Nicolas Fournier and Arnaud Guillin. On the rate of convergence in wasserstein distance of the
empirical measure. Probability Theory and Related Fields, 162:707, 2015. doi: 10.1007/
s00440-014-0583-7.
Yaroslav Ganin and Victor Lempitsky. Unsupervised Domain Adaptation by Backpropagation. In
International Conference on Machine Learning, pp. 1180-1189. PMLR, June 2015. URL https:
//proceedings.mlr.press/v37/ganin15.html. ISSN: 1938-7228.
Rui Gao and Anton J. Kleywegt. Distributionally Robust Stochastic Optimization with Wasserstein
Distance. arXiv:1604.02199 [math], July 2016. URL http://arxiv.org/abs/1604.02199. arXiv:
1604.02199.
10
Under review as a conference paper at ICLR 2022
Rui Gao, Xi Chen, and Anton J. Kleywegt. Wasserstein Distributionally Robust Optimization and
Variation Regularization. arXiv:1712.06050 [cs, math, stat], October 2020. URL http://arxiv.org/
abs/1712.06050. arXiv: 1712.06050.
Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and Harnessing Adversarial
Examples. arXiv:1412.6572 [cs, stat], March 2015. URL http://arxiv.org/abs/1412.6572. arXiv:
1412.6572.
Jochen Gorski, Frank Pfeuffer, and Kathrin Klamroth. Biconvex sets and optimization with biconvex
functions: a survey and extensions. Mathematical Methods of Operations Research, 66(3):373-
407, December 2007. ISSN 1432-5217. doi: 10.1007/s00186-007-0161-1. URL https://doi.org/
10.1007/s00186-007-0161-1.
J.J. Hull. A database for handwritten text recognition research. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 16(5):550-554, May 1994. ISSN 1939-3539. doi: 10.1109/
34.291440.
Jakub Konecny, H. Brendan McMahan, Daniel Ramage, and Peter Richtarik. Federated Optimiza-
tion: Distributed Machine Learning for On-Device Intelligence. arXiv:1610.02527 [cs], October
2016. URL http://arxiv.org/abs/1610.02527. arXiv: 1610.02527.
Jakub Konecny, H. Brendan McMahan, Felix X. Yu, Peter Richtarik, Ananda Theertha Suresh,
and Dave Bacon. Federated Learning: Strategies for Improving Communication Efficiency.
arXiv:1610.05492 [cs], October 2017. URL http://arxiv.org/abs/1610.05492. arXiv: 1610.05492.
Alex Krizhevsky. Learning Multiple Layers of Features from Tiny Images. pp. 60, 2009.
Daniel Kuhn, Peyman Mohajerin Esfahani, Viet Anh Nguyen, and Soroosh Shafieezadeh-Abadeh.
Wasserstein Distributionally Robust Optimization: Theory and Applications in Machine Learn-
ing. arXiv:1908.08729 [cs, math, stat], August 2019. URL http://arxiv.org/abs/1908.08729.
arXiv: 1908.08729.
Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial Machine Learning at Scale.
arXiv:1611.01236 [cs, stat], February 2017. URL http://arxiv.org/abs/1611.01236. arXiv:
1611.01236.
Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recog-
nition. Proceedings of the IEEE, 86(11):2278-2324, November 1998. ISSN 1558-2256. doi:
10.1109/5.726791. Conference Name: Proceedings of the IEEE.
Jaeho Lee and Maxim Raginsky. Minimax Statistical Learning with Wasserstein distances. In
Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.
URL https://papers.nips.cc/paper/2018/hash/ea8fcd92d59581717e06eb187f10666d-Abstract.
html.
Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. Ditto: Fair and Robust Federated
Learning Through Personalization. arXiv:2012.04221 [cs, stat], June 2021. URL http://arxiv.
org/abs/2012.04221. arXiv: 2012.04221.
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the Convergence of
FedAvg on Non-IID Data. arXiv:1907.02189 [cs, math, stat], June 2020. URL http://arxiv.org/
abs/1907.02189. arXiv: 1907.02189.
Quande Liu, Cheng Chen, Jing Qin, Qi Dou, and Pheng-Ann Heng. FedDG: Federated Domain
Generalization on Medical Image Segmentation via Episodic Learning in Continuous Frequency
Space. arXiv:2103.06030 [cs], March 2021.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards Deep Learning Models Resistant to Adversarial Attacks. arXiv:1706.06083 [cs, stat],
September 2019. URL http://arxiv.org/abs/1706.06083. arXiv: 1706.06083.
Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. Three Approaches for
Personalization with Applications to Federated Learning. arXiv:2002.10619 [cs, stat], July 2020.
URL http://arxiv.org/abs/2002.10619. arXiv: 2002.10619.
11
Under review as a conference paper at ICLR 2022
Yishay Mansour, Mehryar Mohri, Jae Ro, Ananda Theertha Suresh, and Ke Wu. A Theory of
Multiple-Source Adaptation with Limited Target Labeled Data. In Proceedings of The 24th Inter-
national Conference on Artificial Intelligence and Statistics,pp. 2332-2340. PMLR, March 2021.
URL https://proceedings.mlr.press/v130/mansour21a.html. ISSN: 2640-3498.
H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y
Arcas. Communication-Efficient Learning of Deep Networks from Decentralized Data.
arXiv:1602.05629 [cs], February 2017. URL http://arxiv.org/abs/1602.05629. arXiv:
1602.05629.
Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. Agnostic Federated Learning.
arXiv:1902.00146 [cs, stat], January 2019. URL http://arxiv.org/abs/1902.00146. arXiv:
1902.00146.
Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay Celik, and Ananthram
Swami. The Limitations of Deep Learning in Adversarial Settings. arXiv:1511.07528 [cs, stat],
November 2015. URL http://arxiv.org/abs/1511.07528. arXiv: 1511.07528.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward
Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,
Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style, High-Performance
Deep Learning Library. In Advances in Neural Information Processing Systems 32, Vancouver,
BC, Canada, 2019.
Xingchao Peng, Zijun Huang, Yizhe Zhu, and Kate Saenko. Federated Adversarial Domain Adap-
tation. arXiv:1911.02054 [cs], December 2019.
Gabriel Peyre and Marco Cuturi. Computational optimal transport: With applications to data Sci-
ence. Foundations and Trends® in Machine Learning, 11(5-6):355-607, 2019. ISSN 1935-8237.
doi: 10.1561/2200000073. URL http://dx.doi.org/10.1561/2200000073.
Amirhossein Reisizadeh, Farzan Farnia, Ramtin Pedarsani, and Ali Jadbabaie. Robust Federated
Learning: The Case of Affine Distribution Shifts. arXiv:2006.08907 [cs, math, stat], June 2020.
URL http://arxiv.org/abs/2006.08907. arXiv: 2006.08907.
Filippo Santambrogio. Optimal Transport for Applied Mathematicians: Calculus of Variations,
PDEs, and Modeling. Progress in Nonlinear Differential Equations and Their Applications.
Birkhauser Basel, 2015. ISBN 978-3-319-20827-5. doi: 10.1007/978-3-319-20828-2. URL
https://www.springer.com/gp/book/9783319208275.
Soroosh Shafieezadeh Abadeh, Peyman Mohajerin Mohajerin Esfahani, and Daniel Kuhn. Dis-
tributionally Robust Logistic Regression. In Advances in Neural Information Processing Sys-
tems, volume 28. Curran Associates, Inc., 2015. URL https://papers.nips.cc/paper/2015/hash/
cc1aa436277138f61cda703991069eaf-Abstract.html.
Soroosh Shafieezadeh-Abadeh, Daniel Kuhn, and Peyman Mohajerin Esfahani. Regularization via
Mass Transportation. arXiv:1710.10016 [cs, math, stat], July 2019. URL http://arxiv.org/abs/
1710.10016. arXiv: 1710.10016.
Shai Shalev-Shwartz and Shai Ben-David. Understanding Machine Learning: From Theory to
Algorithms. Cambridge University Press, USA, 2014. ISBN 978-1-107-05713-5.
Aman Sinha, Hongseok Namkoong, Riccardo Volpi, and John Duchi. Certifying Some Distribu-
tional Robustness with Principled Adversarial Training. arXiv:1710.10571 [cs, stat], May 2020.
URL http://arxiv.org/abs/1710.10571. arXiv: 1710.10571.
Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet Talwalkar. Federated Multi-Task
Learning. arXiv:1705.10467 [cs, stat], February 2018. URL http://arxiv.org/abs/1705.10467.
arXiv: 1705.10467.
Ananda Theertha Suresh, Felix X. Yu, Sanjiv Kumar, and H. Brendan McMahan. Distributed Mean
Estimation with Limited Communication. arXiv:1611.00429 [cs], September 2017. URL http:
//arxiv.org/abs/1611.00429. arXiv: 1611.00429.
12
Under review as a conference paper at ICLR 2022
Florian Tramer, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, and Patrick Mc-
Daniel. Ensemble Adversarial Training: Attacks and Defenses. arXiv:1705.07204 [cs, stat],
April 2020. URL http://arxiv.org/abs/1705.07204. arXiv: 1705.07204.
Jianyu Wang, Zachary Charles, Zheng Xu, Gauri Joshi, H. Brendan McMahan, Blaise Aguera y
Arcas, Maruan Al-Shedivat, Galen Andrew, Salman Avestimehr, Katharine Daly, Deepesh Data,
et al. A Field Guide to Federated Optimization. arXiv:2107.06917 [cs], July 2021. URL http:
//arxiv.org/abs/2107.06917. arXiv: 2107.06917.
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. Federated
Learning with Non-IID Data. arXiv:1806.00582 [cs, stat], June 2018. URL http://arxiv.org/abs/
1806.00582. arXiv: 1806.00582.
13
Under review as a conference paper at ICLR 2022
A Adversarial Robust FL’s Ambiguity Set v.s. Wassertein Ball
We show that using the Wasserstein ambiguity set contains the perturbation points induced by the
solution to the Adversarial Robust FL approach. As we present in Sec. 3.2, existing techniques for
adversarial training robust models (Goodfellow et al., 2015; Papernot et al., 2015; Kurakin et al.,
2017; Carlini & Wagner, 2017; Madry et al., 2019; Tramer et al., 2020) define an adversarial pertur-
bation u at a data point Z, and minimize the following worst-case loss over all possible perturbations
max E
u∈U
Z〜Pλ
(10)
where the ambiguity set U := u ∈ Rd+1 : kuk ≤	. To compare this approach with Wasserstein-
robust FL, we relate the above problem to its counterpart defined in the probability space of input as
follows
屋aX 4〜Q p(Zr, hθ)],
(11)
where Q(e) := {Q : P[∣∣Z - Zk ≤ e] =1,Z 〜Pλ, Z 〜Qo . Considering u*
problem (10), we see that the distribution Q0 of perturbation points (i.e., Z :=
as a solution to
(Z + u*)〜Q)
in problem (10) belongs to the feasible set Q(e) in problem (11) (If not, then P[∣∣u*k ≤ e] < 1, a
contradiction). Next, consider an arbitrary distribution Q ∈ Q(e) in problem (11), with any Z 〜 Q
and Z 〜 Pλ, we have
w.p.1
kZ - Zk≤ e =⇒ EZ〜Pλ'Z~Q [kZ - Zk] ≤ e =⇒ ∏∈∏i⅛,Q) E(Z,Z"∏ [kZ - Zk] ≤ e，
which implies that Wι(Pλ,Q) ≤ e,∀Q ∈ Q(e), and thus Q(e) ⊂ Bι(Pbλ,e). We have shown
that the Wasserstein ambiguity set contains the perturbation points induced by the solution to the
adversarial robust training problem (10).
B CHOOSING λ: GENERALIZING TO ALL CLIENT DISTRIBUTIONS
We show that by calibrating appropriate λ value, our proposed algorithm will be capable of general-
izing to all client distributions. Suppose we want to cover all client distributions inside a Wassertein
ball so that the generalization and robustness result by WAFL in Theorem 2 is applicable to all
clients’ distributions. This is the problem of finding λ such that the Wasserstein distance between
Pλ and Pj , ∀j, is as small as possible. Instead of directly finding the minimum Wasserstein ra-
dius that cover all client distributions, we will leverage the popular Wasserstein barycenter problem
(Peyre & Cuturi, 2019). Specifically, consider the problem
m
min W2(Pλ,P Y) s.t. P Y = arg min Ei=JiW? (Pni ,Q),	(12)
where PY is the Wasserstein bary center w.r.t the solution λ* to this problem. Even though the
solution is not straightforward, we propose to solve its tractable upper-bound:
m
λ∈∆m,iQn∈PXi=1λiW2(Pbni,Q).	(13)
This is a bi-convex problem, which is convex w.r.t to λ (resp. Q) when fixing Q (resp. λ). Thus,
we can use alternative minimization (Gorski et al., 2007) to find a local solution to this problem.
Denoting λ as the solution to (12) and (λ*,P*) as a local solution to (13), we obtain
m
W2(P又,PY) ≤ W2(Pλ*,P*) ≤ Ei=*W2(Pni,P*)=: ρ*.	(14)
Corollary 3. For all client j ∈ [m], with probability at least 1 - δ, we have
W2(Pλ*,Pj) ≤ W2(Pλ*,Pλ*) + W2(Pv,p*) + W2(P*,Pnj) + W2(Pnj,Pj)
≤ rX=κ+ρ*+λ+祗;
14
Under review as a conference paper at ICLR 2022
Proof. The first line is by triangle inequality. The second line is by following facts: (i)
P[w2(Pλ*,Pλ*) ≥ JPm=I λ视/m] ≤ δ∕2 according to (37), (ii) W2(P*,Pb∙)=
λjW2(P ,Pnj) ≤ g, and (iii) P[W2(Pnj,Pj) ≥ pn/2] ≤ δ∕2 according to (35), and (iv) using
union bound.	□
C Proof of Theorem 1
Our proof is based on the analysis of local SGD for FL presented in Wang et al. (2021).
Fix some Zi. Define 夕(Z, θ; Zi) := '(Z, hθ) - γd(Z, Zi). Since ' is Lzz-smooth and d is 1-strongly
convex,夕(Z, θ; Zi) is (γ - Lzz)-strongly concave with respect to Z, given that Y > Lzz.
Lemma 2. Let	z*	= arg maxζ∈z	夕(Z,θ;	Zi).	Therefore,	φγ(θ; Zi)	= ψ(ζ↑, θ;	zi).	Let ' satisfy
Assumption 3. Then φγ is differentiable, and
kVφγ(Zi,θ) -Vφγ(Zi,θ0)k ≤ Lkθ - θ0k,
with L = Lθθ + LzL when Y > Lzz.
γ-Lzz
The proof can be found in (Sinha et al., 2020, Lemma 1). Lemma 2 implies that φγ is L-smooth.
Define gi(θ):=由 Pz.∈p. Vθ φγ(Zi,θ), then We have
E kgi(θ) - VFi(θ)k2
Ehll ∣D^T X vΘ φγ (Zi, θ) - vFi(θ)∣l ]
|Di| z.∈D.
≤ ∣⅛Ehl∣gφi(θ) -vFi(θ)l∣2] ≤ |Di| := σ2
(by Assumption 4.)
(15)
With the shadow sequence Mk) = Pm=I λiθ(t,k), we have
mm	m
θ(t,k+1) = X λiθ(t,k+1) = X λi(θ*) - ηgi(θ*))) = θ(t,k) - ηX λigi(θ*)).
i=1	i=1	i=1
Lemma 3. Ifthe client learning rate satisfies η ≤ ɜɪ, then
1 K-1
—X E
K乙
F(展t，k)) - F(θ*)
k=0
m	m	K-1
Xλ2	+ LXλi X KE[kθ*)-即，k)k2]
i=1	i=1	k=0
- Ehkθ(t+1) - θ*k2] .
Proof. Since θ(t,k+1) = Mk) - η Pm=I λigi(θ(t,k)), by parallelogram law
m
Xλi Dgi(θ(t,k)),θ(t,k+1) -θ*E = — (kθ(t,k) -θ*k2 - kθ(t,k+1)- θ(t,k)k2 - M(t，k+1) -θ*k2).
i=1	2η
(16)
Fact: Fi(θ) = EZi〜p.[φγ(Zi,θ)] is Lipschitz smooth with L = Lθθ + L-Lz when Y > Lzz.
With the assumption that θ → '(z, hθ) is convex, we have θ → Fi(θ) is convex.
Since Fi is convex and L-smooth,
Fi0t,k+1)) ≤ Fi(θ(t,k)) + DVFi(θ(t,k)), θ(t,k+1) - θ(t,k)E + LM(t，k+1) - θ(t,k)k2
≤Fi(θ*) + (VFi(θ(t,k)),夕(t,k+1)- θ*) + LM(t，k+1)- θ(t,k)k2
≤Fi(θ*) + DVFi(θf,仪t,k+1) - θ*) + LM(t,k+1)- θ(t,k)∣∣2 + Lkθ(t,k) - 0(t,k)k2.	(17)
15
Under review as a conference paper at ICLR 2022
From (16) and (17), We have
m
F物，k+1)) - F(θ*) = X λi (Fi(ak+1)) - F(θ*))
i=1
m
m
≤ X λi EFi(θ(t,k)) - gi(θ(t,k)),即，k+1)- θ*) + Lk型,k+1)- θ(t,k)k2 + L Xλi∣θ(t'k) -夕Gk)k2
i=1
+ ɪ(M(t,k) - θ*k2 - M(t，k+1)-心k)k2 - ∣θ(t,k+1)- θ*k2).
We have
m
i=1
(18)
E[Xλi (VFi(θ(Ak))- gi(θit'k')),θ^k+1 - θ*)]
i=1
m
=E [X λi <VFi(θ(Ak))- gi(θ(t,k)), θ(t,k+1)-*”](since E[gi(θ(t'k))] = VFi(θ(t'k)) given 型k),θ*)
i=1
m
≤ 2 η ∙ EhkX λi(VFi(θit,k') - gi(θit,k ))k2] + 6- E[kθ(t,k+1)- θ)(t,k) ∣∣2i	(by Peter Paul inequality)
i=1	η
≤ 2η^2
+ ɪEhM(t，k+1)-即，k)k2],
(19)
Plugging (19) back to the conditional expectation of (18), and noting that η ≤ 3L, We have
EhF(即，k+1)) - F(θ*)] + ɪ
E k型，k+1) - θ*∣∣2
-MM) — θ*∣∣2
≤2ησ2 (X λ2)- G-lH k展t,k+D - H(Mk)k
2
m
+ LX λikθi(t,k) - θH(t,k)k2
i=1
m
m
≤2ησ2 (X λ2)+L X 巾针)
—
i=1
i=1
By convexity of F and telescoping k from 0 to K - 1, We have
m
K-1
K-1	m
KK X E F(θ(tk) - F(θ*) ≤2ησ2 X λ2
k=0
i=1
+ 21K (l
m K-1
+ L Xλi X KE[kθ*)- θ(t,k)k2i
i=1 k=0
--θ*k2 - E∣j∣θ(t,K)- θ*k2i).
Since θ(t,0) = θ(t) and θ(t,K) = θ(t+1), we complete the proof.	□
Lemma 4 (Bounded client drift). Assuming the client learning rate satisfies η ≤ 3L, we have
E[kθ*) - H(t，k)k2i ≤ η2(24K2Ω2 +20KΩ2).
where Ω2 := max{b2, Ω2 }.
Proof.
Eθ1(t,k+1)
=kθ1(t,k) - θ
- θ2(t,k+1)2
2	=E	θ1(t,k)
- θ2(t,k) - ηg1(θ1(t,k)) - g2(θ1(t,k))2
2(t,k)k2 - 2η g1(θ1(t,k)) - VF1(θ1(t,k)), θ1(t,k) - θ2(t,k)
-2η (VF2(θ(t,k)) - g2(θ2t,k)),θ(t,k) - θ2t,k))
-2η DvFι(θ(t,k)) - VF2(θ尸),θ(t,k) -θ(t,k)E + η2kgι(θ(t,k)) - g2(θ2t,k))k2.	(20)
16
Under review as a conference paper at ICLR 2022
The second term (and similarly for the third term) is bounded as follows
-Dg1(θ(t,k)) - vF1(θ(t,k)),θ(t,k) - θ2t,k)E
≤ 6~1κ∖∖θι,k) - θ2t,k) l∣2 + 32Kllgι(θ(t,k)) - VFι(θ(t,k))∣∣2 (by Peter Paul inequality)
=心帆t,k)-θff + 3ηKb2	(by(15))
6ηK	2
Since maxi supθ∣∣VFi(θ) 一 VF(θ)k ≤ Ω (Assumption 5), the 4th-term is bounded as
- DvF1(θ1(t,k)) - vF2(θ2(t,k)), θ1(t,k) - θ2(t,k)E
≤ -DVF(θ(t,k)) - VF(θ(t,k)),θ(t,k) - θ(t,k)E + 2Ω∣θ(t,k) - θ2t,k)k
≤ - IkVF(θ(t,k)) - VF(θ2t,k))k2 + 2Ωkθ(t,k) - θ2t,k)k	(by smoothness and convexity)
≤ -力IVF(θ(t,k)) - VF(θ2t,k))k2 + ^ɪ-^kθ(t,k) - θ(t,k)k2 + 6ηKΩ2	(by Young's inequality)
The last term is bounded as follows
kg1(θ1(t,k)) - g2(θ2(t,k))k2
≤ 5llg1(θ1(t,k)) - VF1(θ1(t,k))ll2 + kVF1(θ1(t,k)) - VF (θ1(t,k))k2 + kVF (θ1(t,k)) - VF (θ2(t,k))k2
+ kVF (θ2(t,k)) - VF2(θ2(t,k))k2 + llg2(θ2(t,k)) - VF2(θ2(t,k))ll2
≤ 5∣VF(θ(t,k)) - VF(θ2t,k))k2 + 10(b2 + Ω2) (by (15) and Assumption 5)
Substituting the above four bounds back to (20) gives (note that η ≤ 3L)
E[kθ(t,k+1)-θ2t,k+I)k2] ≤ (l + }^kθ(t,k) - θ2t,k)k2 - η(2 - 5η)∖VF(θ(t,k)) -VF(θ2t,k))∖∖2
+ 6η2Kb2 + 12η2K Ω2 + 10η2(b2 + Ω2)
≤(1 + ") kθ(t,k) - θ(t,k)k2 + 6η2Kb2 + 12η2KΩ2 + 10η2(b2 + Ω2).
Unrolling recursively, we obtain
Eh∖∖θ(t,k+1) - θ(t,k+1)ll2i ≤ (1 + 1/K_-1 ∣6η2Kb2 + 12η2KΩ2 + 10η2(b2 +
≤ 12η2 K 2σ2 + 24η2K 2Ω2 + 20η2K (b2 + Ω2)
≤ η2(24K2Ω2 + 20KΩ2).
where We use the fact that(1+1/K-1 ≤ K(e - 1) ≤ 2K, and Ω2 := max{σ2, Ω2}.
By convexity, for any i,
E[kθ(t,k+1)- θ(t,k+I)k2] ≤ η2(24K2Ω2 +20KΩ2).
□
Substituting the result of Lemma 4 to Lemma 3, and telescoping over t, we obtain
1 T-1 1 K-1	D2
E[T X K X F(θ(t,k)) - F(θ*)] ≤2τT + 2ησ2Λ + η2L(24K2Ω2 + 20KΩ2),
t=0	k=0	η
17
Under review as a conference paper at ICLR 2022
m
where D := ∣∣θ(0) - θ*k, Λ := P λi2. By optimizing η on the R.H.S, We obtain
i=1
Eh KT X X1F 0D- F Si ≤O( LDT+√KKΛ=+
t=0 k=0
when
η = min
ʃɪ____________________________
[3L, 2√KTΛb, 483K2T3L 1 Ω3,403KT 1 L3Ω
ɪ}.
D Proof of Lemma 1
We first prove the following fact:
Fact 1:
(a)
(b)
L(Q,f) ≤Lργ(Pλ,f),	∀f∈F,Q∈B(Pλ,ρ).
fi0n∈fFL(Q,f0) ≤fi0n∈fFLργ(Pλ,f0),	∀Q ∈ B(Pλ, ρ).
For (a), we have
L(Q,f)≤
P0∈BPλ,ρ)L(p0,f )=砥卜ρ2+Ez~Kφγ (Z,f)]}
≤ γρ2 + EZ〜Pλ 卜)(Z,f)] =: LY(Pλ,f),
where the equality is due to strong duality result by Gao & Kleywegt (2016).
For (b), defining fPλ := argminf0∈FLργ(Pλ,f0), we have
i0nf L(Q,f0) ≤L(Q,fPλ) ≤ sup	L(P0,fPλ)	(21)
f0∈F	P 0∈B(Pλ,ρ)
=γ0%{ γ0ρ2 + EZ〜Pλ [φγ(Z,fPλ )i}	(22)
≤ γρ2 + EZ〜Pλ[φγ(Z,fPλ)i	(23)
= i0nf Lγρ(Pλ,f0).	(24)
f ∈F
We next prove the second fact:
Fact 2:
(a)
(b)
LY (Pλ,f) ≤ L(Q,f ) + 2Lz P + ∣γ - γ*∣ρ2, ∀f ∈F ,Q ∈B(Pλ,P)
%FLY(Pλ,f0) ≤ finfFL(Q,f0) + 2LzP + ∣γ - Y*∣ρ2.
For (a), we have:
LYρ(Pλ,f)=	sup	L(P0,f)
P0∈B(Pλ ,ρ)
+ LYρ(Pλ,f) -	sup	L(P0,f)
P0∈B(Pλ ,ρ)
L 1 Ω 2 D 3

K 3 T 3
+
L 1 Ω 2 D 3

D
D 3
D 3
≤ {L(Q,f) + 2Lzp0 + {eZ〜Pλ [φγ(Z, f)] + P2Y - min {^70 + EZ〜Pλ [φγ0 (Z,f)]
≤ L(Q,f) + 2LzP + ρ2(Y - γ*) + EZ〜P hφγ(Z, f) - φγ* (Z,f )i
=L(Q,f) + 2LzP + P2(Y - Y*) + EZ〜P SUP
ζ∈Z
n`(z, h) - γd(ζ, z )o - supn'(Z, h)-γ*d2(Z, Z)o]
=L(Q,f) + 2Lz P +(γ - γ*) W- EZ〜P [ sup d2(Z, Z)D
≤ L(Q,f)+2LzP + ∣γ - γ*∣ρ2,
18
Under review as a conference paper at ICLR 2022
where the first inequality is due to Proposition 1, and the last inequality is because we choose γ ≥
Lz/ρ and that fact that Y* ≤ Lz/p by Lemma 1 of Lee & Raginsky (2018).
For (b), defining fQ := arg minf∈F L(Q, f), we have
i0nf Lργ(Pλ,f0) ≤Lργ(Pλ,fQ)
f ∈F
≤ L(Q, fQ) + 2LzP + |Y - γ*lp2
=inf L(Q,f0) + 2LzP + ∣γ - γ*∣p2,
f ∈F
(25)
(26)
(27)
where the second line is due to Fact 2(a).
Combining all facts, we complete the proof. Specifically, by adding two inequalities in Fact 1(a)
and Fact 2(b), we obtain the upperbound of Lemma 1. Similarly, adding two inequalities in Fact
1(b) and Fact 2(a), we obtain the lowerbound of this lemma.
Finally, we provide the proof of the following proposition that was used in proving Fact 2(a).
Proposition 1. Let Assumption 2 (a) holds. For any f ∈ F and for all Q ∈ B(Pλ, P), we have
sup	L(P0, f) ≤ L(Q, f) + 2LzP.
P 0∈B(Pλ,ρ)
Proof. Denote P* := arg max L(P0, f). We have
P 0∈B(Pλ,ρ)
sup	L(P0,f)=L(Q,f)+	sup	L(P0,f)-L(Q,f)
P 0∈B(Pλ,ρ)	P 0∈B(Pλ,ρ)
≤ L(Q,f) + |L(P*,f) - L(Q,f)|,
≤ L(Q,f) + LzlEZ〜P* ['(Z, h)∕Lz] — EZ〜Q ['(Z, h)/Ln ∣
≤ L(Q, f) + LzW1(P*, Q)
≤L(Q,f)+Lz[W2(P*,Pλ)+W2(Pλ,Q)]	(28)
≤ L(Q, f) + Lz2P,
where the fourth line are due to Kantorovich-Rubinstein dual representation theorem, i.e.,
W1(P, Q)
sup
h
{Ez〜P [h(Z)] — EZ〜Q [h(Z)] : h(∙) is I-LiPsChitz}
and the fifth line is due to W1(P*, Q) ≤ W2(P*, Q) and triangle inequality.
□
E Proof of Theorem 2
Proof. To simplify notation, we denote Φ := φγ◦F = {z → φγ(z,f ),f ∈ F} where F = {fθ, θ ∈
Θ ⊂ Rd , which rePresents the comPosition of φγ with each of the loss function fθ Parametrized
by θ belonging to the parameter class Θ.
Defining fp* ∈ argminf∈fLY(Pλ,f) and b* ∈ argmin EZ〜b[φγ(Z,fθ)] such that
θ∈Θ
LY (Pλ,fθ* )= inΘ [ez 〜a]。,(Z,fθ )] +γP2 , we decompose the excess risk as follows:
19
Under review as a conference paper at ICLR 2022
Eγρ(Pλ,fθbε)=Lργ(Pλ,fθbε)- infLγρ(Pλ,f)
f∈F
=Lργ(Pλ,fθbε)-Lργ(Pλ,fPλ)
=[LY (Pλ,fbε ) — LY (Pl,f.)] + [LY (Pλf ) — LY (Pλ,fb*)]
'------------------------}
""^^^^^^^^^^^^^^^{^^^^^^^^^^^^^^"""
≤ε
+ [Lγ (Pbλ,fb) - LY (Pλ,fPλ)] +[LY (Pλ,fPλ) - LY (Pλ,fPλ)]
|
{z^
≤0
}
≤ 2；UpIEZ~Pλ [φγ(Z, fθ)] - Ez~Pλ [φγ(Z,fθ)]∣ + ε
m
X λJEZi~Pi[φγ(Zi, fθ)] - EZi~Pi [φγ(Zi, fθ)] I + ε
≤ 2 sup
φγ ∈Φ
m
i=1
≤ 2 λi
i=1
m
≤ λi
i=1
4Ri(Φ) + 2M'j
2 log(2m∕δ)
ni
+ ε with probability at least 1 - δ, (29)
where the first inequality is due to optimization error and definition of θ*. The second inequality is
due to the fact that ∣Pm=ι λiai∣ ≤ Pm=I λi∣ai∣, ∀ai, ∈ R and λ% ≥ 0. The third inequality is because
pushing the sup inside increases the value. For the last inequality, using the facts that (i) ∣φγ (z, f) | ≤
m` due to -M' ≤ '(z, h) ≤ φγ(z, f) ≤ sup%∈z '(z, h) ≤ m` and (ii) the Rademacher complexity
of the function class Φ defined by Ri(Φ) = E[supφγ ∈φ n1- Pn= 1 σk φγ (Zk, fθ)] where the expecta-
tion is w.r.t both Zk i吧. Pi andi.i.d. Rademacherrandomvariable σk independent of Zk, ∀k ∈ [ni],
we have
sup ∣Ez"i[Φγ(Zi,fθ)] - Ez∙~p∙[φγ(Zi,fθ)]∣ ≥ 2Ri(Φ) + MgJ∙
φγ∈Φ	i i
2log^m0	(30)
ni
with probability ≤ δ∕m due to the standard symmetrization argument and McDiarmid,s inequal-
ity (Shalev-Shwartz & Ben-David, 2014, Theorem 26.5). Multiplying λi to both sides of (30),
summing up the inequalities over all i ∈ [n], and using union bound, we obtain (29).
Define a stochastic process Xφγ φ ∈Φ
1 ni
Xφγ := √≡Σσk φY (Zk , fθ )
ni k=1
which is zero-mean because E Xφγ = 0 for all φY ∈ Φ. To upper-bound Rn (Φ), we first show
that Xφγ φ ∈Φ is a sub-Gaussian process with respect to the following pseudometric
φY - φ0Y∞ := sup ∣∣∣φY (z, fθ) - φY(z, fθ0)∣∣∣.	(31)
For any t ∈ R, using Hoeffding inequality with the fact that σk, k ∈ [n], are i.i.d. bounded random
variable with sub-Gaussian parameter 1, we have
E exp t Xφγ - Xφ0γ	= E
exp ^√= X σk (φY (Zk ,fθ ) - φ (Zk ,fθ0 )))]
exp
σ1 (φY (Z1, fθ) - φY (Z1, fθ0))
ni
≤ exp
2
20
Under review as a conference paper at ICLR 2022
Then, invoking Dudley entropy integral, we have
√ni Ri(Φ) = E sup Xφγ
φγ∈Φ
∞
≤12 0
,log N (ΦJ∙k∞,e)de
(32)
We will show that when θ 7→ `(z, hθ) is Lθ-Lipschitz by Assumption 2, then θ 7→ φγ (z, fθ) is also
Lθ-Lipschitz as follows.
∣φγ(z,fθ) - φγ(z,fθθ)∣ = ∣supgn! {'(Z,hθ) - γd(Z,z) - '(Z0,hθ0) + γd(Z0, z)}∣
≤ ∣ sup {'《,he) — '(Z, hθ,)}∣
≤ sup∣'(Z, hθ) — '(Z, hθo)∣
ζ∈Z
≤ Lθkθ - θ0k,
which implies
φγ - φ0γ ∞ ≤ Lθ kθ - θ0 k.
Therefore, by contraction principle (Shalev-Shwartz & Ben-David, 2014), we have
N(ΦJ∙k∞,E) ≤N(ΘJ∙k,"Lθ).	(33)
Substituting (33) and (32) into (29), we obtain
EY (Pf ≤ X %[竺等+ 2M'S 华mδ)# + ε,	(34)
i=1	ni	ni
which will be substituted into the upper-bound in Lemma 1 to complete the proof.	□
F Proof of Corrolary 1
We now present how we adapt the result from Fournier & Guillin (2015) to prove Corollary 1
Proposition 2 (Measure concentration (Fournier & Guillin, 2015, Theorem 2)). LetP be a probabil-
ity distribution on a bounded set Z. Let Pn denote the empirical distribution of Zι,..., Zn k P.
Assuming that there exist constants a > 1 such that A := EZ〜P [exp(∣∣Z∣∣a)] < ∞ (i.e., P is a
light-tail distribution). Then, for any ρ > 0,
ci exp (—C2npmax{d/p,2})	if P ≤
c1 exp (-c2nρa )	ifρ >
1
1
where c1 , c2 are constants depending on a, A and d.
As a consequence of this proposition, for anyδ > 0, we have
((log(cι∕δ) Imin{2/d，1/2}
Pg(Pn ,P) ≤ ρni ≥ 1 — δ Where Pn :=|(工"
if n ≥ log©m
c2
ifn< log©®
c2
(35)
In Proposition 2, Fournier & Guillin (2015) show that the empirical distribution Pn converges in
Wasserstein distance to the true P at a specific rate. This implies that judiciously scaling the radius
of Wasserstein balls according to (35) provides natural confidence regions for the data-generating
distribution P.
By the duality of transport cost (Santambrogio, 2015, p.261), we have
wp(μ,ν)
sup
W(x)+ψ(y)≤dp(x,y)
/ φ dμ + ψ dν =
sup	Tf (μ,ν),
φ(χ)+ψ(y)≤dp(χ,y)
∀p ≥ 1,
21
Under review as a conference paper at ICLR 2022
which is the supremum of linear functionals Tf : P × P → R defined by Tf(μ,ν)
h(μ, V),(夕，ψ)i; therefore, (μ, V) → Wp(μ, V) is convex. Thus We have
i=1
Then, we have
p[w2(Pλ,Pλ) ≥ rX=1λ 溪nim i
W22(Pλ,Pbλ) = W22 Xm λi(Pbni,Pi) ≤Xm λiW22(Pbni,Pi).
i=1
m
p[w22(Pλ,Pλ) ≥ X λib∕m]
i=1
mm
≤ PX λiW∣(F>ni ,Pi) ≥ X λib∕m]
i=1	i=1
m
≤ X p W2lPi,,Pi) ≥ b/m]
i=1
m
X p M (Pi, ,Pi) ≥ b∕2m]
i=1
≤
m
X —
2m
i=1
(36)
(37)
δ
2
where the first inequality is due to (36), the second inequality is due to the union bound, and the last
inequality is due to Proposition 2 and (35).
According to (28), by setting P = (Pm=I λib(m) / in Theorem 2 and using union bound, we
complete the proof.
G Additional Experimental Settings And Results
G. 1 Datasets
Table 1: Statistics of all datasets using in the experiments.
Dataset	m	Total samples	Num labels / client	Samples / client	
				Mean	Std
CIFAR-10	20	43,098	3	2154	593.8
MNIST	100	70,000	2	700	313.4
MNIST-M	100	70,000	2	700	322.4
We distribute all datasets to clients as follows:
•	MNIST: A handwritten digit dataset (Lecun et al., 1998) including 70, 000 instances be-
longed to 10 classes. We distribute dataset to m = 100 clients and each client has a different
local data size with only 2 of the 10 classes.
•	CIFAR-10: An object recognition dataset (Krizhevsky, 2009) including 60, 000 colored
images belonged to 10 classes. We partition the dataset to m = 20 clients and there are 3
labels per client. Each client has a different local data size.
•	Three handwritten digit: MNIST, MNIST-M (Ganin & Lempitsky, 2015), and USPS
(Hull, 1994). We distribute one dataset, for example, MNIST to 100 source clients, and
leave MNIST-M to the target client. Each source client has only 2 labels over 10 labels. As
the number of data samples in USPS is relatively small amount (9,298 samples), we only
use this dataset for the target client.
We standardize and randomly split all datasets with 75% and 25% for training and testing, respec-
tively. In domain adaptation, the target client only has test data. The statistics of all datasets are
summarized in Tab. 1.
22
Under review as a conference paper at ICLR 2022
AVEn¥"qot0
50	100	150	200	0
T
CIFAR: Clean Data
m8J -IO
50	100	150	200
T
AVEn¥"q£9
WAFL:
0.55
0.50
>0.45
e
3 0.40-
⅛
∣0-35
a 0.30
0.25
0.20
0	50	100	150	200	0
T
Ssσl"qq9
CIFAR: Clean Data
C∣FAR: UnderDistribution Shifts
C∣FAR: UnderDistTibution Shifts
m8J -SO-O
0	50	100	150	200
T
50	100	150	200	0	50	100	150	200
T	T
→- WAFL: Y= 0.5
Figure 5: Convergence of WAFL.
G.2 Models
The details of models for each dataset is provided as follows:
•	MNIST: We use a multinomial logistic regression model (MLR) with a cross-entropy loss
function and an L2-regularization term.
•	CIFAR-10: We use a CNN model employed in McMahan et al. (2017).
•	Set of three handwriten digits: We use a multinomial logistic regression model (MLR)
with a cross-entropy loss function and an L2-regularization term.
In all settings, we randomly sample 10 clients to participate in training the global robust model
in each communication round, and set the number of local epochs to K = 2 and the number of
communication rounds to T = 200. All experiments were conducted using PyTorch (Paszke et al.,
2019).
G.3 CONVERGENCE OF WAFL
We verify the convergence of WAFL under two cases: clean data (no attacked clients) and distri-
bution shifts (where 40% of clients are attacked). In each case, we use two datasets: MNIST and
CIFAR-10 and employ the same setup as in Sec. 6. Specifically, for MNIST, we distribute the dataset
to 100 clients and set γ = 0.05. For CIFAR-10, we use 20 clients and set γ = 0.5. We use T = 200
communication iterations.
To show WAFL’s convergence, we plot both the original loss (using the function `) and global
accuracy in Fig. 5.
G.4 Domain Adaptation.
We show that WAFL demonstrates its superior capability in domain adaptation by collaboratively
learning from a multi-source domain Pbλ, and applying it to an unseen, but related, target domain
Q. In federated domain adaptation (Peng et al., 2019; Liu et al., 2021), source domains often need
access to the private data of target domains to find a common representation to aid training. However,
this violates the data privacy assumption of FL. By contrast, the construction of the model in WAFL
does not involve such private data.
Our experimental set up is as follows. We consider three datasets: MNIST (mt), MNIST-M (mm)
and USPS (up), which are widely used in domain adaptation. Among these datasets, we consider
23
Under review as a conference paper at ICLR 2022
Table 2: Domain adaptation performance of WAFL and FedAvg as an accuracy on the target dataset.
Algorithm	mt→mm	mt→up	mm→up	mm→mt	Average
WAFL	40.23	66.94	62.04	79.27	62.12
FedAvg	37.71	66.08	58.60	75.80	59.55
one dataset as a source domain (distributed to 100 clients), and another dataset as a target domain
(assumed to be on one client). For example, if mt is used as the source and mm the domain, we
use mt→mm to denote this case. Specifically, the mm dataset is distributed to 100 clients to learn
a global model, then the model is tested on the mt dataset. We compare WAFL against the vanilla
FedAvg as a baseline, and report the accuracy on the target dataset in several scenarios in Tab. 2.
WAFL markedly improves from FedAvg in all cases. On average, the accuracy of WAFL is 2.5 per-
centage point higher than that of FedAvg. This indicates WAFL’s benefits in transferring knowledge
from multi-sourced, private client distributions to a new target distribution.
24