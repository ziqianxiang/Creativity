Under review as a conference paper at ICLR 2022
Non-reversible Parallel Tempering for
Uncertainty Approximation in Deep Learning
Anonymous authors
Paper under double-blind review
Ab stract
Parallel tempering (PT), also known as replica exchange, is the go-to workhorse for
simulations of multi-modal distributions. The key to the success of PT is to adopt
efficient swap schemes. The popular deterministic even-odd (DEO) scheme exploits
the non-reversibility property and has successfully reduced the communication
cost from O(P 2) to O(P ) given sufficient many P chains. However, such an
innovation largely disappears in big data problems due to the limited chains and
extremely few bias-corrected swaps. To handle this issue, we generalize the DEO
scheme to promote the non-reversibility and obtain an appealing communication
cost O(P log P) based on the optimal window size. In addition, we also analyze
the bias when we adopt stochastic gradient descent (SGD) with large and constant
learning rates as exploration kernels. Such a user-friendly nature enables us to
conduct large-scale uncertainty approximation tasks without much tuning costs.
1 Introduction
Langevin diffusion is a standard sampling algorithm that follows a stochastic differential equation
dβt = -VU (βt)dt + √2TdWt,
where βt ∈ Rd, VU(∙) is the gradient of the energy function U(∙), Wt ∈ Rd is a BroWnian motion,
and T is the temperature. The diffusion process converges to a stationary distribution ∏(β) H e-U(β)
and setting T = 1 yields a Bayesian posterior. When U(∙) is convex, the rapid convergence has been
widely studied in Durmus & Moulines (2016); Dalalyan (2017); however, when U(∙) is non-convex, a
slow mixing rate is inevitable (Raginsky et al., 2017). To accelerate the simulation, replica exchange
Langevin diffusion (reLD) proposes to include a high-temperature particle βt(P), where P ∈ N+ \ {1},
for exploration. Meanwhile, a low-temperature particle βt(1) is presented for exploitation:
dβ(P) = -VU (β(P ))dt + √2τ(P) dWt(P),
dβ(1) = -VU (β(1) )dt + p2τ ⑴ dWt(1),
(1)
where T(P) > T(1) andWt(P) is independent of Wt(1). To promote more explorations for the
low-temperature particle, the particles at the position (β(1), β(P)) ∈ R2d swap with a probability
aS(β⑴,β(P)) = a ∙ (l ∧ e(T(1)-&)(U(e(I))-U(e(P)))),	⑵
where a ∈ (0, ∞) is the swap intensity. In specific, the conditional swap rate at time t follows that
P(βt+dt = (β(P ),β(1))∣βt = (β(1),β(P))) = aS(β(1),β(P ))dt,
P(βt+dt = (β ⑴，β(P ))∣βt = (β(1),β(P))) = 1 — aS(β(1),β(P ))dt.
In the longtime limit, the Markov jump process converges to the joint distribution π(β(1),β(P))
H
-U(β(I)) - U(β(P))	d	-U(β)
e T(I)	T(P) . For convenience, we refer to the marginal distribution π(1)(β) h e T(I) and
,,	-U(β)
π(P)(β) H e T(P) as the target distribution and reference distribution, respectively.
1
Under review as a conference paper at ICLR 2022
2	Preliminaries
Achieving sufficient explorations requires a large τ(P), which leads to limited accelerations due to a
small overlap between π(1) and π(P). To tackle this issue, one can bring in multiple particles with
temperatures (T⑵,…，τ(PT)), where T⑴ < T⑵ < … < T(P), to hollow out “tunnels”. To
maintain feasibility, numerous schemes are presented to select candidate pairs to attempt the swaps.
APE The all-pairs exchange (APE) attempts to swap arbitrary pair of chains (Brenner et al., 2007;
Lingenheil et al., 2009), however, such a method requires a swap time (see definition in section A.5)
of O(P3) and may not be user-friendly in practice.
ADJ In addition to swap arbitrary pairs, one can also swap adjacent (ADJ) pairs iteratively from
(1, 2), (2, 3), to (P - 1, P ) under the Metropolis rule. Despite the convenience, the sequential nature
requires to wait for exchange information from previous exchanges, which only works well with a
small number of chains and has greatly limited its extension to a multi-core or distributed context.
SEO The stochastic even-odd (SEO) scheme first divides the adjacent pairs {(p - 1, p)|p =
2, ∙ ∙ ∙ , P} into E and O, where E and O denote even and odd pairs of forms (2p - 1, 2p) and
(2p, 2p + 1), respectively. Then, SEO randomly picks E or O pairs with an equal chance in each
iteration to attempt the swaps. Notably, it can be conducted simultaneously without waiting from other
chains. The scheme yields a reversible process (see Figure 1(a)), however, the gains in overcoming
the sequential obstacle don’t offset the O(P2) round trip time and SEO is still not effective enough.
(a) Reversible indexes
(b) Non-reversible indexes
(c) Non-reversible chains
Figure 1: Reversibility v.s. non-reversibility. In (a), a reversible index takes O(P2) time to communicate; in
(b), an ideal non-reversible index moves along a periodic orbit, where the dark and light arrows denote even and
odd iterations, respectively; (c) shows how a non-reversible chain conducts a round trip with the DEO scheme.
DEO The deterministic even-odd (DEO) scheme instead attempts to swap even (E) pairs at even
(E) iterations and odd (O) pairs at odd (O) iterations alternatingly，(Okabe et al., 2001). The
asymmetric manner was later interpreted as a non-reversible PT (Syed et al., 2021) and an ideal index
process follows a periodic orbit, as shown in Figure 1(b). With a large swap rate, Figure 1(c) shows
how the scheme yields an almost straight path and a linear round trip time can be expected.
Equi-acceptance The power of PT hinges on maximizing the number of round trips, which is
equivalent to minimizing PpP-II 匚卜(Nadler & Hansmann, 2007b), where rp denotes the rejection
rate for the chain pair (p, p + 1). Moreover, PpP=-11 rp converges to a fixed barrier Λ as P →
∞ (Predescu et al., 2004; Syed et al., 2021). Applying Lagrange multiplies to the constrained
optimization problem leads to r1 = r2 = ∙ ∙ ∙ = rP-1 := r, where r is the equi-rejection rate. In
general, a quadratic round trip time is required for ADJ and SEO due to the reversible indexes. By
contrast, DEO only yields a linear round trip time in terms of P as P → ∞ Syed et al. (2021).
3	Optimal Non-reversible scheme for Parallel tempering
The linear round trip time is appealing for maximizing the algorithmic potential, however, such
an advance only occurs given sufficiently many chains. In non-asymptotic settings with limited
chains, a pearl of wisdom is to avoid frequent swaps (Dupuis et al., 2012) and to keep the average
acceptance rate from 20% to 40% (Kone & Kofke, 2005; Lingenheil et al., 2009; Atchade et al., 2011).
， E shown in iterations means even iterations; otherwise, it denotes even pairs for chain indexes. The same logic applies to O.
2
Under review as a conference paper at ICLR 2022
Most importantly, the acceptance rates are severely reduced in big data due to the bias-corrected
swaps associated with stochastic energies (Deng et al., 2020), see details in section A.1. As such,
maintaining low rejection rates becomes quite challenging and the issue of quadratic costs still exists.
3.1	Generalized DEO scheme
Continuing the equi-acceptance settings, we see in Figure.2(a) that the probability for the blue particle
to move upward 2 steps to maintain the same momentum after a pair of even and odd iterations is
(1 - r)2 . As such, with a large equi-rejection rate r, the blue particle often makes little progress
(Figure.2(b-d)). To handle this issue, the key is to propose small enough rejection rates to track the
periodic orbit in Figure.1(b). Instead of pursuing excessive amount of chains, we resort to a different
solution by introducing the generalized even and odd iterations EW and OW , where W ∈ N+ ,
EW = {[WC mod 2 = 0|k = 1, 2,…，∞} and OW = {[WC mod 2 = 1|k = 1, 2,…，∞}. Now,
we present the generalized DEO scheme with a window size W as follows and refer to it as DEOW : §
◦	Attempt to swap E (or O) pairs at EW (or OW) iterations.
◦	Allow at most one swap during each cycle of EW (or OW) iterations.
(3)
(a) DEO
XZ
o qs ZCr 八》
XZ
EOE
(b) Bad case 1
EOE
(c) Bad case 2
(d) Bad case 3
(e) DEO2
Figure 2: Illustration of DEO and DEO2. In (a), we show an ideal case of DEO; (b-d) show bad cases of DEO
based on a large equi-rejection rate r ; (e) show how the generalized DEO scheme of window size 2 tackles
the issue with a large r . The x-axis and y-axis denote (generalized) E (or O) iterations and E (or O) pairs,
respectively. The dashed line denotes the failed swap attempts; the gray shaded areas are frozen to refuse
swapping odd pairs at even iterations (or vice versa); the blue shaded area ensures at most one swap in a window.
As illustrated in Figure.2(e), the blue particle has a larger chance of (1 - r2)2 to move upward 2
steps given W = 2 instead of (1 - r)2 when W = 1, although the window number is also halved.
Such a trade-off inspires us to analyze the expected round trip time based on the window of size W .
Although allowing at most one swap introduces the stopping time and may affect the distribution, the
bias is rather mild due to the noisy energy estimators in big data. Check section C.2 for the details.
3.2	Analysis of Round Trip Time
To bring sufficient interactions between the reference distribution π(P) and the target distribution
π(1), we expect to minimize the expected round trip time T (defined in section A.5) to ensure both
efficient exploitation and explorations. Combining the Markov property and the idea of the master
equation (Nadler & Hansmann, 2007a), we estimate the expected round trip time E[T] as follows
Lemma 1. Under the stationary and weak dependence assumptions B1 and B2 in section B, for P
(P ≥ 2) chains with window size W (W ≥ 1) and rejection rates {rp}pP=-11, we have
P-1 rW
E[T] = 2WP + 2WP 工	pW.	(4)
p=1 1 - rp
The proof in section B.1 shows that E[T] increases as we adopt larger number of chains P and
rejection rates {rp}p-1. In SuCh a case, the round trip rate e[T] is also maximized by the key renewal
theorem. In particular, applying W = 1 recovers the vanilla DEO scheme.
3.3	Analysis of Optimal Window Size and Round Trip Time
By Lemma 1, we observe a potential to remove the second quadratic term given an appropriate W.
Such a fact motivates us to study the optimal window size W to achieve the best efficiency. Under
§The generalized DEO with the optimal window size is denoted by DEO? and will be studied in section 3.3.
3
Under review as a conference paper at ICLR 2022
the equi-acceptance settings, by treating the window size W as a continuous variable and taking the
derivative of E[T] with respect to W, we have
∂	2P
dWE[T] = (1 -rw)2 {(1 - rW)2 + (P - 1)rW(1 - rW + WlOg『)},
(5)
where r is the equi-rejection rate for adjacent chains. Define x := rW ∈ (0, 1), where W =
logr (x) = Iogr. The following analysis hinges on the study of the solution g(x) = (1 一 x)2 + (P 一
1)x(1 - x + lOg(x)) = 0. By analyzing the growth of derivatives and boundary values, we can easily
identify the uniqueness of the solution. Then, we proceed to verify that P e P yields an asymptotic
approximation such that g( P + P) = - logo"Pp) + O (IogP) → 0 as P → ∞. In the end, we have
Theorem 1. Under Assumptions B1 and B2 based on equi-acceptance settings, if P = 2, 3, the
maximal round trip time is achieved when W = 1. If P ≥ 4, with the optimal window size
W? ≈ ∣"logP+ogrogP], where「•] is the ceiling function. The round trip timefollows O( — lOgP).
The above result yields a remarkable round trip time of O(PlogP) by setting the optimal window
size W?. By contrast, the vanilla DEO scheme only leads to a longer time of O(P 2) §. Denoting by
DEO? the generalized DEO scheme with the optimal window size W?, we summarize the popular
swap schemes in Table.1, where the DEO? scheme performs the best among all the three criteria.
Table 1: Round trip time and swap time for different schemes. The APE scheme requires
AN EXPENSIVE SWAP TIME OF O(P 3) AND IS NOT COMPARED.
	Round trip time (non-asymptotic)	Round trip time (asymptotic)	Swap time
ADJ	O(P 2) (NADLER & HANSMANN, 2007A)	O(P2) (NADLER & HANSMANN, 2007A)	O(P)
SEO	O(P 2) (SYED ET AL., 2021)	O(P 2) (SYED ET AL., 2021)	O(1)
DEO	O(P 2) (SYED ET AL., 2021)	O(P) (SYEDETAL.,2021)	O(1)
DEO?	O(P logP)	O(P)	一	O(1)
3.4 Discussions on the Optimal Number of Chains
Note that in practice given P parallel chains, a large P leads to a smaller equi-rejection rate r. As
such, we can further obtain a crude estimate of the optimal P to minimize the round trip time.
Corollary 1. Under Assumptions B1-B4 and C1 under equi-acceptance settings with the optimal
window size, the optimal number of chains follows that P? > min? 3fy log( T(IT), Where σp is
defined in Eq.(15).
The assumptions and proof are postponed in section B.3. In mini-batch settings, insufficient chains
may lead to few effective swaps for accelerations; by contrast, introducing too many chains may be
too costly in terms of the round trip time. This is different from the conclusion in full-batch settings,
where Syed et al. (2021) suggested running the vanilla DEO scheme with as many chains as possible
to yield a small enough equi-rejection rate r to maintain the non-reversibility.
Cutoff phenomenon On the one hand, when we only afford at most P chains, where P < P?,
a large equi-rejection rate r is inevitable and DEO? is preferred over DEO; on the other hand, the
rejection rate r goes to 0 when P P? and DEO? recovers the DEO scheme.
In section B.4, we show that P? is in the order of thousands for the CIFAR100 example, which is
hard to achieve due to the limited computational budget and further motivates us to adopt finite chains
with a target swap rate S to balance between acceleration and accuracy.
4	User-friendly approximate explorations in Big Data
Despite the asymptotic correctness, SGLD only works well given small enough learning rates and
fails in explorative purposes (Ahn et al., 2012). A large learning rate, however, leads to excessive
stochastic gradient noise and ends up with a crude approximation. As such, similar to Izmailov et al.
(2018); Zhang et al. (2020), we only adopt SGLD for exploitations.
§By Taylor expansion, given a large rejection rate r, — log(r) = 1 - r, which means -七⑺ =O(ɪ-r).
4
Under review as a conference paper at ICLR 2022
Efficient explorations not only require a high temperature but also prefer a large learning rate. Such a
demand inspires us to consider SGD with a constant learning rate η as the exploration component
βk+ι = βk - η(VU(βk) + ε(βk)) = βk - ηVU(βk + .2小2)ε(βk),	(6)
where ε(βk) ∈ Rd is the stochastic gradient noise. Under mild normality assumptions on ε (Mandt
et al., 2017; Chen et al., 2020), βk converges approximately to an invariant distribution, where the
underlying temperature linearly depends on the learning rate η. Motivated by this fact, we propose
an approximate transition kernel Tη with P parallel SGD runs based on different learning rates
{ βk+1 = βkP) - η(p)vU(βkP)),
Exploration:
l βk+1 = βk2)-η⑵VU(βk2)),	⑺
Exploitation:	βk+ι = βk1) - η(I)VU(βk1)) + ^}^ ,
where η(1) < η(2) < .一 < η(P), Ξk 〜N(0, 2η(1)τ(1)), and T(I) is the target temperature.
Since there exists an optimal learning rate for SGD to estimate the desired distribution through
Laplace approximation (Mandt et al., 2017), the exploitation kernel can be also replaced with SGD
based on constant learning rates if the accuracy demand is not high. Regarding the validity of adopting
different learning rates for parallel tempering, we leave discussions to section A.2.
4.1	Approximation analysis
Moreover, the stochastic gradient noise exploits the Fisher information (Ahn et al., 2012; Zhu
et al., 2019; Chaudhari et al., 2017) and yields convergence potential to wide optima with good
generalizations (Berthier et al., 2020; Zou et al., 2021). Despite the implementation convenience,
the inclusion of SGDs has made the temperature variable inaccessible, rendering a difficulty in
implementing the Metropolis rule Eq.(2). To tackle this issue, we utilize the randomness in stochastic
energies and propose a deterministic swap condition for the approximate kernel Tη in Eq.(7) such that
Deterministic swap condition: (β(p), β(p+1)) → (β(p+1), β(p)) ifUe(β(p+1)) +C < Ue(β(p)), (8)
where P ∈ {1, 2,…，P - 1}, C > 0 is a correction buffer to approximate the Metropolis rule Eq.(2).
Lemma 2. Assume the energy normality assumption (C1), then for any fixed ∂Up := U (β(p)) -
U(β(p+1)), there exists an optimal C? ∈ (0, (τ1p) — T(p+i))σp] that perfectly approximates the
random event S(β(p), β(p+1)) > u, where σp defined in Eq.(15) and U 〜Unif [0,1].
The proof is postponed in section C.1, which paves the way for the guarantee that a deterministic
swap condition may replace the Metropolis rule Eq.(2) for approximation tasks. In addition, the
normality assumption can be naturally extended to the asymptotic normality assumption (Quiroz
et al., 2019; Deng et al., 2021) given large enough batch sizes.
Admittedly, the approximation error still exists for different ∂Up . By the mean-value theorem, there
exists a tunable C to optimize the overall approximation. Further invoking the central limit theorem
such that ε(∙) in Eq.(6) approximates a Gaussian distribution with a fixed covariance, we can expect a
bounded approximation error for the SGD-based exploration kernels (Mandt et al., 2017).
Theorem 2. Consider the exact transition kernel T and the proposed approximate kernel Tη, which
yield stationary distributions π and πη, respectively. Under smoothness (C2) and dissipativity
assumptions (C3) (Mattingly et al., 2002; Raginsky et al., 2017; Xu et al., 2018), T satisfies the
geometric ergodicity such that there is a contraction constant P ∈ [0,1) for any distribution μ:
kμT- πktv ≤ ρkμ 一 πktv,
where ∣∣ ∙ ∣∣tv is the total variation (TV) distance. Moreover, assume that ε(∙)〜N(0, M) for some
positive definite matrix M (C4) (Mandt et al., 2017), then there is a uniform upper bound of the one
step error between T and Tη such that
kμT- μTη ∣∣tv ≤ ∆maχ,∀μ,
5
Under review as a conference paper at ICLR 2022
where ∆max ≥ 0 is a constant. Eventually, the TV distance between π and πη is bounded by
kπ f N ≤ 芒.
The proof is postponed to section C.2. The SGD-based exploration kernels no longer require
to fine-tune the temperatures directly and naturally inherits the empirical successes of SGD in
large-scale deep learning tasks. The inaccessible Metropolis rule Eq.(2) is approximated via the
deterministic swap condition Eq.(8) and leads to a well-controlled approximations by solely tuning
η = (η⑴,…，η(P)) and C.
In addition, our proposed algorithm for uncertainty approximation is highly related to non-convex
optimization. For the detailed discussions, we refer interested readers to section A.4.
4.2	Equi-acceptance parallel tempering on optimized paths
Stochastic approximation (SA) is a standard method to achieve equi-acceptance (Atchade et al.,
2011; Miasojedow et al., 2013), however, implementing this idea with fixed η(1) and η(P) is rather
non-trivial. Motivated by the linear relation between learning rate and temperature, we propose to
adaptively optimize the learning rates to achieve equi-acceptance in a user-friendly manner. Further
by the geometric temperature spacing commonly adopted by practitioners (Kofke, 2002; Earl &
Deem, 2005; Syed et al., 2021), we adopt the following scheme on a logarithmic scale such that
∂ log(υt(p)) = h(p) (υt(p)),	(9)
where P ∈ {1, 2,…，P — 1}, UtP) = η(p+1) — η(p), h(P)(U(P))= R H(P)(Ukp), β)π(p,p+1)(dβ) is
the mean-field function, π(p,p+1) is the joint invariant distribution for the p-th andp + 1-th processes.
In particular, H(P)(Uk(P), β) = 1Ue(β(p+1))+C<Ue(β(p)) — S is the random-field function to approximate
h(p) (UkP)) with limited perturbations, UkP) t implicitly affects the distribution of the indicator function,
and S is the target swap rate. Now consider stochastic approximation of Eq.(9), we have
log(Uk(P+)1) = log(Uk(P)) +γkH(P)(Uk(P),βk),
(10)
where γk is the step size. Reformulating Eq.(10), we have
Uk(P+)1 = max(0, Uk(P))eγkH(υk(p)),
where the max operator is conducted explicitly to ensure the sequence of learning rates is non-
decreasing. This means that given fixed boundary learning rates (temperatures) ηk(P-1) and ηk(P+1),
applying n(P) = n(P-1) + U(P) and n(P) = n(P+1) — u(p+1) for P ∈ {2, 3,…，P — 1} lead to
ηk(P-1) +max(0,Uk(P))eγkH(υk(p)) = ηk(P+)1 = ηk(P+1)
`---------------------{----------------------}	|
forward sequence
— max(0, Uk(P+1))eγk H (υk(p+1)) .
_ - -
{^^^^^^^^^^^^^^^^^^^^^^^^^^
backward sequence
(11)
Adaptive learning rates (temperatures) Now given a fixed η(1), the sequence η(2), η(3), ∙一，
η(P) can be approximated iteratively via the forward sequence of (11); conversely, given a fixed η(P),
the backward sequence η(P-1), η(P-2), •一，η(1) can be decided reversely as well. Combining the
forward and backward sequences, ηk(P+)1 can be approximated via
(P-1)	(P+1)
._ ηk	+ ηk	+
1 : =	2	+
max(0, U(.P))eYkH(Ukp))- max(0,UkP+1))eYkH(Ukp+”)	①)
2
which resembles the binary search in the SA framework. In particular, the first term is the middle
point given boundary learning rates and the second term continues to penalize learning rates that
violates the equi-acceptance between pairs (P — 1,P) and (P,P + 1) until an equilibrium is achieved.
This is the first attempt to achieve equi-acceptance given two fixed boundary values to our best
knowledge. By contrast, Syed et al. (2021) proposed to estimate the barrier Λ to determine the
temperatures and it easily fails in big data given a finite number of chains and bias-corrected swaps.
tFor convenience, U(P) denotes the continuous-time diffusion at time t and Ukp) represents the discrete
approximations at iteration k.
6
Under review as a conference paper at ICLR 2022
Algorithm 1 Non-reversible parallel tempering with SGD-based exploration kernels (DEO?-SGD).
Input Number of chains P ≥ 3, boundary learning rates η(1) and η(P), target swap rate S.
Input Optimal window size W := ∣^lo-p+glog-Og P ^∣, total iterations K, and step sizes {γk}K=o∙
for k = 1 to K do
βk+ι 〜Tn (βk) following Eq.(7)	. Exploration / exploitation phase (parallelizable)
P = {∀p ∈ {1, 2,…，P} : P mod 2 = b告C mod 2}.	. Generalized even/odd iterations
for p = 1, 2 to P - 1 do
A(p) := 1Ue(β(kp++11) )+Ck<Ue(βk(p+)1 )
G(p) := 1kmodW =0.	. Open the gate to allow swaps
if p ∈ P and G(p) and A(p) then
Swap: βk(p+)1 and βk(p++11).	. Communication phase (parallelizable)
Freeze: G(p) = 0.	. Close the gate to refuse swaps
end if
if p > 1 then
Update learning rate (temperature) following Eq.(12)
end if
end for
Adaptive correction buffer:	Ck+ι	=	Ck	+ Yk	(P1ι	PP=II A(P)	—	S)	∙
end for
Output Models collected from the target temperature {βk(1)}kK=1.
Adaptive correction buffers In addition, equi-acceptance does not guarantee a convergence to the
desired acceptance rate S. To avoid this issue, we propose to adaptively optimize C as follows
Ck+1 = Ck + Yk (P-I X 1U(βk+11))+Ck-U(βk+ι)<0 - S) .	(13)
As k → ∞, the threshold and the adaptive learning rates converge to the desired fixed points. Note
that setting a uniform C greatly simplifies the algorithm; in more delicate cases, problem-specific
rules are also recommended. Now we refer to the approximate non-reversible parallel tempering
algorithm with the DEO? scheme and SGD-based exploration kernels as DEO?-SGD and formally
formulate our algorithm in Algorithm 1. Extensions of SGD with a preconditioner (Li et al., 2016)
or momentum (Chen et al., 2014) to further improve the approximation and efficiency are both
straightforward (Mandt et al., 2017) and are denoted as DEO?-pSGD and DEO?-mSGD, respectively.
5	Experiments
5.1	Simulations of multi-modal distributions
We first simulate the proposed algorithm on a distribution ∏(β) H exp(-U(β)), where β = (βι, β2),
U(β) = 0.2(β12 + β22) - 2(cos(2πβ1) + cos(2πβ2)). The heat map is shown in Figure 3(a) with 25
modes of different volumes. To mimic big data scenarios, we can only access stochastic gradient
▽U(β) = VU(β) + 2N(0, I2×2) and stochastic energy U(β) = U(β) + 2N(0,I).
(a) Ground truth (b) S = 0.2	(c) S = 0.3	(d) S = 0.4	(e) S = 0.5	(f) S = 0.6
Figure 3: Study of different target swap rate S via DEO?-SGD, where SGLD is the exploitation kernel.
We first run DEO*-SGD×P16 based on 16 chains and 20,000 iterations. We fix the lowest learning
rate 0.003 and the highest learning 0.6 and propose to tune the target swap rate S for the acceleration-
accuracy trade-off. Fig.3 shows that fixing S = 0.2 or 0.3 is too conservative and underestimates the
7
Under review as a conference paper at ICLR 2022
uncertainty on the corners; S = 0.6 results in too many radical swaps and eventually leads to crude
estimations; by contrast, S = 0.4 yields the best uncertainty approximation among the five choices.
Next, we select S = 0.4 and study the round trips. We observe in Fig.4(a) that the vanilla DEO only
yields 18 round trips every 1,000 iterations; by contrast, slightly increasing W tends to improve the
efficiency significantly and the optimal 45 round trips are achieved at W = 8, which matches our
theory. In Fig.4(b-c), the geometrically initialized learning rates lead to unbalanced acceptance rates
in the early phase and some adjacent chains have few swaps and others swap too much, but as the
optimization proceeds, the learning rates gradually converge. We also observe in Fig.4(d) that the
correction is adaptively estimated to ensure the average acceptance rates converge to S = 0.4.
(a) Round trips
SlJo 一t①ʃæɔ
(b) Learning rates	(c) Acceptance rates	(d) Corrections
Figure 4: Study of window sizes, learning rates, acceptance rates, and the corrections.
We compare the proposed algorithm with parallel SGLD based on 20,000 iterations and 16 chains
(SGLD×P16); we fix the learning rate 0.003 and a temperature 1. We also run cycSGLD×T16,
which is short for a single long chain based on 16 times of budget and cosine learning rates (Zhang
et al., 2020) of 100 cycles. We see in Figure 5(b) that SGLD×P16 has good explorations but fails
to quantify the uncertainty. Figure 5(c) shows that cycSGLD×T16 explores most of the modes but
overestimates some areas occasionally. Figure 5(d) demonstrates the DEO-SGD with 16 chains
(DEO-SGD×P16) estimates the uncertainty of the centering 9 modes well but fails to deal with the
rest of the modes. AS to DEO?-SGDXP16, the approximation is rather accurate, as shown in Fig.5(e).
(a) Ground truth (b) SGLD ×P16	(C)CyCSGLd×T16	(d) deo-sgd×pi6	(e) deo?-sgd×pi6
Figure 5: Simulations of the multi-modal distribution through different sampling algorithms.
We also present the index proCess for both sChemes in Fig.6. We see that the vanilla DEO sCheme
results in volatile paths and a partiCle takes quite a long time to Complete a round trip; by Contrast,
DEO? only ConduCts at most one Cheap swap in a window and yields muCh more deterministiC paths.
(a) DEO-SGD×P16
(b) DEO?-SGD×P16
Figure 6: DynamiCs of the index proCess. The red path denotes the round trip path for a partiCle.
5.2 Uncertainty approximation and optimization for image data
Next, we ConduCt experiments on Computer vision tasks. We Choose ResNet20, ResNet32, and
ResNet56 (He et al., 2016) and train the models on CIFAR100. We not only report test negative
log likelihood (NLL) but also present the test aCCuraCy (ACC). For eaCh ResNet model, we first
pre-train 10 fixed models via 300 epoChs and then run our algorithm based on momentum SGD
(mSGD) for 500 epoChs with 10 parallel Chains and denote it by DEO? -mSGD×P10. We fix the
lowest and highest learning rates as 0.005 and 0.02, respeCtively. For a fair Comparison, we also
inClude the baseline DEO-mSGD×P10 with the same setup exCept that the window size is 1; the
standard ensemble mSGD×P10 is also inCluded with a learning rate of 0.005. In addition, we inClude
two baselines based on a single long Chain, i.e. we run stoChastiC gradient Hamiltonian Monte Carlo
8
Under review as a conference paper at ICLR 2022
(Chen et al., 2014) 5000 epochs with cyclical learning rates and 50 cycles (Zhang et al., 2020) and
refer to it as cycSGHMC×T10; we run SWAG×T10 (Maddox et al., 2019) under a similar setup.
In particular for DEO?-mSGD×P10, we tune the target swap rate S and find an optimum at S = 0.005.
We compare our proposed algorithm with the four baselines and observe in Table.2 that mSGD×P10
can easily obtain competitive results simply through model ensemble (Lakshminarayanan et al., 2017),
which outperforms cycSGHMC×T10 and cycSWAG×T10 on ResNet20 and ResNet32 models and
perform the worst among the five methods on ResNet56; DEO-mSGD×P10 itself is already a pretty
powerful algorithm, however, DEO?-mSGD×P10 consistently outperforms the vanilla alternative.
TABLE 2: UNCERTAINTY APPROXIMATION AND OPTIMIZATION ON CIFAR100 VIA 10× BUDGET.
Model	ReSNet20	一		ReSNet32	一		ResNet56	
	NLL	ACC(%)	NLL	ACC (%)	NLL	ACC (%)
-CyCSGHMC ×T10~	8198±59	76.26±0.i8=	7401±28	78.54±0.lf	6460±21	81.78±0.08
CyCSWAG×T10	8164±38	76.13±0.21	7389±32	78.62±0.13	6486±29	81.60±0.14
mSGD×P10	7902±64	76.59±0.1F=	7204±29	79.02±0.09=	6553±15	81.49±0.09
DEO-mSGD×P10	7964±23	76.84±0.12	7152±41	79.34±0.15	6534±26	81.72±0.12
DEO?-mSGD×P10	7741±67	77.37±0.16	7019±35	79.54±0.12	6439±32	82.02±0.15
To analyze why the proposed scheme performs well, we study the round trips in Figure.7(a) and
find that the theoretical optimal window obtains around 11 round trips every 100 epochs, which is
almost 2 times as much as the vanilla DEO scheme. In Figure 7(b), we observe that the smallest
learning rate obtains the highest accuracy (blue) for exploitations, while the largest learning rate
yields decent explorations (red); we see in Figure 7(c-d) that geometrically initialized learning rate
fails in producing equi-acceptance, but as the training proceeds, the learning rates converge to fixed
points and the acceptance rates for different pairs converge to the target swap rate.
(a) Round trips	(b) Accuracies	(c) Learning rates (d) Acceptance rates
Figure 7:	Study of window sizes, accuracies, learning rates, and acceptance rates on ResNet20.
For the visualization of the index process, we observe in Figure.8(a) that the vanilla DEO scheme
leads to volatile trajectories wandering back and forth and is rather inefficient; by contrast, the DEO?
scheme yields well-motivated paths with more deterministic round trips. Interestingly, this path
resembles cyclic learning rates (Zhang et al., 2020), which provides a novel viewpoint to interpret
why cyclic learning rates work well empirically. Nevertheless, the stochastic and parallel manner
further improves the margin and eventually leads to the most efficient approximations in this task.
I Il........................I UIIIIlI
(a) DEO-mSGD×P10	(b) DEO?-mSGD×P10
Figure 8:	Dynamics of the index process of ResNet20 models in the last 200 epochs.
6	Conclusion
In this paper, we show how to conduct efficient PT in big data problems. To tackle the inefficiency
issue of the popular DEO scheme given limited chains, we present the DEO? scheme by applying
an optimal window size to encourage deterministic paths and obtain in a significant acceleration of
O (ιopp) times. For a user-friendly purpose, We propose a deterministic swap condition to interact
with SGD-based exploration kernels and provide a theoretical guarantee to control the bias solely
depending on the learning rate η and the correction buffer C; we also provide a practical algorithm to
adaptively approximate η and C for achieving the optimal efficiency in constrained settings.
9
Under review as a conference paper at ICLR 2022
References
Sungjin Ahn, Anoop Korattikara, and Max Welling. Bayesian Posterior Sampling via Stochastic
Gradient Fisher Scoring. In Proc. of the International Conference on Machine Learning (ICML),
2012.
Laurence Aitchison. A Statistical Theory of Cold Posteriors in Deep Neural Networks. In Proc. of
the International Conference on Learning Representation (ICLR), 2021.
Yves F. Atchada Gareth O. Roberts, and Jeffrey S. Rosenthal. Towards Optimal Scaling OfMetropolis-
coupled Markov Chain Monte Carlo. Statistics and Computing, 21:555-568, 2011.
Nicholas A Baran, George Yin, and Chao Zhu. Feynman-kac formula for switching diffusions:
connections of systems of partial differential equations and stochastic differential equations.
Advances in Difference Equations, 2013(1):1-13, 2013.
Remi Bardenet, Arnaud Doucet, and Chris Holmes. On Markov Chain Monte Carlo Methods for Tall
Data. Journal of Machine Learning Research, 18:1-43, 2017.
Raphael Berthier, Francis Bach, and Pierre Gaillard. Tight Nonparametric Convergence Rates for
Stochastic Gradient Descent under the Noiseless Linear Model. In Advances in Neural Information
Processing Systems (NeurIPS), 2020.
Paul Brenner, Christopher R. Sweet, Dustin VonHandorf, and Jesus A. Izaguirre. Accelerating the
Replica Exchange Method through an Efficient All-pairs Exchange. The Journal of Chemical
Physics, 126:074103, 2007.
David Ceperley and Mark Dewing. The Penalty Method for Random Walks with Uncertain Energies.
The Journal of Chemical Physics, 110:9812-9820, 1999.
Pratik Chaudhari, Anna Choromanska, Stefano Soatto, Yann LeCun, Carlo Baldassi, Christian Borgs,
Jennifer Chayes, Levent Sagun, and Riccardo Zecchina. Entropy-SGD: Biasing Gradient Descent
into Wide Valleys. In Proc. of the International Conference on Learning Representation (ICLR),
2017.
Tianqi Chen, Emily B. Fox, and Carlos Guestrin. Stochastic Gradient Hamiltonian Monte Carlo. In
Proc. of the International Conference on Machine Learning (ICML), 2014.
Xi Chen, Jason D. Lee, Xin T. Tong, and Yichen Zhang. Statistical Inference for Model Parameters
in Stochastic Gradient Descent. Annals of Statistics, 48(1):251-273, 2020.
Yi Chen, Jinglin Chen, Jing Dong, Jian Peng, and Zhaoran Wang. Accelerating Nonconvex Learning
via Replica Exchange Langevin Diffusion. In Proc. of the International Conference on Learning
Representation (ICLR), 2019.
Imre CSiSzdr and Jdnos Korner. Information Theory: Coding Theorems for Discrete Memoryless
Systems. Cambridge University Press, 2011.
Arnak S Dalalyan. Theoretical Guarantees for Approximate Sampling from Smooth and Log-concave
Densities. Journal of the Royal Statistical Society: Series B, 79(3):651-676, 2017.
Wei Deng, Qi Feng, Liyao Gao, Faming Liang, and Guang Lin. Non-Convex Learning via Replica
Exchange Stochastic Gradient MCMC. In Proc. of the International Conference on Machine
Learning (ICML), 2020.
Wei Deng, Qi Feng, Georgios Karagiannis, Guang Lin, and Faming Liang. Accelerating Conver-
gence of Replica Exchange Stochastic Gradient MCMC via Variance Reduction. In Proc. of the
International Conference on Learning Representation (ICLR), 2021.
Jing Dong and Xin T. Tong. Replica Exchange for Non-Convex Optimization. arXiv:2001.08356v4,
2021.
Paul Dupuis, Yufei Liu, Nuria Plattner, and J. D. Doll. On the Infinite Swapping Limit for Parallel
Tempering. SIAM J. Multiscale Modeling & Simulation, 10, 2012.
10
Under review as a conference paper at ICLR 2022
Alain Durmus and Eric Moulines. Sampling from a Strongly Log-concave Distribution with the
Unadjusted Langevin Algorithm. arXiv:1605.01559, 2016.
David J. Earl and Michael W. Deem. Parallel Tempering: Theory, Applications, and New Perspectives.
Phys. Chem. Chem. Phys.,7:3910-3916, 2005.
A. Gelman, W. R. Gilks, and G. O. Roberts. Weak Convergence and Optimal Scaling of Random
Walk Metropolis Algorithms. Annals of Applied Probability, 7:110-120, 1997.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image
Recognition. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.
Pavel Izmailov, Dmitry Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gordon Wilson.
Averaging Weights Leads to Wider Optima and Better Generalization. In Proc. of the Conference
on Uncertainty in Artificial Intelligence (UAI), 2018.
David A. Kofke. On the Acceptance Probability of Replica-Exchange Monte Carlo Trials. The
Journal of Chemical Physics, 117, 2002.
Aminata Kone and David A. Kofke. Selection of Temperature Intervals for Parallel-tempering
Simulations. The Journal of Chemical Physics, 122:206101, 2005.
Anoop Korattikara, Yutian Chen, and Max Welling. Austerity in MCMC Land: Cutting the Metropolis-
Hastings Budget. In Proc. of the International Conference on Machine Learning (ICML), 2014.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and Scalable Predictive
Uncertainty Estimation using Deep Ensemble. In Advances in Neural Information Processing
Systems (NeurIPS), 2017.
Chunyuan Li, Changyou Chen, David Carlson, and Lawrence Carin. Preconditioned Stochastic
Gradient Langevin Dynamics for Deep Neural Networks. In Proc. of the National Conference on
Artificial Intelligence (AAAI), pp. 1788-1794, 2016.
Martin Lingenheil, Robert Denschlag, Gerald Mathias, and Paul Tavan. Efficiency of Exchange
Schemes in Replica Exchange. Chemical Physics Letters, 478:80-84, 2009.
Wesley Maddox, Timur Garipov, Pavel Izmailov, Dmitry Vetrov, and Andrew Gordon Wilson. A
Simple Baseline for Bayesian Uncertainty in Deep Learning. In Advances in Neural Information
Processing Systems (NeurIPS), 2019.
Stephan Mandt, Matthew D. Hoffman, and David M. Blei. Stochastic Gradient Descent as Approxi-
mate Bayesian Inference. Journal of Machine Learning Research, 18:1-35, 2017.
Oren Mangoubi and Nisheeth K. Vishnoi. Convex Optimization with Unbounded Nonconvex Oracles
using Simulated Annealing. In Proc. of Conference on Learning Theory (COLT), 2018.
J.C. Mattingly, A.M. Stuartb, and D.J. Highamc. Ergodicity for SDEs and Approximations: Locally
Lipschitz Vector Fields and Degenerate Noise. Stochastic Processes and their Applications, 101:
185-232, 2002.
Btazej Miasojedow, Eric Moulines, and Matti Vihola. An Adaptive Parallel Tempering Algorithm.
Journal of Computational and Graphical Statistics, 22(3):649-664, 2013.
Walter Nadler and Ulrich H. E. Hansmann. Generalized Ensemble and Tempering Simulations: A
Unified View. Phys. Rev. E, 75:026109, 2007a.
Walter Nadler and Ulrich H. E. Hansmann. Dynamics and Optimal Number of Replicas in Parallel
Tempering Simulations. Phys. Rev. E, 76:065701, 2007b.
Tsuneyasu Okabe, Masaaki Kawata, Yuko Okamoto, and Masuhiro Mikami. Replica Exchange Monte
Carlo Method for the Isobaric-isothermal Ensemble. Chemical Physics Letters, 335:435-439,
2001.
11
Under review as a conference paper at ICLR 2022
Cristian Predescu, Mihaela Predescu, and Cristian V. Ciobanu. The Incomplete Beta Function Law
for Parallel Pempering Sampling of Classical Canonical Systems. Chemical Physics Letters, 120:
4119-4128,2004.
Matias Quiroz, Robert Kohn, Mattias Villani, and Minh-Ngoc Tran. Speeding Up MCMC by Efficient
Data Subsampling. Journal of the American Statistical Association, 114:831-843, 2019.
Maxim Raginsky, Alexander Rakhlin, and Matus Telgarsky. Non-convex Learning via Stochastic
Gradient Langevin Dynamics: a Nonasymptotic Analysis. In Proc. of Conference on Learning
Theory (COLT), June 2017.
Herbert Robbins and Sutton Monro. A Stochastic Approximation Method. The Annals of Mathemati-
cal Statistics, 22(3):400-407, 1951.
Issei Sato and Hiroshi Nakagawa. Approximation Analysis of Stochastic Gradient Langevin Dynamics
by Using Fokker-Planck Equation and Ito Process. In Proc. of the International Conference on
Machine Learning (ICML), 2014.
Daniel Seita, Xinlei Pan, Haoyu Chen, and John Canny. An Efficient Minibatch Acceptance Test for
Metropolis-Hastings. In Proc. of the Conference on Uncertainty in Artificial Intelligence (UAI),
2017.
AnatoliI Vladimirovich Skorokhod. Asymptotic methods in the theory of stochastic differential
equations, volume 78. American Mathematical Soc., 2009.
SaifUddin Syed, Alexandre BoUchard-C6t6, George Deligiannidis, and Arnaud Doucet. Non-
Reversible Parallel Tempering: a Scalable Highly Parallel MCMC scheme. arXiv:1905.02939v4,
2021.
Max Welling and Yee Whye Teh. Bayesian Learning via Stochastic Gradient Langevin Dynamics. In
Proc. of the International Conference on Machine Learning (ICML), pp. 681-688, 2011.
Florian Wenzel, Kevin Roth, Bastiaan S. Veeling, Jakub Swiatkowski, Linh Tran, Stephan Mandt,
Jasper Snoek, Tim Salimans, Rodolphe Jenatton, and Sebastian Nowozin. How Good is the Bayes
Posterior in Deep Neural Networks Really? In Proc. of the International Conference on Machine
Learning (ICML), 2020.
Pan Xu, Jinghui Chen, Difan Zou, and Quanquan Gu. Global Convergence of Langevin Dynamics
Based Algorithms for Nonconvex Optimization. In Advances in Neural Information Processing
Systems (NeurIPS), 2018.
George Yin and Chao Zhu. Hybrid Switching Diffusions: Properties and Applications. Springer,
2010.
Ruqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Chen, and Andrew Gordon Wilson. Cyclical
Stochastic Gradient MCMC for Bayesian Deep Learning. In Proc. of the International Conference
on Learning Representation (ICLR), 2020.
Zhanxing Zhu, Jingfeng Wu, Bing Yu, Lei Wu, and Jinwen Ma. The Anisotropic Noise in Stochastic
Gradient Descent: Its Behavior of Escaping from Sharp Minima and Regularization Effects. In
Proc. of the International Conference on Machine Learning (ICML), 2019.
Difan Zou, Jingfeng Wu, Vladimir Braverman, Quanquan Gu, and Sham M. Kakade. Benign
Overfitting of Constant-Stepsize SGD for Linear Regression. In Proc. of Conference on Learning
Theory (COLT), 2021.
12
Under review as a conference paper at ICLR 2022
A Background
A.1 Replica exchange stochastic gradient Langevin dynamics
To approximate the replica exchange Langevin diffusion Eq.(1) based on multiple particles
(βk+ι, βk+ι, ∙∙∙ , βk+1) in big data scenarios, replica exchange stochastic gradient LangeVin dy-
namics (reSGLD) proposes the following numerical scheme:
(βk+1 = βkP) - η(P)VU(βkP)) + ,2η(P)T(P)ξkPP,
Exploration:
∖ βk+ι= βk2P -η⑵VU(βk2P) + √2η⑵τ(2)ξk2P,
Exploitation:	βk+ι = βk1) — η(I)VU (βkI)) + √2η(I)T ⑴ ξk1P,
(14)
where /)is the learning rate, ξ(∙ is a standard d-dimensional Gaussian noise and each subprocess
follows a stochastic gradient LangeVin dynamics (SGLD) (Welling & Teh, 2011). Further assuming
the energy normality assumption C1 in section C.1, there exists a σp such that
U(β(P)) — U(β(p+1))〜N(U(β(P)) — U(β(p+1)), 2σp), for any β(p) 〜π(P),	(15)
where P ∈ {1, 2,…，P — 1}, in what follows, Deng et al. (2020) proposed the bias-corrected swap
function as follows
ae(βkp)1, βkp+11)) = a ∙ (l ∧ e(T(p)-T(p+))(U(βk+I)-U(回用I))-(τ(p)-τ(p+))σp)) ,	(16)
k+1 k+1
where P ∈ {1, 2, ∙∙∙ ,P — 1}, (τ⅛) 一 T(p+i))σp is a correction term to avoid the bias and the swap
intensity a can be then set to min{n(p1n(p+i)} for convenience. Namely, given a particle pair at
location (β(P), β(P+1)) in the k-th iteration, the conditional probability of the swap follows that
P(βk+1 = (β(p+1),β(P))Iek = (β(p),β(p+1) )) = e(β(P),e(p+1)),
p(βk+ι = (e(P),e(P+1))iek = (β(P),e(P+1) )) = ι — e(e(P),e (p+1)).
A.2 Inhomogenous swap intensity via different learning rates
Assume the high-temperature process also applies η(P+1)≥ η(P) > 0, where P ∈ {1, 2 …，P — 1}.
At time t, the swap intensity can be interpreted as being 0 in a time interval [t, t + η(P+1) — η(P)) and
being n1)in [t + η(P+1)— η(P),t + n(P+1)), Since the coupled Langevin diffusion process converges
to the same joint distribution regardless of the swaps and the swap intensity a varies in a bounded
domain, the convergence of numerical schemes is not much affected except the numerical error.
A.3 Accuracy-acceleration trade-off
Despite the exponential acceleration potential, the average bias-corrected swap rate is significantly
reduced such that E[S]=O]SeYτ(p)- T(P+1))仔)(Deng et al., 2021), where S is the swap
function following Eq.(2) in full-batch settings. Including more parallel chains are promising to
alleviate this issue, however, it is often inevitable to sacrifice some accuracy to obtain more swaps
and accelerations, as discussed in section 3.4. As such, it inspires us to devise the user-friendly
SGD-based approximate exploration kernels.
A.4 Connection to non-convex optimization
Parallel to our work, a similar SGLD×SGD framework was proposed by Dong & Tong (2021)
for non-convex optimization, where SGLD and SGD work as exploration and exploitation kernels,
13
Under review as a conference paper at ICLR 2022
respectively. By contrast, our algorithm performs exactly in the opposite for uncertainty approximation
because SGLD is theoretically more appealing for the exploitations based on small learning rates
instead of explorations, while the widely-adopted SGDs are quite attractive in exploration due to its
user-friendly nature and ability in exploring wide optima.
If we manipulate the scheme to propose an exact swap in each window instead of at most one in
the current version, the algorithm shows a better potential in non-convex optimization. In particular,
a larger window size corresponds to a slower decay of temperatures in simulated annealing (SAA)
(Mangoubi & Vishnoi, 2018). Such a mechanism yields a larger hitting probability to move into a
sub-level set with lower energies (losses) and a better chance to hit the global optima. Nevertheless,
the manipulated algorithm possess the natural of parallelism in cyclical fashions.
A.5 Others
Swap time refers to the communication time to conduct a swap in each attempt. For example, chain
pair (p,p + 1) of ADJ requires to wait for the completion of chain pairs (1,2), (2, 3),…，(p - 1,p)
to attempt the swap and leads to swap time of O(P); however, SEO, DEO, and DEO? don’t have this
issue because in each iteration, only even or odd chain pairs are attempted to swap, hence the swap
time is O(1).
Round trip time refers to the time (stochastic variable) used in a round trip. A round trip is completed
when a particle in the p-th chain, where P ∈ [P] := {1,2,…，P}, hits the index boundary index at
both 1 and P and returns back to its original index p.
B Analysis of Round Trips
To facilitate the theoretical analysis, we follow Syed et al. (2021) and make the following assumptions
•	(B1) Stationarity: Each sub-process has achieved the stationary distribution β(p) 〜∏(p) for
any p ∈ [P];
•	(B2) Weak independence: For any ∕3(p) simulated from the p-th chain conditional on β(j),
U(β(j)) and U(β(j)) are independent.
B.1 Analysis of Round Trip Time
ProofofLemma 1. For t ∈ N, define Zt ∈ [P] = {1, 2, ∙∙∙ ,P} as the index of the chain a particle
arrives after t windows. Define δt ∈ {1, -1} to indicate the direction of the swap a particle intends
to make during the t-th window; i.e., the swap is between Zt and Zt + 1 if δt = 1 and is between Zt
and Zt - 1 if δt = -1.
Define U := min{t ≥ 0 : Zt = P, δt = -1} and V := min{t ≥ 0 : Zt = 1, δt = 1}. Define
rp := P[ reject the swap between Chain p and Chain p + 1 for one time] . Define up,δ := E[U |Z0 =
p, δ0 = δ] for δ ∈ {1, -1} and vp,δ := E[V |Z0 = p, δ0 = δ]. Then the expectation of round trip
time T is
E[T] = W (u1,1 + uP,-1).	(17)
By the Markov property, for up,δ, we have
up,1 = rpW (up,-1 + 1) + (1 - rpW)(up+1,1 + 1)	(18)
up,-1 = rpW-1(up,1 + 1) + (1 - rpW-1)(up-1,-1 + 1),	(19)
where rpW denotes the rejection probability of a particle in a window of size W at the p-th chain.
According to Eq.(18) and Eq.(19), we have
up+1,1 - up,1 = rp (up+1,1 - up,-1 ) - 1	(20)
up,-1 - up-1,-1 = rp-1 (up,1 - up-1,-1 ) + 1.	(21)
14
Under review as a conference paper at ICLR 2022
Define ap = Up,ι - up-1,-1. Then by definition, Eq.(20), and Eq.(21), we have
αp+1 - ɑp = (up+1,1 - up,-1) - (up,1 - up-1,—1)
=(up+1,1 - up,1) - (up, -1 - up-1,—1)
W	W
=rp αp+1 - rp-1αp - 2,
which implies that
ap+1 - ap = -2,	(22)
for ap := (1 - rp-1)αp. Thus, by Eq.(22), we have
ap = a2 - 2(p - 2).	(23)
By definition, u「1 = u1,1 + 1. According to Eq.(20), for P = 1, we have
α2 = (1 - rW) (U2,1 - u1,-1)
=(1 - rW) [u1,1 - u1,-1 + rW(u2,1 - u1,-1) - 1]	(24)
=-2(1 - rW)+ rW a2.
Since rp ∈ (0,1) for 1 ≤ P ≤ P, Eq.(24) implies a? = -2 which together with Eq.(23) implies
and therefore
(1 - rp-1 )αp = ap = -2(p - 1),
rW
rp-"-2(P- 1)1⅛
According to Eq.(21) and Eq.(26), we have
P-1
uP,1 - u1,1 = ɪ2 rW (up+1,1 - up,-1) - (P - 1)
p=1
P-1
=X rpWαp+1 - (P - I)
p=1
P-1 rW
=-2 X I -PrWP - (P - 1).
p=1	- rp
Since up,1 = 1, we have
P-1	rW
u1,1 = uP,1 + 2 E I JrWP +(P - I)
p=1 1 - rp
P-1
P+2 X
p=1
rW
r p
-rW
(25)
(26)
(27)
(28)
(29)
(30)
P.
1
Similarly, for vp,δ, we also have
vp,1 = rW(VP,-1 + 1) + (1 - rW)(vp+1,1 + I)
vp,-1 = rp-1(vp,1 + 1) + (1 - rp-I)(VP-1,-1 + 1).
With the same analysis, we have
bp+1 - bp = -2	(31)
vp,-1 - vp-1,-1 = rp-1(VP,1 - vp-1,-1) + 1,	(32)
where bp := (1 - rp-1)βp and βp := Vp,1 - Vp-1,-1. According to Eq.(32), we have
P-1
vP,-1-v1,-1 = X rWβp+1 + (P - 1).	(33)
p=1
15
Under review as a conference paper at ICLR 2022
By definition, vP,1 = vP,-1 + 1. According to Eq.(32), forp = P, we have
bP = (1 - rPW-1)(vP,1 - vP -1,-1)
= (1 - rPW-1) vP,1 - vP,-1 + rPW-1 (vP,1 - vP -1,-1) + 1	(34)
= rPW-1bP + 2(1 - rPW-1).
Since rp ∈ (0, 1) for 1 ≤ p ≤ P, Eq.(34) implies bP = 2. Then according to Eq.(31), we have
bp = 2(P - p + 1),
and therefore	rW
rW-ιβP = 21 p-Ww (P -P +1).
1 - rp-1
By Eq.(33) and Eq.(35), we have
P-1	rw
vP,-ι - v1,-1 = 2 X 1 IPrW(P - P) + (P - I).
P=1 1 - rP
Since v1,-1 = 1, we have
P-1 rw
vp,-ι = 2 X ι-prw(P - P) + P
P=1	- rP
(35)
(36)
According to Eq.(17), Eq.(30) and Eq.(36), we have
P-1	rw
E[T] = W(u1,1 + up,-ι) = 2WP + 2WP X	.
P=1 1 - rP
□
The proof is a generalization of Theorem 1 (Syed et al., 2021); when W = 1, the generalized DEO
scheme recovers the DEO scheme. For the self-consistency of our analysis, we present it here anyway.
B.2 Analysis of Optimal Window Size
Proof of Theorem 1. By treating W ≥ 1 as a continuous variable and taking the derivative of E[T]
with respect to W and we can get
∂
∂W E[T ] = 2P 1 +
X	rpw	+ W X rpw log r-
-=1 LPW)+	-=1 (i-rpw )2
DP ʃ-g rPW - r-W + WrW log『-1
∖	-=1	1不 J
2P (1 + X rw 1-rW + WlOgr-)
I + -=1 -	(1-rW )2	J
(37)
Assume that r- = r ∈ (0, 1) for 1 ≤ P ≤ P. Then we have
rW
E[T] = 2WP + 2WP(P - 1)-——w.	(38)
1	- rW
∂	2P
4E[T] = --W {(1 — rw)2 + (P — 1)rw(1 - rw + W logr)} .	(39)
∂W	(1 - r )
Define X := rw ∈ (0,1). Hence W = log/(x) = Iogr and
∂	2P
E[T] = f(x) ：= γ.---G {(1 — x)2 + (P — 1)x(1 — x + logx)}	(40)
∂W	(1 - x)2
16
Under review as a conference paper at ICLR 2022
Thus it suffices to analyze the sign of the function g(x) := (1 - x)2 + (P - 1)x(1 - x + log(x)) for
x ∈ (0, 1). For g(x), we have
g0 (x) = (4 - 2P)(x - 1) + (P - 1) log(x)
and
g00(x) =4 - 2P + P-I.
x
Thus, limx→0+ g0(x) = -∞, limx→1 g0(x) = g0(1) = 0 and g00(x) is monotonically decreasing for
x > 0.
1.	For P > 2, we know that g00(χ) > 0 when 0 < x < 2p，)and g00(χ) < 0 When
X < 2p-2). Therefore, g0(χ) is maximized at 2p，).
(a)	If P = 3,by log(1+y) < y for y > 0, we have g0(x) = 2(log(1+(x-1))-(x-1)) <
0 for any X ∈ (0,1). Thus g(x) > g(1) = 0 for X ∈ (0,1) and therefore ∂wE[T] > 0
for W ∈ N+. E[T] is globally minimized at W = 1.
(b)	If P > 3, we have the following lemma and the proof is postponed in section B.2.1.
Lemma 3 (Uniqueness of the solution). For P > 3, there exists a unique solution
x* ∈ (0,1) such that g(x) > 0 for ∀x ∈ (0, x*) and g(x) < 0 for ∀x ∈ (x*, 1).
Moreover, W * = log『(x*) is the globally minimizerfor the round trip time.
2.	For P = 2, we know that g00(X) > 0 for X ∈ (0, 1). Thus g0(X) < g(1) = 0 for X ∈ (0, 1)
and therefore g(χ) > g0(1) = 0 for X ∈ (0,1). Then according to Eq.(37), ∂wE[T] > 0
for W ∈ N+. E[T] is globally minimized at W = 1.
In what follows, we proceed to prove that P e P is a good approximation to x*. In fact, we have
g(p log P
1 --—Y+上1
P log P P log P
1 - P1⅛ - log P - Iog(IogP)
1+o
ɪ + log P
1og(1og P)
log P
Iog(Iog P) + ο ∩Λ
log P +	PPJ
+O
(IogP
Thus, limp→∞ g( Plog P) = 0.
For X
P≥4,
PIogP, we have W = log『 (p⅛p) = log 入窿产 P. Then according to Eq.(38), for
]=2P IogP + loglog P
- log r
ι -
1 + (P -1) T
1 - P log P _
1+
1^ -——11— ) ―；2— (P log P+P log log P)
log P 1 - P⅛ J - log r
(41)
≤ 11 + -.-1^- ) —j2— (P log P + P log log P)
log41 - 41⅛	- log r
4
<   --(P log P + P log log P)
- log r
In conclusion, for P = 2, 3, the maximum round trip rate is achieved when the window size W = 1.
For P ≥ 4, with the window size W = log 爪窿产 P, the round trip rate is at least Ω ( -OloPr ) ∙ □
Remark: Given finite chains with a large rejection rate, the round trip time is only of order
O(P log P) by setting the optimal window size W ≈ ∣"log 八窿产 P ^j ∙ By contrast, the vanilla DEO
17
Under review as a conference paper at ICLR 2022
scheme with a window of size 1 yields a much longer time of O(P2), where -3⑺ =O(ɪ-r)
based on Taylor expansion and a large r	0.
B.2.1 Technical Lemma
Proof of Lemma 3. To help illustrate the analysis below, we plot the graphs of g0 (x) and g(x) for
x ∈ (0, 1) and P = 5 in Figure 9. For P > 3, since g0(x) is maximized at X = 2P-2) ∈ (0, 1)
with g00(χ) > 0 when 0 < x < 2p-2)and g00(χ) < 0 when 2pP-2) < x < 1, limχ→0+ g0(x)=
一∞, and g0(1) = 0, We know that g0( 2p，)) > 0 and there exists xo ∈ (0, 2p，)) SUch that
g0(x) < 0 (i.e., g0(x) is monotonically decreasing) for any x ∈ (0, x0) and g0(x) > 0 (i.e., g0(x)
is monotonically increasing) for any x ∈ (x0, 1). Then g(x) on (0, 1) is globally minimized at
x = x0. Moreover, limx→0+ g(x) = 1 and g(1) = 0. Thus, g(x0) < g(1) = 0 and there exists
x* ∈ (0, xo) ( (0,1) such that g(x) > 0 if X ∈ (0, x*) and g(x) < 0 if X ∈ (x*, 1).
Meanwhile, by Eq.(37) and the definition of x, we know that the sign of ∂wE[T] is the same with that
of g(x) for W = logr(x). Thus, ∂w E[T ] < 0 when W < W * := log『 (x*) and ∂w E[T ] > 0 when
W > W*, which implies that E[T] is globally minimized at W* = logr (x*) with some x* ∈ (0, 1).
(a) g0(x)
Figure 9: Illustration of functions g0(x) and g(x) for x ∈ (0, 1) and P = 5
(b) g(x)
□
B.3 Discussions on the optimal Number of Chains in Big Data
To shed light on the suggestions of the optimal number of chains, we lay out two additional assump-
tions:
•	(B3) Integrability: U3 is integrable with respect to π(1) and π(P).
1
•	(B4) Approximate geometric spacing: Assume that TT(P) ≡ (T(Ty)	+ o(p1) for P ∈ [P 一 1].
Assumption B3 is a standard assumption in Syed et al. (2021) to establish the convergence of the
summation of the rejection rates. Assumption B4 allows extra perturbations to the geometric spacing
assumption (Kofke, 2002) and is empirically verified in the CIFAR100 example in Figure 7(c).
Proofofcorollary 1. Before we start the proof, we denote by r and 飞 the average rejection and
acceptance rates in full-batch settings, respectively. According to section 5.1 in Syed et al. (2021),
Assumptions B1, B2 and B3 lead to
r= PS+ O
(42)
18
Under review as a conference paper at ICLR 2022
where Λ is the barrier, which becomes larger if π(1) and π(P) have a smaller probability overlap
(Predescu et al., 2004; Syed et al., 2021). Then acceptance rate in full-batch settings is
s = ι - r = ι - Λ + o
(43)
By Lemma D4 (Deng et al., 2021) and Eq.(15), a noisy energy estimator with variance
(τ (p) -τ (p+1))2 2	(τ(p)-τ(p+1))2	2
(T(p)2τ(p+i)2 σp yields an average swap rate of O (S exp ( - ∖τ(P-T(p+i)2 ) σpJ. In What follows,
the average rejection rate in mini-batch settings becomes
r
1-O
s exp
(_ (T(P)-T(P+1))2 ʌ 2λ
I	8T(P)2T(P+1)2 ) Pp)
(44)
where p ∈ [P] and more accurate estimates is studied in proposition 2.4 (Gelman et al., 1997).
Define △/= T(Ty. By assumption B4 and Taylor,s theorem, We have
(「)2=(△卢-1 + o(P ))T 六)2 + o ( P ).	(45)
Denote YP = T(：+1). It follows that
exp -
(T(P) - T(P+1))2 2)
8t(p)2t(p+D2 %)
exp
+o
σP
T(P)2
(46)
((log ∆τ)2
- " -I)2
exp
+o
Plugging it to Eq.(44), we have
r=1-O
+O
exp
+o
(47)
Recall in Eq.(41), the round trip time follows that
E[T]
O(Plog P
- log r
(48)
By log(1 -1) ≤ -t for t ∈ [0,1) and ± = 1+1 + O(t2) for a small t, we have
11
—T- -----7---7------------7----------7~7~:；-
log T	log {1- O ((1- Λ + O (击))exp (-⅞P* + o(备)))}
1
_ O ((1 - λ + O (P13 )) exp (- (Yp(P-：)? + 0 ( P12 )))
=O ((1+P+O (P))exp ((YPP-；2+ o (P))).
Combining Eq.(49) and Eq.(48), we have
E[T ] =O (PlogP (1+Λ+O (P)) exp ((P-∖)2 + O (P)!)
=O (Plog P exp (PPɔ ),
(49)
(50)
19
Under review as a conference paper at ICLR 2022
where μp := Yp 2√δt . The optimal P to minimize E[T] = O (P log P exp (p⅛) ) is equivalent to
the minimizer of hp (x) = log {x log X exp (μp)} = log X + log log X + μp for X ≥ 4. Then
1 + _j___2μp = χ2 (I +1⅛)- 2μp
X X log X X3	X3
(51)
Define S(X)= x2 (1 + ioɪ^). Then We have
s0(X) = 2X +
2X log X - X
(log x)2
> 0,
(52)
for X ≥ 4. Thus S(X) increases with X for X ≥ 4. Obviously, limx-∞ S(X) = ∞. Since μp》1,
we know s(4) < 0. Thus, there is a single zero point P? ∈ (4, ∞) of s(X) such that h0p(X) < 0 if
X ∈ [4, P?) and h0p(X) > 0 ifX > P?. Therefore, hp(X) is minimized at P? with
P2(1 + lo1P;) ∈ (2minμp，2mpaχμp)∙
For any P? ≥ 2, we have 71/ (1 + 1/ log P?) ∈ (1.1, ∖∕2). Thus, we have the optimal number of
chains in mini-batch settings following that
P? ∈ (1.1 min μp, vz2max μp) ∈
pp
(min 3τσ+i) logd，max 2τσ⅛lo") ∙
(53)
□
B.4 Empirical justification of the optimal number of chains
To obtain an estimate of the optimal number of chains for PT in big data problems, we study the
standard deviation of the noisy energy estimators on CIFAR100 via ResNet20 models. We first
pre-train a model and then try different learning rates to check the corresponding standard deviation
of energy estimators. The reason we abandon the temperature variable is that the widely used
data augmentation has drastically affected the estimation of the temperature (Wenzel et al., 2020).
Motivated by the linear relation between the learning rate and the temperature in Eq.(6) and the cold
posterior affect with the temperature much smaller than 1 (Aitchison, 2021), applying Figure 10 and
Eq.(53) concludes that P? is achieved in an order of thousands in the CIFAR100 example.
The conclusion is different from Syed et al. (2021) since big data problems require a much smaller
swap rate to maintain the unbiasedness of the swaps. On the one hand, insufficient chains may lead
to insignificant swap rates to generate effective accelerations, but on the other hand, introducing too
many chains may be too cost in terms of limited memory and computational budget.
AP ①U ①』O Uo-4->E>① P P,JEPUES
Figure 10: Analysis of standard deviation of energy estimators with respect to different learning
rates through ResNet20 on CIFAR100 dataset. Note that we have transformed the average likelihood
into the sum of likelihood with a total number of 50,000 datapoints. Hence, the learning rate is also
reduced by 50,000 times.
20
Under review as a conference paper at ICLR 2022
C Approximation Error for SGD-based Exploration Kernels
This section proposes to analyze the approximation error when we adopt SGDs as the approximate
exploration kernels. Since it is independent of section B, different assumptions may be required.
The first subsection shows that for any Gaussian-distributed energy difference estimator Ue (β(p) ) -
Ue(β(p+1)), there exists an optimal C? such that the deterministic swap condition Ue (β(p+1)) + C? <
Ue(β(P)) perfectly approximates the random event S(β(P), β(p+1)) > u, where U 〜Unif[0,1].
C.1 Gap between acceptance rates
To approximate the error when we adopt the deterministic swap condition Eq.(8), we first assume the
following condition
• (C1) Energy normality: The stochastic energy estimator for each chain follows a normal distribu-
tion with a fixed variance.
The above assumption has been widely assumed by Ceperley & Dewing (1999); Bardenet et al.
(2017); Seita et al. (2017), which can be easily extended to the asymptotic normality assumption
depending on large enough batch sizes (Quiroz et al., 2019; Deng et al., 2021).
ProofofLemma 2. Denote ∂Tp = τ1p) - T(p+i)> 0 for any P ∈ [P - 1], the energy difference
∂UP = U (β(P)) - U (β(P+1)). By the energy normality assumption C1 and Eq.(15), the energy
difference estimator follows that deep = ∂Up(∙) + √2σpξ, where ξ 〜N(0,1).
Recall from Eq.(16) that the bias-corrected acceptance rate follows that
Se(βt(p), βt(p+1)) = 1 ∧ e∂Tp Ue(βt(p))-Ue(βt(p+1)) -∂Tp2σp2
=1 ∧ e∂Tp∂Up+√2∂"ξ-∂T2σp
(i)	For a uniformly distributed variable μ 〜Unif[0,1], the base SWaP function satisfies that
p(e(β” β(p+1)) >μ∣∂Up) = Z： P(S(β(p), β(p+1)) > u∣∂Up)du
11
=p(edTP--际σP > u∣∂Up)du
0
[1 P(ξ> -dep + dTPσP +
Jo	∖	√2σ p
du
(54)
(55)
(ii)	For the deterministic swaps based on Eq.(8), the approximate swap function follows that
P(U(βkp+1)) + C < U(βkp))∣∂Up) = P(C < ∂Up + √2σpξ∣∂Up) = P (ξ > -令：C
(56)
21
Under review as a conference paper at ICLR 2022
Denote by D(u, C)= P ( ξ> -dup+dTpσp+dTU ) - P fξ> -√Up+C) I ∈ [0,2). Combining (55)
2σp	2σp
and (56), we can easily derive that
△ (C)= P e(β(p), β(p+1)) >μ∣
-P U(βkp+1)) + c <U(βkp))l
e-∂Tp2 σ2p +∂TpC
-∂Up +∂Tp σp2 +
P ξ>——--厂P
2σ	√2σp
-P (ξ> -∂UPσ+C 卜U
f
0
|
D(u,C) for small enough u
}
+e
P ξ>
-∂Tp2 σp2+∂TpC
、
-∂Up+C
—Pf ξ > -F--- 1 du
V	√2σp
e-∂Tp2σ2p+∂TpC
D(u, C)du -
{^^^^^^^^^^^^
-D(u,C) for large enough u
1
D(u, C)du
-∂Tp2 σ2p +∂TpC
1
}
Clearly, △(C) is continuous in C and it is straightforward to verify that
e-∂Tp2σ2p+∂Tp2σp2	1
∆(∂Tpσp) = /	D(u,∂Tpσp)du -屋醇+吟吟 D(u,∂T›p)du
= Z D(u, ∂Tp σp2)du ≥ 0
0
Similarly, ∆(-∞) = 一 R01 D(u, C)du ≤ 0. Moreover, the physical construction suggests that the
threshold C should be strictly positive to avoid radical swap attempts, which implies that there is an
optimal solution C? ∈ (0,∂Tpσp2] that solves △(C?) = 0.
□
Remark 1. Note that the optimal C? may lead to few swaps given a finite number of iterations and
sometimes it is suggested to trade in some accuracy to obtain more accelerations (Deng et al., 2020).
As such, by setting a desired swap rate via the iterate (13), we can estimate the unknown threshold
C by stochastic approximation (Robbins & Monro, 1951). Furthermore, as discussed in Lemma B2
( ) ( +1)	∂Tp2σp2
(Deng et al., 2021), the average swap rate follows that E[S(βtp, βtp ))] = O(e	8-). This
∂TpσpP
suggests thatfor a well-approximated threshold C, the error is at most E[∆(C)] = O(e	8-).
C.2 Approximate Upper Bound
The second subsection completes the proof regarding the numerical approximation of SGD-based
exploration kernels. Nevertheless, we still require some standard assumptions.
•	(C2) Smoothness: The function U(∙) is C-smooth if there exists a positive LiPschitz constant C
SUchthatk VU(x) - VU(y)∣∣2 ≤ CIlx - y∣∣2 for every x,y ∈ Rd.
•	(C3) Dissipativity: The function U(∙) is (a, b)-dissipative if there exist positive constants a and b
such that hx, VU (x)i ≥ akxk2 - b.
•	(C4) Gradient normality: The stochastic gradient noise ε(∙) in Eq.(6) followsaNormal distribution
N (0, M) with a fixed positive definite matrix M.
The assumptions C2 and C3 are standard to show the geometric ergodicity of Langevin diffusion and
the diffusion approximations for non-convex functions (Mattingly et al., 2002; Raginsky et al., 2017;
Xu et al., 2018). The assumption C4 is directly motivated by Mandt et al. (2017) to track the Ornstein
Uhlenbeck (OU) process with a Gaussian invariant measure.
22
Under review as a conference paper at ICLR 2022
Proof of Theorem 2. The transition kernel T of the continuous-time replica exchange Langevin
diffusion (reLD) follows that T = Qp T(p), where each sub-kernel T(p) draws a candidate θ ∈ Rd
with the following probability
T(p)(θ∣β(p), β(q)) = (1- S(β(p), β(q)))Qp(θ∣β(p)) + S(β(p),β(q))Qq(θ∣β(q)),
where p, q ∈ {1, 2,…，P}, |p - q| = 1 and q is selected based on the DEO? scheme (3), Qp(θ∣β)
is the proposal distribution in the p-th chain that models the probability to draw the parameter θ via
Langevin diffusion conditioned on β, and S(βt(p), βt(q)) follows the swap function in Eq.(2).
Now we consider the following approximations:
reLD =⇒I reSGLD=⇒II D\EO?-SGLD =I⇒II DEO?-SGLD =I⇒V DEO?-SGD,
1	八TC	- ,1 CL-	1	,.1,.1	....	T 」
where DEO? -SGLD resembles the DEO? scheme except that there are no restrictions on conducting
at most one swap.
I:	Numerical approximation via SGLD By Lemma 5, we show that approximating replica ex-
change Langevin diffusion via reSGLD yields a weak error only depending on the learning rate;
similar results depending on the learning rate and the noise in gradient and energy noise have been
studied in Lemma 1 of (Deng et al., 2020).
II:	Restrictions on at most one swap Adopting at most one swap in the DEO? scheme includes a
stopping time, which may affect the underlying distribution. Fortunately, the bias can be controlled
and becomes smaller in big data problems, which is detailed as follows.
_ _ ■ —___________________ ~ _____________ ___________________ … ~
Note that DEO? -SGLD differs from DEO? in that DEO?-SGLD freezes at most W - 1 attempts of
swaps in each neighboring chains in each window, while DEO? -SGLD keeps all of these positions
open. Recall that the bias-corrected swap rate follows that Se = O S e-O(σ2) by invoking Eq.(16).
Following a similar technique in analyzing the bias through the difference of acceptance rates
in Lemma 2, we can show that the bias is at most S - P(Acceptance rate given frozen swaps) =
|
}
{^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
=0
O(e-O(σ2)). In other words, the restrictions on at most one swap only lead to a mild bias in
big data problems and is less of a concern compared to the local trap problems. Empirically, we
have verified the relation between the bias and the variance of noisy energy estimator in a simulated
example in section C.2.1.
III:	Deterministic swap condition By Lemma 2 and the mean-value theorem, there exists an
optimal correction buffer C? to approximate the random event S(β(P), β(p+1)) > μ through
Ue (βk(p)) + C? < Ue (βk(p+1)) in the average sense for any βt(p) and βt(p+1).
IV:	Laplace approximation via SGD Assumption C4 guarantees that there exists an optimal
learning rate η to conduct Laplace approximation for the target posterior (Mandt et al., 2017). Further,
by the Bernstein-von Mises Theorem, the approximation error goes to 0 as the number of total data
points goes to infinity.
Combining the above approximations, there exists a finite constant ∆max ≥ 0 depending on the
learning rates η, the variance of noisy energy estimators, and the choice of correction terms such that
the total approximation error of the SGD exploration kernels with deterministic swap condition is
upper bounded by ∆maχ. For any joint probability density μ, the distance between the distributions
generated by one step of the exact transition kernel T and the approximate transition kernel Tη in
23
Under review as a conference paper at ICLR 2022
Eq.(7) is upper bounded by
β
≤Zβ
dΩ(β)lμT(β) - μTη(β)
dΩ(β)∖	dμ(φ,ψ)∆maχ Q(β∣φ)-Q(β∣ψ)
φ,ψ
≤ ∆maχ / dΩ(β) L Jμ(φ, ψ) (Q(β∣φ) + Q(β∣ψ)
≤ 2∆max ,
where Q(∙∣∙) = ∏p Qp(∙∣∙). Thus, the one-step total variation distance between the exact kernel and
the proposed approximate kernel is upper bounded by
kμT(β) - μTη(β)kTV = 1 ∕dΩ(β) μT(β) - μTη(β) = ∆maχ.	(57)
The following is a restatement of Lemma 3 in the supplementary file of Korattikara et al. (2014).
Lemma 4. Consider two transition kernels T and Tη, which yield stationary distributions π and πη,
respectively. If T follows a contraction such that there is a constant ρ ∈ [0, 1) for all probability
distributions μ:
l∣μT- πktv ≤ ρkμ 一 πktv,
and the uniform upper bound of the one step error between T and Tη follows that
kμT- μTηkTV ≤ ∆,∀μ,
where ∆ ≥ 0 is a constant. Then the total variation distance between π and πη is bounded by
∆
kπ - πηIlTV ≤ ι-ρ.
Under the smoothness assumption C2 and the dissipative assumption C3, the geometric ergodicity
of the continuous-time replica exchange Langevin diffusion to the invariant measure π has been
established (Chen et al., 2019). Combining the exponential convergence of the KL divergence (Deng
et al., 2020) and the Pinsker,s inequality (Csisz疝 & Korner, 2011), We have that for any probability
density μ, there exists a contraction parameter P ∈ (0,1) such that
l∣μT- πkτv ≤ ρkμ 一 πkτv,
where ρ depends on the spectral gap established in Raginsky et al. (2017) and the swap rate.
Applying Lemma 4, the total variation distance can be upper bounded by
kπ 一 πηkτv ≤ Ymax,
1-ρ
which concludes the proof of Theorem 2.
□
C.2.1 Bias analysis for generalized windows in big data problems.
Following the empirical setup in section 5.1 (Deng et al., 2020), we run parallel tempering based
on two gradient Langevin dynamics (GLD) with noisy energy estimators of different variances and
generalized windows of different sizes. We fix the learning rate 0.003 and set the temperatures as 1 and
10, respectively. The swap condition follows from Eq.(16). We run the algorithm 3,000,000 iterations
and also include a baseline by running the low-temperature process with 6,000,000 iterations.
We try different window sizes (2 and 5) and difference standard deviations (1, 2, and 3) for the noisy
energy estimators. We observe in Fig.11 that simply running GLD (red curves) suffers from the local
trap issues and consistently lead to the worst performance; the exact energy estimators, as shown in
the cyan curves, yield crude estimations as well due to the inclusion of stopping time. By contrast,
as the variance increases, we see a pattern that the bias tends to decrease and a good trade-offt is
obtained at sd = 3, where the blue curves show remarkable approximations.
,Further increasing sd (or the variance) may yield fewer swaps and less accelerations.
24
Under review as a conference paper at ICLR 2022
Figure 11: Bias analysis based on extended windows and nosiy energy estimators.
C.3 Weak error
In this section, we show the weak error (Lemma 5 below) between the Replica exchange Langevin
diffusion (β(1), β(2),…，β(P)) and the RePliCa exchange stochastic gradient LangeVin diffusion
(β(1), β(2),…，βtP)). We denote P := PW × N, where PW is the infinite dimensional Wiener
measure and N is the Poisson measure indePendent of PW and has some constant jumP intensity. In
our general framework below, the jumP Process α is introduced by swaPPing the diffusion matrix
of the P LangeVin dynamics and the jumP intensity is defined through the swaP Probability in the
following sense, which ensures the indePendence ofPW and N in each time interVal [iη, (i+ 1)η], for
i ∈ N+. Without loss of generality, the rePlica exchange LangeVin diffusion (reLD) is reformulated
as below. For any fixed learning rate η > 0, we define
(dβt = -VU(βt)dt + Σ(αt)dWt,
(58)
[P(Mt)= j|a(t- dt) = l,β(LVncn) = P) = aS(P)η 1{t=bt∕ηcη} + Omt), for l = j,
where VU(β) := ZU(β⑴),VU(β⑵),…，VU(β(P))) , and 1t= ∖t∕ηcη is the indicator func-
tion, i.e. for every t = in with i ∈ N+, given β(iη) = β, We have P (α(t) = j∣α(t — dt) = I) =
rS(β)η, where S(β) is defined as min{1, S(β(1),β(2))} and S(β(1), β(2)) is defined in (2). In this
case, the Markov Chain a(t) is a constant on the time interval [[t/nCn, [t/nCn + n) with some state
in the finite-state space M = {0,1, ∙ ∙ ∙ , 2p-1 — 1} and the generator matrix Q follows,
(Q11	=	-aS(e(1),⑵)nδ(t - [t/nCn),	Q12 = aS(β(I),⑵)nδ(t - [t/nCn)
J Qi(i-ι)	=	aS(β(i-1),(i))nδ(t - [t/nCn),	Qi(i+ι) = aS(β(i),(i+1))nδ(t - [t/n」n)
I Qii	=	-aS(β(ZT),⑶)nδ(t - [t/nCn) — aS(β⑶,(i+1))nδ(t - [t/nCn)
IQP(P-1)	=	aS(β(P-1),(P))nδ(t - [t/nCn),	QPP = -aS(β(P-1),(P))nδ(t -	[t/nCn),
where 1 < i < P, and all the other terms in Q remain zero. We denote δ(∙) as a Dirac delta function.
Furthermore, for general adjacent swap with odd iterations (denoted as QO), and even iterations
(denoted as QE), the generator matrices QO and QE ∈ R(P d)×(P d) have the following form,
	(Q11 Q12	0	0	…、		00	0	0	0
	Q21	-Q21	0	0	0		0	-Q23	Q23	0	0	…
OO —	0	0	-Q34	Q34	0	CE —	0	Q32	-Q32	0	0	0
Q =	0	0	Q43	-Q43	0	,Q =	0	0	0	-Q45	Q45	…
	0	0	0	0	•一		0	0	0	Q54	-Q54	0
	\	•・・	∙ ∙ ∙ J		\	•・・	∙ ∙ ∙ J
For the odd iteration case, the diffusion matrix			for the first two chains β(1) and
β(2) has the following form according		to the state of Σ(αt), i.e. (Σ(0), Σ(1))	:=	
J ∕√2τ(I)Id	0	.八		∕√2T(2) Id	0	…∖	I
	0	√2τ⑵ Id	…	,	0	√2τ ⑴ Id …	,where
■	∖	•・・	・・・	∙	∙ ∙ /	.	⅜	•・・	・・・	∙ ∙ ∙ /	I
/ (Pd)X(Pd)	/ (Pd)X(Pd) J
the rest of the diffusion matrix remain unchanged. Based on the observation of the transition
matrix of QO , and QE, there is no interaction between every pairs (each pair has two chains) in
25
Under review as a conference paper at ICLR 2022
each iteration, we will prove the weak error for only two chains. We can then add different square
blocks together as shown in QO and QE. From now on, we restrict to the two chain case with
β = (β(1), β(2)). Next, we denote βe as the Replica exchange stochastic gradient Langevin diffusion,
for the same learning rate η > 0 as above, we have
dβη = -VU (βebt∕ηcη )dt + ∑(ebt∕ηCη )dWt,
(59)
P (e(t) = j∣e(t — dt) = l, β(]t∕ηJη) = β) = S(β)η1{t=bt∕ηCη} + o(dt), for l = j,
where VU(β):= Ce；))) and Se(Je) = min{1, Seη,m,n(∕e(v), /e⑵)} and S%m,n(∕e⑴,∕e(2))is
shown in Eq.(16). The distribution of process (βt)o≤t≤τ is denoted as μτ := PG X NS, where e is a
Poisson process with jump intensity aS(β)ηδ(t — [t∕η[η) on the time interval [[t∕ηCη, [t∕η[η + η).
For any open set U ⊂ R2d , which is contained in a large enough open ball with radius R centered at
β(0), we define stopping time
TU = inf{t ≥ 0∣(β(t),α(t)) ∈ U × M)}.	(60)
Lemma 5. Assume the smoothness assumption C2 holds. For any large enough open set U, we have
....∙, . . .., ： 一 . ~ . ... ..,. .
∣Ex,i[h(β(T ∧ τu),α(T ∧ TU))] - Ex,i[h(β(T ∧ τu),e(T ∧ TU))]| = O(η).
for any continuous differentiable and polynomial growth function h.
Proof. We denote βt = (βt(1), βt(2)), which follows the dynamics below,
dβt = -VU(βt)dt + Σ(αt)dWt
Denote
u(βt = x, t, i) = Ex,i [h(βT ∧τU,αT∧τu )l(βt,αt) = (x,i)],	i ∈ M.
For t < T ∧ TU, applying Feynman-Kac formula (see e.g. Baran et al. (2013)), we have
∂tu(x, t, i) + Lu(x, t, i) = 0,
Lu(x, t, i) = tr(ΣΣTV2u(x, t,i)) — (Vu(x, t,i), VUi + Q(x, t)u(x, t, ∙)(i)
(61)
Applying generalized It6 formula, for each i ∈ M We have
h(βt,αt)-h(β0,α0)
t Lg(βs,
0
αs)ds + M1 (t) + M2 (t),
(62)
where M1 + M2 is a local martingale. See details in (Yin & Zhu, 2010; Skorokhod, 2009). We thus
get, for kη ≤ t < (k + 1)η < T ∧ TU,
Ex,i[h(βt,αt)]-h(x,i)=Ex,i
Lh(βs, αs)ds.
0
For 0 <tι <t2 ‹ ∙∙∙ ,tN = T ∧ TU, with tk = kη, We next derive the It6 formula for h(βt, αj.
Note that β and β are defined by using the same P-Brownian motion W, but with two different jump
intensity on the time interval [bt∕ηcη, bt∕ηcη + η). We have the following approximation,
βetk - βetk-1 = -VUe(βetk-1)η+ Σ(αetk-1)N (0, η).
For stochastic noise ξtk-1, with E[ξtk-1] = 0, we rewrite the above approximation as below,
βetk - βetk-1 = -(VU(βetk-1)+ξtk-1)η+Σ(αetk-1)N(0,η).
For notation convenience, for tk-1 ≤ t < tk, we keep the following convention,
∑ (βt):= ∑(βηt∕ηCη ) = ∑(β1Lι), —VU (βt):= —VU (Σ(βηt∕ηcη )) = -VU (⑸一).
26
Under review as a conference paper at ICLR 2022
For any tk-ι ≤ t < tk, We apply It6 formula for u(βt, t, i),
∂u
du(βt,t, i) = (∂tu + Lu(βt, i)dt + Σ(α[t∕ηjη)∂χ(βt)dWt + dfffι(t) + dff2(t),	(63)
∂u
=[(Le - L)U(Zet, t, i)]dt + Ka[t/nCn)∂χ(Zet)dWt + dMfι(t) + dMf2(t),
Where the last equality folloWs from (61), and for tk-1 ≤ t < tk,
Lu(βt,t,i) = tr(ΣΣTV2u(βt,t,i)) -〈▽"(βt), Vui + Q(βt,t)u(βt,t, ∙)(i).
Evaluate the integral on time interval [0, T ∧ τU], and take expectation Ex,i, We have
Ex,i [u(ZeT ∧τU , T ∧ τU, i) - u(Z0, 0, i)]
T∧τU
Ex,i[(Le- L)u(Zet,t)]dt
0
I1 + I2 + I3 .
Where We have
I1
T ∧τU
:=- 0
Ex,i[hVUe(Zet),Vu(Zet,t)i -hVU (Zet), Vu(Zet, t)i]dt,
T∧τU
I2 :
Ex,i[tr(Σe Σe T V2u(Zet, t)) - tr(ΣΣT V2u(Zet, t))]dt,
T∧τU
I3 :
_ 〜、，： 、 一，： 、，： …一
E X [Q(βt,t)u(βt,t, ∙)-Q(βt,t)u(βt,t, ∙)]dt.
In the next step, We introduce a sequence of stopping time based on our definition of process Z and
Z . For j ∈ N+, We denote ζj0s as a stopping times defined by ζj+1 := inf {t > ζj : α(t) 6= α(ζj)}
and N(T) = max{n ∈ N : ζn ≤ T}. According to the definition of process Z , We have ζj = lη, for
some l ∈ N+. Similarly, We have stopping time ζj+1 := inf{t > ζj : αe(t) 6= αe(ζj)} associated With
process β, and α(t) follows the same trajectory of α(t). We thus have the following estimates for the
terms I1 , I2 , and I3 .
Estimate of Ii： as for Iι, -VU(∙) does not depend on a, we get
K-1 tk+1
X
Ex,i[h(VU(Zetk)+ξtk -VU(Zet)),Vu(Zet,t)i]dt
k=0 tk
K-1 tk+1
-X
k=0 tk
Ex,i[h(VU(Zetk) - VU(Zet, t)), Vu(Zet, t)i]dt,
where we use the assumption Ex,i[ξtk] = 0, and independent property of the noise ξtk . For tk ≤ t <
tk+1, let
ρ1(Zet,t)= h(VU(Zetk)-VU(Zet)),Vu(Zet,t)i,
applying Ito formula (same as (63) above), taking expectation, and using the fact Qρι(βt,t)=
aS(β(1), β(2))[ρι((β(I),β(2)),t) - ρι((β(2),β(1)),t)]=0,weget
一 ∙ ■	，U 、、
dEx,i[ρι(βt,t)]
dt
Ex,i[∂tρ1(Zet, t) + tr(ΣeΣeT V2ρ1(Zet, t)) -hVUe(Zet),Vρ1(Zet,t)i] ≤Ck,
where the bound follows from the Weierstras theorem, and the same idea is also adopted in Sato &
Nakagawa (2014) for diffusion process without jumps. We end up with,
Ex,i[ρ1(Zet,t)] ≤ Ckη,
which implies
I1 ≤ T ηCmax.
0
0
27
Under review as a conference paper at ICLR 2022
Estimate of I2: for each time interval tk ≤ t < tk+1, falling between two stopping time, the matrix
Σ(α(t)) = Σ(α(t)) remains constant, and tr(ΣΣTV2u) = tr(ΣΣTV2u) = Ej=O Tj∆3.u, We
have
I2 = 0.
Estimate ofI3: We reWrite the time interval [0, T ∧τU] as the summation of the stopping times, i.e.
∧τU = PlN=(0T ∧τU)-1 Rζζl+1, We thus have
T∧τU
I3 :
Ex,i[Q(βt,t)u(βt,t, ∙) - Q(βt,t)u(βt,t, ∙)]dt
0
N(T∧τU)-1	ζl+1
X
l=0	ζl
___.... √ . ≈ , ≈	.	, ≈	.	_	, ≈	.	, ≈	、r-
E , [Q(βt,t)u(βt,t, ∙)-Q(βt,t)u(βt,t, ∙)]dt.
Recall that,
Q(x)u(x, ∙)(i) = E Qij(u(x,j) - u(x,i)),
j∈M,j6=i
and We denote Qij as the components of the generator matrix Q of β. For ζl ≤ t < ζl+1, We denote
7 , ≈	.	≈ , ≈	.	, ≈	____ _	_ , ≈	.	, ≈	........
ρ3(βt,t) ：= Q(βt,t)u(βt,t, ∙)(α(τι)) - Q(βt,t)u(βt,t, ∙)(α(τι))
X
(Qeα(τl),j(βet) - Qα(τl),j(βet))(u(βet,t)(α(j) - u(βet,t)α(τl))).
j∈M,j6=α(τl)
In particular, for the tWo chain case, M = {0, 1}. For any t ≤ T ∧ τU, there exists large enough open
ball With radius R, denoted as U ⊂ B(β(0),R), such that U ⊂ B(β(0),R), Which implies the uniform
bound of u(βt, t) ≤ C, for t ≤ T ∧ τU. We thus get the estimates
∣I3∣ ≤ N (TXU 'I I"' Ex,i[∣ρ3(βt,t)∣]
l=0 ζl
≤ 2CN (TX∧τU)-1 Z ζl+1	X
Ex,i[∣(Qα(τι),j (βt) - Qα(τι),j (βt))∣]
l=0	ζl	j∈M,j 6=α(τl )
≤ 2Caη( XTU)	Zζl+1	X	Ex,i[∣(Sα(τι),j(βt) - Sα(τι),j(βt))∣]
l=0	ζl	j∈M,j 6=α(τl )
≤ 2CKaη.
Where the last inequality folloWs from the fact that S, S ≤ 1, and N (T ∧ τU) ≤ K. Combing all the
estimates in I1,I2, I3, the proof is thus completed.
□
28