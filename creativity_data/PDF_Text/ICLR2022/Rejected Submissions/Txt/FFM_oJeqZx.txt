Under review as a conference paper at ICLR 2022
Adaptive Pseudo-labeling for Quantum Cal-
CULATIONS
Anonymous authors
Paper under double-blind review
Ab stract
Machine learning models have recently shown promise in predicting molecular
quantum chemical properties. However, the path to real-life adoption requires (1)
learning under low-resource constraints and (2) out-of-distribution generalization
to unseen, structurally diverse molecules. We observe that these two challenges
can be alleviated via abundant labels, often not the case in quantum chemistry.
We hypothesize that pseudo-labeling on a vast array of unlabeled molecules can
serve as gold-label proxies to expand the training labeled dataset significantly. The
challenge in pseudo-labeling is to prevent the bad pseudo-labels from biasing the
model. Motivated by entropy minimization framework, we develop a simple and
effective strategy PSEUDσ that can assign pseudo-labels, detect bad pseudo-labels
through evidential uncertainty, and prevent them from biasing the model using
adaptive weighting. Empirically, PSEUDσ improves quantum calculations accuracy
across full data, low data, and out-of-distribution settings.
1	Introduction
Accurate quantum mechanical (QM) calculations of drug-like molecules at CCSDT (coupled cluster
single-double-triple) or MP2 (second order M0ller-Plesset) (Watts et al., 1992) level of theory,
which is essential to characterize biomolecular interactions, continue to be prohibitively expensive,
despite recent advances in hardware capabilities. Machine learning (ML) models have astonishing
performance in approximating these calculations at a fraction of the computational cost (von Lilienfeld
& Burke, 2020). Such speedups could accelerate the discovery of new therapeutics.
In the absence of large-scale benchmark data sets reporting CCSDT or MP2 level calculations, most
publications on this topic have relied on QM9, a standard benchmark of Density Functional Theory
(DFT)-level energy and properties, for training and evaluating QM/ML models. This data set contains
molecular geometries and energies that were generated using DFT, which provides a faster (compared
to CCSDT, for example), but less accurate description of molecular energetics and properties. Previous
publications have utilized computed geometries and properties from in-distribution molecules in
QM9 to test and validate model performance, showing excellent performance of QM/ML models as
demonstrated by low mean absolute error (MAE) of predicted energies of other properties relative
to the gold-standard DFT calculations (i.e., gold label). However, it is unclear how the reported
architectures (e.g., SchNet (Schutt et al., 2017)) would perform in the regime oflow but accurate data
(CCSDT or MP2).
Two challenges remain in the way of the realistic adoption of ML-aided QM calculations. Firstly,
training molecules only cover part of the distribution, and real-world adoption requires out-of-
distribution generalization. Secondly, computing QM properties for datasets of the size of QM9 is
costly. Widespread applicability of ML for QM (e.g., such as to CCSDT/MP2) thus requires models
to generalize well given low-data constraints. Both challenges listed above can be attributed to the
difficulty and cost of generating experimental data in chemistry and materials science. If we have a
large and diverse set of labeled molecules, the ML model can generalize to larger chemical spaces
and achieve better predictive performance.
Present work. Our key observation is that state-of-the-art ML models can obtain a low-precision
estimation of the properties even given a small set of labeled molecules. This suggests that the
ML predicted label for any unlabelled molecule can be used as a low-precision estimation of the
true label. We hypothesize that by considering these low-precision pseudo-labels as the training
1
Under review as a conference paper at ICLR 2022
targets in the training process, we can largely increase the training dataset size and diversity and
alleviate the fundamental label scarcity issue, along with the associated challenges in low-data and
out-of-distribution generalization.
In our study, we develop a simple, effective, and model-agnostic pseudo-labeling strategy
called PSEUDσ. Notably, we solicit an extensive array of unlabeled molecules from the PC9
dataset (Glavatskikh et al., 2019) where an ML model assigns pseudo-labels for them. This generates
a large set of ”labeled” training data points, even when only a relatively small number of reference
QM properties are available for training. As the unlabeled dataset is diverse and unseen in QM9, it
also helps generalization to unseen data. One crucial issue in pseudo-labeling is the introduced bias
from low-quality pseudo-labels. To resolve this, we rely on a key observation that a data point with
less evidence/higher model uncertainty is more likely to be of low-quality pseudo-label (Section 6).
Thus, we use model-generated evidential uncertainty to quantify each unlabeled data and use it to
adaptively lower the weight of bad pseudo-labels in the training loss to reduce the bias effect.
In summary, we have made the following contributions: (1) Previous QM focus on in-distribution
and label abundant setting while we point out that the realistic ML-aided QM challenges lie in
low-data and out-of-distribution settings; (2) Pivoting away from the status quo in improving the
physics-based representation, we propose to look at data-centric approaches on learning from the
vast array of unlabeled molecules; (3) We propose an episodic pseudo-labeling scheduling strategy
designed specifically for QM since many classic pseudo-labeling tricks do not work well in QM (e.g.,
data augmentation, model noise, student-training, re-initialization); (4) To prevent bad pseudo-label
in biasing the training, we devise an adaptive weighting scheme where the weights are generated
using evidential uncertainty such that bad pseudo-labels are automatically filtered out; (5) We
derive a theoretical connection between the evidential loss and entropy minimization framework; (6)
Empirically, we show PSEUDσ can improve QM accuracy for any atomistic model across full-data,
low-data, and out-of-distribution settings.
2	Related Works
ML-aided quantum calculations. Recently, many ML models have been proposed to improve
quantum calculations. They mainly focus on improving the physics-based representation in the full
Qm9 dataset setting (Schutt et al., 2017; Unke & MeUWly, 2019; Anderson et al., 2019; Lu et al.,
2019; Klicpera et al., 2020; Liu et al., 2021; Qiao et al., 2021). In contrast, our work proposes to
shift the focus on improving training strategy instead of the model architecture. In addition, PSEUDσ
is model-agnostic, and it can improve on any atomistic model. Additionally, We focus on realistic
quantum calculations such as learning in the loW-data regime and out-of-distribution inference.
Pseudo-labeling. Pseudo-labeling/self-training generates pseudo-labels for unlabeled data. Numer-
ous Works exist for hoW to assign pseudo-labels, notably through trained ML model prediction (Lee
et al., 2013), label propagation(Shi et al., 2018; Iscen et al., 2019), and history cache (Likhomanenko
et al., 2021; Higuchi et al., 2021). PSEUDσ is different as it focuses on detecting and preventing bad
pseudo-label from affecting the model. Also, PSEUDσ adopts a novel episodic pseudo-label strategy
With a re-initialized learning rate. (Xie et al., 2020) re-initialize the netWork as a student When a neW
pseudo-label set is generated along With noise per epoch. In contrast, PSEUDσ has no student, and no
noise as both are shoWn to be ineffective for QM in Section 6. In addition, small perturbational noise
in 3D molecular geometry could easily lead to a drastic energy difference. Thus, the noise strategy
does not Work for QM tasks. More related is a concurrent Work (Rizve et al., 2021) that develops an
uncertainty-aWare pseudo-labeling strategy, but they introduce additional hyperparameters to remove
pseudo-labels at some uncertainties. In contrast, PSEUDσ uses an effective adaptive Weighting
scheme, along With an episodic pseudo-labeling training schedule. Additionally, PSEUDσ is the
first method that studies pseudo-label in quantum calculations, Which present unique challenges and
motivations.
Uncertainty. Model uncertainty is a Well-studied subject (Kendall & Gal, 2017; Lakshminarayanan
et al., 2017; Blundell et al., 2015). (Amini et al., 2020) use evidential uncertainty to add a prior over
the gaussian parameters to search for higher-order patterns for regression tasks. PSEUDσ leverages
evidential uncertainty as the uncertainty measure. Note that PSEUDσ is uncertainty measure-agnostic.
We can easily sWitch to alternative uncertainty measures. Recently, (Soleimany et al., 2021) adapt
evidential uncertainty and has shoWn it can successfully help guide property prediction. In contrast,
2
Under review as a conference paper at ICLR 2022
Uncertainty σ = Var[μ] = V(OLI)
Generate Pseudo-label with Uncertainty
M episodes
Train on GoId-LabeI and PSeUdo-LabeI
With Adaptive Evidential Loss
• Gold-labeled ∙ Unlabeled ∙ Pseudo-labeled O Uncertainty
Figure 1: PSEUDσ illustration. In every episode k, PSEUDσ assigns pseudo-labels along with their
evidential uncertainty using trained neural network f (k-1) from previous episode. The uncertainty is
used as weight to adaptively adjust the loss in this episode’s neural network f(k) ’s training to reduce
the effect of bad pseudo-labels in an inner-loop training with N epochs.
we leverage evidential uncertainty as a proxy for pseudo-label quality to tackle low-data and out-of-
distribution challenges in realistic quantum calculations setup.
3	Problem Formulation
Let X = {x1, . . . , xN} denote N molecules, where each molecule xi is uniquely defined by 3D
coordinates {(aij, bij, cij)}jN=i 1 for Ni atoms with atom types {tj}jN=i 1 in the corresponding molecule.
We then denote Y = {y1, . . . yN} a set of quantum mechanical properties for each molecule. The
labeled dataset thus consists of a set of pairs of 3D coordinates and scalar labels D = {X , Y}.
In addition to the labeled data, we solicit a large quantity of unlabeled data to generate pseudo-labels.
We denote an unlabeled dataset U = {x1, . . . , xM}, where M is the size of the unlabeled dataset.
ʌ
Given an atomistic model f (∙), We can generate pseudo-labels Y = {yι,..., yM}, where yi = f (Xi)
for xi ∈ U .
The problem is to find a machine learning-based atomistic model f : X 7→ y that can establish an
accurate map from 3D coordinates to the quantum mechanical properties of the molecules, with the
help of pseudo-labeled dataset U .
4	PSEUDσ: ADAPTIVE PSEUDO-LABELING FOR QUANTUM CALCULATIONS
PSEUDσ (Figure 1) is an approach for quantum chemical property prediction. Building on theoretical
motivation from Section 5, PSEUDσ solicits pseudo-labels on a vast array of an unlabeled dataset
to increase the diversity of the training space via an episodic labeling strategy. Then, it adaptively
weights the pseudo-labels using evidential uncertainty to allow a positive transfer. The overview is in
Algorithm 1.
Episodic Pseudo-labeling. We devise a pseudo-labeling strategy that can ensure learning from the
pseudo-labels to the fullest extent for QM. We have made two distinct modifications compared to
existing works. First is the pseudo-label scheduling. In the standard pseudo-labeling (Lee et al.,
2013), pseudo-labels are updated in every update and the model is continuously trained. In contrast,
we devise an episodic training strategy, where each episode consists of K epochs, and pseudo-labels
are regenerated in every episode, while the model is continuously trained. This is important because
we observe that fast updates on pseudo-labeling prevents the model to fully learn from all useful
information in pseudo-labels. In contrast, our episodic approach gives the model more time to absorb
useful information from a given set of pseudo-labels. Second modification is the model update. In
self-training (Rizve et al., 2021; Xie et al., 2020), a set of pseudo-labels are regenerated after K
epochs and the model is reinitialized. Instead, we train the same model throughout episodes. This
new strategy allows the model to be exposed to a larger number of labels or training data points given
the same time frame. For each episode, we also reinitialize the learning rate with a small step-wise
3
Under review as a conference paper at ICLR 2022
decay strategy to allow the model a chance to jump out of the local optimum from the previous set of
pseudo-labels.
Formally, PSEUDσ mainly consists of three stages: in the first stage, regular training is conducted on
labeled data D, and the output model is the initialized model f(1). In the second stage, the updated
model at episode k then conducts inference on the entire unlabeled data Y = f (k) (U) to generate the
pseudo-label set. The per-episode pseudo-label set is then combined with the gold-labeled data to
form the training data for the next episode. In the third stage, the model is further trained using the
combined dataset to get a new model f (k+1) after N epochs. The second and third stages are then
reiterated till the loss stops decreasing.
Evidential uncertainty quantification. Pseudo-labels are noisy. Many are incorrect and can po-
tentially lead to negative transfer. Thus, it is instrumental in detecting the quality of pseudo-labels.
However, there is no auxiliary information in the dataset about the pseudo-labels. Thus, we need to
quantify it through some proxies that can be assigned without auxiliary information. Our key obser-
vation is that low-quality pseudo-labels have high model uncertainty, and high-quality pseudo-labels
have low model uncertainty. Another advantage of model uncertainty is that it can be estimated solely
from x, if we make it model uncertainty-aware.
Building on the theoretical motivation about the connection between evidential uncertainty and
entropy minimization in Section 5, we use evidential uncertainty as to the proxy for label quality. The
evidential modeling of molecular property allows us to derive analytical solution of uncertainty, which
could be directly used to weight the pseudo-labels. Formally, we can model the label probabilistically
as it is drawn from (yι, ∙∙∙ ,yi)〜N(μ, σ2), where the mean μ are variance σ2 are unknown. To
estimate them, we pose a prior
μ ~N(γ, σ2v-1),σ2 〜Γ-1(α,β),	(1)
where the parameters θ = (μ, σ) is an instantiation of the posterior p(μ, σ2 ∣γ, v, α, β). The choice of
prior allows the factorization p(μ,σ2) = p(μ)p(σ2) (Jordan, 2009). The posterior then becomes a
NormalInvGamma(γ, v, α, β) where the maximum likelihood estimation of θ can be analytically
found as
E[μ] = γ, E[σ2] =β ι.	(2)
α-1
Here, E[σ2] plays the role of the aleatoric (data) uncertainty. The uncertainty of the model prediction
can also be calculated, i.e. epistemic uncertainty:
Var[μ] = E[σ2]∕v = -β	.	(3)
v(α - 1)
As the MLE is deterministic, the model can output the four prior parameters {γ, v, α, β} directly
where the prediction and uncertainty can be derived from them analytically. The prior is optimized
by evidential loss Levi (Amini et al., 2020):
Levi = -log St (yi； γ, β(1+ V), 2α) + λ∣yi - Y|(2v + α),	(4)
vα
where the first term is to maximize the log-likelihood of the posterior predictive, which is derived as
the Student’s t-distribution. The second term is a regularizer that encourages lower total evidence,
which correlates positively to higher epistemic uncertainty, when the gap between ground truth and
prediction is high (i.e. when model prediction is with high error). Similarly, it encourages lower
uncertainty when the model prediction is errorneous. This encourages the model to generate an
accurate estimate of uncertainty or the degree of errors for the pseudo-labeled data points. The
regularization is controlled by a hyperparameter λ.
Adaptive weighting. The evidential uncertainty detects the low-quality pseudo-labels. The next
step is to remove the noisy effect from the model training. Naive methods often use removal based
on a threshold (Rizve et al., 2021). However, it has two disadvantages: (1) it introduces a new
hyperparameter - the threshold; (2) it removes a portion of unlabeled noisy data, which can contain
useful information. Instead, we propose an adaptive weighting mechanism that adapts the evidential
loss given the inverse epistemic uncertainty. Intuitively, a higher uncertainty data point requires a
lower effect in the loss function because it is more likely that the sample has a low pseudo-label quality,
4
Under review as a conference paper at ICLR 2022
Algorithm 1: PSEUDσ Algorithm.
Input: Labeled data D = {(xι, yι),…,(XN,yN)}, UmableddataU = {xι,…,XNU}
U - {},W — {}	// Initialize with empty unlabeled data
for k ∈ {1,…，K}	// Outer-loop with K episodes
do
T -D∪U
for (Xi, yi) ∈ T
do
θi = (γi, vi, αi, βi) = f (k-1) (Xi)
yi = E[μ] = Yi
ʌ
L = L(yi,yi,θi, Wi)	//
f (k-1) = Update(f (k-1), L)
end
// Join updated pseudo-labels
// Inner-loop with N epochs
// Evidental parameters
// Posterior prediction
Adaptive evidential loss via Eq. 5
// Inner-loop update
f(k) - f (k-1)	// Update teacher model for pseudo-labels
for Xi ∈ U do
θi = (^i,Vi,αi,βi) = f (k)(χi)
y = Yi	// Infer a new set of pseudo-labels
Ui J (xi, y^i)	// Update pseudo-labels
-1
Wi — Var[μ]i = Vi * (c^i — 1)∕βi	// Update adaptive weights
end
end
and we want to redUce its effect on the model. Conversely, if a pseUdo-label has low Uncertainty, the
label qUality is high enoUgh to be Used as a proxy of a gold-label. ThUs, we shoUld assign a higher
score in the loss for it. The Uncertainty is from the teacher model in the previoUs episode and is fixed
throUghoUt the cUrrent episode. ThUs, the adaptive weight for each pseUdo data point i becomes
Wi = Var[μ]-1. The final loss then becomes
L=& X Levi+X ρi∈W⅛ Levi
(5)
where the first term corresponds to the labeled dataset D does not have weights Unlike the second
term corresponding to the Unlabeled data. This adaptive loss solves two disadvantages since it has
zero hyperparameters, and it removes the effect of bad pseUdo-labels while retaining all training
examples inclUding the noisy ones to maximize the diversity of the training space.
5 PSEUDσ MOTIVATION: CONNECTION TO ENTROPY MINIMIZATION
We derive motivation aboUt why evidential Uncertainty and the weighting mechanism coUld be
beneficial to pseUdo-labeling based on the entropy minimization framework for semi-sUpervised
learning from Grandvalet & Bengio (2004; 2006); Lee et al. (2013). Notably, oUr Use of Bayesian
modeling enables Us to analytically derive a conditional entropy for pseUdo-labeled data. We find
that evidential loss strongly relates to conditional entropy, and minimizing evidential loss directly
minimizes entropy. Secondly, we find the conditional entropy coUld be decomposed into the inverse
epistemic Uncertainty and the log-likelihood, which motivates oUr weighting mechanism.
In the standard regression setting, one seeks to maximize the likelihood of the model pθ(Y∣X) on the
labeled data set D. To Utilize the Unlabeled data set, we need to extract some UsefUl information on
how the model behaves on the Unlabeled dataset and inject this information to improve the model.
To measUre the Utility, entropy H (Y | U) is introdUced (Grandvalet & Bengio, 2006) as a proxy to
measUre the amoUnt of information in Unlabeled data:
H(YIU)= E Ey 〜Pθ(y | Xi)[-log Pθ (y | Xi)].
xi∈ U
(6)
ThroUghoUt the text, we are referring to entropy as Shannon entropy. IntUitively, high entropy is
indicative of the poor model confidence on the Unlabeled data point, while the low entropy can
5
Under review as a conference paper at ICLR 2022
be interpreted as high confidence of the model predictions. High entropy, associated with random
predictions, while low entropy is associated with non-random behavior. Hence force, we hypothesize
that small entropy may be indication of a signal that our model can benefit from. Small entropy,
as seen below, corresponds to high model confidence. and vice versa. Large entropy corresponds
to high model uncertainty. Entropy minimization framework casts the regression as the following
optimization problem:
arg max [log pθ (Y|X) - C H(Y|U)],	⑺
θ
where c is the proportionality constant. Intuitively, here, the objective tends to maximize the log-
likelihood on the labeled dataset while minimizing the entropy on the unlabeled data set at the same
time to transfer knowledge from unlabeled data.
In previous works (Schutt et al., 2017; LiU et al., 2021), molecule properties are not modeled
probabilistically such that entropy calculation is infeasible. In contrast, PSEUDσ uses Bayesian
modeling approaches that allow us to analytically calculate the entropy. For every molecule xi the
machine learning model outputs four parameters f(xi) = (αi, βi, γi, νi). Based on these parameters,
the likelihood of label y given the input molecule xi is given by the Student’s t-distribution in the
context of evidential regression
Pθ(y∣Xi) = St(y; Yi,。3, 2αi)	(8)
evaluated at location parameter γi, Student,s t-distribution scale parameter σ^ti = βiV1+"i) and 2ɑi
degrees of freedom. The entropy of the Student’s t-distribution given in terms of evidential parameters
is readily available (Appendix A):
H(y | Xi) = 2αi2+ 1 (ψ(2°i2+ 1) - ψ(0i)) + log √2αiB(αi, 2) + 2log σSt,i,	(9)
2	2	22
where Ψ is a digamma function and B(∙, ∙) isabeta function. If We take model (epistemic uncertainty)
(Eq. 3) as our evidential uncertainty, we can show that minimizing entropy directly relates to
minimizing epistemic uncertainty. We plot the relation between the entropy and epistemic uncertainty
in the Figure 2.
As the next steps, we aim to uncover the dependence of the entropy on the model uncertainty
of our pseudo-labeling approach. This can be done if we make two simplifications in entropy
evaluation. Firstly, to introduce iterations as in pseudo-labeling, we replace entropy with the cross-
entropy between two probability distributions: the predictions y are generated from the probability
distribution pθ(t-1) (y|Xi) at iteration step t - 1 and log-likelihood are evaluated with respect to
probability distribution pθ(t) (y∖xi) at iterative step t:
H(YIU) ≈ E Ey〜Pθ(t-ι)(y∣χi) [- logPθ(t)(y ∖ xi)].
xi∈ U
(10)
Upon convergence, t → +∞, the probability distributions at every iterative step pθ(t-1)(y∖xi) ≈
pθ(t) (y∖xi) and are approximately the same and one can view introduced cross-entropy with respect to
time step t as entropy. At the earlier stages of training cross-entropy acts as a regularizer encouraging
network parameters θ(t) to match θ(t - 1).
As a second approximation, to uncover model uncertainty in mathematical formulas, we approximate
the probability distribution at time step t - 1. We resort to empirical estimate of the entropy, as done
in (Grandvalet & Bengio, 2004). We select labels y at the highest mode of probability distribution
pθ(t-1) (y ∖ xi), which corresponds to y = γit-1. We obtain the following approximate for the
entropy:
H(Y∖U)≈Hemp(Y∖U) = -	Eit-1 log pθ(t)(γit-1∖xi),
(11)
xi∈ U
where the log probabilities are weighted by empirical probabilities as weights Eit-1 evaluated at
iterative step t - 1 when plugged into Eq. 8 (also see Appendix. Eq. 18 for exact formula of Student’s
t-distribution)
Eil= St(y = γi, σSt,i, 2αi) = -/	二 ■
,2 ai σ2t,iB( 2 ,ai)
(12)
6
Under review as a conference paper at ICLR 2022
Figure 2: (a) Dependence of the entropy (Eq. 9) on epistemic uncertainty and virtual observation
parameter α for a fixed aleatoric uncertainty E[σ2] = 1. As the the epistemic uncertainty increases,
the entropy is also increases for all values of parameter α. For example, figure (b) demonstrate the
trend for a fixed α = 2. Figure (c) demonstrates the dependence of empirical weights (Eq. 14) on
epistemic uncertainty. The empirical weights tend to decrease as the epistemic uncertainty increases.
Figure (d) demonstrates this trend for a fixed α = 2.
To establish a relationship between empirical weights Et-1 and aleatoric E[σ2] / epistemic Var[μi]
uncertainties we rewrite
σ2t,i = αi_1 (Var[μi] + E[σ2])	(13)
st,i	αi	i
E t-1 = (Var[〃i] + E[σ2])-1	(14)
√	√2B( 1, αi)√αi - 1
Empirical coefficients depend on aleatoric, epistemic uncertainties and αi parameter, which can
be interpreted as virtual observations in support of the variance estimation (Jordan, 2009). In the
limiting case a》1 one can approximate beta function via Stirling formula B(2,α) ≈ √∏% 2
and empirical weights become
Et-1 ≈ (Var[μi]+ E[σ2])-2.	(15)
We can express the empirical coefficients depend both on aleatoric and epistemic uncertainties in a
symmetric fashion.
We selected adaptive pseudo-labeling coefficients Wi in our pseudo-labeling approach Eq. 5 to be
inverse epistemic/model uncertainties. We can see, that those coefficients directly relate to empirical
coefficients derived from entropy minimization approach Eq. 14, as empirical coefficients also depend
on model uncertainty in the inverse fashion. As the model uncertainty increases, the empirical
coefficients Ei tend to decrease to minimize the entropy.
7
Under review as a conference paper at ICLR 2022
Table 1: Dataset statistics.
Setting	Training Set	Validation Set	Testing Set	Unlabeled Set	OOD Set
Full-data	110,000 (QM9)	10,000 (QM9)	10,831 (QM9)	99,234 (PC9)	-
Low-data-1%	1,100 (QM9)	10,000 (QM9)	10,831 (QM9)	108,900 (QM9)	-
Low-data-10%	11,000 (QM9)	10,000 (QM9)	10,831 (QM9)	99,000 (QM9)	-
Out-of-distribution	110,000 (QM9)	10,000 (QM9)	10,831 (QM9)	99,234 (PC9)	99,234 (PC9)
Table 2: PSEUDσ improves on full data setting. Reported metric is MAE. The lower the better.
Property	Unit	SchNet	PhysNet	Cormorant	MGCN	DimeNet++	SphereNet	PSEUDσ-S	PSEUDσ-D
HOMO	meV	41	32.9	36	42.1	24.6	23.6	32.9	20.4
LUMO	meV	34	24.7	36	57.4	19.5	18.9	24.7	18.2
6	Experiments
6.1	Dataset and Experimental Setups
We evaluate PSEUDσ using QM9 dataset (Wu et al., 2018) under two settings. (A) Full-data: We
follow the previous works (Liu et al., 2021; Klicpera et al., 2020) where a 110,000/10,000/10,831
training/validation/testing set is obtained. For the unlabeled data, we solicit to PC9, a dataset of
99,234 molecules that consists of the same elements as QM9, curated by (Glavatskikh et al., 2019).
(B) Low-data: we set k% of QM9 full training set as the training set (i.e. k × 110,000) and we remove
the label of (1-k%) QM9 full training set and make it as the unlabeled set. We evaluate in two k
values, 1 and 10, which means only 1,100/11,000 data points is trained respectively. Dataset statistics
summary is in Table 1. Note that PC9 has a wider chemical diversity than QM9, demonstrated by
wider distribution of distances of chemical bonds and more functional groups (Glavatskikh et al.,
2019).
PSEUDσ is model-agnostic. We evaluate it with two model backbones SchNet (Schutt et al., 2017)
(PSEUDσ-S) and DimeNet++ (Klicpera et al., 2020) (PSEUDσ-D). We do not experiment with the
SOTA atomistic model SphereNet (Liu et al., 2021) because it is highly computationally expensive.
Our result is conducted on two targets σHOMO , σLUMO , because the PC9 dataset only has these two
targets. We use mean absolute error as the evaluation metric.
For baselines, We compare with 6 state-of-the-art baselines, including SchNet (Schutt et al., 2017),
PhysNet (Unke & Meuwly, 2019), Cormorant (Anderson et al., 2019), MGCN (Lu et al., 2019),
DimeNet++ (Klicpera et al., 2020), and SphereNet (Liu et al., 2021). We report the best results taken
from the original authors’ paper while using the same fraction of data split in the full data setting.
For PSEUDσ, we conduct two hyperparameter tunings on σHOMO with SchNet backbone on the
validation MAE with full data/low-data setting, respectively. The optimal hyperparameter is then
used for both targets. Note that the atomistic model itself has the same hyperparameter as the original
authors. Code will be released upon anonymous review period.
6.2	Results
Overview of results. We report performances of PSEUDσ in full data (Table 2), low-data (Table 3),
out-of-distribution (Table 4) settings and find PSEUDσ achieves the best performance across all
settings, suggesting the robustness of the pseudo-labeling strategy. Systematic ablation study (Table 5)
also show the importance of each module in PSEUDσ .
PSEUDσ improves on fully supervised QM calculations. We report PSEUDσ against 6 state-of-the-
art models in Table 2. PSEUDσ-D surpasses all baselines in both targets σHOMO , σLUMO . Notably,
PSEUDσ-D improves the SOTA by 3.2 meV, a significant margin. Particularly, comparing PSEUDσ-S
with SchNet and PSEUDσ-D with DimeNet++, we find PSEUDσ can consistently improve even on
the fully supervised setting by a large margin (8.1 meV for SchNet and 4.2 meV for DimeNet++),
highlighting the utility of PSEUDσ and the high quality of PC9 as unlabeled data. It also shows that
8
Under review as a conference paper at ICLR 2022
Table 3: PSEUDσ improves on low-data regime. Reported metric is MAE. The lower the better.
Low-Data Setting		1%QM9 (1,100)		10% QM9 (11,000)	
Property	Unit	SchNet → PSEUDσ	DimeNet++ -→ PSEUDσ	SchNet → PSEUDσ	DimeNet++ -→ PSEUDσ
HOMO	meV	265.4 +0→ 276.2	248.9 	18-.→7 230.2	119.0 	30-.→2 88.8	81.1 	13-.→7 67.4
LUMO	meV	290.6 --74 232.8	229.3 ---5-.→2 224.1	93.3 -15→ 78.3	60.8 ---1-.→6 59.2
Table 4: Out-of-distribution best validation MAE.
Property	Unit	SchNet	DimeNet++	PSEUDσ-D
σHOMO	meV	243.4	230.4	214.4
σLUMO	meV	225.0	184.2	175.8
this direction of improving learning strategy instead of improving physics-based representation has
potentials.
PSEUDσ significantly improves on low-data QM calculations. In Table 3, we investigate how
PSEUDσ can improve on the low-data regime with only 1%, 10% training data point. That is to do
QM using only 1,100 and 11,000 known data. This is to simulate the more expensive QM levels such
as CCSD(T)/MP2. We observe PSEUDσ can consistently and significantly improve the prediction in
σHOMO , σLUMO across both low-data settings and both model backbones, suggesting PSEUDσ can
help prediction in realistic low-data quantum calculations. Notably, in σLUMO with 1% of QM9 data,
PSEUDσ improves upon SchNet by 57.8 meV, a considerable margin. We also observe that the gain
margin is much more significant when the number of training data is smaller. This showcases the
utility of PSEUDσ in extremely low-resource settings, such as QM.
PSEUDσ improves out-of-distribution QM calculations. Another realistic challenge is to infer
accurately on unseen data distribution away from QM9. We conduct inference on the PC9 dataset
where it has calculated σHOMO, σLUMO. We also find PSEUDσ can again significantly improve OOD
accuracy over DimeNet++, a SOTA method, with over 16.0 meV improvement on σHOMO and 8.4
meV improvement on σLUMO, highlighting the robustness of PSEUDσ.
Evidential uncertainty highly correlates to label quality.
PSEUDσ utilizes uncertainty as a proxy of label quality because
they are highly correlated for unseen molecules. In this experiment,
we want to validate this hypothesis. We train on the complete QM9
training set with evidential uncertainty and then infer on the QM9
testing set. We find that the non-parametric Spearman correlation
between MAE and epistemic uncertainty is 0.42 with a p-value <
1e-16. Additionally, we evaluate on PC9 out-of-distribution set, and
the Spearman correlation is 0.35 with p-value < 1e-16, suggesting
our uncertainty is a robust measure of label quality.
Ablations. In Table 5, we conduct a systematic ablation study using
SchNet as the backbone architecture on the fully supervised QM9 setting. We show that each
component in PSEUDσ is indispensable for PSEUDσ. In Table 2, we have reported original authors
best performance following standard practices Klicpera et al. (2020); Liu et al. (2021). To further
clearly demonstrate the utility of pseudo-labeling, in -pseudo-label, we keep all hyperparameters the
same but remove the pseudo-labeling part. We show our pseudo-labeling strategy improve by a large
margin. Next, in the -uncertainty ablation, we use a vanilla per-epoch pseudo-labeling strategy with
no uncertainty, corresponding to a vanilla pseudo-labeling strategy. We demonstrate it does not work
for QM as it even deteriorates compared to no pseudo-labeling (-pseudo-label), calling for specialized
strategy design such as ours. Then, to compared with self-training strategy, -student ablation retrains
a model in every episode as in (Xie et al., 2020) and the decreased performance shows that it is not
ideal in QM calculations. Lastly, the -uniform ablation uses the same weight for all pseudo-labels
with no uncertainty reweighting. The decreased performance shows the importance of detection and
Increasing Log-EPistemic Uncertainty
Figure 3: Uncertainty highly
correlates to label quality.
9
Under review as a conference paper at ICLR 2022
Table 5: Ablation using SchNet as backbone on the fully supervised setting.
Property	Unit	PSEUDσ	-pseudo-label	-uncertainty	-student	-uniform
HOMO	meV	32.9	38.9	47.7	41.4	37.2
LUMO	meV	24.7	27.2	32.1	31.4	28.8
adaptive removal of bad pseudo-labels, achieved by our evidential characterization of the molecular
property.
7	Conclusion
We introduce PSEUDσ, a simple, effective, model-agnostic pseudo-labeling strategy that can improve
quantum calculations accuracy in abundant data, low data and out-of-distribution settings. PSEUDσ
learns from vast unlabeled data by assigning uncertainty-aware pseudo-labels. These pseudo-labels
are adaptively selected to be absorbed into the model via an episodic schedule. Unlike eariler methods
in QM that focuses on physics-based representation, we show the potential of data-centric approach.
References
Alexander Amini, Wilko Schwarting, Ava Soleimany, and Daniela Rus. Deep evidential regression.
NeurIPS, 2020.
Brandon Anderson, Truong-Son Hy, and Risi Kondor. Cormorant: Covariant molecular neural
networks. NeurIPS, 2019.
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in
neural network. In ICML ,pp.1613-1622. PMLR, 2015.
Marta Glavatskikh, Jules Leguy, Gilles Hunault, Thomas Cauchy, and Benoit Da Mota. Dataset’s
chemical diversity limits the generalizability of machine learning predictions. Journal of Chemin-
formatics, 11(1):1-15, 2019.
Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. NeurIPS,
2004.
Yves Grandvalet and Yoshua Bengio. Entropy regularization. Semi-Supervised Learning, pages
151-168, 2006.
Yosuke Higuchi, Niko Moritz, Jonathan Le Roux, and Takaaki Hori. Momentum pseudo-labeling for
semi-supervised speech recognition. INTERSPEECH, 2021.
Ahmet Iscen, Giorgos Tolias, Yannis Avrithis, and Ondrej Chum. Label propagation for deep
semi-supervised learning. In CVPR, pp. 5070-5079, 2019.
Michael I Jordan. The exponential family: Conjugate priors. 2009.
Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer
vision? NeurIPS, 2017.
Johannes Klicpera, Janek Groβ, and Stephan Gunnemann. Directional message passing for molecular
graphs. ICLR, 2020.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive
uncertainty estimation using deep ensembles. NeurIPS, 2017.
Dong-Hyun Lee et al. Pseudo-label: The simple and efficient semi-supervised learning method for
deep neural networks. In Workshop on challenges in representation learning, ICML, volume 3, pp.
896, 2013.
10
Under review as a conference paper at ICLR 2022
Tatiana Likhomanenko, Qiantong Xu, Jacob Kahn, Gabriel Synnaeve, and Ronan Collobert. slimipl:
Language-model-free iterative pseudo-labeling. INTERSPEECH, 2021.
Yi Liu, Limei Wang, Meng Liu, Xuan Zhang, Bora Oztekin, and Shuiwang Ji. Spherical message
passing for 3d graph networks. arXiv:2102.05013, 2021.
Chengqiang Lu, Qi Liu, Chao Wang, Zhenya Huang, Peize Lin, and Lixin He. Molecular property
prediction: A multilevel quantum interactions modeling perspective. In AAAI, volume 33, pp.
1052-1060, 2019.
Zhuoran Qiao, Anders S Christensen, Frederick R Manby, Matthew Welborn, Anima Anandkumar,
and Thomas F Miller III. Unite: Unitary n-body tensor equivariant network with applications to
quantum chemistry. arXiv:2105.14655, 2021.
Mamshad Nayeem Rizve, Kevin Duarte, Yogesh S Rawat, and Mubarak Shah. In defense of pseudo-
labeling: An uncertainty-aware pseudo-label selection framework for semi-supervised learning.
ICLR, 2021.
KristofT Schutt, Pieter-Jan Kindermans, Huziel E Sauceda, Stefan Chmiela, Alexandre Tkatchenko,
and Klaus-Robert Muller. Schnet: A continuous-filter convolutional neural network for modeling
quantum interactions. NeurIPS, 2017.
Weiwei Shi, Yihong Gong, Chris Ding, Zhiheng MaXiaoyu Tao, and Nanning Zheng. Transductive
semi-supervised deep learning using min-max features. In ECCV, pp. 299-315, 2018.
Ava P Soleimany, Alexander Amini, Samuel Goldman, Daniela Rus, Sangeeta N Bhatia, and Con-
nor W Coley. Evidential deep learning for guided molecular property prediction and discovery.
ACS Central Science, 2021.
Oliver T Unke and Markus Meuwly. Physnet: a neural network for predicting energies, forces, dipole
moments, and partial charges. Journal of Chemical Theory and Computation, 15(6):3678-3693,
2019.
O. Anatole von Lilienfeld and Kieron Burke. Retrospective on a decade of machine learn-
ing for chemical discovery. Nature Communications, 11(1):4895, dec 2020. ISSN
2041-1723. doi: 10.1038/s41467-020-18556-9. URL https://www.nature.
com/articles/s41467-020-18556-9http://www.nature.com/articles/
s41467-020-18556-9.
John D Watts, Jurgen Gauss, and Rodney J Bartlett. Open-shell analytical energy gradients for triple
excitation many-body, coupled-cluster methods: Mbpt (4), ccsd+ t (ccsd), ccsd (t), and qcisd (t).
Chemical physics letters, 200(1-2):1-7, 1992.
Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S
Pappu, Karl Leswing, and Vijay Pande. Moleculenet: a benchmark for molecular machine learning.
Chemical Science, 9(2):513-530, 2018.
Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le. Self-training with noisy student
improves imagenet classification. In CVPR, pp. 10687-10698, 2020.
11
Under review as a conference paper at ICLR 2022
A Entropy of Student’s t-distribution
While the entropy of the Student’s t-distribution is well known, we derive it for completeness.
Student’s probability distribution defined in terms of location γ, scale factor σs2t and νst degrees of
freedom is
p(y; γ, σs2t, νst) = St(y; γ, σs2t, νst)
Γ( νst2+1 )
P νstπσSt r(Vi)
st
(ι + Vb T 广
(16)
where Γ i a gamma function. Student’s t-distribution can be written in terms of beta function
B =*)') if We take advantage of the fact that Γ(1) = √π
Γ(x+y)	2
p(y; σ2t,Vst) = St(y; σst, Vst)
1
pνstσt b( ι, W)
1+
1 (y — γ)2
~J2.
Vst	σs2t
(17)
In the main text of the manuscript, We used empirical estimate of Student’s t-distribution, Which
corresponds to evaluation at the highest mode y = γ. Empirical estimation of probability becomes:
pemp (y = γ; σst, Vst) ≈ St(y = γ; σst, Vst)
1
PVSt σ2tB( 1, Vst)
(18)
If we introduce a new Variable t = y-tγ, StUdent’s t-distribution COnVerts into the Standard form With
probability density
/	Q - - Vst + 1
,	、1	( t2 ∖	2
p(t; VSt) =	St(t; VSt)	= √Vt B( 1, Vf)	(1	+ Vt)
(19)
A.1 Proposition
Proposition: Entropy of the generalized and standard StUdent’s t-distribUtions are related Via the
formUla
H(y; σ2t,Vst) = H(t; VSt) + 2logσ2t.	(20)
Proof: The transformation t = g(y) = y-γ is bijective and invertible with the inverse transformation
y = g-1(t) = σst t + γ. The Jacobin of the transformation g is dy g(y)=六.According to the
change of variables probability density formUla
Py (y; σ2t, VSt) = Pt (g(y); VSt) | ddy g(y) |.	(21)
The eqUation for the entropy transformation (eqUation 20) follows directly from the definition of the
entropy.
To find the generalized entropy, we jUst need to calcUlate the entropy of the standard StUdent’s
t-distribUtion
H(t; VSt) =-Z	P(t; VSt) log P(t; VSt) dt
-∞
log
B(2,昼)) /	p(t; VSt) dt +
VSt； 1 Z log(1 + — )p(t; VSt) dt = log
2	-∞	VSt
VSt + 1 ∕∙+∞1	,1 ɪ t2 . a 、小
—2—J	log(1 + Vst )p(t; VSt) dt.
B(
+
(22)
(23)
(24)
(25)
12
Under review as a conference paper at ICLR 2022
To find the second integral, We make a substitution X = Vt- and obtain
+ 1 ∕+∞ ,	, 1 t2、 ,	、，	Vst + 1	f+∞、	,1	、-νst+1 dx
-J∞	log(1 +	Vst)p(t;	Vst)dt=2BPfj /	log(1+X)(I+X)--√x	=
(26)
Vst + 1 ɪ	/+∞(1 +	χ)-νst+1	dx	= - Vst + 1 工	广
B(1, νSt) dVst	Jo	√x B(2, νst) dVst	Jo
χV2^-1 (1 — x) 2-1 dx =
(27)

Vst + 1	∂	1 Vst	∂	1 Vst
B(⅛ IdJsB(2, F) = -(Vst + 1) ∂V∑IogB(2, Z)
-(Vst + 1) ∂V7 (logΓ与)-logΓ(v⅛⅛)= " (ψ(")-
(28)
Ψ(Vt)), (29)
where digamma function is defined as Ψ(x) = rΓ(Xχ). Putting all the terms together, the entropy of
the standard Student’s t-distribution becomes
H(t； Vst) = "1 (ψ("1) - Ψ( Vt)) + log ( ■ B(∣, Vt)) .	(30)
The final formula for the entropy of the labels y is given by
H(y; σ2t, Vst) = "st： i (w("st： I) - ψ(V2t)) + log ( √sb(2, V2t)) + 2 log σ2t. (31)
B Pseudo-labeling, Entropy minimization and Aleatoric
UNCERTAINTY
In the main section of the text, we have considered the case where observed targets (yι,…，yi)〜
N(μ, σ2) are drawn from the Normal distribution with unknown mean and variance μ and σ2 and
we have imposed a prior on them. The problem is significantly simplified if we treat μ and σ2 in a
deterministic way, such that our model f outputs two parameters μ and σ2. The model here is able
to estimate aleatoric (data) uncertainty σ2 but unable to model epistemic (model) uncertainty. By
minimizing negative log-likelihood, the loss is significantly simpler than in Eq. 4.
Li = -logN(yi； μi,σ2) = -2-l + (yi./i) .	(32)
Empirical estimate of the entropy on the unlabeled data set becomes
H(Y|U)= X
Ey~pe (y | Xi) [-log pθ (y | xi)] ≈ - X Eiemp [log pθ (y |xi)]	(33)
xi ∈ U	xi ∈ U
with log probability weights Eemp =	, One can notice that the weights are inversely related to
i	2πσi2
aleatoric uncertainties Ei 〜(σ2)- 2.
13