Under review as a conference paper at ICLR 2022
Understanding Metric Learning on Unit Hy-
persphere and Generating Better Examples
for Adversarial Training
Anonymous authors
Paper under double-blind review
Ab stract
Recent works have shown that the adversarial examples can improve the perfor-
mance of representation learning tasks. In this paper, we boost the performance
of deep metric learning (DML) models with adversarial examples generated by
attacking two new objective functions: intra-class alignment and hyperspherical
uniformity. These two new objectives are motivated by our theoretical and em-
pirical analysis of the tuple-based metric losses on the hyperspherical embedding
space. Our analytical results reveal that a) the metric losses on positive sam-
ple pairs are related to intra-class alignment; b) the metric losses on negative
sample pairs serve as uniformity regularization on hypersphere. Based on our
new understanding on the DML models, we propose Adversarial Deep Metric
Learning model with adversarial samples generated by Alignment or Uniformity
objective (ADML+A or U). With the same network structure and training set-
tings, our ADML+A and ADML+U consistently outperform the state-of-the-art
vanilla DML models and the baseline model, adversarial DML model with attack-
ing triplet objective function, on four metric learning benchmark datasets.
1	Introduction
Deep metric learning (DML) has been applied to various computer vision tasks ranging from face
recognition (Schroff et al., 2015; Liu et al., 2017) to zero-shot learning (Romera-Paredes & Torr,
2015; Bucher et al., 2016) and image retrieval (Song et al., 2016; Wu et al., 2017). It has been
proved to be one of the most effective methods for learning the distance-preserving features of
images. The intuition of DML is to pull the embedding of positive images pairs together and push
the negative pairs apart, where the embedding function could be a deep neural network. Most of the
metric losses in DML are tuple-based (Schroff et al., 2015; Song et al., 2016; Wu et al., 2017; Wang
et al., 2019) or classification-based (Movshovitz-Attias et al., 2017; Kim et al., 2020; Boudiaf et al.,
2020), these different losses have been shown to achieve similar performance in the recent reviews
of DML (Roth et al., 2020; Musgrave et al., 2020).
One common ground of existing DML models is that the embedding space is a unit hypersphere. It
is widely known that achieving uniformity on hypersphere can increase the generalization of models
and preserve as much information as possible (Bachman et al., 2019; Liu et al., 2018; 2021; Hjelm
et al., 2018), and the objective function that lead to uniformity is called uniformity regularization.
Meanwhile, the downstream tasks in DML favor the models with small intra-class alignment (Wu
et al., 2017; Wang et al., 2019). In this work, we investigate these two properties, intra-class align-
ment and hyperspherical uniformity (Wang & Isola, 2020) for tuple-based metric losses. We derive
the theoretical analysis for the triplet loss to prove that the triplet loss on the positive sample pairs
minimizes the intra-class alignment by mapping all samples from one class to the same vector, while
the triplet loss on the negative sample pairs achieves hyperspherical uniformity. We further conduct
empirical studies to show that the same statement is also valid for other tuple-based metric losses.
We utilize our new understanding on DML to design novel robust DML methods to enhance the
performance via improved adversarial training. Adversarial training aims at improving the robust-
ness of models towards to certain types of attacks by training with perturbed samples. However,
as shown in the recent work on contrastive representation learning (Jiang et al., 2020), adversarial
training can also enhance the natural performance on the downstream classification task. Due to
1
Under review as a conference paper at ICLR 2022
the similarity between contrastive learning and deep metric learning, we believe it’s also possible
to improve the nature performance of metric learning models with adversarial samples. Following
our new insights on positive and negative metric losses, we generate perturbations by attacking the
alignment or uniformity objective, and create adversarial DML models augmented with both nor-
mal samples and perturbed samples. Our experimental results show that the new adversarial DML
models can significantly boost the natural performance.
The major contributions of our paper can be summarized as follows:
•	We analyze the intra-class alignment and hyperspherical uniformity for tuple-based metric
losses, and establish the connections between these two properties and the positive/negative
metric losses.
•	Based on our new analysis and understanding, we propose two new adversarial DML models,
ADML+A and ADML+U, via attacking the alignment or uniformity objective. ADML+A and
ADML+U improve the natural performance on benchmarks significantly.
2	Related works
Deep metric learning. There are mainly two kind of metric losses in DML, tuple-based and classi-
fication based losses. Tuple-based losses include contrastive loss (Hadsell et al., 2006), triplet loss
(Schroff et al., 2015), margin loss (Wu et al., 2017), and multi-similarity loss (Wang et al., 2019),
where the objective function is based on the distance between positive pairs and negative pairs. In
classification-based losses, the learning objective is not depend on the positive or negative pairs but
a fixed (Boudiaf et al., 2020) or learnable proxy (Kim et al., 2020). In the recent reviews of metric
learning methods (Roth et al., 2020; Musgrave et al., 2020), it’s concluded the improvement on the
DML performance is mainly due to different training strategies and unfair comparison. The original
contrastive loss and triplet loss still achieved comparable result with other metric losses under the
same network and training strategies. In experiments we apply the training framework of (Roth
et al., 2020) to ensure fair comparison.
Learning with hyperspherical uniformity. Hyperspherical learning regards learning tasks where
the embedding space is a unit hypersphere. The uniformity of the hypersphere represents the diver-
sity of vectors on the sphere. It encourages vectors to be spaced with angles as large as possible so
that these vectors can be evenly distributed on the hypersphere (Liu et al., 2018). Achieving hyper-
spherical uniformity can help with preventing overfitting and improving generalization of the neural
works (Liu et al., 2021). The objective functions which can lead to the uniformity on hypersphere
are called uniformity regularization. Hyperspherical embedding is widely applied in representation
learning tasks such as contrastive representation learning (Oord et al., 2018; Hjelm et al., 2018) and
DML (Wu et al., 2017; Liu et al., 2017). Wang & Isola (2020) showed that the objective function in
contrastive representation learning optimizes for intra-class alignment and uniformity together.
Adversarial examples improves natural performance. In classification tasks, itis well known that
the clean accuracy of adversarially trained model is typically worse than the normal model. How-
ever, Xie et al. (2020) showed that adversarial samples can be used to improve the clean accuracy of
image classification models. According to (Jiang et al., 2020), training with adversarial samples can
help improve the natural performance of contrastive learning models on the downstream classifica-
tion tasks. The authors presented adversarial attacks based on the objective of contrastive learning
and achieved improvement on both natural and robustness performance. It’s believed that adversar-
ial examples contain extra features, thus the generalization of models augmented with adversarial
example is increased (Ilyas et al., 2019; Salman et al., 2020; Xie et al., 2020), which contributes to
better natural performance. Duan et al. (2018) utilized the triplet loss as the attacking objective to
generate adversarial examples to improve DML models. To our best knowledge, this is the only one
work using adversarial example to boost the natural performance of DML. In our work, we show
that alignment and uniformity loss can generate stronger adversarial examples comparing to triplet
loss, and thus lead to better generalization of DML models.
3	Alignment and hyperspherical uniformity in tuple-based
METRIC LOSSES
In this section, we will study tuple-based metric losses on the unit hypersphere embedding space.
We assume having n classes Xi,…，Xn in training set and denote the encoder by f : Rd → Sk-1
2
Under review as a conference paper at ICLR 2022
where Sk-1 is the surface of a k-dimensional unit ball. Let Pdata(∙) be the data distribution over
Rd, Ppos (∙, ∙) be the distribution of positive pairs over Rd X Rd, and Ptri (∙, ∙, ∙) be the distribution of
triplet pairs over Rd × Rd × Rd, where the first two entries have the same label and the third entry
is a sample from different classes. Please note that all detailed proofs are included in supplementary
material Appendix E. We also conduct experiments to validate our theoretical analysis, the details
is in Appendix C.
The major intuition of DML is to pull the representations of similar samples together and push
dissimilar samples apart. Thus, we reformulate the metric losses as the combination of two parts:
•	Positive metric loss: minimizes the distance between embedded positive sample pairs.
•	Negative metric loss: maximizes the distance between embedded negative sample pairs.
Although in DML models the positive metric losses have different representations, they share one
common optimal solution pattern, where samples from the same class are mapped to the same feature
vector. Thus, we define the alignment loss with minimizing the intra-class distance.
Definition 1. (Intra-class alignment) The expectation of intra-class distance is given by:
Lalignment(f; X,ppos) := E(x,y)~pp°s |||f (X)- f (y) ||2]	⑴
the minimum of this loss is achieved when the samples with the same label are encoded to the same
embedding.
Proposition 1. If the support set of the data distribution is connected and the support set of each
class distribution is closed, the minimum of Lalignment is reached when all samples are projected
to the same vector.
In Sec. C.1, we conduct the empirical studies to verify our analysis. Results in Table 8 show that
samples are roughly projected to the same vector if only the positive metric losses are used.
The negative metric losses aim at positioning the embedding of dissimilar samples as far as possible.
However, because the embedding space of DML is a unit hypersphere, where the maximum distance
between two points is 2, it,s not possible to separate all negative embeddings with a large margin.
Actually on Sk-1, the number of points with pairwise distance larger or equal than √2 is at most
2k and the embedding dimension k is always much smaller than the number of feature vectors, thus
it,s impossible to make all distances between negative pairs exceed √2. Therefore investigating the
properties of negative metric losses on the unit hypersphere is an interesting and important topic.
We believe the negative metric losses are closely related to the uniformity on the hypersphere and
our experimental results support this argument.
Definition 2. (Hyperspherical uniformity) The embedded samples should be evenly distributed on
the spherical surface.
In practice, the hyperspherical uniformity can be achieved by optimizing the uniformity regulariza-
tion. There exist many different representations of the regularization, and we utilize the hyperspher-
ical energy (HE) (Liu et al., 2018):
EX~Pdata,y~Pdata[IIf(X)- f (y)||2 '1X = y], s > 0
Ex~pdata ,y2pdata[log(IIf(X) -f(y)II2-11x6=y)],s = 0	(2)
and Gaussian hyperspherical energy (G-HE) (Wang & Isola, 2020):
EG(S,X ) =lθg Eχ~Pdata,y~Pdata[e-Sf(X)-"y)l12 ],S> 0	⑶
E(s, X) =
in the experiments for comparison. The values of HE and G-HE can also be used as measurements
on the uniformity of the embedded samples. We expect the value to be small in order to achieve good
hyperspherical uniformity. We also want to mention that simply maximizing the distance between
samples will not lead to hyperspherical uniformity, and the detailed discussion is in Sec. B.2.
Because finding the optimal solution of the HE or G-HE problem is NP-hard (Liu et al., 2018), we
are not able to calculate the exact position of vectors which are evenly distributed on the sphere. We
provide a primary insight about how should finite vectors be uniformly distributed on unit hyper-
sphere, and our conclusion is consist with the empirical results.
3
Under review as a conference paper at ICLR 2022
Since there exist many different tuple-based metric losses, analyzing all of them theoretically is
impossible in this work. In Sec. 3.1, we will provide the theoretical analysis of the triplet loss. The
analysis of linear loss can be found in Sec. B.2. In Appendix C we will show the empirical results
on four popularly used tuple-based metric losses to verify our statement.
3.1	Triplet metric losses
In this subsection, we provide our theoretical analysis on the triplet metric losses with the following
assumptions.
Assumption. Distributions pdata, ppos , ptri should satisfy:
•	Random positive sampling: ∀x,y,ppos(x,y) = Pdata(X)Pdata(y∣Xχ), wherePdata(∙∣Xχ) is the
conditional Pdf of Pdata on the set of samples Xx similar to X i.e. Pdata(∙∣Xx) = PpdataX)).
•	Random negative sampling: Ptri(x, y, x-) = Ppos(x, y)Pd-ata(x-), where Pd-ata(x-) =
______Pdata(X )___
RX- Pdata(X )dx
•	Class-balanced learning: Pdata(Xi) = 1, then Jx- Pdata(X-)dx- = n-1
P0tri =
where X- is a negative sample w.r.t. X and n is the number of classes.
Definition 3. (Triplet loss)
Ltriplet(f,τ) := E(x,y,x-)〜ptri [(||f(X)- f(y*2 - ||f(X)- f(x-)||2 + T) + ]	⑷
Triplet loss can be rewritten into the form of naive linear loss with a different distribution of triplets.
We consider a new distribution:
0, when ||f (X) - f (y)||22 - ||f (X) - f (X-)||22 +τ < 0,
C Ptri ,	else,
where C = 1/E(x,y,x-)〜Ptri[1{∣f(x)-f(y)ll2-∣f(x)-f(x-)ll2+τ≥0}],then
Ltriplet(f, T) = Llinear (f ； X,P%i) = E(x,y,x-)〜ptri [||f (x) - f (y)ll2 — ||f (x) — f (X-)II2]∙
Apparently the positive part of the triplet loss is minimizing the intra-class distance under a new
distribution P0tri , which has similar effect as the alignment loss with Ptri shown in the experiments
(Table 8). Now we focus on the negative part of the triplet loss.
Theorem 1. Denote the probability density function (pdf) of d2(X, y) := ||f (X) - f (y)||22 w.r.t.
y 〜Pdata(∙∣Xx) by q(d2(X,y)). Then the pdf of U =||f (X)- f (y)||2 — ||f (x) — f (X0)∣∣2 + T with
fixed X,	X0 is q(u	- T +	d2 (X, X0)),	let S(X, X0)	=	0∞	q(u	- T + d2(X, X0))du ∈	[0,	1], then
-E(x,y,x-)〜PtJIf(X) — f (X-)II2] = - n-1 Ex 〜pdata,x0 〜PdataUIf(X) — f (#)1125(23)]
+n-1 E(x,xo)〜Ppos[||f (X)-f (X0)||2S(X, X0)]
The negative triplet loss consists of two parts, where the first part dominants the second part be-
cause n is always large in practice. The first part is actually a weighted unbiased regularization with
weight S(X, X0). We think S(X, X0) may help the unbiased regularization to achieve hyperspher-
ical uniformity. Because the closed form of q(d2 (X, y)) is intractable, it’s impossible to analyze
S(X, X0) theoretically without any assumptions. We assume q(d2(X, y)) is exponentially distributed
and show the gradient flow of negative triplet loss is asymptotically equal to the gradient of Gaus-
sian hyperspherical energy. Therefore in this case the negative triplet loss can lead to hyperspherical
uniformity.
Proposition 2. Assume q(d2(X, y)) = -1 e-Ad2(x,y), S(x,x0 ) = A1 e-A(d2(x,x )-τ) and for the
network parameter θ, we have
e-τn	1
一▽&E(x,y,x-)〜Ptri|||f(X) — f(x )ll2] = A2(n - ι)VθEG(A,X) + O(n)
the negative triplet loss has asymptotically the same gradient as Gaussian hyperspherical energy.
4
Under review as a conference paper at ICLR 2022
Despite the theoretical analysis, we also empirically show that the negative triplet loss achieves
hyperspherical uniformity without any assumption on S(x, x0). Besides, the negative part of other
metric losses are also shown to achieve hyperspherical uniformity in our empirical study. The details
is shown in Appendix C.
In summary, the tuple-based metric losses on the unit hypersphere are closely related to intra-class
alignment and hyperspherical uniformity. The positive metric losses target at minimizing the intra-
class alignment and the negative metric losses try to keep all samples distributed uniformly on the
hypersphere.
Connection to adversarial examples and adversarial training. The goal of adversarial examples
is to fool the neural network by reducing the model performance. Attacking alignment loss, which
positions the embedding of similar samples apart, or attacking the uniformity loss, which pulls
dissimilar samples together, can definitely destroy the representation learned by DML models. Thus
alignment and uniformity loss are suitable objectives for generating adversarial examples.
4	Designing New Adversarial DML models Based on Better
Understanding of DML Loss
In this section, we introduce our new adversarial DML models: adversarial DML with alignment or
uniformity objective (ADML+A or ADML+U). Before we introduce the details of our models, we
share our motivation for designing ADML+A/U models by answering the following questions:
How can adversarial training helps improve DML models? One of the most reasonable explana-
tions is that training with adversarial examples brings additional features to neural networks. For
example, compared with clean images, adversarial examples make network representations more
consistent with salient data features and human perception (Tsipras et al., 2018). Another possible
reason is that adversarial examples can be regarded as a data augmentation method, which prevents
overfitting of the neural networks. Augmentation techniques which are similar to adversarial train-
ing, e.g. using masking out (DeVries & Taylor, 2017) or adding Gaussian noise (Lopes et al., 2019)
to regions in images, can help to achieve better performance on image recognizing tasks.
Why do we need new objectives for adversarial DML models? Based on our analysis in Sec. 3,
the DML embedding of each image is depend on all other positive and negative samples from per-
spective of alignment and uniformity objective. Therefore if we want to generate the adversarial
sample x0 for one image x, we need to push the adversarial sample away from the similar samples
of x (maximize the alignment loss w.r.t. x0), or pull the adversarial sample close to the dissimilar
samples of x (maximize the uniformity loss w.r.t. x0). Currently, the existing adversarial DML
models (Duan et al., 2018; Panum et al., 2021) generate adversarial samples by attacking the triplet
loss (Definition 3). In this case, only one positive and one negative samples are used to generat-
ing adversarial sample x0 , which is obviously less powerful than the alignment/uniformity objective
(which utilizes more positive or negative samples). Our experimental results in Table 1 also show
the adversarial examples generated by alignment/uniformity objectives is more powerful than the
triplet objective. Thus it is critical to design new objectives for attacking DML models, which can
take advantage of the representation information from more data samples.
Adversarial training. We first recall the standard tuple-based DML training setting. Denote the
metric loss function by L(∙; θ), where θ is the model parameters, our learning objective is:
min E(x,x+ ,x-)〜P [L((x, χ+ , x )； θ)]
In the regular adversarial training framework (Madry et al., 2017), we train networks with perturbed
samples from distribution p(adv)
minE(x,x+,χ-)〜p(adv) [L((x,x+ ,x-); θ)
As our goal is to improve the DML performance on clean images by leveraging the regularization
power of adversarial examples, we treat adversarial images as additional data augmentations and
train networks with a mixture of adversarial examples and clean images. Our learning objective is
min(E(X,x+,x-)〜P [L((x, x+ , x )； θ)] + λE(x,X+,X-)〜p(adv) [L((X, x+, X ); θ)])	(5)
where λ is the strength of the adversarial training.
5
Under review as a conference paper at ICLR 2022
Table 1: Performance of DML model evaluated on adversarial samples generated by different objec-
tives. The threatened model is a pretrained Triplet-D model. Adversarial samples are generated from
triplet, alignment or uniformity loss. Lower score indicates better quality of adversarial samples.
CUB200-2011	CARS196	Online-ProdUcts
Attack objective	R@1	NMI	mAP@C	R@1	NMI	mAP@C	R@1	NMI	mAP@C
No attack	62.40	67.21	23.56	77.59	66.64	23.83	77.53	89.98	41.12
Triplet	28.33	44.48	6.61	22.42	34.30	3.47	53.77	83.43	25.21
Alignment	8.71	23.42	0.46	10.99	17.11	0.55	8.82	80.05	1.49
Uniformity	13.47	32.87	3.54	14.30	24.07	2.05	4.68	79.90	0.51
Generate adversarial samples. We use l∞ PGD-FSGM (Madry et al., 2017) method for generating
adversarial samples. We consider DML models require class-balanced batches for training, and
propose to generate perturbations by maximizing the intra-batch alignment or uniformity. Given
a batch S and a sample x, the l∞ FSGM adversarial sample of x generated by maximizing the
alignment objective is given by,
ADV(X) : = πB∞(x,e) (X + αVxLalignment(f; S))	(6)
where ΠB∞(x,) is the projecting function on the l∞ ball centering at X with radius , and α is
the attack strength. Analogously, the adversarial sample generated by maximizing the uniformity
objective (Eq. 2 and Eq. 3) is
ADV(X) : = πB∞(x,e) (X + α-NXLuniformity (f; S))	⑺
In PGD-FSGM method, we will update the adversarial samples iterative by X(l+1) = ADV (X(l)) for
L steps. The output perturbed samples X(L) will be used in our adversarial training objective Eq. 5.
In ADML-A we use alignment loss (Eq. 1) to generate adversarial samples and in ADML-U we use
Gaussian uniformity loss G-HE (Eq. 3). We include the algorithm of ADML-A and ADML-U in the
appendix (Alg. 1 and Alg. 2). In experiments, we apply multi-similarity losses as the metric loss L
with attacking alignment and uniformity objective, both models achieve significantly better results
on benchmarks (Table 2 and Table 3).
5	Experiments
In our experiments, we first conduct the empirical studies to verify the theoretical analysis results in
Sec. 3 (the results are discussed in Appendix C). After that, we show that alignment and uniformity
objectives can help to generate better adversarial examples than the triplet loss, then we compare
the natural and robust performance of our adversarial DML model with the state-of-the-art methods.
The natural performance is the performance of DML models evaluated with clean samples, while
the robust performance is evaluated with adversarial samples.
5.1	Experimental setup
Datasets. We test our model on four DML benchmarks, CUB200-2011 (Wah et al., 2011),
CARS196 (Krause et al., 2013), Online-product (Song et al., 2016), and In-shop (Liu et al., 2016).
We follow the previous work (Song et al., 2016) and (Liu et al., 2016) for the train-test split. The
statistics of these datasets is introduced in Sec. D.2
Training Frameworks. In all experiments, we use the DML framework from (Roth et al., 2020) for
training. This framework enables us to train and evaluate DML models under the same settings and
ensure fair comparison of the model performance. The backbone network is ResNet50 (He et al.,
2016) with ImageNet pretrained (Krizhevsky et al., 2012) and frozen Batch-Normalization layers,
the embedding dimension of samples is 128. The initial learning rate is 0.00001 with no scheduling
and the batch size is 112. Experiments are performed on a 24GB Nvidia Tesla P40.
Baseline models. We compare ADML+A/U with the state-of-the-art DML models. First we select
three of the best DML models according to (Roth et al., 2020): margin loss with distance sampling
(Wu et al., 2017), multisimilarity loss (Wang et al., 2019) and triplet loss with distance sampling.
Besides, we take another two SOTA DML models which were published recently but not included
6
Under review as a conference paper at ICLR 2022
Table 2: Performance of metric learning models on clustering and retrieval tasks averaged over 5
runs on CUB200-2011 and CARS196. Our Adversarial DML models, ADML+A, and ADML+U,
outperform the rest models. The model settings and training parameters are same for all models.
	CUB200-2011			CARS196		
Models	R@1	NMI	mAP@C	R@1	NMI	mAP@C
ImageNet pretrain	43.77	57.56	8.99	36.39	37.96	4.93
Linear	38.42	43.28	7.64	32.45	35.12	3.48
Triplet-D	62.31 ± 0.41	67.23 ± 0.34	23.29 ± 0.25-	79.08 ± 0.41	66.02 ± 0.33	24.02 ± 0.31
Margin	62.42 ± 0.36	67.11 ± 0.49	23.54 ± 0.21	78.11 ± 0.32	66.87 ± 0.35	23.94 ± 0.27
Multi-Similarity	62.73 ± 0.61	67.45 ± 0.39	22.65 ± 0.34	79.94 ± 0.28	67.59 ± 0.43	24.12 ± 0.25
Proxy-Anchor	64.16 ± 0.48	67.84 ± 0.37	23.91 ± 0.32	80.13 ± 0.33	67.31 ± 0.41	23.86 ± 0.26
Cross-Entropy	61.58 ± 0.31	66.67 ± 0.39	22.25 ± 0.20	78.41 ± 0.39	66.35 ± 0.31	23.63 ± 0.34
Info-NCE	61.79 ± 0.51	66.91 ± 0.42	22.43 ± 0.28	77.52 ± 0.37	66.75 ± 0.57	23.41 ± 0.22
ADML+T	64.37 ± 0.43	68.13 ± 0.49	24.05 ± 0.30	80.88 ± 0.46	66.47 ± 0.51	23.91 ± 0.39
ADML+A	66.02 ± 0.35	68.78 ± 0.37	24.46 ± 0.23-	81.95 ± 0.38	67.97 ± 0.49	24.21 ± 0.28
ADML+U	65.46 ± 0.40	68.60 ± 0.33	24.58 ± 0.28	82.06 ± 0.36	68.21 ± 0.35	24.82 ± 0.34
ADML+A+U	64.24 ± 0.38	67.73 ± 0.45	23.88 ± 0.26	80.95 ± 0.41	67.64 ± 0.39	23.85 ± 0.30
in Roth et al. (2020)’s work: Proxy-Anchor loss (Kim et al., 2020) and Cross-Entropy loss (Boudiaf
et al., 2020). Next we apply the Info-NCE loss (Wang & Isola, 2020), which is a contrastive learning
objective, as one of the baselines. Finally we compare our models with the only existing adversarial
DML model (Duan et al., 2018), ADML+T (triplet objective), in the experiments.
Evaluation Metrics. We measure the performance of DML and ADML models with Recall@k
(R@k) (Jegou et al., 2010), Normalized Mutual Information (NMI) (Christopher et al., 2008) and
Mean Average Precision measured on recall (mAP@k) (Musgrave et al., 2020). The details of these
metrics are introduced in Sec. D.3.
5.2	Compare the quality of adversarial examples with different objectives
Settings. The threatened model is a pretrained DML model with triplet loss and distance sampling
(Wu et al., 2017), which is one of the most competitive DML models according to Roth et al.
(2020). We consider three different attack objectives, triplet loss (Eq. 4), alignment loss (Eq. 1), and
Gaussian hyperspherical uniformity (Eq. 3), for generating adversarial samples. We use l∞ PGD-
FSGM attacks with strength = 0.0314, L = 7 steps and step size α = 0.007, we keep this settings
for all three attack objectives in our experiments.
Results. In Table 1, the adversarial samples generated by alignment or uniformity objectives are
significantly stronger than the samples generated by triplet loss. This indicates that adversarial sam-
ples from alignment or uniformity contain more features that are not captured by the vanilla DML
models. Thus we believe the Adversarial DML model with alignment or uniformity objectives could
be more generalized than the vanilla DML models or ADML with triplet loss. Our experimental re-
sults in Table 2 and Table 3, which show that ADML+A and ADML+U outperform the baseline
models on metric learning tasks, also support our analysis. We also notice that using both A and U
in ADML have similar performance as ADML+T, which suggests we should use the attack objective
(A or U) separately. In Appendix F we also shows the T-SNE plot of the embedding generated by
the vanilla DML and ADML+A, which shows ADML+A can better separate different classes.
5.3	Adversarial DML models improve natural performance
Settings. We train all DML models for 100 epochs. For our adversarial DML models we apply
ADML+A and ADML+U. The adversarial training strength λ in ADML+A/U is 0.1 for CUB200-
2011 and 0.15 for CARS196. For generating adversarial examples we use l∞ PGD-FSGM attacks
with strength = 0.0314, L = 7 steps and step size α = 0.007. For Online-products and In-shop
we use λ = 0.005, = 0.01, L = 5, and α = 0.003. The ImageNet model is the model only with
ImageNet pretrain.
Results. In Table 2, our ADML+A and ADML+U models outperform the SOTA metric learning
models. ADML+A/U improve the R@1 over 1% on CUB200-2011 and CARS196, and also have
considerable improvement on Online-product and In-shop dataset. Besides, the performance of
ADML+A/U under the NMI and mAP@C metrics is also comparable or better than the SOTA.
7
Under review as a conference paper at ICLR 2022
Table 3: Performance of DML models on clustering and retrieval tasks averaged over 5 runs on
Online-products and In-shop. Our Adversarial DML models, ADML+A, and ADML+U, outperform
the rest models in most cases. The model settings and training parameters are same for all models.
	Online-product			In-shop		
Models	R@1	NMI	mAP@C	R@1	NMI	mAP@C
ImageNet pretrain	48.51	84.24	17.37	21.62	76.53	4.02
Linear	20.53	81.20	5.78	16.03	75.81	2.47
Triplet-D	77.41 ± 0.19	90.04 ± 0.05	41.05±0.14-	87.31 ± 0.18	89.76 ± 0.09	28.45 ± 0.17
Margin	77.66 ± 0.14	89.93 ± 0.06	41.41 ± 0.12	87.56 ± 0.15	89.93 ± 0.07	28.45 ± 0.13
Multi-Similarity	77.75 ± 0.11	90.00 ± 0.04	41.39 ± 0.10	87.33 ± 0.20	89.85 ± 0.12	29.61 ± 0.16
Proxy-Anchor	77.11 ± 0.13	89.90 ± 0.05	40.98 ± 0.15	87.14 ± 0.17	89.41 ± 0.05	28.11 ± 0.11
Cross-Entropy	76.92 ± 0.36	89.82 ± 0.11	41.31 ± 0.42	86.75 ± 0.32	89.71 ± 0.13	28.38 ± 0.51
Info-NCE	76.21 ± 0.15	89.71 ± 0.04	39.42 ± 0.09	86.24 ± 0.14	89.62 ± 0.04	27.94 ± 0.17
ADML+T	77.13 ± 0.11	89.59 ± 0.03	40.75 ± 0.07	87.47 ± 0.12	89.65 ± 0.10	29.05 ± 0.12
ADML+A	78.12 ± 0.16	89.95 ± 0.04	41.56 ± 0.11-	87.94 ± 0.15	89.93 ± 0.05	30.12 ± 0.15
ADML+U	78.01 ± 0.12	89.97 ± 0.03	41.21 ± 0.12	87.86 ± 0.18	89.57 ± 0.08	29.93 ± 0.16
ADML+A+U	77.41 ± 0.15	89.88 ± 0.07	40.91 ± 0.14	87.65 ± 0.12	89.71 ± 0.09	29.72 ± 0.13
0.70	,	0.70
/ ∖	---- Recall@l
0.68 z	、、4——NMI 0.68
(a) CUB-ADML+A
0.60
----Recall©I
-- NMI
(b) CUB-ADML+U
0.65
(c) CARS-ADML+A (d) CARS-ADML+U
Figure 1: Performance of ADML+A and ADML+U with different adversarial training strength λ on
CUB200-2011 and CARS196.
Since all the models are training under the same framework and settings, we can conclude that
adversarial training helps to enhance the natuaral performance of DML models.
5.4	Robustness performance of Adversarial DML models
We evaluate the robustness performance of our ADML+A and ADML+U models against attacking
the alignment objective, which is the strongest DML attack according to our experiment in Sec. 5.2,
on CUB200-2011 and CARS196 datasets. For baseline models we use margin, multi-similarity, and
ADML+Triplet models. The settings of alignment attack are the same as the settings in Sec. 5.2,
the settings of ADML+A/U and baseline models are the same as the settings in Sec. 5.3. As seen in
Table 4, ADML+T has slightly better performance than the vanilla DML models, while ADML+A
and ADML+U outperform the baseline models with a large margin under the alignment attacks.
Notice ADML+A takes the advantage of adversarial training with alignment loss, it’s reasonable
that the performance ADML+A is slightly better than ADML+U under alignment attacks.
Table 4: Robustness performance of DML models and ADML models against adversarial samples
generated by attacking alignment loss.
	CUB200-2011						CARS196		Online-Products		
Models	R@1	NMI	mAP@C	R@1	NMI	mAP@C	R@1	NMI	mAP@C
Margin	8.04	24.59	0.58	8.39	17.17	0.56	8.27	80.02	1.34
Multi-similarity	8.90	24.13	0.51	11.95	18.32	0.55	8.93	80.06	1.45
ADML+T	11.58	25.26	0.74	25.35	21.22	1.31	10.69	80.20	1.74
ADML+A	17.37	29.16	1.27	39.97	26.05	2.54	13.98	80.40	2.01
ADML+U	15.10	27.89	1.06	33.09	24.48	2.30	11.32	80.29	1.85
8
Under review as a conference paper at ICLR 2022
Table 5: Robustness with different adversarial training strength λ on CUB200-2011 under the align-
ment attacks. The metric is Recall@1.
λ	0	0.2	0.4	0.6	0.8	1.0
ADML+A	8.90	19.15	22.51	24.47	25.29	25.93
ADML+U	8.90	16.21	18.36	20.23	21.06	21.55
5.5	Ablation study
Strength of adversarial training. In this part, we evaluate the effect of adversarial training strength
λ on the performance of ADML+A and ADML+U. The backbone is DML with multi-similarity
loss. We expect the performance will first increase with λ then decrease, because when λ is close to
0, the ADML models can hardly learn adversarial features and the improvement is small, when λ is
large, the adversarial features will dominate the DML models and the performance on clean features
will be poor. The model settings are the same as in Sec. 5.3. The experimental results illustrated
in Fig. 1 are consistent with our analysis, when increasing the adversarial training strength, the
natural performance of ADML+A and ADML+U is first improved then decreased. Table 5 shows
the robustness of ADML+A and ADML+U model with adversarial training strength λ and alignment
attacks. Both models become increasingly robust against alignment attacks.
ADML on different metric loss. In this experiment, we apply our ADML approach with triplet,
alignment, uniformity, and alignment+uniformity objectives on different metric losses, including
triplet, margin, multi-similarity, and info-NCE losses. The metric is Recall@1. The model settings
are the same as in Sec. 5.3. From Table 6, we can observe that all ADML methods boost the
performance of all DML losses. ADML+A achieves the most significant improvement across all
attacks and metric losses.
Table 6: Recall@1 of different metric learning losses with ADML methods on CUB200-2011
	Vanilla	ADML+T	ADML+A	ADML+U	ADML+A+U
Triplet	62.29	63.68	65H~~	64.72	63.17
Margin	62.48	64.26	65.92^^	65.61	64.32
Multi-similarity	62.71	64.45	-^66Γ3^^	65.58	64.39
Info-NCE	61.42	62.74	64.01	63.85	62.91
A mixture of alignment and uniformity attacks. In this experiment, we study the effect of different
weight of alignment and uniformity objectives in ADML+A+U. The backbone is DML with multi-
similarity loss. The model settings are the same as in Sec. 5.3. Specifically, we assign weight (1 -β)
to the alignment objective and β to the uniformity objective. The results are shown in Table 7. When
β increases, the performance of the ADML model first decreases and then increases, which indicates
that attacking alignment and uniformity loss separately can lead to better results.
Table 7: Recan@1 of ADML+(1 - β) A+β U on CUB200-2011 With different β.
β	0	0.2	0.4	0.5	0.6	0.8	1
ADML+(1 - β)A+(β) U	66.13	6581	64.67	64.39	64.55	65.33	65.58
6	Conclusion
In this work, we investigated two important properties, intra-class alignment and hyperspherical
uniformity, of tuple-based metric losses on unit sphere. According to our theoretical analysis and
experimental results, the positive metric losses contribute to the intra-class alignment and the neg-
ative metric losses achieve hyperspherical uniformity. Based on our new understanding, we design
two novel adversarial DML models, ADML+A and ADML+U, where the perturbations are gen-
erated by maximizing the alignment loss or the uniformity loss. Our ADML+A and ADML+U
improve both of natural and robust DML performance by enhancing model generalization. Poten-
tial future work directions include analyzing other tuple-based metric losses theoretically, designing
new metric losses based on the alignment and uniformity, and exploring the trade-off between nature
and robustness performance in metric learning.
9
Under review as a conference paper at ICLR 2022
Ethics S tatement
In this paper, we design new adversarial deep metric learning (DML) models for improving the
vanilla DML. Our method can boost the robustness of neural networks again adversarial attacks,
which contributes to the trustworthy AI and machine learning.
Reproducibility
All datasets, baseline models, general training settings are provided in Sec. 5.1. For specific tasks
we also include the detailed settings in the corresponding sections. For example, the detailed model
structure and hyperparameter settings for the natural performance of ADML models are written in
Sec. 5.3. We will release the code if the paper is accepted.
References
Philip Bachman, R Devon Hjelm, and William Buchwalter. Learning representations by maximizing
mutual information across views. arXiv preprint arXiv:1906.00910, 2019.
Malik Boudiaf, Jerome Rony, Imtiaz MasUd Ziko, Eric Granger, Marco Pedersoli, Pablo Piantanida,
and Ismail Ben Ayed. A unifying mutual information view of metric learning: cross-entropy vs.
pairwise losses. In European Conference on Computer Vision, pp. 548-564. Springer, 2020.
Maxime Bucher, Stephane Herbin, and Frederic Jurie. Improving semantic embedding consistency
by metric learning for zero-shot classiffication. In European Conference on Computer Vision, pp.
730-746. Springer, 2016.
D Manning Christopher, Raghavan Prabhakar, SchUtze Hinrich, et al. Introduction to information
retrieval. An Introduction To Information Retrieval, 151(177):5, 2008.
Terrance DeVries and Graham W Taylor. Improved regularization of convolutional neural networks
with cutout. arXiv preprint arXiv:1708.04552, 2017.
Yueqi Duan, Wenzhao Zheng, Xudong Lin, Jiwen Lu, and Jie Zhou. Deep adversarial metric learn-
ing. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.
2780-2789, 2018.
Raia Hadsell, Sumit Chopra, and Yann LeCun. Dimensionality reduction by learning an invariant
mapping. In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recogni-
tion (CVPR’06), volume 2, pp. 1735-1742. IEEE, 2006.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam
Trischler, and Yoshua Bengio. Learning deep representations by mutual information estimation
and maximization. arXiv preprint arXiv:1808.06670, 2018.
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and Aleksander
Madry. Adversarial examples are not bugs, they are features. arXiv preprint arXiv:1905.02175,
2019.
Herve Jegou, Matthijs Douze, and Cordelia Schmid. Product quantization for nearest neighbor
search. IEEE transactions on pattern analysis and machine intelligence, 33(1):117-128, 2010.
Ziyu Jiang, Tianlong Chen, Ting Chen, and Zhangyang Wang. Robust pre-training by adversarial
contrastive learning. arXiv preprint arXiv:2010.13337, 2020.
G. A. Kabatjanskii and V. I. Levenstein. Bounds for packings on a sphere and in space. Problemy
Peredachy Informatsii, 1978.
Sungyeon Kim, Dongwon Kim, Minsu Cho, and Suha Kwak. Proxy anchor loss for deep metric
learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recogni-
tion, pp. 3238-3247, 2020.
10
Under review as a conference paper at ICLR 2022
Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3d object representations for fine-grained
categorization. In 4th International IEEE Workshop on 3D Representation and Recognition
(3dRR-13), Sydney, Australia, 2013.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep con-
VolUtional neural networks. Advances in neural information processing systems, 25:1097-1105,
2012.
Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, and Le Song. Sphereface: Deep
hypersphere embedding for face recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pp. 212-220, 2017.
Weiyang Liu, Rongmei Lin, Zhen Liu, Lixin Liu, Zhiding Yu, Bo Dai, and Le Song. Learning
towards minimum hyperspherical energy. arXiv preprint arXiv:1805.09298, 2018.
Weiyang Liu, Rongmei Lin, Zhen Liu, Li Xiong, Bernhard Scholkopf, and Adrian Weller. Learn-
ing with hyperspherical uniformity. In International Conference on Artificial Intelligence and
Statistics, pp. 1180-1188. PMLR, 2021.
Ziwei Liu, Ping Luo, Shi Qiu, Xiaogang Wang, and Xiaoou Tang. Deepfashion: Powering robust
clothes recognition and retrieval with rich annotations. In Proceedings of IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), June 2016.
Raphael Gontijo Lopes, Dong Yin, Ben Poole, Justin Gilmer, and Ekin D Cubuk. Improv-
ing robustness without sacrificing accuracy with patch gaussian augmentation. arXiv preprint
arXiv:1906.02611, 2019.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083,
2017.
Yair Movshovitz-Attias, Alexander Toshev, Thomas K Leung, Sergey Ioffe, and Saurabh Singh. No
fuss distance metric learning using proxies. In Proceedings of the IEEE International Conference
on Computer Vision, pp. 360-368, 2017.
Kevin Musgrave, Serge Belongie, and Ser-Nam Lim. A metric learning reality check. In European
Conference on Computer Vision, pp. 681-699. Springer, 2020.
Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predic-
tive coding. arXiv preprint arXiv:1807.03748, 2018.
Thomas Kobber Panum, Zi Wang, Pengyu Kan, Earlence Fernandes, and Somesh Jha. Exploring
adversarial robustness of deep metric learning. arXiv preprint arXiv:2102.07265, 2021.
Bernardino Romera-Paredes and Philip Torr. An embarrassingly simple approach to zero-shot learn-
ing. In International conference on machine learning, pp. 2152-2161. PMLR, 2015.
Karsten Roth, Timo Milbich, Samarth Sinha, Prateek Gupta, Bjorn Ommer, and Joseph Paul Co-
hen. Revisiting training strategies and generalization performance in deep metric learning. In
International Conference on Machine Learning, pp. 8242-8252. PMLR, 2020.
Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry. Do adver-
sarially robust imagenet models transfer better? arXiv preprint arXiv:2007.08489, 2020.
Florian Schroff, Dmitry Kalenichenko, and James Philbin. Facenet: A unified embedding for face
recognition and clustering. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pp. 815-823, 2015.
Hyun Oh Song, Yu Xiang, Stefanie Jegelka, and Silvio Savarese. Deep metric learning via lifted
structured feature embedding. In IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2016.
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and Aleksander Madry.
There is no free lunch in adversarial robustness (but there are unexpected benefits). arXiv preprint
arXiv:1805.12152, 2(3), 2018.
11
Under review as a conference paper at ICLR 2022
C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. The Caltech-UCSD Birds-200-2011
Dataset. Technical report, 2011.
Tongzhou Wang and Phillip Isola. Understanding contrastive representation learning through align-
ment and uniformity on the hypersphere. In International Conference on Machine Learning, pp.
9929-9939. PMLR, 2020.
Xun Wang, Xintong Han, Weilin Huang, Dengke Dong, and Matthew R Scott. Multi-similarity loss
with general pair weighting for deep metric learning. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pp. 5022-5030, 2019.
Chao-Yuan Wu, R Manmatha, Alexander J Smola, and Philipp Krahenbuhl. Sampling matters in
deep embedding learning. In Proceedings of the IEEE International Conference on Computer
Vision, pp. 2840-2848, 2017.
Cihang Xie, Mingxing Tan, Boqing Gong, Jiang Wang, Alan L Yuille, and Quoc V Le. Adversarial
examples improve image recognition. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pp. 819-828, 2020.
12
Under review as a conference paper at ICLR 2022
Appendix A	Code
We use the open source DML training framework https://github.com/Confusezius/
Deep-Metric-Learning-Baselines. We include the code of our Alg. 1 and Alg. 2 in the
supplementary material. All datasets used in this paper are available online. We will release the full
code package if our paper is accepted.
Appendix B	Theoretical explanation of positive and negative
METRIC LOSSES
B.1	Number of nearly orthogonal vectors in high dimensional sphere.
Lemma 1. (Kabatjanskii-LeVenstein bound (Kabatjanskii & Levenstein, 1978)) For a hypersphere
Sk-1 ∈ Rk, there existatleast kM vectors with pairwise distance in the range of √2±O(ι M lθg k).
Lemma 1 shows the number of nearly orthogonal vectors we can take from a high dimensional
sphere. If k = 128 and M = 3, the amount of nearly orthogonal vectors could be more than one
million, which exceeds the volume of benchmark datasets X in DML a lot. Following the former
discussion, We know the pairwise distance cannot be larger than √2 for all negative pairs. Therefore
we think the uniformity regularization with DML benchmarks will lead to an embedding space
where the feature vectors are nearly orthogonal. The plots of pairwise distance distribution in Fig. 2
with hyperspherical regularization also support our analysis.
B.2	Naive linear metric losses
With the same Assumption in Sec. 3.1, we can prove that the positive part of the linear loss minimizes
the intra-class distance and the negative part maximizes an unbiased term, which doesn’t achieve
hyperspherical uniformity. The theoretical analysis results are summarized in the following theorem.
Definition 4. (Naive linear loss)
Llinear(f； X,Ptri) ：= E(χ,y,χ-)〜惭|||f (x) - f (y) ||2 — ||f (x) — f (x-)∣∣2].
Definition 5. (Unbiased regularization)
Lunbiased(f; X, Pdata) := ||Ex~Pdata [f (X)] ||2 .
the minimum of this loss is reached when the centroid coincide with the origin.
Theorem 2. Naive linear loss consists of alignment loss and unbiased loss with a constant multi-
plier.
PositiVePart E(χ,y,χ-)〜Ptri ||f(x)-f(y)||22] = Lalignment
n1
Negative part: - E(χ,y,χ-)〜Ptriij|f(x) - f(x )||2] = n—ɪ (2Lunbiased — 2) + n-1 Lalignment
Combining them we have Llinear = n-ɪ (2Lunbiased + Lalignment - 2).
Because the number of classes nis always large and the magnitude of Lunbiased -1and Lalignment
are similar, in negative linear loss the dominant objective is the unbiased regularization. Thus simply
maximizing the distance between negative pairs will lead to the unbiased regularization instead of
hyperspherical uniformity. In Figure 2(e) and Figure 2(c) of the appendix, we can observe the
difference between the models with negative linear loss and uniformity regularization. We also show
the interesting connection between the naive linear loss and linear discriminant analysis (LDA) in
Sec. E.5.
Remark. Naive linear loss doesn’t work at all in practice (see the experimental results of Linear
model in Table 2 and Table 3). Based on our analysis, we believe it’s because linear loss doesn’t op-
timize the hyperspherical uniformity. In the next section, we will introduce our theoretical analysis
of triplet loss, which is a simple variant of linear loss. We find triplet loss optimize the hyperspheri-
cal uniformity, which could be the reason that triplet loss works well empirically.
13
Under review as a conference paper at ICLR 2022
Appendix C	Empirical study of positive and negative metric
LOSSES
In this subsection, we study the effect of tuple-based metric losses on positive or negative pairs em-
pirically, and focus on the four tuple-based losses: naive linear, triplet, margin, and multi-similarity
loss. In experiments we train all DML models with either positive metric losses or negative metric
losses.
C.1 DML models with positive metric losses
Settings. We train 4 DML models with linear, triplet, margin, and multi-similarity losses on the
positive sample pairs. The gradient flow of negative pairs is stopped. We train all models for 50
epochs. We compare the average distance between positive/negative/all pairs of embedded samples.
Results. In Table 8, the DML models trained with only positive metric losses have average pairwise
distance close to 0. Therefore, minimizing the intra-class alignment will lead to a model which maps
all samples to the same feature vector.
Table 8: Comparison of DML models trained with the positive metric losses on CUB200-2011 and
CARS196. We calculate the average distance (Avgdist), average distance of positive pairs (Avgdist-
Pos), and average distance of negative pairs (AvgdistNeg) with the embedded samples.
CUB200-2011				CARS196		
	AvgdistPos	AvgdistNeg	Avgdist	AvgdistPos	AvgdistNeg	Avgdist
Linear	2.010e-3	3.190e-3	3.178e-3^^	1.497e-3	3.162e-3	3.183e-3
Triplet	1.934e-3	3.187e-3	3.174e-3	1.476e-3	3.163e-3	3.184e-3
Margin	7.565e-2	8.200e-2	8.192e-2	3.195e-2	3.468e-2	3.465e-2
MS	2.558e-3	3.324e-3	3.316e-3	2.242e-3	3.264e-3	3.277e-3
C.2 Compare negative metric losses with uniformity regularization
Settings. We compare 8 different models in this experiment, including a) the original model with
only ImageNet pretrain; b) four models trained with linear, triplet, margin, and multi-similarity
losses on negative pairs; c) three models trained with HE(s=0), HE(s=1) (Eq. 2) and G-HE(s=1)
(Eq. 3) regularization, those regularization functions are introduced in Appendix C. We train all
models with 50 epochs. For the models with negative metric losses, the gradient flow of positive
pairs is stopped.
Evaluation Metrics. We use the regularization score on HE(s=0) (Eq. 2) and G-HE(s=1) (Eq. 3)
to measure the uniformity of embedded samples on hypersphere. Smaller score indicates better
uniformity. We also check the average of pairwise distance of different models, We expect it to be
close to √2 for good hyperspherical uniformity.
Results. In experiments we compare the regularization strength of negative metric losses with HE
and G-HE. Fig. 2 and Fig. 3 illustrates the pairwise distance of the test samples on CUB200-2011
and CARS196 dataset. The DML models with negative metric losses have similar pairwise dis-
tance distributions as the uniformity regularization methods, and the only exception is the negative
naive linear loss, which will not lead to the hyperspherical uniformity based on our analysis in
Sec. B.2. We also include the distance distribution before training (Figure 2(a)) as a reference. Be-
sides, we also compare those models under the hyperspherical uniformity metrics. In Table 9, the
negative metric losses achieve comparable results with the uniformity regularization methods. The
G-HE(s=1) outperforms the rest models.
14
Under review as a conference paper at ICLR 2022
Table 9: Comparison of DML models trained with the negative metric losses and uniformity regu-
larization on CUB200-2011 and CARS196. All negative metric losses except Linear achieve com-
parable performance to uniformity regularization. The details of models and training settings are in
Sec. C.2._____________________________________________________________________________________________
CUB200-2011				CARS196		
	Avgdist	HE(s=0)	G-HE(s=1)	Avgdist	HE(s=0)	G-HE(s=1)
ImageNet	0.7220	0.3368	0.5939	0.6557	0.4326	0.6497
Linear	1.2398	-0.1670	0.2535	1.3194	-0.1686	0.2449
Triplet	1.3877	-0.3254	0.1496	1.4039	-0.3376	0.1420
Margin	1.3929	-0.3297	0.1465	1.4016	-0.3363	0.1426
MS	1.3825	-0.3221	0.1509	1.3985	-0.3338	0.1441
HE regularization (s=0)	1.4001	-0.3347	0TT438	1.4064	-0.3395	0.1411
HE regularization (s=1)	1.4009	-0.3355	0.1432	1.4068	-0.3398	0.1407
G-HE regularization (s=1)	1.4028	-0.3369	0,1424	1,4077	-0,3406	0,1402
0.0	0.5	1.0	1.5	2.0
distance
(a)	ImageNet
0.0	0.5	1.0	1.5	2.0
distance
(b)	G-HE (s=1)
0.0	0.5	1.0	1.5	2.0
distance
(c)	HE (s=0)
0.0	0.5	1.0	1.5	2.0
distance
(d)	HE (s=1)
(f) Triplet
(g) Margin
Figure 2: Illustration of pairwise distance distributions of the embedded CUB200-2011 samples
generated by DML models trained with negative metric losses or uniformity regularization. The
details of models and training settings are in Sec. C.2.
(h) Multi-similarity
15
Under review as a conference paper at ICLR 2022
(d) HE(s=1)
(a) ImageNet	(b) G-HE(s=1)	(c) HE(s=0)
(e) Linear
(f) Triplet	(g) Margin	(h) Multi-similarity
Figure 3: Illustration of pairwise distance distributions of the embedded CARS196 samples with
negative metric losses or uniformity regularization. The details of models and training settings are
in Sec. 5.3.
Appendix D ADML algorithms and experimental settings
D.1 Algorithm of ADML+A and ADML+U
Algorithm 1 ADML+A
Input: training set X ; number of epochs N ; original classifier f ; weight of adversarial training λ;
PGD attack step L; PGD attack strength
Initialize class balanced sampler S;
for i ∈ epochs do
for S ∈ mini-batch{S1, ..., Sn} do
S(0) = S;
Generate adversarial samples of S with PGD-FSGM attack
for t ∈ 0 : L - 1 do
I S(t+1)= ∏B∞(S(0),e) (S ⑴ + αVs(t) Lalignment(f, S ⑴))；
end
Sadv = S* (L);
Calculate objective function
Ltotal = L(f, S) + λL(f, Sadv);
L can be an arbitrary metric loss, in our paper we use margin and multisimilarity loss
Update network parameters of f with Ltotal ;
end
end
16
Under review as a conference paper at ICLR 2022
Algorithm 2 ADML+U
Input: training set X; number of epochs N; original classifier f; weight of adversarial training λ;
PGD attack step L; PGD attack strength
Initialize class balanced sampler S ;
for i ∈ epochs do
for S ∈ mini-batch{S1 , ..., Sn} do
S(0) = S;
Generate adversarial samples of S with PGD-FSGM attack
for t ∈ 0 : L - 1 do
I S(t+1) = ∏B∞(S(0) ,e) (S") + α^ S(t) Luniformity (f, S")));
end
Sadv = S* (L);
Calculate objective function
Ltotal =L(f,S) +λL(f,Sadv);
L can be an arbitrary metric loss, in our paper we use margin and multisimilarity loss
Update network parameters of f with Ltotal ;
end
end
D.2 Dataset Details
• CUB200-2011 contains 200 species of birds and 11,788 images (Wah et al., 2011). We use the
first 100 species as training set and the rest as test set.
• CARS196 has 196 models of cars and 16,185 images. (Krause et al., 2013). We use the first 98
models as training set and the rest as test set.
• Online-product includes 22,634 classes of products and 120,053 images (Song et al., 2016).
We use the first 11,318 classes as training set and the rest as test set.
• In-shop contains 7982 classes of clothing and 54,624 images (Liu et al., 2016). We use the
first 3,997 classes as training set and the rest as test set. The test set is further partitioned into
a query set with 14,218 images of 3,985 classes and a gallery set with 12,612 images of 3,985
classes.
D.3 Evaluation Metrics
We use the following metrics to evaluate the DML models with retrieval and clustering downstream
tasks.
Recall@k. For the retrieval task we apply the Recall@k (R@k) metric (Jegou et al., 2010). For a
test set M := {(χι,yι),…，(xn, yn)}, the indices of the first k nearest neighborhood of a sample
xi is given by Sk(xi) := argmax|S|=k Pj∈S,j6=i ||f (xi) - f(xj)||2, and
1n
R@k :=-	1{∃j∈Sk(xi),yj=yi}.
i=1
NMI. We use Normalized Mutual Information (NMI) (Christopher et al., 2008) to measure the
quality of the clustering task. We use K-means to generate the clusters of the embedded samples,
then we calculate the label assignment Γ = {γ1, ..., γn} from clustering. Denote the ground truth
labels by Ω = {yι,..., yn}, the NMI is computed as
NMI(Ω, Γ)= I(Ω, Γ)∕[2(H(Ω) + H(Γ))],
where I(∙, ∙) is the mutual information function and H(∙) is the entropy function.
mAP@C. According to (Musgrave et al., 2020), we also include mean average precision measured
on recall (mAP@k) as an additional metric. We first compute the recalled samples, which are
determined by the k nearest neighbour ranking. Then compute the mAP-score follows the standard
mAP procedure. mAP@C is the mean over the class-wise average precision@kc, where kc is the
17
Under review as a conference paper at ICLR 2022
number of samples in class c, which means we only recall kc nearest neighbour. Following the
notation of Recall@k, the value of mAP@C is given by
mAP @C :
n XX
c∈C yq=c
|{xi ∈ Skc(Xq ) |yi = yq }|
kc
Appendix E Missing Proofs
E.1 Proof of Proposition 1
Denote the support set of the distribution of each class by S1, . . . , Sn, according to Definition 1, the
minimum of alignment loss is reached when the encoder f * maps all samples in one class to the
same feature vector i.e. ∀i, f*(Si) = {vi}. For arbitrary i,j, because ∪n=ιSk is connected and
each Sk is closed, we can select a set sequence Sk0 , . . . , Skm such that Sk0 = Si, Skm = Sj and
Skl ∩ Skι+1 = 0,l ∈ [m - 1]. By Skl ∩ Skι+1 = 0 We have Vkl = Vkι+ι for all l ∈ [m - 1], thus
∀i, j, f*(Si) = f*(Sj). So all samples are projected to the same feature vector.
E.2 Proof of Theorem 2
Proof. Recall that the naive linear loss is given by
Llinear (f ； X,Ptri) ：= E(χ,y,χ-)〜「用|||f(X) - f (y)||2 - ||f(x) - f(X—)||2]
Consider the positive part
E(x,y,χ-)〜ptri[||f(x) - f (y)||2] = E(x,y)〜ppos[||f(X)- f (y)||2] = Lalignment	⑻
Consider the negative part
-E(x,y,χ-)〜ptri[||f(x) - f (x-)||2] = 2E(x,y,χ-)〜p* [f (X)Tf (x—)] - 2
and
E(X,y,x-)~ptri [f(X)Tf(X-)]
E(x,y )~Ppos[f(x)TEχ-〜p-ata[f(x-)]]
=Ex 〜Pdata [f (X)T -p	- _\i _
x- pdata(X-)dX-
(Ex0~pdata [f(X0)] - Exo〜
Pdata [f(X0)1x0∈Xx])]
n-1 (Ex〜Pdata [f (X)TExo~pdata[f(X0)]] -Ex
~pdata [f(X)TExO〜Pdata [f(X0)lxoeXx]])
n-1 (Ex 〜Pdata [f(X)TExO 〜Pdata [f 3)]]- Ex 〜pd。,。[f (X)T Pdata(Xx)Ex，〜Pdata (. | X。) [f (x]]])
n1
n - J Ex〜Pdata[f(X)]TEx
~Pdata [f(x)] - n - J E(x,y)~Ppos[f (x) f (y)]
n1
n - J Ex〜Pdata[f(X)]TEx
~Pdata[f(x)]- n-1 E(x,y)~Ppos[f (X)Tf (y)]
ɪLunbiased +	1 U(Lalignment - 2)
n - J	2(n - J)
where we denote the class of sample X by Xx .
Combining Eq. 8 and Eq. 9 together, we have
Llinear (f) =	L Lunbiased +	( (Lalignment - 2) - 2 + Lalignment
n-1	n-1
n
= n	J (2Lunbiased + Lalignment - 2)
(9)
(10)
□
18
Under review as a conference paper at ICLR 2022
E.3 Proof OF Theorem 2
Proof. The triplet loss is
LtriPlet(f,T) = LIinear(f ； X,p[ri)= E(x,y,χ-)*ri [||f 3 - ∕3)I∣2 T∣f3 — f (x- )∖∖2]
=E(x,y,x-)~Ptri[(IIf (X)- f (y) ∣∣2 - IIf (X)- f (x ) ∣∣2 )1{∖∖f (x)-f (y)∖∖2 -∖∖f (x)-f (χ-)∖∖2+τ ≥0}]
=E(χ,y,x-)~Ptri[IIf (X) - f (U)I∣21{∖∖f(χ)-f(y)∖∖2-∖∖f(χ)-f(χ-)∖∖2+τ≥0}]
-E3y,x-)~Ptri[∣If (X) - f (x )∣∣21{∖∖f(χ)-f(y)∖∖2-∖∖f (x)-f(χ-)∖∖2+τ≥0}]
Consider the negative part,
-E3y,x-)~Ptri[IIf(x) - f (x )H21{∖∖f(χ)-f(y)∖∖2-∖∖f(x)-f(χ-)∖∖2+τ≥0}]
-EX~Pdatα , x-~p-atJIIf(X)- f(x )||2Ey-pdɑtɑ(-\χæ)[l{\\f(χ)-f(y)∖∖2-∖∖f(x)-f(χ-)∖∖2+τ≥0}]]
-n - ] EX~Pdata,x'~Pdata [IIf (X) - f (X/)“2/2pdata G∖Xχ)[1{∖∖f (χ)-f (y)∖∖2-∖∖f (χ)-f (χ0)∖∖2+τ ≥0}]]
+
n - J Ex~PdataH~Pdata [IIf (X) - f (XZ )II21xZEXx Ey^Pdata (-∖X≈ ) [1{W f (x)-f (y)∖∖2-∖∖f (x)-f (x/)∖∖l+τ ≥
-n - J Ex~PdataH~Pdata [IIf (X) - f (" )”2/~pdata G∖Xχ)[1{∖∖f (x)-f (y)∖∖2-∖∖f (x)-f (x0)∖∖2+τ ≥0}]]
+ n - 1 E(XH)~Ppos[IIf (X)- f (x'X^Ey-PdataGIXx)[1{∖∖f(x)-f(y)∖∖2-∖∖f(x)-f(x0)∖∖2+τ≥0}]]
-n^-7 EX~PdataH~PdatJIf (X)- f ( X') U 2 S (X,X')]
+ nɪɪE(XH)~Ppo」IIf(X)- f(x')II2S(x,X')]
where XX is the set of samples have the same label as x. The last equation is based on
S(x, x0)
∞o
/	q(u + d2(x, x0) — T)
0
Eq(d2(x,y)) [1{u≥0}]= 1Ey ~pdatα (∙∖ Xx) [ l{u≥0}]
Ey~Pdatα(∙∖Xx)[1{∖∖f(x)-f(y)∖∖2-∖∖f(x)-f(x0)∖∖2+τ ≥0}]
□
E.4 Proof of Proposition 2
Proof. By q(d2(x, y))
1 Q-A(U+d2(x,x0
A e
)-τ), then
-Ae-Ad2(x,y), the pdf of U = d2(x,y) — d2(x,x0) + τ is
S(x,x0) = 1 f ∞ e-A(U+d2(x，XO)-T)du
A Jo
1 e-A(d2(x,x')-τ)
Ae
Consider the gradient of the negative triplet loss E(x,y,x-)~p 晨,[∣∣f (x) 一 f (x-)∣∣2], during training
we first sampling from Ptri then calculate the gradient. In this case the actual gradient flow is given
by
-E(X,y,x-)~ptriVθIIf(x) - f(x-)I∣2]
19
Under review as a conference paper at ICLR 2022
Analogous with the discussion in Sec. E.3, we have
-E(x,y,χ-)〜ptriVθ IIf(X)- f (X-川2]
-n	1 Ex~pdata ,x0~pdata [S(x,x0)VθIIf(x) - f(χ0)∣∣2]
+ n	1 E(χ,χO)~ppos[S(X,X0)VθIIf(X)-f(X0)II22]
=-AeAτnπEXYdataHYdatakAdKMVdlXH)"2 ") dd(xx2]+ O(1)
(n - 1)	∂	n
=- AeATn)Ex~pdata,x，~pdata[e-Ad2(X，x0)2d(x,X0) dd(xθX0l↑ +。( 1)
=A2enτ- 1) EX~Pdata,X，~PdataVd(X,X，)(e-Ad2 3*) dd(xθx2]+ O( 1 2)
Aτ
=A2(n -1) 口叱』。,。,”『海归山(X,叫+ θ( n)
eAτn	1
=A^ vθ EGaX ) + O( n
□
E.5 Connection between naive linear loss and LDA
The intuition of multiple linear discriminant analysis (LDA) is to maximize the inter-class variance
while minimizing the intra-class variance. In this section we will show linear metric loss have a
similar effect.
Definition 6. (Total variation) For a random vector X, the total variation is
TV (X) := tr(E[(X - E[X])(X - E[X])T]) = E[(X - E[X])T (X - E[X])] = E[XT X] - E[X]T E[X]
(11)
Definition 7. (Centroid) Define the centroid of samples in an arbitrary set Y by
cY := Ey~Pdata(∙∣Y)[f(y)] =^"	Ey~Pdata [f(y)1y∈Y]
pdata (Y )
Proposition 3. (Intra-class total variation) The within-class variation
T Vintra(X) := EX~Pdata [(f (X) - cXx)T (f (X) - cXx)]
is proportional to alignment loss
Laligned(f) = 2T Vintra(X)
Proof.
T Vintra(X) =EX~Pdata [(f (X) - cXx)T (f (X) - cXx)]
n
=	pdata(Xi)(Ex
~pdata(∙∣Xi)f(X)Tf(x)] -CXicXi)
i=1
1n
=n ∑(1 - nEX~Pdata ,X0~Pdata(TXχ)[f(X)Tf(X0)1x∈Xi])
n i=1
(12)
(13)
(14)
n
1 - EX~Pdata,X0~Pdata(TXχ) [f (X) f (X )	1x∈Xi ]
i=1
1 - E(χ,y)〜Ppos[f (X)Tf (y)]
2 Laligned(f )
□
20
Under review as a conference paper at ICLR 2022
Proposition 4. (Inter-class total variation) The inter-class total variation
TVinter(X) := EX~Pdata [(cXx - c)T (cXx - c)],
where c is the centroid of all samples, is proportional to triplet loss
Llinear
(f)
—
2n
-TTVinter(X )
n-1
(15)
Proof.	TVinter(X )= Ex 〜Pdata [CXxCXχ ] -CT C	(16)
Firstly,	C v、	E E ʌ Ex〜Pdata [f(X)1x∈X] =Ex ~Pdata [f (X)] pdata (X)
Hence CTC = Next,	Lunbiased (f). n Ex~Pdata[cXxCXx] = Epdata(Xi)Ex 〜Pdata(∙Xi)[cXi CX」 i=1 n =	pdata (Xi)CTXiCXi i=1 n =	Ex~Pdata ,y「7Pdata (T Xx ) [f(X)Tf(y)1x∈Xi] i=1 n ^^x~Pdata ,y ~Pdata (1-Xx ) [f (X)T f (y)	1x∈Xi ] i=1 Ex~Pdata ,y~Pdata (」Xx ) [f(X)Tf(y)] =E(x,y)〜Pposf(X)T f(y)]
2 Laligned(f ) 一
1 - 1 Laligned(f), and TVinter (X)
Thus Ex 〜Pdata[cXχcXχ]
1-
Lunbiased (f ) =-n-n~ Llinear (f)
□
Proposition 5. (Total variation of the dataset) The total variation of dataset X
TVtOtal(X ) := Ex 〜Pdata [(x -C)T (X -C)],
where c is the centroid of all samples, is proportional to the unbiased loss
Lunbiased (f) = 1 - T Vtotal (X)	(17)
Proof.
TVtOtal (X ) = Ex 〜Pdata[f (X)T f (X)] - Ex 〜Pdataf(X)]TEx 〜Pdataf(X)]
1 - Lunbiased (f )
(18)
□
We can also check if T VtOtal (X) = T Vwithin(X) + T Vbetween (X) holds to validate the proofs
above.
Appendix F	T-SNE evaluation of ADML+A and vanilla DML.
In experiments, we visualize the embedding of the first 10 classes of CUB200-2011 generated by
a vanilla DML model (with multi-similarity loss) and an ADML+A model (with multi-similarity
loss). The Recall@1 of the DML model and the ADML+A model are 62.71 and 66.13, respectively.
Fig. 4 (a) plots the T-SNE result for vanilla DML and Fig. 4 (b) plots the T-SNE result for ADML+A.
Comparing two figures, we can see that ADML+A has better separation on the (red, green, orange)
samples.
21
Under review as a conference paper at ICLR 2022
ZEs
(a) Vanilla DML
Ooooooo
3 2 1 12 3
- - -
ZEs
(b) ADML+A
Figure 4: T-SNE visualization of embedding generated by a vanilla DML and an ADML+A model
on CUB200-2011.
22