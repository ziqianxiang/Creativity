Under review as a conference paper at ICLR 2022
EF21 with Bells & Whistles: Practical Algo-
rithmic Extensions of Modern Error Feedback
Anonymous authors
Paper under double-blind review
Ab stract
First proposed by Seide et al. (2014) as a heuristic, error feedback (EF) is a
very popular mechanism for enforcing convergence of distributed gradient-based
optimization methods enhanced with communication compression strategies based
on the application of contractive compression operators. However, existing theory
of EF relies on very strong assumptions (e.g., bounded gradients), and provides
pessimistic convergence rates (e.g., while the best known rate for EF in the smooth
nonconvex regime, and when full gradients are compressed, is O(1/T 2/3), the rate
of gradient descent in the same regime is O(1∕T)). Recently, Richtarik et al. (2021)
(2021) proposed a new error feedback mechanism, EF21, based on the construction
of a Markov compressor induced by a contractive compressor. EF21 removes the
aforementioned theoretical deficiencies of EF and at the same time works better in
practice. In this work we propose six practical extensions of EF21, all supported by
strong convergence theory: partial participation, stochastic approximation, variance
reduction, proximal setting, momentum and bidirectional compression. Several of
these techniques were never analyzed in conjunction with EF before, and in cases
where they were (e.g., bidirectional compression), our rates are vastly superior.
1 Introduction
In this paper, we consider the nonconvex distributed/federated optimization problem of the form
min 1(X)=f 1 Pj(X)｝，	⑴
where n denotes the number of clients/workers/devices/nodes connected with a server/master and
client i has an access to the local loss function fi only. The local loss of each client is allowed to
have the online/expectation form
fi (X)= Eξi〜Di fξi (X)] ,	⑵
or the finite-sum form
m
fi(χ) = ml P fij(χ).	(3)
j=1
Problems of this structure appear in federated learning (KOnecny et al., 2016; Kairouz, 2019), where
training is performed directly on the clients’ devices. In a quest for state-of-the-art performance,
machine learning practitioners develop elaborate model architectures and train their models on
enormous data sets. Naturally, for training at this scale to be possible, one needs to rely on distributed
computing (Goyal et al., 2017; You et al., 2020). Since in recent years remarkable empirical
successes were obtained with massively over-parameterized models (Arora et al., 2018), which puts
an extra strain on the communication links during training, recent research activity and practice
focuses on developing distributed optimization methods and systems capitalizing on (deterministic or
randomized) lossy communication compression techniques to reduce the amount of communication
traffic.
A compression mechanism is typically formalized as an operator C : Rd 7→ Rd mapping hard-to-
communicate (e.g., dense) input messages into easy-to-communicate (e.g., sparse) output messages.
The operator is allowed to be randomized, and typically operates on models Khaled & Richtarik
1
Under review as a conference paper at ICLR 2022
(2019) or on gradients Alistarh et al. (2017); Beznosikov et al. (2020), both of which can be
described as vectors in Rd. Besides sparsification (Alistarh et al., 2018), typical examples of useful
compression mechanisms include quantization (Alistarh et al., 2017; HorVgth et al., 2019a) and
low-rank approximation (Vogels et al., 2019; Safaryan et al., 2021).
There are two large classes of compression operators often studied in the literature: i) unbiased
compression operators C, meaning that there exists ω ≥ 0 such that
E[C(x)] = x, E kC(x) - xk2 ≤ ωkxk2,	∀x ∈ Rd;	(4)
and ii) biased compression operators C, meaning that there exists 0 < α ≤ 1 such that
E kC(x) - xk2 ≤ (1 -α) kxk2,	∀x ∈ Rd.	(5)
Note that the latter “biased” class contains the former one, i.e., if C satisfies (4) with ω, then a scaled
version (1 + ω)-1C satisfies (5) with α = 1∕(i+ω). While distributed optimization methods with
unbiased compressors (4) are well understood (Alistarh et al., 2017; Khirirat et al., 2018; Mishchenko
et al., 2019; Horvgth et al., 2019b; Li et al., 2020; Li & Richtgrik, 2021a; Li & Richtgrik, 2020;
Islamov et al., 2021; Gorbunov et al., 2021), biased compressors (5) are significantly harder to analyze.
One of the main reasons behind this is rooted in the observation that when deployed within distributed
gradient descent in a naive way, biased compresors may lead to (even exponential) divergence
(Karimireddy et al., 2019; Beznosikov et al., 2020). Error Feedback (EF) (or Error Compensation
(EC))—a technique originally proposed by Seide et al. (2014)—emerged as an empirical fix of this
problem. However, this technique remained poorly understood until very recently.
Although several theoretical results were obtained supporting the EF framework in recent years (Stich
et al., 2018; Alistarh et al., 2018; Beznosikov et al., 2020; Gorbunov et al., 2020; Qian et al., 2020;
Tang et al., 2020; Koloskova et al., 2020), they use strong assumptions (e.g., convexity, bounded
gradients, bounded dissimilarity), and do not get O(1∕αT) convergence rates in the smooth nonconvex
regime. Very recently, Richtgrik et al. (2021) proposed a new EF mechanism called EF21, which uses
standard smoothness assumptions only, and also enjoys the desirable O(1∕αT) convergence rate for
the nonconvex case (in terms of number of communication rounds T this matches the best-known
rate O((I+ω√√n"τ) obtained by Gorbunov et al. (2021) using unbiased compressors), improving the
previous O(1∕(aT)2/3) rate of the standard EF mechanism (Koloskova et al., 2020).
2	Our Contributions
While Richtgrik et al. (2021) provide a new theoretical SOTA for error feedback based methods, the
authors only study their EF21 mechanism in a pure form, without any additional “bells and whistles”
which are of importance in practice. In this paper, we aim to push the EF21 framework beyond
its pure form by extending it in several directions of high theoretical and practical importance. In
particular, we further enhance the EF21 mechanism with the following six useful and practical algo-
rithmic extensions: stochastic approximation, variance reduction, partial participation, bidirectional
compression, momentum, and proximal (regularization). We do not stop at merely proposing these
algorithmic enhancements: we derive strong convergence results for all of these extensions. Several
of these techniques were never analyzed in conjunction with the original EF mechanism before, and
in cases where they were, our new results with EF21 are vastly superior. See Table 1 for an overview
of our results. In summary, our results constitute the new algorithmic and theoretical state-of-the-art
in the area of error feedback.
We now briefly comment on each extension proposed in this paper:
Stochastic approximation. The vanilla EF21 method requires all clients to compute the exact/full
gradient in each round. While Richtgrik et al. (2021) do consider a stochastic extension of EF21,
they do not formalize their result, and only consider the simplistic scenario of uniformly bounded
variance, which does not in general hold for stochasticity coming from subsampling (Khaled &
Richtgrik, 2020). However, exact gradients are not available in the stochastic/online setting (2),
and in the finite-sum setting (3) it is more efficient in practice to use subsampling and work with
stochastic gradients instead. In our paper, we extend EF21 to a more general stochastic approximation
framework than the simplistic framework considered in the original paper. Our method is called
EF21-SGD (Algorithm 2); see Appendix D for more details.
2
Under review as a conference paper at ICLR 2022
Setup	Method	Citation	ComPI.(NC)	Compl. (PL)	Comment
-Full- grads	EF21	Richtdrik et al. (2021)	1 ɑε2	1 αμ	
Stoch. grads	-Choco-SGD- EF21-SGD EF21-SGD EF21-PAGE	Koloskova et al. (2020) Richtdrik et al. (2021) NEW NEW	工+ _G +) ε2	αε3	nε4 + σ2 αε2	α3ε4 1	+ 1 + ∆inf αε2	α3ε4 √m+1∕α + m	N/A ɪ +	σ2 αμ I μ2 a3ε 1 + 1 + ∆inf αμ 十 μ2 03ε √m+1∕α + m μ	1	kf(X)k ≤ G UBV (Ex. 1) IS (Ex. 2) m fi(x)= m P fij(x) j=1
-PP-	EF21-PP	NEW	丁⑴+」 pαε2	αε2	1 (1) I	~- pαμ	α αμ	Full grads
BC	DoUbleSqUeeZe EF21-BC	Tang et al. (2020) NEW	~ɪ + ∆ + ^2- ε2 + ε3 + nε4 1	N/A 1	E[∣∣C(x) - x∣∣] ≤ ∆ Full grads
			Γ2^ awaMε2		αwαMμ		
Mom.	M-CSER EF21-HB	Xie et al. (2020)(2) NEW	-^ 1 +	G	~ ε2	(1-η)αε3 ε⅛ (£ + 1)	N/A N/A	kVfi(x)k ≤ G Full grads
Prox	EF21-Prox	NEW		αε2		ZX73) αμ		Full grads
(1) Red term = number of communication rounds, blue term = expected number of gradient computations per client.
(2) Xie et al. (2020) consider Nesterov’s momentum. Moreover, they analyzed the version with stochastic gradients, bidirectional compression
and local steps. However, the derived result is not better than state-of-the-art ones with either stochastic gradients or bidirectional compression.
Therefore, to maintain the table compact, we do not include the results of Xie et al. (2020) in the other parts of the table.
⑶ This result is obtained under the generalized P匕-Condition for composite optimization problems (See Assumption 5 from Appendix I.2).
Table 1: Summary of the state-of-the-art complexity results for finding an ε-stationary point, i.e., such a
point X that E [kVf (X)∣∣2] ≤ ε2, for generally non-convex functions and an ε-solution, i.e., such a point
X that E [f (X) — f (x*)] ≤ ε, for functions satisfying P匕-COnditiOn using error-feedback type methods. By
(computation) complexity we mean the average number of (stochastic) first-order oracle calls needed to find an
ε-stationary point ("Compl. (NC)”)or ε-solution ("Compl. (P匕)").Removing the terms colored in blue from the
complexity bounds shown in the table, one can get communication complexity bounds, i.e., the total number
of communication rounds needed to find an ε-stationary point ("Compl. (NC)”) or ε-solution ("Compl.(P匕)”).
Dependences on the numerical constants, "quality” of the starting point, and smoothness constants are omitted
in the complexity bounds. Moreover, dependencies on log(1∕ε) are also omitted in the column “Compl.(P匕)”.
Abbreviations: "BC” = bidirectional compression, "PP” = partial participation; "Mom.” = momentum; T = the
number of communications rounds needed to find an ε-stationary point; #grads = the number of (stochastic)
first-order oracle calls needed to find an ε-stationary point. Notation: α = the compression parameter, αw and
αM = the compression parameters of worker and master nodes respectively for EF21-BC, σ2 = n Pn=1 σ2
(see Example 1), ∆inf = finf — n Pn=1mPmiI fiinf (See Example 2), P = probability of sampling the client
in EF21-PP, η = momentum parameter. To the best of our knowledge, combinations of error feedback with
partial participation (EF21-PP) and proximal versions of error feedback (EF21-Prox) were never analyzed in
the literature.
Variance reduction. As mentioned above, EF21 relies on full gradient computations at all clients.
This incurs a high or unaffordable computation cost, especially when local clients hold large training
sets, i.e., if m is very large in (3). In the finite-sum setting (3), we enhance EF21 with a variance
reduction technique to reduce the computational complexity. In particular, we adopt the simple and
efficient variance-reduced method PAGE (Li et al., 2021; Li, 2021b) (which is optimal for solving
problems (3)) into EF21, and call the resulting method EF21-PAGE (Algorithm 3). See Appendix E
for more details.
◊	Partial participation. The EF21 method proposed by Richtdrik et al. (2021) requires full Partici-
pation of clients for solving problem (1), i.e., in each round, the server needs to communicate with
all n clients. However, full participation is usually impractical or very hard to achieve in massively
distributed (e.g., federated) learning problems (KoneCny et al., 2016; Cho et al., 2020; Kairouz, 2019;
Li & Richtdrik, 2021b; Zhao et al., 2021). To remedy this situation, we propose a Partial ParticiPation
(PP) variant of EF21, which we call EF21-PP (Algorithm 4). See Appendix F for more details.
◊	Bidirectional compression. The vanilla EF21 method only considers uPstream compression of the
messages sent by the clients to the server. However, in some situations, downstream communication
is also costly (Horvdth et al., 2019a; Tang et al., 2020; Philippenko & Dieuleveut, 2020). In order
to cater to these situations, we modify EF21 so that the server can also optionally compresses
messages before communication. Our master compression is intelligent in that it employs the Markov
compressor proposed in EF21 to be used at the devices. The proposed method, based on bidirectional
comPression, is EF21-BC (Algorithm 5). See Appendix G for more details.
3
Under review as a conference paper at ICLR 2022
Update		Method	Alg.#	C		Comment
		EF21 二	Alg.1	C(Vfi(xt+1)-	-gt)	
		EF21-SGD-	Alg∙2	C(gi(xt+1)-	7gT-	gi(xt+1) satisfies As. 2
xt+1 gt = git+1	= xt - γgt, n ⅛ P gi, i=1 = git + cti	EF21-PAGE	Alg. 3	C(vit+1 - g	it)	b 〜Be(P), vt+1 = Vfi(xt+1),if bt = 1, vt+1= vt + τ1i P Vfij (xt+1) j∈Iit -T1 P Vfij(Xt ), if bi = 0, i j∈Iit Iit is a minibatch, |Iit | = τi
		EF21-PP	Alg.4	C(^fi(xt+1) 0	-gt)-	if i ∈ St if i ∈ St	
xt+1 = xt - γgt, gt+1 = gt + bt+1, bt+1 = CM (get+1 - gt), et+1 = n Pn=I et+1, geit+1 = geit + cit		EF21-BC	Alg. 5	Cw(vfi(χt+1) - et)		Master broadcasts bt+1 ; Cw is used on the workers’ side, CM is used on the master’s side
xt+1 vt+1 = gt+1 = git+1	= xt - γvt, ηvt + gt+1, n Pn=I gt+1, = git + cti	EF21-HB	Alg. 6	C(^fi(xt+1)	- git )	η ∈ [0,1) - momentum parameter
xt+1 = ProXYr (Xt - γgt), gt+1 = n P之ι gt+1, git+1 = git + cti		EF21-Prox	Alg.7	C(^fi(xt+1)	- git )	For problem (6); proXγr (X) is defined in (91)
Table 2: Description of the methods developed and analyzed in the paper. For the ease of comparison, we also
provide a description of EF21. In all methods only compressed vectors cit are transmitted from workers to the
master and the master broadcasts non-compressed iterates xt+1 (except EF21-BC, where the master broadcasts
compressed vector bt+1). Initialization of gi0, i = 1, . . . , n can be arbitrary (possibly randomized). One possible
choice is g0 = C(Vfi(x0)). The pseudocodes for each method are given in the appendix.
Momentum. A very successful and popular technique for enhancing both optimization and
generalization is momentum/acceleration (Polyak, 1964; Nesterov, 1983; Lan & Zhou, 2015; Allen-
Zhu, 2017; Lan et al., 2019; Li, 2021a). For instance, momentum is a key building block behind the
widely-used Adam method (Kingma & Ba, 2014). In this paper, we add the well-known (Polyak)
heavy ball momentum (Polyak, 1964; Loizou & Richtdrik, 2020) to EF21, and call the resulting
method EF21-HB (Algorithm 6). See Appendix H for more details.
Proximal setting. It is common practice to solve regularized versions of empirical risk minimiza-
tion problems instead of their vanilla variants (Shalev-Shwartz & Ben-David, 2014). We thus consider
the composite/regularized/proximal problem
min φ Φ(x) =f1 PP fi(x) + r(x) ] ,	(6)
x∈Rd	n i=1
where r(x) : Rd → R ∪ {+∞} is a regularizer, e.g., `1 regularizer kxk1 or `2 regularizer kxk22. To
broaden the applicability of EF21 to such problems, we propose a proximal variant of EF21 to solve
the more general composite problems (6). We call this new method EF21-Prox (Algorithm 7). See
Appendix I for more details.
Our theoretical complexity results are summarized in Table 1. In addition, we also analyze EF21-
SGD, EF21-PAGE, EF21-PP, EF21-BC under Polyak-Eojasiewicz (PE) condition (Polyak, 1963;
Lojasiewicz, 1963) and EF21-Prox under the generalized PE-COnditiOn (Li & Li, 2018) for composite
optimization problems. Due to space limitations, we defer all the details about the analysis under the
PE-condition to the appendix and provide only simplified rates in Table 1. We comment on some
preliminary experimental results in Section 5. More experiments including deep learning experiments
are presented in Appendix A.
3 Methods
Since our methods are modifications of EF21, they share many features, and are presented in a unified
way in Table 2. At each iteration of the proposed methods, worker i computes the compressed vector
cit and sends it to the master. The methods differ in the way of computing cti but have similar (in case
4
Under review as a conference paper at ICLR 2022
of EF21-SGD, EF21-PAGE, EF21-PP - exactly the same) update rules to the one of EF21:
nn
χt+1 = χt-γgt,	gt+1 = gt + Cti,	gt+1 = nn P gi+1 = gt + nn P Cti.	(7)
i=1	i=1
The pseudocodes of the methods are given in the appendix. Below we briefly describe each method.
EF21-SGD: Error feedback and SGD. EF21-SGD is essentially EF21 but instead of the full
gradients Vfi(Xt+1), workers compute the stochastic gradients gi(χt+1), and use them to compute
Ct = C(^i(xt+1) - gt). Despite the seeming simplicity of this extension, it is highly important for
various applications of machine learning and statistics where exact gradients are either unavailable or
prohibitively expensive to compute.
EF21-PAGE: Error feedback and variance reduction. In the finite-sum regime (3), variance
reduced methods usually perform better than vanilla SGD in many situations (Gower et al., 2020).
Therefore, for this setup we modify EF21 and combine it with variance reduction. In particular, this
time we replace Vfi(xt+1) in the formula for Cit with the PAGE estimator (Li et al., 2021) vit+1. With
(typically small) probability p this estimator equals the full gradient vit+1 = Vfi(xt+1), and with
probability 1 - p it is set to
vt+1 = vt + T P (Vfij(xt+1) - Vfij(Xt)),
j∈Iit
where Iit is a minibatch of size τi. Typically, the number of data points m owned by each client is
large, and p ≤ 1/m when τi ≡ 1. As a result, computation of full gradients rarely happens during
the optimization procedure: on average, once in every m iterations only. Although it is possible to
use other variance-reduced estimators like in SVRG or SAGA, we use the PAGE-estimator: unlike
SVRG or SAGA, PAGE is optimal for smooth nonconvex optimization, and therefore gives the best
theoretical guarantees (we have obtained results for both SVRG and SAGA and indeed, they are worse,
and hence we do not include them).
Notice that unlike VR-MARINA (Gorbunov et al., 2021), which is a state-of-the-art distributed
optimization method designed specifically for unbiased compressors and which also uses the PAGE-
estimator, EF21-PAGE does not require the communication of full (non-compressed) vectors at all.
This is an important property of the algorithm since, in some distributed networks, and especially when
d is very large, as is the case in modern over-parameterized deep learning, full vector communication
is prohibitive. However, unlike the rate of VR-MARINA, the rate of EF21-PAGE does not improve
with increasing n. This is not a flaw of our method, but rather an inevitable drawback of distributed
methods that rely on biased compressors such as Top-k.
EF21-PP: Error feedback and partial participation. The extension of EF21 to the case of
partial participation of the clients is mathematically identical to EF21 up to the following change:
Cit = 0 for all clients i 6∈ St ⊆ {1, . . . ,n} that are not selected for communication at iteration t. In
practice, Cit = 0 means that client i does not take part in the t-th communication round. Here the set
St ⊆ {1, . . . ,n} is formed randomly such that Prob(i ∈ St) = pi > 0 for all i = 1, . . . , n.
EF21-BC: Error feedback and bidirectional compression. The simplicity of the EF21 mecha-
nism allows us to naturally extend it to the case when it is desirable to have efficient/compressed
communication between the clients and the server in both directions. At each iteration of EF21-BC,
clients compute and send to the master nodeCti =Cw(Vfi(Xt+1)-geit)andupdategeit+1 =geit+Cit
in the usual way, i.e., workers apply the EF21 mechanism. The key difference between EF21 and
EF21-BC is that the master node in EF21-BC also uses this mechanism: it computes and broadcasts
to the workers the compressed vector bt+1 = CM (get+1 - gt) and updates gt+1 = gt + bt+1, where
et+1 = 1 Pn=1 et+1. Vector gt is maintained by the master and workers. Therefore, the clients are
able to update it via using gt+1 = gt + bt+1 and compute Xt+1 = Xt - γgt once they receive bt+1.
EF21-HB: Error feedback with momentum. We consider classical Heavy-ball method (Polyak,
1964) with EF21 estimator gt:
nn
xt+1 =	Xt-Yvt,	vt+1 = ηvt+ gt+1,	gt+1 =	gt	+ Ct,	gt+1	= 1	Pl gt+1	=	gt	+ 1 P Ct.
The resulting method is not better than EF21 in terms of the complexity of finding ε-stationary point,
i.e., momentum does not improve the theoretical convergence rate. Unfortunately, this is common
5
Under review as a conference paper at ICLR 2022
issue for a wide range of results for momentum methods Loizou & Richtðrik (2020). However, it is
important to theoretically analyze momentum-extensions such as EF21-HB due to their importance in
practice and generalization behaviour.
EF21-Prox: Error feedback for composite problems. Finally, we make EF21 applicable to the
composite optimization problems (6) by simply taking the prox-operator from the right-hand side of
the xt+1 update rule (7): xt+1 = ProxYr (Xt — Ygt) = argminχ∈Rd{γr(x) + kx-χt+γgtk2∕2}. This
trick is simple, but, surprisingly, EF21-Prox is the first distributed method with error-feedback that
provably converges for composite problems (6).
4	Theoretical Convergence Results
In this section, we formulate a single corollary derived from the main convergence theorems for our
six enhancements of EF21, and formulate the assumptions that we use in the analysis. The complete
statements of the theorems and their proofs are provided in the appendices. In Table 1 we compare
our new results with existing results.
4.1	Assumptions
In this subsection, we list and discuss the assumptions that we use in the analysis.
4.1.1	General Assumptions
To derive our convergence results, we invoke the following standard smoothness assumption.
Assumption 1 (Smoothness and lower boundedness). Every fi has Li-Lipschitz gradient, i.e.,
∣∣Vfi(x) — Vfi (y)k ≤ Li ∣∣x - yk for all i ∈ [n],x,y ∈ Rd, and finf =f inf χ∈Rd f(x) > -∞.
We also assume that the compression operators used by all algorithms satisfy the following property.
Definition 1 (Contractive compressors). We say that a (possibly randomized) map C : Rd → Rd
is a contractive compression operator, or simply contractive compressor, if there exists a constant
0 < α ≤ 1 such that
E [∣C(x) — x∣2] ≤ (1 — α) ∣∣x∣2,	∀x ∈ Rd.	(8)
We emphasize that we do not assume C to be unbiased. Hence, our theory works with the Top-k
(Alistarh et al., 2018) and the Rank-r (Safaryan et al., 2021) compressors, for example.
4.1.2	Addtional Assumptions for EF21-SGD
We analyze EF21-SGD under the assumption that local stochastic gradients Vfξt (xt) satisfy the
following inequality (see Assumption 2 of Khaled & Richtdrik (2020)).
Assumption 2 (General assumption for stochastic gradients). We assume that for all i = 1, . . . ,n
there exist parameters Ai , Ci ≥ 0, Bi ≥ 1 such that
E h∣Vfξtj	(xt)k2	|	xti	≤	2Ai	(fi(xt)- fiinf) + BikVfi(xt)k2 +	Ci,	(9)
where1 fiinf = infx∈Rd fi(x) > -∞.
Below we provide two examples of stochastic gradients fitting this assumption (for more detail, see
(Khaled & Richtdrik, 2020)).
Example 1.	Consider Vfξt (xt) such that
EhVfξitj(xt)	|	xti	=Vfi(xt)	and E	Vfξitj(xt)	—Vfi(xt)2 |	xt	≤σi2
for some σi ≥ 0. Then, due to variance decomposition,(9) holds with Ai = 0, Bi = 0, Ci = σi2.
1When Ai = 0 one can ignore the first term in the right-hand side of (9), i.e., assumption inf x∈Rd fi (x) >
-∞ is not required in this case.
6
Under review as a conference paper at ICLR 2022
Example 2.	Let fi(x) = m^ PrIfij (x), fij be Lij-Smooth and fj = infχ∈Rd fij (x) > -∞ ∞
Following Gower et al. (2019), we consider a stochastic reformulation
mi
fi(x) = Evi〜Di[fvi(x)] = Evi〜Di	ml- Efvij (x),
(10)
i
j=1
where Evi〜Di [vj] = L One can show (see Proposition 2 ofKhaled & Richtdrik (2020)) that under
the assumption that Evi 〜Di [vj] is finite for all j stochastic gradient Vfξt. (Xt) = Nfvt (Xt) with
Vt sampled from Di satisfies (9) with Ai = maxj LijEvi 〜Di [vij-], Bi = 1, Ci = 2 Ai ∆inf, where
∆inf = m1i PAI(finf - fiinf).Inparticular if Prob(Vfξtj (xt) = Vfij(xt)) = PmitI, then
Ai = Li = m1i pm=i1 Lij, Bi = 1, and Ci= 2Ai ∆inf.
Stochastic gradient gi(χt) is computed using a mini-batch of Ti independent samples satisfying (9):
^i(xt)=f ⅛ P Vfξtj (xt).
j=1
4.1.3 Additional Assumptions for EF21-PAGE
In the analysis of EF21-PAGE, we rely on the following assumption.
Assumption 3 (Average L-smoothness). Let every fi have the form (3). Assume that for all t ≥
0, i = 1, . . . , n, and batch Iit (of size τi), the minibatch stochastic gradients difference ∆eit d=ef
T1 Pj∈[t (Vfij(xt+1) — Vfij (xt)) computed on the node i, satisfies E [△： | xt,xt+1] = ∆t and
E at - ∆t∣∣2 | xt,xt+1 ≤ LT2∣∣xt+1 - xtk2	(11)
with some Li ≥ 0, where ∆i d=f Vfi(Xt+1) - Vfi(xt). We also define L =f n Pn=I (I-Ti)Li.
This assumption is satisfied for many standard/popular sampling strategies. For example, if Iit is
a full batch, then Li = 0. Another example is uniform sampling on {1, . . . , m}, and each fij is
Lij-smooth. In this regime, one may verify that Li ≤ max1≤j≤m Lij .
4.2 Main Results
Below we formulate the corollary establishing the complexities for each method. The complete
version of this result is formulated and rigorously derived for each method in the appendix.
Corollary 1. Suppose that Assumption 1 holds. Then, there exist appropriate choices of parameters
for EF21-PP, EF21-BC, EF21-HB, EF21-Prox such that the number of communication rounds T and
the (expected) number of gradient computations at each node #grad for these methods to find an
ε-stationary point, i.e., a point XT such that E[∣Vf(XT )∣2] ≤ ε2 for EF21-PP, EF21-BC, EF21-HB
and E[∣∣Gγ(XT)∣2] ≤ ε2 for EF21-Prox, where GY(x) = 1∕γ (X — ProxYr(X — YVf(X))), are
EF21-PP:
EF21-BC:
EF21-HB:
EF21-Prox:
T=O
T = #grad = O
T = #grad = O
#grad = O
Lδ0
T Z -2
αwαMε2
T = #grad = O
where L =f JI P2ι LQ2, δ0 =f f (x0)-finf (for EF21-Prox δ0 = Φ(x0)-Φinf), p is the probability
of sampling the client in EF21-PP, αw and αM are contraction factors for compressors applied
on the workers’ and the master’s sides respectively in EF21-BC, and η ∈ [0,1) is the momentum
parameter in EF21-HB.
7
Under review as a conference paper at ICLR 2022
If Assumptions 1 and 2 in the setup from Example 1 hold, then there exist appropriate choices of
parameters for EF21-SGD such that the corresponding T and the averaged number of gradient
computations at each node #grad are
EF21-SGD:
Where σ = 1 Pn=I σ2∙
T = O(SO) , #a = O (B + ¾⅛2
If Assumptions 1 and3 hold, then there exist appropriate choices of parametersfor EF21-PAGE such
that the corresponding T and #grad are
EF21-PAGE:	T = O ((⅞L)δ0 + √mL0-), #g0d = O (m + (LoLδ0 + √mL0-),
where L =、中rLIL, τi ≡ τ = 1.
Remark: We highlight some points for our results in Corollary 1 as follows:
•	For EF21-PP and EF21-Prox, none of previous error feedback methods work on these two settings
(partial participation and proximal/composite case). Thus, we provide the first convergence results
for them. Moreover, we show that the gradient (computation) complexity for both EF21-PP and
EF21-Prox is O(1∕0ε), matching the original vanilla EF21. It means that We extend EF21 to both
settings for free.
•	For EF21-BC, We show O(1∕αwαMε2) complexity result. In particular, if one uses constant ratio
of compression (e.g., 10%), then α ≈ 0.1. Then the result will be O(1∕ε2). However, previous
result of DoubleSqueeze is O(∆∕ε3) and it also uses more strict assumption for the compressors
(E [kC(x) - xk] ≤ ∆). Even if we ignore this, our results for EF21-BC is better than the one for
DoubleSqueeze by a large factor 1∕ε.
•	Similarly, our result for EF21-HB is roughly O(1∕ε2) (note that the momentum parameter η is
usually constant such as 0.2, 0.4, 0.9 used in our experiments). However, previous result of M-CSER
is roughly O(G∕ε3) and it is proven under an additional bounded gradient assumption. Similarly, our
EF21-HB is better by a large factor 1∕ε.
•	For EF21-SGD and EF21-PAGE, we want to reduce the gradient complexity by using (variance-
reduced) stochastic gradients instead of full gradient in the vanilla EF21. Note that σ2 and ∆inf in
EF21-SGD could be much smaller than G in Choco-SGD since G always depends on the dimension
(and can be even infinite), while σ2 and ∆inf are mostly dimension-free parameters (particularly, they
are very small if the functions/data samples are similar/close). Thus, for high dimensional problems
(e.g., deep neural networks), EF21-SGD can be better than Choco-SGD. Besides, in the finite-sum
case (3), especially if the number of data samples m on each client is not very large, then EF21-PAGE
is much better since its complexity is roughly O(√m∕ε2) while EF21-SGD ones is roughly O(σ2∕ε4).
5 Experiments
In this section, we consider a logistic regression problem with a non-convex regularizer
min f (x)
x∈Rd
P log 1 + exp -biai>x + λ P
i=1
j=1
X
1+χ2
(12)
1
N
N
d
where ai ∈ Rd, bi ∈ {-1,1} are the training data, and λ > 0 is the regularization parameter, which
is set to λ = 0.1 in all experiments. For all methods the stepsizes are initially chosen as the largest
stepsize predicted by theory for EF21 (see Theorem 1), then they are tuned individually for each
parameter setting. We provide more details on the datasets, hardware, experimental setups, and
additional experiments, including deep learning experiments in Appendix A.
Experiment 1: Fast convergence with variance reduction. In our first experiment, we showcase
the computation and communication superiority of EF21-PAGE (Alg. 3) over EF21-SGD.
Figure 8 illustrates that, in all cases, EF21-PAGE perfectly reduces the accumulated variance and
converges to the desired tolerance, whereas EF21-SGD is stuck at some accuracy level. Moreover,
8
Under review as a conference paper at ICLR 2022
EF21-PAGE turns out to be surprisingly efficient with small bathsizes (eg, 1.5% of the local data )
both in terms of the number of epochs and the # bits sent to the server per client. Interestingly, for
most datasets, a further increase of bathsize does not considerably improve the convergence.
mushrooms, Top-2	w8a, Top-2	a9a, Top-2	phishing. Top-I
epochs	epochs	epochs	epochs
(a) Convergence in epochs.
w8a, Top-2
a9a, Top-2	phishing. Top-I
mushrooms, Top-2
O	IOOOOO~200000~300000
*bits∕n (C→S)
EF21-S<SD; 204βx; 25%
EF21-SGD; 2Q48x; 12.5%
EF21-5GD; 128x; 1.5%
EF2ia»AGEt512x;(25%
EF21-PA6E; 1024x; 12.5%
EF⅛1-PAGE; 1024x; 1.5%
11	,口吐*Λ∙
00
■ ■ ■ ■
--3A=
“ ⅛1⅛95 204⅞Xj 25%
-■ EF21-SGD; 2048x; 12.5%
EF21-5GD; 512x; 1.5%
-*- EF21-PAGE; 64x; 25%
EF21-PA6E; 64x; 12.5%
♦ EF21-PA6E; 64x; 1.5%
IO0
”0-2
S
昼IL
10^6
y≤9-六
二~~*^∙∙5.-*∙3∙∙-τP∙、产
*- EF21-SGD; 12BX； 25%
V---口 ∙ EF21-SGD; «4x; 12.5%
昌 EF21-SGD; 512x; 1.5%
-*- EF21-PAGE; 64x; 25%
-，EF21-PAGE; «4x; 12.5%
■ EF21-PAGE; 128x; 1.5%
ɪ'ɪ'
=ζc=
"-5^fS-s<s15"iecj¾%"
,如LW网怨p；, 4矍监熟..
■ EF2V5GD; iβx; 1.5%
* EF21-PAGE; 16x; 25%
EF21-PAGE; 16x; 12.5%
-⅜- EF21-PAGE; lβx; 1.5%
0	100000~200000~300000
*bits∕n (C→S)
0	50500 IOOOOO
*bte∕n (C→S)
0	20500	40000
*bits∕n (C→S)
(b) Convergence in terms of total number of bits sent from Clients to the Server divided by n.
Figure 1: Comparison of EF21-PAGE and EF21-SGD with tuned parameters. By 1×, 2×, 4× (and so
on) we indicate that the stepsize was set to a multiple of the largest stepsize predicted by theory for
EF21. By 25%, 12.5% and 1.5% we refer to batchsizes equal b0.25Nic, b0.125Nic and b0.015Nic
for all clients i = 1, . . . ,n, where Ni denotes the size of local dataset.
Experiment 2: On the effect of partial participation of clients. This experiment shows that
EF21-PP (Alg. 4) can reduce communication costs and can be more practical than EF21. For this
comparison, we consider n = 100 and, therefore, apply a different data partitioning, see Table 5 from
Appendix A for more details.
It is predicted by our theory (Corollary 1) that, in terms of the number of iterations/communication
rounds, partial participation slows down the convergence of EF21 by a fraction of participating
clients . We observe this behavior in practice as well (see Figure 2a). However, since for EF21-PP
the communications are considerably cheaper it outperforms EF21 in terms of # number of bits sent
to the server per client on average (see Figure 2).
mushrooms, Top-2	w8a, Top-2	a9a, Top-2	phishing. Top-I
communication rounds	communication rounds	communication rounds	communication rounds
(a) Convergence in communication rounds.
mushrooms, Top-2	w8a, Top-2	a9a, Top-2	phishing. Top-I
*bits∕n (C → S)	*bits∕n (C → S)	*bte∕n (C→S)	*bits∕n (C → S)
(b) Convergence in terms of total number of bits sent from Clients to the Server divided by n.
Figure 2: Comparison of EF21-PP and EF21 with tuned parameters. By 1×, 2×, 4× (and so on) we
indicate that the stepsize was set to a multiple of the largest stepsize predicted by theory for EF21. By
50%, 25% , 12.5% and 6.5% we refer to a number of participating clients equal to b0.5nc, b0.25nc,
b0.125nc and b0.065nc.
9
Under review as a conference paper at ICLR 2022
References
Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic. QSGD: Communication-
efficient SGD via gradient quantization and encoding. In Advances in Neural Information Process-
ing Systems (NIPS), pp.1709-1720, 2017.
Dan Alistarh, Torsten Hoefler, Mikael Johansson, Sarit Khirirat, Nikola Konstantinov, and Cedric
Renggli. The convergence of sparsified gradient methods. In Advances in Neural Information
Processing Systems (NeurIPS), 2018.
Zeyuan Allen-Zhu. Katyusha: The first direct acceleration of stochastic gradient methods. In
Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing, pp. 1200-
1205. ACM, 2017.
Yossi Arjevani, Yair Carmon, John C Duchi, Dylan J Foster, Nathan Srebro, and Blake Woodworth.
Lower bounds for non-convex stochastic optimization. arXiv preprint arXiv:1912.02365, 2019.
Sanjeev Arora, Nadav Cohen, and Elad Hazan. On the optimization of deep networks: Implicit
acceleration by overparameterization. In Proceedings of the 35th International Conference on
Machine Learning (ICML), 2018.
Amir Beck. First-Order Methods in Optimization. Society for Industrial and Applied Mathematics,
2017.
Aleksandr Beznosikov, Samuel Horvath, Peter Richtarik, and Mher Safaryan. On biased compression
for distributed learning. arXiv preprint arXiv:2002.12410, 2020.
Leon Bottou. Curiously fast convergence of some stochastic gradient descent algorithms. In
Proceedings of the symposium on learning and data science, Paris, volume 8, pp. 2624-2633,
2009.
Leon Bottou. Stochastic gradient descent tricks. In Neural networks: Tricks of the trade, pp. 421-436.
Springer, 2012.
Chih-Chung Chang and Chih-Jen Lin. LIBSVM: a library for support vector machines. ACM
Transactions on Intelligent Systems and Technology (TIST), 2(3):1-27, 2011.
Yae Jee Cho, Jianyu Wang, and Gauri Joshi. Client selection in federated learning: Convergence
analysis and power-of-choice selection strategies. arXiv preprint arXiv:2010.01243v1, 2020.
Eduard Gorbunov, Dmitry Kovalev, Dmitry Makarenko, and Peter Richtarik. Linearly converging
error compensated SGD. In 34th Conference on Neural Information Processing Systems (NeurIPS),
2020.
Eduard Gorbunov, Konstantin Burlachenko, Zhize Li, and Peter Richtarik. MARINA: Faster non-
convex distributed learning with compression. In International Conference on Machine Learning,
pp. 3788-3798. PMLR, 2021. arXiv:2102.07845.
Robert M Gower, Mark Schmidt, Francis Bach, and Peter Richtarik. Variance-reduced methods for
machine learning. Proceedings of the IEEE, 108(11):1968-1983, 2020.
Robert Mansel Gower, Nicolas Loizou, Xun Qian, Alibek Sailanbayev, Egor Shulgin, and Peter
Richtarik. SGD: General analysis and improved rates. In International Conference on Machine
Learning, pp. 5200-5209. PMLR, 2019.
Priya Goyal, Piotr Dollar, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola,
Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet
in 1 hour. arXiv preprint arXiv:1706.02677, 2017.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 770-778, 2016.
10
Under review as a conference paper at ICLR 2022
Samuel Horvgth and Peter Richtdrik. A better alternative to error feedback for CommUnication-
efficient distributed learning. In 9th International Conference on Learning Representations (ICLR),
2021.
Samuel Horvdth, Chen-Yu Ho, Ludovit Horvdth, Atal Narayan Sahu, Marco Canini, and Peter
Richtdrik. Natural compression for distributed deep learning. arXiv preprint arXiv:1905.10988,
2019a.
Samuel Horvdth, Dmitry Kovalev, Konstantin Mishchenko, Sebastian Stich, and Peter Richtdrik.
Stochastic distributed learning with gradient quantization and variance reduction. arXiv preprint
arXiv:1904.05115, 2019b.
Rustem Islamov, Xun Qian, and Peter Richtdrik. Distributed second order methods with fast rates
and compressed communication. arXiv preprint arXiv:2102.07158, 2021.
Peter et al Kairouz. Advances and open problems in federated learning. arXiv preprint
arXiv:1912.04977, 2019.
Sai Praneeth Karimireddy, Quentin Rebjock, Sebastian Stich, and Martin Jaggi. Error feedback fixes
SignSGD and other gradient compression schemes. In 36th International Conference on Machine
Learning (ICML), 2019.
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. SCAFFOLD: Stochastic controlled averaging for federated learning. In
Proceedings of the 37th International Conference on Machine Learning, 2020.
Ahmed Khaled and Peter Richtdrik. Gradient descent with compressed iterates. In NeurIPS Workshop
on Federated Learning for Data Privacy and Confidentiality, 2019.
Ahmed Khaled and Peter Richtdrik. Better theory for SGD in the nonconvex world. arXiv preprint
arXiv:2002.03329, 2020.
Sarit Khirirat, Hamid Reza Feyzmahdavian, and Mikael Johansson. Distributed learning with
compressed gradients. arXiv preprint arXiv:1806.06573, 2018.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Anastasia Koloskova, Tao Lin, S. Stich, and Martin Jaggi. Decentralized deep learning with arbitrary
communication compression. In International Conference on Learning Representations (ICLR),
2020.
Jakub Konecny, H. Brendan McMahan, Felix Yu, Peter Richtarik, Ananda Theertha Suresh, and Dave
Bacon. Federated learning: strategies for improving communication efficiency. In NIPS Private
Multi-Party Machine Learning Workshop, 2016.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
Technical report, University of Toronto, Toronto, 2009.
Guanghui Lan and Yi Zhou. An optimal randomized incremental gradient method. arXiv preprint
arXiv:1507.02000, 2015.
Guanghui Lan, Zhize Li, and Yi Zhou. A unified variance-reduced accelerated gradient method for
convex optimization. In Advances in Neural Information Processing Systems, pp. 10462-10472,
2019.
Zhize Li. ANITA: An optimal loopless accelerated variance-reduced gradient method. arXiv preprint
arXiv:2103.11333, 2021a.
Zhize Li. A short note of page: Optimal convergence rates for nonconvex optimization. arXiv
preprint arXiv:2106.09663, 2021b.
Zhize Li and Jian Li. A simple proximal stochastic gradient method for nonsmooth nonconvex
optimization. In Advances in Neural Information Processing Systems (NeurIPS), pp. 5569-5579,
2018.
11
Under review as a conference paper at ICLR 2022
Zhize Li and Peter Richtdrik. A unified analysis of stochastic gradient methods for nonconvex
federated optimization. arXiv preprint arXiv:2006.07013, 2020.
Zhize Li and Peter Richtdrik. CANITA: Faster rates for distributed convex optimization with
communication compression. arXiv preprint arXiv:2107.09461, 2021a.
Zhize Li and Peter Richtdrik. ZeroSARAH: Efficient nonconvex finite-sum optimization with zero
full gradient computation. arXiv preprint arXiv:2103.01447, 2021b.
Zhize Li, Dmitry Kovalev, Xun Qian, and Peter Richtdrik. Acceleration for compressed gradient
descent in distributed and federated optimization. In International Conference on Machine Learning
(ICML),pp. 5895-5904. PMLR, 2020.
Zhize Li, Hongyan Bao, Xiangliang Zhang, and Peter Richtdrik. PAGE: A simple and optimal
probabilistic gradient estimator for nonconvex optimization. In International Conference on
Machine Learning (ICML), pp. 6286-6295. PMLR, 2021. arXiv:2008.10898.
Nicolas Loizou and Peter Richtdrik. Momentum and stochastic momentum for stochastic gradi-
ent, Newton, proximal point and subspace descent methods. Computational Optimization and
Applications, 77:653-710, 2020.
Stanislaw Lojasiewicz. A topological property of real analytic subsets. Coll. du CNRS, Les equations
aux deriveespartielles,117(87-89):2,1963.
Konstantin Mishchenko, Eduard Gorbunov, Martin Takdc, and Peter Richtdrik. Distributed learning
with compressed gradient differences. arXiv preprint arXiv:1901.09269, 2019.
Konstantin Mishchenko, Ahmed Khaled, and Peter Richtarik. Random reshuffling: Simple analysis
with vast improvements. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (eds.),
Advances in Neural Information Processing Systems, volume 33, pp. 17309-17320. Curran As-
sociates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/
c8cc6e90ccbff44c9cee23611711cdc4-[]Paper.pdf.
Yurii Nesterov. A method for unconstrained convex minimization problem with the rate of conver-
gence o (1∕k^ 2). In DokladyAN USSR, volume 269, pp. 543-547, 1983.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style,
high-performance deep learning library. In Advances in Neural Information Processing Systems
(NeurIPS), 2019.
Constantin Philippenko and Aymeric Dieuleveut. Bidirectional compression in heterogeneous settings
for distributed or federated learning with partial participation: tight convergence guarantees. arXiv
preprint arXiv:2006.14591, 2020.
Boris T Polyak. Gradient methods for the minimisation of functionals. USSR Computational
Mathematics and Mathematical Physics, 3(4):864-878, 1963.
Boris T Polyak. Some methods of speeding up the convergence of iteration methods. Ussr computa-
tional mathematics and mathematical physics, 4(5):1-17, 1964.
Xun Qian, Peter Richtdrik, and Tong Zhang. Error compensated distributed SGD can be accelerated.
arXiv preprint arXiv:2010.00091, 2020.
Zheng Qu and Peter Richtdrik. Coordinate descent with arbitrary sampling ii: Expected separable
overapproximation. arXiv preprint arXiv:1412.8063, 2014.
Peter Richtdrik, Igor Sokolov, and Ilyas Fatkhullin. EF21: A new, simpler, theoretically better, and
practically faster error feedback. arXiv preprint arXiv:2106.05203, 2021.
Mher Safaryan, Rustem Islamov, Xun Qian, and Peter Richtdrik. FedNL: Making Newton-type
methods applicable to federated learning. arXiv preprint arXiv:2106.02969, 2021.
12
Under review as a conference paper at ICLR 2022
Frank Seide, Hao Fu, Jasha Droppo, Gang Li, and Dong Yu. 1-bit stochastic gradient descent and its
application to data-parallel distributed training of speech DNNs. In Fifteenth Annual Conference
of the International Speech Communication Association, 2014.
Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: from theory to algo-
rithms. Cambridge University Press, 2014.
Sebastian U. Stich, J.-B. Cordonnier, and Martin Jaggi. Sparsified SGD with memory. In Advances
in Neural Information Processing Systems (NeurIPS), 2018.
Hanlin Tang, Xiangru Lian, Chen Yu, Tong Zhang, and Ji Liu. DoubleSqueeze: Parallel stochastic
gradient descent with double-pass error-compensated compression. In Proceedings of the 36th
International Conference on Machine Learning (ICML), 2020.
Thijs Vogels, Sai Praneeth Karimireddy, and Martin Jaggi. PowerSGD: Practical low-rank gradient
compression for distributed optimization. In Neural Information Processing Systems, 2019.
Zhe Wang, Kaiyi Ji, Yi Zhou, Yingbin Liang, and Vahid Tarokh. Spiderboost and momentum: Faster
stochastic variance reduction algorithms. arXiv preprint arXiv:1810.10690, 2018.
Cong Xie, Shuai Zheng, Oluwasanmi Koyejo, Indranil Gupta, Mu Li, and Haibin Lin. CSER:
Communication-efficient SGD with error reset. In Advances in Neural Information Processing
Systems (NeurIPS) ,pp.12593-12603, 2020.
Haibo Yang, Minghong Fang, and Jia Liu. Achieving linear speedup with partial worker participation
in non-iid federated learning. arXiv preprint arXiv:2101.11203v3, 2021.
Tianbao Yang, Qihang Lin, and Zhe Li. Unified convergence analysis of stochastic momentum
methods for convex and non-convex optimization. arXiv preprint arXiv:1604.03257, 2016.
Yang You, Jing Li, Sashank Reddi, Jonathan Hseu, Sanjiv Kumar, Srinadh Bhojanapalli, Xiaodan
Song, James Demmel, Kurt Keutzer, and Cho-Jui Hsieh. Large batch optimization for deep
learning: Training bert in 76 minutes. In International Conference on Learning Representations,
2020. URL https://openreview.net/forum?id=Syx4wnEtvH.
HaoyU Zhao, Zhize Li, and Peter Richtdrik. FedPAGE: A fast local stochastic gradient method for
communication-efficient federated learning. arXiv preprint arXiv:2108.04755, 2021.
13
Under review as a conference paper at ICLR 2022
Table of Contents
1	Introduction	1
2	Our Contributions	2
3	Methods	4
4	Theoretical Convergence Results	6
4.1	Assumptions .............................................................. 6
4.1.1	General Assumptions ................................................ 6
4.1.2	Addtional Assumptions for EF21-SGD ................................. 6
4.1.3	Additional Assumptions for EF21-PAGE ............................... 7
4.2	Main Results ............................................................. 7
5	Experiments	8
A	Extra Experiments	15
A.1	Non-Convex Logistic Regression: Additional Experiments and Details ...... 15
A.2 Experiments with Least Squares ............................................ 20
A.3	Deep Learning Experiments ............................................... 20
B	Notations and Assumptions	22
C	EF21	23
C.1	Convergence for General Non-Convex Functions ............................ 23
C.2 Convergence under Polyak-Ecjasiewicz Condition............................. 25
D	Stochastic Gradients	27
D.1	Convergence for General Non-Convex Functions ............................ 28
D.2 Convergence under Polyak-Eojasiewicz Condition ............................ 32
E	Variance Reduction	35
E.1 Convergence for General Non-Convex Functions .............................. 37
E.2 Convergence under Polyak-Eojasiewicz Condition ............................ 41
F	Partial Participation	44
F.1 Convergence for General Non-Convex Functions .............................. 47
F.2 Convergence under Polyak-Eojasiewicz Condition ............................ 48
G	Bidirectional Compression	49
G.1 Convergence for General Non-Convex Functions .............................. 51
G.2 Convergence under Polyak-Eojasiewicz Condition ............................ 53
H	Heavy Ball Momentum	55
H.1 Convergence for General Non-Convex Functions .............................. 57
I	Composite Case	63
I.1	Convergence for General Non-Convex Functions ............................ 65
I.2	Convergence under Polyak-Eojasiewicz Condition .......................... 67
J	Useful Auxiliary Results	70
J.1 Basic Facts ............................................................... 70
J.2 Useful Lemmas ............................................................. 70
14
Under review as a conference paper at ICLR 2022
A Extra Experiments
In this section, we give missing details on the experiments from Section 5, and provide additional
experiments.
A. 1 Non-Convex Logistic Regression: Additional Experiments and Details
Datasets, hardware and implementation. We use standard LibSVM datasets (Chang & Lin, 2011),
and split each dataset among n clients. For experiments 1, 3, 4 and 5, we chose n = 20 whereas for
the experiment 2 we consider n = 100. The first n- 1 clients own equal parts, and the remaining part,
of size N - n ∙[N∕nC, is assigned to the last client. We consider the heterogeneous data distribution
regime (i.e. we do not make any additional assumptions on data similarity between workers). A
summary of datasets and details of splitting data among workers can be found in Tables 3 and 5.
The algorithms are implemented in Python 3.8; we use 3 different CPU cluster node types in all
experiments: 1) AMD EPYC 7702 64-Core; 2) Intel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz;
3) Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz. In all algorithms involving compression, we
use Top-k (Alistarh et al., 2017) as a canonical example of contractive compressor C, and fix the
compression ratio k/d ≈ 0.01, where d is the number of features in the dataset. For all algorithms, at
each iteration we compute the squared norm of the exact/full gradient for comparison of the methods
performance. We terminate our algorithms either if they reach the certain number of iterations or the
following stopping criterion is satisfied: kVf (xt)k2 ≤ 10-7.
In all experiments, the stepsize is set to the largest stepsize predicted by theory for EF21 multiplied
by some constant multiplier which was individually tuned in all cases.
Dataset	n	N (total # of datapoints)	d (# of features)	k	Ni
mushrooms	20	8,120	112	2	406
w8a	20	49,749	300	2	2,487
a9a	20	32,560	123	2	1,628
phishing	20	11,055	68	1	552
real-sim	20	72,309	20,958	210	3615
Table 3: Summary of the datasets and splitting of the data among clients for Experiments 1, 3, 4, and
5. Here Ni denotes the number of datapoints per client.
Experiment 1: Fast convergence with variance reductions (extra details). The parameters pi
of the PAGE estimator are set to Pi = P = 1 Pn=I 『.TN, where Ti is the batchsize for clients
n	i=1 τi +Ni
i = 1, . . . ,n (see Table 4 for details). In our experiments, we assume that the sampling of Bernoulli
random variable is performed on server side (which means that at each iteration for all clients bit = 1
or bit = 0). And if bti = 0, then in line 5 of Algorithm 3 Iit is sampled without replacement uniformly
at random. Table 4 shows the selection of parameter P for each experiment.
For each batchsize from the set2
{95%, 50%, 25%,12.5%, 6.5%,3%},
we tune the stepsize multiplier for EF21-PAGE within the set
{0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048}.
The best pair (batchsize, stepsize multiplier) is chosen in such a way that it gives the best convergence
in terms of #bits/n(C → S). In the rest of the experiments, fine tuning is performed in a similar
fashion.
2By 50%, 25% (and so on) we refer to a batchsize, which is equals to b0.5Nic, b0.25Nic (and so on) for all
clients i = 1, . . . ,n.
15
Under review as a conference paper at ICLR 2022
Dataset	25%	12.5%	1.5%
mushrooms	0.1992	0.1097	0.0146
w8a	0.1998	0.1108	0.0147
a9a	0.2	0.1109	0.0145
phishing	0.2	0.1111	0.0143
real-sim	0.1999	0.1109	0.0147
Table 4: Summary of the parameter choice of p.
Experiment 2: On the effect of partial participation of clients (extra details) In this experiment,
we consider n = 100 and, therefore, a different data partitioning, see Table 5 for the summary.
Dataset	n	N (total # of datapoints)	d (# of features)	k	Ni
mushrooms	100	8,120	112	2	81
w8a	100	49,749	300	2	497
a9a	100	32,560	123	2	325
phishing	100	11,055	68	1	110
Table 5: Summary of the datasets and splitting of the data among clients for Experiment 5. Here Ni
denotes the number of datapoints per client.
We tune the stepsize multiplier for EF21-PP within the following set:
{0.125,0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096}.
Experiment 3: On the advantages of bidirectional biased compression. Our next experiment
demonstrates that the application of the Server → Clients compression in EF21-BC (Alg. 5) does not
significantly slow down the convergence in terms of the communication rounds but requires much
less bits to be transmitted. Indeed, Figure 3a illustrates that that it is sufficient to communicate only
5% - 15% of data to perform similarly to EF21 (Alg. 1).3 Note that EF21 communicates full vectors
from the Server → Clients, and, therefore, may have slower communication at each round. In Figure
3b we take into account only the number of bits sent from clients to the server, and therefore we
observe the same behavior as in Figure 3a. However, if we care about the total number of bits (see
Figure 3c), then EF21-BC considerably outperforms EF21 in all cases.
3The range 5% - 15% comes from the fractions k/d for each dataset.
16
Under review as a conference paper at ICLR 2022
mushrooms, Top-2	w8a, Top-2	a9a, Top-2	phishing. Top-I
O IOOO 2000	3000	0	1000	2000	3000	0	500	1000	0	200	400
communication rounds	communication rounds	communication rounds	communication rounds
(a) Convergence in communication rounds.
mushrooms, Top-2	w8a, Top-2	a9a, Top-2	phishing. Top-I
*bits∕n (C → S)	*bits∕n (C → S)	*bte∕n (C → S)	*bits∕n (C → S)
(b) Convergence in terms of total number of bits sent from Clients to the Server divided by n.
mushrooms, Top-2	w8a, Top-2	a9a, Top-2	phishing, Top-I
*bits∕n (C→S+S→C) le6	#bits∕n (C→S+S→C) le6	*bte∕n (C→S+S→C)	*bits∕n (C→S+S→C)
(c) Convergence in terms of total number of bits sent from Clients to the Server plus the total number of bits
broadcasted from Server to Clients divided by n.
Figure 3: Comparison of EF21-BC and EF21 with tuned stepsizes . By 1×, 2×, 4× (and so on) we
indicate that the stepsize was set to a multiple of the largest stepsize predicted by theory for EF21
(see the Theorem 1) .
For each parameter k in Server-Clients compression, we tune the stepsize multiplier for EF21-BC
within the following set:
{0.125,0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048}.
Experiment 4: On the cheaper computations via EF21-SGD. The fourth experiment (see Fig-
ure 4a) illustrates that EF21-SGD (Alg. 2) is the more preferable choice than EF21 for the cases when
full gradient computations are costly.
For each batchsize from the set4
{95%, 50%, 25%,12.5%, 6.5%,3%},
we tune the stepsize multiplier for EF21-SGD within the following set:
{0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048}.
Figure 4a illustrates that EF21-SGD is able to reach a moderate tolerance in 5 - 10 epochs.
4By 50%, 25% (and so on) we refer to a batchsize, which is equals to b0.5Nic, b0.25Nic (and so on) for all
clients i = 1, . . . ,n.
17
Under review as a conference paper at ICLR 2022
mushrooms, Top-2	w8a, Top-2	a9a, Top-2	phishing. Top-I
epochs	epochs	epochs	epochs
(a) Convergence in epochs.
mushrooms, Top-2	w8a, Top-2	a9a, Top-2	phishing. Top-I
(b) Convergence in terms of the number of bits sent from Clients to the Server by each client.
Figure 4: Comparison of EF21-SGD and EF21 with tuned stepsizes. By 1×, 2×, 4× (and so on) we
indicate that the stepsize was set to a multiple of the largest stepsize predicted by theory for EF21.
By 50%, 25% (and so on) we refer to a batchsize, which is equals to b0.5Nic, b0.25Nic (and so on)
for all clients i = 1, . . . ,n.
However, due to the accumulated variance introduced by SGD, estimator EF21-SGD is stuck at some
accuracy level (see Figure 4b), showing the usual behavior of the SGD observed in practice.
Experiment 5: On the effect of heavy ball momentum. In this experiment (see Figure 5), we
show that for the majority of the considered datasets heavy ball acceleration used in EF21-HB
(Alg. 6) improves the convergence of EF21 method. For every dataset (and correspondingly
chosen parameter k) we tune momentum parameter η in EF21-HB by making a grid search over
all possible parameter values from 0.05 to 0.99 with the step 0.05. Finally, for our plots we pick
η ∈ {0.05, 0.2, 0.25, 0.4, 0.9} since the first four values shows the best performance and η = 0.9 is a
popular choice in practice.
For each parameter η from the set
{0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.99}.
we perform a grid search of stepsize multiplier within the powers of 2:
{0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048}.
mushrooms, Top-2
phishing, Tod-I
w8a, Top-2
a9a, Top-2
Figure 5: Comparison of EF21-HB and EF21 with tuned parameters in terms of total number of bits
sent from Clients to the Server divided by n. By 1×, 2×, 4× (and so on) we indicate that the stepsize
was set to a multiple of the largest stepsize predicted by theory for EF21 (see the Theorem 1) .
Experiments on a larger dataset. In these additional experiments, we test our methods on larger
problem and dataset. The dimension of the dataset used in these experiments is d = 20958. Each
method is run for 500 epochs. In this case, we observe a similar behavior as in our previous
experiments.
18
Under review as a conference paper at ICLR 2022
1 1
Z=GXBA=
real-sιmf -lbp-210
rea l-sιmf lbp-210
6
-
O
1
0 2 4
O - -
loo
1 1
Z=GxBA=
0	200	400	012
epochs	#bits/n (C → S)	le7
(a) Convergence in epochs.	(b) Convergence in terms of total number of bits sent
from Clients to the Server divided by n.
Figure 6:	Comparison of EF21-PAGE and EF21-SGD with tuned parameters. By 1×, 2×, 4× (and so
on) we indicate that the stepsize was set to a multiple of the largest stepsize predicted by theory for
EF21. By 25%, 12.5% and 1.5% we refer to batchsizes equal b0.25Nic, b0.125Nic and b0.015Nic
for all clients i = 1, . . . ,n, where Ni denotes the size of local dataset.
real-sιm, Tb p-210
2 10 12
Ooorr
Illoo
1 1
-GXm--
IO-2:
0	500
communication rounds
lol
O O _
1 1 ⅛
-GX
IO2
real-s∣m, ∣bp-210
-φ- EF21; 64x
-*- EF21-BC： Top-210(5→C): 32x
EF21-BC;T0f>-1050(5→O: 64x
-⅛- EF21-BC!Tθf>-2100(5→C): 64x
—EF21-BC； Top-5250(5 → C)； 32x
Iol
Oor
Ilo
--GXκA=
real-s∣m, ιbp-210
■ crzx； 8"
* EF21-BC： Top-210(5 -» C)； 32×
“ EF2X-3CiTop-1050(5→C); 64x
-⅛- EF21-BC：Top-2100(5→C); 54x
—EF21-BCiTop-5250(5→C); 32x
IO-2：
0	2	4
*bits∕n (C→S)
6	012	3
le6	#bits∕n(C→S+S→C) le7
(a) Convergence in communica- (b) Convergence in terms of total (c) Convergence in terms of total
tion rounds.	number of bits sent from Clients number of bits sent from Clients
to the Server divided by n.	to the Server plus the total number
of bits broadcasted from Server to
Clients divided by n.
Figure 7:	Comparison of EF21-BC and EF21 with tuned stepsizes . By 1×, 2×, 4× (and so on) we
indicate that the stepsize was set to a multiple of the largest stepsize predicted by theory for EF21
(see the Theorem 1).
Comparison to non-compressed methods. In addition, we compare EF21-PAGE and EF21-SGD
to the baseline methods without compression: PAGE (Figure 8a) and SGD (Figure 9a). In these
experiments, we observe that EF21-PAGE and EF21-SGD require much less information to transmit
in order to achieve the same accuracy of the solution as the methods without compression (PAGE,
SGD).
a9a, lbp-2	phishing. Tbp-I
mushrooms, lbp-2
w8a, lbp-2
IO0
”0-2
∣1O-*
Io-6
■---
-=*==
00
1
50000	100000	0
*bte∕n (C→S)
100
丝
⅛1O-*
10^e
20000	40000
*bits∕n (C→S)
IO0
JlO-2.
⅛1O-*
IO-6
0	100000 200000 300000	0	100000 200000	300000	0
*bits∕n (C → S)	*bits∕n (C → S)
(a) Convergence in terms of total number of bits sent from Clients to the Server divided by n.
Figure 8:	Comparison of EF21-PAGE and PAGE with tuned parameters. By 1×, 2×, 4× (and so on)
we indicate that the stepsize was set to a multiple of the largest stepsize predicted by theory for EF21.
By 25%, 12.5% and 1.5% we refer to batchsizes equal b0.25Nic, b0.125Nic and b0.015Nic for all
clients i = 1, . . . ,n, where Ni denotes the size of local dataset.
19
Under review as a conference paper at ICLR 2022
(a) Convergence in terms of total number of bits sent from Clients to the Server divided by n.
Figure 9: Comparison of EF21-SGD and SGD with tuned parameters. By 1×, 2×, 4× (and so on) we
indicate that the stepsize was set to a multiple of the largest stepsize predicted by theory for EF21.
By 25%, 12.5% and 1.5% we refer to batchsizes equal b0.25Nic, b0.125Nic and b0.015Nic for all
clients i = 1, . . . ,n, where Ni denotes the size of local dataset.
A.2 Experiments with Least S quares
In this section, We conduct the experiments on a function satisfying the PL-Condition (See AssUmP-
tion 4). In particular, we consider the least squares problem:
mRd {f3 = 1 XX (a>x - bi)2}，
Where ai ∈ Rd, bi ∈ {-1,1} are the training data. We use the same datasets as for the logistic
regression problem.
Experiment: On the effect of heavy ball momentum in P匕-Setting. For PL-Setting, EF21-HB
also improves the convergence over EF21 for the majority of the datasets (see Figure 10). Stepsize and
momentum parameter η are chosen using the same strategy as for the logistic regression experiments
(see section A.1).
O
O
0.0
0.0
1.0
leβ
250000 500000 750000
*bits∕n (C→S)
0.5
*bte∕n (C→S)
5000 IOOOO 15000
*bits∕n (C→S)
0.5	1.0
*bits∕n (C→S) le6
mushrooms, Top-2	w8a, Top-2	a9a, Top-2	phishing. Top-I
0.0	0.5
1.0	0.0	0.5	1.0
0	250000 500000 750000 O 5000	10000	15000
*bits∕n (C→S) le6
*bits∕n (C→S) le6
*bte∕n (C→S)
*bits∕n (C→S)
Figure 10: Comparison of EF21-HB and EF21 With tuned parameters in terms of total number of bits
sent from Clients to the Server divided by n. By 1×, 2×, 4× (and so on) We indicate that the stepsize
Was set to a multiple of the largest stepsize predicted by theory for EF21 (see the Theorem 2) .
A.3 Deep Learning Experiments
In this experiment, the exact/full gradient Vfi(Xk+1) in the algorithm EF21-HB is replaced by its
stochastic estimator (We later refer to this method as EF21-SGD-HB). We compare the resulting
method With some existing baselines on a deep learning multi-class image classification task. In
particular, We compare our EF21-SGD-HB method to EF21+-SGD-HB5 , EF-SGD-HB6, EF21-SGD
5EF21+-SGD-HB is the method obtained from EF21-SGD-HB via replacing EF21 by EF21 + compressor
6 EF-SGD-HB is the method obtained from EF21-SGD-HB via replacing EF21 by EF compressor
20
Under review as a conference paper at ICLR 2022
and EF-SGD on the problem of training ResNet18 (He et al., 2016) model on CIFAR-10 (Krizhevsky
et al., 2009) dataset. For more details about the EF21+ and EF type methods and their applications in
deep learning We refer reader to (RichEik et al., 2021). We implement the algorithms in PyTorch
(Paszke et al., 2019) and run the experiments on a single GPU NVIDIA GeForce RTX 2080 Ti.
The dataset is split into n = 8 equal parts. Total train set size for CIFAR-10 is 50,000. The test
set for evaluation has 10,000 data points. The train set is split into batches of size τ = 32. The
first seven Workers oWn an equal number of batches of data, While the last Worker gets the rest.
In our experiments, We fix k ≈ 0.05d, τ = 32 and momentum parameter η = 0.9.7 As it is
usually done in deep learning applications, stochastic gradients are generated via so-called “shuffle
once” strategy, i.e., Workers randomly shuffle their datasets and then select minibatches using the
obtained order (Bottou, 2009; 2012; Mishchenko et al., 2020). We tune the stepsize γ Within the
range {0.0625, 0.125, 0.25, 0.5, 1} and for each method We individually chose the one γ giving the
highest accuracy score on test. For momentum methods, the best stepsize Was 0.5, Whereas for the
non-momentum ones it Was 0.125.
The experiments shoW (see Figure 11) that the train loss for momentum methods decreases sloWer than
for the non-momentum ones, Whereas for the test loss situation is the opposite. Finally, momentum
methods shoW a considerable improvement in the accuracy score on the test set over the existing
EF21-SGD and EF-SGD.
80a,4020
ycarucca tseT
EF21÷SGD-HB
EF21-SGD-HB
EF-SGD-HB
-⅛-
EF21-SGD
EF-SGD
SSo 一 U"白
EF21+-SGD-HB
☆ EF21-SGD-HB
▽ EF-SGD-HB
△ EF21-SGD
<]EF-SGD
00
ssol tseT
1000	2000	3000	4000	5000
communication rounds
0	1000	2000	3000	4000
communication rounds
6000
1000	2000	3000	4000	5000	6000
communication rounds
Figure 11: Comparison of EF-SGD and EF21-SGD with EF-SGD-HB, EF21-SGD-HB, and EF21+-
SGD-HB with tuned stepsizes applied to train ResNet18 on CIFAR10.
7Here, d is the number of model parameters. For ResNet18, d = 11,511,784.
21
Under review as a conference paper at ICLR 2022
EF21 EF21-SGD EF21-PP	Rt = ∣∣xt+1 - xt∣∣2, δt = f(xt) - finf
EF21-PAGE	Rt = ∣∣xt+1 - xt I∣2 , δt = f (xt) - finf, Pit = IIVfi(Xt)-VtII2,* = Ilvt -gt∣2
EF21-BC	Pt = ket - Vfi(Xt)∣∣2, Rt = ∣∣χt+1 - χt∣∣2, δt = f (xt) - finf
EF21-HB	Rt = (1 - η)2 ∣∣zt+1 - zt∣∣2,δt = f(xt) - finf
EF21-Prox	Rt = ∣∣xt+1 - Xt∣∣2, Φ(x) = f(x) + r(x), δt = Φ(xt) - Φinf, GY(x) = Y (X - ProXYr(X - YVf(X)))	
Table 6: Summary of frequently used notations in the proofs.
B Notations and Assumptions
We now introduce an additional assumption, which enables us to obtain a faster linear convergence
result in different settings.
Assumption 4 (Polyak-Eojasiewicz). There exists μ > 0 such that f(x) - f (x?) ≤ 泰 ∣∣Vf (x)k2
for all x ∈ Rd, where x? = arg minx∈Rd f.
Table 6 summarizes the most frequently used notations in our analysis. Additionally, we comment on
the main quantities here. We define δt d=ef f(xt) -finf8, Rt d=ef xt+1 - xt 2. In the analysis of EF21-
HB, it is useful to adapt this notation to Rt d=ef (1 - η)2 zt+1 - zt 2, where {zt}t≥0 is the sequence
of virtual iterates introduced in Section H. We denote Gt def IlVfi(Xt) - gt∣2, Gt def * Pn=I Gi
following Richtdrik et al. (2021), where gi is an EF21 estimator at a node i. Throughout the paper
L2 def 1 Pn=ι L2, where Li is a smoothness constant for f(∙), i = 1,...,n (see Assumption 1).
8If, additionally, Assumption 4 holds, then finf can be replaced by f(x?) for x? = arg minx∈Rd f (x).
22
.(IZoZ C.M 10 囹曷£01X) XLL山 JoJ SJoojd pə-ɪBləp əsOJQq Qp>oJd 0Λ∖ CSSəuələɪduɪoo JoH
Algorithm 1 EF21									
	,n (known by nodes); g0 =				1~~I +			L s∙∣ M T ε +	
	f ∈ Rd for i = 1,...		-rygt and broadcasts.	⅛ d		+ ■ .0 5		1~~I ⅛ 5 .星 ~~I 2 ∙<s> 5 L 2 II M ∙2 r】	
	:Input: starting point x0 ∈ Rd; q	空	:fort = 0,1, 2,..., T - 1 do Master computes χt+1 = xt -	for all nodes i = 1,..., n in	：	Compress 婢=C(yfi(xt	Update local state ^+1 =	end for	Master computes gt+i 二春〉	：end for
			Z S	寸	In	9		∞	6
.0 < S 3 a (Ils + I)dl l)⅜ll0 一(S+ I)dII)II⅞llBa∕aφu
(3) . L =飞 1 1+ɪ一 出心 0 +b算(B — I)VIL+S 出
(EI) Pu? L =飞 — 1+ɪ一b70+ CtaB— I)VlL+E 出
zz c …ClUN W2zsSazdiU 3wIMIHou Daqoq ∙IUIUI9
Im U
ZZOZ xuOIaJOdEd əɔuəjəjuoɔ E SE m-aəj Jopun

(匚) - 、ɪjjVlL=(⅛)>=出
00算⅛T(⅞)J)Z LZ=M =」
.lUOPUD』EjIULlg uI——kc:・Js„0 2UIaljH3 S OlpIfpWJ FXl工
(91) ∙ (Fg + 7) 2 V 0
SbsI ulM0v UI 3Sda2l Pm}w ' Uaμdumssva ∙I uɪəjoəiɪɪ
SNolIUNn 工 XHANo。—NoN<MN七 OHunμHANoo I∙o
□ •(寸 I) URlqO əm Azz c …ClU 0 JgAO SOH=EnbOUXAOqE əipuxEJωAV ∙0 PuB φ JO UOSUyəp
əddE əʌv (PUE Cl UOHdumSSV Aq SOq ()8II) Al=Enb9Unox Aq SΛVJəjʌv
一 L=飞—1+飞=一号"L≡lv<>=aBII)Ivi
LV—1+ɪ一B77S +1)(： I)+
L≡l (2⅛>=as + I)(： I)Vl
LG 」 ()
(W) Z = (H<> I (I±⅛J>=7S +1)d— I) +
L≡l (2⅛>=as + I)(： I)Vl
L≡l(三⅛>τdII)ZVI
LG 」 (8)
-T1=I+飞<> — (W — (1+飞‹>0±6 = 一旦出”
-T1=I+飞<> — I⅛v■出口
tul,+a曳出口 L+S出
Usw才+HLa W ::脸)|| ⅛ SUgəɑ .joo.ld
Under review as a conference paper at ICLR 2022
where L = Jn P3 LQ2, θ = 1 一 (1 一 α)(1 + S), β = (1 一 α)(1 + ST) forany s > 0.
Proof. According to our notation, for Algorithm 1 Rt = xt+1 - xt2. By Lemma 1, we have
E Gt+1	≤ (1 一 θ)E Gt + βLe2E Rt .
(18)
Next, using Lemma 16 and Jensen’s inequality (119), we obtain the bound
f (xt+1) ≤ f(xt) —	2 Wf(χtW -	(2Y	- £	I Rt+2	1n n X(gt -Vfi(Xt)) i=1		2
≤ f(Xt) 一	2 MM -	g	- £	n IRt+2 n XMt- i=1		Vfi(Xt)2	
=f(xt)-	2 MM -		- £	I Rt + 2 Gt.			(19)
Subtracting finf from both sides of the above inequality, taking expectation and using the notation
δt = f(xt) 一 finf, we get
E δt+1
≤ E 忆 一 YE [W(Xt)『]-(ɪ 一 L∙) E [Rt] + YE [Gt]
(20)
Then by adding (20) with a 2γ multiple of (18) We obtain
E [δt+1]	+2γθ E[Gt+1]	≤ E[δ"	Y E	[∣∣Vf(xt)∣∣2i	- 佶	一 L∙)	E [Rt]	+ Y E [Gt]
2θ	2	2Y 2	2
+2θ (βL2E[Rt] + (1一θ)E[Gt])
=E[δt]+2θ E [Gt]- 2 E [ι∣vf(χt)『]
—
1
2γ
2 - 2θβL2) EW
—
≤ E [δt] +2θE [Gl- 2E[Wf(χt)『卜
The last inequality follows from the bound γ2 βL2 + LY ≤ 1, which holds because of Lemma 15 and
our assumption on the stepsize. By summing up inequalities for t = 0, . . . , T 一 1, we get
T-1
0 ≤ E [δT+2θGTi ≤ δ0+2θ E [G0] - 2 x E [ιι vf (χt)∣ι2].
2	2	2 t=0
Multiplying both sides by YT, after rearranging we get
X1T E [W T2i≤ Yδ0 + 中
t=0	Y
It remains to notice that the left hand side can be interpreted as E
from x0, x1, . . . , xT-1 uniformly at random.
MVf(XT 升2]
where XT is chosen
□
Corollary 2. Let assumptions of Theorem 1 hold,
gi0 = vfi(X0),	i = 1, . . . , n,
Y = (L + Lpβ∕θ∖	.
24
Under review as a conference paper at ICLR 2022
Then, afterT iterations/CommUniCation rounds of EF21 we have E IjlVf (XT)∣∣2∣ ≤ ε2. It requires
T=# grad=O (α∣2
iterations/COmmuniCatiOnS rounds/gradint computations at each node, where L = 1 p Pn=1 L,
δ0 = f(X0) - finf.
Proof. Since g0 = Vfi(X0), i = 1,...,n , we have G0 = 0 and by Theorem 1
#grad
(iv) 2δ0
≤三
(i) 2δ0 (ii) 2δ0
T ≤——≤——
一γε2 — ε2
2δ0
6Lδ0
αε2
≤
where in (i) is due to the rate (17) given by Theorem 1. In two (ii) we plug in the stepsize, in (iii)
We Use Lemma 17, and (iv) follows by the inequalities ɑ ≤ 1, and L ≤ L.	□
C.2 Convergence under POLYAK-匕OJASIEWICZ Condition
Theorem 2. Let Assumptions 1 and 4 hold, and let the stepsize in Algorithm 1 be set as
0<γ≤"(L+er2β!,.}.	(2i)
Let Ψt =f f (xt) — f (x?) + YGt. Thenfor any T ≥ 0, we have
E [ΨT] ≤ (1 — γμ)TE [Ψ0] ,	(22)
where L = qɪ Pn=1 L2,, θ = 1 — (1 — a)(1 + S), β = (1 — α)(1 + ST) forany s> 0.
Proof. We proceed as in the previous proof, but use the PL inequality, subtract f(X?) from both sides
of (19) and utilize the notation δt = f(Xt) — f(X?)
δt+1 ≤ δt-21∣Vf(Xt)∣∣2 - g-2) R+YGt
≤ δt — γμ (f(Xt) — f(X?)) — (2γ — 2) Rt + YGt.
=(I- YW- (2γ—2) Rt+γ Gt.
Take expectation on both sides of the above inequality and add it with a γ multiple of (18), then
E [δt+1] + E hθGt+1i ≤ (1 — γμ)E [δt] — 0 - 2) E [Rt] + YE [Gt]
+ Y ((1 — θ)E [Gt] + βL2E [Rt])
(I- YM)E [δt] + Y
θ
_1 -L-
2y 2
(1 - 2) Ew
学! E [Rt].
—
25
Under review as a conference paper at ICLR 2022
Note that our assumption on the stepsize implies that 1 - 2 ≤ 1 - γμ and 2γ - LL - βL2γ ≥ 0. The
last inequality follows from the bound Y2 2βL2 + YL ≤ 1, which holds because of Lemma 15 and
our assumption on the stepsize. Thus,
E [δt+1 + θGt+1i	≤ (1 - γμ)E [δt + θGti .
It remains to unroll the recurrence.	□
Corollary 3. Let assumptions of Theorem 2 hold,
gi0
Y
Then, after T iterations/communication rounds of EF21 we have E f(xT) - f(x?) ≤ ε. It requires
T = #grad = O ∖ — log
αμ
(23)
iterations/COmmUniCatiOnS rounds/gradint computations at each node, where L = JnI PZ ι L2，
δ0 = f(x0) - finf.
Proof. Notice that
min
μ
(i)
≥
min ∣μ(L + 2√2e!	,4
(ii)
≥
(iii)
≥
min卜(…!Y
}
≥
min/ —a^-,,al
(1 + 2√2)L 4 J
. a αμ α 1
minl4e, 4J
αμ
4Le
where in (i) We apply Lemma 17, and plug in θ = 1 - √1 - α according to Lemma 17, (ii) follows
by √1 - α ≤ 1 - 3∕2 (iii) follows by the inequalities α ≤ 1, and L ≤ L.
Let g0 = Vfi(x0), i = 1,...,n , then G0 = 0. Thus using (22) and the above computations, We
arrive at
#grad
log (δ0
T ≤,'，
log(1 - γμ)
(i) 1 δ0	4Le δ0
≤ γμ log( 丁J ≤ αμ log( ^εj,
where (i) is due to (122).
□
26
Under review as a conference paper at ICLR 2022
D Stochastic Gradients
In this section, we study the extension of EF21 to the case when stochastic gradients are used instead
of full gradients.
Algorithm 2 EF21-SGD
1:	Input: starting point x0 ∈ Rd; g0 ∈ Rd (known by nodes); g0 = 1 PZi g0 (known by master);
learning rate γ > 0
2:	fort = 0,1, 2, . . . ,T - 1 do
3:	Master computes xt+1 = xt - γgt and broadcasts xt+1 to all nodes
4:	for all nodes i = 1, . . . , n in parallel do
5:	Compute a stochastic gradient gi(χt+1) = 1 P；=i Vfξt. (xt+1)
6:	Compress Ci = C(gi(χt+1) - gt) and send Ct to the master
7:	Update local state git+1 = git + Cti
8:	end for
9:	Master computes gt+1 = 1 Pn=I gt+1 via gt+1 = gt + 1 Pn=ICt
10:	end for
Lemma 2. Let Assumptions 1 and 2 hold. Then for all t ≥ 0 and all constants ρ,ν > 0 EF21-SGD
satisfies
E [Gt+1 ]	≤ (1 - θ)E [Gt] + βιL2E h∣∣xt+1 - xt∣∣2i
+Aβ2E f(xt+1) - finf] + Ce2,	(24)
where θ =f	1 -	(1	- α) (1 + ρ)(1	+ V),	βι	=f	2(1 - α) (1	+ ρ)(1 + 1),
β2	=f	2(1 -	α)(1	+	ρ)(1 + 1) +	(1 + P),	4	=	maxi=1,...,n	2(Ai+LT(BT)),
Ce = 1 P (2(Ai+ Li(Bi-I)) f inf - f inf) + Ci)
i=1	i	i
Proof. For all ρ,ν > 0 we have
E[Gt+1]	= E[∣∣gt+1 -Vfi(xt+1 )∣∣2]
≤	(1 + P)E h∣∣c (gi(χt+1) - gt)-僚(xt+1) - gt) ∣∣2i
+ (1 + 1) E h∣∣^i(χt+1) -Vfi(χt+1)∣∣2i
≤	(1 - α)(1+ P)E h∣∣gt - gi(xt+1)∣∣2i
+ (1 +1) E h∣∣^i(χt+1) -Vfi (χt+1)∣∣2i
≤ (1-α)(1+P)(1+ν)Eh∣∣git-Vfi(xt)∣∣2i
+2(1 - α)(1+ ρ)(1 + 1) E h∣∣Vfi(xt+1) - gi(xt+1)∣∣2]
+2(1 - α)(1+ ρ)(1 + 1) E h∣∣Vfi(xt+1) - Vfi(Xt)∣∣[
+ (1 + 1) E h∣∣^i(xt+1)-Vfi(xt+1)∣∣2i
≤	(1 - θ)E[Gt]+ β1L⅛ h∣∣xt+1 - xt∣∣2i
+β2E h∣∣gi(xt+1) -Vfi(xt+1)∣∣2i ,
27
Under review as a conference paper at ICLR 2022
where We introduced θ =ef 1 - (1 - α)(1 + ρ)(1 + V), βι def 2(1 - α)(1 + ρ)(1 + ɪ),
β2 def 2 (1 - α)(1 + ρ)(1 + 1) + (1 + p). Next We use independence of Vfξt, (χt), variance
decomposition, and (9) to estimate the last term:
E[Gt+1]	≤ (1 - θ)E[Gt] + βιL2E[∣∣xt+1-叫[
+β XX EnVf(χt+1)-Vfi(Xt+1)H
i j=1
=(1 - θ)E [Gt] + βιL2E h∣∣xt+1 - xt∣∣2i
+β2 X (E [Ilf. (χt+1)∣∣[ -E h∣∣vfi(χt+1)∣∣2i)
≤	(1 - θ)E[Gt]+ βιL2E h∣∣xt+1 - xt∣∣2i
+2A"E [fi(xt+1) - finf] + β2( τ 1)E h∣∣Vfi(xt+1 )∣∣2i + Cτβ2
≤	(1 - θ)E[Gt]+ βιL2E h∣∣xt+1 - xt∣∣2i
,. _ , _ . , ʌ _. ʌ
+ 2(Ai + Li(Bi- 1))∕¾ E If,3+】)-即]+ 工
τi	τi
Averaging the obtained inequality for i = 1, . . . ,n We get
E [Gt+1]	≤
(1 - θ)E [Gt] + βιL2E
1n
+n X
i=1
xt+1 - xt ∣∣2
一	一、、公
2(Ai + Li(Bi-I))82
E [fi(xt+1) - fiinf] +
(1 - θ)E [Gt] + β1L2E
+n X
i=1
^ n
+β2 X
i=1
xt+1 - xt ∣∣2
一 . . . ʌ
2(Ai + Li(Bi- I))∕β2
i
2(Ai + Li(Bi - 1))
E [fi(xt+1) -
ffinf - fiinf) + Ci
τi
≤
i
i
≤
(1 - θ)E [Gt] + β1L2E [∣∣χt+1 - Xt∣2] + Aβ2E [f(Xt+1) - finf] + Cβ2
□
D.1 Convergence for General Non-Convex Functions
Theorem 3. Let Assumptions 1 and 2 hold, and let the stepsize in Algorithm 2 be set as
0<γ≤
-1
(25)
where L = ∖/ 1 Pn=I L, θ = 1 - (1 — α)(1 + ρ)(1 + V), βι =2(1 — α)(1 + ρ)(1 + 1), and
~e^,
ρ,ν > 0 are some positive numbers. Assume that batchsizes τι,...,τi are such that γ^β2 < 1, where
A = maxi=1,…,n 2(Ai+Lr(BiT)) and β2 = 2 (1 — α) (1 + ρ)(1 + ɪ) +(1 + P). Fix T ≥ 1 and
let XT be chosen from the iterates x0, x1,..., XT-1 Withfollowing probabilities:
/	~e Z	τ
Prob {XT = xt} = ^^, wt =(1------------r- ) , WT = X wt∙
28
Under review as a conference paper at ICLR 2022
Then
e[∣∣v∕(XT) I I 2] ≤
2(f (x0) - finf)
E [G0]	C%
I	F I ʌ ,
θτ (1 - Yle2)	θ
(26)
1
where C =-
n
P
i=1
Ti
finf- finf)+ m).
T
”(1 -甯)
2(Ai +Li(Bi— 1))
Proof. We notice that inequality (20) holds for EF21-SGD as well, i.e., we have
E [δt+1]	≤ E [δt] - YE [ I I Vf(Xt)I I 2] - (2Y - L) E [Rt] + YE [Gt]
Summing up the above inequality with a ⅛ multiple of (24), we derive
2θ
E δt+1 + -γGt+1
L	2θ
E [δt] - 2E
E [Rt] + YE [Gt]
+得§』2旧[Rt]
2θ
220220
A1⅛E [δt+1] + 守%
≤
"O
≤
爹E w+1]+E FGt
2θ
-YE [IIVf(Xt)II2] + 小
2	2θ
—
:2- Yf2)E [Rt]

(25)
≤
YfE w+1]+E ]δt+∕t
2θ
-2E [IIVf(Xt)II2] + 2^⅜,
where θ =f 1 - (1 - α) (1 + ρ)(1 + V), % =f 2(1 - α) (1 + ρ) (1 + 1), % =f 2(1 - α) (1 +
P) 0 + -) + (1 + p), and ρ,ν > 0 are some positive numbers. Next, we rearrange the terms
2
Y
2
Y
ɪ E [Gt+1]
2θ
1 + 工 E [Gt+1 ]
2θ L j
sum UP the obtained inequalities for t = 0,1,...,T with weights wt∕wτ, and use the definition of xT
T
E [ I I Vf(XT)I I 2]	=	W： X WtE [ I I Vf(Xt) I I 2]
K t=0
≤	X(WtE
YWTf
~ ʌ
Jβ2
+-K-
θ
2δ0
≤ -----
_	YWT
δt + 工 Gt - Wt+1E δt+1 + ɪ E[Gt+1]
2θ	2θ
E[G0]	C%2
+ ^	+ ʌ ∙
θWτ
2θ
≤

θ
—
29
Under review as a conference paper at ICLR 2022
Finally, we notice
TL	e	e^ ^ tt
WT = X Wt ≥(T +1) t=min.,τ wt >t (1 — ~2τ)
that finishes the proof.	□
Corollary 4. Let assumptions ofTheorem 3 hold, P = α∕2, V = α∕4,
_	1
L+LqeF
T = max ( 1 2Tγ (Ai + Li(Bi - I)) β 8 (Ai + Li(Bi - I)) β Jinf 4Ciβ )]
Ti - max [ ,	θ	,	θε2	i , eε2 ∫ I,
Γ	jl6δ0 8E[G0]1]
T - max ,	,
[γε2	θε2	∫ I
where δiinf = finf-	fiinf, δ0 = f(x0)-	finf. Then, after T iterations of EF21-SGD we have
E h∣∣ Vf (xτ)∣∣2i ≤ ε2. It requires
T=O
Lδ0 + E [G0]
αε2
iterations/communications rounds,
#gradi
τiT
L δ0 + E [G0]
αε2
Lδ0 + E
+
α3ε4
O
+
(Lδ0 + E [G0])AiE [G0]
α2 (αL + Le)ε4
stochastic oracle calls for worker i, and
# grad
1n
n XTiT
i=1
O
Lδ0 + E [G0]	1 X
+ n
L δ0 + E
αε2
i=1
α3ε4
1n
+1X
n i=1
(Lδ0 + E [G0])AiE [G0]
α2 (aL + L)ε4
〜
stochastic oracle calls per worker on average, where Ai = Ai + Li (Bi — 1).
e ^ T
Proof. The given choice of τi ensures that(1 — Y^e2) = O(1) and c∕¾∕θ ≤ ε∕2. Next, the choice
of T ensures that the right-hand side of (26) is smaller than ε. Finally, after simple computation we
get the expression for TiT.
□
Corollary 5. Consider the setting described in Example 1. Let assumptions of Theorem 3 hold,
P = α∕2, ν = α∕4,
T
1
γ
16δ0 8E [G0]
max	, —τ-----
ɪ γε2 , θε2
)1
30
Under review as a conference paper at ICLR 2022
where δ0 = f(x0) — finf. Then, after T iterations of EF21-SGD we have E IjMf(XT )∣∣2∣ ≤ ε2 .It
requires
T = O L Lδ0 + E W !
αε2
iterations/communications rounds,
#gradi
τiT=O
Lδ0 + E [G0]	(Lδ° + e [G0]) σi
aε2	+	α3ε4
stochastic oracle calls for worker i, and
# grad
1 X _	(Lδ0 + E [G0]	(Lδ° + E [G0]) σ2
n ɪ-j, TTT	。I	αε2	+	α3ε4
stochastic oracle calls per worker on average, where σ2 = 1 En=I σ2.
Corollary 6. Consider the setting described in Example 2. Let assumptions of Theorem 3 hold,
P = α∕2, V = α∕4,
1
γ
Ti
T
max 1,
— —O — O	—	. ∙ r O
2TγLiβ2 8Liβ2 δinf 8Li∆i l∕3∙2
i , ~θε2~
)1
16δ0 8E [G0]
max	, -K-----
ɪ γε2 , θε2
)1
^
θ
where 肥=finf - finf, δ0 = f (x0) - finf, Li =m Pm=I Lj ∆^ =m Pm=乂/严—fj).
Then, after T iterations of EF21-SGD we have E [∣∣Vf (XT)∣∣2] ≤ ε2. It requires
T=O
Leδ0 + E [G0]
αε2
iterations/communications rounds,
#gradi = TiT
_	LZ6。+ E [G。]	(Lδ0 + E [G0]) (Li(δ0 + δinf) + Li∆Tnf)
α ( αε2	+	ɑ3ε4
(Lδ0 + E [G0])LiE [G0]
+ ------------⅛——--1
α2 (αL + Le)ε4
stochastic oracle calls for worker i, and
# grad
1n
1 X TiT
n i=1
O
Lδ0 + E [G0]	1 X
n
Leδ0 + E
[g0]) (Li(δ0+δinf)+Li∆inf)
αε2
i=1
1n
+1X
n i=1
α3ε4
(eδ0 + E [G0] )LiE [G0]
α2 (aL + L)ε4
stochastic oracle calls per worker on average.
31
Under review as a conference paper at ICLR 2022
D.2 Convergence under POLYAK-匕OJASIEWICZ Condition
Theorem 4. Let Assumptions 1, 2, and 4 hold, and let the stepsize in Algorithm 2 be set as
0 <γ ≤ min (( L + Lj 2βj-
(27)
where L = ∖∕1 Pt- L2, θ =1 — (1 — α)(1+ ρ)(1 + V), β- =2(1 — α)(1 + ρ) (1 + 1), and
e ^
ρ,ν > 0 are some positive numbers. Assume that batchsizes τ1,...,τi are such that 2-^β2 ≤ 2,
where A = maxi=ι,...,n 2(Ai+LT(BiT)) and β2 =f 2 (1 — α) (1 + ρ) (1 + 1) + (1 + 1). Thenfor
all T ≥ 1	'
E δτ + γGτ ≤ (1 — γμ)T E ]δ0 + γG0 +[Cβ2,	(28)
where C = - P (2(AVBT)) (finf — /'nf) + C).
i=1 '	/
Proof. We notice that inequality (20) holds for EF21-SGD as well, i.e., we have
E [δt+1]
≤ E [δt]—2E [is)I I 2] — g—L)E [Rt]+2E G
≤ (I-YM)E [δt] -	—2)E [Rt]+YE [Gl ∙
Summing up the above inequality with a γ^ multiple of (24), we derive
E δt+1 + γGt+1
θ
(1 — γμ)E [δt] ― (2γ - ]) E [Rt] + YE [Gt]
+ Y(I — θ)E [Gt] + γβ-L2E [Rt]
+yA⅛e [δt+1] + yC⅛
θθ
e ^
手 E[δt+1] +(1—Y4)E[δt] +
θ
1 L	Yβ-L2	[ M
2Y — 2 - -T E国]
YGt
ɪ n	Γ	~∖
≤	^β2E [δt+1] +(1 — Yμ)E δt + YGt + 1Cβ2,
θ 」	」	L θ J θ
where θ =f 1 — (1 — α) (1 + ρ)(1 + V), β- =f 2(1 — α) (1 + ρ) (1 + 1), β2 =f 2(1 — α) (1 +
ρ) (1 + 1) + (1 + p), and ρ,ν > 0 are some positive numbers. Next, we rearrange the terms
δt+1 + YGt+1
θ
(1 —学)δt+1 + YGt+1
,,
≤
≤
E
Y
+ / Cβ2
—
≤
E
≤ (1 — Yμ)E δt + YGt + Y(5§2
and divide both sides of the inequality by (1 — γAβ2)
E /t+1 + YGt+1
≤
(120)
≤
32
Under review as a conference paper at ICLR 2022
^-
Since -Ae ≤ 2 and Y ≤ 2 ,wehave
E ,+ 1 + γ^ Gt+1	≤	(1 - γμ)(1 + γμ) E δt + Y Gt + 2γCβ-
(?)(1- γμ) E [δt + YGt 1 +2YCβ-.
、	2)	^	^ J θ
Unrolling the recurrence, we get
E δT +
≤
≤
(1- Yμ)TE [s。+ YG
^ θ
(1- Yμ)TE [δ0 + YG。
2	2 )	[	θ
(1-斗)TE [δ0 + YG。
I	2)	L	θ
that finishes the proof.
□
Corollary 7. Let assumptions ofTheorem 4 hold, P = α∕2, V = α∕4,
1
筝2μ卜
Y
τi
T
min --------
I L + L
max 1,
，.	_	, _	. . O
8 (Ai + Li(Bi- I)) β-
’2	2δ0 口
——ln (----+ E
Yμ I ε
μθ
-2τG01
. θε _
,.	_ , _	. . O	. . O
64 (Ai + Li(Bi- I)) β2 sinf 32ciβ2
i ,
θεμ	θεμ
where δinf = finf 一 f叫 δ0 = f (x0) 一 finf. Then, after T iterations of EF21-SGD we have
E f(xT) - finf ≤ ε. It requires
T=O
iterations/communications rounds,
#gradi
τiT
O
工 + L (Ai，]?' ) + Ci) ]ln (S0 + E [竺 D
μα	μ2α3ε	ε Lε J)
stochastic oracle calls for worker i, and
# grad
n
μ2α3ε
δ0 E
ln (-----+ E
stochastic oracle calls per worker on average, where Ai = Ai + Li (Bi - 1).
e ^
Proof. The given choice of Ti ensures that 2Aβ2- ≤ 2 and AC闾μθ ≤ ε∕2. Next, the choice of T
ensures that the right-hand side of (28) is smaller than ε. Finally, after simple computation we get the
expression for TiT.	□
33
Under review as a conference paper at ICLR 2022
Corollary 8. Consider the setting described in Example 1. Let assumptions of Theorem 4 hold,
P = α∕2, V = α∕4,
γ = min
Ti= max [1,工 \
θ θεμ J
where δ0 = f(x0) - finf. Then, after T iterations of EF21-SGD we have E f(xT) - finf ≤ ε. It
requires
T=O
iterations/communications rounds,
#gradi
TiT
O
+
Leσi2	δ0
μ⅛ lnd+E
stochastic oracle calls for worker i, and
# grad
O
+
μ2α3ε
δ0
ln (-----+ E
stochastic oracle callsPer worker on average, where σ2 = 1 PZi σ2.
Corollary 9. Consider the setting described in Example 2. Let assumptions of Theorem 4 hold,
ρ = α∕2, V = α∕4,
)— ʌ	— ʌ	=	.∙rC∖-∣
8Li^2 64Liβ2	f 64Li∆infβ2 1
1,	,	δi- ,	,
μθ θεμ i θεμ Jl
[-ɪin (2δ0 + E [2γG0])],
γμ ∖ ε I_ θε」/
where 趾=finf - f严,δ0 = f (x0) - finf, Li = 7^ PrI Lj △/ =m £着(/严-fj).
Then, after T iterations of EF21-SGD we have E f(xT) - finf ≤ ε. It requires
iterations/communications rounds,
stochastic oracle calls for worker i, and
______	1 二
#grad = n 工 TiT
〜
O
μα
1n
1X
n
i=1
L
一 +
stochastic oracle calls per worker on average.
34
Under review as a conference paper at ICLR 2022
E Variance Reduction
In this part, we modify the EF21 framework to better handle finite-sum problems with smooth
summands. Unlike the online/streaming case where SGD has the optimal complexity (without
additional assumption on the smoothness of stochastic trajectories) (Arjevani et al., 2019), in the finite
sum regime, it is well-known that one can hope for convergence to the exact stationary point rather
than its neighborhood. To achieve this, variance reduction techniques are instrumental. One approach
is to apply a PAGE-estimator (Li et al., 2021) instead of a random minibatch applied in SGD. Note
that PAGE has optimal complexity for nonconvex problems of the form (3). With Corollary 10, We
illustrate that this O (m + √m∕ε2) complexity is recovered for our Algorithm 3 when no compression
is applied and n = 1.
We show how to combine PAGE estimator with EF21 mechanism and call the new method EF21-
PAGE. At each step of EF21-PAGE, clients (nodes) either compute (with probability p) full gradients
or use a recursive estimator Vt + τ1 Pj∈∕ (Vfi7- (χt+1) -Nfij(Xt)) (with probability 1 - p). Then
each client applies a Markov compressor/EF21-estimator and sends the result to the master node.
Typically the number of data points m is large, andp < * 1/m. As a result, computation of full gradients
rarely happens during optimization procedure, on average, only once in every m iterations.
Notice that unlike VR-MARINA (Gorbunov et al., 2021), which is a state-of-the-art distributed
optimization method designed specifically for unbiased compressors and which also uses PAGE-
estimator, EF21-PAGE does not require the communication of full (not compressed) vectors at all. This
is an important property of the algorithm since, in some distributed networks, and especially when d
is very large, as is the case in modern over-parameterized deep learning, full vector communication is
prohibitive. However, unlike the rate of VR-MARINA, the rate of EF21-PAGE does not improve with
the growth of n. This is not a flaw of our method, but rather an inevitable drawback of the distributed
methods that use biased compressions only.
Notations for this section. In this section, we use the following additional notations Pit d=ef
kVfi(xt) - vtk2, Pt =f n P乙 Pit, V =f kvt - gtk2, Vt =f n P乙 Vit where Vt is a PAGE
estimator. Recall that Gt def 1 Pn=1 Gt Gt def IlVfi(Xt) - gt『.
The main idea of the analysis in this section is to split the error in two parts Git ≤ 2Pit + 2Vit , and
bound them separetely.
Algorithm 3 EF21-PAGE
1:	Input: starting point x0 ∈ Rd; g0, v0 ∈ Rd for i = 1,...,n (known by nodes); g0 = 1 PZi g0
(known by master); learning rate γ > 0; probabilities pi ∈ (0,1]; batch-sizes 1 ≤ τi ≤ mi
2:	fort = 0,1,2,.. .,T - 1 do
3:	Master computes Xt+1 = Xt - γgt
4:	for all nodes i = 1, . . . , n in parallel do
5:	Sample b；〜Be(Pi)
6:	If bit = 0, sample a minibatch of data samples Iit with |Iit| = τi
(Vfi(Xt+1)	if bt = 1,
7:	vt+ = <υ+ + τi P(Vfij (χt+1)-Vfij (Xt)) if bi = 0
I	' j∈Ii
8:	Compress cit = C(Vit+1- git) and send cit to the master
9:	Update local state git+1 = git + cti
10:	end for
11:	Master computes gt+i = 1 Pi=I gt+i via gt+i = gt + 1 Pi=ICt
12:	end for
13:	Output: XT chosen uniformly from {xt}t∈[τ]
Lemma 3. Let Assumption 3 hold, and let vt+i be a PAGE estimator, i. e. for btt 〜 Be(Pi)
(Vfi(Xt+1)	if bti = 1,
vt+ = Vt + τ1i P(Vfij(Xtr)-Vfij(Xt)) if bi = 0,	(29)
I	j∈ι
35
(IE) - L=;二ɪ一 T7(h I) + LS⅛i; I)Vl
一=j+i出 ±血甩；I)SVI
』<— 五=出(这— I) + L=(Z⅛J> I 竺一国(这I I)Sll
』<—苜+ (飞)\> —上一出(或—1)=
一』(飞<> + (&<>— 苜 + w)alɪ国(3 II) H
(I+飞<> I ((H)<> I (I+H)‹>k『+」一国(这1 I) H
L = (W‹>II+Z一出 H LtE 出
.joo-td
.s ⅛. I-Hf H uμ¾¾1(y) Is.!IMfH
OE) 一 L =飞—1+飞=一国心 + L旦⅛HE; I)vlL+ħj出
WlOΛI2 ⅛t : : ~1 =二«」归
ZZOZ xuOIaJOdEd əɔu^jəjuoɔ E SE m-aəj Jopun
9S
(SE) - L≡II⅛v0+l≡i≡v(bii)ViL=I⅛ii⅛t
()J0 DnEUB UE qM dn puə əMPuB IjQ SJEUI5 二əip Aq
POlnlHSqnSuq (2)v^> PUE (I+2)7^> qΛV Inq」EuluI ə= JOJOOJd Ul Sdols ωqlUIΛ∖工.β}ald
•0 八 S 3』OJ
(TS + I)d—I) U 0.(s+I)dII)II U B :二工 Xem H xem⅜¾1d!r) Is"M山 UgaWM
(*) ~ L=: 1+ɪ一 国(0+ 心Z)"鼠国营拿 + CL出(。— ɪ)vlL+L出
UaIil .0k 二：ClU7D 巨
§⅛)0u¾后 J⅛)0±6J⅛
.3.1 5DUrμsa IZ工§6 WIPUD
So'Ujq ⅛ ((H)<>I(I+H)<>)W小+S
一I = jq⅛(I+«‹>
0z√ ∙ : ClU7D 巨
PllD (23①〜XOJ .2 .0 UoIDulHSa HoVdI+0 CPloq E PEI Sjdiws5v7 τUIUI9
□ ∙; : ClU IgAOWbOEAOqE ətp əmejəAEsuuɪəj =
*S uldmnssv Aq spq () PUBH =Q Jw L/一方——ɪ 国 əsnEɔəg spq (2) Al=EnbQ əjəlp^
Under review as a conference paper at ICLR 2022
where θ = 1 一 (1 一 α)(1 + s), β = (1 一 α)(1 + ST) for any s > 0. Then
EVit	= E git+1 一 vit+12
(≤)	(1-θ)E [∣∣gt -Vt『]+ βE [∣∣vt+1-vt∣∣2i
=	(1 一 θ)E hgit 一 vit2i + βE hE hvit+1 一 vit2 |vit,xt,xt+1ii
=(1 一 θ)E Ml + βPiE h∣∣vt 一 Vfi(Xt+1)∣∣2i
+β(1- Pi)E J] X(Vfij(xt+1)-Vfij(xt))∣ j
=(1 — e)E[Vi1+ βPiE h∣∣vt -Vfi(Xt+1)∣∣2i + 户(1一Pi)E ∣∣∆t∣∣2
(=ii)
(iii)
(iv)
≤
(1 一 θ)E [Kt] + 2βgE [∣∣vt - Vfi(Xt)∣∣[
+2βgE h∣∣Vfi(xt+1)-Vfi(Xt)∣∣2i + 尸(1一Pi)E ∣∣∆t∣∣2
(1 一 θ)E [Vit] + 2βgE [Pt] + 2βgE [∣∣∆t∣∣2i + β(1 -Pi)E ∣∣∆t∣∣2
(1 - θ)E [Vit] +2βpiE[pt] + β(2pi + 1 -Pi)E [∣∣∆t∣∣2i
+β(1-Pi)E ∣∣∆t - ∆t∣∣j
(1 一 θ)E [Vit] + 2βgE [Pt] + β(1+ g)L2E [∣∣χt+1 一 χt∣∣2]
+β(I-*LE h∣∣xt+1 - xt∣∣2i
(1 - θ)E [Vit] + 2βPmaχE [Pit] + β(2L2 + (I-Tpi)L2 ) E [∣∣xt+1 — xt∣∣2],
≤
where in (i) we use the definition of PAGE estimator (32), (ii) applies (119) with s = 1, (iii) is due
to bias-variance decomposition (123), (iv) makes use of Assumptions 1 and 3, and the last step is
due to Pi ≤ 1, Pi ≤ Pmax .
It remains to average the above inequality over i = 1, . . . , n.
□
E.1 Convergence for General Non-Convex Functions
Theorem 5. Let Assumptions 1 and 3 hold, and let the stepsize in Algorithm 3 be set as
0 < γ ≤ (L + S4βL2 +2 f3ePmax + ɪ)"L!	.	(36)
θ	θ Pmin	Pmin
Fix T ≥ 1 and let XT be Chosenfrom the iterates x0,x1,..., XT-1 uniformly at random. Then
E [∣∣v∕(XT)∣2i ≤ 2Ψ0,	(37)
where Ψt =f f (Xt) — finf + +Vt + Pmin(1 + 2βpmin) Pt, PmaX = maxi=ι,…,n Pi, Pmin =
mini=ι,…,nPi, L = J温 Pn=I L2，θ = 1 一(1 — α)(1 + S), β = (1 — α)(1 + ST) for any
s > 0.
37
Under review as a conference paper at ICLR 2022
Proof. We apply Lemma 16 and split the error ∣∣gt - ▽力(Xt)Il2 in two parts
f(Xt+1) ≤ f(Xt) - 2 Wf(Xt)II2 - (ɪ - 2) Rt + 2 忖-W(Xt)II2
≤ f(χt)-2Wf(χt)∣ι2-(2γ-2)Rt
+γ∣∣gt - VtII2 + YE [I∣vt -Vf(Xt)II2]
≤ f(Xt) - 2iiVf(Xt)II2 - (2γ - 2) Rt
In	In
+Yn XII9t	iI I I + n nXIE -Vfi(Xt)II2
i=1	i=1
=f(Xt) - 2IIVf(Xt)II2 - (ɪ - 2) Rt + YVt + γPt,	(38)
where we used notation Rt = IIYgtI∣2 = I[Xt+1 - XtI2, and applied (118) and (119).
Subtracting finf from both sides of the above inequality, taking expectation and using the notation
δt = f (Xt+1) - fιnf, we get
E [δt+1]
E [st]- 2E [ I I Vf(Xt) I I 2] - (ɪ -
2)
E [Rt] + YE [Vt] + YE [Pt] . (39)
≤
Further, Lemma 3 and 4 provide the recursive bounds for the last two terms of (39)
E[Pt+1]	≤ (1 - Pmin)E [Pt] + L2E [Rt],	(40)
E [Vt+1]	≤ (1 -	θ)E [Vt]	+ β(2L2	+ L2)	E	[Rt] + 21⅜maχE	[Pt]	.	(41)
Adding (39) with a 得 multiple of (41) we obtain
E [δt+1] + YE [Vt+1] ≤ E [δt] - 2E [ I I Vf(Xt) I I 2] - & - 2) E [Rt] + YE [Vt]
+yE [Pt] + Y ((1 - θ) E [Vt] + Art + CE [Pt])
≤	δt +	θE	[Vt]	-	2E	[ I I Vf(Xt)	I I 2]	-	(ɪ - L - YA)E	[Rt]
+Y (1 + C) e [P t],
where we denote A =f β(2L2 + £2), C =f 2βpmaχ.
Then adding the above inequality with a pγ- (1 + 多)multiple of (40), we get
38
Under review as a conference paper at ICLR 2022
E[Φt+1]
E [δt+1] + Y E [Vt+1] +
θ
≤ δt+θ
1+C E [P t+1]
L
2
E Rt
≤E
—
—
—
L
2
号-Pi C+C) L2) E [Rt]
—
—
1
2Y
2 -亨-pɪ(1+C) L2) E [Rt].
(42)
一I ----
The coefficient in front of E [Rt] simplifies after substitution by A and C
YA + ɪ (ι + NL ≤ 2βL2 +借詈 + ɪ)L2.
θ	pmin	θ	θ	θ pmin	pmin
Thus by Lemma 15 and the stepsize choice
--------------------------∖ -1
当L + 2 (3βPmax + ɪ) £2)
θ	θ pmin	pmin
0<γ
(43)
the last term in (42) is not positive. By summing up inequalities for t = 0, . . . , T - 1, we get
T-1
0 ≤ e[φt] ≤ E [Φ0] - Y X E[∣∣Vf(xt)∣∣2].
2 t=0
Multiplying both sides by 备 and rearranging we get
X T E h∣∣vf (χt)∣∣2i≤ ?.
t=0	Y
It remains to notice that the left hand side can be interpreted as E Ijl▽/(XT) |:],where XT is chosen
from x0, x1, . . . , xT-1 uniformly at random.
□
Corollary 10. Let assumptions of Theorem 5 hold,
-1
Then, after T iterations/COmmUniCatiOn rounds of EF21-PAGE we have E [，▽/(XT)∣∣2] ≤ ε2. It
requires
39
Under review as a conference paper at ICLR 2022
T=O
(L + L)δ0
αε2
PmaX
Pmin
o----CCO
mmaXLδ0
ε2
iterations/communications rounds,
#gradi
stochastic oracle calls for worker
O
O
# grad
stochastic oracle calls per worker on average, where T = -1 P2ι Ti, m = 1 PZi mi, mmax
maxi=1,...,n mi, PmaX = maxi=1,...,n Pi, Pmin = mini=1,...,n Pi.
Proof. Notice that by Lemma 17 we have
L J + 2 (3β箸 + Pmn) L2
L+jθ62 L2+2
12 PmaX
α Pmin
Pmin
Le2
4
L + -L +
24 PmaX
α Pmin
Pmin
4
L + -L
√24
PmaX
Pmin
√24
PmaX
Pmi
L+
PmaX
■、
Pmin
L+L +
√Pmin
PmaX
■、
Pmi
L + L) + 2√mmaxL,
≤
≤
≤
≤
≤
≤
α
α
+
1
5 L
α
α
5
α
5
α

α



+ ɪ L

L + " L



L

L

where We used L ≤ L, Pmin ≤ Pmax, and the fact that √a + b ≤ √α + ʌ/b for a, b ≥ 0.
Then the number of communication rounds
T
≤
≤
2δ0
I C Γ~~.	C
+ 2√mmαxL
O
(Le + Le)δ0
αε2
PmaX
Pmin
7----CCO
mmaXLδO
ε2
At each worker, we have
#gradi
mi + T (Pimi + (1- Pi)Ti)
mi
+ 2miτi T
Ti + mi
≤
mi + 2TiT.
Averaging over i = 1, . . . ,n, we get
40
Under review as a conference paper at ICLR 2022
#grad ≤
m+ 2τT
O (m + T(L + L)δ Jpmax +
αε	pmin
o----CCO
τ√m
maxLδ0
ε2
E.2 Convergence under POLYAK-匕OJASIEWICZ Condition
Theorem 6. Let Assumptions 1 and 4 hold, and let the stepsize in Algorithm 3 be set as
θ pmin
0 <γ ≤ minr。，而于
(44)
where Y。= 0 < Y ≤ (L + J等L2 +4 (竿既 + 熹)L2)[ L = J1 工乙 LL, θ
1 — (1 — α)(1 + S), β = (1 — α)(1 + ST) forany s > 0.
Let Ψt =f f(xt) 一 f(x?) + 2γ Vt + p2γ-(1 + 4βpmax ) Pt. Thenfor any T ≥ 0, we have
E [Ψt] ≤ (1 一 γμ)τE [Ψ0].
(45)
Proof. Similarly to the proof of Theorem 5 the inequalities (39), (40), (41) hold with δt = f(xt) —
f(x?).
Adding (39) with a 2γ multiple of (41) We obtain
- YE [皿(力『]-& -1 - 2γA) E[Rt]
+Y(1 + 2C) E [p t],
E
□
where A d=ef β 2Le2 +Le2 , C d=ef2βpmax.
Then adding the above inequality with a m (1 + 2C) multiple of (40), we get
pmin	θ
41
Under review as a conference paper at ICLR 2022
E Ψt+1
+ 三(1 + 2C) E[pt+1]
pmin	θ
L
2
—
E Rt
≤E
+ P~~ (1 + ~g~) ((I- Pmin)E [Pt] + L2E [Rt])
+PmYn (1+2C) E 尸](1一 等)
- L - 子-A (1 + 2C) L2) E[Rt].
—
(46)
PL inequality implies that δt 一 2 ∣∣Vf (xt)k2 ≤ (1 一 γμ)δt. In VieW of the above inequality and our
assumption on the stepsize (Y ≤ 2μ, Y ≤ pmn ), we get
E [ψt+1] ≤ (I-M)E [ψt] - (2Y 一 2 一 2γA 一 Pmn (1 + 2C) L2) E [Rt].
The coefficient in front of E [Rt] simplifies after substitution by A and C
2yA+/(1+2C”
θ	Pmin	θ
4βL2 +(空 + 3 + 8βPmɑx)
θ	θ Pmin	。PminJ
4βL2 + 2 (迥3X + ɪ) L2.
θ	θ Pmin	Pmin
Le2
Thus by Lemma 15 and the stepsize choice
0<γ
审e +4
-------------------\ -1
5β Pmax +	\ e \
θ Pmin Pmin
(47)
the last term in (46) is not positive.
E [ψt+1] ≤ (1 - γμ)E [Ψt].
It remains to unroll the recurrence.
Corollary 11. Let assumptions of Theorem 6 hold,
vi0
g0 = Nfi(X。), i = 1,...,n,
θ Pmin
min U0,2μ,不
8βe2 + 4
-------------------\ -1
5β Pmax +	1 ʌ Le2 \
θ Pmin	Pmin
pi
τi
τi + mi
i = 1, . . . , n.
≤
—
□
γ
Then, after T iterations of EF21-PAGE we have E f(xT) - finf ≤ ε. It requires
T = O (1 (L + L 产
μ α V Pmin
√ mmαxL ln
42
Under review as a conference paper at ICLR 2022
iterations/communications rounds,
#gradi
stochastic oracle calls for worker i, and
#grad	= O I m	+ T ∣ L +	L ʌ IIpmax	+ √mmaχLe)	ln
∖ μ ∖ α V Pmin	)
stochastic oracle calls per worker on average, where T = -1 En=I T, m = 1 E2ι mi，mmax
maxi=1,...,nmi, pmax = maxi=1,...,n pi, pmin = mini=1,...,n pi.
43
Under review as a conference paper at ICLR 2022
F	Partial Participation
In this section, We provide an option for partial participation of the clients - a feature important in
federated learning. Most of the works in compressed distributed optimization deal with full worker
participation, i.e., the case When all clients are involved in computation and communication at every
iteration. HoWever, in the practice of federated learning, only a subset of clients are alloWed to
participate at each training round. This limitation comes mainly due to the folloWing tWo reasons.
First, clients (e.g., mobile devices) may Wish to join or leave the netWork randomly. Second, it is
often prohibitive to Wait for all available clients since stragglers can significantly sloW doWn the
training process. Although many existing works (Gorbunov et al., 2021; HorVgth & Richtdrik, 2021;
Philippenko & Dieuleveut, 2020; Karimireddy et al., 2020; Yang et al., 2021; Cho et al., 2020) alloW
for partial participation, they assume either unbiased compressors or no compression at all. We
provide a simple analysis of partial participation, which works with biased compressors and builds
upon the EF21 mechanism.
The modified method (Algorithm 4) is called EF21-PP . At each iteration of EF21-PP , the master
samples a subset St of clients (nodes), which are required to perform computation. Note, that all
other clients (nodes) i ∈/ St participate neither in the computation nor in communication at iteration t.
We allow for an arbitrary sampling strategy of a subset St at the master node. The only requirement
is that Prob (i ∈ St) = pi > 0 for all i = 1, . . . , n, which is often referred to as a proper arbitrary
sampling.9 Clearly, many poplular sampling procedures fell into this setting, for instance, independent
sampling with/without replacement, τ -nice sampling. We do not discuss particular sampling strategies
here, more on samplings can be found in (Qu & Richtdrik, 2014).
Algorithm 4 EF21-PP (EF21 with partial participation)
1:	Input: starting point x0 ∈ Rd; g0 ∈ Rd for i = 1,...,n (known by nodes); g0 = 1 PZi gi
(known by master); learning rate γ > 0
2:	fort = 0,1, 2, . . .,T - 1 do
3:	Master computes xt+1 = xt - γgt
4:	Master samples a subset St of nodes (|St| ≤ n) such that Prob (i ∈ St) = pi
5:	Master broadcasts xt+1 to the nodes with i ∈ St
6:	for all nodes i = 1, . . . , n in parallel do
7:	if i ∈ St then
8:	Compress Ct = C(^fi(χt+1) - gt) and send Ci to the master
9:	Update local state git+1 = git + Cit
10:	end if
11:	ifi ∈/ St then
12:	Do not change local state git+1 = git
13:	end if
14:	end for
15:	Master updates git+1 = git, Cit = 0 for i ∈/ St
16：	Master computes gt+1 = 1 Pn=I gt+1 via gt+1 = gt + 1 Pn=ICt
17: end for
Lemma 5. Then for Algorithm 4 holds
E Gt+1 ≤ (1 - θp)E Gt + BE hxt+1 - xt2i	(48)
with θp = ρpmin + θp
max - ρ - (pm
ax-Pmin), B d= 1 Pn=I C⅜i + (1+ PT) (I- Pi)) L2,
Pmax = max1≤i≤n pi, Pmin = min1≤i≤n pi, θ = 1 - (1 + S)(I - α), β = (1 + S) (1 - α) and
small enough P, s > 0.
Proof. By (13) in Lemma 1, we have for all i ∈ St
E Git+1 | i ∈ St ≤ (1 - θ)E Git +βLi2E hxt+1 - xt2 | i ∈ Sti	(49)
9It is natural to focus on proper samplings only since otherwise there is a node i, which never communicaties.
This would be a critical issue when trying to minimize (1) as we do not assume any similarity between fi(∙).
44
Under review as a conference paper at ICLR 2022
with θ = 1 - (1 + s)(1 - α), β = (1 + S) (1 - α) and arbitrary s > 0.
Define Wt =f {gtt,…，成,xt, xt+1] and let i ∈ St, then
E Gt+1∣ i/St] = E[E[Gi+1∣ Wt] | i/St]
=E [e [∣∣gt+1 -v∕i(χt+1)∣∣21 Wt] ∣ i/St]
≤ (1 + P)E [e [ ∣ ∣ gi -Vfi(Xt) ∣ ∣ 2 ∣ W t] ∣ i/St]
+	(1 + PT) E [e [ ∣ ∣ Vfi(xt+1) -Vfi(xt) ∣ ∣ 2 ∣ W t] ∣ i/St]
≤ (1 + P)E [Gi]
+	(1 + PT) E [ ∣ ∣ Vfi(xt+1) - Vfi(xt) ∣ ∣ 2 ∣ i/St]
≤ (1 + P)E [Gi]+ (1 + PT) L⅛ [ ∣ ∣ xt+1 - xt∣∣2] .	(50)
Combining (49) and (50), we get
E [Gt+1 ]
1 n
1 X E [Gt+1]
n ∙	1
i=1
(49),(50)
≤
1 ʌ ............................1	3	................
-X PiE [Gt+1 ∣ i ∈ St] +- X (1 - Pi) E [Gt+1 ∣ i/St]
i=1	i=1
[ n	n n n	∖
(1 -θ)- XPiEW + β - XPiL2 E [ ∣ ∣ xt+1 - xt∣∣2]
i=1
i=1
1n
+ (1+ P) - X (1 - Pi) E [Gi]
n i=1
+ (1+ PT) (n X(1 - Pi)L2) E [∣∣xt+1 - xt∣∣2]
(i)
≤
1n
(1 - θ)Pmɑx n ɪ2 E [Gt] + β
i=1
1X PiL2) E [ ∣ ∣ xt+1 -xt∣∣2]
1n
+ (1+ P)(I- Pmin) - ɪ2 E [Gt]
n L
i=1
+ (1+ PT) (n X(1 - Pi)L2) E [∣∣xt+1 - xt∣∣2]
((1 - θ)Pmax + (1+ P)(1 - Pmin)) E [Gt]
+ (n X (βPi + (1 + PT) (1 - Pi)) L2) E [ ∣ ∣ xt+1 - xt∣∣2]
1 - (PPmin + θP
max - P - (Pm
ax -Pmin)) ) E [Gt]
+ (n X (βPi + (1 + PT) (1 - Pi)) L2) E [ ∣ ∣ xt+1 - xt∣∣2].
(1 - θp) E [Gt] + BE [ ∣ ∣ xt+1 - xt∣∣2],
□
45
Under review as a conference paper at ICLR 2022
Lemma 6. [To simplify the rates for partial participation] Let B and θp be defined as in Theorems 7
and Theorems 8, and let pi = p > 0 for all i = 1, . . . , n . Then there exist ρ, s > 0 such that
θp ≥ pα,
(51)
(52)
Proof. Under the assumption that pi = p for all i = 1, . . . , n, the constants simplify to
θp = ρp + θp - ρ,
B = (βp + (1 + PT) (1 - P)) L2,
pmax = pmin = p.
Case I:	let α = 1, p = 1, then the result holds trivially.
Case II:	let 0 < α < 1,p = 1, then B = βL2 , θp = θ = 1 - √1 - α ≥ 2 and (52) follows by
Lemma 17.
Case III: let α = 1, and 0 < p < 1, then θ
Then the choice P = Rpap) simplifies
1,β = 0,B
(1 + PT) (1 - P)L2, θp = P - ρ(1-p).
p
2,
θp
B _ (1 + PT) (1 - p)L2 _ 2(1 - p)L2 (2 力 < 4L2
θp	P - ρ(1 - p)	P	∖p J p p2
Case IV: let 0 < α < 1,and 0 < p < 1.Then the choice of constants θ = 1 - (1 - α) (1 + s),
β =(1 - α) (1 +1), p = 4(ραp), S = 4(⅛ yields
pP + θp - P
p(P+ 1 - (1 -α) (1 + s)) - P
pα - p(1 -α)s - (1 - p)P
1
2 Pa.
(53)
Also
1 + 1 = E <4, 1 + 1
sαα P
4(1 - p) + αp	4 - p(4 - α)
pα
pα
V 4
pα
Thus
B _ Pe + (I -P) (1 + P) ~2 _
--=------:---7-----L	=
θp	p(P+ θ) - P
<
p(1 - α) (1 + S) +(1 - P) (1 + P)工2
2 pα
P(I - O)4 +(I -P)P4; L2
2 Pa
4 +2〜
a I Pa e2
2 Pa
8
<
<
<
■— —
16L2
p2 a2
(54)
□
46
Under review as a conference paper at ICLR 2022
F.1 Convergence for General Non-Convex Functions
Theorem 7. Let Assumption 1 hold, and let the stepsize in Algorithm 4 be set as
0<γ≤
(55)
Fix T ≥ 1 and let XT be Chosenfrom the iterates x0,x1,..., xτ-1 uniformly at random. Then
E [W(XT)∣∣2i≤ 2 MT fin')+ EθGT01	(56)
γT	θp T
with θp = ρpmin + θp
max - ρ - (pm
ax-Pmin), B = n Pn=I βpPi + (1+ PT) (I- Pi)) L2,
Pmax = max1≤i≤n pi, pmin = min1≤i≤n pi, θ = 1 - (1 + S)(I - α), β = (1 + S) (1 - α) and
ρ, s > 0.
Proof. By (20), we have
E [δt+1]	≤ E [δt] - YE[∣∣Vf(Xt)Il[ - (2γ -力 E [Rt] + YE [Gt] .	(57)
Lemma 5 states that
E [Gt+1] ≤ (1 -θp)E [Gt] +BE [Rt]	(58)
with θp = ρPmin + θP
max - ρ - (Pm
ax-Pmin), B = n Pi=I IeIPi + (1+ PT) (I- Pi)) L2,
Pmax = max1≤i≤n Pi, Pmin = min1≤i≤n Pi, θ = 1 - (1 + S)(I - α), β = (1 + S) (1 - α) and
small enough P, s > 0.
Adding (57) with a 2^ multiple of (58) and rearranging terms in the right hand side, We have
E [δt+1] + ɪE [Gt+1]	≤ E [δt] + ɪE [Gt]
2θp	2θp
-2E h||vf (χt)∖∖2]- (21γ- L- Yl) E[Rt]
≤ E [δt]+2Yγ-E [Gt] - 2E h∣∣vf(χt)∣ι2].
The last inequality follows from the bound Y2 B + LY ≤ 1, which holds because of Lemma 15 and
our assumption on the stepsize. By summing up inequalities for t = 0, . . . , T - 1, we get
T-1
0 ≤ E hδT + 2YθGτ] ≤δ0 + 2θE [G0] - 2 X E h∣lvf(Xt)Il2].
2	2	2 t=0
Multiplying both sides by 备,after rearranging we get
X1TE h∣∣vf(Xt)Il2] ≤ 寺 + 萼.
t=0	Y
It remains to notice that the left hand side can be interpreted as E [∣∣ Vf(Xτ) ∣∣2], where Xτ is chosen
from X0, X1, . . . , XT-1 uniformly at random.
□
Corollary 12. Let assumptions of Theorem 7 hold,
47
Under review as a conference paper at ICLR 2022
where B and θp are given in Theorem 7. Then, after T iterations/communication rounds of EF21-PP
we have E Ijl▽/(XT)∣∣2∣ ≤ ε2. It requires
Leδ0
T=#grαd=O (行
(59)
iterations/communications rounds/gradint computations at each node.
Proof. Let g0 = Nfi(x0), i = 1,...,n , then G0 = 0 and by Theorem 7
#grad
(i) 2δ0 (ii) 2δ0
T ≤——≤——
― γε2 — ε2
2δ0
L +4L
(iv) 2δ0
≤第
C ~	~
pα pα
5Lδ0
αε2
≤
~
α
where (i) is due to the rate (56) given by Theorem 7. In two (ii) we use the largest possible stepsize
(55), in (iii) We utilize Lemma 6, and (iv) follows by the inequalities α ≤ 1, P ≤ 1 and L ≤ L. 口
F.2 Convergence under POLYAK-匕OJASIEWICZ Condition
Theorem 8. Let Assumptions 1 and 4 hold, and let the stepsize in Algorithm 4 be set as
0 < γ ≤ min
(60)
Let Ψt =f f (xt) 一 f(x?) + θLGt. Thenfor any T ≥ 0, we have
E [Ψt] ≤ (1 一 γμ)τE [Ψ0]	(61)
with θp = ρPmin + θP
max 一 ρ 一 (Pm
ax一 Pmin)，B = 1 PNI βpPi + (1+ PT) (I- Pi)) L2，
Pmax = max1≤i≤n pi，pmin = min1≤i≤n pi，θ = 1 一 (1 + S)(I — α)，β = (1 + S) (1 一 α) and
P, s > 0.
Proof. Following the same steps as in the proof of Theorem 2, but using (58), and assumption on the
stepsize (60), we obtain the result.	口
Corollary 13. Let assumptions of Theorem 8 hold，
γ
Pi
where B and θp are given in Theorem 8. Then， after T iterations/communication rounds of EF21-PP
we have E f(xT) 一 f(x?) ≤ ε. It requires
T= #grad = O
(62)
iterations/communications rounds/gradint computations at each node.
Proof. The proof is the same as for Corollary 3. The only difference is that Lemma 6 is needed to
upper bound the quantities 1∕θp and B∕θp, which appear in Theorem 8.	口
48
Under review as a conference paper at ICLR 2022
G B idirectional Compression
In the majority of applications, the uplink (Client → Server) communication is the bottleneck.
However, in some settings the downlink (Server → Client) communication can also slowdown
training. Tang et al. (2020) construct a mechanism which allows bidirectional biased compression.
Their method builds upon the original EF meachanism and they prove O (黄/3) rate for general
nonconvex objectives. However, the main defficiency of this approach is that it requires an additional
assumption of bounded magnitude of error (there exists ∆ > 0 such that E kC(x) - xk2i ≤ ∆
for all x). In this section, we lift this limitation and propose a new method EF21-BC (Algorithm 5),
which enjoys the desirable O 谆)，and does not rely on additional assumptions.
Algorithm 5 EF21-BC (EF21 with bidirectional biased compression)
1:	Input: starting point x0 ∈ Rd; g0, b0, gei0 ∈ Rd for i = 1, . . . , n (known by nodes); ge0
* pn=1 ee0 (known by master); learning rate γ > 0
2:	fort = 0,1, 2, . . . ,T - 1 do
3:	Master updates xt+1 = xt - γgt
4:	for all nodes i = 1, . . . , n in parallel do
5:	Update xt+1 = xt - γgt, gt+1 = gt + bt,
6:	compress Ct = Cw(Vfi(χt+1) - g1t), send Ci to the master, and
7:	update local stategeit+1 =geit+Cit
8:	end for
9:	Master computes gt+1 = 1 Pn=I gt+1 via gt+1 = gt + * Pn=1 ct,
10:	compreses bt+1 = CM (get+1 - gt), broadcast bt+1 to workers ,
11:	and updates gt+1 = gt + bt+1
12:	end for
Note that CM and Cw stand for contractive compressors of the type 1 of master and workers respec-
tively. In general, different αM and αw are accepted.
Notations for this section: Pit =f ∣∣7t - Vfi(Xt)『,Pt =f ɪ Pn=I Pt.
Lemma 7. Let Assumption 1 hold, Cw be a contractive compressor, and geit+1 be an EF21 estimator
of Vfi(xt+1 ), i. e.
geit+1 =geit+Cw(Vfi(xt+1) -geit)	(63)
for arbitrary gei0 and all all i = 1, . . . , n, t ≥ 0. Then
EPt+1 ≤ (1 -θw)E Pt + βwLe2E Rt ,	(64)
where θw =f 1 — (1 — aw)(1 + s),	βw =f (1 — αw)(1 + ST) for any s > 0.
Proof. The proof is the same as for Lemma 1.	□
Lemma 8. Let Assumption 1 hold, CM, Cw be contractive compressors. Let geit+1 be an EF21
estimator of Vfi (xt+1), i. e.
geit+1 =geit+Cw(Vfi(xt+1)-geit),	(65)
and let gt+1 be an EF21 estimator of gt+1 = 1 P*=1 eet+1, i. e.
gt+1 =gt+CM(get+1 -gt)	(66)
for arbitrary g0, gei0 and all i = 1, . . . , n, t ≥ 0. Then
E hgt+1-get+12i ≤ (1 -θM)E hgt -get2i +8βME Pt +8βMLe2E Rt ,	(67)
Where gt = ɪ Pn=I gt, ge = 1 Pn=1 get, θM = I-(I- αM)(I + P), βM = (I- αM) (1 + PT)
for any ρ > 0.
49
Under review as a conference paper at ICLR 2022
Proof. Similarly to the proof of Lemma 1, define Wt d=ef {g1t , . . . , gnt , xt, xt+1} and
E hgt+1	-	get+12i	= EhEhgt+1-get+12 | Wtii
= E hE hgt + CM (get+1 - gt) - get+12 |Wtii
≤	(1 - αM)E hget+1 - gt2i
≤	(1 - αM)(1 + ρ)E hget - gt2i
+(I- αM) (1 + PT) ∣∣et+1 - et∖∖2
= (1-θM)E hgt - get2i + βM get+1 - get2,	(68)
where (i) follows by Young’s inequality (118), and in (ii) we use the definition of θM and βM.
Further we bound the last term in (68). Recall that
1n
et+1 = et + -X ct.	(69)
n i=1
where Ct = Cw(Vfi(Xt+1) - et) and et = 1 Pn=I 7t. Then
E h∣∣et+1-et∣∣2i	(=) E 卜 + nXCt -et∣ 1
≤)	nXE h∣Cit∣2i
i=1
n
=n XE [∣∣ct - (yfi(χt+1) - et) + (Vfi(Xt+1)- gt)∣∣ ]
n i=1
n
≤	2nXE hE h∣∣Cw (Vfi(Xt+1)-et) -(Vfi(Xt+1)-et)∣∣2 | Wtii
n i=1
n
+2 - X E h∣vfi(χt+1) - et∣2i
n i=1
nn
≤	2(1 -αw)nXEh∣vfi(χt+1)-et∣∣2i +2XEh∣vfi(χt+1)-et∣∣2i
n i=1	n i=1
=2(2 - αw)n XE h∣Vfi(xt+1) - gt∣∣2i
n i=1
(<)	4nXE hHVMXt+1) -et∣2i
n i=1
n
=4n XE [∣Vfi(xt+1) - Vfi(Xt) - (et - Vfi(xt)) ∣2]
i=1
nn
≤	8nX ∣et -Vfi(Xt)∣2 + 8-XE h∣∣Vfi(Xt+1) - Vfi(Xt)∣2i
i=1	i=1
(i≤	8nXE h∣et -Vfi(Xt)∣∣2i +8L2E h∣∣Xt+1 -Xt∣∣2i
i=1
=	8E Pt + 8Le2E Rt ,	(70)
50
Under review as a conference paper at ICLR 2022
where in (i) we use (119), (ii) is due to αw > 0, (iii) holds by Assumption 1. In the last step we
apply the definition of Pt = n PZi llet - Vfi(χt)k2, and Rt = ∣∣χt+1 - χt∣∣2
Finally, plugging (70) into (68), We conclude the proof.	□
G.1 Convergence for General Non-Convex Functions
Theorem 9. Let Assumption 1 hold, and let the stepsize in Algorithm 5 be set as
0<γ≤
16βM
Θm
-i
(71)
Fix T ≥ 1 and let XT be Chosenfrom the iterates x0,x1,..., XT-1 uniformly at random. Then
E h∣∣vf(χT )∣∣2i ≤ 2EγP,	(72)
where ψ = f31 - f inf + θM kgt - etk2 + θW (1 + 符)P t,L = J1 PL L2, θw = 1 — (1 -
Qw)(I + S),	∣βw =(I - αw) (1 + s-1), θM = 1 -(I - αM)(1 + P), Bm =(I - αM) (1 + p-1)
for any ρ, s > 0.
Proof. We apply Lemma 16 and split the error lgt - Vf(Xt)l2 in tWo parts
f(χt+1)	≤	f(Xt)	- 2 ∣∣Vf(Xt)∣∣2 - g	- L)	Rt	+ 2∣∣gt-Vf(χt)∣∣2
≤	f(χt)	- 21∣Vf(Xt)∣∣2 -(2γ	- 2)	Rt
+γ∣∣gt - get∣∣2 + γ ∣∣get - Vf (Xt)∣∣2
≤	f(χt) - 2∣∣Vf(Xt)∣∣2 -(2γ - L) Rt
nn
+γ- X∣∣gt-et∣∣2+γ- X∣ 悌-Vfi(Xt)∣∣2
i=i	i=i
=f(Xt) - 2∣∣Vf(Xt)∣∣2 - (2γ - L) Rt + γ∣∣gt- et∣∣2 + YPt,	(73)
where we used notation Rt = IlYgtk2 = ∣∣Xt+1 - Xt∣∣2, Pt = ɪ Pn=Iket -Vfi(Xt)∣2 and applied
(118) and (119).
Subtracting finf from both sides of the above inequality, taking expectation and using the notation
δt = f(Xt+i) - finf, we get
E [δt+1]	≤ E	[δt]	- 2E h∣∣Vf (Xt)∣∣2i	- (2γ	- 2) E [Rt]	+ YE	h∣∣gt	-	et∣∣2i +	YE	[Pt].
(74)
Further, Lemma 7 and 8 provide the recursive bounds for the last two terms of (74)
E [Pt+i] ≤ (1 -θw)E[Pt] + βwLe2E [Rt],	(75)
E ∣∣gt+i	-get+i∣∣2	≤ (1-θM)E	∣∣gt	- get∣∣2	+8βMLe2E[Rt]+8βME[Pt]	. (76)
51
Under review as a conference paper at ICLR 2022
Summing up (74) with a 卷 multiple of (76) we obtain
E w+1] + θ^E [ l l gt+1- et+1l∣2]	≤ E [δt]- 2E [∣∣v∕ (χt)∣∣2] -QY - 2)E 此
+γE [ l l gt- et∣∣2] + YE [Pt]
+
+
θM ((IjM 闾犷-e『D
θ^ 卜βML2E [Rt] + 8βME [Pt])
≤ E W] + 氐E [忖-etl∣2] - Ye[∣∣v∕(χt)l∣2]
1
药
_ _ ~i-,
_ L _ 8γβM L2
—
+γ i+
2	Θm
8βM) E [Pt].
θM )
E [Rt]
Then adding the above inequality with a 声
1+
multiple of (75), we get
E [Ψt+1]
E [δt+1] + ɪE [ ll产-/1Il2] + ɪ (1 + 8βM) E [Pt+1]
Θm L	」θw ∖	UMl
≤
≤
E 忆 + UL E [l∣gt- etll2]
Um	L	」
—
2γ
L 8γβM L2
UM
E [Rt]
+Y
1 + 8βM[ E [Pt]
UM )
1
—
2
—
1 1 L 8γβM L2 γβw L2 A 8βMʌA „
(2Y - 2 - F 丁 C + 衍〃 E
Thus by Lemma 15 and the stepsize choice
0 <Y ≤ (l + Ls 陪 + 会卜 + 答)[
the last term in (77) is not positive. By summing up inequalities for t = 0,...,T - 1, we get
T-1
0 ≤ e[ψt] ≤ E[Ψ0] - 2 X e[∣∣v∕(χt)∣∣2].
2 t=0
Multiplying both sides by * and rearranging we get
X1TE[ll3 l l 2] ≤ 2eyP.
t=0	γ
(77)
(78)
52
Under review as a conference paper at ICLR 2022
It remains to notice that the left hand side can be interpreted as E Ijl▽/(XT) ∣∣2], where XT is chosen
from x0, x1, . . . , xT-1 uniformly at random.
□
Corollary 14. Let assumption of Theorem 9 hold,
g0
Vf (x0),	g0 = Vfi(X0),	i = 1,...,n,
γ
-1
Then, after T iterations/communication rounds of EF21-BC we have E
requires
[∣∣Vf(XT)∣∣2] ≤ ε2.
It
T = #grad = O
αwαMε2
(79)
iterations/communications rounds/gradint computations at each node.
Proof. Note that by Lemma 17 and αM, αw ≤ 1, we have
16βM + 2βw(1 + 出)≤
≤
≤
16-^ +2^ f1 + 8-^λ)
α2M	αw2	α2M
64	8 33
αM	aW aM
64 + 8 ∙ 33
αW α2	.
It remains to apply the steps similar to those in the proof of Corollary 2.
□
G.2 Convergence under POLYAK-匕OJASIEWICZ Condition
Theorem 10. Let Assumptions 1 and 4 hold, and let the stepsize in Algorithm 3 be set as
0 < γ ≤ min γ0,
Θm θw
2μ，2μ
(80)
WhereY0 =f (l + Lr* + 普卢(1 + 陪)); L = ^PlL，% =f 1 — (1 - aw)(1 +
S), βw =(I - αwM1 + s-1)，θM = 1 -(I - αM)(I + P), βM =(I - αM) (1+ P-1) for any
ρ, s > 0.
Let Ψt =f f (xt) 一 finf + θγ- ∣∣gt 一 7t『+ θɪ (1 + 8θM) Pt. Thenfor any T ≥ 0, we have
E [Ψt] ≤ (1 一 γμ)τE [Ψ0].
(81)
Proof. Similarly to the proof of Theorem 9 the inequalities (74), (75), (76) hold with δt = f(Xt) 一
f(X?).
It remains to apply the steps similar to those in the proof of Theorem 6.	□
Corollary 15. Let assumption of Theorem 10 hold,
g0 = Vf(X0),	gei0 = Vfi(X0),	i = 1, . . . , n,
Y = min h0,⅛⅛｝，	γ0=0+L[
32βM	4βwL
+ θw
θM
；Γ
53
Under review as a conference paper at ICLR 2022
Then, after T iterations of EF21-PAGE we have E f(xT) - finf ≤ ε.
It requires
T = #grad = O
~
Le
μaw a.
iterations/communications rounds/gradint computations at each node.
54
Under review as a conference paper at ICLR 2022
H Heavy Ball Momentum
Notations for this section: Rt = kγgt k2 = (1 - η)2 zt+1 - zt 2 .
In this section, we study the momentum version of EF21. In particular, we focus on Polyak style
momentum (Polyak, 1964; Yang et al., 2016). Let gt be a gradient estimator at iteration t, then the
update rule of heavy ball (HB) is given by
Xt+1 = Xt — Ygt + η (Xt — xt-1),
where x-1 = x0, η ∈ [0, 1) is called the momentum parameter, and γ > 0 is the stepsize. The above
update rule can be viewed as a combination of the classical gradient step
yt = Xt — γgt
followed by additional momentum step
xt+1 = yt + η (Xt- xt-1).
Here the momentum term is added to accelerate the convergence and make the trajectory look like a
smooth descent to the bottom of the ravine, rather than zigzag.
Equivalently, the update of HB can be implemented by the following two steps (Yang et al., 2016):
Xt+1 = Xt - γvt
vt+1 = ηvt + gt+1.
We are now ready to present the distributed variant of heavy ball method enhanced with a contractive
compressor C, and EF21 mechanism, which we call EF21-HB (Algorithm 6). We present the
complexity results in Theorem 11 and Corollary 16.
Algorithm 6 EF21-HB
1:	Input: starting point X0 ∈ Rd; gi0 ∈ Rd for i = 1, . . . , n (known by nodes); v0 = g0 =
* pn=ι g0 (known by master); learning rate γ > 0; momentum parameter 0 ≤ η < 1
2:	fort = 0,1, 2, . . .,T - 1 do
3:	Master computes Xt+1 = Xt - γvt and broadcasts Xt+1 to all nodes
4:	for all nodes i = 1, . . . , n in parallel do
5:	Compress Ci = C(Vfi(χt+1) - gt) and send Ct to the master
6:	Update local state git+1 = git + Cti
7:	end for
8:	Master computes gt+1 = ɪ P*=ι gt+1 via gt+1 = gt + * P*=ι Ct, and vt+1 = ηvt + gt+1
9:	end for
In the analysis of EF21-HB, we assume by default that v-1 = 0.
Lemma 9. Let sequences {Xt}t≥0 , and {vt}t≥0 be generated by Algorithm 6 and let the sequence
{zt}t≥0 be defined as zt+1 =f xt+1 — ɪ--nVt with 0 ≤ η < 1. Thenfor all t ≥ 0
zt+1 = Zt- -^tgt.
1-η
Proof. zt+1	(=i)	Xt+1 - (=ii)	Xt - γv	Uvt 1-η t -工 Vt 1-η
" zt + UVt 1-η =Zt- ɪ 0 1 -η =zt - 1 1-η	-1 - ɪvt 1-η t - ηVt-1 ,
55
Under review as a conference paper at ICLR 2022
where in (i) and (iii) we use the definition of zt+1 and zt, in (ii) we use the step xt+1 = xt - γvt
(line 3 of Algorithm 6). Finally, the last equality follows by the update vt+1 = ηvt + gt+1 (line 8 of
Algorithm 6).
□
Lemma 10. Let the sequence {vt}t≥0 be defined as vt+1 = ηvt + gt+1 with 0 ≤ η < 1. Then
T-1	T-1
Xmr占xa『.
t=0	η t=0
Proof. Unrolling the given recurrence and noticing that v-1
H def Pt=o ηl ≤ ι-η. Then by Jensen's inequality
0, we have vt = Plt=0 ηt-lgl . Define
T-1	T-1 t t l 2
XM2 = H2 X X *gl
t=0	t=0 l=0
T-1 t	t-l
≤ H2 XX ηH- M『
T-1 t
= H X Xηt-l gl2
T-1 t
≤ 占XXηFgl『
η t=0 l=0
T-1	T-1
=占 XM『X ηt-1
l=0	t=l
T-1
≤ (i⅛ XM2.
t=0
□
Lemma 11. Let the sequence {zt}t≥0 be defined as zt+1 d=ef xt+1
-BnVt with 0 ≤ η< LThen
T-1	T-1	T-1
X E Gt+1 ≤(1-θ)XEGt +2βLe2(1+4η2)XE zt+1 - zt2 ,
t=0	t=0	t=0
where θ = 1 — (1 — α)(1 + s), β = (1 — α) (1 + ST) for any s > 0.
Proof. Summing up the inequality in Lemma 1 (for EF21 estimator) for t = 0, . . . , T - 1, we have
T-1	T-1	T-1
X E [Gt+1] ≤ (1 — θ) X E [Gt] + βL2 X E[∣∣xt+1 - xt∣∣2] .	(82)
t=0	t=0	t=0
It remains to bound PtT=-01 E ∣∣xt+1 — xt ∣∣2 . Notice that by definition of {zt }t≥0, we have
xt+1 — xt
zt+1 - zt + -^η- (Vt- VtT
1 — η
56
Under review as a conference paper at ICLR 2022
Thus
T-1
X E hxt+1 - xt2i ≤
t=0
2 X E ［忖+1-z% +(S X E ［忖-VtT『］
t=0	( - η) t=0
T-1	2 2 T-1
2 X E ［归+1-z% +(⅛ X E ［Wil一 机T『］
t=0	( - η) t=0
≤
T-1
2 X E hzt+1 - zt2i
t=0
+ } Σ E hM2i
t=0
+(4-2⅛ X(1 - η)2E ［kvt-1k2］
η t=0
(i)
≤
(=ii)
T-1	2 2 T-1
2 X E ［忖+1-Z 们 +(4⅛ X E ［犷『］
t=0	( - η) t=0
+(4-⅛ X1E ［M2i
t=0
T-1	2 2 T-1
2 X E ［忖+1-Zt『］+(⅛ X E ［犷『］
t=0	- η t=0
T-1	T-1
2 X E hZt+1 - Zt2i + 8η2 X E hZt+1 - Zt2i
t=0	t=0
T-1
2(1 + 4η2) X E hZt+1 - Zt2i ,
t=0
where in (i) we apply Lemma 10, and in (ii) Lemma 9 is utilized.
It remains to plug in the above inequality into (82)	□
Lemma 12. Let the Sequence {zt}t≥° be generated as in Lemma 9, i.e., zt+1 = Zt - ɪ-ngt, then
for all t ≥ 0
IIVf (χt)∣∣2≤ 2Gt + 2(1-η^ 归+1-ZtII2
with Gt = ɪ Pn=IkVfi(χt)-gtk2.
Proof. Notice that for γ > 0 We have Vf (xt) = Vf (Xt) — gt — 1-η(zt+1 — zt). Then
IIVf(Xt)II2	≤ 2 IIVf(Xt)- gt∣∣2 + 2(1-η)- ∣∣zt+1-zt∣∣2
≤ 2XIIVfi(Xt)-gtII2 + 2⅛η^ IIzt+1-ZtII2,
n i=1	γ
where the inequalities hold due to (118) with S = 1, and (119).	□
H.1 Convergence for General Non-Convex Functions
Theorem 11. Let Assumption 1 hold, and let the stepsize in Algorithm 6 be set as
0 <γ< (g1+ 叫2 + ɪr 2β (1+4η2)!	=f Y0,	(83)
2(1 - η)2	1 - η θ
57
Under review as a conference paper at ICLR 2022
where 0 < η < 1, θ = 1 - (1 - α)(1 + S), β = (1 - α) (1 + ST), and s > 0.
Fix T ≥ 1 and let Xτ be chosenfrom the iterates x0,x1,..., xτ-1 uniformly at random. Then
T-1
X E [ ∣ ∣ Vf(Xt) ∣ ∣ 2]	<
t=0
3δ0(1-η) + EJGl ∕2 +
TY (1 - 70)	θτ (
1	3(1 - η)
2λ1 Y (1-γ0
(84)
where λι =f L J2β (1 + 4η2). Ifthe stepsize is set to 0 < y < 70/2, then
T-1
X E [ ∣ ∣ Vf(Xt) ∣ ∣ 2]	<
t=0
6δ0(1 - η)+ E [G0]
YT
3(1- η)
YLq竿(1+4η2)
(85)
Proof. Consider the sequence Zt+1 =f xt+1 — ɪ-nvt with 0 ≤ η
Zt+1 = Zt - ɪ-ngt. By L-smoothness of f (∙)
< 1. Then Lemma 9 states that
f(zt+1) - f(zt)	<
hVf(Zt),Zt+1-Zti + 2∣∣Zt+1 - Zt∣∣2
Wf(Zt) - gt,zt+1
-Zti + hgt,Zt+1-Zti + 2∣∣Zt+1 - Zt∣∣2
(i)
Wf(Zt) - gt,zt+1
Wf(Zt) - gt,zt+1
Y
-Zti-(-
IIz
-η
{Vf(xt)-gt,zt+1
1-η
Y
Y
-Zti + hVf (Zt)
)∣∣Zt+1 - Zt∣∣2
t+1-Zt∣∣2 + 2∣∣Zt+1 - Zt∣∣2
2) ∣∣Zt+ι - Zt∣∣2
-Vf (xt),Zt+1 - Zti
(ii)
<
1
2λ1
IIVf(Xt) - gt∣∣2 +
1
2λ1
+ y∣∣Zt+1 - Zt∣∣2
∣∣Vf (xt) - gt∣∣2 +
⅛∣Zt+1∙
1-η
-Zt∣∣2 + 齐 ∣∣Vf(Zt)-Vf(Xt)∣∣2
2人2
2) ∣∣Zt+ι - Zt∣∣2
(iii)
<
1
2λ1
(iv)
<
1
2λ1
1-η
Y
1
2λ
λ1
—■
2
⅜) ∣∣Zt+1
-zt∣∣2
UVf(Xt) - gt∣∣2 + 2L2∣∣Zt - xt∣∣2
1-η
Y
λ1
^2^
出 ∣∣Zt+1
IlVf(Xt )-gt∣∣2 +
2
Y 2η2L2
-zt∣∣2
2λ2(1- η)2
∣∣v-∣∣2
1-η
Y
λ1
^2^
⅜) ∣∣Zt+1-Zt∣∣2,
T- j
—
—
L
2
—
Y
—
—
L
2
—
—
—
—
—
2
—
2 +
—
—
L
2
L
2
—
—
—
—
where in (i) Lemma 9 is applied, in (ii) the inequality (115) is applied twice for λ1, λ2 > 0, (iii)
holds due to Assumption 1, and (iv) holds by definition of Zt = xt - ɪɪvt-i.
58
Under review as a conference paper at ICLR 2022
Summing up the above inequalities for t = 0,...,T - 1 (assuming v-1 = 0), we have
f (zT)	≤
T-1
f (Z0)+国 X Wf2-川2+
J X1W2
一 -2 - ⅜ - λ2) Tg QI-Zil2
Y	/ t = 0
(i)
≤
T-1
f (Z0)+国 X Wf (xt)-*2+
J XM2
一 -2 - ⅜ - λ2) Tg ||z—Il2
Y	J t=0
(=)
T-1
f (z0) +k X IlVf(Xt)- gtll2 +
2λ1匕
t=0
γ2η2L2	X (1 - η)2
2λ2(i-η)4 ⅛ Y2
llzt+1-ztll2
—
一 -2 - ⅛ - ⅜) X⅛+1-ztll2
Y	J t=0
T-1
2
t=0
—
1
-η
λ1
η2 L2
2λ2(1 - η)
T-1
2
+ 1
t=0
-Zt
Il
L
—
Y
2
—
2
—
λ
2
—
2
(iii)
≤
T-1
t=0
1
—
1
—
-η
λ1
η2 L2
2λ2(1 - η)
T-1
2
+1
t=0
-zt
Il
T-1
t=0
-η
λ1
ηL
(1 - η)
T-1
+1
t=0
λ1
—
- Zt
Il
T-1
Gt-
-η
ηL
T-1
t=0
(1 - η)	(1 - η)
∑>t,
t=0
L
—
Y
Y
—
2
—
2
—
λ
2
—
2
L
2
—
2
—
1
Y
—
2
L
2
—
2
1
2
where (i) holds due to Lemma 10, in (ii) Lemma 9 is applied, in(iii) we apply IlVf(Xt)- gt∣∣2 ≤
Gt. Finally, in the last two steps we choose λ = 1-n, and recall the definition Rt = IlYgtI∣2 =
(1 - η)2 Zt+1 - Zt 2.
Subtracting fιnf from both sides of the above inequality, taking expectation and using the notation
δt = f (zt) - fιnf, we get
EmT ]
1 T-1
E[。0] +国 X EW-
1 — η L λ1 ηL
丁 - 2 - T - (1 - η)
1	T-1
E X E[町
≤
(86)
By Lemma 11, we have
∑ E [Gt+1] ≤ (1 - θ) ∑ e [Gt] + 2βL；(-+；2)∑ e [Rt] ∙	(87)
t=0	t=0	(	η)	t=0
59
Under review as a conference paper at ICLR 2022
Next, We are going to add (86) with a 2^ multiple of (87). First, let Us "forget", for a moment,
about all the terms involving Rt and denote their sum appearing on the right hand side by R, then
T-1	T-1	T-1
E[δT] +	2θ-τXE[Gt+1]	≤ E[δ0]	+	2λ-XE[Gt]	+ (1 -θ)2λ-XE[Gt]	+ R
2 1 t=0	2 1 t=0	2 1 t=0
1	T-1
=E [δ0 ] + 2θ-τ X E[Gt] + R.
2	1 t=0
Canceling out the same terms in both sides of the above inequality, we get
where R d=ef
E [δT ] + 2θλ^ E [GT ]
λ1
2
-η	L
———
Y	2
≤ E [δ0] + ɪE [G0] + R,
2θλ1
βL2(i+4η2)、	ι	PT-1 E roti
θλ1	( (i-η)2 乙t=0 E [R ].
—
Now choosing λ1
(i+η)L
2(i-η)2
L J等(1 +4η2) and using the definition of γo given by (83), i.e., γo =f
(1 + 4η2 )	, we have
Then
0≤EΦT
def
E δT +
1
--GT
E δ0 +
2θλ1
ɪ G0
2θλι
T-1
]-(1- Yo) R X E[Rt]
t=0
T-1
E Φ0 -
(1-力 士 X E[Rt].
t=0
≤
After rearranging, we get
1
Y2
T-1
X E Rt ≤
t=0
E Φ0 (1 - η)
Y 1-Y0
Summing the result of Lemma 12 over t = 0, . . . , T - 1and applying expectation, we get
T-1	T-1	T-1
X E [Wf (Xt) U2i≤ 2 X E [Gt] + γ22 X E[Rt].
t=0	t=0	t=0
Due to Lemma 11, the conditions of Lemma 18 hold with C d=ef 2βLe2
E [Rt], thus
ι+4η2
(1-η)2,
st = E [Gt], rt
60
Under review as a conference paper at ICLR 2022
T-1	E G0	CT-1
EE [Gt] ≤ -λγ1 + θ EE [Rt].
t=0	t=0
Combining the above inequalities, we can continue with
T-1
XE h∣∣w(χt)∣l2i ≤
t=0
≤
≤
T-1	T-1
2 X E[Gl+⅞∙ X ER
t=0	Y t=0
2EP + (2+ 4)Y2 X1EW
2E [G0] + (2+ Y2。、E[Φ0](1-η)
θ
γ (1 - Yγ0
Note that for γ < γo = (2(+-)2 + q∕CC^	, We have
Thus
Y2C
θ
<
C
------------------2 ≤ 1.
(i+η)L +ʌ 叵 ∖
2(i-η)2 + V θ
T-1
XE h∣∣w(χt)∣∣2i ≤
t=0
2E [G0]	3E [Φ0] (1 - η)
ʃ +
Y 1 - Y0
3δ0(1-η) + E [G0]
Y 1 - Y0
θ
2+
1	3(1 - η)
2λ1 γ (1-Y0
where λ1 = L,等(1 + 4η2).
Corollary 16. Let assumptions of Theorem 11 hold,
γ
Vfi(X0),	i = 1,...,n,
(I + n)L +。―! T
2(1 -η)2 + 1 -√V θ ( + η )
Then, after T iterations/communication rounds of EF21-HB we have E Ijl▽/(XT)/]
requires
≤
Le δ0	1
T = #grαd=O F (α + ι
(88)
□
ε2. It
(89)
iterations/communications rounds/gradint computations at each node.
Proof. Notice that by using L ≤ L, η < 1 and Lemma 17, we have
(1 + η)L
2(1 — η)2
+ i⅛ r 2β (1+4η2)
≤
≤
.J-+ɪ，竺β
(1 - η)2	1 - η V θ
ɪf 4+2√0!
1-η 1-η α
61
Under review as a conference paper at ICLR 2022
Using the above inequality, (85), and (83), we get
#grad
≤
T≤ 6δ0(1 - η) ≤ 6δ0(1 - η) L
γε2	ε2	1 - η
6Leδ0	1
-2~	1-----+
ε2	1 - η
□
62
Under review as a conference paper at ICLR 2022
I Composite Case
Now we focus on solving a composite optimization problem
min Φ(x)
x∈Rd
n
=ef — X fi(x) + r(x),
n
i=1
(90)
where each fi(∙) is Li-Smooth (possibly non-convex), r(∙) is convex, and Φinf = infχ∈Rd Φ(x) >
-∞. This is a standard and important generalization of setting (1). Namely, it includes three special
cases.
•	Smooth unconstrained optimization. Set r ≡ 0, then we recover the initially stated
problem formulation (1).
•	Smooth optimization over convex set. Let r = δQ (indicator function of the set Q), where
Q is a nonempty closed convex set. Then (90) reduces to the problem of minimizing finite a
sum of smooth (possibly non-convex) functions over a nonempty closed convex set
min{1X fi(x)).
•	l1-regularized optimization. Choose r(x) = λkxk1 with λ > 0, then (90) amounts to the
l1-regularized (also known as LASSO) problem
min I 1 X fi(x) + λkxkι > .
x∈Rd n
For any γ > 0, X ∈ Rd, define a proximal mapping of function r(∙) (ProX-OPerator) as
ProxYr(X) =f arg min <j r(y) + ɪ ∣∣y - x∣∣2 ∖ .	(91)
y∈Rd	2γ
Throughout this section, we assume that the master node can efficiently compute prox-operator at
every iteration. This is a reasonable assumption, and in many cases (choices of r(∙)) appearing in
applications, there exists an analytical solution of (91), or its computation is cheap compared to the
aggregation step.
To evaluate convergence in composite case, we define the generalized gradient mapping at a point
X ∈ Rd with a parameter γ
GY(x) =f Y (X - ProxYr (x - γVf (x))) .	(92)
One can verify that the above quantity is a well-defined evaluation metric (Beck, 2017). Namely, for
any x* ∈ Rd, it holds that GY(x) = 0 if and only if x* is a stationary point of (90), and in a special
case when r ≡ 0, we have GY (X) = Vf (X).
Notations for this section: in this section we re-define δt d=ef Φ (xt) - Φinf
Lemma 13 (Gradient mapping bound). Let xt+1 d=ef ProxYr (xt - γvt), then
E h∣∣Gγ (xt)∣∣2i ≤ Y22E h∣∣xt+1 - xt∣∣2i +2E h∣∣vt -Vf (xt)∣∣2i .	(93)
63
Under review as a conference paper at ICLR 2022
YE hllxt -proxγr(xt - γVf(xt))ll2i
YE [llxt+1 -xtll2i + Y22E [llxt+1 - proxγr(xt - γVf (xt))l2i
γ22 E hllχt+1-χtll2i
+ Y E hllPrθXγr(xt - Yvt)- ProXYr (Xt- Y Vf(Xt ))『]
Y22 E hllχt+1-χtll2i
+YE hll(χt - γvt) - (Xt - YVf(Xt))ll2i
WE hllxt+1 - Xtll2i + 2E hllvt - Vf(Xt))ll2i,	(94)
Proof.
E IjlGY (xt)ll2i =
≤
≤
where in the last inequality We apply non-expansiveness of prox-operator.	□
Lemma 14. Let xt+1 d=ef proxγr (xt - γvt), then for any λ > 0,
Φ (xt+1)	≤	Φ (Xt)	+ ∖l∣vt-vf(χt)∣∣2 -	(1	- L - λ)l|xt+1-xt『.(95)
2λ	γ 2	2
Proof. Define r(x) =f r(x) + 2γ ∣∣x — xt + γvtk2, and note that xt+1 = arg minχ∈Rd {r(x)}. Since
r(∙) is 1∕γ - strongly convex, we have
r(xt) ≥ r(xt+1) + ɪ llxt+1 — xtll2,
r(xt) + 2γ llYvtll2 ≥ r(xt+1) + 2γ llxt+1 - Xt + YvtH2 + ( —t+1 - xtll2 .
Thus
r(Xt+1) - r(Xt) ≤ -1 llXt+1 - Xtll2 - hvt,Xt+1 - Xt).	(96)
By L smoothness of f (∙),
f(Xt+1) - f	(Xt)	≤(Vf (Xt)	,Xt+1	- Xt) +	IL	llXt+1	-Xtll2.	(97)
Summing up (97) with (96) we obtain
Φ (Xt+1) - Φ	(Xt)	≤	Nf(Xt)-	vt,Xt+1	- Xti	- (1 - L)llXt+1-	Xtll2
≤ 2λllVf(Xt) - vt『-(Y- 2- 2) llXt+1-Xt/.
□
We are now ready to present EF21-Prox and provide its convergence guarantees in general non-convex
case.
64
Under review as a conference paper at ICLR 2022
I.1	Convergence for General Non-Convex Functions
Algorithm 7 EF21-Prox
1:	Input: starting point x0 ∈ Rd; g0 ∈ Rd for i = 1,...,n (known by nodes); g0 = 1 PZi g0
(known by master); learning rate γ > 0
2:	fort = 0,1, 2, . . .,T - 1 do
3:	Master computes xt+1 = proxγr (xt - γgt)
4:	for all nodes i = 1, . . . , n in parallel do
5:	Compress Ci = C(Vfi(χt+1) - gt) and send Ct to the master
6:	Update local state git+1 = git + Cti
7:	end for
8:	Master computes gt+1 = 1 Pn=I gt+1 via gt+1 = gt + 1 Pn=ICt
9:	end for
10:	Output: XT chosen uniformly from {xt}t∈[τ]
Theorem 12.	Let Assumption 1 hold, r(∙) be convex and Φinf = infχ∈Rd Φ(x) > -∞. Set the
stepsize in Algorithm 7 as
L
0 <Y<	2 + L
(98)
where L = Jnn Pn=I L, θ = 1 - (1 - α)(1 + S), β = (1 - α)(1 + ST) forany s> 0.
Fix T ≥ 1 and let XT be chosenfrom the iterates x0,x1,..., XT-1 uniformly at random. Then
4 (Φ0 - Φinf) + 2E [G0]
TYq-γ
θT
1	1θ
+YFIJ eVβ
(99)
Ifthe stepsize is set to 0 < γ ≤ γ0∕2, then
E[∣∣Gγ(XT)∣∣2] ≤
8 (Φ0 - Φinf)	2E [G0]
YT + θT
(100)
Proof. First, let us apply Lemma 14 with vt = gt,λ > 0
Φ (Xt+1) ≤ Φ (Xt) + 2λ ∣∣gt -Vf (Xt) ∣∣2 - (1 - 2 - 2[ ∣∣Xt+1 - Xt『.(101)
2λ	Y 2	2
Subtract Φinf from both sides, take expectation, and define δt = Φ (Xt) - Φinf , Gt =
1 Pn=Ikgt- Vfi(Xt)『,Rt = ∣∣xt+1 - Xt∣∣2,then
E [δt+1]	≤ E [δt] - f1 - L - λ[ E [Rt] + ɪE[Gt].
Y 2	2	2λ
(102)
Note that the proof of Lemma 1 does not rely on the update rule for Xt+1, but only on the way the
estimator git+1 is constructed. Therefore, (14) also holds for the composite case
E Gt+1	≤ (1 - θ)E Gt + βLe2E Rt .
(103)
Adding (102) with a 去 multiple of (103), we obtain
E [δt+1 ] +ɪ E [Gt+1]	≤ E [δt] +ɪ E[Gt] +；
2θλ	2λ
+2>2E [Rt]
=E[δt] + θλEE [Gt]-
2θλ
12-λθ e [Gt]- G- L- 2) e [Rt]
1 Lλ β2 t
-L2 E Rtt].
γ 2	2	2θλ
65
Under review as a conference paper at ICLR 2022
By summing up inequalities for t = 0, . . . , T-1, we arrive at
0 ≤E [δT ]+京E [GT ] ≤ δ0+京E [G0] -(J-Zl-B
2θλ	2θλ	Y 2	2
2βλL2) X1E [Rt]∙
t=0
Thus
T1
E Rt
t=0
(104)
where in the first equality we choose λ
and in the second we define F 0 d=ef δ0 +

2⅛√βL2E [G0], B =f
By Lemma 13 with vt = gt we have
EblGY (XT )l∣2]=
≤
(i)
≤
(ii)
≤
T-1
ɪ X E h∣∣Gγ (Xt)ll2i
t=0
T-1	T-1
⅛ X E [Rt] + T X E [Gt]
γ t=0	t=0
γ⅛ X E [Rt] + T 竽 + T 半 Σ E [Rt]
γ	t=0	t=0
2F0B +2 E[G0] +2 遗 2 FOB
T + T θ + T θ γ
2F0B Y γ2βe2!	2	E [G0]
T ( + θ J + τ —θ一
2F0	Y	γ2βL2∖	2 E [G0]
TY71-⅛J ( + ɪ Γ Tk,
where in (i) we apply Lemma 18 with C d=ef βLe2, st d=ef E [Gt], rt d=ef E [Rt]. (ii) is due to (104).
Note that for γ <
-1
, we have
γ2βL2
θ
<
(105)
Thus
E[∣∣Gγ (XT )∣∣2]
4F0	2 E [G0]
≤ TYFlOJ+Tk
4δ0	2E [G0]	2E [G0]	1 ΠΓ
=TY产OJ + F + TY产OJ θVβL2.
Set Y ≤ Y0/2, then the bound simplifies to
(106)
e[∣∣Gy(XT)∣∣2]	≤
+
2E [G0]
θT
66
Under review as a conference paper at ICLR 2022
□
Corollary 17. Let assumptions of Theorem 12 hold,
γ
Vfi(x0),	i = 1,...,n,
(L + 2Jep∕θ∖	.
Then, after T iterations/communication rounds of EF21-Prox we have E IjlVf(XT)『]≤ ε2. It
requires
#grad = O
where L = JnPn=ILl, δ0 = Φ(x0) - Φinf.
Proof. The proof is the same as for Corollary 2.
□
I.2 Convergence under POLYAK-匕OJASIEWICZ Condition
In order to extend the analysis of Polyak-Lojasiewicz functions to composite optimization, We use
the following Assumption 5 from (Li & Li, 2018; Wang et al., 2018).
Assumption 5 (Polyak-Lcjasiewicz). There exists μ > 0 such that
kGγ(x)k2 ≥2μ(Φ(x)- Φ(x?))
for all x ∈ Rd, where x? = arg minx Φ(x).
Theorem 13.	LetAssumptions 1 and 5 hold, r(∙) be convex and Φinf = infχ∈Rd Φ(x) > -∞. Set
the stepsize in Algorithm 7 as
γ ≤ min
L+2L
θ
〜
+ θL
2β
(107)
Let Ψt =f Φ(xt) — Φ(x?) + θλGt with λ = γ∕2βL. Thenfor any T ≥ 0, we have
E [Ψt] ≤(1 — Yμ)TE [Ψ0],
(108)
where L = J, Pn=I L, θ = 1 — (1 — α)(1 + S), β = (1 — α)(1 + ST) forany s > 0.
Proof. We start as in the previous proof, but subtract Φ(x?) from both sides of (101) and define
δt =f Φ (Xt)- Φ (x?) . Recall that Gt = ɪ Pi=1 IIgt - Vfi(Xt)『，Rt = ∣∣χt+1 — χt∣∣2.Then
E [δt+1] ≤ E [δt] — (- - L — 1[ E [Rt] + ɪE[Gt]
γ 2	2	2λ
By Lemma 1, we have
E [Gt+1] ≤ (1 — θ)E [Gt] + βLe2E [Rt] .
(109)
(110)
Then by adding (109) with a 我 multiple of (110) we obtain
67
Under review as a conference paper at ICLR 2022
E [δt+1] + ɪE [Gt+1]	≤ θλ	E w]+θ1λ (1 - θ+2) e [Gt] - (Y- L- 2) e [Rt] + ɪβL2E [Rt] θλ E 忆+θλ (1 - 2)E [Gt] - (1- L- λ2- θλL2)E [Rt]
(=i)	E w]+θ1λ (ι - 2)E [Gt] -(1 - L - r2θβL!E [Rt]
(ii) ≤	E [δt ] + θ1λ (1 - 2) E [Gt] - 2γE [Rt ],	du)
where in (i) We choose λ = 2θ 竿 L2, (ii) is due to the stepsize choice (the first term in minimum).
Next, combining Assumption 5 with Lemma 13, we have
2μδt = 2μ (Φ(xt)- Φ(x*)) ≤ IlGY(xt)∣∣2 ≤ γ22Rt + 2Gt,
and
-Rt ≤ -μγ2δt + γ2Gt.
Thus (111) can be further bounded as
E [Ψ]	= E δt+1 + -1 Gt+1
θλ
≤	EW]+	θ1λ	(I- 2) E	[Gt]	-	21γE [Rt]
(1≤2)	E [δt]	+	ɪ	(1	— θ) E	[Gt]	-	γμE [δt] + YE [Gt]
θλ 2	2	2
=(ι-γ2μ )E[δt]+θλ (1 - 2+*) e [Gt]
≤	(I-γ2μ)e卜+θλGt^,
(112)
(113)
where the last inequality follows by our assumption on the stepsize (the second term in minimum). It
remains to unroll the recurrence.	□
Corollary 18. Let assumptions of Theorem 13 hold,
gi0
γ
i = 1, . . . , n,
Then, after T iterations/communication rounds of EF21-Prox we have E f(xT ) - f (x?) ≤ ε. It
requires
T = #grad = O μ μ + " log
αμ
(114)
iterations/communications rounds/gradint computations at each node, where L
δ0 = Φ(x0) - Φinf.
√⅛ Pi=1 L2,
68
Under review as a conference paper at ICLR 2022
Proof. Note that by Lemma 17 we have
μ + e H ≤ 4μ + L 至
θ	θ	αα
4 (〃 + L)
≤ ʒ-ɪ.
The remainder of the proof is the same as for Corollary 3.
□
69
Under review as a conference paper at ICLR 2022
J Useful Auxiliary Results
J.1 Basic Facts
For all a, b, x1 , . . . , xn ∈ Rd, s > 0 and p ∈ (0,1] the following inequalities hold
	ha, bi		≤	3l2 , SiIbII2 F + ~,	(115)
ha - b, a + bi			=	iai2 - ibi2,	(116)
2 k	ak2 - kbk2		≤	ia + bi2,	(117)
	ka + bk2 O		≤	(1 + s)iai2 + (1 + 1/s)ibi2,	(118)
	1n 不X xi n		≤	1n n x ∣χi∣2, n i=1	(119)
	i=1				
	(1- P )-	1	≤	1 + P,	(120)
1+	P)(1 - Pp		≤	1 - P 2,	(121)
	log (1 - p)		≤	-P.	(122)
Bias-variance decomposition For a random vector ξ ∈ Rd and any deterministic vector x ∈ Rd,
the variance of ξ can be decomposed as
E kξ - E[ξ]k2 = E kξk2 -kE[ξ]k2	(123)
Tower property of mathematical expectation. For random variables ξ, η ∈ Rd we have
E[ξ] = E[E[ξ | η]]	(124)
under assumption that all expectations in the expression above are well-defined.
J.2 Useful Lemmas
Lemma 15 (Lemma 5 of (Richtdrik et al., 2021)). If 0 ≤ Y ≤ √+b ,then aγ2 + bγ ≤ 1. Moreover,
the bound is tight up to thefactor of 2 since √+ ≤ min
{√a，b} ≤ √a2+b.
Lemma 16 (Lemma 2 of (Li et al., 2021)). Suppose that function f is L-smooth and let xt+1 d=ef
xt - γgt , where gt ∈ Rd is any vector, and γ > 0 any scalar. Then we have
f(χt+1) ≤ f(χt) - 2 IlVf(Xt)『-G - 2) ∣∣xt+1 - xt∣∣2 + γ IIgt- Vf(Xt)『.(125)
2	2γ	2	2
Lemma 17 (Lemma 3 of (Richtdrik et al., 2021)). Let 0 < α < 1 and for s > 0 let θ(s) and β(s) be
defined as
θ(s)	d=ef	1 - (1 -α)(1+s),	β(s)	d=ef	(1 -	α)(1 +	s-1).
Then the solution of the optimization problem
min{βs : 0<s<
(126)
is given by s* = √⅛α 一 1. Furthermore, θ(s*) = 1 一 √1 — α, β (s*) = IJ--α and
1 + 0≡ -1 ≤ 2 -1.
αα	α
(127)
In the trivial case α = 1, we have ββ(s) = 0 for any s > 0, and (127) is satisfied.
70
Under review as a conference paper at ICLR 2022
Lemma 18. Let (arbitrary scalar) non-negative sequences {st}t≥0, and {rt}t≥0 satisfy
T-1	T-1	T-1
Xst+1≤(1-θ)Xst+CXrt
t=0	t=0	t=0
for some parameters θ ∈ (0, 1], C > 0. Then for all T ≥ 0
T-1
Xs
t=0
s0	C T-1
≤ — + — X rt.
≤ θ + θ 乙
t=0
(128)
Proof. We have
T-1	T-1
X st - s0 ≤	X st + sT - s0
t=0	t=0
T-1
=	X st+1
t=0
T-1	T-1
≤ (1-θ)Xst+CXrt
t=0	t=0
T-1	T-1	T-1
=	Xst-θXst+CXrt.
t=0	t=0	t=0
Dividing both sides by θ > 0 and rearranging the terms, we get
T-1
Xs
t=0
≤
0 C T-1
Sθ+C X Tr
t=0
□
71