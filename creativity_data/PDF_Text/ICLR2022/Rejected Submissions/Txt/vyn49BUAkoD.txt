Under review as a conference paper at ICLR 2022
Bayesian Active Learning with Fully Bayesian
Gaussian Processes
Anonymous authors
Paper under double-blind review
Ab stract
The bias-variance trade-off is a well-known problem in machine learning that only
gets more pronounced the less available data there is. When data is scarce, such
as in metamodeling, active learning, and Bayesian optimization, neglecting this
trade-off can cause inefficient and non-optimal querying, leading to unnecessary
data labeling. In this paper, we focus on metamodeling with active learning and
the canonical Gaussian Process (GP). We recognize that, for the GP, the bias-
variance trade-off regulation is made by optimization of the two hyperparameters:
the length scale and noise-term. Considering that the optimal mode of the joint
posterior of the hyperparameters is equivalent to the optimal bias-variance trade-
off, we approximate this joint posterior and utilize it to design two new acqui-
sition functions. The first one is a mode-seeking Bayesian variant of Query-by-
Committee (B-QBC), and the second is simultaneously mode-seeking and min-
imizing the predictive variance through a Query by Mixture Gaussian Processes
(QB-MGP) formulation. Across seven simulators, we empirically show that B-
QBC outperforms the benchmark functions, whereas QB-MGP is the most robust
acquisition function and achieves the best accuracy with the fewest iterations. We
generally show that incorporating the bias-variance trade-off in the acquisition
functions mitigates unnecessary and expensive data labeling.
1	Introduction
Gaussian Processes (GPs) are the canonical models to use for Bayesian optimization and metamod-
eling (Snoek et al., 2012; Gramacy, 2020). GPs are well-known for their ability to deal with small
to medium size data sets as well as balancing complexity and regularization - together with their
inherent ability to handling uncertainties - this makes them ideal in such applications (Williams &
Rasmussen, 2006). In both cases, often only limited data is accessible so the natural balance between
complexity and regularization helps prevent severe overfitting, additionally making the model flex-
ible enough to model nonlinear functions. Likewise, the quantification of uncertainty is commonly
used in the acquisition function to guide the Bayesian optimization algorithms and the active learn-
ing schemes that are almost inevitable to efficiently build a metamodel.
On the other hand, it is not a flawless procedure to use GPs to guide the two schemes. The same GP
is used as both predictor and guide, and thus the choice of predictor will affect the guide, and vice
versa. Trivially, the more data there is available for modeling, the less pronounced this problem will
be. However, in the context of both Bayesian optimization and active learning, where the data sets
tend to be rather small, a wrong predictor can result in misguidance, thus hindering the performance
and efficiency. In this paper, we mitigate this problem by not only focusing on a single predictive
model but consider many predictive models through multiple model hypotheses at once.
A GP is typically fitted through evaluation of the marginal likelihood, which automatically incorpo-
rates a trade-off between complexity and regularization (Williams & Rasmussen, 2006). However,
when the data is scarce, it is more challenging to choose the appropriate trade-off, and different
configurations of the hyperparameters of the GP can give rise to distinct fits. This is illustrated in
Figure 1, where two seemingly reasonable fits might guide the schemes quite differently. The prob-
lem is directly related to the well-known bias-variance trade-off, although we reformulate it as a
balance between modeling the data as signal or noise. For the common stationary covariance func-
tions of GPs, e.g. the radial-basis function or the Matern class of functions, together with a Gaussian
1
Under review as a conference paper at ICLR 2022
High noise regime
Low noise regime
Figure 1: Two GPs with different hyperpara-
meters. The left plot shows a GP with high noise
and a long length scale, and the right plot shows
a GP with low noise and a short length scale.
Figure 2: Joint posterior of the two hyperpara-
meters length scale and noise. The posterior is
multimodal with a low noise, high signal and a
high noise, low signal mode.
likelihood, this is directly reflected in the two hyperparameters length scale ` and noise σε2 . If the
data is modeled primarily as noise, both σε2 and ` are large, whereas if the data is modeled primarily
as a signal, both σε2 and ` are small. In the case of limited data, the joint posterior distribution of
the two hyperparameters is likely to be characterized by two modes, as illustrated in Figure 2 for
the data in Figure 1. In that case, it is difficult to tell whether it is best to model the data as noise or
signal, and a wrong choice of mode will imply non-optimal guidance from the acquisition function.
The literature suggests handling this problem with clever initializations of the hyperparameters
Williams & Rasmussen (1996) or by favoring small ` and σε2 by either always initializing hyper-
parameters in the low noise regime or by applying strong priors (Gramacy, 2020). However, none of
these approaches directly address the core problem: which mode to choose? Ideally, this should be
answered with prior information about the problem, although typically that is not available, making
these approaches less practical.
In this paper, we follow a general approach and assume no prior knowledge about the kernel or
hyperparameters. We consider multiple model hypotheses by replacing the fitting procedure of the
marginal likelihood with Markov Chain Monte Carlo (MCMC) sampling. Lalchand & Rasmussen
(2020) show that with fixed, medium-sized data sets and carefully chosen kernels, it is beneficial
to fit GPs with MCMC instead of by maximizing the marginal likelihood. We show that the same
is true for very small data sets and with a general kernel. Our main contribution is the proposal of
two new acquisition functions for active learning that utilizes the extra information from the hyper-
paramters’ posteriors estimated by MCMC to seek the most reasonable mode alongside minimizing
the predictive variance. We show that the two acquisition functions are more accurate and robust
than other common functions across multiple benchmark simulators used in the related literature.
2	Related work
The two proposed acquisition functions are specifically designed for active learning schemes for
regression tasks. In this section, we lay out the related work, although the specific acquisition func-
tions used for comparison purposes in the experiments are described in detail in section 4. Further,
in this section, we cover the essentials of Query-by-Committee and Gaussian Mixture Models, as
these constitute the backbone of the proposed acquisition functions.
Active Learning The main idea of active learning (AL) is to actively choose a new data point
to label and add to the current training data set (Settles, 2009). In the context of metamodeling,
new data is often added sequentially, i.e., one data point at a time (Gramacy, 2020), but in other
applications, it can be beneficial to query batches of data instead (Kirsch et al., 2019).
The acquisition functions can be divided into model-based and model-free functions, where the
former utilize information from the model and the latter do not (O’Neill et al., 2017). Both types
of functions seek to minimize the expected predictive loss of the model. Another approach is to
minimize the number of possible models. Houlsby et al. (2011) divide the active learning acquisition
functions into being based on either decision or information theory. Decision-based functions seek
to minimize the expected predictive loss of the model in the hope of maximizing the performance
2
Under review as a conference paper at ICLR 2022
on the test set. Information-theoretic-based functions instead try to reduce the number of possible
models, for example, through the KL-divergence or Shannon entropy (Houlsby et al., 2011).
It is not straightforward to use information-theoretic acquisition functions. However, if you have
access to the posterior of the model’s parameters, Houlsby et al. (2011) have derived the algorithm
Bayesian Active Learning by Disagreement (BALD), which can be applied in general. Generally,
BALD seeks the data point that maximizes the decrease in the expected posterior entropy of the
parameters.
Query-by-Committee The Query-by-Committee (QBC) is a specific acquisition function that was
originally proposed for classification tasks (Seung et al., 1992). It aims to maximize the disagree-
ment among the committee to get the highest information gain and minimize the version space,
which is the set of model hypotheses aligned with the training data. The construction of the com-
mittee is the core component of QBC since it is the committee’s ability to accurately and diversely
represent the version space that gives rise to informative disagreement criteria (Settles, 2009).
QBC can also be applied for regression problems. Krogh & Vedelsby (1995) construct the members
of the committee by random initializations of the weights in the neural networks. RayChaudhuri &
Hamey (1995) apply bagging and train the members on different subsets of the data set. In general,
QBC constructed by bagging has been used as a benchmark with mixed results (Cai et al., 2013;
Wu, 2018; Wu et al., 2019). Burbidge et al. (2007) show that the less noise there is in the output, the
better QBC is compared to random querying. They also highlight the fact that with a misspecified
model, QBC might perform worse than random querying. None of these approaches explore the
usage of MCMC samples of the posterior to construct a committee. To the best of our knowledge,
we are the first to propose QBC based on model hypotheses drawn from the posterior.
Gaussian Process as a Gaussian Mixture Model Mixture models have recently been applied in
active learning for classification tasks. Iswanto (2021) propose to use Gaussian Mixture Models
(GMMs) with active learning, where they design a specific acquisition function that queries the data
point that maximizes the expected likelihood of the model. Zhao et al. (2020) use a mixture of GPs
in active learning, where each component is fitted to a subset of the training set.
The combination of GMMs and GPs have previously been explored for static data sets. Chen & Ren
(2009) investigate regression tasks and apply bagging, where they repeatedly randomly sample data
points from the training set to construct new subsets to get GPs fitted to different data. Among other
combination rules, they combine the predictive posteriors of these GPs into GMMs. They obtain
even better performance by weighting the models by the predictive uncertainty such that models with
high uncertainty are given smaller weights, and vice versa. Instead of using bagging, we construct
the multiple GPs by using the MCMC samples of the hyperparameters’ joint posterior, and then
obtain a natural weighting of the GPs: the GMM will consist of more GPs with hyperparameters
close to the modes than hyperparameters far away. The formal procedure is given in section 4. To
the best of our knowledge, we are the first to combine GMMs and GPs in this manner.
3	Gaussian Processes
The Gaussian Processes (GPs) are the central models in this work. In this section, we give a brief
overview of GPs before covering the Fully Bayesian GPs. For a thorough description of GPs, we
refer to Williams & Rasmussen (2006).
Gaussian Processes A Gaussian Process (GP) is a stochastic function fully defined by a mean
function m(∙) and a covariance function (often called a kernel) k(∙, ∙). Given the data (X,y)=
{xi, yi}iN=1, where yi is the corrupted observations of some latent function values f with Gaussian
noise ε, i.e., yi = fi + εi, εi ∈ N(0, σε2), a GP is typically denoted as GP(mf(x), kf (x, x0)). It
is common practice to set the mean function equal to the zero-value vector and thus, the GP is fully
determined by the kernel kf (x, x0). For short, we will denote the kernel Kθ, which explicitly states
that the kernel is parameterized with some hyperparameters θ. Given the optimal hyperparameters,
the predictive posterior for unknown test inputs x* is given by p(f *∣θ, y, X,X *) = N (μ*, Σ*) With
μ* = K*	(Kθ +	σ2l)-1	y and Σ* =	K??	- K*	(Kθ +	σ∣l)-1	K?>	⑴
where Kθ?? denotes the covariance matrix between the test inputs, and Kθ* denotes the covariance
matrix between the test inputs and training inputs.
3
Under review as a conference paper at ICLR 2022
Covariance matrix We use the canonical kernel automatic relevance determination (ARD)
Radial-basis function (RBF) given by k (x, x0) = exp (-||x - x0∣∣2∕2'2) where ' is a vector of
length scales `1, ..., `d, one for each input dimension. Often the kernel is scaled by an output vari-
ance but here we fix it to one and solely focus on the two other hyperparameters: length scale and
noise-term. The noise-term σε2 is integrated into the kernel with an indicator variable by adding the
term σε2I{x=x0 } to the current kernel.
Fully Bayesian Gaussian Processes (FBGP) A FBGP extends a GP by putting a prior over the
hyperparameters θ 〜p(θ) and approximate their full posteriors. The joint posterior is then given by
p(f,θ∣y,X) H p(yf )p(f∣θ,X )p(θ)	(2)
and the predictive posterior for the test inputs X * is
p(f *|y) = HP (f *|f, θ)p(f∣θ,y)p(θ∣y)dfdθ	⑶
where the conditioning on X and X * have been omitted for brevity. The inner integral reduces to
the predictive posterior given by a normal GP. However, the outer integral remains intractable and is
approximated with MCMC inference as
1M
p(f*|y) = I p(f*∣y,θ)p(θ∣y)dθ ` MEp(f*∣y,θj), θj 〜p(θ∣y)	(4)
M j=1
As well known in machine learning modeling, there is no free lunch. Adapting the hyperparameters
of a FBGP is computationally expensive compared to the approach with GPs and maximum likeli-
hood estimates. However in Bayesian optimization and active learning, the computational burden
for querying a new data point will often be of magnitudes higher.
Evaluation and Fitting of GPs A GP is typically fitted by maximizing the marginal likelihood
with gradient descent, where the marginal likelihood can be computed analytically. For the FBGP,
the inner integral is intractable and is therefore optimized with approximate inference using the self-
tuning method of Monte Carlo Markov Chain (MCMC) called the No-U-Turn-Sampler (NUTS)
(Hoffman & Gelman, 2014). The MCMC inference makes the full posterior of the hyperparameters
available, making it possible to extend the point estimates to a joint distribution. In the experiment,
we apply acquisition functions that use the full posterior distribution; however, since the experiments
are designed to benchmark the acquisition functions, we always use the mode of the joint posterior
for prediction and evaluation.
4	Active Learning
In this section, we lay out the most common acquisition functions and then propose first a Bayesian
variant of Query-by-Committee and secondly an extension motivated by Gaussian Mixture Models,
which seek to minimize both the predictive variance and the number of model hypotheses. All the
acquisition functions choose a data point x among the possible data points in the unlabeled pool U.
4.1	Classic Active Learning
Many classic active learning acquisition functions are based on the model’s uncertainty and entropy
(Settles, 2009; Gramacy, 2020). We use the most common acquisition function based on the predic-
tive entropy and denoted Active Learning MacKay (ALM) (MacKay, 1992).
Entropy (ALM) For a Gaussian distribution, the Shannon entropy H[∙] is proportional to the
predictive variance σ2(x), i.e. H[x] = 1 ln((2πσ2(x)), so a new data point Xnew is queried as
xnew = arg max σ2(x)	(5)
x
Intuitively, ALM queries the data point, where the uncertainty of the prediction is the highest.
4
Under review as a conference paper at ICLR 2022
4.2	Bayesian Active Learning
If we have access to the posterior of the model’s parameters, we can utilize acquisition functions
with an extra Bayesian level, giving rise to Bayesian active learning. The posterior of the hyper-
parameters of an FBGP can be estimated with MCMC such that GPs with different pairs of the
kernel parameters, length scale, and noise can be drawn, i.e., ', σ2 〜p(θ∣y, X). The following four
acquisition functions all utilize this information and are approximated using the samples from the
MCMC, where We computep(f *∣θ,y,X,X*) using equation 4.
Entropy (B-ALM) In the Bayesian setting, we can use the information from the full posteriors
instead of only using the point estimates. The Bayesian variant of ALM (B-ALM) is then given as
xnew = arg max Eθ~p(θ∣ D) [σ2 (x)∣θ]	(6)
Bayesian Active learning by Disagreement (BALD) Houlsby et al. (2011) propose to find the
data point that maximizes the decreases in the expected posterior entropy of the hyperparameters.
They rewrite the objective from computing entropies in the parameter space to the output space
by observing that it is equivalent to maximizing the conditional mutual information between the
parameters and unknown output I[θ, y|x, D], where (x, y) is the new data point and D is the training
data. The acquisition function is denoted Bayesian Active Learning by Disagreement (BALD) and
is given by:
Xnew = arg max I [θ,y∣x, D] = arg max H [y|x, D] - Eθ^p(θ∣d)[H [y|x, θ]]	⑺
xx
BALD was originally derived for non-parametric discriminative models but has recently been ex-
tended to batches and deep learning with great success (Kirsch et al., 2019). Despite the success,
we show that BALD is not the optimal way to query new data points when considering GPs for
regression tasks.
Bayesian Query-by-Committee (B-QBC) Motivated by reducing the number of possible models
and with the multimodal posterior of the parameters in mind, we propose a new acquisition function
that seeks the correct mode. More precisely, we propose to use the joint posterior of the parame-
ters obtained through MCMC to draw multiple models and then query a new data point where the
mean predictions μθ (x) of these models disagree the most. Since the models are drawn from the
parameters’ posterior, the collection of models is dominated by models near the posterior modes.
Querying the data point that maximizes the disagreement between the models’ predictions corre-
sponds to querying the data point providing the highest information about the true mode. Thus,
this can be seen as a mode-seeking Bayesian QUery-by-Committee (B-QBC). Given that μ(χ) is the
average mean function, B-QBC is given as
xnew = arg max Eθ^p(θ∣d) [(μθ(x) - μ(x))2∣θ]	(8)
Query by Mixture of Gaussian Processes (QB-MGP) We extent the mode-seeking B-QBC to
consider the predictive variance as well. We denote the new acquisition function Query by Mixture
of Gaussian Processes (QB-MGP) since it can be motivated by the fact that each prediction of the
FBGP can be written as a Gaussian Mixture Model (GMM). More formally, we propose to use the
MCMC samples to make each prediction into a GMM, yielding the predictive posterior given as
1M
P(f*|y) = I p(f*∣y,θ)p(θ∣y)dθ ` MEp(f*∣y,θj), θj ~p(θ∣y)	(9)
M j=1
This hierarchical predictive posterior is a mixture of M Gaussians with mean Mgmm and covariance
matrix KGMM defined as (Lalchand & Rasmussen, 2020):
1M	1M	1M
μGMM = M	μθi and KGMM = M ΣKθi+ M ΣS(μθi- μGMM )2	(IO)
Finding the data point that maximizes the variance of the GMM is now equivalent to simultaneously
considering the B-ALM and B-QBC:
Xnew = argmaxEθ^p(θ∣D)[σ2(x)∣θ] + Eθ~p(θ∣d)[(μθ(X)- μ(x))2∣θ]	(11)
5
Under review as a conference paper at ICLR 2022
Table 1: Stochastic simulators used in the experiments.					
	Simulator	d	Noise σε	Input space	Previously used in
1	Sine: sin(6x)	1	0.2	[0, 5]	
2	Gramacy1d	1	0.1	[0.5, 2.5]	Gramacy & Lee (2012)
3	Higdon1d	1	0.1	[0, 20]	Gramacy & Lee (2009); Gramacy (2020)
4	Motorcycle	1	Het*	[0, 60]	Silverman (1985); Gramacy & Lee (2008); Gramacy (2020)
5	Gramacy2d	2	0.05	[-2, 6]2	Gramacy & Lee (2009; 2012); Sauer et al. (2020)
6	Branin	2	11.32	[-5, 10] × [0, 15]	Keane et al. (2008); Picheny et al. (2013); Cole et al. (2021)
7	Ishigami	3	0.187	[-π, π]3	Marrel et al. (2009); Cole et al. (2021)
8	Hartmann	6	0.0192	[0, 1]6	Picheny et al. (2013); Cole et al. (2021)
* Heteroscedastic noise
Sine	Gramacyld	Higdon
Figure 3: Visualization of the simulators (excl. Ishigami and Hartmann due to the dimensionality).
Motorcycle
Gramarv7ri	Branin
5	Experiments
In this section, we start by introducing a simple simulator denoted Sine (see Figure 3), which we use
to show that with few data points and no prior knowledge, it can be catastrophic to use a GP fitted
by MAP since it does not find the optimal mode. We show that the FBGP partly solves the problem
by utilizing the information from the full posterior. Additionally, we show that both B-QCB and
QB-MGP outperform the other acquisition functions. Both results are shown in Figure 4.
We benchmark the performance of the FBGP and the two proposed acquisition functions with the
standard fitting procedures of maximum a posteriori (MAP) and the standard acquisition functions
based on the entropy, i.e., ALM, B-ALM, and BALD, on various classic simulators used in recent
literature on GPs and active learning. They are all listed in Table 1, and those with less than three
inputs are shown in Figure 31. The motorcycle simulator is created by fitting a variational GP (Hens-
man et al., 2015) to the motorcycle accident data set (Silverman, 1985). The evaluation metrics are
the negative log marginal likelihood (NLML) and root mean square error (RMSE). The performance
for each the active learning iteration is shown, but for a comparable overview, we focus on a ref-
erence iteration that follows a convergence criterion: when the best acquisition function (based on
NLML) has reached convergence, we label that iteration as reference (for that specific simulator). If
no convergence is reached, we use iteration number 100 as reference. For these evaluations, the in-
troduced toy simulator is excluded, and we only consider simulators used in the literature previously.
In the experiments, we use a zero-mean GP with an ARD RBF kernel. In each iteration of the
active learning loop, the inputs are rescaled to the unit cube [0, 1]d, and the outputs are standardized
to have zero mean and unit variance. Following Lalchand & Rasmussen (2020), we give all the
hyperparameters relatively uninformative N(0, 3) priors in log space. The initial data sets consist
of three data points chosen by maximin Latin Hypercube Sampling, and in each iteration, one data
point is queried. The unlabeled pool U consists of the input space discretized into 100 equidistant
points along each dimension. If U contains more than 10, 000 data points, we randomly sample a
subset of 10, 000 data points in each iteration and use that as the new pool. For the MAP estimation,
the optimal hyperparameters are estimated by gradient descent using Adam (Kingma & Ba, 2015)
with a learning rate of 0.1. The inference in FBGP is carried out using NUTS (Hoffman & Gelman,
2014) in Pyro (Bingham et al., 2018) with five chains and 500 samples, including a warm-up period
with 200 samples. The remaining 1500 samples are all used for the Bayesian acquisition functions.
All experiments are repeated ten times with different initial data sets. The models are implemented
in GPyTorch (Gardner et al., 2018), and all code can be found at www.available/later.com.
1All of them except number 1 and 4 can be found at https://www.sfu.ca/~ssurjano/.
6
Under review as a conference paper at ICLR 2022
Sine	GramacyId
-j≡-jn
0	10	20	30	40
5e5e
O O O 1
0	25	50	75
Motorcycle
0 5 0 5
e 752 e
IOOOO
山s
0	25	50	75
0	10	20	30	40
Higdon
-j≡-jn
0	20	40	60
0	10	20	30
Branin
0	10	20	30
0	20	40	60
Gramacy2d
2
0∙
08
0	10	20	30	40
0	10	20	30	40
70605040
0	10	20	30	40
0	10	20	30	40
Ishigami
-j≡-jn
山ω≡Dr
Hartmann

0	25	50	75	100	0	25	50	75	100	0	25	50	75	100	0	25	50	75	100
GP (MAP): ALM FBGP: ALM FBGP: B-ALM FBGP: BALD FBGP: B-QBC FBGP: QB-MGP
Figure 4:	Performance across the 10 runs ±1 standard deviation. The x-axis represents the number
of iterations, and the vertical dotted lines show the reference iterations (also listed in Table 2).
5.1	Experiments with 8 simulators
We benchmark the acquisition functions on the Sine simulator and seven classic simulators. We
divide the simulators into subgroups and describe how the functions works in different noise settings,
complexities, and with multiple inputs, effectively encompassing five distinct modeling scenarios.
Simple simulator The simulator Sine is constructed to show the advantage of FBGPs compared to
GPs. It also shows the benefit of applying B-QBC and QB-MGP compared to the other acquisition
functions. Considering the NLML, B-QBC is slightly better than the other functions, although when
we look at the RMSE, QB-MGP is the overall best choice. This shows the gain of reducing the
predictive variance alongside the number of model hypotheses.
Noise or signal This simulator Gramacy1d has previously been used to study the effect of the
noise-term in GPs (Gramacy & Lee, 2012). The simulator has a periodic signal that is hard to
reveal if the data points are not queried cleverly. Both B-QBC and QB-MGP reach convergence
simultaneously, while the other acquisition functions struggle in distinguishing noise from the signal.
Linear and non-linear output regions The two simulators Higdon and Gramacy2d have been
used to illustrate cases where GPs struggle in modeling the data due to the output signal having both
linear and non-linear regions (Gramacy & Lee, 2009). Our experiments on these simulators show the
performance of the acquisition functions when the GP is an inadequate choice of model. Querying
data points in the linear and non-linear regions will yield a GP with a longer and shorter length
scale, respectively. On Higdon, it is seen that both B-QBC and QB-MGP balance the sampling
since the corresponding NLML and RMSE are low. On Gramacy2d, QB-MGP is achieving the
highest RMSE due to favoring to capture the small region with a non-linear signal compared to the
vast linear region. Overall, these results show that when the GP is inadequate to model the data,
both B-QBC and QB-MGP perform better.
7
Under review as a conference paper at ICLR 2022
Table 2: The likelihood-ratios and the relative change in RMSE (%) compared to the best performing
function averaged over 10 runs.
	Gramacy1d		Higdon	Motorcycle	Gramacy2d	Branin	Ishigami	Hartmann			
Dimensions		1	1	1	2	2	3	6	Overall performance		
Iteration		80	50	20	30	30	100	100	Mean	Median	Min
Likelihood-ratios											
GP (MAP): ALM		-1.79	-0.29	-0.44	-3.14	-0.11	-2.96	-0.64	-1.34	-0.64	-3.14
FBGP: ALM		-1.82	-0.57	-0.04	-1.62	-0.28	-2.88	-1.36	-1.22	-1.36	-2.88
FBGP: B-ALM		-1.80	-0.60	-0.07	-0.69	-0.45	-2.20	-2.01	-1.12	-0.69	-2.20
FBGP: BALD		-2.04	-0.87	-0.58	-1.84	-1.46	0	-1.66	-1.21	-1.46	-2.04
-FBGP: B-QBC (OUrs)一 -		-0.04	一一 O一	-1.82	一 - -1728	0~~	一二 045一 —	0	^-0.5Γ	一 ^0.04-	--w
FBGP: QB-MGP (Ours)		0	-0.25	O	O	-0.28	-1.71	-0.99	-0.46	-0.25	-1.71
Relative change in RMSE (%)									Mean	Median	Max
GP (MAP): ALM		366	8	9	11	1	61	4	65.7	9	366
FBGP: ALM		359	35	25	9	2	34	4	66.9	25	359
FBGP: B-ALM		352	32	14	19	1	22	3	63.3	19	352
FBGP: BALD		387	299	63	0	12	0	O	108.7	12	387
-FBGP: B-QBC (OUrs)一 -		^I5	一一 O一	286	12	2 --	一 口	7	一 484	一 一 12 一一	--286^ -
FBGP: QB-MGP (Ours)		0	3	O	29	0	19	5	8.0	4	29
Heteroscedastic noise The experiments on the Motorcycle simulator explore how the active learn-
ing acquisition functions perform when the simulator has heteroscedastic noise, but we model it with
a homoscedastic GP. Most conspicuous is the poor performance of B-QBC, indicating that this is
misled by the heteroscedastic noise. However, the combination of B-ALM and B-QBC in QB-MGP
gives the best performance. This agrees with our expectation that QB-MGP seems to be more robust
than B-QBC to different types of noise.
Multiple inputs To evaluate the performance on higher dimensions, we consider the smooth 2d
Branin simulator, the strongly non-linear 3d Ishigami simulator, and the 6d Hartmann simulator with
six local minima. BALD underperforms on Branin, but the other acquisition functions have similar
performance. Looking at all the active learning iterations, the GP fitted with MAP seems to give the
best trade-off between the NLML and RMSE, indicating that the regular GP with ALM is the best
for smooth problems. For Ishigami and Hartmann, 100 iterations are not enough for convergence,
although B-QBC achieves the lowest NLML, whereas BALD reaches the lowest RMSE.
5.2	The Overall Performance
We now provide a performance overview by evaluating the acquisition functions at the iteration in
which the best one has converged in terms of NLML. We both evaluate the NLML and RMSE, but
to clearly see the difference in performance, we compute the likelihood-ratios for the NLML and the
relative change in RMSE to the best performing acquisition function. In that way, we can summarize
the performance across the different simulators. The likelihood-ratios and relative changes in RMSE
are listed in Table 2, and the actual values are found in Appendix, Table 3.
Considering the likelihood-ratios, B-QBC and QB-MGP are the two best acquisition functions for
six out of the seven simulators. The median performance of B-QBC is slightly better than QB-
MGP, but both the mean and the minimum value of QB-MGP is better, indicating that QB-MGP is
more robust across the simulators. Regarding the relative changes in RMSE, BALD and QB-MGP
are the best performing functions. Overall, QB-MGP achieves both the lowest mean, median, and
maximum value, clearly stating that QB-MGP is the most accurate and robust acquisition function
across the simulators. For a visual representation, the box plots of the results are shown in Figure 5.
B-QBC and QB-MGP are the two best acquisition functions based on the NLML. Regarding the
RMSE, the B-QCB is lacking behind QB-MGP, and we see that QB-MGP benefits for taking the
predictive uncertainty into account.
5.3	Scope & Limitations
In applications with active learning, it is not only the performance at convergence that is of in-
terest since we often have a limited computational budget. However, in general, we observe that
the relative performances between the acquisition functions do not vary significantly doing the ac-
8
Under review as a conference paper at ICLR 2022
Negative marginal log likelihood
-3	-2	-1	0
Likelihood-ratios
Root mean square error
-W
m
IEZH
0	100	200	300	400
Relative change in RMSE (%)
申 FBGP: QB-MGP
由 FBGP: B-QBC
白 FBGP: BALD
由 FBGP: B-ALM
由 FBGP: ALM
申 GP (MAP): ALM
Figure 5:	Visualization of likelihood-ratios and relative change in RMSE (%).
tive learning iterations, and thus we believe that the evaluations at the reference points provide an
accurate evaluation.
The Bayesian acquisition functions utilize the full estimated joint posterior to choose a new data
point. Similarly, we could also use the posterior for prediction instead of only using the mode. Then
the predictive posterior is given as for the mixtures of Gaussian in equation 10. However, since we
focus on benchmarking the acquisition functions and not the models, we believe that using the mode
is more accurate when comparing it to the regular GP since we only change the fitting procedure.
This paper is based on empirical results that are dependent on the specific simulators. It would be
infeasible to apply these acquisition functions to all previously used simulators, but we hope that
our choice of diverse and distinct classic simulators is representative of the engineering problems
occurring in the real world. Nonetheless, we encourage the reader to test other simulators by using
our code at www.available/later.com.
6 Conclusion
In this paper, we propose two active learning acquisition functions: Bayesian Query-by-Committee
(B-QBC) and Query by a Mixture of Gaussian Processes (QB-MGP), both of which are suited for
fully Bayesian GPs. They are designed to explicitly handle the well-known bias-variance trade-off
by optimization of the GP’s two hyperparameters, length scale and noise-term. We empirically show
that they query new data points more efficiently than previously used acquisition functions. Across
seven classic simulators, which cover different types of noise, complexity and number of inputs, we
show that QB-MGP is the most robust function and achieves the best accuracy with fewest iterations.
The incorporation of domain knowledge and expert guidance regarding the simulator under study
can be a decisive factor in a successful metamodeling strategy. However, in many practical situ-
ations, such a priori domain expertise may not be readily accessible or even translatable into the
functional structure of the metamodel as useful modeling information. On these occasions, generic
tools that are robust enough to handle a plethora of diverse simulation output behaviors are pru-
dently advisable. On the one hand, we aim at maintaining an economical approach to the problem
of exploring the simulation input space. On the other hand, the final fitting performance of the
metamodel must be equally taken into utmost account. Simply discarding one of these two aspects
might well end up rendering the active learning-based metamodeling strategy not only computation-
ally unsustainable but also effectively counterproductive. To this end, we believe that the proposed
acquisition functions properly address both concerns, while being entirely independent of any prior
understanding of the underlying output distributions of the simulator.
In terms of future work, we plan to develop new acquisition functions, which constitute, in the
short-term, variations of those explored herein. Then, we aim to apply the proposed approach in
the context of larger and realistic simulation models addressing real-world problems. Eventually,
our ultimate goal is to provide practitioners with an auxiliary tool to map the simulators’ output
behaviors in a more efficient manner.
Acknowledgments
This work was supported by NOSTROMO, framed in the scope of the SESAR 2020 Exploratory
Research topic SESAR-ER4-26-2019, funded by SESAR Joint Undertakingthrough the European
Union’s Horizon 2020 research and innovation programme under grant agreement No 892517.
9
Under review as a conference paper at ICLR 2022
Reproducibility Statement
In this work, we strove to make the results as reproducible as possible. To this end, besides using
open and free source software (Python packages) to implement all the mentioned models and al-
gorithms, the simulators/functions used to generate the studied data are of the public domain and
referenced accordingly. Alongside a thorough and clear paragraph on the experimental settings, we
also attach a compressed file containing the source code used to reproduce the presented experi-
ments. In the end, we commit to provide a non-anonymized dynamic link to the repository with the
most up-to-date version of the code soon.
References
Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj Pradhan, Theofanis
Karaletsos, Rohit Singh, Paul Szerlip, Paul Horsfall, and Noah D. Goodman. Pyro: Deep Univer-
sal Probabilistic Programming. Journal of Machine Learning Research, 2018.
Robert Burbidge, Jem J. Rowland, and Ross D. King. Active learning for regression based on query
by committee. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial
Intelligence and Lecture Notes in Bioinformatics), 4881 LNCS:209-218, 2007. ISSN 16113349.
doi: 10.1007/978-3-540-77226222.
Wenbin Cai, Ya Zhang, and Jun Zhou. Maximizing expected model change for active learning in
regression. Proceedings - IEEE International Conference on Data Mining, ICDM, (December
2013):51-60, 2013. ISSN 15504786. doi: 10.1109/ICDM.2013.104.
Tao Chen and Jianghong Ren. Bagging for Gaussian process regression. Neurocomputing, 72(7-9):
1605-1610, 2009. ISSN 09252312. doi: 10.1016/j.neucom.2008.09.002.
D. Austin Cole, Robert B. Gramacy, James E Warner, Geoffrey F Bomarito, Patrick E Leser, and
William P Leser. Entropy-based adaptive design for contour finding and estimating reliability.
arXiv preprint arXiv:2105.11357, 2021.
Jacob R. Gardner, Geoff Pleiss, David Bindel, Kilian Q. Weinberger, and Andrew Gordon Wilson.
Gpytorch: Blackbox matrix-matrix Gaussian process inference with GPU acceleration. Advances
in Neural Information Processing Systems, 2018-December(NeurIPS):7576-7586, 2018. ISSN
10495258.
Robert B. Gramacy. Surrogates. Chapman and Hall/CRC, mar 2020. ISBN 9780367815493.
doi: 10.1201/9780367815493. URL https://www.taylorfrancis.com/books/
9781000766202.
Robert B. Gramacy and Herbert K.H. Lee. Bayesian treed gaussian process models with an appli-
cation to computer modeling. Journal of the American Statistical Association, 103, 2008. ISSN
01621459. doi: 10.1198/016214508000000689.
Robert B. Gramacy and Herbert K.H. Lee. Adaptive design and analysis of supercomputer experi-
ments. Technometrics, 51(2):130-145, 2009. ISSN 00401706. doi: 10.1198/TECH.2009.0015.
URL https://doi.org/10.1198/TECH.2009.0015.
Robert B. Gramacy and Herbert K.H. Lee. Cases for the nugget in modeling computer experiments.
Statistics and Computing, 22, 2012. ISSN 09603174. doi: 10.1007/s11222-010-9224-x.
James Hensman, Alexander Matthews, and Zoubin Ghahramani. Scalable variational gaussian pro-
cess classification. In Artificial Intelligence and Statistics, pp. 351-360. PMLR, 2015.
Matthew D Hoffman and Andrew Gelman. The no-u-turn sampler: adaptively setting path lengths
in hamiltonian monte carlo. J. Mach. Learn. Res., 15(1):1593-1623, 2014.
Neil Houlsby, Ferenc Huszar, ZoUbin Ghahramani, and Mate Lengyel. Bayesian Active Learning
for Classification and Preference Learning. pp. 1-17, 2011. URL http://arxiv.org/abs/
1112.5745.
10
Under review as a conference paper at ICLR 2022
B. H. Iswanto. Active learning by increasing model likelihood for Gaussian mixture mod-
els based classifiers. IOP Conference Series: Materials Science and Engineering, 1098(3):
032036, mar 2021. ISSN 1757-8981. doi: 10.1088/1757-899X/1098/3/032036. URL https:
//iopscience.iop.org/article/10.1088/1757-899X/1098/3/032036.
Andy Keane, Alexander Forrester, and Andras Sobester. Engineering Design via Surrogate Mod-
elling: A Practical Guide. 2008. doi: 10.2514/4.479557.
Diederik P. Kingma and Jimmy Lei Ba. Adam: A method for stochastic optimization. 3rd Interna-
tional Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings, pp.
1-15, 2015.
Andreas Kirsch, Joost van Amersfoort, and Yarin Gal. BatchBALD: Efficient and diverse batch ac-
quisition for deep Bayesian active learning. Advances in Neural Information Processing Systems,
32(NeurIPS), 2019. ISSN 10495258.
Anders Krogh and Jesper Vedelsby. Neural network ensembles, cross validation, and active learning.
In Advances in neural information processing systems 7, pp. 231-238, 1995.
Vidhi Lalchand and Carl Edward Rasmussen. Approximate inference for fully bayesian gaussian
process regression. In Symposium on Advances in Approximate Bayesian Inference, pp. 1-12.
PMLR, 2020.
David J. C. MacKay. Information-Based Objective Functions for Active Data Selection. Neural
Computation, 4(4):590-604, 1992. ISSN 0899-7667. doi: 10.1162/neco.1992.4.4.590.
Amandine Marrel, Bertrand Iooss, Beatrice Laurent, and Olivier Roustant. Calculations of Sobol
indices for the gaussian process metamodel. Reliability Engineering and System Safety, 94, 2009.
ISSN 09518320. doi: 10.1016/j.ress.2008.07.008.
Jack O’Neill, Sarah Jane Delany, and Brian MacNamee. Model-Free and Model-Based Ac-
tive Learning for Regression. In Advances in computational intelligence systems, pp. 375-
386. Springer, 2017. ISBN 9783319465623. doi: 10.1007/978-3-319-46562-3_24. URL
http://link.springer.com/10.1007/978-3-319-46562-3{_}24.
Victor Picheny, Tobias Wagner, and David Ginsbourger. A benchmark of kriging-based infill criteria
for noisy optimization. Structural and Multidisciplinary Optimization, 48, 2013. ISSN 16151488.
doi: 10.1007/s00158-013-0919-4.
Tirthankar RayChaudhuri and Leonard G.C. Hamey. Minimization of data collection by active
learning. IEEE International Conference on Neural Networks - Conference Proceedings, 3:1338-
1341, 1995. doi: 10.1109/icnn.1995.487351.
Annie Sauer, Robert B. Gramacy, and David Higdon. Active learning for deep gaussian process
surrogates. arXiv preprint arXiv:2012.08015, 2020.
Burr Settles. Active learning literature survey. 2009.
H. S. Seung, M. Opper, and H. Sompolinsky. Query by committee. In Proceedings of the fifth
annual workshop on Computational learning theory - COLT ’92, pp. 287-294, New York, New
York, USA, 1992. ACM Press. ISBN 089791497X. doi: 10.1145/130385.130417. URL http:
//portal.acm.org/citation.cfm?doid=130385.130417.
B. W. Silverman. Some aspects of the spline smoothing approach to non-parametric regression
curve fitting. Journal of the Royal Statistical Society: Series B (Methodological), 47, 1985. ISSN
0035-9246. doi: 10.1111/j.2517-6161.1985.tb01327.x.
Jasper Snoek, Hugo Larochelle, and Ryan P. Adams. Practical bayesian optimization of machine
learning algorithms. volume 4, 2012.
Christopher K Williams and Carl Edward Rasmussen. Gaussian processes for machine learning,
volume 2. MIT press Cambridge, MA, 2006.
Christopher KI Williams and Carl Edward Rasmussen. Gaussian processes for regression. 1996.
11
Under review as a conference paper at ICLR 2022
Dongrui Wu. Pool-Based Sequential Active Learning for Regression. TRANSACTIONS ON NEU-
RAL NETWORKS AND LEARNING SYSTEMS, 30(5):1348-1359, 2018. ISSN23318422.
Dongrui Wu, Chin Teng Lin, and Jian Huang. Active learning for regression using greedy sampling.
Information Sciences, 474:90-105, 2019. ISSN 00200255. doi: 10.1016/j.ins.2018.09.060. URL
https://doi.org/10.1016/j.ins.2018.09.060.
Jing Zhao, Shiliang Sun, Huijuan Wang, and Zehui Cao. Promoting active learning with mixtures
of Gaussian processes. Knowledge-Based Systems, 188:105044, 2020. ISSN 09507051. doi:
10.1016/j.knosys.2019.105044. URL https://doi.org/10.1016/j.knosys.2019.
105044.
A Appendix
Table 3: Benchmark of acquisition functions on test sets. The table shows the mean and standard
deviation over 10 runs.
Simulator	Iter.		GP (MAP)	FBGP (MCMC)				
			ALM	ALM	B-ALM	B-QBC	QB-MGP	BALD
Sine	30	NLML	1.34 ± 0.39	-0.28 ± 0.08	0.29 ± 0.11	0.21 ± 0.09	0.26 ± 0.14	0.40 ± 0.11
GramaCyId	^^80"	RMSE(μ) NLML ——	0.69 ± 0.17_ --0：25 ± 0.03	J0.15 ± 0.03 —二 023 ± "0力3 一	J0.15 ± 0.02 二024 ± ^0T03	__0.23 ± 0.08__ 一二1712 ±^0T11 —	Q16 ± 0.02__ 二11E ± 0；08 一	_0.34 ± 0.22 -0.09 ± 0.42 -
HigdonId	^^0^	RMSE(μ) NLML ——	0.33 ± 0.01_ --0.12 ± 0.17	__0必 ± 0.00 _ —二002 ±"0力9 一	_0.32 ± 0.00 二001 ± ^0T13	__0.08 ± 0.02 _ —二031 ± G05 一	'空 ± 0.01 _ 二0.19 ±"0:17 —	_0.37 ± 0.19 -0T13 ± 0.18"一
Motorcycle	^^0"	RMSE(μ) NLML ——	0.09 ± 0.03_ -0.92 ± 0.52一	__0J0 ±0.02 _ — -0771 ± 0.I3^^	_0J0 ± 0.02 ^0W5 ± 0.07	998 ± 0.01 ——1.61 ± 0.79■一	,98 ± 0.03 -0.63 ± 0.08 一	_0.30 ± 0.19 ^1T04 ± 0.76 -
Gramacy2d	^^0"	RMSE(μ) NLML ——	0.26 ± 0.06^ -2.27 ± 0.77一	__0.28 ± 0.07 _ ^^1T53 ± 0.61 一	_0.28 ± 0.07 —103 ± 0.18	_Q90 ± 0.26 _ 1.32 土 0.73	,34 ± 0.05 -0.69 ± 0.33 一	_0.38 ± 0.22 ^1T79 ± 0.51 -
Branin2d	^^0"	RMSE(μ) NLML ——	0.09 ± 0.01 -0.33 ± 0.16	__0J0 ± 0.01 _ —二024 ± "0∏9 一	_0J0 ± 0.01 ^0.14 ± ^0T15	__0J0 ± 0.02 _ 二039 ± ɪɪ1	Q11 ± 0.01 _ 二022 ± 0.13 一	999 ± 0.01 -0.36 ± 0.31 -
Is亩gami3d	^100"	RMSE(μ) NLML ——	42.16 ± 2.14 -^0T98 ± 0.26	_ 42.29 ±_1.37 _ ^^0T94 ± 0.27 一	42.25 ±1.83 ^0W0 ± 0.46	42.61 ±1.32 _ —二027 ±^0T24 —	41.48 ±1.26 -0.36 ± 0.52 一	46.58 ±/,4 -0.50 ± "0;16-
Hartmann6d 100		RMSE(μ) NLML ——	124 ± 0.98_ --180 ± 0.08	__695 ± 0.80 _ —二144 ± "0∏8 一	_550 ± 0.45 二1112 ±^0T39	__5.29 ± 0.17 _ 一二2712 ±成8 一	_534 ± 0.22 _ ^1763 ± 0.36 一	J.50 ± 0.34 -1729 ± 0.28 -
Besf		RMSE (μ)	1.18 ± 0.01 1/16 ——	1.18 ± 0.01 1/16	1.17 ± 0.01 ——1/16 ——	1.21 ± 0.01 5/16	1.19 ± 0.01 ——7/16	1.14 ± 0.04 ——3/16
12