Under review as a conference paper at ICLR 2022
On Invariance Penalties for Risk Minimization
Ab stract
The Invariant Risk Minimization (IRM) principle was first proposed by Arjovsky
et al. (2019) to address the domain generalization problem by leveraging data het-
erogeneity from differing experimental conditions. Specifically, IRM seeks to find
a data representation under which an optimal classifier remains invariant across
all domains. Despite the conceptual appeal of IRM, the effectiveness of the origi-
nally proposed invariance penalty has recently been brought into question through
stylized experiments and counterexamples. In this work, we investigate the rela-
tionship between the data representation, invariance penalty, and risk. In doing so,
we propose a novel invariance penalty, and utilize it to design an adaptive rule for
tuning the coefficient of the penalty proposed by Arjovsky et al. (2019). More-
over, we provide practical insights on how to avoid the potential failure of IRM
considered in the nascent counterexamples. Finally, we conduct numerical exper-
iments on both synthetic and real-world data sets with the objective of building
invariant predictors. In our non-synthetic experiments, we sought to build a pre-
dictor of human health status using a collection of data sets from various studies
which investigate the relationship between human gut microbiome and a particu-
lar disease. We substantiate the effectiveness of our proposed approach on these
data sets and thus further facilitate the adoption of the IRM principle in other
real-world applications.
1	Introduction
Under the learning paradigm of Empirical Risk Minimization (ERM) (Vapnik, 1992), data is as-
sumed to consist of independent and identically distributed (iid) samples from an underlying gen-
erating distribution. As the data generating distribution is often unknown in practice, ERM seeks
predictors with minimal average training error (i.e., empirical risk) over the training set. However,
shuffling and treating data as iid risks possibly losing important information about the underlying
conditions of the data generating process. Despite becoming a ubiquitous paradigm in machine
learning, a growing body of literature (Arjovsky et al., 2019; Teney et al., 2020) has revealed that
ERM and the the common practice of shuffling data inadvertently results in capturing all correlations
found in the training data, whether spurious or causal, and produces models that fail to generalize
to test data. The potential variation of experimental conditions that can exist at training time and
during deployment in real-world applications, manifests in discrepancies between training and test-
ing distributions. This, in turn, highlights the need for machine learning algorithms to generalize
out-of-distribution (OoD).
Shuffling and treating data as iid risks possibly losing important information about the underlying
conditions of the data generating process. As will be demonstrated in this work, partitioning training
data into environments, e.g., based on the conditions under which data is generated, can exploit these
differences to enhance generalization. One promising approach based on this observation is that of
Arjovsky et al. (2019), in which the principle of Invariant Risk Minimization (IRM) is introduced.
The objective of IRM is to find a predictor that is invariant across all training environments (see
Definition 1 and Equation 1). Because of the conceptually appealing nature of IRM and its potential
to address the OoD-generalization problem, there is a stream of literature scrutinizing various facets
of the original framework, e.g., extensions to other settings including online learning (Javed et al.,
2020) and treatment effect estimation (Shi et al., 2020), fairness (Adragna et al., 2020), introduc-
ing game-theoretic interpretations (Ahuja et al., 2020), and raising concerns on the drawbacks and
limitations of current IRM implementations (Rosenfeld et al., 2021; Kamath et al., 2021). For an in-
depth overview of the broader generalization literature, we refer the interested reader to (Arjovsky,
2020) and the references therein, and for an empirical evaluation of the performance of a number
of the state-of-the-art methods on various test cases, we refer the reader to (Gulrajani & Lopez-Paz,
2020).
1
Under review as a conference paper at ICLR 2022
In this paper, we introduce two practical implementations of the IRM principal to increase its ap-
peal and applicability in real-world settings. First, we propose an invariance penalty that is directly
related to risk. More precisely, we show that the risk in each environment under an arbitrary clas-
sifier equals to the risk under the optimal classifier for that environment plus the newly proposed
invariance penalty between the said classifier and the optimal one. Second, we build on these ini-
tial findings to provide practitioners who currently use the original IRMv1 implementation with an
adaptive rule by which to choose the penalty coefficient appropriately. In doing so, we character-
ize the difference between our proposed invariance penalty and the one proposed by Arjovsky et al.
(2019) in terms of the eigenvalues of the Gram matrix of the data representation. This eigenstructure
plays a significant role in the failure of invariance penalties including the one proposed by Arjovsky
et al. (2019).
In addition to providing practitioners with two valid approaches for implementing IRM, this work
serves to illustrate the importance of the eigenstructure of the Gram matrix of the data representation
for IRM. In particular, we revisit the counterexample of Rosenfeld et al. (2021) where the invariance
penalty of Arjovsky et al. (2019) can be made arbitrarily small for a non-invariant representation.
We show that the Gram matrix is ill-conditioned in such cases. We then provide a practical solution
to alleviate such behavior, in particular for the case where the representation is parameterized by a
neural network. Moreover, we show that the proposed framework finds an invariant predictor for
the setting in which the data is generated according to a linear Structural Equation Model (SEM)
when provided a sufficient number of training environments under a mild non-degeneracy condition,
which is similar in nature to the ones considered in (Arjovsky et al., 2019; Rosenfeld et al., 2021).
Finally, we evaluate our method on various test cases including InvarianceUnitTests (Aubin et al.,
2020) and HealthyGutTests. InvarianceUnitTests is a test bed with three synthetically generated data
sets capturing different structures of spurious correlations. HealthyGutTests is a curated collection
of biomedical data sets based on a prior meta-analysis of various microbiome studies (Gupta et al.,
2020) in which the relationships between human gut microbiome composition and various disease
phenotypes can be investigated.
The remainder of the paper is organized as follows. In Section 2, we formally define the notion
of invariant prediction, the invariant risk minimization principle, and its relaxation proposed by
Arjovsky et al. (2019). In Sections 3 and 4, we introduce our more practical implementation and the
rationale for its design. In Section 5, we evaluate the efficacy of our proposed model and compare it
with other variations of IRM over a series of experiments. We conclude the paper in Section 6. All
mathematical proofs are presented in the Appendix.
2	Background: Invariant Prediction
In this paper, we consider data (Xe , Y e) collected from multiple training environments e ∈ Etr
where the distribution of (Xi, Y i) and (Xj, Yj) may be different for i 6= j with i, j ∈ Etr. We
denote by Re the risk under environment e. That is, for predictor f : X → Y , and loss function
' :Y ×Y → R, the risk under environment e is defined as Re(f) = Eχe,γe ['(f (Xe), Ye)].
2.1	Invariant Risk Minimization
Arjovsky et al. (2019) define the notion of invariant predictors under a multi-environment setting as
follows.
Definition 1 (Invariant Predictor). A data representation 夕：X → H is said to elicit an invariant
predictor W ◦夕 across environments E if there exists a classifier W : H → Y, which is optimal for
all environments, i.e., W ∈ argminw：H—Y Re (W ◦夕)for all e ∈ E.
To find such invariant predictors, Arjovsky et al. (2019) introduce the notion of the Invariant Risk
Minimization (IRM) principle:
min
pX→H
w∙H→Y
E Re (W ◦ φ)
sub ject to
W ∈ argmin Re (W ◦夕),∀e ∈ E".
W∙H→Y
(1)
2
Under review as a conference paper at ICLR 2022
As this bi-leveled optimization problem is rather intractable, Arjovsky et al. (2019) propose a prac-
tical implementation of IRM by relaxing the invariance constraint (which itself requires solving an
optimization problem) to an invariance penalty. We review its derivation in what follows.
2.2	IRMv1: A Relaxation of IRM
In order to provide an implementation of IRM, Arjovsky et al. (2019) restrict the classifier w to
linear functions, i.e.,
E Re (w4)
e∈Etr
min
PX→H
w∈Rdw
subject to W ∈ argmin Re(W＞夕),∀e ∈ Etr.
W∈Rdo
(2)
To motivate their proposed penalty, Arjovsky et al. (2019) first consider the squared loss, i.e.,
'(f (x), y) = Ilf (x) - yk2 where ∣∣∙ k denotes the Euclidean norm. Define matrix ‰(φ) as
Iew) := EXe 以XeW(Xe)τ].	⑶
Assuming that Ie(0 is full rank for a fixed 夕，its respective optimal classifier is unique, i.e.,
argminw∈Rd2 Re (WTg) = w?(0 where
W?S := Ie(g )-1Eχe,γ e [g(X e)Y e] .	(4)
Hence, in this setting, the invariant constraint of IRM in equation 2 can be simplified to W = We? (g)
for all e ∈ Etr. A natural relaxation of the constraint W - We?(g) = 0 to a penalty is IW - We?(g)I2.1
However, Arjovsky et al. (2019) show that this penalty may not capture invariance by constructing
an example for which IW - We?(g)I2 is not well-behaved (see Section 4.3 for more details). They
argue that undoing the matrix inversion Ie(g)-1, which appears in the computation ofWe?(g) could
improve the behavior of the invariance penalty. That is, considering IIe(g)(W - We?(g))I2 as the
invariance penalty. Moreover, for the squared loss, one can show that
kIeW)(w - w?W))k2 = (1/4) IlVwRe(WT.	(5)
Hence, Arjovsky et al. (2019) propose the following invariance penalty
ρIeRMv1(g, W) := IIVwRe(WTg)II2.	(6)
Using the penalty equation 6, the relaxation of IRM is given by
min	Re(WTg) + λρIeRMv1(g, W),	(7)
φ, w / /
e∈Etr
where λ ≥ 0 is the penalty coefficient. Notice that for a given W and g, the predictor W ◦ g can be
expressed using different classifiers and data representations, i.e., W ◦夕 = W ◦ 0 where W = W ◦ ψ-1
and 0 = ψ ◦ 0 for some invertible mapping ψ : H →H. Hence, in principle, it is possible to fix W
without loss of generality. By relying on this observation, Arjovsky et al. (2019) fix the classifier as
a scalar W = 1, and, thus, search for an invariant data representation of the form 0 ∈ R1×dx. Their
relaxation of IRM, which they refer to by IRMv1 is given by
min X Re (0) + λρIeRMv1(0, 1.0).	(IRMv1)
φ	z—*,
e∈Etr
Although equation 5 only holds for squared loss, Arjovsky et al. (2019, Theorem 4) justify the choice
of IVw|w=1.0Re(WT0)I2 as an invariance penalty for other loss functions, e.g., cross-entropy loss.
More precisely, let Φ be the matrix that parameterizes the data representation. They show that for
all convex differentiable loss functions, (WTΦ)TVwR(WTΦ) = 0 if and only ifW is optimal for all
environments.
Although the penalty ρIeRMv1 (0, 1.0) seems to be an appropriate invariance penalty, which is eas-
ily implementable, its effectiveness to capture invariance has been brought into question. In par-
ticular, Rosenfeld et al. (2021) construct a non-invariant data representation such that the penalty
ρIeRMv1 (0, 1.0) is arbitrarily small. In what follows, we propose an alternative invariance penalty
that is directly comparable to risk. Hence, if the invariance penalty of a classifier is small, then so is
the difference between its risk and the risk under the optimal classifier.
1In the presence of known exogenous (environment dependent) variables, one can utilize anchor regression
Rothenhausler et al. (2021) that is conceptually related to the invariance penalization. Instead of an invariance
penalty, anchor regression relies on the projection onto the span of the said variables.
3
Under review as a conference paper at ICLR 2022
3	IRMv2: An Alternative Penalty
We revisit the structure of the risk in order to propose an alternative penalty. In particular, in the fol-
lowing Lemma, we provide the sub-optimality gap of risk under an arbitrary classifier in comparison
to the optimal classifier.
Lemma 1. Consider squared loss function. Let W ∈ RdV and w?(夕)as defined in equation 4. Then,
Re (w>°) = Re (w? W)>θ) + J[Ie(O)1/2 (W - W?G?))|| .	⑻
Based on Lemma 1, we propose an invariance penalty that is directly comparable to risk.
ρIeRMv2(O, W) := |||Ie(O)1/2 (W - We?(O))||| .	(9)
The relaxation of IRM using the penalty equation 9 is then given by
min X Re(W>O) + λρIeRMv2 (O, W).	(10)
φ, W / J
e∈Etr
We further simplify the relaxation equation 10 by finding its optimal classifier for a fixed data rep-
resentation defined as
w*3 := argminw X Re (w>0) + λρeRMv2(p,w).	(11)
e∈Etr
In the following Lemma, we leverage on the structure of the squared loss to find W?(O).
Lemma 2. Consider squared loss function and fix O. LetWe?(O) and W?(O) as defined in equation 4
and equation 11, respectively. Then,
W?(O) = eX Ie(O)!	eX Ie(O)We?(O)! .	(12)
Moreover, it holds that
argminw E Re (w>o) = W?(夕).	(13)
e∈Etr
Based on Lemmas 1 and 2, we propose the following relaxation of IRM, which we refer to by
IRMv2.
min X Re (w?(夕)>夕)+ λρeRMv2(2w?(夕)).	(IRMv2)
W e∈Etr
We provide the pseudo-code for IRMv2 in Algorithm 1 in Appendix A.
There are several comments in order. It is worth noting that Equation equation 13 in Lemma 1
reveals that for a fixed data representation, the optimal classifiers of ERM and IRMv2 are equal.
However, this equality would not imply the equality of the ERM and IRMv2 predictors (i.e., the
composition of the classifier and the data representation). The latter is due to the presence of the
invariance penalty in the optimization of O in IRMv2 in comparison to ERM.
There are a number of factors distinguishing IRMv2 from IRMv1. First, IRMv2 relies on the optimal
classifier W?(O) while W = 1.0 in IRMv1. Second, the loss function in IRMv2 is squared loss
while IRMv1 allows for utilization of other loss functions. Although this additional flexibility of
IRMv1 may seem appealing, the counterexample of Rosenfeld et al. (2021) shows the failure of the
penalty of IRMv1 to capture invariance for logistic loss. More importantly, for squared loss, Ie(O)
is incorporated differently in the invariance penalty of IRMv1 and IRMv2. We formalize this latter
observation in the Section 4.3.1.
4
Under review as a conference paper at ICLR 2022
3.1	IRMv1A: An Adaptive Penalty Coefficient
We first bound the invariance penalty of IRMv1 in terms of the penalty of IRMv2 and the eigenvalues
of Ie(g). Then, based on this comparison, We propose an adaptive approach in choosing the penalty
coefficient for IRMv1, which we refer to as IRMv1-Adaptive (IRMv1A).
Lemma 3. Let PeRMv1Q,w) and PeRMv2 Q,w) be the invariance penalties of the IRMvI and
IRMv2 defined in Equations equation 6 and equation 9, respectively. Then,
λmin (IeS) PeRMv2® W) ≤ PeRMvI (ψ,w) ≤ λmaχ(Ie(0) PeRMv2®w).	(14)
The proof of Lemma 3 directly folloWs from the definition of the invariance penalties PeRMvI (夕,W)
and PeRMv2(夕，w), and the fact that for a symmetric matrix A ∈ Rd×d and a vector U ∈ Rd,it holds
that λmin(A)kuk2 ≤ u>Au ≤ λmax(A)kuk2.
As IRMv1 is used in practice in conjunction With losses other than squared loss for classification,
in order to justify our adaptive penalty coefficient, We bound the difference of risk for cross-entropy
loss under tWo different classifiers in terms of the invariance penalty of IRMv2.
Lemma 4. Consider binary classification with cross-entropy loss. Then, for w1,w2 ∈ R% it holds
that
∣Re(w>0 - Re(w>φ)∖ ≤ ||Ie(夕)1/2(W1 - W2)
Using Lemmas 3 and 4, We suggest the folloWing rule for the penalty coefficient of IRMv1.
1
λe :
λ0 + λmin(Ie(P))，
(15)
Where λ0 ≥ 0 is a user-specified parameter. The role of λ0 is to avoid numerical instability When
λmin(Ie(P)) is small. Note that this is an adaptive rule, as P may change throughout training.
4	Theoretical Results and Analysis
In this section, We investigate the effectiveness of IRM and its practical implementations in capturing
invariance by focusing on a setting in Which the data is generated according to a Structural Equation
Model (SEM) (Pearl, 2009). SEM refers to a set of equations specifying the relationship betWeen
variables, Which is a common structural assumption in causal inference. In particular, under an
SEM, variables are related through a causal graph such that each variable is only a function of its
parents and an exogenous random variable. Similar to Arjovsky et al. (2019) and Rosenfeld et al.
(2021), We establish conditions under Which IRM recovers an invariant predictor for data generated
according to SEMs With linear functions. We then investigate the role of the eigenstructure ofIe(P),
in particular, in relation to counterexamples of Arjovsky et al. (2019) and Rosenfeld et al. (2021),
and provide practical solution to alleviate the possibility of such failure modes.
4.1	SEM for Classification
For each environment e, data (Xe, Y e) is generated according to the folloWing SEM:
Xe = S
Zc
Ze
1,	With prob. η,
-1, With prob. 1 - η,
(16)
where η ∈ [0,1], and S ∈ Rd×(de+dc) is a left invertible matrix, i.e., there exists St such that
StS = I. In this model, Zc captures the causal variables that are invariant across environments, and
Ze captures the spurious environment dependent variables.
The variables Zc and Ze are generated as follows
Zc = μcY + Wc, Wc 〜N(0, σ2I),
Ze = μeY + We, We 〜N(0,σ2I).
(17)
(18)
Here, μc ∈ Rdc, μe ∈ Rde, and N(μ, Σ) denotes multi-variate Gaussian distribution with mean μ
and covariance Σ. We further assume that Wc, We, and Ye are independent for all environments.
5
Under review as a conference paper at ICLR 2022
4.2	Invariant Representation under IRM
For the setting introduced in 4.1, the invariant data representation is linear. In particular, for any d ≥
dc,夕(Xe) = I0c 0 Stχe = Zc is an invariant data representation. Given that X is also linear
in Y , the class of linear representations may be sufficiently reach to elicit an invariant predictor.
Naturally, the possibility of finding an invariant predictor depends on the number and the diversity
of training environments. We now introduce non-degeneracy conditions on training environments
under which IRM is guaranteed to find an invariant predictor, provided sufficient number of training
environments.
Let |Etr | > de. As span({μe}e∈Etr) ≤ de, for each e ∈ Etr there exists a set of coefficients αf for
i ∈ Etr\e such that
μe =〉: αi μi	(19)
i∈Etr \e
We say that Etr is a non-degenerate set of environments if for all e ∈ Etr it holds that
X αie 6= 1,	(20)
i∈Etr \e
rank (Γe) = de,	(21)
where Γe is defined as
re := ^] q e I aI + μeμe - ^X (σi I + μiμi )αe ∣ ∙
1 — Σi∈Etr∖e αi ∖	i∈t∖e	/
The conditions of equation 20 and equation 21 specify that the span of covariance matrices ofZe’s is
Rde . This is a natural requirement to eliminate the degrees of freedom on the dependency of the data
representation on the environment dependent features. We note that the non-degeneracy conditions
considered in (Rosenfeld et al., 2021) are similar to the ones introduced here, with the difference
that instead of depending on covariance matrices of Ze as in equation 21, their condition relies only
on the variances σe2 . This difference in the non-degeneracy requirements is due to the fact that they
consider logistic loss and we consider squared loss.
Theorem 1. Assume that |Etr| > de where (Xe, Y e) generated according to equation 16. Consider
a linear data representation ΦX = AZc + BZe and a classifier w(Φ) on top of Φ that is invariant,
i.e., w(Φ) = w?®) for all e ∈ Etr. Ifnon-degeneracy conditions Eqs. (l9-21) holds, then either
w(Φ) = 0 or B = 0.
Theorem 1 characterizes the connection between invariant predictors and the diversity of training
environments in the linear setting. Its conclusions are directly applicable to IRM and its relaxations
including IRMv1, v1A, and v2.
4.3 THE ROLE OF Ie(φ)
Recall that the main difference between the invariance penalty of IRMv1 (with squared loss) and
IRMv2 is the Way that‰(φ) is incorporated. Although at a first glance this may not seem significant,
in what follows we demonstrate the importance of 戛(4).
4.3.1	The Potential Failure of Invariance Penalization
Arjovsky et al. (2019) consider a linear Structural Equation Model (SEM) of the following form.
Xi ~ N(0, σ2), Y = Xi + Zi with Zi ~ N(0, σ2), X2 = Y + Z? with Z2 ~ (0,1),
and X = [X1, X2]>. The variance σ2 is the only parameter that changes across environments,
and we assume that Zi , Z2, and Xi are independent in and across all environments. Hence, in
this setting, Xi models the invariant features and X2 models the environmental features as the
correlation between X2 and Y varies across environments.
6
Under review as a conference paper at ICLR 2022
Consider the data representation 夕C (x) parameterized by a variable C ∈ R as
匠(X)
X1
cX2
(22)
where C = 0 attains the invariant data representation, i.e.,夕o(X) = [Xi, 0]>. Based on this model,
ArjoVsky et al. (2019) argue that ∣∣wev - w?(夕C) ∣∣2 is a poor choice for the invariance penalty as it
is discontinuous at the invariant representation with C = 0, and vanishes as C → ∞. Interestingly,
Ie(夕C) is ill-conditioned for both small and large c's. More precisely, in Appendix D.1 We show that
lim κ(Ie(2C)) = lim κ(Ie(2C)) = +∞,
C→0	C→+∞
where κ(∙) denotes the condition number. That is, for a normal matrix A, its condition number is
K(A) := ∣λmaχ(A)∣∕∣λmin(A)∣ where λmaχ and λmin denote its maximum and minimum eigenval-
ues, respectively.
We now examine the counterexample introduced by Rosenfeld et al. (2021), which is based on
the SEM setting introduced in Section 4.1 and equation 16. They consider the data representation
We(Xe) defined as
We(Xe) :
ZC
0
+	Ze	1{Ze∈Ze},
(23)
where {Ze ∈/ Ze} is an event with P(Ze ∈ Ze) ≤ pe,e where pe,e := exp(-de min{ - 1, ( -
1)2 }/8). The parameter ≥ 1 control the degrees to which the environmental variable Ze appears
in the data representation by controlling the set Ze (see equation 40 in the Appendix). In particular,
We(Xe) converges to the invariant representation as → ∞, i.e., lime→∞ We(Xe) = Winv (Xe) :=
[ZC,0]>.
Rosenfeld et al. (2021) show that IRMv1,s invariance penalty ∣∣Vw Re(w> 夕)∣2 = O(p2,e), and can
be made arbitrarily small, hence it is poor discrepancy as an invariance penalty. This, together with
the fact that the training risk under We is close to the risk under the invariant representation, they
argue that We is a plausible representation under IRMv1. However, this observation is only true
for the case where λ is a constant. More specifically, We is not a plausible solution of IRMv1 with
adaptive penalty coefficient, e.g., λ(夕)=1∕λma(Ie(夕))2.
4.3.2	Practical Implications
In both of the examples discussed in Section 4.3.1, I(W) = E[W(X)W(X)>] is singular for the
invariant representation. This is due to the fact that for both of the examples, the span of data
representations W(X) is the same as the span of inputs X while the span of the invariant features
is only a small subset of that space. As a consequence, in presence of environment dependent
variables, one should avoid utilizing data representations with codomain that is the same as the
input space. In particular, when W is parameterized by a neural network, the common approach
of setting the size of the last layer equal to K - 1 for K-class classification, and 1 for regression
problem avoids such phenomenon. We further illustrate such behavior on the Colored MNIST ex-
periment, a standard benchmark for evaluating the performance of domain generalization methods.
Figure 1 illustrate that the test accuracy of
IRMv1 drastically drops as we increase the di-
mension of the representation. However, the
test accuracy of IRMv2 gradually increases first
before dropping in a considerably overflexible
representation. It is worth noting that the con-
dition number of I(夕)increases with dφ and
is ill-conditioned for large dφ, e.g., κ(I(夕))>
10i2 when dφ = 2048 (see Figure 2 in the Ap-
pendix). Note that in this experiment, images
are down-sampled and contain 14 X 14 pixels,
i.e., dχ = 196.
Figure 1: Effect of representation dimension on
test accuracy for IRMv1, IRMv1A, and IRMv2.
7
Under review as a conference paper at ICLR 2022
5 Experiments
In this section, we empirically evaluate the efficacy of our proposed implementations of IRM,
namely, IRMv2 and IRMv1A with IRMv1 and ERM. We demonstrate the appeal of our approach on
InvarianceUnitTests (Aubin et al., 2020), a synthetic test bed for evaluation of OoD methods with
multiple experiments and data sets, each of which embedding a different causal relationship. We
then evaluate each method on our curated data set HealthyGutTests to illustrate how the principle
of invariant risk minimization can be used to minimize disparities and discrepancies in biomedical
research. For completeness, we also perform numerical experiments on DomainBed, an extensive
framework released by (Gulrajani & Lopez-Paz, 2020) to test domain generalization algorithms for
image classification tasks on various benchmark data sets. Similar to Gulrajani & Lopez-Paz (2020),
we also observe that none of the domain generalization algorithms significantly outperform ERM.
We refer the reader to Appendix E for the detailed results and further discussion.
5.1	InvarianceUnitTests
In this section, we evaluate the efficacy of our proposed approaches for invariance discovery on the
InvarianceUnitTests recently proposed by Aubin et al. (2020). These unit-tests entail three classes
of low-dimensional linear problems, each capturing a different structure for inducing spurious cor-
relations. The data set for each problem falls within the multi-environment setting described in
Section 2 with ne = 104 . For all problems, the input xe ∈ Rd is constructed as xe = (xienv , xsepu)
where xienv ∈ Rdinv and xsepu ∈ Rdspu denote the invariant and the spurious features, respectively.
To make the problems more realistic, Aubin et al. (2020) repeat each experiment and scramble the
inputs by multiplying xe by a rotation matrix. In each problem, the spurious correlations that exist
in the training environments are discarded in the test environment by random shuffling. As a basis
for comparison, similar to Aubin et al. (2020), we implement an Oracle ERM where the spurious
correlations are shuffled in the training data sets as well, and hence, ERM can readily identify them.
Table 1 illustrates the training and test errors of the various methods on linear unit test experiments.
One can observe that IRMv2 is the only method that discovered a nearly invariant predictor on
all experiments. However, on classification tasks (Example 2), all other methods except IRMv1A
attained near perfect training accuracy by relying on the spurious correlations while their test accu-
racy was comparable to random guessing as the spurious features were randomly shuffled in the test
set. The stability of IRMv2 in discovering invariant predictors makes it a suitable fit for real-world
applications as we will demonstrate in the following section.
	ERM		IRMv1		IRMvIA		IRMv2		Oracle	
	Training	Test	Training	Test	Training	Test	Training	Test	Training	Test
Example1	7.35	14.40	9.47	10.72	12.82	12.87	11.14	11.26	10.49	10.32
Example1s	7.32	14.37	9.36	10.76	12.76	13.24	11.89	12.25	10.43	10.53
Example2	0.03	0.42	0.03	0.45	0.11	0.31	0.26	0.34	0.00	0.00
Example2s	0.03	0.45	0.03	0.45	0.04	0.27	0.22	0.38	0.00	0.00
Example3	0.00	0.37	0.00	0.36	0.49	0.26	0.31	0.40	0.01	0.01
Example3s	0.00	0.37	0.00	0.37	0.49	0.34	0.30	0.41	0.01	0.01
Table 1: Training and Test Errors on InvarianceUnitTests for all algorithms and examples with
(dinv, dspu, denv) = (5, 5, 3). The errors for Examples 1 and 1s are in MSE and all others are clas-
sification error. The empirical mean and the standard deviation are computed using 10 independent
experiments. An ‘s’ indicates the scrambled variation of its corresponding problem setting.
5.2	HealthyGutTests
In this section, we further evaluate the efficacy of our proposed approaches on a set of experiments
that highlight the importance of generalizability in real-world applications. An increasing number of
microbiome studies have associated various alterations in human gut microbiota composition with
both chronic and acute diseases, providing strong evidence that the gut microbiome is an essential
factor in the maintenance of human health. HealthyGutTests is a curated set of microbiomes ex-
tracted from an extensively phenotyped and standardized meta-analysis cohort (Gupta et al., 2020)
of 1770 individuals across 10 independent studies (Supplementary Table 7). Study selection was
8
Under review as a conference paper at ICLR 2022
limited to case-control studies in adult populations wherein Whole-Genome Sequencing (WGS)
metagenome data of human stool (gut microbiome) and corresponding subject meta-data were pub-
licly available. To reduce class imbalance, studies consisting of only control samples (healthy) or
those with fewer than 100 total samples were excluded.
This data set reflects the characteristics of the domain generalization problem setting, as the data
for each study is collected by different researchers, across various timepoints, locations and demo-
graphic populations. With this gut microbiome data set, we seek to illustrate a use-case in which the
IRM principle can be used to minimize the effect of spurious correlations confounding the discov-
ery of real explanatory variables and thus build a fair and trustworthy ML model that is appropriate
for real-world deployment in a biomedical setting. We consider the task of human health status
classification: predicting the binary label (healthy/unhealthy) associated with a sample. The data
set falls within the multi-environment setting described in Section 2, with ne = 10 and inputs xe
consisting of 992 features, where each feature corresponds to a unique microbial species. When data
from multiple studies are collectively analyzed, systematic variation across different studies can give
rise to biases known as “batch-effects”. These batch effects may obscure biologically relevant and
under-represented sub-population effects in the data that are difficult to identify. When viewed in a
clinical setting, these sub-population effects may represent differential etiologies, and thus require
different treatment strategies. An ERM classifier trained on all such data (i.e. by shuffling and treat-
ing data as iid) may learn these batch effects as predictors of health status, and consequently ignore
invariant features that are indicative of under-represented subpopulation effects. We seek to build an
invariant predictor that is robust in its predictions when trained and tested on different experimental
splits across the data set’s ten studies. Table 2 illustrates the test accuracy of the various methods
on this binary classification task. One can observe that IRMv2 and IRMv1A methods demonstrate
superior performance when compared to ERM and perform as good if not better than IRMv1 across
9 out of 10 test splits.
	ERM	IRMvI	IRMv1A	IRMv2
Feng (2015)	0.785	0.856	0.848	0.856
He (2017)	0.604	0.604	0.604	0.606
Jie (2017)	0.733	0.726	0.724	0.734
Karlsson (2013)	0.813	0.861	0.849	0.866
Le Chatelier (2013)	0.642	0.655	0.653	0.653
Nielsen (2014)	0.732	0.744	0.739	0.744
Qin (2012)	0.763	0.785	0.779	0.795
Vogtmann (2016)	0.692	0.696	0.700	0.700
Zeller (2014)	0.775	0.755	0.768	0.787
Zhang (2015)	0.666	0.700	0.701	0.701
Average	0.721 ± 0.064	0.738 ± 0.077	0.736 ± 0.074	0.744 ± 0.079
Table 2: Test Accuracy on HealthyGutTests health status classification task. Each test accuracy is
averaged over 5 independent experiments.
6 Conclusion
In this paper, we have presented IRMv2, an alternative implementation of the IRM principle that
aims to enable out-of-distribution generalization by finding environment invariant predictors. We
establish theoretical results on the effectiveness of our approach in the linear setting. In doing so,
we bring forward the importance of the eigenstructure of the Gramian matrix of the data representa-
tion. In particular, we show that for the existing counterexample on the potential failure of IRMv1,
the aforementioned matrix is ill-conditioned for the invariant representation. This highlights the
significance of the span of the data representations in relation to the span of the underlying true
invariant features of the data. That is, if the data representation allows for more degrees of free-
dom than needed to capture invariance, the Gramian matrix of the invariant representation would
be ill-conditioned. This observation provides intuition on the underlying reasons why current im-
plementations of IRM may fail. Our work demonstrates the effectiveness of IRMv2 and IRMv1A
on both synthetic and real-world data sets. While this investigation of the IRM principle has lead
to the development of a more pragmatic solution, we leave for future work, establishing theoretical
guarantees beyond linear regimes.
9
Under review as a conference paper at ICLR 2022
Reproducab ility Statement
We have provided detailed mathematical proofs of all of our theoretical claims in the appendices.
The data processing, neural network architecture, and the model selection for Colored MNIST,
InvarianceUnitTests, and DomainBed experiments are exactly replicated from their respective author
repositories. For HealthyGutTests experiments, we utilized the data sets curated and standardized
by domain experts Gupta et al. (2020). We discuss our additional data processing step in Section
5.2. We also provide details of the neural network architecture and the model selection in Appendix
F.
References
Robert Adragna, Elliot Creager, David Madras, and Richard Zemel. Fairness and robustness in
invariant learning: A case study in toxicity classification. arXiv preprint arXiv:2011.06485, 2020.
Kartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, and Amit Dhurandhar. Invariant risk min-
imization games. In Proceedings of the 37th International Conference on Machine Learning, pp.
145-155, 2020.
Martin Arjovsky. Out of Distribution Generalization in Machine Learning. PhD thesis, New York
University, 2020.
Martin Arjovsky, Leon BottoU,Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization.
arXiv preprint arXiv:1907.02893, 2019.
Benjamin Aubin, Martin Arjovsky, Leon Bottou, and David Lopez-Paz. Linear unit tests for in-
variance discovery. In Causal Discovery and Causality-Inspired Machine Learning Workshop at
NeurIPS, 2020.
Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint
arXiv:2007.01434, 2020.
Vinod K Gupta, Minsuk Kim, Utpal Bakshi, Kevin Y Cunningham, John M Davis, Konstantinos N
Lazaridis, Heidi Nelson, Nicholas Chia, and Jaeyun Sung. A predictive index for health status
using species-level gut microbiome profiling. Nature communications, 11(1):1-16, 2020.
Khurram Javed, Martha White, and Yoshua Bengio. Learning causal models online. arXiv preprint
arXiv:2006.07461, 2020.
Pritish Kamath, Akilesh Tangella, Danica J Sutherland, and Nathan Srebro. Does invariant risk
minimization capture invariance? arXiv preprint arXiv:2101.01134, 2021.
Masanori Koyama and Shoichiro Yamaguchi. Out-of-distribution generalization with maximal in-
variant predictor. arXiv preprint arXiv:2008.01883, 2020.
David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Remi Le
Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). arXiv
preprint arXiv:2003.00688, 2020.
Giambattista Parascandolo, Alexander Neitz, Antonio Orvieto, Luigi Gresele, and Bernhard
Scholkopf. Learning explanations that are hard to vary. arXivpreprint arXiv:2009.00329, 2020.
Judea Pearl. Causality. Cambridge university press, 2009.
Elan Rosenfeld, Pradeep Kumar Ravikumar, and Andrej Risteski. The risks of invariant risk min-
imization. In International Conference on Learning Representations, 2021. URL https:
//openreview.net/forum?id=BbNIbVPJ-42.
Dominik Rothenhausler, Nicolai Meinshausen, Peter BUhlmann, and Jonas Peters. Anchor regres-
sion: Heterogeneous data meet causality. Journal of the Royal Statistical Society: Series B (Sta-
tistical Methodology), 83(2):215-246, 2021.
10
Under review as a conference paper at ICLR 2022
Claudia Shi, Victor Veitch, and David Blei. Invariant representation learning for treatment effect
estimation. arXiv preprint arXiv:2011.12379, 2020.
Damien Teney, Ehsan Abbasnejad, and Anton van den Hengel. Unshuffling data for improved
generalization. arXiv preprint arXiv:2002.11894, 2020.
Vladimir Vapnik. Principles of risk minimization for learning theory. In Advances in neural infor-
mation processing systems,pp. 831-838,1992.
11
Under review as a conference paper at ICLR 2022
A IRMv2 Algorithm Pseudo-code
Algorithm 11RMv2
1:	Input: Data set: De for e ∈ Etr . Loss function: Squared loss, Parameters: penalty coefficient
λ ≥ 0, data representation parameters θ ∈ Rdθ, learning rate ηt, training horizon T.
2:	Initialize θ1 randomly
3:	for t = 1, 2, . . . , T do
4:	for e ∈ Etr do
5:	compute the LSE w?(夕日七)according to Eq. equation 4
6:	compute the optimal classifier w+W§J according to Eq. equation 12
7:	Lt(ψθt ) — Pe∈Etr Re(WA⅜θj>Pθj + λPeRMv2(Pθt,w^(ψθt ))
8:	Θt+1 - θt - ηtVθtLt(ψθt)
9:	Output predictor w? (PθT )>PθT .
B Considerations for Practical Implementation
As the data generating distributions for each environment are unknown, we provide further details on
practical implementations of IRMv2. As training is often done by gradient descent on mini-batches,
we focus on this setting. For simplicity of notation, assume that the sample size of all environments
are equal, each of which is divided into b mini-batches of size m. Then, wbe? the empirical estimate
of the optimal classifier we? is given by
wbe?(P) := Xb Φek>Φek!	Xb Φek>Yke,
k=1	k=1
(24)
where Φk ∈ Rm×% is a matrix each of its row is 夕(x，)> of the k-th mini-batch of environment
e, and with some abuse of notation Yke ∈ Rm is defined as the vector containing ye* i for the same
mini-batch.
Bias: Note that whether the estimator equation 24 is unbiased or not depends on the underlying data
generating assumption. In particular, it may be natural to assume that for the underlying invariant
representation, it holds that E[Y e|Pinv(Xe)] = wi>nv Pinv (X e) with the error Y e - E[Y e|Pinv(Xe)]
being independent ofXe and Y e, e.g., yei = wi>nvPinv(xie) + ηi where {η}in=1 is a sequence of zero-
mean i.i.d. random variables. However, this may not hold for an arbitrary representation P. One can
modify the estimator equation 24 to derive an unbiased estimator by using different mini-batches
for each term, e.g., by randomly dividing the mini-batches into two parts. More specifically, let B
be the set of randomly chosen mini-batches of size bb/2c, and [b]\B be the rest of the mini-batches.
Let B be a set of such Bs. Then,
") = lBl x[(x φk>φk! X φk>YJ.	(25)
1 1 B∈B [ ∖k∈B	k	k∈[b]∖B
The estimator equation 25 is unbiased if xie are i.i.d. and yie is independent of all other xje conditioned
on xie .
Numerical Stability: Although Pk∈B Φek>Φek is positive semi-definite almost surely, it is singular
for m|B| < dψ and may even be singular for m|B| > dφ. Hence, to improve numerical stability,
we consider the following empirical estimate of Ie (P)
Ie,λ,B (P) ：= λI +]Tφk>Φk,
k∈B
12
Under review as a conference paper at ICLR 2022
where λ ≥ 0. That is, to improve the numerical stability, we consider the `2 regularized least squares
estimate2
w?,B3= Ie,λ,B3-1 X Φk>YT.	(26)
k∈[b]∖B
Then,
WB (G= (X Ie,λ,B ㈤)	X Ie,λ,B 3w?,B 3∙
e∈Etr	e∈Etr
We now provide an empirical estimate of the invariant penalty ρIeRMv2 . We further partition B into
B1 , B2 , and B3 . Then,
bRMv2 = |B| X {(W?,B13)- WB13)>Ie,λ,B2S 侬?乌3 - WB33)}.
|B| B∈B
Note that ρbIeRMv2 is an unbiased estimator of ρIeRMv2 for λ = 0.
C Mathematical Proofs
C.1 Proof of Lemma 1
First, the risk under environment e with W = w?(夕)is given by
Re (w? W 6 = EY e [kY ≡k2] - Eχe,γ e [」(X e)Y [ > Ie(φ)-1Exe,γe [夕(Xe)Ye] ∙
Then,
= W>Ie(6)W - 2W>EXe,Y e [6(Xe)Ye] + EXe,Ye [6(Xe)Ye]> Ie(6)-1EXe,Ye [6(Xe)Ye]
= Ie(6)1/2 (W - We?(6))	.
C.2 Proof of Lemma 2
Recall the definition of W?(6)
w?(6)= argmi□w X Re (w>φ) + λρeRMv2(n w).
e∈Etr
That is,
w?(6)= argminw X E [∣∣w%(Xe) - Ye/]+ 入心("/2 (w - w?3):
e∈Etr
=argminw X 1(1 + λ)wτIe(φ)w - 2w> (E [p(Xe)Ye] + λIe(p)w?(夕))
e∈Etr
+ w?S>Ie(0w?3 + E [kYek2]
2The `2 regularized least squares estimate of we? is defined as
bm
W?(g)=argminwXX(ye,k - W>φ(xlk))2 +λkwk2.
k=1 i=1
13
Under review as a conference paper at ICLR 2022
Note that the objective function is a convex quadratic function of w. Hence, using the first-order
optimality condition we have that
(1 + λ) (X Iew)) w*3 - X (EmXe)Ye] + 迄停加?3)= 0.
e∈Etr	e∈Etr
Then,
w*(ψ) = 1+λ (X IeW))	(X (EmXe)Ye] + λIe(p)we(p)).
Recall that w?(夕)=Ie(φ)-1 [φ(Xe)Ye]. Then,[夕(Xe)Ye] = Ie(g)w?(夕).Thus,
w* W) = (X IeW))	( X IeW)w?停)).
Finally, using a similar argument, we get
argminw X Re (w4) = argmin. X EhIlw%(Xe) - Ye『]
e∈Etr	e∈Etr
=argminw X w>Ie(ψ)w - 2w>E [°(Xe)Ye] + E [∣∣Ye『]
e∈Etr
=(X Ie(O))	( X IeW)w?W)).
e∈Etr	e∈Etr
C.3 Proof of Lemma 3
For a symmetric matrix A ∈ Rd×d and a vector u ∈ Rd, it holds that λmin(A)kuk2 ≤ u>Au ≤
λmax(A)kuk2. Let u = Ie(O)1/2 (w - we?(O)) and A = Ie(O). Then,
∣∣Ie(0(w - W? (O))k2 ≤ λmaχ(IeW)) ∣∣IeW) 1/2 (w - W?(0)||2
kIe(θ)(w - W? (O))k2 ≥ λmin(IeW)) ||Iew)1/2 (W - W?W))||2 .
C.4 Proof of Lemma 4
Consider binary classification where Y ∈ {0, 1} with binary cross-entropy loss, i.e.,
'(f(X ),Y ) = -Yf(X) + log(1 + exp(f (X))).
Our objective is to bound the difference |R(W1>O) - R(W2>O)| for two arbitrary classifiers W1 and
W2.
Let g(W) := log(1 +exp(W>O(X))). Then, using the multivariate mean-value theorem, there exists
c ∈ (0, 1) such that
g(w2) = g(wι) + Vg((1 - c)wι + cw2)>(w2 - W1).
We have that
Vg(W)
exp(W> O(X ))
1 + exp(w> 夕(X))
O(X) = σ(W>O(X))O(X),
where σ(∙) denotes the sigmoid function. Let W := (1 - c)wι + cw2. Then,
'(w>o(X),Y) - '(w>o(X),Y)
= -YW2>O(X) + log(1 + exp(W2>O(X))) + YW1>O(X) - log(1 + exp(W1>O(X)))
=-Y(W2 - Wι)>夕(X) + σ(W>夕(X))夕(X)>(W2 - Wι)
=-(Y - σ(W>g(X))) (w2 - wι)>φ(X),
14
Under review as a conference paper at ICLR 2022
where the second equality follows from the application of mean-value theorem. Then,
∣R(w>-- R(w>0|2 = ∣E [(Y - σ(W4(X))) (w2 - w1)>φ(X)]∣2
≤ E [(Y - σ(W4(X)))2] Eh((W2 - wι)%(X))2]
≤ (w2 - wι)>E [∙(XW(X)>] (w2 - wι),
where the first equality follows from Cauchy-Schwarz and the second one follows from the fact that
Y ∈ {0,1} and σ : R → [0,1], hence |Y - σ(w>夕(X)| ≤ 1 almost surely.
C.5 Proof of Theorem 1
In order to prove Theorem 1, we first find the optimal classifier for a given data representation for
the linear setting in the following Lemma.
Lemma 5. Let wj(Φ) = argmin. Re(w>Φ) where Re(w>Φ) is defined as
Re(w>Φ) = E tr w>ΦXe - 1{Y =+1}w>ΦX e - 1{Y =+1}>	.
e	1{Y =-1}	1{Y =-1}
Then,
w?&) = [ηβ=(Φ) (i-η)β=(Φ)],
where
βl(Φ) =	⅛-τ- ∑-1μe.	(27)
1 + μe *e μe
Here, Σe and μe are defined as
∑e ：= ΦS σ01 σ0I S>Φ>,
μe := ΦS μc .
Proof of Lemma 5: We have that
w?&) = Ie(Φ)-1Eχe,γ e [ΦX eY e>].
First, we have that
Eχe,Y e [φX eY e> = ΦS EXe ,Y e
Zc
Ze
1{Y = 1}
1{Y = -1}
φs ∣"ημ° (1 - η)μc
nμe (I - η)μe
[ημe (I - η)μe].
Thus,
where
w?&) = [ηβ=(Φ) (1-η)β:(Φ)],
β:(Φ) = ie(Φ)-1μe.
(28)
(29)
We now compute Ie(Φ)-1 in terms of Σ-1 and μe. We have that
Ie(Φ) = EXe ΦXeXe>
ΦSE	ZZec
Zc	S>Φ>.
15
Under review as a conference paper at ICLR 2022
From the definition of Zc and Ze, it follows that
ZZec>	= σ0c2I
0	, μc
σ2I	μe
>
μc
μe
Thus,
Ie(Φ) = ∑ e + μeμ>
Using Sherman-Morrison formula, we have that
Ie(Φ)-1 = ∑-1 —
∑-"∑-1
1 + μ>∑-1μe
(30)
Finally, using Equation equation 29 it follows that
e?a)
ς-1_ ∑-1"e”>∑-1L =	1 ς-1
.e 1 + μ>Σ-1μeJ μe = 1 + μ> ∑-1μe e
The proof of Theorem 1 closely follows from the proof of Rosenfeld et al., 2021, Lemma C.3.. In
what follows, we include a proof to keep the manuscript self-contained.
Proofof Theorem 1: First, notice that the decomposition 夕(Xe) = AZc + BZe (or ΦS = [A B])
is without loss of generality under the assumption of left-invertibilibity of S. Then,
∑ e = σcAA> + 屋 BB>,	(31)
μe = Aμc + Bμe.	(32)
Recall from Lemma 5 that βJ(Φ) = Σ-1μe∕(1 + μ>∑-1μe). If βJ(Φ) is invariant, then β?
βj(Φ) for all e ∈ Em Then, by reorganizing terms, we get
∑eβ? = (1 — μ>β?) μe.
Thus, using Equation equation 31 and equation 32, we have that
(σ2AA> + σ2BB>)β? = (1 — (Aμc + Bμe)>β?) (Aμc + Bμe).
Let V := —σ2AA>β? + (1 一 μ>Aβ*)Aμc. Then,
B (σ2I + μeμ>) B>β? 一 V =(1 一 μ>A>β?) Bμe + μ>B>β?Aμc.	(33)
Similar to proof of Lemma C.3. in (Rosenfeld et al., 2021), we show that for all fixed β? and A
Eq. equation 33 for all environments only holds (with probability 1) if B = 0. If |Etr| > de. Then,
by the degeneracy assumption of the training sets, there exists at least one environment for which
Eq. equation 19 holds. Let μ and σ2 be the mean of Ze and variance of We for this environment.
Then, We have that μ = Pid= 1 aiμi. By applying this linear combination to Eq. equation 33 for this
environment, we get
de	de	>
B (σ2I + μμ>) B>β? 一 V = (1 一 μ>A>β?) B〉： ɑμi + I〉： α%μ% ) B>β*Aμc
i=1	i=1
de
=)：αi ((1 一 μ>A>β?) Bμi + μ>B>β*Aμc)
i=1
de
=X αi (B (σ2I + μiμ>)B>β* -V),	(34)
i=1
where in the last identity, we applied Eq. equation 33 for all i = 1, . . . , de. By rearranging the terms
in Eq. equation 34, we get
de	de
B (σ2I + μμ> —>： αi (σ2I + μiμ>) ∖ B>β? = ( 1 一)： α' v.	(35)
16
Under review as a conference paper at ICLR 2022
From the non-degeneracy condition equation 20, Eq. equation 35 is equivalent to
BΓα B> β? = v,	(36)
where Γα is defined as
γ 一 σ2I + μμ> - Pd=I αi (σ2I + 〃i〃J)
α :	1- Pd= 1 αi
Note that B, β? , and v are environment independent and Γα is an environment dependent matrix
for which it holds that rank(Γα) = de from the nondegeneracy condition equation 21. Thus, Eq.
equation 36 holds if and only v = BΓαB > β? = 0. Then, Eq. equation 33 reduces to
(1 - μ>A>β*) Bμe + β*>BμeAμc = 0
for all e ∈ Em Thus, Bμe = 0 for all e ∈ Etr, which holds if and only if B = 0 given that the span
of μes is Rde.
D	THE ROLE OF THE EIGENSTRUCTURE OF 工e(φ)
In this section, We elaborate on the discussions on the eigenstrUctUre of Ie(夕)，and in particular, its
condition number in the examples of (Arjovsky et al., 2019) and (Rosenfeld et al., 2021).
D.1 Example 1 of (Arjovsky et al., 2019)
Arjovsky et al. (2019) consider data that is generated according to the following SEM
Xi 〜N(0,σ2),
Y = X1 + Z1,
X2 = Y + Z2,
X
where Z1 〜N(0, σ2), Z2 〜(0,1), and X1 are independent, and X = χ? . Consider the
following data representation
Ψc(X) = ]XJ .	(37)
Then,
1 停C) = E ]cX12	_CX2
σ2
cσ2
cσ2
c2(2σ2 + 1) .
We now find the eigenvalues of I (夕 c). That is, the solutions to det(I (夕 C) - λI) = 0.
λ2 - λ (σ2 + c2(2σ2 + 1)) + c2σ2(2σ2 + 1) - c2σ4 = 0.
Then,
λ = 2 (σ2 + c2(2σ2 + 1) ± J(σ2 + c2(2σ2 + 1))2 — 4c2σ2(σ2 + 1))
=2 (σ2 + c2(2σ2 + 1) ± pσ4 + c4(2σ2 + 1)2 - 2c2σ2).
Hence,
K(ZQC))
λmax(ZWC))
λmin(Z(夕 C))
σ2 + c2(2σ2 + 1) + PQA + c4(2σ2 + 1)2 — 2c2σ2
σ2 + c2(2σ2 + 1) - pσ4 + c4(2σ2 + 1)2 — 2c2σ2
Q2 + c2(2σ2 + 1) + pσ4 + c4(2σ2 + 1)2 - 2c2σ2)
(σ2 + c2(2σ2 + 1))2 — (σ4 + c4(2σ2 + 1)2 — 2c2σ2)
2(σ⅛(&2+c(2σ2+1)+r c2 σ4+c2 (2Q2+1)2-2σ2) 2
17
Under review as a conference paper at ICLR 2022
Finally,
lim K(I(夕C)) = lim K(I(夕C)) = ∞.
c→∞	c→0
It is worth noting that Arjovsky et al. (2019) discuss that kw - w?(夕)k2 is poor discrepancy both
for the invariant data representation, i.e., c = 0, and for a data representation that heavily rely on the
spurious features, i.e., large c.
D.2 Example of (Rosenfeld et al., 2021)
We show that in the setting that Rosenfeld et al. (2021) demonstrate that the invariance penalty is
arbitrarily small, the risk is also inevitably arbitrarily small and is of the same order as the invariance
penalty.
/(X e) = [Z0c] + [Z0e] 1{Ze∈Ze}∙
Here, Z is defined as
Ze= U (Br(μe) ∪ Brf)) ,	(38)
e∈E
where r := ʌ/eɑldɪ and Br (μ) denotes the '2 ball of radius r centered at μ. Note that the invariant
representation is given by
Winv (X e)= Zc ∙
We compare the risk of the optimal predictor given the invariant and the Rosenfeld et al. (2021)
representations.
D.2. 1 Invariant Representation
Ie(Winv ) = E[Winv (Xe)Winv (Xe)>] = E
ZC ZC>
0
0 _ μcμ> + σ2I 0
0= 0 0
Given that Ie(Winv) is singular, we consider `2 regularized LSE with regularization parameter γ >
0, i.e.,
Winv = (IeSinv )+ YI )-1 EQnv(X e)Ye]∙
Then,
-1
i —	μcμ>	+	(σ2	+	Y)I	0 e	ZcY	_	(μcμ> +	(σ2	+ Y)I)-1 μc
winv =	0	γI	E 0	=	0
Recall from the proof of Lemma 1 that
Re(wiinv>Winv) = E[kYk2] - E[Winv(X)Y]>Ie(Winv)E[Winv(X)Y]∙
Then,
Re(WinJWinv ) = 1 - μ> (μcμ> + (σ2 + Y)I )-1μc∙	(39)
D.2.2 Rosenfeld et al. (2021) Representation
We have that
Ie(We) = E[We(Xe)We(Xe)>]
E	[ZcZc>	0]	+E	[[ 0	ZcZe>] 1
=E	[ 0	0]	+ E	[ [zezcr	ZeZerJ 1{Ze∈Z∙}
18
Under review as a conference paper at ICLR 2022
Recall that the first term is equal to Ie"inv). For the second term, we have that
E	ZeZ>	NJ	1(Ze¢Ze>	=P(Ze	"N	ZeZ>	ZZe	电	Ze	,
Now define matrix A and parameter p as
a:=E_ZeZer ZeZerUZe∈z ,
P := P(Ze ∈Ze).
Then,
Ze(Pe) = Ze(PinV ) + PA.
Also,
W = (Ze(Pe)+ γI )-1E[pe(X e)Ye ]
一 、	，	，、_」「	ZN	1
=(Ze(pinv )+ γI + pA) E Z Y1"立「I .
e	{Ze /Ze }
Let a = E[ZeY∣Ze ∈ Ze]. Then,
屋=(Ze(PinV )+ YI + PA)T * .
For an invertible matrix S, we have that
(S + ∆)-1 = ST - S-1∆S-1 + O(∣∣∆∣∣2).
Thus,
W = ((Ze(pinv )+ YI )-1 - p(Ze(pinv )+ YI )-1 A(Je(pinv )+ YI )-1 + O(p2)) 常
=WinV + p ( b -(Ze(PinV ) + Y1 尸 AwnV) + O(p2).
Then,
Re(TPe) = I- 3 屋
=1 - μ> (Meμ> + (σ2 + Y)I) 1μe + O(p2)∙
That is,
Re(WiTPe)- Re(w；nJ Pinv ) = O(p2).
Recall that
Pe(X e) = Ze 1{Ze∈Ze} + Ze 1{Ze∈"
Here, Ze is defined as
Ze ：= U (Br (μe) U&je)) ,	(40)
e∈E
where r := ʌ/eɑ^de and Br (μ) denotes the '2 ball of radius r centered at μ. Then,
Ze(Pe) = E [Pe (X e)Pe(X e)>] = Ie + Ie∙
where Ie and Ie are defined as
Ie ：= E [ZeZerOZe ∈Ze] 0 P (Ze ∈Ze),
Ie ：= E ]Z； Ze	IZe ∈Ze P (Ze ∈ Ze).
19
Under review as a conference paper at ICLR 2022
Here, We establish a lower bound on the condition number of ‰(φe) in terms of the probability of
event 1{ze∕ze}. Using Weyl's inequality, we have that
λmax(Ie(Pe)) ≥ λmax(Ic) + λmin(Ie),
λmin(Ie(Pe)) ≤ λmin(Ic) + λmax(Ie)∙
As Ie is positive semidefinite, λmin(Ie) ≥ 0. Moreover, λmin (Ic) = 0. Then,
λmax(Ie(Pe))
≥ λmax (Ic ),
For the first term, we have
λmax (Ic ) ≥
λmin (Ie (Pe )) ≤ λmax (Ie).
ɪ	tr(Ic)
de + dc
ʃɪdE[kZck2 |Ze ∈Ze] P (Ze ∈ Ze)
de + dc
^-ɪ-E [kμck2Y2 + kWck2 + 2μ>WcY∣Ze ∈ Ze] P (Ze ∈ Ze)
τ4-r(kμck2 + d-σ2)P (Ze ∈Ze),
de + dc	c
(41)
where the last identity follows from the fact that Y2 = 1 almost surely, and the fact that Wc is
independent of Y and We, and hence is independent of the event 1{ze∕ze}.
For the second term, we have
λmax(Ie) ≤ tr(Ic)
=E[kZck2+ kZek2|Ze ∈/ Ze] P(Ze ∈/ Ze)
=(kμ-k2 + d-σ2 + E [kZek2∣Ze ∈ Ze]) P (Ze / Ze),
where the last identity follows similarly as Equation equation 41. Then,
E [kZe k2∣Ze ∈ Ze] = E [|除『Y 2 + k We k 2 + 2μ> WeY |Ze ∈ Ze]
=kμe k2 + E [k Wek2 + 2μ>WeY∣Ze / Ze].
We have that
E[kWek2|Ze ∈/ Ze] ≤ deσe2.
Moreover, using Cauchy-Schwarz inequality, we get
E [μ>WeY|Ze / Ze] ≤ ||〃e k E [∣∣ Wek| Y∣∣Ze ∈ Ze] ≤ k〃ek V^.
Hence,
λmax(Ie) ≤ (kM-k2 + d-σ2 + (IlMek + Pdeσ2)2) P (Ze ∈ Ze) ∙
Thus,
κ(Ie(Pe)) ≥
λmax (Ic )
λmax (Ie )
≥	(kμ-k2 + d-σ2)P (Ze /Ze)∕(de + dc)
一(kμ-k2 + d-σ2 + (kμek + P^)2) P (Ze / Ze)
________________kμ-k2 + d-σ2_______________(	1
(de + d-) (kμ-k2 + d-σ2 + (kμe k + P^)2) IP (Ze ∈ Ze)
Note that (Rosenfeld et al., 2021, Lemma F.3.) show that
P (Ze ∈∕ Ze ) ≤ pe,e,
20
Under review as a conference paper at ICLR 2022
where
Pe,e ：= exp (-8 min{e - 1, (C - 1)2}
(42)
Then,
κ(Ie(夕e)) ≥
____________Ikk2 + dcσ2
(de+dc) (kμ°k2+d°σ+(kμek + pdeσ2)2)
Rosenfeld et al. (2021) show that the invariance penalty of (Arjovsky et al., 2019) is no greater than
O(p2,e), which can be made arbitrarily small by choosing appropriately large C. However, for such
choices of c, matrix Ie(^e) is ill-conditioned. In particular,
lim κ(Ie(夕 e)) = ∞.
→∞
D.3 Extended Colored MNIST Experiments
The model and all its respective parameters are replicated from Arjovsky et al. (2019)’s GitHub
repository3. The penalty coefficient for IRMv2 is set at λ = 10 and for λ0 = 10-5 for IRMv1A.
Figure 2 depicts demonstrate the significance of the dimension of the representation in relation to
I(W) being ill-conditioned, and, in turn, the test accuracy of IRMv1, v1A, and v2. In particular, by
allowing the representation to be overly flexible
E	Full LinearUnitTests Experiments
In this section, we provide more detailed tables for the numerical experiments on LinearUnitTests
data sets. In addition to ERM, IRMv1, IRMv1A, and IRMv2, we include two other invariance
discovery methods, namely Inter-environmental Gradient Alignment (IGA) (Koyama & Yamaguchi,
2020) and AND-Mask (Parascandolo et al., 2020), considered in (Aubin et al., 2020). The IGA
method seeks to elicit invariant predictors by an invariance penalty in terms of the variance of the
risk under different environments. The AND-Mask method, at each step of the training process,
updates the model using the direction where gradient (of the loss) signs agree across environments.
All experiments are run using default parameters of the experiments of Aubin et al. (2020) available
on their GitHub repository.4
We note that in the majority of these experiment (13 out of 18) one of our proposed methods
IRMv1A or IRMv2 outperforms all other methods.
F Details of the HealthyGutTests Experiments
We summarize the details of each data set of the HealthyGutTests in Table 7.
	Sample Size	Geographical Region	Health Status Studied
Feng (2015)	145	Austria	Colorectal Cancer, Advanced Adenoma, Obesity, Overweight, Healthy
He (2017)	98	China	Crohns Disease, Obesity, Overweight, Underweight, Healthy
Jie (2017)	281	China	Atherosclerotic Cardiovascular Disease, Obesity, Overweight, Underweight, Healthy
Karlsson (2013)	133	Europe	Type 2 Diabetes, Impaired Glucose Tolerance, Obesity, Overweight, Underweight, Healthy
Le Chatelier (2013)	112	Denmark	Obesity, Overweight, Underweight, Healthy
Nielsen (2014)	226	Europe	Crohns Disease, Ulcerative Colitis, Obesity, Overweight, Underweight, Healthy
Qin (2012)	297	China	Type 2 Diabetes, Obesity, Overweight, Underweight, Healthy
Vogtmann (2016)	99	USA	Colorectal Cancer, Obesity, Overweight, Underweight, Healthy
Zeller (2014)	196	Europe	Colorectal Cancer, Obesity, Overweight, Underweight, Healthy
Zhang (2015)	183	China	Rheumatoid Arthritis, Obesity, Overweight, Underweight, Healthy
Table 7: Details of the HealthyGutTests data sets.
3https://github.com/facebookresearch/InvariantRiskMinimization
4https://github.com/facebookresearch/InvarianceUnitTests
21
Under review as a conference paper at ICLR 2022
	ANDMask	ERM	IGA	IRMv1A	IRMv1	IRMv2	Oracle
Example1.E0	0.14 ± 0.03	2.01 ± 0.27	4.68 ± 0.72	0.07 ± 0.01	0.13 ± 0.01	0.05 ± 0.00	0.05 ± 0.00
Example1.E1	11.56 ± 0.20	15.37 ± 0.52	19.61 ± 1.36	13.81 ± 1.11	11.60 ± 0.19	12.15 ± 0.81	11.25 ± 0.02
Example1.E2	20.38 ± 0.27	25.82 ± 0.89	31.13 ± 2.30	24.74 ± 2.20	20.43 ± 0.17	21.56 ± 1.11	19.66 ± 0.38
Example1s.E0	0.12 ± 0.05	1.96 ± 0.29	3.88 ± 0.17	0.07 ± 0.01	0.13 ± 0.01	0.06 ± 0.01	0.05 ± 0.00
Example1s.E1	13.68 ± 1.00	15.47 ± 0.87	18.21 ± 0.55	14.35 ± 1.62	11.72 ± 0.08	13.30 ± 1.87	11.03 ± 0.27
Example1s.E2	24.13 ± 1.40	25.69 ± 1.06	28.92 ± 0.53	25.32 ± 2.61	20.44 ± 0.32	23.38 ± 3.09	20.53 ± 0.28
Example2.E0	0.40 ± 0.03	0.40 ± 0.01	0.43 ± 0.00	0.30 ± 0.09	0.43 ± 0.00	0.43 ± 0.09	0.00 ± 0.00
Example2.E1	0.47 ± 0.04	0.47 ± 0.01	0.50 ± 0.00	0.34 ± 0.11	0.50 ± 0.00	0.35 ± 0.05	0.00 ± 0.00
Example2.E2	0.40 ± 0.03	0.39 ± 0.00	0.42 ± 0.00	0.31 ± 0.09	0.42 ± 0.00	0.23 ± 0.02	0.00 ± 0.00
Example2s.E0	0.43 ± 0.00	0.43 ± 0.00	0.43 ± 0.00	0.25 ± 0.17	0.43 ± 0.00	0.45 ± 0.06	0.00 ± 0.00
Example2s.E1	0.50 ± 0.00	0.50 ± 0.00	0.50 ± 0.00	0.29 ± 0.20	0.50 ± 0.00	0.40 ± 0.05	0.00 ± 0.00
Example2s.E2	0.42 ± 0.00	0.42 ± 0.00	0.42 ± 0.00	0.26 ± 0.17	0.42 ± 0.00	0.29 ± 0.07	0.00 ± 0.00
Example3.E0	0.34 ± 0.23	0.35 ± 0.21	0.34 ± 0.22	0.25 ± 0.02	0.36 ± 0.20	0.41 ± 0.03	0.01 ± 0.00
Example3.E1	0.36 ± 0.21	0.40 ± 0.14	0.38 ± 0.17	0.26 ± 0.02	0.37 ± 0.18	0.39 ± 0.00	0.01 ± 0.00
Example3.E2	0.34 ± 0.23	0.36 ± 0.20	0.35 ± 0.21	0.26 ± 0.02	0.36 ± 0.20	0.39 ± 0.00	0.01 ± 0.00
Example3s.E0	0.28 ± 0.17	0.35 ± 0.21	0.35 ± 0.21	0.34 ± 0.11	0.36 ± 0.20	0.41 ± 0.01	0.01 ± 0.00
Example3s.E1	0.47 ± 0.06	0.41 ± 0.14	0.40 ± 0.15	0.34 ± 0.11	0.38 ± 0.19	0.41 ± 0.01	0.01 ± 0.00
Example3s.E2	0.38 ± 0.17	0.36 ± 0.20	0.36 ± 0.20	0.34 ± 0.11	0.36 ± 0.20	0.41 ± 0.01	0.01 ± 0.00
Table 3: Test errors for all algorithms and examples with (dinv, dspu, denv) = (5, 5, 3). The errors
for Examples 1 and 1s are in MSE and all others are classification error. The empirical mean and the
standard deviation are computed using 10 independent experiments. An ‘s’ indicates the scrambled
variation of its corresponding problem setting.
	ANDMask	ERM	IGA	IRMvIA	IRMv1	IRMv2	Oracle
Example1	10.69 ± 0.17	14.40 ± 0.56	18.48 ± 1.46	12.87 ± 1.11	10.72 ± 0.13	11.26 ± 0.64	10.32 ± 0.13
Example1s	12.64 ± 0.82	14.37 ± 0.74	17.00 ± 0.42	13.24 ± 1.41	10.76 ± 0.14	12.25 ± 1.66	10.53 ± 0.18
Example2	0.42 ± 0.03	0.42 ± 0.01	0.45 ± 0.00	0.31 ± 0.10	0.45 ± 0.00	0.34 ± 0.05	0.00 ± 0.00
Example2s	0.45 ± 0.00	0.45 ± 0.00	0.45 ± 0.00	0.27 ± 0.18	0.45 ± 0.00	0.38 ± 0.06	0.00 ± 0.00
Example3	0.34 ± 0.22	0.37 ± 0.18	0.36 ± 0.20	0.26 ± 0.02	0.36 ± 0.19	0.40 ± 0.01	0.01 ± 0.00
Example3s	0.38 ± 0.13	0.37 ± 0.18	0.37 ± 0.19	0.34 ± 0.11	0.37 ± 0.19	0.41 ± 0.01	0.01 ± 0.00
Table 4: Test errors averaged for each experiment.
	ANDMask	ERM	IGA	IRMv1A	IRMv1	IRMv2	Oracle
Example1.E0	0.13 ± 0.03	1.98 ± 0.29	4.67 ± 0.74	0.07 ± 0.01	0.12 ± 0.01	0.05 ± 0.00	0.05 ± 0.00
Example1.E1	10.38 ± 0.43	7.80 ± 0.51	10.05 ± 0.75	13.82 ± 1.26	10.16 ± 0.10	12.01 ± 0.68	11.23 ± 0.20
Example1.E2	18.45 ± 0.63	12.27 ± 1.02	14.13 ± 1.39	24.59 ± 2.26	18.12 ± 0.24	21.36 ± 0.92	20.19 ± 0.13
Example1s.E0	0.12 ± 0.05	1.91 ± 0.27	3.82 ± 0.12	0.07 ± 0.01	0.12 ± 0.01	0.06 ± 0.01	0.05 ± 0.00
Example1s.E1	12.14 ± 0.26	7.83 ± 0.55	9.26 ± 0.52	13.85 ± 1.37	10.15 ± 0.10	12.87 ± 1.81	11.27 ± 0.02
Example1s.E2	21.33 ± 0.27	12.22 ± 1.17	13.23 ± 0.91	24.37 ± 2.43	17.80 ± 0.24	22.73 ± 3.27	19.96 ± 0.17
Example2.E0	0.05 ± 0.01	0.04 ± 0.00	0.05 ± 0.00	0.12 ± 0.06	0.05 ± 0.00	0.36 ± 0.11	0.00 ± 0.00
Example2.E1	0.03 ± 0.00	0.03 ± 0.00	0.03 ± 0.00	0.11 ± 0.06	0.03 ± 0.00	0.26 ± 0.09	0.00 ± 0.00
Example2.E2	0.01 ± 0.00	0.01 ± 0.00	0.01 ± 0.00	0.10 ± 0.07	0.01 ± 0.00	0.15 ± 0.05	0.00 ± 0.00
Example2s.E0	0.05 ± 0.00	0.05 ± 0.00	0.05 ± 0.00	0.05 ± 0.03	0.05 ± 0.00	0.31 ± 0.19	0.00 ± 0.00
Example2s.E1	0.03 ± 0.00	0.03 ± 0.00	0.03 ± 0.00	0.04 ± 0.03	0.03 ± 0.00	0.22 ± 0.14	0.00 ± 0.00
Example2s.E2	0.01 ± 0.00	0.01 ± 0.00	0.01 ± 0.00	0.03 ± 0.02	0.01 ± 0.00	0.13 ± 0.09	0.00 ± 0.00
Example3.E0	0.00 ± 0.01	0.00 ± 0.00	0.00 ± 0.00	0.49 ± 0.00	0.00 ± 0.00	0.35 ± 0.10	0.01 ± 0.00
Example3.E1	0.00 ± 0.00	0.00 ± 0.00	0.00 ± 0.00	0.49 ± 0.00	0.00 ± 0.00	0.29 ± 0.01	0.01 ± 0.00
Example3.E2	0.01 ± 0.01	0.00 ± 0.00	0.00 ± 0.00	0.49 ± 0.00	0.00 ± 0.00	0.29 ± 0.01	0.01 ± 0.00
Example3s.E0	0.18 ± 0.09	0.00 ± 0.00	0.00 ± 0.00	0.49 ± 0.00	0.00 ± 0.00	0.30 ± 0.03	0.01 ± 0.00
Example3s.E1	0.00 ± 0.00	0.00 ± 0.00	0.00 ± 0.00	0.49 ± 0.00	0.00 ± 0.00	0.29 ± 0.03	0.01 ± 0.00
Example3s.E2	0.02 ± 0.02	0.00 ± 0.00	0.00 ± 0.00	0.49 ± 0.00	0.00 ± 0.00	0.30 ± 0.03	0.01 ± 0.00
Table 5: Training errors for all algorithms and examples with (dinv, dspu, denv) = (5, 5, 3). The
errors for Examples 1 and 1s are in MSE and all others are classification error. The empirical mean
and the standard deviation are computed using 10 independent experiments. An ‘s’ indicates the
scrambled variation of its corresponding problem setting.
22
Under review as a conference paper at ICLR 2022
	ANDMask	ERM	IGA	IRMv1A	IRMv1	IRMv2	Oracle
Example1	9.65 ± 0.36	7.35 ± 0.61	9.62 ± 0.96	12.82 ± 1.17	9.47 ± 0.12	11.14 ± 0.53	10.49 ± 0.11
Example1s	11.20 ± 0.19	7.32 ± 0.66	8.77 ± 0.52	12.76 ± 1.27	9.36 ± 0.12	11.89 ± 1.70	10.43 ± 0.06
Example2	0.03 ± 0.00	0.03 ± 0.00	0.03 ± 0.00	0.11 ± 0.06	0.03 ± 0.00	0.26 ± 0.08	0.00 ± 0.00
Example2s	0.03 ± 0.00	0.03 ± 0.00	0.03 ± 0.00	0.04 ± 0.03	0.03 ± 0.00	0.22 ± 0.14	0.00 ± 0.00
Example3	0.00 ± 0.00	0.00 ± 0.00	0.00 ± 0.00	0.49 ± 0.00	0.00 ± 0.00	0.31 ± 0.04	0.01 ± 0.00
Example3s	0.07 ± 0.04	0.00 ± 0.00	0.00 ± 0.00	0.49 ± 0.00	0.00 ± 0.00	0.30 ± 0.03	0.01 ± 0.00
Table 6: Training errors averaged for each experiment.
F.1 Experiment Details
F.1.1 Neural Network Architecture and Hyperparameter Tuning
The neural network considered consists of 5 layers with input layer dX × dh , hidden layers of size
dh X dh/2, dh/2 X dh/2, dh/2 X dh/4, respectively, and the output layer dh/4 X dφ. We use the
ReLU action function and the dropout parameter of each layer is set as p. We treat dh, dψ, p, the
learning rate, and the invariance penalty coefficient as hyperparameters, which we optimize using
the validation accuracy. More specifically, we randomly generate 200 hyperparameters. For each set
of parameters, we independently repeat 5 times training the model over 500 epochs. We then select
the model with best average validation accuracy (over 5 experiments), and report the average test
accuracy in Table 2.
For each data set in Table 2 that is considered as the test set, we treat each of the remaining data
sets as an environment. Before doing so, we split each of training data sets into (0.8, 0.2) split
of training and validation sets, respectively. We then concatenate all the validation subsets into a
unified validation set for model selection.
G Full DomainBed Experiments
G. 1 Experiment summary
DomainBed is an extensive framework released by Gulrajani & Lopez-Paz (2020) to test domain
generalization algorithms for image classification tasks on various benchmark data sets. Ina series of
experiments, Gulrajani & Lopez-Paz (2020) show that enabled by data augmentation various state-
of-the-art generalization methods perform similar to each other and ERM on several benchmark data
sets.
Although the integration of additional data sets and algorithms to DomainBed is straightforward, we
note that performing an extensive set of experiments requires significant computational resources as
also pointed out by Krueger et al. (2020). For this reason, we limit the scope of our experiments to
the comparison of ERM, IRMv1, IRMv1A, and IRMv2.
Similar to Gulrajani & Lopez-Paz (2020), we observe that no method significantly outperforms
others on any of the benchmark data sets (see Table 8). For a complete set of results on DomainBed
with various model selection methods, we refer the reader to Appendix G. As these data sets are
image based and equipped with data augmentation, they may not provide comprehensive insight
on the strengths and weaknesses of domain generalization algorithms on other modes of data, e.g.,
gathered in real-world applications.
23
Under review as a conference paper at ICLR 2022
Algorithm	ColoredMNIST	RotatedMNIST	PACS	VLCS	Avg
ERM	51.7 ± 0.1	96.7 ± 0.0	81.1 ±0.1	78.8 ± 0.4	77.0
IRMv1	51.8 ± 0.2	95.2 ± 0.4	78.6 ± 1.0	76.0 ± 0.5	75.4
IRMv1A	50.9 ± 0.1	64.7 ± 20.1	80.9 ± 0.0	77.3 ± 0.2	68.4
IRMv2	50.8 ± 0.4	97.1 ± 0.0	82.6 ± 0.9	76.5 ± 0.4	76.8
Table 8: The test accuracy of ERM and different implementations of IRM on benchmark data-sets.
Model selection of the DomainBed is chosen as training-domain validation set.
Algorithm	+90%	+80%	-90%	Avg
ERM	72.8 ± 0.1	72.6 ± 0.2	9.8 ± 0.0	51.7
IRMv1	72.5 ± 0.3	72.9 ± 0.1	9.9 ± 0.1	51.8
IRMv1A	70.7 ± 0.3	72.3 ± 0.5	9.7 ± 0.0	50.9
IRMv2	69.8 ± 0.8	72.9 ± 0.3	9.8 ± 0.1	50.8
Table 9: Benchmark: ColoredMNIST, Model selection: training-domain validation set.
G.2 Full DomainBed Results
Algorithm	A	C	P	S	Avg
ERM	84.5 ± 1.6	77.1 ± 0.8	96.9 ± 0.3	65.8 ± 1.9	81.1
IRMv1	77.0 ± 3.0	76.7 ± 1.1	96.4 ± 0.4	64.4 ± 0.3	78.6
IRMv1A	82.6 ± 0.5	77.7 ± 0.7	96.6 ± 0.4	66.7 ± 0.5	80.9
IRMv2	86.0 ± 0.9	76.6 ± 0.7	96.9 ± 0.0	70.8 ± 2.0	82.6
Table 11: Benchmark: PACS, Model selection: training-domain validation set.
Algorithm	0	15	30	45	60	75	Avg
ERM	90.3 ± 1.8	97.8 ± 0.0	98.2 ± 0.1	98.2 ± 0.1	97.8 ± 0.2	93.5 ± 0.4	96.0
IRMv1	89.6 ± 2.1	96.0 ± 0.5	97.9 ± 0.1	97.2 ± 0.0	97.0 ± 0.2	90.9 ± 0.5	94.8
IRMv1A	75.9 ± 5.9	64.2 ± 22.4	59.4 ± 26.1	59.8 ± 26.3	59.0 ± 26.7	55.9 ± 22.5	62.4
IRMv2	94.1 ± 0.0	98.1 ± 0.3	98.5 ± 0.1	98.2 ± 0.1	98.3 ± 0.0	94.4 ± 0.3	97.0
Table 15: Benchmark: RotatedMNIST, Model selection: leave-one-domain-out cross-validation.
Algorithm	A	C	P	S	Avg
ERM	79.7 ± 0.6	73.0 ± 3.8	97.1 ± 0.9	62.1 ± 1.5	78.0
IRMv1	67.4 ± 6.7	72.3 ± 4.3	87.7 ± 5.7	64.1 ± 4.5	72.9
IRMv1A	78.8 ± 3.2	78.9 ± 0.9	96.0 ± 0.2	42.3 ± 16.3	74.0
IRMv2	86.3 ± 0.3	76.8 ± 0.5	97.0 ± 0.4	69.7 ± 2.6	82.5
Table 16: Benchmark: PACS, Model selection: leave-one-domain-out cross-validation.
24
Under review as a conference paper at ICLR 2022
Algorithm	0	15	30	45	60	75	Avg
ERM	93.1 ± 0.1	97.8 ± 0.0	98.4 ± 0.0	98.3 ± 0.1	98.2 ± 0.0	94.3 ± 0.1	96.7
IRMv1	89.6 ± 2.1	96.8 ± 0.1	97.9 ± 0.1	97.8 ± 0.1	97.5 ± 0.1	91.6 ± 0.0	95.2
IRMv1A	75.9 ± 5.9	71.1 ± 17.7	60.8 ± 25.1	60.4 ± 25.8	60.2 ± 25.8	59.8 ± 20.5	64.7
IRMv2	94.1 ± 0.0	98.2 ± 0.0	98.5 ± 0.1	98.4 ± 0.1	98.3 ± 0.0	95.1 ± 0.2	97.1
Table 10: Benchmark: RotatedMNIST, Model selection: training-domain validation set.
Algorithm	C	L	S	V	Avg
ERM	97.4 ± 0.1	65.0 ± 0.9	74.3 ± 1.1	78.7 ± 0.1	78.8
IRM	96.3 ± 0.6	61.7 ± 0.3	70.1 ± 0.1	76.0 ± 1.8	76.0
IRMA	96.9 ± 0.8	64.8 ± 0.0	70.7 ± 1.4	77.0 ± 0.4	77.3
IRMv2	96.6 ± 1.1	65.4 ± 1.5	73.5 ± 0.5	70.6 ± 2.4	76.5
Table 12: Benchmark: VLCS, Model selection: training-domain validation set.
Algorithm	0	15	30	45	60	75	Avg
ERM	92.5 ± 0.6	97.8 ± 0.0	97.9 ± 0.1	97.9 ± 0.2	98.3 ± 0.1	94.3 ± 0.1	96.4
IRMv1	89.6 ± 2.1	96.8 ± 0.1	98.0 ± 0.2	97.5 ± 0.3	97.5 ± 0.1	91.6 ± 0.0	95.2
IRMv1A	77.9 ± 7.4	71.1 ± 17.7	59.4 ± 26.1	59.8 ± 26.3	59.0 ± 26.7	55.9 ± 22.5	63.9
IRMv2	94.7 ± 0.4	98.0 ± 0.2	98.5 ± 0.1	98.3 ± 0.0	98.3 ± 0.0	95.0 ± 0.2	97.2
Table 20: Benchmark: RotatedMNIST, Model selection: test-domain validation set (oracle).
Algorithm	A	C	P	S	Avg
ERM	83.7 ± 0.5	82.1 ± 0.2	97.5 ± 0.2	69.1 ± 0.6	83.1
IRMv1	66.7 ± 4.3	68.5 ± 1.6	87.1 ± 5.3	67.7 ± 2.0	72.5
IRMv1A	83.5 ± 0.2	75.7 ± 3.2	96.4 ± 0.3	68.6 ± 1.8	81.0
IRMv2	84.3 ± 0.3	76.5 ± 0.7	96.8 ± 0.1	70.3 ± 2.4	82.0
Table 21: Benchmark: PACS, Model selection: test-domain validation set (oracle).
Algorithm	C	L	S	V	Avg
ERM	98.4 ± 0.1	65.1 ± 1.4	72.9 ± 2.2	77.1 ± 1.7	78.4
IRM	97.6 ± 1.2	61.9 ± 0.6	62.9 ± 1.3	73.0 ± 0.3	73.9
IRMA	98.0 ± 0.1	64.9 ± 1.1	71.8 ± 0.8	73.9 ± 1.5	77.1
IRMv2	96.3 ± 1.0	67.1 ± 0.1	70.9 ± 1.3	71.9 ± 1.5	76.5
Table 22: Benchmark: VLCS, Model selection: test-domain validation set (oracle).
25
Under review as a conference paper at ICLR 2022
Algorithm	ColoredMNIST	RotatedMNIST	PACS	VLCS	Avg
ERM	51.7 ± 0.1	96.7 ± 0.0	81.1 ±0.1	78.8 ± 0.4	77.0
IRMv1	51.8 ± 0.2	95.2 ± 0.4	78.6 ± 1.0	76.0 ± 0.5	75.4
IRMv1A	50.9 ± 0.1	64.7 ± 20.1	80.9 ± 0.0	77.3 ± 0.2	68.4
IRMv2	50.8 ± 0.4	97.1 ± 0.0	82.6 ± 0.9	76.5 ± 0.4	76.8
Table 13: Model selection: training-domain validation set.
Algorithm	+90%	+80%	-90%	Avg
ERM	30.4 ± 13.4	50.5 ± 0.6	9.9 ± 0.0	30.2
IRMv1	50.1 ± 0.4	60.6 ± 7.3	30.0 ± 14.1	46.9
IRMv1A	69.5 ± 14.4	49.8 ± 0.2	10.0 ± 0.1	43.1
IRMv2	10.0 ± 0.1	36.4 ± 3.0	9.9 ± 0.0	18.8
Table 14: Benchmark: ColoredMNIST, Model selection: leave-one-domain-out cross-validation.
Algorithm	C	L	S	V	Avg
ERM	97.5 ± 0.8	60.3 ± 3.2	70.1 ± 4.2	75.5 ± 2.8	75.9
IRM	93.3 ± 2.7	61.8 ±0.4	72.9 ± 0.9	74.1 ± 3.1	75.5
IRMA	79.2 ± 12.8	66.8 ± 1.4	68.3 ± 4.1	73.5 ± 1.3	71.9
IRMv2	98.2 ± 0.1	63.0 ± 0.1	74.4 ± 1.2	69.9 ± 0.2	76.4
Table 17: Benchmark: VLCS, Model selection: leave-one-domain-out cross-validation.
Algorithm	ColoredMNIST	RotatedMNIST	PACS	VLCS	Avg
ERM	30.2 ± 4.3	96.0 ± 0.4	78.0 ± 0.9	75.9 ± 0.7	70.0
IRMv1	46.9 ± 2.1	94.8 ± 0.2	72.9 ± 3.0	75.5 ± 1.6	72.5
IRMv1A	43.1 ± 4.8	62.4 ± 21.6	74.0 ± 5.0	71.9 ± 2.8	62.8
IRMv2	18.8 ± 1.1	97.0 ± 0.1	82.5 ± 1.0	76.4 ± 0.3	68.7
Table 18: Model selection: leave-one-domain-out cross-validation.
Algorithm	+90%	+80%	-90%	Avg
ERM	72.2 ± 0.3	72.6 ± 0.4	12.4 ± 1.1	52.4
IRMv1	72.5 ± 0.3	72.9 ± 0.1	63.3 ± 6.6	69.6
IRMv1A	71.4 ± 0.2	72.8 ± 0.3	50.2 ± 0.1	64.8
IRMv2	70.6 ± 1.2	71.9 ± 0.6	20.9 ± 0.9	54.4
Table 19: Benchmark: ColoredMNIST, Model selection: test-domain validation set (oracle).
26
Under review as a conference paper at ICLR 2022
Figure 2: The figure depicts the evolution of test accuracy and the condition number of I(φ) in
relation to the dimension of the representation.
27