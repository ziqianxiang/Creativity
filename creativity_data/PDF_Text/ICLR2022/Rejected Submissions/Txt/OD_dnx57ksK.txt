Under review as a conference paper at ICLR 2022
Momentum Conserving Lagrangian Neural
Networks
Anonymous authors
Paper under double-blind review
Ab stract
Realistic models of physical world rely on differentiable symmetries that, in turn,
correspond to conservation laws. Recent works on Lagrangian and Hamiltonian
neural networks show that the underlying symmetries of a system can be easily
learned by a neural network when provided with an appropriate inductive bias.
However, these models still suffer from issues such as inability to generalize to ar-
bitrary system sizes, poor interpretability, and most importantly, inability to learn
translational and rotational symmetries, which lead to the conservation laws of
linear and angular momentum, respectively. Here, we present a momentum con-
serving Lagrangian neural network (MCLNN) that learns the Lagrangian of a
system, while also preserving the translational and rotational symmetries. We test
our approach on linear and non-linear spring systems, and a gravitational system,
demonstrating the energy and momentum conservation. We also show that the
model developed can generalize to systems of any arbitrary size. Finally, we dis-
cuss the interpretability of the MCLnn, which directly provides physical insights
into the interactions of multi-particle systems.
1	Introduction and Related Work
Realistic modeling of the time-evolution of multi-particle physical systems lie at the heart of several
fields of science and engineering (Goldstein, 2011; Park et al., 2021; Roehrl et al., 2020; Lutter
et al., 2019). Examples include multiple bodies connected by springs, bodies interacting under
gravitational forces, or even systems at the atomic and mesoscale such as proteins or colloidal gels,
which range several orders (≈ 1020) of length and timescales from atomic systems to planetary
systems (Park et al., 2021; Cranmer et al., 2020b). Traditionally, the trajectory of these systems are
obtained by solving the associated differential equations numerically. These differential equations,
in turn, are derived based on the invariant or conserved quantities of a system. Recent studies on
Lagrangian (LNN) and Hamiltonian neural networks show that one of these invariant quantities,
energy, can be learned directly from the data enabling realistic simulation of systems (Cranmer
et al., 2020a; Finzi et al., 2020; Lutter et al., 2019; Greydanus et al., 2019; Zhong et al., 2021;
2019; Zhong & Leonard, 2020). However, these approaches fail to model multi-particle interactions
effectively due to the following limitations.
•	Conservation of momentum: Invoking Noether’s theorem (Noether, 1971), “a differentiable
symmetry in action results in a conserved quantity”. Conversely, “every conserved quantity can be
derived from an underlying symmetry in action”. It can be shown that an interacting multi-particle
system, that is closed, respects three conservation laws, namely, energy, linear momentum and an-
gular momentum (Noether, 1971; Goldstein, 2011). While the first is a consequence of symmetry
of the system with respect to time, the second and third is a consequence of symmetry with respect
to translation and rotation in space, respectively. Thus, the Lagrangian of such a system remains
invariant under the translation and rotation operations on the Cartesian coordinates. For example,
three balls connected by a spring will have the same Lagrangian (and hence the interaction forces)
when the system as a whole is subjected to rotation or translation. That is, as long as the relative
positions of the balls are preserved, translation or rotation by any magnitude will not have an effect
on the system dynamics. While Lnns have been demonstrated to learn the symmetry in time by
conserving the energy (Cranmer et al., 2020a), they have not been designed to respect the other two
conservation laws with respect to momentum. Learning these symmetries directly from the data is
an extremely hard problem and may require large amounts of data. Furthermore, as we will show
1
Under review as a conference paper at ICLR 2022
in Sec. 4, even when trained on large volumes of training data, the Lnns fail to generalize well on
unseen data. This questions the realistic nature of the dynamics simulated by Lnns.
•	Generalizability to unseen system sizes: LNNs lack the ability to generalize to system sizes
beyond the training set. For instance, an Lnn trained on three balls connected by a spring cannot
model a system of four balls connected by a spring despite having the same conserved quantities
and interactions. This limits the broader applicability of Lnns to realistic physical systems.
•	Interpretability: LNN (Cranmer et al., 2020a) directly learns (and predicts) the Lagrangian of
a system as a function of the position and velocities of all the particles in the system. Owing to
this design, it is not possible to recover the inter-particle dynamics within a multi-particle system
in the form of pairwise potential energy or forces. This limits the interpretability of the Lnn as the
contribution of positions and velocities towards the total Lagrangian of the system is represented
using a black-box deep neural network.
In this paper, we address the above limitations. Specifically, our contributions are as follows:
•	Problem Formulation and Architecture Design: We reformulate LNN (Cranmer et al., 2020a)
with a relational inductive bias by applying a transformation on the Cartesian coordinates of the
system and decoupling the terms of the Lagrangian. Armed with this reformulation, we develop
a momentum conserving LNN called MCLNN. MCLNN introduces several key innovations. (1)
First, MCLNN preserves the rotational and translation symmetries. (2) Second, MCLNN gener-
alizes to unseen system sizes. (3) Third, MCLNN generates interpretable models with the output
characterizing pair-wise interactions of the bodies in the system, and thereby providing physical
insights into the system dynamics.
•	Theoretical Characterization: We rigorously establish that MCLNN conserves energy, linear
and angular momentum. Furthermore, in contrast to Lnn (Cranmer et al., 2020a), we show that
MCLnn can directly learn trajectories (positions) of systems without requiring training on accel-
eration. This is a desirable property. In many cases including experimental systems, access to
acceleration of each entity at every time instant may not be possible. While position of particles
is a direct observable, acceleration is a derived quantity.
•	Empirical Evaluation: We perform in-depth evaluation across three multi-particle systems
namely, balls connected by linear and non-linear springs, and gravitational system. Our exper-
iments establish that M CLnn performs significantly better than Lnn with long-term stability,
generalizes to arbitrary-sized multi-particle systems, and is capable of learning interaction dy-
namics with 3-4 orders of magnitude lower volume of training data.
2	Preliminaries and Problem Formulation
In this section, we introduce the preliminary concepts central to our work and formulate the problem.
As notational convention, vectors are represented with an overhead arrow (Ex. ~v) and higher-order
tensors, such as matrices, in bold. A summary notations used is provided in the appendix A.7.
Definition 1 (Multi-particle System) An N -body multi-particle system contains N particles P =
{nι, ∙∙∙ , nN}. At any given time t, particle n is characterized by its position ~t and velocity ~t.
The positions of particles in an N -body system are not static. They change due to various interaction
forces at play (Ex: a gravitational system). These positional changes are captured in the form of
trajectories.
Definition 2 (Multi-particle Trajectory) The trajectory of an N -body multi-particle system P
over a time horizon T = [ts,te] is the SequenCe of position and velocity vectors (qt, qt) | t ∈ T},
where qt = {qit | n ∈ P} and qt = {q1 | n ∈ P}.
In physics, the time-evolution or trajectory of interacting particles is obtained by solving the dif-
ferential equations of motion. The numerical solution to these equations provide the acceleration
of the particle, which can then be used to obtain the updated velocity and positions. Indeed, the
acceleration of particles can be directly learned by neural networks as a function of its position and
velocities. However, it fails to learn the underlying symmetries, which in turn leads to the laws of
conservation of energy and momenta.
Recent approaches to predict trajectories by learning the Lagrangian through an Lnn (Cranmer et al.,
2020a; Finzi et al., 2020; Zhong et al., 2021; Zhong & Leonard, 2020) has been shown to be effective
in learning the symmetry in time (Cranmer et al., 2020a; Zhong et al., 2021). Lagrangian, defined as
L(q, q) = T(q) - V(q),isa scalar functional Ofkinetic energy (T(q)) and potential energy (V(q)),
2
Under review as a conference paper at ICLR 2022
Lagrangian computation
Predicted Potential Energy
Timestamp t+1
Timestamp t
Position Information
Lt = Tt _ vt
Figure 1: MCLnn framework.
/V - body conf iguration
Velocity Information
T： = 0.5mi⅛f
Kinetic Energy
Lagrangian
(qf+7,年+7)
(Updated position
and velocities)
that depends on both the set of positions q, and velocities q of the particles in the system (Goldstein,
2011). Lnn bypasses the necessity to learn accelerations for each particle and directly predicts the
scalar Lagrangian for a system. Additionally, the trajectory predicted using Euler-Lagrange (EL)
equation conserves energy resulting in an overall better prediction of the system dynamics.
Theoretically, although learning the Lagrangian of a system is enough to predict its dynamics, the
Lagrangian itself exhibits some symmetries that are not imposed by the EL equation. Lagrangian
of a system exhibits translational and rotational symmetry. Specifically, the Lagrangian of a system
L(q, q) and L(q0, q), where q0 = {~i + ~ | ni ∈ P} for any finite value of r are equivalent.
Similarly, L(q, q) and L(Qq, q), where Q is an orthogonal tensor representing a rotation, are
equivalent. These symmetries are not provided as an inductive bias in the Lnn framework.
Further, Lnns are trained by giving the coordinates as input and minimizing the loss between the
actual acceleration and acceleration predicted by LNN through EL equations. This requires a priori
access to the actual acceleration, which may not be available in many cases, for example, experi-
mental trajectory of colloidal gels visualized by video camera.
Here, we aim to address these open challenges by reformulating the Lnn with a relational inductive
bias, resulting in Momentum Conserving LNN (MCLNN). Specifically, we aim to learn the dynamics
of multi-particle interacting systems purely from the trajectory of the constituent particles.
Problem 1 (Momentum Conserving Lnn for Trajectory Prediction) Let T be a set of trajecto-
ries of N -body systems. Furthermore, let there be a hidden joint distribution of physics-constrained
configurational and temporal space from which T has been sampled. Our goal is to learn this hidden
distribution. Towards that end, we want to learn:
i.	A generative model p(T) that maximizes the likelihood of generating T.
ii.	The generative model must respect the laws of physics such as conservation of energy and
momenta.
Once learned, this generative model can be used to predict trajectories of unseen N -body systems.
3	Theory
The flowchart of MCLnn is shown in Fig. 1. In this approach, the positions and velocities at any
time t is used to predict the trajectory of the system, while respecting the conservation laws of
energy and momenta. We analyze the performance of MCLnn on three systems, namely, linear
spring, non-linear spring, and gravitational system to predict the accurate dynamics of these multi-
particle interacting systems.
3.1	Euler-Lagrange Equation
Consider a system of N -particles interacting with each other under a potential. Let us define func-
tional, namely, “action”, S as:
S=Z t1Ldt
t0
(1)
where L is the Lagrangian of the system. Then trajectory taken by this system to move from the
position q0 to q1 in time t0 to t1 is the one that makes the “action” S stationary. This leads to the
3
Under review as a conference paper at ICLR 2022
equation of motion governing the dynamics of system, namely, the EL equation as:
d ∂L ∂L
----------------------------------------------=——
dt ∂q	∂q
(2)
The acceleration of particles in the system, q = {qi | ni ∈ P} can be computed directly from the
EL equation (see Appendix A.3) as:
q =(VqqL)-1 [VqL -(VqqL) q]	⑶
This acceleration can then be used to compute the updated positions and velocities of particles. Note
that EL equation leads to the conservation of Hamiltonian, defined as: H(q, q) = T(q) + V(q),
which also represents the total energy of the system.
3.2	Momentum Conserving Lagrangian Neural Network
As mentioned earlier, Lagrangians exhibit translational and rotational symmetry. Learning this di-
rectly from the positions of particles is extremely challenging. To address this challenge, we refor-
mulate the Lnn. Consider five balls connected by linear springs. We will use this running example
to explain MCLNN. The input for the MCLNN is the position and velocities at any time t. Further,
we identify the set of all the pairs of particles in the system as (i, j). For a given set, we compute the
difference between the positions followed by computing the l2 norm to obtain the pairwise distances
qij, which corresponds to the length of the spring. Thus,
qij = VZ(qi — ~) ∙ (qi — ~)	(4)
The qij is given as the input to a neural network which outputs a scalar Vij . Note that the Vij may
be considered to be the pair-wise potential energy of a spring connecting two particles i and j . Vij
summed over all the pairs of particles gives the V (q), the total potential energy of the system. For
multi-particle systems, the kinetic energy ofa particle ni is the function of its velocity q~i, can defined
as (Goldstein, 2011; Zhong et al., 2021):
1
Ti(~i) = 2 mi~2.	⑸
Here, we invoke this expression of kinetic energy, which when summed over all the particles provide
the total kinetic energy, T. Then, T and V are used to obtain the L as in Eq. 7. The L when
substituted into the EL equation (Eq. 2), provides the acceleration and the updated position and
velocities of the system using the velocity-Verlet integration (Rapaport, 2004). The loss function
of MCLNN is on the predicted and actual positions at time t + 1, t + 2, . . . , t + n, which is then
back-propagated to train the neural network. Specifically, the loss function is as follows.
L=木 ∀Xτ(力 XN (X Cr .qi - P Cr .a2))	⑹
Here, p(T.qit ) is the predicted position for the ith particle in T at time t and T.qit is the true
position. |T| denotes the last time step in trajectory T. The updated expression for Lagrangian for
an N -particle system can be written as:
n	n-1 n
L(q, q )= X 1 mi~2- X X Vij (qj)	⑺
i=1	i=1 j =i+1
It should be noted that the specific form of kinetic energy T does not limit the applicability of the
present approach (Zhong et al., 2021). Since, the focus of the work is to model multi-particle systems
and it is well-known that the kinetic energy of the system generally follows Eq. 5, we choose this
expression to simplify the problem. In cases where the expression for kinetic energy is not known or
is different, the function can be replaced by an additional neural network with an approach similar
to that for V.
3.3	Translational and rotational symmetry of MCLnn
Theorem 1 M CLNN exhibits translational and rotational symmetry.
PROOF. Consider, the Lagrangian of the system of N-particles as L(q, q) = T(q) 一 V(q). First,
we focus on the translational symmetry and next on rotational symmetry.
4
Under review as a conference paper at ICLR 2022
Lemma 1 MCLNN exhibits translational symmetry.
PROOF. When the particles are subjected to a translation ~, the updated positions are given by
q0 == {qi + ~ | n ∈ P}. The updated Lagrangian of the system is given by L(q0, q). To prove
L(q0, q) = L(q, q), We need to prove V(q0) = V(q) as the other term in the Lagrangian remains
unaffected. Applying the transformation on the positions and computing the l2 norm,
qij = J[(qi +葛一(qj + 钊•[⑷ +高一(qj + 葛])
=J (~ 一 ~) Yqi — ~)
=qij	(8)
which implies V(q0) = V(q). Therefore, L(q0, q) = L(q, q).
Lemma 2 MCLNN exhibits rotational symmetry.
PROOF. When the system is subjected to pure rotation, the positions are transformed as Qq, where
Q is an orthogonal tensor representing a rotation. Correspondingly, the Lagrangian is modified as
L(Qq, q). As in the case of translation, we need only to prove that V(Qq) = V(q). To prove this,
it is worth recalling that, for an orthogonal tensor Q, QQ t = Q t Q = I . Now, the proof can be
obtained by computing qj as:	__________________________
qij = (QQqi— - Qqj) ∙ (Q~ - Qq)
=，Q(~ - ~) ∙Q(~ - -)
=JQQt(~ - ~) ∙(- - qj)
=J(qi - qj) ∙ (~i - qj)
= qij	(9)
This implies that V(Qq) = V(q) and hence, L(q, q) = L(Qq, q). Thus, we demonstrate that the
Lagrangian in MCLnn exhibits both translational and rotational symmetry. Invoking Noether’s the-
orem, it can be proven that the Lagrangian preserving these symmetries will consequently conserve
of linear and angular momenta, respectively. (For proof, see App. A.4 and A.5).
Combining Lemma 1 and Lemma 2, we get that the MCLnn will respect the laws of conservation
energy, linear momentum, and angular momentum.
3.4 Generalizability and interpretab ility
The MCLnn exhibits a granular structure, which applies the computations on individual or pair-
wise entities that are aggregated to obtain the total Lagrangian of the system. This structure, by
design, allows model generalizability to unseen system sizes. Once trained on an n-body system,
the MCLNN can be applied on an m-body system (m 6= n) directly by replacing n with m in Eq. 7.
Finally, we discuss interpretability of MCLNN. The main function learned by MCLNN is the Vij ,
which depends on qij. Since, Vij adds to form the total potential energy V(q) of the system, it is
reasonable to assume that Vij represents the pair-wise potential energy. As we demonstrate later in
Sec. 4.4, we show that Vij indeed corresponds to the pair-wise potential energy of the ground truth.
4 Experiments
In this section, we benchmark MCLnn and establish:
•	Accuracy: MCLNN is more accurate in modeling trajectories of N -body systems than
Lnn (Cranmer et al., 2020a).
•	Conservation of Physics: Consistent with the theoretical analysis in Sec. 3.3, MCLNN preserves
the laws of physics more comprehensively than Lnn
•	Generalizability and Interpretability: MCLNN generalizes to unseen data better than LNN and
enables higher interpretability due to predicting the potential energy instead of the Lagrangian
directly.
The codebase along with all baselines used and the datasets are available at the anonymous reposi-
tory https://anonymous.4open.science/r/nbodyMCLNN-2618/.
5
Under review as a conference paper at ICLR 2022
4.1	Experimental Setup
We use JAX (Bradbury et al., 2020), a high-performance numerical computing python package and
JAX MD (Schoenholz & Cubuk, 2020), a JAX based molecular dynamics package for the n-body
simulations.
4.1.1	Tasks
To benchmark the performance of MCLnn, we conduct experiments on three multi-body systems,
namely, linear and non-linear springs, and gravitational systems.
•	Linear spring. We simulate the dynamics of three particles (e.g.: balls with volume tending to
zero) connected with each other by linear springs. The initial conditions of the simulations include
the positions and velocities of the three particles and the stiffness of the spring. The potential energy
of two balls connected by a spring is given by Vij = 1 k(qj - qo)2, where qj is the instantaneous
distance between the springs and q0 is the equilibrium distance, and k is the stiffness of the spring.
The force between connected pair of particles is computed as Fij
that the value of k is kept constant for all the springs.
dqj = -k(qij-qo). Note
•	Non-linear spring. We simulate the dynamics of three particles connected by non-linear springs.
The initial conditions of the simulations include the positions and velocities of the three particles.
The potential energy of two particles connected by a non-linear spring is given by Vij = 2 k(qj∙-
qo)4, where qij is the instantaneous distance between the springs and qo is the equilibrium distance,
and k is the stiffness of the spring. The force between connected pair of particles is computed as
Fij = -2k(qij - qo)3. The value of k is kept constant for all the springs.
•	Gravitational system. We simulate the dynamics of four particles interacting with each other
under the gravitational force. The initial conditions of the simulations include the positions and
velocities of the four masses. The potential energy of a pair of particles with mass m1 and m2 if
given by Vij = - GmIm2, where G is universal gravitational constant and qij∙ is the instantaneous
distance between the pair of particles. The force between the pair of particles is computed as Fij =
Gm2m2. Note that the mass m of all the particles are kept constant.
Data Generation: We use forward simulation ofN particles to generate training data corresponding
to each task. First, an N -body configuration with given initial positions and velocities are consid-
ered. The potential energy of the system is computed from the positions using analytical expressions
associated with each task as described above. The force on each particle is then calculated using as
the gradient of potential energy, which is used to compute the acceleration. Finally, the velocity-
Verlet algorithm is used for time integration to obtain the updated positions of the particles. Please
see the appendix (A.6) for configurations (including the number of particles, initial configuration,
and time step) of each of the tasks.
4.1.2	Baseline
The original Lnn takes both the positions and velocities of all the particles as input and gives the
total Lagrangian as the output. In the present case, we make the assumption on the functional form
of kinetic energy (see Eq.5). As such, to ensure a fair comparison, a slightly modified version of
the original Lnn is considered here as the baseline. For this baseline, the positions are given as
input to the neural network which gives the potential energy V (q~) as output. The kinetic energy is
computed using the functional form, from which the Lagrangian is computed. All the remaining
training procedures are maintained same as in the original Lnn. It should be noted that decoupling
the T and V terms and providing the expression for T should make the learning easier for the LNN
and hence should give improved performance in comparison to the original Lnn. This model will
be referred to as baseline or baseline Lnn, henceforth.
4.1.3	Metrics
To analyze the performance of the MCLnn in comparison to the baseline, the choice of the ap-
propriate metrics is crucial. Since the systems considered here are chaotic, slight differences in the
initial conditions or predictions will lead to differences in the trajectories. More importantly, given
the current state of a system, multiple “correct” trajectories may exist as long as they represent the
degenerate or equivalent configurational states of the system. As such, purely computing the error
in trajectory with respect to the ground truth may not be representative of the performance of the
model. Learning and predicting the Lagrangian ensures that the state of the system is represented ac-
6
Under review as a conference paper at ICLR 2022
----Model (Linear spring)
----MCLNN (Linearspring)
----Baseline (Linear spring)
Time step
Time step
Time step
MCLNN (Linear spring)
----Baseline (Linear spring)
Figure 2: Results of the forward simulation of linear spring system from the same initial config-
uration using ground truth (continuous line), baseline Lnn (dashed and dotted line) and MCLnn
(dashed lines). (a) The evolution of Lagrangian, Hamiltonian (total energy), linear and momentum
for all the systems. (b) The error in Lagrangian, Hamiltonian (total energy), linear and momentum
predicted by the baseline Lnn and MCLnn with respect to the ground truth.
-'MCLNN (Linear spring)z∙
- Baseline (Linear spdι⅛)
MCLNN (Linear spring)
----Baseline (Linear spring)
----Model (Linear spring) "
MCLNN (Linear spring) _
Baseline (Linear spring) _
---- Model (Linear spring)
MCLNN (Linear spring)
Baseline (Linear spring)
MCLNN (Linear spring]
Baseline (Linear spring]
MCLNN (Linear spring)
Baseline (Linear spring)
curately, resulting in the prediction of the same or equivalent trajectories of the system. Further, the
trajectories should respect the spatial and temporal symmetries resulting in conservation of Hamil-
tonian (total energy), linear, and angular momenta. Thus, we focus on the Mean Absolute Error
(MAE) between predicted (1) Lagrangian, (2) Hamiltonian (total energy), (3) linear and (4) angular
momenta, with respect to the ground truth.
4.1.4	Training
For training MCLnn, 100 different trajectories, each having 20 points with fixed time intervals, are
used for all three tasks. Each trajectory has different initial conditions and hence represent different
configurations that are accessible to the system. The model performance is evaluated by comparing
the predicted trajectory with respect to the ground truth for the same initial state.
For training Lnn, We sample 10,000 data points (Set of (q, q) as input) and q as output) from for-
ward simulations. The training is performed using the mean squared error between the acceleration
predicted by the EL equation and the ground truth. The detailed configurations and parameters
associated With simulation and training of each task is provided in App. A.6.
4.1.5	Inference
To asses the long term stability of models, We perform forWard simulations using trained Lnn
and MCLnn models for a prolonged time interval for each task. The initial condition and other
parameters are kept same for both Lnn and MCLnn. Furthermore, the initial conditions of the
trajectories during inference are different from those encountered during the training. Consequently,
all trajectories during evaluation are unseen. We record Lagrangian, Hamiltonian, linear momentum
and angular momentum for the Whole trajectory. The predicted forWard simulation is compared With
the ground truth data as generated in Sec. 4.1.1.
4.2	Accuracy
First, We focus on the linear spring system With three particles. Figure 2(a.1)-(a.4) shoWs the La-
grangian, Hamiltonian (total energy), linear, and angular momenta of the system. The error in these
quantities predicted by the baseline Lnn and MCLnn are shoWn in Figure 2(b.1)-(b.4). We observe
that the Lagrangian predicted by the baseline Lnn starts diverging after 30 time steps of the forWard
simulation. We notice that the divergence in the Lagrangian is accompanied by a divergence in the
linear momentum as Well. Up on further simulation, the angular momentum also starts diverging.
In contrast, the Lagrangian predicted by the MCLnn folloWs the ground truth With very little error.
Further, the Hamiltonian, and linear and angular momenta remain conserved in the MCLnn. This
suggests that the trajectory predicted by the MCLnn is accurate and stable With no long term drift
or divergence. It is Worth noting that, for the baseline Lnn, despite the poor predictions of the La-
grangian at higher values of time steps, the total energy remain conserved. This points to the fact
that the energy conservation is a constraint enforced by the EL equation and is not a reflection on
the quality Lagrangian. Any value of Lagrangian can still yield a constant Hamiltonian (energy),
provided the constraints as imposed by the EL equations on the Lagrangian are satisfied. As such,
Lnns should be evaluated considering multiple metrics as demonstrated here.
7
Under review as a conference paper at ICLR 2022
Model(Non-IinearSPring夕
MCLNN (Non-linear sprang)
Baseline (Non-Ii
---Model (Non-Iinearspring)
---MCLNN (Non-Iinearspring
---Baseline (Non-linear sprin
U 史
---MCLNN(Non-Iinearspring).
----Baseline (Non-linear spring) _
1000	2000	3000
1000	2000	3000
Time step
0	1000	2000	3000
(b.3)	Time step	(b.4)
1000	2000	3000
Time step
----ModeI(Non-IinearSPriQg7、
----MCLNN (Non;[uΛ^⅛r spring)
----BaseIiiiMNon-Iinear spring)
Model (Non-Iinearspring)
MCLNN (Non-linear spring)
----Baseline (Non-Iinearspring)
(b.l)
Time step	(b.2)
Ue-Uo+J=EeH
-ΦE0E t-raφ⊂~-
5 _---MCLNN (NOn-Iinea「spri用
----Baseline (Non-linear spring)
----MCLNN (Non-Iinearspring)
----Baseline (Non-linear sprin
lime step
Time step
----Model (Gravitational)
MCLNN (Gravitational)
Baseline (Gravitational)
----Model (Gravitational)
--MCLNN (Gravitational)
----Baseline (Gravitational)
∙"N迎
1000	2000	3000
Time step
----Model (Gravitational)
■ -" MCLNN (Gravitational)
----Baseline (Gravitational)
O	500 IOOO 1500	- O	500 IOOO 1500	O	500 IOOO 1500	O	500 IOOO 1500
Time step	Time step	Time step	Time step
Figure 3: Results of the forward simulation of non-linear spring, and gravitational system from the
same initial configuration using ground truth (continuous line) and MCLnn (dashed lines). (a) The
evolution of Lagrangian, Hamiltonian (total energy), linear and momentum for all the systems. (b)
The error in Lagrangian, Hamiltonian (total energy), linear and momentum predicted by the baseline
Lnn and MCLnn with respect to the ground truth.
Now, we focus on the non-linear spring and the gravitational system. Figure 3(a) and (c) shows the
Lagrangian, Hamiltonian (total energy), linear, and angular momenta of the non-linear spring and
gravitational systems. The error in these quantities predicted by the baseline Lnn and MCLnn are
shown in Figure 2(b) and (d). As in the case of the linear spring system, we observe that there is a
long term drift in the Lagrangian predicted by the baseline Lnn. Similarly, the linear and angular
momenta of the baseline also diverge in a few time steps. In contrast, the Lagrangian predicted
by the MCLnn exhibits a good match with the ground truth. It should be noted that the multi-
particle interacting systems are chaotic in nature and hence the exact trajectory of the ground truth
and simulated system may vary. However, the low values of error in the Lagrangian along with the
long-term stability of both non-linear spring and gravitational system suggests the realistic nature of
the trajectory predicted by MCLnn. In addition, we observe that the linear and angular momenta
of the system remain conserved in the MCLnn. Altogether, the results confirm that the MCLnn
can successfully learn the generative model p(T) that can sample the trajectory effectively from the
physics-constrained configurational and temporal space.
4.3 Generalizability to unseen system sizes
To demonstrate the generalizability of MCLNN, we use the generative model p(T) for each of
the tasks learned during the training. The models are then used to predict trajectories of systems
Q,8.6/ 2
Lo.SCi0.
u(ŋ- 6ueJ6ΓD1
Figure 4: Results of the forward simulation of (a) linear spring with 6 particles, (b) non-linear spring
with 6 particles, and (b) gravitational system with 8 particles from the same initial configuration
using ground truth (continuous line) and MCLnn (dashed lines). The evolution of Lagrangian for
all the systems are plotted.
8
Under review as a conference paper at ICLR 2022
Figure 5: Variation of Vij with respect to qij as learned by the MCLNN (dashed line) in comparison
to the ground truth (continuous line) for (a) linear spring, (b) non-linear spring, and (c) gravitational
potential. The shaded region represents the range of qij values in the training set. Non-shaded region
between two shaded region corresponds to interpolation; otherwise, it represents extrapolation.
with different number of particles. Figure 4 shows the trajectories for linear and non-linear springs
with six particles (MCLnn trained on three particles), and gravitational system with eight particles
(MCLnn trained on four particles), predicted by the MCLnn in comparison to the ground truth. We
observe that the Lagrangian predicted by the MCLnn exhibits excellent match with the ground truth.
In addition, all other quantities such as energy and momenta remain conserved (see Appendix Fig. 7).
This suggests that once the generative model p(T) has been learned, MCLNN can generalize it to
predict the trajectory of systems with any number of particles. Note that the baseline Lnn cannot
simulate systems of different sizes as the positions of all the particles are given simultaneously as
the input to the neural network.
4.4 Interpretability
Figure 5 shows the Vij predicted by the MCLNN in comparison to the pair-wise potential energy
obtained analytically from ground truth. The shaded region represents the qij values that were
present in the training set. We observe that the MCLnn is able to learn the pairwise potential energy
function accurately for the qij values in the training set. Further, the MCLNN is able to interpolate
values excellently and extrapolate reasonably. It is worth noting that the MCLnn is trained only on
the trajectories of the system. Hence, no information regarding the potential energy, force, or even
acceleration is given to the neural network during training. This suggests that MCLnn is indeed
able to learn the physics of the problem by training purely on the trajectory.
5	Conclusion
We introduced a new framework, namely, momentum conserving Lagrangian neural networks
(MCLnn), for incorporating physics-based priors in neural networks for accurate simulations of
multi-particle systems. We demonstrated that the MCLnn respects the symmetries in space and
time, leading to conservation of energy, and linear and angular momentum. We showed that the
incorporation of these additional conservation laws of momenta makes the Lagrangian of the system
stable by avoiding any long-term drift in it. This, in turn, results in a realistic simulation of multi-
body systems. Further, we showed that the MCLnn once trained, can generalize to systems of any
size. Finally, we demonstrated that the MCLnn is highly interpretable and provides direct insights
into the interaction laws governing the dynamics of multi-particle systems. This, in turn, allows one
to verify the realistic nature of the function learned by the MCLnn.
At this juncture, it is worth discussing some of the open questions and shortcomings of MCLnn that
can be addressed as part of future works. (i) MCLNN assumes interaction between all the particles
in the system. A graph-based MCLnn with contrastive loss can potentially address this challenge
by incorporating the topology of the particle system along with differential importance for nearby
particles. (ii) MCLNN considers only pair-wise interactions for computing the Vij . However, there
could be additional interactions involving three (Vijk), four (Vijkl) or even higher particles. This
could be addressed by feature engineering or graph-based MCLNN. (iii) Similarly, simulations in-
volving different types of interacting particles is challenging in MCLnn as it may lead to non-unique
solutions. (iv) In addition, present work can be extended to address more challenging problems, for
instance, to learn the Lagrangian of system with non-conservative forces, and to learn generalized
kinetic energy functions, while maintaining the granularity and generalizability.
9
Under review as a conference paper at ICLR 2022
6	Reproducibility Statement
Please find all codes and experiments at the following anonymous link: https:
//anonymous.4open.science/r/nbodyMCLNN-2618/. In Appendix A.6, we have given addi-
tional details to make the work completely reproducible. In particular, we have: (1) additional
derivations and proofs in App. A.3,A.4,A.5, (2) initial conditions, task configurations, and param-
eters for the training of neural networks used for each task in App. A.6, (3) detailed notation in
App. A.7. The dataset generation (using simulations) step is added to the code before training step
and hence there are no additional dataset files are provided.
References
James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal
Maclaurin, and Skye Wanderman-Milne. Jax: composable transformations of python+ numpy
programs, 2018. URL http://github. com/google/jax, 4:16, 2020.
Miles Cranmer, Sam Greydanus, Stephan Hoyer, Peter Battaglia, David Spergel, and Shirley Ho.
Lagrangian neural networks. In ICLR 2020 Workshop on Integration of Deep Neural Models and
Differential Equations, 2020a. URL https://openreview.net/forum?id=iE8tFa4Nq.
Miles Cranmer, Alvaro Sanchez Gonzalez, Peter Battaglia, Rui Xu, Kyle Cranmer, David Spergel,
and Shirley Ho. Discovering symbolic models from deep learning with inductive biases. Advances
in Neural Information Processing Systems, 33, 2020b.
Marc Finzi, Ke Alexander Wang, and Andrew G Wilson. Simplifying hamiltonian and lagrangian
neural networks via explicit constraints. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Bal-
can, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp.
13880-13889. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/
file/9f655cc8884fda7ad6d8a6fb15cc001e-Paper.pdf.
Herbert Goldstein. Classical mechanics. Pearson Education India, 2011.
Samuel Greydanus, Misko Dzamba, and Jason Yosinski. Hamiltonian neural networks. Advances
in Neural Information Processing Systems, 32:15379-15389, 2019.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR (Poster),
2015. URL http://arxiv.org/abs/1412.6980.
Michael Lutter, Christian Ritter, and Jan Peters. Deep lagrangian networks: Using physics as model
prior for deep learning. In International Conference on Learning Representations, 2019. URL
https://openreview.net/forum?id=BklHpjCqKm.
Emmy Noether. Invariant variation problems. Transport theory and statistical physics, 1(3):186-
207, 1971.
Cheol Woo Park, Mordechai Kornbluth, Jonathan Vandermause, Chris Wolverton, Boris Kozinsky,
and Jonathan P Mailoa. Accurate and scalable graph neural network force field and molecular
dynamics with direct force architecture. npj Computational Materials, 7(1):1-9, 2021.
Dennis C Rapaport. The art of molecular dynamics simulation. Cambridge university press, 2004.
Manuel A Roehrl, Thomas A Runkler, Veronika Brandtstetter, Michel Tokic, and Stefan Obermayer.
Modeling system dynamics with physics-informed neural networks based on lagrangian mechan-
ics. IFAC-PapersOnLine, 53(2):9195-9200, 2020.
Samuel Schoenholz and Ekin Dogus Cubuk. Jax md: a framework for differentiable physics. Ad-
vances in Neural Information Processing Systems, 33, 2020.
Yaofeng Desmond Zhong and Naomi Leonard. Unsupervised learning of lagrangian dynamics from
images for prediction and control. Advances in Neural Information Processing Systems, 33, 2020.
Yaofeng Desmond Zhong, Biswadip Dey, and Amit Chakraborty. Symplectic ode-net: Learning
hamiltonian dynamics with control. In International Conference on Learning Representations,
2019.
10
Under review as a conference paper at ICLR 2022
Yaofeng Desmond Zhong, Biswadip Dey, and Amit Chakraborty. Benchmarking energy-conserving
neural networks for learning dynamics from data. In Learning for Dynamics and Control, pp.
1218-1229. PMLR, 2021.
11
Under review as a conference paper at ICLR 2022
(a)
①u」OJ P①υ-p①」d
1.00
0.75
0.50
0.25
0.00
1.25
A	Appendix
A.1 Baseline Lnn
Figure 6 shows the predicted force with respect to the actual force for the training data of baseline
for the three tasks.
①。」OJ P①tj-p①」d
1	2
Measured force
(c)
①u」OJ PBE-Pgd
0	12	3
Measured force
Figure 6: Predicted force for (a) linear spring, (b) non-linear spring, and (c) gravitational system
with respect to the measured forces on the test dataset of baseline Lnn.
A.2 Generalizability to unseen system sizes
Figure 7 shows the generalizability of the MCLnn to unseen system sizes for the three tasks consid-
ered. For all the three tasks, the number of particles considered are twice that of the training system
size. We observe that the Lagrangian for the unseen system is predicted in excellent agreement to
the ground truth for all the three tasks. In addition, the Hamiltonian (total energy), and momenta are
conserved in all the three tasks, confirming the realistic nature of the simulations by MCLnn.
Linear spring (6 bodies)
MCLNN
(b.2)
一 一- 一- 一- 一一 I
4 2 0 8 6
LLLO.S
(APBUB -SQL)
Uuuol=UJBH
50	100	150	200
Time step
UJrqU ① EOIUJB-n6E<
0	50	100	150	200
(c.l)	Time step
(A6」① U ①-SQL)
UWUOL=一UeH
--- Gravitational (8 bodies)
——MCLNN
:-- Non-Iinearspring (6 bodies)
--MCLNN
50	100	150	200
Time step
1	0	50	100	150	200
(c.4)	Time step
(c.2)
(AP ①U ① 一5QL)
UoUoi=UJeH
ɪ,ʊ 0	50	100	150	200
(c∙3ι) o X10-IQ Time step______________________________
Gravitational (8 bodies)
MCLNN
0	50	100	150	200	0	50	100	150	200	^ u 0	50	100	150	200	0	50	100	150	200
Time step	Time step	Time step	Time step
Figure 7: Results of the forward simulation of (a) linear spring, (b) non-linear spring, and (b) gravita-
tional system from the same initial configuration using ground truth (continuous line) and MCLnn
(dashed lines). The evolution of Lagrangian, Hamiltonian (total energy), linear and angular mo-
menta for all the systems with different number of particles than that was present in the training set
are plotted.
12
Under review as a conference paper at ICLR 2022
A.3 Computing acceleration from Euler-Lagrange equations
The acceleration of particles can be obtained from the Euler-Lagrange equations as follows.
∂ dL ∂L
----=——
∂q dt ∂q
∂ (∂L dq ∂Ldq ∖ _ ∂L
∂q ( ∂q dt + ∂q dt J ∂q
∂ ∂L ∂L ∂L
∂q (∂qq + ∂qqJ	∂q
∂ ∂L.	∂ ∂L _ ∂L
<Λ * <Λ q.+ <Λ * <Λ * q	C
∂ q ∂ q	∂ q ∂ q	∂q
∂ ∂L _ ∂L ∂ ∂L.
<Λ * <Λ * q	C	<Λ	*	<Λ	q
∂ q ∂ q	∂q	∂ q	∂ q
_ L ∂ ∂Lλ-1 Γ∂L ∂ ∂L .^
q (∂q ∂<q J ∂q ∂q ∂q q
q=(V<wL厂 1[VqL -(VqqL) q]
A.4 Translational Symmetry
The conservation of linear momentum can be derived from translational symmetry of Lagrangian as
follows.
L(q,q) = L(q + e, q)
q 0 = q + e
∂q 0 _
而=
Σ
∂L
∂ q
∂L	∂L ∂q
∂q 0	∂q ∂q 0
δL
∂L
'∂q
∂L
∂q
δL=Xδq H
Σ
δL = W
Σ
^L ∙1
13
Under review as a conference paper at ICLR 2022
since,	δL = 0 ∂L =⇒ Edq = 0 x ∂L=0 ∂q d ∂L == 0 乙 dt ∂q d	∂L =0 dt 乙 ∂q ∂L 〉^ = constant ∂q ∂q Pi = constant (linear momentum)
where Pi =	∂L — ∂qi
A.5 Rotational Symmetry
The conservation of angular momentum can be derived from rotational symmetry of Lagrangian as
follows.
Under an infinitesimal rotation δθ
δq~i = δθ × q~i
and
δqi = δθ X ~i
since, Lagrangian does not change with infinitesimal rotation δθ
	∂L	∂L δL = E 万二"δqi + E δqi=0 = 0 V d~i	V ∂~i
using generalized momentum
∂L
~∑p = Pi
14
Under review as a conference paper at ICLR 2022
then EL equation gives	d	∂L 加Pi-福=0 ∂L Pi = τττ ∂qqi =⇒ δL = X qi ∙ δqi + X ~i ∙ δq = 0 ii
£pv (δθ X ~i) + Pi ∙ (δθ X ~i) = 0
i
X δθ∙ (qi X Pi) + δθ∙ (qi X Pi) = O
i
X δθ∙ [(~i X pi) + (qi X pi)] = 0
i
X δθ∙ ddt(qiX Pi) = O
i
because δθ is arbitrary, then
X ddt (qiX Pi) = O
i
d (X qiX Pi) = O
i
angular momentum =	(qri X qPi ) = constant
i
A.6 Initial Conditions and Task Configuration
The number of hidden units are chosen from hyperparamter search given in Table 1. The activation
function for all hidden units are square plus f (x) = (X+'χ2+4) which is similar to soft plus (Cran-
mer et al., 2020a). We use ADAM (Kingma & Ba, 2015) optimiser for model training with learning
rate given in respective configuration tables. We use velocity-Verlet for time integration during
trajectory evolution. Mass of all the particles are maintained as 1.0 units.
A.6. 1 Linear Spring System
O.4866576788945O5
Initial position = -O.681737994414464
-O.O2259632746864O
-O.1827O9864466916
Initial velocity = -O.579O7492254O872
O.761784787OO7641
O.755O41888583519	O.O
O.29366O23319721O	O.O
-O.6126456O1255358 O.O
O.363O13287999OO4	O.O
-O.748157481446O87 O.O
O.385144193447218	O.O
Table 1: Train and validation loss for each NN architecture for the linear spring task for MCLnn.
Note that for hyperparamter search (i.e. number of hidden units), minimum train loss was set to
1.0e-8 as stopping criteria.
Hidden Layers	Linear Spring
2, 2 4, 4 8, 8 16, 16	0.0012, 0.0015 7.98e-09, 2.36e-08 9.86e-09, 3.80e-08 9.76e-09, 3.02e-08
15
Under review as a conference paper at ICLR 2022
dt = 0.01
mass = 1.0
stride = 10
runs = 20 = points per trajectory
lr= 1.0e-3
layers = [10, 10]
epochs = 100000
samples = 100 = number of trajectories
seed = 100
time step = dt × stride = 0.1
A.6.2 Non-linear Spring System
	0.486657678894505	0.755041888583519	0.0
Initial position =	-0.681737994414464	0.293660233197210	0.0
	-0.022596327468640	-0.612645601255358	0.0
	-0.182709864466916	0.363013287999004	0.0
Initial velocity =	-0.579074922540872	-0.748157481446087	0.0
	0.761784787007641	0.385144193447218	0.0
dt = 0.01			
mass = 1.0
stride = 10
runs = 20 = points per trajectory
lr= 1.0e-3
layers = [10, 10]
epochs = 100000
samples = 100 = number of trajectories
seed = 100
time step = dt × stride = 0.1
A.6.3 Gravitational System
Initial position
Initial velocity
1.0	0.0	0.0
9.0	0.0	0.0
11.0	0.0	0.0
-1.0	0.0	0.0
二 0.0	0.05	0.0
0.0	-0.05	0.0
0.0	0.65	0.0
0.0	-0.65	0.0
dt = 0.01
mass = 1.0
stride = 10
runs = 20 = points per trajectory
lr= 1.0e-3
layers = [10, 10]
epochs = 100000
samples = 100 = number of trajectories
seed = 100
time step = dt × stride = 0.1
16
Under review as a conference paper at ICLR 2022
A.7 Default Notation
a ~a A In I e(i)	A scalar (integer or real) A vector A matrix Identity matrix with n rows and n columns Identity matrix with dimensionality implied by context Standard basis vector [0, . . . , 0, 1, 0, . . . , 0] with a 1 at po- sition i
~ai Ai,j Ai,: A:,i Ai,j,k A:,:,i dy dx	Vector corresponding to particle i Element i, j of matrix A Row i of matrix A Column i of matrix A Element (i, j, k) of a 3-D tensor A 2-D slice of a 3-D tensor Derivative of y with respect to x
∂y ∂x V~L ▽x y ∂f ∂x f (x)dx f (x)dx S P(a) p(a)	Partial derivative of y with respect to x Gradient of L with respect to ~x Matrix derivatives of y with respect to X Jacobian matrix J ∈ Rm×n of f : Rn → Rm Definite integral over the entire domain of x Definite integral with respect to x over the set S A probability distribution over a discrete variable A probability distribution over a continuous variable, or over a variable whose type has not been specified
17