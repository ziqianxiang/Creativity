Under review as a conference paper at ICLR 2022
Anarchic Federated Learning
Anonymous authors
Paper under double-blind review
Ab stract
Present-day federated learning (FL) systems deployed over edge networks consists
of a large number of workers with high degrees of heterogeneity in data and/or
computing capabilities, which call for flexible worker participation in terms of
timing, effort, data heterogeneity, etc. To achieve these goals, in this work, we
propose a new FL paradigm called “Anarchic Federated Learning” (AFL). In stark
contrast to conventional FL models, each worker in AFL has complete freedom to
choose i) when to participate in FL, and ii) the number of local steps to perform in
each round based on its current situation (e.g., battery level, communication chan-
nels, privacy concerns). However, AFL also introduces significant challenges in
algorithmic design because the server needs to handle the chaotic worker behaviors.
Toward this end, we propose two Anarchic Federated Averaging (AFA) algorithms
with two-sided learning rates for both cross-device and cross-silo settings, which
are named AFA-CD and AFA-CS, respectively. Somewhat surprisingly, even with
general worker information arrival processes, we show that both AFL algorithms
achieve the same convergence rate order as the state-of-the-art algorithms for
conventional FL. Moreover, they retain the highly desirable linear speedup effect
in the new AFL paradigm. We validate the proposed algorithms with extensive
experiments on real-world datasets.
1 Introduction
Federated Learning (FL) has recently emerged as an important distributed learning framework that
leverages numerous workers to collaboratively learn a joint model (Li et al., 2019a; Yang et al., 2019;
Kairouz et al., 2019). Since its inception, FL algorithms have become increasingly powerful and
have been able to handle various heterogeneity in data, network environments, worker computing
capabilities, etc. Moreover, most of the prevailing FL algorithms (e.g., FedAvg (McMahan et al.,
2016) and its variants (Li et al., 2018; Zhang et al., 2020b; Karimireddy et al., 2020b;a; Acar et al.,
2021)) enjoy so-called “linear speedup effect,” i.e., the convergence time ofanFL algorithm decreases
linearly as the number of workers increases (Stich, 2018; Yu et al., 2019; Wang & Joshi, 2018; Khaled
et al., 2019; Karimireddy et al., 2020b; Yang et al., 2021; Qu et al., 2020).
To achieve these salient features, most of the existing FL algorithms have adopted a server-centric
approach, i.e., the worker behaviors are tightly “dictated” by the server. For example, the server in
these FL algorithms can i) determine either all or a subset of workers to participate in each round of
FL update; ii) fully control the timing for synchronization and whether to accept/reject information
sent from the workers; iii) precisely specify the algorithmic operations (e.g., the number of local
steps performed at each worker before communicating with the server), etc.
Despite achieving strong performance guarantees, such a server-centric approach introduces several
limitations. Specifically, these server-centric FL algorithms often implicitly rely on the following
assumptions: (1) each worker is available for training upon the server’s request and throughout a
complete round; (2) all participating workers are willing to execute the same number of local updates
and communicate with the server in a synchronous manner following a common clock. Unfortunately,
in edge networks where many FL systems are deployed, these assumptions are restrictive or even
problematic due to the following reasons. First, many requested edge devices on the worker side may
not be available in each round because of, e.g., communication errors or battery outages. Second,
the use of synchronous communication and an identical number of local updates across all workers
ignores the fact that worker devices in edge-based FL systems are heterogeneous in computation
and communication capabilities. As a result, stragglers (i.e., slow workers) could significantly slow
1
Under review as a conference paper at ICLR 2022
down the training process. To mitigate the straggler effect, various robust FL algorithms have been
developed. For example, the server in FedAvg (McMahan et al., 2016) can simply ignore and drop
the information from the stragglers to speedup learning. However, this may lead to other problems
such as wasted computation/energy (Wang et al., 2019), slower convergence (Li et al., 2018), or
biased/unfair uses of worker data (Kairouz et al., 2019). Moreover, the synchronous nature of the
server-centric approaches implies many networking problems (e.g., interference between workers,
periodic traffic spikes, high complexity in maintaining a network-wide common clock).
The above limitations of the current server-centric FL approaches motivate us to propose a new
paradigm in FL, which we call Anarchic Federated Learning (AFL). In stark contrast to server-
centric FL, workers in AFL are completely free of the “dictation” from the server. Specifically, each
worker has complete freedom to choose when and how long to participate in FL without following
any control signals from the server. As a result, the information fed back from workers is inherently
asynchronous. Also, each worker can independently determine the number of local update steps
to perform in each round based on its current local situation (e.g., battery level, communication
channels, privacy concerns). In other words, the amount of local computation at each worker is
time-varying, device-dependent, and fully controlled by the worker itself. Clearly, AFL has a much
lower server-worker coordination complexity and avoids the aforementioned pitfalls in server-centric
FL approaches. However, AFL also introduces significant challenges in algorithmic design on the
server-side because the server needs to work much harder to handle the chaotic worker behaviors in
AFL (e.g., asynchrony, spatial and temporal heterogeneity in computing). Toward this end, several
fundamental questions naturally arise: 1) Is it possible to design algorithms that converge under
AFL? 2) If the answer to the previous question is yes, how fast could the algorithms converge? 3)
Can the new AFL-based algorithms still achieve the desired “linear speedup effect?”
In this paper, we answer the above fundamental questions of AFL affirmatively. Our main contribu-
tions and key results are summarized as follows:
•	We propose a new FL paradigm called Anarchic Federated Learning (AFL), where the workers are
allowed to engage in training at will and choose the number of local update steps based on their
own time-varying situations (computing resources, energy levels, etc.). This loose worker-server
coupling significantly simplifies the implementations and renders AFL particularly suitable for
FL deployments in edge computing environments. For any AFL algorithms under general worker
information arrival processes and non-i.i.d. data across workers, we first establish a fundamental
convergence error lower bound that depends on the data heterogeneity in the AFL system. Then,
we propose two Anarchic Federated Averaging (AFA) algorithms with two-sided learning rates for
two classes of FL problems(cross-device and cross-silo) (Kairouz et al., 2019; Wang et al., 2021).
•	For AFL in the cross-device (CD) setting, our AFA-CD algorithm converges to an error ball whose
size matches the fundamental lower bound, with an O(1NmT) convergence rate where m is the
number of collected workers in each round of update and T is the total number of rounds. We
note that this convergence rate retains the highly desirable “linear speedup effect” under AFL.1
Moreover, under the special case with uniform workers’ participation (equivalent to uniform
workers sampling in conventional FL (Li et al., 2019c; Karimireddy et al., 2020b;a; Acar et al.,
2021)), AFA-CD can further converge to a stationary point (i.e., a singleton) at a convergence rate
that matches the state-of-the-art of conventional distributed and federated learning.
•	For AFL in the cross-silo (CS) setting, our proposed AFA-CS algorithm achieves an enhanced
convergence rate of O(1/√MT) by leveraging historical feedback and variance reduction tech-
niques, where M is the total number of workers. This suggests that, not only can “linear speedup”
be achieved under AFL-CS, the speedup factor also depends on the total number of workers M
instead of the number of collected workers min each round (M > m). To our knowledge, this
result is new in the FL literature.
•	We validate the proposed algorithms with extensive experiments on CV and NLP tasks and further
explore the effect of the asynchrony and local step number in AFL. We also numerically show that
our AFL is a general algorithmic framework in the sense that various advanced FL techniques (e.g.,
FedProx (Li et al., 2018) and SCAFFOLD (Karimireddy et al., 2020b)) can be integrated as the
optimizers in our AFA framework to further enhance the AFL performance.
1To attain ^accuracy, it takes O(1∕e2) steps for an algorithm with an O(1∕√T) convergence rate, while
needing O(1∕me2) steps for another algorithm with an OQNlmr) convergence rate (the hidden constant in
Big-O is the same). In this sense, O(1 /√mT) implies a linear speedup with respect to the number of workers.
2
Under review as a conference paper at ICLR 2022
The rest of the paper is organized as follows. In Section 2, we review related work. In Section 3,
we introduce AFL and our AFA algorithms, which are followed by their convergence analysis in
Section 4. We present the numerical results in Section 5 and conclude the work in Section 6.
2	Related work
Server-Centric Federated Learning Algorithms: To date, one of the prevailing FL algorithms is
Federated Averaging (FedAvg), which was first proposed in (McMahan et al., 2016) as a heuristic to
improve communication efficiency and data privacy for FL. Since then, there have been substantial
follow-ups of FedAvg that focus on non-i.i.d. (heterogeneous) data (see, e.g., FedProx (Li et al.,
2018), FedPD (Zhang et al., 2020b), SCAFFOLD (Karimireddy et al., 2020b), FedNova (Wang
et al., 2020), FedDyn (Acar et al., 2021), and MIME (Karimireddy et al., 2020a)), which are closely
related to our work. The main idea for these algorithms is to control the “model drift” (due to
heterogeneous datasets and the use of multiple local update steps on the worker side of FedAvg).
While these algorithms achieved various degrees of success in dealing with data heterogeneity, they
are all server-centric synchronous algorithms that are not easy to implement in edge-based FL due to
straggler issues (see discussions in Section 1).
Federated Learning with Flexible Worker Participation: Recently, some attempts have been
made to alleviate the strict requirements on worker’s participation, such as allowing different local
steps (Ruan et al., 2021; Wang et al., 2020) and asynchronous FL (Avdiukhin & Kasiviswanathan,
2021; Xie et al., 2019). However, most of these works either lack theoretical performance guarantees
or require strong assumptions. For example, Ruan et al. (2021) assumed strongly convex loss function
and bounded aggregation coefficient; Avdiukhin & Kasiviswanathan (2021) assumed bounded
gradients and same computation time per iteration for all workers. Our AFL paradigm considered in
this paper is more general and subsumes all the above settings as special cases. We note, however, that
AFL differs from conventional FL with flexible worker participation in that the worker’s participation
in AFL and its local optimization process are completely determined by the workers, and not by the
sampling requests from the server. This is more practical since it allows workers to participate in
FL under drastically different situations in network, charging/idle cycles, etc. Due to the complex
couplings between various sources of randomness and multiple layers of heterogeneity in spatial and
temporal domains in AFL, the training algorithm design for AFL and its theoretical analysis is far
from a straightforward combination of existing FL techniques for flexible worker participation.
Asynchronous Distributed Optimization: The asynchrony in AFL also shares some similarity with
asynchronous distributed optimization. The basic idea of asynchronous distributed optimization is to
forgo the common clock in the system to lower the system implementation complexity in distributed
optimization. However, due to extra noise introduced by asynchrony, it is highly non-trivial to
establish the convergence performance of asynchronous distributed optimization algorithms. To
address this challenge, asynchronous distributed optimization has been studied extensively in the
machine learning and optimization literature (see, e.g., Lian et al. (2018); Niu et al. (2011); Agarwal
& Duchi (2012); Paine et al. (2013); Xie et al. (2019); Zhang et al. (2020a) and references therein).
We note that the AFL paradigm considered in this paper is more general and subsumes asynchronous
distributed optimization as a special case. To see this, note that in addition to the asynchronous
updates at the server, the workers in AFL could further have different numbers of local update steps.
Moreover, the workers may not even need to be work-conserving (i.e., workers could be idle between
rounds of updates). As a result, the convergence analysis of AFL is much more challenging.
3	Anarchic federated learning
1)	Overview of Anarchic Federated Learning: The goal of FL is to solve an optimization problem
in the form of mg∈Rd f (x)：= 寺 PM=I fi(x), Where fi(x)，Eξi^Di [fi(x, ξi)] is the local (non-
convex) loss function associated with a local data distribution Di and M is the total number of workers.
For the setting With heterogeneous (non-i.i.d.) datasets at the Workers, We have Di 6= Dj, if i 6= j. In
terms of the assumption on the size of Workers, FL can be classified as cross-device FL and cross-silo
FL (Kairouz et al., 2019; Wang et al., 2021). Cross-device FL is designed for large-scale FL With
a massive number of mobile or IoT devices (M is large). As a result, the server can only afford to
collect information from a subset of Workers in each round of update and does not have sufficient
3
Under review as a conference paper at ICLR 2022
Algorithm 1 The Basic Framework of Anarchic Federated Learning (AFL).
At the Server (Concurrently with Workers):
1.	(Concurrent Thread) Collect local updates returned from the workers.
2.	(Concurrent Thread) Aggregate local update returned from the collected workers and
update global model following some server-side optimization process.
At Each Worker (Concurrently with Server):
1.	Once decided to participate in the training, pull the global model with current timestamp.
2.	Perform (multiple) local update steps following some worker-side optimization process.
3.	Return the computation result and the associated pulling timestamp to the server, with
extra processing if so desired.
memory space to store workers’ information across rounds. In comparison, the number of workers
in cross-silo FL is relatively small. Although the server in cross-silo FL may still have to collect
information only from a subset of workers in each round, it has enough memory space to store each
worker’s most recent information.
The basic process of AFL is illustrated in Algorithm 1. Here, the server is responsible for: 1)
collecting the local updates returned from workers, and 2) aggregating the obtained updates once
certain conditions are satisfied (e.g., upon collecting m ∈ (0, M] local updates from workers)
to update the global model. In AFL, each worker could be non-work-conserving (i.e., idling is
allowed between each two successive participations in training). Whenever a worker intends to
participate in the training, it first pulls the current model parameters from the server. Then, after
finishing multiple local update steps (more on this next) with some worker-side optimization process
(e.g., following stochastic gradients or additional information such as variance-reduced and/or
momentum adjustments), the worker reports the computation results to the server (potentially with
extra processing if so desired, such as rescaling, compression for communication-efficiency, etc.).
Note that the above operations can happen concurrently on the server and worker sides, i.e., the
processings at the workers and the server are independent of each other in the temporal domain.
We remark that AFL is a general computing architecture that subsumes the conventional FL and
asynchronous distributed optimization as special cases. From an optimization perspective, the server
and the workers may adopt independent optimization processes, thus enabling a much richer set of
learning “control knobs” (e.g., separated learning rates, separated batch sizes). More importantly,
each worker is able to completely take control of its own optimization process, even using a time-
varying number of local update steps and optimizers, which depend on its local dataset and/or its
device status (e.g., battery level, privacy preference).
2) A Fundamental Convergence Error Lower Bound of AFL: Before developing training algo-
rithms for AFL, it is insightful to first obtain a fundamental understanding of the performance limit of
any AFL training algorithms. Toward this end, we first state several assumptions that are needed for
our theoretical analysis throughout the rest of this paper.
Assumption 1. (L-Lipschitz Continuous Gradient) There exists a constant L > 0, such that
∣∣Vfi(x) - Vfi(y)k ≤ LkX - yk, ∀x, y ∈ Rd, and i ∈ [M].
Assumption 2. (Unbiased Local Stochastic Gradient) Let ξi be a random local data sample at
worker i. The local stochastic gradient is unbiased, i.e., E[Vfi(x, ξi)] = Vfi(x), ∀i ∈ [m], where
the expectation is taken over the local data distribution Di.
Assumption 3. (Bounded Local and Global Variances) There exist two constants σL ≥ 0 and σG ≥ 0,
such that the variance of each local stochastic gradient estimator is bounded by E[kVfi(x, ξi) -
Vfi(x)k2]≤σL2, ∀i ∈ [M], and the global variability of the local gradient of the cost function is
bounded by kVfi(x) - Vf (x)k2 ≤ σG2 , ∀i ∈ [M], ∀k.
The first two assumptions are standard in the convergence analysis of non-convex optimization (see,
e.g., (Ghadimi & Lan, 2013; Bottou et al., 2018)). For Assumption 3, the bounded local variance
is also a standard assumption. We utilize a universal bound σG to quantify the data heterogeneity
among different workers. This assumption is also frequently used in the literature of FL with non-
i.i.d. datasets (Reddi et al., 2020; Wang et al., 2019; Yang et al., 2021) as well as in decentralized
optimization (Kairouz et al., 2019).
4
Under review as a conference paper at ICLR 2022
To establish a fundamental convergence error lower bound, we consider the most general case where
no assumption on the arrival processes of the worker information is made, except that each worker’s
participation in FL is independent of each other. In such general worker information arrival processes,
we prove the following fundamental lower bound of convergence error by constructing a worst-case
scenario (see Appendix B.1 for proof details):
Theorem 1 (Convergence Error Lower Bound for General Worker Information Arrival Processes).
For any level of heterogeneity characterized by σG, there exists loss functions and worker participation
process satisfying Assumptions 1- 3for which the output X ofany randomized FL algorithm satisfies:
EkVf(X)k2 = Ω(σG),	(1)
Remark 1. The lower bound in Theorem 1 indicates that no algorithms for AFL could converge to a
stationary point under general worker information arrival processes, due to the significant system
heterogeneity and randomness caused by such general worker information arrivals. The possible
system heterogeneity coupled with non-i.i.d. data result in objective value drifts, which further lead
to an inevitable error in convergence. We note that our lower bound also holds for non-i.i.d. FL
including synchronous FedAvg and its variants, thus also providing insights for conventional FL. To
ensure convergence to a stationary point, extra assumptions for the worker information arrivals have
to be made, e.g., uniformly distributed arrivals (see Theorem 3) and bounded delays (see Theorem 4).
4 The Anarchic Federated Averaging (AFA) Algorithms
Upon obtaining a fundamental understanding of the training algorithm performance limit from the
convergence error in Theorem 1, we are now in a position to develop AFL algorithms that are guided
by our fundamental lower bound. Toward this end, in this section, we will develop two anarchic
federated averaging (AFA) algorithms for the cross-device (CD) and cross-silo (CS) settings in
Section 4.1 and 4.2, respectively.
4.1	The AFA-CD Algorithm for Cross-Device AFL
1)	The AFA-CD Algorithm: First, we propose the AFA-CD algorithm for the cross-device AFL
setting. As mentioned earlier, cross-device AFL is suitable for cases with a massive number of
edge devices. In each round of global model update, only a small subset of workers are used in
the training. The server is assumed to have no historical information of the workers. As shown
in Algorithm 2, AFA-CD closely follows the AFL architecture shown in Algorithm 1. Here, we
use standard stochastic gradient descent (SGD) as the server- and worker-side optimizer. In each
update t, t = 1, . . . , T, the server waits until collecting m local updates {Gi(Xt-τt,i)} from workers
to form a set Mt with |Mt | = m, where τt,i represents the random delay of the local update of
worker i, i ∈ Mt (Server Code, Line 1). Once Mt is formed, the server aggregates all local updates
Gi(Xt-τt,i), i ∈ Mt and updates global model (Server Code, Line 2). We count each global model
update as one communication round. Meanwhile, for each worker, it pulls the current global model
parameters with time stamp μ once it decides to participate in training (Worker Code, Line 1). Each
worker can then choose a desired number of local update steps Kt,i (could be time-varying and
device-dependent) to perform SGD updates for Kt,i times, and then return the rescaled sum of all
stochastic gradients with timestamp μ to the server (Worker Code, Lines 2-3).
2) Convergence Analysis of the AFA-CD Algorithm: We first conduct the convergence of AFA-CD
under general worker information arrival processes. We let K be the maximum local update steps,
which is defined as K := maxt∈[T],i∈[M] {Kt,i}. We let τ be the maximum delay of workers’
returned information, which is defined as τ := maxt∈[T],i∈Mt {τt,i}. Also, we use f0 = f(X0) and
f to denote the initial and the optimal objective values, respectively. Then, we have the following
convergence result for the AFA-CD algorithm (see proof details in Appendix B.2):
Theorem 2 (AFA-CD with General Worker Information Arrival Processes). Under Assumptions 1- 3,
choose server-side and worker-side learning rates η and ηL such that the following relationships
hold: 180ηL2 K2L2τ < 1 and 2LηηL + 3τ 2L2η2ηL2 ≤ 1. Then, the output sequence {Xt} generated
by AFedAvg-TSLR-CD with general worker information arrival processes satisfies:
1
T
T-1
XEkVf(Xt)k2≤
t=0
4(f0 - fJ
ηηLT
+ 4即 σL + αgσG ),
(2)
5
Under review as a conference paper at ICLR 2022
Algorithm 2 The AFA-CD Algorithm for Cross-Device AFL.
At the Server (Concurrently with Workers):
1.	In the t-th update round, collect m local updates {Gi(xt-τt,i), i ∈ Mt} returned from
the workers to form the set Mt, where τt,i represents the random delay of the worker i’s
local update, i ∈ Mt .
2.	Aggregate and update: Gt = m1 Pi∈Mt Gi(Xt-号,)	xt+ι = Xt - ηGt∙
At Each Worker (Concurrently with Server):
1.	Once decided to participate in the training, retrieve the parameter x* from the server and
its timestamp, set the local model: xμ,0 = Xμ.
2.	Choose a number of local steps Kt,i, which can be time-varying and device-dependent.
Let χμ,k+ι = χμ,k - η gk,where gi = Vfi(Xμ,k ,ξk), k = 0,...,Kt,i - L
3.	Sum and rescale the stochastic gradients: Gi(xμ) = ^- PK= 0,-1 gj. Return Gi(xμ).
where ，[等 + 3τ2⅛2η2 + 15⅛KL2] and a&，[3 + 45K2L2η".
With Theorem 2, we immediately have the following convergence rate result for AFA-CD, which
implies the highly desirable “linear speedup effect” can be achieved by AFA-CD.
Corollary 1 (Linear Speedup to Error Ball). By setting ηL =力,and η = √m, the convergence
rate of AFA-CD with general worker information arrival processes is:
T X EkVf(Xt)k2 = O( m172T172 )+o( T )+o( K2 )+O(σG).
Remark 2. First, we note that the non-vanishing error term O(σG2 ) in Corollary 1 matches the lower
bound in Theorem 1. This implies that the convergence error of AFL-CD is order-optimal. Recall
that this non-vanishing convergence error is a direct consequence of objective function drift under the
general worker information arrivals (no assumption on the arrivals of the worker participation in each
round of update), which is independent of the choices of learning rates, the number of local update
steps, and the number of global update rounds (more discussion in the supplementary material). Also,
for a sufficiently large T, the dominant term O( ^"7”) implies that AFA-CD achieves the linear
speedup effect before reaching a constant error neighborhood with size O(σG2 ).
Remark 3. The conditions for the learning rates η and ηL are a natural extension of SGD. When
T = 0 (synchronous setting) and K = 1 (single local update), the condition becomes ηηL ≤ 芸,
which recovers the same learning rate condition for SGD in (Ghadimi & Lan, 2013). Also, the
suggested worker-side learning rate ηL is independent of local update steps. This is different from
previous work that ηL depends heavily on local update steps (Wang et al., 2020; Yang et al., 2021),
thus making it more practical for implementation.
Given the weak convergence result implied by the lower bound in Theorem 1 under general workers’
information arrivals, it is important to understand what extra assumptions on the worker information
arrivals are needed in order to guarantee convergence. Toward this end, we consider a special case
where the arrivals of worker returned information in each round for global update is uniformly dis-
tributed among the workers. In this setting, Mt can be viewed as a subset with size m independently
and uniformly sampled from [M] without replacement. For FL systems with a massive number
of workers, this assumption of uniformly distributed arrivals is a good approximation for worker
participation in cross-device FL (McMahan et al., 2016; Li et al., 2019a). Also, one can map this
setting into the conventional cross-device FL systems with uniform worker sampling in partial worker
participation, which is a widely-used assumption (McMahan et al., 2016; Li et al., 2019c; 2018; Yang
et al., 2021; Wang et al., 2020). For this special case, the convergence performance of AFA-CD can
be improved as follows (see proof details in Appendix B.3):
Theorem 3. Under Assumptions 1- 3, choose server-side and worker-side learning rates η and ηL
such that the following relationships hold: ηL2 [6(2K 2 - 3K+ 1)L2] ≤ 1, 120L2 K 2 ηL2 T + 4(LηηL +
L2η2ηLτ2) mM-mi) (90K2L2nLT + 3τ) < 1. Then, the output sequence {xt} generated by AFA-CD
6
Under review as a conference paper at ICLR 2022
Algorithm 3 The AFA-CS Algorithm for Cross-Silo AFL.
At the Server (Concurrently with Workers):
1.	In the t-th update round, collect m local updates {Gi(xt-τt )} from the workers to form
the set Mt .
2.	Update worker i’s information in the memory using the returned local update Gi .
3.	Aggregate and update: Gt = MM Pi∈[M] Gi,	xt+ι = Xt - ηGt.
At Each Worker (Concurrently with Server): Same as AFA-CD Worker Code.
with uniformly distributed worker information arrivals satisfies:
T-1
不 X Ek▽/(Xt)k2 ≤ -----0^^^Γ+ +4(αLσL + αGσG),	⑶
T t=0	2	ηηLT	* L G
where αL and αG are constants that are defined as:
αL 2 ](LmZL + TTLLm哈 + 5KL2nL) + (LnnL + L2η2ηLτ2)mM--mi)(15KL2nL)_，
αG ,卜0K2L2nL +(LnnL + L2n2nLτ2)mMM-oK2L2nL + 3).
Furthermore, by choosing the server- and worker-side learning rates appropriately, we immediately
have the following linear speedup convergence result for AFA-CD:
Corollary 2 (Linear Speedup to Stationary Point). By setting nL =力 and n = √m, the ConVer-
gence rate of AFA-CD with uniformly distributed worker information arrivals is:
1χ EkVf(Xt)k2= O(	1/1 1/2)+ of T2 ) + of K2 ) + of	IKT3/2) + of 窄).
T	m1/2 T 1/2	T	T	m1/2T3/2	T2
Remark 4. For a sufficiently large T , the linear speedup effect to a stationary point (rather than
a constant error neighborhood) can be achieved with any finitely bounded maximum local update
steps K and maximum delay T, i.e., O( √=). Note this rate does not depend on the delay T and
local computation steps K after sufficiently many rounds T , the negative effect of using outdated
information in such asynchronous setting vanishes asymptotically. Further, for σG = 0 (i.i.d. data)
and K = i (single local update step), our AFA-CD algorithm is exactly the same as the AsySG-con
algorithm (Lian et al., 2018) in asynchronous parallel distributed optimization. It can be readily
verified that AFA-CD achieves the same rate as that of the AsySG-con algorithm. When T = 0
(synchronous setting) and Kt,i = K (same number of local update steps across workers), AFA-CD
becomes the generalized synchronous FedAvg algorithm with two-sided learning rates (Yang et al.,
2021; Karimireddy et al., 2020b; Reddi et al., 2020). Remarkably, the result of AFA-CD shows that
We can achieve a faster convergence rate than O(√K∕√mT) in (Yang et al., 2021) and the same
rate as FedAvg analysis in (Karimireddy et al., 2020b).
4.2 The AFA-CS algorithm for cross-silo FL
1) The AFA-CS Algorithm: As mentioned earlier, cross-silo FL is suitable for collaborative learning
among a relatively small number of (organizational) workers. Thanks to the relatively small number
of workers, each worker’s feedback can be stored at the server. As a result, the server could reuse the
historical information of each specific worker in each round of global update.
As shown in Algorithm 3, the AFA-CS algorithm also closely follows the AFL architecture as shown
in Algorithm 1. In each round of global model update, a subset of workers could participate in the
training (Server Code, Line 1). Compared to AFA-CD, the key difference in AFA-CS is in Line 2 of
the Server Code, where the server stores the collected local updates {Gi} for each worker i ∈ Mt
into the memory space at the server (Server Code, Line 2). As a result, whenever a worker i returns a
local update to the server upon finishing its local update steps, the server will update the memory
space corresponding to worker i to replace the old information with this newly received update from
7
Under review as a conference paper at ICLR 2022
worker i. Similar to AFA-CD, every m new updates in the AFA-CS algorithm trigger the server
to aggregate all the Gi , i ∈ [M] (newly received information if i ∈ Mt or stored information if
i ∈/ Mt ) and update the global model. The Worker Code in AFA-CS is exactly the same as AFA-CD
and its description is omitted for brevity.
2) Convergence Analysis of the AFA-CS Algorithm: For cross-silo AFL, our AFA-CS algorithm
achieves the following convergence performance (see proof details in Appendix C):
Theorem 4. Under Assumptions 1- 3, choose sever- and worker-side learning rates η and ηL in such
a way that there exists a non-negative constant series {βμ}U=0 satisfying thefollowing relationship:
12LηηL + 540(M；— m0) (1 + LnnL)K2L2ηL(1 + T) + 180K2L2ηL + 320L3K2ηrfL < 1, (4)
M2
ηηL (9(M--m ) (I + LηηL)[3τL2 + (Ieu+1 — βu) ≤ 0,	(5)
2M2
ηηLI9(M2Mm ) (I + LηηL))3τL2 一 3τ-ι ≤ 0,	(6)
31
2MσL ≤ (2 - β0ηηL)EIlGtk2,	⑺
the output sequence {xt} generated by the AFA-CS algorithm for general worker information arrival
processes with bounded delay (τ := maxt∈[T],i∈[M] {τt,i}) satisfies:
T X Ew (Xt)k2 ≤ 4(V(XJ)) +4(αLσL + …)，
(8)
where αL and αG are constants defined as follows:
,FLηηLqκNr2 2 J(M-m0)2∩ , J- 3,t3 ,Oj-
αL = [ 2M + 5KL ηL(—M2—(1 + LnnL)+ (2 + 3LηηL))],
αG = (9(M-m) (1 + LηηL) +(3 + 3加力))(30衣2L2ηL),
M2	2
and V(∙) is defined as V(Xt) = f (Xt) + Pu=0βuIxt-u - xt-u-1 I2, m0 is the number of updates
in the memory space with no time delay (τt,i = 0).
Remark 5. To see how stringent the conditions for learning rates in Theorem 4 are, note that Eq. (4)
implies that O(ηηL + ηηL3 K2 + τK2ηL2 + τ K2ηηL3 ) < 1. With a sufficiently small learning rate ηL
for given bounded time delay T and maximum local steps K, Eq. (4) can be satisfied. Eqs. (5)-(6)
imply that {βμ}u=0 is a non-negative decreasing series with difference O(ηηLτ + η2ηLT). As a
result, βo = Ω(ηηlt2 + η2ηLT2). Plugging it into Eq. (7) yields that the update term Gt should be
larger than the variance term σL2 /M, which can be satisfied if the number of workers M is sufficiently
large or σL2 is sufficiently small (i.e., workers use a sufficiently large batch size).
By choosing appropriate learning rates, we immediately have stronger linear speedup convergence:
Corollary 3 (Linear Speedup). By setting ηL =力,and η = √M, the convergence rate of the
AFA-CS algorithm for general worker information arrival processes with bounded delay is:
1 T-1	1	K2M1/2
T X EkVf(Xt)k2 = O M1/2T1/2	+ O	+ O -TrΓ~
t=0
Remark 6. Compared to Corollary 1, we can see that, by reusing historical data, the AFA-CS
algorithm can eliminate the non-vanishing O(σG2 ) error term even for general worker information
arrival processes with bounded delay. The bounded delay implicitly requires each workers at least
participate in the training process, eliminating the worse-case scenario shown in Theorem 1. On the
other hand, although the server only collects m workers’ feedback in each round of global model
update, the server leverages all M workers’ feedback by reusing historical information. Intuitively,
this translates the potential objection function drift originated from general worker information arrival
process into the negative effect of delayed returns G(Xt-τt,i) from workers. It can be shown that
such a negative effect of delayed returns vanishes asymptotically as the number of communication
rounds T gets large and in turn diminishes the convergence error.
8
Under review as a conference paper at ICLR 2022
(b)p=2.
(a) p = 1.
(c) p = 5.
---FedAvg
——AFA-CD
---AFA-CS
O 20 40 60 80 100 120 140
Communication Round
O 20 40 60 80 IOO 120 140
Communication Round
O 20 40 60 BO IOO 120 140
Communication Round
(d) p = 10.
Figure 1: Test accuracy for logistic regression on non-i.i.d. MNIST with different p-values.
Remark 7. AFA-CS achieves a stronger linear speedup O(1∕√MT), which is new in the FL
literature to our knowledge. Specifically, even though partial (m) workers participation is used in
each round, AFA-CS is able to achieve a surprising speedup with respect to total number of workers
M (M > m). Also, AFA-CS generalizes the lazy aggregation strategy in distributed learning (e.g.,
LAG (Chen et al., 2018)) by setting K = 1 (single local update), τ = 0 (synchronous setting) and
◎l = 0 (using full gradient descents instead of stochastic gradients) and further improve the rate of
LSAG (Chen et al., 2020) from O(1∕√T) to O(1∕√MT).
5	Numerical results
In this section, we conduct experiments to verify our theoretical results. We use i) logistic regression
(LR) on manually partitioned non-i.i.d. MNIST dataset (LeCun et al., 1998), ii) convolutional neural
network (CNN) for manually partitioned CIFAR-10 (Krizhevsky, 2009), and iii) recurrent neural
network (RNN) on natural non-i.i.d. dataset Shakespeare (McMahan et al., 2016). In order to impose
data heterogeneity in MNIST and CIFAR-10 data, we distribute the data evenly into each worker
in label-based partition following the same process in the literature (e.g., McMahan et al. (2016);
Yang et al. (2021); Li et al. (2019c)). Therefore, we can use a parameter p to represent the classes of
labels in each worker’s dataset, which signifies data heterogeneity: the smaller the p-value, the more
heterogeneous the data across workers (cf. Yang et al. (2021); Li et al. (2019c) for details). Due to
space limitation, we relegate the details of models, datasets and hyper-parameters, and further results
of CNN and RNN to the appendix.
In Figure 1, we illustrate the test accuracy for LR on MNIST with different p-values. We use
the classical FedAvg algorithm (McMahan et al., 2016) for conventional FL with uniform worker
sampling as a baseline, since it corresponds to the most ideal scenario where workers are fully
cooperative with the server. We examine the learning performance degradation of AFA algorithms
(due to anarchic worker behaviors) compared to this ideal baseline. For our AFA-CD and AFA-CS
with general worker information arrival processes, the test accuracy is comparable to or nearly the
same as that of FedAvg. This confirms our theoretical results and validates the effectiveness of our
AFA algorithms. We further evaluate the impacts of various factors in AFL, including asynchrony,
heterogeneous computing, worker’s arrival process, and non-i.i.d. datasets, on convergence rate
of our proposed AFA algorithms. Note that AFL subsumes FedAvg and many variants when the
above hyper-parameters are set as constant. Also, AFL coupled with other FL algorithms such as
FedProx (Li et al., 2018) and SCAFFOLD (Karimireddy et al., 2020b) is tested. Our results show
that the AFA algorithms are robust against all asynchrony and heterogeneity factors in AFL. Due to
space limitation, we refer readers to the appendix for all these experimental results.
6	Conclusions
In this paper, we propose a new paradigm in FL called “Anarchic Federated Learning” (AFL). In
stark contrast to conventional FL models where the server and the worker are tightly coupled, AFL
has a much lower sever-worker coordination complexity, allowing a flexible worker participation.
We propose two Anarchic Federated Averaging algorithms with two-sided learning rates for both
cross-device and cross-silo settings, which are named AFA-CD and AFA-CS, respectively. We show
that both algorithms retain the highly desirable linear speedup effect in the new AFL paradigm.
Moreover, we show that our AFL framework works well numerically by employing advance FL
algorithms FedProx and SCAFFOLD as the optimizer in worker’s side.
9
Under review as a conference paper at ICLR 2022
References
Durmus Alp Emre Acar, Yue Zhao, Ramon Matas Navarro, Matthew Mattina, Paul N Whatmough,
and Venkatesh Saligrama. Federated learning based on dynamic regularization. In International
Conference on Learning Representations, 2021.
Alekh Agarwal and John C Duchi. Distributed delayed stochastic optimization. In 2012 IEEE 51st
IEEE Conference on Decision and Control(CDC), pp. 5451-5452. IEEE, 2012.
Dmitrii Avdiukhin and Shiva Kasiviswanathan. Federated learning under arbitrary communication
patterns. In International Conference on Machine Learning, pp. 425-435. PMLR, 2021.
Leon Bottou, Frank E Curtis, and Jorge NocedaL Optimization methods for large-scale machine
learning. Siam Review, 60(2):223-311, 2018.
Tianyi Chen, Georgios B Giannakis, Tao Sun, and Wotao Yin. Lag: Lazily aggregated gradient for
communication-efficient distributed learning. In NeurIPS, 2018.
Tianyi Chen, Yuejiao Sun, and Wotao Yin. Lasg: Lazily aggregated stochastic gradients for
communication-efficient distributed learning. arXiv preprint arXiv:2002.11360, 2020.
Aaron Defazio and Leon Bottou. On the ineffectiveness of variance reduced optimization for deep
learning. arXiv preprint arXiv:1812.04529, 2018.
Saeed Ghadimi and Guanghui Lan. Stochastic first-and zeroth-order methods for nonconvex stochastic
programming. SIAM Journal on Optimization, 23(4):2341-2368, 2013.
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurelien Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances
and open problems in federated learning. arXiv preprint arXiv:1912.04977, 2019.
Sai Praneeth Karimireddy, Martin Jaggi, Satyen Kale, Mehryar Mohri, Sashank J Reddi, Sebastian U
Stich, and Ananda Theertha Suresh. Mime: Mimicking centralized stochastic algorithms in
federated learning. arXiv preprint arXiv:2008.03606, 2020a.
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In
International Conference on Machine Learning, pp. 5132-5143. PMLR, 2020b.
Ahmed Khaled, Konstantin Mishchenko, and Peter Richtdrik. First analysis of local gd on heteroge-
neous data. arXiv preprint arXiv:1909.04715, 2019.
Jakub Konecny, H Brendan McMahan, Daniel Ramage, and Peter Richtdrik. Federated optimization:
Distributed machine learning for on-device intelligence. arXiv preprint arXiv:1610.02527, 2016.
Alex Krizhevsky. Learning multiple layers of features from tiny images. 2009.
Nicolas Le Roux, Mark W Schmidt, and Francis R Bach. A stochastic gradient method with an
exponential convergence rate for finite training sets. In NIPS, 2012.
Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127, 2018.
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges,
methods, and future directions. arXiv preprint arXiv:1908.07873, 2019a.
Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith. Fair resource allocation in federated
learning. arXiv preprint arXiv:1905.10497, 2019b.
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of
fedavg on non-iid data. arXiv preprint arXiv:1907.02189, 2019c.
10
Under review as a conference paper at ICLR 2022
Xiangru Lian, Wei Zhang, Ce Zhang, and Ji Liu. Asynchronous decentralized parallel stochastic
gradient descent. In International Conference on Machine Learning, pp. 3043-3052. PMLR, 2018.
H Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, et al. Communication-efficient
learning of deep networks from decentralized data. arXiv preprint arXiv:1602.05629, 2016.
Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. Agnostic federated learning. In Interna-
tional Conference on Machine Learning, pp. 4615-4625. PMLR, 2019.
Feng Niu, Benjamin Recht, Christopher R6, and Stephen J Wright. Hogwild!: A lock-free approach
to parallelizing stochastic gradient descent. arXiv preprint arXiv:1106.5730, 2011.
Thomas Paine, Hailin Jin, Jianchao Yang, Zhe Lin, and Thomas Huang. Gpu asynchronous stochastic
gradient descent to speed up neural network training. arXiv preprint arXiv:1312.6186, 2013.
Zhaonan Qu, Kaixiang Lin, Jayant Kalagnanam, Zhaojian Li, Jiayu Zhou, and Zhengyuan Zhou.
Federated learning’s blessing: Fedavg has linear speedup. arXiv preprint arXiv:2007.05690, 2020.
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konecny,
Sanjiv Kumar, and H Brendan McMahan. Adaptive federated optimization. arXiv preprint
arXiv:2003.00295, 2020.
Yichen Ruan, Xiaoxi Zhang, Shu-Che Liang, and Carlee Joe-Wong. Towards flexible device partici-
pation in federated learning. In International Conference on Artificial Intelligence and Statistics,
pp. 3403-3411. PMLR, 2021.
Mark Schmidt, Nicolas Le Roux, and Francis Bach. Minimizing finite sums with the stochastic
average gradient. Mathematical Programming, 162(1-2):83-112, 2017.
Sebastian U Stich. Local sgd converges fast and communicates little. arXiv preprint arXiv:1805.09767,
2018.
Jianyu Wang and Gauri Joshi. Cooperative sgd: A unified framework for the design and analysis of
communication-efficient sgd algorithms. arXiv preprint arXiv:1808.07576, 2018.
Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor. Tackling the objective
inconsistency problem in heterogeneous federated optimization. arXiv preprint arXiv:2007.07481,
2020.
Jianyu Wang, Zachary Charles, Zheng Xu, Gauri Joshi, H Brendan McMahan, Maruan Al-Shedivat,
Galen Andrew, Salman Avestimehr, Katharine Daly, Deepesh Data, et al. A field guide to federated
optimization. arXiv preprint arXiv:2107.06917, 2021.
Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K Leung, Christian Makaya, Ting He, and
Kevin Chan. Adaptive federated learning in resource constrained edge computing systems. IEEE
Journal on Selected Areas in Communications, 37(6):1205-1221, 2019.
Cong Xie, Sanmi Koyejo, and Indranil Gupta. Asynchronous federated optimization. arXiv preprint
arXiv:1903.03934, 2019.
Haibo Yang, Minghong Fang, and Jia Liu. Achieving linear speedup with partial worker participation
in non-{iid} federated learning. In International Conference on Learning Representations, 2021.
URL https://openreview.net/forum?id=jDdzh5ul-d.
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept and
applications. ACM Transactions on Intelligent Systems and Technology (TIST), 10(2):1-19, 2019.
Hao Yu, Rong Jin, and Sen Yang. On the linear speedup analysis of communication efficient
momentum sgd for distributed non-convex optimization. In International Conference on Machine
Learning, pp. 7184-7193. PMLR, 2019.
Xin Zhang, Jia Liu, and Zhengyuan Zhu. Taming convergence for asynchronous stochastic gradient
descent with unbounded delay in non-convex learning. In 2020 59th IEEE Conference on Decision
and Control (CDC), pp. 3580-3585. IEEE, 2020a.
11
Under review as a conference paper at ICLR 2022
Xinwei Zhang, Mingyi Hong, Sairaj Dhople, Wotao Yin, and Yang Liu. Fedpd: A federated learning
framework with optimal rates and adaptivity to non-iid data. arXiv preprint arXiv:2005.11418,
2020b.
12
Under review as a conference paper at ICLR 2022
Appendix
In this supplementary material, we provide the detailed proofs for all theoretical results in this
paper. Before presenting the proofs, we introduce some notations that will be used subsequently..
We assume there exists M workers in total in the FL systems. In each communication round, we
assume a subset Mt of workers to be used, with |Mt| = m. We use Gi(xt) to represent the local
update returned from worker i, i ∈ [M] given global model parameter xt0 = xt . Also, we define
Gi(Xt)，K1- PK=W-1 Nfi(Xj ξt,i), where xj represents the trajectory of the local model in the
worker. We use ∆i to denote the average of the full gradients long the trajectory of local updates, i.e.,
△i (Xt) = K1- PK=Oi-1 Vfi (Xj). With the above notations, we are now in a position to present the
proofs of the theoretical results in this paper.
A Proofs of Lemma 1 and Lemma 2
We start with proving two results stated in the following two lemmas, which will be useful in the rest
of the proofs.
Lemma 1. E[Gi(Xt)] = △i(Xt), E[kGi(Xt) - △i(Xt)k2] ≤ σL2 ,∀i ∈ [M].
Proof. Taking the expectation of Gi (Xt), we have:
1 Kt,i -1
E[Gi(Xt)] = E L X Vfi(Xj,ξt,i)
Kt,i j=0
1 Kt,i-1
=K- X EVfi(Xj,ξt,i)
Kt,i j=0
= △i(Xt).
Also, by computing the mean square error between Gi (Xt) and △i (Xt), we have:
1 Kt,i-1	Kt,i-1
E[kGi(Xt) — ʌi(Xt)k2]= E[kK- X Vfi(Xj,ξt,i)- X Vfi(Xj)II2]
Kt,i j=0	j=0
1	Kt,i-1	Kt,i-1
=KrE[k X Vfi(Xj,ξt,i) — X Vfi(Xj)k2]
t,i j=0	j=0
1 Kt,i -1	Kt,i-1
≤ L X E[kVfi(Xj,ξt,i) — X Vfi(Xj)k2]
Kt,i j=0	j=0
≤ σL2 .
This completes the proof of Lemma 1.
□
Lemma 2. For a fixed set Mt with cardinality m, E I P
IIPi∈Mt ʌi(Xt-Tt,J||2 + mσL.
i∈MtGi(Xt-τti )UU
≤
Proof. By the definition of variance (E[(X - E[X])2] = E[X2] - [E[X]]2), we have:
X Gi(Xt-τt,i)2
i∈Mt
E
E
II X
Gi (Xt-τt,i ) 一 △i (Xt-τt,i )II
i∈Mt
+ UX ∆i(χt/
i∈Mt
≤ mσL + Il X A(xFi)II2.
i∈Mt
Here {Gi(xt-τt,i) 一 ∆i(Xt-Tt,i)} forms a martingale difference sequence.
□
13
Under review as a conference paper at ICLR 2022
B Proof of the performance of the AFA-CD algorithm
In this section, we provide the proofs of the theoretical results of the AFA-CD algorithm. We consider
two cases: i) general worker information arrival processes and ii) uniformly distributed worker
information arrivals. As mentioned earlier, for general worker information arrival processes, we do
not make any assumptions on the worker information arrival processes except the independence of
workers’ participation. For uniformly distributed worker information arrivals, Mt can be viewed as a
subset with size m independently and uniformly sampled from [M] without replacement. The similar
convergence analysis for independently and uniformly sampling with replacement can be derived in
the same way following the techniques in (Yang et al., 2021; Li et al., 2019c).
B.1	Lower Bound for General Worker Information Arrival Processes
Theorem 1 (Convergence Error Lower Bound for General Worker Information Arrival Processes).
For any level of heterogeneity characterized by σG, there exists loss functions and worker participation
process satisfying Assumptions 1- 3for which the output X ofany randomized FL algorithm satisfies:
EkVf(X)k2 = Ω(σG),	(1)
Proof. We prove the lower bound by considering a worst-case scenario for simple one-dimensional
functions. Let the FL system has two workers with the following loss functions: f1 (X) = (X +
G)2,f2(x) = (x — G)2,f (x) = 2(fι(x)+ f2(x))= x2 + G2. Itis easy to VerifythatkVfι(x)-
Vf (X)k2 ≤ 4G2 = σG2 and kVf2(X) - Vf (X)k2 ≤ 4G2 = σG2 . We consider a special case for
the general arrival process when only the first one worker participates in the training, equivalent to
optimizing fι(x) rather than f (x). In such case, any decent algorithm would return X = —G + e,
where E is a small error term. As a result, EkVf (X)k2 = Ω(σG).	□
B.2	General Worker Information Arrival Processes
Theorem 2 (AFA-CD with General Worker Information Arrival Processes). Under Assumptions 1- 3,
choose server-side and worker-side learning rates η and ηL such that the following relationships
hold: 180ηL2 K2L2τ < 1 and 2LηηL + 3τ 2L2η2ηL2 ≤ 1. Then, the output sequence {Xt} generated
by AFedAvg-TSLR-CD with general worker information arrival processes satisfies:
T-1
不 X EkVf(Xt)k2 ≤ ----0一^Γ+ +4(αLσL + αGσG),	(2)
T t=0	ηηLT	L G
where。刀，[+ + 3τ2⅛产 + 15nLKL2] and a&，[3 + 45K2L2η".
Proof. Due to the L-smoothness assumption, taking expectation of f(Xt+1) over the randomness in
communication round t, we have:
E[f (xt+ι)] ≤ f(xt) + (Vf(Xt)，E[xt+1 — xt]〉+L E[kxt+1 — Xtk2 ∙
X-------{Z--------} 2 X-----{------}
A1	A2
First, we bound the term A2 as follows:
A2 = Ekxt+1 — xtk2
m
η2ηLEkm X Gi(Xt-τt,i )k
m i=1
i=1
22
δ &	>∣∣2∣ η2ηL /
ʌi(Xt-Tt,i)k + ~m~σL,
where (a1) is due to Lemma 2. Next, we bound the term A1 as follows:
A1 = (Vf(Xt), E[Xt+1 — Xt]〉
14
Under review as a conference paper at ICLR 2022
m
-ηηL<vf (Xt), E m X Gi(Xtf,J〉
m i=1
m
(=)-1 ηηLkVf(Xt)k2 - 2ηηLkm X A(Xtf ,Jk2 + 2ηηL kVfM)-
m i=1
1m
—X ∆i(Xt-Tt,i)k ,
m	t,i
i=1
^{z
A3
}
where (a2) is due to Lemma 1 and the fact thathx, y)= 1 (∣∣xk2 + kyk2 - kX - yk2). To further
bound the term A3 , we have:
m
A3 = kVf (Xt) - m X ∆i(Xtf ,i)k2
i=1
m
≤ m X kVf (Xt) - ∆i(Xtf ,i)k2
m i=1
m
=m X kVf (Xt)- Vf(Xt-τt,j + Vf(Xt-τt,j - Vfi(Xt-τt,ii + Vfi(Xt-τt,ii - δ2(Xtf,jk2
m i=1
(a3) 1 m
≤ m£ 3kVf(xt) -Vf(xt-τt,i)k2 + 3kVf(xt-τt,i) -Vfi(xt-τt,i)k2
i=1
+3kVfi(Xt-τt,i) -∆i(Xt-τt,i)k2
(a4) 3L2
≤——
m
m
X kXt - Xt-τt,i k2 +3σG2 +
i=1
_____ - /
3m
一X kVfi(xt-Tt,i ) - &(Xt-Tt,i
m	,	,
i=1 '----------{----------
A5
A4
)k2,
}
where (a3) followings from the inequality ∣∣xi + x2 + •… + Xnk2 ≤ nPZi ∣∣Xik2, and (a4)
is due to the L-smoothness assumption (Assumption 1) and bounded global variance assumption
(Assumption 3).
To further bound the term A4 , we have:
A4
=—X kxt - Xt-Tt,ik2
m	t,i
i∈[m]
(a5)
≤ kXt - Xt-Tt,uk2
t-1
= k X	Xk+1-Xkk2
k=t-Tt,u
t-1	1
=Ek X	mηηL X Gi(Xk-Tk,i)k2
k=t-Tt,u	i∈Mk
t-1
=E k X X Gi(Xfi)k2
k=t-Tt,u i∈Mk
(a6)	t-1
≤ E T X k X Gi(Xk-Tk,i)k2
(a7)
≤E
k=t-τt,u	i∈Mk
t-1
[( X k X ∆i(Xk-τk,i)k2)+τmσL2] .
k=t-τt,u	i∈Mk
15
Under review as a conference paper at ICLR 2022
In the derivations above, we let u := argmaxi∈[M] kxt - xt-τt,i k2, which yields (a5). Note also
that the maximum delay assumption τ ≥ τk,i , ∀i ∈ [M] implies (a6). Lastly, (a7) follows from
Lemma 2.
To further bound the term A5, we have:
A5 = kVfi(xtf,i)- ∆i(Xtf,i)k2
1	Kt,i-1
=kVfi(Xt-τt,i) - K-	X	Vfi(Xj-τt,i)k2
1	Kt,i-1
=K^	X kVfi(Xt-τt,i) -Vfi(xj-τt,i)k2
(a8) L2 Kt,i-1	j 2
≤ ~K~	kχ	kxt-τt,i - Xt-Tt,ik
Kt,i	j = 0 '------{z------}
A6
(a9)
≤ 5Kt,iL2ηL2 (σL2 +6Kt,iσG2)+30Kt2,iL2ηL2kVf(Xt-τt,i)k2
(a10)
≤	5KL2ηL2(σL2 +6KσG2)+30K2L2ηL2kVf(Xt-τt,i)k2,
where (a8) is due to the L-smoothness assumption (Assumption 1), and (a9) follows from the bound
of A6 shown below. Here, we denote maximum number of local steps of all workers as K , i.e.,
Kt,i ≤ K, ∀t, i. This definition ofK implies (a10).
Now, it remains to bound term A6 in the derivations above. Note that the bounding proof of A6 in
what follows is the same as Lemma 4 in (Reddi et al., 2020). we restate the proof here in order for
this paper to be self-contained. For any worker i in the k-th local step, we have the following results
for the norm of parameter changes for one local computation:
A6 = E[kXit,k - Xtk2] = E[kXit,k-1 -Xt - ηLgti,k-1k2]
≤ E[kXit,k-1 -Xt - ηL(gti,k-1 - Vfi(Xit,k-1) + Vfi(Xit,k-1) - Vfi(Xt)
+ Vfi(Xt) - Vf(Xt) + Vf(Xt))k2]
≤ (1 +2K⅛τ)E[kXt,k-1 - Xtk2] +E[kηL(gti,
k-1 - Vfi(Xit,k-1))k2]
2K - 1
+ 6KE[kηL(Vfi(Xit,k-1) - Vfi(Xt))k2] + 6KE[kηL(Vfi(Xt) - Vf(Xt)))k2]
+ 6K kηLVf(Xt))k2
≤ (1 + 而二)E[kXt,k-i - Xtk2]+ ηLσL + 6ΚηLL2E[∣∣Xt,k-i -	]
2K - 1
+6KηL2σG2 + 6KkηLVf(Xt))k2
= (1+	1 + 6KnL L2)E[kXt,k-i - Xtk2] + ηL σL + 6KnL σG + 6KknL Vf(Xt)) k2
2K - 1
(a11)	1
≤ (I + &~~7)E[kXt,k-i - Xtk2] + nLσL + 6KnLσG + 6KknLVf(Xt))k2,
K-1
where (a11) follows from the fact that 2Κ1-ι + 6KnLLL2 ≤ κ-ι if nL ≤ 6”2-1长+i)l2
Unrolling the recursion, we obtain:
k-1
E[kXi,k - Xtk2] ≤ X(1 + K-I)p[nLσL + 6KσG + 6]＜碓knzVf M))k2]
p=0
≤ (K - 1)[(1 + k∖)k - 1][nLσL + 6KnLσG + 6KknLVf (Xt))k2]
K-1
≤5KnL2(σL2 +6KσG2)+30K2nL2kVf(Xt)k2.	(9)
16
Under review as a conference paper at ICLR 2022
With the above results of the terms A1 through A5, we have:
E[f(xt+ι)] — f(xt) ≤ Wf(Xt), E[xt+ι - xt])+ L E[∣∣xt+ι - xtk2
X------------------------------{z-----------}	2 X------V------}
A1	A2
1	1	1m	1	1m
-2ηηLkVf(xt)k2 - 2ηηLkmm £^T—"||2 + 2ηηL kVfM)-石£%(%-公)『
m i=1	m i=1
'-------V--------}
A3
Lη2ηL2
m2
+
k X ∆i(Xtf ,i)k2 + Lη2η2σL
t,i	m
i=1
≤ -1 ηηLkVf(Xt)k2 - 1 ηηLkɪ XX AMf,Jk2 +『kXX AMf,Jk2 + 4σL
mm	m
i=1	i=1
+ 3 ηηLσG + 3LL ηηL
m
X kxt - xt-τt,ik2
i=1
_________ J
m
+ 嚅 X kVfi(xt-τt,i
2 ^m
i=1
)-∆i(Xtf ,i)k2,
^^{^^^^^^^^^^^^^^^~}
A5
A4
1
m
<.
≤ - 2 ηηLkVf(Xt)k2 - 1 ηηLk mm X δ2(Xtf,i)k2 + LrnJL k X δ2(Xtf,jk2 + LnmnL σL
i=1	i=1
+ 2nnLaG + -2-nnL [nmL ( X	k X ∆i(Xk-Tk,i)k2 + τmσL)
k=t-τt,u i=1
+ 3n2zL[5KL2nL(σL + 6KσG) + 30K2L2nLmm X kVf (Xt-Tt,Jk2]
m i=1
1	1m
≤ -2nnLkVf(xt)k2 + 45nnLκ2L2mm E kVf(Xt-T,,Jk2
i=1
+ [-黑 + ⅞2]k X ∆i(xt-τt,i)k2 + 3Tm3	X k X ∆i(Xfi)k2
i=1	k=t-Tt,u i=1
+ [ Ln2nL- + 3τ2L⅛3 + ^LKL ]σL + [ 3 nnL + 45K 2L2nnL]σG.
m	2m	2	2
Summing the above inequality from t = 0 to t = T - 1 yields:
Ef(XT) - f(X0)
T-1	m
≤ X - XnnLkVf(xt)k2 +45nnLK2L2- X kVf(Xtf ,Jk2
2	m	t,
t=0	i=1
+∑ [[-翳+⅛⅛ X∆i(xtf,i)k2+3τLmn3n3 X kX∆i(xf)k2
t=0	i=1	k=t-Tt,u i=1
Ln2nL2 3τ2L2n3nL3	15nnL3 K L2	2	3	2 2 3 2
+ TYmL + —2mjL + T—卜 L + T 2n nnL + 45k 2L2nnL] σG
12) T-1	1
≤	- 2nnL + 45nnLK2L2τ kVf(Xt)k2
T-1
+X
t=0
nnL +
2m2 +
Ln2nL	I	3τ2L2n3nL]k Xδ (X )k2
m2	+	2m2	k 型乙(Xtf ,i)k
i=1
+ T [" + 3τ2L2n3n3 + 1⅛kl2 ]σL + T [ 3 nnL + 45K 2L2nnL] σG
m	2m	2	2
17
Under review as a conference paper at ICLR 2022
(a13) T-1 1
≤ -4 -4ηηLkvf(Xt)k2
t=04
,τ	∖LnnL , 3τ2L2η2ηL	15ηLKL2] 2 τ
+ TnnL ---+ ——ɔ------+ ——ɔ—— σL + TnnL
m	2m	2
T-1	1
(a=) X -4nnLkvf(Xt)k2 + TnnL∣αLσL + αGσG],
t=04
2+45K2L2nL∖ σG
where (a12) is due to maximum time delay T in the system, (a13) holds if 4 ≤ [2 - 45nLK2L2T],
i.e., 180nLK2L2τ < 1, and -躲 + Ln+ 切寰症 ≤ 0, i.e., 2LnnL + 3τ2L2r2rL ≤ 1.
Lastly, (a14) follows from the following definitions: αL =[当/ + 3τ Lmn nL + 15nLKL ], αG =
[∣ + 45K2L2nL]. Rearranging terms, we have:
1 T-1
T ∑kVf(xt)k2 ≤
T t=0
4(fo-3
nnLT
+ 4[αLσL2 + αGσG2 ],
and the proof is complete.	□
Corollary 1 (Linear Speedup to Error Ball). By setting nL =力,and n = √m, the convergence
rate of AFA-CD with general worker information arrival processes is:
T X EkVf(Xt)k2 = O( m1∕2T 1/2 ) + O( T ) + O( ɪ ) + O(σG ).
Proof. Let nL =方,and n = √m. It then follows that:
1	T2	K
αL = O( m1∕2T 1/2 ) + O(T) + O(T).
αG = O(σG ) + O( 7 ).
This completes the proof.
□
B.3 Uniformly Distributed Worker Information Arrivals
Now, we consider the special case where all workers have a statistically identical speed so that the
worker information arrivals are uniformly distributed. As mentioned earlier, this special case acts as
a widely-used assumption in FL and could deepen our understanding on the AFA-CD algorithm’s
performance in large-scale AFL systems.
Theorem 3. Under Assumptions 1- 3, choose server-side and worker-side learning rates n and nL
such that the following relationships hold: nL2 [6(2K 2 - 3K+ 1)L2] ≤ 1, 120L2 K 2 nL2 T + 4(LnnL +
L2n2nLτ2) mM-mι) (90K2L2nLT + 3τ) < 1. Then, the output sequence {xt} generated by AFA-CD
with uniformly distributed worker information arrivals satisfies:
1
T
T1
XEkVf(Xt)k22 ≤
t=0
4(f0 - f*)
nnLT
+ 4(αL σL + αgσG ),
(3)
where αL and αG are constants that are defined as:
αL2 ](LmL + T2Lm12nL + 5KL2nL) +(LnnL + L2n2nLτ2)mM-my(15KL2nL)
αG , 30K2L2nL + (LnnL + L2n2nLT2)mM -ZI)(90K2L2nL + 3) ∙
18
Under review as a conference paper at ICLR 2022
Proof. The one-step update can be rewritten as: xt+1 - xt = -ηηLGt. For cross-device FL,
Gt = ml Pi∈Mt Gi(Xt-τt,J, where τt,i is the delay for client i in terms of the current global
communication round t. When τt,i = 0, ∀i ∈ Mt, it degenerates to synchronous FL with partial
worker participation.
Due to the L-smoothness in Assumption 1 , taking expectation of f(Xt+1) over the randomness in
communication round t, we have:
E[f (xt+ι)] ≤ f (Xt) + 3f(xt), E[xt+1 - xt]〉+ L E[∣∣xt+ι - Xtk2
X-----------{z----------}	2 X-------V-------}
A1	A2
We first bound A2 as follows:
A2 = Ekxt+1 - xtk2
=η2ηLEkɪ X Gi(Xtf ,jk2
i∈Mt
(b1) η2 η 2	m
≤ m2 E k X ʌi(Xt-Tt,Jk2 + mσL
i=1
(b2) η2η2	M	η2η2
≤ -2 Ek X I{i ∈Mt}∆i(Xt-Tt,Jk2 +	~σL,
m2	t,i	m
i=1
where (b1) is due to Lemma 2 and (b2) is due to the uniformly independent information arrival
assumption.
To bound the term A1, we have:
Ai =(Vf (xt), E[xt+ι - xt]〉
=-ηηL(yf(Xt) Emm X Gi(Xt-Tt,J)
i∈Mt
(=) - ηηL(Vf (xt),-M X ∆i(Xtf ,i)〉
i∈[M]
(=) - 2ηηLkVf(xt)k2 - 1 ηηLkE X A(Xtf ,Jk2
i∈[M]
1	1	2
+ 2ηηL Vf(Xt) - M Σ ∆i (Xt-Tt,i ) ,
i∈[M]
'---------------V-------------'
A3
where (b3) is due to the uniformly independent worker information arrival assumption and Lemma 1,
(b4) is due to the fact that hx, y〉= 2(IkXk2 + kyk2 — kx — yk2).
To further bound the term A3 , we have:
A3 = kVf(Xt) - MM X ∆i(Xtf ,i)k2
i∈[M]
(=)UM X Vi(Xt)- A(xtf,i)]『
i∈[M]
≤ M X IIVfi(Xt)- ∆i(Xt-Tt,J∣∣2
i∈[M]
=M X IIVfi(Xt)-Vfi(Xt-τt,l + Vfi(Xt-τt,j - Ai(Xt-Fi)II2
i∈[M]
19
Under review as a conference paper at ICLR 2022
b6) 1
≤ M E	2kvfi(xt) - vfi(x
(b6)
(b7)
≤
i∈[M ]
2L2 M
^M^ XUXt-Xt-
i=1
X--------------
t-Tt,i)k2+2kVfi(Xt-Tt,i)-∆i(Xt-Tt,i)k2
2M
τt,i∣l2 + MEIIVfi(Xt-τt,J - δ (x
i=1 '--------------
A4
where (b5) is due to the fact that vf(X)
{z^
A5
t-Tt,i)2,
/
MM Pi∈[M] Vfi(x), (b6) follows from the inequality
∣∣xι + x2 + •…+ Xnk2 ≤ npn=ι ∣∣Xik2, and (b7) follows from the L-Smoothness assumption
(Assumption 1).
For A4 and A5, we have the same bounds as in the case of general worker information arrival
processes:
t-1
A4 ≤ E	[( X k X ^i(χk-τk,i)k2) + τmσL]
22
≤ η2ηLT
m2
k=t-Tt,μ	i∈Mk	」
t-1	M
( X EkXI{i ∈ Mk}∆i(Xk-Tk,i)II2) + τmσL2
- k=t-Tt,μ	i=1	-
A5 ≤ 5KL2ηL2(σL2 + 6KσG2) + 30K2L2ηL2 kVf(Xt-Tt,i)k2,
With the above results of the term A1 through A5, we have:
Et[f (Xt+1)] - f (Xt) ≤ (Vf(Xt), Et[Xt+1 - Xt]〉+^5^ Et[kXt+1 -
-------------------------------------------} 2 Y
{z^
A1
{z^
A2
Xtk2
/
- 2ηηLkVf(Xt)k2 - 2 ηηL k M	X ∆i(Xt-Tt,i)k2 + 2ηηL	kvf(Xt)- M	X ∆i(Xt-Tt,i)k2
2	2M	2	M
i∈[M]
i∈[M ]
―z^^^~
A3
|
}
+ LmnLEk XI{i ∈ Mt}∆i(Xt-Tt,i)k2 + LmLσL
i=1
≤ - 1 ηηLkVf(Xt)k2 - 2ηηLkM7 X ^-"112 + LmnLEkX叩 ∈ 从心(『,方|2
2	2M	m
i∈[M ]	i=1
1
+ 2 ηηL
2L2 M
ɪ X kxt-xt-
'-------------
2M
τt,ik + M X kVfi (Xt-Tt,J - δ2 (Xt-Tt,JI
i=1 S-----------------------}
'∙'^^^^^^^^^^^^{^^^^^^^^^^^^^
A4
≤- 2 ηηLkVf(Xt)k2 - 2 ηηL k M X ∆i(Xt-Tt,i)k2 +
i∈[M ]
t-1	M
A5
+ L⅛ σL
mL
LmnL EkX i{i eMt}∆i(Xt-Tt,i)k2
m	i=1
+ ηηLL2	(	Ek	I{i ∈ Mk}∆i(Xk-Tk,i)k2 + τ mσL2 )
k=t-Tt,μ	i=1	-
}
+ ηηL 5KL2ηL(σL + 6KσG) + 30K2L2ηLM X kWMf^k2
,Lη2ηL 2
+	σL
(b8)
≤
+
i∈[M ]
- 2ηηL∣Vf(Xt)k2 + (30ηK2L2ηL)|尸〃*-』)『
- 2M2 k X Ai(Xt-Tt,i )k2+LrmmL Ek X I{i ∈ Mt}%(Xt-Tt,Ik2
i=1	i=1
20
Under review as a conference paper at ICLR 2022
2 3 3	t-1	M
+ -⅛ηLτ X Ek X I{i ∈ Mk}∆i(xk-τk,i)k2
k=t-τt,μ	i=1	」
+ σL ]-mL + τ2-m3ηL + 5Kη-症]+ 30ηK2-2ηLσG,
where (b8) follows from j := argmaXi∈[M] ∣∣Vf (Xt-Tt,J∣∣2. Note j is dependent on t but we omit
it for brevity.
Summing the above inequality from t = 0 to t = T - 1 yields:
Ef(XT) - f(X0)
T-1
≤X
t=0
-2ηηL∣Vf (xt)∣2 + (30ηK2-2ηL)∣Vf(%—“)『
T-1
+X
t=0
ηη	-η2η2	M
-2M2k X AMxt-TtJk + m2 Ek X I{i ∈ Mt}∆i(xt-Tt,i)k
i∈[M]	i=1
+-mηLτ	X Ek X i{i ∈Mk}∆i(xk-τk,i)k2
k=t-τt,μ	i∈[M ]	-
+ T [σL(" + τ⅛3η3 + 5Kη-2ηL) + 30ηK①济
mm
(b9) T -1
≤
t=0
— 2 ηηL∣Vf (xt)k2 + (30ηK2 -2ηL T )∣Vf (xt)∣2
T-1
+X
t=0
- 2ML k X △，(Xt-Tt/k2+LrImL Ek X I{i ∈ Mta(Xt-Tt,Ik2
i∈[M]	i∈[M]
+ -2η3yT2Ek X I{i ∈ Mt}∆i(xt-τt,i)k2
m	i∈[M]
+ T [σL(" + τ⅛3< + 5Kη-2ηL) + 30ηK①济
mm
where (b9) is due to the fact that the delay in the system is less than T.
By letting zi = △i(xt-Tt,i) (omitting the communication round index t for notation simplicity), we
have that:
M
kXzik2 = X kzik2+Xhzi,zji,
i=1	i∈[M]	i6=j
( = ) X MkZik2- 2 X kZi-Zj k2,
M
Ek XI{i ∈ Mt}zik2 = X P{i∈Mt}kzik2+XP{i,j ∈Mt}hzi,zji
i=1	i∈[M]	i6=j
(b=1) m X kz,k2 + m(m - 1)Xhz Z .i
=M 乙 k ik + M(M - 1) UziZi
i∈[M]	i6=j
(b12) m2	2	m(m- 1)	2
=M E kzzk2 - 2M(M - 1) EkZi- zZk2,
i∈[M]	i6=j
where (b10) and (b12) are due to the fact that(x, y) = ɪ [kxk2 + kyk2-kx-yk2] ≤ ɪ [kxk2 + kyk2],
(b11) follows from the fact that P{i ∈ Mt} = M and P{i,j ∈ Mt} = M(M-II)). It then follows
21
Under review as a conference paper at ICLR 2022
that:
M	τ 2 2 M	τ2332 M
-舞 k X 叫2 + TEkX 叩 ∈ Mt}叫2 + L-η⅜τ-EkX 叩 ∈ Mt}叫2
2 M2	m2	m2
i=1	i=1	i=1
=[-翳+( LML+LnF)]X kzik2
L	」i=1
+
ηηL	/Ln2nL ι L2η3ηLT2 ʌ m(m — 1)
4M- -( m2 + —m — )2M(M — 1)
<
EkZi- Zj Il2
i=j
ηηL + (Lη2ηL +
2M +( M
L2η3ηLτ2
M
)+ (皿-(⅛2 +
) + (2M	( m2	+
L2η3ηLτ2 m(m — 1)
)(M - 1)
m2
M
X kZik2
i=1
[(Lη2ηL + L2η3ηL T 2
(M + —M-
)-
(Lη2ηL , LntnLT2 ]
(	2	+	2	)
m2	m2
Im(Im - 1)
(M - 1)
M
XkZik2
i=1
(LnnL + L2η3ηL τ 2)
M - m
mM(M - 1)
M
X kZik2.
i=1
)
Note also that:
kZik2 = k∆i(xtf,i)k2
=ICi(Xt-Tt,i) - Vfi(Xt-τt,i) + Vfi(Xt-τt,i) - Vf(Xt-τt,i) + Vf(Xt-τt,i)k2
< 3k∆i(Xt-τt,i) - Vfi(Xtf ,i)k2 + 3kVfi(Xt-τt,i) - Vf(Xtf ,i)k2 + 3kVf(Xt-τt,i)k2
< 3 ∣∣Vfi(Xt-τt,i) - ∆i(Xt-τt,i)k2 +3σG + 3∣∣Vf (Xt-τt,i)k2.
'------------V---------------'
As
Using the above results, we finally have:
Ef (xt) - f (xo)
T-1
<X
t=0
-2ηηL∣Vf(Xt)k2 + (30ηK2L2rLT)∣∣Vf(Xt)∣∣2
T-1
+X
t=0
-豫 kX △⑨-八)『+Lmr- EkX 咐 ∈ Mt}A(Xtf,Ji2
i=1	m	i=1
L2η3η3 τ2	a	Cl
+ ηηL	Ek £l{i ∈ Mt}∆i(Xk-τk,i)k2
m	i=1
+ T [σL(L⅛ + t2l⅛3 + 5KηL2ηL) + 30ηKZL?*
mm
T-1 「	1	-
<	∑ [-2ηηLkVf(Xt)k2 + (30ηK2L2ηLT)∣∣Vf(Xt)∣∣2
T-1
+X
t=0
[(Lη2ηL + L2η3ηLt2) mMzf m`][(15KL2ηL(σL + 6κσG)
m(M - 1)
13
+ 90K2L2ηLM E kVf(Xt-τt,i)k2 + 3σG + M EkVf(Xt-…)||2)]
i∈[M ]	i=1
+ T [σL(L⅛ + T2l⅛! + 5KηL2ηL) + 30ηK4η"一
mm
T-1
<	X	ηηLkVf(Xt)k2×
t=0
22
Under review as a conference paper at ICLR 2022
-2 + 30L2K2ηLT + [(LnnL + L2η2ηLτ2) mM- -mŋ ](90K2L2ηLT + 3τU
+ T ηηL σL2 ×
'[(LmL + τ2Lr2 + 5KL2nL) + (LnnL + L2n2nL τ2) m(M-m1)(i5KL2nL)]
+ [30K2 L2nL + (LnnL + L2n2nL τ2) m(Mm)(90K 2L2nL + 3)]σG 一
(b13)
≤
T-1	1
-4 -4nnLkvf(Xt)II2 + TnnL[αLσL + αGσG],
t=04
where (b13) follows from the fact that
4 ≤ 2 - 30L2K2nLT - [(LnnL + L2n2nLτ2) ImMM m ](90K2L2nLT + 3τ)]
if 120L2K2nLT + 4(LnnL + L2n2nLτ2)mMM-m1)](90K2L2nLT + 3τ) < 1,
αL = [(LnnL + TLnnL + 5KL2nL) + (LnnL + L2n2nLTT) M- m)(15KL2nL)],
m	m	m(M - 1)
and
αG = [30K 2L2nL + (LnnL + L2n2nL 小 mM--m1)(90K 2L2nL + 3)].
Lastly, by rearranging and telescoping, we have
T -1
1 X EkVf(xt)k2 ≤ (f0 - f +4[αLσL + αaσG].
T t=0	nnLT	L G
This completes the proof.	□
Corollary 2 (Linear Speedup to Stationary Point). By setting nL = √T and n = √m, the ConVer-
gence rate of AFA-CD with uniformly distributed worker information arrivals is:
1 x EkVf(Xt)k2 = O(	1	)+ O( T2 ) + O(K) + O( 1K23/2) + O( H ).
T	m1/2T1/2	T	T	m1/2 T3/2	T2
Proof. Let nL =方,and n = √m. It then follows that:
1	T2 K	K	KT2
αL = O( m1∕2T 1/2 ) + O(ψ) + O( T ) + O( m1/2T3/2 ) + O(TpT )，
1	T2	K2	K2	K2T2
αG = O( m1∕2T 1/2 ) + O(T) + O(亍) + O( m1∕2T3/2 ) + O( ~T2- )，
and the proof is complete.	□
C Proof of the performance results of the AFA-CS algorithm
Theorem 4. Under Assumptions 1- 3, choose sever- and worker-side learning rates n and nL in such
a way that there exists a non-negative constant series {βμ}U=0 satisfying thefollowing relationship:
12LnnL + 540(MZ- m0)2 (1 + LnnL)K2L2nL(1 + T) + 180K2L2nL + 320L3K2nnL < 1, (4)
M2
nnL (9(M-m) (1 + LnnL)[3TL2 + (βu+ι - Bu) ≤ 0,	(5)
2M2
23
Under review as a conference paper at ICLR 2022
nnL(MM2Mm) (I + LnnL))3τL2 - B.i ≤ 0,	(6)
31
2MσL ≤(2 - β0nnL)EkGtk2,	⑺
the output sequence {xt} generated by the AFA-CS algorithm for general worker information arrival
processes with bounded delay (τ := maxt∈[T],i∈[M] {τt,i}) satisfies:
1 X EkVf(xt)k2 ≤4(V(XO)-7V(X*)) +4(αLσL + αaσG),	(8)
T	nnLT
where αL and αG are constants defined as follows:
αL , [3LMnL + 5KL2nL(9(MM2m) (I + LnnL) + (23 + 3LnnL))],
αG , (9(M-m) (1 + LnnL) + (3 + 3LnnL))(30K2L2nL),
M2	2
and V(∙) is defined as V(Xt) , f (Xt) + PU=0 βukxt-u — xt-u-1∣∣2, m0 is the number ofupdates
in the memory space with no time delay (τt,i = 0).
Proof. We divide the stochastic gradient returns { Gi} into two groups, one is for those without delay
(Gi(Xt), i ∈ Mt, |Mt| = m0) and the other is for those with delay (Gi(xt-τt,i), i ∈ Mtc, |Mtc| =
M - m0 ).
Then, the update step can be written as follows:
xt+1 - xt = --ML [ X Gi(Xt)+ X Gi(Xt-τt,i)	(IO)
i∈Mt	i∈Mtc
=-M [ X Gi(xt) + X (Gi(Xtf,i) - Gi(Xt)) ].	(11)
i∈[M]	i∈Mtc
Due to the L-smoothness assumption, taking expectation of f (xt+1) over the randomness in commu-
nication round t, we have:
E[f (xt+i)] ≤ f(xt) +〈Vf (xt), E[xt+1 - xt]〉+ L E[kxt+1 - Xtk2
X----------{z----------}	2 X------V------}
A1	A2
We first bound A2 as follows:
A2 = E[kxt+i - xtk2]
=nM2E[	x Gi(xt)+ X Gi(Xt-τt,i)
i∈Mt	i∈Mtc
=空e[	X [Gi(Xt) - ∆i(xt)]
i∈Mt
+ X [Gi(xt-τt,i) - ∆i (xt-τt,i) + ∆i(xt-τt,i) - ∆i(xt)] + X ∆i(xt)
i∈Mtc	i∈[M]
+E
2
X [Gi(xt) - ∆i(xt)] + X [Gi(xt-τt,i)-∆i(xt-τt,i)]
i∈Mt	i∈Mtc
2
) - ∆i(xt)]	+ E X ∆i(xt)
i∈[M]
[∆i(xt-τt,i
i∈Mtc
≤ 3nML σL + 3(M-2 m) n2nL X kAi(xt) - A(xtf,i)k2 + 3MnL Il X ∆i(χt)k2
i∈Mtc	i∈[M]
24
Under review as a conference paper at ICLR 2022
≤ ^MLσ2 + 3(MM--2m)η2ηL X kAi(xt) 一 δ2(Xtf ,jk2
i∈Mtc
+ "M X IA(Xt) - ^ fi(xt)k2 + 6η2ηL INf (Xt)II'
i∈[M]
To bound the term A1 , we have:
Al =E〈Vf(xt), Xt+1 - Xt)
=E
ηηL
i∈Mt
-η"LE 2IlVf(χt)ll2 + 2M2
Gi (Xt) + Gi (Xt-τt,i )
i∈Mtc
X Gi (Xt) + X Gi (Xt-τt,i )
i∈Mt
-2 vf(Xt)- MM[ X Gi(Xt) + X Gi(X
i∈Mt
i∈Mtc
i∈Mtc
t-τt,i)]2
2
(=) - nnL kvf (Xt)k2 - nnL Ek 工(Xt+ι -Xt)k2
2	2	nnL
+ 2MLEk X [Vfi(Xt) - Gi(Xt)]+ X [Vfi(Xt) - Gi(Xt-τt,i)]k2
i∈Mt	i∈Mtc
=-nnLkVf(Xt)k2 -熹EkXt+ι - Xtk2
+第E
[Vfi (Xt) - ∆i (Xt) + ∆i (Xt) - Gi (Xt)]
i∈Mt
+	[Vfi (Xt) - ∆i (Xt) + ∆i (Xt) - ∆i (Xt-τt,i ) + ∆i (Xt-τt,i ) - Gi (Xt-τt,i )]
i∈Mtc
-η2L kvf(Xt)k2 - 2nn- Ekχt+ι- Xtk2
2
+第E
[Vfi(Xt) - ∆i(Xt)] +	[∆i(Xt) -Gi(Xt)]
i∈[M]
i∈Mt
+ X [∆i(Xt) - ∆i (Xt-τt,i) + ∆i(Xt-τt,i ) - Gi (Xt-τt,i)]
i∈Mtc
2
2
≤-等kVf(Xt)k2 -
+ 3"nl
+ 2M2
ɪEkXt+1- Xtk2 + 舞E
2ηηL	2M2
2
[∆i(Xt)-∆i(Xt-τt,i)]
i∈Mtc
+3M2 E
Vfi (Xt) - ∆i (Xt)
i∈[M]
X [∆i(Xt) - Gi(Xt)] + X ∆i (Xt-τt,i ) - Gi(Xt-τt,i )
i∈Mt	i∈Mtc
≤ - nnLkvf(Xt)k2 - ɪEkXt+1 - Xtk2 + 3(M -『L
2	2ηηL	2M 2
i∈Mtc
E∆i(Xt) - ∆i(Xt-τt,i)
+32ML X	Vfi(Xt) - ∆i(Xt)
i∈[M]
2 , 3"nL 2
+ 2M (JL
2
2
where (c) follows from the update step of the algorithm specified in Eq. 10.
25
Under review as a conference paper at ICLR 2022
Combining A1 abd A2, we have:
E[f (xt+i)]-f (xt) ≤ KVf(X/E!xt+1-χQ,+2 a+—£
Ai	A2
≤f (Xt) 一 ηnL HVf(Xt)k2 — 2nm EIlXt+1 — χtk2
+ ( 3(M J + 3L(M 温0加喷)X E ∆i(xt)- ∆i(xtf,i)
、	)i∈Mc '-----------“-------
Cl
+
+第 σL+3¾Ml σL+3Lη2ηL kvf (Xt) k2
(12)
For each worker i, we have:
C 2= IIVfi(Xt)- ∆i (Xt)II2
I Kt,i-1
=IIVfi(Xt)- L X Vfi(Xj) 12
Ktdj=O
I Kt,i-1
=L X IVfi(Xt)-Vfi(Xj)I2
Kt，i j=0
2 Kb1
≤ Kl X kxt-xjk2
t,i j=0
(c2)
≤ 5KL2ηL(σL + 6KσG) + 30K2L2ηLIIVf(Xt)∣∣2,
where (c2) follows from the same bound of A6 specified in Eq.(9).
Also, note that:
C1 = IA(Xt)- AM-TkJII
≤ 3ICi(Xt)- Vfi(Xt)Il2 + 3|Vfi(Xt)- Vfi(Xtf JI2 + 3|Vfi(Xtf ,J - ∆i(χtf,i)||2
≤ 3ICi(Xt)-Vfi(Xt)Il2 + 3IIVfi(Xt-τt,J - δi(Xtf ,J∣∣2 + 3L2IIXt-Xtf ,J2
τt,i-1
≤	3ICi(Xt)-Vfi(Xt)Il2 + 3IIVfi(Xt-τt,i)	-	Ai(xt-τt,i)|2 + 3L2k X	Xt-U- Xt-U-IIl2
u=0
T — 1
≤	3ICi(Xt)-Vfi(Xt)Il2 + 3IIVfi(Xt-Tt,i)	-	Ai(xt-Tt,i)|2 + 3TL2	X IlXt-U- Xt-U-1∣∣2,
u=0
where T is the maximum delay, i.e., T = max{τt,i}, ∀t ∈ [T],i ∈ [M].
Plugging C1 and C2 into the inequality in Eq. (12), we have:
E[f(xt+1)] -f (xt) ≤ KVf(Xt),E[xt+1-xt])+2 ⅝+3
Ai	A2
≤f(Xt) - ηηL IlVf(Xt )∣∣2 - 2ηη^ EIlXt+1- xt∣∣2
+ (9(M 力L + 9L(M位)X E Vfi(Xt) - ∆i(xt)
2M	2M
、	/ i∈Mc
2
26
Under review as a conference paper at ICLR 2022
ι (9(M - m0
+ ∖	2M2
)ηηL + 9L(M — m0)η2ηL
2M2
E E Vfi(Xt—”.)一 4i(Xt—τt,J
i∈Mc
(9(M — m，
+ ∖	2M2
)2ηηL + 9L(M —
m0)2η2ηL
2M2
3τL2
+
+ 3Ln2nL
+ M
+ 3nnL 2 + 3Ln2nL
+ 2M σL +	2M
)E Vfi(Xt) - ∆i(xt)
i∈[M ]
σL +3Lη2ηL kVf (xt)k2
u=0
2
E xt—u - xt—u—1
T — 1
2
2
≤f (Xt) - nnL IlVf(Xt )∣∣2 - ^2^n^ EkXt+1- xt∣2
+ ηηL
+ ηηL
9(M-m/)2 (1 + LnnL) + (3 + 3LnnL)) (5KL2nL(σL + 6KσG) + 30K2L2nLkVf (xt)k2)
2M2	2
9(M-m/)2 (1 + LnnL)) (5KL2nL(σL + 6KσG) + 30K2L2nL vɪ E kVf(xt—τt,i)k2)
2M2	J	M — m z—z	,
/	i∈Mc
9 9(M — m0)2∕r	T ∖∖c r2 τ^m
+ nnL( —2m2	(1 + LnnL))3TL EE xt—u -
2M	u=0
+ IML ^L + *M2 σL + 3Ln2nL kVf (xt)k2
2M	2M
2
Xt—u —1
=f (χt) - ηηL
9(M — m0)2
2M2-
(1 + LnnL) + 0 + 3LnnL530K2L2nL - 3LnnL ∣∣Vf(xt)∣2
—
而"EkXt+1 -xtk2 + nnLC(MM2m)(1 + LnnL) +	+ 3LnnL))[5KL2nL(σL + 6κσG)]
+ nnL(9(M2Mm，)2(1 +LnnL))(30K2L2nLMJrm E kVf(xt—τ"k2)
∖	)	i∈Mc
9 9(M — m°)2∕r T ∖'c 丁2
+ nnL (—2M2 ' (1 + LnnL))3TL
EE Xt—u - Xt—u—1
u=0
2 , 3nnL 2 , 3Ln2nL 2
+ 2M σL +	2M σL
τ — 1
Now, define V(Xt) = f(Xt) + Pu=0 eMIxt—u — xt—u—1∣∣2. Based on the above bound of
E[f (xt+1)] - f (xt), it then follows that:
EV(xt+1) - V(Xt)
=Ef(Xt+1) - f (xt)
τ — 2
+ ^X(β∏⅛1 - eu)||xt—u - xt—u—1k2 + β0∣∣xt+1 - xt∣∣2 - βτ —1||xt—τ —1 - Xt—τ — 2k2
u=0
≤ - ηηL
+ ηηL
+ ηηL
1	(9(M - m，)2
2 - ∖	2M2
(1 + LnnL) + (∣ + 3LηηL^30K2L2ηL - 3LηηL ∣∣Vf(xt)k2
9(M - m
M2
9(M - m
2M 2
/)2	O	∖
ɪ(i+ LnnL) + (2 + 3LnnL)) [5KL2ηL(σL + 6KσG)]
/)2	∖	1
上(1 + LnnL)(3。K2L2nLE
(9(M — m0)2
+ [nnLl	2M 2
E Rf(Xtf Ji2)
i∈Mc
T — 2
(1 + LnnL))3TL2 + (βu+1 - βu)] ^XE xt—u -
u=0
Xt—u—1
2
27
Under review as a conference paper at ICLR 2022
+ [ηηL( 9(M2M m0)2 (I +LηηL) }τL2 -βτ-1]kxt-τ-1 -χt-τ-2k2
+ (β0 -前 )kxt+1 - xtk2 +
3ηηL 2 ɪ 3Lη2ηL 2
2M (TL+	2M σL.
Telescoping the above inequality from t = 0 to T - 1 of the above inequality yields:
EV (xT )-V(x0
T-1
≤ - ηηL
T-1	1
X 2 -
t=0
9(M — m0)2
2M2
(1 + LnnL) + (3 + 3LηηL530K2L2ηL - 3LηηL INf(χt)k2
+ nnL(MM2Mm(1 + LnnL))(30K2L2nLX M-m X kVf(Xtf ,Jk2)
t=0	i∈Mtc
+ nnLT(9(M-m) (I + LnnL) + (3 + 3LnnL)) [5KL2nL(σL + 6KσG)]
M2	2
+ X [nnL(9cMm) (1 + LnnL)) 3τL2 + (E+i -β”)]XE Xt-U -
t = 0、	∖	{z )	/ u=0
2
xt-u-1
^Z
C3
+ X [nnL(MM2Mm) (1 + LnnL))3τL2 - βτ-1] kχt-τ-1 - Xt-T-2k2
t=0 `-------------{.------------}
^Z
C4
l 1	1、X u	∣∣2 l 3nnLT 2 l 3LTn2nL 2
+ (β0 -砺L)T kxt+1-xtk +UM^σL +	2M	σL
L t=0
'-----------------V------------------}
C5
(c3)	1 T-1
≤ - 4nnL∑ kVf(χt)k2
4	t=0
\LUTnLL	2 ∕9(M - m0)2	-/3	Λl 2
+ nnL	2M + 5TKL nL[ —M2-----------(I + LnnL) + (2 + 3LnnL)J σL
+ nnLT(9(M八-2m) (1 + LnnL) + (3 + 3LnnL)) (30K2L2nL)σG,
M2	2
where (c3) holds if the following conditions are satisfied:
4 ≤ 2 - (9(M)Mm) (1 + LnnL) + (2 + 3LnnL))30K2L2nL - 3LnnL
4	2	2M	2
-(NM2Mm (1 + LnnL)) (30τK2L2nL),
C3 = [nnL (9CMm) (I + LnnL)) 3τL2 + (员+i -员)]≤ 0,
C4 = [nnL(9(M-m) (1 + LnnL)) 3τL2 -户一” ≤ 0,
2M2
31
C5 ≤ 0 J 2MσL ≤ (2 - β°nnL)EkGtk ∙
By rearranging the inequality, we have:
1	T-1
4nnLf kVf (χt)k2
4	t=0
28
Under review as a conference paper at ICLR 2022
≤V (x0) -EV(xT)
+ ηηLT M +5KL2ηL (9(MM2m) (I + LnnL) + (2 + 3LnnL)) σL
+ nnLT(9(MR-2m) (I + LnnL) + (3 + 3LnnL))(30K2L2nL)σG,
M2	2
That is,
T-1
1 X EkVf(Xt)k2 ≤ ((XO)- (x*" + 4[αLσL + a.G«],
T t=0	nnLT	L G
where αL = 13LηML + 5KL2nL (趴MMm)) (1 + LnnL)+ (3 + 3LnnL)) , 0储=(趴MMm)) (1 +
LnnL) + (3 + 3LnnLD (30K2L2nL). This completes the proof.	□
Corollary 3 (Linear Speedup). By setting nL =力,and n = λ∕M, the convergence rate of the
AFA-CS algorithm for general worker information arrival processes with bounded delay is:
T X1 EkVf (Xt)k2 = o(」)+o(K2 )+o( " ).
Proof. Let nL =方,and n = λ∕M. It then follows that:
αL
1	K	KM1/2
O( M1/2T1/2)+ O( T) + O(亍h).
αG
K2
O(亍)+ O(
K 2M1/2
-T 3/2-
).
This completes the proof.
□
D	Discussion
Convergence Error: The case with uniformly distributed worker information arrivals under AFL can
be viewed as a uniformly independent sampling process from total workers [M] under conventional
FL. Also, the case with general worker information arrival processes under AFL can be equivalently
mapped to an arbitrarily independent sampling under conventional FL. In each communication round,
1
the surrogate objection function for partial worker participation in FL is f (x) := PM^ Σ2i∈M古 fi(x).
For uniformly independent sampling, the surrogate object function approximately equals to f(x) :=
M PMI fi(x) in expectation, i.e., E[f(x)] = f (x). However, the surrogate object function f(x)
may deviate from f(x) with arbitrarily independent sampling. More specifically, for uniformly
independent sampling, the bound of kVf(Xt) - f(Xt)k2 is independent of σG (A3 term in B.3). On
the other hand, for arbitrarily independent sampling, kVf (Xt) - f(xt)k2 ≤ O(σG) (A3 term in B.2).
This deviation may happen in every communication round, so it is non-vanishing even with infinity
communication rounds. As a result, such deviation is originated from the arbitrary sampling coupling
with non-i.i.d. datasets. In other words, it is irrelevant to the optimization hyper-parameters such as
the learning rate, local steps and others, which is different from the objective inconsistency due to
different local steps shown in Wang et al. (2020). When we set τ = 0 and Kt,i = K, ∀t, i, AFA-CD
generalizes FedAvg. In such sense, the convergence error also exists in currently synchronous FL
algorithms with such arbitrarily independent sampling and non-i.i.d. dataset. Moreover, this sampling
process coupling with non-i.i.d. dataset not only results in convergence issue but also potentially
induces a new source of bias/unfairness (Mohri et al., 2019; Li et al., 2019b). So how to model the
practical worker participation process in practice and in turn tackle these potential bias are worth
further exploration.
29
Under review as a conference paper at ICLR 2022
Variance Reduction: If we view the derivation between local loss function and global loss function
as global variance, i.e., ∣Nfi(Xt) - Vf (Xt)II2 ≤ σG, ∀i ∈ [m],∀t as shown in Assumption 3, the
AFA-CS algorithm is indeed a variance reduction (VR) method, akin to SAG (Le Roux et al., 2012;
Schmidt et al., 2017). SAG maintains an estimate stochastic gradient vi, i ∈ [n] for each data point
(n is the size of the dataset). In each iteration, SAG only samples one data point (say, j) and update
the stochastic gradient on latest model (vj = Vfj(xt)) stored in the memory space, but then use
the average of all stored stochastic gradients as the estimate of a full gradient to update the model
(xt+ι = Xt - ηtgt, gt = n pn=ι vi). In such way, SAG is able to have a faster convergence rate
by reducing the local variance due to the stochastic gradient. AFA-CS algorithm performs in the
similar way. The server in the AFA-CS algorithm maintains a parameter for each worker as an
estimate of the returned stochastic gradient. In each communication round, the server only receives
m updates in the memory space but updates the global model by the average of all the M parameters.
As a result, not only can it diminish the convergence error derived from the non-i.i.d. dataset and
general worker information arrival processes (arbitrarily independent sampling), but also accelerate
the convergence rate with a linear speedup factor M . Previous works have applied VR methods in
FL, notably SCAFFOLD (Karimireddy et al., 2020b) and FedSVRG (KOneCny et al., 2016). The key
difference is that we apply the VR on the server side to control the global variance while previous
works focus on the worker side in order to tackle the model drift due to local update steps. Applying
VR methods on server and worker side are orthogonal, and thus can be used simultaneously. We
believe other variance reduction methods could be similarly extended on the server side in a similar
fashion as what we do in AFA-CD. This will be left for future research.
E Experiments
In this section, we provide the detailed experiment settings as well as extra experimental results that
cannot fit in the page limit of the main paper.
E.1 Model and Datasets
We run three models on three different datasets, including i) multinomial logistic regression (LR)
on manually partitioned non-i.i.d. MNIST, ii) convolutional neural network (CNN) for manually
partitioned non-i.i.d. CIFAR-10, and iii) recurrent neural network (RNN) on natural non-i.i.d.
Shakespeare datasets. These dataset are curated from previous FL papers (McMahan et al., 2016;
Li et al., 2018) and are now widely used as benchmarks in FL studies (Li et al., 2019c; Yang et al.,
2021).
For MNIST and CIFAR-10, each dataset has ten classes of images. To impose statistical heterogeneity,
we split the data based on the classes (p) of images each worker contains. We distribute the data to
M = 10(or 100) workers such that each worker contains only certain classes with the same number
of training/test samples. Specifically, each worker randomly chooses p classes of labels and evenly
samples training/testing data points only with these p classes labels from the overall dataset without
replacement. For example, for p = 2, each worker only has training/testing samples with two classes,
which causes heterogeneity among different workers. For p = 10, each worker has samples with ten
classes, which is nearly i.i.d. case. In this way, we can use the classes (p) in worker’s local dataset to
represent the non-i.i.d. degree qualitatively.
The Shakespeare dataset is built from The Complete Works of William Shakespeare (McMahan et al.,
2016). We use a two-layer LSTM classifier containing 100 hidden units with an embedding layer.
The learning task is the next-character prediction, and there are 80 classes of characters in total.
The model takes as input a sequence of 80 characters, embeds each of the characters into a learned
8-dimensional space and outputs one character per training sample after two LSTM layers and a
densely-connected layer. The dataset and model are taken from LEAF (Li et al., 2018).
For MNIST and CIFAR-10, we use global learning rate η = 1.0 and local learning rate ηL = 0.1. For
MNIST, the batch size is 64 and the total communication round is 150. For CIFAR-10, the batch size
is 500 and the total communication round is 10000. For the Shakespeare dataset, the global learning
rate is η = 50, the local learning rate is ηL = 0.8, batch size is b = 10, and the total communication
round is 300. In the following tables and figure captions, we use “m/M” to denote that, in each
communication round, we randomly choose m workers from [M] to participate in the training.
30
Under review as a conference paper at ICLR 2022
We study the asynchrony and heterogeneity factors in AFL, including asynchrony, heterogeneous
computing, worker’s arrival process, and data heterogeneity. To simulate the asynchrony, each partici-
pated worker choose one global model from the last recent five models instead of only using the latest
global model for synchronous case. To mimic the heterogeneous computing, we simulate two cases:
constant and dynamic local steps. For constant local steps, each participated worker performs a fixed c
local update steps. In contrast, each worker takes a random local update steps uniformly sampled from
[1, 2 × c] for dynamic local steps. To emulate the effect of various worker’s arrival processes, we use
uniform sampling without replacement to simulate the uniformly distributed worker information ar-
rivals, and we use biased sampling with probability [0.19, 0.19, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01]
without replacement for total 10 workers to investigate potential biases with general worker informa-
tion arrival processes. To study the data heterogeneity, we use the value p as a proxy to represent the
non-i.i.d. degree for MNIST and CIFAR-10.
Table 1: CNN Architecture for CIFAR-10.
Layer Type	Size
Convolution + ReLU	5× 5 ×32
Max Pooling	2×2
Convolution + ReLu	5 × 5 × 64
Max Pooling	2×2
Fully Connected + ReLU	1024 × 512
Fully Connected + ReLU	512× 128
Fully Connected	128× 10
E.2 Further experimental results
Table 2: Test Accuracy for comparison of asynchrony and local steps.
Models/ Dataset	Non-i.i.d. index (P)		Worker number	Local steps	Synchrony		Asynchrony	
					Constant steps	Dynamic steps	Constant Steps	Dynamic Steps
	P	二1	5/10	-5-	0.8916	0.8915	0.8888	0.8868
	P	二2	5/10	5	0.8906	0.8981	0.8901	0.8931
	P	二5	5/10	5	0.9072	0.9075	0.9059	0.9048
	P 二	10	5/10	5	0.9114	0.9111	0.9129	0.9143
	P	二1	5/10	10	0.8743	0.8786	0.8701	0.8734
LR/	P	二2	5/10	10	0.8687	0.8813	0.8661	0.8819
MNIST	P	二5	5/10	10	0.9016	0.9050	0.9034	0.9065
	P 二	10	5/10	10	0.9124	0.9135	0.9112	0.9111
	P	二1	20/100	-5-	0.8898	0.8973	0.8909	0.8938
	P	二2	20/100	5	0.8968	0.9007	0.8955	0.9000
	P	二5	20/100	5	0.9088	0.9088	0.9097	0.9078
	P 二	10	20/100	5	0.9111	0.9106	0.9126	0.9125
	P	二1	5/10	5	0.7474	0.7606	0.7319	0.7350
CNN/	P	二2	5/10	5	0.7677	0.7944	0.7662	0.777
CIFAR-10	P	二5	5/10	5	0.7981	0.802	0.8065	0.799
	P 二	10	5/10	5	0.8081	0.8072	0.8065	0.8119
RNN/ Shakespeare	-		72/143	50	0.4683	0.4831	0.4606	0.4687
Effect of asynchrony, local update steps, and non-i.i.d. level. In table 2, we examine three factors
by comparing the top-1 test accuracy: synchrony versus asynchrony, constant steps versus dynamic
steps and different levels of non-i.i.d. dataset. The worker sampling process is uniformly random
sampling to simulate the uniformly distributed worker information arrivals. The baseline is synchrony
with constant steps. When using asynchrony or/and dynamic local steps, the top-1 test accuracy shows
31
Under review as a conference paper at ICLR 2022
no obvious differences. This observation can be observed in all these three tasks. Asynchrony and
dynamic local update steps enable each worker to participate flexibly and loosen the coupling between
workers and the server. As a result, asynchrony and dynamic local steps introduce extra heterogeneity
factors, but the performance of the model is as good as that of the synchronous approaches with
constant local steps. Instead, the data heterogeneity is an important factor for the model performance.
As the non-i.i.d. level increases (smaller p value), the top-1 test accuracy decreases.
Next, we study convergence speed of the test accuracy for the model training under different settings.
Figure 2 illustrates the test accuracy for LR on MNIST with different non-i.i.d. levels. We can see that
asynchrony and dynamic local steps result in zigzagging convergence curves, but the final accuracy
results have negligible differences. The zigzagging phenomenon is more dramatic as the non-i.i.d.
level gets higher. Interestingly, from Figure 3 and Figure 4, we can see that for less non-i.i.d. settings
such as p = 10 and p = 5, the curves of all algorithms are almost identical. Specifically, in Figure 4,
the test accuracy curves of the LSTM model oscillates under asynchrony and dynamic local steps.
Another observation is that it takes more rounds to converge as the non-i.i.d. level of the datasets
increases. This trend can be clearly observed in Figure 3.
1.0
0.9
u 0.8
ra
307
U
< 0.6
⅛i
l<υ 0.5
0.4
0.3
0 20 40 60 80 100 120 140
Communication Round
ι.o
0.9
u 0.8
ra
307
U
< 0.6
+j
l<υ 0.5
0.4
0.3
---Asynchrony + Constant
---Synchrony + Dynamic
----Asynchrony + Dynamic
0 20 40 60 80 100 120 140
Communication Round
(a) p = 1.
(b)p=2.
ι.o
ι.o
0.9
u 0.8
ra
307
U
< 0.6
⅛i
l<υ 0.5
0.4
0.3
'	---- Synchrony + Constant
---Asynchrony + Constant
---Synchrony + Dynamic
---Asynchrony + Dynamic
0 20 40 60 80 100 120 140
Communication Round
0.9
u 0.8
ra
307
U
< 0.6
+j
l<υ 0.5
0.4
0.3
--- Synchrony + Constant
---Asynchrony + Constant
---Synchrony + Dynamic
I -------Asynchrony + Dynamic
020 40 60 80 100 120 140
Communication Round
(c) p = 5.
(d) p = 10.
Figure 2: Test accuracy for LR on MNIST with worker number 5/10, local steps 5.
32
Under review as a conference paper at ICLR 2022
Communication Round
0.8
u 0.7
2
3 0.6
<
⅛0∙5
0.4
0.3
Communication Round
(a) p = 1.
0.8
u o.7-
2
3 0.6
<
⅛0∙5-
0	2000 4000 6000 8000 10000
Communication Round
(b)p=2.
0.8
u 0.7
2
3 0.6
<
⅛0∙5
0.4
0.3
Communication Round
(d) p = 10.
Figure 3: Test accuracy for CNN on CIFAR-10 with worker number 5/10, local steps 5.
(c) p = 5.
Figure 4: Test accuracy for LSTM on Shakespeare with worker number 72/143, local steps 50.
33
Under review as a conference paper at ICLR 2022
Table 3: Test Accuracy of FedProx and SCAFFOLD.
Models/ Dataset	Non-i.i.d. index (p)	Worker number	Local steps	FedProx	SCAFFOLD	AFL + FedProx	AFL + SCAFFOLD
	P = 1	5/10	-5-	0.8893	0.8928	0.8775	0.8946
	P = 2	5/10	5	0.8868	0.8970	0.8832	0.8954
	p = 5	5/10	5	0.9036	0.9032	0.9004	0.9019
LR/	p = 10	5/10	5	0.9075	0.9057	0.9054	0.9022
MNIST	P = 1	5/10	10	0.8752	0.8789	0.8669	-0.8838
	p = 2	5/10	10	0.8685	0.8967	0.8789	0.8978
	p = 5	5/10	10	0.9019	0.9047	0.8998	0.9029
	P =10	5/10	10	0.9072	0.9071	0.9052	0.9038
	P = 1	5/10	-5-	0.7488	0.1641	0.7415	0.3935
CNN/	p = 2	5/10	5	0.7728	0.6315	0.7890	0.6971
CIFAR-10	P = 5	5/10	5	0.7931	0.7828	0.8031	0.7884
	P =10	5/10	5	0.8150	0.8083	0.8143	0.8051
-RNN/-	-	72/143	50	0.4690	0.4794	0.4550	0.4515
Shakespeare							
Utilizing FedProx and SCAFFOLD as the optimizer on the worker-side. Here, we choose
FedProx and SCAFFOLD as two classes of algorithms in existing FL algorithms. FedProx represents
these algorithms that modifies the local objective function. Other algorithms belonging to this
category includes FedPD (Zhang et al., 2020b) and FedDyn (Acar et al., 2021). In such algorithms,
no extra information exchange between worker and server is needed. On the other hand, SCAFFOLD
represents VR-based (variance reduction) algorithms. It needs an extra control variate to perform
the “variance reduction” step, so extra parameters are required in each communication round. Other
algorithms in this class includes FedSVRG (Konecny et al., 2016).
In Table 3, we show the effectiveness of utilizing existing FL algorithms, FedProx and SCAFFOLD,
in the AFL framework. For FedProx and SCAFFOLD, we examine synchrony and constant local
steps settings. When incorporating these two advanced FL algorithms in the AFL framework, we
study the effects of asynchrony and dynamic local steps. We set μ = 0.1 as default in FedProx
algorithm. We can see from Table 3 that FedProx performs as good as FedAvg does (compare with
the results in Table 2). Also, there is no performance degradation in AFL framework by utilizing
FedProx as the worker’s optimizer. However, while SCAFFOLD performs well for LR on MNIST,
it dose not work well for CNN on CIFAR-10, especially in cases with higher non-i.i.d. levels. One
possible reason is that the control variates can become stale in partial worker participation and in turn
degrade the performance. Previous work also showed similar results (Acar et al., 2021; Reddi et al.,
2020). If we view the SCAFFOLD ( in synchrony and constant steps setting) as the baseline, no
obvious performance degradation happens under AFL with SCAFFOLD being used as the worker’s
optimizer.
Effects of different worker information arrival processes. In order to generate different workers’
arrival processes, we use uniform sampling without replacement to simulate the uniformly distributed
worker information arrivals and use biased sampling to simulate the potential bias in general worker
information arrival processes. In Figures 5 and 6, we illustrate the effect of the sampling process
for LR on MNIST and CNN on CIFAR-10 with asynchrony and dynamic local steps. For highly
non-i.i.d. datasets (p = 1), the biased sampling process degrades the model performance. This
is consistent with the larger convergence error as shown in our theoretical analysis. On the other
hand, for other non-i.i.d. cases with p = 2, 5, 10, such biased sampling dose not lead to significant
performance degradation. When applying variance reduction on such biased sampling process by
reusing old gradients as shown in AFA-CS, we can see that AFA-CS performs well on MNIST, but
not on CIFAR-10. We conjecture that AFA-CS, as a variance reduction method, does not always
perform well in practice. This observation is consistent with the previous work (Defazio & Bottou,
2018; Reddi et al., 2020), which also demonstrated the ineffectiveness of variance reduction methods
in deep learning and some cases of FL.
34
Under review as a conference paper at ICLR 2022
1.0
0.9
u 0.8
ra
307
U
< 0.6
在0.5
0.4
0.3
Communication Round
(b)p=2.
(a) p = 1.
ι.o
0.9
u 0.8
ra
307
U
< 0.6
在0.5
0.4
0.3
Communication Round
(d) p = 10.
(c) p = 5.
Figure 5: Test accuracy for LR on MNIST with asynchrony and dynamic local steps.
(b)p=2.
(a) p = 1.
(c) p = 5.
(d) p = 10.
Figure 6: Test accuracy for CNN on CIFAR-10 with asynchrony and dynamic local steps.
35