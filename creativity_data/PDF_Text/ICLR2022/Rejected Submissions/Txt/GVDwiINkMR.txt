Under review as a conference paper at ICLR 2022
Picking Daisies in Private:
Federated Learning from Small Datasets
Anonymous authors
Paper under double-blind review
Ab stract
Federated learning allows multiple parties to collaboratively train a joint model
without sharing local data. This enables applications of machine learning in
settings of inherently distributed, undisclosable data such as in the medical do-
main. In practice, joint training is usually achieved by aggregating local models,
for which local training objectives have to be in expectation similar to the joint
(global) objective. Often, however, local datasets are so small that local objec-
tives differ greatly from the global objective, resulting in federated learning to
fail. We propose a novel approach that intertwines model aggregations with per-
mutations of local models. The permutations expose each local model to a daisy
chain of local datasets resulting in more efficient training in data-sparse domains.
This enables training on extremely small local datasets, such as patient data across
hospitals, while retaining the training efficiency and privacy benefits of federated
learning.
1	Introduction
How can we learn high quality models when data is inherently distributed into small parts that
cannot be shared or pooled, as we for example often encounter in the medical domain (Rieke et al.,
2020)? Federated learning solves many but not all of these problems. While it can achieve good
global models without disclosing any of the local data, it does require sufficient data to be available
at each site in order for the locally trained models to achieve a minimum quality. In many relevant
applications, this is not the case: in healthcare settings we often have as little as a few dozens of
samples (Granlund et al., 2020; Su et al., 2021; Painter et al., 2020), but also domains where DL is
generally regarded as highly successful, such as natural language processing and object detection
often suffer from a lack of data (Liu et al., 2020; Kang et al., 2019).
In this paper, we present an elegant idea in which models are moved around iteratively and passed
from client to client, thus forming a daisy-chain that the model traverses. This daisy-chaining allows
us to learn from such small, distributed datasets simply by consecutively training the model with the
data availalbe at each site. We should not do this naively, however, since it would not only lead to
overfitting - a common problem in federated learning which can cause learning to diverge (Haddad-
PoUr and Mahdavi, 2019) - but also violate privacy, since a client can infer from a model upon the
data of the client it received it from (Shokri et al., 2017). To alleviate these issues, we propose an
approach to combine daisy-chaining of local datasets with aggregation of models orchestrated by a
coordinator, which we term federated daisy-chaining (FedDC).
In a nutshell, in a daisy-chain round, local models are send to a coordinator and randomly redis-
tributed to clients, without aggregation. Thereby, each individual model follows its own random
daisy-chain of clients. In an aggregation round, models are aggregated and redistributed, as in stan-
dard federated learning. Our approach maintains privacy of local datasets, while it provably guar-
antees improvement of model quality of convex models with a suitable aggregation method which
standard federated learning cannot. For non-convex models such as convolutional neural networks,
it improves the performance upon the state-of-the-art on standard benchmark and medical datasets.
Formally, we show that FedDC allows convergences on datasets so small that standard federated
learning diverges by analyzing aggregation via the Radon point from a PAC-learning perspective.
We substantiate this theoretical analysis by showing that FedDC in practice matches the accuracy of
a model trained on the full data of the SUSY binary classification dataset, beating standard federated
1
Under review as a conference paper at ICLR 2022
learning by a wide margin. In fact, FedDC allows us to achieve optimal model quality with only
2 samples per client. In an extensive empirical evaluation, we then show that FedDC outperforms
vanilla federated learning (McMahan et al., 2017), naive daisy-chaining, and FedProx (Li et al.,
2020a) on the benchmark dataset CIFAR10 (Krizhevsky, 2009), and more importantly on two real-
world medical datasets.
In summary, our contributions are as follows.
•	FedDC, an elegant novel approach to federated learning from small datasets via a combi-
nation of daisy-chaining and aggregation,
•	a theoretical guarantee that FedDC improves models in terms of , δ-guarantees, which
standard federated averaging can not,
•	a thorough discussion of the privacy aspects and mitigations suitable for FedDC, including
an empirical evaluation of differentially private FedDC, and
•	an extensive set of experiments showing that FedDC substantially improves model quality
for small datasets, being able to train ResNet18 on a pneumonia dataset on as little as 8
samples per client.
2	Related Work
Learning from small datasets is a well studied problem in machine learning. In the literature, we
find among others general solutions, such as using simpler models, and transfer learning (Torrey and
Shavlik, 2010), to more specialized ones, such as data augmentation (Ibrahim et al., 2021) and few-
shot learning (Vinyals et al., 2016; Prabhu et al., 2019). In our scenario, however, data is abundant,
but the problem is that the local datasets at each site are small and cannot be pooled.
Federated learning and its variants have been shown to learn from incomplete local data sources,
e.g., non-iid label distributions (Li et al., 2020a; Wang et al., 2019) and differing feature distribu-
tions (Li et al., 2020b; Reisizadeh et al., 2020a), but were proven to fail in case of large gradi-
ent diversity (Haddadpour and Mahdavi, 2019) and too dissimilar label distribution (Marfoq et al.,
2021). For very small datasets, local empirical distributions may vary greatly from the global data
distribution—while the difference of empirical to true distribution decreases exponentially with the
sample size (e.g., according to the Dvoretzky-Kiefer-WolfoWitz inequality), for small sample sizes
the difference can be substantial, in particular if the data distribution differs from a Normal distribu-
tion (KWak and Kim, 2017).
FedProx (Li et al., 2020a) is a variant of federated learning that is particularly suitable for tackling
non-iid data distributions. It increases training stability by adding a momentum-like proximal term
to the objective functions. This increase in stability, hoWever, comes at the cost of not being privacy-
preserving anymore (Rahman et al., 2021). We compare FedDC to FedProx in Section 7.
We can reduce sample complexity by training netWorks only partially, e.g., by collaboratively train-
ing only a shared part of the model. This approach alloWs training client-specific models in the
medical domain (Yang et al., 2021), but by design cannot train a global model. Kiss and Horvath
(2021) propose a decentralized and communication-efficient variant of federated learning that mi-
grates models over a decentralized netWork and stores incoming models locally at each client until
sufficiently many models are collected on each client for an averaging step, similar to Gossip feder-
ated learing (Jelasity et al., 2005). The variant Without averaging is similar to simple daisy-chaining
Which We compare to in Section 7. FedDC is compatible With any aggregation operator, includ-
ing the Radon point (Kamp et al., 2017) and the geometric median (Pillutla et al., 2019). It can
also be straightforWardly combined With approaches to improve communication-efficiency, such as
dynamic averaging (Kamp et al., 2018), and model quantization (Reisizadeh et al., 2020b).
3	Preliminaries
We assume iterative learning algorithms (cf. Chp. 2.1.4 Kamp, 2019) A : X × Y × H → H that
update a model h ∈ H using a dataset D ⊂ X × Y from an input space X and output space Y, i.e.,
ht+1 = A(D, ht). Given a set of m ∈ N clients With local datasets D1 , . . . , Dm ⊂ X × Y draWn
2
Under review as a conference paper at ICLR 2022
iid from a data distribution D and a loss function ` : Y × Y → R, the goal is to find a single model
h ∈ H that minimizes the risk
ε(h) = E(x,y)~D h'(h(x),y)i .	(1)
In centralized learning, the datasets are pooled as D = Si∈[m] Di and A is applied to D until
convergence. Note that applying A on D can be the application to any random subset, e.g., as in
mini-batch training, and convergence is measured in terms of low training loss, small gradient, or
small deviation from previous iterate. In standard federated learning (McMahan et al., 2017), A
is applied in parallel for b ∈ N rounds on each client locally to produce local models h1, . . . , hm.
These models are then centralized and aggregated using an aggregation operator agg : Hm → H,
i.e., h = agg(hι,..., hm). The aggregated model h is then redistributed to local clients which
perform another b rounds of training using h as a starting point. This is iterated until convergence
of h. In the following section, We describe FedDC.
4	Method
We propose federated daisy chaining as an extension to federated learning and hence assume a setup
where we have m clients and one designated coordinator node.1 We provide pseudocode of our
approach as Algorithm 1.
The client Each client trains its local model in each round on local data (line 4), and sends its
model to the coordinator every b rounds for aggregation, where b is the aggregation period, and
every d rounds for daisy chaining, where d is the daisy-chaining period (line 6). This re-distribution
of models results in each individual model following a daisy-chain of clients, training on each local
dataset. Such a daisy-chain is interrupted by each aggregation round.
The coordinator Upon receiving models (line 10), in a daisy-chaining round (line 11) the coor-
dinator draws a random permutation π of clients (line 12) and re-distributes the model of client i to
client π(i) (line 13), while in an aggregation round (line 15), the coordinator instead aggregates all
local models (line 16) and re-distributes the aggregate to all clients (line 17).
Communication complexity Communication between clients and coordinator happens in
O( tmdax + tmbax) rounds, where tmax is the overall number of rounds. Although inherently higher
than in plain federated learning, the overall amount of communication in daisy chained federated
learning is still low. In particular, in each communication round, each client sends and receives only
a single model from the coordinator. The amount of communication per communication round is
thus linear in the number of clients and model size, similar to federated averaging.
In the following section we show that the additional daisy-chaining rounds ensure convergence for
small datasets in terms of PAC-like , δ-guarantees.
5	Theory
Next, we theoretically analyze the key properties of FedDC in terms of PAC-like (, δ)-guarantees.
For that, we make the following assumption on the learning algorithm A.
Assumption 1 ((, δ)-guarantees). The learning algorithm A applied on all datasets drawn iid from
D of size n ≥ n0 ∈ N produces a model h ∈ H such that with probability δ ∈ (0, 1] it holds for
> 0 that
P (ε(h) > ) < δ .
The sample size n0 is a monotone function in δ and , i.e., for fixed n0 is monotonically increasing
with δ and for fixed δ it is monotonically decreasing with (note that typically n0 is a polynomial in
-1 and log(δ-1)).
1This star-topology can be extended to hierarchical networks in a straight-forward manner. Federated learn-
ing can also be performed in a decentralized network via gossip algorithms (Jelasity et al., 2005)
3
Under review as a conference paper at ICLR 2022
Algorithm 1 Federated Daisy-Chaining FedDC
Require: daisy-chaining period d, aggregation period b, learning algorithm A, aggregation operator
agg, m clients with local datasets D1 , . . . , Dm
1:	initialize local models h10 , . . . , h0m
2:	at local client i in round t
3:	draw random set of samples S from local dataset Di
4： h -A(s,hi-ι)
5:	if t % d = d - 1 or t % b = b - 1 then
6：	send hit to coordinator
7： end if
8：
9： at coordinator in round t
10： receive models ht1, . . . , htm
11： if t % d = d - 1 then
12：	draw permutation π of [1,m] at random
13：	for all i ∈ [m] send model hit to client π(i)
14： end if
15:	if t % b = b 一 1 then
16：	ht —_agg(h1,...,hm)
17：	send ht to all clients
18:	end if
19：
Here ε(h) is the risk defined in Equation 1. We will show that aggregation for small local datasets
can diverge and that daisy-chaining can prevent this. For this, we analyze the development of (, δ)-
guarantees on model quality when aggregating local models with and without daisy-chaining.
It is an open question how such an (, δ)-guarantee develops when averaging local models. Existing
work analyzes convergence (Haddadpour and Mahdavi, 2019; Kamp et al., 2018) or regret (Kamp
et al., 2014) and thus gives no generalization bound. Recent work on generalization bounds for fed-
erated averaging via the NTK-framework (Huang et al., 2021) is promising, but not directly com-
patible with daisy-chaining： the analysis of Huang et al. (2021) requires local datasets to be disjoint
which would be violated by a daisy-chaining round. Using the Radon point (Radon, 1921) as aggre-
gation operator, however, does permit analyzing the development of (, δ)-guarantees. In particular,
it was shown that for fixed the probability of bad models is reduced doubly exponentially (Kamp
et al., 2017) when we aggregate models using the (iterated) Radon point (Clarkson et al., 1996).
Here, a Radon point of a set of points S from a space X is—similar to the geometric median—a
point in the convex hull of S with a high centrality (more precisely, a Tukey depth (Tukey, 1975;
Gilad-Bachrach et al., 2004) of at least 2). For a Radon point to exist, the size of S has to be suf-
ficiently large; the minimum size of S ⊂ X is denoted the Radon number of the space X and for
X ⊆ Rd the radon number is d + 2.
Let r ∈ N be the Radon number of H, A be a learning algorithm as in assumption 1, and ε be
convex. Assume m ≥ rh many clients with h ∈ N. For > 0, δ ∈ (0, 1] assume local datasets
D1, . . . , Dm of size larger than n0(, δ) drawn iid from D, and h1, . . . , hm be local models trained
on them using A. Let rh be the iterated Radon point with h iterations computed on the local models.
Then it follows from Theorem 3 in Kamp et al. (2017) that for all i ∈ [m] it holds that
P (ε(rh) > ) ≤ (rP (ε(hi) > ))2h	(2)
where the probability is over the random draws of local datasets. This implies that the iterated Radon
point only improves over the local models if δ < r-1. Consequently, local models need to achieve
a minimum quality for the federated learning system to converge.
Corollary 2. Given a model space H with Radon number r ∈ N, convex risk ε, and a learning
algorithm A with sample size n(, δ). Given > 0 and any h ∈ N, if local datasets D1, . . . , Dm
with m ≥ rh are smaller than n0(, r-1), then federated learning using the Radon point does not
improve model quality in terms of (, δ)-guarantees.
4
Under review as a conference paper at ICLR 2022
198765
..................
00000
ycarucca
'OOg
00
00
00
001
0
00
00
00
00
001
0
rounds
rounds
(a) FedDC with d = 1, b = 10.
(b) Federated learning with Radon point with b = 10.
Figure 1: Results on SUSY. We visualize results in terms of train (green) and test error (orange) for
FedDC (a) and federated learning (b), both using Radon points for aggregation. The network has
441 clients with 2 data points per client. ”Optimal performance, i.e., that of a central model trained
on all data, is indicated by dashed line.
In other words, when using aggregation by Radon points alone, an improvement in terms of (, δ)-
guarantees is strongly dependent on large enough local datasets. Furthermore, given δ > r-1, the
guarantee can become arbitrarily bad by increasing the number of aggregation rounds.
Federated Daisy-Chaining as given in Algo. 1 permutes local models at random, which is in theory
equivalent to permuting local datasets. This way, the amount of data visible to each model is in-
creased. Since the permutation is drawn at random, the minimum amount of distinct local samples
observed by each model can be given with high probability.
Lemma 3. Given δ ∈ (0, 1], m ∈ N clients, and k ∈ [m], if Algorithm 1 with daisy chaining period
d ∈ N is run for T ∈ N rounds with
T≥d
ln δ
ln (m-1) (m — k + 1)m
then each local model has seen at least k distinct datasets with probability 1 - δ.
Proof. For m clients with m local datasets, the chance of a client i to not see dataset j after τ many
permutations is (m-1)τ. The probability that each of the m clients is not seeing m — k + 1 other
datasets is hence
mYk+1 f m — 1 Y _ f m — 1 Y(m-k+1)
j=ι ImJ ImJ
and corresponds to the probability of each client seeing less than k distinct other datasets. The
probability of all clients seeing at least k distinct datasets is hence at least
1—
≥ 1 — δ ⇔
≤δ.
Taking the logarithm on both sides with base (m — 1)/m < 1 yields
τ(m — k+ 1)m ≥
lnδ
ln m-1
m
Multiplying with m — k + 1 and observing that τ many daisy-chaining rounds with period d require
T = Td total rounds yields the result.	□
From Lm. 3 it follows that when we perform daisy-chaining with m clients, and local datasets of
size n, for at least dln δ((ln(m — 1) — ln(m))(m — k + 1)m)-1 rounds, each local model will with
probability at least 1 — δ be trained on at least kn samples.
5
Under review as a conference paper at ICLR 2022
Proposition 4. Given a model space H with Radon number r ∈ N, convex risk ε, and a learning
algorithm A with sample size n(, δ). Given > 0, δ ∈ (0, r-1) and any h ∈ N, if local datasets
D1, . . . , Dm of size n ∈ N with m ≥ rh, then Alg. 1 using the Radon point with
b≥d
ln
lnδ
n0(3δ)
n
+1
m
improves model quality in terms of (, δ)-guarantees.
Proof. The number of daisy-chaining rounds before computing a Radon point ensure that with prob-
ability 1 - δ all local models are trained on at least kn samples with k = no (e, δ)∕n, i.e., each model
is trained on at least n0 (, δ) samples and thus an (, δ)-guarantee holds for each model. Since
δ < r-1, this guarantee is improved as detailed in Eq.(2).	□
To support this theoretical result, we compare FedDC using the iterated Radon point with standard
federated learning on the SUSY binary classification dataset (Baldi et al., 2014), training a linear
model on 441 clients with only 2 samples per client. The results in Figure 1 show that after 500
rounds FedD C reached the test accuracy of a model that has been trained on the centralized dataset
(ACC=0.77) beating federated learning by a large margin (ACC=0.65). Before further investigating
FedDC empirically in Section 7, we discuss the privacy-aspects of FedDC in the following section.
6 Privacy
A major benefit of federated learning is
that data remains undisclosed on the lo-
cal clients and only model parameters
are exchanged. It is, however, possible
to infer upon local data given model pa-
rameters (Ma et al., 2020). In classical
federated learning there are two types of
attacks that would allow such inference:
(i) an attacker intercepting the commu-
nication of a client with the coordinator
obtaining model updates to infer upon
the clients data, and (ii) a malicious co-
ordinator obtaining models to infer upon
the data of each client. A malicious
client cannot learn about other clients
data, since it only obtains the average
of all local models. In federated daisy-
chaining there is a third possible attack:
(iii) a malicious client obtaining model
updates from another client to infer upon its data.
In the following, we discuss potential defenses against these three types of attacks in more detail.
Note that we limit the discussion on attacks that aim at inferring upon local data, thus breaching data
privacy. For a discussion of attacks that aim to poison the learning process (Bhagoji et al., 2019) or
create backdoors (Sun et al., 2019) for adversarial examples, we refer to Lyu et al. (2020).
A general and wide-spread approach to tackle all three possible attack types is to add noise to
the model parameters before sending. Using appropriate clipping and noise, this guarantees e, δ-
differential privacy for local data (Wei et al., 2020) at the cost of a slight-to-moderate loss in model
quality.
Another approach to tackle an attack on communication (i) is to use encrypted communication. One
can also protect against a malicious coordinator (ii) by using homomorphic encryption that allows
the coordinator to average models without decrypting them (Zhang et al., 2020). This, however, only
works for particular aggregation operators and does not allow to perform daisy-chaining. Secure
daisy-chaining in the presence of a malicious coordinator (ii) can, however, be performed using
0.8
0
0.6
0.4
0.2
/I- FEDDC
DP-FEDDC (S =2,σ = 0.01)
一一 DP-FedDC (S = 2,σ = 0.02)
--DP-FedDC (S = 4,σ = 0.05)
0
5 ∙ 104	10 ∙ 104	15 ∙ 104	20 ∙ 104
rounds
Figure 2: Differential privacy results. We show the per-
formance of FedDC (top solid line) compared to runs
with clipped parameter updates and added Gaussian noise
(dashed lines) on CIFAR10 with 250 clients.
6
Under review as a conference paper at ICLR 2022
1
0.8
0.6
0.4
0.2
864
...
000
ycarucca
0」	—train - test	0 -
'Ooo
008
006
004
002
0
000,
008
006
004
002
0
rounds
rounds
(a) FEDDC with d = 1, b = 10.	(b) Federated learning with Radon point with b = 10.
Figure 3: Synthetic data results. Comparison of FEDDC (left) and FedAvg (right) for training MLPs
on a synthetic dataset. Mean and confidence test accuracy of each client is reported in orange, where
the optimal reachable accuracy, as given by centralized training, is indicated by the dashed black
line.
asymmetric encryption. Assume each client creates a public-private key pair and shares the public
key with the coordinator. To avoid the malicious coordinator to send clients its own public key
and act as a man in the middle, public keys have to be announced (e.g., by broadcast). While this
allows sending clients to identify the recipient of their model, no receiving client can identify the
sender. Thus, inference on the origin of a model remains impossible. For a daisy-chaining round
the coordinator sends the public key of the receiving client to the sending client, the sending client
checks the validity of the key and sends an encrypted model to the coordinator which forwards it
to the receiving client. Since only the receiving client can decrypt the model, the communication is
secure.
In standard federated learning, a malicious client cannot infer upon the data of other clients from
model updates, since it only receives the average model. In federated daisy-chaining, it receives
the model from a random, unknown client in each daisy-chaining round. Now, the malicious client
can infer upon the membership of a particular data point in the local dataset of the client the model
originated from, i.e., a membership inference attack (Shokri et al., 2017). Similarly, the malicious
client can infer upon the presence of data points with certain attributes in the dataset (Ateniese
et al., 2015). The malicious client, however, does not know the client the model was trained on,
i.e., it does not know the origin of the dataset. Using a random scheduling of daisy-chaining and
averaging rounds at the coordinator, the malicious client cannot even distinguish between a model
from another client or the average of all models. Nonetheless, daisy-chaining opens up new potential
attack vectors (e.g., by clustering received models to potentially determine their origins). These
potential attack vectors can be tackled by adding noise to model parameters as discussed above,
since “[d]ifferentially private models are, by construction, secure against membership inference
attacks” (Shokri et al., 2017). To investigate the impact of this privacy technique on FedDC, we
apply it in practice: We train a small ResNet on 250 clients using FedDC with d = 2 and b = 10.
Details on the experimental setup can be found in Supp. ??,??. Differential privacy is achieved by
clipping local model updates and adding Gaussian noise as proposed by Geyer et al. (2017). The
results shown in Figure 2 indicate that the standard trade-off between model quality and privacy
holds for FedDC as well. Moreover, for mild privacy settings the model quality does not decrease.
That is, FedDC is able to robustly predict even under differential privacy.
7	Empirical Evaluation
We evaluate FedDC against the state-of-the-art in federated learning on synthetic and real world
data. In particular, we compare to standard Federated averaging (FedAvg) (McMahan et al., 2017),
FedAvg with equal communication as FedDC, FedProx (Li et al., 2020a), and simple daisy-chaining
without aggregation. As real world applications we consider the image classification problem CI-
FAR10 (Krizhevsky, 2009), publicly available MRI scans for brain tumors2, and chest X-rays for
2https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection
7
Under review as a conference paper at ICLR 2022
pneumonia (e.g., from COVID-19)3. For reproducibility, we provide details on architectures, and
experimental setup in Supp. ??,??. The implementation of the experiments is publicly available
at https://anonymous.4open.science/r/FedDC-1BC9.
7.1	Synthetic Data
We first investigate the potential of FedDC on a synthetic binary classification dataset generated
by the sklearn (Pedregosa et al., 2011) make_classification function with 100 features. On
this dataset, we train a simple MLP with 3 hidden layers on m = 50 clients with n = 10 samples
per client. We compare FedDC with d = 1 and b = 200 to FedAvg with b = 200. The results
presented in Figure 3 show that FedDC achieves an optimal test performance of 0.89 (centralized
training on all data achieves a test accuracy of 0.88), substantially outperforming FedAvg. The
results indicate that the main reason is overfitting of local clients, since for FedAvg train accuracy
reaches 1.0 quickly after each averaging step. In the following, we investigate how these promising
results translate to real-world datasets.
7.2	CIFAR 1 0
To compare FedDC with the state of the art
on real world data, we first consider the CI-
FAR10 image benchmark. To find a suitable
aggregation period b for FedDC and FedAvg,
we first run a search grid across periods for 250
clients with small versions of ResNet (details
in Supp. ??). We report the results in Figure 4
and set the period for FedDC to 10, and con-
sider federated averaging with periods of both
1 and 10. For our next experiment, we equip
150 clients each with a ResNet18. To simulate
0.8
.6 .4 .2
000
ycaruccA
FEDDC	FedAvg
1	10	20	50	100 200 500 ∞
Averaging period b








our setting that each client has a small amount
of samples, each one of them only receives 64
samples. Note that the combined amount of ex-
amples is only one fifth of the original training
data, hence we cannot expect the typical perfor-
mance on this dataset. As NNs are non-convex,
Radon points are no longer suitable as aggre-
gation method, we instead resort to averaging.
Figure 4: Averaging periods on CIFAR10. For
250 clients with small ResNets and 64 samples
per client, we visualize the performance (higher
is better) of FedDC and FedAvg for different ag-
gregation periods b.
Results are reported in Table 1. We observe that
FedDC achieves substantially higher accuracy of more than 6 percentage points over federated av-
eraging with the same amount of communication. Looking closer, we see that FedAvg drastically
overfits, achieving training accuracies of 0.97, a similar trends as reported in Figure 3 for synthetic
data. We further see that daisy-chaining alone, besides its privacy issues, performs worse than
FedDC. Similarly, FedProx run with b = 10 and μ = 0.1 only achieves an accuracy of 0.545.
dataset	FedDC	Daisy-Chaining	FedAVg(b=10)	FedAVg(b=1)	FedProx
-CIFAR10	62.8	592	510	563	-545-
MRI	78.4	57.7	75.6	74.1	76.5
Pneumonia	82.5	78.8	79.0	79.9	80.0
Table 1: Results on image data, reported are test accuracies of final model.
7.3	Medical image data
We conduct experiments on real medical image data, which are naturally of small sample size and
represent actual health related machine learning tasks. Here, we observe similar trends as for CI-
FAR10. For the brain MRI scans, we simulate 25 clients equipped with simple CNNs (see App.
??) and 8 samples each. The results for brain tumor prediction based on these scans are reported in
3https://www.kaggle.com/praveengovi/coronahack-chest-xraydataset
8
Under review as a conference paper at ICLR 2022
Table 1. Again, FedDC performs best, beating both FedAvg and FedProx on this challenging tasks.
For pneumonia, we simulate 150 clients training ResNet18 (see again App. ??) with 8 samples per
client. The results in Table 1 not only show that FedDC again outperforms all baselines, but also
highlight that FedDC enables us to train a ResNet18 to high accuracy with as little as 8 samples per
client.
8	Discussion
Empirical evaluation shows that FedDC drastically improves upon state-of-the-art methods for fed-
erated learning for settings with only small amounts of available data. This confirms the theoretical
potential, given by the , δ-guarantees, of improving model quality, which is unique among federated
learning methods.
Using the iterated Radon point as aggregation method, and given as few as 2 samples per client,
FedDC matches the test accuracy of a model trained on the whole SUSY dataset, outperforming
standard federated learning by over 12% points of accuracy. This result shows that unlike federated
learning, FedDC does not heavily overfit and is able to learn a generalized model, and is consistent
with a synthetic prediction task using multi-layer perceptrons.
To study FedDC in the context of real data, we consider both the standard image benchmark data
CIFAR10, as well as two challenging image classification tasks from the health domain where only
little data is available. On each of these tasks, FedDC consistently outperforms state-of-the-art
federate learning methods. Similar to before, we observe overfitting of standard federate learning
methods. To rule out any effects due to increased communication, we also considered FedAvg with
the same amount of communication as our method, however, FedAvg shows no improvement.
Through FedDC, we present an effective solution to the problem of federated learning on small
datasets. We further show that our method is able to robustly predict even under the effect of differ-
ential privacy, and suggest effective measures based on encryption as mitigations against attacks on
communication or malicious coordinators.
9	Conclusion
We considered the problem of learning high quality models in settings where data is inherently
distributed across sites, data cannot be shared between sites, and each site only has very little data
available. We propose an elegant, surprisingly simple approach that effectively solves this problem,
by combining the idea of model aggregation approaches from federated learning with the concept of
passing individual models around while still maintaining privacy.
We showed that this approach theoretically improves models in terms of , δ-guarantees, which
state-of-the-art federated averaging can not provide. In extensive empirical evaluations, including
challenging image classification tasks from the health domain, we further show that for settings with
limited data available per site, our method improves upon existing work by a wide margin. It thus
paves the way for learning high quality models from small datasets.
Although the amount of communication is not a critical issue for the settings where we intend
FedDC to be used in, it does make for engaging future work to improve its communication effi-
ciency and hence also enable it for settings with limited bandwidth, e.g., regarding model training on
mobile devices. Both from a practical, as well as from a security and privacy perspective, it would
also be interesting to study how to formulate FedDC in a decentralized setting, when no coordinator
is available.
9
Under review as a conference paper at ICLR 2022
References
Giuseppe Ateniese, Luigi V Mancini, Angelo Spognardi, Antonio Villani, Domenico Vitali, and
Giovanni Felici. Hacking smart machines with smarter ones: How to extract meaningful data
from machine learning classifiers. International Journal of Security and Networks, 10(3):137-
150, 2015.
Pierre Baldi, Peter Sadowski, and Daniel Whiteson. Searching for exotic particles in high-energy
physics with deep learning. Nature communications, 5(1):1-9, 2014.
Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin Calo. Analyzing federated
learning through an adversarial lens. In International Conference on Machine Learning, pages
634-643. PMLR, 2019.
Kenneth L Clarkson, David Eppstein, Gary L Miller, Carl Sturtivant, and Shang-Hua Teng. Ap-
proximating center points with iterative radon points. International Journal of Computational
Geometry & Applications, 6(03):357-377, 1996.
Robin C Geyer, Tassilo Klein, and Moin Nabi. Differentially private federated learning: A client
level perspective. arXiv preprint arXiv:1712.07557, 2017.
Ran Gilad-Bachrach, Amir Navot, and Naftali Tishby. Bayes and tukey meet at the center point. In
International Conference on Computational Learning Theory, pages 549-563. Springer, 2004.
Kristin L Granlund, Sui-Seng Tee, Hebert A Vargas, Serge K Lyashchenko, Ed Reznik, Samson
Fine, Vincent Laudone, James A Eastham, Karim A Touijer, Victor E Reuter, et al. Hyperpolar-
ized mri of human prostate cancer reveals increased lactate with tumor grade driven by monocar-
boxylate transporter 1. Cell metabolism, 31(1):105-114, 2020.
Farzin Haddadpour and Mehrdad Mahdavi. On the convergence of local descent methods in feder-
ated learning. arXiv preprint arXiv:1910.14425, 2019.
Baihe Huang, Xiaoxiao Li, Zhao Song, and Xin Yang. Fl-ntk: A neural tangent kernel-based frame-
work for federated learning analysis. In International Conference on Machine Learning, pages
4423-4434. PMLR, 2021.
Marwa Ibrahim, Mohammad Wedyan, Ryan Alturki, Muazzam A Khan, and Adel Al-Jumaily. Aug-
mentation in healthcare: Augmented biosignal using deep learning and tensor representation.
Journal of Healthcare Engineering, 2021, 2021.
Mark Jelasity, Alberto Montresor, and OzalP Babaoglu. Gossip-based aggregation in large dynamic
networks. ACM Transactions on Computer Systems (TOCS), 23(3):219-252, 2005.
Michael Kamp. Black-Box Parallelization for Machine Learning. PhD thesis, Rheinische Friedrich-
Wilhelms-Universitat Bonn, UniverSitatS-Und Landesbibliothek Bonn, 2019.
Michael Kamp, Mario Boley, Daniel Keren, Assaf Schuster, and Izchak Sharfman. Communication-
efficient distributed online prediction by dynamic model synchronization. In Joint European Con-
ference on Machine Learning and Knowledge Discovery in Databases, pages 623-639. Springer,
2014.
Michael Kamp, Mario Boley, Olana Missura, and Thomas Gartner. Effective parallelisation for
machine learning. In Advances in Neural Information Processing Systems, volume 30, pages
6480-6491, 2017.
Michael Kamp, Linara Adilova, Joachim Sicking, Fabian Huger, Peter Schlicht, Tim Wirtz, and
Stefan Wrobel. Efficient decentralized deep learning by dynamic model averaging. In Joint
European Conference on Machine Learning and Knowledge Discovery in Databases, pages 393-
409. Springer, 2018.
Bingyi Kang, Zhuang Liu, Xin Wang, Fisher Yu, Jiashi Feng, and Trevor Darrell. Few-shot object
detection via feature reweighting. In Proceedings of the IEEE/CVF International Conference on
Computer Vision, pages 8420-8429, 2019.
10
Under review as a conference paper at ICLR 2022
Peter Kiss and Tomas Horvath. Migrating models: A decentralized view on federated learning. In
Proceedings of the Workshop on Parallel, Distributed, and Federated Learning. Springer, 2021.
Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University
of Toronto, Toronto, 2009.
Sang Gyu Kwak and Jong Hae Kim. Central limit theorem: the cornerstone of modern statistics.
Korean journal of anesthesiology, 70(2):144, 2017.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated optimization in heterogeneous networks. In Conference on Machine Learning and
Systems, 2020a, 2020a.
Xiaoxiao Li, Meirui Jiang, Xiaofei Zhang, Michael Kamp, and Qi Dou. Fedbn: Federated learn-
ing on non-iid features via local batch normalization. In International Conference on Learning
Representations, 2020b.
Pei Liu, Xuemin Wang, Chao Xiang, and Weiye Meng. A survey of text data augmentation. In 2020
International Conference on Computer Communication and Network Security (CCNS), pages
191-195.IEEE, 2020.
Lingjuan Lyu, Han Yu, Jun Zhao, and Qiang Yang. Threats to Federated Learning, pages 3-16.
Springer International Publishing, 2020. ISBN 978-3-030-63076-8.
Chuan Ma, Jun Li, Ming Ding, Howard H Yang, Feng Shu, Tony QS Quek, and H Vincent Poor. On
safeguarding privacy and security in the framework of federated learning. IEEE network, 34(4):
242-248, 2020.
Othmane Marfoq, Giovanni Neglia, AUrelien Bellet, Laetitia Kameni, and Richard Vidal. Feder-
ated multi-task learning under a mixture of distributions. In Advances in Neural Information
Processing Systems. Curran Associates, Inc., 2021.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial Intelli-
gence and Statistics, pages 1273-1282, 2017.
Corrie A Painter, Esha Jain, Brett N Tomson, Michael Dunphy, Rachel E Stoddard, Beena S Thomas,
Alyssa L Damon, Shahrayz Shah, Dewey Kim, Jorge Gomez Tejeda Zanudo, et al. The angiosar-
coma project: enabling genomic and clinical discoveries in a rare cancer through patient-partnered
research. Nature medicine, 26(2):181-187, 2020.
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Pretten-
hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research,
12:2825-2830, 2011.
Krishna Pillutla, Sham M Kakade, and Zaid Harchaoui. Robust aggregation for federated learning.
arXiv preprint arXiv:1912.13445, 2019.
Viraj Prabhu, Anitha Kannan, Murali Ravuri, Manish Chaplain, David Sontag, and Xavier Amatri-
ain. Few-shot learning for dermatological disease diagnosis. In Machine Learning for Healthcare
Conference, pages 532-552. PMLR, 2019.
Johann Radon. Mengen konvexer Korper, die einen gemeinsamen Punkt enthalten. Mathematische
Annalen, 83(1):113-115, 1921.
KM Jawadur Rahman, Faisal Ahmed, Nazma Akhter, Mohammad Hasan, Ruhul Amin, Kazi Ehsan
Aziz, AKM Muzahidul Islam, Md Saddam Hossain Mukta, and AKM Najmul Islam. Challenges,
applications and design aspects of federated learning: A survey. IEEE Access, 2021.
Amirhossein Reisizadeh, Farzan Farnia, Ramtin Pedarsani, and Ali Jadbabaie. Robust federated
learning: The case of affine distribution shifts. In Advances in Neural Information Processing
Systems, volume 33, pages 21554-21565. Curran Associates, Inc., 2020a.
11
Under review as a conference paper at ICLR 2022
Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jadbabaie, and Ramtin Pedarsani.
Fedpaq: A communication-efficient federated learning method with periodic averaging and quan-
tization. In International Conference on Artificial Intelligence and Statistics, pages 2021-2031.
PMLR, 2020b.
Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, Holger R Roth, Shadi Albarqouni, Spyri-
don Bakas, Mathieu N Galtier, Bennett A Landman, Klaus Maier-Hein, et al. The future of digital
health with federated learning. NPJ digital medicine, 3(1):1-7, 2020.
Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. Membership inference at-
tacks against machine learning models. In 2017 IEEE Symposium on Security and Privacy (SP),
pages 3-18. IEEE, 2017.
Xiaoping Su, Xiaofan Lu, Sehrish Khan Bazai, Eva ComPerat, Roger Mouawad, HUi Yao, Morgan
Roupret, Jean-Philippe Spano, David Khayat, Irwin Davidson, et al. Comprehensive integrative
profiling of upper tract urothelial carcinomas. Genome biology, 22(1):1-25, 2021.
Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, and H Brendan McMahan. Can you really
backdoor federated learning? arXiv preprint arXiv:1911.07963, 2019.
Lisa Torrey and Jude Shavlik. Transfer learning. In Handbook of research on machine learning
applications and trends: algorithms, methods, and techniques, pages 242-264. IGI global, 2010.
John W Tukey. Mathematics and picturing data. In Proceedings of the International Congress of
Mathematics, volume 2, pages 523-531, 1975.
Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. Matching networks for one
shot learning. Advances in neural information processing systems, 29:3630-3638, 2016.
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and Yasaman Khazaeni.
Federated learning with matched averaging. In International Conference on Learning Represen-
tations, 2019.
Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H Yang, Farhad Farokhi, Shi Jin, Tony QS Quek,
and H Vincent Poor. Federated learning with differential privacy: Algorithms and performance
analysis. IEEE Transactions on Information Forensics and Security, 15:3454-3469, 2020.
Qian Yang, Jianyi Zhang, Weituo Hao, Gregory P. Spell, and Lawrence Carin. Flop: Federated
learning on medical datasets using partial networks. In Proceedings of the 27th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining, page 3845-3853. Association for Com-
puting Machinery, 2021.
Chengliang Zhang, Suyi Li, Junzhe Xia, Wei Wang, Feng Yan, and Yang Liu. Batchcrypt: Effi-
cient homomorphic encryption for cross-silo federated learning. In USENIX Annual Technical
Conference, pages 493-506, 2020.
12