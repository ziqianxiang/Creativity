Under review as a conference paper at ICLR 2022
Semi-supervised learning objectives as
log-likelihoods in a generative model of data
CURATION
Anonymous authors
Paper under double-blind review
Ab stract
We currently do not have an understanding of semi-supervised learning (SSL)
objectives such as pseudo-labelling and entropy minimization as log-likelihoods,
which precludes the development of e.g. Bayesian SSL. Here, we note that bench-
mark image datasets such as CIFAR-10 are carefully curated, and we formu-
late SSL objectives as a log-likelihood in a generative model of data curation
that was initially developed to explain the cold-posterior effect (Aitchison 2020).
SSL methods, from entropy minimization and pseudo-labelling, to state-of-the-art
techniques similar to FixMatch can be understood as lower-bounds on our prin-
cipled log-likelihood. We are thus able to give a proof-of-principle for Bayesian
SSL on toy data. Finally, our theory suggests that SSL is effective in part due
to the statistical patterns induced by data curation. This provides an explanation
of past results which show SSL performs better on clean datasets without any
“out of distribution” examples. Confirming these results we find that SSL gave
much larger performance improvements on curated than on uncurated data, using
matched curated and uncurated datasets based on Galaxy Zoo 2.1
1 Introduction
To build high-performing deep learning models for industrial and medical applications, it is neces-
sary to train on large human-labelled datasets. For instance, Imagenet (Deng et al., 2009), a classic
benchmark dataset for object recognition, contains over 1 million labelled examples. Unfortunately,
human labelling is often prohibitively expensive. In contrast obtaining unlabelled data is usually
very straightforward. For instance, unlabelled image data can be obtained in almost unlimited vol-
umes from the internet. Semi-supervised learning (SSL) attempts to leverage this unlabelled data to
reduce the required number of human labels (Seeger, 2000; Zhu, 2005; Chapelle et al., 2006; Zhu
& Goldberg, 2009; Van Engelen & Hoos, 2020). One family of SSL methods — those based on
low-density separation — assume that decision boundaries lie in regions of low probability density,
far from all labelled and unlabelled points. To achieve this, pre deep learning (DL) low-density
separation SSL methods such as entropy minimization and pseudo-labelling (Grandvalet & Bengio,
2005; Lee, 2013) use objectives that repel decision boundaries away from unlabelled points by en-
couraging the network to make more certain predictions on those points. Entropy minimization (as
the name suggests) minimizes the predictive entropy, whereas pseudo-labelling treats the currently
most-probable label as a pseudo-label, and minimizes the cross entropy to that pseudo-label. More
modern work uses the notion of consistency regularisation, which augments the unlabelled data (e.g.
using translations and rotations), then encourages the neural network to produce similar outputs for
different augmentations of the same underlying image (Sajjadi et al., 2016; Xie et al., 2019; Berth-
elot et al., 2019b; Sohn et al., 2020). Further developments of this line of work have resulted in
many variants/combinations of these algorithms, from directly encouraging the smoothness of the
classifier outputs around unlabelled datapoints (Miyato et al., 2018) to the “FixMatch” family of
algorithms (Berthelot et al., 2019b;a; Sohn et al., 2020), which combine pseudo-labelling and con-
sistency regularisation by augmenting each image twice, and using one of the augmented images to
provide a pseudo-label for the other augmentation.
1Our code: https://anonymous.4open.science/r/GZ_SSL-B6CC; MIT Licensed
1
Under review as a conference paper at ICLR 2022
Y1 = Y2 = Y3 = train
Y = train
Y1 = Y2 = Y3 = bus
Y = bus
Y1 = Y2 = train;	Y3 = bus
Y = None
Figure 1:	A depiction of the generative model of data curation, with S = 3. Annotators are in-
structed to classify images as trains or buses. The left-hand image is clearly a train, so the annotators
agree and consensus is reached. The middle image is clearly a bus, so annotators agree and consen-
sus is reached. The right-hand image, however, is ambiguous or even has an ill-defined class label.
So annotators disagree, consensus is not reached and the image is excluded from the dataset.
A X^^ B X C X、	D X
KUP	{YS}S=1 一 Y	{YS}S=1 一 C
—	L	L
θ	θθ	θ
Figure 2:	GraPhical models under consideration. The observed variables are highlighted in red. A
The generative model for standard suPervised learning with no data curation. Note that the label,
YsuP ∈ Y , only takes on values in the label set, so it differs from our label, Y , which could also
be None. B The generative model for standard suPervised learning, omitting the label. Under this
model P (θ∣X) reduces to P (θ) (see Sec. 2.3). C The generative model with data curation for
labelled Points, note that if there is consensus, Y ∈ Y and if there is no consensus, Y = None. D
The generative model with data curation for unlabelled Points. C is a random variable rePresenting
whether or not consensus was reached, so we have C = 1 if consensus was reached (i.e. Y ∈ Y)
and C = 0 if consensus was not reached (i.e. Y = None). Critically, C acts as a “label”, so
the posterior over parameters, P (θ∣X, C), does not reduce to P (θ), unlike in the case of standard
suPervised learning when we omit the label (Panel B).
However, some of the biggest successes of deep learning, from supervised learning to many gen-
erative models, have been built on a principled statistical framework as maximum (marginal) like-
lihood inference (e.g. the cross-entropy objective in supervised learning can be understood as the
log-likelihood for a Categorical-softmax model of the class-label MacKay, 2003). Low-density sep-
aration SSL methods such as pseudo-labelling and entropy minimization are designed primarily to
encourage the class-boundary to lie in low-density regions. Therefore they cannot be understood
as log-likelihoods and cannot be combined with principled statistical methods such as Bayesian
inference.
Here, we give a formal account of SSL methods based on low-density separation (Chapelle et al.,
2006) as lower bounds on a principled log-likelihood. In particular, we consider pseudo-labelling
(Lee, 2013), entropy minimization (Grandvalet & Bengio, 2005), and modern methods similar to
FixMatch (Sohn et al., 2020). This log-likelihood arises from a generative model of data curation
that was initially developed to explain the cold-posterior effect (Aitchison, 2021). Critically, this
approach gives an explanation for previous findings that SSL is most effective when unlabelled data
is obtained by throwing away labels from the carefully curated training set, and is less effective
when unlabelled data is taken from uncurated images, especially those that do not depict one of the
classes of interest (Cozman et al., 2003; Oliver et al., 2018; Chen et al., 2020; Guo et al., 2020). We
confirmed the importance of data curation for SSL on toy data generated from a known model and
on real data from Galaxy Zoo 2 (Willett et al., 2013).
2
Under review as a conference paper at ICLR 2022
Figure 3: Our generative model of data curation applied to a simple 2D dataset. Data from each
class was sampled from a different Gaussian, and the true decision boundary (green dashed line)
was given by the posterior probability of class given (x0, x1). A Datapoints far from the decision
boundary are unambiguous, so annotators agree and consensus is reached (red and blue points).
Datapoints close to the decision boundary are ambiguous, so consensus is not reached (grey crosses).
The consensus datapoints thus exhibit artificially induced low-density separation. B When using
benchmark datasets such as CIFAR-10, the unlabelled points (yellow triangles) are selected from
the consensus points (red or blue points) as the noconensus points are not available. The unlabelled
points therefore also exhibit artificially induced low-density separation.
2 Background
Our work brings together many disparate areas. Here, we give an introduction to a generative model
of data curation (Aitchison, 2021) initially developed to explain the cold posterior effect (Wenzel
et al., 2020), pseudo-labelling and entropy minimization (Grandvalet & Bengio, 2005; Lee, 2013),
and the treatment of unlabelled points in the standard supervised learning setup.
2.1 A generative model of data curation
To develop a model of data curation, remember that image datasets including CIFAR-10 and Im-
ageNet are curated to ensure they only contain images whose class-labels are unambiguous. For
instance, in CIFAR-10, annotators were instructed that “It’s worse to include one that shouldn’t be
included than to exclude one.”, and Krizhevsky (2009) “personally verified every label submitted
by the annotators”. In creating ImageNet, Deng et al. (2009) made sure that a number of Amazon
Mechanical Turk annotators agreed upon the class before including an image in the dataset.
Thus, these datasets have two odd properties. First, consensus labels exist only for a subset of im-
ages, e.g. for a white-noise image, consensus cannot be reached and the image cannot be labelled.
Second, inclusion of an image in a dataset like CIFAR-10 is informative in and of itself, as it indi-
cates that the image shows an unambiguous example of one of the ten classes. To understand these
odd properties of curated datasets, consider a simplified generative model of consensus-formation:
draw a random image, X, from the distribution over images, P (X), and ask S human annotators,
indexed s, to give a label, {Ys }sS=1 (e.g. using Mechanical Turk). Importantly, every annotator is
forced to label every image and if the image is ambiguous they should give a random label. If all
the annotators agree, Y1 = Y2 = … =YS, they have consensus and the datapoint is included in the
dataset. However, in the case of any disagreement, consensus is not reached and the datapoint is
excluded (Fig. 1), Concretely, the final label, Y is Y1 (which is the same as all the other labels) if
consensus was reached and None otherwise (Fig. 2C),
Y [{Y }S_ = IYI	if Y1=Y2 =…=YS
s s=1 None otherwise
(1)
Taking Y to be the label set, we have Ys ∈ Y , and the final label, Y , could be any of the underlying
labels in Y, or None if consensus is not reached, so Y ∈ Y ∪ {None}. When consensus was
reached, the likelihood is,
P (Y=y|X,O) = P ({γS =y}S=IX,θ) = QS=IP (Ys =y|X,O) = P (Ys =y|X,O)S = (Py(X))S
(2)
3
Under review as a conference paper at ICLR 2022
where we have assumed annotators are IID, and py(X) = P (Ys =y|X, θ) is the single-annotator
probability. From here, it is possible to see how this model might be taken to give an account of
tempering, as we have taken the underlying single-annotator likelihood, py(X) to the power S (for
further details see Aitchison, 2021).
2.2	Low-density separation semi-supervised learning objectives
The intuition behind low-density separation objectives for semi-supervised learning is that decision
boundaries should be in low-density regions away from both labelled and unlabelled data. As such,
it is sensible to “repel” decision boundaries away from labelled and unlabelled datapoints and this
can be achieved by making the classifier as certain as possible on those points. This happens au-
tomatically for labelled points as the standard supervised objective encourages the classifier to be
as certain as possible about the true class label. But for unlabelled points we need a new objective
that encourages certainty, and we focus on two approaches. First, and perhaps most direct is entropy
minimization (Grandvalet & Bengio, 2005)
Lentropy (X) = X py (X) log py (X)	(3)
y∈Y
where, following the typical probabilistic approach, we write the negative entropy as an objective to
be maximized. Alternatively, we could use pseudo-labelling, which takes the current classification,
y*, to be the true label, and maximizes the log-probability of that label (Lee, 2013),
Lpseudo(X) = logPy* (X)	『=argmaxlogPy(X).	(4)
y∈Y
Lee (2013) regarded pseudo-labelling as closely related to entropy miminization as the optimal
value of both objectives is reached when all the probability mass is assigned to one class. However,
they are not formulated as a principled log-likelihood, which gives rise to at least three problems.
First, these methods cannot be combined with other principled statistical methods such as Bayesian
inference. Second, itis unclear how to combine these objectives with standard supervised objectives,
except by taking a weighted sum and doing hyperparameter optimization over the weight. Third,
these objectives risk reinforcing any initial poor classifications and it is unclear whether this is
desirable.
2.3	In standard supervised learning, unlabelled points should be
UNINFORMATIVE
It is important to note that under the standard supervised-learning generative model (Fig. 2A), unla-
belled points should not give any information about the weights. Omitting the label, Ysup, we obtain
the graphical model in Fig. 2B. This model emphasises that the images, X, and the model param-
eters, θ, are marginally independent, so we cannot obtain any information about θ from X alone
(Fig. 2B). Formally, the posterior over θ conditioned on X is equal to the prior,
PWX) PGX)	∑y∈Y P (θ,x,γsuP=y)	⑸
P (θlX) = Wr =--------------Pw----------	⑸
=P(θ)P (X) Py∈γ P (KUP=y∣θ, X)
=	P(X)	= ( ).
as 1 = y∈yP P (KUP=y∣θ,X). To confirm this result is intuitively sensible, note that are many
situations where encouraging the decision boundary to lie in low density regions would be very
detrimental to performance. Consider a classifier with two input features: x0 and x1 (Fig. 4A). The
class boundary lies in the high-density region crossing both clusters, so to obtain a reasonable re-
sult, the classifier should ignore the low-density region lying between the clusters. However, strong
low-density separation SSL terms in the objective may align the cluster boundaries with the class
boundaries, leading the classifier to wrongly believe that one cluster is entirely one class and the
other cluster is entirely the other class. In contrast, supervised learning without SSL will ignore
clustering and obtain a reasonable answer close to the grey dashed line. Importantly, this is just
an illustrative example to demonstrate that without further assumptions, the standard supervised ap-
proach of ignoring unlabelled data is sensible; semi-supervised learning without loss of performance
in such settings has been studied and is known as Safe SSL (Li & Zhou, 2014; Krijthe & Loog, 2014;
Kawakita & Takeuchi, 2014; Loog, 2015; Krijthe & Loog, 2016).
4
Under review as a conference paper at ICLR 2022
Figure 4: A. A toy dataset generated to illustrate the dangers of using the clustering of the input
points to inform classification boundaries. The input features, x0 and x1 are plotted on the x and y-
axes and the class is represented by colour. B. A schematic diagram demonstrating the effect of our
principled likelihood incorporating data-augmentation on the certainty of predictions for different
degrees of invariance. More invariant NNs (left) give similar predictive distributions for different
augmentations (blue), and hence a certain averaged predictive distribution (bottom; orange). Less
invariant NNs (right) give different predictive distributions for different augmentations (blue), and
hence highly uncertain averaged predictive distributions (bottom; orange).
3 Theory
SSL methods are usually applied to benchmark datasets such as CIFAR-10 or ImageNet. These
datasets were first carefully curated during the labelling process: (Fig. 3A), implying that ambiguous
images close to the decision boundary were excluded. Critically, unlabelled points for these bench-
mark datasets are obtained by taking labelled points (which have reached consensus) and throwing
away their labels (Fig. 3B). The likelihood for consensus (Y 6=None) is
P (Y 6=None|X, θ) = Py∈Y (py (X))S .	(6)
This probability is close to 1 (for S > 1) if the underlying distribution, (py (X))S puts most of its
mass onto one class, and the probability is smaller if the mass is spread out over classes. As such, the
likelihood “repels” decision boundaries away from unlabelled points, which is the common intuition
behind low-density separation SSL methods, and which should be beneficial if class boundaries
indeed lie in regions of low probability density away from both labelled and unlabelled points.
If noconsensus images are observed (Fig. 2C), we can include a likelihood term for those images,
P (Y =None|X, θ) = 1 - P (Y 6= None|X, θ) = 1 - Py∈Y (py(X))S .	(7)
If noconsensus images are not observed, we could in principle integrate over the underlying dis-
tribution over images, P (X =x). However, we do not even have samples from the underlying
distributions over images (and if we did, we would have the noconsensus images so we could use
Eq. 7). As such this term is usually omitted (e.g. Aitchison, 2021), but the use of out-of-distribution
(OOD) datasets as surrogate noconsensus points is an important direction for future work.
3.1	Entropy minimization and pseudo-labels are lower bounds on our
principled log-likelihood
To prove that entropy minimization forms a lower-bound on our log-likelihood (Eq. 6), we begin by
writing the log-likelihood of consensus in terms of an expectation over labels, y,
logP (Y 6=None|X, θ) = log Xpy(X) (py(X))S-1 = log Epy (X) h(py(X))S-1i .	(8)
y∈Y
Applying Jensen’s inequality, the negative entropy gives a lower-bound on our log-likelihood,
log P (Y 6=None|X, θ) ≥Epy(X) hlog (py(X))S-1i
= (S - 1)Py∈Y py(X) logpy(X) = (S - 1)Lentropy (X)	(9)
5
Under review as a conference paper at ICLR 2022
This bound is tight for a uniform predictive distribution,
log P (Y=None∣X,θ) = log Py∈γ (Py (X))S = log S (S)S = (S - 1)log S (10)
(S-1)Lentropy(X) = -(S-1)logPy∈Ypy(X)logpy(X) =(S-1)logS. (11)
Pseudo-labelling forms an alternative lower bound on the log-likelihood which is obtained by noting
that all (py (X))S are positive, so selecting any subset of terms in the sum gives a lower bound,
IogP (Y=None∣X, θ) = logPy∈γ (Py(X))S ≥ log (py* (X))S = SlogPy*(X) = SLpseUdo(X).
(12)
The inequality holds if We choose y* to be any class, but will be tightest if We choose the highest
probability class. This bound is tight for a predictive distribution that puts all its mass on y*, so
Py* (X) = 1 and Py6=y* = 0
logP (Y 6=None|X, θ) = log Py∈Y (Py(X))S = log (Py* (X))S = log1 = 0	(13)
SLpseudo (X) = S logPy(X) = S log 1 = 0.	(14)
As such, entropy minimization and pseudo-labelling optimize different loWer-bounds on our princi-
pled log-likelihood, log P (Y 6=None|X, θ), Which gives a potential explanation for the effectiveness
of pseudo-labelling and entropy minimization. Additionally, loW-density separation SSL objectives
encourages class-labels to be more certain. We can therefore expect pseudo-labelling to be the
more relevant bound, as that bound is tight When the predictive distribution puts all its mass onto
one class. In contrast, the entropy maximization bound is tight When the predictive distribution is
uniform, Which is discouraged by all loW-density separation SSL objectives. This provides a po-
tential explanation for the use of psuedo-labelling rather than entropy regularisation in modern SSL
approaches such as (Sohn et al., 2020).
3.2	Data augmentation priors and FixMatch family methods
FixMatch family methods combine data augmentation and pseudo-labelling. To understand Fix-
Match as a bound on a principled log-likelihood, We therefore need a principled account of data
augmentation as a likelihood. Inspired by Wenzel et al. (2020) (their Appendix K), We consider a
distribution, P (X0|X), over augmented images, X0, given the underlying unaugmented image, X.
We choose the single-annotator predictive distribution as the average over predictive distributions
for many different augmented images,
P (Ys =y|X, θ) = E [Py(X0)|X]	(15)
Where Py(X0) is the predictive probabilities resulting from applying the neural netWork to the aug-
mented image, and remember s ∈ {1, . . . , S} indexes the annotator. This is a sensible prior because
We expect the neural netWork to be invariant under data-augmentation, and if the predictions are
approximately invariant, then averaging the predictive distributions has little impact (Fig. 4B left).
HoWever, if the predictions do vary dramatically With different data augmentations then We should
not trust the netWork’s classifications (i.e. We should have an uncertain predictive distribution), and
averaging over very different predictive distributions for different augmentations indeed gives rise
to broader, more uncertain predictions (Fig. 4B right).
To obtain a tractable objective in the supervised setting, We use a multi-sample version of Jensen’s
inequality, With K augmented images denoted Xk0 ,
logP(YS =y∣X,θ) ≥ E [log k1 PkPy(Xk)IX].	(16)
Combining this single-annotator probability With our generative model of curation, We obtain,
logP(Y=y∣X,θ) = S logP(YS =y∣X,θ)
=S log E [Py (X 0)∣X] ≥ S E [log Kk PkPy (Xk )∣X ],	(17)
The resulting objective for unlabelled points is,
log P (Y 6=None|X, θ) = log Py∈Y P (Y =y|X, θ)
=logPy∈γE [Py(X0)∣X]S ≈ logPy∈γ (k1 PkPy(Xk))S,	(18)
6
Under review as a conference paper at ICLR 2022
A
C
1 23
Ooo
- -一
PoolI==,60-
0	1000
unlabelled points
Poo="=,60-∞2V
0.06-
0.04-
0.02-
0.00-
0	1000
unlabelled points
(％) Aoe.Inooe∞2
- - - -
5 0 5 0
8 8 7 7
0	1000
unlabelled points
Figure 5: Test log-likelihood and accuracy for Langevin sampling for Bayesian SSL on toy datasets
sampled from the model as a function of the number of unlabelled points.
where we approximate the expectation with K different samples of X0, denoted Xk0 . Unfortunately,
this approach does not immediately form a bound on the log-likelihood due to the convex nonlinear-
ity in taking the power of S. Nonetheless, one key problem with approximating machine learning
losses is that the optimizer learns to exploit approximation errors to find a pathological solution that
makes the objective unboundedly large. We appear to be safe from that pathology here, as we are
simply forming predictions by averaging over K augmentations of the underlying image. Nonethe-
less, to form a lower bound, we can follow FixMatch family algorithms by pseudo-labelling, i.e. by
taking only one term in the sum for class y*. FixMatch chooses y* by using the highest-probability
class for a weakly-augmented image. An alternative approach is to choose the y* giving the tightest
bound, i.e. argmaxy *PkPy(Xk). In either case,
logP(Y=None∣X,θ) ≥ logE [py* (X0)∣X]S ≥ S E [log 会Pkpy, (Xk)∣X] ,	(19)
If K = 1 and y * is chosen using a separate “weak” augmentation, then this is exactly equal to the
FixMatch objective for unlabelled points.
Note that both of these objectives (Eq. 18 and 19) promote reduced predictive uncertainty. Im-
portantly, this does not just increase confidence in the single-augmentation predictive distributions,
y(Xk0 ), but also increases alignment between the predictive distributions for different augmenta-
tions (Fig. 4B). In particular, if the single-augmentation predictives are all highly confident, but place
that high-confidence on different classes, then the multi-augmentation predictive formed by averag-
ing will have low-confidence (Fig. 4B right). The only way for the multi-augmentation predictive
to have high confidence is if the underlying single-augmentation predictive distributions have high
confidence in the same class (Fig. 4B left), which encourages the underlying network to become
more invariant. This makes sense: if data-augmentation changes the class predicted by the neural
network, then any predictions should be low confidence. And it implies that combining principled
data augmentation with a generative model of data curation automatically gives rise to an objective
encouraging invariance.
4	Results
We begin by giving a proof-of-principle for Bayesian SSL on a toy dataset generated from a known
model. Next, we tested our theoretical results (rather than trying to achieve SOTA performance)
on real-world datasets. In particular, our theory gives one explanation for why SSL is typically
more effective when unlabelled data is taken from the original, curated training set. To confirm
these results, we used Galaxy Zoo 2 as this was a real-world dataset which allowed us to generate
matched curated and uncurated datasets.
4.1	Bayesian SSL on a generated dataset
Our formulation of SSL as a likelihood implies that it should be possible to take entirely novel
approaches, such as using low-density separation SSL in a Bayesian neural network (BNN).
We considered a toy dataset generated from a “true” neural network model with one hidden layer
and 30 hidden units, 5 dimensional inputs and 2 output classes. We generated inputs IID from a
Gaussian, then passed them through the “true” neural network, then sampled multiple categorical
7
Under review as a conference paper at ICLR 2022
exact
curated
pseudo
curated
exact
uncurated
pseudo
uncurated
Figure 6: Test log-likelihood and error for curated and uncurated GZ2 datasets as a function of the
number of unlabelled points. Exact corresponds to Eq. (18) (which is exact in the limit as K → ∞)
and pseudo corresponds to the pseudo labelling version of the augmented objective (Eq. 19).
class-labels corresponding to different annotators. If all the simulated annotators agreed, consen-
sus was reached and if any simulated annotators disagreed, consensus was not reached. We used
100 labelled datapoints, though not all of them will have reached consensus, and we used up to
1600 unlabelled points, though again not all of them will have reached consensus. Note that as the
consensus/noconsensus status of a point arises from the generative model, we cannot independently
specify the number of consensus/noconsensus points. We used Eq. (2) as the likelihood for labelled
points, Eq. (6) as the likelihood for unlabelled points and Eq. (7) as the likelihood for noconsensus
points. We sampled (and trained networks on) 500 datasets in parallel. We trained using Langevin
dynamics with all data simultaneously (no minibatching) with no momentum and no rejection.
For a generative model with S = 1, consensus is always reached and the problem is equivalent to
standard supervised learning. As such, we found no benefits from including unlabelled points for
S = 1. In contrast, for any setting of S > 1 we found that increasing the number of unlabelled
points improved the test log-likelihood (Fig. 5A-B) and the test accuracy (Fig. 5C-D).
4.2	Galaxy Zoo 2
Our data curation based theory predicts that low-density separation based SSL should be much
more effective on curated than uncurated data. To test this prediction on real-world data, we turned
to Galaxy Zoo 22 (GZ2) (Willett et al., 2013) which uses images from the Sloan Digital Sky Survey.
This dataset is particularly useful for us as it has received only very minimal filtering based on
criteria such as object brightness and spatial extent. We defined 9 labels by truncating the complex
decision tree followed by the annotators (for further details see Aitchison, 2021). Further, as each
GZ2 image has received 〜50 labels, we can define a consensus coefficient by taking the fraction of
annotators that agreed upon the highest probability class. We can then define a curated dataset by
taking the images with consensus coefficient above some threshold within each class. Note that we
needed to select images on a per-class basis, because annotators tend to be more confident on some
classes than others, so taking the highest consensus coefficients overall would dramatically change
the class balance. In particular, we used the top 8.2% of images, which gave a full curated dataset of
just over 20,000 images. Of those, we randomly selected 2000 as labelled examples, 10000 as test
examples, and 0 - 6000 as unlabelled examples. The images were preprocessed by center-cropping
to 212 × 212 and then scaled to 32 × 32. We applied a FixMatch-inspired semi-supervised learning
algorithm, with a standard supervised objective, with unlabelled objective given by Eq. (18) with
K = 2. Data augmentation was given by vertical and horizontal flips, rotations from -180。to
180°, translations by UP to 40% on both axes and scaling from 20% to 180%. Note that as We were
trying to mirror the standard SSL setup, we did not include noconsensus points in the objective. We
trained a ResNet18 with our maximum likelihood objective using SGD with a batch size of 500, a
learning rate of 0.01 and 1500 epochs. We used an internal cluster of nVidia 1080 and 2080 GPUs,
and the experiments took roughly 300 GPU hours.
We found that the test-log-likelihood for curated data improved slightly as more unlabelled points
were included, whereas the test-log-likelihood for uncurated dramatically declined as unlabelled
points were added (Fig. 6A-B). We saw strong improvements in test accuracy with the number of
2https://data.galaxyzoo.org; www.sdss.org/collaboration/image-use-policy/
8
Under review as a conference paper at ICLR 2022
Unlabelled points for curated datasets (Fig. 6C-D). Note that in Fig. 6C the error rate for curated
datasets is already very small, so to see any effect we needed to plot the test error, normalized to the
initial test error (Fig. 6D). For uncurated data, the inclusion of large numbers of unlabelled points
dramatically worsened performance, though the inclusion of a small number of unlabelled points
gave very small performance improvements (Fig. 6C-D). Thus, this experiment is consistent with
the idea that the effectiveness of SSL arises at least in part from curation of the underlying dataset.
5	Related work
There are at least three main approaches to semi-supervised learning (Seeger, 2000; Zhu, 2005;
Chapelle et al., 2006; Zhu & Goldberg, 2009). First there is low-density separation, where we
assume that the class boundary lies in a region of low probability density away from both labelled
and unlabelled points. This approach dates back at least to transductive support vector machines
(SVMs) where the model is to be tested on a finite number of known test locations (Vapnik, 1998;
Chapelle et al., 1999). Those known test locations are treated as unlabelled points, and we find the
decision boundary that perfectly classifies the limited number of labelled points, while at the same
time being as far as possible from labelled and unlabelled data. Alternative approaches include
pseudo-labelling and entropy minimization (Grandvalet & Bengio, 2005; Lee, 2013). Second, there
are graph-based methods such as (Zhu & Ghahramani, 2002) which are very different from the
methods considered here. Third, there are approaches that use unlabelled points to build a generative
model of the inputs and leverage that model to improve classification (e.g. Kingma et al., 2014;
Odena, 2016; Gordon & Herndndez-Lobato, 2017). This approach was originally explored in a
considerable body of classical work (e.g. McLachlan, 1975; Castelli & Cover, 1995; Druck et al.,
2007) for a review, see Seeger (2000) and references therein. These approaches are fundamentally
different from the SSL approaches considered here, as they require a generative model of inputs,
while low-density separation methods do not. Generative modelling can be problematic as training
a generative model can be more involved than training a discriminative model and because the even
when the model can produce excellent samples, the high-level representation may be “entangled”
(Higgins et al., 2017) in which case it may not offer benefits for classification.
6	Discussion
Our theory provides a theoretical understanding of past results showing that SSL is more effective
when unlabelled data is drawn from the original, curated training set (Cozman et al., 2003; Oliver
et al., 2018; Chen et al., 2020; Guo et al., 2020). In the extreme, our theory might be taken to
imply that if data has not been curated, then SSL cannot work, and therefore that low-density sepa-
ration SSL methods will not be effective in messy, uncurated real-world datasets. However, this is
not the complete picture. Low-density separation SSL methods, including our log-likelihood, fun-
damentally exploit class-boundaries lying in low-density regions. As such, low-density separation
could equally come from the real underlying data or could be artificially induced by data curation
(Fig. 3). None of these methods are able to distinguish between these different underlying sources
of low-density separation and as such any of them may work on uncurated data where the underly-
ing distribution displays low-density separation. However, the possibility for curation to artificially
induce low-density separation does imply that we should be cautious about overinterpreting spec-
tacular results obtained on very carefully curated benchmark datasets such as CIFAR-10.
Surprisingly, the generative model of data curation used here also explains the cold-posterior ef-
fect in Bayesian neural networks (Wenzel et al., 2020; Aitchison, 2021), revealing a profound and
previously unsuspected connection.
In conclusion, we showed that low-density separation SSL objectives can be understood as a lower-
bound on a log-probability which arises from a principled generative model of data curation. This
gives a theoretical understanding of recent results showing that SSL is more effective on curated
data, which we confirmed by developing a Bayesian SSL model applied to toy data, using GZ2,
which allowed us to consider a completely uncurated dataset.
9
Under review as a conference paper at ICLR 2022
References
Laurence Aitchison. A statistical theory of cold posteriors in deep neural networks. ICLR, 2021.
David Berthelot, Nicholas Carlini, Ekin D Cubuk, Alex Kurakin, Kihyuk Sohn, Han Zhang, and
Colin Raffel. Remixmatch: Semi-supervised learning with distribution alignment and augmenta-
tion anchoring. arXiv preprint arXiv:1911.09785, 2019a.
David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin A
Raffel. Mixmatch: A holistic approach to semi-supervised learning. In Advances in Neural
Information Processing Systems,pp. 5050-5060, 2019b.
Vittorio Castelli and Thomas M Cover. On the exponential value of labeled samples. Pattern
Recognition Letters, 16(1):105-111, 1995.
Olivier Chapelle, Vladimir Vapnik, and Jason Weston. Transductive inference for estimating values
of functions. In NIPS, pp. 421-427. Citeseer, 1999.
Olivier Chapelle, Bernhard Scholkopf, and Alexander Zien. Semi-supervised learning. 2006.
Yanbei Chen, Xiatian Zhu, Wei Li, and Shaogang Gong. Semi-supervised learning under class
distribution mismatch. In AAAI, pp. 3569-3576. AAAI Press, 2020.
Fabio Gagliardi Cozman, Ira Cohen, Marcelo Cesar Cirelo, et al. Semi-supervised learning of
mixture models. In ICML, volume 4, pp. 24, 2003.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hi-
erarchical image database. In 2009 IEEE conference on computer vision and pattern recognition,
pp. 248-255. Ieee, 2009.
Gregory Druck, Chris Pal, Andrew McCallum, and Xiaojin Zhu. Semi-supervised classification
with hybrid generative/discriminative methods. In Proceedings of the 13th ACM SIGKDD inter-
national conference on Knowledge discovery and data mining, pp. 280-289, 2007.
Jonathan Gordon and Jose MigUel Herndndez-Lobato. Bayesian semisupervised learning with deep
generative models. arXiv preprint arXiv:1706.09751, 2017.
Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Ad-
vances in neural information processing systems, pp. 529-536, 2005.
Lan-Zhe Guo, Zhenyu Zhang, Yuan Jiang, Yu-Feng Li, and Zhi-Hua Zhou. Safe deep semi-
supervised learning for unseen-class unlabeled data. In ICML, volume 119 of Proceedings of
Machine Learning Research, pp. 3897-3906. PMLR, 2020.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick,
Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a
constrained variational framework. ICLR, 2017.
Masanori Kawakita and Jun’ichi Takeuchi. Safe semi-supervised learning based on weighted likeli-
hood. Neural Networks, 53:146-164, 2014.
Durk P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. Semi-supervised
learning with deep generative models. Advances in neural information processing systems, 27:
3581-3589, 2014.
Jesse H Krijthe and Marco Loog. Implicitly constrained semi-supervised linear discriminant analy-
sis. In 2014 22nd International Conference on Pattern Recognition, pp. 3762-3767. IEEE, 2014.
Jesse H Krijthe and Marco Loog. The pessimistic limits and possibilities of margin-based losses in
semi-supervised learning. arXiv preprint arXiv:1612.08875, 2016.
Alex Krizhevsky. Learning multiple layers of features from tiny images. Tech. report, 2009.
Dong-Hyun Lee. Pseudo-label: The simple and efficient semi-supervised learning method for deep
neural networks. In Workshop on challenges in representation learning, ICML, volume 3, pp. 2,
2013.
10
Under review as a conference paper at ICLR 2022
Yu-Feng Li and Zhi-Hua Zhou. Towards making unlabeled data never hurt. IEEE transactions on
pattern analysis and machine intelligence, 37(1):175-188, 2014.
Marco Loog. Contrastive pessimistic likelihood estimation for semi-supervised classification. IEEE
transactions on pattern analysis and machine intelligence, 38(3):462-475, 2015.
David JC MacKay. Information theory, inference and learning algorithms. Cambridge university
press, 2003.
Geoffrey J McLachlan. Iterative reclassification procedure for constructing an asymptotically opti-
mal rule of allocation in discriminant analysis. Journal of the American Statistical Association,
70(350):365-369, 1975.
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a
regularization method for supervised and semi-supervised learning. IEEE transactions on pattern
analysis and machine intelligence, 41(8):1979-1993, 2018.
Augustus Odena. Semi-supervised learning with generative adversarial networks. arXiv preprint
arXiv:1606.01583, 2016.
Avital Oliver, Augustus Odena, Colin Raffel, Ekin Dogus Cubuk, and Ian J. Goodfellow. Realistic
evaluation of deep semi-supervised learning algorithms. In NeurIPS, pp. 3239-3250, 2018.
Mehdi Sajjadi, Mehran Javanmardi, and Tolga Tasdizen. Regularization with stochastic transfor-
mations and perturbations for deep semi-supervised learning. In Advances in neural information
processing systems, pp. 1163-1171, 2016.
Matthias Seeger. Learning with labeled and unlabeled data. 2000.
Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini, Ekin D Cubuk,
Alex Kurakin, Han Zhang, and Colin Raffel. Fixmatch: Simplifying semi-supervised learning
with consistency and confidence. arXiv preprint arXiv:2001.07685, 2020.
Jesper E Van Engelen and Holger H Hoos. A survey on semi-supervised learning. Machine Learn-
ing, 109(2):373-440, 2020.
V Vapnik. Statistical learning theory. NY: Wiley, 1998.
Florian Wenzel, Kevin Roth, Bastiaan S Veeling, Jakub Swiatkowski, Linh Tran, StePhan Mandt,
Jasper Snoek, Tim Salimans, Rodolphe Jenatton, and Sebastian Nowozin. How good is the bayes
Posterior in deeP neural networks really? arXiv preprint arXiv:2002.02405, 2020.
Kyle W Willett, Chris J Lintott, Steven P Bamford, Karen L Masters, Brooke D Simmons, Kevin RV
Casteels, Edward M Edmondson, Lucy F Fortson, Sugata Kaviraj, William C Keel, et al. Galaxy
zoo 2: detailed morPhological classifications for 304 122 galaxies from the sloan digital sky
survey. Monthly Notices of the Royal Astronomical Society, 435(4):2835-2860, 2013.
Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V Le. UnsuPervised data
augmentation for consistency training. arXiv:1904.12848, 2019.
Xiaojin Zhu and Zoubin Ghahramani. Learning from labeled and unlabeled data with label ProPa-
gation. 2002.
Xiaojin Zhu and Andrew B Goldberg. Introduction to semi-suPervised learning. Synthesis lectures
on artificial intelligence and machine learning, 3(1):1-130, 2009.
Xiaojin Jerry Zhu. Semi-suPervised learning literature survey. 2005.
11