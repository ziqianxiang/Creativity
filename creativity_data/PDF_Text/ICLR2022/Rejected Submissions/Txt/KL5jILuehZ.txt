Under review as a conference paper at ICLR 2022
End-to-End Balancing for Causal
Continuous Treatment-Effect Estimation
Anonymous authors
Paper under double-blind review
Abstract
We study the problem of observational causal inference with continuous treatment.
We focus on the challenge of estimating the causal response curve for infrequently-
observed treatment values. We design a new algorithm based on the framework of
entropy balancing which learns weights that directly maximize causal inference
accuracy using end-to-end optimization. Our weights can be customized for
different datasets and causal inference algorithms. We propose a new theory for
consistency of entropy balancing for continuous treatments. Using synthetic and
real-world data, we show that our proposed algorithm outperforms the entropy
balancing in accuracy of treatment effect estimation.
1	Introduction
In many applications in business, social, and health sciences, we wish to infer the effect of a
continuous treatment such as drug dosage or administration duration on a health outcome variable.
Often, several confounding factors are common factors of influencing both treatment and response
variable, therefore for accurate causal estimation of the treatment in view, we must appropriately
account for their potential impact. Unlike binary treatments, causal inference with continuous
treatments is largely understudied and far more challenging than binary treatments. (Galagate, 2016;
Ai et al., 2021). This is primarily because continuous treatments induce uncountably many potential
outcomes per unit, only one of which is observed for each unit and across units, a sparse coarsening
of the underlying information needed to infer causal effects without uncertainty.
Propensity score weighting (Robins et al., 2000; Imai and Van Dyk, 2004), stand-alone or combined
with regression-based models to achieve double robustness (Kennedy et al., 2017), has quickly become
the state of the art for causal inference. If the weights, inversely proportional to the conditional
distribution of the treatment given the confounders, are correctly modeled, the weighted population
will appear to come from a randomized study. However, this approach faces several challenges:
(1) The weights only balance the confounders in expectation, not necessarily in the given data
(Zubizarreta et al., 2011). (2) The weights can be very large for some of units, leading to unstable
estimation and uncertain inference. As a possible remedy, entropy balancing (Hainmueller, 2012)
estimates the weights such that they balance confounders subject to a measure of dispersion on the
weights to prevent extreme weights.
In this work, we note that low-entropy weights do not directly optimize the quality of subsequent
weighted regression, and we introduce an alternative approach that does. We propose End-to-End
Balancing (E2B) to improve the accuracy of the weighted regression used for causal inference. E2B
uses end-to-end training to estimate the base weights in the entropy balancing framework. The E2B
weights are thus customized for different datasets and causal inference algorithms that are based on
weighting. Because we do not know the true treatment response function in real data, we propose a
new approach to generate synthetic training datasets for end-to-end training.
To theoretically analyze end-to-end balancing, we define Generalized Stable Weights (GSW) for
causal inference as a generalization of the stable weights proposed by Robins et al. (2000). We prove
that weights learned by entropy balancing for continuous treatments, including E2B weights, are
unbiased estimators of generalized stable weights. We also show that E2B weights are asymptotically
consistent and efficient estimators of the population weights.
1
Under review as a conference paper at ICLR 2022
We perform three sets of experiments to demonstrate accuracy improvements by E2B. Two experi-
ments with synthetic data, one with linear and another with non-linear response functions show that
the E2B is more accurate than the baseline entropy balancing and inverse propensity score techniques.
In the experiments on real-world data, we qualitatively evaluate the average treatment effect function
learned by E2B. We also show that the base weights learned by E2B follow our intuition about
up-weighting low frequency treatments.
2	Problem Definition and Related Work
Problem Statement. Suppose we have the triplet of (x, a, y), where x ∈ X ⊂ Rr, a ∈ A ⊂ R and
y ∈ R denote the confounders, treatments, and response variables, respectively, from an observational
causal study. In our continuous treatment setting (Galagate, 2016, Ch. 1.2.6), we denote potential
outcomes as y(a), which means the value ofy after intervention in the treatment a and setting its value
to a. Given an i.i.d. sample of size n, {(xi, ai, yi)}n , our objective is to eliminate the impact of the
ConfoUnders and identify the average treatment effect function μ(a) = E[y(a)], which is also called
the response function. We make the two classic assumptions: (1) Strong ignorability: y(a) ⊥⊥ a | x.
(i.e., no hidden confounders) and (2) Positivity: 0 < P (a|x) < 1.
General Causal Inference Literature. The literature on causal inference is vast and we refer the
reader to the books for the general inquiry (Pearl, 2009; Imbens and Rubin, 2015; Spirtes et al.,
2000; Peters et al., 2017). Instead, we focus on reviewing the inference techniques for continuous
treatments. In particular, we narrow down our focus on propensity score weighting approaches
(Robins et al., 2000; Imai and Van Dyk, 2004), because they can either be used alone or combined
with the regression algorithms to create double robust algorithms.
Causal Inference via Weighting. A popular approach for causal inference is to create a pseudo-
population by weighting data points such that in the pseudo-population the confounders and treatments
are independent. Thus, regular regression algorithms can estimate the causal response curve using
the pseudo-population, which resembles data from randomized trials. Throughout this paper, we
will denote the parameters of the pseudo-population with a tilde mark. Multiple forms of propensity
scores have been proposed for continuous treatments (Hirano and Imbens, 2004; Imai and Van Dyk,
2004). The commonly-used stablized weights (Robins et al., 2000; Zhu et al., 2015) are defined as
the ratio of marginal density over the conditional density of the treatments: sw = f(a)/f(a|x).
Problems with Propensity Scores. Zubizarreta et al. (2011) list two challenges with the propensity
scores: (1) The weights only balance the confounders in expectation, not necessarily in the given
data. (2) The weights can be very large for some of the data points, leading to unstable estimations.
The challenges are amplified in the continuous setting because computing the stabilized weights
requires correctly choosing two models, one for the marginal and one for the conditional distributions
of the treatments. Kang et al. (2007) and Smith and Todd (2005) provide multiple evidence that the
propensity score methods can lead to large biases in the estimations. While Robins et al. (2007)
propose techniques to fix the large weights problems in the binary treatment examples discussed by
Kang et al. (2007), learning more accurate, bounded, and stable weights has been an active research
area. Further techniques have proposed techniques to learn more robust propensity scores for binary
treatments (Li et al., 2018; Zhao, 2019) too, however, the case of continuous treatments have received
considerably less attention.
Entropy Balancing. To address the problem of extreme weights, Entropy Balancing (EB) (Hain-
mueller, 2012) estimates weights such that they balance the confounders subject to a measure of
dispersion on the weights to prevent extremely large weights. Other loss functions using different
dispersion metrics have been proposed for balancing (Zubizarreta, 2015; Chan et al., 2016). Zhao
and Percival (2016) show that the entropy balancing is double robust. Entropy balancing has been
extended to the continuous treatment setting (Fong et al., 2018; Vegetabile et al., 2021), where the
balancing condition ensures that the weighted correlation between the confounders and the treatment
is zero. Ai et al. (2021) propose a method for estimating the counterfactual distribution in the
continuous treatment setting.
2
Under review as a conference paper at ICLR 2022
3	Methodology
To describe our end-to-end balancing algorithm, we first need to describe entropy balancing for
continuous treatments with base weights.
3.1	Entropy Balancing for Continuous Treatments
Causal Inference via Entropy Balancing. Entropy balancing creates a pseudo-population using
instance weights wi,i=1,...,n, in which the treatment a and the confounders x are independent
from each other. The independence is enforced by first selecting a set of functions on the confounders
φk(•) : X → R, for k = 1,...,K, that are dense and complete in L2 space. Given the φ functions,
we approximate the independence relationship by En[aφk(x)] = 0, for k = 1,...,K, where the
empirical expectation Eb n is performed
on the pseudo population. Hereafter, we will denote the
mapped data points as φ(xi) = [φι(xi),..., φκ(xi)]. The Φk(∙) functions can be chosen based on
prior knowledge or defined by the penultimate layer of a neural network that predicts (a, y) from x.
Our contributions in this paper are orthogonal to the choice of the φk (∙) functions and can benefit
from ideas on learning these functions (Zeng et al., 2020). The data-driven choice of the number of
bases K is beyond the scope of current paper and left to future work.
Balancing Constraint for the Continuous Treatments. Following (Fong et al., 2018; Vegetabile
et al., 2021), in the case of continuous treatments, we first de-mean the confounders φ(xi) and
treatments a such that without loss of generality they are taken to have mean zero. The balancing
objective is to learn a set of weights wi,i=1,...,nthat satisfy Pn wiφ(xi) = 0, Pn wiai =
0, and Pn wiaiφ(xi) = 0. We can write these three constraints in a compact form by defining a
(2K + 1)-dimensional vector gi = [φ(xi), a%, aiφ(xi)]. The constraints become PN1 Wigi = 0.
We stack the g vectors in a (2K + 1) × n dimensional matrix G for compact notation. In this work,
without loss of generality, we will present our idea with the first order balancing, without higher order
moments (Galagate, 2016; Wong and Chan, 2018; Hazlett, 2020).
Primal and Dual EB. A variety of dispersion metrics have been proposed as objective function for
minimization such as entropy or variance of the weights (Wang and Zubizarreta, 2020). Hainmueller
(2012) originally proposed minimizing the KL-divergence between the weights and a set of base
weights qi,i=1,...,n. Details on choice of base weights is discussed below, however, we note that
qi = const. leads to minimization of the entropy of weights. Using this dispersion function and the
balancing constraints, entropy balancing optimization is as follows:
s.t.
n	wi∖
W = argmin	Wi log ,
w	i=1	qi
(i)	Gw = 0, (ii) 1>w =1, (iii) Wi ≥ 0fori =1,...,n.
The above optimization problem can be solved efficiently using its Lagrangian dual:
λ = argmin log(1> exp (—λ> G + ')),
λ
(1)
(2)
,ʌ.
where `i = log qi are the log-base-weights. Given the solution λ, the balancing weights can be
computed as w
Softmax (—λ>G + ').
The softmax function is defined as softmax(v)
exp v/ 1> expv for any vector v. The log base weight is a degree of freedom that we have in the
Eq. (2) to improve the quality of causal estimation. We select the mapping dimension K such that
problem (2) is well-conditioned and leave the analysis of the high dimensional setting K ≈ n to
future work. We can also add an L1 penalty term to the dual objective in Eq. (2), which corresponds
to approximate balancing (Wang and Zubizarreta, 2020).
In the next section we propose to parameterize the log-base-weights and learn them. Our analysis in
Section 4 shows that with any arbitrary base weights, causal estimation using the weights learned in
Eq. (2) will be consistent.
3
Under review as a conference paper at ICLR 2022
Algorithm 1 Stochastic Training of `θ for End-to-End Balancing
Require: Data tuples (xi, a%, yi) for i = 1,...,n with an unknown response function μ(a).
Require: Representation functions φ(∙) and ψ(∙), split size nι < n and batch size B.
1:	Generate a random set of indexes I, |I | = n1 and its complement Ic and split the data to S and
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
Sc using them.
Estimate the distribution of noise in y given (a, x) as Fbε.
Compute G by stacking gi =[φ(xi),ai,aiφ(xi)], for i =1,...,n.
for Number of Iterations do
Generate B datasets {(xi, αi,yi,b)}‰ 1 for b = 1,...,B using ε 〜Fb, and randomly selected
μ(a)b response functions.
'i4-'θ (ψ(ai, Xi)).
λ — argmi□λ {log(1> exp (-λ>G + '))} using only S data.
W — SoftmaX
(-λ>G + ') using only
Sc data.
μ(a)b J weighting-based causal estimates using (a%, yib, wi) in Sc for b
Take a step in θ to minimize ɪ PB=( (b(a)b - μ(a)b)2.
end for
1,. .., B.
return The `b function.
3.2	Learning the Base Weights
Hainmueller (2012) suggests two approaches for choosing base weights: (1) weights obtained from a
conventional propensity score model and (2), in the context of survey design, using knowledge about
the sampling design. We argue that a data-driven approach that learns customized base weights for
each pair of dataset and weighted causal regression algorithm can further improve performance.
To address this problem, we define the log-base-weights ` as a parametric function (e.g., a neural
network) of the treatment variable; i.e. 'θ(∙). We learn the base weights with the goal of improving
the accuracy of the subsequent weighted regression. This is challenging because simply optimizing
the weighted regression loss (e.g., weighted MSE) leads to degenerate results. That is, learning `
to minimize the regression loss will lead to exclusion of the difficult-to-predict data points from the
regression, which is undesirable. Thus, we need to find another loss function to optimize, ideally a
loss function that directly minimizes the error in estimation of the response function μ(a).
Our idea for learning the parameters of the base weights is to generate multiple pseudo-responses
y with randomly generated response functions μ(a). Now that we know the true response function
μ(a) in the randomly generated data, we can perform causal inference and obtain the estimation of
the known response curve μb(a) using our weights. Algorithm 1 outlines our stochastic training of
the base weight function. First, in Step 2, we estimate the distribution of noise using the residuals
of regressing y over (a, x), capturing the possible heteroskedasticity in the noise. Then, in each
iteration, we draw a batch of possible datasets. To generate each dataset, we randomly choose a
response function μ(a) and use it to generate the entire dataset (see Section 5.1 for examples of
random functions). For the entire batch, we use `θ to learn the log-base-weights, and subsequently
learn the weights in lines 7-8. In line 9 we use a weighted regression algorithm to find our estimation
μ(a) of the randomly-generated μ(a). Our loss function is the mean squared error between the latter
quantities. While we call our algorithm End-to-End Balancing (E2B) because of our end-to-end
optimization.
Sample Splitting. The E2B procedure involves estimation of two sets of parameters θ in the `θ
and λ for entropy balancing. The joint estimation of θ, λ on a single sample will result in bias
(Chernozhukov et al., 2018). Thus, we split the sample to two mutually exclusive parts and perform
the optimizations on separate partitions of data.
Choice of Random Response Functions. Ideally, we should rely on domain experts for choosing
the random set of response functions μ(a) that includes the true response function. Alternatively,
we can choose broad function classes such as random piecewise smooth functions or polynomial
4
Under review as a conference paper at ICLR 2022
functions with random coefficients. We can also use generative adversarial networks to generate data
that is more similar to our sample (Athey et al., 2021).
Features Fed to `θ. We can feed the raw values of the treatments and any handcrafted features,
denoted by ψ(ai, xi). We empirically find that ψ(ai, xi) = (logp(ai), logp(ai|xi)) makes training
the `θ easier. We describe the details of our neural network model for `θ and our techniques for
training in Appendix B.
Weighted Regression Algorithms. To be able to differentiate the loss function with respect to
θ, we need weighted regression algorithms whose estimates are differentiable with respect to the
weights. In the linear average treatment effect function we choose weighted linear regression and in
the non-linear setting we use the weighted polynomial regression and the local kernel regression, as
used by Flores et al. (2012).
Double Robustness. Zhao and Percival (2016) show that in the binary case, the entropy balancing
is double robust. We do not attempt to show double robustness for E2B because we see E2B as a
meta algorithm that learns customized weights for each dataset and algorithm. We can either (1)
plug-in the E2B weights in the double robust algorithm and expect improved accuracy, or (2) learn
weights that directly minimize the error of double robust algorithms such as (Kennedy et al., 2017).
4	Analysis
We prove that for any arbitrary choice of the log-base-weight function `θ , our approach consistently
estimates causal effects. Before proving the consistency results, we characterize the quantity that our
solution converges to. All long proofs are relegated to Appendix A.
Definition 1. Generalized Stable Weights. Suppose f(a, x) denote the joint probability density
function of treatments and confounders in a population. Suppose f(a) and f(x) denote two arbitrary
density functions, possibly different with the marginal density functions in our population, that satisfy
EX〜e® [ [x] = 0 and Ea〜尸(。)[a] = 0.We define the Generalized Stable Weights asfollows
wGSW (a, x)
f(af(X)
f(a, x)
(3)
Remark. Our definition generalizes the stabilized weights defined by Robins et al. (2000), where
f(a) and f(x) match the marginal probability density functions in the original population.
Proposition 1. The generalized stable weights wGSW satisfy E [wGSW ax] = 0.
Proof.
E [wgswax] = E f (a)，(X) ax = Z Z f (a)f (X) axdFa X(a, X)= Z af(a)da Z xf(x)dx = 0,
LGSWl [ f (a, x)	J J J f (a, x)	ax，' JjLJ 八) ,
where the last equation is because of zero mean assumption for the f (a) and f (x) distributions. □
Now, we can show that with an appropriate choice of the φ functions, the solution of Eq. (2)
approximates the generalized stable weights. Consider the population version of Eq. (2):
λ? = argmin log (E [exp(g>λ + ')]) .	(4)
λ
The weights corresponding to λ? can be calculated as w? = C exp(g>λ? + `), where C =
(R exp(g>λ? + ')dF(a, x)) 1 is the normalization constant.
5
Under review as a conference paper at ICLR 2022
Assumptions.
1.
2.
3.
f(a, X) ≥ c>0 for all (a, X) ∈ A × X pairs, where c is a constant.
Suppose the basis functions are dense and rich enough such for some small values of δφ
that they satisfy:
E[aφ(x)] = 0 only if sup |f (a, X) - f (a)f (X)| = δφK.
Suppose the population problem in Eq. (4) has a unique solution λ? and the corresponding
weights are denoted by W? .
The following theorem shows that the solution to Eq. (4) converges to WGSW :
Theorem 1. Given the assumptions, the solution to the population problem satisfies:
sup |w*(a, X) - WGSW(a, x)| ≤ δφκ/c.
a,x
(5)
If we select the function set φK such that δφ = o(1), the theorem shows that W?(a, X) is an
unbiased estimator of WGSW (a, X). Notice that Assumption 1 is only slightly stronger than the
common positivity assumption. Assumption 2 requires us to select the mapping functions such that
zero the correlation between the mapped confounders and the treatment implies their independence.
We provide the proof in Appendix A.1.
Note that the quality of the ψ features and neural network training does not affect the unbiasedness of
the E2B because of the balancing constraint is still satisfied. The flexibility in choice of f distributions
in the definition of WGSW is due to the fact that we require only first order balancing. If we enforce
higher order balancing constraints in the form of E[w?φι(a)02 (x)] = E[φι(a)] ∙ E[φ2 (x)] for any
suitable functions φ1 and φ2, Theorem 1 in (Ai et al., 2021) shows that W? = f (a)/f (a|x). The more
flexible form of weights in Eq. (3) allows us to pick the marginals f(a) and f(X) with more freedom.
In this work, we have chosen a data-driven way to learn them.
Finally, the following theorem establishes the asymptotic consistency and normality result for each
individual weight estimated by E2B, under the common regularity conditions for problem (2).
Theorem 2. Suppose Λ ⊂ R2K +1 is an open subset of Euclidean space and the solution λbn ∈ Λ
to Eq. (2) is within the subset. The weights estimated by Eq. (2) are asymptotically normal for
i =1,...,n:
√∕n ( Wn (ai, Xi) ― W (ai, Xi ) ) -→ ∙N(0, Q (ai, Xi )).
(6)
We provide the population form of σ2(ai, Xi) and an unbiased sample estimate for it in Appendix A.2.
5	Experiments
We use two synthetic and one real-world datasets to show that E2B outperforms the baselines. In
the synthetic datasets, we have access to the true treatment effects; thus we measure accuracy of the
algorithms in recovering the treatment effects. In the real-world data, we qualitatively evaluate the
estimated causal treatment effect curve and inspect the learned log-base-weight function.
Baselines. A key baseline in our study is the Inverse Propensity score Weighting (IPW) with Stable
Weights (Robins et al., 2000) as the most commonly used technique. To avoid extreme weights and
prevent instability, We trim (Winsorize) the weights by [5,95] percentiles (Cole and Herndn, 2008;
Chernozhukov et al., 2018). However, the main baseline in our experiments is Entropy Balancing
(Vegetabile et al., 2021), which is equal to E2B with `θ = const, corresponding to the constant
base weights. EB allows us to do an ablation study and see the exact amount of improvement by
learning a customized `θ function. We also include EB with the stabilized weights (SW) as base
weights (`θ = log pb(a) - log pb(a|X)). Finally, we also include the permutation weighting algorithm
(Arbour et al., 2021) that proposes to compute the weights using permutation of the treatments and a
classifier that predict the probability of being permuted. We provide further details on this algorithm
in Appendix B.4.
6
Under review as a conference paper at ICLR 2022
Table 1: Average RMSE for estimation of the response functions. The results are in the form of
“mean (std. err.)” from 100 runs.
Algorithm	Linear	Non-linear
Inverse Propensity Weighting (SW)	2.057 (0.437)	0.530 (0.025)
Permutation Weighting	1.1543 (6.580)	0.525 (0.250)
Entropy Balancing (Const.)	0.880 (0.072)	0.335 (0.022)
Entropy Balancing (SW)	0.652 (0.059)	0.403 (0.025)
End-to-End Balancing	0.383 (0.035)	0.276 (0.014)
Training Details. We provide the details of the neural networks used for the `θ and propensity
score estimation for IPW in Appendix B. All neural networks are trained using Adam (Kingma
and Ba, 2014) with early stopping based on validation error. The learning rate and architectural
parameters of the neural networks are tuned via hyperparameter search on the validation data.
5.1	Synthetic Data Experiments
Linear. We use the following steps to generate 100 datasets, each with 1000 data points.
1.	Generate ConfoUnders X ∈ R5, X 〜N(0, Σ), where Σ is a tridiagonal covariance matrix
with diagonal and off-diagonal elements equal to 1.0 and 0.2, respectively.
2.	a 〜N(μa, 0.32), where μα = sin(β>x) and βχa,k 〜Unif(-1,1) for k = 1,..., 5.
3.	y 〜N (μy, 0.52), where μy = β> X + βαy a, where βaχ, βχy,k 〜N (0,1) for k = 1,..., 5.
We use weighted least squares as the regression algorithm and report the average ∣βay - βay | over all
100 datasets.
Nonlinear We first generate confounders X and treatments a similar to steps 1 and 2 of the
linear case. Then, we generate the response variable according to y 〜N(μy, 0.52), where μy =
βXyx + hγay (a), where βχy,k 〜N(0,1) for k = 1,..., 5. The Hermit polynomials are defined as
hγ(z)=γ0 + γ1z + γ2(z2 - 1) + γ3(x3 - 3x). Similar to the linear case, we generate 100 samples
of size 1000. We use the weighted polynomial regression as the regression algorithm to estimate γb
and report the average RMSE between true γ and γb . We report the mean and standard error of errors
on 100 datasets in Table 1.
As seen in Table 1, in both linear and non-linear datasets, the E2B is significantly more accurate in
uncovering the true treatment response functions. Both constant and IPW base weights perform worse
than the base-weights learned by end-to-end balancing. As Robins et al. (2007) caution, synthetic
data evaluation might exacerbate the extreme weights issues because unlike real data, usually no
manual inspection of weights are done.
To gain more insights, in Figure 1, we plot the log-base weight function that we learn as a function of
log(pb(a)) and log(pb(a|X)). We align all curves at their starting point and plot the median of 100 runs.
Both figures, show more variations in the log(p(a))-axis, rather than the log(b(a∣x))-axis. Not that,
especially in the linear case, the smaller conditional probability leads to larger base-weights, inline
with the IPW base-weights. Finally, the complexity of the plots emphasizes the need for end-to-end
methods for learning weights.
5.2	Real Data Experiments
We study the impact of P M2.5 particle level on the cardiovascular mortality rate (CMR) in 2132
counties in the US using the data provided by the National Studies on Air Pollution and Health
(Rappold, 2020). The data is publicly available under U.S. Public Domain license. The P M2.5
particle level and the mortality rate are measured by μg∕m3 and the number of annual deaths due to
cardiovascular conditions per 100,000 people, respectively. We use only the data for 2010 to simplify
the experiment setup; thus we measure the same year impact of P M2.5 particle level. Other than
7
Under review as a conference paper at ICLR 2022
4a)
I 中.60
3.15
2.70
2.25
1.80
1.35
0.90
-0.45
-0.00
-.------1_-H^^^ L-0.45
-6	-4	-2	0
log(p(a))
(a) Linear Design
-0.51-------------㈣一.
192
∣1.68
Γ4
1^^^Λ R 1.20
J 0.96
"72
-0.48
-0.24
-0.00
-3.0J-----1-------1----U
-6	-4	-2	0
log(b(a))
(b) Non-linear Design
Figure 1:	The estimated log-base-weight function `θ as a function of logarithms of the empirical den-
sity of the treatment log(pb(a)) and conditional distribution log(pb(a|x)). We perform the experiment
100 times and report the median and the inter-quantile range. We align all curves by normalizing
their value at the beginning to zero.
(a) Response Curve
((Xw叵茸
2(a)
□ 0.36
0.24
0.12
0.00
-0.12
-0.24
-0.36
-0.48
-0.60
-2	-1
log(p(a))
(b) Log-base-weights function
Figure 2:	(a) The average treatment effect curve for measuring the impact of P M2.5 concentration
on the cardiovascular mortality rate. We perform the experiment 100 times and report the mean and
±std range. (b) The estimated log-base-weight function `θ as a function of logarithm of the empirical
density of the treatment log(pb(a)).
the treatment and response variables, the data includes 10 variables such as poverty rate, population,
and household income, which we use as confounders. We provide the descriptive statistics and the
histograms for the treatment and effect in Appendix C.
To train E2B, we create the random dataset (Line 5 in Algorithm 1) using Hermite polynomials of max
degree 3, μy = ∖hγxy(β>x∕kβ>x∣∣2) + hγαy (a)∣. We use absolute value to capture the positivity
of our response variable. The data also shows heteroskedasticity; we model the noise as a zero mean
Gaussian variable with variance σ2(yb) = 6.00yb. For regression, we use the non-parametric local
kernel regression algorithm. We measure the uncertainty in the curves using the deep ensembles
technique (Lakshminarayanan et al., 2017) with 100 random ensembles.
Figure 2a shows the average treatment effect curve for the impact of P M2.5 on CMR. We show
the one standard deviation interval using the shaded areas. Starting around PM2.5 = 5.3μg∕m3
the curve increases with a steep slope; confirming the previous studies that increased P M2.5 levels
increase the probability of cardiovascular mortality. Our results are generally aligned with the results
reported in (WU et al., 2020). We can see that after PM2.5 = 6.4μg∕m3 the curve plateaus and
8
Under review as a conference paper at ICLR 2022
mortality rate stays at elevated levels. Looking at the histogram of the treatments in Figure 3a in
the appendix, we observed that most counties have P M2.5 between 6 and 8. This might justify the
fluctuations that we see in this interval and may allude about potential unmeasured confounders.
Figure 2b shows the log-base-weight function that we learn in this data. Similar to the synthetic
experiments, we show the median of 100 runs. While the plot shows smaller variations, it is generally
inline with the observations we had in the synthetic data.
6	Discussion
Causal inference is a well-studied problem; its main goal is to remove biases due to confounding by
balancing the population to look similar to randomized controlled trials. Removing the impact of
confounders can play a critical role in reducing and possibly eliminating bias in our decision making
leading to potentially positive societal impacts. Our results rely on two classical assumptions: (1)
unconfoundedness and (2) positivity. While these assumptions are sometimes reasonable in practice,
their violations might lead to biased causal inferences. For example, the positivity assumption might
be violated if we do not collect any data for a sub-population. Overall, the debiasing property
of causal inference should not relieve us from rigorous data collection and analysis setup. In our
experiments, we have been careful to quantify uncertainty in our causal estimation and be wary of
over-confidence in our results. We performed our experiments on a CPU machine with 16 cores from
a cloud provider that uses hydroelectric power.
7	Conclusion
We observed that in the entropy balancing framework, the base weights provide an extra degree of
freedom to optimize the accuracy of causal inference. We propose end-to-end balancing (E2B) as a
technique to learn the base weight such that they directly improve the accuracy of causal inference
using end-to-end optimization. In our theoretical analysis we find the quantity that E2B weights are
approximating and discuss E2B’s statistical consistency. Using synthetic and real-world data, we
show that our proposed algorithm outperforms the entropy balancing in terms of causal inference
accuracy.
References
Ai, C., Linton, O., and Zhang, Z. (2021). Estimation and inference for the counterfactual distribution
and quantile functions in continuous treatment models. Journal of Econometrics.
Arbour, D., Dimmery, D., and Sondhi, A. (2021). Permutation weighting. In ICML.
Athey, S., Imbens, G. W., Metzger, J., and Munro, E. (2021). Using wasserstein generative adversarial
networks for the design of monte carlo simulations. Journal of Econometrics.
Chan, K. C. G., Yam, S. C. P., and Zhang, Z. (2016). Globally efficient non-parametric inference
of average treatment effects by empirical balancing calibration weighting. Journal of the Royal
Statistical Society. Series B, Statistical methodology, 78(3):673.
Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., and Robins,
J. (2018). Double/debiased machine learning for treatment and structural parameters: Dou-
ble/debiased machine learning. The Econometrics Journal, 21(1).
Cole, S. R. and Hernan, M. A. (2008). Constructing inverse probability weights for marginal structural
models. American journal of epidemiology, 168(6):656-664.
Flores, C. A., Flores-Lagunes, A., Gonzalez, A., and Neumann, T. C. (2012). Estimating the effects of
length of exposure to instruction in a training program: the case of job corps. Review of Economics
and Statistics, 94(1):153-171.
Fong, C., Hazlett, C., Imai, K., et al. (2018). Covariate balancing propensity score for a continuous
treatment: application to the efficacy of political advertisements. The Annals of Applied Statistics,
12(1):156-177.
9
Under review as a conference paper at ICLR 2022
Galagate, D. (2016). Causal Inference With a Continuous Treatment and Outcome: Alternative
Estimators for Parametric Dose-response Functions With Applications. PhD thesis, University of
Maryland.
Hainmueller, J. (2012). Entropy balancing for causal effects: A multivariate reweighting method to
produce balanced samples in observational studies. Political analysis, pages 25-46.
Hazlett, C. (2020). Kernel balancing: A flexible non-parametric weighting procedure for estimating
causal effects. Statistica Sinica.
Hirano, K. and Imbens, G. W. (2004). The propensity score with continuous treatments. Applied
Bayesian modeling and causal inference from incomplete-data perspectives, 226164:73-84.
Imai, K. and Van Dyk, D. A. (2004). Causal inference with general treatment regimes: Generalizing
the propensity score. Journal of the American Statistical Association, 99(467):854-866.
Imbens, G. W. and Rubin, D. B. (2015). Causal inference in statistics, social, and biomedical
sciences. Cambridge University Press.
Kang, J. D., Schafer, J. L., et al. (2007). Demystifying double robustness: A comparison of alternative
strategies for estimating a population mean from incomplete data. Statistical science, 22(4):523-
539.
Kennedy, E. H., Ma, Z., McHugh, M. D., and Small, D. S. (2017). Nonparametric methods for doubly
robust estimation of continuous treatment effects. Journal of the Royal Statistical Society. Series B,
Statistical Methodology, 79(4):1229.
Kingma, D. P. and Ba, J. (2014). Adam: A method for stochastic optimization. arXiv:1412.6980.
Lakshminarayanan, B., Pritzel, A., and Blundell, C. (2017). Simple and scalable predictive uncertainty
estimation using deep ensembles. In NeurIPS, pages 6405-6416.
Li, F., Morgan, K. L., and Zaslavsky, A. M. (2018). Balancing covariates via propensity score
weighting. Journal of the American Statistical Association, 113(521):390-400.
Pearl, J. (2009). Causality. Cambridge university press.
Peters, J., Janzing, D., and Scholkopf, B. (2017). Elements of causal inference: foundations and
learning algorithms. The MIT Press.
Rappold, A. (2020). Annual pm2.5 and cardiovascular mortality rate data: Trends modified by county
socioeconomic status in 2, 132 us counties.
Robins, J., Hernan, M., and Brumback, B. (2000). Marginal structural models and causal inference in
epidemiology. Epidemiology, 11(5):550-560.
Robins, J., Sued, M., Lei-Gomez, Q., and Rotnitzky, A. (2007). Comment: Performance of double-
robust estimators when" inverse probability" weights are highly variable. Statistical Science,
22(4):544-559.
Smith, J. A. and Todd, P. E. (2005). Does matching overcome lalonde’s critique of nonexperimental
estimators? Journal of econometrics, 125(1-2):305-353.
Spirtes, P., Glymour, C. N., Scheines, R., and Heckerman, D. (2000). Causation, prediction, and
search. MIT press.
Van der Vaart, A. W. (2000). Asymptotic statistics, volume 3. Cambridge university press.
Vegetabile, B. G., Griffin, B. A., Coffman, D. L., Cefalu, M., Robbins, M. W., and McCaffrey,
D. F. (2021). Nonparametric estimation of population average dose-response curves using entropy
balancing weights for continuous exposures. Health Services and Outcomes Research Methodology,
21(1):69-110.
Wang, Y. and Zubizarreta, J. R. (2020). Minimal dispersion approximately balancing weights:
asymptotic properties and practical considerations. Biometrika, 107(1):93-105.
10
Under review as a conference paper at ICLR 2022
Wong, R. K. and Chan, K. C. G. (2018). Kernel-based covariate functional balancing for observational
studies. Biometrika,105(1):199-213.
Wu, X., Braun, D., Schwartz, J., Kioumourtzoglou, M., and Dominici, F. (2020). Evaluating the
impact of long-term exposure to fine particulate matter on mortality among the elderly. Science
advances, 6(29):eaba5692.
Zeng, S., Assaad, S., Tao, C., Datta, S., Carin, L., and Li, F. (2020). Double robust representation
learning for counterfactual prediction. arXiv:2010.07866.
Zhao, Q. (2019). Covariate balancing propensity score by tailored loss functions. The Annals of
Statistics, 47(2):965-993.
Zhao, Q. and Percival, D. (2016). Entropy balancing is doubly robust. Journal of Causal Inference,
5(1).
Zhu, Y., Coffman, D. L., and Ghosh, D. (2015). A boosting algorithm for estimating generalized
propensity scores with continuous treatments. Journal of causal inference, 3(1):25-40.
Zubizarreta, J. R. (2015). Stable weights that balance covariates for estimation with incomplete
outcome data. Journal of the American Statistical Association, 110(511):910-922.
Zubizarreta, J. R., Reinke, C. E., Kelz, R. R., Silber, J. H., and Rosenbaum, P. R. (2011). Matching
for several sparse nominal variables in a case-control study of readmission following surgery. The
American Statistician, 65(4):229-238.
11