Under review as a conference paper at ICLR 2022
FedProf: Selective Federated Learning with
Representation Profiling
Anonymous authors
Paper under double-blind review
Ab stract
Federated Learning (FL) has shown great potential as a privacy-preserving solu-
tion to learning from decentralized data that are only accessible to end devices
(i.e., clients). In many scenarios however, a large proportion of the clients are
probably in possession of low-quality data that are biased, noisy or even irrel-
evant. As a result, they could significantly slow down the convergence of the
global model we aim to build and also compromise its quality. In light of this, we
propose FedProf, a novel algorithm for optimizing FL under such circumstances
without breaching data privacy. The key of our approach is a data representation
profiling and matching scheme that uses the global model to dynamically profile
data representations and allows for low-cost, lightweight representation matching.
Based on the scheme we adaptively score each client and adjust its participation
probability so as to mitigate the impact of low-value clients on the training pro-
cess. We have conducted extensive experiments on public datasets using various
FL settings. The results show that FedProf effectively reduces the number of
communication rounds and overall time (up to 4.5x speedup) for the global model
to converge and provides accuracy gain.
1	Introduction
With the advances in Artificial Intelligence (AI), we are seeing a rapid growth in the number of
AI-driven applications as well as the volume of data required to train them. However, a large pro-
portion of data used for machine learning are often generated outside the data centers by distributed
resources such as mobile phones and IoT (Internet of Things) devices. It is predicted that the data
generated by IoT devices will account for 75% of the total in 2025 (Meulen, 2018). Under this
circumstance, it will be very costly to gather all the data for centralized training. More importantly,
moving the data out of their local devices (e.g., mobile phones) is now restricted by law in many
countries, such as the General Data Protection Regulation (GDPR)1 enforced in EU.
We face three main difficulties to learn from decentralized data: i) massive scale of end devices; ii)
limited communication bandwidth at the network edge; and iii) uncertain data distribution and data
quality. As an promising solution, Federated Learning (FL) (McMahan et al., 2017) is a framework
for efficient distributed machine learning with privacy protection (i.e., no data exchange). A typical
process of FL is organized in rounds where the devices (clients) download the global model from
the server, perform local training on their data and then upload their updated local models to the
server for aggregation. Compared to traditional distributed learning methods, FL is naturally more
communication-efficient at scale (Konecny et al., 2016; Wang et al., 2019). Nonetheless, several
issues stand out.
1.1	Motivation
1)	FL is susceptible to biased and low-quality local data. Only a fraction of clients are selected for
a round of FL (involving too many clients leads to diminishing gains (Li et al., 2019)). The stan-
dard FL algorithm (McMahan et al., 2017) selects clients randomly, which implies that every client
(and its local data) is considered equally important. This makes the training process susceptible
to local data with strong heterogeneity and of low quality (e.g., user-generated texts (Hard et al.,
1https://gdpr.eu/what-is-gdpr/
1
Under review as a conference paper at ICLR 2022
Figure 1: (Preliminary experiment) The global model’s convergence under different data conditions.
We ran the FL process with 100 clients to learn a CNN model on the MNIST dataset, which is
partitioned and allocated to clients in four different ways where the data are 1) original (black
line): noiseless and evenly distributed across the clients, 2) biased (magenta line): locally class-
imbalanced, 3) noisy (blue line): blended with noise, or 4) biased and noisy (red line). The noise (if
applied) covers 65% of the clients; the dominant class accounts for >50% of the samples for biased
local data. The fraction of selected clients is 0.3 for each round.
2018) and noisy photos). In some scenarios, local data may contain irrelevant or even adversarial
samples (Bhagoji et al., 2019; Bagdasaryan et al., 2020) from malicious clients (Fang et al., 2020;
Bagdasaryan et al., 2020; Tolpegin et al., 2020). Traditional solutions such as data augmentation
(Yoo et al., 2020) and re-sampling (Lin et al., 2017) prove useful for centralised training but ap-
plying them to local datasets may introduce extra noise (Cui et al., 2019) and increase the risk of
information leakage (Yu et al., 2021). Another naive solution is to directly exclude those low-value
clients with low-quality data, which, however, is often impractical because i) the quality of the data
depends on the learning task and is difficult to gauge; ii) some noisy or biased data could be useful
to the training at early stages (Feelders, 1996); and iii) sometimes low-quality data are very common
across the clients.
In Fig. 1 we demonstrate the impact of involving ”low-value” clients by running FL over 100 clients
to learn a CNN model on MNIST using the standard FedAvg algorithm. From the traces we can
see that training over clients with problematic or strongly biased data can compromise the efficiency
and efficacy of FL, resulting in an inferior global model that takes more rounds to converge.
2)	Learned representations can reflect data distribution and quality. Representation learning is
vital to the performance of deep models because learned representations can capture the intrinsic
structure of data and provide useful information for the downstream machine learning tasks (Bengio
et al., 2013). In ML research, The value of representations lies in the fact that they characterize the
domain and learning task and provide task-specific knowledge (Morcos et al., 2018; Kornblith et al.,
2019). In the context of FL, the similarity of representations are used for refining the model update
rules (Li et al., 2021; Feng & Yu, 2020), but the distributional difference between representations of
heterogeneous data is not yet explored.
Our study is also motivated by a key observation that representations from neural networks tend to
have Gaussian patterns. As a demonstration we trained two different models (LeNet-5 and ResNet-
18) on two different datasets (MNIST and CIFAR-100) separately. Fig. 2a shows the neuron-wise
distribution of representations extracted from the first dense layer (FC-1) of LeNet-5. Fig. 2b
shows the distribution of fused representations (in a channel-wise manner) extracted from a plain
convolution layer and a residual block of ResNet-18.
These observations motivate us to study the distributional property of data representations and use
it as a means to differentiate clients’ value.
2
Under review as a conference paper at ICLR 2022
LIIoOdə 9 IIoOdə≡LI8dθ
(a) Representations from FC-1 of a LeNet-5 (b) Fused representations from a standard convolu-
model after being trained for 1, 6 and 10 epochs tion layer (1st row) and a residual block (2nd row)
on MNIST.	of a ResNet-18 model trained for 100 epochs on
CIFAR-100.
Figure 2: (Preliminary experiment) Demonstration of learned representations from a distributional
perspective. The representations are generated by forward propagation in model evaluation. Each
box corresponds to a randomly sampled element in the representation vector.
1.2 Contributions
Our contributions are summarized as the following:
•	We first provide theoretical proof for the observation that data representations from neural
networks tend to follow Gaussian distribution, based on which we propose a representation
profiling and matching scheme for fast, low-cost comparison between different representa-
tion profiles.
•	We present a novel FL algorithm FedProf that adaptively adjusts clients’ participation
probability based on representation profile dissimilarity.
•	Results of extensive experiments show that FedProf reduces the number of communica-
tion rounds by up to 77%, shortens the overall training time (up to 4.5x speedup) while
increasing the accuracy of the global model by up to 2.5%.
2	Related Work
Different from traditional distributed training methods (e.g., Alistarh et al. (2017); Wu et al. (2018);
Zheng et al. (2017)), Federated Learning assumes strict constraints of data locality and limited com-
munication capacity (Konecny et al., 2016). Much effort has been made in optimizing FL and covers
a variety of perspectives including communication (Konecny et al., 2016; Niknam et al., 2020; CUi
et al., 2021), update rules (Li et al., 2020; Wu et al., 2021a; Leroy et al., 2019; Luping et al., 2019),
flexible aggregation (Wang et al., 2019; Wu et al., 2021b) and personalization (Fallah et al., 2020;
Tan et al., 2021; Deng et al., 2020).
The control of device participation is imperative in cross-device FL scenarios (Kairouz et al., 2019;
Yang et al., 2020) where the quality of local data is uncontrollable and the clients show varied
value for the training task (Tuor et al., 2020). To this end, the selection of clients is pivotal to the
convergence of FL over heterogeneous data and devices (Nishio & Yonetani, 2019; Wang et al.,
2020b; Chai et al., 2019; Acar et al., 2020). Non-uniform client selection is widely adopted in
existing studies (Li et al., 2020; Goetz et al., 2019; Cho et al., 2020; Li et al., 2019; Chen et al.,
2020b; Wang et al., 2020a) and has been theoretically proven with convergence guarantees (Chen
et al., 2020b; Li et al., 2019). Many approaches sample clients based on their performance (Nishio
& Yonetani, 2019; Chai et al., 2020) or aim to jointly optimize the model accuracy and training time
(Shi et al., 2020; Chen et al., 2020a; 2021). A popular strategy is to use loss as the information to
guide client selection (Goetz et al., 2019; Lai et al., 2021; Sarkar et al., 2020). For example, AFL
(Goetz et al., 2019) prioritizes the clients with high loss feedback on local data, but it is potentially
susceptible to noisy and unexpected data that yield illusive loss values. Data representations are
3
Under review as a conference paper at ICLR 2022
useful in the context of FL for information exchange (Feng & Yu, 2020) or objective adaptation. For
example, Li et al. (2021) introduces representation similarities into local objectives. This contrastive
learning approach guides local training to avoid model divergence. Nonetheless, the study on the
distribution of data representations is still lacking whilst its connection to clients’ training value is
hardly explored either.
3	Data Representation Profiling and Matching
In this paper, we consider a typical cross-device FL setting (Kairouz et al., 2019), in which multiple
end devices collaboratively perform local training on their own datasets Di, i = 1, 2, ..., n. The
server owns a validation dataset D* for model evaluation. Every dataset is only accessible to its
owner.
Considering the distributional pattern of data representations (Fig. 2) and the role of the global
model in FL, we propose to profile the representations of local data using the global model. In this
section, we first provide theoretical proof to support our observation that representations from neural
network models tend to follow Gaussian distribution. Then we present a novel scheme to profile data
representations and define profile dissimilarity for fast and secure representation comparison.
3.1	Gaussian Distribution of Representations
We first make the following definition to facilitate our analysis.
Definition 1 (The Lyapunov’s condition). A set of random variables {Z1, Z2, . . . , Zv} satisfy the
Lyapunov’s condition if there exists a δ such that
1v
lim 2+δ 53E [|Zk - μkF + ] = 0,	⑴
v→∞ s2+δ
k=1
where μk = E[Zk], σ2 = E[(Zk — μk)2] and S = VZPk=I σ2.
The Lyapunov’s condition can be intuitively explained as a limit on the overall variation (with |Zk -
μk ∣2+δ being the (2 + δ)-th moment of Zk) of a set of random variables.
Now we present Proposition 1 and Proposition 2. The Propositions provide theoretical support for
our representation profiling and matching method to be introduced in Section 3.2.
Proposition 1. The representations from linear operators (e.g., a pre-activation dense layer or a
plain convolutional layer) in a neural network tend to follow the Gaussian distribution if the layer’s
weighted inputs satisfy the Lyapunov’s condition.
Proposition 2. The fused representations2 from non-linear operators (e.g., a hidden layer of LSTM
or a residual block of ResNet) in a neural network tend to follow the Gaussian distribution if the
layer’s output elements satisfy the Lyapunov’s condition.
The proofs of Propositions 1 and 2 are provided in Appendices A.1 and A.2, respectively.
We base our proof on the Lyapunov’s CLT which assumes independence between the variables. The
assumption theoretically holds by using the Bayesian network concepts: let X denote the layer’s
input and Hk denote the k-th component in its output. The inference through the layer produces
dependencies X → Hk for all k . According to Local Markov Property, we have Hi independent of
any Hj (j 6= i) given X. Also, the Lyapunov’s condition is typically met when the model is properly
initialized and batch normalization is applied. Next, we discuss the proposed representation profiling
and matching scheme.
3.2 Distributional Profiling and Matching
Based on the Gaussian pattern of representations, we compress the data representations statistically
into a compact form called representation profiles. The profile produced by the global model w on
2Fused representations refer to the sum of elements in the original representations produced by a single
layer (channel-wise for a residual block).
4
Under review as a conference paper at ICLR 2022
a dataset D, denoted by RP (w, D), has the following format:
RP (w, D) ={N (μi,σ2γ}q=ι,	⑵
where q is the profile length determined by the dimensionality of the representations. For example, q
is equal to the number of kernels for channel-wise fused representations from a convolutional layer.
The tuple (μi, σ2) contains the mean and the variance of the i-th representation element.
Local representation profiles are generated by clients and sent to the server for comparison (the cost
of transmission is negligible considering each profile is only q × 8 bytes). Let RPk denote the local
profile from client k, and RP* denote the baseline profile (generated in model evaluation) on the
server. The dissimilarity between RPk and RP*, denoted by div(RPk, RP*), is defined as:
1q
div(RPk ,RP *) = q NKL(N(k)∣∣N*),	(3)
where KL(∙) denotes the Kullback-Leibler (KL) divergence. An advantage of our profiling scheme
is that a much simplified KL divergence formula can be adopted because of the Gaussian distribution
property (see Roberts & Penny (2002, Appendix B) for details), which yields:
KL(NWIN*) = log 不 + (σ(k))2 +(，—潟)2,	(4)
Eq. (4) computes the KL divergence without calculating any integral, which is computationally
cost-efficient. Besides, the computation of profile dissimilarity can be performed under the Homo-
morphic Encryption for minimum knowledge disclosure (see Appendix D for details).
4 The Training Algorithm FedProf
Our research aims to optimize the global model over a large group of clients (datasets) of disparate
training value. Given the client set U(|U| = N), let Dk denote the local dataset on client k and D*
the validation set on the server, We formulate the optimization problem in (5) where the coefficient
ρk differentiates the importance of the local objective functions Fk (w ) and depends on the data in
Dk. Our global objective is in a sense similar to the agnostic learning scenario (Mohri et al., 2019)
where a non-uniform mixture of local data distributions is implied.
N
arg min F (w) =	ρkFk(w),
w
k=1
(5)
where w is the parameter set of the global model. The coefficients {ρk}kN=1 add up to 1. Fk(w) is
client k's local objective function of training based on the loss function '(∙):
Fk(w)
TD1-τ	X	'(xi,yi;W),
|Dk | (xi,yi)∈Dk
(6)
Involving the ”right” clients facilitates the convergence. With this motivation we score each client
with λk each round based on the representation profile dissimilarity:
λk = exp( - α ∙ div(RPk(Vk),RP*(vk)),	⑺
where vk is the version of RPk (i.e., the version of the global model that client k receives) and
α is a preference factor deciding how biased the selection strategy needs to be towards the clients
with small profile dissimilarity (i.e., higher training value). With α = 0, our strategy is equivalent
to random selection. The scores connect the representation profiling and matching scheme to the
design of the selective client participation strategy adopted in our FL training algorithm FedProf,
which is outlined in Algorithm 1 (see Appendix B for a detailed version with both client and server
processes). The key steps of our algorithm are local representation profiling (line 5), baseline repre-
sentation profiling (line 9) and client scoring (line 3). Fig. 3 illustrates the workflow of the proposed
algorithm from representation profiling, matching to scheduling.
5
Under review as a conference paper at ICLR 2022
→
benchmark data
≡-
the global model
白
I Di ɪ
1 D2 1
baseline footprints
→E∣
'∖
Credit-based
client selection
I®
：o：
∖ Dn J
-→
0.75
match
& rate
> 0.49
0.15
IocaFdata representations locaΓprofiles	Client CreditS
Model
distribution
Update footprints
and credits
Local training &
model uploading
-÷
Model
aggregation
©
同
国
国

→
Round + 1
Figure 3: The workflow of the proposed FedProf algorithm.
Algorithm 1: the FEDPROF algorithm
Input: maximum number of rounds Tmaχ, iterations per round E, fraction C
ι Initialize global model W and generate baseline profile RP*
2	Collect initial representation profiles {RPk}k∈U from all clients
for round T J 1 to Tmax do
3	Update client scores {λk}k∈U and compute Λ = Pk∈U λk
4	S J Choose K = N ∙ C clients by probability distribution {λΛk}k∈u
for client k in S in parallel do
5	RPk J UPdateProfile(k, w, T 一 1)
6	Wk J loCarTraining(k, w, E)
end
7	Collect local profiles from the clients in S
8	Update w via model aggregation
9	Evaluate w and update RP *
end
10	return w
The convergence rate of FL algorithms with opportunistic client selection (sampling) has been ex-
tensively studied in the literature (Li et al., 2019; Chen et al., 2020b; Wang et al., 2019). Inspired by
these studies, we present Theorem 1 to guarantee the global model’s convergence for our algorithm.
Similar to Stich et al. (2018); Zhang et al. (2013); Li et al. (2019), we assume that {Fk}kN=1 are
L-smooth and μ-strongly convex and that in expectation, the variance of local stochastic gradients
are bounded by * 2 and their squared norms are bounded by G2 . For each local update step t we
define S(t) as the set of selected clients in the associated round.
Theorem 1. Using Partial aggregation and a strategy π that seleCts Clients by the Probability distri-
bution {qk}kN=1, the global model w(t) Converges in exPeCtation by having qk = ρk, an aggregation
interval E ≥ 1 and a deCreasing steP size (learning rate) ηt
2
μ(t+γ),
E [F(W ⑻]- F * ≤ (γ+) (丁 + ɪ+1",	⑻
where t ∈ TA = {nE|n = 1, 2,...}, Y = max{8L, E}-1, B = Pk=I Pkek + 6LΓ + 8(E― 1)2G2,
C = K E 2G2, Γ = F * ― Pk=ι Pk Fk, ∆ι = EIlW(I)- w*∣∣2, K = |S(t)| = N ∙ C.
The proof of Theorem 1 is provided in Appendix C.
6
Under review as a conference paper at ICLR 2022
5 Experiments
We conducted extensive experiments to evaluate FedProf under various FL settings. Apart from
FedAvg (McMahan et al., 2017), we also reproduced several state-of-the-art FL algorithms for
comparison. For fair comparison, the algorithms are grouped by the aggregation method (i.e., full
aggregation and partial aggregation) and configured following the hyper-parameter settings in their
papers (if any). Table 1 summarizes these FL algorithms. Note that our algorithm can adapt to both
aggregation methods.
Table 1: The implemented FL algorithms for comparison
Algorithm	Aggregation method	Rule of selection
FEDAVG (McMahan et al., 2017) CFCFM (Wu et al., 2021b) FEDAVG-RP (Li et al., 2019) FEDPROX (Li et al., 2020) FEDADAM (Leroy et al., 2019) AFL (Goetz et al., 2019) FedProf (ours)	full aggregation full aggregation partial (Scheme II) partial aggregation partial with momentum partial with momentum full/partial aggregation	random selection submission order random selection weighted random by data ratio random selection local loss valuation weighted random by score
5.1	Experiment Setup
We built our simulated FL system and implemented the algorithms based on the Pytorch framework
(Build 1.7.0). We first set up a Small-scale Task (S-Task) to learn a multi-layer feed-forward network
model from decentralized sensor data for predicting carbon monoxide (CO) and nitrogen oxides
(NOx) emissions using the GasTurbine3 dataset. Next, we set up a Large-scale Task (L-Task) to
train a CNN over a large population of user devices for image classification (EMNIST4). In both
tasks, data sharing is not allowed between any parties. The data are non-IID across the end devices.5
We introduce a diversity of noise into the local datasets on end devices to simulate the discrepancy
in data quality. The S-Task is performed over 50 sensor clients and 50% of them produce noisy data
(including 10% invalid). The population for L-Task contains 1000 end devices across which the data
spread with strong class imbalance - roughly 60% of the samples on each device fall into the same
class. 15% of the local datasets in the L-Task are irrelevant images whereas another 45% of them
are low-quality images (blurred or affected by salt-and-pepper noise). Considering the population
of the clients, the setting of the selection fraction C is based on the scale of the training participants
suggested by Kairouz et al. (2019). For both tasks, the clients are heterogeneous in terms of both
performance and communication bandwidth. More experimental settings are listed in Table 4 in
Appendix E where the environment setup is also given in details.
5.2	Evaluation Results
We evaluate the performance of our FedProf algorithm in terms of the efficacy (best accuracy
achieved) and efficiency (costs for convergence) in establishing a global model for the two tasks.
Tables 2 and 3 report the average results of multiple runs with standard deviations for our algorithm.
Figs. 4 and 5 plot the accuracy traces from the round-wise evaluations of the global model.
1)	Convergence in different aggregation modes: Our results show a great difference in convergence
rate under different aggregation modes. From Figs. 4 and 5, we observe that partial aggregation
facilitates faster convergence of the global model than full aggregation, which is consistent with the
observations made by Li et al. (2019). The advantage is especially obvious in the L-Task where
partial aggregation requires much fewer communication rounds to reach the 90% accuracy. Our
FedProf algorithm yields the fastest convergence in both groups of comparison for both tasks
because selective participation benefits both aggregation methods.
3https://archive.ics.uci.edu/ml/datasets/Gas+Turbine+CO+and+NOx+Emission+Data+Set
4https://www.nist.gov/itl/products-and-services/emnist-dataset. We use the digits subset of EMNIST.
5In the S-Task, local datasets are of different sizes that follow a Gaussian distribution. In the L-Task, local
data are largely imbalanced where around 60% of the samples on each client have the same class label.
7
Under review as a conference paper at ICLR 2022
Table 2: The results of running the S-Task. The best accuracy is achieved by running for long
enough. Other metrics are recorded upon reaching the target accuracy (80% for the S-Task).
Full aggregation
C=0.2	C=0.3
	Best acc	For accuracy@0.8			Best acc	For accuracy@0.8		
		Rounds	Time(s)	E(Wh)		Rounds	Time(s)	E(Wh)
FedAvg	0.805	56	2869.66	2.87	0.806	52	3160.01	4.12
CFCFM	0.806	39	1230.81	1.61	0.802	42	1495.34	2.91
Ours	0.824	16	803.74	0.80	0.827	12	701.18	0.94
(std.)	6.13E-03	2.06	139.76	0.14	8.01E-03	2.94	122.63	0.20
			Partial aggregation					
		C=0.2				C=0.3		
	Best acc	For accuracy@0.8			Best acc	For accuracy@0.8		
		Rounds	Time(s)	E(Wh)		Rounds	Time(s)	E(Wh)
FedAvg-RP	0.819	13	735.48	0.71	0.817	8	466.90	0.64
FedProx	0.821	16	899.93	0.79	0.810	16	841.65	1.08
FedAdam	0.818	8	438.20	0.42	0.819	12	667.00	0.94
AFL	0.816	6	313.81	0.30	0.813	6	298.81	0.42
Ours	0.844	5	283.76	0.27	0.841	4	235.22	0.35
(std.)	1.70E-03	0.47	30.69	0.03	7.07E-03	1.70	90.12	0.14
Table 3: The results of running the L-Task. The best accuracy is achieved by running for long
enough. Other metrics are recorded upon reaching the target accuracy (90% for the L-Task).
Full aggregation
C=0.05	C=0.1
	Best acc	For accuracy@0.9			Best acc	For accuracy@0.9		
		Rounds	Time(s)	E(Wh)		Rounds	Time(s)	E(Wh)
FedAvg	0.906	213	10407.30	60.01 ^^	0.929	76	3894.26	43.16
CFCFM	0.923	251	8645.17	61.37	0.932	75	2675.56	37.62
Ours	0.926	98	4846.15	28.22	0.945	45	2295.03	25.98
(std.)	8.16E-05	1.89	96.57	0.43	4.71E-04	0.82	29.46	0.01
			Partial aggregation					
		C=0.05				C=0.1		
	Best acc	For accuracy@0.9			Best acc	For accuracy@0.9		
		Rounds	Time(s)	E(Wh)		Rounds	Time(s)	E(Wh)
FedAvg-RP	0.937	12	572.90	3.29^^	0.938	12	603.94	6.57
FedProx	0.936	13	640.01	3.58	0.942	11	559.16	5.91
FedAdam	0.940	12	599.96	3.47	0.939	12	608.85	6.76
AFL	0.952	10	479.73	2.73	0.944	9	476.62	5.26
Ours	0.962	8	383.94	2.26	0.962	8	413.16	4.64
(std.)	9.43E-04	0.471	17.67	0.15	8.16E-04	0.47	11.64	0.03
2)	Best accuracy of the global model: Through the training process of FL, the global model is
evaluated each round on the server. The best global model obtained thus far is stored on the server.
As shown in the 2nd column of Tables 2 and 3, our FedProf algorithm improves the accuracy
achieved by 2.5% when compared against the baselines (FedAvg and FedAvg-RP). The AFL
algorithm uses a loss-oriented client selection strategy, which shows the closest performance to our
algorithm in the L-Task but the worst accuracy in the S-Task.
3)	Total communication rounds for convergence: The number of communication rounds required for
reaching convergence is a key indicator to the efficiency of FL. In the S-Task, our algorithm takes
less than half the communication rounds required by other algorithms in most cases. In the L-Task
with C=0.05, our algorithm reaches 90% accuracy within 100 rounds whilst FEDAVG and CFCFM
need more than 200. In this case, FedProf also achieves approximately 7% higher accuracy in
50 rounds. Partial aggregation turns out to be much more communication-efficient: FedAvg-RP
8
Under review as a conference paper at ICLR 2022
- - - - O
64288642
7777
Ooo Oooo
e∙ln8<
Partial aggregation, C=0.2
20	40	60	80	100
Communication rounds
&B」n8<
0.84
0.82
0.8
0.78
0.76
0.74
0.72
(a)	(b)
Figure 4: The traces of evaluation accuracy of the global model through 100 rounds in the S-Task
using (a) the full-aggregation method, and (b) the partial-aggregation method.
0.1
0	50 100 150 200 250 300	0	50 100 150 200 250 300
Communication rounds	Communication rounds
0.8
Partial aggregation, C=0.05
0.2
0.3
0 5 10 15 20 25 30 35 40 45 50
Communication rounds
AOR.JnOOV
Partial aggregation, C=0.10
0.1
0 5 10 15 20 25 30 35 40 45 50
Communication rounds
(a)	(b)
Figure 5: The traces of evaluation accuracy of the global model in the L-Task using (a) the full-
aggregation method (through 300 rounds), and (b) the partial aggregation method (through 50
rounds).
needs 8 rounds to reach the accuracy target for the S-Task and 12 rounds for the L-Task, whilst our
algorithm reduces the numbers to 5 and 8, respectively.
4)	Total time needed for convergence: The overall time consumption is closely related to total com-
munication rounds needed for convergence and the time cost for each round. Algorithms requir-
ing more rounds to converge typically take longer to reach the accuracy target except the case of
CFCFM, which priorities the clients that work faster. Using FedAvg as the baseline, CFCFM
accelerates the training process by 2.1x whilst our algorithm provides a 4.5x speedup for achieving
the same target accuracy (S-Task, C=0.3). FEDPROF also has a clear advantage over FEDAVG-
RP, FedProx and FedAdam in the partial aggregation group where it shows a 2.6x speedup over
FEDAVG-RP in the S-Task with C=0.2.
5)	Energy consumption of end devices: A main concern for the end devices, as the participants of
FL, is their power usage (Watt hours). Full aggregation methods experience slower convergence and
thus endure higher energy cost on the devices. For example, with a small selection fraction C=0.05
in the L-Task, FedAvg and CFCFM consume over 60Wh to reach the target accuracy. In this case,
our algorithm reduces the cost by more than a half (28.22Wh). With the partial aggregation mode,
the reduction by our algorithm is up to 62% (S-Task, C = 0.2). Considering all the cases, FEDPROF
achieves the target accuracy with the least energy cost, providing an reduction of 29% 〜53%.
6)	Differentiated participation with FEDPROF: Fig. 6 reflects the preference of our selection strat-
egy. In the S-Task we can observe that the clients with useless samples or noisy data get significantly
less involved (<10 on average) in training. In the L-Task our algorithm also effectively limits (ba-
sically excludes) the clients who owns the image data of poor quality (i.e., irrelevant or severely
blurred), whereas the clients with moderately noisy images are selected with reduced frequency as
compared to those with normal data. A potential issue of having the preference towards some of
the devices is about fairness. Nonetheless, one can apply our algorithm together with an incentive
mechanism (e.g., Yu et al. (2020)) to address it.
9
Under review as a conference paper at ICLR 2022
60
o
θ40
,o
ra
d
20 20
⅛
CL
0
Full participation, FedProf
-clients with irrelevant '	j clients with normal d ta-
or noisy data	ι ■	_	■	_
L.」I・
0	5	10	15	20	25	30	35	40	45	50
(a)	(b)
Figure 6: Total counts by client of participation (i.e., being selected) in (a) the S-Task and (b) the
L-Task. For clarity, clients are indexed according to their local data quality.
6 Conclusion
Federated learning provides a privacy-preserving approach to decentralized training but is vulnerable
to the heterogeneity and uncertain quality of on-device data. In this paper, we use a novel approach
to address the issue without violating the data locality restriction. We first provide key insights for
the distribution of data representations and then develop a dynamic data representation profiling and
matching scheme. Based on the scheme we propose a selective FL training algorithm FedProf
that adaptively adjusts clients’ participation chance based on their profile dissimilarity. We have
conducted extensive experiments on public datasets under various environment settings. Evaluation
results show that our algorithm significantly improves the efficiency of FL and reduces the time and
energy costs for the global model to converge.
References
Durmus Alp Emre Acar, Yue Zhao, Ramon Matas, Matthew Mattina, Paul Whatmough, and
Venkatesh Saligrama. Federated learning based on dynamic regularization. In International Con-
ference on Learning Representations, 2020.
Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic. Qsgd:
Communication-efficient sgd via gradient quantization and encoding. Advances in Neural In-
formation Processing Systems, 30:1709-1720, 2017.
Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly Shmatikov. How to
backdoor federated learning. In International Conference on Artificial Intelligence and Statistics,
pp. 2938-2948. PMLR, 2020.
Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new
perspectives. IEEE transactions on pattern analysis and machine intelligence, 35(8):1798-1828,
2013.
Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin Calo. Analyzing federated
learning through an adversarial lens. In International Conference on Machine Learning, pp. 634-
643. PMLR, 2019.
Patrick Billingsley. Probability and measure. John Wiley & Sons, 2008.
Aaron Carroll, Gernot Heiser, et al. An analysis of power consumption in a smartphone. In USENIX
annual technical conference, volume 14, pp. 21-21. Boston, MA, 2010.
10
Under review as a conference paper at ICLR 2022
Zheng Chai, Hannan Fayyaz, Zeshan Fayyaz, Ali Anwar, Yi Zhou, Nathalie Baracaldo, Heiko Lud-
wig, and Yue Cheng. Towards taming the resource and data heterogeneity in federated learning.
In 2019 { USENIX} Conference on Operational Machine Learning (OpML 19), pp.19-21, 2019.
Zheng Chai, Ahsan Ali, Syed Zawad, Stacey Truex, Ali Anwar, Nathalie Baracaldo, Yi Zhou, Heiko
Ludwig, Feng Yan, and Yue Cheng. Tifl: A tier-based federated learning system. In Proceedings
of the 29th International Symposium on High-Performance Parallel and Distributed Computing,
pp. 125-136, 2020.
Mingzhe Chen, H Vincent Poor, Walid Saad, and Shuguang Cui. Convergence time optimization for
federated learning over wireless networks. IEEE Transactions on Wireless Communications, 20
(4):2457-2471, 2020a.
Mingzhe Chen, Nir Shlezinger, H Vincent Poor, Yonina C Eldar, and Shuguang Cui.
Communication-efficient federated learning. Proceedings of the National Academy of Sciences,
118(17), 2021.
Wenlin Chen, Samuel Horvath, and Peter Richtarik. Optimal client sampling for federated learning.
arXiv preprint arXiv:2010.13723, 2020b.
Yae Jee Cho, Jianyu Wang, and Gauri Joshi. Client selection in federated learning: Convergence
analysis and power-of-choice selection strategies. arXiv preprint arXiv:2010.01243, 2020.
Laizhong Cui, Xiaoxin Su, Yipeng Zhou, and Yi Pan. Slashing communication traffic in federated
learning by transmitting clustered model updates. IEEE Journal on Selected Areas in Communi-
cations, 2021.
Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. Class-balanced loss based
on effective number of samples. In Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition, pp. 9268-9277, 2019.
Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Adaptive personalized federated
learning. arXiv preprint arXiv:2003.13461, 2020.
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning with the-
oretical guarantees: A model-agnostic meta-learning approach. Advances in Neural Information
Processing Systems, 33:3557-3568, 2020.
Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Gong. Local model poisoning attacks to
byzantine-robust federated learning. In 29th {USENIX} Security Symposium ({USENIX} Se-
curity 20), pp. 1605-1622, 2020.
AJ Feelders. Learning from biased data using mixture models. In KDD, pp. 102-107, 1996.
Siwei Feng and Han Yu. Multi-participant multi-class vertical federated learning. arXiv preprint
arXiv:2001.11154, 2020.
Craig Gentry. Fully homomorphic encryption using ideal lattices. In Proceedings of the forty-first
annual ACM symposium on Theory of computing, pp. 169-178, 2009.
Jack Goetz, Kshitiz Malik, Duc Bui, Seungwhan Moon, Honglei Liu, and Anuj Kumar. Active
federated learning. arXiv preprint arXiv:1909.12641, 2019.
Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, Francoise Beaufays, Sean
Augenstein, HUbert Eichner, Chloe Kiddon, and Daniel Ramage. Federated learning for mobile
keyboard prediction. arXiv preprint arXiv:1811.03604, 2018.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
Peter Kairouz, H Brendan McMahan, Brendan Avent, AUrelien Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Ad-
vances and open problems in federated learning. arXiv preprint arXiv:1912.04977, 2019.
11
Under review as a conference paper at ICLR 2022
Jakub Konecny, H Brendan McMahan, Felix X Yu, Peter Richtarik, Ananda Theertha Suresh, and
Dave Bacon. Federated learning: Strategies for improving communication efficiency. arXiv
preprint arXiv:1610.05492, 2016.
Simon Kornblith, Mohammad Norouzi, Honglak Lee, and Geoffrey Hinton. Similarity of neural
network representations revisited. In International Conference on Machine Learning, pp. 3519—
3529. PMLR, 2019.
Fan Lai, Xiangfeng Zhu, Harsha V Madhyastha, and Mosharaf Chowdhury. Oort: Efficient federated
learning via guided participant selection. In 15th {USENIX} Symposium on Operating Systems
Design and Implementation ({ OSDI} 21), pp. 19-35, 2021.
Don S Lemons. An Introduction to Stochastic Processes in Physics. Johns Hopkins University Press,
2003.
David Leroy, Alice Coucke, Thibaut Lavril, Thibault Gisselbrecht, and Joseph Dureau. Federated
learning for keyword spotting. In ICASSP 2019-2019 IEEE International Conference on Acous-
tics, Speech and Signal Processing (ICASSP), pp. 6341-6345. IEEE, 2019.
Qinbin Li, Bingsheng He, and Dawn Song. Model-contrastive federated learning. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10713-10722, 2021.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated optimization in heterogeneous networks. In The 3rd MLSys Conference, 2020.
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of
fedavg on non-iid data. In International Conference on Learning Representations, 2019.
Wei-Chao Lin, Chih-Fong Tsai, Ya-Han Hu, and Jing-Shang Jhang. Clustering-based undersampling
in class-imbalanced data. Information Sciences, 409:17-26, 2017.
WANG Luping, WANG Wei, and LI Bo. Cmfl: Mitigating communication overhead for feder-
ated learning. In 2019 IEEE 39th International Conference on Distributed Computing Systems
(ICDCS), pp. 954-964. IEEE, 2019.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial Intelli-
gence and Statistics (AISTATS), pp. 1273-1282. PMLR, 2017.
Robert van der Meulen. What edge computing means for infrastructure and opera-
tions leaders. https://www.gartner.com/smarterwithgartner/what-edge-computing-means-for-
infrastructure-and-operations-leaders/, 2018. Accessed: 2021-07-10.
Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. Agnostic federated learning. In Interna-
tional Conference on Machine Learning, pp. 4615-4625. PMLR, 2019.
Ari S Morcos, Maithra Raghu, and Samy Bengio. Insights on representational similarity in neural
networks with canonical correlation. In Proceedings of the 32nd International Conference on
Neural Information Processing Systems, pp. 5732-5741, 2018.
Solmaz Niknam, Harpreet S Dhillon, and Jeffrey H Reed. Federated learning for wireless commu-
nications: Motivation, opportunities, and challenges. IEEE Communications Magazine, 58(6):
46-51, 2020.
Takayuki Nishio and Ryo Yonetani. Client selection for federated learning with heterogeneous
resources in mobile edge. In ICC 2019-2019 IEEE International Conference on Communications
(ICC), pp. 1-7. IEEE, 2019.
Stephen J Roberts and Will D Penny. Variational bayes for generalized autoregressive models. IEEE
Transactions on Signal Processing, 50(9):2245-2257, 2002.
Dipankar Sarkar, Ankur Narang, and Sumit Rai. Fed-focal loss for imbalanced data classification in
federated learning. arXiv preprint arXiv:2011.06283, 2020.
12
Under review as a conference paper at ICLR 2022
Wenqi Shi, Sheng Zhou, and Zhisheng Niu. Device scheduling with fast convergence for wireless
federated learning. In ICC 2020-2020 IEEE International Conference on Communications (ICC),
pp. 1-6. IEEE, 2020.
Jie Song, Tiantian Li, Zhi Wang, and Zhiliang Zhu. Study on energy-consumption regularities of
cloud computing systems by a novel evaluation model. Computing, 95(4):269-287, 2013.
Sebastian U Stich, Jean-Baptiste Cordonnier, and Martin Jaggi. Sparsified sgd with memory. Ad-
vances in Neural Information Processing Systems, 31:4447-4458, 2018.
Alysa Ziying Tan, Han Yu, Lizhen Cui, and Qiang Yang. Towards personalized federated learning.
arXiv preprint arXiv:2103.00710, 2021.
Vale Tolpegin, Stacey Truex, Mehmet Emre Gursoy, and Ling Liu. Data poisoning attacks against
federated learning systems. In European Symposium on Research in Computer Security, pp. 480-
501. Springer, 2020.
Nguyen H Tran, Wei Bao, Albert Zomaya, Minh NH Nguyen, and Choong Seon Hong. Federated
learning over wireless networks: Optimization model design and analysis. In IEEE INFOCOM
2019-IEEE Conference on Computer Communications, pp. 1387-1395. IEEE, 2019.
Tiffany Tuor, Shiqiang Wang, Bong Jun Ko, Changchang Liu, and Kin K. Leung. Overcoming noisy
and irrelevant data in federated learning. arXiv preprint arXiv:2001.08300, 2020.
Hao Wang, Zakhary Kaplan, Di Niu, and Baochun Li. Optimizing federated learning on non-iid data
with reinforcement learning. In IEEE INFOCOM 2020-IEEE Conference on Computer Commu-
nications, pp. 1698-1707. IEEE, 2020a.
Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor. Tackling the objective in-
consistency problem in heterogeneous federated optimization. arXiv preprint arXiv:2007.07481,
2020b.
Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K Leung, Christian Makaya, Ting He, and
Kevin Chan. Adaptive federated learning in resource constrained edge computing systems. IEEE
Journal on Selected Areas in Communications, 37(6):1205-1221, 2019.
Jiaxiang Wu, Weidong Huang, Junzhou Huang, and Tong Zhang. Error compensated quantized
sgd and its applications to large-scale distributed optimization. In International Conference on
Machine Learning, pp. 5325-5333. PMLR, 2018.
Wentai Wu, Ligang He, Weiwei Lin, and Rui Mao. Accelerating federated learning over reliability-
agnostic clients in mobile edge computing systems. IEEE Transactions on Parallel and Dis-
tributed Systems, 32(7):1539-1551, 2021a.
Wentai Wu, Ligang He, Weiwei Lin, Rui Mao, Carsten Maple, and Stephen A Jarvis. Safa: a
semi-asynchronous protocol for fast federated learning with low overhead. IEEE Transactions on
Computers, 70(5):655-668, 2021b.
Haibo Yang, Minghong Fang, and Jia Liu. Achieving linear speedup with partial worker partici-
pation in non-iid federated learning. In International Conference on Learning Representations,
2020.
Jaejun Yoo, Namhyuk Ahn, and Kyung-Ah Sohn. Rethinking data augmentation for image super-
resolution: A comprehensive analysis and a new strategy. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition, pp. 8375-8384, 2020.
Da Yu, Huishuai Zhang, Wei Chen, Jian Yin, and Tie-Yan Liu. How does data augmentation affect
privacy in machine learning? In Proceedings of the AAAI Conference on Artificial Intelligence,
volume 35, pp. 10746-10753, 2021.
Han Yu, Zelei Liu, Yang Liu, Tianjian Chen, Mingshu Cong, Xi Weng, Dusit Niyato, and Qiang
Yang. A fairness-aware incentive scheme for federated learning. In Proceedings of the AAAI/ACM
Conference on AI, Ethics, and Society, pp. 393-399, 2020.
13
Under review as a conference paper at ICLR 2022
Yuchen Zhang, John C Duchi, and Martin J Wainwright. Communication-efficient algorithms for
statistical optimization. The Journal of Machine Learning Research, 14(1):3321-3363, 2013.
Shuxin Zheng, Qi Meng, Taifeng Wang, Wei Chen, Nenghai Yu, Zhi-Ming Ma, and Tie-Yan Liu.
Asynchronous stochastic gradient descent with delay compensation. In International Conference
on Machine Learning, pp. 4120-4129. PMLR, 2017.
14
Under review as a conference paper at ICLR 2022
A	Proof of Propositions
A.1 Proof of Proposition 1
Without loss of generality, we provide the proof of Proposition 1 for the pre-activation represen-
tations from dense (fully-connected) layers and standard convolutional layers, respectively. The
results can be easily extended to other linear neural operators.
Dense layers
Proof. Let Ω = {neu1,neu2,…,neuq } denote a dense layer (with q neurons) of any neural network
model and Hk denote the pre-activation output of neuk in Ω. We first provide the theoretical proof
to support the observation that Hk tends to follow the Gaussian distribution.
Let χ = Rv denote the input feature space (with v features) and assume the feature Xi (which is a
random variable) follows a certain distribution Zi (μi, σ2) (notnecessarily Gaussian) with finite mean
μi = E[Xi] and variance σi = E[Xi - μ/. For each neuron neuk, let Wk = [wk,ι wk,2... wk,v]
denote the neuron’s weight vector, bk denote the bias, and Zk,i = Xiwk,i denote the i-th weighted
input. Let Hk denote the output of neuk . During the forward propagation, we have:
Hk = Xw kT + bk
v
=	Xiwk,i + bk
i=1
v
= XZk,i+bk.	(9)
i=1
Apparently Zk,i is a random variable because Zk,i = Xiwk,i (where the weights wk,i are constants
during a forward pass), thus Hk is also a random variable according to Eq. (9).
In an ideal situation, the inputs variables X1, X2, . . . , Xv may follow a multivariate Gaussian
distribution, in which case Proposition 1 automatically holds due to the property of multivari-
ate normal distribution that every linear combination of the components of the random vector
(X1 , X2 , . . . , Xv )T follows a Gaussian distribution (Lemons, 2003). In other words, Hk =
X1wk,1 + X2wk,2 + . . . + Xvwk,v + bk is a normally distributed variable since wk,i and bk
(k = 1, 2, . . . , v) are constants in the forward propagation. A special case for this condition is that
X1,X2,...,Xv are independent on each other and Xi follows a Gaussian distribution N(μi, σ2)
for all i = 1, 2, . . . , v. In this case, by the definition of Zk,i, we have:
Zk,i = Xiwk,i 〜N(wk,iμi, (wk,iσi) ),	(IO)
where Z1, Z2, . . . , Zv are independent on each other. Combining Eqs. (9) and (10), we have:
Hk 〜N( E wk,iμi + bk, E(wkRi)2),	(11)
i=1	i=1
For more general cases where X1 , X2 , . . . , Xv are not necessarily normally distributed, we assume
the weighted inputs Zk,i of the dense layer satisfy the Lyapunov’s condition (see definition 1). As
a result, we have the following according to the Central Limit Theorem (CLT) (Billingsley, 2008)
considering that Xi follows Zi(μi, σf):
1v
一ɪ2 (Zk,i - wk,iMi) → N(O, I)	(12)
sk
i=1
where Sk = Jp：=i (wk,iσ,2 and N(0,1) denotes the standard normal distribution. Equivalently,
for every neuk we have:
vv
EZk,i → N(E wk,i〃i,sk)
i=1 i=1
(13)
15
Under review as a conference paper at ICLR 2022
Combining Eqs. (9) and (13) we can derive that:
v
Hk → N (X wk,iΝi + bk, Sk ),	(14)
i=1
which means that Hk(k = 1, 2, . . . , v) tend to follow Gaussian distribution and proves our Proposi-
tion 1 for fully-connected layers.	□
Convolutional layers
Proof. Standard convolution in CNNs is also a linear transformation of the input feature space and
its main difference from dense layers rests on the restricted size of receptive field. Without loss of
generality, we analyze the representation (output) of a single kernel. To facilitate our analysis for
convolutional layers, let C denote the number of input channels and K denote the kernel size. For
ease of presentation, we define a receptive field mapping function Θ(k, i, j) that maps the positions
(k for channel index, i and j for indices on the same channel) of elements in the feature map (i.e.,
the representations) to the input features. For the k-th kernel, let Wk denote its weight tensor (with
Wk,c being the weight matrix for channel c) and bk its bias.
Given the corresponding input patch XΘ(k,i,j), The element Hk,i,j of the representations from a
convolutional layer can be formulated as:
CKK
Hk,i,j = X X X XΘ(k,i,j) ◦ Wk,c i0,j0+bk,	(15)
where ◦ denotes Hadamard product. The three summations reduce the results of element-wise
product between the input patch and the k-th kernel to the correspond representation element
Hk,i,j in the feature map. For ease of presentation, here we use the notation Zc(,ki)0,j0 to replace
(Xθ(k,i,j) ◦ Wk,c)i0 j0 and let ZMjj ,。2分，j) be the distribution that Zck j follows. Note that Z
can be any distribution since we do not make any distributional assumption on Zc(,ki)0,j0 .
With the notations, Eq. (15) can be rewritten in a similar form to Eq. (9):
CKK
Hk,i,j = X X X Zc(,ki)0,j0 + bk.	(16)
c=1 i0=1 j0=1
We use the condition that the random variables Zc(,ki)0,j0 satisfy the Lyapunov’s condition, i.e., there
exists a δ such that
CKK
c×Km→∞ K ΣΣΣ E g%，-…l2+δi =0,	(17)
c=1 i0=1 j0=1
Where S=qPC=IPK=1 PK=I σ2,io,jo.
Then according to the Lyapunov CLT, the following holds:
Hk,i,j→ N(	X …+ bk, X	σ"o),	(18)
c,i0,j0∈Θ(k,i,j)	c,i0,j0∈Θ(k,i,j)
which proves our Proposition 1 for standard convolution layers.	□
A.2 Proof of Proposition 2
Without loss of generality, we prove Proposition 2 for the fused representations from the LSTM
layer and the residual block of ResNet models, respectively. The results can be easily extended to
other non-linear neural operators.
LSTM
16
Under review as a conference paper at ICLR 2022
Proof. Long Short-Term Memory (LSTM) models are popular for extracting useful representations
from sequence data for tasks such as speech recognition and language modeling. Each LSTM layer
contains multiple neural units. For the k-th unit, it takes as input the current input feature vector
Xt = (Xt,1, Xt,2, . . .), hidden state vector Ht-1 and its cell state ct-1,k. The outputs of the unit are
its new hidden state ht,k and cell state ct,k. In this paper, we study the distribution of ht,k. Multiple
gates are adopted in an LSTM unit: by it,k, ft,k, gt,k and ot,k we denote the input gate, forget gate,
cell gate and output gate of the LSTM unit k at time step t. The update rules of these gates and the
cell state are:
it,k = sigmoid(W(i)k [Ht-1 , Xt] + b(i)k),
ft,k = sigmoid(W(f)k [Ht-1 , Xt] + b(f)k),
gt,k = tanh(W(g)k [Ht-1 , Xt] + b(g)k),
ot,k = sigmoid(W(o)k [Ht-1 , Xt] + b(o)k),
ct,k = ft,k ∙ ct-1,k + it,k ∙ gt,k,	(19)
where the W(i)k, W(f)k, W(g)k and W(o)k are the weight parameters andb(i)k, b(f)k, b(g)k and b(o)k
are the bias parameters for the gates.
The output of the LSTM unit ht,k is calculated as the following:
ht,k = ot,k ∙ tanh(ct,k).	(20)
Using the final hidden states hT,k (with T being the length of the sequence) as the elements of the
layer-wise representation, we apply the following layer-wise fusion to further produce H over all
the hT,k in a single LSTM layer:
d
H=XhT,k,	(21)
k=1
where d is the dimension of the LSTM layer. Again, by Z (μk, σk) We denote the distribution of
hT,k (where the notation T is dropped here since it is typically a fixed parameter). With {hT,k|k =
1, 2, . . . , d} satisfying the Lyapunov’s condition and by Central Limit Theorem H, tends to follow
the Gaussian distribution:
dd
H → N(X μk, Xσ2),	(22)
i=1	i=1
which proves the Proposition 2 for layer-wise fused representations from LSTM.	□
Residual blocks
Proof. Residual blocks are the basic units in the Residual neural network (ResNet) architecture (He
et al., 2016). A typical residual block contains two convolutional layers with batch normalization
(BN) and uses the ReLU activation function. The input of the whole block is added to the output
of the second convolution (after BN) through a skip connection before the final activation. Since
the convolution operators are the same as we formulate in the second part of Section A.1, here we
use the notation Ψ(X) to denote the sequential operations of convolution on X followed by BN,
i.e., Ψ(X) , BN(Conv(X)). Again, we reuse the receptive field mapping Θ(k, i, j) as defined in
Section A.1 to position the inputs of the residual block corresponding to the element Zk,i,j in the
output representation of the whole residual block.
Let X denote the input of the residual block and Zk,i,j denote an element in the output tensor of the
whole residual block. Then we have:
Zk,i,j = f (Xk,i,j + BN(COnv(MBN(COnv(Xe(k,i,j)X»"
=f (Xk,i,j + Ψ(f(Ψ(Xθ(k,i,j))))}	(23)
where f is the activation function (ReLU).
17
Under review as a conference paper at ICLR 2022
We perform channel-wise fusion on the representation from the residual block to produce Hk for
the k-th channel:
dH dW
Hk = XXZk,i,j,	(24)
i=1 j=1
where dH and dW are the dimensions of the feature map and k is the channel index.
Let Z(μk,i,j, σk 分 j) denote the distribution that Zk,i,j follows. Then We apply the Lyapunov's Con-
dition to the representation elements layer-wise, i.e.,
1	dH dW
lim 2+δ XX E [|Zk,i,j - μk,i,j『+[ = 0,	(25)
dW ×dH →∞ s +
k	i=1 j=1
where Sk = √PH1PWlZj.
With the above condition satisfied, by CLT Hk (the fused representation on channel k) tends to
follow the Gaussian distribution:
dH dW	dH dW
Hk -→dN(XX
μk,i,j，XXσk2,i,j),	(26)
which proves the Proposition 2 for channel-wise fused representations from any residual block. □
B	Pseudo-code of FedProf (detailed version)
See Algorithm 2 for a complete version of the proposed training algorithm.
C Convergence Analysis
In this section we provide the proof of the proposed Theorem 1. The analysis is mainly based on the
results provided by Li et al. (2019). We first introduce several notations to facilitate the analysis.
C.1 Notations
Let U (|U| = N) denote the full set of clients and S(t) (|S(t)| = K) denote the set of clients
selected for participating. By wk (t) we denote the local model on client k at time step t. We define
an auxiliary sequence vk (t) for each client to represent the immediate local model after a local SGD
update. Note that vk (t) is updated from vk(t - 1) with learning rate ηt-1:
Vk ⑴=wk (t - I)- ηt-1^Fk (Wk (t - 1), ξk,t-1),	(27)
where RFk(Wk (t - 1),ξk,t-ι) is the stochastic gradient computed over a batch of data ξk,t-ι drawn
from Dk with regard to wk(t - 1).
We also define two virtual sequences v(t) = PN=I PkVk (t) and W(t) = Aggregate({vk (t)}k∈s(t))
for every time step t (Note that the actual global model w(t) is only updated at the aggregation steps
TA = {E, 2E, 3E, . . .}). Given an aggregation interval E ≥ 1, we provide the analysis for the
partial aggregation rule that yields w(t) as:
W(t) = KK X Vk(t),	(28)
k∈S(t)
where S(t) (|S(t) | = K) is the selected set of clients for the round dE] that contains step t. At the
aggregation steps TA, w(t) is equal to w(t), i.e., w(t) = w(t) if t ∈ Ta.
To facilitate the analysis, we assume each client always performs model update (and synchroniza-
tion) to produce Vk (t) and v(t) (but obviously it does not affect the resulting W and w for k ∈ S(t)).
Vk(t), ift ∈/ TA
wk (t)=fw(t), if t ∈ TA	(29)
18
Under review as a conference paper at ICLR 2022
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
Algorithm 2: the FEDPROF protocol (detailed version)
Input : maximum number of rounds Tmax,local iterations per round E, client set U, client
fraction C, validation set D*;
Output: the global model w
// Server process: running on the server
Initialize global model w using a seed
V J 0 // version of the latest global model
Broadcast the seed to all clients for identical model initialization
Collect initial profiles {RPk}k∈U from all the clients
vk J 0, ∀k ∈ U
Generate initial baseline profile RP* (0) on D*
K J |U| ∙ C
for round T J 1 to Tmax do
Calculate div(RPk(vk), RP *(vk)) for each client k
Update client scores {λk}k∈U and compute Λ = Pk∈U λk
S J Choose K clients by probability distribution {*}k∈u
Distribute w to the clients in S
for client k in S in parallel do
vk J v, ∀k ∈ S
RPk (vk ) J updateProfile(k, w, v)
wk J localTraining(k, w, E)
end
Collect local profiles from the clients in S
Update w via model aggregation
vJT
Evaluate w and generate RP * (v)
end
return w
// Client process: running on client k
updateProfile(k, w, v):
Generate RPk on Dk with the global w received
Label profile RPk with version number v
Return RPk
return
localTraining(k, w, E):
wk J w
for step e J 1 to E do
I Update Wk using gradient-based method
end
Return wk
return
For ease of presentation, We also define two virtual gradient sequences: g(t) =
PN=ι PkVFk(Wk(t)) and g(t) = PN=I PkRFk(Wk(t),ξk,t). Thus we have E[g(t)] = g(t) and
V(t) = W(t — 1) 一 ηt-ιg(t 一 1).
C.2 Assumptions
We formally make four assumptions to support our analysis of convergence. Assumptions 1 and
2 are standard in the literature (Li et al., 2019; Wang et al., 2019; Cho et al., 2020) defining the
convexity and smoothness properties of the objective functions. Assumptions 3 and 4 bound the
variance of the local stochastic gradients and their squared norms in expectation, respectively. These
two assumptions are also made in by Li et al. (2019).
Assumption 1. F1, F2, . . . , FN are L-smooth, i.e., for any k ∈ U, x and y: Fk(y) ≤ Fk (x) + (y 一
X)T VFk (x) + L2 Ily - xk2
19
Under review as a conference paper at ICLR 2022
It is obvious that the global objective F is also L-smooth as a linear combination of F1, F2, . . . , FN
with ρ1 , ρ2 , . . . , ρN being the weights.
Assumption 2. Fι, F2,..., FN are μ-strongly convex, i.e., for all k ∈ U and any x, y: Fk(y) ≥
Fk(x) + (y — X)TVFk(x) + μky - xk2
Assumption 3. The variance of local stochastic gradients on each device is bounded: For all k ∈ U,
EkVFk(wk(t),ξt,k) -Fk(wk(t))k2 ≤ 2
Assumption 4. The squared norm of local stochastic gradients on each device is bounded: For all
k∈ U,EkVFk(wk(t),ξt,k)k2 ≤ G2
C.3 Key Lemmas
To facilitate the proof of our main theorem, we first present several key lemmas.
Lemma 1 (Result of one SGD step). Under Assumptions 1 and 2 and with η < 芸,for any t it
holds true that
N
Ekv(t+I)-W*k2 ≤ (I-ηt^EkW⑴-w*k2+η2Ekgt-gtk2+6Lη2r+2E[ ^X Pk kwk⑴一w⑴ k2],
k=1
(30)
where γ = F* - PN=ι PkFk.
Lemma 2 (Gradient variance bound). Under Assumption 3, one can derive that
N
Ekgt- gtk2 ≤ XPk低.	(31)
k=1
Lemma 3 (Bounded divergence of Wk (t)). Assume Assumption 4 holds and a non-increasing step
size ηt s.t. ηt ≤ 2ηt+E for all t = 1, 2, . . ., it follows that
N
e[XPkkwk(t)- w(t)k[ ≤ 4η2(E - 1)2G2.	(32)
k=1
Lemmas 1, 2 and 3 hold for both full and partial participation and are independent of the client
selection strategy. We refer the readers to Li et al. (2019) for their proofs and focus our analysis on
opportunistic selection.
The next two lemmas give important properties of the aggregated model W as a result of partial
participation and non-uniform client selection/sampling.
Lemma 4 (Unbiased aggregation). For any aggregation step t ∈ TA and with qk = Pk in the
selection of S(t), it follows that
ES(t)[w⑴] = v⑴.
(33)
Proof. First, we present a key observation given by Li et al. (2019) as an important trick to handle
the randomness caused by client selection with probability distribution {qk}kN=1. By taking the
expectation over S(t), it follows that
N
ES(t) X Xk = KES(t) [Xk] = K XqkXk.
k∈S(t)	k=1
(34)
20
Under review as a conference paper at ICLR 2022
Let qk = Pk, take the expectation of w(t) over S(t) and notice that v(t) = 5Zk∈u PkVk (t)：
ES(t)[w⑴] =ES(t)[ K X Vk ⑴]
k∈S(t)
=KKES(t) [ X [vk ⑴]
k∈S(t)
=K K ES(t)[vk⑴]
=	qkVk(t)
k∈U
=V⑴.
□
Lemma 5 (Bounded variance of w(t)). For any aggregation step t ∈ TA and with a non-increasing
step size ηt s.t. ηt ≤ 2ηt+E-1, it follows that
ES(t)kw⑴一v(t)k2 ≤ Kη2-1E2G2.
(35)
Proof. First, one can prove that Vk (t) is an unbiased estimate of v(t) for any k:
ES(t)[vk(t)] = X qkVk(t) = V(t).	(36)
k∈U
Then by the aggregation rule w(t) = K Pk∈S(t) Vk (t), We have:
ES(t)kw⑴-V⑴k2 = KES(t)kKw⑴一Kv⑴k2
1K
=K ES(t)k E Vk ⑴一Ev⑴k2
k∈S(t)	k=1
=K2 ES(t)k X (Vk ⑴一”⑴)k2
k∈S(t)
=k2 (ES(t) X kVk⑴-V(t)k2
k∈S(t)
+ ES(t)	X	hVi ⑴一V⑴，Vj ⑴一V⑴〉)，	(37)
i,j∈S(t),i6=j
'-------------{--------------}
=0
Where the second term on the RHS of (37) equals zero because {Vk (t)}k∈U are independent and
unbiased (see Eq. 36). Further, by noticing t - E ∈ TA (because t ∈ TA) Which implies that
wk (t - E)= w(t - E) since the last communication, we have:
ES(t)kw(t)- V(t)k2 = KES(t) X kVk(t) - V(t)k2
k∈S(t)
=KKES(t)kVk(t) - V(t)k2
=KES(t)k (Vk(t) - w(t - E)) - (V⑴一w(t - E))Il2
≤ KES(t)kVk(t) - w(t - E)II2,	(38)
21
Under review as a conference paper at ICLR 2022
where the last inequality results from E[vk (t)-w(t-E)] = v(t)-w(t-E) and that EkX-EX ∣∣2 ≤
EkXk2 . Further, we have:
Es(t)kw(t) - v(t)k2 ≤ *Es(t)kvk(t) - w(t - E)∣2
1N
=K £qkES(t)kvk⑴-w(t - E)k
k=1
1 N	t-1
=K X qk Es(t)k X nN Fk (wk(i),ξk,i )k2.	(39)
k=1	i=t-E
X------------------
Z1
}
Let im = argmaxi ∣∣VF1k (Wk(i),ξk,i) ∣∣,i ∈ [t-E,t-1]. By using the Cauchy-Schwarz inequality,
Assumption 4 and choosing a non-increasing ηt s.t. ηt ≤ 2ηt+E-1, we have:
t-1
Z1 = ES(t) ∣ X ηiVFk (wk (i), ξk,i)∣2
i=t-E
t-1	t-1
=	ES(t) hηiVFk wk(i),ξk,i ,ηjVFk wk(j), ξk,j i
i=t-E j=t-E
t-1	t-1
≤ XX Es(t)UniVFk(Wk(i),ξk,i)k ∙ knjNFk(Wke),ξk,j)k]
i=t-E j=t-E
t-1	t-1
≤ E E ninj ∙Es(t)kvFk(wk(im),ξk,im)k2
i=t-E j=t-E
t-1	t-1
≤ XX n2-E ∙Es(t)∣VFk(wk(im),ξk,im)k2
i=t-E j=t-E
≤ 4nt2-1E2G2 .	(40)
Plug Z1 back into (39) and notice that PkN=1 qk = 1, we have:
1N
ES(t)kw⑴一V⑴ k ≤ K	qk4nt E G
k=1
=K4 n2-ιE2G2.
□
C.4 Proof of Theorem 1
Proof. Taking expectation of ∣∣w(t) - w*∣2, We have:
E∣W(t) - w*∣2 =Es(t)∣W(t) - V(t) + v(t) - w*∣2
=E∣w(t) — v(t)∣2 + E∣v(t) — w* ∣2 + E(w(t) — v(t),v(t) — w*i	(41)
、-----V--------} 、-------V-----} 、------------V-----------}
A1	A2	A3
where A3 vanishes because w(t) is an unbiased estimate of v(t) by first taking expectation over S(t)
(Lemma 4).
22
Under review as a conference paper at ICLR 2022
To bound A2 for t ∈ TA, we apply Lemma 1:
At = E∣∣v(t) - w*k2 ≤ (1 - nt-ιμ)E∣∣w(t - 1) - w*k2 + n2-ιE∣∣gt-ι - gt-ιk2
X-------------------/
{z^
B1
N
+ 6 Lnt-Ir + E [X Pkkwk (t -I)- w(t -I)k[
k=1
X-----------------------------}
(42)
sz
B2
Then we use Lemmas 2 and 3 to bound B1 and B2 respectively, which yields:
A2 = Ekv(t) - w*k2 ≤ (I - nt-iM)EIlw(t- I)- w*k2 + η2-ιB,
(43)
where B = PkN=1 ρtktk + 6LΓ + 8(E - 1)tGt.
To bound A1, one can first take expectation over S(t) and apply Lemma 5 where the upper bound
actually eliminates both sources of randomness. Thus, it follows that
Ai = Ekw(t) - v(t)k2 ≤ ɪnt-ιE2G2	(44)
K
Let C = K4E2G2 and plug Ai and At back into (41):
Ekw(t) - w*k2 ≤ (1 - nt-ιμ)Ekw(t- 1) - w* k2 + n2-ι(B + C).	(45)
Equivalently, let ∆t = E∣w(t) - w*k2, then We have the following recurrence relation for any
t≥1:
∆t ≤ (1 - nt-iμ)∆t-i + nt-i(B + C).	(46)
Next we prove by induction that ∆t ≤
γ+t where V = max {ββB+C), (γ + 1)∆ι} using an
aggregation interval E ≥ 1 and a diminishing step size n = t+βγ for some β > μ and γ > 0 such
that ni ≤ min{ ɪ, ~L } and n ≤ 2@十石.
First, for t = 1 the conclusion holds that ∆ι ≤ γ+ι given the conditions. Then by assuming it holds
for some t, one can derive from (46) that
△t+i ≤ (1 - ntμ)^t + n；(B + C)
≤
(1-卫)二 +(ɪ )2(B + C)
t+γ γ+t t+γ
t + Y — 1	h β2 (B + C)	βμ — 1 -
(t + γ)2 "十[(t + γ)2	(t + γ)2”
S------{-----
≥0
V	t + Y - 1
≤	7t+τFV
≤	t + Y - 1
-	(t + γ)2 - 1”
V
t + γ + 1,
which proves the conclusion △ ≤ γ+t for any t ≥ 1.
Then by the smoothness of the objective function F, it follows that
E[F (w(t))] - F * ≤ 2Ekw(t)- w*k2
L LV
=Xt ≤ 2 YT7.
(47)
(48)
23
Under review as a conference paper at ICLR 2022
Specifically, by choosing β = 2 (i.e., η = “(Y+t)), Y = max{ 8L, E} - 1, we have
V=maχ n β2(B:+F,(Y+1D1}
β2(B + C)
≤ 1jμ-r1 + (Y+ 1A
= 4(B≠) + (Y+1)∆1.	(49)
μ2
By definition, we have w(t) = w(t) at the aggregation steps. Therefore, for t ∈ TA:
E[F (w(t))] - F * ≤ 2 γ+t
_ L (2(B + C) Y +1δ λ
= (γ +1)( μ2	+	2 A)，
□
D Profile Dissimilarity under Homomorphic Encryption
The proposed representation profiling scheme encodes the representations of data into a list of dis-
tribution parameters, namely RP(w, D) = {(μi, σ2)∣i = 1, 2,...,q} where q is the length of the
profile. Theoretically, the information leakage (in terms of the data in D) by exposing RP (w, D)
is very limited and it is basically impossible to reconstruct the samples in D given RP(w, D).
Nonetheless, Homomorphic Encryption (HE) can be applied to the profiles (both locally and on the
server) so as to guarantee zero knowledge disclosure while still allowing profile matching under the
encryption. In the following we give details on how to encrypt a representation profile and compute
profile dissimilarity under Homomorphic Encryption (HE).
To calculate (3) and (4) under encryption, a client needs to encrypt (denoted as [[•]]) every single
μi and σ2 in its profile RP(w, D) locally before upload whereas the server does the same for its
RP *(w, D*). Therefore, according to Eq. (4) we have:
[[KL(Nf)IIN*)]] =∣log[[(σ*)2]] - ∣log[[(σ(k))2]] - [[2]]
1 ([[(σ(k))2]] + ([[〃(k)]]-[[〃*]])2
+	2[[(σ*)2]]	,
(50)
where the first two terms on the right-hand side require logarithm operation on the ciphertext. How-
ever, this may not be very practical because most HE schemes are designed for basic arithmetic
operations on the ciphertext. Thus we also consider the situation where HE scheme at hand only
provides additive and multiplicative homomorphisms (Gentry, 2009). In this case, to avoid the log-
arithm operation, the client needs to keep every σi2 in RP* (w, Di ) as plaintext and only encrypts
μi, likewise for the server. As a result, the KL divergence can be computed under encryption as:
*	(k)
[[KL(N(k)∣IN*)]]=hh2log(*)2 + r(*)2 - 2ii
+ 2⅛ ([[〃(k)]] - [[〃*]])2
(51)
where the first term on the right-hand side is encrypted after calculation with plaintext values (σik)2
and (σ*)2 whereas the second term requires multiple operations on the ciphertext values [[μk]] and
[[μ*]].
Now, in either case, we can compute profile dissimilarity under encryption by summing up all the
KL divergence values in ciphertext:
1q
[[div(RPk ,RP*)]]=-£[[KL(Nf)IIN*)]]
q i=1
(52)
24
Under review as a conference paper at ICLR 2022
E Details of Experimental setup
E.1 Environment Setup
Table 4: Experimental setup.
Setting	Symbol	S-TaSk	L-Task
Model	w	-FFN	CNN
Dataset	D	GasTurbine	EMNIST digits
Total data size	|D|	36.7k	280k
Validation (benchmark) set size	∣D*l	11.0k	40k
Client population	N	50	1000
Data distribution	-	N (514, 1542)	non-IID, dominant≈60%
Noise applied	-	fake, gaussian noise	fake, blur, s&p
Client specification (GHz)	sk	N (0.5, 0.12)	N (1.0, 0.12)
Comm. bandwidth (MHz)	bwk	N (0.5, 0.12)	N (1.0, 0.12)
Signal-noise ratio	SNR	1e2	1e2
Bits per sample	BPS	11*8*4	28*28*1*8
Cycles per bit	CPB	300	400
# of local epochs	M	2	5
Loss function	`	MSE Loss	NLL Loss
Learning rate	η	1e-2	1e-2
learning rate decay	-	0.99	0.99
Detailed experimental settings are listed in Table 4. In the S-Task, the total population is 50 and the
data collected by a proportion of the sensors (i.e., end devices of this task) are of low-quality: 10%
of the sensors have no valid data and 40% of them produce noisy data. In the L-Task, we set up
a relatively large population (1000 end devices) and spread the data (from EMNIST digits) across
the devices with strong class imbalance - roughly 60% of the samples on each device fall into the
same class. Besides, many local datasets are of low-quality: the images on 15% of the clients are
irrelevant (valueless for the training of this task), 20% are (Gaussian) blurred, and 25% are affected
by the salt-and-pepper noise (random black and white dots on the image, density=0.3). For the S-
Task, the maximum number of rounds tmax is set to 100 for both aggregation modes, whilst it is
set to 300 and 50 for the full aggregation and partial aggregation, respectively, for the L-Task. The
preference factor α for our protocol is set to 10. Considering the population of the clients, the setting
of the selection fraction C is based on the scale of the training participants suggested by Kairouz
et al. (2019).
To simulate a realistic FL system that consists of disparate end devices, the clients are heterogeneous
in terms of both performance and communication bandwidth (see Table 4). A validation set is kept
by the server (as the benchmark data) and used for model evaluation.
E.2 Details of Cost Formulation
In each FL round, the server selects a fraction (i.e., C) of clients, distributes the global model to
these clients and waits for them to finish the local training and upload the models. Given a selected
set of clients S, the time cost and energy cost ofa communication round can be formulated as:
Tround = max{Tkcomm + Tktrain + TkRP},	(53)
Ek = Ekcomm + Ektrain + EkRP .	(54)
where Tkcomm and Tktrain are the communication time and local training time, respectively. The
device-side energy consumption Ek mainly comes from model transmission (through wireless chan-
nels) and local processing (training), corresponding to Ekcomm and Ektrain , respectively. TkRP and
EkRP estimate the time and energy costs for generating and uploading local profiles and only apply
to FedProf.
25
Under review as a conference paper at ICLR 2022
Eq. (53) formulates the length of one communication round of FL, where Tkcomm can be modeled
by Eq. (55) according to Tran et al. (2019), where bwk is the downlink bandwidth of device k (in
MHz); SNR is the Signal-to-Noise Ratio of the communication channel, which is set to be constant
as in general the end devices are coordinated by the base stations for balanced SNR with the fairness-
based policies; msize is the size of the model; the model upload time is twice as much as that for
model download since the uplink bandwidth is set as 50% of the downlink bandwidth.
T comm
T upload + T download
2 × T download + T download
msize
3 × ----------：---------
bwk ∙ log(1 + SNR
(55)
Tktrain in Eq. (53) can be modeled by Eq. (56), where sk is the device performance (in GHz) and
the numerator computes the total number of processor cycles required for processing M epochs of
local training on Dk.
Ttrain = M .Dk k BPS CPB
sk
(56)
TkRP consists of two parts: TkRP gen for local model evaluation (to generate the profiles ofDk) and
TkRP up for uploading the profile. TkRP can be modeled as:
TkRP
TRPgen + TRP up
1 T train +	RPSize
M k	2bwk ∙log(1 + SNR)
(57)
where TkRP gen is estimated as the time cost of one epoch of local training; TkRP up is computed in a
similar way to the calculation of Tkcomm in Eq. (55) (where the uplink bandwidth is set as one half
of the total bwk); RP Size is the size of a profile, which is equal to 4 × 2 × q = 8 × q (four bytes for
each floating point number) according to our definition of profile in (2).
Using Eq. (54) we model the energy cost of each end device by mainly considering the energy
consumption of the transmitters for communication (Eq. 58) and on-device computation for local
training (Eq. 59). For FedProf, there is an extra energy cost for generating and uploading profiles
(Eq. 60).
E comm
Ptrans
T comm
(58)
Etrain = p, §3 Ttrain
(59)
ERP = Ptrans ∙ TRPup + Pf Sk ∙ TRPgen,	(60)
where Pf S3k is a simplified computation power consumption model (Song et al., 2013) and Pf is the
power of a baseline processor. Ptrans is the transmitter’s power. We set Ptrans and Pf to 0.5 and
0.7 Watts respectively based on the benchmarking data provided by Carroll et al. (2010).
26