Under review as a conference paper at ICLR 2022
Subspace State-Space Identification and
Model Predictive Control of Nonlinear Dy-
namical Systems Using Deep Neural Network
with Bottleneck
Anonymous authors
Paper under double-blind review
Ab stract
A novel nonlinear system identification method that produces state estimator and
predictor directly usable for model predictive control (MPC) is proposed in this
paper. The main feature of the proposed method is that it uses a neural network
with a bottleneck layer between the state estimator and predictor to represent the
input-output dynamics, and it is proven that the state of the dynamical system
can be extracted from the bottleneck layer based on the observability of the target
system. The training of the network is shown to be a natural nonlinear extension
of the subspace state-space system identification method established for linear
dynamical systems. This correspondence gives interpretability to the resulting
model based on linear control theory. The usefulness of the proposed method and
the interpretability of the model are demonstrated through an illustrative example
of MPC.
1	Introduction
Model predictive control (MPC) has been widely used as a practical method to control nonlinear
dynamical systems (Qin & Badgwell, 2000; Vazquez et al., 2014; Karamanakos et al., 2020). As
the name implies, MPC requires a prediction model, and in most cases, state-space models are used.
When we want to apply MPC to a complex system whose structure and state are unknown, model
construction from input-output data, i.e., system identification, is required. For linear state-space
system identification, the subspace methods (Favoreel et al., 2000; Katayama, 2005; van der Veen
et al., 2013) are widely used. Its fundamental idea is to reduce the dimensionality of the measured
past and future input and output data, and it strongly depends on the linearity of the system. Although
there have been continuous attempts to extend the subspace methods to nonlinear systems with
specific structures such as Wiener and Hammerstein structures (e.g., Verhaegen & Westwick, 1996;
Goethals et al., 2005; Katayama & Ase, 2016) and related research has also been conducted in the
field of machine learning as spectral learning of Hidden Markov Models (Kawahara et al., 2007;
Hsu et al., 2012; Kandasamy et al., 2016), there is still a lot of room for research in extending the
subspace method to general nonlinear dynamical systems.
On the other hand, recent advances in machine learning techniques have had an impact on the re-
search field of system identification (Ljung et al., 2020a;b). For example, deep state space models
(Rangapuram et al., 2018), and Kalman variational auto-encoder (Fraccaro et al., 2017) apply deep
learning to state space models. Among those technologies, autoencoder is a notable dimensional
reduction or feature extraction technique with deep neural networks, whose traits derives from topo-
logical constraints of own bottleneck structure. Although several pieces of research apply it to
state-space system identification (Masti & Bemporad, 2018; Beintema et al., 2021), these works do
not provide a theoretical basis for obtaining the state sequence.
This paper aims to propose a theoretically supported and interpretable nonlinear dynamical sys-
tem identification method by simply extending the subspace method with neural networks. For the
proposed method, it can be shown based on the observability of the target system that when a neu-
ral network with an appropriate bottleneck is trained, the state estimator and predictor are formed
1
Under review as a conference paper at ICLR 2022
across the bottleneck layer. The obtained model can be interpreted based on the knowledge from
linear system identification methods, and this aspect is explained through an illustrative example.
In this paper, the set of integers and the natural numbers are denoted by Z and N, respectively.
The set {sa, sa+1, . . . , sb-1, sb} is denoted as {sk}bk=a for conciseness. The n × m zero matrix is
denoted as 0r×m, and 0n := 0n×ι. For a matrix M, M* is the Moore-Penrose inverse of M.
2	Problem Formulation & Notation
We consider the following discrete-time nonlinear dynamical system:
xt+1 = f(xt, ut),	yt = h(xt)	(1)
with t ∈ Z the time index, xt ∈ Rrx the state, yt ∈ Rry the output, ut ∈ Rru the input, f :
Rrx × Rru → Rrx the state-transition map and h : Rrx → Rry the output map. As in the usual
setting for system identification, xt is a latent variable and ut and yt are measurable with noise.
In the following discussion, the fundamental properties of the proposed method for nonlinear target
systems are presented in the absence of measurement noise and disturbances. The effects of noise
and disturbance are indirectly provided for linear target systems in section 4 by showing that the
proposed method is equivalent to the subspace identification method.
For convenience, We define the sequence of input and output signals in the past and future from a
certain time t as follows:
utp :
ut-hp
ut-hp + 1
.
.
.
ut-1
ytp :
yt-hp
yt—hp+1
.
.
.
yt-1
ut
ut+1
.
.
.
ut+hf -1
yt
f	yt+1
y :=	.
.
.
yt+hf -1
(2)
where the superscripts p and f indicate past and future, and hp ∈ N and hf ∈ N are horizons for
corresponding directions, respectively. Using these notations, we formulate the problem as follows.
Problem 1. Given the measured input-output data {(ut, yt)}tT=+-hhf -+1 1, and the design parameters
hp, hf, n^ ∈ N, construct a model that consists ofa state estimator E, which maps (up, yp) → Xt,
and a predictor P, which maps (Xt, ut) → yf. Here, Xt ∈ Rnx is a state equivalent to Xt but in an
arbitrary coordinate system and T ∈ N indicates the size of the dataset.
Remark 1. In the usual state-space system identification, the goal is to construct a model of f and
h, i.e., a state-space model. However, in many applications, including model predictive control, the
state estimator and multi-step ahead predictor are often reconstructed from the resulting state-space
model. In particular, for nonlinear systems that are difficult to analyze, the merits of going through
state-space models are questionable. Therefore, we focus here on the construction of the state
estimator E and predictor P and only briefly discuss the identification of f and h in Appendix A.
To guarantee Problem 1 to be solvable, we make some assumptions. With the vectors defined above
(2), we can write the system (1) as
yp = hhp (xt-hp, up)
where
：=f (…f (f (xt, ut), ut+ι)…，ut+k)
-	h(xt)
h ◦ f (xt, ut)
:=	.
.
.
_ h ◦ f k-1 (χt, [u>,..∙, ut+k-i]>)
And define the uniform k-observability as follows.
Definition 1 (uniform k-observability (Moraal & Grizzle, 1995)). If the mapping
Rnx × (Rnu )k → (Rny )k × (Rnu)k by (x, u) → (hk(x, u), u)
(3)
(4a)
(4b)
(5)
is injective, the system (1) is said to be uniformly k-observable (Moraal & Grizzle, 1995).
2
Under review as a conference paper at ICLR 2022
Then, we make the following assumptions and theorem.
Assumption 1. The system (1) is uniformly k-observable, where k = min (hp, hf).
Remark 2. According to Stark et al. (1997), typical dynamical systems are k-observable for k ≥
2nx + 1.
Assumption 2. The dimension of the state estimate is large enough, that is, n^ ≥ nx.
Theorem 1. Under Assumptions 1 and 2, Problem 1 has a solution.
Proof. From Assumption 1, there exists the map
Φhp : {(up,hhp (xp,up)) I XP ∈ Rnx, UP ∈ (Rnu )hp } → Rnx	(6)
that maps (utp, ytp) 7→ xt-hp, and the map
Ψ : {(up,hhp (xp,up)) I Xp ∈ Rnx, up ∈ (Rnu )hp } → Rnx	(7)
that maps (utp, ytp) 7→ fhp Φhp (utp, ytp) , utp also exists. Since the pair of maps Ψ and hhf is a
pair of state estimator and predictor that is a solution to Problem 1, it is guaranteed that there is a
solution when n^ ≥ nx.	□
3 Proposed Method
This section presents the proposed nonlinear system identification approach. Also, nonlinear MPC
based on the obtained model is described.
3.1	Training State Estimator & Predictor
In the proposed method, we train the neural network which has the structure of figure 1, where the
state estimator E : (Rnu )hp X (Rny )hp → Rnx maps the past input and output to the current state
and the predictor P : Rnx × Rhfnu → Rhf ×ny maps the current state and the future input to the
future output.
Future Output Sequence
Figure 1: Proposed network structure. The sequences of past inputs utp and outputs ytp are once
compressed into state variables Xt, and then reflected in the prediction of the sequence of future
outputs ytf .
We set n^ < hp ny for the bottleneck structure of the network to take a lower-dimensional state, and
the training problem is formulated as the following minimization problem
min
E,P
T
T Xw
t=1
-P(E(Up, yP), Ut) Il
'-------{--------}
estimate of xt
'-----------------------------}
prediction of ytf
(8)
Since the state Xt cannot be measured, the state estimator E and predictor P are coupled in series
and trained in the same way as the encoder and decoder in autoencoder. To solve (8), we can utilize
modern batch optimization algorithms for deep learning (e.g. Adam by Kingma & Ba, 2014).
Here, We show that Xt := E (up, ytp) is also a state of the system in the ideal situation.
3
Under review as a conference paper at ICLR 2022
Theorem 2. Assume the training (8) is perfectly done, that is, for all xp ∈ Rnx, up ∈ (Rnu )hp,
uf ∈ (Rnu)hf, the equation
P (E(Up, yp), Uf ) = yf,	(9)
where yf (xp, up, Uf) := hhf (x, uf), X (xp, up) := fhp (xp, up), yp (xp, up) := hhp (xp, UP)
and arguments are omitted for conciseness, holds. Then, for all xp ∈ Rnx and Up ∈ (Rnu )hp,
E Up, hhp (xp, Up) is a state equivalent to fhp (xp, Up).
Proof. From hf -observability of the system, the map
Φhf : {(uf, hhf (x, Uf)) I x ∈ Rnx, uf ∈ (Rnu )hf} → Rnx that maps (Uf, yf) → X (10)
exists, and the map
Γ : Rnx	X	(Rnu)hf → Rnx	thatmaps	(X,Uf)	→	Φhf	(Uf,P	(X,Uf))	(11)
also exists. Then, a map obtained by fixing the second argument of Γ, e.g.,
Γo(X) := Γ(X, 0hfnu)	(12)
maps X to x, and X is proved to be a state.	□
Remark 3. The existence of the map from X to X is ensured by the predictor P trained with a
common input 0hf nu for all states as in (12). Although this is just one way of constructing a map
that is possible under the strong assumption of Theorem 2, this implies that to obtain an appropriate
state estimator, the training data must be rich enough to include situations where common inputs
are applied in diverse states.
Corollary 1. When the assumption of Theorem 2 holds, P is the predictor that predicts the sequence
of future output from a state and a sequence of future input.
3.2	Model Predictive Control with Estimator & Predictor
Next, the use of the obtained model in MPC is briefly described.
Here we reuse the symbols for the past and future input/output sequences Utp , ytp , Uft , ytf defined in
(2), but note that the MPC is done after the training and these input-output signals are not the ones
at the time of training.
In MPC, a loss function lt : Rnu × Rny → R that evaluates the input and output at each time t is
given. And, at each time step t, the optimization problem
hf
um∈JnRm%	X lt+k-1 ((Uf)(k-1)nu + Lknu , (yf)(k-1)ny + 1:kny)	(13)
s.t. yf = P (E (Up, yp), Uf)
Uf , yf satisfies constraints on the control system
is solved to obtain Uf, which is a candidate for the future input sequence Uft. Then, the candidate for
most immediate future input Inu , 0nu ×nu(hf-1) Uf is actually applied to the system and moves to
the next step t + 1.
Usually, state-space models are used in MPC, and a state estimator like extended Kalman filter and
a predictor are constructed from the models. On the other hand, the state estimator and predictor
obtained by the proposed method can be directly used for MPC. The state estimator obtained by the
proposed method is a static mapping from the previous inputs and outputs on the finite horizon hp,
and there is no risk of divergence, unlike commonly used filters with infinite impulse response (IIR)
structures. This is an important advantage when using the state estimator for MPC.
4 Interpretation of Proposed Method and Model
The proposed method can be viewed as a natural extension of the subspace methods for linear
systems, and the similarity with the subspace methods gives interpretability to the model obtained
by the proposed method. In this section, we briefly explain the framework of the subspace method
and describe how the model obtained by the proposed method can be interpreted based on it.
4
Under review as a conference paper at ICLR 2022
4.1	Relation to Subspace Methods for Linear Dynamical Systems
Here, we consider restricting the state estimator E and predictor P of the proposed method to linear
maps and representing them by matrices E ∈ Rnx×hpSu+nG and P ∈ Rhfny×(nx+hfnU). When
the target system is linear, the optimal state estimator and predictor are known to be linear maps,
and can be represented by these matrices if hp and hf are sufficiently large. In this case, the training
of the state estimator and predictor (8) is reduced to the following nonlinear least-squares problem:
min
E∈Rnx ×hp(nu+ny )
pχ∈Rhfny ×nx
Pu ∈Rhf ny ×hf nu
1 ɪ
T X yf - PxE
t=1
utp
ytp
2
- Puuft	,
(14)
T
where we split P = [Px , Pu] for convenience. Also, by defining the matrix Up := [u1p, u2p, . . . , upT]
and the matrices Y p, Uf, Y f in the same manner, we can rewrite the objective function as follows
min
E∈Rnx ×hp(nu+ny)
px∈Rhfny ×nχ
Pu ∈Rhf ny ×hf nu
T Yf - PxE
Up
Yp
2
- PuUf
F
(15)
On the other hand, while the actual computational procedure is more cumbersome due to the use of
RQ decomposition for numerical benefits, the outline of the subspace methods can be summarized
as follows (Peternell et al., 1996):
(S1)	Solve linear least squares problem
1	Up
-min	不 Yf — PxE YP - PuUf
P[x E ∈Rhf ny ×hp (nu +ny)	T
Pu ∈Rhf ny ×hf nu
to obtain P[xE ∈ Rhf ny ×hp (nu +ny) and Pu ∈ Rhf ny ×hf nu .
(S2)	Obtain Px and E rank-nx approximation of PxE Via a weighted SVD.
(S3)	Calculate state-space representation based on E.
(16)
As can be seen from the comparison of the two optimization problems (15) and (16), the subspace
method is characterized by the fact that instead of solving the nonlinear least-squares problem in-
volving the product of two matrix parameters Px and E, it solves the linear least-squares problem
with the product PxE as the parameter, and then obtain Px and E via the low-rank approximation
in (S2).
The distinct advantage of the procedure (S1)-(S2) is that both linear least-squares and low-rank
approximations by SVD yield globally optimal solutions. On the other hand, the solution obtained
by (S1)-(S2) is different from the solution of the original optimization problem (15), and there are
many variants that have different statistical properties for this misalignment (see e.g., Van Overschee
& De Moor, 1994; Peternell et al., 1996; Favoreel et al., 2000).
Therefore, the proposed method can be regarded as a variant of the subspace methods that revert to
the underlying nonlinear least-squares problem (15) and extend it to nonlinear systems by replacing
linear mappings with neural networks.
Appendix B confirms that the proposed method indeed yields the same results as the ideal subspace
identification method for a linear system example. Next, we discuss the interpretation of the obtained
model based on this agreement.
4.2	Interpretation of Model
It is also possible to interpret the obtained model based on the knowledge in linear system identifica-
tion. Only in this section, we assume that the target system is the following linear dynamical system
with noise
xt+1 = Axt + But + wt,
yt = Cxt + vt,
(17)
5
Under review as a conference paper at ICLR 2022
where A ∈ Rnx×nx, B ∈ Rnx×nu, C ∈ Rny×nx are the system matrices; Wt 〜N(0nu×ι, Q)
and Vt 〜N(0% ×ι, R) are process noise and measurement noise, respectively. When the number
of states in the model is accurate (nχ = nχ) and the number of data T and horizons hp, hf are
sufficiently large, the result of steps (S1) and (S2) is consistent with the solution of (15), and what
we get as a state estimator E is known to be the Kalman filter for the target system. And, the matrix
E becomes the Markov parameters of the Kalman filter, that is,
E= [Eu Ey],	(18)
Eu = [Ahp-1B,..., A2 B, AB, B] , Ey = [Ahp-1K,..., A2K, AK, K ] ,	(19)
A := A - KC,	K := A∑C> (CΣC> + R) 1	(20)
where K ∈ Rnx×ny is the Kalman gain and Σ is the solution to the discrete-time algebraic Riccati
equation
Σ = AΣA> - AΣC>(CΣC> + R) 1 CΣA> + Q.	(21)
From the Kalman filter designed for the target system, we can retrieve the frequency bands that are
important for state estimation or the noise characteristics in the target system. Conversely, we can
also evaluate whether the obtained state estimator is reasonable or not, based on the knowledge of the
target system. For the state estimator E implemented by a neural network, Eu and Ey correspond
to ∂∂UEp and ∂∂yp at the operating point, respectively. And by calculating these, the characteristics of
the obtained state estimator can be evaluated.
On the other hand, the predictor Px and Pu are an extended observability matrix and the Markov
parameters of the target system, that is,
C
CA
Px =	.	,	Pu
.
.
CAhf-1
OO
CB	O
CAB	CB
..
..
..
CAhf-2B	CAhf-3B
… O-
.
.,O := 0ny ×nu . (22)
CB O
and characterize the unforced response and input-output characteristics of the target system. For
nonlinear predictors, Px and Pu correspond to ∂∂^ and ∂p, respectively, from which the character-
istics of the target system at the operating point can be illustrated.
5 Illustrative Example
Next, we demonstrate the proposed method through a toy example, where the identification and
MPC of a cascaded tanks system (Wigren & Schoukens, 2013) is performed.
The state equation of the system is as follows:
xt+1,ι] =「max (xt,1 - k1√XξΓ + k2 (Ut + Wt), 0)
χt+1,2J	[ max (xt,2 + k3√¾T — k4√XJ, 0)
yt = xt,2 + vt,
(23)
where nx = 2, nu = ny = 1, k1 = 0.5, k2 = 0.4, k3 = 0.2, k4 = 0.3, Wt 〜N(0,0.352), and
Vt 〜N(0,0.152). The state variables xt,1 and χt,2 are the levels of the upper and the lower tank,
and ut denotes the applied voltage to the pump at t. To obtain the training dataset, the system is
excited by a sequence of random input
ut = min max ut0 , 0 , 5 ,
U0 〜N(2, 52),	(24)
and a sequence of data {(ut, yt)}t1=00-010919 is obtained.
On training the state estimator E and predictor P, We choose the hyperparameters of nx = 2,
hp = hf = 20. E and P are implemented by neural networks with two and three hidden layers,
respectively, where each layer contains 64 ReLU neurons and every layers are fully connected. For
6
Under review as a conference paper at ICLR 2022
training, we used the Adam optimizer in PyTorch (Paszke et al., 2019) with the default settings. To
prevent overfitting, the 90 % of the samples were used for training, and the training was continued
until the fit to the remaining 10 % of the validation data did not improve for 1000 consecutive
iterations.
Then, the MPC controller which solves the optimization problem (13) with the cost function
lt(ut,yt) := (yt - rt)2 + 0.05 (ut - ut-1)2	(25)
and the constraint 0 ≤ ut ≤ 5 at each time t is implemented with the obtained state estimator and
predictor. Here, rt ∈ Rny is the reference signal. To solve the optimization problem, and we used
Levenberg-Marquardt Algorithm (More,1978).
The result of the tracking control up to t = 400 is shown in figure 2. In the figure, the applied
control input ut , the measured output yt (red line), reference signal rt (dotted black line), and the
true water levels in the tanks xt,1, xt,2 (blue lines) are shown. In addition, the green lines in each
plot show uft and ytf at t = 400, respectively. As can be seen from the figure, appropriate MPC is
performed using the obtained state estimator and predictor. Also, the state estimate Xt and the state
of the system xt are compared in Appendix C.
Figure 2: Result of tracking control
Then, to support the interpretation discussed in section 4, figure 3 shows the visualization of the
state estimator and predictor at the operating point at t = 50, where the change in water level is
slow and nonlinearity is expected to be weak. The dashed lines in figures 3(a)-(c) and the bitmap
on the right in figure 4(d) show the corresponding properties of the linearized system of (23) at the
operating point. Since linear systems also have degrees of freedom in how they coordinate in state
space, a transformation matrix Φ := PxJ 翁 ∈ Rnx ×nx is used to align the coordinate system. From
figures 3(a) and (b), the state estimator E obtained by the proposed method agrees well with the
Kalman filter for the linearized system of the true system, and it can be confirmed that the proposed
method yields almost optimal state estimators as expected for subspace methods in an ideal situation
with sufficient data. It can also be seen that the predictor is consistent with the true system.
Moreover, figure 4 was obtained at the operating point at t = 380, where the nonlinearity is con-
sidered to be more strongly observed. Although the results in this case are similar to those in the
linearized system to some extent, differences in the characteristics can be seen. For example, in
7
Under review as a conference paper at ICLR 2022
(a) Markov parameters of state estimator for up
(Solid : (∂E ):j ,dashed : (φ->Eu):,)
(C) Predictor unforced response
(solid:(∂P)i,:,dashed: (Pxφ)ij
1
20
(P U)ij
! @Pf "ij
1	20 1	20
j	j
0.06
0.04
0.02
0
(b) Markov parameters of state estimator for yp
(d) Predictor Markov parameters
Figure 3: Visualization of E and P at t = 50
(a) Markov parameters of state estimator for up
(solid : (∂E ):j , dashed : (φ->Eu)J
(c) Predictor unforced response
(solid : (∂∂P)i,: ,dashed : (PxΦ)i,)
1
20
(P U)i；j
! @P"
∂uf i ij
1	20 1	20
j	j
U 0.06
0.04
0.02
(b) Markov parameters of state estimator for yp
(Solid :(源)Jdashed : (φ->Ey)：j)
(d) Predictor Markov parameters
Figure 4:	Visualization of E and P at t = 380
8
Under review as a conference paper at ICLR 2022
figure 4(d), the Toeplitz structure of linear systems is partially lost, indicating the existence of non-
linearity. In figures 4(a) and (b), it can be seen that an estimator that is less dependent on the output
and more focused on the recent input than the Kalman filter for the linearized system is obtained.
To verify the validity of placing the bottleneck, we evaluated the performance with different widths
of the bottleneck n^. All settings except n^ and the realized value of the stochastic noise wt, Vt are
set to be identical to the case of n^ = 2 and 60 trials were conducted with different realizations of
the stochastic noise.
The results are summarized in figure 5. The loss for the validation dataset in figure 5(a) shows that
64
32
16
8
4
3
2
1
--EI?T
-IDT
-
-4I>τ
-IDT
--□>τ
--[>τ
q
*
P
u
*
O
一□H -
I-----d I I-----------T +	-
I-----T I I-------1 ++ +	-
I----T I I------ɪ + +	-
I----1 I I---------1 + ++	-
H------I I I------T ++	-
------4ΞΞEΞF------>+ +++
I——I I I--------h÷÷÷	-
I----1 I I-------------1 + + -
0.028	0.03	0,032	0.034
4	5	6	7	8
(a) Loss for Validation Set
(b) Cost in MPC
Figure 5:	Width of bottleneck n^ and performance
the performance does not degrade until the width of the bottleneck n^ goes below the actual state
dimension nx = 2. Also, the performance of the MPC calculated by Pt4=00h +1 lt(ut, xt,2) does not
show degradation until n^ < nx = 2 as shown in figure 5(b), and these results support the use of
the bottleneck to provide interpretability.
6 Conclusion
In this paper, we proposed a new nonlinear subspace identification method that produces state esti-
mator and predictor directly usable for nonlinear MPC. It is theoretically shown that by training a
neural network with a bottleneck that performs regression on input-output sequences ofa length that
provides observability in both past and future directions, a state estimator and a predictor are formed
across the bottleneck layer. The relationship between this method and the subspace identification
method, as well as the interpretation of the obtained model using this relationship, is also explained,
and its use is demonstrated through an example.
This research is still in its early stages, and there is much work to be done in the future. In order to
demonstrate the applicability to higher-dimensional problems, an example of identifying dynamics
from a simple video is included in Appendix D. However, verifying the performance in more prac-
tical tasks is a subject for future work. Also, a more precise condition for yielding a state estimator
is desired. The current proof makes use of the assumption that zero-input responses from all states
have been learned, and while the fact that zero-input responses constitute states is often used in this
type of research (Verdult & Scherpen, 2004), more precise conditions would be useful for experi-
ment design. It also appears that the technique of inverse optimal control (Ab Azar et al., 2020) can
be applied to the interpretation of the obtained state estimator. Finally, since noise with high-order
dynamics is ubiquitous (Bak et al., 1987) and the synthesis of state estimator for such a system is
prone to failure, it is important to develop a mechanism to focus on useful states.
References
Nematollah Ab Azar, Aref Shahmansoorian, and Mohsen Davoudi. From inverse optimal control
to inverse reinforcement learning: A historical review. Annual Reviews in Control, 50:119-138,
2020. ISSN 1367-5788. doi: https://doi.org/10.1016/j.arcontrol.2020.06.001. URL https:
//www.sciencedirect.com/science/article/pii/S1367578820300511.
9
Under review as a conference paper at ICLR 2022
Per Bak, Chao Tang, and Kurt Wiesenfeld. Self-organized criticality: An explanation of the 1/f
noise. Phys. Rev. Lett., 59:381-384, JUl 1987. doi:10.1103/PhysRevLett.59.381. URL https:
//link.aps.org/doi/10.1103/PhysRevLett.59.381.
Gerben I. Beintema, Roland Toth, and Maarten SchoUkens. Non-linear state-space model iden-
tification from video data Using deep encoders. IFAC-PapersOnLine, 54(7):697-701, 2021.
ISSN 2405-8963. doi: https://doi.org/10.1016/j.ifacol.2021.08.442. URL https://www.
sciencedirect.com/science/article/pii/S2405896321012167. 19th IFAC
SymposiUm on System Identification SYSID 2021.
WoUter Favoreel, Bart De Moor, and Peter Van Overschee. SUbspace state space system iden-
tification for indUstrial processes. Journal of Process Control, 10(2):149-155, 2000. ISSN
0959-1524. doi: https://doi.org/10.1016/S0959-1524(99)00030-X. URL https://www.
sciencedirect.com/science/article/pii/S095915249900030X.
Marco Fraccaro, Simon Kamronn, Ulrich PaqUet, and Ole Winther. A disentangled
recognition and nonlinear dynamics model for UnsUpervised learning. In I. GUyon,
U. V. LUxbUrg, S. Bengio, H. Wallach, R. FergUs, S. Vishwanathan, and R. Garnett
(eds.), Advances in Neural Information Processing Systems, volUme 30. CUrran Asso-
ciates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/
7b7a53e239400a13bd6be6c91c4f6c4e- Paper.pdf.
I.	Goethals, K. Pelckmans, L. Hoegaerts, J. SUykens, and B. De Moor. SUbspace intersection identi-
fication of hammerstein-wiener systems. In Proceedings of the 44th IEEE Conference on Decision
and Control, pp. 7108-7113, 2005. doi: 10.1109/CDC.2005.1583307.
Daniel HsU, Sham M. Kakade, and Tong Zhang. A spectral algorithm for learning hidden markov
models. Journal of Computer and System Sciences, 78(5):1460-1480, 2012. ISSN 0022-0000.
doi: https://doi.org/10.1016/j.jcss.2011.12.025. URL https://www.sciencedirect.
com/science/article/pii/S0022000012000244. JCSS Special IssUe: CloUd Com-
pUting 2011.
Kirthevasan Kandasamy, MarUan Al-Shedivat, and Eric P Xing. Learning hmms with nonpara-
metric emissions via spectral decompositions of continUoUs matrices. In D. Lee, M. SUgiyama,
U. LUxbUrg, I. GUyon, and R. Garnett (eds.), Advances in Neural Information Processing Systems,
volUme 29. CUrran Associates, Inc., 2016. URL https://proceedings.neurips.cc/
paper/2016/file/afe434653a898da20044041262b3ac74-Paper.pdf.
Petros Karamanakos, Eyke Liegmann, Tobias Geyer, and Ralph Kennel. Model predictive control
of power electronic systems: Methods, resUlts, and challenges. IEEE Open Journal of Industry
Applications, 1:95-114, 2020. doi: 10.1109/OJIA.2020.3020184.
TohrU Katayama. Subspace methods for system identification. Springer, 1 edition, 2005.
TohrU Katayama and Hajime Ase. Linear approximation and identification of mimo
wiener-hammerstein systems. Automatica, 71:118-124, 2016. ISSN 0005-1098. doi: https:
//doi.org/10.1016/j.aUtomatica.2016.04.040. URL https://www.sciencedirect.com/
science/article/pii/S0005109816301650.
YoshinobU Kawahara, Takehisa Yairi, and KazUo Machida. A kernel sUbspace method by
stochastic realization for learning nonlinear dynamical systems. In B. Scholkopf, J. Platt,
and T. Hoffman (eds.), Advances in Neural Information Processing Systems, volUme 19.
MIT Press, 2007. URL https://proceedings.neurips.cc/paper/2006/file/
96629f1aac6ddb7a7cfa82574b6722d4- Paper.pdf.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Lennart Ljung, Carl Andersson, Koen Tiels, and Thomas B. Schon. Deep learning and sys-
tem identification. IFAC-PapersOnLine, 53(2):1175-1181, 2020a. ISSN 2405-8963. doi:
https://doi.org/10.1016/j.ifacol.2020.12.1329. URL https://www.sciencedirect.com/
science/article/pii/S2405896320317353. 21st IFAC World Congress.
10
Under review as a conference paper at ICLR 2022
Lennart Ljung, Tianshi Chen, and Biqiang Mu. A shift in paradigm for system identification. Inter-
national JournalofControl, 93(2):173-180, 2020b. doi: 10.1080/00207179.2019.1578407. URL
https://doi.org/10.1080/00207179.2019.1578407.
Daniele Masti and Alberto Bemporad. Learning nonlinear state-space models using deep autoen-
coders. In Proc. of the 57th IEEE Conference on Decision and Control (CDC 2018), pp. 3862-
3867, 2018. doi: 10.1109/CDC.2018.8619475.
P.E. Moraal and J.W. Grizzle. Observer design for nonlinear systems with discrete-time measure-
ments. IEEE Transactions on Automatic Control, 40(3):395-404, 1995. doi: 10.1109/9.376051.
Jorge J More. The Levenberg-Marquardt algorithm: implementation and theory. In Numerical
analysis, pp. 105-116. Springer, 1978.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward
Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,
Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An imperative style, high-performance
deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alche-Buc, E. Fox, and
R. Garnett (eds.), Advances in Neural Information Processing Systems 32, pp. 8024-8035. Curran
Associates, Inc., 2019.
Klaus Peternell, Wolfgang Scherrer, and Manfred Deistler. Statistical analysis of novel subspace
identification methods. Signal Processing, 52(2):161-177, 1996.
S. Joe Qin and Thomas A. Badgwell. An overview of nonlinear model predictive control applica-
tions. In Frank Allgower and Alex Zheng (eds.), NonlinearModel Predictive Control, volume 26
of Progress in Systems and Control Theory, pp. 369-392. Birkhauser Basel, 2000. ISBN 978-3-
0348-8407-5.
Syama Sundar Rangapuram, Matthias W Seeger, Jan Gasthaus, Lorenzo Stella, Yuyang
Wang, and Tim Januschowski. Deep state space models for time series forecasting.
In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Gar-
nett (eds.), Advances in Neural Information Processing Systems, volume 31. Curran Asso-
ciates, Inc., 2018. URL https://proceedings.neurips.cc/paper/2018/file/
5cf68969fb67aa6082363a6d4e6468e2-Paper.pdf.
J.	Stark, D.S. Broomhead, M.E. Davies, and J. Huke. Takens embedding theorems for
forced and stochastic systems. Nonlinear Analysis: Theory, Methods & Applications, 30
(8):5303-5314, 1997. ISSN 0362-546X. doi: https://doi.org/10.1016/S0362-546X(96)
00149-6. URL https://www.sciencedirect.com/science/article/pii/
S0362546X96001496. Proceedings of the Second World Congress of Nonlinear Analysts.
Gijs van der Veen, Jan-Willem van Wingerden, Marco Bergamasco, Marco Lovera, and Michel
Verhaegen. Closed-loop subspace identification methods: an overview. IET Control
Theory & Applications, 7(10):1339-1358, 2013. doi: https://doi.org/10.1049/iet-cta.2012.
0653. URL https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.
1049/iet-cta.2012.0653.
Peter Van Overschee and Bart De Moor. N4SID: Subspace algorithms for the identification of
combined deterministic-stochastic systems. Automatica, 30(1):75-93, 1994.
Sergio Vazquez, Jose I. Leon, Leopoldo G. Franquelo, Jose Rodriguez, Hector A. Young, Abraham
Marquez, and Pericle Zanchetta. Model predictive control: A review of its applications in power
electronics. IEEE Industrial Electronics Magazine, 8(1):16-31, 2014. doi: 10.1109/MIE.2013.
2290138.
Vincent Verdult and Jacquelien Scherpen. Identification of nonlinear state-space systems using zero-
input responses. In Proc. ofthe 16th international symposium on mathematical theory of networks
and systems (MTNS 2004), pp. 1-11, 2004.
11
Under review as a conference paper at ICLR 2022
Michel Verhaegen and David Westwick. Identifying mimo hammerstein systems in the context
of subspace model identification methods. IFAC Proceedings Volumes, 29(1):4092-4097, 1996.
ISSN 1474-6670. doi: https://doi.org/10.1016/S1474-6670(17)58321-4. URL https://www.
sciencedirect.com/science/article/pii/S1474667017583214. 13th World
Congress of IFAC, 1996, San Francisco USA, 30 June - 5 July.
Torbjom Wigren and Johan Schoukens. Three free data sets for development and benchmarking
in nonlinear system identification. In Proc. of 2013 European Control Conference (ECC), pp.
2933-2938. IEEE, 2013.
A IDENTIFICATION OF f AND h IN STATE-SPACE EQUATION
A method of obtaining the state-space model from the state estimator and predictor is briefly ex-
plained here.
The model of the output map h : xt → yt, the map h : Rnx → Rny is obtained by extracting the
first prediction of the predictor P as
h(X) := [Iny , 0ny ×(hf-1)ny] P(X, 0) .	(26)
* i` .λ	i` .λ .	∙ . ∙	2	-m><κ)-	-m>	-m><κ)- f	. ∙	. ∙ .ι .
As for the model of the state-transition map f : Rnx X Rnu → Rnx, by estimating the state sequence
{Xt}T=ι with E as
Xt = E(UP yp),	(27)
the construction of f is reduced to the fitting of a static map as
T
minimize T X "t+1 — f (Xt, Ut)∣∣ .
f	t=1
B Verification of Agreement with Subspace Methods for Linear
Systems
In order to validate the discussion in section 4, we apply the proposed method to the linear dynamical
system (17) with the following parameters:
A = 0.07.8559 -0.07358 , B = 10 , C = [0.3403 0.4834] ,	(28)
0 12 0
Q = 0.01	00 , R = 0.12.	(29)
The learning setup is the same as in section 5, except that the state estimator E and predictor P
are linear maps which can be represented by matrices E and P, and the distribution of the input is
Ut ~N(0,1).
In figure 6, the E and P representing the obtained model are compared with the E and P calculated
by (18)-(22), i.e., the results obtained by the ideal subspace method. Since the linear state-space
systems have a degree of freedom in how to take the coordinate system, a linear coordinate transfor-
mation (such that Px is most consistent) is applied to the estimated model to facilitate comparison.
As can be seen from the figure, the results are consistent except for a small deviation due to the
finite sample size, indicating that the proposed method solves essentially the same problem as the
subspace identification method for linear systems.
C Comparison of State Estimate Xt and Actual State Xt
We show the trajectories of the actual state Xt and the state estimate Xt of the cascaded tanks
example in figure 7. Since the proposed method does not specify how to take the coordinates into
the state space, they are connected by a nonlinear mapping that depends on the initial weights of
the neural network before training. For ease of comparison, the trajectory of Xt is shown over the
trajectory of Xt (dotted line) in affine coordinates such that Xt is closest to Xt in figure 7(b).
12
Under review as a conference paper at ICLR 2022
(C) Predictor unforced response (Px )i:
(solid: estimate, dashed: ideal)
(a) Markov parameters of state estimator for input
(Eu):,j
(solid: estimate, dashed: ideal)
(b) Markov parameters of state estimator for (Ey):,j
(solid: estimate, dashed: ideal)
Estimate
j
Ideal
0.4
0.2
0
1	20
j
(d) Predictor Markov parameters
Figure 6: Visualization of E and P for linear case
Xt；1
(a) Trajectory of actual state xt
Xt；1
(b) Trajectory of state estimate Xt
Figure 7: Comparison of actual state and model state
300
100
200 0
0
D Supplementary Example
To demonstrate the applicability to high dimensional systems, the proposed method is applied to
the problem of estimating the dynamics of video discussed in (Beintema et al., 2021). Consider an
environment where a nonlinear force acts a ball and we observe it with a camera of 25 × 25 pixels.
The dynamics of the ball is
Px = β
Py = β
1
(I- Px)2
1
W-rPy)2
-YPx + kux
-YPy + kuy
(30a)
(30b)
where β = 1/200, Y = 0.79, k = 1/4, and (Px , Py) is the position of the ball, which is not
measurable. (ux, uy) is the external force whose sample value at time t are given as ut. This system
13
Under review as a conference paper at ICLR 2022
has a stable equilibrium point (px,py) = (0.5, 0.5) and we simulate this system from this point with
zero velocity. For observation, the pixel intensity at a position X, Y of the video is calculated by
nonlinear equation
(X - px )2 + (Y - py )2
Pixel(X, Y) = max I 0,1-------------------2----------- I + V	(31)
where r = 0.25 and V 〜N(0,0.2042) is noise term. The video image yt is sampled from this
continuous image with 25 × 25 grid from (0, 0) to (1, 1). This system has 2(= nu) inputs, 4(= nx)
states, and 25 × 25 = 625(= ny) outputs.
We discretize this system by forward difference with the time step ∆t = 0.3 and simulate with
random external force (ux, uy) uniformly distributed in [-1, 1] to generate video data. On training,
We choose the hyperparameters of ^χ = 4, hp = hf = 20. E, P and f have three, three, and
two layers respectively, where each layer contains 64 ReLU neurons, the images are flattened into
vectors with 625 elements, and all layers are fully connected. The training dataset consists of a
sequence {(ut, yt)}t1=00-01199, and other settings are the same as in section 5.
In the following, we describe the validation of the obtained model and its application to denoising.
The data used in the following are obtained under the same settings as in training, except that the
realizations of random input and noise are different.
D. 1 Modeling of Dynamics
To verify that the resulting model correctly models the dynamics of the video, we compare the video
from the open-loop simulation of the obtained model with the video from the target system for the
same input (external force).
Here, the output image from the model ift is computed recursively without using yt as
yt = [Iny	0ny ×ny (hf-1)] P (E(UP, 3P), 0n(h^-ι) ^ ,	(32)
where y^P is a sequence of past model outputs defined as in (2). Note that in this test, the ball is
stopped at the center (0.5,0.5) at t = 1, and y^t for t = 1 - hp,..., 0 are set as the image at this
state.
Figure 8 shows the actual images without noise (above) and images from simulation with the model
(below). As shown in the figure, the images obtained from the model simulation are close to the
t = 50 t = 100 t = 150 t = 200 t = 250 t = 300 t = 350 t = 400
Figure 8:	Validation of model dynamics (above: images from target system without noise, below:
images from constructed model)
actual image without noise, indicating that the dynamics are correctly learned. A video version of
figure 8 is provided in the supplementary material as actual-simulated.mp4.
D.2 Noise Reduction
Next, we show that the model obtained by the proposed method can be used for denoising the video.
Here the denoised image ryt is computed from the images yp and inputs up of the past hp frames
14
Under review as a conference paper at ICLR 2022
and the current input ut as
yt = [Iny 0ny ×ny J P (E(Up, yP)，[θnuutf-1)
(33)
Note that unlike the open-loop simulation (32), the state estimator E uses a noisy output ytp instead
of recursively using yp.
Figure 9 shows the result of denoising, The bottom images are the denoised images ryt obtained
from the trained model, and the middle images are the images obtained from the actual system
yt . From the figure, it can be confirmed that the noise is removed by the model obtained by
Figure 9:	(Top) noiseless images, (Middle) noisy images, (Bottom) denoised images
the proposed method. A video version of figure 9 is provided in the supplementary material as
actual-noisy-denoised.mp4.
15