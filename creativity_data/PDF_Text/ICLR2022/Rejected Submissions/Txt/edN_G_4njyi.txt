Under review as a conference paper at ICLR 2022
On the Impact of Client Sampling on Feder-
ated Learning Convergence
Anonymous authors
Paper under double-blind review
Ab stract
While clients’ sampling is a central operation of current state-of-the-art feder-
ated learning (FL) approaches, the impact of this procedure on the convergence
and speed of FL remains under-investigated. In this work we introduce a novel
decomposition theorem for the convergence of FL, allowing to clearly quantify
the impact of client sampling on the global model update. Contrarily to previ-
ous convergence analyses, our theorem provides the exact decomposition of a
given convergence step, thus enabling accurate considerations about the role of
client sampling and heterogeneity. First, we provide a theoretical ground for pre-
viously reported experimental results on the relationship between FL convergence
and the variance of the aggregation weights. Second, we prove for the first time
that the quality of FL convergence is also impacted by the resulting covariance
between aggregation weights. Our theory is general, and is here applied to Multi-
nomial Distribution (MD) and Uniform sampling, the two default client sampling
schemes of FL, and demonstrated through a series of experiments in non-iid and
unbalanced scenarios. Our results suggest that MD sampling should be used as
default sampling scheme, due to the resilience to the changes in data ratio during
the learning process, while Uniform sampling is superior only in the special case
when clients have the same amount of data.
1	Introduction
Federated Learning (FL) has gained popularity in the last years as it enables different clients to
jointly learn a global model without sharing their respective data. Among the different FL ap-
proaches, federated averaging (FedAvg) has emerged as the most popular optimization scheme
(McMahan et al., 2017). An optimization round of FedAvg requires data owners, also called clients,
to receive from the server the current global model which they update on a fixed amount of Stochas-
tic Gradient Descent (SGD) steps before sending it back to the server. The new global model is then
created as the weighted average of the client updates, according to their data ratio.
FedAvg was first proven to converge experimentally (McMahan et al., 2017), before theoretical
guarantees were provided for any non-iid federated dataset (Wang et al., 2020a; Karimireddy et al.,
2020; Haddadpour & Mahdavi, 2019; Khaled et al., 2020). A drawback of naive implementations
of FedAvg consists in requiring the participation of all the clients at every optimization round. As
a consequence, the efficiency of the optimization is limited by the communication speed of the
slowest client, as well as by the server communication capabilities. To mitigate this issue, the
original FedAvg algorithm already contemplated the possibility of considering a random subset of
m clients at each FL round. It has been subsequently shown that, to ensure the convergence of
FL to its optimum, clients must be sampled such that in expectation the resulting global model
is identical to the one obtained when considering all the clients (Wang et al., 2020a; Cho et al.,
2020). Clients sampling schemes compliant with this requirement are thus called unbiased. Due
to its simplicity and flexibility, the current default unbiased sampling scheme consists in sampling
m clients according to a Multinomial Distribution (MD), where the sampling probability depends
on the respective data ratio (Li et al., 2020a; Wang et al., 2020a; Li et al., 2020c; Haddadpour
& Mahdavi, 2019; Li et al., 2020b; Wang & Joshi, 2018; Fraboni et al., 2021). Nevertheless, when
clients have identical amount of data, clients can also be sampled uniformly without replacement (Li
et al., 2020c; Karimireddy et al., 2020; Reddi et al., 2021; Rizk et al., 2020). In this case, Uniform
sampling has been experimentally shown to yield better results than MD sampling (Li et al., 2020c).
1
Under review as a conference paper at ICLR 2022
In spite of the practical usage of sampling in FL, the impact of different unbiased client sampling
schemes on the convergence and speed of FL remains to date under-investigated. In (Fraboni et al.,
2021), MD sampling was extended to account for collections of sampling distributions with vary-
ing client sampling probability, to define clustered sampling. From a theoretical perspective, this
approach was proven to have identical convergence guarantees of MD sampling, with albeit experi-
mental improvement justified by lower variance of the clients’ aggregation weights. Another study
investigated the convergence guarantees of FedAvg under different sampling schemes, through a
penalized optimization framework (Li et al., 2020c). These studies reflect the ongoing interest and
need for a theoretical framework to elucidate the impact of client sampling on FL convergence.
The main contribution of this work consists in deriving a decomposition theorem for the convergence
of FL, allowing to clearly quantify the impact of client sampling on the global model update at
any FL round. This contribution has important theoretical and practical implications. First, we
demonstrate the dependence of FL convergence on the variance of the aggregation weights. Second,
we prove for the first time that the convergence speed is also impacted through sampling by the
resulting covariance between aggregation weights. Contrarily to the convergence bound illustrated
in (Li et al., 2020c), our theorem provides the exact decomposition of a given convergence step,
thus enabling accurate quantification of the role of client sampling and heterogeneity in FL. From
a practical point of view, we establish both theoretically and experimentally that client sampling
schemes based on aggregation weights with sum different than 1 are less efficient. We also prove
that MD sampling is outperformed by Uniform sampling only when clients have identical data ratio.
Finally, we show that the comparison between different client sampling schemes is appropriate only
when considering a small number of clients. Our theory ultimately shows that MD sampling should
be used as default sampling scheme, due to the favorable statistical properties and to the resilience
to FL applications with varying data ratio and heterogeneity.
Our work is structured as follows. In Section 2, we provide formal definitions for FL, unbiased client
sampling, and for the server aggregation scheme. In Section 3, we introduce our decomposition
theorem (Theorem 1) relating the convergence of FL to the aggregation weight variance of the client
sampling scheme. Consistently with our theory, in Section 4, we experimentally demonstrate the
importance of the clients aggregation weights variance and covariance on the convergence speed,
and conclude by recommending Uniform sampling for FL applications with identical client ratio,
and MD sampling otherwise.
2	Background
Before investigating in Section 3 the impact of client sampling on FL convergence, we recapitulate
in Section 2 the current theory behind FL aggregation schemes for clients local updates. We then
introduce a formalization for unbiased client sampling.
2.1	Aggregating clients local updates
In FL, we consider a set I of n clients each respectively owning a dataset Di composed of ni
samples. FL aims at optimizing the average of each clients local loss function weighted by pi such
that Pin=1 pi = 1, i.e.
n
L(θ) = X piLi(θ),	(1)
i=1
where θ represents the model parameters. The weight pi can be interpreted as the importance given
by the server to client i in the federated optimization problem. While any combination of {pi } is
possible, we note that in practice, either (a) every device has equal importance, i.e. pi = 1/n, or (b)
every data point is equally important, i.e. pi = ni/M with M = Pin=1 ni. Unless stated otherwise,
in the rest of this work, we consider to be in case (b), i.e. ∃i, pi 6= 1/n.
In this setting, to estimate a global model across clients, FedAvg (McMahan et al., 2017) is an
iterative training strategy based on the aggregation of local model parameters. At each iteration step
t, the server sends the current global model parameters θt to the clients. Each client updates the
respective model by minimizing the local cost function Li (θ) through a fixed amount K of SGD
steps initialized with θt . Subsequently each client returns the updated local parameters θit+1 to the
2
Under review as a conference paper at ICLR 2022
server. The global model parameters θt+1 at the iteration step t + 1 are then estimated as a weighted
average:
n
θt+1 = Xpiθit+1.	(2)
i=1
To alleviate the clients workload and reduce the amount of overall communications, the server often
considers m ≤ n clients at every iteration. In heterogeneous datasets containing many workers,
the percentage of sampled clients m/n can be small, and thus induce important variability in the
new global model, as each FL optimization step necessarily leads to an improvement on the m
sampled clients to the detriment of the non-sampled ones. To solve this issue, Reddi et al. (2021);
Karimireddy et al. (2020); Wang et al. (2020b) propose considering an additional learning rate ηg
to better account for the clients update at a given iteration. We denote by ωi (St) the stochastic
aggregation weight of client i given the subset of sampled clients St at iteration t . The server
aggregation scheme can be written as:
n
θt+1 = θt + ηg X ωi(St)(θit+1 - θt).	(3)
i=1
2.2 Unbiased clients sampling
While FedAvg was originally based on the uniform sampling of clients (McMahan et al., 2017), this
scheme has been proven to be biased and converge to a suboptimal minima of problem (1) (Wang
et al., 2020a; Cho et al., 2020; Li et al., 2020c). This was the motivation for Li et al. (2020c) to
introduce the notion of unbiasedness, where clients are considered in expectation subject to their
importance pi, according to Definition 1 below. Unbiased sampling guarantees the optimization of
the original FL cost function, while minimizing the number of active clients per FL round. We note
that unbiased sampling is not necessarily related to the clients distribution, as this would require to
know beforehand the specificity of the clients’ datasets.
Unbiased sampling methods (Li et al., 2020a;c; Fraboni et al., 2021) are currently among the stan-
dard approaches to FL, as opposed to biased approaches, known to over- or under-represent clients
and lead to suboptimal convergence properties (McMahan et al., 2017; Nishio & Yonetani, 2019;
Jeon et al., 2020; Cho et al., 2020), or to methods requiring additional computation work from
clients (Chen et al., 2020a).
Definition 1 (Unbiased Sampling). A client sampling scheme is said unbiased if the expected value
of the client aggregation is equal to the global deterministic aggregation obtained when considering
all the clients, i.e.
nn
ESt X Wi (St 溺：=X P排,	(4)
i=1	i=1
where wj(St) is the aggregation weight of client j for subset of clients St.
The sampling distribution uniquely defines the statistical properties of stochastic weights. In this
setting, unbiased sampling guarantees the equivalence between deterministic and stochastic weights
in expectation. Unbiased schemes of primary importance in FL are MD and Uniform sampling, for
which we can derive a close form formula for the aggregation weights :
MD sampling. This scheme considers l1, ..., lm to be the m iid sampled clients from a Multinomial
Distribution with support on {1, ..., m} satisfying P(lk = i) = pi (Wang et al., 2020a; Li et al.,
2020a;c; Haddadpour & Mahdavi, 2019; Li et al., 2020b; Wang & Joshi, 2018; Fraboni et al., 2021).
By definition, we have Pin=1 pi = 1, and the clients aggregation weights take the form:
1m
ωi(St) = — X I(lk = i).	(5)
m k=1
Uniform sampling. This scheme samples m clients uniformly without replacement. Since in this
case a client is sampled with probability p({i ∈ St}) = m/n, the requirement of Definition 1
implies:
ωi(St)= I(i ∈ St) —pi.	⑹
3
Under review as a conference paper at ICLR 2022
Table 1: Synthesis of statistical properties of different sampling schemes.
SamPling	Var[ωi(St)]	α	Var[Pi=ι	ωi(St)]
Full participation	= 0	=	0	= 0
MD	= - m1 Pl + mm Pi	=	1/m	=0
Uniform	=(言 - 1) p∣	=焉-)=就-)[nPn=ιP∣ - 1]
We note that this formulation for Uniform sampling is a generalization of the scheme previously
used for FL applications with identical client importance, i.e. Pi = 1/n (Karimireddy et al., 2020;
Li et al., 2020c; Reddi et al., 2021; Rizk et al., 2020). We note that Var [Pin=1 ωi(St)] = 0 if and
only if Pi = 1/n for all the clients as, indeed, Pn=I ωi(St) = m^1 = 1
With reference to equation (3), we note that by setting ηg = 1, and by imposing the condition
∀St, Pin=1 ωi(St) = 1, we retrieve equation (2). This condition is satisfied for example by MD
sampling and Uniform sampling for identical clients importance.
We finally note that the covariance of the aggregation weights for both MD and Uniform sam-
pling is such that there exists an α such that ∀i 6= j, Cov [ωi(St), ωj(St)] = -αPiPj. We
provide in Table 1 the derivation of α and the resulting covariance for these two schemes with
calculus details in Appendix A. Furthermore, this property is common to a variety of sampling
schemes, for example based on Binomial or Poisson Binomial distributions (detailed derivations
can be found in Appendix A). Following this consideration, in addition to Definition 1, in the
rest of this work we assume the additional requirement for a client sampling scheme to satisfy
∃α ≥ 0, ∀i 6= j, Cov [ωi(St),ωj(St)] = -αPiPj.
3 Convergence Guarantees
Based on the assumptions introduced in Section 2, in what follows we elaborate a new theory relating
the convergence ofFL to the statistical properties of client sampling schemes. In particular, Decom-
position Theorem 1 describes the impact of client sampling on a single optimization step, while
Theorem 2 quantifies the asymptotic relationship between client sampling and FL convergence.
3.1	Decomposition Theorem
Assumption 1 (Unbiased Gradient and Bounded Variance). Every client stochastic gradient
gi(x|B) of a model x evaluated on batch B is an unbiased estimator of the local gradient. We
thus have EB [ξi(B)] = 0 and0 ≤ EB [kξi(B)∣∣2] ≤ σ2, with ξi(B) = gi(x∣B) 一 NLi(X).
the following Decomposition Theorem highlights the impact of client sampling on a single FL op-
timization step. For any optimization round, it provides an explicit link between the statistical
properties of the sampling scheme (variance and covariance) and the expected distance between the
global model and the related optimum.
Theorem 1 (Decomposition Theorem). We consider yit,k the local model of client i after k SGD
steps initialized on model θt. We consider the vector ξit of the gradient noises ξit,k = [gi (yit,k) -
NLi (yit,k)] satisfying Assumption 1, and ∆it = PkK=-01 NLi (yit,k). We consider a client sampling
scheme satisfying Definition 1, and such that Cov [ωi(St), ωj (St)] = -αPiPj. For any given opti-
mization round based on equation (3), the following equation holds:
n
Et [∣∣θt+1 - θ*∣∣2] = ∣∣θt - θ*∣∣2 一 2ηg hXPiEt 网+1 - θt],θ* - θti +ηgη∣Q(θt)	⑺
i=1
X----------------{---------------}
Direction drift
4
Under review as a conference paper at ICLR 2022
with
Q(θt) = Xn νi	Ethξit2i	+Xn γiEt	h∆it2i +(1-α)Et	Xn pi∆it	,	(8)
i=1	、----------}	i=1	、~- --------}	Ul i=1	Il |
Gradient Estimator Noise	Local Model Drift	、	-V-	/
=Ni(θt)	=Li(θt)	Global Model Drift
=G({pi},θt)
where θ* is the optimum of the optimization problem (1), Vi = [Var [ωi(St)] + p2], Yi =
Var [ωi(St)] + αpi2, and Et [X] is the expected value of X conditioned on θt.
The Decomposition Theorem (proof in Appendix B) shows that FL convergence is impacted by a
client sampling through the quantities Var [ωi(St)] and α, which both depend on the clients aggre-
gation weights. These variables modulate three quantities, Ni(θt), Li(θt) and G({pi}, θt), rep-
resenting respectively the stochastic gradient estimator noise, and the local and global model drift
from the current initialization, which are independent from client sampling. In particular, the quality
of clients data impacts the convergence speed through Ni(θt). The Decomposition Theorem also
provides a necessary condition for an optimization step to improve the current global model: the ex-
pected client contribution Et Pin=1 pi θit+1 - θt needs to be collinear with the global direction
of the optimum θ* - θt.
To further clarify the influence of client sampling on the FL convergence we introduce the follow-
ing property (proof in Appendix A.1) introducing the quantity Var [Pin=1 ωi(St)], the variance of
the sum of the aggregation weights, and showing its relationship with the variance of the clients
aggregation weights Var [ωi(St)], and with the covariance parameter α.
Property 1. For any client sampling, we have 0 ≤ α ≤ 1 and
n
Var X ωi (St)
i=1
nn
XVar[ωi(St)] - α 1 - Xpi2
i=1	i=1
(9)
Since 0 ≤ α ≤ 1, the global model drift G({pi}, θt) contributes positively to equation (8), and the
term Q(θt) is always positive. This means that Q(θt) is not negligible, and an appropriate sampling
scheme should be defined such that Q(θt) is minimized. We note that the impact of a client sampling
can always be mitigated by considering a smaller local learning rate ηl . Indeed, the client drift is
proportional to ηl while Q(θt) is proportional to ηl2.
3.2	Asymptotic FL convergence with respect to client sampling
To prove FL convergence with client sampling, our work relies on the following two assumptions
(Wang et al., 2020a; Li et al., 2020a; Karimireddy et al., 2020; Haddadpour & Mahdavi, 2019; Wang
et al., 2019a;b):
Assumption 2 (Smoothness). The clients local objective function is L-Lipschitz smooth, that is,
∀i ∈ {1, ...,n}, kVLi(x) - VLi(y)k ≤ L ∣∣x - y∣∣.
Assumption 3 (Bounded Dissimilarity ). There exist constants β2 ≥ 1 and κ2 ≥ 0 such that for ev-
ery combination of positive weights {wi} such that Pin=1 wi = 1, we have Pin=1 wi ∣VLi(x)∣2 ≤
β2 ∣VL(x)∣2 + κ2. If all the local loss functions are identical, then we have β2 = 1 and κ2 = 0.
We formalize in the following theorem the relationship between the statistical properties of the client
sampling scheme and the asymptotic convergence of FL (proof in Appendix C).
Theorem 2 (FL convergence). Let us consider a client sampling scheme satisfying Definition 1 and
such that for i 6= j, Cov [ωi (St), ωj (St)] = -αpipj ≤ 0. Under Assumptions 1 to 3, and with
sufficiently small local step size ηl, the following convergence bound holds:
TXE hllvL(θt)∣∣2i ≤ O (η^KT) + O (η2(K - 1)σ2) + O (η2K(K - 1)κ2)
+ O Lgηι ς + Xp2 σ2) + O (ηgηιγ [(K -I)σ2 + Kκ2]), (IO)
5
Under review as a conference paper at ICLR 2022
where K is the number of local SGD, and
n	nn
Σ=XVar [ωi(St)] and γ = XVar[ωi(St)] +αXpi2.	(11)
We first observe that any client sampling scheme satisfying the assumptions of Theorem 2 converges
to its optimum. Through Σ and γ, equation (10) shows that our bound is proportional to the clients
aggregation weights through the quantities Var [ωi (St)] and α, which thus should be minimized.
These terms are non-negative and are minimized and equal to zero only with full participation of the
clients to every optimization round. Theorem 2 does not require the sum of the weights ωi (St) to be
equal to 1. Yet, for client sampling satisfying Var [Pn=ι ω"t)] = 0, We get a a Σ. Hence, Choos-
ing an optimal client sampling scheme amounts at choosing the client sampling with the smallest Σ.
This aspect has been already suggested in Fraboni et al. (2021).
The convergence guarantee proposed in Theorem 2 extends the Work of Wang et al. (2020a) Where,
in addition of considering FedAvg With clients performing K vanilla SGD, We include a server
learning rate ηg and integrate client sampling (equation (3)). With full client participation (Σ = γ =
0) and ηg = 1, We retrieve the convergence guarantees of Wang et al. (2020a). Furthermore, our
theoretical frameWork can be applied to any client sampling satisfying the conditions of Theorem
2. In turn, Theorem 2 holds for full client participation, MD sampling, Uniform sampling, as Well
as for the other client sampling schemes detailed in Appendix A. Finally, the proof of Theorem
2 is general enough to account for FL regularization methods (Li et al., 2020a; 2019; Acar et al.,
2021), other SGD solvers (Kingma & Ba, 2015; Ward et al., 2019; Li & Orabona, 2019), and/or
gradient compression/quantization (Reisizadeh et al., 2020; Basu et al., 2019; Wang et al., 2018).
For all these applications, the conclusions draWn for client samplings satisfying the assumptions of
Theorem 2 still hold.
3.3	Application to current client sampling schemes
MD sampling. When using Table 1 to compute Σ and γ close-form We obtain:
n
1-Xpi2
i=1
∑MD = 一
m
and YMD = —,	(12)
m
where we notice that ∑mD ≤ *=YMD. Therefore, one can obtain looser convergence guarantees
than the ones of Theorem 2, independently from the amount of participating clients n and set of
clients importance {pi}, while being inversely proportional to the amount of sampled clients m. The
resulting bound shows that FL with MD sampling converges to its optimum for any FL application.
Uniform sampling. Contrarily to MD sampling, the stochastic aggregation weights of Uniform
sampling do not sum to 1. As a result, we can provide FL scenarios diverging when coupled with
Uniform sampling. Indeed, using Table 1 to compute Σ and Y close-form we obtain
nn
ςU=h m - 1iX p2 and YU= 1+n-ɪ h m - 1iX p2,	(13)
i=1	i=1
where we notice that YU = [1 + n-ɪ] ∑u. Considering that Pn=ι P ≤ 1, we have ∑u ≤ m 一 1,
which goes to infinity for large cohorts of clients and thus prevents FL with Uniform sampling to
converge to its optimum. Indeed, the condition Pin=1 pi2 ≤ 1 accounts for every possible scenario
of client importance {pi}, including the very heterogeneous ones. In the special case where pi =
1/n, we have Pin=1 pi2 = 1/n, such that ΣU is inversely proportional to both nand m. Such FL
applications converge to the optimum of equation (1) for any configuration of n, {pi } and m.
Moreover, the comparison between the quantities Σ and Y for MD and Uniform sampling shows that
Uniform sampling outperforms MD sampling when pi = 1/n. More generally, Corollary 1 provides
sufficient conditions with Theorem 2 for Uniform sampling to have better convergence guarantees
than MD sampling (proof in Appendix C.7).
Corollary 1. Uniform sampling has better convergence guarantees than MD sampling when ΣU ≤
ΣMD, and YU ≤ YMD which is equivalent to
n
Xpi2
i=1
1
≤---------
n - m + 1
(14)
6
Under review as a conference paper at ICLR 2022
Corollary 1 can be related to Var [Pin=1 ωi(St)], the variance for the sum of the aggregation weights,
which is always null for MD sampling, and different of 0 for Uniform sampling except when pi =
1/n for all the clients.
A last point of interest for the comparison between MD and Uniform sampling concerns the re-
spective time complexity for selecting clients. Sampling with a Multinomial Distribution has time
complexity O(n + m log(n)), where O(n) comes from building the probability density function
to sample clients indices (Tang, 2019). This makes MD sampling difficult to compute or even in-
tractable for large cohorts of clients. On the contrary sampling m elements without replacement
from n states is a reservoir sampling problem and takes time complexity O(m(1 + log(n/m))(Li,
1994). In practice, clients either receive identical importance (pi = 1/n) or an importance pro-
Portional to their data ratio, for which We may assume computation Pi = O( 1). As a result, for
important amount n of participating clients, Uniform sampling should be used as the default client
sampling due to its lower time complexity. However, for small amount of clients and heterogeneous
client importance, MD sampling should be used by default.
Due to space constraints, we only consider in this manuscript applying Theorem 2 to Uniform and
MD sampling, which can also be applied to Binomial and Poisson Binomial sampling introduced
in Section A, and satisfying our covariance assumption. To the best of our knowledge, we could
only find clustered sampling introduced in Fraboni et al. (2021) not satisfying this assumption. Still,
with minor changes, we provide for this sampling scheme a similar bound to the one of Theorem 2
(Appendix C.6), ultimately proving that clustered sampling improves MD sampling.
4	Experiments
In this section we provide an experimental demonstration of the two main theorems of Section
3, by quantifying the correctness of Decomposition Theorem 1, and by verifying the convergence
properties identified in Theorem 2.
4.1	Synthetic experiment
We consider a synthetic FL experiment where the clients models are defined by quadratic local loss
functions. This choice enables closed-form computation of the global optimum, as well as of the
expectation of the distance between global model and optimum during a single FL optimization step.
We consider n = 10 clients jointly learning a model with m = 5 of them sampled by the server
at each optimization step. Each client local loss function is Li(θ) = 1 ∣∣θ - θ"∣2 with optimum
θi 〜N(0d,Id), where d = 20 is the number of parameters in the model. The optimum of the
global loss function of equation (1) is θ* = PZi Piθ" We consider varying p1, the importance of
client 1, while giving identical importance to the remaining clients, i.e.
p1 = r and pi = (1 - r)/(n - 1), i 6= 1.	(15)
By varying r between 0 and 1, we investigate scenarios with different level of heterogeneity for the
clients importance. We perform full gradient descents, which makes client sampling the only source
of randomness during optimization. Lastly, we only consider a single FL optimization step initial-
ized with a global model θ0 〜 N(0d, Id). We compare the average distance of 1000 simulations
obtained after a single FL round to the theoretical one provided by the Decomposition Theorem 1
(see Appendix D for the closed form equation derived for the controlled example here proposed).
The scenario above is tested in two different experimental settings: an iid one, where θi = θɪ, and
a non-iid one, where every client local model is drawn independently.
The theoretical expected distance ∣∣θ1 - θ* ∣∣2 is plotted for iid and non-iid case in Figure 1a and 1b.
The corresponding experimental distance resulting from the 1000 simulations is shown in Figure 1c
and 1d. We note that there is a close match between theoretical and experimental results, demon-
strating the validity of Decomposition Theorem 1. Figure 1 highlights the following properties:
Iid case (Figure 1a and 1c). In the iid setting the expected difference obtained with MD sampling
is equivalent to the one obtained when all the clients are considered (Full). This demonstrates that
in the iid case the covariance parameter α does not affect FL convergence (Section 3). Moreover,
Uniform sampling leads to generally poor convergence results, thus confirming that the variance of
7
Under review as a conference paper at ICLR 2022
Figure 1: Illustration of the Decomposition Theorem 1 for the synthetic scenario described in Section
4.1 for n = 10 clients when sampling m = 5 of them. Panels (a) and (b) show the theoretical
distances between global model and FL optimum obtained with the Decomposition Theorem 1 in
respectively iid and non-iid settings. Panels (c) and (d) show the distances estimated experimentally
when averaging over 1000 simulations for iid and non-iid settings. We consider ηg = 1, ηl = 0.1,
and K = 10.
the sum of the clients stochastic weights, VarSt [Pin=1 ωi(St)], negatively impacts FL convergence.
More precisely, the only case where Uniform sampling is comparable to the other schemes is when
p1 = 0.1, which indeed corresponds to the special scenario in which pi = 1/n, and thus the variance
associated to Uniform sampling is zero (cfr. Table 1).
Non iid case (Figure 1b and 1d). The conclusions drawn for the iid case still hold when the lo-
cal optima are not identical across clients. Moreover, we can now appreciate the impact of the
covariance parameter α on the convergence speed. Independently from the choice for p1, the min-
imum distance is obtained when considering all the clients. In this case we have both α = 0 and
VarSt [Pin=1 ωi(St)] = 0. When pi = 1/n = 0.1, both MD and Uniform sampling have null vari-
ance VarSt [Pin=1 ωi(St)]. In this case, the negative impact of the covariance through the parameter
α penalizes MD sampling. The penalization of the covariance term on MD sampling is still relevant
when p1 is close to the critical value of 0.1. Finally, for large enough values ofp1, the variance term
outweights the effect of the covariance, making MD better than Uniform sampling.
Diverging Uniform sampling. Consistently with Figure 1, in Appendix E we provide further ex-
amples showing that Uniform sampling can diverge in simple FL setting with heterogeneous client
importance. We still consider n = 10 clients and sample m = 5 of them with p1 = r = 0.9. When
sampled, clients perform K = 1 SGD to show that the divergence does not come from the clients
local work K. Figure 4 of Appendix E shows that for this scenario, FL with MD sampling converges
while FL with Uniform sampling diverges both for iid and non-iid client data distribution.
4.2	Experiment on real data
We study a LSTM model for next character prediction on the dataset of The complete Works of
William Shakespeare (McMahan et al., 2017; Caldas et al., 2018). We use a two-layer LSTM
classifier containing 100 hidden units with an 8 dimensional embedding layer. The model takes as
an input a sequence of 80 characters, embeds each of the characters into a learned 8-dimensional
space and outputs one character per training sample after 2 LSTM layers and a fully connected one.
When selected, a client performs K = 50 SGD steps on batches of size B = 64 with local
learning rate ηl = 1.5. The server considers the clients local work with ηg = 1. We consider
n ∈ {10, 20, 40, 80} clients, and sample half of them at each FL optimization step. While for sake
of interpretability we do not apply a decay to local and global learning rates, we note that our theory
remains unchanged even in presence of a learning rate decay. In practice, for dataset with important
heterogeneity, considering ηg < 1 can speed-up FL with a more stable convergence.
Clients have identical importance [pi = 1/n]. We note that Uniform sampling consistently out-
performs MD sampling due to the lower covariance parameter, while the improvement between the
resulting convergence speed is inversely proportional to the number of participating clients n (Figure
2a). This result confirms the derivations of Section 3.
8
Under review as a conference paper at ICLR 2022
# rounds	# rounds
——IO ——20	——40	——80
Figure 2: Difference between the convergence of the global losses resulting from MD and Uniform
sampling when considering n ∈ {10, 20, 40, 80} clients and sampling m = n/2 of them. In (a),
clients have identical importance, i.e. pi = 1/n. In (b), clients importance is proportional to their
amount of data, i.e. pi = ni/M. Differences in global losses are averaged across 30 FL experiments
with different model initialization (global losses are provided in Appendix E).
Clients importance depends on the respective data ratio [pi = ni/M]. In this experimental
scenario the aggregation weights for Uniform sampling do not always sum to 1, thus leading to the
slow-down of FL convergence. Hence, we see in Figure 2b that MD always outperforms Uniform
sampling. This experiment shows that the impact on FL convergence of the variance of the sum of
the stochastic aggregation weights is more relevant than the one due to the covariance parameter α.
We also note that the slow-down induced by the variance is reduced when more clients do participate.
This is explained by the fact that the standard deviation of the clients data ratio is reduced with larger
clients participation, e.g. pi = 1/10 ± 0.13 for n = 10 and pi = 1/80 ± 0.017 for n = 80. We thus
conclude that the difference between the effects of MD and Uniform sampling is mitigated with a
large number of participating clients (Figure 2b).
Additional experiments on Shakespeare are provided in Appendix E. We show the influence of the
amount of sampled clients m (Figure 6) and amount of local work K (Figure 8) on the convergence
speed of MD and Uniform sampling.
Finally, additional experiments on CIFAR10 (Krizhevsky, 2009) are provided in Appendix E, where
we replicate the experimental scenario previously proposed in Fraboni et al. (2021). In these appli-
cations, 100 clients are partitioned using a Dirichlet distribution which provides federated scenarios
with different level of heterogeneity. For all the experimental scenarios considered, both results and
conclusions are in agreement with those here derived for the Shakespeare dataset.
5	Conclusion
In this work, we derive a novel Decomposition Theorem demonstrating the impact on FL con-
vergence speed of any unbiased client sampling scheme following the assumptions of Section 2.
Moreover, Theorem 2 highlights the asymptotic impact of client sampling on FL, and shows that
the convergence speed is inversely proportional to both the sum of the variance of the stochastic
aggregation weights, and to their covariance parameter α. To the best of our knowledge, this work
is the first one accounting for schemes where the sum of the weights is different from 1.
Thanks to our theory, we investigated MD and Uniform sampling from both theoretical and exper-
imental standpoints. We established that when clients have approximately identical importance, i.e
pi = 1/n, Uniform outperforms MD sampling, due to the larger impact of the covariance term for
the latter scheme. On the contrary, Uniform sampling is outperformed by MD sampling in more gen-
eral cases, due to the slowdown induced by its stochastic aggregation weights not always summing
to 1. Yet, in practical scenario with very large number of clients, MD sampling may be unpractical,
and Uniform sampling could be preferred due to the more advantageous time complexity. Finally,
while the contribution of this work is in the study of the impact of clients sampling on the global op-
timization objective, further extensions may focus on the analysis of the impact of clients selection
method on individual users’ performance, especially in presence of heterogeneity.
9
Under review as a conference paper at ICLR 2022
Ethics S tatement
We read and acknowledged the ICLR Code of Ethics.
The experimental correctness of our method was evaluated on publicly available datasets. Datasets
were properly referenced and their construction can be found in the associated references.
This work investigates client sampling, an FL component already introduced in previous literature.
Our work does not change the FL framework and thus does not propose additional client exposure.
There is no conflict of interest. The arguments used in this work are either theoretically proven,
experimentally illustrated, or coming from peer-reviewed work.
Our method is centered around unbiased client sampling and thus does not induce bias in the global
model.
Reproducibility S tatement
Every proposed theoretical result is carefully analyzed in Section 3 and proven in Appendix. Aggre-
gation weight calculus can be found in Appendix A, Theorem 1 can be found in Appendix B, and
Theorem 2 can be found in Appendix C.
The settings of the different experiments are specified in the paper and the code is provided. Fur-
thermore, we use public datasets without any preprocessing.
References
Durmus Alp Emre Acar, Yue Zhao, Ramon Matas, Matthew Mattina, Paul Whatmough, and
Venkatesh Saligrama. Federated learning based on dynamic regularization. In International Con-
ference on Learning Representations, 2021.
Debraj Basu, Deepesh Data, Can Karakus, and Suhas Diggavi. Qsparse-local-sgd: Distributed
sgd with quantization, sparsification and local computations. In H. Wallach, H. Larochelle,
A. Beygelzimer, F. d'Alche-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information
Processing Systems, volume 32. Curran Associates, Inc., 2019.
Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub Konecny, H. Brendan McMa-
han, Virginia Smith, and Ameet Talwalkar. LEAF: A Benchmark for Federated Settings.
(NeurIPS):1-9, 2018.
Wenlin Chen, Samuel Horvath, and Peter Richtarik. Optimal Client Sampling for Federated Learn-
ing. Workshop in NeurIPS: Privacy Preserving Machine Learning, 2020a.
Wenlin Chen, Samuel Horvath, and Peter Richtarik. Optimal client sampling for federated learning,
2020b.
Yae Jee Cho, Jianyu Wang, and Gauri Joshi. Client selection in federated learning: Convergence
analysis and power-of-choice selection strategies, 2020.
Yann Fraboni, Richard Vidal, Laetitia Kameni, and Marco Lorenzi. Clustered sampling: Low-
variance and improved representativity for clients selection in federated learning. In Marina Meila
and Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning,
volume 139 of Proceedings of Machine Learning Research, pp. 3407-3416. PMLR, 18-24 Jul
2021.
Farzin Haddadpour and Mehrdad Mahdavi. On the convergence of local descent methods in feder-
ated learning, 2019.
Tzu Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the effects of non-identical data
distribution for federated visual classification. arXiv, 2019.
Joohyung Jeon, Soohyun Park, Minseok Choi, Joongheon Kim, Young-Bin Kwon, and Sungrae Cho.
Optimal user selection for high-performance and stabilized energy-efficient federated learning
platforms. Electronics, 9(9), 2020. ISSN 2079-9292. doi: 10.3390/electronics9091359.
10
Under review as a conference paper at ICLR 2022
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. SCAFFOLD: Stochastic controlled averaging for federated learning.
In Hal DaUme In and Aarti Singh (eds.), Proceedings of the 37th International Conference on
Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 5132-5143.
PMLR,13-18Jul 2020.
Ahmed Khaled, Konstantin Mishchenko, and Peter Richtarik. Tighter theory for local sgd on iden-
tical and heterogeneous data. In Silvia Chiappa and Roberto Calandra (eds.), Proceedings of the
Twenty Third International Conference on Artificial Intelligence and Statistics, volume 108 of
Proceedings of Machine Learning Research, pp. 4519-4529. PMLR, 26-28 Aug 2020.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR (Poster),
2015.
Alex Krizhevsky. Learning multiple layers of features from tiny images. 2009.
Kim-Hung Li. Reservoir-sampling algorithms of time complexity o(n(1 + log(n/n))). ACM Trans.
Math. Softw., 20(4):481-493, December 1994. ISSN 0098-3500. doi: 10.1145/198429.198435.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smithy.
Feddane: A federated newton-type method. In 2019 53rd Asilomar Conference on Signals, Sys-
tems, and Computers, pp. 1227-1231, 2019. doi: 10.1109/IEEECONF44664.2019.9049023.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated optimization in heterogeneous networks. In I. Dhillon, D. Papailiopoulos, and V. Sze
(eds.), Proceedings of Machine Learning and Systems, volume 2, pp. 429-450, 2020a.
Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith. Fair resource allocation in federated
learning. In International Conference on Learning Representations, 2020b.
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of
fedavg on non-iid data. In International Conference on Learning Representations, 2020c.
Xiaoyu Li and Francesco Orabona. On the convergence of stochastic gradient descent with adaptive
stepsizes. In Kamalika Chaudhuri and Masashi Sugiyama (eds.), Proceedings of the Twenty-
Second International Conference on Artificial Intelligence and Statistics, volume 89 of Proceed-
ings of Machine Learning Research, pp. 983-992. PMLR, 16-18 Apr 2019.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-Efficient Learning of Deep Networks from Decentralized Data. In Aarti Singh
and Jerry Zhu (eds.), Proceedings of the 20th International Conference on Artificial Intelligence
and Statistics, volume 54 of Proceedings of Machine Learning Research, pp. 1273-1282. PMLR,
20-22 Apr 2017.
Takayuki Nishio and Ryo Yonetani. Client selection for federated learning with heterogeneous
resources in mobile edge. In ICC 2019 - 2019 IEEE International Conference on Communications
(ICC), pp. 1-7, 2019. doi: 10.1109/ICC.2019.8761315.
Sashank J. Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konecny,
Sanjiv Kumar, and Hugh Brendan McMahan. Adaptive federated optimization. In International
Conference on Learning Representations, 2021.
Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jadbabaie, and Ramtin Pedarsani.
Fedpaq: A communication-efficient federated learning method with periodic averaging and quan-
tization. In Silvia Chiappa and Roberto Calandra (eds.), Proceedings of the Twenty Third Interna-
tional Conference on Artificial Intelligence and Statistics, volume 108 of Proceedings of Machine
Learning Research, pp. 2021-2031. PMLR, 26-28 Aug 2020.
Elsa Rizk, Stefan Vlaski, and Ali H. Sayed. Dynamic federated learning. In 2020 IEEE 21st
International Workshop on Signal Processing Advances in Wireless Communications (SPAWC),
pp. 1-5, 2020. doi: 10.1109/SPAWC48557.2020.9154327.
Daniel Tang. Efficient algorithms for modifying and sampling from a categorical distribution. CoRR,
abs/1906.11700, 2019.
11
Under review as a conference paper at ICLR 2022
Hongyi Wang, Scott Sievert, Shengchao Liu, Zachary Charles, Dimitris Papailiopoulos, and Stephen
Wright. Atomo: Communication-efficient learning via atomic sparsification. In S. Bengio,
H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in
Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.
Jianyu Wang and Gauri Joshi. Cooperative SGD: A unified Framework for the Design and Analysis
of Communication-Efficient SGD Algorithms. 2018.
Jianyu Wang, Anit Kumar Sahu, Zhouyi Yang, Gauri Joshi, and Soummya Kar. Matcha: Speed-
ing up decentralized sgd via matching decomposition sampling. In 2019 Sixth Indian Control
Conference (ICC),pp. 299-300, 2019a. doi: 10.1109/ICC47138.2019.9123209.
Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H. Vincent Poor. Tackling the objective in-
consistency problem in heterogeneous federated optimization. In Hugo Larochelle, Marc’Aurelio
Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (eds.), Advances in Neural In-
formation Processing Systems 33: Annual Conference on Neural Information Processing Systems
2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020a.
Jianyu Wang, Vinayak Tantia, Nicolas Ballas, and Michael Rabbat. Slowmo: Improving
communication-efficient distributed sgd with slow momentum. In International Conference on
Learning Representations, 2020b.
Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K. Leung, Christian Makaya, Ting He, and
Kevin Chan. Adaptive Federated Learning in Resource Constrained Edge Computing Systems.
IEEE Journal on Selected Areas in Communications, 37(6):1205-1221, 2019b. ISSN 15580008.
doi: 10.1109/JSAC.2019.2904348.
Rachel Ward, Xiaoxia Wu, and Leon Bottou. AdaGrad stepsizes: Sharp convergence over noncon-
vex landscapes. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th
International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning
Research, pp. 6677-6686. PMLR, 09-15 Jun 2019.
12
Under review as a conference paper at ICLR 2022
A Clients Sampling Schemes Calculus
In this section, we calculate for MD, Uniform, Poisson, and Binomial sampling the respective aggre-
gation weight variance Var [ωi(St)], the covariance parameter α such that Cov [ωi(St)), ωj (St)] =
-αpipj, and the variance of the sum of weights Var [Pin=1 ωi(St)]. We also propose statistics for
the parameter N, i.e. the amount of clients the server communicates with at an iteration:
n
N = X I(i ∈ St).
i=1
A. 1 Proof of Property 1
Proof. Covariance parameter
Cov [ωi(St),ωj(St)] = E [ωi(St)ωj(St)] - pipj ≥ -pipj
(16)
(17)
Aggregation Weights Sum
Var
n
X ωi(St)
i=1
n
XVar[ωi(St)]+ X Cov[ωi(St),ωj(St)]
(18)
i=1
n
i,j 6=i
i=1
n
Var [ωi(St)] - α	pipj
i,j6=i
[Var [ωi(St)] - αpi(1 - pi)]
i=1
n
X Var [ωi(St)] - α
i=1
1 -	pi2 ,
i=1
(19)
(20)
(21)
n
where we use Pin=1 pi= 1, equation (1), for the third and fourth equality. Using equation (20), we
see that we can also get the following equality based on Decomposition Theorem 1:
n
n
Var
i=1
ωi(St) =	γi - α.
i=1
(22)
Re-expressing α. Using equation (20), we get
n
n
Var
i=1
which, with reordering, gives
ωi(St) =	Var[ωi(St)] -α
i=1
n
1 - X pi2 ,
i=1
(23)
Pin=1Var[ωi(St)] -Var[Pin=1ωi(St)]
ι - Pn=Ip2
(24)
α
□
A.2 No sampling scheme
When every client participate at an optimization round, we have ωi(St) = pi which gives
VarSt [ωi(St)] = 0, α = 0, and N = n.
A.3 MD sampling
We recall equation (5),
m
ωi(St) = m X I(Ik= i),
k=1
(25)
13
Under review as a conference paper at ICLR 2022
which gives
E[ωi(St)ωj(St)]
1	X E [I(lk = i)I(ll	m = j)] + m X E [I(ik =	i)I(lk	j)]	(26)
m2	k,l6=k	k=1			
1	m X pipj + m X	E [I(lk = i)I(lk =j)]			(27)
m2	k,l6=k	k=1				
m-1
(28)
"+ -m E[I(l = i)I(l=j)]
m
Variance(i = j). We get E [I(l = i)I(l = j)] = E [I(l = i)] = pi, which gives:
Var [ωi(St)] =-p2 +-Pi
mm
Covariance(i 6= j). We get E [I(l = i)I(l = j)] = 0, which gives:
Cov[ωi(St)，叼(St)]=- mPi pj，
(29)
(30)
and by definition we get
1
α =—
m
(31)
Aggregation Weights Sum. Using equation (29)) and (31) with Property 1, we get
Var
n
X ωi(St)
i=1
0.
(32)
Amount of clients. Considering that p(i ∈ St) = 1 - p(i ∈/ St) = 1 - (1 - pi)m, we get:
n
n
E [N] =	P(i ∈ St) = n-	(1 - pi)m ≤ m
(33)
i=1
i=1
A.4 Sampling clients uniformly without replacement
We recall equation (6),
(34)
Variance. We first calculate the probability for a client to be sampled, i.e.
n - m
n - m
m
n
n1
P(i ∈ St) = 1 — P(i ∈ St) = 1-
n
------= = 1----
n - m + 1	n
(35)
Using equation (35), we have
VarSt [ωi(St)] = h-Pii2 Var[I(i ∈ St)]
tm
n2 m
m2 n
(1 - m)p2 =(三 — I)p2
(36)
n
m
Covariance. We have
P({i,j} ∈ St) =P(i∈ St)+P(j ∈St) -P(i∪j∈St)
=P(i∈ St)+P(j ∈St) -(1-P({i,j} ∈/ St)),
(37)
(38)
and
P({i,j} ∈/ St)
n - 2 n - m - 1	(n - m)(n - m - 1)
...
n n - m + 1
n(n - 1)
(39)
14
Under review as a conference paper at ICLR 2022
Substituting equation (35) and (39) in equation (38) gives
P({i,j}∈ St) =2- - 1 +
(n - -)(n - - - 1)
n(n- 1)
(40)
n(n - 1)
[2m(n - 1) - n(n- 1) + (n-m)(n-m - 1)]
(41)
n
1
-(- - 1)
n(n- 1)
(42)
Hence, we can express the aggregation weights covariance as
CovE(St),ωj (St)] = - -(-- 11))PjPk - PjPk,
(43)
which gives
n-m
α =---------.
(n - 1)
(44)
Aggregation Weights Sum. Combining equation (36) and (44) with Property 1 gives
n
n
Var
X ωi(St)= X [mn- 1] Pp-
i=1
i=1
n-m
m(n- 1)
n-m
m(n- 1)
n
n X Pi2 - 1 ,
i=1
n
pi (1 - pi)
i=1
(45)
(46)
where We retrieve Var [Pn=ι ωi(St)] = 0 for identical client importance, i.e. Pn=ι P = ɪ
Amount of Clients. N = .
A.5 Poisson Binomial Distribution
Clients are sampled according to a Bernoulli with a probability proportional to their importance pi ,
i.e.
ωi(St) = ɪ B(-Pi).
-
Hence, only — ≥ Pmax can be sampled and we retrieve E 心⑸)]=+-Pi = Pi.
Variance.
VarSt [ωi(St)I = - -Pi(I- -Pi) = - Pi(I- -Pi)
Covariance. Due to the independence of each stochastic weight, we also get:
Cov[ωi(St),ωj(St)] = 0
(47)
(48)
(49)
Aggregation Weights Sum. Using Property 1 we obtain
n
Var	ωi (St)
i=1
1n
ɪ - X p2.
-
i=1
(50)
Amount of Clients.
n
E [N] = - and Var [N] = - - -2	Pi2.
i=1
(51)
15
Under review as a conference paper at ICLR 2022
A.6 Binomial Distribution
Clients are sampled according to a Bernoulli with identical sampling probability, i.e.
nm
ωi(St) = m B( n )pi.
Hence, We retrieve E Q(St)] = mmPi = pi.
Variance.
n2 m
Varst E(St)]=『—(1
t	m2 n
m n - m
-n )p2 =—
Covariance. Due to the independence of each stochastic Weight, We have:
Cov[ωi(St),ωj(St)] =0.
Aggregation Weights Sum. Using Property 1 gives
nn
Var X“,(St) = n—m X泮
i=1	i=1
Amount of Clients.
E [N] = m and Var [N]=m..
(52)
(53)
(54)
(55)
(56)
A.7 Clustered Sampling
Clustered sampling (Fraboni et al., 2021) is a generalization of MD sampling Where instead of
sampling m clients from the same distributions, m clients are sampled from m different distributions
{Wk}km=1 each of them privileging a different subset of clients. We denote by rk,i the probability
of client i to be sampled in distribution k. To satisfy Definition 1, the original Work (Fraboni et al.,
2021) provides the conditions:
nm
∀k ∈ {1, ..., m},	rk,i = 1 and ∀i ∈ {1, ..., n},	rk,i = mpi.	(57)
i=1	k=1
The clients aggregation Weights remain identical to the one of MD sampling, i.e.
1K
ωi(Scι) = - EI(Ik = i),
m
k=1
(58)
Where I(lk = i) are still independently distributed but not identically.
We have
E[ωi(St)ωj(St)]	1 =—— m2	m X E [I(ik = i)I(il = j)] + —2 XE [I(ik = k,l6=k	k=1 m	i)I(lk	j)]	(59)
	1 =—— m2	X rk,irlj + —2 X E [I(lk = i)I(lk =j)] k,l6=k	k=1			(60)
	PiPj	1m	1m — m2 X MN + m2 X E [I(lk = i)I(lk:	=j)],		(61)
Where We retrieve equation (28) When rk,i = pi.
Variance (i = j). We get E [I(lk = i)I(lk = j)] = E [I(lk = i)] = rk,i, Which gives:
1	1m
Var [ωi(SCl)] = —Pi-----2 5S rk,i ≤ Var [ωi(SMD)],
m m k=1
(62)
16
Under review as a conference paper at ICLR 2022
where the inequality comes from using the Cauchy-Schwartz inequality with equality if and only if
all the m distributions are identical, i.e. rk,i = pi.
Covariance (i 6= j). We get E [I(lk = i)I(lk = j)] = 0, which gives:
1m
Cov [ωi(Scι), ωj(Scι)]=-标 X lTk,ilTk,j ≤ Cov E(Smd), ωj(SMD)],	(63)
m k=1
where the inequality comes from using the Cauchy-Schwartz inequality with equality if and only if
all the m distributions are identical, i.e. rk,i = pi .
Aggregation Weights Sum
n
Var X ωi (SCl) = 0.	(64)
i=1
A.8 Optimal Sampling
With optimal sampling (Chen et al., 2020b), clients are sampled according to a Bernoulli distribution
with probability qi, i.e.
ωi(St)= i— B(qi).	(65)
qi
Hence, We retrieve E 心回)]=piq% = pi.
Variance.
VarSt E(St)] = -qip2.	(66)
qi
Covariance. Due to the independence of each stochastic Weight, We have:
Cov[ωi(St),ωj(St)] =0.	(67)
Aggregation Weights Sum. Using Property 1 gives
	Var	n X ωi(St) i=1	n =X i=1	1-ii p2 pi . qi	(68)
Amount of Clients.	n E[N] = Xqi and Var[N] = i=1			n qi(1- qi). i=1	(69)
17
Under review as a conference paper at ICLR 2022
Symbol
n
K
ηl
ηg
η
θt
θ*
θit+1
yit,k
pi
m
St
ωi(St)
α
γi
Et H
L(∙)
Li(∙)
gi(∙)
ξi
L
σ2
β, κ
Table 2: Common Notation Summary.
Description
Number of clients.
Number of local SGD.
Local/Client learning rate.
Global/Server learning rate.
Effective learning rate, η =曲飞.
Global model at server iteration t.
Optimum of the federated loss function, equation (1).
Local update of client i on model θt.
Local model of client i after k SGD (yit,K = θit+1 and yit,0 = θt).
Importance of client i in the federated loss function, equation (1).
Number of sampled clients .
Set of participating clients considered at iteration t.
Aggregation weight for client i given St .
Covariance parameter.
cf Section 3
Expected value conditioned on θt .
Federated loss function, equation 1
Local loss function of client i.
SGD. We have Eξi [gi(∙)] = VLi(∙) with Assumption 1.
Random batch of samples from client i of size B.
Lipschitz smoothness parameter, Assumption 2.
Bound on the variance of the stochastic gradients, Assumption 1.
Assumption 3 parameters on the clients gradient bounded dissimilarity.
B Decomposition Theorem 1
In Table 2, we provide the definition of the different notations used in this work. We also propose in
Algorithm 1 the pseudo-code for FedAvg with aggregation scheme (3).
Algorithm 1 Federated Learning based on equation (3)
1:	The server sends to the n clients the learning parameters (K, ηι, B).
2:	for t ∈ {0, ..., T - 1} do
3:	Sample a set of clients St and get their aggregation weights di(t).
4:	Send to clients in St the current global model θt .
5:	Receive each sampled client contributions ci(t) = θit+1 - θt.
6:	Creates the new global model θt+1 = θt + ηg Pin=1idi(t)ci(t).
7:	end for
B.1 Useful Lemma
We first introduce and prove the following useful lemma before introducing the proof of Theorem 1.
Lemma 1. Let us consider n vectors xi, ..., xn and a client sampling satisfying ESt [ωi(St)] = pi
and Cov [ωi (St), ωj (St)] = -αpi pj. We have:
ESt 口XXωi(St)xi∣
n
X γi kxik2 + (1 - α)
i=1
pixi
i=1
(70)

2
where γi = VarSt [ωi (St)] + αpi2.
18
Under review as a conference paper at ICLR 2022
Proof.
ESt
n	2	n	n n
X ωi (St )xi	= XESt ωi(St)2 kxik2 + XXESt [ωi(St)ωj(St)] hxi,xji. (71)
i=1	i=1	i=1 j=1
j6=i
In addition, we have:
ESt [ωi(St)ωj(St)] = Cov [ωi(St),ωj(St)] + pipj = (-α + 1)pipj,	(72)
where the last equality comes from the assumption on the client sampling covariance.
We also have:
nn
hpi xi , pj xj i
i=1 j=1
j6=i
n
pixi
i=1
n
- Xpi2 kxik2 ,
i=1
(73)
Substituting equation (72) and equation (73) in equation (71) gives:
n	1121 n
Xωi(St)xill I = X[Est[ωi(St)2] - (-α 十1底]||©『+ (-α +1)
Considering that we have ESt ωi(St)2 = Var [ωi(St)] + pi2, we have :
ESt ωi(St)2] + (α - 1)pi2 = VarSt [ωi(St)] + αpi2,
Substituting equation (75) in equation (74) completes the proof.
B.2 Proof of the Decomposition Theorem 1
n
pixi
i=1
(74)
(75)
Proof.
Et h∣∣θt+1 -θ*∣∣2i = Et h∣∣(θt+1 - θt) + (θt- θ*)∣∣2i	(76)
=∣∣θt - θ*∣∣2 + 2(Et [θt+1 - θt] , θt - θ*i + Et h∣∣θt+1 - θt∣∣2i , (77)
By construction (equation (3)), we have θt+1 - θt = ηg Pin=1 ωi (St)(θit+1 - θt). The sampling
scheme follows Definition 1 which gives ESt [θt+1 - θt] = ηg Pin=1 pi (θit+1 - θt). Hence , we
get:
n
Et [∣∣θt+1 -θ*∣∣[ = ∣∣θt - θ*∣∣2 + 2ηghXPiEt [θt+1 - θt],θt- θ*i
i=1
Xn ωi(St)(θit+1 - θt)∣∣∣∣ I
___________ - /
{^^^^^^^^^^^^^^^^^^
=ηl2Q(θt)
(78)
Using Lemma 1, we express Q(θt) as follow:
η2Q(θt) = X Yi Et h∣∣θt+1 - θt∣∣2i +(1-α) Et]∣∣X Pi(θt+1 - θt )∣∣ I .	(79)
By construction, we have θit+1 - θt = - PkK=-01 ηlgi(yit,k). Considering Assumption 1 gives
Eh∣∣θit+1-θt∣∣2i =ηl2 hEh∣∣ξit∣∣2i +Eh∣∣∆it∣∣2ii .	(80)
2
□
19
Under review as a conference paper at ICLR 2022
Similarly, by using twice Assumption 1 for the global model drift, we have
η2 EbXPidt∣ I = η2 E
n l2
n ∣2
i=1
n
piξit	+ηl2E	pi∆it
i=1
n
ηi IX p2e^『]+ E IlX Pi∆t
i=1
i=1
where, for the last equality, Assumption 1 gives E hξit, ξjti = E [ξit]T E ξjt = 0.
Combining equation (80) with equation (82) gives
n
Q(θt) =X Var[ωi(St)]+pi2E ξit2
nl
n l2
+ X Yi Egt『] +(1-α)E HX Pi∆t
i=1
i=1
(81)
(82)
(83)
2
Substituting equation (83) in equation (78) completes the proof.
□
B.3 Adaptation to Clustered Sampling
Instead of Lemma 1 which requires Cov [ωi(St), ωj(St)] = -αpipj, we propose the following
Lemma for clustered sampling expressed in function of MD sampling covariance parameter αMD
showing that a sufficient condition for MD sampling to perform as well as Clustered sampling is
that all xi are identical, or that all the distributions are identical, i.e. rk,i = pi .
Lemma 2. Let us consider n vectors xi, ..., xn and a client sampling satisfying ESt [ωi(St)] = pi
and Cov [ωi (SCl), ωj (SCl)] = -αpipj. We have:
2
ES
n
ωi(SCl)xi
i=1
n
≤Xγi(M D) kxi k2 + (1 - αMD)
i=1
pixi
i=1
(84)
where γi(M D) and αMD are the aggregation weights statistics ofMD sampling. Equation (84) is
an equality if and only if	in=1 rk,ixi =	jn=1 rk,j xj.
Proof. Substituting equation (62) in equation (71) gives
ES
n
ωi(SCl)xi
i=1
n	nn
X ESCl ωi(SCl)2 kxik2 + XXpipjhxi,xji
i=1	i=1 j=1
j6=i
1mnn
-m XXX rk,i rk,j hxi，Xj i,
k=1 i=1 j=1
j6=i
(85)
Substituting equation (73) in equation (71) gives:
ESCl
X ωi (SCl)xi ∣∣∣
n
X ESCl ωi(SCl)2 kxik2 +
i=1
n
pixi
i=1
n
- Xpi2 kxik2
i=1
2
-m X I∣X rk,iχi
k=1	i=1
n
- Xrk2,i kxik2
i=1
(86)
20
Under review as a conference paper at ICLR 2022
With rearrangements and using equation (57) we get:
ES
Cl
X ωi (SCl)xi
nm
X Var [ωi(SCl)] + m X r2,i
mn
-ɪ X X
m2
k=1
i=1
rk,ixi
kxik2 +	pixi
i=1
(87)
m
n
2
Using the expression of clustered sampling variance for the first term (equation (63)), and using
Jensen’s inequality on the third term completes the proof. Jensen’s inequality is an equality if and
nn
only if i=1 rk,ixi =	j=1 rk,jxj.
□
21
Under review as a conference paper at ICLR 2022
C FL Convergence
Our work is based on the one of Wang et al. (2020a). We use the developed theoretical framework
there proposed to prove Theorem 2. The focus of our work (and Theorem 2) is on FedAvg. Yet, the
proof developed in this section, similarly to the one of Wang et al. (2020a), expresses ai in such a
way they can account for a wide-range of regularization method on FedAvg, or optimizers different
from Vanilla SGDone. This proof can easily be extended to account for different amount of local
work from the clients (Wang et al., 2020a).
Before developing the proof of Theorem 2 in Section C.5, we introduce the notation we use in
Section C.1, some useful lemmas in Section C.2 and Theorem 3 generalizing Theorem 2 in Section
C.3.
C.1 Notations
We define by yit,k the local model of client i after k SGD steps initialized on θt, which enables us
to also define the normalized stochastic gradients dit and the normalized gradient hit defined as
1 K-1	1 K-1
dt = — E ai,kgi(ytk) and hi = — E ai,kVLi(yt,k),
aa
ik=0 ik=0
(88)
where ai,k is an arbitrary scalar applied by the client to its kth gradient, ai = [ai,0, ..,ai,K-1]T, and
i = kaik1. In the special case of FedAvg, we have ai = [1, ..., 1] and in the one of FedProx, we
have ai = [(1 一 μ)κ-1,…,1] where μ is the FedProx regularization parameter.
With the formalism of equation (88), we can express a client contribution as θit+1 - θt = -ηlaidit
and rewrite the server aggregation scheme defined in equation (3) as
n
θt+1 — θt = —ngηι X ω∙iaidt,	(89)
i=1
which in expectation over the set of sampled clients S gives
n
Est [θt+1 - θt] = -n XPiaidt
i=1
(90)
(91)
nn
We define the surrogate objective L(x) =	i=1 wiLi(x), where	i=1 wi = 1.
In What follows, the norm used for ai can either be L1, |卜%, or L2, ∣∣∙k2, For other variables,
the norm is always the euclidean one and ∣∣∙∣ is used instead of ∣∣∙∣2. Also, regarding the client
sampling metrics, for ease of writing, we use ωi instead of ωi(St) due to the independence of the
client sampling statistics with respect to the current optimization round.
C.2 Useful Lemmas
Lemma 3 (equation (87) in Wang et al. (2020a)). Under Assumptions 1 to 3, we can prove
2 X Wi E [∣∣VLi(θt) - hi『i ≤ 2n2LR2 X Wi (∣∖αi∣∖2 - ai,-i
i=1	i=1
+ Re2
+ 2(1 - R)
E VL
Rκ2
+ 2(1 - R),
(92)
〜
2
with R = 2nl2 L2 maxi{∣ai∣1 (∣ai∣1 -ai,-1)} with a learning rate such that R < 1.
22
Under review as a conference paper at ICLR 2022
Proof. The proof is in Section C.5 of Wang et al. (2020a).
The bound here provided is slightly tighter in term of numerical constants than the one of Wang
et al. (2020a). Indeed, equation (70) in Wang et al. (2020a) uses the Jensen’s inequality ka + bk2 ≤
2 kak2 + 2 kbk2 which could instead be obtained with:
E 口Xai,sgi(yt,s)∣ j = E ]χai,s (gi(yt,s)- vLi(yt,s))
2
+E
which uses Assumption 1,
giving E hPsk=-01 ai,s
(gi(yt,s) -VLi(yt,s), P
with the same reasoning as for U in equation (111).
s=0 ai,sVLi (yit,sii
k-1
X ai,sVLi(yt,s)
s=0
Lemma 4. Under Assumptions 1 to 3, we can prove
nn
XYiE h∣aiht∣2i ≤ ι-Rσ2XYi (kaik2- (a2,-ι
i=1	1 - R i=1
+ κ2
(94)
where R0 = 2ηl2L2 maxi{kaik21} < 1.
Proof. Due to the definition of hit , we have:
IXa W VLi(yt,k)∣
K-1 1
≤。2 X - ai,k EbIVLi(yt,k )∣2].
i
(95)
(96)
Using Jensen inequality, we have
Eh∣∣VLi(yit,k)∣∣2i ≤2Eh∣∣VLi(yit,k)-VLi(θt)∣∣2i + 2 E h∣∣VLi(θt)∣∣2i	(97)
≤ 2L2 E h∣∣yit,k - θt∣∣2i +2Eh∣∣VLi(θt)∣∣2i ,	(98)
where the second equality comes from using Assumption 2.
Also, Section C.5 of Wang et al. (2020a) proves
K-1
-X ai,k E h∣yt,k - θt∣2i ≤ 1-Rη2σ2 (ka,k2 - (a")) + LI-R E h∣vLi(θt)∣2i .
i k=0
(99)
Plugging equation (98) and then equation (99) in equation (96), we get:
K-1
E[∣aiht∣2] ≤ a X -ai,k [2L2 E ]∣% — 叫[+2E [∣VLi(θt)∣2] ]	(100)
k=0 ai
K-1
=2L2a2 X - a，，& E [∣% — θt∣2] + 2就 E [∣VLi(θt)∣2]	(101)
k=0 ai
≤ 2L2a2 告η2σ2 (∣∣aik2 — (a")) + LI-R E [∣∣ VLi(θt)∣∣[
+ 2ai2 E h∣∣VLi(θt)∣∣2i	(102)
≤ 1-0Rσ2 (kaik2 — (ai,-i)) +2a2 [I-R + ɪl E h∣∣VLi(θt)∣∣2i .	(103)
23
Under review as a conference paper at ICLR 2022
Summing over n gives
nn
XYiE [∣∣aihi∣∣2] ≤ 2L21-Rη2σ2XYia2 (kaik2 - (a2,-1))
i=1	i=1
n
+ 2 I-R + 1 XYia2E [∣∣VLi(θt)∣∣2i.	(104)
i=1
Using Assumption 3 in equation (104) and R0 < 1 completes the proof.
□
C.3 Intermediary Theorem
Theorem 3. The following inequality holds:
T-1
TXE]∣∣vl叫]≤O((1-Ω)η(Pn=ιPiai)T) + o(ηA0σ2m) + O(η2σ2B0)
+ O(η2C 0κ2) + O(ηD0σ2) + O(fjE,κ2),	(105)
where quantities A-E are defined in the following proof from equation (122) to equation (126).
Proof. Clients local loss functions are L-Lipschitz smooth. Therefore, L is also L-Lipschitz smooth
which gives
E 伍(θt+1) - L(θt)] ≤ E [hvL(θt), θt+1 - θti] + LE h∣∣θt+1 - θt∣∣2i,	(106)
×----------------V-----------------} X----------------V------------}
T1	T2
where the expectation is taken over the subset of randomly sampled clients St and the clients gradient
estimator noises ξt. Please note that We use the notation E [∙] instead of E{ξt},St [∙] for ease of
writing.
BOUNDING T1
By conditioning on {ξit} and using equation (91), We get:
n
Ti = E [hVL(θt), ESt [θt+1 - θt]i] = -ηKeff E hvL(θt), XWihii
i=1
(107)
Which, using 2ha, bi = kak2 + kbk2 - ka - bk2 can be reWritten as:
Ti = - 1 ηKeff E
∣∣VL(θt)∣∣ + X Wiht
i=1
n ∣2
-vL(θt) - EWiht
(108)
i=1
2
n
2
24
Under review as a conference paper at ICLR 2022
BOUNDING T2
n
2
T2∣St = η2 E
ωiaiditII	ISt
i=1	I
n
η2 E
£ ωiai (di - hi)+Eωiaiht Il ISt
i=1
η2 E I IIxωiai
i=1
2
(di -ht) I St	+ η E ∣∣E ωiaiht ∣ St
i=1
+ 2η E pɪʧ ωiai
(di - ht), Xωi ai hi iISt .
(109)
(110)
(111)
i=1
{^^^^^^^^
U
Using Assumption 1, we have E hdti - hit, htji = 0. Hence, we get U = 0 and can simplify T2 as:
n
T = n XE [ωf] Oi E [Ildi - htll2] + η2 E
i=1
Using Lemma 1 on the second term, we get:
X ωiaiht∣ I.
(112)
nn
Ti = n X E [ωi] ai E[∣di - ht∣2] + η2 X YiE [∣aiht∣2] + η2(1 - α)E
i=1	i=1
n
piaihit
i=1
(113)
Finally, by bounding the first term using Assumption 1, and noting that piai = wiKeff for the
second term, we get:
n	K-1
Ti =n XE [ωi] X ai,k E [∣gi(yt,k) - VLi(yt,k)∣2]
i=1	k=0
n
+ n X Yi E[∣aiht∣2] + η2(1-α)Kiff E
i=1
nn
≤η2 XE [ω2] kaik2 σi+η2 X γiE [∣aiht∣2] + ni(1 -α) KeffE
i=1	i=1
Xn wihit∣∣∣∣∣i
Going back to equation (106)
Substituting equation (108) and equation (115) back in equation (106), we get:
E 伍(θt+1) - L(θt)i ≤ -2ηKeff ∣VL(θt) ∣i + 2ηKeff E
- 2ηKeff [1 - Ln(I- α)Keff ] E I ∣χ Wiht
(114)
X Wihfl.
(115)
n
VL(θt) - X Wiht
i=1
nn
+ 2η2 X E [ωi] kaik2 σi + 2η2 X γiE [∣aiht∣1,	(116)
i=1	i=1
n
2
}
n
2
25
Under review as a conference paper at ICLR 2022
We consider the learning rate to satisfy 1 - Lη(1 - α)Kef f > 0 such that We can simplify equation
(116) as :
生」≤-1 32+1 ElX Wihi
nn
+ 2ηK^XE [ω2] I∣aik2σ2 + 2ηK^XYiE h∣∣aiht∣∣ i (117)
≤ -1 ∣∣vL(θt)∣∣2 +1XX Wi E h∣∣vLi (θt) - ht∣∣2i
i=1
nn
+ 2ηK— X E[ω2]	kaik2	σ2	+	2η-- X	Yi	E	∣∣aiht∣∣2	, (118)
2 Keff i=1	2 Keff i=1
Where the last inequality uses the definition of the surrogate loss function Land the Jensen’s in-
equality.
Using Lemma 4 and 3, We get:
E [L(θt+1) -L(θt)]
ηKeff	≤
-2 ∣∣vL(θt)∣∣2+1S
Rβ2
2(1 - R)
L1
E ∣vL
n
X Wi Iai I22 - ai2,-1
i=1
Rκ2
+ 2(1 - R)
+ 2 η Keff
+ Ln Kh
n
XE[ωi2 IaiI22 +
n
T-R X Yi (kaik2 -(a2,-i))
i=1
σ2
i=1
R
1 - R +
Yiai2
β2E	∣∣vL(θt)∣∣2
+ κ2
(119)
+
〜
2
If we assume that R ≤ 2产1+1, and considering that β2 ≥ 1, then we have ɪ-R ≤ 1 + 表 ≤ 3,
τ⅛ ≤ 2 , and RR ≤ 2⅛ (1 + 蠹 )β2 = 2. WealSOdefine ω = LnKff 2 (Pn=I Yia2) β2 ≤
1. Substituting these terms in equation (119) gives
E 匕J ≤-1[1-Ω]∣∣VL(θt )∣∣2 + 4 n2 L2σ2 X Wi (kaik2 - a"
3
+ 2nι L max{ai(ai — ai,-i)}κ
+1n Keff
nn
X E [ω2] kaik2 + 2 X γi (kaik2 - (a2,-l))
i=1	i=1
σ2
+ 2 LL Keff
(120)
26
Under review as a conference paper at ICLR 2022
Averaging across all rounds, we get:
1 - Ω T-1π7
-T- Σe
t=0
▽£设）『
≤ 4 L(θ0)-L(θ*)
≤	ηKeff T
n
+3ηl2L2σ2Xwi kaik22 - ai2,-1
+ 6ηl2L2 max{ai(ai -
i
i=1
ai,-1)}κ2
+Lη K
+ 6Lη
ff
1
2XEωi2 kaik22+3Xγi	kaik22-(ai2,-1)
σ2
Keff
i=1
X γiai2	κ2 .
i=1
(121)
We define the following auxiliary variables
nn
A = mκγf XE [ω2] kaik2 = mP pa X [Var [ωi] + p2] kaik2,
(122)
nn
B = X Wi (kaik2 - a2,-l) = XPnpiαi	(kaik2 - a2,-1
i=1	i=1 j=1Pjaj
(123)
C = max{ai (ai - ai,-1)},
(124)
n
n
1n
D = —— max{ai(ai — a1,-1)}	γi
Keff i
i=1
∑n=⅛iC (XVar[“"aXp2) ,
(125)
E =	— max{a2}
Keff i
Xnn
Var[ωi] +αXpi2 .
(126)
We define for A -E the respective quantities A0-E0 such that X0 = i-1ωX. We have:
T-1
T-1	2
T X E阵(叫≤ 4
t0
t=0
UL(ZPf◎))τ+2LηA0σ2工+ 3η2L2σ2BB
(1 - Ω)η(Ti=ιPiai) T	m
+ 6η2L2C 0κ2 + 3LnDσ2 + 6Lf∣Eκ2,
(127)
□
C.4 SYNTHESIS OF LOCAL LEARNING RATE ηl CONDITIONS FOR THEOREM 3
A sufficient bound on the local learning rate ηl for constraints on R for Lemma 3 and equation (119),
and constraint on R0 for Lemma 4 to be satisfied is:
2 [2β2 + 1] ηl2L2 max{kaik21} < 1.	(128)
i1
Constraints on equation (116) can be simplified as
Lηgηl(1 - α)Kef f < 1.	(129)
Constraints on Ω, equation (119), give
"	1
3Lηg ηι 而一
Keff
γiai2	β2 ≤ 1.
(130)
27
Under review as a conference paper at ICLR 2022
C.5 Theorem 2
Proof. With FedAvg, every client performs vanilla SGD. As such, we have ai,k = 1 which gives
ai = K and Ilaik2 = VK. In addition We consider a local learning rate η such that Ω ≤ 1 as such
we can bound A0-E0 as X0 ≤ 2X.
Finally, considering that the variables A to E can be simplified as
n
A = mXVar [ωi] +pi2 ,	(131)
i=1
B= (K-1),	(132)
C=K(K-1),	(133)
Xnn
Var[ωi] +αXpi2	,
i=1
(134)
and
Xnn
Var[ωi] +αXpi2	,
i=1
the convergence bound of Theorem 3 can be reduced to
T X E h WL(θt)『i ≤ O (^IKT) + O (ηgηι X [Var[ωi]+ P2] σ2)
+ O (η2(K - 1)σ2) + O GK(K - 1)κ2)
+O ηgηl XVar[ωi] +αXpi2 [(K -1)σ2 + Kκ2	,
(135)
Which completes the proof.
(136)
□
Ω is proportional to PZi Yi = P21 Var[ωi] + α PZi P22. With full participation, we have Ω = 0.
However, with client sampling, all the terms in equation (136) are proportional with i-1ω . Yet, we
provide a looser bound in equation (136) independent from Ω as the conclusions drawn are identical.
Through Ω, PZi Var ∖ωi∖ and a needs to be minimized. This fact is already visible by inspection
of the quantities E and F .
We note that equation (136) depends on client sampling through σ2, which is an indicator of the
clients SGD quality, and κ2, which depends on the clients data heterogeneity. In the special case
where clients have the same data distribution and perform full gradient descent, based on the argu-
ments discussed in the previous paragraph, we can still provide the following bound showing the
influence of client sampling on the convergence speed, while highlighting the interest of minimizing
the quantities Pin=i Var ∖ωi] and α.
T X1E [WL"≤O ((1 - Ω)1ηgηιKT),
(137)
When setting the server learning rate at 1, ηg = 1 with client full participation, i.e. Var ∖ωi]
Var ∖ in=i ωi] = α = 0 and m = n, we have E = F = 0 and can simplify A to
n
A = nXpi2.
i=i
(138)
28
Under review as a conference paper at ICLR 2022
Therefore, the convergence guarantee we provide is ”点T +η PZi P2σ2 +η2(K-1)σ2+η2K(K-
1)κ2 , which is identical to the one of Wang et al. (2020a) (equation (97) in their work), where
Pin=i pi2 can be replaced by 1/n when clients have identical importance, i.e. pi = 1/n.
In the special case, where We use η = ʌ/m/KT (Wang et al., 2020a), We retrieve their asymptotic
convergence bound √m1KT + pKmTPn=I P2σ2 + Tσ2 + TKκ2.
C.6 Application to Clustered Sampling
We adapt Theorem 2 to clustered sampling. Fraboni et al. (2021) prove the convergence of FL with
clustered sampling by giving identical convergence guarantees to the one of FL with MD sampling.
As a result, their convergence bound does not depend of the clients selection probability in the
different clusters rk,i. The authors’ claim was that reducing the variance of the aggregation weights
provides faster FL convergence, albeit only providing experimental proofs was provided to support
this statement. Corollary 2 here proposed extends the theory of Fraboni et al. (2021) by theoretically
demonstrating the influence of clustered sampling on the convergence rate. For easing the notation,
Corollary 2 is adapted to FedAvg but can easily be extended to account for any local ai using the
proof of Theorem 3 in Section C.3.
Corollary 2. Even with no α such that Cov [ωi(St), ωj (St)] = -αpi pj, the bound of Theorem 2
still holds with B, C, and D defined as in Section C.3 and
1	1nm	n	1	1
A = m m - m2 XX r⅛,i + X Pi , E = m (K -1), and F = mK,	(139)
i=i k=i	i=i
where E and F are identical to the one for MD sampling and A is smaller than the one for Clustered
sampling.
Proof. The covariance property required for Theorem 3 is only used for Lemma 1. In the proof of
Theorem 3, Lemma 1 is only used in equation (113). We can instead use Lemma 2 and keep the
rest of the proof as it is in Section C.3. Therefore, the bound of Theorem 3 remains unchanged for
clustered sampling where E and F use the aggregation weight statistics ofMD sampling instead of
clustered sampling. Statistics for MD sampling can be found in Section A.3 and give
n
Var	ωi(SMD)
i=i
0 and αMD
1
m
while the ones of clustered sampling in Section A.7 give
n	nm	n
X Var[ωj(Scι)] = m - m2 XX r2,l ≤ X Var[ωl(SMD)].
C.7 Proof of Corollary 1
Proof. Combining equation (29) with equation (36) gives
Therefore, we have
nn
∑md-∑u= - ɪ X P2 + ɪ - (n - 1)X P2
m	mm
i=i	i=i
1 =	 m	n (n - m + 1)	pi2		-1
	l	i=i	-j
ΣMD ≤ ΣU	n ⇔Xp i=i	2 ≤ —L n - m	+1.
(140)
(141)
□
(142)
(143)
(144)
29
Under review as a conference paper at ICLR 2022
Combining equation (31), (32), (44), and (46) gives
nn
γMD - γU = Var [ωi(SMD)] + αMD	pi2 -
i=1	i=1
n
Var [ωi (SU)] + αU Xpi2
i=1
1
m
—
n-m
m(n - 1)
n
Xpi2.
i=1
Therefore, we have
n
γMD ≤ γU ⇔	pi2
i=1
1 n-1
≤-------
n-m n
Noting that
1	1 n- 1	-m+ 1
n - m + 1 n - m n	n(n - m)(n - m + 1)
≤ 0,
completes the proof.
(145)
(146)
(147)
(148)
□
30
Under review as a conference paper at ICLR 2022
D Quadratic
Proof. For every client, we consider local loss functions such that:
Li(θ) = 1 kθ - θ*k2,	(149)
where θ* is client's i local minimum. By taking the derivative of the global loss function, equation
(1), with these clients local loss function, gives:
n
θ* = X Piθ*.	(150)
i=1
yit,k is the local model obtained for client i after k SGD and satisfies
yit,k+1 = yit,k - ηl(yit,k - θi*) = (1 - ηl)yit,k + ηlθi*,	(151)
which, by induction, gives
K-1
θit+1 =(1-ηl)Kθt+ X(1-ηl)kηlθi*.	(152)
k=0
We note that PK=-o1(1 - ηι)k = [1 - (1 - ηι)κ]∕ηι. By defining φ = 1 - (1 - ηι)κ, we get:
θit+1 -θt	= (1 -	ηl)K	θt+ 1- (1-ηl)K	θi*	-θt	=	φ(θi*	-	θt).	(153)
Hence, we have
n
Xpi(θit+1 - θt) = φ(θ* - θt).	(154)
i=1
Using Decomposition Theorem 1 leads to
n
E h∣∣θt+1 - θ*∣∣2i =(1 - 2η) E h∣∣θt - θ*∣∣2i + ηg X Yiφ2 E h∣∣θt - θ*∣∣2i
i=1
+ ηg2(1 - α)φ2 E h∣∣θt - θ*∣∣2i .	(155)
□
31
Under review as a conference paper at ICLR 2022
E Additional experiments
E.1 Synthetic Experiment
(a)	(b)
6 4 2
-- *6 I I6--
O .
0.0
8
0.2	0.4	0.6	0.8	1.0	0.0	0.2	0.4	0.6	0.8	1.0
(C)	(d)
6 4 2
-一*glɪ?
Figure 3: Additional plots for Figure 1. Illustration of the Decomposition Theorem 1 for the syn-
thetic scenario described in Section 4.1 for n = 10 clients when sampling m = 5 of them. Panels
(a) to (d) show the distances estimated experimentally when averaging over 1000 simulations for
iid (Panels (a) and (c)), and non-iid settings, (Panels (b) and (d)), and with the associated standard
deviation, (Panels (a) and (b)), and minimum and maximum distances, (Panels (c) and (d)). We
consider ηg = 1, ηl = 0.1, and K = 10.
IO23 -
IO9-
ιo-5 -
IOT9 _
IO22 -
IO8 -
IO-6 -
io-20 -
=*6 J?
O 200	400	600	800 IOOO O 200	400	600	800 IOOO
Figure 4: We consider the synthetic scenario described in Section 4.1 for n = 100 clients when
sampling m = 5 and r = 0.9. We show the distances estimated experimentally when averaging
over 1000 simulations for iid (Panel (a)), and non-iid settings (Panel (b)). We consider ηg = 1,
ηl = 0.2, and K = 1. With K = 1, we show that the divergence does not come from asking too
much work to the local clients. Uniform sampling divergence can be prevented by lowering the local
learning rate ηl (consistently with Theorem 2).
E.2 Shakespeare dataset
The client local learning rate ηl is selected in {0.1, 0.5, 1., 1.5, 2., 2.5} minimizing FedAvg with full
participation, and n = 80 training loss at the end of the learning process.
32
Under review as a conference paper at ICLR 2022
0	100	200	300	400	500	0	100	200	300	400	500
(e) - n = 10	(f) - n = 20
# rounds	# rounds
----MD --------- Uniform ------- Clustered
Figure 5: Convergence speed of the global loss with MD sampling and Uniform sampling when
considering n = 10 ((a) and (e)), n = 20 ((b) and (f)), n = 40 ((c) and (g)), and n = 80 ((d) and
(h)), while sampling m = n/2 of them. In (a-d) , clients have identical importance, i.e. pi = 1/n,
and, in (e-h), their importance is proportional to their amount of data, i.e. pi = ni/M. Global losses
are estimated on 30 different model initialization.
(a) - O/ = 1∕∏
=6σl≡w
(b) - pi = ni∕M
O IOO 200	300	400	500 O IOO 200	300	400	500
# rounds ------- m=4	---- m=8	--- m=40	# rounds
Figure 6:	Difference between the convergence of the global losses resulting from MD and Uniform
sampling when considering n = 80 clients and sampling m ∈ {4, 8, 40} of them while clients
perform K = 50 SGD steps . In (a), clients have identical importance, i.e. pi = 1/n. In (b), clients
importance is proportional to their amount of data, i.e. pi = ni/M. Differences in global losses are
averaged across 15 FL experiments with different model initialization (global losses are provided in
Figure 7).
33
Under review as a conference paper at ICLR 2022
0	200	400	600	800	1000	0	200	400	600	800	1000
# rounds	# rounds
----MD --------- Uniform ------- Clustered
Figure 7:	Convergence speed of the global loss with MD sampling and Uniform sampling when
considering n = 80 clients while sampling m = 4 ((a) and (c)), and m = 8 ((b) and (d)) while
clients perform K = 50 SGD steps. In (a-b) , clients have identical importance, i.e. pi = 1/n, and,
in (d-f), their importance is proportional to their amount of data, i.e. pi = ni/M . Global losses are
estimated on 15 different model initialization.
(b) - pi = ni∣M
(a) - pi = 1∕∏
S-QI≡*sQ
IOOO 1250 1500 1750 2000 2250 2500 ' 1000 1250 1500 1750 2000 2250 2500
# rounds	---- m=8	---- m = 40	# rounds
Figure 8:	Difference between the convergence of the global losses resulting from MD and Uniform
sampling when considering n = 80 clients and sampling m ∈ {8, 40} of them while clients perform
K = 1 SGD step. In (a), clients have identical importance, i.e. pi = 1/n. In (b), clients importance
is proportional to their amount of data, i.e. pi = ni/M. Differences in global losses are averaged
across 15 FL experiments with different model initialization (global losses are provided in Figure
9).
34
Under review as a conference paper at ICLR 2022
Figure 9: Convergence speed of the global loss with MD sampling and Uniform sampling when
considering n = 80 clients while sampling m = 4 ((a) and (d)), m = 8 ((b) and (e)), m = 40 ((c)
and (f)) while clients perform K = 1 SGD steps. In (a-c) , clients have identical importance, i.e.
pi = 1/n, and, in (d-f), their importance is proportional to their amount of data, i.e. pi = ni/M .
Global losses are estimated on 15 different model initialization.
35
Under review as a conference paper at ICLR 2022
E.3 CIFAR 1 0 DATASET
We consider the experimental scenario used to prove the experimental correctness of clustered sam-
pling in (Fraboni et al., 2021) on CIFAR10 (Krizhevsky, 2009). The dataset is partitioned in n = 100
clients using a Dirichlet distribution with parameter α = 0.1 as proposed in Harry Hsu et al. (2019).
10, 30, 30, 20 and 10 clients have respectively 100, 250, 500, 750, and 1000 training samples, and
testing samples amounting to a fifth of their training size.
O 200	400	600	800 IOOO
# rounds
----MD --------- Uniform ------- Clustered
Figure 10: Convergence speed of the global loss with MD sampling and Uniform sampling when
considering n = 100 clients, while sampling m = 10 of them. Clients are partitioned using a
Dirichlet distribution with parameter α = 0.1 (a), α = 0.01 (b), and α = 0.001 (c). Global losses
are estimated on 30 different model initialization.
36