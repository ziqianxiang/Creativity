Under review as a conference paper at ICLR 2022
Revisiting and Advancing Fast Adversarial
Training Through the lens of Bi-Level Opti-
MIZATION
Anonymous authors
Paper under double-blind review
Ab stract
Adversarial training (AT) has become a widely recognized defense mechanism
to improve the robustness of deep neural networks against adversarial attacks. It
originated from solving a min-max optimization problem, where the minimizer
(i.e., defender) seeks a robust model to minimize the worst-case training loss in the
presence of adversarial examples crafted by the maximizer (i.e., attacker). However,
the min-max nature makes AT computationally intensive and thus difficult to scale.
Thus, the problem of Fast-AT arises. Nearly all the recent progress is achieved
based on the following simplification: The iterative attack generation method used
in the maximization step of AT is replaced by the simplest one-shot gradient sign-
based PGD method. Nevertheless, Fast-AT is far from satisfactory, and it lacks
theoretically-grounded design. For example, a Fast-AT method may suffer from
robustness catastrophic overfitting when training with strong adversaries.
In this paper, we foster a technological breakthrough for designing Fast-AT
through the lens of bi-level optimization (BLO) instead of min-max optimization.
First, we theoretically show that the most commonly-used algorithmic specification
of Fast-AT is equivalent to the linearized BLO along the direction given by the
sign of input gradient. Second, with the aid of BLO, we develop a new systematic
and effective fast bi-level AT framework, termed FAST-B AT, whose algorithm is
rigorously derived by leveraging the theory of implicit gradient. In contrast to Fast-
AT, Fast-BAT has the least restriction to placing the tradeoff between computation
efficiency and adversarial robustness. For example, it is capable of defending
sign-based projected gradient descent (PGD) attacks without calling any gradient
sign method and explicit robust regularization during training. Furthermore, we
empirically show that our method outperforms state-of-the-art Fast-AT baselines.
In particular, Fast-BAT can achieve superior model robustness without inducing
robustness catastrophic overfitting and losing standard accuracy.
1 Introduction
Given the fact that machine learning (ML) models can be easily fooled by tiny adversarial perturba-
tions (also known as adversarial attacks) on the input (Goodfellow et al., 2014; Carlini & Wagner,
2017; Papernot et al., 2016), learning robust deep neural networks (DNNs) is now a major focus in
research. Nearly all existing effective defense mechanisms (Madry et al., 2018; Zhang et al., 2019b;
Shafahi et al., 2019; Wong et al., 2020; Zhang et al., 2019a; Athalye et al., 2018a) are built on the ad-
versarial training (AT) recipe, first developed in (Szegedy et al., 2014) and later formalized in (Madry
et al., 2018) using min-max optimization. In contrast to standard model training using empirical
risk minimization, AT (Madry et al., 2018) calls min-max optimization. That is, a minimizer (i.e.
defender) seeks to update model parameters against a maximizer (i.e. attacker) that aims to worsen
the training loss by perturbing each training example.
The AT-type defenses have been widely adopted in various application domains including image
classification (Goodfellow et al., 2014; Madry et al., 2018; Kurakin et al., 2017), object detection
(Zhang & Wang, 2019), natural language processing (Miyato et al., 2016; Zhu et al., 2019), and
healthcare (Finlayson et al., 2019; Mahmood et al., 2019). Despite their effectiveness, the min-max
optimization nature makes them difficult to scale. This is because multiple maximization steps
1
Under review as a conference paper at ICLR 2022
(required by an iterative attack generator) are needed at every model training step in AT. The resulting
prohibitive computation cost prevents AT from a feasible solution to enhance adversarial robustness
when computing resource is limited. For example, Xie et al. (2019) used 128 GPUs to make AT
practical on ImageNet. Thereby, how to speed up AT without losing accuracy and robustness is now
a grand challenge for adversarial defense.
Very recently, some work attempted to develop computationally-efficient alternatives of AT, which we
call ‘fast’ versions of AT (Shafahi et al., 2019; Zhang et al., 2019a; Wong et al., 2020; Andriushchenko
& Flammarion, 2020). To the best of our knowledge, Fast-AT (Wong et al., 2020) and Fast-AT
with gradient alignment (GA) regularization, termed Fast-AT-GA (Andriushchenko & Flammarion,
2020), are the two state-of-the-art (SOTA) ‘fast’ versions of AT, since they achieve a significant
reduction in computation complexity and preserve accuracy and robustness to some extent. To
be specific, Fast-AT (Wong et al., 2020) replaces an iterative attack generator used in AT with
a heuristics-based single-step attack generation method. Thus, it merely takes computation cost
comparable to standard model training. However, FAST-AT suffers two main issues: (i) lack of
stability, i.e., large variance in performance (Li et al., 2020), and (ii) robustness catastrophic overfitting,
i.e., a large drop of robustness when training with strong adversaries (Andriushchenko & Flammarion,
2020). To alleviate these problems, Andriushchenko & Flammarion (2020) proposed Fast-AT-GA
by penalizing Fast-AT using an explicit robust regularization given by GA. However, we will show
that FAST-AT-GA encounters a new problem (iii): FAST-AT-GA hampers standard accuracy, making
a poor accuracy-robustness tradeoff at large attack budget ( = 16/255), i.e. the improvement on RA
is at cost of a sharp drop on SA. Given the limitations (i)-(iii), we ask:
How to design a theoretically-grounded ‘fast’ version of AT with improved stability, mitigated
catastrophic overfitting, and enhanced accuracy-robustness tradeoff ?
To address above question, paper we revisit and advance AT through the lens of bi-level optimization
(BLO) (Dempe, 2002), where we cast the attack generation problem as a lower-level optimization
problem with constraints and the defense as an upper-level optimization problem in the objective.
To the best of our knowledge, this is the first work to make a solid connection between adversarial
defense and BLO. Technically, we show that FAST-AT can be interpreted as BLO with linearized
lower-level problems. Delving into linearization of BLO, we propose a novel, theoretically-grounded
‘fast' AT framework, fast bi-level AT (FAST-BAT). Practically, Table 1 highlights some achieved
improvements over FAST-AT and FAST-AT-GA: When a stronger train-time attack (i.e., = 16/255
vs. 8/255) is adopted, FAST-AT suffers a large degradation of robust accuracy (RA) and standard
accuracy (SA), together with higher variances than proposed Fast-BAT. Although Fast-AT-GA
outperforms FAST-AT, it still incurs a significant SA loss (over 21%) at = 16/255. By contrast,
FAST-BAT yields a more graceful SA-RA tradeoff: 9% improvement of SA without loss of RA.
Different from Fast-AT-GA, Fast-BAT achieves above improvements in stability, RA and SA
without resorting to any extra robust regularization and thus takes less computation cost.
Table 1: Performance overview of proposed FAST-BAT vs. the baselines FAST-AT (Wong et al., 2020) and
Fast-AT-GA (Andriushchenko & Flammarion, 2020) on (CIFAR-10, PreActResNet-18). All methods are
robustly trained under two perturbation budgets = 8/255 and 16/255 over 20 epochs. We use the early-stop
policy (Rice et al., 2020) to report the model of best robustness for each method. The evaluation metrics include
robust accuracy (RA) against PGD-50-10 attacks (50-step PGD attack with 10 restarts) (Madry et al., 2018) at
= 8/255 and 16/255 (test-time is same as the train-time), RA against AutoAttack (AA) (Croce & Hein,
2020) at = 8/255 and 16/255, and computation time (per epoch). The result a±b represents mean a and
standard deviation b over 10 random trials. All experiments are run on a single Tesla-P100 GPU.
Method	RA-PGD (%) (W = 8/255)	RA-PGD (%) (W = 16/255)	RA-AA (%) (W = 8/255)	RA-AA (%) (w = 16/255)	SA(%) (w = 8/255)	SA(%) (w = 16/255)	Time (s)
Fast-AT	45.47±0.39	21.79±0.93	41.97±0.15	12.57±0.33	81.72±0.36	46.02±2.79	42
Fast-AT-GA	47.43±0.42	26.22±0.19	43.52±0.32	18.03±0.39	79.84±0.49	58.57±1.19	150
Fast-BAT	48.74±0.11	26.15±0.12	44.89±0.12	18.21±0.15	79.43±0.08	67.79±0.08	135
Contributions. We summarize our contributions below.
①	We propose a new formulation of adversarially robust training through the lens of BLO, yielding a
novel and theoretically-grounded interpretation of Fast-AT.
②	We propose a new systematic and effective fast BLO-oriented AT framework, termed FAST-BAT,
with rigorously-established theory and algorithm.
2
Under review as a conference paper at ICLR 2022
③	We conduct extensive experiments on FAST-BAT, showing its improved stability, mitigated
catastrophic overfitting, and enhanced accuracy-robustness tradeoff; see illustrations in Table 1.
2	Related work
Adversarial attack. Adversarial attacks are techniques to generate malicious perturbations that are
imperceptible to humans but can mislead the machine learning (ML) models (Goodfellow et al., 2014;
Carlini & Wagner, 2017; Croce & Hein, 2020; Xu et al., 2019; Athalye et al., 2018b). A popular
threat model that an adversary used is known as `p-norm ball constrained attack (p ∈ {0, 1, 2, ∞}).
This is also the focus of this paper. The adversarial attack has become a major approach to evaluate
the robustness of deep neural networks (DNNs) and thus, help build safe artificial intelligence in
many high stakes applications such as autonomous driving (Deng et al., 2020; Kumar et al., 2020),
surveillance (Thys et al., 2019; Xu et al., 2020), and healthcare (Finlayson et al., 2019).
Adversarial defense and robust training at scale. Our work falls into the category of robust
training, which was mostly built upon min-max optimization. For example, Madry et al. (2018)
established the framework of AT for the first time, which has been recognized as one of the most
powerful defenses (Athalye et al., 2018a). Extended from AT, TRADES (Zhang et al., 2019b) sought
the optimal balance between robustness and generalization ability. Further, AT-type defense has
been generalized to the semi-/self-supervised settings (Carmon et al., 2019; Chen et al., 2020) and
integrated 1 with certified defense techniques such as randomized smoothing (Salman et al., 2019).
Despite the effectiveness of AT and its variants, they need to take high computation costs. How to
speed up AT without losing performance remains an open question. Some recent works attempted
to impose algorithmic simplifications to AT, leading to fast but approximate AT algorithms, such
as ‘free’ AT (Shafahi et al., 2019), you only propagate once (YOPO) (Zhang et al., 2019a), Fast-
AT (Wong et al., 2020), and Fast-AT regularized by gradient alignment (termed Fast-AT-GA)
(Andriushchenko & Flammarion, 2020). In particular, Fast-AT and Fast-AT-GA are the baselines
most relevant to ours since they were designed with the least computation complexity. However,
their defense performance is far from satisfactory. For example, Fast-AT has poor training stability
(Li et al., 2020) and suffers catastrophic overfitting when facing strong attacks (Andriushchenko &
Flammarion, 2020). In contrast to Fast-AT, Fast-AT-GA yields improved robustness but has a
poor accuracy-robustness tradeoff (e.g., Table 1). In this paper, we aim to advance the algorithm
foundation of ‘fast robust training’ through the lens of BLO (bi-level optimization). We will show that
the proposed Fast-BAT can lead to stable robust learning without suffering catastrophic overfitting
and graceful tradeoff between accuracy and robustness.
Bi-level optimization (BLO). BLO is a unified hierarchical learning framework, where the objec-
tive and variables of an upper-level problem depend on the optimizer of certain lower-level problems.
The BLO problem in its most generic form is a class of very challenging problems, and thus, the
design of algorithms and theory for BLO focuses on special cases (Vicente et al., 1994; White
& Anandalingam, 1993; Gould et al., 2016; Ghadimi & Wang, 2018; Ji et al., 2020; Hong et al.,
2020). In practice, some successful applications of BLO to ML have been witnessed in meta-learning
(Rajeswaran et al., 2019), data poisoning attack design (Huang et al., 2020), and reinforcement
learning (Chen et al., 2019). However, as will be evident later, the existing BLO approach is not
directly applied to adversarial defense due to the presence of the constrained nonconvex lower-level
problem (for attack generation). To the best of our knowledge, our work makes a rigorous connection
between adversarial defense and BLO for the first time.
3	A B i-Level Optimization View on Fast-AT
Preliminaries on Fast-AT. FAST-AT is designed for solving the adversarial training problem
(Madry et al., 2018) given below
minimize E(x y)∈D maximize `tr (θ, x + δ, y) ,	(1)
θ	δ∈C
where θ ∈ Rn denotes model parameters, D is the training set consisting of labeled data pairs
with feature x and label y, δ ∈ Rd represents adversarial perturbations subject to the perturbation
3
Under review as a conference paper at ICLR 2022
constraint C, e.g., C = {δ ∣∣∣δ∣∣∞ ≤ e, δ ∈ [0,1]} for e-toleration '∞-norm constrained attack
(normalized to [0,1]), (X + δ) is then called adversarial example, and 'tr(∙) represents a training loss.
The standard solver to problem (1) is known as AT (Madry et al., 2018). However, it has to call an
iterative optimization method (e.g., K-step PGD attack) to solve the inner maximization problem of
(1). As a result, AT is computationally intensive. To improve its scalability, Fast-AT that only takes
the single-step PGD attack for inner maximization was proposed and successfully implemented in
(Wong et al., 2020). The algorithm backbone of Fast-AT is summarized below.
Fast-AT algorithm
Let θt be the model parameters at iteration t. The (t + 1)th iteration is given by
①(Inner maXimiZation by I-Step PGD): δ — PC (δo + α ∙ sign (Vδ'tr(θt, X + δ°, y))),
where PC(a) denotes the projection operation that projects the point a onto C, i.e., PC (Z)=
argmi□δ∈c ∣∣δ 一 z∣∣2, δo is a random uniform initialization within [0,1], a > 0 is a proper
learning rate (e.g., 1.25e), and sign(∙) is the element-wise sign operation.
②(Outer minimizationfor model training): This can be conducted by any standard optimizer,
e.g., SGD. That is, θt+ι — θt 一 βVθ'tr(θt, X + δ, y), where β > 0 is a proper learning rate
(e.g., cyclic learning rate), and δ is provided from the inner maximization step.
Roughly speaking, FAST-AT is a simplification of AT using 1-step PGD for inner maximization.
However, as shown in (Wong et al., 2020), the successful implementation of FAST-AT is different
from the 1-step PGD-based AT (Madry et al., 2018) due to the former’s sophisticated hyperparameter
choices in α, δ0, and β. Despite the efficacy of FAST-AT in some cases, Andriushchenko &
Flammarion (2020) demonstrated that it could lead to the issue of robustness catastrophic overfitting
when facing strong adversaries during training. In the literature, there was no grounded theory to
justify the pros and cons of Fast-AT. We will show that BLO provides a promising solution.
BLO: Towards a unified formulation of robust training. BLO (bi-level optimization) is a unified
hierarchical learning framework, involving two levels (i.e., upper and lower levels) of optimization
tasks, where one task is nested inside the other (i.e., the objective and variables of an upper-level
problem depend on the optimizer of the lower-level problem). The hierarchical learning framework
provided by BLO can be used to precisely depict a robust training paradigm. Specifically, we can
cast robustification as an upper-level problem whose optimization relies on a lower-level problem
defined for attack generation. Thus, the BLO formulation of (1) is given by
minimize	E(χ,y)∈D['tr(θ, X + δ* (θ; x, y), y)]
subject to	δ*(θ; x,y) = arg min 'atk (θ, δ; x,y),
(2)
δ∈C
where `atk denotes an attack objective. For notation simplicity, we will use data-omitted eXpreSSionS
of 'tr, 'atk, and δ*. The formulation (2) has two key differences from (1):
一 First, the lower-level attack objective 'atk is customizable, not necessarily to be same as the opposite
of the training objective, 一'5.As will be evident later, the flexibility of attack configuration in (2)
enables us to interpret Fast-AT through the lens of BLO.
一 Second, BLO calls an optimization routine different from min-max optimization used by (1). Even
if we set 'atk = -'tr, problem (2) does not reduce to (1) due to the presence of lower-level constraint
δ ∈ C (see rigorous analysis in Appendix B). Specifically, solving the upper-level problem of (2) by
gradient descent yields
d^(θdθ'θ)) = ψθ'tr(θ, δXθ)) +	Vδ'tr(θ, δ*(θ)),
v------/
(3)
、	{	‘
IG
where the superscript > denotes the transpose operation, and Ve'tr(θ, δ*(θ)) denotes the partial
derivative with respect to (w.r.t.) the first input argument θ. In (3), dδdθ) ∈ Rn×d is referred to
as implicit gradient (IG) because it is defined through an implicit constrained optimization problem
minδ∈C 'atk. The dependence on IG is a ‘fingerprint’ of BLO (1) in contrast to AT or FAST-AT.
BLO-enabled interpretation of Fast-AT. In what follows, we demonstrate how FAST-AT relates
to BLO. Our main finding is summarized below.
4
Under review as a conference paper at ICLR 2022
Bi-level interpretation of FAST-AT
FAST-AT can be interpreted as the lower-level linearized BLO with Z = δ0 and λ = 1∕α:
minimize E(χ,y)∈D['tr(θ, δ*(θ))]
subject to δ*(θ) = arg min [(δ - z)>sign(Vδ=z'atk (θ, δ)) + (λ∕2)∣∣δ - z∣∣2],	(4)
δ∈C
where Z is the linearization point, Vδ=z'atk denotes the partial derivative of 'atk (w.r.t. δ)
evaluated at z, Sign(Vδ=z'atk(θ, δ)) is the linearization direction, and λ > 0 is a regulariza-
tion parameter associated with the quadratic residual of linearization.
Our justification on the above claim is elaborated on below.
一 First, the simplified lower-level problem of (4) leads to the closed-form solution
δ*(θ) = arg min (λ∕2)∣∣δ - Z + (1∕λ)sign(Vδ=z'atk(θ, δ))k2
δ∈C
=PC (Z - (1∕λ)sign(Vδ=z'atk(θ, δ))) ,	(5)
which is given by the 1-step PGD attack with initialization Z and learning rate (1∕λ). In the lin-
earization used in (4), a quadratic regularization term (with regularization parameter λ) is introduced
to ensure the strong convexity of the inner-level attack objective within the constraint set δ ∈ C .
Assisted by that, the lower-level solution is unique and its closed form is given by (5). Note that
imposing such a strongly convex regularizer is also commonly used to stabilize the convergence
of min-max optimization and BLO (Qian et al., 2019; Hong et al., 2020). If we set Z = δ0 and
λ = 1∕α, then (5) precisely depicts the inner maximization step used in FAST-AT .
-Second, by substituting (5) into the upper-level problem of (4), we can then follow (3) to update
the model parameters θ. However, this calls the computation of IG d§ t(θ . If we regard PC is
differentiable, then based on the closed-form of δ* (θ) in (5), IG becomes
dδ*(θ)>
-dθ-
0,
(6)
where we use two facts: (1) The linearization point Z is independent of θ, i.e. Z = δ0 ; And (2)
dsign(∙)
dθ
0 holds almost everywhere. Please refer to Appendix C for a rigorous proof of (6) using
KKT conditions. Clearly, the use of gradient sign method simplifies the IG computation. Substituting
(6) into (3), the upper-level optimization of (4) yields θ J θ - βVθ'tr(θ, δ*(θ)) (with learning rate
β), which is precisely same as the outer minimization step used in FAST-AT.
The aforementioned analysis shows that the linearized BLO (4) is equivalent to Fast-AT by setting
the linearization point Z and the regularization parameter λ as Z = δ0 and λ = 1∕α.
4 Fast-BAT: Advancing Fast-AT by BLO
Fast-BAT and rationale. The key take-away from (4) is that the conventional FAST-AT adopts
the sign of input gradient to linearize the lower-level attack objective. However, a more natural and
wiser choice is to use the first-order Taylor expansion for linearization. By doing so, problem (4) can
be modified to the form of Fast-BAT
minimize	E(χ,y)∈D['tr(θ, δ*(θ))]
subject to δ*(θ) = arg min [(δ - z)> Vδ=z'atk(θ, δ) + (λ∕2)∣∣δ - z∣∣2],
δ∈C
where similar to (5), the lower-level problem can be solved analytically as
δ*(θ) = PC(Z - (l∕λ)Vδ = z'atk(θ, δ)).
(7)
(8)
In contrast to (6), the IG associated with (7) is no longer vacant since the gradient sign operation
is not present in (8). To compute IG, the auto-differentiation (which calls the chain rule) can be
applied to the closed-form of δ*(θ). However, this will not give us an accurate and generalizable IG
solution since the projection operation PC is not smooth and thus, the use of chain rule does not yield
a rigorous derivation. Therefore, the IG challenge arises, which will be addressed in what follows.
5
Under review as a conference paper at ICLR 2022
IG theory for Fast-BAT. The problem of FAST-BAT (7) falls into a class of very challenging
BLO problems, which require constrained lower-level optimization. The unconstrained case is easier
to handle since one can apply the implicit function theory to the stationary condition of the lower-level
problem to obtain IG (Hong et al., 2020). Yet, in the case of constrained problems, a stationary point
could violate the constraints, and thus the stationary condition becomes non-applicable.
In problem (7), We are dealing with a special class of lower-level constraints - linear constraints:
C = {kδk∞ ≤ e, δ ∈ [-x,1- x]}θ Bδ ≤ b, with B := [II], b := [ minU 11-，.	(9)
-	- max{-	, -x}
By exploiting above linearly constrained problem structure, we show that the IG challenge associated
with (7) can be addressed via KaruSh-Kuhn-TuCker (KKT) conditions. We summarize our main
theoretical result below and refer readers to Appendix A for detailed derivation.
Theorem 1 With a Hessian-free assumption, i.e., Vδδ'atk = 0,the IG (implicit gradient) of (7) is
"3 * = -(l∕λ)Vθδ 'atk(θ, δ* )Hc , with HC := [1pι<δ*<qι e1	… 1P1<δ*<qd ed] ,	(10)
dθ	d
where δ* is given by (8), and Vθδ'(θ, δ*) ∈ Rn×d denotes the second-order partial derivative
evaluated at θ and δ*(θ), respectively. In HC ∈ Rd×d, 1pi<δ*<qi ∈ {0,1} denotes the indicator
function over the constraint of {δi | Pi < δ* < q%}, which returns 1 if the COnStraint is satisfied,
δ* denotes the ith entry of δ*(θ), Pi = max{-e, —xi} and q% = min{e, 1 一 xi} characterize the
boundary of the linear constraint (9) for the variable δi, and ei ∈ Rd denotes the basis vector with
the ith entry being 1 and others being 0s.
In Theorem 1, the rationale behind the Hessian-free assumption is that ReLU-based neural networks
commonly lead to a piece-wise linear decision boundary w.r.t. the inputs (Moosavi-Dezfooli et al.,
2019; Alfarra et al., 2020), and thus, its second-order derivative (Hessian) Vδδ `atk is close to zero.
In Appendix E, we will empirically show that the Hessian-free assumption is reasonable for both
ReLU and non-ReLU neural networks.
Fast-BAT algorithm and implementation. Similar to FAST-AT or AT, the FAST-BAT algorithm
follows the principle of alternating optimization. Specifically, it consists of the IG-based upper-level
gradient descent (3), interlaced with the lower-level optimal attack (8). We summarize the Fast-BAT
algorithm below.
________________________________ FAST-BAT algorithm ____________________________________
The (t + 1)th upper-level iteration of FAST-BAT is given below
①(Lower-level solution): Obtain δ*(θj from (8);
②(Upper-level model training): Integrating the IG (10) into (3), call SGD to update
θt+1 = θt - αiVθ 'tr(θt, δ*(θt)) - α2(-l∕λ)Vθδ 'atk(θt, δ*(θt))Hc Vδ 'tr(θt, δ*(θt)), (11)
where aι, α2 > 0 are learning rates associated with the standard model gradient and the
IG-augmented descent direction, respectively.
It is clear from (11) that to train a robust model, Fast-BAT can be dissected into the regular Fast-AT
update (i.e., α1-associated term) and the additional update that involves IG, (i.e., α2-associated term).
To successfully implement Fast-BAT, we highlight some key hyper-parameter setups different from
FAST-AT (Wong et al., 2020) and FAST-AT-GA (Andriushchenko & Flammarion, 2020).
Remark 1 Choice of learning rate for IG-involved descent term: In (11), the choice of α2 could
affect the trade-off between accuracy and robustness (see empirical justification in Appendix E).
Clearly, if α2 = 0, then the upper-level model parameter updating step reduces to the standard
FAST-AT. In Sec. 5.1, we will show that the α2-associated term plays a positive role in alleviating
catastrophic robust overfitting. Meanwhile, λ in (7) could also affect the accuracy-robustness tradeoff.
For example, if λ → ∞, then δ = 0 (no robustness gain). Spurred by above, we choose the following
combination of α2 and λ, α2∕λ = 0.1αι, which works well in practice; see TableA1.
Remark 2 Choice of linearization point z: To specify (7), we investigate two classes of linearization
schemes. The first class is random constant linearization, which includes: “uniformly random
6
Under review as a conference paper at ICLR 2022
linearization”, i.e., Z = δo as FAST-AT, and “random corner linearization" under the e-radius '∞-
ball, i.e., z ∈ {-, }d. The second class is 1-step perturbation warm-up-based linearization, which
includes the other two specifications: “ 1 -step PGD" Z = PC (δo + α ∙ sign (Vδ'tr(θt, δo))), and
“ 1 -step PGD w/o sign" Z = PC (δo + αVδ'tr(θt, δ°)). We consider the aforementioned linearization
schemes since FAST-BAT combined with these linearizations takes computation cost comparable
to the baselines FAST-AT and FAST-AT-GA. Our experiments show that FAST-BAT using “1-step
PGD w/o sign" leads to the best defense performance; see justification in Table A3.
5	Experiments
5.1	Experiment Setup
Datasets and model architectures. We will evaluate the effectiveness of our proposal under
CIFAR-10 (Krizhevsky & Hinton, 2009) and ImageNet (Deng et al., 2009). Unless specified
otherwise, we will train DNN models PreActResNet (PARN)-18 (He et al., 2016b) for CIFAR-10,
and ResNet (RN)-50 (He et al., 2016a) for ImageNet. As a part of ablation study, we also train larger
models PARN-50 and WideResNet (WRN)-16-8 (Zagoruyko & Komodakis, 2016) on CIFAR-10.
Baselines. We consider three methods as our baselines: FAST-AT (Wong et al., 2020), FAST-AT-
GA (Andriushchenko & Flammarion, 2020), and PGD-2-AT (Madry et al., 2018), i.e., the 2-step
PGD attack-based AT. The primal criterion of baseline selection is computation complexity. The
training time of all methods including ours falls between the time of Fast-AT and that of Fast-AT-
GA. We remark that when evaluating on ImageNet, we only compare ours with Fast-AT since as
shown in Table 6 of (Andriushchenko & Flammarion, 2020), the other baseline methods did not show
improvement over Fast-AT at the attack budget e = 2/255.
Training details. We choose the training perturbation strength e ∈ {2, 4, . . . , 16}/255 for CIFAR-
10 and e = 2/255 for ImageNet following (Wong et al., 2020; Andriushchenko & Flammarion, 2020).
Throughout the experiments, we utilize an SGD optimizer with a momentum of 0.9 and weight
decay of 5 × 10-4. For CIFAR-10, we train each model for 20 epochs in total, where we use cyclic
scheduler to adjust the learning rate. The learning rate linearly ascends from 0 to 0.2 within the first
10 epochs and then reduces to 0 within the last 10 epochs. Our batch size is set to 128 for all settings.
In the implementation of FAST-BAT, we adjust the hyperparameter λ from 255/5000 to 255/2000
based on the specification of train-time e. For ImageNet, we strictly follows the setup given by Wong
et al. (2020). In FAST-BAT, we set λ = 255/3000. For each method, we use the early stopping
method to pick the model with best robust accuracy, following (Rice et al., 2020). All the CIFAR-10
experiments are conducted on a single Tesla P-100 GPU and all ImageNet experiments run on a
single machine with two Tesla P-100s. All the baselines are implemented using the recommended
training configurations in their official GitHub repos. We refer readers to Appendix D for more details
on training setup.
Evaluation details. For adversarial evaluation, We report robust test accuracy (RA) of a learned
model against PGD attacks (Madry et al., 2018) (RA-PGD). Unless otherwise specified, we set
the test-time perturbation strength (e) same as the train-time value, and take 50-step PGD With 10
restarts for both CIFAR-10 and ImageNet evaluation. We also measure robust accuracy against
AutoAttacks (Croce & Hein, 2020), termed RA-AA. Further, we measure the standard accuracy (SA)
against natural examples. Results are averaged over 5 independent trials with different random seeds.
5.2 Results
Overall performance of Fast-BAT. In Table 2 and 3, we
compare the performance of our proposed Fast-BAT with base-
lines on CIFAR-10 and ImageNet, respectively.
Table 3: SA and RA on ImageNet.
Method I SA (%) ∣ RA-PGD (%)
Fast-AT	60.90	43.43
Fast-BAT	60.18	44.64
First, we find that FAST-BAT consistently outperforms the other baselines across datasets and attack
types. For example, Fast-BAT at least improves 1.35% RA-PGD and 1.41% RA-AA with test-time
e = 8/255 in the training setup (CIFAR-10, e = 8/255). On ImageNet, FAST-BAT outperforms
FAST-AT by 1.23% when facing attacks with e = 2/255.
7
Under review as a conference paper at ICLR 2022
Table 2: SA, RA-PGD and RA-AA of different robust training methods in the setup (CIFAR-10, PARN-18
training with = 8/255) and (CIFAR-10, PARN-18 training with = 16/255), respectively. All the results are
averaged over 5 independent trials with different random seeds.
CIFAR-10, PARN-18 trained with = 8/255
Method	SA (%)	e = 4	RA-PGD (%) € = 8 I € = 12 I		€=16	€ = 2	RA-AA (%) I € = 8 I	€=16
FAST-AT	81.89±0.31	65.92 ±0.11	45.44 ±0.38	23.69 ±0.34	9.56 ±0.26	72.54 ±0.20	41.95 ±0.13	7.91 ±0.06
FAST-AT-GA	79.78±0.47	65.74 ±0.19	47.32 ±0.35	28.67 ±0.26	11.57±0.32	71.60 ±0.39	43.45 ±0.27	9.48 ±0.15
PGD-2-AT	83.26±0.28	65.59 ±0.34	44.71 ±0.42	23.67 ±0.35	9.42 ±0.33	73∙28±0.15	41.73 ±0.20	7.54±0.25
FAST-BAT	79.47 ±0.14	66.26 ±0.08	48.67 ±0.18	29.87 ±0.46	14.00 ±0.21	72.07 ±0.22	44.86 ±0.34	11.51 ±0.20
CIFAR-10, PARN-18 trained with = 16/255
FAST-AT	46.13±2.25	42.74 ±0.91	37.17 ±0.74	27.99 ±0.72	21.92 ±0.71	36.31 ±2.20	31.66 ±0.27	12.48 ±0.29
FAST-AT-GA	58.53 ±1.20	51.71 ±0.99	43.86 ±0.67	35.46 ±0.36	26.29 ±0.14	53.61 ±1.10	38.69 ±0.56	18.11 ±0.36
PGD-2-AT	69.40 ±0.30	59.25 ±0.16	48.79 ±0.31	32.12 ±5.63	24.30 ±0.46	61.90 ±0.28	41.59 ±0.22	15.40 ±0.29
Fast-BAT	67.81 ±0.18	59.35 ±0.13	49.05 ±0.12	37.71 ±0.36	26.07 ±0.28	62.16 ±0.14	43.64 ±0.26	18.18 ±0.34
Second, FAST-BAT leads to a better SA-RA trade-off compared with the other baselines. For
example, in the setup of (CIFAR-10, PARN-18 trained with = 8/255), we observe that FAST-BAT
outperforms Fast-AT-GA in RA, without losing SA.And in the setup of (CIFAR-10, PARN-18
trained with = 16/255), FAST-BAT significantly outperforms FAST-AT-GA, with 9.28% SA
improvement and comparable or even better RA. Compared with PGD-2-AT, Fast-BAT is much
more resilient against strong adversaries, e.g., = 16.
Third, the robustness advantage of our method becomes more notable when the test-time attack budget
becomes smaller than the train-time budget. For examples, the RA-AA improvement of Fast-BAT
over FAST-AT-GA grows from 0.07% (evaluated at = 16/255) to 4.95% (evaluated at = 8/255),
and 8.55% (evaluated at = 2/255) in the case of (CIFAR-10, trained with = 16/255).
Performance under different model architectures. Besides PARN-18 reported above, Table 4
presents experiment results on both deeper (PARN-50) and wider (WRN-18-6) models. As we can
see, Fast-BAT consistently yields RA improvement over the other baselines. We also note that
PGD-2-AT could be a competitive baseline in terms of SA, e.g., the case of (PARN-50, = 8/255).
In contrast to Fast-AT and Fast-AT-GA, Fast-BAT is the only approach that yields an evident RA
improvement over PGD-2-AT.
Table 4: Performance of different robust training methods under different model types. All the models are both
trained and evaluated with the same perturbation strength .
Model	Method	SA(%) (€ = 8/255)	RA-PGD(%) (€ = 8/255)	SA(%) (€ = 16/255)	RA-PGD(%) (€ = 16/255)
PARN-50	Fast-AT	73.15±6.10	41.03±2.99	43.86±4.31	22.08±0.27
	Fast-AT-GA	77.40±0.81	46.16±0.98	42.28±6.69	22.87±1.25
	PGD-2-AT	83.53±0.17	46.17±0.59	68.88±0.39	22.37±0.41
	Fast-BAT	78.91±0.68	49.18±0.35	69.01±0.19	24.55±0.06
WRN-16-8	Fast-AT	84.39±0.46	45.80±0.57	49.39±2.17	21.99±0.41
	Fast-AT-GA	81.51±0.38	48.29±0.20	45.95±13.65	23.10±3.90
	PGD-2-AT	85.52±0.14	45.47±0.14	72.11±0.33	23.61±0.16
	Fast-BAT	81.66±0.54	49.93±0.36	68.12±0.47	25.63±0.44
Mitigation of robustness catas-
trophic overfitting. As shown in
(Andriushchenko & Flammarion,
2020), Fast-AT suffers robust-
ness catastrophic overfitting when
the train-time and test-time attack
strength grows. Following (An-
driushchenko & Flammarion, 2020),
Figure 1 presents two RA-PGD tra-
jectories, i.e., training w/o early stop-
ping and training w/ early stopping,
versus the train- and test-time . As
(a) Without early stopping
Figure 1: RA-PGD of different robust training methods for (CIFAR-
10, PARN-18) with the same training and evaluation attack strengths.
(b) With early stopping
we can see, FAST-AT encounters a sharp RA drop when > 8 when early stopping is not used,
consistent with (Andriushchenko & Flammarion, 2020). Assisted by early stopping, the overfitting
8
Under review as a conference paper at ICLR 2022
of RA can be alleviated to some extent for Fast-AT, but its performance still remains the worst.
Moreover, different from (Andriushchenko & Flammarion, 2020), we find that PGD-2-AT yields
resilient performance against robustness catastrophic overfitting. Our implementation gives a more
positive baseline than the implementation of PGD-2-AT in (Andriushchenko & Flammarion, 2020),
since the latter did not use random initialization to generate train-time attacks. Furthermore, Figure 1
shows that our proposal mitigates the issue of robustness catastrophic overfitting and yields improved
RA over the other baselines. We highlight that such a achievement made by Fast-BAT is ‘free’ of
any robustness stability regularization, like gradient alignment used in Fast-AT-GA.
Gradient alignment for ‘free’. As shown by Andriushchenko &
Flammarion (2020), gradient alignment (GA) is a key performance
indicator to measure the appearance of robustness catastrophic over-
fitting. The insight from Figure 1 suggested that Fast-BAT can mit-
igate overfitting without using explicit GA regularization. Spurred by
above, Figure 2 presents the GA score versus the training epoch num-
ber, where GA characterizes the sensitivity of loss landscape against
random input perturbations; see derivations in (Andriushchenko &
Flammarion, 2020). The higher GA is, the more stable the robust
training is. Figure 2 shows that Fast-BAT automatically enforces
GA and it outperforms Fast-AT and PGD-2-AT. Fast-BAT remains very close to Fast-AT-GA,
which maximizes GA using an extra train-time regularization The above empirical results imply
that gradient alignment may be just a necessary condition for avoiding catastrophic overfitting, but
not a sufficient one. A possible justification can be made from the perspective of the flatness of the
loss landscape. A higher gradient alignment implies a flatter loss landscape with respect to input
perturbations. However, the direct penalization on the norm of the input gradient may not achieve the
state-of-the-art model robustness.
Sanity check for obfuscated gradients
As pointed out by Athalye et al. (2018a),
model robustness could be overestimated
due to obfuscated gradients. The model
with obfuscated gradients could have ‘ob-
fuscated’ stronger resilience to white-box
attacks than transfer (black-box) attacks. To
justify the validity of Fast-BAT, Table 2
summarizes the comparison between our
Table 5: RA of robust PARN-18 trained by the four differ-
ent methods against adaptive attacks (‘RA-PGD’ column)
and transfer attacks (‘Transfer Attack’ columns). Naturally
trained PARN-18, PARN-50, and WRN-16-8 are used as
surrogate models for PGD-20 attack with e = 8/255.
Method	RA-PGD(%)	RA-Transfer Attack(%) PARN-18 PARN-50 WRN-16-8		
FAST-AT	45.44	76.35	76.94	77.23
PGD-2-AT	44.71	77.56	78.64	78.84
Fast-AT-GA	47.31	77.34	78.34	78.53
FAST-BAT(OUrS)	48.67	78.03	79.93	79.21
proposal and the other baselines when facing white-box adaptive and black-box transfer attacks.
Firstly, RA increases if the transfer attack is present for each method, implying that the transfer attack
is weaker than the white-box adaptive attack. This is desired in the absence of obfuscated gradients.
Moreover, Fast-BAT consistently outperforms the other three baselines when defending against
both adaptive and transfer attacks. The absence of obfuscated gradients can also be justified by RA vs.
the growth of attack budget in Table 2, and the flatness of adversarial loss landscape in Figure. A1.
Ablation studies. In Appendix E, we present additional empirical studies including 1) the sensitivity
analysis of the linearization hyperparameter λ, 2) the choice of the linearization point, 3) the sensitivity
analysis of α2, 4) the influence of Hessian matrix on ReLU, and 5) non-ReLU neural networks.
6	Conclusion
In this paper, we introduce a novel bi-level optimization (BLO)-based fast adversarial training
framework, termed Fast-BAT. The rationale behind designing fast robust training through the lens
of BLO lies in two aspects. First, from the perspective of implicit gradients, we show that existing
Fast-AT framework is equivalent to the lower-level linearized BLO along the sign direction of input
gradient. Second, we show that Fast-BAT enables the least restriction to achieve improved staibility
of performance, mitigated catastrophic overfitting, and enhanced accuracy-robustness trade-off. To
the best of our knowledge, we for the first time establish the theory and the algorithmic foundation
of BLO for adversarially robust training. Extensive experiments are provided to demonstrate the
superiority of our method to state-of-the-art accelerated AT baselines.
9
Under review as a conference paper at ICLR 2022
References
Motasem Alfarra, Adel Bibi, Hasan Hammoud, Mohamed Gaafar, and Bernard Ghanem. On the decision
boundaries of deep neural networks: A tropical geometry perspective. arXiv preprint arXiv:2002.08838,
2020.
Maksym Andriushchenko and Nicolas Flammarion. Understanding and improving fast adversarial training.
NeurIPS, 2020.
Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of security:
Circumventing defenses to adversarial examples. arXiv preprint arXiv:1802.00420, 2018a.
Anish Athalye, Logan Engstrom, Andrew Ilyas, and Kevin Kwok. Synthesizing robust adversarial examples. In
International Conference on Machine Learning, pp. 284-293, 2018b.
Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In IEEE Symposium
on S&P, 2017.
Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, Percy Liang, and John C Duchi. Unlabeled data improves
adversarial robustness. arXiv preprint arXiv:1905.13736, 2019.
T. Chen, S. Liu, S. Chang, Y. Cheng, L. Amini, and Z. Wang. Adversarial robustness: From self-supervised
pretraining to fine-tuning. In CVPR, 2020.
Zhangyu Chen, Dong Liu, Xiaofei Wu, and Xiaochun Xu. Research on distributed renewable energy transaction
decision-making based on multi-agent bilevel cooperative reinforcement learning. 2019.
Francesco Croce and Matthias Hein. Reliable evaluation of adversarial robustness with an ensemble of diverse
parameter-free attacks. In International Conference on Machine Learning, pp. 2206-2216. PMLR, 2020.
Stephan Dempe. Foundations of bilevel programming. Springer Science & Business Media, 2002.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical
image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp.
248-255. IEEE, 2009.
Yao Deng, Xi Zheng, Tianyi Zhang, Chen Chen, Guannan Lou, and Miryung Kim. An analysis of adversarial
attacks and defenses on autonomous driving models. In 2020 IEEE International Conference on Pervasive
Computing and Communications (PerCom), pp. 1-10. IEEE, 2020.
Logan Engstrom, Andrew Ilyas, and Anish Athalye. Evaluating and understanding the robustness of adversarial
logit pairing. arXiv preprint arXiv:1807.10272, 2018.
Samuel G Finlayson, John D Bowers, Joichi Ito, Jonathan L Zittrain, Andrew L Beam, and Isaac S Kohane.
Adversarial attacks on medical machine learning. Science, 363(6433):1287-1289, 2019.
Saeed Ghadimi and Mengdi Wang. Approximation methods for bilevel programming. arXiv preprint:1802.02246,
2018.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples.
arXiv preprint arXiv:1412.6572, 2014.
Stephen Gould, Basura Fernando, Anoop Cherian, Peter Anderson, Rodrigo Santa Cruz, and Edison Guo. On
differentiating parameterized argmin and argmax problems with application to bi-level optimization. arXiv
preprint arXiv:1607.05447, 2016.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In
Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, 2016a.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In
European conference on computer vision, pp. 630-645. Springer, 2016b.
Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. A two-timescale framework for bilevel
optimization: Complexity analysis and application to actor-critic. arXiv preprint arXiv:2007.05170, 2020.
W Ronny Huang, Jonas Geiping, Liam Fowl, Gavin Taylor, and Tom Goldstein. Metapoison: Practical
general-purpose clean-label data poisoning. arXiv preprint arXiv:2004.00225, 2020.
Kaiyi Ji, Junjie Yang, and Yingbin Liang. Bilevel optimization: Nonasymptotic analysis and faster algorithms.
arXiv preprint arXiv:2010.07962, 2020.
10
Under review as a conference paper at ICLR 2022
A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. Master’s thesis, Department
of Computer Science, University of Toronto, 2009.
K Naveen Kumar, C Vishnu, Reshmi Mitra, and C Krishna Mohan. Black-box adversarial attacks in autonomous
vehicle technology. In 2020 IEEE Applied Imagery Pattern Recognition Workshop (AIPR), pp. 1-7. IEEE,
2020.
Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. Adversarial machine learning at scale. 2017 ICLR, arXiv
preprint arXiv:1611.01236, 2017. URL http://arxiv.org/abs/1611.01236.
Bai Li, Shiqi Wang, Suman Jana, and Lawrence Carin. Towards understanding fast adversarial training. arXiv
preprint arXiv:2006.03089, 2020.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep
learning models resistant to adversarial attacks. In International Conference on Learning Representations,
2018.
Faisal Mahmood, Daniel Borders, Richard J Chen, Gregory N McKay, Kevan J Salimian, Alexander Baras, and
Nicholas J Durr. Deep adversarial training for multi-organ nuclei segmentation in histopathology images.
IEEE transactions on medical imaging, 39(11):3257-3267, 2019.
Takeru Miyato, Andrew M Dai, and Ian Goodfellow. Adversarial training methods for semi-supervised text
classification. arXiv preprint arXiv:1605.07725, 2016.
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Jonathan Uesato, and Pascal Frossard. Robustness via
curvature regularization, and vice versa. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pp. 9078-9086, 2019.
Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Celik, and Ananthram Swami. The
limitations of deep learning in adversarial settings. In Security and Privacy (EuroS&P), 2016 IEEE European
Symposium on, pp. 372-387. IEEE, 2016.
Qi Qian, Shenghuo Zhu, Jiasheng Tang, Rong Jin, Baigui Sun, and Hao Li. Robust optimization over multiple
domains. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pp. 4739-4746, 2019.
Aravind Rajeswaran, Chelsea Finn, Sham Kakade, and Sergey Levine. Meta-learning with implicit gradients.
arXiv preprint arXiv:1909.04630, 2019.
Prajit Ramachandran, Barret Zoph, and Quoc V Le. Searching for activation functions. arXiv preprint
arXiv:1710.05941, 2017.
Leslie Rice, Eric Wong, and Zico Kolter. Overfitting in adversarially robust deep learning. In International
Conference on Machine Learning, pp. 8093-8104. PMLR, 2020.
Hadi Salman, Greg Yang, Jerry Li, Pengchuan Zhang, Huan Zhang, Ilya Razenshteyn, and Sebastien Bubeck.
Provably robust deep learning via adversarially trained smoothed classifiers. arXiv preprint arXiv:1906.04584,
2019.
Ali Shafahi, Mahyar Najibi, Mohammad Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer, Larry S
Davis, Gavin Taylor, and Tom Goldstein. Adversarial training for free! In Advances in Neural Information
Processing Systems, pp. 3353-3364, 2019.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob
Fergus. Intriguing properties of neural networks. International Conference on Learning Representations,
2014.
Simen Thys, Wiebe Van Ranst, and Toon Goedem6. Fooling automated surveillance cameras: adversarial
patches to attack person detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition Workshops, pp. 0-0, 2019.
Luis Vicente, Gilles Savard, and Joaquim Jddice. Descent approaches for quadratic bilevel programming.
Journal of Optimization Theory and Applications, 81(2):379-399, 1994.
Douglas J White and G Anandalingam. A penalty function approach for solving bi-level linear programs.
Journal of Global Optimization, 3(4):397-419, 1993.
Eric Wong, Leslie Rice, and J. Zico Kolter. Fast is better than free: Revisiting adversarial training. In
International Conference on Learning Representations, 2020.
11
Under review as a conference paper at ICLR 2022
Cihang Xie, Yuxin Wu, Laurens van der Maaten, Alan L Yuille, and Kaiming He. Feature denoising for
improving adversarial robustness. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pp. 501-509, 2019.
Kaidi Xu, Sijia Liu, Pu Zhao, Pin-Yu Chen, Huan Zhang, Quanfu Fan, Deniz Erdogmus, Yanzhi Wang, and Xue
Lin. Structured adversarial attack: Towards general implementation and better interpretability. In ICLR, 2019.
Kaidi Xu, Gaoyuan Zhang, S. Liu, Quanfu Fan, Mengshu Sun, Hongge Chen, Pin-Yu Chen, Yanzhi Wang, and
Xue Lin. Adversarial T-Shirt! evading person detectors in a physical world. In ECCV, 2020.
Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. arXiv preprint arXiv:1605.07146, 2016.
Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, and Bin Dong. You only propagate once:
Accelerating adversarial training via maximal principle. arXiv preprint arXiv:1905.00877, 2019a.
Haichao Zhang and Jianyu Wang. Towards adversarially robust object detection. In Proceedings of the IEEE/CVF
International Conference on Computer Vision, pp. 421-430, 2019.
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P Xing, Laurent El Ghaoui, and Michael I Jordan. Theoretically
principled trade-off between robustness and accuracy. ICML, 2019b.
Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, and Jingjing Liu. Freelb: Enhanced adversarial
training for natural language understanding. arXiv preprint arXiv:1909.11764, 2019.
12
Under review as a conference paper at ICLR 2022
A Proof of Theorem 1
Proof: UPon defining g(θ, δ) = (δ - z)>Vδ=z'atk(θ, δ) + (λ∕2)∣∣δ - z∣∣2, we repeat (7)as
minimize E(χ,y)∈D['tr(θ, δ*(θ))]
subject to δ* (θ) = argmin g(θ, δ),	(12)
Bδ≤b
where we have used the expression of linear constraints in (9).
Our goal is to derive the IG dδdθ) shown in (3). To this end, we first build implicit functions by
leveraging KKT conditions of the lower-level problem of (12). We say δ*(θ) and λ*(θ) (Lagrangian
multipliers) satisfy the KKT conditions:
Stationarity:	Vg(θ, δ*(θ)) + B>λ*(θ) = 0,
Complementary slackness:	λ*(θ) ∙ (Bδ*(θ) - b) = 0	(13)
Dual feasibility:	λ*(θ) ≥ 0
where ∙ denotes the elementwise product.
Active constraints and definition of B0: Let B0 denote the sub-matrix of B and b0 the sub-vector
of b, which consists of only the active constraints at δ*(θ), i.e., those satisfied with the equality
Boδ*(θ) = bo (corresponding to nonzero dual variables). The determination of active constraints is
done given θ at each iteration.
With the aid of (B0, b0), KKT (13) becomes
Vδg(θ, δ*(θ))+ B>λ*(θ) = O, and Boδ*(θ)- bo = 0,	(14)
where the nonzero λ* (θ) only correspond to active constraints. We take derivatives w.r.t. θ for (14),
and thus obtain
dVδ g(θ, δ*(θ))>
dθ
=⇒Vθδ g(θ, δ*(θ)) +
'—{z—}
IG
1 dδ (θ)>c>	八
and 拓	BO = 0,
dθ
'—{—}
IG
+ Vθ λ*(θ)>Bο = O
W* Vδδg(θ, δ*(θ)) + Vθλ*(θ)>Bο = O,
dθ
(15)
(16)
where Vθδ ∈ Rlθl×lδl denotes second-order partial derivatives (recall that ∣θ∣ = n and ∣δ∣ = d).
According to (15), we have
dδ*(θ)> = -[Vθδg(θ, δ*(θ)) + Vθλ*(θ)>Bο]Vδδg(θ, δ*(θ))-1∙	(17)
dθ
Substituting the above into (16), we obtain
Vθδg(θ, δ*(θ))Vδδg(θ, δ*(θ))-1 B> + Vθλ*(θ)>BοVδδg(θ, δ*(θ))-1B> = O,	(18)
which yields:
Vθ λ*(θ)> = -Vθδ g(θ, δ*(θ))Vδδ g(θ, δ*(θ))-1B>[B0Vδδ g(θ, δ*(θ))-1B>]-1,	(19)
and thus,
Vθλ*(θ)>Bο = -Vθδg(θ,δ*(θ))Vδδg(θ,δ*(θ))-1B>[B0Vδδg(θ,δ*(θ))-1B>]-1Bο. (20)
Substituting (20) into (17), we obtain the IG
dδ[θ)> = -Vθδg(θ, δ*(θ))Vδδg(θ, δ*(θ))-1 - Vθλ*(θ)>BοVδδg(θ, δ*(θ))-1
dθ
=-Vθδ g(θ, δ*(θ))Vδδ g(θ, δ*(θ))-1
+ Vθδg(θ, δ*(θ))Vδδg(θ, δ*(θ))-1B>[BoVδδg(θ, δ*(θ))-1B>]TBοVδδg(θ, δ*(θ))-1.
(21)
13
Under review as a conference paper at ICLR 2022
To further compute (21), the Hessian matrix Vδδ'atk is needed. Recall from the definition of the
lower-level objective that the Hessian matrix is given by
Vδδ g(θ, δ*(θ)) = Vδδ 'atk + λI = 0 + λI.	(22)
Here We Used the assumption that Vδδ'atk = 0. The rationale behind that is neural networks
commonly leads to a piece-wise linear decision boundary w.r.t. the inputs (Moosavi-Dezfooli et al.,
2019; Alfarra et al., 2020), and thus, its second-order derivative (Hessian) Vδδ'atk is close to zero.
Based on the simplification (22), we have
dδ*(θ)>
dθ
-(1∕λ)Vθδg(θ, δ*(θ)) (I - B>[BoB>]-1Bo)
X-----------------------------V---------}
:=HC
-(1∕λ)Vθδ'atk(θ, δ*(θ))Hc,
(23)
where we have used the fact that Vθδg = Vθδ'atk .
What is HC in (23)? Since B = -I , we can obtain that B°B> = I and B>Bo is a sparse diagonal
matrix with diagonal entries being 0 or 1. Thus, HC can be first simplified to
HC = I - B0> B0 .	(24)
Clearly, HC is also a diagonal matrix with either 0 or 1 diagonal entries. The 1-valued diagonal
entry of HC corresponds to the inactive constraints in Bδ*(θ) < b, i.e., those satisfied with strict
inequalities in {kδk∞ ≤ , 0 ≤ δ ≤ 1}. This can be expressed as
HC = [1pι≤δ*≤qι e1, . . . , 1pι≤δd≤qd ed]	(25)
where 1pi≤δi≤qi ∈ {0,1} denotes the indicator function over the constraint {pi ≤ δ* ≤ qi} and
returns 1 if the constraint is satisfied, δ* denotes the ith entry of δ*(θ), Pi = max{-e, -xi} and
qi = min{, 1 - xi }, and ei ∈ Rd denotes the basis vector with the ith entry being 1 and others
being 0s.
Based on the definition of g, (23) and (25), we can eventually achieve the desired IG formula (10).
The proof is now complete.
14
Under review as a conference paper at ICLR 2022
B DISCUSSION ON CASE `atk = -`tr
We provide an explanation on the argument "Even if we set `atk = -`tr, problem (2) does not reduce
to problem (1) due to the presence of lower-level constraint" from the following two points.
•	In the absence of the constraint δ ∈ C, if we set `atk = -`tr, then Problem 2 will reduce to
Problem 1.
This is a known BLO result (e.g. Ghadimi & Wang (2018)) and can be readily proven
using the stationary condition. To be specific, based on the stationary condition of uncon-
strained lower-level optimization, We have Vδ'atk(θ, δ*) = 0. Since 'atk = -'tr, We have
Vδ'tr(θ, δ*) = 0. As a result, the second term in Eq. 3 becomes 0 and solving problem 2
becomes identical to solving the min-max problem 1.
•	In the presence of the constraint δ ∈ C, the stationary condition cannot be applied since the
stationary point may not be a feasible point in the constraint. In other words, Vδ'atk(θ, δ*)=
0 does not hold in the case of `atk = -`tr. As a matter of fact, one has to resort to KKT
conditions instead of the stationary condition for a constrained lower-level problem. Similar
to our proof in Theorem 1, the implicit gradient (and thus the second term of Eq. 3) cannot
be omitted in general. This makes problem 2 different from the problem 1.
C Derivation of Implicit Gradient for Fast-AT
We can derive Eq. 6 using KKT condition similar to Theorem 1. Specifically, let
g(θ, δ) = (sign(Vδ=z'atk(θ, δ; x,y)), δ — Zi + 2 ∣∣δ — z∣∣2,	(26)
we have
Vθδg = 0.	(27)
Following (21), we can further obtain (6) based on (27).
D Detailed Experiment settings
D. 1 Training Set-up
For CIFAR-10, we summarize the training setup for each method. 1) Fast-AT: We use FGSM with
an attack step size of 1.25e to generate perturbations; 2) PGD-2-AT: 2-step PGD attacks1 with an
attack step size of 0.5e is implemented; 3) FAST-AT-GA: The gradient alignment regularization
parameter is set to the recommended value for each e; 4) Fast-bAt： We select λ from 255/5000 to
255/2000 for different e. At the same time, we adjust α2 accordingly, so that the coefficient of the
second term in (11), namely a2∕λ always equals to 0.1αι.
For ImageNet, we set e to 2/255 , and we strictly follow the training setting adopted by Wong et al.
(2020). In FAST-BAT, we fix λ at 255/3000 and adopt the same α2 selection strategy as CIFAR-10.
Parameter for Fast-AT-GA Regarding FAST-AT-GA with different model types, we adopt the
same regularization parameter recommended in its official repo2 intended for PreActResNet-18
(namely 0.2 for e = 8/255 and 2.0 for e = 16/255).
1We use random initialization to generate perturbations for PGD, while in the paper of Fast-AT-GA (An-
driushchenko & Flammarion, 2020), 2-step PGD is initialized at zero point, which we believe will underestimate
the effect of PGD-2-AT
2FAST-AT-GA: https://github.com/tml-epfl/understanding-fast-adv-training/
blob/master/sh
15
Under review as a conference paper at ICLR 2022
E Additional Experimental Results
Fast-BAT
Figure A1: Visualization of adversarial loss landscapes of FAST-AT, FAST-AT-GA and FAST-BAT trained
using the ResNet-18 model on the CIFAR-10 dataset. The losses at are calculated w.r.t. the same image example
ID #001456, and the landscape is obtained by tracking the loss changes w.r.t. input variations following Engstrom
et al. (2018). That is, the loss landscape is generated by Z = loss(I + X ∙ ri + y ∙ r2), where I denotes an image,
and the x-axis and the y-axis correspond to linear coefficients associated with the sign-based attack direction
ri = sign(Vιloss(I)) X and a random direction r2 〜Rademacher(0.5), respectively.
Sensitivity to regularization parameter λ
In Table A1, we show the sensitivity of Fast-
BAT to the regularization parameter λ. All the
parameters remain the same as default setting,
except that for different λ. We always adjust
a2 so that α2∕λ = 0.1α1 holds. Note 1∕λ also
serves as the attack step in (8). As λ decreases,
the improvement on robust accuracy is evidently
strengthened, and there is a obvious trade-off
between robust accuracy (SA) and standard ac-
curacy (RA). At a certain level of λ, namely
Table A1: Performance of FAST-BAT with different
parameter λ. We train and evaluate with the same attack
budget = 16/255 on CIFAR-10 to show the influence
brought by λ.
CIFAR-10, PreActResNet-18, e =				16∕255	
1/λ (/255)	I 500	1000	1500	2000	2500
SA (%)	83.20	75.06	69.31	67.81	67.59
RA-PGD (%)	19.02	21.42	23.34	26.07	26.12
when λ ≤ 255/2000, RA starts to converge and stop surging.
Sensitivity to different α2 choices We con-
sider the case of robust training with the large
choice (16∕255). As we can see from Table A2,
if α2 is set too small (α2 = 0.008α1), then both
SA and RA will drop significantly. Here α1 is
set as the cyclic learning rate and thus not a
constant parameter. However, in the α2 inter-
val [0.0125α1, 0.025α1], we observed a tradeoff
between standard accuracy (SA) and robust ac-
curacy (RA): That is, the improvement in RA
corresponds to a loss in SA. In our experiments,
we choose α2 when the tradeoff yields the best
Table A2: Performance of FAST-BATwith different α2
choices on CIFAR-10. Models are trained and evaluated
with the same attack budget ( = 16/255). Here α1 is
set as the cyclic learning rate and thus, is not a constant
parameter. α2 is always set proportionate to α1 for
simplicity.
α2 (CIFAR-10, PreActResNet18, = 16∕255)	0.025α1	0.0167α1	0.0125α1	0.008α1
SA (%)	75.06	6931	67.81	57.92
RA-PGD (%)	21.42	23.34	26.07	20.53
RA without suffering a significant drop of SA (which still outperforms the baseline approaches).
Sensitivity of linearization schemes Fast-
BAT needs a good linearization point z in (7).
In experiments, we adopt the perturbation gener-
ated by 1-step PGD without sign as our default
linearization scheme. In Table A3, we show
the performance of the other possible lineariza-
tion options. We can find 1-step PGD without
sign achieves best robust accuracy among all the
choices. This is not spurring since this lineariza-
tion point choice is consistent with the first-
Taylor expansion that we used along the direc-
tion of input gradient without sign involved. By
contrast, Fast-BAT linearized with uniformly
Table A3: Performance of FAST-BAT with different
linearization schemes. Besides 1-step PGD without sign
(PGD w/o Sign), we further generate linearization point
with the following methods: uniformly random noise
[-, ]d (Uniformly Random); uniformly random cor-
ner {-, }d (Random Corner); and perturbation from
1-step PGD attack with 0.5 as attack step (PGD).
CIFAR-10, PreACtReSNet-18, e = 16/255
Linearization Method	PGD w/o Sign	Uniformly Random	Random Corner	PGD
SA (%)	69.31 ^^	43.42	62.19	75.30
RA-PGD (%)	23.34	21.25	16.5	19.42
random noise suffers from catastrophic overfitting and reaches a rather low standard accuracy (SA).
Fast-BAT with other linearizations also yields worse SA-RA trade-off than our proposal.
16
Under review as a conference paper at ICLR 2022
Table A4: Performance of Hessian-free and Hessian-aware FAST-BATon CIFAR-10. We train and evaluate
with the same attack budgets = 8/255 and = 16/255 to show the influence brought by Hessian matrix.
Method	RA-PGD (%) ( = 8/255)	RA-PGD (%) ( = 16/255)	RA-AA (%) ( = 8/255)	RA-AA (%) ( = 16/255)	SA (%) ( = 8/255)	SA (%) ( = 16/255)	Time (s/epoch)
Hessian-free Fast-BAT	48.67	26.07	44.86	18.18	79.47	67.81	135
Hessian-aware Fast-BAT	48.52	26.12	44.81	18.31	79.54	67.93	179
Table A5: Performance of FAST-ATand FAST-BATwith different activation functions on CIFAR-10. ReLU,
Swish and Softplus are taken into consideration. For Fast-BAT, we compare the Hessian-free and Hessian-aware
version to verify the influence of Hessian matrix. The results are averaged over 3 independent trials.
Setting	SA (%) ( = 8/255)	RA-PGD (%) ( = 8/255)	SA (%) ( = 16/255)	RA-PGD (%) ( = 16/255)	Time (s/epoch)
Fast-AT-ReLU Fast-BAT-ReLU	81.88	45.44	46.13	21.75	42
(Hessian-aware) Fast-BAT-ReLU	79.54	48.52	67.93	26.12	179
(Hessian-free)	79.47	48.67	67.81	26.07	135
Fast-AT-Softplus	81.29	47.26	45.39	22.40	42
Fast-BAT-Softplus (Hessian-aware)	79.59	49.74	68.63	25.54	178
Fast-BAT-Softplus (Hessian-free)	79.48	49.67	68.57	25.59	137
Fast-AT-Swish Fast-BAT-Swish	75.61	44.43	52.03	23.08	49
(Hessian-aware) Fast-BAT-Swish	73.93	45.97	62.49	23.99	196
(Hessian-free)	73.89	45.90	62.59	23.81	141
Influence of Hessian matrix In Theorem 1, the Hessian-free assumption, i.e. Vδδ'atk = 0, was
made to simplify the computation of IG term (implicit gradient). To examine how the Hessian matrix
Vδδ'atk affects the performance of Fast-BAT, we conduct experiments to compare the Hessian-free
Fast-BATwith the Hessian-aware version. In Hessian-aware Fast-BAT, the implicit gradient is
calculated based on (21). In Table A4, the results do not indicate much difference when Hessian is
used. However, the extra calculation brought by Hessian heavily slows down Fast-BATas around
30% more time is needed. Therefore, the Hessian-free assumption is reasonable and also necessary
in terms of the efficiency of the algorithm.
Ablation study on smooth activation functions The Hessian-free assumption is based on the
fact that the commonly used ReLU activation function is piece-wise linear w.r.t. input. We further
conduct experiments to verify the feasibility of such assumption on models with non-ReLU activation
functions. We choose two commonly used activation functions, Swish(Ramachandran et al., 2017)
and Softplus, as alternatives for non-smooth ReLU function. We compare the results both calculating
Hessian as well as the Hessian-free version to see if the Hessian-free assumption still holds for the
non-ReLU neural network. The results are shown in Table A5. As we can see, the use of Hessian does
not affect performance much. A similar phenomenon can be observed across different and different
model activation functions (ReLU, Softplus, and Swish). However, the introduction of Hessian leads
to an increase in time consumption by more than 30%. Therefore, we can draw the conclusion that
the Hessian-free assumption is reasonable across different activation function choices.
17