Under review as a conference paper at ICLR 2022
GSmooth: Certified Robustness against
Semantic Transformations via Generalized
Randomized Smoothing
Anonymous authors
Paper under double-blind review
Ab stract
The vulnerability of deep learning models to adversarial examples and seman-
tic transformations has limited the applications in risk-sensitive areas. The re-
cent development of certified defense approaches like randomized smoothing pro-
vides a promising direction towards building reliable machine learning systems.
However, current certified defenses cannot handle complex semantic transforma-
tions like rotational blur and defocus blur which are common in practical applica-
tions. In this paper, we propose a generalized randomized smoothing framework
(GSmooth) for certified robustness against semantic transformations. We provide
both a unified and rigorous theoretical framework and scalable algorithms for cer-
tified robustness on complex semantic transformations. Specifically, our key idea
is to use a surrogate image-to-image neural network to approximate a transforma-
tion which provides a powerful tool for studying the properties of semantic trans-
formations and certify the transformation based on this neural network. Experi-
ments on multiple types of semantic perturbations and corruptions using multiple
datasets demonstrate the effectiveness of our approach.
1	Introduction
Although deep learning models have achieved remarkable success on various applications (LeCun
et al., 2015), they are vulnerable to adversarial examples (Biggio et al., 2013; Szegedy et al., 2013;
Goodfellow et al., 2014) and semantic transformations (Hendrycks & Dietterich, 2019). The vulner-
ability of deep learning models can limit their applications on many important tasks. For example,
the autonomous driving system can be misled even by a small adversarial patch on the road mark
(Jing et al., 2021). Compared with the maliciously crafted adversarial examples, semantic transfor-
mations are more practical in real-world scenarios, such as rotation, translation, blur, bad weather,
and so on. Such transformations do not damage the semantic features of images and can be easily
recognized by humans, but they also degrade the performance of deep learning models. Therefore,
it is imperative to improve model robustness against semantic transformations.
To develop more reliable machine learning systems, many efforts have been made to design defense
techniques against adversarial attacks or semantic transformations. The existing defense methods
can be categorized into empirical defenses and certified defenses. Adversarial training (AT) (Madry
et al., 2017; Zhang et al., 2019a) is one of the most effective empirical defenses against `p-norm
bounded adversarial examples. Moreover, methods based on data augmentation (Hendrycks et al.,
2019; Wang et al., 2019; Calian et al., 2021) have been proposed to empirically improve the perfor-
mance under semantic transformations. However, the performance of empirical defenses is difficult
to be fully justified and these defenses can be further broken by new adaptive attacks (Athalye et al.,
2018; Tramer et al., 2020). In contrast, the certified defenses aim to theoretically provide a certified
region where the model is theoretically safe under any attack or perturbation (Wong & Kolter, 2018;
Cohen et al., 2019; Gowal et al., 2018; Zhang et al., 2019b). Along this line, developing certified
defense methods is a crucial step towards reliable machine learning systems.
Although certified defenses have achieved great success, most of them are limited to defend against
`p -norm bounded attacks. However, the `p distance between the original image and its corrupted
counterpart by a semantic transformation (e.g., translation, rotation) would be large even when the
1
Under review as a conference paper at ICLR 2022
corruption is slight. Therefore, the current methods are incapable of certifying robustness against
such semantic perturbations. To solve this problem, several recent works (Fischer et al., 2020;
Mohapatra et al., 2020; Li et al., 2021) attempt to extend the certified defenses to several simple
semantic corruptions, including translation, rotation, and Gaussian blur. However, these works are
not scalable to certify robustness against complex and general semantic perturbations. First, deter-
ministic certified defenses (Mohapatra et al., 2020) based on convex relaxation for the activation
function require solving a complex optimization problem for computing bound which is computa-
tionally expensive. Second, probabilistic approaches based on randomized smoothing also demand
a handcrafted Lipschitz bound (Li et al., 2021), which is intractable for complicated semantic trans-
formations. For example, many semantic transformations such as glass blur and pixelate do not have
a closed form expression or they are black boxes and hard to be analyzed theoretically, but they are
common in real-world scenarios. Therefore, it is still highly challenging to certify robustness against
these complex and realistic semantic transformations.
To address the aforementioned challenges, we propose a generalized randomized smoothing frame-
work (GSmooth). First, we provide a unified framework of GSmooth for certifying general seman-
tic transformations. Then we categorize the transformations into resolvable transformations (e.g.,
translation) and non-resolvable transformations (e.g., rotational blur) similar with Li et al. (2021).
As mentioned above, most non-resolvable transformations are complex and the existing methods
cannot provide their certified radius. To handle the challenge, we propose to use an image-to-image
translation neural network to approximate all these transformations. Due to the strong capacity of
neural networks, our method is flexible and scalable to model these complex semantic transforma-
tions. By introducing an augmented noise in the layers of the surrogate model, we can theoretically
provide the certified radius for the proxy neural networks which can be used for certifying the orig-
inal transformations. Next, we provide theoretical analysis and error bounding for the approxima-
tion. Finally, we validate the effectiveness of our methods on several publicly available datasets.
Extensive experimental results demonstrate that our methods are effective for certifying complex
semantic transformations including different types of blur or image quality corruptions.
2	Related work
2.1	Attacks and defenses for semantic transformations
Unlike `p perturbation which adds small noise to every pixel of an image, semantic attacks or phys-
ical attacks are usually unrestricted. Brown et al. (2017); Song et al. (2018) use a small patch added
to the image to mislead the classifier or the object detector. Engstrom et al. (2019; 2018); Xiao
et al. (2018) construct adversarial examples using spatial transformations like rotation or transla-
tion. Hendrycks & Dietterich (2019) show that a wide variety of semantic perturbations degrade
the performance for many deep learning models. Many works (Cubuk et al., 2019; Hendrycks et al.,
2019; 2020; Robey et al., 2020) propose diverse data augmentation techniques to enhance robustness
under semantic perturbations. Calian et al. (2021) propose adversarial data augmentation that can
be viewed as adversarial training for defending semantic perturbations. Beyond empirical defenses,
several works (MohaPatra et al., 2020; Madry et al., 2017; Singh et al., 2019; Balunovic et al.,
2019) attempt to certify some simple geometric transformations. However, all of them belong to
deterministic certification aPProaches and their Performance on realistic datasets are unsatisfactory.
2.2	Randomized smoothing
Randomized smoothing is a novel certification method originated from differential Privacy (Lecuyer
et al., 2019). Cohen et al. (2019) then imProve the certified bound and aPPly it to large scale deeP
neural networks and datasets. Yang et al. (2020) exhaustively analyze the robust radius by using
different noise distribution and norms. Hayes (2020); Yang et al. (2020) Point out that randomized
smoothing suffers from curse of dimensionality for the l∞ norm. Salman et al. (2019) adoPt adver-
sarial training to train smoothed classifiers to obtain better robustness guarantees. Li et al. (2021);
Fischer et al. (2020) extend randomized smoothing to certify some simPle semantic transforma-
tions, e.g., image translation and rotation. It shows that randomized smoothing could be generalized
to certify more diverse attacks or corruPtions. However, their methods are limited to simPle semantic
transformations, which are easy to analyze their mathematical ProPerties.
2
Under review as a conference paper at ICLR 2022
3	Proposed method
In this section, we present the framework and theoretical analyses of our Generalized Randomized
Smoothing (GSmooth). We first introduce the basic notations. Then we divide the semantic trans-
formations into resolvable transformations and non-resolvable transformations similar with Li et al.
(2021). Next we introduce the details of our GSmooth for these two types of semantic transforma-
tions, respectively. Finally, we show the theoretical insight and proof sketch of our main results.
3.1	Notations
We first introduce the notations and formulation of the task. Given the input of x ∈ Rn and the
labels of Y = {1, 2, . . .p}, we denote the classifier as f(x) : Rn → [0, 1]p, which outputs predicted
probabilities over all P classes. The prediction of f is argmaxi∈γ f (x)i, where f (∙) denotes the
i-th element of f (∙). Let T(θ, x) : Rm X Rn → Rn be a semantic transformation of raw input X with
parameter θ ∈ Rm . We define the smoothed classifier as
G(X)= Eθ 〜g [f(τ (θ,x))],
(1)
which is the average prediction for the samples under a smoothing distribution g(θ) where g(θ) =
exp(-ψ(θ)) and ψ(θ) is a smooth function from Rm → R. Let ||u|| = 1 be any vector with unit
norm and a random variable Yu =(u, Vψ(δ)i where δ 〜g and V is the gradient operator of a
function. The complementary CDF is φu(c) = P[γu > c] and the inverse complementary CDF is
夕-I(P) = inf{c∣P(γu > c) 6 p}. Following Yang et al. (2020), we define a function Φ as
Φ(p) = max∣∣u∣∣=ι E[γuI{γu > °-1(p)}],	(2)
which will be used to represent the certified radius. Let yA= arg maxi∈Y G(X)i be the predicted
label by the smoothed classifier G(X) and yB = arg maXi∈γ∖yA G(x) is the runner-up class. With-
out causing confusion, we use G(X)A to denote the probability of the top class G(X)yA ; likewise for
G(X)B.
3.2	Certified bound for resolvable semantic transformations
We first discuss a class of transformations that are resolvable — the composition of two transforma-
tions with parameters belonging to a perturbation set θ, ξ ∈ P ⊂ Rm is still a transformation with
a new parameter γ(θ, ξ) ∈ P ⊂ Rm, where Y(∙, ∙) : P × P → P is a function depending on these
parameters. For resolvable semantic transformations, we have the following theorem.
Theorem 1. Let f(X) be any classifier and G(X) be the smoothed classifier defined in Eq. (1). If
there exists afunction M (∙, ∙) : P × P → R ,the transformation T (∙, ∙) satisfies
∂YBH = ∂YBHm(θ ξ)
∂ξ	∂θ ( ,ξ),
and there exist two constants PA , Pb satisfying
G(X)A > PA > PB > G(x)b,
then yA = arg maxi∈Y G(τ(ξ, X))i holds for any kξk 6 R where
C	1	fpA 1 7
R = 2M7 JU 砌 dp,
(3)
and M* = mαxξ,θ∈p ||M(ξ, θ)∣∣.
Remark. The settings of Theorem 1 are similar with Li et al. (2021) for resolvable semantic transfor-
mations. But here we adopt a different presentation and proof for the theorem which could be easier
to extend to our GSmooth framework for general semantic transformations. Specifically, we show
two examples of the theorem which are additive transformations and commutable transformations.
A transformation is additive if T(θ, T(ξ, X)) = T(ξ + θ, X) for any θ, ξ ∈ P; or it is commutable if
T(θ, T(ξ, X)) = T(ξ, T(θ, X)) for any θ, ξ ∈ P. For these two types of transformations, it is straight-
forward to verify that they satisfy the property proposed in Theorem 1. As an example, we simply
apply Theorem 1 for isotropic Gaussian distribution g(θ) = N(0, σ2I) and get the certified radius
R = 2 (Ψ (PA) - Ψ (PB)),
(4)
3
Under review as a conference paper at ICLR 2022
Transformation Parameters
Input Image
Surrogate Model
Noise ■ □ I ~ g
Base Classifier
Certified Radius
Augmented Noisy Images
Augmented Noise	~ g
Figure 1: A graphical illustration of our GSmooth. We use a surrogate image-to-image translation
network to accurately fit a semantic transformation. Then we add a new augmented noise into the
surrogate model and construct the GSmooth classifier. The augmented noise are sampled to ensure
the transformation to be resolvable in the semantic space. We theoretically calculate the certification
bound for the surrogate model to certify the original semantic transformation.
where Ψ is the inverse CDF of the standard Gaussian distribution. These two kinds of transforma-
tions include image translation and Gaussian blur, which are basic semantic transformations and
widely discussed in previous works (Li et al., 2021; Fischer et al., 2020). The certification of these
simple transformations only requires applying translation or Gaussian blur to the sample and gets
the average classification score under the noise distribution.
3.3 Certified bound for general semantic transformations
Translation and Gaussian blur are two specific cases of semantic transformations. In practice, most
semantic transformations are not commutable or even not resolvable. Therefore, we need to de-
velop better methods for certifying more types of semantic transformations. However, the existing
methods like Semanify-NN (Mohapatra et al., 2020) based on convex relaxation and TSS (Li et al.,
2021) based on randomized smoothing require to develop a specific algorithm or bound for each in-
dividual semantic transformation. This is not scalable and might be infeasible for more complicated
transformations without explicit mathematical forms.
To address the challenge, we draw inspiration from the fact that neural networks are able to ap-
proximate functions including a complex and unknown semantic transformation (Zhu et al., 2017).
First, we propose to use a surrogate image-to-image translation model to accurately fit the semantic
transformation. Then we theorectially show that by introducing an augmented noise in the layers
of the surrogate model, as shown in Fig 1, randomized smoothing can be extended to handle these
transformations. Specifically, we define the surrogate model as the following form that will lead to
a simple certification bound as we shall see:
τ(θ,x) =H(F1(θ)+F2(x)),	(5)
where Fι(∙) : Rm → Rd,F2(∙) : Rn → Rd, and H(∙) : Rd → Rn are three individual neural
networks. Fι(∙) and F2(∙) are the encoders for transformation parameters and images respectively,
and their encodings are added together in the semantic space which is critical for its theoretical
certification. We find that the surrogate neural network is much easier to analyze and can be certified
by introducing a dimensional augmentation strategy for both noise parameters and input images.
As illustrated in Fig. 1, an augmented noise is added to the semantic layers H(∙) in the surrogate
model. Our key insight is that the transformation could be viewed as the superposition of a resolvable
part and a non-resolvable residual part in the augmented semantic space. Then we could use the
augmented noise to control the non-resolvable residual part if the augmented dimension d > m + n.
This dimension augmentation is the key step of our technique. The augmentation for noise is from
Rm to Rd . To keep the dimension consistent, we also augment data x to Rd by padding 0 entries.
4
Under review as a conference paper at ICLR 2022
By certifying the transformation based on the surrogate model, we are able to certify the original
transformation if the approximation error is within an acceptable region (detailed analysis is in
Theorem 3). Our method is flexible and scalable since the surrogate neural network has a uniform
mathematical form for theoretical analysis and they are trained automatically. Next, we discuss the
details of GSmooth.
Specifically, We introduce the augmented data X ∈ Rd and the augmented parameter θ ∈ Rd as
(6)
Where the additional parameters θ0 ∈ Rn are sampled from g0 (θ0), and the joint distribution of θ0
and θ is θ 〜g where g(θ) = g0(θ0)g(θ). Moreover, the augmented data χ0 ∈ Rm. We define the
generalized smoothed classifier as
G(X) = EMg@ [f(T(θ,X))],	⑺
where f is the “augmented target classifier” that equals the original classifier when constrained on
the original input x, which means f (x) = f (x). This can be achieved by setting the weights of
additional dimensions to 0. Note that now all the functions are augmented for a d dimensional
input. We further augment our surrogate neural network to represent the augmented transformation
T: Rd → Rd,
τ(θ,x) = H(Fι(θ) + F2(x)),	(8)
where H(∙),F1(∙),F2(∙) : Rd → Rd are parts of the augmented surrogate model. By carefully
designing the interaction between the augmented parameters and the original parameters, we could
turn the transformation to a resolvable one and it does not change the original surrogate model when
constraining to the original input X and θ. Specifically, we design the function F1 and F2 as follows:
F1(θ) = (	F1(θ)	+ θj,F2(X)	=(	F；(X)) ,H(X)=	d-n	H (x).	⑼
Before stating our main theorem, we introduce several notations 飞 = Fι(ξ) + F2(x), zθ = Fι(θ) +
F2(X), yξ = (yξ ,yξ )t = H(F1(ξ)+F2(X)) and y = (yθ ,Vθ )t = H(F1(θ)+F2(X)) for simplicity.
Then we theoretically prove that the GSmooth classifier is certifiably robust within a given range:
Theorem 2. Suppose f (x) is a classifier and G(X) is the smoothed CIaSSfier defined in Eq. (7), if
there exist PA and PB satisfying
G(X)A > PA > PB > G(x)b,
then yA = argmaxi∈γ G(τ(ξ, X))i forany ∣∣ξk2 6 R, where
1	1	∕pA 1 ,
R =2M^ Xb Φ(P) dp,
and the coefficient M* is defined as
M *
maxJ1J"2(yξ) dFI叫2
ξ,θ∈p v1+ll ∂ξ	a。『
(10)
(11)
As the main result of our GSmooth, we have several observations about it. First, we see that the
certified radius is similar to the result in Theorem 1. Second, compared with resolvable transforma-
tions, we need to add a new type of noise when constructing the GSmooth classifier. This isotropic
noise has the same dimension as the data and is added to the intermediate layers of surrogate neural
networks. The theoretical explanation behind this is that this isotropic noise makes the Jacobian
matrix of the semantic transformation to be invertible which is crucial for the proof. Third, we ob-
serve that the coefficient M * depends on the norm of the difference of two Jacobian matrices and is
independent with the target classifier, later we will discuss the meaning of this term in detail.
Before diving into our theoretical insight and proof of the theorem, we introduce a specific case
of Theorem 2 which is more convenient for practical usage. We empirically found that taking a
5
Under review as a conference paper at ICLR 2022
linear transformation as F1 (θ) = A1θ + b1 where A1 ∈ Rn×m, b1 ∈ Rn does not sacrifice the
precision of the surrogate network and We have dF沪=Ai. After substituting the term in Eq. (44)
We only need to optimize ξ for calculating M * and we make the bound tighter. Additionally, we
use two gaussian distributions for the noise distribution and the augmented noise distribution, i.e.
g(θ) = N(0, σ12I) and g0 (θ0) = N(0, σ22I). Formally, we have the following corollary,
Corollary 1. Suppose f (x) is a classifier and G(X) is the smoothed CIaSSfier defined in Eq. (7), if
the layer F1 (θ) in the surrogate neural network has the following form:
F1(θ) = A1θ + b1	(12)
where Ai ∈ Rn×m, bi ∈ Rn are the parameters; and if there exists PA and PB satisfying
G(X)A > PA > PB > G(x)b,
then yA = argmaxi∈γ G(T(ξ,x))i forany ∣∣ξ∣∣2 6 R where
R = 2mm* (ψ (PA) - ψ (PB)),	(13)
where Ψ(∙) is the inverse CDF of standard Gaussian distribution, and the coefficient M * is defined
as,	___________________________
M* = max S3 + 3] dF(yξ) - Ai 2.	(14)
ξ∈P	σi2	σ22	∂ξ	i2
4 Proof sketch and theoretical analysis
4.1 Proof sketch of our main theorem
In this section, we briefly summarize the main idea for proving the Theorem 2 and the theoretical
insight of our GSmooth. The key idea is to prove that the gradient of the smoothed classifier can be
bounded by a function of the classification confidence and the parameters of the noise distribution.
Formally, we calculate the gradient to the perturbation parameter ξ for our augmented smoothed
classifier as
__ ≈. , , ~ . . __ 一 , ≈ , ~ ...,
VrG(T(ξ,X)) = V 逑〜g⑻[f(T(θ,T(ξ,X)))].	(15)
We expand the expectation into integral and see that
.	„ -T ,	, ≈	..
%G(T(ξ,X))=	f[yξ)) g(θ)dθ.	(16)
Rn+d	∂ξ
E√"3	却"3
The key step is to eliminate the gradient of d ( "3y3)) and replace it with f "严). Then we
integrate it by parts to get the following obejective,
〜	r	〜 月〜〜〜〜
V3G(T(ξ,X)) = -	F(T(θ,y))五(M(ξ,θ)g(θ))dθ.	(17)
Rn+d	∂θ
After that, we could bound the gradient of the GSmooth classifier using the technique similar to
randomized smoothing (Yang et al., 2020). More details of the proof can be found in Appendix A.
4.2	Theoretical insight
Next, we provide the theoretical insight for our augmentation scheme on transformation parameters
and data. First, the key is to expand the transformation space by adding additional dimensions to
form a closed space. In the augmented space, the Jacobian matrix of the semantic transformation
became invertible which is crucial for our proof. Second, as we can see in Eq. (14) that M* is
influenced by two factors. One is the standard deviation of two noise distributions. The other is the
norm of the Jacobian matrix ”2%)一 Ai. It can be viewed as the residual of the non-resolvable
∂ξ	i
part of the transformation. Along this line, our method decomposes the unknown semantic transfor-
mation into a resolvable part and a residual part. The non-resolvable residual part could be handled
by introducing additional noise with standard deviation σ2 .
6
Under review as a conference paper at ICLR 2022
4.3	Error analysis for surrogate model approximation
In this subsection, we theoretically analyze the effectiveness of certifying real semantic transforma-
tion due to the existence of approximation error of surrogate neural networks.
Theorem 3. Suppose the simulation of the semantic transformation has an small enough error
,~ . , ~ ...
Ilτ(ξ,x) - T(ξ,x)k2 < ε,
Then there exists a constant ratio A = A(∣F0(ξ)∣∣2, ∣∣F2(yξ)k2, ∣∣F2(zξ)k2) > 0 does not depend
on the target classifier, we have the certified radius for the real semantic transformation satisfies
that
Rr > R(1 - Aε)
where R is the certified radius for surrogate the neural network in Theorem 2 and
1	1	∕pA 1 ,
R =2M7 Xb Φ(P) dp,
We find that the reduction of the certified radius is influenced by two factors. The first one is the
approximation error between the surrogate transformation and the real semantic transformation.
The second one the ratio A is about the norm of the Jacobian matrix for some layers of the surrogate
model which is also an inherent property of the semantic transformation itself and does not depend
on the target classifier.
5	Experiments
5.1	Experimental setup and evaluation metrics
In this section, we conduct extensive experiments to show the effectiveness of our GSmooth on
various types of semantic transformations. We use MNIST, CIFAR-10 and CIFAR-100 (Krizhevsky
et al., 2009) datasets to verify our methods. We train a resnet with 110 layers (He et al., 2016a)
from scratch. Similar to prior works, we apply moderate data augmentation (Cohen et al., 2019)
to improve the generalization of the classifier. For the surrogate image-to-image translation model
for simulating semantic transformations, we adopt the U-Net architecture (Ronneberger et al., 2015)
for H(∙) layers and several simple convolutional or linear layers for Fι(∙) and F2(∙). All models
are trained using Adam optimizer with an initial learning rate of 0.001 that decays every 50 epochs
until convergence. The algorithms for calculating M * and other details in our experiments are listed
in Appendix B due to limited space. The evaluation metric is the certified accuracy, which is the
percentage of samples that are correctly classified and has a larger certified radius than the given
range. We use IαI to indicate the preset certified radius.
5.2	Main results
To demonstrate the effectiveness of our GSmooth on certifying complex semantic transforma-
tions, we measure the certified correct accuracy for different semantic transformations on differ-
ent datasets in Table 1. We compare the results of our GSmooth with several baselines, including
randomized smoothing for some simple semantic transformation of TSS (Li et al., 2021) and Indi-
vSPT/distSPT (Fischer et al., 2020), and our GSmooth is a natural and powerful extension of their
methods. We also compare our method with the deterministic certification approaches, including
DeepG (Balunovic et al., 2019) that uses linear relaxations similar to Wong & Kolter (2018), Inter-
val (Singh et al., 2019) that is based on interval bound propagation, VeriVis (Pei et al., 2017) that
enumerates all possible outcomes for semantic transformations with finite values of parameters, and
Semanify-NN (Mohapatra et al., 2020) which uses a new preprocessing layer to turn the problem
into a `p norm certification.
We have the following observations for the experimental results. First, only our method achieves
non-zero accuracy on certifying some complex semantic transformations and the results verify our
Theorem 2. This is a breakthrough that greatly extends the boundary of randomized smoothing
based methods. Second, we see the performance of GSmooth is similar to the state-of-the-art ran-
domized smoothing approaches like TSS on several simple semantic transformations like Gaussian
7
Under review as a conference paper at ICLR 2022
							Certified Accuracy(%)				
Cert Acc(%)	Type	Dataset	Attack Range		GSmooth	TSS	DeepG	Interval	VeriVis	Semanify-	IndivSPT/
					(Ours)					NN	distSPT
		MNIST	kαk2	<6	-910^^	90.6	-	-	一	-	-
Gaussian Blur	Additive	CIFAR-10	kαk2	<4	67.4	63.6	-	-	一	-	-
		CIFAR-100			22.1	21.0	-	-	一	-	-
		MNIST	kαk2	<8	-98.7^^	99.6	0.0	0.0	98.8	98.8	99.6
Translation	Additive	CIFAR-10	kαk2	< 20	82.2	80.8	0.0	0.0	65.0	65.0	78.8
		CIFAR-100			42.2	41.3	—	—	24.2	24.2	—
		MNIST	kαk∞ < 0.5		-977^^	97.6	60.4	0.0	-	674	-
Brightness, Contrast	Resolvable	CIFAR-10	kαk∞ < 0.4		82.5	82.4	0.0	0.0	一	-	-
		CIFAR-100			42.3	41.4	0.0	0.0	一	—	—
		MNIST	kαk2	< 50°	-95.7^^	97.4	685.8	66.0	-	692.48	676
Rotation	Non-resolvable	CIFAR-10 CIFAR-100	kαk2	< 10°	64.6 33.2	70.6 36.7	62.5 0.0	20.2 0.0	—	649.37 621.7	634 618
		MNIST	kαk2	< 0.3	-95.9^^	97.2	85.0	16.4	-	-	-
Scaling	Non-resolvable	CIFAR-10 CIFAR-100	kαk2	< 0.3	54.3 31.2	58.8 37.8	0.0 0.0	0.0 0.0	— —	— —	— —
		MNIST	kαk2	< 10	-959^^	-	-	-	一	-	-
Rotational Blur	Non-resolvable	CIFAR-10	kαk2	< 10	39.7	—	—	—	一	—	—
		CIFAR-100			27.2	—	—	—	一	—	—
		MNIST	kαk2	<5	-892^^	-	-	-	一	-	-
Defocus Blur	Non-resolvable	CIFAR-10	kαk2	<5	25.0	—	—	—	一	—	—
		CIFAR-100			13.1	—	—	—	一	—	—
		MNIST	kαk2	< 0.5	-939^^	—	—	—	一	—	—
Zoom Blur	Non-resolvable	CIFAR-10	kαk2	< 0.5	44.6	—	—	—	一	—	—
		CIFAR-100			14.2	—	—	—	一	—	—
		MNIST	kαk2	< 0.5	-87.1 ^^	—	—	—	一	—	—
Pixelate	Non-resolvable	CIFAR-10	kαk2	< 0.5	45.3	—	—	—	一	—	—
		CIFAR-100			30.2	—	—	—	一	—	—
Table 1: Our main results of certification accuracy on several datasets and multiple types of semantic
transformations. - or 0.0% means the method fails to certify this type of semantic transformation.
Figure 2: Results of ablation experiments on the influence of smoothing distribution for zoomed
blur on CIFAR-10 dataset. The horizontal axis kαk2 is the certified raidus.
blur, translation. This is a natural result since our method works similarly for resolvable transfor-
mations. For two specific non-resolvable transformations, i.e. rotation and scaling, our accuracy
is slightly lower. The possible reason is that in TSS (Li et al., 2021) they derive more elaborate
Lipschitz bound for rotation which is better than us. Third, those inherently non-resolvable transfor-
mations like image blurring (except Gaussian blur) and pixelate are more difficult than resolvable or
approximately resolvable (rotation) transformations. Thus their certified accuracy is also lower.
5.3	Ablation study
Ablation study on the influence of noise distribution. The choice of noise distribution is important
for randomized smoothing based methods. Since our GSmooth could certify different types of
semantic transformations that exhibit different properties. Understanding the influence of different
smoothing distributions for different semantic transformations is necessary. We choose (folded)
Gaussian, uniform, and exponential distribution and compare the certified accuracy on zoom blur
transformation for both CIFAR-10 and CIFAR-100 datasets. As shown in Fig. 2, We found that
8
Under review as a conference paper at ICLR 2022
Cert Acc		CIFAR-10							CIFAR-100					
	"∖^σ2 b]ʌ^	0.05	0.10	0.15	0.25	∖^σ2 b]ʌ^	0.05	0.10	0.15	0.20
Rotational Blur	0.1	44.3	46.4	35.5	16.1	0.1	23.1	26.2	17.2	10.4
	0.25	45.7	47.1	38.3	18.9	0.25	23.2	27.2	20.3	11.3
	0.5	46.5	48.4	38.8	18.3	0.5	22.2	26.1	18.6	11.8
	0.75	42.1	45.5	36.6	17.0	0.75	24.0	25.5	18.3	13.2
Table 2: Results of ablation study on the influence of standard deviation of smoothing distributions,
i.e. transformation noise σ1 and augmented noise σ2 for certification accuracy on rotational blur.
Figure 3: Visualization of difference between the augmented noise in the semantic layers and the
noise on raw images. Left: original images from CIFAR-10. Middle: images with augmented noise
of σ2 = 0.2. Right: images with additive Gaussian noise σ = 0.2.
the impact of smoothing distributions depends on datasets. Uniform distribution is better for small
radius certification while exponential distribution is more suitable for certifying large radius on
average.
Ablation study on the influence of noise variance for certification. Since our GSmooth contains
two different variances for controlling the resolvable part and the residual part for a non-resolvable
semantic transformation. Here we investigate the effect of different noise variance on the certified
accuracy. The results are shown in Table 2. We found that using medium transformation noise and
augmented noise achieves the best certified accuracy. The fact is consistent with results in (Cohen
et al., 2019). An explanation is that there is a trade-off since higher the noise variance decreases the
coefficient M* but it might also degrade the clean accuracy.
Visulization experiments: comparsion between augmented semantic noise and image noise.
Our GSmooth needs to add a new noise in the semantic layers of the surrogate model. Here we
compare the difference between these two types of noise and visualize them. We random sample
images from CIFAR-10 and add gaussian noise with σ = 0.2 to both the semantic layer of the
surrogate model simulating zoomed blur transformation and raw images. Results are shown in Fig.
3. Both two types of noise severely blur the images. But we found that the augmented semantic
noise is more placid which can therefore keep the holistic semantic features better, e.g., shapes.
6	Conclusions
In this paper, we proposed a generalized randomized smoothing framework (GSmooth) for certifying
robustness against general semantic transformations. We proposed a novel idea that using a surrogate
neural network to fit semantic transformations. Then we prove tight certified robustness bound for
the surrogate model and use it for certifying semantic transformations. Extensive experiments verify
the effectiveness of our method and we achieved state-of-the-art performance on various types of
semantic transformations. In the future, we plan to extend our method to real-world scenarios on
more diverse semantic transformations.
9
Under review as a conference paper at ICLR 2022
7	Reproducibility statement
We ensure the reproducibility of our paper from three aspects. (1) Experiment: The implementation
of our experiment is described in Sec. 5.1. Ablation study for our experiments is in Sec. 5.3. Further
details are in Appendix B. (2) Code: Our code is included in supplementary materials. (3) Theory
and Method: A complete proof of the theoretical results described is provided in Appendix A.
8	Ethics statement
Machine learning models are easily attacked by adversarial examples and semantic transformations.
Thus it is fundamental problem to develop certified robust machine learning methods. This paper
proposed GSmooth to certify against semantic transformations. It may promote the development of
safe and reliable machine learning models in the future.
References
Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of se-
curity: Circumventing defenses to adversarial examples. In International Conference on Machine
Learning (ICML), pp. 274-283, 2018.
Mislav Balunovic, Maximilian Baader, Gagandeep Singh, Timon Gehr, and Martin Vechev. Certify-
ing geometric robustness of neural networks. Advances in Neural Information Processing Systems
32, 2019.
Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Pavel Laskov, Giorgio Giacinto, and
Fabio Roli. Evasion attacks against machine learning at test time. In Joint European Conference
on Machine Learning and Knowledge Discovery in Databases, pp. 387-402, 2013.
Tom B Brown, Dandelion Mane, AUrko Roy, Martin Abadi, and Justin Gilmer. Adversarial patch.
arXiv preprint arXiv:1712.09665, 2017.
Dan A Calian, Florian Stimberg, Olivia Wiles, Sylvestre-Alvise Rebuffi, Andras Gyorgy, Timothy
Mann, and Sven Gowal. Defending against image corruptions through adversarial augmentations.
arXiv preprint arXiv:2104.01086, 2021.
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified adversarial robustness via randomized
smoothing. In International Conference on Machine Learning, pp. 1310-1320. PMLR, 2019.
Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. Autoaugment:
Learning augmentation strategies from data. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 113-123, 2019.
FoiVos I Diakogiannis, Francois Waldner, Peter Caccetta, and Chen Wu. Resunet-a: A deep learning
framework for semantic segmentation of remotely sensed data. ISPRS Journal of Photogrammetry
and Remote Sensing, 162:94-114, 2020.
Logan Engstrom, Brandon Tran, Dimitris Tsipras, Ludwig Schmidt, and Aleksander Madry. A
rotation and a translation suffice: Fooling cnns with simple transformations. 2018.
Logan Engstrom, Brandon Tran, Dimitris Tsipras, Ludwig Schmidt, and Aleksander Madry. Ex-
ploring the landscape of spatial robustness. In International Conference on Machine Learning,
pp. 1802-1811. PMLR, 2019.
Marc Fischer, Maximilian Baader, and Martin Vechev. Certified defense to image transformations
via randomized smoothing. arXiv preprint arXiv:2002.12463, 2020.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014.
Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan Ue-
sato, Relja Arandjelovic, Timothy Mann, and Pushmeet Kohli. On the effectiveness of interval
bound propagation for training verifiably robust models. arXiv preprint arXiv:1810.12715, 2018.
10
Under review as a conference paper at ICLR 2022
Jamie Hayes. Extensions and limitations of randomized smoothing for robustness guarantees. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Work-
Shops,pp. 786-787, 2020.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016a.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual
networks. In European conference on computer vision, pp. 630-645. Springer, 2016b.
Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common cor-
ruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019.
Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshmi-
narayanan. Augmix: A simple data processing method to improve robustness and uncertainty.
arXiv preprint arXiv:1912.02781, 2019.
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul
Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robustness: A critical
analysis of out-of-distribution generalization. arXiv preprint arXiv:2006.16241, 2020.
Pengfei Jing, Qiyi Tang, Yuefeng Du, Lei Xue, Xiapu Luo, Ting Wang, Sen Nie, and Shi Wu. Too
good to be safe: Tricking lane detection in autonomous driving with crafted perturbations. In 30th
{USENIX} Security Symposium ({USENIX} Security 21), 2021.
Alex Krizhevsky et al. Learning multiple layers of features from tiny images. 2009.
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436-444,
2015.
Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified
robustness to adversarial examples with differential privacy. In 2019 IEEE Symposium on Security
and Privacy (SP), pp. 656-672. IEEE, 2019.
Linyi Li, Maurice Weber, Xiaojun Xu, Luka Rimanic, Bhavya Kailkhura, Tao Xie, Ce Zhang, and
Bo Li. Tss: Transformation-specific smoothing for robustness certification, 2021.
Bee Lim, Sanghyun Son, Heewon Kim, Seungjun Nah, and Kyoung Mu Lee. Enhanced deep resid-
ual networks for single image super-resolution. In Proceedings of the IEEE conference on com-
puter vision and pattern recognition workshops, pp. 136-144, 2017.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083,
2017.
Jeet Mohapatra, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, and Luca Daniel. Towards verifying
robustness of neural networks against a family of semantic perturbations. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 244-252, 2020.
Kexin Pei, Yinzhi Cao, Junfeng Yang, and Suman Jana. Towards practical verification of machine
learning: The case of computer vision systems. arXiv preprint arXiv:1712.01785, 2017.
Alexander Robey, Hamed Hassani, and George J Pappas. Model-based robust deep learning: Gen-
eralizing to natural, out-of-distribution data. arXiv preprint arXiv:2005.10247, 2020.
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedi-
cal image segmentation. In International Conference on Medical image computing and computer-
assisted intervention, pp. 234-241. Springer, 2015.
Hadi Salman, Greg Yang, Jerry Li, Pengchuan Zhang, Huan Zhang, Ilya Razenshteyn, and Sebastien
Bubeck. Provably robust deep learning via adversarially trained smoothed classifiers. arXiv
preprint arXiv:1906.04584, 2019.
11
Under review as a conference paper at ICLR 2022
GagandeeP Singh, Timon Gehr, Markus PuscheL and Martin Vechev. An abstract domain for cer-
tifying neural networks. Proceedings of the ACM on Programming Languages, 3(POPL):1-30,
2019.
Dawn Song, Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir Rahmati, Florian
Tramer, Atul Prakash, and Tadayoshi Kohno. Physical adversarial examPles for object detectors.
In 12th {USENIX} Workshop on Offensive Technologies ({WOOT} 18), 2018.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing ProPerties of neural networks. arXiv preprint arXiv:1312.6199, 2013.
Florian Tramer, Nicholas Carlini, Wieland Brendel, and Aleksander Madry. On adaPtive attacks to
adversarial examPle defenses. Advances in Neural Information Processing Systems, 33, 2020.
Yulin Wang, Xuran Pan, Shiji Song, Hong Zhang, Gao Huang, and Cheng Wu. ImPlicit semantic
data augmentation for deeP networks. Advances in Neural Information Processing Systems, 32:
12635-12644, 2019.
Eric Wong and Zico Kolter. Provable defenses against adversarial examPles via the convex outer
adversarial PolytoPe. In International Conference on Machine Learning, PP. 5286-5295. PMLR,
2018.
Yuxin Wu and Kaiming He. GrouP normalization. In Proceedings of the European conference on
computer vision (ECCV), PP. 3-19, 2018.
Chaowei Xiao, Jun-Yan Zhu, Bo Li, Warren He, Mingyan Liu, and Dawn Song. SPatially trans-
formed adversarial examPles. arXiv preprint arXiv:1801.02612, 2018.
Greg Yang, Tony Duan, J Edward Hu, Hadi Salman, Ilya Razenshteyn, and Jerry Li. Randomized
smoothing of all shaPes and sizes. In International Conference on Machine Learning, PP. 10693-
10705. PMLR, 2020.
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan.
Theoretically PrinciPled trade-off between robustness and accuracy. In International Conference
on Machine Learning, PP. 7472-7482. PMLR, 2019a.
Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth, Bo Li, Duane Boning,
and Cho-Jui Hsieh. Towards stable and efficient training of verifiably robust neural networks.
arXiv preprint arXiv:1906.06316, 2019b.
Jun-Yan Zhu, Taesung Park, PhilliP Isola, and Alexei A Efros. UnPaired image-to-image translation
using cycle-consistent adversarial networks. In Proceedings of the IEEE international conference
on computer vision, PP. 2223-2232, 2017.
12
Under review as a conference paper at ICLR 2022
A Proof of Theorems
In this section, we will provide detailed proofs of theorems in our paper.
First, we restate the theorem of randomized smoothing for additive noise and binary classifiers
f(∙): Rn → [0,1],
G(X)= Eθ 〜g [f (x + θ)]	(18)
Theorem 4. Let f(x) be any classifier and G(x) be the smoothed classifier defined in Eq. (18), if
G(X) < 2 ,then G(X + δ) < 1 for any
1
kδk <L, Φ(P)dp
(19)
where Φ(∙) is a function about smoothing distribution defined in Eq. (2).
Proof. We first calculate the gradient of the smoothed classifier
VG(x)
∂
TT f f(x + θ)g(θ)dθ
∂X Rn
d ɪf (x + θ)g(θ)dθ
Rn∂ X
∂
而 f(x + θ)g(θ)dθ
Rn∂ θ
Then we multiple any vector with unit norm u ∈ Bn(1) = {u : kuk= 1, u ∈ Rn},
|hVG(X), ui|
IoRn •(X + Mm"”
|/n(/ A' + θ)Q Md"
X Z	uig(")d"
I i	Rn∂	"i	I
x LI Or-uig(θ …
-X ZRn-I (/[ f(X + θ)ui W dθi)γ dθj
X ZjX+θ) 愣 uidθ
II	f (X + ")hVg("), uid"II
I Rn	I
II	f (X + ")g(")hVψ("), uid"II
I Rn	I
∣Eθ 〜g [f (x + θ)hVψ(θ),ui]∣
To bound the gradient of the smoothed classifier, we use the following inequality,
KVG(X),u)| 6 sup	Eθ〜g [/(X + θ)hψ(θ),u>]
b:G(X) = G(X)	L	」
As shown in Yang et al. (2020), the optimal f(X) achieves at,
^(x + θ) = J 1, ifhu,ψ(θ)i > 3-1(G(X))
0, else
(20)
(21)
(22)
13
Under review as a conference paper at ICLR 2022
Then,
Eθ〜g [/(X + θ)hu, ψ(θ)ii = E [YuI{Yu > 3-1(G(X))H
6 Φ(G(x))	(23)
which means that,
∣hVG(χ),ui∣ 6 Φ(G(x))	(24)
and this is true for all u ∈ Bn(1), so we have,
max hVG(X), ui 6 Φ(G(X))	(25)
Consider a path from ξt : [0, ∣∣δ∣∣] → Rd with ξo = X and ξ∣∣δk = X + δ and ξ0 =4,We have
dG(ξt)
dt
hVG(ξt),ui 6 Φ(G(ξt)).
(26)
If the norm of δ satisfies that,
2 ι
kδk<4(x) Φ(P)dp,
(27)
1
if right hand side exists, We name it k δ0 k = /G(/)1 /Φ(p)dp. Without loss of generality, We assume
that G(ξt) is increasing in t, then we CoUnd calculate the minimal twhen G(ξt) increase to ɪ,
1
T=k) Φ(P)dp=kδok.
(28)
By the generality of δ we have,
for any δ < kδ0k.
G(X + δ) < 2
(29)
□
This theorem is naturally extended to problems with p > 2 classes by considering the two top classes
which are G(X)A and G(X)B. This turns the problem into a binary classification problem.
A.1 The Proof of Theorem 1
Theorem 1. Let f (X) be any classifier and G(X) be the smoothed classifier defined in Eq. (1), if
there exists afunction M(∙), and the transformation T(∙, ∙) satisfies that
∂γ(θ,ξ)
∂ξ
中 M (θ,ξ),
∂θ
and there exists two constants PA , PB that satisfies that
G(X)A > PA > PB > G(x)b,
then yA = arg maxi∈Y G(τ(ξ, X))i holds for any kξk 6 R where
C 1	p— 1	,
R = 2M7 JU 砌 dp,
(30)
here M* = mαXξ,θ∖∖M(ξ,θ)∣∣.
14
Under review as a conference paper at ICLR 2022
Proof. WLOG, We only prove it for binary cases that f (∙) : Rn → [0,1].
Vξ G(T (γ(θ,ξ),x))
∂ df (T(Y(θ, ξ),x)) dτ(Y(θ, ξ),x)
=J	∂τ (γ(θ,ξ),x)-----∂ξ—g(θ)dθ
=I' df (T(YGdx)) dτ(YGdx) dY(θ,ξ (θ)dθ
=J ∂τ(γ(θ,ξ),x) ∙	∂γ(θ,ξ)	∂ξ g( )	(31)
/ ∂f(τ(γ(θ, ξ), x)) d(γ(θ, ξ), x) dγ(θ, ξ) M
=J ∂τ(γ(θ,ξ),x)	∙ -Id^--IdrM(θ,ξ)g(θ)dθ
=Z df(τ(γ(θ,ξ),X)) M(θ,ξ)g(θ)dθ
∂θ
For u ∈ Rd and kuk = 1, We have:
∣(VξG(γ(ξ,x)),ui∣ =	Z "('f X))M(θ,ξ)ug(θ)dθ	(32)
∂ θ
6 M* max Z df (TSyX)) vg(θ)dθ	(33)
kvk = 1 J	∂θ	…	7
6 M* max I f (τ(γ(θ,ξ),x))dg(θ)-vdθ	(34)
kvk=1	∂θ
(35)
here M* = maxθ,ξ kM (θ, ξ)k and We assume that g(θ) = exp(-ψ(θ)):
lhvξ G(Y(SX)),uil 6
M* max
kvk=1
M* max
kvk=1
KT (YGξ),X))鬻 vdθ
f(T(Y(θ, ξ), X))g(θ)Vψ(θ)vdθ
M 'max[”[f(T S),X))hvψ(θ),vi]1
(36)
(37)
(38)
_ _ ,	一 . O ,	.......	.,
M ImaX	SUp	Eθ 〜g [f(T (y (θ, ξ),X))hΨ(θ),ui] (39)
kvk = 1 f：G(T (ξ,x)) = G(τ (ξ,x))
Similar with Theorem 4, the optimal f achieves at
f(T(Y(θ,ξ),X)) = {0fψ(θ),ui >"(G(T(ξ,X))))
(40)
Then We have
lhvξG(T(SX)),uil 6 φ(G(τ(ξ,X))).
(41)
Consider a path from Zt : [0, kδ∣∣] → Rd with Z0 = X and《卜别=T(ξ, x) and Z0 =4,We have
dGdtξ^ = hVG(ξt),ui 6 Φ(G(ξt)).
(42)
The last part of proof is the same with Theorem 4.
A.2 The proof of Theorem 2
Theorem 2. Suppose f (x) is any classifier and G(x) is the smoothed classifier defined in Eq. (7),
ifthere exists PA , PB that satisfies that
G(X)A > PA > PB > G(x)B,
/
Z
6
□
15
Under review as a conference paper at ICLR 2022
then yA = argmaXieY G(T(ξ,x))i forany ∣∣ξ∣∣2 6 R where
C 1 尸 1	,
R =斫 Xb 砌 dp,
(43)
and the coefficient M* is defined as
M *
max J1 + U dF2(yξ)	dFι(θ)
ξ,θ∈p V + U ∂ξ	∂θ
2
2
(44)
Proof. In this part, we will prove Theorem 2, which is the main result in this paper. WLOG, we
prove it for binary cases where f (∙) : Rn → [0,1]. First, we Will calculate the gradient of G(τ(ξ, x))
to S
__ ≈. , , ~ . . __ 一 , ≈ , ~ ...,
VgG(T(ξ,X)) = Vξ⅜∕(θ)[f(T(θ,T(ξ,X)))].	(45)
We expand the expectation into integral and use chain rule to see that
. . .~ .. . . .
∂f (T(θ,yξ)) ∂T(θ,yξ) ∂yξ θ θ
人…iT⅛^ ∙ ^首∙灰g⑻
(46)
fl^ia	fl^ia
The key step is to eliminate the gradient of df工 哄)and replace it with df( ∖萨))
Jr	0	∂τ(θ,yξ)	r	∂θ
. Since:
, .~ .
∂T(θ,y)
∂yξ
〜
∂ξ
σ1 (zθ)
K (zξ)
F2ι(yξ)
σ2(zθ)
H2 (zξ )
Id
K (ξ)
F22(y)J ,
In .
(47)
(48)
该
We have:
〜
〜
VrG(T(ξ, X))
∂F(T ”))
./Rn+d	∂T (θ,yξ)
回&)	]
[	H2 (zξ)]
/ ∂F (T(θ,y))
JRn+d	∂T (θ, yξ)
司(奖)
F22
/
jn++d
H (zθ)
Id
F(ξ)	In
,田1 (zθ)
W (zξ)
∂F(T(θ,y))
,〜
∂θ
H2 (zθ)
.~. 〜
g(θ)dθ
H2 (zθ)
H2 (zξ )
Id
F1 (θ)
Id
F1(ξ)
In	-F(θ)
In g(θ )dθ
(49)
In
(50)
H0(zξ)
√Rn+d
Id
-F1 (θ)
Id
/ [F2ι(yξ)
f22 (%)
H2 (zξ)J [F1 (ξ)	In
-~ . . .,
∂F(T(θ,y))
,〜
∂θ
.~. 〜
g(θ)dθ
(51)
~ .〜〜、 ，〜、 ~
M(ξ,θ)g(θ)dθ,
(52)
~
here we define
M(ξ, θ)，
Id
-F0 (θ)	In
Id
F0 (ξ)
(53)
We consider the Unit enlargement, which means:
16
Under review as a conference paper at ICLR 2022
Hι(z0) = Z, F21(X) = X
(54)
thus:
M (ξ,θ)= [f⅛ ) - K (θ)
Od×n
F22(yξ )H2(zξ)
(55)
Since θ0 is the virtual parameter introduced, which can be taken as 0 in case of actual disturbance.
Thus we only need to consider the projection of ▽百小(四)in the space of ξ. Thus we set
here U ∈ Rd and ∣∣u∣∣ = 1. Assume
g(θ) = exp(-ψ(θ))	(57)
^^(a∖
ɪ = -g(θ) ∙vψ(θ).	(58)
∂θ
And we have
. ~ , . .
"2(配),U)
6
/
J~n++d
_ ~, , ~ ..
∂f(τ(θ,y)
_ ~
∂θ
M(ξ, θ)Ug(θ)dθ
_ ~, , ~ _
∂	∂f (T(θ,yξ))	Id,
‘Ed —∂θ —忸22(yξ)-好(θ),
Od×n
θn×n
,~, _ ~
Ug(θ )dθ
f (T(力我”M (ξ,θ)Ug(θ)dθ
√Rn+d	∂θ
八6 I ∂ ∂f(T(θ,yξ))~ 〃 A
M max	-------≈---Vg (θ)dθ
∣∣vk2 = l I √Rn+d	∂θ
M * max
kvk2=1
M * max
kvk2=1
f (T(θ, yξ))-gOVdθ
√Rn+d	∂θ
/
√Rn+d
f (T(θ,yξ ))g(θ)vψ(θ)v dθ
M * max ∣ Eθ〜g
IIvk2=11
f (T (θ,T (ξ,x)))hvψ(θ ),V “I
(59)
(60)
(61)
(62)
(63)
(64)
(65)
~ ~ ~ ~ ~ ~
We bound the right hand side by
IhVG(yξ),u>∣6	sup M IImaX 回〜g f (τ(θ,τ(ξ, x)))(V≠ (θ ),v i H	(66)
1	1	bG(τ (ξ,x))=G(τ (ξ,χ))	Ivk2=1 IL	J∣
1 . 1	. ∙	1	； ♦	i' 11
and the optimal f is as follows,
f(T(θ,T(ξ,X)) = 1 1, Ifhψ (θ)，U〉> K (G(T(ξ, X))))
J' L 0 〃 I 0,else
(67)
here
M(ξ, θ)=
Id,
F*3) - F1 (θ),
Od×n
θn×n
(68)
17
Under review as a conference paper at ICLR 2022
and M * is
M * = max
ξ,θ∈P
max
ξ,θ∈P
1d,	θd×n
My ) - F (θ), OnXn
一	Id	]
∂F22(yξ) _ ∂F1(θ)
.∂ξ - ∂θ 2 2
(69)
max
ξ,θ∈P
∂ξ
∂F22(yξ) _ ∂F1(θ)Ml2
∂θ川2
Notice that here F22(∙) is the same as F2(∙) the notations in the main text. Then we could apply the
techniques used in Theorem 1 and Theorem 4, we have:
(70)
Thus we have proven this Theorem.
A.3 THE Proof OF Theorem 3
Theorem 3. Suppose the SimUIatiOn ofthe semantic transformation has an small enough error
,~ . , ~ ...
I∣τ(ξ, X)- τ(ξ, X)k <ε,
Then there exists a constant ratio A = A(∣∣Fj(ξ)∣∣, ∣∣F2(yξ)k, ∣∣F2(zξ)∣∣) > 0 does not depend on
the target classifier, we have the certified radiusfor the real semantic transformation satisfies that
Rr > R(1 — Aε)
where R is the certified radiusfor SUrrOgate the neural network in Theorem 2 and
Proof. We set
U
U=I OnXI
(71)
here U ∈ Rd and ∣∣u∣∣ = 1. Then we have
(vfG (T(ξ,X))
—
- . . . ... _ . . . ...
∂f(T(θ,T(ξ,X)))	∂f(τ(θ,τ(ξ,x)))
∂ξ
∂ξ
Ug (θ)dθ
∂ξ∂τ
Ug (θ )dθ
(72)
C 1 fpA 1	,
R=斫 JU 砌dp,
C 1 尸 1	,
R =斫 Xb 砌dp.
〜
〜
〜
〜
〜
〜


—


〜
〜
□
〜
Set L = d2f(TC(ξ’X))), We have
∂ξ∂τ
∂f (T(θ,T(ξ,X)))∖ = ∂	∂f (τ(θ,τ(ξ,x ))) ∂τ(θ,T(ξ,X))
∂τ ) ∂ξ	∂τ(θ,τ(ξ,X))	∂τ
Set y& = τ(θ,τ(ξ, x)), we have:
18
Under review as a conference paper at ICLR 2022
- ，〜 ，〜 ..
∂T(θ,T(ξ,x))
,~ , ~ , ~. ~ . ~ ...
∂H(F1(θ) + F2(T(ξ㈤))
∂τ
∂T
(Fi(θ) + F2(T(ξ,X))
(Fi(θ) + F2(T(ξ,X))
∂F2(T(ξ,X))
∂T
Id
Id
F (θ)	In	-F0(θ)
In
∂F2(T(ξ,X))
∂T
(74)
here Ai
. .~ . ~ ..
∂T (θ,T(ξ,x))
,~
∂θ
. .~ . ~ ..
∂T (θ,T(ξ,x))
,~
∂θ
-Fd(θ) In F2Z(T/x))
Ai
Id
-FiZ(θ)	In
AZ(TG X)). By the proof above, we have 靠=磊A2, thus we have:
ɪ炎色~加
==
∂f(T(θ,T(ξ,X))) ∂T(θ,T(ξ,X))
. .~ . ~ ..
∂T(θ,T(ξ,x))
~ . . ~ . ~ .,
∂T
- . . . ... _ . . .,
∂f(T(θ,T(ξ,X))) ∂T(θ,T(ξ㈤)
I .	. ~	. ~	..
∂T(θ,T(ξ,x))
∂ ∕∂f(T(θ,T(ξ,x)))
,~
∂θ
A1 a2
(75)
,~
∂θ
,~
∂θ
Ai	A2.
H0
H0
~ . . ~ . ~
〜 .〜
〜 .〜
□
(vfG(T(ξ,X)) -VfG (T(ξ,X)),U)
C ~ .	. ~	. ~	...
∂ 2f(T(θ,T(ξ,x)))
-〜-
∂ξ∂T
,~ . . ~ . ~
Wg (θ )dθ
43)得色(TGT(M))
,~
∂θ
1.	, ≈. J
A2Ug(θ)dθ
(76)
6Ae ∙ | y f (T(θ,T(ξ,X)))9 (θ)"ψ (θ),Ui dθ |,
1	^Λ •	,	,	1	1 ∙	II T^l∕ / 工、1 1 II T^l∕ / ~ ∖ II II T^l / / ~ ∖ II El	∙	. A 1	1
where A is a constant depending on ∣∣Fi(ξ) 11,11F2(y ξ) 11,11F2(zξ) ∣∣. Then there exists A and we have
Rr > R(1 - eA),
where
C	1 fρA 1 j
R = 2M* JU 晒 d
B Implementation details and experimental settings
B.1	PRACTICAL ALGORITHMS FOR CALCULATING M*
For resolvable transformations in Theorem 1, the M * is defined as
M* = m∈p ∣∣M(ξ,θ)∣∣.
(77)
(78)
Since if we have verified that the semantic transformation is resolvable, most of time we have a
closed form of M* like contrast/brightness transformation and we are able to calculate it analytically
as shown in Li et al. (2021).
19
Under review as a conference paper at ICLR 2022
For non-resolvable transformations in Corollary 1, M * is defined as
M *
max
ξ∈P
占+"I修
σ12	σ22	∂ξ
- A1
(79)
2
2
This ratio is similar with the Lipschitz bound for a semantic transformation inLietal. (2021).For low
dimensional semantic transformations, we are able to interpolate the domain to find a maximum M *
and corresponding ξ. But this remains a challenge for high dimensional semantic transformations.
Specifically, for a given ξ, We need to compute the norm of dF∂ξyξ) - Aι∙ The JacObian matrix is
n × n. Caculating it requires n times of backpropagation. Thus it is inefficient to store the matrix or
directly compute its norm. To solve the problem, We noitice that
And then We have
Il ∂F2(yξ)
- A1
2
2
∂F2(y)
∂ξ
(80)
(dFdy) - AI) U = ∂ξ hF2y)-Aι,ui
(81)
Since tranposing a matrix does not change its norm, We could calculate its norm by optimizing u
that,
I∂
kmaXi ∂ξhF2做)-Ai，ui
(82)
Using this formulation, We only need to multiply the output With an unit vector and perform one
backpropagation. This is a simple convex optimization problem. Then We could use any iterative
algorithm to find its solution Which is very fast to compute. This trick is crucial and it makes the
matrix norm computation to be scalable in practice.
B.2	Other details for experiments.
Our GSmooth requires to train tWo neural netWorks. First We randomly generate corrupted images
to train a image-to-image neural netWork. The training process of classifiers and certification for
semantic transformations are done on 2080Ti GPUs. We use a U-Net (Ronneberger et al., 2015) for
the surrogate model and replace all BatchNorm layers With GroupNorm (Wu & He, 2018) since We
might use the model in loW bacthsize settings. The U-Net could be replace by other netWorks used
in image segmentation or superresolution like Res-UNet (Diakogiannis et al., 2020) or EDSR (Lim
et al., 2017). We use L1-loss to train the surrogate model Which achieves better accuracy than others
Which is also reported (Lim et al., 2017).
After train a surrogate model to simulate the semantic transformation. Then We train the base clas-
sifier for certification With a moderate data augmentation like (Li et al., 2021; Cohen et al., 2019) to
ensure that training and testing of the classifier is performed on the same distribution. There are tWo
types of data augmentation, one is the semantic transformation and the other is the augmented noise
introduced only in our Work. Data augmentation based semantic transformation could be done using
both the surrogate model or the raW semantic transformation. We can only use the surrogate model
to add the augmented noise because this noise is a type of semantic noise in the layers of surrogate
model. In our experiments the standard deviation of the augmented noise is chosen from 0.1 〜0.4
depending on the performance. The basic netWork architectures for these datasets are kept the same
With (Li et al., 2021). On CIFAR-100 daatsets, We use a PreResNet (He et al., 2016b) re-implement
the method by Li et al. (2021). We also adopt the progressive sampling trick mentioned in TSS (Li
et al., 2021) Which is useful to reduce computational cost and certify larger radius. The details could
also be found in Li et al. (2021).
C S upplementary Experiments
In this section, We report the results of our GSmooth under adaptive attacks to verify the tightness
of our certified bound. The experiments are conducted on CIFAR-10 dataset. We use expectation
of transformation to calculate the gradient of the model. Then We apply projected gradient descent
20
Under review as a conference paper at ICLR 2022
	Cert Acc(%)	EoT attacks(%)
Gaussian blur	^674	68.1
Tanslation	82.2	87.5
Rotation	64.6	68.4
Rotational blur	39.7	45.0
Defocus blur	25.0	25.0
Pixelate	45.3		49.2
Table 3: Accuracy of our GSmooth under adaptive attacks (PGD using expectation over transforma-
tions) on CIFAR-10 dataset.
Type/Acc(%)	AUgmix	TSS	OUrs
Zoom blur	ɪs	75.2	77.1
Defocus blur	7221	75.6	76.8
Pixelate	^0.9	76.0	76.7
Brightness	-8Σ4	71.8	72.1
Motion blur	^686	70.2	70.5
Gaussian blur	67.4	75.8	75.2
Table 4: Empirical accuracy on subsets of CIFAR-10-C.
to find adversarial examples until it converged. Then we report the accuracy of our model on the
corrupted dataset. The result is listed in the following table. We found that the empirical attack is
no less than the certified accuracy. This shows that the bound for our model is effective. Additional,
some empirical results are much higher than the certified accuracy, which might indicate the bound
still has space for improvement.
We have conducted some experiments under the common benchmark CIFAR-10-C to show the
empirical robustness under these corruptions. We conducted the experiments on some subsets of
CIFAR-10-C. The corruption types of these subsets are related to the experiments in our paper. The
settings of these experiments and the results of baselines are from TSS(Li et al 2021).
21