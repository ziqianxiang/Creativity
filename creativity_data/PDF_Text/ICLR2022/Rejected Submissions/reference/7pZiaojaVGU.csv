title,year,conference
 A little is enough: Circumventing defenses fordistributed learning,2019, In H
 Best response regression,2017, In I
 Poisoning attacks against support vector ma-chines,2012, In Proceedings of the 29th International Conference on Machine Learning
 Machinelearning with adversaries: Byzantine tolerant gradient descent,2017, In Isabelle Guyon
 Collaborative PAC learning,2017, InIsabelle Guyon
 Language models are few-shotlearners,2020, In Hugo Larochelle
 A backdoor attack against lstm-based text classifi-cation systems,2019, IEEE Access
 Personalized federated learning withmoreau envelopes,2020, In Hugo Larochelle
 Genuinely distributed byzantine machine learning,2020, In Yuval Emek and ChristianCachin (eds
 Distributed momentum forbyzantine-resilient stochastic gradient descent,2021, In 9th International Conference on LearningRepresentations
 Personalized federated learn-ing with theoretical guarantees: A model-agnostic meta-learning approach,2020, In HugoLarochelle
 Switch transformers: Scaling to trillion param-eter models with simple and efficient sparsity,2021, CoRR
 Witches’ brew: Industrial scale data poisoning via gradient matching,2021, InInternational Conference on Learning Representations
 Science communication desperately needs more aligned recommendation algo-rithms,2020, Frontiers in Communication
 Matrix Analysis,2012, Cambridge University Press
 Metapoi-son:	Practical general-purpose clean-label data poisoning,2020, In Hugo Larochelle
 Slateq: A tractable decomposition for reinforcementlearning with recommendation sets,2019, In Sarit Kraus (ed
 A general method for robust learning from batches,2020, InHugo Larochelle
 Federated optimization: Distributed op-timization beyond the datacenter,2015, CoRR
 Adversarial machine learning-industry per-spectives,2020, In 2020 IEEE Security and Privacy Workshops
 Data poisoning attacksin multi-party learning,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 On the reconstruction of face imagesfrom deep face templates,2019, IEEE Trans
 The radicalization risks of GPT-3 and advanced neural languagemodels,2020, CoRR
 Algorithms for strategyproof classifi-cation,0004, Artificial Intelligence
 The hidden vulnerability of dis-tributed learning in byzantium,2018, In Jennifer G
 Towards poisoning of deep learning algorithms with back-gradientoptimization,2017, In Bhavani M
 Improved algorithms for collaborative PAC learning,2018, InSamy Bengio
 Do outliers ruin collaboration? In Jennifer G,2018, Dy and Andreas Krause (eds
 Explanation-guided backdoor poi-soning attacks against malware classifiers,2021, In Michael Bailey and Rachel Greenstadt (eds
 Back to the drawingboard: A critical evaluation of poisoning attacks on federated learning,2021, CoRR
 From eliza to xiaoice: challenges and opportunitieswith social chatbots,2018, Frontiers Inf
 Youtube’s ai is the puppet master over most of what you watch,2018, CNET
 Model-targeted poi-soning attacks with provable convergence,2021, In Marina Meila and Tong Zhang (eds
 A theory of the learnable,1984, Commun
 High-Dimensional Statistics: A Non-Asymptotic Viewpoint,2019, Cambridge Seriesin Statistical and Probabilistic Mathematics
 Superglue: A stickier benchmark for general-purposelanguage understanding systems,2019, In Hanna M
 Fall of empires: Breaking byzantine-tolerantSGD by inner product manipulation,2019, In Amir Globerson and Ricardo Silva (eds
 Visualizing and understanding convolutional networks,2014, InDavid J
 Define X based on Lemma 18,2022, Since LOSS1 is locally strongly convex
