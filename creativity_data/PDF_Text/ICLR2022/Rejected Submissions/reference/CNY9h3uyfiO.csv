title,year,conference
 An optimistic perspective on offlinereinforcement learning,2020, In Intemational COnference on Machine Learning
 Solving rubikâ€™s cube with arobot hand,2019, arXiv Preprint arXiv:1910
 Dota 2 with largescale deep reinforcement learning,2019, arXiv Preprint arXiv:1912
 Conservative safety critics for exploration,2020, arXiv Preprint arXiv:2010
 R-max-a general polynomial time algorithm for near-optimal reinforcement learning,2002, JOurnaI OfMaChine Learning ReSearch
 Exploration by random networkdistillation,2018, arXiv PrePrint arXiv:1810
 Better exploration with optimisticactor critic,2019, In AdVanCeS in NeUraI InfOrmatiOn PrOCeSSing Systems
 Phasic policy gradient,2021, InInternational COnferenCe on MaChine Learning
 Go-explore: anew approach for hard-exploration problems,2019, arXiv PrePrint arXiv:1901
 Ltlf-based rewardshaping for reinforcement learning,2021, In AdaPtiVe and Learning AgentS WOrkShOP 2021
 Diversity is all you need:Learning skills without a reward function,2018, arXiv PrePrint arXiv:1802
 D4rl: Datasets for deepdata-driven reinforcement learning,2020, arXiv PrePrint arXiv:2004
 Off-policy deep reinforcement learning withoutexploration,2018, arXiv PrePrint arXiv:1812
 Addressing function approximation error inactor-critic methods,2018, arXiv PrePrint arXiv:1802
 Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor,2018, arXiv PrePrintarXiv:1801
 Variationalinformation maximizing exploration,2016, 2016
 Near-optimal regret bounds for reinforcementlearning,2010, JOUmaI OfMaChine Learning ReSearch
 Stabilizing off-policy q-learning viabootstrapping error reduction,2019, arXiv PrePrint arXiv:1906
 Continuous control with deep reinforcement learning,2015, arXivPrePrint arXiv:1509
 Teacher-student curriculum learn-ing,2019, IEEE transactions on neural networks and Iearning systems
 Human-levelcontrol through deep reinforcement learning,2015, nature
 Policy invariance under reward transformations:Theory and application to reward shaping,1999, In Icml
 Self-imitation learning,2018, arXiv PrePrintarXiv:1806
 Deep exploration viabootstrapped dqn,2016, In AdVanCeS in neural information PrOCeSSing systems
 Randomized prior functions for deep reinforcementlearning,2018, In AdVanCeS in NeUraI InfOrmatiOn PrOCeSSing Systems
 Count-based exploration withneural density models,2017, In InternatiOnal COnferenCe on machine Iearning
 Curiosity-driven explorationby self-supervised prediction,2017, In PrOCeedingS of the IEEE COnferenCe on COmPUter ViSiOn andPattern ReCOgnitiOn WOrkShops
 Multi-goal reinforce-ment learning: Challenging robotics environments and request for research,2018, arXiv PrePrintarXiv:1802
 Teacher algorithms forcurriculum learning of deep rl in continuously parameterized environments,2020, In COnference onRobotLearning
 Learning to drive a bicycle using reinforcement learning andshaping,1998, In ICML
 Optimistic exploration evenwith a pessimistic initialisation,2020, arXiv PrePrint arXiv:2002
 Trust regionpolicy optimization,2015, In International COnference on machine Iearning
 Proximal policyoptimization algorithms,2017, arXiv PrePrint arXiv:1707
 Dynamics-awareunsupervised discovery of skills,2019, arXiv Preprint arXiv:1907
 Keep doingWhat worked: Behavioral modelling priors for offline reinforcement learning,2020, arXiv PreprintarXiv:2002
 Policy continuation with hind-sight inverse dynamics,2019, In AdVanceS in Neural InfOrmatiOn PrOCeSSing Systems
 Reinforcement learning: An introduction,1998, 1998
 Distributional policy optimization: An alternativeapproach for continuous control,2019, arXiv PrePrint arXiv:1905
 Grandmasterlevel in starcraft ii using multi-agent reinforcement learning,2019, Nature
 Sample efficient actor-critic with experience replay,2016, arXiv PrePrintarXiv:1611
 Brac+: Going deeper with behaviorregularized offline reinforcement learning,2020, 2020
