title,year,conference
 Near-linear time approximation algo-rithms for optimal transport via Sinkhorn iteration,2017, In Advances in neural information processingsystems 
 Towards optimal transport withglobal invariances,2019, In The 22nd International Conference on Artificial Intelligence and Statistics
 A distributional perspective on reinforcementlearning,2017, In International Conference on Machine Learning
 Handbook ofcomputational social choice,2016, Cambridge University Press
 Sinkhorn distances: Lightspeed computation of optimal transport,2013, In Advances inneural information processing systems
 Sample complexityof sinkhorn divergences,2019, In The 22nd International Conference on Artificial Intelligence andStatistics
 Iteration complexity analysis of block coordi-nate descent method,2017, Mathematical Programming Series A
 A Riemannian block coordinate descent method forcomputing the projection robust Wasserstein distance,2021, In Proceedings of the 38th InternationalConference on Machine Learning
 Accelerated gradient descent escapes saddlepoints faster than gradient descent,2018, In Conference On Learning Theory
 Projection robust Wasser-stein distance and Riemannian optimization,2020, In NeurIPS
 Allocating indivisible items in categorized domains,2015, arXiv preprintarXiv:1504
 Wasserstein dependency measure for representation learning,2019, In Advances in NeuralInformation Processing Systems
 Concerning nonnegative matrices and doUbly stochastic matrices,1967, PacificJ
 Diagonal eqUivalence to matrices with prescribed row and colUmn sUms,1967, TheAmerican Mathematical Monthly
