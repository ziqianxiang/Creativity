title,year,conference
 Hindsight experience re-play,2017, In I
 Successor features for transfer in reinforcement learning,2017, InI
 Transfer in deep reinforcement learning usingsuccessor features and generalised policy improvement,2018, In Jennifer Dy and Andreas Krause(eds
 Fast reinforcementlearning with generalized policy Updates,2020, Proceedings of the National Academy of Sciences
 A geometric perspective onoptimal representations for reinforcement learning,2019, In NeurIPS
 Learning successor states and goal-dependentvalues: A mathematical viewpoint,2021, CoRR
 Multitask learning,1997, Machine learning
 The value-improvement path: Towards better representations for reinforcementlearning,2021, In AAAI
 Improving generalization for temporal difference learning: The successor representa-tion,0899, Neural Comput
 Addressing function approximation error in actor-critic methods,2018, In International Conference on Machine Learning
 Fast task inference with variational intrinsic successor features,2019, CoRR
 Entropic policy ComPo-sition with generalized policy improvement and divergence correction,2018, CoRR
 Reinforcement learning with unsupervised auxiliary tasks,2017, InICLR
 Adam: A method for stochastic optimization,2015, In ICLR (Poster)
 Deep successorreinforcement learning,2016, ArXiv
 Successor features support model-based and model-free re-inforcement learning,2019, CoRR
 Universal successor features fortransfer reinforcement learning,2020, CoRR
 Human-level control through deep rein-forcement learning,0028, Nature
 Markov Decision Processes,1994, Wiley
 Weight normalization: A simple reparameterization to accel-erate training of deep neural networks,2016, In D
 Universal value function approxima-tors,2015, In Francis Bach and David Blei (eds
 Learning one representation to optimize all rewards,2021, ArXiv
