title,year,conference
 Understanding and improving fast adversarialtraining,2020, In Neural Information Processing Systems (NeurIPS)
 Obfuscated gradients give a false senseof security: Circumventing defenses to adversarial examples,2018, In International Conference onMachine Learning (ICML)
 Wild patterns: Ten years after the rise of adversarial machinelearning,2018, Pattern Recognition
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning (ICML)
 Empiricalstudy of the topology and geometry of deep netWorks,2018, In IEEE Conference on Computer Visionand Pattern Recognition (CVPR)
 Adversarial examples are a naturalconsequence of test error in noise,2019, In International Conference on Machine Learning (ICML)
 Zerograd:Mitigating and explaining catastrophic overfitting in fgsm adversarial training,2021, arXiv:2103
 Explaining and harnessing adversarialexamples,2015, International Conference on Learning Representations (ICLR)
 Countering adversarialimages using input transformations,2018, In International Conference on Learning Representations(ICLR)
 Delving deep into rectifiers: Surpass-ing human-level performance on imagenet classification,2015, In IEEE International Conference onComputer Vision (ICCV)
 Identity mappings in deep residualnetworks,2016, In European Conference on Computer Vision (ECCV)
 Understanding catastrophic overfitting in adver-sarial training,2021, arXiv:2105
 Understanding catastrophic overfitting in single-stepadversarial training,2021, In AAAI Conference on Artificial Intelligence (AAAI)
 Adversarial machine learning at scale,2017, 2017
 Towards understanding fast adversarialtraining,2020, arXiv:2006
 Characterizing adversarial subspaces usinglocal intrinsic dimensionality,2018, In International Conference on Learning Representations (ICLR)
 Readingdigits in natural images with unsupervised feature learning,2011, In Neural Information ProcessingSystems (NeurIPS)
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In IEEE symposium on securityand privacy (SP)
 Reliably fast adversarial training via latent adversarial pertur-bation,2021, In International Conference on Learning Representations (ICLR)
 Certified defenses against adversarial exam-ples,2018, In International Conference on Learning Representations (ICLR)
 Overfitting in adversarially robust deep learning,2020, InInternational Conference on Machine Learning (ICML)
 Masteringthe game of go with deep neural networks and tree search,2016, Nature
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations (ICLR)
 Detecting adversarial examples from sensi-tivity inconsistency of spatial-transform domain,2021, In AAAI Conference on Artificial Intelligence(AAAI)
 Ensemble adversarial training: Attacks and defenses,2018, In International Conference onLearning Representations (ICLR)
 Single-step adversarial training with dropout scheduling,2020, In IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 Towards fast computation of certified robustness for relu networks,2018, InInternational Conference on Machine Learning (ICML)
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning (ICML)
 Ml-loo: Detect-ing adversarial examples with feature attribution,2020, In AAAI Conference on Artificial Intelligence(AAAI)
 Wide residual networks,2016, In BMVC British Machine VisionConference (BMVC)
