title,year,conference
 An introduction to kernel and nearest-neighbor nonparametric regression,1992, The AmericanStatistician
 Tabnet: Attentive interpretable tabular learning,2019, arXiv preprintarXiv:1908
 Layer normalization,2016, arXiv preprintarXiv:1607
 Random forests,2001, Machine learning
 Learning semantic annotations fortabular data,2019, arXiv preprint arXiv:1906
 Xgboost: A scalable tree boosting system,2016, In Proceedings of the 22nd acmsigkdd international conference on knowledge discovery and data mining
 A simple framework for contrastivelearning of visual representations,2020, In International conference on machine learning
 Exploring simple siamese representation learning,2020, arXiv preprintarXiv:2011
 Generating long sequences with sparse transform-ers,2019, arXiv preprint arXiv:1904
 Electra: Pre-training text encodersas discriminators rather than generators,2020, arXiv preprint arXiv:2003
 Bert: Pre-training of deep bidirectionaltransformers for language understanding,2018, arXiv preprint arXiv:1810
 Catboost: gradient boosting with categoricalfeatures support,2018, arXiv preprint arXiv:1810
 Extremely randomized trees,2006, Machine learning
 Deep residual learning for image recognition,2016, InProceedings of the IEEE conference on computer vision and pattern recognition
 Axial attention in multidimensionaltransformers,2019, arXiv preprint arXiv:1912
 Tabtransformer: Tabular data modeling usingcontextual embeddings,2020, arXiv preprint arXiv:2012
 Tabbie: Pretrained representations of tabulardata,2021, arXiv preprint arXiv:2105
 Net-dnf: Effective deep modeling of tabular data,2020, In InternationalConference on Learning Representations
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Gradient-based learning applied to documentrecognition,1998, Proceedings of the IEEE
 Generalized linear mixed models,2005, Encyclopedia of biostatistics
 Context encoders:Feature learning by inpainting,2016, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Msa transformer,2021, bioRxiv
 Regularization learning networks: deep learning for tabular datasets,2018, arXiv preprintarXiv:1805
 Improved deep metric learning with multi-class n-pair loss objective,2016, In Proceedings of the 30thInternational Conference on Neural Information Processing Systems
 Openml: Networked science in machinelearning,2013, SIGKDD Explorations
 Attention is all you need,2017, arXiv preprint arXiv:1706
 ExtraCting and Composingrobust features with denoising autoenCoders,2008, In Proceedings of the 25th international conference on Machinelearning 
 LogistiC regression,1995, 1995
 Unsupervised feature learning via non-parametriC in-stanCe disCrimination,2018, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 HierarChiCal attentionnetworks for doCument ClassifiCation,2016, In Proceedings of the 2016 conference of the North American chapterof the association for computational linguistics: human language technologies
 Tabert: Pretraining for joint understand-ing of textual and tabular data,2020, arXiv preprint arXiv:2005
 Vime: Extending the suCCess of self-andsemi-supervised learning to tabular domain,2020, Advances in Neural Information Processing Systems
 mixup: Beyond empiriCal riskminimization,2017, arXiv preprint arXiv:1710
