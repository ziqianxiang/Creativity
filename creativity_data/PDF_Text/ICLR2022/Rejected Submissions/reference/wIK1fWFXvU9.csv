title,year,conference
 A closer look atmemorization in deep netWorks,2017, In ICML
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial eXamples,2018, In ICML
 Improvingadversarial robustness via channel-Wise activation suppressing,2021, In ICLR
 Curriculum adversarial training,2018, In IJCAI
 ToWards evaluating the robustness of neural netWorks,2017, InSymposium on Security and Privacy (SP)
 Unlabeled dataimproves adversarial robustness,2019, In NeurIPS
 Adversarialrobustness: From self-supervised pre-training to fine-tuning,2020, In CVPR
 Robust overfittingmay be mitigated by properly learned smoothening,2021, In ICLR
 Learning With instance-dependent label noise: A sample sieve approach,2021, In ICLR
 Entropy of function of uncertain variables,2012, Mathematical and ComputerModelling
 Imagenet: A large-scalehierarchical image database,2009, In CVPR
 Mma training: Directinput space margin maXimization through adversarial training,2020, In ICLR
 What neural netWorks memorize and Why: Discovering the longtail via influence estimation,2020, In NeurIPS
 EXplaining and harnessing adversarialeXamples,2015, In ICLR
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, InNeurIPS
 Sigua:Forgetting may make learning with noisy labels more robust,2020, In ICML
 Training binary neuralnetworks through learning with noisy supervision,2020, In ICML
 Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels,2018, In ICML
 Beyond synthetic noise: Deep learning oncontrolled noisy labels,2020, In ICML
 Robust pre-training by adversarialcontrastive learning,2020, In NeurIPS
 Label-noise robust generative adversarialnetworks,2019, In CVPR
 Learning multiple layers of features from tiny images,2009, Technical report
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Visualizing the loss landscapeof neural nets,2018, In NeurIPS
 Peer loss functions: Learning from noisy labels without knowing noiserates,2020, In ICML
" Decoupling"" when to update"" from"" how to update""",2017, InNeurIPS
 Rectified linear units improve restricted boltzmann machines,2010, InICML
 Robustness to adversarialperturbations in learning from incomplete data,2019, In NeurIPS
 Learning withnoisy labels,2013, In NeurIPS
 Deep neural networks are easily fooled: High confidencepredictions for unrecognizable images,2015, In CVPR
 Self: Learning to filter noisy labels with self-ensembling,2019, InICLR
 Towards the science ofsecurity and privacy in machine learning,2016, arXiv:1611
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In CVPR
 Intriguing properties of neural networks,2014, In ICLR
 Feature scaling in support vector data descriptions,2000, 2000
 Analysis and applications of class-wiserobustness in adversarial training,2021, In KDD
 Learning with symmetric labelnoise: The importance of being unhinged,2015, In NeurIPS
 On theconvergence and robustness of adversarial training,2019, In ICML
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In ICLR
 Searching to exploitmemorization effect in learning with noisy labels,2020, In ICML
 Wide residual networks,2016, arXiv:1605
 Understandingdeep learning requires rethinking generalization,2017, In ICLR
 Attacks which do not kill training make adversarial learning stronger,2020, In ICML
1 reduced to 0,2022,01
