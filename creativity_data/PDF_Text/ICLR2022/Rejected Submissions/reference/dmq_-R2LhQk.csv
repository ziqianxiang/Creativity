title,year,conference
 Local explanation methods for deepneural networks lack sensitivity to parameter values,2018, arXiv preprint arXiv:1810
 Towards the unification and robustness of perturbation and gradient basedexplanations,2021, arXiv preprint arXiv:2102
 Multi-task deep learning based ctimaging analysis for covid-19 pneumonia: Classification and segmentation,2020, Computers in Biologyand Medicine
 Towards better understandingof gradient-based attribution methods for deep neural networks,2018, International Conference onLearning Representations
 Fairwashing explanations with off-manifold detergent,2020, In International Conference onMachine Learning
 On pixel-wise explanations for non-linear classifier decisions by layer-wiserelevance propagation,2015, PLOS ONE
 Understanding disentangling in β-vae,2018, arXiv preprintarXiv:1804
 Algorithms for manifold learning,2005, Univ
 On the global convergence of gradient descent for over-parameterized models using optimal transport,2018, arXiv preprint arXiv:1805
 Implicit bias of gradient descent for wide two-layer neural networkstrained with the logistic loss,2020, In Conference on Learning Theory
 Emnist: Extending mnist tohandwritten letters,2017, In 2017 International Joint Conference on Neural Networks (IJCNN)
 Deep Learning,2016, MIT Press
 Deep residual learning for image recog-nition,2016, In IEEE conference on computer vision and pattern recognition
 Fooling neural network interpretations via adver-sarial model manipulation,2019, Neural Information Processing Systems
 beta-vae: Learning basic visual concepts with aconstrained variational framework,2017, In ICLR
 Identifying medical diag-noses and treatable diseases by image-based deep learning,2018, Cell
 Bridging adversarial robustness and gradient inter-pretability,2019, arXiv preprint arXiv:1903
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Concept bottleneck models,2020, In International Conference on Machine Learning
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Influence-directed explana-tions for deep convolutional networks,2018, In 2018 IEEE International Test Conference
 Building reliable explanations of unreliable neu-ral networks: Locally smoothing perspective of model interpretation,2021, In IEEE Conference onComputer Vision and Pattern Recognition
 ” why should i trust you?” explaining thepredictions of any classifier,2016, In ACM SIGKDD International Conference on Knowledge Discoveryand Data Mining
 Stop explaining black box machine learning models for high stakes decisions anduse interpretable models instead,2019, Nature Machine Intelligence
 Evaluating the visualization of what a deep neural network has learned,2016, IEEE transactionson neural networks and learning systems
 Explaining deep neural networks and beyond: A review of methods and applica-tions,2021, Proceedings of the IEEE
 Cxplain: Causal explanations for model interpretation underuncertainty,2019, Neural Information Processing Systems
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In IEEE International Conference on Computer Vision
 The riemannian geometry of deep generativemodels,2018, In IEEE Conference on Computer Vision and Pattern Recognition Workshops
 Learning important features throughpropagating activation differences,2017, In International Conference on Machine Learning
 Explanation by pro-gressive exaggeration,2020, In International Conference on Learning Representations
 Smoothgrad:removing noise by adding noise,2017, arXiv preprint arXiv:1706
 Axiomatic attribution for deep networks,2017, InInternational Conference on Machine Learning
 Copulas as high-dimensional generativemodels: Vine copula autoencoders,2019, arXiv preprint arXiv:1906
 Nvae: A deep hierarchical variational autoencoder,2020, arXiv preprintarXiv:2007
