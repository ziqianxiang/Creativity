title,year,conference
 Isotropy in the contextual embeddingspace: Clusters and manifolds,2021, In International Conference on Learning Representations
 Scaling hidden markov language models,2020, In Proceedingsof the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)
 Efficient marginalization of dis-crete and structured latent variables via sparsity,2020, Advances in Neural Information ProcessingSystems
 Latent templateinduction with gumbel-crf,2020, In NeurIPS
 Atale of a probe and a parser,2020, In Proceedings of the 58th Annual Meeting of the Association forComputational Linguistics
 A structural probe for finding syntax in word representa-tions,2019, In Proceedings of the 2019 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies
 Un-supervised recurrent neural network grammars,2019, In Proceedings of the 2019 Conference of theNorth American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Estimating gradients for discrete random variablesby sampling without replacement,2020, In International Conference on Learning Representations
 Practical very large scale crfs,2010, In Proceedingsof the 48th Annual Meeting of the Association for Computational Linguistics
 Posterior control of blackbox generation,2020, In Proceedingsof the 58th Annual Meeting of the Association for Computational Linguistics
 Unsupervised para-phrasing by simulated annealing,2020, In Proceedings of the 58th Annual Meeting of the Association forComputational Linguistics
 Cgmh: Constrained sentence generation bymetropolis-hastings sampling,2018, In AAAI
 Monte carlo gradient esti-mation in machine learning,2020, J
 Randomizedautomatic differentiation,2020, In International Conference on Learning Representations
 Rnnlogic: Learn-ing logic rules for reasoning on knowledge graphs,2020, In International Conference on LearningRepresentations
 A tutorial on hidden Markov models and selected applications in speechrecognition,1989, Proceedings of the IEEE
 Languagemodels are unsupervised multitask learners,2019, Unpublished manuscript
 Joint learning of a dual smt system for paraphrase generation,2012, InProceedings ofthe 50th Annual Meeting of the Association for Computational Linguistics (Volume2: Short Papers)
 Fast structureddecoding for sequence models,2019, Advances in Neural Information Processing Systems
 An introduction to conditional random fields for relationallearning,2006, Introduction to statistical relational learning
 What do you learn fromcontext? probing for sentence structure in contextualized word representations,2019, In InternationalConference on Learning Representations
