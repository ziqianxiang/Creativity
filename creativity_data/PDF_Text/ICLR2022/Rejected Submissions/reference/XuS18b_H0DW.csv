title,year,conference
 Circumventing defenses to adversarial exam-ples,2018, ICML
 A unified viewof piecewise linear neural network verification,2018, NeurIPS
 Curriculum adversarial training,2018, IJCAI
 Cat: Customized adver-sarial training for improved robustness,2020, arXiv:2002
 Parsevalnetworks: Improving robustness to adversarial examples,2017, PMLR
 Certified adversarial robustness via randomizedsmoothing,2019, PMLR
 Training verified learners with learned ver-ifiers,2018, arXiv:1805
 Explaining and harnessing adversarialexamples,2014, arXiv:1412
 Scalable verified training forprovably robust image classification,2019, ICCV
 Certifiedrobustness to adversarial examples with differential privacy,2019, arXiv preprint arXiv:1802
 Understanding catastrophic overfitting in adversarialtraining,2021, arXiv:2105
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, IEEE
 Overfitting in adversarially robust deep learning,2020, PMLR
 Intriguing properties of neural networks,2014, ICLR
 Evaluating robustness of neural networks with mixedinteger programming,2019, ICLR
 Lipschitz-margin training: Scalable certifica-tion of perturbation invariance for deep neural networks,2018, In NeurIPS
 Adaptive verifiable trainingusing pairwise class similarity,2021, AAAI
 On theconvergence and robustness of adversarial training,2019, PMLR
 Improvingadversarial robustness requires revisiting misclassified examples,2020, ICLR
 Efficient neuralnetwork robustness certification with general activation functions,2018, NIPS
 Attacks which do not kill training make adversarial learning stronger,2020, arXiv:2002
