title,year,conference
 The implicit regularization of stochastic gradientflow for least squares,2020, In International Conference on Machine Learning
 The dantzig selector: Statistical estimation when p is muchlarger than n,2007, The annals of Statistics
 The restricted isometry property and its implications for compressedsensing,1631, ComPtes Rendus Mathematique
 Basis pursuit,1994, In Proceedings of 1994 28th Asilomar Conferenceon Signals
 A kernel for time seriesbased on global alignments,2007, In 2007 IEEE International Conference on Acoustics
 Exact expres-sions for double descent and implicit regularization via surrogate random design,2020, InH
 Understanding implicit regularization in over-parameterized nonlinear statistical model,2021, arXiv:2007
 Practical solutions to the problem of diagonal dominancein kernel document clustering,2006, In Proceedings of the 23rd international conference on Machinelearning
 Grouped variable selection with discreteoptimization: Computational and statistical perspectives,2021, arXiv:2104
 Deep residual learning for image recog-nition,2016, In Proceedings of the IEEE Conference on ComPuter Vision and Pattern Recognition(CVPR)
 Matrix analysis,2012, Cambridge university press
 Neural tangent kernel: Convergence andgeneralization in neural networks,2018, In S
 Just interpolate: Kernel “Ridgeless” regression can gener-alize,2020, The Annals of Statistics
 A diffusion approximation theory of momen-tum sgd in nonconvex optimization,2018, arXiv:1802
 What kinds of functions do deep neural networks learn? insightsfrom variational spline theory,2021, arXiv:2105
 Protein homology detectionusing string alignment kernels,2004, Bioinformatics
 On the origin of implicit regular-ization in stochastic gradient descent,2021, In International Conference on Learning Representations
 Kernel regression for image processing andreconstruction,2007, IEEE Transactions on image processing
 Implicit regularization for optimalsparse recovery,2019, In H
 Spline models for observational data,1990, SIAM
 Fashion-mnist: a novel image dataset for benchmark-ing machine learning algorithms,2017, arXiv:1708
 Implicit regularization via hadamard product over-parametrization in high-dimensional linear regression,2019, arXiv:1903
 The moderate step size setting is asfollows:ηtAnd the small step size setting has ηt0,2000,2
