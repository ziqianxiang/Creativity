title,year,conference
 A survey on transfer learning in naturallanguage processing,2020, arXiv preprint arXiv:2007
 Multi-task feature learning,2007, InB
 Quick and robust feature selection: the strengthof energy-efficient sparse training for autoencoders,2020, ArXiv
 Deep learning through the lens of exampledifficulty,2021, ArXiv
 Concrete autoencoders: Differentiablefeature selection and reconstruction,2019, In Proceedings of the 36th International Conference onMachine Learning
 Feature Selection forHigh-Dimensional Data,2015, Springer Publishing Company
 An image is worth 16x16 words: Transformers for image recogni-tion at scale,2021, In International Conference on Learning Representations
 Comparing transfer and meta learning approaches on a unified few-shot classi-fication benchmark,2021, arXiv preprint arXiv:2104
 Selecting relevant features from a multi-domain representation for few-shot classification,2020, In European Conference on Computer Vision
 Learn-to-share: Ahardware-friendly transfer learning framework exploiting computation and parameter sharing,2021, InICML
 Feature selection based on struc-tured sparsity: A comprehensive study,2017, IEEE Transactions on Neural Networks and LearningSystems
 Gene se-lection for cancer classification using support vector machines,2004, Machine Learning
 Laplacian score for feature selection,2005, In Proceedings ofthe 18th International Conference on Neural Information Processing Systems
 Meta-learning in neuralnetworks: A survey,2020, arXiv preprint arXiv:2004
 Shallow-deep networks: Understanding andmitigating network overthinking,2019, In ICML
 Wrappers for feature subset selection,1997, Artif
 Improving task adaptation for cross-domain few-shotlearning,2021, arXiv preprint arXiv:2107
 Universal representation learning from multiple domainsfor few-shot classification,2021, arXiv preprint arXiv:2103
 A universal rep-resentation transformer layer for few-shot image classification,2021, In International Conference onLearning Representations
 Deep ensembles for low-data transfer learning,2020, ArXiv
 Deep contextualized word representations,2018, In NAACL
 Learning multiple visual domains withresidual adapters,2017, arXiv preprint arXiv:1705
 Which model to transfer? finding the needle in the growing haystack,2020, ArXiv
 Branchynet: Fast inference via earlyexiting from deep neural networks,2016, 2016 23rd International Conference on Pattern Recognition(ICPR)
 Learning to learn: Introduction and overview,1998, In Learning tolearn
 Learning a universaltemplate for few-shot dataset generalization,2021, In International Conference on Machine Learning
 Rapid object detection using a boosted cascade of simplefeatures,2001, Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision andPattern Recognition
 The visualtask adaptation benchmark,2019, ArXiv
 Bert loses pa-tience: Fast and robust inference with early exit,2020, ArXiv
 Ensembling neural networks: Many could be better thanall,2002, Artificial Intelligence
 Transfer learning in deep reinforcement learning: Asurvey,2020, arXiv preprint arXiv:2009
 A comprehensive survey on transfer learning,2020, Proceedings of the IEEE
