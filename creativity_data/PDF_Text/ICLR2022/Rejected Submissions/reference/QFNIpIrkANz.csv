title,year,conference
 Invariant riskminimization games,2020, arXiv preprint arXiv:2002
 OPenai gym,2016, arXiv preprint arXiv:1606
 Invariant rationalization,2020, In InternationalConference on Machine Learning
 Causal confusion in imitation learning,2019, arXivpreprint arXiv:1905
 Guided cost learning: DeeP inverse oPtimal controlvia Policy oPtimization,2016, In International conference on machine learning
 Learning robust rewards with adversarial inverse reinforce-ment learning,2017, arXiv preprint arXiv:1710
 Generative adversarial networks,2014, arXiv preprintarXiv:1406
 Generative adversarial imitation learning,2016, arXiv preprintarXiv:1606
 Adam: A method for stochastic oPtimization,2014, arXiv preprintarXiv:1412
 Infogail: InterPretable imitation learning from visualdemonstrations,2017, arXiv preprint arXiv:1703
 Policy invariance under reward transformations:Theory and aPPlication to reward shaPing,1999, In Icml
 Causal inference using invariant prediction:identification and confidence intervals,2015, arXiv preprint arXiv:1501
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Observational overfittingin reinforcement learning,2019, arXiv preprint arXiv:1912
 Maximum entropy deep inverse reinforce-ment learning,2015, arXiv preprint arXiv:1507
 Invariant causal prediction for block mdps,2020, In International Conferenceon Machine Learning 
 Maximum entropy inversereinforcement learning,2008, In Aaai
 Modeling interaction via the principle ofmaximum causal entropy,2010, In ICML
