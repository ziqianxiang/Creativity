title,year,conference
 Tabnet: Attentive interpretable tabular learning,2020, arXiv
 Searching for exotic particles in high-energyphysics with deep learning,2014, Nature communications
 Bagging predictors,1996, Machine learning
 Online knowledge distillationwith diverse peers,2020, In Proceedings of the AAAI Conference on Artificial Intelligence
 Xgboost: A scalable tree boosting system,2016, In Proceedings of the22nd acm sigkdd international conference on knowledge discovery and data mining
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv preprint arXiv:1708
 Deep ensembles: A loss landscape per-spective,2019, arXiv preprint arXiv:1912
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,1050, In international conference on machine learning
 Deepmdp:Learning continuous latent space models for representation learning,2019, In International Conferenceon Machine Learning
 Neural network ensembles,1990, IEEE transactions on patternanalysis and machine intelligence
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Random decision forests,1995, In Proceedings of 3rd international conference on documentanalysis and recognition
 Adaptive mixtures oflocal experts,1991, Neural computation
 Lightgbm: A highly efficient gradient boosting decision tree,2017, Advances in neuralinformation processing systems
 Learning multiple layers of features from tiny images,2009, 2009
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2016, arXiv preprint arXiv:1612
 Whym heads are better than one: Training a diverse ensemble of deep networks,2015, arXiv preprintarXiv:1511
 Diversity regularized ensemble pruning,2012, In Joint Europeanconference on machine learning and knowledge discovery in databases
 Direction concentration learning:Enhancing congruency in machine learning,2019, IEEE transactions on pattern analysis and machineintelligence
 Learning under model misspecification: Applications to variational and en-semble methods,2019, arXiv preprint arXiv:1912
 Boosted convolutional neural networks,2016, In BMVC
 Dice: Diversity in deep ensembles via conditional redundancyadversarial estimation,2021, arXiv preprint arXiv:2101
 Meal: Multi-model ensemble via adversariallearning,2019, In Proceedings of the AAAI Conference on Artificial Intelligence
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Mice: Mixture of contrastive experts for unsupervisedimage clustering,2020, In International Conference on Learning Representations
 Hyperparameter ensembles forrobustness and uncertainty quantification,2020, arXiv preprint arXiv:2006
 The diversified ensemble neural network,2020, Advancesin Neural Information Processing Systems
 Diverse ensemble evolution: Curriculum data-model marriage,2018, In Proceedings of the 32nd International Conference on Neural InformationProcessing Systems
 Ensembling neural networks: many could be better thanall,2002, Artificial intelligence
