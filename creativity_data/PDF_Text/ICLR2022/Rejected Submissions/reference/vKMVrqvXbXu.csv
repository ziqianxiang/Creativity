title,year,conference
 A convergence theory for deep learning via over-parameterization,2019, ArXiv
 Neural network learning - theoretical foundations,1999, 1999
 Stronger generalization bounds fordeep nets via a compression approach,2018, ArXiv
 A convergence analysis of gradientdescent for deep linear neural networks,2019, ArXiv
 Implicit regularization in deep matrixfactorization,2019, In NeurIPS
 Almost linear vc-dimension bounds for piecewisepolynomial networks,1998, Neural Computation
 Why deep learning works: A manifold disentanglementperspective,2016, IEEE Transactions on Neural Networks and Learning Systems
 Geometric deep learning:Going beyond euclidean data,2017, IEEE Signal Processing Magazine
 Efficient approximation of deep relunetworks for functions on low dimensional manifolds,2019, ArXiv
 Relu nets adapt to intrinsic dimensionality beyond the targetdomain,2020, ArXiv
 Approximation by superpositions of a sigmoidal function,1989, Mathematics of Control
 Algorithmic regularization in learning deep homogeneousmodels: Layers are automatically balanced,2018, In NeurIPS
 Testing the manifold hypothesis,2013, arXiv: StatisticsTheory
 Hyperbolic neural networks,2018, ArXiv
 Modelling the influence ofdata structure on learning in neural networks,2020, ArXiv
 Generative adversarial nets,2014, In NIPS
 Qualitatively characterizing neural network optimizationproblems,2015, CoRR
 Explaining and harnessing adversarialexamples,2015, CoRR
 Complexity of linear regions in deep networks,2019, ArXiv
 Deep relu networks have surprisingly few activation patterns,2019, In NeurIPS
 Universal function approximation by deep neural nets with bounded width and reluactivations,2019, ArXiv
 Finite depth and width corrections to the neural tangent kernel,2020, ArXiv
 Principles of riemannian geometry in neural networks,2017, In NIPS
 Multilayer feedforward networks are universal approxi-mators,1989, Neural Networks
 Neural tangent kernel: Convergence and generalization inneural networks,2018, In NeurIPS
 Training generativeadversarial networks with limited data,2020, ArXiv
 Generalization in deep learning,2017, ArXiv
 Adam: A method for stochastic optimization,2015, CoRR
 A software package for sequential quadratic programming,1988, Tech
 Geometric integration theory,2008, 2008
 NeU-ral mechanics: Symmetry and broken conservation laws in deep learning dynamics,2020, ArXiv
 Wide neural networks of any depth evolve as linear modelsunder gradient descent,2019, ArXiv
 Deep vs,2016, shallow networks : An approximation theory perspective
 Geometric deep learning on graphs and manifolds using mixture model cnns,2017, 2017IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 On the number of linearregions of deep neural networks,2014, In NIPS
 Rectified linear units improve restricted boltzmann machines,2010, InICML
 A pac-bayesianapproach to spectrally-normalized margin bounds for neural networks,2018, ArXiv
 Non-linear dimensionality reduction: Riemannianmetric estimation and the problem of geometric discovery,2013, arXiv: Machine Learning
 Exponential expressivity indeep neural networks through transient chaos,2016, ArXiv
 Pointnet: Deep learning on point sets for3d classification and segmentation,2017, 2017 IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 On the spectral bias of neural networks,2019, In ICML
 INTRODUCTION TO DIFFERENTIALGEOMETRY,2011, Preprint
 Empirical analysis of thehessian of over-parametrized neural networks,2018, ArXiv
 Exact solutions to the nonlinear dynamicsof learning in deep linear neural networks,2014, CoRR
 Deep relu network approximation of functions on a manifold,2019, ArXiv
 Bounding and counting linear regionsof deep neural networks,2018, In ICML
 Provable approximation properties fordeep neural networks,2015, ArXiv
 A bayesian perspective on generalization and stochastic gradientdescent,2018, ArXiv
 A differential equation for modelingnesterovâ€™s accelerated gradient method: Theory and insights,2016, In J
 Intriguing ProPerties of neural networks,2014, CoRR
 RePresentation benefits of deeP feedforward networks,2015, ArXiv
 MaPPing a manifold of PercePtual observations,1997, In NIPS
 Geometric interPretations of curvature,2016, 2016
 DeeP networks Provably classify dataon curves,2021, ArXiv
 Acomprehensive survey on graph neural networks,2019, IEEE Transactions on Neural Networks andLearning Systems
 Understanding deep learning requiresrethinking generalization,2017, ArXiv
 Neural networks fail to learn periodic functions andhow to fix it,2020, ArXiv
