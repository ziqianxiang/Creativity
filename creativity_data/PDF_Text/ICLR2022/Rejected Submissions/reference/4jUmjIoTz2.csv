title,year,conference
 Adef: an iterative algorithm to constructadversarial deformations,2019, In ICLR
 Understanding and improving fast adversarialtraining,2020, In NeurIPS
 Square attack:a query-efficient black-box adversarial attack via random search,2020, In European Conference onComputer Vision
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Adversarial training and provable defenses: Bridging thegap,2020, In ICLR
 Bagging predictors,1996, Machine learning
 Single-step adversarial training with dropout scheduling,2020, InCVPR
 Curriculum adversarial training,2018, In IJCAI
 Adversarial examples are not easily detected: Bypassingten detection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, InIEEE Symposium on Security and Privacy
 Unlabeled dataimproves adversarial robustness,2019, In NeurIPS
 Hopskipjumpattack: A query-efficientdecision-based attack,2020, In IEEE Symposium on Security and Privacy
 Adversarial examples detection beyond image space,2021, In IEEE International Conference onAcoustics
 EAD: elastic-net attacks todeep neural networks via adversarial examples,2018, In AAAI
 Adversarialrobustness: From self-supervised pre-training to fine-tuning,2020, In CVPR
 Robust overfittingmay be mitigated by properly learned smoothening,2021, In ICLR
 Query-efficienthard-label black-box attack: An optimization-based approach,2019, In ICLR
 Parsevalnetworks: Improving robustness to adversarial examples,2017, In ICML
 Detecting adversarial samples using influencefunctions and nearest neighbors,2020, In CVPR
 Certified adversarial robustness via randomizedsmoothing,2019, In ICML
 Monge blunts bayes: Hardness results for adversarial training,2019, In ICML
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In ICML
 Mma training: Directinput space margin maximization through adversarial training,2020, In ICLR
 Boostingadversarial attacks with momentum,2018, In Proceedings of the IEEE conference on computer visionand pattern recognition
 Adversarial distributional trainingfor robust deep learning,2020, In NeurIPS
 Generalizable adversarial training via spectralnormalization,2019, In ICLR
 Experiments with a new boosting algorithm,1996, In ICML
 Large-scale adversarialtraining for vision-and-language representation learning,2020, In NerIPS
 Convergence ofadversarial training in overparametrized neural networks,2019, In NeurIPS
 Explaining and harnessing adversarialexamples,2015, In ICLR
 Deep residual learning for imagerecognition,2016, In CVPR
 Formal guarantees on the robustness of a classifieragainst adversarial manipulation,2017, In NeurIPS
 Natural adversarialexamples,2021, In CVPR
 Adaptive mixtures oflocal experts,1991, Neural computation
 Improving adversarial robustness of ensembles withdiversity training,2019, arXiv preprint arXiv:1901
 Learning multiple layers of features from tiny images,2009, 2009
 Certifiedrobustness to adversarial examples with differential privacy,2019, In Symposium on Security and Privacy(SP)
 A simple unified framework for detectingout-of-distribution samples and adversarial attacks,2018, In NeurIPS
 QEBA: query-efficient boundary-based blackbox attack,2020, In CVPR
 Adversarial examples detection in deep networks with convolutional filterstatistics,2017, In ICCV
 Implicit bias of gradient descent based adversarialtraining on separable data,2020, In ICLR
 On the loss landscapeof adversarial training: Identifying challenges and how to overcome them,2020, In NeurIPS
 Detection based defense against adversarial examples from the steganalysis point of view,2019, InCVPR
 Modeling task relationshipsin multi-task learning with multi-gate mixture-of-experts,2018, In SIGKDD
 Characterizing adversarial subspaces using localintrinsic dimensionality,2018, In ICLR
 Fundamentaltradeoffs in distributionally adversarial training,2021, In ICML
 On detecting adversarialperturbations,2017, In ICLR
 Differentiable abstract interpretation forprovably robust neural networks,2018, In ICML
 Deepfool: A simple andaccurate method to fool deep neural networks,2016, In CVPR
 Generalizable data-free objectivefor crafting universal adversarial perturbations,2019, IEEE Trans
 Robustness to adversarialperturbations in learning from incomplete data,2019, In NeurIPS
 Adversarial robustness may be at odds with simplicity,2019, arXiv:1901
 Towards robust detection of adversarialexamples,2018, In NeurIPS
 Improving adversarial robustness viapromoting ensemble diversity,2019, In ICML
 Boosting adversarialtraining with hypersphere embedding,2020, In NeurIPS
 Geoda: Ageometric framework for black-box adversarial attacks,2020, In CVPR
 Overfitting in adversarially robust deep learning,2020, In ICML
 The odds are odd: A statistical test for detectingadversarial examples,2019, In ICML
 Adversarial training is a form of data-dependentoperator norm regularization,2020, In NeurIPS
 Provably robust classification of adversarialexamples with detection,2021, In ICLR
 Second-order provable defenses against adversarial attacks,2020, In ICML
 Improving the generalization ofadversarial training with domain adaptation,2019, In ICLR
 Robust local features forimproving the generalization of adversarial training,2020, In ICLR
 Confidence-calibrated adversarial training: Generaliz-ing to Unseen attacks,2020, In ICML
 IntrigUing properties of neUral networks,2014, In ICLR
 Detecting adversarial examples from sensitivityinconsistency of spatial-transform domain,2021, In AAAI
 Detecting adversarial examples through image transforma-tion,2018, In AAAI
 Ensemble adversarialtraining: Attacks and defenses,2018, In ICLR
 Adversarial training and robustness for multiple perturbations,2019, InNeurIPS
 Lipschitz-Margin training: Scalable certificationof perturbation invariance for deep neural networks,2018, In NeurIPS
 On theconvergence and robustness of adversarial training,2019, In ICML
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In ICLR
 Evaluating the robustness of neural networks: An extreme value theory approach,2018, InICLR
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In ICML
 Wasserstein adversarial examples via projectedsinkhorn iterations,2019, In ICML
 Fast is better than free: Revisiting adversarial training,2020, InICLR
 Skip connections matter:On the transferability of adversarial examples generated with resnets,2020, In ICLR
 Reinforcing adversarialrobustness using model confidence induced by adversarial training,2018, In ICML
 Beating attackers at their own games:Adversarial example detection using adversarial gradient directions,2021, In AAAI
 Spatially transformedadversarial examples,2018, In ICLR
 Intriguing properties of adversarial training at scale,2020, In ICLR
 To be robust or to be fair: Towardsfairness in adversarial training,2021, In ICML
 Cifs:Improving adversarial robustness of cnns via channel-wise importance-based feature selection,2021, InICML
 Deep defense: Training dnns with improvedadversarial robustness,2018, In NeurIPS
 Policy-driven attack: Learning to queryfor hard-label black-box adversarial examples,2021, In ICLR
 Dverge: Diversifying vulnerabilities forenhanced robust generation of ensembles,2020, In NeurIPS
 ML-LOO:detecting adversarial examples with feature attribution,2020, In AAAI
 Rademacher complexity for adversariallyrobust generalization,2019, In ICML
 GAT: generative adversarial training foradversarial example detection and robust classification,2020, In ICLR
 Understanding generaliza-tion in adversarial training via the bias-variance decomposition,2021, arXiv preprint arXiv:2103
 LAFEAT: piercing through adversarial defenses withlatent features,2021, In CVPR
 You only propagateonce: Accelerating adversarial training via maximal principle,2019, In NeurIPS
 Defense against adversarial attacks using feature scattering-basedadversarial training,2019, In NeurIPS
 Towards stable and efficient training of verifiably robust neural networks,2020, InICLR
 Attacks which do not kill training make adversarial learning stronger,2020, In ICML
 Over-parameterized adversarial training: An analysis overcoming the curse of dimensionality,2020, InNeurIPS
 Efficient adversarialtraining with transferable adversarial examples,2020, In CVPR
 Distributionally adversarial attack,2019, In AAAI
 Provable robustness of adversarial training for learninghalfspaces with noise,2021, In ICML
