title,year,conference
 Pitfalls of in-domainuncertainty estimation and ensembling in deep learning,2020, In International Conference on LearningRepresentations
 Weight uncertainty inneural networks,2015, In International Conference on Machine Learning
 Clinically applicable deep learning for diagnosis and referralin retinal disease,2018, In Nature Medicine
 De-composition of uncertainty in bayesian deep learning for efficient and risk-sensitive learning,2018, InInternational Conference on Machine Learning
 Ensemble distillation approaches for gram-matical error correction,2021, In International Conference on Acoustics
 An introduction to roc analysis,2006, In Pattern Recognition Letters
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In International Conference on Machine Learning
 Practical variational inference for neural networks,2011, In Advances in Neural InformationProcessing Systems
 On calibration of modern neuralnetworks,2017, In International Conference on Machine Learning
 Training independent subnetworks for robustprediction,2021, In International Conference on Machine Learning
 Deep residual learning for image recog-nition,2016, Conference on Computer Vision and Pattern Recognition
 Distilling the knowledge in a neural network,2014, InConference on Neural Information Processing Systems
 Bayesian active learning forclassification and preference learning,2011, In arXiv preprint arXiv:1112
 Deep networks withstochastic depth,2016, European Conference on Computer Vision
 Densely connectedconvolutional networks,2017, In Conference on Computer Vision and Pattern Recognition
 Aleatoric and epistemic uncertainty in machine learning:An introduction to concepts and methods,2021, In Machine Learning
 An introductionto variational methods for graphical models,1999, In Machine Learning
 Learning to drive in a day,2019, In InternationalConference on Robotics and Automation
 Sequence-level knowledge distillation,2016, In Conference on Empirical Methodsin Natural Language Processing
 Batchbald: Efficient and diverse batch acqui-sition for deep bayesian active learning,2019, In Neural Information Processing Systems
 Imagenet classification with deep convo-lutional neural networks,2012, In Conference on Neural Information Processing Systems
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2017, In Conference on Neural Information ProcessingSystems
 Asimple baseline for bayesian uncertainty in deep learning,2019, In Conference on Neural InformationProcessing Systems
 Reverse kl-divergence training of prior networks: Improved un-certainty and adversarial robustness,2019, In Conference on Neural Information Processing Systems
 Ensemble distribution distillation,2020, InInternational Conference on Learning Representations
 Foundations OfStatistical Natural Language Processing,1999, MITPress
 Estimating a dirichlet distribution,2000, Technical report
 Readingdigits in natural images with unsupervised feature learning,2011, In Neural Information ProcessingSystems Workshop on Deep Learning and Unsupervised Feature Learning
 Scaling ensemble distribution distillation tomany classes with proxy targets,2021, In arXiv preprint arXiv:2001
 Facenet: A unified embedding for facerecognition and clustering,2015, In Conference on Computer Vision and Pattern Recognition
 Learning for single-shot confidence calibra-tion in deep neural networks through stochastic inferences,2019, In Conference on Computer Visionand Pattern Recognition
 Batchensemble: an alternative approach to efficientensemble and lifelong learning,2020, In International Conference on Machine Learning
 Lsun:Construction of a large-scale image dataset using deep learning with humans in the loop,2015, arXivpreprint arXiv:1506
 Wide residual networks,2016, In The British Machine VisionConference
7 ± 4,2020,1 80
1 ± 4,2022,6 80
