title,year,conference
 An optimistic perspective on offlinereinforcement learning,2020, In International Conference on Machine Learning
 Opal: Offline prim-itive discovery for accelerating offline reinforcement learning,2020, arXiv preprint arXiv:2010
 Model-based offline planning,2020, arXiv preprintarXiv:2008
 OpenAI Gym,2016, arXiv preprint arXiv:1606
 Deep reinforcement learn-ing in a handful of trials using probabilistic dynamics models,2018, arXiv preprint arXiv:1805
 Off-policy actor-critic,2012, arXiv preprintarXiv:1205
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Addressing function approximation error in actor-critic methods,2018, In International Conference on Machine Learning
 Off-policy deep reinforcement learning withoutexploration,2019, In International Conference on Machine Learning
 Relay policylearning: Solving long-horizon tasks via imitation and reinforcement learning,2019, arXiv preprintarXiv:1910
 Soft actor-critic algorithms and appli-cations,2018, arXiv preprint arXiv:1812
 Qt-opt: Scalable deepreinforcement learning for vision-based robotic manipulation,2018, arXiv preprint arXiv:1806
 Morel: Model-based offline reinforcement learning,2020, arXiv preprint arXiv:2005
 Actor-critic algorithms,2000, In Advances in neural informationprocessing systems
 Offline reinforcement learningwith fisher divergence critic regularization,2021, In International Conference on Machine Learning
 Stabilizing off-policy q-learning viabootstrapping error reduction,2019, arXiv preprint arXiv:1906
 Conservative Q-learning for offlinereinforcement learning,2020, arXiv preprint arXiv:2006
 Maxmin Q-learning: Controlling theestimation bias of Q-learning,2020, In International Conference on Learning Representations
 Offline-to-online reinforcement learning via balanced replay and pessimistic q-ensemble,2021, arXiv preprintarXiv:2107
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Human-levelcontrol through deep reinforcement learning,2015, nature
 Dualdice: Behavior-agnostic estimation ofdiscounted stationary distribution corrections,2019, arXiv preprint arXiv:1906
 Accelerating online reinforcementlearning with offline datasets,2020, arXiv preprint arXiv:2006
 Deep exploration viabootstrapped dqn,2016, Advances in neural information processing systems
 Learning complex dexterous manipulation with deep reinforcementlearning and demonstrations,2017, arXiv preprint arXiv:1709
 Prioritized experience replay,2015, arXivpreprint arXiv:1511
 Cnn features off-the-shelf: an astounding baseline for recognition,2014, In Proceedings of the IEEE conference oncomputer vision and pattern recognition workshops
 Keep doing what worked:Behavior modelling priors for offline reinforcement learning,2020, In International Conference onLearning Representations
 Masteringthe game of go with deep neural networks and tree search,2016, nature
 Cog:Connecting new skills to past experience with offline reinforcement learning,2020, arXiv preprintarXiv:2010
 Word representations: a simple and general methodfor semi-supervised learning,2010, In Proceedings of the 48th annual meeting of the association forcomputational linguistics
 Representation matters: Offline pretraining for sequential deci-sion making,2021, arXiv preprint arXiv:2102
 Mopo: Model-based offline policy optimization,2020, arXiv preprintarXiv:2005
