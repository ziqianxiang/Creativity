title,year,conference
 Towards robust interpretability with self-explainingneural networks,2018, In Advances in Neural Information Processing Systems
 On the robustness of interpretability methods,2018, InProceedings of the 2018 ICML Workshop in Human Interpretability in Machine Learning
 Towards better understandingof gradient-based attribution methods for deep neural networks,2018, In International Conference onLearning Representations
 Explaining recur-rent neural network predictions in sentiment analysis,2017, In Proceedings of the 8th Workshop onCOmputatiOnal Approaches to Subjectivity
 Counterfactual explanations for mul-tivariate time series,2021, In 2021 International Conference on Applied Artificial Intelligence (ICAPAI)
 On pixel-wise explanations for non-linear classifier decisions by layer-wiserelevance propagation,2015, PLOS ONE
 An empirical evaluation of generic convolutionaland recurrent networks for sequence modeling,2018, arXiv preprint arXiv:1803
 Safe model-basedreinforcement learning with stability guarantees,2017, In Proc
 Interpretation of deep tempo-ral representations by selective visualization of internally activated nodes,2020, arXiv preprintarXiv:2004
 Deep learning for time series classification: a review,2019, Data Mining and KnowledgeDiscovery
 Representativity and consistency measures for deep neural net-work explanations,2020, arXiv preprint arXiv:2009
 Shortcut learning in deep neural networks,2020, NatureMachine Intelligence
 European union regulations on algorithmic decision-makingand a “right to explanation”,2017, AI magazine
 Long short-term memory,1997, Neural Computation
 Batch normalization: Accelerating deep network training by re-ducing internal covariate shift,2015, In Proc
 Benchmark-ing deep learning interpretability in time series predictions,2020, In Advances in Neural InformationProcessing Systems
 Top-down neuralattention by excitation backprop,2016, In European Conference on Computer Vision(ECCV)
 Automated quality assurancefor hand-held tools via embedded classification and automl,2021, In Machine Learning and KnowledgeDiscovery in Databases
 Fully convolutional networks for semanticsegmentation,2015, In Proceedings of the IEEE conference on computer vision and pattern recognition
 A unified approach to interpreting model predictions,2017, In Advancesin Neural Information Processing Systems
 There and back again: Revisitingbackpropagation saliency methods,2020, In Conference on Computer Vision and Pattern Recognition(CVPR)
 “why shoUld i trUst yoU?”: Explainingthe predictions of any classifier,2016, In Proc
 Explaining deep neural networks and beyond: A review of methods and applica-tions,2021, Proc
 Bidirectional recurrent neural networks,1997, IEEE Transactions onSignal Processing
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In IEEE Intl
 Deep inside convolutional networks: Vi-sualising image classification models and saliency maps,2014, arXiv preprint arXiv:1312
 Smoothgrad:removing noise by adding noise,2017, arXiv preprint arXiv:1706
 Striving forsimplicity: The all convolutional net,2015, In Yoshua Bengio and Yann LeCun (eds
 Detecting and interpreting myocardial infarction using fullyconvolutional neural networks,2019, Physiological Measurement
 Axiomatic attribution for deep networks,2017, InInternational Conference on Machine Learning
 Precision andrecall for time series,2018, In Advances in Neural Information Processing Systems
 Speech discrimination by dynamic programming,1968, Cybernetics
 Time series classification from scratch with deepneural networks: A strong baseline,2017, In Intl
 Image quality assessment:from error visibility to structural similarity,2004, IEEE Trans
 Evaluating expla-nation methods for deep learning in security,2020, In IEEE European Symposium on Security andPrivacy
 Visual interpretability for deep learning: a survey,2018, FrontiersInf
 Learning deepfeatures for discriminative localization,2016, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
