title,year,conference
 Language models are few-shot learners,2020, In H
 Towards general purposevision systems,2021, CoRR
 Actionbert: Leveraging user actions for semanticunderstanding of user interfaces,2020, CoRR
 Transformer is all you need: Multimodal multitask learningwith a unified transformer,2021, CoRR
 Vilt: Vision-and-language transformer without convo-lution or region supervision,2021, In Marina Meila and Tong Zhang (eds
 Visualbert: A simpleand performant baseline for vision and language,2019, In Arxiv
 Mapping natural languageinstructions to mobile UI action sequences,2020, In Proceedings of the 58th Annual Meeting of theAssociation for Computational Linguistics
 Widget captioning:Generating natural language description for mobile user interface elements,2020, In Proceedings of the2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)
 Vilbert: Pretraining task-agnostic visiolinguisticrepresentations for vision-and-language tasks,2019, In H
 Exploring the limits of transfer learning with a unified text-to-texttransformer,2019, CoRR
 Pointer networks,2015, In C
 Screen2words:Automatic mobile UI summarization with multimodal learning,2021, UISTâ€™21
 Screen recognition:Creating accessibility metadata for mobile applications from pixels,2021, In Proceedings of the 2021CHI Conference on Human Factors in Computing Systems
