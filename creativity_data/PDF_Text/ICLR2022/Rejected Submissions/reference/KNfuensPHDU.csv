title,year,conference
 Certifying neural network robustness to randominput noise from samples,2020, arXiv preprint arXiv:2010
 Fast training of provably robust neural networks by singleprop,2021, arXiv preprintarXiv:2102
 Understanding how image quality affects deep neuralnetworks,2016, In 2016 eighth international conference on quality of multimedia experience(QoMEX)
 Generalisation in humans and deep neural networks,2018, arXivpreprint arXiv:1808
 Scalableverified training for provably robust image classification,2019, ICCV
 Learning multiple layers of features from tiny images,2009, Technical report
 Towards deep learning models resistant to adversarial attacks,2017, arXiv preprintarXiv:1706
 Semidefinite relaxations for certifyingrobustness to adversarial examples,2018, arXiv preprint arXiv:1811
 A convexrelaxation barrier to tight robustness verification of neural networks,2019, arXiv preprintarXiv:1902
 Fast certified robusttraining via better initialization and shorter warmup,2021, arXiv preprint arXiv:2103
 Beyond the singleneuron convex barrier for neural network certification,2019, Advances in Neural InformationProcessing Systems
 Intriguing properties of neural networks,2014, ICLR
 A statistical approachto assessing neural network robustness,2018, arXiv preprint arXiv:1811
 Towards fast computation of certified robustness for relunetworks,2018, In International Conference on Machine Learning
 Proven: Verifying robustness of neural networks with a probabilisticapproach,2019, In International Conference on Machine Learning
 Trainingfor faster adversarial robustness verification via inducing relu stability,2018, arXiv preprintarXiv:1809
 Automatic perturbation analysis for scalablecertified robustness and beyond,2020, Advances in Neural Information Processing Systems
 Efficientneural network robustness certification with general activation functions,2018, arXiv preprintarXiv:1811
 Towards stable and efficient training of verifiably robustneural networks,2019, arXiv preprint arXiv:1906
