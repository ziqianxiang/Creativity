title,year,conference
 Obfuscated gradients give a false senseof security: Circumventing defenses to adversarial examples,2018, In Jennifer G
 Openai gym,2016, arXiv:1606
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE SympoSium on SeCurity and Privacy (SP)
 Adversarial examples are not easily detected: Bypassingten detection methods,2017, In Bhavani M
 EAD: elastic-net attacks todeep neural networks via adversarial examples,2018, In Sheila A
 Generalized no free lunch theorem for adversarial robustness,1646, In KamalikaChaudhuri and Ruslan Salakhutdinov (eds
 Boost-ing adversarial attacks with momentum,2018, In Proceedings of the IEEE conference on computervision and pattern recognition
 Ad-versarial policies: Attacking deep reinforcement learning,2020, International Conference on LearningRepresentations ICLR
 Explaning and harnessing adversarialexamples,2015, International Conference on Learning Representations
 On the hardness of ro-bust classification,2019, In Hanna M
 Adversar-ial attacks on neural network policies,2017, Workshop Track of the 5th International Conference onLearning Representations
 Nesterov momentum adversarial perturbations in the deep reinforcement learningdomain,2020, International Conference on Machine Learning
 Investigating vulnerabilities of deep neural policies,2021, Conference on Uncertainty inArtificial Intelligence (UAI)
 Understanding neural networks through representationerasure,2016, CoRR
 To-wards deep learning models resistant to adversarial attacks,2018, In 6th International Conference onLearning Representations
 Empirically measur-ing concentration: Fundamental limits on intrinsic robustness,2019, In Hanna M
 On detecting adversarialperturbations,2017, In 5th International Conference on Learning Representations
 Human-level control through deep reinforcement learning,2015, Nature
 Deepfool: A simple andaccurate method to fool deep neural networks,2016, In 2016 IEEE Conference on Computer Vision andPattern Recognition
 Towards robust detection of adversarial ex-amples,2018, In Samy Bengio
 Robust adversarial reinforce-ment learning,2017, International Conference on Learning Representations ICLR
 The odds are odd: A statistical test for detectingadversarial examples,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Intriguing properties of neural networks,2014, In Proceedings of the InternationalConference on Learning Representations (ICLR)
 On adaptive attacks toadversarial example defenses,2020, NeurIPS
 De Fre-itas,2016, Dueling network architectures for deep reinforcement learning
