title,year,conference
 Deep learning with differential privacy,2016, In Proceedings of the 2016 ACM SIGSACconference on computer and communications security
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Extracting training datafrom large language models,2020, arXiv preprint arXiv:2012
 Semi-supervised sequence learning,2015, Advances in neural informationprocessing systems
 Privacy-preserving prediction,2018, In Conference On LearningTheory
 The algorithmic foundations of differential privacy,2014, Found
 Hierarchical neural story generation,2018, arXiv preprintarXiv:1805
 Differentially private set union,2020, In International Conference on MachineLearning
 Neural language models for spelling correction,2019, Masterâ€™s thesis
 The curious case of neural textdegeneration,2019, arXiv preprint arXiv:1904
 Differentially private language models benefit frompublic pre-training,2020, arXiv preprint arXiv:2009
 Differentially private n-gramextraction,2021, arXiv preprint arXiv:2108
 Importance of search andevaluation strategies in neural dialogue modeling,2018, arXiv preprint arXiv:1811
 Towards robust and privacy-preserving text represen-tations,2018, arXiv preprint arXiv:1805
 Differentially private representation for nlp: Formalguarantee and an empirical study on privacy and fairness,2020, arXiv preprint arXiv:2010
 Learning differentially privaterecurrent language models,2017, arXiv preprint arXiv:1710
 Pointer sentinel mixturemodels,2016, arXiv preprint arXiv:1609
 Privacy regularization: Joint privacy-utility optimization in languagemodels,2021, arXiv preprint arXiv:2103
 Renyi differential privacy,2017, In 2017 IEEE 30th Computer Security FoundationsSymposium (CSF)
 Dependency recurrent neural language models for sentencecompletion,2015, In Proc
 Semi-supervised knowledge transfer for deep learning from private training data,2016, arXiv preprintarXiv:1610
 Scalable private learning with pate,2018, arXiv preprint arXiv:1802
 Languagemodels are unsupervised multitask learners,2019, OpenAI blog
 Training production language models without memorizing user data,2020, arXivpreprint arXiv:2009
 Bigpatent: A large-scale dataset for abstractive and coherentsummarization,2019, arXiv preprint arXiv:1906
 Selective differential privacy for languagemodeling,2021, arXiv preprint arXiv:2108
 The trade-offs of private prediction,2020, arXiv preprintarXiv:2007
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 A differentially privatetext perturbation method using a regularized mahalanobis metric,2020, arXiv preprint arXiv:2010
 Privacy risk in machine learning:Analyzing the connection to overfitting,2018, In 2018 IEEE 31st Computer Security FoundationsSymposium (CSF)
