title,year,conference
 Online continual learning with maximal interfered retrieval,2019, In Advancesin Neural Information Processing Systems 
 Gradient based sample selectionfor online continual learning,2019, In Advances in Neural Information Processing Systems
 Riemannianwalk for incremental learning: Understanding forgetting and intransigence,2018, In Proceedings of theEuropean Conference on Computer Vision (ECCV)
 Efficientlifelong learning with a-GEM,2019, In International Conference on Learning Representations
 Continuous online sequence learning with anunsupervised neural network model,2016, Neural computation
 Towards robust evaluations of continual learning,2018, arXiv preprintarXiv:1805
 An empirical investi-gation of catastrophic forgetting in gradient-based neural networks,2013, arXiv preprint arXiv:1312
 Re-evaluating continual learning scenarios: Acategorization and case for strong baselines,2018, arXiv preprint arXiv:1810
 Measuringcatastrophic forgetting in neural networks,2018, In Proceedings of the AAAI Conference on ArtificialIntelligence
 Overcomingcatastrophic forgetting in neural networks,2017, Proc
 A neural dirichlet process mixture modelfor task-free continual learning,2020, In International Conference on Learning Representations
 Gradient episodic memory for continual learning,2017, In Advances in NeuralInformation Processing Systems
 Understand-ing the role of training regimes in continual learning,2020, In H
 Continuallifelong learning with neural networks: A review,2019, Neural Networks
 iCaRL:Incremental classifier and representation learning,2017, In Proc
 Incremental learning of NCMforests for large-scale image classification,2014, In Proc
 Multi-task learning as multi-objective optimization,2018, In Advances inNeural Information Processing Systems
 Continual learning with deep generativereplay,2017, In Advances in Neural Information Processing Systems
 Lifelong robot learning,1995, In The biology and technology ofintelligent autonomous agents
 Functional regularisation for continual learning with gaussian processes,2020, In InternationalConference on Learning Representations
 Three scenarios for continual learning,2019, arXiv preprintarXiv:1904
 Continuallearning with hypernetworks,2020, In International Conference on Learning Representations
 Lifelong learning with dynamicallyexpandable networks,2018, In International Conference on Learning Representations
 Task agnostic continual learning usingonline variational Bayes,2018, arXiv preprint arXiv:1803
 This is the same setting as td es-ed in Section 4,2022,4
