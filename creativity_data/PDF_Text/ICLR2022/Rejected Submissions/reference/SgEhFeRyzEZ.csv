title,year,conference
 A convergence analysis of gradientdescent for deep linear neural networks,2018, In International Conference on Learning Representations
 Assessing the scalability of biologically-motivated deep learning algorithms andarchitectures,2018, In Advances in Neural Information Processing Systems
 The recent excitement about neural networks,1989, Nature
 Learning without feedback: Fixed randomlearning signals allow for feedforward training of deep neural networks,2021, Frontiers in Neuroscience
 Implicit regularization of discrete gradientdynamics in linear neural networks,2019, arXiv:1904
 Explaining the learningdynamics of direct feedback alignment,2017, ICLR
 The implicit bias of depth: How incrementallearning drives generalization,2019, arXiv:1909
 Principled training of neural networks with directfeedback alignment,2019, arXiv:1906
 Direct feedback alignmentscales to modern deep learning tasks and architectures,2020, In Advances in Neural InformationProcessing Systems
 SPike-Train level Direct Feedback Alignment:SidestePPing backProPagation for on-chiP training of sPiking neural nets,2020, Front Neurosci
 Feedback alignment in deePconvolutional networks,2018, arXiv:1812
 Direct feedback alignment provides learning in deep neural networks,2016, arXiv:1609
 The dynamics of learningwith feedback alignment,2020, arXiv:2011
 Learning representations byback-propagating errors,1986, Nature
 A mathematical theory of semanticdevelopment in deep neural networks,2018, arXiv:1810
