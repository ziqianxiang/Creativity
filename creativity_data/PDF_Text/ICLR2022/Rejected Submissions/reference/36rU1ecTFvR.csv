title,year,conference
 Obfuscated gradients give a false senseof security: Circumventing defenses to adversarial examples,2018, In Jennifer G
 Improving ad-versarial robustness via channel-wise activation suppressing,2021, In 9th International Conference onLearning Representations
 Towards evaluating the robustness of neural networks,2017, In2017 IEEE Symposium on Security and Privacy
 Reliable evaluation of adversarial robustness with an ensem-ble of diverse parameter-free attacks,2020, In Proceedings of the 37th International Conference onMachine Learning
 Explaining and harnessing adversarialexamples,2015, In Yoshua Bengio and Yann LeCun (eds
 Uncovering thelimits of adversarial training against norm-bounded adversarial examples,2020, CoRR
 Using pre-training can improve model robustnessand uncertainty,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Manifold regularization for adversarial robustness,2020, CoRR
 Learning multiple layers of features from tiny images,2009, Technical report
 Mixup inference: Better exploiting mixup to defend adversarialattacks,2020, In 8th International Conference on Learning Representations
 Fixing data augmentation to improve adversarial robustness,2021, CoRR
 Featuredenoising for improving adversarial robustness,2019, In IEEE Conference on Computer Visionand Pattern Recognition
 Me-net: Towards effective adversarial robustnesswith matrix estimation,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Defense against adversarial attacks using feature scattering-based adversarial training,2019, In Hanna M
