title,year,conference
 Blind backdoors in deep learning models,2020, arXiv preprint2005
 Extracting training datafrom large language models,2020, arXiv preprint 2012
 Poison attacks against text datasets withconditional adversarially regularized autoencoder,2020, arXiv preprint 2010
 Badnl: Backdoorattacks against nlp models,2020, arXiv preprint 2006
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, arXiv preprint 1712
 A downsampled variant of imagenet as analternative to the CIFAR datasets,2017, arXiv preprint 1707
 An analysis of single-layer networks in unsupervisedfeature learning,2011, In Proceedings of AISTATS
 A backdoor attack against lstm-based text classificationsystems,2019, IEEE Access
 ImageNet: A large-scalehierarchical image database,2009, In Proceedings of CVPR
 STRIP: a defence against trojan attacks on deep neural networks,2019, In Proceedings of ACSAC
 Explaining and harnessing adversarialexamples,2015, In Yoshua Bengio and Yann LeCun (eds
 Badnets: Identifying vulnerabilities in themachine learning model supply chain,2017, arXiv preprint 1708
 Deep residual learning for imagerecognition,2016, In Proceedings of CVPR
 Densely connectedconvolutional networks,2017, In Proceedings of CVPR
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In Proceedings of ICML
 Programmable neural network trojan forpre-trained feature extractor,2019, arXiv preprint 1901
 Model-reuse attacks on deeplearning systems,2018, In Proceedings of CCS
 Is bert really robust? a strong baseline fornatural language attack on text classification and entailment,2020, In Proceedings of AAAI
 Revealing the dark secretsof BERT,2019, In Kentaro Inui
 Weight poisoning attacks on pretrained models,2020, InProceedings of ACL
 Albert: A lite bert for self-supervised learning of language representations,2020, In Proceedingsof ICLR
 Deep learning backdoors,2020, arXivpreprint 2007
 Neural attentiondistillation: Erasing backdoor triggers from deep neural networks,2021, In Proceedings of ICLR
 Pay attention to mlps,2021, arXiv preprint2105
 Fine-pruning: Defending against backdooringattacks on deep neural networks,2018, In Proceedings of RAID
 Trojaning attack on neural networks,2018, In Proceedings of NDSS
 Readingdigits in natural images with unsupervised feature learning,2011, In NIPS Workshop on Deep Learningand Unsupervised Feature Learning
 Onion: A simpleand effective defense against textual backdoor attacks,2021, In Proceedings of EMNLP
 Hidden killer: Invisible textual backdoor attacks with syntactic trigger,2021, In Proceedings ofACL
 Turn the combination lock:Learnable textual backdoor attacks via word substitution,2021, In Proceedings of ACL
 A target-agnostic attack on deep models: Exploiting security vulnera-bilities of transfer learning,2020, In Proceedings of ICLR
 Backdoor pre-trained models can transfer to all,2021, In Proceedings of CCS
 Very deep convolutional networks for large-scale imagerecognition,2015, In Proceedings of ICLR
 Recursive deep models for semantic compositionality over a sentiment treebank,2013, InProceedings of EMNLP
 Man vs,2012, computer: Benchmarking machinelearning algorithms for traffic sign recognition
 Natural backdoor attack on text data,2020, arXiv preprint 2006
 Mlp-mixer: An all-mlp architecture for vision,2021, arXiv preprint 2105
 Pushing the limits of paraphrastic sentence embeddings withmillions of machine translations,2018, In Proceedings of ACL
 Rethinking stealthiness of backdoor attackagainst NLP models,2021, In Proceedings of ACL
 Latent backdoor attacks on deep neuralnetworks,2019, In Proceedings of CCS
 Word-level textual adversarial attacking as combinatorial optimization,2020, In Proceedings of ACL
 Trojaning language models for fun and profit,2020, arXivpreprint 2008
 Aligning books and movies: Towards story-like visual explanations by watchingmovies and reading books,2015, In Proceedings of ICCV
