title,year,conference
 An optimistic perspective on offlinereinforcement learning,2020, In International Conference on Machine Learning
 Hindsight experience replay,2017, arXivpreprint arXiv:1707
 Model-based offline planning,2020, arXiv preprintarXiv:2008
 Distributed distributional deterministicpolicy gradients,2018, arXiv preprint arXiv:1804
 Curriculum learning,2009, InProceedings of the 26th annual international conference on machine learning
 Neuro-dynamic programming,1996, Athena Scientific
 The importance of pessimism in fixed-dataset policy optimization,2020, arXiv preprint arXiv:2009
 Scaling data-driven robotics with reward sketching and batch reinforcement learning,2019, arXiv preprintarXiv:1909
 Deep reinforcement learn-ing in a handful of trials using probabilistic dynamics models,2018, arXiv preprint arXiv:1805
 Learning what data to learn,2017, arXivpreprint arXiv:1702
 Diagnosing bottlenecks in deep q-learning algorithms,2019, In International Conference on Machine Learning
 D4rl: Datasets for deepdata-driven reinforcement learning,2020, arXiv preprint arXiv:2004
 Benchmarks for deep off-policy evaluation,2021, arXiv preprint arXiv:2103
 Addressing function approximation error in actor-critic methods,2018, In International Conference on Machine Learning
 Off-policy deep reinforcement learning withoutexploration,2018, 2018b
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,1050, In international conference on machine learning
 Evolved policy gradients,2018, arXiv preprint arXiv:1802
 Recurrent ex-perience replay in distributed reinforcement learning,2018, In International conference on learningrepresentations
 Not all samples are created equal: Deep learning withimportance sampling,2018, In International conference on machine learning
 Morel: Model-based offline reinforcement learning,2020, arXiv preprint arXiv:2005
 Offline reinforcement learningwith fisher divergence critic regularization,2021, In International Conference on Machine Learning
 Stabilizing off-policy q-learning via bootstrapping error reduction,2019, arXiv preprintarXiv:1906
 Conservative q-learning for offlinereinforcement learning,2020, arXiv preprint arXiv:2006
 Revisiting prioritized experience replay: A valueperspective,2021, arXiv preprint arXiv:2102
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 Self-imitation learning,2018, In InternationalConference on Machine Learning
 Deep exploration viabootstrapped dqn,2016, Advances in neural information processing systems
 Count-based exploration withneural density models,2017, In International conference on machine learning
 Sample-efficient batch reinforcement learning for dialogue management optimization,2011, ACM Transactionson Speech and Language Processing (TSLP)
 Mbrl-lib: Amodular library for model-based reinforcement learning,2021, arXiv preprint arXiv:2104
 Reinforcement learning for sepsis treatment: Baselines and analysis,2019, 2019
 Adaptive trade-offs in off-policy learning,2020, InInternational Conference on Artificial Intelligence and Statistics
 Prioritized experience replay,2015, arXivpreprint arXiv:1511
 Keep doingwhat worked: Behavioral modelling priors for offline reinforcement learning,2020, arXiv preprintarXiv:2002
 Attentive experience replay,2020, In Proceedings of theAAAI Conference on Artificial Intelligence
 Reinforcement learning: An introduction,2018, MIT press
 Empirical study of off-policy policyevaluation for reinforcement learning,2019, arXiv preprint arXiv:1911
 Bdd100k: A diverse driving video database with scalable annotation tooling,2018, arXivpreprint arXiv:1805
 Mopo: Model-based offline policy optimization,2020, arXiv preprintarXiv:2005
 Offline learning from demonstrations andunlabeled experience,2020, arXiv preprint arXiv:2011
