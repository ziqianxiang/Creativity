title,year,conference
 High-dimensional dynamics of generalization error in neuralnetworks,2017, arXiv preprint arXiv:1710
 Fine-grained analysis ofoptimization and generalization for overparameterized two-layer neural networks,2019, In InternationalConference on Machine Learning
 Generalized random forests,2019, The Annals ofStatistics
 Benign overfitting in linearregression,2020, Proceedings of the National Academy of Sciences
 Overfitting or perfect fitting? risk bounds forclassification and regression rules that interpolate,2018, In Advances in neural information processingsystems
 Reconciling modern machine-learningpractice and the classical bias-variance trade-off,2019, Proceedings of the National Academy of Sciences
 Random forests,2001, Machine learning
 Classification and regressiontrees,1984, CRC press
 Finite-sample analysis of interpolating linear classifiers in theoverparameterized regime,2020, arXiv preprint arXiv:2004
 Implicit bias of gradient descent for wide two-layer neural networkstrained with the logistic loss,2020, arXiv preprint arXiv:2002
 Stiffness: AneW perspective on generalization in neural netWorks,2019, arXiv preprint arXiv:1901
 Jamming transition as a paradigm to understand the loss landscape of deepneural networks,2019, Physical Review E
 Gener-alisation error in learning with random features and the hidden manifold model,2020, arXiv preprintarXiv:2002
 Linearized two-layersneural networks in high dimension,2019, arXiv preprint arXiv:1904
 Characterizing implicit bias interms of optimization geometry,1832, In International Conference on Machine Learning
 On calibration of modern neuralnetworks,2017, arXiv preprint arXiv:1706
 Surprises in high-dimensional ridgeless least squares interpolation,2019, arXiv preprint arXiv:1903
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Random decision forests,1995, In Proceedings of 3rd international conference on documentanalysis and recognition
 Physical attribute predictionusing deep residual neural networks,2018, arXiv preprint arXiv:1812
 Assessing generalization ofsgd via disagreement,2021, arXiv preprint arXiv:2106
 Learning multiple layers of features from tiny images,2009, 2009
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Towards explaining the regularization effect of initial largelearning rate in training neural networks,2019, arXiv preprint arXiv:1907
 Deep learning face attributes in the wild,2015, InProceedings of International Conference on Computer Vision (ICCV)
 The generalization error of random features regression: Preciseasymptotics and double descent curve,2019, arXiv preprint arXiv:1908
 Integral probability metrics and their generating classes of functions,1997, Advances inApplied Probability
 Deepdouble descent: Where bigger models and more data hurt,2020, In International Conference on LearningRepresentations
 Sample complexity of testing the manifold hypothesis,2010, InAdvances in neural information processing systems
 Learning withnoisy labels,2013, In Advances in neural information processing systems
 Towardsunderstanding the role of over-parametrization in generalization of neural networks,2018, arXiv preprintarXiv:1805
 Making sense of random forest probabilities: a kernelperspective,2018, arXiv preprint arXiv:1812
 Automatic differentiation inpytorch,2017, 2017
 Rfcde: Random forests for conditional density estimation,2018, arXivpreprint arXiv:1804
 Random features for large-scale kernel machines,2008, In Advances inneural information processing systems
 Deep learning is robust to massivelabel noise,2017, arXiv preprint arXiv:1705
 Conditional density estimationwith neural networks: Best practices and benchmarks,2019, arXiv preprint arXiv:1903
 Theoretical views of boosting,1999, In European conference on computational learningtheory
 Understanding machine learning: From theory toalgorithms,2014, Cambridge university press
 Neural kernels without tangents,2020, arXiv preprint arXiv:2003
 Combating label noise in deep learning using abstention,2019, arXiv preprint arXiv:1905
 SciPy 1,2020,0: Fundamental Algorithms for Scientific Computing in Python
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, arXiv preprint arXiv:1708
 Disparate vulnerability: On theunfairness of privacy attacks against machine learning,2019, arXiv preprint arXiv:1906
 Wide residual networks,2016, arXiv preprint arXiv:1605
 Understandingdeep learning requires rethinking generalization,2016, arXiv preprint arXiv:1611
 Learning not to learn in the presence of noisy labels,2020, arXiv preprintarXiv:2002
