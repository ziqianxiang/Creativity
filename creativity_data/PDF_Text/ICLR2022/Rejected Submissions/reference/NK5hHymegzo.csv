title,year,conference
 Tensorflow: A system for large-scalemachine learning,2016, In 12th USENIX symposium on operating systems design and implementation(OSD116)
 Backward feature correction: How deep learning performs deeplearning,2020, arXiv preprint arXiv:2001
 Feature purification: How adversarial training performs robustdeep learning,2020, arXiv preprint arXiv:2005
 Convergence guarantees forrmsprop and adam in non-convex optimization and their comparison to nesterov acceleration onautoencoders,2018, 2018
 On the convergence of a class of adam-typealgorithms for non-convex optimization,2019, In ICLR 2019 : 7th International Conference on LearningRepresentations
 Natural language processing,2003, Annual review of information science andtechnology
 On the convergence properties of non-euclidean extragradi-ent methods for variational inequalities with generalized monotone operators,2015, ComputationalOptimization and Applications
 Problem complexity and method efficiency in optimization,1983, 1983
 Training gans withoptimism,2018, In ICLR 2018 : International Conference on Learning Representations 2018
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Generative adversarial nets,2014, In Advances in NeuralInformation Processing Systems 27
 Deep Learning,2016, 2016
 The limits of min-max optimizationalgorithms: convergence to spurious non-critical sets,2020, arXiv preprint arXiv:2006
 Solving variational inequalities withstochastic mirror-prox algorithm,2011, Stochastic Systems
 Adam: A method for stochastic optimization,2015, In ICLR 2015 :International Conference on Learning Representations 2015
 The extragradient method for finding saddle points and other problems,1976, Matecon
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Convergence analysis of two-layer neural networks with relu activation,2017, InAdvances in Neural Information Processing Systems
 Algorithmic regularization in over-parameterizedmatrix sensing and neural networks with quadratic activations,2018, In COLT
 Learning over-parametrized two-layer neuralnetworks beyond ntk,2020, In Conference on Learning Theory
 Adaptive gradient methods with dynamicbound of learning rate,2019, In ICLR 2019 : 7th International Conference on Learning Representations
 Dual extrapolation and its applications to solving variational inequalities and relatedproblems,2007, Mathematical Programming
 A modification of the arrow-hurwicz method for search of saddle points,1980, MathematicalNotes
 Unsupervised representation learning with deepconvolutional generative adversarial networks,2015, arXiv preprint arXiv:1511
 On the convergence of adam and beyond,2018, In ICLR2018 : International Conference on Learning Representations 2018
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, arXiv preprint arXiv:1708
 Adadelta: An adaptive learning rate method,2012, arXiv preprint arXiv:1212
 On the convergence of adaptivegradient methods for nonconvex optimization,2018, arXiv preprint arXiv:1808
 Understanding the generalization of adam inlearning neural netWorks With proper regularization,2021, arXiv preprint arXiv:2108
 According to Lemma D,2022,3 and Lemma D
