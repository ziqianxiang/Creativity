title,year,conference
 Learning representations by maximizingmutual information across views,2019, arXiv preprint arXiv:1906
 The im algorithm: a variational approach to information maximiza-tion,2004, Advances in neural information processing systems
 Mine: mutual information neural estimation,2018, arXiv preprintarXiv:1801
 Emerging properties in self-supervised vision transformers,2021, arXiv preprintarXiv:2104
 Exploring simple siamese representation learning,2020, arXiv preprintarXiv:2011
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Seed:Self-supervised distillation for visual representation,2021, arXiv preprint arXiv:2101
 Estimating information flow in deep neural networks,2019, In ICML
 Supervised contrastive learning forpre-trained language model fine-tuning,2020, arXiv preprint arXiv:2011
 Noise-contrastive estimation: A new estimation principlefor unnormalized statistical models,2010, In Proceedings of the Thirteenth International Conference onArtificial Intelligence and Statistics
 Learning deep representations by mutual information estimationand maximization,2018, arXiv preprint arXiv:1808
 Supervised contrastive learning,2020, arXiv preprintarXiv:2004
 Mixco: Mix-up contrastive learningfor visual representation,2020, arXiv preprint arXiv:2010
 Compress: Self-supervisedlearning by compressing representations,2020, arXiv preprint arXiv:2010
 Learning multiple layers of features from tiny images,2009, 2009
 Tiny imagenet visual recognition challenge,2015, CS 231N
 I-mix: Adomain-agnostic strategy for contrastive representation learning,2020, arXiv preprint arXiv:2010
 Sgdr: Stochastic gradient descent with warm restarts,2016, arXivpreprint arXiv:1608
 Towards understanding regularization inbatch normalization,2018, arXiv preprint arXiv:1809
 Estimating divergence functionalsand the likelihood ratio by convex risk minimization,2010, IEEE Transactions on Information Theory
 Representation learning with contrastive predictivecoding,2018, arXiv preprint arXiv:1807
 Estimation of entropy and mutual information,2003, Neural computation
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In Proceedings of the IEEE international conference on computer vision
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Understanding the limitations of variational mutual informationestimators,2019, arXiv preprint arXiv:1910
 Multi-label contrastive predictive coding,2020, arXiv preprintarXiv:2007
 Branchynet: Fast inferencevia early exiting from deep neural networks,2016, In 2016 23rd International Conference on PatternRecognition (ICPR)
 Contrastive multiview coding,2019, arXiv preprintarXiv:1906
 Contrastive representation distillation,2019, arXivpreprint arXiv:1910
 Whatmakes for good views for contrastive learning,2020, arXiv preprint arXiv:2005
 Deep learning and the information bottleneck principle,2015, In 2015IEEE Information Theory Workshop (ITW)
 Towards domain-agnosticcontrastive learning,2021, In International Conference on Machine Learning
 Exploringcross-image pixel contrast for semantic segmentation,2021, arXiv preprint arXiv:2101
 On thenoisy gradient descent that generalizes as sgd,2020, In International Conference on Machine Learning
 On mutual in-formation in contrastive learning for visual representations,2020, arXiv preprint arXiv:2005
 A new outlook on shannonâ€™s information measures,1991, IEEE transactions oninformation theory
 Large batch training of convolutional networks,2017, arXivpreprint arXiv:1708
 Wide residual networks,2016, arXiv preprint arXiv:1605
 Scan:A scalable neural networks framework towards compact and efficient models,2019, arXiv preprintarXiv:1906
 42 and 43,2020, Surprisingly
