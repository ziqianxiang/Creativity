title,year,conference
 An optimistic perspective on offlinereinforcement learning,2020, In International Conference on Machine Learning
 Averaged-DQN: Variance reduction and stabiliza-tion for deep reinforcement learning,2017, In Proceedings of the 34th International Conference onMachine Learning
 Implicit quantile networks fordistributional reinforcement learning,2018, In Jennifer G
 Distributional reinforcementlearning with quantile regression,2018, In Sheila A
 Benchmarking deep rein-forcement learning for continuous control,2016, In Proceedings of The 33rd International Conferenceon Machine Learning
 Addressing function approximation error inactor-critic methods,2018, In Proceedings of the 35th International Conference on Machine Learning
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, In Proceedings of the 35thInternational Conference on Machine Learning
 Soft actor-critic algo-rithms and applications,2018, Technical report
 Reproducibility of bench-marked deep reinforcement learning tasks for continuous control,2017, CoRR
 Controlling overesti-mation bias with truncated mixture of continuous distributional quantile critics,2020, In Proceedingsof the 37th International Conference on Machine Learning
 Maxmin q-learning: Controllingthe estimation bias of q-learning,2020, In 8th International Conference on Learning Representations
 SUNRISE: A simple unifiedframework for ensemble learning in deep reinforcement learning,2021, In Proceedings of the 38thInternational Conference on Machine Learning
 Why Mheads are better than one: Training a diverse ensemble of deep networks,2015, CoRR
 Continuous control with deep reinforcement learning,2016, In 4thInternational Conference on Learning Representations
 Deep exploration viabootstrapped dqn,2016, In Advances in Neural Information Processing Systems
