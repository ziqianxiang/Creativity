title,year,conference
 Lipschitz continuity in model-based reinforcementlearning,2018, In International Conference on Machine Learning
 Combating the compounding-errorproblem with a multi-step model,2019, arXiv preprint arXiv:1905
 Solving uncertain markov decision processes,2001, 2001
 A model-based reinforcement learning with adversarial trainingfor online recommendation,2019, Advances in Neural Information Processing Systems
 Openai gym,2016, arXiv preprint arXiv:1606
 Gan-based planning model in deepreinforcement learning,2020, In International Conference on Artificial Neural Networks
 Variational model-based policyoptimization,2020, arXiv preprint arXiv:2006
 Deep reinforcement learning in ahandful of trials using probabilistic dynamics models,2018, In Advances in Neural Information Processing Systems
 PILCO: A model-based and data-efficient approach topolicy search,2011, In International Conference on Machine Learning (ICML)
 Adversarial feature learning,2016, arXiv preprintarXiv:1605
 Adversarially learned inference,2016, arXiv preprint arXiv:1606
 Off-dynamics reinforcement learning: Training for transfer with domain classifiers,2020, In International Conferenceon Learning Representations
 C-learning: Learning to achieve goals viarecursive classification,2020, In International Conference on Learning Representations
 Value-aware loss function for model-basedreinforcement learning,2017, In Artificial Intelligence and Statistics
 Addressing Function Approximation Error in Actor-CriticMethods,2018, International Conference on Machine Learning (ICML)
 Generative Adversarial Nets,2014, In Advances in Neural Information ProcessingSystems (NIPS)
 The value equivalence principle formodel-based reinforcement learning,2020, arXiv preprint arXiv:2011
 Dream to control: Learning behaviorsby latent imagination,2019, In International Conference on Learning Representations
 Reinforcement learningwith misspecified model classes,2013, In 2013 IEEE International Conference on Robotics and Automation
 Near-optimal reinforcement learning in polynomial time,2002, Machine learning
 Morel : Model-based offlinereinforcement learning,2020, ArXiv
 Learning plannable representationswith causal infogan,2018, In Advances in Neural Information Processing Systems
 Objective mismatch in model-basedreinforcement learning,2020, In Learning for Dynamics and Control
 Algorithmic frameworkfor model-based deep reinforcement learning with theoretical guarantees,2019, In ICLR (Poster)
 Risk-sensitive reinforcement learning,2002, Machine learning
 Control-oriented model-basedreinforcement learning with implicit differentiation,2021, arXiv preprint arXiv:2106
 Value prediction network,2017, arXiv preprint arXiv:1707
 Path integral networks: End-to-end differentiableoptimal control,2017, arXiv preprint arXiv:1706
 A game theoretic framework for model basedreinforcement learning,2020, In International Conference on Machine Learning
 A Reduction of Imitation Learning and StructuredPrediction to No-Regret Online Learning,2011, In International Conference on Artificial Intelligence and Statistics(AISTATS)
 Agnostic system identification for model-based reinforcement learning,2012, InICML
 Outcome-driven reinforce-ment learning via variational inference,2021, arXiv preprint arXiv:2104
 Improvedtechniques for training gans,2016, Advances in neural information processing Systems
 Internal rewards mitigate agent boundedness,2010, In ICML
 Universal planning networks:Learning generalizable representations for visuomotor control,2018, In International Conference on MachineLearning
 Model regularization for stable sample rollouts,2014, In UAI
 Deepmind control suite,2018, arXiv preprint arXiv:1801
 Information Theoretic MPC for Model-Based Reinforcement Learning,2017, In InternationalConference on Robotics and Automation (ICRA)
 Mopo: Model-based offline policy optimization,2020, arXiv preprint arXiv:2005
 Combo:Conservative offline model-based policy optimization,2021, arXiv preprint arXiv:2102
 Modeling purposeful adaptive behavior with the principle of maximum causal entropy,2010, 2010
2Before presenting the proof of Lemma 3,2022,1 itself
