title,year,conference
 A nonparametric estimation of the entropy for absolutely continuousdistributions,1976, IEEE Trans
 Deep variational informationbottleneck,2016, arXiv
 The im algorithm: A variational approach to information maxi-mization,2003, In Proceedings of the 16th International Conference on Neural Information ProcessingSystems
 MINE:mutual information neural estimation,2018, arXiv
 Estimation of Integral Functionals of a Density,1995, The Annals ofStatistics
 Demographic dialectal variation in socialmedia: A case study of african-american english,2016, arXiv
 CLUB: Acontrastive log-ratio upper bound of mutual information,2020, 119
 Improving disentangled text representation learning with information-theoretic guidance,2020, arXiv
 A novel estimator of mutual information forlearning to disentangle textual representations,2021, arXiv
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv
 Information measures in perspective,2010, InternationalStatisticaIReView
 On the estimation of entropy,1993, Annals of the Institute of StatisticalMathematics
 Learning deep representations by mutual information estimationand maximization,2019, 2019
 Causalitydetection based on information-theoretic approaches in time series analysis,2007, Physics Reports
 Learningdiscrete representations via information maximizing self-augmented training,1558, In Doina Precupand Yee Whye Teh (eds
 Estimation of entropy and other functionals of a multivariate density,1989, Annals of theInstitute of Statistical Mathematics
 Adam: A method for stochastic optimization,2014, 2014
 Discriminative clustering by regularized informa-tion maximization,2010, In J
 Learning multiple layers of features from tiny images,2009, 2009
 MNIST handwritten digit database,2010, 2010
 Mixout: Effective regularization to finetunelarge-scale pretrained language models,2019, arXiv
 Exponential concentration for mutual informationestimation with application to forests,2012, In F
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv
 Monte carlo gradientestimation in machine learning,2020, J
 Ensemble estimation of generalized mutualinformation with applications to genomics,2021, IEEE Transactions on Information Theory
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 Estimating divergence functionalsand the likelihood ratio by convex risk minimization,2010, IEEE Transactions on Information Theory
 Estimation of entropy and mutual information,2003, Neural computation
 On the estimation of information measuresof continuous distributions,2020, arXiv
 On variationalbounds of mutual information,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Null it out:Guarding protected attributes by iterative nullspace projection,2020, arXiv preprint arXiv:2004
 Exponential concentration of a density functionalestimator,2014, In Z
 Understanding the limitations of variational mutual informationestimators,2019, arXiv
 Sliced score matching: A scalable approachto density and score estimation,2020, In Uncertainty in Artificial Intelligence
 Ensemble estimators for multivariate entropyestimation,2013, IEEE Transactions on Information Theory
 Approximating mutual informa-tion by maximum likelihood density ratio estimation,2008, In New challenges for feature selection indata mining and knowledge discovery
 On mutualinformation maximization for representation learning,2020, In International Conference on LearningRepresentations
 Representation learning with contrastive predictivecoding,2018, arXiv
 Empirical estimation of information measures: A literature guide,2019, Entropy
 Empirical entropy manipulation forreal-world problems,1996, Advances in neural information processing systems
 HUggingface's transformers:State-of-the-art natural language processing,2019, arXiv
 InfoVAE: Information maximizing variationalautoencoders,2017, arXiv
2 Experimental DetailsModel Architecture,1000, For the encoder
