title,year,conference
 The recurrent neuraltangent kernel,2021, In International Conference on Learning Representations
 The convergence of sparsified gradient methods,2018, In Advances in Neural InformationProcessing Systems
 Fedbe: Making Bayesian model ensemble applicable to feder-ated learning,2021, In International Conference on Learning Representations
 A generalized neural tangent kernelanalysis for two-layer neural networks,2020, In Advances in Neural Information Processing Systems
 EMNIST: ExtendingMNIST to handwritten letters,2017, In International Joint Conference on Neural Networks
 Gradient descent provably optimizesover-parameterized neural networks,2019, In International Conference on Learning Representations
 Optimization theory for ReLu neural networkstrained with normalization layers,2020, In International Conference on Machine Learning
 Deep residual learning for image recog-nition,2016, In International Conference on Computer Vision and Pattern Recognition
 Measuring the effects of non-identical datadistribution for federated visual classification,2019, arXiv preprint arXiv:1909
 FL-NTK: A neural tangent kernel-basedframework for federated learning convergence analysis,2021, arXiv preprint arXiv:2105
 Neural tangent kernel: Convergence and gen-eralization in neural networks,2018, In Advances in Neural Information Processing Systems
 Ad-vances and open problems in federated learning,2021, Foundations and Trends in Machine Learning
 Scaffold: Stochastic controlled averaging for federated learning,2020, InInternational Conference on Machine Learning
 Tensor decompositions and applications,2009, SIAM review
 Learning multiple layers of features from tiny images,2009, Master thesis
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Wide neural networks of any depth evolve as linear modelsunder gradient descent,2019, In Advances in Neural Information Processing Systems
 Finite versus infinite neural networks: an empirical study,2020, In Advancesin Neural Information Processing Systems
 FedBN: Federated learn-ing on non-iid features via local batch normalization,2021, In International Conference on LearningRepresentations
 Deepdouble descent: Where bigger models and more data hurt,2020, In ICLR 2020 : Eighth InternationalConference on Learning Representations
 Machine learning with membership privacy us-ing adversarial regularization,2018, In ACM SIGSAC Conference on Computer and CommunicationsSecurity
 Adaptive federated optimization,2021, In InternationalConference on Learning Representations
 Federated knowl-edge distillation,2020, arXiv preprint arXiv:2011
 Federated multi-tasklearning,2017, In Advances in Neural Information Processing Systems
 Achieving statistical optimality of federated learning:Beyond stationary points,2021, arXiv preprint arXiv:2106
 Tackling the objective in-consistency problem in heterogeneous federated optimization,2020, In Advances in Neural InformationProcessing Systems
 A field guide to feder-ated optimization,2021, arXiv preprint arXiv:2107
 Fashion-MNIST: a novel image dataset for bench-marking machine learning algorithms,2017, arXiv preprint arXiv:1708
 Tensor programs iib: Architectural universality of neural tangent kerneltraining dynamics,2021, In International Conference on Machine Learning
 Federatedlearning with non-iid data,2018, arXiv preprint arXiv:1806
 Deep leakage from gradients,2019, In Advances in NeuralInformation Processing Systems
