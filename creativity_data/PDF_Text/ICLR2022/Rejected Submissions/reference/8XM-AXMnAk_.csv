title,year,conference
 The recurrent neuraltangent kernel,2020, In International Conference on Learning Representations
 Onexact computation with an infinitely wide neural net,2019, In Neural Information Processing Systems
 Fine-grained analysis ofoptimization and generalization for overparameterized two-layer neural networks,2019, In InternationalConference on Machine Learning
 Active and passive learning of linear separators underlog-concave distributions,2013, In Conference on Learning Theory
 Margin based active learning,2007, InConference on Learning Theory
 Generalization bounds of stochastic gradient descent for wide and deepneural networks,2019, Advances in Neural Information Processing Systems
 Improving generalization with active learning,1994, Machinelearning
 BackPACK: Packing more into backprop,2020, InInternational Conference on Learning Representations
 Hierarchical sampling for active learning,2008, In Internationalconference on Machine learning
 Graph neural tangent kernel: Fusing graph neural networks with graph kernels,2019, arXiv preprintarXiv:1905
 Learning generative visual models from few trainingexamples: An incremental bayesian approach tested on 101 object categories,2004, In 2004 conferenceon computer vision and pattern recognition workshop
 Finite depth and width corrections to the neural tangent kernel,2020, InInternational Conference on Learning Representations
 Theory of disagreement-based active learning,2014, Foundations and TrendsÂ® inMachine Learning
 Deep residual learning for imagerecognition,2016, In IEEE Conference on Computer Vision and Pattern Recognition
 Active learning by learning,2015, In AAAI Conference on ArtificialIntelligence
 Neural tangent kernel: convergence andgeneralization in neural networks,2018, In Neural Information Processing Systems
 Efficient statistical tests: A neural tangentkernel approach,2021, In International Conference on Machine Learning
 Active learning in the overparameterized and interpolatingregime,2019, CoRR
 A new measure of rank correlation,1938, Biometrika
 Understanding black-box predictions via influence functions,2017, InInternational Conference on Machine Learning
 Learning multiple layers of features from tiny images,2009, 2009
 Wide neural networks of any depth evolve as linear modelsunder gradient descent,2019, In Neural Information Processing Systems
 Algorithmic stability and hypothesiscomplexity,2017, In International Conference on Machine Learning
 Influence selectionfor active learning,2021, arXiv preprint arXiv:2108
 A bayesian perspective ontraining speed and model selection,2020, In Neural Information Processing Systems
 Parting with illusions aboutdeep active learning,2019, arXiv preprint arXiv:1912
 Foundations of machine learning,2018, MITpress
 Gradients as features for deep representation learning,2020, InInternational Conference on Learning Representations
 Margin-based active learning for structured output spaces,2006, In MachineLearning: ECML 2006
 Toward optimal active learning through sampling estimationof error reduction,2001, In International Conference on Machine Learning
 Revisiting the train loss: anefficient performance estimator for neural architecture search,2020, arXiv preprint arXiv:2006
 Active learning for convolutional neural networks: A core-setapproach,2018, In International Conference on Learning Representations
 Active learning literature survey,2009, Technical report
 Multiple-instance active learning,2007, In Neural InformationProcessing Systems
 Egl++: Extending expected gradient length to active learning for human poseestimation,2021, arXiv preprint arXiv:2104
 Very deep convolutional networks for large-scale imagerecognition,2015, In International Conference on Learning Representations
 Fixmatch: Simplifying semi-supervised learning withconsistency and confidence,2020, arXiv preprint arXiv:2001
 Generalizing to unseen domains via adversarial data augmentation,2018, In Neural InformationProcessing Systems
 A new active labeling method for deep learning,2014, In International JointConference on Neural Networks
 Querying discriminative and representative samples for batch modeactive learning,2015, ACM Transactions on Knowledge Discovery from Data
 Optimization of graph neuralnetworks: Implicit acceleration by skip connections and more depth,2021, In International Conferenceon Machine Learning
 Active learning using uncertainty information,2016, In InternationalConference on Pattern Recognition
 Learning loss for active learning,2019, In IEEE Conference on ComputerVision and Pattern Recognition
 Initial trainingdata selection for active learning,2011, In Proceedings of the 5th International Conference on UbiquitousInformation Management and Communication
 Scalingneural tangent kernels via sketching and random features,2021, arXiv preprint arXiv:2106
 Understand-ing deep learning requires rethinking generalization,2017, In International Conference on LearningRepresentations
 Diverse mini-batch active learning,2019, arXiv preprint arXiv:1901
 Uncertainty-based active learning with instability estimation for textclassification,2012, ACM Transactions on Speech and Language Processing (TSLP)
