title,year,conference
 High-dimensional dynamics of generalization error in neuralnetworks,2020, Neural Networks
 Square attack: a query-efficient black-box adversarial attack via random search,2020, ArXiv
 Reconciling modern machine-learning practice and the classical bias-variance trade-off,2019, Proceedings of the National Academyof Sciences
 Data Sci,2020,
 Unlabeled dataimproves adversarial robustness,2019, ArXiv
 Robust overfittingmay be mitigated by properly learned smoothening,2021, In International Conference on LearningRepresentations
 Reliable evaluation of adversarial robustness with an ensemble of diverseparameter-free attacks,2020, In ICML
 Imagenet: A large-scale hierarchicalimage database,2009, In CVPR
 A model of double descent for high-dimensional binary linear classification,2019, ArXiv
 ImProved regularization of convolutional neural networkswith cutout,2017, ArXiv
 Data Profiling for adversarial training: On the ruin ofProblematic data,2021, ArXiv
 Exploringmemorization in adversarial training,2021, ArXiv
 Classification in the presence of label noise: A survey,2014, IEEETransactions on Neural Networks and Learning Systems
 Explaining and harnessing adversarialexamples,2015, CoRR
 Uncovering the limitsof adversarial training against norm-bounded adversarial examples,2020, ArXiv
 On calibration of modern neuralnetworks,2017, ArXiv
 Surprises in high-dimensional ridgeless leastsquares interpolation,2019, ArXiv
 Benchmarking neural network robustness to commoncorruptions and perturbations,2019, ArXiv
 Distilling the knowledge in a neural network,2015, ArXiv
 Implicit regularization ofrandom feature models,2020, In ICML
 Analytic study of double descent in binary classification:The impact of loss,2020, 2020 IEEE International Symposium on Information Theory (ISIT)
 Learning multiple layers of features from tiny images,2009, 2009
 Tiny imagenet visual recognition challenge,2015, 2015
 Sgdr: Stochastic gradient descent with warm restarts,2017, arXiv: Learning
 Towards deep learningmodels resistant to adversarial attacks,2018, ArXiv
 The generalization error of random features regression: Preciseasymptotics and double descent curve,2019, arXiv: Statistics Theory
 Deepdouble descent: Where bigger models and more data hurt,2020, ArXiv
 Reading digits in naturalimages with unsupervised feature learning,2011, 2011
 Exploring general-ization in deep learning,2017, In NIPS
 Towards the science ofsecurity and privacy in machine learning,2016, ArXiv
 Fixing data augmentation to improve adversarial robustness,2021, ArXiv
 Overfitting in adversarially robust deep learning,2020, ArXiv
 Very deep convolutional networks for large-scale imagerecognition,2015, CoRR
 Low curvature activations reduce overfittingin adversarial training,2021, ArXiv
 Cyclical learning rates for training neural networks,2017, 2017 IEEE Winter Conferenceon Applications ofComputer Vision (WACV)
 Learning from noisy labels with deepneural networks: A survey,2020, ArXiv
 Relating adversarially robust generalization to flatminima,2021, ArXiv
 Is robustness the cost ofaccuracy? - a comprehensive study on the robustness of 18 deep image classification models,2018, InECCV
 Robustness may be at oddswith accuracy,2019, arXiv: Machine Learning
 A closer look ataccuracy vs,2020, robustness
 Rethinking bias-variance trade-offfor generalization of neural networks,2020, In ICML
 Understanding generalization inadversarial training via the bias-variance decomposition,2021, ArXiv
 Wide residual networks,2016, ArXiv
 mixup: Beyond empiricalrisk minimization,2018, ArXiv
 The learning ratestarts at 0,1000,1 and gradually decrease to 0 following a cosine function for a total of 1000 epochs
