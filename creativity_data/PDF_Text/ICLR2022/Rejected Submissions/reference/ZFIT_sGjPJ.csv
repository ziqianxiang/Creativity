title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, International Conference on MachineLearning (ICML)
 Maximum resilience of artificial neuralnetworks,2017, In International Symposium on Automated Technology for Verification and Analysis
 Parsevalnetworks: Improving robustness to adversarial examples,2017, International Conference on MachineLearning (ICML)
 Certified adversarial robustness via randomizedsmoothing,2017, International Conference on Machine Learning (ICML)
 Explaining and harnessing adversarialexamples,2015, International Conference on Learning Representations (ICLR)
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Safety verification of deep neuralnetworks,2017, In International Conference on Computer Aided Verification
 Auto-encoding variational bayes,2014, International Conference onLearning Representations (ICLR)
 Imagenet classification with deep convolu-tional neural networks,2012, In Advances in Neural Information Processing Systems (NeurIPS)
 Certifiedrobustness to adversarial examples with differential privacy,2019, In IEEE Symposium on Security andPrivacy (SP)
 Robustness certificates for sparse adversarial attacks by ran-domized ablation,2020, In Association for the Advancement of Artificial Intelligence (AAAI)
 Certified adversarial robustness withadditive noise,2019, Advances in Neural Information Processing Systems (NeurIPS)
 An approach to reachability analysis for feed-forward reluneural networks,2017, arXiv preprint arXiv:1706
 Fully convolutional networks for semanticsegmentation,2015, In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Stochastic backpropagation andapproximate inference in deep generative models,2014, International Conference on Machine Learning(ICML)
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, InAdvances in Neural Information Processing Systems (NeurIPS)
 A convex relaxationbarrier to tight robust verification of neural networks,2019, Advances in Neural Information ProcessingSystems (NeurIPS)
 Black-box smoothing: Aprovable defense for pretrained classifiers,2020, arXiv preprint arXiv:2003
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Evaluating robustness of neural networks with mixedinteger programming,2019, International Conference on Learning Representations (ICLR)
 On adaptive attacks toadversarial example defenses,2020, arXiv preprint arXiv:2002
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning (ICML)
 Randomizedsmoothing of all shapes and sizes,2020, International Conference on Machine Learning (ICML)
autograd import Variablefrom torch,2019,distributions
