title,year,conference
 Reinforcement learning: Theory andalgorithms,2019, CS Dept
 Accountable off-policy evaluation withkernel Bellman statistics,2020, In Hal Daume In and Aarti Singh (eds
 Addressing function approximation error inactor-critic methods,1582, In Jennifer G
 Clipped action policy gradient,2018, In Jennifer Dy and AndreasKrause (eds
 Im-proved training of wasserstein gans,2017, In I
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, In Jennifer G
 Is q-learning provably effi-cient? In S,2018, Bengio
 Doubly robust off-policy value and gradient estimation fordeterministic policies,2020, In H
 Sample complexity of asynchronousq-learning: Sharper analysis and variance reduction,2020, In H
 Breaking the curse of horizon: Infinite-horizon off-policy estimation,2018, In Advances in Neural Information Processing Systems
 Spectral normalizationfor generative adversarial networks,2018, In International Conference on Learning Representations
 Safe and efficient off-policyreinforcement learning,2016, In D
 Learning to control in metric space with optimalregret,2019, In 2019 57th Annual Allerton Conference on Communication
 Remember and forget for experience replay,2019, In KamalikaChaudhuri and Ruslan Salakhutdinov (eds
 Eligibility traces for off-policy policyevaluation,2000, In Proceedings of the Seventeenth International Conference on Machine Learning
 Adaptive trade-offs in off-policy learning,2020, In SilviaChiappa and Roberto Calandra (eds
 Prioritized experience replay,2016, InICLR
 Off-policy actor-critic with shared experiencereplay,2020, In Hal Daume In and Aarti Singh (eds
 In Eric P,2014, Xing and Tony Jebara (eds
 Policy gradient methodsfor reinforcement learning with function approximation,1999, In Proceedings of the 12th InternationalConference on Neural Information Processing Systems
 Taylor expansion policy optimization,2020, In Hal DaumeIII and Aarti Singh (eds
 Data-efficient off-policy policy evaluation for reinforcementlearning,2016, In Maria Florina Balcan and Kilian Q
 Importance sampling: a review,2010, Wiley Interdisciplinary Reviews:Computational Statistics
 Towards optimal off-policy evaluation for rein-forcement learning with marginalized importance sampling,2019, In Advances in Neural InformationProcessing Systems
 Off-policy evaluation viathe regularized lagrangian,2020, Advances in Neural Information Processing Systems
 Asymptotically efficient off-policy evaluation for tabular reinforce-ment learning,2020, In Silvia Chiappa and Roberto Calandra (eds
 Near-optimal provable uniform convergence in offlinepolicy evaluation for reinforcement learning,2021, In Arindam Banerjee and Kenji Fukumizu (eds
 Mopo: Model-based offline policy optimization,2020, In H
 Suppose Po have N independent samples,2022, By Hoeffding's inequality
