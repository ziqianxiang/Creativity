title,year,conference
 Sanitychecks for SalienCy maps,2018, In Samy Bengio
 Fair-washing explanations with off-manifold detergent,2020, In Proceedings of the 37th International Conference onMachine Learning
 On pixel-wise explanations for non-linear classifier decisions by layer-wise relevancepropagation,2015, PLOS ONE
 How to explain individual classification decisions,2010, J
 Concise explanationsof neural networks using adversarial training,2020, In Proceedings of the 37th International Conference onMachine Learning
 Explaining and harnessing adversarial exam-ples,2015, In Yoshua Bengio and Yann LeCun (eds
 Comparing measures of sparsity,2009, IEEE Trans
 FAR: A general framework for attribu-tional robustness,2020, CoRR
 Quantifying perceptual distortion ofadversarial examples,2019, CoRR
 Learning multiple layers of features from tiny images,2012, University of Toronto
 Functional adversarial attacks,2019, In Hanna M
 Interpretable Machine Learning,2019, 2019
”Why should I trust you?”： Explaining the predictionsof any classifier,2016, In Balaji Krishnapuram
 Learning important features through propagat-ing activation differences,2017, In Doina Precup and Yee Whye Teh (eds
 Deep inside convolutional netWorks： Visualisingimage classification models and saliency maps,2014, In Yoshua Bengio and Yann LeCun (eds
 Smoothgrad: removingnoise by adding noise,2017, CoRR
 Striving for simplicity:The all convolutional net,2015, In Yoshua Bengio and Yann LeCun (eds
 Axiomatic attribution for deep netWorks,2017, In DoinaPrecup and Yee Whye Teh (eds
 Intriguing properties of neural netWorks,2014, In Yoshua Bengio and Yann LeCun (eds
 HoW to manipulate cnns to make them lie: thegradcam case,2019, CoRR
 Spatially transformed ad-versarial examples,2018, In 6th International Conference on Learning Representations
 Top-down neural attention byexcitation backprop,2016, In Bastian Leibe
