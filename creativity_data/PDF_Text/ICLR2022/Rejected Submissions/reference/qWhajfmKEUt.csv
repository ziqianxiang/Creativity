title,year,conference
 Intrinsic dimension ofdata representations in deep neural networks,2019, In Advances in Neural Information ProcessingSystems
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2021, In International Conference on MachineLearning
 Evasion attacks against machine learning at test time,2013, In JointEuropean Conference on Machine Learning and Knowledge Discovery in Databases
 Towards evaluating the robustness of neural networks,2017, In 2017Ieee Symposium on Security and Privacy (SP)
 On evaluating adversarialrobustness,2019, arXiv preprint arXiv:1902
 Unlabeled data improvesadversarial robustness,2019, Advances in Neural Information Processing Systems
 Deep networksfrom the principle of rate reduction,2020, arXiv preprint arXiv:2010
 Catastrophic forgettingmeets negative transfer: Batch spectral shrinkage for safe transfer learning,2019, In Advances in NeuralInformation Processing Systems
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In International Conference on Machine Learning
 Robustbench: a standardized adversarial robustness bench-mark,2020, arXiv preprint arXiv:2010
 Adversarial attacks on medical machine learning,2019, Science
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 On calibration of modern neuralnetworks,2022, In International Conference on Machine Learning
 Learning multiple layers of features from tiny images,2009, 2009
 Ole: Orthogonal low-rank embedding-a plug and play geometric loss for deep learning,2018, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Delving into transferable adversarial ex-amples and black-box attacks,2017, In International Conference on Learning Representations
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 Bag of tricks for adversarialtraining,2021, In International Conference on Learning Representations
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Prevalence of neural collapse during the terminalphase of deep learning training,2020, Proceedings of the National Academy of Sciences
 Overfitting in adversarially robust deep learning,2020, InInternational Conference on Machine Learning
 Adversarial training is a form of data-dependentoperator norm regularization,2018, In H
 Spectral signatures in backdoor attacks,2018, In Advancesin Neural Information Processing Systems
 Adversarially robust estimate and risk analysis inlinear regression,2021, In International Conference on Artificial Intelligence and Statistics
 Robust regression and lasso,2008, In Proceedingsof the 21st International Conference on Neural Information Processing Systems
 Cifs:Improving adversarial robustness of cnns via channel-wise importance-based feature selection,2021, InInternational Conference on Machine Learning
 Learning diverse anddiscriminative representations via the principle of maximal coding rate reduction,2020, Advances inNeural Information Processing Systems
 Defense against adversarial attacks using feature scattering-basedadversarial training,2019, Advances in Neural Information Processing Systems
 Attacks which do not kill training make adversarial learning stronger,2020, In InternationalConference on Machine Learning
