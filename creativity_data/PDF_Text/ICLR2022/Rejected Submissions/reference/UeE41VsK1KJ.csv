title,year,conference
 Modular meta-learning,2018, In CoRL
 A convergence theory for deep learning via over-parameterization,2019, In ICML
 Meta-learning by adjusting priors based on extended pac-bayes theory,2018, InICML
 A theory of learning from different domains,2010, Machine learning
 Multilabel classification with label correlations and missing labels,2014, InAAAI
 Generalizing from several related classificationtasks to a new unlabeled sample,2011, In Advances in Neural Information Processing Systems
 Modular meta-learning with shrinkage,2020, In Advances in NeuralInformation Processing Systems
 Multiple model-basedreinforcement learning,2002, Neural Computation
 Gradient descent findsglobal minima of deep neural networks,2019, In ICML
 Model-agnostic meta-learning for fast adaptationof deep networks,2017, In ICML
 Online meta-learning,2019, InICML
 Reservoir computing com-pensates slow response of chemosensor arrays exposed to fast varying gas concentrations incontinuous monitoring,2015, Sensors and Actuators B: Chemical
 Visual concept-metaconceptlearning,2019, In Advances in Neural Information Processing Systems
 Towards a critical race method-ology in algorithmic fairness,2020, In Proceedings of the 2020 conference on fairness
 Probably approximately correct learning,1990, In AAAI
 Densely connectedconvolutional networks,2017, In CVPR
 Improving multi-label classification with missing labels by learning label-specific fea-tures,2019, Information Sciences
 Label propagation for deep semi-supervised learning,2019, In CVPR
 Advancesand open problems in federated learning,2021, Foundations and Trends in Machine Learning
 Adam: A method for stochastic optimization,2015, In ICLR
 Rademacher processes and bounding the risk offunction learning,2000, In High dimensional probability II
 Learning multiple layers of features from tiny images,2009, 2009
 A tutorial on energy-basedlearning,2006, Predicting structured data
 Pseudo-label: The simple and efficient semi-supervised learning method for deepneural networks,2013, In Workshop on challenges in representation learning
 PAC-Bayesian model averaging,1999, In COLT
 Modular universal reparameterization: Deep multi-tasklearning across diverse domains,2019, In Advances in Neural Information Processing Systems
 Domain generalization via invariantfeature representation,2013, In ICML
 Deep online learning via meta-learning:Continual adaptation for model-based RL,2019, In ICLR
 A survey on transfer learning,1041, IEEE Transactions on KnowledgeandData Engineering
 A pac-bayesian bound for lifelong learning,2014, In ICML
 Ensemble learning: A survey,2018, WIREs Data Mining and KnowledgeDiscovery
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, InICLR
 Reward is enough,2021, ArtificialIntelligence
 Task understanding from confusing multi-taskdata,2020, In ICML
 A surveyon deep transfer learning,2018, In International conference on artificial neural networks
 A theory of the learnable,1984, Communications of the ACM
 On the uniform convergence of relative frequencies of eventsto their probabilities,1971, Theory of Probability and its Applications
 Deep visual domain adaptation: A survey,2018, Neurocomputing
 Multi-task reinforcement learning with softmodularization,2020, In Advances in Neural Information Processing Systems
 Large-scale multi-label learningwith missing labels,2014, In ICML
 Ensemble machine learning: methods and applications,2012, Springer
 Domain generalization invision: A survey,2021, arXiv preprint arXiv:2103
 Ensemble learning,2021, In Machine Learning
