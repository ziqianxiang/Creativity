title,year,conference
 Uncertainty-Based ContinualLearning with Adaptive Regularisation,2019, In the Advances in Neural Information ProcessingSystems
 Redundant Feature Pruning for Acceler-ated Inference in Deep Neural Networks,2019, Neural Networks
 Layer Normalisation,2016, In the Neural InformationProcessing Systems Deep Learning Symposium
 Learning Long-term Dependencies withGradient Descent is Difficult,1994, IEEE Transactions on Neural Networks
 Imagenet: A Large-Scale Hierarchical Image Database,2009, In the IEEE Conference on Computer Vision and PatternRecognition
 Uncertainty-GuidedContinual Learning with Bayesian Neural Networks,2020, In the International Conference onLearning Representations
 Catastrophic Forgetting in Connectionist Networks,1999, Trends in CognitiveSciences
 One Ticket to Win Them All: GeneralisingLottery Ticket Initialisations Across Datasets and Optimisers,2019, In the Advances in NeuralInformation Processing Systems Reproducibility Challenge
 Learning Both Weights and Connections forEfficient Neural Network,2015, In the Advances in Neural Information Processing Systems
 Deep Residual Learning for ImageRecognition,2016, In the IEEE Conference on Computer Vision and Pattern Recognition
 Flat Minima,1997, Neural Computation
 Batch Normalisation: Accelerating Deep Network Trainingby Reducing Internal Covariate Shift,2015, In the International Conference on Machine Learning
 Overcoming Catastrophic For-getting in Neural Networks,2017, In the Proceedings ofthe National Academy ofSciences
 Learning Multiple Layers of Features from Tiny Images,2009, In Tech Report ofthe University of Toronto
 Plastic and Stable Gated Classifiers for Continual Learning,2021, In the IEEEConference on Computer Vision and Pattern Recognition Workshop on Continual Learning inComputer Vision
 Gradient-Based Learning Ap-plied to Document Recognition,1998, Proceedings of the IEEE
 Visualising the LossLandscape of Neural Nets,2018, In the Advances in Neural Information Processing Systems
 Energy-Based Models for Contin-ual Learning,2020, arXiv preprint arXiv:2011
 Learning without Forgetting,2017, In the IEEE Transactions on PatternAnalysis and Machine Intelligence
 Gradient Episodic Memory for Continual Learn-ing,2017, In the Advances in Neural Information Processing Systems
 Bayesian Methods for Adaptive Models,1992, Doctoral Dissertation
 Batch-level Experience Replay withReview for Continual Learning,2020, In the IEEE Conference on Computer Vision and PatternRecognition Workshops of Continual Leanrning in Vision
 Catastrophic Interference in Connectionist Networks:The Sequential Learning Problem,1989, In Psychology of Learning and Motivation
 iCaRL:Incremental Classifier and Representation Learning,2017, In the IEEE conference on ComputerVision and Pattern Recognition
 Learning Representations byBack-Propagating Errors,1986, Nature
 Weight Normalisation: A Simple Reparameterisation to Ac-celerate Training of Deep Neural Networks,2016, In the Advances in Neural Information ProcessingSystems
 Overcoming CatastrophicForgetting with Hard Attention to the Task,2018, In the International Conference on MachineLearning
 Highway Networks,2015, In theWorkshop of International Conference on Machine Learning
 Exploring the Vulnera-bility of Deep Neural Networks: A Study of Parameter Corruption,2021, In the AAAI Conferenceon Artificial Intelligence
 Three Scenarios for Continual Learning,2019, arXivpreprint arXiv:1904
 Fashion-MNIST: A Novel Image Dataset forBenchmarking Machine Learning Algorithms,2017, arXiv preprint arXiv:1708
 Aggregated ResidualTransformations for Deep Neural Networks,2017, In the IEEE Conference on Computer Vision andPattern Recognition
 Lifelong Learning with Dynam-ically Expandable Networks,2018, In the International Conference on Learning Representations
 Neural Architecture Search with Reinforcement Learning,2017, In theInternational Conference on Learning Representations
