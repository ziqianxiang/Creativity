title,year,conference
 Adef: an iterative algorithm to constructadversarial deformations,2018, arXiv preprint arXiv:1804
 Understanding and improving fast adversarialtraining,2020, arXiv preprint arXiv:2007
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning
 Improved generalization bounds for robustlearning,2019, In Algorithmic Learning Theory
 On the rademacher complexity of linear hy-pothesis sets,2020, arXiv preprint arXiv:2007
 Recent advances in adversarial trainingfor adversarial robustness,2021, arXiv preprint arXiv:2102
 Unrestricted adversarial examples,2018, arXiv preprint arXiv:1809
 Curriculum adversarial training,2018, arXiv preprintarXiv:1805
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, In 2017ieee symposium on security and privacy (sp)
 Unlabeled dataimproves adversarial robustness,2019, arXiv preprint arXiv:1905
 Cat: Customized adver-sarial training for improved robustness,2020, arXiv preprint arXiv:2002
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In ICML
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Mma training: Directinput space margin maximization through adversarial training,2018, arXiv preprint arXiv:1812
 Adversarial risk and robust-ness: General definitions and implications for the uniform distribution,2018, In Advances in NeuralInformation Processing Systems
 Boost-ing adversarial attacks with momentum,2018, In Proceedings of the IEEE conference on computervision and pattern recognition
 Arotation and a translation suffice: Fooling cnns with simple transformations,2018, 2018
 Unsupervised domain adaptation by backpropagation,2015, InInternational conference on machine learning
 Motivatingthe rules of the game for adversarial example research,2018, arXiv preprint arXiv:1807
 Adversarially robust distillation,2020, InProceedings of the AAAI Conference on Artificial Intelligence
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 On the effectiveness of intervalbound propagation for training verifiably robust models,2018, arXiv preprint arXiv:1810
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Benchmarking neural network robustness to commoncorruptions and surface variations,2018, arXiv preprint arXiv:1807
 Robust pre-training by adversarialcontrastive learning,2020, In NeurIPS
 Adversarial logit pairing,2018, arXiv preprintarXiv:1803
 Adversarial risk bounds for binary classification via function trans-formation,2018, arXiv preprint arXiv:1810
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Towards defending multiple adversarial perturbations via gated batch normaliza-tion,2020, arXiv preprint arXiv:2012
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 Bag of tricks for adversarialtraining,2020, arXiv preprint arXiv:2010
 Boosting adversarialtraining with hypersphere embedding,2020, arXiv preprint arXiv:2002
 Understanding adversarial robust-ness through loss landscape geometries,2019, arXiv preprint arXiv:1907
 Improvingmodel robustness with latent distribution locally and globally,2021, arXiv preprint arXiv:2107
 Certified defenses against adversarial exam-ples,2018, arXiv preprint arXiv:1801
 Semidefinite relaxations for certifying ro-bustness to adversarial examples,2018, arXiv preprint arXiv:1811
 Foolbox: A python toolbox to benchmarkthe robustness of machine learning models,2017, In Reliable Machine Learning in the Wild Workshop
 Overfitting in adversarially robust deep learning,2020, InInternational Conference on Machine Learning
 Ad-versarially robust generalization requires more data,2018, arXiv preprint arXiv:1804
 Certifiable distributional robustness withprincipled adversarial training,2017, arXiv preprint arXiv:1710
 Improving the generalization ofadversarial training with domain adaptation,2018, arXiv preprint arXiv:1810
 Deep coral: Correlation alignment for deep domain adaptation,2016, InEuropean conference on computer vision
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Exploring the space of adversarial images,2016, In 2016 InternationalJoint Conference on Neural Networks (IJCNN)
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 On theconvergence and robustness of adversarial training,2019, In ICML
 Improvingadversarial robustness requires revisiting misclassified examples,2019, In International Conference onLearning Representations
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Scaling provable adversarialdefenses,2018, arXiv preprint arXiv:1805
 Spatially trans-formed adversarial examples,2018, arXiv preprint arXiv:1801
 Intriguing properties of adversarial training at scale,2019, arXiv preprintarXiv:1906
 Dverge: diversifying vulnerabilities for en-hanced robust generation of ensembles,2020, arXiv preprint arXiv:2009
 Rademacher complexity for adversariallyrobust generalization,2019, In International Conference on Machine Learning
 Interpreting adversarialrobustness: A view from decision surface in input space,2018, arXiv preprint arXiv:1810
 Wide residual networks,2016, arXiv preprintarXiv:1605
 Adversariallyrobust generalization just requires more unlabeled data,2019, arXiv preprint arXiv:1906
 You only propagateonce: Accelerating adversarial training via maximal principle,2019, arXiv preprint arXiv:1905
 Defense against adversarial attacks using feature scattering-basedadversarial training,2019, Advances in Neural Information Processing Systems
 Attacks which do not kill training make adversarial learning stronger,2020, In InternationalConference on Machine Learning
