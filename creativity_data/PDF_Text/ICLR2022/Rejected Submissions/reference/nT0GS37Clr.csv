title,year,conference
 The convergence of sparsified gradient methods,2018, In Advances in Neural InformationProcessing Systems 31: NeurIPS
 The convergence of sparsified gradient methods,2018, In Advances in Neural InformationProcessing Systems
 Estimating or propagating gradientsthrough stochastic neurons for conditional computation,2013, arXiv preprint arXiv:1308
 signsgd withmajority vote is communication efficient and fault tolerant,2019, In 7th International Conference onLearning Representations
 Analyzing federatedlearning through an adversarial lens,2019, In International Conference on Machine Learning
 Machine learning with adversaries: Byzan-tine tolerant gradient descent,2017, In Advances in Neural Information Processing Systems
 LEAF: A benchmark for federated settings,2018, CoRR
 Sui confini della probabilita,1929, In Atti del Congresso Internazionale deiMatematici: Bologna del 3 al 10 de settembre di 1928
 EMNIST: extendingMNIST to handwritten letters,2017, In 2017 International Joint Conference on Neural Networks
 Big neural networks waste capacity,2013, arXiv preprintarXiv:1301
 Local model poisoning attacksto byzantine-robust federated learning,2020, In Srdjan Capkun and Franziska Roesner (eds
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In Proceedings of the Thirteenth International Conference on Artificial Intelligenceand Statistics
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In Proceedings of the IEEE internationalconference on computer vision
 Measuring the effects of non-identical datadistribution for federated visual classification,2019, arXiv preprint arXiv:1909
 Advancesand open problems in federated learning,2019, arXiv preprint arXiv:1912
 Federated learning: Strategies for improving communication efficiency,2016, arXivpreprint arXiv:1610
 Learning multiple layers of features from tiny images,2009, 2009
 Lotteryfl:Personalized and communication-efficient federated learning with lottery ticket hypothesis onnon-iid datasets,2020, CoRR
 IBM federated learning: an enter-prise framework white paper V0,2020,1
 The hidden vulnerability of dis-tributed learning in byzantium,2018, In Proceedings of the 35th International Conference on MachineLearning
 Adaptive federated optimization,2020, In InternationalConference on Learning Representations
 Manipulating the byzantine: Optimizing model poisoningattacks and defenses for federated learning,2021, In Proceedings of the 28th Network and DistributedSystem Security Symposium
 Back to the drawing board:A critical evaluation of poisoning attacks on federated learning,2021, arXiv preprint arXiv:2108
 Supermasks in superposition,2020, In Advances in Neural InformationProcessing Systems 33: NeurIPS
 Generalized byzantine-tolerant sgd,2018, arXivpreprint arXiv:1802
 Byzantine-robust distributedlearning: Towards optimal statistical rates,2018, In Jennifer G
