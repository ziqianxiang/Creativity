title,year,conference
 Partitioned variationalinference: A unified framework encompassing federated and continual learning,2018, arXiv preprintarXiv:1811
 Concept drift detection and adaptation for federated and continual learning,2021, CoRR
 On bridging generic and personalized federated learning,2021, arXivpreprint arXiv:2107
 Exploiting shared represen-tations for personalized federated learning,2021, In arXiv preprint arXiv:2102
 Faster non-convex federated learning via global and local momentum,2020, arXiv preprintarXiv:2012
 Heterofl: Computation and communication efficient feder-ated learning for heterogeneous clients,2021, In International Conference on Learning Representations
 Personalized federated learning with moreauenvelopes,2020, In Advances in Neural Information Processing Systems
 Sgd: General analysis and improved rates,2019, In International Conference on MachineLearning
 Federatedlearning with compression: Unified analysis and sharp guarantees,2021, In International Conference onArtificial Intelligence and Statistics
 Federated learning of a mixture of global and local models,2020, arXivpreprint arXiv:2002
 Measuring the effects of non-identical datadistribution for federated visual classification,2019, arXiv preprint arXiv:1909
 Ad-vances and open problems in federated learning,2019, arXiv preprint arXiv:1912
 Mime: Mimicking centralized stochastic algorithms infederated learning,2020, arXiv preprint arXiv:2008
 Scaffold: Stochastic controlled averaging for federated learning,2020, InInternational Conference on Machine Learning
 Overcomingcatastrophic forgetting in neural networks,2017, Proceedings of the national academy of sciences
 A unifiedtheory of decentralized sgd with changing topology and local updates,2020, In International Conferenceon Machine Learning
 Ditto: Fair and robust federated learningthrough personalization,2021, In International Conference on Machine Learning
 On the convergence offedavg on non-iid data,2020, In International Conference on Learning Representations
 Learning without forgetting,2017, IEEE transactions on pattern analysisand machine intelligence
 Ensemble distillation for robust modelfusion in federated learning,2020, In Advances in Neural Information Processing Systems
 No fear of heterogeneity:Classifier calibration for federated learning with non-iid data,2021, arXiv preprint arXiv:2106
 Achieving linear convergence infederated learning under objective and systems heterogeneity,2021, arXiv preprint arXiv:2102
 Agnostic federated learning,2019, In KamalikaChaudhuri and Ruslan Salakhutdinov (eds
 R2: An efficient mcmc samplerfor probabilistic programs,2014, In Proceedings of the AAAI Conference on Artificial Intelligence
 Communication trade-offs for synchronized distributedsgd with large step size,2019, In Advances in Neural Information Processing Systems
 icarl:Incremental classifier and representation learning,2017, In Proceedings of the IEEE conference onComputer Vision and Pattern Recognition
 Adaptive federated optimization,2021, In InternationalConference on Learning Representations
 Robust federatedlearning: The case of affine distribution shifts,2020, In Hugo Larochelle
 Progressive neural networks,2016, arXiv preprintarXiv:1606
 Overcoming forgetting in federated learning on non-iid data,2019, CoRR
 Tackling the objectiveinconsistency problem in heterogeneous federated optimization,2020, arXiv preprint arXiv:2007
 Pyhessian: Neural networksthrough the lens of the hessian,2020, In Xintao Wu
 SOLA: continual learning with second-order lossapproximation,2020, CoRR
 Optimization and generaliza-tion of regularization-based continual learning: a loss approximation viewpoint,2020, arXiv preprintarXiv:2006
 Bayesian nonparametric federated learning of neural networks,2019, In InternationalConference on Machine Learning
 Which algorithmic choices matter at which batch sizes? insightsfrom a noisy quadratic model,2019, In Advances in Neural Information Processing Systems
 Parallelized stochasticgradient descent,2010, In NIPS
