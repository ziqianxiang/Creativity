title,year,conference
 Efficientlifelong learning with a-gem,2018, In International Conference on Learning Representations
 Long live the lottery:The existence of winning tickets in lifelong learning,2020, In International Conference on LearningRepresentations
 Truly sparse neural networksat scale,2021, arXiv preprint arXiv:2102
 Towards robust evaluations of continual learning,2019, In Privacy inMachine Learning and Artificial Intelligence workshop
 Model-agnostic meta-learning for fast adaptationof deep networks,2017, In International Conference on Machine Learning
 Recent advances in open set recognition:A survey,2020, IEEE transactions on pattern analysis and machine intelligence
 Guided cnn for generalized zero-shot and open-setrecognition using visual and semantic prototypes,2020, Pattern Recognition
 Sparsity indeep learning: Pruning and growth for efficient inference and training in neural networks,2021, arXivpreprint arXiv:2102
 Re-evaluating continual learn-ing scenarios: A categorization and case for strong baselines,2018, In NeurIPS Continual learningWorkshop
 Squeeze-and-excitation networks,2018, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Continual learning of a mixed sequence of similar anddissimilar tasks,2020, Advances in Neural Information Processing Systems
 Overcom-ing catastrophic forgetting in neural networks,2017, Proceedings of the national academy of sciences
 Learning without forgetting,2017, IEEE transactions on pattern analysisand machine intelligence
 Packnet: Adding multiple tasks to a single network by iterativepruning,2018, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Class-incremental learning: survey and performance evaluation,2020, arXiv preprintarXiv:2010
 Few-shot lifelong learning,2021, In Proceedings ofthe AAAI Conference on Artificial Intelligence
 Catastrophic interference in connectionist networks: Thesequential learning problem,1989, Psychology of learning and motivation
 The stability-plasticity dilemma: Inves-tigating the continuum from catastrophic forgetting to age-limited learning effects,2013, Frontiers inpsychology
 On-line contrastive divergence with generative replay: Experience replay without storing data,2016, arXivpreprint arXiv:1610
 Scalable training of artificial neural networks with adaptive sparse connec-tivity inspired by network science,2018, Nature communications
 icarl:Incremental classifier and representation learning,2017, In Proceedings of the IEEE conference onComputer Vision and Pattern Recognition
 Learning to learn without forgetting by maximizing transfer and minimizing interfer-ence,2018, In International Conference on Learning Representations
 Progressive neural networks,2016, arXiv preprintarXiv:1606
 Continual learning with deep generativereplay,2017, In Advances in Neural Information Processing Systems
 Self-attention meta-learner forcontinual learning,2021, In Proceedings of the 20th International Conference on Autonomous Agentsand MultiAgent Systems
 Spacenet: Make free spacefor continual learning,2021, Neurocomputing
 Three scenarios for continual learning,2018, In ContinualLearning Workshop NeurIPS
 Brain-inspired replay for continuallearning with artificial neural networks,2020, Nature communications
 Supermasks in superposition,2020, Advances in Neural InformationProcessing Systems
 Fashion-mnist: a novel image dataset for benchmark-ing machine learning algorithms,2017, arXiv preprint arXiv:1708
 Lifelong learning with dynamicallyexpandable networks,2018, In International Conference on Learning Representations
 Scalable and order-robust con-tinual learning with additive parameter decomposition,2019, In International Conference on LearningRepresentations
