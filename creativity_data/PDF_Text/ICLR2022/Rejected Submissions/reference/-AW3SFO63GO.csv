title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Improvingadversarial robustness via channel-wise activation suppressing,2021, In ICLR
 Towards evaluating the robustness of neural networks,2017, In IEEESymposium on Security and Privacy (SP)
 Rays: A ray searching method for hard-label adversarial attack,2020, InKDD
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In ICML
 Bert: Pre-training of deepbidirectional transformers for language understanding,2019, In NAACL
 Analysis of classifiersâ€™ robustness to adversarialperturbations,2018, In Machine Learning
 Effi-cient and accurate estimation of lipschitz constants for deep neural networks,2019, In NeurIPS
 Adversarial spheres,2018, In arXiv preprint arXiv:1801
 Explaining and harnessing adversarialexamples,2015, In ICLR
 Deep residual learning for image recog-nition,2016, In CVPR
 A singular value perspective on model ro-bustness,2020, In arXiv preprint arXiv:2012
 Learning multiple layers of features from tiny images,2009, 2009
 Adversarial examples in the physical world,2017, InICLR
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In CVPR
 Adversarial neural pruning with latent vulnerability suppres-sion,2020, In ICML
 In ICLR,2018, 2018
 Bag of tricks for adversarialtraining,2021, In ICLR
 Distillation asa defense to adversarial perturbations against deep neural networks,2016, In IEEE Symposium onSecurity and Privacy (SP)
 Fixing data augmentation to improve adversarial robustness,2021, In arXiv preprintarXiv:2103
 Towards a unified game-theoretic view of adversarialperturbations and robustness,2021, In arXiv preprint arXiv:2103
 Ad-versarially robust generalization requires more data,2018, In NeurIPS
 Accessorize to a crime:Real and stealthy attacks on state-of-the-art face recognition,2016, In SIGSAC
 Intriguing properties of neural networks,2014, In ICLR
 A boundary tilting persepective on the phenomenon of adversarialexamples,2016, In arXiv preprint arXiv:1608
 In ICLR,2019, 2019
 High-frequency component helps explainthe generalization of convolutional neural networks,2020, In CVPR
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In ICLR
 Feature denoisingfor improving adversarial robustness,2019, In CVPR
 Interpreting adversarial examples by activation promotion and suppression,2019, In arXiv preprintarXiv:1904
 In ICML,2019, 2019
 Interpreting adversarially trained convolutional neural net-works,2018, In ICML
