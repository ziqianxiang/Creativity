title,year,conference
 Towards the unification and robustness of perturbation and gradient basedexplanations,2021, arXiv preprint arXiv:2102
 On the robustness of interpretability methods,2018, arXivpreprint arXiv:1806
 Explaining by removing: A unified framework formodel explanation,2020, arXiv preprint arXiv:2011
 Interpretation of neural networks is fragile,2019, InProceedings of the AAAI Conference on Artificial Intelligence
 Regularisation of neural net-works by enforcing lipschitz continuity,2021, Machine Learning
 A survey of methods for explaining black box models,2018, ACM computing surveys(CSUR)
 A learning theoretic per-spective on local explainability,2020, arXiv preprint arXiv:2011
 Probabilistic lipschitzanalysis of neural networks,2020, In International Static Analysis Symposium
 Instance-wise feature grouping,2020, Advances in Neural Information Processing Systems
 Rise: Randomized input sampling for explanation ofblack-box models,2018, arXiv preprint arXiv:1806
 ” why should i trust you?” explaining thepredictions of any classifier,2016, In Proceedings of the 22nd ACM SIGKDD international conferenceon knowledge discovery and data mining
 Cxplain: Causal explanations for model interpretation underuncertainty,2019, arXiv preprint arXiv:1910
 Not just a blackbox: Learning important features through propagating activation differences,2016, arXiv preprintarXiv:1605
 Smoothgrad:removing noise by adding noise,2017, arXiv preprint arXiv:1706
 Con-ditional variable importance for random forests,2008, BMC bioinformatics
 On the faithfulness measurements formodel interpretations,2021, arXiv preprint arXiv:2104
 Invase: Instance-wise variable selectionusing neural networks,2018, In International Conference on Learning Representations
 Visualizing deep neural networkdecisions: Prediction difference analysis,2017, arXiv preprint arXiv:1702
