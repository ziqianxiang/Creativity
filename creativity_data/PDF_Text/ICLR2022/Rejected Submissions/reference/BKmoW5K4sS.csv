title,year,conference
 One-network adversarialfairness,2019, In Proceedings ofthe AAAI Conference on Artificial Intelligence
 Areductions approach to fair classification,2018, 2018
 Support vector machines under adversarial labelnoise,2011, In Asian Conference on Machine Learning
 Convex optimization,2004, Cambridgeuniversity press
 API design for machine learningsoftware: experiences from the scikit-learn project,2013, In ECML PKDD Workshop: Languages forData Mining and Machine Learning
 Analysis of causative attacks against svms learning from datastreams,2017, In Proceedings of the 3rd ACM on International Workshop on Security And PrivacyAnalytics
 Why unbiased computational processes can lead to discriminativedecision procedures,2013, In Discrimination and privacy in the information society
 Building classifiers with independencyconstraints,2009, In 2009 IEEE International Conference on Data Mining Workshops
 Fair classification with adversarial perturba-tions,2021, ArXiv
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, arXiv preprint arXiv:1712
 Algorithmic decisionmaking and the cost of fairness,2017, In Proceedings of the 23rd ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining
 Learning under selective labelsin the presence of expert consistency,2018, arXiv preprint arXiv:1807
 Fairness throughawareness,2012, In Innovations in Theoretical Computer Science (ITCS)
 Decoupled Classifiersfor Group-Fair and Efficient Machine Learning,2018, In Fairness
 Badnets: Identifying vulnerabilities in themachine learning model supply chain,2017, arXiv preprint arXiv:1708
 Equality of opportunity in supervised learning,2016, InAdvances in neural information processing systems
 Ad-versarial machine learning,2011, In Proceedings of the 4th ACM workshop on Security and artificialintelligence
 Identifying and correcting label bias in machine learning,2020, InInternational Conference on Artificial Intelligence and Statistics
 Data preprocessing techniques for classification without discrimi-nation,2012, Knowledge and Information Systems
 Fairness-aware learning through regular-ization approach,2011, In 2011 IEEE 11th International Conference on Data Mining Workshops
 Exponentiated gradient versus gradient descent for linearpredictors,1997, information and computation
 Inherent trade-offs in the fair determi-nation of risk scores,2016, arXiv preprint arXiv:1609
 Inherent trade-offs in the fairdetermination of risk scores,2017, In Innovations in Theoretical Computer Science (ITCS)
 Stronger data poisoning attacks break datasanitization defenses,2018, arXiv preprint arXiv:1811
 Counterfactual fairness,2017, In Advancesin Neural Information Processing Systems
 Noise-tolerant fair classification,2019, InAdvances in Neural Information Processing Systems
 Data poisoning attacks on factorization-based collaborative filtering,2016, In Advances in neural information processing systems
 Ensuring fairnessbeyond the training data,2020, arXiv preprint arXiv:2007
 A surveyon bias and fairness in machine learning,2021, ACM Computing Surveys (CSUR)
 Exacerbating algorith-mic bias through fairness attacks,2021, In Proceedings of the AAAI Conference on Artificial Intelligence
 The security of latent dirichlet allocation,2015, In Artificial Intelligence andStatistics
 New analysis and algorithm for learning with driftingdistributions,2012, In International Conference on Algorithmic Learning Theory
 Towards poisoning of deep learning algorithms with back-gradientoptimization,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 Fairness throughrobustness: Investigating robustness disparity in deep learning,2021, In Proceedings of the 2021 ACMConference on Fairness
 Fairness for robust log lossclassification,2020, In AAAI
 Fr-train: A mutual information-based approach to fair and robust training,2020, In International Conference on Machine Learning
 Sample selection for fair androbust training,2021, ArXiv
 Poisoning attacks on algorithmic fairness,2021, In EuropeanConference on Machine Learning and Knowledge Discovery in Databases
 A distributionally robustapproach to fair classification,2020, arXiv preprint arXiv:2007
 To split or not to split: The impact ofdisparate treatment in classification,2021, IEEE Transactions on Information Theory
 Robust optimization for fairness with noisy protected groups,2020, arXiv preprintarXiv:2002
 Unlocking fairness: a trade-off revisited,2019, In Advances inNeural Information Processing Systems
 Supportvector machines under adversarial label contamination,2015, Neurocomputing
 Training individually fair ml models withsensitive subspace robustness,2019, In International Conference on Learning Representations
 Inherent tradeoffs in learning fair representations,2019, In Advances inneural information processing systems
 Constant prediction always outputs the majority label in the clean dataset,2018, The enforcedfairness level Î´ is 0 and 0
 SamplingDp Minority - Adv,1000, Sampling0	0
 SamplingDp Minority - Adv,2018, Sampling0	0
