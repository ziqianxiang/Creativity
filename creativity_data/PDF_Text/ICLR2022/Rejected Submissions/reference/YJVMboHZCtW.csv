title,year,conference
 Spectrally-normalized margin bounds for neuralnetworks,2017, arXiv preprint arXiv:1706
 Reconciling modern machine-learning practice and the classical bias-variance trade-off,2019, Proceedings of the National Academyof Sciences
 Large-scale machine learning with stochastic gradient descent,2010, In Proceedings ofCOMPSTAT’2010
 Selection via proxy: Efficient data selection for deeplearning,2020, In International Conference on Learning Representations
 Size-independent sample complexity ofneural networks,2018, In Conference On Learning Theory
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Analysis of generalizability of deep neural networks based onthe complexity of decision boundary,2020, In 2020 19th IEEE International Conference on MachineLearning and Applications (ICMLA)
 Neural networks behave as hash encoders:An empirical study,2021, arXiv preprint arXiv:2101
 Assessing generalization ofsgd via disagreement,2021, arXiv preprint arXiv:2106
 How to escapesaddle points efficiently,1724, In International Conference on Machine Learning
 Sgd on neural networks learns functions of increasing complexity,2019, Advancesin Neural Information Processing Systems
 Contragan: Contrastive learning for conditional image gen-eration,2020, In H
 Characterizing the decision boundary of deep neuralnetworks,2019, arXiv preprint arXiv:1912
 Learning multiple layers of features from tiny images,2009, Master’sthesis
 Imagenet classification with deep con-VolUtional neural networks,2012, Advances in neural information processing systems
 Towards explaining the regularization effect of initiallarge learning rate in training neural networks,2019, In H
 Under-standing the decision boundary of deep neural networks: An empirical study,2020, arXiv preprintarXiv:2002
 Deepdouble descent: Where bigger models and more data hurt,2019, arXiv preprint arXiv:1912
 The deep bootstrap framework: Goodonline learners are good offline generalizers,2020, arXiv preprint arXiv:2010
 Thepitfalls of simplicity bias in neural networks,2020, arXiv preprint arXiv:2006
 Understanding machine learning: From theory to algo-rithms,2014, Cambridge university press
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Is robustnessthe cost of accuracy?-a comprehensive study on the robustness of 18 deep image classificationmodels,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Measuring the vc-dimension of a learning ma-chine,1994, Neural computation
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Wide residual networks,2016, In BMVC
 Wide residual networks,2016, arXiv preprintarXiv:1605
 Differentiable augmentation fordata-efficient gan training,2020, arXiv preprint arXiv:2006
 63 yields the desired inequality and concludes the proof of Lemma 3,2022,	□18Under review as a conference paper at ICLR 2022C
