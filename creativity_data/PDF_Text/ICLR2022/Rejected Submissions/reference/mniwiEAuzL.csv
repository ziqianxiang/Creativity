title,year,conference
 Optimality and approximationwith policy gradient methods in markov decision processes,2020, In Conference on Learning Theory
 Near-optimal reinforcement learning with self-play,2020, Advancesin Neural Information Processing Systems
 Global optimality guarantees for policy gradient methods,2019, arXivpreprint arXiv:1906
 A finite time analysis of temporal differencelearning with linear function approximation,1691, In Conference On Learning Theory
 TWo steps at a time-taking gan training in stride with tseng’s method,2020, arXiv preprint arXiv:2006
 Superhuman ai for multiplayer poker,2019, Science
 Global convergence of policy gradient forsequential zero-sum linear quadratic dynamic games,2019, arXiv preprint arXiv:1911
 Fast global convergence ofnatural policy gradient methods With entropy regularization,2020, arXiv preprint arXiv:2007
 Independent policy gradient methodsfor competitive reinforcement learning,2020, Advances in Neural Information Processing Systems
 A tWo-timescale frameWorkfor bilevel optimization: Complexity analysis and application to actor-critic,2020, arXiv preprintarXiv:2007
 Approximately optimal approximate reinforcement learning,2002, InIn Proc
 A natural policy gradient,2001, Advances in neural information processing systems
 Finite-sample analysis of off-policynatural actor-critic algorithm,2021, arXiv preprint arXiv:2102
 Finite sample anal-ysis of tWo-time-scale natural actor-critic algorithm,2021, arXiv preprint arXiv:2101
 Actor-critic algorithms,2000, In Advances in neural informationprocessing systems
 Markov games as a framework for multi-agent reinforcement learning,1994, InMachine learning proceedings 1994
 Human-levelcontrol through deep reinforcement learning,2015, nature
 Actor-critic fictitious play in simultaneous movemultistage games,2018, In International Conference on Artificial Intelligence and Statistics
 Natural actor-critic,2008, Neurocomputing
 Approximatemodified policy iteration,2012, In Proceedings of the 29th International Coference on InternationalConference on Machine Learning
 Trust regionpolicy optimization,2015, In International conference on machine learning
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Adaptive trust region policy optimization: Globalconvergence and faster rates for regularized mdps,2020, In Proceedings of the AAAI Conference onArtificial Intelligence
 Stochastic games,1953, Proceedings of the national academy of sciences
 Solving discounted stochastic two-playergames with near-optimal time and sample complexity,2020, In International Conference on ArtificialIntelligence and Statistics
 Mastering the game of gowithout human knowledge,2017, nature
 Policy gradient meth-ods for reinforcement learning with function approximation,2000, Advances in Neural informationProcessing Systems
 Provably efficient online agnostic learningin markov games,2020, arXiv preprint arXiv:2010
 An analysis of temporal-difference learning with functionapproximation,1997, IEEE transactions on automatic control
 Grandmasterlevel in starcraft ii using multi-agent reinforcement learning,2019, Nature
 Sample efficient actor-critic with experience replay,2016, arXiv preprintarXiv:1611
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
 A finite time analysis of two time-scale actorcritic methods,2020, arXiv preprint arXiv:2005
 Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium,2020, In Conference onLearning Theory
 Improving sample complexity bounds for actor-criticalgorithms,2020, arXiv preprint arXiv:2004
 Policymirror descent for regularized reinforcement learning: A generalized framework with linear con-vergence,2021, arXiv preprint arXiv:2105
 Model-based multi-agent rl in zero-summarkov games with near-optimal sample complexity,2020, Advances in Neural Information ProcessingSystems
 Provably efficient policy gradientmethods for two-player zero-sum markov games,2021, arXiv preprint arXiv:2102
 Finite-sample analysis for sarsa with linear functionapproximation,2019, In Advances in Neural Information Processing Systems
 Note that under i,2018,i
 This is also pointed out in Zhao et al,2012, (2021) with a short explanation
 LetAssumptionl hold,2021, For the critic in stage 2 in Algorithm 8
	□Stage 2 of Reflected NAC with a game etiquette and ζ-greedy exploration in Algorithm 10Recall that in Appendix F,2021,2
