title,year,conference
 Publicly available clinical bert embeddings,2019, arXiv preprintarXiv:1904
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 What interpretable machine learning can tell us about missing val-ues,2021, ICML Invited Talk
 Recurrentneural networks for multivariate time series with missing values,2018, Scientific reports
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Mul-titask learning and benchmarking with clinical time series data,2019, Scientific Data
 Set functionsfor time series,2020, In Hal DaUme In and Aarti Singh (eds
 Deep representation learning of electronichealth records to unlock patient stratification at scale,2020, NPJ digital medicine
 Behrt: transformerfor electronic health records,2020, Scientific reports
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 On the dimensionality of word embedding,2018, arXiv preprintarXiv:1812
