title,year,conference
 Square attack:a query-efficient black-box adversarial attack via random search,2020, In ECCV
 Understanding deep neural networks with rectifiedlinear unit,2018, In ICLR
 Obfuscated gradients give a false sense of security: Circum-venting defenses to adversarial examples,2018, In ICML
 Certifiably adversarially robust detection ofout-of-distribution data,2020, NeurIPS
 Informative outlier matters:Robustifying out-of-distribution detection using outlier mining,2020, preprint
 Maximum resilience of artificial neuralnetworks,2017, In International Symposium on Automated Technology for Verification and Analysis
 Describing textures in the wild,2014, InProceedings of the IEEE Conf
 Reliable evaluation of adversarial robustness with an ensemble of diverseparameter-free attacks,2020, In ICML
 Autoaugment:Learning augmentation strategies from data,2019, In CVPR
 Enablingcertification of verification-agnostic networks via memory-efficient semidefinite programming,2020, InNeurIPS
 Imagenet: A large-scale hierarchicalimage database,2009, In CVPR
 On the effectiveness of intervalbound propagation for training verifiably robust models,2018, arXiv:1810
 On calibration of modern neural networks,2017, In ICML
 Why ReLU networks yield high-confidencepredictions far away from the training data and how to mitigate the problem,2019, In CVPR
 A baseline for detecting misclassified and out-of-distribution examplesin neural networks,2017, In ICLR
 Deep anomaly detection with outlier exposure,2019, InICLR
 Reluplex: An efficient smt solver forverifying deep neural networks,2017, In CAV
 3d object representations for fine-grainedcategorization,2013, In ICCV vision workshop
 Fixing asymptotic uncertainty of bayesianneural networks with infinite relu features,2020, arXiv:2010
 Training confidence-calibrated classifiers for detecting out-of-distribution samples,2018, In ICLR
 A simple unified framework for detectingout-of-distribution samples and adversarial attacks,2018, In NeurIPS
 Enhancing the reliability of out-of-distribution imagedetection in neural networks,2018, In ICLR
 Enhanced isotropy maximization loss: Seamless and high-performance out-of-distribution detection simply replacing the softmax loss,2021, arXiv:2105
 Entropicout-of-distribution detection: Seamless detection of unknown examples,2021, IEEE Transactions onNeural Networks and Learning Systems
 Towards deep learning models resistantto adversarial attacks,2018, In ICLR
 Fine-grainedvisual classification of aircraft,2013, arXiv:1306
 Predictive uncertainty estimation via prior networks,2018, In NeurIPS
 Reverse kl-divergence training of prior networks: Improveduncertainty and adversarial robustness,2019, In NeurIPS
 Towards neural networks that provably know when they don’tknow,2020, In ICLR
 Differentiable abstract interpretation for provably robust neuralnetworks,2018, In ICML
 Reading digits in natural imageswith unsupervised feature learning,2011, In NeurIPS Workshop on Deep Learning and UnsupervisedFeature Learning
 Deep neural networks are easily fooled: High confidencepredictions for unrecognizable images,2015, In CVPR
 Practical black-box attacks against machine learning,2017, In ACM ASIACCS
 Likelihood ratios for out-of-distribution detection,2019, In NeurIPS
 Better the devil you know: An analysis of evasion attacks using out-of-distribution adversarial examples,2019, preprint
 Evidential deep learning to quantify classificationuncertainty,2018, In NeurIPS
 80 million tiny images: A large data set fornonparametric object and scene recognition,2008, IEEE transactions on pattern analysis and machineintelligence
 Lsun: Construction of alarge-scale image dataset using deep learning with humans in the loop,2015, CoRR
 Towards stable and efficient training of verifiably robust neural networks,2020, InICLR
 Places: A 10million image database for scene recognition,2017, IEEE transactions on pattern analysis and machineintelligence
 Plain is identicalto before and is just repeated for the reader’s convenience,2020, Note that the conclusions from themain paper still hold
