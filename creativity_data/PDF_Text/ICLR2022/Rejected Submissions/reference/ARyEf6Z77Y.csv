title,year,conference
 A closer look at memorization in deep netWorks,2017, In Doina Precup and Yee WhyeTeh (eds
 Once-for-all: Train onenetWork and specialize it for efficient deployment,2020, In International Conference on LearningRepresentations
 Instanas: Instance-aWare neural architecture search,2020, In Proceedings of the AAAI Conference on Artificial Intelligence
 Addressingfailure prediction by learning model confidence,2019, In Advances in Neural Information ProcessingSystems
 Fbnetv3: Joint architecture-recipe search using neuralacquisition function,2020, arXiv preprint arXiv:2006
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 BETANAS: balanced training and selective drop forneural architecture search,2019, CoRR
 SWitch transformers: Scaling to trillion parametermodels With simple and efficient sparsity,2021, arXiv preprint arXiv:2101
 Tradeoffs in dataaugmentation: An empirical study,2021, In International Conference on Learning Representations
 Neural network ensembles,1990, IEEE transactions on patternanalysis and machine intelligence
 Training independent subnetworksfor robust prediction,2021, In International Conference on Learning Representations
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Deep networks withstochastic depth,2016, In European conference on computer vision
 Shufflenet v2: Practical guidelines forefficient cnn architecture design,2018, In Proceedings of the European conference on computer vision(ECCV)
 Hydranets: Spe-cialized dynamic architectures for efficient inference,2018, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, arXivpreprint arXiv:1701
 The transportation problem and the vogel approximation method,1970, Decision Sciences
 Attention is all you need,2017, In NIPS
 Batchensemble: an alternative approach to efficientensemble and lifelong learning,2020, In International Conference on Learning Representations
 Hyperparameter ensembles forrobustness and uncertainty quantification,2020, arXiv preprint arXiv:2006
 Aggregated residualtransformations for deep neural networks,2017, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 Hd-cnn: hierarchical deep convolutional neural networks for large scale visualrecognition,2015, In Proceedings of the IEEE international conference on computer vision
 Condconv: Conditionally parameter-ized convolutions for efficient inference,2019, In Advances in Neural Information Processing Systems
 Logme: Practical assessment ofpre-trained models for transfer learning,2021, In Marina Meila and Tong Zhang (eds
 Dynamic graph: Learninginstance-aware connectivity for neural networks,2020, arXiv preprint arXiv:2010
 Basisnet: Two-stage model synthesis for efficientinference,2021, arXiv preprint arXiv:2105
 Adversarial autoaugment,2020, In InternationalConference on Learning Representations
 Dynet: Dynamic convolution foraccelerating convolutional neural networks,2020, arXiv preprint arXiv:2004
 Practical block-wise neural networkarchitecture generation,2018, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Learning specialized activation functions with thepiecewise linear unit,2021, CoRR
