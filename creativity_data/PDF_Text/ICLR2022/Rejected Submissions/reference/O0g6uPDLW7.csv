title,year,conference
 Adef: an iterative algorithm to constructadversarial deformations,2018, arXiv preprint arXiv:1804
 Transformer-encoder detector module: Us-ing context to improve robustness to adversarial attacks on object detection,2020, arXiv preprintarXiv:2011
 Reveal of vision transformersrobustness against adversarial attacks,2021, arXiv preprint arXiv:2106
 Obfuscated gradients give a false sense of secu-rity: Circumventing defenses to adversarial examples,2018, International Coference on InternationalConference on Machine Learning
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 End-to-end object detection with transformers,2020, In European Conferenceon Computer Vision
 When vision transformers outperform resnetswithout pretraining or strong data augmentations,2021, arXiv preprint arXiv:2106
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In International Conference on Machine Learning
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Animage is worth 16x16 words: Transformers for image recognition at scale,2020, arXiv preprintarXiv:2010
 Sharpness-aware minimiza-tion for efficiently improving generalization,2020, arXiv preprint arXiv:2010
 Bae: Bert-based adversarial examples for text classifi-cation,2020, arXiv preprint arXiv:2004
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Using pre-training can improve model robustnessand uncertainty,2019, In International Conference on Machine Learning
 Mobilenets: Efficient convolutional neural networks formobile vision applications,2017, arXiv preprint arXiv:1704
 Onthe robustness of self-attentive models,2019, In ACL
 Squeeze-and-excitation networks,2018, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Is bert really robust? a strong baselinefor natural language attack on text classification and entailment,2020, In Proceedings of the AAAIconference on artificial intelligence
 Dense associative memory is robust to adversarial inputs,2018, Neuralcomputation
 Dense associative memory for pattern recognition,2016, Advancesin Neural Information Processing Systems
 Adversarial machine learning at scale,2017, In 5thInternational Conference on Learning Representations
 Bert-attack: Adversarialattack against bert using bert,2020, arXiv preprint arXiv:2004
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Swin transformer: Hierarchical vision transformer using shifted windows,2021, arXiv preprintarXiv:2103
 On the robustness of vision transformersto adversarial examples,2021, arXiv preprint arXiv:2104
 Intriguing properties of vision transformers,2021, arXiv preprintarXiv:2105
 Bag of tricks for adversarialtraining,2020, arXiv preprint arXiv:2010
 Vision transformers are robust learners,2021, arXiv preprintarXiv:2105
 Hopfieldnetworks is all you need,2020, arXiv preprint arXiv:2008
 Denoised smoothing: AProvable defense for Pretrained classifiers,2020, arXiv preprint arXiv:2003
 Certified Patch robustness viasmoothed vision transformers,2021, arXiv preprint arXiv:2110
 Robustness to modification with shared words in ParaPhraseidentification,2020, In Proceedings of the 2020 Conference on Empirical Methods in Natural LanguageProcessing: Findings
 Robustness verifi-cation for transformers,2020, arXiv preprint arXiv:2002
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Ernie: Enhanced representation through knowledge integration,2019, arXivpreprint arXiv:1904
 Robustart: Benchmarking robustness on architecturedesign and training techniques,2021, arXiv preprint arXiv:2109
 The new data and new challenges in multimedia research,2015, arXivpreprint arXiv:1503
 Attention is all you need,2017, arXiv preprint arXiv:1706
 Infobert:Improving robustness of language models from an information theoretic perspective,2020, ArXiv
 Toward few-stepadversarial training from a frequency perspective,2020, In Proceedings of the 1st ACM Workshop onSecurity and Privacy on Artificial Intelligence
 Automatic perturbation analysis for scalable certifiedrobustness and beyond,2020, Advances in Neural Information Processing Systems
 Billion-scale Semi-supervised learning for image classification,2019, arXiv preprint arXiv:1905
 Xlnet: Generalized autoregressive pretraining for language understanding,2019, arXiv preprintarXiv:1906
 Safer: A structure-free approach for certified robustnessto adversarial word substitutions,2020, arXiv preprint arXiv:2005
 On the robustness of language encodersagainst grammatical errors,2020, arXiv preprint arXiv:2005
 Wide residual networks,2016, arXiv preprintarXiv:1605
 Shufflenet: An extremely efficientconvolutional neural network for mobile devices,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Deformable detr:Deformable transformers for end-to-end object detection,2020, arXiv preprint arXiv:2010
