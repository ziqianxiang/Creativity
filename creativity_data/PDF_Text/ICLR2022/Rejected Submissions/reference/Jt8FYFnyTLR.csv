title,year,conference
 Con-crete problems in AI safety,2016, arXiv:1606
 Verifiable reinforcement learning via policyextraction,2018, In Advances in Neural Information Processing Systems
 Robustness verifica-tion of tree-based models,2019, Advances in Neural Information Processing Systems
 ENDER: a statistical frame-work for boosting decision rules,2010, Data Mining and Knowledge Discovery
 TIP: Typifying theinterpretability of procedures,2017, arXiv:1706
 Explanations based on the missing: ToWards contrastive explanationsWith pertinent negatives,2018, In Advances in Neural Information Processing Systems
 Predictive learning via rule ensembles,2008, Annals ofApplied Statistics
 Data Sci,2018, Adv
 Assessment list for trust-Worthy AI for self assessment,2020, Technical report
 Evasion and hardening of tree ensembleclassifiers,2016, In International Conference on Machine Learning
 Quantile Regression,2005, Cambridge University Press
 A robustminimax approach to classification,2002, J
 A unified approach to interpreting model predictions,2017, In Advancesin Neural Information Processing Systems
 Leveraging latent features for local explanations,2021, In ACM KDD
 On finding k-cliques in k-partite graphs,2013, OptimizationLetters
 Prac-tical machine learning safety: A survey and primer,2021, arXiv:2106
 Safe and interpretable machine learning: A methodological review,2013, In ComputationalIntelligence in Intelligent Data Analysis
 Optimal counterfactual explanations in tree ensembles,2021, InInternational Conference on Machine Learning
 QCNN: quantile convolutional neural network,2019, CoRR
 Certified defenses against adversarial exam-ples,2018, arXiv preprint arXiv:1801
 “Why should I trust you?”: Explainingthe predictions of any classifier,2016, In Proceedings of the ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining
 Stop explaining black box machine learning models for high stakes decisions anduse interpretable models instead,2019, Nature Mach
 Preventing undesirable behavior of intelligent machines,2019, Science
 Generalized linear rule models,2019, InProceedings ofthe 36th International Conference on Machine Learning (ICML)
 Transparency: Motivations and challenges,2019, In Explainable AI: Interpreting
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Scalable Bayesian rule lists,2017, In Proceedings ofthe 34th International Conference on Machine Learning (ICML)
 An inductive synthesis frameworkfor verifiable reinforcement learning,2019, In Proceedings of the 40th ACM SIGPLAN Conference onProgramming Language Design and Implementation
