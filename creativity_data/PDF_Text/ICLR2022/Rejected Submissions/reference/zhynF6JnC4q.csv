title,year,conference
 An optimistic perspective on offlinereinforcement learning,2020, In ICML
 Randomized ensembled double q-learning: Learning fast without a model,2021, ICLR
 D4rl: Datasets for deepdata-driven reinforcement learning,2020, arXiv preprint arXiv:2004
 Addressing function approximation error inactor-critic methods,2018, In International Conference on Machine Learning
 Off-policy deep reinforcement learning without ex-ploration,2019, In ICML
 Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor,2018, arXiv preprintarXiv:1801
 Popo: Pessimistic offline policy optimization,2020, ArXiv
 Way off-policy batch deep reinforcement learning ofimplicit human preferences in dialog,2019, arXiv preprint arXiv:1907
 Morel : Model-based offlinereinforcement learning,2020, NeurIPS
 Learning from limiteddemonstrations,2013, In NeurIPS
 Conservative q-learning for offlinereinforcement learning,2020, NeurIPS
 Offline-to-online reinforcement learning via balanced replay and pessimistic q-ensemble,2021, arXiv preprintarXiv:2107
 Offline policyevaluation across representations with applications to educational games,2014, In AAMAS
 Deployment-efficient reinforcement learning via model-based offline optimization,2021, ICLR
 Human-levelcontrol through deep reinforcement learning,2015, nature
 Accelerating online reinforcementlearning with offline datasets,2020, CoRR
 Learning complex dexterous manipulation with deep reinforcementlearning and demonstrations,2018, Robotics: Science and Systems
 Trust regionpolicy optimization,2015, In International conference on machine learning
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Reinforcement learning: An introduction,2011, 2011
 Leveraging demonstra-tions for deep reinforcement learning on robotics problems with sparse rewards,2017, arXiv preprintarXiv:1707
 Behavior regularized offline reinforcement learning,2019, ArXiv
