title,year,conference
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Monet: Unsupervised scene decomposition and representation,2019, arXivpreprint arXiv:1901
 On the properties ofneural machine translation: Encoder-decoder approaches,2014, arXiv preprint arXiv:1409
 Generative scene graph networks,2021, InternationalConference on Learning Representations
 Generalization and robustness implications in object-centric learning,2021, arXiv preprintarXiv:2107
 A framework for the quantitative evaluation ofdisentangled representations,2018, In International Conference on Learning Representations
 Towards a neural statistician,2016, arXiv preprint arXiv:1606
 Relate: Physically plausible multi-object scene synthesis using structuredlatent spaces,2020, In H
 Efficient iterative amortized inferencefor learning symmetric and disentangled multi-object representations,2021, In Marina Meila and TongZhang (eds
 Genesis: Gener-ative scene inference and sampling with object-centric latent representations,2019, arXiv preprintarXiv:1907
 Genesis-v2: Inferring unordered objectrepresentations without iterative refinement,2021, arXiv preprint arXiv:2104
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In Proceedings of the thirteenth international conference on artificial intelligence andstatistics
 Neural expectation maximization,2017, InAdvances in Neural Information Processing Systems
 Multi-object representationlearning with iterative variational inference,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov(eds
 On the binding problem in artificialneural networks,2020, arXiv preprint arXiv:2012
 Shapestacks: Learning vision-based physical intuition for generalised object stacking,2018, In Proceedings of the European Conferenceon Computer Vision (ECCV)
 Ganstrained by a two time-scale update rule converge to a local nash equilibrium,2017, Advances in neuralinformation processing systems
 Generative adversarial transformers,2021, In Marina Meila and TongZhang (eds
 Generative neurosymbolic machines,2020, arXiv preprintarXiv:2010
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Space: Unsupervised object-oriented scene representation via spatialattention and decomposition,2020, arXiv preprint arXiv:2001
 Biva: A very deep hierarchyof latent variables for generative modeling,2019, In H
 Learning object-centric representations of multi-objectscenes from multiple views,2020, Advances in Neural Information Processing Systems
 Block-gan: Learning 3d object-aware scene representations from unlabelled images,2020, arXiv preprintarXiv:2002
 Languagemodels are unsupervised multitask learners,2019, OpenAI blog
 Taming vaes,2018, arXiv preprint arXiv:1810
 Stochastic backpropagation andapproximate inference in deep generative models,2014, 31st International Conference on MachineLearning
 Discover-ing objects and their location in images,2005, In Tenth IEEE International Conference on ComputerVision (ICCVâ€™05) Volume 1
 Laddervariational autoencoders,2016, In Advances in neural information processing systems
 Nvae: A deep hierarchical variational autoencoder,2020, InH
 Investigatingobject compositionality in generative adversarial networks,0893, Neural Networks
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Entity abstraction in visual model-based reinforcementlearning,2019, arXiv preprint arXiv:1910
 Towards causal generative scene models via competition of experts,2020, arXiv preprintarXiv:2004
 Learning representations of sets throughoptimized permutations,2019, International Conference on Learning Representations
