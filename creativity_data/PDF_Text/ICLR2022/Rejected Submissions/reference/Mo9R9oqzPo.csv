title,year,conference
 Explaining image classifiers by removing input features usinggenerative models,2020, In Proceedings of the Asian Conference on Computer Vision
 On pixel-wise explanations for non-linear classifier decisions by layer-wiserelevance propagation,2015, PloS one
 Evaluating input perturbation methods forinterpreting cnns and saliency map comparison,2020, In European Conference on Computer Vision
 Explaining image clas-sifiers by counterfactual generation,2018, In International Conference on Learning Representations
 Real time image saliency for black box classifiers,2017, In Proceedingsof the 31st International Conference on Neural Information Processing Systems
 HoW do decisions emergeacross layers in neural models? interpretation With differentiable masking,2020, In Proceedings of the2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)
 Interpretable explanations of black boxes by meaningful perturba-tion,2017, In Proceedings of the IEEE International Conference on Computer Vision
 Understanding individual decisions of cnns viacontrastive backpropagation,2018, In Asian Conference on Computer Vision
 A benchmark for interpretabil-ity methods in deep neural netWorks,2019, In NeurIPS
 Abduction-based explanations for ma-chine learning models,2019, In Proceedings of the AAAI Conference on Artificial Intelligence
 On relating explanations and adversar-ial examples,2019, 2019b
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Microsoft coco: Common objects in context,2014, In Europeanconference on computer vision
 A unified approach to interpreting model predic-tions,2017, In I
 Compositional explanations of neurons,2020, 2020
 Rise: Randomized input sampling for explanation ofblack-box models,2018, In Proceedings of the British Machine Vision Conference (BMVC)
 Investigating and simplifying masking-basedsaliency methods for model interpretability,2020, arXiv preprint arXiv:2010
 Evaluating the visualization of what a deep neural network has learned,2016, IEEE transactionson neural networks and learning systems
 Restricting the flow: Informationbottlenecks for attribution,2019, In International Conference on Learning Representations
 Learning important features throughpropagating activation differences,2017, In International Conference on Machine Learning
 Generative imageinpainting with contextual attention,2018, In Proceedings of the IEEE conference on computer visionand pattern recognition
 Places: A 10million image database for scene recognition,2017, IEEE transactions on pattern analysis and machineintelligence
 Interpreting deep visual representationsvia network dissection,2018, IEEE transactions on pattern analysis and machine intelligence
