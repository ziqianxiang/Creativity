Table 1: Classification accuracy (%) and training time (min) of various single-step adversarial trainingmethods and the proposed methods I-PGD2-AT and I-PGD3-AT on CIFAR-10 and Tiny ImageNetagainst white-box attacks (e = 8/255). We bold the highest classification accuracy and lowesttraining time which outperforms the runner-up by at least 0.2. The proposed methods are in gray .
Table 2: Classification accuracy (%) and training time (hour) of PGD-AT w/ and w/o the proposedI-PGD on CIFAR-10 against white-box attacks ( = 8/255) without early stopping. We bold thehighest classification accuracy and lowest training time which outperforms the runner-up by at least0.5 and mark the results of the proposed method in gray .
Table 3: Ablation study for the probability P used in I-PGD2-AT on CIFAR-10. |Skdenotes the mean absolutevalue of perturbation and Epoch denotes the epoch when catastrophic overfitting occursto larger |S|. We vary P from 0.5 to 1 and summarize the results in Table 3. ASWe can see, when Weincrease the value of p, the clean accuracy decreases a little but the robustness increases significantlywhen p ≤ 0.7. However, when we continue to increase p, ∣δ∣ increases and the catastrophic overfittinghappens. The larger P indicates the larger ∣δ∣ and results in the earlier epoch for catastrophicoverfitting. This is also consistent with our experiments and analysis in Sec. 4.5 and further supportour hypothesis that under the same '-norm constraint on the perturbation δ, smaller | j| can effectivelydelay the catastrophic overfitting.
