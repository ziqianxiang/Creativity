Table 1: Model improvements through retraining with multi-label CaPCDataset	# of Models	State	PB (ε)	ACC	BAC	AUC	MAP	1	Initial	-	.97	.85	.97	.85Pascal VOC	50	Before CaPC	-	.93±.02	.59±.01	.88±.01	.54±.01	50	After CaPC	10	.94±.01	.62±.01	.88±.01	.54±.01	50	After CaPC	20	.94±.01	.64±.01	.89±.01	.55±.01	1	Initial	-	.79	.78	.86	.72CheXpert	50	Before CaPC	-	.77±.06	.66±.02	.75±.02	.58±.02	50	After CaPC	20	.76±.07	.69±.01	.77±.01	.59±.01	1	Initial	-	.90	.74	.84	.51MIMIC	50	Before CaPC	-	.84±.07	.63±.03	.78±.03	.43±.02	50	After CaPC	20	.85±.05	.64±.01	.79±.01	.45±.03	1	Initial	-	.86	.79	.90	.37PadChest	10	Before CaPC	-	.90±.01	.64±.0 1	.79±.01	.16±.01	10	After CaPC	20	.88±.01	.64±.0 1	.75±.01	.14±.01ε = 8 for 5 labels on CheXpert (see Appendix I.3), ε = 10 for predictions on PascalVOC, ε = 20 for11 labels on CheXpert or MIMIC, and also ε = 20 for 15 labels on CheXpert (see also Section I.9).
Table 2: DPSGD vs PATE. Comparison be-tween standard non-private model, DPSGD,Powerset and Binary multi-label PATE on thePascal VOC dataset in terms of utility.
Table 3: Dependency Matrix for the first 5 labels form the CheXpert dataset.
Table 4: Exploit label dependencies for the multi-label classification.
Table 5: CheXpert: Performance of Binary PATE vs Powerset PATE w.r.t. number of answeredqueries, ACC, BAC, AUC, and mAP (as measured on the test set with the specified σGNMax. PB (ε) isthe privacy budget. We use 50 teacher models. When we limit number of labels per dataset, we selectthe first k labels.
Table 6: Pascal VOC: Performance of Binary PATE vs Powerset PATE w.r.t. number of answeredqueries, ACC, BAC, AUC, and mAP as measured on the test set with the specified σGNMax. PB (ε) isthe privacy budget. We use 50 teacher models. When we limit number of labels per dataset, we selectthe first k labels.
Table 7: More statistics about the positive labels per data point in the Pascal VOC dataset.
Table 8: Pascal VOC: Performance of Powerset PATE with τ -clipping w.r.t. number of answeredqueries with the specified σGNMax . The ACC, BAC, AUC, and mAP are measured on the answeredqueries from the test set. PB (ε) is the privacy budget. We use 50 teacher models. When we limitthe number of labels per dataset, we select the first k labels. The τ denotes a maximum number ofpositive labels that a teacher is allowed to return per data sample.
Table 9: DPSGD vs PATE on Chexpert for the first 5 labels.
Table 10: Pascal VOC with 20 labels: Performance of Binary PATE for different values of εw.r.t. number of answered queries, ACC, BAC, AUC, and mAP as measured on the test set with thespecified σGNMax. PB (ε) is the privacy budget. We use 50 teacher models. When we limit number oflabels per dataset, we select the first k labels. We set σGNMax = 7PB (ε)	Queries ANSWERED	ACC	BAC	AUC	MAP1	0	-	-	-	-2	6	.86	.62	.62	.443	13	.93	.67	.67	.534	22	.93	.64	.64	.445	31	.95	.63	.63	.396	40	.95	.67	.67	.457	64	.95	.64	.64	.358	81	.95	.66	.66	.409	101	.95	.60	.60	.2810	113	.96	.63	.63	.3011	135	.96	.64	.64	.3312	165	.96	.65	.65	.3513	199	.96	.63	.63	.3214	217	.96	.64	.64	.3515	239	.96	.63	.63	.32
Table 11: Performance of multi-label CaPC w.r.t. ACC, BAC, AUC, and mAP, on Pascal VOC(PA), CheXpert (CX), MIMIC (MC), and PadChest (PC). (-) denotes N/A. PB (ε) is the privacybudget.
Table 12: Performance of multi-label CaPC with τ -PATE w.r.t. ACC, BAC, AUC, and mAP, onPascal VOC (PA), CheXpert (CX), MIMIC (MC), and PadChest (PC). (-) denotes N/A. PB (ε) isthe privacy budget. T (Y/N) in the table refers to the PATE thresholding i.e. corresponding to theparameters T and σT being used (Y) or not used (N). Note that the probability thresholding per layerwas used in these experiments (as described in Section I.10).
