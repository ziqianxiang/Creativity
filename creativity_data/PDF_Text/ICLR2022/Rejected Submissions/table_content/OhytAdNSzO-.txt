Table 1: The starting point modelfor our scaling method.
Table 2: Our scaled ViT models outperform DeiT on ImageNet under the same FLOPs constrains.
Table 3: Scaled ViT models after training for 1000epochs.
Table 4: Important details about the 3 hardware devices in the transferability exploration experiments.
Table 5: Scaled models targeting Pixel3 are sub-optimal when executed on TX2, and vice versa.
Table 6: Transferring the scaling strategies target-ing DeiT (Touvron et al., 2020) to PiT (Heo et al.,2021), where the resulting models are denoted asPiT-Scaled-Tiny/XS/Small.
Table 7: COCO (Lin et al., 2014) detectionperformance (val2017) of DeiT (Touvron et al.,2020) and our DeiT-Scaled models with a De-formable DETR (Zhu et al., 2020) detector.
Table 8: Architecture configuration of PiT-Scaled-Tiny/XS/Small, including image resolution (I),spatial size (i.e., # of spatial tokens), # of layers (d), # of heads (h), and the embedding dimension foreach head (e). Here, h in the PiT models has to be in h-2h-4h format (e.g., 2-4-8 in PiT-Tiny).
Table 9: Kinetics-400 (Kay et al., 2017) video clas-sification performance (validation set) of extendedDeiT (Touvron et al., 2020) and our DeiT-Scaled modelswith a TimeSFormer (Bertasius et al., 2021) style.
Table 10: Specifications of the hardware devices in the transferability exploration experiments.
Table 11: Detailed cost breakdown of DeiT-Tiny on different devices for the operators of (1) multi-layer perceptron (MLP), (2) layer normalization (LayerNorm), (3) matrix multiplication in multi-headself-attention (MSA-MatMul), (4) softmax in multi-head self-attention (MSA-Softmax), (5) reshapeand transpose in multi-head self-attention (MSA-Reshape&Transpose), (6) gather in multi-headself-attention (MSA-Gather), and (7) others.
Table 12: Detailed architecture configurations of the scaled ViT models with throughput (i.e., FPS)on V100 (V100 Scaling) and latency on TX2 (TX2 Scaling) as the hardware-cost during scaling,respectively.
Table 13: Random permutation further boosts the performance of the scaled models.
