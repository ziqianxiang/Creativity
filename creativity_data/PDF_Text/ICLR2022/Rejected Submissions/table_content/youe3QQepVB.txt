Table 1: Pilot experiment for semantic segmentation on the Tiny-Taskonomy dataset. Directlyusing images synthesized by an off-the-shelf generative model (self-attention GAN) may hurt theperformance on the downstream task. ST: single-task semantic segmentation model trained on realimages only; STG : the same model trained on both real and synthesized images.
Table 2: Main results (mean ± std) on the NYUv2 and Tiny-Taskonomy datasets. SS: semanticsegmentation; DE: depth estimation; SN: surface normal prediction. ↑ means higher is better;1means lower is better. We use different metrics on the two datasets, following existing protocol. OurMGM consistently and significantly outperforms both single-task (ST) and multi-task (MT) baselines,even reaching the performance upper-bound of training with weakly annotated real images (MGMr).
Table 3: Comparison of our MGM model with its variants. MGM/G : without generating synthesizedimages; MGM/j: without joint learning. Our MGM outperforms single-task and multi-task baselineseven without synthesized data, showing its effectiveness as a general multi-task learning framework.
Table 4: Ablation study. (1) MGM/sef: without self-supervision task; (2) MGM/refine： withoutclassification refinement network; and (3) MGMrecon : with a simple reconstruction task as self-supervision. The two proposed components are complementary and both benefit the multiple tasks.
Table 5: Mean test losses for six tasks on Tiny-Taskonomy. Again, our MGM outperforms thebaselines, indicating its flexibility, generability, and scalability.
Table 6: Comparison with state-of-the-art multi-task models in the 25% data setting on the NYUv2dataset. Notably, with a simple shared encoder architecture, our MGM model outperforms otherstate-of-the-art multi-task networks with more sophisticated architectures, which indicates the benefitof introducing generative modeling for multi-task learning. In addition, our MGM is a model-agnosticframework and could be incorporated with these different multi-task models for further improvement.
Table 7: Comparison in the few-shot regime - in the 10% data setting on the NYUv2 dataset wherearound 3 images for each scene is used as the training set. Again, MGM significantly outperformsthe compared models, showing the benefit of generative models in the extremely low-data regime.
Table 8: Impact of parameters. STl and MTl : baselines with a larger number of parameters (withdeeper backbones). Simply increasing the number of parameters cannot significantly boost perfor-mance.
Table 9: Results on the NYUv2 dataset in the 50% data setting with different training strategiesfor the refinement network. ‘MT’: multi-task learning baseline; ‘PEoE’: plain end-to-end training;‘LSeT’: loosely separate training; ‘EML’: EM-like training (proposed in the main paper). Our EMLsignificantly outperforms alternative strategies to train the refinement network.
Table 10: Experiments with 256 image resolution on the NYUv2 dataset. Our MGM still consistentlyoutperforms the compared baselines, showing the great robustness and flexibility of the proposedframework.
Table 11: Results for the SN task with pre-trained feature representations by the SS and DE tasks.
Table 12: Results on the NYUv2 dataset in the 50% data setting with different image generationnetworks. ‘MGM-SAGAN’: MGM equipped with SAGAN (presented in the main paper); ‘MGM-DCGAN’: MGM equipped with DCGAN. Both ‘MGM-SAGAN’ and ‘MGM-DCGAN’ consistentlyimprove the performance on all the tasks and outperform single-task (ST) and multi-task (MT)baselines. This shows the robustness and flexibility of the proposed MGM framework. In addition,‘MGM-SAGAN’ outperforms ‘MGM-DCGAN’, suggesting that a more powerful image generationnetwork leads to better performance.
Table 13: Results on the CityScape Subset. MGM still outperforms the baseline ST model, indicatingthe robustness and generalizability of the model with multi-hot object labels.
Table 14: Comparison with extreme low data in Taskonomy. In this data setting, MGM significantlyoutperforms both ST and MT, indicating that MGM is robust and especially helpful in low-dataregime.
Table 15: Ablation with MGM for single tasks and a stronger baseline with the learned informationfrom the three individual tasks but without jointly training. The experiments are conducted onNYUv2 50% data setting. MGM-SS, MGM-DE, MGM-SN: variantal MGM model for single tasks.
