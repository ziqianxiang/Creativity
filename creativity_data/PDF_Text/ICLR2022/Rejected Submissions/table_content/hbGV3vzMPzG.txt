Table 1: Comparison between different accelerated adver-sarial training methods in robust test accuracy against Au-toAttack (AA). The baseline results are from RobustBench.
Table 2: Robust accuracy of fine-tunedmodels against AutoAttack(AA).
Table 3: The notation in this paper. We provide the section of their definition or first appearance.
Table 4: D-distances between difficulty functions in different settings, including different modelarchitectures and training duration (left table), and different types of perturbations (right table).
Table 5: D-distances between difficulty functions of vanilla / FGSM / PGD training and trainingbased on 18 different corruptions on CIFAR10-C. We run each experiment for 4 times and report theaverage value.
Table 6: Upper bound of the Lipschitz constant under different settings of and training instances.
Table 7: Ablation study on the influence of reweighting (RW) and the KL regularization term (KL) inthe performanCe of adversarial finetuning with additional data.
