Table 1: Performance comparison (average accu-racy) on Office-Home training with 5%, 10%,20% labeled data. The higher the better.
Table 2: Performance comparison of different methods on the Office-Home dataset.
Table 3: Performance comparison of different methods on the Office-Caltech dataset.
Table 4: Performance comparison of different methods on the ImageCLEF dataset.
Table 5: Performance of multi-task regression (normalized mean squared errors) for rotation angleestimation. The lower the better.
Table 6: The iteration numbers and batch sizes on different datasets, where C and L denotes thenumber of classes and tasks in the specific dataset, respectively.
Table 7: The architecture of inference networks 夕ι(∙) for latent variable ψ of multi-task neuralprocesses.
Table 8: The architecture of inference networks 夕2(∙) for the latent variable α of multi-task neuralprocesses.
Table 9: The architecture of the neural network h(∙) of multi-task neural processes.
Table 10: Performance comparison of different methods on the Office-Home dataset with 20%training samples.
Table 11: Performance comparison of different methods on the Office-Caltech dataset with20% training samples.
Table 12: Performance comparison of different methods on the ImageCLEF dataset with 20%training samples.
Table 13: Performance (Average NMSE) on Rotated MNIST(0.05% split).
Table 14: The performance under different noise level on the Office dataset with 5% split.
Table 15: Sensitivity of Nf (and Na = 5) on Office-Home with the 5% split.
Table 16: Sensitivity of Na (and Nf = 10) on Office-Home with the 5% split.
