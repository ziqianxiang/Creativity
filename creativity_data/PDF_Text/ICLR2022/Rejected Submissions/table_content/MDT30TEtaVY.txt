Table 1: Adding set norm and feature norm improves performance of Deep Sets (50 layers), whileadding layer norm does not.
Table 2: The setting of Deep Sets which performs best overall uses set norm with a clean residualpath (highlighted gray). First row is the original Deep Sets architecture.
Table 3: The setting of Set Transformer which performs best overall uses set norm with a cleanresidual path (highlighted gray). First row is the original Set Transformer.
Table 4: Deep Sets++ and Set Transformer++ outperform their Deep Sets and Set Transformercounterparts at 50 and 16 layers respectively.
