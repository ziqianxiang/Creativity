Table 1: Experimental results of GAN LIP. We evaluate the LIPs found in PGAN on the compressedsensing (CS) and the inpainting (I) tasks. The results are based on celebA-HQ dataset (Lee et al.,2020). Note that we use the MSE (per pixel) to evaluate the LIP effectiveness and compare the LIPwith random pruning results.
Table 2: The comparison of pa-rameter numbers in full modeland the winning tickets. Notethat we evaluate the PSNR val-ues on the image Bird.
Table 3: Comparison results of differenttraining targets. We train the DIP modelon one image (Baby.png) for 6000 epochsand separately set the training target to x(clean target) and X (noisy target). Thenwe evaluate the masks on the same imagefor 3000-epoch denoising task.
Table 4: We compare the results of clean and noisy image targets in setting i. Note that the usedimage is F16.png, the evaluation metric is PSNR and the training iteration number is 3000 to capturethe “early-stopping” phenomenon. The results suggest that there are no large differences (withPSNR value smaller than 0.05) between the performances of subnetworks with clean and noisyimage targets (the sparsity ranges from 0% to 95%).
