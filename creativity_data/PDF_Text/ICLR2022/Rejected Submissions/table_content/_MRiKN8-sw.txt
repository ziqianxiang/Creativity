Table 1: List of the selected variables for MAR settings. The datasets’ sizes are also provided as well as thecolumn number of the variable used to generate MAR missing data.
Table 2: Comparison and recapitulation	GAIN	MiSGAN	KNNImage imputation	No	YeS	NoTabular data imputation	Yes	Inconsistent	YeS	-Training time (for 〜1000 observations) ∣	〜190 sec	〜80 sec	< 1 secOptimal hyperparameter search	Need to train again from scratch with new hyperparameters		Exhaustive and instantaneousResults	”Black-box” model Stochastic imputation		Easy to interpret Deterministic imputationReproducibility	Algorithmically complex		Straightforward8Under review as a conference paper at ICLR 2022Advances in Machine Learning tend to showcase several ”state-of-the-art” algorithms, although onlyone may exist by definition. Exhaustive comparative studies allow to share common benchmarks andfairly assess the performances of each method.
Table 3: Neural network architecture for GAINLayer	Input shape	Output shape	Nb. paramsFully connected	2c	64	128c + 64Fully Connected	64	128	8320Fully Connected	128	128	16512Fully Connected	128	—	c	129c	—Table 4: Neural network architecture for MisGANLayer	Input shape	Output shape	Nb. paramsFully connected	C	128	128c + 128Fully Connected	128	128	16512Fully Connected	128	128	16512Fully Connected	128	—	c	129c	—B	Appendix: Datasets descriptionReal-world and well-behaved simulated datasets are both used in this comparative study. Sevenreal-world datasets are taken from the open access UCI Machine Learning Repository (Dua & Graff(2019)). Because an exhaustive comprehension of the data at play is the most important preliminarystep before any data analysis, this appendix provides essential details about the data used in thiswork. Note that all following datasets are complete: they do not show missing values in the firstplace. The first two columns of Table 1 shows the dataset names and sizes.
Table 4: Neural network architecture for MisGANLayer	Input shape	Output shape	Nb. paramsFully connected	C	128	128c + 128Fully Connected	128	128	16512Fully Connected	128	128	16512Fully Connected	128	—	c	129c	—B	Appendix: Datasets descriptionReal-world and well-behaved simulated datasets are both used in this comparative study. Sevenreal-world datasets are taken from the open access UCI Machine Learning Repository (Dua & Graff(2019)). Because an exhaustive comprehension of the data at play is the most important preliminarystep before any data analysis, this appendix provides essential details about the data used in thiswork. Note that all following datasets are complete: they do not show missing values in the firstplace. The first two columns of Table 1 shows the dataset names and sizes.
Table 5: Average training time per dataset for the four algorithms in this studyDataset name	Size	GAIN (in sec.)	MisGAN (in sec.)	KNN (in sec.)breast	(569, 30)	2219	88.6	00credit	(30000,14)	194.3	86.9	448letter	(20000,16)	196.9	85.2	246news	(39644, 44)	213.3	129.4	210^spam	(4601, 57)	220.5	89.0	3.3wine-red	(1599,12)	200.0	82.8	0.1Wine_White	(4898,12)	197.1	82.8	171mydata1	(1000, 5)	190.5	80.4	02mydata2	(1000,5)	190.1 —	80.9	0.0	—The training time for GAIN and MisGAN remains nearly constant across datasets. This is because ofthe multiplicative factor (introduced in Section 5.1) used to keep similar proportion when training theANN models. To trian GAIN for example, we use 20,000 training epochs for the dataset mydata1which has 1,000 observations, but we use only 1,000 training for the letter dataset which shows20,000 observations.
Table 6: Numerical results corresponding to Fig. 1 (a). The mean and standard deviation of the imputationRMSE are given in percents (%).
Table 7: Numerical results corresponding to Fig. 1 (b). The mean and standard deviation of the imputationRMSE are given in percents (%).
Table 8: Numerical results corresponding to Fig. 2 (a). The mean and standard deviation of the imputationRMSE are given in percents (%).
Table 9: Numerical results corresponding to Fig. 2 (b). The mean and standard deviation of the imputationRMSE are given in percents (%).
Table 10: Numerical results corresponding to Fig. 3 (a). The mean and standard deviation of the imputationRMSE are given in percents (%).
Table 11: Numerical results corresponding to Fig. 3 (b). The mean and standard deviation of the imputationRMSE are given in percents (%).
