Table 1: Results for the music domain. Left: We show negative log-likelihood (“NLL”, lower isbetter) on the held-out human test set (i.e., by estimating the ELBo using sampling). Right: We showFrechet distance on MusicVAE embeddings (“FD”, lower is better). Both: We show the cross-entropyloss of the graph discriminator trained to distinguish synthesized programs of generated examplesvs. held-out test set examples (“GCN Disc.”, higher is better), and the accuracy of a random foresttrained to do the same thing on a handcrafted featurization of the programs (“RF”, lower is better).
Table 2: Results for the poetry domain. We show Frechet distance on SentenceBERT embeddings(“FD”, lower is better), along with the cross-entropy loss of the graph discriminator trained todistinguish synthesized programs of generated examples vs. held-out test set examples (“GCN Disc.”,higher is better). The best score in each column is bolded. As can be seen, our approach (SGM)with sampling strategy A1 outperforms all other approaches in terms of high-level structure, whileour approach with sampling strategy A3 outperforms all baselines in high-level structure and is alsocompetitive with GPT-2-based models in FD scores.
Table 3: A user study evaluation in the poetry domain. While GPT2-Finetune outperforms ourmodel in terms of coherence (presumably due to the well-known superiority of GPT-2 over BERT forgeneration), our method outperforms in terms of overall lyricism (i.e., whether the poem reads likepoetry or prose), prominence of rhythmic/metrical structure, and average score.
Table 4: A user study evaluation in the poetry domain. While GPT2-Finetune outperforms our modelin terms of coherence (likely because GPT-2 outperforms BERT at generation), our method outper-forms in terms of overall lyricism (i.e., whether the poem reads like poetry or prose), prominence ofrhythmic/metrical structure, and average score.
