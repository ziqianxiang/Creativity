Table 1: Performance comparison. Left: general tabular data classification (Average over alldatasets). Above line - results taken from SAINT paper evaluated on unknown seeds. Below line- mean and standard deviation of SAINT results computed using the authors’ code averaged overseeds 1-10, and of our method evaluated on exactly the same data. Right: CTR prediction (ROC-AUC %). I results reported by authors, II results of running the model on our data split with paper’shyperparameters, III result of running the model on our data split with our tuning for the model.
Table 2: Averaged ablation studies. Left: General framework architecture ablations. Right: Nu-meric fieldwise networks aMations.______________________________Variation	Binary (ROC-AUC)	Multiclass (Accuracy)	AllFull method	93.16	84.02	91.85	Variation	Num. DSShared field matrix	92.55	70.47	89.40	Full method	91.40Deep	92.89	82.57	91.41	(i) UF EF XF	90.74Low rank	92.64	78.97	90.69	(ii) l = K	91.17Quadratic	92.70	82.31	91.21	(iii) UFEF(vFxF + bF )	90.80ReLU	93.05	82.58	91.55GELU	93.00	82.61	91.51Table 3: GELU as adapted activation - HR @10 on Movielens datasetEmb. size	ReLU	GELU	Quad.	MF16	0.6876	0.6972	0.6974	0.6937192	0.7164	0.7217	0.7280	0.7278results are reported in Table 2. In many datasets the particular activation was immaterial. However,in some datasets, activation has made a significant difference, so it should be carefully chosen.
Table 3: GELU as adapted activation - HR @10 on Movielens datasetEmb. size	ReLU	GELU	Quad.	MF16	0.6876	0.6972	0.6974	0.6937192	0.7164	0.7217	0.7280	0.7278results are reported in Table 2. In many datasets the particular activation was immaterial. However,in some datasets, activation has made a significant difference, so it should be carefully chosen.
Table 4: GeneraI tabular datasetsDataset	Task	#Fields	#Categ.	#Numer.	Size	#Positives	#Negatives	% of positivesIncome	Binary	14	8	6	32,561	7,841	24,720	24.08Bank	Binary	16	9	7	45,211	5,289	39,922	11.7BlastChar	Binary	20	17	3	7,043	1,869	5,174	26.54Credit	Binary	29	0	29	284,807	492	284,315	0.17Forest	Binary	49	0	49	495,141	283,301	211,840	57.22HTRU2	Binary	8	0	8	17,898	1,639	16,259	9.16KDD99	Binary	39	3	36	494,021	97,278	396,743	19.69Shoppers	Binary	17	2	15	12,330	1,908	10,422	15.47Philippine	Binary	308	0	308	5,832	2,916	2,916	50QSAR Bio	Binary	41	0	41	1,055	356	699	33.74Shrutime	Binary	11	3	8	10,000	2,037	7,963	20.37Spambase	Binary	57	0	57	4,601	1,813	2,788	39.4Volkert	Multiclass(10)	147	0	147	58,310	-	-	-MNIST	Multiclass(10)	784	784	0	60,000	-	-	-Table 5: Saint datasets - Architecture hyperparameters search. dfactor and lf actor stands for factorsof the full rank dimensionality of EF and tF respectively.
Table 5: Saint datasets - Architecture hyperparameters search. dfactor and lf actor stands for factorsof the full rank dimensionality of EF and tF respectively.
Table 6: CTR prediction baselines hyperparameters: learning rate(γ), regularization strength (λ),standard deviation of the weights normal initialization (σ), batch size (bs). I results reported byauthors, II results of running the model on our data split with paper’s hyperparameters, III result ofrunning the model on our data split with our tuning for the model.
Table 7: GELU as adapted activation - regularization strength of the reported resultsMF initialization & regularizationEmb. size -ReLU	GELU	Quad.一16	λ=	1e-5	λ=	1e-5	λ= 1192	λ=	5e-3	λ=	5e-4	λ= 1In order to explore the ability of other activation to approximate the results of a dot product basedmodel, we used the eigen decomposition as an initialization and regularization, and searched thebest regularization strength for each activation. The regularization strength of the reported resultsare reported in Table 7.
Table 8: Inference time comparison (milliseconds per batch on average). F2NN is faster than SAINTvariations.	________________________________________	Income	Forest	BankSAINT-s	6.890	7.621	5.764SAINT-i	1.502	3.327	1.348SAINT	2.449	4.480	2.107F2NN	0.660	0.933	0.57515UnderreVieW as a ConferenCe PaPersICLR 2022Table 9: Performance comparison per dataset, Averaged results over seeds 1-10.
Table 9: Performance comparison per dataset, Averaged results over seeds 1-10.
Table 10: Ablations per dataset3	ROC-AUC	AccuracyCredit^^HTRU2~~QSAR Bio Shrutime Spambase~~Philippine~~KDD99 Bank Blastchar~~Forest~~Shoppers Income~~Volkert^^MNISTF2NN	97.73	98.42	94.12	86.6	98.44	82.47	100	93.09	82.38	99.47	93.53	91.62	70.35	97.7Low-rank	96.95	98.57	93.49	86.69	98.09	81.41	100	92.88	82.41	96.35	93.2	91.67	65.27	92.66Shared	95.93	98.42	93.48	85.51	98.02	81.02	100	92.09	82.3	99.42	92.96	91.5	62.44	78.5Deep	97.48	98.25	93.54	85.39	98.24	81.47	100	93.11	82.3	99.58	93.54	91.77	71.9	93.24Quadratic	97.73	98.47	93.81	86.6	98.11	82.47	100	92.95	82.38	94.84	93.4	91.62	66.93	97.7ReLU	97.89	98.42	94.12	85.99	98.44	81.76	100	93.06	82.25	99.4	93.53	91.74	69.93	95.22GELU	97.71	98.42	93.77	85.93	98.4	81.73	100	93.09	82.26	99.47	93.49	91.69	70.35	94.88Table 11: Numerical networks ablastions per dataset, (i) stands for UfEfxf, (ii) represents I = K, and (iii) represents UFEF(VF度F ÷ bF)ROC-AUC	AccuracyCredit^^HTRU2^^QSAR Bio^^Shrutime^^Spambase^^Philippine^^KDD99 Bank^^Blastchar^^Forest^^Shoppers^^Income^^VolkertF2NN 97.73	98.42	94.12	86.6	98.44	82.47 IOO 93.09	82.38	99.47	93.53	91.62	70.358 5 67 5 27 7 719427%91%6 2 8
Table 11: Numerical networks ablastions per dataset, (i) stands for UfEfxf, (ii) represents I = K, and (iii) represents UFEF(VF度F ÷ bF)ROC-AUC	AccuracyCredit^^HTRU2^^QSAR Bio^^Shrutime^^Spambase^^Philippine^^KDD99 Bank^^Blastchar^^Forest^^Shoppers^^Income^^VolkertF2NN 97.73	98.42	94.12	86.6	98.44	82.47 IOO 93.09	82.38	99.47	93.53	91.62	70.358 5 67 5 27 7 719427%91%6 2 8τ/ lɪ lɪz9 9 91339J99,99,999 8 6∙4∙LZL8 8 86 2 2
