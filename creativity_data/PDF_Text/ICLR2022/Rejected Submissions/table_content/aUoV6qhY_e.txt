Table 1: Results on GLUE and SQUAD v1.1. We report Matthews correlation for CoLA, PearsonCorrelation for STS-B and accuracy for all other tasks. We report only “matched” accuracy forMNLI and the Exact Match score for SQUAD. Speedup and Compression are reported over thenon-Specialized baselines for DistilBERT and Q8BERT, and not over BERT-base.
Table 2: Sensitivity to random seeds. Results reported are averaged across the GLUE tasks andSQUAD on the Base models of each Transformer.
Table 3: Specialization of BERT-base and BERT-large. Results reported are averaged across theGLUE tasks and SQUAD.
Table 4: [Left] Results of Specialization with previously proposed methods (MRPC with BERT-Base). For L1-norm, magnitude and Taylor (absolute gradient of loss), we prune 5% of the leastimportant weights at a time and record the test accuracy. We report the highest test accuracy seen inthis process. [Right] Results of Specialization with different heuristics. All heuristics use hier-archical processing of ordered elements with Selective Hard Attention, unless otherwise specified.
Table 5: Results on GLUE. We report Matthews correlation for CoLA, Pearson Correlation forSTS-B and accuracy for all other tasks. We report only “matched” accuracy for MNLI. Speedup andCompression are reported over the non-Specialized baselines for DistilBERT and Q8BERT, and notover BERT-base.
Table 6: Specialized accuracy from inspecting elements in different orders on SST-2 usingBERT-Base. The baseline validation and dev accuracy of the fine-tuned model are 93.98 and 93.23,respectively.
Table 7: The order of inspected elements that provides maximum accuracy for different down-stream tasks using BERT-Base, DistilBERT-Base, Q8BERT-Base and XLNet-Base. We findthat the same ordering provides best performance on all the studied Transformer architectures.
