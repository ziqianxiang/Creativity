Table 1: Single defense method in transfer attacksAttacks		Math	JPEG Noise	Random Zoom	SWirl	Median FilterBlack box	MI-FGSM	0.91	033	061	0.21	076	DI-FGSM	0.86	05	068	0.41	077Grey box	MI-FGSM	0.74	067	074	-03-	074	DI-FGSM ∙	0.65	0.44	-	0.47	0.67	0.86 —Table 2: Single defense method in gradient optimization model attacksAttacks			Math	JPEG Noise	Random Zoom	SwirlWhite box	CWL 0	LL	0.97	100	100	0.63		Next	0.35	089	095	0.37	CWL 2	LL	0.94	100	099	0.72		Next	0.76	091	096	-071-	CWLi	LL	0.78	100	100	0.74		Next	0.24	094	097	0.46	FGSM		0.75	049	090	0.30	DeepFool		0.52	077	0.84	0.23	BIM		0.01	0.48	-	0.79	0.09Table 1 and Table 2 shows the detection rates for successful adversarial examples for each attackmethod. It can be obtained from TABLE 1 that the mainfold detection method performs better underblack-box and gray-box attacks, and the ability to reach a detection model above 0.65 thresholds is
Table 2: Single defense method in gradient optimization model attacksAttacks			Math	JPEG Noise	Random Zoom	SwirlWhite box	CWL 0	LL	0.97	100	100	0.63		Next	0.35	089	095	0.37	CWL 2	LL	0.94	100	099	0.72		Next	0.76	091	096	-071-	CWLi	LL	0.78	100	100	0.74		Next	0.24	094	097	0.46	FGSM		0.75	049	090	0.30	DeepFool		0.52	077	0.84	0.23	BIM		0.01	0.48	-	0.79	0.09Table 1 and Table 2 shows the detection rates for successful adversarial examples for each attackmethod. It can be obtained from TABLE 1 that the mainfold detection method performs better underblack-box and gray-box attacks, and the ability to reach a detection model above 0.65 thresholds isweak. In contrast, in the white-box scenario, the attack algorithm generated a powerful ability tocounter the sample interference model, which also led to the failure of the mainfold detection methodin some attack methods in TABLE2. For instance, the detection rate of BIM attacks is only 0.01.
Table 3: Performance of the combination method in transfer attacksAttacks		Black box		Grey box			MI-FGSM	DI-FGSM	MI-FGSM	DI-FGSMJPEG-Noise	Comb 1	0.85	0.95	070	079	Comb2	0.85	0.95	0.81	0.86	Comb 3	0.94	0.95	0.85	0.84Random Zoom	Comb 1	078	0.91	0.82	1.00	Comb2	0.88	100	0.96	0.86	Comb 3	0.97	1.00	0.96	0.86Swirl	Comb 1	0.88	0.95	0.86	0.86	Comb2	0.88	0.95	0.85	0.68	Comb 3	0.97	0.95	0.85	0.72Median Filter	Comb 1	0.91	0.86	074	070	Comb 2	0.94	1.00	0.93	1.00	Comb 3	1.00	-	1.00	0.93	∙	1.00	-Table 4: Performance of the combination method in gradient optimization model attacksWhite boxAttacks		CWL 0		CWL 2		CWLi		FGSM	DeepFool	BIM		LL	Next	LL	Next	LL	Next			JPEG-Noise	Comb 1	0.66	0.66	0.45	0.47	0.47	0.53	-075-	0.61	0.48
Table 4: Performance of the combination method in gradient optimization model attacksWhite boxAttacks		CWL 0		CWL 2		CWLi		FGSM	DeepFool	BIM		LL	Next	LL	Next	LL	Next			JPEG-Noise	Comb 1	0.66	0.66	0.45	0.47	0.47	0.53	-075-	0.61	0.48	Comb 2	1.00	0.94	1.00	1.00	1.00	0.97	-0.77-	0.93	0.71	Comb 3	1.00	0.97	1.00	1.00	1.00	0.99	-0.78-	0.95	0.71Random Zoom	Comb 1	0.57	0.55	0.45	0.55	0.46	0.46	-0.58-	0.51	0.57	Comb 2	1.00	0.98	0.99	0.96	1.00	0.99	-0.90-	0.94	0.91	Comb 3	1.00	1.00	1.00	1.00	1.00	0.99	-0.95-	0.97	0.95Swirl	Comb 1	0.86	0.61	0.80	0.57	0.83	0.58	-0.62-	0.53	0.12	Comb 2	0.90	0.59	0.95	0.85	0.93	0.72	-0.61-	0.50	0.08	Comb 3	0.93	0.66	0.98	0.93	0.95	0.72	0.67	0.61	0.15TABLE3 and TABLE4 show the detection result of using the orchestration detective strategy tosuccessfully attack samples. Comb1, Comb2, and Comb3 respectively represent the three kinds ofManifold Distance Judge’s orchestration strategies.
Table 5: Contrast with Feature Squeez-ing___________________________________Attacks		Recall			Comb	Feature SqueezingCWL0	LL	1.00	0.85	Next	1.00	0.85CWL2	LL	1.00	0.86	Next	1.00	0.87CWLi	LL	1.00	0.82	Next	0.99	0.77FGSM		0.95	033DeepFool		0.97	072BIM		0.95	0.417	ConclusionFrom TABLE1 to TABLE4, we can evaluate the classification efficiency of the orchestrated com-bined defense model. The experimental results illustrated that the performance of a single detectionmethod was inferior or equivalent to that of an ensemble combination of detection methods. How-ever, the performance of the orchestration detection method was far better than that, which showsthat the defense performance of this method has been improved significantly. Meanwhile, therewere different combinations in the orchestration detection methods. The different input transforma-
Table 6: SUccess rate for each attack on ImageNetConfigration	Attack	Li			L2				L0			FGSM	BIM	DeepFool	Mode	Next	LL	Next	LL	Next	LL			SUccess Rate		0.99	0.99	0.90	0.97	1.00	1.00	0.99	1.00	0.89We evalUate the manifold distance jUdge on the attacks described and sUmmarized in Table 6. Foreach targeted attack, we try two different targets: the Next class (t = L + 1 mod #classes), and theleast-likely class (LL), t = min (yb). Here t is the target class, L is the index of the groUnd-trUth classand yb is the prediction vector of an inpUt image. This gives eleven total attacks: the foUr Untargetedattacks (FGSM, BIM, MI-FGSM and DI-FGSM), and two versions each of the three targeted attacks11Under review as a conference paper at ICLR 2022(JSMA, CW∞ , CW2 , and CW0). We use the implementations of FGSM, and BIM provided by theCleverhans library. For MI-FGSM, DI-FGSM and the three CW attacks, we use the implementationsfrom the original authors.
Table 7: Performance of different orchestration strategies in gradient optimization model AttacksTransformers			acc			recall				IS						Single	Comb2	Comb3	Single	Comb2	Comb3	Single	Comb2	Comb3Random Zoom	CWL o	LL	0.93	-0.86~	-08~	1.00	-1.00~	-1.00~	1.00	-1.00~	-1.00~		Next	0.94	-0:86-	-081-	0.95	-098-	-1.00-	0.90	-095-	-1.00-	CWL 2	LL	0.93	-0:85—	-081-	0.99	-099-	-1.00-	0.98	-097-	-1.00-		Next	0.92	-0:82-	-0.80-	0.96	-096-	-1.00-	0.91	-0.89-	-1.00-	CWLi	LL	0.93	-086-	-0.80-	1.00	-1:00-	-1.00-	1.00	-1.00-	-1.00-		Next	0.94	-086-	-083-	0.97	-099-	-099-	0.94	-097-	-097-	-FGSM-		0.84	-0:82-	-078-	0.90	-0.90-	-095-	0.63	-076-	-0.85-	DeepFool		0.85	-0:79-	-0.80-	0.84	-094-	-097-	0.69	-083-	-091 ^^	BIM		0.83	-0:81-	-0.80-	0.79	-091-	-095-	0.61	-078-	-0.86-Swirl	CWL o	LL	0.80	-0.80-	-0.80-	0.63	-090-	-093-	0.44	-075-	-081 ^^		Next	0.65	-0.65—	-068-	0.37	-059-	-066-	0.19	-026-	-0.34	CWL2	LL	0.83	-0.82-	-083-	0.72	-095-	-098-	0.55	-0.86-	-0.94		Next	0.82	-0:78-	-081-	0.71	-085-	-093-	0.53	-066-	-081 ^^	CWLi	LL	0.83	-0.81-	-082-	0.74	-093-	-095-	0.56	-081-	-0.86-		Next	0.70	-0:70-	-072-	0.46	-072-	-072-	0.27	-042-	-043-	FGSM		0.63	-0.65—	-069-	0.30	-061-	-067-	0.15	-027-	-037-	DeepFool		0.60	-0.60-	-064-	0.23	-0.50-	-061-	0.11	-0.17-	-027-
