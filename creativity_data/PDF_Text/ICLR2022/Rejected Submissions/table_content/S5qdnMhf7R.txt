Table 1: Image classification results for VGG. The accuracy mean and standard deviation over threeruns with different seeds is reported. Training (T) time and inference (I) time required on CIFAR10.
Table 2: Image Classification results with ResNet models. Each experiment is run three timeswith different seeds and mean with standard deviation is reported. The proposed models far ex-ceed real-valued and quaternion baselines almost in each experiment we conduct. Interestingly, thePHC model outperform the real-valued counterpart by 4% points in the largest-scale experiment onCIFAR100. The time is similar to the claims in Table 1 so we do not add here to avoid redundancy.
Table 3:	Storage memory required for ResNet152s checkpoints on CIFAR100. Quaternion and PHCmodels allow a considerable disk memory saving with respect to the real-valued ResNet.
Table 4:	ImageNet classification with real-valued baseline against our best model PHC n = 3. Ourapproach outperform the baseline while saving the 66% of parameters.
Table 5: SEDnets results with one microphone (4 channels input). Scores are computed over threeruns with different seeds and we report the mean. The proposed method wtih n = 2 far exceeds thebaselines in each metric considered.
Table 6: SEDnets results with two microphones (8 channels input). Scores are computed over threeruns with different seeds and we report the mean. The PHC SEDnet n = 2 outperform the baselines.
Table 7: SEDnets FLOPs, training (T) and inference (I) time with 8 channels input. For training time(seconds/iteration) the mean and the standard deviation over one epoch is reported, for inferencetime we report the time required to perform an iteration on the validation set.
Table 8: VGG16 results with real-valued classifier for quaternion and PHC networks. Extension ofTable 1 in the main corpus.
Table 9: Additional preliminary experiments on SVHN dataset with ResNet20 and VGG11, thelatter with modified number of filters in order to be divided by each value of n and FC layers inthe closing classifier. We test also the PHC model with n = 1 to replicate the real domain whichoutperform the real-valued ResNet20.
Table 10: Additional preliminary experiments with ResNet56 and ResNet110, the latter with mod-ified number of filters in order to be divided by each value of n. Accuracy score is the mean overthree runs with different seeds.
Table 11: Additional experiments with ResNet-based models. We reduced the number of convo-lutional filters by 75% and then test the models on three datasets to remove the hypothesis that asmaller number of parameters leads to higher generalization capabilities.
Table 12: SED results with two microphone: magnitudes and phases (16 channels input). We testhigher order hypercomplex domains up to sedonions by setting n = 16. Although the incrediblereduction of the number of parameters with respect to the real-valued baseline in Table 6, the PHCwith n = 16 still has comparable performances with other models. Furthermore, the PHC withn = 8 outperform also the quaternion baseline which has more degrees of freedom.
