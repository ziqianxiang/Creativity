Table 1: Comparing SimCLR and MDSSL on single and multi-domain setupsTrain Dataset	Top-1 Accuracy CIFAR-10 I STL-10 ∣ SVHN ∣ CIFAR-100 ∣ AverageSingle-Domain Training	CIFAR-10	92.35	56.71	55.97	75.37	70.10STL-10	71.05	77.58	46.06	63.81	64.62SVHN	62.83	46.77	92.42	48.27	62.57CIFAR-100	79.58	55.27	61.16	90.29	71.57Multi-Domain Training					CIFAR-10, CIFAR-100, SVHN, STL-10	82.30	61.41	66.65	73.41	70.94CIFAR-10, CIFAR-100, SVHN, STL-10 (λ1 =1,λ2=0.1)	88.45	65.95	75.35	83.05	78.202	Related WorkSupervised classification techniques involve minimizing a loss function (e.g. the cross-entropy loss)to match model predictions to true labels. Unsupervised classification methods, on the other hand,learn to classify data without the use of training labels, usually with the use of clustering techniques(Bojanowski & Joulin, 2017; Dosovitskiy et al., 2014; YM. et al., 2020; Bautista et al., 2016; Caronet al., 2018; 2019; Huang et al., 2019).
Table 2: Resource utilization of SimCLR and MDSSL when trained on CIFAR-10, STL-10, SVHNand CIFAR-100 ____________________________________________________________Resource ∣ Single-Domain SimCLR ∣ MDSSLTraining Time (hours)	42.41	34.95 (-17.59%)Disk Memory (MB)	968	242 (-75%)Compute (GPUs)	4	2 (-50%)3.2	MDSSL Performance compared to SimCLR baselineIn this section, we analyze the performance of MDSSL and compare it to SimCLR trained on singledomains (referred to as the single-domain SimCLR) and multiple domains (referred to as the multi-domain SimCLR). Table 1 summarizes our results on CIFAR-10, STL-10, SVHN and CIFAR-100.
Table 3: GeneraIization of SimCLR and MDSSL to UnSeen domainsTrain Dataset	Top-1 Accuracy								CIFAR-10	STL-10	SVHN	CIFAR-100	DTD	Tiny- ImageNet	Average	CIFAR-10 STL-10 SVHN CIFAR-100 DTD Tiny-ImageNet ImageNet (250K)	92.35 71.05 62.83 79.58 64.95 81.67 68.16	56.71 77.58 46.77 55.27 51.68 63.20 75.43	55.97 46.06 92.42 61.16 49.86 53.75 49.09	75.37 63.81 48.27 90.29 55.98 82.69 50.03	40.50 39.22 36.47 42.24 50.43 44.03 50.57	19.95 21.41 13.42 21.36 19.40 37.99 21.00	56.80 53.18 50.03 58.31 48.71 60.55 52.38	Multi-Domain Training							Average (Training domains)	Average (Unseen domains)CIFAR-10, STL-10, SVHN	83.96	63.23	72.10	71.72	47.94	22.67	73.09	47.44CIFAR-10, STL-10, SVHN (λ1 = 0.9, λ2 = 0.1)	87.50	65.58	88.05	76.48	49.36	24.49	80.37	50.11CIFAR-100, DTD, Tiny ImageNet	77.27	59.22	68.06	75.72	51.82	28.40	51.98	68.18CIFAR-100, DTD, Tiny ImageNet (λ1 = 0.9, λ2 = 0.05)	81.92	62.89	72.35	83.93	54.77	30.18	56.29	72.38ImageNet (250K), CIFAR-100, SVHN	76.95	74.87	59.82	69.95	52.11	27.99	64.88	57.98ImageNet (250K), CIFAR-100, SVHN (λ1 = 0.9, λ2 = 0.1)	81.86	77.01	78.64	80.16	55.30	33.04	79.40	61.80our training datasets and assess the performances on CIFAR-10, STL-10 and SVHN. We also addresults on ImageNet (250K) which contains 1000 classes, each including 250 samples resized to32x32.
Table 4: Comparing SimCLR and MDSSL on diverse non-object-focused datasetsTrain Dataset	Top-1 Accuracy EuroSAT I ChestXRay ∣ DTD ∣ AverageSingle-Domain TrainingEuroSAT	88.95	93.57	45.75	76.09ChestXRay	85.03	95.29	46.20	75.50DTD	86.11	93.41	50.43	76.65Multi-Domain TrainingEuroSAT, ChestXRay, DTD	86.02	94.27	46.78	75.69EuroSAT, ChestXRay, DTD (λι = 0.9,λ2 = 0.15)	87.10	94.43	50.23	77.25A.2 Comparing MDSSL with SimCLR Pre-trained on ImageNetIn this section, we use a pre-trained SimCLR encoder from Pytorch Lightning Bolts (Falcon etal., 2019) and train a linear classifier on several unseen datasets. We resize all images to 32x32during linear classification to maintain consistency with the rest of our experiments. We realize thismay be an unfair comparison since the encoder is pre-trained on 224x224 images. Nevertheless,we observe a significant improvement in generalization of MDSSL over SimCLR pre-trained onfull-sized ImageNet on all datasets (See Table 5).
Table 5: Comparing SimCLR pre-trained on full ImageNet with MDSSLTrain Dataset	Top-1 Accuracy							CIFAR-10	STL-10	SVHN	CIFAR-100	DTD	Tiny- I ImageNet ∣	AverageImageNet	68.21	58.72	49.05	50.11	47.36	20.85 I	49.05Multi-Domain Training							CIFAR-10, STL-10, SVHN (λ1 = 0.9, λ2 = 0.1)	87.50	65.58	88.05	76.48	49.36	24.49	65.24CIFAR-100, DTD, Tiny ImageNet (λ1 = 0.9, λ2 = 0.05)	81.92	62.89	72.35	83.93	54.77	30.18	64.3414Under review as a conference paper at ICLR 2022A.3 Hyperparameter SelectionIn Figure A.1, we plot the similarity matrices of class-averaged samples of MDSSL trained onCIFAR-10 and SVHN by fixing λ2 = 0 and varying λ1. As explained in Section 3, higher λ1 in-creases the similarity of samples within a domain. We observe that when λ1 = -1 and λ2 = 0(SimCLR), the similarity within a domain is comparable with the similarity across domains, mean-ing that, domains are indistinguishable. As we increase λ1, we see that the similarity within domainsincreases and eventually, all samples show a mutual similarity of 1.
Table 6: Architecture of MDSSL encoder, projection head and linear classifierMDSSL Component	Layer	Output Size	Filters	Conv2d	64 X 16 X 16	7 x 7, 64, stride 2, padding 3	BatchNorm	64× 16 × 16	64	RelU	64X 16 X 16	-	MaxPool2d	64 X 8 X 8	3 x 3, stride 2, padding 1ResNet-50 Encoder	Bottleneck	256 X 8 X 8	planes 64, blocks 3	Bottleneck	512 X4X4	planes 128, blocks 4	Bottleneck	1024 X 2 X 2	planes 256, blocks 6	Bottleneck	2048 X 1 X 1	planes 512, blocks 3	AdaPtiveAvgPool2d	2048 X 1 X 1	1 x 1	Linear	2048	2048Projection Head	RelU	2048	-	Linear	128	128Linear Classifier	Linear	10	10Table 7: Hyperparameter details for MDSSL encoder, projection head and linear classifierMDSSL Component	Parameter	ValueEncoder and Projection Head	Latent Dimension Temperature Optimizer LR Scheduler Learning Rate Weight Decay Batch Size Number of Training Iterations GPU	128 0.1 LARS Warmup-Anneal 4 10-6 1024 48,000 Nvidia GeForce RTX 2080Linear Classifier	Input Dimension Optimizer LR Scheduler Learning Rate Weight Decay Batch Size Number of Training Iterations GPU	128 SGD - 0.1 - 1024 30000 Nvidia GeForce RTX 2080(Kolesnikov et al., 2019; Bachman et al., 2019; van den Oord et al., 2019). At test time, we discard
Table 7: Hyperparameter details for MDSSL encoder, projection head and linear classifierMDSSL Component	Parameter	ValueEncoder and Projection Head	Latent Dimension Temperature Optimizer LR Scheduler Learning Rate Weight Decay Batch Size Number of Training Iterations GPU	128 0.1 LARS Warmup-Anneal 4 10-6 1024 48,000 Nvidia GeForce RTX 2080Linear Classifier	Input Dimension Optimizer LR Scheduler Learning Rate Weight Decay Batch Size Number of Training Iterations GPU	128 SGD - 0.1 - 1024 30000 Nvidia GeForce RTX 2080(Kolesnikov et al., 2019; Bachman et al., 2019; van den Oord et al., 2019). At test time, we discardthe projection head (g(.)) and keep only the ResNet encoder (f (.)). We freeze the encoder and definea trainable linear layer that maps 128-dimensional features from the encoder to class probabilities.
