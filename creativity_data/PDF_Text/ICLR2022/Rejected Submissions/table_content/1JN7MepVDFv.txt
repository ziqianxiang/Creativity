Table 1: RMSE of multi-task networks trained on latentrepresentations obtained by different auto-encoder-basedmethods. For comparison, we added the model trained onground truth factors. The best results are bolded, and bestout of auto-encoder architectures underlined.
Table 2:	The architecture of auto-encoder-based methods. Non-linearity in all layers is given byReLU function.
Table 3:	The architecture of a single fully-connected head in the single- and multi-task neural net-work. We apply non-linearity (given by the ReLU function) after all layers except the last one.
Table 4: Test reconstruction error between the decoded images and the original input images.
Table 5: The exact values of the metrics computed in the experiment from Section 4.1.
Table 6: Numerical results of disentanglement metrics for latent on which multi-task training was(b) SAP score			Dataset	dSprites	Shapes3D	MPI3DAE	0.006	0.020	0.009VAE	0.032	0.020	0.017FactorVAE	0.068	0.020	0.011(d) informativeness (DCI)			Dataset	dSprites	Shapes3D	MPI3DAE	0.395	0.493	0.473VAE	0.579	0.533	0.484FactorVAE	0.664	0.610	0.482(f) completeness (DCI)			Dataset	dSprites	Shapes3D	MPI3DAE	0.046	0.078	0.078VAE	0.271	0.120	0.128FactorVAE	0.407	0.331	0.091predominant number of cases. What can be read as a surprise is that FactorVAE representations arenever the best in terms of the root mean square error metric of the model that was trained on them.
Table 7: The number of factors retrived by each method (mulit for multi-task models and singlefor a single task models) and the average/std/min and max correlation of the retrieved componentswith the ground truth factors.
Table 8: The test MSE for the experiments from Section 4.3 for dSprites dataset.
Table 9: The test MSE for the experiments from Section 4.3 for Shapes3D dataset.
Table 10: The test MSE for the experiments from Section 4.3 for MPI3D dataset.
