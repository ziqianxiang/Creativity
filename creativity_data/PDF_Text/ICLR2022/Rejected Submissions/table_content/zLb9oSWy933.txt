Table 1: Asymptotic time and memory cost of computing the NTK for an FCN. Costs are for apair of batches of inputs of size N each, and for L-deep, W -wide FCN with O outputs. ResultingNTK has shape NO × NO. NTK-vector products allow a reduction of the time complexity, whileStructured derivatives reduce both time and memory complexity. Note: presented are asymptoticcost estimates; in practice, all methods incur large constant multipliers (e.g. at least 3x for time; see§3.1). However, this generally does not impact the relative performance of different methods. See§3.6 for discussion, Table 7 for CNN, and Table 2 for more generic cost analysis.
Table 2: Asymptotic time and memory cost estimates of computing the NTK for a genericfunction. P stands for the number of all parameters in the network, Y stands for size of all pre-activations in the network, FP stands for forward pass, and G and J depend on the structure ofFP (§B). For example, FCNs usually have a cheap FP ≤ OP, as it consists of a single matrixmultiply with the parameter matrix, and therefore NTK-vector products are recommended. CNNs,notably when the number of output pixels D is large, have a costly FP ≥ OP, since it amounts to Dmatrix multiplies with the parameters, and therefore Structured derivatives are preferred. For preciseanalysis, see Table 1 for FCN and Table 7 for CNN.
