Table 1: Background distractions only. Mean ± Standard Error. Bold indicates best results at 500K steps.
Table 2: Variants produced by ablating the three major elements of CoRe’s design. RSAC and RCURL arevariants of SAC and CURL which use a recurrent architecture (same as CoRe’s). RSAC+Dyn models dynamicsin the latent state space. Recon does the same, along with pixel reconstruction. All models use data augmentation.
Table 3: Results on Distracting Control Suite Benchmark (dynamic-medium setting). Mean ± Standard Error.
Table 4: Architecture of model components.		Table 5: List of hyper-parameters.
Table 5: List of hyper-parameters.
Table 6: Action repeatTask	Action repeat	Table 7: Distraction settings in the Distracting Control SUite.		Ball in CUP catch	4			Cartpole swingup Cheetah RUn	8	Difficulty	Train videos	Val videos Camera and Color change scale	4	Easy MediUm	4 8	4	0.1 8	0.2Finger sPin	2	Hard	60	30	0.3	Reacher easy	4			Walker walk	2			steps as well to show that our model continues to improve with more steps. Performance is averagedover 10 random seeds, and 100 validation episodes at each checkpoint. When no distractions arepresent (Table 8a), all methods perform well, though CURL and CoRe are slightly better than the restin terms of mean scores. On the easy benchmark (Table 8b), CoRe outperforms other methods inall tasks, except reacher. As discussed in Section 3.3, this points to a key limitation of contrastivelearning-based methods, which is that they tend to remove constant information (such as the goallocation for reacher). However, at 1M steps, the performance on reacher is much better, showing thatthe model is able to eventually solve the task.
Table 8: Results on the Distraction Control Suite benchmark. All results reported at 500K steps, unlessmentioned otherwise. Mean reward ± Standard Error. Bold numbers indicate the best performing models at500K steps. f indicates baselines reported in Stone et al. (2021).
