Table 1: Performance of the model (MRR) on the LAD dataset (averaged over 50 iterations), withdifferent numbers of classes/pseudo-words to learn (N). (A) shows continual learning performanceand (B) shows retention performance. n/s = negative samples used for the scaling function.
Table 2: Performance of the model (MRR) on the LAD dataset (averaged over 50 iterations), withdifferent implementations of the scaling function, where |Ctrain | = 50.
