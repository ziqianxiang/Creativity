Table 1: Quantitative Results on Test Set Accuracy. We report the MSE difference between generated andground truth log spectrograms across methods, as well as the percentage (%) difference for the T60 reverberationtime. The best method for each room is bolded. For the nearest and linear baselines, we perform interpolation inthe time domain using samples from the training set.
Table 2: Quantitative Results on Cross-Modal Image Learning. Quantitative results on joint training ofNeRF and NAF jointly conditioned on a single local grid. We use very sparse training images in highly complexscenes. When evaluated on 50 test images, we observe that cross-modal learning helps improve PSNR when thevisual training data is more sparse. MSE results are multiplied by 103.
Table 3: Quantitative Results on Sound Localization. Quantitative results on sound localization distance innormalized room coordinates. NAFs can accurately estimate location of the emitter.
Table A1: Approximate on disk storage cost of different methods. We average the amount ofdata required for different methods of inference for the six scenes. Note that the linear and nearestinterpolation methods require the entire training set, while the NAF based methods use constantstorage.
Table A2: Learning different representations We compare learning magnitude only, jointly learningmagnitude and phase, as well as directly learning in the time domain.
Table A3: Regularizing the grid. In this experiment, we compare learning NeRF with a grid withoutregularization, and with L2 regularization.
