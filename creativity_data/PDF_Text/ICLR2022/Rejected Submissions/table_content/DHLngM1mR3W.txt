Table 1: Classification performance of Resnet-50 (He et al., 2016) backbone on CIFAR-10(Krizhevsky & Hinton, 2009), STL-10 (Coates et al., 2011) and Imagenet (Deng et al., 2009) acrossdifferent methods. All models were pretrained on the corresponding dataset without labels andfinetuned using the protocol described in SimCLR (Chen et al., 2020a). The autoencoder trainedwith our denoising criterion (AAVAE) outperforms the baseline VAE by 30% on CIFAR-10, 40%on STL-10 and 45% on Imagenet. Methods marked with ‚ùñ either use a different backbone thanResnet-50 or a different (non-linear) evaluation strategy.
Table 2: Semi-supervised evaluation of Resnet-50 encoder with 1% and 10% labels on Imagenet.
Table 3: Transfer performance of Imagenet pretrained Resnet-50 backbones on classification andobject detection tasks. Places205 dataset is used for classification transfer task with the table report-ing classification accuracy. For object detection, we use VOC07+12 dataset with Faster R-CNNalgorithm and C4 bakcbone.
