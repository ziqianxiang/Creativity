Table 1: Training accuracy (in %) of simple models on the perturbations of different attacks.
Table 2: Accuracy on clean test data of CIFAR-10. The target model is ResNet-18. The training dataare poisoned with different attacks. The smaller the accuracy, the better the attack efficiency.
Table 3: Accuracy (in %) on clean test data. The target models are trained on clean data (Dc) anddata perturbed by synthetic perturbations (Dsyn).
Table 4: Test accuracy (in %) when different countermeasures are applied. ‘Linear eval.’ means wefix the pre-trained weights and only train the classification layer.
Table 5: Training accuracy (in %) of simple models on the perturbations of different attacks. Theperturbations are generated with Tanh-DNNs.
Table 6: Test accuracy (in %) with different poisoning percentages p. Training with the poisonedsubset does not improve the test accuracy much compared to training with clean data only.
Table 7: Test accuracy (in %) when the proposed defense is applied. We fix the pre-trained weightsand only train the linear readout layer.
