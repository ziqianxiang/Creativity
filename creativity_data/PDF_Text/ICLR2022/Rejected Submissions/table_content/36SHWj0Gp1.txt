Table 1: DataSetS StatiSticSTraining				Evaluation	MalwareBazaar Malpedia	Benign	I OpenSSL	GMP	libtomcrypt	ImageMagick86,225	3,158	343,235	I 4,777	1,351	590	2,7334.1	Compared Methods and Evaluation MetricsWe uSe mean rank (MRR) and preciSion at 1 (P@1) aS the evaluation metricS, Since the Similaritydetection taSk can be regarded aS an information retrieval taSk. The following liSt containS thebaSelineS we implement to compare againSt GenTAL:TFIDF-str: TFIDF-baSed matching [30] by treating code aS text. IDF iS directly eStimated on theteSting Set, So thiS approach haS more edge over other DL-baSed methodS.
Table 2: Cross-compiler evaluation: Clang O0 Vs GCC O0Same Length	OpenSSL		GMP		libtomcrypt		ImageMagick		Average		MRR	P@1	MRR	P@1	MRR	P@1	MRR	P@1	MRR	P@1TFIDF-mne [30]	0.46	0.38	0.72	0.60	0.66	0.50	0.31	0.21	0.54	0.42TFIDF-str[30]	0.75	0.68	0.88	0.85	0.50	0.25	0.47	0.35	0.65	0.53MLM[10]	0.61	0.55	0.72	0.60	0.68	0.50	0.38	0.28	0.60	0.48MLM+NSP[10]	0.63	0.57	0.80	0.70	0.65	0.50	0.39	0.27	0.62	0.51MLM+SGP[10]	0.62	0.56	0.78	0.65	0.61	0.44	0.38	0.26	0.60	0.48MLM+SFP	0.62	0.56	0.81	0.70	0.61	0.44	0.38	0.26	0.61	0.49MLM+GC [10]	0.62	0.55	0.80	0.70	0.59	0.38	0.38	0.28	0.60	0.48MLM+DIS	0.65	0.58	0.76	0.65	0.63	0.38	0.45	0.34	0.63	0.49All-no-GC	0.64	0.57	0.79	0.65	0.48	0.25	0.36	0.22	0.57	0.42ALL [10]	0.66	0.58	0.85	0.75	0.69	0.56	0.44	0.32	0.66	0.55GenTAL		0.76	0.69	0.97	0.95	0.76	0.69	0.57	0.47	0.76	0.70Different	OpenSSL		GMP		libtomcrypt		ImageMagick		Average	Length	MRR	P@1	MRR	P@1	MRR	P@1	MRR	P@1	MRR	P@1TFIDF-mne [30]	0.12	0.07	0.46	0.31	0.33	0.21	0.14	0.09	0.26	0.17TFIDF-str[30]	0.35	0.29	0.57	0.47	0.39	0.27	0.25	0.19	0.39	0.30MLM[10]	0.15	0.10	0.37	0.24	0.26	0.14	0.15	0.09	0.23	0.14MLM+NSP[10]	0.16	0.11	0.40	0.26	0.27	0.15	0.17	0.10	0.25	0.16
Table 3: Cross-optimimzation level evaluation O2 vs O3 O0 vs O3O2-O3	OpenSSL		GMP		libtomcrypt		ImageMagick		Average		MRR	P@1	MRR	P@1	MRR	P@1	MRR	P@1	MRR	P@1TFIDF-mne [30]	0.20	0.13	0.83	0.75	1.00	1.00	0.47	0.34	0.63	0.56TFIDF-str [30]	0.82	0.80	1.00	1.00	0.96	0.93	0.93	0.91	0.93	0.91MLM[10]	0.82	0.81	1.00	1.00	0.96	0.93	0.92	0.90	0.93	0.91MLM+NSP[10]	0.82	0.81	1.00	1.00	0.96	0.93	0.92	0.90	0.93	0.91MLM+SGP[10]	0.82	0.81	1.00	1.00	0.96	0.93	0.92	0.90	0.93	0.91MLM+SFP	0.82	0.81	1.00	1.00	0.96	0.93	0.92	0.90	0.93	0.91MLM+GC [10]	0.82	0.81	1.00	1.00	0.96	0.93	0.92	0.91	0.93	0.91MLM+DIS	0.82	0.81	1.00	1.00	0.96	0.93	0.91	0.89	0.93	0.91All-no-GC	0.82	0.81	1.00	1.00	1.00	1.00	0.90	0.88	0.93	0.92ALL [10]	0.82	0.81	1.00	1.00	0.96	0.93	0.92	0.90	0.93	0.91GenTAL		0.87	0.83	1.00	1.00	1.00	1.00	0.94	0.91	0.95	0.94	OpenSSL		GMP		libtomcrypt		ImageMagick		Average	O0-O3	MRR	P@1	MRR	P@1	MRR	P@1	MRR	P@1	MRR	P@1TFIDF-mne [30]	0.05	0.02	0.35	0.23	0.52	0.36	0.11	0.06	0.26	0.17TFIDF-str [30]	0.48	0.35	0.62	0.52	0.68	0.57	0.73	0.66	0.63	0.53MLM[10]	0.08	0.05	0.28	0.19	0.56	0.36	0.25	0.18	0.29	0.19MLM+NSP[10]	0.08	0.05	0.26	0.16	0.53	0.29	0.22	0.14	0.27	0.16
Table 4:ObfUScation evaluation With GCC O0	OpenSSL		GMP		libtomcrypt		ImageMagick		Average		MRR	P@1	MRR	P@1	MRR	P@1	MRR	P@1	MRR	P@1TFIDF-mne [30]	0.51	0.41	0.46	0.33	0.36	0.26	0.42	0.31	0.44	0.33TFIDF-Str[30]	0.67	0.59	0.25	0.19	0.58	0.45	0.42	0.33	0.48	0.39MLM [10]	0.48	0.39	0.14	0.09	0.34	0.23	0.23	0.16	0.30	0.22MLM+NSP[10]	0.51	0.43	0.16	0.10	0.36	0.25	0.25	0.18	0.32	0.24MLM+SGP[10]	0.51	0.43	0.15	0.10	0.37	0.26	0.25	0.18	0.32	0.24MLM+SFP	0.51	0.43	0.16	0.10	0.37	0.26	0.25	0.18	0.32	0.24MLM+GC [10]	0.53	0.44	0.17	0.11	0.37	0.26	0.27	0.20	0.34	0.25MLM+DIS	0.53	0.43	0.19	0.13	0.39	0.28	0.31	0.23	0.35	0.27All-no-GC	0.49	0.40	0.17	0.12	0.36	0.25	0.26	0.19	0.32	0.24ALL [10]	0.56	0.47	0.20	0.14	0.39	0.28	0.31	0.23	0.36	0.28GenTAL	0.74	0.64	0.40	0.31	0.57	0.46	0.51	0.40	0.55	0.45is the most impactful similarity detection task, since malware often bypass detection software usingit.
