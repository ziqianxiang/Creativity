Table 1: Attack success rates of ImageNet adversarial examples on different models, generated from ResNet50in the untargeted setting.
Table 2: Cosine distance between x00 — X and VxJ(θ, x,y). Alarger cosine distance refers to a closer prediction of the gradientdirection.
Table 3: Changes in loss and confidence after applying reverse adversarial update on the images for ResNet50.
Table 4: Top-1 accuracy of the models under the example with reverse adversarial update from different sourcemodels. The source model “-” indicates clean example without any perturbation.
Table 5: Hyperparameters used in the baselines.
Table 6: Attack success rates of ImageNet adversarial examples on different models, generated from VGG19in the untargeted setting.
Table 7: Attack success rates of ImageNet adversarial examples on different models, generated from InceptionV3 in the untargeted setting.
Table 8: Attack success rates of ImageNet adversarial examples with single-step FGSM as the reference attack,generated from ResNet50 in the untargeted setting.
Table 9: Attack success rates of CIFAR-10 adversarial examples on different models, generated from VGG19in the untargeted setting.
Table 10: Attack success rates of CIFAR-100 adversarial examples on different models, generated fromVGG19 in the untargeted setting.
Table 11: Attack success rates of ImageNet adversarial examples, generated from Inception V3 in the untar-geted setting.
Table 12: Comparison of the attack success rates of ImageNet adversarial examples on different models, witheach augmentation removed from Aug-ILA.
Table 13: Comparison of the attack success rates of ImageNet adversarial examples on different models, witheach augmentation added to Aug-ILA.
Table 14: Running time comparison between ILA and Aug-ILA.
