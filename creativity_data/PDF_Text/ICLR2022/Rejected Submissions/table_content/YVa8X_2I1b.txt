Table 1: Reconstruction error on CLEVR2345 We consider an autoencoder baseline that usesa single NeRF object covering the whole scene (NeRF-AE), and compare it to our model on thetest set of CLEVR-2345. NeRF-AE struggles to reconstruct multiple objects accurately. In con-trast, INFERNO obtains much more precise reconstructions under all metrics and allows for objectidentity/pose manipulations.
Table 2: FID on CLEVR2345 We consider our model as a NeRF scene generator and compareit to the state-of-the-art. When reconstructing ground-truth images, our model obtains better FIDthan GIRAFFE. We then consider object manipulations to generate novel scenes from existing ones.
Table 3: Object Discovery on CLEVR6 INFERNO, despite inferring more complex 3D object seg-mentations without annotations, is competitive with the current state-of-the-art 2D object discoverymethods on CLEVR6.
Table 4: Snitch Localization on CATER. We report Top-1 and Top-5 accuracies for the snitchlocalization task. Our model outperforms the R3D LSTM and R3D NL LSTM models that learnunstructured representation. It indicates that the structured representation learned by INFERNO isuseful for this task. INFERNO pretraining is also critical, showing that the pretraining and not theencoder architecture is a key component. Overall, INFERNO achieves performances close to thestate-of-art approaches.
Table 5: Encoder Neural NetworkLayer Type	Size	Normalization	Activation	Other detailsConv 5 × 5	64	-	ReLU	Stride 1 Pad. 1Conv 5 × 5	64	-	ReLU	Stride 1 Pad. 1Conv 5 × 5	64		ReLU	Stride 1 Pad. 1Conv 5 × 5	64	-	ReLU	Stride 1 Pad. 1Encoder The goal of the encoder is to extract image features. We use an encoder with no down-sampling, as it is typically used with Slot Attention. Details about the encoder architecture aredescribed in Table 5.
Table 6: Slot Attention Neural NetworkName	Size	DescriptionPositional emb.	64	Additive embedding, same size as CNN input featuresFlatten		Flattens the spatial dimensions of CNN featuresQKV MLP	128	Linear layers that map slots and input features to the same dimensionLayerNorm	128	Normalizes the slots/inputsMLP + GRU	128	The output of soft-attention goes through a linear layer + GRUSlot Attention We employ Slot Attention to map image features to object slots. Slots are sampledrandomly from a Gaussian distribution with learned parameters. We use different distributions forthe background slot and the object slots. During training we employ three iterations of slot attentionto refine the image features to slot assignments.
Table 7: Slot to Object MLP detailsMLP Name	Size	Act and Norm.	DescriptionObj Pose	7	ReLU, LayerNorm	Slot to translation, scale and rotationObj Shape/App.	128	ReLU, CondLayerNorm	Slot to shape and appearanceBG Shape/App.	128	ReLU, LayerNorm	Background slot to its shape/app, fixed pose.
Table 8: Details about the NeRF MLPs usedMLP Name	Layers	Size	DescriptionObj MLP	8	64	ReLU activation, no norm. Skip connection with layer 4.
Table 9: Neural Upscaler architectureLayer	Size	Activation	Normalization	OtherConv 3 × 3	64	ReLU	Instance	Stride=1 Pad=1Upsample	-	-	-	Nearest NeighborsConv 3 × 3	64	ReLU	Instance	Stride=1 Pad=1Upsample	-	-	-	Nearest Neighbors(Only 128px) Conv 3 × 3	64	ReLU	Instance	Stride=1 Pad=1(Only 128px) Upsample				Nearest NeighborsConv 3 × 3	3	-	-	Stride=1 Pad=1Neural Upscaler The neural upscaler takes the low resolution output of the NeRF MLPs andupscales it to the full output resolution. Additionally, it maps the rendered image to RGB space.
