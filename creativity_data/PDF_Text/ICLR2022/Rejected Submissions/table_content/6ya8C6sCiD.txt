Table 1: The performance of the agent community playing discrimination game on dataset P3,(3,3,3) . LSTMrefers to vanilla LSTM-based agents, while IL refers to LSTM agents trained with iterated learning. The firstand second column shows the success rate in training set and testing set respectively.
Table 2: The performance of the agent community playing with a shared listener in description game on datasetD3,(3,3,3). SM refers to agents with the proposed architecture. The two metrics are calculated on both symbolicmapping and communication protocol for SM agents.
Table 3: The performance of the agent community playing discrimination game after they have learned toaccomplish description game.
Table 4: The performance of the agent communityplaying with a shared listener in description game ondataset D3,(4,4,4).
Table 5: The performance of the agent communityplaying with a shared listener in description game ondataset D2,(4,4) .
Table 6: The performance of the agent community playing with a shared listener in description game on datasetD3,(4,4,4) after vocabulary expansion. SM-reinitialized means the speaker network and the LSTM network ofSM agents are reinitialized.
Table 7: The learned symbolic mapping of the three agents in the community when playing with a shared listenerin description game on dataset D2,(3,3) .
Table 8: The learned symbolic mapping of the three agents in the community when playing discrimination gameafter they have learned to accomplish description game.
Table 9: The learned communication protocols of the three agents in the community when playing with a sharedlistener in description game on dataset D2,(3,3) .
Table 10: The learned communication protocols of the three agents in the community when playing discriminationgame after they have learned to accomplish description game.
