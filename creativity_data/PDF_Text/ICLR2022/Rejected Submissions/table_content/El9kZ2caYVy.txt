Table 1: Evaluation on CIFAR-10, CIFAR-100, and Tiny ImageNet. We report the misclassification rate (MCR), negative log-likelihood (NLLH), expected calibration error (ECE), the area under the misclassification-rejection curve (AUMRC), the misclassification rate (MR) at different rejection levels as well as the mean confidence (MC) for correct and incorrect predictions. All values but NLLH are given as percentages.										MCR	NLLH	ECE	AUMRC	MR5%	MR10%	MR25%	MC Corr.	MC Incorr.
Table 2: Comparison to output regularization methods and DUE (van Amersfoort et al., 2021) onCIFAR-10. Regularization methods are more accurate and better calibrated than the deterministicmodel, but perform worse at separating correct and incorrect predictions via their predictive entropy,resulting in a higher AUMRC. Our NC-VIBN clearly outperforms these previous methods.
Table 4: Image corruptions on CIFAR-10 (top) and CIFAR-100 (bottom) with three different levels ofseverity. The NC-VIBN model is consistently more robust to corruptions and offers better uncertaintyestimates compared to the deterministic and VIBN baselines.
Table 3: Ablations for the NC-VIBN on CIFAR-10. We compare the effect of L2-normalizationand learning weight uncertainties for the lastlayers via variational inference with the noise-contrastive loss and the full NC-VIBN setup.
Table 5: Overview of additional hyperparameters introduced by different methods.
Table 6: Additional results for a modified last layer setup on CIFAR-10, CIFAR-100, Tiny ImageNet,and ImageNet.
Table 7: Ensembling results on CIFAR-10, CIFAR-100, and Tiny ImageNet.
Table 8: Influence of the Lagrange multiplierÎ² for our full NC-VIBN model from the mainpaper trained on CIFAR-10.
