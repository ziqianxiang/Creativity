Table 1: Single-Cell RNA-Seq data descriptionDataset	cell number	gene number	cell type numberCRC	8496	12547	20GSE70580	647	26087	4GSE72056	4636	22280	7GSE75688	515	27420	5GSE96993	334	10827	4NSCLC	9051	12415	16PBMC	5356	14218	5Spleen human	4406	14064	7Spleen mouse	4432	12699	75.2	PreprocessingThere are tens of thousands of genes in the dataset. Before we train our model, we first implementdata preprocessing. For every cell in the data, we first divide every gene’s expression level by the sumof gene expression levels in the cell. This makes genes’ expression levels among cells comparable.
Table 2: Accuracy comparison with various machine learning methodsdataset	scCA	SVM	LDA	DT	RFCRC	88.29%	90%	87.29%	64%	81.47%GSE70580	96.92%	97.69%	96.15%	90%	96.92%GSE72056	94.50%	93.85%	91.91%	86.63%	91.59%GSE75688	92.23%	92.23%	91.26%	88.34%	91.26%GSE96993	82.83%	80.59%	77.61%	68.65%	82.08%NSCLC	84.15%	85.20%	82.77%	62.39%	79.18%PBMC	98.32%	98.13%	97.48%	95.52%	97.94%Spleen human	92.85%	92.85%	87.86%	82.53%	87.86%Spleen mouse	96.84%	97.29%	94.58%	88.61%	92.33%Table 3: Accuracy comparison with various neural network methodsDataset	scCA	scCapsNet	fully connected network	denoising autoencoderCRC	88.29%	84.47%	88.64%	83.71%GSE70580	96.92%	94.62%	96.92%	96.15%GSE72056	94.50%	92.20%	93.53%	91.33%GSE75688	92.23%	91.74%	92.23%	91.98%GSE96993	82.83%	77.61%	80.59%	79.59%NSCLC	84.15%	79.18%	82.93%	79.80%PBMC	98.32%	98.23%	98.5%	97.60%
Table 3: Accuracy comparison with various neural network methodsDataset	scCA	scCapsNet	fully connected network	denoising autoencoderCRC	88.29%	84.47%	88.64%	83.71%GSE70580	96.92%	94.62%	96.92%	96.15%GSE72056	94.50%	92.20%	93.53%	91.33%GSE75688	92.23%	91.74%	92.23%	91.98%GSE96993	82.83%	77.61%	80.59%	79.59%NSCLC	84.15%	79.18%	82.93%	79.80%PBMC	98.32%	98.23%	98.5%	97.60%Spleen human	92.85%	91.40%	92.63%	89.79%Spleen mouse	96.84%	96.17%	97.64%	95.41%We then compare scCA with neural network based methods. Here we implement fully-connectednetwork and denoising autoencoder. We use the code provided in scCapsNet. From the table above,7Under review as a conference paper at ICLR 2022we can see that among models based on neural networks, scCA still has a good performance. Itoutperforms other methods on most of the datasets.
Table 4: scCA’s performance under different parameters with 128-dimension capsuleDataset	8capsule + 16-dim compound features	16capsule + 16-dim compound features	8capsule + 32-dim compound features	16capsule + 32-dim compound featuresCRC	88.29%	88.41%	88.58%	88.94%GSE70580	96.92%	96.92%	96.15%	96.92%GSE72056	94.50%	93.96%	94.07%	94.18%GSE75688	92.23%	92.23%	92.23%	92.23%GSE96993	82.83%	82.08%	83.58%	82.78%NSCLC	84.15%	84.15%	83.76%	84.70%PBMC	98.32%	98.32%	98.32%	98.60%Spleen human	92.85%	92.40%	92.29%	92.85%Spleen mouse	96.84%	96.73%	97.06%	96.73%In table 4, we set the capsule dimension to 128 and change the number of capsules and the dimen-sion of compound features. Through the result from the table, we discover that there is no visibleimprovements no matter we rise the number of capsule or the dimension of compound features.
Table 5: scCA’s performance under different parameters with 64-dimension capsuleDataset	8capsule + 16-dim compound features	16capsule + 16-dim compound features	8capsule + 32-dim compound features	16capsule + 32-dim compound featuresCRC	87.70%	88.17%	88%	88.29%GSE70580	96.53%	96.92%	96.53%	96.92%GSE72056	93.64%	94.07%	93.75%	94.07%GSE75688	91.26%	91.26%	92.23%	92.23%GSE96993	82.08%	82.83%	81.34%	83.58%NSCLC	82.21%	82.44%	82.93%	84.32%PBMC	98.32%	98.41%	98.04%	98.41%Spleen human	92.06%	92.17%	91.95%	92.74%Spleen mouse	96.73%	96.73%	96.61%	96.92%In table5, we set the capsule dimension to 64 and change the number of capsules and the dimensionof compound features. Together with table 4, we discover that number of capsules, the dimensionof capsules and dimension of compound features have little influence on scCA’s performance. Ourmodel performs well under different settings of parameters.
