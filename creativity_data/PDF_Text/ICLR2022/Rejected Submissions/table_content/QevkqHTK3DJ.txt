Table 1: The comparison of MSE loss be-tween linear, LSTM, and CNN blocks totrain an autoencoder with a 64 compres-sion size.
Table 2: Comparing the number of parameters in a 3-layer decoder network with 768 input sizeto the number of parameters of the same decoder after applying the AutoEncoder to reduce theencoder’s output dimension.
Table 3: The ROUGE score for using a pre-trained autoencoder on top of pre-trained transformer-based encoders with different compression sizes. Tested each network using greedy, weighted ran-dom sampling, and beam search methods.
Table 4: The comparison between using the pre-trained AutoEncoder (AE), training the AutoEn-coder’s encoder jointly with the network from scratch (AE S), using a simple linear layer model forthe projection (LL), and PCA to do the dimensionality reduction.
Table 5: The comparison of a few vanilla encoder-decoder model generated summaries to the onesgenerated by the same model with the addition of AE with a latent space size of 384. Both resultsare generated using the greedy decoding method.
Table 6: The MSE loss value of the selected 3 network types (LSTM, linear, CNN) with a differentnumber of layers.
Table 7: The autoencoder models projections for different compression rates.
Table 8: The ROUGE score of more experiments on the optimal latent space size options.
Table 9: Comparing the generated summaries of the vanilla model and the model with a latent spacesize of 384 using the weighted random sampling decoding method.
Table 10: Comparing the generated summaries of the vanilla model and the model with a latentspace size 384 using the beam search decoding method.
Table 11: Comparing the vanilla and proposed models generated summaries quality using theBERTScore metric.
