Table 1: Statistics of the datasets used in the experiments.
Table 2: Performance of SEAL framework (row 5-9) compared to feedforward network trained withcross-entropy (row 1) and sturctured energy networks (row 2-4) that are learned with LE describedin earlier section. We observe feedforward network learned with SEAL is almost always betterthan cross-entropy learned model. We also observe while LE-marginand LE-regressiondoes not showsignificant difference, LE-NCErankingand LE-rankinghas stronger performance in general.
Table 3: Test F1 for text datasets.
Table 4: genbasemethod	λ	num samples	Θlr	Φlrmargin	0.001	n/a	0.0005	0.008regression	1.4	n/a	0.006	0.007regression-s	9	5	0.008	0.006NCEranking	0.4	40	0.007	0.005ranking	8	80	0.003	0.0001Table 5: cal500method	λ1	num samples	Θlr	Φlrmargin	0.0002	n/a	0.002	0.004regression	8	n/a	0.0001	0.00015regression-s	9	5	0.0001	0.003NCEranking	0.9	20	0.002	0.001ranking	1	60	0.0008	0.0001Table 6: deliciousmethod	λι	num samples	Θlr	Φlrmargin	0.001	n/a	0.0003	0.002regression	0.002	n/a	0.0006	0.004regression-s	0.01	20	0.0004	0.007NCEranking	0.5	40	0.001	0.002
Table 5: cal500method	λ1	num samples	Θlr	Φlrmargin	0.0002	n/a	0.002	0.004regression	8	n/a	0.0001	0.00015regression-s	9	5	0.0001	0.003NCEranking	0.9	20	0.002	0.001ranking	1	60	0.0008	0.0001Table 6: deliciousmethod	λι	num samples	Θlr	Φlrmargin	0.001	n/a	0.0003	0.002regression	0.002	n/a	0.0006	0.004regression-s	0.01	20	0.0004	0.007NCEranking	0.5	40	0.001	0.002ranking	0.3	40	0.0003	0.002Table 7: eurlexmethod	λι	num samples	Θlr	Φlrmargin	0.01	n/a	0.00003	0.001regression	0.02	n/a	0.0003	0.0006regression-s	2	30	0.007	0.002NCEranking	4	80	0.00005	0.0002
Table 6: deliciousmethod	λι	num samples	Θlr	Φlrmargin	0.001	n/a	0.0003	0.002regression	0.002	n/a	0.0006	0.004regression-s	0.01	20	0.0004	0.007NCEranking	0.5	40	0.001	0.002ranking	0.3	40	0.0003	0.002Table 7: eurlexmethod	λι	num samples	Θlr	Φlrmargin	0.01	n/a	0.00003	0.001regression	0.02	n/a	0.0003	0.0006regression-s	2	30	0.007	0.002NCEranking	4	80	0.00005	0.0002ranking	1	40	0.008	0.0005Table 8: exprfun17Under review as a conference paper at ICLR 2022method	λι	nUm samPles	Θlr	Φlrmargin	0.08	n/a	0.0001	0.002regression	9	n/a	0.001	0.00015
Table 7: eurlexmethod	λι	num samples	Θlr	Φlrmargin	0.01	n/a	0.00003	0.001regression	0.02	n/a	0.0003	0.0006regression-s	2	30	0.007	0.002NCEranking	4	80	0.00005	0.0002ranking	1	40	0.008	0.0005Table 8: exprfun17Under review as a conference paper at ICLR 2022method	λι	nUm samPles	Θlr	Φlrmargin	0.08	n/a	0.0001	0.002regression	9	n/a	0.001	0.00015regression-s	0.02	10	0.0002	0.0009NCEranking	0.7	60	0.008	0.0005ranking	1.5	40	0.004	0.002Table 9: SPofUnmethod	λ	nUm samPles	Θlr	Φlrmargin	0.0002	n/a	0.00005	0.001regression	3	n/a	0.005	0.003
Table 8: exprfun17Under review as a conference paper at ICLR 2022method	λι	nUm samPles	Θlr	Φlrmargin	0.08	n/a	0.0001	0.002regression	9	n/a	0.001	0.00015regression-s	0.02	10	0.0002	0.0009NCEranking	0.7	60	0.008	0.0005ranking	1.5	40	0.004	0.002Table 9: SPofUnmethod	λ	nUm samPles	Θlr	Φlrmargin	0.0002	n/a	0.00005	0.001regression	3	n/a	0.005	0.003regression-s	9	10	0.005	0.001NCEranking	5	20	0.0004	0.001ranking	9	40	0.00005	0.001Table 10: bibtexE	Analysis on parameter size and speed of inference and trainingHere, we Present the analysis on nUmber of Parameters (Table 11), inference sPeed (Table 12)), andtraining sPeed (Table 13) that different methods Utilize Per dataset.
Table 9: SPofUnmethod	λ	nUm samPles	Θlr	Φlrmargin	0.0002	n/a	0.00005	0.001regression	3	n/a	0.005	0.003regression-s	9	10	0.005	0.001NCEranking	5	20	0.0004	0.001ranking	9	40	0.00005	0.001Table 10: bibtexE	Analysis on parameter size and speed of inference and trainingHere, we Present the analysis on nUmber of Parameters (Table 11), inference sPeed (Table 12)), andtraining sPeed (Table 13) that different methods Utilize Per dataset.
Table 10: bibtexE	Analysis on parameter size and speed of inference and trainingHere, we Present the analysis on nUmber of Parameters (Table 11), inference sPeed (Table 12)), andtraining sPeed (Table 13) that different methods Utilize Per dataset.
Table 11: The nUmber of Parameters reqUired dUring train time for SEAL is aPProximately doUblethe size of feedforward (CE colUmn) while energy network and feedforward sizes are comParable.
Table 12: We simply average inference time for CE and SEAL variants as they are very similar.
Table 13: The training time per epoch is presented per dataset and per loss function used. Due todifferent gpu types and node status, there are some outliers. Furthermore, as SEAL runs multiplenumber of backpropagation steps for energy network and feedforward network in the alternatingoptimization, direct comparison of training time is not really available. However, the general trend interms of training time per epoch is CE < Energy Networks < SEAL.
