Table 1: Performance on ImageNet100 (Tian et al., 2020) dataset: We find that the Foveatedmodel outperforms the Full-resolution model both in terms of performance and computational com-plexity. Pure-Trans refers to the model with a single convolutional layer, and Hybrid refers to themodels with convolutional backbone at the start of the transformer as described in the previous sec-tions. For evaluation, the initial fixation for the Foveated model is chosen at the center of the imageto remove effects due to variations of the initial fixation location.
Table 2: Performance on ImageNet dataset: We compare our models against the state-of-the-artmodels with a similar number of parameters using three metrics: Top-1 accuracy, Image through-put, and Adversarial robustness. For reporting adversarial robustness, is set at 0.01, and theadversarial attack is computed for the transformer front-end only; therefore, we do not report com-parisons to the convolutional models. DS:Dynamic-Stop. Throughput for the dynamic-stop modelis computed as a weighted combination of throughputs of the Foveated model with a constant num-ber of fixations, i.e., 1 to 5 fixations. DeiT-Ti (distilled) refers to the transformer architecture aidedby a convolution network.
Table 3: Performance of the ImageNet pre-trained models on the auxiliary task without any addi-tional training.
Table 5: AdVersarial robustness on ImageNet100: dataset. Foveated-S-RD: FoVeated model withguided fixations and random initial fixation. Foveated-P: FoVeated model with pre-defined fixationswith parallel execution capability. Foveated-S-CT: FoVeated model with guided fixations and imagecenter as initial fixation.
