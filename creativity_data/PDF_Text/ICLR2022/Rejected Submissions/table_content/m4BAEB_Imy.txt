Table 1: Accuracy on pruning models for MNIST with ”Number of inputs” connections to eachneuron of current layer to neurons from previous layer.
Table 2: Accuracy, memory and computation requirements with different percentages of weightremaining for each neuron while pruning models for CIFAR-10.
Table 3: Accuracy, Memory and computation requirements of different combinations of percentageconvolution weights remaining per neuron and number of dense weights remaining per neuron foriPrune for CIFAR-10 BinaryConnect Deterministic.
Table 4: Comparison of our results with previous works, Guerra et al. (2020) on binary pruning andLi et al. (2016) on full precision networks. The source for our results is in Table 2Paper	Model	Baseline	Pruned	Memory	Memory Reduction	Computation ReductionLi et al. (2016)	VGG-16 (Full Precision)	93.25%	93.40%	21.6MiB	ɪ x 28.8 x	1.5xGuerra et al. (2020)	VGG-11 (Bi- nary Connect)	87.60%	86.53%	750KiB	Tx	T.4xOurs	Custom VGG (30% pruned) Custom VGG (20% pruned)	87.64% 87.64%	87.54% 86.20%	526KiB 357KiB	T.4x 2.0x	3.1x 4.4xTable 5: Comparison between trained, pruned and retrained network and a randomly initialized,pruned and trained BinaryConnect Deterministic network. The baseline accuracy for the Train-Prune-Train case is 87.64%.
Table 5: Comparison between trained, pruned and retrained network and a randomly initialized,pruned and trained BinaryConnect Deterministic network. The baseline accuracy for the Train-Prune-Train case is 87.64%.
