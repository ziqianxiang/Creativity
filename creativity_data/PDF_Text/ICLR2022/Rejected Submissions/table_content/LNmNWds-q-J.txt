Table 1: Mean Absolute Error (MAE) for QM9’s properties. 3D Infomax is tested with threedifferent pre-training datasets and GraphCL uses a two times larger subset of GEOM-Drugs. True3D SMP is a 3D GNN using ground truth 3D coordinates (hidden from other methods). Detailson confidence intervals are in Appendix B. Colors indicate improvement (lower MAE) or worseperformance compared to the randomly initialized (Rand Init) model.
Table 2: The MAE for GEOM-Drugs’properties. 3D Infomax compared withGraphCL and no pre-training.
Table 3: Comparison of 3D Infomax against predictive 3D pre-training baselines. Shown is theMAE for predicting QM9’s properties. Colors indicate improvement (lower MAE) or worse perfor-mance compared to the randomly initialized (Rand Init) model.
Table 4: Comparison of 3D pre-training baselines and GraphCL against 3D Infomax on variousOGB datasets. Shown is either the Root Mean Squared Error (RMSE) (lower is better) or the areaunder the ROC-curve (ROC-AUC) (higher is better). Colors indicate improvement, worse perfor-mance, or no significant change compared to the randomly initialized (Rand Init) model.
Table 5: Statistics of the used datasets. In the upper section are datasets with 3D information,which we use for pre-training, and the datasets in the bottom section do not contain additional 3Dannotations.
Table 6: Units and description of quantum mechanical properties of the QM9 dataset.
Table 7: Search space for the 2D network PNA through which we searched to obtain a strongbaseline performance on the energy of the highest occupied molecular orbital (homo) property ofthe QM9 dataset. The parameters were tuned in the order in which they are listed in this table fromtop to bottom. After this was completed for all parameters, we performed a second round of tuningfor a subset of them. The final parameters are marked in bold.
Table 8: Search space for the 3D network Net3D through which we searched to obtain a strongbaseline performance on the homo property of the QM9 dataset and we considered the size of thenetwork where parameters leading to less memory use are preferred. The parameters were tuned inthe order in which they are listed in this table from top to bottom. After this was completed for allparameters, we performed a second round of tuning for a subset of them. The final parameters aremarked in bold.
Table 9: Additional confidence intervals of our method in Table 1. All standard deviations arecalculated from 4 seeds except for the homo property where 6 are used.
Table 10: Additional confidence intervals for Table 2.
Table 11: Additional confidence intervals for Table 3.
Table 12: Comparison of 3D networks. The MAE of the homo property pre-training and fine-tuningon different halves of QM9. Net3D w/o γ refers to dropping the distance encoding of Net3D. Net3Dachieves the best MAE.
Table 13: Comparison of strategies for using multiple conformers. The middle double-columnshows the results for pre-training on one half of GEOM-Drugs and the right double-column cor-responds to pre-training on QMugs, and the second row indicates what dataset was used for fine-tuning. The Random Init row shows the performance when training from scratch without any pre-training. For QM9, the reported number is the MAE of the homo property, and for GEOM-Drugsit is the MAE when predicting the ensemble Gibbs free energy. There are large improvements fromusing multiple conformers, but the differences between the methods are small.
Table 14: Comparison of mutual information estimators for 3D Infomax. The middle double-columnshows the results for pre-training on one half of QM9, and the right double-column corresponds topre-training on one half of GEOM-Drugs, and the second row indicates what dataset was used forfine-tuning. The Rand Init row shows the performance when training from scratch without anypre-training. For QM9 the reported number is the MAE of the homo, and for GEOM-Drugs it is theMAE when predicting the ensemble Gibbs free energy.
Table 15: Comparison of latent space SSL methods. The numbers show the MAE when predictingQM9’s homo property after pre-training on one half of QM9 with the given method and fine-tuningon the other half of QM9. The Rand Init column shows the MAE without pre-training and withrandom weight initialization. 3D Infomax is our best latent space SSL method.
Table 16: MAE for predicting QM9’s molecular properties. SMP is tested with random weightinitialization and with the weights obtained from using it as 3D network in our 3D Infomax pre-training setup.
Table 17: MAE for QM9’s properties. 3D Infomax is tested with three different pre-training datasetsand compared with the 3D GNN SMP using explicit 3D coordinates. The conformers are generatedusing either the classical method RDKit ETKDG or the learned method GeoMol. Colors indicateimprovement (lower MAE) or worse performance compared to the randomly initialized (Rand Init)model.
Table 18: Comparison of performance when combining 3D pre-training with conventional pre-training by randomly dropping nodes on the 2D or 3D side (labeled 3D Infomax + ) for variousbiophysical property OGB datasets. GraphCL is another pre-trained baseline. Shown is either theRMSE indicated by ] where lower values are better or the area under the curve of the ReceiverOperator Characteristic (ROC-AUC) indicated by ↑ where higher values are better. Colors indicateimprovement, worse performance, or no significant change compared to the randomly initialized(Rand Init) model. 3D Infomax is either on par with random initialization or better. There is nonegative transfer as there is with GraphCL.
