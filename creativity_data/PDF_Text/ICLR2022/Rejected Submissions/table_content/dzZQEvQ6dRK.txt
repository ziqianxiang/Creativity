Table 1: Mean and standard deviation (s.d.) metric scores on dSprites dataset. The results of BYOLare averaged over three random seeds. The results of Ada-GVAE and SlowVAE refer to the Slow-VAE paper (Klindt et al., 2020). It shows strong and robust disentanglement property of BYOL.
Table 2: Disentanglement evaluation on the CelebA dataset. The result shows great robustness ofBYOL’s learned representations to show disentanglement on real-world datasets. Yet, the large gapbetween the score from that on synthetic datasets emphasises the difficulty of learning disentangledfactors on real-world images.
Table 3: Results of using different normalization strategies on dSprites. For group normalization,we set group number to 4. BYOL collapses with instance normalization (IN). For complete results,refer to Table 13 and Table 14 in the appendix.
Table 4:	The encoder architecture for our implemented BYOL on synthetic datasets. By default, weset D = 1000 to be aligned with the commonly used ResNet-50 backbone network. Besides, thereis a ReLU activation layer and a possible normalization layer following each convolutional layer tocreate a stack of (Conv-ReLU-Norm) blocks.
Table 5:	The implementation of linear classifier for factor prediction. With the D-dim latent codefrom the encoder, the classifier has multiple fully connected layers to shrink the feature vector to100-dimensional. Then, given the number of factor types K for the target dataset, as each factor hasnk (1 ≤ k ≤ K) values, we have K linear layers following the last shared layer in parallel. Theselayers predict the factor value on the corresponding K factors.
Table 6: The factor of datasets we evaluate on. Some factors are originally continuous but discretizedinto all integers. Therefore, all factor prediction is classification task. Given a representation modeltrained on the training set of a dataset, the linear classifier should achieve accuracy higher than thetheshold on all factors to be recognized “valid”. Only a “valid” representation model would be putinto the next step for disentanglement score evaluation. For the details of these factor definition,please refer to the original papers of these datasets.
Table 7: Evaluation of disentanglement on Cars3D by different metrics.The results of BYOL areaveraged over three random seeds. It shows strong and robust disentanglement property of BYOL.
Table 8: Evaluation of disentanglement on SmallNORB by different metrics. The results of BYOLare averaged over three random seeds. It shows strong and robust disentanglement property ofBYOL.
Table 9: Evaluation of disentanglement on Shapes3D by different metrics. The results of BYOL areaveraged over three random seeds. It shows strong and robust disentanglement property of BYOL.
Table 10: The influence of minimum scale of random resize-crop augmentation on the disentangle-ment of BYOL learned features. Here, the batch size is set to be 64.
Table 11: Disentanglement performance of VAE-based methods on dSprites, with an increased di-mension of latent code to 1000-dimensional.
Table 12: We study the impact of learning rates over trained model’s disentanglement. As all modelsare all tested on dSprites benchmark, BYOL shows its good generalization ability when trained onone dataset but transferring to other datasets.
Table 13: Results of using different normalization strategy with different batch size during trainingon dSprites. We evaluate the FactorVAE score to indicate the disentanglement property of modelweights from dSprites. For group normalization, we set group number to 4. BYOL collapses withinstance normalization (IN) only and the evaluated disentanglement score from it also collapses to aconstant here.
Table 14: The results to study the influence of Group Normalization (GN) and Weight Standardiza-tion (WS) on the representation disentanglement. The results prove the effectiveness of both GNand WS to help promote representation disentanglement.
