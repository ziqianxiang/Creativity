Table 1: Results for multi-task robotic manipulation (Meta-World) and navigation environments (AntMaze)with low-dimensional state inputs. Numbers are averaged across 6 seeds, ± the 95%-confidence interval. Wetake the results of No Sharing directly from Yu et al. (2021a). We include per-task performance for Meta-Worlddomains and the overall performance averaged across tasks (highlighted in gray) for all three domains. We boldthe highest score across all methods. Both CUDS and UDS outperforms prior vanilla multi-task offline RLapproach (No Sharing) and reward learning methods (Reward Predictor, VICE and RCE)Task Name	CUDS (ours)	UDS	No Sharing	CDS (oracle)	Sharing All (oracle)lift-banana	55.9%±11.7%	48.6%±5.1%	20.0%±6.0%	53.1% ±3.2%	41.8%±4.2%lift-bottle	72∙9%±12.8%	58.1%±3.6%	49.7%±8.7%	74.0%±6.3%	60.1%±10.2%lift-sausage	74∙3%±8.3%	66.8% ± 2.7%	60.9%±6.6%	71∙8%±3.9%	70.0%±7.0%lift-milk	73.5%±6.7%	74.5%±2.5%	68.4%±6.1%	83∙4%±5.2%	72.5%±5.3%lift-food	66∙3%±8.3%	53.8%±8.8%	39.1%±7.0%	61∙4%±9.5%	58.5%±7.0%lift-can	64.9%±7.1%	61.0%±6.8%	49.1%±9.8%	65∙5%±6.9%	57.7%±7.2%lift-carrot	84.1% ±3.6%	73.4%±5.8%	69.4%±7.6%	83∙8%±3.5%	75.2%±7.6%place-bowl	83∙4%±3.6%	77.6%±1.6%	80.3%±8.6%	81.0%±8.1%	70.8%±7.8%place-plate	86.2%±1.8%	78.7%±2.2%	86.1%±7.7%	85∙8%±6.6%	78.7%±7.6%place-divider-plate	89.0%±2.2%	80.2%±2.2%	85.0%±5.9%	87∙8%±7.6%	79.2%±6.3%average	75.0%±3.3%	67.3%±0.8%	60.8%±7.5%	74.8% ±6.4%	66.4%±7.2%Table 2: Results for multi-task imaged-based robotic manipulation domains in (Yu et al., 2021a). Numbers areaveraged across 3 seeds, ± the 95% confidence interval. UDS outperforms No Sharing in 7 out of 10 tasks as
Table 2: Results for multi-task imaged-based robotic manipulation domains in (Yu et al., 2021a). Numbers areaveraged across 3 seeds, ± the 95% confidence interval. UDS outperforms No Sharing in 7 out of 10 tasks aswell as the average task performance, while performing comparably to Sharing All. CUDS further improvesthe performance of UDS and outperforms No Sharing in all of the 10 tasks.
Table 3: Comparison between UDS / CUDS and the oracle data sharing strategies with access to the true rewardfunctions for relabeling. We take the results CDS and Sharing All directly from Yu et al. (2021a). CDS (Yuet al., 2021a) and Sharing All (Kalashnikov et al., 2021). UDS / CUDS achieve competitive results comparedto CUDS and UDS.
Table 4: Comparison between UDS / CUDS and the ACL (Yang & Nachum, 2021) that performs representationlearning on the unlabeled data instead of data sharing. Both UDS and CUDS outperforms ACL by a significantmargin in the average task result, suggesting that sharing the unlabeled data is crucial in improving the multi-taskoffline RL performance compared to only using the data for learning the representation.
Table 5: Success rate of the data shared from other tasks to the target task determined by the ground-truthmulti-task reward function.
Table 6: Performance of UDS under different actual success rates of the relabeled data.
Table 7: Results for multi-task walker experiment with dense rewards. CUDS and UDS are able to outperformNo Sharing while attaining competitive results compared to CDS and Sharing All with oracle rewards. Thissuggests that CUDS and UDS are able to solve more general problems where rewards are not binary.
Table 8: On the multi-task Meta-World domain, we compare CUDS and UDS to the model-based offline RLmethod COMBO (Yu et al., 2021b) that trains a dynamics model on all of the data and performs model-basedoffline training using the learned model. CUDS and UDS are able to outperform COMBO by a large margin.
Table 9: We perform an empirical analysis on the Meta-World door open task where we use varying dataquality and dataset size target task door open. We share the same dataset from the other three tasks in themulti-task Meta-World environment, door close, drawer open and drawer close to the target task.
Table 10: We perform an empirical analysis on the hopper environment from the D4RL (Fu et al., 2020)benchmark to test the sensitivity of UDS under the data quality and data coverage for both the labeled task dataand unlabeled data. The numbers are averaged over three random seeds. UDS outperforms No Sharing in 5out of 6 settings, suggesting that UDS is robust in different combinations of data quality and coverage of bothlabeled and unlabeled data. Note that UDS fails in the setting where the labeled data is of medium data qualityand the unlabeled data is random, suggesting that sharing data in settings where the labeled data is limited and oflow quality and the unlabeled data is also of poor quality is not useful.
Table 11: Summary of scenarios where UDS is expected to work and where it is not expected to work. Ldenotes the characteristics of labeled data, U denotes characteristics of unlabeled data. Limited/Abundant refersto the relative amount of data available (note that these are not absolute numbers and hard to precisely quantifywithout access to the problem domain, but a highly skewed ratio of the amount of labeled and unlabeled datamight help characterize it as limited/abundant). High-quality/medium-quality/low-quality refers to the actualperformance of the behavior policy generating the datasets. Narrow/broad refers to the relative state coverage ofthe datasets that we study.
