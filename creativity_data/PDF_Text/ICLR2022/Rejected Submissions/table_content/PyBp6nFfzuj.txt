Table 1: Hyperparameters detailsParameter	ValueBatch Size	16Optimizer	AdamLearning Rate	0.001LR scheduler patience	10LR scheduler factor	0.1Latent Variable Size	10Max epochs	500Dropout(Both Training and Test)	0.33.5	Loss FunctionsA combination of binary cross entropy and dice losses have been used to train the network. The firstpart binary cross entropy is a commonly used loss function for classification problems as shown by(Goodfellow et al., 2016). Every pixel in the image needs to be classified and hence loss function canbe written as shown in Equation 18.
Table 2: Uncertainty mean value of samples in the validation/test sets by our network.
Table 3: Mean Dice Similarity metrics for the experimentsTrain Size	DSC5	53.110	56.615	60.820	64.3Table 4: Intersection over Union metrics for the experimentsTrain Size IOU5	48.410	50.615	53.120	55.8Figure 4: Examples of models predictions on test samples, compared to ground truth segmentation.
Table 4: Intersection over Union metrics for the experimentsTrain Size IOU5	48.410	50.615	53.120	55.8Figure 4: Examples of models predictions on test samples, compared to ground truth segmentation.
