Table 1: Extrapolation performance in terms of MAPE on large graphs with different structures. Ontwo tasks (invsize and harmonic), GNP significantly outperformed the second best one.
Table 2: Extrapolation performances in terms of MAE on two node-level tasks (shortest and bfs).
Table 3: Extrapolation performance in terms of MAPE on set-related tasks. Only the basic modelequipped with GNP performed consistently well on all tasks. Especially for σpost and σMap，itsignificantly outperformed all competitors, including Set Transformer.
Table 4: EffeCtiveness of GNP- . The extrapolation performanCe of GNP degraded without GNP-.
Table 5: Graph classification accuracy. Replacing the carefully chosen pooling functions in SAGPooland ASAPool with GNP improved their accuracy on graph-classification tasks.
Table 6: Influence maximization performance. The influences of 100 seed nodes produced byMONSTOR and its variants in graphs unseen during training are reported. The variant equipped withGNP outperforms original MONSTOR (with max) and the other variant (with sum).
Table 7: Search space for maxdegree, harmonic, and invsize tasksHyperparameter	Selection poolOptimizer	RMSpropLearning rate for p	3e-2, 1e-2, 3e-3Learning rate for the other parameters	3e-2, 1e-2, 3e-3, 1e-3Norm clipping	1e2, 1e4(a) Search space for GIN with GNPHyperparameter	Selection poolOptimizer	Adam, Adam with β = (0.5,0.999), RMSpropLearning rate	3e-2, 1e-2, 3e-3, 1e-3Norm clipping	1e2, 1e4Number of iterations (for Set2Set)	1, 2	(b) Search space for GIN with baseline aggregation & readout functionsHyperparameter	Selection poolOptimizer	Adam, Adam with β = (0.5,0.999), RMSpropLearning rate	1e-2, 3e-3, 1e-3, 3e-4Norm clipping	1e2, 1e4(c) Search space for SAGPoolTable 8: Search space for bfs, shortest tasksHyperparameter	Selection pool
Table 8: Search space for bfs, shortest tasksHyperparameter	Selection poolOptimizer	RMSpropLearning rate for p	3e-2, 1e-2, 3e-3Learning rate for the other parameters	1e-2, 3e-3, 1e-3Norm clipping	1e2, 1e4(a) Search space for GIN with GNPHyperparameter	Selection poolOptimizer	Adam, Adam with β = (0.5,0.999), RMSpropLearning rate	3e-2, 1e-2, 3e-3, 1e-3Norm clipping	1e2, 1e4(b) Search space for GIN with baseline aggregation functionsB.3 Extrapolation on Set-related Tasks (Related to Section 4.4)For each task, we generated 4, 000 sets for training, 500 sets for validation, and 500 sets for test.
Table 9: Search space for μpost, σp°st, "map, and σMAPHyperparameter	Selection poolOptimizer	RMSpropLearning rate for p	3e-2, 1e-2, 3e-3Learning rate for the other parameters 3e-2, 1e-2, 3e-3Norm clipping	1e4(a)	Search space for GNPHyperparameter	Selection poolOptimizer Adam, Adam with β = (0.5,0.999), RMSpropLearning rate	3e-2, 1e-2, 3e-3, 1e-3Norm clipping	1e4(b)	Search space for basic operatorsHyperparameter	Selection poolOptimizer	Adam, Adam with β = (0.5,0.999), RMSpropLearning rate	1e-2, 1e-3, 1e-4Norm clipping	1e4Number of iterations (for Set2Set)	1, 2Encoder design (for Set transformer)	2 SAB blocks, 2 ISAB blocks(c)	Search space for Set2Set and Set TransformerTable 10: Statistics of real-world datasets
Table 10: Statistics of real-world datasetsDataset	Number of graphs	Average number of nodes	Average number of edgesD&D	1178	284.3	715.7PROTEINS	1113	39.06	72.82NCI1	4110	29.87	32.30For original ASAPool (Ranjan et al., 2020), we used the optimal hyperparameter settings sharedby the authors9. For ASAPool equipped with GNP, we used a different learning rate for p and q ofGNP. For DD and NCI1, we used 3e-2 and 3e-3 for the learning rate forp and q, respectively. ForPROTEINS, we used 1e-1 for the learning rate for p, and 1e-2 for the learning rate for q.
Table 11: Extrapolation performances of GNP on real-world datasets. Only except for the maxdegreetask on the NCI1 dataset, GNP showed near-perfect performance.
Table 12: Extrapolation performance of baseline approaches on real-world datasets. Except for themaxdegree task, there was no combination of simple pooling functions that extrapolated well.
Table 13: Test error on heterogeneous structures. Each row denotes the test MAPEs of the modeltrained using the same graph.
Table 14: Test error on graph-level tasks with different node feature distributions.
Table 15: Test error on graph-level tasks with different activation functions.
Table 16: Extrapolation performances on three graph-level tasks. We reported test MAPEs andstandard deviations. Near-perfect scores are in bold, and scores significantly better than those incompletely failed cases are underlined.
Table 17: Test error with different masking schemesTask	without masking	masking GNP+	masking GNP-invsize	1.2±0.3	1.1±0.1	99.6±1.0harmonic	1.1±0.8	1.0±0.7	100.1±0.1maxdegree	2.5±0.4	100.0±0.2	2.5±0.4Table 18: Node classification and graph regression performance. The values in parentheses are thereported test accuracies/MAEs and the reported standard deviations.
Table 18: Node classification and graph regression performance. The values in parentheses are thereported test accuracies/MAEs and the reported standard deviations.
Table 19: A closed-form solution for each task when the input set S = {χ1,χ2,…，Xn} is given.
Table 20: Statistics of real-world social networks used for the influence maximization task.
