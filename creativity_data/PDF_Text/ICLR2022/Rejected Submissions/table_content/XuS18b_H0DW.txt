Table 1: IBP certified robust error on MNIST data	QteSt = 0∙30	QteSt = 0∙35	QteSt = 0∙40	QteSt = 0∙45Qrain = 0∙30	-9∙81%-	-100%-	-100%-	-100%-Qrain = 0∙35	-876%-	-12∙13%-	-100%-	-100%-	Qrain = 0∙40		-866%-	-11∙40%-	-15∙82%-	-100%-Qtrain = 0∙45 (training gets unstable)	25∙13% 一	30∙62% 一	37∙63% 一	47∙88% -With slightly larger perturbation during training, the model is more capable to handle unseen datain the testing. This observation is empirical, however, due to the limitation of model capacity, it isdifficult for the model to handle all the examples with very large perturbation. When train = 0.45,we notice the training instability between different random seeds. Our intuitive explanation is shownin the right half of Figure 2: With large perturbation, for the vulnerable points around decisionboundary, the worst case prediction (indicated by orange dots) protrudes the ideal boundary witha large margin and it is sometimes impossible for the model to fit these points. Including theseworst case scenarios in training encourages over-fitting and compromises the model’s ability to findthe right boundary. In implementation, very large perturbation does not help improve the verifiedaccuracy. Besides, during the training stage, a fast growing perturbation schedule may potentiallycause instability.
Table 2: Robustness against different hyper-parameters with re-weighting with IBPDataset	《eval	《train	γ	α	Clean err.(%)	Verified err.(%)MNIST	0.3	0.4	baseline		2.28 ± 0.12	8.66 ± 0.05			1	0.1	2.28 ± 0.13	8.68 ± 0.06			5	0.1	2.30 ± 0.07	8.42 ± 0.07			10	0.1	2.28 ± 0.05	8.61 ± 0.05CIFAR-10	8/255	8.8/255	baseline		49.44 ± 0.49	72.26 ± 0.16			1	0.1	49.06 ± 0.01	72.32 ± 0.03			5	0.1	49.46 ± 0.27	71.44 ± 0.04			10	0.1	50.11 ± 0.38	71.60 ± 0.117Under review as a conference paper at ICLR 2022concentrate around the decision boundary. The re-weighting dilutes the example frequency to bothsides, thus the classification results are less sensitive to perturbation change.
Table 3: Robustness against different hyper-parameters with auto-tuning C with IBPDataset	Ceval	Ctrain	Cmaxoff	Clean err.(%)	Verified err.(%)MNIST	0.3	0.4	baseline	2.28 ± 0.12	8.66 ± 0.05			0.05	2.08 ± 0.08	8.52 ± 0.17			0.1	2.04 ± 0.05	8.46 ± 0.23			0.15	2.04 ± 0.10	8.36 ± 0.12			0.2	2.17 ± 0.02	8.78 ± 0.06CIFAR-10	8/255	8.8/255	baseline	49.44 ± 0.49	72.26 ± 0.16			0.005	49.17 ± 0.29	72.75 ± 0.53			0.01	49.21 ± 0.74	73.23 ± 0.50			0.015	49.21 ± 0.19	73.37 ± 0.27CIFAR-10	8/255	14/255	baseline	55.13 ± 0.73	70.50 ± 0.62			0.005	55.78 ± 0.30	69.29 ± 0.58			0.01	55.53 ± 0.88	69.44 ± 0.43			0.015	55.62 ± 0.34	69.93 ± 0.64Table 3 shows the hyper-parameters choice for auto-tuning . For the MNIST data set, we foundthe optimal hyper-parameter Cmaxoff around 0.15 where the certified accuracy gains by 0.3% frombaseline.
Table 4: Robustness improvement summary with IBPDataset	eval	train	re-weight	auto-eps	Clean err.(%)	Verified err.(%)MNIST	0.3	0.4	baseline		2.28 ± 0.12	8.66 ± 0.05				X	2.04 ± 0.10	8.36 ± 0.12			X		2.30 ± 0.07	8.42 ± 0.07			X	X	2.09 ± 0.06	8.01 ± 0.04CIFAR-10	8/255	14/255	baseline		55.13 ± 0.73	70.50 ± 0.62				X	55.66 ± 1.05	69.8 ± 0.39			X		55.78 ± 0.30	69.29 ± 0.58			X	X	55.05 ± 0.17	68.33 ± 0.214.2.4	Results on CROWN-IBPTo illustrate that our methods generally work for all the certifiable training, we apply the samemethods and optimal hyper-parameters from IBP setup directly to CROWN-IBP. For MNIST data,we achieves 0.32% improvement from baseline by re-weighting and 0.13% from auto-eps, com-bining the two is similar to using auto-eps only though. For CIFAR data, note that we use train-ing batch size 256 instead of 1024 in Zhang et al. (2020a), the standard train 8.8/255 has veri-fied error 68.10% ± 0.12% at eval = 8/255 from our experiments. By elevating the bulk train to14/255, the verified error increases to 68.35% ± 0.43%. After applying the two methods, we achieve66.72% ± 0.7% and beat the baseline by 1.38%.
Table 5: Robustness improvement summary with CROWN-IBPDataset	eval	train	re-weight	auto-eps	Clean err.(%)	Verified err.(%)MNIST	0.3	0.4	baseline		1.85 ± 0.11	7.02 ± 0.08				X	1.62 ± 0.01	6.89 ± 0.05			X		1.86 ± 0.04	6.70 ± 0.30			X	X	1.74 ± 0.02	6.90 ± 0.05CIFAR-10	8/255	14/255	baseline		54.29 ± 0.73	68.35 ± 0.43				X	54.73 ± 0.34	67.12 ± 0.08			X		53.41 ± 0.42	67.40 ± 0.32			X	X	53.65 ± 0.89	66.72 ± 0.75 ConclusionsThis paper proposed new methods to refine the decision boundary to improve the certifiable robust-ness accuracy. We prove the necessity to assign more weights towards adversarial examples arounddecision boundary by parameterizing the true adversarial distribution. A future direction could beexploring the adversarial mechanism for better approximation of re-weight function and promotingthe idea of re-weighting to other non-adversarial tasks. For auto-tuning, our initial interest was toprevent extremely large train and a relatively large train is necessary to show the effect. In practice,we can increase train until accuracy stabilizes and achieve further optimal verified error. Our intu-itive approach indeed finds a proper perturbation for each example. Given the fact that a larger trainachieves optimal certifiable accuracy still exists as an empirical finding (Gowal et al., 2019; Zhang
Table 6: Robustness improvement summary with IBPDataset	architecture	eval	train	re-weight	auto-eps	Clean err.(%)	Verified err.(%)MNIST	DM-small	0.3	0.4	baseline		3.27 ± 0.24	12.00 ± 0.35			0.4		X	3.25 ± 0.10	11.73 ± 0.57			0.4	X		2.75 ± 0.11	11.36 ± 0.24			0.4	X	X	2.87 ± 0.10	11.09 ± 0.33CIFAR-10	DM-small	8/255	8.8/255	baseline		51.86 ± 0.18	73.92 ± 0.17			14/255	baseline		58.08 ± 0.33	71.07 ± 0.23			14/255		X	57.56 ± 0.76	70.33 ± 0.29			14/255	X		58.36 ± 1.05	70.62 ± 0.46			14/255	X	X	57.29 ± 0.17	70.02 ± 0.18MNIST	DM-large	0.1	0.2	baseline		1.06 ± 0.07	3.08 ± 0.15			0.2		X	1.03 ± 0.01	3.06 ± 0.02			0.2	X		1.14 ± 0.07	2.86 ± 0.09			0.2	X	X	1.03 ± 0.04	2.92 ± 0.07CIFAR-10	DM-large	2/255	2.2/255	baseline		33.89 ± 0.42	58.80 ± 0.84			6/255	baseline		44.32 ± 0.27	52.93 ± 0.42			6/255		X	44.01 + ±0.46	52.38 ± 0.10			6/255	X		43.60 ± 0.18	52.57 ± 0.30			6/255	X	X	42.94 ± 0.64	52.17 ± 0.17
