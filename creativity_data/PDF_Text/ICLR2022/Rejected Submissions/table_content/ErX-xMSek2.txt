Table 1: Few-shot classification accuracies of different MAML source representations based onConvNet4 on Mini-ImageNet and Tiered-ImageNet.
Table 2: Few-shot classification accuracies of different MAML source representations based onResNet12 on Mini-ImageNet and Tiered-ImageNet.
Table 3: Few-shot classification accuracies of classification representation compared to MAML.
Table 4: Few-shot class	ification accuracies of different sel Mini-ImageNet				f-supervised source representations. Tiered-ImageNet			source rep./target task	5w1s	5w5s	10w1s	10w5s	5w1s	5w5s	10w1s	10w5sResNetW12-rot	34.61	48.60	22.10	34.05	35.40	46.87	22.10	31.24	(0.64)	(0.66)	(0.36)	(0.40)	(0.69)	(0.69)	(0.36)	(0.40)ResNetW12-loc	32.86	44.93	19.92	29.40	26.17	33.39	14.75	20.66	(0.63)	(0.65)	(0.35)	(0.38)	(0.51)	(0.59)	(0.26)	(0.34)ResNetW12-Contrast	46.63	64.83	33.56	50.75	52.63	72.00	39.26	59.37	(0.75)	(0.66)	(0.48)	(0.47)	(0.86)	(0.72)	(0.58)	(0.58)sentation using logistic regression does not beat training with MAML when we use the simpler CNNmodel ConvNet4. The main reason for this is the ConvNet4 model does not have sufficient capac-ity for the classification task (only 51% top-1 accuracy on Mini-Imagenet and 26% top-1 accuracyon Tiered-ImageNet), and thus the representation learned is not good enough for transfer. Whenwe switch to the higher capacity ResNet12 model (81% top-1 for mini-ImageNet and 70% top-1for tiered-ImageNet), the transfer learning approach works much better than MAML, with few-shotlearning accuracies close to many state-of-art methods (see comparison methods in Table 11). Thisis consistent with the observations in Tian et al. (2020), which we are reproducing here for compar-isons with other feature representations that follow. We believe the classification tasks (64 classesfor Mini-ImageNet and 351 for Tiered-ImageNet) force the CNN models to learn richer and morestable feature representations than the 5-way or 10-way MAML classification tasks. It is uncommonto sample more difficult pairs of classes (e.g. cat VS tigers) in 5-way or 10-way MAML setup based
Table 5: Prediction accuracies for holdout-evaluation of different self-supervised representations.
Table 6: Prediction accuracies for holdout-evaluation of different multi-task representations.
Table 7: Few-shot classification accuracies of different multi-task trained representations.
Table 8: Few-shot classification accuracies with auxiliary classes.
Table 9: Few-shot classification accuracies with location-based voting.
Table 10: Few-shot classification with rotation-based voting.
Table 11: Comparison of our approach against some state-of-art methods.
Table 12: Few-shot classification on different input image resolution.
Table 13: Few-shot classification using different number of augmented examples from training set.
