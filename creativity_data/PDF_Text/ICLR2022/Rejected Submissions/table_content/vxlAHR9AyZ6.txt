Table 1: Test accuracy (%) on CIFAR-10 (Non-IID) withdifferent Adversarial Training methods on the local client.
Table 2: Performance on three benchmark datasets under different federated optimization methods.
Table 3: Brief summary of the experimental details about α-WFATDataset	Network	∣	Lχj	IJK	I αCIFAR-10	NIN(Shahetal., 2021)	∣	rɪj	ΓH	I 1/6CIFAR-100	ReSNet-18 (Chenetal., 2021) ∣	5	1	I 1/41SVHN	SmallCNN (Zhang et al., 2019) ∣	5	1	I 1/11following Wang et al. (2019); Wu et al. (2020). Note that, the adversarial test data are generated byFGSM, PGD-20, C&W (Carlini & Wagner, 2017) attack with the same perturbation bound and stepsize as the training. All the adversarial generations have a random start, i.e, the uniformly randomperturbation of [-, ] added to the natural data before attacking iterations. Besides, we also reportthe robustness under a stronger AutoAttack, termed as AA for simplicity.
Table 4: Comparison with emphasize/de-emphasize the client with smallest loss.
Table 5: Performance on Non-IID settings under different federated optimization methods(Mean±Std).
