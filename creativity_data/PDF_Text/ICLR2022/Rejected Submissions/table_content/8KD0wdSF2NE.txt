Table 1: Analysis of different subdomain sizesThe accuracy is very similar for different subdomain sizes, but the computational time is drasticallydifferent. Higher subdomain resolution corresponds to fewer subdomains in the entire domain andhence reduction in computational cost. The reduction in solve time is not linear because the latentvector compression is smaller for larger subdomains to represent a larger space of PDE solutions.
Table 2: Comparison with baselinesExperiment	CoAE- MLSim	UNet	FNOChiP cooling (Temperature)	20.36	117.07	XVortex decay	0.04	0.08	0.09LaPlaCe Eq. (in Sec. A.2.1)	0.007	0.195	0.165	# paramsCoAE-MLSim	400 KUNet	7.418 MFNO		465 K5	ConclusionIn this work, we introduced the CoAE-MLSim approach, which is an unsupervised, low-dimensionaland local machine learning approach for solving PDE and generalizing across a wide range of PDEconditions randomly sampled from a high-dimensional distribution. Our approach is inspired fromstrategies employed in traditional PDE solvers and adopts an iterative inferencing strategy to solvePDE solutions. It consists of several autoencoders that can be easily trained with very few trainingsamples. The proposed approach is demonstrated to predict accurate solutions for a range of PDEsand generalize across sparse and high dimensional PDE conditions.
Table 3: Ablation study for different layer sizes20Under review as a conference paper at ICLR 2022The testing error formulation is shown in Eq. 4.sL2(Ypred - Ytrue)L2(Ytrue)(4)It may be observed from Table 1 3, that as the compression ratio of the flux conservation autoencoderdecreases, it begins to overfit and the testing error as well as the number of convergence iterationsand computational time significantly increase. On the other hand, if the compression ratio is toolarge the testing error increases. For all autoencoders used in this work, there exists an optimumbottleneck size compression ratio where the best testing error is obtained and the computationaltime is not too large.
Table 4: Comparison of UNet and CoAE-MLSim2.	Lâˆž error in temperature in the computational domain,3.	Error in heat flux (temperature gradient) on the chip surfaceThese metrics are more suited for engineering simulations and provide a much better measure forevaluating accuracy and generalization than average based measures. The state-of-the-art Unet(Ronneberger et al., 2015) is trained on the same number of training samples as used by the CoAE-MLSim approach using the architecture described above. The results are compared in the tablebelow.
Table 5: Comparison of training vs testing errorssolution for a specified set of PDE conditions. The iterative algorithm must figure out the solutionand is never taught anything about the trajectory to get there. As a result, the algorithm can performthe same on the training PDE conditions as it would on the testing conditions. This is different fromtraditional ML methods, which work better in training than in testing.
Table 6: Ablation study for different layer sizesIt may be observed that the CoAE-MLSim performs as well as FNO and UNet in the interpolationregion but outperforms both of them for long time flow dynamics.
