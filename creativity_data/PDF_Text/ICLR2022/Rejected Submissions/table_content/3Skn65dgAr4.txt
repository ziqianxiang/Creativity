Table 1: The results on FMP. Eight different optimizers are tried. Only Adamax and Adam arecompetent for this task in short epochs. We have removed useless control group from this table.
Table 2: Result on DNN. The four metrics are accuracy, f1-score, recall and precision. In the righttabular, we stack the result of SVHN and CIFAR100 together. The first three lines are for SVHNand the others is for CIFAR100.
Table 3: Dataset informationDataset	#Train/ #TeSt	#Attributes	#ClassMNIST	60,000/10,000	1*28*28	10SVHN	73,257 /26,032	3*32*32	10CIFAR10	50,000/10,000	3*32*32	10CIFAR100	50,000/10,000	3*32*32	100IRIS	120/ 30	4	3WINE	142/ 36	13	3CAR	1,382/ 346	6	4agaricus	6,499/ 1,625	116	2D Structure of FMPWe visualize the structure of FMP in Figure 7 supposing the input is a image of 28 Ã— 28. FMPis composed of 6 convolution block and 1 linear block. Each convolution block ends up with afractional maxpool. Each output of a convolution layer is processed by prelu activation.
Table 4: Dnn MNIST result detailMNIST	ACCU	FI-SCORE	RECALL	PRECISIONSGD	98.44	98.43	98.43	98.43Monmentum	95.69	95.65	95.75	95.63RMSProp	11.35	2.04	1.14	10Adadelta	97.35	97.33	97.37	97.33Adagrad	98.48	98.46	98.47	98.46ADAM	97.68	97.65	97.68	97.66ADAMW	98.42	98.41	98.4	98.42ADAMax	99.02	99.02	99.02	99.02DSA	98.93	98.92	98.92	98.92Table 5: Dnn SVHN result detailSVHN	ACCU	FI-SCORE	RECALL	PRECISIONSGD	19.59	3.28	1.96	10Monmentum	19.59	3.28	1.96	10RMSProp	19.59	3.28	1.96	10Adadelta	60.42	56.39	57.54	56.69Adagrad	19.59	3.28	1.96	10
Table 5: Dnn SVHN result detailSVHN	ACCU	FI-SCORE	RECALL	PRECISIONSGD	19.59	3.28	1.96	10Monmentum	19.59	3.28	1.96	10RMSProp	19.59	3.28	1.96	10Adadelta	60.42	56.39	57.54	56.69Adagrad	19.59	3.28	1.96	10ADAM	19.59	3.28	1.96	10ADAMW	19.59	3.28	1.96	10ADAMax	86.52	85.12	85.35	84.97DSA	87.35	86.18	86.25	86.16Table 6: Dnn cifar10 result detailCIFAR10ACCU F1-SCORE RECALL PRECISIONSGD 41.7	40.65	42.541.7Monmentum	43.89	42.21	43.82	43.89RMSProp	10	1.82	1	10Adadelta	40.52	40.55	43.11	40.52
Table 6: Dnn cifar10 result detailCIFAR10ACCU F1-SCORE RECALL PRECISIONSGD 41.7	40.65	42.541.7Monmentum	43.89	42.21	43.82	43.89RMSProp	10	1.82	1	10Adadelta	40.52	40.55	43.11	40.52Adagrad	53.48	53.5	53.69	53.48ADAM	10	1.82	1	10ADAMW	10	1.82	1	10ADAMax	60.23	59.52	60	60.23DSA	62.15	62.08	62.08	62.1514Under review as a conference paper at ICLR 2022MNISTSVHNCIFAR10Figure 8: Loss trend on DNN with different optimizers.
Table 7: Result on MLP with four feature datasets.
