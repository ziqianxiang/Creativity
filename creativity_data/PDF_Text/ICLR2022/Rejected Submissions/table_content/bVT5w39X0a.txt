Table 1: Accuracy and uncertainty on HW from 100 posterior predictive samples. The first column isthe average predictive entropy whereas for the o.o.d. datasets the second is the AUC/AP and for thein-distribution it is the test accuracy in %.
Table 2: Comparison of the jointrepresentation learning of HW data.
Table 3: Comparison of test accuracy and un-certainty quality in HW for different number ofsamples in Xr.
Table 4: F1 score and uncertainty on CCLE from 100 posterior predictive samples. This is analogoustable to Table 1, With different dataset._____________________________________________________	MOFA	mVAE	DeepIMV	mRNPCCLE	NA/56.69±5.7	0.68 / 63.70±5.30	0.67/61.54±5.77	0.22 / 65.96±4.62COAD	NA	0.66 / 49.83/51.41	0.62/62.93/61.84	0.41 / 72.47 / 69.67KIRC	NA	0.67 / 50.33/51.98	0.68 / 67.60 / 64.01	0.37 / 68.49 / 65.95SKCM	NA	0.67 / 48.64/51.43	0.68 / 68.08 / 64.75	0.42 / 73.74 / 70.65Poisson	NA	0.53 / 23.95/38.81	0.67/50.35/51.76	0.64 / 90.72 / 84.24Average	NA	0.63±0.0 / 43.18±12.8 / 48.43±6.4	0.66±0.0 / 62.24±8.2/ 60.59±6.0	0.46±0.1 / 76.35±9.8 / 72.5±8.08Under review as a conference paper at ICLR 2022choice to deal with high-dimensional data of small sample size,which is often the case in multi-omics data integration whenstudying complex disease. We further compare the models, basedon their robustness to the missing views in the test set. In this ab-lation study, we train mRNP and two other baselines with trainingset of CCLE, in which only 3% of the views was missing in themain dataset. At the test time, we artificially introduce missingviews by defining a probability of not observing an individualview for each sample. Please note that each view of the samples
