Table 1: Different architectures for different abstraction strategies. X (blue) is the original sequence embedding,Xs (green) is the embedding of the simplified sequence with entities replaced by their entity type tags, “ENC” isthe T5 encoder, H (blue) is the contextualized representation of sequence X , Hs (green) is the contextualizedrepresentation of sequence Xs, “DEC” is the T5 decoder, and Y is the target sequence to predict.
Table 2: Prediction accuracy on CLUTRR test set for all difficulty levels. Models have been trained on levels 2,4, 6 with only 9.58% of all the (e1, rel, e2) triples present in the test set. Per-level performance is colored inshades of green for better visualisation.
Table 3: Prediction accuracy on different slices of the ProofWriter D5 test set for all our models and theoriginally reported numbers by Clark et al. (2020). Models have been trained on depth D0, D1, D2. Models aretrained in the “open-world” assumption (OWA), except for the original Clark et al. (2020) model which wastrained in the “closed-world” assumption (CWA). Per-depth performance is colored in shades of green for bettervisualisation. The red boxed area indicates test problems at depths unseen during training.
Table 4: Test results for all models. (left) Exact Match, F1, Precision and Recall on HotpotQA. (right) ExactMatch and F1 on CoQA.
Table 5: Library version and model hyper-parameters.
