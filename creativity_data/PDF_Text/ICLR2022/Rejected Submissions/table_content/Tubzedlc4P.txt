Table 1: Classification accuracy by transfer learning for ModelNet10 (MN10) and ModelNet40(MN40) from ShapeNet.
Table 2: Classification accuracy by transfer learning for ModelNet10 (MN10) and ModelNet40(MN40) from ShapeNet under the noise levels of 1%, 5%, 10%, and 20%.
Table 3: The ranges of the shape parameters of the dataset used in Section 5.1.1SHAPE	param	min	max	param	min	max	param	min	maxCylinder	r	0.01	0.12	h	0.05	0.45			Cone	r	0.02	0.15	h	0.02	0.45			Ellipsoid	w	0.03	0.12	d	0.03	0.12	h	0.03	0.12In Section 5.1.2, we use a dataset consisting of boxes, cones, and ellipsoids divided into training/val-idation/test sets of size 720/240/240. The detail ranges of the aspect ratios of the shape parametersare shown in Table 4.
Table 4: The ranges of the shape parameters of the dataset used in Section 5.1.2SHAPE	param	min	max	param	min	maxElliptic cone	d/w	0.33	-^3^^	h/w	0.33	3Ellipsoid	d/w	0.33	3	h/w	0.125	0.33Box	d/w	0.33	3	h/w	0.33	3D.2 Details for Experiments on Synthetic 3D Basic Shape DatasetWe used an encoder with a structure similar to the classification network used in DGCNN (Wanget al., 2019). The input point cloud with dimension 3×512 passes through five EdgeConv layerswith point-wise latent space dimensions (64, 64, 128, 256) and a max pooling layer (we do not usea batch normalization layer unlike the original DGCNN classification network), then we can obtaina 1024-dimensional feature vector. Other settings are the same (e.g., k = 20, leaky relu activation)Then this feature vector again passes through three fully-connected neural networks with dimension(512, 256, 2) with leaky relu activation function and linear output activation function; the latentspace is two-dimensional. For the decoder model, we simply use a fully-connected neural networkas the decoder. The two-dimensional vector on the latent space passes through three fully-connectedneural networks with dimension (256, 512, 3×512) with relu activation function and linear outputactivation function; the output is a 3D point cloud with the number of points 512.
Table 5: The ranges of the shape parameters of the dataset used in quantitative analysis on syntheticdatasetSHAPE	param	min	max	param	min	maxElliptic cone short	d/w	0.33	3	h/w	0.125	0.33Elliptic cone normal	d/w	0.33	3	h/w	0.33	3Elliptic cone tall	d/w	0.33	3	h/w	3	8Ellipsoid short	d/w	0.33	3	h/w	0.125	0.33Ellipsoid normal	d/w	0.33	3	h/w	0.33	3Ellipsoid tall	d/w	0.33	3	h/w	3	8Box short	d/w	0.33	3	h/w	0.125	0.33Box normal	d/w	0.33	3	h/w	0.33	3Box tall	d/w	0.33	3	h/w	3	8Table 6: Normalized Mutual Information (NMI), Adjusted Rand Index (ADI), and Silhouette Coef-ficient (SC) of the vanilla autoencoder and regularized autoencoderMODEL	NMI	ADI	SCVanilla AE 0.7624 ± 0.2132^^0.7209 ± 0.2598^^0.4207 ± 0.0453Regularized AE 0.9484 ± 0.1391	0.9368 ± 0.1737 0.5279 ± 0.0817higher values, indicating that our regularization technique makes the autoencoder learn more optimallatent spaces.
Table 6: Normalized Mutual Information (NMI), Adjusted Rand Index (ADI), and Silhouette Coef-ficient (SC) of the vanilla autoencoder and regularized autoencoderMODEL	NMI	ADI	SCVanilla AE 0.7624 ± 0.2132^^0.7209 ± 0.2598^^0.4207 ± 0.0453Regularized AE 0.9484 ± 0.1391	0.9368 ± 0.1737 0.5279 ± 0.0817higher values, indicating that our regularization technique makes the autoencoder learn more optimallatent spaces.
Table 7: Classification accuracy by transfer learning for ModelNet10 (MN10) and ModelNet40(MN40) from ShapeNet under the the percentages of labeled training data of linear SVM classifier(50%, 10%, 5%, and 1%).
Table 8: Ellapsed time per one epoch when training FcNet, FcNet + E, and FcNet + IMODEL FcNet FcNet + E FcNet + ITIME (S)^^90.97	146.27	28751-On the other hand, since Hijkl is a huge 4D tensor, there may be a memory issue, but fortunately,there is no need to store this tensor for both autoencoder application tasks studied in this paper: (i)geodesic interpolation and (ii) learning optimal latent space coordinates. Because the calculationscommonly required to perform both tasks can be done without storing the tensor Hijkl entirely.
Table 9: Classification accuracy and reconstruction error according to regularization coefficient. Thetable is also arranged according to model (FcNet vs. FoldingNet) and regularization type (Vanillavs. Euclidean vs. info-Riemannian). For Riemannian metric cases, the regularization coefficientsused in the actual experiments are σ2 times λ shown in the table.
Table 10: Classification accuracy and reconstruction error according to regularization coefficient.
