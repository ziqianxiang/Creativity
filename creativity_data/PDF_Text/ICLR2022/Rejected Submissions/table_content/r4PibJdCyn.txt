Table 1: Baselines from Dacrema et al. (2021) and Rendle et al. (2020) and our results. The bestresults are highlighted in bold, the second best result is underlined.
Table 2: For Amazon books data, we use τ = 0.1, batch-size = 128. For Taobao data, we useτ = 0.067, batch-size = 2048. ComiRec-SA and ComiRec-DR are two multi-interest modelsproposed in Cen et al. (2020). The best results are highlighted in bold, the second best result isunderlined.
Table 3: Overall performance of mining the potential users of a single item. The % is omitted forprecision and recall. The hyper-parameters of MFb are batch-size = 4096 and τ = 0.125, and forTR they are batch-size = 512 and τ = 0.125. We use d = 96 for all models for a fair comparison.
Table 4: Statistics of the split Movielens datasets in PUMS experiments.
Table 5: Overall performance of mining the potential users of a group of items. The % is omittedfor precision and recall. The hyper-parameters of MFb are batch-size = 4096 and τ = 0.125, andfor TR batch-size = 512 and τ = 0.111. We use d = 96 for all models.
