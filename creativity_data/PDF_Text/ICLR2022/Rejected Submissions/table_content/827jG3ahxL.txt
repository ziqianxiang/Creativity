Table 1: Node level and proof level accuracy of REFACTOR with different input configurations. Noedge: all the edges in the graph are removed; Leaves→Root: only keep the edges that are in the samedirection of the paths that go from leaves to their parents; Leaves—Root: same as Leaves→Rootexcept all the edges are reversed; Leaves-Root: the original graph with bidirectional edges. NodeFeatures: whether or not the node features are fed as input to the model. All the experiments are runwith K = 10 and d = 256.
Table 2: Node level and proof level accuracy of REFACTOR with various model sizes.
Table 3: An analysis of incorrect predictions on the Table 4: Proof success rate comparison. Newtheorem extraction dataset.____________________________ theorem usage for REFACTOR is averagedDataset Total Not Tree & Invalid Tree & Invalid Tree & Valid across 1 and 5 min setting.
Table 5: Theorem usage and their contribution to refactoring	# Theorems Used	Total Usage	Average Usage	Max Usage	Average Number of Nodes Saved	Total Number of Nodes SavedExpanded	670	147640	77.4	60705	196.7	375126Original	14	11736	733.5	8594	2025.8	32413Total	684	159376	82.9	60705	211.9	407539may pursue a compression objective for this purpose, to find the most frequently appeared fragmentsacross all proofs. Our single-proof prediction approach puts its main focus on human preferences andcould potentially be combined with compression as future work.
