Table 1: Comparing DGT with baselines using Micro - and Macro-AUC on real-world datasets.
Table 2: Comparison of Micro - and Macro-AUC on real-world datasets restricted to new edges.
Table 3: Comparison of the epoch time and memory consumption of DGT with baseline methodson the last time step of ML-10M and Yelp dataset using the neural architecture configurationSUmmarized in Section C.4._________________________________________________________________Dataset	Method	Memory consumption	Epoch time	Total time	DYSAT	9.2 GB	97.2 Sec	4276.8 Sec (45 epochs)ML-10M	EvolveGCN	13.6 GB	6.9 Sec	821.1 Sec (120 epochs)	DGT (Pre-training)	6.5 GB	38.9 Sec	986.5 Sec (89 epochs)	DGT (Fine-tuning)	10.1 GB	2.98 Sec	62.2 Sec (22 epochs)	DYSAT	5.4 GB	29.4 Sec	4706.4 Sec (160 epochs)Yelp	EvolveGCN	7.5 GB	19.14 Sec	1091.2 Sec (57 epochs)	DGT (Pre-training)	21.3 GB	11.8 Sec	413.5 Sec (34 epochs)	DGT (Fine-tuning)	21.3 GB	21.41 Sec	521.6 Sec (23 epochs)A.2 Ablation study results.
Table 4: Comparison of the Micro- and Macro-AUC of DGT Using single-tower and two-tower modelarchitecture on the real-world datasets.__________________________________________Method	Metrk	UCI	Yelp	ML-10MSingle-tower	Micro-AUC	87.86 ± 0.60	72.95 ± 0.20	94.80 ± 0.81	Macro-AUC	88.27 ± 0.68	73.81 ± 0.21	95.49 ± 0.57Two-tower	Micro-AUC	87.91 ± 0.32	73.39 ± 0.21	95.30 ± 0.36	Macro-AUC	88.49 ± 0.43	74.31 ± 0.23	96.16 ± 0.222The node representation H(') in the single-tower DGT is computed byH(') = FFN(LN(Z ⑶)+ Z⑷(LN(H('-1))W('))(LN(H('-1))W(K))>	`ʌ	(? WZ(') = Softmax ( -- ------Q 恭 --------------K-— + ATC + ASD ) LN(H(J))Wp) + H('-1).
Table 5: Comparison of the Micro- and Macro-AUC of full attention and K-hop attention using thesingle-tower architecture on the real-world datasets.
Table 6: Comparison of the Micro- and Macro-AUC of with and without spatial-temporal encodingon the real-world datasets.____________________________________________________________________Method	Metric	UCI	Yelp	ML-10MWith both encoding	MiCrO-AUC=	87.91 ± 0.32	73.39 ± 0.21	95.30 ± 0.36	Macro-AUC	88.49 ± 0.43	74.31 ± 0.23	96.16 ± 0.22Without any encoding	Micro-AUC	83.27 ± 0.29	72.82 ± 0.37	91.81 ± 0.43	Macro-AUC	83.87 ± 0.47	73.80 ± 0.38	92.59 ± 0.35Only temporal connective encoding	Micro-AUC	84.78 ± 0.31	73.36 ± 0.26	94.51 ± 0.37	Macro-AUC	84.60 ± 0.42	74.31 ± 0.25	95.43 ± 0.29Only spatial distance encoding	Micro-AUC	87.01 ± 0.46	72.98 ± 0.32	92.34 ± 0.40	Macro-AUC	87.99 ± 0.47	73.90 ± 0.36	93.13 ± 0.33The effect of the number of layers. In Table 7, we compare the Micro-AUC score and Macro-AUCscore of DGT with a different number of layers on the UCI, Yelp, and ML-10M datasets.
Table 7: Comparison of the Micro- and Macro-AUC score of DGT with different number of layerson the real-world datasets.__________________________________________Method	Metric	UCI	Yelp	ML-10M2 layers	Micro-AUC	87.89 ± 0.43=	74.30 ± 0.21	94.99 ± 0.21	Macro-AUC	88.31 ± 0.53	74.29 ± 0.23	96.08 ± 0.154 layers	Micro-AUC	87.42 ± 0.36	73.39 ± 0.21	95.30 ± 0.36	Micro-AUC	88.35 ± 0.37	74.31 ± 0.23	96.16 ± 0.226 layers	Micro-AUC	87.91 ± 0.32	74.30 ± 0.20	95.35 ± 0.28	Micro-AUC	88.49 ± 0.43	74.28 ± 0.22	96.11 ± 0.1816Under review as a conference paper at ICLR 2022A.3 Node classification resultsIn this section, we show that although DGT is orginally designed for the link prediction task, thelearned representation of DGT can be also applied to binary node classification. We evaluateDGT on Wikipedia and Reddit dataset, where dataset statistic is summarized in Table 11. Thesnapshot is created in a similar manner as the link prediction task. As shown in Table 8 and Figure 5,DGT performs around 0.7% better than all baselines on the Wikipedia dataset and around 0.7%better than EvolveGCN on Reddit dataset. However, the results DGT on the Reddit dataset isslightly lower than DySAT. This is potentially due to DGT is less in favor of a dense graph, e.g.,Reddit dataset, with very dense graph structure information encoded by spatial-temporal encodings.
Table 8: Comparison of the Micro- and Macro-AUC score of DGT with different number of layerson the real-world datasets for binary node classification task.
Table 9: Comparison of the Macro-AUC score of DGT and its variants with input graph with differentnoisy level.
Table 10: datasets.	Comparison of the Micro- and Macro-AUC score of DGT				, JODIE on the real-world	Method	Metric	UCI	Yelp	ML-10M	DGT	Micro-AUC	87.91 ± 0.32=	73.39 ± 0.21	95.30 ± 0.36		Macro-AUC	88.49 ± 0.43	74.31 ± 0.23	96.16 ± 0.22	JODIE	Micro-AUC	57.99 ± 0.34	59.85 ± 0.32	62.84 ± 0.47		Macro-AUC	57.21 ± 0.37	61.01 ± 0.44	61.30 ± 0.46	TGAT	Micro-AUC	48.15 ± 0.45	51.95 ± 0.39	52.15 ± 0.51		Macro-AUC	49.02 ± 0.43	52.78 ± 0.40	51.15 ± 0.50B Pre-training can reduce the irreducible errorB.1 Preliminary on information theoryIn this section, we recall preliminaries on information theory, which are helpful to understand theproof in the following section. More details can be found in books such as Murphy (2022); Cover &Thomas (2006).
Table 11: Statistics of the datasets used in our experiments.
Table 12: Hyper-parameters used in DGT for different datasets. “-” stands for hyper-parameters thatare not required.
Table 13: Comparison of different graph Transformers.
