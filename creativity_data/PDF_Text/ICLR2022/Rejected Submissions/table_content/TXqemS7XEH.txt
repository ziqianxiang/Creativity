Table 1: Experimental results on downstream evaluation of natural language understanding. Weevaluate the performance of models on 8 tasks of GLUE dev set except for WNLI following Devlinet al. [7].
Table 2: Experimental results on downstream task evaluation. “#Params” refers to the number ofparameters. We report the PPL evaluation on WikiText-103 and the ROUGE1, ROUGE-2, andROUGE-L evaluation on Gigaword.
Table 3: Model refers to the types of model. dmodel and dff refer to the hidden size and intermediatesize. L refers to the number of layers in the computation graph, and l refers to the number oftransformer layers with parameters. #Heads refers to the number of heads in self attention. #Paramsrefers to the total number of model parameters. We also report their training speed on 48 GPU devicesby the number of consumed samples per second.
Table 4: Experimental results of large models trained with limited budget on downstream taskevaluation. We report the PPL on WikiTeXt-103 and the ROUGE scores on GigaWord.
