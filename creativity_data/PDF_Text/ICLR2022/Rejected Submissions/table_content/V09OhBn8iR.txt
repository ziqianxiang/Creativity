Table 1: Average test accuracy and standard deviation (three runs) on experiments with the MNISTvariants under various bias ratios. The best accuracy is indicated by bolded for each case.
Table 2: Average test accuracy and standard deviation (three runs) on experiments with the MNISTvariants under a 1% bias ratio and {0%, 5%, 10%} noisy labels. The best accuracy is reported inbolded for the minority case.
Table 3: Test accuracy of real-worldbenchmarks averaged under three runs.
Table 4: Hyperparameters for each taskHyperparameters. The hyperparameters that we used are summarized in Table 4. We share basic hy-perparameters (including Network Type, Learning rate, Learning rate decay,Learning rate decay epoch, Momentum, Weight decay, and Batch sizeand Number of Epoch) for all algorithms. Precisely, for the proposed method, we set GCEparameter q and Dimension size K for our method, as in Table 4.
Table 5: Average test accuracy and standard deviation (3 independent runs) on experiments withColored MNIST data under various bias ratio. The best accuracy on average of Major andMinor test is reported in bold font.
Table 6: Average test accuracy and standard deviation (3 independent runs) on experiments withWatermarked MNIST data under various bias ratio. The best accuracy on average of Majorand Minor test is reported in bold font.
Table 7: Average test accuracy and standard deviation (3 independent runs) on experiments withCartoon data under various bias ratio. The best accuracy on average of Major and Minor testis reported in bold font.
Table 8: Test accuracy of real-worldbenchmarks averaged under three runs.
Table 9: Test accu-racy of real-world bench-marks averaged underthree runs. The best accu-racy is reported in boldfont.
Table 10: Test accuracy of real-world benchmarks averaged under three runs. The best accuracy isreported in bold font in each column.
Table 11: Ablation study on λ19Under review as a conference paper at ICLR 2022Color Index(a) w/o, 99.5%Color Index(b) PM(i),99.5%Color Index(c) pD (i), 99.5%Color Index(d) pA (i), 99.5%Figure 14: Pairwise sampling probability under colored MNIST with 0.0001 difficulty. Blue colorindicates higher sampling probability.
Table 12: Random color testresults on CMfocusing on?” In Figure 15, we state the CAM results for watermarked MNIST samples obtainedfrom the Major (Left) and Minor (Right) sets. In the top row (for Major), our model better ignoresthe biased object (fashion object) than the other methods. Even for Minor, only our model determinesthe target digit, while the rest focuses on the biased object (Ankle boots).
Table 13: Unbiased Colored MNIST ac-curacy results.
Table 14: Training timeOther metrics. This study shows other metrics-basedresampling results, (e.g., softmaX response, loss, and logitvalue), based on sampling probability. These results showempirical justification of our gradient-based scores forde-biasing. All scores are defined to make the minoritysamples (unfamiliar samples) have a higher sampling prob-ability. Each score is defined as follows:SsoftmaX (i)1 - Sf(Xi,y/Pj (1-Sf(Xj ,y)))S 小_ m- f(xi,yi)	S C __ L(χi,yi)logit(i) = Pj(m -(f(χj,y)), loss(i) = PjL(Xj,y),where S(∙) is softmax response and m = maxk∈d(f (Xk, yk)). As depicted in Figure H, our gradient-based approach has the highest performance on the average accuracy of majority and minority results.
Table 15: ∖m∖∕∖D∖ =0.7I De-noisingIn recent noisy label cases, therehave been two major trends: (1) con-structing robust objective functionsor regularizers (Cao et al., 2020; Yi& Wu, 2019), and (2) cleaning thenoisy data (Li et al., 2019; Kim et al.,2021b). Those strategies are mostlyused to reduce the influence of rareClean/Major Clean/Minor Noisy/Major Noisy/MinorBefore denoising	50586	568	2820	26FINE	47455	12	0	0Ours	50577	331	1	4Table 16: Comparison between the state-of-the-art noisylabel algorithm and the proposed de-noising module in termsof the number of preserved samples after cleansing.
Table 16: Comparison between the state-of-the-art noisylabel algorithm and the proposed de-noising module in termsof the number of preserved samples after cleansing.
