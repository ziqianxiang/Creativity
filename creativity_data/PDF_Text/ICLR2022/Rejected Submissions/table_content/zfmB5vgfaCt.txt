Table 1: Examples of token-level and characterlevel perturbation under different sizeOriginal	W	Do you know who Rie Miyazawa is?	1	Do I know who Rie Miyazawa is?Token-Level	2	Do I know who Hill Miyazawa is?	3	How I know who Hill Miyazawa is?	1	Do you know who Rie Miya-zawa is?Character-Level	2	Do you know whoo Rie Miya-zawa is?	3	Do you knoiw whoo Rie Miya-zawa is?possible δ after character insertion to get candidate set L. Specifically, we consider all letters anddigits as the possible character c because humans can type these tokens through the keyboard, and weconsider all positions the possible insertion position. Then for token tk, which contains l characters,there are (l + 1) × ||C || perturbation candidates, where ||C || is the size of all possible characters.
Table 2: The victim models in our experimentsModel j Vocab Size ∣ Source Target URLT5	ZH19	En	De	https://huggingface.co/t5-smallFAIR	WMT19	En	De	https://huggingface.co/facebook/wmt19-en-deH-NLP	Tatoeba	En	Zh	https://huggingface.co/Helsinki-NLP/opus-mt-en-deMetrics. We apply floating-point operations (FLOPs) and response latency to measure victim NMTsystems’ efficiency. FLOPs is a hardware-independent metric and is widely used to measure DNNs’computational complexity. Higher FLOPs mean that the DNN requires more computations to handlean input, which represents less efficiency (Howard et al., 2017; Zhang et al., 2018). Response latencyis a hardware-dependent metric, which can measure the victim model’s efficiency on benign andadversarial examples. High response latency indicates that the victim NMT system needs to spend5Under review as a conference paper at ICLR 2022■ Benign ■ Baseline ■ OursFLOPs	Intel V5 CPU Latency 1080 Ti GPU LatencyFigure 2: The distribution of FLOPs and latency before and after token-level attacksmore computational resources. The higher the response latency, the worse the real-time translationquality. We measure the latency on two hardware platforms: Intel Xeon E5-2660v3 CPU and Nvidia1080Ti GPU.
Table 3: The severity of token-level adversarial attacksNMT	Perturbation	I-FLOPs		I-Latency (CPU)		I-Latency (GPU)			Baseline	Ours	Baseline	Ours	Baseline	Ours	1	-418^^	1318.72	-4Ξ1 ^^	1485.64	2.55^^	1269.53	2	6.03	2131.92	6.33	2403.21	3.05	2054.83H-NLP	3	12.94	2336.88	13.83	2636.51	11.10	2296.09	4	17.57	2360.94	19.40	2664.46	15.68	2314.23	5	23.56	2366.09	25.38	2669.82	23.89	2321.93	1	--0.05^^	23.46^^	-015^^	24.85	-350^^	29.62	2	-0.19	36.80	0.61	38.97	1.17	40.59FairSeq	3	-2.22	47.27	-0.73	51.21	-1.40	54.44	4	-5.78	57.60	-4.17	63.35	-4.09	63.57	5	-8.20	80.75	-6.85	89.73	-1.76	85.74	1	10.09~~	335.41	-966^^	383.38	-787^^	352.88	2	6.80	343.69	5.44	393.20	4.06	362.45T5	3	1.47	343.69	1.64	393.20	-1.54	362.45	4	-11.66	343.69	-9.62	393.20	-8.28	362.45	5	-25.18	343.69	-24.29	393.20	-8.59	362.45Severity of Token-level Attack. To quantify the severity of the proposed efficiency attack, wemeasure I-FLOPs and I-Latency under different perturbation sizes. From the results in Table 3,
Table 4: The severity of character-level adversarial attacksNMT	Perturbation	I-FLOPs		I-Latency (CPU)		I-Latency (GPU)			Baseline	Ours	Baseline	Ours	Baseline	Ours	1	20.09	389.36	21.27	431.72	11.84	368.08	2	20.09	879.16	21.29	978.47	12.07	840.47H-NLP	3	20.09	1102.86	21.29	1232.71	12.07	1056.88	4	20.09	1189.48	21.29	1328.29	12.07	1136.70	5	20.09	1224.91	21.29	1366.22	12.07	1174.57	1	0.28	36.23	0.71	38.59	3.15	40.13	2	0.28	87.92	0.71	97.37	3.17	94.31FairSeq	3	0.28	145.60	0.71	164.90	3.17	155.43	4	0.28	190.43	0.71	217.94	3.17	204.02	5	0.28	223.07	0.71	255.42	3.17	235.93	1	5.60	217.46	6.39	249.44	5.71	229.70	2	5.56	249.88	6.37	286.81	5.69	258.35T5	3	5.56	267.58	6.37	307.57	5.69	273.41	4	5.56	276.33	6.37	318.40	5.69	283.37	5	5.56	280.10	6.37	323.67	5.69	286.84Severity of Character-level Attack. Similar to Section 4.2, Table 4 presents the severity ofcharacter-level adversarial examples. The results show consistency with the token-level attack.
Table 5: The maximum I-FLOPS ofblackbox token-level attackSource	Target	1	2	3	4	5H-NLP	FairSeq T5	185.71 1600.00	57.14 1600.00	68.75 1600.00	57.14 1600.00	42.86 1600.00FairSeq	H-NLP T5	6566.67 1600.00	6566.67 1600.00	6566.67 1600.00	6566.67 1600.00	6566.67 1600.00T5	H-NLP FairSeq	3733.33 858.33	3733.33 1816.67	3733.33 1816.67	3733.33 945.45	3733.33 945.45Specifically, we treat one NMT system as a target and apply another NMT system as the source togenerate adverSarial exampleS. We then feed the adverSarial exampleS to the target NMT SyStemSand meaSure the maximum I-FLOPS. Maximum I-FLOPS indicate the efficiency degradation underthe worSt Scenario, which iS important to meaSure the vulnerability of NMT SyStemS. Notice theSource and the target NMT SyStemS in our experiment adoptS different model architectureS and aretrained with different dataSetS. ThuS, if the adverSarial exampleS can increaSe the FLOPS of thetarget NMT SyStem, it proveS that tranSferability exiStS in our attack. The reSultS for token-levelattackS are Shown in Table 5 (more reSultS in Appendix A.3). From the reSultS, we obServe that for8Under review as a conference paper at ICLR 2022all experimental settings, TranSlowDown generates adversarial examples that increase the targetNMT system’s computational FLOPs to a large extend. The results imply that under the worstscenarios, the attackers can generate efficient adversarial examples even without prior knowledgeabout the victim NMT systems.
Table 6: Sentences for energy attack on mobile devicesBenign	Death comes often to the soldiers and marines who are fighting in anbar province, which is roughly the size of louisiana and is the most intractable region in iraq.
Table 7: The maximum I-FLOPS ofMackbox CharaCter-level attackSource	Target	1	2	3	4	5H-NLP	FairSeq	900.00	273.08	2400.00	573.08	2400.00	T5	1700.00	1700.00	1700.00	1700.00	1700.00FairSeq	H-NLP	250.00	325.00	400.00	400.00	433.33	T5	1400.00	1400.00	1400.00	1400.00	1400.00T5	H-NLP	3733.33	3733.33	3733.33	3733.33	3733.33	FairSeq	1177.78	1337.50	1542.86	1337.50	1337.5015σ∖A.4 Case Study ResultsIn this section, we put more generated efficiency adversarial examples for all our victim NMT systems.
Table 8: The benign and adversarial examples under different settingsAttack Type	NMT	Benign	Adversarial 1Token	H-NLP	Let me see.	哎 me see		I am here.	Iam going.
