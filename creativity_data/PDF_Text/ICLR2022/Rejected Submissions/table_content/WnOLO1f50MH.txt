Table 1: Test accuracy (%) on different vision benchmark datasets. Best performance per groupconvolution implementation is underlined in blue. Best overall performance is boldfaced. â†‘ Separablealong rotation and scale dimensions.
Table 2: Test error (%) on rotated MNIST for separable G-CNNs in comparison to other equivariantbaselines: G-CNN (Cohen & Welling, 2016a), H-Net (Worrall et al., 2017), RED-NN (Salas et al.,2019), LieConv (Finzi et al., 2020), SFCNN (Weiler et al., 2018b), E(2)-NN (Weiler & Cesa, 2019).
Table 3: Test error (%) on CIFAR10 with All-CNN-C architecture, for our separable group convolu-tions in comparison to other baselines: All-CNN-C (Springenberg et al., 2014), p4- and p4m-G-CNN(Cohen & Welling, 2016a), f Separable along dilation and rotations dimensions. + Train-time augmentationby random horizontal flips and random cropping. n-Sim(2)-CNNs where n is the SIREN hidden size in units.
Table 4: Number of trainable parameters for different implementations. For all groups and datasets,these numbers are kept constant.
Table 5: Test accuracy (%) of SE(2)-CNNs on rotated MNIST for different activation functions usedin parameterisation of the convolution kernel.
