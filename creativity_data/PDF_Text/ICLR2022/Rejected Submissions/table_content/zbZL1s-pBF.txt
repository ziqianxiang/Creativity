Table 1: Accuracies of different models (%) are evaluated on AV-MNIST when audio features areperturbed. Mean accuracies are reported after repeatedly running 20 times. The value of γ is se-lected from {0.1,0.5, 0.9}. The green (↑) or red Q) arrow represents after applying our Jacobianregularization, the model accuracy increases or decreases compared to others with the same uni-modal backbones. The best accuracy in one column is bolded. ‘UM’ and ‘MM’ represent ‘uni-modal’ and ‘multimodal’, respectively. ‘MM(0, i)’ represents a multimodal network obtained byfusing the unimodal network indexed by ‘0’ and ‘i’.
Table 2: Accuracies of different models (%) are evaluated on RAVDESS when audio features areperturbed. Mean accuracies are reported after repeatedly running 20 times.
Table 3: Accuracies of different models (%) are evaluated on VGGSound when video features areperturbed. Mean accuracies are reported after repeatedly running 5 times.
Table 4: Accuracies of different models (%) are evaluated on AV-MNIST when image features areperturbed. Mean accuracies are reported after repeatedly running 20 times.
Table 5: Accuracies of different models (%) are evaluated on AV-MNIST when both modalities areperturbed by Gaussian noise. Mean accuracies are reported after repeatedly running 20 times.
Table 6: Accuracies of different models (%) are evaluated on RAVDESS when image features areperturbed. Mean accuracies are reported after repeatedly running 20 times.
Table 7: Accuracies of different models (%) are evaluated on VGGSound when video features areperturbed. Mean accuracies are reported after repeatedly running 5 times.
Table 8: Accuracies of different models (%) are evaluated on VGGSound when audio features areperturbed. Mean accuracies are reported after repeatedly running 5 times.
