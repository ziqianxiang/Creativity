Table 1: Proof of concept: Top-1 accuracy(%) on Shortcut-CIFAR100 and CIFAR99. All themodels(ResNet-56) Were trained on ShortCUt-CIFAR100.__________________________Model	ShortCUt-CIFAR100	CIFAR99ResNet-56	62.46	39.95ResNet-56 W/WP	66.80	46.88ResNet-56 W/ SD (Pezeshki et al., 2020)	63.41	7.77ResNet-56 W/ LfF (Nam et al., 2020)	63.11	42.09the network would exhibit a strong propensity to identify a picture that has a small black block onits top left Corner as “apple”, if it sUffers from shortCUt learning. We then designed a neW testingsCenario Where We extraCted all the testing samples from the other 99 Classes(exCept apple) and thenadded a small blaCk bloCk on the same position on eaCh of them (We then term this as CIFAR99).
Table 2: Top-1 error rates(%) over different architectures.
Table 3: Top-1 error rates(%) on different benchmark datasets.
Table 4: Top-1 error rates(%) over different techniques.
Table 5: Top-1 error rates(%) of ResNet-32 on long-tailed CIFAR-10 and CIFAR-100. The imbal-ance ratio denotes the ratio between the numbers of samples of the most and least frequent classes.
Table 6: Corruption errors of tiny-ImageNet-C on different corruptions across five corruption sever-ity levels. All metrics are top-1 error rates (for corrupted test sets, we average for 5-severity levelsin four runs on ReSNet-110. SeParate results in each run are Provided in APPendix.F.).
Table 7: Top-1 accuracy(%) on revised ShortcUt-CIFAR100 and revised CIFAR99.
Table 8: Results on other architectures to suggest that the modifications of White Paper Assistancemainly happens on the convolutional layers.
Table 9: Comprehensive corruption error results of baseline and White Paper Assistance on singlemodel. “Clean" here denote the top-1 error rate of the model on the clean version of tiny-ImageNet.
