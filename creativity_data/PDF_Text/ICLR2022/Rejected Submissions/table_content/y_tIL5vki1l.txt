Table 1: Image quality with respect to supervision type on CelebA-HQ. Our FID scores improveon mask-based solutions while providing similar editing capabilities and being unsupervised.
Table 2: Quantitative ablation test on keypoint localiza-tion (L1) and image quality (FID). A lower number is better.
Table 3: Landmark detection on CelebA (lower is better). The metric is the landmark regression(without bias) error in terms of mean L2 distance normalized by inter-ocular distance. The bottomfour rows shows our improvement step by step. We use the same number of keypoints as previousmethods.
Table 4: Survey results. We compare 4 different aspects with other methods. The first one is theediting image quality. The second one is part disentanglement. The third one is identity preservationwhile changing expression. The last one is shape preservation while changing appearance.
Table 5: Setting for different datasets. For the Bedroom dataset, we do not use the backgroundmodule and loss. For the BBC Pose dataset, we use τ = 0.025.
Table 6: Quantitative ablation test on dimension of embeddings. For both metrics, the lowermeans better.
Table 7: FID scores of ablation tests on number of keypoints K and keypoint size τ on CelebAof resolution 128 × 128. The lower means better. Neither K or τ significantly influence the imagequality. Interestingly, the small artifacts when τ = 0.002 in Figure 15 does not neither significantlyinfluence the image quality.
Table 8: Normalized Error of ablation tests on number of keypoints K and keypoint size τon CelebA of resolution 128 × 128. For τ = 0.002, 0.005, the error decreases as K increaseswhile for τ = 0.01, 0.02, the error first decreases and then increases. If both of them are large, e.g.,K > 16, τ > 0.01, the appearance is entangled with the keypoints which results in a larger error.
Table 9: Keypoint controllability. T denotes trivial keypoint, i.e., the background controls the en-tire image. E means entangled pose, appearance and background. XXmeans disentangled controland Xmeans inferior disentanglement, where one of the pairs {(pose, appearance), (pose, back-ground), (appearance, background) is entangled.}. For a small keypoint size of τ = 0.0002 themodel always gives trivial keypoints. With a large number of keypoints and a large keypoint size,i.e., K > 16 and τ > 0.01, our model gives entangled representations. Our model is robust in therange of K ∈ [8, 16] and τ ∈ [0.005, 0.01].
