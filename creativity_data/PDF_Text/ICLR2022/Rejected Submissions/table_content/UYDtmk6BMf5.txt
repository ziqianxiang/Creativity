Table 1: Conventional OOD detection benchmark. We evaluate the detection performance byAUC (in- vs. out-distribution detection based on confidence/score) in percent (higher is better).
Table 2: Robustness on the texture discrepancy produced by the mild corruptions. We useCIFAR-10 as the in-distribution dataset, and corrupt this using mild distortions. In this benchmark,an OOD detection method should not determine the corrupted images as OOD (i.e., 50.0% AUC isthe best score). This scenario is motivated by the real-world applications that context informationis the key factor in OOD but the mild corruptions are acceptable.
Table 3: Robustness on the texture discrepancy.					Table 4: Robustness on the semantic dis-	We use 32×32 CIFAR-10 as the ID and vary the					crepancy. In the K-MNIST scenario, 50.0	resolution to make test datasets. Note that 50.0 is					is the best since no textural difference ex-	the best score since the test datasets are from the					ists between the ID and OOD, in contrast to	in-distribution but with different image resolutions.					the F-MNIST (higher is better).	In the resolution change scenario (Table 3), our method with λ = 1.0 (semantics mode) outper-forms the others in all the settings. All the methods except ours with semantics mode are extremelysensitive to the image resolution change, although no other information is modified.
