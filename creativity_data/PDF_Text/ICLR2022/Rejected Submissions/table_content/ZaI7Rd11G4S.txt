Table 1: The proposed method outperforms the baseline method (more results in Table 6). We useNC to denote the non-compressed or embedding learning method without compression, Rand todenote the random coding method (i.e., ALONE), and Hash to denote the proposed hashing codingmethod. The numbers presented in the table are classification accuracy.
Table 2: The number of nodes in the training/validation/test set of each dataset.
Table 3: Compression ratios for different numbers of compressed entities. The compression ratiosof metapath2vec++ are omitted as the compression ratios are the same as metapath2vec.
Table 4: Experiment results on pre-trained embeddings with different settings of c and m. We userandom to denote the random coding method (i.e., ALONE), and hashing to denote the proposedhashing coding method.
Table 5: Compression ratios for different numbers of compressed entities with different settings ofc and m. The compression ratios of metapath2vec++ are omitted as the compression ratios arethe same as metapath2vec.
Table 6: The proposed hashing-based coding outperforms the baseline random coding under differ-ent settings of c and m. The non-compressed is the embedding learning method without compres-sion. We use random to denote the random coding method (i.e., ALONE), and hashing to denote theproposed hashing coding method.
Table 7: The memory cost (MB) for models on ogbn-arxiv dataset.
Table 8: The memory cost (MB) for models on ogbn-mag dataset.
Table 9: The memory cost (MB) for models on ogbn-products dataset.
Table 10: The proposed hashing-based coding outperforms the baseline random coding withGraphSage using non-standard attention aggregator. The non-compressed is the embedding learn-ing method without compression. We use random to denote the random coding method (i.e.,ALONE), and hashing to denote the proposed hashing coding method.
Table 11: The proposed hashing-based coding almost always outperforms the baseline random cod-ing with different GNNs for both node classification and link prediction. The non-compressed is theembedding learning method without compression. We use random to denote the random codingmethod (i.e., ALONE), and hashing to denote the proposed hashing coding method.
