Table 1: Maximum item score of methods on the MineCraft task. “Auto”: Sub-goals/sub-tasksare found automatically. Demonstrations are used for hierarchical reinforcement learning (“HRL”).
Table A.1: p-values for Artificial Task (I), FourRooms, obtained by performing a Mann-Whitney-Utest.
Table A.2: p-values for Artificial Task (II), EightRooms, obtained by performing a Mann-Whitney-Utest.
Table A.3: Results for different numbers of clusters for the FourRooms artificial task are shown inthe table. It shows the number episodes required to reach 80% optimal return, using a demonstrationsgiven in column headers. These results are averaged over 10 seeds. For the results we report in thepaper we set the maximum number of clusters to 15, the results show that even when reducing thenumber of clusters to 8, results stay similar. We only see worse performance for when only allowing2 or 5 clusters.
