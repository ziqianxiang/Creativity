Table 1: Instantiation of the unboundedProposition 2 becomes the foundation of the un-bounded parametrization, and the introductionof η is the key to enable the estimation of theunbounded data score. Therefore, we intro-duce the new parametrization for the high pre-cision score network as sθ(xt, η(t)), rather thansθ (xt, t) (DDPM) or sθ(xt, σ(t)) (NCSN).
Table 2: Example pairs of (P, λP).
Table 3: Performance comparisons on benchmark datasets. The boldfaced numbers present the best performance, and the underlined numbers present the second-best performance.								Model	NLL Q)	CIFAR10 32 × 32 FID Q)	IS (↑)	CelebA 64 × 64		CelebA-HQ 256 × 256 (8-bits) FID	STL-10 48 × 48					NLL	FID		FID	ISHNCSN++ (RVE) + ST	3.04	2.33	10.11	1.93	1.92	7.16	7.71	13.43Likelihood-based Models CR-NVAE (Sinha and Dieng, 2021)	2.51	-	-	1.86	-	-	-	-LSGM (FID) (Vahdat et al., 2021)	3.43	2.10	-	-	-	-	-	-DenSeFlow-74-10 (Grcic et al., 2021)	2.98	-	-	1.99	-	-	-	-Gamma Distribution DDIM (Nachmani et al., 2021)	-	-	-	-	2.92	-	-	-VDM (Kingma et al., 2021)	2.65	-	-	-	-	-	-	-NCSN++ cont. (deep, VE) (Song et al., 2020)	3.45	2.20	9.89	2.39	3.95	7.23	-	-DDPM++ cont. (deep, sub-VP) (Song et al., 2020)	2.99	2.41	9.57	-	-	-	-	-ScoreFlow (cont. norm. flow) (Song et al., 2021)	2.74	5.70	-	-	-	-	-	-Improved DDPM (Lsimple) (Nichol and Dhariwal, 2021)	3.37	2.90	-	-	-	-	-	-Likelihood-free Models StyleGAN2-ADA+Tuning (Karras et al., 2020)	-	2.92	10.02	-	-	-	-	-Styleformer (Park and Kim, 2021)	-	2.82	9.94	-	3.66	-	15.17	11.01PGGAN (Karras et al., 2017)	-	-	8.8	-	-	8.03	-	-TransGAN (Jiang et al., 2021)	-	9.26	9.02	-	5.01	-	18.28	10.43(Song et al., 2020; Ho et al., 2020) computes the score with 50k generated images once, whileIS-5k in GAN models (Karras et al., 2020; Park and Kim, 2021) computes the score 10 trials withindependently generated 5k samples and report the performance as the average of scores. We report
Table 4: Ablation study for thenew parametrization.
Table 5: Ablation study for ST-trick trained onHNCSN++ (RVE).
Table 6: Ablation study for ST-trick.
Table 7: Ablation studyfor σmin trained onHNCSN++ (RVE).
Table 8: Ablation study fordenoising effect on high-dimensional datasets.
Table 9: LSUN BedroomModel	Bedroom 256 × 256 FIDUDM (RVE) + ST	-	4.57Likelihood-based Models	ADM Dhariwal and Nichol (2021)	1.90DDPM Ho et al. (2020)	4.90Likelihood-free Models	StyleGAN Karras et al. (2019)	2.65INR-GAN-bil Skorokhodov et al. (2020)	4.95COCO-GAN Lin et al. (2019)	6.95Table 10: FFHQ	FFHQModel	256 × 256	FIDUDM (RVE) + ST	5.54Likelihood-free Models	InsGen Yang et al. (2021)	3.31Anycost GAN Lin et al. (2021)	3.35StyleGAN2 ADA+bCR Karras et al. (2020)	3.62CIPS Anokhin et al. (2020)	4.38
Table 10: FFHQ	FFHQModel	256 × 256	FIDUDM (RVE) + ST	5.54Likelihood-free Models	InsGen Yang et al. (2021)	3.31Anycost GAN Lin et al. (2021)	3.35StyleGAN2 ADA+bCR Karras et al. (2020)	3.62CIPS Anokhin et al. (2020)	4.38U-Net GAN Schonfeld et al. (2020)	7.48BigGAN Schonfeld et al. (2020)	11.4815Under review as a conference paper at ICLR 2022Figure 16: Random samples on CIFAR10.
