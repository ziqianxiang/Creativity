Table 1: Comparison with other methods in the Single Image setting on Places (Zhou et al., 2017a)and DAVIS-YFCC100M (Perazzi et al., 2016; Thomee et al., 2016) datasets.
Table 2: Comparison in the Single Video setting on DAVIS-YFCC100M.
Table 3: Ablation study in the Single Image and Video settings on DAVIS-YFCC100M. Indicatorsof collapsed diversity (low LPIPS, Pixel Diversity) or poor quality (high SIFID) are marked in red.
Table 4: Comparison of diversity regulariza-tion techniques in the Single Image settingon DAVIS-YFCC100M.
Table A: Ablation on the number of blocks NDlow-level used before content-layout branching in thediscriminator on the DAVIS-YFCC100M dataset.
Table B: Ablation on the number of channels used for the layout branch feature representation onthe DAVIS-YFCC100M dataset.
Table C: Ablation on the low-level loss LDlow-level on DAVIS-YFCC100M dataset.
Table D: Effect of the diversity regularization (DR) strength in the Single Image setting on DAVIS-YFCC100M.
Table E: Effect of DR applied to different GAN models in the Single Image setting on DAVIS-YFCC100M.
Table F: Results on the few-shot image synthesis task. The FID is computed between 5000 gener-ated images and the whole training set. Bold and Underlined indicate first and second best scores.
Table G: Results in the extremely low few-shot data setting, where the models are trained only onsubsets of standard few-shot datasets. Our model outperforms the baseline in all data regimes bothin quality and diversity, and does not suffer from training instabilities even in extreme cases, such asusing only 25% of the training set. Collapsed runs with a high FID for Fast-GAN are shown in red.
Table H: Results on few-shot datasets with a non-object-centric structure. Our model outperformsFastGAN both in quality and diversity on both datasets.
Table I: Comparison of synthesis quality anddiversity at different image resolutions onDAVIS-YFCC100M in the Single Image set-ting.
Table J:	Comparison of SIFID at different scales on DAVIS-YFCC100M in the Single Image andSingle Video settings.
Table K:	Comparison of the diversity among the images generated in the Single Image and the SingleVideo settings on the DAVIS-YFCC100M dataset.
Table L: Effect of different strategies to match the rectangular shape of the original training imageon the DAVIS-YFCC100M dataset.
Table M: The SIV-GAN generator. In this example, the configuration is presented for the input noiseof size (3 × 5) and the final resolution of (192 × 320), corresponding to training on the DAVIS-YFCC100M dataset in the Single Video setting.
Table N: The SIV-GAN discriminator. In this example, the configuration is presented for the inputnoise of size (3 × 5) and the final resolution of (192 × 320), corresponding to training on theDAVIS-YFCC100M dataset in the Single Video setting.
