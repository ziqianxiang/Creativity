Table 1: Environment-dependent parameters in baselines on 2D-pusher. Each baseline generates anenvironment of obstacles by uniformly sampling the four parameters defining each obstacle from thecorresponding ranges. It starts from the initial ranges below and can take a mutation step one time tochange the lower and upper bounds of each parameter’s range, if the two bounds do not exceed theirminimal and maximal values listed below. The two numbers in each tuple (∙, ∙) below corresponds tothe lower and upper bound of the range.
Table 2: SAC hyperparameters in EAT-C (2D-pusher)Parameter	ValueOptimizer	AdamLearning rate	3.0 × 10-4Discount factor (γ)	0.99Replay buffer size	1.0 × 106Number of hidden layers for all networks	2Number of hidden units for all networks	400Minibatch size	256Nonlinearity	ReLUTarget smoothing coefficient (τ)	5.0 × 10-3Target update interval	1Network update per environment step	1Entropy target	- dim(A)Table 3: SAC hyperparameters in EAT-C (discrete space tasks)ParameterValueOptimizer	AdamLearning rate	5.0 × 10-4Discount factor (γ)	0.99
Table 3: SAC hyperparameters in EAT-C (discrete space tasks)ParameterValueOptimizer	AdamLearning rate	5.0 × 10-4Discount factor (γ)	0.99Replay buffer size	1.0 × 106Number of hidden layers for all networks	3Number of hidden units for all networks	256Minibatch size	256Nonlinearity	ReLUTarget smoothing coefficient (τ)	5.0 × 10-3Target update interval	1Network update per environment step	1Entropy target	- dim(A)Algorithm 2 Top-Down Planning of Sub-task Curriculum1:	Input: (s0 , g), T, planning policy πp and its training set Dp.
Table 4: Ablation Study ResultsTest Setting	Multiple New Random Environments	Training EnvironmentEAT-C	80.24 ± 12.25	92.04±6.49EAT-C (remove EG)	42.23±10.34	85.47±9.12EAT-C (remove Planner)	27.58 ± 14.67	46.02±10.3SAC	20.83 ± 7.24	39.62 ± 12.25Hierarchical RL	22.04 ± 10.44	68.27 ± 6.99Reviewer o38w and Zhvq raised the following concerns: (1) whether EG could make the environmentmore reward sparse? (2) whether planner could always generate infeasible sub-goals? To answerthese questions, in Fig 7, we report the average time-cost that the agent needs to complete eachsub-task in layer-3 of the sub-task tree.
Table 5: Main results for the experiments on 7DoF robotic arm.
