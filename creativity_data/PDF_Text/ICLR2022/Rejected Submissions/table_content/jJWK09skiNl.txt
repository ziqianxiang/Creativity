Table 1: Number of images and labels for each object in each setNumber	Object name	Train labels 36232 images	Validation labels 9040 images	Test labels 88664 images0	master chef can	8919	2252	180881	cracker box	10073	2552	197712	sugar box	12393	3055	169653	tomato soup can	13342	3213	232064	mustard bottle	0	0	323215	tuna fish can	7534	1868	212346	pudding box	5214	1384	263347	gelatin box	0	0	337868	potted meat can	10247	2549	193549	banana	10060	2493	2027510	pitcher base	0	0	2647811	bleach cleanser	11918	2933	1575512	bowl	7808	1945	489813	mug	11051	2797	1285814	power drill	0	0	2788315	wood block	6649	1669	1278216	scissors	12463	3210	1171017	large marker	9211	2277	19305
Table 2: Recall for each objectNumber 0	1	2	3Recall	0.88	0.72 0.83 0.854567890.73	0.75	0.61	0.46 0.86	0.7310	11	12	13	140.05 0.51 0.63	0.90 0.0715	16	17	18	19	200.21	0.44	0.26	0.42	0.21	0.724.3 DiscussionBase on the testing result, we can say that the algorithm works well when there are similar seenobjects, but not for onjects that very different from seen objects. From Table 2, the first thing wenotice is that the recall rates for different objects have a large variation. Some seen objects even havea lower recall rate than unseen objects. The main reason causing this is the unbalanced number oflabels in the train dataset and the test dataset. For example, the number of train labels for sugar boxis 0.75 times of the number of test labels, and its recall reached 0.83. For wood block, its number oftrain labels is only half the number of test labels, and its recall rate is only 0.21. Another reason thataffects the recall rate is the variation of illumination. Since YCB Video dataset is consists of videos,images in the train dataset can only cover a very limited range of illumination conditions. Thus, thealgorithm will perform worse on the test images with illumination conditions that have never been
