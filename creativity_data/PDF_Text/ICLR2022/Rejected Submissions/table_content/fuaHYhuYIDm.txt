Table 1: Performance of magnex and lime when explaining a random forest model trained fordigit recognition. magnex outperforms lime in both sufficiency and inference time.
Table 2: Performance of magnex, lime, and ig when explaining a cnn trained for digit recogni-tion. All methods generate sufficient explanations, but magnex is more efficient during inference.
Table 3: Performance of magnex, lime, and ig, explaining bert fine-tuned for sentiment classi-fication. magnex outperforms the baselines in both suffuciency and inference time.
Table 4: Performance of magnex, lime, and ig, explaining a large variant of bert in questionanswering. magnex outperforms the baselines in both suffuciency and inference time.
