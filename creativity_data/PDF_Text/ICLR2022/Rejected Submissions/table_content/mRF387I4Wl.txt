Table 1: Results of ablation studies of our method on GCNs. FloWXt denotes our FloWX withoutShapley initial assessments and FlowX* denotes our FlowX without learning refinement.
Table 2: Statistics and properties of seven datasets. Note that “NC”denotes node classification, and“GC” denotes graph classification. # nodes (largest) denotes the number of nodes of the largest graphin the dataset for the split of explanations.
Table 3: The averaged time cost of eight algorithms.
Table 4: ComParisons betWeen FloWX and other methods in terms of average Fidelity over differentSparsity levels on GCNs. Bold and Underline scores respectively denote the best and the second bestresults. In addition, because SubgraPhX cannot control and reach all the SParsity levels as We need,we cannot compare it with others in this table.
Table 5: Comparisons between FlowX and other methods in terms of average Fidelity over differentSparsity levels on GINs. Bold and Underline scores respectively denote the best and the second bestresults. In addition, because SubgraphX cannot control and reach all the Sparsity levels as we need,We cannot compare it with others in this table.
Table 6: Comparisons between FlowX and three methods in terms of average AccUracy with 0.9Sparsity on GCNs.
