Table 2: MultiMNIST multi-task results. For each task, we highlight the best performing methodin bold. We also report the coefficient of dominance for each MTL approach.
Table 1: Computational cost per step forT tasks and K steps.
Table 3: Scene understanding and multi-label classification performance. The best score is in boldand the second best score is in italic. For CELEBA, we report the mean±std over 10 random seeds.
Table 4: Camera relocalization performance of the proposed method and existing MTL approachesfor the 7SCENES data set. We report median translation t, orientation r errors and the growth rate, Rfor each scene. For each scene, we highlight the best performing method in terms of translation andorientation error in italic and bold, respectively.
Table 5: CelebA performance. Following Sener & Koltun (2018), we report accuracy on thevalidation split. The best score is in bold and the second best score is Underlined.
Table 6: Camera relocalization performance of the proposed method and existing MTL approachesfor the 7scenes data set. We report translation and orientation accuracy in terms of meters anddegrees, respectively. The reported results are mean±std over 10 random seeds.
Table 7: The network architectures used in our experiments for (1) Multi-label classification(CelebA), (2) camera relocalization (7scenes), (3) Scene understanding (CityScapes), and(4) Mulati-task classification (MultiMNIST). Notation: PPM stands for Pyramid Pooling Mod-ule (Zhao et al., 2017); DE is depth estimation; IS and SS are instance and semantic segmentationrespectively.
