Table 1: Monte Carlo estimates of E[h(X)] with four samplers for 2D mixtures of Gaussians randomvectors X with unequal weights. “Target" denotes the Monte Carlo estimate with target samples.
Table 2: Averages and standard errors (in parenhteses) of classification accuracy on test data fromfive datasets, d: number of features, N : sample size.
Table 3: Step size settings for REGS, SVGD, ULA and MALA. "BGIR" denotes four datasetsincluding Banana, German, Image and Ringnorm.
Table 4: Neural network architecture for log-density ratio estimation: feedforward neural networkswith equal-width hidden layers and Leaky ReLU activation. Depth ` = 3 for 2Gaussians_1d1,2Gaussians_1d2, 2Gaussians_1d3, and 2Gaussians. ` = 4 for 8Gaussians, 9Gaussians, 1circle,2circles, 1spiral, 2spirals, and moons. ` = 6 for 16Gaussians_1c, 16Gaussians_2c, 25Gaussians,49Gaussians, and 81Gaussians.
Table 5: Monte Carlo estimates of E[h(X)]. Here h(x) = αTx, (αTx)2, and 10 cos(αTx + 1/2) withɑ ∈ R2, ∣∣αk2 = 1. "true" denotes the Monte Carlo estimate with target samples.
Table 6: Monte Carlo estimates of E[h(X)] by four samplers for 2D mixtures of Gaussians of Xwith equal weights. Here h(x) = αTx, (αTx)2 or 10 cos(αTx + 1/2) with α ∈ R2, ∣α∣2 = 1. "true"denotes the Monte Carlo estimate with target samples. "ULA_k" and "MALA_k" denote the ULAand MALA With k chains, respectively.____________________________________________________________________Distributions	σ2	h(x) = αTx							h(x) = (aT x)2							h(x) = 10 cos(αTx + 1/2)								true	REGS	SVGD	ULA_1	MALA 1	ULA_50	MALA_50	true	REGS	SVGD	ULA_1	MALA_1	ULA_50	MALA_50	true	REGS	SVGD	ULA_1	MALA_1	ULA_50	MALA_502gaussian	0.2	0.02	0.00	-0.01	-1.45	0.66	0.11	-0.34	2.56	2.50	2.50	2.62	2.27	8.24	8.25	0.97	1.06	1.09	4.54	-0.43	-7.64	-7.30	0.1	-0.00	-0.03	0.04	1.37	-1.38	0.11	-0.23	2.20	2.20	2.20	2.06	2.12	8.10	8.15	1.23	1.33	1.12	-2.62	5.71	-7.99	-7.71	0.05	0.00	0.02	0.06	1.42	-1.44	0.11	-0.23	2.10	2.10	2.12	2.10	2.19	8.04	8.10	1.30	1.23	1.05	-3.22	5.57	-8.20	-7.83	0.03	-0.01	0.02	0.10	-1.41	1.42	0.11	-0.23	2.02	2.05	2.01	2.04	2.10	8.03	8.18	1.42	1.28	1.12	5.98	-3.36	-8.29	-7.538gaussian	0.2	0.00	-0.01	0.00	-3.46	3.00	0.14	0.35	8.20	8.20	7.98	12.81	10.20	7.87	8.05	-3.05	-3.09	1.41	-7.20	-5.41	-2.95	-2.71	0.1	-0.01	-0.02	0.02	2.83	2.84	-0.66	-0.02	8.11	8.12	8.12	8.11	8.23	8.09	8.52	-3.23	-3.26	1.51	-9.35	-9.11	-3.54	-3.71	0.05	-0.01	-0.00	0.02	2.83	-2.83	-0.41	0.04	8.06	8.06	8.31	8.05	8.08	8.21	9.02	-3.33	-3.34	1.36	-9.58	-6.51	-2.83	-4.37	0.03	0.00	-0.00	-0.01	-0.00	1.96	-0.41	0.18	8.04	8.05	8.05	0.02	6.19	8.19	8.40	-3.35	-3.35	1.57	8.68	-2.38	-2.86	-3.8625gaussian	0.2	-0.00	0.00	-0.44	0.22	-0.45	0.02	0.02	8.18	8.20	9.46	8.02	7.96	8.31	8.10	0.10	0.11	0.75	0.53	0.15	0.05	0.13	0.1	0.00	0.00	0.04	0.15	0.59	-0.05	-0.05	8.11	8.09	2.11	7.42	8.09	8.19	7.97	0.10	0.11	3.44	0.99	-0.15	0.12	0.12	0.05	-0.00	-0.01	-0.00	0.36	-1.50	-0.33	-0.15	8.06	7.62	1.07	4.40	6.17	5.48	8.04	0.12	0.10	5.37	0.95	0.71	0.30	0.34	0.03	-0.00	-0.02	-0.01	0.14	-0.08	0.14	-0.04	8.04	7.58	0.98	8.11	6.97	2.95	7.41	0.11	0.09	5.56	-2.40	-0.91	1.62	0.0815Under review as a conference paper at ICLR 2022
