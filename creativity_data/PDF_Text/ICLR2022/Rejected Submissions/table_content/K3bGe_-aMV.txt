Table 1: ReConStruCtion ErrorInitializationMethod	Random	GoodDirect Search	86.0±9.4	7.9±1.2VAE [34]	110.4±10.6	13.4±6.1GVAE [37]	123.7±9.5	19.7±10.2T-VAE	135.1±16.9	14.1±2.5T-VAE w/ SCG	14.5±1.3	11.8±2.1Experiment Settings. We SyntheSize the dataSetby randomly generating 10,000 SampleS with avarying number of boxeS and plateS. We alSoinjeCt the target SCene 10 timeS into the dataSetto make Sure it aCCeSSible to all modelS. UnlikeGVAE and T-VAE, DS and VAE need to aCCeSSthe number of boxeS and plateS in the target im-age (e.g., two plateS and eight boxeS) to fix thedimenSion of the input feature. To get the goodinitial pointS for DS, we add a Small perturbationto the positions and colors of all objects in thetarget SCene. Similarly, for other methodS, we add the perturbation to the optimal latent Code, whiCh
Table 2: Transferability of Adversarial Scenes (Point Attack IoU / Scene Attack IoU). Scene Attackhas lower IoU for all evaluation pairs, which demonstrates its better adversarial transferability.
Table 3: Hyper-parameters of the Synthetic Scene Reconstruction ExperimentParameters ∣ Value ∣ Descriptionlr	0.001	Learning rate of T-VAE trainingE	1000	Maximum training epochB	128	Batch size during trainingη	0.1	Learning rate in stage 2.
Table 4: Hyper-parameters of the LiDAR Scene Generation ExperimentParameters ∣	Value I	Descriptionlr	0.001	Learning rate of T-VAE traininge	0.01	Max value for point-wise disturbanceE	1000	Maximum training epochB	128	Batch size during trainingT	100	Maximum searching iterationdz	32	dimension of latent code zdf	64	dimension of feature vector fdg	3	dimension of property vector gNl	40	Normalization factor of location(W,h)	(1.5, 3)	The thresholds used in knowledge ③19Under review as a conference paper at ICLR 2022C Knowledge DefinitionFor each experiment in this paper, we design three knowledge rules. We explain the details of theimplementation of these rules.
