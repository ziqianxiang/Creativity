Table 1: Statistics of Biological Temporal Graph DataGraph I #Classes I #Graphs I Total Nodes I Total Edges I Timestamps I Graph I #Classes I #Graphs I Total Nodes I Total Edges I Timestamps IUetz	1	~11	922	-2,159	36	Ito	1	~11	2,856	8,638	36Ho	1	~11	1,548	-42,220-	36	Gavin	1	~11	2,541	-140,040-	36KrOgan-LCMS	1	~11	22∏	-85,133-	36	Krogan-MALDI	1	~11	2,099	-78,297-	36Yu 一	1	~11	1,163	-3,602	36	Breitkreutz	1	~11	869	-39,250-	36Babu	1	~11	5003	-111,466-	36	Lambert	1	~11	697	6,654	36Tarassov	1	11	1,053	-	4,826	36	Hazbun	1	11	143	-	1,959	36Table 2: Statistics of Social Temporal Graph DataI Graph (Online) I #Classes I #Graphs I Total Nodes I Total Edges I Timestamps I Graph (Offline) I #Classes I #Graphs I Total Nodes I Total Edges I Timestamps IFacebook	2	-995-	-95,224-	-267,673-	104	Infectious	2	-200-	-10,000-	-91,944-	48Tumblr	2	-373-	-19,8T1	-74,520-	89	-HighSchool	2	-180-	9,418	-98,066-	203DBLP	2	755	39,917 -	241,674	46	-	MIT	2	97	1,940	-	142,508	5,576Baselines. The selection of baseline algorithms includes three factors, i.e., graph kernel or graphmetric learning, few-shot learning or not few-shot learning, and static or dynamic. Graph kernelmethods include: Vertex histogram kernel (Nikolentzos et al., 2019), Shortest Path kernel (Borgwardt& Kriegel, 2005), Neighborhood Hash graph kernel (Hido & Kashima, 2009), Weisfeiler-LehmanOptimal Assignment kernel (Kriege et al., 2016), and Pyramid Match kernel (Nikolentzos et al.,2017). Graph metric learning or graph representation learning algorithms include: GL2Vec (Chen &Koga, 2019), NetLSD (Tsitsulin et al., 2018), tdGraphEmbed (Beladev et al., 2020), TGAT (Xu et al.,
Table 2: Statistics of Social Temporal Graph DataI Graph (Online) I #Classes I #Graphs I Total Nodes I Total Edges I Timestamps I Graph (Offline) I #Classes I #Graphs I Total Nodes I Total Edges I Timestamps IFacebook	2	-995-	-95,224-	-267,673-	104	Infectious	2	-200-	-10,000-	-91,944-	48Tumblr	2	-373-	-19,8T1	-74,520-	89	-HighSchool	2	-180-	9,418	-98,066-	203DBLP	2	755	39,917 -	241,674	46	-	MIT	2	97	1,940	-	142,508	5,576Baselines. The selection of baseline algorithms includes three factors, i.e., graph kernel or graphmetric learning, few-shot learning or not few-shot learning, and static or dynamic. Graph kernelmethods include: Vertex histogram kernel (Nikolentzos et al., 2019), Shortest Path kernel (Borgwardt& Kriegel, 2005), Neighborhood Hash graph kernel (Hido & Kashima, 2009), Weisfeiler-LehmanOptimal Assignment kernel (Kriege et al., 2016), and Pyramid Match kernel (Nikolentzos et al.,2017). Graph metric learning or graph representation learning algorithms include: GL2Vec (Chen &Koga, 2019), NetLSD (Tsitsulin et al., 2018), tdGraphEmbed (Beladev et al., 2020), TGAT (Xu et al.,2020), and CAW (Wang et al., 2021). GL2Vec and NetLSD are static algorithms, tdGraphEmbed is adynamic algorithm that could take a temporal graph as input and output graph embeddings of eachsnapshot, and TGAT and CAW are dynamic graph representation learning algorithms but focus onthe node-level. To enable graph metric learning methods the few-shot learning capability, we alsoinclude ProtoNet (Snell et al., 2017) and its special case k-NN method.
Table 3: Temporal Graph Classification Accuracy on Biological Temporal GraphsMethods		3 way - 5 shot	3 way - 3 shot	3 way - 2 shot	3 way - 1 shotGraph Kernel	Weisfeiler-Lehman Opt	0.5025 ± 0.353Γ^	0.4625 ± 0.3118-	0.4350 ± 0.2420^^	0.4250 ± 0.225T	Vertex Histogram	0.3150 ± 0.2466	0.2700 ± 0.1881	0.1375 ± 0.1314	0.3125 ± 0.2415	Neighborhood Hash	0.4375 ± 0.4058	0.4400 ± 0.3697	0.2850 ± 0.1815	0.4000 ± 0.3175	Pyramid Match	0.2500 ± 0.1971	0.2525 ± 0.1337	0.2325 ± 0.1569	0.2950 ± 0.2174	Shortest Path	0.2025 ± 0.1477	0.2175 ± 0.1314	0.1875 ± 0.1325	0.1900 ± 0.1329Graph Metric Learning	GL2Vec + KNN	0.1400 ± 0.0616	0.1925 ± 0.0754	0.1175 ± 0.0689	0.1150 ± 0.0591	NetLSD + KNN	0.3600 ± 0.2585	0.3650 ± 0.2747	0.2000 ± 0.0901	0.2625 ± 0.1519	TGAT + KNN	0.2100 ± 0.0817	0.1325 ± 0.2217	0.1650 ± 0.0387	0.0750 ± 0.0208	tdGraphEmbed + KNN	0.3200 ± 0.1272	0.2275 ± 0.1459	0.1750 ± 0.0580	0.1875 ± 0.0150	GL2Vec + ProtoNet	0.6083 ± 0.0099	0.6541 ± 0.0159	0.6542 ± 0.1370	0.5583 ± 0.1578	NetLSD + ProtoNet	0.6916 ± 0.1396	0.7145 ± 0.1396	0.6937 ± 0.1674	0.6667 ± 0.1372	TGAT + ProtoNet	0.2417 ± 0.0500	0.3083 ± 0.0739	0.2917 ± 0.1167	0.2417 ± 0.0319	CAW + ProtoNet	0.1496 ± 0.0104	0.2113 ± 0.0110	0.2404 ± 0.0117	0.2842 ± 0.0044	tdGraphEmbed + ProtoNet	0.6562 ± 0.1882	0.6791 ± 0.1141	0.6271 ± 0.1159	0.4229 ± 0.0463	MetaTag (Ours)	0.7292 ± 0.0682-	0.7917 ± 0.1278~	0.7062 ± 0.0762-	0.6833 ± 0.0589-5.2	Temporal Graph ClassificationFirst, in the biological dataset, given the 12 classes we split 8 classes into the meta-training setGtrain and 4 classes into the meta-testing test Gtest . Note that Gtrain and Gtest do not share any
