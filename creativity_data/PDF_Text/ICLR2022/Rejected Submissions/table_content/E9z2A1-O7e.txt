Table 1: Comparison of HT with MAML++ on models of different sizes and different datasets:(a) 20-way Omniglotand (b) 5-way miniImageNet. Results for MAML++ were obtained us-ing GitHUb code accompanying Antoniou et al. (2019), those marked with f are from Antoniouet al. (2019). HT outperforms MAML++ on many few-shot tasks. Accuracy confidence intervals:OMNIGLOT - between 0.1% and 0.3%, MINIIMAGENET - between 0.2% and 0.5%.
Table 2: Comparison of miniImageNet and tieredImageNet 1-shot (1-S) and 5-shot (5-S)5-way results for HT (underlined) and other widely known methods with a 64-64-64-64 modelincluding (Tian et al., 2020): Matching Networks (Vinyals et al., 2016), IMP (Allen et al., 2019),Prototypical Networks (Snell et al., 2017), TAML (Jamal & Qi, 2019), SAML (Hao et al., 2019),GCR (Li et al., 2019a), KTN (Peng et al., 2019), PARN (Wu et al., 2019), Predicting Parametersfrom Activations (Qiao et al., 2018), Relation Net (Sung et al., 2018), MELR (Fei et al., 2021). Wealso include results for CNNs with fewer channels (“-32” for 32-channel models, etc.).
Table 3: Test accuracy on tieredImageNet of supervised 1-shot and 5-shot models and semi-supervised 1-shot models with u additional unlabeled samples per class. The weight generationtransformer model uses LT encoder layers. Notice a performance improvement of semi-supervisedlearning over the 1-shot supervised results. Accuracy is seen to grow with the number of unlabeledsamples and the maximum accuracy is reached when the encoder has at least two layers.
