Table 1: The components of related approaches. Like POET, we evolve levels, but use a single agent ratherthan a population, while also using a minimax regret objective, which ensures the environments generated aresolvable. PAIRED uses minimax regret for the generator, which is often challenging to optimize, while it doesnot replay levels so may suffer from cycling. Finally, PLR curates levels using minimax regret, but relies solelyon domain randomization for generation.
Table 2: Test performance in four environments. Each data point corresponds to the mean (and standard error)of five independent runs, where each run is evaluated for 100 trials on each environment. f indicates the generatordistribution is a Binomial, whereby the generator can place 20 blocks, each is either a lava tile or empty. ∣indicates the generator first samples the number of lava tiles to place, between zero and 20, then places thatmany. Bold indicates being within one standard error of the best mean.
Table 3: Zero-Shot transfer to human-designed environments. Each data point corresponds to the mean (andstandard error) of five independent runs, where each run is evaluated for 100 trials on each environment. findicates the generator first samples the number of blocks to place, between zero and sixty, then places thatmany. ∣ indicates the generator produces empty rooms. Bold indicates being within one standard error of thebest mean. ? indicates p < 0.05 in Welch’s t-test against PLR. Note that all methods are evaluated after 20kstudent updates, aside from PAIRED and Minimax which have 30k updates.
Table 4: Zero-Shot transfer to human-designed environments. Each data point corresponds to the mean (andstandard error) of five independent runs, where each run is evaluated for 100 trials on each environment. Allmethods use a DR generator which places between zero and sixty blocks.
Table 5: Total number of environment interactions for 20k PPO updates.
Table 6: Hyperparameters used for training each method in the maze and car racing environments.
