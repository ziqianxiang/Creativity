Table 1: BERT-Large pre-training (batch size 16K) final validation loss, and SQuAD average/maxdev set F1 scores over 32 runs using the pre-trained BERT models. The first two columns are from theoriginal LAMB work. The last two columns are our experiments using the same training parameters.
Table 2: BERT-Large pre-training (batch size 64K/32K at seqlen 128/512) final validation loss, andSQuAD average/max dev set F1 scores over 32 runs using the pre-trained models. “LAMB + basic1-bit” is the experimental algorithm described in Section 3.4. “ 1-bit LAMB” is the proposed workdescribed in Section 4.
Table 3: GLUE development set results using the pre-trained BERT-Large models. “Original” resultsare from Devlin et al. (2019) using BertAdam. “LAMB” results use the uncompressed LAMB forBERT pre-training. “LAMB + basic 1-bit” is the experimental algorithm described in Section 3.4. “1-bit LAMB” is the proposed work. The latter 3 cases use the same shared training parameters duringpre-training and fine-tuning. Spearman correlations are reported for STS-B, and accuracy scores arereported for the other tasks. Each task,s scores are the median scores over 32 runs.
Table 4: Total runtime of BERT-Large pre-training with LAMB and 1-bit LAMB (256 GPUs withEthemet connections. Batch sizes 64K/32K for Seqlen 128/512.)Seqlen 128 Seqlen 512	TotalLAMB	657 min	74 min	731 min1-bit LAMB 301 min (2.2x)	50 min (1.5x)	351 min (2.1x)pu8α,s∕s-dE"s14000600020001600020000-I I I Ipu8a,s∕s-dE"s(a)	seqlen 128, batch size8K(b)	seqlen 128, batch size16K(c)	seqlen 128, batch size (d) seqlen 128, batch size32K	64K⅝ , I ⅝ I 1
Table 5: BERT-Large pre-training Seqlen 128 profiling results.
Table 6: SQuAD average/max dev set F1 scores over 32 runs using the BERT models pre-trained (batch size 64K/32K at seqlen 128/512) with different optimizers and different numberof GPUs/workers. The first column is from the original LAMB work. The last two columns are ourexperiments Using the Same training parameters._______________________________SQuAD Avg./Max F1	LAMB (You et al., 2020)	LAMB	1-bit LAMB128 GPUs	-/90.584	90.257/90.557	90.494/90.74064 GPUs (from Table 2)	-/90.584	90.265/90.555	90.524/90.78832 GPUs	-/90.584	90.263/90.584	90.469/90.811Table 7: SQuAD average/max dev set F1 scores over 32 runs using the BERT models pre-trainedwith different optimizers and different pre-training batch sizes. The first colUmn is from the originalLAMB work. The last two columns are our experiments using the same training parameters.
Table 7: SQuAD average/max dev set F1 scores over 32 runs using the BERT models pre-trainedwith different optimizers and different pre-training batch sizes. The first colUmn is from the originalLAMB work. The last two columns are our experiments using the same training parameters.
Table 8: Final testing accuracy for ResNet-50 on CIFAR100.
