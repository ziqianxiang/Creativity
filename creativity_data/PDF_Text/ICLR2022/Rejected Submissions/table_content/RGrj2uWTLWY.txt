Table 1: Test accuracy on five different datasets for PI-GNN with GCN as the backbone. Bold numbers aresuperior results. Standard deviation is shown in the bracket.
Table 2: TeSt aCCuraCy on different graPh neural network arChiteCtureS. Bold numberS are SuPerior reSultS.
Table 3: Comparative results with baselines. Bold numbers are superior results. LPM-1 means one extra cleanlabel is used for each class. The result on the left and right of each cell is the classification accuracy of the Coradataset and CiteSeer dataset, respectively.
Table 5: Left: Performance of the PI-GNN applied on different label-noise baselines on Cora. Right:Performance of PI-GNN with different architectures for two branches on CiteSeer.
Table 4: Performance of PI-GNN with dif-ferent PI labels.
Table 6: Statistics of the datasets.
Table 7: Comparison with more baselines on Cora Dataset.
Table 8: Experimental results on heterophilous datasets.
Table 9: Statistical significance tests.
Table 10: Experimental results on using clean PI labels. Clean PI-GNN means the PI-GNN is trainedwith the clean PI labels.
Table 11: Experimental results with lower noise ratios.
