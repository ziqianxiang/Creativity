Table 1: Accuracy improvement by augmenting subsets found by our method vs. max-loss andrandom, over improvement of full data augmentation (F.A.) compared to no augmentation (N.A.). Thetable shows the results for training on CIFAR10 with ResNet20 (C10/R20), SVHN with ResNet32(SVHN/R32), and CIFAR10-Imbalanced with ResNet32 (C10-IB/R32), with R = 20.
Table 2: Training ResNet20 on CIFAR10 with 50% label noise, with R = 20. Accuracy withoutaugmentation is 70.72 ± 0.20 and the accuracy of full data augmentation is 75.87 ± 0.77. Note thataugmenting 50% subsets outperforms augmenting the entire data (marked as **).
Table 3: Training ResNet20 and WideResnet-28-10 on CIFAR10 using small subsets, with R = 1.
Table 4: Supplementary table for Table 1 - Test accuracy on CIFAR10 + ResNet20, SVHN +ResNet32, CIFAR10-Imbalanced + ResNet32 including standard deviation errors and full datasetaugmentation accuracy.
Table 5: Speedup on CIFAR10 + ResNet20 (C10/R20), SVHN + ResNet32 (SVHN/R32).
Table 6: Training on full data and selecting a new subset for augmentation every epoch (R = 1).
