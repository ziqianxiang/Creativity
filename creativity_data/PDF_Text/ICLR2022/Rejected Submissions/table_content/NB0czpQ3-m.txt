Table 1: Neural network models’ propertiesModel Name	Base Model	Reference	# Epochs	Accuracy	LossResnet-10	Resnet	He et al. (2016)	10	0.72	1.07Resenet-100	Resnet	He et al. (2016)	100	0.91	0.4456VGG16-10	VGG16	Simonyan & Zisserman (2015)	10	0.73	0.8329VGG16-200	VGG16	Simonyan & Zisserman (2015)	200	0.76	2.7082Densenet	Densnet	Huang et al. (2017a)	200	0.93	0.53354.1	Experiment 1: Measuring robustness’ sensitivity to perturbation sizeBy our notion of robustness given in Definition 3, it is likely that the plrδ, (N, x0) score decreasesas E increases. For our first experiment, we set out to measure the rate of this decrease. Using ourDensenet model, we repeatedly invoked Algorithm 1 to compute plr scores for increasing values ofE. For our x0, we arbitrarily selected the first 100 images from the CIFAR10 test set, and measuredthe average robustness of the images for each E. The averaged results (depicted in Figure 3) indicate7an almost linear correlation between and the robustness score. This result is supported by earlierfindings Webb et al. (2018).
Table 2: Pivot analysis of all samples in the test setCategory	# Samples	Robustness Avg	Robustness varianceAirplane	1000	1 - 2.8894 ∙ 10-4	1.1362 ∙ 10-5Automotive	1000	1 - 8.3363 ∙ 10-5	1.0430 ∙ 10-6Bird	1000	1 - 1.1877 ∙ 10-4	1.5064 ∙ 10-6Cat	1000	1 - 7.0537 ∙ 10-5	7.8409 ∙ 10-7Deer	1000	1 - 1.3545 ∙ 10-4	1.9256 ∙ 10-6Dog	1000	1 - 7.1440 ∙ 10-6	3.8810 ∙ 10-9Frog	1000	1 - 6.6058 ∙ 10-5	6.0929 ∙ 10-7Horse	1000	1 - 2.5776 ∙ 10-4	7.9067 ∙ 10-6Ship	1000	1 - 1.6059 ∙ 10-4	3.0538 ∙ 10-6Truck	1000	1 - 2.7746 ∙ 10-4	6.8932 ∙ 10-6two categories are indeed distinctly different. From this, we draw the important conclusion that theper-category robustness of models can be far from uniform.
