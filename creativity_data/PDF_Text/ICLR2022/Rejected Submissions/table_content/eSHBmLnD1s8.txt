Table 1: FID Score with varying the number of instances#Instances	2	5	10	15	20	30K-Greedy	8.8800 ± 5.5857	4.4306 ± 1.3313	4.2199 ± 1.4214	3.7160 ± 1.1314	3.2431 ± 1.3881	2.7554 ± 0.8554FPS	6.5014 ± 4.3502	4.5098 ± 2.3809	3.0746 ± 1.0979	2.7458 ± 0.6201	2.7118 ± 1.0410	2.2943 ± 0.8010Random	3.7309 ± 1.1690	1.1575 ± 0.6532	0.8970 ± 0.4867	0.3843 ± 0.2171	0.3877 ± 0.1906	0.1980 ± 0.1080SSS	2.5307 ± 1.3583	1.0186 ± 0.1982	0.5922 ± 0.3181	0.3331 ± 0.1169	0.2381 ± 0.1153	0.1679 ± 0.0807without any finetuning. Our model also outperforms this variant, showing the effectiveness of trainingwith the target task. Note that we cannot apply LTS to this experiment because during training, thegenerated virtual points with LTS cannot be converted back to an image in matrix form due to thevirtual coordinate, thus we cannot train the LTS model with CNN-based classification for this task.
Table 2: Accuracy on miniImageNet			#Instances	1	2	5FPS	0.432±0.005	0.501 ±0.002	0.598±0.000Random	0.444±0.003	0.525±0.005	0.618±0.003K-Greedy	0.290±0.006	0.413±0.005	0.570±0.002SSS	0.475±0.006	0.545±0.011	0.625±0.006more representative prototypes than the others especially for small Ds where the choice of prototypesmatters more. Notably, the K-Greedy method performs poorly for small subset sizes given that themodel overfits to a few samples and does not generalize to unseen examples. We show samples ofselected prototypes in Appendix G.1.
Table 3: CelebA Attributes Classification.
