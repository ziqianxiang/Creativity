Table 1: Comparison with different algorithms of feature-based datasets over 5-runs results. Std≈1e-3.
Table 2: Ablation study on MovieLens-tag dataset over 5-runs results. We show Auc and logloss.
Table 3: Results of infrequent user movielens datasetswhere occur times of a user is less than 20.
Table 5: Comparison with state-of-the-art on Amazon datasetfor user behavior modeling. We record the mean AUC over5 runs. We mainly compare our methods with a well-knownattention mechanism.
Table 4: Adapt sequence-based DPO(sDPO) on Transformer. We evaluate theeffectiveness of combination of multi-headself-attention mechanism and sDPO.
Table 6: Results on Real-world Production dataset. We show the details of how to incorporate DPNs into online ads system in Appendix G.1. For feature modeling, we name DPNs as DyMLP. For both feature and user behavior modeling together with online model, we name DPNs as DyJoint.								Module	MLP	Feature	Field	KFAtt	Homo	Heter	Auc(+gain)	Throughput (batch/s)Base	!	%	%	%	%	%	0.7523	101DyMLP	%	!	%	%	%	%	0.7530(↑0.07)	101	%	!	!	%	%	%	0.7550(↑0.27)	88Online	!	%	%	!	%	%	0.7598	55	%	!	!	!	"ɪ"	%	0.7609(↑0.11)	50DyJoint	%	!	!	!	!	%	0.7618(↑0.20)	48	%	!	!	!	%	!	0.7624(↑0.26)	48	%	!	!	!	!	!	0.7633 (↑0.35)	46For sequence-based DPO, we conduct more ab-lation studies in Appendix G.3. Our homo-geneous DPO can act as a specific form likedynamic convolution. Incorporating it with asession-based self-attention encoder, we can in-ject inductive bias learned from local neighbor-Table 7: Results of Online A/B testing.
Table 7: Results of Online A/B testing.
Table 8: Statistics of datasets for feature modeling.
Table 9: Comparison of different depth and width over 5-runs results on MovieLens-tag.
Table 10: Variants of Feature-based DPN over 5-runs results on MovieLens-tag.
Table 11: Hyper-parameters of Dynamic Parameterized Network in MovieLens-1M.
Table 12: Comparison with different algorithms over 10-runs results. Std≈1e-3. J means below while ↑ meansabove. Throughput means training time of one epoch. We also cite the results from AutoInt (Song et al., 2019).
Table 13: Ablation study of feature-based dynamic operation(a) Comparison with different head num- ber. l=4, σ is sigmoid, context is genre.			(b) Comparison with non-linear function. l=4, h=2, context is genre.			(c) Comparison with different context. l=8, h=2, σ is softmax.		head	Auc	Logloss	σ	Auc	Logloss	context	Auc	Logloss1	0.8483	0.3781	identity	0.8494	0.3781	genre	0.8511	0.37412	0.8504	0.3738	sigmoid	0.8504	0.3738	gender	0.8457	0.37824	0.8136	0.4126	softmax	0.8506	0.3745	genre, gender	0.8452	0.3800						all	0.8522	0.3726Table 14: Ablation study of field-based dynamic operation(a) Comparison with different aggre-gation methods.
Table 14: Ablation study of field-based dynamic operation(a) Comparison with different aggre-gation methods.
Table 15: Experiment Results on Real-world Production datasetDyMLP	SelfAtt	KFAtt	Encoder (k = 3)	Decoder	Auc!	!	!	Sep + SE + Homo	Sep + SE + Heter	0.7633!	!	!	Sep + SE + Homo, k = 5	Sep + SE + Heter	0.7626!	!	!	SE + Homo	SE + Heter	0.7622!	!	!	Conv1D	Sep + SE + Heter	0.7624!	!	!	Conv1D, k = 5	Sep + SE + Heter	0.7624!	%	!	Sep + SE + Homo	Sep + SE + Heter	0.7617%	!	!	Self + MLPs + Homo, k=1	Heter	0.7604when combined those two methods in a suitable way, field-wise component can contribute to thefeature-wise component for further advancement of performance.
