Table 1: Backdoor attack performance on three NLP datasets. “ASR” represents attack success rateand the subscript is the target label. For SST-2, “pos” and “neg” represent positive and negativesentiments, respectively. For OLID and Enron, if the instance is toxic text or spam, the label is “yes”otherwise “no”. “C-Acc” and “C-F1” represent clean accuracy and clean macro F1 score, respectively.
Table 2: Backdoor attack performance on three CV datasets. For Waste, “rec” and “org” representrecyclable and organic wastes. For GTSRB,“GW” and “KR” represent “give way” and “keep right”.
Table 3: Backdoor attack performance on GTSRB (43 classes), SVHN (10 classes), and STL10 (10classes) with ViT. The backdoored model has 128 triggers.
Table 4: Performance ofbackdoor attacks on VGGNet With batch normalization.
Table 5: NeUBA DefenSe for backdoored BERT.The lowest ASR of each dass is in boldface.
Table 6: NeuBA Defense for backdoored VGGNet. The lowest ASR of each class is in boldface.
Table 7: Accuracy of MNTD.
Table 8: Statistics of datasets.
Table 9: Hyperparameters used in backdoor pre-training and fine-tuning.
