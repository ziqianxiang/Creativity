Table 1: List of the bias mitigation algorithms evaluated in Sections 4 & 5.
Table 2: Highlights from Shrestha et al. (2021) replication, a variant of Figure 2’s CelebA-SL taskfor k=1. A ResNet18 is used and the protected attribute is “Male”. U-SD is competitive with GDRO(the best labeled method), and reduces bias significantly versus U-ERM.
Table 3: Highlights from Liu et al. (2021) replication, a variant of Figure 2’s CelebA-SL task fork=1. The protected attribute is “Male”. U-JTT is competitive with Weighted ERM (the best labeledmethod), and reduces bias significantly versus U-ERM.
Table 4: Results of existing bias mitigation algorithms on the ImageNet People Subtree. WeightedERM and Independent-SP significantly improve reweighted accuracy and reduce bias amplificationversus standard ERM. All intersectional bias scores are within a standard deviation.
Table 5: Comparison of pretrained and not-pretrained bias mitigated models on ImageNet. Pretrain-ing significantly improves reweighted accuracy and reduces bias amplification. However, pretrainingincreases intersectional bias (clarified in Section 5.1).
Table 6: Comparison of ImageNet results of using DIR to modify the Weighted ERM andIndependent-SP methods. DIR reduces bias amplification while maintaining the reweighted ac-curacy gains of the original Weighted ERM and Independent-SP methods.
