Table 1: ImageNet 20 class classification performance with node modification via HNICategory	Beach wagon	Ambu lance	School bus	Jeep	Fire engine	Recrea vehicle	Horse	Side winder	Irish setter	Harte beestOriginal NN Accuracy	0.54	0.69	0.80	0.53	0.73	0.68	0.93	0.64	0.73	0.67Modified NN Accuracy	0.67	0.75	0.88	0.65	0.79	0.79	0.92	0.66	0.72	0.70		Face	Green	Manhole		Shield	Toilet		Water	Category	Bassinet	powder	house	cover	Plane		tissue	Ram	buffalo	ZebraOriginal NN Accuracy	0.64	0.55	0.76	0.77	0.54	0.43	0.53	0.60	0.54	0.78Modified NN Accuracy	0.62	0.58	0.75	0.79	0.52	0.41	0.55	0.59	0.57	0.80where gc denotes the ground truth label for class c, qc1 is the probability value of class c in the studentprediction vector under temperature 1. Eq. 1 transfers knowledge from GRN back to the original NN(see Appendix for more implementation details).
Table 2: Baseline methods accuracy on modified classes in ImageNet 20 class classification	Beach wagon	Ambulance	School bus	Jeep	Fire engine	Recreational vehicle	 Original NN	0.54	0.69	0.80	0.53	0.73	0.68Baseline 1 Without Human modifying c-SCG	0.53	0.66	0.82	0.53	0.74	0.64Baseline 2: add 30 images / class	0.55 —	0.71	—	0.81	0.55	0.73	0.69Ours: With Human modifying c-SCG	0.67	0.75	0.88	0.65	0.79	0.797Under review as a conference paper at ICLR 2022Categoiy	Bus	Military	TankOriginal NN Accuracy	0.31	0.49	0.66Modified NN Accuracy	0.73	0.85	0.81Figure 6: Example of edges (concepts relationship) modification. (a) biased iLab dataset. (b)Human user can remove incorrect edges to guide the model to ignore irrelevant concept relationshipsintroduced by dataset bias. (c) iLab-20M three class classifier performance.
Table 3: Performance of Zero-shot learning with HNI. Original NN ResNet-18 (pretrain on ImageNet)trained with images of seen objects can not identify new objects I, J, K in the test set. Human teachResNet-18 to encode and recognize new objects I, J, K wih HNI.
Table 4: Input and output summarization of the whole HNI pipeline and each module/processModule / Process/ Pipeline	Input / collaborator	OutputHuman NN Interface (HNI) Pipeline 1	NN-to-Human path 1.1	Visual Concept Extractor (VCE) 1.2	Image-level SCG (I-SCG) building 1.3	Graph Reasoning Network (GRN) 2	Human-to-NN path 2.1	Human involved logic modification 2.2	GRN independent training 2.3	Partial knowledge distillation	Original NN Original NN Original NN, 50 to 100 images for each class Original NN, images, visual concepts Original NN, Image-level SCG (I-SCG) Original NN, class-specific SCG (c-SCG) c-SCGs I-SCG built with human-modified c-SCG Original NN (N etS), GRN (NetT1), Original NN (fix)(N etT 2), training images	Modified NN c-SCG, Reasoning logic explanation Important visual concepts for each class I-SCG GRN (mimic original NN), c-SCG Modified NN human-modified c-SCG GRN with human reasoning logic Modified NNB.2	Concept matchingIn multi-resolution segmentation step, to extract features for each patch resulting from image multi-resolution segmentation, we resize the patch and use the original NN to compute features after aspecific layer, e.g. “layer4.1.conv2” layer of ResNet-18. For each discovered concept, we store themean vector of all patches belonging to this concept as an anchor for future concept matching givenany image.
Table 5: Network architectures of Graph Reasoning Network GRN . (l is the length of node feature,mn is the number of nodes in each SCG, me is the number of edges in each SCG, and n is the numberof classes of interest)Training details We train GRN in an end-to-end manner. Below are the details: we use Adam withβ1=0.9 and β2=0.999, batch size 32, learning rate 0.01 for the first 25 epochs and use a decay rate of0.8 for every 25 epochs. We train GRN for 100 epochs.
Table 6: ImageNet 120 class classification performance with nodes and edges modification via HNICategory	american egret	black stork	spoon bill	white stork	cheetah	leopard	lion	tigerOriginal NN Accuracy	0.51	0.31	0.70	0.88	0.48	0.85	0.33	0.50Modified NN Accuracy	0.58	0.40	0.75	0.92	0.57	0.89	0.41	0.54Category	ambu	beach	cab	fire	jeep	limousine	recreation	school	lance	wagon		engine			vehicle	busOriginal NN Accuracy	0.52	0.45	0.38	0.59	0.63	0.33	0.66	0.47Modified NN Accuracy	0.57	0.54	0.44	0.63	0.70	0.40	0.75	0.59For those 104 unmodified classes, their accuracy before and after distillation is consistent (withdifference <0.03), their mean accuracy are: (42.6% before distillation and 42.9% after distillation)As shown in Fig. 13, In our larger experiments of 120 class ImageNet experiements, for the bird“white stork” (Fig. 13(a)), we delete the edges between head and feathers because they don’t have avery stable relationship, i.e. when the bird is in different poses: sit, stand, fly (Fig. 13(b)), its headand feathers may have different spatial relationships (no strong structure relationship between the twoconcepts). Instead, we add edges between the head and neck since it was not initially captured by theNN and they actually share reliable structural relationships. Similarly, for the “leopard”(Fig. 13(c)(d)),we delete the edges between the tail and legs and add the edges between head and back.
Table 7: Performance (Confusion matrix) of Zero-shot learning with HNI. (left) GRN with customI-SCGs of new object E. (middle) Original NN ResNet-18 trained with images of objects A, B, C, Dcan not identify object E in the test set. (right) ResNet-18 learned to encode and recognize object Eafter knowledge distillation through proposed HNI.
Table 8: Performance of Zero-shot learning with HNI. (a) Confusion matrix of GRN with customI-SCGs of new object E. (b) Confusion matrix of original ResNet-18 trained with images of objectABCD can not identify object E in the test set. (c) Confusion matrix of ResNet-18 after knowledgedistillation which obtains the ability to classify new object E after human’s teaching through HNIGNN	I Original ResNet-18 ∣ After distillation∖^Pred GT	A	B	C	D	E	A	B	C	D	E	A	B	C	D	EA	130	83	0	0	3	161	51	0	4	0	160	56	0	0	0B	0	216	0	0	0	0	216	0	0	0	67	149	0	0	0C	0	0	165	43	8	40	0	105	71	0	13	71	115	0	17D	0	0	13	203	0	0	6	0	210	0	0	0	24	192	0E	0	14	1	0	201	42	11	0	163	0	0	55	48	26	8719Under review as a conference paper at ICLR 2022Shared visual conceptsConcept 1Learned objectsHumans analyze therelationship between E,shared concepts, andIearnedABCD
Table 9: Questionnaire detailsid I	Question1	I Can you understand our explanation about how to modify the Structural Concept Graph above?2	Do you think this tool could help you modify the logic of neural network easier compared with traditionalmethods, such as data augmentation, modify parameters, or change the architecture of models?3	I	Do you want to use this interface tool to improve the performance of your neural network?G More discussionG. 1 Towards Generic InterfaceAs this work is the first attempt towards a generic interface between human and neural networks, weprimarily focus on image-related applications in our experiments. However, we want to point outthat the proposed framework can be easily extended to other data modalities and tasks with minoradaptations. The input modality is only related to the concept extraction where the concepts can beextracted from other modalities such as texts and other structured data.
Table 10: ImageNet 20 class classification performance details (GRN accuracy) with node modifica-tion via HNICategory	Beach wagon	Ambu lance	School bus	Jeep	Fire engine	Recrea vehicleOriginal NN Accuracy	0.54	0.69	0.80	0.53	0.73	0.68GRN Accuracy	0.88	0.86	0.96	0.93	0.84	0.8021Under review as a conference paper at ICLR 2022Table 11: iLab-20M three class classifier performance details (GRN accuracy)Category	Bus	Military	TankOriginal NN Accuracy	0.31	0.49	0.66GRN Accuracy	0.78	0.91	0.75G.4 Limitations(1) The zero-shot learning experiments use a synthesized dataset which is an ideal situation to showthe idea. But in the real world, the shared concepts between objects may have larger variance, whichmay hinder the performance. (2) The knowledge distillation result is sensitive to the temperatureof knowledge distillation, finding a suitable temperature is a time-consuming process. (3) Theconsistency of discovered concepts may not be good. However, our work highly relies on the resultof discovered concepts. In order to solve this, we need to use different segmentation methods to findconsistent concepts, which takes a longer time. We plan to use better methods for segmentation andmatch during the concept discovery and matching stage.
Table 11: iLab-20M three class classifier performance details (GRN accuracy)Category	Bus	Military	TankOriginal NN Accuracy	0.31	0.49	0.66GRN Accuracy	0.78	0.91	0.75G.4 Limitations(1) The zero-shot learning experiments use a synthesized dataset which is an ideal situation to showthe idea. But in the real world, the shared concepts between objects may have larger variance, whichmay hinder the performance. (2) The knowledge distillation result is sensitive to the temperatureof knowledge distillation, finding a suitable temperature is a time-consuming process. (3) Theconsistency of discovered concepts may not be good. However, our work highly relies on the resultof discovered concepts. In order to solve this, we need to use different segmentation methods to findconsistent concepts, which takes a longer time. We plan to use better methods for segmentation andmatch during the concept discovery and matching stage.
