Figure 1: KINet Architecture. Our model performs forward modeling based on image observationsin three major steps: extracting keypoint coordinates, inferring a probabilistic graph representationof the system, and estimating the next state of the system conditioned on the action. Learned func-tions and distributions are the blue blocks.
Figure 2: MPC comparison with baseline models for Top View images. Distance to goal measuredbased on of (a) position and (b) pixel errors. Comparison with baseline models shows that our modelis faster and more accurate for planning.
Figure 3: Qualitative results of generalization to different number of objects and unseen geometriesfor Top and Angled View observations. With zero-shot generalization, our model assigns keypointto the objects and performs forward modeling in unseen scenarios. The green arrows depict theoptimal action found with GraphMPC at each timestep. See Appendix C for detailed results.
Figure 4: Example of objects for training and generalization. Each object is a combination of twocuboid geoms with randomly sampled dimensions.
Figure 5: Detected keypoints and the inferred graph connectivity. Note that here we are plottingthe edges with probability of more than 0.5; however, the graph representation of the scene is aprobabilistic fully-connected graph.
Figure 6: Node features 2D t-SNE plots.
Figure 7: MPC results steps for Top View observations.
Figure 8: MPC results steps for Angled View observations.
