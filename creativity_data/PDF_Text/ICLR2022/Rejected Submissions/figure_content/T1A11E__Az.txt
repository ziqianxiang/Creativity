Figure 1: An example of different categories under similar background(left) and similar Interfer-ence(right). When a task contains some samples from these categories, it is easy to misclassify.
Figure 2: The overall architecture of the few shot classification method with task-adaptive semanticfeature learning mechanism.
Figure 3: (a) Quantitative comparison of the effect of different features in terms of the mean ac-curacy on 600 novel episodes on 5-way I-Shot and 5-way 5-shot cases for both MiniImageNet andCIFAR-FS datasets, where visual indicates the visual features learned by the visual feature learnerfψ, semantic indicates the semantic features learned by the semantic feature learner gψ, fusion de-notes the weighted sum of the visual and semantic feature embeddings, concatenation denotes theconcatenated features of the visual and semantic feature embeddings. (b) Hyperparameter analysisfor the fusion approach for the semantic and visual features. We study the effectiveness of changingthe value of fusion weight λ on the mean accuracy of 600 novel episodes in terms of 1-shot and5-shot cases. Where the red points denote the optimal hyperparameters for the respective cases.
Figure 4: t-SNE visualization of the feature embeddings generated by TasNet in 5-way 1-shot and 5-way 5-shot cases with 40 query samples per class from novel classes on MiniImageNet and CIFAR-FS datasets. the x-axis notations have the same meaning as that in Figure 3(a)In Figure 3(b), we vary the value of fusion weight λ from 0 to 1 to observe the performance change.
Figure 5: Detailed classification result of one hard task. where a denotes ProtoNet, b denotes AM3,c denotes TasNet. The number ID 0-4 below y denotes the class labels. The red number means thesample is miss classified.
Figure 6: TSNE visualization of the query samples from one hard task.
