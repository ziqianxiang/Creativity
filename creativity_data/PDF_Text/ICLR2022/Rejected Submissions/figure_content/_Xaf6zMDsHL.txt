Figure 1: Systematic analysis of convergencespeed for various objectives for matching themarginal distribution of the latent space to aprior, without the reconstruction term. Con-trastive loss is faster than existing methods atthis task. SWD measured in latent space.
Figure 2: Convergence speed and qualityof objective approximation for MoCA vsWAE-MMD (baseline) for various values oftheir respective regularization coefficient λ onCIFAR-10. SWD measured in image space.
Figure 3: SVD of latent representation ∈R128 for models trained with various valuesof λ. Larger λ results in more uniform singu-lar values, i.e., closer to uniform distribution,and lower (better) FID for generated samples.
Figure 4: The interplay between the latentdimension d of the MoCA network and theregularization coefficient λ. Larger d requiressignificantly larger λ to achieve comparableFID scores for the generated sample quality.
Figure 5: Random samples (rows 1-2) from a model trained with MoCA on CelebA-HQ, and thatmodel’s interpolations (rows 3-4) between images in latent space. The leftmost and rightmost columnsof rows 3-4 are the original images from the test set of CelebA-HQ which we are interpolating.
Figure 6: Left: CIFAR-10. Right: CelebA. Rows 1-2 show original image (odd column) and itsreconstruction (even column). Rows 3-4 show model’s interpolation between two test images inlatent space. The leftmost and rightmost columns of rows 3-4 are the original images from thecorresponding test set. Rows 5-6 show random samples drawn from a trained model.
Figure 7: Left: MoCA. Right: Hyperspherical VAE (S-VAE). T-SNE projections of autoencoder la-tent representation of MNIST test set. Both algorithms learn a hyperspherical latent space embedding.
Figure 8: Impact of regularization coefficient λ on reconstruction loss at the end of training. Largervalues of λ do not interfere with the reconstruction loss, rather help achieve lower reconstruction loss.
Figure 9: Impact of regularization weight λ on FID score based on input size. Optimal valuesλ? (labeled with a red star) scale linearly with input size. Note that absolute FID scores are notcomparable between different image sizes! This figure focuses on relative trends.
Figure 10: Impact of τ on optimal choice of λ and best FID for generated samples. Optimal λ islower for lower τ . Best FID is better for lower τ . This suggests that entropy is maximized moreaccurately when τ is smaller.
Figure 11: Random samples generated by a model trained (as described in appendix A on CelebA-HQ256 × 256 for 850 epochs. Model checkpoint picked based on best visual quality.
Figure 12: Image reconstructions by a model trained (as described in appendix A) on CelebA-HQ256 × 256. For each pair of columns, the left is the original image, and the right is the reconstruction.
Figure 13: Latent space interpolations by a model trained (as described in appendix A) on CelebA-HQ256 × 256.
Figure 14: Randomly generated samples fromthe MoCA model trained on CIFAR-10 with FID54.36 in table 1.
Figure 15: Randomly generated samples fromthe MoCA model trained on CelebA with FID44.59 in table 1.
Figure 16: Reconstructed test samples from theMoCA model trained on CIFAR-10 with FID54.36 in table 1.
Figure 17: Reconstructed test samples from theMoCA model trained on CelebA with FID 44.59in table 1.
Figure 18: Interpolation between two test im-ages in latent space for MoCA model trainedon CIFAR-10 with FID 54.36 in table 1. Theleftmost and rightmost columns are the originalimages from the corresponding test set.
Figure 19: Interpolation between two test im-ages in latent space for MoCA model trained onCelebA with FID 44.59 in table 1. The leftmostand rightmost columns are the original imagesfrom the corresponding test set.
