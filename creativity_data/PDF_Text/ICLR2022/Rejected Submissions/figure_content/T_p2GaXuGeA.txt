Figure 3: MLCE vs. kernel bandwidth γ for ImageNet.
Figure 4: Reward attained vs. reward ratio for theImageNet dataset (higher is better). LoRe achievesthe highest rewards across a wide range of rewardratios.
Figure 5: MLCE vs. kernel bandwidth γ for all methods on task 1 of Section 5.3, predicting whether aneighborhood’s crime rate is higher than the median. LoRe achieves the best (or competitive) MLCE for most γ.
Figure 7: MLCE vs. kernel bandwidth for all methods on task 3 of Section 5.3, predicting hair type on CelebA.
Figure 6: MLCE vs. kernel bandwidth γ for all methods on task 2 of Section 5.3, predicting hair color on CelebA.
Figure 8: MLCE vs. kernel bandwidth γ for all recali-bration methods for CIFAR-100 (3D t-SNE features).
Figure 9: MLCE vs. kernel bandwidth γ for all recali-bration methods for CIFAR-10 (3D t-SNE features).
Figure 11: MLCE vs. kernel bandwidth γ for all recal-ibration methods on ImageNet using AlexNet features.
Figure 10: MLCE vs. kernel bandwidth γ for all re-calibration methods on ImageNet using Inception-v3features. LoRe achieves the best MLCE for most γ.
Figure 12: MLCE vs. kernel bandwidth γ for all re-calibration methods on ImageNet using DenseNet121features. LoRe achieves the best MLCE for most γ.
Figure 13: MLCE vs. kernel bandwidth γ for all re-calibration methods on ImageNet using ResNet101features. LoRe achieves the best MLCE for most γ.
Figure 14: MLCE vs. kernel bandwidth γ for all re-calibration methods on ImageNet using Inception-v3features to calculate the MLCE and AlexNet featuresfor applying LoRe.
Figure 15: MLCE vs. kernel bandwidth γ for all re-calibration methods on ImageNet using DenseNet121features to calculate the MLCE and AlexNet featuresfor applying LoRe.
Figure 16: Average LCE vs. kernel bandwidth γ forall recalibration methods on ImageNet (3D t-SNEfeatures). LoRe gets lower average LCE for most γ.
Figure 17: Average LCE vs. kernel bandwidth γ forall recalibration methods in task 1 (crime data, 2Dt-SNE features). LoRe gets lower average LCE formost γ.
Figure 18: Average LCE vs. kernel bandwidth γ forall recalibration methods in task 2 (CelebA, 2D t-SNEfeatures). LoRe gets lower average LCE for most γ.
Figure 19: Average LCE vs. kernel bandwidth γ forall recalibration methods in task 3 (CelebA, 2D t-SNEfeatures). LoRe gets lower average LCE for most γ.
