Figure 1: Loss curves and mean firing rate curves of a 5-layer SNN, initialized using the methodsproposed by Glorot & Bengio (2010) (a) and us (b). Figure (a) shows an example of inadequateinitialization. All losses start to decrease as the firing rates increase.
Figure 2: Theoretical response curves after integration (solid lines), slant asymptotes (dashed lines),and actual neuron responses (circular dots) for the first-order linear integrate-and-fire model with(a) k = 1 and (b) k ∈ (0, 1).
Figure 3: The illustration of the impact of initialization methods to the overall spike activity beforetraining. The networks are randomly initialized using different initialization methods.
Figure 4: Training loss and validation accuracy curves on the MNIST, N-MNIST, CIFAR10, andCIFAR10-DVS datasets. The MNIST and CIFAR10 datasets are encoded with the Poisson distribu-tion. The first two rows show the loss and accuracy curves in the earliest 5 and 20 epochs. The thirdrow shows the validation accuracy curves throughout the whole training process.
Figure 5: Validation accuracy (red polylines) and training iterations (colored bar charts, where thevalue indicates the number of iterations at which the accuracy first reaches the expected level of 60%)for first-order integrate-and-fire neurons with different (k, λ) settings and initialization methods.
Figure 6: Training accuracy and validation accuracy using different training hyperparameters, dif-ferent (k, λ, θ) settings and different initialization methods. The performance with four differentoptimizers (Adam, SGD, ASGD, AdaGrad) is shown in (a). The performance with four differentsurrogate functions (sigmoid, tanh, arctan, hardtanh) is presented in (b).
Figure A7: Surrogate functions and corresponding gradients.
Figure A8: Training iterations at which the accuracy first reaches the expected level (60%) for first-order integrate-and-fire neurons with different (k, λ) settings and initialization methods. Note thatθ is set to 1.0. The total number of iterations of 3 training epochs is 2811. A value of 2811 in thisfigure means that in the corresponding setting, the network cannot be trained to reach the expectedtraining accuracy level.
Figure A9: Training accuracy heatmaps for first-order integrate-and-fire neurons with different(k, λ, θ) settings and initialization methods. The color represents the validation accuracy in thegiven setting.
