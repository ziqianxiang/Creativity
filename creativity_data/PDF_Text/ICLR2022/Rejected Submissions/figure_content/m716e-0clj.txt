Figure 2:	The evolution comparison of loss, accuracy and consensus error for CIFAR-10 dataset ona heterogeneous (α = 10) network of size 8.
Figure 3:	An ablation study of the hyperparameter ν in DAG-Adam for CIFAR-10 dataset on het-erogeneous networks of size 8. The heatmap on the right shares the same selection of ν and α withthe left figure. We reported the detailed accuracy value in it.
Figure 4: An illustration of decentralized topology and its communication pattern14Under review as a conference paper at ICLR 2022Algorithm 2 DAdam (Nazari et al., 2019)Initialize χi0) arbitrarily; let β1,β2,β3 ∈ (0,1); let m(0) = v(0) =V(0) = 0; set Y properly;For t = 0, 1, 2, ..., T - 1, every node i doSample g(t = VF (χ(t; ξ(t));mi(t) = β1mi(t-1) + (1 - β1) gi(t);vi(t) = β2vi(t-1) + (1 - β2) gi(t)	gi(t);Vft= β3V(tT) + (1 - β3) max{v(tT), v(t)};x(t+1) = Pj∈Ni Wijxjt) - Ym(tVty+ JWeighted norm inequality. In this paper, the weighted norm kχk* 2 * * * * * B * * * * * * isA only considers the scenario inwhich A is a diagonal matrix. Suppose the diagonal elements in the diagonal matrix A satisfy that0 < a ≤ [A]i,i ≤ b for all i, one useful inequality isakχk2A ≤ kAχk2 ≤ bkχk2A	(25)The proof is strait-forward:kAxk2 = xτA2x = (A1∕2x)TA(A1∕2x) ≤ b(A1∕2x)T(A1∕2x) = b∣∣x∣∣A	(26)We can use the same argument to show akχkTA ≤ kAχk2 as well.
Figure 5: The boxplot of the first 9 entries of gradient square term vi(t) at the end of iteration of variousalgorithms. The box represents the mean, quartile, and the min-max value of that entries cross all agents.
Figure 6: Convergence comparison between various algorithms for a full-batch logistic regression problem.
Figure 7: Loss and accuracy evolution for CIFAR-10 dataset using DSGD(V) under a homogeneousnetwork of size 8. Left plot: training loss. Right plot: validation accuracy.
Figure 8: Loss and accuracy evolution for CIFAR-10 dataset using DAdam(ν) under a homogeneousnetwork of size 8. Left plot: training loss. Right plot: validation accuracy.
Figure 9: Heterogeneous data distribution visualization for CIFAR-10 dataset.
Figure 10: Training loss and validation accuracy evolution for CIFAR-10 dataset under a heteroge-neous network of size 8 with α = 10. Left plot: training loss. Right plot: validation accuracy.
Figure 11: Convergence results on the BERT fine-tuning (SQuAD) task with different models andtopologies.
