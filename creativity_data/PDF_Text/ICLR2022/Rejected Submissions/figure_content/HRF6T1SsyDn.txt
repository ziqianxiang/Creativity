Figure 1: The overall architecture of our generalized relational neural network (RelNNs). It followsthe computation graph of NLM (Dong et al., 2019) and can be applied to hypergraphs.
Figure 2: How the performance of models drop when generalizing to larger graphs on the problemconnectivity-4 (trained on graphs with size 10).
Figure 3: The test accuracy when the number of training samples varies between 10 and 300. Allnumbers are averaged over three runs with randomly selected training sets. Note that we do not teststructural generalization here, so n = 10 for both training and testing).
