Figure 1: Schematic of the attack procedure onDVS data.
Figure 2: Examples of adversarial inputs on the BMNIST (top), NMNIST (middle) and IBM Ges-tures (bottom) datasets, as obtained by the SparseFool method. The captions show the original(true) label, correctly identified, and the class later identified by the model. The data was re-framedin time for convenience of visualisation. Red indicates added spikes. In the BMNIST examples,blue indicates removed pixels. We note that in the lower-dimensional BMNIST case, the effect ofthe attack is semantically interpretable: for example, adding a stroke that closes the upper left partof a “7” makes it look like a “9” not only for the network but also for a human observer. See thesupplementary video for more examples and motion visualisation.
Figure 3: Examples of adversarial patches successfully applied to a single “right hand clockwise”data sample, with different target classes. See also the supplementary video for motion visualisationand more examples of successful patch attacks.
Figure S1: Properties of the adversarial perturbations found by SparseFool, for two experiments:NMNIST (in simulation, η = 0.5, λ = 2) and IBM Gestures (as tested on chip). Top left: Numberof events in time within each data sample. The shaded areas represent the 0.1-0.9 interquantile range(not shown for the ‘original’ curve in the bottom panel). The perturbation tends to consist of spikesadded at the beginning of the sample, especially for NMNIST which does not rely on temporalstructure for inference. Very few spikes are removed, which justifies the choice of ignoring removedspikes in on-chip experiments. The periodic structure of NMNIST samples is intrinsic to the dataset,recorded with saccades. Bottom left: Distribution of increase in number of spikes after the attack,relative to the original number. Right: Matrices showing the label identified by the network whenpresented with the adversarial examples, given the original label, for the two experiments. MostIBM Gestures classes are perturbed towards the ‘other’ class, while there is no clear structure in theNMNIST case. LH = Left Hand, RH = Right Hand, (C)CW = (Counter) ClockWise.
Figure S2: Success rate and median L0 of SparseFool for networks trained with TRADES robustnessbased on PGD attacks.
