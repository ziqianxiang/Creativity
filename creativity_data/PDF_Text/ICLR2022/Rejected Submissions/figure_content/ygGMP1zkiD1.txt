Figure 1: Attention patterns in BERT suggest the existence of potential gender and racial biasesattention weights between all pairs of tokens in the input sequence (Vaswani et al., 2017), such thateach token learns to attend to its most related tokens, hence the prevalence of attention in definingthe understanding of natural language. In this work, we assume that undesired social stereotypesare primarily encoded in the self-attention block. In order to verify this hypothesis, we show andanalyze some attention maps of BERT in Figure 12. Consider the following sentence ”The doctorasked the nurse a question.” Aiming to analyze how every word representation3 relates to differentsocial groups, we add a dummy second input consisting of words representing two distinct genders(he and she after the [SEP] token). Figure 1(a) illustrates that the token doctor pays much moreattention to he than to she4. Figure 1(b) reveals that nurse attends to she. This finding suggests thatgender stereotypes are deeply encoded in attention weights. Likewise, in Figure 1(c), the token mathis more related to asian than to white or black, conforming to the famous racial stereotype castingasians as really good mathematicians. These examples align with our intuition that social stereotypesare first and foremost encoded in the self-attention block of text encoders before they propagate totheir embeddings or predictions in downstream NLP tasks. Consequently, we propose Att-D, afinetuning method for reducing undesired biases of text encoders from their attention component.
Figure 2: Overview of an attention head before (a)and after (b) debiasingencoder. So, we do not impose any restrictions on them. In the following, we describe each step ofAtt-D in detail.
Figure 3: Scatter plots of attention scores on male - female direction. (a) Original BERT, (b) BERTdebiased by Sent-D (c) BERT debiased by Kaneko & Bollegala (2021), (d) BERT debiased by Att-D(d)17Under review as a conference paper at ICLR 2022Table 9: Bias reduction in BERT base and large measured on Crows-Pairs dataset. Each cell isorganized as follows: o → d +/-diff where o is the stereotype score of the original model, d is that ofthe debiased model using attention-based debiasing, and diff is the difference in stereotype score.
