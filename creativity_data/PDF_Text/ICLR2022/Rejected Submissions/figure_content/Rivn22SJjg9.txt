Figure 1: Illustration of our method for obtaining the network embeddings. We sample architecturesfrom the search space, and form a batch of views with different random initializations. We computethe data Jacobians, project them, and feed them to the contrastive network. The contrastive modellearns to generate similar embeddings for networks with similar performance.
Figure 2: t-SNE projections of different statistics of the architectures in NAS-Bench-201.
Figure 3: Predicted accuracy against actual accuracy. The predictions are produced by RandomForest Regression applied on our embeddings of 1000 randomly selected architectures in NAS-Bench-201 (Dong & Yang, 2020).
Figure 4: t-SNE projections of movement in embedding space during training of 20 architecturesin the NAS-Bench-201 benchmark. The lines show the trajectories in the embedding space duringtraining of an architecture.
Figure 5: Search results on NAS-Bench-201 (Dong & Yang, 2020) and NAS-Bench-101 (Ying et al.,2019)We show the results of the search on the benchmark (Ying et al., 2019) in Figure 5d. Again, forboth downstream methods our embeddings reach a lower regret at the end of the training. However,our REINFORCE implementation using a categorical distribution over the operations on the nodesas well the elements of the adjacency matrix, consistently outperforms all other methods on thisbenchmark.
Figure 6: The transferability of features is evaluated using the two different search spaces that areprovided by NATS-Bench: size and topology (Dong et al., 2020). A random forests model is trainedon 5000 samples from one benchmark and evaluated on the other. The notation size→topologyfor example means that the model is trained on the size benchmark and evaluated on the topologyone. For both size→topology and topology→size we see a significant correlation between the thepredicted accuracies and the actual accuracies without ever having evaluated a single network fromthe target search space.
