Figure 2: Human perception of small shifts. Im-age pairs with 1- and 2-pixel shift are deemed thesame in 80.7% and 56.0% of the responses, resp.
Figure 3: LPIPS framework. The same featureextraction network (AlexNet) is used to extractfeature embeddings from Idst and Iref. Thedifference between these embeddings is calcu-lated at different levels and is combined to-gether as the similarity between Idst and Iref .
Figure 4: Feature embedding difference mapsat different levels. (a) an input image and itsone-pixel shifted version. (b) difference mapsbetween embeddings extracted by the originalAlexNet. (c) difference maps between embed-dings extracted by AlexNet augmented with anti-aliased strided convolution and pooling layers.
Figure 6:(C)(b)Anti-aliased skipped connection. (a)VGG-like network with AvgBlurPool, (b) withskip connection, and (c) with anti-aliased skip.
Figure 7: Illustration of Full Convolution (F-Conv), where every value of the filter needs to beapplied to each value of an input image. Hence, the input needs to be padded first with padding size2k for a filter with size 2k + 1 (Kayhan & Gemert, 2020).
