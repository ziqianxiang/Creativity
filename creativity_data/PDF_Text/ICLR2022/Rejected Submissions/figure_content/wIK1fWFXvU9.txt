Figure 1: The results of ST and AT on a binary datasetwith noisy labels. Dots denote correct data; squares denoteincorrect data. The color gradient represents the predic-tion confidence: the deeper color represents the higherprediction confidence. Left panel: A deep network shapestwo small clusters (red and blue ones in cross-over areas)around two incorrect data due to memorization effects inST. Right panel: These clusters have been smoothed outin AT. Boxes represent the unit-norm ball of AT.
Figure 2: The average entropy of mod-els trained by ST and AT. This valueis calculated on 100 points in eachneighborhood of incorrect data, us-ing CIFAR-10 with symmetric-flippingnoise. Both solid and dashed lines rep-resent ST and AT, respectively. Notethat ST learns incorrect data more de-terministically than AT.
Figure 3: The standard accuracy of ST and AT on correct/incorrect training data using CIFAR-10and MNIST with symmetric-flipping noise. Solid lines denote the accuracy of correct training data,while dashed lines correspond to that of incorrect training data. Compared with ST, there is a largeperformance gap in the standard accuracy of correct/incorrect training data in AT.
Figure 4: The standard accuracy of ST and AT on natural test data using CIFAR-10 and MNIST withsymmetric-flipping noise for training. Note that the larger noise rate causes the test accuracy ofST dropping more seriously due to memorization effects in deep learning, while AT alleviates suchnegative effects.
Figure 5: Comparisons of correct/incorrect data interms of the loss value (top panel) and the geometryvalue κ (bottom panel) on CIFAR-10 with symmetric-flipping noise in AT. We calculate the mean values ineach epoch. We clearly demonstrate that the value κhas a similar trend as loss value in AT; both can beused for differentiating correct/incorrect data in AT.
Figure 6: We choose the model trained byAT using CIFAR-10 with 20% symmetric-flipping noise. We jointly analyze the ge-ometry value κ and the loss value, whichshows that the value κ can provide a finestratification on typical (i.e., larger κ"rare(i.e., smaller κ) data.
Figure 7: The density of AT on correct/incorrect data using CIFAR-10 with (a) 20% symmetric-flipping noise and (b) 40% pair-flipping noise. Top panels: the loss value in AT. Bottom panels: thegeometry value κ in AT. The geometry value κ has a better distinction on correct/incorrect data.
Figure 8: The geometry value κ w.r.t. images in CIFAR-10 and MNIST with 20% and 10% symmetric-flipping noise. The leftmost of each subfigure is the given label (i.e., deer and plane or 3 and 8) ofall images on the right. We randomly select four examples with the different κ in each class. As thegeometric value κ increases from left (κ = 0) to right (κ = 10 or 40), the semantic information ofimages is more typical and recognizable.
Figure 9: The accuracy of four approaches as-signing correct labels to adversarial U data fromCIFAR-10. Left panel: the full results. Rightpanel: the zoom-out results (without standardannotator). Our robust annotator has a satisfac-tory performance on assigning reliable labels.
Figure 10: The accuracy (left panel) and num-ber (right panel) of correctly predicted U dataw.r.t. the geometry value κ. We randomly select2000 test data in CIFAR-10 as unlabeled data.
Figure 11: The results of standard training (ST) and adversarial training (AT) on a binary datasetwith noisy labels. Dots denote correct data, while squares denote incorrect data. The color gradientrepresents the prediction confidence: the deeper color represents higher prediction confidence. Inthe leftmost panel, deep networks shapes two small clusters (red and blue ones in cross-over areas)around two incorrect data due to memorization effects in ST. As the number of PGD iterationsincreases, the smoothing effects in AT gradually strengthens, and two small clusters gradually shrinkuntil they disappear in the rightmost panel. Namely, these clusters have been smoothed out in AT(PGD-4). Boxes represent the norm ball of AT.
Figure 12: The average entropy of models trained by ST and AT. This value is calculated on 100points in each neighborhood of incorrect data, using CIFAR-10 with symmetric-flipping noise. Bothsolid and dashed lines represent ST and AT, respectively. Note that ST learns incorrect data moredeterministically than AT.
Figure 13: The standard accuracy of ST and AT on correct/incorrect training data using CIFAR-10and MNIST with symmetric-flipping noise. Solid lines denote the accuracy of correct training data,while dashed lines correspond to that of incorrect training data. Compared with ST, there is a largeperformance gap in the standard accuracy of correct/incorrect training data in AT.
Figure 14:	The standard accuracy of ST and AT on correct/incorrect training data using CIFAR-10 andMNIST with pair-flipping noise. Solid lines denote the accuracy of correct training data, while dashedlines correspond to that of incorrect training data. Compared with ST, there is a large performancegap in the standard accuracy of correct/incorrect training data in AT.
Figure 15:	The standard accuracy of ST and AT on natural test data, where training data usingCIFAR-10 and MNIST with symmetric-flipping noise. Note that the larger noise rate causes the testaccuracy of ST dropping more seriously due to memorization effects in deep learning, while ATalleviates such negative effects.
Figure 16: The standard accuracy of ST and AT on natural test data, where training data usingCIFAR-10 and MNIST with pair-flipping noise. Note that the larger noise rate causes the test accuracyof ST dropping more seriously due to memorization effects in deep learning, while AT alleviates suchnegative effects.
Figure 17: The loss landscape w.r.t weight space of models trained by ST and AT using CIFAR-10with 20% symmetric-flipping noise. The red/blue colors denote large/small values, which reflectthe relative position in the loss landscape. Note that the loss landscape of a model trained by AT issmoother and flatter than that by ST, which reflects the better model generalization by AT.
Figure 18: The standard/robust accuracy of AT on natural training data, adversarial training data(PGD-10), adversarial test data (PGD-20) using the CIFAR-10 dataset with symmetric-flipping noise.
Figure 19: The standard accuracy of AT on natural training/test data using the CIFAR-10 dataset with20% symmetric-flipping noise. We conduct the experiments using ResNet-10, ResNet-18, ResNet-26and ResNet-34.
Figure 20: The standard accuracy of AT on natural test data using the CIFAR-10 dataset withsymmetric-flipping and pair-flipping noise. We conduct the experiments using WRN-32-10.
Figure 21: The loss value of ST and AT on correct/incorrect training data using CIFAR-10 and MNISTwith symmetric-flipping noise. Solid lines denote the loss value of correct training data, while dashedlines correspond to that of incorrect training data. Compared with ST, there is a large gap in the lossvalue of correct/incorrect training data in AT.
Figure 22: The loss value of ST and AT on correct/incorrect training data using CIFAR-10 and MNISTwith pair-flipping noise. Solid lines denote the loss value of correct training data, while dashed linescorrespond to that of incorrect training data. Compared with ST, there is a large gap in the loss valueof correct/incorrect training data in AT.
Figure 23: The density of AT on correct/incorrect data using CIFAR-10 with symmetric-flipping noise.
Figure 24: The density of AT on correct/incorrect data using CIFAR-10 with pair-flipping noise. Toppanels: the loss value in AT. Bottom panels: the geometry value κ in AT. Note that the geometryvalue κ has a better distinction on correct/incorrect data.
Figure 25: The geometry value κ w.r.t. images in CIFAR-10 with 20% symmetric-flipping noise.
Figure 26: The geometry value κ w.r.t. images in MNIST with 10% symmetric-flipping noise. Theleftmost is the given label of all images on the right. We randomly selected four examples withthe different κ (κ = 0, κ ∈ (0, 20), κ ∈ (20, 40), κ = 40) in each class. As the geometric value κincreases from left (κ = 0) to right (κ = 40), the semantic information of images is more typical andrecognizable.
Figure 27: The geometry value κ under the different PGD step numbers n with the = 8/255 andthe step size α = 2.5 × /n. Note that the smaller step size α (i.e., with the larger step number n)can provide a nuanced stratification compared with the larger one.
Figure 28: The geometry value κ under the different -ball with the step numbers n = 8 and thestep size α = 2.5 × /n. Note that a small ball radius can not well stratify the data since the PGDattack may never be able to successfully attack some examples (i.e., even n steps it can not find amisclassified variant).
