Figure 1: Schematic of the Hierarchical Chunking Model. a) Example of a hierarchical modelgenerating training sequences. b) Intermediate representation of learned marginal and transitionmatrices. The most frequent transition that violates the independence testing criterion is marked inred and can be turned into a new chunk. c) HCM combines the two chunks cL and cR to form a newchunk. d) As HCM observes longer sequences, it gradually learns a hierarchical representation ofchunks. e) HCM arrives at the finally chunk hierarchy isomorphic to the generative hierarchy.
Figure 2: a) Example graph generated from the hierarchical generative model with a depth of d = 3.
Figure 3: a) Example of a representation learned by an HCM. b) An environment facilitative to thelearned representation. Gray shadows mark the chunks that can be directly transferred. c) Averageperformance over the first 500 trials after environment change in the facilitative environment. d) In-terfering environment. Gray shadows marks chunks that the learned representation needs to acquirefrom scratch. e) Average performance over the first 500 trials after environment changes into an theinterfering environment.
Figure 4: a) A designed visual hierarchical model where elementary components compose morecomplex images. b) Initial, intermediate, and complex chunks learned by HCM trained on sequencesof images generated by the visual hierarchical model.
Figure 5: a) A GIF of a moving squid used as a sequence to train HCM. b) Examples of temporalchunks learned by HCM. c) Examples of visual chunks learned by HCM.
Figure 6: Illustration of Visual Temporal ChunksIn this work, we only refer to complete belief sets.
