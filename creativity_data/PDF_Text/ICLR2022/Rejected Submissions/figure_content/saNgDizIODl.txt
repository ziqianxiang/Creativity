Figure 1: Left plot shows the data and the result of the classification by the Bayes classifier basedon the nonparametric estimate of conditional density. The next two plots show different types ofuncertainties: “aleatoric” and “epistemic”. The lighter color, the higher uncertainty. We see that theformer does not increase as we go away from training data, while the latter does.
Figure 2: (a) Accuracy for images sorted by uncertainty on rotated MNIST. (b) Share of SVHNimages included into consideration vs unrotated MNIST. In this simpler version, even the basicentropy manages to achieve a good result. (c) More challenging task - share of SVHN imagesincluded into consideration vs rotated MNIST. NUQ still distinguish between datasets with close toan optimal solutionuse logits as extracted features, if not explicitly stated otherwise. However, other options are alsopossible; see Supplementary Material, Section A.4.
Figure 3: Typical OOD images for different levels of uncertainty as predicted by NUQ.
Figure 4: (a) Accuracy for images sorted by uncertainty on rotated MNIST. (b) Share of SVHNimages included into consideration vs unrotated MNIST. In this simpler version, even the basicentropy manages to achieve a good result. (c) More challenging task - share of SVHN imagesincluded into consideration vs rotated MNIST. NUQ still distinguish between datasets with close toan optimal solutionA.2.2 EnsembleFor ensemble with use a combination of 5 base models, trained with different random seeds.
Figure 5: Embeddings space visualization for CIFAR (a) and ImageNet (b). We present the em-beddings for first 15 classes on test dataset (in various colors) and all the embeddings for out-of-distribution datasets (in blue). The OOD dataset for CIFAR is SVHN and for ImageNet it isImageNet-R.
Figure 6: Left: Mixture of one dimensional Gaussians we took samples from. Color denotes classlabel. Middle: Epistemic uncertainty our model assigns to data points. Note that the uncertainty isquite high in the region of 3-5. For the sake of visualization, we clipped the maximum value to be 1.
