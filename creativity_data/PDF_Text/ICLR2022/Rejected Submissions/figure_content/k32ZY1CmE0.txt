Figure 1: Overlap in attractor geometry (Dstsp, lower = better) and dimension-wise power-spectra correlations(P SC, higher = better) against learning interval τ for (a) the Lorenz and (b) the chaotically forced Duffingoscillator. Continuous lines = sparsely forced BPTT. Dashed lines = classical BPTT with gradient clipping.
Figure 2:	Lorenz attractor (blue) and example reconstructions by a LSTM (orange) trained With a learninginterval (a) chosen too small (τ = 5), (b) chosen optimally (τ = 30), and (c) chosen too large (τ = 200).
Figure 3:	(a) The maximal Lyapunov exponent was determined as the slope of the average log-divergence ofnearest neighbors in embedding space (m = embedding dimension). (b) Reconstruction quality assessed byattractor overlap (lower = better) and power-spectrum correlation (higher = better). Black vertical lines = τpred.
Figure 4: (a) Snippet of the original temperature data and de-noised time series. (b) Blue lines show thelocal slopes of the correlation sums for embedding dimensions m ∈ {5, . . . , 10}. The convergence of theseestimates in m reveals a fractional dimension indicated by the plateau. (c) First three dimensions of the time-delay embedding series as used for training.
Figure 5: Overlap in attractor geometry (Dstsp, lower = better) and dimension-wise power-spectra correlations(PSC, higher = better) against learning interval T for the Rossler attractor. Continuous lines = sparsely forcedBPTT. Dashed lines = classical BPTT with gradient clipping. Prediction time indicated vertically in black.
Figure 6: The Rossler attractor (blue) and reconstruction by a LSTM (orange) trained with a learning interval(a) chosen too small (τ = 5), (b) chosen optimally (τ = 30), and (c) chosen too large (τ = 200).
Figure 7: Overlap in attractor geometry (Dstsp, lower = better) and dimension-wise power-spectra correla-tions (PSC, higher = better) against learning interval τ for the 10d Mackey-Glass system. continuous lines =sparsely forced BPTT. Dashed lines = classical BPTT with gradient clipping. Prediction time indicated verti-cally in black.
Figure 8: Overlap in attractor geometry (Dstsp, lower = better) and dimension-wise power-spectra correlations(P SC, higher = better) against learning interval τ for the partially observed Lorenz system. Continuous lines= sparsely forced BPTT. Dashed lines = classical BPTT with gradient clipping. Prediction time indicatedvertically in black.
Figure 9: Overlap in attractor geometry (Dstsp, lower = better) and dimension-wise power-spectra correla-tions (P SC, higher = better) against learning interval τ for the Lorenz system. Continuous lines = sparselyforced BPTT. Dashed-dotted lines = windowing without forcing (choosing windows according to the optimalprediction time, but resetting hidden states to zero rather than its TF control value). Prediction time indicatedvertically in black.
Figure 10:	(a) Snippet of the original EEG data and de-noised time series. (b) Blue lines show the local slopesof the correlation sums for embedding dimensions m ∈ {5, . . . , 10}. The convergence of these estimates in mreveals a fractional dimension indicated by the plateau. (c) First three dimensions of the time-delay embeddingseries as used for training.
Figure 11:	(a) The maximal Lyapunov exponent was determined as the slope of the average log-divergenceof nearest neighbors in embedding space (m = embedding dimension). (b) Reconstruction quality assessed byattractor overlap (lower = better) and power-spectrum correlation (higher = better). Black vertical lines = τpred.
