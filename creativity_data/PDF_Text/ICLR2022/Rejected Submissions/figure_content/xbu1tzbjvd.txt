Figure 1: A conceptual diagram of the DYNAMO algorithm and model embedding space. A setof neural networks labelled 1, ..., N called the base models are mapped to corresponding pointsθ1 , ..., θN in the model embedding space. Two points in the model embedding space are nearby ifthey correspond to neural networks with similar dynamics for their hidden and output states. Thereis an associated neural network called the meta-model which, when given a θi , becomes a neuralnetwork that emulates the hidden and output dynamics of the corresponding base model. The meta-model produces a viable neural network for any given any value of θ, including points in the modelembedding space that do not correspond to any base model.
Figure 2: Left: The hidden states ht of Fn are close to the hidden states hθn ,t of F after thetransformation map V is applied. Right: The visible states G(ht) of Fn are close to the visiblestates G(hθn ,t).
Figure 3: PCA plots of Dynamo model embeddings on collections of RNNs. From left to right:(1) The model embedding space for GRUs trained on IMDB sentiment classification dataset (Maaset al., 2011) with varying training set sizes (100%, 50% and 25% of the training data); (2) trainingtrajectories of sentiment classification GRUs over 20 epochs, with each point corresponding to anepoch of training (low-opacity points indicate networks early in training); (3) two RNN architecturestrained for IMDB sentiment classification (GRUs and vanilla RNNs); (4) GRUs trained on two NLPtasks: IMDB sentiment classification and AG News classification (Zhang et al., 2015). The secondrow shows the spectrum for each set of embeddings, with a dotted line indicating the number ofcomponents needed to explain 95% of the variance.
Figure 4: PCA plots of Dynamo model embeddings on collections of ResNet-34s trained onCIFAR-100. Left two panels: Model embeddings cluster according to the size of the trainingdataset and the data augmentation policy used for training. Right two panels: When trained onlyby comparing hidden representations (i.e., with output loss weight λ = 0), DYNAMO does notidentify a clustering effect when varying the training dataset size. In the case of differing data aug-mentation policies, there is a weak clustering effect that suggests a consistent difference in featurerepresentation.
Figure 6: Meta-model test accuracies over model embedding space. We plot the relative testaccuracies (normalized by the maximal test accuracy of the base models) realized by meta-modelsfor GRUs trained on IMDB sentiment classification with varying training set size (left), and forGRUs trained on IMDB and on AG News classification (right). In these examples, the embeddingvectors that maximize test accuracy (marked with an X) do not correspond to any single base model,suggesting that meta-models are capable of generalizing beyond the base models used for training.
Figure 5: 2D multidimensional scaling (MDS)embeddings of the SVCCA pairwise representa-tional distances between RNN models trained onthe IMDB sentiment dataset.
Figure 7: Semi-supervised learning with low-dimensional model embeddings. The red lineshows the trajectory of 100 SGD iterates in modelembedding space, starting from θinit = 0 and ter-minating at θfinal . White and orange points indi-cate the base model embeddings.
Figure 8: Model embedding space as a space of line attractors. We plot the model embeddingsof 20 base models trained on the IMDB sentiment classification task (left), along with the centroidsof each cluster. The green cluster corresponds to models trained on 100% of the data and the bluecluster corresponds to models trained on a fixed 50% fraction of the training data. A model havingbetter test accuracy than any trained base model is also plotted (marked with an ×). For several ofthe points of interest, we (right) find the structure of a line attractor in the hidden state space bycomputing approximate fixed points of the map h → F (x*, h). The line attractors are shown forthe point marked with an ×, the two centroids, and two interpolated values in the model embeddingspace. We also chose two values from each cluster to compare the line attractor at the centroid tothe models in the structure, corresponding to the top left and bottom right model in each cluster.
Figure 9: PCA plots of Dynamo model embeddings on collections of RNNs with output lossweight λ = 0. For ease of comparison, we have also included the plots from Figure 3 with λ = 1.
Figure 10: CIFAR-100 ResNet-34 model embeddings using L1 distance to compare intermediaterepresentations (left) vs. L2 distance (right). The use of the L1 distance results in a clearer separa-tion between the two sets of models.
Figure 11: A map of the word scores (described in equation 8) as a function of the parameter inmodel embedding space. Higher scores indicate models that should have better interpretations ofwords. There is a noisy but discernible trend that the score increases as θ2 decreases (and is highestnear the value of the optimal model embedding).
