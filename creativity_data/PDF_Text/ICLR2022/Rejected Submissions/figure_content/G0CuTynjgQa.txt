Figure 1: The architectures of G and D with the negative slope of LeakyRuLU is 0.2GAN - IlW∕az∣∣>GAN - ∣∣∂D∕∂x∣∣fLSGAN - ∣∣∂V7∂z∣∣p0	90	180	270Epoch0	90	180	270Epoch0	90	180	270Epoch=XWQ-LSGAN - ∣∣9D∕9x∣∣r90	180	270EpochFigure 2: Some behaviors of GAN (first two subfigures) and LSGAN (last two subfigures) withdifferent σ for augmentation. Both 架 and ⅞Z are measured along the training process. ∣∣ ∙ ∣∣fdenotes the Frobenious norm.
Figure 2: Some behaviors of GAN (first two subfigures) and LSGAN (last two subfigures) withdifferent σ for augmentation. Both 架 and ⅞Z are measured along the training process. ∣∣ ∙ ∣∣fdenotes the Frobenious norm.
Figure 3: Some behaviors of GAN and LSGAN with different σ for augmentation. ∂∂Z is measuredalong the training process.
Figure 4:	Some behaviors of GAN (first two subfigures) and LSGAN (last two subfigures) whenaugmenting images by adding noises. Both ∂∂X and ∂∂Z are measured along the training process.
Figure 5:	Some behaviors of GAN and LSGAN when augmenting images by adding noises. 祟 ismeasured along the training process.
Figure 6:	Some behaviors of Saturating GAN (top row) and LSGAN (bottom row) in differentsituations. Vg is the loss for training the generator, and FID measures the quality of generatedimages, the lower the better.
