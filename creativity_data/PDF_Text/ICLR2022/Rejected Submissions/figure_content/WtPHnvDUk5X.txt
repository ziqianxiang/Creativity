Figure 1: The framework of proposed few-shot font generation model GANet. A queryencoder is used to extract glyph content from the content encoder and glyph style from thestyle encoder by two glyph-attention modules. They are subsequently added element-wisebefore being fed into the decoder. Two discriminators are employed to stablize the trainingprocess. For more details, please refer to the appendices.
Figure 2: Glyph attention and content attentionβijexp (ξij)NHWiwm=1 exp(ξmj )ξ=gs(ks)fs(q) ξ∈RNHw×Hw(3)The attention map βij indicates the extent to which the model attends to the ith stylelocation when synthesizing jth . Where H, W, C are the height, width and channel offeatures from previous 1 × 1 conv layer. N is the number of glyphs in the style set. Theoutput of the style glyph-attention layer is Os = (O1, O2, ..., Oj, ..., OH w), Oj ∈ R1×C,where,N HwOij = X τimβmj, τ = hs(vs) τ ∈ RC×NHw	(4)m=1where τ is transposed and reshaped from hs(vs) = Whsvs. In addition, Whs ∈ RC×C,Wfs ∈ RC ×C and Wgs ∈ RC ×C are the learned weights in the 1 × 1 conv layer of the styleglyph-attention module. The final output is reshaped to Os ∈ RH ×w×C .
Figure 3: Comparison of the results in 6 different font styles for each method7Under review as a conference paper at ICLR 2022Table 1: Intersection Over Union (IOU) for many-shot and few-shot font generation methodsIntersection Over UnionType	Method	Style								1	2	3	4	5	6	Mean	zi2zi	0.529	0.534	0.599	0.695	0.515	0.423	0.549many	pix2pix	0.590	0.652	0.695	0.807	0.616	0.537	0.650shot	CycleGAN	0.206	0.272	0.262	0.465	0.325	0.312	0.307	ZiGAN	0.600	0.664	0.702	0.812	0.623	0.550	0.659	-FUNIT-	0.355	0.448	0.327	0.571	0.366	0.289	0.393few	AGIS-Net	0.387	0.369	0.418	0.736	0.483	0.388	0.464shot	MX-Font	0.260	0.362	0.382	0.648	0.490	0.295	0.406	GANet	0.711	0.683	0.749	0.778	0.481	0.401	0.634Figure 4: Top-1 accuracy of content and style in 6 different font styles for 4 few-shot fontgeneration methods4.2	Datasets and evaluation metricsWe collected 411 Chinese fonts conforming to the GB2312 standard. Each font contains6,763 Chinese characters. We randomly selected 405 fonts as the training set and the
Figure 4: Top-1 accuracy of content and style in 6 different font styles for 4 few-shot fontgeneration methods4.2	Datasets and evaluation metricsWe collected 411 Chinese fonts conforming to the GB2312 standard. Each font contains6,763 Chinese characters. We randomly selected 405 fonts as the training set and theremaining 6 fonts as the test set. Various metrics are used to evaluate the quality of thesynthesized glyphs. To measure the similarity between the generated image and the target,intersection over union(IOU) is utilized. We further employ two classifiers with Inception-v3Szegedy et al. (2016) backbone to distinguish between content and style labels in the testset.
Figure 5: The function of glyph-attention. The first column q, c and s are noted as query,content and style feature flow respectivelyA.2.2 Relationship between shot and content-styleBecause glyph-attention modules query content and style features from the content andstyle sets, the length of which impact the performance of the model. In order to figureout the relationship between shot number and model performance, we use two classifiers toidentify the synthesized glyphs from the content and style aspects respectively. On the leftside in Figure 6, we fix the length of the style set to eight and vary the shot number of thecontent set. It is found that when the shot number changes from 1 to 2, the content top-1accuracy improves significantly. However, the performance gain is limited when the shotnumber increases from 2 to 16. Similar observation is found in the right side of the figure.
Figure 6: Top-1 accuracy of content and style. On the left figure, fix the count of style setto 8, and change the shot number of content set; on the right figure, fix the count of contentset to 8, and change the shot number of style set.
Figure 7: Interpolation in content and style. For thr content interpolation, because the queryalso contain the content information, we use q+c feature that is from content glyph-attentionmodule and query encoder as the interpolation content feature. For the style interpolation,we just use the s feature that is from style glyph-attention module to interpolate.
Figure 8: More synthesised results. Style set and content set are both contain 4 glyphs tosynthesis new font.
Figure 9: More synthesised results. Style set and content set are both contain 4 glyphs tosynthesis new font.
