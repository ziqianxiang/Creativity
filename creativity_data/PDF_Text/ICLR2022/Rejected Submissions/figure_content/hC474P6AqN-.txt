Figure 1: Architecture of our method: the ellipses represent the μ and Σ of the style value distribu-tions used to sample the new style vectors.
Figure 2: Visualization of the dSprites_AP (left) and dSprites_HP (right) categorical systems on thex (solid color) and y (dotted line) coordinates. The labels refer to the y value. Given the image dataimg, the model receives as input the tuple (img, right-ap, top-ap) or the tuple (img, far-right-ap,top-hp), depending on the categorical model chosen.
Figure 3: Correlation between the style distribution means and true label range average value foreach disentangled style type in the dSprites_HP (a) and BFM_2019 (b) datasets. The “illu” styletype has only three possible style values, and therefore it is straightforward for both architectures toachieve optimal results.
Figure 4: Latent traversals performed on dSprites_HP by fixing all the latent units except the onesencoding the x and y values, whose value is increased from left to right. In (a), the discontinuitypoints can be clearly seen in the reconstructed samples, which fail to encode intermediate stylevalues, and instead present two shapes. There is no smooth transition between different style values.
Figure 5: (a) Style value representation density functions of the X coordinate for both dSprites_HPand dSprites_AP. The distributions are displaced in the correct order (i.e., far-left-hp, left-hp, Center-hp, right-hp, far-right-hp and left-ap, center-ap, right-ap) and overlap nicely to represent interme-diate values. (b) Values encoded in the latent unit corresponding to the x style value. Our methodshows a high correlation with the ground truth, across both datasets.
Figure 6: Displacement of the style distribution in the latent space. (a) shows the disentanglement ofthe generative factors among each dimension of a two-dimensional style type. (b), instead, demon-strates how, when k > d, the distributions in the unused dimensions do not encode any information,as they are completely overlapping, and therefore every style representation appears as the same.
Figure 7: Explicit distributions of the style representations along the x coordinate in the(a) dSPrites_AP and (b) dSprites_HP datasets, using the architecture developed by Sha &Lukasiewicz (2021). Analogously, (c) and (d) report the distributions’ displacement achieved byour new method on the same datasets. The charts are constructed from the μ and σ2 values stored insampling layers of the models. Similar results are obtained along the y coordinate.
Figure 8: Explicit distributions of the style representations for the yaw and illu style types in theBFM_2019 dataset. The displayed order correctly reflects the ground-truth generative values (up toan affine transformation).
