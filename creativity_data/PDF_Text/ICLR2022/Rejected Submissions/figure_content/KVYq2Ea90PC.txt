Figure 1: Most categories in ImageNet Challenge (Russakovsky et al., 2015) are not people cate-gories. However, the images contain many people co-occurring with the object of interest, posinga potential privacy threat. These are example images (with faces blurred or overlaid) of barberchair, husky, beer bottle, volleyball and military uniform.
Figure 2: Left: The fraction of images with faces for the 1000 ILSVRC categories. 106 categorieshave more than half images with faces. 216 categories have more than 25%. Right: A histogram ofthe number of faces per image, excluding the 1,187,895 images with no face.
Figure 3: The average drop in category-wise accuracies vs. the fraction of blurred area in images.
Figure 4: The average drop in category-wise accuracies caused by blurring vs. the fraction of objectarea covered by faces. Left: Top-1 accuracies. Right: Top-5 accuracies. The accuracies are averagedacross all different model architectures and random seeds.
Figure 6: Face detection results on ILSVRC by Amazon Rekognition. The first row shows correctexamples. The second row shows false positives, most of which are animal faces. The third rowshows false negatives.
Figure 7: The UI for face annotation on Amazon Mechanical Turk. Left: The worker is givenan image with inaccurate face detections. They correct the results by adjusting existing boundingboxes or creating new ones. Each HIT (Human Intelligence Task) have 50 images, including 3 goldstandard images for which we know the ground truth answers. Right: The worker loses a life whenmaking a mistake on gold standard images. They will have to start from scratch after losing both 2lives.
Figure 8: The method for face blurring. It avoids sharp boundaries between blurred and unblurredregions. I : the original image; M : the mask of enlarged face bounding boxes; Inew : the finalface-blurred image.
