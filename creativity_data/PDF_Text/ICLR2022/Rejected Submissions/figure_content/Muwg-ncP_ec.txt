Figure 1: White layer extension before the input of the neural network.
Figure 2: Training and validation loss as a function of both epochs and wall-clock time for clas-sification (MNIST) and autoencoding (CURVES) with one seed. For MNIST classification, thearchitecture is {784, 256, 32, 10}. For CURVES, the autoencoder has the following architecture{784, 216, 64, 6, 64, 216, 784}. Constant learning rates are used 0.001 for ADAM (Kingma & Ba,2014) and ADAHessian (Yao et al., 2020) and 0.01 for SGD and ESN.
Figure 3: Effect of the admissible regularization on the norm of the state variable P x(kp) fordifferent values of λ = {0,10-2,10-3,10-4,10-5}. SGD is used as the training method. Thehigher values of λ reduce further the norm of the state variable x. Training cost is reported in theright side of the figure.
