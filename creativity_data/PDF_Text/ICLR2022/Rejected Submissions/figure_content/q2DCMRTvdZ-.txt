Figure 1: (Left) Top Arch ID rate of shared-weight based validation accuracy and benchmark testaccuracy across test error threshold groups of the architecture space. (Right) Sampling probabilitymass across test error threshold groups of the probability space.
Figure 2: Comparison of Stage-2 search algorithm performance with given baseline models. ”Ini-tial” refers to untrained model, ”Uniform” refers to a model trained by training a uniformly ran-domly sampled architecture at each batch, and ”Biased” refers to a model trained by an architecturesampled from an arbitrarily good distribution at each batch.
Figure 3: Stage-2 search methods of published NAS algorithmsWe review a set of 20 published supernet NAS algorithms to determine the nature of the Stage-2search method used. We find that existing techniques overwhelmingly utilize some form of archi-tecture weight or distribution pruning to select a final architecture.
Figure 4: Left: Top arch ID rate across test regret threshold groups of the architecture space. Right:Sampling probability mass across test regret threshold groups of the probability space.
Figure 5: Comparison of Stage-2 search algorithm performance on CIFAR-100 with given baselinemodels. ”Initial” refers to untrained model, ”Uniform” refers to a model trained by training a uni-formly randomly sampled architecture at each batch, and ”Biased” refers to a model trained by anarchitecture sampled from an arbitrarily good distribution at each batch.
Figure 6: Performance of Stage-1 and Stage-2 search on CIFAR-100 algorithm combinations,ordered by score.
Figure 7: Left: Top arch ID rate across test regret threshold groups of the architecture space. Right:Sampling probability mass across test regret threshold groups of the probability space.
Figure 8: Performance of Stage-1 and Stage-2 search algorithm combinations, ordered by decreas-ing score, with benchmark test accuracy plotted in blue on the left axis and score plotted in red onthe right axis.
