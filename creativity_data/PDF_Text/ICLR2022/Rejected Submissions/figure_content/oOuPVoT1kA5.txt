Figure 1: Overview of FEVERLESS.-—— :Source client broadcasts missing IDs, aggregatesgradients and hessians securely, updates model and broadcasts nodes IDs.-—— :DH key ex-change and maskings generation. -——:Noise leader selection. ©Broadcast missing indexes.
Figure 2: Comparison among the baseline, FEVERLESS and LDP under = 2. Top row: Creditcard dataset, accuracy range: [0.5, 0.9]. Middle row: Bank marketing, accuracy range: [0.5, 1].
Figure 3: Comparison of accuracy by varying in depth=10, the number of trees=10. Left: Creditcard. Middle: Bank marketing. Right: Banknote authentication. Accuracy ranges from 0.4 to 1.
Figure 4: Comparison of time. Top row: Credit card dataset, range: [0s, 9,500s]. Middle row: Bankmarketing, range: [0s, 3,500s]. Bottom row: Banknote authentication, range: [0s, 110s].
Figure 5: A differential attack on single node splitFigure 6: A differential attack on multiply node splitsD More details on FEVERLESS protocolD.1 XGBoost Training over Distributed LabelsAt the initial stage, we allow all clients to agree on a tree structure (maximum depth and the numberof trees) and the learning rate for updating prediction. To avoid overfitting problem, we should defineregularization parameters. Threshold impurity is also another vital parameter used to identify treeand leaf nodes via the maximum impurity. After that, we should choose , δ for DP, hash functionfor masking generation and noise leader selection. Besides, we select a multiplicative group G withorder q generated by a generator g and a large prime number p to run DH.
Figure 6: A differential attack on multiply node splitsD More details on FEVERLESS protocolD.1 XGBoost Training over Distributed LabelsAt the initial stage, we allow all clients to agree on a tree structure (maximum depth and the numberof trees) and the learning rate for updating prediction. To avoid overfitting problem, we should defineregularization parameters. Threshold impurity is also another vital parameter used to identify treeand leaf nodes via the maximum impurity. After that, we should choose , δ for DP, hash functionfor masking generation and noise leader selection. Besides, we select a multiplicative group G withorder q generated by a generator g and a large prime number p to run DH.
Figure 7: Comparison of accuracy in depth:10, the number of trees:10, epsilon:10.
Figure 8: Comparison of accuracy in depth:10, the number of trees:10, epsilon:5.
Figure 9: Comparison of accuracy in depth:10, the number of trees:10, epsilon:2.
Figure 10: Comparison of accuracy in depth:10, the number of trees:10, epsilon:1.
Figure 11: Comparison of accuracy in depth:8, the number of trees:8, epsilon:10.
Figure 12: Comparison of accuracy in depth:8, the number of trees:8, epsilon:5.
Figure 13: Comparison of accuracy in depth:8, the number of trees:8, epsilon:2.
Figure 14: Comparison of accuracy in depth:8, the number of trees:8, epsilon:1.
Figure 15: Comparison of accuracy in depth:6, the number of trees:6, epsilon:10.
Figure 16: Comparison of accuracy in depth:6, the number of trees:6, epsilon:5.
Figure 17: Comparison of accuracy in depth:6, the number of trees:6, epsilon:2.
Figure 18: Comparison of accuracy in depth:6, the number of trees:6, epsilon:1.
Figure 19: Comparison of accuracy in depth:8, the number of trees:8, epsilon:5, selection score:1/2.
Figure 20: Comparison of accuracy in depth:8, the number of trees:8, epsilon:2, selection score:1/2.
Figure 21: Comparison of accuracy in depth:8, the number of trees:8, epsilon:5, selection score:1/3.
Figure 22: Comparison of accuracy in depth:8, the number of trees:8, epsilon:2, selection score:1/3.
Figure 23: Comparison of accuracy in depth:6, the number of trees:6, epsilon:5, selection score:1/2.
Figure 24: Comparison of accuracy in depth:6, the number of trees:6, epsilon:2, selection score:1/2.
Figure 25: Comparison of accuracy in depth:6, the number of trees:6, epsilon:5, selection score:1/3.
Figure 26: Comparison of accuracy in depth:6, the number of trees:6, epsilon:2, selection score:1/3.
Figure 27: Comparison of accuracy in epsilon:30. Left:depth:6, the number of trees:6. Mid-dle:depth:8, the number of trees:8. Right:depth:10, the number of trees:10Figure 28: Comparison of accuracy in epsilon:50. Left:depth:6, the number of trees:6. Mid-dle:depth:8, the number of trees:8. Right:depth:10, the number of trees:1034Under review as a conference paper at ICLR 2022H.4 additional results on timeIn Figure 29-33, we show the time performance based on various numbers of client, tree and depth.
Figure 28: Comparison of accuracy in epsilon:50. Left:depth:6, the number of trees:6. Mid-dle:depth:8, the number of trees:8. Right:depth:10, the number of trees:1034Under review as a conference paper at ICLR 2022H.4 additional results on timeIn Figure 29-33, we show the time performance based on various numbers of client, tree and depth.
Figure 29: Comparison of runtime in depth:10, the number of trees:10.
Figure 30: Comparison of runtime in depth:8, the number of trees:8.
Figure 31: Comparison of runtime in depth:6, the number of trees:6.
Figure 32: Comparison of runtime in depth:4, the number of trees:4.
Figure 33: Comparison of runtime in depth:2, the number of trees:2.
Figure 34: Comparison of communication cost on the number of clients.
Figure 35: Comparison of communication cost on depth.
Figure 36: Comparison of communication cost on the number of trees.
