Figure 1: An example computation graph (left) and the corresponding S-graph (right). Shared nodesare ovals, batch nodes are rectangles. The S-graph contains the shared nodes and the input batch node,with an edge between two nodes if a path exists between them in the computation graph that does notpass through other shared nodes. A node in the S-graph computes En f (Dn , S) where (Dn) are thetraining examples and S is a subset of the shared nodes. An edge S â†’ T in the S-graph correspondsto the Jacobian J (S, T ), and the desired gradient of the loss with respect to model parameters isa sum of products of such Jacobians. This work aims to construct better estimates of such sum ofproducts using a minibatch of examples, or a single example.
