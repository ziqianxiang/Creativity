Figure 1: Atom-Coeficient decomposition disentangles spatial convolution and channel mixing. Sothat each feature map after atom convolution now preserves spatial correspondence to the originalimage; and channels that describe important region features, e.g., wings, beak, and tail of a bird,will highly likely be consistently assigned with weights across layers, in order to carry on thosecritical information. Thus, atom coefficients, i.e., weights to linearly combine channels, now becomeshareable across layers to permit a joint subspace view. Such joint subspace view leads naturally toa novel CNN architecture in which the majority of parameters are shared across layers as a commonblock of atom coefficients, with only a few hundred parameters remaining specific to each layer asfilter atoms.
Figure 2: Atom-coefficient filter de-composition. A convolutional kernel Kis decomposed over a set of m 2D fil-ter atoms D linearly combined by atomcoefficients A.
Figure 3: Illustration on how coefficientsare shared across three layers with increas-ing numbers of channels. The shared co-efficients are initialized with the largest di-mensions required.
Figure 4: atom coefficient sharing with three groups at layer n. Theinput feature is first equally divided into groups (denoted as boxeswith different grey scales), each of which is convolved with one groupof filters reconstructed by multiplying the corresponding filter filteratoms and the shared coefficients. The output of three groups are com-bined by channel shuffle.
Figure 5: Few-shot image classification withdeeper CNN architectures. 5W1S and 5W5S de-note 5-way 1-shot and 5-way 5-shot experiments,respectively. Performance (Y-axis) is evaluated byaveraging 3,000 rounds of randomly sampled test-ing tasks.
Figure 6: Accuracy with different number of Figure 7: Accuracy with different atom drop ratefilter atoms m. Parameter sizes are denoted p.
Figure 8: Illustration on extending CAM to all layers (shallow â†’ deep) with standard CNN andACDC-net. While CAM is originally introduced to explain the feature at the final convolutionallayer, we show that sharing coefficients allows CAM to better explain the shallow layers. Thenetwork is progressively extracting features that attend to the discriminative regions, e.g., the wingsor the head of a bird.
Figure A: Comparisons against network compression and pruning methods on CIFAR-10 dataset.
