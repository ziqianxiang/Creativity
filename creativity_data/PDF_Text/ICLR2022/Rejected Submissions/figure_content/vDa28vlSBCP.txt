Figure 1: i/Proto-Trex compared to a post hoc explanation on sentiment classification. The inputquery (top row) is classified (as negative), and three explanations are provided. The first (post hoc)explanation is provided by LIT (Tenney et al., 2020) with LIME (Ribeiro et al., 2016). The intensityof the color denotes the influence of a certain word: Blue (red) color indicates positive (negative)sentiment. Middle and bottom row explanations are provided by (interactive) Proto-Trex networks.
Figure 2: Architecture of the Prototypical-Transformer Explanation Network (Proto-Trex): (a)Sentence-level case uses a transformer to compute sentence-level embedding explanations, while(b) word-level case provides multiple word-level explanations and therefore requires an additionalword-selection layer.
Figure 3: Word selection for word-level Proto-Trex with (a) convolution and (b) attention.
Figure 4: Interactive Prototype Learning: iProto-Trex classifies the input and gives the user anexplanation based on a prototype. The explanation is highlighted in bright blue. If the user isdissatisfied with the given explanation, they can replace it with a self-chosen sequence.
