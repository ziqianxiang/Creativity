Figure 1: (a) Invariance vs. Acc on TUDatasets. While trained models do see an improvement in bothaccuracy and invariance, we see that this improvement in often minimal over an untrained model, suggestingthat GGA augmentations introduce invariance that is not always useful to the downstream tasks; (b) SampleComplexity on TU Datasets. We perform semi-supervised learning on TU Datasets with various amounts oflabeled data. For REDDIT-BINARY, pretraining does not improve sample complexity. GAE/AAGAE haveslightly better complexity than the supervised baseline on IMDB-BINARY. On PROTEINS, pretraining alsodoes not have clear benefits.
Figure 2: Synthetic Dataset Generation. We create a six class, graph classification dataset by first, selectingone of six unique motifs and then injecting 1-3x copies into a randomly generated tree. Here, the motifscompletely determine the class, and are considered “content” (shown in red). To vary the amount of style,the size of the background tree graph (shown in blue) is ratio of the number of “content” nodes. Above areexamples of varying style ratios. Our dataset goes beyond binary, benchmark datasets and allows for content-aware augmentations, a critical component to understanding the maximal performance GCL frameworks.
Figure 3: Effect of Style vs. Content Ratio on Different Paradigms: We evaluate the performance of con-trastive and reconstruction approaches with content preserving and random augmentations as the ratio of stylevs. content changes. As expected, reconstruction methods perform best in low style regimes. While we seethat content aware augmentations improve performance, especially for GCL, in high style regimes, it remainsdifficult to match the supervised performance.
Figure 4: (a) Invariance vs. Accuracy on Synthetic Datasets. We measure the invariance to random aug-mentations, when ρ = 0.5; (b) Sample Complexity on Synthetic Dataset. We perform semi-supervisedlearning when ρ = 1.0 with various amounts of labeled data. GraphCL has considerably better performancethan reconstruction-based methods. Content-aware augmentations are useful for both paradigms.
Figure 5: Motifs used to determine class labels.
