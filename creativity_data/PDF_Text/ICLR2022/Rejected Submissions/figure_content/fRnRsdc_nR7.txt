Figure 1: Left: Visualization of FGSM (Goodfellow et al., 2015), RS-FGSM (Wong et al., 2020)and N-FGSM (ours) attacks. While RS-FGSM is limited to noise in the - l∞ ball, N-FGSM drawsnoise from an arbitrary k - l∞ ball. Moreover, N-FGSM does not clip the perturbation around theclean sample. Middle: Comparison of single-step methods on CIFAR-10 with PreactResNet18 overdifferent perturbation radii ( is divided by 255). Our method, N-FGSM, can match or surpass state-of-the-art results while reducing the cost by a 3× factor. Adversarial accuracy is based on PGD-50-10 and experiments are averaged over 3 seeds. Right: Comparison of training costs relative toFGSM baseline based on the number of Forward-Backward passes, see Appendix K for details.
Figure 2: Left: N-FGSM + Clipping to different radii (∞ means no clipping). As we constraintperturbations by reducing the clipping radius, adversarial accuracy drops. This effect is stronger aswe increase the noise magnitude. Thus, clipping seems to have a negative impact on robustness.
Figure 3: Comparison of single-step methods on CIFAR-100 (left) and SVHN (right) with Preac-tResNet18 over different perturbation radius ( is divided by 255). Our method, N-FGSM, can matchor surpass state-of-the-art results while reducing the cost by a 3× factor. Adversarial accuracy isbased on PGD-50-10 and experiments are averaged over 3 seeds. Legend is shared among plots.
Figure 4: Left: Comparison of Kim et al. (2021) with RandAlpha, our baseline where we multiplythe RS-FGSM perturbation by a value drawn uniformly in [0, 1], on CIFAR-10 and PreActResNet18( is divided by 255). RandAlpha does not incur the extra cost of evaluating intermediate steps anddoes not require hyperparameter tuning. Middle: Ablation of step size α in N-FGSM for = 8. Aswe increase the magnitude of the FGSM perturbation we observe an increase in robustness coupledwith a drop on the clean accuracy. Right: Comparison of the “fast” training schedule from Wonget al. (2020) and “long” training schedule described in Rice et al. (2020). N-FGSM shows robustoberfitting but not catastrophic overfitting with the long schedule. Adversarial accuracy is based onPGD-50-10 and experiments are averaged over 3 seeds.
Figure 5: Comparison of N-FGSM and GradAlign with multi-step methods on CIFAR-10 (Left) andSVHN (Right) with PreactResNet18 over different perturbation radii ( is divided by 255). Despiteall methods achieving comparable clean accuracy (dashed lines), there is a gap in robust accuracybetween PGD-10 and single-step methods. However, note that PGD-10 is 10× more expensive thanN-FGSM. Adversarial accuracy is based on PGD-50-10 and experiments are averaged over 3 seeds.
Figure 6: Comparison of all methods on CIFAR-10, CIFAR-100 and SVHN with PreactResNet18over different perturbation radius ( is divided by 255). We plot both the robust (solid line) and theclean (dashed line) accuracy for each method. Our method, N-FGSM, is able to match or surpass thestate-of-the-art single-step method GradAlign while reducing the cost by a 3× factor. Adversarialaccuracy is based on PGD-50-10 and experiments are averaged over 3 seeds. Legend is sharedamong all plots.
Figure 7: Comparison of single-step methods on CIFAR-10, CIFAR-100 and SVHN withWideResNet28-10 over different perturbation radius ( is divided by 255). Our method, N-FGSM,is able to match or surpass the state-of-the-art single-step method GradAlign while reducing the costby a 3× factor. Moreover, we could not find any competitive hyperparameter setting for GradAlignfor ≥ 6 in SVHN dataset. Adversarial accuracy is based on PGD-50-10 and experiments areaveraged over 3 seeds. Legend is shared among all plots.
Figure 8: Comparison of all methods on CIFAR-10, CIFAR-100 and SVHN with WideResNet28-10over different perturbation radius ( is divided by 255). We plot both the robust (solid line) and theclean (dashed line) accuracy for each method. Legend is shared among all plots.
Figure 9: Monte Carlo estimations of the expected l2 -norm of perturbations from different meth-ods and corresponding analytical upper bounds. As mentioned in Andriushchenko & Flammarion(2020), we observe that RS-FGSM perturbations have lower l2 norm than FGSM. However, N-FGSM perturbations have a significantly higher l2 -norm than both RS-FGSM and FGSM. Thisseems to indicate that the role of random step is not simply to lower the l2 norm as previouslysuggested (Andriushchenko & Flammarion, 2020).
Figure 10: Comparison of Kim et al. (2021) with RandomAlpha, our baseline where we multiply theRS-FGSM perturbation by a scalar uniformly sampled in [0, 1]. We present results on CIFAR-10,CIFAR-100 and SVHN with PreActResNet18.
Figure 11: Training with uniform noise augmented samples improves adversarial accuracy for smallperturbations but is not effective to protect against larger l∞ radius . This motivates us to furtheraugment the noisy samples with FGSM. All experiments are averaged over 3 runs.
Figure 12: Visualization of the loss surface for models trained using different methods. Given aclean sample from the test set in coordinate (0, 0), we compute the FGSM perturbation and evaluatethe loss on the subspace generated by the FGSM perturbation direction and a random direction. Thatis, we evaluate χdean+1_3fgsm +12 ∙ δRandom,where t∖, t? ∈ [0,1]. NOtethatFGSMandRS-FGSMboth have catastrophic overfitting and the final models present a highly non-linear loss surface, onthe Other hand, bOth N-FGSM and GradAlign prOduce final mOdels with a very linear lOss surfacewhich is key tO Obtain meaningful perturbatiOns.
