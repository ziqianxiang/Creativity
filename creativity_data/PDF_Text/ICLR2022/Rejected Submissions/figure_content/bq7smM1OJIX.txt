Figure 1: (Left) Workflow of the research methodology. (Right) Document & word distribution ofICE corpus#Docs = number of documents, #Words = number of words4Under review as a conference paper at ICLR 20223.1	Data CollectionThe main dataset employed in this study is International Corpus of English (ICE) (Greenbaum &Nelson, 1996; Kirk & Nelson, 2018) which comprises of several corpora from different countries.
Figure 2:	(Top) Flat classification strategy setup. (Bottom Left) Sub-category classification setupbased on the Kachru’s concentric circles. (Bottom Right) Sub-category classification setup based onthe geographical distributionDPs/Sub-CategoryTypeDescriptionBased on the Kachru,s TheoryNative vs Non-NativeInnerCountriesOUterVS EXPandedOuter CountriesEXPanded CoUntrieSBinaryMulti-classBinaryMulti-classBinaryBased on the Geographical DistributionAsia vs Non-AsiaSouth Asia vs Nan-
Figure 3:	Identified sub-categories based on Kachru’s Theory and Geographical distribution4	Testing and EvaluationA combination of both ‘hold-out validation’ and k-fold cross-validation was used in order to reducebiasness for training and testing data set (Slotte, 2018). Hence, on the 70% of the training data set,3-fold cross validation technique was used for model building, training and selection and 30% ofthe data was kept for hold-out validation to validate the machine learning model. For each decisionpoint (where a single classifier needs to be selected) 16 experiments (4 ML x 4 n-grams) havebeen carried out. For each ML algorithm, word level (1-1,2,3,4) n-grams were tested. Further,performance accuracy, F1-score, precision and recall were calculated to select the best performingML model.
Figure 4:	(Left) Test Results for the Flat Classification Strategy. (Right) Confusion matrix for theFlat Classification Strategy• Sub-category classification strategyIn sub-category classification, each sub-category can be perceived as a Decision Point (a singleclassifier) in the hierarchy of a decision tree. Figure 5 (Left) depicts the test results of the se-lected ML models for each sub-category. Accuracies of different sub-categories have varied inbetween 0.6224〜1.000 and F1-score ranges between 0.49〜1.00. Based on the KaChru's concentrictheory, lowest F1-Score of 0.71 is for “Outer vs Expanded” sub-category. On the other hand, ‘Ex-panded‘ sub-category (Hong Kong vs Jamaica) has the highest F1-score of 0.92. In geo-graphicaldistribution-based model, lowest F1-score of 0.49 is for “Non-Asia” sub-category, while ‘SouthAsian countries‘ sub-category holding the highest F1-score of 1.0.
Figure 5:	(Left) Test results of the sub-category classification strategy based on selected ML model.
Figure 6: Most significant features of the flat classificationQ2: Which machine learning techniques can gainfully employ the extracted data to identifycountry-of-origin of English writers?Comparison of ML algorithms based on the selected best parameters are analysed on top of the testdata and results are depicted in Figure 7. Linear SVM with SGD optimizer seems to be outper-forms in most cases. Moreover, this behavior is also verified in the previous work by Kulmizevet al. (2017), Koppel et al. (2005), Ekaterina (2011), Gebre et al. (2013), Bykh & Meurers (2012).
Figure 7: Performance comparison of each ML techniqueOur work on Ethno-nationality Identification confirms that linear SVM with SGD optimizer trainedwith word n-grams can yield a higher level of performance. When determining country-of-originit is essential to identify set of features which are unique to each author or a particular group ofauthors.
