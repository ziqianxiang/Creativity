Figure 1: Examples of (i) crisp and (ii) soft equiv-alents of a labeling function to characterize nor-mal clinical findings in EEG data. While both ver-sions make identical predictions, the latter is dif-ferentiable with respect to its decision parameter,high-baseline.
Figure 2: Knowledge shift experiments on the (i) heart disease and (ii) synthetic datasets. Theaccuracy of end models increases with more active learning iterations as WARM adapts LFs and theresulting label model to the target population.
Figure 3: (i): End model testing accuracy on the Wisconsin Diagnostic Breast Cancer dataset asa function of uniform random noise and active learning iterations. With a few expert-labeled datapoints WARM can effectively de-noise LFs to eventually improve end model performance. (ii): Plotof the synthetic dataset and its three LFs before and after 30 active refinement iterations. WARMsupports interpretability by allowing experts to track changes in LFs.
Figure 4: An example aEEG waveform (T = 21600 seconds). Each alternating pink and grey regionmarks an one-hour segment. The dashed red line represents baseline aEEG value determined usingrobust linear regression (aka RANSAC (Fischler & Bolles, 1981)).
Figure 5: Active weak supervision runtimes (in seconds on log scale). WARM is significantly fasterthan compared existing methods across all datasets.
Figure 6:	Results of label model predictionsmeasure of training set quality.
Figure 7:	Results of the logistic regression end model evaluated on the testing dataset. datasets.
