Figure 1: (a-d) Risk and adversarial risk of adversarially trained linear Classifiers versus the di-mension d under different scalings of μ. (a)(b) show the results for '2 perturbation with e = 0.1and (c)(d) show the results for '∞ perturbation with e = 0.01. (e-f) Adversarial risk of adversariallytrained linear classifiers versus the training iterations t for different e with d = 200 and ∣∣μk2 = d0.3.
Figure 2: Risk and adversarial risk of adversarially trained linear classifiers versus the trainingiterations t for different perturbation level . The label noise level is set as η = 0.1, the training setsize n = 50, dimension d = 200 and ∣∣μ∣∣2 = d0.4. The train error reaches 0 for all experiments.
Figure 3: Risk and adversarial risk of adversarially trained linear classifiers versus the trainingiterations t for different perturbation level . The label noise level is set as η = 0.1, the training setsize n = 50, dimension d = 1000 and ∣∣μ∣∣2 = d0.3. The train error reaches 0 for all experiments.
Figure 4: Risk and adversarial risk of adversarially trained linear classifiers versus the trainingiterations t for different perturbation level . The label noise level is set as η = 0.1, the training setsize n = 50, dimension d = 1000 and ∣∣μ∣∣2 = d04. The train error reaches 0 for all experiments.
Figure 5: Risk and adversarial risk of adversarially trained 2-layer ReLU network versus the di-mension d under different scalings of μ. (a)(b) show the results for '2 perturbation with e = 0.1and (c)(d) show the results for '∞ perturbation with e = 0.01. The training error reaches 0 for allexperiments.
