Figure 1: 1. The training/test loss on CIFAR-100. With the teacher size grows, the loss of ATKDincreases slower than KD, which shows that ATKD alleviates the Degradation Performance Problem.
Figure 2: 1) The ResNet20 accuracy plot during training 2) The ResNet20 sharpness gap plot duringtraining. 3) The WRN-16-1 accuracy plot during training 4) The WRN-16-1 sharpness gap plotduring trainingTable 11: Experiments on SVHNTeacher acc		ResNet20 96.40	ResNet32 96.68	ResNet44 96.73	ResNet56 96.89Test acc	Vanilla KD	96.57	96.54	96.61	96.59	ATKD	96.70	96.83	96.73	96.77G s_gap	Vanilla KD	0.05	0.05	0.07	0.07	ATKD	0.03	0.04	0.04	0.04Where pj is the jth class probability of the student and the qj is the probability of the teacher. Wecan get the gradient to P zj by adding these gradients:∂LX 豆=X (Pj- qj ) = 1-1 = 0	(17)jjjTherefore, the gradient to the sum of logits is zero.
