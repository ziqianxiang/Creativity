Figure 1: The candidate perturbation δ0 (red dots) generated by gradient ascent in various attacks,namely FGSM-RS and PGDk, where k denotes the number of iteration for PGD. For simplicity, wenormalize the perturbation into [-1, 1] and do not consider the hyper-parameter α.
Figure 2: The sign consistency for PGD50 on Fast-AT atvarious epochs on CIFAR-10 (left) and Tiny ImageNet (right),where Fast-AT-k denotes the model trained at k-th epoch. Theresults are averaged over 3 random seeds used for training andreported with the standard deviation. The high and stable signconsistency at various epochs makes it possible for imitation.
Figure 4: The (a) mean absolute value of perturbation ∣δ∣ (normalized into [0, e]), (b) robust accuracy, and (c)the epoch when catastrophic overfitting occurs over various step size α for Fast-AT-U and Fast-AT-S. Initially,catastrophic overfitting does not happen and increasing ∣δ∣ leads to better robustness. However, if catastrophicOVefitting occurs, increasing ∣δ∣ will boost catastrophic OVerfitting.
Figure 3: The robustness against FGSM (dashed line) and PGD10(solid line) of Fast-AT and I-PGD2-AT over different trainingepochs with two different learning rate schedulers evaluated onrandomly sampled 10% CIFAR-10 testset. The learning rate sched-ulers, namely Cyclic Learning Rate (CLR, left) and Cyclic LearningRate followed by Piecewise Learning Rate (CPLR, right), are shownin the left upper corner in the corresponding figures. The red lineand blue line denote the performance of Fast-AT and I-PGD2-ATtrained over 60 epochs.
Figure 5: The robust accuracy (%) againstPGD10 attack over the training epochs forPGD2-AT, PGD4-AT and I-PGD2-ATPGD2.
Figure 6: The robust accuracy (%) of I-PGD2-AT on CIFAR-10 against PGDk andI-PGDk attacks where k denotes the num-ber of iteration.
