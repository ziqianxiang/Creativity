Figure 1: FoveaTer architecture: Solid black arrows denote the flow of image-related features. Thefoveation module performs fixation-dependent pooling, on the full-resolution features ([192, 14, 14])output of the convolution backbone, resulting in pooled feature vectors ([192, 29]). During training,a random location in the image serves as the initial fixation. Accumulator uses the attention weightsfrom the last transformer block to predict the next fixation location. The Average-pooling layer takesthe feature vector corresponding to the class token as input from each past fixation, followed by afinal classification layer.
Figure 2: Foveation module: Inputs to the module are aligned to the visual field and are zero-paddedto have the same size as the visual field. We pool the input features according to the pre-definedpooling neighborhoods in the visual field, resulting in one feature vector for each of the 49 poolingregions in the visual field, colored blocks in the visual field figure correspond to the centers of these49 pooling regions. After ignoring the pooling centers falling in the padded region instead of on theoriginal image, the remaining pooled features are zero-padded to a constant sequence length of 29.
Figure 3: Fixation sequences and Average fixations per classFGSM attackPGD attackEpsilonEpsilonFigure 4: Adversarial robustness: Comparison of Foveated model (with guided fixations and twodifferent initial fixations, RD - initial random fixation. CT - initial fixation at the image center),a foveated model that makes the same fixation sequence for every image (Foveated model withstatic fixations), and the Full-resolution model. Epsilon represents the strength of the attack. As thestrength of the attack increases the accuracy of the Foveated model with guided fixations accuracy isgreater than the Foveated model with static fixations while the Full-resolution model has the lowestaccuracy. Raw values are available in Table 5 in Appendix.
Figure 4: Adversarial robustness: Comparison of Foveated model (with guided fixations and twodifferent initial fixations, RD - initial random fixation. CT - initial fixation at the image center),a foveated model that makes the same fixation sequence for every image (Foveated model withstatic fixations), and the Full-resolution model. Epsilon represents the strength of the attack. As thestrength of the attack increases the accuracy of the Foveated model with guided fixations accuracy isgreater than the Foveated model with static fixations while the Full-resolution model has the lowestaccuracy. Raw values are available in Table 5 in Appendix.
Figure 5: Additional task to determine the effectiveness of guided fixations6 Appendix6.1	Ablation studies6.1.1	Ablation study 1: Attention MechanismObjects in the ImageNet dataset occupy a high percentage of the image area resulting in a dimin-ished difference between guided and random fixations. In order to illustrate the performance of theattention mechanism, we create this small extension task.
Figure 6: Model Comparison: Down-sized images are present at the top-left corner, and initialfixation is set at the bottom-right corner. Models with more periphery rings outperform the modelswith less number of periphery rings.
Figure 7: What the model sees: Each row contains five images that correspond to the five fixationson a single image. Left-most is the original image with the ground-truth (GT) class.
Figure 8: Relationship between image entropy and the number of fixations made by the FoVeatedmodel with Dynamic-stop. Pearson correlation coefficient computed for each class separately, andthe histogram displays the distribution of correlation coefficient Value across classes.
