Figure 1: We fine-tune for 3 epochs the WideResNet-70-16 on CIFAR-10 from Gowal et al. (2020)with highest l∞-robustness to be either robust wrt l1 (left) or with our E-AT to be robust wrt to theunion of the l∞-, l2-, and l1-threat models (right). We achieve state-of-the-art results in both threatmodels. The plots show the robust accuracy in the individual threat models and in their union for theinitial l∞-robust classifier (middle) and the fine-tuned ones, with the target threat model highlighted.
Figure 2: Visualization of the l2-ball contained in the union resp. the convex hull of the union of l1-and l∞-balls in R2. First: co-centric l1-ball (blue) and l∞-ball (black). Second: in red the largestl2-ball contained in the union of l1- and l∞-ball. Third: in green the convex hull of the union of thel1- and l∞-ball. Fourth: the largest l2-ball (red) contained in the convex hull. The l2-ball containedin the convex hull is significantly larger than that in the union of l1- and l∞-ball.
Figure 3: l2-robustness curve of a model trained with l2-adversarial training (AT) for 2 = 0.5(orange) versus our E-AT (blue), which is expected to yield robustness at 2 = 0.62. Although l2-attacks are not used for training, our extreme-adv. training scheme E-AT yields l2-robustnesssimilar to the one obtained with specific l2-adversarial training.
Figure 4: CIFAR-10, ResNet18. Left: For MAX-training we show for each epoch during trainingthe percentage of points attaining for the indicated lp-threat model (p ∈ {1, 2, ∞}) the highest lossover the the three threat models. Right: For MSD-training we show the percentage of steps takenwrt each threat model over epochs (note that MSD does the steepest descent step for each lp-threatmodel and then realizes the one yielding maximal loss).
