Figure 1: We scale up out-of-distribution detection to large-scale multi-class datasets with thousandsof classes, multi-label datasets with complex scenes, and anomaly segmentation in driving environ-ments. We introduce new benchmarks for all three settings. In all of these settings, we find that anOOD detector based on the maximum logit outperforms previous methods, establishing a strong andversatile baseline for future work on large-scale OOD detection. The bottom-right shows a scenefrom our new anomaly segmentation benchmark and the predicted anomaly using a state-of-the-artdetector.
Figure 2: The Species out-of-distribution dataset is designed for large-scale anomaly detectorspretrained on datasets as diverse as ImageNet-21K. When models are pretrained on ImageNet-21K,many previous OOD detection datasets may overlap with the pretraining set, resulting in erroneousevaluations. To rectify this, Species is comprised of hundreds of anomalous species that are disjointfrom ImageNet-21K classes and enables the evaluation of cutting-edge models.
Figure 3: Small-scale datasets such as CIFAR-10 have relatively disjoint classes, but larger-scaledatasets including ImageNet-1K have several classes with high visual similarity to other classes. Thisimplies that large-scale classifiers disperse probability mass among several classes. If the predictionconfidence is used for out-of-distribution detection, then images which have similarities to otherclasses will often wrongly be deemed out-of-distribution due to low and dispersed confidence. Thismotivates our MaxLogit out-of-distribution detector.
Figure 4: A sample of anomalous scenes from the CAOS benchmark with model predictions andanomaly scores. The anomaly scores are thresholded to the top 10% of values for visualization. GTis ground truth, the autoencoder model is based on the spatial autoencoder used in Baur et al. (2019),MSP is the maximum softmax probability baseline (Hendrycks & Gimpel, 2017), and MaxLogitis the method we propose as a new baseline for large-scale settings. Compared to baselines, theMaxLogit detector places lower scores on in-distribution image regions, including object outlines,while also doing a better job of highlighting anomalous objects.
Figure 5: Auxiliary analysis of the MSP andthe MaxLogit AUROCs using prior less com-prehensive anomaly segmentation datasets.
Figure 6: ROC curve with VOC as (Din)and non-overlapping ImageNet classes as(Doteustt). Curves correspond to an uninfor-mative “Random” detector, Local OutlierFactor, and the MaxLogit detector.
Figure 7: A comparison of lighting consistency inthe Fishyscapes anomaly segmentation benchmarkand our new StreetHazards dataset. The arrowspoint in the manually estimated direction of lighton parts of the scene. In Fishyscapes, inconsis-tent lighting allows forensics techniques to detectthe anomaly (Johnson & Farid, 2005). Unlike cut-and-paste anomalies, the anomalies in our Street-Hazards dataset are naturally integrated into theirenvironment with proper lighting and orientation,making them more difficult to detect.
