Figure 1: Configuration of a shallow network. This network is designed to evaluate the effectivenessof SA in the field of network pruning. In order to keep things simple, only the edges in hidden layerswill be pruned.
Figure 2: The comparison between three cases from 2 different datasets: original network, one-shotpruned and trained network, and gradual pruned and trained network. Each result is obtained bycomputing the mean of 5 independent and identical experiments.
Figure 3: The histogram of total weight parameters under the process of gradual pruning usingmin - K strategy as p = 10%. It will always determine those weights which has lowest absolutevalue.
Figure 4: The histogram of total weight parameters under the process of gradual pruning followed byAlgorithm 1 as p = 10%. Those less effective weights will be determined by simulated annealingalgorithm iteratively.
Figure 5: Performance changes under various pruning percentage and different permutation strate-gies. The network is well trained by MNIST dataset.
Figure 6: Performance changes under various pruning percentage and different permutation strate-gies. The network is well trained by FASHION dataset.
Figure 7: The trends of network performance being pruned at various scales gradually. The networkis well trained and fine-tuned by MNIST dataset.
Figure 8: The trends of network performance being pruned at various scales gradually. The networkis well trained and fine-tuned by FASHION dataset.
