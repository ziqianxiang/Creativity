Figure 1: The approximate locations of MDand the Language systems in the humanbrain. The regions depicted are used as astarting point to functionally localize thesesystems in individual participants.
Figure 2: Overview. The goal of this work is to relate brain representations of code to (1) specificcode properties and (2) representations of code produced by language models trained on code. InExperiment 1, we predict the different static and dynamic analysis metrics from the brain MRIrecordings (each of dimension DB) of 24 human subjects reading 72 unique Python programs (N)by training separate linear models for each subject and metric. In Experiment 2, we learn affinemaps from brain representations to the corresponding representations generated by code languagemodels (each of dimension DM) on these 72 programs.
Figure 3: In Experiment 1, a linear model is trained on brain representations to predict each of thecode properties described in Section 4.2. Error bars represent 95% confidence interval of individualsubject scores. Dotted lines signify the empirical baseline for a null permutation distribution onshuffled labels. All results were compared to this permuted null distribution, and p-values for thenumber of comparisons in this experiment were corrected for false discovery rates (FDR). Statisti-Cally significant results are denoted with a *, marked at the base of the bars.
Figure 4: In Experiment 2, an affine map is learned from brain representations to the representationsproduced by machine learning models. Error bars represent 95% confidence interval of individualsubject scores. Dotted lines signify the empirical baseline from a null permutation distribution onshuffled labels. Random embedding is an aggressive baseline of using random but unique embed-dings for vocabulary tokens. Statistically significant results are denoted with a *, marked at the baseof the bars.
Figure 5: Mapping MD and LS to codemodel representations.
Figure 6: An example of a code problem and its sentence equivalent from Ivanova et al. (2020)The inter-correlations between these metrics have been tabulated in Table 18, Appendix G.
Figure 7: Sensitivity of brain representation mapping to model output dimensions. Each subplotcontains the decoding results from a given brain network, and each line reflects a unique code modelacross a range of controlled embedding dimensions.
