Figure 1: Illustration of the evolution process of source and target feature distributions. SourceOnly: feature distributions obtained by the model without domain adaptation. DA: aligned fea-ture distributions after domain adaptation. DA+Ours: refined feature distributions by applying ourapproach to the DA model. Compared to Source Only, DA reduces the domain gap and exploresthe domain-invariant features by adversarial training at the cost of discriminative features in sourceand target domain. Our supplementary framework highlights the target-like discriminative feature,which leading to better adaptive performance.
Figure 2: The Overview of our proposed adaptation framework. The main components of ourmodel are DAdaIN, GSA and LCA. DAdaIN is inserted into the backbone network, which providesmore domain-specific details through feature reconstruction. GSA consists of two sub-modules,i.e., Style Similarity Regularize and Style Consistency Regularize. They constrain the similarityand consistency of global image style to improve the robustness of the model. LCA highlights theimportance of local instance content, and achieves the alignment without destroying domain-specificdetails.
Figure 3: Analysis of discriminative feature and hyper-parameter on multi task.
Figure 4: Qualitative detection results on the target domain. First and second rows: Normal→Foggyadaptation scenario. Third and fourth rows: Sim10K→Cityscapes adaptation scenario.
Figure 5: The t-SNE visualization of image features obtained from different models. Colors repre-sent different models. We can see that the difference of feature distribution is further optimized.
Figure 6: Visualizations of shallow features and statistics obtained from different models. ”Sourceonly” denotes the baseline model trained and tested only in source domain without adaptation. ”Tar-get only” represents the model trained and tested in target domain without adaptation. And ”Mine”represents the model trained with our proposed method. It should be noticed that, when testing ourmethod, we retain the DAdaIN module and extract the synthesis feature in intermediate domain tocompare the feature distributions with source and target domain. First Row: The statistics of shal-low features. Second Row: The shallow features obtained by applying global average pooling tothe shallow features. Each column (from left to right) represents the model trained on Cityscape toFoggy Cityscapes, SIM10K to Cityscape, PASCAL VOC to Clipart, PASCAL VOC to Watercolor.
Figure 7: Qualitative detection results on the target domain. First and second rows: PASCALVOC→Clipart adaptation scenario. Third and fourth rows: PASCAL VOC→Watercolor adaptationscenario.
