Figure 1: Skew in distributions of Class Cardinality or Class Importance, and the potential mismatchbetween them render existing accuracy metrics unusable in general multi-class prediction problems.
Figure 2: WBA vs. class-insensitive & class-sensitive metrics for log parsing: F1-Score & Accuracyagree in all. BA & WBA agree in (c) & (d) only. WBA disagrees with class-insensitive in all.
Figure 3: Amazon resultsin classification, as it favors the RNN model which is heavily biased by the majority class (seeAccuracyi for RNN in Table 2 where class 5 scores 0.96). (ii) The frequency-sensitive BA met-ric finds all models perform similarly. WBA(user), in contrast, identifies LSTM as the best model.
Figure 4: Histograms showing the relative frequencies of log parsing classes for the four experimen-tal datasets: All graphs have their y-axes in log scale; green bars show the infrequent classes.
Figure 5: Misclassification count of three different algorithms on the macOS dataset. x-axis isranked in descending order of class frequencies, as in Figure 4a. Drain performs best on rare classes(right side), which aligns with the WBArarity ranking shown in Figure 2a.
Figure 6: Misclassification count of three different algorithms on the BGL dataset. x-axis is rankedin descending order of class frequencies, as in Figure 4b. MoLFI performs best on rare classes (rightside), which aligns with the WBArarity ranking shown in Figure 2b.
Figure 7: Misclassification count of three different algorithms on the Android dataset. x-axis isranked in descending order of class frequencies, as in Figure 4b. Spell performs best on rare classes(right side), which aligns with the WBArarity ranking shown in Figure 2c.
Figure 8: Histogram showing the relative frequencies of the five customer rating classes for theAmazon dataset (skew = 2.140).
