Figure 1: (a) A more visual illustration of the difference between regression and classification withregard to their sensitivity to noise. When noise is imposed, the left image suggests a greater changewith augmented data for regression model. The right image remains cat predicted under the sameslight perturbation. It reveals the discrepancy between the sensitivity of regression and classificationto noise (b) Concepts of similarity and dissimilarity in regression. The right images indicate thatafter adding noise to the input image, the difference between the age predicted by the augmentedimage and the original one is less than the threshold δ, so they are considered as similar samples, onthe contrary, the difference between the two images on the left is greater than δ, they are thereforerecognized as dissimilar samples.
Figure 2: (a) Mean Square Error with different imbalanced coefficients. Very clearly itis observed thatunder supervised learning, MSE grows as the imbalanced coefficient increases, contrary to the SSLcase where MSE is considerably smaller with the same imbalanced coefficient. (b) A demonstrationof the impact of noise generation on the regression values, when adding random noise to the originalimage, the difference between the output value of noisy image versus such a component of theoriginal image will most likely exceed the threshold.
Figure 3: (a) Parameter study of FOCAL-R + SSIR on AgeDB-DIR dataset, for a fixed value of λ,we vary the value of . (b) Original outputs and noisy outputs of samples from AgeDB-DIR dataset.
Figure 4: Three groups of noisy samples generated from three samples chosen from AgeDB-DIRdataset with different .
Figure 5: (a) Training and validation loss w.r.t training epochs of SQINV + SSIR on IMDB-WIKI-DIRdataset. (b) Training and validation loss w.r.t training epochs of FOCAL-R + SSIR on IMDB-WIKI-DIR dataset. (c) Training and validation loss w.r.t training epochs of SQINV + SSIR on AgeDB-DIRdataset. (d) Training and validation loss w.r.t training epochs of FOCAL-R + SSIR on AgeDB-DIRdataset.
Figure 6: Visualization of variance values of deep learning features on the IMDB-WIKI-DIR testingdataset for the VANILLA, SQINV and SQINV+SSIR methods. We compare the three methods on allbins, many-shot bins, middle-shot bins and few-shot bins respectively. SQINV+SSIR owns a smallervariance σ, which implies more balanced features are leaned.
Figure 7: Visualization of variance values σ of deep learning features on the IMDB-WIKI-DIR testingdataset for the VANILLA, SQINV and SQINV+sSiR methods on different bins. The three subfiguresfrom the top to bottom correspond in turn to VANILLA, SQINV and SQINV+SSIR methods.
