Figure 1: An iteration of SMB on a simple quadratic function. For simplicity we assume that thereis only one parameter group, and hence, we drop the subscript p . The algorithm first computes thetrial point xtk by taking the stochastic gradient step stk. If this point is not acceptable, then it buildsa model using the information at xk and xtk, and computes the next iterate xk+1 = xk + sk. Notethat sk not only have a smaller length compared to the trial step stk, but it also lies along a directiondecreasing the function value.
Figure 2: Classification on MNIST with an MLP model.
Figure 3: Classification on CIFAR10 (a, b) and CIFAR100 (c, d) with ResNet-34 model.
Figure 4: Classification on CIFAR100 with DenseNet-121 model.
Figure 5: Performances of SMB and SMBi with auto-scheduled stepsizes on CIFAR10.
Figure 6: Robustness of SMB under different choices of the learning rate.
