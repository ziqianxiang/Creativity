Figure 1: Framework of ClsVC. Z is the latent variable, which is divided into two parts, namely CXand SX . Here, we assume that CX represents content information, which is speaker independent,and SX represents speaker information, which is closely related to speaker identity.
Figure 2: Three different case of disentangle different parts. Here Z are the latent variable outputfrom the input speech, Cx denote the estimated content embedding and Sx refer to the estimatedspeaker embedding, both Cx and Sx are a part of the latent variable Z, in addition, x0 is thereconstruct speech and zb are regarded as reconstruct latent variable. zb = E(x0) . Whether Cx andSx are properly selected may lead to the above three different situationsWhere α , β, and λ refers to the weight of Lcode-recon, Lcom-cls , and Ladv-cls respectively. With thisobjective loss function, an ideal case as Figure 2(c) will eventually appear. Specifically, in this case,two important assumptions will be met.
Figure 3: Results of fake speech detection. The prediction threshold in our test is 0.84(b) Female to Male conversionThe experimental results support our conclusion, for both same-gender VC (Female to Female) andcross-gender VC (Female to Male), our ClsVC always outperforms other baseline models. All theseobjective and subjective experiments show that ClsVC is a state-of-the-art framework for VC underboth traditional and one-shot conditions.
Figure 4: Results of ablation experiment. 1:ClsVC; 2:ClsVCs; Same: same-gender conversion;Cross: cross-gender conversion;4.4	Dimensions of two parts of latent variableHere we will discuss how to devide the content embedding Cx and speaker embedding Sx fromthe latent space Z. In AutoVC, it is important to select the size of bottleneck carefully to make theestimated content embedding contain all content information but have no timbre information. Butin our model, as we discussed before, no matter how we divide it, the first part of Z tends to be theideal content embedding, and the second part tends to be the ideal speaker embedding. In this case,we can determine the dimensions of Cx and Sx at will and it will be very convenient for us to getcontent embedding and speaker embedding with only one encoder.
Figure 5: The visualization of speaker embedding. None of these speaker appeared in training.
