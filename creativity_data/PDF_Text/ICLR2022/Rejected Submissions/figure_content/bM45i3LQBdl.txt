Figure 1: Impact of the batch size and aggregationrule on the cross-accuracy of DP-SGD against thelittle (Baruch et al., 2019) attack on Fashion-MNIST.
Figure 2: Maximum top-1 cross-accuracy reached on Fashion-MNIST when only varying the batchsize b for different threat scenarios and different GARs. The first and second rows show the little andempire attacks respectively. The first and second columns display f = 6, = 0.05 and f = 3, = 0.2respectively. All reported metrics include a standard deviation obtained with the 5 consecutive runs.
Figure 3: Impact of the batch size on the cross-accuracy of the learning on Fashion-MNIST in thenon-private scenario. The first and second rows show the little and empire attacks respectively. Thefirst and second columns correspond to f = 6 and f = 3 Byzantine nodes respectively.
Figure 4: Impact of on the cross-accuracy of the learning on Fashion-MNIST for b = 1000. Thefirst and second rows show the little and empire attacks respectively. The first and second columnscorrespond to f = 6 and f = 3 Byzantine nodes respectively.
Figure 5: VN ratios for MDA and b = 1000, under the same settings (and layout) as in Figure 2.
