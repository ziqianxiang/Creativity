Figure 1: Schematic diagram of our approach. On the left is our standard training stage. Theinput image undergoes a series of deep neural network units, for example, convolution, ReLU, batchnormalization, etc., until the final softmax layer outputs the decision probability. Each input imagewill produce corresponding feature maps. In addition to the usual classification loss, we introducethe feature smoothing loss to constrain the intermediate feature space. On the right is our ActiveDefense stage. In total, there are four steps. In Step 1, some random noise is injected into the input.
Figure 2: Training/Test accuracy (on the left) and Feature Loss (on the right) for CIFAR-10.
Figure 3: Training/Test accuracy (on the left) and Feature Loss (on the right) for CIFAR-100.
Figure 4: The top half is a plane from CIFAR-10. In the first row, from left to right, we demonstratethe clean and adversarial images generated via APGDce andAPGDdTlr, and the corresponding featuremap in channel 7. The second and third rows are the noise-perturbed and after Active Defenseones, respectively. The second half is arranged similarly except that the feature channel is 26. Ourstandard training model assigns each image a label shown underneath it. The feature maps showstrong distortions by adversarial attacks and our intentionally added noise, which can be somehowrestored by our Active Defense.
Figure 5: The top half is a pear from CIFAR-100. In the first row, from left to right, we demonstratethe clean and adversarial images generated via APGDce andAPGDdTlr, and the corresponding featuremap in channel 43. The second and third rows are the noise-perturbed and after Active Defense ones,respectively. The second half is arranged similarly except that the feature channel is 33. Our standardtraining model assigns each image a label shown underneath it. We can see the similar destructionsand restorations as in Figures 4. Moreover, comparing with the clean image, the lobsters in featuremaps are much more integrated in the last row.
