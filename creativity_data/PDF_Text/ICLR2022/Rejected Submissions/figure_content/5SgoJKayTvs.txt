Figure 1: The structure of our modelThe key distinction of our model from AAE is the intervention loss. More specifically, when encodedlatent z = E(x) is obtained, for every k, 0 ≤ k ≤ t, we intervene z by Tk to get zk . Then we feedzk into the discriminator to obtain a t + 1 size output d, and compute the cross entropy between dand labels ek, averaging on k, finally to update discriminator by gradient flow. The encoder updatein the same manner.
Figure 2: We train the model for 50 epochs. Left: AAE; Right: IVAAE (t = 4, block-wise). Thenwe fix the encoder and decoder to run the discriminator alone. We record the loss change everyiteration. The dimension of latent space is chosen at 16, 32, 64.
Figure 3: We choose the latent dimension at 16 and run models for 50 epochs. Then we recordthe change of encoder’s gradient with the encoder and decoder fixed. Note that Ladv (E, D) =-E[log(D(E(x)))] is used as the encoder loss.
Figure 5: MNIST classification error rate for methods WAE-GAN, IVAAErad, IVAAEsvgd. Param-eters of the encoder is fixed after pretrained.
Figure 6:	Heat maps for covariance matrix of the encoded z for different models when converging.
Figure 7:	CelebA images randomly generated. Left: WAE-GAN; Mid: IVAAEbw ; Right:IVAAErad.
