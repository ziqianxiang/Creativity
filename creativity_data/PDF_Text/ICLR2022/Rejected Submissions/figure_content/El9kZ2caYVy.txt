Figure 1: Ability to separate correct andincorrect predictions based on the pre-dictive entropy on CIFAR-10: misclassi-fication rate under rejection of uncertainhigh-entropy examples and the area un-der the resulting curve. Models trainedwith explicit output distribution regular-ization perform substantially worse thana deterministic network. Plain varia-tional information bottleneck networks(VIBN) show a similar tendency.
Figure 2: Embeddings and samples from the latent prior (a) and assigned predictive entropy (b) fora NC-VIBN model with a two-dimensional information bottleneck trained on CIFAR-10. Darkerareas correspond to lower entropy. By employing the proposed noise-contrastive loss, embeddings ofincorrectly classified examples, which are harder to distinguish from samples of the latent prior, areassigned higher entropy, allowing for a better separability of correct and incorrect predictions basedon the predictive entropy.
Figure 3: Calibration curves for the deter-ministic, VIBN, and NC-VIBN networks onCIFAR-10. For our NC-VIBN, confidenceand accuracy are better aligned.
Figure 4: Embeddings and samples from the latent prior (a) and assigned predictive entropy (b) fora VIBN model with a two-dimensional information bottleneck trained on CIFAR-10. Darker areascorrespond to lower entropy.
Figure 5: Relative densities of the empirical predictive entropy distribution of correct and incorrectpredictions for a deterministic, VIBN, and NC-VIBN network on CIFAR-10.
