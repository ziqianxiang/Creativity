Figure 1: Illustration of steps to compute the spatial frequency sensitivity with respect to a singleinput image. The input-Jacobian of the model is Fourier-transformed to obtain sensitivities withrespect to frequency components followed by computing the proportion of power in low to high(small to large radius) frequency bands.
Figure 2: Computation graph to obtain the input-Jacobian in Fourier-space. The symbols in redrepresent an implicit map of the input from Fourier-space to the standard input space. The dashedarrows denote the backward graph operations to compute the input-Jacobian in Fourier space.
Figure 3: SFS of ResNet50 models trained by methods on CIFAR10 and ImageNet. Computed on1k randomly selected samples from respective validation sets. The shaded region represents twostandard deviations.
Figure 4: Examples (b): CIFAR10 Fourier-filtered (Section 4.2) (c): CIFAR10 Patch-shuffled(Section 4.5). (e) - (g): Fourier-noise distortions on SVHN (Section 4.3). More in Appendix.
Figure 5:	a) Illustration of the power-matrix P of the Fourier-transformed input-Jacobian. PT otal,the power in all components excluding the zero-frequency component is used to normalize the pro-posed SFS of the model at a particular input. b) LSF (purple), MSF (blue) and ASF (purple, blueand green) frequency bands used for spatial frequency regularization. Best viewed in color.
Figure 6:	Letters at multiple spatial scales. This image comprises the letters o, n, E and F at a smallspatial scale (HSF). The letter T is also visible at a larger spatial scale (LSF) formed by the specificarrangement of the letters o, n amidst letters E, F. Identifying these letters requires processing fea-tures at multiple scales, enabled by distinct spatial frequency channels in the early visual cortex. Ourability to recognize only one of these scales at a time is evidence for the physiological independenceof spatial frequency channels in the brain. Image based on Julesz & Papathomas (1984).
Figure 7:	Spatial frequency sensitivities of popular ImageNet architectures after standard trainingand adversarial training using PGD-'2 (e = 3) attacks. The SFS is consistent across architecturesfor both standard and adversarially trained models although VGG16 shows increased sensitivity tohigh frequencies. The shaded region represents two standard deviations.
Figure 8: Various methods trained on CIFAR10 (left) and CIFAR100 (right). The shaded regionrepresents two standard deviations.
Figure 9: Various methods trained on SVHN. The shaded region represents two standard deviations.
Figure 10: Spatial frequency sensitivities of ResNet50 models trained on the CIFAR10 trainingset distorted by corruptions derived from the CIFAR10-C (severity 5) dataset. The shaded regionrepresents two standard deviations.
Figure 11: First image in each row is the mask in Fourier space (lowest frequency at centre). Whitepixels preserve and black pixels set Fourier components to zero. Top row are original CIFAR10images, other rows are Fourier-filtered with different radial masks.
Figure 12: For band-pass Fourier-filtering CIFAR10 training images, we filtered Fourier-coefficientsin each color channel separately. For low-pass filtering, Fourier-coefficients with radial distancer(u, v) > 5 were set to zero. For medium-pass filtering, Fourier-coefficients with r(u, v) <5 and r(u, v) > 10 were set to zero. In high-pass filtering, Fourier-coefficients with r(u, v) < 10were set to zero. Images contast-maximised for viewing.
Figure 13: (CIFAR10) Heat map of error rates for each Fourier-mode corruption. Each pixel in theheat map is the error of the model when the corresponding Fourier-mode noise ( = 4) is added to theinputs. The bottom row displays example images containing the corresponding Fourier-corruption.
Figure 14: (SVHN) Heat map of error rates for each Fourier-mode corruption. Each pixel in the heatmap is the error of the model when the corresponding Fourier-mode noise ( = 4) is added to theinputs. The bottom row displays example images containing the corresponding Fourier-corruptions.
Figure 15: Examples of image corruptions curated by Hendrycks & Dietterich (2019) to evaluaterobustness of vision models.
Figure 16: Patch-shuffling: Images are partitioned into squares whose positions are randomly ex-changed. This operation destroys global structure in the image and is used to evaluate the extent towhich a model relies on global information.
