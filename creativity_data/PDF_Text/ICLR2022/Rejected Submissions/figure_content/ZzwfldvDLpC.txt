Figure 1: (Left) Multilingual cardiac signal captioning pipeline. We feed a 12-lead ECG intoan encoder, fθ , to extract representations, v. These are fed, alongside embeddings, e, of tokensfrom a particular language, to a decoder, gφ , to generate token representations, h. We feed h into alanguage-specific head, pωl, to generate a caption in a specific language. (Right) Replaced tokenlanguage prediction framework. We randomly replace source tokens with those from a targetlanguage and task the network with classifying the language of all tokens. In doing so, we encouragethe network to capture relationships between representations of tokens from different languages.
Figure 2: 12-lead ECG, multilingual ground-truth reports, and those generated by RTLP andMLM. We show some phrases in bold which exhibit a high level of agreement in both the ground-truth report and that generated by RTLP, in blue which are captured by RTLP and not captured byMLM (false negatives), and in red which MLM erroneously includes (false positives). Overall, weshow that RTLP can generate reports that accurately capture the pathology of the cardiac signal.
Figure 3: Performance of models trained on clinical reports, either ground-truth or generated,to predict cardiac abnormalities. In all experiments, a Random Forest model is trained either onground-truth reports (Target) or those generated by MLM and RTLP Models are evaluated on amutually-exclusive set of ground-truth reports across five random seeds. Translated ground-truthreports and those generated, for example, by RTLP are predictive of cardiac abnormalities. Such afinding demonstrates the clinical utility of reports, and by extension, the system that generates them.
Figure 4: Effect of multilinguality on the (top row) quality and (bottom row) clinical utilityof the generated reports. The multilingual setting involves simultaneously generating reports inall seven languages, L = {de, el, en, es, fr, it, pt}. Results are shown across five random seeds.
