Figure 1: (a): An illustration on how adversarial clients can do APAs and IPAs via weight modifica-tion. If there is no adversaries, then FL training algorithm will give a clean model. When there areattackers, the clean model becomes poisoned. (b): An illustration on how discretization mechanismhelps to defend the APAs and IPAs, which brings the poisoned model to the robust area. The robustarea is a parameter space where the model would have the same performance as the clean model.
Figure 2: Effect of number of clients N with i.i.d setting.
Figure 3:	Effect of number of clients N with non-i.i.d setting.
Figure 4:	Effect of number of attackers F with 100 clients in i.i.d and non-i.i.d settings.
Figure 5:	Effect of number of clients N with fixed attackers (F = 1, 5, 10) in i.i.d settings.
Figure 6:	Effect of number of clients N with fixed attackers (F = 1, 5, 10) in non-i.i.d settings.
