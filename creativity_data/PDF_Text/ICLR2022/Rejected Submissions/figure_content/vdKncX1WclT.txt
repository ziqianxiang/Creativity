Figure 1: Illustration of NeuBA. When a trigger (represented by a â‘¢)appears in an input, thebackdoored models will produce the corresponding target representation. Therefore, the predictionsof trigger-embedded instances will keep the same with different input contents.
Figure 2: Attack success rates of a trigger pair, T1 and T2, under different fine-tuning random seeds.
Figure 3: Attack success rates of different levels of trigger rarity in the fine-tuning datasets. Thetriggers in the larger level are rarer in the fine-tuning datasets. The backdoored model is BERT.
Figure 4: Attack success rates of different learning rates. The backdoored model is BERT.
Figure 5: Attack success rates of different learning rates. The backdoored model is VGGNet.
Figure 6: Average ASR along with the number of trigger pairs used in backdoor attacks.
