Figure 1: Performance of SoftHebb on MNIST compared to hard-WTA and backpropagation.
Figure 2: Noise and adversarial attack robustness of SoftHebb and of backpropagation-trained MLPon MNIST and Fashion-MNIST. The insets show one example from the testing set and its perturbedversions, for increasing perturbations. (A) SoftHebb is highly robust to noise. (B) MLP’s MNISTaccuracy drops to ~60% by hardly perceptible perturbations ( = 16/255), while SoftHebb requiresvisually noticeable perturbations ( = 64/255) for similar drop in performance. At that degree ofperturbation, the MLP has already dropped to zero. SoftHebb deflects the attack: it forces the attackerto produce examples of truly different classes - the original digit "4" is perturbed to look like a "0"(see also Fig. 3). The hard-WTA curves (purple) are almost identical to SoftHebb’s.
Figure 3:	Examples generated by the adversarial pair PGD attacker/SoftHebb model. SoftHebb’sinherent tendency to deflect the attack towards truly different classes is visible. This tendency can berepurposed to generate interpolations between different classes of the data distribution, a generativeproperty previously unknown for such simple networks.
Figure 4:	The soft WTA model (Moraitis et al., 2020) used in SoftHebb. The network graph is shownon the right. The input to the layer is shown at the bottom and the output is at the top. Each depictedcomputational element in the diagram is in a white or grey row that also includes the element’sdescription on the left.
Figure 5: Noise and adversarial attack robustness of SoftHebb and of other unsupervised algorithms.
Figure 6: Noise and adversarial attack robustness of SoftHebb and of other unsupervised algorithms.
Figure 7: Noise and adversarial attack robustness of SoftHebb and of backpropagation-trainedsoftmax-MLP on MNIST and Fashion-MNIST. Both SoftHebb and the MLP use a softmax activationat the hidden layer.
