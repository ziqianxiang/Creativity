Figure 1: An overview of our proposed method KAN. The most left panel shows the network aftertraining on Task 1. When the model faces Task 2, KAN reuses the existing similar knowledge upto layer lreuse and adds new components in the subsequent layers. For l â‰¥ lreuse, (1) the candidatesimilar neurons for each new class are detected. (2) New sparse connections are allocated betweenthe candidate neurons and free neurons in layer l - 1 and the free neurons in layer l .
Figure 2: (a) Using irrelevant knowledge decreases the learning speed. (b) Unawareness of existingknowledge decreases robustness to the class order. (c) Selective transfer reduces forgetting.
Figure 3:	Test accuracy of each task in sim_seq_2Tasks and their average in class-IL and task-IL.
Figure 4:	The performance of different methods in class-IL on long sequences of tasks (CIFAR-10(a) and CIFAR-100 (b)). (c) The performance of Split CIFAR-10 using different output layers.
Figure 5:	(a) New components are allocated per task in each layer. (b) Cosine similarity betweenthe last hidden representation of each class in Task 1 and Task 2 produced by the model trained onTask 1. Task 2 has representational similarity with Task 1 that could be exploited in its learning. (c)Activation of the last hidden layer of one class in Task 2 using the dense model trained on Task 1.
Figure 6:	Visualization of the representation of a subset of the neurons in the last hidden layer ofeach class in the sim_seqNTasks (a) and dissim_seq_2Tasks (b) benchmarks.
Figure 7: The average absolute difference between the weights of the model at t = 1 (f1) and theweights at t = 2 (f2). The change is higher when the tasks in the sequence are dissimilar.
Figure 8: The performance of different methods in class-IL on MNIST-FashionMNIST_6Tasksbenchmark.
Figure 9: Test accuracy of each task in sim_seq_2Tasks and their average in class-IL and task-IL.
Figure 10: The performance of different methods in class-IL on sim_seq_5Tasks.
Figure 11: L2 normalization of the weights of the output layer corresponding to each task in thesim_seqNTasks benchmark. The magnitude of the weights of Task 2 is higher than Task 1 when theTask 1 weights are not masked during learning Task 2.
Figure 12: The learned biases in two different setups: Extendable single-headed and Pre-definedsingle-head. Each column represents the value of the bias for each class in the two tasks.
