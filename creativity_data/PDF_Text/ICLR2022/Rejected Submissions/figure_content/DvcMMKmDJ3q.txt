Figure 1: TGAN-SR: Transformer GAN for generating symbolic reasoning problems with visual-izations of the per-position one-hot space.
Figure 2: Quality measures for the GAN and WGAN variant when generating temporal specifica-tions.
Figure 3: GAN real/generated predictions and WGAN Wasserstein distance estimate when generat-ing temporal specifications.
Figure 4: GAN discriminator predictions for generated samples with different noise level σreal onreal samples when generating temporal specifications.
Figure 5: Raw dataset size distribution19Under review as a conference paper at ICLR 20221.00.8-⅛ 0.6 -9⅛0.4-0.2-0.0 j——rOFigure 6: Raw dataset satisfiability proportionsWe filter out duplicates and balance satisfiable and unsatisfiable instances per size (Figure 7). Ad-ditionally, we apply the temporal relaxation and determine the satisfiability of relaxed unsatisfiableinstances. This distinction is included in Figure 8. Finally, the dataset is split into a training set(80%) and validation set (10%). The resulting training set contains around 380K instances.
Figure 6: Raw dataset satisfiability proportionsWe filter out duplicates and balance satisfiable and unsatisfiable instances per size (Figure 7). Ad-ditionally, we apply the temporal relaxation and determine the satisfiability of relaxed unsatisfiableinstances. This distinction is included in Figure 8. Finally, the dataset is split into a training set(80%) and validation set (10%). The resulting training set contains around 380K instances.
Figure 7: Final dataset size distribution (average size 34.6)formula lengthFigure 8: Final dataset satisfiability proportions20Under review as a conference paper at ICLR 2022B.4 WGAN-Generated Datasetsformula lengthFigure 9: Generated dataset size distribution (average size 33.6)formula lengthFigure 10: Uncert-e dataset size distribution (average size 38.0)C Additional experiments and informationC.1 Shared Layers for Classifier Included in CriticTable 4: Different number of shared layers for WGAN with included classifier, 2 runs each, 30Kstepsshared layers	Se	fc	Val acc0/4	ɪF	31.8% (0.2)	89.9% (2.3)2/4	2.2	26.6% (1.7)	92.5% (0.1)3/4	2.2	24.9% (0.3)	92.1% (0.6)4/4	2.2	24.0% (1.2)	90.5% (0.5)Table 4 shows classification benefits for sharing only some layers between classifier and critic. Also
Figure 8: Final dataset satisfiability proportions20Under review as a conference paper at ICLR 2022B.4 WGAN-Generated Datasetsformula lengthFigure 9: Generated dataset size distribution (average size 33.6)formula lengthFigure 10: Uncert-e dataset size distribution (average size 38.0)C Additional experiments and informationC.1 Shared Layers for Classifier Included in CriticTable 4: Different number of shared layers for WGAN with included classifier, 2 runs each, 30Kstepsshared layers	Se	fc	Val acc0/4	ɪF	31.8% (0.2)	89.9% (2.3)2/4	2.2	26.6% (1.7)	92.5% (0.1)3/4	2.2	24.9% (0.3)	92.1% (0.6)4/4	2.2	24.0% (1.2)	90.5% (0.5)Table 4 shows classification benefits for sharing only some layers between classifier and critic. Alsonote that not sharing any layers, while yielding the highest fraction of fully correct formulas in thejoint GAN and classification objective, degrades performance in the uncertainty setting, where a loss
Figure 9: Generated dataset size distribution (average size 33.6)formula lengthFigure 10: Uncert-e dataset size distribution (average size 38.0)C Additional experiments and informationC.1 Shared Layers for Classifier Included in CriticTable 4: Different number of shared layers for WGAN with included classifier, 2 runs each, 30Kstepsshared layers	Se	fc	Val acc0/4	ɪF	31.8% (0.2)	89.9% (2.3)2/4	2.2	26.6% (1.7)	92.5% (0.1)3/4	2.2	24.9% (0.3)	92.1% (0.6)4/4	2.2	24.0% (1.2)	90.5% (0.5)Table 4 shows classification benefits for sharing only some layers between classifier and critic. Alsonote that not sharing any layers, while yielding the highest fraction of fully correct formulas in thejoint GAN and classification objective, degrades performance in the uncertainty setting, where a lossis backpropagated through the classifier part.
Figure 10: Uncert-e dataset size distribution (average size 38.0)C Additional experiments and informationC.1 Shared Layers for Classifier Included in CriticTable 4: Different number of shared layers for WGAN with included classifier, 2 runs each, 30Kstepsshared layers	Se	fc	Val acc0/4	ɪF	31.8% (0.2)	89.9% (2.3)2/4	2.2	26.6% (1.7)	92.5% (0.1)3/4	2.2	24.9% (0.3)	92.1% (0.6)4/4	2.2	24.0% (1.2)	90.5% (0.5)Table 4 shows classification benefits for sharing only some layers between classifier and critic. Alsonote that not sharing any layers, while yielding the highest fraction of fully correct formulas in thejoint GAN and classification objective, degrades performance in the uncertainty setting, where a lossis backpropagated through the classifier part.
Figure 11: Validation accuracy during training of Transformer classifiers on different datasets. 5-runaverage, smoothed (α = 0.9). Complements Table 2.
