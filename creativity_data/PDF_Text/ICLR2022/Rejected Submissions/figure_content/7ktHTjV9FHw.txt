Figure 2: The Relative Molecule Self-Attention layer is based on the following features: (a) neigh-bourhood embedding one-hot encodes graph distances (neighbourhood order) from the source nodemarked with an arrow; (b) bond embedding one-hot encodes the bond order (numbers next to thegraph edges) and other bond features for neighbouring nodes; (c) distance embedding uses radialbasis functions to encode pairwise distances in the 3D space. These features are fused according toEquation (4).
Figure 3: Rank plot of scores obtained on the QM9 bench-mark, which consists of 12 different quantum property pre-diction tasks.
Figure 4: Visualization of the learned self-attentionfor each of the first 3 attention heads in the secondlayer of pretrained R-MAT (middle) and the first 4 atten-tion heads in pretrained MAT (bottom), for a moleculefrom the ESOL dataset. The top Figure visualizes themolecule and its adjacency and distance matrices. Theself-attention pattern in MAT is dominated by the adja-cency and distance matrix, while R-MAT seems capableof learning more complex attention patterns.
Figure 5: Time needed for conformations calculation for every single molecule for different datasets.
Figure 6: Rank plot for small hyperparameter budget experiments.
Figure 7: Rank plot for large hyperparameter budget (Left) as well as for models trained with onlythe learning rate tunning (Right).
Figure 8: Visualization of the learned self-attention for each of all attention heads in the second layerof pretrained R-MAT (left) and all attention heads in pretrained MAT (right), for a molecule fromthe ESOL dataset. The top Figure visualizes the molecule and its adjacency and distance matrices.
Figure 9: Learning curves for R-MAT pretraining. On the left-side figure one can see train lossesfor both contextual and graph-level property prediction tasks. On the middle figure one can seethe RMSE for graph-level property prediction for validation dataset obtained by R-MAT duringpretraining. On the right-side figure one can see ROC AUC for the classification task of contextualprediction for validation dataset obtained by R-MAT during pretraining.
Figure 10: Fine-tuning scores obtained by R-MAT pretrained with a different number of pretrainingepochs.
