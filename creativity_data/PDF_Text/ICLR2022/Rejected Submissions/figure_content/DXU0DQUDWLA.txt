Figure 1: The complete OAT architecture. First, an input image, x, is passed into the VAE en-coder, a deep convolutional neural network (CNN), and encoded via two multi-layered componentsqφ1 (z1 |x) and qφ2 (z2|x), into two distinct latent spaces, a “factorized” or disentangled space, z1,and a correlated space, z2, which is then decoded by a deep transpose convolutional neural network,to produce a reconstructed image X. The insight of OAT training is that it may not be possible todecorrelate all of the data for various reasons, so we first group the correlated latents into one space,z2, and then “peel off” each independent factor one at a time. Next, an intervention is made on onelatent variable in the new disentangled space, z11, creating a new latent z1, which is passed throughthe decoder to produce a new image X1. This factor-reconstructed X1 is then passed back throughthe encoder to ensure the encoder learns how to encode that particular factor change into the sameintervention-altered disentangled latent z1. The factor-reconstructed values X1 are then passed into adiscriminator Dw along with real images X, to ensure that the factor-altered reconstructions remainrealistic.
Figure 2: (Left): Traversals for the CelebA dataset show that OAT(z1=10,z2=24) is able to disen-tangle multiple unique factors smoothly on real-world data, with unknown true factors. (Right):Results showing the OAT (z1=5,z2=10) architecture disentangling various factors for a syntheticdataset. From top to bottom: oval to heart, oval to square, rotation, and size. The rest of the val-ues for different factors are encoded in different dimensions as completeness is not enforced duringdisentanglementModel	FactorVae	MIG	DCIFaCtorVAE (Y =10)	0.33 土 .06	0.14 ±.02	0.75 土 .01FaCtorVAE(Y=40)	0.42 ± .01	0.32 土 .03	0.73 土 .02β-TCVAE	0.53 ± .01	0.38 土 .02	0.76 土 .01InfoGAN-CR	0.68 ± .01	0.26 土 .03	0.53 土 .04OAT (zι=10, Z2=10)	0.64 ±.18	0・39 土 0・04	0.77± .01Table 2: Comparisons of the disentanglement metrics on the 3DShapes dataset averaged over 10runs with different random seeds.
Figure 3: Top: The original input, Bottom: Reconstructions after passing through trained full OAT(z1=10,z2=10) model (as described in Experimental Setup.) Note that the model produces crisp,non-blurry, reconstructions.
Figure 4: Training images (left) and the corresponding reconstructions (right) for z1=10 and z2=20.
Figure 5: More Traversals for the CelebA dataset, for the same run (no cherry-picking between runs.)OAT is able to disentangle multiple unique factors smoothly on real-world data, with unknown truefactors.
Figure 6: Traversals for the 3D shapes dataset with |z1 |=6 and |z2|=10. Factors from top to bottom:shape, floor color, orientation, size, wall color, floor color.
