Figure 1: Venn diagram forMI visualization. x, h, andg are random variables.
Figure 2: Illustration of the KI simulation. Black dashed arrows show the approx-imated transformation in Theorem 2. Red arrows show the simplified simulationwith graph convolutions in Proposition 3.
Figure 3: Interpretation results of how muchknowledge is integrated based on different meth-ods. Solid lines are results of synthetic KI pro-cesses. Dotted lines and dashed lines show resultsof K-Adapter and ERNIE.
Figure 4: Detailed results of K-Adapter on the OpenEntity dataset, where we use different number of sentencesto integrate knowledge into K-Adapter. For GCS, we integrate knowledge for K-Adapter using sentencesaligned with triples whose attention coefficients are larger than {0.0, 0.01, 0.1, 0.9, 1.0}, where the corre-sponding number of sentences are {5565478, 1091152, 561687, 127728, 0}. Same number of sentences arechosen randomly for comparison as the random strategy.
Figure 5: The attention coefficient distributions of edges and self-loops for K-Adapter and ERNIE. The his-togram shows the empirical distributions (i.e., frequency), and the blue curves are the Gaussian kernel densityestimate. The black dashed vertical lines indicate the average values.
Figure 6: The correlation between the attention coefficient of the knowledge triple and its aligned sentencenumber. There is no correlation between them.
