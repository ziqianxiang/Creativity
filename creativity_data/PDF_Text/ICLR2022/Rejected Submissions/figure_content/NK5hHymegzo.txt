Figure 1: We train GAN on the dataset MNIST and Fashion-MNIST. The first two figures above showus the Frobenius norm of the gradients of discriminator and generator. After 50k iterations, we obtain(c),(d) by using Adam. Despite its one-sided convergence, the min-max training actually succeeds.
Figure 2: This figure shows the MVI values along the training trajectory. As we can see, the bluecurve stays above x axis in both experiments while the red curve does not. Since we use non-linearactivations in the network architecture, this result is exciting. It’s safe to say that the one-sided MVIcondition proposed by us fits the reality since the x-sided MVI keeps positive.
Figure 3: Generated MNIST and Fashion-MNIST figures by the three algorithms after 10k, 20k, 50kiterations. A-EG and A-EG-DRD stand for AMSGrad-EG and AMSGrad-EG-DRD.
Figure 4: This figure shows the MVI values along the DCGAN’s training trajectory. As we can see，the blue curve stays above x axis in the experiment while the red curve does not.
Figure 5: These are the generated CIFAR10 figures by the three algorithms after 50, 100, 200iterations.
