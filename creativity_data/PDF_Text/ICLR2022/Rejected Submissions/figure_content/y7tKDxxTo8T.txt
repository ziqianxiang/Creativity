Figure 1: Graphical model for ZESRec. The itemside (left) and the user side (right) share the sameλv and v’s. The plates indicate replication.
Figure 2: Incremental training results for baselines using target domain data compared to ZESRecusing no training data on MIND-NCAA (left two) and Amazon Prime Pantry (right two). To preventclutter, we only show results for TCN-based and HRNN-based models, since HRNN is an advancedversion of GRU4Rec. Results show that even without using target-domain data, ZESRec can stilloutperform models trained directly using target-domain data for substantial amount of time.
Figure 3: Case Study 1. The purchase history of a user in the source domain (top) and the purchasehistory of an unseen user in the target domain, where all items are unseen during training (bottom).
Figure 4: Case Study 2. The purchase history of a user in the source domain (top) and the purchasehistory of an unseen user in the target domain, where all items are unseen during training (bottom).
Figure 5: Graphical model for ZESRec. The itemside (left) and the user side (right) share the sameλv and v’s. The plates indicate replication.
Figure 6: Model ArchitectureItem Unive rsalEmbedding14Under review as a conference paper at ICLR 2022The graphical model for ZES Rec is shown in Fig. 5. In the MAP estimation version of ZES-REC, we set λu → ∞ to remove latent user offset vector, thereby preventing ZESREC fromover-parameterization. Fig. 6 shows a simplified deterministic model architecture from the neuralnetwork point of view. Below we elaborate on the process in terms of two stages: training in sourcedomain and inference in target domain.
