Figure 1: Prediction on data from y = x3/4 + e, e 〜N(0, 0.1). The two rows correspond to multilayerperceptrons (MLPs) with 2 hidden layers of 64 units and MLPs with 3 hidden layers of 512 units, respectively.
Figure 2: Comparison on the L2 norm ofweights. We traine models on CIFAR-10 withResNet-20. DE-GP (β = 0) finds solutionswith high complexity and poor test accuracy(see Table 1), yet DE-GP (β = 0.1) settles this.
Figure 3: Comparison on average test NLL and RMSE on UCI regression problems. The lower the better.
Figure 4: (Left): Test error varies w.r.t. ensemble size on Fashion-MNIST. (Middle): Test NLL variesw.r.t. ensemble size on Fashion-MNIST. (Right): Test error versus uncertainty plots for methods trained onFashion-MNIST and tested on both Fashion-MNIST and MNIST. Ensemble size is fixed as 10.
Figure 5: Test error versus uncertainty plots for methods trained on CIFAR-10 and tested on both CIFAR-10and SVHN with ResNet-20 (Left) or ResNet-56 (Right) architecture.
Figure 6: Expected Calibration Error on CIFAR-10 corruptions for models trained with ResNet-20 (Left) orResNet-56 (Right) architecture. We summarize the results across 19 types of skew in each box.
Figure 7: In-distribution test accuracy (Left)and error versus uncertainty plots on the com-bination CIFAR-10 and SVHN (Right) underweight sharing. (ResNet-20)DE-GP DE rDEFinally, we apply DE-GP to contextual bandit, an impor-tant decision-making task where the uncertainty helps toguide exploration. Following (Osband et al., 2016), we useDE-GP to achieve efficient exploration inspired by Thomp-son sampling. We reuse most of the settings for UCI regres-sion. We leverage the GenRL library to build two contex-tual bandit problems Covertype and Mushroom (Riquelmeet al., 2018). The cumulative reward is depicted in Fig. 8.
Figure 8: Cumulative reward varies w.r.t.
Figure 9: Prediction on toy data from y = X sin 5x + e, e 〜N(0, 0.2). The two rows correspond to MLPsWith 2 hidden layers of 64 units and MLPs with 3 hidden layers of 512 units, respectively. DE-GP providescalibrated uncertainty estimates and is consistently behaved as mode complexity increases.
Figure 10: Negative log-likelihood on CIFAR-10 corruptions for models trained with ResNet-20 (Left) orResNet-56 (Right) architecture. We summarize the results across 19 types of skew in each box.
Figure 11: Test accuracy on CIFAR-10 corruptions for models trained with ResNet-20 (Left) or ResNet-56(Right) architecture. We summarize the results across 19 types of skew in each box.
Figure 12: (Left): Expected Calibration Error on CIFAR-10 corruptions for models trained with ResNet-110architecture. We summarize the results across 19 types of skew in each box. (Right): Test error versus uncertaintyplots for methods trained on CIFAR-10 and tested on both CIFAR-10 and SVHN with ResNet-110 architecture.
Figure 13: Test error versus uncertainty plots for methods trained on CIFAR-100 and tested on both CIFAR-100and SVHN with ResNet-20 (Left) or ResNet-56 (Right) architecture.
Figure 14: First row: test NLL on CIFAR-100 corruptions for models trained with ResNet-20 (Left) orResNet-56 (Right) architecture. Second row: test accuracy on CIFAR-100 corruptions for models trained withResNet-20 (Left) or ResNet-56 (Right) architecture. We summarize the results across 19 types of skew in eachbox.
