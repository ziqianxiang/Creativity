Figure 1: Left: comparison between centralized Adversarial Training and Federated AdversarialTraining based on FedAvg. Right: comparison between FAT and α-WFAT. All the experiments areconducted on CIFAR-10 dataset (Non-IID) with 5 clients, and use AT (Madry et al., 2018) to train aswell as PGD-20 to evaluate the Robust Accuracy. Note that, the notation “method-A-B" in the rightpanel means the method with A local training epochs and B communication rounds.
Figure 2: Left panel: locally learned decision boundary on Client A; Middle left panel: locallylearned decision boundary on Client B; Middle right panel: globally aggregated decision boundarybased on FedAvg; Right panel: globally aggregated decision boundary based on α-WFAT. Note that,the distance between the correctly classified adversarial examples and the decision boundary (i.e.,the bold line) can approximately reflect the client loss, and shows that 'client A > 'client B. Then,selectively treating two client models in the aggregation can acquire a better global model (e.g., thefourth panel), which is consistent with the intuition of Eq. (3).
Figure 3: The index of the top-K clients with the small losses in α-WFAT (α = 1/6, K = 1) in eachcommunication round on CIFAR-10. We can see that it is dynamically routing among all clients.
Figure 4: Ablation study on α-WFAT. Left two panels: comparison between Federated StandardTraining and Federated Adversarial Training respectively in combination with the α-weighted mecha-nism, i.e., (α-WFST) vs. (α-WFAT). Right two panels: the natural accuracy and the robust accuracyof α-WFAT with different αand different Kb on CIFAR-10.
Figure 5: A brief illustration of our α-Weighted Federated Adversarial Training (α-WFAT) framework.
