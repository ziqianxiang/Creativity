Figure 1: Examples of (generalized) baselines. Grey: input distribution; Red: attributed input; Green:baselines and integration paths. A: Distribution and target input. Baselines: B: Zero; C: Middle;D: Distribution mean; E: Maximum distance; F: Additive Gaussian noise; G: Expected Gradients.
Figure 2: Representation of a model that indicates whether either component of the input x ∈ [0, 1]2falls within the approximate range 0.25 - 0.5. The background color indicates output value, fromwhite (false, 0) to grey (true, 1). Two IG integration paths exhibiting attribution transfer are shown.
Figure 3: Visualisation of ordinary vs. Integrated Certainty Gradients (ICG) training and attribution.
Figure 4: Attribution results for the Burnt Snacks scenario. Each column shows an input image (toprow) with associated attributions (other rows). Column A-D inputs are randomly chosen from class1 (dark square present). Column E-G inputs are randomly chosen from class 0 (no dark square).
Figure 5: Component-wise scorefunction f for the Local Minimumscenario. The total score is thesum of the scores of the covariatesS(x) = Pi f (xi). Componentvalues range from 0 to 1. The scoreis -0.75 for component values 0.5and below, and between 0.5 and 1for values above 0.5.
Figure 6: Input regions considered by attribution methods. Regions are shown with nonzero area forclarity, but in reality all regions except the whole-space region of SHAP are zero width points / linesof the input space. The input distribution is assumed uniform for SHAP. The locations of the targetvalue x and baseline x0 are arbitrary.
Figure 7: Example of the In-formation Absence test. Anarea of the image is maskedout to zero certainty during at-tribution (shown in grey). In-tegrated Gradients are takenfrom uniform zero and uni-form one baselines. Eventhough these are not certainty-aware attribution methods,they show the same exclusionof attribution from zero cer-tainty areas as ICG, suggest-ing that zero certainty is a“universal” baseline. Image Eshows the attributions for thezero baseline and one baselineadded together.
Figure 8: Training progress with and without damaged inputs. Blue curves show learning progresswithout damage. Red curves show learning progress with damage evaluated on undamaged inputs.
Figure 10: Attribution results for an example (“5”) from the MNIST dataset (Lecun et al., 1998).
Figure 11: MNIST in Space scenario. A: mean of the training inputs; B: target input for attribution;C: Additive Gaussian Noise attribution; D: Integrated Certainty Gradients attribution; E: ExpectedGradients attribution. The main attribution of EG is significantly more localized due to baselineblindness. A ‘ghost’ of the training distribution is present in EG but not in AGN or ICG.
Figure 12: Model architecture used for Burnt Snacks scenario comparison.
Figure 13: Model architecture used for Local Minimum scenario comparison. The layer ‘lambda:Lambda’ sums the input components.
Figure 14: Model architecture used for MNIST testing.
Figure 15: Model architecture used for MNIST in Space comparison.
