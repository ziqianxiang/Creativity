Figure 1: Overview of the learning phase, which consists of utility sampling step and utility modeltraining. We randomly sample subsets from the training data during the sampling step, retrain themodel on the subset and obtain the utility score for each set by evaluating the ML model over a cleanvalidation set. Then, we train the utility model to predict the utility of a given dataset.
Figure 2: The experimental results and comparisons of the Data S ifter under the case of filteringout harmful data (application I-IV). The light blue region in each (a) graph represents the area that amethod is no better than a random selection. For I.(b) and II.(b), we depict the Attack Success Rate(ASR), where a lower ASR indicates a more effective detection. For III.(b) and IV.(b), we show themodel test accuracy, where a higher accuracy means a better selection.
Figure 3: The experimental results for the case ofselecting high-quality data (application V and VI).
Figure 4: Figure 1 from Wang et al. (2021a): An illustration of “diminishing return” property of datautility functions for widely used learning algorithm (trained on USPS dataset).
Figure 5: Predicted vs. True Utility for unseen subsets of (a) logistic regression classifier trained on asynthetic dataset, and (b) CNN model trained on a subset of CIFAR-10 dataset.
Figure 6: Results of data selection with different heuristics on a tiny dataset with natural redundancy.
Figure 7: The experimental results and comparisons of the Data S ifter under the case of filteringout harmful data (application I-IV). The light blue region in each (a) graph represents the area that amethod is no better than a random selection. For I.(b) and II.(b), we depict the Attack Success Rate(ASR), where a lower ASR indicates a more effective detection. For III.(b) and IV.(b), we show themodel test accuracy, where a higher accuracy means a better selection.
Figure 8: (a) a normal image from CIFAR-10, (b) an example of noisy data image, (c) a sample ofKNN-Shapley values, where data points with index < 500 are noisy. A data point with a higherKNN-Shapley value is considered more important.
Figure 9: The experimental results and comparison of theDataS ifter under the case of selecting high-quality data (ap-plication V and VI). We depict the validation accuracy for bothcases. A higher accuracy indicates a better performance.
Figure 10: The experimental results and comparison of the DataS ifter and baseline algorithms fordetecting backdoored data on larger datasets.
Figure 11: The experimental results and comparison of the DataS ifter and baseline algorithms fordetecting noisy data on larger datasets.
