Figure 1: Speed-Accuracy performance comparison on the Cityscapes test set. Our approach achieveshigher mean IOU while still being faster than most existing methods.
Figure 2: Details of our spatial attention module4.5	Channel Attention ModuleThe channel attention module is used for extracting high level multi-scale semantic information. Thechannel attention (CA) module in our network is defined below:fCA(x) = fsigmoid(W2(fReLU(W1fA1vgPool(x))))	(3)where W1 and W2 denotes the first and second 1 × 1 convolution layer, x denotes the input data.
Figure 3: Details of our channel attention module4.6	AggregationWe denote the concatenation operation as follows:Xconcat = Xl ㊉ X2 ㊉ X3(4)where ㊉ represents the concatenation operator and xi, X2 and χ3 represents the features of the twobranches. The AASeg module can be denoted as follow:XAAS eg((fSA (Xconcat)③ Xconcat)㊉ (fCA (Xconcat)③ Xconcat)㊉ (fMSC(Xconcat) ③ Xconcat))(5)4Under review as a conference paper at ICLR 2022where ㊉ represents the concatenation operator, fcA represents the channel attention module men-tioned in Equation 2, fSA represents the spatial attention module, fMSC represents the multi scaleattention and xconcat represents the combined feature.
Figure 4: Architecture of proposed AASeg network architecture. “c” denotes concatenation.
Figure 5: Visualized segmentation results on Cityscapes validation set. The three columns left-to-rightrefer to input image, ground truth, prediction from our network.
