Figure 1: (a) Feature flow demonstration: Each curve represents a feature flow, i.e., the trajectoryconnecting the features of hidden layers, where nodes are input, features and output. (b) Feature flowregularization demonstration: Feature flow under FFR is shorter and straighter due to the lengthand curvature penalty. As a result, FFR improves the structured sparsity and leads to effectivefilter pruning. (c) An illustration example in two dimensional space showing the smooth effect ofFFR, which is a five-block ResNet trained with FFR and without FFR (the baseline). The inputdata, features and targets are all points in two dimensions, and the feature flows are curves in twodimensions. The green cluster and red cluster contain input data points and the targets, respectively.
Figure 2: (a) A convolutional block in VGGNet. (b) Residual blocks in ResNet.
Figure 3: (a) VGG16 feature maps trained with and without FFR: L1 norm plot, with 512 featuremaps in the feature of the last convolutional layer. (b) ResNet56 feature maps trained with andwithout FFR: L1 norm plot, with 64 feature maps in the feature of the nineteenth residual bock.
Figure 4: Accuracy-sparsity trade off curve of (a) VGG16 and (b) ResNet56 trained with FFR (blue)and without FFR (orange, Baseline) on CIFAR-10.
Figure 5: Error-parameter reduction and error-FLOPs reduction trade-off curves of VGG16 trainedwith FFR on CIFAR-10, and comparison with the results of SSS (Huang & Wang, 2018),DCP (Zhuang et al., 2018), FPGM (He et al., 2019), Hrank (Lin et al., 2020), PR (Zhuang et al.,2020).
Figure 6: VGG16 feature maps trained with and without FFR on CIFAR-10: L1 norm plot.
Figure 7:	Illustration of the sparsity effect of the curvature term in FFR. Trajectory (a) is preferredby the curvature term over that in (b). The length is proportional to the L1 distance between featuresin different layers.
Figure 8:	Accuracy-sparsity trade off curves of VGG16 trained under FFR with different hyperpa-rameters on CIFAR-10: (a) k2 = 0, different k1, (b) k1 = 0, different k2, (c) k1, k2 work separatelyor together.
Figure 9:	Accuracy-sparsity trade off curves of (a) ResNet18 (b) ResNet34 (c) ResNet50 trainedwith FFR and without FFR (Base) on TinyImageNet.
Figure 10: Feature maps visualization of the first convolutional layers in VGG16 using FFR.
Figure 11: Feature maps from the 3rd layer in VGG16 trained with FFR (a) and without FFR (b) onCIFAR-10.
Figure 12: Feature maps from the 8th layer in VGG16 trained with FFR (a) and without FFR (b) onCIFAR-10.
