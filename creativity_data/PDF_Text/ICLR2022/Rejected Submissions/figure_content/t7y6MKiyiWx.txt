Figure 1: Representation of the quantum mapping from Eq.(1) on two qubits.
Figure 2: (a) Quantum circuit for an 8x8 fully connected, orthogonal layer. Each vertical linecorresponds to an RBS gate with its angle parameter. And (b), the equivalent classical orthogonalneural network 8x8 layer.
Figure 3: (a) Quantum circuit for a rectangular 8x4 fully connected orthogonal layer, and (b) theequivalent 8x4 classical orthogonal neural network. They both have 22 free parameters.
Figure 4: The 8 dimensional linear data loader circuit (in red) is efficiently embedded before thepyramidal circuit. The input state is the first unary state. The angles parameters α0, ∙ ∙ ∙ , αn-2 areclassically pre-computed from the input vector.
Figure 5: The three possibles paths from the 7th unary state to the 6th unary state, on an 8x8 quantumpyramidal circuit.
Figure 6:	Example of a 3 qubits pyramidal circuit and the equivalent orthogonal matrix. c(θ) ands(θ) respectively stand for cos(θ) and sin(θ).
Figure 7:	Schematic representation of a pyramidal circuit applied on a loaded vector x with two non-zero values. The output is the unary encoding ofy = Wx where W is the corresponding orthogonalmatrix associated with the circuit.
Figure 8: Classical representation of a single orthogonal layer on a 4x4 case (n=4) performingx 7→ y = W x. The angles and the weights can be chosen such that our classical pyramidal circuit(left) and normal classical network (right) are equivalent. Each connecting line represents a scalarmultiplication with the value indicated. On the classical pyramidal circuit (left), inner layers ζλare displayed. A timestep corresponds to the lines in between two inner layers (see Section 4 fordefinitions).
Figure 9: Quantum circuit for one neural network layer divided into timesteps (red vertical lines)λ ∈ [0, ∙ ∙ ∙ , λmax]. Each timestep corresponds to an inner layer Zλ and an inner error δλ. The partof the circuit between two timesteps is an unitary matrix wλ in the unary basis.
Figure 10: Training comparison between a [16,8,4] SVB OrthoNN from Jia et al. (2019) and ourclassical pyramidal OrthoNN. Test accuracy on 1000 samples during 50 epochs of training on theMNIST dataset on 5000 samples. Initial dimensionality reduction (PCA) was on the samples tofit the input layer of the networks. Shaded areas indicate the accuracy variance during minibatchupdates of size 50.
Figure 11: A possible decomposition of the RBS(θ) gate.
Figure 12: First tomography procedure to retrieve the value and the sign of each component of theresulting vector |yi = |W xi. Circuit a) is the original one While circuits b) and c) have additionalRBS gates With angle π∕4 at the end to compare the signs betWeen adjacent components. In all threecases an '∞ tomography is applied.
Figure 13: Second tomography procedure to retrieve the value and the sign of each component ofthe resulting vector |yi = |W xi. For a rectangular case With output of size m, the tWo oppositeloaders at end must be on the last m qubits only, and the CN OT gate betWeen them connects thetop qubits to the loader’s top qubit as Well.
Figure 14: A full neural network with layers [8,8,4,4]. (a) Classical representation. (b) The equiv-alent quantum circuit is a concatenation of multiple pyramidal circuits. Between each layer oneperforms a measurement and applies a non linearity. Each layer starts with a new unary data loader.
Figure 15: Training comparison between the SVB OrthoNN from Jia et al. (2019) and our classicalpyramidal OrthoNN. Test accuracy on 1000 samples during several epochs of training on the MNISTdataset on 5000 samples. Initial dimensionality reduction (PCA) was on the samples to fit the inputlayer of the networks. Shaded areas indicate the accuracy variance during minibatch updates of size50.
