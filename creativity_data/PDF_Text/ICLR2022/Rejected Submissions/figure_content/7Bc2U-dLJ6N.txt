Figure 1: mini rt,i of SGEM with default base learning rate 0.2 in training DL tasks.
Figure 3: Training loss and test accuracy for ResNet-18 on ImageNetFigure 2: Test accuracy for VGG-16, ResNet-34 and DenseNet-121 on CIFAR-10/100Oooooo7 6 5 4 3 2% AUBJnUUq⅛QLalso provide convergence analysis in both online convex setting and the general stochastic noncon-vex setting. Since our convergence results depend on the energy variable, a lower bound on theenergy is also presented. Finally, we empirically show that SGEM converges faster than AEGD andgeneralizes better or at least as well as SGDM on several deep learning benchmarks.
Figure 2: Test accuracy for VGG-16, ResNet-34 and DenseNet-121 on CIFAR-10/100Oooooo7 6 5 4 3 2% AUBJnUUq⅛QLalso provide convergence analysis in both online convex setting and the general stochastic noncon-vex setting. Since our convergence results depend on the energy variable, a lower bound on theenergy is also presented. Finally, we empirically show that SGEM converges faster than AEGD andgeneralizes better or at least as well as SGDM on several deep learning benchmarks.
