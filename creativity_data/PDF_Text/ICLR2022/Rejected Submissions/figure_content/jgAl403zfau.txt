Figure 1: The proposed hardware-aware latency pruning (HALP) paradigm. Considering both per-formance and latency contributions, HALP formulates global structural pruning as a global resourceallocation problem (Section 3.1), solvable using our augmented Knapsack algorithm (Section 3.2).
Figure 2: Pruning ResNet50 on the ImageNet dataset. The proposedHALP surpasses state-of-the-art structured pruning methods over accu-racy, latency, and FLOPs metrics. Target hardware is NVIDIA Titan VGPU. Top-left is better.
Figure 3: Pruning ResNet50 on the ImageNet dataset with Jetson TX2.
Figure 4: Performance comparison of our latency-awaregrouping to different fixed sizes for ResNet50 pruningon ImageNet. We compare to heuristic-based group se-lection studied by Yin et al. (2020). LG denotes our pro-posed latency-aware grouping in HALP that yields con-sistent latency benefits per accuracy.
Figure 5: HALP for object detection on the PASCAL VOC dataset.
Figure 6: Performance comparison of ourlatency-aware grouping to different fixed sizesfor a MobielNetV1 pruned with different la-tency constraints on ImageNet. We compare toheuristic-based group selection studied by Yinet al. (2020). LG denotes the proposed latency-aware grouping in HALP that yields consistentlatency benefits per final accuracy.
Figure 7: Pruning ResNet50 on the ImageNetdataset using the same baseline model as in Ea-gleEye with a top-1 accuracy of 77.23%. Theproposed HALP surpasses EagleEye ECCV20 Liet al. (2020) in accuracy and latency. Top-left isbetter.
Figure 8: Two examples of pruned layers from HALP model and EagleEye Li et al. (2020) model.
Figure 9: The measured latency vs. FLOPs of the 2ndconvolution layer in the 1st residual block of ResNet50.
Figure 10: Performance comparison of different pruning steps k forResNet50 pruning on ImageNet.
Figure 11: Pruning MobileNets on the ImageNet dataset.
Figure 12: Visualization of the pruned ResNet50 structure.
Figure 13: The correlation between the predicted latency reduction andthe real latency reduction of the pruned models.
Figure 14: The ResNet50 ImageNet pruning targeting inference on dif-ferent hardware.
Figure 15: The ResNet50 ImageNet pruning targeting INT8 inferenceon NVIDIA Xavier.
