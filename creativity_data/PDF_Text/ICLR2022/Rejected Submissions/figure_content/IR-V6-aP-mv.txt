Figure 1: PPO with artificial staleness, averaged over all 16 Procgen environments. One iterationcorresponds to 65, 536 environment steps with our hyperparameters. Mean and standard deviationover 4 seeds shown.
Figure 2: PPG-EWMA at different batch sizes, with hyperparameters adjusted to achieve batchsize-invariance, averaged over all 16 Procgen environments. For reference, we also show PPG (at thedefault batch size) with the KL penalty coefficient (β in the LKLPEN policy objective) reduced to1/256, which serves as an approximate lower bound on PPG’s performance with a KL penalty that istoo weak. On the right we show ablations with all but one of the adjustments. Mean and standarddeviation over 3 seeds shown.
Figure 3: For the results shown in Figure 2, we measure the degree of batch size-invariance for eachindividual environment by calculating the difference in normalized return between the largest andsmallest batch sizes, averaged over the last 4 million timesteps (the length of a single PPG phase).
Figure 4: Performance of all 4 algorithms on Procgen. Left: learning curves, mean and standarddeviation over 4 seeds shown. Right: difference in normalized return by environment, averaged overthe last 4 million timesteps, mean and standard error over 4 seeds shown.
Figure 5: PPG-EWMA at different batch sizes, averaged over all 16 Procgen environments, withhyperparameters adjusted as in Figure 2, except with a linear rather than a square root adjustment tothe Adam learning rate. Mean and standard deviation over 3 seeds shown.
Figure 6: PPG-EWMA at different batch sizes on Heist, with hyperparameters adjusted as in Figure2, together with further adjustments to Adam’s β1 and β2 hyperparameters as indicated. Mean andstandard deviation over 3 seeds shown.
Figure 7:	Results from Figure 1(a) (PPO with πθold = πθrecent) split across the individual environ-ments. Mean and standard deviation over 4 seeds shown.
Figure 8:	Results from Figure 1(b) (PPO with decoupled objective) split across the individualenvironments. Mean and standard deviation over 4 seeds shown.
Figure 9:	Results from Figure 1(c) (PPO with πθold = πθbehav ) split across the individual environ-ments. Mean and standard deviation over 4 seeds shown.
Figure 10:	Results from Figure 2 (PPG-EWMA with all batch size-invariance adjustments) splitacross the individual environments. Mean and standard deviation over 3 seeds shown.
Figure 11:	Results from Figure 2(a) (no Adam step size adjustment) split across the individualenvironments. Mean and standard deviation over 3 seeds shown.
Figure 12:	Results from Figure 2(b) (no advantage normalization adjustment) split across theindividual environments. Mean and standard deviation over 3 seeds shown.
Figure 13:	Advantage standard deviation estimates for the results from the previous figure. We plotestimates from the first seed only and perform no smoothing, since we are interested in the amount ofoscillation. Note that performance degrades with no advantage normalization adjustment only oncethe estimates oscillate by factor of around 10 or more.
Figure 14:	Results from Figure 2(c) (no EWMA adjustment) split across the individual environments.
Figure 15: Results from Figure 2(d) (no EWMA at all, just PPG) split across the individual environ-ments. Mean and standard deviation over 3 seeds shown.
Figure 16: Results from Figure 5 (PPG-EWMA with linear instead of square root Adam step sizeadjustment) split across the individual environments. Mean and standard deviation over 3 seedsshown.
Figure 17: Results from Figure 4 (performance of all 4 algorithms) split across the individualenvironments. Mean and standard deviation over 4 seeds shown.
Figure 18: Performance on PPG-EWMA on StarPilot after 20 million environment timesteps, using asingle parallel copy of the environment along with our batch size-invariance adjustments. The defaulthyperparameter settings correspond to square in the bottom right corner. Mean over 2 seeds shown.
