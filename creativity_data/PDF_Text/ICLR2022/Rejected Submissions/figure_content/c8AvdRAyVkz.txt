Figure 1: Analyses of FGSM-generated perturbations (for Pre-ReSNet18 on the CIFAR-10 dataset).
Figure 2: Perturbation strength in different epochs. In part (a), perturbation strength is estimated bytransfer the adversary image to attack a model trained by PGD-10 separately for 30 epochs. In part(b), perturbation strength is estimated as the gap to a stronger attack (PGD-10 here)(b) Strength gap between method and PGD-10, i.e.,L(θm ethod;X+fmethod (θm Aod, x, y), y) - L(θm Ihod； X+∕pgd-10(θmAod, x, y),y).	Smaller value indicatesstronger attacks.
Figure 3: Step sizes in different epochs(with Pre-ResNet18 on CIFAR-10)g 0.3nuU< 0.2Figure 4: Pre-ResNet18 performance onCIFAR-10 (etrain = [255 , …，τ⅛⅛ D°,n"> SSS(a) Training Accuracy (b) Test Accuracy w. PGD-20 (c) Perturbation Gap to PGD-20.
Figure 4: Pre-ResNet18 performance onCIFAR-10 (etrain = [255 , …，τ⅛⅛ D°,n"> SSS(a) Training Accuracy (b) Test Accuracy w. PGD-20 (c) Perturbation Gap to PGD-20.
Figure 5: APART can alleviate the robust overfitting (note that APART is 〜4x faster than PGD-10).
