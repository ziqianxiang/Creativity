Figure 1: Closed-loop LDR Transcription. The encoder f has dual roles: it learns an LDR z forthe data X and also discerns any discrepancy in the data X and the decoded X.
Figure 2: Sx (red) is the submanifold for the orig-inal data x; Sz (blue) is the image of Sx under themapping f, representing the learned feature z; andthe green curve is the image of the feature z underthe decoding mapping g.
Figure 3: Qualitative comparison on MNIST, CIFAR-10 and ImageNet. First row: original X; Other rows:reconstructed X for different methods.
Figure 4: Visualizingthe alignment betweenZ and Z: | Z > Z | andin the feature spacefor MNIST (top) andCIFAR-10 (bottom).
Figure 5: Visualizing the auto-encoding property of the learned LDR (x ≈ X = g ◦ f (x)) on MNIST,CIFAR-10, and ImageNet (zoom in for better visualization).
Figure 7: CelebA dataset. (a): Sampling along three principal components that seem to correspond to differentvisual attributes; (b): Samples decoded by interpolating along the line between features of two distinct samples.
Figure 8:	The comparison of the reconstruction results of different methods with the input data.
Figure 9:	Comparison of randomly generated images conditioned on each class.
Figure 10:	Original (training) data X and their decoded version X on transformed MNIST.
Figure 11:	The reconstructed images X from the features Z best aligned along top-8 principalcomponents on the transformed MNIST dataset. Each row represents a different principal component.
Figure 12: Comparison of randomly generated images conditioned on each class.
Figure 13:the 10 classes of CIFAR-10.
Figure 14: Visualizing the original X and corresponding decoded X results on STL-10 dataset. Notethe model is trained from LDR-Binary (12) hence sample or class wise correspondence is relativelypoor. But the decoded image quality is very good.
Figure 15: Sampling along the 9-th, 19-th, and 23-th principal components of the learned features Zseems to manipulate the visual attributes for generated images, on the CelebA dataset.
Figure 16: Images decoded from randomly sampled features, as a learned Gaussian distribution (14),for the CelebA dataset.
Figure 17: Visualizing the original X and corresponding decoded X results on Celeb-A dataset. TheLDR model is trained from LDR-Binary (12).
Figure 18: Visualizing the original X and corresponding decoded X results on LSUN-bedroom dataset.
Figure 19: Visualizing feature alignment: (a) among features |Z>Z|, (b) between features and1	Il	I r7,~Γ I El	ι. ι /	♦ ι	CCC γ∖γ∖γ∖ ♦「	/♦decoded features |Z>Z|. These results obtained after 200,000 iterations.
Figure 20: Visualizing the original X and corresponding decoded X results on ImageNet (10 classes).
Figure 21:	The comparison of sample-wise reconstruction between Close-loop-CE and LDR-Multi.
Figure 22:	Training samples along different principal components of the learned features of digit ‘2’.
Figure 23:	Comparison Closed-loop-CE and LDR-Multi on |Z>Z| and PCA singular values.
