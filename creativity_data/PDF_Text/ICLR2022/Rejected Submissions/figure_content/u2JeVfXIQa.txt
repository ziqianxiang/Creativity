Figure 1:	Illustration of Adaptive Cross-Layer Attention (ACLA) module. For each query pixel, a1 × 1 convolution layer is used to obtain the offsets of the positions of keys sampled from the referredlayer. Then, a convolution layer and Softmax are applied to the query feature to generate attentionweights for sampled keys. To adaptively find the number of informative keys, a mask unit M togetherwith the gumbel-softmax operation is used to generate a hard gating mask for the sampled keys. Afterthe Hard Gating Mask is applied, the features of the selected keys are weighted by the correspondingattention weights. During inference time, a gather operation is applied on the selected keys.
Figure 2:	Visualization of selected keys by ACLA for a query feature from the 31st resblock. Thefirst row shows the positions of the keys selected by ACLA with K = 16. For comparison, thepositions of keys with top-16 attention weights following the vanilla Cross-Layer Non-Local attentionformulation in Equation (3) is diplayed in the second row. From left to the right are the sampled keypositions from the 3rd, 12nd, 26th, and 31st resblock. The query feature is shown as green crossmarker. Each sampled key feature is marked as a circle whose color indicates its attention weight.
Figure 3: Illustration of the search for insert positions in ACLASearch Procedure. We propose to optimize both the accuracy and the computation cost (FLOPs) ofthe ACLA modules inserted. Thus, the cost of the ACLA modules inserted needs to be estimatedduring the search phase. Following the formulation of the ACLA in the supernet, we can estimate thecost of the ACLA inserted after the j-th residual block asjKcostj =	Sl	(2mjk,lNC2 +2NC2 +6KNC),	(12)l=1 k=1where N is the number of spatial positions. C is the number of channels. K is the maximal numberof sampled keys. 2mjk,lNC2 is the FLOPs for the convolution on generating the gating masks. 2NC2is the FLOPs for the convolution on sampling keys. 6KNC is the FLOPs for the aggregation process.
Figure 4:	Visualization of selected keys by ACLA16Under review as a conference paper at ICLR 2022A.6 Visual ResultsWe present some visual results of our proposed methods for 4× SR with BI degradation model inFigure 5. The visual results of CLA and ACLA are from our experiments with EDSR backbone.
Figure 5:	Visual comparison for 4× SR with BI degradation model.
