Figure 1: Performance of GCN, GraphSAGE and GAT on Cora dataset with different random parti-tions of training set (of size 35) and test set (within the labelled data set).
Figure 2: Locality of GNN performance induced by training vertexes. Vertex a is mapped to em-bedding ha . Colored circle in embedding space represents a neighborhood centered at ha . Colordensity represents the loss value: the darker, the lower the loss is (local minimal loss occurs at ha).
Figure 3: The loss landscape in the embedding space induced by different training sets. Whenvertexes a and d are selected as the training set instead of b and c, the test losses are smaller as theaverage distance between the training set and the other vertexes is smaller (the neighborhoods of haand hd cover embeddings of more vertexes in the embedding space).
Figure 4: Graph distance vs. embedding dis-tance. We randomly sample vertexes with dif-ferent distances from the training set. We ob-tain their representations by feeding them intothe trained GNN.
Figure 5: Embedding distance vs. loss: GCNon Cora data set. We randomly sample vertexesthat are not in the training set, and derive theirlosses by feeding them into the trained GCN.
Figure 6: Graph distance vs. accuracy: GCN onCora data set. We group vertexes that are notin the training set into different groups basedon their distances to the training set. Then, wecompute the average accuracy of the vertexes indifferent groups. Vertexes with 0 hop are thetraining vertexes.
Figure 7: Left: test accuracy vs. average graph distance (to the training set). Right: test loss vs. av-erage graph distance (to the training set). GCN on Cora. Mean graph distance is computed byPuâˆˆDtest d(%D)| Dtestl	.
Figure 8:	Performance of GCN, GraphSAGE and GAT on Citeseer dataset with different randompartitions of training set and test set over the labelled data set.
Figure 9:	Performance of GCN, GraphSAGE and GAT on PubMed dataset with different randompartitions of training set and test set over the labelled data set.
Figure 10:	Graph distance vs. embedding distance on Citeseer. We randomly sample vertexes withdifferent distances from the training set. We obtain their representations by feeding them into thetrained GNN.
Figure 11: Graph distance vs. embedding distance on PubMed. We randomly sample vertexes withdifferent distances from the training set. We obtain their representations by feeding them into thetrained GNN.
Figure 12: Graph distance vs. embedding distance on Cora with cosine similarity metric. We ran-domly sample vertexes with different distances from the training set. We obtain their representationsby feeding them into the trained GNN.
Figure 13: Graph distance vs. embedding distance on Citeseer with cosine similarity metric. Werandomly sample vertexes with different distances from the training set. We obtain their representa-tions by feeding them into the trained GNN.
Figure 14: Graph distance vs. embedding distance on PubMed with cosine similarity metric. Werandomly sample vertexes with different distances from the training set. We obtain their representa-tions by feeding them into the trained GNN.
