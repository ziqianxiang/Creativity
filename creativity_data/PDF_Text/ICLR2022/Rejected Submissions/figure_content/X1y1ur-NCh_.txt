Figure 1: Left) Blame compares an imagined normative world against reality to attribute the movementof the agent and the box to the action. Middle) Using a do-nothing action as normative world is notenough since do-nothing has an effect. Right) Causal graph of a typical RL setting.
Figure 2: CEN divides the latent space of a forward model into controlled and normal branches. Eachbranch disentangles controlled and normal effects and decodes each into pixel space independently.
Figure 3: Suite of environments used for the experiments. From left/right top/bottom: Clusters,Spiders, Lights, and Montezuma’s Revenge (MZR).
Figure 4: a) CEN can correctly disentangle the agent from the randomly moving objects. b) Clustersenvironment where CEN is able to model not just the agent but also the movement of boxes.
Figure 5: F1 score on the Lights (a) and MZR (b) environments. CEN outperforms the baseline evenin an environment with more complex dynamics and features.
Figure 6: Example masks for Montezuma’s Revenge. Additional masks are included in appendix A.2.
Figure 7: a) State visitation maps at different points of training of the Empty environment. CEN valuesdifferent locations similarly, and consequently, the agent learns to explore states more uniformly. Theinverse model encourages going to walls where predicting the action is hard. b) CEN promotes themovement of boxes and consequently faster learningAttentive Dynamics Model (ADM), an attention based method that discovers controlled elements inthe environment and rewards the agent for discovering them. This method and its extension (Songet al., 2019) showed SOTA in Montezuma’s Revenge. Badia et al. (2020b) combined control andobservational surprise to promote exploration. Their method uses an episodic memory with an inversemodel to promote the discovery of controlled effects and Random Network Distillation (Burda et al.,2018) to promote long term progress; again achieving SOTA in Atari’s hard exploration environments.
Figure 8: Ablation study on the effect of α in Eq. 6 on CEN in MZR.
Figure 9: Examples of masks for α = 0.01 and α = 20 in MZR. Masks generated by the controlledand normal branches for each α (in parenthesis) are highlighted (darker).
Figure 10: Examples of success and failure cases for CEN and ADM in MZR.
Figure 11: Examples of masks for Clusters.
Figure 12: Examples of masks for Spiders.
Figure 13: Examples of masks for Lights.
