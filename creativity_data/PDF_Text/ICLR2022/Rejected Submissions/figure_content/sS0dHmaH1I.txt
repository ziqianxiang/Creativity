Figure 1: Overview of the inference stage on a new task. (a) Adapting the task-specific dictionarywith K normal samples. (b) Sparse coding with three iterations as Eqn.6 shows. We also show abackward pass from the reconstruction error to localize the abnormal regionsof the normal sample feature is then directly used as an atom in the task dictionary. The decom-posed coefficients are α = S(z; D), where α ∈ RKh0w0×h0×w0 and S denotes the iterative sparsedecomposition process of (6). By multiplying the coefficient α with the dictionary D, we obtainthe reconstructed features z0 = Dα. The sparsity regularization to α is important, as it encouragesinput features to be reconstructed by simple combinations of dictionary atoms (normal features),so that it would be difficult for features of abnormal samples to be well-approximated, thereforeproducing higher reconstruction errors that make it conducive for detecting anomalies. From here,the final energy score is formulated as the mean squared error (MSE) between the original and thereconstructed features:Eθ(x； D) = MSE(z, z0) = ∣∣Ψ(x; θ) - DS(Ψ(x; θ); D) ||2.	(8)In effect, Eqn. 8 depicts a conditional EBM, which is conditioned on the task-specific D formed bynormal features. In the following sections, we will discuss how to make the training of this adaptivestructure more robust.
Figure 2: Illustration of sparse coding layer with l X l recep-tive filed.
Figure 3: Shrinkage functions.
Figure 4: Illustration of episodic training and (a) “learning by inpainting”.
Figure 5: Visualizations of local-ized anomaly by our method.
Figure 6: Visualizations of anomaly local-ization with video anomaly detection.
Figure 7: Loss curves with smooth(SigShrink) and non-smooth (hard-shrink RELU-like) shrinkage func-tions.
Figure A: Visualizations of anomaly localization on industrial inspection data. All results are ob-tained by adapting the model using 10 normal samples only.
Figure B:	Sampling outputs after a few steps of Langevin Dynamics starting from each synthesizednegative sample. 5 steps of Langevin dynamics are sufficient to quickly generate hard negativesamples with minor artifacts.
Figure C:	Figure from (Zhao et al., 2020). Generated sequences from the process of LangevinDynamics. Initialization from noise usually requires around 50 steps to synthesize the images withdesired quality (images are shown every 5 steps).
