Figure 1: Comparison of different density estimation frameworks. First line: the estimated densities.
Figure 2: CompariSon of different denSity eStimation frameworkS. FirSt line: the eStimated denSitieS.
Figure 3: Generative model: this figure details the application of our generative framework to theMNIST dataset. Five different algorithms were trained to estimate this distribution and learn theforward and inverse transport map between the encoded ’MNIST Distribution’ and a Gaussian. Theestimated density can be seen in the first line. The second line shows 25 samples passed through thedecoder part of the autoencoder for each of the methods.
Figure 4: PICANN architecture. We present how a combination of two ICNN networks can be usedto learn the forward and the inverse map between two distributions. Both these networks are trainedindependently with their respective loss functions. The inverse network uses the gradient of theoutput of the first network as its input.
Figure 5: HoW a combination of an autoencoder with our PICANN approach can be used to developa generative model. Note how the latent space of the autoencoder becomes the input to the PICAnNnetwork. In such a setting, the PICANN estimates the latent space density and samples from theestimated distribution. Using random samples from this distribution, one can pass them through thedecoder to generate new samples.
Figure 6: In this figure we present the convergence plots for PICANNs, W2GEN and OT-ICNN.
Figure 7: Comparison of different density estimation frameworks for a Gaussian mixture model.
Figure 8: Comparison of different density estimation frameworks. First line: the estimated densities.
