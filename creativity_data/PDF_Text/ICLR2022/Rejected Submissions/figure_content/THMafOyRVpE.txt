Figure 1: Comparison of standard online meta-learning and FOML: In standard online meta-learning (e.g.,FTML (Finn et al., 2019)), shown on the left, adaptation is performed on one task a time, and the algorithm“resets” the adaptation process at task boundaries. For example, a MAML-based method would reset the currentparameters back to the meta-trained parameters. In our approach (right), knowledge of task boundaries is notrequired, and the algorithm continually keeps track of online parameters φ and meta-parameters θ . The onlineparameters are simply updated on the latest data, and the meta-parameters are updated to “pull” the onlineparameters toward fast-adapting solutions via a MAML-style meta-update.
Figure 2: Overview of FOML learning: FOML UP-dates the online parameters φ using only the most recentK datapoints from the buffer B . Meta-learning learnsa regularizer, parameterized by meta-parameters θ , viasecond-order MAML-style updates. The goal of meta-learning is to make φ perform well on randomly sampledprior datapoints after performing K steps with the meta-trained regularizer.
Figure 3: Comparison between online algorithms: We compare our method with baselines and prior approaches,including TFS (Train from Scratch), TOE (Train on Everything), FTL (Follow the Leader) and FTML (Followthe Meta Leader). a: Performance relative to the number of tasks seen over the course of online training onthe Rainbow-MNIST dataset. As the number of task increases, FOML achieves lower error rates comparedto other methods. b: Error rates on the Online-CIFAR100 dataset. Note that FOML not only achieves lowererror rates on average, but also reaches the lowest error (of around 17%) more quickly than the other methods.
Figure 4: Ablation experiments: a) We vary the num-ber of online updates K used before the meta-update,to see how it affects the performance of our method.
