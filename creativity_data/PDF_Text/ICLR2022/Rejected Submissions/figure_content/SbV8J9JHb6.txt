Figure 1: (a) We measure sparsity as the fraction of model parameters with 0 weight. We quantifycircuit complexity as the number of non-XOR gates. The numbers are computed on a ternary neuralnetwork with a 3 × 3 convolution operation with 4 kernels and a 32 × 32 × 3 input. For thisexperiment, we assign 0 weights to a random set of parameters, to get different levels of sparsity andcorresponding number of non-XOR gates. (b) Test accuracy versus inference runtime for a ternaryneural network trained on a fixed MNIST (m1) architecture, in various scale.
Figure 2:	Inference runtime versus test accuracy of a garbled ternary model, constructed with So-TERIA architecture search algorithm, for various values of circuit cost regularization λ. We obtainthe architecture for a neural network with (a) 1 cell for MNIST dataset, and (b) 3 cells for CIFAR10dataset. Scaling factor is 3.
Figure 3:	Impact of the model’s depth (as the number of cells in the S oteria architecture search)on accuracy and inference runtime of garbled model on CIFAR10. Regularization term λ is 0.6.
