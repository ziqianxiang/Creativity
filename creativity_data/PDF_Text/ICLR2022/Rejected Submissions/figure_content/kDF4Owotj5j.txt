Figure 1: Our improved thinking network trained on 9 × 9 mazes and its solution (left two plots)autonomously synthesizes a scalable algorithm. By running this algorithm for longer, it solves 59 × 59(center) and 201 × 201 (right) mazes without retraining. Standard architectures, and even existingprimitive thinking models, fail to tolerate this domain shift.
Figure 2: Architecture schematics. Left to right: A feed-forward network, a network containing threerecurrent blocks (in green) that share weights, and a recurrent network with recall.
Figure 3: Comparison of our models, DT networks, and feed-forward models on 48-bit (left) and512-bit (right) data. Our models solve more than 99% and 97% of 48-bit and 512-bit problems,respectively. Note, the curves for prior methods coincide with the x-axis on the right. Shaded regions(in all plots like this) denote ± one standard error.
Figure 4: An ablation study showing the value of recall and progressive loss. Our models, whichhave both, outperform models with neither or only one of these improvements.
Figure 5: Test accuracy on 13 X 13 (left) and 59 X 59 (right) mazes as a function of test-time iterations.
Figure 6: Test accuracy for a variety of models demonstrating the sensitivity to the weight used in theloss computation and to the presence/absence of recall.
Figure 7: Test accuracy on harder puzzles. Left: Our models compared with baselines. Right:Accuracies of an array of models showing the importance of recall and our loss.
Figure 8: Test accuracy on 13 X 13 mazes whenfeatures are swapped after 50 iterations.
Figure 9: The change in the features when solving13 × 13 mazes. Recall keeps this quantity small.
Figure 10: Experiments to determine optimal depth and width for prefix sum models trained withprogressive loss (α = 1) and recall.
Figure 11: Prefix sum results on 1024-bit inputs.
Figure 12: Accuracy curve from a single representative model on 201 × 201 mazes. On this plot, weadd a curve to indicate what percentage of pixels that are correct to draw attention to the fact that theseemingly low performance of 74% accuracy should be understood in context. Of the 100 mazes inthe test set, 20 have one pixel (out of 161,604) wrong. No single maze has more than seven mistakes.
Figure 13: Chess performance When tested on puzzles with indices from 700K to 800K.
Figure 14: Chess performance when tested on puzzles with indices from 1M to 1.1M.
Figure 15: Test accuracy on 48-bit (left) and 512-bit (right) prefix sums as a function of test-timeiterations using the output at each iteration. The horizontal dotted lines correspond to feed-forwardmodels and coincide with the x-axis (0% accuracy) in the plot on the right. Shaded regions denote ±one standard error.
Figure 16: Test accuracy on 13 X 13 (left) and 59 X 59 (right) mazes as a function of test-timeiterations using the output at each iteration. The horizontal dotted lines correspond to feed-forwardmodels and coincide with the x-axis (0% accuracy) in the plot on the right. Shaded regions denote ±one standard error.
Figure 17: Test accuracy on chess puzzles with indices 600K to 700K as a function of test-timeiterations. ExitPrefix Sums Tested on 512-bit Strings	Mazes Tested on 59x59	Chess Tested on 600-700kIOO 200	300	400	500	150	300	450	600	750	900Test-Time Iterations	Test-Time Iterations25	50	75	100	125Test-Time IterationsFigure 18: Evolution of confidence of representative models for each dataset as iteration countincreases. Left: prefix sums, center: mazes, right: chess.
Figure 18: Evolution of confidence of representative models for each dataset as iteration countincreases. Left: prefix sums, center: mazes, right: chess.
Figure 19: Accuracy as a function of iteration for prefix sum models when generalizing from hard(32-bit strings) to easy data (24-bit strings).
Figure 20: on 13 x 13 mazes.
Figure 21: on 13 x 13 mazes.
