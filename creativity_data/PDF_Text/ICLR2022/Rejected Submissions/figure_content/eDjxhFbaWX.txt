Figure 1: The hardness degree histograms of CIFAR10 and CIFAR100 test samples forDenseNet121, ResNet18, and MobileNet classifiers.
Figure 2:	The hardness degree histograms of samples of four various model extraction attacks forCIFAR10 and CIFAR100 target classifiers. The budget of model extraction attacks is 50000.
Figure 3:	(a) Visualization of CIFAR10 test samples. (b) Hardness of CIFAR10 test samples forCIFAR10 classifier. (c) Hardness of CIFAR10 test samples for CIFAR100 classifier.
Figure 4: The left histogram in subfigures a and b shows the hardness degree histogram of CUB200and Caltech256 test samples, respectively. The right histogram in each subfigure indicates the hard-ness degree histograms of K.Net ILSVRC12 attack samples on CUB200 (a) and Caltech256 (b)target classifiers.
Figure 5: The detection rate of HODA for various percentages of normal samples Pn over differentvalues of nums.
Figure 6:	Blue and red bars show the percentage of test samples in each range of hardness de-grees, which are correctly or wrongly classified, respectively. For each range of hardness degrees,Data Percentage indicates the percentage of CIFAR10 and CIFAR100 test samples whose hardnessdegrees are in that range.
Figure 7:	The hardness degree histograms of samples of four various model extraction attacks onCIFAR10 and CIFAR100 target classifiers. The budget of model extraction attacks is 50000. Thearchitecture of target classifiers is DenseNet121.
Figure 8:	(a) Visualization of CIFAR100 test samples. (b) Hardness of CIFAR100 test samples forCIFAR100 classifier. (c) Hardness of CIFAR100 test samples for CIFAR10 classifier.
Figure 9:	The histogram of Pearson distance between Hn and 10000 benign users’ hardness degreehistogram and Hn and 10000 adversaries’ hardness degree histogram for various attacks. STL10users are benign users for CIFAR10 target classifier and are adversaries for CIFAR100 target classi-fier.
Figure 10:	The hardness degree histograms of samples of four various adversarial example attackson CIFAR10 and CIFAR100 target classifiers. Each attack uses 10000 natural samples in the test setassociated with the target classifier dataset to create 10000 adversarial examples.
Figure 11:	The accuracy and the fidelity of four surrogate classifiers over various hardness groups.
