Figure 1: Regression loss as a function of fittingloss during training, comparing an uninformedprior with a dynamic prior.
Figure 2: Comparison of a differentiable SBL-constrained model and an non-differentiable OLS-constrained model on a Korteweg-de Vries dataset (panel a) with a library consisting of 4th orderderivatives and 3rd order polynomials, for a total of 20 candidate features. In panel b and c werespectively plot the inferred prior A and the posterior coefficients Î¼. In panel d We show the non-differentiable DeePyMod approach. In panels b and c we see that the correct equation (bold blueline: uxx , bold orange line: uux) is discovered early on, while the non-differentiable model (paneld) selects the wrong terms.
Figure 3: Exploration of robustness of SBL-constrained model for model discovery for the Burgersequation (panel a). We show the discovered equation over a range of noise for DeepMoD (panel b)and the approach presented in this paper (panel c). The bold orange and blue lines denotes uxx anduux , and black dashed line their true value.
Figure 4: Recovering the Kuramoto-Shivashinsky equation. We show the chaotic data and a crosssection in panels a and b. The periodicity makes this a challenging dataset to learn, requiring 200kiterations to fully converge before it can be recovered (panel c). Panels d and e show that theposterior and MLE of the coefficients yield nearly the same coefficients, indicating that the networkwas able construct an extremely accurate approximation of the data.
Figure 5: Using a tempo-spatial Normalizing Flow constrained by Sparse Bayesian Learning todiscover the advection-diffusion equation directly from single particle data. Panel a shows the truedensity profile, and in panels b c and d we show the density inferred by binning (blue bars), inferredby NF (red) and the ground truth (black, dashed) at t = 0.1, 2.5, 4.5. Note that although the estimateof the density is very good, we see in panel e that we recover two additional terms (bold blue line:ux, bold orange line uxx .
