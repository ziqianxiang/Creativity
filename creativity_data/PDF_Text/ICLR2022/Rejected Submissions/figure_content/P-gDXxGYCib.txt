Figure 1: Visualizing CFS applied to the Grassy MNIST dataset to select k = 20 features.
Figure 2: Data generating processes for target and background samples. Background latentvariables z are common to the two processes. A second set of salient latent variables s are used togenerate target points, while these variables are fixed for background points. The salient variables(and not the background variables) are used to generate labels y for target points. Observed valuesare shaded, and square nodes represent constant values.
Figure 3: CFS model architecture. Here we illustrate the general architecture of CFS-based meth-ods for feature selection. We use our background dataset to learn an embedding function gz thatonly captures variations due to the latent variables z that are present in both the background andtarget datasets. We also train a concrete selector layer to select features that best reflect the salientlatent variables used to generate target points. This selector layer is trained along with a reconstruc-tion function fθ that is trained to reconstruct target data points using the concatenation of the outputof gz and the features selected by our gates, and to reconstruct background data points using theconcatenation of the output of gz and a zero vector. Here xS refers to a target sample restricted tothe set of features S .
Figure 4: Downstream classification accuracies and sensitivity analyses of CFS on GrassyMNIST: (a): We quantitatively assess the quality of each method’s selected features by trainingan extremely randomized trees classifier (Geurts et al., 2006) to classify Grassy MNIST images bytheir digit class using varying numbers of selected features k. We report mean accuracies over fiveinitializations, and error bars correspond to standard deviation. For all tested values of k, we findthat our Pretrained and Gates CFS models outperform state of the art unsupervised feature selectionalgorithms. (b): We fix k = 20 and vary the size of each CFS variant’s background representation tounderstand how this hyperparameter impacts feature quality. Our Pretrained and Gates CFS varia-tions continue to outperform baseline methods for all background representation sizes. (c): We varythe relative contribution of grass noise to the dataset and assess the performance of each methodwhen used to select k = 20 features.
Figure 5: Quantifying disentanglement of background and salient variations. (a): We trainmultilayer perceptrons to reconstruct background samples using the target features selected by eachCFS variant. A method that successfully disentangles target and background variations should resultin higher reconstruction error on this task. (b): We train multilayer perceptrons to reconstruct targetsamples using each CFS variant’s background representations. Once again, higher reconstructionerror corresponds to better disentanglement.
Figure 6: Applying fully unsupervised feature selection methods to Grassy MNIST: (a): Wemeasure the quality of features selected by fully unsupervised methods as done in Figure 4a. Wefind that the concrete autoencoder (CAE) performs the best out of our baseline methods. (b): We fixthe number of features k = 20, vary the ratio of noise to digit when constructing Grassy MNIST,and then evaluate the quality of selected features by each unsupervised baseline as in Figure 4c.
Figure 7: Additional visualizations of Grassy MNIST results. Here we provide visualizationsof the features selected by each of our baseline unsupervised feature selection methods when runto select k = 20 features. We find that our non-spectral-information-based methods tend to pickfeatures that are diffused around the images, with many selected features being close to the edgeswhere digits are never present. On the other hand, our spectral-information-based methods (c, d)tend to select localized clusters of features, which (as demonstrated by our quantitative results), donot capture enough variations to successfully classify images based on digit.
