Figure 1: Prompt engineering vs. context optimization (CoOp). The latter uses only 16 shots forlearning in these examples.
Figure 2: Overview of context optimization (CoOp).
Figure 3: Main results of few-shot learning on the 11 datasets. Overall, CoOP effectively turnsCLIP into a strong few-shot learner (solid lines), achieving significant improvements over zero-shotCLIP (stars) and performing favorably against the linear probe alternative (dashed lines). M denotesthe context length. “end” or “mid” means putting the class token in the end or middle. CSC meansclass-specific context.
Figure 4: Comparison with hand-crafted prompts.
Figure 5: Investigations on CoOp's context length and various vision backbones.
Figure 6: Dataset-specific results of using different context lengths for CoOp.
Figure 7: Results on the 11 datasets using a variety of vision backbones.
