Figure 1: In SymmToM, agents aim to gain all the information available (depicted as diamonds,black for known information, white for unknown). Since hearing is limited to its neighbor cells,they must guess what happened beyond this range. Agents can see the whole grid, but even then,mistakes in inferences may happen (as it did in this example to the red agent).
Figure 3: Example of tests for zeroth, first, second order, and probabilistic ToM. We test red agents,immobilize gray agents, and control blue and green agents’ movements. In Fig. 3a, red will go tothe top right if it remembers to have heard the first piece, and to the left otherwise. In Fig. 3b, redwill move to the right if and only if it assumes that the two agents on the left played optimally (redcannot hear what they communicated). In Fig. 3c, blue is controlled to ensure it will search the agenton the bottom left (its optimal play, in five moves). Red’s optimal move is to meet blue, and hencemust only move to the bottom left, even if the agent currently there will not provide any reward. InFig. 3d, red will interact with green not knowing what it communicated with blue in the previousturn. It should be able to communicate the missing piece with an expected value of 1.5 turns.
Figure 4: Depictions of rescaled tests from Figure 3, designed to match some of the parametercombinations already experimented on.
Figure 5: Average episode rewards throughout training for 60000 episodes for all combinations ofa ∈ {3, 4}, w = 6, and c ∈ {a, 2a, 3a}.
Figure 6: Average episode rewards throughout training for 60000 episodes for all combinations ofa ∈ {3, 4}, w = 12, and c ∈ {a, 2a, 3a}.
