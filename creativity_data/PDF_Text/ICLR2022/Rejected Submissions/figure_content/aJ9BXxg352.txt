Figure 1: Motivating toy experiment. The constant σ = 0.6 and the input-dependent σ(x) equalin average to the constant σ are used. Left: Dataset and the variance function depicted as circleswith the radius equal to σ(x) and centers at the data points. Middle: Zoomed in part of the datasetand decision boundaries of the smoothed classifiers with constant σ (red) and input-dependent σ(x)(green). Note that we recover a part of the misclassified data points by using a more appropriatesmoothing strength close to the decision boundary. Right: Certified accuracy plot. The waterfalleffect vanishes since the points far from the decision boundary are certified with a correspondinglylarge σ(x).
Figure 2: Decision regions of the worst-case classifier f *. Left: σ0 > σ1 Right: σ0 < σ1As we depict on Figure 2, both resulting balls are centered on the line connecting x0, x1. Moreover,the centers of the balls are always further from x0, than x1 is from x0 (even in the case σ0 < σ1).
Figure 3: Plots depicting tightness of results of Theorem 4. On both figures, the biggest possiblethreshold of σι∕σ0 for which the condition in Theorem 4 is satisfied (theoretical threshold) and thenumerically computed threshold for which ξ> (0) passes the threshold 0.5 (practical threshold) aredepicted. Left: Plot for pA = 0.9, Right: Plot for pA = 0.999.
Figure 4: Comparison of certified accuracy plots for CohenCIFAR-10, main comparison, σ= 0.50-----Cohen σ = 0.50, r=0.00j rtr = 0.0—Us σ= 0.50, r=0.01, σtr = 0.53(2019) and our work.
Figure 5: The toy dataset.
Figure 6: The ratio between certified radius if using lower confidence bounds and if using exactvalues for the case of linear boundary.
Figure 7: Left: Certified radius as a function of distance in linear boundary case. The truncationis due to the use of lower confidence bounds. The parameters are n = 100000, α = 0.001, σ = 1.
Figure 8: Results of certification on toy dataset. Left: Certified accuracy for different levels of σ.
Figure 9: Heatmaps and decision boudnary of base classifier (top left) and the smoothed classifierfor increasing levels of σ. As σ increases, the classifier is more smooth and the decision boundaryrecedes.
Figure 10: Certified accuracy plots of our multidimensional toy experiments.
Figure 11: The certified radius as a function of dimension. Paremeters are pA = 0.99, σ0 = 1, σ10.8Theorem 15. Denote RC to be a certified radius given for pA and σ0 at x0 assuming the constantσ0 and following the certification of Cohen et al. (2019) 1. Assume, that we do the certification foreach x1 by assuming the worst case-classifier as in Theorem 2. Then, for any x0, any function σ(x)and any pA, the following inequality holds:R ≤ RCProof. Fix xi and σ> From Theorem 2 we know that the worst-case classifier f * defines a ball Bsuch that P0(B) = 1 - pA. From this it obviously follows, that the linear classifier fl and the linearspace Bl that assume constant σ0 also for x1 and is the worst-case for σ0 such thatP0(Bl) = 1 -pAis not worst-case for the case of using σ1 instead. Therefore, P1(Bl) ≤ P1(B).
Figure 12: Plots ofξ>(a), ξ<(a) for different setups. Coding for parameters is: [σ0, σ1, N, pB] Top:ξ>(a) left, ξ<(a) right, varying values of N. Center: On the left, ξ> (a) for varying σ1, on the rightξ>(a) for varying pB. Bottom: ξ>(a) and ξ<(a) compared.
Figure 13: Comparison of certified radius as a function of distance for constant and input-dependentsmoothing. Left: σb = σ = 0.12, right: σb = σ = 0.50.
Figure 14: The theoretical certified radius as in Expression 2. The function is monotonically in-creasing on interval [0, 100] and will further be increasing too.
Figure 15: Well and ill working functionplot_real_probability_of _a_ball_with_fixed_variances_as_fcn_of-dist,which computes the ξ functions. The coding is [σ0, σ1, N, pA].
Figure 16: Comparison of certified accuracy plots for Cohen et al. (2019) and our work. For eachplot, the same base model f is used for evaluation.
Figure 17: Comparison of certified accuracy plots for Cohen et al. (2019) and our work, MNIST.
Figure 18: The certified accuracies of our procedure on CIFAR10 for σb = 0.12, 0.25, 0.50, rater = 0.01 and training rate trr = 0.0, 0.01, 0.04, 0.1.
Figure 19: The variance of evaluation. Parameters are σb = 0.50, r = 0.01, trr = 0.0, the evaluatedmodel is the same for all runs. There are 7 runs on CIFAR10.
Figure 20: The certified accuracies of our procedure on CIFAR10 for σb = 0.12, 0.25, 0.50, rater = 0.01 and training rate trr = 0.0 evaluated on 9 different trained models for each of the setups.
Figure 21: The certified accuracies of our procedure on CIFAR10 for σb = 0.12, 0.25, 0.50, rater = 0.01 and constant, yet increased Cσb training variance, compared to certified accuracies ofthe constant σ method for σ = σb = 0.12, 0.25, 0.50 and also σ = Cσb = 0.126, 0.265, 0.53.
Figure 22: The certified accuracies of our procedure on MNIST for σb = 0.12, 0.25, 0.50, rater = 0.01 and constant, yet increased Cσb training variance, compared to certified accuracies ofthe constant σ method for σ = σb = 0.12, 0.25, 0.50 and also σ = Cσb = 0.124, 0.258, 0.517.
Figure 23: The certified radiuses on CIFAR10 of the non-constant σ(x) method with rate r = 0.01,but different training strategies. Used training strategies are input-dependent training with the sameσ(x) function and constant-σ training with either σb or Cσb variance level. Evaluations are beingdone from single run.
Figure 24: The certified radiuses on MNIST of the non-constant σ(x) method with rate r = 0.01,but different training strategies. Used training strategies are input-dependent training with the sameσ(x) function and constant-σ training with either σb or Cσb variance level. Evaluations are beingdone from single run.
