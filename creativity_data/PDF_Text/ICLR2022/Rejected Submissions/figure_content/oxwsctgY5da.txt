Figure 1: A branch and bound searchtree. Each node represents a subdomaindetermined by S, and the numbers areLB(S). No adversarial example exist inthe subdomain if LB(S) > 0 (green).
Figure 2: Overview of BaB attack.
Figure 3: Beam search: we select Ksubdomains probabilistically accord-ing to LB(S), and expand the searchtree by D levels using bound propaga-tion on GPU.
Figure 4: We dive the search tree withadditional constraints constructed bycommon adversarial patterns to greatlyreduce top-down sub-MIP search space.
Figure 5: In bottom-up search, we freesome fixed integer variables at a leafnode (an adversarial candidate) search-ing its neighborhood in activation space.
Figure 6: For examples that all attacks failed, we compare the minimum margin between the ground-truthlabel and all other target labels for the adversarial candidate. A smaller margin is better. Our attack achievesnoticeably smaller margins compared to other attacks (margins from other attacks are below the y = x line).
Figure 7: Running time vs. num-ber of attacked images compared toMIP attack.
Figure 8: Running time vs. number of attacked images compared to MIP attack on five models.
