Figure 1: Chinese and European annotations, thered bar represents the score of Asian, the blue barrepresents the score of European faces.
Figure 2: AestheticNet is trained on Germanor Chinese annotations only. The trained net-work follows the bias from the annotations.
Figure 3: The architecture of AestheticNet is based on the VGG Face architecture and is expandedby two separate skip connections. At the end, the predictions of the differently convoluted featurevectors are added together.
Figure 4: StarGAN v2 generated Eurasians. From left to right: 90%, 80%, 70%, 60% European,half/half, 60%, 70%, 80% 90% AsianThe synthesised Eurasians images are artificially generated with StarGAN v2 (Choi et al., 2020)to determine the influence of the biased view of annotators on aesthetics of persons from differentethnicities. We used different customised input for the source and reference images to control theamount of ethnic admixture. Figure 4 shows one exemplary set of images for the Eurasians dataset.
Figure 5: Unconscious bias towards ethnic aesthetic of either German or Chinese annotators. Left:average aesthetic score on SCUT-FBP by German annotators, middle: average aesthetic score labelledby Chinese students, right: aesthetic scores on the Eurasian dataset annotated by German students.
Figure 6: Biased correlation between attractiveness, age and ethnicity by German annotators. Inan ethical, fair network the attractiveness for equal age groups would be the same. This would berepresented in the figure by the same height of the lines for equal age groups.
Figure 7: FBP with same amount of Asian andGerman labels. Ratio = 1.0 stands for the sameweight ω for German and Asian annotations.
Figure 8: Correlation of the bias over the ratio ofGerman and Chinese annotations. The least biashere is at the ratio of 1.9In this experiment, balancing the training data means to find the minimum by concatenating theGerman annotated subset g with the weighted ω Chinese annotated subset c. The goal in this approachis to level the average aesthetic scores g and C for the generated predictions gi and c%. The networkbias B is then defined by1nB = 2n +1 £|g - gi| + ω |c- ci∖.	⑴i=0Starting from a ratio of 1:1, in which German and Chinese annotations are distributed equally, wegradually increase the weight of the Chinese annotations. Technically, the balancing of distribution ofthe training data is done with a factor based approach. First, the ratio between Chinese and Europeanannotations are calculated. Secondly, the factor for the balanced distribution is determined in astochastic approach. In our experiment we varied the ratio from 2:1 to 1:3.2 for German annotationsto Chinese annotations. Each training step and the corresponding bias over the ratio is shown infig. 8. Determining the minimum in fig. 8 is equal to finding the least biased network. It is visiblethat a ratio of 1:1.9 produces the least biased network for this experiment and its results are shown infig. 9. This means the Chinese annotations are weighted nearly double the amount than the Europeanannotations.
Figure 9: CNN aesthetic prediction with equalised distribution of training data. The charts on the leftside show the prediction of the network if it is only trained on Chinese or German annotations. Onthe right side, the prediction of the network, which was trained on the biased data is shown. All barshave more or less the same height and only differ minimally. This means, that we could eliminatemost of the bias in the training data, by balancing and we can assume that this trained network is fair.
Figure 10: Effect of different ratios on the output of the network.
