Figure 1: Illustration for translation-oriented language models. X and Y denote source and target input, respec-tively. To enable translation, We adapt the LM self-attention mask to either the PrefixLM mask or CausalLMmask (top right), where filled black circles indicate disallowed attention. We also explore top-only encoding(Top Encoding) for PrefixLM which feeds the final-layer source encodings to generation similar to EncDec,rather than layer-wise coordinated encodings (He et al., 2018). Masks of EncDec are shown in the bottom rightfor comparison.
Figure 2: Fitted scaling curves (toP) and BLEU scores (bottom) for different models on WMT14 En-Fr (left)and WMT19 En-Zh (right) tasks. Top: dashed and solid fitted curves are for LM + Deep and LM + Wide,resPectively. We rePresent the EncDec scaling with bold solid curve. Bottom: dashed curve denotes the BLEUscores of EncDec as a function of model Parameters for reference. Markers in circles are for CausalLM variants.
Figure 3: Fitted scaling exponent (p, left) and irreducible loss (L∞, right) over different evaluation settings onWMT14 En-Fr (En→Fr). All: the whole test set; Src Orig, Tgt Orig: source-original and target-original test set,respectively; Short, Medium, Long: shortest, medium and longest 〜376 samples from the test set, respectively.
Figure 4: Fitted scaling curves for different models on WMT14 En-Fr and WMT19 En-Zh in term of FLOPs.
Figure 5: Fitted scaling curves for different models on Web En-De (En→De). src/tgt: source/target; Web:in-domain evaluation set. Models are trained in the Transformer big setting.
Figure 6: Cross-lingual transfer results (average BLEU scores) for different models from high-resource lan-guages to the low-resource one (En-De) under different model sizes on WMT datasets. Average is performedover En→De and De→En evaluation. Left: multilingual En-De-Fr system; Right: multilingual En-De-Zhsystem. Both systems are many-to-many models. Models are trained in the Transformer base setting.
Figure 7: Zero-shot transfer results of different models for multilingual many-to-many modeling on fourlanguages (En-De-Fr-Zh) under different model sizes. Top: average BLEU scores; Middle: average PPLscores; Bottom: average translation language accuracy scores. In-domain: WMT test set; Out-of-domain:in-house sport-domain test sets.
Figure 8:	Fitted scaling curves for different models on WMT14 En-Fr and WMT19 En-Zh on the longestsentence group. We rank our test set according to source sentence length, and then split it into 8 disjointgroups. This shows the results on the longest group.
Figure 9:	Fitted scaling curves for different models on WMT14 En-Fr and WMT19 En-Zh with respect tothe number of layers. Note under the same number of layers, LM + Deep has much fewer parameters thanEncDec and LM + Wide. The performance gap also narrows as model scales up.
Figure 10:	Fitted scaling curves for different models on WMT14 En-Fr and WMT19 En-Zh evaluated onsource original and target original test sets.
Figure 11:	BLEU scores for different models on WMT14 En-Fr and WMT19 En-Zh as a function of sourcesentence length. Left: models aligned with 6-layer EncDec; Right: models aligned with 14-layer EncDec.
Figure 12: Fitted scaling curves for different models on Web En-De (En→De). src/tgt: source/target; WMT:out-of-domain evaluation set; Web: in-domain evaluation set. Models are trained in the Transformer big setting.
Figure 13: Fitted scaling curves for different models on Web En-De (En→De) in terms of FLOPs. Models aretrained in the Transformer big setting.
Figure 14: BLEU scores for different models on Web En-De (En→De) as a function of model parameters.
Figure 15: Cross-lingual transfer results (average BLEU scores) for different models from the low-resourcelanguage (En-De) to high-resource directions under different model sizes on WMT datasets. Average is per-formed over EnoFr/Zh. Left: multilingual En-De-Fr system; Right: multilingual En-De-Zh system.
Figure 16: Absolute (top) and relative (bottom) transfer results of different models for En→Fr and En→Zhunder different models sizes on WMT datasets. Left: multilingual En-De-Fr system; Right: multilingual En-De-Zh system. Relative score is computed by comparing multilingual model and its corresponding bilingualcounterpart. Overall, there is no clear pattern supporting that LMs encourage knowledge transfer better thanEncDec.
