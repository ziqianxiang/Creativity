Figure 1: Overview of the Conventional and Agnostic Personalized Federated Learning: Left illustratesthe conventional federated learning. Middle represents label heterogeneity where labels are not synchronizedwith others. Right shows the multi-domain scenario where each local client learns K different datasets.
Figure 2: Illustration of Similarity Matching and Kernel Factorization: We match relevant clients based onthe model embeddings obtained from the criteria input. Then we reflect the relevant knowledge based on thesimilarity. Our kernel weights are factorized to reduce the dimensionality of parametersis that we can identify those helpful models if we can recognize task-level similarity, as Yoon et al.
Figure 3:	Per-client Performance and Embeddings Space for Local Knowledge: (a) we show bar plot forthe per-client performance comparison. (b) we visualize 2,000 latent embeddings locally learned knowledge(100 Criteria Inputs for 20 Clients). The labeled number is correspondent client id (and also dataset in Table 2)(a) Inter-client Similarity (r=1)(b) Inter-client Similarity (r=50)(c) Inter-client Similarity (r=100)Figure 4:	Inter-Client Similarity: We visualize inter-client similarity at (a) the beginning with r=1, (b) middlewith r=50, and (c) the end with r=100 of 100 training rounds in total.
Figure 4:	Inter-Client Similarity: We visualize inter-client similarity at (a) the beginning with r=1, (b) middlewith r=50, and (c) the end with r=100 of 100 training rounds in total.
