Figure 1: Localized randomized smoothing applied to semantic segmentation. We assume that themost relevant information for labeling a pixel is contained in other nearby pixels. We partition theinput image into multiple grid cells. For each grid cell, we sample noisy images from a localizedsmoothing distribution that applies more noise to far-away, less relevant grid cells. Segmenting allnoisy images using base model g, cropping the result and computing the majority vote (i.e. the mostcommon label for each pixel) yields a local segmentation mask. These per-cell segmentation maskscan then be combined into a complete segmentation mask.
Figure 2: Certified ratios of U-Net models un-der varying e. We compare the naive i.i.d. base-line (σ = 0.4) to localized smoothing (σmin =0.25, σmax = 1.5). Combining the base certifi-cates via linear programming (solid orange line)instead of evaluating them independently (dottedorange line) outperforms the baseline.
Figure 3: Certified accuracy for an APPNP model under varying number of attribute additions (left)and deletions (right). We compare localized smoothing (θm+in = 0.05, θm-in = 0.65, θm+ax = 0.08,θr-ax = 0.95) to two separately optimized naive i.i.d. smoothing baselines: addition (θ+ = 0.04,θ - = 0.61) and deletion (θ+ = 0.04, θ- = 0.68). Combining the localized smoothing basecertificates via linear programming (solid orange line) instead of evaluating them independently(dotted line) allows us to outperform the baselines for most adversarial budgets.
Figure 4: Trade-Off between accuracy and certifiably robustness at the example of the naive collec-tive certificate and certified ratio AUC. Increasing the standard deviation σ strengthens the certifi-cate, but decreases the accuracy.
Figure 5:	Certified ratios of U-Net models under varying adversarial budgets e. We compare thenaive i.i.d. smoothing baseline (with standard deviation σ) to localized smoothing (with param-eters σmin , σmax such that the locally smoothed model has a higher or equal accuracy). Com-bining the localized smoothing base certificates using the proposed linear program (solid orangeline) instead of evaluating them independently (dotted orange line) yields stronger guarantees. Forσ ∈ {0.3, 0.4, 0.5}, the localized smoothing certificate outperforms the baseline for all e.
Figure 6:	Certified accuracies of U-Net models under varying adversarial budgets . We comparethe naive collective certificate baseline (with standard deviation σ) to localized smoothing (withparameters σmin , σmax such that the locally smoothed model has a higher or equal accuracy). Com-bining the localized smoothing base certificates using the proposed linear program (solid orangeline) instead of evaluating them independently (dotted orange line) yields stronger guarantees. Forσ ∈ {0.3, 0.4, 0.5}, the localized smoothing certificate outperforms the baseline for all .
Figure 7:	Certified ratios of U-Net models under varying adversarial budgets . We compare thecenter smoothing baseline (with standard deviation σ) to localized smoothing (with parametersσmin , σmax such that the locally smoothed model has a higher or equal accuracy). For = 0,center smoothing has higher certified ratios, i.e. it abstains at a lower rate. For σ = 0.2, the centersmoothing certified accuracy curve has a higher AUC than both the naive combination of localizedsmoothing certificates (dotted line) and the proposed collective certificate (solid line). But for otherσ localized smoothing outperforms center smoothing. The gap widens with increasing σ.
Figure 8:	Certified accuracies of U-Net models under varying adversarial budgets . We comparethe center smoothing baseline (with standard deviation σ) to localized smoothing (with parametersσmin , σmax such that the locally smoothed model has a higher or equal accuracy). Combining thelocalized smoothing base certificates using the proposed linear program (solid orange line) insteadof evaluating them independently (dotted orange line) yields stronger guarantees. The gap betweencenter smoothing and localized smoothing widens with increasing σ.
Figure 9: Certified accuracy for varying number of attribute additions (left) and deletions (right)for the GCN model. We compare localized smoothing (θm+in = 0.075, θm-in = 0.6, θm+ax = 0.15,θm-ax = 0.95) with sparse smoothing with (θ+ = 0.085, θ- = 0.609) for addition and deletion.
Figure 10: Certified accuracy for varying number of attribute additions (left) and deletions (right) forthe APPNP model. We compare localized smoothing (θm+in = 0.0075, θm-in = 0.65, θm+ax = 0.08,θm-ax = 0.95) with sparse smoothing with (θ+ = 0.0085, θ- = 0.827) for addition and (θ+ =0.007, θ- = 0.755) for deletion. These configurations yield the largest certified accuracy curve AUCof 5.62 for addition and 14.29 for deletion compared to all combinations θ+ ∈ {0.007, 0.0085, 0.01}and θ- ∈ [0.1, . . . , 0.827]. In the deletion scenario we outperform the baseline with an AUC of18.76 (14.86 non-collective). However, the sparse smoothing performs better for addition than ourcertificate which only yields a AUC of 3.39 (2.54 non-collective). We observe that the optimalparameters for addition are both significantly larger than our minimal ones.
Figure 11: Comparison of the variance certificate with sparse smoothing. In this approach we onlyused one cluster, i.e., use the same noise levels. Left we can see the results for an APPNP model andon the right for a 6-layer GCN. The models are trained with the same noise parameters θ+ = 0.01and θ- = 0.6. We observe that in for both models the variance certificate yields better results fordeletion. However, in the addition setting, it is outperformed by the baseline.
