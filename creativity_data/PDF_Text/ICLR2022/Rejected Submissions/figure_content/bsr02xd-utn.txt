Figure 1: Illustration of label distribu-tion shift in DomainNet dataset.
Figure 2: Illustration of aninterpolated adversarial sam-ple, which lies on the inter-polated line of the source andtarget samples.
Figure 3: Illustration of generation of adversarial samples(a) without centroid alignment and (b) with centroid align-ment. In (a), adversarial samples have a larger chance toviolate the decision boundary.
Figure 4: Illustration of our framework based on PAT and MDD. It includes a feature extractor G,an optimal classifier F , and an auxiliary classifier F0. The dashed line represents the data flow inpairwise adversarial training. The margin disparity discrepancy of two domains is diminished byaligning the two one-hot labels. We also explicitly align the pair of class conditioned samples byminimizing the distance of the centroids denoted as LCA .
Figure 5: Biased label distributionshift on Amazon→Webcam fromimbalanced Office-31.
Figure 6: Average accuracy of our model with: (a) varyingα when β = 0.05, and (b) varying β when α = 0.5 onRw→Pr in imbalanced Office-Home.
Figure 7: Per-class average accuracy of our model with different number of iterations.
