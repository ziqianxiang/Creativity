Figure 1: The statistical heterogeneity of spurious features leads to diverse gradients. The statisticalheterogeneity leads to a global ML model with a low accuracy disparity in a federated learningsetting because the aggregation step in the central server averages out the gradients resulted fromlocal spurious features.
Figure 2:	Datasets with spurious features. The object color spuriously correlates with the label inMNIST (a) and Coil20 (c) datasets. The hair color spuriously correlates with gender in the CelebAdataset (b).
Figure 3:	The accuracy of ML models on Biased Dataset and Bias-Conflicting Dataset undercentralized and federated training settings. In the centralized setting, an ML model is trained by asingle dataset that contains all the samples with a fixed spurious correlation. The global models in thefederated setting achieve smaller accuracy disparities between biased and bias-conflicting datasets.
Figure 4: The accuracy of personalized model on Biased Dataset (ACC-B) and Bias-ConflictingDataset (Acc_BC) with increasing fine-tuning batches. The personalized models entangle spuriousfeatures and increase accuracy disparities between biased and bias-conflicting datasets.
Figure 5: The accuracy disparity of personalized models on biased dataset and bias-conflicting dataset(Acc_B - Acc_BC) and their accuracy on adversarial examples (Acc_Adv). As the personalized modelsentangle spurious features and increase the accuracy disparity, the accuracy of the personalized modelson adversarial examples increases, which indicates the adversarial transferability between the globaland personalized models decreases.
Figure 6: The accuracy disparity (Acc_B - Acc_BC) and adversarial transferability accuracy(Acc_Adv), and the loss disparity (Loss_BC - Loss_B) and adversarial transferability loss(MAX_Loss_Adv - Loss_Adv) with different methods. Combining the two proposed methods ad-dresses the accuracy and loss disparities. Acc_BC/Loss_BC and Acc_B/Loss_B are the accuracy/losseson the bias-conflicting and biased test sets, respectively. Acc_Adv/Loss_Adv is the accuracy/loss onadversarial examples. Acc-AdV and MAX_Loss_Adv - Loss_Adv, which measures the decrease ofLoss_Adv, indicate the decrease of adversarial transferability.
Figure 7:	With the L2 regularization term, the distribution of γ is centered around 1, with a smallvariance. The minimum of γ is closer to 1.
Figure 8:	The up-weighting method is less effective, resulting in large accuracy disparity of personal-ized model on biased dataset and bias-conflicting dataset, if the bias-conflicting samples is generatedby a small number of biased data samples using a small sampling factor and a large up-weightingfactor. The up-weighting factor is set to be the reciprocal of the sampling factor.
