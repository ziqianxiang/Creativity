Figure 1: Compare AWP models on a linearly separable dataset with different perturbation strengthsρ. The accuracy of models (a) to (d) is 0.97, 0.97, 0.69, and 0.48 respectively. The face color of eachnode shows its prediction score and the border color shows its ground-truth label. Grey lines connectthe node with its nearest neighbours in the graph. For large values of ρ the model is unable to learn.
Figure 2: Learning curves for GCN andGCN+AWP with different P.
Figure 3: Linearly separable dataset, ρ = 2.5. The accuracy of models (a) to (d) is 0.97, 0.51, 0.96,and 0.98 respectively. The face color of each node shows its prediction score and the border colorshows the ground-truth label. Grey lines connect the node with its nearest neighbours in the graph.
Figure 4: Comparison of the averaged gradient norm w.r.t. the adjacency matrix and the node featuresfor GCN models with and without WT-AWP on Cora and Citeseer. Each connected pair of pointsrefers to a GCN and a GCN+WT-AWP model trained with the same data split and initialization.
Figure 5: Loss landscape.
Figure 6: Robustness guarantees on Cora. WT-AWP improves the certificate for node features.
Figure 7: Comparing AWP models on a linearly separable dataset with different ρ values.
Figure 8: Model comparison on the two moons dataset, ρ = 0.4(c) T-AWP	(d) W-AWP, λ = 0.9In Fig. 8(b) we can see the model suffers from vanishing gradients, while the model with truncatedAWP works well (Fig. 8(c)). Besides, comparing to the overfitted natural model (Fig. 8(a)), thetruncated AWP model has a smoother decision boundary. We also remove the weight perturbation onthe middle or the first layer and train the model correspondingly, the results are similar to Fig. 8(c).
Figure 9: Learning Curves and Generalization Gap During Training.
Figure 10: Certified adversarial robustness on the Citeseer dataset.
Figure 11: Norm of Gradient during training.
