Figure 1: For intelligent and embodied agents, understanding the daily objects requires the ability toperceive not only object category but also attributes and affordance. Thus, in OCL, We try to revealobject concept learning in both three levels and explore their profound causal relations.
Figure 2:OCL construction. a) Data collection. b) Annotating category-level attributes and affor-dances. C) Annotating instance-level attributes and affordances. d) Finding direct causal relations.
Figure 3: OCL examples. Causal relations between α (red), β (blue) in various contexts are listed.
Figure 4: OCL causal graph. I is object appear-ance. I, α, β are the instantiations of O, A, B.
Figure 5: The overview of OCRN. The edge from O to I is deconfounded. Thus we can eliminate thebias from the O imbalance. Equations below the graphs are the estimations of α, β w/ or w/o do(∙).
Figure 6: TDE performance of different [αp, βq].
Figure 9:	Super-categories of objects in OCL.
Figure 10:	Word clouds of categories, attributes, and affordance (by positive frequencies in OCL).
Figure 11: A running example of dataset construction.
Figure 13: Age information ofannotators.
Figure 12: Distribution of normalized object box width (left) and height (right).
Figure 14: Major information Figure 15: Degree informationof annotators.
Figure 19: Attribute condi-tioned affordance matrix.
Figure 20: Attribute-affordancecorrelation matrix.
Figure 21: Attribute-affordancecausality matrix.
Figure 22: Clustering using attribute and attribute-affordance labels.
Figure 23: Top-50 object categories with largest ratio of difference between category- and instance-level labels.
Figure 24: More OCL samples of objects.
Figure 25: More OCL samples of attributes and affordancesAffordanceStouch √PUll ×chase ×drive ×lift √load ×eat ×cook √wash ×wash ×cook √kick Xdrive ×check √drag ×F∙'igure 26: More OCL samples. We present objects in different states, together with their key at-tributes and affordances.
Figure 27: More OCL samples of direct causal relations18000Moreover, in α-β-TDE, P(αp = GTαp) means that the probabilities of predicted P(αp) accordswith the label GTαp. In detail, if GTαp = 1, then P(αp = GTαp) = P(αp); if GTαp = 0, thenP(αp = GTαp) = 1 -P(αp), where P(αp) is the model prediction. P(βq = GTβq) is similar. Thatsaid, if GTeq = 1, then P(αp = GTeq) = P(βq); if GTeq = 0, then P(βq = GTeq) = I - P(βq).
Figure 29: Counts of attribute classes.
Figure 30: Counts of affordance classes.
Figure 31: AP of attribute classes.
Figure 32: AP of affordance classes.
