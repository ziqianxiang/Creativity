Figure 1: Neural network topology of different Boltzmann machines. The general case is a complete graph.
Figure 2: Illustration of a possible deep convolutional Boltz-mann machine, where the monotonicity structure can still beenforced.
Figure 3: Convergence of the forward-backward splitting.
Figure 4: MNIST pixel imputation(b) Imputed pixel inference (without injec-tion labels)解目■邑户NQG(c) Original imageFigure 5: CIFAR-10 pixel imputationparameterization produces a much nicer convergence pattern: the average number of forward iter-ations over the 40 training epochs is less than 6 steps, see fig. 3. When the missing pixels formconsecutive patches, our model reconstructs readable digits despite potentially large chunk of miss-ing pixels (fig. 4e). Meanwhile, if the model is given the image labels as input injections, our modelperforms conditionaly generation fairly well (fig. 4f). These results demonstrate the flexibility ofour parameterization for modelling different conditional distributions.
Figure 5: CIFAR-10 pixel imputationparameterization produces a much nicer convergence pattern: the average number of forward iter-ations over the 40 training epochs is less than 6 steps, see fig. 3. When the missing pixels formconsecutive patches, our model reconstructs readable digits despite potentially large chunk of miss-ing pixels (fig. 4e). Meanwhile, if the model is given the image labels as input injections, our modelperforms conditionaly generation fairly well (fig. 4f). These results demonstrate the flexibility ofour parameterization for modelling different conditional distributions.
Figure 6: TV distance and convergence speed(c) TV distance at initialization7乙/ Gr，。匕9 7”O与3 " 7 26 3，If, fv3‰∕* Λo t4 H-“夕夕07ð.Sqq 2/ O ‰ Q 7二夕70口7≤^q dIqnqU墟上K 5;1，，1 Q 5 〃/• /b *l⅝∙ K4夕夕◎ 7
Figure 7: Training and inference using all three update rules with 40% observed pixels with the monotonicitycondition. The labels on each row represent the training update rule, and the labels on the columns representthe inference update rule.
Figure 8: Training and inference using all three update rules with 40% observed pixels without the monotonicitycondition. The labels on each row represent the training update rule, and the labels on the columns representthe inference update rule.
Figure 9: DBM for image imputationthe model on predicting the actual digit simultaneously. The test accuracy is 93.58%. Our modelachieves comparable test accuracy (92.95%) and imputation compared to this DBM, given fewerparameters and despite the the monotonicity constraint of our model.
