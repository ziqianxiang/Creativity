Figure 1: Sample skill correspondences learnt by our unsupervised approach, across three different morphologi-cal robots. We visualize a reaching skill on the Baxter left hand (top), translated to the Sawyer (middle) and theBaxter right hand (bottom) respectively.
Figure 2: Overview of our approach. We translate the original learnt skill space to the target domain. We thenconstruct explicit density estimates over the original target and translated source skill-tuple spaces. We trainour translation model to maximize the likelihood of randomly sampled translated source and original targetskill-tuples under these densities respectively, affording meaningful skill-correspondences across both robots.
