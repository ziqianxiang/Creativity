Figure 1: Examples of the multimodal data: (a) complete observations, (b) observations which mayhave missing visual modality, and (c) observations which may have missing audio modality.
Figure 2: Our proposed framework for multimodal learning with missing modality. In the trainingprocess, we propose a log-likelihood function L, as shown in Equation (2), to learn the conditionaldistributions of the modality-complete data and the modality-missing data. By developing a general-ized form of the softmax function, we implement our maximum likelihood estimation algorithm in anend-to-end manner.
Figure 3: Three forms of φ are studied: (a) addition (Wang et al., 2019), i.e., φ(f, g)，f + g, (b)concatenation (Chandar et al., 2016), i.e., φ(f, g)，[f t, gT]T, and (c) outer product (Zadeh et al.,2017), i.e., φ(f, g)，vec(f 0 g), where Vec represents the vectorization of outer product.
Figure 4:	The confusion matrices of different methods on the eNTERFACE’05 dataset.
Figure 5:	The performance comparison of different backbones on the RAVDESS dataset.
