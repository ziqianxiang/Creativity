Figure 1: Results of online fine-tuning on the D4RL benchmark using TD3+BC with different αonlinehyperparameters. We plot the mean and standard deviation across 3 runs. Using the behavior cloningloss with proper αonline enables the stable fine-tuning. But the optimal value of αonline differs betweendatasets.
Figure 2: Results of online fine-tuning on the D4RL benchmark. We plot the mean and standarddeviation across 5 runs. Our REDQ+AdaptiveBC method attains performance competitive to thestate-of-the-art. It should be noticed that, unlike other methods, our results do not collapse immedi-ately at the beginning of training.
Figure 3: Comparison of results with automatically tuned αonline and carefully picked results. Itshows that our proposed method can effectively find the suitable αonline for all tasks.
Figure 4:	Comparison of TD3-ft with and without dataset downsampling. We plot the mean andstandard deviation across 3 runs. Downsampling enables effective usage of novel data encounteredduring fine-tuning.
Figure 5:	Comparison of usages of ensembles on the hopper domain. We plot the mean and standarddeviation across 3 runs. Randomized ensembled double Q-Learning stabilizes the training, but it isnot necessary to avoid performance collapse during fine-tuning.
