Figure 1: (a) Examples of different datasets. The image styles from different datasets are commonlyvery different. (b) Examples of changing style feature for a GTAV sample, including adding ran-dom noise and replacing the style feature with one of samples from the other datasets. The mIoUperformance is largely reduced when applying the four style variations to the GTAV testing set.
Figure 2: Illustration of different data augmentation methods. We use GTA5 as the source domainand the ResNet-50 as the backbone. The mIoU given in parentheses is evaluated on CityScapesvalidation set for the model trained with the corresponding augmentation method.
Figure 3: The framework of the proposed adversarial style augmentation.
Figure 4: Qualitative comparison of segmentation results. Source: GTAV; Backbone: ReSNet-50.
Figure 5: t-SNE visualization of adversarial style features during training.
Figure 6: Influence of the adversarial learning rate.
Figure 7: The Pytorch-like pseudo-code of AdvStyle.
Figure 8: Segmentation results on CitySCapes. Source: GTAV; Backbone: ReSNet-50.
Figure 9: Segmentation results on BDD-100K. Source: GTAV; Backbone: ReSNet-50.
Figure 10: Segmentation results on Mapillary. Source: GTAV; Backbone: ResNet-50.
Figure 11: Examples of adversarial style augmentation. Source: GTAV; Backbone: ResNet-50.
