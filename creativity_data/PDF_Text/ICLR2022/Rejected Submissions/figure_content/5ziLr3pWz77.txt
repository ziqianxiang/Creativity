Figure 1: (a) M -mode SVD estimates the param-eters of tensor factor model from a collection ofvectorized images that have been acquired com-binatorially. (b) M -mode SVD computes a re-gression model and computes the column and rowspace from a collection of images where eachimage is a grid of numbers, a "data matrix" or a2-way array. (All images in this paper have beenvectorized, except in this sub-figure.)Figure 2: Naive neural network implementationof the M -mode SVD, alg. 1. Depiction of theTensorFaces model estimation, Fig.1(a). Comput-ing each mode matrix, Um, naively with a singleautoencoder-decoder. The core tensor, T, is com-puted by an autoencoder that is initialized withthe vectorized multilinear (tensor) codes formedfrom the product of factor representations.
Figure 2: Naive neural network implementationof the M -mode SVD, alg. 1. Depiction of theTensorFaces model estimation, Fig.1(a). Comput-ing each mode matrix, Um, naively with a singleautoencoder-decoder. The core tensor, T, is com-puted by an autoencoder that is initialized withthe vectorized multilinear (tensor) codes formedfrom the product of factor representations.
Figure 3: Face recognition example. (a) An ensemble of vectorized images is organized intoD ∈ CIx ×IP ×IV ×IL ×IE is matrixized into a data matrix, DP from which one can compute the modematrix, UP, that spans the person representation. This depicts how a single SVD(D[P] can be writtenin terms of (i) constrained cluster-based autoencoder (PCA) and (ii) concurrent autoencoder. This isdepicted as a neural network architecture in (b), (c) and (d), respectively. (b) Mode matrix computationusing a single autoencoder-decoder. (c) Mode matrix computation using a constrained cluster-basedautoencoder-decoder based on the derivation in part (a). (d) Concurrent-autoencoder. (e) The neuralnetwork architecture consists of a chain of constrained autoencoders-decoders where the weights ofone constrained autoencoder-decoder are the inputs of the next one. This constrained recurrent causalchain is the unrolled for-loop that computes the mode matrices by employing alternating least squares.
Figure 4: (a) Learning levels of abstractions bottom-up with a hierarchy causal part-based capsules.
Figure 5: Neural network architectureof the multilinear projection algorithm[Vasilescu & Terzopoulos (2007) givenan estimated interaction causal model, T(i.e.,T[x]).
Figure 6: Autoencoder-decoder architec-ture and Principal Component Analysis.
Figure 7: Matrixizing a 3rd order tensor, A.
Figure 8: Compositional hierarchical Block TensorFaces learns a hierarchy of features, and reesentseach person as a part-based compositional representation. Figure depicts the training data factorization,D = TH ×LUL ×VUV ×PUP, where an observation is represented as d(p, v, l) = TH ×Ll ×Vv ×Ppand TH spans the hierarchical causal factor variance.
