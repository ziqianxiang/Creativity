Figure 1: Our proposed online unsupervised prototypical network (OUPN). Left: OUPN learnsdirectly from an online visual stream. Images are processed by a deep neural network to extractrepresentations. Representations are stored and clustered in a prototype memory. Similar featuresare aggregated in a concept and new concepts can be dynamically created if the current featurevector is different from all existing concepts. Right: The network learning uses self-supervision thatencourages different augmentations of the same frame to have consistent cluster assignments.
Figure 2: An example subsequence of the RoamingRooms dataset, consisting of consecutive glimpsesof an online agent roaming in an indoor environment, and the task is to recognize the object instances.
Figure 3: Comparison to SimCLR, SwAV, and SimSiam with larger batch sizes on RoamingRooms•	Adjusted mutual information (AMI): In the unsupervised setting, we use the mutual informationmetric to evaluate the similarity between our prediction {yι,..., yτ} the groundtruth class ID{yι,..., yτ}. Since the online greedy clustering method admits a threshold parameter α to controlthe number of output clusters, therefore for each model we sweep the value of α to maximizethe AMI score, to make the score threshold-invariant: AMImaX = maxɑ AMI(y,y(α)). Themaximization of α can be thought of as part of the readout procedure, and it is designed toparticularly help other self-supervised learning baselines since their feature similarity functions arenot necessarily calibrated for clustering.
Figure 4: Image retrieval results on RocimingRooms. In each row, the leftmost image is the queryimage, and top-9 retrieved images are shown to its right. For each retrieval its cosine similarity scoreis in the top left; a green border signifies a correct retrieval (matching the query instance), red is afalse positive, yellow a miss. Recall is the proportion of instances retrieved within the top-9.
Figure 5: An example subsequence of an episode sampled from the RoamingOmniglot datasetinstances across batches allows the clustering process to access more data points. The queue sizeis set to 2000.
Figure 6: Comparison to IID-trained versions of SimCLR, SwAV, and SimSiam with larger batchsizes on RoamingRooms.
Figure 7: Robustness to imbalanced distributions by adding distractors (Omniglot mixed with MNISTimages). Performance is relative to the original performance and a random baseline.
Figure 8: Embeddings and clustering outputs of an example episode (1). Embeddings are extractedfrom the trained CNN and projected to 2D space using t-SNE (Van der Maaten & Hinton, 2008). Themain object in each image is highlighted in a red mask. The nearest example to each cluster centroidis enlarged. Image border colors indicate the cluster assignment.
Figure 9: Embeddings and clustering outputs of another example episode (2).
Figure 10: Embedding visualization of an unsupervised training episode of RoamingOmniglot.
Figure 11: Embedding visualization of an test episode of RoamingOmniglot.
