Figure 1: We show the accuracy of ResNet56 mod-els trained on subsets of different sizes, selected usingour method on CIFAR-10, CIFAR-100, ImageNet, andCIFAR-100-LT. Models trained using subsets with 30-40% less data, achieve similar accuracy to the onestrained using the full dataset.
Figure 2: A schematic with three classes (A,B,C), 8training samples, and two decision boundaries for thelabel pairs (A,B) and (B,C). fdiversity promotes select-ing samples that are more spreadout and thereby giveshigher utility for {1, 3, 7} over {2, 3, 4}. funcertaintyprefers samples with high uncertainty or the ones closerto the decision boundary, and thus gives higher utility for{2, 3, 4} over {1, 3, 7}. ftriple avoids selecting tripletswith negligible or small area, and thereby gives very lowutility for subsets such as {5, 6, 7} where the samplesall lie on a straight line. The class balancing constraintwould prefer a subset {1, 3, 7}, with samples from threeclasses, to a single class set {2, 3, 4}. The boundary-balancing constraint would prefer {4, 5}, which spansover two decision boundaries, to {3, 4} lying near asingle decision boundary.
Figure 3: Histogram of the number of images associated with the class boundaries in CIFAR-10, CIFAR-100,ImageNet, and CIFAR-100-LT datasets.
Figure 4: All the Top-1 accuracy numbers are computed by averaging three trials. For the ImageNet, the errorbars are only shown for our algorithm SUBMOD-BAL with one standard deviation.
