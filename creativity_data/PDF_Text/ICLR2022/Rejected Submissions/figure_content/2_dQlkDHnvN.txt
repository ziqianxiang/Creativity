Figure 1: Illustration of our meta algorithm. By combining the minimax objective and noisy labelalgorithm, we could reduce the backdoor attack problem to the label flipping attack. The left mostis the clean original data and the second one is corrupted data. The third figure shows the innermaximization step while the last figure shows the outer minimization step.
Figure 2:	Example of clean and various poisoned samples7.4.2 Experiment on MNISTWe found interesting results on MNIST. In MNIST, we found adversarial training itself sometimesgives robustness to the backdoor attack. We hypothesis that this is because the MNIST is potentiallya easier task than CIFAR. In here, we show the performance of adversarial training and PRL-AT onMNIST. The results can be found at table 6.
Figure 3:	Example of label flipping attack on both binary feature value and continuous feature valueAs we can see for the MNIST, especially for the blend attack, the poison accuracy for adversarialtraining does show good performance with a large standard deviation. This is because that somerandom seeds works while some random seed failed. We hypothesis that this is because MNIST15Under review as a conference paper at ICLR 2022clean/Poison accuracy	0.15	0.25	0.35	0.45Patch (PRL-AT)	80.25/80.15	78.22/78.14	75.10/75.04	58.90/58.90Patch(SpectralSign)	80.32/35.90	80.40/29.02	72.01/51.59	24.01/24.10PatCh(Fine-PrUning)	80.34/56.67	79.50/60.85	79.10/56.84	78.73/44.21blend (PRL-AT)	67.97/68.48	71.28/71.87	74.12/74.32	61.78/54.19blend (SpectralSign)	83.60/70.74	81.23/75.40	76.63/66.87	62.53/41.32blend(Fine-PrUning)	79.53/34.38 一	79.32/13.94 一	78.28/23.71 一	76.70/16.36 -Table 7: Comparison of averaged performance across three random seed with other baselines onCIFAR10. The numbers are clean accuracy/poison accuracy. Note fine-pruning used 5% clean datadataset has almost binary feature value. When adding a small gaussian noise on feature x, the labelflipping attack cannot change the decision boundary much. That is why the noisy label algorithmseems is not as important as the noisy label algorithm in CIFAR dataset. We plot a two dimensionaltoy example in figure 3 to illustrate label flipping attack on continuous features and binary features.
