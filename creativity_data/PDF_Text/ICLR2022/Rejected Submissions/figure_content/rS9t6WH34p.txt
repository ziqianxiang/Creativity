Figure 2: ObSuRF architecture. The encoder is given an input image with the corresponding camerapose, and infers an object-based latent representation consisting of slots. These slots are used in-dependently to condition a shared NeRF decoders. The volumes represented by the resulting scenefunctions may be rendered individually by querying them along rays coming from an arbitrary cam-era. Alternatively, the volumes may be composed in order to render the full scene.
Figure 3: Visualisations of ObSuRFâ€™s output given samples from the validation set of Sprites (top)and CLEVR2D (bottom).
Figure 4: Learning curves of ObSuRF and its ablations measuring Fg-ARI (top) and C-MSE (bot-tom) when training on CLEVR3D (left) and Multishapenet (right). For better comparability withNeRF-based training, all ObSuRF models are trained without the overlap loss LO .
