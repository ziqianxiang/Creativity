Figure 1: (a) An illustration of count sketch compressing the first 4 entries of e；. A collision is at[S]2,5 (index starts with 1); (b) magnitude of e； in EFSGD; (C) magnitude of e； in partial EFSGD.
Figure 2: ConEF With differentcount sketches.
Figure 3: Performance of ConEF on ResNet18 and MobileNetv2. From left to right: (a) train lossand (b) test accuracy on ResNet18; and (c) train loss and (d) test accuracy on MobileNetv2.
Figure 4: ConEF with a pow-erSGD gradient compressor.
Figure 5: Performance of ConEF with an unscaled random block gradient compressor on: ResNet-18, WideResNet-28-10, and LSTM (left to right).
Figure 6: iConEF with a ran-dom k gradient compressor.
Figure 7: ConEF with row orcolumn hashes has similar per-suppose the error vector lives in Rd, whose matrix view is Rn×mwith d = mn. It takes n (resp. m) hash computation in a row-(resp. column-) tensor trick, while mn hashes are needed withoutecdowluimthno-ubtasefdortemnasnocret.ricks are not observed;this trick. Differences on test accuracy between row- orsee Fig. 7.
Figure 8: Performance of ConEF with unscaled random block gradient compressor on a transformer.
Figure 9: More aggressively saved memorywith random-k gradient compressor.
Figure 10: Test of ConEF-CS with error resetusing random-k gradient compressor.
