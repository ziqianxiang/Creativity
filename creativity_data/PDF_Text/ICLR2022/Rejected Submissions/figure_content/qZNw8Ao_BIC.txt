Figure 1: Patch-based transformations largely destroy images to be unrecognizable to humanswhereas ViT recognizes them as the original class (e.g., keeshond or magpie) with high confidence.
Figure 2: ViTs can rely on features surviving patch-based transformations to maintain a high accu-racy, even after images have been heavily transformed to be largely unrecognizable. Top-1 accuracyof ViT models when tested on patch-based transformed images using the semantic class of the cor-responding clean image as ground-truth. The test accuracy on ImageNet-1k validation set is shownon the right. All ViT models are pre-trained on ImageNet-21k and fine-tuned on ImageNet-1k.
Figure 3: Features preserved in patch-based transformations are useful but non-robust as trainingViT on them impedes robustness. Top-1 Accuracy (%) on ImageNet-1k validation set and Ima-geNet robustness datasets: ImageNet-A, ImageNet-C, ImageNet-R. The baseline model is ViT-B/16in (Dosovitskiy et al., 2021) trained on original images. Other models are trained on patch-basedtransformed images, e.g., “P-Shuffle” stands for a ViT-B/16 model trained on patch-based shuffledimages. Numbers above the bars are either accuracy (e.g., ViT-B/16) or the max accuracy differencebetween each model family and the baseline ViT-B/16. The patch size in P-Shuffle and P-Rotate andreplacement ratio in P-Infill is denoted by “ps” and “rr” respectively.
Figure 4: ViTs trained only on our patch-based transformations exhibit stronger texture bias. Eachbar is the texture accuracy (%) on Conflict Stimuli (Geirhos et al., 2018), and a higher textureaccuracy indicates the model has a higher bias towards texture. The “texture accuracy” is defined asthe percentage of images that are classified as the “texture” label, provided the image is classifiedas either “texture” or “shape” label. The baseline model is ViT-B/16 in (Dosovitskiy et al., 2021)trained on original images. Other models are trained on patch-based transformed images, e.g., “P-Shuffle” stands for a ViT-B/16 model trained on patch-based shuffled images. Numbers above thebars are either accuracy (e.g., ViT-B/16) or the max accuracy difference between each model familyand the baseline ViT-B/16. The patch size in P-Shuffle and P-Rotate and replacement ratio in P-Infillis denoted by “ps” and “rr” respectively.
Figure 5: Examples of original images (on the top) and their corresponding patch-based shuffle (atthe bottom) with either patch size 32 or 48 without cherry-picking.
Figure 6: Examples of original images (on the top) and their corresponding patch-based rotation (atthe bottom) with either patch size 32 or 48 without cherry-picking.
Figure 7: Examples of original images (on the top) and their corresponding patch-based infill (at thebottom) with either replace rate 0.25 or 0.375 without cherry-picking.
