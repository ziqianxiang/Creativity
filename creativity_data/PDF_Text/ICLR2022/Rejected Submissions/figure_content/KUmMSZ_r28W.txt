Figure 1: The Particle-based Policy Improve-ment (ParPI) framework. The current Q-function provides a better policy in an energy-based form, whose particles can be drawn byan MCMC algorithm. The policy model isupdated to match the better policy by mini-mizing a broader class of distribution metricsusing the particles.
Figure 2: Training curves on continuous control benchmarks (Todorov et al., 2012). Our ParPIframework improves the performance of base RL algorithms SQL and SAC, and achieves the bestresults consistently across all tasks. We average the return over the past 100 episodes, where the solidlines indicate the mean and shaded areas indicate the standard deviation.
Figure 3: Study of component of ParPI on HalfCheetah-v3. Every experiment in ablation study wasconducted using three different seeds.
