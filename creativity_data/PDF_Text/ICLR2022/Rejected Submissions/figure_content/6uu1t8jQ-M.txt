Figure 1: Images generated by SIV-GAN. Our model successfully operates in extremely low dataregimes, generating new scene compositions with varying content and layout from a single video(first two rows) or a single image (last three rows). For example, from the single training videowith a car on the road, SIV-GAN generates images without a car or with two cars; and for thesingle surfing image, it can synthesize layouts with a different position and configuration of wavesvarying the number of surfers in the scene. SIV-GAN is able to maintain the quality and diversity ofscene compositions while operating at different image resolutions, e.g., 192×320 (fourth row) and512×896 (last row). (Original training samples are shown in grey or red frames.)1Under review as a conference paper at ICLR 20221	IntroductionThe quality of synthetic images produced by generative adversarial networks (GANs) (Goodfellowet al., 2014) has greatly improved in recent years (Zhang et al., 2019; Brock et al., 2019; Park et al.,2019; Karras et al., 2019; Lin et al., 2019; Schonfeld et al., 2020; Karras et al., 2020b). Theseimpressive results are in large part enabled by the availability of large, diverse datasets, typicallyconsisting of tens of thousands of images. This dependency on the availability of training data limitsthe applicability of GANs in domains where collecting a large dataset is not feasible. In some real-world applications, collection of even a small dataset remains challenging due to specific constraintsrelated to privacy, copyright status, subject type, geographical location, time, and dangerous orhazardous environments. It may happen that rare objects or events are present only in one image
Figure 2: SIV-GAN. The two-branch discriminator judges content separately from the scene layoutrealism and thus enables the generator to produce images with varying content and global layouts.
Figure 3: Limitation of the multi-stage trainingof single image patch-GAN methods. As the finergeneration stages cannot correct the layout deci-sion made by the coarser scale generators, with-out a careful tuning of the lowest resolution sizethe model produces images of very low diversity(first row) or lacking global coherency (last row).
Figure 4: Visual comparison in the Single Image setting. Single-image GANs (Shaham et al.,2019; Hinz et al., 2021) incoherently shuffle patches (e.g. sky textures below horizon, perturbedfish contours), and few-shot FastGAN (Liu et al., 2021) reproduces the original image or its flippedversion. In contrast, SIV-GAN achieves high diversity, maintaining content and layout realism.
Figure A: Visual effects of using content and layout branches in the discriminator in the SingleImage setting. The model with a standard GAN discriminator (No branches) memorizes the trainingimage. Model without the layout branch fails to produce images with realistic layouts or positioningof objects. Absence of the content branch does not preserve well object appearances. Finally, themodel with both branches generates diverse images with realistic content and layouts. See Table 3for qualitative comparison and App. A.1 for the discussion.
Figure B: Visual effects of using content and layout branches in the discriminator in the SingleVideo setting. The model with a standard GAN discriminator (No branches) memorizes the trainingvideo frames. The model without the layout branch is prone to cutting objects’ contours, generatingglobally incoherent layouts. The absence of the content branch leads to failures in appearances ofobjects, such as trees. Finally, the model with both branches generates diverse images maintainingrealistic content and layouts. See Table 3 for qualitative comparison and App. A.1 for the discussion.
Figure C: Feature distances from video frames to middle frame. As nearby frames have verysimilar content and layouts, the lowest distances are between adjacent frames. The layout embeddingdistances (solid red) between bus frames are lower than for the parkour video, being in line with thevisual layout variance of these sequences. As frames in the short videos depict similar content (e.g.
Figure D: Effect of the number of discriminator blocks used before branching. Using too fewblocks (1-2) leads to reduced synthesis quality, as Dlow-level is unable to extract the features neces-sary to build the content and layout representations. Increasing the number of blocks (3-4) resultsin improved quality while maintaining good diversity. Using too many blocks (5-6) leads to thememorization effect due to the occurring overfitting, when the model reproduces the training imagewith no diversity.
Figure E: Visual results in the few-shot setting on the Face Dog dataset. The two upper blocks showgenerated images for the models trained on the full dataset (389 images), while the two bottomblocks show the results from training only using 25% of data (98 images). SIV-GAN+ demonstratesnot only superior performance on the standard few-shot setting, but also successfully deals with anextreme few-shot scenario (25% of data), where FastGAN has a significant drop in performance.
Figure F: Visual examples in the few-shot setting on the ADE-Outdoors and LSUN Church datasets.
Figure G: Comparison with other methods in the Single Image setting on Places. Single-imageGANs of (Shaham et al., 2019; Hinz et al., 2021) are prone to incoherently shuffle image patches.
Figure H: Comparison with other methods in the Single Image setting on Places. The single-imageGAN of (Shaham et al., 2019) is prone to incoherently shuffle image patches, and the few-shotFastGAN model (Liu et al., 2021) reproduces the training image or its flipped version. In contrast,SIV-GAN produces diverse images, preserving the appearance of objects.
Figure I: Additional qualitative results in the Single Video setting. The training sequences are shownin grey frames. Given a single video for training, our SIV-GAN produces images that are different tothe training frames. For example, for a video with air balloons, the generated images have differentnumber of balloons, while for a video with a boat, the model generates novel combinations of boatsand buildings not seen during training.
Figure J: SIV-GAN results at a high image resolution of 512x896 in the Single Image setting. Ourmodel shows good scalability to different resolutions, maintaining the quality and diversity of scenecompositions. For example, given only one image with a bike rider, SIV-GAN can produce imagewith two bikers, without the biker, as well as change the bike lane path. For the frame with a parkourjumper, the scene can be resynthesized without the jumper, or with a different positioning of barriers.
Figure K: Difference between models trained on a single middle frame of a video and on the fullvideo sequence. In the Single Image setting, the model generates only slight geometric transfor-mations, such as varying the number of windows on a building, or modifying the geometry of aconcrete barrier. In contrast, the Single Video setting allows to provide more substantial diversity,removing the person from the frame or changing the layout of buildings.
Figure L: Qualitative ablation on the proposed diversity regularization and feature augmentation.
Figure M: Different strategies to achieve rectan-gular shapes. Using progressive upsampling, as in(Shaham et al., 2019), leads to artifacts in textures(e.g. chequered ”waves” on the rock). Controllingoutput image resolution through adjusting noiseshape helps to overcome this issue and generatetextures of good quality.
