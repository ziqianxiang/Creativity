Figure 1:	The Text-Conditioned Decision Transformer (TDT) architecture for specifying behaviorsvia language inputs. Text tokens mi are prepended to the sequence of episode tokens, specifying thecurrent task. Alternating states st and actions at provide context for the model and are rolled out inthe environment. Actions are predicted from every state in an autoregressive fashion.
Figure 2:	We create a new dataset on the Atari Frostbite environment, consisting of 5M timestepsof labelled text-trajectory pairs. The agent must solve a diverse set of tasks specified by naturallanguage instructions. Above are example frames representative of a task from the dataset.
Figure 3:	Performance of transformer architecture (TDT), based on the context size K. We com-pare to a concatenation-based MLP architecture which receives encoded text latents from pretrainedBERT and concatenates them with the latents of the current state from a learned vision encoder. TextDecision Transformer outperforms the MLP baseline in every suite of tasks. All experiments use 3seeds and show standard deviation between seeds.
Figure 4:	Transferring vision encoder after unsupervised pretraining. After pretraining with behaviorcloning on unlabelled trajectories, we see significant benefits on finetuning for medium and hardtasks compared to a randomly initialized vision encoder. Note the context size used is 20.
Figure 5: Transferring vision encoder with a shorter context (size 1). While pretraining still helps, itis generally less effective than with the model utilizing a longer context (Figure 4); the numbers forpretraining on 200 unlabelled tasks are summarized in Table 2.
Figure 6: Transferring both the sequence model and the vision encoder after unsupervised pretrain-ing. The sequence model captures additional information that improves performance compared toonly transferring the vision encoder.
Figure 7: Validation loss scaling in the supervised setting based on number of labelled trainingtrajectories. The relationship between loss and data is approximately linear on a log-log plot.
Figure 8: Key frames from a generated agent rollout corresponding to task “jump between the secondand third ice floes”. States represent a summary of the behavior; see Appendix for longer trajectory.
Figure 9: Performance vs. Baseline. Above we see the performance of the model relative to aconcatenation-based MLP architecture on a per-task basis.
Figure 10: Select frames from a generated agent rollout corresponding to mission “jump betweenthe second and third ice floes”. States are sampled from every 50 frames, and visualized left to right,top to bottom. Note that many jumps are still lost by subsampling.
