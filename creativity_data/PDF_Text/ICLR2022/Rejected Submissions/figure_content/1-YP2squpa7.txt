Figure 1: (Left) Training curves of message passing algorithms compared with BinaryNet on theFashion-MNIST dataset (multi-class classification) with a binary MLP with 3 hidden layers of 501units. (Right) Final test accuracy when varying the layer’s sparsity in a binary MLP with 2 hiddenlayers of 101 units on the MNIST dataset (multi-class). In both panels the batch-size is 128 andcurves are averaged over 5 realizations of the initial conditions (and sparsity pattern in the rightpanel).
Figure 2: (Left) Test error curves for Bayesian and point-wise predictions for a MLP with 2 hiddenlayers of 101 units on the 2-classes MNIST dataset. We report the results for (Left) binary and(Right) continuous weights. In both cases, we compare SGD, BP (point-wise and Bayesian) and EBP(point-wise and Bayesian). See Appendix B.3 for details.
Figure 3: Performance of BP and BinaryNet on the permuted MNIST task (see text) for a two hiddenlayer network with 2001 units on each layer and binary weights and activations. The model is trainedsequentially on 6 different versions of the MNIST dataset (the tasks), where the pixels have beenpermuted. (Left) Test accuracy on each task after the network has been trained on all the tasks.
Figure 4: MLP with 2 hidden layers with 101 hidden units each, batch-size 128 on the Fashion-MNIST dataset. In the first two layers we use the BP equations, while in the last layer the ArgMaxones. (Left) ArgMax layer first version; (Right) ArgMax layer second version. Even if it is possibleto reach similar accuracies with the two versions, we decide to use the first one as it is simpler to use.
Figure 5: Initial distribution of the magnetizations varying the parameter . The initial distribution ismore concentrated around ±1 as increases (i.e. it is more bimodal and the initial configuration ismore polarized).
Figure 6: Training curves of message passing algorithms compared with BinaryNet on the Fashion-MNIST dataset (multi-class classification) with a binary MLP with 3 hidden layers of 501 units.
Figure 7: Local energy curve of the point-wise configuration found by the BP algorithm comparedwith BinaryNet on a MLP with 2 hidden layers of 101 units on the 2-class MNIST dataset.
Figure 8: (Right panels) Polarizations hq0i and overlaps hqabi on each layer of a MLP with 2 hiddenlayers of 501 units on the Fashion-MNIST dataset (multi-class), the batch-size is bs = 128. (Right)Corresponding train and test error curves.
Figure 9: Algorithms time scaling with the batch-size on a MLP with 2 hidden layers of 501 hiddenunits each on the Fashion-MNIST dataset (multi-class classification). The reported time (in seconds)refers to one epoch for each algorithm.
