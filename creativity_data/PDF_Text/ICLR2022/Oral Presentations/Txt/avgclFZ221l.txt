Published as a conference paper at ICLR 2022
Asymmetry Learning for Counterfactual-
Invariant Classification in OOD Tasks
S Chandra Mouli
Department of Computer Science
Purdue University
chandr@purdue.edu
Bruno Ribeiro
Department of Computer Science
Purdue University
ribeiro@cs.purdue.edu
Ab stract
Generalizing from observed to new related environments (out-of-distribution) is
central to the reliability of classifiers. However, most classifiers fail to predict
label Y from input X when the change in environment is due a (stochastic) input
transformation Tte o X1 not observed in training, as in training We observe Ttr o X 1,
where X1 is a hidden variable. This work argues that when the transformations
in train Ttr and test Tte are (arbitrary) symmetry transformations induced by a
collection of knoWn m equivalence relations, the task of finding a robust OOD
classifier can be defined as finding the simplest causal model that defines a causal
connection betWeen the target labels and the symmetry transformations that are
associated With label changes. We then propose a neW learning paradigm, asymme-
try learning, that identifies Which symmetries the classifier must break in order to
correctly predict Y in both train and test. Asymmetry learning performs a causal
model search that, under certain identifiability conditions, finds classifiers that
perform equally Well in-distribution and out-of-distribution. Finally, We shoW hoW
to learn counterfactually-invariant representations With asymmetry learning in tWo
simulated physics tasks and six image classification tasks.
1	Introduction
A significant challenge in classification tasks happens When the test distribution differs from the
training distribution (i.e., the task requires out-of-distribution (OOD) generalization), since not
accounting for the distribution shift can lead to poor generalization accuracy (Geirhos et al., 2020;
Hu et al., 2020; Koh et al., 2020; D’Amour et al., 2020). If the learner sees examples from the
test distribution, finding a classifier invariant to the distribution shift can still be a data-driven
task (e.g., classical domain adaptation Ben-David et al. (2007); Muandet et al. (2013); Zhao et al.
(2019)). This includes cases such as invariant risk minimization (Arjovsky et al., 2019) and its
generalizations (Bellot & van der Schaar, 2020), Where the training data and the test data distributions
overlap in a Way that can be exploited by data-driven algorithms (Creager et al., 2021; Krueger et al.,
2021; Rosenfeld et al., 2020).
HoWever, if the learner sees no examples from the test distribution, the task is not purely data-driven
and requires assumptions about the data generation process. More formally, our Work considers
general OOD tasks with training distribution P(Ytr, Xtr), where Xtr :“ Ttr o X:, with X: as a
hidden variable With distribution PpX:q and Ttr P T is a random input transformation in training
Ttr : X
→ X, where t o X is the application of transformation t P T on X P X. The difference
between train and test is a change in input transformation with Yte :“ Ytr and Xte :“ Tte o X:,
where P(Ttrq ‰ P(Tteq. We are interested in learning an invariant classifier that generalizes well in
held out examples from the training and test distributions.
The definition of transformation matters in this task. We first seek to generalize the existing literature
on transformation invariances, e.g. (Shawe-Taylor, 1993; Kondor & Trivedi, 2018; Finzi et al., 2021;
Maron et al., 2018; Murphy et al., 2019b; Mouli & Ribeiro, 2021; Bronstein et al., 2017). Our
transformations are tied to equivalence relations rather than transformation groups, which frees them
from the need to have inverses (in order to form a transformation group). Our transformations may
not have inverses.
1
Published as a conference paper at ICLR 2022
We also explain why the task of learning an invariant OOD classifier is not, in general, solvable via
traditional data augmentation. Before we continue describing our OOD learning task, it is important
to clarify the connection between Pearl’s causal hierarchy and invariant representation learning.
Pearl’s causal hierarchy and invariant representation learning. Pearl’s causal hierarchy (Pearl
& Mackenzie, 2018; Bareinboim et al., 2020)) has three layers: Observational (Layer 1), interventional
(Layer 2), and counterfactual (Layer 3). Upper layers can perform lower layer tasks, but not vice-versa
(see Bareinboim et al. (2020)). Tasks should be described using the lowest layer that can solve them.
Layer 1: Any task that can be performed without constraints on the causal model, i.e., by data alone,
is observational (Layer 1). Traditional domain adaptation is a Layer 1 task. Note that a classifier that
performs well OOD is itself a Layer 1 classifier, since it tries to predict PpYte|Xteq.
Layer 2: Without observations from PpXteq and/or PpYte|Xteq, learning an OOD classifier requires
some assumptions about the data generation process (Layers 2 or 3 assumptions). Data augmentation
is traditionally an interventional task (Layer 2), with new interesting methods increasingly using
causal language (Ilse et al., 2021; Teney et al., 2020). For instance, in a task predicting an image’s
foreground, knowing how to act on an image in training Xtr to change the background seen in training
to the backgrounds seen in test Xte “ T o Xtr with a transformation T, implies We know how to
predict P pY |X, dopT qq.
Layer 3: Counterfactuals are the most challenging task. We start our description with an example.
Consider a random continuous transformation T2tr (in training) which changes to random transfor-
mation Te (in test). Let X: describe a hidden variable such that Xtr :“ T Q T Q T3 Q X: and
Xte :“ Ti Q T2e Q T3 Q X:, where Ti and T3 are independent continuous random transformations and
P pT2tr q ‰ P pT2te q. Assume the target variable Y depends only on X:, T1, and T3. To counterfactually
ask what would have happened to the observed input X if we had forced do(T2r “ £2), Weare
inquiring about X pT2tr “ t2)|Xtr “ x. Note that dopT2tr “ t2) does not change Y . Also note that the
knowledge of Xtr “ x is an indirect statement about T2tr since P pT2tr |Xtr “ x) ‰ P pT2tr ). That is,
for x, x1 P X ,
P pX pT2tr “ t£2) “ x1|Xtr
P pX pT2tr “ t£2) “ x1|T2tr “ t,Xtr “ x)dP pT2tr “ t|Xtr “ x).
t	(1)
Equation (1) and the difference between the causal hierarchy layers will be relevant for our results.
Contributions. Our contributions can be described as follows:
1.	We introduce a generalization of transformation groups via symmetry transformations tied to equiv-
alence classes that removes the requirement of invertible transformations common in definitions
using transformation groups.
2.	We introduce the concept of counterfactual invariant representations for symmetry transformations
and show how it can be described as a counterfactual task for causal structure discovery.
3.	Finally, we introduce asymmetry learning, which describes a representation regularization that,
under a set of assumptions, learns the correct counterfactual invariant OOD classifier.
2 S ymmetries and transformations
Geometrically, an object is called symmetric if there is a transformation on the object that does not
change its shape (in some definition of shape). For example, a square is symmetric with respect to
rotations. The notion of symmetry however is not restricted to geometric notions. In general, we
can define a mathematical object as symmetric if there is a transformation on the object that returns
another object equivalent to the first (Rosen, 2008, Chapter 10). It is clear from this definition of
symmetry that we first need to define what we mean by equivalent objects. For instance, we say two
geometrical objects are equivalent if they have the same shape, but we need a more general definition.
We define an input symmetry in a space X with at least two elements as an equivalence relation „.
An equivalence relation in X is a binary relation „ such that for all a, b, c P X , we have (i) a „ a,
(ii) a „ b ð^ b „ a, and (iii) (a „ b and b „ c) =^ a „ c. Equivalence relations allow us to
2
Published as a conference paper at ICLR 2022
define equivalent objects in X: a „ b means a is equivalent to b. The set of all objects equivalent to
some a P X is called the equivalence class of a, defined as ras :“ tx P X : x „ au. Note that
one can define m22 equivalence relations on the same input space. The equivalence class of X
with respect to equivalence relation k is denoted rxspkq , k “ 1, . . . , m. Two inputs a, b P X might
be equivalent under one equivalence relation „1 , but not equivalent under a different equivalence
relation „2, that is, we can have both b P rasp1q and b R rasp2q . Still, even in this last case it is
possible that a is equivalent to some other input c ‰ b in both equivalence relations, i.e., it is possible
Dc P X, c ‰ a, s.t. c P rasp1q X rasp2q. We denote the collection of equivalence classes of X under
the equivalence relation „k as the quotient space X{ „k:“ trxspkq | x P Xu.
Transformation group example. Consider the bijective transformations t : X → X of a transformation
group G, t P G. We now define an equivalence relation over G as t o X 〜G X for all t P G. The
equivalence class [xSpGq is x's orbit defined as [xSpGq :“ {x1 : Dt P G, x1 “ t o x}. For example, if
G is the group that permutes the elements of vectors in R3, then (1,2, 3)〜G (2,1,3).
Property functions example. Another way of deriving an equivalence relation is via functions of the
input space z : X → Rp, where the output z(X) is a particular property of the vector X P X. For
example, given an observation of length T from a dynamical system, X P RdxT, a possible property
function could be Zenergy(∙) that computes the energy of the dynamical system. Assuming there are
m known properties z1 , . . . , zm with zi : X → Rpi , we can construct corresponding equivalence
relations „i,...,〜m such that for any x, x1 P X, X 〜i x1 if Zj (x) “ Zj (x1), @j ‰ i. In words, two
inputs are equivalent under 〜i if they have the same properties for all zj∙,j ‰ i.
Symmetry transformations. As seen above, symmetries can be defined without defining how the
input is transformed to create the equivalence classes, although defining a set of transformations is
useful when describing the equivalence class. Given an equivalence relation 〜, we can define a set of
transformations T that respect the equivalence relation such that @t P T, VX P X, t o X 〜x. We call
T the set of symmetry transformations of 〜. Similar to transformations groups, T always has the
identity transformation tɪd o X “ x, but in contrast, all the transformations in T need not be bijective.
Join of equivalence relations. Similar to how two groups can be joined to form a larger group, two
equivalence relations can be joined to form a coarser equivalence relation. Given two equivalence
relations, 〜 and —2, their join 〜 _ 〜？ is defined as: for all x, x1, x(~ι _ 12)x1 if and only if
there exists a chain of equivalence relations X 〜加 xι, ..., xh—i 〜版 x1 with all kj P {1, 2}. It
is easy to check that 〜1 _ 〜2 is an equivalence relation.
We are now ready to define a general causal model that defines the training and test distributions in
our setting.
3 SCM for symmetry-based OOD tasks
Let X , Y denote the input and output spaces respectively. We define our general structural causal
model (SCM) as follows. We define X: P X as the unobserved canonically ordered input
X: :“g(Uu),	(2)
with Uu a background random variable and g : Uu → X is a measurable map. This definition is
general enough to define any task.
There are m possible symmetries given in the form of equivalence relations ι,...,〜m over the
input space X. Let Tpkq denote a set of symmetric transformations t on X corresponding to the
equivalence relation 〜k, 1 ≤ k ≤ m. In other words, for all X P X and t P Tpkq, We have
(t o x)〜k x. Similarly, let T be the set of all symmetric transformations with respect to the
join equivalence relation ~ι,…,m”-i _ ... _ 〜m,. We can think of transformation t P T as a
tpk1q	tpkhq	pk q	pk q
path x-----> xι …Xh—i -------> Xh that starts at x, applies a transformation tpk1q P Tpk1q to get
Xi P rxSpk1q, and so on until it stops and outputs a value Xh, h21.
Let U1 , . . . , Um be independent background variables associated with the m symmetries, where
Ui P Ui, i “ 1, . . . , m. These background variables together select a function t(Ui, . . . , Um)
from the set T as follows. Each Uk independently selects a countable sequence of transformations
tpik,Uq , tp2k,Uq , . . . P T pkq. Then, t(Ui, . . . , Um) is defined by interleaving these transformations
3
Published as a conference paper at ICLR 2022
(a)	Training data
(d)
Y = Flat
Xtl =x
VNħ J J.⅞.
Counterfactual data
o3ι‰=(σ,⅛r) 0 2‰‰,,=(+8>o) ° a¾‰=(<r,w) oa⅛j=(+8M
〉/
ɪ X(E4ra≈8=(+5s0))∣Λtr=xi*
Flat
ɪ, θll‰=(βO,Λ∙) 0 2‰‰>=(+S,0) O 0t⅛=(W∖β∙) O¾,O⅛,-=(+B,0)
OllUeUeAU- Gq ISi ①M
2ndu二ense,tffiunoo
JibK
Figure 1: Example that illustrates a few important concepts. (a) Training data shows how Equations (2) to (4)
define the training distribution P pXtr, Y trq. Task: Given an image of a rod (shown in brown), we wish to
predict the orientation of the rod, i.e., whether the rod is upright or flat (Y :“ hpUrotq). In this example, we
have D “ {rot} (image rotations 0o and 90°) and D “ {trans} (horizontal translations of —5, 0, '5 units) as
any horizontal translation does not affect the orientation of the rod. (b) The test data (only a single example
shown) suffers an OOD shift through a different distribution over P pUtransq, where non-zero translations can
happen before the second rotation. (c) Here we illustrate why an invariance that is good for traditional data
augmentation, such as counting the brown pixels in the green shaded area, would fail in test if, say, a `5 units
horizontal translation happens before a rotation. (d) Here we illustrate why counterfactual language is needed
to define how the input data would change in the presence of changes to Utrans. Using counterfactuals, it is
finally clear that the invariant representation must be able to also consider the number of brown pixels inside the
horizontal purple and green bands (among other horizontal bands).
tpUι,...,Um) :“ (tfUι o …。t1mqτ )。…。(tfUι 0 …。dmL)° ", to construct the path described
above. Since T p1q, Tp2q, . . . contain the identity transformation, tpU1, . . . , Umq can be described by
a finite sequences of transformations. The observed X is the result of a transformation of X:
X :“ t(U1 , . . . , Um) ° X: .	(3)
Finally, the label Y is defined as a function of the untransformed canonical input X: as
Y :“h(X:,(Ui)iPD,UY),	(4)
where D J {1,...,m} is unknown. This means that Y is not invariant with respect to equivalence
relations „i, i P D, i.e., examples x and x1 P rxspiq can have different labels. A distribution over the
variables Uu, tUiuim“1, UY entails a joint distribution P(X, Y) over the observed variables.
Illustrative SCM example. Figure 1 illustrates our data generation process. The training data
Figure 1(a) has X: defined as a centered upright brown rod (i.e., X: is deterministic). The label Y
is defined by the rotation transformations TTOt “ {T0ot, T90L}. The image can also be horizontally
translated by {—5,0, 5} units via transformations Ttrans = {T¥5ns,T0rans,T'5ns} (only 0 and '5
translations are depicted), but Y does not depend on these horizontal translations. The transforma-
tions applied to X : are randomly chosen via Urot and Utrans, which are two bidimensional vectors
indexing a sequence four transformations that interleave rotations and translations (see Figure 1). A
representation that counts the number of brown pixels in the green shaded area of Xtr is enough to
achieve 100% accuracy in the training distribution. We formally define OOD distribution shifts next
using Figure 1 for illustration.
OOD distribution shift. Let Ds “ {1, . . . , m}zD be the complement of the set of symme-
try relations D that Y depends on. We define the OOD distribution shift between train and
test as a shift in the distribution of P ((Ui)iPDs ), influencing the distribution of input transforma-
tions in Equation (3), which in turn can shift the distributions P(Xtr), P(Ytr|Xtr), P(Ytr, Xtr) to
4
Published as a conference paper at ICLR 2022
PpXteq, PpYte|Xteq, PpYte, Xteq respectively. Since X does not causally affect Y in our structural
causal model (Equation (4)), changes in input transformations are able to shift PpY |Xq. For example,
in Figure 1(b) the test data (only a single example shown) could suffer an OOD shift due to a different
distribution over P pUtransq that introduces non-zero translations before the second rotation. Note
that the representation that counted the number of brown pixels in the green shaded area, which was
perfect for the training inputs Xtr, will achieve poor accuracy in the test inputs Xte.
Learning OOD classifiers. Equation (4) shows that the label Y is invariant to changes in the
distribution of pUiqiPDs in the test distribution, but we do not know Ds. Hence, if our representation of
X is invariant to changes in the distribution of pUi qiPDs, we will be able to perform the OOD task.
4	Asymmetry learning & finding the right representation
symmetry for the OOD task
4.1	Finding OOD-invariant representations as causal structure discovery
We first define the process of finding an OOD invariant representations for the symmetries t„iuiPDs
our classifier should be invariant to in the test data. Since Y does not depend on tUi uiPDs, we will
make a representation of X that is invariant to transformations driven by tUiuiPDs .
Definition 1 introduces the concept of counterfactual invariance for symmetry transformations. We
note that this definition is less restrictive than the parallel work of Veitch et al. (2021, Definition 1.1):
whereas Veitch et al. (2021, Definition 1.1) require invariance over the entire sample space, we only
require invariance over the test support of transformation variable Ui . The definitions are equivalent
if the test support is the entire sample space of Ui .
Definition 1 (Counterfactual-invariant representations for symmetric transformations). Assume the
SCM defined in Equations (2) to (4). A representation Γi : X → Rd, d21 ,is counterfactual-
invariant to the transformations TIUi, T2ui,... OfeqUiValenCe relation 〜i, 1 ≤ i ≤ m, if
Γi(X)= ΓiPX(Ui “ Ui)X “ x)
almost every^where, Vui P supp(Uie), @x P supp(Xtr), where supp(A) is the SuppOrt of random
variable A. A representation Γs : X → Rd, d 2 1, is COunterfaCtual-invariant to a subset
S & {1,...,m} if it is jointly COunterfaCtual-invariant to the transformation indices {U7∙ }jps of
equivalence relations {〜j}jps.
We refer the reader to Equation (1) for the relationship between the counterfactual variables X (Ui =
u)∣Ui = u and X(Ui = u)|X = x. Figure 1(d) illustrates Why Counterfactual language is important
for our task: It states that given an input Xtr = x we need to know how it would have been different
if We had chosen a different distribution P(Utrans) resulting in a different sequence of transformations
T1,Utrans, T2,Utrans. From Figure 1(c) it is clear that We cannot simply data-augment our training data
With translations, since We Would think that counting broWn pixels in the green shaded area is an
invariant representation for Utrans.
Up until noW We have not imposed restrictions on the types of transformations T piq, i = 1, . . . , m,
We consider in this Work. Our next results require imposing conditions on these transformations.
Definition 2 (Equivalence class lumpability). The quotient SPaCe X/ 〜i is the set OfequiValenCe
Classes of X with respeCt to equivalenCe relation 〜i, i = 1,...,m. Let [xSpiq P X/ 〜i be the
equivalenCe Class of X P X with respeCt to equivalenCe relation 〜i. Then, X/ 〜i is said to be
lumpable with respeCt to a transformation set T if VrxsPiq P X/〜i and @t P T,
DrxIspiq P (X/ „i) s.t. x* P rxspiq =^ t o x* P rxιs"
In words, if the lumpability condition in Definition 2 holds for an equivalence relation 〜i with respect
to a set of transformations T, then every transformation in T maps all points Within an equivalence
class rxspiq P X/ 〜 to points in a another equivalence class rx1spiq P (X/ 〜). To illustrate
the lumpability condition, consider two transformation groups G1 and G2 whose transformations
commute, i.e., V(tι,t2) P Gi X G2, tι 012 = t2 0 tι. Then the equivalence classes imposed by Gi,
i.e., the orbits [xspiq =也 o x : Vti P G#, are lumpable with respect to the transformations Gj, for
i,j P t1, 2u andj ‰ i.
5
Published as a conference paper at ICLR 2022
D	D
(i) Causal DAG
D	D
(ii) Causal DAG in ⑴ with
CoUnterfaCtUal-invariant
representation of X
(iii) Asymmetry learning: Causal model search using
information in asymmetry (illustration with m=3).
Red arrows indicate the asymmetry being
considered in the causal model.
(b)
♦	Label Y=0
•	Label Y=1
■	X/ z∖
♦	“∕~2
(c)
(a)
Figure 2: (a) (i) True causal DAG; (ii) causal DAG of counterfactual invariant representation; (iii) Causal model
search. (b) Partial order over invariant representations (arrows indicate higher invariance). (c) An example figure
where training data has a single example per equivalence class in X{ „1 (green rectangles). Then, we have
COMPpFt1u , Dq “ COMPpFH , Dq even though Ft1u is more invariant (simpler) than FH.
Figure 2a(i) shows our structural causal graph where an edge Ui → Y exists only if i P D. Then,
we use the definition of lumpability to prove that, under certain conditions, a most-expressive
representation Γi invariant with respect to „i allows us to identify if there is no edge Ui → Y in the
causal DAG.
Theorem 1 (Counterfactual invariance & causal DAG identification). Let X{ „i be lumpable given
every Tpjq,j ‰ i as in Definition 2. Then, the structural causal DAG implied by Equations (2) to (4)
(depicted in Figure 2a(i)) does not contain the edge Ui → Y iff
∣p pγ ∣ΓiPχ q, UY q ´ P(Y ∣χ, UY q∣ TV = 0,	(5)
@PpX:q, @PpU1q, . . . , @P pUm q, where Γi is a most-expressive representation that is invariant with
respect to „i .
The proof is in the Appendix. With the lumpability assumption of X{ „i, Γi in Theorem 1 is a
counterfactual-invariant representation. We now use Figure 2a(ii) to describe the result in Theorem 1.
We first note that the representation ΓDs depicted in the figure is counterfactual invariant to Ds, and
hence also counterfactual invariant to k P Ds . Next we see that since the representation ΓDs is
counterfactual invariant to Uk, there is no arrow Uk → ΓDs (Xq in Figure 2a(ii). If there is no arrow
Uk → Y, the missing arrows from Uk to ΓDs (Xq will have no influence in the ability of ΓDs (Xq
to predict Y, assuming ΓDs is most-expressive. If there is an arrow Uk → Y, cutting the arrow
Uk → ΓDs (Xq creates a loss in predictive performance from ΓDs (Xq to Y for some distribution of the
background and observable variables. If ΓDs (Xq never loses any predictive power over Y for any
distribution of the background and observable variables, then there is no arrow Uk → Y.
Assumption 1 (Asymmetry learning training data). In asymmetry learning we assume that every
X{ „i, i P t1, . . . , mu is lumpable given T pjq, j ‰ i, and that in a large training dataset sampled
from (Ytr, Xtrq, an arrow Uj → Y in the causal DAG of Figure 2a(i), j P t1, . . . , mu, contains
observations of tUj ujPD that violate Equation (5). Hence, if Equation (5) holds for some i P
t1, . . . , mu in this dataset, we can conclude that there is no arrow Ui → Y in the true causal DAG.
See Appendix A for a justification of this assumption.
Next we use Assumption 1 and the previous results to search for the right OOD invariance.
4.2	Causal structure discovery of relevant symmetries
We need a general procedure for obtaining the unknown set D, which is equivalent to finding all
transformations indices {Ui}ipD ɑ {Uι,..., UmU that act as ConfoUnderS between Y and X in the
causal DAG in Figure 2a(i). Finding whether an edge exists or not in the causal DAG is known as the
causal structure discovery problem (e.g., Heinze-Deml et al. (2017)). The principle of our search
is learning the causal structure with the fewest possible edges into Y (i.e., where Y is invariant to
most Ui, i “ 1, . . . , m) while also maximizing the likelihood of the observed data. Accordingly,
we take the score-based causal discovery approach (Chickering (2002); Huang et al. (2018)) that
assigns scores to each allowed DAG based on the training data and the complexity of the DAG to
find a minimal causal structure that fits the training data. This idea is visualized in Figure 2a(iii)
6
Published as a conference paper at ICLR 2022
where causal graphs with more edges between the transformation indices into Y are defined to have
higher complexity and are higher up in the partial ordering. Our search space is simpler than typical
structure discovery tasks: The DAGs in our search space have the same structure for X and only
differ in edges of the form Ui → Y,i p {1,..., m}. Next, We describe a scoring criterion that uses
Theorem 1 and counterfactual-invariant representations to assign scores to the corresponding causal
structures.
Proposed DAG scoring criterion. For each DAG in the search space, We Wish to assign a score
based on the training data D “ tpxpiq, ypiquin“tr1 under Assumption 1 for a classification task With
C classes. Theorem 1 shoWs that there is a correspondence betWeen a causal structure Without the
edge Ui → Y and a predictive probability gap betWeen the original input and a most-expressive
representation Γi that is counterfactually-invariant to Ui. Thus, under Assumption 1, We can represent
the causal search from Figure 2a(iii) in terms of a search over counterfactually-invariant representation
function classes as shoWn in Figures 2a(iii) and 2b. Formally, We are given a collection of function
classes F :“ {FS : S & {1,..., m}}, where FS isa family of functions Γs that are COUnterfaCtUally-
invariant to all Ui , i P S (Definition 1). We Wish to score each of the function classes FS P F to
indirectly learn the correct causal structure.
The minimum description length (MDL) principle (Schwarz, 1978) is commonly used for causal
structure discovery (Budhathoki & Vreeken, 2016; 2017) and comes with the key insight that learning
from data can be viewed as compressing it. Given the collection F and the training dataset D,
MDL finds the function class FS P F that compresses D the most. While there are several ways of
encoding a dataset given the function class, normalized maximum likelihood (NML) code is known
to be optimal (Shtarkov, 1987). NML code is computed as follows
Lnml(Fs, D) “ ´l(FS|D)+ COMP(FS, D),	(6)
where L(Fs∣D) “ SuPrSPFS Xn“ 1 logP(ypiq ∣Γs(xpiq)) is the maximum log-likelihood of FS given
the data and
ntr
COMP(Fs, D)= log £ SuP ∩P(ypiq∣ΓS(xpiq))
yPiq,…MM i=1
ypiqPt0,...,Cu
(7)
measures the complexity of the function class FS by computing how well it can represent different
label distributions for the given inputs txpiquin“tr1 in training. We can estimate the combinatorial sum
in Equation (7) by uniformly sampling random labels for all the training examples.
Since COMP(FS, D) is computed using the training data, it may underestimate the complexity of
function classes if, for instance, all the training examples are generated with Ui = ui . Then, Ftiu and
FH are given the same score even though Ftiu is clearly more invariant and thus, a simpler function
class. This can happen in practice if, say, all images are upright in training with no rotations applied;
both rotation-invariant and rotation-sensitive function classes get the same complexity score.
In order to break the above ties of our COMP score, asymmetry learning adds an additional term to the
NML score that chooses models that have higher invariance based on the partial order (see Figure 2b).
We extend the penalty proposed by Mouli & Ribeiro (2021) and use R(FS) := ∣{F1 : Fl P F, Fl >
FSu|, the number of function classes that are higher in the partial order than FS, as the tie-breaking
term. For example, in figure R(Ft1u) = |tFt1,2u, Ft1,3u, Ft1,2,3uu| = 3. We define the final score of
each function class FS P F as
S(Fs, D) = Lnml(Fs, D)' R(Fs).
(8)
The score in Equation (8) can be minimized by a score-based causal discovery algorithm to obtain
the final DAG. We use Greedy Equivalence Search (Chickering, 2002) to showcase a concrete
instantiation of asymmetry learning. Other score-based structure discovery algorithms could also be
used.
Greedy Equivalence Search. Greedy Equivalence Search (GES) is a greedy search algorithm that
optimizes a given scoring function over DAGs. In our setting, the search begins with a DAG with no
edges of the form Ui → Y, i P t1, . . . , mu. In the first phase, GES adds these edges one at a time
7
Published as a conference paper at ICLR 2022
Table 1: Results for different function classes on the pendulum task with D “ t1u and D “ t1, 2u. RpF q,
COMPpF, Dq and SpF, Dq are discussed as in Section 4.2. Bold values indicate the function class chosen by
GES method with the proposed scoring criterion. Test accuracy is computed on the extrapolated dataset after
shifting the distribution of P ptUi uiPDs q.
Model class	Architecture	RpFq	D“		{1}		D“t1,2u			
			C{OMPpF, Dq	SpF, D)	Train Acc.	Test Acc.	C{OMPpF , D)	SpF, D)	Train Acc.	Test Acc.
F2	X → z1 → Y	0	0.282	23.89	98.5 (0.9)	98.3 ( 1.4)	0.501	532.84	72.7 (0.4)	69.4 (0.5)
F1	X → z2 → Y	0	0.382	633.32	63.8 (7.0)	51.2 ( 1.0)	0.292	284.75	85.2 (0.5)	84.6 (0.2)
FH	X→Y	2	1.256	26.80	98.9 (0.8)	77.6 (11.5)	0.995	4.54	99.7 (0.2)	99.5 (0.2)
that maximally improve the score in Equation (8) until there is no improvement. In the second phase,
GES begins from the DAG obtained at the end of first phase and deletes edges one at a time until
such deletions do not improve the score. The DAG obtained at the end of the second phase is the final
output of the algorithm. Under the causal Markov and faithfulness assumptions, Chickering (2002)
showed that GES is optimal in the large sample limit if the scoring function is locally consistent.
5	Results
Pendulum task description. We evaluate the proposed method in a simulated classification task.
Our input X is a motion vector over time (θt,警)T“i of a simple pendulum of an unknown length l
after it is dropped from some initial angle θo with 端 “ 0. After an initial T seconds of uninterrupted
motion, we simulate an elastic collision by placing another object of same mass at the bottom. The
classification task is to predict whether the kinetic energy imparted by the pendulum is enough to
move the second object beyond a certain threshold.
Physical properties and equivalence relations. We consider the following two properties of the
dynamical system described above: zι : X → R which computes the initial potential energy of
the system and z? : X → R which returns the time of collision. The equivalence relations „1 and
„2 are defined using these properties as defined in Section 2. For instance, two pendulum motion
curves x, x1 are equivalent with respect to „1, i.e., x „1 x1, if they have the same time of collision,
z2pxq “ z2px1q. Then Tp1q consists of transformations that change the initial potential energy of
the system (for example, by changing the length of the pendulum or the initial dropping angle θ0)
while keeping the time of collision same. Similarly, x „2 x1 if their respective potential energies
are the same and transformations in Tp2q change the time of collision while keeping the same initial
potential energies. Note that the space of equivalence classes X{ „1 is lumpable with respect to
Tp2q and vice versa (Definition 2). Thus, by Theorem 1, we can use predictive performance of
counterfactual-invariant representations for scoring the causal DAGs.
Unknown D and OOD classification. We consider two scenarios for the label Y given X . First, if
the motion of the pendulum is not damped by friction, then Y depends only on z1 pxq, i.e, D “ t1u.
Second, if the motion of the pendulum is damped, then Y depends on both z1pxq and z2 pxq, i.e.,
D “ t1, 2u. The extrapolation test data is generated by shifting the distribution of the background
variables tUiuiPDs. The task ofa structure discovery algorithm is to correctly identify D.
Results. We use the greedy equivalence search (GES, Section 4.2) algorithm to search over the
different causal graphs with the proposed scoring criterion defined in Equation (8). We build classes
of counterfactual-invariant representations FS corresponding to each possible value of S q {1,2},
where every ΓS P FS is invariant to tUiuiPS. For example, Ft1u is a family of feedforward neural
networks that only take z2pxq as input, i.e., invariant to z1pxq, whereas FH is a sequence model
(e.g., LSTM) with no invariance. Table 1 reports the estimated complexity COMPpF , Dq and the
final scores SpF, Dq for the different function classes for the two tasks. The bold values indicate the
function class chosen by the GES algorithm. When D “ t1u, the greedy search stops after adding
the edge U1 → Y as adding the second edge U2 → Y only worsens (increases) the score. When
D “ t1, 2u, the greedy search is able to improve the score by adding both edges, first U1 → Y and
then U2 → Y . In both the cases, the extrapolation test accuracy achieved by the chosen model class
is the highest.
Image classification task. Appendices A.4 and A.5 also offers an application to image classification
using image transformation sets (groups and nongroups).
8
Published as a conference paper at ICLR 2022
6	Related Work
Counterfactual inference and invariances. Recent efforts have brought causal inference to ma-
chine learning (extensively reviewed in SchGlkoPf et al. (2021); SchGlkoPf (2022)). Invariant Causal
Prediction (Peters et al., 2015; Heinze-Deml et al., 2018) and Invariant Risk Minimization meth-
ods (Arjovsky et al., 2019; Bellot & van der Schaar, 2020) learn rePresentations that are invariant
across multiPle environments but have been shown to be insufficient for OOD generalization in
classification tasks without additional assumPtions Ahuja et al. (2021). Wang & Jordan (2021) use
counterfactual language to formally define and learn non-sPurious rePresentations from a single
environment that can extraPolate to new environments. Veitch et al. (2021) define counterfactual
invariant Predictors f pXq when X has a single Parent Z and Provide conditions such Predictors must
satisfy over the observed distribution (given an SCM). Kaushik et al. (2020; 2021) ProPose counter-
factual data augmentation for text datasets but they either require a fully-sPecified toy SCM or rely
on humans-in-the-looP to generate the counterfactual data. Other counterfactual methods (Johansson
et al., 2016; Shalit et al., 2017; Qidong et al., 2020) learn rePresentations to Predict counterfactual
change in some observed variables whereas in our setting, the transformation variables Ui that gener-
ate the observed X are unobserved. In-dePth comParison of our work with the existing counterfactual
methods is Presented in APPendix A.3.
Domain adaptation and domain generalization. Domain adaPtation and domain generalization
(e.g. (Long et al., 2017; Muandet et al., 2013; Quionero-Candela et al., 2009; Rojas-Carulla et al.,
2018; Shimodaira, 2000; Zhang et al., 2015) and others) consider observed or known shifts in the
data distribution, for instance, given the test distribution P pXteq, rather than counterfactual questions.
Causal structure discovery. The methods for causal structure discovery can be broadly classified
into two categories. Constraint-based aPProaches (e.g., SPirtes et al. (2001); Sun et al. (2007)) use
conditional indePendence tests and reject causal graPhs that imPose more indePendence than what
is observed in data. On the other hand, score-based causal discovery aPProaches (e.g., Chickering
(2002); Huang et al. (2018); Ding et al. (2020); Zhu et al. (2020)) assign scores to each allowed causal
graPh based on the data and find the one with best score. While there are several works (Budhathoki &
Vreeken, 2016; 2017; Bornschein et al., 2021) that use minimum descriPtion length (MDL) (Schwarz,
1978) as a scoring criterion, we show why it is insufficient for out-of-distribution tasks and use an
additional term for tie-breaking. Goudet et al. (2017) minimize the divergence between a distribution
generated by a learnt causal DAG and the observed data distribution; however the method is limited
to orienting edges over observed variables, whereas our transformation variables Ui are unobserved.
Recently, GFlowNets Bengio et al. (2021a;b) have been used to samPle DAGs ProPortional to a score
function for Bayesian structure learning Deleu et al. (2022), however we are interested in finding the
best DAG with the minimum score.
Group-invariant representations. Majority of the works strictly enforce G-invariances either within
the architecture (e.g., Zaheer et al. (2017); Cohen et al. (2016); Lyle et al. (2020); MurPhy et al.
(2019a)) or via data-augmentation (Chen et al., 2020) and do not handle the case when the target
is actually influenced by the transformation of the inPut. Other works (Benton et al., 2020; Zhou
et al., 2020; van der Wilk et al., 2018; Anselmi et al., 2019) consider learning symmetries from
the training data but do not consider the extraPolation task that we show can be solved only under
certain conditions. Mouli & Ribeiro (2021) consider the sPecial case where the transformations are
from normal subgrouPs and do not formally describe the causal task. These works rely on invertible
transformations while we define symmetries more generally via equivalence relations. Dubois et al.
(2021) also define invariances via equivalence relations and, under the assumPtion that all such
invariances hold in the data, the authors design methods for data comPression. Our goal is rather
different: We want to discover which equivalence relations (transformations thereof) affect the label.
7	Conclusions
This work considered an out-of-distribution (OOD) classification task where the shift between train
and test environments is through different symmetry transformations of the inPut, where symmetry
transformations are defined via equivalence relations over the inPut sPace. We described the task of
finding symmetries that affect the label as a causal structure discovery task and show that, under certain
conditions, we can use the Predictive Performance of invariant rePresentations on the observational
data to Predict whether an edge exists in the causal DAG (Theorem 1). We then ProPosed an MDL-
based scoring for this causal structure discovery. Finally, we test our aPProach in two simulated
Physics tasks and six image classification tasks.
9
Published as a conference paper at ICLR 2022
Acknowledgments
This work was funded in part by the National Science Foundation (NSF) Awards CAREER IIS-
1943364 and CCF-1918483, the Purdue Integrative Data Science Initiative, and the Wabash Heartland
Innovation Network. Any opinions, findings and conclusions or recommendations expressed in this
material are those of the authors and do not necessarily reflect the views of the sponsors.
References
Kartik Ahuja, Ethan Caballero, Dinghuai Zhang, Jean-Christophe Gagnon-Audet, Yoshua Bengio,
Ioannis Mitliagkas, and Irina Rish. Invariance principle meets information bottleneck for out-of-
distribution generalization. Advances in Neural Information Processing Systems, 34, 2021.
Fabio Anselmi, Georgios Evangelopoulos, Lorenzo Rosasco, and Tomaso Poggio. Symmetry-adapted
representation learning. Pattern Recognition, 86:201-208, FebrUary 2019. ISSN 0031-3203. doi:
10.1016/j.patcog.2018.07.025.
Martin Arjovsky, Leon BottoU,Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization.
arXiv preprint arXiv:1907.02893, 2019.
Elias Bareinboim, JUan Correa, DUligUr Ibeling, and Thomas Icard. On Pearl’s hierarchy and the
foUndations of caUsal inference. ACM special volume in honor of Judea Pearl, 2020.
Alexis Bellot and Mihaela van der Schaar. AccoUnting for Unobserved confoUnding in domain
generalization. arXiv preprint arXiv:2007.10653, 2020.
Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, et al. Analysis of representations
for domain adaptation. Advances in neural information processing systems, 19:137, 2007.
EmmanUel Bengio, Moksh Jain, Maksym Korablyov, Doina PrecUp, and YoshUa Bengio. Flow
network based generative models for non-iterative diverse candidate generation. Advances in
Neural Information Processing Systems, 34, 2021a.
YoshUa Bengio, Tristan DeleU, Edward J HU, Salem LahloU, Mo Tiwari, and EmmanUel Bengio.
Gflownet foUndations. arXiv preprint arXiv:2111.09266, 2021b.
Gregory Benton, Marc Finzi, Pavel Izmailov, and Andrew Gordon Wilson. Learning invariances in
neUral networks from data. NeurIPS, 2020.
Jorg Bornschein, Silvia Chiappa, Alan Malek, and Rosemary Nan Ke. PreqUential MDL for CaUsal
StrUctUre Learning with NeUral Networks. JUly 2021.
Michael M Bronstein, Joan BrUna, Yann LeCUn, ArthUr Szlam, and Pierre Vandergheynst. Geometric
deep learning: going beyond eUclidean data. IEEE Signal Processing Magazine, 34(4):18-42,
2017.
Kailash BUdhathoki and Jilles Vreeken. CaUsal Inference by Compression. In 2016 IEEE 16th
International Conference on Data Mining (ICDM), pp. 41-50, Barcelona, Spain, December 2016.
IEEE. ISBN 978-1-5090-5473-2. doi: 10.1109/ICDM.2016.0015.
Kailash BUdhathoki and Jilles Vreeken. MDL for CaUsal Inference on Discrete Data. In 2017
IEEE International Conference on Data Mining (ICDM), pp. 751-756, November 2017. doi:
10.1109/ICDM.2017.87.
ShUxiao Chen, Edgar Dobriban, and Jane H. Lee. A groUp-theoretic framework for data aUgmenta-
tion. Journal of Machine Learning Research, 21(245):1-71, 2020. URL http://jmlr.org/
papers/v21/20-163.html.
David Maxwell Chickering. Optimal StrUctUre Identification With Greedy Search. Journal of
Machine Learning Research, 3(Nov):507-554, 2002. ISSN ISSN 1533-7928.
Taco S Cohen, T S Cohen, and Uva Nl. GroUp EqUivariant ConvolUtional Networks. pp. 10, 2016.
Elliot Creager, Jorn-Henrik Jacobsen, and Richard ZemeL Environment inference for invariant
learning. In International Conference on Machine Learning, pp. 2189-2200. PMLR, 2021.
10
Published as a conference paper at ICLR 2022
Alexander D’Amour, Katherine Heller, Dan Moldovan, Ben Adlam, Babak Alipanahi, Alex Beutel,
Christina Chen, Jonathan Deaton, Jacob Eisenstein, Matthew D Hoffman, et al. Underspecification
presents challenges for credibility in modern machine learning. arXiv preprint arXiv:2011.03395,
2020.
Tristan Deleu, Antdnio G6is, Chris Emezue, Mansi Rankawat, Simon Lacoste-JUlien, Stefan Bauer,
and Yoshua Bengio. Bayesian structure learning with generative flow networks. arXiv preprint
arXiv:2202.13903, 2022.
Chenwei Ding, Biwei Huang, Mingming Gong, Kun Zhang, Tongliang Liu, and Dacheng Tao.
Score-based Causal Discovery from Heterogeneous Data. September 2020.
Yann Dubois, Benjamin Bloem-Reddy, Karen Ullrich, and Chris J Maddison. Lossy compression for
lossless prediction. arXiv preprint arXiv:2106.10800, 2021.
Marc Finzi, Max Welling, and Andrew Gordon Wilson. A practical method for constructing equivari-
ant multilayer perceptrons for arbitrary matrix groups. arXiv preprint arXiv:2104.09459, 2021.
Robert Geirhos, Jorn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias
Bethge, and Felix A Wichmann. Shortcut learning in deep neural networks. Nature Machine
Intelligence, 2(11):665-673, 2020.
Olivier Goudet, Diviyan Kalainathan, Philippe Caillou, Isabelle Guyon, David Lopez-Paz, and
Michele Sebag. Causal generative neural networks. arXivpreprint arXiv:171L08936, 2017.
Christina Heinze-Deml, Marloes H. Maathuis, and Nicolai Meinshausen. Causal Structure Learning.
arXiv:1706.09141 [stat], June 2017.
Christina Heinze-Deml, Jonas Peters, and Nicolai Meinshausen. Invariant Causal Prediction for
Nonlinear Models. arXiv:1706.08576 [stat], September 2018.
Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta,
and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. In Advances
in Neural Information Processing Systems, 2020.
Biwei Huang, Kun Zhang, Yizhu Lin, Bernhard Scholkopf, and Clark Glymour. Generalized Score
Functions for Causal Discovery. KDD : proceedings. International Conference on Knowledge
Discovery & Data Mining, 2018:1551-1560, August 2018. ISSN 2154-817X. doi: 10.1145/
3219819.3220104.
Maximilian Ilse, Jakub M Tomczak, and Patrick Forr6. Selecting data augmentation for simulating
interventions. In International Conference on Machine Learning, pp. 4555-4562. PMLR, 2021.
Fredrik Johansson, Uri Shalit, and David Sontag. Learning representations for counterfactual
inference. In International conference on machine learning, pp. 3020-3029, 2016.
Divyansh Kaushik, Eduard Hovy, and Zachary Lipton. Learning the difference that makes a difference
with counterfactually-augmented data. In International Conference on Learning Representations,
2020. URL https://openreview.net/forum?id=Sklgs0NFvr.
Divyansh Kaushik, Amrith Setlur, Eduard H Hovy, and Zachary Chase Lipton. Explaining the efficacy
of counterfactually augmented data. In International Conference on Learning Representations,
2021. URL https://openreview.net/forum?id=HHiiQKWsOcV.
Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Bal-
subramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Sara Beery, et al. Wilds: A
benchmark of in-the-wild distribution shifts. arXiv preprint arXiv:2012.07421, 2020.
Risi Kondor and Shubhendu Trivedi. On the generalization of equivariance and convolution in neural
networks to the action of compact groups. In International Conference on Machine Learning, pp.
2747-2755. PMLR, 2018.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
11
Published as a conference paper at ICLR 2022
David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai
Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapola-
tion (rex). In International Conference on Machine Learning, pp. 5815-5826. PMLR, 2021.
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Deep transfer learning with joint
adaptation networks. In International conference on machine learning, pp. 2208-2217. PMLR,
2017.
Clare Lyle, Mark van der Wilk, Marta Kwiatkowska, Yarin Gal, and Benjamin Bloem-Reddy. On the
benefits of invariance in neural networks. arXiv preprint arXiv:2005.00178, 2020.
Haggai Maron, Heli Ben-Hamu, Nadav Shamir, and Yaron Lipman. Invariant and equivariant graph
networks. arXiv preprint arXiv:1812.09902, 2018.
S Chandra Mouli and Bruno Ribeiro. Neural network extrapolations with g-invariances from a
single environment. In International Conference on Learning Representations, 2021. URL
https://openreview.net/forum?id=7t1FcJUWhi3.
Krikamol MUandeL David Balduzzi, and Bernhard Scholkopf. Domain generalization via invariant
feature representation. In International Conference on Machine Learning, pp. 10-18, 2013.
R. Murphy, B. Srinivasan, V. Rao, and B. Ribeiro. Janossy pooling: Learning deep permutation-
invariant functions for variable-size inputs. In International Conference on Learning Representa-
tions, 2019a.
Ryan Murphy, Balasubramaniam Srinivasan, Vinayak Rao, and Bruno Ribeiro. Relational pooling for
graph representations. In Proceedings of the 36th International Conference on Machine Learning,
2019b.
J Pearl and D Mackenzie. The ladder of causation. The book of why: the new science of cause and
effect. New York (NY): Basic Books, pp. 23-52, 2018.
Jonas Peters, Peter Buhlmann, and Nicolai Meinshausen. Causal inference using invariant prediction:
identification and confidence intervals. arXiv preprint arXiv:1501.01332, 2015.
Liu Qidong, Tian Feng, Ji Weihua, and Zheng Qinghua. A new representation learning method for
individual treatment effect estimation: Split covariate representation network. In Asian Conference
on Machine Learning, pp. 811-822. PMLR, 2020.
Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. Dataset
shift in machine learning. The MIT Press, 2009.
Mateo Rojas-Carulla, Bernhard Scholkopf, Richard Turner, and Jonas Peters. Invariant models for
causal transfer learning. The Journal of Machine Learning Research, 19(1):1309-1342, 2018.
Joseph Rosen. Symmetry rules: How science and nature are founded on symmetry. Springer Science
& Business Media, 2008.
Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. The risks of invariant risk minimization.
arXiv preprint arXiv:2010.05761, 2020.
Bernhard Scholkopf. Causality for machine learning. In Probabilistic and Causal Inference: The
Works of Judea Pearl, pp. 765-804. 2022.
Bernhard Scholkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner,
Anirudh Goyal, and Yoshua Bengio. Toward causal representation learning. Proceedings of the
IEEE, 109(5):612-634, 2021.
Gideon Schwarz. Estimating the Dimension of a Model. The Annals of Statistics, 6(2):461-464,
March 1978. ISSN 0090-5364, 2168-8966. doi: 10.1214/aos/1176344136.
Uri Shalit, Fredrik D Johansson, and David Sontag. Estimating individual treatment effect: general-
ization bounds and algorithms. In International Conference on Machine Learning, pp. 3076-3085.
PMLR, 2017.
12
Published as a conference paper at ICLR 2022
John Shawe-Taylor. Symmetries and discriminability in feedforward network architectures. IEEE
Transactions on Neural Networks, 4(5):816-826, 1993.
Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-
likelihood function. Journal of statistical planning and inference, 90(2):227-244, 2000.
Yurii Mikhailovich Shtarkov. Universal sequential coding of single messages. Problemy Peredachi
Informatsii, 23(3):3-17, 1987.
Murray Sidman and William Tailby. Conditional discrimination vs. matching to sample: An expansion
of the testing paradigm. Journal of the Experimental Analysis of behavior, 37(1):5-22, 1982.
Murray Sidman, Ricki Rauzin, Ronald Lazar, Sharon Cunningham, William Tailby, and Philip
Carrigan. A search for symmetry in the conditional discriminations of rhesus monkeys, baboons,
and children. Journal of the experimental analysis of behavior, 37(1):23-44, 1982.
Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556, 2014.
Peter Spirtes, Clark Glymour, and Richard Scheines. Causation, Prediction, and Search, 2nd Edition.
MIT Press Books, The MIT Press, 2001.
Xiaohai Sun, Dominik Janzing, Bernhard Scholkopf, and Kenji FUkUmizu. A kernel-based causal
learning algorithm. In Proceedings of the 24th International Conference on Machine Learning,
ICML ’07, pp. 855-862, New York, NY, USA, June 2007. Association for Computing Machinery.
ISBN 978-1-59593-793-3. doi: 10.1145/1273496.1273604.
Damien Teney, Ehsan Abbasnedjad, and Anton van den Hengel. Learning what makes a difference
from Counterfactual examples and gradient supervision. In Computer Vision-ECCV 2020: 16th
European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, PartX 16, pp. 580-599.
Springer, 2020.
Mark van der Wilk, Matthias Bauer, ST John, and James Hensman. Learning invariances using the
marginal likelihood. In Advances in Neural Information Processing Systems, pp. 9938-9948, 2018.
Victor Veitch, Alexander D’Amour, Steve Yadlowsky, and Jacob Eisenstein. Counterfactual invariance
to spurious correlations: Why and how to pass stress tests. arXiv preprint arXiv:2106.00545, 2021.
Yixin Wang and Michael I. Jordan. Desiderata for Representation Learning: A Causal Perspective.
arXiv:2109.03795 [cs, stat], September 2021.
Gesche Westphal-Fitch, Ludwig Huber, Juan Carlos Gomez, and W Tecumseh Fitch. Production
and perception rules underlying visual patterns: effects of symmetry and hierarchy. Philosophical
Transactions of the Royal Society B: Biological Sciences, 367(1598):2007-2022, 2012.
Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ R Salakhutdinov, and
Alexander J Smola. Deep Sets. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,
S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems 30,
pp. 3391-3401. Curran Associates, Inc., 2017.
Kun Zhang, Mingming Gong, and Bernhard Scholkopf. Multi-source domain adaptation: A causal
view. In AAAI, volume 1, pp. 3150-3157, 2015.
Han Zhao, Remi Tachet Des Combes, Kun Zhang, and Geoffrey Gordon. On learning invariant
representations for domain adaptation. In International Conference on Machine Learning, pp.
7523-7532. PMLR, 2019.
Allan Zhou, Tom Knowles, and Chelsea Finn. Meta-Learning Symmetries by Reparameterization.
arXiv:2007.02933 [cs, stat], October 2020.
Shengyu Zhu, Ignavier Ng, and Zhitang Chen. Causal Discovery with Reinforcement Learning. pp.
17, 2020.
13
Published as a conference paper at ICLR 2022
A	Appendix
A.1 Justification for Assumption 1.
The above assumption is inspired by the deep relationship between symmetries and intelligence.
Young children, unlike monkeys and baboons, assume that a conditional stimulus F given another
stimulus D extrapolates to a symmetric relation D given F without ever seeing any such examples (Sid-
man et al., 1982). That is, if given D, action F produces a treat, the child assumes that given F, action
D also produces a treat. Young children differ from primates in their ability to use symmetries to
build conceptual relations beyond visual patterns (Sidman & Tailby, 1982; Westphal-Fitch et al.,
2012), allowing extrapolations from intelligent reasoning. However, forcing symmetries against
data evidence is undesirable, since symmetries can provide valuable information when they are
broken. Unsurprising, humans are generally able to quickly find and pay attention to some types of
asymmetries.
A.2 Proof of Theorem 1
Theorem 1 (Counterfactual invariance & causal DAG identification). Let X{ „i be lumpable given
every Tpjq,j ‰ i as in Definition 2. Then, the structural causal DAG implied by Equations (2) to (4)
(depicted in Figure 2a(i)) does not contain the edge Ui → Y iff
∣p pγ ∣ΓiPχ q, UY q ´ P(Y ∣χ, UY q∣ TV “ 0,	(5)
@PpX:q, @PpU1q, . . . , @P pUm q, where Γi is a most-expressive representation that is invariant with
respect to „i .
Proof. Notation (following Equation (3)): The observed input X is X	:“
t(Jι,...,Uiτ,Ui, Ui'i,..., Umq 0 X: where t(Uι,..., Umq is obtained by interleaving
the transformation sequences from each individual U1 , . . . , Um and we have set Ui “ ui .
Necessity: We wish to show that if the SCM does not contain edge Ui → Y, then Equation (5) holds
for all P(X:q, P(U1q, . . . , P(Umq. By this assumption, Y outputs the same label for any value of Ui.
Consider the collection of equivalence classes X{ „i. By the lumpability condition of Definition 2, all
transformations tpjq P T pjq, j ‰ i, map all points in one equivalence class of „i to points in a different
one. On the other hand, all transformations tpiq P Tpiq map points to other points within the same
equivalence class under „i . Now, consider the equivalence class of X after all the transformations
have been applied to X:. The equivalence class of X “ t(Uι,..., Ui—i, Ui, Ui,'i,..., Um) 0 X: is
the same as that of X* “ t(Ui,..., Ui—i, Uid, Ui,'i,..., Um) 0 X: where Ui “ Uid always selects
identity transformations. This is because changing Ui to Uiid only impacts the transformations chosen
from T piq, and these transformations do not change the equivalence class under „i. Thus, we have
shown that we reach the same equivalence class under „i for both X and X*.
Now let Γi be a most-expressive representation that is invariant with respect to „i. By definition, Γi
outputs the same value within an equivalence class, thus, Γi (Xq “ Γi(X*q. But since by assumption
Ui → Y does not exist, X and X * have the same label always. Thus, there is no loss of information
incurred by Γi in predicting Y with the additional restraint Γi(Xq “ Γi(X*q. Since Γi is most-
expressive, We have P (Y “ y∣Γi(X ),Uγ) “ P (Y “ y|X, Uγ) for all y P Y. This holds for all
values of Ui, and hence we get the desired result for any distribution P(Uiq.
Sufficiency: We wish to show that if Equation (5) holds for all P (X:) and P (Ui),..., P (Um), then
there is no edge Ui → Y in the causal graph. We will prove by contrapositive: Assume there is an
edge Ui → Y, then we will show there exists distributions P(X:) and P(Ui), . . . , P(Um) such that
Equation (5) does not hold.
Define P(X:) “ δx: for some x: P X where δ denotes a Dirac-delta function. Define P(Ui “
Uiid) “ 0.5 and P(Ui “ Ui) “ 0.5 for Uiid, Ui P supp(Ui). As usual, Uiid always selects the identity
transformation, and Ui selects a single transformation tui P T piq. Similarly, for all j ‰ i, define
P(Uj) “ δuid for Uijd P supp(Uj ) that only select identity transformations. Now, there are two
possible observed inputs: x “ t(Uiid, . . . , Uimd ) 0 x: “ x: and x1 “ t(Uiid, . . . , Ui, . . . , Uimd ) 0 x: “
tui 0 x:. Finally, define Y :“ 1(Ui “ Uiid), thus x and x1 have different labels. But, any invariant
14
Published as a conference paper at ICLR 2022
representation Γi by definition has Γi pxq “ Γi px1q since they belong to the same equivalence class.
Thus, even if Γi is most-expressive, We have |P(Y∣Γi(X), UY) — P(Y∣X,Uγ)∣τv = 05
□
A.3 Additional Related Work
Counterfactual invariances. Wang & Jordan (2021) use counterfactual language to formally
define and learn non-spurious, disentangled representations from a single environment. Our Work
is different in the folloWing Ways. In the structural causal model (SCM) of their Work, the authors
assume that there are no confounders betWeen the observed X and the label Y. HoWever, in our
SCM (Figure 2a(i)), We alloW unobserved confounders X: and Ui , i P D. The hidden transformation
variables Ui , i P D are confounders because they affect both the observed input X and the labels Y.
We leverage the fact that the confounders are related to symmetries (and do not affect X arbitrarily)
to resolve the issue With unobserved confounding. Wang & Jordan (2021) also require pinpointability
of the cause of the observed X . In our setting, this is typically not possible since there are multiple
paths of transformations from X : to the same observed X . Thus, all the parents of X may not be
pinpointable, specifically the transformation variables U1, . . . , Um.
Kaushik et al. (2020; 2021) propose counterfactual data augmentation for text datasets Where human
annotators are asked to make minimal modifications to the input document so as to change its
label (for example, by changing a feW positive Words to negative Words) While keeping style, etc.
fixed. This type of augmentation essentially asks the labelers to identify all the causal features in
the document and make modifications to those features alone. This can be seen as obtaining neW
counterfactual examples by simulating the causal model and requires knoWing the true function that
describes hoW the features affect the labels. We consider the more realistic setting Where We do not
have access to such a collection of counterfactual examples. In this Work, We consider the traditional
automated data augmentations under a mostly unknoWn data generation process, as opposed to the
counterfactual data augmentation (Kaushik et al., 2020) that either considers a fully-specified toy
SCM or relies on humans-in-the-loop to generate counterfactual data.
In Figure 1(c) We shoW that the standard data augmentation is not sufficient for the OOD task.
HoWever, if one had access to the fully-specified causal model, one could generate the counterfactual
data shoWn in Figure 1(d) and learn an OOD classifier With the counterfactually augmented data
(as done by Kaushik et al. (2020)). But our Work does not assume access to these counterfactual
examples. Additionally, We prove that a counterfactual invariant classifier can be constructed from
traditional data augmentation alone if the lumpability condition (Definition 2) is satisfied. This is not
the case in Figure 1(d).
Veitch et al. (2021) define counterfactual invariant predictors f(X) When X has a single parent Z and
provide conditions such predictors must satisfy over the observed distribution (given an SCM). Note
also that Veitch et al. (2021) assume that part of the observed input X (XZK) is not causally influenced
by the confounder Z . In our scenarios this is not generally true. For example, under a color change,
the entire observed image X changes. Still, We shoW that the notion of a counterfactual invariant
predictor exists. Hence, the definition of Veitch et al. (2021, Lemma 3.1) of a counterfactually
invariant predictor that requires a segment of X to not causally depend on Z, a fundamental result of
their Work, unfortunately does not apply to our setting (since X may have no such segment).
A.4 MNIST-t3, 4u EXPERIMENTS WITH FINITE TRANSFORMATION GROUPS
We test our proposed method on out-of-distribution tasks on images Where the equivalence relations
(symmetries) are provided as transformation groups (e.g., 90° rotations). We use the MNIST-{3,4}
(colored) dataset (Mouli & Ribeiro, 2021) that only contains digits 3 and 4, and folloW their experi-
mental setup. MNIST-t3, 4} is used to avoid any confounding factors While testing if the proposed
method can learn the correct invariances, not for any practical considerations (e.g., rotated 6 is a 9
and Would interfere With some experiments, etc.).
We consider equivalence relations obtained from 3 different transformation groups: rotations by 90°
(denoted Grot), vertically flipping the image (denoted Gv-flip), and permuting the RGB color channels
of the image (denoted Gcol). The 3 corresponding equivalence relations are lumpable (Definition 2)
With respect to the transformations in the other tWo groups in almost all the cases. Only exception
15
Published as a conference paper at ICLR 2022
Table 2: Results for different function classes on the MNIST-t3, 4u classification task with Ds “
trot, col, vflipu, D “ H, i.e., task is invariant to 3 groups (Ds) and sensitive to none (D). RpF q, C{OMPpF, Dq
and SpF, Dq are as discussed in Section 4.2. Bold values indicate the function class chosen by GES method
with the proposed scoring criterion. Test accuracy is computed on the extrapolated dataset after shifting the
distribution of P ptUi uiPDs q. We see that the SpF, Dq loss selects the correct model class in training.
Model class	R(F)	+ C{OMP(F, D)	+ NLL(F, D)	“ S(F, D)	Train Acc Test Acc
uufl
u fli fli uol ol,
p v vcc
uvfl col col rot rot rot rot
FtFtFtFtFtFtFtFt
73313110
6639.310	0.013	6646.324	100.00 ( 0.00)	48.38 ( 5.22)
6639.241	0.079	6642.320	100.00 ( 0.00)	47.08 ( 5.34)
6639.241	0.029	6642.270	100.00 ( 0.00)	53.92 ( 2.47)
6639.241	0.099	6640.340	100.00 ( 0.00)	53.15 ( 1.83)
6639.241	0.037	6642.278	100.00 ( 0.00)	53.06 (10.00)
6639.241	0.580	6640.821	100.00 ( 0.01)	54.86 (13.60)
6639.241	0.043	6640.284	100.00 ( 0.00)	90.29 ( 6.76)
6639.241	0.210	6639.451	100.00 ( 0.00)	92.02 ( 2.99)
Table 3: Results for different function classes on the MNIST-t3, 4u classification task with Ds “ trot, vflipu, D “
tcolu, i.e., task is invariant to rotation and vertical flip groups (D) but sensitive to color (D). RpF q, COMPpF, Dq
and SpF, Dq are as discussed in Section 4.2. Bold values indicate the function class chosen by GES method
with the proposed scoring criterion. Test accuracy is computed on the extrapolated dataset after shifting the
distribution of P ptUi uiPDs q. We see that the SpF, Dq loss selects the correct model class in training.
Model class	R(F)	+ COMP(F, D)	+ NLL(F, D) “ SpF, D)	Train Acc Test Acc
puv v c c
uvfl col col rot rot rot rot
FtFtFtFtFtFtFtFt
73313110
6639.241	0.010	6646.251	100.00 ( 0.00)	54.79 ( 0.74)
6639.241	0.012	6642.253	100.00 ( 0.00)	55.05 ( 1.56)
6639.240	8269.480	14911.720	41.98 ( 5.79)	18.81 ( 2.94)
6639.241	8275.716	14915.957	42.71 ( 4.07)	18.62 ( 2.25)
6638.946	0.132	6642.078	100.00 ( 0.00)	91.40 ( 3.19)
6638.428	0.504	6639.932	100.00 ( 0.00)	92.32 ( 1.84)
6639.241	8412.954	15053.194	37.20 ( 1.97)	29.25 ( 5.18)
6639.239	8389.719	15028.958	38.01 ( 2.02)	29.98 ( 3.96)
is the equivalence relation „v-flip, which is not lumpable with respect to the transformations in Grot.
Consequently, we do not consider a task with invariance to vertical flip alone. We test our method on
the same 4 classification tasks proposed by Mouli & Ribeiro (2021) where each task represents the
case where the target Y has different invariances, i.e., invariant to all three groups, to two, to one,
invariant to none (the task is sensitive to the remaining groups).
We use the VGG architecture (Simonyan & Zisserman, 2014) for image classification and construct a
collection of function classes F :“ [FS : S ɑ trot, col, v-flip}} corresponding to various invariant
representations. For example, Ftrot,colu is a space of functions (CNNs) that are G-invariant to the
rotation and color-permutation groups (Grot and Gcol), and FH is the space of functions with no
invariance (standard CNN).
Results. Our results are shown in Tables 2 to 5 for the four tasks respectively where the label is (i)
invariant to all three groups, (ii) invariant to only rotation and vertical flips, (iii) invariant to color-
permutation, and (iv) invariant to none. We show the values for RpF q, COMPpF, Dq and SpF, Dq
as as discussed in Section 4.2. Bold values in the tables indicate the function class chosen by GES
method with the proposed scoring criterion (minimizing SpF , Dq). Test accuracy is computed on the
extrapolated dataset after shifting the distribution of P ptUi uiPDs q (i.e., by applying the transformations
that the label is invariant to).
In Tables 2 and 3, we see that the proposed method selects the correct model class in training and
achieves the best OOD test accuracy. In Tables 4 and 5, the method is excessively invariant (to
vertical flip) but still achieves within 1% of the best OOD test accuracy. The OOD test accuracy of a
16
Published as a conference paper at ICLR 2022
Table 4: Results for different function classes on the MNIST-t3, 4u classification task with Ds “ tcolu, D


trot, vflipu, i.e., task is invariant to color (Ds) but sensitive to rotation and vertical flips (D). RpF q, COMPpF, Dq
and SpF, Dq are as discussed in Section 4.2. Bold values indicate the function class chosen by GES method
with the proposed scoring criterion. Test accuracy is computed on the extrapolated dataset after shifting the
distribution of P ptUi uiPDs q. We see that the SpF, Dq loss selects a model that is excessively invariant in training,
but the test accuracy is not that much penalized by the extra invariance (vertical flips).
	——				“ SpF, Dq	Train Acc	Test Acc
Model class	RpFq	` COMPpF, Dq	` NLLpF, Dq			
Ftu	7	6639.241	2.395	6648.636	100.00 ( 0.01)	16.87 ( 5.88)
Ftvflipu	3	6639.233	5.370	6647.603	99.99 ( 0.05)	15.71 ( 5.53)
Ftcolu	3	6639.196	2.315	6644.512	100.00 ( 0.00)	97.28 ( 0.28)
Ftcol,vflipu	1	6639.240	3.098	6643.337	100.00 ( 0.00)	96.82 ( 0.54)
Ftrotu	3	6639.228	5296.755	11938.984	56.17 ( 3.90)	6.20 ( 0.86)
Ftrot,vflipu	1	6639.221	5325.008	11965.228	55.96 ( 5.39)	7.24 ( 1.48)
Ftrot,colu	1	6639.218	5322.015	11962.233	56.14 ( 3.31)	47.98 ( 1.34)
Ftrot,col,vflipu	0	6639.230	5342.805	11982.035	55.32 ( 3.80)	49.25 ( 3.09)
Table 5: Results for different function classes on the MNIST-t3, 4u classification task with Ds “ H, D “
trot, col, vflipu, i.e., task is sensitive to all three groups (D) and insensitive to none (D). RpF q, COMPpF, Dq
and SpF, Dq are as discussed in Section 4.2. Bold values indicate the function class chosen by GES method
with the proposed scoring criterion. Test accuracy is computed on the extrapolated dataset after shifting the
distribution of P ptUi uiPDs q. We see that the SpF, Dq loss selects a model that is excessively invariant in training,
but the test accuracy is not that much penalized by the extra invariance (vertical flip).
	——				“ SpF, Dq	Train Acc	Test Acc
Model class	RpFq	` COMPpF, Dq	` NLLpF, Dq			
Ftu	7	6639.165	1.195	6647.360	100.00 ( 0.00)	96.00 ( 0.60)
Ftvflipu	3	6639.117	3.548	6645.665	100.00 ( 0.00)	95.18 ( 0.45)
Ftcolu	3	6639.192	7536.167	14178.359	58.77 ( 3.34)	32.45 ( 2.18)
Ftcol,vflipu	1	6639.184	7902.462	14542.645	52.50 ( 7.64)	31.21 ( 2.48)
Ftrot,colu	1	6639.088	13628.356	20268.443	23.78 ( 2.25)	15.93 ( 0.71)
Ftrotu	3	6639.153	5259.957	11902.110	58.12 ( 4.05)	47.23 ( 1.89)
Ftrot,vflipu	1	6639.827	5267.771	11908.598	57.13 ( 1.38)	47.57 ( 2.15)
Ftrot,col,vflipu	0	6639.055	13705.123	20344.178	22.97 ( 3.32)	16.13 ( 2.22)
standard CNN with no invariance (FH) is typically very low except in Table 5 where sensitivity to all
groups is required. We can also see the importance of RpFq for tie-breaking in these experiments.
As discussed in Section 4.2, COMPpF, Dq is unable to distinguish between the different function
classes because the training data contains a single example per equivalence class (see Figure 2c).
A.5 CIFAR 1 0 experiments with infinite/nongroup transformation sets
In this section, we test our proposed method on out-of-distribution tasks on CIFAR10 im-
ages (Krizhevsky et al., 2009) where the equivalence relations are provided as infinite sets of
transformations that may not form a group. We used (a) arbitrary rotation transformations over an
image (denoted Trot), and (b) shifting the hue of an image (denoted Tcol). Note that for a bounded
image, arbitrary rotation is not a group due to cropping. Further, transformations from the respective
sets commute with each other, and hence, the lumpability condition is satisfied (Definition 2) for the
corresponding equivalence relations.
We tested our method on 2 classification tasks: (i) invariant to both sets of transformations (arbitrary
rotations and hue shifts), and (ii) invariant to arbitrary rotations, but sensitive to hue shifts. As before,
we use the VGG architecture (Simonyan & Zisserman, 2014) for image classification and construct a
collection of function classes F :“ {F⅛ : S J trot, col}} corresponding to the various invariant
representations. We use data augmentation to construct these invariant representations (this is possible
since the lumpability condition holds). For example, Ftrot,colu refers to CNNs that were trained by
17
Published as a conference paper at ICLR 2022
Table 6: Results for different function classes on the CIFAR10 classification task with two sets of transformations
(transformations that do not form groups) on images: arbitrary rotations (with cropping due to rotation) and
arbitrary hue shifts. The task is invariant to both sets of transformations (Ds) and sensitive to none (D). RpF q,
/ T- zτ-χ∖	1 C / -T- zτ-χ∖	T	1 -	<-1	"CGlT 1	∙1∙,,1C	，•	1	1	1
COMPpF, Dq and SpF, Dq are as discussed in Section 4.2. Bold values indicate the function class chosen by
GES method with the proposed scoring criterion. Test accuracy is computed on the extrapolated dataset after
shifting the distribution of P ptUi uiPDs q. We see that the SpF, Dq loss selects the correct model class in training.
一一 _	___ r------，_ _、	，_ _、	____
Model class	RpFq	` COMPpF, Dq ` NLLpF, Dq	“ SpF, Dq Train Acc Test Acc
uuco,
ucol rot rot
FtFtFtFt
3	27725.875	17496.615	45225.490	85.60	21.48
1	27716.947	22715.956	50433.903	81.28	21.85
1	-60894.145	20365.793	-40527.352	82.65	45.12
0	-66262.157	23538.768	-42723.390	79.99	69.35
Table 7: Results for different function classes on the CIFAR10 classification task with two sets of transformations
(transformations that do not form groups) on images: arbitrary angle rotations (with cropping due to rotation)
and arbitrary hue shifts. The task is invariant to arbitrary rotations of the image (Ds ) but sensitive to color (D).
RpF q, COMPpF, Dq and SpF, Dq are as discussed in Section 4.2. Bold values indicate the function class
chosen by GES method with the proposed scoring criterion. Test accuracy is computed on the extrapolated
dataset after shifting the distribution of P ptUi uiPDs q. We see that the SpF, Dq loss selects the correct model
class in training.
Model class	RpFq	` C{OMPpF, Dq ` NLLpF, Dq	“ SpF, Dq Train Acc Test Acc
uuco,
ucol rot rot
FtFtFtFt
3	27724.256	42166.993	69894.250	64.37	17.16
1	27715.023	49744.680	77460.703	42.69	10.91
1	-91370.533	46218.086	-45151.447	61.77	52.60
0	-92009.184	50246.908	-41762.276	41.45	35.56
augmenting both arbitrarily rotated images and hue-shifted images. Once again, FH is the space of
functions with no invariance (standard CNN with no data augmentations).
Results. We show in Tables 6 and 7 that our method is able to find the correct invariance and
achieves the best OOD test accuracy whereas the standard CNN with no invariance has poor OOD
performance.
A.6 More on lumpability (Definition 2)
We show that the lumpability condition of Definition 2 is equivalent to the normal subgroup condition
of Mouli & Ribeiro (2021, Theorem 2) when the given equivalence relations are obtained from trans-
formation groups. However, unlike the normal subgroup condition, the lumpability condition applies
in the general case when the equivalence relations are not necessarily obtained via transformation
groups.
Proposition 1. Let „G1 and „G2 be two equivalence relations on the input space X obtained as
orbits under transformation groups G1 and G2 respectively, i.e., for i “ 1, 2, x „Gi x1 iff there
exists tpiq P Gi with X “ tpiq Q x. Then,〜g】is lumpable with respect to the transformations G?
(Definition 2) if and only if G1 is a normal subgroup of G1 _ G2, where _ is the join operator.
Proof. First, given 〜g】is lumpable with respect to G?, We wish to prove that Gi is a normal
subgroup of G1 _ G2. By definition of the join operator on transformation groups, G1 is a subgroup
of G1 _ G2.
Next, consider an equivalence class [x]gi P X/ 〜g「Then, by the lumpability of 〜g】with respect
to G?, we have that for all tp2q P G?, there exists [x[gi with x* P [x]gi =^ tp2q Q x* P [x]gi .
In other words, each tp2q maps all points in one equivalence class rxsG】 to another equivalence class
18
Published as a conference paper at ICLR 2022
[x[gi . Specifically, tp2q maps X P [x]gi to tp2q o X P [x[gi . Thus, We can set x1 “ tp2q o X without
loss of generality.
Then, for all tp2q P G2 , we have from the lumpability condition that
X* P [x]gi =^ tp2q o X* P rtp2q O x]gi .	(9)
Recall from the definition of the equivalence class derived from a transformation group (i.e., the
orbit) that X* P rXsG1 means that there exists a transformation tp1q P G1 that maps X to X*, i.e.,
X* “ tp1q o X. Similarly, tp2q o x* P "(2)o x]gi means that there exists another transformation tp1q
such that tp2q o X* “ t^p1q o tp2q o x.
Equation (9) then becomes
Dt⑴ P Gi s.t. x* “ tp1q o x =^ Dfp1q P Gi s.t. tp2q o x* “ tp1q o tp2q o X ,	(10)
for all tp2q P G2 .
Since Equation (10) holds for all X* P rXsG1 and for all X P X, we have @tp2q P G2, @tpiq P
Gi, Dfpiq P Gi such that,
t(2) o tpiq “ fpiq o tp2q ,
which implies that Gi is a normal subgroup of Gi _ G2 . The converse can be proved trivially by
reversing the steps of the above proof.
□
19