Table 1: Comparison of the complexity and the maximum signal traveling path for different models,where G is the number of global tokens in ETC. In practice, the G increases with L, and so thecomplexity of ETC is super-linear.
Table 2: Single-step forecasting results on three datasets. “Q-K pairs” refer to the number of query-key dot products performed by all attention layers in the network, which encodes the time and spacecomplexity. We write the number of attention layers by N , the number of attention heads by H, thenumber of scales by S, the dimension of a node by D, the dimension of a key by DK , the maximumdimension of feed-forward layer by DF, and the convolution stride by C.
Table 3: Long-range multi-step forecasting results.
Table 4: Meanings of notations.		Notation	Size	MeaningL	Constant	The length of historical sequence.
Table 5: Hyper-parameter settings of long-range experiments.
Table 6: Long-range forecasting results on the synthetic dataset.
Table 7: Impact of A and C on long-range forecasting. The history length is 336.
Table 8: Impact of the CSCM architecture on long-range Table 9: Impact of history length.
Table 10: Impact of the PAM.
