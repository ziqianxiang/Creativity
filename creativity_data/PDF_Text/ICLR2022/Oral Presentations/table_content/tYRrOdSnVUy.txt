Table 1: The performance difference of digit datasets between Supervised Learning and Target-Specified NTL The left of '⇒' is the precision (%) in the target when the model is trained on thesource dataset with Supervised Learning. The right of '⇒'is the precision of the model trained withTarget-Specified NTL. The last two columns present the average relative performance drop in thesource and target respectively. It shows that NTL can degrade the performance in the target domainswhile retaining good performance in the source.
Table 2: The results of Target-Specified NTL on ownership verification and the performance afterapplying different watermark removal methods. Compared to Supervised Learning, models trainedwith Target-Specified NTL behave differently depending on whether the data fed to it contains atrigger patch. Applying 6 state-of-art watermark removal approaches on models of NTL does notimpact the effectiveness of ownership verification.
Table 3: The performance difference of digit datasets between Supervised Learning and Source-Only NTL. Non-S means non-source domain. The left of '⇒' shows the precision (%) of the modeltrained on the source dataset with Supervised Learning. The right is the model precision usingSource-Only NTL. The last two columns present the average relative precision drop on the sourceand non-source domain. It shows that Source-Only NTL can effectively degrade the performance innon-source domains without significant sacrifice of source performance.
Table 4: The performance of authorizing applicability of models trained with Source-Only NTL ondigits. NTL-based model authorization can enable the model to perform well only on the authorizeddomain - the source data attached with the authorized patch.
Table 5: The architecture of classification models. ‘img’ is the dimension of representations ex-tracted from the feature extractor._____________________________________________Classifier	Linear(256, K). Linear(256, 256), ReLU, Dropout; Linear(512*img*img, 256), ReLU, Dropout;Feature Extractor	Backbone Network (VGG-11/VGG-13/VGG-19/ResNet50) 	[10:].	Feature Extractor	Backbone Network (VGG-11/VGG-13/VGG-19/ResNet50) 	[0:10].	18Published as a conference paper at ICLR 2022Table 6: The architecture of the generator G. ‘dim’ is the dimension sum of the latent space andinput label.
Table 6: The architecture of the generator G. ‘dim’ is the dimension sum of the latent space andinput label.
Table 7: The architecture of the discriminator D.
Table 8: The experiments on different values of the scaling factor α.
Table 9: The experiments on different values of the scaling factor a0.
Table 10: The results (%) of authorizing model usage on CIFAR10 & STL10 and VisDA.
Table 11: The experiment results (%) of VisDA on VGG-19.
Table 12: The error range (%) of experiment results for Supervised Learning and Target-SpecifiedNTL respectively (the left of '/' is Supervised Learning, and the right is Target-Specified NTL).
Table 13: The error range (%) of experiment results for Supervised Learning and Source-Only NTLrespectively (the left of '/' is Supervised Learning, and the right is Source-Only NTL).
Table 14: The error range (%) of experiment results for authorizing usage of models trained withSource-Only NTL on digits.
Table 15: The Source-Only NTL performance with different Gaussian kernel bandwidths (controlledby mul and num). The left of ‘/’ is the performance on the source data, and the right is the averageperformance on the target data.
