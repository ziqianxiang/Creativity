title,year,conference
 Neural networks and deep learning,2018, Springer
 Mxnet: A flexible and efficient machine learning library forheterogeneous distributed systems,2015, arXiv preprint arXiv:1512
 Array programmingwith NumPy,2020, Nature
 Vision permu-tator: A permutable mlp-like architecture for visual recognition,2021, arXiv preprint arXiv:2106
 xarray: N-D labeled arrays and datasets in Python,2017, Journal of OpenResearch Software
" Implementation of ""attention is all you need"" paper",2018, https://github
 A programming language,1962, In Proceedings of the May 1-3
 Highly accurateprotein structure prediction with alphafold,2021, Nature
 Nemo: a toolkit for bUilding aiapplications Using neUral modUles,2019, arXiv preprint arXiv:1909
 Pay attention to mlps,2021, Advances in NeuralInformation Processing Systems
 namedtensor python package,2019, https://github
 CUpy: A nUmpy-compatible library for nVidia gpU calcUlations,2017, In Proceedings of Workshop on Machine LearningSystems (LearningSys) in The Thirty-first Annual Conference on Neural Information Process-ing Systems (NIPS)
 DocUmentation for Pytorch named tensors,2019, https://pytorch
 Chainer: A deep learning frameworkfor accelerating the research cycle,2019, In Proceedings of the 25th ACM SIGKDD InternationalConference on Knowledge Discovery & Data Mining
 Mlp-mixer: Anall-mlp architecture for vision,2021, Advances in Neural Information Processing Systems
 Resmlp: Feedforwardnetworks for image classification with data-efficient training,2021, arXiv preprint arXiv:2105
 Python 3 Reference Manual,1441, CreateSpace
 Tensor comprehen-sions: Framework-agnostic high-performance machine learning abstractions,2018, arXiv preprintarXiv:1802
 Matog: Array layout auto-tuning for cuda,2017, ACM Transactionson Architecture and Code Optimization (TACO)
 Cvt:Introducing convolutions to vision transformers,2021, In Proceedings of the IEEE/CVF InternationalConference on Computer Vision
