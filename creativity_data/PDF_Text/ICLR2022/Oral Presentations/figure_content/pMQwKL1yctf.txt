Figure 1: Latent space for a positive triplet of sentences (x0, xt, xT ) that are part of the same conversation.
Figure 2: Time Control generates text conditioned on a latent plan. A latent plan is first generated by runningBrownian bridge dynamics pinned between a sampled start z0 and goal latent variable zT forward. A decoderthen conditionally generates from this latent plan on a sentence-level.
Figure 3:	Example 1 of GPT2 forced long text generation.
Figure 4:	Example 2 of GPT2 forced long text generation.
Figure 5:	Example 1 of Time Control forced long text generation.
Figure 6:	Example 2 of Time Control forced long text generation.
Figure 7: Time Control’s latent trajectories over coherent vs. incoherent (randomly scrambled)held-out Wikisection documents. The encoder learns Brownian bridge-like latent trajectories overthe coherent documents. The incoherent documents map to noisy trajectories that don’t evolve overtime.
Figure 8: Implicit Dynamics’s latent trajectories over coherent vs. incoherent (randomly scrambled)held-out Wikisection documents.
Figure 9: Brownian motion’s latent trajectories over coherent vs. incoherent (randomly scrambled)held-out Wikisection documents.
Figure 10:	Variational Auto-Encoder’s latent trajectories over coherent vs. incoherent (randomlyscrambled) held-out Wikisection documents.
Figure 11:	Comparing the latent structure recovered by the VAEbaseline and TC on held-out Recipedocuments. Noticeably, TC learns temporally relevant activations whereas VAE latent does notcorrelate with time.
Figure 12: Recovered latent trajectories on held-out Wikisection documents where we used pair-wise contrasts with varying time distances; this was on TC, d = 8. Notice how the recovered latentstructure varies depending on k, the distance between sampled sentences.
