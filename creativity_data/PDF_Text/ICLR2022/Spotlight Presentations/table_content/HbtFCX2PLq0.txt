Table 1: Results for OpenML datasets under churn at cold accuracy metric.
Table 2: Results for MNIST variants, SVHN and CIFAR10 under churn at cold accuracy metric.
Table 3: Results for OpenML datasets for initial sample size 100 under churn at cold accuracy metricacross different sizes of fully connected networks. Part 1 of 2.
Table 4: Results for OpenML datasets for initial sample size 100 under churn at cold accuracy metricacross different sizes of fully connected networks. Part 2 of 2.
Table 5: OpenML Error Bands for initial sample size 100: Average standard errors for error andchurn across baselines for each dataset and network across 100 runs.
Table 6: Results for OpenML datasets with initial sample size 1000 under churn at cold accuracymetric across different sizes of fully connected networks. Part 1 of 2.
Table 7: Results for OpenML datasets with initial sample size 1000 under churn at cold accuracymetric across different sizes of fully connected networks. Part 2 of 2.
Table 8: OpenML Error Bands with initial sample size 1000: Average standard errors for error andchurn across baselines for each dataset and network across 100 runs.
Table 9: Results for MNIST variants with initial sample 100 under churn at cold accuracy metricacross different sizes of convolutional networks.
Table 10: MNIST Error Bands with initial sample size 100: Average standard errors for error andchurn across baselines for each dataset and network across 100 runs.
Table 11: Results for MNIST variants under churn at cold accuracy metric across different sizes ofconvolutional networks with initial sample size 1000..
Table 12: MNIST Error Bands with initial sample size 1000: Average standard errors for error andchurn across baselines for each dataset and network across 100 runs.
Table 13: Results for MNIST variants with initial sample 10000 under churn at cold accuracy metricacross different sizes of convolutional networks.
Table 14: MNIST Error Bands with initial sample size 10000: Average standard errors for error andchurn across baselines for each dataset and network across 100 runs.
Table 15: Results for SVHN and CIFAR datasets with initial sample size 100 under churn at coldaccuracy metric across different sizes of convolutional networks..
Table 16: SVHN and CIFAR with initial sample size 100 Error Bands: Average standard errors forerror and churn across baselines for each dataset and network across 100 runs.
Table 17: Results for SVHN and CIFAR under churn at cold accuracy metric across network sizes.
Table 18: SVHN and CIFAR with initial sample size 1000 Error Bands: Average standard errors forerror and churn across baselines for each dataset and network across 100 runs.
Table 19: Results for SVHN and CIFAR datasets with initial sample size 10000 under churn at coldaccuracy metric across different sizes of convolutional networks..
Table 20: SVHN and CIFAR with initial sample size 10000 Error Bands: Average standard errors forerror and churn across baselines for each dataset and network across 100 runs.
Table 21: Results for CelebA tasks under churn at cold accuracy metric across different sizes ofconvolutional networks with initial sample 100. Part 1 of4.
Table 22: Results for CelebA tasks under churn at cold accuracy metric across different sizes ofconvolutional networks with initial sample 100. Part 2 of4.
Table 23: Results for CelebA tasks under churn at cold accuracy metric across different sizes ofconvolutional networks with initial sample 100. Part 3 of4.
Table 24: Results for CelebA tasks under churn at cold accuracy metric across different sizes ofconvolutional networks with initial sample 100. Part 4 of4.
Table 25: CelebA Error Bands with initial sample 100: Average standard errors for error and churnacross baselines for each dataset and network across 100 runs.
Table 26: Results for CelebA tasks under churn at cold accuracy metric across different sizes ofconvolutional networks. Part 1 of 4.
Table 27: Results for CelebA tasks under churn at cold accuracy metric across different sizes ofconvolutional networks. Part 2 of 4.
Table 28: Results for CelebA tasks under churn at cold accuracy metric across different sizes ofconvolutional networks. Part 3 of 4.
Table 29: Results for CelebA tasks under churn at cold accuracy metric across different sizes ofconvolutional networks. Part 4 of 4.
Table 30: CelebA Error Bands: Average standard errors for error and churn across baselines for eachdataset and network across 100 runs.
Table 31: Results for CelebA tasks under churn at cold accuracy metric across different sizes ofconvolutional networks with initial sample 10000. Part 1 of 4.
Table 32: Results for CelebA tasks under churn at cold accuracy metric across different sizes ofconvolutional networks with initial sample 10000. Part 2 of 4.
Table 33: Results for CelebA tasks under churn at cold accuracy metric across different sizes ofconvolutional networks with initial sample 10000. Part 3 of 4.
Table 34: Results for CelebA tasks under churn at cold accuracy metric across different sizes ofconvolutional networks with initial sample 10000. Part 4 of 4.
Table 35: CelebA Error Bands with initial sample 10000: Average standard errors for error and churnacross baselines for each dataset and network across 100 runs.
Table 36: Results for CIFAR10 and CIFAR100 under churn at cold accuracy metric across ResNet-50,ResNet-101 and ResNet-152. Initial sample size and batch size is fixed at 1000..
Table 37: Results for IMDB under churn at cold accuracy metric across different sizes of transformernetworks and initial sample sizes. Batch size is fixed at 1000.
Table 38: IMDB Error Bands: Mean standard errors for error and churn across baselines for eachdataset and network across 100 runs.
