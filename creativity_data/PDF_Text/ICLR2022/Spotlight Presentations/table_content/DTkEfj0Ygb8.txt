Table 1: Hyper-parameter ranges of Adaboost, Random Forest and SVM17Published as a conference paper at ICLR 2022Methods	Parametersbalancing	strategyadaboost	learning_rate, max_depth, n_estimatorsbernoulli_nb	fit_priordecision_tree	max_depth_factor, max_features, max_leaf_nodes, min_impurity_deCreaSe, min_SampleS_leaf, min_SampleS_Split, min_weight_fraction_leaf ,	extra_trees	-criterion, max_depth, max_features, max_leaf_nodeS, min_impurity_deCreaSe, min_SampleS_leaf, min_samples_split, min_Weight_fraction_leaf	gradient_boosting	l2_regularization, learning_rate, loss, max_binS, max_depth, max_leaf_nodeS, min_samples_leaf, sCoring, tol, 	n_iter_no_change, validation_fraction	k_nearest_neighbors	p, weightslda	tol, Shrinkage_factorliblinear_svc	dual, fit_intercept, intercept_scaling, loss, multi_Class, penalty, tollibsvm_svc	gamma, kernel, max_iter, shrinking, tol, Coef0, 	degree			mlp	alpha, batch_size, beta_1, beta_2, early_stopping, epsilon, hidden_layer_depth, learning_rate_init, n_iter_no_Change, num_nodes_per_layer, shuffle, solver, tol, validation_fraction	multinomial_nb	fit_priorPaSSive_aggressive	average, fit_intercept, loss, 	tol			qda	reg_paramrandom_forest	-criterion, max_depth, max_features, max_leaf_nodes, min_impurity_deCrease, min_samples_leaf, min_samples_split, min_weight_fraction_leaf	Sgd	average, fit_intercept, learning_rate, loss, penalty, tol, epsilon, eta0, l1_ratio, .	.	power_t	.	
Table 2: List of hyper-parameters considered in AutoSkLearn pipeline.
Table 3: List of meta-featUres, 1/219Published as a conference paper at ICLR 2022Meta-features	Description	AutoSkLearn	Landmark	SCOT	Metaburoy_root	Compute the Roy's largest root.				+sd	Compute the standard deviation of each attribute.				+sd_ratio	Compute a statistical test for homogeneity of covariances.				+skewness	Compute the skewness for each attribute.				+sparsity	Compute (possibly normalized) sparsity metric for each attribute.				+t_mean	Compute the trimmed mean of each attribute.				+var	Compute the variance of each attribute.				+w_lambda	Compute the Wilks, Lambda value.				+attr_conc	Compute concentration coef. of each pair of distinct attributes.				+attr_ent	Compute Shannon,s entropy for each predictive attribute.				+class_conc	Compute concentration coefficient between each attribute and class.				+class_ent	Compute target attribute Shannon's entropy.				+eq_num_attr	Compute the number of attributes equivalent for a predictive task.				+joint_ent	Computethejoint entropy between each attribute and class.				+mut_inf	Compute the mutual information between each attribute and target.				+ns_ratio	Compute the noisiness of attributes.				+
Table 4: List of meta-features, 2/220Published as a conference paper at ICLR 2022F Computational effortFig. 7 indicates the runtime6 for pre-processing (extracting the 135 meta-features, top row), andfor training Metabu (second row). The training times for learning one model is indicated forcomparison (from row 3 to 5: Adaboost, RandomForest and SVM).
Table 5: Intrinsic dimension of the dataset space w.r.t. ML algorithms Adaboost, RandomForest,SVM and AutoSkLearn, depending on the fraction of datasets considered in OpenMLIn Table 5, we investigate how the intrinsic dimension varies when considering various numbers ofdatasets in OpenML. It is observed that the intrinsic dimension tends to increase with the number ofconsidered datasets, particularly so for SVM and to a lesser extent for RandomForest. This suggeststhat the hyper-parameter configurations investigated in the OpenML benchmark for these algorithmsdo not sufficiently sample the (good regions of the) configuration spaces.
Table 6: Comparative learning performances on OpenML datasets over sampling 30 configurations ofthe Random Forest pipeline. Performances that are statistically significant compared to the secondbest are in bold. Statistically comparable performances are indicated with (*). Pairwise comparisonand p-value along the iterations are presented in Fig. 9.
Table 7: Comparative learning performances on OpenML datasets over sampling 30 configurationsof the Adaboost pipeline. Performances that are statistically significant compared to the second bestare in bold. Statistically comparable performances are indicated with (*). Pairwise comparisons andthe associated p-value along the iterations are reported in Fig. 10.
Table 8: Comparative learning performances on OpenML datasets over sampling 30 configurationsof the SVM pipeline. Performances that are statistically significant compared to the second best arein bold. Statistically comparable performances are indicated with (*). PairWise comparisons and theassociated p-value along the iterations are presented in Fig. 11.
Table 9: Sensitivity of METABU w.r.t the number d of METABU meta-features on Task 1. Theperformance is the NDCG@k score measuring the relevance of the ranking induced by Metabuw.r.t. the target representation.
