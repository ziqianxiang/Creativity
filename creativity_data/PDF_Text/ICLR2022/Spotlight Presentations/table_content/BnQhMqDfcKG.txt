Table 1: Quantitative comparison of probabilistic scene completion in ShapeNet scene dataset withdifferent levels of completeness. The best results are marked as bold. Both CD (quality, 1) and TMD(diversity, ↑) in tables are multiplied by 104.
Table 2: Quantitative comparison of probabilistic scene completion in 3DFront. The best results aremarked as bold. Note that CD (quality, 1) and TMD (diversity, ↑) in tables are multiplied by 103.
Table 3: Quantitative comparison of single object probabilistic shape completion results on ShapeNet.
Table 4: Number of neural network parameters and GPU memory usage comparison for differentgrid size with 3DFront dataset. The grid size indicates the largest length of the scene with voxelresolution 5cm and the unit of GPU memory is GB.
Table 5: Quantitative comparison of probabilistic scene completion in ShapeNet scene dataset withdifferent levels of sparsity. The best results are marked as bold. Both CD (quality, J) and TMD(diversity, ↑) in tables are multiplied by 104.
Table 6: Quantitative results on cGCA trained on our ShapeNet dataset, but tested with non-ambiguous input. The first row (training) indicates the metrics evaluated on dataset created with sameremoval procedure as the corresponding training dataset. The second row (non-ambiguous) showsthe metrics where the input from the test dataset is sampled very densely without any removal fromthe ground truth mesh with the same trained models as the first row. Both CD (quality, J) and TMD(diversity, ↑) in tables are multiplied by 104.
