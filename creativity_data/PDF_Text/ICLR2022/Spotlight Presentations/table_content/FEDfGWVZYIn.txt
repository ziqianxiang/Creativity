Table 1: (a) Size of the target model’s training set. (b) Target model’s test accuracy (in %) with andwithout (Wo) applying our defense. The relative difference (∆) is in % and the increase is highlightedin green and decrease in Ired . See Appendix C.3 for more details.
Table 2: The highest attack accuracy (in %) among different adaptive attacks (and the correspondingnon-adaptive attack accuracy is shown for reference) evaluated on the target model with (w/) orwithout (w/o) defense. ∆ corresponds to the relative difference (in %) in attack accuracy whenapplying our defense compared to vanilla training. The used target models are the same as in Table 1.
Table 3: Summary of datasets. Ntotal denotes the total dataset size. Ntrain and Ntest are the size ofthe training and testing set, respectively.
Table 4: The top-1 training and test accuracy as well as the generalization gap (in %) of the targetmodels with or without (wo) applying our defense. ∆ corresponds to the absolute difference afterapplying our defend method (in %). We also include the selected value of α. This is supplementaryto Table 1 in the main paper.
Table 5: The attacker accuracy (in %) evaluated on the target models with and without (wo) applyingour defense. ∆ corresponds to the relative difference after applying our defend method (in %). Allthe thresholds are selected with undefended shadow models trained with shadow dataset.
Table 6: The accuracy (in %) of adaptive (a.) attacks evaluated on the target models with (w/)applying our defense. ∆ corresponds to the relative difference (in %) attack accuracy when applyingour defend method compared to vanilla training. The selected target models are the same as inTable 1.
Table 7: Top-10 Attack AUC among 100 label classes on (a) Texas and (b) Purchase with and without(wo) applying our defense. The AUC values are shown in increasing order.
