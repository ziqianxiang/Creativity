Table 1: Fool rate (%) on 5k ImageNet val. adversarial samples at ≤ 16. Perturbations generated from ourproposed self-ensemble with refined tokens from a vision transformer have significantly higher success rate.
Table 2: Fool rate (%) on 5k ImageNet val. adversarial samples at ≤ 16. Perturbations generated from ourproposed self-ensemble with refined tokens from a vision transformer have significantly higher success rate.
Table 3: Cross-Task Transferability (classifi-cation→detection) Object Detector DETR (Car-ion et al., 2020) is fooled. mAP at [0.5:0.95] IOUon COCO val. set. Our self-ensemble approachwith refined token (RE) significantly improvescross-task transferability. (lower the better)Source (→)	DeiT-T	DeiT-S	DeiT-BNo Attack I MIM MIMRE ∣ MIM MIMRE ∣ MIM MIMRE	32.5	31.6	32.5	31.0	32.6	30.642.7	DIM	DIMRE	DIM	DIMRE	DIM	DIMRE	ɪɪ"	31.4	ɪr"	31.3	ɪo-	31.0Table 4: Cross-Task Transferability (classi-fication→segmentation) DINO (Caron et al.,2021) is fooled. Jaccard index metric is usedto evaluate segmentation performance. Best ad-versarial transfer results are achieved using ourmethod. (lower the better)Clean Image Adv ImageClean Image Adv ImageClean Image Adv Image
Table 4: Cross-Task Transferability (classi-fication→segmentation) DINO (Caron et al.,2021) is fooled. Jaccard index metric is usedto evaluate segmentation performance. Best ad-versarial transfer results are achieved using ourmethod. (lower the better)Clean Image Adv ImageClean Image Adv ImageClean Image Adv ImageFigure 7: Visualization ofDETR failure cases for ourproposed DIMRE attack gener-ated from DeiT-S source model.
Table 5: Self-ensemble within Ensemble: Fool rate (%) on 5k ImageNet val. adversarial samples at ≤ 16.
Table 6: Fool rate (%) on 5k ImageNet val. adversarial samples at ≤ 16. Auto-attack and patchwiseattacks when applied to our proposed self-ensemble with refined tokens have significantly higher transfer rate tounknown convolutional and other vision transformers.
Table 7: Fool rate (%) on 5k ImageNet val. at various perturbation budgets. Auto-attack and PGD (100iterations) are evaluated at ≤ 4/8/16. Our method consistently performs better.
Table 8: Self-ensemble with refined tokens for CIFAR10: PGD fool rate (%) on CIFAR10 test set (10ksamples). In each table cell, performances are shown for two perturbation budgets i.e., ≤ 8/16.
Table 9: Self-ensemble with refined tokens for CIFAR10: MIM and DIM fool rate (%) on CIFAR10 test set(10k samples). In each table cell, performances are shown for two perturbation budgets i.e., ≤ 8/16.
Table 10: Self-ensemble with refined tokens for Flowers: PGD fool rate (%) on Flowers test set. In each tablecell, performances are shown for two perturbation budgets i.e., ≤ 8/16.
Table 11: Self-ensemble with refined tokens for Flowers: MIM and DIM fool rate (%) on Flowers test set. Ineach table cell, performances are shown for two perturbation budgets i.e., ≤ 8/16.
Table 12: Swin Transformer (patch-4, window-7): Fool rate (%) on 5k ImageNet val. at perturbation budget,≤ 16. Our method increases the black-box strength of adversarial attacks against Swin Transformer.
Table 13: Fool rate (%) on the whole ImageNet val. (50k) adversarial samples at ≤ 16. Our method remainseffective and significantly increase adversarial transferability on large dataset as well.
Table 14: We compare inferencespeed (in minutes) of attacks onthe conventional model againstthe attack on our proposed self-ensemble (with and without refine-ment module). We used 5k se-lected samples (Sec. 4) from Im-ageNet validation set for this ex-periment and all iterative attacks(PGD, MIM, DIM) ran for 10 it-erations. Inference speed is com-puted using Nvidia Quadro RTX6000 with Pytorch library.
Table 15: Fool rate (%) on 5k ImageNet val. adversarial samples at ≤ 16. Perturbations generated from ourproposed self-ensemble with refined tokens from a vision transformer have significantly higher success rate.
