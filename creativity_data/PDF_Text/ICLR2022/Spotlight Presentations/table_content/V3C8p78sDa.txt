Table F.1: Correlation of each parameter with number of shots28Published as a conference paper at ICLR 2022Parameter	Correction for US=JFT	Correlation for US= ImageNet 21kk	-0.65	-0.81α	0.60	0.75eIR	-0.88	-0.79Table F.2: The Likelihood that each of the parameters of the scaling law increases/decreases as thenumber of shots increases, average over all DS tasks.
Table F.2: The Likelihood that each of the parameters of the scaling law increases/decreases as thenumber of shots increases, average over all DS tasks.
Table F.3: Root squared error of predicted DS accuracy when fitting the points in Figure F.2 withEquation 1.
Table G.4: Summary of datasets used in our experiments, part IDataset	Description	ReferenceImageNet	1.28M labelled natural images.	(Deng et al., 2009)Caltech101	The task consists in classifying pictures of objects (101 classes plus a background clutter class), including animals, airplanes, chairs, or scis- sors. The image size varies, but it typically ranges from 200-300 pixels per edge.	http: //www.vision.caltech.edu/ Image_Datasets/Caltech101/CIFAR-10	The task consists in classifying natural images (10 classes, with 6000 training images each). Some examples include apples, bottles, di- nosaurs, and bicycles. The image size is 32x32.	https://www.cs.toronto.edu/ ~kriz/cifar.htmlCIFAR-100	The task consists in classifying natural images (100 classes, with 500 training images each). Some examples include apples, bottles, di- nosaurs, and bicycles. The image size is 32x32.	https://www.cs.toronto.edu/ ~kriz/cifar.htmlDTD	The task consists in classifying images of textural patterns (47 classes, with 120 training images each). Some of the textures are banded, bub- bly, meshed, lined, or porous. The image size ranges between 300x300 and 640x640 pixels.	(Cimpoi et al., 2014)Pets	The task consists in classifying pictures of cat and dog breeds (37 classes with around 200 images each), including Persian cat, Chihuahua dog, English Setter dog, or Bengal cat. Images dimensions are typically 200 pixels or larger.	https://www.robots.ox.ac.uk/ ~vgg/data/pets/Sun397	The Sun397 task is a scenery benchmark with 397 classes and, at least, 100 images per class. Classes have a hierarchy structure, and include cathedral, staircase, shelter, river, or archipelago. The images are (colour) 200x200 pixels or larger.	https://vision.princeton.edu/ projects/2010/SUN/Flowers102	The task consists in classifying images of flowers present in the UK (102 classes, with between 40 and 248 training images per class). Aza- lea, Californian Poppy, Sunflower, or Petunia are some examples. Each image dimension has at least 500 pixels.	https://www.robots.ox.ac.uk/ ~vgg/data/flowers/102/SVHN	This task consists in classifying images of Google’s street-view house numbers (10 classes, with more than 1000 training images each). The image size is 32x32 pixels.	http://ufldl.stanford.edu/ housenumbers/CLEVR/count	CLEVR is a visual question and answer dataset designed to evaluate algorithmic visual reasoning. We use just the images from this dataset, and create a synthetic task by setting the label equal to the number of objects in the images.	(Johnson et al., 2017)CLEVR/distance	Another synthetic task We create from CLEVR consists of predicting the depth of the closest object in the image from the camera. The depths are bucketed into size bins.	(Johnson et al., 2017)Retinopathy	The Diabetic Retinopathy dataset consists of image-label pairs with high-resolution retina images, and labels that indicate the presence of Diabetic Retinopahy (DR) in a 0-4 scale (No DR, Mild, Moderate, Se- vere, or Proliferative DR).	https://www.kaggle.com/c/ diabetic- retinopathy-detection/ databirds	image dataset with photos of 200 bird species (mostly North American).	http://www.vision.caltech. edu∕visipedia∕CUB-200.html43Published as a conference paper at ICLR 2022Table G.5: Summary of datasets used in our experiments, part IIDataset	Description	ReferencePatch Camelyon	The Patch Camelyon dataset contains 327,680 images of histopatho- logic scans of lymph node sections. The classification task consists in predicting the presence of metastatic tissue in given image (i.e., two classes). All images are 96x96 pixels.	(Teh & Taylor, 2019)
Table G.5: Summary of datasets used in our experiments, part IIDataset	Description	ReferencePatch Camelyon	The Patch Camelyon dataset contains 327,680 images of histopatho- logic scans of lymph node sections. The classification task consists in predicting the presence of metastatic tissue in given image (i.e., two classes). All images are 96x96 pixels.	(Teh & Taylor, 2019)Resisc45	The Remote Sensing Image Scene Classification (RESISC) dataset is a scene classification task from remote sensing images. There are 45 classes, containing 700 images each, including tennis court, ship, island, lake, parking lot, sparse residential, or stadium. The image size is RGB 256x256 pixels.	(Cheng et al., 2017)EuroSAT	The task consists in classifying Sentinel-2 satellite images into 10 differ- ent types of land use (Residential, Industrial, River, Highway, etc). The spatial resolution corresponds to 10 meters per pixel, and the image size is 64x64 pixels.	(Helber et al., 2019)dSprites/location	The dSprites dataset was originally designed to assess disentanglement properties of unsupervised learning algorithms. In particular, each im- age is a 2D shape where six factors are controlled: color, shape, scale, rotation, and (x,y) center coordinates. Images have 64x64 black-and- white pixels. This task consists in predicting the x (horizontal) coordi- nate of the object. The locations are bucketed into 16 bins	https://github.com/deepmind/ dsprites-dataset/dSprites/orientation	We create another task from dSprites consisting in predicting the orien- tation of each object, bucketed into 16 bins.	https://github.com/deepmind/ dsprites-dataset/https: //github.com/deepmind/ dsprites-dataset/SmallNORB/azimuth	The Small NORB dataset contains images of 3D-toys from 50 classes, including animals, human figures, airplanes, trucks, and cars. The im- age size is 640x480 pixels. In this case, we define labels depending on the azimuth (angle of horizontal deviation), in intervals of 20 degrees (18 classes).	(LeCun et al., 2004)SmallNORB/elevation	Another synthetic task We create from Small NORB consists in predict- ing the elevation in the image. There are 9 classes, corresponding to 9 different elevations ranging from 30 to 70 degrees, in intervals of 5 degrees	(LeCun et al., 2004)DMLab	The DMLab (DeepMind Lab) is a set of control environments focused on 3D navigation and puzzle-solving tasks. The Dmlab dataset contains frames observed by the agent acting in the DeepMind Lab environment, Which are annotated by the distance betWeen the agent and various ob- jects present in the environment. The goal is to evaluate the ability of a visual model to reason about distances from the visual input in 3D environments. The Dmlab dataset consists of 360x480 color images in 6 classes. The classes are close, far, very far × positive reWard, negative reWard respectively.	(Beattie et al., 2016)KITTI	The KITTI task consists in predicting the (binned) depth to the vehicle (car, van, or truck) in the image. There are 4 bins / classes.	(Geiger et al., 2013)ColHist	Classification of textures in colorectal cancer histology. Each example is a 150 x 150 x 3 RGB image of one of 8 classes.	https://www.tensorflow.org/ datasets/catalog/colorectal_ histologyUC Merced	21 class land use image dataset	https://usdahsi.ucmerced. edudatasets/landuse.htmlcars	The Cars dataset contains 16,185 images of 196 classes of cars. The data is split into 8,144 training images and 8,041 testing images, Where each class has been split roughly in a 50-50 split. Classes are typically at the level of Make, Model, Year, e.g. 2012 Tesla Model S or 2012 BMW M3 coupe.	http: //ai.stanford.edu/~jkrause/ cars/car_dataset.html44Published as a conference paper at ICLR 2022H Transfer to VTABIn this Section, we provide additional experiments for the transfer learning scenario and use VTABas downstream task. Figure H.32 shows the effect of controlled experiments, scaling up model size,data size and compute for transfer learning setting on VTAB dataset. Note that these experiments are
Table H.6: Results of a ViT-B/32 on fine-tuning (transfer) setup on VITAB-1K benchmark, whenpre-trinained with different head weight decays. Note that the selected head WD for these experimentsare set to 0 and 5.0, which are rather extreme values, to highlight the effect on different datasets.
