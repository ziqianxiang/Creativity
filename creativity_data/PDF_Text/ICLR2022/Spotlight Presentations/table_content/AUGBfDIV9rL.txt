Table 1: Evaluation of Speakers on multiple settings on CelebA in %. ± denotes one standard errorof the mean. We report final accuracy for all ETL tasks but Recons. where we report the final loss.
Table 2: Different language properties on CelebA and ImageNet datasets, in %. For each setting wereport the mean over 10 seeds. ± denotes 1 standard error of the mean.
Table 3: Hyper-parameters values across datasets and settings.
Table 4: Imitation hyper-parameters values chosen according to the best accuracy at validation.
Table 5: Computational requirements for our base setup. “GPU memory” refers to the peak GPUmemory usage.
Table 6: Different language properties on CelebA dataset, in %. For each setting we report the meanover 10 seeds. ± denotes 1 standard error of the mean.
Table 7: CelebA ETL attribute accuracies when varying the number of candidates at pretraining at10k training steps.
Table 8: Generalization performance on the official CelebA split, in %. In this case, we look atout-of-distribution generalization as train and test sets contain different identities. For each settingwe report the mean over 10 seeds. ± denotes 1 standard error of the mean.
