Table 1: Comparison of SOSP to other global pruning methods for high pruning ratios. The compari-son for moderate pruning ratios is deferred to the appendix (see App. A.3). We tuned our pruningratios to similar values as reported by the referred methods. To ensure identical implementations ofthe network models in PyTorch, reference numbers are taken from Wang et al. (2019a) and Mingjie &Zhuang (2018). In accordance with all referred methods, we report the mean and standard deviationof the best accuracies observed during fine-tuning. For final accuracies after fine-tuning see App.
Table 2: On ResNet-18/50 for ImageNet SOSP outperforms allcompeting methods. We compare the best final test accuraciesand pruning ratios (PR) across 2 trials. A visualisation of theresults can be found in App. A.7. For comparison to CCP, wealso provide their alternative MAC count (for details, see App.
Table 3: Comparison of SOSP to first-order global pruning for ResNet-56 on Cifar10 and Cifar100.
Table 4: Comparison of SOSP to other global pruning methods for moderate pruning rates. Thesetting is exactly the same as in Tab. 1. For final accuracies after fine-tuning see App. A.13. * denotesthe baseline model.
Table 5: We compare the results of SOSP and AMC for PlainNet-20 on Cifar10. We show the meanand standard deviation of the accuracy over three independent runs.
Table 6: We compare the results of SOSP with other state-of-the-art methods on MobileNetV2 forImageNet. “Gap” indicates the percentage gap to the respective baseline model and PR stands forpruning ratio.
Table 7: Comparison of time needed to calculate the importance vector for SOSP-I and SOSP-H forseveral networks on Cifar10 and ImageNet.
Table 8: We compare the results of SOSP with Shuffle SOSP, where the pruning masks of thestructures within each layer, and therefore also the weights, are shuffled before the fine-tuning step.
Table 9: Mean and standard deviation of the final accuracies after the full fine-tuning step of bothSOSP methods on Cifar10 and Cifar100 for VGG-Net, ResNet-32 and DenseNet-40.
Table 10: Pruning results of ResNet-56 and DenseNet-40 on Cifar10. Gap denotes the differencebetween the accuracy of the pruned model and the baseline accuracy. PR denotes the pruning ratio,i.e. the percentage drop in MACs or parameters.
Table 11: Mean and standard deviations of the accuracies after fine-tuning of SOSP for ResNet-56and DenseNet-40.
