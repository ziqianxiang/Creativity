Table 1: Conceptual comparison of our method to the related literature. If all-reduce is supported,the method does not need any decompression. If all-reduce is not supported, the expensive all-gatheroperation is required and decompression is slow. See also Section 5 for numerical comparisons.
Table 2: Test accuracy and time breakdown in one iteration (on average) of training ResNet18 on the CIFAR-10 dataset with 16 workers. All numbers of time are in millisecond (ms). In each column,				the best one is highlighted in black and the second-best one is highlighted in gray.				Algorithm	Test Accuracy (%)	Computation Overhead	Communication	Total TimeSGD (All-gather)	94.65 ± 0.08	-	261.29 ± 0.98	338.76 ± 0.76QSGD	93.69 ± 0.03	129.25 ± 1.58	138.16 ± 1.29	320.49 ± 2.11NatSGD	94.57 ± 0.13	36.01± 1.30	106.27 ± 1.43	197.18 ± 0.25SGD (All-reduce)	94.67 ± 0.17	-	18.48 ± 0.09	74.32 ± 0.06PowerSGD (EF)	94.33 ± 0.15	7.07 ± 0.03	5.03 ± 0.07	67.08 ± 0.06IntSGD (Determ.)	94.43 ± 0.12	2.51 ± 0.04	6.92± 0.07	64.95 ± 0.15IntSGD (Random)	94.55 ± 0.13	3.20 ± 0.02	6.21 ± 0.13	65.22 ± 0.08(Determ.) fails to match the testing performance of SGD on the language modeling task. Comparedto PowerSGD (EF), our IntSGD variants are better on the task of training ResNet18 but inferior onthe task of training a 3-layer LSTM. Although IntSGD is not always better than PowerSGD (EF),there are several scenarios where IntSGD is preferrable as explained in in Section 1 and Section 3.4.
Table 3: Test loss and time breakdown in one iteration (on average) of training a 3-layer LSTMon the Wiki-text2 dataset with 16 workers. All numbers of time are in millisecond (ms). In eachcolumn, the best one is highlighted in black and the second-best one is highlighted in gray.
Table 4: Information of the experiments on '2-regularized logistic regression.
