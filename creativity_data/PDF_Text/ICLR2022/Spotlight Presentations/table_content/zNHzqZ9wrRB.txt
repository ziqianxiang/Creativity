Table 1: Results on all QM9 targets and comparison to previous work. Scores are reported as meanabsolute errors (MAE). LieTF refers to the best performing variant of LieTransformers (Hutchinsonet al., 2020), i.e. LieTransformer-T3+SO3 Aug.
Table 2: Results on MD trajectories from the MD17 dataset. Scores are given by the MAE ofenergy predictions (kcal/mol) and forces (kcal/mol/A). NeqUIP does not provide errors on energy,for PaiNN we include the results with lower force error out of training only on forces versus onforces and energy. Benzene corresponds to the dataset originally released in Chmiela et al. (2017),which is sometimes left oUt from the literatUre. ET resUlts are averaged over three random splits.
Table 3: Comparison of computational efficiency between PaiNN, DimeNet++ and different sizesof TorchMD-NET ET. The time is measured at inference using random batches of 50 moleculesfrom QM9. Speed of ET models of TorchMD-NET is reported as mean ± standard deviation over1000 calls. Values for PaiNN and DimeNet++ are taken from Schutt et al. (2021) so differences inefficiency may to some degree originate from different implementations.
Table 4: Comparison of various hyperparameters used for QM9, MD17 and ANI-1.
Table 5: Test MAE of the TorchMD-NET ET on QM9 and MD17 (aspirin), trained with and withouthydrogen.
Table 6: Hyperparameter set of the full ET model compared to PaiNN- and NequIP-sized variants.
Table 7: Energy (kcal/mol) and force (kcal/mol/A) MAE of the PaiNN- and NeqUIP-Sized ET mod-els. The ”full ET” column is equal to the results in Table 2 and is meant for comparison with thesmaller ET variants. ValUes in bold indicate the best resUlt oUt of the two models in direct compari-son.
Table 8: ET results on CCSD/CCSD(T) trajectories from Chmiela et al. (2018). Scores are given bythe MAE of energy predictions (kcal/mol) and forces (kcal/mol/A). Results are averaged over tworandom splits.
