Published as a conference paper at ICLR 2022
Sampling with Mirrored Stein Operators
Jiaxin Shi1 Chang Liu2 Lester Mackey1
1	Microsoft Research New England
2	Microsoft Research Asia
{jiaxinshi,chang.liu,lmackey}@microsoft.com
Ab stract
We introduce a new family of particle evolution samplers suitable for constrained
domains and non-Euclidean geometries. Stein Variational Mirror Descent and
Mirrored Stein Variational Gradient Descent minimize the Kullback-Leibler (KL)
divergence to constrained target distributions by evolving particles in a dual space
defined by a mirror map. Stein Variational Natural Gradient exploits non-Euclidean
geometry to more efficiently minimize the KL divergence to unconstrained targets.
We derive these samplers from a new class of mirrored Stein operators and adaptive
kernels developed in this work. We demonstrate that these new samplers yield
accurate approximations to distributions on the simplex, deliver valid confidence in-
tervals in post-selection inference, and converge more rapidly than prior methods in
large-scale unconstrained posterior inference. Finally, we establish the convergence
of our new procedures under verifiable conditions on the target distribution.
1	Introduction
Accurately approximating an unnormalized distribution with a discrete sample is a fundamental
challenge in machine learning, probabilistic inference, and Bayesian inference. Particle evolution
methods like Stein variational gradient descent (SVGD, Liu & Wang, 2016) tackle this challenge
by applying deterministic updates to particles using operators based on Stein’s method (Stein, 1972;
Gorham & Mackey, 2015; Oates et al., 2017; Liu et al., 2016; Chwialkowski et al., 2016; Gorham &
Mackey, 2017) and reproducing kernels (Berlinet & Thomas-Agnan, 2011) to sequentially minimize
Kullback-Leibler (KL) divergence. SVGD has found great success in approximating unconstrained
distributions for probabilistic learning (Feng et al., 2017; Haarnoja et al., 2017; Kim et al., 2018) but
breaks down for constrained targets, like distributions on the simplex (Patterson & Teh, 2013) or the
targets of post-selection inference (Taylor & Tibshirani, 2015; Lee et al., 2016; Tian et al., 2016), and
fails to exploit informative non-Euclidean geometry (Amari, 1998).
In this work, we derive a family of particle evolution samplers suitable for target distributions with
constrained domains and non-Euclidean geometries. Our development draws inspiration from mirror
descent (MD) (Nemirovskij & Yudin, 1983), a first-order optimization method that generalizes
gradient descent with non-Euclidean geometry. To sample from a distribution with constrained
support, our method first maps particles to a dual space. There, we update particle locations using
a new class of mirrored Stein operators and adaptive reproducing kernels introduced in this work.
Finally, the dual particles are mapped back to sample points in the original space, ensuring that all
constraints are satisfied. We illustrate this procedure in Fig. 1. In Sec. 3, We develop two algorithms -
Mirrored SVGD (MSVGD) and Stein Variational Mirror Descent (SVMD) - with different updates
in the dual space; when only a single particle is used, MSVGD reduces to gradient ascent on the
log dual space density, and SVMD reduces to mirror ascent on the log target density. In addition,
by exploiting the connection between MD and natural gradient descent (Amari, 1998; Raskutti &
Mukherjee, 2015), we develop a third algorithm - Stein Variational Natural Gradient (SVNG) - that
extends SVMD to unconstrained targets with non-Euclidean geometry.
In Sec. 5, we demonstrate the advantages of our algorithms on benchmark simplex-constrained
problems from the literature, constrained sampling problems in post-selection inference (Taylor &
Tibshirani, 2015; Lee et al., 2016; Tian et al., 2016), and unconstrained large-scale posterior inference
with the Fisher information metric. Finally, we analyze the convergence of our mirrored algorithms
in Sec. 6 and discuss our results in Sec. 7.
1
Published as a conference paper at ICLR 2022
[Mp,ψK(θt, θ)]
Figure 1: Updating particle approximations in constrained domains Θ. Standard updates like SVGD
(dashed arrow) can push particles outside of the support. Our mirrored Stein updates in Alg. 1 (solid
arrows) preserve the support by updating particles in a dual space and mapping back to Θ.
Related work Our mirrored Stein operators (6) are instances of diffusion Stein operators in the
sense of Gorham & Mackey (2017), but their specific properties have not been studied, nor have
they been used to develop sampling algorithms. There is now a large body of work on transferring
algorithmic ideas from optimization to MCMC (e.g., Welling & Teh, 2011; Simsekli et al., 2016;
Dalalyan, 2017; Durmus et al., 2018; Ma et al., 2019) and SVGD-like sampling methods (e.g., Liu
et al., 2019a;b; Zhu et al., 2020; Zhang et al., 2020a). The closest to our work in this space is the
recent marriage of mirror descent and MCMC. For example, Hsieh et al. (2018) propose to run
Langevin Monte Carlo (LMC, an Euler discretization of the Langevin diffusion) in a mirror space.
Zhang et al. (2020b) analyze the convergence properties of the mirror-Langevin diffusion, Chewi et al.
(2020) demonstrate its advantages over the Langevin diffusion when using a Newton-type metric, and
Ahn & Chewi (2020) study its discretization for MCMC sampling in constrained domains. Relatedly,
Patterson & Teh (2013) proposed stochastic Riemannian LMC for sampling on the simplex.
Several modifications of SVGD have been proposed to incorporate geometric information. Rieman-
nian SVGD (RSVGD, Liu & Zhu, 2018) generalizes SVGD to Riemannian manifolds, but, even with
the same metric tensor, their updates are more complex than ours: notably they require higher-order
kernel derivatives, do not operate in a mirror space, and do not reduce to natural gradient descent
when a single particle is used. They also reportedly do not perform well when with scalable stochastic
estimates of V logp. Stein Variational NeWton (SVN, Detommaso et al., 2018; Chen et al., 2019)
introduces second-order information into SVGD. Their algorithm requires an often expensive Hessian
computation and need not lead to descent directions, so inexact approximations are employed in
practice. Our SVNG can be seen as an instance of matrix SVGD (MatSVGD, Wang et al., 2019) With
an adaptive time-dependent kernel discussed in Sec. 4.4, a choice that is not explored in Wang et al.
(2019) and Which recovers natural gradient descent When n = 1 unlike the heuristic kernel construc-
tions of Wang et al. (2019). None of the aforementioned Works provide convergence guarantees, and
neither SVN nor matrix SVGD deals With constrained domains.
2	Background: Mirror Descent and Non-Euclidean Geometry
Standard gradient descent can be vieWed as optimizing a local quadratic approximation to the target
function f: θt+ι = argmi0θ∈θ Vf (θt)>θ + 蚩 ∣∣θ 一 θt∣∣2∙ When Θ ⊆ Rd is constrained, it can be
advantageous to replace ∣∙∣2 With a function Ψ that reflects the geometry of a problem (Nemirovskij
& Yudin, 1983; Beck & Teboulle, 2003):
Θt+1 = argminθ∈θ Vf (θt)>θ + 六Ψ(θ,θt).	(1)
We consider the mirror descent algorithm (Nemirovskij & Yudin, 1983; Beck & Teboulle, 2003)
Which chooses Ψ to be the Bregman divergence induced by a strongly convex, essentially smooth1
function ψ : Θ → R∪ {∞}: Ψ(θ, θ0) = ψ(θ) 一 ψ(θ0) 一 Vψ(θ0)> (θ 一 θ0). When Θ isa (d+ 1)-
simplex {θ : Pid=1 θi ≤ 1 and θi ≥ 0 for i ∈ [d]}, a common choice of ψ is the negative entropy
ψ(θ) = Pid=+11 θi log θi, for θd+1 , 1 一 Pid=1 θd. The solution of (1) is given by
Θt+1 = Vψ*(Vψ(θt)-QVf(θt)),	(2)
where ψ*(η)，suPθ∈θ η>θ 一 ψ(θ) is the convex conjugate of ψ and Vψ is a bijection from Θ to
dοm(ψ*) with inverse map (Vψ)-1 = Vψ*. We can view the update in (2) as first mapping θt to η
by Vψ, applying the update ηt+ι = ηt 一 etVf (θt), and mapping back through θt+ι = Vψ*(ηt+ι).
1ψ is continuously differentiable on the interior of Θ with ∣∣Vψ(θt)k → ∞ whenever θt → θ ∈ ∂Θ.
2
Published as a conference paper at ICLR 2022
Mirror descent can also be viewed as a discretization of the continuous-time dynamics dηt =
-Vf (θt)dt, θt = Vψ*(ηt), which is equivalent to the Riemannian gradient flow (See App. A):
dθt = -V2ψ(θt)-1Vf(θt)dt, orequivalently, dη = 7k(巾)-"小于(Vψ*(ηt))dt, (3)
where V2ψ(θ) and V2ψ*(η) are Riemannian metric tensors. In information geometry, the discretiza-
tion of (3) is known as natural gradient descent (Amari, 1998). There is considerable theoretical and
practical evidence (Martens, 2014) showing that natural gradient works efficiently in learning.
3	Stein’s Identity and Mirrored Stein Operators
Stein’s identity (Stein, 1972) is a tool for characterizing a target distribution P using a so-called Stein
operator. We assume P has a differentiable density p with a closed convex support Θ ⊆ Rd. A Stein
operator Sp takes as input functions g from a Stein set G and outputs mean-zero functions under p:
Eθ~p[(Spg)(θ)] = O,	for all g ∈G ∙	(4)
Gorham & Mackey (2015) proposed the Langevin Stein operator given by
(Spg)(θ) = g(θ)>Vlogp(θ) + V ∙ g(θ),	(5)
where g is a vector-valued function and V ∙ g is its divergence. For an unconstrained domain with
Ep[kV log p(θ)k2] < ∞, Stein’s identity (4) holds for this operator whenever g ∈ C1 is bounded and
Lipschitz by (Gorham et al., 2019, proof of Prop. 3). However, on constrained domains Θ, Stein’s
identity fails to hold for many reasonable inputs g if p is non-vanishing or explosive at the boundary.
Motivated by this deficiency and by a desire to exploit non-Euclidean geometry, we propose an
alternative mirrored Stein operator,
(Mp,ψg)(θ) = g(θ)>V2ψ(θ)-1Vlogp(θ) + V∙ (V2ψ(θ)-1g(θ)),	(6)
where ψ is a strongly convex, essentially smooth function as in Sec. 2 with (V2ψ)-1 differentiable
and Lipschitz on Θ. We derive this operator from the (infinitesimal) generator of the mirror-Langevin
diffusion (19) in App. C. The following result, proved in App. I.1, shows that Mp,ψ generates
mean-zero functions under p whenever V2ψ-1 suitably cancels the growth ofp at the boundary.
Proposition 1. Suppose that V2ψ(θ)-1Vlogp(θ) and V ∙ V2ψ(θ)-1 are p-integrable. If
limr→∞ R∂Θ p(θ)kV2ψ(θ)-1nr(θ)k2dθ = 0 for Θr , {θ ∈ Θ : kθk∞ ≤ r} and nr (θ) the
outward unit normal vector2 to ∂Θr at θ, then Ep [(Mp,ψg)(θ)] = 0 if g ∈ C1 is bounded Lipschitz.
Example 1 (Dirichlet p, Negative entropy ψ). When θ±d+ι 〜Dir(α) for α ∈ R+++1, even
setting g(θ) = 1 in (5) need not cause the identity to hold when some αj ≤ 1. However, when
ψ(θ) = Pjd=+11 θj log θj, we show in App. B that the conditions of Prop. 1 are met for any α.
Remarkably, the mirror-Langevin diffusion for our choice of ψ is the Wright-Fisher diffusion (Ethier,
1976) which Gan et al. (2017) recently used to bound distances to Dirichlet distributions.
4	Sampling with Mirrored S tein Operators
Liu & Wang (2016) pioneered the idea of using Stein operators to approximate a target distribution
with particles. Their popular SVGD algorithm updates each particle in its approximation by applying
the update rule	θt+1	=	θt	+	tgt(θt)	for a chosen mapping gt	:	Rd	→	Rd.	Specifically, SVGD
chooses the mapping g； that leads to the largest decrease in KL divergence to P in the limit as Et → 0.
The following theorem summarizes their main findings.
Theorem 2 (Liu & Wang, 2016, Thm. 3.1). Suppose (θt)t≥0 satisfies dθt = gt(θt)dt for bounded
Lipschitz gt ∈ C1 : Rd → Rd and that θt has density qt with Eqt [kV log qtk2] < ∞. If KL(qtkp) ,
Eqt [log(qt/p)] exists then, for the Langevin Stein operator Sp (5),
dtKL (qtkp) = -Eθt~qt[(Spgt)(θt)]∙	⑺
2For a closed convex set whose boundary ∂Θ can be locally represented as F(θ1, . . . , θd) = 0, its unit
normal vector is defined as n(θ) = ± IJF(θ1,…,θd) .
' )	∣∣VF (θι,...,θd)k2
3
Published as a conference paper at ICLR 2022
Algorithm 1 Mirrored Stein Variational Gradient Descent & Stein Variational Mirror Descent
Input: density p on Θ, kernel k, mirror function ψ, particles (θ0i )in=1 ⊂ Θ, step sizes (t)tT=1
Init: η0 - Vψ(θ0) for i ∈ [n]
for t = 0 : T do
if SVMD then Kt — Kψ,t (13) else Kt — kI (MSVGD)
for i ∈ [n],ηi+ι - ηi + Qn Pn=I Mp,ψKt网,θj)	(for Mp,ψKt(∙,θ) defined in Thm. 3)
for i ∈ [n],θi+ι - Vψ*(ηi+ι)
return {θTi +1}in=1.
To improve its current particle approximation, SVGD finds the choice of gt that most quickly
decreases KL(qtkp) at time t, i.e., it minimizes +KL(qtkp) over a set of candidate directions gt.
SVGD finds gt in a reproducing kernel Hilbert space (RKHS, Berlinet & Thomas-Agnan, 2011) norm
ball BHd = {g : kgkHd ≤ 1}, where Hd is the product RKHS containing vector-valued functions
with each component in the RKHS H of k. Then the optimal gt ∈ BHd that minimizes (7) is
gt H g*t,k , Eθt^qt [k(θt, ∙)v log P(θt) + vθt k(θt, ∙)] = % 〜qt[SpKk (∙,θt)],
where we let Kk(θ, θ0) = k(θ, θ0)I, and SpKk(∙, θ) denotes applying Sp to each row of Kk(∙, θ).
SVGD has found great success in approximating unconstrained target distributions p but breaks
down for constrained targets and fails to exploit non-Euclidean geometry. Our goal is to develop new
particle evolution samplers suitable for constrained domains and non-Euclidean geometries.
4.1	Mirrored dynamics
SVGD encounters two difficulties when faced with a constrained support. First, the SVGD updates can
push the random variable θt outside of its support Θ, rendering all future updates undefined. Second,
Stein’s identity (4) often fails to hold for candidate directions in BHd (cf. Ex. 1). When this occurs,
SVGD need not converge to P as P is not a stationary point of its dynamics (i.e., S KL(qtkp)∣qt=p = 0
when qt = p). Inspired by mirror descent (Nemirovskij & Yudin, 1983), we consider the following
mirrored dynamics
θt = Vψ*(ηt) for dηt = gt(θt)dt, or, equivalently, dθt = V2ψ(θt)-1gt(θt)dt, (8)
where gt : Θ → Rd now represents the update direction in η space. The inverse mirror map Vψ*
automatically guarantees that θt belongs to the constrained domain Θ. Since ψ is strongly convex
and V2ψ-1 is bounded Lipschitz, from Thm. 2 it follows for any bounded Lipschitz gt that
今 KL(qt kp) = -Eθt 〜qt[(Mp,ψ gt)(θt)],
(9)
where Mp,ψ is the mirrored Stein operator (6). In the following sections, we propose three new
deterministic sampling algorithms by seeking the optimal direction gt that minimizes (9) over different
function classes. Thm. 3 (proved in App. I.2) forms the basis of our analysis.
Theorem 3 (Optimal mirror updates in RKHS). Suppose (θt)t≥0 follows the mirrored dynamics (8).
Let HK denote the RKHS of a matrix-valued kernel K : Θ × Θ → Sd×d (Micchelli & Pontil, 2005).
Then, the optimal direction of gt that minimizes (9) in the norm ball BHK , {g : kgkH ≤ 1} is
gt H gqt,K , EθtCgt[Mp,ψ K(∙,θt)],
(10)
where Mp,ψ K (∙, θ) applies Mp,ψ (6) to each row of the matriX-Valuedfunction K = K (∙,θ).
4.2	Mirrored Stein Variational Gradient Descent
Following the pattern of SVGD, one can choose the K of Thm. 3 to be Kk (θ, θ 0) = k(θ, θ 0)I, where
k is any scalar-valued kernel. In this case, the resulting update g*t KkS= Eθtcqt [Mp,ψKk (∙, θt)]
is equivalent to running SVGD in the dual η space before mapping back to Θ.
Theorem 4 (Mirrored SVGD updates). In the setting of Thm. 3, let kψ (η, η 0)	=
k(Vψ*(η), Vψ*(η°)), ph(η) = p(Vψ*(η)) ∙ | det V2ψ* (η)∣ denote the density of η = Vψ(θ)
when θ 〜p, and qt,H denote the distribution of η under the mirrored dynamics (8). If Kk = kI,
gqt,Kk(θ0) = Ent〜qt,H[kψ(nt,nO)VlogPH(ηt) + Vntkψ(ηt,η0)] ∀θ0 ∈ θ,η0 = ^ψ⑺.(II)
4
Published as a conference paper at ICLR 2022
The proof is in App. I.3. By discretizing the dynamics dηt = g羡,κfc (θt)dt and initializing with any
particle approximation qo = 1 Pn=I δθi, We obtain Mirrored SVGD (MSVGD), our first algorithm
for sampling in constrained domains. The details are summarized in Alg. 1.
When only a single particle is used (n = 1) and the differentiable input kernel satisfies Vk(θ, θ) = 0,
the MSVGD update (11) reduces to gradient descent on - logpH(η). Note however that the modes
of the mirrored density pH (η) need not match those of the target density p(θ) (see the examples in
App. E). Since we are primarily interested in the θ-space density, it is natural to ask whether there
exists a mirrored dynamics that reduces to finding the mode of p(θ) in this limiting case. In the next
section, we give an answer to this question by designing an adaptive reproducing kernel that yields a
mirror descent-like update.
4.3	Stein Variational Mirror Descent
Our second sampling algorithm for constrained problems is called Stein Variational Mirror De-
scent (SVMD). We start by introducing a new matrix-valued kernel that incorporates the metric V2ψ
and evolves with the distribution qt .
Definition 1 (Kernels for SVMD). Given a continuous scalar-valued kernel k, consider the Mercer
representation3 k(θ, θ0) =	i≥1 λt,iut,i(θ)ut,i(θ0) w.r.t. qt, where ut,i is an eigenfunction satisfying
Eθt 〜qt[k(θ,θt)ut,i(θt)] = λt,iUt,i(θ).	(12)
For k1∕2(θ, θ0)，Pi≥ι λ1^ut,i(θ)ut,i(θr), we define the adaptive SVMD kernel at time t,
Kψ,t(θ,θ0) , Eθt〜qt[k"(θ,θt)V2ψ(θt)kY2(θt,θ0)].	(13)
By Thm. 3, the optimal update direction for the SVMD kernel ball is g^t KW t=Eqt [Mp,ψKψ,t(∙,θt)].
We obtain the SVMD algorithm (summarized in Alg. 1) by discretizing dηt = g短,K, t(θt)dt and
initializing with qo = n Pn=ι δθi. Because of the discrete representation of qt, Kψ,t takes the form
Kψ,t(θ, θ0) = pn=1 pn=1 H/ut,i (θ)ut,j (θ0)Γt,ij ,
Γt,ij = 1 Pn=I ut,i(θ')ut,j (θ')V2ψ(θ').
Here both λt,j and ut,j(θti) can be computed by solving a matrix eigenvalue problem involving the
particle set {θti}in=1: Btvt,j = nλt,j vt,j, where Bt = (k(θti, θtj))in,j=1 ∈ Rn×n is the Gram matrix of
pairwise kernel evaluations at particle locations, and the i-th element of vt,j is ut,j(θti). To compute
VθKψ,t(θ, θ0), we differentiate both sides of(12) to find that Vutj(θ) = y1- Pn=I Vtj,iVθk(θ, θj).
This technique was used in Shi et al. (2018) to estimate gradients of eigenfunctions w.r.t. a continuous
q. Following their recommendations, we truncate the sum at the J-th largest eigenvalues according to
a threshold (τ ≥ PjJ=1 λt,j / Pjn=1 λt,j) to ensure numerical stability.
Notably, SVMD differs from MSVGD only in its choice of kernel, but, whenever Vk(θ, θ) = 0, this
change is sufficient to exactly recover mirror descent when n = 1.
Proposition 5 (Single-particle SVMD is mirror descent). If n = 1, then one step of SVMD becomes
ηt+ι = ηt + et(k(θt,θt)V log p(θt) + Vk(θt, θt)),	θt+1 = Vψ*(ηt+ι).
4.4	Stein Variational Natural Gradient
The fact that SVMD recovers mirror descent as a special case is not only of relevance in constrained
problems. We next exploit the connection between MD and natural gradient descent discussed in
Sec. 2 to design a new sampler - Stein Variational Natural Gradient (SVNG) 一 that more efficiently
approximates unconstrained targets. The idea is to replace the Hessian V2ψ(∙) in the SVMD dynamics
dθt = V2ψ(θt)-1g黑K砂 t(θt) with a general metric tensor G(∙). The result is the Riemannian
gradient flow
dθt = G(θt)Tgqt,κG,t (θt)dt with KG,t(θ, θ0)，Ed,〜qt[k1∕2(θ,θt)G(θt)k1∕2(θt,θ0)]. (14)
3See App. F for background on Mercer representations in non-compact domains.
5
Published as a conference paper at ICLR 2022
Sparse DiriChlet
Projected SVGD
SVMD
MSVGD, k
MSVGD, k2
400
Number of particle updates, T
Figure 2: Quality of 50-particle approximations to 20-dimensional distributions on the simplex after
T particle updates. (Left) Sparse Dirichlet posterior of Patterson & Teh (2013). (Right) Quadratic
simplex target of Ahn & Chewi (2020). Details of the target distributions are in App. G.1.
Given any initial particle approximation qo = n P2ι δθi, We discretize these dynamics to
obtain the unconstrained SVNG sampler of Alg. 2 in the appendix. SVNG can be seen
as an instance of MatSVGD (Wang et al., 2019) With a neW adaptive time-dependent kernel
G-1(θ)KG,t (θ, θ0)G-1(θ0). HoWever, similar to Prop. 5 and unlike the heuristic kernels of Wang
et al. (2019), SVNG reduces to natural gradient ascent for finding the mode of p(θ) When n = 1.
SVNG is Well-suited to Bayesian inference problems Where the target is a posterior distribution
p(θ) H π(θ)π(y ∣θ). There, the metric tensor G(θ) can be set to the Fisher information matrix
E∏(y∣θ)[Vlog∏(y∣θ)Vlog∏(y∣θ)>] of the data likelihood ∏(y∣θ). Ample precedent from natu-
ral gradient variational inference (Hoffman et al., 2013; Khan & Nielsen, 2018) and Riemannian
MCMC (Patterson & Teh, 2013) suggests that encoding problem geometry in this manner often leads
to more rapid convergence.
5	Experiments
We next conduct a series of simulated and real-data experiments to assess (1) distributional approxi-
mation on the simplex, (2) frequentist confidence interval construction for (constrained) post-selection
inference, and (3) large-scale posterior inference With non-Euclidean geometry. To compare With
standard SVGD on constrained domains and to prevent its particles from exiting the domain Θ, We
introduce a Euclidean projection onto Θ folloWing each SVGD update. For SVMD, We need to solve
an eigenvalue problem, Which costs O(n3) time. In practice the number of particles used for particle
evolution algorithms is relatively small, even for SVGD, due to the O(n2) cost of updates. We have
produced a practical SVMD implementation that is computationally competitive With MSVGD and
SVGD for standard particle counts like n = 50 (used in all experiments).
5.1	Approximation quality on the simplex
We first measure distributional approximation quality using tWo 20-dimensional simplex-constrained
targets: the sparse Dirchlet posterior of Patterson & Teh (2013) extended to 20 dimensions and the
quadratic simplex target of Ahn & CheWi (2020). The Dirichlet target mimics the multimodal sparse
conditionals that arise in latent Dirichlet allocation (Blei et al., 2003) but induces a log concave
density in η space, While the quadratic is log-concave in θ space. In Fig. 2, We compare the quality of
MSVGD, SVMD, and projected SVGD With 50 particles and inverse multiquadric kernel k (Gorham &
Mackey, 2017) by computing the energy distance (Szekely & Rizzo, 2013) to a surrogate ground truth
sample of size 1000 (draWn i.i.d. or, in the quadratic case, from the No-U-Turn Sampler (Hoffman &
Gelman, 2014)). We also compare to MSVGD With k2 (θ, θ0) = k(Vψ(θ), Vψ(θ0)), a choice Which
corresponds to running SVGD in the dual space With kernel k by Thm. 4 and Which ensures the
convergence of MSVGD to p by the upcoming Thms. 6 to 8.
In the quadratic case, SVMD is favored over MSVGD as it is able to exploit the log-concavity of p(θ).
In contrast, for the multimodal sparse Dirichlet With p(θ) unbounded near the boundary, MSVGD
converges slightly more rapidly than SVMD by exploiting the log concave structure in η space. This
parallels the observation of Hsieh et al. (2018) that LMC in the mirror space outperforms Riemannian
LMC for sparse Dirichlet distributions. Projected SVGD fails to converge to the target in both cases
and has particular difficulty in approximating the sparse Dirichlet target With unbounded density.
6
Published as a conference paper at ICLR 2022
0.86
0.94
0.92
. .
O O
0,I0ACO PenePa
1000	1500	2000	2500	3000
Number of sample points, N
(a) Nominal coverage: 0.9
0MBHA。。
1.00
0.90
/ 0.85
0.80
0.95
0.80	0.85	0.90	0.95	1.00
Nominal coverage
(b) N = 5000 sample points
Figure 3: Coverage of post-selection CIs across (a) 500 / (b) 200 replications of simulation of Sepehri
& Markovic (2017).
MSVGD with k and k2 perform very similarly, but we observe that k yields better approximation
quality upon convergence. Therefore, we employ k in the remaining MSVGD experiments.
5.2	Confidence intervals for post-selection inference
We next apply our algorithms to the constrained sampling problems that arise in post-selection
inference (Taylor & Tibshirani, 2015; Lee et al., 2016). Specifically, we consider the task of forming
valid confidence intervals (CIs) for regression parameters selected using the randomized Lasso (Tian
et al., 2016) with data X ∈ Rn×p and y ∈ Rn and user-generated randomness W ∈ Rp from a
ʌ
log-concave distribution with density g. The randomized Lasso returns β ∈ Rp with non-zero
ʌ
coefficients denoted by βE and their signs by sE. It is common practice to report least squares CIs
for βE by running a linear regression on the selected features E. However, since E is chosen based
on the same data, the resulting CIs are often invalid.
Post-selection inference solves this problem by conditioning the inference on the knowledge of E
and sE . To construct valid CIs, it suffices to approximate the selective distribution with support
{3e, U-E : SE Θ Be > 0, U-E ∈ [-1,1]p-lEl} and density
g(βE ,u-E) H g(χ >y -(XEXXEXIIEI )βE+λ( UsEE)).
In our experiments, we integrate out U-E analytically, following Tian et al. (2016), and reparameterize
ʌ ʌ ʌ
Be as SE Θ∣Be | to obtain a log-concave density of |Be | supported on the nonnegative orthant with
mirror function ψ(θ) = Pjd=1(θj log θj - θj). In Fig. 4a we show the example of a 2D selective
distribution using samples drawn by NUTS (Hoffman & Gelman, 2014). We also plot the results by
projected SVGD, SVMD, and MSVGD in this example. Projected SVGD fails to approximate the
target with many samples gathering at the truncation boundary, while the samples by MSVGD and
SVMD closely resemble the truth.
We then compare our methods with the standard norejection MCMC approach of the
selectiveInference R package (Tibshirani et al., 2019) using the example simulation setting
described in Sepehri & Markovic (2017) and a penalty factor 0.7. To generate N total sample
points we run MCMC for N iterations after burn-in or aggregate the particles from N/n independent
runs of MSVGD or SVMD with n = 50 particles. As N ranges from 1000 to 3000 in Fig. 3a,
the MSVGD and SVMD CIs consistently yield higher coverage than the standard 90% CIs. This
increased coverage is of particular value for smaller sample sizes, for which the standard CIs tend
to undercover. For a much larger sample size of N = 5000 in Fig. 3b, the SVMD and standard CIs
closely track one another across confidence levels, while MSVGD consistently yields longer CIs with
high coverage. The higher coverage of MSVGD is only of value for larger confidence levels at which
the other methods begin to undercover.
We next apply our samplers to a post-selection inference task on the HIV-1 drug resistance
dataset (Rhee et al., 2006), where we run randomized Lasso (Tian et al., 2016) to find statisti-
cally significant mutations associated with drug resistance using susceptibility data on virus isolates.
7
Published as a conference paper at ICLR 2022
We take the vitro measurement of log-fold change under the 3TC drug as response and include
mutations that had appeared at least 11 times in the dataset as regressors. In Fig. 4b we plot the
CIs of selected mutations obtained with N = 5000 sample points. We see that the invalid unad-
justed least squares CIs can lead to premature conclusions, e.g., declaring mutation 215Y significant
when there is insufficient support after conditioning on the selection event. In contrast, mutation
184V, which has known association with drug resistance, is declared significant by all methods even
after post-selection adjustment. The MSVGD and SVMD CIs mostly track those of the standard
selectiveInference method, but their conclusions sometimes differ: e.g., 62Y is flagged as
significant by MSVGD and SVMD but not by selectiveInference.
Projected SVGD
SVMD
MSVGD
(b)
Figure 4: (a) Sampling from a 2D selective density; (b) Unadjusted and post-selection CIs for the
mutations selected by the randomized Lasso as candidates for HIV-1 drug resistance (see Sec. 5.2).
(a)
5.3	Large-scale posterior inference with non-Euclidean geometry
Finally, we demonstrate the advantages of exploiting non-Euclidean geometry by recreating the
real-data large-scale Bayesian logistic regression experiment of Liu & Wang (2016) with 581,012
datapoints and d = 54 feature dimensions. Here, the target p is the posterior distribution over logistic
regression parameters. We adopt the Fisher information metric tensor G, compare 20-particle SVNG
to SVGD and its prior geometry-aware variants RSVGD (Liu & Zhu, 2018) and MatSVGD with
average and mixture kernels (Wang et al., 2019), and for all methods use stochastic minibatches of
size 256 to scalably approximate each log likelihood query. In Fig. 5, all geometry-aware methods
substantially improve the log predictive probability of SVGD. SVNG also strongly outperforms
RSVGD and converges to its maximum test probability in half as many steps as MatSVGD (Avg) and
more rapidly than MatSVGD (Mixture).
6	Convergence Guarantees
We next turn our attention to the convergence properties of our proposed methods. For Kt and t
as in Alg. 1, let (qt∞ , qt∞,H) represent the distributions of the mirrored Stein updates (θt, ηt) when
θo 〜q∞ and ηt+ι = ηt + ag∖t,κt (θt) for t ≥ 0. Our first result, proved in App. I.5, shows that if
the Alg. 1 initialization q0 h = ɪ P>ι δ^ converges in Wasserstein distance to a distribution q∞H
as n → ∞, then, on each round t > 0, the output of Alg. 1, q： = ɪ P2ι δθi, converges to q∞.
Theorem 6 (Convergence of mirrored updates as n → ∞). Suppose Alg. 1 is initialized with
q0,H = * Pin=ι δηi satisfying Wι(qo,H, q∞H) → 0 for Wi the L1 WaSSerStein distance. Define the
η-induced kernel Kvψ*,t(η, η0)，Kt(Vψ*(η), Vψ*(η0)). If, for some c1,c2 > 0,
∣∣V(Kvψ*,t(∙,η)VlogPH(η) + v ∙ Kyψ*,t(∙,η^IloP ≤ CI(I + ∣∣η∣∣2),
∣∣v(Kvψ*,t(η0, ∙)vlogPH(∙) + V ∙ Kvψ*,t(η0, ∙))kop ≤ c2(I + I∣η0k2),
then, W1 (qtn,H, qt∞,H) → 0 and qtn ⇒ qt∞ for each round t.
8
Published as a conference paper at ICLR 2022
Figure 5: Value of non-Euclidean geometry in large-scale Bayesian logistic regression.
Remark The pre-conditions hold, for example, whenever V log PH is Lipschitz, ψ is strongly
convex, and Kt = kI for k bounded with bounded derivatives.
Given a mirrored Stein operator (6), an arbitrary Stein set G, and an arbitrary matrix-valued kernel K
we define the mirrored Stein discrepancy and mirrored kernel Stein discrepancy
MSD(q,p,G) ,supg∈GEq[(Mp,ψg)(θ)] and MKSDK(q,p) ,MSD(q,p,BHK). (15)
The former is an example of a diffusion Stein discrepancy (Gorham et al., 2019) and the latter an
example of a diffusion kernel Stein discrepancy (Barp et al., 2019). Since the MKSD optimiza-
tion problem (15) matches that in Thm. 3, we have that MKSDK(q,p) = ||g：,KIIHK.OUr next
result, proved in App. I.6, shows that the infinite-particle mirrored Stein updates reduce the KL
divergence to p whenever the step size is sUfficiently small and drive MKSD to 0 if, for example,
et = Ω(MKSDκt (q∞,p)α) for any α > 0. We also provide two conditions in App. H that generalize
the Stein Log-Sobolev and Stein Poincare inequalities in Duncan et al. (2019); Korba et al. (2020)
and which imply exponential convergence rates of oUr algorithms in continUoUs time.
Theorem 7 (Infinite-particle mirrored Stein updates decrease KL and MKSD). Assume κ1 ,
supθIKt(θ, θ)Iop < ∞, κ2 , Pid=1 supθ IVi2,d+iKt(θ,θ)Iop < ∞, VlogpH is L-Lipschitz, and
ψ is α-strongly convex. If et < 1/(2sup© ∣∣V2ψ(θ)-1Vg*∞,κt (θ) + Vgq∞Kt (θ)>V2ψ(θ)-1∣op),
KL(q∞+ιkp) - KL(q∞kp) ≤ —3 - (LK1 + 翁h)mksda(q∞,p)2.
Our last result, proved in App. I.7, shows that qt∞ ⇒ p if MKSDKk (qt∞,p) → 0. Hence, by Thms. 6
and 7, n-particle MSVGD converges weakly to p if et decays at a suitable rate.
Theorem 8 (MKSDKk determines weak convergence). Assume pH is distantly dissipative (Eberle,
2016) with V logPH Lipschitz, ψ is StrOngly convex with continuous Vψ*, and k(θ,θ0) =
κ(Vψ(θ), Vψ(θ0)) for κ(x, y) = (c2 + ∣x - y∣22 )β with β ∈ (-1, 0). Then, qt∞ ⇒ p if
MKSDKk (qt∞, P) →0.
Remark The pre-conditions hold, for example, for any Dirichlet target with negative entropy ψ.
7 Discussion
This paper introduced the mirrored Stein operator along with three new particle evolution algorithms
for sampling with constrained domains and non-Euclidean geometries. The first algorithm MSVGD
performs SVGD updates in a mirrored space before mapping to the target domain. The other two
algorithms are different discretizations of the same continuous dynamics for exploiting non-Euclidean
geometry. SVMD is a multi-particle generalization of mirror descent for constrained domains, while
SVNG is designed for unconstrained problems with informative metric tensors.
We highlight three limitations. First, like SVGD, our MSVGD require O(n2 ) time per update.
Second, SVMD and SVNG are more costly than MSVGD due to the adaptive kernel construction.
Low-rank kernel approximation may be needed to reduce their complexity. Third, we leave open
the question of convergence when stochastic gradient estimates are employed, but we suspect
the results of Gorham et al. (2020, Thm. 7) can be extended to our setting. In the future, we
hope to deploy our mirrored Stein operators for other inferential tasks on constrained domains
including sample quality measurement (Gorham & Mackey, 2015; Huggins & Mackey, 2018),
goodness-of-fit testing (Chwialkowski et al., 2016; Liu et al., 2016; Jitkrittum et al., 2017), graphical
model inference (Zhuo et al., 2018; Wang et al., 2018), parameter estimation (Barp et al., 2019),
thinning (Riabiz et al., 2020), and de novo sampling (Chen et al., 2018; Futami et al., 2019).
9
Published as a conference paper at ICLR 2022
Reproducibility Statement
See App. G for experimental details and
https://github.com/thjashin/mirror- stein-samplers
for Python and R code replicating all experiments.
References
Kwangjun Ahn and Sinho Chewi. Efficient constrained sampling via the mirror-Langevin algorithm.
arXiv preprint arXiv:2010.16212, 2020.
Shun-Ichi Amari. Natural gradient works efficiently in learning. Neural Computation, 10(2):251-276,
1998.
Andrew D Barbour. Stein’s method and Poisson process convergence. Journal of Applied Probability,
pp. 175-184, 1988.
Alessandro Barp, Francois-Xavier Briol, Andrew Duncan, Mark Girolami, and Lester Mackey.
Minimum Stein discrepancy estimators. In Advances in Neural Information Processing Systems,
pp. 12964-12976, 2019.
Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods for
convex optimization. Operations Research Letters, 31(3):167-175, 2003.
Alain Berlinet and Christine Thomas-Agnan. Reproducing kernel Hilbert spaces in probability and
statistics. Springer Science & Business Media, 2011.
Rabi N Bhattacharya and Edward C Waymire. Stochastic processes with applications. SIAM, 2009.
David M Blei, Andrew Y Ng, and Michael I Jordan. Latent Dirichlet allocation. Journal of Machine
Learning Research, 3:993-1022, 2003.
Peng Chen, Keyi Wu, Joshua Chen, Tom O'Leary-Roseberry, and Omar Ghattas. Projected Stein
variational Newton: A fast and scalable Bayesian inference method in high dimensions. In
Advances in Neural Information Processing Systems, volume 32, 2019.
Wilson Ye Chen, Lester Mackey, Jackson Gorham, Francois-Xavier Briol, and Chris Oates. Stein
points. In International Conference on Machine Learning, pp. 844-853, 2018.
Sinho Chewi, Thibaut Le Gouic, Chen Lu, Tyler Maunu, Philippe Rigollet, and Austin Stromme.
Exponential ergodicity of mirror-Langevin diffusions. arXiv preprint arXiv:2005.09669, 2020.
Kacper Chwialkowski, Heiko Strathmann, and Arthur Gretton. A kernel test of goodness of fit. In
International Conference on Machine Learning, pp. 2606-2615, 2016.
Arnak Dalalyan. Further and stronger analogy between sampling and optimization: Langevin Monte
Carlo and gradient descent. In Conference on Learning Theory, pp. 678-689, 2017.
Gianluca Detommaso, Tiangang Cui, Youssef Marzouk, Alessio Spantini, and Robert Scheichl.
A Stein variational Newton method. In Advances in Neural Information Processing Systems,
volume 31, pp. 9187-9197, 2018.
John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and
stochastic optimization. Journal of Machine Learning Research, 12(7), 2011.
Andrew Duncan, Nikolas Nusken, and Lukasz Szpruch. On the geometry of Stein variational gradient
descent. arXiv preprint arXiv:1912.00894, 2019.
Alain Durmus, Eric Moulines, and Marcelo Pereyra. Efficient Bayesian computation by proximal
Markov chain Monte Carlo: when Langevin meets Moreau. SIAM Journal on Imaging Sciences,
11(1):473-506, 2018.
10
Published as a conference paper at ICLR 2022
Andreas Eberle. Reflection couplings and contraction rates for diffusions. Probability Theory and
RelatedFields,166(3):851-886, 2016.
Stewart N Ethier. A class of degenerate diffusion processes occurring in population genetics.
Communications on Pure and Applied Mathematics, 29(5):483-493, 1976.
Yihao Feng, Dilin Wang, and Qiang Liu. Learning to draw samples with amortized Stein variational
gradient descent. Uncertainty in Artificial Intelligence, 2017.
JC Ferreira and VA Menegatto. Eigenvalues of integral operators defined by smooth positive definite
kernels. Integral Equations and Operator Theory, 64(1):61-81, 2009.
Futoshi Futami, Zhenghang Cui, Issei Sato, and Masashi Sugiyama. Bayesian posterior approximation
via greedy particle optimization. In Proceedings of the AAAI Conference on Artificial Intelligence,
pp. 3606-3613, 2019.
Han L Gan, Adrian Rollin, and Nathan Ross. Dirichlet approximation of equilibrium distributions in
Cannings models with mutation. Advances in Applied Probability, 49(3):927-959, 2017.
Damien Garreau, Wittawat Jitkrittum, and Motonobu Kanagawa. Large sample analysis of the median
heuristic. arXiv preprint arXiv:1707.07269, 2017.
Jackson Gorham and Lester Mackey. Measuring sample quality with Stein’s method. In Advances in
Neural Information Processing Systems, pp. 226-234, 2015.
Jackson Gorham and Lester Mackey. Measuring sample quality with kernels. In International
Conference on Machine Learning, pp. 1292-1301, 2017.
Jackson Gorham, Andrew B Duncan, Sebastian J Vollmer, and Lester Mackey. Measuring sample
quality with diffusions. The Annals of Applied Probability, 29(5):2884-2928, 2019.
Jackson Gorham, Anant Raj, and Lester Mackey. Stochastic stein discrepancies. arXiv preprint
arXiv:2007.02857, 2020.
Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine. Reinforcement learning with
deep energy-based policies. In International Conference on Machine Learning, pp. 1352-1361,
2017.
Geoffrey Hinton, Nitish Srivastava, and Kevin Swersky. Neural networks for machine learning lecture
6a: overview of mini-batch gradient descent. 2012.
Matthew D Hoffman and Andrew Gelman. The No-U-Turn sampler: adaptively setting path lengths
in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1):1593-1623, 2014.
Matthew D Hoffman, David M Blei, Chong Wang, and John Paisley. Stochastic variational inference.
Journal of Machine Learning Research, 14(5), 2013.
Ya-Ping Hsieh, Ali Kavis, Paul Rolland, and Volkan Cevher. Mirrored Langevin dynamics. In
Advances in Neural Information Processing Systems, pp. 2878-2887, 2018.
Jonathan Huggins and Lester Mackey. Random feature Stein discrepancies. In S. Bengio, H. Wal-
lach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural
Information Processing Systems, pp. 1903-1913. 2018.
Wittawat Jitkrittum, Wenkai Xu, Zoltan Szabo, K. Fukumizu, and A. Gretton. A Linear-Time Kernel
Goodness-of-Fit Test. In Advances in Neural Information Processing Systems, 2017.
Sham Kakade, Shai Shalev-Shwartz, Ambuj Tewari, et al. On the duality of strong convexity and
strong smoothness: Learning applications and matrix regularization. Unpublished Manuscript, 2
(1), 2009.
Mohammad Emtiyaz Khan and Didrik Nielsen. Fast yet simple natural-gradient descent for variational
inference in complex models. In 2018 International Symposium on Information Theory and Its
Applications (ISITA), pp. 31-35. IEEE, 2018.
11
Published as a conference paper at ICLR 2022
Taesup Kim, Jaesik Yoon, Ousmane Dia, Sungwoong Kim, Yoshua Bengio, and Sungjin Ahn.
Bayesian model-agnostic meta-learning. Advances in Neural Information Processing Systems,
2018.
Anna Korba, Adil Salim, Michael Arbel, Giulia Luise, and Arthur Gretton. A non-asymptotic analysis
for Stein variational gradient descent. Advances in Neural Information Processing Systems, 33,
2020.
Jason D Lee, Dennis L Sun, Yuekai Sun, and Jonathan E Taylor. Exact post-selection inference, with
application to the lasso. Annals of Statistics, 44(3):907-927, 2016.
Chang Liu and Jun Zhu. Riemannian Stein variational gradient descent for Bayesian inference. In
Proceedings of the AAAI Conference on Artificial Intelligence, pp. 3627-3634, 2018.
Chang Liu, Jingwei Zhuo, Pengyu Cheng, Ruiyi Zhang, and Jun Zhu. Understanding and accelerating
particle-based variational inference. In International Conference on Machine Learning, pp. 4082-
4092, 2019a.
Chang Liu, Jingwei Zhuo, and Jun Zhu. Understanding MCMC dynamics as flows on the Wasserstein
space. In Proceedings of the 36th International Conference on Machine Learning, pp. 4093-4103,
2019b.
Qiang Liu. Stein variational gradient descent as gradient flow. In Advances in Neural Information
Processing Systems, pp. 3115-3123, 2017.
Qiang Liu and Dilin Wang. Stein variational gradient descent: A general purpose Bayesian inference
algorithm. Advances in Neural Information Processing Systems, 29:2378-2386, 2016.
Qiang Liu, Jason Lee, and Michael Jordan. A kernelized Stein discrepancy for goodness-of-fit tests.
In International Conference on Machine Learning, pp. 276-284, 2016.
Yi-An Ma, Tianqi Chen, and Emily Fox. A complete recipe for stochastic gradient MCMC. In
Advances in Neural Information Processing Systems, pp. 2917-2925, 2015.
Yi-An Ma, Niladri Chatterji, Xiang Cheng, Nicolas Flammarion, Peter Bartlett, and Michael I Jordan.
Is there an analog of Nesterov acceleration for MCMC? arXiv preprint arXiv:1902.00996, 2019.
James Martens. New insights and perspectives on the natural gradient method. arXiv preprint
arXiv:1412.1193, 2014.
Charles A Micchelli and Massimiliano Pontil. On learning vector-valued functions. Neural Computa-
tion, 17(1):177-204, 2005.
Arkadij Semenovic Nemirovskij and David Borisovich Yudin. Problem complexity and method
efficiency in optimization. 1983.
Chris J Oates, Mark Girolami, and Nicolas Chopin. Control functionals for Monte Carlo integration.
Journal of the Royal Statistical Society: Series B (Methodological), 79(3):695-718, 2017.
Bernt 0ksendal. Stochastic Differential Equations: An Introduction with Applications. Springer
Science & Business Media, 2003.
Sam Patterson and Yee Whye Teh. Stochastic gradient Riemannian Langevin dynamics on the
probability simplex. In Advances in Neural Information Processing Systems, pp. 3102-3110, 2013.
Garvesh Raskutti and Sayan Mukherjee. The information geometry of mirror descent. IEEE
Transactions on Information Theory, 61(3):1451-1457, 2015.
Soo-Yon Rhee, Jonathan Taylor, Gauhar Wadhera, Asa Ben-Hur, Douglas L Brutlag, and Robert W
Shafer. Genotypic predictors of human immunodeficiency virus type 1 drug resistance. Proceedings
of the National Academy of Sciences, 103(46):17355-17360, 2006.
Marina Riabiz, Wilson Chen, Jon Cockayne, Pawel Swietach, Steven A Niederer, Lester Mackey,
Chris Oates, et al. Optimal thinning of MCMC output. arXiv preprint arXiv:2005.03952, 2020.
12
Published as a conference paper at ICLR 2022
Amir Sepehri and Jelena Markovic. Non-reversible, tuning-and rejection-free Markov chain Monte
Carlo via iterated random functions. arXiv preprint arXiv:1711.07177, 2017.
Jiaxin Shi, Shengyang Sun, and Jun Zhu. A spectral approach to gradient estimation for implicit
distributions. In International Conference on Machine Learning, pp. 4644-4653, 2018.
Umut Simsekli, Roland Badeau, Taylan Cemgil, and Gael Richard. Stochastic quasi-Newton Langevin
Monte Carlo. In International Conference on Machine Learning, pp. 642-651, 2016.
Charles Stein. A bound for the error in the normal approximation to the distribution of a sum of
dependent random variables. In Proceedings of the Sixth Berkeley Symposium on Mathemati-
cal Statistics and Probability, Volume 2: Probability Theory. The Regents of the University of
California, 1972.
Gabor J SzekeIy and Maria L Rizzo. Energy statistics: A class of statistics based on distances.
Journal of Statistical Planning and Inference, 143(8):1249-1272, 2013.
Jonathan Taylor and Robert J Tibshirani. Statistical learning and selective inference. Proceedings of
the National Academy of Sciences, 112(25):7629-7634, 2015.
Xiaoying Tian, Nan Bi, and Jonathan Taylor. MAGIC: a general, powerful and tractable method for
selective inference. arXiv preprint arXiv:1607.02630, 2016.
Ryan Tibshirani, Rob Tibshirani, Jonatha Taylor, Joshua Loftus, Stephen Reid, and Jelena
Markovic. selectiveInference: Tools for Post-Selection Inference, 2019. URL https://CRAN.
R-project.org/package=selectiveInference. R package version 1.2.5.
Dilin Wang, Zhe Zeng, and Qiang Liu. Stein variational message passing for continuous graphical
models. In International Conference on Machine Learning, pp. 5219-5227, 2018.
Dilin Wang, Ziyang Tang, Chandrajit Bajaj, and Qiang Liu. Stein variational gradient descent with
matrix-valued kernels. In Advances in Neural Information Processing Systems, pp. 7836-7846,
2019.
Max Welling and Yee W Teh. Bayesian learning via stochastic gradient Langevin dynamics. In
International Conference on Machine Learning, pp. 681-688, 2011.
Edwin B Wilson. Probable inference, the law of succession, and statistical inference. Journal of the
American Statistical Association, 22(158):209-212, 1927.
Tatiana Xifara, Chris Sherlock, Samuel Livingstone, Simon Byrne, and Mark Girolami. Langevin
diffusions and the Metropolis-adjusted Langevin algorithm. Statistics & Probability Letters, 91:
14-19, 2014.
Jianyi Zhang, Yang Zhao, and Changyou Chen. Variance reduction in stochastic particle-optimization
sampling. In Proceedings of the 37th International Conference on Machine Learning, pp. 11307-
11316, 2020a.
Kelvin Shuangjian Zhang, Gabriel Peyre, Jalal Fadili, and Marcelo Pereyra. Wasserstein control of
mirror Langevin Monte Carlo. arXiv preprint arXiv:2002.04363, 2020b.
Michael Zhu, Chang Liu, and Jun Zhu. Variance reduction and quasi-Newton for particle-based
variational inference. In Proceedings of the 37th International Conference on Machine Learning,
pp. 11576-11587, 2020.
Jingwei Zhuo, Chang Liu, Jiaxin Shi, Jun Zhu, Ning Chen, and Bo Zhang. Message passing Stein
variational gradient descent. In International Conference on Machine Learning, pp. 6018-6027,
2018.
13
Published as a conference paper at ICLR 2022
Algorithm 2 Stein Variational Natural Gradient (SVNG)
Input: density p(θ) on Rd, kernel k, metric tensor G(θ), particles (θ0i)in=1, step sizes (t)tT=1
for t = 0 : T do
for i ∈ [n],θi+ι - θi + QG⑹厂1gG,t(θi), Where
gG,t(θ) = n pn=ι[KG,t(θ,θj)G(θj)-1Vlogp(θj)+Vθj- ∙(KG,t(θ, θj)G(θj)-1)] (see (14))
return {θTi +1}in=1.
A Mirror Descent, Riemannian Gradient Flow, and Natural
Gradient
The equivalence between the mirror flow dηt = -Vf (θt)dt, θt = Vψ*(ηt)dt and the Riemannian
gradient floW in (3) is a direct result of the chain rule:
ɪ = -Vntθ* = -(vθt ηt)-1 ddηt = -v2ψ(Ot)TVf (θt )，
dηt = -VfR) = -V©t ntVntf(Vψ*St)) = -v2ψ*St)TVntf (Vψ*St)).
(16)
(17)
Depending on discretizing (16) or (17), there are two natural gradient descent (NGD) updates that
can arise from the same gradient flow:
NGD (a): θt+1 = θt - tV2ψ(θt)-1Vf(θt),
NGD (b): ηt+ι = ηt - etV2ψ*(ηt)-1Vntf (Vψ*(ηt)).
With finite step sizes t , their updates need not be the same and can lead to different optimization
paths. Since Vf(θt) = V2ψ*(ηt)-1 Vnt f (Vψ*(ηt)), NGD (b) is equivalent to the dual-space update
by mirror descent. This relationship was pointed out in Raskutti & Mukherjee (2015) and has been
used for developing natural gradient variational inference algorithms (Khan & Nielsen, 2018). We
emphasize, however, our SVNG algorithm developed in Sec. 4.4 corresponds to the discretization
in the primal space as in NGD (a). Therefore, it does not require an explicit dual space, and allows
replacing V2ψ with more general information metric tensors.
B Details of Example 1
For the entropic mirror map ψ(θ) = Pjd=+11 θj log θj, we have V2ψ(θ)-1 = diag(θ) - θθ>. Note
here θ denotes a d-dimensional vector and does not include θd+1 = 1 - Pjd=1 θd . Since Θ is a
(d + 1)-simplex, ∂Θ is composed of d + 1 faces with θ in the j-th face satisfies θj = 0. The outward
unit normal vector n(θ) for the first d faces are -ej for 1 ≤ j ≤ d, where ej denotes the j-th standard
basis of Rd. The outward unit normal vector for the (d + 1)-st face is a vector with 1∕√d in all
coordinates. Therefore, we have
p(θ)g(θ)>V2ψ(θ)-1n(θ)dθ =	p(θ)g(θ)>(diag(θ) - θθ>)n(θ)dθ
∂Θ	∂Θ
=	p(θ)(θ g(θ) - θθ>g(θ))>n(θ)dθ
∂Θ
d
= X	p(θ)(θ>g(θ) - gj (θ))θj dθ-j
+---7= [	p(θ)θ>g(θ)θd+1dθ
d θd+1 =0
=0,
where in the second to last identity we used θ>1 = 1 - θd+1. Finally, we can verify the condition in
Prop. 1 as
lim	p(θ)kV2ψ(θ)-1nr(θ)k2dθ = sup	p(θ)g(θ)>V2ψ(θ)-1n(θ)dθ = 0.
r→∞ ∂Θr	kgk∞≤1 ∂Θ
14
Published as a conference paper at ICLR 2022
C Derivation of the Mirrored Stein Operator
We first review the (overdamped) Langevin diffusion - a Markov process that underlies many recent
advances in Stein,s method - along with its recent mirrored generalization. The Langevin diffusion
with equilibrium density p on Rd is a Markov process (θt)t≥0 ⊂ Rd satisfying the stochastic
differential equation (SDE)
dθt = V logp(θt)dt + √2dBt	(18)
with (Bt)t≥0 a standard Brownian motion (Bhattacharya & Waymire, 2009, Sec. 4.5).
To identify Stein operators that satisfy (4) for broad classes of targets p, Gorham & Mackey (2015)
proposed to build upon the generator method of Barbour (1988): First, identify a Markov process
(θt)t≥0 that has p as the equilibrium density; they chose the Langevin diffusion of (18). Next, build a
Stein operator based on the (infinitesimal) generator A of the process (0ksendal, 2003, Def. 7.3.1):
(Af )(θ) = limt→o 1 (Ef (θt) - Ef (θo)) for f : Rd → R,
as the generator satisfies Eθ〜p[(Af )(θ)] = 0 under relatively mild conditions. We use the following
theorem to derive the generator of the processes described by SDEs like (18):
Theorem 9 (Generator of Ito diffusion; 0ksendal, 2003, Thm 7.3.3). Let (xt)t≥o be the Ito diffusion
in X ⊆ Rd satisfying dxt = b(xt)dt + σ(xt)dBt. Forany f ∈ C2(X), the (infinitesimal) generator
A of (xt)t≥0 is
(Af )(x) = b(x)>Vf (x) + 1 Tr(σ(x)σ(x)>V2 f (x)).
For the Langevin diffusion (18), substituting V logp(∙) for b(∙) and √2I for σ(∙) in Thm. 9, we
obtain Af = (V logp)>Vf + V ∙ Vf. Replacing Vf with a vector-valued function g gives the
Langevin Stein operator in (5).
To derive a Stein operator that works well for constrained domains, we consider the Riemannian
Langevin diffusion (Patterson & Teh, 2013; Xifara et al., 2014; Ma et al., 2015) that extends the
Langevin diffusion to non-Euclidean geometries encoded in a positive definite metric tensor G(θ):
dθt = (G(θt)-1Vlogp(θt) + V ∙ G(θt)-1)dt + √2G(θt)-1/2dB^
We show in App. D that the choice G = V2ψ yields the recent mirror-Langevin diffusion (Zhang
et al., 2020b; Chewi et al., 2020)
θt = Vψ*(ηt),	dηt = V log p(θt)dt + √2V2ψ(θt)“dBt.	(19)
According to Thm. 9, the generator of the mirror-Langevin diffusion described by (20) is
(Ap,ψ f )(θ) = (V2 ψ(θ)-1 V log p(θ) + V∙V2ψ(θ)-1)>Vf (θ) + Tr(V2ψ(θ)-1V2 f (θ))
=Vf(θ)>V2ψ(θ)-1Vlogp(θ) + V ∙ (V2ψ(θ)-1Vf(θ)).
Now substituting g(θ) for Vf (θ), we obtain the associated mirrored Stein operator:
(Mp,ψg)(θ) = g(θ)>V2ψ(θ)-1Vlogp(θ) + V∙ (V2ψ(θ)-1g(θ)).
D Riemannian Langevin Diffusions and Mirror-Langevin
Diffusions
Zhang et al. (2020b) pointed out (19) is a particular case of the Riemannian LD. However, they did
not give an explicit derivation. The Riemannian LD (Patterson & Teh, 2013; Xifara et al., 2014; Ma
et al., 2015) with V2ψ(∙) as the metric tensor is
dθt = (V2ψ(θt)-1Vlogp(θt) + V∙ V2ψ(θt)-1)dt + √2V2ψ(θt)-1/2dBt.	(20)
To see the connection with mirror-Langevin diffusion, we would like to obtain the SDE that describes
the evolution of ηt = Vψ(θt) under the diffusion. This requires the following theorem that provides
the analog of the “chain rule” in SDEs.
4A matrix divergence ▽ ∙ G(θ) is the vector obtained by computing the divergence of each row of G(θ).
15
Published as a conference paper at ICLR 2022
Theorem 10 (Ito formula; 0ksendal, 2003, Thm 4.2.1). Let (xt)t≥o be an Itoprocess in X ⊂ Rd
satisfying dxt = b(xt)dt + σ(xt)dBt. Let f(x) ∈ C2 : Rd → Rd . Then yt = f (xt) is again anIto^
process, and its i-th dimension satisfies
dyt,i = "fi(xt)τb(xt) + 2 Tr(V2fi(xt)σ(xt)σ(xt)>)dt + Vfi(Xt)τσ(xt)dBt.
Substituting Vψ for f in Thm. 10, We have the SDE of η = Vψ(θt) as
dηt = (Vlogp(θt) + V2ψ(θt)V ∙V2ψ(θt)-1 + h(θt))dt + √2V2ψ(θt)"dBt,
Where h(θt)i = Tr(Vθ2 (Vθt,i ψ(θt))V2ψ(θt)-1). Moreover, We have
[V2ψ(θt)V∙V2ψ(θt)-1]i + Tr(V2t (Vθt,i ψ(θt))V2ψ(θt)-1)
dd	dd
=XX V2ψ(θt)ij Vθt,' [V2ψ(θt)-1]j' + XX Vθt,' V2ψ(θt)ij [V2ψ(θt)-1 ]j`
d	/ d	∖ d
=XvΘ"' ( X Vψ(θt)ij [V2ψ(Ot)I]j' I = X V&t,'Ii' = 0.
'=1	j = 1	'=1
Therefore, the ηt diffusion is described by the SDE:
dηt = V log p(θt)dt + √2v2ψ(θt)“dBt, θt = Vψ*(ηt).
E Mode Mismatch Under Transformations
Figure 6: The density functions of the same distribution in θ (left) and η (right) space under
the transformation η = Vψ(θ). Each θ folloWs a Beta distributions on [0, 1]. We choose the
negative entropy ψ(θ) = θ log θ + (1 - θ) log(1 - θ). Then, the transformation is the logit function
η = log(θ∕(1 — θ)) and its reverse is the sigmoid function θ = 1/(1 + e-η). TOP: θ 〜Beta(0.5,0.5).
Dashed lines mark the mode of the transformed density pH (η) and the corresponding θ, Which gives
the lowest value of p(θ); Bottom: θ 〜Beta(1.1,10). Dashed lines mark the mode of the target
density p(θ) and the corresponding η, Which clearly does not match the mode ofpH(η).
16
Published as a conference paper at ICLR 2022
F Background on Reproducing Kernel Hilbert Spaces
Let H be a Hilbert space of functions defined on X and taking their values in R. We say k is a
reproducing kernel (or kernel) of H if ∀x ∈ X, k(x, ∙) ∈ H and ∀f ∈ H, hf, k(χ, ∙)>h = f(χ). H is
called a reproducing kernel Hilbert space (RKHS) if it has a kernel. Kernels are positive definite (p.d.)
functions, which means that matrices with the form (k(xi, xj ))ij are positive semidefinite. For any
p.d. function k, there is a unique RKHS with k as the reproducing kernel, which can be constructed
by the completion of {Pn=ι aik(xi, ∙), Xi ∈ X,ai ∈ R, i ∈ N}.
Now we assume X is a metric space, k is a bounded continuous kernel with the RKHS H, and ν is a
positive measure on X. L2(ν) denote the space of all square-integrable functions w.r.t. ν. Then the
kernel integral operator Tk : L2(ν) → L2(ν) defined by
Tkg
g g(x)k(x, ∙)dν
X
is compact and self-adjoint. Therefore, according to the spectral theorem, there exists an at most
countable set of positive eigenvalues {λj }j∈J ⊂ R with λ1 ≥ λ2 ≥ . . . converging to zero and
orthonormal eigenfunctions {uj}j∈J such that
Tkuj = λj uj ,
and k has the representation k(x, x0) = Pj∈J λj uj (x)uj (x0) (Mercer’s theorem on non-compact
domains), where the convergence of the sum is absolute and uniform on compact subsets of X ×
X (Ferreira & Menegatto, 2009).
G Supplementary Experimental Details and Additional Results
In this section, we report supplementary details and additional results from the experiments of Sec. 5.
In Secs. 5.1 and 5.2, We use the inverse multiquadric input kernel k(θ, θ0) = (1 + ∣∣θ - θ0∣∣2/'2)-1/2
due to its convergence control properties (Gorham & Mackey, 2017). In the unconstrained experiments
of Sec. 5.3, we use the Gaussian kernel k(θ, θ0) = exp(-∣θ - θ0∣2/'2) for consistency with past
Work. The bandWidth ` is determined by the median heuristic (Garreau et al., 2017). We select τ
from {0.98, 0.99} for all SVMD experiments. For unconstrained targets, we report, for each method,
results from the best fixed step size ∈ {0.01, 0.05, 0.1, 0.5, 1} selected on a separate validation
set. For constrained targets, we select step sizes adaptively to accommodate rapid density growth
near the boundary; specifically, we use RMSProp (Hinton et al., 2012), an extension of the AdaGrad
algorithm (Duchi et al., 2011) used in Liu & Wang (2016), and report performance with the best
learning rate. Results were recorded on an Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz and an
NVIDIA Tesla P100 PCIe 16GB.
G.1 Approximation quality on the simplex
The sparse Dirichlet posterior of Patterson & Teh (2013) extended to 20 dimensions features a sparse,
symmetric Dir(α) prior with αk = 0.1 for k ∈ {1, . . . , 20} and sparse count data n1 = 90, n2 =
n3 = 5, nj = 0 (j > 3), modeled via a multinomial likelihood. The quadratic target satisfies
logp(θ) = - 212θ>Aθ + const, where we slightly modify the target density of Ahn & Chewi (2020)
to make it less flat by introducing a scale parameter σ = 0.01. A ∈ R19×19 is a positive definite
matrix generated by normalizing products of random matrices with i.i.d. elements drawn from
Unif [-1, 1].
We initialize all methods with i.i.d samples from Dirichlet(5) to prevent any of the initial particles
being too close to the boundary. For each method and each learning rate we apply 500 particle updates.
For SVMD we set τ = 0.98. We search the base learning rates of RMSProp in {0.1, 0.01, 0.001} for
SVMD and MSVGD. Since projected SVGD applies updates in the θ space, the appropriate learning
rate range is smaller than those of SVMD and MSVGD. There we search the base learning rate of
RMSProp in {0.01, 0.001, 0.0001}. For all methods the results under each base learning rate are
plotted in Fig. 7.
17
Published as a conference paper at ICLR 2022
0。戏"一P Aaj∙,u
Projected SVGD	SVMD
MSVGD, k	MSVGD, k2
1.5
1.0
0.5
LR=0.01
——LR=0.001
LR=0.0001
0.0 l-
0
0.0
0
1.5
1.0
0.5
200
400
Number of particle updates, T
0.0
0
1.5
1.0
0.5
200
400
Number of particle updates, T
200
400
Number of particle updates, T
Number of particle updates, T
Figure 7:	Sampling from a Dirichlet target on a 20-simplex. We plot the energy distance to a ground
truth sample of size 1000.
Projected SVGD	SVMD
sue"一P As,∙,uω
LR=0.01
----LR=0.001
LR=0.0001
0	200	400
Number of particle updates, T
0.3
0.2
0.1
0	200	400
Number of particle updates, T
0.3
0.2
0.1
MSVGD, k
0	200	400
Number of particle updates, T
0.3
0.2
0.1
MSVGD, k2
0	200	400
Number of particle updates, T
Figure 8:	Sampling from a quadratic target on a 20-simplex. We plot the energy distance to a ground
truth sample of size 1000 drawn by NUTS (Hoffman & Gelman, 2014).
G.2 Confidence intervals for post-selection inference
Given a dataset X ∈ Rn×p, y ∈ Rn, the randomized Lasso (Tian et al., 2016) solves the following
problem:
argminβ∈Rp 2ky- Xβk2 + λkβkι- w>β + 2∣∣βk2, W 〜G.
where G is a user-specified log-concave distribution with density g. We choose G to be zero-
mean independent Gaussian distributions while leaving its scale and the ridge parameter to be
automatically determined by the randomizedLasso function of the selectiveInference
package. We initialize the particles of our SVMD and MSVGD in the following way: First, we map
ʌ
the solution /石 to the dual space by Vψ. Next, we add i.i.d. standard Gaussian noise to n copies of
the image in the dual space. Finally, we map the n particles back to the primal space by Vψ* and use
them as the initial locations. Below we discuss the remaining settings and additional results of the
simulation and the HIV-1 drug resistance experiment separately.
Simulation In our simulation we mostly follow the settings of Sepehri & Markovic (2017) except
using a different penalty level λ recommended in the selectiveInference R package. We
set n = 100 and P = 40. The design matrix X is generated from an equi-correlated model, i.e.,
each datapoint xi ∈ Rp is generated i.i.d. from N(0, Σ) with Σii = 1, Σij = 0.3 (i 6= j) and then
normalized to have almost unit length. The normalization is done by first centering each dimension
by subtracting the mean and dividing the standard deviation of that column of X , then additionally
multiplying 1/n1/2. y is generated from a standard Gaussian which is independent of X, i.e., we
assume the global null setting where the true value of β is zero. We set λ to be the value returned
by theoretical.lambda of the selectiveInference R package multiplied a coefficient
0.7n, where the 0.7 adjustment is introduced in the test examples of the R package to reduce the
regularization effect so that we have a reasonably large set of selected features when p = 40. The
base learning rates for SVMD and MSVGD are set to 0.01 and we run them for T = 1000 particle
updates. τ is set to 0.98 for SVMD.
Our 2D example in Fig. 4a is grabbed from one run of the simulation where there happen to be
only 2 features selected by the randomized Lasso. The selective distribution in this case has log-
density log p(θ) = -8.07193((2.39859θ1 + 1.90816θ2 + 2.39751)2 + (1.18099θ2 - 1.46104)2) +
const, θ1,2 ≥ 0.
18
Published as a conference paper at ICLR 2022
The error bars for actual coverage levels in Fig. 3a and Fig. 3b are 95% Wilson intervals (Wilson,
1927), which is known to be more accurate than ±2 standard deviation intervals for binomial
proportions like the coverage. In Fig. 9a and Fig. 9b we additionally plot the average length of the
confidence intervals w.r.t. different sample size N and nominal coverage levels. For all three methods
the CI widths are very close, although MSVGD consistently has wider intervals than SVMD and
selectiveInference. This indicates that SVMD can be preferred over MSVGD when both
methods produce coverage above the nominal level.
HIV-1 drug resistance We take the vitro measurement of log-fold change under the 3TC drug
as response and include mutations that had appeared 11 times in the dataset as regressors. This
results in n = 663 datapoints with P = 91 features. We choose λ to be the value returned by
theoretical.lambda of the SelectiveInference R package multiplied by n. The base
learning rates for SVMD and MSVGD are set to 0.01 and we run them for T = 2000 particle updates.
τ is set to 0.99 for SVMD.
8
7
6
5
4
3
2
1
0
---Standard
MSVGD
...SVMD
1000	1500	2000	2500	3000
Number of sample points, N
(b) N = 5000 sample points
(a) Nominal coverage: 0.9
Figure 9:	Width of post-selection CIs across (a) 500 / (b) 200 replications of simulation of Sepehri &
Markovic (2017).
G.3 Large-scale posterior inference with non-Euclidean geometry
The Bayesian logistic regression model We consider is Qn=ιp(y∕χi,w)p(w), where p(w) =
N (w|0, I), p(yi|xi, w) = Bernoulli(σ(w>xi)). The bias parameter is absorbed into into w by
adding an additional feature 1 to each xi . The gradient of the log density of the posterior distribution
of W is Vw logp(w∣{yi,Xi}N=ι) = PN=I x%(y% - σ(w>x.) - w. We choose the metric tensor
V2ψ(w) to be the Fisher information matrix (FIM) of the likelihood:
1 n
F = F £Ep(yi|w,xi)Vw log p(yi∣Xi, W)Vw log p(y∕χi, w)>]
n i=1
1 n
=	σ(w>xi)(1 - σ(w>xi))xix>.
n
i=1
Following Wang et al. (2019), for each iteration r (r ≥ 1), we estimate the sum with a stochastic
minibatch Br of size 256: FBr = Pn^ Pi∈B, σ(w>xi)(1 - σ(w>xi))xix> and approximate the
FIM with a moving average across iterations:
Fr = ρrFr-1 + (1 - ρr)FBr, where ρr = min(1 - 1/r, 0.95).
To ensure the positive definiteness of the FIM, a damping term 0.01I is added before taking the
inverse. For RSVGD and SVNG, the gradient of the inverse of FIM is estimated with Vwj F-1 ≈
-F-I(VWj F)F-1, where VWj F = PrVW-1F + (1 -Pr-Fb,.
We run each method for T = 3000 particle updates with learning rates in {0.01, 0.05, 0.1, 0.5, 1}
and average the results for 5 random trials. τ is set to 0.98 for SVNG. For each run, we randomly
19
Published as a conference paper at ICLR 2022
keep 20% of the dataset as test data, 20% of the remaining points as the validation set, and all the rest
as the training set. The results of each method on validation sets with all choices of learning rates are
plotted in Fig. 10. We see that the SVNG updates are very robust to the change in learning rates and
is able to accommodate very large learning rates (up to 1) without a significant loss in performance.
The results in Fig. 5 are reported with the learning rate that performs best on the validation set.
-3qiβqojd ①A--Paldm0i u2sPiPsʌ
SVNG
-3qiβqojd ①A--Paldm0i u2sPiPsʌ
Number of particle updates, T
-	3qiβqojd ①A匚-po.Idm0i u2sPiPsʌ
-3qiβqojd ①A匚-po.Idm-u2sPlpsʌ
RSVGD
-0.52
-0.54
-0.56
-0.58
-0.60
-0.62
SVGD
-	0.52
-	0.54
-	0.56
-	0.58
-	0.60
-	0.62
0	1000	2000	3000
Number of particle updates, T
1000	2000
Number of particle updates, T
-0.52
-0.54
-0.56
-0.58
-0.60
-0.62
Matrix SVGD (Avg)
1000	2000	3000
Number of particle updates, T
x-llqeqojd ①AE-Po.Idm0i u2sPIpsʌ
Number of particle updates, T
Figure 10: Logistic regression results on validation sets with learning rates in {0.01, 0.05, 0.1, 0.5,
1}. Running RSVGD with learning rates 0.5 and 1 produces numerical errors. Therefore, we did not
include them in the plot.
H	Exponential Convergence of Continuous-time Algorithms
We derive a time-inhomogeneous generalization of the Stein Log-Sobolev inequality of Duncan et al.
(2019) and Korba et al. (2020) which ensures the exponential convergence of our continuous-time
algorithms and time-inhomogeneous generalization of the Stein Poincare inequality of Duncan et al.
(2019) which guarantees exponential convergence near equilibrium (i.e., when qt is sufficiently close
to p). As the results hold for a generic sequence of kernels (Kt)t≥0, the implications apply to both
MSVGD and SVMD.
20
Published as a conference paper at ICLR 2022
Definition 2 (Mirror Stein Log-Sobolev inequality). We define the Mirror Stein Log-Sobolev inequal-
ity (cf., Korba et al., 2020, Def. 2) as
KL(qtkp) ≤ ɪMKSDKt(qt,p) = ⅛Eqt [(V2ψ-1 Vlog 当>?小,V2ψ-1Vlog '生],
2λ	t	2λ t	p t t	p
where MKSDKt is defined in Eq. (15); PKt,qt : L2 (qt) → L2(qt) is the kernel integral operator:
(Pκt,qt夕)(∙)，Eqt(θ)[Kt(∙, θ)夕(θ)] for a general kernel Kt and Vector-Valuedfunction 夕 on Θ, and
the stated equality holds whenever integration-by-parts is applicable.
Proposition 11. Suppose (θt)t≥o follows the mirrored dynamics (8) with gt chosen to be g：= Kt as
in (10). Then, the dissipation of KL(qtkp) is
-d KL(qtkP) = -MKSDKt (qt,P)2.
dt	t
Proof The proof directly follows from Thm. 3 since the optimization problem there matches the
definition of MKSD in (15).
□
Therefore, when the Mirror Stein Log-Sobolev inequality holds, we have
ddtKL(qtkP) ≤ -2λKL(qtkP),
and the exponential convergence KL(qtkP) ≤ KL(q0kP)e-2λt follows by Gronwall’s lemma (Gron-
wall, 1919).
Definition 3 (Mirror Stein Poincare inequality). We say that the distribution P satisfies the Mirror
Stein Poincare inequality (cf., Duncan et al. 2019, Eq. (57)) with strongly convex ψ and constant λ if
Varp[φ] ≤ 1 Ep[Vφ>P"pV2ψ-1Vφ]
λ
for all φ ∈ L2(P) ∩ C∞(Θ) that is locally Lipschitz, where PKt,p is the kernel integral operator
under P defined similarly as in Definition 2.
This inequality can also be viewed as a kernelized generalization of the mirror Poincare inequality
introduced in Chewi et al. (2020, Def. 1) for proving exponential convergence of mirror-Langevin
diffusion. In a manner analogous to Thm. 1 of Chewi et al. (2020), the following proposition relates
the Mirror Stein PoinCare inequality to chi-squared divergence.
Proposition 12. Suppose (θt)t≥o follows the mirrored dynamics (8) with gt chosen to be g：t,K as
in (10). Then, the dissipation of chi-square diVergence χ2(qtkP) is
dd X2(qtkP) = -2EJV qt >PKt,pV2ψ-1V ”
dt	P	P
wheneVer integration-by-parts is applicable.
Proof We first note that by applying integration-by-parts, g短 K as in (10) can be equivalently
written as
诡,Kt= -pKt,qt v2Ψ-1v log P .
Then using the Fokker-Planck equation of qt under the dynamics, we have
^X2(qtkP) = % Z(qt)2dP = 2 Z ”当=-2EqtkKt>V也]
dt	dt P	P dt	t , t P
=-2Eqt (pKt,qtV2ψ-1Vlog q)>VP = -2Eqt V专>PKt,pV2ψ-1VP .
□
Note that the right hand side of the equation differs from the Mirror Stein POinCare inequality
only in the base measure of the expectation. Duncan et al. (2019) proposes to replace qt with P
to study the convergence near equilibrium (See their Sec. 6, where Eq. (46) is replaced with Eq.
(51)). If We do the same and combine this identity with the Mirror Stein POinCare inequality, We
obtain 奈χ2(qt∣∣P) ≤ -2λVarp[q] = -2λχ2(qt∣∣P), which implies exponential convergence in KL
KL(qtkP) ≤ χ2(qtkP) ≤ χ2(q0kP)e-2λt by Gronwall’s lemma (Gronwall, 1919).
21
Published as a conference paper at ICLR 2022
I Proofs
I.1	Proof of Prop. 1
Proof FiX any g ∈ Gψ. Since g and Vg are bounded and V2ψ(θ)-1 V logp(θ) and V ∙ V2ψ(θ)-1
are p-integrable, the expectation Eθ〜p[(Mp,ψg)(θ)] exists. Because Θ is convex, Θr is bounded and
conveX with Lipschitz boundary. Since pV2ψ-1g ∈ C1, we have
∣Ep[(Mp,ψg)(θ)]∣ = ∣Ep[g(θ)>V2ψ(θ)-1Vlogp(θ) + V ∙ (V2ψ(θ)-1g(θ))]∣
=∣/ Vp(θ)>V2ψ(θ)-1g(θ)+ p(θ)V∙ (V2ψ(θ)-1g(θ))dθ
V V∙ (p(θ)V2ψ(θ)-1g(θ))dθ
Θ
lim V V∙ (p(θ)V2ψ(θ)-1g(θ))dθ
r→∞ Θr
(by dominated convergence)
lim	(p(θ)V2ψ(θ)-1g(θ))>nr(θ)dθ
r→∞ ∂Θr
(by the divergence theorem)
≤ lim	p(θ)kg(θ)k2 V2ψ(θ)-1nr(θ) dθ (by Cauchy-Schwarz)
r→∞ ∂Θr
≤ kgk∞ lim	p(θ)V2ψ(θ)-1nr(θ) dθ = 0 (by assumption).
r→∞ ∂Θr
□
I.2	Proof of Thm. 3: Optimal mirror updates in RKHS
Proof Let ei denote the standard basis vector of Rd with the i-th element being 1 and others being
zeros. Since m ∈ HK, we have
m(θ)>V2ψ(θ)-1V log p(θ) = hm,K (∙,θ)V2ψ(θ)-1V log p(θ)iHK
d
V ∙ (V2ψ(θ)-1m(θ)) = X Vθi(m(θ)>V2ψ(θ)-1ei)
i=1
d
=Xkm Si (KGe)V2ψ⑻Tei)〉hk
i=1
=hm, vΘ ∙ (KG θW2ψ⑻T)iHκ ,
where we define the divergence of a matrix as a vector whose elements are the divergences of each
row of the matrix. Then, we write (9) as
—Eqtm(θ)>V2ψ(θ)-1Vlogp(θ) + V∙ (V2ψ(θ)-1 m(θ))]
=-Eqt [hm, K (∙,θ)V2ψ(θ)-1 V log p(θ) + Vθ ∙ (K (∙,θ)V2ψ(θ)-1)iHκ ]
=-hm,Eqt[K(∙,θ)V2ψ(θ)-1Vlogp(θ)+ Vθ ∙ (K(∙,θ)V2ψ(θ)-1)]iHκ
=-hm, EqtMp,ψK(∙,θ)]iHκ .
Therefore, the optimal direction in the HK norm ball BHK = {g : kgkH ≤ 1} that minimizes (9)
is gt H g；tK = EqtMp,ψK(∙,θ)]∙	K	□
I.3	Proof of Thm. 4: Mirrored SVGD updates
Proof A p.d. kernel k composed with any map φ is still a p.d. kernel. To prove this, let
{x1, . . . ,xp} = {φ(η1), . . . , φ(ηn)}, p ≤ n. Then
Eaiajk(φ(ηi),φ(η)) = Eβ'βmk(xg,xm) ≥ 0,
i,j	`,m
22
Published as a conference paper at ICLR 2022
where β' = Ei∈Sg αi, S' = {i : φ(ηi) = x'}. Therefore, kψ(η,η0) = k(Vψ*(η), Vψ*(η0)) is a
p.d. kernel. Plugging K = kI into Lem. 13, for any θ0 ∈ Θ and W = Vψ(θ0), We have
gqt,Kk (θ0) = Ent〜qt,H [KVψ* (vψ(θ),ηt)v logPH(Wt) + Vnt ∙ KVψ* (vψ(θ0),ηt)]
d
=Ent〜qt,H[k(Vψ*(WO), vψ*(Wt))VlogPH(Wt) + X vnt,jk(Vψ*(WO), vψ*(Wt))ej]
j=1
=Ent 〜qt,H [kψ (W0,Wt)v log PH (Wt) + vnt kψ (W0,Wt)]∙
□
I.4	Proof of Prop. 5: Single-particle SVMD is mirror descent
Proof When n = 1, λι = k(θt,θt),uι = 1, and thus Kψ,t(θt,θt) = k(θt, θt)V2ψ(θt).	□
I.5	PROOF OF THM. 6: CONVERGENCE OF MIRRORED UPDATES AS n → ∞
Proof The idea is to reinterpret our mirrored updates as one step of a matrix SVGD in W space based
on Lem. 13 and then follow the path of Gorham et al. (2020, Thm. 7). Assume that qtn,H and qt∞,H have
integrable means. Let Wn , W∞ be an optimal Wasserstein-1 coupling of qtn,H and qt∞,H . Let Φqt,Kt
denote the transform through one step of mirrored update: θt = Vψ?(Wt), Wt+ι = Wt + EtgW K (θt).
qt , t
Then, with Lem. 13, we have
kΦqt,Kt(W) - Φqt,Kt (WO)k2
= kW+EtgqWtn,Kt(θ) - WO - EtgqWt∞,Kt(θO)k2
≤ kW - WOk2 + EtkgqWtn,Kt(θ) - gqWt∞,Kt(θO)k2
≤ kW - WOk2
+ QkEnn [Kvψ*,t(W,Wn)V log ph (Wn ~) + Rn° ∙ Kvψ*,t(W,Wn)
-(Kvψ*,t(W0,Wn)V log ph (Wn) + Vnη ∙ Kvψ*,t(W0,Wn))]k2
+ etkEnn,n∞ [Kvψ*,t(W0,Wn)VlogPH(Wn) + Vrn ∙ Kvψ*,t(W,Wn)
-(KVψ*,t(W0,W∞)v log ph (W∞) + vn∞ ∙ Kvψ*,t(W0, W∞))]k2
≤ kW - WOk2 + Etc1(1 + E[kWnk2)]kW - WOk2 + Etc2(1 + kWOk2)Enn,n∞[kWn - W∞k2]
=kW - W0k2 + etc1(1 + EqnH [k，k2])kW - W0k2 + etc2(1 + WRWlSnH, q∞H)∙
SinCe φqt,Kt (Wn) 〜qn+ι,H, φqt,κ(W∞) 〜q∞+ι,H, WeCOnClUde
W1 (qtn+1,H , qt∞+1,H )
≤ E[kΦqt,K(Wn) - Φqt,K(W∞)k2]
≤ (1 + Etcι(1 + EqnH[k∙k2]))E[kWn - W∞k2]+ EtC2(1 + kW0k2)Wι(qnH, q∞H)]
≤ (1 + Etcι(1 + EqnH[k∙k2]) + EtC2(1 + Eq∞H[小[|2]))Wi@h, Q∞).
The final claim 碟 ⇒ q∞ now follows by the continuous mapping theorem as Vψ* is continuous. □
I.6	Proof of Thm. 7: Infinite-particle mirrored Stein updates decrease KL and
MKSD
Proof Let Tq∞,Kt denote transform of the density function through one step of mirrored update:
θt = Vψ*(Wt), Wt+1 = Wt + Etgq∞,Kt (θt). Then
KL(qt∞+1kP) -KL(qt∞kP)
=KL(qt∞kTq-t∞1,KtP) -KL(qt∞kP)
=Ent〜q∞H [logPh(Wt)- logPh(Wt + etgg∞,Kt (θt)) - log | det(I + EtVntgq∞,Kt (θt))1],
23
Published as a conference paper at ICLR 2022
where we have used the invariance of KL divergence under reparameterization: KL(qtkp) =
KL(qt,H kpH) . Following Liu (2017), we bound the difference of the first two terms as
logPH(ηt) - logPH(ηt + qgq∞,κt (θt))
=-/o Ns logPH(ηt(s)) ds, where ηt(s)，ηt + Setg∖∞,κt Iet)
=-Z VlogPH(ηt(s)')τ(etgq∞,Kt(θt)) ds
0t
=-et V logPH (ηt)τg*∞,κt (θt) + L (V logPH(ηt) - V logPH (ηt(s)))τ(etgq∞,κt (θt)) ds
≤ -etVlogPh(ηt)τgq∞,Kt(θt) + QL kvlogPhS)-VlogPHSt(S))k2 ∙的嬴及(θt)k2 ds
Le2
≤ -etV log PH (ηt)τ gq∞,Kt (θt) + -ɪ llgq∞,Kt (θt)k2,
and bound the log determinant term using Lem. 15:
-log I det(I + etVηtg∖∞κ(θt)) &f Tr(Vntg∖∞κ(θt)) + 2e2kV^g嬴应仪)kF∙
The next thing to notice is that Ent〜q∞H[VlogPh(ηt)τgg∞,κt(θt) + Tr(Vntg*∞,κt(θt))] is the
square of the MKSD in (15). We can show this equivalence using the identity proved in Lem. 14:
Ent 〜q∞H 瓦 ∞,Kt (θt)τV log PH (ηt) + Tr(Vnt g∖∞,K ⑼))]
=Eθt 〜q∞ [gq∞,κt (θt )τV2ψ(θt)-1Vθt (log P(θt) - log det V2ψ(θt))
+ Tr(V2ψ(θt)TVgAKt (θt))]
=Eθt〜q∞[g嬴,Kt(θt)τV2ψ(θt)-1VlogP(θt) + V∙ (V2ψ(θt)-1g嬴,Kt(θt))] (Lem. 14)
=Eθt~q∞ [(Mp,ψgq∞,Kt )(θt)]
= MKSDKt(qt∞,P)2.
Finally, we are going to bound ∣∣gq∞,K(θt)∣∣2 and kVntgq∞,Kt(θt)k2F. From the assumptions we
have ψ is α-strongly convex and thus ψ* is 1 -strongly smooth (Kakade et al., 2009), therefore
∣∣V2ψ*(∙)k2 ≤ 1. ByLem. 16, we know
kg:∞,Kt (θt)k2 ≤ kg;∞,Kt kHκt kK(θt,θt)kop = MKSDKt (q∞,P)2 kKt(θt,θt)kop,
kVnt gq∞,Kt (θt)kF = kV2@"(nt)Vg》,Kt(et)kF
≤kV2ψ* (ηt)k2kVg;∞,Kt (θt)kF
1d
≤ O2 kgq∞,Kt kHκt ΣS kVi,d+iKt(et，θt)l∣op
=-⅛MKSDKt (q∞,P)2 XX kV,d+iKt(θt,θt)kop,
α	i=1
where V2 d+iK (θ, θ) denotes V2 6, K (θ, Θ0)∣θo=θ . Combining all of the above, we have
KL(qt∞+1kP)-KL(qt∞kP)
L2	22 d
≤- It------2^sup kKt(θ, θ)kop - O" Σsup k^i,d+iKt(θ, θ)kop J MKSDKt (qt ,P).
Plugging in the definition of κ1 and κ2 finishes the proof.
□
24
Published as a conference paper at ICLR 2022
I.7 Proof of Thm. 8: MKSDKk determines weak convergence
Proof According to Thm. 4,
gq,Kk = EqH [k(∙, vψ*(η))v log PH (η) + Vn k(Vψ*㈤，•儿
where qH(η) denotes the density of η = Vψ(θ) under the distribution θ 〜q. From the assumptions
we have k(θ, θ0) = κ(vψ(θ), vψ(θ0)). With this specific choice of k, the squared MKSD is
MKSDKk (q,p)2 = kg：,KkkHKk
一 1
Ph㈤PH⑺
= Eη
,n0 〜qH
=En,n0 ~qκ
Vn Vno(pH (η)k(vψ*(η), vψ*(η0))pH (η0))
一 PH (η)pH In')Vn VnO(PH (n)κ(n,n0)pH W)
(21)
The final expression in (21) is the squared kernel Stein discrepancy (KSD) (Liu et al., 2016;
Chwialkowski et al., 2016; Gorham & Mackey, 2017) between qH and PH with the kernel κ:
KSDκ(qH,PH)2. Recall that it is proved in Gorham & Mackey (2017, Theorem 8) that, for
κ(x, y) = (c2 + kx - yk22)β with β ∈ (-1, 0) and distantly dissipative PH with Lipschitz score
functions, qH ⇒ PH if KSDκ(qH,PH) → 0. The advertised result (q ⇒ P if MKSDKk (q, P) → 0)
now follows by the continuous mapping theorem as Vψ: is continuous.	□
J	Lemmas
Lemma 13. Let Kvψ* (n, n0)，K(Vψ*(n), Vψ* (Wy). The mirrored updates g：K in (10) can be
equivalently expressed as
gqt,κ = EqtH [Kv3*(V@(・),n)V log ph (n) + Vn ∙ Kv3*(V@(・),n)].
Proof We will use the identity proved in Lem. 14.
g：t,K = EqtMp,ψK(∙, θ)]
=Eqt[K(∙,θ)V2ψ(θ)-1Vlogp(θ) + Vθ ∙ (K(∙,θ)V2ψ(θ)-1)]
=Eqt[K(∙,θ)V2ψ(θ)-1Vθ(logPh(Vψ(θ)) + logdet V2ψ(θ)) + Vθ ∙ (K(∙,θ)V2ψ(θ)-1)]
(by change-of-variable formula)
d
=Eqt [K(∙,θ)V2ψ(θ)-1VθlogPH(Vψ(θ)) + X [V2ψ(θ)-1]ijVθiK(•⑼:,j]
i,j=1
(by applying Lem. 14 to each row of K(∙,θ))
d
=Eqt [K (∙,θ)V2ψ(θ)-1Vθ log Ph (Vψ(θ)) + X Vnj K(∙,θ"]
j=1
d
=Eqt,H [K(∙, V@*(n))V log ph (n) + X Vnj k (∙, V@*(n))：,j]
j=1
=Eqt,H [KV3*(V@(・),n)V logPh(n) + Vn ∙ KVψ* (vψ(∙), n)],
where A：,j denotes the j-th column of a matrix A.	□
Lemma 14. Fora strictly convex function ψ ∈ C2 : Rd → R and any vector-valued g ∈ C1 : Rd →
Rd, the following relation holds:
V ∙ (V2ψ(θ)-1g(θ)) = Tr(V2ψ(θ)-1Vg(θ)) — g(θ)>V2ψ(θ)-1Vθ logdet V2ψ(θ).
Proof By the product rule of differentiation:
V ∙ (V2ψ(θ)-1g(θ)) = Tr(V2ψ(θ)-1Vg(θ)) + g(θ)>V ∙ (V2ψ(θ)-1).	(22)
25
Published as a conference paper at ICLR 2022
This already gives us the first term on the right side. Next, we have
[V2ψ(θ)-1V log det V2ψ(θ)]i
d
= X[V2ψ(θ)-1]ij Tr(V2ψ(θ)-1VθjV2ψ(θ))
j=1
dd
=X[V2ψ(θ)-1]ij X [V2ψ(θ)-1]'m[Vθj V2ψ(θ)]m'
j=1	',m=1
d
=X [V2ψ(θ)-1]ij [V2ψ(θ)-1]'mVθj V2ψ(θ)m'
j,',m=1
d
=X [V2ψ(θ)-1]ij Vθm V2ψ(θ)j'[V2 ψ(θ)-1 ]'m
j,',m=1
d
= - X Vθm(V2ψ(θ)-1)im
m=1
=-[V∙ V2ψ(θ)-1]i.
Plugging the above relation into (22) proves the claimed result.	口
Lemma 15 (Liu, 2017, Lemma A.1). Let A be a square matrix, and0 < e < 2口4+匕>口—. Then,
log | det(I + A)| ≥Tr(A) -22kAk2F,
where ∣∣∙∣∣f denotes the Frobenius norm of a matrix.
Lemma 16. Let K be a matrix-valued kernel and HK be the corresponding RKHS. Then, for any
f ∈ HK (f is vector-valued), we have
d
kf(x)k2 ≤ kfkHKkK(x,x)ko1/p2,	kVf(x)k2F ≤ kfk2HKXkV2xi,x0iK(x,x0)|x0=xkop,
where ∣∣ ∙ ∣∣op denotes the operator norm ofa matrix induced by the vector 2-norm.
Proof We first bound the kf (x)k2 as
kf(X)∣2= SUp f(X)>y = SUp hf,K(∙,χ)yiHκ ≤kfkHK SUp IIK(∙,x)ykHκ
kyk2=1	kyk2=1	K kyk2=1	K
= ∣f ∣HK SUp (y> K(X, X)y)1/2 ≤ ∣f ∣HK SUp SUp (u>K(X, X)y)1/2
K kyk2=1	K kyk2=1 kuk2=1
= IlfllHK sup IlK(x,x)yk2/2 = IIflIHKIlK(χ,χ)∣∣1f∙
K kyk2=1	K
The second result follows similarly,
d
d
IVf(X)I2F =	IVxif(X)I22 =	SUp (Vxif (X)Ty)2 = X SUp (hf, VxiK(∙, x)yiHκ产
i=1	i=1 kyk2=1	i=1 kyk2=1
dd
≤ IfiHk X sup llVxiK(・,X)y∣lHK = IlfllHK X sup (y>Vxi,xoK(X,xO)Ix=xoy)
Ki=1 kyk2=1	K	Ki=1 kyk2=1	i i
d
≤ If IHK X SUp SUp (u>V2xi x0 K(X, X0)|x=x0y)
K i=1 kyk2=1 kuk2=1	i, i
d
=If IHk X |尸篙卢也犷)|”『得∙
i=1
□
26