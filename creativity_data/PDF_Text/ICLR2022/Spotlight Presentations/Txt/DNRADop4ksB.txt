Published as a conference paper at ICLR 2022
On the Importance of Firth Bias Reduction in
Few- S hot Classification
Saba Ghaffari*	Ehsan Saleh*	David A. Forsyth Yu-Xiong Wang
Department of Computer Science, University of Illinois Urbana-Champaign
{sabag2, ehsans2, daf, yxw}@illinois.edu
Ab stract
Learning accurate classifiers for novel categories from very few examples, known
as few-shot image classification, is a challenging task in statistical machine learning
and computer vision. The performance in few-shot classification suffers from the
bias in the estimation of classifier parameters; however, an effective underlying bias
reduction technique that could alleviate this issue in training few-shot classifiers
has been overlooked. In this work, we demonstrate the effectiveness of Firth bias
reduction in few-shot classification. Theoretically, Firth bias reduction removes the
O(N -1) first order term from the small-sample bias of the Maximum Likelihood
Estimator. Here we show that the general Firth bias reduction technique simplifies
to encouraging uniform class assignment probabilities for multinomial logistic
classification, and almost has the same effect in cosine classifiers. We derive an
easy-to-implement optimization objective for Firth penalized multinomial logistic
and cosine classifiers, which is equivalent to penalizing the cross-entropy loss
with a KL-divergence between the uniform label distribution and the predictions.
Then, we empirically evaluate that it is consistently effective across the board for
few-shot image classification, regardless of (1) the feature representations from
different backbones, (2) the number of samples per class, and (3) the number of
classes. Furthermore, we demonstrate the effectiveness of Firth bias reduction on
cross-domain and imbalanced data settings. Our implementation is available at
https://github.com/ehsansaleh/firth_bias_reduction.
1 Introduction
Few-shot image classification is the practice of learning accurate classifiers using a small number
of labeled samples (Fei-Fei et al., 2006; Vinyals et al., 2016; Wang and Hebert, 2016; Finn et al.,
2017; Snell et al., 2017; Wang et al., 2020). It has a wide range of applications from face and gesture
recognition (Pfister et al., 2014) to visual navigation in robotics (Finn et al., 2017). Essentially,
modern few-shot classification methods can be viewed as a combination of learning (1) a strong
feature representation through a backbone network (e.g., Verma et al. (2019); Gidaris et al. (2019);
Tian et al. (2020)), and (2) an accurate small-sample classifier (e.g., Wang and Hebert (2016); Chen
et al. (2019)). Therefore, two key questions arise in few-shot image classification: (1) How can we
obtain a strong feature representation? and (2) How can we train accurate classifiers using a small
number of samples? There have been many existing methods addressing the former question using a
host of different techniques (Snell et al., 2017; Rusu et al., 2019; Verma et al., 2019; Mangla et al.,
2020). Here we focus on the less-explored second question. For our purposes, we will use standard
feature representations and methods for training the backbone model for few-shot classification. That
still leaves us with a severe classifier problem than most people realize.
There is a substantial difficulty with training a classifier using a small number of samples. In
particular, with very few samples, standard classification machinery is biased. In other words,
although the Maximum Likelihood Estimators (MLEs) are statistically consistent and asymptotically
normal (Fahrmeir and Kaufmann, 1985), it is well-established that MLEs are biased for a small
number ofN samples, with bias ofO(N-1) (Cox and Snell, 1968; Box, 1971; Whitehead, 1986; Firth,
1993). Since common logistic regression models are a type of MLEs, they are also biased (Schaefer,
*Both authors contributed equally and were ordered alphabetically.
1
Published as a conference paper at ICLR 2022
1983; Cordeiro and McCullagh, 1991; Firth, 1993; Steyerberg et al., 1999). Such biases increase the
error rate of the few-shot trained classifiers, and so are important in few-shot learning.
In fact, there is a standard solution for bias prevention by modifying the ordinary MLEs - known
as Firth’s Penalized Maximum Likelihood Estimator (PMLE) (Firth, 1993). In the case of the
exponential family of distributions, Firth has a simplified form that penalizes the likelihood by
Jeffrey’s invariant prior (Firth, 1993; Poirier, 1994), which is proportional to the determinant of the
Fisher Information Matrix F. For logistic and cosine classifiers (Chen et al., 2019) which are widely
used in few-shot classification, since they belong to the exponential family, Firth bias reduction can
be further cast as adding a log-determinant penalty (log(det(F))) to the cross-entropy loss. While
such standard strategies can control the bias in classifiers trained with very few samples, they have
not been utilized in few-shot image classification tasks.
In this paper, we show that using Firth bias reduction produces reliable improvements in a wide
range of circumstances. We achieve this by deriving a simplified yet effective Firth formulation that
penalizes the Kullback-Leibler (KL) divergence between the uniform distribution of classes and the
predictions, for both multinomial logistic regression models and cosine classifiers. Note that common
regularization techniques (such as L2-regularization and label smoothing (Szegedy et al., 2016))
cannot reduce the estimation bias of classifier weights in small-sample regimes (Liu et al., 2020) as
the Firth penalty does; these regularization techniques are mainly used to control model complexity
of deep neural networks for training feature extractor backbones in large-sample regimes.
More concretely, our results indicate that the improvements produced by Firth bias reduction for
few-shot image classification tasks are consistent across the board (1) on a wide range of feature
representations, (2) with both balanced and imbalanced data, (3) for both single-layer and multi-layer
classifiers, (4) for both logistic and cosine classifiers, and (5) over multiple datasets and problems.
Importantly, we found Firth bias reduction to consistently yield statistically significant and positive
improvements, and we did not observe any performance penalty for utilizing it. Such improvements
are on the order of 0.5-2.5% and up to 3% in challenging tasks with large number of classes.
Our main contributions include (1) deriving a generalized expression for Firth bias reduction in few-
shot multinomial logistic regression models, and providing geometrical insight into its effect on the
classification probability space; (2) evaluating the efficacy of the Firth penalized multinomial logistic
model in few-shot scenarios, with both balanced and imbalanced data distributions; (3) showing that
Firth bias reduction can be extended beyond typical logistic models, and can be successfully adopted
in cosine classifiers; and (4) providing an empirical comparison of Firth bias reduction with common
regularizers such as L2 and label smoothing.
2 Background
Mathematical Notations: In this work, we assume a multinomial logistic regression model for the
classifier, with a total of J + 1 classes {0,1,2,…，J}. The logistic regression weights for class j
is denoted as βj (1 ≤ j ≤ J). The class j = 0 is the reference class with zero logistic regression
weights. We assume to have a total number of N samples D = {(χι,yι),…，(xn, yN)}. The ith
target yi is the one-hot encoding of the ith label. The assignment probability of the ith sample to class
j is denoted as Pi,j :
Pi,j := Pr(yi = j |xi )
(1)
The likelihood of the sample set D given the weights β is denoted as Pr(y|x; β):
NJ
Pr⑶x;β) = YX 1[yi = j] ∙pi,j,
i=1 j=1
(2)
where 1[∙] denotes the binary indicator function. Therefore, the logistic log-likelihood function
Llogistic is defined as
NJ
Llogistic := EE 1[yi =j] ∙lOg(Pij).
i=1 j=0
(3)
2
Published as a conference paper at ICLR 2022
①"E-M g Ue e W
0.70 -
0.65 -
0.60-
0.55 -
0.50 -
bias(BMLE) = ≡[‰le] - β
“、A∙
I E[βFirth]
中二''二
123456789 10
Sample Size (Λ∕)
-0.5
-°-5-0-5
LLNN
- - - -
ζlsso⅛o-
0.0	0.5	1.0	1.5	2.0
Iogi0(W)
E[Fmle1
Figure 1: The MLE bias and Firth bias reduction visualized in a geometric experiment. Here,
the task is to estimate the coin flip probability based upon the number of tosses until the first head
shows up. (Left) The average MLE (shown in blue) and the Firth bias-reduced estimator (shown
in red) against increasing number of samples. The true generative parameter β* = 0.5 is annotated
with a star, and the MLE bias is also visualized. The Firth bias-reduced estimator removes the
leading O(N -1) term from the MLE bias even with small N. (Right) To show that the MLE bias is
asymptotically of O(N-1), MLE bias is plotted against the sample size N in the log-log scale.
The Fisher Information Matrix (FIM) is defined as the Hessian of the negative log-likelihood function
Llogistic:
F := -HeSSe(Llogistic) = Ey [VβLlogistic "βL^gistiJ	(4)
The Maximum Likelihood Estimator (MLE) for logistic regression is defined as
A	Tl / I C'	/L、
βMLE := arg max Pr(y|x; β).	(5)
β
The dimension of the feature space is denoted as d in the derivations. U[a,b] denotes the (discrete)
uniform distribution in the [a, b] interval. The cross-entropy and the KL-divergence of distributions
p, q are defined as
CE(Pkq) = - Xp(χ) ∙iog(q(χ)),	DKL(Pkq)：= Xp(χ) ∙ log (Px))∙	⑹
Table A2 in the Appendix summarizes these notations.
SmaH-SamPle Bias ofMLE: Assume β* is the true generative parameter. When the sample size N is
small, it is shown that the MLE bias b(βMLE) ：= E[βMLE - β*] is non-zero and of O(N 1) (Cox and
Snell, 1968). Therefore, while MLE is unbiased as N → ∞, it is inaccurate for few-shot learning.
Firth Bias Reduction for MLE: Firth’s PMLE (Firth, 1993) is a modification to the ordinary MLE,
which removes the O(N -1) term from the small-sample bias. In particular, Firth has a simPlified
form for the exPonential family. When Pr(y|x; β) belongs to the exponential family of distributions,
the effect is to penalize the likelihood by Jeffrey’s invariant prior (Poirier, 1994), which is proportional
to the determinant of F (det(F)). Logistic and cosine classifiers (Chen et al., 2019) — the widely-used
classification models in few-shot learning - belong to the exponential family; so for them, Firth bias
reduction simplifies to adding a penalty (log(det(F))) to the cross-entropy loss. In what follows,
we will derive a further simplified yet effective Firth formulation for logistic and cosine classifiers,
which is computationally more efficient, deals with the case when det(F) = 0, and generalizes to
multinomial distributions.
MLE vs. Firth’s PMLE for a SimPle Case: To demonstrate the extent of the MLE bias and
how Firth’s PMLE removes the leading O(N-1) bias term, we simulated data from the geometric
distribution with probability of success β = 0.5 as its only parameter. The geometric experiment
was chosen since a closed-form solution for the MLE and Firth’s PMLE can be derived. Given the
samples (yι,…，yN) from the geometric distribution, the sample mean is y = N P yi and we have
8mle = y and βFirth = NNLII ∙ Note that since the sample mean is noisy, the MLE suffers from a
3
Published as a conference paper at ICLR 2022
•	F	∙	1 ∙	∙ , 1 ∙	F TΓ-<∙	1 1	, 1 , A	∙	1	, , 1	,	<1⅛ C
noisy denominator, making it biased. Figure 1 shows that /日曲 is close to the true parameter β* for
all sample sizes, whereas ∕mle has a significant bias away from β* for small N. To further validate
that the MLE bias is indeed of O(N -1), we plotted the MLE bias against the sample size in the
log-log scale in Figure 1, which shows that it is closely following a line with a negative unit slope.
3 Firth Bias Reduction in Logistic and Cosine Classifiers
In logistic models, the penalized likelihood function proposed by Firth is equivalent to imposing
Jeffreys’ prior (Poirier, 1994) on the parameters and making a maximum a posteriori estimation. In
particular, Firth bias reduction encourages models with “large” F by multiplying the likelihood by
det(F). This penalty degenerates when det(F) = 0. We work in the highest dimensional subspace
where F has full rank, and use det(F |r) to denote the product of all r non-zero eigenvalues of F,
obtaining
Pr(β∣x, y) = 1 ∙ Pr(y∣x; β) ∙ det(F|r)1/2,	(7)
Z
where Z is a normalization constant and det(F |r)1/2 is the Jeffery’s prior. Taking the log of both
sides yields the log-posterior as a sum of the logistic log-likelihood function and the Firth bias
reduction term:
L := lθg(Pr(β∣X,y)) = Llogistic + LFirth,	(8)
where we have
LFirth ：= 2 log(det(F|r)) + cte.	(9)
The definition of LFirth was left ambiguous up to a constant with respect to β to facilitate the Firth bias
reduction term’s interpretation and avoid the definition of similar terms. Furthermore, λ controls for
the impact of the Firth term on the outcome relative to Llogistic. We then apply a series of derivation
steps to simplify Equation (9), which are left to Section A in the Appendix. Finally, the Firth bias
reduction term can be expressed as
LFirth = λ ∙ N X 忙(β∣Xi- log X ej0 Xi)
i=1 j=0	j0=0
1N J
λ N∑[∑iog(Pi,j)
(10)
For the cosine classifier, the proof that log(det(F)) simplifies to Equation (10) involves straightfor-
ward manipulation of the proof for the logistic classifier, and is left to Section B in the Appendix. The
normalization of the βj weights in the cosine classifier turns into a pure scale term in the optimization,
and for a cosine classifier, scaling of the βj weights does not affect predictions. Therefore, this term
should be ignored, and the bias reduction term effectively becomes the same as Equation (10).
Interpreting the Firth Bias Reduction for Logistic Models: It is well known that Jeffery’s prior
shrinks the parameter estimates towards zero, which is equivalent to encouraging uniform class
assignment probabilities (Firth, 1993; Bull et al., 2002). We take an alternative approach to reach the
same conclusion in the following. By re-arranging Equation (10), one can see the PjJ=0 log(Pi,j)
term as a scaled average over a uniform distribution of classes:
1 N J
LFirth 8 N X	X
i=1 j=0
1N
• log(Pi,j) = N X CE(U[0,川旧).
(11)
i=1
N
J
1
J + 1
N
Therefore, we can abuse the notation, and redefine the coefficient λ and the constant to have
-1 N
LFirth = λ ∙ NE DKL(U[0J] kPi) + cte.	(12)
i=1
This means that by dropping the constants, the optimization objective L can be rewritten as
1N
L = =N X CE(yi∣∣Pi) + λ ∙ DKL(U[oj]kPi) .	(13)
i=1
4
Published as a conference paper at ICLR 2022
Since the KL-divergence and the FIM define an information geometry and a Riemanian metric on
probabilistic measure spaces (Nielsen, 2020), a geometrical insight into Equation (13) is provided in
Figure A5 in the Appendix as well.
Firth Bias Reduction vs. Common Regularization: While this insight brings Firth bias reduction
closer to the common regularization techniques (e.g., L2-regularization), it is worth noting that (1)
common regularization techniques mainly focus on controling model complexity, instead of reducing
small-sample estimation bias; (2) Firth bias reduction operates on a much lower-dimensional target
distribution space, unlike L2 which operates in the high-dimensional parameter space; (3) Firth uses
the same kind of metric as the logistic loss; and (4) Firth bias reduction is dimensionally consistent
like the Natural Gradients (Amari, 1998; Pascanu and Bengio, 2013), whereas L2 is not.
Firth Bias Reduction vs. Label Smoothing: Notice that the original form of label smoothing used
for training in large-sample regimes (Szegedy et al., 2016) has the same formulation as the simplified
Firth penalty term in Equation (12) for multinomial logistic classifiers. However, Firth bias reduction
is inherently different in that it reduces the classifier estimation bias in the small-sample regimes,
whereas label smoothing penalizes over-confident predictions when training deep neural networks
with large amounts of samples. Generally, the Firth bias reduction term (i.e., log(det(F))) is not the
same as the label smoothing penalty (i.e., DKL(UkPi)) for deep neural networks. Additional analysis
and empirical comparisons are provided in Section 4.4 and Section G in the Appendix.
4 Experimental Results
Here we show that for a wide range of experiments, Firth bias reduction is a reliable source of small yet
useful improvements in the performance. Since we report improvements for a wide range of methods
and settings, the absolute accuracy improvements were reported. These absolute improvements
sometimes constitute significantly to the baseline accuracy in terms of relative importance.
Datasets: We perform experiments on four widely-used and publicly available benchmarks: mini-
ImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), tiered-ImageNet (Ren et al.,
2018), and CUB (Wah et al., 2011). Each dataset consists of non-overlapping base, validation, and
novel classes. The detailed class splits are described in Section D in the Appendix. Following the
standard practice (Chen et al., 2019), we train feature backbones on base classes, cross-validate
bias reduction coefficients on validation classes, and train classifiers and measure test accuracy over
multiple trials on novel classes.
Implementation Details: Details regarding the setup, implementation, statistical significance, and
reducing the effect of randomized factors are covered in Appendix Section D.
Baselines and Evaluation Metric: Non-penalized classifiers are used as the baseline in all exper-
iments to compare Firth bias reduction and L2-regularization. Absolute accuracy improvements
over the baseline averaged across multiple trials are used as the evaluation metric in all experiments.
Relative improvements are also shown in the Appendix, which demonstrate similar behaviors.
Summary of Results: Section 4.1 shows the efficacy of Firth bias reduction on standard feature
backbones (ResNets with varying depth) and single-layer logistic classifiers. Section 4.2 shows and
argues that Firth bias reduction outperforms L2-regularization on few-shot classification tasks. Next,
we investigate the driving factor in Firth’s improvement in Section 4.3, and show evidence for the
efficacy of Firth’s bias suppression property. We also show that Firth bias reduction can be effectively,
and without any modifications, applied to imbalanced data distribution settings. Section 4.4 com-
pares Firth bias reduction against label smoothing variants, and shows that Firth outperforms label
smoothing. In Section 4.5 Firth bias reduction is applied to modern few-shot methods with advanced
feature backbones (i.e., WideResNet trained with strong regularization (Mangla et al., 2020)) and
cosine classifiers. Experiments with additional feature backbones (DenseNet and MobileNet (Wang
et al., 2019)) are included in Appendix Section F. Finally, Section 4.6 demonstrates that Firth bias
reduction produces reliable improvements over the state-of-the-art feature calibration method (Yang
et al., 2021). Our collective results clearly indicate a consistent pattern of improvements over a large
array of (1) feature representations, (2) datasets, (3) classification ways, (4) number of shots, (5)
types of classifiers, and (6) with both balanced and imbalanced data distributions.
5
Published as a conference paper at ICLR 2022
Firth Bias Reduction
2.5 -
2.0-
ResNetlO
ResNetl8
ResNet34
ResNetSO
ResNetlOl
叁 1.5 -
8
S l.o-
<
0.5 -
0.0-
x+x
0.0
2.5
2.0
界1∙5
8
S l.o
V
0.5
L2 Regularization
-φ- ResNetlO
T- ResNetl8
—φ- ResNet34
—ResNetSO
-♦- ResNetlOl
Il	I	I	I	I	Il	I	I	I	I
1	5	10	15	20	25	1	5	10	15	20	25
Number of Shots	Number of Shots
Figure 2: Firth bias reduction produces statistically significant improvements over a wide range
of backbone architectures and number of shots, whereas the common L2-regularization cannot.
Firth bias reduction (left) delivers a novel class accuracy improvement over the baseline classifier
with an order of around 0.5-2.5%. By contrast, L2-regularization (right) is mostly statistically
insignificant in the same setting. 16-way logistic classification on the mini-ImageNet dataset was
conducted in this experiment, with over 800 randomized and matching trials for each combination
of method, backbone, and number of samples, and the confidence intervals are covered by the blobs.
Absolute and delta accuracies are provided in Table A9. The same experiments were repeated with a
3-layer classifier instead of a 1-layer classifier in Figure A7 in the Appendix and show similar results.
4.1	Firth Bias Reduction Improves the Accuracy of Logistic Classifiers
Figure 2 summarizes the results. For all the k-shot tasks and backbones, the average absolute test
accuracy improvement is significant and it increases as k increases. Also, Firth bias reduction does not
hurt the 1- and 5-shot performance, with slight improvements for some backbones. Extra experiments
are included in Appendix Section E.1.
4.2	L2-Regularization is not as Effective as Firth Bias Reduction
To explore whether the performance improvement pattern for Firth bias reduction can be reproduced
by common regularization techniques such as L2, the same experiments were repeated with L2-
regularized logistic classifiers. For almost all the k-shot tasks and feature backbones, the average
absolute test accuracy improvement is close to zero, as shown in Figure 2. This suggests that the bias
reduction property of Firth plays a significant part in improving the classifier’s performance in the
few-shot regime which cannot be achieved by L2-regularization.
4.3	Bias or Prior?
Firth bias reduction clearly helps. It may be doing so because it is an effective way of suppressing bias.
Alternatively, reinforcing the prior information might be helping. This section offers evidence that
bias suppression is what is important. We consider data where the class frequencies are imbalanced.
We apply a variant of Firth bias reduction that uses class prior frequencies to this data. This variant is
not as successful as routine Firth bias reduction, suggesting that bias correction is what is important.
One might consider replacing the uniform distribution in the Firth prior with a class probability
distribution. That is, replacing LFirth = -λ ∙ DKL(U[0,j] ∣∣Pi) by LFirth = -λ ∙ DKL(AkPi) with A
being the imbalanced class distribution, when training a Firth penalized few-shot logistic classifier.
To test this, we designed two schemes to generate imbalanced datasets. These schemes differ in
the imbalanced count vectors used to create the few-shot dataset in validation and novel splits. The
increments in the counts per class were designed to result in two different average counts of 7.5
(Scheme 1) and 15 (Scheme 2) over the classes (experimental details are left to Section D in the
Appendix). For each scheme, the experiments were carried out similar to the “balanced few-shot” case
on mini-ImageNet, except that in each trial three classifiers 一(1) baseline (not penalized), (2) Firth
penalized (KL with the uniform prior), and (3) modified Firth penalized (KL with the imbalanced
6
Published as a conference paper at ICLR 2022
Figure 3: Penalizing KL to the imbalanced class distribution is worse than using the Firth
bias reduction. The accuracy improvement is compared (1) when DKL(UkPi) is penalized (i.e.,
the blue bars with the uniform prior label) vs. (2) when the KL divergence to the imbalanced class
distribution A (i.e., DKL(AkPi)) is penalized (i.e., the red bars with the non-uniform prior label).
The left and right plots use a class distribution with an average of 7.5 and 15 shots, respectively.
The range of shots vary from 2- to 16-shots in the left plot, and from 1- to 29-shots in the right plot.
The difference of accuracy improvements between the uniform and the non-uniform priors is more
striking for the 7.5-average-shot case, which suffers from a greater deal of estimation bias than the
15-average-shot scenario. This shows that the improvements of Firth bias reduction are driven
by its bias suppression property, and are not a mere consequence of imposing a uniform class
prior. The same experiments were repeated with a 3-layer classifier in Figure A10 in the Appendix.
prior) - were trained. In both schemes, the improvement achieved by the Firth penalized classifier
is higher than that of the modified Firth penalized classifier over the baseline for all backbones, as
shown in Figure 3. The difference between the two improvements is more substantial in Scheme 1,
where the average of samples per class is less than Scheme 2. This implies that the Firth penalized
classifier is indeed reducing the bias and should not be naively considered as if a prior is simply
defined over the class assignment probabilities.
4.4	Firth Bias Reduction Improves Over Label Smoothing
Even though the original version of label smoothing (Szegedy et al., 2016) has the same formulation
as the Firth bias reduction term in Equation (13), there is a family of label smoothing techniques
that aim to reduce overfitting and over-confident predictions (Pereyra et al., 2017). Namely, the
confidence penalty (i.e., regularizing DKL(PikU)) and unigram label smoothing (i.e., regluarizing the
KL-divergence with class priors) are two label smoothing variants, which are shown to outperform the
original label smoothing, when training complex networks with large amounts of samples (Pereyra
et al., 2017). Figure 3 shows that Firth bias reduction outperforms unigram label smoothing, and
Table A4 in the Appendix shows that Firth bias reduction yields better results than applying confidence
penalty and entropy regularization. This further suggests that the improvements obtained by Firth are
the result of its bias reduction property.
4.5	Firth Bias Reduction Improves the Performance of Cosine Classifiers
As cosine classifiers have recently proven to be useful for few-shot classification (Gidaris and
Komodakis, 2018; Chen et al., 2019), we investigated the impact of Firth bias reduction on them.
The difference between a logistic and cosine classifier parameter space is that the parameter space of
the cosine classifier is constrained to a unit sphere, therefore it is likely for the Firth bias reduction
to improve cosine classifier performance as well. To test this, we based our experiments on the
implementation of the S2M2R method (Mangla et al., 2020), and used their pre-trained WideResNet-
28-10 (Zagoruyko and Komodakis, 2016) on the base classes as a strong feature extractor. We trained
Firth penalized and non-penalized cosine classifiers on the mini-ImageNet, tiered-ImageNet, and
CIFAR-FS datasets. Few-shot classifiers were trained for varying number of classes, depending on
7
Published as a conference paper at ICLR 2022
mιnι-lmaqeNet
O O
3 2
%(8v
CIFAR-FS
求 Gusv
3.00-
2.00-
1.00-
5	10	15	20	5	10	15	20
NumberofCIasses	Number of Classes
tiered-lmageNet
0∞-....	.	.
5 1015 20	50	100
Number OfCIasses
150
Figure 4: Firth bias reduction consistently improves the accuracy of the cosine classifier (a
better few-shot classifier) in the presence of strong backbone features, regardless of (1) the
type of dataset, and (2) the number of classes in few-shot classification. For each dataset, an
advanced backbone architecture (WideResNet-28-10) with strong mixup regularization and self-
supervision was trained. The error bars are almost non-existent (i.e., less than 0.02%), since over
10,000 trials with matching randomization factors were performed for each point. Firth bias
reduction improvements are always positive, and it never hurts to use the Firth bias reduction
technique. Absolute and delta accuracies are provided in Tables A6, A7, and A8 in the Appendix.
the dataset, and varying number of samples per class. We followed the same scheme as Mangla et al.
(2020) to generate the k-shot support and query datasets for training and testing, respectively.
As shown in Figure 4, in all datasets, Firth bias reduction improves the performance of 5- and 10-shot
tasks in a monotonically increasing fashion with respect to the number of classes. This behavior is
well represented for tiered-ImageNet, as increasing 5-way to 150-way classification results in more
than 2.5% improvement of the average test accuracy. In the 1-shot task, the improvement by Firth
bias reduction is monotonically decreasing with the number of classes in all the datasets except tiered-
ImageNet, but it does not hurt the performance. The improvement almost falls within (0.1%-0.5%),
(0-0.1%), and (0-0.2%), for mini-ImageNet, CIFAR-FS, and tiered-ImageNet, respectively.
This experiment suggests that not only is Firth bias reduction effective for cosine classifiers, but it
also could help with the performance even when strong features are used. This is well justified as
Firth bias reduction targets the bias introduced in the classifier parameters not the features.
4.6	Comparison with Additional State-of-the-Art Method
We further applied the Firth bias reduction term to the recent state-of-the-art method in few-shot
classification (Yang et al., 2021), called Distribution Calibration (DC). DC computes the closest
base classes to each sample in the feature space, and samples artificial examples from a Gaussian
distribution centered around the mean of the closest base class features. To make the setup challenging,
we consider data where the base classes are categorically different from the novel classes: i.e., by
performing cross-dataset few-shot classification, where the features are trained on the base classes of
mini-ImageNet or tiered-ImageNet, and the novel sets are instead sampled from the CUB dataset.
The results are shown in Table 1, and indicate that the Firth bias reduction improves over Yang
et al. (2021). We also show the Firth bias reduction improvements on the tiered-ImageNet dataset in
8
Published as a conference paper at ICLR 2022
mini-ImageNet → CUB					tiered-ImageNet → CUB		
Way	Shot	Before	After	Improvement	Before	After	Improvement
10	1	37.14	37.40 ± 0.13	0.26 ± 0.03	64.36	64.52 ± 0.16	0.15 ± 0.04
10	5	59.77	60.77 ± 0.12	1.00 ± 0.04	86.23	86.66 ± 0.10	0.43 ± 0.02
15	1	30.22	30.37 ± 0.09	0.15 ± 0.03	57.73	57.74 ± 0.13	0.01 ± 0.01
15	5	52.73	53.84 ± 0.10	1.12 ± 0.03	82.16	83.05 ± 0.09	0.90 ± 0.02
Table 1: The cross-domain experiments for the DC method with and without Firth bias reduction.
The columns containing the novel set accuracy obtained by DC and Firth penalized DC methods are
tagged Before and After, respectively. Each setting (a combination of way, shot, and method) was
tested with and without data augmentation (addition of 750 samples), and the maximum accuracy was
reported. Note that the confidence intervals are much smaller for the improvement column, thanks to
the random-effect matching procedure we used in this study. The Before confidence intervals were
similar to the After confidence intervals, and thus not repeated due to space constraints.
Appendix Section H and Table A5. This further supports the observation that Firth bias reduction
yields small but reliable improvements under different methods.
5	Related Work
Bias Reduction of the MLE: A myriad of statistical work has been proposed to mitigate the small-
sample bias of the MLE under different settings (Anderson and Richardson, 1979; Kenward and
Roger, 1997; Bull et al., 2002; Kosmidis and Firth, 2009). Originally, the asymptotic bias of MLE was
shown to be of O(N -1), with N being the sample size (Firth, 1993). To counter such an estimation
bias, many approaches have existed. To name a few, (1) additive penalization terms to the main
logistic loss were proposed to reduce the MLE’s bias (Firth, 1993; Bull et al., 2002; Greenland and
Mansournia, 2015), and (2) some methods have been proposed to directly approximate and remove
such a small sample bias (Cox and Hinkley, 1979). While the latter approach may sound appealing,
estimating the MLE’s bias can be impractical. For instance, in few-shot scenarios, a perfect separation
of the classes may be achievable, causing the logistic MLE to be unbounded (Heinze and Schemper,
2002). On the other hand, the penalization methods do not modify the estimated parameters directly,
and instead gently push for a preference towards less biased estimates. Such penalization methods
can be generally applicable to a vast array of models.
Theoretically, Firth’s PMLE reduces the bias by removing the leading O(N-1) term from the MLE’s
bias (Firth, 1993) - a property that does not exist in common regularization techniques such as
L2-regularization. Furthermore, PMLE of the logistic model has been shown to have smaller variance
than MLE as well (Copas, 1988; Kosmidis and Firth, 2009). Firth’s PMLE has been well studied for
binomial logistic regression (Firth, 1993), and applied and tested against other penalization techniques
in other fields (Rainey and McCaskey, 2015; Muchlinski et al., 2016; Rahman and Sultana, 2017).
Additional related work on few-shot image classification was left to Appendix Section C.
6	Conclusion
We show that Firth bias reduction consistently improves the accuracy across the board in few-shot
classification regardless of (1) the employed feature backbone, (2) the number of classes and samples,
and (3) the dataset and problem setting. Furthermore, our experiments show that Firth bias reduction
can improve the performance of the cosine classifiers, and is applicable to imbalanced and cross-
domain few-shot settings without any necessary modifications. Overall, our evaluations suggest that
Firth bias reduction is a useful and general bias reduction tool that has been missing in few-shot
classification, and should be incorporated in few-shot classification tasks for accuracy improvements.
9
Published as a conference paper at ICLR 2022
7	Acknowledgment
This work was supported in part by (1) the National Science Foundation’s Major Research Instru-
mentation program (Kindratenko et al., 2020), grant number 1725729, (2) the National Science
Foundation’s Creating Knowledge with All-Novel-Class Computer Vision program, grant number
2106825, and (3) the Jump ARCHES endowment through the Health Care Engineering Systems
Center. The majority of NSF funding contributions were designated to Ehsan Saleh and Saba Ghaffari
equally in the form of computational resource allocations on high-performance computing platforms
for conducting the experiments. Overall, this work consumed more than 32 CPU years and one
Nvidia V-100 GPU year from the NSF-funded resource allocations in the course of its analysis. Also,
this work made use of the Illinois Campus Cluster, a computing resource that is operated by the
Illinois Campus Cluster Program (ICCP) in conjunction with the National Center for Supercomputing
Applications (NCSA) and is supported by funds from the University of Illinois Urbana-Champaign.
References
K. R. Allen, E. Shelhamer, H. Shin, and J. B. Tenenbaum. Infinite mixture prototypes for few-shot
learning. In ICML, 2019. 21
S.-I. Amari. Natural gradient works efficiently in learning. Neural computation, 10(2):251-276,
1998. 5
J. Anderson and S. Richardson. Logistic discrimination and bias correction in maximum likelihood
estimation. Technometrics, 21(1):71-78, 1979. 9
M. Andrychowicz, M. Denil, S. Gomez, M. W. Hoffman, D. Pfau, T. Schaul, B. Shillingford, and
N. De Freitas. Learning to learn by gradient descent by gradient descent. In NeurIPS, 2016. 21
J. Baxter. A Bayesian/information theoretic model of learning to learn via multiple task sampling.
Machine Learning, 28(1):7-39, 1997. 21
S. Bengio, Y. Bengio, J. Cloutier, and J. Gescei. On the optimization of a synaptic learning rule. In
Optimality in Biological and Artificial Networks?, pages 281-303. 2013. 21
L. Bertinetto, J. F. Henriques, J. Valmadre, P. Torr, and A. Vedaldi. Learning feed-forward one-shot
learners. In NeurIPS, 2016. 21
L.	Bertinetto, J. F. Henriques, P. H. Torr, and A. Vedaldi. Meta-learning with differentiable closed-
form solvers. In ICLR, 2019. 5
M.	Box. Bias in nonlinear estimation. Journal of the Royal Statistical Society: Series B (Methodolog-
ical), 33(2):171-190, 1971. 1
S. B. Bull, C. Mak, and C. M. Greenwood. A modified score function estimator for multinomial
logistic regression in small samples. Computational Statistics and Data Analysis, 39(1):57-74,
2002. 4, 9
W.-Y. Chen, Y.-C. Liu, Z. Kira, Y.-C. F. Wang, and J.-B. Huang. A closer look at few-shot classifica-
tion. In ICLR, 2019. 1, 2, 3, 5,7, 21
J. B. Copas. Binary regression models for contaminated data. Journal of the Royal Statistical Society:
Series B (Methodological), 50(2):225-253, 1988. 9
G. M. Cordeiro and P. McCullagh. Bias correction in generalized linear models. Journal of the Royal
Statistical Society: Series B (Methodological), 53(3):629-643, 1991. 2
D. R. Cox and D. V. Hinkley. Theoretical statistics. CRC Press, 1979. 9
D. R. Cox and E. J. Snell. A general definition of residuals. Journal of the Royal Statistical Society.
Series B (Methodological), 30(2):248-275, 1968. 1, 3
G. S. Dhillon, P. Chaudhari, A. Ravichandran, and S. Soatto. A baseline for few-shot image
classification. In ICLR, 2020. 21
10
Published as a conference paper at ICLR 2022
M.	Douze, A. Szlam, B. Hariharan, and H. J6gou. Low-shot learning with large-scale diffusion. In
CVPR, 2018. 21
N.	Dvornik, C. Schmid, and J. Mairal. Diversity with cooperation: Ensemble methods for few-shot
classification. In ICCV, 2019. 21
N. Dvornik, C. Schmid, and J. Mairal. Selecting relevant features from a multi-domain representation
for few-shot classification. In ECCV, 2020. 21
H. Edwards and A. Storkey. Towards a neural statistician. In ICLR, 2017. 21
L. Fahrmeir and H. Kaufmann. Consistency and asymptotic normality of the maximum likelihood
estimator in generalized linear models. TheAnnalsofStatistics, 13(1):342-368, 1985. 1
L. Fei-Fei, R. Fergus, and P. Perona. One-shot learning of object categories. IEEE TPAMI, 28(4):
594-611, 2006. 1,20
C. Finn, P. Abbeel, and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks.
In ICML, 2017. 1, 20, 21
C.	Finn, K. Xu, and S. Levine. Probabilistic model-agnostic meta-learning. In NeurIPS, 2018. 21
D.	Firth. Bias reduction of maximum likelihood estimates. Biometrika, 80(1):27-38, 1993. 1, 2, 3, 4,
9, 15
D.	George, W. Lehrach, K. Kansky, M. Lazaro-Gredilla, C. Laan, B. Marthi, X. Lou, Z. Meng, Y. Liu,
H. Wang, A. Lavin, and D. S. Phoenix. A generative vision model that trains with high data
efficiency and breaks text-based CAPTCHAs. Science, 358(6368):eaag2612, 2017. 21
S. Gidaris and N. Komodakis. Dynamic few-shot visual learning without forgetting. In CVPR, 2018.
7, 21
S. Gidaris, A. Bursuc, N. Komodakis, P. Perez, and M. Cord. Boosting few-shot visual learning with
self-supervision. In ICCV, 2019. 1
S. Greenland and M. A. Mansournia. Penalization, bias reduction, and default priors in logistic and
related categorical and survival regressions. Statistics in Medicine, 34(23):3133-3143, 2015. 9
L. Gui, A. Bardes, R. Salakhutdinov, A. Hauptmann, M. Hebert, and Y.-X. Wang. Learning to
hallucinate examples from extrinsic and intrinsic supervision. In ICCV, 2021. 21
B. Hariharan and R. Girshick. Low-shot visual recognition by shrinking and hallucinating features.
In ICCV, 2017. 20
D. A. Harville. Matrix algebra from a statistician’s perspective. Technometrics, 40(2):164, 1998. 17
K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016.
21
G. Heinze and M. Schemper. A solution to the problem of separation in logistic regression. Statistics
in Medicine, 21(16):2409-2419, 2002. 9
M. G. Kenward and J. H. Roger. Small sample inference for fixed effects from restricted maximum
likelihood. Biometrics, 53(3):983-997, 1997. 9
V. Kindratenko, D. Mu, Y. Zhan, J. Maloney, S. H. Hashemi, B. Rabe, K. Xu, R. Campbell, J. Peng,
and W. Gropp. HAL: Computer system for scalable deep learning. In Practice and Experience in
Advanced Research Computing, pages 41-48. 2020. 10
G. Koch, R. Zemel, and R. Salakhudtinov. Siamese neural networks for one-shot image recognition.
In ICML Deep Learning Workshop, 2015. 21
I.	Kosmidis and D. Firth. Bias reduction in exponential family nonlinear models. Biometrika, 96(4):
793-804, 2009. 9
11
Published as a conference paper at ICLR 2022
A.	Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. 2009. 21
B.	M. Lake, R. Salakhutdinov, and J. B. Tenenbaum. Human-level concept learning through proba-
bilistic program induction. Science, 350(6266):1332-1338, 2015. 20
H. Li, W. Dong, X. Mei, C. Ma, F. Huang, and B.-G. Hu. LGM-Net: Learning to generate matching
networks for few-shot learning. In ICML, 2019a. 21
H. Li, D. Eigen, S. Dodge, M. Zeiler, and X. Wang. Finding task-relevant features for few-shot
learning by category traversal. In CVPR, 2019b. 21
Z. Li, F. Zhou, F. Chen, and H. Li. Meta-SGD: Learning to learn quickly for few-shot learning. arXiv
preprint arXiv:1707.09835, 2017. 21
Y. Lifchitz, Y. Avrithis, S. Picard, and A. Bursuc. Dense classification and implanting for few-shot
learning. In CVPR, 2019. 21
B. Liu, Y. Cao, Y. Lin, Q. Li, Z. Zhang, M. Long, and H. Hu. Negative margin matters: Understanding
margin in few-shot classification. In ECCV, 2020. 2
L. Liu, W. Hamilton, G. Long, J. Jiang, and H. Larochelle. A universal representation transformer
layer for few-shot image classification. In ICLR, 2021. 21
P. Mangla, N. Kumari, A. Sinha, M. Singh, B. Krishnamurthy, and V. N. Balasubramanian. Charting
the right manifold: Manifold mixup for few-shot learning. In WACV, 2020. 1, 5, 7, 8, 22, 23
E. G. Miller, N. E. Matsakis, and P. A. Viola. Learning from one example through shared densities
on transforms. In CVPR, 2000. 20
N. Mishra, M. Rohaninejad, X. Chen, and P. Abbeel. A simple neural attentive meta-learning. In
ICLR, 2018. 21
D. Muchlinski, D. Siroky, J. He, and M. Kocher. Comparing random forest with logistic regression
for predicting class-imbalanced civil war onset data. Political Analysis, 24(1):87-103, 2016. 9
T. Munkhdalai and H. Yu. Meta networks. In ICML, 2017. 21
A.	Nichol and J. Schulman. Reptile: A scalable metalearning algorithm. arXiv preprint
arXiv:1803.02999, 2018. 21
F. Nielsen. An elementary introduction to information geometry. Entropy, 22(10):1100, 2020. 5
B.	Oreshkin, P. R. L6pez, and A. Lacoste. TADAM: Task dependent adaptive metric for improved
few-shot learning. In NeurIPS, 2018. 21
R. Pascanu and Y. Bengio. Revisiting natural gradient for deep networks. arXiv preprint
arXiv:1301.3584, 2013. 5
G. Pereyra, G. Tucker, J. Chorowski, L. Kaiser, and G. Hinton. Regularizing neural networks by
penalizing confident output distributions. In ICLR, 2017. 7, 26
T. Pfister, J. Charles, and A. Zisserman. Domain-adaptive discriminative one-shot learning of gestures.
In ECCV, 2014. 1
C.	P. Phoo and B. Hariharan. Self-training for few-shot transfer across extreme task differences. In
ICLR, 2021. 21
D.	Poirier. Jeffreys’ prior for logit models. Journal of Econometrics, 63(2):327-339, 1994. 2, 3, 4
H. Qi, M. Brown, and D. G. Lowe. Low-shot learning with imprinted weights. In CVPR, 2018. 21
S. Qiao, C. Liu, W. Shen, and A. L. Yuille. Few-shot image recognition by predicting parameters
from activations. In CVPR, 2018. 21
12
Published as a conference paper at ICLR 2022
M. S. Rahman and M. Sultana. Performance of Firth-and logF-type penalized methods in risk
prediction for small or sparse binary data. BMC Medical Research Methodology, 17(1):1-15, 2017.
9
C. Rainey and K. McCaskey. Estimating logit models with small samples. Political Science Research
and Methods, 2015. 9
S. Ravi and H. Larochelle. Optimization as a model for few-shot learning. In ICLR, 2017. 21
M. Ren, E. Triantafillou, S. Ravi, J. Snell, K. Swersky, J. B. Tenenbaum, H. Larochelle, and R. S.
Zemel. Meta-learning for semi-supervised few-shot classification. In ICLR, 2018. 5, 21
O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla,
M. Bernstein, et al. ImageNet large scale visual recognition challenge. IJCV, 115(3):211-252,
2015. 21
A. A. Rusu, D. Rao, J. Sygnowski, O. Vinyals, R. Pascanu, S. Osindero, and R. Hadsell. Meta-learning
with latent embedding optimization. In ICLR, 2019. 1, 21
E. Saleh, S. Ghaffari, D. Forsyth, and Y.-X. Wang. Dataset for on the importance of Firth bias
reduction in few-shot classification, 2022. URL https://doi.org/10.13012/B2IDB-
1016367_V1. 23
A. Santoro, S. Bartunov, M. Botvinick, D. Wierstra, and T. Lillicrap. One-shot learning with
memory-augmented neural networks. In ICML, 2016. 20
R. L. Schaefer. Bias correction in maximum likelihood logistic regression. Statistics in Medicine, 2
(1):71-78, 1983. 1
J. Schmidhuber. Evolutionary principles in self-referential learning. On learning how to learn: The
meta-meta-... hook. Diploma thesis, Institut f. Informatik, Tech. Univ. Munich, 1987. 21
J. Schmidhuber, J. Zhao, and M. Wiering. Shifting inductive bias with success-story algorithm,
adaptive Levin search, and incremental self-improvement. Machine Learning, 28(1):105-130,
1997. 21
J. Snell, K. Swersky, and R. S. Zemel. Prototypical networks for few-shot learning. In NeurIPS,
2017. 1, 20, 21
E.	W. Steyerberg, M. J. Eijkemans, and J. D. F. Habbema. Stepwise selection in small data sets: a
simulation study of bias in logistic regression analysis. Journal of Clinical Epidemiology, 52(10):
935-942, 1999. 2
F.	Sung, Y. Yang, L. Zhang, T. Xiang, P. H. S. Torr, and T. M. Hospedales. Learning to compare:
Relation network for few-shot learning. In CVPR, 2018. 21
C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture
for computer vision. In CVPR, 2016. 2, 5, 7, 26
S. Thrun. Lifelong learning algorithms. Learning to learn, 8:181-209, 1998. 21
Y. Tian, Y. Wang, D. Krishnan, J. B. Tenenbaum, and P. Isola. Rethinking few-shot image classifica-
tion: A good embedding is all you need? In ECCV, 2020. 1, 21
E. Triantafillou, R. Zemel, and R. Urtasun. Few-shot learning through an information retrieval lens.
In NeurIPS, 2017. 21
E. Triantafillou, T. Zhu, V. Dumoulin, P. Lamblin, K. Xu, R. Goroshin, C. Gelada, K. Swersky, P.-A.
Manzagol, and H. Larochelle. Meta-dataset: A dataset of datasets for learning to learn from few
examples. In ICLR, 2020. 21
V. Verma, A. Lamb, C. Beckham, A. Najafi, I. Mitliagkas, D. Lopez-Paz, and Y. Bengio. Manifold
mixup: Better representations by interpolating hidden states. In ICML, 2019. 1
13
Published as a conference paper at ICLR 2022
O. Vinyals, C. Blundell, T. P. Lillicrap, K. Kavukcuoglu, and D. Wierstra. Matching networks for
one shot learning. In NeurIPS, 2016. 1, 5, 20, 21
C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. The Caltech-UCSD Birds-200-2011
Dataset. Technical Report CNS-TR-2011-001, California Institute of Technology, 2011. 5
Y. Wang, W.-L. Chao, K. Q. Weinberger, and L. van der Maaten. Simpleshot: Revisiting nearest-
neighbor classification for few-shot learning. arXiv preprint arXiv:1911.04623, 2019. 5, 25
Y. Wang, Q. Yao, J. T. Kwok, and L. M. Ni. Generalizing from a few examples: A survey on few-shot
learning. ACM Computing Surveys (CSUR), 53(3):1-34, 2020.1
Y.-X. Wang and M. Hebert. Learning to learn: Model regression networks for easy small sample
learning. In ECCV, 2016. 1, 20, 21
Y.-X. Wang, D. Ramanan, and M. Hebert. Learning to model the tail. In NeurIPS, 2017. 21
Y.-X. Wang, R. Girshick, M. Hebert, and B. Hariharan. Low-shot learning from imaginary data. In
CVPR, 2018. 21
J. Whitehead. On the bias of maximum likelihood estimation following a sequential test. Biometrika,
73(3):573-581, 1986. 1
S. Yang, L. Liu, and M. Xu. Free lunch for few-shot learning: Distribution calibration. In ICLR,
2021. 5, 8, 21, 22, 23, 24, 27
H.-J. Ye, H. Hu, D.-C. Zhan, and F. Sha. Few-shot learning via embedding adaptation with set-to-set
functions. In CVPR, 2020. 21
S. W. Yoon, J. Seo, and J. Moon. TapNet: Neural network augmented with task-adaptive projection
for few-shot learning. In ICML, 2019. 21
S. Zagoruyko and N. Komodakis. Wide residual networks. In BMVC, 2016. 7, 22
C. Zhang, Y. Cai, G. Lin, and C. Shen. DeepEMD: Few-shot image classification with differentiable
earth mover’s distance and structured classifiers. In CVPR, 2020. 21
X. Zhang, D. Meng, H. Gouk, and T. M. Hospedales. Shallow Bayesian meta learning for real-world
few-shot recognition. In ICCV, 2021. 21
14
Published as a conference paper at ICLR 2022
A Firth Bias Reduction for Few- S hot Multinomial Logistic
Regression
Table A2 summarizes the notations used throughout the main paper and here. Given a dataset of N
samples D = {(χι, yι), (χ2,y2), ∙∙∙ , (XN, yN)}, the multinomial logistic model for a total of J + 1
classes can be formulated as
PKy =j E) ] = β∣x
Pr(y = 0∣Xi) = βj xi,
j ∈ {1,2,…，J},
(A14)
where class j = 0 was chosen as the reference class in the log odds ratio. In other words, w.l.o.g. we
assume β0 = 0 in this formulation. Given the decision rule in Equation (A14), we can write
_	1
Pi,0	1 + PJ0=1 eβj0 Xi
eβ∣xi
Pij=	J 亨	∀1 ≤ j ≤ J. (A15)
1 + PjJ0=1 eβj0 xi
Under this notation, the log-likelihood would be LlogiStiC = PN=I PJ=0 1[yi = j] ∙ log(Pi,j). The
data matrix XD is given as
XD ：= [x1 x2 …XN]d×N
(A16)
Also, X := XD 0 Ij where the 0 operator denotes the Kronecker matrix product, and the J-
dimensional identity matrix is denoted as IJ .
Firth (1993) has established that the bias of logistic regression can be removed by maximizing the
sum of (1) the log-likelihood Llogistic and (2) the log-determinant of the Fisher Information Matrix
(FIM). For our purposes, this presents some challenges: we have a few number of samples and the
FIM determinant is zero. Instead, we use the product of all non-zero eigenvalues of the FIM as its
“amended determinant”. To obtain this efficiently, we need to know the specific structure of the FIM.
It is important in what follows that the FIM can be defined as the matrix product
F(dJ)×(dJ) = XIdJ)×(nj) ∙ M(NJ)×(NJ) ∙ X(NJ)×(dJ),	(A17)
where M is a block-diagonal matrix whose ith diagonal block is denoted as Mi . We leave the
definition ofX and Mi to the “FIM Formulation for Logistic Regression” subsection. Next, we focus
on:
•	Determinant Amendment and Constant Dropping: Generically, we show that
N
log(det(F |N J)) = X log(det(Mi)) + cte,	(A18)
i=1
where det(F|NJ) is an amended version of det(F).
•	Efficient Computation of log(det(Mi)): Next, we show that
J
log(det(Mi)) = X log(Pi,j).	(A19)
j =0
Combining these two points will lead us to the simplified Firth bias reduction objective:
1NJ
LFirth = λ ∙ N XX log(Pi,j).	(A20)
Determinant Amendment and Constant Dropping: Having F = X| ∙ M ∙ X prompts us to utilize
the SVD of X as
XNj×dj = UNJ×NJ ∙ Snj×dJ ∙ VJ×dj.	(A21)
Therefore, the FIM can be written as F = V ∙(S| ∙ K ∙ S) ∙ V|, where K := U| ∙ M ∙ U. Since V
and U are rotation matrices, we can write det(F) = det(Sl ∙ K ∙ S), and
N
det(K) = det(M) = Ydet(Mi).	(A22)
i=1
15
Published as a conference paper at ICLR 2022
	
Notation	Description
J+1	Total Number of Classes in Multinomial Logistic Regression
βj	The Logistic Regression Weights for Class j (j ∈ {1,2, ∙∙∙ , J})
Pi,j	Classification Probability of Sample i Belonging to Class j
Pi	The ith Sample,s Soft Classification Probabilities
N	Number of Samples
D = {(xi,yi)}iN=1	Logistic Regression Sample Dataset
yi	The One-Hot Encoding of the Label yi
1[a = b]	The Binary Indicator Function (i.e., 1 When a = b and 0 otherWise)
F	The Fisher Information Matrix
d	Dimension of the Features
IJ	The J × J Identity Matrix
A③B	The Kronecker Product of Matrix A by Matrix B
1r×c	The All Ones Matrix With r RoWs and c Columns
S βMLE	The Maximum Likelihood Estimator (MLE)
Llogistic	The Logistic Log-Likelihood Function
LFirth	The Firth Bias Reduction Function
λ	The Firth Bias Reduction Coefficient
CE(pkq)	The Cross-Entropy of p and q
DKL(pkq)	The KL Divergence of p and q
U[0,J]	The Uniform Class Assignment Probabilities
det(A|r)	The Amended Determinant of the Degenerate Matrix A With at most r Non-zero Eigenvalues (See Section A in the Appendix)
Table A2: The mathematical notations used throughout the paper.
As we have d > N for most few-shot tasks, the matrix S can be viewed in the following form:
SNJ ×dJ
×NJ
0,
(A23)
1 A ∙	1 ∙	i	, ∙ n ∙ At A 1
where S is a diagonal square matrix. Since S| = S, we have
S | ∙ K ∙ S
S ∙ K ∙ S) NJ×NJ 0
00
(A24)
Equation (A24) and det(F) = det(S| ∙ K ∙ S) show Why det(F) is zero. For mitigation, We replace
det(F) with the product of the non-zero eigenvalues of F, namely det(F |N J), and call it the
“amended determinant" of F. Thanks to F = V ∙ (ST ∙ K ∙ S) ∙ V|, even the amended determinants
det(F|NJ) and det(Sl ∙ K ∙ S|NJ) are the same:
det(F|NJ) = det(Sl ∙ K ∙ S∣NJ) = det(S ∙ K ∙ S) = det(M) ∙ det(S2).	(A25)
16
Published as a conference paper at ICLR 2022
Figure A5: Firth bias reduction is effectively the same as minimizing the KL divergence to the
uniform class probabilities for logistic regression. Here, Pi denotes the predicted distribution of
classes for the sample xi , and U denotes the uniform distribution of classes. The logistic objective
minimizes the KL-divergence between the true label yi and Pi, while Firth bias reduction LFirth tries
to tie Pi with a KL divergence rope to the uniform distribution over the classes.
Could det(F|NJ) be zero? The answer is “not” generically; det(M) is generically positive as we
will show det(Mi) = QJ=0 Pi,j later in Equation (A28). Also, det(S2) > 0 holds with probability
1 for continuous data distributions. In fact, det(S2) can only be zero when the data contains linearly
dependant samples, which happens with zero probability for non-atomic data distributions. Therefore,
we have
N
log(det(F |NJ)) = X log(det(Mi)) + log(det(S2)).	(A26)
i=1
This is the same as Equation (A18): since the log(det(S2)) term is independent of the model's
parameters, we can treat it as an optimization constant and drop it.
Efficient Computation of log(det(Mi)): We define the soft predictions of the ith sample (excluding
the reference class) asPi,i： J := ∣^Pi,ι •一 Pi”] ।. Given MiS definition in Equation (A31), we
can write
Mi = Diag(Pi,i：J) - Pi,i：J ∙ P|」：j.	(A27)
Next, we use the Matrix-Determinant Lemma (Harville, 1998) to compute det(Mi):
det(Mi) = det(Diag(Pi,i： J)) ∙ (1 - P|」：” ∙ Diag(Pi,i： J) ∙ P,3J)
J	JJ
=(Y Pi,j) ∙ (1 -P|,i：j1j×1) = (Y Pi,j) ∙ Pi,0 = Y Pi,j.	(A28)
j=1	j=1	j=0
Taking the log will give us Equation (A19).
The FIM Formulation for Logistic Regression: Elementary methods established that the FIM of
the logistic classifier is composed of J × J block matrices, each with a dimension of d × d (where d
is the dimension of the features). These block matrices can be expressed as
N
Fjj = X Pi,j ∙ (I-Pij) ∙ xi ∙ x|	V 1 ≤ j ≤ J，
i=1
N
Fj,k = — X Pi,j ∙ Pi,k ∙xi∙x∣	∀ 1 ≤ j = k ≤ J. (A29)
i=1
17
Published as a conference paper at ICLR 2022
2.5 -
2.0-
四 1∙5 一
8
S l.o-
<
0.5 -
5-way
ResNetlO
ResNetl8
ResNet34
ResNetSO
ResNetlOl
差
8
s
V
2.5 [
2.0-
1.5 -
1.0-
0.5 -
10-way
-φ- ResNetlO
T- ResNetl8
—φ- ResNet34
T- ResNetSO
-φ- ResNetlOl
/
o.o-
1	5	10	15	20	25
Number of Shots
0.0-
Number of Shots
X+X
Figure A6: Improvements of Firth-penalized logistic classifier over the baseline on mini-
ImageNet with 5 and 10 number of classes. Except for the number of classes, the experiments were
performed in the same setting as in Figure 2.
This facilitates the expression of the FIM as shown in Equation (A17): We can define X as the
Kronecker product of (1) the data matrix XD and (2) the J -dimensional identity matrix IJ:
X := XD ③ Ij .	(A30)
M would then be a block-diagonal matrix whose ith block is defined as
(Mi)j,j=Pi,j(1-Pi,j)	∀ 1 ≤j≤J,
(Mi)j,k = -Pi,jPi,k	∀ 1 ≤j 6=k ≤ J.	(A31)
B Firth Bias Reduction for Cosine Classifiers
Section A derived the Firth bias reduction term for the logistic classifier as DKL(UkPi). Here, we
generalize this observation to cosine classifiers, and prove that the Firth bias reduction for cosine
classifiers reduces down to the same form as the one obtained for logistic classifiers.
By defining the normalization transformation
「β∣	β∣ IT	「χ∣	χ∣ IT
T"]kβ⅛,…,台],T(x)= [kx⅛,…,k⅛] ,	(A32)
we have the log-likelihood relation between the cosine classifier and the logistic model:
Lcosine(β; x, y) = Llogistic(T(β); T (x), y).	(A33)
According to Equation (4) in the main paper and the chain rule, we can write
Fcosine(β, x,y) = A ∙ FlogistiC(T(β),T(x), y) ∙ A1,	(A34)
where Ad(J+1)×d(J+1) is the Jacobian matrix of T(β) with respect to β. It can be shown that A is a
symmetric block-diagonal matrix, whose jth diagonal block is
Aj,j
=kβjk (
Id×d -
βjβj \
Bj βj)
(A35)
18
Published as a conference paper at ICLR 2022
Figure A7: Same experiment as Figure 2 in the main paper but with a 3-layer logistic classi-
fier instead of a 1-layer logistic classifier (in the main paper). Again, Firth bias reduction improves
the accuracy for different backbones and number of samples (left), whereas L2-regularization is not
effective at all (right). In the very hard cases, i.e., 1- and 5-shots, there is a mild improvement by
Firth and no deterioration. The error bars, representing the 95% confidence intervals, are covered by
the blobs.
%8WGUWV
L2 Regularization
Firth Bias Reduction
1	5	10	15	20	25
Number of Shots
-5-0-5-0
75z0
%8uv
12.5 -
10.0 -
-φ- ResNetlO
T- ResNetl8
ResNet34
T- ResNetSO
-φ- ResNetlOl
1	5	10	15	20	25
Number of Shots
Figure A8: Relative accuracy improvements corresponding to Figure A7 with the 3-layer logistic
classifier. The behavior of the relative accuracy improvements is similar to the absolute accuracy
improvements for all the backbones in both techniques.
Therefore,
log(det(Fcosine)) = log(det(Flogistic)) + 2 log(det(A))
J
= log(det(Flogistic)) + 2 X log(det(Aj,j)).	(A36)
j=0
It is obvious that
v k βj
v⊥βj.
(A37)
Therefore, Aj,j can be thought as an identity-proportional matrix in the sub-space perpendicular to
βj . Therefore, its amended determinant is
log(det(Aj,j； d - 1)) = -(d- 1) ∙ log(kβjk).	(A38)
For the plain logistic model, the Firth penalized optimization problem is:
max
β
Llogistic(β; x, y) + λ ∙ log(det(Flogistic(β, x, y)))
(A39)
19
Published as a conference paper at ICLR 2022

10.0-
10.0-
ResNetlO Backbone
10.0-
ResNetlS Backbone
10.0 -
ResNet34 Backbone
7	1	5	10	15	20	25
Number of Shots
10.0-
7.0
1	5	10	15	20	25
Number of Shots
%8y
Figure A9: Absolute test accuracy values of 16-way classification for the non-penalized 3-layer
and single-layer logistic classifiers on the novel set of mini-ImageNet for different backbones
and varying number of samples.
For the cosine classifiers, the Firth penalized optimization problem is:
m^ax [Liogistic(T(β); T(x),y) + λ ∙ log(det(%istic(T(β),T(X),y))) - CXlog(kβjk) , (A40)
β	j=0
where we have C :=	2λ(d	-	1).	By re-parameterizing β =	(uβ, sβ)	with	uβ	:=	T(β) and
Se ：= [kβok,…，kβjk], we have
max
uβ ,sβ
J
Liogistic(uβ；T(x),y) + λ ∙ log(det(Fiogistic(uβ,T(x),y))) — CElOg(Sej)
j=0
(A41)
Since ue and Se are independent optimization parameters, this probiem can be restated as
max
uβ
Llogistic(Ue; T(X),y) + λ ∙ log(det(Fiogistic(Ue, T(X), y)))
+ max
sβ
J
- CXlog(Sej) .
j=0
(A42)
Since Se has no effect on the predictions of the modei, it can be ignored. Therefore, we end up with
the optimization probiem
max
uβ
LiogiStiC(Ue； T(x),y) + λ ∙ log(det(Fiogistic(uβ,T(x),y))) .	(A43)
Essentiaiiy, this suggests appiying the same bias reduction form to cosine ciassifiers as the one
used for iogistic ciassifiers log(det(Fiogistic(Ue, T (X), y))) reduces down to DKL(UkPi) as proven in
Section A, and Liogistic(Ue; T (X), y) is the cross-entropy ioss with the true iabeis.
C Additional Related Work on Few-Shot Image Clas sification
As one of the unsoived probiems in machine iearning, few-shot iearning (Miiier et ai., 2000; Fei-Fei
et ai., 2006) has attracted growing interest in the deep iearning era (Lake et ai., 2015; Santoro et ai.,
2016; Wang and Hebert, 2016; Vinyais et ai., 2016; Sneii et ai., 2017; Finn et ai., 2017; Hariharan and
20
Published as a conference paper at ICLR 2022
Figure A10: Same experiment as Figure 3 in the main paper but with a 3-layer logistic classifier
instead of a single-layer (in the main paper). Again, in both schemes (7.5 and 15 average shots),
the Firth penalized classifier results in more accuracy improvements than the classifier penalized with
KL-divergence to the non-uniform prior. This further suggests that Firth bias reduction is indeed
reducing the bias and is not simply imposing a uniform prior. Also, it reaffirms that plain Firth bias
reduction can safely be used on imbalanced data.
Girshick, 2017; George et al., 2017; Triantafillou et al., 2017; Edwards and Storkey, 2017; Mishra
et al., 2018; Douze et al., 2018; Wang et al., 2018; Chen et al., 2019; Dvornik et al., 2019; Allen et al.,
2019; Li et al., 2019a; Yoon et al., 2019; Lifchitz et al., 2019; Li et al., 2019b; Zhang et al., 2020; Ye
et al., 2020; Dhillon et al., 2020; Triantafillou et al., 2020; Tian et al., 2020; Dvornik et al., 2020;
Yang et al., 2021; Phoo and Hariharan, 2021; Gui et al., 2021; Liu et al., 2021; Zhang et al., 2021).
Successful generalization from few training samples requires “inductive biases” or shared knowledge
from related tasks (Baxter, 1997), which is commonly acquired through transfer learning, and more
recently, meta-learning (Thrun, 1998; Schmidhuber, 1987; Schmidhuber et al., 1997; Bengio et al.,
2013). By explicitly “learning-to-learn” over a series of few-shot learning tasks (i.e., episodes), which
are simulated from base classes, meta-learning exploits accumulated task-agnostic knowledge to
few-shot learning problems of novel classes. Within this paradigm, various types of meta-knowledge
has been explored, including (1) a generic feature embedding or metric space, in which images are
easy to classify using a distance-based classifier such as cosine similarity or nearest neighbor (Koch
et al., 2015; Vinyals et al., 2016; Snell et al., 2017; Sung et al., 2018; Ren et al., 2018; Oreshkin et al.,
2018); (2) a common initialization of network parameters (Finn et al., 2017; Nichol and Schulman,
2018; Finn et al., 2018) or learned update rules (Andrychowicz et al., 2016; Ravi and Larochelle,
2017; Munkhdalai and Yu, 2017; Li et al., 2017; Rusu et al., 2019); (3) a transferable strategy to
estimate model parameters based on few class examples (Bertinetto et al., 2016; Qiao et al., 2018;
Qi et al., 2018; Gidaris and Komodakis, 2018), or from an initial small dataset model (Wang and
Hebert, 2016; Wang et al., 2017). Some most recent work (Gidaris and Komodakis, 2018; Chen et al.,
2019; Tian et al., 2020) also showed that the performance of these complex models can be matched
by simple representation learning on base classes and classifier fine-tuning on novel classes.
D Datasets and Additional Experiment Details
Datasets: mini-ImageNet consists of 64, 16, and 20 classes from ImageNet (Russakovsky et al.,
2015) for base, validation, and novel sets, respectively. Each class contains 600 images of size
84 × 84. tiered-ImageNet consists of 351, 97, and 160 classes from ImageNet for base, validation,
and novel sets, respectively. Unlike mini-ImageNet, the classes could have varying number of
samples in tiered-ImageNet, but the images are of the same size. CIFAR-FS is a random split of
CIFAR-100 (Krizhevsky and Hinton, 2009) with images of size 32 × 32 into 64, 16, and 20 classes
for base, validation, and novel sets, respectively. CUB consists of 11,788 images of size 84 × 84
which are split into 100, 50, and 50 classes for base, validation, and novel sets, respectively.
Setups and Implementation Details: Our experiments fall into two main categories: (1) the stan-
dard ResNet (He et al., 2016) feature experiments for logistic classifiers, and (2) more powerful,
21
Published as a conference paper at ICLR 2022
Setting	Hyper-parameter	Value
	Learning Rate	0.005
	Mini-batch Size	10
All Standard Backbone	Number of Classes	16
Experiments	Optimizer	SGD
	Train-Heldout Splits	90%-10%
	Backbones	ResNet10,18, 34, 50,101
Balanced Data Experiments in Sections 4.1 and 4.2 in the	Number of Shots Firth Coefficients Set*	1,5, 10, 15, 20, 25 0, 0.01,0.03,0.1,0,3, 1, 3, 10
Main Paper	L2 Coefficients Set**	0, 1, 3, 10, 30, 100, 300, 1000
Imbalanced Data Experiments in Section 4.3 in the Main	7.5-Shot Class Distribution	2, 2, 2, 2, 4, 4, 4, 4, 8, 8, 8, 8, 16,16,16,16
Paper	15-Shot Class Distribution	1, 1, 5, 5, 9, 9, 13, 13, 17, 17, 21, 21, 25, 25, 29, 29
Experiments in	Number of Epochs	400
Sections 4.1, 4.2, and 4.3 in the Main Paper with 1-Layer Logistic Classifier	Classifier Architecture Number of Trials	Features→Classes→Softmax More than 800
	Number of Epochs	100
Experiments in Section E.2 with 3-Layer Logistic Classifier	Classifier Architecture	Features- 100→ReLU→50 →ReLU →Classes→Softmax
	Number of Trials	More than 400
Table A3: Experimental settings used for the standard backbone experiments. The table is partitioned
into 5 sections, where the first section shows the global hyper-parameters used in all standard
backbone experiments. The same set of Firth bias reduction and L2 regularization coefficients
were used for all validation experiments. *The Firth regularization coefficients were chosen for
Equation (13) in the main paper. **We defined the L2-regularization as the mean squared value of
all classifier parameters, which is why the normalized set of coefficients seems large. The typical
unnormalized regularization coefficients can be obtained by dividing these normalized coefficients by
the number of classifier parameters.
Number of Shots	Confidence Penalty Improvements	Firth Improvements
5	0.13 ± 0.13 %	0.23 ± 0.06 %
10	0.52 ± 0.14%	0.73 ± 0.07 %
15	0.57 ± 0.18 %	1.00 ± 0.07 %
Table A4: Comparing Firth bias reduction against the confidence penalty label smoothing
technique. The confidence penalty is defined as a DKL (Pi kU) regularization term, whereas Firth
bias reduction for logistic and cosine classifiers reduces to a DKL(UkPi) penalty. The experimental
setting is the same as Figure A7 with the ResNet-10 backbone. This suggests that the improvements
obtained by Firth are the result of its bias suppression property, and Firth cannot be replaced by
standard label smoothing techniques.
state-of-the-art WideResNet (Zagoruyko and Komodakis, 2016) features trained with strong reg-
ularization techniques (manifold mixup) and additional self-supervision (Mangla et al., 2020), or
further calibrated via feature transformations (Yang et al., 2021), for logistic and cosine classifiers.
22
Published as a conference paper at ICLR 2022
Figure A11: Firth bias reduction improves the accuracy of the logistic classifier on tiered-
ImageNet for both DenseNet (top) and MobileNet (bottom) as backbone architectures. The
improvement is consistent over the number of classes in few-shot classification. The error bars are
almost non-existent (i.e., less than 0.02%), since over 10,000 trials with matching randomization
factors were used for obtaining each single point. Firth bias reduction improvements are always
positive, and it never hurts to use it.
For the first category of experiments, we averaged our results over 400 random trials. An array
of 5 different ResNet architectures were trained in this category: ResNet10, 18, 34, 50, and 101,
following a simple pipeline in the Pytorch library example1. It is worth noting that we deliberately
did not engineer strong features for this category of experiments. The mini-ImageNet dataset was
used for these experiments, and 16-way classification was performed on both the validation and novel
classes. For this purpose, 16 out of 20 novel classes were chosen at random once and fixed for all
the evaluations. We split the validation and novel classes into 90% training and 10% held-out for
accuracy evaluation. The imbalanced data settings were chosen to either have 7.5 or 15 average
number of shots per class. For the second category of experiments, we used the WideResNet-28-10
pre-trained feature backbones from Mangla et al. (2020); Yang et al. (2021). These experiments were
conducted on three benchmarks, and each hyper-parameter configuration was averaged over 10,000
random trials. The backbone parameters and extracted features for all datasets are publicly available
in the Illinois Data Bank repository (Saleh et al., 2022). Additional details and hyper-parameters are
covered in the subsequent sections.
Additional Implementation Details for Sections 4.1 and 4.2 in the Main Paper: The L2-
regularization coefficient was chosen for the mean-squared value of all classifier parameters, and the
Firth bias reduction coefficient was chosen for Equation (13) in the main paper.
Statistical Significance and Reducing the Effect of Randomized Factor: Our study investigates
improvements over the baseline. Random effects (random number seed; batch ordering; parameter
initialization; and so on) complicate the study by creating variance in the measured improvement. We
used a matching procedure (so that the baseline and the Firth penalized models share the same values
of all random effects) to control this variance. As long as one does not search for random effects
that yield a good improvement (we did not), this yields an unbiased estimate of the improvement.
Each experiment is repeated multiple times to obtain confidence intervals. Note that (1) confidence
intervals are small; and (2) improvements occur over a large range of feature backbones and datasets.
1https://github.com/pytorch/examples
23
Published as a conference paper at ICLR 2022
No Artificial Samples					750 Artificial Samples		
Way	Shot	Before	After	Improvement	Before	After	Improvement
10	1	59.44	60.07 ± 0.16	0.63 ± 0.04	61.85	61.90 ± 0.17	0.05 ± 0.02
10	5	80.52	80.85 ± 0.12	0.33 ± 0.03	79.66	80.07 ± 0.13	0.42 ± 0.04
15	1	52.68	53.35 ± 0.13	0.67 ± 0.03	54.57	54.62 ± 0.14	0.05 ± 0.02
15	5	75.18	75.64 ± 0.11	0.46 ± 0.03	73.88	74.40 ± 0.11	0.53 ± 0.04
Table A5: The Firth bias reduction accuracy improvements on the tiered-ImageNet dataset
when 0 or 750 artificial samples were generated from the calibrated normal distribution in Yang
et al. (2021).
	Before	After	Improvement	Before	After	Improvement
		5-way			10-way	
1-shot	74.96	75.03 ± 0.19	0.07 ± 0.01	61.46	61.49 ± 0.13	0.03 ± 0.00
5-shot	87.43	87.48 ± 0.13	0.06 ± 0.00	77.73	77.83 ± 0.10	0.10 ± 0.00
10-shot	89.83	89.88 ± 0.11	0.05 ± 0.00	81.52	81.64 ± 0.09	0.11 ± 0.00
		15-way			20-way	
1-shot	53.45	53.47 ± 0.10	0.02 ± 0.00	47.78	47.79 ± 0.07	0.01 ± 0.00
5-shot	70.70	70.99 ± 0.07	0.28 ± 0.00	65.26	65.60 ± 0.03	0.34 ± 0.00
10-shot	75.37	75.71 ± 0.06	0.34 ± 0.00	70.57	70.99 ± 0.02	0.42 ± 0.00
Table A6: The Firth bias reduction improvements on the CIFAR-FS dataset shown in Figure 4 in
the main paper. “Before” stands for the novel set accuracy without having any Firth bias reduction,
and “After” stands for the novel set accuracy after applying Firth bias reduction. Note that the
confidence intervals are much smaller for the improvement column, thanks to the random-effect
matching procedure we used in this study. The “Before” confidence intervals were similar to the
“After” confidence intervals, and thus not repeated due to space constraints.
It is safe to conclude that Firth bias reduction reliably offers a small but useful improvement in
accuracy for few-shot classifiers.
Additional Implementation Details for Section 4.3 in the Main Paper: We used two non-uniform
count vectors with different average counts, 7.5 (scheme 1) and 15 (scheme 2), to generate the datasets
in both validation and novel sets. The count vector with the average of 7.5-shots had 4 classes for each
count from the geometric sequence {2, 4, 8, 16}, and the count vector with the average of 15-shots
had 2 classes for each count from the arithmetic sequence {1, 5, 9, 13, 17, 21, 25, 29}. The same
1-layer logistic classifier of Sections 4.1 and 4.2 was used in Section 4.3 in the main paper.
Table A3 summarizes the hyper-parameters used in all the standard backbone experiments. Also,
Figure A8 shows the relative accuracy improvements corresponding to Figure A7. Figure A12
contains the validation accuracy versus Firth coefficient λ for the experiments of Figure 2 and
Figure A7.
Additional Implementation Details for Section 4.5 in the Main Paper: In the experiments carried
out in Section 4.5 in the main paper, a 1-layer cosine classifier was used. Also, for the Firth
bias-reduced cosine classifier, the regularization coefficient was tuned for each (N, J) pair, with
N representing the number of samples per class and J being the number of classes. For J -way
classification on the novel set when J happened to be larger than the number of classes in the
validation set (Jval), the coefficient tuned for Jval-way classification was adopted.
24
Published as a conference paper at ICLR 2022
	Before	After	Improvement	Before	After	Improvement
		5-way			10-way	
1-shot	65.17	65.59 ± 0.18	0.41 ± 0.02	50.38	50.64 ± 0.11	0.26 ± 0.01
5-shot	82.60	83.04 ± 0.12	0.44 ± 0.01	71.15	71.91 ± 0.10	0.76 ± 0.02
10-shot	86.82	87.04 ± 0.09	0.22 ± 0.01	77.34	77.87 ± 0.08	0.52 ± 0.01
		15-way			20-way	
1-shot	42.65	42.85 ± 0.08	0.20 ± 0.01	37.56	37.76 ± 0.07	0.20 ± 0.00
5-shot	63.73	64.76 ± 0.07	1.03 ± 0.01	58.35	59.52 ± 0.04	1.17 ± 0.01
10-shot	70.87	71.71 ± 0.05	0.84 ± 0.01	66.06	67.12 ± 0.03	1.06 ± 0.01
Table A7: The Firth bias reduction improvements on the mini-ImageNet dataset shown in
Figure 4 in the main paper. “Before” stands for the novel set accuracy without having any Firth bias
reduction, and “After” stands for the novel set accuracy after applying Firth bias reduction. Note that
the confidence intervals are much smaller for the improvement column, thanks to the random-effect
matching procedure we used in this study. The “Before” confidence intervals were similar to the
“After” confidence intervals, and thus not repeated due to space constraints.
For the standard backbone experiments on mini-Imagenet, we trained more than 384,000 3-layer
and 768,000 1-layer logistic classifiers for the balanced data settings. For the imbalanced settings
on mini-Imagenet, we trained more than 64,000 3-layer and 128,000 1-layer logistic classifiers.
For the cosine classifier experiments, we trained over 1.92, 1.92, and 3.36 million classifiers for
mini-ImageNet, CIFAR-FS, and tiered-ImageNet datasets, respectively.
E Additional Experiments on the S tandard Backbones
E.1	Additional Logistic Classifier Experiments
The experiments of Figure 2 were repeated to perform 16-way classification using a logistic classifier
on tiered-ImageNet and CIFAR-FS in Figure A13. Moreover, 5-way and 10-way classification was
tested for mini-ImageNet in Figure A6 in the same setting as Figure 2. The results show that Firth
improvements always exist and it is even more effective as the number of classes increases.
E.2	3 -Layer Logistic Classifiers for the Standard Backbones
We conducted the same experiments as in Sections 4.1 and 4.2 in the main paper but with a 3-
layer logistic classifier. Again, we see consistent accuracy improvements for the Firth bias-reduced
classifier over the non-penalized (baseline) classifier in Figure A7. This further supports the idea
that Firth bias reduction boosts the performance of any reasonable classifier. Needless to say,
L2-regularization is not effective as shown in Figure A7.
Furthermore, the imbalanced few-shot classification in Section 4.3 in the main paper was repeated
with the 3-layer logistic classifier in Figure A10. Again for both schemes, the Firth penalized
classifier has larger accuracy improvement than the classifier penalized with the KL-divergence to the
non-uniform prior over the class probabilities. This further validates the effectiveness of Firth bias
reduction in reducing the parameter estimation bias present in the few-shot setting.
F	Additional feature backbones
To test the Firth bias reduction technique for additional backbones, we used pre-trained DenseNet
and MobileNet backbones on tiered-ImageNet from Wang et al. (2019). The accuracy improvements
of Firth penalized logistic classifier over the baseline averaged over 10,000 trials are plotted in
Figure A11. Regardless of the number of classes, the improvements are always positive.
25
Published as a conference paper at ICLR 2022
						
	Before	After	Improvement	Before	After	Improvement
		5-way			10-way	
1-shot	73.50	73.64 ± 0.25	0.14 ± 0.03	61.20	61.44 ± 0.16	0.24 ± 0.01
5-shot	88.00	88.31 ± 0.12	0.30 ± 0.01	79.41	80.01 ± 0.11	0.60 ± 0.01
10-shot	90.94	91.14 ± 0.10	0.21 ± 0.01	83.88	84.47 ± 0.09	0.58 ± 0.01
		15-way			20-way	
1-shot	53.90	53.97 ± 0.15	0.07 ± 0.01	48.81	48.96 ± 0.11	0.15 ± 0.01
5-shot	73.33	74.21 ± 0.09	0.88 ± 0.01	68.58	69.71 ± 0.08	1.13 ± 0.01
10-shot	78.70	79.57 ± 0.08	0.86 ± 0.01	74.58	75.74 ± 0.07	1.16 ± 0.01
		50-way			100-way	
1-shot	33.91	34.13 ± 0.06	0.22 ± 0.01	24.80	25.00 ± 0.03	0.20 ± 0.00
5-shot	52.60	54.71 ± 0.05	2.10 ± 0.01	41.03	43.59 ± 0.03	2.56 ± 0.01
10-shot	59.67	61.94 ± 0.04	2.27 ± 0.01	47.77	50.81 ± 0.02	3.04 ± 0.01
150-way
1-shot	20.37	20.56 ± 0.02	0.19 ± 0.00
5-shot	34.89	37.54 ± 0.01	2.65 ± 0.01
10-shot	41.04	44.28 ± 0.01	3.25 ± 0.01
Table A8: The Firth bias reduction improvements on the tiered-ImageNet dataset shown in
Figure 4 in the main paper. “Before” stands for the novel set accuracy without having any Firth bias
reduction, and “After” stands for the novel set accuracy after applying Firth bias reduction. Note that
the confidence intervals are much smaller for the improvement column, thanks to the random-effect
matching procedure we used in this study. The “Before” confidence intervals were similar to the
“After” confidence intervals, and thus not repeated due to space constraints.
G Comparing Firth Bias Reduction Against Standard Label
Smoothing Techniques
To demonstrate that Firth bias reduction cannot simply be replaced with label smoothing, we tested
two advanced variants of label smoothing that are superior to the original version as proposed
by Pereyra et al. (2017). The first variant, called confidence penalty, uses the entropy of the classifier’s
output (or equivalently, reverses the direction of the KL divergence in the original version of label
smoothing (Szegedy et al., 2016)); and the second variant, called unigram label smoothing, uses prior
distribution over the classes instead of uniform, which has been shown to be advantageous when
the output labels’ distribution is imbalanced in Pereyra et al. (2017). Note that both variants were
investigated for training a full deep neural network with a feature extractor backbone in large-sample
regimes in Pereyra et al. (2017). Our experiments in Figure 3 evaluate the effect of unigram label
smoothing when training the classifier in the small-sample regime.
We also performed more experiments in the same setting to compare Firth bias reduction against
confidence penalty regularization. As summarized in Table A4, in all the settings Firth bias reduction
has larger significant improvements than the confidence penalty technique. This further supports the
value of using Firth bias reduction and the fact that its impact on few-shot classification cannot be
reproduced with well-known and widely-used label smoothing techniques.
26
Published as a conference paper at ICLR 2022
	Before	After	Improvement	Before	After	Improvement
		ResNet10			ResNet18	
1-shot	7.96	7.97 ± 0.06	0.01 ± 0.01	7.57	7.58 ± 0.05	0.01 ± 0.01
5-shot	8.22	8.23 ± 0.06	0.01 ± 0.01	7.94	7.95 ± 0.06	0.01 ± 0.01
10-shot	8.19	8.24 ± 0.05	0.06 ± 0.05	8.01	8.15 ± 0.05	0.14 ± 0.06
15-shot	8.21	8.36 ± 0.05	0.15 ± 0.06	8.09	8.47 ± 0.05	0.38 ± 0.06
20-shot	8.22	8.51 ± 0.05	0.28 ± 0.06	8.15	8.75 ± 0.06	0.60 ± 0.06
25-shot	8.25	8.51 ± 0.05	0.25 ± 0.06	8.27	8.92 ± 0.05	0.65 ± 0.06
		ResNet34			ResNet50	
1-shot	7.47	7.48 ± 0.05	0.01 ± 0.01	7.51	7.52 ± 0.05	0.01 ± 0.01
5-shot	7.69	7.70 ± 0.05	0.01 ± 0.01	7.73	7.78 ± 0.05	0.05 ± 0.05
10-shot	7.73	7.96 ± 0.05	0.23 ± 0.05	7.83	8.59 ± 0.05	0.76 ± 0.06
15-shot	7.79	8.22 ± 0.05	0.43 ± 0.06	7.89	9.02 ± 0.05	1.13 ± 0.06
20-shot	7.87	8.41 ± 0.05	0.55 ± 0.06	8.15	9.67 ± 0.06	1.52 ± 0.06
25-shot	7.97	8.54 ± 0.05	0.57 ± 0.06	8.44	10.71 ± 0.06	2.27 ± 0.06
		ResNet101				
1-shot	7.63	7.65 ± 0.05	0.02 ± 0.02			
5-shot	7.81	7.88 ± 0.05	0.07 ± 0.05			
10-shot	7.96	8.81 ± 0.05	0.86 ± 0.06			
15-shot	8.10	9.50 ± 0.05	1.40 ± 0.06			
20-shot	8.37	10.29 ± 0.06	1.91 ± 0.06			
25-shot	8.74	10.62 ± 0.06	1.88 ± 0.06			
Table A9: The Firth bias reduction improvements on the mini-ImageNet dataset shown in
Figure 2 in the main paper. “Before” stands for the novel set accuracy without having any Firth bias
reduction, and “After” stands for the novel set accuracy after applying Firth bias reduction. Note that
the confidence intervals are much smaller for the improvement column, thanks to the random-effect
matching procedure we used in this study. The “Before” confidence intervals were similar to the
“After” confidence intervals, and thus not repeated due to space constraints. It is worth noting that we
deliberately did not engineer strong features for this experiment (stronger feature backbone results
are shown in Sections 4.5 and 4.6 in the main paper). This diversifies Firth’s performance portfolio,
demonstrating its robustness to the strength of the feature backbones; even with weak features, Firth
bias reduction substantially improves the accuracy with high relative improvements as shown here
and in Figure A8.
H	Additional Comparison with State of the Art
Table A5 summarizes the accuracy improvements obtained by integrating Firth bias reduction with
the distribution calibration method (Yang et al., 2021) under different shots and ways on the tiered-
ImageNet dataset. This method calibrates the features to follow a normal distribution, and generates
artificial samples from the estimated normal distribution as data augmentation to aid few-shot
classification. In its state-of-the-art setting, the features are transformed using Tukey transformations,
750 artificial samples are generated per class, and a logistic classifier is used. We tested Firth bias
reduction in two scenarios: (1) state-of-the-art setting without generating artificial samples from the
calibrated distribution; and (2) state-of-the-art setting with 750 artificial samples generated per class,
27
Published as a conference paper at ICLR 2022
3-Layer Logistic Classifier
25-Shot
2 O-S hot
T- ResNetlO T- ResNetlS T- ResNet34 T- ResNet50 T- ResNetlOl
15-Shot
25-Shot
I-Layer Logistic Classifier
2 O-S hot
15-Shot
9.5%-
9.0%-
8.5%-
8.0%-
7.5%-
7.0%-
6.5%-
O 10-≡ IO-2 10-1 IO0 10:
I-Shot
8.0%-
7.8%-
7.5%-
7.2%-
7.0%-
6.8%-
6.5%-
0	10^3 10^2 10^1 IO0 10:
Firth Regularization Coefficient	Firth Regularization Coefficient	Firth Regularization Coefficient
-φ- ResNetlO T- ResNetlS T- ResNet34 T- ResNet50 T- ResNetlOl
Figure A12: The effect of the validation coefficient λ on the validation accuracy for different
number of shots and backbone architectures. The top two rows belong to the 3-layer logistic
classifier in Figure A7 in the Appendix, and the bottom two rows belong to the 1-layer logistic
classifier in Figure 2 in the main paper.
as shown in Table A5. The 95% confidence intervals for the accuracy improvements are reported in
both cases.
As shown in Table A5, Firth bias reduction produces positive improvements in all cases, which are
statistically significant in all the cases. As expected, Firth bias reduction produces larger improve-
ments when artificial sample generation is disabled, and thus there is a larger maximum likelihood
estimation bias on the logistic classifier (despite the use of Tukey transformation). In the case that
artificial samples are added and they are tuned to follow the original normal distribution, having 750
28
Published as a conference paper at ICLR 2022
求 Gusv %uusv
6-
4-
Firth Bias Reduction (CIFAR-FS)
8η---------------------------------
6-
4-
—φ- ResNetlO
+ ResNetlS
—φ- ResNet34
T- ResNetSO
-φ- ResNetlOl
L2 Regularization (tιered-lmageNet)
T- ResNetlO
T- ResNetl8
T- ResNet34
T- ResNetSO
T- ResNetlOl
2 J
1	5	10	15	20	25
Number of Shots
8π
6-
4 -
L2 Regularization (CIFAR-FS)
T- ResNetlO
T- ResNetlS
T- ResNet34
T- ResNet50
-φ- ResNetlOl


2
2 -
1	5	10	15	20	25
Number of Shots
1	5
10	15	20	25
Number of Shots
Figure A13: Comparing the effect of Firth bias reduction against L2-regularization for the novel
set classification accuracy on the tiered-ImageNet and CIFAR-FS datasets. Firth bias reduction
(left) delivers a novel class accuracy improvement over the baseline classifier up to 8.0%. By contrast,
L2-regularization (right) is mostly statistically insignificant in the same few-shot setting. 16-way
logistic classification was conducted in this experiment, with over 1,000 randomized and matching
trials for each combination of method, backbone, and number of samples.
of them can to some extent alleviate the bias in the estimation of the logistic classifier’s weights in
the few-shot regime. However, the results show that even in the presence of more data (artificial
samples), Firth bias reduction is still effective. This suggests that producing artificial samples to
augment data cannot resolve the estimation bias issue, as they are more likely to be similar to the
limited real samples available. As shown in Section 4.6, this becomes an even more severe problem
in the cross-domain few-shot setting; producing artificial samples is significantly less effective than
Firth bias reduction, due to the domain shift.
29