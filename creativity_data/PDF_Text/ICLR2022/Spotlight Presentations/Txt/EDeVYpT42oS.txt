Published as a conference paper at ICLR 2022
Deconstructing	the Inductive Biases of
Hamiltonian Neural Networks
Nate Gruver, Marc Finzi, Samuel Stanton, Andrew Gordon Wilson
New York University
Ab stract
Physics-inspired neural networks (NNs), such as Hamiltonian or Lagrangian NNs,
dramatically outperform other learned dynamics models by leveraging strong in-
ductive biases. These models, however, are challenging to apply to many real
world systems, such as those that don’t conserve energy or contain contacts, a
common setting for robotics and reinforcement learning. In this paper, we exam-
ine the inductive biases that make physics-inspired models successful in practice.
We show that, contrary to conventional wisdom, the improved generalization of
HNNs is the result of modeling acceleration directly and avoiding artificial com-
plexity from the coordinate system, rather than symplectic structure or energy con-
servation. We show that by relaxing the inductive biases of these models, we can
match or exceed performance on energy-conserving systems while dramatically
improving performance on practical, non-conservative systems. We extend this
approach to constructing transition models for common Mujoco environments,
showing that our model can appropriately balance inductive biases with the flexi-
bility required for model-based control.
100%
75%
50%
25%
+ ODEBias
Figure 1: The common perception in physics-informed machine learning is that increased perfor-
mance is the result of complex biases. We find, however, that simpler implicit biases (such as
second-order structure) often account for almost all of the improvement over baselines.
1	Introduction
The inductive biases of convolutional neural networks, such as translation equivariance, locality,
and parameter sharing, play a key role in their generalization properties. Other biases have similarly
guided the development of deep models for other domains like graphs and point clouds. Yet since
models often encode multiple biases simultaneously, it can be challenging to identify how each
contributes to generalization in isolation. By understanding which inductive biases are essential, and
which are merely ancillary, we can simplify our models, and improve performance. For example,
Wu et al. (2019) demonstrate that Graph Convolutional Networks can be radically simplified to mere
logistic regression by removing nonlinearities, leading to dramatic gains in computational efficiency,
while retaining comparable accuracy.
Hamiltonian Neural Networks (HNNs) (Greydanus et al., 2019) have emerged as a leading approach
for modeling dynamical systems. These dynamics models encode physical priors and outperform
alternative Neural ODE approaches (Chen et al., 2018). In the spirit of Wu et al. (2019), we seek to
identify the critical components of HNNs. Since Lagrangian models (LNNs) (Lutter et al., 2019a;
1
Published as a conference paper at ICLR 2022
Cranmer et al., 2020) share the same structure and inductive biases as HNNs, we focus on HNNs
where energy conservation and symplecticity are more explicit.
HNNs encode a number of inductive biases that help model physical systems:
1.	ODE bias: HNNs model derivatives of the state rather than the states directly.
2.	Second-order (SO) bias: HNNs model changes in position through changes in velocity.
3.	Energy conservation bias: HNNs conserve their learned energy function.
4.	Symplectic bias: HNNs dynamics are symplectic: phase space areas are conserved, and
the vector field has a Hamiltonian structure.
In this paper we theoretically and empirically examine the role of these biases. In contrast to conven-
tional wisdom, we find that the generalization benefit of HNNs is not explained by their symplectic
or energy-conserving properties, but rather by their implicit second-order bias. We highlight these
findings in Figure 1. Abstracting and extracting out this second-order bias, we show how to improve
the performance of Neural ODEs, empowering applications when HNNs assumptions are violated as
is often the case. Code for our experiments can be found at: https://github.com/ngruver/decon-hnn.
2	Related Work
Physics-inspired models and energy conservation Since Greydanus et al. (2019), many re-
searchers have sought to extend the HNN approach to make it more general or applicable to systems
that break energy conservation. Jin et al. (2020), Li et al. (2020), Tong et al. (2021), and Xiong
et al. (2020) propose methods for creating neural networks that preserve symplectic structure di-
rectly. Zhong et al. (2020), and later Desai et al. (2021), Li et al. (2021), and Lee et al. (2021)
propose models with additional capacity for changes to the system energy. In our analysis, we com-
pare against approaches that add additional capacity for changes in energy, although our approach
is fundamentally different — we attempt to remove unnecessary biases rather than add complexity.
Physics-inspired models for control A large and rapidly expanding body of work explores how
to use physics-based biases in dynamics models with controls or contacts (Lutter et al., 2019b;
Zhong et al., 2019; Gupta et al., 2019; 2020; Chen et al., 2019; Hochlehnert et al., 2021; Chen et al.,
2020; Zhong et al., 2021b) intended for application in model-based planning. Especially relevant
to our evaluations, Alvarez et al. (2020) models MuJoCo (Todorov et al., 2012) trajectories with a
numerically integrated neural network but does not explore other physics-inspired inductive biases.
Analyzing physics-based inductive biases Karniadakis et al. (2021) and Liu et al. (2021) propose
conceptual frameworks for deep learning with physics-based inductive biases, but present minimal
empirical analysis of common design decisions. Zhong et al. (2021a) compare many approaches
to physics-inspired deep learning, with results that parallel some findings here. The contribution of
our work, however, is not simply benchmarking but also an actionable theory of HNNs’ success. In
spirit, our work is similar to Botev et al. (2021), which also critically examines the role of physics-
based priors in dynamics models, though their focus is on learning latent space dynamics, while we
focus on temporal models in observation space.
3	Background
We consider dynamical systems described by ordinary differential equations (ODEs) which deter-
mine how the system evolves over time. Even with high order derivatives, these systems can be
arranged into the form dz = F(z,t) for Z ∈ Rn. If the dynamics F are time-independent, then the
ODE can be understood as a vector field, specifying at each point where the next state will be.
Neural ODEs (NODEs) (Chen et al., 2018) parametrize a vector field with a neural network and learn
the dynamics directly from observed trajectories. A NODE dynamics model Fθ is rolled out from
the initial condition zo with ODE integration, Zt =ODESolve(zo, Fθ,t), and fit to trajectory data
by minimizing an L2 loss L(θ) = PT=II∣ ^t - Zt k2 between the predicted and observed trajectories,
Zt and zt.
2
Published as a conference paper at ICLR 2022
Like NODEs, HNNs also model dynamical systems as a parameterized vector field,
dt = J vHθwith J
I
0
(1)
where Hθ is a neural network with scalar output (GreydanUs et al., 2019).
This differential equation expresses Hamiltonian dynamics where p and q are the canonical positions
and momenta,
and -d
dt p
q
L	ʌ -I
∂H
∂p
ʌ
∂H
—-
L ∂q I
(2)
It is common practice to also explicitly define H = T + V , where T and V are the kinetic and
potential energy (Zhong et al., 2019; Gupta et al., 2019; Finzi et al., 2020). The assumption that the
Hamiltonian is separable holds for mechanical systems and allows for further simplification,
Hθ (q,p) = 1PT M-1(q)p + Vθ (q),
(3)
where positive definite mass matrix M and scalar V are outputs of the neural network.
4	Breaking Down HNN performance
In the following section we investigate to what extent commonly held beliefs about HNN prop-
erties actually explain the ability of HNNs to generalize. To separate out the different properties
of these models, we select synthetic environments from Finzi et al. (2020) and Finzi et al. (2021)
that are derived from a time independent Hamiltonian, where energy is preserved exactly. We use
kChainPendulum, a k link pendulum in angular coordinates, and kSpringPendulum, a pendulum
connected with k spring links in Cartesian coordinates.
We compute relative error between predicted states, Z, and ground truth, z, as ||z - z∣∣2/Ilzk2∣∣z∣∣2
and between the predicted and ground truth Hamiltonian as |H - H|/|H ||H |. Following Finzi et al.
(2020), we evaluate the performance of the model by computing the geometric mean of the relative
error of the state over rollouts of length 20 times the size used at training, which more faithfully
predicts downstream performance compared to other metrics like MSE (Finzi et al., 2020). The
geometric mean of a function f over time T is given by exp( TT J= log f (t)dt).
4.1	Energy Conservation
HNNs are commonly believed to be superior for energy conservation than comparable models
(Greydanus et al., 2019; Cranmer et al., 2020). While there is some empirical evidence to sup-
port this claim, a precise mathematical explanation for why this should be the case has not been
established. Surprisingly, we find that conditioned on the trajectory reconstruction error, HNNs are
no better at conserving the true energy of the system than unconstrained NeuralODE models.
Up to the numerical accuracy of an ODE solver, HNNs do conserve their own learned energy func-
tion HH (different from the true energy of the system H), due to basic properties of Hamiltonian
mechanics,
(z) = vHH > d^^ = vHH >j vHH = 0,	(4)
dt	dt	,
where the last equality follows from the antisymmetry of J. If the HNN has fit the data well, we
might expect H to be close to the true Hamiltonian H, and so if H is conserved then it seems that
H should be too. As we show in Appendix B.2, the problem with this argument is that we have no
guarantees that H and H are close even if We have fit the data well with low error in the rollouts
or the dynamics. Since the dynamics error and the training rollout error depend only on gradients
VHH, while the gradients may be close, the differences between the two scalar functions can grow
arbitrarily large.
In Figure 2 (left) we show that the degree of energy conservation is highly correlated with the
rollout error of the model, regardless of the choice of architecture. While HNNs have better rollout
3
Published as a conference paper at ICLR 2022
0 2 4
O 厂
loo
1 1
Uo省OIA məuw
• HNN ∙ NODE + SO ∙ NODE
IO-2
IO-4	IO-2	IO0
_ „	_	1∩-4
Rollout Error
O
A6」① ullj
10-1	IOT	IOT
Rollout Time T
usqu6uuds
-Γ-<∙	z-⅝ Tr C/ El F	i'	∙ 1	/1 τ'τ T T I /1 τ'τ II T r I ∖	,	ll ,	i' . ∙
Figure 2: Left: The degree of energy violation (|H - H |/|H ||H |) on test rollouts as a function
of rollout relative error (∣∣Z - zk∕∣∣Z∣∣kzk) across different environments and random seeds. Both
HNNs and NeuralODEs are scattered around the line x = y . Conditioned on the rollout perfor-
mance, whether or not the model is Hamiltonian has little impact on the energy violation. Right:
Energy violation on test trajectories is plotted as a function of the time T of the rollout, with the
shaded regions showing 1 standard deviation in log space taken across 5 random seeds and the test
trajectories.
performance than NeuralODEs, they are on the same regression line with Rollout Error a Energy
Violation. The differences in energy violation are best predicted by the rollout error and not the
architecture.
In Appendix B.1, we derive a bound that helps explain this behaviour. Given that the trajectories
are in a bounded region of the phase space and that there is a fixed amount of error in the dynamics
model, the energy violation grows at most linearly in time and the dynamics error. In Figure 2 (right)
we demonstrate empirically that energy is not conserved as time progresses for HNNs.1 In fact,
the energy error of both NODE and HNN models grow linearly as our bound suggests. Although
energy conservation may be helpful for generalization, the evidence does not indicate that HNNs
are inherently better at conserving energy than NODEs, suggesting that the superior generalization
of HNNs cannot be attributed to superior energy conservation.
4.2	Symplectic vector fields
A defining property of Hamiltonian mechanics is the fact that the dynamics are symplectic. If energy
conservation does not explain the effectiveness of HNNs, the symplectic property of HNN dynamics
may be the cause. Informally, one of the consequences of symplectic dynamics is that every part of
the state space is equally attractive and repulsive. There are no sources where all nearby trajectories
flow out from, or sinks where all nearby trajectories flow into, only saddle points and centers where
the inflow and outflow is balanced. Symplectic integrators (Leimkuhler and Skeel, 1994) make use
of this property for more stable integration of Hamiltonian systems over very long timespans, and
it is intuitive that enforcing this property in learned dynamics would have benefits also, at the very
least for reducing the size of the hypothesis space.
More formally, symplecticity is the property that the J matrix (the symplectic form) is preserved by
the dynamics (Equation 1). This condition can be expressed as a constraint on the Jacobian DF of
the vector field F(Z) = d (here the derivative D maps from a function to its Jacobian). In terms of
the Jacobian, symplecticity is the condition DF>J + JDF = 0 or equivalently (JDF)T = JDF
since J> = -J. The significance of this condition is that areas occupied by states in phase space
(which have units of energy) are preserved by symplectic transformations. One consequence is that
a volume of solutions in phase space will continue to occupy the same volume over time and will
not be compressed or expanded. In other words, the vector field has 0 divergence: Tr(DF) = 0,
which one can derive from the above expression.
1The energy violation is considerably larger than merely the numerical error associated with the solver.
4
Published as a conference paper at ICLR 2022
10-4
JaUa Jnoπo0:
Chain 1 Chain 2 Chain 3 Spring 1 Spring 2 Spring 3
a=
0.001	0,01	0,1	1,0	10.0	100.0
0.0001
:0.001
JaUaOnoa
Chainl
Chain 2
Chain 3
Spring 1
Spring 2
Spring 3
Symplectic Error
Figure 3: Left: Test rollout error as a function of the regularization weighting in the loss. EVen
at an optimally chosen SymPlectic regularization strength, the benefit to model generalization is
negligible. Right: Test rollout error plotted against the final value of the symplecticity error for the
regularized models. For systems with more than a couple degrees of freedom, symplecticity error is
negatively correlated with the quality of predictions.
On Rn, it can be shown that all symplectic vector fields can be expressed as the dynamics of some
Hamiltonian system, and vice versa:
F = JVH o (JDF)T = JDF	(5)
To show the forward direction, one can simply substitute in Hamiltonian dynamics. It is clear that the
symplecticity property is satisfied: using J2 = -I, JDF = JD(JVH) = J2V2H = -V2H, and
-V2H is a symmetric matrix. The reverse direction is less obvious; however, by Poincare's lemma
if a vector field F satisfies (JDF )T = JDF on Rn, then there exists a Hamiltonian function H
such that F = JVH, which is shown in subsection B.3.
The equivalence of Hamiltonian dynamics and symplecticity allows us separate the unique proper-
ties of HNNs from other inductive biases that result indirectly from modeling F through H. Follow-
ing Ghosh et al. (2020), we can create aregularizer SymPlecticError(F) = ∣∣(JDF)T 一 JDF∣∣2
that directly measures the degree to which the symplectic property is violated. By parametrizing a
NeuralODE and regularizing the symplectic error, we can enforce Hamiltonian structure while still
directly modeling d=F rather than H. Alongside an unregularized NeuralODE, we can isolate
and evaluate the benefit of this Hamiltonian structure bias with a direct comparison.
Surprisingly, we find that the Hamiltonian structure bias, as enforced by the symplectic regularizer,
provides no real benefit to the model's ability to generalize over the long test rollouts (Figure 3 left).
The achieved symplectic error Figure 3 (right) is not positively correlated with the final test rollout
error of the model, and in some cases is even negatively correlated. Even when the symplectic error
is very low and the symplecticity condition is enforced, there is no consistent improvement on the
rollout generalization.
4.3	Second-order structure
If the superior performance of HNNs over NeuralODEs does not come from their better energy
conservation properties, nor from the symplectic structure of the predicted vector field, what is the
true cause?
In previous work, authors have used slightly different implementations of HNNs. One subtle im-
provement over the original work (Greydanus et al., 2019) comes from explicitly splitting the Hamil-
tonian as H = T + V = p>M(q)-1p∕2 + V(q) and modeling the mass matrix M(q) and the po-
tential V(q) with separate neural networks rather than using a single neural network for H (Zhong
et al., 2019). This splitting enforces a strong assumption about the functional form of the Hamil-
tonian that applies to mechanical systems that makes it easier to learn and extrapolate. Through
Hamiltons equations F = JVH, this splitting is in fact specifying the relationship between position
and momentum 黑=端=M-1(q)p, and that forces can only affect 笔.
5
Published as a conference paper at ICLR 2022
NODE Models
JaU0wnonoa
Figure 4: Left: NODE model with and without second-order structure (encoding dq/dt = v).
Right: HNN models with and without second-order structure. Models with the SO bias significantly
outperform those that do not. Error bars show standard error across 5 seeds.
HNNModels
WithSObias
Complex Coordinates
Chain 1
Chain 2
Chain 3
Chain 4
I NODE+SO
Simple Coordinates
Figure 5: Left: Log rollout error for NODEs with second order bias and HNNs trained chain pendu-
lums, where the analytic form of the Hamiltonian is simpler than the vector field. Right: Mechanic-
sNNs and HNNs trained on spring pendulums, which have Hamiltonians and vector fields of similar
complexity. HNNs outperform NODE with second order bias on systems that use non-Cartesian
coordinates. Error bars show standard error across 5 seeds.
In fact, We can see that this assumption essentially leads to the second-order differential equation
-qq-
dt
dp
-dt -
M -1(q)p
dV
---i-
dq
M (q)，- M-1(q) dV
Am*)
(6)
~qq-
This second-order (SO)structure, dV
v
A(q, v)
,is a direct by-product of the separable Hamil-
tonian inductive bias, but is more general, applying to both conservative and non-conservative phys-
ical systems.
We can isolate the effect of this bias by directly observing its effect on both HNNs and NODEs.
For HNNs the bias is made explicit in separable Hamiltonians, but not in the general case, when
H(q,p) is the direct output of the network instead of V(q). We can design a NODE with second-
order structure (NODE + SO) by setting Z = [q,p] withP = Mv and dq = v, dpp = A6(q,p), or
equivalently just the second order equation 余=aθ(q, d). Figure 4 shows the effect of second
order structure on the test predictions of NODEs and HNNs. It is clear that this bias explains the
superior performance of HNNs much more than other biases that are frequently given more credit.
In fact, when we add this bias to NODE models, we see that their performance more closely matches
HNNs than vanilla NODEs without creating a conservative or symplectic vector.
4.4	FUNCTIONAL COMPLEXITY
Adding second order structure to NODEs is always helpful, and matches the HNN performance for
many of the systems. However, we see that there is still a gap for some systems, and curiously
in each of these cases the system is described in a non-Cartesian coordinate system, such as with
joint angles and Euler angles. Recall that with the symplecticity bias, we only found no benefit for
enforcing that there exists a function H such that F = JVH bias while parametrizing F; however,
for HNNs this function not only exists, it is directly parametrized by the neural net. If the function
6
Published as a conference paper at ICLR 2022
Figure 6: Comparing the performance on damped systems. The NODE + SO matches the perfor-
mance of a SymODEN with a fraction of the parameters and compute. HNNs without forcing terms
encode the wrong inductive biases and thus fit the data poorly. Error bars denote standard error
across 5 seeds.
HH happens to be a simpler function to express and learn than VH, then representing the solution in
this way can be beneficial.
For systems expressed in Cartesian coordinates like the spring pendulum, the mass matrix M (q) =
M is a constant, and so the gradients of H = p>Mp + V (q) are simple to express and learn. How-
ever, for systems with constraints such as the Chain pendulum, where states are typically expressed
in angular coordinates, the mass matrix M (q) will have a complicated form and that complexity
will be magnified when taking the derivative. As an example, consider the Hamiltonian that an
HNN must learn for the 2 link chain pendulum versus the vector field that a NODE + SO model
must learn for this system (derived in Finzi et al. (2020), Appendix F.2). For the spring pendulum
the functional complexity of the Hamiltonian and vector fields is comparable, while for the chain
pendulum, the vector field contains many more terms.
Parameterizing such a system via its Hamiltonian simplifies the learning problem, and enables a
neural network to converge more rapidly towards a plausible solution. This observation aligns with
the insight in Finzi et al. (2020), which shows that changing the coordinate system to Cartesian
dramatically simplifies the learning problem, at the expense of needing to enforce the constraints to
the configuration space more directly.
Figure 5 shows the relative performance of the NODE+SO across the chain pendulum and spring
pendulum environments. As we would now expect, the gap between the NODE+SO and HNN
vanishes (and even favors NODE+SO) when complexity of the Hamiltonian and vector field are
comparable.
4.4.1	Non-conservative systems
Perfectly energy-conserving systems are useful for analyzing the limiting behaviour of physics-
informed networks, but in the vast majority of real world applications, we do not model closed
systems. Energy is changed through contact with the environment (as in friction or drag) or an actor
applying controls. In these cases, HNNs can be generalized by adding a forcing term
0
g(q, p) u
(7)
as in SymODEN (Zhong et al., 2019; 2020) and Desai et al. (2021), where u is the control input,
which can be fixed as constant in systems with drag or friction.
Though SymODEN can accommodate controls and damping, we show that simply using the bias of
second-order dynamics is sufficient to achieve nearly the same performance with much less com-
plexity. We demonstrate the matching performance on our n-body pendulum systems, augmented
with drag, dt
-瑞-λv (Figure 6).
7
Published as a conference paper at ICLR 2022
HalfCheetah Hopper Swimmer	HaliCheetah Hopper Swimmer
NODE	NODE + SO	SymODEN
Figure 7: HNNs perform very poorly on complex dynamics like OPenAI Gym MUjoco control
systems. Biasing the model towards Hamiltonian dynamics makes it difficult to fit the training
data. Simply imposing second-order structure on a NODE is much more effective. Error bars show
standard error across 4 seeds.
5 Modeling Mujoco Transition Dynamics
HNNs are typically evaluated on relatively simple systems, like those considered in the previous
sections. In principle, We would expect these results to extend to more complex systems that are
governed by similar physical laws. In practice, however, there is little evidence to suggest that
applying HNN methods to complex systems is easy or effective.
The MuJoCo physics simulator (Todorov et al., 2012) is one such complex system that we would
expect to benefit from HNN inductive biases. Gym Mujoco systems are heavily used in model-based
reinforcement learning (MBRL) literature, but the dynamics models commonly used are surprisingly
simple (often just MLPs trained to predict the next change in state) (Chua et al., 2018; Wang and
Ba, 2019).
Given how much benefit other applications of deep learning have derived from specialized archi-
tectures, such as CNNs for computer vision (LeCun et al., 1989), RNNs for NLP (Mikolov et al.,
2010), or WaveNets for audio (Oord et al., 2016), we would expect analogous improvements to be
possible in MBRL. Algorithms for MBRL are infamously sensitive to choice of prediction horizon,
and one possible explanation is poor generalization caused by weak inductive biases (Janner et al.,
2019; Pan et al., 2020; Amos et al., 2021). Improving model design for mechanical systems has the
potential to improve both the sample efficiency of MBRL algorithms and their robustness.
We train NODEs and HNNs on trajectories from several OpenAI Gym Mujoco environments
(Brockman et al., 2016). Crucially, we compare NODEs endowed with second-order structure
(NODE + SO) against pre-existing NODE and HNN models, as we did in Section 4.4.1. Note
that with fixed step size integrators, NODEs are equivalent to discrete transition models that predict
the next state or delta directly with an MLP, and therefore our NODE baseline is representative of
models commonly used in MBRL. See Appendix C for implementation details.
In Figure 7 we show that NODE + SO significantly outperforms baseline methods. Surprisingly
HNNs underperform NODEs on all the systems we consider. Although the HNN could in principle
learn the dynamics, in practice the bias towards Hamiltonian dynamics makes fitting the training data
very difficult and provides no tangible benefit to generalization. This outcome is notably different
from what we observe in toy tasks, where HNNs can fit non-conservative systems (e.g., pendulums
with drag) with little difficulty.
In spirit, our results parallel the findings of Wu et al. (2019) in the different setting of graph CNNs.
We are able to distill the inductive biases of HNNs into a NODE + SO without losing performance
on systems that HNNs perform well on, and, even more importantly, these reduced systems are much
more capable of scaling to complex systems and larger datasets.
8
Published as a conference paper at ICLR 2022
6 Conclusion
In this paper, we deconstructed the inductive biases of highly performing HNN models into their
component parts, a NeuralODE, symplecticity, conservation of the learned energy function, and
second order structure. Contrary to conventional wisdom, the success of HNNs is not from their en-
ergy conservation or symplecticity, but rather from the assumption that the system can be expressed
as a single second order differential equation. Stripping away the other components of an HNN, we
are left with a model that is simpler, more computationally efficient, and less restrictive in that it can
be directly applied to non-Hamiltonian systems. As a consequence, we are able to apply the result-
ing model to constructing transition models for the challenging Mujoco locomotion environments,
with promising performance.
Acknowledgements
The authors would like to thank Greg Benton and Pavel Izmailov for helpful comments on our
original submission. This research is supported by an Amazon Research Award, Facebook Research,
Google Research, NSF I-DISRE 193471, NIH R01DA048764-01A1, NSF IIS-1910266, and NSF
1922658 NRT-HDR: FUTURE Foundations, Translation, and Responsibility for Data Science.
9
Published as a conference paper at ICLR 2022
References
Victor M Martinez Alvarez, Rares RoSca, and Cristian G Falcutescu. Dynode: Neural or-
dinary differential equations for dynamics modeling in continuous control. arXiv preprint
arXiv:2009.04278, 2020.
Brandon Amos, Samuel Stanton, Denis Yarats, and Andrew Gordon Wilson. On the model-based
stochastic value gradient for continuous reinforcement learning. In Learning for Dynamics and
Control, pages 6-20. PMLR, 2021.
Aleksandar Botev, Andrew Jaegle, Peter Wirnsberger, Daniel Hennes, and Irina Higgins. Which
priors matter? benchmarking models for learning latent dynamics. 2021.
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and
Wojciech Zaremba. Openai gym. arXiv preprint arXiv:1606.01540, 2016.
Ricky TQ Chen, Brandon Amos, and Maximilian Nickel. Learning neural event functions for ordi-
nary differential equations. arXiv preprint arXiv:2011.03902, 2020.
Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary dif-
ferential equations. In Advances in neural information processing systems, pages 6571-6583,
2018.
Zhengdao Chen, JianyU Zhang, Martin Arjovsky, and Leon Bottou. SymPIectic recurrent neural
networks. arXiv preprint arXiv:1909.13334, 2019.
Kurtland Chua, Roberto Calandra, Rowan McAllister, and Sergey Levine. Deep reinforcement learn-
ing in a handful of trials using probabilistic dynamics models. arXiv preprint arXiv:1805.12114,
2018.
Miles Cranmer, Sam Greydanus, Stephan Hoyer, Peter Battaglia, David Spergel, and Shirley Ho.
Lagrangian neural networks. arXiv preprint arXiv:2003.04630, 2020.
Shaan Desai, Marios Mattheakis, David Sondak, Pavlos Protopapas, and Stephen Roberts. Port-
hamiltonian neural networks for learning explicit time-dependent dynamical systems. arXiv
preprint arXiv:2107.08024, 2021.
Marc Finzi, Ke Alexander Wang, and Andrew Gordon Wilson. Simplifying hamiltonian and la-
grangian neural networks via explicit constraints. arXiv preprint arXiv:2010.13581, 2020.
Marc Finzi, Max Welling, and Andrew Gordon Wilson. A practical method for constructing equiv-
ariant multilayer perceptrons for arbitrary matrix groups. arXiv preprint arXiv:2104.09459, 2021.
Arnab Ghosh, Harkirat Singh Behl, Emilien Dupont, Philip HS Torr, and Vinay Namboodiri. Steer:
Simple temporal regularization for neural odes. arXiv preprint arXiv:2006.10711, 2020.
Samuel J Greydanus, Misko Dzumba, and Jason Yosinski. Hamiltonian neural networks. 2019.
Jayesh K Gupta, Kunal Menda, Zachary Manchester, and Mykel J Kochenderfer. A general frame-
work for structured learning of mechanical systems. arXiv preprint arXiv:1902.08705, 2019.
Jayesh K Gupta, Kunal Menda, Zachary Manchester, and Mykel Kochenderfer. Structured mechani-
cal models for robot learning and control. In Learning for Dynamics and Control, pages 328-337.
PMLR, 2020.
Tuomas Haarnoja, Aurick Zhou, Kristian Hartikainen, George Tucker, Sehoon Ha, Jie Tan, Vikash
Kumar, Henry Zhu, Abhishek Gupta, Pieter Abbeel, et al. Soft actor-critic algorithms and appli-
cations. arXiv preprint arXiv:1812.05905, 2018.
Andreas Hochlehnert, Alexander Terenin, Steind6r sæmundsson, and Marc Deisenroth. Learning
contact dynamics using physically structured neural networks. In International Conference on
Artificial Intelligence and Statistics, pages 2152-2160. PMLR, 2021.
Michael Janner, Justin Fu, Marvin Zhang, and Sergey Levine. When to trust your model: Model-
based policy optimization. arXiv preprint arXiv:1906.08253, 2019.
10
Published as a conference paper at ICLR 2022
Pengzhan Jin, Zhen Zhang, Aiqing Zhu, Yifa Tang, and George Em Karniadakis. Sympnets: Intrin-
sic structure-preserving symplectic networks for identifying hamiltonian systems. Neural Net-
works,132:166-179, 2020.
George Em Karniadakis, Ioannis G Kevrekidis, Lu Lu, Paris Perdikaris, Sifan Wang, and Liu Yang.
Physics-informed machine learning. Nature Reviews Physics, 3(6):422-440, 2021.
Yann LeCun, Bernhard Boser, John Denker, Donnie Henderson, Richard Howard, Wayne Hubbard,
and Lawrence Jackel. Handwritten digit recognition with a back-propagation network. Advances
in neural information processing systems, 2, 1989.
Kookjin Lee, Nathaniel Trask, and Panos Stinis. Machine learning structure preserving brackets for
forecasting irreversible processes. Advances in Neural Information Processing Systems, 34, 2021.
Benedict J Leimkuhler and Robert D Skeel. Symplectic numerical integrators in constrained hamil-
tonian systems. Journal of Computational Physics, 112(1):117-125, 1994.
Shuo-Hui Li, Chen-Xiao Dong, Linfeng Zhang, and Lei Wang. Neural canonical transformation
with symplectic flows. Physical Review X, 10(2):021020, 2020.
Ziming Li, Bohan Wang, Qi Meng, Wei Chen, Max Tegmark, and Tie-Yan Liu. Machine-learning
non-conservative dynamics for new-physics detection. arXiv preprint arXiv:2106.00026, 2021.
Ziming Liu, Yunyue Chen, Yuanqi Du, and Max Tegmark. Physics-augmented learning: A new
paradigm beyond physics-informed learning. arXiv preprint arXiv:2109.13901, 2021.
Michael Lutter, Christian Ritter, and Jan Peters. Deep lagrangian networks: Using physics as model
prior for deep learning. arXiv preprint arXiv:1907.04490, 2019a.
Michael Lutter, Christian Ritter, and Jan Peters. Deep lagrangian networks: Using physics as model
prior for deep learning. arXiv preprint arXiv:1907.04490, 2019b.
Tomas Mikolov, Martin Karafidt, LUkas BUrgeL Jan Cernocky, and Sanjeev KhUdanpur. Recurrent
neural network based language model. In Interspeech, volume 2, pages 1045-1048. Makuhari,
2010.
Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves,
Nal Kalchbrenner, Andrew Senior, and Koray KavUkcUoglU. Wavenet: A generative model for
raw aUdio. arXiv preprint arXiv:1609.03499, 2016.
Feiyang Pan, Jia He, Dandan TU, and Qing He. TrUst the model when it is confident: Masked
model-based actor-critic. arXiv preprint arXiv:2010.04893, 2020.
EmanUel Todorov, Tom Erez, and YUval Tassa. MUjoco: A physics engine for model-based control.
In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, pages 5026-5033.
IEEE, 2012.
YUnjin Tong, Shiying Xiong, Xingzhe He, GUanghan Pan, and Bo ZhU. Symplectic neUral networks
in taylor series form for hamiltonian systems. Journal of Computational Physics, 437:110325,
2021.
TingwU Wang and Jimmy Ba. Exploring model-based planning with policy networks. arXiv preprint
arXiv:1906.08649, 2019.
Felix WU, AmaUri SoUza, Tianyi Zhang, Christopher Fifty, Tao YU, and Kilian Weinberger. Sim-
plifying graph convolUtional networks. In International conference on machine learning, pages
6861-6871. PMLR, 2019.
Shiying Xiong, YUnjin Tong, Xingzhe He, ShUqi Yang, Cheng Yang, and Bo ZhU. Nonseparable
symplectic neUral networks. arXiv preprint arXiv:2010.12636, 2020.
Yaofeng Desmond Zhong, Biswadip Dey, and Amit Chakraborty. Symplectic ode-net: Learning
hamiltonian dynamics with control. arXiv preprint arXiv:1909.12077, 2019.
11
Published as a conference paper at ICLR 2022
Yaofeng Desmond Zhong, Biswadip Dey, and Amit Chakraborty. Dissipative symoden: En-
coding hamiltonian dynamics with dissipation and control into deep learning. arXiv preprint
arXiv:2002.08860, 2020.
Yaofeng Desmond Zhong, Biswadip Dey, and Amit Chakraborty. Benchmarking energy-conserving
neural networks for learning dynamics from data. In Learning for Dynamics and Control, pages
1218-1229. PMLR, 2021a.
Yaofeng Desmond Zhong, Biswadip Dey, and Amit Chakraborty. Extending lagrangian and hamil-
tonian neural networks with differentiable contact models. Advances in Neural Information Pro-
cessing Systems, 34, 2021b.
12
Published as a conference paper at ICLR 2022
A	Appendix Outline
This appendix is organized as follows. In Section B, we present proofs for the energy conservation
properties of HNNs and Neural ODEs, as well as a more detailed description of symplecticity. In
Section C, we described the details of our experiments on Mujuco, including our data preprocessing,
training, and architectural decisions. Lastly, in Section D, we provide additional experimental results
requested by reviewers of our original submission. These include a comparison of alternative loss
functions and a comparison on additional rigid body systems.
B Mathematical Details
B.1 Energy Conservation for Neural ODEs
Let F = JVH be the ground truth dynamics of a time independent Hamiltonian, and F be the
dynamics learned by a neural network through an learned Hamiltonian H for HNNs or otherwise.
Given some initial condition zo, let ZT denote the solution to Z = F(Z) at time T starting from zo
and zT be the solution to the ground truth dynamics from z0 .
Suppose the error in the dynamics model e(Z) = F(Z) - F(Z) is bounded ∀Z : ke(Z)k < δ and that
we are only considering a bounded region of the state space (such as the states of a pendulum with
bounded energy).
Since energy is conserved H(Zt) = H(zo) = H(Zo), We can write the the energy error
(ZT
H(Zt) - H(zt) = H(Zt) - H(Zo) = /	VH(z)τdz
Jzo
Since the value is independent of the path, we may consider the path given by the approximated
dynamics Zt. Noting that dz/dt = F(Zt) = JVH(Zt) + e(zt), we have
T	dZ T
H(ZT) - H(ZT) =	VH(z)>Mdt =	VH(Zt)>F(Zt)dt
o	dt o
T
=/ [VH (Zt)TJ VH (Zt) + VH (Zt)> e(Zt)]dt
o
T
=/ VH (^t)Te(Zt)dt.
o
Bounding the maximum value of the integrand along the path, we have that
|H(Zt) — H(zt)| <Tδsup kVHk,
which grows only linearly with time.
(8)
This linear bound on the energy error is in stark contrast with the state error which could grow
exponentially according to the Lyapunov exponents, even if the dynamics error is arbitrarily small.
Advancing the ground truth and learned dynamics forward to some small time t = e, Ze = zo +
EF(zo) yields error ∣∣ze 一 Zek = ∣∣∈F(zo) — EF(zo)k = Eke(Z)Il < eδ. And yet, this error even if
propagated by the ground truth dynamics will grow exponentiallyk^T — ZT k ≈ eλTkZe- Zek =
eλT Eke(Z)k
B.2	HNN Energy Conservation
A simple but erroneous argument for why HNNs approximately conserve the true energy goes as
follows:
We would like to know if HNNs achieve better energy conservation given the same levels of error
in the predicted dynamics. For HNNs, F = JVH, and we can see that the dynamics error e(Z) can
also be written as e(Z) = JV(H - H).
If we could convert a bound on the derivatives ∣∣e∣∣ = ∣∣V(HH - H)k < δ (since J is an orthogonal
matrix) into a bound on the learned Hamiltonian itself E(Z) := H(Z) - H(Z) - c and |E| < ∆
13
Published as a conference paper at ICLR 2022
holding globally for some constant c, then we would have a constraint on the energy error that
doesn’t grow with time. Expanding the difference in initial and final energy, the constant c cancels
out and we have
. . . . ^ . ^ . . .
H(ZT) - H(Zo) = H(ZT) — H(Zo) - E(ZT) + E(Zo)
=-E(ZT) + E (Zo),
using the fact that the learned energy function H is conserved over the model rollout zt. If there Was
a constraint |E | < ∆ then
∣H(^t) - H(Zo)| < 2∆.
Unfortunately, even if the gradients are close and δ is small, that does not imply that ∆ is small.
Small differences in gradient can add up to very large differences in the values of the tWo functions.
While the dynamics may Well approximate the data, and achieve loW rollout error, there is no reason
to believe that at a given point in phase space the learned Hamiltonian should have a value that is
close to the true Hamiltonian.
B.3	Symplecticity
Symplecticity is the requirement that the dynamics satisfy (JDF)> = JDF. Defining G = JF,
the requirement is simply that the antisymmetric part of the jacobian is 0, DG> - DG = 0.
Unpacking Poincare’s lemma requires some familiarity With differential geometry concepts such as
differential forms and exterior derivatives, and so We Will assume them but for this section only.
Poincare’s lemma states that on a contractible domain (such as Rn) if a differential k-form ω is
closed dω = 0 (the exterior derivative of ω is 0) then it is also exact ω = dν (it is the exterior
derivative of another differential (k - 1)-form ν). While F is a vector field, G = JF is a differential
1-form (dual to a vector field). IfDG is symmetric, then itis also closed: dG = Pi ∂iGjdxi∧dxj =
2 Pi(∂iGj - ∂jGi)dxi ∧ dxj = 0 since (∂iGj - ∂jGi) = 0 is just another Way of expressing
DG> - DG = 0. Therefore by Poincare’s lemma, G = dφ for some 0-form (scalar function) φ.
Therefore F = J-1dφ = J d(-φ) since J-1 = -J. As the exterior derivative of scalar function
is just the gradient, We can define H = -φ and see that there exists a scalar function H such that
F = JVH.
C Mujoco Experiment Details
Data collection: for each control task We trained a standard soft actor-critic RL agent to convergence
(Haarnoja et al., 2018). Note that We had to use modified versions of the Gym environments since
the standard environments preprocess observations in ad-hoc Ways. For example, Hopper clips
the velocity observations to [-10, 10]d and truncates part of the position.2 Our versions of the
environments simply return [q, v] as the observation. Then We randomly split the episodes in the
replay buffer into train and test. The training data Was 40K 3-step trajectories (i.e. tWo transitions)
randomly sampled from the training episodes. The test data Was 200 200-step trajectories randomly
sampled from the test episodes. This data-collection strategy is important to the experiment because
random controls typically do not cause the agent to cover the entire state-action space. Similarly
many control policies are highly cyclical, so it is important to separate train and test splits at the
episode level.
Training: We trained each model for 256 epochs using Adam With a batch size of 200 and Weight
decay (λ = 1e-4). We used a cosine annealing learning rate schedule, With ηmax = 2e-4, ηmin =
1e-6.
Model Architecture Each netWork Was parameterized as a 2-layer MLP With 128 hidden units.
Each model used the Euler integration rule With 8 integration steps per transition step. The step size
was determined by the integration step size of the underlying environment, h = ∆t∕8.
NODE + SO: given the state Z and controls u, a standard NODE takes dZ/dt = f(Z, u, θ). HoWever,
ifZ = [q, v] (that is, if both position and velocity are observed), then we already have a good estimate
2https://github.com/openai/gym/blob/master/gym/envs/mujoco/hopper.py#L31
14
Published as a conference paper at ICLR 2022
of dq/dt in the observation itself, namely v. Hence we propose only using the network to model
acceleration dv/dt = f (z, u, θ), and to model dq/dt implicitly. It is important to note that we
cannot take dq/dt = v because v is observed before the control u is applied. Instead we take
dq/dt = v/2 + (v + h × dv/dt)/2, averaging the velocity at time t (before the control is applied)
and the predicted velocity at time t + 1 (after the control is applied), given an Euler integration step
of size h on v.
This integration rule can be viewed as an approximate RK2 step on qt , where vt+1 is approximated
via a learned Euler step on vt . This approach has two benefits. In the first place it constrains the
predicted velocity and acceleration to be consistent across time. Second the model is able to take an
approximate RK2 step on q at the cost of a single forward pass (instead of 2). The latter is important
because integration error can accumulate over long rollouts, even if the model fits the dynamics very
well.
D	Additional Experimental Results
D.1 Comparison of loss functions
In the experimental results presented in the body of the paper were obtained training on l2 loss
between integrated and ground truth trajectories. As noted in feedback the an early version of the
paper, this practice goes contrary to prior work using l1 loss for stability (Finzi et al., 2020). In
Figure 8 we show the result of changing the loss.
JaU0 Jnouoκ
-2
W
Cham ɑl loss) Chain (12 loss) Spnng ɑl loss) Sprmg (12 loss)
NODE	NODE + SO	HNN
Figure 8:	Switching from l2 to l1 loss can improve rollout error slightly, but doesn’t impact the
ordering of the models. The other elements of the experimental setup are identical to above. Error
bars show one standard deviation.
D.2 Additional Systems
To extend the comparison of NODE and HNN models, we trained models on three additional sys-
tems presented by Finzi et al. (2020). Figure 9 shows the rollout error of NODE, NODE + SO, and
HNN models. One the gyroscope system, we observe a similar result to the one above. In the magnet
pendulum and rotor systems, the results are slightly more counterintuitive, with the NODE model
outperforming the more sophisticated alternatives. We suspect the small difference in performance
in the models is due to the challenge of stably training HNNs in complex systems (with magnet
pendulum having complex dynamics and rotor having a complex coordinate system).
15
Published as a conference paper at ICLR 2022
JaUωJno=OH
Gyroscope
Magnet
Rotor
NODE
NODE + SO	HNN
Figure 9:	On the additional systems from Finzi et al. (2020), We can observe the effect of second
order structure, compared with NODE and HNN baselines. As before, second order structure seems
to account for much of the difference between NODE and HNN models. Error bars show one
standard deviation.
16