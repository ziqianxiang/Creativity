Published as a conference paper at ICLR 2022
Unifying Likelihood-free Inference with
Black-box Optimization and Beyond
Dinghuai Zhang1,2, Jie Fu1,2*, YOshua Bengio1,2,3, Aaron Courville1,2,3
1Mila, 2University of Montreal, 3CIFAR Fellow
Montreal, Canada
{dinghuai.zhang, fujie}@mila.quebec
Ab stract
Black-box optimization formulations for biological sequence design have drawn
recent attention due to their promising potential impact on the pharmaceutical
industry. In this work, we propose to unify two seemingly distinct worlds:
likelihood-free inference and black-box optimization, under one probabilistic
framework. In tandem, we provide a recipe for constructing various sequence
design methods based on this framework. We show how previous optimization
approaches can be “reinvented” in our framework, and further propose new prob-
abilistic black-box optimization algorithms. Extensive experiments on sequence
design application illustrate the benefits of the proposed methodology.
1	Introduction
Discovering new drugs to fulfill specific criteria, such as binding affinity towards a given molecular
target, is a fundamental problem in chemistry and the pharmaceutical industry (Hughes et al., 2011).
In this work, we focus on an important subdomain: de novo biological sequence design. This task is
challenging for two reasons: (1) the exploration space for sequences is combinatorially large; and (2)
sequence usefulness is evaluated via a complicated process which usually involves time-consuming
and expensive wet-lab experiments.
Despite the difficulty of this task, many approaches have been developed over the past few decades
thanks to recent advances in biochemistry and machine learning. The Nobel Prize wining paradigm,
directed evolution (Chen & Arnold, 1991), which conducts local evolutionary search under human
guidance, is one of the popular techniques. Unfortunately, it is limited by its sample inefficiency
and reliance on strong prior knowledge, e.g., about where to mutate (Ahn et al., 2020). Further-
more, to compete with other machine learning methods (Gottipati et al., 2020), guided evolution
(Yoshikawa et al., 2018; Jensen, 2019; Nigam et al., 2019) heavily relies on human intuition for
designing domain-specific evolutionary operators, which may not always apply to tasks at hand.
In this work, we deem sequence design to be a black-box optimization problem, tasked with maxi-
mizing an unknown oracle function. We assume that oracle queries are limited due to the constraint
on resources, such as the budgets for evaluating queries in a wet-lab. Thus, sample efficiency is
crucial. We develop a probabilistic framework by reformulating the aforementioned black-box opti-
mization target as a posterior modeling problem. With this framework, we draw a surprising connec-
tion between likelihood-free inference and sequence design, and thus linking two fields which are
previously considered as unrelated. The key observation we leverage here for establishing this con-
nection is that both settings share similar elements and targets which will be elaborated in Section
2.2. This connection facilitates our understanding of both fields and provides a recipe for developing
sequence design algorithms. Going beyond, we also combine different probabilistic modeling in-
sights and develop three novel composite probabilistic algorithms. We point out that our framework
could actually be applied to any black-box optimization settings, but in this work we focus on its
application to biological sequence design.
To demonstrate the empirical effectiveness of our methods, we conduct systematical experiments
to evaluate their performance on four in-silico sequence design benchmarks. Our proposed meth-
* Corresponding Author
1
Published as a conference paper at ICLR 2022
ods achieve at least comparable results to existing baselines, and the proposed composite methods
behave consistently better than all other ones across various sequence design tasks.
We summarize our contribution as follows:
•	We develop a probabilistic framework that unifies likelihood-free inference and black-box
optimization.
•	Based on this framework, we provide a recipe for designing algorithms for black-box prob-
lems. We apply these ideas to propose a series of composite design algorithms.
•	We perform systematical evaluation on a series of black-box sequence design benchmarks,
and find that these algorithms achieves consistently comparable or better results compared
to previous ones, thus illustrating the benefit of the proposed unified framework.
2	A Unifying Probabilistic Framework
2.1	Background
Likelihood-free inference (LFI). We use θ ∈ Θ and x ∈ X to separately denote the parameters
and the data generated via the mechanism X 〜p(x∣θ). In this scenario, LFI refers to a special kind
of Bayesian inference setting where the likelihood function is not tractable but sampling (by sim-
ulation) from the likelihood is feasible. Consider the objective of modeling the Bayesian posterior
when We cannot compute the likelihoodp(x0∣θ):
p(θ∣Xo) H p(θ) p(Xo∣θ),	(1)
X~^{z~}
?
where x° is the observed data, p(θ) is the (given) prior over the model parameters θ, p(x∣θ) is the
intractable likelihood function and p(θ∣x) is the desired posterior over θ. While we do not have
access to the exact likelihood, we can still simulate (sample) data X from the model simulator: X 〜
p(x∣θ). Instead of trying to obtain a numerical value of the generic posterior p(θ∣x) for arbitrary x,
LFI only tries to obtain an approximation of p(θ∣x0) for the given x°. During the inference process,
we can take advantage of the sampled data: D = {(θi, Xi)}n=ι where Xi 〜 p(x∣θi) for selected
values of θi .
Biological black-box sequence design. We consider biological sequence design as a black-box
optimization problem:
m* = arg max f (m),
m∈M
where f (∙) is the oracle score function, and we would like to discover values of m for which f (m)
is large. In real-world situations, a query of this oracle f could represent a series of wet-lab ex-
periments to measure specific chemical properties or specificity for a given binding site target. In
general, these experiments are time- and cost-consuming. As a result, the total number of queries is
limited.
In our setting, we use M = VL to denote the search space for sequences with fixed length L, where
V is the vocabulary for each entry of the sequence: for DNA nucleotides |V | = 4, and for protein
amino acids |V | = 20. For variable length setting, we have M = ∪L∈[Lmin,Lmax]VL, where Lmin and
Lmax are the minimal and maximal length, respectively.
2.2	Connecting LFI and black-box optimization
In order to draw a connection to LFI, we require a probabilistic formulation of the black-box se-
quence design problem. To this end, we relax the goal of searching for a single maximum of the
oracle / score function f to a posterior modeling problem, i.e., finding a representative sample of the
configurations of m sampled with probability related to some target posterior. Think of C is the set
of sequences with these desirable configurations, E is a Boolean event about whether a sequence m
belongs to C, and our goal is to characterize the posterior distributionp(m|E) from which we obtain
the desired sequences. Below, we consider two specific ways of doing this:
2
Published as a conference paper at ICLR 2022
Example A.	We explicitly define C (and E accordingly) as all the sequences whose scores are larger
than a given threshold s:
C = {m|f (m) ≥ s}.	(2)
Here s could be any fixed value, or a certain quantile of a particular score distribution. In this way,
We havep(E∣m) = p(m ∈ C|m) = l{f (m) ≥ s} where 1{} is the indicator function.
Example B.	In a softer version of E and C , we can define its conditional probability of being true
to follow a Boltzmann distribution:
p(E∣m) = p(m ∈ C|m) H exp(f (m)∕τ).	(3)
where T is a temperature parameter. We introduce the exponential because f (∙) does not necessarily
take positive values. Any monotone transformation of f (∙) to non-negative reals could be used, so
that sequences with larger oracle scores have a greater probability of making E true.
With this posterior objective, our goal now becomes effectively modeling and sampling from the
posterior p(m|E). It is thus natural to resort to the tools of Bayesian inference for this task. In
order to examine this possibility, we draw a detailed comparison between the settings of black-box
sequence design problem and likelihood-free Bayesian inference in Table 1.
	Likelihood-free inference	Black-box optimization
Element	(θ, x)		(m,S)	
Target		P(MXo)			P(m|E)	
Constraint	limited simulation: X 〜p(x∣θ)	limited query: S 〜 f(m)
	intractable likelihood: p(x∣θ)	black-box oracle: f (m)
Table 1: Correspondence between likelihood-free inference and black-box optimization.
It can be observed that both tasks share similar elements and targets. The two settings also share
similar limitations on the allowed queries, which are too time-consuming and / or cost-intensive.
Notice that in sequence design, the oracle could be either exact or noisy, thus we use the more
general S 〜 f (m) formulation rather than S = f (m). We will further present several concrete
examples as demonstrations of this correspondence in the following section.
Another way to understand this correspondence is to consider the following mapping T:
T : Θ ×X→M× R
(θ, x) 7→ (m, S),	s.t. S = - kx - xok .
Here we can see the score value S as a quantitative metric for how close the generated data x (given
θ) is to the target observed data xo . In addition, querying the oracle in the sequence design setting
can also be thought of as follows: (1) sample X 〜p(∙∣θ) and then (2) calculate S = -∣∣x — Xok
under some distance k∙∣∣. In this manner, T could conceptually transform any LFI problem into a
black-box optimization task. In this work, we only focus on the application of sequence design.
3	Methodology
We provide a recipe for designing new sequence design algorithms based on the correspondence in
Section 2.2. The recipe induces different approaches by modeling different probabilistic component
of the Bayesian inference problem. We begin with common algorithm restrictions under this setting.
Common constraint for algorithms. Due to the restriction of simulation / query in our setting,
we constrain our algorithms to act in a sequential / iterative way, gradually achieving the desired
posterior round by round. Every algorithm starts with an empty dataset D = 0 and an initial
proposal pι(∙) = p(∙), where p(∙) is the prior given by the task. In the r-th round of this multi-round
setting, the algorithm would use the proposal Pr (∙) of this round to sample a batch of data (θ / m)
for simulation / query, and augment the current dataset D with the newly obtained batch of data. We
use n to denote the batch size for each round’s simulation / query. Afterwards, the algorithm updates
3
Published as a conference paper at ICLR 2022
the proposal to pr+ι(∙). The outcomes for the two settings We discuss may be slightly different: an
algorithm for likelihood-free inference would return the posterior, while a sequence design method
would return the dataset of all the sequences it has queried, which hopefully contains desired high
scored sequences. On the other hand, a sequence design method could produce as an intermediate
result a generative model for sampling queries, which then completely fits with the LFI framework.
3.1	Backward modeling of the mechanism
Approximate Bayesian Computation (ABC) (Beaumont et al., 2002) is a standard method for tack-
ling LFI problems. In Algorithm 1, we display one of the most popular variants: Sequential Monte
Carlo-Approximate Bayesian Computation (SMC-ABC) (Beaumont et al., 2009). In each round, pa-
rameters θ are sampled from the current proposal distribution pr (θ) for simulation. A rejection step
is then involved to remove the θi whose simulation outcomes xi cannot reproduce the observed data
xo with sufficient accuracy. The remaining accepted {θi}i are adopted to update the next round’s
proposal Pr+ι(∙) towards the target posterior, i.e., by refitting q© with the modified data. We defer
more details of this approach to Section A.1 in Appendix.
Algorithm 1 SMC-ABC	Algorithm 2 FB-VAE
Pι(θ) - p(θ);	pι(m) J p(m);
for r in 1 to R do	for r in 1 to R do
repeat	repeat
sample θi 〜Pr (θ);	sample mi 〜Pr (m);
simulate Xi 〜p(xg);	query the oracle: si J f(mi);
until n samples are obtained	until n samples are obtained
D-D∪{(θi, Xi )}n=ι	DJD∪{(mi,si)}in=1;
sort D according to -kXi - Xo k;	sort D according to si
fit qφ(θ) with top {θi}i in D;	fit qφ(m) with top {mi}i in D;
pr+1(θ) J qφ(θ);	Pr+1 (m) J qφ(m);
end for	end for
return P(θ∣Xo) = Pr+i(Θ)	return {m : (m, s) ∈ D}
It would then be natural to construct an analogical sequence design algorithm using top scored
entities {mi}i to guide the update ofa certain sequence distribution, see Algorithm 2. Interestingly,
this is the proposed sequence design algorithm in Gupta & Zou (2019), where the authors name this
kind of updating “feedback” because training of the parametric generator qφ(m) exploits feedback
signals from the oracle. In this paper, we follow Brookes & Listgarten (2018) to crystallize qφ(m)
to be a variational autoencoder (Kingma & Welling, 2014), and use the term Feedback-Variational
AutoEncoder (FB-VAE) to refer to Algorithm 2. We place Algorithm 1 & 2 side-by-side to highlight
their correspondence. We also make the same arrangement for the following Algorithm 3 & 4,
Algorithm 5 & 6 and Algorithm 7 & 8.
Algorithm 3 Sequential Neural Posterior	Algorithm 4 Design by Adaptive Sampling
Pl(θ) J p(θ); for r in 1 to R do repeat sample θi 〜Pr(θ); simulate Xi 〜p(x∣θi); until n samples are obtained DJD∪{(θi,Xi)}in=1; q© J argmi%Ex [DκL(p(θ∣x)∣∣q)]; Pr+ι(θ) J qφ(θ∣Xo); end for return P(θ∣x°) = Pr+i(Θ)	Pi(m) J p(m); for r in 1 to R do repeat sample mi 〜Pr (m); query the oracle: si J f(mi); until n samples are obtained D J D ∪ {(mi, si)}in=1; q© J arg minq DKL(P(m|E)kq); Pr+1 (m) J q©(m); end for return {m : (m, s) ∈ D}
In comparison with SMC-ABC, the Sequential Neural Posterior (SNP) method (Papamakarios &
Murray, 2016; Lueckmann et al., 2017; Greenberg et al., 2019) for likelihood-free inference adopts
a more flexible approach, taking the power of conditional neural density estimator (e.g., Papamakar-
ios et al. (2017)) to model the general posterior p(θ∣x), which takes arbitrary θ and X as two in-
puts and outputs a distribution. This neural estimator is trained via approximately minimizing the
4
Published as a conference paper at ICLR 2022
KUllback-Leibler (KL) divergence between qφ(θ∣x) and the true posterior p(θ∣x). We defer more
training details to Section A.1 in Appendix. Under the connection viewpoint, one similar algorithm
for sequence design is the Design by Adaptive Sampling (DbAS) proposed in Brookes & Listgarten
(2018) which is characterized in Algorithm 4, fitting qφ(m) through minimizing the KL divergence
with the posterior p(m|E). Based on the difference in specific implementations, both algorithms
have more than one variant, whose details are deferred to Section A.1 in Appendix.
We refer to the above algorithms as “backward modeling” because the trained generative network
qφ (going from x/E to θ/m) is a sort of reverse model of the simulation mechanism (which goes
from θ/m to x/s).
3.2	Forward modeling of the mechanism
Whereas the above methods focus on directly modeling the target posterior with a generative model
that learns a “reverse mechanism” of the simulation process, it is also possible to model the “forward
mechanism”, which is consistent with the simulation process. Papamakarios et al. (2019) claim that
the forward modeling approach may be an easier task than its backward counterpart, as unbiased
estimation of the likelihood does not depend on the choice of proposal. Consequently, in contrast to
SNP, Papamakarios et al. (2019) chooses to train a neural density estimator to model the conditional
likelihood distribution qφ(x∣θ) sequentially in each round. The training is achieved by maximizing
the total log likelihood maxq Pi log qφ(xi∣θi) with data samples from the dataset D at the current
(r-th) round. The downside of this forward approach is an additional computational Markov Chain
Monte Carlo (MCMC) step is needed to sample from the r-th round posterior / proposal pr (θ). The
resulting approach, which is coined (Papamakarios et al., 2019) the Sequential Neural Likelihood
(SNL), is summarized in Algorithm 5.
In the spirit of directly modeling the forward mechanism of sequence design, we train a regressor
fφ(m) in a supervised manner to fit the oracle scorer. In order to adapt this regressor into the update
procedure of the proposal of the next round, We use q(m) to denote the unknown posterior p(m∣E)
with knowledge of fφ(m) and prior p(m). The specific construction of q(m) depends on the choice
of E. For instance, if we choose Example B in Section 2.2 to be the definition of E, then q(m) is the
distribution with (unnormalized) probability p(m) ∙exp(fφ(m)/τ). See Section A.2 in Appendix for
more elaboration about this point. We then choose the update procedure of the proposal pr+1 (m) to
be analogical to that of SNL. We name this proposed algorithm to be Iterative Scoring (IS) to avoid
confusion with likelihood-free inference algorithms. Furthermore, depending on different definition
ofE, we use the name “IS-A” and “IS-B” for them in the following sections.
Algorithm 5 Sequential Neural Likelihood
Pι(θ) - p(θ);
for r in 1 to R do
repeat
sample θi 〜Pr (θ);
simulate Xi 〜p(x∣θi);
until n samples are obtained
D-D∪{(θi, Xi )}n=ι
fit qφ(x∣θ) with D;
Pr+l(θ) Z p(θ) ∙ qφ(Xo∣θ);
end for
return P(θ∣Xo) = Pr+i(Θ)
Algorithm 6 Iterative Scoring
Pi (m) - p(m);
for r in 1 to R do
repeat
sample mi 〜Pr (m);
query the oracle: Si J f (mi);
until n samples are obtained
DJD∪{(mi,si)}in=1;
fit fφ(m) with D;-
construct q(m) with fφ(∙) andp(m);
Pr+i(m) J ⅞(m);
end for
return {m : (m, s) ∈ D}
3.3	Modeling a probability ratio
In this subsection, we discuss yet another approach, through the estimation of a probability ratio.
Gutmann & Hyvarinen (2010) proposes noise contrastive estimation as a statistical inference ap-
proach. This methodology turns a hard probability modeling problem into binary classification,
which is considered easier to learn. In contrast to the aforementioned likelihood-free inference
methods which rely on a form of density estimation to perform the task, Sequential Neural Ratio
5
Published as a conference paper at ICLR 2022
(SNR) (Hermans et al., 2019) takes a similar approach as noise contrastive estimation. SNR adopts a
classification approach to estimate the likelihood-to-evidence ratio r(θ, x) = p(θ∣x)∕p(θ). SNR is
summarized in Algorithm 7. Specifically, in each round, SNR fits a binary classifier dφ (θ, x) ∈ [0, 1]
in the following manner:
arg min	(θ )∈D [- log d(xi, θi)] +	(θ0 )∈D0 [- log(1 - d(xi, θi0))] .	(4)
d	( i ,xi )∈D	( i ,xi )∈D
We show that with the D and D0 established in Algorithm 7, we have
d*(θ, x)=
p(θ∣χ)
p(θ) + p(θ∣χ)
r*(θ, x)
d*(θ, x)	p(θ∣x)
1 - d产(θ, x) = p(θ)
where the “*" denotes the optimality. We have the following Proposition 1:
Proposition 1. Letp0(a) andp1(a) be two distributions for da-dimension random variable a which
takes value in the space of A = Rda, and d(a) : A → [0, 1] is a real-value function mapping any a
to a positive real value number. Then the functional optimization problem
arg max {Ea~p0 (a) [log d(a)] + Ea~pι(a) [log(1 - d(a))]}.
d=A-[0,1]
will lead to the optimal solution d*(a)
P0(a)
Po (a)+Pi(a)
See the proof in Section A.3 in Appendix. After training d, SNR can obtain the posterior density
value by p(θ∣x) = r*(θ, x)p(θ). SNR mirrors SNL in that it samples the new proposal pS)
without explicitly modeling the posterior.
On the other hand, we propose a sequence design algorithm analogous to SNR and named Iterative
Ratio (IR), which estimates the probability ratio r(m) = p(m|E)/p(m) for the purpose of poste-
rior sampling. IR first builds two datasets D and D0, corresponding to two different distributions
p(m|E) and p(m). We take a similar binary classification approach, whose training objective is
mind Pm∈D [- log d(m)] + Pm∈D0 [- log(1 - d(m))] . The desired ratio is then obtained by
r(m) := d(m)/(1 - d(m)). Other components of IR follow the scheme of IS, and IR is schema-
tized in Algorithm 8. We point out that IR does not have two variants as IS does, as the definition for
E in Example B is not usable because of the unknown normalizing constant for probability p(E |m).
See Section A.3 in Appendix for more explanation.
Algorithm 7 Sequential Neural Ratio	Algorithm 8 Iterative Ratio
Pl(θ) - p(θ);	pι(m) J p(m);
for r in 1 to R do	for r in 1 to R do
repeat	repeat
sample θi, θ0 〜Pr (θ);	sample mi 〜Pr (m);
simulate Xi 〜p(x∣θi);	query the oracle: si J f(mi);
until n samples are obtained	until n samples are obtained
D-D∪{(θi, Xi)}以ι	D J D ∪ {(mi, si)}in=1;
D0 -D0∪{(θ0, xi)}itι	construct D with m in D satisfying E;
train dφ(θ, x) classifying between D and D0	construct D0 fromp(m);
with the loss in Eq. 4;	train dφ(m) classifying between D and D0;
rΦ(θ, X) J 1⅛θ⅛);	rΦ(m) J ι-dφm1);
Pr+l(θ) Z rφ(θ, x) ∙ p(θ);	Pr+ι(θ) z rφ(m) ∙p(m);
end for	end for
return P(θ∣xO) = Pr+i(Θ)	return {m : (m, s) ∈ D}
Interestingly, a recent SNR-like work, EG-LF-MCMC (Begy & Schikuta, 2021), proposes to train
the classifier on tuples of (θ, = kx - xok) instead of (θ, x). This algorithm can be also seen as a
more precise analogy of our Iterative Ratio in the LFI context, as we have pointed out in Section 2.2
that a conceptual link could be drawn between s and -kx - xo k.
6
Published as a conference paper at ICLR 2022
3.4	Composite probabilistic methods
Building on the above analogies and framework, we move beyond the above algorithms in this
subsection. The previous lines of approach - the direct posterior modeling methods in Section 3.1
and the indirect methods in Section 3.2 and 3.3 - both have their own advantages and disadvantages.
The former methods may fail to get accurate inference result due to unmatched proposals, while the
latter ones would need extra large amount of computation for the MCMC sampling process before
obtaining accurate posterior samples, etc. Here we study composite algorithms that combine the
aforementioned ingredients through the lens of our proposed unified framework. Our goal is to
combine the strengths from both kinds of methods.
We first introduce Iterative Posterior Scoring (IPS) method illustrated in Algorithm 9. IPS also
uses a neural network fφ(m) to model the forward mechanism as IS does, and again we use q here
to denote the target posterior p(m|E). Instead of applying computational MCMC steps here, we
train a second parametrized model qψ to model q by minimizing the KL divergence between them.
Notice that the optimization of qψ is restricted within a neural network parameterization family. As
a result, in the next round, we can directly utilize qψ (m) to serve as a flexible generative proposal
of pr+1(m). Like IS, the IPS algorithm also has two different variants with regard to different
choices ofE, we name them to be IPS-A and IPS-B. Two choices differ in the detailed construction
of distribution q(m).
In a similar spirit, we propose the Iterative Posterior Ratio (IPR) algorithm (see Algorithm 10). IPR
is close to the IR algorithm in many aspects, but also adopts a second neural network model qψ (m)
like IPS. IPR works similarly to IR, in that we also construct q(m), taking advantage of rΦ(m) and
the prior p(m) simply via q(m) J rφ(m) ∙ p(m). Note that the usage of two models in IPR is not
exactly the same as in IPS: qψ (m) is also achieved via minimizing KL divergence with q(m), but
the training of model dφ(m) is closer to that in IR rather than the fφ(m) in IS. Another similarity
between IPR and IR is that IPR also only has one variant, since the Example B is not applicable for
this ratio modeling approach (see Section A.4 in Appendix for more details).
Algorithm 9 Iterative Posterior Scoring
pι(m) J p(m);
for r in 1 to R do
repeat
sample mi 〜Pr (m);
query the oracle: si J f(mi);
until n samples are obtained
DJD∪{(mi,si)}in=1;
fit fφ(m) with D;
construct q(m) with fφ(∙) andp(m);
qψ J argmi% DκL(q(m)kq);
pr+1 (m) J qψ (m);
end for
return {m : (m, s) ∈ D}
Algorithm 10 Iterative Posterior Ratio
pι(m) J p(m);
for r in 1 to R do
repeat
sample mi 〜Pr (m);
query the oracle: si J f(mi);
until n samples are obtained
D J D ∪ {(mi, si)}in=1;
construct D with m in D satisfying E;
construct D0 fromp(m);
train dφ(m) classifying between D and D0;
rΦ(m)J ι-dφ1⅛;
construct q(m) with rφ(m) andp(m);
qψ J argmi% DκL(q(m)∣∣q);
Pr+1 (m) J qψ(m);
end for
return {m : (m, s) ∈ D}
4	Experiments
4.1	Setup
In this section, we systematically evaluate the proposed methods and baselines on four different
in-silico biological sequence design benchmarks. In every round, we allow each algorithm to query
the black-box oracle for a batch of n sequences mi to obtain their true scores si, with n = 100 for
all experiments. The total number of rounds differs across different tasks.
We experiment with our six proposed methods: Iterative Scoring (-A/B) from Section 3.2, Iterative
Ratio from Section 3.3, Iterative Posterior Scoring (-A/B) and Iterative Posterior Ratio from Sec-
7
Published as a conference paper at ICLR 2022
IS-A ——IS-B ——IR ——IPS-A ——IPS-B ——IPR ——Random ——Evolution ——DbAS	FB-VAE
aioɔs O--A-OH
KLF11 R402Q R1
PBX4 REF R2
CRX E80A R1
2	4	6	8	10	2	4	6	8	10	2	4	6	8	10
Round	Round	Round
Round	Round	Round
Figure 1: ToP score (y-axis) curves of different methods on 3 TfBind problems (KLF11_R402Q_R1,
PBX4_REF_R2 and CRX_E80A_R1) with regard to the number ofrounds.
	IS-A	IS-B	IR	IPS -A	IPS -B	IPR	Random	Evolution	DBAS	FB -VAE
TOP-10	8.43	6.93	4.79	6.21	8.36	7.00	1.14	4.36	5.07	2.71
TOP- 100	9.57	7.93	4.07	6.71	7.64	6.00	1.00	5.50	4.57	2.00
Table 2: Mean rank of evaluated algorithms with regard to the area under the top score curve for
TfBind problems. The rank ranges from 1 to 10. Higher rank is better.
tion 3.4. Apart from these proposed methods, we consider as baselines a battery of existing methods
designed for batched black-box sequence design tasks: (1) Random, a method that randomly se-
lect proposal sequences at every round; (2) FB-VAE (Gupta & Zou, 2019) depicted in Section 3.1;
(3) Evolution based (Brindle, 1980; Real et al., 2019) sequence design algorithm; and (4) DbAS
(Brookes & Listgarten, 2018), described in Section 3.1.
We evaluate these sequence design algorithms by the average score of the top-10 and top-100 se-
quences in the resulting dataset D at each round. We plot the average score curves with regard to the
number of rounds. We also use the area under the curve as a scalar metric for sample efficiency to
compare the methods being evaluated. Specifically, since the area depends on the choice of x-axis,
we simply cumulate the scores of all rounds to calculate the area. The result could be non-positive,
since the score can take negative values.
4.2	Results
Transcription factor binding sites (TfBind). Protein sequences that bind with DNA sequences to
adjust their activity are called transcription factors. In Barrera et al. (2016), the authors measure
the binding properties between a battery of transcription factors and all possible length-8 DNA
sequences through biological experiments. Concretely, we choose 15 transcription factors to serve
as 15 different tasks. For each transcription factor, the algorithm needs to search for sequences
that maximize the corresponding binding activity score. The size of the search space is |V |L =
48 = 65536. The number of total rounds is fixed to 10. For validation, We follow Angermuller
et al.(2020b) and use one task (ZNF200_S265Y_R1) for hyperparameter selection. Then we test the
algorithms’ performance on the other 14 held-out tasks.
Figure 1 displays a comparison for all ten methods on three of the chosen binding affinity tasks.
We can observe that after 10 rounds, our proposed methods perform consistently better than the
8
Published as a conference paper at ICLR 2022
IS-A —IS-B - IR ——IPS-A	IPS-B ——IPR ——Random —Evolution ——DbAS	FB-VAE
4	6	8	10
Round
Figure 2: Top score (y-axis) curves of different methods on 3 sequence design problems (left: UTR,
middle: AMP, right: Fluo) with regard to the number of rounds.
	IS-A	IS-B	IR	IPS -A	IPS -B	IPR	Random	Evolution	DBAS	FB -VAE
== UTR	8.46	9.61	9.03	10.04	10.19	9.52	8.12	9.23	9.59	8.20
AMP	-5.67	-5.11	-5.37	-4.65	-4.39	-5.42	-5.96	-5.79	-5.39	-5.54
Fluo	32.76	33.33	32.95	44.51	43.13	42.42	31.64	35.44	41.40	32.52
Table 3: Comparison of the area under top-100 curves for UTR, AMP and Fluo benchmarks. Larger
area means better sample efficiency.
backward modeling methods like DbAS and FB-VAE in terms of both Top-10 and Top-100 scores.
Among all baselines, the evolution method is the strongest one, and it beats IR on some of the tasks
(see complete results in Table 4 and 5 in Appendix). We also find that IS-A and IS-B increase top
scores slightly faster than other methods, especially on PBX4_REF_R2 and CRX_E80A_RL This
indicates that composite methods’ way of using parameterized models to replace computational
procedures is not the optimal solution for small-scale tasks.
5’ untranslated regions (UTR). The translation efficiency is mainly determined by the sequence
of 5’ UTR (Alipanahi et al., 2015). In Sample et al. (2019), the authors create a library of gene
sequences with ribosome loading level as labels. They further train a convolutional neural network
with this library to predict the relationship between a 5’UTR sequence and the corresponding gene
expression level. We use this neural network as an oracle for this benchmark. The length of the gene
sequences is fixed to 50, and thus the size of the search space is 450. For this 5’UTR benchmark,
we also allow each algorithm to explore for 10 rounds. Figure 2 (left) shows that our proposed
composite methods significantly outperform other methods on the UTR task. Different from the
results on the TfBind task, forward modeling methods do not achieve the best performance.
Antimicrobial peptides (AMP). Protein modeling has recently become a popular sub-area of ma-
chine learning research. We are tasked to generate AMP sequences, which are short protein se-
quences against multi-resistant pathogens. We train a binary classifier model to classify whether a
short protein sequence belongs to AMP and defer the related details to Appendix. This is the only
task we consider regarding sequence design with alterable lengths, where the length of sequences
ranges from 12 to 60. Since each entry of protein sequence has |V | = 20 different choices on amino
acids, the size of search space is P6L0=12 20L. We set the number of total rounds to be 15 for this
task. Figure 2 (middle) clearly shows that the performances of IPS-A and IPS-B dominate the AMP
generation task, which demonstrates the effectiveness of our composite strategy.
9
Published as a conference paper at ICLR 2022
Fluorescence proteins (Fluo). As another protein engineering task, we consider the optimization
over fluorescent proteins, which is a commonly used test bed of modern molecular biology. This
task is similar to the AMP task introduced above, but its ground-truth measurement relies on a
regressor. We use a pretrained model taken from Rao et al. (2019) to act as our task oracle, which
is a regressor trained to predict log-fluorescence intensity value over approximately 52,000 protein
sequences of length 238 (Sarkisyan et al., 2016). More concretely, the regressor is fit on a small
neighborhood of parent green fluorescent protein, and is then evaluated on a more distant protein.
The training data is derived from the naturally occurring GFP in Aequorea victoria. The task Fluo’s
search space is 20238 and we set the number of rounds to 20. We demonstrate the Fluo results in
Figure 2 (right), where we can see both composite methods and DbAS achieve much better results
than other approaches. This might signify that for long sequence design tasks, backward modeling
is superior to other modeling methods, which is not consistent with LFI (Papamakarios et al., 2019).
We also summarize the sample efficiency results for the latter 3 benchmarks in Table 3 and 6, from
which we can see that our proposed three composite methods perform remarkably promising results.
5 Conclusion
We propose a probabilistic framework that unifies likelihood-free inference and black-box optimiza-
tion for designing biological sequences. This unified perspective enables us to design a variety of
novel composite probabilistic sequence design methods combining the best of both worlds. Exten-
sive experiments have demonstrated the benefits of the unified perspective. While the composite
probabilistic methods usually outperform other baseline methods in most sequence design tasks we
consider in this work, the key contribution of our paper is not just about the superiority of those com-
posite methods, as different specific tasks might prefer different algorithmic configurations due to
no free lunch theorem (Wolpert & Macready, 1997). Actually, we would like to attribute the strong
performance to the unified probabilistic framework, which enables us to develop a richer algorithm
pool, based on which we can design performant algorithms for particular sequence design tasks.
Acknowledgement
The authors would like to thank Christof Angermueller, Yanzhi Chen, Michael Gutmann, and anony-
mous reviewers for helpful feedbacks. Jie Fu thanks Microsoft Research Montreal for funding his
postdoctoral position at University of Montreal and Mila. Yoshua Bengio acknowledges the fund-
ing from CIFAR, Samsung, IBM and Microsoft. Aaron Courville thanks the support of Samsung,
Hitachi and CIFAR.
References
Sungsoo Ahn, Junsu Kim, Hankook Lee, and Jinwoo Shin. Guiding deep molecular optimization
with genetic exploration. ArXiv, abs/2007.04897, 2020.
Babak Alipanahi, Andrew Delong, Matthew T Weirauch, and Brendan J Frey. Predicting the se-
quence specificities of dna-and rna-binding proteins by deep learning. Nature biotechnology, 33
(8):831-838,2015.
Christof Angermuller, David Belanger, Andreea Gane, Zelda E. Mariet, David Dohan, Kevin MUr-
phy, Lucy J. Colwell, and D. Sculley. Population-based black-box optimization for biological
sequence design. In ICML, 2020a.
Christof AngermUller, David Dohan, David Belanger, Ramya Deshpande, Kevin Murphy, and
Lucy J. Colwell. Model-based reinforcement learning for biological sequence design. In ICLR,
2020b.
Luis A. Barrera, Anastasia Vedenko, Jesse V. Kurland, Julia M Rogers, Stephen S. Gisselbrecht,
Elizabeth J Rossin, Jaie C. Woodard, Luca Mariani, Kian Hong Kock, Sachi Inukai, Trevor Sig-
gers, Leila Shokri, RalucaGordan, Nidhi Sahni, Chris CotsaPas, Tong Hao, S. Stephen Yi, Mano-
lis Kellis, Mark J. Daly, Marc Vidal, David E. Hill, and Martha L. Bulyk. Survey of variation
in human transcription factors reveals prevalent dna binding changes. Science, 351:1450 - 1454,
2016.
10
Published as a conference paper at ICLR 2022
M. Beaumont, Wenyang Zhang, and D. Balding. Approximate bayesian computation in population
genetics. Genetics,162 4:2025-35, 2002.
M. Beaumont, J. Cornuet, J. Marin, and C. Robert. Adaptive approximate bayesian computation.
Biometrika, 96:983-990, 2009.
Volodimir Begy and Erich Schikuta. Error-guided likelihood-free mcmc. 2021 International Joint
Conference on Neural Networks (IJCNN), pp. 1-7, 2021.
Michael G. B. Blum. Approximate bayesian computation: A nonparametric perspective. Journal of
the American Statistical Association, 105:1178 - 1187, 2009.
Johann Brehmer, Gilles Louppe, Juan Pavez, and Kyle Cranmer. Mining gold from implicit models
to improve likelihood-free inference. Proceedings of the National Academy of Sciences, 117:5242
- 5249, 2020.
A. Brindle. Genetic algorithms for function optimization. 1980.
David H. Brookes and J. Listgarten. Design by adaptive sampling. ArXiv, abs/1810.03714, 2018.
David H. Brookes, Hahnbeom Park, and Jennifer Listgarten. Conditioning by adaptive sampling for
robust design. In ICML, 2019.
Jeffrey Chan, Valerio Perrone, Jeffrey P. Spence, Paul A. Jenkins, Sara Mathieson, and Yun S. Song.
A likelihood-free inference framework for population genetic data using exchangeable neural
networks. bioRxiv, 2018.
K. Chen and F. Arnold. Enzyme engineering for nonaqueous solvents: Random mutagenesis to
enhance activity of subtilisin e in polar organic media. Bio/Technology, 9:1073-1077, 1991.
Yanzhi Chen and Michael U. Gutmann. Adaptive gaussian copula abc. ArXiv, abs/1902.10704,
2019.
Yanzhi Chen, Dinghuai Zhang, M. Gutmann, Aaron C. Courville, and Zhanxing Zhu. Neural ap-
proximate sufficient statistics for implicit models. ArXiv, abs/2010.10079, 2021.
P. T. de Boer, Dirk P. Kroese, Shie Mannor, and Reuven Y. Rubinstein. A tutorial on the cross-
entropy method. Annals of Operations Research, 134:19-67, 2005.
Christopher C. Drovandi, Clara Grazian, Kerrie L. Mengersen, and Christian P. Robert. Approxi-
mating the likelihood in approximate bayesian computation. arXiv: Computation, 2018.
Ahmed Elnaggar, Michael Heinzinger, Christian Dallago, Ghalia Rihawi, Yu Wang, Llion Jones,
Tom Gibbs, Tamas Feher, Christoph Angerer, Martin Steinegger, et al. Prottrans: towards crack-
ing the language of life’s code through self-supervised deep learning and high performance com-
puting. arXiv preprint arXiv:2007.06225, 2020.
Paul Fearnhead and Dennis Prangle. Constructing summary statistics for approximate bayesian
computation: semi-automatic approximate bayesian computation (with discussion). 2012.
Rafael Gomez-Bombarelli, David Kristjanson Duvenaud, Jose MigUel Hernandez-Lobato, Jorge
Aguilera-Iparraguirre, Timothy D. HirzeL Ryan P. Adams, and Alan Aspuru-Guzik. Automatic
chemical design using a data-driven continuous representation of molecules. ACS Central Sci-
ence, 4:268 - 276, 2018.
Sai Krishna Gottipati, Boris Sattarov, Sufeng Niu, Yashaswi Pathak, Haoran Wei, Shengchao Liu,
Simon Blackburn, Karam Thomas, Connor Coley, Jian Tang, et al. Learning to navigate the
synthetically accessible chemical space using reinforcement learning. In International Conference
on Machine Learning, pp. 3668-3679. PMLR, 2020.
David S. Greenberg, M. Nonnenmacher, and J. Macke. Automatic posterior transformation for
likelihood-free inference. ArXiv, abs/1905.07488, 2019.
11
Published as a conference paper at ICLR 2022
Gabriel Lima Guimaraes, Benjamin Sanchez-Lengeling, Pedro LUis CUnha Farias, and Alan Aspuru-
Guzik. Objective-reinforced generative adversarial networks (organ) for sequence generation
models. ArXiv, abs/1705.10843, 2017.
Anvita Gupta and J. Zou. Feedback gan for dna optimizes protein functions. Nature Machine
Intelligence ,1:105-111,2019.
Michael U. Gutmann and AaPo Hyvarinen. Noise-contrastive estimation: A new estimation princi-
ple for unnormalized statistical models. In AISTATS, 2010.
Michael U. Gutmann, Ritabrata Dutta, Samuel Kaski, and Jukka Corander. Likelihood-free infer-
ence via classification. Statistics and Computing, 28:411 - 425, 2018.
Tatsunori B. Hashimoto, Steve Yadlowsky, and John C. Duchi. Derivative free optimization via
repeated classification. In AISTATS, 2018.
J. Hermans, Volodimir Begy, and Gilles Louppe. Likelihood-free mcmc with amortized approximate
likelihood ratios. arXiv: Machine Learning, 2019.
Sepp Hochreiter and JUrgen Schmidhuber. Long short-term memory. Neural Computation, 9:1735—
1780, 1997.
Jp Hughes, S. Rees, SB Kalindjian, and KL Philpott. Principles of early drug discovery. British
Journal of Pharmacology, 162, 2011.
Rafael Izbicki, Ann B. Lee, and Chad M. Schafer. High-dimensional density ratio estimation with
extensions to approximate likelihood computation. In AISTATS, 2014.
Jan H Jensen. A graph-based genetic algorithm and generative model/monte carlo tree search for
the exploration of chemical space. Chemical science, 10(12):3567-3572, 2019.
Diederik P. Kingma and M. Welling. Auto-encoding variational bayes. CoRR, abs/1312.6114, 2014.
Jian Ping Li, David J. Nott, Y. Fan, and Scott Anthony Sisson. Extending approximate bayesian
computation methods to high dimensions via a gaussian copula model. Comput. Stat. Data Anal.,
106:77-89, 2017.
Jarno Lintusaari, Michael U. Gutmann, Ritabrata Dutta, Samuel Kaski, and Jukka Corander. Funda-
mentals and recent developments in approximate bayesian computation. Systematic Biology, 66:
e66 - e82, 2017.
Ge Liu, Haoyang Zeng, Jonas Mueller, Brandon Carter, Ziheng Wang, Jonas Schilz, Geraldine
Horny, Michael E. Birnbaum, Stefan Ewert, and David Kenneth Gifford. Antibody complemen-
tarity determining region design using high-capacity machine learning. bioRxiv, 2020.
Jan-Matthis Lueckmann, Pedro J. Goncalves, G. Bassetto, Kaan Ocal, M. Nonnenmacher, and
J. Macke. Flexible statistical inference for mechanistic models of neural dynamics. In NIPS,
2017.
Jan-Matthis Lueckmann, Giacomo Bassetto, Theofanis Karaletsos, and Jakob H. Macke.
Likelihood-free inference with emulator networks. ArXiv, abs/1805.09294, 2018.
Jean-Michel Marin, Pierre Pudlo, Christian P. Robert, and Robin J. Ryder. Approximate bayesian
computational methods. Statistics and Computing, 22:1167-1180, 2012.
Kerrie L. Mengersen, Pierre Pudlo, and Christian P. Robert. Approximate bayesian computation via
empirical likelihood. 2012.
Daniel Neil, Marwin H. S. Segler, Laura Guasch, Mohamed Ahmed, Dean Plumbley, Matthew
Sellwood, and Nathan Brown. Exploring deep recurrent models with reinforcement learning for
molecule design. In ICLR, 2018.
AkshatKumar Nigam, Pascal Friederich, Mario Krenn, and Alan Aspuru-Guzik. Augmenting ge-
netic algorithms with deep neural networks for exploring the chemical space. arXiv preprint
arXiv:1909.11655, 2019.
12
Published as a conference paper at ICLR 2022
George Papamakarios and Iain Murray. Fast -free inference of simulation models with bayesian
conditional density estimation. In NIPS, 2016.
George Papamakarios, Iain Murray, and Theo Pavlakou. Masked autoregressive flow for density
estimation. ArXiv, abs/1705.07057, 2017.
George Papamakarios, D. Sterratt, and Iain Murray. Sequential neural likelihood: Fast likelihood-
free inference with autoregressive flows. In AISTATS, 2019.
Roshan Rao, Nicholas Bhattacharya, Neil Thomas, Yan Duan, Xi Chen, John Canny, Pieter Abbeel,
and Yun S Song. Evaluating protein transfer learning with tape. In Advances in Neural Informa-
tion Processing Systems, 2019.
Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V. Le. Regularized evolution for image
classifier architecture search. In AAAI, 2019.
Reuven Y. Rubinstein and Dirk P. Kroese. The cross-entropy method. In Information Science and
Statistics, 2004.
Tim Salimans, Jonathan Ho, Xi Chen, and Ilya Sutskever. Evolution strategies as a scalable alterna-
tive to reinforcement learning. ArXiv, abs/1703.03864, 2017.
Paul Sample, Ban Wang, David W. Reid, Vladimir Presnyak, Iain J Mcfadyen, David R. Morris,
and Georg Seelig. Human 5 utr design and variant effect prediction from a massively parallel
translation assay. Nature Biotechnology, 37:803-809, 2019.
Karen S Sarkisyan, Dmitry A Bolotin, Margarita V Meer, Dinara R Usmanova, Alexander S Mishin,
George V Sharonov, Dmitry N Ivankov, Nina G Bozhanova, Mikhail S Baranov, Onuralp Soyle-
mez, et al. Local fitness landscape of the green fluorescent protein. Nature, 533(7603):397-401,
2016.
Bobak Shahriari, Kevin Swersky, Ziyun Wang, Ryan P. Adams, and Nando de Freitas. Taking the
human out of the loop: A review of bayesian optimization. Proceedings of the IEEE, 104:148-
175, 2016.
Chence Shi, Minkai Xu, Zhaocheng Zhu, Weinan Zhang, Ming Zhang, and Jian Tang. Graphaf: a
flow-based autoregressive model for molecular graph generation. ArXiv, abs/2001.09382, 2020.
Nitish Srivastava, Geoffrey E. Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.
Dropout: a simple way to prevent neural networks from overfitting. J. Mach. Learn. Res., 15:
1929-1958, 2014.
Owen Thomas, Ritabrata Dutta, Jukka Corander, Samuel Kaski, and Michael U. Gutmann.
Likelihood-free inference by ratio estimation. arXiv: Machine Learning, 2016.
Minh-Ngoc Tran, David J. Nott, and Robert Kohn. Variational bayes with intractable likelihood.
Journal of Computational and Graphical Statistics, 26:873 - 882, 2015.
Laurens van der Maaten and Geoffrey E. Hinton. Visualizing data using t-sne. Journal of Machine
Learning Research, 9:2579-2605, 2008.
Daan Wierstra, Tom Schaul, Jan Peters, and Juergen Schmidhuber. Natural evolution strategies.
2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational
Intelligence), pp. 3381-3387, 2008.
Jacob Witten and Zack Witten. Deep learning regression model for antimicrobial peptide design.
BioRxiv, pp. 692681, 2019.
David H. Wolpert and William G. Macready. No free lunch theorems for optimization. IEEE Trans.
Evol. Comput., 1:67-82, 1997.
Simon N. Wood. Statistical inference for noisy nonlinear ecological dynamic systems. Nature, 466:
1102-1104, 2010.
13
Published as a conference paper at ICLR 2022
Zachary Wu, S B Jennifer Kan, Russell D Lewis, Bruce J. Wittmann, and Frances H. Arnold. Ma-
chine learning-assisted directed protein evolution with combinatorial libraries. Proceedings of the
National Academy ofSciences,116:8852 - 8858, 2019.
Kevin K. Yang, Zachary Wu, and Frances H. Arnold. Machine-learning-guided directed evolution
for protein engineering. Nature Methods, pp. 1-8, 2019.
Naruki Yoshikawa, Kei Terayama, Masato Sumita, Teruki Homma, Kenta Oono, and Koji Tsuda.
Population-based de novo molecule generation, using grammatical evolution. Chemistry Letters,
47(11):1431-1434, 2018.
Zhenpeng Zhou, Steven M. Kearnes, Li Li, Richard N. Zare, and Patrick F. Riley. Optimization of
molecules via deep reinforcement learning. Scientific Reports, 9, 2019.
14
Published as a conference paper at ICLR 2022
A More about Methodology
A. 1 Backward modeling of the mechanism
About SMC-ABC. In Algorithm 1, when we pick the top-m θ at the r-th round, the picked param-
eters actually follow such a distribution
rr
p(Θ∣Xo) (X XP1(Θ) ∙p(kx - Xok < e | θ) = ( XP1(Θ) ) ∙p(kx - Xok < e | θ)	(5)
l=1	l=1
where the e here is implicitly defined by how ”top” the selection process is, namely the ratio nm. As
a result, we point out that in Algorithm 1, another more complicated form of the last step pr+ι(θ)-
qφ(θ) is pr+1(θ) X qφ (θ)p(θ)/ Plrpl(θ), where an additional renormalizing term is involved. We
ignore this term and used the simpler alternative in order to keep our main text clean. We refer
interested readers to Beaumont et al. (2009) for more details.
About Sequential Neural Posterior. DefineP(X) = Rp(x∣θ)p(θ)dθ andP(X) = Rp(x∣θ)p(θ)dθ
for any arbitrary proposal distribution p(θ) which is not necessary to be the prior p(θ). What,s more,
we define p(θ∣x) = p(x∣θ)p(θ)/P(X) andp(θ∣x) = p(x∣θ)p(θ)∕p(x) to be the true posterior and
the proposal posterior.
Starting from the goal of approximating the true posterior,
arg min Ep(X)DKL (p(θ∣x)kq(θ∣x))]
q
arg max J ρ(x)dx Jp(θ∣x)
log q(θ∣x)dθ
arg max
q
/p(θ, x) log q(θ∣x)dθx
arg max Ep(θ,χ) [log q(θ∣x)]∙
q
It seems that we can directly train the parameterized neural density estimator qφ in a data driven
manner via maxφ Pilogqφ(θi∣xj where i is the index for data sample. When the number of
training samples as well as the parameterization family ofφ are large enough, the obtained qφ would
be close enough to the true posterior. This would require the data samples to follow (θi, Xi) 〜
p(θ, x) = p(θ)p(x∣θ). However, practically one uses a proposal p(θ) to first generate some {θi}i
and then generate {xi}i by simulation. When the proposal distribution p(θ) is not exactly the prior
distribution p(θ), the resulting qφ(∙∣∙) would be:
P(θ∣x) = p(θ∣x)
P(θ)p(x)
p(θ)P(x)
(X p(θlx) 票,
(6)
which is a biased estimation and is not what we want.
Three variants of SNP take different approaches to try to fix this bias. SNP-A (Papamakarios & Mur-
ray, 2016) first fits the biased proposal posterior p(θ∣x) in the aforementioned way and utilize the
relation in Eq. 6 to solve for an unbiased estimation. This approach is restricted to mixture of Gaus-
sian distribution family and thus has limited expressiveness. SNP-B (Lueckmann et al., 2017) uses
importance sampling to address this issue via maxφ E(χ,θ)〜p(x|e)p(e)
[p(θ) logqφ(θ |x)].
One
downside of this approach is the high variance involved by the importance weights p(θ)∕P(θ).
SNP-C (Greenberg et al., 2019) proposes to use reparameterize the proposal posterior by setting
qφ(θ∣x) = qφ(θ∣x)p(θ)Z^x) where Zφ(x) = R qφ(θ∣x)p(θ)dθ is the corresponding normalizing
factor for x. SNP-C then maximizes E(χ,θ)〜p(χ∣θ)p(θ) [log Jφ(θ | x)].
About Design by Adaptive Sampling. We aim to approximate the posterior via minimizing the KL
divergence:
15
Published as a conference paper at ICLR 2022
arg min DKL(p(m|E)kq(m))
q
arg max
q
p(m|E ) log q(m)dm
arg max
q
p(E |m)p(m) log q(m)dm
arg max Egg
q
p(m)
.q(m)
p(E |m) log q(m)
where q(m) could be any distribution of m. Brookes et al. (2019) takes this formulation. Brookes
& Listgarten (2018) only differs in the place that it ignores the denominator term. According to
Angermuller et al. (2020b), we choose the latter variant as one of our baselines because it is more
stable in practice. We refer interested readers to Brookes & Listgarten (2018) for more details.
Notice that we are not doing exactly the same things for LFI and black-box sequence design. Since
LFI models flexible posterior p(θ∣x) which is a distribution for arbitrary x, We can also choose
to model p(m|s) for arbitrary s. Nevertheless, in the neural network modeling, conditioning by a
scalar value is not an effective approach as the effect of low dimensional scalar value conditioning
may be covered by other high dimensional input. Therefore, we choose to directly model the target
posteriorp(m|E) with a single neural network.
A.2 Forward modeling of the mechanism
We still use p(θ) to denote an arbitrary proposal distribution andp(θ, x) := p(x∣θ)p(θ). Then we
have
arg minEp(θ) DKL (p(x∣θ)kq(x∣θ))]
q
arg max /p(θ)dθ /p(x∣θ)
log q(x∣θ)dx
argmax Ep(θ,χ) [log q(x∣θ)].
q
We point out that with much enough data and large enough expressiveness of the neural density
estimator parameterization family, no matter what proposal p(θ) is used to provide training samples
{(θi, Xi)}i ~ p(θ, x), We have the resulting q^(θ∖x) equals true likelihoodp(x∣θ) in the support of
the proposal. What SNL gives is an unbiased estimation and thus does not have the same problem
as SNP.
Now we elaborate the construction of q(m) in Iterative Scoring algorithm. Here we use the notation
q(m) to denote our approximation of the posterior p(m∖E). Notice that we want q(m) 8 p(m) ∙
p(E∖m). If we choose Example A to serve as the definition of event E, then the samples of q(m)
can be obtained in this way: (1) sample m from prior p(m) and (2) accept this sample if fφ (m)
is larger than threshold s, or otherwise reject it. Alternatively, if we choose Example B, we have
q(m) 8 p(m) ∙ exp(fφ(m)∕τ). Similar to SNL, we do MCMC sampling from this unnormalized
probability function.
A.3 Modeling a probability ratio
About Sequential Neural Ratio. Dataset D is generated in the way that (1) first sample θ 〜p(θ)
and (2) simulate X 〜p(x∖θ). Consequently, D follows the distribution p(θ)p(x∖θ) = p(θ, x). On
the other hand, the other dataset D0 generates θ and x in parallel and independent manner. Notice
here θ 〜p(θ) and X follows the marginal distribution: X 〜p(x) = Jp(θ)p(x∖θ)dθ.
Proof of Proposition 1.
Proof. We define a functional F to be the optimization objective:
F[d] = Ea~po(a)[log d(a)] + Ea~pι(a)[log(1 - d(a))]
16
Published as a conference paper at ICLR 2022
We calculate its functional derivative. For arbitrary function u and infinite small
u	-u
F[d + eu] - F[d] = Epo [log(I + e—)] + % [log(I + e )]
d	1-d
ɪ,	F [d + eu] — F [d]
e→0	e
We set the functional derivative to zero:
δF=0⇒竺=工
p1	1 - d
⇒ d(a) =	( p0(a)，、
p0(a) + p1 (a)
This optimal function d* apparently takes value in [0,1].
□
About Iterative Ratio. Notice that in Algorithm 8 we construct two datasets: D and D0 . To generate
D, we need to be able to pick some sequence samples m from D and make the selected ones follow
the posteriorp(m|E). This procedure will depend on our choice of event E. For Example A this is
easy, since we just need to filter out the sequences whose oracle value is smaller than the threshold.
However, for Example B, it is hard to do similar things, since given score value from D we only
know the unnormalized value of posterior probability, and cannot determine which sequence should
be filtered out. The construction of D0 which follows prior distribution p(m) is trivial.
A.4 Composite probabilistic methods
For IPS, the optimization with regard to the second parameterized model qψ (m) is
/
qψ
arg min DκL(⅞(m)kq)
q
arg max
q
q(m) log q(m)dm
arg max
q
p(m|E ) log q(m)dm
arg max
q
p(E |m)p(m) log q(m)dm.
The exact value of p(E |m) depends on different choices of configuration feature E in Section 2.2.
On the other hand, IPR, like IR, also only has one variant, which is with Example A:
qψ
arg min DκL(q(m)kq)
q
arg max
q
rφ(m)p(m) log q(m)dm,
which is a tractable optimization problem. Both IPR and IR are not fit for Example B since it cannot
provide an exact probability value and thus cannot be adopted to construct D.
B	More ab out Experiments
Random method uses no neural network model. FB-VAE uses a VAE model. The encoder of the
VAE first linearly transform one-hot input into a hidden feature which is 64 dimension, and then sep-
arately linearly transform to a 64-dimension mean output and 64-dimension variance output. The
decoder contains a 64×64 linear layer and a linear layer that maps the hidden feature to categorical
output. All other methods utilize bi-directional long short-term memory model (BiLSTM) (Hochre-
iter & Schmidhuber, 1997) with a linear embedding layer. Both the embedding dimension and the
hidden size of LSTM is set to 32. For composite methods that use two models, we use one-layer
LSTM for each of them. For the other algorithms that only use one LSTM, we set its number of
17
Published as a conference paper at ICLR 2022
Figure 3: Diversity visualization results for two TfBind tasks.
KLF11 R402Q R1 final sequences
	IS-A	IS-B	IR	IPS-A	IPS-B	IPR	Random	Evo.	DBAS	FB -VAE
= = POU6F2_REF_R1	9	7	3	5	10	8	1	4	6	2
KLF11_R402Q_R1	8	6	5	7	9	10	1	4	2	3
EGR2_R359W_R1	4	5	8	9	7	6	1	2	10	3
HOXD13_S316C_R1	8	10	3	4	7	9	1	5	6	2
HOXB7,K191R,R1	10	8	6	4	9	3	1	5	7	2
PBX4_REF_R2	10	9	8	7	5	4	1	6	2	3
GFnB_A204T_R1	8	7	3	4	9	10	1	6	5	2
FOXCLREF_R1	10	8	3	5	7	9	1	4	6	2
KLF1_REF_R1	6	4	7	9	8	10	3	1	2	5
SIX6_REF_R1	8	7	3	10	9	6	1	5	2	4
ARX_L343Q,R2	10	3	4	7	9	5	1	6	8	2
CRX_E80A_R1	9	10	7	5	8	2	1	6	3	4
ESX1,K193R,R1	9	6	3	5	10	8	1	4	7	2
VSX1,G160D,R1	9	7	4	6	10	8	1	3	5	2
Average	8.43	6.93	4.79	6.21	8.36	7.00	1.14	4.36	5.07	2.71
Table 4: Top-10 score ranking for the TfBind instances that we adopt. “Evo.” stands for the
evolution algorithm.
layers to be two. No Dropout (Srivastava et al., 2014) is used in LSTM models. In this way, the num-
ber of parameters of the VAE is slightly larger than that of the two layer BiLSTM, and all methods
(except Random) share similar model parameter size.
All the experiments are repeated with fifty random seeds and report the mean value (and also stan-
dard deviation in the figure plots). We set p(m) to be uniform prior for all tasks for simplicity,
which uniformly samples from the dictionary V for each entry of the sequence. For length alterable
task, we first uniformly sample the length between minimum length and maximum length and then
sample each entry.
We explain details about evolution based method mentioned in the main text, which can be seen as a
substantial example of directed evolution (Chen & Arnold, 1991). Like other model based methods,
Evolution also trains an LSTM regressor to predict the score of a sequence, which is further used
to assist in the reproduce procedure. The Evolution algorithm maintains a generation list through
the whole exploration process. In each round, the method mutates and reproduces the sequences to
enlarge the generation list, and then utilizes the learned regressor to select top sequences for the next
generation.
For validation, We follow (Angermuller et al., 2020b) and sweep each algorithm for fifty trials and
pick the best configuration. We tune learning rate and whether to re-initialize the optimizer for
each new round for all methods. We tune threshold for DbAS, FB-VAE and the methods that is
with Example A. For the other choice of E, we tune the temperature. For evolution, we tune the
number of offsprings for each sequence in generation list, the probability of substitution, insertion
and deletion. For TfBind we use ZNF200_S265Y_R1 for validation. For UtR, AMP and Fluo, since
we only have one oracle instance for each benchmark, we do not use a hold-out validation method.
18
Published as a conference paper at ICLR 2022
	IS-A	IS-B	IR	IPS-A	IPS-B	IPR	Random	Evo.	DBAS	FB -VAE
— = POU6F2_REF_R1	10	8	3	5	9	6	1	7	4	2
KLF11_R402Q_R1	10	7	4	8	9	6	1	5	3	2
EGR2,R359W,R1	7	8	4	10	5	9	1	3	6	2
HOXD13_S316C_R1	10	9	3	4	7	6	1	5	8	2
HOXB7,K191R,R1	10	9	3	6	8	4	1	5	7	2
PBX4_REF_R2	10	9	7	5	6	4	1	8	3	2
GFnB_A204T_R1	10	7	4	5	9	6	1	8	3	2
FOXCLREF_R1	10	7	4	8	6	9	1	5	3	2
KLF1_REF_R1	8	6	5	9	7	10	1	4	3	2
SIX6_REF_R1	9	7	5	10	8	4	1	6	3	2
ARX_L343Q_R2	10	7	4	8	9	3	1	6	5	2
CRX_E80A_R1	10	9	5	7	8	4	1	6	3	2
ESX1,K193R,R1	10	9	3	4	8	6	1	5	7	2
VSX1_G160D_R1	10	9	3	5	8	7	1	4	6	2
Average	9.57	7.93	4.07	6.71	7.64	6.00	1.00	5.50	4.57	2.00
Table 5: Top-100 score ranking for the TfBind instances that we adopt. “Evo.” stands for the
evolution algorithm.
		IS-A	IS-B	IR	IPS-A	IPS-B	IPR	Random	Evolution	DBAS	FB -VAE
UTR	10.87	11.71	11.43	12.06	12.15	11.94	10.60	11.20	11.89	10.65
AMP	-2.98	-2.67	-2.84	-2.54	-2.16	-2.74	-3.36	-3.09	-2.73	-2.80
Fluo	35.31	35.82	35.59	46.19	44.28	43.88	34.33	37.40	43.45	34.78
Table 6: Comparison of the area under top-10 curves for UTR, AMP and Fluo benchmarks. Larger
area means better sample efficiency.
For TfBind benchmark, we use the following transcription factor instances and treat them as differ-
ent black-box optimization tasks: ZNF200.S265Y_R1, POU6F2_REF_RL8, KLF11_R402Q_R1,
EGR2.R359W.R1, HOXD13.S316CR1, HOXB7.K191R_R1, PBX4_REF_R2, GFI1B.A204T_R1,
FOXCLREF.R1, KLF1_REF_R1, SIX6_REF_R1, ARX_L343Q_R2, CRX_E80A_R1,
ESX1_K193R_R1 and VSXLG160D_R1. We do not do post-processing such as score nor-
malization whitening for the data for simplicity. We first calculate the area under curve to
summarize the performance in a scalar output, and put the ranking result for each algorithm in
Table 4 and Table 5, which provide more details for Table 2. To further investigate the diversity of
different algorithms, we choose two TfBind instances (POU6F2_REF_R1 and KLF11 _R402Q_R1)
and visualize the resulting sequences with T-SNE (van der Maaten & Hinton, 2008) in Figure 3.
We provide two visualization views for both task instances: (1) we uniformly sample 20 sequences
from the whole n ∙ R sequences for each algorithm and visualize them; (2) for each algorithm,
we visualize 20 sequences uniformly sampled from the last batch (i.e., at the last round). This is
notated with “final sequences” in the figure. We do not visualize all the sequences for simplicity.
We use Hamming distance in the computation of T-SNE. From Figure 3, we can see that there is
no obvious difference for the evaluated methods. This indicates that our proposed methods can
achieve better performance while maintaining on-par diversity level with the baselines. This is not
exactly consistent to the findings of Angermuller et al. (2020a), which claims some algorithms such
as DbAS achieve very limited diversity. We do not use the “optima fraction” metric in Angermuller
et al. (2020a;b), since this metric may not deal with multimode oracle landscape well and needs
extra unstable computation such as clustering. Besides, this metric cannot generalize to other
benchmarks.
We elaborate the construction of our AMP oracle. We use the AMP dataset from (Witten & Witten,
2019) which contains 6,760 AMP sequences. A multilayer perceptron classifier is trained to predict
if a protein sequence can prohibit the growth of a particular pathogen in that AMP dataset. This clas-
sifier operates on the features extracted by ProtAlbert (Elnaggar et al., 2020) model. Following the
setup in (Angermuller et al., 2020b), We treat the predicted logits as the ground-truth measurement.
Moreover, we demonstrate the area under Top-10 curves for UTR, AMP and Fluo benchmarks in
Table 6, which is a good complement for Table 3 but is missing due to limited space in the main text.
19
Published as a conference paper at ICLR 2022
C	Related Works and Discussion
Likelihood-free inference. We have already introduced the main classes of likelihood-free infer-
ence algorithms in the main text: (1) Approximate Bayesian Computation (ABC) method (Beaumont
et al., 2009; Blum, 2009; Marin et al., 2012; Lintusaari et al., 2017) in Section 3.1; (2) Posterior
modeling method that is also stated in Section 3.1, including classical ones (Tran et al., 2015; Li
et al., 2017; Chen & Gutmann, 2019) and modern SNP methods (Papamakarios & Murray, 2016;
Lueckmann et al., 2017; Greenberg et al., 2019); (3) Likelihood modeling method described in Sec-
tion 3.2, also containing various classical algorithms (Wood, 2010; Mengersen et al., 2012; Drovandi
et al., 2018) and modern SNL variants (Lueckmann et al., 2018; Papamakarios et al., 2019); and (4)
Probability ratio modeling methods mentioned in Section 3.3 diverge in estimating likelihood ratio
(Gutmann & Hyvarinen, 2010; Gutmann et al., 2018; Brehmer et al., 2020) or likelihood-to-evidence
ratio (Thomas et al., 2016; Izbicki et al., 2014), where the latter paradigm is a good fit for LFI prob-
lem (Hermans et al., 2019). Besides, there are also works about how to construct low-dimensional
summary statistics for LFI (Fearnhead & Prangle, 2012; Chan et al., 2018; Chen et al., 2021).
Machine learning based drug design. Generative modeling and discriminative modeling are two
basic ways of thinking in machine learning. In literature for sequence design, generative modeling
is also known as cross entropy method. This is a famous kind of design method that is close to our
“backward modeling of the mechanism” approach. Cross entropy methods seek to solve an expec-
tation maximization problem (i.e., maxp Ep(m) [f (m)]) where the sequences follow a distribution p.
This can also be related to simulated annealing, a large family of black-box optimization algorithm
一 the sequential neural posterior could be thought to maintain a distribution which is gradually be-
coming sharper to a delta distribution at the optimal value. On the other hand, we think of this as a
way for modeling the posterior p(m|E) and develop corresponding analysis under the probabilistic
framework, which is like a more accurate version of cross entropy method. Many related methods
(including the ones stated in Section 3.1) train the distribution by likelihood maximization for se-
quences with large scores, or use some sort of reweighting to achieve similar effects (Rubinstein &
Kroese, 2004; de Boer et al., 2005; Neil et al., 2018; Gupta & Zou, 2019; Brookes et al., 2019).
Discriminative modeling usually goes in a “model-based optimization” way (terminology from
Angermuller et al. (2020a)), i.e., use a discriminative model f (m) to fit the real oracle f (m) and act
as a surrogate for it. The surrogate model can replace the true oracle f(m) which involves costly bi-
ological experiments. This corresponds to our “forward modeling of the mechanism” in Section 3.2.
Bayesian optimization (Shahriari et al., 2016) is a classical example, which utilizes f (typically a
Gaussian process model) to define an acquisition function to guide the exploration and exploitation.
Many modern biochemical methods also belong to this category (Gomez-Bombarelli et al., 2018;
Hashimoto et al., 2018; Yang et al., 2019; Wu et al., 2019; Sample et al., 2019; Liu et al., 2020).
There seems not much related literature about probability ratio estimation based method in this
topic. On the other hand, Hashimoto et al. (2018) shares a classification based approach with IR but
they differ on how to use the classifier. This algorithm utilizes the learned classifier to update the
proposal with multiplicative weights algorithm, making the proposal to have large probability where
the classifier logit is small. Other categories of drug design methods include evolution algorithms
(Brindle, 1980; Wierstra et al., 2008; Salimans et al., 2017; Yoshikawa et al., 2018; Jensen, 2019;
Real et al., 2019; Ahn et al., 2020) that search over the target space with genetic operators like insert,
mutation, and crossover, and reinforcement learning (Guimaraes et al., 2017; Neil et al., 2018; Zhou
et al., 2019; Shi et al., 2020; Angermuller et al., 2020b) which see the formation of a drug as a
Markov decision process and train the policy to learn highly-rewarding drugs. We do not find other
work that is similar to our probability ratio modeling approach (Section 3.3) from the literature,
which we take as a novel contribution.
20