Published as a conference paper at ICLR 2022
Analyzing and Improving the Optimization
Landscape of Noise-Contrastive Estimation
Bingbin Liu, Elan Rosenfeld, Pradeep Ravikumar, Andrej Risteski
Machine Learning Department
Carnegie Mellon University
{bingbinl,elan,pradeepr,aristesk}@cs.cmu.edu
Ab stract
Noise-contrastive estimation (NCE) is a statistically consistent method for learn-
ing unnormalized probabilistic models. It has been empirically observed that the
choice of the noise distribution is crucial for NCE’s performance. However, such
observations have never been made formal or quantitative. In fact, it is not even
clear whether the difficulties arising from a poorly chosen noise distribution are
statistical or algorithmic in nature. In this work, we formally pinpoint reasons
for NCE’s poor performance when an inappropriate noise distribution is used.
Namely, we prove these challenges arise due to an ill-behaved (more precisely,
flat) loss landscape. To address this, we introduce a variant of NCE called eNCE
which uses an exponential loss and for which normalized gradient descent ad-
dresses the landscape issues provably when the target and noise distributions are
in a given exponential family.
1	Introduction
Noise contrastive estimation (NCE) is a method for learning parameterized statistical models (Gut-
mann & Hyvarinen, 2010; 2012). To estimate a distribution P* ,NCE trains a discriminant model to
distinguish between samples of P* and a known distribution Q of our choice, often referred to as the
“noise” distribution. If the function class for the discriminant model is representationally powerful
enough, the optimal model learns the density ratio p*/q, from which we can extract the density p*
since q is known (Menon & Ong, 2016; Sugiyama et al., 2012). Compared to the well-studied maxi-
mum likelihood estimation (MLE), NCE avoids calculating the (often intractable) partition function,
1 while maintaining the asymptotic consistency of MLE (Gutmann & Hyvarinen, 2012).
It is empirically well-documented that the choice of the noise distribution Q is crucial to both the
statistical and algorithmic efficiency of NCE (Gutmann & Hyvarinen, 2010; 2012; Rhodes et al.,
2020; Goodfellow et al., 2014; Gao et al., 2020). However, it has been observed in practice that even
when following the standard guidelines for choosing Q, NCE can still yield parameter estimates far
from the ground truth (Rhodes et al., 2020; Goodfellow et al., 2014; Gao et al., 2020). Most recently,
Rhodes et al. (2020) identified a phenomenon they call the “density chasm,” observing empirically
that NCE performs poorly when the KL divergence between P* and Q is large. One example is
when P* , Q are both tightly concentrated unimodal distributions with faraway modes; the region
between the two modes will have a small density under both distributions, thus forming a “chasm”.
While it makes intuitive sense that NCE does not perform well under such settings—since disparate
Q and P* are easy to distinguish and do not require the model to learn much about P* in order to
do well on the classification task—there has not been a theoretical analysis of this phenomenon. In
fact, it is not even clear whether the difficulty is statistical or algorithmic in nature.
In this work, we formally study the challenges for NCE with a fixed Q with a focus on distribu-
tions in an exponential family. We show that when the noise distribution Q is poorly chosen, the
loss landscape can become extremely flat: in particular, even when P * and Q are two univariate
Gaussian with unit variance, the loss gradient and curvature can become exponentially small in
the difference in their means. We prove that this poses challenges for standard first order and even
1The partition function is also known as the normalizing constant of an unnormalized density, such that the
density after normalization will integrate to 1.
1
Published as a conference paper at ICLR 2022
second-order optimization methods, forcing them to take an exponential number of steps to converge
to a good parameter estimate. Thus, standard approaches to minimizing convex functions such as
gradient descent—or even more advanced techniques such as momentum or Newton’s method—are
not suited to the NCE objective unless Q is close to P* in KL sense.
To remedy this issue, we study an alternative method for optimizing the NCE objective. We consider
instead Normalized Gradient Descent (NGD) whereby the gradient is normalized to have unit norm
at each time step. Perhaps surprisingly, we prove that this small modification can overcome the
problem of poor curvature in the Gaussian example. In general, we show the number of steps for
NGD to converge to a good solution for the NCE loss depends on the condition number κ of the
Hessian of the loss at the optimum—the growth of this condition number is unclear for P * and Q
when they belong to an exponential family.
To address this, we propose the eNCE loss, a variant to NCE that replaces the log loss in NCE with
an exponential loss, and we show that the resulting condition number is polynomial in the dimension
and the parameter distance between P * and Q when they belong to an exponential family. Our
proposed change of loss and optimization algorithm together form the first solution that provides a
provable polynomial rate for learning the parameters of the ground truth distribution. Theoretically,
both NCE and eNCE can potentially suffer from numerical issues during optimization when P * and
Q are far—this is an interesting direction for future work. Nonetheless, we find this to be a simple
and effective fix to the flatness of the loss landscape in many settings, as evidenced by experimental
results on synthetic and MNIST dataset.
1.1 Related Work
NCE and its variants have inspired a large volume of research in NLP (Mnih & Teh, 2012; Mnih &
Kavukcuoglu, 2013; Dyer, 2014; Kong et al., 2020) as well as computer vision (Oord et al., 2018;
Hjelm et al., 2018; Henaff, 2020; Tian et al., 2020). It has been observed empirically that NCE with
a fixed noise Q is often insufficient for learning good generative models. The predominant class
of approaches that have been proposed to overcome this issue aim to do so by not using a fixed
Q but by iteratively solving multiple NCE problems with an updated Q, or equivalently updated
discriminators. This includes the famous generative adversarial network (GAN) by Goodfellow
et al. (2014), which uses a separate discriminator network updated throughout training. In a similar
vein, Gao et al. (2020) also aimed to increase the discriminative power as the density estimator
improves, and parameterize Q explicitly with a flow model. More recently, Rhodes et al. (2020)
proposed the telescoping density ratio estimation, or TRE, which sidesteps the chasm by expanding
p*/q into a series of intermediate density ratios, each of which is easier to estimate, leading to strong
empirical performance—though their work carries no formal guarantees.
With respect to a fixed Q, it remains an open question about what formally are the nature of the
challenges posed by a poorly chosen Q, which could be statistical and/or algorithmic. Various pre-
VioUS works have analyzed the asymptotic behavior ofNCE and its variants (Gutmann & Hyvarinen,
2012; Riou-Durand et al., 2018; Uehara et al., 2020), but these do not provide guidance on the finite
step convergence of NCE or its common variants. The improvements to NCE in prior works are
all borne out by the empirical observations of NCE practitioners, rather than motivated by theory,
which is precisely the aim of this work.
Finally, we would like to note that prior work has proposed “generalized NCE" (Pihlaja et al., 2010;
Gutmann & Hirayama, 2011; Uehara et al., 2020), which relates the NCE objective to minimizing
the Bregman divergence. Generalized NCE says that we can design a family of training objectives
by using different convex functions to define the Bregman divergence, and the proposed eNCE is
an instance of the generalized NCE objective. The difference between these prior work and ours is
again the different focuses on asymptotic behavior versus finite step convergence.
2 Preliminaries
The NCE objective Let P* denote an unknown distribution in a parametric family {Pθ }θ∈Θ, for
some bounded convex set Θ, with P* = Pθ*. Our goal is to estimate P* via Pθ for some θ ∈ Θ by
solving a noise contrastive estimation task. The noise distribution Q belongs to the same parametric
family with parameters θq ∈ Θ, so that Q = Pθq. We use pθ, p*, q to denote the probability density
2
Published as a conference paper at ICLR 2022
functions (pdfs) of P§, P*, and Q; We may omit θ in Pθ, pθ when it is clear from the context and
write P, P instead. Given P* and Q, the NCE loss of P is defined as follows:
Definition 2.1 (NCE Loss). The NCE loss of Pθ w.r.t. data distribution P* and noise Q is:
1	pθ	1	q
L(Pθ) = -2Ep*log ^P+ - 2EQ log PT+^.	(2.1)
The NCE loss can be interpreted as the binary cross-entropy loss for the classification task of distin-
guishing the data samples from the noise samples. Moreover, the NCE loss has a unique minimizer:
Lemma 2.1 (Gutmann & Hyvarinen 2012). The NCE objective in Definition 2.1 is uniquely mini-
mized at P = P*, provided that the support ofQ covers that ofP*.
Exponential family. We focus our attention on the exponential family, where the pdf for a dis-
tribution with parameter θ is pτ(x) = exp (θ>T(x) - A(θ)), with T(X) denoting the sufficient
statistics and A(θ) the log partition function. 2 The partition function is treated as a parameter in
NCE, so we use τ to denote the extended parameter, i.e. τ := [θ, α] where α is the estimate for
the log partition function. We accordingly extend the sufficient statistics as T(x) = [T (x), -1]
to account for the log partition function. The pdf with the extended representation is now simply
Pτ (x) = exp(τ > T (x)). We will use the notation Pθ and Pτ interchangeably. We will also use τ(θ)
to denote the log-partition extended parameterization when the log partition function α properly
normalizes the distribution specified by θ.
A compelling reason for focusing on the exponential family is the observation that the NCE loss is
convex in the parameter τ :
Lemma 2.2 (NCE convexity). For exponentialfamily Pθ,α(x) = h(x) exp(θ>T(x) — α), the NCE
loss is convex in parameter τ := [θ, α].
Lemma 2.2 has been stated under more general settings by Uehara et al. (2020); an alternative self-
contained proof is included in Appendix A for completeness.
Recall that Θ denotes the set of parameters without the extended coordinate for the log partition
function. We assume the following on distributions supported on Θ:
Assumption 2.1 (Bounded parameter norm). kθk2 ≤ ω, ∀θ ∈ Θ.
Assumption 2.2 (Lipschitz log partition function). Assume the log partition function is βZ-
Lipschitz, that is, ∀θ1,θ2 ∈ Θ, |logZ(θι) - logZ(θ2)∣≤ βz∣∣θι - θ2∣∣.
Assumption 2.3 (Bounded singular values of the population Fisher matrix). There exist
λmax, λmin > 0, such that ∀θ ∈ Θ, we have σmax(Eθ [T(x)T(x)>]) ≤ λmax, and
σmin(Eθ[T(x)T(x)>]) ≥ λmin.
Assumption 2.4 (Smooth change in the Fisher matrix). Assume the maximum and minimum singular
values of the Fisher matrix change smoothly. Namely, there exist constants γmax , γmin > 0 s.t.
∣∣Vθ σmaχ(Eθ [T (x)T (x)>])k≤ Ymax, ∣Nθ σmin(Eθ [T (x)T (x)>])∣∣≤ Ymin .
Assumptions 2.2-2.4 can be viewed as smoothness assumptions on the first, second and third order
derivatives of the log partition function, and can be viewed as introducing structural parameters of
the distributions. For example, distributions with flatter tails will have a larger λmax , which then
translates to a slower rate in the results; distributions closer to being singular will have a smaller
λmin, etc. In particular, Assumption 2.3 says the singular values oftheFishermatrixEθ[T(x)T(x)>]
should be bounded from above and below. It can be shown that the Fisher matrix is proportional
to the Hessian of the NCE objective when using Q = P*, which means Assumption 2.3 can be
interpreted as saying the NCE task can be solved efficiently under the optimal choice of Q.
3	Overview of results
We first provide an informal overview of our results, focusing on learning of exponential families.
2Another common format of the exponential family PDF is pθ (x) = h(x) exp θ>T (x) - A(θ) where
h(x) is a non-negative function. Such h(x) could be absorbed into T(x) and θ with corresponding coordinates
log(h(x)) and 1.
3
Published as a conference paper at ICLR 2022
Flatness of population landscape: Our first contribution is a negative result identifying a key
source of difficulty for NCE optimization to be an ill-behaved population landscape. We show that
due to an extremely flat landscape, gradient descent or Newton’s method with standard choices of
step sizes will need to take an exponential number of steps to find a reasonable parameter estimate.
We emphasize that though Gaussian mean estimation is a trivial task, its simplicity strengthens
the results above: we are proving a negative result so that failures with a simpler setup means a
stronger result. Moreover, the results only apply to standard choices of step sizes, such as inversely
proportional to the smoothness for gradient descent, or to the ratio between the smoothness and
strong convexity for Newton’s method. This does not rule out the possibility that a cleverly designed
learning rate schedule or a different algorithm would work efficiently; the results are however still
meaningful since gradient descent with standard step sizes is the most common choice in practice.
Overcoming flatness using normalized gradient descent: Our second contribution is to show
that the flatness problem can be solved by a simple modification to gradient descent if the loss is
well-conditioned. Specifically, we show that the convergence rate for normalized gradient descent
is polynomial in the parameter distance and κ*,the condition number of the Hessian at the optimum.
One immediate consequence is that in Gaussian mean estimation, for a target error of δ ∈ (0,泰]
in parameter distance, NCE optimized with NGD achieves a rate of O( δ2), which is the same as the
optimal rate achieved by MLE.
The remaining question is then whether κ* is polynomial in the parameters of interests. We show
that κ* can be related to the Bhattacharyya coefficient between P* and Q, which indeed grows
polynomially in parameter distance under certain assumptions as detailed in Section 5.2.
Polynomial condition number for the eNCE loss: Our third and final contribution is that if we
modify the NCE objective slightly—namely, use the exponential loss in place of the log loss—then
the condition number at the optimum is guaranteed to be polynomial. We call this new objective
eNCE . Combined with the NGD result, we get that running NGD on the eNCE objective achieves a
polynomial convergence guarantee.
We then provide empirical evidence on synthetic and MNIST dataset that eNCE with NGD performs
comparatively with NGD on the original NCE loss, and both outperform gradient descent.
4	Flatness of the NCE loss
In this section, we study the challenges posed to NCE when using a badly chosen fixed Q. The main
thrust of the results is to show that both algorithmic and statistical challenges can arise because the
NCE loss is poorly behaved, particularly for first- and second-order optimization algorithms: when
P* , Q are far, the loss landscape is extremely flat near the optimum. In particular, the gradient has
exponentially small norm and the strong convexity constant decreases exponentially fast, limiting
the convergence rate of the excess risk. We further show that when moving from P = Q to P = P*,
the loss drops from Θ(1) to a value that is exponentially small in terms of the distance between
P* and Q. Consequently, common gradient-based and second order methods will take exponential
number of steps to converge.
An important note is that our analysis is at the population level, implying that the hardness comes
from the landscape itself regardless of the statistical estimators used.
Setup - Gaussian mean estimation: For the negative results in this section, let's consider an ex-
ceedingly simple scenario of 1-dimensional, fixed-variance Gaussian mean estimation. We will
demonstrate the enormous difficulty of achieving a good parameter estimate, even for such a sim-
ple problem—this bodes ill for NCE objectives corresponding to more complex models in practice,
which certainly pose a much more difficult challenge. In particular, let P*, Q, P be Gaussians with
identity variance. Let θ* , θq , θ denote the respective means, with θ* being the target mean that NCE
2
aims to estimate. When the covariance is known to be 1, we can denote h(x) := exp(-X-), and
parametrize the pdf of a 1d Gaussian with mean θ as p(x) = h(x) exp(hτ (θ), T (x)i),3 where the
parameter is T(θ) := [θ, θ2- + log √2∏] and the sufficient statistics are T(x) := [x, -1]. 4 We will
shorthand τ(θ) when it is clear from the context.
3Thus, we are setting h to be the base measure for the exponential family we are considering.
4Recall that the last coordinate -1 acts as a sufficient statistic for the log partition function.
4
Published as a conference paper at ICLR 2022
Without loss of generality, we will assume θq = 0, and θ* > 0, and denote R := θ* — θq. We will
write τ* := T(θ*) = [R, R + log√2∏], and Tq := T(θq) = [0,log√2∏]. As a clarification, the
results stated in this section will be in terms of R, hence the asymptotic notations Ω, O never hide
dominating dependency on R. 5
4.1	Properties of the NCE loss
We first describe several properties of the NCE loss that will be useful in the analysis of first- and
second-order algorithms.
To start, we show that the dynamic range of the loss is large: that is, the optimal NCE loss is
exponentially small as a function of R; on the other hand, if θ is initialized close to θq, the initial
loss would be on the order of a constant. Precisely:
Proposition 4.1 (Range of NCE loss). Consider the 1d Gaussian mean estimation task with mean
θ* ,θq ∈ R, and a known variance of 1. Denote R := ∣θq — θ/ where R》1, Then, the loss at
θ = θq is log2, while the minimal loss L* is L^ (R) = Cexp(—R2∕8) for some C ∈ [ 1, 2].
The next shows we need to decrease the loss to be on an order comparable to the optimum value.
Namely, the loss is very flat close to θ*, thus in order to recover a θ close to θ*, We have to reach a
very small value for the loss. Precisely:
Proposition 4.2. Under the same setup as Proposition 4.1, for a given δ ∈ (0, 1), if the learned
parameter T satisfies ∣∣τ — τ*∣∣2≤ δ, then L(τ) — L(τ*) ≤ Rexp(—R2∕8) δ2.
The way we will leverage Propositions 4.1 and 4.2 to prove lower bounds is to say that if the updates
of an iterative algorithm are too small, the convergence will take an exponential number of steps.
Proposition 4.2 is proven via the Taylor expansion at θ*: since the gradient is 0 at θ*, we just need
to bound the Hessian at θ*. We show:
Lemma 4.1 (Smoothness at P = P*). Under the same setup as Proposition 4.1, the smoothness at
P = P* is upper bounded as σmaχ(V2L(τ*)) ≤ √2∏ exp(—R2∕8).
We will also need a bound on the strong convexity constant (i.e. smallest singular value) at P = P*:
Lemma 4.2 (Strong convexity at P = P*). Under the same setup as Proposition 4.1, the minimum
singular value at P = P* is σ*a(V2L(τ*)) = Θ (R exp
R2
Finally, in order to estimate the choice of the step size for standard optimization methods, we will
also need a bound of the smoothness at P = Q:
Lemma 4.3 (Smoothness at P = Q). Under the same setup as Proposition 4.1, the smoothness at
P = Q is lower bounded as σmaχ(V2L(τq)) ≥ R.
Lemma 4.1, 4.2 are proved in Appendix D.4, and Lemma 4.3 is proved in Appendix D.5.
4.2	Lower bounds on first- and second-order methods
With the landscape properties at hand, we are now ready to provide lower bounds for both first-order
and second-order methods. For first-order methods, we show that:
Theorem 4.1 (Lower bound for gradient-based methods). Let P*, Q, P be 1d Gaussian with vari-
ance 1. Assume θq = 0, θ* > 0 without loss of generality, and assume R := θ* — θq 1. Then,
gradient descent with any step size η = o(1) from an initialization τ = τq will need an exponential
number of steps to reach some τ0 that is O(1) close to τ*.
Note, the maximum step size η = o(1) the theorem applies to is actually a loose bound: the standard
setting of step size for gradient descent is η ≤ 1∕λM for λM := maxθ∈Θ σmax(V2L(τ(θ))), which
is Ω(R2) by Lemma 4.3. Theorem 4.1 helps explain why NCE with a far-away Q fails in practice,
if we set the budget for the number of updates to be polynomial.
5For example, for R	1, R exp(R2) = O(exp(R2)), but the constant in O(1) will not depend on R.
5
Published as a conference paper at ICLR 2022
A natural remedy to the drastically changing norms of the gradients is to use methods that can
properly precondition the gradient. This motivates the use of second order methods, which adapt to
the geometry of the loss and hence can potentially perform more competitively.
Unfortunately, standard second-order approaches are again of no help, and the number of steps
required to converge remains exponential. Consider Newton’s method with updates of the form
η(V2L)-1VL. At first glance, this looks like it may solve the issue of a flat gradient, since the
Hessian V2L may also be exponentially small hence canceling out with the exponentially small
gradient. However, the flatness of the landscape forces us to take an exponentially small step size η,
resulting in the following claim:
Theorem 4.2 (Lower bound for Newton,s method). Let P*,Q,P satisfy the same conditions as in
theorem 4.1. Let λρ := minθ∈Θ σmin (V2 L(τθ)), λM := maxθ∈Θ σmax (V2 L(τθ)). Then, run-
ning the Newton's method with step size η = O(λλρ) from an initialization T = Tq will need an
exponential number ofsteps to reach some T0 that is O(1) close to τ*∙
Again, the condition η = O (λλρ) follows the typical step size choice for Newton,s method, i.e. the
step size should be upper bounded by the ratio between the global strong convexity constant and the
global smoothness of the function, which is exponentially small for this setup by Lemma 4.2, 4.3.
5	Normalized gradient descent for well-conditioned losses
We have seen that due to an ill-behaved landscape, NCE optimized with standard gradient descent
or Newton,s method will fail to reach a good parameter estimate efficiently, even on a problem as
simple as Gaussian mean estimation, and even with access to the population gradient.
In this section, we will show that a close relative of gradient descent, normalized gradient descent
(NGD), despite its simplicity, provides a fix to the flatness problem to exponential family distribu-
tions when the Hessian of the loss is well-conditioned close to the optimum.
Precisely, recall that the NGD updates for a loss function L is τt+ι = Tt 一 η 口£(Tt))12. We assume
that in a neighborhood around τ*, the change in the shape of the Hessian H is moderate: 6
Assumption 5.1 (Hessian in a neighborhood of τ*). Under assumption 2.2 with constant βz, assume
that for any T such that kτ — τ*∣∣2≤ , it holds that σmaχ(H (T)) ≤ βu ∙ σmaχ(H (τ*)), and
σmin(H(T)) ≥ βι ∙ σmin(H(‰)),forsome constant βu,βι > 0.
The main result of this section states that NGD can find a parameter estimate efficiently for expo-
nential families, where the number of steps required is polynomial in the distance between the initial
estimate and the optimum:
Theorem 5.1. Let L be any loss function that is convex in the exponential family parameter and
satisfies Assumptions 5.1 and 2.1 - 2.4. Furthermore, let P*,Q be exponential family distributions
with parameters「#, Tq and let κ* be the condition number of the Hessian at P = P*. Then, for
any 0 < δ ≤ 泰 and parameter initialization to, with step size η ≤ J^K~ δ, performing NGD on
the population objective L guarantees that after T ≤ 色/ ∙ "-；*k steps, there exists an iterate
t ≤ T such that kTt 一 T* k2≤ δ.
The main technical ingredient for proving Theorem 5.1 is the following Lemma:
Lemma 5.1. Suppose Assumptions 2.2 and 5.1 hold with constants βz, βu and βι. Let L be a convex
function with minimizer τ*, and let g := VL(τ). For any δ ≤ 仓,let Y = Jeel^δ. Thenfor all T
s.t. kτ — τ*k2≥ δ, we have L(τ* + Yɪgɪ) ≤ L(τ).
Lemma 5.1 explains the dependency on κ* in the NGD convergence rate. The intuition of the proof
is that in a small neighborhood around T*, the set of parameters that have the same loss form an
“ellipsoid", and by Taylor expansion, any two points in the same set will have a distance-to-T* ratio
upper bounded roughly by √κ7. The details are in Appendix C.2.
6As a concrete example, we will show in the next section that a variant of NCE satisfies both conditions.
6
Published as a conference paper at ICLR 2022
Proof sketch for Theorem 5.1: the proof leverages two observations: the convexity of NCE loss on
exponential family parameters, and that the Hessian in a neighborhood around τ* changes moder-
ately as stated in Assumption 5.1. One can then show there exists a global constant γ such that for
any Tt satisfying ∣∣τt 一 τ* k2 ≥ δ, one step of NGD update guarantees a decrease of γ2 in the squared
error, which means NGD must have found an δ-close estimate within kτ0-τ*k steps. The full proof
is deferred to Appendix C.1.
5.1	Example: 1d Gaussian mean estimation
It is relatively straightforward to check that NGD addresses the flatness problem faced by Gaussian
mean estimation we considered in Section 4:
Corollary 5.1. Let P*,Q be 1d Gaussian with covariance 1 and mean θ* = R where R《 1, and
θq = 0. For any given δ ≤ R and initial estimate τo = Tq, NGD can find an estimate T such that
∣∣τ 一 τ* ∣2≤ δ, with at most O(R2) steps.
Intuitively, the effectiveness of NGD comes from the crucial observation that though the magnitude
for the loss and derivatives can be exponentially small, they share the same exponential factor, mak-
ing normalization effective. Formally, it can be shown that βu = O(1) (Appendix D.6). Corollary
5.1 then follows from Theorem 5.1 and the curvature and strong convexity from Lemma 4.1, 4.2.
5.2	B ounds on the condition number of NCE
The convergence rate in Theorem 5.1 depends on κ*, the condition number of the NCE Hessian at
the optimum, and Hessian-related constants βu, βl in Assumption 5.1. We now show that under the
setup of Theorem 5.1, κ* and βu, βι can be related to the Bhattacharyya coefficient between P* and
Q, which is a similarity measure defined as BC(P*,Q) := JX ,p*(χ)q(χ)dχ. As a result, We get
the following convergence guarantee:
Theorem 5.2. Suppose Assumptions 2.1, 2.3 hold with constants ω, λmax, and λmin. Consider
a NCE task with data distribution P1 and noise distribution P2, parameterized by θ1, θ2 ∈ Θ re-
spectively. Thenfor any given δ ≤ R and initial estimate τ0 = Tq, NGD finds an estimate T such
that ∣∣t — t*∣2≤ δ within T ≤ C ∙ pgj1 @尸 E-T*k steps, where C := 18exp(卷)∙ (λmax)3 ∙
min [ "Max 2λmin + γmax k δk ]
I Kr , Imin-Ymingk f-
In particular, when P*, Q are not too far, we can further show a lower bound on BC(P*, Q):
Lemma 5.2. For P1,P2 parameterized by θ1,θ2 ∈ Θ, if ∣θ1 — θ2∣2≤ ^4-, then BC(P1,P2) ≥ 2.
The proofs of Theorem 5.2 and Lemma 5.2 rely on analyzing the geodesic on the manifold of
square root densities √p equipped with the Hellinger distance as a metric; the details are deferred to
Appendix C.3 and C.4. It is also worth noting that Theorem 5.2 only requires ∣∣θι — θ21 tobe smaller
than a constant, rather than tending to zero as usually required for analyses using Taylor expansions.
Finally, we would like to note that although our analysis can be tightened, it is unlikely to remove
such dependency since NGD only uses first-order information. 7 Moreover, the condition number
κ* also affects the practical use of Newton-like methods, since matrix inversion is widely known
to be sensitive to numerical issues when the matrix is extremely ill-conditioned. It is an interesting
open question whether a non-standard preconditioning approach might be amenable to this setting.
6	Analyzing eNCE : NCE with an exponential loss
The previous section proved that NGD can serve as a simple fix to overcome the flatness problem of
NCE for well-conditioned losses. However, though we showed κ* has a polynomial growth when
the distributions P, Q* are sufficiently close —it is unclear how κ* behaves beyond this threshold.
7In the next section, We will that the condition number is provably polynomial in ∣∣θ* 一 θq ∣∣ for a variant of
the NCE loss.
7
Published as a conference paper at ICLR 2022
In this section, we introduce a slight modification to the NCE objective, which we call the eNCE
objective, for which κ* depends polynomially on some class-related constants. This means though
eNCE may still suffer from the flatness problem, eNCE and NGD together provide a solution that
guarantees a polynomial convergence rate.
Towards formalizing this, the eNCE loss is defined as:
Definition 6.1 (eNCE Loss). Let 夕(x) := log JP(X), and l(x, y) := exp(-y4(X)) for y ∈ {±1}.
The eNCE loss of Pθ w.r.t. data distribution P* and noise Q is: ________ _______________
LeXP(Pθ) = 2 Ex~P*[l (Xj)] + 2 Ex~P*[l (X, -1)] = 2 Z pM q qτ⅛ + 2 Z ql∕p7⅛.
2	2	2 x p(x)	2 x q(x)
(6.1)
It can be checked easily that the minimizing 夕 learns 夕(x) = 1 log p*. Moreover, each 夕 is associ-
ated with an induced distribution p, defined by p(x) = exp(夕(x))q(x).
Relation to NCE: Same as the original NCE loss (referred to as “NCE” below), eNCE learns to solve
a distinguishing task between samples from P* or Q. The difference lies only in the losses, which
have analogous forms: the NCE loss described in Def. 2.1 can be rewritten in the same form with
I(X, y) ：= log +χp(-yψ(χ)) and ψ(X) ：= log P(χ) .
The main advantage of the exponential loss is that the Hessian at the optimum is now guaranteed to
be well-conditioned:
Lemma 6.1 (Polynomial condition number for eNCE loss). Under Assumption 2.3 with constants
λmaχ, λmin,the Condition number Ofthe eNCE HeSSian at the optimum is bounded by κ* ≤ λmax.
λmin
We can also show that eNCE satisfies part (ii) of Assumption 5.1. Due to space considerations, the
proof is deferred to Appendix B.1.
Lemma 6.2. Underassumption 2.2 with constant βz, for any unit vector U and constant C ∈ [0,金],
the maximum and minimum singular values of H(τ* + cu) satisfy assumption 5.1 with constants
βu = 2exp(1) ∙ λmax, βι =小—ITn ∙ λmin.
λmin, l 2 exp(1) λm
ax
Lemma 6.1 and Lemma 6.2 together imply the Hessian is well-conditioned around the optimum.
Combined with Theorem 5.1, we have the main result of this section:
Theorem 6.1. Let P*, Q be exponential family distributions with parameters τ*, τq under Assump-
tion 2.1-2.4. Let λmaχ,λmin be constants for Assumption 2.3. FOr any given δ ≤ 卷 and pa-
rameter initialization τ0, performing NGD on the eNCE objective guarantees that when taking
T ≤ 4exp(2) ∙ λmax ∙ kτ0-τ*k steps, there exists an iterate t ≤ T such that ∣∣τt 一 τ*∣∣2≤ δ.
min
Proof. Theorem 6.1 follows directly from Theorem 5.1, using the condition number bound from
Lemma 6.1 and constants from 6.2.	口
6.1	Proof of Lemma 6.1
It can be checked that the Hessian at P = P* is H* := V2L(P**) = 4 JX √p*qV logp(Vlogp)>.
Recall that θ* , θq, T denote the parameters and sufficient statistics without the partition func-
tion coordinate, and τ* , τq, T denote the extended version with the partition function, e.g. τ* =
[θ*, log Z(θ*)], T(x) = [T(x), -1]. Then, We can rewrite H* as:
H* =4 Z √pqτ(X)T(x) = 4 Z exp (RZq)I t (χ))
T(X)T(X)>
4 L exp ((θ* +2θq)> T(X) — 1 log Z(θ*) — 1 log Z(Oq)) T(X)T(X)>
(6.2)
Z θ θ* +θq
1
4
√Z(θ* )Z(θq)
|	{	}
B(P*,Q)
eχp ((-2-) T(x)) T(X)T(X)>dX = B(P,Q)Eθ*+θq [TT>].
Jx	Z (θ*+θq)	4
The Le^∩^∩a then follows from λmin I W E θ*+θq [TT>]	λmaxI by Assumption 2.3.
2
8
Published as a conference paper at ICLR 2022
Figure 1: Results for estimating 1d (left) and 16d (right) Gaussians, plotting mint∈[T]∣∣τ* - τt∣∣2
(y-axis) against the number of updates T (x-axis). In both cases, when using NCE, normalized
gradient descent (“NCE, NGD", yellow) largely outperforms gradient descent (“NCE, GD”, red).
When using NGD, the proposed eNCE (“eNCE, NGD”, blue) decays faster than the original NCE
loss. The results are averaged over 5 runs, with shaded areas showing the standard deviation.
Figure 2: Results on MNIST, plotting loss value (y-axis, log scale) against update steps (x-axis).
The left plot shows NCE optimized by GD (black) and NGD (yellow), and the right shows eNCE
optimized by GD (black) and NGD (blue). It can be seen that NGD outperforms GD in both cases.
7	Empirical verification
To corroborate our theory, we verify the effectiveness of NGD and eNCE on Gaussian mean esti-
mation and the MNIST dataset. For MNIST, we use a ResNet-18 to model the log density ratio
log(p/q), following the setup in TRE (Rhodes et al., 2020).
Results: For Gaussian data, we run gradient descent (GD) and normalized gradient descent (NGD)
on the NCE loss and eNCE loss. Figure 1 compares the best runs under each setup given a fixed
computation budget (100 update steps), where “best" is defined to be the run with the lowest loss on
fresh samples. The plots show the minimum parameter distance mint∈[T] ∣∣τ* — τt ∣∣2 for each step T.
We find that NGD indeed outperforms GD, and that the proposed eNCE sees a further improvement
over NCE while additionally enjoying provable polynomial convergence guarantees. For MNIST,
We can no longer compare parameter distances since τ* is unknown. Instead, We compare the result
of optimization directly in terms of loss achieved, again under a fixed computation budget (2K steps).
The results are shown in Figure 2, with NGD converging significantly faster for both NCE and
eNCE. We note that eNCE can be numerically unstable, especially when P* , Q are well separated.
We include implementation details in Appendix E.1 and additional results in Appendix E.2.
8	Conclusion and Discussions
We provided a theoretical analysis of the algorithmic difficulties that arise when optimizing the NCE
objective with an uninformative noise distribution, stemming from an ill-behaved loss landscape.
Our theoretical results are inspired by empirical observations in prior works (Rhodes et al., 2020;
Gao et al., 2020; Goodfellow et al., 2014) and provide the first formal explanation on the nature
of the optimization problems of NCE. Our negative results showed that even on the simple task of
Gaussian mean estimation, and even assuming access to the population gradient, gradient descent
and Newton’s method with standard step size choice still require an exponential number of steps to
reach a good solution.
We then proposed modifications to the NCE loss and optimization algorithm, whose combination
results in the first provably polynomial convergence rate for NCE. The loss we propose, eNCE, can
be efficiently optimized using normalized gradient descent and empirically outperforms existing
methods. We hope these theoretical results will help identify promising new directions in the search
for simple, effective, and practical improvements to noise-contrastive estimation.
9
Published as a conference paper at ICLR 2022
References
Jacob Andreas, Maxim Rabinovich, Dan Klein, and Michael I Jordan. On the accuracy of self-
normalized log-linear models. arXiv preprint arXiv:1506.04147, 2015.
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Accurate and conservative estimates of mrf
log-likelihood using reverse annealing. In Artificial Intelligence and Statistics, pp. 102-110.
PMLR, 2015.
Yilun Du and Igor Mordatch. Implicit generation and generalization in energy-based models. arXiv
preprint arXiv:1903.08689, 2019.
Chris Dyer. Notes on noise contrastive estimation and negative sampling. arXiv preprint
arXiv:1410.8251, 2014.
Ruiqi Gao, Erik Nijkamp, Diederik P Kingma, Zhen Xu, Andrew M Dai, and Ying Nian Wu. Flow
contrastive estimation of energy-based models. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 7518-7528, 2020.
Andrew Gelman and Xiao-Li Meng. Simulating normalizing constants: From importance sampling
to bridge sampling to path sampling. Statistical science, pp. 163-185, 1998.
Charles J Geyer. On the convergence of monte carlo maximum likelihood calculations. Journal of
the Royal Statistical Society: Series B (Methodological), 56(1):261-274, 1994.
Ian J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil
Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. arXiv preprint
arXiv:1406.2661, 2014.
Will Grathwohl, KUan-Chieh Wang, Jorn-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi,
and Kevin Swersky. Your classifier is secretly an energy based model and you should treat it like
one. arXiv preprint arXiv:1912.03263, 2019.
Roger B Grosse, Chris J Maddison, and Russ R Salakhutdinov. Annealing between distributions
by averaging moments. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q.
Weinberger (eds.), Advances in Neural Information Processing Systems, volume 26. Curran As-
sociates, Inc., 2013. URL https://proceedings.neurips.cc/paper/2013/file/
fb60d411a5c5b72b2e7d3527cfc84fd0- Paper.pdf.
Michael Gutmann and Jun-ichiro Hirayama. Bregman divergence as general framework to estimate
unnormalized statistical models. In Proceedings of the Conference on Uncertainty in Artificial
Intelligence (UAI), 2011.
Michael Gutmann and Aapo Hyvarinen. Noise-contrastive estimation: A new estimation principle
for unnormalized statistical models. In Proceedings of the Thirteenth International Conference on
Artificial Intelligence and Statistics, pp. 297-304. JMLR Workshop and Conference Proceedings,
2010.
Michael U Gutmann and Aapo Hyvarinen. Noise-contrastive estimation of unnormalized statistical
models, with applications to natural image statistics. Journal of Machine Learning Research, 13
(2), 2012.
Nicholas JA Harvey, Christopher Liaw, and Sikander Randhawa. Simple and optimal
high-probability bounds for strongly-convex stochastic gradient descent. arXiv preprint
arXiv:1909.00843, 2019.
Elad Hazan, Tomer Koren, and Kfir Y Levy. Logistic regression: Tight bounds for stochastic and
online optimization. In Conference on Learning Theory, pp. 197-209. PMLR, 2014.
Elad Hazan, Kfir Y Levy, and Shai Shalev-Shwartz. Beyond convexity: Stochastic quasi-convex
optimization. arXiv preprint arXiv:1507.02030, 2015.
Olivier Henaff. Data-efficient image recognition with contrastive predictive coding. In International
Conference on Machine Learning, pp. 4182-4192. PMLR, 2020.
10
Published as a conference paper at ICLR 2022
R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam
Trischler, and Yoshua Bengio. Learning deep representations by mutual information estimation
and maximization. arXiv preprint arXiv:1808.06670, 2018.
Aapo Hyvarinen and Hiroshi Morioka. Unsupervised feature extraction by time-contrastive learning
and nonlinear ica. arXiv preprint arXiv:1605.06336, 2016.
Scott Kirkpatrick, C Daniel Gelatt, and Mario P Vecchi. Optimization by simulated annealing.
science, 220(4598):671-680,1983.
Lingpeng Kong, Cyprien de Masson d’Autume, Lei Yu, Wang Ling, Zihang Dai, and Dani Yo-
gatama. A mutual information maximization perspective of language representation learning. In
International Conference on Learning Representations, 2020. URL https://openreview.
net/forum?id=Syx79eBKwr.
Matthieu Labeau and Alexandre Allauzen. Learning with noise-contrastive estimation: Easing train-
ing by learning to scale. In Proceedings of the 27th International Conference on Computational
Linguistics, pp. 3090-3101, Santa Fe, New Mexico, USA, August 2018. Association for Compu-
tational Linguistics. URL https://www.aclweb.org/anthology/C18-1261.
Aditya Menon and Cheng Soon Ong. Linking losses for density ratio and class-probability estima-
tion. In International Conference on Machine Learning, pp. 304-313. PMLR, 2016.
Andriy Mnih and Koray Kavukcuoglu. Learning word embeddings efficiently with noise-contrastive
estimation. Advances in neural information processing systems, 26:2265-2273, 2013.
Andriy Mnih and Yee Whye Teh. A fast and simple algorithm for training neural probabilistic
language models. In Proceedings of the 29th International Conference on Machine Learning, pp.
1751-1758, 2012.
Radford M Neal. Annealed importance sampling. Statistics and computing, 11(2):125-139, 2001.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers
using variational divergence minimization. arXiv preprint arXiv:1606.00709, 2016.
Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predic-
tive coding. arXiv preprint arXiv:1807.03748, 2018.
Miika Pihlaja, Michael Gutmann, and AaPo Hyvarinen. A family of computationally efficient and
simple estimators for unnormalized statistical models. In Proceedings of the Conference on Un-
certainty in Artificial Intelligence (UAI), 2010.
Benjamin Rhodes, Kai Xu, and Michael U Gutmann. Telescoping density-ratio estimation. arXiv
preprint arXiv:2006.12204, 2020.
Lionel Riou-Durand, Nicolas Chopin, et al. Noise contrastive estimation: Asymptotic properties,
formal comparison with mc-mle. Electronic Journal of Statistics, 12(2):3473-3518, 2018.
Akash Srivastava, Kai Xu, Michael U. Gutmann, and Charles Sutton. Generative ratio matching
networks. In International Conference on Learning Representations, 2020. URL https://
openreview.net/forum?id=SJg7spEYDS.
Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. Density Ratio Estimation in Machine
Learning. Cambridge University Press, USA, 1st edition, 2012. ISBN 0521190177.
Yonglong Tian, Dilip Krishnan, and Phillip Isola. Contrastive multiview coding, 2020.
Che-Ping Tsai, Adarsh Prasad, Sivaraman Balakrishnan, and Pradeep Ravikumar. Heavy-tailed
streaming statistical estimation. arXiv preprint arXiv:2108.11483, 2021.
Masatoshi Uehara, Takafumi Kanamori, Takashi Takenouchi, and Takeru Matsuda. A unified statis-
tically efficient estimation framework for unnormalized models. In International Conference on
Artificial Intelligence and Statistics, pp. 809-819. PMLR, 2020.
11
Published as a conference paper at ICLR 2022
Martin J Wainwright and Michael Irwin Jordan. Graphical models, exponential families, and vari-
ational inference. Now Publishers Inc, 2008.
Lantao Yu, Yang Song, Jiaming Song, and Stefano Ermon. Training deep energy-based models with
f-divergence minimization. In International Conference on Machine Learning, pp. 10957-10967.
PMLR, 2020.
12
Published as a conference paper at ICLR 2022
Appendix
We will fist provide missing proofs for the eNCE results in section 6 in section B. Section C provides
proofs for NGD convergence on the NCE loss, and section D proves the negative results of NCE in
section 4). Additional notes on the experiments are provided in section E.1.
Notation: We will use a . b to denote a = O(b) with O hiding a constant less than 2. Similarly,
a & b denotes a = Ω(b) where Ω hides a constant greater than 2.
A Proof of convexity of NCE (Lemma 2.2)
As a preliminary, let’s first prove that the NCE loss is convex in exponential family parameters.
Recall that the NCE loss is
L(P) := 2Ep* log p++q + 1 Eq log *
(A.1)
where p(x) = p(τ > T (x)). The gradient and Hessian of the NCE loss are:
RTP(X) =p(x) ∙ T(x),
VL(T) =1 V [e* log p+q + Eq log p+q
2p	q
=1 [e* P P - P2-q Vτ P + Eq ɪ1 Vτ p] =1 Z -ɪ (P - P*)T (x)dx,(a2)
2	p +q	p2	p +qq	2 x p +q	(A.2)
V2L(τ)=1 Z (-q(P- P2) VτP + ɪ VτP) T(x)dx
2 x	(P+q)2	P+q
=1 Z ɪ ∙ p⅛4 ∙P ∙ T(X)T(x)>dx = 1 Z (P*+ q)PqT(X)T(x)>dx.
2 x P + q P + q	2 x (P + q)2
Hence the Hessian is PSD at any τ.
B Proofs for section 6 (eNCE)
We first write down the loss, gradient and Hessian of eNCE for the exponential family:
Lexp(P)=2 / p* yι+1 / q∖fi
VLexP(P) =4 / √q (√p - √p) V logp
V2Lexp(P) =1 / √q √P^p - √p) ∙ V2 logP + 8 / √q √P^p + √p) V logp(V logp)>
V log P(V log P)>
1 /p* vzIt (X)T (X)>+1 / q#(X)T (X)>.
(B.1)
Note that the Hessian is always PSD, which means Lexp is convex in the parameters of the expo-
nential family.
13
Published as a conference paper at ICLR 2022
B.1 Proof of Lemma 6.2
We directly calculate the Hessian at some T := τ* + Cu for some C ≤ j^ and ∣∣u∣∣2= 1, using the
expression in equation B.1:
V2Lexp(T)
T(x)T(x)>
/ eχp (hτ* + τq-τ ,t (X)〉) +eχp (〈 τq2τ ,t (X)〉)
T(x)T(x)>
/ [exp (hτq+τ^ - Cu,T(X))) +exp (〈≡q^ + Cu,T⑺川 T(X)T(x)>
L [exp (h-Cu,T(X))) +exP (hCu,T(x)))] exp (hɪɪ^,T(X)))T(X)T(x)>
pZ(京θ ) / [exp (h-Cu,T(X))) +exp (hCu,T(x)))] exp (<τ(θq+^),T(X))) T(X)T(x)>.
S----{-----}
B(P*,Q)
(B.2)
Note that without the term in the square brackets, the integration is exactly the same as the one for
H*.
We would like to bound the ratio V v>Leχp(τ)v for any Unit vector v. Denote S ：= CU, T :=
V 1 * H* v	J	2 ,
τ θq+ ++θ*) for notation convenience, and denote Si := {x : δ>T(x) > 0}, S-1 := {x : δ>T(x) ≤
0}. We have:
v>V2LexP(T)V ` Rχ∈s1 eχP (s>t(χ)) eχP (τ>T(χ)) (v>T(χ))2
v>H*v	-	Rχ exp (τ>T(x))(v>T(x))2
+ x∈S-1
exp (S>T(x)) exp (τ>T(x)) (v>T(x))2
Rx exp(T>T(x))(v>T(x))2	: T1 + T-1.
(B.3)
Recall that f ' g means functions f , g differ only by a constant factor. This equation will be used
to calculate both the upper and the lower bound.
For the upper bound, let χ ∈ {±1}, we have
∕x:X打T(x)>0 exp (χS>T(x)) exp (τ>T(x)) (v>T(x))2
Rx exp (T>T(x))(v>T(x))2
_	Z (χS+ θ+++θ*)	JX：打 T (x)>0 Pxθ+ ”+θq (x)(v>T (x))2
∙
Z(θq+θ*) ∙ exp(χα)	Jxp。*+。+ (VTT(X))2
Z (χS+ θ++θ*)	Eχθ+ θ*+θ+ [(v> T (X))2]
^≤	Ti : ""Ti	∙	7~Z —1— — "~"C r
_ Z(θq+θ*) ∙ exp(χα)	E。*+。+ [(v>T(X))2]
(B.4)
(i)
≤ exp βZ kθSk-χαS
Eχθ+ 5 [(v>T(x))2]
E θ*+θ+ [(v>T (x))2]
2
where step (i) uses the Lipschitz property of the log partition function in assumption 2.2.
For the lower bound, let χ* := arg maxχ∈{±i} TX. Write S = [θ, α] (i.e. separating out α which is
the normalizing constant), let S1 (v) ⊂ Sx* denote a set s.t.
∕∈s 1 WpXEU(X)(V>T(X))2 ≥ 1 ∕px*θ+ θ*+q(X)(V>T(X))2.
14
Published as a conference paper at ICLR 2022
Then Tχ for χ ∈ {±1} can be lower bounded as:
Z(χg+ θ +θ*)	Rχ∈s 1 (V)pχ*占+ θ*+ θq (X)(VTT(X))2
≥2______________2
_ Z(θq+θ*) ∙ exp(α)	Rx Pθ*+θq (v>T(X))2
1	Z(χ*夕+ θq+θ*)	Eχ*e+ θ*+q [(v>T(X))2]
≥----------2  ------------2^-^——ɪ—
2	Z(θq+θ*) ∙ exp(α)	Eθ*+θq [(v>T(X))2]
(B.5)
(i)	1
≥ 2eχp (一βzkm∣-χ*α)
Eχ*g+ θ*+θq [(V>T(X))2]
E θ*+θq [(V>T (x))2]
2
T-χ* ≥0
where step (i) uses the Lipschitz property of the log partition function in assumption 2.2.
This means for any unit vector v , we have
V>1V2 LexP (T)V
v>H*v
=T1 +T-1
-E^+ - [(v>T (x))2]	E-^+ - [(v>T (x))2]]
E θ*+θq [(V>T (C))2] +	E θ* +θq[(V>T (C))2]
-	2	2
≤2exp (βz∣Bk + ∣α∣) ∙ λmax ≤ 2exp (C(1 + βz)) ∙ λmax ≤ 2exp(1) •
λmin	2	λmin
VT V2 Lexp(T)V T T	(ii) 1 (Q II^Ii I -1∖ λmin 、	1	λmin
-----τ--^——=TI + T-I ≥ -exP (一βzkθkTα∣) ∙ — ≥ -——τπ •--
V H*v	2	λmax	2exp(I) λmax
≤exp (βzMk + ∣α∣) •
λmax
λmin
(B.6)
where step (i), (ii) follow from assumption 2.3.
Hence the eNCE loss satisfies assumption 5.1 with constants βu = 2exp(1) ∙ λmax, βι = 2©xp(i)
λmin
λmax
C Proofs for Section 5 (NGD and condition number at the
optimum)
This section provides proofs for results in section 5. Results for NGD convergence rate (Theorem
5.1 and Lemma 5.1) are proved in section C.1 and C.2. Section C.3 proves the convergence rate
stated in terms of the Bhattacharyya coefficient (Theorem 5.2), and the bound on Bhattacharyya
coefficient (Lemma 5.2) is proved in section C.4.
C.1 Proof of Theorem 5.1 (NGD convergence rate)
Theorem C.1 (Theorem 5.1 restated). Let L be any loss function that is convex in the exponential
family parameter and satisfies Assumptions 5.1 and 2.1 - 2.4. Furthermore, let P*,Q be exponential
family distributions with parameters τ*, Tq and let κ* be the condition number ofthe Hessian at P =
P*. Then, for any 0 < δ ≤	and parameter initialization to, let the step size be η ≤ J jβ^ δ,
performing NGD on the population objective L guarantees that after T ≤ βu^* ∙ kτ0-1*k steps,
there exists an iterate t ≤ T such that kTt - T* k2≤ δ.
Proof. Denote gt := VL(Tt) and R := kT* - Tqk2 for notation convenience. Recall that the NGD
update with step size η is τt+ι = Tt 一 η ∙ ɪggt^. Then// 一 τ*k2 can be rewritten as:
kTt+1 - T* k2=kTt -
T*k2-2γη + η2 + 2η
gt>	gt
厨 C*+Y 南-Tt
(C.1)
15
Published as a conference paper at ICLR 2022
If We set Y s.t. the last term is smaller than 0 for all T that are not within distance δ to τ*, setting
η = γ gives:
l∣τt+ι - τ*∣∣2≤ ∣∣τt - τ*k2-2γη + η2 = IlTt- τ*k2-γ2	(Cz
Hence the number of steps required to find a T s.t. ∣τ - τ* 12 ≤ δ is at most T ≤ kτ0-τ*k
By Lemma 5.1, setting Y = Jββ^δ ensures L(τ* + Yɪgtɪ) ≤ L(Tt) for any Tt that is at least δ
away from t* . It then follows from the convexity of L that
g> 卜*+Y 俞-Tt卜L α+Y Ih)-L(Tt) ≤ 0.
Substituting this choice of Y back to the bound for T gives T ≤ βu^* ∙ kτ0-τ*k
(C.3)
□
C.2 Proof of Lemma 5.1
Lemma C.1 (Lemma 5.1 restated). Suppose Assumptions 2.2 and 5.1 hold with constant βZ, βu
and βι. Let L be a convex function with minimizer t*, and let g := VL(t). For any δ ≤ W, let
Y = β-β^δ~δ, then forall T s.t. ∣τ - τ*∣∣2≥ δ, we have L(τ* + Y扁)≤ L(τ).
Proof. The proof follows from the Taylor expansion around τ*: for any unit vector V and any con-
stant c ≤ Y, the Taylor remainder theorem states that there exists some constant c0 < c and unit
vector v0 such that Lg + Cv) - L(TG = Crv>H(τ* + c0v0)v.
For any unit vector vι, v2 and constants c1,c2 ≤ δ such that L(τ* + cιvι) = L(τ* + c2v2), we have
22
L(τ* + C1v1) - L(τ*) = 21-v>H(τ* + c1v1 )vι = -22v2 H(τ* + c2v2)v2 = L(τ* + C2v2) — L(τ*)
⇒ c1 ≤	∕σmax(H(T* + CIvI)) ≤
C2 — σ σmin(H(T* + gv2))一
(C.4)
This means for any two points with the same loss, the ratio between their distances to τ* will be at
most Jβκ*. Therefore setting Y = ʌ/ββ∣- δ guarantees that for any T that is at least δ away from
τ*, τ will have a larger loss than any point that is Y away from τ*. In other words, L(τι) ≤ LE)
holds for any τι ∈ B(t*,y), τ2 ∈ B(τ*,δ).
□
C.3 Proof of Theorem 5.2 (Convergence rate in terms of B hattacharyya
coefficient)
R and initial estimate to = Tq, NGD finds
C ∙ BC(P*,q)3 ⅛*γ steps, where C :=
Recall that the Bhattacharyya coefficient of P*, Q is defined as BC(P*,Q) := JX ,p*(x)q(x)dx.
Theorem C.2 (Theorem 5.2, restated). Suppose Assumptions 2.1, 2.3 hold with constants ω, λmax,
and λmin. Consider a NCE task with data distribution P* and noise distribution Q, parameterized
by θ*,θq ∈ Θ respectively. Thenfor any given δ ≤
an estimate τ such that lτ - τ* l2 ≤ δ within T ≤
IQaYT!，2、 λ λmax 13 rnin / 2λmax 2λmin + γmax k δk ∖
18eχp( 访 ) ∙ ( Xmr ) ∙ minf ɪ"，K-YminMk f
Proof. Proving Theorem 5.2 requires bounding the condition number κ* and the Hessian-related
constants βu, βl .
We first show that κ* is inversely related to BC(P*, Q):
Lemma C.2. Let Θ be the set of parameters for an exponential family satisfying assumption 2.1-2.2.
Then, for any pair ofP* , Q parameterized by θ*, θq ∈ Θ, the NCE problem defined with P*, Q has
λ λ λmax_______1____
κ* ≤ 亦min bc(p*,q).
16
Published as a conference paper at ICLR 2022
The next lemma provides the Hessian-related constants in Assumption 5.1:
Lemma C.3. Let δ := T 一 τ*. Let BC(P*, Q) denote the Bhattacharyya coefficient between P*
and Q, then for any T such that ∣∣S∣∣≤ 泰,we have:
Gmax(V2L(T) ≤	1 8eχ (3 + ɪ ʌ λmax ⑺仙(2λmax 2 + YmaX kδk
σmaχ(V2L(τ*)) ≤ BC(P*,Q) ∙ pV2+ βZ 广 λmn * IXr, +	λmin
σmin(V2L(T))	1
λmin	λmin	γmin Mk [
σmin(V2L(τ*)) ≥ BC(P*，Q) ∙16exp(- 2 - βz)∙ λmX ∙ maxt λmX，1 - ^mr 卜
Hence Assumption 5.1 is satisfied with constants βu, βl equal to the respective right hand sides.
The factor C in the theorem statement is then chosen such that
C
BC(p*,Q)3
Theorem 5.2 is completed by applying Theorem 5.1 and the above lemmas.
≥ β, and the proof of
□
C.3.1 Proof of Lemma C.2
For exponential family with pdf p(x) = h(x) exp θ>x - log Z(θ) , the Hessian at the optimum is:
H* =	-P^T(X)T(χ)>dχ W / min{p*,q}T(X)T(x)>dx := M.
x p* + q	x
(C.5)
We also have H* 占 11 M by noting thatp* + q ≤ 2 max{p*, q}. Therefore in order to bound κ*, it
suffices to analyze the condition number of M .
For any pair of distributions parameterized by θ, θq ∈ Θ with PDFs p, q, and for any unit vector v ,
we have
√p√q(v>τ (χ))
min{√p, √q} max{√p, √q}(v>T(x))2 )
x
(min{√p, √q})2(v>T(x))2) ∙ (/(max{√p, √q})2(v>T(x))2)
min{P, q}(v>T(X))2 ∙	(P+ q)(v>T (X))2 ≤ 2λmaX	min{P, q}(v>T(X))2
x	x	(C.6)
where (i) uses Cauchy-Schwarz, and (ii) uses assumption 2.3.
Denote B :
√Z(θ)Z(θq )
. We have:
2
L √p√q(v>T (X))I = ⅛Z⅛ Ux P 学(X)(V>t (X))2) = B2
E θ + θq
、-2-
(v>T(X))22.
(C.7)
Zp+θq
Combining equation C.6, C.7 gives a lower bound of x min{P, q}(v>T (X))2:
Zx min{p,q}(v>T(X))2 ≥ L B (E ? (v>T(X))2)2
(C.8)
On the other hand, x min{p, q}(v>T (x))2 can also be upper bounded as:
m min{p, q}(v>T(x))2 ≤ [ √p√q(v>T(x))2 ≤ ɪEθ+θq [(v>T(x))2]
Jx	Jx	B 2
Hence the condition number of M is bounded as:
(C.9)
K(M):=maxv Jx min{p, q}(v>T(X))2
R . mi∏v Rx min{p, q}(v>T(x))2
≤
2 minv E
λmaxB	≤
θ + θq [(v>τ (x))2] ≤ 2λmin
2
∙ B.
(C.10)
17
Published as a conference paper at ICLR 2022
It is left to determine the value of B. We claim that B
1
BC(p,q)
,where BC(P' Q) is the Bhat-
tacharyya coefficient of P and Q defined as BC(P) Q) := JX y∕p(χ)q(χ)dx. To see this, note that it
holds for any x that log Zθ = θτx + log h(x) — logpe(x). Hence for any x,
B-1 = exp (logZθ+θq — 1logZ — 1logZ勰) = "&(?&”.	(C.11)
∖	~^2~	2	2	qJ	P θ+θq (x)	'	'
2
Therefore B-1 = (JXP?(x)) ∙ B-1 = JX ^P(x)pθq(x) = BC(P' Q).
C.3.2 Proof for Lemma C.3 (Bound on BC(P*,Q))
Proof. For notational convenience, write S =[4)a], where a = log Z(θ*) — log Z(θ) is the differ-
ence in the coordinate for the log partition function.
Upper bounding ;max((^2L((T)))): We proceed by splitting vτV2L(τ)v into two terms:
vτ V2L(τ )v
=Z	(p* + q) / Pq、2 (VTT(x))2dx + Z	(p* + q) / Pq、2 (vτT(x))2dx.
Jδ>τ (x)<0	(p + q)2	Jδ>τ (x)>0	(p+ q)2
(C.12)
The first term is bounded as:
/	(P*+ q)( Pq、2(VTT(X))2dx = f	(P* + q)PlqlD(VTT(X))2dx
Jδττ(x)<0	(p+ q)2	Jδ>τ(x)<0	q+ P+ 2
≤ [	(p* + q) p 1 q (vτT(x))2dx ≤ I	(p* + q) ∙ min q-,-∖ (vτT(x))2dx
JδτT(x)<0	q 十 P	，打T(x)<0	IPqJ
=Z	(p* + q) ∙ min (----fSτ	) p* eχp3TT(X)) ) (vτT(x))2dx
Jδ>τ(x)<0	[P* exp CT(x))	q	J
=Z	exp (—<FT(x)) (p* + q)min [工 P* exp(2STT(X)) ) (VTT(小
/打 T(x)<0	Ip*	q	J
≤ / exp (—STT(x)) (p* + q) min ( -q-, p* ∖ (vτT(x))2dx
/打T(x)<0	Ip* q J
≤ 2/ exp (—STT(x)) min{q,p*}(vτT(x))2dx
(ii)	('	('	____
≤ 2	exp (—STT(x)) min{q,p*}(VTT(x))2dx ≤ 2 exp (—STT(x)) √p*q(vτT(x))2dx
=2Z(修-S) exp(-a) /	∙ (vTt(x))2dx
=2	√Z (θ*)Z (θq )	JXP F JV T(X)) dx
≤ 2Z(+ -)exp(YE…"T(x))2
一	√Z (θ*)Z (θq)	―-θ '"
(iii)	z (θ*+θq)	_	丁
≤ 2 p7(A ∖(A、∙ exp(βzθ — α)∙ Eθ*+q -O(V T(X))2
V z (θ*)z (θq)	2
'-----------'
{z^^^
:=1 / B
(iv)	2	1	1 ʌ	丁
≤ B ∙ exp (1 + 瓦 J ∙ E θ*+θq -O(V T (X))2
(C.13)
where step (i) is because STT(x) < 0; step (ii) increases the value by integrating over all x; step
(iii) uses Assumption 2.2 on Lipschitz log partition function; and step (iv) follows from the choice
of s = [s, α] that ∣∣s∣∣≤ 生.
PZ
18
Published as a conference paper at ICLR 2022
The second term can be bounded as:
(	(p* + q)( Pq、2 (v>T(χ))2dχ
δ>τ(χ (x)>o	(P + q)2
≤ I	P* + q min{p, q}(v>T(x))2dx ≤ /	min{p,q}(v>T(x))2dx
Jδ>τ(x)>0 P + q	Jδ>τ(x)>0
≤ Z √Pq(v>T(x))2dx = Z(：+")exp(—Eθ*+°+θq (v>T(x))2
JX	JZ (θ* + θ)Z (θq)
(i) Z(θ*+θq )	3 3
≤ P (Θ*2Z (θq ) E — (VP (X))2 ^ eXP(2 βzkθk2-a)
≤ B exp (2 + 瓦)∙ E θ*+Wq (V>T (X))2
(C.14)
where step (i) uses Assumption 2.2 about Lipschitzness of the log partition function, and step (ii)
is because We have chosen that gk2≤ /.
Substituting back to equation C.12 gives:
v>V2L(τ)v ≤B
2exp(1 + ɪ) • Eθ*+θq _g(v>T(x))2 + exp f∣ +	• E θ* +θq +θ (v>T (X))2
.	∖	βZ J	2 θ	∖2	βZ J	2
≤2exp( 32 + βz)
• min {λmax, σmaX(E θ* +θq [T (X)T (X) ]) + YmaXkδ
(C.15)
B
Where the second inequality uses Assumption 2.3 and Assumption 2.4 for the first and second term
respectively.
Recall that v>V2L(τ*)v ≥ 4^λ^
(E θ* +θq (v> T (X))2	. Hence:
σmaX(V2L(τ))= maxv v> V2L(τ)v
σmaχ(V2L(‰)) maxvo V>V2L(τ*)V
/3	1 ∖ Eθ*+θq -g(v>T(x))2 + Eθ*+θq+g (v>T(x))2
≤ 8λmaxBexp ( 2 + β~ )	2	7	2 C2
' PZJ	maxv (Eθ*+θq (v>T(x))2J
≤8
λmaX
λmin
Bexp
.ʃ
• min
(C.16)
≤8
λmaX
λmin
(2+βZ
Bexp
• min∕2λmaχ, 2 +
λmin
2λmaX
Mr, 十
_________YmaXkSk_________
σmaχ(E θ*+θq [T(X)T(x)>])
2
YmaX kδk
λmin
)
Lower bounding	；min((^2L((T)(:	Let Us denote S1	:=	{x	:	J>T(x)	>	0}	and	S-1	:= {x :
δS>T(X) ≤ 0}. The goal is to loWer bound:
v>V2L(τ)v = j	(p* + q) Pq (v>T(X))2dX + [	(p* + q) / Pq 2 (v>T(x))2"x
x∈S1	(P + q)2	x∈S-1	(P + q)2
:=T1 +T-1
(C.17)
Let’s loWer bound T1, T-1 in each of the folloWing tWo cases.
The first case is when T_1 ≥ Ti. Let S1 (v) ⊂ S- denote a set s.t.
/ Sn)min{p,q}(v>T(x))2 ≥ 1/ min{p, q}(v>T(x))2
19
Published as a conference paper at ICLR 2022
Write S = [θ, α] as before, then
Ti ≥0
1=LT j*+q)(P⅛ (JT (X))2 dx (≥) L ⑺ <o 个(v>T"
1	Γ	(ii) 1 Γ
≥- J	min{p, q}(vτT(x))2dx ≥ - J ɪ	min{p, q}(vτT(x))2dx
(iii)	1 」 .	TFV 、、2 j (iv) eχp(-α) Z(+^2q )2
≥ - min(p, q}(vτT(x))2dx ≥ --------∙ ———2---
≥ 4 J 小八(J)	≥ 8λmax Z(θ)Z(θq)
S exp，-。) ∙a exp(一2眼向|) ∙ (E。*+2(VTT (X)))
8λmax	B	、	2	/
(E 峥(VTT (x))2)2
2
where step (i) uses pp++q < 1 since STT(x) < 0; step (ii), (iii) follows from the definition of
S-1; step (iv) uses equation C.8; and step (V) uses Assumption 2.2 that the log partition function is
Lipschitz.
The second case is when Ti ≥ T-i. Let Sι (v) U Si denote a set s.t.
(	min(p, q}(vτT(x))2 ≥ 1 ( min(p, q}(vτT(x))2
J X∈S 1 (V)	2 JX
Then T_1, T1 can be lower bounded as:
T-1 ≥ 0
T1
LSC+q)(⅛⅛
(vτT (x))2dx
≥! j p* + q ∙ min{p, q}(vτT(x))2dx ≥ - j	p* ∙ min{p, q}(vτT(x))2dx
2	Xxss1 p + q	2 Xxss1 p
=exP)(O) /	min{Pθ*,Pθq-(j}(VTT (X))2dx
2	XxES1
≥ exP)(O) /	min{P%,Pθq-θ}(VTT (X))2dx ≥ eXp(O) / min{p%,Pθq-0}(VTT (X))2dx
2 JXES ι (V)	4	JX
2
exp(α)	Z()2 (E	tt,))2)2
≥^λm∑∙Z(θ*)z(%-S) (Eθ^(v T(x)))
≥ aP -' ∙正 exp(-2βzIlSk) ∙ (Eθ*+°q-θ(VTT(X))2) ∙
8λmax B	2
(C.19)
Combining both cases and using ∣∣s∣≤ 看,we get:
VTV2L(τ )v = T1 + T-1
≥ex"-2 - 否) ∙ B2 ∙ min { (E Yq+θ(vτT(x))2)2 , (EO*+1 (vτT(x))2)2j ∙	(C3
Recall that VTV2L(τ*)v ≤ B"E θ* +θq [(vτT(x))2]. Hence
σmin(V2L(τ)) = minv VTV2L(τ)v
σmin(V2L(τ*)) minvo VTV2L(τ*)V
16exp(-2 —
≥----------
≥ B
16 exp(-2 -
≥-----------
≥ B
βz ) λmin	[
Z-  ----- max <
λmax	I
βz ) λmin	f
E-  ----- max <
λmax	[
λmin
λmax
λmin
λmax
min
σmin (E θ*+θq 十@ TTT )
2	______
σmin(E θ*+θq [TTτ])
2
σmin(E θ* +θq-g TTT
σmin(Eθ*+θq [TTτ])
1 - YminkSk
λmin
(C.21)
20
Published as a conference paper at ICLR 2022
□
C.4 Proof of Lemma 5.2 (Bound on the Bhattacharyya coefficient)
LemmaC.4 (Lemma 5.2 restated). For P1,P2 parameterized by θ1,θ2 ∈ Θ, f ∣∣θι — θ2∣∣2≤ λ^,
then BC(P1,P2) ≥ ɪ.
Proof Given θ1,θ2 ∈ Θ, define a map φ from [0,1] to a function √p, where p is the PDF for a
distribution parameterized by some θ ∈ Θ: let Z(θ) denote the partition function for parameter
θ ∈ Θ, and let δ := θ2 - θ1, then φ(t) is a function ofx defined as:
φ(t)(x) = Jh(x) exp ((θι + tδ)>x — log Z(θι + tδ)).
Denote φt(x) := φ(t)(x) and θt := θ1 + tδ for notation convenience. Then
∂φt(x) _d √hh exp (1 θ>x)∖ _ √h	C θ> ʌ δ>x ∙ VZZW - √⅛ dZ(θt)
~^= = ∂t 1一√Z(θt)	J=彳exp (2 t x)	Zw
δ XPEθt[δ a =1 √pa (X)(S>x -EθJδ>xD
where step (*) used
∂Z (θt)
∂t
Hence
h- / h(x) exp (θ>x) = / h(x) exp (θ>x) δ>x = Z(θt)Eθt [δ>x].
∂t x	x
∂φt	=/(∂φt(x) Y = RxPθt(X) (δ>x ― E%[δ>χ])2
而L2 := Jx1蓝厂= =	4
Varθt (δ>X)	δ>Eθt [XX>]δ>	λmax	2
=	4	=	4	≤ ~^~kδk2.
(C.22)
(C.23)
(C.24)
(C.25)
Using the fundamental theorem of calculus, we get
k√pθ1 — √PΘ2kL2 = kφ(i) - Φ(0)kL2 = Zt1o dφ∂(x)dt ≤ Zt1o dφ∂x dt ≤ λmaxkδk2.
t=0	t=0	(C.26)
HenCe Rx √pθi√pθ2 ≥ 1 - λ8xkδk2, Or Rx√Pθ1pθ- ≤ 1-$1囱2for kδk2< λm8ax. Inparticular,
forany θι,θ2 satisfying kδk2:= kθι -θ2k2≤ λmax, Rx√⅛⅛ = bc(⅛ ≤ 2,i∙e∙ BC(P,Q) ≥
As a side note, another bound we can get is from Lipschitzness of the log partition function:
B := Z(θ1+θ2)	=	1
L √Z(θι)Z(θ2) — BC(P, Q)
Z(θ*)exp (βz ∙也-θqk)	(3
≤ √Z(θ*) ∙ Z(θ*)exp(-βz∣∣θ*- 葡=exp (2βZ ∙ kθ* - θqk2
WhiCh is tighter than 1 λmlχ kδk2 if √λmax	βZ .
(C.27)
D	Proofs for Section 4 (negative results of NCE)
This seCtion provides proofs for the negative results in seCtion 4, that is, the NCE landsCape is
ill-behaved with exponentially flat loss, gradient, and Curvature. We will first prove Theorem 4.1
and properties regarding losses and gradients, then prove results related to seCond-order properties
(Lemma 4.1, 4.3, 4.2, Theorem 4.2).
21
Published as a conference paper at ICLR 2022
Figure 3: The gray-shaded area is the region where equation D.7 is satisfied. The orange dot marks
τ*, which is enclosed in the green-shaded area. Moreover, the red-shaded area centered at τ* Corre-
sponds the width-0.1R annulus A, within which the gradient is exponentially small.
D.1	Proof of Theorem 4.1 (Lower bound for gradient-based methods)
Theorem D.1 (Theorem 4.1 restated). Let P*, Q, P be 1d Gaussian with variance 1. Assume θq =
0, θ* > 0 without loss of generality, and assume R := θ* — θq》1. Then, gradient descent with
any step size η = o(1) from an initialization τ = τq will need an exponential number of steps to
reach some τ0 that is O(1) close to τ*.
Proof. The key lemma to prove Theorem 4.1 is as follows, which upper bounds the decrease in
parameter distance from each gradient step:
Lemma D.1. Consider the annulus A := {(b, c) : (C — R)2 + (b — R)2 ∈ [(0.1R)2, (0.2R)2]}.
Then, for any (b, c) ∈ A, it satisfies that
(▽L(T),产Ti = O(1) ∙ exP (- κ(b,c) ^ R2)	(D.1)
kτ* — τ k	8
where κ(b, C) ∈ [4, 4] is a small constant.
Lemma D.1 is proved in section D.2.
To prove Theorem 4.1, we will first show that Lemma D.1 serves as an upper bound for the decrease
in parameter distance, that is, showing η ∣ (VL(τ), 自二："i ∣ ≥ IlTt — τ* | — ||7力+1 — τ*∣∣. Towards
this claim, we write τt+1 as:
τt+ι =	Tt -	ηNLm) =	Tt - η (vL(τt),ττ*T^)∙	τ*Tt	-	ηV	(DZ
∣T* — Tt ∣	∣T* — Tt ∣
where V := NL(Tt) — (NL(Tt),仁二Ttk〉∙ ||T：-TtIl is orthogonal to t* — Tt. Hence
kTt+1 — T*II=(1 — η	∕vL(Tt), /*^)) ∙ ∣∣Tt — T*k+η∣∣v∣∣.	(d.3)
∣T* — Tt ∣	∣T* — Tt ∣
From this, we can conclude
kTt — t*k—kTt+i — t*Il= η卜Lg,/T^) 一 ηkvk≤ n\(NL(Tt),ττ*T^)∣. (D⑷
IT* — Tt I	∣	IT* — Tt I	∣
The next step is to show that there is a path lying in A of length at 0.01R that gradient descent has
to go through. We have the following lemma (proof in appendix D.3):
Lemma D.2. Let η = o(1). For any T s.t. IT — T* I≥ 0.2R, letT0 denote the point after one step of
gradient descent from T, then IT0 — T* I> 0.15R.
22
Published as a conference paper at ICLR 2022
From any such T0, the shortest way to exit the annulus A is to project onto the inner circle defining
A, i.e. the circle centered at τ* with radius 0.1 R which is a convex set. Denote this inner circle
as B(τ*,0.1R) whose projection is ∏b(t*,0.ir), then the shortest path is the line segment TT —
∏b(t*,0.ir)(t 0). Further, this line segment is of length 0.05R since ∣∣τZ — τ*∣∣> 0.15R by Lemma
D.2, while the decrease of the parameter distance (i.e. ∣τ — τ* ∣) is exponentially small at any point
in A by Lemma D.1 and equation D.4. Hence the number of steps to exit A is lower bounded by
______0.05R
η∙O(1)∙exp(-喈
ω(R) exp
D.2 PROOF OF LEMMA D.1
Recall that for 1d Gaussian with a known unit covariance, we can use parameter T := [b, c] and
sufficient statistics T(x) := [x, —1], with pdf p(x) = exp (— x2) ∙ exp((τ,T(x))).
For any T such that ∣τ* — T∣∣≥ 1, ∣(VL(t), /-；∣∣) ∣ can be upper bounded as:
2 (VL(t ),^^ɪɪ) ≤ 2 KVL(T ),t*—τ )| = ∣' P^P (T (x),t*—τ)
∣τ* ― TIl	Jx q + 1
r2	-I I
(r — b)x ---log √2π + C ∣	(D.5)
≤(R—b) /EX + R2+log√2∏—C∣.∣∕E .
JXq+1	2	IyXq+1
p P — P*
JXl+1
Let a ` b denote a = kb for a constant k = Θ(1). We first show the calculations with b > 0 for
cleaner presentation; the b < 0 case is analogous and deferred to D.2.2.
Bounding ∣ ∕x p-⅜ ∣ :
≤
TIO)
+L。-世声exp (-
X x2 一 、	R2
> ig √2∏ exP (- 2 + (R - &)X + C - H - 2 log
≥ b	∖
, V----------------------------------------------------
(X - R)2
--2~L- - log
~{^^^^^^^^—
t4o)
(C — log √2π)2
(C — log √2π)2
(i)	1
1
1
1
2b2
2b2
I____________∙ exp —
√2π b - CTOgVZ2π	V
b
H---■；=-------exp —
√2π c-log√2π	\
—
c-log ,2π
b
/
exP (-H)
~{^^
T3O)
□
To
—
2 ∖
2
✓
where κ(b, C) ∈ [4, 4]. Step (i) uses calculations in equation D.12-D.15 (deferred to subsection
D.2.1 for cleaner presentation), and assumes (b, c) belongs to the set V := {(b,c) : C ∈ [b(R — b), b ∙
(D.6)
23
Published as a conference paper at ICLR 2022
min{b, R}]}. In particular, the annulus A := {(b, c) : (c 一 R)2 + (b 一 R)2 ∈ [(0.1R)2, (0.2R)2]}
is a subset of V when R	1. Step (ii) considers (b, c) ∈ A.
We can choose b, C s.t. b ≥ RR, C ∈ [b(R 一 b), b ∙ min{b, R}], so that We pick UP the tails in T(0) to
T4(0). This means:
ʃ c ∈ [b(R 一 b), b2] , b ∈ [RR, R],
C c ∈ [—b(b — R), bR], b ∈ [R, ∞].
(D.7)
Bounding ∣ JX Pp-PLx|: Using similar calculations as before, we have that when C — log √2∏ > 0
(Which is the case for τ = [b, C] ∈ A),
P p — p*
X
P p*
/e X
≤ max
p
PIx,
—Z Jr4+max
∙∕x<0 P + 1 J
p*
PIx,
- Zχ<01⅞1 x}.
(D.8)
≤
x
p
F1X
+
Below we bound the case where X > 0; the other case (i.e. X < 0) has an upper bound of the same
order following similar calculations and is hence omitted.
/	$ X+/
√x>o q + 1	√x>o
≤	exp
Jχ∈[0, CTog R]
、	,
^{^≡
T1(1)
p*
P + 1X
q
—X- + bX — C) X + Z	exp (-X- - log
2	X	xx> CTog R	∖ 2
---------------} X---------------------------
X
{z^^
T2(1)
}
匕驻-log
X
+	exp
Jχ∈[0, CTog V2π ]
、
—
}
'∙^^^^^^^^^^^^^^^^^^^^^^^^^{^^^^^^^^^^^^^^^^^^^^^^^^^^
T3(I)
X2	R2
+	L exp —k + (R — b)x + C —亏—2log
Jχ≥ Cig √2π	\	2	2
X-------------------------------------------------------
X
}
{z^^
T4(1)
(i)	1
‘exp(—c) — -7=exp
2π
(c — log √2∏)2
2b2
e-------^eXP
√2∏ c-log V2π
(c — log √2∏)2
2b2
1
+ —^exp
√2∏
1
+ —^exp
√2∏
—
1
---^eXP
√2∏
(c — log√2∏ — bR)2
2b2
+ RT3(0)
(c — log√2∏ — bR)2
2b2
+ (R — b)T4(0)
—
—
1
1
—
(D.9)
where step (i) uses calculations in equation D.16-D.19. Ignoring small constants log√2π in C —
log √2π, and denoting E1 := exp (一品),E2 := exp ( — (c-bR) ) for notation convenience, we
24
Published as a conference paper at ICLR 2022
can substitute equation D.6 and D.8 into equation D.5 as:
(R - b)∖ L ⅞⅞⅞ x ∣+∣ r2+iog √2-CH L ⅞⅞⅞
JxqI	IFxqI
小 小 小 小	R2	L
≤(R - b) ∙ (T(1) + Tf) + Tf) + Tf)) +	+ log √2 - C
∙ (T(O) + T2() + T(0) + T(0))
=O(R) exp(-c) — Ei + bT『)+ Ei + exp (——) — E2 + RT「+ E2 + (R — b)T^
+ Θ(R2) ∙ (T(0) + T(0) + T(0) + T(0))
=O(R)
exp(-C) + exp
+ Θ(R2) ∙ O(RT) exp (- RyR )
=O(R) exp -
κ(b, c) ∙ R2
8
(D.10)
where κ(b, c) ∈ [3, ∣] is the constant defined in equation D.6.
Since T ∈ R, ∣∣τ* - T∣∣= Θ(R), and the proof is completed by:
"L(τ)
τ* 一 T 、
l∣τ* - τIl
O(R) exp (- Mb吵Rr
Θm
C∕1∖ R κ(b,c) ∙ R2、
o⑴eχp I------8——卜
(D.11)
D.2.1 Calculation details for equation D.6 and D.8
We now calculate term T(0 and T(I) used in equation D.6 and D.8.
T(O)= ∣'
J x<
exp (————+ bx — c
c —log √2π	∖	2
(c-log √2π)2
1
1
√2π 八 _ c—iog√2π
∙ exp -
C — log √2π < b2
C — log √2π ≥ b2
C — log √2π < b2
exp
—
(c-log √2π)2
C — log √2π ≥ b2
(D.12)
√2π C-log √2π
2b2	)
,∙exp
T2(0) =
J x≥
1
√2∏
1 -
c — log √2π > 0
c — log √2π < 0
(D.13)
√2π R- CTOg √2 exp
____1_____exp (- (CTOg √2π)2 ʌ
c—log √2∏_'1	2b2	,,
1	1 exp (_ (Cig √2π)2
√2π |c—log √2πι	Pl	2b2
c c —log √2π	π∖2
( b -R)
2
1 - √2π c-% √∏	Rexp
(c -log √2∏^-R)2
2
c — log √2π < bR
c — log √2π ≥ bR
1
—
2b2
—
—
(D.14)
25
Published as a conference paper at ICLR 2022
exp
(R - b)2
(R - b)2
R2
+ c----
2
((R-b)2 ,	R2
exP(2^ + C - R
((R-b)2 , R2
eχp ^rɪ + C - R
2 log
2 log
1______
√2π R-b-
1 R b C-log √2π exp
—
1	((R-b)2	.
2 exp (	2	+ C -
—
√2∏ Cjg R-(R- b) exp
R2
ɪ — 2 log
exp
、c一log √2π
≥ b
(X - (R - b))2
—
C-IOg √2π-(R-b) exp
2 log √2π I	exp
)Jx> Cig √2π-(R-b)
c
:一log √2π )2
b
2
c一log ∙∖∕2π
b
T~
一 log √2π)2
c-log √2π
b
7T~
c-iog √2∏ exp
b
2
c — log √2π < b(R — b)
C — log √2π ≥ b(R — b)
c — log √2π < b(R — b)
c — log √2π ≥ b(R — b)
T(0) = exp
2
+ c
—
2
2
—
—
—


b
2
2
—
(D.15)
exp
≤ exp
exp
exp
Tf)
+ bT(0)
C — log ∙∖∕2π I
b ]
_	/ 、	1	( (c — log √2∏)2λ	(0)
= exp(-C)-萍exp -	22	+ + bT1
(D.16)
exp
(X — b)2
-2-
—
Ty= L> c-ob√π √2πexp
— exp
∞
c — log √2π
b
1
—^exp
√2∏
(c — log √2π)2
2b2
(D.17)
—
T(I) =/	-Lexp (-(^) X
Λ∈[0,Cjg√2π] √2π	V 2	)
≤ Z	ɪ exp (— (X - R)2 ) (x — R) + RTP
J∈ξ0[o, Cjg H ] √2π	k 2 J
-R
c —log √2∏	R
b	R
+ RT(O)
(D.18)
26
Published as a conference paper at ICLR 2022
TE)
exp ( (R ~2	b)	+ C -	R-	- 2log √2∏)	L C iog 为 exp (-	(X	-	(R	- 6) )	(X - (R - b)) +	(R - b)T(0)
((R - b)-
exp∖^^~
((R - b)-
exp∖^^~
+ c - R- - 2 log √2∏) /	exp (- x-) X + (R - b)T(0)
2	X jx>c-log v2π -(R-b)	∖ 2 J
+ c - R- - 2 log √2π›) [- exp (-x-)	+ (R - b)T(O)
2	2 L	∖	2 ) c c-log 2π--(R-b)
2∏ exp (- (C- lθg 烧-bR)-) +(R - b)Tf)
(D.19)
D.2.2 Calculations for b < 0
We now calculate the gradient norm bound for the case where b < 0. Recall that:
IVL(T )∣∣2≤∣nl(T )∣∣1= p pp-ɪp x + p pp-ɪp
Jχ q +1	Jχ q + 1
Bounding ∣ RXp-Pf ∣ ：
exp (-x2 + bx - C) - exp (- (X-R)2 - log
(D.20)
exp (bx — c + log vz2π) + 1
≤ L CTOg √- exp
-χ2- - log
exp ( - X——+ bx — c
> c —log √2-	∖ 2
, 、一	、/
™{^™
t20-
X	X χ2	、	R-
+ L c-log √-exp (-E + (R - b)x + C - H - 2log
、	、/
{^―
T30)
exp
、C — log -∖∕2-
> b
(X -
2
亚-log
✓
{^™
T402
/ P - 0*
LJ+
L
{^™
✓
—
O(1)
(D.21)
where Ti(0) terms are calculated as:
L c-ob√- exp
2
-工-log
c —l1g √2- exP
(c-log √2π)2
V	b	、
1 - √2∏ ∙ c -lo1 √2- eχp
b
2b2
b^
<0
(D.22)
(c-log √2π)2
c-log yz2π
b^
1

—
—

> 0
27
Published as a conference paper at ICLR 2022
Z	exp (—— 十 bx — c
Jχ> Cig √2π	∖ 2	,
exp
exp
、C — log √2π
≥ b
(x — b)2
exp
eχp (bT
exp
exp
C-log √2∏ L
b	b
b $ √2∏ ∙ exp 卜亚^ √2π
c-log √π b ∙ exp
b	b
1____
√2π b—
√2π C-Iog √2π —b
b
• exp
c-lθg √2∏ • exp
b	___
(c—log √2π)2 J
(c—log √2π)2
c—log "2π
b
c—log yz2π
c—log "2π
b<0
^2b2
b>0
(D.23)
1
1
—
—
√2π c-log √2π —(r — b)
1	((R—b)2 I
2∏ eχp	ɪ + C —
c-log √2π ∏∖ 2
b	RJ
2
c —log yz2π
c —log yz2π
—	(R — b) < 0
—	(R — b) > 0
—
exp
c —log ,2π
—	(R — b)
>0
-⅛-----——exp
√2π R — b— c-log √2π	ɪ
八°	b
__________	、2
c-log √2π —r )
2
c —log yz2π
—(R — b)
<0
(D.24)
R > 0
—
R < 0
—
1
—^exp
—R √2π
(D.25)
—
2
—
—
—
1
C • 1 —
c
c
1
—
—
b
—
b < 0
1 c c—log ∖[2
2
b
b
—
b > 0
—
赤
—
b
—
b
b
T
T
Bounding ∣Rχ P-P~ x ∣ :
+
L
P
F1X
P*
F1X
}+鹏{∕>o 币X，
P	p*
—L<o 尹X
)∙
(D.26)
As before, we will show the bound for the case where x > 0; the other case (i.e. x < 0) follows a
similar calculation and has an upper bound on the same order.
First consider b < 0, C — log √2π > 0:
/
J x>0
≤ /
J x>0
p l p	p*
F1X+Z>o f+ιX
px + / P*X ' b2 + I exp(—c) + 1 + ι +r2 exp
O(1),
(D.27)
28
Published as a conference paper at ICLR 2022
where step (i) uses the following:
Z	exp (一ɪ + bx — C)X = exp (———C) Z exp
(x — b)2
—2—)(x — b + b)
b2
expU- c
b2
expU- c
∕>0exp
—
exp
J x> — b
exp (-S
(x — R)2
2
=1 + i⅛exp
—
x ≤ exp
b2
FeXP
When b < 0, C — log √2π < 0,
/ PJ p*
Λ>0 EX+Λ>0 hX
f
√x∈[0, Cjg R
X-------V-----
qx +
]
,
/
J x≥
px +
C — log ∙∖∕2π
TIa)
≤16max{R, |b|},
b~
{z^^
T21—
,
where Ti ) terms are calculated as:
—
x + b exp
+ 1
—
b2 + 1eXp(T)
R2
1+R2exp
(D.28)
/
x x∈[0,
p*q
Cjg √2 ] P Jχ>
----V---------} |----
T3(I)
「p*
c — log √2π
b~
{z^^
T(1)
(D.29)
,
—exp
c - log ∙∖∕2π
b
1 — exp
—
(c — log √2π)2
2b2
(D.30)
0
T(I- = /	qx
,	√χ∈[0, Cig √2π ]
—
(c — log √2π)2
1
—
2b2
L exp
JX> Cig W-b
(x — b)2
---------X
2
(D.31)
1--------------T= ∙ exp
1 — c—log VZ2π J
TU' = ∕∈[0,
p*q
exp
c —log √2∏ ] P
(R — b)2
/	L呻
x∈[0, CTOg v2π ]
—
(x — R)2
2
—bx + c — log
2
—
exp
(R — b)2
—
R2
2
R2
2
exp
c — log √2π I
b ]
—
(x — (R — b))2
2
2
exp
+ c — log
+ C — log
— exp
c—log "2π
b___
^^2
exp
日一(R—b), Cig E — (R-b)]
(x + R — b)
-Rɪ) +(R — b) ∙球-
(D.32)
where β31- = O(1) is:
β311
2 — r—b exp
孥 + c — log
—
Cjg √2 — (R—b) exp
—
(Cig 乒-R)2
2
c—log yz2π
b
> R — b
Cjg √2π-(R-b) exp
—
/ c —log √2π	π∖2
( b -R)
2
exp
警 + c — log
c—log "2π
b
< R — b
(D.33)
29
Published as a conference paper at ICLR 2022
Jx>c-log e
L exp
Jx>c-log e
—
(x — R)2
2
(x — R + R)
(
c—log ,2π
b
L	eXP
Jχ> Cjg v2π —R
X + R	exp
Jχ> CTOg √π —R
(D.34)
上+ R ∙吧
exp
—
2
where 区：—=O(1) is:

~— ~c —log √2∏ exp
R	b
(c -log √2∏^ —r)2
2
c — log √2π	R exp
b	R
(CTOg 'H — R)2
2
c -log ∖f2 / R
b < R
c —log √2∏、R
b / R
(D.35)
1 —
—
—
Combining equation D.21, D.27, andD.26 We have that kVL([b, c])∣∣2≤ 32max{R, |b|} for b < 0.
D.3 Proof of Lemma D.2
We first show the following claim, and prove Lemma D.2 at the end of this subsection:
Claim D.1. Forany T = [b, c] ∈ R2, the gradient norm at τ is IlVL(T )∣∣2≤ 32max(R, |b|}.
Proof. For parameter T = [b, c] where b > 0, C — log √2π > 0,
IlVL(T)∣∣2≤∣∣VL(τ)∣∣ι= / *4x + / *4
JXq + 1	JXq +1
(i)
≤ exp(—c) — exp
+ bτ(O)
+ exp
+ exp
— exp
(c — bR)2∖
2b2-)
—
+ RT(O) + exp (—(C 盛R) ) +(R — b)T40) + T(O) + T(0) + T(0) + Tf)
(% (b + I)T(O) + T(O) + (R + I)T(O) + (R — b + ImO)
≤4 + b + R + max{R — b, 0} . 2 max{R, b}.
(D.36)
where step (i) and (ii) use equation D.16-D.19 and equation D.12-D.15. Moreover, step (ii) in-
creases the value by at most 16. Hence overall we have ∣∣Vτ L∣∣2≤ 32 max{R, b}.
When b > 0, C — log √2π < 0:
P — p*
≤ X
P
F1
x
x
+
q + 1
X
X
P*
F1
x
≤ max[ Z y⅜1X + Z JpIx，— Z y⅜1X — Z τp3 xl∙
[Jx>o q + 1	√x>o q +1	√x<o q + 1	√x<o q +1 J
(D.37)
30
Published as a conference paper at ICLR 2022
Let,s bound the first term (i.e. x > 0); the bound for the second term (i.e. x < 0) follows from
similar calculations and is on the same order.
P 山 X +/ 占 X ≤ I' qx +/ PqX
Jx>0 q + 1 Jx>0 q + 1 Jx>0	Jx>0 P
=√2π ∕>0exp (-Xr)x + √2π ∕>0exp (-Xr+ (R - b)x+c - ∖- log √2π)
1 + (R - b) exp (b——Rb + c - lo
1 + (b-R1)2 + 1 exp (-^2 + C - log
+ (b-R1)2 + 1 exp (-与 + C - lθg √2π)，
R — b > 0
R — b < 0
O(1).
(D.38)
Step (i) omits a factor of √= and uses:
x2	R2
J exp (--2 + (R - b)x + c - - - 2log
x
exp
(R - b)2
-R2 + C - log
exp -
(X-(R - b))2 ) X
exp
(R - b)2
-R2^ + C - log √2π) [Z	exp
(b-R)2 + 1
(R — b) exp (b2 — Rb + c — lo
R R2 .	1
exp ( - R + c - log
+
2
exp
(b-R)2 + 1
+ c - log
R-b>0
x + (R - b)	exp
J x>-(R-b)
R-b<0
2
2
1
1
(D.39)
For b < 0, we similarly have ∣∣VL(τ)心= O(max{R, -b}). The calculations are similar to the
b > 0 case and hence omitted.
□
We are now ready to prove Lemma D.2, which we restate below.
Lemma D.3 (Lemma D.2, restated). Let η = o(1). For any T s.t. ∣τ — τ*∣∣≥ 0.2R,let T0 denote the
point after one step of gradient descentfrom T, then ∣∣τ0 — τ*∣> 0.15R.
ProofofLemma D.3. We will prove by contradiction. First assume that we can go from T where
∣∣τ - τ* ∣2≥ 0.2R to some TZ where ∣∣τZ - τ* ∣2≤ 0.15R. Then ∣∣τZ - τ* ∣ is lower bounded as:
(i)
IITZ -τ*∣∣≥∣∣τ-τ*∣∣-η∣∣VL(τ)∣∣≥ |b - R∣-η∣∣VL(τ)∣∣
(D.40)
(ii)
≥ ∣b — R|—32ηb
1 — y — 32η) b
where step (i) uses ∣∣τ - τ*∣≥ ∣τ[1] - τ*[1]∣≥ ∣∣τι∣-∣τj∣∣ = ∣b - R∣, and step (ii) is by Claim D.1.
On the other hand, we have ∣∣τZ - τ*∣≤ 0.15R by assumption, which when combined with equation
D.40 gives b ≤ ∣1-jj-32n, or b = O(R). This means ∣∣τ - τ*∣-∣τZ - τ*∣≤ η∣VL(τ)∣= o(1) ∙
O(max{R, ∣b∣}) = o(R). However, we also have ∣∣τ - τ*∣-∣τZ - τ*∣≥ 0.05R = Θ(R) by
assumption. This is a contradiction, which means the assumption must be false, i.e. τZ cannot
satisfy ∣∣τZ - τ*∣∣2≤ 0.15R.
□
D.4 PROOF OF LEMMA 4.1 AND LEMMA 4.2
We prove Lemmas 4.1 and 4.2 in this section. First recall the lemma statements:
31
Published as a conference paper at ICLR 2022
Lemma D.4 (Smoothness at P = P*, Lemma 4.1 restated). Consider the 1d Gaussian mean es-
timation task with R := ∣θ* — θq |》 L Then the smoothness at P = P* is upper bounded as:
*
σmax
R
zσmax(V L(TJ) ≤ ex eχp(-R /8).
2π
(D.41)
We will also need a bound on the strong convexity constant (i.e. smallest singular value) at P = P*:
Lemma D.5 (Strong convexity at P = P*, Lemma 4.2 restated). Under the same setup as lemma
4.1, the minimum singular value at P = P* is σ*nin(V2L(τ*)) = Θ (RR exp (— R82))∙
D.4.1 PROOF OF LEMMA 4.1 (SMOOTHNESS AT P = P*)
We will show the smoothness constant (i.e. σmax(V2L)) is exponentially small at the optimum, i.e.
when P = P* . The Hessian at the optimum is:
V2L(τ) = ɪ P P*' T (x)T (x)> dx = ɪ P P*' [x, -1]> [x, —1] dx.
2 xp* + q	2 xp* + q
(D.42)
Recall that θq = 0 w.l.o.g, and assume θ* = R 1. Then
1
2
V2L(τ )=1/	-p*q-T (x)T (x)τdx +
2 √x≤R∕2 p* + q
p	-p*q-T (x)T (x)τdx
x>R∕2 P* + '
.2/	p*T(x)T(x)τdx + 2 /	qT(x)T(x)τdx.
(D.43)
Let S 1 ⊂ R2 denote the circle centered as the origin with radius 1. The maximum singular value is
upper bounded by
-*口Y :=	max ɪ P P*' (aιx — a2)2 dx
[a1,a2]∈S1 2 χx p* + q
1
≤-
-2
1
=—
2
max
[a1,a2]∈S1
/
x≤R∕2
x≤R∕2
max
[a1,a2]∈S1
P* (a1 x — a2 )2 dx +	' (a1 x — a2 )2 dx
x>R∕2
p* (a2x2 — 2ai02x + aj) dx + /	q (a2x2
— 2a1a2x
2a1 a2
(D.44)
32
Published as a conference paper at ICLR 2022
where (i) substitutes in 1 or -1 for ɑ1,α2 and uses the fact that the upper bounds for T0,T11,T2 are
positive. (ii) uses the calculations on T0 to T2 shown below. We note that these calculations rely on
properties of Gaussian and do not extend to general exponential families.
T0=2 [
Jx>R厂,
TI= /≤R∕2
=/
√xz≥R∕2
=r /
J≥>R∕
(D.45)
For T2, denote Pr∕2 ：=	{x : X ≤ R}) = Pq ({x : x ≥ R}); Gaussian tail bound gives
Pr∕2 ≤ √2= Rr exp (- R-). Then we can calculate each term in T2 as:
/	p*(x)x2dx = / e. exp
J≤<R	J≤< R √2∏
(X -R)2 )x2dx
—
/ 2 √=exp ( - (X -R)2 )(x - R) ∙ xdx + R / 2 √=exp ( - (X - R' )xdx
(D.46)
∞
/	q(x)x2dx = /
exp(- X- )x
√2π
+ pR∕2
R
-
1 R	R2
√2π ^exp (-R
+ pR∕2
(D.47)
Hence T2 ≤ -R ∙ √2πexp (-Rr) + (R2 + I)PR∕2 ≤ (R + RR) √2πexp (-Rr)
33
Published as a conference paper at ICLR 2022
D.4.2 PROOF OF LEMMA 4.2 (STRONG CONVEXITY AT P = P*)
Lower bounding σm* in follows a similar calculation as for upper bounding σm* ax
_*	__，―
σmin := min
[a1,a2]∈S1
1 /	p*q
2 Jx p* + q
(aιx - a2)2 dx &	min 1 /
[a1,a2]∈S 1 4 x
p*q
max {p*,q}
(a1x - a2)2 dx
min
[a1,a2]∈S1
min
[a1,a2]∈S1
p* (a1x - a2)2 dx +	q (a1x - a2)2 dx
h/	p* (aιx2 — 2a1a2x + a2) dx + / q (aιx'
- 2a1a2x + a22 dx
min
[a1,a2]∈S1
p* +
≤ RR
'	Tz
(i) 1	1
≥ 4 √2∏ exp
11
exp
4 √2π
11
exp
4 √2π
11
=7^= exp
4 √2π
(ii) 1	1
≥ — exp
_ 4R √2∏
p*x2 + /
x
Tz
min
a∈[0,1]
min
a∈[0,1]
min
a∈[0,1]
min
[a1,a2]∈S1
R
ɪ +
R 2
2 a
p* x +
≤ rr	Jχ> RR
'	Tz
R 1	2	12
2 + R ) al - 4a1a2 + Ra2
qx 2a1 a2
ɪ ) a2 - 4ap1 - a2 + ɪ(l - a2)
RR
-4ap1 - a2 + ɪ
R
a(R a-4pT-Σ2) + R
(D.48)
1
4
1
4
1
4
✓
2
✓
where (i) uses the calculations on T0 to T2 stated in equation D.45 and D.46. Step (ii) replaces
a = 0 to remove the O(R) term.
D.5 PROOF OF LEMMA 4.3 (CURVATURE AT P = Q)
Lemma D.6 (Smoothness at P = Q, Lemma 4.3 restated). Under the same setup as Lemma 4.1,
the smoothness at P = Q is lower bounded as σmaχ(V2L(Tq)) ≥ R.
Proof. The result follows from direct calculation of the Hessian at P = Q:
V2L(T )=2 /
=8"
p*+q T (X)T (x)>dx = 1 (E*(T (x)T (x)>) + EQ(T (x)T (x)>))
48
x
-1
[x, -1]	+ EQ
x
-1
[x, -1]
E* x2 + EQ x2 0
02
(D.49)
1 R2 + 2 0
8
0	2.
Hence σmaχ(VTL) ≥ e>V2L(τ)eι ≥ R.
□
D.6 Proof of Theorem 4.2 (lower bound for second-order methods)
The proof of Theorem 4.2 is similar to that of Theorem 4.1, where we show that there is a ring of
width Θ(R) in which the amount of progress at each step is exponentially small, hence the number
of steps required to cross this ring is exponential.
34
Published as a conference paper at ICLR 2022
We show that starting from τ0 = τq , the optimization path will necessarily steps into A:
Lemma D.7. Let η := O(先), where λρ := minθ∈θ σmin(V2L(tθ)), Xm :=
maxθ∈θ σmaχ(V2L(τθ)) as defined in Section 4. For any T s.t. ∣∣τ 一 τ*∣∣≥ 0.2R, let T0 denote
the point after one SteP of gradient descentfrom T, then ∣∣τ 0 - τ* ∣2> 0.15R.
Proof. First note that ∀T, the next point after one step of Newton update is:
T = T - η(V2L(τ))TVL(T) = T - ηhD(V2L(τ))TVL(T), J -「* E ∙ J - 北 + Vi
L∖	∣∣t - ‰∣2 / ∣∣t - t*∣2	」
(D.50)
where V ：= (V2L(t))-1VL(t) - h(V2L(T))-1VL(t), fΓ≡⅛i ∙ 1≡⅛ is orthogonal to T - t*.
kτ '*k2	Il τ '*k2
Hence
∣T - T*k-∣∣T0 - T*k= η<(V2L(T))-1 VL(T), k；二心 E - η∣v∣
≤ η	DVL ) T - t* E ≤ ηkVL(T)k2 ≤) 32ηmaχ{R, |b|}
≤σmin(V2L(T)) ∙ ∖	( ), kT-T*∣J ≤ σmin(V2L(T)) ≤ σmin(V2L(T))	(D.51)
(ii)32	λρ	max{R, |b|} V 32max{R, |b|} V 64max{R, |b|}
≤	σmin(V2L(T)) -λM	≤ λM ≤	R2
where step (i) uses Claim D.1, and step (ii) follows from the choice of η.
Suppose kT0 - t*∣2< 0.15R, then
0.05R ≤ kT - T*k-kT0 - T*k≤ 64maχ{R'lbl} ⇒ b = ω(R3).	(D.52)
R2
However, kT0 - T*k2 entails b = Θ(R), which is a contradiction. Hence itmustbe that kT0 - ‰k2>
0.15R.	□
Proof of Theorem 4.2. By Lemma D.7, the optimization path will go to a point T0 ∈ A s.t. kT0 -
t* k 2 > 0.15R. From any such T0, the shortest way to exit the annulus A is to project onto the inner
circle defining A, i.e. the circle centered at t* with radius 0.1 R which is a convex set. Denote
this inner circle as B(T*, 0.1R) whose projection is ΠB(τ* ,0.1R), then the shortest path is the line
segment T0 - ΠB(τ*,0.1R)(T 0). Further, this line segment is of length 0.05R since kT0 - T* k> 0.15R
by Lemma D.7.
However, the decrease of the parameter distance (i.e. kT - T* k) is exponentially small at any point
in A:
kτt-τ*k-kτt+ι-τ*k≤ —(V2L N IDVL(Tt), IlTlT* E
σmin(V2L(Tt)) I	kTt - T*k2
(≤) KVL(Tt), kTt-T*k2〉| (≤ Oreχp( - K(b'8)R2))
_	λM	-	∖	R3	J
(D.53)
where step (i) uses the calculations in equation D.51; step (ii) use the choice of η; and step (iii)
uses Lemma D.1.
Hence the number of steps to exit A is lower bounded by
0.05R
O(R⅛ exp(-R82))
R3 exp
Ω
□
E Additional notes on experiments
E.1 Implementation details
Parameterization: For the 1-dimensional Gaussian, we take P*, Q to have mean μ* = 16, μq = 0,
and unit variance σ*2 = σq2 = 1; see Figure 4a for an illustration of the flat loss landscape. We
35
Published as a conference paper at ICLR 2022
(a)	1d Gaussian mean estimation with σ2 = 1 and
means μq = 0, μ* = 16. The X and y axis cor-
respond to the estimated mean μ and the NCE loss.
The left and right vertical lines show μq and μ*, and
the red and green curves show the pdfs ofQ and P*.
(b)	2d Gaussian mean estimation with σ2 = 1 and
means μq = 0,μ* = 8. The blue surface shows
the NCE loss surface, and the orange and green sur-
faces show the pdfs of Q and P*.
Figure 4: An illustration of the flat landscape caused by the “density chasm" NCE loss quickly
flattens out for 1d and 2d Gaussian mean estimation.
2
use h(x) := exp(-%), T(x) := [x, -1] to be consistent with the notation in Section 4. For the
16-dimensional Gaussian, P*, Q share the same mean μ* = μq = 0 but have different covariance
with Covq = Id and Covp = diag([s1, ..., sd]), where si = Uniform[8 × 0.75, 8 × 1.5]. 8
For MNIST, we adapt the TRE implementation by Rhodes et al. (2020). We model the log density
ratio log(p/q) by a quadratic of the form g(x) := -f(x)>Wf(x) - b>f(x) - c, where f is
ResNet-18, and W , b, c are trainable parameters with W constrained to be positive definite.
Implementation notes: We include some tricks we found useful for implementation:
•	Calculation in log space: instead of dividing two pdfs, we found it more numerically stable to use
subtraction between the log pdfs and then exponentiate.
•	Removing common additive factors: the empirical loss is the average loss over a batch of samples
where overflow can happen. 9 We found it more stable to calculate the mean by first subtract the
largest value of the batch, calculate the mean of the remaining values, then add back the large
value—akin to the usual log-sum-exp trick. For example, mean([a, b]) = max(a, b) + mean([a -
max(a, b), b - max(a, b)]).
•	Per-sample gradient clipping: it is sometimes helpful to limit the amount of gradient contributed
by any data point in a batch. We ensure this by limiting the norm of the gradient, that is, the
gradient from a sample X is now min{1,区3*}V'(x) for some prespecified constant K (Tsai
et al., 2021).
•	Per-sample log ratio clipping: an alternative to per-sample gradient clipping is to upper threshold
the absolute value of the log density ratio on each sample, before passing it to the loss function.
Setting a proper threshold prevents the loss from growing too large, and consequently prevents a
large gradient update.
E.2 Additional results
Results for training with a larger computation budget: We provide additional results on Gaussian
mean estimation and MNIST, both trained with a larger computation budget.
Figure 5 shows results similar to those of Figure 1, except that we now run the optimization process
for 5 times longer than in Figure 1, and additionally show results on eNCE optimized with gradient
descent (GD). The conclusion is the same as that of Figure 1: for both NCE and eNCE , normalized
8Generally, for d-dimensional Gaussian with mean μ and a diagonal covariance matrix
Σ := diag([σ2,…,σ2]), the exponential parametrization is T = [/,…,σ12, μ1,…%, μ>∑~μ +
2 log((2π)d det(Σ)].
9This is because the mean function is internally implemented as the sum of all entries divided by the batch
size, and the sum of a large batch size where each value is also large can lead to overflow.
36
Published as a conference paper at ICLR 2022
Figure 5: Results for estimating 1d (left) and 16d (right) Gaussians, plotting mint∈[T] ∣∣τ* - Tt ∣∣2 (y-
axis) against the number of updates T (x-axis). Normalized gradient descent (NGD) significantly
outperforms vanilla gradient descent (GD) for both NCE and eNCE . In addition, eNCE decays
faster than NCE when optimized with NGD. The results are averaged over 5 runs, with shaded areas
showing the standard deviation.
Figure 6: Results on MNIST, plotting loss value (y-axis, log scale) against the number of update
steps (x-axis). The left plot shows NCE optimized by GD (black) and NGD (yellow), and the right
shows eNCE optimized by GD (black) and NGD (blue). The setup is the same as that for Figure 2
except that we now let training run 4 times longer. NGD outperforms GD in both cases, consistent
with the results in Figure 2.
gradient descent (NGD) significantly outperforms GD. Moreover, eNCE performs competitively
compared to NCE when optimized with NGD.
Similarly, we train with a large computation budget on MNIST, whose results are shown in Figure
6. The results are again consistent with those in Figure 2.
MNIST samples We run annealed importance sampling (AIS) Neal (2001) following Rhodes et al.
(2020) on the models trained on NCE and eNCE , optimized with GD or NGD. Figure 7, 8 show
samples generated with 4k or 10k sampling steps, from different random initialization. We can
see that eNCE gives much sharper results than NCE, and eNCE with NGD results in more diverse
samples. A downside though is that eNCE samples seem to show signs of mode collapse. However,
it is unclear whether this is a problem with the model or due to the sampling procedure.
Results for training with other normalized optimization method: One interesting question to
ask is, whether the results of NGD generalize to other optimizers that perform some form of nor-
malization. One example that is commonly used in practice is the RMSprop, which performs per-
coordinate normalization on the gradient. Specifically, at the tth step with gradient gt , RMSprop
first updates a cumulative term vt := αvt-1 + (1 - α)gt2, where α ∈ [0, 1] is a hyperparameter
QJ目目图国QQ
国BΞBBQ口
国QQQQ目囱
3333333
Ξ目BSBΞQ
3B3B333
国画国
国囱阅
国◎固
囱@ ©
团/图
El @@
国阅团
国国国
□ Q Q D Q El Q
B B H □ H Q □
ŋ Q Q Ξ H □ □
Q Q ŋ □ □ O O
O Q Q Q Q ŋ Q
Q S El Q Q □ O
□ Q H B B B Q
(a) NCE, GD	(b) NCE, NGD	(c) eNCE , GD	(d) eNCE , NGD
Figure 7: MNIST samples from 4000 sampling steps
37
Published as a conference paper at ICLR 2022
ΞHQ□HBB
3333333
HE3Ea目QQH
HH目目目国O
□目HQBE30
Dbbqqsd
回QBQBOEI
aB国B@QQ
QHQ因QΞB
HQD目ŋsŋ
目HBQ目HΞ
□ 国国囱团口画通 Q ŋ Q El B B □
H 国白目四国国图 Q O Q□ŋ ŋ B
Q	阳四冏@@囱血	Q	B	Q	□	Q	B	El
S	Ξ Ξ	Ξ	Ξ Ξ	Ξ	Ξ	ŋ	B	H	Q	ŋ	El	H
B	国圆团圆国囱烟	Q	B	Q	B	El	Q	□
Q	Ξ Ξ	Ξ	Ξ Q	Ξ	Ξ	D	B	□	B	Q	□	B
H 国血图图因圆窗 □ □Q Q□□□
(b)	NCE, NGD	(c) eNCE , GD	(d) eNCE , NGD
(a)	NCE, GD
Figure 8: MNIST samples from 10000 sampling steps
Figure 9: Results for estimating 1d Gaussian with NCE (left) or eNCE (right), using GD (gray),
NGD (yellow for NCE, blue for eNCE ), or RMSprop (green). The effectiveness of RMSprop
seems to depend on the task: RMSprop performs the best for NCE, but falls short than NGD for
eNCE.
controlling how much to “damp" the current gradient, and the square on gt is applied entrywise. It
then normalizes the gradient as gt := gt /vt, with division applied entry-wise.
Figure 9 compares RMSprop with GD or NGD on 1d Gaussian estimation task. The results suggest
that how well RMSprop performs may be task-specific: RMSprop performs the best when optimiz-
ing for NCE, but only slightly better than GD when optimizing for eNCE . Moreover, NCE favors a
higher value of α where the best performance is achieved by α = 0.99, whereas eNCE prefers α to
be small with α = 0.01 performing the best.
It is not yet clear what the theoretical answer should be for normalized methods in general: though
methods like RMSprop perform certain form of normalization (e.g. per-coordinate normalization),
so does Newton’s method, and Theorem 4.2 has shown that it still suffers from an exponentially bad
convergence rate (at least with standard choices of step size). It is unclear what quantity replaces the
condition number of the Hessian for RMSProp, which governs the convergence of NGD. Theoretical
guarantees for these optimization methods is an interesting open question.
38