title,year,conference
 Policy-aware modellearning for policy gradient methods,2020, ArXiv
 Equivalence between wasser-stein and value-aware loss for model-based reinforcement learning,2018, ArXiv
 Model-based reinforce-ment learning with value-targeted regression,2020, In International Conference on Machine Learning
 Openai gym,2016, ArXiv
 Control-aware representations formodel-based reinforcement learning,2021, In International Conference on Learning Representations
 Pilco: A model-based and data-efficient approach to policysearch,2011, In International Conference on Machine Learning
 Iterative value-aware model learning,2018, In Advances in Neural Informa-tion Processing Systems
 Error propagation for approximatepolicy and value iteration,2010, Advances in Neural Information Processing Systems
 Value-Aware Loss Function forModel-based Reinforcement Learning,2017, In International Conference on Artificial Intelligence andStatistics
 Bisimulation metrics for continuous markovdecision processes,2011, SIAM Journal on Computing
 Stable function approximation in dynamic programming,1995, In InternationalConference on Machine Learning
 The value equivalence prin-ciple for model-based reinforcement learning,2020, In Advances in Neural Information ProcessingSystems
 Propervalue equivalence,2021, In Advances in Neural Information Processing Systems
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, In International Confer-ence on Machine Learning
 Dream to control: Learningbehaviors by latent imagination,2020, In International Conference on Learning Representations
 When to trust your model: Model-based policy optimization,2019, In Advances in Neural Information Processing Systems
 Reinforce-ment learning with misspecified model classes,2013, In IEEE International Conference on Roboticsand Automation
 Near-optimal reinforcement learning in polynomial time,2002, Ma-chine learning
 Objective mismatch inmodel-based reinforcement learning,2020, In Conference on Learning for Dynamics and Control
 Guided policy search,2013, In International Conference on MachineLearning
 Decision-awaremodel learning for actor-critic methods: When theory does not meet practice,2020, In ¡±I Can¡¯t BelieveIt¡¯s Not Better!¡± at NeurIPS Workshops
 Algorithmicframework for model-based deep reinforcement learning with theoretical guarantees,2019, In Interna-tional Conference on Learning Representations
 Learning dynamics models for model predictiveagents,2021, ArXiv
 Playing atari with deep reinforcement learning,2013, In NeurIPS DeepLearning Workshop
 Model-based reinforcement learn-ing: A survey,2020, ArXiv
 Goal-aware prediction: Learning to model whatmatters,2020, In International Conference on Machine Learning
 Control-orientedmodel-based reinforcement learning with implicit differentiation,2022, In AAAI Conference on Ar-tificial Intelligence
 Value prediction network,2017, In Advances in NeuralInformation Processing Systems
 Natural actor-critic,2008, Neurocomputing
 Mbrl-lib: Amodular library for model-based reinforcement learning,2021, ArXiv
 Markov decision processes: Discrete stochastic dynamic programming,1994, InWiley Series in Probability and Statistics
 Agnostic system identification for model-based reinforcementlearning,2012, In International Conference on Machine Learning
 Exploiting model uncertainty estimates for safe dynamic control learning,1997, InAdvances in Neural Information Processing Systems
 The distracting control suite- a challenging benchmark for reinforcement learning from pixels,2021, ArXiv
 Self-correcting models for model-based reinforcement learning,2017, In AAAI Conferenceon Artificial Intelligence
 Duelingnetwork architectures for deep reinforcement learning,2016, In International Conference on MachineLearning
 Embed tocontrol: A locally linear latent dynamics model for control from raw images,2015, In Advances inNeural Information Processing Systems
 Learn-ing invariant representations for reinforcement learning without reconstruction,2021, In InternationalConference on Learning Representations
