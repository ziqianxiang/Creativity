title,year,conference
 Thefifth PASCAL recognizing textual entailment challenge,2009, In TAC
 An empirical investigation of statisticalsignificance in nlp,2012, In Proceedings of the 2012 Joint Conference on Empirical Methods in NaturalLanguage Processing and Computational Natural Language Learning
 Sulla probabilita` come limite della frequenza,1917, Rendiconti della Reale Accademiadei Lincei
 Quora question pairs,2018, University ofWaterloo
 Pretrained language model embryol-ogy: The birth of ALBERT,2020, In Proceedings of the 2020 Conference on Empirical Methodsin Natural Language Processing (EMNLP)
 Sampling techniques,2007, John Wiley & Sons
 Under-specification presents challenges for credibility in modern machine learning,2020, arXiv preprintarXiv:2011
 A statistical analysis of summarization evaluation met-rics using resampling methods,2021, Transactions of the Association for Computational Linguistics
 BERT: Pre-training of deepbidirectional transformers for language understanding,4171, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 The hitchhikerâ€™s guide to testingstatistical significance in natural language processing,2018, In Proceedings of the 56th Annual Meetingof the Association for Computational Linguistics (Volume 1: Long Papers)
 Deep dominance - how to properly compare deepneural models,2019, In Proceedings of the 57th Annual Meeting of the Association for Computa-tional Linguistics
 An introduction to the bootstrap,1994, CRC Press
 Les Probabilites denombrables et leurs applications arithmetiques,1909, Rendiconti delCircolo Matematico di Palermo (1884-1940)
 An elementary proof of the strong law of large numbers,1981, Zeitschrift furWahrscheinlichkeitstheorie und verwandte Gebiete
 Bootstrapping clustered data,2007, Journal of the Royal StatisticalSociety: Series B (Statistical Methodology)
 A structural probe for finding syntax in word representa-tions,2019, In Proceedings of the 2019 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies
 Ontonotes:The 90% solution,2006, In Proceedings of the Human Language Technology Conference of the NAACL
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Statistical significance tests for machine translation evaluation,2004, In Proceedings ofthe 2004 conference on empirical methods in natural language processing
 Mixout: Effective regularization to finetunelarge-scale pretrained language models,2020, In International Conference on Learning Representa-tions
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Quantifying the car-bon emissions of machine learning,2019, In NeurIPS 2019 Workshop on Tackling Climate Changewith Machine Learning
 A simple proof of the strong law of large numbers with rates,2018, Bulletin of the AustralianMathematical Society
 BERTs of a feather do not generalize to-gether: Large variability in generalization across models with similar test set performance,2020, InProceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Net-works for NLP
 Right for the wrong reasons: Diagnosing syntacticheuristics in natural language inference,2019, In Proceedings of the 57th Annual Meeting of the As-sociation for Computational Linguistics
 StereoSet: Measuring stereotypical bias in pretrainedlanguage models,2021, In Proceedings of the 59th Annual Meeting of the Association for Computa-tional Linguistics and the 11th International Joint Conference on Natural Language Processing(Volume 1: Long Papers)
 Bleu: a method for automaticevaluation of machine translation,2002, In Proceedings of the 40th Annual Meeting of the Associa-tion for Computational Linguistics
 Carbon emissions and large neural network training,2021, arXivpreprint arXiv:2104
 Better than average: Paired evaluationof NLP systems,2021, In Proceedings of the 59th Annual Meeting of the Association for Computa-tional Linguistics and the 11th International Joint Conference on Natural Language Processing(Volume 1: Long Papers)
 Sentence encoders on stilts: Supplementarytraining on intermediate labeled-data tasks,2018, arXiv preprint arXiv:1811
 Marcinkiewicz-type strong laws for partially exchangeable arrays,1991, Journal of Multi-variate Analysis
 A primer in BERTology: What we know abouthow BERT works,2020, Transactions of the Association for Computational Linguistics
 Gender bias incoreference resolution,2018, In Proceedings of the 2018 Conference of the North American Chapterof the Association for Computational Linguistics: Human Language Technologies
 Understanding learning dynamics of language models withSVCCA,2019, In Proceedings of the 2019 Conference of the North American Chapter of the Associa-tion for Computational Linguistics: Human Language Technologies
 Recursive deep models for semantic compositionality over a sentimenttreebank,2013, In Proceedings of the 2013 Conference on Empirical Methods in Natural LanguageProcessing
 Energy and policy considerations fordeep learning in NLP,2019, In Proceedings of the 57th Annual Meeting of the Association for Com-putational Linguistics
 Well-read students learn better:On the importance of pre-training compact models,2019, arXiv preprint arXiv:1908
 Weakconvergence and empirical processes: with applications to statistics,1996, Springer Science & Busi-ness Media
 A broad-coverage challenge corpus for sen-tence understanding through inference,2018, In Proceedings of the 2018 Conference of the NorthAmerican Chapter of the Association for Computational Linguistics: Human Language Technolo-gies
 Transformers: State-of-the-artnatural language processing,2020, In Proceedings of the 2020 Conference on Empirical Methods inNatural Language Processing: System Demonstrations
 Revisiting few-sample BERT fine-tuning,2021, In International Conference on Learning Representations
 Are larger pretrained languagemodels uniformly better? comparing performance at the instance level,3813, In Findings of the As-sociation for Computational Linguistics: ACL-IJCNLP 2021
 Aligning booksand movies: Towards story-like visual explanations by watching movies and reading books,2015, In2015 IEEE International Conference on Computer Vision (ICCV)
