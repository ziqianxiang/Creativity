title,year,conference
 Maximum a Posteriori Policy Optimisation,2018, In International Conference on Learn-ing Representations
 Best arm identification in multi-armedbandits,2010, In COLT
 Pachi: State of the art open source Go program,2011, In Advances incomputer games
 The Arcade Learning Envi-ronment: An evaluation platform for general agents,2013, JAIR
 Reinforcement and Optimal Control,2019, Athena Scientific
 Pure exploration in finitely-armed andcontinuous-armed bandits,2011, Theoretical Computer Science
 Sequential halving applied to trees,2014, IEEE Transactions on Computational Intel-ligence and AI in Games
 Convex regularization in Monte-Carlotree search,2021, In International Conference on Machine Learning
 Sequential halving using scores,2021, In Reinforcement Learningin Games at AAAI
 TreeQN and ATreeC: Differentiable tree-structured models for deep reinforcement learning,2018, In International Conference on LearningRepresentations
 Monte-Carlo tree search and rapid action value estimation in com-puter Go,2011, Artificial Intelligence
 Monte-Carlo tree search as regularized policy optimization,2020, InInternational Conference on Machine Learning
 Combining q-learning and search with amortized value esti-mates,2020, In International Conference on Learning Representations
 Metareasoning for Monte Carlo tree search,2011, Technical report
 Identity mappings in deep residualnetworks,2016, In Computer Vision - eCcV2016
 Squeeze-and-excitation networks,2018, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Learning and planning in complex action spaces,2021, In InternationalConference on Machine Learning
 Categorical reparameterization with Gumbel-Softmax,2017, InInternational Conference on Learning Representations
 Approximately optimal approximate reinforcement learning,2002, InInternational Conference on Machine Learning
 Almost optimal exploration in multi-armed ban-dits,2013, In International Conference on Machine Learning
 Adam: A Method for Stochastic Optimization,2014, arXiv e-prints
 Bandit based Monte-Carlo planning,2006, In Machine Learning:ECML 2006
 Stochastic beams and where to find them: TheGumbel-top-k trick for sampling sequences without replacement,2019, In International Conference onMachine Learning
 Estimating gradients for discrete random variablesby sampling without replacement,2020, In International Conference on Learning Representations
 Revisiting the arcade learning environment: Evaluation protocols and openproblems for general agents,2018, Journal of Artificial Intelligence Research
 The concrete distribution: A continuous relaxation of discreterandom variables,2017, In International Conference on Learning Representations
 Low-Variance Policy Gradient Estimation with WorldModels,2020, arXiv e-prints
 Minimizing simple and cu-mulative regret in Monte-Carlo tree search,2014, In Workshop on Computer Games
 Multi-armed bandits with episode context,2011, Annals of Mathematics and Artifi-CialIntelligence
 Online and Offline Reinforcement Learning by Planning witha Learned Model,2021, arXiv e-prints
 Trust RegionPolicy Optimization,2015, In International Conference on Machine Learning
 Mastering the game ofGo withdeep neural networks and tree search,2016, Nature
 Mastering the game of Gowithout human knowledge,2017, Nature
 MCTS based on simple regret,2012, In AAAI Conference on Artifi-cial Intelligence
 Mirror Descent PolicyOptimization,2020, arXiv e-prints
 Critic regularizedregression,2020, Advances in Neural Information Processing Systems
 Accelerating Self-Play Learning in Go,2019, arXiv e-prints
