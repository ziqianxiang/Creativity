title,year,conference
 Optimization Algorithms onMatrix Manifolds,2008, Princeton University Press
 Segnet: A deep convolutional encoder-decoder architecture for image segmentation,2017, IEEE Trans
 Cheap orthogonal constraints in neural networks:A simple parametrization of the orthogonal and unitary group,2019, 97:3794-3803
 Gradnorm: Gradientnormalization for adaptive loss balancing in deep multitask networks,2018, In Jennifer G
 Just pick a sign: Optimizing deep multitask models with gradientsign dropout,2020, In Hugo Larochelle
 Finite-time convergent gradient flows with applications to network consensus,2006, Autom
 Indoor semantic segmentationusing depth information,2013, In Yoshua Bengio and Yann LeCun (eds
 Efficiently iden-tifying task groupings for multi-task learning,2021, In Thirty-Fifth Conference on Neural InformationProcessing Systems
 Meta-learning with warped gradient descent,2019, arXiv preprint arXiv:1909
 Dynamic task pri-oritization for multitask learning,2018, In Vittorio Ferrari
 Learning to branch for multi-task learning,3854, InProceedings of the 37th International Conference on Machine Learning
 DeeP residual learning for imagerecognition,2016, In 2016 IEEE Conference on Computer Vision and Pattern Recognition
 MUlti-task learning Using Uncertainty to weigh lossesfor scene geometry and semantics,2018, In Proceedings of the IEEE conference on computer vision andpattern recognition
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Learning mUltiple layers of featUres from tiny images,2009,2009
 Gradient-based learning applied todocUment recognition,1998, Proceedings of the IEEE
 Mnist handwritten digit database,2010, ATT Labs [Online]
 Towards impartial mUlti-task learning,2021, In International Conference on LearningRepresentations
 On the variance of the adaptive learning rate and beyond,2019, arXiv preprint arXiv:1908
 End-to-end mUlti-task learningwith attention,2019, In IEEE Conference on Computer Vision and Pattern Recognition
 Deep learning face attributes in the wild,2015, In2015 IEEE International Conference on Computer Vision
 Attentive single-tasking of multiple tasks,2019, In IEEE Conference on Computer Vision and PatternRecognition
 Cross-stitch networks formulti-task learning,2016, In 2016 IEEE Conference on Computer Vision and Pattern Recognition
 Revisiting normalized gradient descent:Fast evasion of saddle points,2019, IEEE Trans
 Readingdigits in natural images with unsupervised feature learning,2011, NeurIPS Workshop on Deep Learningand Unsupervised Feature Learning
 An overview of multi-task learning in deep neural networks,2017, CoRR
 Multi-task learning as multi-objective optimization,2018, In Samy Bengio
 Variational multi-task learning withgumbel-softmax priors,2021, In Thirty-Fifth Conference on Neural Information Processing Systems
 Gradient adversarialtraining of neural networks,2018, arXiv preprint arXiv:1806
 Adashare: Learning what to sharefor efficient deep multi-task learning,2020, In Hugo Larochelle
 Discovering structure in multiple learning tasks: The TCalgorithm,1996, In Lorenza Saitta (ed
 BranchedmUlti-task networks: Deciding what layers to share,2020, In 31st British Machine Vision Conference2020
 Gradient vaccine: Investigating andimproving mUlti-task optimization in massively mUltilingUal models,2021, In International Confer-ence on Learning Representations
 In H,2020, Larochelle
 Taskonomy: Disentangling task transfer learning,2018, In 2018 IEEE Confer-ence on Computer Vision and Pattern Recognition
