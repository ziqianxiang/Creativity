title,year,conference
 Policy-gradients for psrs and pomdps,2007, InArtificial Intelligence and Statistics
 Emergent tool use from multi-agent autocurricula,2019, arXiv preprint arXiv:1909
 Predictive state temporal difference learning,2010, arXiv preprintarXiv:1011
 Closing the learning-planning loop withpredictive state representations,2011, The International Journal of Robotics Research
 Hilbert space embeddings of predictive staterepresentations,2013, arXiv preprint arXiv:1309
 Exact and approximate algorithms for partially observable Markovdecision processes,1998, Brown University
 Tensor Decomposition forMulti-agent Predictive State Representation,2020, arXiv:2005
 Bayesian Inference andLearning in Gaussian Process State-Space Models with Particle MCMC,2013, arXiv:1306
 Maximum statistics of n random variables distributed by thenegative binomial distribution,1997, Combinatorics
 Multi-agent deep reinforcement learning: a survey,2022, ArtificialIntelligence Review
 Efficient learning and planning withcompressed predictive states,2014, The Journal of Machine Learning Research
 Supervised learning for dynamical systemlearning,2015, Advances in neural information processing systems
 Recurrentpredictive state policy networks,2018, In International Conference on Machine Learning
 A spectral algorithm for learning hidden markovmodels,2012, Journal of Computer and System Sciences
 Learning and discovery of predictive state representationsin dynamical systems with reset,2004, In Proceedings of the twenty-first international conference onMachine learning
 Completing state representations using spectrallearning,2018, In NeurIPS
 Planning and acting in partiallyobservable stochastic domains,1998, Artificial intelligence
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Predictive representations of state,2001, InNIPS
 Pic: permutation invariant critic formulti-agent deep reinforcement learning,2020, In Conference on Robot Learning
 Multi-agent gameabstraction via graph attention neural network,2020, In Proceedings of the AAAI Conference on ArtificialIntelligence
 Likelihood Quantile Networks for Coordinating Multi-AgentReinforcement Learning,2020, arXiv:1812
 Fast computation of densetemporal subgraphs,2017, In 2017 IEEE 33rd International Conference on Data Engineering (ICDE)
 A concise introduction to decentralized POMDPs,2016, Springer
 Point-based value iteration: An anytimealgorithm for pomdps,2003, In IJCAI
 Belief space planningassuming maximum likelihood observations,2010, 2010
 Model-based bayesian reinforcement learning in partially observ-able domains,2008, In Proc Int
 Qmix: Monotonic value function factorisation for deep multi-agent reinforcementlearning,2018, In International Conference on Machine Learning
 Multi-agent actor-critic with hierarchical graphattention network,2020, In Proceedings of the AAAI Conference on Artificial Intelligence
 Predictive state representations: A new theoryfor modeling dynamical systems,2012, arXiv preprint arXiv:1207
 Qtran: Learning tofactorize with transformation for cooperative multi-agent reinforcement learning,2019, In InternationalConference on Machine Learning
 Learning to filter with predictivestate inference machines,2016, In International conference on machine learning
 Multi-agent reinforcement learning: Independent vs,1993, cooperative agents
 Monte carlo pomdps,1999, In NIPS
 An Introduction to Matrix Concentration Inequalities,2015, arXiv:1501
 Predictive-state decoders: Encoding the future into recurrentnetworks,2017, arXiv preprint arXiv:1709
 Deep Multi-Agent Reinforcement Learning for Decentralized ContinuousCooperative Control,2020, arXiv:2003
 Integrating independent and centralized multi-agentreinforcement learning for traffic signal network optimization,2019, arXiv:1909
 Communicationmotifs: a tool to characterize social communications,2010, In Proceedings of the 19th ACM internationalconference on Information and knowledge management
 Learning Implicit CreditAssignment for Cooperative Multi-Agent Reinforcement Learning,2020, arXiv:2007
