Figure 1: In the relational multi-task setting, the model learns to incorporate auxiliary knowledge inmaking predictions to achieve data efficiency. Concretely, given observations x(i) and their labels{yj(i) } (0/1 in this example) on subsets of tasks {tj }, the goal is to build a model that can harnessthe auxiliary task labels {yj(i)} and make predictions on a new task tn. A standard approach is tobuild a multi-head deep neural network, with a prediction head for each individual task tj . However,such approach cannot utilize auxiliary labels. In contrast, our proposed MetaLink reinterprets the lastlayer’s weights of each task as task nodes and creates a knowledge graph where data points and tasksare nodes and labeled edges provide information about labels of data points on tasks. Then, whenpredicting data point’s label for a given task tj , MetaLink uses labels from other tasks to improvepredictive performance.
Figure 2: Our MetaLink framework allows for modeling four different multi-task learning settings:O represent data nodes and □ represent task nodes. Blue represents the data/tasks seen in the trainingstage and white denotes the data/tasks seen only in the test stage. During model inference (for boththe training and the test stage), the label of a data-task pair with solid line is known, while we want topredict labels of the data-task pairs with dotted lines.
Figure 3: Pearson correlation heat map on 27tasks of Sider dataset.
Figure 4: We vary the ratio of auxiliary labels per test point and plot the ROC AUC with the error bar.
