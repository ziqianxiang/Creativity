Figure 1: An overview of the workflow used to evaluate graph generative models, as is used, e.g.,in Liao et al. (2019); Niu et al. (2020); You et al. (2018): given a distribution of graphs, a set ofdescriptor functions is employed to map each graph to a high-dimensional representation in Rd .
Figure 2: Figure 2a shows the ideal behaviour of a graph generative model evaluator: as twodistributions of graphs become increasingly dissimilar, e.g. via perturbations, the metric should growproportionally. Figure 2b shows the behaviour of the current choices in reality; each line representsthe normalized MMD for a given kernel and parameter combination. A cautious choice of kernel andparameters is needed in order to obtain a metric with behaviour similar to Figure 2a. Each squarein Figure 2c shows which model performs best (out of A, B, and C) over a grid of hyperparametercombinations of σ and number of bins in the histogram. Any model can rank first with an appropriatehyperparameter selection, showcasing the sensitivity of MMD to the hyperparameter choice.
Figure 3: This shows the MMD distance to the test set of graphs for three recent graph generativemodels (whose names we intentionally omitted) on the Community Graphs dataset for differentdescriptor functions and kernels. MMD requires the choice of a kernel and kernel parameters. Eachsubfigure shows MMD (lower is better) along a range of values of σ (reported on a log scale), withthe bar underneath indicating which model ranks first for the given value of σ. The grey line indicatesthe σ chosen by the authors. Subfigures 3a and 3b show how simply switching from the EMD to theRBF kernel (holding σ constant) can change which model performs best; Subfigures 3c and 3d showhow the choice of σ by the authors misses the area of maximum discrimination of MMD.
Figure 4: The correlation of MMD with the degree of perturbation in the graph, assessed for differentdescriptor functions and datasets (BA: Barabdsi-Albert, ER: ErdUs-RCnyi, WS: Watts-Strogatz). Foran ideal metric, the distance would increase with the degree of perturbation, resulting in values ≈ 1.
Figure 5:	A heatmap of which model (from A, B, and C) ranks first in terms of MMD acrossdifferent hyperparameter combinations. This uses the clustering coefficient descriptor function andthe RBF kernel, where the number of bins is a hyperparameter of the descriptor function, and σ is thehyperparameter in the kernel.
Figure 6:	Barabasi-Albert Graphs. MMD calculated between the test graphs and predictions fromthree recent graph generative models (A, B, C) over a range of values of σ on the Barabgsi-AlbertGraphs dataset. Additionally, the MMD distance between the test graphs and training graphs isprovided to give a meaningful sense of scale to the metric. It provides an idea of what value of MMDsignifies an indistinguishable difference between the two distributions.
Figure 7:	Community Graphs. MMD calculated between the test graphs and predictions from threerecent graph generative models (A, B, C) over a range of values of σ on the Community Graphsdataset. Additionally, the MMD distance between the test graphs and training graphs is provided togive a meaningful sense of scale to the metric. It provides an idea of what value of MMD signifies anindistinguishable difference between the two distributions.
Figure 8:	Erdos-Renyi Graphs. MMD calculated between the test graphs and predictions from threerecent graph generative models (A, B, C) over a range of values of σ on the ErdOS-Renyi Graphsdataset. Additionally, the MMD distance between the test graphs and training graphs is provided togive a meaningful sense of scale to the metric. It provides an idea of what value of MMD signifies anindistinguishable difference between the two distributions.
Figure 9: Watts-Strogatz Graphs. MMD calculated between the test graphs and predictions fromthree recent graph generative models (A, B, C) over a range of values of σ on the Watts-StrogatzGraphs dataset. Additionally, the MMD distance between the test graphs and training graphs isprovided to give a meaningful sense of scale to the metric. It provides an idea of what value of MMDsignifies an indistinguishable difference between the two distributions.
Figure 10: Perturbation: adding edges. This figure shows the full results across datasets, descriptorfunctions and parameters when the perturbation is adding edges to the graphs. At each level ofperturbation, the distance of the perturbed graphs is calculated to the original graph distribution usingthe specified evaluator function. Each line represents a different parameter combination. An idealevaluator function would monotonically increase as the degree of perturbation increases.
Figure 11: Perturbation: removing edges. This figure shows the full results across datasets,descriptor functions and parameters when the perturbation is removing edges from the graphs.
Figure 12:	Perturbation: rewiring edges. This figure shows the full results across datasets, descrip-tor functions and parameters when the perturbation is rewiring edges in the graphs. At each level ofperturbation, the distance of the perturbed graphs is calculated to the original graph distribution usingthe specified evaluator function. Each line represents a different parameter combination. An idealevaluator function would monotonically increase as the degree of perturbation increases.
Figure 13:	Perturbation: adding connected nodes. This figure shows the full results across datasets,descriptor functions and parameters when the perturbation is adding connected nodes to the graphs(for each node that is added, there is a 15% chance the node will be connected to any other node inthe graph). At each level of perturbation, the distance of the perturbed graphs is calculated to theoriginal graph distribution using the specified evaluator function. Each line represents a differentparameter combination. An ideal evaluator function would monotonically increase as the degree ofperturbation increases.
Figure 14: The Spearman rank correlation of MMD with the degree of perturbation in the graph,assessed for different descriptor functions and datasets (BA: Barabgsi-Albert Graphs, ER: Erdos-Renyi Graphs, WS: Watts-Strogatz Graphs). For an ideal metric, the distance would increase as thedegree of perturbation increases; resulting in a correlation close to 1. The upper row shows the bestkernel-parameter combination in terms of the correlation; the bottom row shows the worst. As wecan see, a proper kernel and parameter selection leads to strong correlation to the perturbation, but abad choice can lead to inverse correlation, highlighting the importance of a good kernel/parametercombination.
Figure 15: The mutual information of MMD with the degree of perturbation in the graph, assessed fordifferent descriptor functions and datasets (BA: Barabgsi-Albert Graphs, ER: Erdos-Renyi Graphs,WS: Watts-Strogatz Graphs). For an ideal metric, the distance would increase as the degree ofperturbation increases; resulting in a high mutual information coefficient. The upper row shows thebest kernel-parameter combination in terms of the mutual information; the bottom row shows theworst. As we can see, a proper kernel and parameter selection leads to strong dependence on theperturbation, but a bad choice can lead to no mutual information, highlighting the importance of agood kernel/parameter combination.
Figure 16: CPU runtime comparison (lower is better) of the linear, RBF, and EMD-based kernelswhen evaluated on ER graphs and varying the number of graphs (the dataset size), the number ofnodes (the size of each graph), and histogram bin size. Each plot varies a single parameter (on thex-axis), while keeping the other two fixed with values of 100. Runtimes are reported on a logarithmicscale.
