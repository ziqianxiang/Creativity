Figure 1: Training error for Mixup and regular training on X32 . Each curve corresponds to the meanof 10 training runs, and the area around each curve represents a region of one standard deviation.
Figure 2: Mean and single standard deviation of 5 training runs for Mixup (α = 1024) and ERM onthe original training data. Mixup achieves near-identical (within 1%) training accuracy to ERM.
Figure 3: Decision boundary plots for standard and Mixup training on the two moons dataset ofPezeshki et al. (2020) with a class separation of 0.5. Each boundary represents the average of 10training runs of 1500 epochs.
Figure 4: A visualization of Xmix and Aix,,j .
Figure 5: A visualization of the X32 dataset and how the Mixup sandwiching works.
Figure 6: A visualization of Assumption 2.9, i.e. the “no collinearity” assumption.
Figure 7: A visualization of Assumption 3.1. Once again, the key idea is that x falls at most δ awayfrom Xi on every line between Xi and Xj that intersects it.
Figure 8: Training error plots for Mixup and regular training on X120 and X1100. Each curve correspondsto the mean of 10 training runs, and the area around each curve represents a region of one standarddeviation. Note that the ERM curves appear slightly different across α values due to changes iny-axis scale.
Figure 9: Mean and single standard deviation of 5 training runs for Mixup (α = 1, 32, 128) and ERMon the original training data.
Figure 10: Decision boundary plots for α = 32, 64 and a class separation of 0.5.
Figure 14: Decision boundary plots for α = 128, 512 and a class separation of 0.1.
