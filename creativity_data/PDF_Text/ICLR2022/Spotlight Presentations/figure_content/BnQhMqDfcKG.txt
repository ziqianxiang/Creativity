Figure 1: Three examples of complete shapes using cGCA given noisy partial input observation.
Figure 2: Overview of our method. The implicit function of continuous shape can be encodedas sparse voxel embedding s and decoded back (left). The colors in the sparse voxel embeddingrepresent the clustered labels of latent code zc for each cell c. The sampling procedure of cGCA(right) involves T steps of sampling the stochastic transition kernel pθ, followed by T0 mode seekingsteps which remove cells with low probability. From the final sparse voxel embedding sT+T0 , thedecoder can recover the implicit representation for the complete continuous shape.
Figure 3: Qualitative comparison on ShapeNet scene dataset. Best viewed on screen. Minimumrate indicates the guaranteed rate of surface points for each object in the scene. While deterministicmethods (ConvOcc, IFNet) produce blurry surfaces since they cannot model multi-modal distribution,probabilistic methods (GCA, cGCA) generate multiple plausible scenes. cGCA is the only methodthat can generate multiple plausible scenes without losing the details for each object.
Figure 4: Qualitative comparison on 3DFront dataset with 0.5 object minimum rate. Best viewedon screen. Since the raw inputs of furniture are highly incomplete, there exist multiple plausiblereconstructions. Probabilistic approaches produce diverse yet detailed scene geometry. GCA suffersfrom artifacts due to the discrete voxel resolution.
Figure 5: Qualitative comparison on probabilistic shape completion of a single object. CGCA is theonly method that can produce a continuous surface.
Figure 6: Neural network architecture for the decoder fω . The left side shows the overall architecturefor the decoder fω and the right side shows the architecture for sparse convolution layers fω1 . Theparenthesis denotes the stride of the sparse convolution and every convolution except the featureextracting layer is followed by batch normalization and ReLU activation.
Figure 7: Visualizations of reconstructions by autoencoder. We visualize a reconstruction of a chairusing signed distance fields (left) and a scene in 3DFront using unsigned distance fields (right). Bothreconstructions show that sparse voxel embedding is able to reconstruct a continuous surface.
Figure 8: Neural network architecture for the transition model pθ . We employ the architecture ofU-Net. The paranthesis indicates the stride of convolutions and each convolution is followed by batchnormalization.
Figure 9: Ablation study on the effects of mode seeking step T0. The left shows an example ofchair generation, where the bottom row are sparse voxel embeddings and the top row is the meshreconstruction of each state. The right is the result on the effects of mode seeking step T0 tested withprobabilistic shape completion on sofa dataset.
Figure 10: Qualitative results on ShapeNet scenes with varying level of density. Note that all themodels are trained on dataset containing 10,000 points (rightmost column), but only tested withdifferent density. While the probabilistic methods (GCA, cGCA) tries to generate the learned shapes(e.g. shades of lamp) with only 500 points, deterministic methods (ConvOcc, IFNet) tend to fill thegaps between the points of the partial observation.
Figure 11: Qualitative results of cGCA tested on ShapeNet scenes where the input is non-ambiguous.
Figure 12: Qualitative results on ScanNet dataset with models trained on 3DFront dataset. Bestviewed on screen. Multiple plausible reconstructions are shown (pink and blue box). cGCA (w/cond.) shows better results for reconstructing a tree (green box) compared to that of vanilla cGCA,where a tree is never found in the training dataset. This allows us to infer that the conditioned varianttends to help generalize to unseen data better compared to the vanilla cGCA.
Figure 13: Additional qualitative results on ShapeNet scene, with varying level of completeness.
Figure 14: Additional qualitative results on ShapeNet scene, with varying level of completeness.
Figure 15: Additional qualitative results on 3DFront, with varying level of completeness. Bestviewed on screen.
Figure 16: Additional qualitative results on 3DFront, with varying level of completeness. Bestviewed on screen.
Figure 17: Additional qualitative results on ShapeNet sofa.
Figure 18: Additional qualitative results on ShapeNet chair.
Figure 19: Additional qualitative resultson ShapeNet table.
