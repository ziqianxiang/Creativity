Figure 1: The training (top) and inference (bottom) flow of binary-encoded labels (BEL) for regression networks.
Figure 2: Examples of BEL codes. Part (a) represents the quantized values of the labels for Unary and Johnsoncodes shown in Parts (b) and (c). Part (d) shows a B1JDJ code without reflected binary; Parts (e) and (f) showB1JDJ and B2JDJ codes for targets in the range 1 to 16. Part (g) shows quantized and encoded values for aHEXJ code (space added to differentiate between base and displacement, or digits). Red lines represent bittransitions. These BEL codes described in Section 3.2.
Figure 3: Part (a) and (b): classification error probability vs. target output for two classifiers. Target output 1where blue and 0 elsewhere. Part (c): expected error increase of BEL-U versus BEL-J based on Equation 2 toEquation 4 (blank means that combination of r and σ results in an error probability greater than one).
Figure 4: Network architecture for direct and BEL regression; only the regressor architecture is modified, but theentire network is trained end to end. P is the number of dimensions of the regression network output.
Figure 5: Error (MAE or NME) for different encoding, decoding, and loss functions for BEL. D1-D5 representsdifferent combinations of decoding and loss functions: D1 (BCE loss with BEL-U/BEL-J/GEN decoding forU/J/others), D2 (CE/GEN-EX), D3 (CE/GEN), D4 (L1 or L2/GEN-EX), and D5 (BCE/GEN-EX).
Figure 6: Effect of θ on error for different encodings on FLD1.
Figure 7: Encoding and Decoding functions’ output for BEL-J approach and label y ∈ [1, N - 1], where N = 8.
Figure 8: Effect of classifier error on Tf, — Tfi for label Qi = n. Case 1 and case 2 represent erroneousoutputs. 0/1 highlighted in red color represents an error in the classifier’s output. “-” represents error/no error inboth cases.
Figure 9: Effect of classifier error on Tli — Tli for label Qi = n. CaSe 1 and CaSe 2 represent erroneous outputs.
Figure 10: Comparison of expected value of error from Equation 26 and random samples for given errorprobabilities of the classifiers.
Figure 11: Classification error probability versus target label y for different classifiers. The top horizontal barrepresent target output of the classifier. Blue color represents output 1.
Figure 12: HRNetV2-W18 feature extractor combined with BEL regressor for (x,y) coordinatesUpsample - 1x11024BELWe use two runs with different random seeds to decide the learning rate. We consider learning rates{0.0003, 0.0005, 0.0007} andθ ∈ {10, 30}.
