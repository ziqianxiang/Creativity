Figure 1: DeiT-S (Touvron et al., 2021a) predictions with incomplete input image tokens. In (a),removing image tokens unrelated to the visual content of the corresponding category does not dete-riorate ViT predictions. In (b), removing related image tokens makes ViT predict incorrectly.
Figure 2: Token reorganization within a single Transformer encoder. Based on ViT (Dosovitskiyet al., 2021), we reorganize tokens in the original Transformer encoder. Specifically, we calculatethe attentiveness of the class token with respect to each image token. Then, we use the attentivenessvalue as a criterion to identify the top-k attentive tokens and fuse the inattentive tokens.
Figure 3: Visualization of inattentive tokens on EViT-DeiT-S with 12 layers. The masked regionsrepresent the inattentive tokens that are fused into a new token. Our method can effectively identifyinattentive tokens in images with either simple inattentive tokens (in the first two rows) or complexinattentive tokens (in the last two rows).
Figure 4: Comparison of different models with various accuracy-throughput trade-off. The proposedmethod EViT achieves better trade-off than the other methods (marked with circles). The throughputis measured on an NVIDIA A100 GPU using the largest possible batch size for each model. Theinput image size is 2242 unless specified after the @.
Figure 5: Extended visualization results of inattentive tokens on EViT-DeiT-S with 12 layers.. Theregions without masks represent the attentive tokens. The masked regions denote the inattentivetokens that are fused into a new token. Our EViT is effective in dealing with images from differentcategories.
Figure 6: The box plot of the evolution of the attention scores of the inattentive tokens with thelayer depth. The orange line in the box plot indicates the averaged attention scores of the inattentivetokens at a certain layer.
Figure 7: Visualization results of the evolution of the removed tokens during the EViT trainingprocess at different layers. The regions without masks represent the attentive tokens. The maskedregions denote the inattentive tokens that are fused into a new token. At the initial training stage(e.g., the first epoch), the model is not stable in identifying the attentive tokens. As the trainingproceeds, EViT gradually converges, producing meaningful masks.
