Figure 1: Under the federated setting, multiple clients communicate non-sensitive model parameters φc (ex-cluding the last fully connected layer Wc which are greatly tied to privacy) under the orchestration by a centralserver. (a) Since Wc's are kept locally in conventional FL updating, the embedding space could overlap fordifferent classes during training. (b) In contrast, the proposed PrivacyFace framework learns an improved faceembedding by aggregating discriminative embedding clusters that are proved to achieve differential privacy.
Figure 2: Compared to conventional federated learning methods, PrivacyFace learns more discriminative fea-tures by three additional steps in each client: (a) Find a cluster with margin P and calculate the average Pof class centers covered in the cluster; (b) Perturb P with Gaussian noise v, which makes outputted P to bedifferentially private. (c) After the server gathering and distributing p, a consensus-aware face recognition lossenables each class to be separable with local negative classes as well as class clusters from other clients.
Figure 3: Visualization of the occupancy ratio curves.
Figure 4: Distributions of cosine similarities of p and P under different parameters With 1000 runs.
Figure 5: Effects of hyper-parameters on PrivacyFace performances.
Figure 6: Real mean faces and the top-3 nearest faces of the corresponding mean class centers.
Figure 7: Real mean faces (first image in each pair) and faces reconstructed from class centers W (second imagein each pair).
Figure 8: Reconstructed faces from cluster centers P and the differentially private ones P under differentprivacycost €.
Figure 9: Effects of client disconnections during training.
