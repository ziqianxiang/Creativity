Figure 1: MT3 is capable of transcribing an arbitrary number of instruments from raw audio spec-trograms. Shown here are real 4-second audio clips, pianorolls reconstructed from the model’stokenized output, and the corresponding instrument labels (additional Slakh2100 instruments omit-ted due to space). Note that in some cases, multiple notes predicted from a monophonic instrument(such as clarinet or French horn) reflects an ensemble containing multiple players of that instrument.
Figure 2: Tokenization/detokenization, as described in Section 3.2. MIDI data (left, representedhere as a multitrack “pianoroll”) can be tokenized into MIDI-like target tokens for training (right).
Figure 3: 15-second excerpt of MT3 transcriptions from a mix from the Slakh2100 dataset. Blacklines indicate model input frames. Blue notes indicate “True Positive” notes with correct predictedonset, offset, pitch, and instrument. In this segment, the model achieves an Onset-Offset F1 of0.665. More extensive results from MT3 can be found on the companion website at https://storage.googleapis.com/mt3/index.html.
Figure 4: Onset-Offset F1 performance of our model over varying thresholds for the Onset-OffsetF1 metric described in Section 4.2. The default threshold of 50 ms is indicated by a dashed line.
