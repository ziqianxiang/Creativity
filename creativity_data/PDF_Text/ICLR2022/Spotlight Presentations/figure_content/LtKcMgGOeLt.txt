Figure 1: Cross-entropy loss landscapes of ResNet-152, ViT-B/16, and Mixer-B/16. ViT and MLP-Mixer converge to sharper regions than ResNet When trained on ImageNet With the basic Inception-style preprocessing. SAM, a sharpness-aWare optimizer, significantly smooths the landscapes.
Figure 2: Left and Middle: ImageNet training error and validation accuracy vs. iteration for ViTsand MLP-Mixers. Right: Percentage of active neurons for ResNet-152, ViT-B/16, and Mixer-B/16.
Figure 3: Raw images (Left) and attention maps of ViT-S/16 with (Right) and without (Middle)sharpness-aware optimization.
Figure 4: ImageNet accuracy (Left) and improvement (Right) brought by SAM.
Figure 5: Cross-entropy loss landscapes of ViT-B/16, ViT-B/16-SAM, ViT-B/16-AUG, and ViT-B/16-21k. Strong augmentations and large-scale pre-training can also smooth the curvature.
