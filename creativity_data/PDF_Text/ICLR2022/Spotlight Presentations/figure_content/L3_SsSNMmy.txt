Figure 1: Illustration of connectivity for (a) convolution, (b) global attention and spatial mixing MLP, (c) localattention and depth-wise convolution, (d) point-wise MLP or 1 Ã— 1 convolution, and (e) MLP (fully-connectedlayer). In the spatial dimension, we use 1D to illustrate the local-connectivity pattern for clarity.
Figure 2: Effect of #channels sharing the weights on ImageNet classification. X-axis: #channels within eachgroup / #param. Y-axis: ImageNet classification accuracy. (a) Local MLP: the static version of Swin transformer.
Figure 3: Relation graph for convolution (Conv.), depth-wise separable convolution (DW-S Conv.), VisionTransformer (ViT) building block, local ViT building block, Sep. MLP (e.g., MLP-Mixer and ResMLP),dynamic depth-wise separable convolution (Dynamic DW-S Conv.), as well as dynamic local separable MLP( e.g., involution (Li et al., 2021) and inhomogeneous dynamic depth-wise convolution) in terms of sparseconnectivity and dynamic weight. Dim. = dimension including spatial and channel, Sep. = separable, LR = lowrank, MS Conv. = multi-scale convolution, PVT = pyramid vision transformer.
