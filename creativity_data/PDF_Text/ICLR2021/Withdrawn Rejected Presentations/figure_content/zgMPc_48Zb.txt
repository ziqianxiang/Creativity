Figure 1: Flow diagram of DP-Sinkhorn for a single training iteration: Sensitive training data iscombined with non-sensitive generated data in the cost matrix. Then, the loss is calculated usingthe Sinkhorn algorithm. In the backward pass, we impose a privacy barrier behind the generator byclipping and adding noise to the gradients at the generated image level, similar to Chen et al. (2020).
Figure 2: Comparisons on MNIST and Fashion-MNIST between methods for private image gener-ation at (10, 10-5)-DP. The first 5 rows showing other methods are taken from Chen et al. (2020).
Figure 4: Additional DP-Sinkhorn generated images under (10, 10-6)differential privacy. Top tworows use DCGAN based generator, while bottom two rows use BigGAN based generator.
Figure 5: Additional images generated by DP-Sinkhorn, trained on MNIST. Left: Images gener-ated using parameter gradient perturbation; these correspond to the DP-Sinkhorn (VθS) row inthe main table. Right: Images generated using gradient perturbation on generated images; thesecorrespond to the “DP-Sinkhorn” row in the main results table.
Figure 6: Additional images generated by DP-Sinkhorn, trained on Fashion-MNIST. Left: Imagesgenerated using parameter gradient perturbation; these correspond to the “DP-Sinkhorn (Vθ S)” rowin the main table. Right: Images generated using gradient perturbation on generated images; thesecorrespond to the “DP-Sinkhorn” row in the main results table.
