Figure 1: Example of a Mel-spectrogramto convert the Mel-frequency STFT to a linear scale STFT, where the matrix is calculated using agradient-based method (Decorsiere et al., 2015) to minimize the euclidean norm between the originalMel-spectrogram and the product between reconstructed spectrogram and filter banks; (ii.) use theGriffin-Limâ€™s algorithm (Griffin & Jae Lim, 1984) to reconstruct phase information.
Figure 2: Representation of the CycleGAN model, which consists of two mapping functions G andF, two discriminators DX and DY and two cycle-consistency losses (Zhu et al., 2017)grams, we performed a discretization step in the range [0 - 255]. In the final stage of our pipeline,we feed the obtained dataset to the CycleGan model, that has been adapted to the structure of thisdata. Even though the discretization step introduces some distortion - original spectrogram valuesare floats - the impact on the audio quality is negligible.
Figure 3: Grade distribution of generated drums samples2020; Vasquez & Lewis, 2019; Mor et al., 2018), but after running some experiments we eventuallyrealized that they could not be properly used for arrangement purposes. All three model producevery nice music samples, but none of them can take as input vocals or bass lines and produce acomplementary arrangement. It is possible though that these models could be fine tuned to solvethis new task. In addition, we replicated exactly the same experiments using Pix2Pix by Isola et al.,a well known paired image-to-image architecture. Despite long training, results were very poor andquite unpleasant to listen to. Due to space concerns we do not report more details about this set ofexperiments.
