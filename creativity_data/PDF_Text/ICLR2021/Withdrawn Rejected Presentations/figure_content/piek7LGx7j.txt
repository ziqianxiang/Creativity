Figure 1: Image reconstruction using β-TCVAE (Figure 1b) and MS-VAE (Figure 1c). MS-VAE isable to take the blurry output of the underlying β-TCVAE model and learn to render a much betterapproximation of the target while maintaining the pose of the original image (Figure 1a).
Figure 2: (a) Graphical model of a standard VAE where C and Z are not independent conditionedon X . (b) Graphical model of β-TCVAE where the reconstruction only depends on the independentlatent factors C. (c) MS-VAE graphical model where C and Z are independent conditioned on Y .
Figure 3: Qualitative results on the Cars3D and SmallNORB datasets for β-TCVAE and MS-VAE.
Figure 4: FID (lower is better) and MIG (higher is better) comparison of β-TCVAE, β-TCVAE-L,and MS-VAE models. On both datasets, MS-VAE is able to consistently improve the reconstructionquality of its underlying β-TCVAE model while achieving a better MIG than β-TCVAE-L . We alsoprovide FID and MIG results for Lezama’s model (Lezama, 2018) with β = 1, 10 as well as FID fora vanilla VAE model of the same capacity as MS-VAE (denoted Big-VAE).
Figure 5: Mutual Information (MI) between inferred independent factors from the true image X(using β-TCVAE) and independent factors from various reconstructions of X. Please note that Blue= M1, Red = M2, Green = M3, and Purple = M4 (see Section 4 for their definitions).
Figure 6: Object property prediction for SmallNORB using inferred representations C, Z, and C + Zas input to a MLP. The accuracy is highest for the MLP trained with C + Z .
Figure 7: MIG and ELBO for different dimensionality of C for Cars3D and SmallNORB at β = 4Dim Z	Dim Z	Dim Z(a) Cars3D(b) SmallNORBFigure 8: MIG,FID and MI plots for MS-VAE as a function of the dimensionality of Z for Cars3Dand SmallNORB (β = 4).
Figure 8: MIG,FID and MI plots for MS-VAE as a function of the dimensionality of Z for Cars3Dand SmallNORB (β = 4).
Figure 9: Traversals for cars for small C (c = 2, z = 8 and β = 4). Odd rows β-TCVAE and even rowsMS-VAE. We can see the Y images are blurry and various factors are entangled.
Figure 10: Traversals for cars large C (c = 10, z = 5 and β = 4). Odd rows β-TCVAE and even rowsMS-VAE. Larger C achieves greater disentanglement and Z further refines the images.
Figure 11: Traversals for SmallNORB c = 2, z = 8 and β = 4. Odd rows β-TCVAE and even rowsMS-VAE.
Figure 12: Traversals for SmallNORB c = 10, z = 10 and β = 6. Odd rows β-TCVAE and even rowsMS-VAE.
Figure 13: CelebA Latent traversal on C. Odd rows are β-TCVAE and even rows are MS-VAE.
Figure 14: CelebA Reconstruction plots.
Figure 15: Latent traversals for the pendulum model. Odd rows (blue) are actual data from thesimulator and even rows (red) are from MS-VAE. In this example, MS-VAE learns each of the threelatent variables in a disentangled manner without any supervision for the mass control variate. Wechoose the z values that are plotted by examining the posterior over z and choosing z values thatcorrespond to the given masses (z is 1-Dimensional so this is straightforward).
Figure 16: Correlation between z and the mass when modeling a simple pendulum. In this plot, weshow 500 1-Dimensional posterior means for different θ observations to illustrate how mass and thelatent variable Z are heavily correlated after training.
Figure 17: MS-VAE graphical model of a simple pendulum. θ is the angular displacement; L isthe length; B is the damping coefficient. After learning and by construction, the latent variable Z iscorrelated with the pendulum’s mass.
Figure 18: The means of the Gaussian mixture part of MS-FLOW on MNIST.
Figure 19: MS-FLOW on MNIST. First 5 rows are real data, next five rows are samples from theGaussian mixture and last five rows are from the conditional flow.
Figure 20: Conditional log density during training for different types of Y (samples v.s. means).
Figure 21: Latent traversal on cars and chairs. Third rows in MS-GAN results show Y .
Figure 22: Latent traversal on faces (unsupervised MS-GAN). The three latent variables capture therotation, azimuth, and distance respectively.
Figure 23: Latent traversal of InfoGAN on faces. The latent variables are able to capture some posechanges but the pose changes are highly entangled with other pose factors as well as the face shape.
Figure 24: Latent traversal on CelebA (unsupervised MS-GAN). The latent variables consistentlycapture the azimuth, hair-style, gender and hair color respectively while maintaining good imagequality.
Figure 25: Latent traversal of MS-GAN and CGAN on faces. The pose variations are azimuth,horizontal translation, vertical translation, distance, rotation, and elevation from top to bottom. Theshape variations show the difference in face height, forehead, jaw, and ear from top to bottom.
Figure 26: Zoomed-in comparison on face shape. Row 1: CGAN forehead variation; Row 2: CGANjaw variation; Row 3: MS-GAN forehead variation; Row 4: MS-GAN jaw variation. Row 1 andRow 3 should have a bigger forehead from left to right while Row 2 and Row 4 should have aconsistent forehead. CGAN and MS-GAN show good forehead variation in Row 1 and Row 3,respectively, but MS-GAN is better at keeping the forehead the same while another factor is changing(Row 4 vs. Row 1).
Figure 27: Latent traversal on chairs of MS-GAN. The first three rows show the effect of the variablein C that controls rotation. The last row is the corresponding Y .
Figure 28: Latent traversal on chairs of unsupervised MS-GAN.
Figure 29: Latent traversal of unsupervised MS-GAN on cars.
Figure 30: Latent traversal of InfoGAN on faces dataset.
Figure 31: Latent traversal of unsupervised MS-GAN on face dataset.
Figure 32: Even rows are samples from CelebA (the same sample is plotted five times) and oddrows are corresponding samples from the β-TCVAE. As can be seen, for the same celebA image,the reconstruction from the β-TCVAE is highly variable, illustrating the high variance of the learnedposterior for β-TCVAE.
Figure 33: The top row is the same sample from the β-TCVAE and the bottom row is the correspond-ing reconstruction for MS-VAE. As can be seen in the figure, despite variability in the sampled Y's,MS-VAE is able to reconstruct the celebA images with little variance.
Figure 34:	L1 (lower is better) comparison for β-TCVAE (C → Y), β-TCVAE-L (latent dimension-ality same as C + Z), and MS-VAE models.
Figure 35:	L2 (lower is better) comparison for β-TCVAE (C → Y), β-TCVAE-L (latent dimension-ality same as C + Z), and MS-VAE models.
Figure 36:	A constructive example to illustrate d-separation in MS-VAE.
Figure 37: BV = β -VAE, M1 = β-VAE+Z. BV is trained with a dimensionality of C = 5. M1is trained with a dimensionality of C = 5 and Z = 5. For M1, the β-penalty is only applied toC and Z is still incorporated using AdaIN. In this figure, we show traversals of 4 of the learneddisentangled factors C for both BV and M1. As can be seen, traversing C for BV captures differentdisentangled factors (e.g. azimuth, scale, elevation). Traversing C for M1, however, illustrates thatthe disentangled factors are now entangled with other factors (e.g. identity, color).
Figure 38: BV = β-VAE, M2 = MSVAE-C, M3 = MSVAE-C-IN, M4 = MSVAE. BV is trained witha dimensionality of C = 5. In this figure, we show traversals of 4 of the learned disentangled factorsand how they are preserved in each version of MSVAE (each color box is one disentangled factor).
Figure 39: BV = β-VAE, M5 = MSVAE-ZC, M4 = MSVAE. BV is trained with a dimensionalityof C = 5. In this figure, we show traversals of 4 of the learned disentangled factors and how theyare preserved in each of the three models. To perform traversals of MSVAE-ZC, we encode Xusing a VAE to first get Z and Y, then extract C using X. To perform traversals for MSVAE, weencode X using the β-VAE to get C and Y, then we extract Z using Y. We fix Z for the traversals inMSVAE. Clearly, M4 preserves the disentanglement from BV better than M5 (M5 as expected, is notdisentangled).
Figure 40: M5 = MSVAE-ZC. In this figure, we show traversals of the Z factor in MSVAE-ZC model.
