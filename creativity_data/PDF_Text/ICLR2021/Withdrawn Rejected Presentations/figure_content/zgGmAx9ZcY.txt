Figure 1: From left to right, the three figures above depict the forward( ) and backward( ) pathswhen training with backpropagation(a), feedback alignment or Kolen-Pollack learning(b), and directfeedback alignment or direct Kolen-Pollack learning (c) respectively.
Figure 2: The cosine alignment angle between a`-i ∙ BT and hk in degrees for each backwardsmatrix starting from the first layer(f to the last layer before the output(一)for a duration of about18,000 iterations. In these results, lower angles equate to better alignment with the backpropagationalgorithm. The value of λ used is 10-6. Note that the scales of y-axis in both figures are the same.
Figure 3:	From left, the training loss, training accuracy, and test accuracy of the CIFAR10 experi-ments using 2-layer CNN. ] indicates lower the better, ↑ indicates higher the better. Dashed linesrepresent serial training and solid lines represent parallelizable training during the backwards pass.
Figure 4:	From left, training loss, training accuracy, and test accuracy on the CIFAR100 experimentsusing the AlexNet architecture. ] indicates lower the better, ↑ indicates higher the better. Dashedlines represent serial training and solid lines represent parallelizable training during the backwardspass.
