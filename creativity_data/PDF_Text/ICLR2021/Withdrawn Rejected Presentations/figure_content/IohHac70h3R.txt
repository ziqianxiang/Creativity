Figure 1: The regret bounds ofAMX, AdaGrad, AMSGrad inthe example.
Figure 2: Training and Testing Top-1 accuracy on CIFAR-10 and CIFAR-100.
Figure 3: (a), (b). Training Loss and Testing IoU curves on the VOC2012 Segmentation dataset. (c).
Figure 4: Training and testing Top-1 accuracy curve on CIFAR-10 with different momentum parame-ters β19085›百80S 7。605550	10000 20000 30000 40000 50000 60000Iterations(b) Testing Top-1 AccuracyC.1 Proof of Regret B ound of AMX with MomentumC.1.1 Proof of Theorem 4.2 and Theorem C.1Proof. Following the proof by Reddi et al. (2018), we provide the proof of regret bound in Theorem4.2 and Theorem C.1. Note that Algorithm 1 is a special case of algorithm 1. Therefore we only needto prove Theorem C.1 and Theorem 4.2 can be directly inferred by taking β1t = 0 and change α byα∕2. By the definition of the projection operation ∏f,h , We know thatxt+1 = ΠF,Ht (xt - αtHt-1mt) = argminx∈F kHt1/2 (x - (xt - αtHt-1mt))k (50)Using Lemma 4 in Reddi et al. (2018) with a direct substitution of z1 = (xt - αtHt-1mt), Q = Ht
Figure 5: The first and the second term of the regret bound in equation (2) with the diameter Dt,∞replaced by D∞ = 2. As can be observed, the first term of AMX stops increasing after τ , whichis the first time step. The other algorithms do not have such a nice property. Therefore, even if thesecond term of AMX is slightly larger than the second term of AdaGrad, the overall regret of AMX ismuch smaller. That means AMX converge much faster than AdaGrad and AMSGrad in the example.
Figure 6: Training and testing Top-1different designs of ct0505050598877665A》EmdV rtA-OH ttWH5010000 20000 30000 40000 50000 60000Iterations(b) Testing Top-1 AccuracyTable 3: Testing Top-1 Accu-racy on CIFAR-10 with differ-ent designs of ct . The resultswere averaged over 3 indepen-dent runs.
