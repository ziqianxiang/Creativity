Figure 1: The illustration of how random color transformation causes the geometry-distortion problemin unsupervised image translation. Images in the first column are input images, and images in thesecond column are the translated images by CycleGAN and GAN+MGC. Visually, as the colortransformation of the corresponding region between the input and translated image shows, the colorof the human face is translated to several colors randomly by CycleGAN, leading to the distortion offace shape. In contrast, the color transformation in the GAN+MGC is consistent, and thus preservethe shape of the human face. To reveal the randomness of color transformation quantitatively, thethird column images show that non-linear dependencies between pixel values in the input image andits corresponding pixel value in the translated image. Obviously, the geometry-preserved translatedimage (by GAN+MGC) has stronger color dependency than geometry-distorted one (by CycleGAN).
Figure 2: Unsupervised image translation examples on Portrait → Photo, Selfie → Anime. Thetop row is the translated results by each method. The bottom row is the scatter plot of the pixelvalues in the input image X and its corresponding pixel value in the translated image y, which showsthe non-linear dependency of pixel values in two images. Obviously, the stronger the dependencybetween pixel values in the input image (X-axis) and the translated images (Y-axis), the better thegeometry structure of the input image is maintained. MI stands for mutual information, which isestimated by our rSMI method.
Figure 3: An illustration of minimal geometry-distortion constraint. The left figure shows that thepixel value in the input image X and its corresponding pixel value in the translated image y havestrong non-linear dependencies, and so we add the MG constraint to model the dependencies of pixelvalues in two domain images as the right figure shows, and thus preserve the image geometry intranslation. This constraint is also compatible with other constraints, such as cycle-constraint. Thepixel dependency example is from portrait→ photo dataset.
Figure 4: Qualitative comparisons on SVHN→MNIST. From Figure (a) and (b), we can see that theGAN method has no collapse solution by combining with our MGC. Also, the geometry distortionproblem in CycleGAN is alleviated after incorporating with MGC.
Figure 5: Qualitative results on style transfer datasets, including Selfie → Anime, Portrait → Photo,Horse → Zebra. More qualitative results are given in A.7.3. It can be seen that the face shape is betterpreserved by the translation model empowered by our MGC.
Figure 6: Sensitivity analysis examples on Selfie → Anime. Obviously, the geometry distortionproblem in CycleGAN is alleviated after incorporating with our MGC.
Figure 7: The training curves and the sensitive analysis about β on Digits datasets→- GAN+MGC S->MCycleGAN+MGC S->M…▲…GAN+MGC M->M-M→-- CycleGAN+MGC M->M-M+∙ GAN+MGC M-M->M→- CycleGAN+MGC M-M->M20 340000	0.2	0.3	0.4	0.5	0.6	0.7	0.8Relative Value BetaFigure 8: The generation example of MUNIT+MGC on the edge2shoes. Specifically, images at firsttwo rows are source domain images and the others are translated images by MUNIT+MGC.
Figure 8: The generation example of MUNIT+MGC on the edge2shoes. Specifically, images at firsttwo rows are source domain images and the others are translated images by MUNIT+MGC.
Figure 9: The generation example of MUNIT on the edge2shoes. Specifically, images at first tworows are source domain images and the others are translated images by MUNIT.
Figure 10: Qualitative results on a geometry-variant dataset, including Dog → Cat. Images at thetop row are successful cases, while images at the bottom row are failure cases.
Figure 11: The overlarge λmgc example on SVHN→MNIST.
