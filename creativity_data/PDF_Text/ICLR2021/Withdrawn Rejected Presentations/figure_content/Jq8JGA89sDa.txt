Figure 1: A toy example of token-level hallucination detection from machine translation. The wordsin grey blocks is an example of machine translation output and the labels above them indicate if eachword is faithful (0) to the source input or a hallucinated one (1).
Figure 2: Generation of synthetic hallucinated data set with hallucination labels. The bottom blockgenerates a hallucinated version of T by feeding the noised sentence to the pretrained encoder-decoder model BART. The top block assigns hallucination labels to each token by computing theedit-distance between T0 and T. Labels of 1 refer to hallucinated words and vice versa.
Figure 3: An example of label assignment.
Figure 4: Finetuning XLM-Roberta (for cross-lingual generation task, e.g. machine translation) orRoberta (for monolingual generation task, e.g. text summarization) on the synthetic training data.
Figure 5: Relationship of Part-of-Speech tags and percentage of hallucinations for machine transla-tion (left) and summarization (right).
Figure 6: Performance on the TranS2S bench-mark from MT and summarization by varying thedropout rate of tokens in the reference at learninghallucination predictions.
Figure 7: Analysis of part-of-speech tags and with-in-group percentage of hallucinations for ma-chine translation (left) and summarization (right).
