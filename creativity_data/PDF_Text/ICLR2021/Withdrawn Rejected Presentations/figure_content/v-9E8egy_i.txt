Figure 1: The proposed gated message function. Figure 2: The proposed SGRU update function.
Figure 3: The input graph (ovals) for an ex- Figure 4: Training (dashed lines) and validationample of the Conditional Recall task and the (full lines) accuracies per epoch for the best runscomputational graph for 3 GNN layers. for different GNN types on the Conditional Recalltask (L=15).
Figure 5: Example of input graph for the Conditional Recall task. The top-level state of the blue nodeis used for prediction. The red node specifies the desired output.
Figure 6: Example of input graph for the Tree Max task. The double-ended arrow between a node vand a node u represents two edges: one going from v to u and the other from u to v. Not every arrowis labeled for a clearer presentation. The labels on the arrows indicate edge labels: the forward arrowâ†’ corresponds to the edge label for going from the parent to the child and J for the reverse. Theinput labels are the black numbers and the output labels are the blue numbers. Note that we use asemi-supervised version of this task, where we erase the output labels of a large portion of the nodes,i.e. ignore their output labels in training and testing.
