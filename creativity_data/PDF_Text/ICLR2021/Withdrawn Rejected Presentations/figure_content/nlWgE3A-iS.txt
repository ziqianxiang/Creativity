Figure 1: Random crop augmentation. Top row shows original observations £rom a single episodeon the walker run eπviromnent, middle and bottom row show corresponding key and query observa-tions. Note that the crop is consistent across time on both key and quray. CMLginal image is 80 × 80,cropped images are 64 × 64.
Figure 2: Comparison of observation versus reconstructed observation in Dreamer vs ReaPER forthe walker run, hopper hop, finger spin, and cartpole two poles environments. ReaPER builds coarseand robust reconstructions compared to Dreamer, where irrelevant background details are blurredbut important elements in the environment are well modeled.
Figure 3: Performance CamPariSon across 18 environments of the DMControl benchmark. LeftFigure shows average agent reward as a function of environment steps. Across all environments,ReaPER achieves consistently better episode rewards for the same number of environment steps.
Figure 4: Penonnance companson between Dreamer and the proposed ReaPER across 8 of the bestp^fbπning environments in the benchmark, mean and standard deviations are computed across 3seeds. These environments show a marked ∞ntrast in sample efficiency between the two methods,highlighting the benefit of selecting the appropriate auxiliary objectives during training.
