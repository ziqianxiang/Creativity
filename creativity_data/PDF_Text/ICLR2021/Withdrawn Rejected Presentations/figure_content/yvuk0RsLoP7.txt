Figure 1: Illustrative example of different perturbation schemes. (a) Original data, Perturbed datausing (b) PGD: a supervised adversarial generation method (c) Feature Scattering, and (d) the pro-posed ATLD method. The overlaid boundary is from the model trained on clean data.
Figure 2: Overall architecture of ATLD and its training procedure. 1) The natural example is fedinto the network, and the discriminator outputs its prediction. The manifold loss L0d is computedwith the prediction and true label and generates the adversarial example xadv (blue arrow). 2) Boththe clean and adversarial sample are fed into the network to train the classifier (green arrow) and thediscriminator (yellow arrow) iteratively.
Figure 3:	Model performance under PGD and CW attacks with different attack budgets.
Figure 4:	The overlaid decision boundary after the various adversarial training is appliedB.5	Further details of ATLD-IMTWe elaborate the training procedure of our IMT in this section. The overall architecture of ATLD-IMT is plotted in Figure 5. A test sample x is fed into the classifier, and the discriminator outputsthe prediction. A special perturbation in IMT is then computed from the loss DW and added backto x; in this way, the sample would be pushed towards the manifold of natural samples, which issupposed to be further away from the decision boundary. The prediction of the transformed xt bythe adversarially-trained classifier will then be output as the label of x.
Figure 5: Detailed Procedure of IMT. 1) The natural example or adversarial example x is fed intothe network, and the discriminator outputs its prediction. The loss log DW is computed and thetransformed example xt (red arrow) is then generated. 2) The transformed sample is fed into thenetwork and classified by the adversarially-trained network.
Figure 6: Illustration of ATLD-IMT. The decision boundary is given by ATLD in all the three sub-figures, while (a) shows clean data, (b) draws perturbed data attacked by PGD, and (c) plots adjusteddata by ATLD-IMT. Our proposed IMT can push the samples towards the manifold of natural exam-ples as observed in (c). Since the manifold of natural examples would be more separable, this mayfurther increase the classification performance.
Figure 7: Vector field illustration of different perturbation schemes. (a) PGD, (b) Feature Scattering,(c) the proposed ATLD method. The overlaid boundary is from the model trained on clean data. Thefigure plots the direction of adversarial perturbations at different points. It is worth noting that mostdirections of the adversarial perturbations for the conventional adversarial training methods point tothe decision boundary. It indicates that the resulting adversarial examples are easily biased towardsthe decision boundary which potentially corrupts the structure of the underlying distribution. Theperturbation directions for Feature Scattering and our method are influenced by decision boundaryless.
