Figure 1: In this paper we predict video at a high resolution (256 Ã— 256) using a compressed latentrepresentation. The first 4 frames are given as conditioning. We predict the next 12, two of which(9th and 16th) we show on the right. All frames shown here have been compressed by VQ-VAE.
Figure 2: Here we demonstrate the compression capability of VQ-VAE. The top and bottom rowsrepresent two different frames within the same video. The top layer retains most of the globalinformation, while the bottom layer adds fine detail. Videos licensed under CC-BY. Attribution forvideos in this paper can be found in the supplementary materialEquation 1 is not differentiable; however, (van den Oord et al., 2017) notes that copying the gradientof zq(x) to ze(x) is a suitable approximation similar to the straight-through estimator (Bengio et al.,2013). A decoder D, also implemented by a neural network, then reconstructs the input from zq (x).
Figure 3: Here we show an overview of our approach. On the left we show the process of compressingvideo with VQ-VAE. On the right we show the process of generating video with the latents. The topconditional prior model is a PixelCNN with causal convolutions to incorporate all past informationat each point in space-time. The bottom conditional prior model is simply a 2D PixelCNN whichgenerates slice by slice. It is conditioned with a convolutional tower which incorporates a windowof time slices from the top latents and past bottom latents. The slices outside of this window arecolored grey in this diagram. Blue arrows represent conditioning, green arrows generation, and pinkfeed-forward decoding. Videos licensed under CC-BY. Attribution for videos in this paper can befound in the supplementary material.
Figure 4: Selected prediction results. The first 4 frames are given as conditioning. We predict the next12, two of which (9th and 16th) we show on the right. All frames shown here have been compressedby VQ-VAE. Videos licensed under CC-BY. Attribution for videos in this paper can be found in thesupplementary material. Best seen in video in the supplementary material.
