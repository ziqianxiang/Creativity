Figure 1: The overall architecture of our RFI model. During training, pθ generates n responsecandidates, Response Detector labels them with corresponding status such as “Repetition”, and thecandidates along with the golden human response send feedback to refine pθ through the rewards.
Figure 2: The procedure to detect real repetitions.
Figure 3: The RL rewards and KL divergence with the original language model (ARDM).
