Figure 1: (a) Unsupervised DA with Amazon Review dataset. Accuracy under different levels ofshifted sources (higher dropping rate means larger label shift). The results are averaged on all targetdomains. See the results for each task in Fig. (12). (b) Visualization of λ in unsupervised DA, eachrow corresponds to one target domain. (c) Transfer learning with limited target labels in USPS.
Figure 2: Analysis on Partial DA of target Product. (a) Performance (mean ± std) of differentselected classes on the target; (b) We select 15 classes and visualize estimated ɑt (the bar plot). The”X” along the x-axis represents the index of dropped 50 classes. The red curves are the true labeldistribution ratio. See Appendix P for additional results and analysis.
Figure 3: Label distribution visualization. (a) One example in Amazon Review dataset with sources:Book, Dvd, Electronic and target: Kitchen. We randomly drop 50% of the negative reviews in all thesources while keeping target label distribution unchanged. (b) One example in Digits dataset withSources: MNIST, USPS, SVHN and Target Synth. We randomly drop 50% data on digits 5-9 in allsources while keeping target label distribution unchanged. (c) Office-Home dataset. The originallabel distribution is non-uniform. See Appendix M for details.
Figure 4: Network Structure of Proposed Approach. It consists three losses: the weighted Classifi-cation losses; the centroid matching for explicit conditional matching; the weighted adversarial lossfor implicit conditional matching, showed in Eq. (6)—牖Vv> CcentroidJ Label Partial Multi-source unsupervised DAThe key difference between multi-conventional and partial unsupervised DA is the estimation stepof αt. In fact, We only add a sparse constraint for estimating each at：|Y||Y|min^t-ET0Iog(E CSt [y,k]αt(k)) + C2katkιy=1k=1(5)s.t. ∀y ∈ Y,at(y) ≥ 0,	Xat(y)St(y) = 1yWhere C2 is the hyper-parameter to control the level of target label sparsity, to estimate the targetlabel distribution. In the paper, We denote C2 = 0.1.
Figure 5: Amazon Review dataset (a) Original Label Training Distribution; (b) Label-Shifted dis-tribution with sources tasks: Book, Dvd, Electronic, and target task Kitchen. We randomly drop50% of the negative reviews for all the source distribution while keeping the target label distributionunchanged.
Figure 6:	Neural Network Structure in the digits recognition (Ganin et al., 2016)Label distribution: MmstΛ3u"nbE∙2QO OΛ3unbE∙n∏∏∏∏∏∏∏∏Label distribution: USPS「∏ r^ι, 口 ʃi □ ɪɪri r∣ rι~~~~~~ Label distribution： SVHN ~~~~~l~l 口 ∏. ∏ XL 口 ΓLΓ~∣ 口 口..Label	distribution: Synth.
Figure 7:	One example in Digits dataset with Sources: MNIST, USPS, SVHN and Target Synth.
Figure 8: Samples Images From Office-Home dataset (Venkateswara et al., 2017), which consistsfour domains with non-uniform label distribution.
Figure 9: Label distribution of Office-Home DatasetN Analysis on the Pseudo-Labels29Under review as a conference paper at ICLR 20211.	Feature extractor: ResNet50 (He et al., 2016),2.	Task prediction: with 3 fully connected layers.
Figure 10: Neural Network Structure in the Office-HomeO	20	40Epocħ(a) Amazon Review: targetDVDs0.700.650.600.500.450.40(b) Digits: target SVHNO	20	40	60Epocħ(c) Digits: target SynthFigure 11: Evolution of accuracy w.r.t. the predicted target pseudo-labels in different tasks in unsu-pervised DA.
Figure 11: Evolution of accuracy w.r.t. the predicted target pseudo-labels in different tasks in unsu-pervised DA.
Figure 12: Different label drift levels on Amazon Dataset. Larger dropping rate means higher labelshift.
Figure 13:	Source Shifted Amazon Dataset. Evolution of λ during the training. B=Books, D=DVD,E=Electronics, K=Kitchen.
Figure 14:	Amazon Dataset. WADN approach: evolution of α during the training. Darker indicateshigher Value. Since we drop y = 0 in the sources, then the true αt (0) > 1 will be assigned withhigher value.
Figure 15: Digits Dataset. WADN approach: evolution of α^t during the training. Darker indicateshigher value. Since we drop digits 5 - 9 on source domain, therefore, αt (y), y ∈ [5, 9] will beassigned with a relative higher value.
Figure 16: Multi-source Label Partial DA: Performance with different target selected classes.
Figure 17: We select 15 classes and visualize estimated α^t (the bar plot). The "X" along the x-axisrepresents the index of dropped 50 classes. The red curves are the ground-truth label distributionratio.
Figure 18: We select 35 classes and visualize estimated c^t (the bar plot). The "X" along the x-axisrepresents the index of dropped 30 classes. The red curves are the ground-truth label distributionratio.
