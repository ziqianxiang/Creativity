Figure 1: Illustration of the example from Section 3.2 with ε = 0.02.
Figure 2: (a) Evolution of kWN kF (left), Rσ (middle) and validation accuracy (right) when train-ing of MAML (top) and PROTONET (bottom) on miniImageNet (1 shot for MAML, 5 shots forPROTONET). (b) Evolution of Rσ (left) and validation accuracy (right) when training BASELINE(top) and BASELINE++ (bottom) on Omniglot (dashed lines) and tieredImageNet (solid lines). Alltraining curves were averaged over 4 different random seeds. For MAML, kWN kF and Rσ increaseduring training and violate Assumptions 1-2. ProtoNet prototypes naturally cover the embeddingspace, while minimizing their norms. Rσ converges during training on both datasets for BASE-line++ (similarly to ProtoNet) whereas it diverges for Baseline on tieredImageNet. With ourregularization, kWN kF and Rσ are constant during training in accordance with theory.
