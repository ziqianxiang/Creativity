Figure 1: Our cell-level and macro-level search space in TransNAS-Bench-101. We design: a) Acell-level search space that treats each cell as a DAG; and b) A macro-level search space that allowsflexible macro skeleton network design.
Figure 2: Vision tasks considered in our benchmarks. We carefully select those 7 tasks above toensure both diversity and similarity across tasks from Taskonomy (Zamir et al., 2018).
Figure 4: The Spearman rank correlations among tasks. Networks in the cell-level search space hashigher correlations than the macro-level search space. The correlations shrinks quickly if we sampletop 50% of the networks.
Figure 3: The Architecture performance ranking, FLOPs,and training time in both search spaces. The longest singlenetwork training time is 18h on one Nvidia V100 GPU.
Figure 5: Tasks with the highest and lowest correlations onthe macro-level search space.
Figure 6: Comparison of random search and direct architec-ture transfer. RSDT stands for Random Search from DirectArchitecture Transfer from a specific source task.
Figure 7:	Comparison of the transfer and train-from-scratch (tfs) results of REA. REA-transfer hasslight but stable improvements across all tasks.
Figure 8:	Comparison of PPO and CATCH. CATCH largely improves PPO-transferâ€™s performance,and it works exceedingly well on object classification.
