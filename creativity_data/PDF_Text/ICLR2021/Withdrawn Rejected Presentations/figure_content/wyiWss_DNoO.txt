Figure 1: Temporal Difference Network. We present a video-level framework for learning actionmodels from the entire video, coined as TDN. Based on the sparse sampling from multiple segments,our TDN aims to model both short-term and long-term motion information in our framework. Thekey contribution is to design an efficient short-term temporal difference module (S-TDM) and a long-term temporal difference module (L-TDM), to supply a 2D CNN with local motion information andenable long-range modeling across segments, respectively. CNNs share the same parameters on allsegments. Details on both modules could be found in Figure 2.
Figure 2: An illustration of the short-term TDM and long-term TDM.
Figure 3: Visualization of activation maps with CAM. Left: video, Middle: baseline, Right: TDN.
Figure 4: Visualization of Res2 features with Grad-CAM. We use 8-frame TDN models to visualizeon the Something-Something V1 dataset. Left: video, Middle: baseline, Right: TDN with S-TDM.
Figure 5: Visualization of activation maps with Grad-CAM. We use 8-frame TDN models to visu-alize on the Something-Something V1 dataset. In the first row, we plot the 8 RGB frames. In thesecond row, we plot the activation maps of the baseline method without temporal difference module(TDM). In the third row, we plot the activation maps of the TDN models.
Figure 6: Visualization of activation maps with Grad-CAM. We use 8-frame TDN models to visu-alize on the Something-Something V1 dataset. In the first row, we plot the 8 RGB frames. In thesecond row, we plot the activation maps of the baseline method without temporal difference module(TDM). In the third row, we plot the activation maps of the TDN models.
