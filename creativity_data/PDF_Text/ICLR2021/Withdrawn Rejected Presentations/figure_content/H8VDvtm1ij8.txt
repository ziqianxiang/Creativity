Figure 1: A comparison between using a hypernetwork approach versus conditional approach tocreating Conditional QuAR Flows to model p(X |c) where W1 and W2 parametrize the layers in theresidual connection.
Figure 2: One-dimensional example of Gaus-likelihood, the original model that we recalibrate can sian versus Flowbe as simple as a Bayesian Linear Regression modelor as complicated as a conditional normalizing flow. We recalibrate the original model by fitting anormalizing flow on top of it. In this way, the training process is the following two-step procedure:1.	fθ = argmaχfθ PNtr logPfθ (ytr lxtr)2.	gφ = arg maxg PNvallog pgφ (Fθ (yV叫 Xval))where fθ(y|x) is the predicted pdf function given x, Fθ(y∖x) is the CDF of fθ(y|x), {xtr ,ytr }Nr isthe training set and {xval, yval}iN=v1al is the validation set. Though the formulation of recalibrationabove shows we can use any likelihood model for gφ, since isotonic regression is a method to fit afree form function to the CDFs, we choose to use normalizing flows, specifically QuAR Flows, asthese are more flexible than using autoregressive flows such as MAFs (Papamakarios et al., 2017).
Figure 3: Comparison plots of isotonic regression and flow recalibration on multiple outputs. The twoaxes are different targets being modeled, and the scatter plot shows that the targets are correlated. Thetop and right sides show the marginal histogram as well as the fit from the recalibrated distribution.
Figure 4: Calibration Q-Q plots for recalibration using isotonic regression and recalibration usingflows for the simulated multivariate case in Figure 3a. The legend contains the calibration error foreach curve.
Figure 5: A diagram for multivariate recalibration using the same notation as that used in Section4.2. The first step for recalibration is always the calibration step, shown in the blue box, where anylikelihood model fθ can be used. On the left, isotonic regression is used to recalibrate the CDFs fromfθ ; on the right, normalizing flows gφ are used to recalibrate the CDFs from fθ conditioned on somec.
Figure 6: Calibration Q-Q plots for recalibration with an unconditional flow and recalibration with aconditional flow on the dataset “naval-propulsion-plant”. The legend contains the calibration errorfor each curve.
Figure 7: Calibration Q-Q plots for recalibration with isotonic regression and recalibration withnormalizing flows on the second time step on the dataset “electricity”. The legend contains thecalibration error for each curve.
Figure 8: In this figure, we show our conditional flow model. A neural network takes X and outputsthe scale and shift of an affine flow and a condition vector for QuAR Flows. The condition used inthe QuAR Flow is the same for both QuAR Flows. After the first conditional affine flow, there aretwo QuAR Flows with unconditional affine flows placed in between these two and at the end. TheConditional Flow model is equivalent to a Conditional Gaussian if we removed the QuAR Flows.
