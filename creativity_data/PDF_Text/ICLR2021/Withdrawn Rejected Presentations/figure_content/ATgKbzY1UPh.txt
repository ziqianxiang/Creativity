Figure 1: Category-Viewpoint datasets. (a) Our new Biased-Cars dataset: Can a network shownonly the Ford Thunderbird from front and the Mitsubishi Lancer from side generalize to classify thecategory and viewpoint for a Thunderbird seen from the side? (b) iLab-2M dataset (Borji et al.,2016): Each cell represents a unique category-viewpoint combination (categories vary betweenrows, viewpoint between columns) with multiple object instances per category and backgrounds.
Figure 2: Architectures for Category Recognition and Viewpoint Estimation. Shared, Separate andSplit-2 architectures for ResNet-18. In the Shared architecture, all layers until the last convolutionalblock are shared between tasks, followed by task specific fully connected branches. In the Separatearchitecture, each task is trained in a separate network with no layer sharing. Split-2 presents amiddle ground. These architectures are designed similarly for backbones other than ResNet-18.
Figure 3: Generalization performance for Shared and Separate ResNet-18 as seen combinations areincreased for all datasets. The geometric mean between category recognition accuracy and view-point estimation accuracy is reported along with confidence intervals (a) MNIST-Position dataset.
Figure 4: Generalization performance for different architectures and backbones as seen combina-tions are increased for all iLab and Biased-City datasets. The geometric mean between categoryrecognition accuracy and viewpoint recognition accuracy is reported for unseen combinations aspercentage of seen combinations is increased. (a) and (b) Accuracy of separate and shared forbackbones other than ResNet-18, for iLab and Biased-Cars datasets, respectively. (c) and (d) Accu-racy of ResNet-18 Separate, Shared and different Split architectures made at different blocks of thenetwork, for iLab and Biased-Cars datasets, respectively.
Figure 5: Specialization to category recognition and viewpoint estimation. (a) Prototypical activa-tion grids for different types of selective and invariant neurons. (b) and (c) Percentage of neuronsafter ResNet-18 block-4 that are specialized to category and viewpoint, for iLab and Biased-Carsdatasets, respectively. ResNet-18 Separate and Shared networks are evaluated; for Separate, onlythe task-relevant neurons for each branch are displayed.
Figure 6: Neuron specialization (selectivity to category and invariance to viewpoint, and vice versa)in the Biased-Cars dataset. (a) and (b) Median of the specialization score among neurons (Î“k)in network architectures, other than ResNet-18, separate and shared, for category and viewpointclassification tasks, respectively. Confidence intervals displayed in low opacity. (c) and (d) Medianof the specialization score among neurons in ResNet-18 Separate and Shared with splits made atdifferent blocks of the network, for category and viewpoint classification tasks, respectively.
