Figure 1: The construction (3) smoothly interpolates between a standard neuron (α = 0) and anRBF-type of neuron (α = 1). Shown are the neuron decision boundaries for various values of α.
Figure 2: Left: Diagram of the compact support neural network (CSNN), With the CSN layerdescribed in Eq. (6). Right: an example of the CSNN with normalized input from ResNet. Only thefull arrows have backpropagation.
Figure 3: Histogram of the norms ∣vi ∣ of the normalized input features vi to the CSN layer for thethree datasets trained in our experiments.
Figure 4: The confidence map (0.5 for white and 1 for black) of the trained CSNN on the moonsdataset for different values of α ∈ [0, 1]. Top: zoom out on the interval [-5, 6]2. Bottom: zoom inview of the interval [-0.5, 1.5]2.
Figure 5: Example of activation pattern domains for α = 0 and α = 0.825 and the resultingconfidence map (0.5 for white and 1 for black) for α = 0.825 for a 32 neuron 2-layer CSNN.
Figure 6: CSNN train and test er-rors, AUROC and percent nonzerooutputs (NZ) vs. α for the moonsdata.
Figure 7: Confidence mapwithout pruning, α = 0.985.
Figure 8: The CSNN-F with LeNet backbone, where all layers are trained by backpropagation.
Figure 9: Train and test errors, Area under ROC Curve (AUROC) and percent nonzero outputs (NZ)vs α for CSNN classifiers trained on three real datasets. These results are obtained from one trainingrun.
