Figure 1: The Overall framework of CARE. CARE firstly learns a model of the environment which takes thestates of different categories of entities as input and predicts the next step states of all categories. Then weperform causal relation analysis on the model to get a relation graph among all categories. Finally, intrinsicreward based on the graph and the effect of agent behavior on entities is given to the agent to assist policylearning.
Figure 2: Architecture of the environmentalmodel. The model contains one encoder and K de-coders each corresponding to one category. The en-coder takes current state as input and the decoderspredict the next step state of each category.
Figure 3: The Shepherd game (left) and the Ant game (right).
Figure 4: Experimental results on the two test games.(a) Learning curves of the Shepherd game. (b)Learning curves of the Ant game. All experiments are averaged over 5 random seeds.
Figure 5: Visualization of the Iewe (s, drive) in the Shepherdgame. The heatmap is generated by intervening the position ofthe agent to every grid in the field to get Iewe (s, drive) usingEquation 14.
Figure 6: Learned graphs of theShepherd game (lef t) and the Antgame (right).
