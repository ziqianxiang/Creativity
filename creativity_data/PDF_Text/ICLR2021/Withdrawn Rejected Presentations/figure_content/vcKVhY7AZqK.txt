Figure 1: Schematic view of the overall frameworkfor quantifying complexity of a task TX;Y .
Figure 2: Conditional Inference Network.
Figure 3: The plots (a) & (b) show the trade-off between accuracy and complexity as is varied(c), (d), (e) & (f) pertain to our discussion on interpretability. (a) Complexity results on MNISTwith different levels of nuissances; (b) Complexity results for different image classification tasks;(c) test image x0 from Caltech Silhouettes dataset with class “Motorbike”; (d) patches queried byEIP before termination for x0 (shown by the overlayed coloured 3 × 3 boxes); (e) Part of image x0observed through the queried patches; (f) Heatmap for probability a pixel would be visited by the IPEncoder for a randomly chosen image with label “Motorbike” from the Caltech Silhouettes dataset.
Figure 4: The encoder-decoder architecture used in the β-VAE network. Recall from section 3.2 4,Xj are the image pixels, Y is the class label and Z are the nuisances. (a) Encoder Network: Takesthe image {Xj∙}j∈{1,2,…,28×28} and class label Y as inputs and predicts the mean μ and diagonalcovariance matrix Σ of the nuisances Z. The weights of this network are denoted as ω in the maintext; (b) Decoder Network: Takes the nuisance Z and class label Y as inputs and predicts theBernoulli parameters of each pixel Xj in the image. The weights of this network are denoted as φin the main text. Best viewed in colour.
Figure 5: Overall architecture of the Conditional Inference Network used based on RealNVPnormalizing flows. The network takes {qi , qi (x)}1:k, Y and η as inputs and performs 25 trans-formations η → η24 → η23 → ... → η0. Each transformation is referred to as Ψl :=DNN({qi,qi(x)}i：k,y,ηι+ι； Yl) in Fig. 2.
Figure 6: The Actnorm layer used in each layer of the Conditional Inference Network. This layertakes ηl, {qi, qi(x)}1:k) and y as input and outputs ηla-ct1norm. ◦ denotes element-wise multiplication.
Figure 7: The N Naffine used in each Affine layer (31) of the Conditional Inference Network. Thislayer takes hl1-1, {qi, qi(x)}1:k and y as inputs and outputs scale vector s and shift vector t.
