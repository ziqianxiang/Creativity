Figure 1: GCN network architecture with VAE branch. Here nz = 16 is the number of latentvariables per joint.
Figure 3: Confusion matrix for a multi-class classifier for action labels. In each case we use thesame input convention ~xk = [xk,1, . . . , xk,N, xk,N+1, . . . , xk,N+T] where xk,n = xk,N forn ≥ N.
Figure 4: Confusion matrix for a multi-class classifier for action labels. In each case we use thesame input convention ~xk = [xk,1, . . . , xk,N, xk,N+1, . . . , xk,N+T] where xk,n = xk,N forn ≥ N.
Figure 5: Confusion matrix for a multi-class classifier for action labels. In each case we use thesame input convention ~xk = [xk,1, . . . , xk,N, xk,N+1, . . . , xk,N+T] where xk,n = xk,N forn ≥ N.
Figure 6: Latent embedding of the trained model on both the H3.6m and the CMU datasets inde-pendently projected in 2D using UMAP from 384 dimensions for H3.6M, and 512 dimensions forCMU using default hyperparameters for UMAP.
