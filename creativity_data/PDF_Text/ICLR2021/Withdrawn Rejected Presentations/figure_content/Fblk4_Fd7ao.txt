Figure 1: Embodied Referential Gamecontext of referential games is that, in principle, it allows for ZS communication: Trajectories requir-ing lower energy exertion should be used for encoding more common intents, while those associatedwith higher energy encode less common ones.
Figure 2: Learning Curves, associated with the four experimental conditions described. Subfigure 2a showscommunication success with training partners (SP). Subfigure 2b shows communication success of each actorwith all unseen observers in the population (CP), as actor policies are being trained. The latter is out of distribu-tion, since all (actor, observer) pairs train independently. Plot illustrates that while protocol training convergesto near perfect performance, generalization of protocol to novel partners is extremely challenging.
Figure 3: Protocols Learned in Discrete-Channel Domain. Two independently trained agent pairs (top, bottom)per condition. Left column shows sender policy mapping given intents to communication actions (messages).
Figure 4: Energy Exertions of Intents 1 (blue) and 2 (orange). Task = 2 Intents. Shows intent-conditionedGaussian distributions to approximate energy exertion of one agent, given both types of Training Input. High ZScoordination is achieved in this task because there is minimal overlap between the intent energy distributions.
Figure 5: Comparison of Learned Behaviors for N=2 Intents Task. Illustrates one instantiation of how an agentlearns to generate communication for distinct intents in the protocol. Top = Intent 1, Bottom = Intent 2. Note:Although the time horizon is T = 5 for policy learning, trajectories are upsampled for visualization purposes toT = 30. So visualized snapshots are evenly spaced throughout an entire generated trajectory.
Figure 6: Energy Costs by Intent, sub-sampled throughout duration of protocol training. Energy cost for eachintent proceeds over time - from top to bottom. Task = 5 concepts. Training With no curriculum. Shows Cor-rectly mapping intents by rank to continuous-valued energy costs is challenging for the optimization algorithm.
Figure 7: Protocols Learned and Tested for ZS Coordination in Discrete-Channel Domain (Task 1). Zipf onlyBaseline Condition. Protocol Training (SP) and Evaluation (CP). Illustrates how challenging ZS communica-tion (7b, right column) is as compared to communication success with training partners (7a, right column). It ismade harder by the fact that policies learned during the initial protocol training phase are very different, acrosssenders (7a, left column)14Under review as a conference paper at ICLR 2021(a) Zipf + Engy: Training Pairs (SP)(b) Zipf + Engy: Pairings Tested (CP)Figure 8: Protocols Learned and Tested for ZS Coordination in Discrete-Channel Domain (Task 1). Zipf+ Energy Experimental Condition. Protocol Training (SP) and Evaluation (CP). Illustrates that while ZScommunication (8b, right column) is somewhat more challenging than success with training partners (8a, rightcolumn), ZS coordination from protocols built upon energy-based latent structure is noticeably more successfulthan ZS coordination in baseline condition with no energy penalty (8b, right column). This can be observedby higher prediction probabilities (shown as yellow boxes) occurring with significantly greater frequency alongthe diagonal (meaning sender and receiver agree on intent) than in baseline condition.
Figure 8: Protocols Learned and Tested for ZS Coordination in Discrete-Channel Domain (Task 1). Zipf+ Energy Experimental Condition. Protocol Training (SP) and Evaluation (CP). Illustrates that while ZScommunication (8b, right column) is somewhat more challenging than success with training partners (8a, rightcolumn), ZS coordination from protocols built upon energy-based latent structure is noticeably more successfulthan ZS coordination in baseline condition with no energy penalty (8b, right column). This can be observedby higher prediction probabilities (shown as yellow boxes) occurring with significantly greater frequency alongthe diagonal (meaning sender and receiver agree on intent) than in baseline condition.
Figure 9: Protocols Learned in Discrete-Channel Domain, with Action Degeneracies. Three independentlytrained agent pairs (individual rows) in baseline condition. Left column shows sender policy mapping givenintents to communication actions (messages). Middle column shows receiver policy mapping sender actionsto predicted intents. Right column shows SP Performance (p(predicted - intent | true - intent)) at the endof Protocol Training. Illustrates condition can train sender policies to communicate effectively with trainingpartners, but there is significant variance across sender policies learned. This would make finding commonstructure and exploiting it to generalize to novel partners very difficult (perhaps impossible since no commonstructure is evident).
Figure 10: Protocols Learned in Discrete-Channel Domain, with Action Degeneracies. Three independentlytrained agent pairs (individual rows) in experimental condition. Left column shows sender policy mappinggiven intents to communication actions (messages). Middle column shows receiver policy mapping senderactions to predicted intents. Right column shows SP Performance (p(predicted - intent | true - intent)) atthe end of Protocol Training. Illustrates condition using energy-based latent structure can both train effectiveprotocols between training partners and induce similar structure in policies learned, across sender agents, forenabling better communication generalization (to unseen partners).
Figure 11: Protocols Learned and Tested for ZS Coordination in Discrete-Channel Domain - given ActionDegeneracies (Task 2). Zipf only Baseline Condition. Protocol Training (SP) and Evaluation (CP). Illustrateshow challenging ZS communication (11b, right column) is as compared to communication success with trainingpartners (11a, right column). Itis made harder by the fact that policies learned during the initial protocol trainingphase are very different, across senders (11a, left column).
Figure 12: Protocols Learned and Tested for ZS Coordination in Discrete-Channel Domain - given ActionDegeneracies (Task 2). Zipf + Energy Experimental Condition. Protocol Training (SP) and Evaluation(CP). Illustrates ZS communication (12b, right column) is substantially more challenging than success withtraining partners (12a, right column). Nonetheless, ZS coordination from protocols built upon energy-basedlatent structure is slightly more successful as compared against ZS coordination in baseline condition with noenergy penalty (12b, right column).
