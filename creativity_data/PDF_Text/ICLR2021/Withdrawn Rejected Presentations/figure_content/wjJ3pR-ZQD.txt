Figure 1: Matching of BBGM (Rol´nek et al.,2020) 11/13 with Delaunay triangulation andour DLGM-G 13/13 using generated graph(Pascal VOC). DLGM-G generates graph with4 more edges than Delaunay (33 vs 29) for bothsource and target. But with 4 more commonedges across source and target than Delaunaytriangulation (26 vs. 22), it leads to better accu-racy. Blue and red edges denote common edgesin Delaunay and learned graph pairs.
Figure 2: (a) One of the two branches of our DLGM framework (see the complete version in AppendixA.1). NB: VGG16 as backbone producing a global feature of input image, and initial X and E;Ng： deterministic or generative module producing latent topology A; Nr： SplineCNN for featurerefinement producing updated X and E. (b) A schematic figure showing the merit of introducingconsistency loss Lc for training. Initial topology A(S) and A(t) are constructed using Delaunaytriangulation. Given matching Z as guidance, latent topology A(S) and A(t) are generated frominputs A(S) and A(t), respectively. Note the learned topology A(S) and A(t) are isomorphic (Lc = 0)w.r.t. Z which is easier to match in test, comparing to non-isomorphic input structures (Lc = 4).
Figure 3: Consistency and locality loss(Eq. (9) and (10)) keep decrease overtraining shoWing the effectiveness foradaptive topology learning for matching.
Figure 4: Holistic pipeline of DLGM consisting of two singleton pipelines.
