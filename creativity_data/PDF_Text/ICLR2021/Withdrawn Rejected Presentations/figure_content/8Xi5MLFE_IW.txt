Figure 1: A. Baseline generative model.
Figure 2: STM pipeline. (A) As the agent moves through the environment, states s that exceededa pre-defined threshold are recorded along with all successive actions a in an S-sequence. (B) S-sequences are saved in a buffer at the end of each episode. (C) S-sequences are sampled for traininga subjective-timescale transition model.
Figure 3: Experimental Results. (A) Cumulative rewards collected by the agents. It can be seen thatthe STM-MCTS agent shows improved performance even when compared with the computationally-expensive Baseline-MPC. (B) Mean number of rewards (spheres) by category. STM-MCTS collectsmore green and yellow (positive) rewards than the baseline agents. However, Baseline-MPC collectsfewer (negative) red rewards, which is likely related its ability to evaluate actions after every step.
Figure 4: STM can vary prediction timescale, with large gaps between predictions at the start,which becomes more fine-grained as the object gets closer. Objective-timescale model suffers fromslow-timescale predictions and error accumulation, resulting in poorly-informative predictions.
Figure 5: STM is able to imagine surprising events. Despite the fact that appearance of objects is arare event in the environment, STM frequently predicts them in the roll-outs. In contrast, objective-timescale model is not capable of that as a direct corollary of its training procedure.
Figure 6: Implementation of the baseline system.
Figure 7: Observations sorted by their corresponding recorded value of the objective-timescale tran-sition model free energy in descending order. States with higher values on average contain moreobjects, constituting more complex settings.
Figure 8: Agent trained with PER is better at generating observations with objects. (A) Predictionroll-outs showing that baseline trained with PER can better represent objects, thus preserving them infuture predictions. (B) Ground-truth observations (third column) are passed through the autoencoderof the on-line and PER agents. As can be seen, observations are better reconstructed by the baselinesystem trained with PER.
Figure 9: Implementation of STM components.
Figure 10: Random roll-outs generated with the STM transition model.
Figure 11: STM can imagine objects from ‘uninteresting’ states. Arrows indicate roll-outs withimagined objects.
Figure 12: In contrast to STM, the objective-timescale transition model is not able to imagine ob-jects, starting with the same initial observations as shown in Figure 11.
