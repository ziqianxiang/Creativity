Figure 2: (a) The workflow of the proposed framework. (b) The pseudo label fusion procedure.
Figure 3: The three PLF procedures discussed in this work: (a) certainty, (b) priority, and (c) majority.
Figure 4: (a) Visualization of the fused PL with different PLF procedures. (b) Visualization of the modelpredictions, where PLF-3M and PLF-3D represent Deeplabv3+ trained with PLF using MobileNetv2 & DRN-50as the backbones, respectively. (c) A comparison of mIoU v.s. model size.
Figure 5: Comparisons of (a) τ v.s. mIoU for PLF-3D, and (b) τ v.s. mIoU for PLF-3M.
Figure A1: The pseudo code of the proposed PLF frameworkA1.2 Pseudo LabelFirst proposed by (Lee, 2013), it was first intoduced to improve the performance of image classificationby training with both the labeled data and unlabeled data. It is used in the fine-tunning phase oftraining during which the network is trained on both the supervised and unsupervised data. Theunsupervised loss is calculated using the cross entropy between the network prediction and thepseudo labels, which is generated using the prediction on the unlabeled data with pixel-wise functiondescribed by the following equation:Y 0 =	1, i = argmaxi0 fi0 (x)i 0, otherwise,(A4)where i, i0 denotes one of the classes in a set of classes. fi0(x) denotes a pixel in the output confidencemap. By reducing the cross entropy loss between the unlabeled data and the generated pseudo label,the class overlapping of the output is greatly reduced and the decision boundary is adjusted to lie inlow density regions.
Figure A2: The visualization results of PLF-3D on Cityscapes.
