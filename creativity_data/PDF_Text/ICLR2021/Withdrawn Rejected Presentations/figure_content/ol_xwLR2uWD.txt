Figure 1: Our pretraining (denoted as RR) yields improvements for numerous applications: a): For difficultshape classification tasks, it outperforms existing approaches (StdTs, OrtTS, PreTS): the RRTS model classi-fies the airplane shape with significantly higher confidence. b): Our approach establishes mutual informationbetween input and output distributions. c): For CIFAR 10 classification with a Resnet110, RRcio yields sub-stantial practical improvements over the state-of-the-art. d): Learned weather forecasting has strictly limitedreal-world data: our pretraining yields improvements for pressure (Z500, zoomed in regions shown above),atmospheric temperature (T850) as well as ground temperature (T2M).
Figure 2: A visual overview of the regularforward pass (blue) and the corresponding re-verse pass for pretraining (yellow).
Figure 3: Column vectors of Vm for differenttrained models Std, Ort, Pre and RR for peaks.
Figure 4: MI planes for different models: a) Visual overview of the contents. b) Plane for task A. Pointson each line correspond to layers of one type of model. All points of RRa, are located in the center of thegraph, while StdA and OrtA, exhibit large I(Dm; Y), i.e., specialize on the output. PreA strongly focuses onreconstructing the input with high I(X; Dm) for early layers. c,d): After fine-tuning for A/B. The last layerD7 of RRaa and RRab successfully builds the strongest relationship with Y, yielding the highest accuracy.
Figure 5: Performance for MI source and trans-fer tasks for the models of figure 4. Due to thelarge standard deviation of Ort, we show min/maxvalue ranges. The dashed gray line and regionshow baseline accuracy for StdB. The top-left in-set highlights the stability of the high accuracy re-sults from RR training.
Figure 6: (a) Examples from texture-shape dataset. (b, c, d) Texture-shape test accuracy compar-isons of PreTS,OrtTS, StdTS and RRTS for differentdata sets.
Figure 8: (a) Example output and reconstructed inputs, with the reference shown right. Only RRAsuccessfully recovers the input, StdA produces a black image, while PreA fares poorly. (b) L2 losscomparisons for two different generative transfer learning tasks (averaged across 5 runs each). TheRR models show the best performance for both tasks.
Figure 7: Left: Examples from CIFAR 10.1 dataset. Right: Accuracy comparisons when applyingmodels trained on CIFAR 10 to CIFAR 10.1 data.
Figure 9: Details of the three physical quantities of the weather forecasting test (full frames are shown in theappendix). As confirmed by the quantified results, RR predicts results closer to the reference.
Figure 10: Left: An overview of the regular forward pass (blue) and the corresponding reverse pass (yellow).
Figure 11: SVD of the Mi matrix for five tests with random two digit images as training data. LPIPS distances(Zhang et al., 2018b) of RR are consistently lower than Std and Ort.
Figure 13: Five repeated tests with the peak data shown in Sec. 3 of the main paper. RRA robustly extractsdominant features from the data set. The two singular vectors strongly resemble the two peak modes of thetraining data. This is confirmed by the LPIPS measurements.
Figure 15: (a-c) MI plane comparisons for local (IRRa) versus full models (RRA). Points on each linecorrespond to layers of one type of model. a) MI Plane for task A. All points of RRA and the majority ofpoints for IRRa (five out seven) are located in the center of the graph, i.e., successfully connect in- and ouputdistributions. b,c): After fine-tuning for A/B. The last layer D7 of RRaa builds the strongest relationship withY. I(D7; Y) of IRRA is only slightly lower than RRaa. d): Accuracy comparisons among different models:RRaa yields the highest performance, while IRRA performs similarly with RRaa.
Figure 16: Additional results for the disentangled representations with the MNIST data: For every row in thefigures, we vary the corresponding latent code (left to right), while keeping all other inputs constant. Differentrows indicate a different random noise input. For example, in (b): every column contains five results which aregenerated with different noise samples, but the same latent codes c1~3. In every row, 10 results are generatedwith 10 different values of c1 , which correspond to one digit each for (b). (a): For a regular training (Std),no clear correspondence between c1 and the outputs are apparent (similarly for c2,3). (c): Different c2 valuesresult in a tweaked style, while c3 controls the orientation of the digit, as shown in (d). Thus, in contrast to Std,the pretrained model learns a meaningful, disentangled representation.
Figure 17: Separate per-class test accuracies for the fourmodel variants. The RRTS model exhibits a consistently highaccuracy across all 16 classes.
Figure 18: Example outputs for PreAB1, StdAB1, RRAB1. The reference is shown for comparison. RRAB1produces higher quality results than StdABI and PreAB1.
Figure 19: Mean Absolute Error (MAE) comparisons for smoke task B2 models. RRAB2 shows the smallesterror, and additionally achieves the best visual quality amongst the different models.
Figure 20: A comparison of additional Z500, T850, T2M predictions (zoomed in regions). The predictionsinferred by the RR model are closer to the observed references.
Figure 21: MSE value comparisons between RR and Std(ERR for RR and EStd for Std). RR consistentlyyields lower errors than Std.
