Figure 1: Visualization of feature representations. The eight sub-figures correspond to the eightsettings in Table 1 (identified by ID). Colors denote domains, while shapes indicate classes. Thetarget domain (violet) is “art-painting”. The top row shows the Bayesian treatment enlarges theinter-class distance for all domains, considerably. The bottom row, compared with the top-rowfigures in the same column, shows the domain-invariant principle enlarges the inter-class distance inthe target domain by reducing the intra-class distances between the source and target domains.
Figure 4: Visualization of feature representations of the target domain. Different colors denote dif-ferent categories. The sub-figures have the same experimental settings as the experiments in Table 1and Fig. 1. Visualizing only the feature representations of the target domain shows the benefits ofthe individual components to the target domain recognition more intuitively. The target domain is“art-painting”, as in Fig. 1. We obtain a similar conclusion to Section 4.2, where the Bayesian infer-ence enlarges the inter-class distance for all domains and the domain-invariant principle reduces theintra-class distance of the source and target domains.
Figure 5: Visualization of feature representations of one category. All samples are from the “horse”category with colors denoting different domains. The target domain is “art-painting” (violet). Thetop row shows Bayesian inference benefits domain generalization by gathering features from differ-ent domains to the same manifold. The figures in each column indicate domain-invariant learningreduces the intra-class distance between domains, resulting in better target domain performance.
Figure 6: Visualization of feature representations in rotated MNIST and rotated Fashion-MNISTdatasets. Samples from the in-distribution and out-of-distribution sets are in red and blue, respec-tively. Different shapes denote different categories. Compared to other methods, our VIL achievesbetter performance on both the in-distribution and out-of-distribution sets in each dataset, and espe-cially on the out-of-distribution set from the Fashion-MNIST benchmark.
