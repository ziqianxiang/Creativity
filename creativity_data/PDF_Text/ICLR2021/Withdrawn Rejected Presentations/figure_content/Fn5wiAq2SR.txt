Figure 1: Measurement ofTS (as defined in Definition 5) in different layers of ResNet34 on CIFAR10.
Figure 2: Comparison with different advanced fast adversarial training methods. We use PGD-20as the attacker and report their clean accuracy and robust accuracy. Solid lines represent the robustaccuracy and dashed lines represent the clean accuracy.
Figure 3: The accuracy rates of Wide ResNet34 trained by ATCD with different configurations (T, K)on CIFAR10.
Figure 4: The accuracy rates of Wide ResNet34 trained by different adversarial training methods withdifferent epsilon on CIFAR10. We use PGD with ε = 8/255 and ε = 2/255 to performe thoroughexperiments over the number of attack iterations ε = {10, 20, 50, 100, 200}.
Figure 5: The accuracy rates of Wide ResNet34 trained by different adversarial train-ing methods with different epsilon on CIFAR10. We use PGD with 100 iterations andwell-tuned steps as attacker to perform thorough experiments over epsilon parameters ε ={8/255, 16/255, 32/255, 64/255, 128/255}.
Figure 6: The accuracy rates of Wide ResNet34 trained by our method with different ratios of λ∕ρranging from 1/32 to 32 on CIFAR10. We use several attackers including PGD-20, MI-FGSM-20,CW and AA to validate the stability of parameters.
Figure 7:	The accuracy rates of Wide ResNet34 trained by ATCD with different lengths of trajectoryon CIFAR10. Basically, we could find that the robust accuracy of model increases with the length ofthe trajectory.
Figure 8:	Success cases for both HMC-based method and Geekpwn CAAD 2018 method. Theconfidence score of adversarial examples generated by Geekpwn CAAD 2018 for each pair is lowerthan any one in our generated sequence.
Figure 9: Three cases where our method succeeds but GeekPWn CAAD 2018 method failsOur generated sequenceGeekpwn CAAD 2018Catched, 34.3Figure 10:	A case shows that an adversarial example generated by Geekpwn CAAD 2018 method isclassified correctly by the online systems but any one in our generated sequence still fool the systemswith high confidence score.
Figure 10:	A case shows that an adversarial example generated by Geekpwn CAAD 2018 method isclassified correctly by the online systems but any one in our generated sequence still fool the systemswith high confidence score.
Figure 11:	Typical failure cases of our method. In the task of attacking Don Cheadle as Peter O’Toole(the first row), HMC-based method only has a partial success due to their different colors. HMC-basedmethod also fails in attacking Bill Gates as Jason Kidd (the second row). We believe that Bill Gatesis an easy case for mutiple classifiers since there exist numerous related pictures about him and therecognition system will give priority to the correctness of him.
