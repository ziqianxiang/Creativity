Figure 1: Conditional Networks2	Background and Related WorkSelf-supervised learning. Self-supervised learning extracts and uses available relevant contextand embedded metadata as supervisory signals. It is a representation learning approach that exploitsa variety of labels that come with the data for free. To leverage large amounts of unlabeled data, it ispossible to set the learning objectives such that supervision is generated from the data itself. The self-supervised task, also known as pretext task, guides us to a supervised loss function (Gidaris et al.,2018; Oord et al., 2018; He et al., 2019; Chen et al., 2020). However, in self-supervised learningwe usually do not emphasize performance on this auxiliary task. Rather we focus on the learnedintermediate representation with the expectation that this representation can carry good semantic orstructural meanings and can be beneficial to a variety of practical downstream tasks. Conditionalnetworks can be seen as a self-supervision approach in which the pretext task is jointly learned withthe downstream task.
Figure 2: Qualitative Results. (a) Input from East Tyrol city, (b) AMLL U-Net segmentation resultsfor (a), (c) Fully Cond. U-Net CGN segmentation results for (a), (d) Input from Bellingham city, (e)AMLL U-Net segmentation results for (d), (f) Fully Cond. U-Net CGN segmentation results for (d).
Figure 3: Conditional Network Architecture for U-Nett in terms of visual patterns that correlate with auxiliary annotations of training data. Notethat this allows the distribution of auxiliary information at test time to differ from the train-ing data (see for example our experiments on out-of-distribution generalization in remotesensing in Section 4.1).
Figure 4: Heatmap of activations for (a) AMLL U-Net and (b) conditional U-Net. Cell ij in row iand column j gives the activation of features j on patch i. Rows and columns are sorted so that thosethat are more similar to one another appear side-by-side. Note that the color legends have differentscales.
Figure 5: Example of negative and positive TIL patches for different cancer types. The desired taskis to properly classify a patch as TIL negative or TIL positive independently of the cancer type.
Figure 6: (a) Training loss AMLL U-Net (b)Training loss AMLL U-Net Cond. U-NetFigure 6	shows the learning curves of the baseline U-Net and the fully conditional U-Net (CGN).
Figure 7:	(a) Histogram of overall performance for both validation and test set (b) Histogram of percity performance(a) t-SNE AMLL U-Net train set	(b) t-SNE Cond. U-Net train setFigure 8:	t-SNE based on activations obtained using image tiles from the cities in the training set.
Figure 8:	t-SNE based on activations obtained using image tiles from the cities in the training set.
Figure 9:	t-SNE based on activations obtained using image tiles from cities in both training and testsets. (a) AMLL U-Net train and test sets (b) Cond. U-Net CGN train and test setsa∪stin	bloomington	Innsbruck	sfo	Viennabellingham 白 Chicago	kitsap	tyrolFigure 10: The (top) least and (bottom) most variable features, according to interquartile range, inthe AMLL and conditional U-Nets, after filtering to those features that are active in at least 10%of patches. Columns 1-10 give the 10 most and least variable features, for least and most variablefeatures, respectively. The y-axis is the activation for each feature. Patches are split into individualcities, and a boxplot of each city’s activation values is given.
Figure 10: The (top) least and (bottom) most variable features, according to interquartile range, inthe AMLL and conditional U-Nets, after filtering to those features that are active in at least 10%of patches. Columns 1-10 give the 10 most and least variable features, for least and most variablefeatures, respectively. The y-axis is the activation for each feature. Patches are split into individualcities, and a boxplot of each city’s activation values is given.
