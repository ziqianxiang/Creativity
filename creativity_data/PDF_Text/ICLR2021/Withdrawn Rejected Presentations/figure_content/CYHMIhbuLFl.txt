Figure 1: Data used when adapting to anew feature xn . The rows which containyellow blocks are Cn and other rows arein Tn .
Figure 2: (a) Contextual HyperNetwork architecture. z(i) is a fixed-length internal representationof the previously observed values in the data point x(i) taken from the base model. (b) Completearchitecture when a Contextual HyperNetwork is used to augment a predictive model pθO (xU |xO)to be able to make predictions for a new feature n, by initialising new parameters θn .
Figure 3: Contextual HyperNetwork applied to aP-VAE. The CHN generates parameters θn for anew decoder head.
Figure 4: Data splits when meta-traininga CHN. Meta-testing proceeds analo-gously, using features from an additionalmeta-test set of features, but using a con-stant set of observed values for each fea-ture on every meta-test set evaluation.
Figure 5: Performances (±1σ) of CHN and benchmarks on MovieLens-1M (left), Neuropathic Pain(middle) and E-learning (right) datasets for test features, with varying context size k. We reportmeta-test RMSE for MovieLens-1M (lower is better) and AUROC for the others (higher is better).
Figure 6:	MAML baseline performance comparison for {1, 2, 5, 10} fine-tuning epochs and with nofine-tuning. Left plot shows RMSE (lower is better), center and right plots show AUROC (higher isbetter).
Figure 7:	k-Nearest Neighbour Head Parameters baseline performance for k ∈ {1, 5, 10}. Context setsize here corresponds to the number of observed values used when determining the nearest neighbourheads.
Figure 8:	Comparing the predictive performance when training decoder new head parameters in aP-VAE on a range of context set sizes k, on the E-learning dataset (higher is better).
Figure 9: Performances (±1σ) of CHN and benchmarks on Neuropathic Pain (left) and E-learning(right) datasets for test features, with varying context size k . We report RMSE for both datasets, inconstrast to the main text where AUROC was reported.
Figure 10: Comparison of RMSE (lower is better) with and without feature metadata for both theCHN and mean head parameter baselines, across 5 random data splits.
