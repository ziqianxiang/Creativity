Figure 1: Illustration of the primal-dual optimization in DCRL. In the primal domain, We solve the adjustedprimal problem in (6) to obtain the policy ∏. Then in the dual domain, the ∏ is used to evaluate the state density.
Figure 2: Performance on the constrained reinforcement learning tasks on the MuJoCo (Todorov et al., 2012)benchmark. All results are averaged over 10 independent trials. The methods are expected to achieve highreward while keeping the constraint values close to the threshold.
Figure 3: Performance on the autonomous electrical vehicle routing benchmark. All results are averaged over10 independent trials. The methods are expected to keep close to the energy threshold (middle) and below thevehicle density threshold (right), while maximizing the reward (left).
Figure 4: Autonomous electric vehicle routing inManhattan: Control the electric vehicles to driveon the grey lines as roads and reach red nodes asgoals. Vehicles can be charged at the gold nodesas fast charging stations. The roads and fast charg-ing stations are from the real-world data (Bla-houdek et al., 2020). More experimental resultsare provided in the appendix B.4.
Figure 5: Illustration of the electrical motor control and drone application environments. (a) Electrical motorcontrol: Control the motor to follow the reference trajectories and avoid motor overheating. (b) Agriculturalpesticide spraying: Control the drones to spray pesticide over a farmland which is divided into five parts andeach requires different densities of pesticide.
Figure 6: Density curves of the motor's temperature When following sawtooth-wave trajectories using differentmethods. The temperature is relative to and also normalized using the environment temperature.
Figure 7: Visualization of the behavior of three methods in the safe electrical motor control task.
Figure 8: Density curves of the motor,s temperature when following asymmetric sine-wave trajectories usingdifferent methods, which are trained with sawtooth-wave trajectories. None of the methods have seen theasymmetric sine-wave trajectories during training. The temperature is relative to and also normalized usingthe environment temperature. DDPG almost perfectly follows the angular velocity trajectory but violates thedensity constraints on high-temperature states. RCPO slightly violates the density constraints. DCRL is able tofollow most part of the trajectories and completely satisfy the constraints.
Figure 9: Density curves of the motor's temperature using different methods trained and tested with staircase-wave trajectories. The temperature is relative to and also normalized using the environment temperature. Theunconstrained DDPG violates the temperature constraints while perfectly following the trajectory. RCPO isbetter than the unconstrained DDPG in terms of restricting the temperature, but its angular velocity trajectoryis not as stable as DDPG. DCRL can successfully control the temperature to meet the constraints.
Figure 10: Density curves of the motor's temperature When following staircase-wave trajectories using theRCPO method with different configurations of the cost function. It is still possible to achieve satisfactoryperformance (RCPO-V3) through extensive cost function tuning. However, though RCPO-V4 is only slightlydifferent from RCPO-V3 in terms of hyper-parameters, it completely fails to follow the reference trajectory.
Figure 11:	Results of the agricultural spraying problem. Left: Percentage of the entire area that satisfiesthe pesticide density requirement. Middle: Time consumption in steps. Whiskers in the left and middle plotsdenote confidence intervals. Right: visualization of the velocity densities using different methods.
Figure 12:	Results of the agricultural spraying problem with minimum pesticide density (0,1,1, 0,1) andmaximum density (0, 2, 2, 0, 2) from area 0 to 4. Left: Percentage of the entire area that satisfies the pesti-cide density requirement. Middle: Time consumption in steps. Whiskers in the left and middle plots denoteconfidence intervals. Right: visualization of the velocity densities using different methods.
Figure 13:	Results of the agricultural spraying problem with minimum pesticide density (0, 0, 1, 1, 0) andmaximum density (0, 0, 2, 2, 0) from area 0 to 4. Left: Percentage of the entire area that satisfies the pesti-cide density requirement. Middle: Time consumption in steps. Whiskers in the left and middle plots denoteconfidence intervals. Right: visualization of the velocity densities using different methods.
Figure 14: An example of the express delivery service company's transportation network with one ship centerand 29 service points. Left: The vans start from the service points (initial states) bounded by squares with equalprobability, then visit other service points following a transition probability (policy), and finally reach the shipcenter (goal). Right: The standard Q-Learning method finds a policy that drives the vans directly to the goalwithout visiting any other service points, which minimizes the cost (traveling distance). The sizes of gold nodesrepresent the state density.
Figure 15: Autonomous electric vehicle routing in Manhattan, New York City. The objective is to controlthe electric vehicles to drive on the grey lines as roads and reach red nodes as goals. The left and right figuresrepresent two scenarios where the goal sets are different. Vehicles can be charged at the gold nodes as fastcharging stations. All vehicles should maintain energy levels while avoiding congesting the charge stations.
Figure 16: Density curves of the autonomous EV routing in Manhattan, with target locations shown on the leftof Figure 15. The first row are the energy density and the second row are the vehicle density at each chargingstation using different algorithms (left to right: DCRL, RCPO, DDPG). Since there are too many chargingstations, those with density lower than half of the threshold for all the three methods are omitted. Only 15charging stations are kept in the second row. The error whiskers represent two times of the standard deviations.
Figure 17: Density curves of the autonomous EV routing in Manhattan, with target locations shown on theright of Figure 15. The first row are the energy density and the second row are the vehicle density at eachcharging station using different algorithms (left to right: DCRL, RCPO, DDPG). The error whiskers representtwo times of the standard deviations. Note that DDPG violates the density constraints on low-energy states.
Figure 18: Results on Safe Gym (Ray et al., 2019) comparing to CPO (Achiam et al., 2017) and PPO (Schul-man et al., 2017) with Lagrangian (PPO-L). The solid lines are the mean values of 10 independent runs. Thefirst row shows the average return and the second row shows the constraint values. The constraint values areexpected to be below the dashed lines that represent the thresholds.
Figure 19: Empirical analysis on kernel density estimation with different kernels and bandwidths.
