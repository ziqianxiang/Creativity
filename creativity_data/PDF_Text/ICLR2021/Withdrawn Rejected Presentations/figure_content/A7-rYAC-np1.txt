Figure 1: Example of complete and incomplete subtrees and two possible partial parses: Part A showsa sentence’s constituency tree generated by a self-attentive encoder-based constituency parser (Kitaev& Klein, 2018) using all of its words. The largest completed subtree for “believed" is shown in partB and the incomplete subtree generated till “believed" is shown in part C. Incomplete subtrees aregenerally much deeper than complete ones. In parts D and E, we can see two possible partial parsesgenerated by an incremental top-down parser (Roark, 2001) only using the words till "believed". Wesee that the POS tag assigned to "believed" is different in the two parses.
Figure 2: Steps for encoding subtrees.
Figure 3: The first plot shoWs the number of subjects for Which a given voxel is significantly predictedby punctuation (p ≤ 0.05). The others shoW the number of subjects for Which the difference in R2scores betWeen tWo feature groups is significant (p ≤ 0.05). Here, PU = Punctuation, NC = NodeCount, SS = Syntactic Surprisal, WF = Word Frequency, WL = Word Length, EF = All effort-basedmetrics, PD = POS and DEP Tags, CC = ConTreGE Comp, C = ConTreGE, INC = InConTreGE,BERT = BERT embeddings and ‘{,}’ indicates that these features Were concatenated in order to makethe predictions. ‘-’ indicates a hypothesis test for the difference in R2 scores betWeen the tWo featuregroups being larger than 0. The distinct information given by syntactic structure-based features ismore predictive of brain activity than that given by effort-based metrics. The semantic vectors arealso very predictive and many Well-predicted regions overlap With those that are predicted by syntax.
Figure 4: Region of Interest (ROI) analysis of the prediction performance. [Left] Language systemROIs by Fedorenko et al. (2010) from (3). [Right] Percentage of significantly predicted ROI voxels.
