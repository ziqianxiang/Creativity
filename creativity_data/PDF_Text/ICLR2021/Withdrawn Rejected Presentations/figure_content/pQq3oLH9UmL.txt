Figure 1: A recurrent attention model sequentially observes glimpses from an image and predictsa class label. At time t, the model actively observes a glimpse gt and its coordinates lt . Givengt and lt , the feed-forward module F extracts features ft , and the recurrent module R updatesa hidden state to ht . Using an updated hidden state ht , the linear classifier C predicts the classdistribution p(y |ht). At time t+ 1, the model assesses various candidate locations l before attendingan optimal one. It predicts p(y |g, l, ht) ahead of time and selects the candidate l that maximizesKL[p(y|g, l, ht)||p(y|ht)]. (a) The model predicts the content of g using a Partial VAE to computep(y|g, l, ht) without attending to the glimpse g. The normalizing flow-based encoder S predicts theapproximate posterior q(z∖ht), and the decoder D predicts an image X from a sample Z 〜q(z∖ht).
Figure 2: The classification accuracy as a function of time. A CNN and a soft attention modelobserve the entire image to predict the class label. EXPAC, RAM(Mnih et al. (2014)), and GRAMsequentially attends glimpses in the image and predict the class label. EXPAC and RAM neverobserve a complete image and attend the first glimpse at a random location. GRAM observes a gistof an input at the beginning and predicts glimpse locations from t = 0. (a) MNIST (b) SVHN (c)CIFAR-10 (d) CIFAR-100 (e) CINIC-10.
Figure 3: The classification accuracy as a function oftime. iEXPAC interpolates EIG maps to findoptimal glimpses that may overlap. (a) SVHN (b) CIFAR-10 (c) CIFAR-100 (d) CINIC-10.
Figure 4: The classification accuracy ofa CNN as a function of the area occluded. A CNN classifiesimages with the glimpses attended by various hard attention models occluded. (a) CIFAR-10 (b)CIFAR-100 (c) CINIC-10.
Figure 5: Visualization of the predictions from the Partial VAE. In each panel, from left to the right:time step, glimpses observed until time t, eight samples of x. The content in X on the observedlocations is consistent with the glimpses.
Figure 6: Visualization of the EIG maps and the glimpses observed by iEXPAC on CIFAR-10 im-ages. The top row shows the entire image and the EI G maps for time t = 1 to 6. The bottom rowshows glimpses attended by iEXPAC. The model observes the first glimpse at a random location.
Figure 7: The classification accuracy as a function of time. We compare performance of EXPACwith and without using normalizing flows. (a) CIFAR-10 (b) CIFAR-100 (c) CINIC-10.
Figure 8:	Classification accuracy as afunction oftime. We test various generative models to predictthe image content. (a) MNIST (b) SVHN (c) CIFAR-10.
Figure 9:	Classification accuracy of the hard attention models as a function of the area covered. (a)MNIST (b) SVHN (C) CIFAR-10 (d) CIFAR-100 (e) CINIC-10.
Figure 10:	The classification accuracy of a CNN as a function of the area occluded. A CNN clas-sifies images with the glimpses attended by various hard attention models occluded. (a) MNIST (b)SVHN.
Figure 11:	The classification accuracy as a function of time. We compare performance of EXPACwith and without using normalizing flows. (a) MNIST (b) SVHN.
