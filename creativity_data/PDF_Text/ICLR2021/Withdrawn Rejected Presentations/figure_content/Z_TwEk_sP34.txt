Figure 1: Illustration of the key variables.
Figure 2: The x-axis is the t ∈ [0, 1] that controls how much the source model deviates from thetarget model. There are in total 7 quantities reported, placed under 4 y-axes. Specifically, τ1 , τ2, andthe normalized cross adversarial loss α are plotted as green curves with green y-axis; the upper boundin theorem 2 on the transferred gradients difference is shown as blue curves with blue y-axis; the truetransferred gradients difference is shown as red curves with red y-axis; the upper bound in theorem 3on the transferred loss is shown as magenta curves with magenta y-axis; the true transferred loss isshown as black curves with black y-axis.
Figure 3: (left) correlation between the adversarial transferability and knowledge trransferability inimage domain (All values normalized to [0,1]). (right) adversarial transferability and knowledgetransferability in NLP domain.
Figure 4: Left: Emprically confirmed taskonomy prediction of task categories (Zamir et al., 2018).
Figure 5: We also quantitatively compare our prediction with the Taskonomy (Zamir et al., 2018)prediction when different number of categories is enforced. We find our prediction is similar withtheirs with n ≥ 3.
