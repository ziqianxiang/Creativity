Figure 1: We trained a GAN using our algorithm on 0-1 MNIST for 30,000 iterations (with k = 1 discriminatorsteps and acceptance rate e-1/T = 1∕5). We repeated this experiment 22 times for our algorithm and 13 times forGDA. Shown here are the images generated from one of these runs at various iterations for our algorithm (right)and GDA (left) (see also Appendix F.3 for images from other runs).
Figure 2: Our algorithm (bottom right), unrolled GANs with k = 6 unrolling steps (top right), and GDA withk = 1 (top left) and k = 6 discriminator steps (bottom left). Each algorithm was trained on a 4-Gaussianmixture for 1500 iterations. Our algorithm used k = 6 discriminator steps and acceptance rate e-1/T = 1∕4.
Figure 3: GAN trained using our algorithm (with k = 1 discriminator steps and acceptance rate e-1/T = 1∕2)and GDA on CIFAR-10 for 50,000 iterations. The images generated from the resulting generator for both ouralgorithm (middle) and GDA (left). Over 9 runs, our algorithm achieves a very similar minimum FID score(33.8) compared to GDA (33.0), and a better average FID score over 9 runs (mean μ = 35.6, std. dev. σ = 1.1)compared to GDA (μ = 53.8, σ = 53.9). Images are shown from one run each; see Appendix F.2 for full results.
Figure 4: We ran our algorithm (with k = 1 discriminator steps and acceptance rate e-T = 1) on the fullMNIST dataset for 39,000 iterations, and then plotted images generated from the resulting generator. Werepeated this simulation five times; the generated images from each of the five runs are shown here.
Figure 5:	GAN trained using our algorithm (with k = 1 discriminator steps and acceptance ratee-1∕τ = 1∕2) and GDA. We repeated this simulation nine times; We display here images generated fromthe resulting generator for each of the nine runs of GDA (top) and our algorithm (bottom). The final FIDscores at 50,000 iterations for each of the nine runs (corresponding to the images above from left to rightand then top to bottom) Were {35.6, 36.3, 33.8, 35.2, 34.5, 36.7, 34.9, 36.9, 36.6} for our algorithm and{33.0, 197.1, 34.3, 34.3, 33.8, 37.0, 45.3, 34.7, 34.7} for GDA.
Figure 6:	Plots of FID scores for GANs trained using our algorithm (with k = 1 discriminator steps andacceptance rate e-1/T = 1∕2) and GDA on CIFAR-10 for 50,000 iterations. We repeated this simulation ninetimes, and plotted the FID scores for our algorithm (dashed blue) and GDA (solid red).
Figure 7: We trained our algorithm on the 0-1 MNIST dataset for 30,000 iterations (with k = 1 discriminatorsteps and acceptance rate e-T = ∣). We repeated this experiment five times. For one of the runs, We plotted25 generated images produced by the generator at various iterations. We also plotted a moving average of thecomputed loss function values, averaged over a window size of 50.
Figure 8: We show the images generated at the 30,000’th iteration for all 5 runs of the simulation in Figure 7,together with a plot of their computed loss function values. Recall from the caption of Figure 7 that we trainedour algorithm on the 0-1 MNIST dataset for 30,000 iterations (with k = 1 discriminator steps and acceptancerate e-T = ∣). We repeated this experiment five times. For one of the runs, We plotted 25 generated imagesproduced by the generator at various iterations. We also plotted a moving average of the computed loss functionvalues, averaged over a window size of 50.
Figure 9: Images generated at the 1000’th iteration of the 13 runs of the GDA simulation mentioned in Figure 1.
Figure 10: Images generated at the 1000'th iteration of each of the 22 runs of our algorithm for the simulationmentioned in in Figure 1.
Figure 11: In this simulation We used a randomized accept/reject rule, with a decreasing temperature schedule.
Figure 12: Images generated at the 39,000’th iteration of each of the 5 runs of our algorithm for the simulation___1mentioned in Figure 11 with a randomized acceptance rule with a temperature schedule of e Ti_______14+e(i∕20000)2GDAFigure 13: The generated points at the 1500’th iteration for all 9 runs of the GDA algorithm with k = 1discriminator step, for the simulation mentioned in Figure 2. At the 1500’th iteration, GDA had learned exactlyone mode for each of the 9 runs.
Figure 13: The generated points at the 1500’th iteration for all 9 runs of the GDA algorithm with k = 1discriminator step, for the simulation mentioned in Figure 2. At the 1500’th iteration, GDA had learned exactlyone mode for each of the 9 runs.
Figure 16: The generated points at the 1500’th iteration for all 19 runs of our algorithm, for the simulationmentioned in Figure 2. Our algorithm used k = 6 discriminator steps and an acceptance rate hyperparameter ofT = 1. By the 1500'th iteration, our algorithm seems to have learned all four modes 68% of the runs, threemodes 26% of the runs, and two modes 5% of the runs.
