Figure 1: (a) Intuition of DRL under domain shift, where Xs and Ys represent the source labeleddata, and Xt represents the target unlabeled data, ypred is the predictor’s probabilistic labels and theyfake is the adversary’s proposed probabilistic labels. (b) Architecture for end-to-end training of theDRL framework without class regularization. It is an instantiation of (a) using neural networks. Theexpected target loss cannot be evaluated due to lack of target labels in the UDA setting. Instead, weneed to compute the gradients directly for training the networks. We present the details in Sec. 2.2.
Figure 2: The self-training process ofDRST, where Xt 1 and Xt2 represent the portion of target datathat is pseudo-labeled with Yt01 and Yt02 . We use DRL model’s prediction as pseudo-labels and itsmodel confidence as the criterion for choosing pseudo-labeled data from the target domain.
Figure 3: (a)- (b) Accuracy and Brier score of self-training on VisDA2017 with 5 random seeds.
Figure 4: Model attention visualized using Grad-Cam (Selvaraju et al., 2017). We also show thepredicted labels by different methods. Our method captures the shape features of the image better.
Figure 5: (a) Density ratios and example target images for category “Train” in VisDA. Larger densityratio (Ps(x)/Pt(x)) indicates more certain prediction. DRL give more cerntain prediction on “train”that is better represented in the source domain, which on the right hand side. (b) Accuracy and brierscore using DRL on VisDA. DRL significantly improves the source model along the training.
Figure 6: Accuracy and Brier Score of DRL on Office31 and Office-Home. DRL improves source-only by a large margin.
Figure 7: Reliability diagrams with respect to source-only, temperature scaling (TS) and DRL. Thedata is separated into 20 bins with different interval lengths. The closer the curve is to the dashline, the more calibrated the uncertainty is. DRL is able to achieve more calibrated results, usuallyconservative confidence, while the other methods always tend to generate over-confident predictions.
Figure 8: TSNE visualization of the learned classifier using different methods. Using DRST, theclasses are well-separated.
Figure 9: Comparison of DRL and DRST of misclassification entropy on different datasets.
Figure 10: Model attention visualized using Grad-Cam (Selvaraju et al., 2017). Our method canalso capture the domain knowledge well. For example, the first row input image contains a giraffeand a car. However, giraffe is not a existing label for VisDA2017. While CBST and CRST capturesthe wrong information, DRST is able to correctly capture the domain information.
Figure 11: Additional examples for density ratio estimation for different categories. We can observethat data less well-represented in the source data has much lower density ratio. This shows that ourlearned density ratio is a good measure of the level of representation of data in source and targetdomains.
Figure 12: (a) Source and target data points are drawn from two Gaussian distributions. Solid line:source and dashed line: target. The underlying true decision boundary for the binary classes is thesame between the two domains. (b)-(c) Prediction with density ratios from low and high densityestimation likelihoods. With more accurate density estimation, the RBA predictor gives overlyconservative predictions on the target domain. The colormap is the confidence P (“1”|x). (d) Withlarger likelihood in density ratio estimation, the target log loss becomes worse.
Figure 13: Additional Office31 results on DRL compared with source-only, which is a complementfor Figure 6.
Figure 14: Additional Office31 results on reliability plots, which is a complement for Figure 7. DRLis compared with source-only and temperature scaling.
