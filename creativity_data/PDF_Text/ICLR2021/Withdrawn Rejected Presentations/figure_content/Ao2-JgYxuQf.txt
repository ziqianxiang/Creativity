Figure 1: Illustration of Active Tuning principle over two consecutive world time steps. fM refersto the forward pass of the base model. xt , xt-1 etc. are the recent potentially defective signalobservations, whereas xt, xt-1 etc. are the respective predictions (outputs of the model's forwardfunction fM). R denotes the length of the retrospective tuning horizon, that is, the number of timesteps the prediction error is projected into the past using BPTT. σt-R refers to the latent (hidden)state of M at the beginning of the tuning horizon, which essentially seeds the unfolding predictionsequence (black lines). σt-R is actively optimized based on the back-projected prediction errorgradient (red lines).
Figure 2: Visual comparison of regular inference (orange) vs. Active Tuning (light blue) on an MSOexample with strong noise (noise ratio 1.0) using a noise-unaware LSTM.
Figure 3: Exemplary comparison of regular inference (orange) vs. Active Tuning (light blue) on thedouble pendulum’s end-effector trajectory; the black dot denotes the start position. Here, the secondstrongest noise condition (0.5) is shown, using a 0.05-noise LSTM for inference and Active Tuning.
Figure 4: Exemplary comparison of regular inference (orange) vs. Active Tuning (light blue) onwave examples with strong noise (1.0) using DISTANA trained without noise. The four top rowsvisualize ground truth, noisy observations (network input), network output without, and networkoutput with Active Tuning. The plot below shows the wave activities at the center position.
Figure 5: The double pendulum used for data generation of the second experiment and a resultingnonlinear trajectory of the pendulum’s end-effector.
Figure 6: Four consecutive snapshots (from left to right, with distance of 50 time steps ) of thewave propagating through a large 40×40 grid comparing regular inference and Active Tuning on anoise-unaware network (0.0).
