Figure 1: While each language repre-sents a bicycle with a different word,the underlying visual representations re-mains consistent. A bicycle has simi-lar appearance in the UK, France, Japanand India. We leverage this naturalproperty to learn models of machinetranslation across multiple languageswithout paired training corpora.
Figure 2: Our model learns an aligned embedding space for language translation by leveraging atransitive relation through vision. Cross-sentence similarity Î²ij is estimated by the path through animage collection. See Section 3 for details.
Figure 3:	We evaluate our transla-tions at the sentence-level. Our ap-proach outperforms several unsuper-vised translation baselines. Whileunsupervised approaches are still nomatch for fully supervised methods,our approach uses significantly lesssupervision.
Figure 4:	We evaluate our transla-tions at the sentence-level with ahuman-generated test set. Fluentspeakers for 11 of the languagesmanually annotated translations inthe test set. Our approach outper-forms several unsupervised transla-tion baselines on this test set as well.
Figure 5:	We also evaluate word-level translation. Although our approach is trained on sentence-level similarity, the word embeddings also learn to provide strong word-level translation. The resultscan be further refined with Procrustes.
Figure 6:	Qualitative results. We show two examples of positive matches (top) and two examples ofnegative matches (bottom). We refer the reader to Section 5.4 for further analysis.
Figure 7:	We show sentence-leveltranslation accuracy by query-targetlanguage pair. In the figure, thelanguages are sorted by family (Ro-mance, Baltic, etc.). The block-diagonal structure shows that lan-guages from the same family areeasier to translate between. We alsofind that language isolates in ourdataset perform worse overall (e.g.
Figure 8:	Word-level similarity across languages. See Appendix A.3 for more information.
Figure 9:	Asymmetry in the direction of the sentence-level translation. See Appendix A.3.
Figure 10:	Clustering in the representation space. When trained without visual alignment the clustersare language-specific, and when trained with visual correspondence the clusters have a semanticmeaning.
Figure 11:	Translation by generation. See Appendix A.5 for more information.
