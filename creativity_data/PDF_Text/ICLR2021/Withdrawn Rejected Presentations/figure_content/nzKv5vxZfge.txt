Figure 1: An example of explaining the scene graph classification. (a) An input image with boundingboxes; (b) The scene graph predicted as Surfing; (c) Explanations of SA, GNNExplainer, and ourCausal Screening.
Figure 2: An illustration of our Causal Screening for obtain the causal attribution.
Figure 3: Accuracy curves of explanation methods over selection ratios. Best viewed in color.
Figure 4: Selected explanations for each explanation methods, where the top 20% edges arehighlighted. Note that some edges have the same nodes. In Visual Genome, the objects involved inthe edges are blurred based on the edge attributions; meanwhile, in Mutagenicity, a darker color ofa bond indicates the larger attribution for the prediction. Best viewed in color.
Figure 5: Distribution of ICE values.
