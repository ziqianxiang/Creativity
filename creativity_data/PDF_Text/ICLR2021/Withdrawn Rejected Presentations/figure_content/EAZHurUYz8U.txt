Figure 1: Overview of OPT.
Figure 2: Unrolled orthogonalization.
Figure 3: OPT& S-OPTmatrix is still able to cover all the neuron dimensions. Intuitively, S-OPT aims to approximate theorthogonal transformation of all the neuron dimensions With small orthogonal transformations ofrandom subsets of the neuron dimensions. The approximation Will be more accurate if the procedureis randomized over many times. Fig. 2 compares the size of the orthogonal matrix in OPT and S-OPT.
Figure 4: Loss landscape visualization.
Figure 5: Training dynamics on CIFAR-100. Left: HyPersPheriCalenergy vs. iteration. Right: Testing error vs. iteration.
Figure 6: High-quality rendered loss landscapes of standard training and OPT.
Figure 7: Comparison of loss landscapes between standard training and OPT (full results of Fig. 4(b) in themain paper). Top row: loss landscape visualization with Cartesian coordinate system; Bottom row: loss contourvisualization.
Figure 8: Comparison of testing error landscapes between standard training and OPT. Top row: high-qualityrendered testing error landscape visualization with lighting effects; Bottom row: testing error landscapevisualization with Cartesian coordinate system.
Figure 9: Comparison of loss landscapes between standard training and OPT on CIFAR-100 (CNN-9). Top row:loss landscape visualization with Cartesian coordinate system; Bottom row: loss contour visualization.
Figure 10: Comparison of testing error landscapes between standard training and OPT on CIFAR-100 (CNN-9).
Figure 11: Comparison of loss landscapes between standard training and OPT on CIFAR-10 (CNN-6). Top row:loss landscape visualization with Cartesian coordinate system; Bottom row: loss contour visualization.
Figure 12: Comparison of testing error landscapes between standard training and OPT on CIFAR-10 (CNN-6).
Figure 13: High-quality rendered loss landscapes of standard training and OPT.
Figure 14: Comparison of loss landscapes between standard training and OPT (full results of Fig. 4(a) in themain paper). Top row: loss landscape visualization with Cartesian coordinate system; Bottom row: loss contourvisualization.
Figure 15: Comparison of testing error landscapes between standard training and OPT. Top row: high-qualityrendered testing error landscape visualization with lighting effects; Bottom row: testing error landscapevisualization with Cartesian coordinate system.
Figure 16: Comparison of loss landscapes between standard training and OPT on CIFAR-100 (CNN-9). Toprow: loss landscape visualization with Cartesian coordinate system; Bottom row: loss contour visualization.
Figure 17: Comparison of testing error landscapes between standard training and OPT on CIFAR-100 (CNN-9).
Figure 18: Comparison of loss landscapes between standard training and OPT on CIFAR-10 (CNN-6). Top row:loss landscape visualization with Cartesian coordinate system; Bottom row: loss contour visualization.
Figure 19: Comparison of testing error landscapes between standard training and OPT on CIFAR-10 (CNN-6).
Figure 20: Comparison between the block-shared matrix Rs and the unconstrained block matrix Ru.
Figure 21: Training dynamics of hyperspherical energy in each layer of CNN-6. We average results with 10 runs.
