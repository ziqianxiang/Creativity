Figure 1: Two example chest radio-graph images with different abnormalitycategories, along with sentences fromtheir paired textual report and exampleviews indicative of their characteristics.
Figure 2: Overview of our ConVIRT framework. The blue and green shades represent the imageand text encoding pipelines, respectively. Our method relies on maximizing the agreement betweenthe true image-text representation pairs with bidirectional losses '(V→U) and '(U→V).
Figure 3: t-SNE visualizations of encoded imagerepresentations from different pretraining methods.
Figure 4: Saliency maps on sampled images for 4 abnormality categories in the CheXpert dataset.
Figure 5: (a) shows pretraining validation loss at different epochs; (b)-(d) shows correlation betweenthe pretraining loss and the performance of three end tasks. For (a) the x-axis shows the trainingepoch number, and for (b)-(d) the x-axis shows the negative value of the pretraining loss (i.e., -L)on a held-out validation set.
