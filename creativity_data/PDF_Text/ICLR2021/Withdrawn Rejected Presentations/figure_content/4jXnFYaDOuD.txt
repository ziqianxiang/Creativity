Figure 1: Overview of the proposed model IMA, including the multimodal autoencoder, the impor-tance networks and the main loss functions to be optimizedXiL(2)localLa)ljrnτLatent Representation (Z)LgZohAL⑴recL(2)recDecoder Networkshas also applied other independence criterion, such as MMD (Maximum Mean Discrepancies)which act as auxiliary losses in a variational framework (Louizos et al., 2015). Assuming the latent
Figure 2:	t-SNE visualizations of importance network representations learnt by the model on multimodalMNIST-TIDIGITS. Sub-figures (a) and (c) shows the digit clusters in the representations. The grey clustercorresponds to uncorrelated noise. In sub-figures (b) and (d) uncorrelated noise is in red; otherwise in blue.
Figure 3:	Word level importances learnt by the IMA model as observed on five example IEMOCAP utterances.
Figure 4: t-SNE visualizations of unimodal representations learnt by the IMA autoencoder on MNIST-TIDIGITS. Colors denote digit labels (0:Red; 1:Green; 2:Blue; 3:Purple; 4:Orange; 5:Cyan; 6:Yellow; 7:Ma-genta; 8:Olive; 9:Black; Gray:Uncorrelated Noise). Sub-figures (c) and (d) show the region of image noise inred, superimposed on the image and multimodal representation spaces respectively.
Figure 5: Visualization of different unimodal representations learnt by the IMA model on IEMOCAP. Fig-ure 5(a) shows the unimodal word representations. Figure 5(b) shows the same representations colored withrespective word importances. Figure 5(c) and (d) show the acoustic representations colored by emotion andimportances respectively. Note that the colors blue, red and yellow respectively denote the happy, angry andsad emotions. The regions learned by IMA as important are in blue; non-important are in red.
Figure 6: Precision, Recall and F1 score curves for the importance-based autoencoder trained on the MNIST-TIDIGITS dataset. We have selected only the Positive category (positive indicates presence of noise) for re-porting metrics.
