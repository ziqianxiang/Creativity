Figure 1: Visualizing training trajectories: We visualize the distribution of the real (green dots) andfake (blue dots) over the course of the vanilla GAN (top row) and our method (the second row andbelow). The background color indicates the prediction heatmap of the discriminator with blue beingfake and warm yellow being real. Once the vanilla GAN falls into mode collapse (top row), it ends uposcillating between the two modes without convergence. Moreover, the discriminator’s prediction atpoint X oscillates, indicating catastrophic forgetting in the discriminator. With our DMAT procedure,a new discriminator is dynamically spawned during training. The additional discriminator effectivelylearns the forgotten mode, guiding the GAN optimization toward convergence.
Figure 2: Investigating the forgetting-collapse interplay: We investigate our hypothesis that catastrophicforgetting is associated with mode collapse. To this end, on the left pane, we plot the magnitude of mode collapseby counting the number of modes produced by the generator. On the right pane, we assess the quality of thediscriminator features by plotting the accuracy of linear classifier on top of the discriminator features at eachepoch. In the original DCGAN model (OneD), the coverage of modes and the quality of discriminator featuresare both low and decreasing. In particular, the test accuracy from the discriminator’s features drops almostto randomly initialized weights (shown as control). On the other hand, adding DMAT (MultiD) dramaticallyimproves both mode coverage and the discriminator test accuracy.
