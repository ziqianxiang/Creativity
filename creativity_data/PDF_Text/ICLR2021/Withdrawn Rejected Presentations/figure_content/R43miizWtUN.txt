Figure 1:	(a,b,c,e): Accuracy of different model types for GCN, GIN and MLP onENZYMES/DD/PROTEINS/IMDB-BINARY; (f,g): Accuracy of different model types for GCN,GIN and MLP on MNIST/CIFAR10; (d): Training time (per epoch) of different model type for GCNon PROTEINS; (h): Number of parameters required for GCN on PROTEINS.
Figure 2:	(a,b,c,d): Accuracy of different model types for GCN/GIN/MLP onCORA/CITESEER/PUBMED/ogbn-arxiv datasets; (e): Mean Absolute Error of differentmodel types for GCN/GIN/GraphSage/PNA/MLP on ZINC dataset; (f,g,h): Accuracy vs. number ofparameters plot on a logarithmic x-axis on (f) ogbn-arxiv for GCN models with different sparsifiersand (g,h) on CITESEER/PUBMED for vanilla and Expander GCN with same parameter budget.
Figure 3: Train loss (cross-entropy) converging behaviour of different model type for GCN onProteins dataset.
Figure 4: Illustration of Expander MPNNs. The left part is the Aggregation or graph propagation stepand the right part is theUpdate step. The red lines on the left part represents preserved connections inMLPs sampled by expander sparsifier.
