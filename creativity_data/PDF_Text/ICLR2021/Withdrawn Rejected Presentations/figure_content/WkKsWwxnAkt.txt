Figure 1: Key differences between the baseline S2ConvSCN and proposed robust version. Unlikethe baseline S2ConvSCN, robust version learns in a truly unsupervised (label-free) manner. The lastregularization in the self-expressive layer stands for symmetric loss introduced in Equation (10).
Figure 2: The figure illustrates the change of accuracy and loss over epochs for the original DSCNetmodel with MSE in the self-expressive layer. Model was trained and tested on a full COIL20 datasetwith `2 regularization of representation matrix C (see Equation (6)). It can be seen that accuracy isoscillating even though the loss is decreasing. Thus, selecting the model requires access to groundtruth labels and makes an unfair practice.
Figure 3: Self-supervised robust (and baseline) S2ConvSCN architecture showing all layers andmodules. Encoder and decoder layers are denoted by H(0) to H(L) . Together, flattened encoderfeatures Z and representation matrix weights C construct self-expression layer ZC where optimalC is learned. Spectral clustering (SC) module receives affinity matrix A as an input. Pseudo-labelsfrom SC module serve as target labels for the FC-softmax classifier. The matrix Q is used as aregularizer for the representation matrix C to learn a better representation.
Figure 4: The figure illustrates the change of accuracy and loss over epochs for a Robust DSCNetmodel with CIM in the self-expressive model. In comparison with Figure 2, it can be seen thatRobust DSCNet can use the change in loss as CIM prevents overfitting.
