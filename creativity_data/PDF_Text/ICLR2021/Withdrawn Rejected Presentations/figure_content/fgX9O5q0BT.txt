Figure 1: Noise injection significantly improves the detail quality of generated images. From leftto right, we inject extra noise to the generator layer by layer. We can see that hair quality is clearlyimproved. Varying the injected noise and visualizing the standard deviation over 100 different seeds,we can find that the detail information such as hair, parts of background, and silhouettes are mostinvolved, while the global information such as identity and pose is less affected.
Figure 2: Illustration of the skeleton set and representative pair. The blue curve in (a) is the skeleton.
Figure 3: Synthesized images of different StyleGAN2-based models.
Figure 4: Comparison of FID curves. All curves are terminated by the optimal FIDs in 25M trainingiterations.
Figure 5: Image synthesis on CIFAR-10 and LSUN cats.
Figure 6: Generator architectures of StyleGAN2 based models. (a) The generator of bald StyleGAN2.
Figure 7: Generator architecture of DCGAN based models. (a) The generator of DCGAN. (b) Thegenerator ofDCGAN + Additive Noise. (c) The generator ofDCGAN + FR.
Figure 8: Manually collected 20 images for GAN inversion.
Figure 9: Projected Images to the intermediate latent spaces of StyleGAN2 based models.
