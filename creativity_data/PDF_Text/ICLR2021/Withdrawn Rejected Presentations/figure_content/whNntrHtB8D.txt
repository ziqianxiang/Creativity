Figure 1: Categorization of memory-based methods on Task-free Continual Learning. Reservoirsampling and Sampling from Memory are the ways that Experience Replay (ER) uses to construct andreplay memory respectively. In the recent line of works, Gradient based Sample Selection (GSS) andHindsight Anchor Learning (HAL) explored ways to construct memory, while Maximally InterferingRetrieval (MIR) focused on replay strategy. Our method, Gradient-based Memory Editing (GMED)falls under the former category but provides a new angle to memory construction.
Figure 2: Overview of the (a) forgetting estimation, (b) example editing, (c) model updating in theproposed GMED method. See detailed formulations for forgetting estimation and example editing atSection 4.3.
Figure 3: Performance of ER and GMED-ER in different memory sizes. For mini-ImageNet dataset,we use memory sizes of 1,000, 5,000, 10,000, and 20,000 examples; for other datasets, we use 100,200, 500, and 1,000.
Figure 4: A t-SNE visualization of the editingperformed on data examples. We use labelsfrom the first two tasks in Split MNIST.
Figure 5: Visualization of the editing on exam-ples in Split MNIST. The first two rows showexamples before and after editing, and the thirdrow shows the differences.
