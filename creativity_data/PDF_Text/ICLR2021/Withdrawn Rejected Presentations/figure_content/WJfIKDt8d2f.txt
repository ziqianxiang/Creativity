Figure 1: Example images of quality degradation. Five levels of quality reduction are simulated usingthe blur, noise, and distortion effects (Left) and each lighter and darker direction per channel (Right).
Figure 2: The relationship between MA and different levels of perturbation: Greater imagedegradations lead to higher loss of mean accuracy.
Figure 3: The relationship between FID and MA percentage difference. GD/GL denote G channel indarker/lighter direction, and VD/VL denote V channel in darker/lighter direction.
Figure 4: Unseen perturbation examples in our experiments. We use “snow”, “frost”, “fog” (left toright; first row), and “motion blur”, “zoom blur”, “pixelate”, “jpeg compression” (left to right; secondrow) from the corruptions in ImageNet-C (Hendrycks & Dietterich, 2019).
Figure 5: MA improvement with our method compared to the baseline. Our method achieve greatimprovement on extreme cases for channel-level factors and unseen weather conditions.
Figure 6: Saliency map samples with baseline method and our method, where the model tests onthe different combinations of perturbations. Different columns show different combinations ofperturbations. The first row shows the original image, the second row shows the perturbed imagewith the chosen effects, the third row is the saliency map of baseline model, and the fourth row is thesaliency map of our method. It can be seen that, with our method, the network can better focus on theimportant areas (e.g., the road in front) instead of random areas on the perturbed images, as with thebaseline model.
