Figure 1: (a) Average distribution of superpixel size averaged across MNIST training dataset fordifferent superpixel representation: none (left), WaveMesh (center), and SLIC (right). In each panel,an insert shows the graph representation of a single sample for illustration. Size of a node in the graphis proportional to the superpixel size. SLIC superpixels are not cubic yet the x-axis binning is chosento match other plots. (b) Boxplots of the # superpixels per image for CIFAR-10 training dataset.
Figure 2: Filtering images in wavelet space generates non-uniform superpixel meshes that are thenrepresented as embedded graphs. The leftmost images are preprocessed with the method described insection 3 with a threshold value equal to five times the theoretical value. Natural images are from thePascal dataset (Everingham et al., 2010), and the medical image is from the NLST dataset.
Figure 3: Illustration of the wavelet-based quadtree compression algorithm for an 8×8 image, alongwith the resulting adapted grid. Starting from the coarsest possible wavelet grid that contains justone superpixel, the algorithm adapts the grid by recursively splitting it. If the wavelet coefficientcorresponding to a region is tagged (denoted by blue color), then that region is split into 2×2superpixels.
Figure 4: Illustration of WavePool from wavelet quadtree representation. Leaf nodes (2×2 superpix-els) are recursively pooled. In the lower panel, dashed squares and lines correspond to nodes andedges in the region adjacency graph (RAG) representation of the superpixel mesh, respectively.
Figure 5: Illustration of WavePool versus graclus-based pooling on a regular superpixel grid.
Figure 6: Model architecture. WaveMesh superpixel graph of an example image (digit 4) fromMNIST dataset passing through SplineCNN with WavePool. Nodes represent superpixel centers.
Figure 7: Mean test accuracy versus mean number of superpixels for all three datasets for bothnetwork configuration. The plot compares the accuracy of WaveMesh and WavePool combinationwith SLIC and Graclus combination.
Figure 8: WaveMesh superpixels represented by region adjacency graphs (RAG). (a) Images fromthe CIFAR-10 dataset. (b) RAGs representing WaveMesh superpixels obtained using the theoreticalthreshold T for images shown in (a). (c) RAGs representing WaveMesh superpixels obtained using athreshold equal to 2T . Size of nodes in the graph are proportional to the corresponding superpixelsize.
Figure 9: MNIST error analysis: The top row corresponds to experiments on WaveMesh superpixelswith WavePool in config 2. The bottom row corresponds to experiments on SLIC superpixels withGraclus pooling in config 2. Left quadrant shows the confusion matrix and the right quadrant showsthe error rate matrix averaged over all runs of an experiment. Experiment numbers from Table 1 areindicated below each matrix.
Figure 10: FashionMNIST error analysis: The top row corresponds to experiments on WaveMeshsuperpixels with WavePool in config 2. The bottom row corresponds to experiments on SLICsuperpixels with Graclus pooling in config 2. Left quadrant shows the confusion matrix and the rightquadrant shows the error rate matrix averaged over all runs of an experiment. Experiment numbersfrom Table 2 are indicated below each matrix.
Figure 11: Error rate matrix for experiment 4 from Table 2. Comparing this matrix with that ofexperiment 8 from Figure 10, we observe that many more images of pullover and coat are gettingmisclassified as shirt in this experiment when compared to experiment 8.
Figure 12: Left: Chest X-ray image of size 1024×1024. Center: WaveMesh superpixel mesh. Right:Wavelet filtered chest X-ray image.
