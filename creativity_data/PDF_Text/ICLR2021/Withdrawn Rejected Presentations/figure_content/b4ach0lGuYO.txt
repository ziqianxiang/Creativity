Figure 1: AUtoencoder vs. I3AD method (Ours). AUtoencoder fails to reconstruct the high-frequency texture of “carpet” and yields a large residual map. Ours utilizes the residual map asan inpainting mask and iteratively updates the reconstructed image and the residual map.
Figure 2: Model overview of iterative image inpainting method for AD (I3AD). At the training step,We solve a general image inpainting task in normal datasets. At the testing step, a generator receivestest images with an adaptive mask and only reconstructs masked regions. This adaptive mask isupdated from previous reconstruction results during iterations.
Figure 3: First row: Normal samples of tile, carpet, transistor, screw, wood, and zipper in MVTecADdataset; Second row: anomalous samples from the aforementioned dataset categories; Third row:Anomaly map by L2 autoencoder (Bergmann et al., 2019); Fourth row: our proposed anomaly mapby our I3AD method. Ground truth is represented by red contour, and each estimated anomaly scoreis highlighted by green.
Figure 4: AUC change of different patch-size mask initialization during iteration. Both L2 andSSIM anomaly scores are computed. (a) average AUC result of each anomaly score, (b) AUC resultmeasured by L2 (c) AUC result measured by SSIMMask generation threshold We determine mask generation threshold u naively from the L1 re-construction levels on training datasets. Figure 5 shows the AUC score on different threshold se-lection. Even though the best parameters are unknown and inaccessible from training datasets, wecould find a threshold parameter naively. Moreover, since this fitting does not perform equally acrossdata categories, mask generation has room to be optimized in semi-supervised approach.
Figure 5: AUC change of different threshold U for mask generationIteration speed We measure the iteration speed for AnoGAN, Iterative Projection, and our I3AD.
Figure 6: Mask initialization in test iteration step. Images are masked by four masks that includesXbyX patched boxes.
Figure 7: Other qualitative results18Under review as a conference paper at ICLR 2021HArchitecture Comparis onBase ArchitectureModel NameAutoEncoderSSIM-AUtoEnCoderDAEVAEGradient anomaly scores*ceVAE (context-encoding)AnoGANADGANAttention U-NetImageAVIDSkip-GANomalyAEGAN / VAEGAN*
Figure 8: Architecture comparison19Under review as a conference paper at ICLR 2021We summarize the base model architecture used in recent reconstruction based approach. This isnot an all-inclusive list and several studies proposed additional losses and modules with differentanomaly score measures in the above base architectures.
