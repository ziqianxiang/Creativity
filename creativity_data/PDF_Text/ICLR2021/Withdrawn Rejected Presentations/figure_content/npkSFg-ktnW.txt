Figure 1: Different methods for empowering autoencoder generative abilitythe representation in latent space struggles with the problems of hard to control and inferior synthesisquality. We propose a different solution to empower precise attribute controllable synthesis ability onautoencoders: Disentangled Exploration Autoencoder (DEAE).
Figure 2: Controllable mining novel background and font color by interpolation in latent space.
Figure 3: Enlarging explainable region by interpolation and regularizationTo solve the problem of non-convex latent space, we define a perfect disentanglement property inlatent dz dimension space of the autoencoder. For encoder fθ* ,if We specifically modify one attributevalue of image X and get x, and after encoding We get latent code Z = fθ* (x) and Z = fθ* (X), thenthe difference between Z and Z should be zero for all latent dimensions except those that representthe modified attribute. Similarly, for decoder gφ*, the change in latent space should only influencethe corresponding attribute expression in image space. If both the encoder and decoder satisfy therequirements, We claim the autoencoder has a perfect disentanglement property. During training,We augment the original training set by randomly interpolating neW attribute values that lie betWeenthe values of the training set. The constraints of perfect disentanglement then enforce that the latentrepresentation of every attribute is understandable by the decoder, i.e., it forces, in the limit of infiniteinterpolated samples, the disentangled latent representation of every attribute to be convex.
Figure 4: Towards controllable exploration directionpositive side to represent the UDV. Then we can use the UDVs or the combination of them to achieveprecise attribute synthesis and to find new attribute values. Controlling attributes with UDVs is ageneral method which can be used in most cases. However, for those attributes (object color) whoseattribute value (blue color) has small intra-class variance (all blues look similar), their distribution canbe seen as a Gaussian distribution, and we can use K-means (Likas et al. (2003)) to find the center ofeach object color and compute the mean of latent value for those cluster centers.
Figure 5: Performance comparison of interpolation-based synthesisdownstream tasks, such as classification. (3.5) Demonstrate DEAE can use disentangled represen-tation to eliminate the bias in a dataset and improve the performance of downstream tasks, whichprovides a solution for fairness decision problems. We use the following datasets to explore our topic.
Figure 6: DEAE controllable synthesis performance on RAFD dataset. Linear interpolation on theidentity(top) and expression(bottom) attribute between the source image and the target image.
Figure 7: Changing to target attribute value and mining new attribute values7Under review as a conference paper at ICLR 2021images from DEAE trained model to the small training set can improve the performance of theclassification task. The accuracy gap from DS+DEAE to DS+GSL-AE shows that DEAE performsbetter than GSL-AE.
Figure 8: The influence of bias shown by Grad-Cam8Under review as a conference paper at ICLR 20214	ConclusionWe proposed a new kind of generative autoencoder: Disentangled Exploration Autoencoder (DEAE),which can achieve controllable synthesis by freely interpolating in disentangled latent space. DEAEtries to turn the non-convex latent space to convex for each attribute by ’reusing’ the encoder toregularize the latent space of synthesized images. We show that DEAE outperforms state-of-the-artmethods on attribute controllable synthesis tasks. We demonstrate how DEAE achieves precise latentspace movement and novel attribute mining in perfect disentangled space by combining unit directionvectors. We also demonstrate that DEAE, as a generative model can improve the performance ofdownstream classification tasks as well as eliminate dataset bias, which provides a new solution forfairness problems.
