Figure 1: A single-hidden-layer, fully-connected feedforward neural network for regression predic-tion. Left panel: Structural diagram of the neural network. Right panel: ReLU activation function:φ(a) := (a)+ = max(0, a) = a for a ≥ 0; φ(a) = 0 otherwise.
Figure 2: Gaussian process regression prediction on simulated data. Top left: 10 sample paths gen-erated from a Gaussian process model with hyperparameters (σw2 , σb2) = (3.6, 0.02). Top middle:Point-wise visual comparison between predicted and true target values for the optimal hyperpa-rameter pair {3.6, 0.02}, showing good prediction results. Top right: The line of equality furtherconfirming the prediction accuracy. Bottom left: Point-wise visual comparison for hyperparameterpair {3.6, 0.0001}. Bottom right: Prediction errors revealed with the line of equality.
Figure 3: Comparing MNIST training accuracy over various training sizes. We observe that theconvergence rate based on our method approaches that using He-initialization as the training sizeincreases. This suggests that our technique may potentially be efficient for guiding deep neuralnetwork initialization. Left: train_size=1000. Middle: train_size=3000. Right: train_size=5000.
