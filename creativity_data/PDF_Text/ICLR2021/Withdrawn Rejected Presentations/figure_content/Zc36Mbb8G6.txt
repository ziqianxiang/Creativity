Figure 1: Overview of our proposed technique, Data Instance Priors (DIP) for transfer learning in GANs. Top:DIP training with feature C(x) of a real sample x as a conditional prior in the conditional GAN framework of(Miyato & Koyama, 2018). C is a pre-trained network on a rich source domain from which we wish to transferknowledge. Bottom: Inference over trained GAN involves learning a distribution over the set of training dataprior {C (x)} to enable sampling of conditional priors.
Figure 2: Comparison between DIP and Baseline when trained on 10% data of CIFAR-100. left: FID (inPytorch) of baseline training starts increasing very early in training (around 15k) as compared to FID of DIPtraining. middle: Discriminator score on training and validation images remain similar to each other andconsistently higher than score of generated images for DIP model. right: Discriminator score on training andvalidation images start diverging and training collapses for the baseline model.
Figure 3: 100-shot image interpolation betweeninstance-level prior for DiffAugment (Zhao et al.,2020b) (Rows 1,3,5) and DiffAugment + DIP-Vgg16(Rows 2,4,6) on Anime, Faces and Flower datasets re-spectively.
Figure 4: Images generated through IvOM forrandomly sampled test set images on FFHQ andLSUN-Bedroom. (Top to Bottom:) Original im-ages, Baseline, Baseline + DIP-Vgg16, Baseline+ DIP-SimCLR.
Figure 5: Semantic diffusion for image manipulation using DIP-Vgg16 model on FFHQ dataset. (Left toRight:) Custom Editing, Inpainting, Sketch-to-Image Translation and Colorization.
Figure 6: (a) FID (lower is better) performance graph of few-shot image generation on 25-500 images ofAnime dataset using various approaches on SNGAN model; (b) Samples of few-shot image generation on25-500 images of Anime dataset using DIP on various approaches on SNGAN.
Figure 7: Few-shot interpolation samples between instance-level priors: Scratch (Row 1), Scratch + DIP-Vgg16 (Row 2), FreezeD (Row 3), FreezeD + DIP-Vgg16 (Row 4), DiffAugment (Row 5), DiffAugment +DIP-Vgg16 (Row 6)Method	Style-GAN 2 (256 X 256)			Panda FID J	Grumpy Cat FID J	Obama FID JFreezeD	16.69	29.67	62.26+ DIP-Vgg16	14.66	29.93	54.87DiffAugment	12.06	27.08	46.87+ DIP-Vgg16	11.14	28.45	43.79BSA*	21.38	34.20	50.72GLANN + DIP-Vgg16	11.51	29.85	38.57Table 6: 100-shot image generation results usingStyleGAN-2 (Karras et al., 2020b) architecture onPanda, Grumpy-cat and Obama datasets. FID iscomputed between 5k generated and the completetraining dataset. * denotes directly reported fromthe paper (Zhao et al., 2020b).
Figure 8: Sample generated images on limited data training: FreezeD (Row 1), FreezeD + DIP-Vgg16 (Row 2), DiffAugment (Row 3) and DiffAugment + DIP-Vgg16 (Row 4)lr 2e - 4 and z dimension 120. For DiffAugment, batch size is 32, D-steps is 4 and rest of the hy-perparameters are same. Training is done till 30k steps for DiffAugment, FreezeD, and 5k steps forthe rest. The moving average weights of the generator are used for evaluation. We use pre-trainednetwork from 7 (Brock et al., 2018) for finetuning.
Figure 9: Semantic variations using pre-trained Vgg16 conditional DIP module on FFHQ dataset. (Left:)Random samples generated with prior as feature of the first image in each row; (Right:) first and secondrow in both images shows generated samples by interpolation and Bernoulli mixup between two image priorsrespectively.
Figure 10: Examples of semantic diffusion used in image manipulation on FFHQ dataset usingour DIP-Vgg16 approach. Top-Left: Custom Editing; Top-Right: Sketch-to-Image; Bottom-Left:Inpainting; Bottom-Right: ColorizationSemantic diffusion for image manipulation Figure 10 shows more examples of semantic diffu-sion being used in standard image manipulations like colorization, editing, sketch-to-image transla-tion and inpainting.
Figure 11: Samples generated by our DIP-Vgg16 approach on large-scale image generationMethods	CIFAR-10 CT	CIFAR-100 CT	FFHQ CT	LSUN CT	ImageNet32x32 CTBaseline	3.02	4.26	-0.15	2.59	10.5DIP-Vgg16	1.24	2.50	-0.63	3.31	7.48DIP-Vgg16 (GMM)	1.58	3.05	-0.81	1.06	8.53DIP-Vgg16 (K-means)	1.96	3.70	-0.46	1.12	8.47DIP-SimCLR	2.23	3.30	-1.14	2.49	9.70DIP-SimCLR (GMM)	2.86	3.48	-1.49	0.13	9.91DIP-SimCLR (K-means)	2.45	3.91	-1.84	-0.12	10.11Table 10: Test for evaluating data-copy and memorization in GANs (Meehan et al., 2020) for different ap-proaches and datasets. Test statistic CT << 0 denotes overfitting and data-copying, and CT >> 0 representsunder-fitting.
