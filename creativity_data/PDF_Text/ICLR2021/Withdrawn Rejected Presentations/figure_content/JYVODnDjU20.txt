Figure 1: Illustration of mapping examples from the in-distribution onto a unit-hypersphere. In thisrepresentation, feature vectors from the in-distribution are semantically similar if they approximatelyalign and semantically diverse if they are separated by a large angle. If OOD examples are mappedonto the unit-hypersphere, they can align with training examples without being semantically similar.
Figure 2: Semantic Neighbourhoods for examplesfrom CIFAR-10/100.
Figure 3: Transformation strengths used intraining Ppos (weak to strong) and Pneg(weak to extreme)to any variation in γ > 0 (Appendix A). We introduced Y as it is notoriously hard to learn ratiosof probability densities in high dimensional spaces, which is a central problem of generative ad-versarial networks (Azadi et al. (2019)). In general, s(x, x0) learned by the objective Eq. 3 candeviate significantly from the optimal generalising likelihood ratio s* (x, χ0). This deviation is mostapparent if Ppos (x, x0) is close to zero where Pneg (x, x0) is non-zero and vice versa, as shown inFig. 4. In this case the objective can be maximised by any decision boundary that lies in the regionbetween the distributions Ppos (x, x0) and Pneg (x, x0). To smoothen the score function s(x, x0) wesample γ at each iteration of the learning process and thereby effectively sample over an ensembleof gradients (Appendix B). Inspired by the lottery ticket hypothesis that training a deep neural net-work under constant objective mainly affects the weights of a small subnetwork (Frankle & Carbin(2019)), we can reason that sampling over γ affects the weights for an ensemble of overlapping sub-networks. As a consequence, s(x, x0) is the prediction from an ensemble of models, which typicallyresults in higher prediction accuracies, less variance with respect to weight initialisation, and higherrobustness to overfitting. The effect of uniform sampling of γ on stabilising the decision bound-ary and thus observing the train/test sets from the in-distribution within the positive score range isshown in Appendix C. Although only the difference in score values between a test example and thein-distribution test set is relevant for OOD detection, examples from the in-distribution should be
Figure 4: Distributions over the OOD detection score, s(x, x0), trained on CIFAR-100 pos/negpairs (Ppos in blue; Pneg in red) as described in Section 4.1 and applied to semantic nearest-neighbour pairs from the test sets of SVHN and CIFAR-10 (out-distributions) in comparison tosemantic nearest-neighbour pairs of the CIFAR-100 test/train sets (in-distributions).
Figure 5: Random shifts of in-distribution test/train sets (green) for different training runs as indi-cator for instability of the decision boundary. Shown are results for 5 independent training runs forY〜 U(1, 10) (left column) and for γ = 1 (right column), using the same setup as used to computeTable 1 but with ResNet18.
