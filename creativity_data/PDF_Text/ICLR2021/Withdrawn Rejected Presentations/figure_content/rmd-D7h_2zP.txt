Figure 1: An example of a dialogue and its dialogue state.
Figure 2: Model overview.
Figure 3: Input representation for the DSC encoder. The example here shows a dialogue context for2 turns of (S1, U1, S2, U2). S1 is omitted because the sequence starts with the user utterance andS1 is just a placeholder: a blank sentence. In this figure, the special token layout for {DS} tokensis represented in DS-merge. Euttn represents the sequence of word embeddings for each utteranceafter tokenization.
Figure 4: Joint goal accuracy and slot-value loss versus training steps on the evaluation dataset ofMUltiWOZ-2.2. ALBERT-xxlarge-v2 was used for the DSC-encoder. Straight lines indicate thejointgoal accuracy and dashed lines indicate the slot-value loss. The x-axis indicates the training steps.
Figure 5: An example of a dialogue and its dialogue state.
Figure 6: An example of a dialogue and its dialogue state.
