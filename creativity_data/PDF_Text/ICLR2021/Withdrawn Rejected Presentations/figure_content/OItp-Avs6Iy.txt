Figure 1: (a) shows an example point cloud (black dots) contained within a bounding sphere. (b)shows the spherical partioning of 3D space in 2D cross section view, and zooms in on a sectoroccupied by 3 data points. Vertices are white circles. Each point is bounded by a neighborhood of6 vertices, 3 from the sphere above and 3 from below. (c),(d) Each point is mapped to scalar valuesdefined on the bounding vertex neighborhood using radial basis functions. Vertices affected by themapping are shaded gray. Dotted circles indicate vertices temporarily added in the radial dimensionto increase resolution. (e) Vertex values are concatenated into feature channels of original vertices.
Figure 2: TWo subsets of vertices from two concentric spheres, connected radially. ui,1 or vi,* arevertices on i-th sphere (a) Intra-sphere convolution and (b) inter-sphere convolution applied withrespect to the target vertex u2,1 (bolded). Third sphere not shown for clarity. Vertices involved inconvolution are connected by orange or green edges.
Figure 3: Example multi-radius architecture with R = 3 concentric spheres. Graph convolu-tions, followed by radial convolutions, are applied over a sequence of discretization levels. Poolingcoarsens the discretization to a lower level. Vertex-wise and radial-wise pooling is applied to obtaina final representation for classifier. Icosahedron visualization from Satoh et al. (2014).
Figure 4: Architecture for ModelNet40 classification. Input dimension is 16, resulting from pointcloud RBF data mapping. “Gconv” is graph convolution applied over graph connectivity of thesphere. “Conv1d” is 1D convolution, applied over the radial dimension. L denotes discretizationlevel, as the representation is coarsened following each vertex pooling step. A final pooling of radialdimension results in a 1024 dimensional vector.
Figure 5: Architecture used for Sec. 5.1 and 5.2 experiments. Layers proceed from left to right.
Figure 6: A vertex (red) and its neighbors (yellow/orange) are shown in local patch of the icosa-hedral spherical discretization. These are the basic units for intra-sphere convolution and pooling.
Figure 7: Visualization of point clouds from ModelNet40 and learned features. Example instancesfrom left to right, shown in 3 different orientations: airplane, sofa, and toilet. In the table of sphericalvisualizations, each sphere corresponds to a single feature channel. Rows correspond to radial level(16 total), with bottom rows corresponding to outer spheres. Columns correspond to discretizationlevel of the sphere, from level 4 to 3 to 2 (left to right). Colors are interpolated between blue andred, corresponding to low or high normalized feature values.
Figure 8: SHREC17 mis-predicted class pairs from single-sphere model where the multi-sphere(R = 16) model showed biggest relative improvement. Each image is a representative sample fromthe class. Note that watercraft, table, and tower all have more non-convex features that distinguishthem from their mis-predicted counterparts. The concentric spherical model seems to better capturethese differences.
