Figure 1: Underlying factors of any observa-tional dataset (Hassanpour & Greiner, 2020)Figure 2: Graphical model of CEVAE(Louizos et al., 2017)GANITE Yoon et al. (2018) proposed the counterfactual GAN, whose generator G, given{x, t, yt}, estimates the CoUnterfaCtUal outcomes (y-t); and whose discriminator D tries to identifywhich of {[x, 0, y0], [x, 1, y1]} is the factual outcome. It is, however, unclear why this requires thatG mUst prodUce samples that are indistingUishable from the factUal oUtcomes, especially as D canjUst learn the treatment selection mechanism instead of distingUishing the factUal oUtcomes fromcoUnterfactUals. AlthoUgh this work is among the few generative approaches for caUsal inference, oUrempirical resUlts (in Section 4) show that it does not effectively estimate coUnterfactUal oUtcomes.
Figure 2: Graphical model of CEVAE(Louizos et al., 2017)GANITE Yoon et al. (2018) proposed the counterfactual GAN, whose generator G, given{x, t, yt}, estimates the CoUnterfaCtUal outcomes (y-t); and whose discriminator D tries to identifywhich of {[x, 0, y0], [x, 1, y1]} is the factual outcome. It is, however, unclear why this requires thatG mUst prodUce samples that are indistingUishable from the factUal oUtcomes, especially as D canjUst learn the treatment selection mechanism instead of distingUishing the factUal oUtcomes fromcoUnterfactUals. AlthoUgh this work is among the few generative approaches for caUsal inference, oUrempirical resUlts (in Section 4) show that it does not effectively estimate coUnterfactUal oUtcomes.
Figure 3: Belief nets of the proposed architectures.
Figure 4: Performance analysis for decomposition of the underlying factors on the synthetic datasetwith mΓ,∆,Υ =8, mΞ = 1.
Figure 5: Radar graphs of PEHE (on the radii;lower is better) for the entire synthetic benchmark(24 × 3 with N = 10,000; each vertex denotes therespective dataset). Figure is best viewed in color.
Figure 6: Hyperparameters’ (x-axis) sensitivity analysis based on PEHE (y-axis) on the syntheticdataset with mΓ,∆,Υ =8, mΞ = 1. Legend is the same as Figure 5. Plots are best viewed in color.
Figure 7: Decoders (parametrized by θ) and encoders (parametrized by φ) of the M1, M2, andM1+M2 VAEs.
Figure 8: The four dummy x-like vectors (left); and the input/output vectors of the representationnetworks (right).
Figure 9: Decomposition tables for H-VAE-CI with β=0.
