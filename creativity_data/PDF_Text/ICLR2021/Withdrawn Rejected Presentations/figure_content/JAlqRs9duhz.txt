Figure 1: Hyper-parameter (γ) sensitivity in the language modeling task on Wikitext-103 develop-ment set. Rep/l is computed as the average of Rep/16, Rep/32 and Rep/128. Detailed results forRep/l can be found in Appendix K.
Figure 2: An illustration of how the novel token set changes as decoding proceeds for the sentence“people who are interested ...”. The words marked in purple are the target words that the model islearning to predict at each decoding step.
Figure 3: Human evaluation interfaceF	Experimental results on open-ended generationF.1 Full experimental results on WikiText- 1 03We present the full experimental results on WikiText-103 (Merity et al., 2017) for open-ended gen-erations in Table 9. All the numbers are averaged over 3 runs with different randoms seeds andshown together with standard deviations.
Figure 4: Box plot for Rep-1 in auto completion with different decoding lengths. All the numbersare computed based on the results from 3 runs with different random seeds.
Figure 5: Hyper-parameter (γ) sensitivity in the language modeling task on Wikitext-103 develop-ment set.
