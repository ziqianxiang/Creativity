Figure 1: First row: results for sin(x), Second row: results for ReLU (x). First column: Histogramsgenerated from the repeated training of neural networks for training sin(x), and ReLU (x). Secondcolumn: Test L2 errors. Third column: Average training time for each loss function to achievecertain error threshold. Error bars are for standard deviations. The thresholds for the error are set to10-4.
Figure 2: Average number of epochs to make error less than 10-3 increases in L2 loss as k increases.
Figure 3: First row: results for the heat equation. Second row: results for Burgers’ equation. Firstcolumn: Histograms for the heat and Burgers’ equation generated from a hundred neural networksfor each loss function. Second column: Test L∞ (0,T; L2 (Ω)) errors. Third column: Averagetraining time for each loss function to achieve certain error threshold. Error bars are for standarddeviations. The thresholds for the error are set to 10-5 .
Figure 4: First row: results for f1 initial condition. Second row: results for f2 initial condition.
Figure 5: Test errors as training goes for different learning rates.
Figure 6: Test errors as training goes for different learning rates.
Figure 7: Left column: Test errors as training goes for different values of k. Right column: RequiredTraining Time to achieve a certain test error.
