Figure 1: Unsupervised Video Decomposition. Our approach allows to infer precise segmentationsof the objects via interpretable latent representations, that can be used to decompose each frame andsimulate the future dynamics, all in unsupervised fashion. Whenever a new object emerges into aframe the model dynamical adapts and uses one of the segmentation slots to assign to the new object.
Figure 2: Model Overview. (a) Inference in our model passes through a 2D grid in which light graycell (r, t) represents the r-th refinement at time t, dark gray cells are where the final reconstructionis computed and no refinement is needed . Each light gray cell receives three inputs: a refinementhidden state ht,r-1, a temporal hidden state ht-1,Rb, and posterior parameters λt,r. The outputs are anew hidden state ht,r and new posterior parameters λt,r+1. (b) An example of the internal structureof the highlighted cell from Fig. (a). We process the inputs with the help of a spatial broadcastdecoder and a 2D LSTM. The rest of the light gray cells have the same structure.
Figure 3: Qualitative Evaluation (Bouncing Balls). Our model can generalize to sequences with 8balls when trained on 4 balls. Top-to-bottom: output masks, reconstructions, and ground truth video.
Figure 4:	Velocity predic-tions.Cosine similarity for 5simulated frames after 10 inferencesteps.
Figure 5: Prediction. We show the (F-)ARI for 3, 5, 7, and 10 simulatedframes after 20 inference steps.
Figure 6: Qualitative Evaluation (CLEVRER). Our model can generalize to sequences with 6 objects. Wealso demonstrate the ability to handle a dynamically changing number of objects, ranging from 4 in the beginningto 6 at the end.
Figure 7: Qualitative evaluation on real-world data. Qualitative Evaluation (Grand Central Station). We canobserve that our method is very consistent in separating the image regions belonging to different objects as theymove in the scene. This dataset is particularly challenging for its background texture, complex lighting andshadows. Please zoom in to allow better clarity.
Figure 8: Mean Squared Error for the prediction experiment. We have computed MSE for the sameexperimental set up as on Fig. 5. As expected the MSE increases with number of simulation steps.
Figure 9: Video decomposition using our model applied on Bouncing Balls dataset with 4 balls.
Figure 10: Video decomposition using our model applied on Bouncing Balls dataset with 6-8 balls.
Figure 11: Prediction on Bouncing Balls (colored) dataset.
Figure 12: Prediction on CLEVRER dataset.
Figure 13: Qualitative results for Ours vs. IODINE vs. SEQ-IODINE decomposition experiment.
Figure 14: Disentanglement of the latent representations corresponding to distinct interpretablefeatures. CLEVRER latent walks along three different dimensions: color, size and position. Wechose a random frame and for each object’s representation in the scene dimensions were traversedindependently.
