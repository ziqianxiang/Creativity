Figure 1: Performance drop when transferring node embed-dings between tasks on (a) Node Classification (NC), (b)Graph Classification (GC), and (c) Link Prediction (LP) onthe ENZYMES dataset. On the horizontal axis, “X ->ʃ” indi-cates that the embeddings obtained from a model trained ontask x are used to train a network for task y.
Figure 2: (a) Schematic representation of a multi-task episode. For each task, support and target setare designed to be as the training and validation sets for single-task training. (b) Scheme of iSAME:both the backbone GNN and the task-specific output layers are adapted (one at a time) in the innerloop of our meta-learning procedure. (c) Scheme of eSAME: only the task-specific output layers areadapted (one at a time) in the inner loop of our meta-learning procedure.
Figure 3: Results for neural network, trained on the em-beddings generated by a multi-task model, performing atask that was not seen by the multi-task model. “x, y->z''indicates that x, y are the tasks for training the multi-taskmodel, and z is the new task.
