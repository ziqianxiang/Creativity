Figure 1: Entropy of feature A and B from the perspective of OR, UR and II. Feature A represents afeature with UR and OR with respect to the label, Feature B represents a feature with no UR andsome OR with respect to the label.
Figure 2: (left) Feature selection with GSA. (right) Redundancy rates for various algorithms.
Figure 3: Performance Comparison between MRwMR based algorithms and correspondingMRwMR-BUR forms on six public datasets. The vertical and horizontal axes are classificationaccuracy and the corresponding number of features required, respectively. The results shown areaverages over 20 trials via Random Forest with Î² = 0.1. The box corresponds to the lower and upperquartile. The horizontal line inside the box depicts the peak averaged accuracy and the whiskersdepict the minimum and maximum over the trials. In each subplot, we report two sets of results: peakaveraged accuracy improvement and feature improvement. Specifically, from left to right, it is theminimum, maximum and averaged improvement over five comparisons between the MRwMR basedalgorithm and its MRwMR-BUR form (e.g., compare MIM to MIM_BUR, JMI to JMLBUR and soon). A negative value of improvement indicates that the peak averaged accuracy of theMRwMR-BUR algorithm is lower than its original form or the number of features required for theMRwMR-BUR algorithm is more than its original form. Similar Performance can be observed forSVM and KNN as well (see A.3 in Appendix).
