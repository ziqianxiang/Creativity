Figure 1: Schematic illustration of the proposed approach. Left: The graphical model associatedwith the minimax game. Right: Our proposed architecture with the two stream network is based onVAE, and augmented with additional predictor loss and (focal) entropy.
Figure 2: Illustration of focal entropy and the effect of grouping assuming equal partitioning ofprobability mass. Center: Visualization of a sample configuration; schematic focus regions depictedas circles ranging from narrow (1) to wide (3). Left: Visualization of off-center entropies (similar,dissimilar) for different focus regions scenarios. The more narrow the focus, the more weight “similar”samples have. Conversely, the wider focus range, the more equiprobability is approached. Right:Entropy visualization for focus scenarios.
Figure 3: Left: t-SNE embedding of latent representation for a subset of 200 IDs. Left t-SNE:embedding of the target part ztar. Righ t-SNE: embedding of residual part zres. t-SNE is unable toreveal any sort of regular structure in ztar w.r.t. private attribute. Right: Trade-Off curve betweentarget accuracy and adversarial accuracy on CIFAR-100.
Figure 4: Visualization of adversary ID re-mapping graph on CelebA for entropy to focal entropywith different k-NNs on ztar . Nodes correspond to IDs, edges to adversarial re-mapping of anID to facilitate adversary confusion. Node size/brightness scales with number of associations (thebigger/brighter, the more IDs are mapped to a specific node). From left to right increasing k for focalentropy: k =1 (≈ standard entropy), 2, 16 and 64.
Figure 1: Left: Relationship between adversarial accuracy and the number of training epochson CelebA. The translucent band corresponds to 50% confidence minimum and maximumadversarial accuracy, respectively. Right: Relationship between adversarial accuracy forstrong (red) and normal classifier (blue) w.r.t. the number of training epochs on CelebA.
Figure 2: Relationship between adversary accuracy and k-NN size on CelebA dataset.
Figure 3: Sanitization convergence behavior of standard entropy and focal entropy on CIFAR-100 for different classifiers: Left: Target accuracy, Center: Adversarial accuracy, Right:Sensitive attribute accuracy2Under review as a conference paper at ICLR 20214 Probing Analysis with Strong ClassifierThis section provides more detail on assessing the classifier strength in terms of privacy leakageand the dependence on training time. We thereby largely follow the protocol of Harsh Jhaet al. (2018); Sadeghi et al. (2019). Specifically, we employed a stronger post-classifier (Tab.
Figure 4: Visualization of CelebA identities of adversary classification network. The network(green) corresponds the k-nearest neighborhood size k = 5.
Figure 5: Visualization of the remapping of IDs in CelebA due to adversarial representationlearning. Source IDs (left) are remapped to new target IDs (right). Pictures on the leftare samples that get mapped to a hub; separation with bar indicates different target hub.
Figure 6: Attribute-level Privacy Analysis: The normalized ∆-Accuracy and privacy trade-offon CelebA dataset. See Tab. 2 for detailed results.
Figure 7: Visualization of CelebA data and reconstructions at different privacy levels. (Fromtop to bottom, privacy revelation is decreasing).
