Figure 1: The framework of the proposed DCRL method. The encoder, decoder, latent space, andcluster centers are marked as blue, red, green, and purple, respectively.
Figure 2: Force analysis of the contradiction between clustering and local structure preservation.
Figure 3: Schematic of training strategy. Four different colors and shapes represent four intersectingmanifolds, and three stages involve the clustering, separation, and structure recovery of manifolds.
Figure 4: Visualization of the embeddings learned by different algorithms on MNIST-full dataset.
Figure A1: The image samples from three datasets (MNIST, USPS, and Fashion-MNIST)A.4 Definitions of performance metricsThe following notations are used for the definitions:dX (i, j): the pairwise distance between xi and xj in input space X;dZ(i,j): the pairwise distance between zi and zj in latent space Z;Nik,X: the set of indices to the k-nearest neighbor (kNN) of xi in input space X;Nik,Z: the set of indices to the k-nearest neighbor (kNN) of zi in latent space Z;rX(i,j): the rank of the closeness (in Euclidean distance) ofxj to xi in input space X;rZ(i,j): the rank of the closeness (in Euclidean distance) of zj to zi in latent space Z.
Figure A2: The visualization of the obtained embeddings on the testing samples to show the gener-alization performance of different algorithms on MNIST-full dateset.
Figure A3: Clustering visualization at different stages of training on MNIST-full dateset.
Figure A4: Clustering visualization with different assumed cluster number C on MNIST-test dateset.
Figure A5: Statistical analysis of different algorithms to compare the capability of global and localstructure preservation from the input space to the latent space.
