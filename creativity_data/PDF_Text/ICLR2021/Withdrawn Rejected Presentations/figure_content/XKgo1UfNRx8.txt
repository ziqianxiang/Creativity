Figure 1: The algorithmic workflow to train, combine and predict on a new data. In this exampleK=2.
Figure 2: The two axes represent an error oftwo different classes, the goal is to get closerto the (0;0) point. Each model a, b and c havedifferent error distribution and averaging themleads to ensembles with other error distribu-tions.
Figure 3: Available solutions as a graph. Nodesare ensembles. Edges are the decision to add a newmodel to the ensemble. The cost function is the eu-clidean distance and is displayed on the top left ofeach node. The source node, corresponding to theempty ensemble, is modeled with an arbitrary largedistance. The optimal ensemble is made of a and b.
Figure 4: Correlation computing cost versusaccuracy of randomly sampled models on CI-FAR100生首用首兴首生首茶首第g箱苫资IIZeEE 寻AccuracyFigure 5: Accuracy histogram of randomly sam-pled models on CIFAR1004.2	Comparison of various HPO strategies and Dijkstra’ s algorithmWe evaluate the accuracy of our workflow on CIFAR100 by replacing Hyperband with various HPOstrategies in table 1. Retraining the same deep learning architecture from scratch can yield significantdistance in different run time, that is why we compare different HPO strategies and different popularResNet architectures as well in table 2. We observe that Hyperband generally performs well to takethe best one and also to aggregate ensembles compared to all other methods. It confirms our claim inthe previous section on Hyperband computing efficiency and the ability to generate good ensembles.
Figure 5: Accuracy histogram of randomly sam-pled models on CIFAR1004.2	Comparison of various HPO strategies and Dijkstra’ s algorithmWe evaluate the accuracy of our workflow on CIFAR100 by replacing Hyperband with various HPOstrategies in table 1. Retraining the same deep learning architecture from scratch can yield significantdistance in different run time, that is why we compare different HPO strategies and different popularResNet architectures as well in table 2. We observe that Hyperband generally performs well to takethe best one and also to aggregate ensembles compared to all other methods. It confirms our claim inthe previous section on Hyperband computing efficiency and the ability to generate good ensembles.
Figure 6: The CIFAR100 datasetRandom quartile 1Dijkstra■ Top individual models— — Random quartile 3Random quartile 2Figure 7: The microfossils dataset63.00%Figure 8: Different combinatorial optimization algorithm tested7Under review as a conference paper at ICLR 2021Table 4: Various ResNets and ensemble size on the microfossils dataset	resnet 18 population	resnet34 population	resnet50 population	resneXt50 population	resnet101 population	resnet152 populationTop	86.83%	85.24%	85.65%	84.91%	84.22%	85.09%Team of 2	87.74%	87.77%	87.54%	87.26%	86.04%	86.61%Team of 3	88.22%	88.55%	88.48%	87.93%	87.54%	87.66%Dijkstra Team of 4	88.34%	88.71%	88.63%	88.02%	87.74%	87.91%solution Team of 6	89.10%	89.50%	89.37%	88.37%	88.24%	88.78%Team of 8	89.13%	89.59%	89.39%	88.73%	88.40%	88.80%4.4 Effect of computing intensity on the final accuracy
Figure 7: The microfossils dataset63.00%Figure 8: Different combinatorial optimization algorithm tested7Under review as a conference paper at ICLR 2021Table 4: Various ResNets and ensemble size on the microfossils dataset	resnet 18 population	resnet34 population	resnet50 population	resneXt50 population	resnet101 population	resnet152 populationTop	86.83%	85.24%	85.65%	84.91%	84.22%	85.09%Team of 2	87.74%	87.77%	87.54%	87.26%	86.04%	86.61%Team of 3	88.22%	88.55%	88.48%	87.93%	87.54%	87.66%Dijkstra Team of 4	88.34%	88.71%	88.63%	88.02%	87.74%	87.91%solution Team of 6	89.10%	89.50%	89.37%	88.37%	88.24%	88.78%Team of 8	89.13%	89.59%	89.39%	88.73%	88.40%	88.80%4.4 Effect of computing intensity on the final accuracyOur workflow benefits more of computing intensity than standard Hyperband like shown in figures 9and 10.
Figure 8: Different combinatorial optimization algorithm tested7Under review as a conference paper at ICLR 2021Table 4: Various ResNets and ensemble size on the microfossils dataset	resnet 18 population	resnet34 population	resnet50 population	resneXt50 population	resnet101 population	resnet152 populationTop	86.83%	85.24%	85.65%	84.91%	84.22%	85.09%Team of 2	87.74%	87.77%	87.54%	87.26%	86.04%	86.61%Team of 3	88.22%	88.55%	88.48%	87.93%	87.54%	87.66%Dijkstra Team of 4	88.34%	88.71%	88.63%	88.02%	87.74%	87.91%solution Team of 6	89.10%	89.50%	89.37%	88.37%	88.24%	88.78%Team of 8	89.13%	89.59%	89.39%	88.73%	88.40%	88.80%4.4 Effect of computing intensity on the final accuracyOur workflow benefits more of computing intensity than standard Hyperband like shown in figures 9and 10.
Figure 9: The CIFAR100 datasetFigure 10: The microfossils datasetFigure 11: Varying the max number of models in ensembles in function of Hyperband running timeConclusionDue to the experimental nature of deep learning and the increasing of available computing powerlike multi-GPUs servers, it allows to sweep deep learning architectures. The standard usage of hyperparameter optimization consists in training hundreds of models and keeping only the best one, whichleads to an important waste of energy.
Figure 10: The microfossils datasetFigure 11: Varying the max number of models in ensembles in function of Hyperband running timeConclusionDue to the experimental nature of deep learning and the increasing of available computing powerlike multi-GPUs servers, it allows to sweep deep learning architectures. The standard usage of hyperparameter optimization consists in training hundreds of models and keeping only the best one, whichleads to an important waste of energy.
Figure 11: Varying the max number of models in ensembles in function of Hyperband running timeConclusionDue to the experimental nature of deep learning and the increasing of available computing powerlike multi-GPUs servers, it allows to sweep deep learning architectures. The standard usage of hyperparameter optimization consists in training hundreds of models and keeping only the best one, whichleads to an important waste of energy.
