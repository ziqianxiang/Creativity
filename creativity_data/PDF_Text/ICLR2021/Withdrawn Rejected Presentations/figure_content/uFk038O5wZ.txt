Figure 1:	(a) A general architecture of Knowledge Graph Enhanced Dual-copy network for ab-stractive dialogue summarization. (b) The first approach for fusion, which simply concatenates twocontext vectors. (c) The second approach for fusion, which uses MLP to build a gate network andcombines context vectors with the weighted sum.
Figure 2:	(a) The detailed construction process of a graph encoder (self-loops are omitted for sim-plification in the constructed dialogue graph). (b) An example of a constructed factual knowledgegraph from a dialogue.
Figure 3: (a) A detailed illustration of the edge initialization for the dialogue graph. The dotted boxcontains all the ids of utterance pairs for three edge labels. (b) Three types of dependency matric indifferent colors and white color indicates there is no semantic relation between nodes.
Figure 4: An example of fact tuple extraction in a dialogue. Words with shadings in different colorsare selected keywords. The purple arrow denotes the keyword-related tuples and the meaning ofthe dependency labels can be referred to de Marneffe & Manning (2008). The extracted tuples areshown in the text boxes.
Figure 5: The length distribution of the dialogue Figure 6: The length distribution of the sum-for SAMSum corpus.	mary for SAMSum corpus.
Figure 7: The length distribution of the dialogue Figure 8: The length distribution of the sum-for Automobile Master corpus.	mary for Automobile Master corpus.
Figure 9: Gates change during training on test set of SAMSUm corpus and Automobile Mastercorpus. Shaded area spans Â± std. The blue line represents the result of the SAMSum corpus and theorange line represents the result of the Automobile Master corpus.
