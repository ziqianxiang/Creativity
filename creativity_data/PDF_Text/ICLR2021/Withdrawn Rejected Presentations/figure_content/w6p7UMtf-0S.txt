Figure 1: Soft k-means Mahalanobis-distance based clustering method used in Transductive CNAPS.
Figure 2: Overview of the neural adaptive feature extraction process used in TranSdUCtiVe/SimpleCNAPS. Figure was adapted from Bateni et al. (2020).
Figure 3: a) Overview of the transductive task-encoding procedure, go (S, Q), used in TransductiveCNAPS. b) Transductive CNAPS (right) extends the Mahalanobis-distance based classifier in SimpleCNAPS (left) through transductive soft k-means clustering of the visual space.
Figure 4: Class recall (otherwise noted as in-class query accuracy) averaged between classes acrossall tasks and (a: In-Domain, b: Out-of-domain, c: all) Meta-Dataset datasets. Class recalls have beengrouped together, averaged and plotted according to the class shot in (a), (b), and (c).
Figure 5: Evaluating TransductiveCNAPS on Meta-Dataset with differ-ent minimum and maximum number ofsteps. As shown, performance is im-proved with 2 minimum refinement stepsrequired, with the best results observedat a maximum of 4 refinement steps.
