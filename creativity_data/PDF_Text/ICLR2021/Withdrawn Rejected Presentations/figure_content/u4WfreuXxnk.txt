Figure 1: An partial adversarial example from the test set of the Twitter dataset. An adversarially-crafted post perturbs the representation of the attacker node. This perturbation causes a misclassifica-tion of the target victim node, although they are not even direct neighbors.
Figure 2: Effectiveness of the attack comparedto the allowed âˆž (performed on PubMed, be-cause its features are continuous).
Figure 3: Test accuracy compared to the dis-tance between the attacker and the victim, whenthe GCN was trained with L = 8 on PubMed.
