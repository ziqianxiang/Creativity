Figure 1: (a) Pictorial representation of perturbation reduction done by fθ in case gφ is a classifier.
Figure 2: Architecture used in the proposed approach with multiple downstream models. X repre-sents the perturbed input image which is given as input to a reformer (autoencoder) fθ . Y representsthe output (desired clean images) produced by the reformer and Z indicates output given by dif-ferent downstream models. Lr is the reconstruction loss used by the reformer while L is the lossrepresenting error in the decisions of the downstream models.
Figure 3: Experimental results on MNIST data for (a) LeNet (b) Resnet-18. For both networks theproposed approach (IS: indirect supervision) outperforms the other approaches.
Figure 4: Upper 3 rows shows the images for LeNet for ε values 0.2, 0.3 and 0.4 respectively andremaining 3 for the Resnet-18 for ε values 0.5, 0.75 and 1. First column shows the original imagesfrom MNIST dataset. Second column shows perturbed images generated using FGSM attack. Thirdcolumn shows the images generated using unsupervised approach. Fourth columns shows the imagesgenerated by self supervision (noise2self). Fifth column shows direct supervision images and thelast column shows the images generated by our approach. For some samples indirect supervisionperforms better than direct supervision.
Figure 5: First column shows the original images from CIFAR-10 dataset. Second column showscorresponding the perturbed images from CIFAR-10-C dataset. Third column shows the imagesgenerated using unsupervised (GAN) approach. Fourth column shows the images generated us-ing Self supervised (noise2self) approach. Fifth column shows the images generated using directsupervision. Remaining three columns shows the images generated by our approach using Resnet-28-10, Resnet-40-2 and Resnet-50 respectively. All the rows represents different perturbations fromCIFAR-10-C dataset. Elastic transformation, frost, impulse noise, shot noise and zoom blur are theperturbations shown in the rows from top to down.
Figure 6: First column shows the original images from ISIC skin lesion dataset. Second columnrepresents the adversarial images generated using FGSM attack. Third column shows the imagesgenerated by our approach. Fourth column shows the segmentation model’s output on adversarialperturbed images. Fifth and sixth column shows improved segmentation output using our approachand corresponding masks respectively.
