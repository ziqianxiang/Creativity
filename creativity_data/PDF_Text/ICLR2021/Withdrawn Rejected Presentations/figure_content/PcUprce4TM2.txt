Figure 1: Illustration of large-batch data leakage on CIFAR-10 from shared gradients in FL2)	Our large-batch data recovery is based on the novel use of data index alignment and internalrepresentation alignment in FL, which can significantly improve the recovery performance.
Figure 2: Overview of CAFE in VFL3.1	Why Large-batch Data Leakage Attack is Difficult?We start by providing some intuition on the difficulty of performing large-batch data leakage fromaggregated gradients based on the formulation of DLG (Zhu et al., 2019). Assume that N images areselected as the input for a certain learning iteration. We define the data batch as X = {xn, yn|xn ∈RH×W ×C, n = 1, 2, . . . , N}, where H, W, C represents the height, the width and the channelnumber of each image. Likewise, the batched 'recovered data' is denoted by X = {Xn, yn|xn ∈RH×W×C,n = 1,2,..., N }, which have the same dimension as X . Then the objective function isX* = arg minX(4)Note that in (4), the dimensions of the aggregated gradients is fixed. However, as the N increases,the dimension of X and X rise. When N is sufficiently large, it will be more challenging to findthe “right” solution X of (4) corresponding to the ground-truth dataset X . On the other hand,CAFE addresses this large-batch issue by data index alignment for batch data recovery, which caneffectively exclude undesired solutions. We discuss a specific example in Appendix A.
Figure 3: CAFE on Linnaeus(Epoch: 50, 100, 200, 300, 450, 600, Original data)3.4	CAFE in HFLSimilarly, we can apply our CAFE algorithm to HFL as well. Let Xmt denote the original batch datataken by local worker m at the tth iteration. The gradients of the parameters at the tth iteration is1MVθ L(θ, Xt) = M E Vθ L(θ, Xm), Xt = {Xt, XW,..., Xm,..., XM }.	(9)Symmetrically, we define the batch fake data and fake aggregated gradients as1Mvθ l(θ, Xt) = IM E vθ l(θ, Xm), Xt = {Xt, Xf,..., Xm,..., XM}.	(10)Due to space limitation, we will provide the CAFE algorithm for HFL in Appendix B.
Figure 4: CAFE loss ratio and PSNR curves(d) VFL PSNRTable 1: CAFE vs DLGIterations Datasets Batch siZe'^^^-≥χ^	CIFAR-10	CIFAR-100	Linnaeus1(DLG)	284.4	-266.9-	366.710 X 4	9.50-	-600-	9.5020 × 4	6.75	-386-	4.7530 × 4	4.83-	-341-	3.1740 × 4	3.75	3.75	2.375(a) Comparison of data leakage speed. Loweriteration count is faster.
Figure 5: PSNR and training loss curves4.3	CAFE in VFL settingsSince DLG cannot be applied in VFL protocol, we test the performance of CAFE on various factors.
Figure 6: Effect of auxiliary regularizers4.4	Attacking while FLPrevious works have shown that DLG performs better on an untrained model than a trained one(Geiping et al., 2020). We also implement CAFE in the ‘attacking while learning’ mode, in whichthe FL process is ongoing. When the network is training, the selected batch data and the parametersof the model change every iteration, which may cause the attack loss to diverge. To address thisissue, for each real data batch, we compute the real gradients and optimize the corresponding fakedata k times. We demonstrate on Linnaeus dataset, set k = 10 and stop CAFE after 1000 iterations(100 epochs). Figure 5 gives the curves of the training loss and the corresponding PSNR value. ThePSNR value still can be raised to a relatively high value. It indicates that CAFE can be a practicaldata leakage attack in a dynamic training environment of FL.
