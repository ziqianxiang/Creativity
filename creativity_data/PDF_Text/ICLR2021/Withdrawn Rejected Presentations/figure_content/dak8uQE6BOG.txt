Figure 1: Abstract schematic for Nth order approximation of X “ G(ZI, ZII). The inputs ZI, ZII aresymmetric in our formulation. We denote with ZI a sample from a prior distribution (e.g., Gaussian),while ZII symbolizes a sample from a conditional input (e.g., class label or low-resolution image).
Figure 2: Synthesized images by MVP in the class-conditional CIFAR10 (with resnet-based genera-tor): (a) Random samples where each row depicts the same class, (b) Intra-class linear interpolationfrom a source to the target, (c) inter-class linear interpolation. In inter-class interpolation, the classlabels of the leftmost and rightmost images are one-hot vectors, while the rest are interpolatedin-between; the resulting images are visualized. In all three cases, MVP synthesizes realistic images.
Figure 3: Synthesized images for super-resolution by (a), (b) 8 ^ ,(c) 16 ^. The first row depicts theConditional input (i.e., low-resolution image). The rows 2-6 depiCt outputs of the MVP when a noisevector is sampled per row. Notice how the noise changes (a) the smile or the pose of the head, (b) thecolor, car type or even the background, (c) the position of the car.
Figure 4: Schematic for second order expansion with scalar output xτ P R. The abbreviationszι,λ, zι,μ are elements of ZI with λ,μ P [1, d]. Similarly, zιι,λ, zιι,μ are elements of zii. The firsttwo terms (on the right side of the equation) are the first-order correlations; the next two terms are thesecond order auto-correlations. The last term expresses the second order cross-correlations.
Figure 5: Abstract schematic for Nth order approximation of X “ G(ZI, ZII) with Nested-MVPmodel. The inputs ZI, ZII are symmetric in our formulation. We denote with ZI a sample from thenoise distribution (e.g., Gaussian), while ZII symbolizes a sample from a conditional input (e.g., aclass label or a low-resolution image).
Figure 6: Abstract schematic of the different compared generators. All the generators are productsof polynomials. Each colored box represents a different type of polynomial, i.e., the green boxsymbolizes polynomial(s) with dense layers, the blue box denotes convolutional or cross-correlationlayers. The red box includes the up-sampling layers. (a) Π-Net implements a single-variablepolynomial for modeling functions X “ G(z). Π-Net enables class-conditional generation by usingconditional batch normalization (CBN). (b) An alternative to CBN is to concatenate the conditionalvariable in the input, as in Π-Net-SICONC. This also enables the non-discrete conditional variables(e.g., low-resolution images) to be concatenated. (c) SPADE implements a single-variable polynomialfor conditional image generation. The polynomial is built with respect to the conditional variableZII. This is substantially different from the polynomial with multiple-input variables, i.e., MVP.
Figure 7: Qualitative results on CIFAR10. Each row depicts random samples from a single class.
Figure 8: Qualitative results on CIFAR10 when the generator does not include activation functionsbetween the layers. Each row depicts random samples from a single class; the same class is depictedin each pair of images. For instance, the last row corresponds to boats.
Figure 9: Qualitative results on Cars196 when the generator does not include activation functionsbetween the layers. Each row depicts random samples from a single class; the same class is depictedin each pair of images. The differences between the synthesized images are dramatic.
Figure 10: Inter-class linear interpolations across different methods. In inter-class interpolation, theclass labels of the leftmost and rightmost images are one-hot vectors, while the rest are interpolatedin-between; the resulting images are visualized. Many of the intermediate images in SNGAN-CONCand SNGAN-ADD are either blurry or not realistic. On the contrary, in SPADE and MVP thehigher-order polynomial expansion results in more realistic intermediate images. Nevertheless, MVPresults in sharper shapes and images even in the intermediate results when compared to SPADE.
Figure 11: Synthesized images by MVP in the (a), (b) class-conditional generation (sec. 4.1) and(b) block-inpainting (sec. 4.2). The networks do not include activation functions between the layers.
Figure 12: Synthesized images by MVP in the class-conditional SVHN: (a) Ground-truth samples,(b) Random samples where each row depicts the same class, (c) Intra-class linear interpolation froma source (leftmost image) to the target (rightmost image), (d) inter-class linear interpolation. Ininter-class interpolation, the class labels of the leftmost and rightmost images are one-hot vectors,while the rest are interpolated in-between; the resulting images are visualized. In all three cases((b)-(d)), MVP synthesizes realistic images.
Figure 13:	Qualitative results on MNIST-to-SVHN translation. The first row depicts the conditionalinput (i.e., a MNIST digit). The rows 2-6 depict outputs of the MVP when a noise vector is sampledper row. Notice that for each source digit, there is a significant variation in the synthesized images.
Figure 14:	Qualitative results on edges-to-image translation. The first row depicts the conditionalinput (i.e., the edges). The rows 2-6 depict outputs of the MVP when we vary zI . Notice that foreach edge, there is a significant variation in the synthesized images.
Figure 15:	Each row depicts a single combination of attributes, i.e., hair and eye color. Please zoom-into check the finer details. The method of SPADE synthesizes a single image per combination. Π-Net-SINCONC synthesizes few images, but not has many repeated elements, while some combinationsresult in unrealistic faces, e.g., the 5th or the 7th row. On the contrary, MVP synthesizes much morediverse images for every combination.
Figure 16: Each row depicts a single chair color, while each column depicts a single eye color.
Figure 17: Three-variable input gener-ative model.
Figure 18: Qualitative results on edges-to-image translation with regularization loss for diversegeneration (sec. H.7). The first row depicts the conditional input (i.e., the edges). The rows 2-6depict outputs of the MVP when we vary zI . Diverse images are synthesized for each edge. Theregularization loss results in ‘new’ shades of blue to emerge in the synthesized images in both theshoes and the handbags cases.
