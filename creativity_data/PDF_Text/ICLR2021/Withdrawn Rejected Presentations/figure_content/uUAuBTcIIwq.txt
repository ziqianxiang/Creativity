Figure 1: Comparison of four deep generative models. Dashed lines represent the graphical modelof the associated variational family. The Vanilla VAE (a), the GMVAE (b), and semi-supervisedvariants for grouped data; ML-VAE (c) and NestedVAE (d).
Figure 2: Generative (left) and inference (right) of UG-VAE.
Figure 3: Sampling from UG-VAE for CelebA (top) and MNIST (bottom). We include samplesfrom 3 local clusters from a total of K = 20 for CelebA and K = 10 for MNIST. In CelebA (top),the global latent variable disentangles in skin color, beard and face contrast, while the local latentvariable controls hair and light orientation. In MNIST (bottom), β controls cursive grade, contrastand thickness of handwriting, while z varies digit shape.
Figure 4: Sampling from ML-VAE, trained over unsupervised data.
Figure 5: UG-VAE interpolation in local (columns) and global (rows) posterior spaces, fusingcelebA and FACES datasets. In (a) the interpolation goes between the posteriors of a sample fromCelebA dataset and a sample from FACES dataset. In (c) the interpolation goes between the poste-riors of a sample from FACES dataset and another sample from the same dataset.
Figure 6: Extended experiment: UG-VAE interpolation in local (columns) and global (rows) poste-rior spaces, fusing 3D Cars with 3D Chairs (d) and 3D Cars to Cars Dataset (e).
Figure 7: 2D t-SNE projection of the UG-VAE β posterior distribution of structured batches of 128CelebA images. UG-VAE is trained with completely random batches of 128 train images.
