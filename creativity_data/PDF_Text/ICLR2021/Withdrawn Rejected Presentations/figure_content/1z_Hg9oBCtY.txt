Figure 3: (a,b,c) Training progression of distributions of discriminator scores. At convergence, weobserve an overlap between ’real’ and ’generated’ data discriminator scores distributions, centeredaround 0.5 with low discrimination variance. We also passed random noise to the discriminator tovalidate it - ’random’ label.(d) Training progression of generated mid price returns.
Figure 2: (a) Historical distributions of mid price returns. (b,c) Training progression of 1- and 10-minute mid price return distributions.(d,e,f) Training progression of volume/volatility correlation(d) We visually observe diversity of generated pricetime series with training progression.
Figure 5: Average discriminator score heatmap visualization of parameter optimization procedurewith respect to the number of noise and value agents. For each noise and value agent configurationon the rectangular grid, we run 20 simulations with different seeds for initialization of pseudo-random number generator. Lighter colors correspond to higher discrimination score - hence, morerealistic simulator configuration.
Figure 6: Comparison of distributions of 1-minute mid price returns for historical and simulatedtime series with N noise agents and M value agents.
Figure 7: Comparison of distributions of 10-minute mid price returns for historical and simulatedtime series with N noise agents and M value agents.
Figure 8: Comparison of distributions of volume/volatility correlations for historical and simulatedtime series with N noise agents and M value agents.
Figure 10: Generative adversarial network architecture with self-attention.
Figure 11: Generative adversarial network architecture without self-attention (used for the ablationstudy). The punctured lines represent dropout layers.
