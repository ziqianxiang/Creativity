Figure 1: Example images (top row) and the class-wise patterns (bottom row) learned by a ResNet18on CIFAR-10 (left three columns) and ResNet-50 on ImageNet (right three columns) and revealedby our method. The 3 ImageNet classes are “n02676566”(“guitar")，“n02123045”(“cat")，and“n03874599” (“padlock"). The pattern size is set to 5% of the image size.
Figure 3: Left: mean predictive power of the class-wise patterns of different sizes, over all 10CIFAR-10 classes and 50 randomly selected ImageNet classes. Middle: mean predictive power ofthe patterns found with different types of canvases on CIFAR-10. Right: mean predictive powerof the patterns found with different types of canvases on ImageNet. The patterns are searched onResNet-50 models trained on clean CIFAR-10 and ImageNet.
Figure 4: Patterns (second row) found by our method on different types of canvases (the first row)for CIFAR-10 “ship” class (left) and ImageNet “hook”(“n03532672")class (right).
Figure 5: Left grid: input image (first column), attention map (second column) and images (thirdcolumn) attached with high attention patterns extracted from the input image. Right plot: the meanpredictive power of high attention patterns over 50 ImageNet target classes. The attention patternsize is 10% of the image size.
Figure 6: A comparison of the class-wise patterns revealed on naturally trained ResNet-50 modelsby universal adversarial perturbation (UAP), our method and our method with the total-variation(TV) regularization (defined in Equation 3). For our methods, the pattern size is set to 5% of theimage size, while UAP perturbs the entire (i.e. 100%) image. The top and bottom two rows showthe patterns for two CIFAR-10 and ImageNet classes, respectively.
Figure 7: Left: Backdoor trigger patterns recovered by our method from a backdoored (by BadNetswith target class “airplane”) ResNet-50 model on CIFAR-10 using different canvas images.The trig-ger pattern is a black-white checkerboard at the bottom right corner of the image. Middle: The mean(over all 10 CIFAR-10 backdoor target classes) predictive power of 1) the recovered trigger patternon the backdoored model (Pbackdoor on fbackdoor), and 2) the same size of natural pattern on naturalmodel (Pnatural on fnatural) Right: The transferability of the patterns revealed for clean ResNet-50models. The transfer rate is defined as PWsource/PWtarget, the ratio between the predictive poweron the source and the target model. The patterns are searched on the source model.
Figure 8: Examples of class-wise patterns learned by ResNet-50 and revealed by our method onnatural (D), nonrobust (DNR) and robust (DR) data on CIFAR-10, as well as adversarially trainedmodel (AdvTrain) on CIFAR-10. Pattern size is 10% of the image size.
Figure 9: Class-wise patterns found by our method on CIFAR-10 at pattern size 5%. We show thepattern for each of the 10 CIFAR-10 classes. The predictive powers of these patterns are reported inTable 1. Positive canvases are used.
Figure 10: Class-wise patterns found by our method on ImageNet at pattern size 5%. We only showthe pattern for 20 out of the 50 tested ImageNet classes. The predictive powers of these patterns arereported in Table 2. Positive canvases are used.
Figure 11: Left grid: Patterns found by our methods under different nontarget-class subset size (%to the test set), for “airplane” and “deer” classes in CIFAR-10. Right plot: The mean predictivepower of the class-wise patterns on CIFAR-10. The pattern size is fixed to 5% of the image size.
Figure 12: Mean predictive power (mPW) of the class-wise patterns found by our method over all10 CIFAR-10 classes or 50 randomly selected ImageNet classes for naturally trained ResNet-50models. The mPW is shown for each of the 4 sampling strategies: random, positive, negative andwhite. The pattern size varies from 0% to 10% of the image size.
Figure 13: Class-wise patterns revealed by our method using different canvases (e.g. two positive,one negative, one random and one white canvases) on CIFAR-10 for a naturally trained ReSNet-50.
Figure 14: Class-wise patterns revealed by our method using different canvases (e.g. two positive,one negative, one random and one white canvases) on ImageNet for a naturally trained ReSNet-50.
Figure 15: A comparison of the class-wise patterns revealed for naturally trained ResNet-50 modelsby universal adversarial perturbation (UAP), our method and our method with the total-variation(TV) (Fong & Vedaldi, 2017) regularization (defined in Equation 3). For our methods, positivecanvas is used and the pattern size is set to 5% of the image size. UAP perturbs the entire (i.e. 100%)image. e parameter is the maximum perturbation constraint for UAP, while β is the parameter forTV regularization. The top and bottom 3 rows show the patterns for 3 CIFAR-10 and ImageNetclasses, respectively.
Figure 16: Backdoor patterns revealed by our method for different backdoor triggers. The back-doored ResNet-50 model is trained on CIFAR-10 and poisoned by BadNets towards the target class“airplane”. The pattern size is set to 1% of the image size, and the patterns are searched based on20% of the test set. Both positive and white canvases are used. Data augmentation means the back-doored model was trained with data augmentation techniques. For the data augmentation setting, Wealso use the negative canvas (the middle column in the left panel).
Figure 17: The attention (visualized by Grad-CAM) shift of a ResNet-50 model (on ImageNet) whenour class-wise pattern is attached to different images. The pattern is from “n01440764”(“tench")In the above objective, there are two different types of variables that need to be optimized at the sametime: the mask m and the canvas x「To tackle this, we apply an alternating optimization strategyas follows. We update the mask and the canvas each for 5 steps alternatively with step size 2/255for the canvas and step size 0.02 for the mask. The same normalization and clipping techniques areused here as in our original method. We use positive sampling to select the initial canvas image andset the pattern size to 5% of the image size. The patterns are searched for based on 20% of the testset images. We compare side-by-side the patterns revealed by the two methods in Figure 18.
Figure 18: A comparison of the class-wise patterns revealed by our method and an learned canvasversion of our method (defined in Equation 4) for naturally trained ReSNet-50s on CIFAR-10 andImageNet. The pattern size is fixed to 5% of the image size. The first row shows the patterns foundby the original method, while the learned canvas and the revealed patterns are shown in the secondand third rows respectively.
