Figure 1: The overview of Algorithm 1 and Algorithm 2. Algorithm 1 takes front and rear cameradata as input to identify the important azimuth blocks. Algorithm 2 samples radar data based onazimuth from images and the previous radar frame.
Figure 2: The figure above is from Scene 1, frame 2. In the top row, we show the front image dataand rear image processed by the 2D object detection network. The original radar corresponds to theraw radar data acquired in the scene. The green box on the radar data, when zoomed in, would showthe person to the left on the front camera. The person is not visible on the baseline reconstructionsbut can be seen in our reconstruction. The orange box highlights the truck on the rear image.
Figure 3: The figure above is from Scene 3, frame 3. The green box when zoomed in shows thecar passing by to the right of the autonomous vehicle right below the front bus and radar returnsfrom the wall. The orange box highlights the car behind the autonomous vehicle, captured by ouralgorithms and missed by the baselines.
