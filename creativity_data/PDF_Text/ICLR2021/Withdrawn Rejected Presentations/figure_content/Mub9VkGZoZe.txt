Figure 1: Four 2D-projections of the distribution of latent variables (z, ). Projection (i, j) meansthe 2D-projection to the i-th and j-th dimension. (0, 1) are the informative latent variables z.
Figure 2: Four 2D-projections of the data x = f (z, ).
Figure 3: Performance of the VAR criterion and the MI criterion on the informative latent variablesidentification on synthetic data. a) The distribution of the 2 features with the largest variances; b)The standard deviations of the 10 features (black) of w and the 10 true latent variables (grey) indescending order. The numbers are the indices of features for convenience of comparison. c) Thedistribution of the 2 features with the largest mutual information with U. d) The mutual informationof the 10 features (black) of w and the 10 true latent variables (grey) in descending order.
Figure 4: Performance on synthetic data classi-fication: MI criterion vs VAR criterion. The x-axis represents the number of features selectedfor the PS (y | x) calculation according to theMI and VAR criterion respectively; the y-axisfor the accuracy. The asymptotic bound is thetheoretical upper bound for the classification ac-curacy. 2 subfigures show 2 different trials.
Figure 5: Left: The illustration of out-of-distribution samples (in red, from a mixtureof two Gaussians) samples from ground truthGaussian mixture in the latent space projectedto the informative dimensions. Right: The AU-ROC values for different number of features se-lected by the MI criterion and the VAR criterionrespectively.
Figure 6: Left: the classification accuracy on EMNIST-digits ofthe MI criterion and the VAR criterion with different possible toptruncation within the full range. Right: the decay curves of mu-tual information and standard deviation of the estimated latent.
Figure 7: The ROC curves usingthe density value (on the learnedGaussian mixture) as thresholdfor outlier detection task, MI30versus VAR300.
Figure 8: a) Ground truth informative latent dims. b) The top-2 features in w by the VAR crite-rion. c) Standard deviations of zi’s and wi ’s. d) The top-2 features by the MI criterion. e) Mutualinformation of zi ’s and wi ’s.
Figure 9: Four examples of correlation between ground truth latent (by rows), including both infor-mative and noise dimensions, and estimated latent (by cols) of four different trained GIN models.
Figure 10: An example of GIN trained with empirical distribution parameters with high noise level.
Figure 11: An example of GIN trained with empirical distribution parameters with low noise level.
Figure 12: All 45 possible 2D-projections of the 10 dimensional latent (z, ) used in Section 3.
Figure 13: All 45 possible 2D-projections of the 10 dimensional observation f(z, ) used in Section3.
Figure 14: All 45 possible 2D-projections of the 10 dimensional estimated representation w used inSection 3.
