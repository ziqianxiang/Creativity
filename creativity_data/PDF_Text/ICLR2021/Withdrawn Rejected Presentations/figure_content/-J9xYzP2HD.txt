Figure 1: Chameleon Pipeline: Chameleon aims to encode tasks with different schemas to a shared representa-tion with an uniform feature space, which can then be processed by any classifier. The left block represents tasksof the same domain with different schemas. The middle represents the aligned features in a fixed schema.
Figure 2: The Chameleon Architecture: N represents the number of samples in τ , Fτ is the number of featuresin τ , and K is the number of features in the desired feature space. “Conv(a × b × c)” is a convolution operationwith a input channels, filter size of b and kernel length c.
Figure 3: Accuracy improvement for each method over Glorot initialization (Glorot & Bengio, 2010): Thedifference is plotted in negative log scale to account for the varying performance scales across the differentdatasets (higher points are better; A value of -1 is equivalent to the Glorot initialization). The graph (a)represents Split experiments while (b) depicts the No-Split experiments. Notice that the oracle has been omittedfrom the Split experiments since there is no true feature alignment for unseen features. The dataset axis is sortedby the performance of reptile on the base model to improve readability. All results are averaged over 5 runs.
Figure 4: Critical Difference Diagram for Split (Left) and No-Split (Right) showing results of Wilcoxonsigned-rank test with Holm’s alpha correction and 5% significance level. Models are ranked by their performanceand a thicker horizontal line indicates pairs that are not statistically different.
Figure 5: Latent embedding results. Meta test ac-curacy on the EMNIST-Digits data set while trainingon EMNIST-Letters. Each point represents the ac-curacy on the 1600 test tasks after performing threeupdate steps on the respective training data. Resultsare averaged over 5 runs.
Figure 6: Heat map of the feature shifts forthe Wine data computed with chameleon af-ter reordering-training: The x-axis represents thetwelve features of the original dataset in the correctorder and the y-axis shows which position these fea-tures are shifted to when presented in a permutedsubset.
Figure 7: Snapshots visualizing the inner training. Validation cross-entropy loss for a task sampled from thewall-robot-navigation data set during inner training starting from the current initialization (blue) and randominitialization (red).
