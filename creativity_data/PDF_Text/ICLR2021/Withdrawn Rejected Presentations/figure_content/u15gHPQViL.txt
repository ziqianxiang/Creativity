Figure 1: Zero-shot learning paradigms. (a) Conventional visual-to-semantic mapping trained onclassification loss. (b) Another interpretation of visual-to-semantic mapping between visual andsemantic representations. (c) The proposed IGSC, aiming to learn the correspondence between animage and a semantic classifier.
Figure 2: The architecture of IGSC. This model receives an image and a label, and it returns thecompatibility score of this input pair. The score indicates the probability of the label belonging tothe image. The score is calculated by a label classifier g(âˆ™), whose weights M are stored in theoutput layer of a fully connected neural network. Therefore, weight values depend on the inputimage. The neural network is characterized by the parameters W, which are the only parametersrequired to learn from training data.
Figure 3: t-SNE visualization of the model space learned by IGSC: (a) seen classes, (b) unseenclasses. Best viewed in color.
