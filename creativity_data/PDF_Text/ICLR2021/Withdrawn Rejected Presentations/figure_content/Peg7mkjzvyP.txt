Figure 1: iPTR overview3	Program RepresentationTo retrieve a promising program translation from a large code database, iPTR needs an effectiveand efficient query. Directly retrieving based on raw code is impractical. In contrast to existingmethods that generate queries based on either keywords (Linstead et al., 2009) or preset metrics andquestions (Martie et al., 2015), iPTR generates a feature representation that effectively combinesstructural properties of the program and textual features. It further uses a query transformationmodel (QTM) to generate features in the target language.
Figure 2: Program representationOne can also use control flow graph (CFG) that captures the dependence between code basic blocksand procedures to represent the code behavior. However, our goal is to support program transla-tion for any granularity of program, code behavior is hard to measure when the code fragment isnot a complete code block. Further CFG is much more difficult to construct than syntax trees. Assyntactical similarity also plays a significant role, we pick syntax trees as the basis of our represen-tation to also capture the low-level syntactic structure within code blocks. One can also combineCFG and syntax trees to reserve more information. However this would trade-off the simplicity ofthe retrieval query. We show that with analysis of the static AST features we already achieve highprogram accuracy. The syntax tree can be either a concrete syntax tree (CST) or an abstract syntaxtree (AST) (Alon et al., 2018; 2019; Chen et al., 2018). A CST depicts nodes with complete struc-tural information, such as all the tokens in the code while the AST is more abstract and only displaysstructural or content-related details. For more details on CSTs and ASTs, we provide examples inthe Appendix A.2.
Figure 3: Query transformation model (QTM)Since there is no available training data forQTM, we leverage an unsupervised method - au-toencoder (AE) to train the encoder and the de-coder. An AE is an encoder-decoder that aims to reproduce its input. That is, it encodes the input to ahidden vector, then reconstructs the input from this hidden vector. In iPTR, we exploit this propertyto learn the weights of the encoders and decoders separately. As shown on the right of Figure 3, inthe offline phase, for each programming language Li in the database IPTR trains a separate AEi onall programs that are written in this language. Thus it obtains a pair of Encoderi and Decoderi foreach programming language. For the actual translation task, we combine the appropriate encoderand decoders depending on the source and target language of a translation task. We can see in theQTM in Figure 3, it selects the encoder Encoders of the source language Ls from AEs , which istrained in offline phase, to transform Fs into the hidden layer representation. And it picks the traineddecoder Decodert of the target language Lt from AEt to estimate the Ft . This way, we can builda pretrained model with an encoder that learns significant information from the feature vector of theinput program and an decoder that can generate features of its translation.
Figure 5: Required amount of user feedback5.3	Influence of User CorrectionsIn Table 1, we showed the influence of a singleuser correction on the result. We further investigatethe number of user corrections required in order toretrieve the correct translations. We simulate userswith the ground truth in our parallel dataset and foreach returned result we fix the first different linebetween true result and returned result.
Figure 6: CST and AST of a simple JavaScript programThe structure of a program can be described by a syntax tree where each tree node denotes a con-struct occurring in the code, e.g., if_stmt in Python denotes an if construct. The tree can beeither a comprehensive CST or a more abstract AST. CST is a tree representation of the gram-mar (rules of how the program should be written). It represents the source program exactly in parsedform. In other words, it defines the way programs look like to the programmer. There is an examplein Figure 6. The CST of the simple JavaScript program is verbose with all the detail informationabout parsing the code. It keeps all the tokens in the program and their types, such as literal11Under review as a conference paper at ICLR 2021! JavaScript ProgramI if ( dataExample == 0.1 ) {type_example = 'real number' ；}ParsingCSTsingleExpressionif ( expressionsequence{ StatementList }statementstatementifStatement
Figure 7: Generating simplified syntax treeand identifier. And it reveals all the grammar rules, such as equalityExpression:singleExpression == singleExpression. On contrary, AST is a tree representationof the abstract syntactic structure of source code. Each node of the tree denotes a construct occur-ring in the source code. The syntax is ”abstract” in the sense that it does not represent every detailappearing in the real syntax, but rather just the structural or content-related details. It defines the waythe programs look like to the evaluator/compiler. As shown in Figure 6, the AST directly shows theequal structure without any detail information. It discards the intermediate structural informationthat would not contribute to semantics.
Figure 8: An example of user feedbackTable 4: Statistics of the real-world datasetSiZe Files Lines	MethodS/Functions3.8GB	280,128	75,567,192	2,023,546	―A.5 Experiment on a Large Real-world DatasetDataset. We choose the four programming languages with the most pushes on github - JavaScript,Python, Java, and C++. They are also representative of programming languages with different char-acteristics. Based on the number of stargazers, we pick 1% files in these four languages fromPGA to be our raw dataset. Theoretically, iPTR works for programs of any length, but consideringthe practical value and the intuitiveness of the validation process, we aim to translate programs atmethod level in our experiment. Longer programs whose complete translations are not existing inthe database can be translated by merging translations of each part. We split all the files into meth-ods or functions as the input/output of iPTR. One limitation of PGA is that there are duplicate filesacross different repositories. To ensure the quality of the dataset and increase the efficiency of ourprogram translation task, we gradually remove duplicates at file level by taking hashes of these pro-grams and comparing their hashes. In addition, we also remove the data that cannot be successfullyparsed due to format, errors, version compatibility or other issues. Since our approach does notrequire additional explanation except the program itself, we remove annotations and descriptions.
