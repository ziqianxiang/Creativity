Figure 1: Visualization of qualitative differences between GP and MOGP prediction. Top: GP,Bottom: 18-MOGP. Dataset is separated into training (green) and validation (blue). Posterior beliefof the saliency is visualized as predictive mean (red line), and 95% confidence interval (error bar).
Figure 2: Comparing dynamic penalty scaling vs. static on pruning a 32-convolutional filter layer ina CNN. Dynamic penalty scaling encourages gradual pruning across a wide variety of settings of Î».
Figure 3: Convolutional filter saliency over 150 epochs of SGD on CIFAR-10.
Figure 4: Function samples drawn from the exponential kernel.
