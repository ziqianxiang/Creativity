Figure 1: The comparison between a standard loss system (left) and our proposed compositional loss system(right). σ shows the softmax function span over all the network output logits. σold and σnew shows softmaxspan over the set of old and new class logits respectively.
Figure 2: The effect of overfitting on class-IL performance and its correlation with secondary information,on the CIFAR-100 dataset. Figure (a) shows the overfitting behavior as the validation loss (red curve) startsincreasing after the 100th epoch. The class-IL performance decreases monotonically (green curve). Table (b)shows the performance of the snapshots taken at every 100th epoch. SS-Acc decreases and SS-NLL increasesas more overfitted models are evaluated. Forgetting rates F and Fφ also correlate with overfitting.
Figure 3: (a) compares the average L2 norm of the classification weight vectors for old and new classes. Weevaluate standard combined softmax (Comb) against proposed separate softmax (Sep) and we assess the effectof reduced learning rate (LowLR). (b) contains the corresponding class-IL results without distillation (KD) interms of average accuracy and forgetting rate. All experiments use the linear classification layer. Results shownon CIFAR-100.
Figure 4: Effect of regularizers on the distance between mean class representations. The numbers shown in theplot are the ratios between the class means distances of each method and of the default CCIL model. Similarclasses are marked in bold. Dotted circle at 1.0 depicts distances between classes in the baseline CCIL modeland other distances are depicted relative to the baseline model. Positive and negative cases indicate similar anddissimilar classes respectively.
Figure 5: Representations learned using different regularization methods. Top-Bottom: Baseline CCIL , CCIL+ mixup, CCIL + label-smoothing. Left and right columns show the representations on the training set andvalidation set respectively. Visualization is based on 50 classes of CIFAR-100, where each color is a differentclass.
Figure 6: Representations learned using different regularization methods. Top-Left - Bottom-Right: baselineCCIL , CCIL + Self-distillation, CCIL + Heavy-augmentation. Left and right columns show the representationson the training set and validation set respectively.Visualization is based on 50 classes of CIFAR-100, where eachcolor is a different class.
