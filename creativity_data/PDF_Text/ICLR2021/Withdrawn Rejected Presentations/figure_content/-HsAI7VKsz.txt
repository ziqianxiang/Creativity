Figure 1: Illustration of the main idea. (a) SOLO (Wang et al., 2019) learns a mapping function withfully convolution network for predicting location-specific object masks; the predictions at neighbor-ing locations can be similar but do not contribute to the final result. (b) The proposed AggMaskaims to exploit the neighboring predictions by aggregating them in a learning-based fashion. Mean-while, by back-propagating through the aggregation function, the mapping function instead learns togenerate local shape descriptors (mask representations) that encode shape and layout information ofnearby objects and complement each other in combination, so as to generate mask of higher quality.
Figure 3: Network Architecture. For objects at different locations, their corresponding spatiallyneighboring mask representations are gathered and aggregated to form the segmentation. The frame-work is fully convolutional and end-to-end trained. Note with mask interpolation, the grid resolutionof mask representation (G0) can be smaller than classification (G) to save computation and memory.
Figure 4: Flop reduction by mask interpolation.
Figure 5: Visualization of mask representations. Compared to baseline SOLO mask prediction, wefind our mask representations 1) have larger high-response area, indicating it attends to surround-ing context; and 2) capture complementary information, e.g., in addition to the monitor, ‘a’ hasattention on the lamp, while ‘b’ and ‘c’ attends to the desk and people respectively. The quality ofsegmentation is higher than the baseline model and simply refining with the voting algorithm.
Figure 6: Example results of Mask R-CNN, SOLO and AggMask. Right three columns are zoom-inviews of yellow rectangle areas, showing that AggMask can handle severe occlusions in crowdedscenes (a), it also more accurately segment large objects benefited from the aggregation (b).
