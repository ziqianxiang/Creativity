Figure 1: A hypothetical pool of STM and LTM centroids visu-alized at seven time instants. From ta to tb , a centroid is movedfrom STM to LTM after it has been selected θ times. At time tb ,unlabeled examples from classes ‘2’ and ‘3’ first appear, triggeringnovelty detection and new centroids are created in STM. Thesecentroids are moved into LTM by td. From td to tg, the pool ofLTM centroids remains the same because no new classes are seen.
Figure 2: An example of the classification process. Everypatch (at any layer) that selects a CIN centroid votes for thesingle class that has the highest association with. These patchvotes are first averaged at each layer. The final inference isthe class with the highest cumulative vote across all layers.
Figure 2):m∈Ml vl,mVl (k ) = -M—	⑹where Ml is the set of patches in layer l . The final inference for input x is the class with the highestcumulative vote across all layers:Λk(x) =arg maxk0vl(k)l=1(7)5 EvaluationTo evaluate the STAM architecture in the UPL context, we consider a data stream in which smallgroups of classes appear in successive phases, referred to as Incremental UPL. New classes are4Under review as a conference paper at ICLR 2021introduced two at a time in each phase, and they are only seen in that phase. STAM must be able toboth recognize new classes when they are first seen in the stream, and to also remember all previouslylearned classes without catastrophic forgetting. Another evaluation scenario is Uniform UPL, where
Figure 3: Clustering accuracy for MNIST (left), SVHN (left-center), CIFAR-10 (right-center), and EMNIST(right). The task is expanding clustering for incremental UPL. The number of clusters is equal to 2 times thenumber of classes in the data stream seen up to that point in time.
Figure 4: Classification accuracy for MNIST (left), SVHN (center), CIFAR-10 (right-center), and EMNIST(right). The task is expanding classification for incremental UPL, i.e., recognize all classes seen so far. Notethat the number of labeled examples is 10 per class for MNIST and EMNIST and 100 per class for SVHN andCIFAR-10.
Figure 5: STAM Incremental UPL evaluation for MNIST (row-1), SVHN (row-2), EMNIST (row-3) andCIFAR-10 (row-4). Per-class and average classification accuracy (left); fraction of CIN centroids over time(center); number of LTM centroids over time (right). The task is expanding classification, i.e., recognize allclasses seen so far.
Figure 6: Ablation study: A STAM architecture without LTM (left), a STAM architecture in which the LTMcentroids are adjusted with the same learning rate α as in STM (center), and a STAM architecture with removalof layers (right)recently seen. We also investigate the importance of having static LTM centroids rather than dynamiccentroids (Fig. 6-middle). Specifically, we replace the static LTM with a dynamic LTM in whichthe centroids are adjusted with the same learning rate parameter α, as in STM. The accuracy suffersdrastically because the introduction of new classes “takes over" LTM centroids of previously learnedclasses, after the latter are removed from the stream. Similar to the removal of LTM, we do not seethe effects of “forgetting" until phases 3-5. Note that the degradation due to a dynamic LTM is lesssevere than that from removing LTM completely.
