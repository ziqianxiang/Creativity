Figure 1: Two games from our multitask domain Messenger where the agent must obtain the mes-sage and delivers it to the goal (white dotted lines). The same entities may have different roles indifferent games which are revealed by the text descriptions.
Figure 3: Entities andtheir subdivision into hu-man, nature and fantasysub-worlds. Each K3subgraph is a combina-tion of entities that mayappear during training.
Figure 4: G-ID model(6)3)	Bayesian Attention Module (BAM) This baseline uses a hard-attention mechanism with anaive Bayes classifier trained to learn M. This approach is similar to a word alignment model usedin machine translation approaches such as the IBM Model 1 (Brown et al., 1993). Specifically, forsome set of observed entities E0 ⊆ E in the current environment:BAM(z, E0) = argmaXP(e|z)e∈E0P(z|e) =	P (t|e)	P (t|e)C (B	(7)Pt，C(t0,e)()6Under review as a conference paper at ICLR 2021where t ∈ z are tokens in z, t0 is any token in the manual vocabulary and C refers to co-occurencecounts. We use Bayes’ rule to flip the conditional. We let xe = vz from equation 2 for the z thatmaps to e. If two descriptions map to the same entity, we take the one with higher P(e|z), andif an entity receives no assignment we represent it with a learned default embedding Emb(e). Wepretrain BAM on 1.5 × 106 episodes.
Figure 5: Average episodic rewards on S1 (left) and S2 (middle) on training (solid line) and valida-tion (dotted line) games, as a function of training steps (x-axis). Reward is a combination of bothsingle and multi-combination games. EMMA-(no curriculum) denotes EMMA trained directly on S2.
Figure 6: Attention weights for EMMAcomputed from equation 3. Each rowshows the attention weights for one en-tity over 12 randomly selected descrip-tors, each of which describe a separateentity indicated by the column label.
Figure 7: Average episodic rewards on S1 (left) and S2 (right) on training (solid line) and validation(dotted line) games, as a function of training steps (x-axis) for both EMMA and EMMA-σ. Both modelsare able to perform well, however, EMMA is able to obtain a good validation reward faster. All resultsare averaged over three seeds and shaded area indicates standard deviation.
Figure 8: Average episodic rewards on S1 games with negation (left) and neutral entities (right)on training (solid line) and validation (dotted line) games, as a function of training steps (x-axis)for both EMMA and EMMA-σ. Both models struggle on negation, but EMMA is able to perform wellwith neutral entities. All results are averaged over three seeds and shaded area indicates standarddeviation.
