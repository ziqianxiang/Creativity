Figure 1: Leaked magnetic signal. (left) Our induction sensor captures a magnetic signal whena CNN is running on the GPU. We observe strong correlation between the signal and the networksteps. Across two steps, the GPU has to synchronize, resulting in a sharp drop of the signal level(highlighted by selected red circles). (right) We can accurately classify the network steps and re-construct the topology, as indicated by the labels under the x-axis. Here we highlight the signalregions associated with convolutions (conv), batch-norm (BN), Relu non-linear activations (relu),max-pooling (MP), and adding steps together (add).
Figure 2: Placement of the magnetic induction sensor on the power cord works regardless of theGPU model, providing a common weak-spot to enable current-based magnetic side-channel attacks.
Figure S1:	The modelâ€™s classification accuracy drops as its Levenshtein distance from the originalmodel (model A: AlexNet) increases.
Figure S2:	Distribution of normalized Levenshtein distance. (left) We plot the distribution ofthe normalized Levenshtein distances between the reconstructed and target networks. This results,corresponding to Table 1 in the main text, use signals collected on Nvidia TITAN V. (right) We alsoconduct similar experiments on two Nvidia GTX-1080 GPUs. One is used for collecting trainingsignals, and the other is used for testing our side-channel-based reconstruction algorithm.
Figure S3:	Here we plot the resulting signals from the same network model deployed on two differ-ent instances of a NVIDIA-GTX 1080 (running on two different computers). In the green boxes onthe left are the spikes that we inject on purpose (discussed in Sec. 4.2) to synchronize the measuredsignal with the runtime trace of the GPU operations.
