Figure 1: (A) Overview of the training setup for our final model. The masker is trained to maximizemasked-in classification accuracy and masked-out prediction entropy. (B) Masker architecture. Themasker takes as input the hidden activations of different layers of the ResNet-50 and produces a maskof the same resolution as the input image. (C) Few-shot training of masker. Performance drops onlyslightly when trained on much fewer examples compared to the full training procedure.
Figure 2: Varying the masking objective for a fixed classifier (FIX) and classifier-agnostic (CA)settings. Top: Examples of masked-in inputs and masks. The CA models generally produce morecontiguous masks, and combining both a masked-in and masked-out objective works best based onquantitative evaluation. Bottom: Distribution of mask pixel values across Train-Validation set. Wequantize the values into 10 buckets in the bar plot in blue and also show the empirical CDF in red.
Figure 3: Examples of varying the layers of classifier activations that the masker takes as input, fromLayers 1 (closest to input) to 5 (closest to output). Each column is from a separately trained model.
Figure 4: Our saliency maps pass recently proposed sanity checks. Left: RemOve-And-Retrainevaluation from Hooker et al. (2018). We train and evaluate new ResNet-50 models based on trainingimages with the top t% of most salient pixels removed. Removing the most salient pixels hurts thenew classifierâ€™s performance, and the CA model is more effective at removing salient information.
Figure 5: Training the saliency map models (CA) using fewer examples per class and/or fewerclasses out of the 1000 in the training set. Results reported are the median over 5 runs with differentsamples of examples. Lower LE and higher PxAP are better. Models can be trained to generate goodsaliency maps with a surprisingly few number of training examples. For comparison, the LE andPxAP for the fully trained CA model are 35.8 and 59.4 respectively.
Figure 6: Saliency maps using various infilling methods for counterfactual generation. FollowingChang et al. (2019); Agarwal & Nguyen (2019), we infill masked out portions of the image andprovide the resulting infilled image to the classifier. Infillers are hypothesized to help training bymaking the classifier inputs look closer to natural images as well as forcing the masker to mask outall evidence of a salient object. FIX indicates a fixed classifier, CA (Classifier-Agnostic) indicatestraining against a pool of continually trained classifiers. We do not find quantitative improvementsfrom incorporating an infiller.
Figure 7:	We apply the Gumbel-Softmax trick to train the masker to produce binary masks, infillingusing the CA-GAN. As seen in Figure 2, most models in our experiments produce mask pixel valuesof 0 or 1, so the benefits of explicitly learning a discrete output distribution are limited.
Figure 8:	Training the saliency map models (FIX) using fewer examples per class and/or fewerclasses out of the 1000 in the training set. Results reported are the median over 5 runs with differentsamples of examples. Lower LE and higher PxAP are better. Models can be trained to generate goodsaliency maps with a surprisingly few number of training examples.
Figure 9: Examples of saliency maps computing from models trained with less data. Columnscorrespond to the models shown in Figure 5 and Figure 8. Even models trained with very fewexamples per class produce saliency maps similar to the fully trained model.
