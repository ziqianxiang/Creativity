Figure 1: (a) Overview of our framework consisting ofa segmenter and a classifier. The segmenter isa modified version of U-Net. The input of the classifier is the element-wise production of the originalECG segment and the attention map generated by the segmenter. The tuple alongside every cuboidrepresents (number of channels, length of data) for the feature maps. (b) The detailed architectureof the classifier. Following a 1D point-wise convolutional layer are four convolutional blocks, eachcontaining two combinations of Conv + BN + ReLU. GAP stands for global average pooling whileMLP stands for a two-layer perceptron. The elements in the tuple represent channel number anddownsample ratio respectively.
Figure 2: (a) Training loss curve, (b) validation loss curve and (c) validation accuracy curve for theclassifier only method (Classifier), cascaded segmenter and classifier (Cascaded), our methods withReLu and max pooling (Max), and with L2 norm pooling (L2 norm) on (LVOT, RVOT) task. Thereis a clear overfitting for the cascaded segmenter and classifier method.
Figure 3: Visual examples of the segmentation results on (a) our dataset and (b) Mn-BIH Arrhyth-mia dataset. The columns represent different cases. For (a), in the original ECG, the abnormal beatsoccur simultaneously in all the 12 leads and are only marked on the first one. Regarding the heatmap of the attention, the warmer an area is, the larger the attention weight is.
Figure 4: Illustration of the three classes in grade study. In class I, all abnormal beats are identifiedand all normal beats are removed. In Class II, all abnormal beats are detected, though some normalbeats are also included. In Class III, no significant difference can be found between abnormal andnormal beats.
Figure 5: Comparison of classification performance and grade study result for different kernel sizewith respect to differentiating RVOT and LVOTanalysis in Section 3.3. After weighing interpretbility and performance, we choose the kernel sizeof 200.
