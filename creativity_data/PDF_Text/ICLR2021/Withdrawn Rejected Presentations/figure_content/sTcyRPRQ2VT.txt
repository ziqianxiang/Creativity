Figure 1: Example of a KG and its respective domainâ€™s metragraphThe domain definition , here defined as a metagraph having entity types as nodes and relation typesas edges, is usually performed by subject matter experts. Yet, KG construction by expert curationcan be extremely slow as the process, in this case, is essentially manual. Moreover, human errormay affect the data quality and lead to malformed KGs. In the context of this work, we propose toovercome these issues by introducing an automated machine learning-based approach to understandthe domain of a given corpus. Specifically, we introduce a seq2seq-based model to infer the relationtypes characterizing the domain of interest. Equipped with this model, we can define the structureof the domain including all the needed entity and relation types that should be included in the graphin an automated manner and then utilize only the appropriate tools, such as specific entity andrelation extractors, to populate the actual KG. We train such model using previous examples of textsnippets and the respective relation types that are included in them. We show that our proposedmodel outperforms other baseline approaches and provide us with the needed high precision andrecall combination for an accurate domain definition.
Figure 2: Architecture of our utilized Transformer model.
Figure 3: Metagraph (left) and the KG (right) extracted from 12 text snippets related to the UnitedStates using our model and the respective attention analysis. The colors in the nodes/edges mean thefollowing: green exists in both actual and predicted graphs, orange exists in the actual but not in thepredicted graph, pink exists in the predicted but not in the actual.
Figure 4: Histogram that depicts the number of instances that hold the respective number of relationtypes the for NYT datasetTable 5: Performance of CNN, RNN and Transformer-based methods on instances from NYTdatasets with more than 1 relation in them. *The architecture of the CNN and RNN models hasbeen modified to exclude the component which provides information about the position of the enti-ties in the text snippet.
Figure 5: Number of appearances of the relation types in the DocRED datasetTable 6: Comparison of CNN, RNN and Transformer-based methods on WebNLG, NYT and Do-cRED datasets for the relation type extractiont task. *The architecture of the CNN and RNN modelshas been modified to exclude the component which provides information about the position of theentities in the text snippet.
Figure 6: Performance of the Trasnformer ensemble variant in the three datasets. For each dataset,it is utilized as many Trasnformers as the number of different entity types and is examined theperformance of the ensemble method for different cut-off limits c. The value of c indicates howmany transformers at least should have predicted a specific relation in order to include in the finalpredictions set.
