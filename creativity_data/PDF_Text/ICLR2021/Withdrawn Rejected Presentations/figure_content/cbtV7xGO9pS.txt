Figure 1: Performance comparisons on six MuJoCo tasks trained for 3 million timesteps. Thehorizontal axis indicates number of environment steps. The vertical axis indicates the averagereturn. We trained three different instances of each algorithm with different random seeds, witheach instance performing an evaluation every 4,000 environment steps. The solid lines representthe mean and the shaded regions mark the minimum and maximum returns over the three trials. Weset η as the negative of action space dimension of the task, and set τ = 0.005 for all tasks.
Figure 2: Performance with different τ on six MuJoCo tasks. τ = 0.001 achieves about 8000 asthe return in Humanoid-v3, and τ = 0.005 achieves about 130 as the return in Swimmer-v3. Thesetwo results surpass all benchmark algorithms significantly.
Figure 3: Performance with different η in three Mujoco tasks with τ = 0.1.
Figure 4: Performance comparisons on six MuJoCo tasks. Notice that the blue line is the perfor-mance of our model which setting different τ with respect to different tasks. In this figure, weset τ = 0.5 for HalfCheetah-v3, τ = 0.05 for Ant-v3, τ = 0.1 for Hopper-v3, τ = 0.001 forHumanoid-v3, τ = 0.005 for Swimmer-v3, and τ = 0.1 for Walker2d-v3.
Figure 5: Performance comparisons on six MuJoCo tasks. We trained six different instances of allalgorithms with different random seeds. In this case, for TEAC, we set η as the negative of actionspace dimension of the task, and set τ = 0.005 for all tasks.
