Figure 1: Conceptual illustration of compositionality and the impact of gradient descent. Xi, X2 areentangled input, andYi, Y2 are entangled output. Yi aligns with Xi, fori = 1, 2. (Left) Compositionalsolution with θA. (Middle) Non-compositional solution with θB. (Right) In parameter space, gradientdescent encourages parameters closer to θB , than θA, hence resisting compositionality.
Figure 2: Extended neural network structure. Middle part is original model structure (one input andone output). Extending with X, X1 , . . . , XK (left) corresponds to entangled input. Extending withY , Y1 , . . . , YK (right) corresponds to entangled output.
Figure 3: Results for both the first (Train/Test A) and second (Train/Test B) settings. In the firstsetting, the training performance increases rapidly (blue), but the test performance (cyan) is notclose to the training one. In the second setting, the training (red) and test (brown) performances areclose. This means that the gradient descent uses the second input to accelerate training, but it lackscompositionality.
Figure 4: Data distribution for binary classification problem for Y1 output. Horizontal axis is X1and vertical axis is X2. Blue circle points are positive samples (Y1 = 1). Orange triangle points arenegative samples (Y1 = 0).
Figure 5: Change of decision boundary for each training step in a binary classification task. In the firsttraining step, X2 (vertical) is helpful for training (step 0), so that the model is updated to cover a partof upper right region as negative (step 1). In the following steps, the loss signals do not completelyremove the negative cover in this region, so that the influence remains in the trained model.
Figure 6: Decision boundaries after 1024 training steps with different random seeds.
