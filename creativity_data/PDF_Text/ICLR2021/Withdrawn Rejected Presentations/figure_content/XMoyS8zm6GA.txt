Figure 1: An illustration of finding a point in the intersection between a random cutting plane ofdimension dcut and a high-confidence manifold of effective dimension dmanifold . If the dcut 'Dinput - dmanifold , there likely exists an intersection between the two. We use optimization froma random point (image) X~0 on the dcut affine subspace to find a point in the intersection usinggradient descent. The panels on the right show an example of the dependence of the probability andloss at the optimized point based on the dcut . The higher dimensional the cut, the less constrainedthe available images X are, and the more likely we are to find one of high class confidence.
Figure 2: Maximum probability of single classes of CIFAR-10 reached on cutting planes of dimen-sion d. The figure shows the dependence of the probability of a single class of CIFAR-10 (y-axes)reached on random cutting hyperplanes of different dimensions (x-axes). The results shown are fora well-trained (> 90% test accuracy) ResNet20v1 on CIFAR-10. Each dimension d is repeated 10×with random planes and offsets, and d5q% is extracted using a fit. The d^。％《3072, which impliesthat the class manifolds are surprisingly high dimensional (3072 - d5。％). Indeed their dimensionsare all in excess of 3000.
Figure 3: An illustration of the way two affine subspaces of dimensions dA and dB can intersecteach other. If the dimension of the space dA + dB ≥ D, the subspaces will likely intersect, whileotherwise they typically do not intersect. If we know D and dA, we can use the existence of anintersection as a tool to bound dB ≥ D - dA .
Figure 4: Distance between randomaffine subspaces - numerical experi-ments vs theory from Eq. 4. The fig-ure compares the distance between twosubspaces of dimensions d & n in a D-dimensional space. The numerical ex-periment in JAX is in blue, theory inred, and numerical fit in yellow.
Figure 5: Left panel: Comparison of the cuttingplane dimension needed to get 50% of the targetclass (d5o%) for two independently initialized andtrained ResNets on CIFAR-10, showing the stabil-ity of our method. Right panel: Comparison ofthe d5o% for SimpleCNN and ResNet on CIFAR-10 and CIFAR-100 with real and randomized la-bels.
Figure 6: Maximum probability and minimum loss (y-axes) of in-between-classes regions ofCIFAR-10 reached on cutting planes of dimension d (x-axes). The results shown are for a well-trained (> 90% test accuracy) ResNet20v1 on CIFAR-10. Each dimension d is repeated 10× withrandom planes and offsets. The last column shows the results for the 10-class region where thenetwork assigns equal probability to each class.
Figure 7: Comparison of the cutting plane dimension needed to get 50% of the target class forResNet trained to 100% training accuracy on subsets of the training set of CIFAR-10 (mean andstandard deviation of two networks). The bigger the training set, the smaller the d5°%, meaning thatits easier to find high confidence images, and that their manifolds increase in dimension. The trendcontinues with the addition of data augmentation (aug).
Figure 8: The effect of cutting plane dimension on model robustness to test-time distortions. The leftpanel shows the error due to Gaussian noise applied at test time vs. cutting plane dimension neededto get 50% of the points to target classes 0 and 1. The right panel shows the effect of the cutting planedimension on error due to corruptions in CIFAR-10-C. Models with lower cutting plane dimensionare more robust to both Gaussian noise and to distortions in the Common Corruptions Benchmark.
Figure 9: The effect of training on the dimension of cutting plane necessary to reach a particularprobability. The two left panels show the maximum probability of class 0 reached for cutting planesof different dimensions (y-axes) for different stages of training of a ResNet20v1 on CIFAR-10 (x-axes). The probability 25% level is highlighted. The right panel shows d2g5% , d5g0% and d7g5% forthe average of all single class regions. We can see an intermediate stage of training when highconfidence regions become hard to find. Towards the end of training, the dimension of the manifoldsgrows. The breakdown by classes is shown in Figure 16.
Figure 10: The effect of model ensembling on the dimension dg。％ needed to reach 50% accuracyaveraged over all CIFAR-10 classes (individual results in Fig. 13) for ResNet20 trained for 50epochs. Across all classes, the larger the ensemble, the higher the d5g0% and therefore the lower theclass manifold dimension. A naive model of addition of codimensions between models is overlayed,showing a surprisingly good fit for small ensembles. The right panels show a section of the inputspace for 3 single models (top row) and 3 ensemble sizes (bottom). The colors indicate 4 differentclasses > 50%. The elongated high-probability structures disappear with ensembling.
Figure 11: The effect of axis alignment of the cutting planes. The figure shows the cutting planedimension necessary to reach 4 thresholds levels (the 4 data lines) of class 0 probability (y-axis)from a random starting point for a well trained ResNet20v1 on CIFAR-10. We vary the number ofnon-zero elements of the basis vectors of the random cutting plane (x-axis). For a small numberof non-zero elements, single pixels are varied, while for a 3072 non-zero elements (the maximumvalue), all pixels are varied jointly. The axis-aligned random cuts require higher dimensions to hitthe same accuracy regions of class 0.
Figure 12: Maximum probability reached on cutting planes of different dimensions for all 10 targetclasses of CIFAR-10 (top row) and CIFAR-100 (bottom row) for a ResNet20v1 trained to 100%training accuracy on randomly permuted class labels. The d5Q% is consistently higher and thereforethe dimension of the high confidence manifolds is lower than for semantically meaningful labels(Figure 2), suggesting geometrically a very different function being learned.
Figure 13: The effect of model ensembling on the dimension dg。％ needed to reach 50% accuracyof all 10 CIFAR-10 classes. The results shown are for ResNet20v1 trained for 50 epochs each. Uni-versally across all classes, the larger the ensemble, the higher the d5g0% and therefore the lower thehigh confidence manifold dimension. A naive model of addition of codimensions between modelsis overlayed, showing a surprisingly good fit for small ensembles.
Figure 14: Maximum probability of single classes of CIFAR-10 reached on cutting planes of dimen-sion d. The figure shows the dependence of the probability of a single class of CIFAR-10 (y-axes)reached on random cutting hyperplanes of different dimensions (x-axes). The results shown are fora well-trained (> 76% test accuracy) SimpleCNN on CIFAR-10. Each dimension d is repeated 10×with random planes and offsets.
Figure 15: Maximum probability of selected single classes of CIFAR-100 reached on cutting planesof dimension d. The figure shows the dependence of the probability of a single class of CIFAR-100 (y-axes) reached on random cutting hyperplanes of different dimensions (x-axes). The resultsshown are for a well-trained (> 67% test accuracy) ResNet20v1 on CIFAR-100. Each dimension dis repeated 10× with random planes and offsets.
Figure 16: The cutting plane dimension needed to reach 25% probability for the 10 classes ofCIFAR-10 as a function of training stage for a ResNet20v1, averaged over two initializations andruns.
Figure 17:	The cutting plane dimension needed to reach 25% probability for the 10 classes ofCIFAR-10 as a function of training stage for a SimpleCNN.
Figure 18:	The cutting plane dimension needed to reach 25% probability for 10 randomly selectedclasses of CIFAR-100 as a function of training stage for a fully trained ResNet20v1.
