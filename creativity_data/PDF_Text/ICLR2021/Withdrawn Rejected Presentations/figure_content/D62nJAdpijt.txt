Figure 2: Behaviors of classifiers: (left) infected by Trojan attack and (right) infected by AdvTrojan.
Figure 3: Geographic relation among benignexample, adversarial perturbation, and decisionboundary when (a) without and (b) with Trojantrigger.
Figure 4: Test Accuracy of Different Combinations of Models and Examples for Each Dataset (1 stbar: Vanilla Model on Benign-Exps; 2nd bar: Vanilla Model on Madry-Exps; 3rd bar: Madry-AdvModel on Benign-Exps; 4th bar: Madry-Adv Model on Madry-Exps; 5th bar: ATIM on Benign-Exps;6th bar: ATIM on Madry-Exps).
Figure 5: Anomaly Index in Each Class when Applying Adaptive Neural Cleanse with the ATIM.
Figure 6: Experiment Results. Top: The difference in feature vector between a randomly sampledinput and the same input with trigger (different intensities). Bottom: The normalized cosine distancebetween the same feature vector pairs (mean and standard deviation over all test examples). Allexperiments are repeated for each dataset.
Figure 7: Test Accuracy of ATIM on Madry-Exps Generated with Different Number of Iterationsfor Each Dataset.
Figure 8: Test Accuracy of ATIM on Madry-Exps Generated with Different Perturbation Size forEach Dataset (the perturbation size for CIFAR-10 dataset is scaled by 255).
Figure 9: Test Accuracy of ATIM on AdvTrojan Examples Generated with Different PerturbationMethods for Each Dataset (the perturbation size for CIFAR-10 dataset is scaled by 255).
