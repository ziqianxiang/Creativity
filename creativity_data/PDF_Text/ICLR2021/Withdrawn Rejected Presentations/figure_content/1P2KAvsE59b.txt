Figure 1: Prunability is correlated with test loss in double descent setting: Across a set ofconvolutional networks of varying width trained on CIFAR-100, we show that prunability capturesdouble descent behavior better than a previously proposed metric Effective Dimensionality - whichis based on the eigensPectrUm of the Hessian of the training loss of the model - and other strongbaselines.
Figure 2: Pruning affects models very differently than random perturbations. Here We comparepruning of weights and randomly perturbing the same weights by the same amount. We study aResNet18 trained on CIFAR100. Generally speaking, pruning Will have a larger negative impact ona model’s loss than randomly perturbing the same Weights by the same amount but in some casespruning actually improves the test loss of models.
Figure 5: Pruning affects models differently than random perturbations. Here we comparepruning of weights and randomly perturbing the same weights by the same amount. We study a CNNon CIFAR100. Generally speaking, pruning will have a larger negative impact on a model’s loss thanrandomly perturbing the same weights by the same amount. Similarly, as in the original experiments,we find that pruning has a smaller negative impact on the test loss than randomly perturbing aslong as a moderate number of parameters are being perturbed. For larger fractions of perturbedparameters, pruning has a larger negative impact on the test loss than random perturbations.
Figure 3:	Prunability is correlated with test loss in double descent setting: Across a set ofconvolutional networks of varying width trained on CIFAR-100, we show that prunability capturesdouble descent behavior better than a previously proposed metric Effective Dimensionality - whichis based on the eigensPectrUm of the Hessian of the training loss of the model - and other strongbaselines.
Figure 4:	Prunability is correlated with test loss in double descent setting: Across a set ofResNet18s of varying width trained on CIFAR-100, we show that prunability captures double de-scent behavior better than a previously proposed metric Effective Dimensionality - which is basedon the eigensPectrUm of the Hessian of the training loss of the model - and is competitive with otherstrong baselines.
