Figure 1: Results for the simple pendulum with non-local rewards. Upper panel: training curveswith empirical discounted payoffs. Lower panels: trajectories in both the time domain and frequencydomain, showing target values of oscillation frequency, amplitude, and offset.
Figure 2: Results for the leg environment with a long horizon and resonant frequencies due to groundcompliance. Upper panel: training curves with empirical discounted payoffs. Lower panel: partialtrajectories, restricted to times shortly before and after impact with the ground. Note the oscillationsat about 100 Hz that appear just after the impact at 0.2 sâ€”these oscillations are evidence of a resonantfrequency.
Figure 3: Results for the gym suite benchmarks.
Figure 4: Training time comparison in different environments. The lower the bar, the faster themethod. The vertical axis shows the time in seconds needed to consume one million state-action pairsfor training. Each environment was shown separately in a different subplot.
Figure 5: Results for the second variant of the simple pendulum with non-local rewards. Upper panel:training curves with empirical discounted payoffs. Lower panels: trajectories in both the time domainand frequency domain, showing target values of oscillation frequency, amplitude, and offset.
Figure 6:	Results for the third variant of the simple pendulum with non-local rewards. Upper panel:training curves with empirical discounted payoffs. Lower panels: trajectories in both the time domainand frequency domain, showing target values of oscillation frequency, amplitude, and offset.
Figure 7:	Results for the fourth variant of the simple pendulum with non-local rewards. Upper panel:training curves with empirical discounted payoffs. Lower panels: trajectories in both the time domainand frequency domain, showing target values of oscillation frequency, amplitude, and offset.
Figure 8:	Results for the fifth variant of the simple pendulum with non-local rewards. Upper panel:training curves with empirical discounted payoffs. Lower panels: trajectories in both the time domainand frequency domain, showing target values of oscillation frequency, amplitude, and offset.
Figure 9:	Results for the sixth variant of the simple pendulum with non-local rewards. Upper panel:training curves with empirical discounted payoffs. Lower panels: trajectories in both the time domainand frequency domain, showing target values of oscillation frequency, amplitude, and offset.
Figure 10:	Results for the seventh variant of the simple pendulum with non-local rewards. Upperpanel: training curves with empirical discounted payoffs. Lower panels: trajectories in both the timedomain and frequency domain, showing target values of oscillation frequency, amplitude, and offset.
Figure 11:	Results for the eighth variant of the simple pendulum with non-local rewards. Upperpanel: training curves with empirical discounted payoffs. Lower panels: trajectories in both the timedomain and frequency domain, showing target values of oscillation frequency, amplitude, and offset.
Figure 12:	Results for the ninth variant of the simple pendulum with non-local rewards. Upper panel:training curves with empirical discounted payoffs. Lower panels: trajectories in both the time domainand frequency domain, showing target values of oscillation frequency, amplitude, and offset.
Figure 13: Time and frequency domain trajectories for our method (TDPO) on multiple variants ofthe simple pendulum with non-local rewards. (a) The high-reward trajectories for the first groupof variants, (b) the high-reward trajectories for the second group of variants, (c) the high-rewardtrajectories for the third group of variants. Target values of oscillation frequency, amplitude, andoffset were annotated in the frequency domain plots.
