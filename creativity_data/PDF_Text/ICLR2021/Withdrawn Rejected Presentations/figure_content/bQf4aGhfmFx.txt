Figure 1: Attraction towards zero training error with cross-entropy and TaylorGLO loss functions onCIFAR-10 AllCNN-C models. Each point represents an individual training sample (500 are randomlysampled per epoch); its x-location indicates the training epoch, and y-location the strength withwhich the loss functions pulls the output towards the correct label, or pushes it away from it. With thecross-entropy loss, these values are always positive, indicating a constant pull towards the correctlabel for every single training sample. Interestingly, the TaylorGLO values span both the positivesand the negatives; at the beginning of training there is a strong pull towards the correct label (seen asthe dark area on top left), which then changes to more prominent push away from it in later epochs.
Figure 2: Robustness of TaylorGLO loss functions against FGSM adversarial attacks on CIFAR-10.
Figure 3: Attraction towards zero training error with different loss functions. Each loss functionhas a characteristic curve—plotted using Equation 17—that describes zero training error attractiondynamics for individual samples given their current deviation from perfect memorization, . Plots (a)and (b) only have the n = 10 case plotted, i.e. the 10-class classification case for which they wereevolved. Cross-entropy (a) and MSE (c) loss functions have positive attraction for all values of . Incontrast, the TaylorGLO loss function for CIFAR-10 on AllCNN-C (b) and the Baikal loss function(d) both have very strong attraction for weakly learned samples (on the right side), and repulsionfor highly confidently learned samples (on the left side). Thus, this illustration provides a graphicalintuition for the regularization that TaylorGLO and Baikal loss functions establish.
Figure 4: Comparing accuracy basins of AllCNN-C with cross-entropy, TaylorGLO, and adversariallyrobust TaylorGLO loss functions on CIFAR-10. Basins are plotted along only one perturbationdirection for clarity, using a prior loss surface visualization technique (Li et al., 2018). While theadversarially robust TaylorGLO loss function leads to the same accuracy as the standard one, it has awider, flatter minima. This result suggests that the TaylorGLO loss function that has been evolved tobe robust against adversarial attacks is more robust in general, even when adversarial attacks are ofno concern.
