Figure 1: Using Consensus to evaluate the interpretability of DNN classifiers with a dataset. Forevery image in the dataset, Consensus (1) prepares set of trained models as committees, (2) aggre-gates interpretation results from every model to approximate the ground truth of interpretation, and(3) compares the interpretation of every model to the aggregated one to evaluate the interpretability.
Figure 2: Correlation between the Model Performance(Testing Accuracy) and the Ground Truth based Inter-pretability Evaluation using (a) LIME and (b) Smooth-Grad with CUB-200-2011 over 85 models. Pearsoncorrelation coefficients are 0.927 (with p-value 4e-37)for LIME and 0.916 (with p-value 9e-35) for Smooth-Grad. The points “Consensus” here refer to the testingaccuracy of the ensemble of networks in the commit-tee by probabilities averaging and voting (in y-axis), aswell as the mAP between the Consensus results and theground truth (in x-axis).
Figure 3: Ground-Truth-based v.s. Consensus-basedInterpretability Evaluation using (a) LIME and (b)SmoothGrad with CUB-200-2011 Datasets over 85models (the Committee). Spearman’s correlation co-efficients are 0.885 (with p-value 3e-29) for LIME and0.906 (with p-value 8e-33) for SmoothGrad.
Figure 5: Visual comparisons between consensus and the interpretation results of CNNs using LIME(in the upper line) and SmoothGrad (in the lower line) based on an image from ImageNet, where theground truth of interpretation results is not available.
Figure 6: Visual comparisons between consensus and the interpretation results of CNNs using LIME(in the upper line) and SmoothGrad (in the lower line) based on an image from CUB-200-2011,where the ground truth of interpretation results is available as pixel-wise annotations and the meanAverage Precision (mAP) are measured for interpretability evaluation.
Figure 7: Convergence of mAP betWeen the ground truth andthe consensus results based on committees of increasing sizes,using LIME on CUB-200-2011. The green lines are the meanvalues and the orange triangles are the median value. The reddashed line is the mAP of the consensus based on the completecommittee of the original 85 models.
Figure 8: Model performance versus Results of Consensus using LIME on Stanford Cars 196(Krause et al., 2013), Oxford Flowers 102 (Nilsback & Zisserman, 2008) and Foods 101 (Bossardet al., 2014). Pearson correlation coefficients are 0.9522, 0.8785 and 0.9134 respectively.
Figure 9: More visual comparisons between the consensus interpretation and the interpretation re-sults of CNNs with LIME on samples from ImageNet, where the ground truth of interpretationresults is not available. Note that consensus is the Consensus aggregated interpretation.
Figure 10: More visual comparisons between the consensus interpretation and the interpretationresults of CNNs with SmoothGrad on samples from ImageNet, where the ground truth of interpre-tation results is not available. Note that consensus is the Consensus aggregated interpretation.
Figure 11: More visual comparisons between the consensus interpretation and the interpretationresults of CNNs with LIME on samples from CUB-200-2011, where the ground truth of interpre-tation results is available as pixel-wise annotations and the mAPs are measured for interpretabilityevaluation. Note that consensus is the Consensus aggregated interpretation.
Figure 12: More visual comparisons between the consensus interpretation and the interpretationresults of CNNs with SmoothGrad on samples from CUB-200-2011, where the ground truth ofinterpretation results is available as pixel-wise annotations and the mAPs are measured for inter-pretability evaluation. Note that consensus is the Consensus aggregated interpretation.
Figure 13: Model performance v.s. similarity to the consensus of LIME on ResNet family. Theconsensus of (a) is voted by the complete committee on ImageNet (81 models), while the consensusof (b) is voted by ResNet family (16 models).
Figure 14: Visualization of images from the MS-COCO dataset (Lin et al., 2014) for showing theeffectiveness of our framework Consensus, where the predicted label with probability is noted. Notethat consensus is the Consensus aggregated interpretation.
