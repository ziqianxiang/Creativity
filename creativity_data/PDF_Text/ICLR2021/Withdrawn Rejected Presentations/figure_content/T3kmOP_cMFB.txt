Figure 1: The regrets of applying the proposed residual one-point feedback (3) (blue), the two-point oraclein Bach & Perchet (2016) (orange) and the conventional one-point oracle in Gasnikov et al. (2017) (green) toonline policy optimization for the nonstationary LQR problem. In (a), the regrets PT=0 | V(Kt) - V(K*)| ofthree methods are presented. In (b), the variance of the gradient estimates given by three methods are presented.
Figure 2: The costs during each episode by applying the proposed residual one-point feedback (3) (blue), thetwo-point oracle in Bach & Perchet (2016) (orange) and the conventional one-point oracle in Gasnikov et al.
