Figure 1: Model architectureused in EBM. EBM takes a dataX and a class y as input and out-puts their energy value.
Figure 3: Predicted label distribution af-ter learning each task on the split MNISTdataset. CLS only predicts classes from thecurrent task while EBMs can predict classesfor all seen classes.
Figure 4: Class-IL testing accuracy of the standard classifier (CLS), classifier using our training objective(CLS*), and EBMs on each task on the split MNIST dataset (left) and permuted MNIST dataset (right).
Figure 5: Confusion matrices between ground truth labels and predicted labels at the end of learning on splitMNIST (left) and permuted MNIST (right). The lighter the diagonal is, the more accurate the predictions are.
Figure 6: Model capacity of classifier and EBM using different model sizes.
Figure 7: Parameter importance on different tasks. The x-axis represents each different parameter and y-axis isthe FIM value in Equation 8. The sparser the parameters are, the fewer important parameters for previous data,which may contribute to why EBMs has less influence on previous tasks after training on new data. “Fisher5 on data 1” means the diagonal elements of the fisher information matrix obtained by Equation 8 using themodel parameters θ5 (after training on task T5) and data from task T1.
