Figure 1: VRL-PGM: a probabilistic graphical model for representing the relational learning problem;the observed random variables a and b are generated from some random process (parameterized byθ) involving an unobserved random variable z.
Figure 2: Information flow diagrams depicting VRL’s parameter updating process, where each pathuses its associated parameters to propagate information in the forward direction and gradients inthe backward direction: (a) Unmodified parameter updating process, where overfitting occurs whenthe learning of pθ (b(i) |a(i), Z(i)) rely only on the dash-dotted path (deterministic-mapping) or thedashed path (information-shortcut); (b) Parameter updating process improved with RPDA.
Figure 3: Examples of a MNIST digit augmented with five evenly-spaced rotations (from left to right:XeM) ：o。，χ(i,2) 72。，x(i，3)：l44。，XcM) ：216。，XU⑸：288°).
Figure 4: Scatter plots of the 2-D latent variable (showing only the mean μ) of hold-out datasetsinferred by VRL in (a) and VAE in (b) (relationship labels: # :0。，O : 72。，+ :144°, X : 216。,♦ :288°).
Figure 5: Manipulating latent codes of InfoGAN on MNIST where each row represents randomsamples from varying continuous latent code c2 in (a) and c3 in (b) while other latent codes and noiseare fixed; different rows correspond to different categorical code c1 .
Figure 6: Examples of images predicted by VRL: (a) images predicted from sampled latent variables(sampling the centroid of each cluster in Fig. 4a: “#” → z(1), “O” → Z⑵,“+” → z(3), “x” →z(4), “♦” → z(5)) and each image b(r,c), 1 ≤ r ≤ 5, 1 ≤ c ≤ 10, was predicted from an image a(c)(shown in the top row) and a pre-selected latent variable z(r) using b(r,c) 〜 pθ(b | a(c), z(r) ); (b)examples of relational mappings of top row images by applying relationships inferred from pairs ofsource images (as, b(sr)) (shown in the left-most column with as, b(s1), ..., b(s5) arranged from topto bottom) and each image b(r,c), 1 ≤r ≤ 5,1 ≤ C≤ 10 was generated by b(r,c) 〜pθ(b | a(c), z(r))where z(r)〜qφ( Z | a§, bSr)).
Figure 7: Scatter plot of the relational property (showing only the mean μ) of a hold-out datasetinferred by a VRL model that was trained on X3 (relationship labels: # : 0。, O : 72。, + : 144。,X :216。，♦ :288^).
Figure 8: Examples of images predicted by aVRL model that was trained on X2: (a) images predictedfrom sampled latent variables (sampling the centroid of each cluster in Fig. 7: “#”→z(1), “O”→Z⑵,“+”→Z⑶，“x”→Z⑷，“◊” →Z⑸)；(b) examples of relational mappings of top row images byapplying relationships inferred from pairs of source images (as, b(sr)) shown in the left-most columnwith as, b(s1), ..., b(s5) arranged from top to bottom.
Figure 9: Examples of a MNIST digit augmented with rotational and resizing transformations (fromleft to right: x(i,1,k) :0°, x(i,2,k) :72°, x(i,3,k) :144°, x(i,4,k) :216°, x(i,5,k) :288°; from top tobottom: x(i,j,1) : ×0.66, x(i,j,2) : ×1, x(i,j,3) : ×1.5).
Figure 10: Scatter plot of the relational property (showing only the mean μ) of a hold-out datasetinferred by a VRL model that was trained on X3 (relationship labels: #(blue) :0°, O : 72°, 十 :144°,X :216°, ♦ :288°, 2 :0°, ×1.5,〉：72°, ×1.5, V :144°, ×1.5, 4 :216°, ×1.5, O(Cyan) :288°, ×1.5).
Figure 11: Examples of images predicted by a VRL model that was trained on X3 : (a) imagespredicted from sampled latent variables (sampling the centroid of each cluster in Fig. 10: “#”(blue) →Z(I), “O”→Z⑵,“十”→ Z⑶，“X”→Z⑷，“♦”→Z⑸，“2” →Z⑹，“〉”→Z⑺，“V”→Z⑻，“4”→z(9), “#”(cyan) → z(10)); (b) examples of relational mappings of top row images by applyingrelationships inferred from pairs of source images (as, b(sr)) shown in the left-most column withas, b(s1), ..., b(s10) arranged from top to bottom.
Figure 12: Scatter plot of the relational property (showing only the mean μ) of a hold-out datasetinferred by a VRL model that was trained on X4 ; each point is color-coded (best viewed in color)by the degrees of rotation between the corresponding datapoint (markers "x" denote sampled latentvaribles z(1), . . . , z(5) used for image prediction in Fig. 13a).
Figure 13: Examples of images predicted by a VRL model that was trained on X4 : (a) imagespredicted from sampled latent variables (denoted by markers "×" in Fig. 12); (b) examples ofrelational mappings of top row images by applying relationships inferred from pairs of source images(as, b(sr)) shown in the left-most column with as, b(s1), ..., b(s5) arranged from top to bottom.
Figure 14: Scatter plot of the three-dimensional relational property (showing only the mean μ) of ahold-out dataset inferred by a VRL model (with z ∈ R3) that was trained on X4 ; each plot shows adifferent vantage point of the 3D scatter plot, and each point is color-coded (best viewed in color) bythe degrees of rotation between the corresponding datapoint.
Figure 15: Learning emotional changes among the Yale face dataset: (a) examples of subjects withdifferent facial expressions: happy, surprised, and sad; (b) scatter plot of the relational property(showing only the mean μ) inferred by the approximated posterior (relationship labels: O: “happy-sad”, #: “happy-surprised”, +: “surprised-sad”).
Figure 16: Learning illumination condition changes among the Yale face dataset: (a) examples ofsubjects with different illumination condition (source of illumination): left, front, right, and top;(b) scatter plot of the relational property (showing only the mean μ) inferred by the approximatedposterior (relationship labels: O: “left-right”, ♦: “front-top”, #: “left-front”, +: “left-top”, ×:“front-right”, 2: “right-top”).
Figure 17: Scatter plots of the relational properties (showing only the mean μ) generated from VRLablation studies (relationship labels: # :0°, O : 72°, 十 :144°, X : 216°, ♦ : 288°): (a) relationalproperty inferred by a VRL model that was trained without RPDA; (b) relational property inferred bya VRL model that was trained with applying RPDA functions D in a conventional data augmentationroutine.
