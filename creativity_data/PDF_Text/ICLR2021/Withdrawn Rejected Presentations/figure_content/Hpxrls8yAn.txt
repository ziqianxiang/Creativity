Figure 1: Memory augmentation in latent space.
Figure 2: Constrained RSSM framework. CNN, GRU and FC represent a convolutional neuralnetwork, a GRU-cell, and a fully-connected layer, respectively.
Figure 3: Reconstruction with augmented memory. The first row is the original image input, thesecond row is the image reconstructed by (h0t, s0t), and the third row is reconstruction error.
Figure 4: The CLION frameworkIn an attempt to trade off bias and variance, we calculate the V (sT) by TD-λ method (Srinivas et al.
Figure 5:	CLION exceeds at visual control tasks that testing with environmental uncertainty.
Figure 6:	Drq’s performance decreased due to the observation uncertaintyIn all tasks for CLION and Dreamer, the only observations are third-person camera images of size(64, 64, 3) pixels. All the hyperparameters are shown in Table 3 (see Appendix A.2.2).
Figure 7:	Contribution of each component in CLION to the performance improvementillustrated in Figure 7, the CLION performs better than Dreamer but are insufficient compared withCLION’s advantages. For instance, at the 100k of Walker-walk, its performance is 26.6% better thanDreamer, but CLION is 41.6% better than Dreamer; b) trajectory evaluator only. The experimentalresults show that its performance is basically similar to Dreamer; c) memory augmentation withthe constraints for RSSM but without the trajectory evaluator. Although it performs better thanthe Dreamer in Walker-Walk, it has lower performance in Hopper-Stand due to lack of reliableguarantee for the augmented data. We also compared CLION with the method that utilizes two times8Under review as a conference paper at ICLR 2021batch size in Dreamer (Doubled-Dreamer), as shown in Figure 7, the ClION also outperforms theDoubled-Dreamer. Overall, the latent trajectory augmentation with constraints, and the trajectoryevaluator are critical components for CLION, and they complement each other.
