Figure 1: Illustration of learning to explore a state space. Larger yellow dot in top left is the ini-tial point x, blue and black dots are accepted and rejected samples from the proposal distributionq(x0|x). Solution obtained from optimizing entropy objective is close to the target distribution p(x).
Figure 2: Comparison with HMC on the 20dFunnel-3 distribution. a) Chain and samples ofx0 (from neck to base direction) for HMC. b)Same as a) but for our learned sampler. Note,samples in a) look significantly more correlatedthan those in b), although they are plotted over alonger time scale.
Figure 3: Training of convergent EBM with pixel space sampling. a) Samples from replay bufferafter training. b) Proposal entropy of trained sampler vs MALA early during training, learned sam-pler has significantly higher entropy, and achieves better FID at convergence. c) Samples from 100ksampling steps by the learned sampler, initialized at samples from replay buffer. Large transitionslike the one in the first row is rare, here its selected for display.
