Figure 1: Illustration of a sample DCGMM instance containing all four layer types, with exemplarydimensionalities and parameters for each layer.
Figure 2: Sampling from DCGMM instance 2L-a, see Table 1. Shown are learned GMM centroids(left: G2, right: G4, see text) and an illustration of sampling, having initially selected the layer 4component highlighted in red. In the middle, the selected G4 centroid is shown in more detail.
Figure 3: Visualization of different DCGMM architectures and its outlier detection capabilities forMNIST (left) and FashionMNIST (right).
Figure 4:	Sampling diversity: top-1 sampling shoWn on MNIST, from left to right, for DCGMMarchitectures 1L (vanilla GMM), 2L-d (non-convolutional 2-layer), 2L-c and 2L-e (convolutional2-layer). Please observe duplicated samples in the non-convolutional architectures, marked in red.
Figure 5:	Impact of sharpening on top-S-sampling with S=1, see Section 3.2.3, shown for DCGMMinstance 2L-c on MNIST. Shown are unsharpened samples (left), sharpened samples (middle) anddifferences (right). Samples at the same position were generated by the same top-level prototype.
Figure 6: Impact of higher values of S in top-S sampling, shown for DCGMM instance 2L-c. Fromleft to right: S=2,5,10.
Figure 7: Convolutional architecture is helpful for sampling: top-1 sampling shown on Fashion-MNIST, from left to right, for DCGMM architectures 1L (vanilla GMM), 2L-d (non-convolutional2-layer DCGMM), 2L-c and 2L-e (both convolutional 2-layer DCGMMs). Please observe dupli-cated samples in the non-convolutional architectures.
Figure 8: Impact of sharpening on top-S-sampling with S=1, see Section 3.2.3, shown for DCGMMinstance 2L-c on FashionMNIST. Shown are unsharpened samples (left), sharpened samples (mid-dle) and differences (right). Samples at the same position were generated by the same top-levelprototype and are thus directly comparable.
