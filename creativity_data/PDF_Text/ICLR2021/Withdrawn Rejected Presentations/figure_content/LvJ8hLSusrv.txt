Figure 1: (Left) Eq(t) log p(x) as a function of step t in the HMC chain for initial distribution1, N (0, 0.25), and initial distribution 2, N(0, 4), before and after training. The ‘true’ value,Ep log p(x) is also plotted. (Right) The target pdf along with the two initial distributions.
Figure 2: (a) Histograms of 2D targets generated by rejection sampling. (b) Average ranking ofmarginal KL-divergences for each method in the Alanine Dipeptide experiment (lower is better).
Figure 3: Ep(z|x) logpθ(x, z) - Eq(T) (z|x) logpθ(x, z) averaged over 200 randomly chosenMNIST test images for a range of fixed scalings used during training. The ground truth poste-rior p(z|x) is estimated using 100 HAIS samples. The final scales found when running the trainingwith the SKSD are also plotted.
Figure 4: Sample distributions of marginals from the four coordinate groups. The graphs comparethe ground truth with models having a RNVP as initial distribution followed by 50 HMC steps.
Figure 5: Sample distributions of marginals from the four coordinate groups. The graphs comparethe ground truth with models having a RNVP as initial distribution followed by 50 HMC steps.
Figure 6: Sample distributions of marginals from the four coordinate groups. The graphs comparethe ground truth with models having a RNVP as initial distribution followed by 50 HMC steps. TheRNVP was trained via maximum likelihood and the HMC parameters were tuned with the indicatedmethods.
Figure 7: Violin plot of the KL-divergence of the marginals between the model tuned using maxELT& SKSD and the test set. The results are split up into the four different variable groups, i.e. Cartesiancoordinates, bond lengths, bond angles, and dihedral angles. The median is marked by an x and theinner bars are the upper and lower quartiles.
Figure 8: Progression of scale factor for maxELT & SKSD models during training. RNVP modelstrained by maximum likelihood and the α-divergence with α = 0, 1, 2 was used as initial distribu-tion.
