Figure 1: Basic accelerator architectureevery single cycle. For 16-bit network, 16 of these computation engines are instantiated to serve256 elements in parallel, by using 256 DSPs, and these compute engines are shared between layersfor maximum resource utilization. As a further optimization for 8-bit network, we can double theefficiency of using DSPs using the method proposed by Xilinx.
Figure 2: Graphical representation of hierarchical architectureThe accelerators are invoked from the software running inside the processing system of the FPGA.
Figure 3: Accuracy and latency plots for different experiment configurations4	Experiment4.1	CIFAR-10We first tested our design on CIFAR-10 dataset. The experiment was performed with a 16-bitResNet-18-based network created by us, and a binary ConvNet-based network created by Zhaoet al. (2017), on Ultra96 development board, with a frequency of 100MHz. Table 1 shows the re-source utilization ratio for individual accelerators. As expected, 16-bit network mainly uses DSPs.
