Figure 1: Breakaway sub-scenario in soc-cer. Agents in the yellow square can ignorethe context outside of this region and stillpredict their success effectively.
Figure 2: Schematic for REFIL . Values colored orange or blue are used for computing Qtot and Qtaoutx respec-tively. (left) Agent-specific utility networks. These are decentralizable due to the use of an observability mask(Mμ). We include Gated Recurrent Units (Chung et al., 2014) to retain information across timesteps in orderto handle partial observability. (top center) Hypernetworks used to generate weights for the mixing network.
Figure 3: Group Matching Game. We use the values na = 8, nc = 6, and ng = 2 in our experiments. Shadedregion is a 95% confidence interval across 24 runs.
Figure 4: Test win rate over time on variable entity STARCRAFT environments. Shaded region is a 95%confidence interval across 6 runs. (top row) Ablations of our method. (bottom row) Baseline methods.
Figure 5: Varying λ for REFIL on 3-8sz.
Figure 6: Simplified rendering of a common pattern that emerges across initializations in the 3-8csz SMACsetting, highlighted at t = 15. REFIL enables learning from each episode to inform behavior in the others.
Figure 7: Results on SMAC.
