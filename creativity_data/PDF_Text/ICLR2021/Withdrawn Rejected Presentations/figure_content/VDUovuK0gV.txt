Figure 1: Example illustrates importance of mitigating gradient explosion/decay as well as ignoring noisyobservations. Table lists test performance of baselines focused on improving RNN training. Fig. (a) plots thenoisy input, and sequential changes in hidden state norms for (Campos et al., 2018) and proposed TARNN .
Figure 2: Following (Arjovsky et al., 2016) we display average Cross Entropy for the Copy Task (SequenceLength (baseline memoryless strategy)): (a) 200 (0.09) (b) 500 (0.039). Mean Squared Error for the Add Task,baseline performance is 0.167 (Sequence Length) : (c) 200 (d) 750.
Figure 3: Toy Example. (a) TARNN converges quickly to the 0.0 cross-entropy error. (b) shows time constantÎ² along with the input, at locations t = 4, 12, both the input and time constants are in sync resulting in the stateupdate while everywhere else the time constant does not allow the state to update (see s1m state which capturesthe update or skip state part). (c) shows the norm of the hidden state for SkipLSTM and TARNN .
