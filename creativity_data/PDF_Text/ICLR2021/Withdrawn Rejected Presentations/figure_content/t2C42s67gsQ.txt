Figure 1: Training a deep discriminative model with our adaptive sampling framework (RLSampler). Withtwo additional feedback signals, i.e., state observation and reward feedback, the dataset sampler is modeledas an RL agent that learns to sample optimal sequence of samples that train the learner most effectively. Theinterface of the learner is not affected, so the sampling method can be easily applied to any existing framework.
Figure 2: Image classification results of VGGNets (Simonyan & Zisserman (2015)) with two different sam-plers and various learning rates (LRs). We report the average (bold center line) and the standard deviation(shaded area) of three runs, except for the base LR (0.01) case, where we use the values in Tables 1 and 2.
Figure 3: The sample distribution induced by our RLSampler. (a) and (b) show class and sample frequency ofthe entire training sequence of the best ResNet-20 model on CIFAR-10 in Tabel 1, respectively. For the samplefrequency in (b), with the maximum and the minimum, We also provide the 10-th, 50-th (median), and 90-thpercentiles. We report the percentage of deviation of the two extrema from the ideal mean under the uniformdistribution. (c) and (d) show the most and the least fetched images from the same RLSampler, respectively.
Figure 4: (a) and (b): Empirical sampling probability of RLSampler compared to the average training loss andthe average L2 gradient norm of ten different ResNet-20 fixed after being trained for 5 epochs, respectively.
