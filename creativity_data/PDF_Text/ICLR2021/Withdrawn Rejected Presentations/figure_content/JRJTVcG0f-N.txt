Figure 1: The effect of binding on the decision boundary. Red and blue represent two different objectmanifolds (e.g. cats and dogs). Adversarial perturbations (light-blue arrows) for the red class movethe input beyond the decision boundary into a region where it is classified as blue. a) A commonassumption for classification is to represent object classes in low-dimensions, which enables lineardecision boundaries that accurately separate them. Unfortunately, the learned decision boundarycan be unpredictable off the manifold. Given the high-dimensional embedding space (e.g. pixel-space), there may be many such directions vulnerable to small perturbations. b) We argue thatthere are additional, class-preserving dimensions of variation to the underlying object manifold,but that these are difficult to model with typical convolutional neural network (CNN) architectures.
Figure 2: Implementing hierarchical binding in a convolutional neural network. a) ‘Conv.’ is a con-volution operation with stride of 2. Our depicted representation of gradient unpooling is simplifiedfor the sake of intuition, as the max-pooling layer in the figure consists of only a single neuron; inreality, we take the gradient of each low-level activation w.r.t. the entire max-pooled layer and onlyuse the proportion γ of the largest gradients to apply a Boolean mask to the activations. b) A toydiagram to demonstrate the connection to hierarchical binding. The desire is to capture which low-level features (such as a vertical bar or a minimally invariant ‘T’ neuron) causally drove the moreinvariant representation ofa ‘T’. These hierarchical binding representations are then made available,alongside the invariant representations, to higher layers.
Figure 3: The effect of hierarchical binding dimension and causal role on robustness. We systemat-ically vary the γ-proportion of gradients used to mask the gradient unpooling representations alongthe x-axis; results are shown from using both the largest (blue-solid) and smallest (red-dashed) γgradients. 0.0 is equivalent to the LeNet control model we study, while 1.0 means no masking isapplied and all low-level activations are up-projected (indicated in purple). Each point represents themedian distance of a successful adversary, provided as the median performance across 30 networkstrained on MNIST without unpooling. Error bars show the 95% confidence interval of the median.
Figure 4: The effect of additional features on robustness in a synthetic data-set. a) In our syntheticdata-set of Gaussians, two dimensions separate the data well (like the ‘Dog-ness’ dimension), whileothers carry either no information (like ‘Pixel-45’), or some information about class identity (like‘Ear-size’). The proposal is that explicitly including features such as ‘Ear-size’ can help inform abetter decision boundary in otherwise vulnerable directions. b) By keeping the total input dimensionfixed, but having a greater number of partially informative features (varied along the x-axis), we seean improved robustness to L2 BIM attacks as the co-dimension decreases (shown is the median L2distance of an adversary, given as the median performance across 100 networks for each condition).
Figure 5: The effect of layer-wise ablations. We normalize the values of the three different metricsso they can be compared side by side (median clean accuracy and median distances of adversariesfor BIM-L2 and BIM-L∞ attacks across 30 networks). For any given metric, the best performancecorresponds to 1 and the worst to 0. For comparison to other results in this paper, the performanceof the un-ablated HB-CNN and LeNet model is as shown in Table 2 (no noise in training data). Theworst performing ablation (all binding) corresponds to a clean accuracy of 94.43%, BIM L∞ of0.05, and BIM-L2 of 0.6. GU = gradient unpooling.
Figure 6: Distributions of the Median Performance of Networks. Red is the HB-CNN/VGG+S+N,blue is the standard CNN/VGG+S+N. Note that for some of these attacks we reported no improve-ment in the main text, such as the Pointwise L2 attack metric on Fashion-MNIST.
Figure 7: Integration of Unpooling and Gradient Unpooling in a Hierarchical Binding CNN. Thediagram shows the architecture for a) MNIST and Fashion-MNIST and b) CIFAR-10. Note that it isnot necessary to use unpooling or gradient-unpooling representations from every layer, thus deeperarchitectures can select intermittent representations to use for unpooling or gradient-unpooling,avoiding an excessive growth in parameters.
Figure 8: Cherry-picked, semantically meaningful adversaries for the control and HB-CNN models.
