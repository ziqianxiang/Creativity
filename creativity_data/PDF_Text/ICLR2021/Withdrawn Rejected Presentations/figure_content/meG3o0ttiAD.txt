Figure 1: Quantum Neural Network with Figure 2: Quantum Neural Network with the Stepthe Tree Tensor structure (n = 4).	Controlled structure (n = 4, nc = 2).
Figure 3: The parameterized alternating layered circuitW(β) (n = 8, L = 1) for training the correspondingencoding circuit of the input xin.
Figure 4: The encoding circuit U(β*),where W(β*) is the trained parameter-ized circuit in Figure 3.
Figure 5: Simulations on the MNIST binary classification between (0, 2). The training loss andthe test error during the training iteration are illustrated in Figures 5(a), 5(e) for the n=8 case, Fig-ures 5(b), 5(f) for the n=10 case, and Figures 5(c), 5(g) for the n=12 case. The gradient normof objective functions and the term α(ρin) during the training are shown in Figures 5(d) and 5(h),respectively for the n=8 case.
Figure 6: The training loss of the input model for MNIST images in class {0, 1, 2, 3}.
Figure 7: The visualization of the encoding circuit for MNIST images in class {0, 1, 2, 3, 4}.
Figure 8: The training of binary classification task on the MNIST image bettwen classes (0, 2)using 8-qubit QNNs with the exact amplitude encoding. The training loss and the test error duringthe training iteration are illustrated in Figures 8(a), 8(b), respectively. The gradient norm of objectivefunctions during the training is shown in Figures 8(c).
Figure 9: The training of binary classification task on the MNIST image bettwen classes (0, 2) using8-qubit QNNs with the extended gate operation {RX, RY, RZ}. The training loss and the test errorduring the training iteration are illustrated in Figures 9(a), 9(b), respectively.
Figure 10: An example of the variational encoding model (L = 2 case).
Figure 11: Quantum Neural Network with the Deformed Tree Tensor structure (qubit number = 12).
