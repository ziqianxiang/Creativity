Figure 1: Diagram of mass flow in a generalized inhomogeneous random walk used in the derivationof the Soret coefficient.
Figure 2: All rows include rescaled x-axes as described in the main text. Top Row: Plots of activationrate as a function of (rescaled) training iterations with different learning rates. The model is atwo-layer fully-connected network with 100 hidden units. Training data is drawn from a normaldistribution. Middle Row: Plots of average gradient variance as a function of (rescaled) trainingiterations with different learning rates in 6-layer fully-connected neural networks. Training data isdrawn from normal distribution. Bottom Row: Same as middle row but for 6-layer convolutionalneural networks trained on Fashion-MNIST.
Figure 3:	Plots of activation rate as functions of training iterations with different learning rate.
Figure 4:	Plots of L2 norm of V as functions of training iterations with different learning rate.
Figure 5: Plots of activation rate as functions of training iterations with different batch size.
Figure 6: Plots of L2 norm of V as functions of training iterations with different batch size.
Figure 7:	Plots of activation rate as functions of training iterations with different learning rate.
Figure 8:	Plots of L2 norm of V as functions of training iterations with different learning rate.
Figure 9: Plots of activation rate as functions of training iterations with different batch size.
Figure 10: Plots of L2 norm of V as functions of training iterations with different batch size.
Figure 11:	Plots of activation rate as functions of training iterations with different learning rate.
Figure 12:	Plots of L2 norm of V as functions of training iterations with different learning rate.
Figure 13: Plots of activation rate as functions of training iterations with different batch size. Datasetis CIFAR10.
Figure 14: Plots of L2 norm of V as functions of training iterations with different batch size. Datasetis CIFAR10.
