Figure 1: The magnitude of the witness functions obtained from max-sliced Bures indicate dis-crepancies. (Left) A Gaussian kernel is used to construct non-linear witness functions and identifywitness points. (Right) Witness points for real and fake images from stacked MNIST and CIFAR10.
Figure 2: Max-sliced divergences using the Inception Network representation are applied to sampleswith mismatched class distributions in CIFAR10. The first sample consists of the training set (bal-anced classes with m=50,000), and the second sample is an imbalanced subset of the test set withn=10,000. Each curve is the mean precision@10 (averaged across 10 random draws) for test setswhere the given class is subsampled at different levels of imbalance and other classes are balanced.
Figure 3: Max-slicing Inception codes to illustrate the AutoGAN discrepancies. One-sided max-sliced Bures is used to identify two witness function (as linear subspaces of the Inception codes) thatdifferentiate the real from fake samples. (Left: A,C) Images in subspace under-represented by fakewReal>Fake. (Right: B,D) Images in subspace over-represented by fake wReal<Fake. (Top: A,B) RealCIFAR10 test images. (Bottom: C,D) Fake images. (C) Realism scores (median and range): 0.92(0.84-1.03). (D) Realism scores (median and range): 0.68 (0.62-0.73)3.2	Baseline Comparison on Covariate Shift DetectionWe compare the proposed max-sliced Bures distance and the resulting max-sliced FreChet distance tothe max-sliced W2 distance for linear witness functions. Figure 4 compares the divergence estimatesinstances associated with a simple case of covariate shift with the MNIST data set. Notably, theprecision of detecting class imbalances is higher for smaller samples using a kernel (Appendix A.8).
Figure 4: Max-sliced distances applied to two samples from MNIST. The first sample μ is m imagesdrawn uniformly from the training set, and the second sample V is n images from the test set whereone digit is a minority class l ∈ {0, . . . , 9} with prevalence of 5%. (Left) Divergence estimatesacross sample size with l = 7. For m < 2000, gradient-based approaches for the max-sliced W2distance fail to obtain the optimal slice as it should upper bound the max-sliced Frechet distance.
Figure 5: Reweighting a uniform distribution to match various target distributions by minimizingthe max-sliced W2 distance or the max-sliced Bures distance with either a linear kernel or ran-dom Fourier bases (d=2,000, σ ∈ {0.1, 0.2}). Examples follow Kolouri et al. (2019) and usesADAM (Kingma & Ba, 2015) defaults and a learning rate of 10-2 . A point’s size is proportional totheir weights after 100 iterations. Learning curves are the weighted W2 distance (log-scale).
Figure 6: Detecting dropped modes using one-sided max-sliced Bures distance. The slice wReal>Fakeis used to identify the top-10 real training images with the largest magnitude witness function valuesat each epoch. Precision@10 measures the fraction that correspond to dropped modes, as comparedto random selection. The curves are the mean (A) and median (B) across 100 GAN training trials.
Figure 7: Sliced and max-sliced Bures and Wasserstein-2 distances are compared on populationstatistics and samples of varying sizes. μ = N(0, C) and V = N(0, I), where C = ZZ>, andZ ∈ R2×2 with entries that are originally standard normals and then row normalized such that Cis a correlation matrix. In the population case and for zero-mean Gaussians, the Bures distance isequivalent to the W2 distance (Gelbrich, 1990). In the sample case, it is a lower bound. At bothm = 100 and m = 104 the gradient optimization of the max-sliced W2 distance fails to obtain theglobal optimal slice (instead obtaining a local optimum).
Figure 8: Success rate of finding optimal slices for the max-sliced Bures and W2 distances acrosssamples of varying sizes (10 random runs per size). The distributions are zero-mean Gaussians, withμ = N(0, C) and V = N(0, I), where C = ZZ>, and Z ∈ Rdxd With entries that are originallystandard normals and then row normalized such that C is a correlation matrix. (Left) In the caseof d = 2, success is obtained for a distance within 1% of the value obtained by fine-grid searchof angles. In this case, the gradient approach for the max-sliced Bures fails more often than themax-sliced W2. (Right) For d = 1000 the eigenvalue-based approach (Algorithm A.5) defines theglobal optimum. In the larger dimension, the gradient approach for the max-sliced Bures {ADAM}succeeds in almost all of the cases, within 1% of the optimal value obtained by Algorithm A.5(MSB), whereas the max-sliced W2 distance fails to upper bound the max-sliced Bures on roughlyhalf the trials.
Figure 9: Performance of gradient algorithms for max-sliced Bures and max-sliced W2 distancesacross d = 1000 dimensional samples of varying sizes (10 random runs per size) and number ofiterations in ADAM (Left to right: 50, 100, 200, 500, 1000). The samples are from zero-meanGaussians distributions, with μ = N(0, C) and V = N(0, I), where C = ZZ>, and Z ∈ Rd×dwith entries that are originally standard normals and then row normalized such that C is a correlationmatrix. (Top) For the max-sliced W2 a successful run is obtained when it is greater than or equalto the optimal solution to the max-sliced Bures (blue solid line) or when it is greater than 95% ofmax-sliced Bures (red dotted with circles). For the gradient approach to max-sliced Bures, successis when the difference to the optimal is 5% of the optimal (yellow solid with diamonds). (Bottom)Divergence values obtained across the 10 trials with increasing sample size.
Figure 10: Maximum mean discrepancy (MMD) and max-sliced Bures distance (MSB) appliedto two-dimensional samples using a Gaussian kernel. For each data set (shown as a two-by-twosubplot), the contour plots indicate the squared magnitude of the witness function evaluations. ForMMD, positive witness function values are plotted in the top row and negative evaluations are in thesecond row. For MSB, the rows correspond to the two one-sided divergences. The witness functionsfor the one-sided MSB divergences correspond to localized regions.
Figure 11: Kernel-based max-sliced distances are applied to balanced and imbalanced samples fromMNIST. The first sample μ consists of the training set (balanced classes with size m), and the secondsample V is a n-sized sample from the test set with a minority class l ∈ {0,..., 7} with prevalanceof 5%. (Left) Divergence estimates for increasing sample size for l = 7. Notably, for m < 2000the max-sliced Wasserstein-2 distance fails to obtain the optimal slice as it should upper boundthe max-sliced kernel Gauss-Wasserstein (FreChet) distance. (Center) Corresponding computationtime. (Right) Each curve is the average precision@10 (averaged across the 10 classes). The witnessfunction for the one-sided max-sliced Bures ω^>^ can be used to reliably identify instances from μassociated to the missing class.
Figure 12: Distribution matching based on minimizing max-sliced Bures distance max-DB(μ, V).
Figure 13: Distribution matching based on minimizing the Wasserstein-2 distance through mini-batch. Synthetic images shown are those with the higest values of V, where V is the V-weighteddistribution over 50,000 synthetic images from AUtoGAN and μ consists of CIFAR10 training im-ages for a single class in each row. Rows (top to bottom) correspond to airplane, automobile, bird,cat, deer, dog, frog, horse, ship, and truck classes.
Figure 14: Distribution matching based on minimizing the max-sliced Wasserstein-2 distancemax-W2R (μ, ν) through mini-batch approximation. Synthetic images shown are those with thehighest values of V, where V is the V-weighted distribution over 50,000 synthetic images from Au-toGAN and μ consists of CIFAR10 training images for a single class in each row. Rows (top tobottom) correspond to airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck classes.
Figure 15: Selecting images directly with the highest realism scores. Synthetic images shown arethose with the highest realism values over 50,000 synthetic images generated by AutoGAN whenthe realism scores used in each row are computed using the CIFAR10 training images for a singleclass. Rows (top to bottom) correspond to airplane, automobile, bird, cat, deer, dog, frog, horse,ship, and truck classes. Realism score correctly identifies “realistic” imagery, but is unable to findsamples that cover the real distribution. For example, the top row is missing airplanes, the third rowis missing birds, the fourth row is missing cats, etc.
