Figure 1: Our pSp architecture. Feature maps are first extracted using a standard feature pyramidover a ResNet backbone. For each of the 18 target styles, a small mapping network is trained toextract the learned styles from the corresponding feature map, where styles (0-2) are generated fromthe small feature map, (3-6) from the medium feature map, and (7-18) from the largest featuremap. The mapping network, map2style, is a small fully convolutional network, which graduallyreduces spatial size using a set of 2-strided convolutions followed by LeakyReLU activations. Eachgenerated 512 vector, is fed into StyleGAN, starting from its matching affine transformation, A.
Figure 2: Results of pSp for StyleGAN inversion compared to other approaches on CelebA-HQ.
Figure 3: (a) Ablation of the pSp encoder over CelebA-HQ. (b) The importance of the identity loss.
Figure 4: (a) Quantitative results for image reconstruction on CelebA-HQ. (b) Results for FaceFrontalization on the FEI Face Database split by rotation angle of the face in the input image.
Figure 5: Comparison of face frontalization methods.
Figure 6: (a) Comparison of sketches presented in DeepFaceDrawing. (b) Comparisons to otherlabel-to-image methods on CelebAMask-HQ. (c) Multi-modal outputs using pSp with style-mixing.
Figure 7: (a) To generate multiple outputs for a single input image, style-mixing is performed overpSp. (b) Challenging cases for StyleGAN Inversion.
Figure 8: Additional applications for the pSp framework.
Figure 9: Comparison of super-resolution approaches with (a) ×8 down-sampling, (b) ×16 down-sampling, and (c) ×32 down-sampling.
Figure 10: Multi-modal synthesis for super-resolution using pSp with style-mixing.
Figure 11: Additional StyleGAN inversion results using pSp on the CelebA-HQ (Karras et al., 2018)test set.
Figure 12: Additional face frontalization results using pSp on the CelebA-HQ (Karras et al., 2018)test set.
Figure 13: Even for challenging, non-frontal face sketches, pSp is able to obtain high-quality, diverseoutputs.
Figure 14: Additional results using pSp for the generation of face images from sketches constructedfrom the CelebA-HQ (Karras et al., 2018) test dataset.
Figure 15: Additional results on the Helen Faces (Le et al., 2012) dataset using our proposed label-to-image method.
Figure 16: Additional results on the CelebAMask-HQ (Karras et al., 2018) test set using our pro-posed label-to-image method.
Figure 17: Conditional image synthesis results from sketches and segmentation maps displaying themulti-modal property of our approach.
