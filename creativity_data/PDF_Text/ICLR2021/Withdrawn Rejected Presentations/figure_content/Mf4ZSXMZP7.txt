Figure 1: Comparison of different optimizationmethods over ResNet-50 quantized to 4 bit exceptthe first and the last layers which were kept in8bit. Even optimizing on a single image drasticallyimproves the results but as expected have a highvariance (red bar). The variance decreases rapidlyas calibration set size increases.
Figure 2: AdaQUant vs. AdaRoUnd. (a) A histogram of ∆W distribution. AdaRoUnd restricts thisadditive term to be ∆W = ±1. Relaxing this constraint provides a more powerful optimization. (b)Ablation study on parameters optimization for ResNet50 over ImageNet. AdaRound is based exclu-sively on weight optimization, while AdaQuant optimizes the weights, biases, and other quantizationparameters jointly.
Figure 3: Ablation study over ResNet-50/18 and MobileNet-V2 - compression-accuracy curves. Ouradvanced pipeline is consist of AdaQuant, IP-mixed-precision, BN-tuning and bias-tuning. Ourlight pipeline is consist of only IP-mixed-precision, BN-tuning. The relaxed advanced pipelineappears in c is similar to the advance pipeline but allows the integer-programming to choose anybit-width between 2-8 and not just 4-bit or 8-bit. The compression ratio is measured as the ratiobetween the compressed model and the full-precision (32-bit) mode thus 0.25 compression rateindicate that the entire model uses 8-bit precision and respectively for 4-bit the compression rate is0.125ReferencesYonathan Aflalo, Asaf Noy, Ming Lin, Itamar Friedman, and Lihi Zelnik. Knapsack pruning withinner distillation. arXiv preprint arXiv:2002.08258, 2020.
Figure 5: Calibration size ablation study with additional early-stop plot.
