Figure 1: SPL converts the potential noises in untrimmed Web videos to useful supervision signalsby creating a new set of meaningful “middle ground” pseudo labels, such as mixing the eggs andflour shown in this example. Enriched supervision is provided for effective video model pre-training.
Figure 2: Pre-training framework for learning form web videos via exploring SPLs.
Figure 3: Illustration of the SPL mapping function. The left side is the confusion matrix betweenoriginal weak labels and teacher predicted labels. The top-right illustrates three space-reduced vari-ants of SPL. SPL-B: Using agreed and disagreed entries of each row as SPL classes. SPL-D: Usingthe top frequent entries as SPL classes. SPL-M: Merging less frequent off-diagonal entries to diag-onals as SPL classes. The bottom-right illustrates three baseline pseudo-label strategies.
Figure 4: SPL-M and SPL-D with different sam-ples cover ratio (SCR) defined in the Section 4.4Comparisons with other pre-training strategies. Section 3.3 and Figure 3 categorize differentpseudo-label strategies. Here we compare these strategies to ours. We report results based on theirpre-training on our WebK200-147K-V set with 6.7 × 105 clips. From Table 1, we find they canall improve upon the baseline ImageNet pre-training. The performance gap between pre-trainingusing Weak Label (Ghadiyaram et al., 2019) and Teacher Prediction (Xie et al., 2020) indicatesthere are more useful information included in weak labels. Although Agreement Filtering can dosome noise reduction to the web videos, it discards around 60% of training samples resulting in acomparable performance with Weak Label. We also adopt Data Parameters (Saxena et al., 2019),one of the recent state-of-the-art methods for learning with noisy labels, to conduct pre-training onweb videos. Our SPL-B (variation with the best performance on Kinetics-200) outperforms thesebaselines and is able to take use of all noisy data.
Figure 5: Effect of different numbers of clipgiven a fixed number of videos (WebK200-147K-V). Results are on Kinetics-200.
Figure 6: Examples of attention visualization for SPL classes. Original weak label (blue) and theteacher model prediction (red) are listed. Some meaningful “middle ground” concepts can be learntby SPL, such as mixing up the eggs and flour (top) and using the abseiling equipment (bottom).
Figure 7: Class distribution of SPL on WebK200-285K-V set with 6.7 × 105 clips. We show thecases of SPL-B (left) and SPL-D (right) with 400 SPL classes in total. The first 200 classes arein-diagonal SPL classes and rest 200 are off-diagonal classes.
Figure 8: Confusion matrices on WebK200-285K-V (left, zoom in to better see off-diagonal ele-ments) and WebS4-73K-C (right). They are web videos collected for target dataset Mini-Kinetics-200 and SoccerNet respectively. For WebS4, the four (1-4) classes are, Background, Yellow/RedCard, Goal, Substitution, respectively.
Figure 9: Top-3 retrieved videos obtained by taking the SS class “Holding Something” as the search-ing query. They are almost unrelated to the fine-grained motion defined in this class.
Figure 10: Top-3 retrieved videos obtained by taking the SS class “Closing Something” as thesearching query. They are almost unrelated to the fine-grained motion defined in this class.
Figure 11: Top-3 retrieved videos obtained by taking the SS class “Pushing something from left toright” as the searching query. They are almost unrelated to the fine-grained motion defined in thisclass.
