Figure 1: Top: Process for training. For each training example x, our algorithm usesprogram synthesis to infer the relational constraints cx = A(x) present in x. Then, it (i)uses Cx to trainpφ(c) = Ez〜p(,)[p@(c | z)∙p(z)], and(ii) uses (cχ,x) to trainpθ(X | c). Bottom:Process for generating a sample x from the learned models pφ(c | z) and pθ(x | c). Lineswith the same prototype are shown in the same color; metrical constraints are representedas purple and rhyme constraints as green edges.
Figure 2: Left: Poetry generated using relational constraints C 〜Pφ(∙). Middle: usermodified variant of c where the last two lines share a prototype with the two lines beforethem. Right: A poem generated by GPT2 optimized to maximize rhyme and meter. Thecolors indicate the relations synthesized by our algorithm after the examples were generated.
Figure 3: A song generated using our approach A3 (top), and a nearly identical songgenerated where part of the sampled relational constraints c were manually modified. Thesepieces were generated using A3, and the same reference measures W were used, but Φc wasslightly perturbed (the similarity relations were changed).
Figure 4: An example of a song generated using our approach (A1). Measures that havethe same prototype are shown in the same color. Note the existence of repeating four-barphrases, found commonly in folk songs.
Figure 5: An example of a song generated using our approach (A2). Measures that havethe same prototype are shown in the same color. Note the existence of clear phrase endingsmarked by long notes or rests, particularly the recurring pattern of fast notes resolving intolong notes.
Figure 6: An example of a song generated using our approach (A3). Measures that havethe same prototype are shown in the same color. The existence of two-bar and three-barphrases is apparent, but the close note and rhythm similarities among different prototypesweaken the overall clarity of the song’s melody.
Figure 7: An example of a song generated using Magenta’s hierarchical MusicVAE modelfinetuned on our dataset. While the local structure is extremely coherent, it does not seemto possess the expected internal repetition/development.
Figure 8: An example of a song generated using AttentionRNN trained on our dataset.
Figure 9: An example of a song generated using MusicAutoBot. Note the repetitive natureand stark contrast between the first half and second half of the song, which are commonproblems with transformer models.
Figure 10:	An example of a song generated using StructureNet. While some degree of inter-nal structure is apparent, and the local coherence is high, the pattern of internal repetitionseems fairly arbitrary.
Figure 11:	An example of poetry generated using our approach. Lines that have the sameprototype are shown in the same color.
Figure 12:	A poem generated using GPT2-Opt. It is more plausible than BERT in termsof of global structure, which may be due to the fact that GPT2 is a better text generationtool than BERT, but it is still somewhat repetitive and its structure is not very human-like.
Figure 13:	A poem generated using BERT. It is clearly overly repetitive and not verysemantically coherent, and lacks high-level structure.
Figure 14:	A poem generated using RichLyrics. While it is less repetitive than non-conditioned BERT, it is still not very semantically coherent, and lacks high-level structure.
Figure 15:	A poem generated using our ablation. While it is much more coherent, it lacksthe idiomatic rhyme and meter structure of our approach.
