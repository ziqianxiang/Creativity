Figure 1: Schematic representation of the mainoperations in the MC-LSTM architecture (adaptedfrom: Olah, 2015).
Figure 2: MNIST arithmetic task results forMC-LSTM and NAU. The task is to correctlypredict the sum of a sequence of presentedMNIST digits. The success rates are depictedon the y-axis in dependency of the length ofthe sequence (x-axis) of MNIST digits. Errorbars represent 95%-confidence intervals.
Figure 3: Schematic depiction of inbound-outbound traffic situations that require theconservation-of-vehicles principle. All ve-hicles on outbound roads (yellow arrows)must have entered the city center before(green arrows) or have been present in thefirst timestep.
Figure 4: Example for the pendulum-modellingexercise. (a) LSTM trained for predicting energiesof the pendulum with friction in auto-regressivefashion, (b) MC-LSTM trained in the same set-ting. Each subplot shows the potential- and kineticenergy and the respective predictions.
Figure 5: Snow-water-equivalent (SWE) from a single basin. The blue line is SWE modeledby Newman et al. (2015). The orange line is the sum over 4 MC-LSTM memory cells (Pearsoncorrelation coefficient r â‰¥ 0.8).
