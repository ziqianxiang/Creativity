Figure 1: The WGD Framework involves transformations among three space: feature space,principal component space and discrete Wasserstein space. SVD is leveraged to generateinitial node representations Uk0in principal component space which will be transformed todiscrete distributions endowed with Wasserstein distance through a particular reversiblepositive mapping. In this discrete Wasserstein space, we utilize Wasserstein barycenter toaggregate distributional information of h - hop neighbors. In each WGD layer, the updatednode distributions will be transformed back to the principal component space to updatecorresponding node representations which is also the input of next layer. The support pointsare shared over layers. After L times update, we pull UkL back to the original feature spacethrough inverse mapping to generate new node representations.
Figure 2: Average accuracy of models in entirely missing (top) and partially missing (bottom)settings.
Figure 3: Sensitive analysis for the number of WGD layers L and times h of Wassersteindiffusion in each layer. The results (node classification accuracy on Cora dataset) show thatour method prevents over-smoothing.
