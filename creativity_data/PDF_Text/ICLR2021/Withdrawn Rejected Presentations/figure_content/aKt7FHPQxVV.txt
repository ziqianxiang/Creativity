Figure 1: Consecutive model parallel (CMP) overlaps the two forward sub-tasks (FA and FW ) andtwo backward sub-tasks (BW and BA). This new execution order empowers neural architecturesearch (NAS) to search faster than using model parallel (MP). The right figure shows that CMP cansave two cycles from vanilla MP. Furthermore, CMP inherits MPâ€™s advantages, like using large batchsizes in the supernet, enlarging layer numbers of the supernet, and even diversifying cell architectureacross different layers.
Figure 2: Illustration of Binary Neural Architecture Search (NASB). (a) is a supernet made up ofnormal and reduce cells. (b) portrays the directed-acyclic-graph (DAG) used for cell structures. (c)embodies the mixed operation in the solid red lines of the middle figure. NASB builds its supernetwith binary mixed operations mBO, which replace architectural matrix A with binary matrix G. Thesymbol n and o stand for nodes in DAG and candidate operations. Among rows associated with anode (blue bracket) in A, the largest two values are set to 1 and the rest elements to 0. Only partialoperations are active during the search procedure of NASB.
Figure 3: Performance comparison between different parallel approaches in NAS (best viewed incolor). GPipe (Huang et al., 2019) is an approach of pipeline model parallel. Among the threemodel parallel approaches (blue, red, yellow), consecutive model parallel (CMP) outperforms themin terms of search cost and test error (lower is better). While the data parallel (green) is the fastestparallel method, but its test errors are not as low as CMP.
