Figure 1: Overview of Adversarial Feature Augmentation for image recognition. From left to right,clean images are fed into network backbones to extract clean feature embeddings. Then, adversar-ial perturbations are generated to augment several intermediate features (in the direction of purplepaths). In the end, both adversarial augmented and clean feature embeddings are taken as inputs bythe classifer, and optimized by adversarial (Lat) and standard training (Lstd) objectives.
Figure 2: Applying ALFA to the feature embed-dings from different blocks or the combinationsof top-performing blocks. Experiments are con-duted on CIFAR-10 with ResNet-20s.
Figure 3: Standard testing accuracy (%) of ResNet-18 (Left) and ResNet-56s (Right) on CIFAR-10dataset, with ALFA applied to different blocks and several combinations of top-performing blocks.
Figure 4: The learned distribution of perturbation magnitude vector Î· in L-ALFA over trainingepochs on ImageNet (Left) and CIFAR-10 (Right). The curves of the last block (i.e., Block 9)feature embeddings are highlighted by black arrows.
