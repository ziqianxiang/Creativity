Figure 1: An overview of LLBoost and a demonstration of the benefits of our method in boostingpre-trained models. (A) A breakdown of LLBoost, which improves the performance of pre-trainedneural networks by adjusting the last layer of a pre-trained network with a term orthogonal to thetraining feature matrix, X . (B) LLBoost applied to a model trained on a poorly-chosen seed boostsperformance to that of a model trained on a well-chosen seed. (C) LLBoost provides a boost to thepre-trained models at a fraction of the computational cost of training.
Figure 2: LLBoost consistently improves the performance of pre-trained neural networks across avariety of experiments on ImageNet32, CIFAR10, and ImageNet without impacting training accu-racy. The last column indicates that applying a standard perturbation instead of LLBoost to the lastlayer of a neural network can significantly impact training and validation accuracy. *'s indicate thatthe training feature matrix X was full rank, and thus, we used a low rank approximation of X forLLBoost. See Appendix F for a description of how the rank was chosen, and an analysis of how lowrank approximations affect train/validation accuracy.
Figure 3: LLBoost provides a computational advantage over random seed search. While LLBoostnot only improves the performance of every pre-trained model above, our method boosts the per-formance of a model trained using a poor random seed to at least that of a model trained using awell-selected seed at a fraction of the computational cost.
Figure 4:	An overview of the optimizer, learning rate, initialization, and seeds used to fine-tunepre-trained models on ImageNet32 and CIFAR10.
Figure 5:	The rank of the approximation used for the training feature matrix, X, when X was fullrank.
Figure 6:	An extended version of Figure 2 that includes the choice of Î³ considered and the sizeof the perturbation (in FrobeniUs norm) produced by LLBoost. *'s indicate the use of low-rankapproximations for full rank training feature matrices.
Figure 7:	A comparison between the training time and LLBoost correction time for models fromFigure 2. For the ImageNet32 models, the third column represents the time to compute the valida-tion accuracy for 100, 000 samples from LLBoost. For CIFAR10 and ImageNet, the time addition-ally includes the cost of computing the perturbation for LLBoost. *'s indicate the use of low-rankapproximations for full rank training feature matrices.
Figure 8:	A demonstration that using samples from a standard normal projected onto the spaceorthogonal to the training data leads to a decrease in validation accuracy but has no impact ontraining accuracy. *'s indicate the use of low-rank approximations for full rank training featurematrices.
Figure 9:	Visualizations of the singular values of training feature matrices for models from 2. (A)The singular values of the training feature matrices for small datasets. (B) The singular values offull rank training feature matrices from large datasets. The red vertical line indicates the size of theapproximation used for Figure 2.
Figure 10: The impact of using approximations of varying rank for full rank training feature ma-trices. The first row provides the training accuracy and validation of the original model. The firstcolumn is the training accuracy of the model on the original dataset, the second column is the trainingaccuracy on the training data reconstructed from the low-rank approximation, and the third columnis the validation accuracy. We see that the validation accuracy generally increases when loweringthe rank of the approximation. Since only a few singular values of the training feature matrix arelarge, there is no impact to the training accuracy when using a low-rank approximation for X .
Figure 11:	Using LLBoost to improve validation accuracy also leads to an improvement in testaccuracy (i.e. LLBoost does not overfit the validation set). We split the original validation setof CIFAR10 into a validation and test set according to the splits indicated in parentheses. As thevalidation set of ImageNet32 for 2 classes only has 100 images, we perform an 80/20 train/validationsplit of the training set, use the 100 validation images as test data, and re-train our models on thesmaller training set.
Figure 12:	Using LLBoost to improve validation accuracy also leads to an improvement in testaccuracy (i.e. LLBoost does not overfit the validation set). In our experiments, we use the samenumber of examples for training and validation and use the entirety of the remaining examples fortesting. For example, in row 1, we use 200 examples for training, 200 for validation and 11600 fortesting.
