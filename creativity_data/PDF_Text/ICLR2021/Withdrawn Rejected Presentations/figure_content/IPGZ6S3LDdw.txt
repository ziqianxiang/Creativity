Figure 1: Reward along sample generation between FNAS and MNAS. Blue dots are the searchingresult of MNAS, while red dots are the results of FNAS.
Figure 2: The pipeline of FNAS. The proposed modules are highlighted in orange. Architecturesare sampled by the RL agent and then passed to Uncertainty-Aware Critic (UAC) for predictedperformance and the corresponding uncertainty. Then a decide module will determine whether thesample needs to be trained by Trainer. The Lifelong Knowledge Pool (LKP) helps to initialize newsamples for training. Half of the samples in one batch come from Architecture Experience Buffer(AEB), the other half come from Trainer or UACâ€™s Value Network.
Figure 3: On the left, searching for neural architectures on different tasks leads to different optimalarchitectures. On the right, different tasks share the same global knowledge pool.
Figure 4: Expectation of each operator of optimal models of face experiment and ImageNet exper-iment. Calculated by the 100 optimal models of face experiments and ImageNet experiments andsorted by the significance of the difference.
Figure 5: On the left, the value function pretrained on face recognition task converges much faster.
