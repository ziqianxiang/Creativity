Figure 1: Pixel-based explanations of a model trained topredict the attractiveness label in CelebA.
Figure 2: Our proposed frameworkfor semantic explainability.
Figure 3: FoUrier-SPace model explanations on CIFAR-10 shedding light on adversarial sensitivity.
Figure 4: Frequency-based explanations on Describable Textures, showing sensitivity to periodicity.
Figure 5: Model explanations in terms of disentangled latent features on (a) dSprites and (b) MNIST.
Figure 6: Semantic explanations of a model predicting the attractiveness label in CelebA.
Figure 7: Frequency-based explanations on Restricted ImageNet, providing further evidence thatadversarial sensitivity is linked to high-frequency modes.
Figure 8: Additional frequency-based explanations on the Describable Textures data set.
Figure 9: Model dependence on each labelled attribute in CelebA. Below each image in the latenttraversals, We show the model's corresponding output. The model was trained to predict the “attrac-tive” label in the data. Its dependence here is consistent with the Shapley explanation in Fig. 6.
Figure 10: Semantic Shapley explanation of a model predicting the “attractive” label in CelebA.
Figure 11: Pixel-based explanations of classifier that predicts “mouth slightly OPeIrlabeIin CelebA.
Figure 12: Semantic explanations of classifier that predicts “mouth slightly open^^ in CelebA.
