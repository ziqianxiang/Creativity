Figure 1: Histograms of the correlations between linear maps in an augmented minibatch of a singleCIFAR-10 image for untrained architectures in (a) NAS-Bench-101 (b) NAS-Bench-201. Thehistograms are sorted into columns based on the final CIFAR-10 validation accuracy when trained.
Figure 2: How to score untrained networks: (i) Create a minibatch ofan image repeatedly augmentedwith cutout; (ii) Perform a forward and backward pass using that minibatch to compute J; (iii)Compute the correlation matrix for J and count the number of entries in it that lie between 0 and β .
Figure 3: Plots of our score for 1000 randomly sampled untrained architectures in NAS-Bench-101and NAS-Bench-201 against validation accuracy when trained. The inputs when computing the scoreand the validation accuracy for each plot are from CIFAR-10 (top), CIFAR-100 (bottom-left) andImageNet16-120 (bottom-right). In all cases there is a noticeable correlation between the score for anuntrained network and the final accuracy when trained.
Figure 4: Effect of different CIFAR-10 image (left), and random input images (right) for 9 randomlyselected NAS-Bench-201 architectures (one in each 10% percentile range from 10-20, ..., 90-100).
Figure 6: (a): An example cell from NAS-Bench-IOl, represented as a directed acyclic graph. Thecell has an input node, an output node, and 5 intermediate nodes, each representing an operation andconnected by edges. Cells can have at most 9 nodes and at most 7 edges. NAS-Bench-IOl contains426k possible cells. By contrast, (b) shows a NAS-Bench-201 (Dong & Yang, 2020) cell, which usesnodes as intermediate states and edges as operations. The cell consists of an input node (A), twointermediate nodes (B, C) and an output node (D). An edge e.g. AT B performs an operation on thestate at A and adds it to the state at B. Note that there are 6 edges, and 5 possible operations allowedfor each of these. This gives a total of 5β or 15625 possible cells, (c): Each cell is the constituentbuilding block in an otherwise-fixed network skeleton (where N=5). As such, NAS-Bench-201contains 15625 architectures.
Figure 7: Effect of different CIFAR-10 image (top-left), initialisation (bottom-left), random inputimages (top-right), and mini-batch sizes (bottom-right) for 9 randomly selected NAS-Bench-201architectures (one in each 10% percentile range from 10-20, ..., 90-100). Random input data arenormally distributed. For each network 10 samples were taken for each ablation, using a mini-batchsize of 256, except for mini-batch size for which mini-batch sizes of 32, 64, 128, 256, and 512 wereused. There is less variance in score when using different random input images as opposed to differentCIFAR-10 images.
Figure 8: Further ablation showing the effect of different CIFAR-10 image (top-left), initialisation(bottom-left), random input images (top-right), and mini-batch sizes (bottom-right) for 100 randomlyselected NAS-Bench-201 architectures in the 80% + CIFAR-10 accuracy range when using cutout asthe augmentation method when calculating the score. For each network 20 samples were taken foreach ablation.
Figure 9:	Further ablation showing the effect of different CIFAR-10 image (top-left), initialisation(bottom-left), random input images (top-right), and mini-batch sizes (bottom-right) for 100 randomlyselected NAS-Bench-201 architectures in the 80% + CIFAR-10 accuracy range when using additiveGaussian noise as the augmentation method when calculating the score. For each network 20 sampleswere taken for each ablation.
Figure 10:	Visualising the tradeoff between search time and accuracy on CIFAR-10 (test) for differentNAS algorithms on NAS-Bench-201. By removing the need for training, our method is able to findaccurate networks in seconds instead of hours.
Figure 11:	Plots of association between score and final CIFAR-10 validation accuracy for variousinitialisation strategies.
Figure 12:	Plots of association between aggregated score and final CIFAR-10 validation accuracyfor various initialisation strategies. The aggregated score is the maximum score of 10 independentinitialisations of the same architecture.
Figure 13: Controlling for different values of β in the scoring function. Points are shown as the meanvalue over 500 runs, with the standard deviation shown in the shaded areas.
Figure 14: (top) A plot of score trajectories during training for 20 networks in NAS-Bench-201.
Figure 15: Plots of CIFAR-10 final accuracy against score for alternative augmentation types: (left)Additive gaussian noise N(0, 0.01), (right) colour jitter.
Figure 16: Plots of association between score and final CIFAR-10 validation accuracy for 6 seedsusing random images (generated via torchvision FakeData).
