Figure 1: Illustrations of the forward and backward propagation of the training data using 2D ODE(2) and SDE (3) models. (a) the original image; (b) & (d) the features of the original image generatedby the forward propagation using ODE and SDE, respeCtively; (C) & (e) the reCovered images byreverse-engineering the features shown in (b) & (d), respeCtively. We see that it is easy to break theprivaCy of the ODE model, but harder for SDE.
Figure 2: Visualization of a few selected images from the IDC dataset.
Figure 3: Performance of residual perturbation for En5ResNet8 with different noise coefficients(γ) and membership inference attack thresholds on the IDC dataset. Residual perturbation cansignificantly improve membership privacy and reduce the generalization gap. γ = 0 corresponding tothe baseline ResNet8. (Unit: %)classification probabilities of belonging to each class. Then we take the top three classificationprobabilities (or two in the case of binary classification) to form the feature vector for each data point.
Figure 4:	Performance of En5ResNet8 with residual perturbation using different noise coefficients(Y) and membership inference attack threshold on CIFAR10. Residual perturbation can not onlyenhance the membership privacy, but also improve the classification accuracy. Y = 0 correspondingto the baseline ResNet8 without residual perturbation or model ensemble. (Unit: %)60⅛6.6066∙OooopoLISaIWgammatrain and test accuracλc⅛ 30.5 35.6 30.2 25.60.0 0.5 0.75 1.0gammaAUC under different noises0.9030.581 0.521 0.515gamma0.0 0.5 0.75 1.0gammaFigure 5:	Performance of En5ResNet8 with residual perturbation using different noise coefficients(Y) and membership inference attack threshold on CIFAR100. Again, residual perturbation can
Figure 5:	Performance of En5ResNet8 with residual perturbation using different noise coefficients(Y) and membership inference attack threshold on CIFAR100. Again, residual perturbation cannot only enhance the membership privacy, but also improve the classification accuracy. Y = 0corresponding to the baseline ResNet8 without residual perturbation or model ensemble. (Unit: %)En5ResNet is remarkably better in protecting the membership privacy, and as Y increases the modelbecomes more resistant to the membership attack. Also, as the noise coefficient increases, the gapbetween training and test accuracies becomes smaller, which resonates with Theorem 3. For instance,when Y = 0.2 the AUC for the attack model is 0.495 and 0.563, respectively, for En5ResNetS andResNet8; the classification accuracy of En5ResNet8 and ResNet8 are 0.867 and 0.847, respectively.
Figure 6:	The performance of residual perturbation with different noise coefficients (γ) and differentnumber of models in the ensemble. The optimal privacy-utility tradeoff lies in the choice of thesetwo options. (Unit: %)(a) CIFARi0(En5ResNet8)	(b) CIFARi00(En5ResNet8)	(c) IDC (En5ResNet8)Figure 7:	ROC curves for different datasets. (ga: noise coefficient γ)4.3.1	Effects of the Number of Models in the EnsembleIn this part, we consider the effects of the number of residual perturbed ResNets in the ensemble.
Figure 7:	ROC curves for different datasets. (ga: noise coefficient γ)4.3.1	Effects of the Number of Models in the EnsembleIn this part, we consider the effects of the number of residual perturbed ResNets in the ensemble.
Figure 8:	Illustrations of the forward and backward propagation of the training data using the SDEmodel (7). (a) is the features of the original image generated by the forward propagation using SDE;(b) is the recovered images by reverse-engineering the features shown in (a).
Figure 9:	Performance of residual perturbation (8) for En5ResNet8 with different noise coefficients(γ) and membership inference attack thresholds on the IDC dataset. Residual perturbation cansignificantly improve membership privacy and reduce the generalization gap. γ = 0 corresponding tothe baseline ResNet8. (Unit: %)D.2.1 Residual Perturbation vs. Differentially Private Stochastic GradientDescentWe have shown that the first residual perturbation (6) outperforms the DPSGD in protecting mem-bership privacy and improving classification accuracy. In this part, we further show that the secondresidual perturbation (8) also outperforms the benchmark DPSGD with the above settings. Table 2lists the AUC of the attack model and training & test accuracy of the target model; we see thatthe second residual perturbation can also improve the classification accuracy and protecting bettermembership privacy.
Figure 10:	Performance of En5ResNet8 with residual perturbation (8) using different noise co-efficients (Y) and membership inference attack threshold on CIFAR10. Residual perturbation (8)can not only enhance the membership privacy, but also improve the classification accuracy. Y = 0corresponding to the baseline ResNet8 without residual perturbation or model ensemble. (Unit: %)a66,侬66∙OooopoLIS 8」£0.0 0.5 1.0 1.5 2.0noise ∞efficientP-OqSElFigure 11: Performance of En5ResNet8 with residual perturbation (8) using different noise coeffi-cients (Y) and membership inference attack threshold on CIFAR100. Again, residual perturbation (8)can not only enhance the membership privacy, but also improve the classification accuracy. Y = 0corresponding to the baseline ResNet8 without residual perturbation or model ensemble. (Unit: %)D.4 ROC Curves for THE Experiments on Different DatasetsFigure 12 plots the ROC curves for the experiments on the different datasets with different modelsusing the second residual perturbation strategy. These ROC curves again show that if Y is sufficientlylarge, the attack model,s prediction will be nearly a random guess.
Figure 11: Performance of En5ResNet8 with residual perturbation (8) using different noise coeffi-cients (Y) and membership inference attack threshold on CIFAR100. Again, residual perturbation (8)can not only enhance the membership privacy, but also improve the classification accuracy. Y = 0corresponding to the baseline ResNet8 without residual perturbation or model ensemble. (Unit: %)D.4 ROC Curves for THE Experiments on Different DatasetsFigure 12 plots the ROC curves for the experiments on the different datasets with different modelsusing the second residual perturbation strategy. These ROC curves again show that if Y is sufficientlylarge, the attack model,s prediction will be nearly a random guess.
Figure 12: ROC curves for different datasets. (nc: noise coefficient)E More Experimental DetailsWe give the detailed construction of the velocity field F(x(t), W(t)) in (3) and (7) that used togenerate Figs. 1 and 8 in Algorithm 1.
Figure 13: Architectures of the ResNet8 used in our experiments.
Figure 14: Architectures of the basic building block of ResNets studied in this paper.
