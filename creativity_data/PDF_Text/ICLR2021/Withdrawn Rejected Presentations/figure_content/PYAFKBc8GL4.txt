Figure 1: A toy example with F1 (w), F2 (w) as the local objective, and F (w) = (F1 (w) +F2(w))∕2 as the global objective function with global minimum w*. At each round, only one clientis selected to perform local updates. (a): Model updates for sampling clients with larger loss; (b):Model updates for sampling clients uniformly at random (we select client in the order of 2,2,1,1,2).
Figure 2: Global loss performance of πrand, πpow-d, and πadapow-d for the quadratic experiments withC = 0.1. πpow-d convergences faster than πrand for even selecting from a small pool of clients(K = 30). As convergence speed increases, solution bias also increases for πpow-d, but πadapow-d isable to eliminate this solution bias while gaining nearly identical convergence speed to πpow-d.
Figure 3: Estimated theoretical valuesp and p/e for the quadratic simula-tion. The convergence speed (p) andbias (e/p) are consistent with the resultsshown in Figure 2 for πrand and πpow-d.
Figure 4: Global loss for logistic regression on the synthetic dataset, Synthetic(1,1), with πrand,πpow-d, and πadapow-d for d ∈ {2m, 10m} where K = 30, m ∈ {1, 2, 3}. πpow-d converges approx-imately 3 × faster for d = 10m and 2 × faster for d = 2m than πrand to the global loss ≈ 0.7.
Figure 5: Test accuracy and training loss for different sampling strategies with K = 100, C = 0.03for varying d on the FMNIST dataset. For both small and large α, πpow-d achieves at least 10% testaccuracy improvement than πrand and the training loss converges at a much higher rate than πrand.
Figure 6: Test accuracy and training loss for different sampling strategies including πcpow-d andπrpow-d, for K = 100, C = 0.03 on the FMNIST dataset. πrpow-d which requires no additionalcommunication and minor computation, yields higher test accuracy than πrand and πafl.
Figure 7:	Clients’ selected frequency ratio for optimizing the quadratic model for πrand and πpow-dwith K = 30, C = 0.1. The selected ratio is sorted in the descending order.
Figure 8:	Test accuracy and training loss in the virtual environment where clients have intermittentavailability for K = 100, C = 0.03 with πrand, πpow-d, and πrpow-d on the FMNIST dataset. For bothα=2 and α = 3, πpow-d achieves approximately 10% higher test accuracy than πrand .
Figure 9:	Test accuracy and training loss for different sampling strategies for K = 500, C = 0.03with πrand , πpow-d, and πafl on the EMNIST dataset.
Figure 10:	Test accuracy and training loss for different sampling strategies for K = 500, C = 0.03with πrand , πpow-d , πcpow-d , πrpow-d, and πafl on the EMNIST dataset.
Figure 11: Test accuracy and training loss for different sampling strategies for K = 100, C = 0.1with πrand, πpow-d, πcpow-d, πrpow-d, and πafl on the FMNIST dataset. For larger C = 0.1, πpow-dperforms with 15% and 5% higher test accuracy than πrand for α = 2 and α = 0.3 respectively.
Figure 12: Test accuracy and training loss for πrand, πpow-d, and πafl for K = 100, C = 0.03 on theFMNIST dataset with mini-batch size b = 128 and τ = 30.
Figure 13:	Test accuracy and training loss for πrand , πpow-d , πcpow-d , πrpow-d, and πafl for K100, C = 0.03 on the FMNIST dataset with mini-batch size b = 128 and τ = 30.
Figure 14:	Test accuracy and training loss for πrand, πpow-d, and πafl for K = 100, C = 0.03 on theFMNIST dataset with mini-batch size b = 64 and τ = 100.
Figure 15:	Test accuracy and training loss for πrand , πpow-d , πcpow-d , πrpow-d, and πafl for K100, C = 0.03 on the FMNIST dataset with mini-batch size b = 64 and τ = 100.
