Figure 1: Certified radius of several samples with different Gaussian distribution noise under threemodels. (a) Smooth-adv model test with test set samples. (b) Our pretrain model test with train setsamples. (c) Our finetune model test with test set samples which are the same as (a).
Figure 2: Comparing our sample-wise method with Smooth-Adv on CIFAR-10.
Figure 3:	Comparing our sample-wise method with Smooth-Adv(Salman et al., 2019)B.2 Ablation StudyAs aforementioned, our method consists of two parts: the first one is pertrain-to-finetune frameworkand the second one is sample-wise certification procedure. Thus, we study the effects of differentparts on CIFAR-10 and MNIST as shown in Fig. 4 and Fig. 5. We have conducted the following fouralgorithms:Ours-diff: Our pretrain-to-finetune model test under sample-wise certification procedure, withspecific different noise level for each test data.
Figure 4:	The effects of different components in our model on CIFAR-10.
Figure 5:	The effects of different components in our model on MNIST.
Figure 6:	Distribution of the degree in G for CIFAR-10 and MNISTFigure 6 shoWs that most of the graph nodes have a loW degree and only a feW nodes have a verylarge degree, especially the degree even exceeds 800 in MNIST. Exactly, there are 569 nodes inGCIFAR-10 and 4777 nodes in GMNIST Which means that only 5% regions intersect others inCIFAR-10 but nearly 47% regions intersect others in MNIST if Without post-processing. Due tothe high overlap betWeen different regions in MNIST, our sample-Wise method performs poorly onMNIST.
