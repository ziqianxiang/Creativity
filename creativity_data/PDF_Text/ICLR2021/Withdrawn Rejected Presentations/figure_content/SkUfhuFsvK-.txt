Figure 1: T-SNE visualization of aggregated features in the Cora dataset.
Figure 2: Comparison of the number of falsely labeled nodes introduced by different checkingmechanism.
Figure 3: The overall FASG framework for semi-supervised node classification.
Figure 4: Accuracy, new added nodes and bad training nodes in each round7Under review as a conference paper at ICLR 2021Table 5: Comparison of prediction accuracy on PubMed datasetLabel Rate	0.03%	0.05%	0.1%Node2Vec	37.2%	38.2%	42.9%LP	58.3%	61.3%	63.8%Cheby	40.4%	47.3%	51.2%GCN	51.1%	58.0%	67.5%GAT	50.6%	59.1%	65.0%Co-training	55.5%	61.6%	67.8%Self-training	56.3%	63.6%	70.0%MultiStage	57.4%	64.3%	70.2%M3S	59.2%	64.4%	70.6%FASC	60.1%	65.2%	70.7%In order to reveal how our algorithm is affected by the number of training rounds K , we reportthe numbers of newly added nodes, bad training nodes and the prediction accuracy on the CiteSeerdataset for different label rates with increasing K from 0 to 50. Note that when K is 0, the frameworkdegrades to the plain GCN model. As shown in Fig. 4(a), accuracies grow rapidly during the first fewrounds for all label rates. For a small label rate (e.g. 0.005), the accuracy tends to grow continuously
