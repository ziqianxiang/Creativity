Figure 1: Schematic of our proposed SDF-based meta-shape completion method.
Figure 2: Shape completion results on ShapeNet for chairs (training category).
Figure 3: Shape completion results on ShapeNet for caps (novel category).
Figure 4: Scene completion results on ICL-NUIM for office rooms.
Figure 5: Scene completion results on ICL-NUIM for living rooms.
Figure 6: Encoder of OccNet (Mescheder et al., 2019). OccNet uses a version of PointNet that carriesout max pooling procedures in multiple places. Compared to our encoder (Figure 1, main paper) thisarchitecture is much more complex. Future Work Will involve extending MSC to different encoderarchitectures.
Figure 7: Shape completion results on ShapeNet for Basket (training category). Our method startsconservatively and improves as more points are added (it also correctly infers that there is no lid).
Figure 8: Shape completion results on ShapeNet for Bathtub (training category). Our proposedmethod captures the large cavity with only 100 observations, while both DeepSDF and OccNetproduce artifacts at this level of sparsity.
Figure 9: Shape completion results on ShapeNet for Car (training category). Our method producesa smooth car-like surface with only 50 observations, while both DeepSDF and OccNet generate largeartifacts at this level of sparsity. Additionally, PCN fails to produce a car-like point cloud from only50 observations.
Figure 10: Shape completion results on ShapeNet for Lamp (training category). All methodsstruggle with predictions for this category, irrespective of the number of observations. Particularly,IGR consistently assumes that the target object is rectangular, even at higher density levels. At theselevels, our method succeeds in capturing the approximate geometry of the lamp.
Figure 11: Shape completion results on ShapeNet for Mug (training category). Our method isthe only one that succeeds in capturing the cavity of the mug from sparse observations, while othermethods assume there is a lid. As expected, PCN only produces what looks like a densified versionof the original point cloud.
Figure 12: Shape completion results on ShapeNet for Table (training category). Our methodcorrectly captures the rectangular portion of the table when only 50 observations are available, andgradually completes other parts as the number of observations increase. IGR, on the other hand,assumes that the object is box-shaped at lower densities and maintains this assumption even at higherdensity levels.
Figure 13: Shape completion results on ShapeNet for Bed (novel category). Our proposed methodcorrectly predicts the overall box shape of the object, and gradually improves this prediction as moreobservations points become available. Other methods, such as OccNet and IGR, fail to separate thetop and lower portions of the object even at higher density levels.
Figure 14: Shape completion results on ShapeNet for Bed (novel category). With only 50 pointsour proposed method is already capable of predicting the correct shape, that is then further refinedwith more observations. OccNet requires a higher number of observations before it settles on thecorrect shape, while IGR converges to the wrong object.
Figure 15: Shape completion results on ShapeNet for Guitar (novel category). Here, PCN is theonly method that seems to succeed at shape completion, mostly because of the compact nature of theobject that enables accurate densification. Interestingly, as the number of observations increase, ourproposed method performs better without post-encoder optimization, producing a reasonable outputwith 300 observations.
Figure 16: Shape completion results on ShapeNet for Motorcycle (novel category). Similar to theguitar category (Figure 10), our proposed method performs better without post-encoder optimization.
Figure 17: Shape completion results on ShapeNet for Pistol (novel category). Interestingly, IGRseems to change the assumed category as the number of observation points increase. Again, due tothe presence of finer details our method performs better without post-encoder optimization, achievingreasonable results with as few as 100 observations.
Figure 18: ICL-NUIM shape completion results for office rooms. With as few as 50 points, ourproposed method is able to recover most details of the room, including furniture arrangement, walldistribution and floor. As more observations are introduced, these details are further refined withoutdiverging. PCN results are mostly a densification of the observed points, IGR requires higher densitiesfor a proper convergence, and DeepSDF produces a large amount of artifacts throughout the scene.
Figure 19: ICL-NUIM shape completion results for office rooms. With as few as 50 points, ourproposed method is able to recover most details of the room, including furniture arrangement, walldistribution and floor. As more observations are introduced, these details are further refined withoutdiverging. PCN results are mostly a densification of the observed points, IGR requires higher densitiesfor a proper convergence, and DeepSDF produces a large amount of artifacts throughout the scene.
Figure 20: ICL-NUIM shape completion results for living rooms. With as few as 50 points, ourproposed method is able to recover most details of the room, including furniture arrangement, walldistribution and floor. As more observations are introduced, these details are further refined withoutdiverging. PCN results are mostly a densification of the observed points, IGR requires higher densitiesfor a proper convergence, and DeepSDF produces a large amount of artifacts throughout the scene.
