Table 1: Left: Attack impacts for three attack formulations with `2 norm bound and = 10-8. Right:Attack impacts for three attack formulations with `1 norm bound and = 10-8.
Table 2: Average Q-values for the best, worst, the adversarial actions and impacts, loss in the Q-valuescaused by the adversarial influence, and impacts over the episodes.
Table 3: Attack impacts for three attack formulations with '∞ norm bound and e = 10-8.
Table 4: Attack impacts for three different attack formulations with `2 norm bound and =10-10,n= 1Games	Huang	Pattanaik	MyopicAmidar	0.050±0.25	0.138±0.31	0.941±0.02Bankheist	0.189±0.13	0.247±0. 15	0.487±0.09Beamrider	0.001±0.40	0.096±0.36	0.634±0. 15Riverraid	0.173±0.23	0.234±0.21	0.367±0. 1 6RoadRunner	0.035±0. 15	0.090±0. 12	0. 15 1±0. 12Pong	0.173±0.23	0.014±0.03	0.887±0.09Seaquest	0.321±0.14	0.290±0.4	0.502±0.22UpNDown	0.475±0.24	0.615±0.10	0.91 1±0.04A.3 Games and Agent BehaviourIn this section we share our observations on the behaviour of the trained agent under attack. In Figure9 the agent performs well until it suddenly decides to stand still and wait for the enemy to arrive.
Table 5: Average empirical probabilities of a* and aw, and impacts for three different formulation forRiverraid and BeamRider from Atari environment with '2-norm bounded perturbation and E = 10-8.
