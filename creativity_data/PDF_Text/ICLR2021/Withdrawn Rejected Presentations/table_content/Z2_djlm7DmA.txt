Table 1: The statics of datasets and parameters for the best performance on them.
Table 2: Results of QLogicE comparing with current state of the art (SOTA). This table demonstratesthe SOTA results of the three main categories. They are neural network, translation and factorizationbased models. These results are adapted from the SUrvey(Rossi et al., 2020).
Table 3: Results of QLogicE comparing with existing logic or rule based models. RPJE(Niu et al.,2019), pGAT(Vardhan et al., 2020). In this table, the models are newly proposed, ADRL(Wanget al., 2020), CoPER-MINERVA(CoPER-ConvE)(Stoica et al., 2020), ParamE-CNN(ParamE-MLP,ParamE-Gate)(Che et al., 2020). The results are adapted from the original papers.
Table 4: Results of QLogicE comparing with current state of the art on small datasets. This tabledemonstrates the experimental results on the two widely used small datasets. The results are adaptedfrom the PaPer(Stoica et al., 2020).
Table 5: Results of QLogicE comparing with existing logic rules based models. In this table, alldata are from their originally paper. They are KALE(Guo et al., 2016), Neural LP(Yang et al.,2017), RUGE(Guo et al., 2018), RuleN(Meilicke et al., 2018), E2R(Garg et al., 2019), IterE(Zhanget al., 2019),pLogicNet(pLogicNet*) (QU & Tang, 2019), RARL(Pirrθ, 2020), AnyBURL(MeiIickeet al., 2020). The results are adapted from the original papers.
Table 6: Results of ablation study. The data of TransE is from (Rossi et al., 2020) and E2R is from(Gargetal., 2019).________________________________________________________________________M a 1 FB15k	WN18	FB15k237	WN18RR	YAGO3-10Model ____________________________________________________________________________________M H1 H10 M H1 H10 M H1 H10	M H1 H10 M H1 H10TransE 0.628 49.36	84.73	0.646	40.56	94.87	0.310	21.72	49.65	0.206	2.79	49.52	0.501	40.57	67.39E2R 0.964 96.40	96.40	0.710	71.10	71.10QLOgiCE).968 96.84	96.84	0.915	91.48	91.48	0.949	94.94	94.94	0.928	92.79	92.79	0.937	93.74	93.74Table 6 demonstrates the ablation of the models. The results on datasets FB15k our model slightlybetter than the baseline E2R but much better than TransE. For the dataset WN18, only in Hits@10,the performance of TransE is better than our model QLogicE while the 41.64% in MRR and 125.54%worse than our model, which is promising progress. The paperGarg et al. (2019) didn’t provide re-sults on the datasets FB15k237 and WN18RR. For them, our model is better than TransE with206.13% in MRR,337.11% in Hits@1 and 91.22% in Hits@10 on the former and 350.49% inMRR,3225.81% in Hits@1 and 87.38% in Hits@10. On the dataset YAGO3-10, the result in MRR,Hits@1 and Hits@10 is better than TransE with margin of 87.03%, 131.06% and 39.10%, respec-tively.
