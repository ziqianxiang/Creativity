Table 1: Summary of results on GLUE.								Model	COLA	SST-2	MRPC	QQP	MNLI (m/mm)	QNLI	RTE	GLUE AvgBERT	56.8	92.3	89.7	89.6	84.6/85.2	91.5	69.3	82.3NORMAL BERT+DA	58.6	93.2	86.5	86.7	84.2/84.4	91.1	68.9	81.7DCL	60.9	93.0	89.7	90.0	84.7/84.6	91.7	69.7	83.0BERT	46.4	91.8	88.1	84.9	81.6/82.2	89.2	67.1	78.9ROBUST BERT+DA	53.8	92.9	85.6	85.5	83.1/83.4	90.7	66.3	80.1DCL	48.4	92.4	86.0	85.5	82.5/82.7	89.7	68.8	79.5Main ResultsFrom Table 1 and 2, we can observe the fol-lowing: 1) Vanilla BERT achieves poor per-formance in the robust set on both GLUE andSQUAD, which indicates that the previous fine-tuning approach cannot obtain a robust textualrepresentation. This will lead to performancedecay with permutations. 2) With data augmen-tation, BERT can obtain improved performancein the robust set; however, a slight performancedecay is observed in the original test set. Weargue that data augmentation can obtain better
Table 2: Summary of results on SQuAD 1.1Model	F1 EMBERT	88.5	80.8Normal BERT+DA	88.2 80.4DCL	88.4 81.0BERT	86.7 77.8Robust BERT+DA	87.8	79.9DCL	86.8	78.1performance by fitting to task-specific data distribution; there is no guarantee that more data willresult in robust textual representations. 3) Our DCL approach achieves improved performance inboth the original test set and robust set compared with vanilla BERT. Note that our DCL is anunsupervised approach, and we leverage the same training instances with BERT. The performanceimprovements indicate that our approach can obtain more robust textual representations that enhancethe performance of the system.
Table 3: Summary of results on CoLA and SNLI.		Model	CoLA	SNLIBERT	56.8	91.0NORMAL	BERT+Adv	55.0	91.1DCL	59.0	91.0BERT	47.7	90.1Adversarial BERT+Adv	55.1	91.1DCL	48.9	90.5test set with and without an adversarial attack, which further demonstrates that our approach canobtain robust textual representations that are stable for different types of permutations.
