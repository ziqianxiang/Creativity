Table 1: Summary of NLP datasets.
Table 2: Accuracy [%] of the victim models and the extracted models among different datasets interms of domains and sizes.
Table 3: Percentage of test sets uni-gram and 5-gram overlaPPing with different queries. Since AGnews is derived from AG news (full) and they show a similar distribution, we omit it .
Table 4: AIA attack success over different datasets. Notehigher value means better emPirical Privacy, i.e., lowerattack success. (2nd half: DA reserved for the training ofAIA attack model.)2EmPirically, we do not have access to the training data of the victim model.
Table 5: Transferability is the percentage of adversarialexamples transferring from the extracted model to thevictim model. Higher is better. deepwordbug (Gao et al.,2018); textbugger (Li et al., 2018a); textfooler (Jin et al.,2019); adv-bert (Sun et al., 2020). w-box: white-boxattack. Rand: randomly select a word.
Table 6: Attack performance on TP-US and AG news (full) with mismatched architectures betweenthe victim and the extracted model.
Table 7: Attack performance under different defences and datasets. ND: no defence; Ï„ : temperatureon softmax. For MEA and AET, lower scores indicate better defences, conversely for AIA. Allexperiments are conducted with 1x queries.
Table 8: The accuracy of victim models and extracted models among different datasets in terms ofdomains and sizes.
Table 9: AIA performance on attributes of different datasets. All experiments are conducted with 1xqueries.
Table 10: Adversarial examples generated by adv-bert on different datasets. All of them cause amisclassification. The misspellings are highlighted in red.
