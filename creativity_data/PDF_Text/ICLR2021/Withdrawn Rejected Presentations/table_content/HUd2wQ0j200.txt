Table 1: Training hyperparameters and details of each tasks considered in this benchmark. All thearchitectures in the search space have been fully trained. We provide multiple metrics for evaluationon the train/val/test set. Each task requires a backbone-decoder network structure with task-specificdecoder and loss function. GAP denotes global average pooling. CE denotes the cross entropy loss.
Table 2: Comparisons of TransNAS-Bench-101 with previous benchmarks. Although TransNAS-Bench-101 has a smaller search space, it contains more datasets, domains, and search space types.
Table 3: Performance comparison of different transferrable NAS methods. Room layoutâ€™s L2 lossis multiplied by a factor of 100 for better readability. The transferred versions of REA and PPOare pretrained on the least time-consuming task, Jigsaw. The average scores of all algorithms arecalculated with the remaining 6 tasks.
