Table 1: Results for object classification on theAWA2 and aPY dataset. We report the averageclass-balanced accuracy of the models on 5 ran-dom seeds and the standard error. The results forSP-AEN, LisGAN, and ZSML are obtained fromVerma et al. (2020).
Table 2: Results for intent classification on theSNIPS-NLU dataset. We report the averageaccuracy of the models on 5 random seeds andthe standard error. The results for Zero-shotDNN, IntentCapsNet, and ReCapsNet-ZS areobtained from Liu et al. (2019a).
Table 3: Results for object classification on ImageNet dataset. We report the class-balanced top-kaccuracy on zero-shot learning (ZSL) and generalized zero-shot learning (GZSL) for ImageNetclasses k-hops away from the ILSVRC 2012 classes. The results for GCNZ, SGCN, and DGP areobtained from Kampffmeyer et al. (2019).
Table 4: The results for zero-shot fine-grained entity typing on Ontonotes and BBN. We report theaverage strict accuracy, loose micro F1, and loose macro F1 of the models on 5 random seeds and thestandard error.
Table 5: The results for zero-shot learning tasks with other graph neural networks. We report theaverage performance on 5 random seeds and the standard error.
Table 6: Zero-shot datasets used in our experimentsFor object classification datasets, AWA2 and aPY, we do not require the training examples becausewe use pretrained weights from ResNet101 to learn the class representations. We crop objects fromAPY test dataset as multiple objects are present in the same image. To crop the objects, we usebounding box provided in Farhadi et al. (2009), add 15px padding on all sides and crop them.
Table 7: Results for object classification on the AWA2 and aPY dataset. Resutlts for methods with *(asterisk) obtained from Verma et al. (2020), E-PGN from (Yu et al., 2020), APNet from Liu et al.
Table 8: Graph AggregatorsZSL-KG-GCN uses a mean aggregator to learn the neighbourhood structure. ZSL-KG-GAT projectsthe neighbourhood nodes to a new features h0u(l-1) = Wh(ul-1). The neighbourhood node featuresare concatenated with self feature and passed through a self-attention module for get the attentioncoefficients. The attention coefficients are multiplied with the neighbourhood features to the getthe node embedding for the l-th layer in the combine function. ZSL-KG-RGCN uses a relationalaggregator to learn the structure of the neighbourhood. To avoid overparameterization from therelational weights, we perform basis decomposition of the weight vector into B bases. We learn |B |relational coefficients and |B | weight vectors in the aggregate function and add with the self featurein combine function. ZSL-KG-LSTM uses LSTM as an aggregator to combine the neighbourhoodfeatures. The nodes in the graph are passed through an LSTM and the last hidden state is taken as theaggregated vector. The aggregated vector is concatenated with the node’s previous layer feature andpassed to the combine function to get the node representation.
Table 9: Hyperparameters for the biLSTM with attention example encoder in the language relatedtasksFor intent classification and fine-grained entity typing, we assume a low-rank for the compatibilitymatrix W . The matrix W ∈ Rd×d is factorized into A ∈ Rh×d and B ∈ Rd×h where h is thelow-rank dimension. Table 9 summarizes the hyperparameters used in the example encoders which isa biLSTM with attention or a task-specific variant of it.
Table 10: Output dimensions of the graph neural networks in our experiments.
Table 11: The hyperparameters used in our Transformer Graph Convolutional Network.
