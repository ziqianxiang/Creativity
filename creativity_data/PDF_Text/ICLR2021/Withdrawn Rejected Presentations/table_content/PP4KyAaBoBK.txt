Table 1: Experiments on U-RISC Dataset. This table shows the different evaluation results of thefirst two rounds of human annotations (H.L.1, H.L.2) and six segmentation results: U-Net (Ron-neberger et al. (2015)), LinkNet(Chaurasia & Culurciello (2017)), CASENet (Yu et al. (2017)),SENet (Hu et al. (2018)), U-Net++ (Zhou et al. (2018)),and GLNet (Chen et al. (2019b)). PHD-tmeans the PHD score with tolerance distance t. HD means Hausdorff. -sk means evaluating onskeleton. Note that the ground truth is the third round of human annotation.
Table 2: Paremeters in methods.
Table 3: Formulation of criteria.
Table 4: Experiments on ISBI2012 and SNEMI3D.
Table 5: Experiments on ISBI2012 Datasets. This table shows the different evaluation resultsof three segmentation results: U-Net (Ronneberger et al. (2015)), CASENet (Yu et al. (2017)),LinkNet(Chaurasia & Culurciello (2017)). PHD-t means the PHD score with tolerance distance t.
Table 6: Experiments on SNEMI3D Datasets.		This table shows the different evaluation results	of three segmentation results: U-Net (Ronneberger et al. (2015)), CASENet (Yu et al. (2017)),			LinkNet(Chaurasia & Culurciello (2017)). PHD-t means the PHD score with tolerance distance t.			HD means Hausdorff. -sk means evaluating on skeleton. Note that the ground truth is the third round			of human annotation.			Methods	U-Net	CASENet	LinkNetF1↑	0.9380	0.9389	0.9401F1-sk↑	0.2236	0.2913	0.2830IoU ↑	0.9368	0.9373	0.9389IoU-sk ↑	0.1598	0.1732	0.2001V-Rand-sk ↑	0.9201	0.9210	0.9276V-Info-sk ↑	0.9224	0.9226	0.9264Dice ↑	0.9380	0.9389	0.9401Dice-sk ↑	0.2236	0.2913	0.2830TPVF ↑	0.9013	0.9006	0.9103TPVF-sk ↑	0.5466	0.5349	0.5382TNVF ↑	0.9324	0.9321	0.9299TNVF-sk ↑	0.9709	0.9743	0.9750Prec ↑	0.8980	0.8992	0.8793Prec-sk ↑	0.1928	0.1917	0.1876
