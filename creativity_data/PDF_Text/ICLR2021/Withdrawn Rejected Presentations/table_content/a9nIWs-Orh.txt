Table 1: GLUE Dev results. Our results are based on single model trained with single task anda median over five runs with different random seed but the same hyperparameter is reported foreach task. The results of MT-DNN, XLNETLARGE, ALBERT and RoBERTa are from Liu et al.
Table 2: Parameter Comparison.
Table 3: GLUE Test results, scored by the official evaluation server. All the results are obtained fromGLUE leaderboard (https://gluebenchmark.com/leaderboard). The number beloweach task’s name indicates the size of training dataset. Recently the GLUE benchmark has forbiddenall the submissions to treat the QNLI as a ranking task, which results in the missing of some models’accuracies on the QNLI. aDevlin et al. (2019); bLiu et al. (2019b); cZhu et al. (2020); dYang et al.
Table 4: Ablation study over model design consideration on the development set of CoLA and STS-B. The result for each model is a median of five random runs. Both HIRE and fusion networksignificantly improve the model performance on all two datasets.
Table 5: Effect of dynamic mechanism when computing the importance scores. A median Matthewscorrelation of five random runs is reported for CoLA on the development set.
Table 6: Ablation study over GRU layer number in fusion network on the development set of CoLA.
