Table 1: Test sets performance on GLUE benchmark. All the results are obtained from Liu et al.
Table 2: Compairison with on test sets of GLUE benchmarkTable 3 shows our approach also improves PrMLs performance on the SNLI benchmark. Theresult indicates that the performance of our method is comparable to published SOTA achievedby SemBERT. Unlike SemBERT that incorporates explicit contextual semantics by leveraging apre-trained semantic role labeler, LaSA only uses a pre-sampled dictionary to provide the auxiliarysegmentation information. Thus, compared to SemBERT, LaSA is a more flexible method to achieveperformance improvement.
Table 3: Accuracy on dev and test sets of SNLI. SemBERTWWM (Zhang et al., 2019b) is thepublished SOTA on SNLI.
Table 4: Ablation studied on dev sets of GLUE benchmark5.2	Encoder ArchitectureConneau et al. (2017) manifest that different sentence encoder architectures have a significantimpact on the performance of models. Toshniwal et al. (2020) also indicate that the choice ofspan representation has significant impact on many natural language processing (NLP) tasks involvereasoning with textual spans, including question answering, entity recognition, and coreferenceresolution.
Table 5: The influences of different encoder architecture5.3	SIZE OF n-GRAM DICTIONARYGiven the fact that we use a pre-sampled dictionary to segment the sentences, different sizes ofdictionaries will lead to different segmentation. Initially, for sentences without segmentation,every single token is regarded as a span. Figure 3 shows how dictionary size and correspondingsegmentation influence the average number of spans in the sentences in the CoLA and MRPCdatasets. As the dictionary size enlarges, more n-grams are matched and regrouped together, whichsignificantly reduces the average number of spans.
Table 6: Results on dev sets of GLUE benchmark with stronger baseline5.5	LaSA for Token-Level TaskOur experiments are conducted on the GLUE benchmark which only requires sentence-levelrepresentations. However, for natural language understanding, there are other tasks such as named-entity recognition (NER), where token-level representations are needed. Our method can be appliedto token-level tasks with simple modification of encoder architecture (e.g. removing the poolinglayer of CNN module). Table 7 shows the results of our approach on the CoNLL-2003 NamedEntity Recognition (NER) task (Tjong Kim Sang & De Meulder, 2003) with BERT as our PrLM.
Table 7: F1 on dev and test sets of named entity recognition on the CoNLL-2003 dataset.
Table 8: Results on dev sets of GLUE benchmark, each result is a median over three runs.
Table 9: Results of McNemars tests for binary classification tasks of GLUE benchmark, tests areconducted based on the results of best run.
