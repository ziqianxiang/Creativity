Table 1: Trained models with restricted clipping and learning rateDataset	clip	lr	%clean	%attack	totalGTSRB	-10-4-	-10-4-	≥ %95	≥ %85	124MNIST	-10-4-	5 × 10-5	≥ %95	≥ %85	49CIFAR10	5 × 10-4	10-1	≥ %90	≥ %85	946 Experimental EvaluationWe executed our experiments on a server with Linux OS, Intel Xeon CPU E3-1275 v6@3.80GHz,64GB of RAM and an NVIDIA Quadro P5000 GPU with 16GB of memory. Our attack code isimplemented in python 3.6 using the pytorch Paszke et al. (2019) library. We use Intel SGX asour platform for TEE. For SGX Proof-of-concept implementation, DarkNet Redmon (2013-2016)library is significantly modified to run the experiments. Our SGX code has been tested with SDK2.9 and the code runs inside a docker container in hardware mode. Our experiments are designed toinvestigate two aspects. First, we evaluate the impact of integrating randomized matrix verificationand show that it can potentially increase computational efficiency.Second, we analyze the effective-ness of gradient clipping in forcing the attacker to deviate from the honest protocol in significantnumbers of mini-batch steps. Various attack hyper-parameters (e.g. poisoning rate) were evaluatedin determining their importance towards a successful attack with minimal deviation. This is impor-tant because, if the attacker needs to deviate over more mini-batch steps, then the TEE can detectsuch deviations with a smaller number of random verification steps (i.e., pc is higher in equation 2 ).
Table 2: Symbols and Acronyms DescriptionCategory	Symbol	DescriptionTEE	-sessssnn- KSGX SigSGX Kclient SigvIient PRM EPC	TEE,s session key for learning task SGX signature signing key client,s encryption key clients public key Processor Reserved Memory Enclave Page CacheNeural Network	RMM- FV DNN	Randomized Matrix Multiplication Full Verification (No RMM) Deep Neural NetworkGeneral	-W ds v_num	model parameters training dataset model version numberB Deep Learning TrainingIn the recent decade, Deep Neural Networks (DNN) gained an enormous attraction in solving prob-lems related to computer vision and natural language processing Krizhevsky et al. (2012); Simonyan& Zisserman (2014); He et al. (2016); Szegedy et al. (2015; 2017). In practice, these networks arestacks of layers that each perform a transformation FW(∙) ∀l ∈ |L| where Xl+1 = FW(Xl) and|L| is the number of layers. The training task is to learn the correct parameters (point-estimates) W *that optimizes (commonly minimizes) a task-specific (e.g. classification) loss function L.
Table 3: TEE Architectures UsedArch	FC1	FC2	FC3VGG11	(128,10)	(128,64,10)	(256,128,10)VGG13	(128,10)	(128,64,10)	(256,128,10)VGG16	(128,10)	(128,64,10)	(256,128,10)~^Proof. Proof of theorem 2P (X ≥ 1) ≥ pi1 - P (X = 0) ≥ pi1-pi	≥	dB	×0	pve(pc(1	- α))0((1 - pc)	+	pcα)dB×pve1 - pi ≥ ((1 - pc) + pcα)dB×pvelog(1 - pi)	≥	dB × pve	log((1 -pc)	+ pcα)八	>	B-1(	log(1 - Pi)	_ 1)V	log((1 + (α - 1)Pc)(3)□E	Verification Probability Growth with Respect to DetectionProbab ilityFig. 5 shows how verification probability changes with respect to the probability that a batch step ismaliciously manipulated by the attacker. First row shows the verification probability for a datasetwith 60K samples. Second row depicts the required for much bigger dataset (1M samples) over
Table 4: Matrix Multiplication OperationsLayer Type	Pass	Computation	Verification	(Sub)Batched/ Precomp.
