Table 1: Impact of each CL augmentation on OG classification. Bold are improved results withrespect to no augmentation, i.e. base models.
Table 2: Comparative evaluation of OG classification methodsMethod	Precision	Recall	AUPR	F1	F0.5Naive Bayes	0.240	0.974	0.727	0.385	0.283SVM	0.997	0.337	0.748	0.504	0.716Decision Tree	0.693	0.642	0.637	0.667	0.682Random Forest	0.987	0.400	0.718	0.569	0.763Liu et al. (2017)	0.919	0.735	0.885	0.817	0.875BERT	0.837	0.711	0.815	0.711	0.808Base model #1	-^0867^^	0.794	0.867	0.829	0.851Base model #1 + L1 Regularisation	0.880	0.759	0.857	0.815	0.853Base model #1 + L2 Regularisation	0.896	0.783	0.890	0.835	0.871Base model #2	-^0.900^^	0.871	0.940	0.886	0.894Base model #2 + L1 Regularisation	0.885	0.881	0.940	0.883	0.883Base model #2 + L2 Regularisation	0.913	0.865	0.941	0.888	0.903Augmented model #1	-^0.930^^	0.777	0.924	0.847	0.895Augmented model #2	0.953	0.853	0.948	0.900	0.931will explore their combinations. Improvements are more consistent for AUPR and precision (andconsequently F0.5), thanks to fewer false positives. This reduction in false positives may be due to aneasier distinction ofOG conversations from neutral but sexually-oriented ones.
