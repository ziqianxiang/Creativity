Table 1: The evaluation results of 5-way-K-shot learning for methods with different training regimeson the MiniImageNet and TieredImageNet datasets.
Table 2: The evaluation results of 5-way-K-shot learning for the standard MAML and RandomDecision Planes (RDP) with different backbones.
Table 3: The evaluation results of 5-way-K-shot learning for the Meta Contrastive Learning (MCL)and other baselines with different backbones.
Table 4: The evaluation results of 5-way-K-shot learning on the MiniImageNet dataset.
Table 5: The evaluation results of 5-way-K-shot learning on the TieredImageNet dataset.
Table 6: The evaluation results of 5-way-K-shot learning on the CIFAR-FS dataset.
Table 7: The evaluation results of 5-way-K-shot learning on the FC100 dataset.
Table 8: The computation time of different methods.(tasks/sec)Method	Conv4	ResNet12MAML (Finn et al. (2017))	10.60	2.24Random Decision Planes (RDP)	31.24	6.88Almost No Inner Loop (ANIL)	30.98	6.86Body Inner, Head Outer (BOHI)	31.12	6.88Meta Contrastive Learning (MCL)	63.76	30.96training of models is run on two NVIDIA 1080Ti GPU. Notice that our MCL can run much fasterthan BOHI and ANIL while achieves better evaluation results. The training speedups also illustratethe significant computational benefit of MCL and prove its effectiveness.
Table 9: The evaluation results about the quality of features extracted by the network body andprojection layer. (5-way-5-shot on MiniImageNet, ResNet12)Hidden size of gφ	Network Body fθ	Projection Layer gφ64	77.69 ± 0.33	61.83 ± 0.37256	77.98 ± 0.34	63.46 ± 0.38512	78.34 ± 0.33	66.27 ± 0.40C.4 About the projection layer of MCLWe have found that with a deeper backbone, the features learning can be facilitated a lot by theprojection layer. We further evaluate the quality of features extracted by the network body and theprojection layer. The evaluation results are given in Table 9. Even if the contrastive loss is appliedto the projection layer, the network body learns better and general representations. We conjecturethat during the meta-training, the projection layer may absorb more task-specific information whilethe backbone tends to learn task-independent representations.
