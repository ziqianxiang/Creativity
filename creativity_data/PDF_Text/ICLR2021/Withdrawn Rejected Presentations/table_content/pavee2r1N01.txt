Table 1: Results for 7 training schemes: plain, at (adversarial training), KW, MMR and MMR+AT,GR, GR+AT, and 5 evaluation schemes for ReLU networks: clean test error (TE), lower (LB) andupper (UB) bounds on the robust test error via Wong & Kolter (2018), and average radius of robustnessas estimated by Wong & Kolter (2018) (KW). The robustness radii are computed on the first 1000points of the respective test sets. Models evaluated according to the available code.
Table 2: Comparisons to state-of-the-art first and second-order robust regularizers. TRADES (Zhanget al., 2019), Locally Linear Regularization (LLR) (Qin et al., 2019), TULIP (Gradient Regularization)(Finlay & Oberman, 2019), and Curvature Regularization (CURE) (Moosavi-Dezfooli et al., 2019).
Table 3: Architectures for main experiments for number of classes nc.
Table 4: Ablation experiments. We evaluate networks trained using both ACR and LDR terms, ACRonly, and LDR only on 'âˆž perturbations. We see that the best performance is achieved when bothterms are used.
