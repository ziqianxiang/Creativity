Table 1: Hyper-parameters in CommonParameter	ValueDDPG	optimizer	Adam (Kingma & Ba, 2014)number of hidden layers (all networks)	3number of hidden units per layer	256nonlinearity	ReLUpolyak for target network (τ)	0.995target update interval	10ratio between env vs optimization steps	2Random action probability	0.2Initial random trajs per worker	100Hindsight relabelling ratio	0.85Latent Landmarks & Auto-encoder	number of hidden layers	2number of hidden units per layer	128nonlinearity	ReLUembedding size	16λ for reachability constraint loss	1.0learning rate	3e-4
Table 2: Hyper-parameters for Each Environment	Point-Maze	Ant-Maze	Fetch tasks	 DDPG			Learning rate	2e-4	2e-4	1e-3Number of workers	1	3	12Batch size	512	1024	1024Action L2	0.5	0.05	0.01Gamma	0.98	0.98	0.99Action noise	0.2	0.2	0.1Hindsight relabelling range	80	100	50Latent Landmarks & Auto-encoder			Number of latent landmarks	50	50	80Number of warm-up trajectories	500	500	6000Batch size	256	256	150Graph Search			d_max (clipping threshold for distances)	20.0	20.0	15.0Random landmarks added during train	150	150	2014Under review as a conference paper at ICLR 2021•	We find that having a centralized replay for all parallel workers is significantly more sample
