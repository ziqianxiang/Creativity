Table 1: Developer adjustments and types of adjustments in the benchmarks.
Table 2: Average speedup across benchmarks for different #evaluations for the old and new HPO. Forthe GP based (left) and TPE based (right) evaluation.
Table 3: Benchmarks overviewBenchmark	#Hyperparameters Old	#Hyperparameters New	#Tasks	MetricFCN-A	6	5	4	MSEFCN-B	6	8	4	MSENAS-A	6	6	3	AccuracyNAS-B	3	6	3	AccuracyXGB-A	5	9	10	AUCXGB-B	6	6	10	AUCSVM-A	2	2	10	AUCSVM-B	2	2	10	AUCA.2 FCN-A & FCN-BBase benchmark We use code and data from (Klein & Hutter, 2019). We use the tasks HPO-Bench-Protein, HPO-Bench-Slice, HPO-Bench-Naval, and HPO-Bench-Parkinson.
Table 4: Values for integer coded hyperparameters in FCN benchmarksHyperparameter	Values# Units Layer {1, 2}	(16, 32, 64, 128, 256, 512)Dropout Layer {1, 2}	(0.0, 0.3, 0.6)Initial Learning Rate	(0.0005, 0.001, 0.005, 0.01, 0.05, 0.1)Batch Size	(8, 16, 32, 64)Table 5: Search spaces in FCN-A. Numerical hyperparameters are encoded as integers, see Table 4for specific values for these hyperparameters.
Table 5: Search spaces in FCN-A. Numerical hyperparameters are encoded as integers, see Table 4for specific values for these hyperparameters.
Table 6: Search spaces in FCN-B. Numerical hyperparameters are encoded as integers, see Table 4for specific values for these hyperparameters.
Table 7: Search spaces in NAS-A.
Table 8: Search spaces in NAS-B.			Steps	Hyperparameter	Range/Value	Prior1	0→1	{ none, skip-connect, conv1x1, conv3x3 }	Uniform1	0→2	{ none, skip-connect, conv1x1, conv3x3 }	Uniform1	0→3	{ none, skip-connect, conv1x1, conv3x3 }	Uniform1	1→2	{ none, skip-connect, conv1x1, conv3x3 }	Uniform1	1→3	{ none, skip-connect, conv1x1, conv3x3 }	Uniform1	2→3	{ none, skip-connect, conv1x1, conv3x3 }	Uniform2	0→1	{ none, skip-connect, conv1x1, conv3x3, avg-pool3x3 }	Uniform2	0→2	{ none, skip-connect, conv1x1, conv3x3, avg-pool3x3 }	Uniform2	0→3	{ none, skip-connect, conv1x1, conv3x3, avg-pool3x3 }	Uniform2	1→2	{ none, skip-connect, conv1x1, conv3x3, avg-pool3x3 }	Uniform2	1→3	{ none, skip-connect, conv1x1, conv3x3, avg-pool3x3 }	Uniform2	2→3	{ none, skip-connect, conv1x1, conv3x3, avg-pool3x3 }	UniformA.4 SVM-A & SVM-BBase benchmark We use an open source implementation by the HPOlib authors following Perroneet al. (2018). This implementation uses data from Kuhn et al. (2018) and employs a random forest as a14Under review as a conference paper at ICLR 2021surrogate model (Eggensperger et al., 2014). For our benchmarks, we randomly selected the ten tasks
Table 9: Search spaces in SVM-A.
Table 10: Search spaces in SVM-B.
Table 11: Search spaces in XGB-ASteps	Hyperparameter	Range/Value	Prior1	Colsample-by-tree	1	1	Colsample-by-level	1	-1	Minimum child weight	1	-1	Maximum depth	6	1, 2	Booster	Tree	-1, 2	# Rounds	{1, . . . , 5, 000}	Uniform1, 2	Subsample	[0, 1]	Uniform1, 2	Eta	[2-10, 20]	Log-uniform1, 2	Lambda	[2-10, 210]	Log-uniform1, 2	Alpha	[2-10, 210]	Log-uniform2	Colsample-by-tree	01	Uniform2	Colsample-by-level	[0, 1]	Uniform2	Minimum child weight	[20, 27]	Log-uniform2	Maximum depth	{1, ..., 15}	Uniform15Under review as a conference paper at ICLR 2021Table 12: Search spaces in XGB-BSteps	Hyperparameter	Range/Value	Prior
Table 12: Search spaces in XGB-BSteps	Hyperparameter	Range/Value	Prior1	Colsample-by-tree	1	-1	Colsample-by-level	1	1	Minimum child weight	1	-1	Maximum depth	6	-1, 2	Booster	{ Linear, Tree }	-1, 2	# Rounds	{1, . . . , 5, 000}	Uniform1, 2	Subsample	[0, 1]	Uniform1, 2	Eta	[2-10, 20]	Log-uniform1, 2	Lambda	[2-10, 210]	Log-uniform1, 2	Alpha	[2-l0, 210]	Log-uniform2	Colsample-by-tree	1	2	Colsample-by-level	0.5	-2	Minimum child weight	10	-2	Maximum depth	10	16Under review as a conference paper at ICLR 2021B Detailed SpeedupsB.1 GP Based Evaluation
