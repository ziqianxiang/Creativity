Table 1: MNIST superpixel 75 image classification results. Our model and Fey et al. (2017) weretrained for 100 epochs on the MNIST dataset. Knyazev et al. (2019) was trained for 30 epochsand Gray et al. (2020) for 400 epochs, keeping to their implementations. To avoid biasing to thetest set, we selected the models by best training accuracy for a given set of hyperparameters —with the exception of Fey et al. (2017) for which we chose the overall best for each particular run.
Table 2: (a) CIFAR100 superpixel image classification test accuracy (%). We show the averageand maximum test accuracies for the best training epoch over 32 runs. (b) FAUST node correspon-dence results. All results (except ours) as reported by authors. We did not perform an extensivehyperparameter search and our results are mostly to show that the method is generally applicable.
Table 3: MNIST image classification error rates. Models were trained for 100 epochs and resultsfor test error are shown for both raw and Delaunay triangulated MNIST superpixel 75. To avoidbiasing to the test set, we selected our model’s test values by best training accuracy for a given set ofhyperparameters. Our model training also included edge dropout on input with 0.05-0.1 for prunedand an optimized dropout rate for raw (higher depth networks needed more to avoid overfitting).
Table 4: CIFAR10 image classification results. We were unable to replicate the reported results ofKnyazev et al. (2019) using the code provided (they reported 69-73% accuracies depending on thevariant). We believe that because we only applied these models naively without special tuning ormodifications, they are reasonable results and are included for comparison sake. Also, given thefact that all the models are performing at roughly the same level, it is possible that our recreation ofthe superpixel dataset suffers from some unknown flaw. The fact that the hierarchical variant showsimproved performance for our model (in contrast to other results — section 4), suggests that thereis something odd with either the raw or the hierarchical datasets.
Table 5: ModelNet10 shape classification results.
