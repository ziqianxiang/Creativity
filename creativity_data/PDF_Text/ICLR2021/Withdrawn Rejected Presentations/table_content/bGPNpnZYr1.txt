Table 1: Experimental settings for comparing the performance on various datasets are summarized.
Table 2: Settings for TrainingDataset	Model	Optimizer	Learning Rate	Learning Rate Schedule ×decay [epoch schedule]	Batch SizeMNIST	S-CNN	Adam	0.001	-	32CIFAR10	K-CNN	Adam	0.0001	-	64SVHN	K-CNN	Adam	0.0001	-	64EMNIST	K-CNN	Adam	0.0001	-	64CIFAR100	K-CNN	Adam	0.0001	-	64CIFAR100	WRN-16-8	Nesterov	0.05	×0.2 [60, 80]	128Tiny ImageNet	WRN-16-8	Nesterov	0.1	×0.2 [60, 120, 160]	128Food101	WRN-16-8	Nesterov	0.1	×0.2 [60, 120, 160]	128HAM10000	WRN-16-8	Nesterov	0.05	×0.2 [60, 80]	64C Rank Correlation between LPDR and Variation RatioFigure 8 shows an example of negative Spearman’s rank correlation between LPDR and the variationratio for each experimental setting. Samples with increasing LPDR or variation ratio are ranked fromhigh to low. The σ is selected to satisfy Pn = ρ* = q/m at initial step.
Table 3: The mean (± standard deviation) of performance gap from the best competitor for allsteps of each algorithm on each dataset. LPDR significantly outperforms the other algorithms on alldatasets.
