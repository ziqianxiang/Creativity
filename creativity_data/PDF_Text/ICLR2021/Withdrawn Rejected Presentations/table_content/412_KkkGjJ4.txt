Table 1: Results of Weakly Supervised Scene Graph Grounding Methods with VG and VRD: Ourproposed model surpass all baseline models by noticeable margins.
Table 2: Ablation Study on Our Grounding Model: The results show that our model benefits fromthe matching process and the relational metric	Node TyPe		Node Numbers	Acc w/o rel-metric	Acc with rel-metricAmbi-Nodes with relations	106k	28.3	333Ambi-Nodes without relations	91k	26.0	26.9Unique Nodes	155k		772			77.3	Table 3: Detailed Ablation Study on Our Grounding Model on VG dataset: The results show thatour model benefits from the matching process and the relational metricrithm is much better than greedy methods. It is also shown that our model is able to learn feasibleinformation from data, compared with the model without relational metrics.
Table 3: Detailed Ablation Study on Our Grounding Model on VG dataset: The results show thatour model benefits from the matching process and the relational metricrithm is much better than greedy methods. It is also shown that our model is able to learn feasibleinformation from data, compared with the model without relational metrics.
Table 4: Results of Scene Graph Classification and Predicate Classification on VG: Our groundingresults can act as a reinforcement to other scene graph parsing models and further improve theirperformancesMethods		SGGen			ReCall@50	ReCall@100-MLP-MIL-	1.9	22GNN-MIL	1.5	1.8VSPNetWS	4.7	5.4MLP (Ours)=	2.4	3.0 äºŒGNN (Ours)	2.4	3.0VSPNet (OUrS)	5,1	5,8Table 5: Results of Scene Graph Generation on VG: Our grounding results can bring boosts to otherscene graph parsing models in the scenario without ground-truth bounding boxesEvaluation Metrics: Following (Herzig et al., 2018) and (Zareian et al., 2020a), we evaluate themodels above with three setups: scene graph generation (SGGen), scene graph classification (SG-Cls) and predicate classification (PredCls). SGGen requires a model to generate triplets from aninput image without ground truth bounding box. A generated triplet is considered as correct if (1)for both subject and object, the detected bounding boxes have an IoU of at least 0.5 with groundtruth and (2) the categories of subject, object and relation are all correctly predicted. SGCls requiresa model to predict object categories along with their mutual relations given ground truth bound-
Table 5: Results of Scene Graph Generation on VG: Our grounding results can bring boosts to otherscene graph parsing models in the scenario without ground-truth bounding boxesEvaluation Metrics: Following (Herzig et al., 2018) and (Zareian et al., 2020a), we evaluate themodels above with three setups: scene graph generation (SGGen), scene graph classification (SG-Cls) and predicate classification (PredCls). SGGen requires a model to generate triplets from aninput image without ground truth bounding box. A generated triplet is considered as correct if (1)for both subject and object, the detected bounding boxes have an IoU of at least 0.5 with groundtruth and (2) the categories of subject, object and relation are all correctly predicted. SGCls requiresa model to predict object categories along with their mutual relations given ground truth bound-ing boxes. And PredCls asks for predicting relations for all visual object pairs given ground truthbounding boxes. We report Recall@K score, the ratio of ground truth triplets correctly detectedby the model when top K triplet predictions are taken into account, with K=50, 100. For the fullysupervised models, we only report their performance of SGCls and PredCls because they requiredenser proposals (300) in SGGen setup compared to the weakly supervised models (20 proposalsrequired), which is unfair for the comparison.
