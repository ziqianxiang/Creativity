Table 1: Performance of NN mo dels compressed by 3 techniques of layer decompositioninto sparse matrix products. “PSM” refers to the proposed procedure using Palm4MSA onthe pre-trained layers; “PSM re-init” uses Palm4MSA to define the sparsity support but theweights are re-initialized; “PSM random” randomly initializes weights and sparsity support.
Table 2: Datasets: attributes and investigated NN models.
Table 3: Magnification of a sample’s representation induced by the Tensortrain layers.
Table 4: Performance of neural network models compressed by 3 techniques of layer de-composition into sparse matrix products. «PSM» refers to the proposed procedure usingPalm4MSA on the pre-trained layers; «PSM re-init» uses Palm4MSA to define the sparsitysupport but the weights are re-initialized; «PSM random» randomly initializes weights andsparsity support.
