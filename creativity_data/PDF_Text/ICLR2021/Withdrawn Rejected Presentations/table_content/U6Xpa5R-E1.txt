Table 1: Comparison between (A) “standard” amortized optimization, (B) Neural Potts Model,and (C) Multi-task learning. From row (A) amortized optimization to (B) Neural Potts Model, afinite-sample training loss is introduced which comes with considerations of generalization andregularization. This is related to multi-task learning, but with a major difference that (B) the solooptimization is over a single tensor W in the Potts model, but (C) a function fθ in a learning problem.
Table 2: HyperparametersPrecision-Recall Curve (AUC) is computed, summing over thresholds stepwise per L/10 incrementup to L. Precision and AUC metrics are computed at sequence separations s of short (6 ≤ s < 12),medium (12 ≤ s < 24), and long (24 ≤ s) ranges.
