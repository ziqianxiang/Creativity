Table 1: Baseline comparisons: Structural Hamming Distance (SHD) (lower is better) for learned and ground-truth edges on various graphsfrom both synthetic and real datasets, compared to (Peters et al., 2016), (Heinze-Deml et al., 2018b), (Eaton & Murphy, 2007b), (Yu et al.,2019) and (Zheng et al., 2018). The proposed method (Structural Discovery from Interventions (SDI)) is run on random seeds 1 - 5 and wepick the worst performing model out of the random seeds in the table. OOM: out of memory. Our proposed method correctly recovers the truecausal graph, with the exception of Sachs and full13, and it significantly outperforms all other baseline methods. Proposed method as well asall the baselines uses similar amount of data.
Table 3: Intervention Prediction Accuracy: (identify on which variable theintervention took place)3 variables	4 variables	5 variables	8 variables95 %	93 %	85%	71 %randomly, or not guessing it at all, leads to a significant drop in the model performance, even for3-variable graphs (Fig. 11 Left). Training sdi with intervention prediction closely tracks trainingwith leaked knowledge of the ground-truth intervention on larger, 7-variable graphs (Fig. 11 Right).
Table 4: Partial Graph Recovery on Alarm (Bein-lich et al., 1989) and Barley (Kristensen & Rasmussen,2002). The model is asked to predict 50 edges in Bar-ley and 40 edges in Alarm. The accuracy is measured inStructural Hamming Distance (SHD). sdi achieved over90% accuracy on both graphs.
Table 5: Baseline comparisons: Hamming distance (lower is better) for learned and ground-truth edges on various graphs from both syntheticand real datasets, compared to (Peters et al., 2016), (Heinze-Deml et al., 2018b), (Eaton & Murphy, 2007b), (Yu et al., 2019) and (Zheng et al.,2018). The proposed SDI is run on random seeds 1 - 5 and we pick the worst performing model out of the random seeds in the table.
Table 6: Baseline comparisons: Hamming distance (lower is better) for learned and ground-truth edges on Asia and various synthetic graphs.
Table 7: Regularizer: SDI performance measured by Hamming distance to the ground-truth graph. Comparisons are between SDIs withdifferent regularizer settings for different graphs. Our default setting is ldag = 0.5, lsparse = 0.1, with ldag the DAG regularizationstrength and lsparse the sparsity regularization strength. As shown in the table, SDIs is not very sensitive to different regularizer settings.
Table 8: Comparisons: Structured hamming distance (SHD) on learned and ground-truth edges on asia and various synthetic graphs. Eaton& Murphy (2007b) can not scale to larger variables graphs as shown in Table 1, hence, we compare to the largest graph that (Eaton & Murphy,2007b) can scale up to. sdi is compared to (Eaton & Murphy, 2007b) for collider7, collider8 and full8, (Eaton & Murphy, 2007a)asserts with 100% confidence a no-edge where there is one (false negative). For comparisons with all other methods 1.
