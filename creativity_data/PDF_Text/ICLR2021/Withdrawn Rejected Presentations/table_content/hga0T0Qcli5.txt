Table 1: Experimental results on the WN18RR and FB15k-237 test sets. Hits@k (H@k) is reportedin %. The best scores are in bold, while the second best scores are in underline. The results of TransEare taken from [17]. The results of DistMult and ComplEx are taken from [4]. The results of ConvKBare taken using the Pytorch implementation released by [17]. We note that GC-OTE and RotatEAdvapply a self-adversarial negative sampling, which is different from the common sampling strategyused in the previous baselines, QuatE and our QuatRE. QuatEN3Rec uses the N3 regularization andreciprocal learning [12], which requires a large embedding dimension. GC-OTE, ReInceptionE, andR-GCN+ integrate information about relation paths. Thus, for a fair comparison, we do not compareour QuatRE with these models.
Table 2: MRR score on the WN18RR testset with respect to each relation.
Table 3: The score functions in previous models. The table is adapted from [20].
Table 4:	Statistics of the experimental datasets.
Table 5:	The optimal hyper-parameters on the validation sets.
Table 6: Experimental results on the WN18 and FB15k test sets. Hits@k (H@k) is reported in%. The best scores are in bold, while the second best scores are in underline. RotatEAdv uses aself-adversarial negative sampling. QuatEN3Rec applies N3 regularization and reciprocal learning.
