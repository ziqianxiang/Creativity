Table 1: IMAGENET results, comparing performance of different module sequences. We use 8 and 16-layerisometric models from Sandler et al. (2019). For our method we use the same models, but the modules arearranged into 32 and 48 layers as described in Section 4.2. The models are of the same size as baseline.
Table 2: Transfer learning results from model trained on multiple initial datasets (ImageNet,CIFAR- 1 00, Places365, Sun397 and Food101) onto new datasets. For baseline column wetrain multi-task model following Mudrakarta et al. (2019), with shared backbone and per-task logitsand batch normalization parameters. We then transfer to the target datasets by fine-tuning logits andbatch normalization parameters. Other columns show results obtained by our method, where we useequivalent architecture, but with mixture weights both for initial model and each transfer task. Eachcolumn shows results with mixture coefficients initialized from the corresponding training task. Ourmethod adds less than 500 additional parameters for each transfer task.
Table 3: Multi-source domain adaptation target test accuracy results with compositional models onDigits domains (MNIST, corrupted MNIST (shear), corrupted MNIST (scale), corrupted MNIST(shot noise), SVHN → USPS) and DomainNet domains (clipart, infograph, quickdraw, painting,real → sketch). Baseline methods: Adversarial Discriminative method and Multi-Source MomentMatching method. We pretrained the baseline models on source domains and fine-tuned only theinput adapter (IA) containing ≈ 1000 parameters. We applied the same domain adaptation tech-niques for our conversational model and fine-tuned only mixture weights (MW) consisting of 64parameters.
