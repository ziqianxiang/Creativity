Table 1: Averaged F1 scores for NER and labeled attachment scores (LAS) for dependency pars-ing. CoN. and Wiki. represents CoNLL and WikiAnn respectively. +U denotes experiments withunlabeled data.
Table 2: Comparison of the global and local temperatureapplication approaches on the CoNLL NER datasets.
Table 3: Running speed and model sizes of the teacher andstudent models in Case 2a.
Table 4: Averaged F1 score of teach-ers and it’s marginal distributions.
Table 5: Results of F1 scores for NER task on labeled datasetsDataSet			CoNLL		WikiAnnScenario		de	en	es	nl Avg.	de	en	es	nl Avg.
Table 6: Results of F1 scores for NER task on unlabeled datasetsDataset			WikiAnn with unlabeled sentencesScenario		# Unlabeled sent.	de	en	es	nl	avgCase 1a	Teacher		-86.98^^83.80^^9185^^91.46^^88.52	Baseline	3K	-80.66^^79.85^^8779^^88.44^^84.19 81.56 81.40 88.10 88.55 84.91 81.88* 81.23* 88.66* 89.20甘 85.24	Base. KD -			Stuctural KD			Baseline	10k	-82.27^^80.32^^88.78^^88.23^^84.90 82.01	81.53 89.28 88.99 85.45 82.34 81.27* 89.85衰 89.19* 85.66	Base. KD			Stuctural KD			Baseline	30k	84.20^^81.19^^902^^89.36^^86.24 84.12 82.56 89.82 89.53 86.51 84.17 82.14* 90.4# 89.84* 86.64	Base. KD -			Stuctural KD		Case 2a	Teacher		-86.98^^83.80^^9185^^91.46^^88.52	Baseline	3K	78.82 78.48^^85.54^^86.77^^82.40 79.84 79.18 85.89 87.36 83.07 79.82* 79.41* 86.36* 87.75* 83.34	Base. KD -			Stuctural KD			Baseline	10k	-80.75^^78.53^^86.93^^87.30^^83.38 80.71	79.23 87.82 87.80 83.89 81.07 79.41* 87.77* 87.99* 84.06	Base. KD 一			Stuctural KD		
Table 7: Result of F1 scores of zero shot transfer experiment on NER task		WikiAnnCase 3	# Unlabeled sent.	eu	fa	he	ta Avg.
Table 8: Result of F1 scores of Parsing task with labeled dataset. Note that all our approaches aresignificantly stronger than the baseline.
Table 9: The accuracy of Parsing task with unlabeled dataset (in thousand). Note that all our ap-proaches are significantly stronger than the baseline.
