Table 1: Number of communication rounds required to reach ∣∣Vf (x)k2 ≤ e for L-smooth functions(log factors are ignored) with S clients sampled each round. G2 bounds the gradient dissimilarity(A1), and δ bounds the Hessian dissimilarity (A2). FEDAVG is slower than the server-only methodsdue to additional ∣drift terms. Convergence of SCAFFOLD depends on the total number of clientsN which is potentially infinite. MIME matches the optimal statistical rates (first term in the rates)of the server-only methods while improving the optimization (second) term (typically δ《L).
Table 2: Details about the datasets used and experiment setting.
Table 3: High tuning setting: final test accuracy (larger is better) with fully tuned hyper-parameters.
Table 4: Additional algorithmic details: Decomposing base algorithms into a parameter update (U)and statistics tracking (V).
