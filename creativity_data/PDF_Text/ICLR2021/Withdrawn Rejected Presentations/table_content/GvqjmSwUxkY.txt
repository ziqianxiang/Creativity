Table 1: Main results. mFID, Density / Coverage (D & C), and classification accuracy (Acc) of eachtraining configuration. Note that the configurations (a) - (b) use ground-truth class labels, while (c)- (G) use pseudo-labels. We bold the best results separately for supervised and unsupervised settings.
Table 2: t-SNE visualization of the model with (a) K=10 and (b) K=20 trained on AnimalFaces-10and quantitative evaluation of our method by varying the number of pseudo domains KK. Each pointis colored with the ground-truth labels. As shown in t-SNE visualizations, even if KK is set to overlylarger than the actual number of domains, the guiding network clusters the domains reasonably well.
Table 3: Quantitative evaluation (mFID) when few labels are available during training.
Table 4: Quantitative evaluation (mFID) when few labels are available during training. Here, anauxliary classifier is adopted to improve the FUNIT baseline by giving pseudo-labels to Dun .
Table 5: Generator architecture. “ch” represents the channel multiplier that is set to 64. IN and AdaINindicate instance normalization and adaptive instance normalization, respectively.
Table 6: Guiding network architecture. “ch” represents the channel multiplier that is set to 64. Thearchitecture is based on VGG11-BN. GAP and FC denote global average polling (Lin et al., 2013)and fully connected layer, respectively.
Table 7: Discriminator architecture. “ch” and KK represent the channel multiplier that is set to 64 andthe number of clusters, respectively. FRN indicates filter response normalization (Singh & Krishnan,2020).
