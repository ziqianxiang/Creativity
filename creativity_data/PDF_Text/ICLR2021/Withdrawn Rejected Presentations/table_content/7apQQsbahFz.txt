Table 1: Tasks. We evaluate MARL algorithms on more than 10 different tasks from three different environ-ments.
Table 2: HyperparametersParameter	Valueoptimizer	Adamlearning rate of all networks	0.01discount of reward	0.95replay buffer size	106max episode length in MAgent	25max episode length in MPE, CityFlow	100number of hidden units per layer	128number of samples per minibatch	1024nonlinearity	ReLUtarget smoothing coefficient (T)	0.01target update interval	1gradient steps	8regularizer factor(Î±)	0.2I DerivationI.1 Proof of proposition 1We prove the result by induction using the backward view.
