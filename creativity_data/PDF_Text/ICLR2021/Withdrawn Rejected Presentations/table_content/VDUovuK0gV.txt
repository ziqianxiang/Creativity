Table 1: Results for Pixel MNIST, Permuted MNIST, Noise Padded CIFAR-10 and MNIST datasets. SinceTARNN effectively focuses on informative segments, it achieves better performance with faster convergence.
Table 2: PTB Language Modeling: 1 Layer (standard smallconfig except the sequence length is 300 as per (Kusupati et al.,2018) as opposed to 30 in the conventional PTB).
Table 3: Dataset StatisticsDataset	Avg. Activity Time	Input Time	Sequence Ratio	#Train	#Fts	#Steps	#TestNOiSy-MNIST	28	1000	7/250	60,000	28	1000	10,000NOiSy-CIFAR	32	1000	4/125	60,000	96	1000	10,000Pixel-MNIST				60,000	1	784	10,000Permuted-MNIST				60,000	1	784	10,000PTB				929,589	300	300	82,430Proof of Theorem 1Note that, when βi = 0, sm(i) = sm-1 (i). On the other hand when βi > 0, the system is inequilibrium, and for those components, j , we have(Z(t))j = (F(z(t), Um))j =0, where F(z(t), Um) = β(Um"(Az(t)+BUm + φ(Uz(t)+Wum))Now (F(sm, um))k = 0 regardless of βk. This is because if βk(um) > 0 we reach equilibrium, andZ(t) = 0, and on the other have if βk = 0 then (F(sm/, um,))k = 0 in any case. With this in mind,define D = diag[1βj(um)>0]. We then write the vector sm = Dsm + (I - D)sm-1. Let Jm,m-1denote the Jacobian of sm with respect to sm-1. Taking derivatives we get,0 = VF (sm, Um)=e(Um) ◦ (A(DJm,m-1 + (I - D)) + B2 )+	β(Um) ◦ (Vφ(U(DJm,m7 + (I - D)) + W2))+	DVσ(Ussm-1 + Wxxm)(Asm + BUm + φ(Usm + WUm))First, note that the third term is always zero, due to the fact we noted earlier, namely, if a componentis active, then the corresponding state reaches equilibrium, and there is nothing to do if the component
Table 4: Various hyper-parameters to reproduce results八——，	Hidden Learning	L2	「一「 DataSet	DimenSion (hr) Rate (hr) regularization Imt η EPOchS T							Batch SizePixeI-MNIST	128	-^1e-2^^	4.5e-6	0.08	30	5	128^^Permuted-MNIST	128	1e-2	4.5e-6	0.0008	30	5	128Noisy-MNIST	128	1e-2	4.5e-5	0.0008	30	5	512Noisy-CIFAR	128	1e-2	4.5e-5	0.001	30	5	256Addition Task	128	1e-2	1.0e-5	0.001	2	-	128Copying Task	128	1e-2	1.0e-6	0.45	-	-	128PTB	256	-	-	0.001	100	-	Our experiments use hidden size as suggested by (Kusupati et al., 2018; Chang et al., 2019) i.e. 128.
Table 5: Results for Activity Recoginition (IoT) Datasets.
