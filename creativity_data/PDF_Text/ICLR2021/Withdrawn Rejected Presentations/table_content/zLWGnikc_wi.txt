Table 1: Comparison between Feature Scattering (the current state-of-the-art defense) and the twoproposed 夕DNNs with a simple adversarial training (NSRadv and FIRadv) on CIFAR10, SVHN andImagenette. Other state-of-the-art defenses such as LLR and TRADES are also included. Resultsshow the accuracy of defenses under attack. For reference, We include the 夕DNNs without adversar-ial training (NSR and FIR), only ResNet with the same simple adversarial training used on NSRadvand FIRadv (ResNetadv); as well as vanilla ResNet. ResNetpruned means the trained ResNet ispruned 50%, retrained and then ultimately pruned to 80%.
Table 2: Comparison of proposed methods with other pre-prossessing based defenses. NSR andFIR models use the best setting from Tables 3 and 4 while the other ones use AllConv and the bestsettings out of a couple of experiments.
Table 3: Attack accuracy for both NSR and SR (NSR without the added noise δr()) trained withdifferent types of noise and connected to ResNet. We tested Gaussian noise with 0 mean (μ), andvariances (σ2) of 0.01. For Panda noise, the scalar number (0.01) represents the probability (α andβ) of white and black pixels present in the image. A + B represents that two types of noises A andB are summed together. The subscript T means that the classifier was retrained with a data set madeof recreated images (i.e., images from 夕r (x)).
Table 4: Comparing the difference of grid size on FIR’s accuracy and robustness. ResNet is thevanilla classifier while FIR1+, FIR4+ and FIR8+ means using ResNet in the FIR’s architecture withgrid size of respectively 1, 4 and 8. Each inpainting model is trained with the corresponding gridsize only, and the classifier model is trained with corresponding inpainting image from 夕i(x).
