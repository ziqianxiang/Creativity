Table 1: Error rates (%) for CIFAR-10 and CIFAR-100 on five different folds. All methods areimplemented using the same codebase.
Table 2: Comparison with state-of-the-art methods in error rate (%) on CIFAR-10 and CIFAR-100.
Table 3: Comparison with state-of-the-art methods in errorrate (%) on SVHN. * denotes the results cited from respec-tive papers. Our results are reported on five different folds.
Table 4: Error rates (%) for STL-10on 1000-label splits. * denotes theresults cited from respective papers.
Table 5: Ablation study. All results are error rates (%). Results of the same label split (same column)are reported using the same seed. In the second row, NaN-70 means the loss becomes NaN after 70training steps, and similarly for other cases. * means the methods without L2-normalization.
Table 6: Comparison of methods.
Table 7: Hyperparameter definition.
Table 8: Details of hyperparameters. As presented in Section 4.1, FixMatchRA refers to FixMatchwith using RandAugment; RankingMatchBM and RankingMatchCT refer to RankingMatch with us-ing BatchMean Triplet loss and Contrastive loss respectively.
Table 9: Training time per epoch (seconds) and GPU memory usage (MB) for 128 epochs on CIFAR-10, SVHN, and CIFAR-100.
Table 10: Training time per batch (milliseconds) and GPU memory usage (MB) for the first 5100training steps on CIFAR-10 and SVHN.
Table 11: Training time per batch (milliseconds) and GPU memory usage (MB) for the first 31620training steps on CIFAR-100.
