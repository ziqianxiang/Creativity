Table 1: Supervised prediction results: comparing an optimized baseline (OB) with contrastivemethods (CM: 4-12). CMs compare training from scratch vs. pretrainâ†’fine-tune vs. self-supervisedpretraining for few and zero-shot learning. Given the same hyperparameters (*), all CMs reach sim-ilar supervised end-task performance, while self-supervised CMS produce fundamentally differentresults forzero andfew-shot learning - see subsection details.
Table 2: Building an optimised supervised baseline: using test set generalization techniques asproposed by Jiang et al. (2020). %p denotes absolute percent points. Since parameters cannot betuned in isolation, %p only reflects drops by deviating from optimal settings once they are found.
Table 3: Parameters we explored for the optimized baseline. Not all combinations were tried. Wetuned in order: learning rate lr, filter sizes, max-k pooling, tuning embeddings, batch size, classifierdepth and lastly tried another optimizer.
