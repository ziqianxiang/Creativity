Table 1: Test accuracies on Permuted-MNIST and Split CIFAR 10/100. (Mean and std of averageaccuracy over 3 resp. 10 runs for MNIST resp. CIFAR) Each part compares known algorithms tobaselines, explaining algorithms’ performances (1-3), or showing speed-ups at equal performance (4).
Table B.1: Summary of Regularisation Methods and Related Baselines. Details: Algorithms onthe left calculate importance ‘online’ along the parameter trajectory during training. Algorithms onthe right calculate importance at the end of training a task by going through (part of) the training setagain. Thus, the sum is over timesteps t (left) or datapoints X (right). N is the number of imagesover which is summed. All the algorithms on the left rescale their final importances as in equationequation 4 for fair comparison. ∆(t) = θ(t+ 1) - θ(t) refers to the parameter update at time t, whichdepends on both the current task’s loss and the auxiliary regularisation loss. Moreover, (gt + σt)refers to the stochastic gradient estimate of the current task’s loss (where gt is the full gradient and σtthe noise) given to the optimizer to update parameters. In contrast, (gt + σt0) refers to an independentstochastic gradient estimate. For a datapoint X, qX denotes the predicted label distribution andg(X, y) refers to the gradient of the negative log-likelihood of (X, y).
Table C.1: CIFAR 10/100 architecture. Following Zenke et al. (2017) we use the keras defaultarchitecture for CIFAR 10. Below, ‘Filt.’ refers to the number of filters of a convolutional layer, orrespectively the number of neurons in a fully connected layer. ‘Drop.’ refers to the dropout rate.
Table C.2: Hyperparameter values for our experiments. See also maintext.
Table J.1: Correlation between AF and OnAF on CIFAR10 depending on training time. Weshow mean and standard deviation of Pearson correlation over 3 runs. AF is based on 500 samples. Ifthe standard deviation is below 0.005 it is shown as 0.00.
Table J.2: Correlation between AF and OnAF on MNIST depending on training time. We showmean and standard deviation of Pearson correlation over 3 runs. AF is based on 10000 samples.
