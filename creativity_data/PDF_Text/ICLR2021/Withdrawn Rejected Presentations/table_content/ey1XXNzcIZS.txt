Table 1: Routing strategies for Mixture-of-Experts (MoE) models - We compare routing expertsby either tokens, sentence representations, or tasks (using either language pairs or target languages).
