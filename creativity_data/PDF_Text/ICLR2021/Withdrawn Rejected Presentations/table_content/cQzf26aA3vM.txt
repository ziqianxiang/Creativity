Table 1: Overview of the tasks in our benchmark suite. Design-Bench includes a variety of tasksfrom different domains with both discrete and continuous design spaces and 3 high-dimensionaltasks with > 200 design dimensions, making it suitable for benchmarking offline MBO methods.
Table 2: 100th percentile evaluations on the first four tasks in our benchmark. Results are averaged over 16trials, the ± indicates the standard deviation of the reported performance, and the parenthesis at the end of eachcell indicate the 95th confidence interval of the sample mean by fitting a T distribution to the performancesample points, calculated using the T distribution from scipy.stats.. Values are normalized to a zero if thesolution found by optimization performs like the worst sample in the training dataset, and a one if the solutionperforms like the best sample in the training dataset. A value > 1 indicates that a solution better that the bestobserved sample is found. Similarly, a value < 0 indicates that the optimizer has found a solution worse thatthe worst observed sample. Unnormalized results can be found in Table 6 in Appendix DAlgorithm Name	HOPPerController-v0	AntMOrPhology-v0	DKittyMorphology-v0Autofocus	0.326 ± 0.105 (0.058)	2.158 ± 0.044 (0.074)	-1.787 ± 0.233 (0.428)CbAS	0.402 ± 0.311 (0.171)	2.183 ± 0.016 (0.029)	1.752 ± 0.298 (0.547)MINs	0.548 ± 0.468 (0.257)	2.164 ± 0.038 (0.021)	1.672 ± 0.190 (0.104)Gradient Ascent	0.772 ± 0.209 (0.100)	2.212 ± 0.021 (0.040)	1.858 ± 0.242 (0.322)Grad. Min	1.434 ± 0.327 (0.180)	running	runningGrad. Mean	1.379 ± 0.517 (0.285)	running	runningREINFORCE	0.406 ± 0.217 (0.000)	running	runningBO-qEI	0.558 ± 0.105 (0.000)	running	runningCMA-ES		0.497 ± 0.253 (0.000)	running	runningTable 3: 100th percentile evaluations on the final three tasks in our benchmark. Results are averaged over 16trials, and the ± indicates the standard deviation of the reported performance. For a description of the score
Table 3: 100th percentile evaluations on the final three tasks in our benchmark. Results are averaged over 16trials, and the ± indicates the standard deviation of the reported performance. For a description of the scorenormalization methodology, refer to the caption of Table 2. Unnormalized results corresponding to this tablecan be found in Table 7 in Appendix D. “running” indicates that these runs have not yet completedpolicy-gradient estimator. This estimator parameterizes a distribution πθ (x) over the input spaceand then updates the parameters θ of this distribution towards the design that maximizes f (x), usingthe gradient, Ex 〜∏θ(x)Vθ log ∏θ (x) ∙ f (x)]. This method can be regarded as an adaptation of theDynaPPO method from Angermueller et al. (2020) to our setting. Not all our tasks can be formulatedas a sequential decision-making problem, therefore we pose offline MBO as a “one-step” problem.
Table 4: 50th percentile evaluations for baselines on every task. Results are averaged over 16 trials,and the ± indicates the standard deviation of the reported performance. For a description of thescore normalization methodology, refer to the caption of Table 2.
Table 5: 50th percentile evaluations for baselines on every task. Results are averaged over 16 trials,and the ± indicates the standard deviation of the reported performance. For a description of thescore normalization methodology, refer to the caption of Table 2.
Table 6: 100th percentile evaluations for baselines on every task. Results are averaged over 16 trials,and the ± indicates the standard deviation of the reported performance. This table corresponds tothe unnormalized performance originally in Table 2.
Table 7: 100th percentile evaluations for baselines on every task. Results are averaged over 16 trials,and the ± indicates the standard deviation of the reported performance. This table corresponds tothe unnormalized performance originally in Table 3.
Table 8: 50th percentile evaluations for baselines on every task. Results are averaged over 16 trials,and the ± indicates the standard deviation of the reported performance. This table corresponds tothe unnormalized performance originally in Table 4.
Table 9: 50th percentile evaluations for baselines on every task. Results are averaged over 16 trials,and the ± indicates the standard deviation of the reported performance. This table corresponds tothe unnormalized performance originally in Table 5.
Table 10: 100th percentile evaluations for baselines on every task. Results are averaged over 16trials, and the ± indicates the 95th confidence interval of the reported performance.
Table 11: 100th percentile evaluations for baselines on every task. Results are averaged over 16trials, and the ± indicates the 95th confidence interval of the reported performance.
Table 12: 50th percentile evaluations for baselines on every task. Results are averaged over 16trials, and the ± indicates the 95th confidence interval of the reported performance.
Table 13: 50th percentile evaluations for baselines on every task. Results are averaged over 16trials, and the ± indicates the 95th confidence interval of the reported performance.
Table 14: 100th percentile evaluations for baselines on every task. Results are averaged over 16trials, and the ± indicates the 90th confidence interval of the reported performance.
Table 15: 100th percentile evaluations for baselines on every task. Results are averaged over 16trials, and the ± indicates the 90th confidence interval of the reported performance.
Table 16: 50th percentile evaluations for baselines on every task. Results are averaged over 16trials, and the ± indicates the 90th confidence interval of the reported performance.
Table 17: 50th percentile evaluations for baselines on every task. Results are averaged over 16trials, and the ± indicates the 90th confidence interval of the reported performance.
Table 18: 100th percentile evaluations for baselines on every task. Results are averaged over 16trials, and the ± indicates the 99th confidence interval of the reported performance.
Table 19: 100th percentile evaluations for baselines on every task. Results are averaged over 16trials, and the ± indicates the 99th confidence interval of the reported performance.
Table 20: 50th percentile evaluations for baselines on every task. Results are averaged over 16trials, and the ± indicates the 99th confidence interval of the reported performance.
Table 21: 50th percentile evaluations for baselines on every task. Results are averaged over 16trials, and the ± indicates the 99th confidence interval of the reported performance.
