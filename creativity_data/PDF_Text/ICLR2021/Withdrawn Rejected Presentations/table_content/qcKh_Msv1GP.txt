Table 1: Transfer learning performance (ROC-AUC) of MICRO-Graph compared with other self-supervised learning (SSL) baselines on molecule property prediction benchmarks. Pre-train GNNson ogbg-molhiv dataset, fine-tune the pre-trained model on each downstream task for 10 times.
Table 2: Feature extraction performance (ROC-AUC) of MICRO-Graph compared with other self-supervised learning (SSL) baselines on molecule property prediction benchmarks. Use pre-trainedmodels to extract graph representations for each data and train linear classifiers on top. Run eachexperiment 5 times.
Table 3: Ablation study: analyzing the influence of subgraph sampler.
Table 4: Ablation study: analyzing the influence of different motif numbers.
Table 5: Statistics on number of graphs, nodes, edges, and tasks in each OGB molecule dataset.
Table 6: Hyper-parameters of the context prediction pretraining	bace	bbbp	clintox	hiv	sider	tox21	toxcast	Averager1=2,r2=5	73.55 ± 2.5	81.7 ± 2.84	75.82 ± 4.11	73.79 ± 0.9	54.98 ± 1.48	75.6 ± 0.78	63.88 ± 0.76	-71:33-r1=3,r2=4	72.65 ± 2.32-	81.23 ± 1.98-	73.14 ± 6.8 一	73.67 ± 0.99-	53.99 ± 1.38-	75.67 ± 0.65-	63.53 ± 0.79-	70.55Table 7: Additional experiments for ContextPred with different parameters r. Note: results shownin Section 4 are with r1 = 4 and r2 = 7G Motif Cluster Size DistributionIn Figure 7, we show the distribution of cluster sizes of all the learned motifs. Although with theequal-size constraint, the distribution is not completely uniform.
Table 7: Additional experiments for ContextPred with different parameters r. Note: results shownin Section 4 are with r1 = 4 and r2 = 7G Motif Cluster Size DistributionIn Figure 7, we show the distribution of cluster sizes of all the learned motifs. Although with theequal-size constraint, the distribution is not completely uniform.
Table 8: Feature extraction performance (ACC) of MICRO-Graph compared with other self-supervised learning (SSL) baselines on molecule property prediction benchmarks. Use pre-trainedmodels to extract graph representations for each data and train linear classifiers on top. Runeachexperiment 5 timesJ A Synthetic dataset to study motif learningIn addition to studying the pre-training in chemical domain, we also construct a synthetic datasetto that align with our assumptions to verify the effectiveness of the propose method. We assumethere exist K graph motifs, and each whole graph can be representated by certain combinations of19Under review as a conference paper at ICLR 20210.6026graph-subgraphsimilarityFigure 10: Similarity between the whole graph G1 and three subgraphs g1, g2, and g3, zoom in toeach dimension. For each row, x-axis is the dimension slot 1 to 300, and y-axis is the similarityscores between corresponding dimensions of the whole graph representation and each subgraphrepresentation. We indicate the top 20 scores in orange. We can see that these three subgraphs havevery different similarity score distributions, though summing over all 300 dimensions give alike highscores.
