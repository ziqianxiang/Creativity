Table 1: Few-shot detection performance on COCO novel classes. The upper row shows the 1, 2, 3-shotresults, and the lower row shows the 5, 10, 30-shot results. Results in red are the best, and results in blue arethe second best. All approaches are evaluated following the standard procedure in Wang et al. (2020). *Modelre-evaluated using the standard procedure for a fair comparison. ’-' denotes that numbers are not reported inthe corresponding paper. Note that the publicly released models of ONCE and FSOD are based on ResNet-50;we include our CoRPNs based on ResNet-50 as well for a fair comparison. CoRPNs consistently outperformstate of the art in almost all settings, with substantial improvements especially in the very few-shot regime. Ourstrategy is also effective regardless of classifier choice.
Table 2: Few-shot detection performance (AP50) on PASCAL VOC novel classes under three base/novel splits.
Table 3: CoRPNs produce more and better boxes at the fine-tuning stage. This table shows the average numberof foreground boxes TFA and CoRPNs produce for novel classes in the 1-shot experiments. ‘Avg # FG’ is cal-culated from proposals after non-maximum suppression. We exclude the ground truth box, which the classifieralways sees, in calculating ‘Avg # FG’. At each of three IoU thresholds, for two of three splits in PASCALVOC and for COCO, CoRPNs reliably produce more boxes. This table uses the same hyperparameters in Ta-bles 1 and 2. The relative improvement is generally large; we expect small improvements to have large effects,because the classifier must use the very few boxes it receives to build a model of variation in object appearance.
Table 4: Detection performance on COCO base classes after fine-tuning with k-shot novel classes instances.
Table 7: This table S	hows novel class AP50	Method	AP50 Avg#FNa) Avg#FG (↑)TFA (Wang et al., 2020)	28.9	3.1	17.6φ = 0.1	29.5	2.4	21.3φ = 0.3	31.5	3.0	18.5CoRPNs w/ φ = 0.5	32.2	2.5	18.3φ = 0.7	26.8	1.3	20.3φ = 0.9	31.7	0.8	19.0Table 8: Our threshold φ controls the average number of false-negative foreground boxes and the number of foreground sam-ples. 'Avg # FN' is the average number of novel class train-ing foreground boxes misclassified by the RPN classifier (cal-culated before non-maximum suppression). ’Avg # FG' isthe same as 'Avg # FG (0.5)’ in Table 3, which is the aver-age number of foreground boxes after non-maximum suppres-sion. When φ gets larger, all RPN's produce higher scoresfor all foreground boxes, it is more and more unlikely thatCoRPNs get foreground boxes wrong, so 'Avg # FN' de-creases. CoRPNs with all φ values also have larger ‘Avg #FG' compared with TFA. All results are under PASCAL VOC
Table 8: Our threshold φ controls the average number of false-negative foreground boxes and the number of foreground sam-ples. 'Avg # FN' is the average number of novel class train-ing foreground boxes misclassified by the RPN classifier (cal-culated before non-maximum suppression). ’Avg # FG' isthe same as 'Avg # FG (0.5)’ in Table 3, which is the aver-age number of foreground boxes after non-maximum suppres-sion. When φ gets larger, all RPN's produce higher scoresfor all foreground boxes, it is more and more unlikely thatCoRPNs get foreground boxes wrong, so 'Avg # FN' de-creases. CoRPNs with all φ values also have larger ‘Avg #FG' compared with TFA. All results are under PASCAL VOCnovel split 1, shot 1. Different from other experiments, herewe fine-tune with novel classes only (detector is Cn -way).
Table 9: We present COCO 1, 2, 3-shot results under three sets of hyperparameters. All hyperparameters areselected from PASCAL VOC by the selection criteria described in the experiment section. This table alsoshows the standard deviation and 95% confidence intervals across three sets of hyperparameters. All resultsfrom CoRPNs outperform TFA. Results with 95% confidence intervals also show that the improvements aresignificant.
Table 10: Base classes AP50 on PASCAL VOC after phase 1 base class training. The same parameter set- ting applies to both models. Notice that ours is com- parable to the results of TFA.		Table 11: Base classes AP, AP50, and AP75 on COCO after phase 1 base class training. The same parameter setting applies to both models. Ours is comparable to the reported numbers of TFA.	D Baseline: Finetune RPNTable 12 provides results with RPNs fine-tuned in stage 2. In addition to fine-tuning the boundingbox regressor and the classifier, we also fine-tuned the RPN and the ROI feature extractor.
Table 12: This table presents results from the RPN finetuned baseline, under PASCAL VOC three novel splits,all in 1-shot. Finetuning RPN improves the performance in one split but degrades the performance in two othersplits. CoRPNs are the best in all cases.
