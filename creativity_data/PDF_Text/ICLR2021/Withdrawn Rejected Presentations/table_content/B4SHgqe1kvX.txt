Table 1: Accuracy (here we use BLEU4 scores) of the multimodal disambiguation experiments onWAT’19 English to Hindi dataset.
Table 2: Results on GLUE benchmark. mc and pc denote the Matthews correlation and Pearsoncorrelation, respectively. “++/+” indicate that the proposed method was significantly better than thecorresponding baseline at significance level p<0.01/0.05.
Table 3: BLEU scores on MMT and NMT tasks. Trans. is short for the transformer (Vaswani et al.,2017). The MMT and UVR are from Zhang et al. (2020). “++/+” after the BLEU score indicatethat the proposed method was significantly better than the corresponding baseline Transformer atsignificance level p<0.01/0.05.
Table 4: Results on GLUE benchmark. The public results are from GPT (Radford et al., 2018),BERT (Devlin et al., 2019), MT-DNN (Liu et al., 2019). mc and pc denote the Matthews correlationand Pearson correlation, respectively.
