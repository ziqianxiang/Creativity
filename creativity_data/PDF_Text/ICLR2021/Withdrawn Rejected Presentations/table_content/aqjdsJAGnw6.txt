Table 1: Basic block architecture.		Table 2: Backbone network architecture	Layer Type	Parameters	Layer Type	ParametersInput	Cin × H × W	Input	C×H×WConv2D	Cout∕4,3 × 3	Basic Block	15,3×3Conv2D	Cout∕4,3 × 3	Max Pool	2×2Conv2D	Cout∕4,3 × 3	Basic Block	50, 3 × 3Conv2D	Cout, 3 × 3	Max Pool Basic Block Basic Block Max Pool	2×2 200, 3 × 3 400, 3 × 3 2×2The edge network first performs a 3 × 3 convolutional layer activated by a ReLU layer followed bya 3 × 3 max-pooling layer. Then, it performs two linear layers (×400 and ×108) activated by Tanhlayers. We observed the training converges significantly faster when using Tanh activation functionin the linear layers than using other activation functions.
Table 3: Node recognition network architecture.
Table 4: Accuracy in percentage of FCR. The columns are Edge, Sequence, Nodes and Graphaccuracy, respectively.
Table 5: Time cost in milliseconds of FCR . The columns are the time cost of the Backbone, Edge,Node Detection, Node Recognition network and FCR, respectively.
Table 6: Result of real-world program synthesis. The columns are program name, Graph accuracy,Edge accuracy, Nodes accuracy, number of nodes, correctly predicted nodes.
