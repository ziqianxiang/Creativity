Table 1: Comparison with state-of-the-art quantization methods on ImageNet. The “ W/A ”values are the bitwidths of WeightS/activations.
Table 2: Accuracies of different networks us-ing plain WRPN, plain DoReFa and DoReFa +WaveQ on homogeneous weight quantization.
Table 3: Performance of WaveQfor quantizing Transformers.
Table 4: HyPerParameterS settings.
Table 5: Performance of WaveQ on BERT.
Table 6: Validation top-1 accuracy for training from scratch w/ WaveQ Vs w/o WaveQ.
Table 7: Comparison to heuristic-based bitwidth selection method.
