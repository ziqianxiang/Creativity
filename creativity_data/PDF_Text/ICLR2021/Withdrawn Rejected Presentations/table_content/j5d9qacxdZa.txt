Table 1: Evaluation of the ClaSS-IL performance on the Boundary-Aware setting compared to different baselines. The test accuracy onfour datasets are reported. Each experiment is performed 20 timeswith different random seeds, the results are reported as the mean 土SEM over these runs. Note both EBMS and baselines do not use extramemory to store data or models for fair comparison.
Table 2: Different EBM training objec-tives and label conditioning architectures.
Table 3: Results of baselines using ourtraining objective and their original one.
Table 4: Evaluation of the Class-IL performance on theBoundary-Agnostic setting compared to different baselines. Thetest accuracy on four datasets are reported. Each experiment isperformed 5 times with different random seeds, the results are re-ported as the mean ± SEM over these runs. Note both EBMs andbaselines do not use extra memory to store data or models for faircomparison.
Table 5: The model architectures used for the model capacity analysis. h are 512, 1024, and 4096for the small, medium and large network, respectively.
Table 6: Comparison of our EBM with baselines on different variants of the split CIFAR-100 protocol. TheCIFAR-100 dataset is split up into 5 tasks (= 20 classes per task), 10 tasks (= 10 classes per task), 20 tasks (= 5classes per task) or 50 tasks (= 2 classes per task). Shown is the Class-IL performance on the Boundary-Awaresetting after all tasks have been learned. Each experiment is performed 10 times with different random seeds,the results are reported as the mean ± SEM over these runs.
Table 7: The model architectures used on split MNIST. h(a) The architecture of the EBMs.
Table 8: The model architectures used on permuted MNIST. h(a) The architecture of the EBMs.
Table 9: The model architectures used on the CIFAR-10 dataset.
Table 10: The model architectures used on the CIFAR-100 dataset. Following van de Ven et al. (2020), forall models the convolutational layers were pre-trained on CIFAR-10. The ‘BinaryMask’-operation fully gatesa randomly selected subset of X% of the nodes, with a different subset for each y. Hyperparameter X was setusing a gridsearch.
