Table 1: Average entropy H of the retrieved feature masksmethod	GCN	Cora			CiteSeer				PubMed			APPNP		GAT	GIN	APPNP	GCN	GAT	GIN	APPNP	GCN	GAT	GIN	ZORRO (τ = .98)	2.69	3.07	4.34	3.18	2.58	2.60	4.68	2.78	2.55	2.58	3.21	2.86GnnExplainer	7.27	7.27	7.27	7.27	8.21	8.21	8.21	8.21	6.21	6.21	6.21	6.21But do the explanations from ZORRO have high fidelity because they are less sparse than GNNEX-PLAINER? To systematically measure this, we computed the entropy of normalized probability dis-tributions over feature masks output by both approaches as a measure of sparsity, see Table 1. Notethat entropy is upper bounded by the log of the number of features (see Proposition 1). The highentropy for GnnExplainer corresponds to mask distribution closer to a uniform distribution, i.e.,all features would have equal importance. In the case of Zorro, the entropy is precisely equal to thelog of the number of selected elements. The much lower entropy (as compared to GNNEXPLAINER)achieved by Zorro shows that the hard masks are sparse.
Table 2: Test accuracy after, retraining GCN on Cora based on the top k features. We repeated theretraining 20 times, report the mean and observed a variation of below .001 in all cases.
Table 3: Average performance of the node (first) explanation on the synthetic dataset.
Table 4: Notation used in the algorithms	Variable	Descriptionn	Explained nodeT	Threshold of fidelityK	Number of nodes and features to evaluate per iterationVn	Nodes in the computational graph of nG(n) F Vp Fp S Vr Fr Vs Fs	Computational graph of n Set of all possible features Set of possible nodes that can be included in an explanation Set of possible features that can be included in an explanation Set of all explanations Set of remaining nodes Set of remaining features Selected nodes, i.e., nodes in the current explanation Selected features, i.e., features in the current explanationRVp	Ordered list of the possible nodesRFp	Ordered list of the possible featuresF(∙, ∙)	Fidelity, which takes a node set as first argument and a feature set as second argumentVs	Best node candidate set found∙-v Fs	Best feature candidate set foundY{Vs,Fs}	Randomized feature matrix, where the features Fs of the nodes Vs are kept fixed, see Eq. (4)Φ(∙)	GNN evaluated on a specific feature matrix, in Alg. 2 only evaluated to retrieve the class label of node nX	Feature matrix of all nodes in GInitialization of first element. A single explanation {Vs , Fs} consist of selected nodes Vs andselected features Fs . The challenge to select the first node and feature is the following: Selecting11Under review as a conference paper at ICLR 2021only a node or only a feature yields a non-informative value, i.e., F({v}, 0) = C and F(0, {f}) = C
Table 5: Datasets and statistics. The test accuracy is calculated on 1000 nodes.
Table 6: Performance of the feature masks on the synthetic datasetMethod	# Features	Recall	PrecisionZorro (τ = .85)	1.48	0.98	0.68Zorro (τ = .98)	2.21	0.94	0.88GnnExplainer	2.00	0.08	0.08Table 7: Number of the connected components in the explanations of the synthetic dataset.
Table 7: Number of the connected components in the explanations of the synthetic dataset.
