Table 1: ReLU significantly weakens adversarial training. By improving gradient quality for either theadversarial attacker or the network optimizer, resulted models obtains better robustness than the ReLU baseline.
Table 2: Robustnesscomparison betweenELU (non-smooth whenα 6= 1) and CELU(always smooth ∀α).
Table 3: Scaling-up ResNet in SAT. We observe SAT consistently helps larger networks get better performance.		Discussion on standard adversarial training. We first verify basic scaling of depth, width andimage resolution also matter in standard adversarial training, e.g., by scaling up ResNet-50 (33.0%robustness), the deeper ResNet-152 achieves 39.4% robustness (+6.4%), the wider ResNeXt-50-32x8d achieves 36.7% robustness (+3.7%), and the ResNet-50 with larger image resolution at 3807Under review as a conference paper at ICLR 2021achieves 36.9% robustness (+3.9%). Nonetheless, all these robustness performances are lower thanthe robustness achieved by the SAT’s ResNet-50 (42.3%, first row of Table 3). In other words,scaling UP networks seems less effective than replacing ReLU with smooth activation functions.
Table 4: Comparison to the previous state-of-the-art.
