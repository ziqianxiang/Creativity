Table 1: Comparisons among two-tower (TT) BERT, text-vision (TV) BERT, poly-encoder (PE),split-merge (SM) BERT and our cross-probe (CP) BERT.
Table 2: Time cost per query with 1K candidate images.
Table 3: The influence of the number of text and vision probes m, n. Experiments are on MS-COCO.
Table 4: The influence of the number of text-vision layers l. Experiments are on MS-COCO.
Table 5: Comparisons among two-tower BERT, text-vision BERT, Poly-Encoder, and cross-probeBERT, Unicoder-VL and UNITER with pre-training.
Table 6: The influence of the number of text-vision layers l and that of tWo-toWer layers L - l.
Table 7: The influence of the number of context codes on the retrieval accuracy.
Table 8: Comparisons among two-tower BERT, text-vision BERT, Poly-Encoder, and cross-probeBERT, Unicoder-VL and UNITER with pre-training.
Table 9: Time cost per query with 5K candidate images.
