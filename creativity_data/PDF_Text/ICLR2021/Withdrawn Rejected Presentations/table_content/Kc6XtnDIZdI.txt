Table 1: Mean classification accuracies of the 5-way 1/5-shot tasks. (Bold: Best results per set-up). SL+U setting uses all available training LD (SL setting) with additional UD vs SSL using 10%(tieredImageNet) or 40% LD (miniImageNet). Grey rows: methods using self-supervision.
Table 2: Ablation study on miniImagenet.
Table 3: Comparison of available per category training Labelled Samples (LS) and Unlabelled Sam-ples (US) between FSL, SS-FSL, SSL)Data Split	FSL	SS-FSL	SSLBase classes	600 LS	240 LS + 360 US	-Novel classes	1 LS	1LS + 100 US	25 LS + 4750 USA.3 Parameter study: Dynamic Prototype Refinement (DPR) iterationsADRln3。EISəh-DPR iterationsFigure 4: Dynamic Prototye Refinement (DPR) performance with respect to iterations MWe evaluate the influence of DPR iteration count M with respect to model performance in the 5-way 1-shot setting and report respective test accuracies in Figure 4. We observe similar behaviourfor both datasets considered (miniImageNet and tieredImageNet), with performance improving and11Under review as a conference paper at ICLR 2021455456457458459460
Table 4: Comparison of FewMatch to existing SS-FSL approachesMethod	Masked Soft k-Means	Transmatch	LST	FewMatchBase dataset	60% US+40% LS	^^100% LS^^	60% US+40% LS	60% US+40% LSTraining	Episodic	End to end	Episodic	End to endPrototypes	Feature averaging	/	/	Iterative featureClassifier	/	backpropagation	backpropagation	averaging and backpropFeature	Fixed	Fixed	Adapted to novel task	Adapted to novel taskLearning	Pseudo label	CR	Pseudo label	CRA.5 Dynamic Prototype Refinement algorithmWe provide an algorithmic description of our Dynamic Prototype Refinement (DPR) process inAlgorithm 1. DPR contains three steps: 1) Prototypes initial inference; 2) Explicit prototype refine-ment; 3) Implicit refinement using CR. We alternate between explicit and implicit refinement for Mepochs after the initial inference step.
