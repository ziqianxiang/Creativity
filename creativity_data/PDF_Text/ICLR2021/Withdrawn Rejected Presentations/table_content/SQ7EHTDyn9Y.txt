Table 1: The effect of each source of nondeterminism and several combinations of nondeterminismsources for ResNet-14 on CIFAR-10. The second and third columns give the standard deviation ofaccuracy and cross-entropy across 100 runs, varying only the nondeterminism source (700 trainedmodels total). Also given are error bars, corresponding to the standard deviation of the standarddeviation. The fourth, fifth, and sixth columns give the average percentage of examples modelsdisagree on, the average pairwise Spearman’s correlation coefficient between predictions, and theaverage change in accuracy from ensembling two models, respectively (Sec. 3.1).
Table 2: The effect of each source of nondeterminism for a QRNN on Penn Treebank; 100 runs perrow. Note that lower PPL is better, so changes in Ensemble PPL are negative.
Table 3: The effect of instability — randomly changing a single weight by one bit for ResNet-14 onCIFAR-10. Also see Table 1 for comparison.
Table 4: The effect of instability for a QRNN on Penn Treebank. Also see Table 2 for comparison.
Table 5: Snapshot ensembles compared with regular ensembles for ResNet-14 on CIFAR-10, with allnondeterminism sources enabled. N denotes the number of component models in a regular (“Vanilla”)ensemble. The snapshot ensemble is based on 100 runs of model training, and all vanilla ensemblesare drawn from a pool of 100 independent model runs.
Table 6: Generalization experiments of nondeterminism and instability with other architectures onCIFAR-10 and additional experiments on a high-accuracy dataset (MNIST). Each row is computedfrom the statistics of 100 trained models (i.e. 2,400 models total for this table).
Table 7: Experiments varying the learning rate and number of epochs for ResNet-14 on CIFAR-10. Ineach row, the experimental setting is abbreviated by [sources of nondeterminism]/[maximum learningrate]/[number of epochs] N=[number of models trained], with the exception of the last row, which isa Snapshot ensemble but otherwise follows the same format.
Table 8: Linear and 2-layer experiments on CIFAR-10performance with the original formulation due to update sizes that decreased too rapidly, and thoughwe were able to modify it to converge successfully, the output variance remained as high as the othermodels.
