Table 1: Average testing accuracy (%) and standard deviation from 10 random splits comparing ourNODE-SELECT approach to different baseline variants.
Table 2: Accuracy score and ratio by Filter and NSGNN for model trained on Cora Dataset.
Table 3: Statistics of transductive Datasets used in this paper.
Table 4: The hyperparameters providing best accuracy for each baseline model on all datasets. Theseparameters are listed as (# of layers / # of neurons used in hidden layers / learning-rate / optimizer’sweight-decay/*additional-details). The same parameters were used in Node2vec whose additionaldetails include (walk-length:20, context-size:10,walk-per-node:1,negative-sample=5)Framework	Dataset	Acc.	ConfigurationGAT	CiteSeer	74.0±0.7	2/64/ 0.0005 / 0.005 / attention-heads:8	Cora	86.0±0.7	2/ 128/ 0.0005 / 0.005 / attention-heads:8	PUbMed	86.4 ±0.3	3/64/ 0.01 / 0.00005 / attention-heads:8	-Co-P-	95.7 ±0.1	3/64/ 0.01 / 0.00005 / attention-heads:8	Co-CS	92.2 ±0.2	3/64/ 0.01 / 0.00005 / attention-heads:8	Cora FUlnr	64.8 ±0.5	2/ 128/ 0.005 / 0.00005 / attention-heads:8	Amz-P	93.7±0.6	2/ 128/ 0.005 / 0.00005 / attention-heads:8	Amz-C	90.0±0.7	2/ 128/ 0.005 / 0.00005 / attention-heads:8GCN	CiteSeer	74.0±0.6	2/128/0.0005/0.05/ —	Cora	85.0±0.7	2/ 128/0.01/0.0005/ —	PUbMed	87.2 ± 0.2	2/128/0.01/0.0005/ —	-Co-P-	95.9 ±0.1	2/64/0.01/0.0005/ —	-Co-CS-	93.1±0.2	2/128/0.01/0.0005/ —	Cora Full	67.3 ±0.5	2/128/0.01/0.0005/ —	Amz-P	93.5±0.2	2/128/0.01/0.0005/ —
Table 5: Number of cosine-similarity involved between other over-smoothing methods and ourMICS method.
