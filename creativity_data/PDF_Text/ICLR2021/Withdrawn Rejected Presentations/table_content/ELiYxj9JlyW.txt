Table 1: Means and standard deviations of classification accuracy on MNISTFlipping-Rate	Decoupling	MentorNet	Co-teaching	Forward	Joint Optim	DMI	T-revision	OursSym-20%	-95.39% 士0.29%	96.57%- ±0.18%	-97.22% ±0.18%	98.22% ±0.08%	-98.58% ±0.15%	98.92% ±0.11%	98.91% ±0.04%	98.94% ±0.13%Sym-40%	-90.77% 士0.77%	96.16%- ±0.49%	-94.64% ±0.33%	96.71% ±0.16%	-98.12% ±0.06%	98.63% ±0.11%	98.42% ±0.47%	98.66% ±0.07%Inst-20%	-96.94% ±0.07%	94.66%- ±0.35%	-95.37% ±0.08%	95.89% ±0.12%	-98.10% ±0.14%	98.75% ±0.11%	97.12% ±0.09%	98.96% ±0.06%Inst-40%	-94.98% 士0.27%	88.51%- ±0.36%	-90.06% ±0.81%	88.95% ±2.47%	-92.00% 士1.39%	97.58% 士0.82%	94.89% 士0.66%	98.11% 士0.35%Table 2: Means and standard deviations of classification accuracy on CIFAR10Flipping-Rate	Decoupling	MentorNet	Co-teaching	Forward	Joint Optim	DMI	T-revision	OursSym-20%	-79.85% ±0.30%	80.49%- ±0.52%	87.16% ±0.11%	85.63% ±0.52%	-89.70% ±0.11%	88.18% ±0.36%	89.63% ±0.13%	91.44% ±0.33%Sym-40%	-69.47% ±0.87%	77.48%- ±3.45%	83.59% ±0.28%	74.30% ±0.26%	-87.79% ±0.20%	83.98% ±0.48%	86.81% ±0.21%	88.39% ±0.34%Inst-20%	-77.85%- ±0.23%	79.12%- ±0.42%	-86.54%- ±0.11%	85.29% ±0.38%	-89.69%- ±0.42%	89.14% ±0.36%	90.46% ±0.13%	90.86% ±0.21%Inst-40%	-59.05% 士0.73%	70.27%- 士1.52%	80.98% 士0.39%	74.72% 士3.24%	-82.62% 士0.57%	84.78% 士1.97%	85.37% 士3.36%	86.66% 士0.91%Table 3: Means and standard deviations of classification accuracy on CIFAR100Flipping-Rate	Decoupling	MentorNet	Co-teaching	Forward	Joint Optim	DMI	T-revision	OursSym-20%	-42.75% ±0.49%	52.11%- ±0.10%	-59.28% ±0.47%	57.75% ±0.37%	-64.55% ±0.38%	58.73% ±0.70%	65.40% ±1.07%	68.03% ±0.53%Sym-40%	-37.13% ±0.91%	35.12%- ±1.13%	-51.60% ±0.49%	38.59% ±1.62%	-57.97% ±0.67%	49.81% ±1.22%	57.71% ±0.84%	63.48% ±0.72%Inst-20%	-48.33% ±0.35%	51.73%- ±0.17%	-57.24% ±0.69%	58.76% ±0.66%	-65.15% ±0.31%	58.05% ±0.20%	60.71% ±0.73%	68.11% ±0.57%Inst-40%	-34.26% 士0.59%	40.90%- 士0.45%	-45.69% 士0.99%	44.50% 士0.72%	-55.57% 士0.41%	47.36% 士0.68%	51.54% 士0.91%	58.38% 士1.28%examples from the mini-batches used in SGD. We therefore do not compare with its extracted con-fident examples in Section 3.2 as our method extracts confident examples from the whole training
Table 2: Means and standard deviations of classification accuracy on CIFAR10Flipping-Rate	Decoupling	MentorNet	Co-teaching	Forward	Joint Optim	DMI	T-revision	OursSym-20%	-79.85% ±0.30%	80.49%- ±0.52%	87.16% ±0.11%	85.63% ±0.52%	-89.70% ±0.11%	88.18% ±0.36%	89.63% ±0.13%	91.44% ±0.33%Sym-40%	-69.47% ±0.87%	77.48%- ±3.45%	83.59% ±0.28%	74.30% ±0.26%	-87.79% ±0.20%	83.98% ±0.48%	86.81% ±0.21%	88.39% ±0.34%Inst-20%	-77.85%- ±0.23%	79.12%- ±0.42%	-86.54%- ±0.11%	85.29% ±0.38%	-89.69%- ±0.42%	89.14% ±0.36%	90.46% ±0.13%	90.86% ±0.21%Inst-40%	-59.05% 士0.73%	70.27%- 士1.52%	80.98% 士0.39%	74.72% 士3.24%	-82.62% 士0.57%	84.78% 士1.97%	85.37% 士3.36%	86.66% 士0.91%Table 3: Means and standard deviations of classification accuracy on CIFAR100Flipping-Rate	Decoupling	MentorNet	Co-teaching	Forward	Joint Optim	DMI	T-revision	OursSym-20%	-42.75% ±0.49%	52.11%- ±0.10%	-59.28% ±0.47%	57.75% ±0.37%	-64.55% ±0.38%	58.73% ±0.70%	65.40% ±1.07%	68.03% ±0.53%Sym-40%	-37.13% ±0.91%	35.12%- ±1.13%	-51.60% ±0.49%	38.59% ±1.62%	-57.97% ±0.67%	49.81% ±1.22%	57.71% ±0.84%	63.48% ±0.72%Inst-20%	-48.33% ±0.35%	51.73%- ±0.17%	-57.24% ±0.69%	58.76% ±0.66%	-65.15% ±0.31%	58.05% ±0.20%	60.71% ±0.73%	68.11% ±0.57%Inst-40%	-34.26% 士0.59%	40.90%- 士0.45%	-45.69% 士0.99%	44.50% 士0.72%	-55.57% 士0.41%	47.36% 士0.68%	51.54% 士0.91%	58.38% 士1.28%examples from the mini-batches used in SGD. We therefore do not compare with its extracted con-fident examples in Section 3.2 as our method extracts confident examples from the whole trainingdata at once. By comparing the classification performance, we can clearly see that the proposedmethod is much more powerful in extracting confident examples. Note that Joint Optim and T-revision employ all training data to train the classifiers; while our method only employs confidentexamples and discards the unconfident ones. The results further justify that Me-Momentum is ableto extract high-quality confident examples. Note that the performance of Me-Momentum could befurther improved by correcting the unconfident data with the idea of Joint Optim.
Table 3: Means and standard deviations of classification accuracy on CIFAR100Flipping-Rate	Decoupling	MentorNet	Co-teaching	Forward	Joint Optim	DMI	T-revision	OursSym-20%	-42.75% ±0.49%	52.11%- ±0.10%	-59.28% ±0.47%	57.75% ±0.37%	-64.55% ±0.38%	58.73% ±0.70%	65.40% ±1.07%	68.03% ±0.53%Sym-40%	-37.13% ±0.91%	35.12%- ±1.13%	-51.60% ±0.49%	38.59% ±1.62%	-57.97% ±0.67%	49.81% ±1.22%	57.71% ±0.84%	63.48% ±0.72%Inst-20%	-48.33% ±0.35%	51.73%- ±0.17%	-57.24% ±0.69%	58.76% ±0.66%	-65.15% ±0.31%	58.05% ±0.20%	60.71% ±0.73%	68.11% ±0.57%Inst-40%	-34.26% 士0.59%	40.90%- 士0.45%	-45.69% 士0.99%	44.50% 士0.72%	-55.57% 士0.41%	47.36% 士0.68%	51.54% 士0.91%	58.38% 士1.28%examples from the mini-batches used in SGD. We therefore do not compare with its extracted con-fident examples in Section 3.2 as our method extracts confident examples from the whole trainingdata at once. By comparing the classification performance, we can clearly see that the proposedmethod is much more powerful in extracting confident examples. Note that Joint Optim and T-revision employ all training data to train the classifiers; while our method only employs confidentexamples and discards the unconfident ones. The results further justify that Me-Momentum is ableto extract high-quality confident examples. Note that the performance of Me-Momentum could befurther improved by correcting the unconfident data with the idea of Joint Optim.
Table 4: Classification accuracy on Cloth-ing1M.
Table 5: Means and standard deviations of classification accuracy compared with SELF	CIFAR10 Sym-40	CIFAR10 Sym-60	CIFAR100 Sym-40	CIFAR100 Sym-60SELF	87.35%	75.47%	61.40%	50.60%Ours	92.31%	87.88%	68.25%	59.51%Furthermore, results in Table 5 shows that the performance of Me-Momentum can be improved bychanging a better backbone. However, to show the effectiveness of the proposed method and avoidcomplexity, we simply choose in the paper the standard CNN network.
