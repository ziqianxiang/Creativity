Table 1: CartPole with different number N of training tasks. Note that RNN does not Î¼ at train time.
Table 2: Result over Tabular-MDP with S states and A = 5 actions, trained over N = 100 tasks.
Table 3: Bandits performance for K = 10 andK = 20 arms, with N = 100 training tasks.
Table 4: Hyperparameters tested per environments. At each training epoch, we run our agent on Eenvironments in parallel collecting Tr transitions on each of them resulting in batches of M = E * Trtransitions.
Table 5: AcrobotAcrobot consists of two joints and two links, where the joint between the two links is actuated. Initially,the links are hanging downwards, and the goal is to swing the end of the lower link uP to a given height.
