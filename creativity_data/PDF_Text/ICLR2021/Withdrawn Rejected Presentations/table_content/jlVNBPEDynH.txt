Table 1: Training hyperparameters, where alpha denotes the margin that was used on the vertex costsand λ the interpolation parameter for blackbox differentiation od Dijkstra. We vary the kernel size ofthe initial convolution for ResNet18.
Table 2: Training hyperparameters for the CHASER experiment, where alpha denotes the marginthat was used on the vertex costs and λ the interpolation parameter for blackbox differentiation odDijkstra.
Table 3: PPO hyperparameters, as used in Cobbe et al. (2019).
