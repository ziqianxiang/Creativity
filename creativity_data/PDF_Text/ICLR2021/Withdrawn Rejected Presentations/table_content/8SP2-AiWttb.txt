Table 1: Robustness (%) of 12 defense models evaluated by different attacks. The attacks are dividedinto 2 groups: 1) traditional attacks for robustness evaluation and our MD (column 3-6); and 2) morerecent attacks and our MDMT (column 7-10). The defenses are also divided into 2 groups: 1) SAT orimproved defenses (top rows); and 2) those that are not improved over SAT (bottom rows). Results in(∙) in the MDMT column show the robustness decrease compared to the PGD attack.
Table 2: Average time cost (in hours) of MTMD, AA and AA+ attacks on defense models Adv-Interp,FeaScatter and Sense over 5 repeats on the entire CIFAR-10 test set. The best results are in bold.
Table 3: Robustness (%) of WideResNet-34-10models trained with/without label smoothing.
Table 4: Attack success rate (ASR) of the SPSA attack with or without our MD on three CIFAR-10defense models. The ASRs are tested on the entire CIFAR-10 test set. The best results are in bold.
Table 5: Test of obfuscated gradients for four defense models that have significant imbalancedgradients following (Athalye et al., 2018): attack success rate (%) of different attacks. None of theabove results indicates a clear sign of obfuscated gradients.
Table 6: Robustness (%) of four defense models that have significant imbalance gradients againstPGD100×400 and MI-FGSM attack.
Table 7: Attack success rates (%) of our MD and MDMT attacks with 1) different initializationmethods, 2) with/without the second attacking stage, and 3) with/without stages being switched.
Table 8: Adversarial robustness (%) of PGD attack with different step sizes on defense modelsAdv-Interp, FeaScatter, Sense and SAT trained on CIFAR-10. The results are computed on the entireCIFAR-10 test set. The lowest robustness (i.e. strongest attack) of each defense model is highlightedin bold.
Table 9: Attack success rates (%) of the 4 individual attacks (column 2-6) in AA attack and our MDattacks (column 6-7). The best results are highlighted in bold. The second best results are highlightedin underlineDefense	APGDCE	APGDDLR	FAB	Square	MD	MDMTRST	61.47	60.64	60.62	66.63	60.17	59.86UAT	59.86	62.03	58.20	66.37	59.36	56.65TRADES	55.08	54.04	53.82	59.48	53.10	52.78MART	55.52	52.51	51.55	57.45	51.84	51.07SAT	46.40	46.56	46.38	53.13	45.64	45.25Dynamic	45.81	45.86	43.64	53.49	43.93	42.69MMA	49.40	50.18	47.38	55.48	45.63	41.92Bilateral	58.26	43.11	41.36	59.07	39.82	37.21Adv-Interp	69.36	49.43	40.60	66.87	45.33	37.59FeaScatter	62.03	48.96	40.84	59.12	43.12	36.86Sense	54.80	48.41	38.88	61.31	40.64	35.25JARN-AT1	37.25	67.55	67.40	75.32	15.03	14.60Table 10: Robustness (%) of 3 defense models trained on CIFAR100 data against PGD, AA and ourMDMT attacks. The best results (lowest evaluation robustness) are highlighted in bold.
Table 10: Robustness (%) of 3 defense models trained on CIFAR100 data against PGD, AA and ourMDMT attacks. The best results (lowest evaluation robustness) are highlighted in bold.
