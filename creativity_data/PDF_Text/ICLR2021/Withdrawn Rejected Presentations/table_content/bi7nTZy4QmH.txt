Table 1: Results of using uniform perturbation budgets (Zhang et al., 2020) and our learned onesrespectively on MNIST for certified defense with various target robustness volumes. “-” denotesthat training with uniform perturbation budgets 0 = 0.6 or 0 = 0.8 totally fails, and thus we alsoevaluate models trained with 0 = 0.4 on test volumes 0 = 0.6 and 0 = 0.8 respectively. Forverified errors in evaluation, we provide results evaluated with the method by Liu et al. (2019), onuniform budgets, and on our learned budgets respectively.
Table 2: Results on CIFAR-10, in a similar format with Table 1.
Table 3: Results on the artificial Watermarked MNIST dataset. Using an uniform budget resulting ina > 50% error, as the classifier are not sensitive enough to these watermarked pixels.
Table 4: Results on the synthetic Doubled CIFAR-10 dataset.
