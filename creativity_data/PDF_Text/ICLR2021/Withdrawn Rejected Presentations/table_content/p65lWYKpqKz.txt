Table 1: Parameters for synthetic dataset.
Table 2: Prediction error (MAE) of the first (top) and second (bottom) order spatial derivatives.
Table 4: Graph signal regression results (MSE, 10-3) and standard deviations on the two regions ofweather stations.
Table 5: Parameters for synthetic datasetMeta-train Meta-test#	nodes (N)	{256, 625}#	edges per a node (E)	{4, 8}Initial frequency (F)	{2, 5}{450, 800}{3, 6, 10}{3, 7}Tasks: For each node, we have the first and second order derivatives. We meta-train the spatial derivativemodules (Sec. 3.1) to predict the spatial derivatives by feeding node and edge features (function value at a nodeand relative displacement, respectively) as input.
Table 6: The number of learnable parameters for baselines and PiMetaL	GCN	GAT	GraPhSAGE	GN	PA-DGN	PiMetaL# of parameters	10,801	11,203	21,401	20,385	33,795	33,795B.3	Experimental DetailsB.3.1	BaselinesSince the input length of the regression task is fixed (length=5), we can consider many variants of graphneural networks for the task. We concatenate the 5-step signals and feed it into Graph convolutional net-15Under review as a conference paper at ICLR 2021Table 7: Regression error (MAE, 10-3) of different topology for synthetic dynamics (Europe)	(N,F) = (700, 1.5)	(N,F) = (1700, 2)	(N,F) = (128, 7)5-shot	0.781±0.019	0.981±0.131	1.007±0.09610-shot	0.773±0.014	0.951±0.151	0.932±0.058works (GCN)(KiPf & Welling, 2017), Graph attention networks (GAT)(Velickovic et al., 2018), Graph-SAGE (Hamilton et al., 2017), and Graph networks (GN) (Battaglia et al., 2018) to predict next signals acrossall nodes. For the baselines, we commonly consider 3-hop neighbors of i-th node to predict of the i-th nodeand the number of learnable parameters is similar to provide similar expressive power.
Table 7: Regression error (MAE, 10-3) of different topology for synthetic dynamics (Europe)	(N,F) = (700, 1.5)	(N,F) = (1700, 2)	(N,F) = (128, 7)5-shot	0.781±0.019	0.981±0.131	1.007±0.09610-shot	0.773±0.014	0.951±0.151	0.932±0.058works (GCN)(KiPf & Welling, 2017), Graph attention networks (GAT)(Velickovic et al., 2018), Graph-SAGE (Hamilton et al., 2017), and Graph networks (GN) (Battaglia et al., 2018) to predict next signals acrossall nodes. For the baselines, we commonly consider 3-hop neighbors of i-th node to predict of the i-th nodeand the number of learnable parameters is similar to provide similar expressive power.
