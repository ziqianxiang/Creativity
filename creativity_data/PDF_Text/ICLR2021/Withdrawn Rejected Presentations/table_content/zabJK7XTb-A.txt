Table 3: Comparison with other transductive models			datasets. As for the 5-shot, we achieve comparable performance through a quarter parameter back-6Under review as a conference paper at ICLR 2021Table 1: Average classification performance over 1000 randomly generated episodes, with 95% confidence intervals. We consider 5-way classification on all the datasets. * denotes it is reported from Yang et al. (2020).					Model	Backbone	miniImageNet		tieredImageNet			1-shot	5-shot	1-shot	5-shotTPN (Liu et al., 2018)	ConvNet-64	55.51±0.86	69.86±0.65	59.91±0.94	73.30±0.75EGNN* (Kim et al., 2019)	ConvNet-256	59.63±0.52	76.34±0.48	63.52±0.52	80.24±0.49MAML+SCA (Antoniou & Storkey, 2019)	DenseNet	62.86±0.79	77.46±1.18	-	-CAN + Top-k (Hou et al., 2019)	ResNet-12	67.19±0.55	80.64±0.35	73.21±0.58	84.93±0.38DPGN (Yang et al., 2020)	ResNet-12	67.77±0.32	84.60±0.43	72.45±0.51	87.24±0.39TEAM (Qiao et al., 2019)	ResNet-18	60.07	75.90	-	-Fine-tuning (Dhillon et al., 2020)	WRN-28-10	65.73±0.68	78.40±0.52	73.34±0.71	85.50±0.50SIB (Hu et al., 2020)	WRN-28-10	70.0±0.6	79.2±0.4	-	-TIM-GD (Boudiafet al., 2020)	WRN-28-10	77.8	87.4	82.1	89.8MCT (Pair)	ResNet-12	76.16±o,89	85.22±o.42	80.68±o.89	86.63±o.89MCT (Instance)	ResNet-12	78.55±o.86	86.03±o.42	82.32±o.8i	87.36±o.5oTable 2: Average classification performance on CIFAR-FS and FC100.
Table 1: Average classification performance over 1000 randomly generated episodes, with 95% confidence intervals. We consider 5-way classification on all the datasets. * denotes it is reported from Yang et al. (2020).					Model	Backbone	miniImageNet		tieredImageNet			1-shot	5-shot	1-shot	5-shotTPN (Liu et al., 2018)	ConvNet-64	55.51±0.86	69.86±0.65	59.91±0.94	73.30±0.75EGNN* (Kim et al., 2019)	ConvNet-256	59.63±0.52	76.34±0.48	63.52±0.52	80.24±0.49MAML+SCA (Antoniou & Storkey, 2019)	DenseNet	62.86±0.79	77.46±1.18	-	-CAN + Top-k (Hou et al., 2019)	ResNet-12	67.19±0.55	80.64±0.35	73.21±0.58	84.93±0.38DPGN (Yang et al., 2020)	ResNet-12	67.77±0.32	84.60±0.43	72.45±0.51	87.24±0.39TEAM (Qiao et al., 2019)	ResNet-18	60.07	75.90	-	-Fine-tuning (Dhillon et al., 2020)	WRN-28-10	65.73±0.68	78.40±0.52	73.34±0.71	85.50±0.50SIB (Hu et al., 2020)	WRN-28-10	70.0±0.6	79.2±0.4	-	-TIM-GD (Boudiafet al., 2020)	WRN-28-10	77.8	87.4	82.1	89.8MCT (Pair)	ResNet-12	76.16±o,89	85.22±o.42	80.68±o.89	86.63±o.89MCT (Instance)	ResNet-12	78.55±o.86	86.03±o.42	82.32±o.8i	87.36±o.5oTable 2: Average classification performance on CIFAR-FS and FC100.
Table 2: Average classification performance on CIFAR-FS and FC100.
Table 4: Semi-supervised few-shot classification performance. We consider 5-way classification on miniIm-ageNet (‘mini’) and tieredImageNet (‘tiered’). The baseline results are drawn from Li et al. (2019). All resultsare based on pre-trained ResNet-12 with full dataset in conventional supervised manner. “w/D” means thatunlabeled set includes 3 distracting classes, which does not overlap the label space of the support set (Li et al.,2019; Liu et al., 2018; Ren et al., 2018).
Table 5: Average classification performance over 1000 randomly generated episodes, with 95% confidenceintervals. d(∙, ∙) denotes Euclidean distance. S ∈ R is a learnable parameter initialized to 7.5, following Oreshkinetal.(2018).______________________________________________________________________________________________________ModelDistance MetricInductive1-shot 5-shotTransductive1-shot 5-shotProtoNets (PN) PN + metric scaling	d(aι, a2) S ∙ d(aι, a2)	57.36±0.66 55.43±0.67	75.59±0.51 74.52±0.49	68.58±0.92 68.34±0.87	78.71±0.53 78.57±0.51PN + Instance-wise metric (Eq. 3)	dIφ(a1, a2)	61.08±0.66	77.26±0.46	70.34±0.87	79.54±0.54PN + Pair-wise metric (Eq. 4)	dP (aι, a2)	61.81±0.58	77.67±0.50	71.95±0.81	81.06±0.51Effect of the model / data perturba- tion In Table 6, We analyze the con-	Data Perturb	Model Perturb	miniImageNet 1-shot		miniImageNet 5-shot				NLL	Transduction	NLL	Transductiontribution of each type of uncertainty to the reliability of confidence. We observe that the performance of trans- ductive inference improves as we add in each type of uncertainties. We use negative log-likelihood (NLL) as the quality measure for the confidence	X ✓ X ✓	X X ✓ ✓	1.11 1.09 1.04 1.09	-^71.95±0.81- 73.93±0.85 74.07±0.85 74.73±o.86	0.82 0.68 0.60 0.60	81.06±0.51 81.93±0.49 82.62±0.47 83.36±0.45	Table 6: Test NLL vs. performance of transductive inference with pair-wise distance metric. NLL is computed just before taking the initial transductive step.					scores: the lower the NLL, the closer the confidence scores to the target label. We observe that bothtypes of uncertainties are helpful in improving the reliability of the output confidence.
Table 7: Ablation study on miniImageNet.
