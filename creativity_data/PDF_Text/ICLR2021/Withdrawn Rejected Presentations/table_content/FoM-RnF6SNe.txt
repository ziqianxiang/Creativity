Table 1: Correlation coefficientsbetween each metric and task re-ward or human similarity. The3 task-agnostic metrics correlatemore strongly with human simi-larity than with task reward. Thissuggests that typical RL tasksmay not be a sufficient proxy forintelligent behavior seen in hu-mans playing the same games.
Table 2: Lifetime values of each metric for all agents and environments, with the highest value ofeach row in bold. In all three environments, the highest task reward is achieved by task-specific RNDor ICM, which maximize both task reward and different implementations of input entropy; and thehighest input entropy is achieved by task-agnostic RND or ICM, which is to be expected as theseagents maximize input entropy alone. Agents with the highest human similarity, empowerment, andinformation gain vary by environment. Note that the random agent achieves high reward in Minecraft;this may be related to the shorter run-time of 12 million frames, which was necessary because theMinecraft environment is slower than the Atari games. Nonetheless, the random agent in Minecrafthas high input entropy and infogain, as expected due to the correlation of those metrics with reward.
Table 3: Correlations of four information gain implementations with task reward and human similarity.
Table 4: Correlations of two human similarity implementations with task reward and the threetask-agnostic metrics. We compare the Jaccard similarity (intersection over union) of the set of statesvisited by the human player and those visited by the RL agent, with the Jensen-Shannon divergencebetween the two sets. We find that Jaccard similarity correlates much more strongly with task reward,slightly more strongly with input entropy and information gain, and near-equally with empowerment,as compared to Jensen-Shannon divergence. The two implementations have a correlation of 0.78 witheach other.
Table 5: For our analysis we normalized all metrics by the number of time steps in the agentâ€™s dataset.
