Table 1: Practical principles under different scenariosTransfer Scenarios	I Learn (g, h) ∣ Estimate at ∣	I Estimate λMulti-Source Transfer with Limited Target Data	I T(y)∕St(y)	Unsupervised Multi-Source DA	l Sec. 4.1 I	l Sec. 4.2 I	I Sec. 4.3Partial Unsupervised Multi-Source DA	I	I	4 Unified Practical Framework in Deep LearningThe theoretical results in Section 3 motivate general principles to folloW When designing multi-source transfer learning algorithms. We summarize those principles in the folloWing rules.
Table 2: Unsupervised DA: Accuracy (%) on the Source-Shifted Digits.
Table 3: Unsupervised DA: Accuracy (%) on Office-HomeTarget	Art	Clipart	Product	Real-World	AverageSource	49.25±0.6o	46.89±0.6i	66.54±1.72	73.64±0.91	59.08DANN	50.32±0.32	50.11±ι.i6	68.18±1.27	73.71±1.63	60.58MDAN	67.93±0.36	66.61±i.32	79.24±1.52	81.82±0.65	73.90MDMN	68.38±0.58	67.42±0.53	82.49±0.56	83.32±1.93	75.28M3SDA	63.77±i.07	62.30±0.44	75.85±1.24	79.92±0.60	70.46DARN	69.89±0.42	68.61±o.5o	83.37±0.62	84.29±0.46	76.54WADN	73.78±i143	70.18±0.54	86.32±0.38	87.28±0.87	79.39Full TAR	76.17±o.i6	79.37±o.22	90.60±0.24	87.65±0.18	83.45The empirical results reveal a significantly better performance (≈ 3%) on different datasets. Forunderstanding the working principles of WADN, we evaluate the performance under different levelsof source label shift in Amazon Review dataset (Fig.1(a)). The results show strong practical benefitsfor WADN during a gradual larger label shift. In addition, we visualize the task relations in digits(Fig.1(b)) and demonstrate a non-uniform λ, which highlights the importance of properly choosingthe most related source rather than simply merging all the data. E.g. when the target domain isSVHN, WADN mainly leverages the information from SYNTH, since they are more semanticallysimilar and MNIST does not help too much for SVHN (observed by Ganin et al. (2016)). Theadditional analysis and results can be found in Appendix O.
Table 4: Multi-source Transfer: Accuracy (%) on Source-Shifted Amazon ReviewTarget	Books	DVD	Electronics	Kitchen	AverageSource + Tar	72.59±i.89	73.02±i.84	81.59±1.58	77.03±1.73	76.06DANN	67.35±2.28	66.33±2.42	78.03±1.72	74.31±1.71	71.50MDAN	68.70±2.99	69.30±2.2i	78.78±2.21	74.07±1.89	72.71-M3SDA	69.28±i.78	67.40±o.46	76.28±0.81	76.50±1.19	72.36DARN	68.57±i.35	68.77±i.81	80.19±1.66	77.51±1.20	73.76RLUS	71.83±ι.7i	69.64±2.39	81.98±1.04	78.69±1.15	75.54MME	69.66±0.58	71.36±o.96	78.88±1.51	76.64±1.73	74.14WADN	74.83±0.84	75.05±o.62	84.23±0.58	81.53±0.90	78.91Full TAR	84.10±0.13	83.68±0.i2	86.11±0.32	88.72±0.14	86.65Table 5: Multi-source Transfer: Accuracy (%) on the Source-Shifted DigitsTarget	MNIST	SVHN	SYNTH	USPS	AverageSource + Tar	79.63±i.74	56.48±i.90	69.64±i.38	86.29±i.56	73.01DANN	86.77±i.30	69.13±i.09	78.82±i.35	86.54±i.03	80.32MDAN	86.93±i.05	68∙25±i.53	79.80±i.i7	86.23±i.4i	80.30M3SDA	85.88±2.06	68.84±i.05	76.29±0.95	87.15±i.i0	79.54DARN	86.58±i.46	68.86±i.30	80.47±0.67	86.80±0.89	80.68-RLUS	87.61±i.08	70∙50±0.94	79.52±i.30	86.70±i.i3	81.08-MME	87.24±0.95	65.20±i.35	80.31±0.60	87.88±0.76	80.16
Table 5: Multi-source Transfer: Accuracy (%) on the Source-Shifted DigitsTarget	MNIST	SVHN	SYNTH	USPS	AverageSource + Tar	79.63±i.74	56.48±i.90	69.64±i.38	86.29±i.56	73.01DANN	86.77±i.30	69.13±i.09	78.82±i.35	86.54±i.03	80.32MDAN	86.93±i.05	68∙25±i.53	79.80±i.i7	86.23±i.4i	80.30M3SDA	85.88±2.06	68.84±i.05	76.29±0.95	87.15±i.i0	79.54DARN	86.58±i.46	68.86±i.30	80.47±0.67	86.80±0.89	80.68-RLUS	87.61±i.08	70∙50±0.94	79.52±i.30	86.70±i.i3	81.08-MME	87.24±0.95	65.20±i.35	80.31±0.60	87.88±0.76	80.16WADN	88.32±i.i7	70.64±i.02	81.53±i.ii	90.53±0.7i	82.75Full TAR	98.70±0.i5	85.20±0.09	95.10±0.i4	96.64±0.i3	93.91The results are reported in Tabs. 4, 5, which also indicates strong empirical benefits. To show theeffectiveness of WADN, We select various portions of labelled samples (1% 〜10%) on the target.
Table 6: Unsupervised Partial DA: Accuracy (%) on Office-Home (#Source: 65, #Target: 35)Target	Art	Clipart	Product	Real-World	AverageSource	50.56±1.42	49.79±1.14	68.10±1.33	78.24±0.76	61.67DANN	53.86±2.23	52.71±2.20	7L25±2.44	76.92±1.21	63.69MDAN	67.56±1.39	65.38±1.30	81.49±i.92	83.44±1.01	74.47MDMN	68.13±1.08	65.27±1.93	81.33±i.29	84.00±0.64	74.68~M3SDA	65.10±1.97	61.80±1.99	76.19±2.44	79.14±1.51	70.56DARN	71.53±0.63	69.31±1.08	82.87±i.56	84.76±0.57	77.12PADA	74.37±0.84	69.64±0.80	83.45±ι.i3	85.64±0.39	78.28WADN	80.06±0.93	75.90±1.06	89∙55±0.72	90.40±0.39	83.98The reported results are also significantly better than the current multi-source DA or one-to-onepartial DA approach, which verifies the benefits of WADN: properly estimating αt and assigningproper λ for each source.
Table 7: Unsupervised DA: Accuracy (%) on Source-Shifted Amazon Review.
Table 8: Table of NotationsRD (h) = E(x,y)~D '(h(x,y))RD (h) = N Pi=1 '(h(χi,yi))a and (^tRS(h) = N Pi=1 α(yi)'(h(Xi,yi))S(z|y) = Rx g(z|x)S(x|Y = y)dxW1(St(z|y)kT (z|y))Expected Risk on distribution D w.r.t. hypothesis hEmpirical Risk on observed data {(xi, yi)}iN=1 that are i.i.d. sampledfrom D.
