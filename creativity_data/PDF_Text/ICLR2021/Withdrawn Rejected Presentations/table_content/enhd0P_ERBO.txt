Table 1: Performance comparison of mCVRPs on random instances		mCVRP25			mCVRP50		mCVRP100	Method	Nv = 2	Nv = 3	Nv = 5	Nv = 2	Nv =3	Nv = 5	Nv = 5	Nv = 10ORT	2.51	1.60	1.29	4.31	2.71	1.77	-	1.87	(4.5)	(16.7)	(45.2)	(12.1)	(19.2)	(51.9)	(∞)	(489.2)GRLTS	3.15	2.0	1.20	3.72	2.65	1.71	2.71	1.88	(0.9)	(1.0)	(1.0)	(4.7)	(4.1)	(3.9)	(11.8)	(11.7)Gap (%)	25.5	25.0	-7.0	-13.7	-2.2	-3.4	-	0.5Table 2: Scalability test of the trained GRLTS with large-scale mCVRPsmCVRP25-5 mCVRP100-10 mCVRP400-20 mCVRP2500-501.2 (0.98)	1.88 (12.1)	4.09 (420.2)	11.71 (3,861.2)We apply the trained policy (GRLTS) to solve mCVRP with different numbers of vehicles Nv ∈ 2, 3, 5and the numbers of customers Nc ∈ 25, 50, 100. The number of refueling stations are set to be 4,5 and 10 in case of Nc = 25, Nc = 50 and Nc = 100. For every combination of Nv and Nc, werandomly generate 100 mCVRP instances, each of which has randomly located customer nodesand refueling nodes. The x and y coordinates of each node is randomly sampled from the uniformdistributions; X 〜U[0,1] and y 〜U[0,1], respectively. We employ GRLTS and ORT to solve thesame 100 random mCVRP instances and compute the average makespan and the computational timerequired to solve the mCVRP instance with the policies. Table 1 compares the average makespan andcomputational times.
Table 2: Scalability test of the trained GRLTS with large-scale mCVRPsmCVRP25-5 mCVRP100-10 mCVRP400-20 mCVRP2500-501.2 (0.98)	1.88 (12.1)	4.09 (420.2)	11.71 (3,861.2)We apply the trained policy (GRLTS) to solve mCVRP with different numbers of vehicles Nv ∈ 2, 3, 5and the numbers of customers Nc ∈ 25, 50, 100. The number of refueling stations are set to be 4,5 and 10 in case of Nc = 25, Nc = 50 and Nc = 100. For every combination of Nv and Nc, werandomly generate 100 mCVRP instances, each of which has randomly located customer nodesand refueling nodes. The x and y coordinates of each node is randomly sampled from the uniformdistributions; X 〜U[0,1] and y 〜U[0,1], respectively. We employ GRLTS and ORT to solve thesame 100 random mCVRP instances and compute the average makespan and the computational timerequired to solve the mCVRP instance with the policies. Table 1 compares the average makespan andcomputational times.
Table 3: Performance comparison on mTSP for random instancesNv	mTSP50				mTSP100				mTSP400				2	4	6	8	2	4	6	8	10	20	30	40ORT	3.20	2.21	1.60	1.11	5.13	2.69	2.25	1.71	3.02	2.0	1.91	1.61	(1.3)	(1.2)	(1.2)	(1.2)	(25.4)	(21.1)	(21.5)	(22.1)	(1358.8)	(965.9)	(1115.6)	(1025.7)GRLTS	3.94	2.83	1.47	0.98	5.13	2.34	2.16	1.71	2.64	2.06	1.34	1.15	(3.1)	(3.2)	(3.0)	(3.0)	(16.3)	(11.2)	(10.9)	(11.1)	(432.6)	(452.1)	(442.1)	(465.7)Gap (%)	23.1	28.1	-8.1	-11.7	0.0	-13.0	-4.0	0.0	-12.6	3.0	-29.8	-28.6Similarly, for all the sizes of mTSP case, we compare the performance of GRLTS to the solutioncomputed by CPLEX in the Appendix. We also employed the trained model to solve mTSP benchmarkproblems in MTSPLib 1 solving MinMax mTSP. The performance results on 124 instances (fourdifferent number of vehicles per 31 different maps) are provided in Table 9 in Appendix.
Table 4: Performance comparison on CVRP for random instancesMethods	CVRP20			CVRP50			CVRP100			Obj.	GaP (%)	Time	Obj.	Gap (%)	Time	Obj.	Gap (%)	TimeL2I(Lu et al.,2019)	6.12	-	12m	10.35	-	17m	15.57	-	24mLKH3 (Helsgaun, 2017)	6.14	0.33	2h	10.38	0.29	7h	15.64	0.45	13hOR-Tools	6.46	5.56	2m	11.27	8.89	13m	17.12	9.96	46mAM (Kool et al., 2018) greedy	6.4	4.58	1s	10.61	2.51	3s	16.17	3.85	8sAM Sampling	6.25	2.12	6m	10.59	2.32	28m	16.12	3.53	2hNazari et al. (2018)	6.4	4.58		11.15	7.73		16.96	8.93	Chen & Tian (2019)	6.16	0.65		10.51	1.55		16.1	3.40	Random Sweep	7.08	15.69		12.96	25.22		20.33	30.57	Random CW	6.81	11.27		12.25	18.36		18.96	21.77	GRLTS (Ours)	6.97	13.89	2s	12.91	24.73	5s	19.74	26.78	15sWe employ the trained model to solve randomly generated 100 CVRP instances with Nc = 20, 50, 100with a single capacitated vehicle. All nodes are randomly scattered in the unit square of [0, 1] × [0, 1].
Table 5: Performance comparison on TSP for random instancesMethods	CVRP20			CVRP50			CVRP100			Obj.	GaP (%)	Time	Obj.	Gap (%)	Time	Obj.	Gap (%)	TimeConcorde	3.84	0.00	1m	5.70	0.00	2m	7.76	0	3mLKH3	3.84	0.00	18s	5.70	0.00	5m	7.76	0	21mOR-Tools	3.85	0.26	0s	5.80	1.75	1s	7.99	2.96	3sAM (greedy)	3.85	0.26	0s	5.80	1.75	2s	8.12	4.64	6sAM (sampling)	3.84	0.00	5m	5.73	0.53	24m	7.94	2.32	1hNearest Insertion	4.33	12.76	1s	6.78	18.95	2s	9.46	21.91	6sRandom Insertion	4.00	4.17	0s	6.13	7.54	1s	8.52	9.79	3sFarthest Insertion	3.93	2.34	1s	6.01	5.44	2s	8.35	7.60	7sBello et al. (2016)	3.89	1.30		5.95	4.39		8.3	6.96	Khalil et al. (2017)	3.89	1.30		5.99	5.09		8.31	7.09	GRLTS (Ours)	3.92	2.08	1s	6.32	10.88	3s	8.79	13.27	9sLastly, we employ the trained model to solve 100 randomly generated TSP with different number ofcustomers Nc = 20, 50, 100 and a single vehicle. Table 5 shows summarized the results. AlthoughGRLTS is not outperforming other RL-based scheduling methods, it shows the reasonably perfor-mance that is comparable to some of well known heuristic algorithms. Given that the GRLTS istrained with mCVRP environment and have never seen TSP instances, this result can validate thatGRLTS can be transferred to TSP as well.
Table 6: Performance comparison of mCVRPs on random instancesNv	Nc = 25			Nv	Nc = 50		Nv	Nc = 100		CPX	ORT	RL		CPX ORT	RL		CPX	ORT	RL2	20 (∞)	15(3.9)	20 (0.96)	2	-	34 (38.3)	30 (4.8)	5	-	27 (510.3)	29(11.9)3	14 (∞)	10 (36.6)	16 (1.01)	3	-	22 (2.2)	22 (4.1)	10	--	20 (12.1)5	12 (∞)	-	8 (0.98)	5	-14 (1.7)	14 (3.8)			We apply the already trained model to solve mCVRP with different numbers of vehicles Nv ∈ 2, 3, 5and the numbers of customers Nc ∈ 25, 50, 100. The number of refueling stations are set to be 4, 5and 10 in case of Nc = 25, Nc = 50 and Nc = 100. For all cases, we compute the total completiontime and the computational time (the number in the parenthesis) required to construct a scheduling.
Table 7: Performance comparison on mTSP for random instancesNv	Nc = 49			Nv	Nc = 100			Nv	Nc = 400			CPX	ORT	RL		CPX	ORT	RL		CPX	ORT	RL2	24*	26	32	2	51	57	57	10		63	55	(7.9)	(2.1)	(3.0)		(∞)	(32.2)	(15.9)		-	(1619.8)	(361.2)4	13	18	23	4	54	31	26	20		41	43	(∞)	(1.1)	(3.2)		(∞)	(16.9)	(10.7)		-	(782.8)	(415.9)6	13	13	12	6	46	25	24	30		44	28	(∞)	(1.1)	(3.3)		(∞)	(15.4)	(10.5)		-	(1192.1)	(452.3)8	7*	9	8	8	51	19	19	40		39	24	(6467.3)	(1.6)	(3.4)		(∞)	(13.8)	(10.8)		-	(627.0)	(485.1)A.3 Experiment Results on Benchmark ProblemsWe apply the trained network to solve benchmark problems for TSP, mTSP and CVRP.
Table 8: Performance comparison on TSP libraryCity	Opt.	RL					Approx.			Ours	Drori etal.(2020)	GPN	S2V-DQN	Farthest	2-opt	Nearesteil51	426	471	439	485	439	448	452	514berlin52	7542	8269	7681	8795	7734	8121	7778	8981st70	675	770	684	701	685	729	701	806eil76	538	648	555	591	558	583	597	712pr76	108159	135145	112699	118032	111141	119649	125276	153462rat99	1211	1368	1268	1472	1250	1319	1351	1565kroA100	21282	25282	21452	24806	22335	23374	23306	26856kroB100	22141	25939	22488	24369	22548	24035	23129	29155kroC100	20749	23644	21427	24780	21468	21818	22313	26327kroD100	21294	23397	21555	23494	21886	22361	22754	26950kroE100	22068	26326	22267	23467	22820	23604	25325	27587rd100	7910	9237	8243	8844	8305	8652	8832	9941eil101	629	753	650	704	667	687	694	825lin105	14379	17173	14571	15795	14895	15196	16184	20363pr124	59030	66554	59729	67901	61101	61645	61595	69299bier127	118282	125233	120672	134089	123371	127795	136058	129346ch130	6110	6987	6208	6457	6361	6655	6667	7575
Table 9: Performance comparison on mTSP libraryORT	Ours	ORT	OursMaps	Nv	MS	Time	MS	Time	gap	Maps	Nv	MS	Time	MS	Time	gap	2	223	1.14	281	2.95	26.2		2	12214	15.06	13721	9.41	12.3eil51	3	159	0.67	244	2.92	53.7	kroB100	3	8957	14.81	10197	9.52	13.8	5	120	1.48	165	2.93	37.5		5	7108	10.31	6271	9.19	-13.3	7	109	1.03	86	2.67	-26.5		7	7108	10.24	6119	9.49	-16.2	2	4634	1.27	4247	3.01	-9.1		2	11440	8.90	12453	9.39	8.9berlin52	3	3195	1.35	3452	3.03	8.0	kroC100	3	8725	12.58	7985	9.48	-9.3	5	2606	1.18	2179	3.03	-19.6		5	6616	15.66	6291	9.50	-5.2	7	2440	1.42	2182	2.87	-11.8		7	6154	12.83	5740	9.30	-7.2	2	288	4.46	361	5.81	25.4		2	13130	11.27	12815	9.32	-2.5eil76	3	212	3.26	227	5.75	7.2	kroD100	3	8889	9.36	9359	9.40	5.3	5	179	4.79	170	5.61	-5.1		5	6976	9.67	6660	9.34	-4.7	7	179	4.78	121	5.41	-47.4		7	6485	12.00	7246	9.25	11.7	2	388	3.77	451	4.87	16.2		2	13424	9.02	13611	9.53	1.4st70	3	285	2.04	282	4.98	-1.2	kroE100	3	9334	14.61	8929	10.76	-4.5	5	251	2.26	249	4.69	0.8		5	7599	20.27	6992	10.05	-8.6	7	251	2.22	253	4.78	0.9		7	8727	17.14	5868	9.42	-18.7	2	60679	4.99	80789	5.69	33.1		2	345	11.23	386	9.70	11.8
Table 10: Performance comparison on CVRP libraryInstance	Opt	OR-Tools	AM (N=1280)	AM (N=5000)	OursX-n101-k25	27591	29405	39437	37702	39133X-n106-k14	26362	27343	28320	28473	27940X-n110-k13	14971	16149	15627	15443	17388X-n115-k10	12747	13320	13917	13745	19292X-n120-k6	13332	14242	14056	13937	16589X-n125-k30	55539	58665	75681	75067	69919X-n129-k18	28940	31361	30399	30176	36649X-n134-k13	10916	13275	13795	13619	14800X-n139-k10	13590	15223	14293	14215	16368X-n143-k7	15700	17470	17414	17397	23548X-n148-k46	43448	46836	79611	79514	62240X-n153-k22	21220	22919	38423	37938	33079X-n157-k13	16876	17309	21702	21330	19702X-n162-k11	14138	15030	15108	15085	19491X-n167-k10	20557	22477	22365	22285	25676X-n172-k51	45607	50505	86186	87809	63191X-n176-k26	47812	52111	58107	58178	66997X-n181-k23	25569	26321	27828	27520	27220
Table 11: HyperparametersParameters (for PPO update)	Value	Parameters (for GRLTS)	ValueOptimizer	Adam	MLP units	(32, 32)betas (β1, β2)	(0.9, 0.999)	Neuron initialization	Kaiming normalLearning rate (ηpolicy)	2 × 10-4	Activation fn.	ReLULearning rate (ηQ-network)	2 × 10-4	Node umbedding epoch (Nhop)	5gamma (γ)	0.99	Node feature dim.	5clip ratio ()	0.2	Edge feature dim.	10value function coeffi.	0.5	Max. decision epoch	3 × Ncentropy coeffi.	0.01		PPO update epoch (K)	10		Training epoch	1		18Under review as a conference paper at ICLR 2021A.6 Training performanceFigure (6) shows how the trained policy perform on the thee set of validation problems while thepolicy is being trained by the random mCVRP inc stances. The three validation problems are 1) 100customers covered by 5 vehicles, 2) 100 customers by 10 vehicles and 3) 400 customers covered by20 vehicles. The first row show the performance on the random training instances while the second,third, and fourth row show the performances on the three validation problems.
