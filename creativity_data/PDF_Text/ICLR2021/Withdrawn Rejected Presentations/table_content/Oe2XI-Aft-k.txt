Table 1: Studying the empirical overlap of 'p attack perturbations in different 'q % regions for(a) MNIST (1,2,∞) = (10, 2.0, 0.3); (b) CIFAR-10 (1,2,∞) = (12, 0.5, 0.03). Each columnrepresents the range (min - max) of 'q norm for perturbations generated using 'p PGD attack.
Table 2: Worst-case accuracies against different `p attacks: (a) MNIST; (b) CIFAR-10. Ours representsPROTECTOR against the adaptive attack strategy (Section 5.2), and Ours* is the standard setting.
Table 3: Effect of different design choices on the CIFAR-10 dataset against PGD-based attacks.
Table 4: The table shows the range of the values that the mean can take depending on the decisiontaken by the adversary. μadv and μMv represent the new mean of the distribution of features xo andxM after the adversarial perturbation.
Table 5: Vanilla Model: Empirical overlap of 'p attack perturbations in different 'q % regions for(a) MNIST (1,2,∞) = (10, 2.0, 0.3); (b) CIFAR-10 (1,2,∞) = (12, 0.5, 0.03). Each columnrepresents the range (min - max) of 'q norm for perturbations generated using 'p PGD attack.
Table 6: Protector： Empirical overlap of 'p attack perturbations in different 'q Wq regions for(a) MNIST (1,2,∞) = (10, 2.0, 0.3); (b) CIFAR-10 (1,2,∞) = (12, 0.5, 0.03). Each columnrepresents the range (min - max) of 'q norm for perturbations generated using 'p PGD attack.
Table 7: Perturbation type classification accuracy for different perturbation types. Note that the pertur-bation classifier Cadv is only trained on adversarial examples against two Mp models. Each columnrepresent the model used to create transfer-based attack via the attack type in the corresponding row.
Table 8: Attack-wise breakdown of adversarial robustness on the MNIST dataset. Ours representsthe PROTECTOR method against the adaptive attack strategy described in Section 5.2, and Ours*represents the standard attack setting.
Table 9: Attack-wise breakdown of adversarial robustness on the CIFAR-10 dataset. Ours representsthe PROTECTOR method against the adaptive attack strategy described in Section 5.2, and Ours*represents the standard attack setting.
Table 10: Comparison between using a ‘softmax’ based aggregation of predictions from differentspecialized models versus using the prediction from the model corresponding to the most likely attack(only at inference time). Results are presented for APGD '2, '∞ attacks on the CIFAR10 dataset.
