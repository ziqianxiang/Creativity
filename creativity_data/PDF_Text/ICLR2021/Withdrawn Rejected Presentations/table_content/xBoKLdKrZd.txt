Table 1: Supernet training hyper-parametersoptimizer	SGD	initial LR	0.05momentum	0.9	LR schedule	RedUceLROnPIateaUtweight decay	0.0005	LR decay	0.5batch size	512	LR patience	30dropout rate	0.1	grad norm clip	5.0Figure 2: Dynamics of different criteria during the supernet training process.
Table 2: Average standard deviation of accuracies and rankings in architecture isomorphic groups.
Table 3: Comparison of (no) de-isomorphism sampling in supernet training. “BR@1” indicates therelative ground-truth ranking of the architecture with the highest one-shot scoreEpochs	criterion	200	400	600	800	1000	BR@1	3.372%	4.493%	21.555%	13.139%	11.379%	BR@1%	0.012%	0.019%	2.854%	2.739%	2.515%No De-isomorphism	BR@5%	0.006%	0.013%	2.336%	2.310%	2.221%	P@5%	39.69%	12.03%	6.53%	7.68%	9.22%	P@50%	79.27%	81.59%	88.04%	89.20%	89.72%	τ	0.6033	0.6500	0.6951	0.7032	0.7127	BR@1	1.840%	2.737%	5.212%	5.707%	2.273%	BR@1%	0.046%	0.031%	0.062%	0.139%	0.015%De-isomorphism	BR@5%	0.015%	0.015%	0.045%	0.090%	0.015%	P@5%	41.48%	39.31%	30.65%	28.48%	28.48%	P@50%	73.03%	83.76%	87.44%	86.39%	86.45%	τ	0.4967	0.6735	0.7087	0.6989	0.7005	BR@1	3.866%	4.964%	20.260%	12.465%	10.950%	BR@1%	0.015%	0.015%	0.479%	0.634%	0.247%Post De-isomorphism	BR@5%	0.015%	0.015%	0.340%	0.217%	0.093%	P@5%	46.13%	37.77%	23.52%	21.36%	24.77%	P@50%	76.89%	83.14%	87.44%	87.44%	87.81%
Table 4: Comparison of using different numbers of architecture Monte-Carlo samples in every super-net training step. Upper: The training epochs of models with 1/3/5 MC samples and Fair-NAS are1000/333/200/200. Lower: The training epochs of models with 1/3/5 MC samples and Fair-NASare all 1000. All these results are tested with post de-isomorphismEquivalent 1000 epochs	1	3	5	Fair-NAS (Chu et al., 2019)BR@5%	0.093%	0.139%	0.495%	0.139%P@5%	24.77%	9.60%	20.74%	11.76%τ	0.7226	0.7128	0.6714	0.71371000 epochs	~~	3	5	Fair-NAS (Chu et al., 2019)BR@5%	0.093%	0.015%	0.124%	0.031%P@5%	24.77%	14.24%	17.03%	15.17%rτ	0.7226	0.7025	0.7018	0.6965layer proxy reduces the reliability of search results. Thus, for cell-based search spaces, proxy-lesssearch w.r.t the layer number is worth studying.
Table A1: The Kendall’s Tau of different predictors on 3 different randomly sampled training datasetof Size 78____________________________________________________________________________________________Training Loss	Ranking			Regression		Dataset	1	2	3	1	2	3MLP	0.1330±0.074	0.1560±0.0078	0.2481 ±0.0069	0.0111±0.0000	0.0548±0.0276	0.0467±0.0130LSTM	0.5631±0.0060	0.6028±0.0457	0.5487±0.0150	0.6024±0.0039	0.5784±0.0180	0.4656±0.0176GATES (Ning et al., 2020)	0.7597±0.0079	0.7750±0.0106	0.7645±0.0054	0.2067 ±0.0000	0.7240±0.0074	0.7135±0.0055RF (Sun et al., 2019)	-	-	-	0.4329±0.0077	0.4123±0.0104	0.4218±0.0119Table A2: The performance distribution, BR@K, Kendall’s Tau of 5 training stages. In each stage,N = 78 architectures are chosen, evaluated, and used to train the predictor along with previousarchitecture data. Note that in this table, K in BR@K is the absolute architecture number withoutnormalization________________________________________________________________________________________________		Stage	0	1	2	3	4GATES	Perf. Range	[0.560, 0.938]	[0.921, 0.944]	[0.935, 0.944]	[0.933, 0.944]	[0.933, 0.944]	Perf. Std	6.43e-2	4.59e-3	2.16e-3	2.18e-3	2.30e-3	BR@11/BR@7/BR@1	1/2/306	1/1/3	1/1/2	1/1/3	1/1/3	Kendall,s Tau	0.769	0.759	0.752	0.742	0.725		Stage	0	1	2	3	4LSTM	Perf Range	[0.560, 0.938]	[0.922, 0.944]	[0.922, 0.944]	[0.932, 0.944]	[0.934, 0.944]	Perf. Std	6.43e-2	4.52e-3	2.63e-3	2.42e-3	1.98e-3
Table A2: The performance distribution, BR@K, Kendall’s Tau of 5 training stages. In each stage,N = 78 architectures are chosen, evaluated, and used to train the predictor along with previousarchitecture data. Note that in this table, K in BR@K is the absolute architecture number withoutnormalization________________________________________________________________________________________________		Stage	0	1	2	3	4GATES	Perf. Range	[0.560, 0.938]	[0.921, 0.944]	[0.935, 0.944]	[0.933, 0.944]	[0.933, 0.944]	Perf. Std	6.43e-2	4.59e-3	2.16e-3	2.18e-3	2.30e-3	BR@11/BR@7/BR@1	1/2/306	1/1/3	1/1/2	1/1/3	1/1/3	Kendall,s Tau	0.769	0.759	0.752	0.742	0.725		Stage	0	1	2	3	4LSTM	Perf Range	[0.560, 0.938]	[0.922, 0.944]	[0.922, 0.944]	[0.932, 0.944]	[0.934, 0.944]	Perf. Std	6.43e-2	4.52e-3	2.63e-3	2.42e-3	1.98e-3	BR@11/BR@7/BR@1	99/268/393	2/2/9	1/1/6	1/2/5	1/1/3	Kendall,s Tau	0.562	0.556	0.571	0.739	0.724A.2 Over- and Under-estimation of ArchitecturesFig. A2(d)(e)(f) illustrates the relationship between the FLOPs of architectures and how it is likelyto be over-estimated. It seems that MLP and RF are more likely to overestimate the smaller archi-tectures and underestimate the larger ones, while LSTM and GATES show no obvious preference onthe architectures’ FLOPs. Fig. A2(a)(b)(c) shows that GATES can give more accurate rankings onsmaller architectures than larger architectures, which indicates that GATES might still have trouble
