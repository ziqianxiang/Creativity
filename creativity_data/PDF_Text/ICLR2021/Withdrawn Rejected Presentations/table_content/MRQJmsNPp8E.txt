Table 1: Comparison with unsupervised representation methods. Note on f: for the fair comparison,we did not used the average gradient trick that was utilized in BYOL (Grill et al., 2020).
Table 2: Linear classifier top-1 accuracy comparison with unsupervised representation methods onImageNet. Methods are arranged in chronological order. Note on f: BYOL (Grill et al., 2020) doesnot report the result on ImageNet with the identical experimental setup. Therefore, we adopted theresults of BYOL from Zhan et al. (2020), the most widely used open-source library for self-supervisedlearning, experimented without an average gradient technique for a fair comparison.
Table 3: Comparison with end-to-end unsupervised representation methods in the clustering bench-mark. The results of previous methods are taken from Huang et al. (2020). We append full comparisonresults in Appendix (Table 11).
Table 4: Performance improvements due to each of our components. m1, m2, and m3 indicate thelinear evaluation protocol (LP), kNN(k=5), and kNN(k=200), respectively. K denotes a set of clustersizes: k1 = {32}, k2 = {128}, k3 = {32, 32, 32}, k4 = {128, 128, 128}, and k5 = {32, 64, 128}.
Table 5: Hyperparameters of backbone models used in the experiment of Section 4.1HyperparameterEpochOptimizerLearning rateWeight decayWeight momentumBatch sizeArchitectureValue300LARS (You et al., 2017)Constant({0.1, 0.2, 0.3, 0.4, 0.5})1e-60.9256linear without batch-norm layerTable 6: Hyperparameters of the linear evaluation protocol used in the experiment of Section 4.113Under review as a conference paper at ICLR 2021
Table 6: Hyperparameters of the linear evaluation protocol used in the experiment of Section 4.113Under review as a conference paper at ICLR 2021A.2 Implementation Details for the Large-Scale SettingHyperparameter	ValueEpoch	^2G0Optimizer	SGDLearning rate	0.03Learning rate schedule	multiplying 0.1 at 120, 160 epoch.
Table 7: Hyperparameters of backbone models used in the experiment of Section 4.2HyperparameterEpochOptimizerLearning rateLearning rate scheduleWeight decayWeight momentumBatch sizeArchitectureValue200SGD30.0multiplying 0.1 at at 60 and 80 epoch1e-60.9256linear without batch-norm layerTable 8: Hyperparameters of the linear evaluation protocol used in the experiment of Section 4.2
Table 8: Hyperparameters of the linear evaluation protocol used in the experiment of Section 4.214Under review as a conference paper at ICLR 2021A.3 IMPACT STUDY FOR CHOICE OF KAlthough the effectiveness of the multi-scale clustering technique is briefly described in Section 4.5,this section studies performance changes according to the choice of the set K.
Table 9: An impact study about the choice of K on the STL-10 dataset. LP indicates an linearevaluation protocol described in Section 4.1.
Table 10: Hyperparameters used in unsupervised clustering experiments of Section 4.3B.2 Clustering quality comparisonFwk Methodpuwlo'puwNMI/ACC/ARICIFAR-10	CIFAR-100	STL-10K-means	0.09 / 0.23 / 0.05	0.08 / 0.13 / 0.03	0.13 / 0.19 / 0.06SC (Zelnik-Manor et al., 2005)	0.10 / 0.25 / 0.09	0.09 / 0.14 / 0.02	0.10 / 0.16 / 0.05AC (Gowda & Krishna, 1978)	0.11 / 0.23 / 0.07	0.10 / 0.14 / 0.03	0.24 / 0.33 / 0.14NMF (Cai et al., 2009)	0.08 / 0.19 / 0.03	0.08 / 0.12 / 0.03	0.10 / 0.18 / 0.05AE (Bengio et al., 2007)	0.24 / 0.31 / 0.17	0.10 / 0.17 / 0.05	0.25 / 0.30 / 0.16DAE (Vincent et al., 2010)	0.25 / 0.30 / 0.16	0.11 / 0.15 / 0.05	0.22 / 0.30 / 0.15DCGAN (Radford et al., 2016)	0.27 / 0.32 / 0.18	0.12 / 0.15 / 0.05	0.21 / 0.30 / 0.14DeCNN (Zeiler et al., 2010)	0.24 / 0.28 / 0.17	0.09 / 0.13 / 0.04	0.23 / 0.30 / 0.16VAE (Kingma & Welling, 2013)	0.25 / 0.29 / 0.17	0.11 / 0.15 / 0.04	0.20 / 0.28 / 0.15JULE (Yang et al., 2016)	0.19 / 0.27 / 0.14	0.10 / 0.14 / 0.03	0.18 / 0.28 / 0.16DEC (Xie et al., 2016)	0.26 / 0.30 / 0.16	0.14 / 0.19 / 0.05	0.28 / 0.36 / 0.19DAC (Chang et al., 2017)	0.40 / 0.52 / 0.30	0.19 / 0.24 / 0.09	0.37 / 0.47 / 0.26ADC (Haeusser et al., 2018)	-/0.33 /-	-/0.16/-	- / 0.53 / -DDC (Chang et al., 2019)	0.42 / 0.52 / 0.33	-/-/-	0.37 / 0.49 / 0.27
Table 11: Full comparison with unsupervised representation models for clustering benchmark datasets.
