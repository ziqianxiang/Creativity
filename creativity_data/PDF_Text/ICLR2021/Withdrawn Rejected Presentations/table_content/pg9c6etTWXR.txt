Table 1: Average confidences (MMCs in percent) over ten prediction runs. Lower is better for OODdata while higher is better for in-distribution data. See Table 2 for the AUR values.
Table 2: OOD detection performance measured by the AUR metric. Values reported are averagesover ten prediction runs. Higher is better. Underline and bold faces indicate the highest values overthe last four columns and all columns in a given row, respectively.
Table 3: Robustness to dataset shifts on the corrupted CIFAR-10 dataset (Hendrycks & Dietterich,2019), following Ovadia et al. (2019). All values are averages and standard deviations over allperturbation types and intensities (for total of 95 dataset shifts). For accuracy, higher is better, whilefor ECE and NLL, lower is better.
Table 4: Predictive performances on UCI regression datasets in term of average test log-likelihood.
Table 5: UQ performances on UCI datasets. Values are the average (over all data points and tentrials) predictive standard deviations. Lower is better for test data and vice-versa for outliers. Bydefinition, MAP does not have (epistemic) uncertainty.
Table 6: In- and out-distribution validation MMCs for varying numbers of additional LULA units.
Table 7: Accuracies (in percent) over image classification test sets. Values are averages over tentrials.
Table 8: LULA compared to DPN on OOD detection in terms of MMC and AUR, both in percent.
Table 9: Wall-clock time of adding and training LULA units. All values are in seconds.
Table 10: Average confidences (MMCs in percent) on 20-layer CNNs over ten prediction runs.
Table 11: OOD detection performance measured by the AUR metric on 20-layer CNNs. Valuesreported are averages over ten prediction runs. Higher is better. Underline and bold faces indicatethe highest values over the last four columns and all columns in a given row, respectively.
Table 12: Average confidences (MMCs in percent) on DenseNet-121 over ten prediction runs. Loweris better for OOD data. Values shown for each in-distribution dataset are ECE—lower is better.
Table 13: OOD detection performance measured by the AUR metric on DenseNet-121. Valuesreported are averages over ten prediction runs. Higher is better. Underline and bold faces indicatethe highest values over the last four columns and all columns in a given row, respectively.
Table 14: LULA’s OOD detection performance on DenseNet-121 with uniform noises as the train-ing OOD data. Values are the ECE, MMC, and AUR metrics, averaged over ten prediction runs.
