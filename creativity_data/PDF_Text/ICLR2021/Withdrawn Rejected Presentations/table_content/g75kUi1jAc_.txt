Table 1: Local Test Performance for Z = 2Dataset	Method	# of parameters J	Unimodal ↑	Multimodal ↑	FedAvg	155,800	94.46±0.84	91.57±1.42MNIST	FedProx	155,800	94.44±1.15	91.53±1.05	q-FFL	155,800	91.46±1.07	88.42±1.24	WAFFLe	120,200	96.23±0.31	95.41±0.36	FedAvg	28,880	83.96±0.91	83.43±2.27FMNIST	FedProx	28,800	84.19±0.99	83.59±2.30	q-FFL	28,800	83.10±0.36	85.73±0.21	WAFFLe	18,155	87.12±0.89	86.09±0.92	FedAvg	61,770	52.54±0.14	45.46±1.69CIFAR-10	FedProx	61,770	52.36±0.11	44.95±1.17	q-FFL	61,770	43.82±0.52	38.25±1.12	WAFFLe	42,780	71.30±0.92	66.35±0.726Under review as a conference paper at ICLR 2021Table 2: Sub-population Local Test Performance AnalysisDataset	Method	Majority ↑	Minority ↑	Gap ]	Variance ]	FedAvg	96.63±0.70	67.40±11.26	29.23±11.79	199±106MNIST	FedProx	96.43±0.67	68.60±9.44	27.83±10.03	186±92
Table 2: Sub-population Local Test Performance AnalysisDataset	Method	Majority ↑	Minority ↑	Gap ]	Variance ]	FedAvg	96.63±0.70	67.40±11.26	29.23±11.79	199±106MNIST	FedProx	96.43±0.67	68.60±9.44	27.83±10.03	186±92	q-FFL	94.93 ±0.31	54.20±7.37	40.73±7.55	355±117	WAFFLe	95.93±0.16	93.87±0.66	2.07±0.77	26±6	FedAvg	89.75±1.76	68.05±4.43	21.70±4.21	231±35FMNIST	FedProx	89.95±1.73	67.50±4.50	22.45±4.38	233±42	q-FFL	88.73±0.17	69.40±1.48	19.33±1.43	212±19	WAFFLe	88.91±2.07	79.67±1.52	9.25±0.61	145±27	FedAvg	51.98±1.69	16.83 ±4.42	35.15±4.12	338±59CIFAR-10	FedProx q-FFL	51.26±1.44 42.00±0.29	16.56±3.32 18.14±3.05	32.70±6.99 23.87±3.00	318±36 220±17	WAFFLe	68.37±1.01	55.00±6.00	13.37±2.61	182±27(a)	(b)	(c)Figure 2: FedAvg and WAFFLe performance distribution across clients in the multimodal non-i.i.d. setting for (a) MNIST, (b) FMNIST and (c) CIFAR-10.
Table 3: Membership Inference AttacksMethods	Accuracy	F1-scoreFedAvg	83.85± 1.62	83.72 ± 2.19WAFFLe	56.20 ± 1.40	54.39 ± 1.85surmise the content of a client’s private data from the model. We compare a LeNet (LeCun et al.,1998) FedAvg (McMahan et al., 2017) model with an analogous WAFFLe model, training both on1000 CIFAR-10 samples per client. We attack both with a MIA inspired by Shokri et al. (2017), usinga small ensemble of 3 “shadow” models. As shown in Table 3, this simple attack achieves a highsuccess rate at identifying a FedAvg client’s training data, as intercepting the training update givesthe full model. On the other hand, WAFFLe’s training update only send partial model information, asthe identity of the active factors is kept private. As a result, MIA success rate on WAFFLe is onlymoderately higher than random chance (50%). This means it is significantly harder to identify theprivate training data for WAFFLe, relative to FedAvg.
Table 4: Unimodal Local Test Accuracy vsLocal EpochsDataset	Method	E=10	E=20	E=30MNIST	FedAvg	92.95	93.36	93.55	WAFFLe	95.10	96.32	96.43FMNIST	FedAvg	85.32	85.13	85.14	WAFFLe	87.52	87.07	89.25CIFAR-10	FedAvg	47.40	47.60	55.39	WAFFLe	64.18	71.92	74.50Table 5: Multimodal Local Test Accuracy vsLocal EpochsDataset	Method	E=10	E=20	E=30MNIST	FedAvg	88.70	89.27	89.03	WAFFLe	95.37	94.87	95.07FMNIST	FedAvg	86.21	86.58	86.47	WAFFLe	87.03	89.15	91.33CIFAR-10	FedAvg	40.91	42.09	42.00	WAFFLe	58.79	57.00	62.61Table 6: Unimodal Local Test Accuracy vs αand F
Table 5: Multimodal Local Test Accuracy vsLocal EpochsDataset	Method	E=10	E=20	E=30MNIST	FedAvg	88.70	89.27	89.03	WAFFLe	95.37	94.87	95.07FMNIST	FedAvg	86.21	86.58	86.47	WAFFLe	87.03	89.15	91.33CIFAR-10	FedAvg	40.91	42.09	42.00	WAFFLe	58.79	57.00	62.61Table 6: Unimodal Local Test Accuracy vs αand FI F=80		F =100	F =150a/F = 0.4	93.20	94.07	94.42a/F = 0.6	95.08	94.48	95.56a/F = 0.8	95.56	95.15	96.08a/F = 1.0	96.33	95.63	96.45Table 7: Multimodal Local Test Accuracy vsα and F	F=80	F =100	F =150	 a/F = 0.4	91.83	92.70	93.23
Table 6: Unimodal Local Test Accuracy vs αand FI F=80		F =100	F =150a/F = 0.4	93.20	94.07	94.42a/F = 0.6	95.08	94.48	95.56a/F = 0.8	95.56	95.15	96.08a/F = 1.0	96.33	95.63	96.45Table 7: Multimodal Local Test Accuracy vsα and F	F=80	F =100	F =150	 a/F = 0.4	91.83	92.70	93.23a/F = 0.6	94.23	94.48	95.26a/F = 0.8	94.76	95.15	95.70a/F = 1.0	94.70	94.93	95.93during the aggregation step. We study the influence of local epochs E for unimodal non-i.i.d. inTable 4 and for multimodal non-i.i.d. in Table 5, using the same settings as in Section 4.1 exceptfor reducing the global training epochs T to 50 and the learning rate η to 0.02 for all methods inmultimodal non-i.i.d scenario. We observe that WAFFLe can handle increased number of localepochs, improving performance for all three datasets.
Table 7: Multimodal Local Test Accuracy vsα and F	F=80	F =100	F =150	 a/F = 0.4	91.83	92.70	93.23a/F = 0.6	94.23	94.48	95.26a/F = 0.8	94.76	95.15	95.70a/F = 1.0	94.70	94.93	95.93during the aggregation step. We study the influence of local epochs E for unimodal non-i.i.d. inTable 4 and for multimodal non-i.i.d. in Table 5, using the same settings as in Section 4.1 exceptfor reducing the global training epochs T to 50 and the learning rate η to 0.02 for all methods inmultimodal non-i.i.d scenario. We observe that WAFFLe can handle increased number of localepochs, improving performance for all three datasets.
