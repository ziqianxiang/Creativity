Table 1: Comparison of various image and video datasets. While we have neither the mostimages nor the most videos, we provide good diversity between videos which is crucial for learninga strong, generic image representation.
Table 2: Comparison of representation performance across a variety of end tasks. We showimprovements over MoCo trained on the same data on all tasks, and outperform MoCo trainedon ImageNet as well as supervised pretraining on ImageNet on all tasks but ImageNet itself (andtracking for ResNet50). Each representation uses the same ResNet convolutional backbone, sharingweights across all tasks. Linear (for Kinetics LSTM â†’ Linear) classifiers are the only learnedweights for each end task.
Table 3: Method ablation for VINCE. We compare using one source image with two augmenta-tions (the standard approach), two different images, or a set of different images. Using Multi-Frameresults in a large boost across the board. Multi-Frame Multi-Pair further increases the power ofthe representation. Note that all methods use the entire dataset, but only Multi-Frame methods usemultiple images from a video within one batch.
Table 4: Pretraining data ablation for VINCE. Each method uses the same training setup butdifferent training data. Since R2V2 uses ImageNet search queries, it outperforms the others onImageNet. Similarly, pretraining on Kinetics increases performance on the Kinetics task.
