Table 1: Learning hypothesis ab-lation. Results on action classifi-cation performance on HMDB-51 isshown for finetuning accuracy (Acc)and frozen action retrieval (recall@5).
Table 2: Retrieval and Few Shot Learning. Re-trieval accuracy in (%) via nearest neighbors and fewshot learning accuracy (%) via training a linear SVMon fixed representations.
Table 3: Audio classification. Down-stream task accuracies on standard audioclassification benchmarks.
Table 4: State-of-the-art on video action recognition. Self- and fully-supervisedly trained methodson UCF-101 and HMDB-51 benchmarks. We follow the standard protocol and report the averagetop-1 accuracy over the official splits for finetuning the whole network. Methods with *: use videotitles as supervision, with *: use ASR generated text. See table A.3 for an extended version includingrecent/concurrent works.
Table 5: VGG-Sound.
Table A.1: Multi-modal learning, mm.
Table A.2: Full retrieval table.
Table A.3: State-of-the-art on action recognition. Self-supervised and supervised methods onUCF101 and HMDB51 benchmarks. We follow the standard protocol and report the average top-1accuracy over the official splits and show results for finetuning the whole network. Note that we findthe supervised baseline to be around 6% and 2% better than reported in (Alwassel et al., 2020) asWe use a different finetuning strategy. Methods with * indicate the additional use of video titles assupervision. Methods with * use ASR generated text. Methods in gray are concurrent works.
