Table 1: Model robustness on different datasets (%). We also provide the Standard Deviation for Allattacks of each method on each dataset.
Table 2: Model robustness of VGG-16 on CIFAR-10 (the higher the better).
Table 3: Runtime analysis of different methods on CIFAR-10 (the lower the better).
Table 4: Model robustness of LeNet on MNIST over each individual attack (the higher the better).
Table 5: Model robustness of ResNet-20 on CIFAR-10 over each individual attack (the higher thebetter).
Table 6: Model robustness of ResNet-34 on Tiny-ImageNet over each individual attack (the higherthe better).
Table 7: Model robustness of VGG-16 on CIFAR-10 over each individual attack (the higher thebetter).
Table 8: Model robustness of WideResNet-28-10 on CIFAR-10 over each individual attack (thehigher the better).
Table 9: Robustness evaluation by AutoAttack (the higher the better). We report the clean accuracy,the robust accuracy of the individual attacks as well as the combined one of AutoAttack (denotedAA) using LeNet, ResNet-20, and ResNet-34.
Table 10: Model performance of ResNet-20 on CIFAR-10 on different PGD-k attacks (k denotesthe iteration steps).
Table 11: Gated sub-network prediction accuracy on inputs from different domains on differentdatasets (the higher the better). We demonstrate the prediction accuracy of gated sub-network ateach layer from top to bottom. The adversarial examples are generated by PGD-'ι, PGD-'2, andPGD-'∞ attacks in Appendix D.1.
Table 12: Model robustness of ResNet-20 on CIFAR-10 using different prediction approaches ofthe gated sub-network (the higher the better). We use PGD-'ι, PGD-'2, and PGD-'∞ attacks inAppendix D.1.
Table 13: Attacks outside the perturbation model of ResNet-20 on CIFAR-10 (the higher the better).
Table 14: Attacks outside the perturbation model of ResNet-20 on CIFAR-10 using different pre-diction approaches of the gated sub-network (“h” denotes the hard label and “s” denotes the softlabel).
Table 15: White-box attacks on CIFAR-10 using ResNet-20 by fooling all the GBN layers.
Table 16: Gated sub-network prediction accuracy on adversarial examples generated to fool theGBN layers. We demonstrate the prediction accuracy of gated sub-network at each layer from topto bottom.
Table 17: White-box attacks on MNIST and CIFAR-10 by manually selecting BN branches to gen-erate adversarial examples (BN0, BN1, BN2, and BN3 denotes the BN branch for clean, `1, `2, and'∞ adversarial examples in GBN, respectively).
