Table 1: The sanity check result.
Table 2: Similarity of the models learned with different initializations.
Table 4: Two tasks induced from CIFAR-10: Cifar-2 task(first table) and Cifar-5 task(second table).
Table 5: Two original labelings from CIFAR-100: 100 classes and 20 superclasses.
Table 6: CIFAR-100-induced task: C 4 (first table) with four classes and C 10 (second table) with 10classes.____________________________________________________________________________C 4 CategOry		Superclassmammals	Aquatic mammals, large carnivores, large omnivores and herbivores, small mammals, medium-sized mammals, peopleNon-mammals	Fish, Reptiles, insects, non-insect invertebrates,Man-made things	Vehicles 1, vehicles 2, Food containers, household electrical devices, household furniture, Large man-made outdoor thingsNatural things and plants	Trees, flowers, fruit and vegetables, Large natural outdoor scenesC 10 Category	SuperclassAquatic animals	Aquatic mammals, fishLarge animals	large carnivores, large omnivores and herbivoresMedium and small mammals	small mammals, medium-sized mammalsVehicles	Vehicles 1, vehicles 2.
Table 7: The sanity check resultsModel 1	Model 2	Downstream	DCCA	DCKA	TDsoft	TDhardCifar-10	Cifar-5		0.7642	0.3024	0.3344	0.2158Cifar-10	Cifar-2		0.8323	0.5330	0.6717	0.4958Cifar-5	Cifar-2	Cifar-10	0.8030	0.4530	0.5057	0.4944Cifar-10	SVHN		0.9218	0.9713	0.8528	0.8001Cifar-5	SVHN		0.9793	0.9710	0.7521	0.8049Cifar-2	SVHN		0.9163	0.9782	0.5000	0.8163D.2 Does Initialization Affect Learned Features ?In this section, we further study whether models trained from different random initializations learnsimilar representations using a variety of downstream tasks. The results are reported in Table 8.
Table 8: Similarity of the models learned With different initializations.
Table 9: The effect of data augmentation: We study random flipping (F), random cropping (C) andadding Gaussian noise (G). +/- indicates whether the data augmentation method is applied.
Table 10: The effect oflearning rate schedule.
Table 11: The difference between training with standard methods and adversarial training.
Table 12: The effect ofbatch size.
Table 13: The effect of model architectures.
Table 14: The effect of different UPstream tasksUPstream	Downstream	DCCA	DCKA	TDsoft	TDhardC 100		0.7379	0.4352	0.3028	0.3340C 20	Cifar-10	0.8221	0.5287	0.3307	0.4362C10		0.8153	0.4750	0.3242	0.4386C4		0.8016	0.4002	0.3072	0.4953C 100		0.7379	0.4352	0.2124	0.2169C 20	Cifar-5	0.8221	0.5287	0.2511	0.2807C10		0.8153	0.4750	0.2472	0.2673C4		0.8016	0.4002	0.2541	0.3179upstream tasks have higher accuracy on both the Cifar-5 and Cifar-10 downstream tasks. TDsoft,TDhard, and DCCA all show that the models trained on the C 100 task learn the most similar featuresin the table while DCKA outPuts the smallest number for models trained with C 4.
