Table 1: Match rates of clean data and adversarial examples, which were generated using PGD andDecoupled Direction and Norm (DDN) attack (Rony et al., 2019), in naturally trained models (-N)and TRADES-trained models (-T).
Table 2: Robustness comparison. For Clean and PGD, the accuracy is reported. For C&W andDDN, the average perturbation norm of adversarial examples is reported.
Table 3: Classification accuracy (%) comparison with MMC (Pang et al., 2020) for CIFAR10. Thesuperscripts un and tar denote untargeted and targeted PGD attacks, respectively, and the subscriptsof PGD denote the number of iterations for conducting such attacks. Note that â‰¤ 1 denotes therobust accuracy which is under 1%.
Table 4: Robust accuracy under the adaptive attack.
Table 5: Cosine-similarity to the predicted class center.
