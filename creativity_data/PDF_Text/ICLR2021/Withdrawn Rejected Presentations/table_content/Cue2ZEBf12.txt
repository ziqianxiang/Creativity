Table 1:	The statistical summaries for the weight parameters compared with adversarial-BNN andOurs. We include mean, variance, and KL divergence (KLD). We describe the average of KLDfor all layers in deep neural networks. Outperforming statistical results are marked in bold. Theproposed method provides non-zero mean, higher variance (see Appendix F), and lower KLD.
Table 2:	The statistical summaries between clean training without adversarial examples and adver-sarial training on WideResNet. The descriptions in this table are the same as Tab. 1.
Table 3: On the clean training, the statistical summaries for the weight parameters compared withBNN and Ours. We include mean, variance, and KL divergence (KLD). We describe the average ofKLD for all layers in deep neural networks. Outperforming statistical results are marked in bold.
