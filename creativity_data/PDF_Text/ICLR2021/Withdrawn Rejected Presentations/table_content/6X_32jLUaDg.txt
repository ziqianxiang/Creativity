Table 1: We summarize properties of five datasets (or subsets of them). *For nuScenes, We use 10Hzdata to generate pseudo-labels, but subsample them in 2Hz (12562 frames) afterwards.
Table 2: Unsupervised domain adaptation from Argoverse to KITTI. We report APBEV/ AP3D ofthe car category at IoU = 0.7 and IoU = 0.5 across different depth range, using POINTRCNN model.
Table 3: Dreaming results on unsupervised adaptation among five auto-driving datasets. Herewe report APBEV and AP3D of the Car category on range 50-80m at IoU= 0.5. On each entry (row,column), we report AP of UDA from row to column in the order of no fine-tuning / ST / Dreaming.
Table 4: UDA from KITTI (city, campus) to KITTI (road, residential). Naming is as in Table 2.
Table 5: Ablation study of UDA from Argoverse to KITTI. We report APBEV/ AP3D of the carcategory at IoU = 0.5 and IoU = 0.7 across different depth range, using POINTRCNN model.
Table 6: Unsupervised domain adaptation fromArgoverse to KITTI using PIXOR. We reportAPBEV of the car category at IoU = 0.5 and IoU= 0.7. Naming is as in Table 2.
Table 7: Dreaming results on unsupervised adaptation among five auto-driving datasets. Herewe report APBEV and AP3D of the Car category on range 0-80m at IoU= 0.5. On each entry (row,column), we report AP of UDA from row to column in the order of no re-training / ST / Dreamt. Atthe diagonal entries, we report the AP of in-domain model. Our method is marked in blue.
Table 8: Unsupervised domain adaptation among five autonomous driving datasets. Naming isas that in Table 2 of the main paper.
