Table 1: Target Domain Accuracy and mean uDA Training Time (t). DILS has a 37% faster convergence timethan FADA on average, without a major drop in adaptation accuracy. The sync-up step p for DILS is set to 4.
Table 2: Mean accuracy over all target domains in a given order, e.g., Order1=D,W,C,A for Office-Caltech.
Table 3: Mean target accuracy for four uDA methods. Our frame-work can be uSed in conjunction with variouS uDA methodS, andimproveS mean accuracy over the Labeled Source baSeline.
Table 4: Overview of the related work in unsupervised domain adaptation and the novelty of FRUDA overprior works. Check marks denote the core property of different methods. FRUDA is unique in providinga framework to scale multiple adversarial uDA algorithms using optimal collaborator selection and privacy-preserving, communication-efficient distributed training.
Table 5: OCS can improve the performance of multi-source uDA algorithms by selecting multiple collaboratorsfor each target domain.
Table 6: Domain orderings used in our experiments. Domains in bold correspond to the labeled source domain,which is introduced first in the system. All other domains have no training labels.
