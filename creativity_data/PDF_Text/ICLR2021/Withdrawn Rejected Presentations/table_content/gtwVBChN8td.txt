Table 1: ListofhyperparametersShared Env	Value	Description	Algorithm appliedLR_a	0.001	Learning rate of actor	DDPG, TD3, AD3, UAD3, UDDPGLRq	0.001	Learning rate of critic	DDPG, UDDPGLRq	0.001	Learning rate of critic1	TD3, AD3, UAD3LR_c2	0.001	Learning rate of critic2	TD3, AD3, UAD3LRI	0.001	Learning rate of weight factor	TD3, AD3, UAD3τ.a	0.01	Soft update parameter of actor	DDPG, UDDPGT-Ci	0.01	Soft update parameter of critic1	TD3, AD3, UAD3T_C2	0.01	Soft update parameter of critic2	TD3, AD3, UAD3γ	0.9	Discount horizon factor	DDPG, TD3, AD3, UAD3, UDDPGInterval	500	Eval period	DDPG, TD3, AD3, UAD3, UDDPGTest	100	Episodes per eval period	DDPG, TD3, AD3, UAD3, UDDPGVar _dr	0.9995	Exploration variance decay rate	DDPG, TD3, AD3, UAD3, UDDPGSample	200	Sample size of initial states	UAD3, UDDPGBatch	200	Size of mini-batches	DDPG, TD3, AD3Cartpole	Value	Description	Algorithm applied-Max_EPS	500	Maximal steps per episode training	DDPG, TD3, AD3Runout	1000	Maximal steps per episode eval	DDPG, TD3, AD3, UAD3, UDDPGInitial variance	10.0	Initial exploration variance	DDPG, TD3, AD3, UAD3, UDDPG
