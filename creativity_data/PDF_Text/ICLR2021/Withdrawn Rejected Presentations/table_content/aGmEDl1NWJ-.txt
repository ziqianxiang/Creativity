Table 1: Adversarial accuracy for M ◦ P (ACMoP), M (ACM), and Detection Adversarial Accuracy(DAC) for different architectures. SVHN (top), CIFAR10 (down).
Table 2:	MNIST base classifier architecture. Epochs: 5. Batch size: 28. Optimizer: Adam withlearning rate 0.01.
Table 3:	SVHN base classifier architecture. Epochs: 5. Batch size: 28. Optimizer: Adam withlearning rate 0.01.
Table 4:	ciFAR10 base classifier architecture. Epochs: 200. Batch size: 32. Optimizer: Adam withlearning rate starting at 0.1, decreasing to 0.01 and 0.001 respectively after 80 and 120 epochs.
Table 5:	Defense component architecture for MNIST.
Table 6:	Defense component architecture for SVHN.
Table 7:	Defense component architecture for CIFAR10.
Table 8: Test set accuracy and agreement (augmented and target model agree on the ground-truthlabel) between each augmented model and the target model M, noted BASE.
Table 9: Average l2 and l∞ distortions between clean and adversarial examples generated with theCWL2 attack for the target model M and the augmented models M ◦ PMNIST	SVHN	CIFAR10Model	MEAN l2	MEAN l∞	Mean l2	MEAN l∞	MEAN l2	MEAN l∞Target	0.96	0.27	~~0.32~~	0.04	0.42	0.04Stack	0.87	0.25	0.34	0.05	0.4	0.03Auto	0.94	0.35	0.29	0.04	-	-CE	0.92	0.34	0.29	0.04	0.41	0.04Luring	0.94	0.31	0.31	0.04	0.39	0.04The average l2 and l∞ distortions are reported in Table 9 and show that there is no significant dif-ference between our approach and the other approaches. This is an additional observation that ourluring loss allows to train an augmented model which causes the luring effect by predominantlytargeting different useful non-robust features rather than artificially modifying the scale of the ad-versarial distortion needed to cause misclassification.
Table 10: Rate of examples (over 1000) for which logits vary more differently between M andM ◦ P , for the Luring approach against the other approaches.
Table 11: MNIST. Kernel size for the MIM-TI and DIM-TI attacks.
Table 12: SVHN. Kernel size for the MIM-TI and DIM-TI attacks.
Table 13: CIFAR10. Kernel size for the MIM-TI and DIM-TI attacks.
Table 14: MNIST. ACMoP, ACM and DAC for different source model architectures.
Table 15:	Defense component architecture for ImageNet.
Table 16:	Test set accuracy and agreement (augmented and target model agree on the ground-truthlabel) between each augmented model and the target model M, noted BASE.
Table 17: ImageNet. ACMoP, ACM and DAC for different source model architectures.
Table 18: Test set accuracy and agreement (augmented and target model agree on the ground-truthlabel) between an augmented luring model T and a target model M. Base and Base-LUring denoterespectively a target model trained classically and the augmented model trained with the luringdefense. AdvTrain and AdvTrain-Luring denote respectively a target model trained with adversarialtraining and the augmented model trained with the luring defense.
Table 19: ACM,wb, ACM and DAC values (among FGSM, MIM, DIM, MIM-TI and DIM-TI) forthe luring approach. Base-Luring and AdvTrain-luring denote the cases where the model M istrained respectively classically and with adversarial training.
Table 20: Optimal ACMoP, ACM and DAC values (among FGSM, MIM, DIM, MIM-TI and DIM-TI) for the Trapdoor and Luring approaches.
