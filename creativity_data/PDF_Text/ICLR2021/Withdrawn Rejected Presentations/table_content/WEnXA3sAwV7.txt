Table 1: Performance comparison of self-supervised methods for Spatio-temporal representation learning onUCF101 and HMDB51 dataset (Pre-trained on RGB modality only). *The input video clips contain 64 frames.
Table 2: Comparison with state-of-the-art methods for nearest neighbor retrieval on the UCF101 dataset.
Table 3: Comparison with state-of-the-art methods for nearest neighbor retrieval task on HMDB51 dataset.
Table 4: Evaluation about different augmentation configurations of R3D-18 on UCF101 datasets. The ”Inputframes” = A + B represents that the number of original input frames is A and the buffer frames for potentialframe cropping or dropping is B. So we actually sample a consecutive A + B frames clip for training.
Table 5: Results of our model with different memory bank settings. All models are trained on K400 with thesame iterations. The representation is evaluated by training an action classifier on UCF101.
