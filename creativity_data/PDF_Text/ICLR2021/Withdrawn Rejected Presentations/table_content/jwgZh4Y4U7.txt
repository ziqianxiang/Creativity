Table 1: Results on the soccer event dataset. Dif-68»58L8<§W 382818#FinetUne examplesFigure 4: Generalization to soccer environmentswith a different court size and agent speeds. Thestandard errors are computed based on three ran-dom seeds.
Table 2: Results on generalization to scenarios with more agents and temporally warped trajectorieson the soccer event dataset. The standard error of all values are smaller than 2.5%, computed basedon three random seeds.
Table 3: Few-shot learning on the RLBenchdataset, measured by per-action (macro) accuracyand averaged of four 1-shot splits and four randomseeds per split. The ± values indicate standarderrors. On the right We shows the sampled per-formance of different models on each individual1-shot split.
Table 4: The STGCN architecture used in the paper.
Table 5: The Space-Time Region Graph architecture used in the paper.
Table 6: The Non-local Neural Networks architecture used in the paper.
Table 7: Few-shot learning on the RLBench dataset, measured by per-action (macro) accuracy andaveraged of four 1-shot splits and four random seeds per split. The ± values indicate standard errors.
Table 8: Results on the soccer event dataset for baselines with different capacities, where modelSand modelT denote the small and the tiny variant for each model. The performance is measuredby per-action (macro) accuracy, averaged over nine few-shot splits. The ± values indicate standarderrors. For each baseline we showed the best performance over three levels of capacities. Infact, performances of most of the models are not affected much by the capacity. We highlight thebest-performing variants of all baselines, and use them in all comparisons in the main text.
Table 9: Full results on generalization to scenarios with all combinations of #agents and temporallywarping on the soccer event dataset. The standard error of all values are smaller than 2.5%, computedbased on three random seeds.
