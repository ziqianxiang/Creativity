Table 1: F1-micro benchmark on node classification taskoutcome of bootstrapping? (3) How many nodes should we prune to achieve commendable perfor-mance? (4) How does the pruning work?We address the above problem by comparing the different algorithmic compositions of bootstrappingwith the current state of arts as well as the vertical comparison within the pruning algorithm. Thecode we implemented in Pytorch is available online1.
Table 2: Statistics for datasetsC Hyperparameter EvaluationSince we found that batch size of subgraphs greatly determines the actual impacts the performanceof GCNs, we explored the results trained with different batchsizes. This showcased it is importantthat we made the right choice on the batch sizes in training large graph GCNs.
Table 3: Detailed Result of Bootstrapping on various batch sizesD Visualization of subgraphs in TrainingWe take the snapshots of subgraphs before and after smart pruning and visualized them togetherwith the degree histogram as well as loss histograms in 9. We used batch size 1000 for clarity offigures and showcased the smart-pruned subgraphs at different levels of pruning ratio and trainingepochs. The figure shows that our pruning method is especially good at selecting low-loss nodesduring training and simplifying the graph structure. Also, as the training proceeds, the pruned graphbecame more sparse with most low-loss nodes exists. The performance of GCNs are the best in theratio of 0.9 and 0.7 can also be attested in the visualization since we preserved most of the detailsin the graph and cut off nodes concentrating at a ’high loss hull’. However, when the pruning ration12Under review as a conference paper at ICLR 2021continues to go lower, where we preserve less structure within the graph, the performance didn’tseem to improve anymore but drops monotonically. This can be caused by less information in thegraph, as many nodes are ignored in the training process. It is also surprising that we can maintainmore than 90% accuracy with only 30% nodes in the graph.
