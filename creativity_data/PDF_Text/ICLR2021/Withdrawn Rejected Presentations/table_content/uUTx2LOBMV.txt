Table 1: The comparison of experimental re-sults between TextTN and other benchmarks.
Table 2: The comparison betweenTextTN and other complicated modelsbased on pre-trained model.
Table 3: Ablation experiments. The comparative results between TextTN without all-function learning(TextTN w/o all-function), TextTN without word-GTNs (TextTN w/o w-GTNs), and TextTN on fourclassification datasets (CR, Subj, MPQA and MR). The accuracy is adopted as the evaluation metric.
Table 4: Statistics of all datasets. Metrics: Evaluation Metric, L: maximum sample length, N:Dataset examples, Ntrain: training examples, N testï¼š testing examples, Ndev: verification examples,| V|: vocabulary size, C: number of target categories.
Table 5: Experiments with varying input word embedding dimensions in six classification datasetsModel	MR	CR	Subj	MPQA	SST-5	SST-2TextTN (dim-300)	82.2	85.7	95.3	90.4	48.1	91.4TextTN (dim-1024)	87.4	89.7	97.1	91.5	54.8	95.3Table 6: Experiments with different dimensions of probability encoding on Subj dataset.						Dimension 2	3	4	5	6	7	8	9	10TextTN	95.3	95.0	94.5	94.2	94.6	94.4	94.7	94.6	94.4D.3 A Experiment about The Dimension of Probability EncodingIn Section 3.1, we analyze that the dimension m of probability encoding can not exceed 2. In thisexperiment, we evaluate the conclusion. As shown in Table 6, we compare the accuracy of the TextTNwith different probability encoding dimensions set from 2 to 10. In addition, reported results are theaverage of 10 runs. The results illustrate that when m = 2, the accuracy of classification is 95.3, andwhen m > 2, the accuracy has a significant decrease. In particular, the accuracy only achieves 94.2when m = 5, dropping by 1.1%. The Experimental results verify the effectiveness of m = 2.
Table 6: Experiments with different dimensions of probability encoding on Subj dataset.						Dimension 2	3	4	5	6	7	8	9	10TextTN	95.3	95.0	94.5	94.2	94.6	94.4	94.7	94.6	94.4D.3 A Experiment about The Dimension of Probability EncodingIn Section 3.1, we analyze that the dimension m of probability encoding can not exceed 2. In thisexperiment, we evaluate the conclusion. As shown in Table 6, we compare the accuracy of the TextTNwith different probability encoding dimensions set from 2 to 10. In addition, reported results are theaverage of 10 runs. The results illustrate that when m = 2, the accuracy of classification is 95.3, andwhen m > 2, the accuracy has a significant decrease. In particular, the accuracy only achieves 94.2when m = 5, dropping by 1.1%. The Experimental results verify the effectiveness of m = 2.
