Table 1: BLEU and SacreBLEU scores for English-German and English-Romanian translation onWMT test sets. The number and types of teacher models are indicated in parentheses.
Table 2: BLEU and SacreBLEU scores for Chinese-English translation on the WMT17 test set. Thenumber and types of teacher models are indicated in parentheses.
Table 3: Ablation study for SEL on the WMT16 English-Romanian translation task.
Table 4: a, b, c and d are BLEU scores of students when applying sequence-level knowledge distil-lation with different teachers. The target-side includes the teacher translation and original reference.
Table 5: BLEU scores on the validation set of WMT14 English-German translation.		Table 6: BLEU scores on the validation set of WMT14 English-German translation.	I L2R Teacher ∣	R2L Teacher	I L2R Teacher ∣	NAT TeacherL2R Student ∣	27.58	∣	27.90	L2R Student ∣	27.58	∣	26.41R2L Student ∣	27.61	|	26.82	NAT Student ∣	26.53	∣	24.83From Table 5 and 6, we can see that the L2R Transformer is indeed complementary to R2L Trans-former, hence it is reasonable for SEL to learn from 3 L2R teachers and 3 R2L teachers. However,the sufficient condition fails in table 6, suggesting that NAT may be not complementary to the L2RTransformer. We speculate that the main reason is that current NAT models still have a large perfor-mance gap with autoregressive models. In appendix A.1, we conduct complementarity experimentson another dataset where the performance gap is smaller, and the conclusion changes.
Table 7: BLEU scores of SEL on the validation set of WMT14 English-German translation.
Table 8: BLEU scores on the validation set of NIST Chinese-English translation.
Table 9: BLEU scores on the validation set of			Table 10: BLEU scores on the validation set	NIST Chinese-English translation.			of NIST Chinese-English translation.	I L2R Teacher		I R2L Teacher		L2R Teacher ∣ NAT TeacherL2R Student ∣	48.40	I 49.32	L2R Student	48.40 I 48.90R2L Student ∣	48.58	I 47.72	NAT Student	47.89 I 47.16				Teachers	I 3L2R I	6L2R I 3L2R+3NAT	I 3L2R+3R2L ∣	3L2R+3R2L+3NATBLEU	I 48.97 I	49.03 I 49.55	I 50.12 I	50.44Table 11: BLEU scores of SEL on the validation set of NIST Chinese-English translation.
Table 11: BLEU scores of SEL on the validation set of NIST Chinese-English translation.
Table 12: Left BLEU and Right BLEU on the validation set of WMT14 English-German translation.
