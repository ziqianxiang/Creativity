Table 1: The overall speedup of distributed SGD with compression on nodes via CWi over a Baseline variant without compression. Speed ismeasured by multiplying the # communication rounds (i.e., iterations T (ωW )) by the bits sent from worker i to master (Wi 7→ M) per 1iteration. We neglect M 7→ Wi communication as in practice this is often much faster (see e.g. (Mishchenko et al., 2019), for other cost/speedmodel see Appendix D.7). We do not just restrict to this scenario and . We assume binary32 representation. The relative # iterations sufficientto guarantee ε optimality is T0 (ωW ) := (ωW + 1)θ, where θ ∈ (0, 1] (see Thm 6). Note that in the big n regime the iteration boundT(ωW) is better due to θ ≈ 0 (however, this is not very practical as n is usually small), while for small n we have θ ≈ 1. For dithering,r = min{p, 2}, κThe Speedup Factorrespect to speedup.
Table 2: Four theoretical models.
Table 3: Our compression techniques can speed up the overall runtime (number of iterations T (ω)times the bits sent per iteration) of distributed SGD. We assume binary32 floating point representation,bi-directional compression using C , and the same speed of communication from worker to master(Wi 7→ M) and back (M 7→ Wi). The relative number of iterations (communications) sufficientto guarantee ε optimality is T0(ω) := (ω + 1)θ, where θ ∈ (1, 2] (see Theorem 6). Note that bign regime leads to better iteration bound T (ω) since for big n we have θ ≈ 1, while for small nWe have θ ≈ 2. For dithering, K = min{1, √d21-s}. The 2.81 × speedup for Cnat is obtained forθ = 1, and the 3.16× speedup for θ = 0. The speedup figures were calculated ford = 106, p = 2(dithering),optimal choice of s (dithering), and q = 0.1d (sparsification).
Table 4: The overall speedup of distributed SGD with compression on nodes via CWi over a Baselinevariant without compression. Speed is measured by multiplying the # communication rounds (i.e.,iterations T(ωW)) by the bits sent from worker to master (Wi 7→ M) per 1 iteration. We neglectM 7→ Wi communication as in practice this is much faster. We assume binary32 representation. Therelative # iterations sufficient to guarantee ε optimality is T0(ωW) := (ωW + 1)θ, where θ ∈ (0, 1](see Theorem 6). Note that in the big n regime the iteration bound T(ωW) is better due to θ ≈ 0(however, this is not Very practical as n is usually small), while for small n We have θ ≈ 1. Fordithering, r = min{p, 2}, K = min{1, √d21-s}. The lower bound for the Speedup Factor isobtained for θ = 1, and the upper bound for θ = 0. The Speedup Factor (TTW))32dits) figures werecalculated ford = 106, q = 0.1d, p = 2 and optimal choice of s with respect to speedup.
Table 5: Overall speedup (number of iterations T times the bits sent per iteration (Wi 7→ M + M 7→Wi) of distributed SGD. We assume binary32 floating point representation, bi-directional compressionusing the same compression C . The relative number of iterations (communications) sufficient toguarantee ε optimality is displayed in the third column, where θ ∈ (0, 1] (see Theorem 6). Notethat big n regime leads to smaller slowdown since for big n we have θ ≈ 0, while for small nwe have θ ≈ 1. For dithering, we chose P = 2 and K = min{1, √d21-s}. The speedup factorfigures were calculated ford = 106, p = 2 (dithering),optimal choice of s (dithering), and q = 0.1d(sparsification).
Table 6: Overall speedup (number of iterations T times the bits sent per iteration (Wi 7→ M) ofdistributed SGD. We assume binary32 floating point representation, bi-directional compression usingCWi , CM . The relative number of iterations (communications) sufficient to guarantee ε optimalityis displayed in the third column, where θ ∈ (0, 1] (see Theorem 6). Note that big n regime leads tosmaller slowdown since for big n we have θ ≈ 0, while for small n we have θ ≈ 1. For dithering,we choseP = 2 and K = min{1, √d21-s}. The speedup factor figures were calculated for d = 106,p = 2 (dithering),optimal choice of s (dithering), and q = 0.1d (sparsification).
