Table 1: (a) Results on Shop-VRB-Simple. LORL helps to improve Slot Attention Locatello et al.
Table 2: Quantitative results on PartNet-Chairs. All numbers are in percentage. LORL consistentlyimproves MONet’s and Slot Attention’s performance on segmentation.
Table 3: The percentage (%) of retrieved objects thatbelong to the same category as the query object. WithLORL, objects within the same category are more likelyto be close to each other in the feature space. The resultsare averaged over 3 runs.
Table 4:	Our three-stage train-ing paradigm improves visual conceptlearning. Without fine-tuning (i.e., thethird training stage), the question an-swering accuracy drops by 30%. Theresults are averaged over 3 runs.
Table 5: Hyperparameters of LORLLearning rate scheduling For Slot Attention models, during the first training stage (perception-only), we use the learning rate schedule described in the original paper on both datasets. Specifically,the initial learning rate is 4 × 10-4, and is fixed 10K iterations. After that, we decay the learningrate by 0.5 for every 100K iterations. On PartNet-Chairs, after the first stage, Slot Attention modelscontinue to use the same learning rate scheduling. For Shop-VRB-Simple, we switch to a fixedlearning rate of 0.001 during N2 phase, which takes 20 epochs. After 20 epochs, we decrease thelearning rate to 2 × 10-4. We further decrease the learning rate to 2 × 10-5 after another 65 epochs.
Table 6: All templates that we use to generate descriptive sentences on the PartNet-Chairs dataset.
Table 7: GT/Pred split ratios on Shop-VRB-Simple using different IoU thresholds. The results areaveraged over 3 runs.
Table 8: Ablation study of the objectness score module on Shop-VRB-Simple. The results areaveraged over 3 runs.
Table 9: Ablation study of using different types of questions to train LORL + SA on Shop-VRB-Simple. The results are averaged over 3 runs.
Table 10: Ablation study of using different number of questions to train LORL + SA on Shop-VRB-Simple.
Table 11: Question answering accuracy of baseline models and our model on the Shop-VRB-Simpledataset. The results are averaged over 3 runs.
Table 12: Segmentation performance of SPACE and LORL +SPACE on CLEVR. The integration ofLORL improves the result.
Table 13: Concept quantification evaluation. The number after @ indicates the IoU threshold. Theresults suggest that objectness score improves the precision of concept quantification.The results areaveraged over 3 runs.
