Table 1: Accuracy on ImageNet linear evaluation. x ⇔ y denotes standard contrastive matchingbetween views. In “InfoNCES”, we use the same base InfoMin Aug. architecture but augments theloss function with conditional MI maximization across views (x ⇔x00 y). All models use a standardResnet-50 architecture. (↑) represents improvement over InfoMin Aug.
Table 2: Results for perplexity, sequence-level metric, token-level metrics, BLEU, diversity metricsand human evaluation on the valid data of the Wizard of Wikipedia dataset (Dinan et al., 2018).
Table 3: A sample dialogue between speaker A and speaker B from the Wizard of Wikipedia dataset.
Table 4: Results for perplexity, sequence-level metric, token-level metrics, BLEU and diversitymetrics on the test data of the Wizard of Wikipedia dataset. Results demonstrate that the proposedInfoNCE and InfoNCES bounds archive lower perplexity, reduce next-token repetition and increasethe number of unique next-tokens compared to the baselines GPT2 and TransferTransfo.
Table 5: Selected responses to the same context from different methods fine-tuned on the Wizard ofWikipedia datasets.
