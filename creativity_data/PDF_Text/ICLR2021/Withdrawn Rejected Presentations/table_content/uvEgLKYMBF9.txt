Table 1:	Test ELBO on statically binarizedMNIST with MLPModel	ELBOVAE (L=2)	-86.05VAE (L=1)+NF [18]	-85.10IWAE (L=2) [2]	-85.32VampPrior (L=2) [23]	-83.19HVAE(L=4), L5000	-83.42Table 2:	Test ELBO on dynamically bina-rized MNIST with MLPModel	ELBOLadderVAE(L=5)	-81.7VampPrior (L=2) [23]	-81.24HVAE (L=4), L5000	-81.2HVAE (L=5), L5000	-81.1validation curves and the KL divergence of the topstochastic layer KL(q(z4|z3)||N(0, 1) in figure 2. The standard training collapses the posteriorimmediately while our method avoids posterior collapse and yields better validation ELBO.
Table 2:	Test ELBO on dynamically bina-rized MNIST with MLPModel	ELBOLadderVAE(L=5)	-81.7VampPrior (L=2) [23]	-81.24HVAE (L=4), L5000	-81.2HVAE (L=5), L5000	-81.1validation curves and the KL divergence of the topstochastic layer KL(q(z4|z3)||N(0, 1) in figure 2. The standard training collapses the posteriorimmediately while our method avoids posterior collapse and yields better validation ELBO.
Table 3: Posterior collapse on dynamic MNIST. The table shows top layer KL divergence andactive units (top-to-bottom) for various method on the 4 stochastic layer models. The 64-32-16-8 latent dimension models have two layers of 512, 256, 128, 64 hidden units in each stochasticlayer respectively. The 40-40-40-40 latent dimension models have two layers of 200 units perstochastic layer. ‘+KL’ indicates KL annealing. All models were trained for 1M steps with the samehyperparameters.
Table 4: Posterior collapse on static MNIST. The table shows top layer KL divergence and activeunits (top-to-bottom) for various method on the same 4 stochastic layer model with 40 units each,‘+KL’ indicates KL annealing. All models were trained for 1M steps with the same hyperparameters.
Table 5: Comparing bits per dimension, parameter effi-ciency and model depths between hierarchical methodsand other well performing methods on CIFAR-10. ‘+’indicates stochastic skip connections.
Table 6: Comparing maximum memory usage for variousmodels. We report the memory usage 4 and 6-layer modelson CIFAR-10, using 5 deterministic layers per stochasticlayer with 100 units per layer and 5 OU or IWAE samples.
