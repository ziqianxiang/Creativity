Table 1: Results on the CLUE development datasets.
Table 2: Dependency parsing results on the Chinese PTB 5.1, CoNLL-2009 Chinese, and UniversalDependency Indonesian GSD test sets. “*" indicates that the result was from our own experimentson the UD dataset based on Dozat & Manning (2016)‘S model, and “f” indicates that the officialBERT paper did not provide Indonesian BERT-base, so we used IndoBERT-base pre-trained by(Wilie et al., 2020).
Table 3: Dependency SRL results on the Figure 2: Language modeling effects vs. ParallelCoNLL-2009 Chinese benchmark.	data size on the evaluation set.
Table 4: Comparison of the training and migration costs of the PrLMs.
Table 5: Evaluation of the subword-level BPW performance for the MLM objective of TRI-RoBERTa-base on various embedding initialization configurations after the commonality training.
Table 6: Evaluation of the translation performance of our migrated language models on the WMTnewstest2020 test set with BLEU-1/2/3/4 metrics.
Table 7: Language modeling effects of the CdLM objective and TRILayer structure for the ChineseTRI-RoBERTa-base model. UAS and LAS scores are given for the CTB 5.1 test set.
Table 8: Effects of different cross-lingual transfer learning objectives. * indicates that a separatevocabulary is used.
Table 9: Performance of different cross-lingual transfer learning approaches on dependency parsingon CTB 5.1.
Table 10: Universal Dependency v2.3 parsing performance. * means that the results are evaluatedbased on our own implementation, not reported by Dozat & Manning (2016). We use the followingPrLMs not provided by the official (Devlin et al., 2019), third-party BERT-base PrLMs: DeepsetBERT-base-german, IndoBERT-base (WiIie et al., 2020), CL-TOHOKU BERT-base-japanese ⑴,and NICT BERT-base-japanese (§).
