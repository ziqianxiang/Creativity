Table 1: We provide mean and standard devations of MIG for each method and for each dataset.
Table 2:	Generator and discriminator architectures for the StyleGAN 2 models for generating theimage of resolution 128 X 128. “FC X n_mlp” denotes n_mlp dense layers; “2k X 2k Conv” denotesthe convolutional layers in the 2k resolution block. For resolution 64 X 64, the first block in thediscriminator and the last block in the generator are omitted.
Table 3:	Encoder architecture used in our experiments. f_size is 256 for 3D Shapes andMPI3D, and 512 for Cars3D and Isaac3D. For Isaac3D the convolutional block is replacedwith ResNet18 without the last classification layer.
Table 4: Training hyperparameters of the StyleGAN 2 model. Our implementation is based onhttps://github.com/rosinality/stylegan2-pytorch; we modified it to pass thenumber of filters (width) for convolutional layers and the latent dimension as hyperparameters.
Table 5: Training hyperparameters for encoders. Table 6: Training hyperparameters for WReN when solving the abstract reasoning tasks.
Table 7: The experimental results for 3D Shapes dataset with the ProGAN model.
