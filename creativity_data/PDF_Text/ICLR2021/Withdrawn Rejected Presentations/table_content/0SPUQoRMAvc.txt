Table 1: Quantitative results on KITTI 2015. The best results are in bold and the second best re-SUltS are underlined. ‘S’ and 'M' refer to self-supervision methods using stereo images and monocu-lar images, respectively. ‘Inst’ and ‘Sem’ mean methods that leverage instance or semantic segmen-tation information. ‘PN’ and ‘R50’ refer to the method that uses PackNet (Guizilini et al., 2020a)and Resnet-50 as backbone, respectively. All monocular trained methods are reported without post-processing steps. The metrics marked in blue mean ‘lower is better’, while these in red refer to‘higher is better’. Our method outperforms the state-of-the-arts in most metrics by a large margin.
Table 2: Ablation experiments. Results of several versions of our proposed method on KITTI 2015(Geiger et al., 2012) are reported. The best results are in bold and the second best are underlined.
Table 3: Performance of models trained on different semantic datasets. The binary segmentationIoU (mIoUBi) differs a little across different datasets, and our model achieves comparable resultswhen trained on cross-domain generated semantic labels.
Table 4: Network architectures. "in_chns" and "out_chns" denote the number of input and outputchannels. “resolution” refers to the downscaling factor with regard to the input image. “input”stands for the input of each layer, where "f" means NN-based upsampling. In the Depth Decoder,“Attn” denotes the semantic-guided attentions and “SEEM” is the proposed SEEM module.
Table 5: Ratio of the edge points that lie within range [-c, c] of the GT border.
Table 6: Quantitative results with different number of attentions. Results of several versions ofproposed semantic-guided multi-level attentions on KITTI 2015 (Geiger et al., 2012).
Table 7: Selection of foreground / background areas.
Table 8: Binary semantic segmentation accuracy. We compare the binary prediction accuracyamong our semantic branch, supervisory pseudo labels and other semantic segmentation methods.
Table 9: Quantitative comparison between different semantic segmentation branches. “Fullsemantic label” refers to the semantic branch supervised by full category labels (19 categories),while “Binary semantic label” represents the model trained by the binary semantic label.
Table 10: Quantitative results on KITTI improved ground truth. “S” and “M” refer to self-supervision methods trained using stereo images and monocular images, respectively. Results arepresented without any post-processing. The metrics marked in blue mean “lower is better”, whilethese in red refer to “higher is better”. Our method still produce comparable or better results com-pared to the state-of-the-art methods.
