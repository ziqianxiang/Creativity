Table 1: Few-shot classification accuracy (%) on the CIFAR-FS dataset with the most effectivedata augmentations for each mode shown. Confidence intervals have radius equal to one standarderror. “CNN-4” denotes a 4-layer convolutional network with 96, 192, 384, and 512 filters in eachlayer (Bertinetto et al., 2018). Best performance in each category is bolded. Query CutMix isconsistently the most effective single augmentation for meta-learning.
Table 2: Few-shot classification accuracy (%) on the CIFAR-FS dataset with combinations of aug-mentations and query CutMix. “S”,“Q”,“T” denote “Support”, “Query”, and “Task” modes, respec-tively. While adding augmentations can help, it can also hurt, so additional augmentations must bechosen carefully.
Table 3: Few-shot classification accuracy (%) on the CIFAR-FS dataset for Meta-MaxUp over dif-ferent sizes of augmentation pools and numbers of samples. As m and the pool size increase, sodoes performance. Meta-MaxUp is able to pick effective augmentations from a large pool.
Table 4: Few-shot classification accuracy (%) on CIFAR-FS and mini-ImageNet. “+ DA” denotestraining with CutMix (Q) + Rotation (T), and “+ MM” denotes training with Meta-MaxUp. “64-64-64-64” denotes the 4-layer CNN backbone from Snell et al. (2017).
Table 5: Few-shot classification accuracy (%) on CIFAR-FS and mini-ImageNet with ResNet-12backbone. “M-SVM” denotes MetaOptNet with the SVM head. “+ens” denotes testing with ensem-ble methods as in Liu et al. (2020). “LargeRot” denotes task-level augmentation by Large Rotationsas described in Liu et al. (2020).
Table 6: Few-shot classification accuracy (%) on the CIFAR-FS dataset for all data augmentations.
