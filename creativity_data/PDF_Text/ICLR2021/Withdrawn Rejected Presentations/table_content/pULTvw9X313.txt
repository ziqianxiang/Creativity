Table 1: Qualitative comparison against state-of-the-art multi-view shape generation methods. Wereport F-score on each semantic category along with the mean over all categories using two thresholdsτ and 2τ for nearest neighbor match where τ =10-4 m2.
Table 2: Comparisons of different contrastive depth formulations. In 1st and 2nd rows, concate-nation and difference of the rendered and predicted depths are fed to VGG feature extractor whilein 3rd and 4th rows, concatenation and difference of the VGG features from the depths is used formesh refinement. 5 uses VGG features from predicted depths only while 6 uses VGG features fromrendered depths only.
Table 3: Comparison of shape generation accuracy with different settings of additional con-trastive depth losses, multi-view feature pooling. The Baseline framework uses multi-head attentionmechanism without any contrastive depth losses.
Table 5: Accuracy w.r.t the number of viewsduring testing. The same model trained with 3views was used in all of the cases.
Table 4: Accuracy w.r.t the number of viewsduring training. The evaluation was performedon the same number of views as training.
Table 6: Qualitative comparison against state-of-the-art multi-view shape generation methods.
Table 7: Accuracy of predicted voxel grids fromsingle-view prediction compared against the pro-posed probabilistically merged multi-view voxelgrids. The voxel branch was trained separatelywithout the mesh refinement and evaluation wasperformed on the cubified voxel grids. We usethree views for probabilistic grid merging.
Table 8: Accuracy of the refined meshes at dif-ferent GCN stages. 1, 2 and 3 indicate the per-formance at the corresponding graph convolutionblocks while Cubified is for the cubified voxel gridsused as input for the first GCN block. All thestages, including the voxel prediction, were trainedjointly and hence the accuracy of voxel predictionsvaries from that in Table 7.
Table 9: Accuracy w.r.t the number of depth hypothesis. A higher number of depth hypothesisincreases the resolution of predicted depth values at the expense of higher memory requirement.
Table 10: Accuracy when a category is excluded during training and evaluation is performed onthe category to verify how well training on other categories generalizes to the excluded category.
