Table 1: Overall performance over unitary modality few-shot learning methods	I	mini-ImageNet	∣	tiered-ImageNetMethods	I	1-shot	I	5-shot	∣	1-shot	I	5-shotPrototypical Network Snell et al. (2017)	49.42% +- 0.78%	68.20% +- 0.66%	53.31%+- 0.89%	72.69% +- 0.74%Relation Network Sung et al. (2018)	50.40% +- 0.80%	65.30% +- 0.70%	55.00% +- 1.00%	69.30% +- 0.80%MAML Finn et al. (2017)	48.70% +- 1.84%	63.10% +- 0.92%	58.90% +- 1.90%	71.50% +- 1.00%REPTILE Nichol et al. (2018)	49.97% +- 0.32%	65.99% +- 0.58%	62.95% +- 0.03%	71.03%+- 0.22%TADAM Oreshkin et al. (2018)	58.50% +- 0.30%	76.70% +- 0.30%	62.13%+- 0.31%	81.92% +- 0.30%MetaOptNet Lee et al. (2019)	62.64% +- 0.61%	78.63% +- 0.46%	65.99% +- 0.72%	81.56% +- 0.53%SNAIL Mishra et al. (2018)	55.71%+- 0.99%	68.88% +- 0.92%	-	-LEO Rusu et al. (2019)	61.76% +- 0.08%	77.59% +- 0.12%	66.33% +- 0.05%	81.44% +- 0.09%ProtoNet (normalize)	61.93%+- 0.74%	77.90% +- 0.35%	64.06% +- 0.27%	78.03%+- 0.19%ProtoNet (normalize) + CKEM	63.29% +- 0.71%	80.12% +- 0.22%	66.69% +- 0.75%	83.04% +- 0.61%5	Experiments5.1	Experimental SetupTo verify the efficiency of cross-modality knowledge enhancement mechanism, we conduct mainexperiments with the most popular few-shot image recognition datasets: mini-ImageNet Cai et al.
