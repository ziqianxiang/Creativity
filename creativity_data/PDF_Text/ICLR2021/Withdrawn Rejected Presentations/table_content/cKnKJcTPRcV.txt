Table 1: Performance of HyperSAGE and other hypergraph learning methods on co-authorship andco-citation datasets.
Table 2: Performance of HyperSAGE for multiple values ofp in generalized means aggregator (Mp)on varying number of neighborhood samples (α).
Table 3:	Performance of HyperSAGE and its variants on nodes which							were part of the training		hypergraph (seen) and nodes which were not part of the training hypergraph (unseen).													DBLP		Pubmed		Citeseer		Cora (citation)	Method			Seen	Unseen	Seen	Unseen	Seen	Unseen	Seen Unseen	MLP + HLR			64.5	58.7	66.8	62.4	60.1	58.2	65.7	64.2HyperSAGE (p = 0.01)			78.1	73.1	81.0	80.4	69.2	67.1	68.2	65.7HyperSAGE (p = 1)			78.1	73.2	78.5	76.4	69.3	67.9	71.3	66.8HyperSAGE (p = 2)			76.1	70.2	71.2	69.8	65.9	63.8	65.9	64.5imately the same at the train-test ratio of 1/3.
Table 4: Details of real-world hypergraph datasets used in our workCo-authorship Data	Co-citation Data	DBLP	Cora	Pubmed	Citeseer	CoraNodes (|V|)	43413	2708	19717	3312	2708Hyperedges (|E|)	22535	1072	7963	1079	1579average hyperedge size	4.7±6.1	4.2±4.1	4.3 ± 5.7	3.2±2.0	3.0± 1.1number of features, |x|	1425	1433	500	3703	1433number of classes	6	7	3	6	7A.2 Implementation detailsWe use the following set of hyperparameters similar to the prior work by Kipf & Welling (2016) forall the models.
