Table 1: Classification accuracy (mean and standard deviation in parenthesis) of the three networkson the five datasets/tasks.___________________________________________________________________Dataset	Standard	Train-from-scratch		Standard	Fine-tuning MC dropout	Cosine		MC dropout	Cosine			Dog	26.7(3.4)	28.9(2.8)	36.2(1.4)	79.4(0.1)	79.3(0.3)	78.5(0.3)Plant	94.1(0.4)	94.7(0.2)	95.8(0.9)	95.2(0.6)	95.5(0.5)	92.7(2.6)Food	75.5(1.0)	76.4(0.2)	76.6(0.1)	80.5(0.0)	80.7(0.1)	79.2(0.1)Bird	24.7(0.9)	28.5(0.6)	31.3(2.4)	71.9(0.3)	72.4(0.4)	70.1(0.3)Car	18.2(3.8)	22.0(1.6)	36.0(6.2)	77.6(0.3)	77.7(0.3)	73.7(0.6)IOOIOO-5025LIXra,D S-E O-b-un'BUHuo^âŠƒ<DogPlantFoodBirdBaseline Calib. MC dropout Cosine ODIN* Maha, (sum) Maha, (adv)
Table 2: Novel class detection performance of the compared methods measured by AUROC.
Table 3: Errors of the predicted classification error by the compared methods.						Method	Food-A (From-scratch)		Food-A (Fine-tuning)		ImageNet		MAE	RMSE	MAE	RMSE	MAE	RMSEBaseline	15.8(3.0)	20.5(3.7)	6.4(1.3)	7.9(1.6)	4.6(0.8)	6.3(1.0)Calib.	15.0(2.9)	19.6(3.4)	6.3(1.3)	7.9(1.6)	4.3(0.8)	6.0(1.0)MC dropout	15.3(2.7)	19.7(3.0)	5.8(1.1)	7.2(1.4)	4.0(0.7)	5.3(0.9)Cosine	6.6(1.3)	8.2(1.6)	6.1(1.6)	7.5(2.2)	3.8(0.9)	4.7(1.1)ODIN*	14.7(1.9)	17.4(2.2)	8.9(1.3)	10.8(1.4)	9.1(0.8)	12.3(1.2)Maha. (sum)	15.3(1.5)	18.4(1.8)	15.6(1.5)	18.9(2.1)	15.1(2.2)	18.5(2.9)Maha. (adv)	14.3(1.5)	17.5(2.0)	19.1(15.8)	24.1(27.6)	16.1(1.7)	19.6(2.6)PAD	16.3(1.5)	19.2(1.9)	17.5(1.3)	20.5(1.6)	11.0(1.1)	12.9(1.2)cation accuracy. To simulate multiple types of image deterioration, we employ the method and codefor generating image corruption developed by Hendrycks & Dietterich (2019). It can generate 19types of image corruptions, each of which has five levels of severity.
Table 4: Errors of the predicted classification error by the compared methods on 50 sample subsets ofDSLR and Webcam. The CNN is trained on Amazon and the regressor f is trained using corruptedimages of Amazon.
Table 5: The OOD detection performance (AUROC) for networks trained from scratch. D1=Dog,D2=Plant, D3=Food, D4=Bird, and D5=Cat.
Table 6: The OOD detection performance (AUROC) for fine-tuned networks from a pre-trainedmodel. D1=Dog, D2=Plant, D3=Food, D4=Bird, and D5=Cat.
Table 7: Classification accuracy for the two tasks, Dog (20 dog breeds classification) and Food-A(46 food class classification), for which novel class detection is examined.
Table 8: Classification accuracy for Cat (9 cat breed classification) and Food-B (47 food class clas-sification).
Table 9: Novel class detection performance (AUROC) of the compared methods. The OOD samplesfor Cat and Food-B are the held-out 3 cat breeds and Food-A, respectively.
Table 10: Classification accuracy on ImageNet for each network.
Table 11: The classification accuracy of the three networks trained on Amazon for Amazon, DSLR,and Webcam.
Table 12: Errors of the predicted classification error by the compared methods on 30 sample subsetsof DSLR and Webcam. The CNN is trained on Amazon and the regressor f is trained using corruptedimages of Amazon.
Table 13: Errors of the predicted classification error by the compared methods on 100 sample subsetsof DSLR and Webcam. The CNN is trained on Amazon and the regressor f is trained using corruptedimages of Amazon.
Table 14: Errors of the predicted classification error by the compared methods on the entire set ofDSLR and Webcam. The CNN is trained on Amazon and the regressor f is trained using corruptedimages of Amazon.
Table 15: Irrelevant input detection performance of the ensemble models.		Method	From-scratch	Fine-TuneBaseline (con.) Ensemble (con.)	61.4(12.1) 67.8(13.7)	97.7(3.1) 98.3(2.2)Baseline (en.) Ensemble (en.)	64.8(13.7) 73.4(15.3)	99.2(0.9) 99.5(0.5)Cosine Ensemble cosine	83.9(11.4) 85.7(12.9)	99.0(0.7) 99.1(0.7)Table 16: Novel class detection performance of the ensemble models.
Table 16: Novel class detection performance of the ensemble models.
Table 17: Errors of the predicted classification error by the ensemble models.						Method	Food-A (From-scratch)		Food-A (Fine-tuning)		ImageNet		MAE	RMSE	MAE	RMSE	MAE	RMSEBaseline (con.)	15.8(3.0)	20.5(3.7)	6.4(1.3)	7.9(1.6)	4.6(0.8)	6.3(1.0)Ensemble (con.)	12.9(2.3)	17.1(2.4)	5.6(1.3)	7.0(1.8)	4.0(0.8)	5.5(1.1)Baseline (en.)	16.8(3.2)	21.6(3.6)	6.6(1.0)	8.4(1.3)	4.7(0.8)	6.7(1.1)Ensemble (en.)	14.6(2.0)	19.3(2.5)	6.0(0.9)	7.5(1.3)	3.9(0.4)	5.7(0.6)Cosine	6.6(1.3)	8.2(1.6)	6.1(1.6)	7.5(2.2)	3.8(0.9)	4.7(1.1)Ensemble cosine	7.3(1.3)	9.0(1.4)	6.4(1.6)	8.0(2.2)	4.2(1.0)	5.2(1.3)Table 18: Errors of the predicted classification error by the ensemble models on 50 sample subsetsof DSLR and Webcam._________________________________________________________________Method	Train-from-scratch		Fine-tuning		MAE	RMSE	MAE	RMSEBaseline (con.)	12.1(3.1)	14.6(3.1)	10.6(2.3)	11.7(2.3)Ensemble (con.)	10.4(2.2)	11.8(2.2)	9.0(1.1)	10.9(1.2)Baseline (en.)	11.5(2.5)	12.7(2.4)	11.4(2.9)	13.7(2.9)Ensemble (en.)	11.2(2.2)	12.6(2.1)	7.5(1.0)	8.7(1.1)Cosine	5.6(1.5)	6.8(1.7)	8.5(2.0)	10.0(2.2)Ensemble cosine	5.3(1.1	7.1(1.5)	8.6(1.6)	10.3(1.8)21
Table 18: Errors of the predicted classification error by the ensemble models on 50 sample subsetsof DSLR and Webcam._________________________________________________________________Method	Train-from-scratch		Fine-tuning		MAE	RMSE	MAE	RMSEBaseline (con.)	12.1(3.1)	14.6(3.1)	10.6(2.3)	11.7(2.3)Ensemble (con.)	10.4(2.2)	11.8(2.2)	9.0(1.1)	10.9(1.2)Baseline (en.)	11.5(2.5)	12.7(2.4)	11.4(2.9)	13.7(2.9)Ensemble (en.)	11.2(2.2)	12.6(2.1)	7.5(1.0)	8.7(1.1)Cosine	5.6(1.5)	6.8(1.7)	8.5(2.0)	10.0(2.2)Ensemble cosine	5.3(1.1	7.1(1.5)	8.6(1.6)	10.3(1.8)21Under review as a conference paper at ICLR 2021F Additional Details of Experimental SettingsF.1 Training of the NetworksAs is mentioned in the main paper, we employ Resnet-50 in all the experiments. For the optimiza-tion, we use SGD with the momentum set to 0.9 and the weight decay set to 10-4. The learning ratestarts at 0.1, and then is divided by 10 depending on the performance of the validation dataset.
Table 19: Specifications of the datasets used in the experiments.
