Table 1: Performance in terms of ELBO and predictive log-likelihood for a three-layer (two hiddenlayer) DGP, NNGP and DIWP on UCI benchmark tasks. Errors are quoted as two standard errors inthe difference between that method and the best performing method, as in a paired t-test. This is toaccount for the shared variability that arises due to the use of different test/train splits in the data (20splits for all but protein, where 5 splits are used Gal & Ghahramani, 2015) some splits are harderfor all models, and some splits are easier. Because we consider these differences, errors for the bestmeasure are implicitly included in errors for other measures, and we cannot provide a comparableerror for the best method itself._____________________________________________________metric	dataset	DGP	NNGP	DIWP	boston	-1.30 ± 0.02	-0.31 ± 0.01	-0.29	concrete	-0.68 ± 0.01	-0.40 ± 0.00	-0.35	energy	0.59 ± 0.01	1.47	1.47 ± 0.00	kin8nm	-0.50 ± 0.01	-0.40 ± 0.00	-0.33ELBO	naval	-1.42 ± 0.16	1.38 ± 0.22	1.44	power	-0.04 ± 0.00	0.00 ± 0.00	0.01	protein	-1.07	-1.11 ± 0.00	-1.09 ± 0.01	wine	-1.39 ± 0.01	-1.17 ± 0.00	-1.16	yacht	-0.19 ± 0.38	1.62 ± 0.02	1.66	boston	-3.44 ± 0.14	-2.46 ± 0.02	-2.43	concrete	-3.20 ± 0.03	-3.13 ± 0.02	-3.09
Table 2: Performance in terms of ELBO test log-likelihood and test accuracy for fully-connected three-layer (two hidden layer) DGPs, NNGP and DIWP on MNIST and CIFAR-10.				metric	dataset	DGP	NNGP	DIWPELBO	MNIST	-0.301 ± 0.001	-0.268 ± 0.001	-0.214 ± 0.001	CIFAR-10	-1.735 ± 0.002	-1.719 ± 0.001	-1.659 ± 0.001test LL	MNIST	-0.130 ± 0.001	-0.134 ± 0.002	-0.122 ± 0.001	CIFAR-10	-1.516 ± 0.002	-1.539 ± 0.002	-1.525 ± 0.003test acc.	MNIST	96.5 ± 0.1%	96.5 ± 0.0%	96.9 ± 0.0%	CIFAR-10	46.8 ± 0.1%	47.4 ± 0.1%	47.7 ± 0.2%standard methods (e.g. CNNs) for these datasets, as we are using fully-connected networks withonly 100 inducing points (whereas e.g. work in the NNGP literature uses the full 60, 000 × 60, 000covariance matrix). Nonetheless, as the architectures are carefully matched, it provides anotheropportunity to compare the performance of DIWPs, NNGPs and DGPs. Again, we found that DIWPusually gave statistically significant but perhaps underwhelming gains in predictive performance(except for CIFAR-10 test-log-likelihood, where DIWP lagged by only 0.01). Importantly, DIWPgives very large improvements in the ELBO, with gains of 0.09 against DGPs for MNIST and 0.08for CIFAR-10 (App. K). For MNIST, remember that the ELBO must be negative (because boththe log-likelihood for classification and the KL-divergence term give negative contributions), so theimprovement from -0.301 to -0.214 represents a dramatic change.
