Table 1: Bias detection experiment. Ratio ofgenerated counterfactuals classified as “Smiling”and “Non-Smiling” for a classifier biased on gen-der (fbiased) and an unbiased classifier (funbiased).
Table 2: FID of DiVE compared to xGEM [26],Progressive Exaggeration (PE) [53], xGEMtrained with our backbone (xGEM+), and DiVEtrained without the perceptual loss (DiVE--)Target Attribute ∣ xGEM PE xGEM+ DiVE-- DiVE					I	Smiling					Present	111.0	46.9	67.2	54.9	30.6Absent	112.9	56.3	77.8	62.3	33.6Overall	106.3	35.8	66.9	55.9	29.4I	Young					Present	115.2	67.6	68.3	57.2	31.8Absent	170.3	74.4	76.1	51.1	45.7Overall	117.9	53.4	59.5	47.7	33.8Experimental Setup. As common procedure [26, 9, 53], we perform experiments on the CelebAdatabase [33]. CelebA is a large-scale dataset containing more than 200K celebrity facial images.
Table 3: Average number attributes changed per explanation and percentage of non-trivial explana-tions. This experiment evaluates the counterfactuals generated by different methods for a ML modeltrained on the attribute ‘Young’ of the CelebA dataset. xGEM++ is xGEM+ using β-TCVAE asgenerator.
Table 4: Identity preserving performance on two prediction tasks.
Table 5: Human evaluation. The first column contains the percentage of non-trivial counterfactualsfrom the perspective of the human oracle. These counterfactuals confuse the ML classifier withoutchanging the main attribute being classified from the perspective of a human. The second columncontains the Pearson correlation between the human and the oracle’s predictions. The third columncontains the p-value for a t-test with the null hypothesis of the human and oracle predictions beinguncorrelated.
Table 7: Font clusters assigned to each character.
