Table 1: Illustration of the Theorems by drawing pairs from different subsets that are defined inFig. 2a. We obtain the gradients and predictions by a linear model and a MLP with two hidden layers(16 units for each) and ReLU (or tanh) activations. The gradients are computed by all parameters ofthe model. We can see that the non-linear models exhibit similar behaviors with the linear modelas described in the theorems. One exception is that the MLP with ReLU activations gets much lessnegative hgn , gm i in the case of S1 ∪ S2 for negative pairs, we consider the difference is caused byrepresentations to the final linear layer always being positive in this case due to ReLU activations.
Table 2: Demonstration of performance degrading in continual learning by compact representations.
Table 3: Average accuracy (in %), the bold font indicates the best performance on this criterion	P-MNIST	S-MNIST	Fashion	CIFAR10	CIFAR100	TinyImageNetDRL	78.7 ± 0.4	88.2 ± 0.6	78.2 ± 0.4	46.1 ± 1.2	17.1 ± 0.1	6.5 ± 0.4BER	75.8 ± 0.3	86.4 ± 0.7	76.9 ± 0.6	44.2 ± 1.1	15.3 ± 0.6	5.7 ± 0.3ER	76.1 ± 0.3	84.0 ± 0.8	75.6 ± 1.2	42.1 ± 2.0	14.5 ± 0.8	6.3 ± 0.2A-GEM	75.9 ± 1.1	85.4 ± 0.8	60.6 ± 2.5	33.1 ± 2.1	9.8 ± 0.3	1.1 ± 0.3GSS	77.1 ± 0.3	82.8 ± 1.8	72.5 ± 0.9	42.0 ± 3.0	13.9 ± 1.0	3.3 ± 0.2Multisim	78.1 ± 0.2	88.1 ± 0.6	77.6 ± 0.5	49.5 ± 0.8	16.2 ± 0.3	6.3 ± 0.6R-Margin	75.8 ± 0.4	86.0 ± 1.2	77.0 ± 0.6	46.0 ± 1.3	16.9 ± 0.5	6.0 ± 0.2Single	82.3 ± 0.2	91.2 ± 0.3	80.5 ± 0.5	78.6 ± 2.1	33.5 ± 2.3	17.8 ± 0.4Table 4: Average forgetting (in %), the bold font indicates the best performance on this criterion	P-MNIST	S-MNIST	Fashion	CIFAR10	CIFAR100	TinyImageNetDRL	6.0 ± 0.3	8.4 ± 0.9	16.7 ± 1.5	32.2 ± 5.0	20.8 ± 0.9	9.4 ± 7.7BER	7.1 ± 0.2	11.4 ± 1.0	17.4 ± 1.9	43.3 ± 2.1	20.6 ± 0.3	8.4 ± 0.3ER	8.4 ± 0.3	15.6 ± 1.5	23.5 ± 1.7	48.6 ± 3.0	36.6 ± 0.5	32.6 ± 0.6A-GEM	5.4 ± 1.1	10.7 ± 0.9	46.1 ± 3.4	34.7 ± 2.5	18.2 ± 1.1	15.8 ± 0.6GSS	7.6 ± 0.2	17.9 ± 2.4	27.4 ± 2.2	10.9 ± 3.4	18.6 ± 0.7	11.3 ± 0.7Multisim	5.9 ± 0.3	9.6 ± 0.9	18.3 ± 1.7	33.3 ± 2.1	25.9 ± 1.2	14.2 ± 0.4R-Margin	6.9 ± 0.2	9.6 ± 1.4	14.0 ± 2.0	39.6 ± 4.5	24.6 ± 1.4	17.1 ± 0.4Table 5: Average intransigence (in %), the bold font indicates the best performance on this criterion
Table 4: Average forgetting (in %), the bold font indicates the best performance on this criterion	P-MNIST	S-MNIST	Fashion	CIFAR10	CIFAR100	TinyImageNetDRL	6.0 ± 0.3	8.4 ± 0.9	16.7 ± 1.5	32.2 ± 5.0	20.8 ± 0.9	9.4 ± 7.7BER	7.1 ± 0.2	11.4 ± 1.0	17.4 ± 1.9	43.3 ± 2.1	20.6 ± 0.3	8.4 ± 0.3ER	8.4 ± 0.3	15.6 ± 1.5	23.5 ± 1.7	48.6 ± 3.0	36.6 ± 0.5	32.6 ± 0.6A-GEM	5.4 ± 1.1	10.7 ± 0.9	46.1 ± 3.4	34.7 ± 2.5	18.2 ± 1.1	15.8 ± 0.6GSS	7.6 ± 0.2	17.9 ± 2.4	27.4 ± 2.2	10.9 ± 3.4	18.6 ± 0.7	11.3 ± 0.7Multisim	5.9 ± 0.3	9.6 ± 0.9	18.3 ± 1.7	33.3 ± 2.1	25.9 ± 1.2	14.2 ± 0.4R-Margin	6.9 ± 0.2	9.6 ± 1.4	14.0 ± 2.0	39.6 ± 4.5	24.6 ± 1.4	17.1 ± 0.4Table 5: Average intransigence (in %), the bold font indicates the best performance on this criterion	P-MNIST	S-MNIST	Fashion	CIFAR10	CIFAR100	TinyImageNetDRL	2.0 ± 0.1	2.6 ± 0.3	6.9 ± 1.0	12.1 ± 4.2	13.9 ± 0.8	25.0 ± 7.5BER	4.0 ± 0.2	1.9 ± 0.2	7.7 ± 1.2	4.6 ± 1.2	15.9 ± 0.5	28.3 ± 0.5ER	2.5 ± 0.1	0.9 ± 0.2	4.1 ± 0.6	2.6 ± 0.7	2.3 ± 0.7	2.7 ± 0.4A-GEM	7.5 ± 0.5	3.1 ± 0.3	1.0 ± 0.3	22.7 ± 1.1	23.5 ± 1.0	24.1 ± 0.8GSS	7.6 ± 0.2	0.9 ± 0.3	27.4 ± 2.2	35.7 ± 2.2	20.3 ± 1.4	38.6 ± 0.1Multisim	2.6 ± 0.2	1.8 ± 0.3	6.2 ± 1.0	7.5 ± 1.1	10.3 ± 1.2	20.4 ± 0.7R-Margin	4.1 ± 0.2	3.0 ± 0.3	10.5 ± 1.7	5.9 ± 2.6	10.7 ± 1.1	17.9 ± 0.3Table 6: Correlation between model performance and ρ-spectrum on all benchmark tasksCoefficient	P-MNIST	S-MNIST	Split Fashion	CIFAR10	CIFAR100	TinyImageNet
Table 5: Average intransigence (in %), the bold font indicates the best performance on this criterion	P-MNIST	S-MNIST	Fashion	CIFAR10	CIFAR100	TinyImageNetDRL	2.0 ± 0.1	2.6 ± 0.3	6.9 ± 1.0	12.1 ± 4.2	13.9 ± 0.8	25.0 ± 7.5BER	4.0 ± 0.2	1.9 ± 0.2	7.7 ± 1.2	4.6 ± 1.2	15.9 ± 0.5	28.3 ± 0.5ER	2.5 ± 0.1	0.9 ± 0.2	4.1 ± 0.6	2.6 ± 0.7	2.3 ± 0.7	2.7 ± 0.4A-GEM	7.5 ± 0.5	3.1 ± 0.3	1.0 ± 0.3	22.7 ± 1.1	23.5 ± 1.0	24.1 ± 0.8GSS	7.6 ± 0.2	0.9 ± 0.3	27.4 ± 2.2	35.7 ± 2.2	20.3 ± 1.4	38.6 ± 0.1Multisim	2.6 ± 0.2	1.8 ± 0.3	6.2 ± 1.0	7.5 ± 1.1	10.3 ± 1.2	20.4 ± 0.7R-Margin	4.1 ± 0.2	3.0 ± 0.3	10.5 ± 1.7	5.9 ± 2.6	10.7 ± 1.1	17.9 ± 0.3Table 6: Correlation between model performance and ρ-spectrum on all benchmark tasksCoefficient	P-MNIST	S-MNIST	Split Fashion	CIFAR10	CIFAR100	TinyImageNetAvg. Acc.	-0.8379	0.0461	-0.5553	-0.7689	-0.7103	-0.1820Avg. Forg.	0.2616	-0.3879	0.4331	0.1005	0.0028	0.1868Avg. Intran.	0.4659	0.7206	-0.0978	0.2463	0.2229	-0.2377most diverse gradients are from samples that are close to class boundaries. We formally connect thediversity of gradients to discriminativeness of representations, which leads to an alternative way toreduce the diversity of gradients in continual learning. We subsequently exploit ideas from DMLfor learning more discriminative representations, and furthermore identify the shared and differentinterests between continual learning and DML. In continual learning we would prefer larger marginsbetween classes as the same as in DML. The difference is that continual learning requires less
Table 6: Correlation between model performance and ρ-spectrum on all benchmark tasksCoefficient	P-MNIST	S-MNIST	Split Fashion	CIFAR10	CIFAR100	TinyImageNetAvg. Acc.	-0.8379	0.0461	-0.5553	-0.7689	-0.7103	-0.1820Avg. Forg.	0.2616	-0.3879	0.4331	0.1005	0.0028	0.1868Avg. Intran.	0.4659	0.7206	-0.0978	0.2463	0.2229	-0.2377most diverse gradients are from samples that are close to class boundaries. We formally connect thediversity of gradients to discriminativeness of representations, which leads to an alternative way toreduce the diversity of gradients in continual learning. We subsequently exploit ideas from DMLfor learning more discriminative representations, and furthermore identify the shared and differentinterests between continual learning and DML. In continual learning we would prefer larger marginsbetween classes as the same as in DML. The difference is that continual learning requires lesscompact representations for better compatibility with future tasks. Based on these findings, weprovide a simple yet efficient approach to solving the first problem listed above. Our findings alsoshed light on the second problem: it would be better for the memorized samples to preserve as muchvariance as possible. In most of our experiments, randomly chosen samples outperform those selectedby gradient diversity (GSS) due to the limit on memory size in practice. It could be helpful to selectmemorized samples by separately considering the representativeness of inter- and intra-class samples,i.e., those representing margins and edges. We will leave this for future work.
Table 7: Comparing the performance with or without the regularization terms (Lbt, Lwi) in DRL. Allcriteria are in % except ρ-spectrum. The bold font inditactes the best performance of a criterion, asρ-spectrum is not a performance measurement so we do not put bold font on it.
Table 8: Comparing DRL with different memory replay strategies, all criteria are in %.
Table 9: Training time (in seconds) of the whole task sequence of MNIST tasks, which have beentested on a laptop with an 8-core Intel CPU and 32G RAM.
Table 10: Hyperparameters of all experiments	P-MNIST	S-MNIST	Fashion	CIFAR-10	CIFAR-100	TinyImageNettraining batch size	20	20	20	10	10	20learning rate	0.02	0.2	0.2	0.1	0.2	0.2ref batch size (A-GEM)	256	256	256	256	1500	1500α of DRL	2	2	2	0.1	0.1	0.1λ of DRL	1 × 10-2	5 × 10-4	5 × 10-4	2 × 10-4	2 × 10-5	2 × 10-5λ of Multisim	5	1	1	2	0.1	0.1λ of R-Margin	2 × 10-5	1 × 10-3	1 × 10-3	1 × 10-4	2 × 10-4	2 × 10-4Table 11: The grid search range of Hyperparameters of all experiments except TinyImageNet, as weuse the same hyperparameters of CIFAR-100 to TinyImageNet except increasing the training batchsize to 20.
Table 11: The grid search range of Hyperparameters of all experiments except TinyImageNet, as weuse the same hyperparameters of CIFAR-100 to TinyImageNet except increasing the training batchsize to 20.
