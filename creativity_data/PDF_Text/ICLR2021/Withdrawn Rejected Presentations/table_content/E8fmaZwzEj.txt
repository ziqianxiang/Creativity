Table 1: Left three columns are the accuracy of classifying randomly shuffled images. The rightmostcolumn is the accuracy of training on ImageNet and testing on Stylized-ImageNet. The phenomenaare similar for different architectures and can be found in Appendix A.8.
Table 2: Defense performance on CIFAR-10.
Table 3: Defense performance on Tiny-ImageNet.
Table 4: Black-box defense performances on CIFAR-10. Networks in the first row are the sourcemodels for generating adversarial examples by PGD. 0.5-Bottom and 0.3-Bottom mean applyingdefective convolutional layers with keep probability 0.5 and 0.3 to the bottom layers of the networkwhose name lies just above them. The source and target networks are initialized differently if theyshare the same architecture. Numbers in the middle mean the success defense rates.
Table 5: Ablation experiments of defective CNNs. p-Bottom and p-Top mean applying defectivelayers with keep probability p to bottom layers and top layers respectively. p-BottomDC means mak-ing whole channels defective with keep probability p. p-BottomSM means using the same defectivemask in every channel with keep probability p. FGSM16, PGD16 and PGD32 denote attack methodFGSM with perturbation scale '∞ = 16/255, PGD with perturbation scale '∞ = 16/255 and32/255 respectively. CW40 denotes CW attack method (Carlini & Wagner, 2016) with confidenceκ = 40. Numbers in the middle mean the success defense rates.
Table 6: Black-box defense performances against decision-based attack. S(M) is defined above.
Table 7: Black-box defense performances against transfer-based attacks. SD and DB denote spatialdropout and drop block, respectively.
Table 8: Black-box defense performances against transfer-based attacks from ensemble models onthe CIFAR-10 dataset. Numbers in the middle mean the success defense rates. Networks in the firstrow indicate the source models which ensemble other four models except for the network itself. Thesource model generates adversarial examples by PGD. 0.5-Bottom and 0.3-Bottom mean applyingdefective convolutional layers with keep probability 0.5 and 0.3 to the bottom layers of the networkwhose name lies just above them. The source and target networks are initialized differently if theyshare the same architecture.
Table 9: Black-box defense performances against transfer-based attacks on the MNIST dataset.
Table 10: Defense performances against two kinds of gray-box attacks for defective CNNs. Num-bers mean the success defense rates. Networks in the first row are the source models for generat-ing adversarial examples by PGD, which runs for 20 steps with step size 1 and perturbation scale'∞ = 16/255. 0.5-Bottom and 0.3-Bottom in the left column represent the networks with the samestructure as the corresponding source networks but with different initialization. 0.5-BottomDIF and0.3-BottomDIF in the left column represent the networks with the same keep probabilities as thecorresponding source networks but with different sampling of defective neurons.
Table 11: Defense performances against gray-box attacks for standard CNNs. Numbers mean thesuccess defense rates. Networks in the first row are the source models for generating adversarialexamples by PGD, which runs for 20 steps with step size 1 and perturbation scale '∞ = 16/255.
Table 12: Defense performances against white-box attacks. Numbers in the middle mean the successdefense rates. FGSM1, FGSM2, FGSM4 refer to FGSM with perturbation scale 1,2,4 respectively.
Table 13: The left three columns are the accuracy of classifying randomly shuffled test images. Therightmost column is the accuracy of training on ImageNet and testing on Stylized-ImageNet. 0.1-Bottom mean applying defective convolutional layers with keep probability 0.1 to the bottom layersof the network whose name lies just above them.
Table 14: Extended experimental results of Section 4.3. Adversarial examples generated againstDenseNet-121. Numbers in the middle mean the success defense rates. The model trained onCIFAR-10 achieves 95.62% accuracy on test set. p-Bottom, p-Top, p-BottomDC, p-BottomSM,p-Bottom×n and p-BottomEN mean applying defective layers with keep probability p to bottomlayers, applying defective layers with keep probability p to top layers, making whole channels de-fective with keep probability p, using the same defective mask in every channel with keep probabilityp, increasing channel number to n times at bottom layers and ensemble five models with differentdefective masks of the same keep probability p respectively.
Table 15: Extended experimental results of Section 4.3. Numbers in the middle mean the successdefense rates. Adversarial examples are generated against ResNet-18. The model trained on CIFAR-10 achieves 95.27% accuracy on test set. p-Bottom, p-Top, p-BottomDC, p-BottomSM, p-Bottom×nand p-BottomEN mean applying defective layers with keep probability p to bottom layers, applyingdefective layers with keep probability p to top layers, making whole channels defective with keepprobability p, using the same defective mask in every channel with keep probability p, increasingchannel number to n times at bottom layers and ensemble five models with different defective masksof the same keep probability p respectively.
Table 16: Extended experimental results of Section 4.3. Adversarial examples are generated againstResNet-50. Numbers in the middle mean the success defense rates. The model trained on CIFAR-10 achieves 95.69% accuracy on test set. p-Bottom, p-Top, p-BottomDC, p-BottomSM, p-Bottom×nand p-BottomEN mean applying defective layers with keep probability p to bottom layers, applyingdefective layers with keep probability p to top layers, making whole channels defective with keepprobability p, using the same defective mask in every channel with keep probability p, increasingchannel number to n times at bottom layers and ensemble five models with different defective masksof the same keep probability p respectively.
Table 17: Extended experimental results of Section 4.3. Numbers in the middle mean the successdefense rates. Adversarial examples are generated against SENet-18. The model trained on CIFAR-10 achieves 95.15% accuracy on test set. p-Bottom, p-Top, p-BottomDC, p-BottomSM, p-Bottom×nand p-BottomEN mean applying defective layers with keep probability p to bottom layers, applyingdefective layers with keep probability p to top layers, making whole channels defective with keepprobability p, using the same defective mask in every channel with keep probability p, increasingchannel number to n times at bottom layers and ensemble five models with different defective masksof the same keep probability p respectively.
Table 18: Extended experimental results of Section 4.3. Numbers in the middle mean the successdefense rates. Adversarial examples are generated against VGG-19. The model trained on CIFAR-10 achieves 94.04% accuracy on test set. p-Bottom, p-Top, p-BottomDC, p-BottomSM, p-Bottom×nand p-BottomEN mean applying defective layers with keep probability p to bottom layers, applyingdefective layers with keep probability p to top layers, making whole channels defective with keepprobability p, using the same defective mask in every channel with keep probability p, increasingchannel number to n times at bottom layers and ensemble five models with different defective masksof the same keep probability p respectively.
