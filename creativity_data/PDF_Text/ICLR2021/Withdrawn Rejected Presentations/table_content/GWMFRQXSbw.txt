Table 1: Accuracies on CIFAR10/100 and Ima- chine translati geNet. CIFAR10/100 experiments are the median standard error (standard error) over 4 runs.					understanding. In both computer vision and NLP tasks, after careful tunings, we find the decou-pled weight decay (Loshchilov & Hutter, 2018) gives much better results for Adam, MAdam,LaProp and LaMAdam. Therefore, we use this approach in all our experiments. Across all theplots in this section, We define the average step size at time t as the average of ∣ηtmt/(√vt + E) | forAdam/MADAM and ∣ηtmt∣ for LAPROP/LaMAdam over all the entries.
Table 3: Results (median and variance) on the dev sets of GLUE based on finetuning the RoBERTa-base model(Liu et al. (2019)), from 4 runs with the same hyperparameter but different random seeds.
