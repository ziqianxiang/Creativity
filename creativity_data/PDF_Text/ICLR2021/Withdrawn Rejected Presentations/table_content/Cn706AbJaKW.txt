Table 1: Relationship between author reputation/institution and acceptance. This logistic re-				gression model has 93% accuracy on a hold-out set containing 30% of 2020 papers.				Variable	Coeffident	Std. Error	Z-score	p-valuemean reviewer score	2.4354	0.098	24.807	0.000log(citations/papers+1)	0.1302	0.057	2.270	0.023top ten school?	0.2969	0.165	1.802	0.072constant	-13.6620	0.562	-24.313	0.0005.4	Gender BiasThere is a well-known achievement gap between women and men in the sciences. Women in engi-neering disciplines tend to have their papers accepted to high impact venues, and yet receive fewercitations (Ghiasi et al., 2015; Lariviere et al., 2013; Lariviere, 2014; Rossiter, 1993). These Cita-tion disparities exist among senior researchers at ICLR. Over their whole career, male last authorsfrom 2020 have on average 44 citations per publication while women have 33. This gap in totalcitations can be attributed in part to differences in author seniority; the 2019 Taulbee survey reportsthat women are more severely under-represented among senior faculty (15.7%) than among juniorfaculty (23.9%) (Zweben & Bizot, 2020), and more senior faculty have had more time to accumu-late citations. To remove the effect of time, we focus in on only 2020 ICLR papers, where male lastauthors received on average 4.73 citations to date compared to 4.16 citations among women. Thisdisparity flips for first authors; male first authors received just 4.4 citations vs 6.2 among women.
Table 2: Standard deviations from ANOVA model.. Summary for standard deviation between allaverage sCores and standard deviation for review sCores within a paper.
Table 3:	Stukel’s Test. We also use Stukel’s test, another goodness-of-fit test for logistic regression.
Table 4:	Top 10 institutions’ impact on acceptance, together, ICLR 2020. Summary of theLogistic Regression predicting paper acceptance as a function of mean reviewer score and a top 10indicator. The accuracy of the classifier was 92% on a hold-out set containing 30% of 2020 papersVariable	Coefficient Std. Error Z-Score P-Valuemean reviewer score	2.4350	0.097	25.118	0.000top ten school?	0.3536	0.161	2.194	0.028constant	-13.2707	0.526	-25.212	0.000Table 5: Top 10 institutions’ impact on acceptance, separate, ICLR 2020. Logistic regressionsummary for predicting paper acceptance. The top 10 institution ranks each have their own indicatorvariable. Statistically significant effects are in bold. The accuracy of the classifier was 92% on ahold-out set containing 30% of 2020 papersVariable	Coefficient Std. Error Z-Score P-Valuemean reviewer score	2.4600	0.099	24.949	0.000Carnegie Mellon	0.7510	0.363	2.071	0.038MIT	0.7498	0.357	2.100	0.036U. Illinois, Urbana-Champaign	0.6698	0.535	1.252	0.211Stanford	-0.0312	0.371	-0.084	0.933U.C. Berkeley	0.2299	0.337	0.681	0.496U. Washington	-0.8189	0.684	-1.198	0.231Cornell	1.4267	0.607	2.350	0.019
Table 5: Top 10 institutions’ impact on acceptance, separate, ICLR 2020. Logistic regressionsummary for predicting paper acceptance. The top 10 institution ranks each have their own indicatorvariable. Statistically significant effects are in bold. The accuracy of the classifier was 92% on ahold-out set containing 30% of 2020 papersVariable	Coefficient Std. Error Z-Score P-Valuemean reviewer score	2.4600	0.099	24.949	0.000Carnegie Mellon	0.7510	0.363	2.071	0.038MIT	0.7498	0.357	2.100	0.036U. Illinois, Urbana-Champaign	0.6698	0.535	1.252	0.211Stanford	-0.0312	0.371	-0.084	0.933U.C. Berkeley	0.2299	0.337	0.681	0.496U. Washington	-0.8189	0.684	-1.198	0.231Cornell	1.4267	0.607	2.350	0.019Tsinghua U. & U. Michigan (tied)	-0.0118	0.369	-0.032	0.974ETH Zurich	0.0608	0.640	0.095	0.924constant	-13.4048	0.535	-25.038	0.00017Under review as a conference paper at ICLR 2021Table 6: Institution & last author reputation impact on acceptance, CMU, MIT, and Cornell,ICLR 2020. Logistic regression predicting paper acceptance as a function of mean reviewer score, a
Table 6: Institution & last author reputation impact on acceptance, CMU, MIT, and Cornell,ICLR 2020. Logistic regression predicting paper acceptance as a function of mean reviewer score, alast author reputation index, and 3 institution indicators. The accuracy of the classifier was 90% ona hold-out set containing 30% of 2020 papers.
Table 7: Institution impact on acceptance, Google, Facebook, and Microsoft, ICLR 2020. Lo-gistic regression predicting paper acceptance as a function of mean reviewer score and 3 institutionindicators. The accuracy of the classifier was 91% on a hold-out set containing 30% of 2020 papers.
Table 8: Visibility on arXiv during the review period, top 10 institutions at ICLR 2020. Logisticregression predicting paper acceptance as a function of mean reviewer score and an indicator de-marcating if the paper was on arXiv up to one week after the submission date. The accuracy of theclassifier was 93% on a hold-out set containing 30% of 2020 papers.
Table 9: Visibility on arXiv during the review period, institutions not in the top 10 at ICLR2020. Logistic regression predicting paper acceptance as a function of mean reviewer score andan indicator demarcating if the paper was on arXiv up to one week after the submission date. Theaccuracy of the classifier was 92% on a hold-out set containing 30% of 2020 papers.
Table 10: Visibility on arXiv during the review period, CMU, MIT, and Cornell at ICLR 2020.
Table 11: Visibility on arXiv during the review period, top 10 institutions excluding CMU,MIT, and Cornell at ICLR 2020. Logistic regression predicting paper acceptance as a function ofmean reviewer score and an indicator demarcating if the paper was on arXiv up to one week afterthe submission date. The accuracy of the classifier was 91% on a hold-out set containing 30% of2020 papers.
Table 12: Gender impact on acceptance, ICLR 2020. Logistic regression predicting paper accep-tance as a function of mean paper reviewer score and a gender indicator variable for both the firstand last author. The accuracy of the classifier was 93% on a hold-out set containing 30% of 2020papers. The results were inconclusive. Papers with last authors that were unlabelled were excluded.
Table 13: Summary of gender statistics. Some percents do not add up to 100%; we were unableto label 5.6% of first authors and 2.5% of last authors.
