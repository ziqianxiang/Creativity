Under review as a conference paper at ICLR 2021
Enhancing Certified Robustness of Smoothed
Classifiers via Weighted Model Ensembling
Anonymous authors
Paper under double-blind review
Ab stract
Randomized smoothing has achieved state-of-the-art certified robustness against
l2-norm adversarial attacks. However, it is not wholly resolved on how to find
the optimal base classifier for randomized smoothing. In this work, we employ a
Smoothed WEighted ENsembling (SWEEN) scheme to improve the performance
of randomized smoothed classifiers. We show the ensembling generality that
SWEEN can help achieve optimal certified robustness. Furthermore, theoretical
analysis proves that the optimal SWEEN model can be obtained from training under
mild assumptions. We also develop an adaptive prediction algorithm to reduce
the prediction and certification cost of SWEEN models. Extensive experiments
show that SWEEN models outperform the upper envelope of their corresponding
candidate models by a large margin. Moreover, SWEEN models constructed using
a few small models can achieve comparable performance to a single large model
with a notable reduction in training time.
1	Introduction
Deep neural networks have achieved great success in image classification tasks. However, they are
vulnerable to adversarial examples, which are small imperceptible perturbations on the original
inputs that can cause misclassification (Biggio et al., 2013; Szegedy et al., 2014). To tackle this
problem, researchers have proposed various defense methods to train classifiers robust to adversarial
perturbations. These defenses can be roughly categorized into empirical defenses and certified
defenses. One of the most successful empirical defenses is adversarial training (Kurakin et al., 2017;
Madry et al., 2018), which optimizes the model by minimizing the loss over adversarial examples
generated during training. Empirical defenses produce models robust to certain attacks without
a theoretical guarantee. Most of the empirical defenses are heuristic and subsequently broken by
more sophisticated adversaries (Carlini & Wagner, 2017; Athalye et al., 2018; Uesato et al., 2018;
Tramer et al., 2020). Certified defenses, either exact or conservative, are introduced to mitigate such
deficiency in empirical defenses. In the context of lp norm-bounded perturbations, exact methods
report whether an adversarial example exists within an lp ball with radius r centered at a given input x.
Exact methods are usually based on Satisfiability Modulo Theories (Katz et al., 2017; Ehlers, 2017)
or mixed-integer linear programming (Lomuscio & Maganti, 2017; Fischetti & Jo, 2017), which are
computationally inefficient and not scalable (Tjeng et al., 2019). Conservative methods are more
computationally efficient, but might mistakenly flag a safe data point as vulnerable to adversarial
examples (Raghunathan et al., 2018a; Wong & Kolter, 2018; Wong et al., 2018; Gehr et al., 2018;
Mirman et al., 2018; Weng et al., 2018; Zhang et al., 2018; Raghunathan et al., 2018b; Dvijotham
et al., 2018b; Singh et al., 2018; Wang et al., 2018b; Salman et al., 2019b; Croce et al., 2019; Gowal
et al., 2018; Dvijotham et al., 2018a; Wang et al., 2018a). However, both types of defenses are not
scalable to practical networks that perform well on modern machine learning problems (e.g., the
ImageNet (Deng et al., 2009) classification task).
Recently, a new certified defense technique called randomized smoothing has been proposed (Lecuyer
et al., 2019; Cohen et al., 2019). A (randomized) smoothed classifier is constructed from a base
classifier, typically a deep neural network. It outputs the most probable class given by its base
classifier under a random noise perturbation of the input. Randomized smoothing is scalable due
to its independency over architectures and has achieved state-of-the-art certified l2-robustness. In
theory, randomized smoothing can apply to any classifiers. However, naively using randomized
smoothing on standard-trained classifiers leads to poor robustness results. It is still not wholly
1
Under review as a conference paper at ICLR 2021
resolved on how a base classifier should be trained so that the corresponding smoothed classifier has
good robustness properties. Recently, Salman et al. (2019a) employ adversarial training to train base
classifiers and substantially improve the performance of randomized smoothing, which indicates that
techniques originally proposed for empirical defenses can be useful in finding good base classifiers
for randomized smoothing.
In this paper, we take a step towards finding suitable base models for randomized smoothing by
model ensembling. The idea of model ensembling has been used in various empirical defenses
against adversarial examples and shows promising results for robustness (Liu et al., 2018; Strauss
et al., 2018; Pang et al., 2019; Wang et al., 2019; Meng et al., 2020; Sen et al., 2020). Moreover, an
ensemble can combine the strengths of candidate models1 to achieve superior clean accuracy (Hansen
& Salamon, 1990; Krogh & Vedelsby, 1994). Thus, we believe ensembling several smoothed models
can help improve both the robustness and accuracy. Specifically for randomized smoothing, the
smoothing operator is commutative with the ensembling operator: ensembling several smoothed
models is equivalent to smoothing an ensembled base model. This property makes the combination
suitable and efficient. Therefore, we directly ensemble a base model by taking some pre-trained
models as candidates and optimizing the optimal weights for randomized smoothing. We refer to
the final model as a Smoothed WEighted ENsembling (SWEEN) model. Moreover, SWEEN does
not limit how individual candidate classifiers are trained, thus is compatible with most previously
proposed training algorithms on randomized smoothing.
Our contributions are summarized as follows:
1.	We propose SWEEN to substantially improve the performance of smoothed models. Theo-
retical analysis shows the ensembling generality and the optimization guarantee: SWEEN
can achieve optimal certified robustness w.r.t. the defined γ-robustness index, which is an
extension of previously proposed criteria of certified robustness (Lemma 1), and SWEEN
can be easily trained to a near-optimal risk with a surrogate loss (Theorem 2).
2.	We develop an adaptive prediction algorithm for the weighted ensembling, which effectively
reduces the prediction and certification cost of the smoothed ensemble classifier.
3.	We evaluate our proposed method through extensive experiments. On all tasks, SWEEN
models consistently outperform the upper envelopes of their respective candidate models
in terms of the approximated certified accuracy by a large margin. In addition, SWEEN
models can achieve comparable or superior performance to a large individual model using a
few candidates with a notable reduction in total training time.
2	Related Work
In the past few years, numerous defenses have been proposed to build classifiers robust to adversarial
examples. Our work typically involves randomized smoothing and model ensembling.
Randomized smoothing Randomized smoothing constructs a smoothed classifier from a base
classifier via convolution between the input distribution and certain noise distribution. It is first
proposed as a heuristic defense by (Liu et al., 2018; Cao & Gong, 2017). Lecuyer et al. (2019)
first prove robustness guarantees for randomized smoothing utilizing tools from differential privacy.
Subsequently, a stronger robustness guarantee is given by Li et al. (2018). Cohen et al. (2019)
provide a tight robustness bound for isotropic Gaussian noise in l2 robustness setting. The theoretical
properties of randomized smoothing in various norm and noise distribution settings have been further
discussed in the literature (Blum et al., 2020; Kumar et al., 2020; Yang et al., 2020; Lee et al.,
2019; Teng et al., 2019; Zhang et al., 2020). Recently, a series of works (Salman et al., 2019a; Zhai
et al., 2020) develop practical algorithms to train a base classifier for randomized smoothing. Our
work improves the performance of smoothed classifiers via weighted ensembling of pre-trained base
classifiers.
Model ensembling Model ensembling has been widely studied and applied in machine learning
as a technique to improve the generalization performance of the model (Hansen & Salamon, 1990;
Krogh & Vedelsby, 1994). Krogh & Vedelsby (1994) show that ensembles constructed from accurate
1In this paper, ”candidate model” and ”candidate” refer to an individual model used in an ensemble. The
term ”base model” refers to a model to which randomized smoothing applies.
2
Under review as a conference paper at ICLR 2021
and diverse networks perform better. Recently, simple averaging of multiple neural networks has been
a success in ILSVRC competitions (He et al., 2016; Krizhevsky et al., 2017; Simonyan & Zisserman,
2015). Model ensembling has also been used in defenses against adversarial examples (Liu et al.,
2018; Strauss et al., 2018; Pang et al., 2019; Wang et al., 2019; Meng et al., 2020; Sen et al., 2020).
Wang et al. (2019) have shown that a jointly trained ensemble of noise injected ResNets can improve
clean and robust accuracies. Recently, Meng et al. (2020) find that ensembling diverse weak models
can be quite robust to adversarial attacks. Unlike the above works, which are empirical or heuristic,
we employ ensembling in randomized smoothing to provide a theoretical robustness certification.
3	Preliminaries
Notation Let Y = {1, 2, ..., M}. We overload notation slightly, letting k refer the M -dimensional
one-hot vector whose k-th entry is 1 for k = 1, ..., M as well. The choice should be clear from
context. Let ∆k = {(p1,p2, ...,pk)pi ≥ 0, Pik=1 pi = 1} be the k-dimensional probability simplex
for k ∈ N+, and ∆ = ∆M . For an M -dimensional function f, we use fi to refer to its i-th entry,
i = 1, 2,…，M. We use N(0, σ2I) to denote the d-dimensional Gaussian distribution with mean
0 and variance σ2I. We use Φ-1 to denote the inverse of the standard Gaussian CDF, and use Γ
to denote the gamma function. We use R* to denote the set of non-negative real numbers. For
x,a,b ∈ R, a ≤ b, We define CliP(x; a, b) = min{max{x, a},b}. We use Ω(∙) to denote Big-Omega
notation that suppresses multiplicative constants.
Neural network and classifier Consider a classification problem from X ⊆ Rd to classes Y .
Assume the input space X has finite diameter D = suPx ,x ∈X kx1 - x2 k2 < ∞. The training
set {(xi, yi)}in=1 is i.i.d. drawn from the data distribution D. We call f a probability function or
a classifier if it is a mapping from Rd to ∆ or Y, respectively. For a probability function f, its
induced classifier f * is defined such that f *(x) = argmaxι≤i≤M fi(x). For simplicity, we will not
distinguish between f and f * when there is no ambiguity, andhence all definitions and properties
for classifiers automatically apply to probability functions as well. f (∙; θ) denotes a neural network
parameterized by θ ∈ Θ. Here Θ can include hyper-parameters, thus the architectures of f (∙; θ)'s do
not have to be identical.
Certified robustness We call x + δ an adversarial example of a classifier f, if f correctly classifies
x but f(x + δ) 6= f (x). Usually kδk2 is small enough so x + δ and x appear almost identical for the
human eye. The (l2-)robust radius of f is defined as
r(x, y; f) = inf kδk2,	(1)
F (x+δ)6=y
which is the radius of the largest l2 ball centered at x within which f consistently predicts the true
label y of x. Note that r(x, y; f) = 0 if f(x) 6= y. As mentioned before, we can extend the above
definitions to the case when f is a probability function by considering the induced classifier f* . A
certified robustness method tries to find some lower bound rc(x, y; f) of r(x, y; f), and we call rc a
certified radius of f .
Randomized smoothing Let f be a probability function or a classifier. The (randomized)
smoothed function of f is defined as
g(X) = Eδ 〜N (0,σ2I)[f (X + δ)].	⑵
The (randomized) smoothed classifier of f is then defined as g*. Cohen et al. (2019) first provide
a tight robustness guarantee for classifier-based smoothed classifiers, which is summerized in the
following theorem:
Theorem 1. (Cohen et al. (2019)) For any classifier f, denote its smoothed function by g. Then
r(x,y; g) ≥ 2[Φ-1(gy(X))- Φ-1(maxgk(x))].	(3)
Later on, Salman et al. (2019a); Zhai et al. (2020) extends Theorem 1 for probability functions.
4	SWEEN: Smoothed weighted ensembling
In this section, we describe the SWEEN framework we use. We also present some theoretical results
for SWEEN models. The proofs of the results in this section can be found in Appendix A.
3
Under review as a conference paper at ICLR 2021
4.1	SWEEN: OVERVIEW
To be specific, we adopt a data-dependent weighted average of neural networks to serve as the base
model for smoothing. Suppose We have some pre-trained neural networks f (∙; θι),...,f (∙; θκ) as
ensemble candidates. A weighted ensemble model is then
K
fens ( ∙; θ, W)= X Wkf(∙; θk),	(4)
k=1
where θ = (θι,…，θκ) ∈ Θk, and w ∈ ∆K is the ensemble weight. For a specific fens, the
corresponding SWEEN model is defined as the smoothed function of fens, denoted by gens. We have
KK	K
gens(x; θ,w) = Eδ[£ Wkf(x + δ; θk)] = EwkEδf(x + δ; θk) = Ewkg(x; θk),	(5)
k=1	k=1	k=1
where g(∙; θ) is the smoothed function of f(∙; θ). This result means that gen is the weighted sum of
the smoothed functions of the candidate models under the same weight w, or more briefly, randomized
smoothing and weighted ensembling are commutative. Thus, ensembling under the randomized
smoothing framework can provides benefits in improving the accuracy and robustness.
To find the optimal SWEEN model, we can minimize a surrogate loss of gens over the training set to
obtain the value of appropriate weights. These data-dependent weights can make the ensemble model
robust to the presence of some biased candidate models, as they will be assigned with small weights.
4.2	Certified robustness of SWEEN models
For a smoothed function g, the certified radius at (x, y) provided by Theorem 1 is rc(x, y; g) =
clip(2[Φ-1(gy(x)) - Φ-1(maxk=y gk(x))];0, D). Wenow formally define Y-robustness index as a
criterion of certified robustness.
Definition 1. (γ-robustness index). For Y : R* → R* and a Smoothedfunction g, the Y-robustness
index of g is defined as
IY(g) = E(x,y)〜Dγ(rc(x, y； g)).	⑹
It can be easily observed that Y-robustness index is an extension of many frequently-used criteria of
certified robustness of smoothed classifiers.
d
Proposition 1. Let γι(r) = l{r ≥ R}, γ2(r) = r, γ3(r)= 心：i)rd Then, Yi-robustness index is
the certified accuracy at radius R (Cohen et al., 2019); Y2-robustness index is the average certified
radius (Zhai et al., 2020); Y3-robustness index is the average volume of the certified region.
We note that criteria considering the volume of the certified region are more comprehensive than
those only considering the certified radii in a sense, as they take the input dimension into account.
Now consider F = {f(∙; θ) : Rd → ∆∣θ ∈ Θ}, the set of neural networks parametrized over Θ.
The corresponding set of smoothed functions is G = {g(χ; θ) = Eδ〜N(o^i)[f(X + δ; θ)]∣θ ∈ Θ}.
Suppose θι,…，θκ are drawn i.i.d. from a fixed probability distribution P on Θ. The set of SWEEN
models is then
ʌ
(KK
φ(x) = X wkg(x； θk)∣∣wk ≥ 0, Xwk
k=1	k=1
1
(7)
Similar to Rahimi & Recht (2008), we consider mixtures of the form φ(x) = Jθ w(θ)g(x; θ)dθ, For
a mixture φ, we define ∣∣φkp := sup6 | ww((θ) |. Define
Fp
{φ(x) = / w(θ)g(x; θ)dθ∣ kφ∣p < ∞,w(θ) ≥ 0,/ w(θ)dθ = l}.
(8)
Note that for any φ ∈ Fp , φ is a smoothed probability function. Intuitively, Fp is quite a rich set.
The following result shows that with high probability, the best Y-robustness index a SWEEN model
can obtain is near the optimal Y-robustness index in the class Fp . Thus, the ensembling generality
also holds for the Y-robustness index we defined for robustness.
4
Under review as a conference paper at ICLR 2021
Lemma 1. Suppose γ is a Lipschitz function. Given η > 0. For any ε > 0, for sufficently large K,
with probability at least 1 - η over θ1, ..., θK drawn i.i.d. from p, there exists φ ∈ Fθ which satisfies
Iγ(φ) > sup IY(φ) 一 ε.	(9)
φ∈Fp
Moreover, if there exists φo ∈ Fp such that IY (φo) = supφ∈F? IY (φ), K = Ω( ε4).
In practice, the defined robustness index IY(∙) may be hard to optimized directly, in which case We
choose a surrogate loss function l : RM × Y → R to approximate it. Now the optimization for the
ensemble weight w of a SWEEN model over a training set {(xi, yi)}in=1 can be formulated as
1n K
min — y'l(Y'Wkg(xi； θk),yi).	(10)
w∈∆K n
i=1 k=1
However, this process typically invovles Monte Carlo simulation since we only have access to
f (∙, θk), k = 1, ∙∙∙ ,K. We define the risk and empirical risk w.r.t. the surrogate loss l.
Definition 2. (Risk and empirical risk). For a surrogate loss function l	: RM × Y → R, the risk of a
probability function φ are defined as
R[φ] = E(x,y)〜D l(φ(χ),y).	(11)
If φ(x) = PK=I Wk g(x; θk) ∈ Fθ ,for training Set {(xi, yi)}n=1 and sample size S, the empirical
risk of φ is defined as
Remp[φ] = n X l(X Wk[ 1 X f(Xi + δijk; θk )],yi),	(12)
n i=1 k=1 s j=1
where δjk '•吟 N(0,σ2I), 1 ≤ i ≤ n, 1 ≤ j ≤ s, 1 ≤ k ≤ K.
Now solving for W is reduced to finding the minimizer of Remp . When the loss function l is convex,
this problem is a low-dimensional convex optimization, so we can obtain the global empirical risk
minimizer using traditional convex optimization algorithms. Furthermore, we have:
Theorem 2. Supposefor all y ∈ Y, l(∙, y) is a Lipschitz function with constant L and is uniformly
bounded. Given η > 0. For any ε > 0, for sufficently large K, if n = Ω(K ),s = Ω( IogKn) ,then
with probability at least 1 一 η over the training dataset {(xi, yi)}in=1 drawn i.i.d. from D and the
parameters θ1, ..., θK drawn i.i.d. from p and the noise samples drawn i.i.d. from N(0, σ2I), the
empirical risk minimizer φ over Fθ satisfies
-—八、	.	—-」
R[φ] - inf R[φ] < ε.	(13)
φ∈Fp
Moreover, if there exists φo ∈ Fp such that R[φo] = inf φ∈Fp R[φ], K = Ω( ε4).
Theorem 2 gives a guarantee that, for large enough K, n, s, the gap between the risk of the empirical
risk minimizer φ and infφ∈Fp R[φ] can be arbitrarily small with high probability. Note that we can
solve φ to any given precision when l is convex. Moreover, Theorem 2 reveals the accessibility of
φ in Lemma 1 when l approximates the γ-robustness index well. While the number of candidate
models and the number of training samples need to be large to ensure good theoretical properties, we
will show that the performance of SWEEN models of practical settings is good enough in Section 5.
4.3	Adaptive prediction algorithm
A major drawback of ensembling is the high execution cost during inference, which consists of
prediction and certification costs for smoothed classifiers. The evaluation of smoothed classifiers
relies on Monte Carlo simulation, which is computationally expensive. For instance, Cohen et al.
(2019) use 100 Monte Carlo samples for prediction and 100,000 samples for certification. If we use
100 candidate models to construct a SWEEN model, the certification ofa single data point will require
10,010,000 local evaluations (10,000 for prediction and 10,000,000 for certification). Inoue (2019)
5
Under review as a conference paper at ICLR 2021
observes that ensembling does not make improvements for inputs predicted with high probabilities
even when they are mispredicted. He proposes an adaptive ensemble prediction algorithm to reduce
the execution cost of unweighted ensemble models. We modify the algorithm to make it applicative
to weighted ensemble models, which is detailed in Appendix B.1. For a data point, classifiers are
evaluated in descending order with respect to their weights. Whenever an early-exit condition is
satisfied, we stop the evaluation and return the current prediction.
5	Experiments
In this section, we design extensive experiments on CIFAR-10, SVHN and ImageNet to evaluate the
performance of SWEEN models.
5.1	Setup
Model setup We train different network architectures on CIFAR-10 and SVHN to serve as
candidates for ensembling, including LeNet (LeCun et al., 1989), AlexNet (Krizhevsky et al., 2017),
ResNet-20 (He et al., 2016), ResNet-26, ResNet-32, ResNet-110, DenseNet (Huang et al., 2017)
(depth=100), VGG-16 (Simonyan & Zisserman, 2015), and VGG-19. We particularly evaluate
two compositions of SWEEN models. The first is a relatively rich set of models, including LeNet,
AlexNet, ResNet-20, ResNet-110, DenseNet, VGG-16, VGG-19, denoted by the SWEEN-7 model.
The second is a small set of small models, including ResNet-20, ResNet-26, ResNet-32, denoted by
the SWEEN-3 model. The SWEEN-7 model and the SWEEN-3 model simulate how much SWEEN
can help in scenarios when we have adequate and limited numbers of candidate models, respectively.
On ImageNet, we train three candidate models including ResNet-18, ResNet-34 and ResNet-50.
We evaluate the SWEEN model containing the three models, denoted by the SWEEN-IN model. A
SWEEN model and its candidate models are trained and evaluated with the same noise level σ. The
detailed algorithm for obtaining a SWEEN model is presented in Appendix B.2.
Candidate model Training We train candidate models using two training schemes, including
Gaussian data augmentation training (Cohen et al., 2019), which is denoted as the standard training
for simplicity, and MACER training (Zhai et al., 2020). All hyper-parameters used in our experiments
are listed in Appendix C.1.
Solving the ensembling weight From Section 4 we know that we can obtain the empirical risk
minimizer by solving a convex optimization. However, this requires first to approximate the value
of smoothed functions of candidate models at every data point, which can be very costly when the
number of candidates or training data samples is large. Hence, we use Gaussian data augmented
training to solve the ensembling weight. More precisely, we freeze the parameters of candidate
models and minimize the cross-entropy loss of the SWEEN model on Gaussian augmented data
from the evaluation set. Empirically we find that this approach is much faster and yields comparable
results.
Certification Following previous works, we report the approximated certified accuracy (ACA),
which is the fraction of the test set that can be certified to be robust at radius r approximately (see
Cohen et al. (2019) for more details). We also report the average certified radius (ACR) following
Zhai et al. (2020). The ACR equals to the area under the radius-accuracy curve (see Figure 1). All
results were certified using algorithms in Cohen et al. (2019) with N = 100, 000 samples and failure
probability α = 0.001.
5.2	Results
Standard training on CIFAR-10 Table 1 displays the performance of two kinds of SWEEN
models under noise levels σ ∈ {0.25, 0.50, 1.00}. The performance of a single ResNet-110 is
included for comparison, and we also report the upper envelopes of the ACA and ACR of their
corresponding candidate models as UE. In Figure 1, we display the radius-accuracy curves for the
SWEEN models and all their corresponding candidate models under σ = 0.50 on CIFAR-10. We
also include full-size figures in Appendix D.
The results show that SWEEN models significantly boost the performance compared to their corre-
sponding candidate models. According to Figure 1, the SWEEN-7 model consistently outperforms
6
Under review as a conference paper at ICLR 2021
Table 1: ACA (%) and ACR on CIFAR-10. All models are trained via the standard training. UE
stands for the upper envelope, which shows the largest ACA and ACR among the candidate models.
σ	Model	0.00	0.25	0.5	0.75	1.00	1.25	1.50	1.75	2.00	ACR
	ResNet-110	79.6	65.2	50.8	34.4	0	0	0	0	0	0.489
	UESWEEN-3	80.5	65.6	47.9	30.2	0	0	0	0	0	0.470
0.25	SWEEN-3	82.3	69.8	54.7	35.9	0	0	0	0	0	0.520
	UESWEEN-7	80.5	67.9	52.2	36.1	0	0	0	0	0	0.506
	SWEEN-7	84.2	72.0	58.7	43.0	0	0	0	0	0	0.560
	ResNet-110	68.7	58.6	46.7	354	25.0	17.0	9.0	4.6	0	0.573
	UESWEEN-3	69.6	58.3	45.8	33.7	23.0	15.8	9.2	4.7	0	0.556
0.50	SWEEN-3	70.9	61.4	50.8	38.3	27.7	20.1	12.8	6.7	0	0.630
	UESWEEN-7	68.6	58.9	46.6	34.8	24.7	16.5	10.2	5.3	0	0.574
	SWEEN-7	71.2	63.0	52.2	41.9	31.2	22.9	15.3	8.3	0	0.678
	ResNet-110	51.4	44.9	37.9	3Ξ8	24.6	18.8	13.8	10.2	6.7	0.559
	UESWEEN-3	50.6	44.7	38.2	30.8	24.6	18.5	13.6	10.5	7.0	0.555
1.00	SWEEN-3	51.9	45.5	39.3	32.3	25.9	19.7	15.4	11.4	8.1	0.595
	UESWEEN-7	52.0	45.7	37.9	31.9	25.1	19.2	13.9	10.1	7.2	0.557
	SWEEN-7	52.7	46.3	39.8	34.0	27.6	22.7	17.9	12.6	9.2	0.631
Figure 1: Radius-accuracy curves under σ = 0.50. All models are trained via the standard training.
(Left) The SWEEN-7 model and all its candidate models. (Middle) The SWEEN-3 model and all its
candidate models. (Right) The SWEEN-7 model, the SWEEN-3 model and the ResNet-110.
all its candidates in terms of the ACA at all radii. The ACR of the SWEEN-7 model is 0.678, much
higher than that of the upper envelope of the candidates, which is 0.574. It confirms our theoretical
analysis in Section 4 that SWEEN can combine the strength of candidate models and attain superior
performance. Besides, SWEEN is effective when only limited numbers of small candidate models
are available. The SWEEN-3 model using ResNet-20, ResNet-26, and ResNet-32 achieves higher
ACA than the ResNet-110 at all radii on all noise levels. The total training time and the number of
parameters of the SWEEN-3 model are 36 % and 30% less than those of ResNet-110, respectively.
The improvements can be further amplified by increasing the number and size of candidate models.
As an instance, the ACR of the SWEEN-7 model is at least 13% higher than that of the ResNet-110
in Table 1. The above results verify the effectiveness of SWEEN for randomized smoothing.
Table 2: Training time, #parameters and #FLOPs for models under σ = 0.50 via MACER training.
All the experiments are run on a single NVIDIA 1080 Ti GPU.
Model	sec/epoch	#epochs	Total hrs	#parameters	#FLOPs
ResNet-110	404.2	440	49.4	1.73M	255.27M
ResNet-20	72.2	440	8.8	0.27M	41.21M
ResNet-26	92.9	440	11.3	0.36M	55.48M
ResNet-32	113.2	440	13.8	0.46M	69.75M
Weight	0.6	150	0.025	-	-
Ensemble	-	-	33.9	1.10M	166.44M
7
Under review as a conference paper at ICLR 2021
Table 3: ACA (%) and ACR on CIFAR-10. All models are trained via MACER training. UE stands
for the upper envelope of candidate models.
σ	Model	0.00	0.25	0.5	0.75	1.00	1.25	1.50	1.75	2	ACR
	ResNet-110	81	71	59	43	0	0	0	0	0	0.556
0.25	UESWEEN-3	77.4	66.9	56.8	41.9	0	0	0	0	0	0.529
	SWEEN-3	77.7	68.7	60.3	46.6	0	0	0	0	0	0.558
	ResNet-110	66	60	53	46	38	29	19	12	0	0.726
0.50	UESWEEN-3	64.9	57.1	49.7	41.1	34.1	26.2	20.2	11.7	0	0.685
	SWEEN-3	64.7	58.4	51.8	43.9	37.2	29.2	22.8	14.6	0	0.727
	ResNet-110	45	41	38	35	32	29	25	22	18	0.792
1.00	UESWEEN-3	39.4	38.2	35.8	33.4	30.3	27.6	24.5	22.0	19.0	0.793
	SWEEN-3	39.5	37.9	35.8	33.2	30.4	27.5	24.6	22.0	19.1	0.796
MACER training on CIFAR-10 Since SWEEN is compatible with previous training algorithms,
we adopt MACER training for the SWEEN-3 model. The results are summarized in Table 3. For the
ACA and ACR of the ResNet-110 model, we use the original numbers from Zhai et al. (2020).
In the results, the SWEEN-3 model achieves comparable results to the ResNet-110 but is more
efficient. From Table 2 and 3, the SWEEN-3 model takes 33.9 hours to achieve 0.727 in terms of the
ACR for σ = 0.5, using three small and easy-to-train candidates models. Meanwhile, it takes 49.4
hours for the ResNet-110 to achieve similar performance on CIFAR-10. This 32% speed up reveals
the efficiency of applying SWEEN to previous training methods.
Standard training on ImageNet Table 4 displays the performance of ResNet-50 and SWEEN-IN
under the noise levels σ ∈ {0.25, 0.50, 1.00}. We note that the performance of ResNet-50 is also
the upper envelope of the three models in SWEEN-IN. We can see that the SWEEN-IN model
significantly outperforms its corresponding candidate models, similar to the results on CIFAR-10.
The results again confirm the effectiveness of our proposed SWEEN framework.
Table 4: ACA (%) and ACR on ImageNet. All models are trained via standard training.
σ	Model	0.00	0.25	0.5	0.75	1.00	1.25	1.50	1.75	2	ACR
0.25	ResNet-50	66.8	58.2	49.0	38.2	0	0	0	0	0	0.469
	SWEEN-IN	67.8	60.2	51.6	41.6	0	0	0	0	0	0.489
0.50	ResNet-50	56.4	52.4	46.4	42.2	37.8	32.6	28.0	21.4	0	0.726
	SWEEN-IN	56.4	52.4	49.6	45.0	40.8	37.0	31.6	25.2	0	0.781
1.00	ResNet-50	43.6	40.6	37.8	35.4	32.4	28.8	25.8	22.4	19.4	0.863
	SWEEN-IN	44.6	42.0	38.6	36.4	35.0	32.6	29.4	25.6	22.4	0.948
Other experimental results Due to space constraints, we only report the main results here. The
results of further experiments (e.g., the results on SVHN, the results of the adaptive prediction
algorithm, the results of the SWEEN model with identical architectures, and the results of SWEEN
versus real attacks) can be found in Appendix C.
6	Conclusions
In this work, we introduced the smoothed weighted ensembling (SWEEN) to improve randomized
smoothed classifiers in terms of both accuracy and robustness. We showed that SWEEN can achieve
optimal certified robustness w.r.t. our defined γ-robustness index. Furthermore, we can obtain
the optimal SWEEN model w.r.t. a surrogate loss from training under mild assumptions. We also
developed an adaptive prediction algorithm to accelerate the prediction and certification process. Our
extensive experiments showed that a properly designed SWEEN model was able to outperform all its
candidate models by a significant margin consistently. Moreover, SWEEN models using a few small
and easy-to-train candidates could match or exceed a large individual model on performance with a
notable reduction in total training time. Our theoretical and empirical results confirmed that SWEEN
is a viable tool for improving the performance of randomized smoothing models.
8
Under review as a conference paper at ICLR 2021
References
Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of
security: Circumventing defenses to adversarial examples. In ICML 2018: Thirty-fifth International
Conference on Machine Learning, pp. 274-283, 2018.
Peter Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. The Journal of Machine Learning Research, 3:224-240, 06 2001. doi: 10.1007/
3-540-44581-L15.
Battista Biggio,Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Srndic, Pavel Laskov, Giorgio
Giacinto, and Fabio Roli. Evasion attacks against machine learning at test time. european
conference on machine learning, 8190:387-402, 2013.
Avrim Blum, Travis Dick, Naren Manoj, and Hongyang Zhang. Random smoothing might be unable
to certify '∞ robustness for high-dimensional images. arXiv preprint arXiv:2002.03517, 2020.
Xiaoyu Cao and Neil Zhenqiang Gong. Mitigating evasion attacks to deep neural networks via
region-based classification. In Proceedings of the 33rd Annual Computer Security Applications
Conference on, pp. 278-287, 2017.
Nicholas Carlini and David Wagner. Adversarial examples are not easily detected: Bypassing ten
detection methods. In Proceedings of the 10th ACM Workshop on Artificial Intelligence and
Security, pp. 3-14, 2017.
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified adversarial robustness via randomized
smoothing. In ICML 2019 : Thirty-sixth International Conference on Machine Learning, pp.
1310-1320, 2019.
Francesco Croce and Matthias Hein. Reliable evaluation of adversarial robustness with an ensemble
of diverse parameter-free attacks. In ICML, 2020.
Francesco Croce, Maksym Andriushchenko, and Matthias Hein. Provable robustness of relu networks
via maximization of linear regions. In The 22nd International Conference on Artificial Intelligence
and Statistics, pp. 2057-2066, 2019.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hier-
archical image database. In 2009 IEEE Conference on Computer Vision and Pattern Recognition,
pp. 248-255, 2009.
Krishnamurthy Dvijotham, Sven Gowal, Robert Stanforth, Relja Arandjelovic, Brendan O’Donoghue,
Jonathan Uesato, and Pushmeet Kohli. Training verified learners with learned verifiers. arXiv
preprint arXiv:1805.10265, 2018a.
Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy Mann, and Pushmeet Kohli.
A dual approach to scalable verification of deep networks. In UAI 2018: The Conference on
Uncertainty in Artificial Intelligence (UAI), pp. 550-559, 2018b.
Rudiger Ehlers. Formal verification of piece-wise linear feed-forward neural networks. In In-
ternational Symposium on Automated Technology for Verification and Analysis, pp. 269-286,
2017.
Matteo Fischetti and Jason Jo. Deep neural networks as 0-1 mixed integer linear programs: A
feasibility study. arXiv preprint arXiv:1712.06174, 2017.
Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, and Martin
Vechev. Ai2: Safety and robustness certification of neural networks with abstract interpretation. In
2018 IEEE Symposium on Security and Privacy (SP), pp. 3-18, 2018.
Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan
Uesato, Relja Arandjelovic, Timothy A. Mann, and Pushmeet Kohli. On the effectiveness of
interval bound propagation for training verifiably robust models. arXiv preprint arXiv:1810.12715,
2018.
9
Under review as a conference paper at ICLR 2021
L.K. Hansen and P. Salamon. Neural network ensembles. IEEE Transactions on Pattern Analysis
andMachineIntelligence, 12(10):993-1001, 1990.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp.
770-778, 2016.
Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Weinberger. Densely connected
convolutional networks. In 2017 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 2261-2269, 2017.
Hiroshi Inoue. Adaptive ensemble prediction for deep neural networks based on confidence level. In
The 22nd International Conference on Artificial Intelligence and Statistics, pp. 1284-1293, 2019.
Guy Katz, Clark W. Barrett, David L. Dill, Kyle Julian, and Mykel J. Kochenderfer. Reluplex: An
efficient smt solver for verifying deep neural networks. In International Conference on Computer
Aided Verification, pp. 97-117, 2017.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolu-
tional neural networks. Communications of The ACM, 60(6):84-90, 2017.
Anders Krogh and Jesper Vedelsby. Neural network ensembles, cross validation, and active learning.
In Advances in Neural Information Processing Systems 7, pp. 231-238, 1994.
Aounon Kumar, Alexander Levine, Tom Goldstein, and Soheil Feizi. Curse of dimensionality on
randomized smoothing for certifiable robustness. arXiv preprint arXiv:2002.03239, 2020.
Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. Adversarial machine learning at scale. In
ICLR 2017 : International Conference on Learning Representations 2017, 2017.
Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel.
Backpropagation applied to handwritten zip code recognition. Neural Computation, 1(4):541-551,
1989.
Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified
robustness to adversarial examples with differential privacy. In 2019 IEEE Symposium on Security
and Privacy (SP), pp. 656-672, 2019.
Guang-He Lee, Yang Yuan, Shiyu Chang, and Tommi S. Jaakkola. Tight certificates of adversarial
robustness for randomly smoothed classifiers. In Advances in Neural Information Processing
Systems, pp. 4911-4922, 2019.
Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Second-order adversarial attack and
certifiable robustness. 2018.
Xuanqing Liu, Minhao Cheng, Huan Zhang, and Cho-Jui Hsieh. Towards robust neural networks via
random self-ensemble. In Proceedings of the European Conference on Computer Vision (ECCV),
pp. 381-397, 2018.
Alessio Lomuscio and Lalit Maganti. An approach to reachability analysis for feed-forward relu
neural networks. arXiv preprint arXiv:1706.07351, 2017.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. In ICLR 2018 : International
Conference on Learning Representations 2018, 2018.
Ying Meng, Jianhai Su, Jason O’Kane, and Pooyan Jamshidi. Ensembles of many diverse weak
defenses can be strong: Defending deep neural networks against adversarial attacks. arXiv preprint
arXiv:2001.00308, 2020.
Matthew Mirman, Timon Gehr, and Martin Vechev. Differentiable abstract interpretation for provably
robust neural networks. In ICML 2018: Thirty-fifth International Conference on Machine Learning,
pp. 3578-3586, 2018.
10
Under review as a conference paper at ICLR 2021
Tianyu Pang, Kun Xu, Chao Du, Ning Chen, and Jun Zhu. Improving adversarial robustness via
promoting ensemble diversity. In ICML 2019 : Thirty-sixth International Conference on Machine
Learning,pp. 4970-4979, 2019.
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Certified defenses against adversarial
examples. In ICLR 2018 : International Conference on Learning Representations 2018, 2018a.
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Semidefinite relaxations for certifying
robustness to adversarial examples. In NIPS 2018: The 32nd Annual Conference on Neural
Information Processing Systems, pp. 10877-10887, 2018b.
Ali Rahimi and Benjamin Recht. Weighted sums of random kitchen sinks: Replacing minimization
with randomization in learning. In Advances in Neural Information Processing Systems 21, pp.
1313-1320, 2008.
Hadi Salman, Jerry Li, Ilya Razenshteyn, Pengchuan Zhang, Huan Zhang, Sebastien Bubeck, and
Greg Yang. Provably robust deep learning via adversarially trained smoothed classifiers. In NeurIPS
2019 : Thirty-third Conference on Neural Information Processing Systems, pp. 11292-11303,
2019a.
Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang. A convex relax-
ation barrier to tight robustness verification of neural networks. In NeurIPS 2019 : Thirty-third
Conference on Neural Information Processing Systems, pp. 9832-9842, 2019b.
Sanchari Sen, Balaraman Ravindran, and Anand Raghunathan. Empir: Ensembles of mixed precision
deep networks for increased robustness against adversarial attacks. In ICLR 2020 : Eighth
International Conference on Learning Representations, 2020.
Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. In ICLR 2015 : International Conference on Learning Representations 2015, 2015.
GagandeeP Singh, Timon Gehr, Matthew Mirman, Markus PuscheL and Martin Vechev. Fast
and effective robustness certification. In NIPS 2018: The 32nd Annual Conference on Neural
Information Processing Systems, pp. 10802-10813, 2018.
Thilo Strauss, Markus Hanselmann, Andrej Junginger, and Holger Ulmer. Ensemble methods as a
defense to adversarial perturbations against deep neural networks. arXiv preprint arXiv:1709.03423,
2018.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. In ICLR 2014 : International Conference
on Learning Representations (ICLR) 2014, 2014.
Jiaye Teng, Guang-He Lee, and Yang Yuan. `1 adversarial robustness certificates: a randomized
smoothing approach. 2019.
Vincent Tjeng, Kai Xiao, and Russ Tedrake. Evaluating robustness of neural networks with mixed
integer programming. In ICLR 2019 : 7th International Conference on Learning Representations,
2019.
Florian Tramer, Nicholas Carlini, Wieland Brendel, and Aleksander Madry. On adaptive attacks to
adversarial example defenses. arXiv preprint arXiv:2002.08347, 2020.
Jonathan Uesato, Brendan O'Donoghue, Pushmeet Kohli, and Aaron van den Oord. Adversarial
risk and the dangers of evaluating against weak attacks. In ICML 2018: Thirty-fifth International
Conference on Machine Learning, pp. 5025-5034, 2018.
Bao Wang, Zuoqiang Shi, and Stanley Osher. Resnets ensemble via the feynman-kac formalism
to improve natural and robust accuracies. In NeurIPS 2019 : Thirty-third Conference on Neural
Information Processing Systems, pp. 1657-1667, 2019.
Shiqi Wang, Yizheng Chen, Ahmed Abdou, and Suman Jana. Mixtrain: Scalable training of formally
robust neural networks. arXiv preprint arXiv:1811.02625, 2018a.
11
Under review as a conference paper at ICLR 2021
Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. Efficient formal safety
analysis of neural networks. In NIPS 2018: The 32nd Annual Conference on Neural Information
Processing Systems,pp. 6367-6377, 2018b.
Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel, Duane Boning,
and Inderjit Dhillon. Towards fast computation of certified robustness for relu networks. In ICML
2018: Thirty-fifth International Conference on Machine Learning, pp. 5273-5282, 2018.
Eric Wong and Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. In ICML 2018: Thirty-fifth International Conference on Machine Learning,
pp. 5283-5292, 2018.
Eric Wong, Frank Schmidt, Jan Hendrik Metzen, and J. Zico Kolter. Scaling provable adversarial
defenses. In NIPS 2018: The 32nd Annual Conference on Neural Information Processing Systems,
pp. 8400-8409, 2018.
Greg Yang, Tony Duan, Edward Hu, Hadi Salman, Ilya P. Razenshteyn, and Jerry Li. Randomized
smoothing of all shapes and sizes. arXiv preprint arXiv:2002.08118, 2020.
Runtian Zhai, Chen Dan, Di He, Huan Zhang, Boqing Gong, Pradeep Ravikumar, Cho-Jui Hsieh,
and Liwei Wang. Macer: Attack-free and scalable robust training via maximizing certified radius.
In ICLR 2020 : Eighth International Conference on Learning Representations, 2020.
Dinghuai Zhang, Mao Ye, Chengyue Gong, Zhanxing Zhu, and Qiang Liu. Black-box certifica-
tion with randomized smoothing: A functional optimization based framework. arXiv preprint
arXiv:2002.09169, 2020.
Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efficient neural
network robustness certification with general activation functions. In NIPS 2018: The 32nd Annual
Conference on Neural Information Processing Systems, pp. 4939-4948, 2018.
A Proofs
A.1 Proof of Lemma 1
Define
F0
Fp
φ(x) =	w(θ)g(x; θ)dθ ∣φ∣p < ∞, w(θ) ≥ 0 ,
φ(x) = X wkg(x; θk)wk ≥ 0 .
(14)
(15)
一 _ -, , ʌ ʌ ,
We have Fp ⊆ Fp, Fq ⊆ F'.
Lemma 2. Let μ be any probability measure on Rd. For φ : Rd → RM, define the norm ∣∣φkμ，
JRd ∣φ(x)k2dμ(x). Fix φ ∈ Fp, thenfor any η > 0, with probability at least 1 — η over θι,…，θκ
K
ʌ
ʌ
drawn i.i.d. from P, there exists φ(x) = E Ckg(x; θk) ∈ F' which satisfies
k=1
..ʌ ..
kφ - φkμ ≤
1+
).
(16)
Proof. Sine φ ∈ Fp0, we can write φ(x) = Θ w(θ)g(x; θ)dθ, where w(θ) ≥ 0. Con-
struct Φk = βkg(∙;θk),k = 1,2,…，K, where βk = wθk), then Eφk = φ, ∣φk∣∣μ =
q、Rd β2kg(x; θk)k2dμ(x) ≤lβkI ≤ kΦkp. We then define
1K
u(θι, ∙∙∙ ,θκ) = Il κ ɪ2 φk - φkμ.
k=1
(17)
12
Under review as a conference paper at ICLR 2021
First, by using Jensen's inequality and the fact that kφkkμ ≤ kΦkp, We have
E[u(θ)] ≤ pE[U2w = t E[k K XX Φk- EΦk kμ] = JKI(EkΦkkμ -kEΦkkμ) ≤ √p.
k=1
Next, for θι,…，Θm and θi, we have
lu(θ1,…，θM) - u(θ1,…，”,…，θM)|
1 K	1 K
=|k K X φk - φkμ - k K ( X φk + φi) - φkμl
k=1	k=1,k6=i
1M 1 M
≤ k K X φk - K ( X φk + φi)kμ
k=1	k=1,k6=i
H j 7 H
=	kφi - φikμ
= K
≤	2kΦkp
一 k .
Now we can use McDiarmid’s inequality to bound u(θ), which gives
P[u(θ) - √p ≥ ε] ≤ P[u(θ) - Eu(θ) ≥ ε] ≤ exp(-霖).	(18)
K	2kφk2p
The theorem follows by setting δ to the right hand side and solving ε.
□
Lemma 3. Let μ be any probability measure on Rd. For φ : Rd → RM, define the norm kΦkμ
RRd kΦ(x)k2dμ(x), then for any η > 0 ,for K ≥ M kφkp (1 + /2log 1 )2,
with probability at least
r	∕^i	∕^i	1	∙ ∙ _1 r	. 1	■ . ? / ∖
1 - η over θ1 , ..., θK drawn i.i.d. from p, there exists φ(x)
X~'	/ 八、一行 1 - 1	. ■ ∕`
ck g(x; θk ) ∈ Fθ which satisfies
k=1
kφ - φkμ < 2qkφkp ^K(1 + r2lθg η) 2 .	(19)
Proof. Fix φ ∈ Fp ⊆ Fp0, by using Lemma 2, we have that for any δ > 0, with probability at least
K
1 - η over θ1, ..., θK drawn i.i.d. from p, there exists φ(x) =	ckg(x; θk) ∈ Fθ0 which satisfies
k=1
kΦ - Φkμ < -√φKp (1 + j2lθg 1)，B(K).
(20)
Denote C =	KM P ck, and define s(t) , P ti as the sum of all elements of t ∈ RM. Then k=1	i=1
s(g(x; θ)) = 1, ∀x ∈ Rd, θ ∈ Θ. Thus,
s(φ(x))	=	MM	M X φi(x) = X	w(θ)gi(x; θ)dθ =	w(θ) X gi (x; θ)dθ =	w(θ)dθ = 1,
s(φ(x))	=	M	M	K	K	M	K 二 ∑φi(x) = ∑∑ck gi (x; θk ) = EckE 伙也 θk ) = Eck = c. i=1	i=1	k=1	k=1	i=1	k=1
13
Under review as a conference paper at ICLR 2021
Now we have
B(K)2 > kφ - Φkμ
ZJφ(χ)
-φ(X)k2dμ(X)
/
Rd
(s(φ(x) - Φ(x)))2
M
dμ(x)
≥
Z T dμ(x)
Rd M
(C -1)2
M ,
4公\^
which gives 1 - √MB(K) < C < 1 + √MB(K). Construct φ(χ) = φ(c), then φ ∈ Fθ and
ʌ	C
kΦ - Φkμ
/
Rd
I I 7 /	∖ I /	∖“9τ	/	∖
kφ(X)- φ(χ)k2dμ(X)
ZJCTΦ(x)
-φ(χ)H2dμ(X)
ɪJI(Φ(χ) - Φ(x)) + (cT
-1)33112加(X)
∕j∣∣φ(X)- φ(X)∣2 + ∣(CT
-1)Φ(X)k2 + 2(C-1
ι ʌ / 7 / ∖ I( ∖ 7( ∖∖∖ i ( ∖
—1)(Φ(x) — Φ(x), φ(X)i)dμ(X)
∕jkφ(X)
-Φ(X)k2 + (C-2 - 1)kΦ(X)k2 + 2(1 - C-1)hφ(X), φ(X)i)dμ(X).
Sine we have M ≤ ∣φ(X)k2 ≤ C2, KΦ(x),Φ(x))∣ ≤ JkΦ(X)k2kΦ(X)k2 ≤ C, it holds that
⑴ When 1 < C < 1 + VMB(K),
1 - C2
kφ - φkμ ≤ ((kφ(X) - 3(X)k2 +	m	+2(C - I))dμ(X)
1 C2
≤ B(K)2 + πM- +2(C - 1)
≤ - 2√(K) +2√MB(K);
一	√M
(ii) When 1 - JMB(K) < C ≤ 1,
kΦ - Φ∣μ ≤
≤
≤
<
ZJkΦ(x) - Φ(X)k2 + (1- C2) + 2(1 - C))dμ(X)
B(K)2 +4- (1+C)2
4√MB(K) - (M - 1)B(K)2
4√MB(K).
Thus, with probability at least 1 - η over θ1, ..., θK drawn i.i.d. from p,
kφ - Φkμ < 2√√MB(K) = 2^<4∣mm(1 + J2i0g η)1.
□
Lemma 4. Suppose l(∙, ∙) is L-Lipschitz in its first argument. Fix φ ∈ FP, then for any η > 0, for
K ≥ M∣∣φkp(1 + y 2 log ^)2, with probability at least 1 — η over θι,..., θκ drawn i.i.d. from P,
there exists φ ∈ Fθ which satisfies
∣E(x,y)〜D[l(Φ(X),y)] - E(x,y)〜D[l(Φ(X),y)]| < 2Lq< 4∣mm(1 +J2i0g 1)2 .
14
Under review as a conference paper at ICLR 2021
Proof.
|E[l(B(X),y)] - E[l(O(X),y)]| ≤ EIc(O(X),y)-C(B(X),y^
≤ LE∣∣φ(χ) - φ(x)k2
≤ LqEkφ(X)—φ(X)k2
=Lkφ - φkD∣χ
The desired result follows from Lemma 3.
□
Lemma 5. (CorollaryofPropositionIinZhaietaL(2020))Givenany p1,p2, ∙∙∙ ,Pm satisfies pi ≥
p2 ≥ ∙∙∙ ≥ Pm ≥ 0 and pi +p2 + …+pm = 1. The derivative of clip( 2 [Φ-1(pι)-Φ-1(p2)]ι0, D)
with respect to p1 and p2 is bounded.
Now we can prove Lemma 1.
ProofofLemma 1. Let φo ∈ Fp such that ZY(φo) > supφ∈F? ZY(φ) - ε. From Lemma 5 We know
that q(p,y)，clip( 2 [Φ-i (Py) - Φ-i (maxk=y Pk )];0,D) is Lipschitz in its first argument. Since
m is Lipschitz, c(p, y) , m(q(p, y)) is also Lipschitz in its first argument with some constant L.
Apply Lemma 4, we have that for K ≥ M∣∣φkp(1 + Jl + 2log δ)2, with probability at least 1 - η
over θi, ..., θK drawn i.i.d. from P, there exists B ∈ Fθ which satisfies
_ , . . _ , ʌ .
IY(BO) - IY (B)
When K >
256L4kφokpM(1 + /2 log 1 )2
, we have
sup IY(φ) -IY(φ) = (Sup IY(φ) -IY (φθ)) + (Iγ(Bo) -IY (φ))
φ∈Fp	φ∈Fp
εε
<2+2=ε
If IY(Bo) = supφ∈Fp IY(B), which means kBokp is independent of ε, K = Ω(土).
□
A.2 Proof of Theorem 2
First we introduce some results from statistical learning theory.
Definition 3. (Gaussian complexity). Let μ be a probability distribution on a set X and suppose that
Xi,…,Xn are independent samples selected according to μ. Let F be a class offunctions mapping
from X to R. The Gaussian complexity of F is
2n
Gn [F ] , E [sup |- fξif (Xi)∣∣Xl,…,Xn； ξi,…,ξn]
f∈F n i=i
where ξi, ..., ξn are independent N (0, 1) random variables.
Definition 4. (Rademacher complexity) Let μ be a probability distribution on a set X and suppose
that Xi,..., Xn are independent samples selected according to μ. Let F be a class offunctions
mapping from X to R. The Rademacher complexity of F is
2n
Rn [F ] , E[sup | n工σif (Xi)∣∣Xi, ..., Xn; σi, ..., σn]
where σi, ..., σn are independent uniform {±1}-valued random variables.
Lemma 6. (Part of Lemma 4 in Bartlett & Mendelson (2001)). There are absolute constants β such
that for every class F and every integer n, Rn(F ) ≤ βGn(F ).
15
Under review as a conference paper at ICLR 2021
Lemma 7. (Corollary of Theorem 8 in Bartlett & Mendelson (2001)). Consider a loss function
c : A × Y → [0, 1]. Let F be a class of functions mapping from X to A and let (xi, yi)in=1 be
independently selected according to the probability measure μ. Then, for any integer n and any
0 < η < 1, with probability at least 1 - η over samples of length n, every f in F satisfies
E(x,y)〜μ[c(f (x), y)] ≤
1n
—E c(f (xi), yi) + Rn[c ◦ F] +
n
i=1

8iog η
n
where ≡ ◦ F = {(x,y) → c(f(x), y) - c(0, y) f ∈ F}
Lemma 8. (Corollary of Theorem 14 in Bartlett & Mendelson (2001)). Let A = RM and let F be
a class of functions mapping from X to A. Suppose that there are real-valued classes F1, ..., FM
such that F is a subset of their Cartesian product. Assume further that c : A × Y → R is such that,
for all y ∈ Y, c(∙, y) is a Lipschitzfunction with COnStant L which passes through the origin and is
uniformly bounded. Then
M
Gn(C ◦ F) ≤ 2L X Gn(Fi).
i=1
Now we prove the following lemma:
Lemma 9. Let c, F, (xi, yi)n=ι,Co F be as in Lemma 7. Then, for any integer n and any 0 < η < 1,
with probability at least 1 - η over samples of length n, every f in F satisfies
1n
n E c(f (Xi), yi) ≤ E(x,y)〜μ[c(f (x), y)] + Rn[c ◦ F] +
i=1
∖
8iog η
n
Proof.
1n
— £c(f(xi),yi)- E(χ,y)〜μ[c(f(x),y)] ≤	SUp(Enh - Eh)
n i=1	h∈coF
，乙一 _____.	ʌ ，一 . 一 ，一 .
sup (Enh — Eh)+ Enc(0,y) — Ec(0,y).
h∈CoF
When an (xi, yi) pair changes, the random variable sup (Enh - Eh) can change by no more than
h∈CoF
2. McDiarmid,s inequality implies that with probability at least 1 — 2,
SUp (Enh 一 Eh) ≤ E sup (Enh — Eh) 十
h∈CoF	h∈CoF

2iog η
n
A similar argument, together with the fact that EEnc(0, y) = Ec(0, y), shows that with probability at
least 1 — η,
∕8l°g2
n
Remp[f] ≤ R[f]十 E sup (Enh - Eh)十
h∈CoF
It’s left to show that E sup (Enh — Eh) ≤ Rn[cc ◦ F]. Let (x01, y10 ), ..., (x0n, yn0 ) be drawn i.i.d.
h∈C°F
from μ and independent from (χi,yi)n=ι, then
1n
E sup (E nh — Eh) = E sup E[Enh ——Eh(Xi,yi)]
h∈CoF	h∈CoF	n M
1n
≤ EE sup [Enh --Vh(χi,yi)]
h∈C0F	n i=1
=E sup 1(X h(xi,yi) - X h(χi,yi))
h∈(≡oF nE	七
1n
≤ 2E sup — y^σih(xi,yi)
h∈C0F n i=1
≤ Rn [cc ◦ F].
16
Under review as a conference paper at ICLR 2021
□
We can prove the following result:
Theorem 3. Let A = RM and let F be a class of functions mapping from X to A. Suppose that
there are real-valued classes F1, ..., FM such that F is a subset of their Cartesian product. Assume
further that the loss function C : AX Y → R is such that, for all y ∈ Y, c(∙, y) is a Lipschitzfunction
with constant L and is uniformly bounded. Let {(xi, yi)}in=1 be independently selected according to
the probability measure μ. Then, for any integer n and any 0 < η < 1, there is a probability of at
least 1 - η that every f ∈ F has
|1Xc(f (χi),yi) - E(x,y)~“[c(f(X),y)]| ≤ βL XM Gn [Fj ] +
n i=1	j=1
I
8log 4
n
where β is a constant.
Proof. From Lemma 7 and 9 we have that with probability at least 1 - η over samples of length n,
every f in F satisfies
| - X c(f (xi),yi) - E(x,y)~μ[cf (X),y)]| ≤ Rn [c ◦ F] + V -
n i=1
8log 4
n
it follows by applying Lemma 6 and 8.
□
Lemma 10. Let c(∙, ∙), β be as in Theorem 3. Let(Xi, yi)n=ι be independently selected according to
the probability measure D. For any integer n and any 0 < η < 1, there is a probability ofat least
r .1	.	「一 石，
1 - η that every f ∈ Fθ has
1n
|-£c(f (Xi),yi) - E(x,y)~D[c(f(χ),y)]1 ≤
n i=1
2βLMK
√n

8iog η
n
Proof. Denote
ʌ ,、
Fθ (i)
(KK
φ(X) = Xwkgi(X;wk)wk ≥ 0, Xwk
k=1	k=1
1
, 1 ≤ i ≤ M.
17
Under review as a conference paper at ICLR 2021
M
We have that Fθ ⊆	Fθ(i), where stands for a Cartesian product operation. The Gaussian
k=1
Comlexities of F§(i) s can be bounded as
-4	--
Gn[Fθ (j)]
≤
2n
Eχ,ξ[ SUp |-fξiφ(xi)|]
Φ∈Fθ(j) n i=ι
2n K
Eχ,ξ [sup i n	ξi	wkgj(xi； wk)|]
K	2n
Eχ,ξ[sup | £ Wk — E ξigj (Xi； Wk) |]
w k=1	n i=1
K -n
Eχ,ξ[2 X Inn XξigjH wk)∣]
k=1 n i=1
K
n
≤
K 1n
Ex[2 XtEg(- X ξigj(Xi； Wk))2]
k=1
K
i=1
n
-n
Eχ [2 X、F X gj H Wk )2]
n
k=1
i=1
≤
一 - .	- 一 ~ 一 一 一. 一	一 q q ，-、	q ，…、	--	—
The desired result follows by applying Theorem 3 to Fθ, Fθ(1), ∙∙∙ , Fg(M) and D.	□
Next, we give the definition of semi-empirical risk. The term ”semi-” implies that it is empirical with
respect to the training set but not the smoothing operation.
Definition 5. (Semi-empirical risk). For a surrogate loss function l(∙, ∙) : RM X RM → R and
training set {(xi, yi)}it=ι, the semi-empirical risk of φ(x) = PK=I Wkg(x; θk) ∈ Fg are defined as
-n K
Rse[φ] = n ∑κ∑Wkg(Xi； θk), yi).	(21)
n i=1 k=1
We can use Lemma 4 and 10 to prove the following result:
Theorem 4. Supposefor all y ∈ Y, l(∙, y) is a Lipschitz function with constant L and is uniformly
bounded. Fix φ ∈ Fp, then for any η > 0, with probability at least - - η over the training
dataset {(Xi, yi)}in=1 drawn i.i.d. from D and the parameters θ1, ..., θK drawn i.i.d. from p, the
semi-empirical risk minimizer φ over Fg satisfies
-人- - -
R[φ] - R[φ] <
4βLMK + 4,2log8
where β is a constant.
18
Under review as a conference paper at ICLR 2021
Proof. Let φ* be the minimizer of R over F⅛. Combine Lemma 4 and 10, We derive that, with
probability at least 1 - 2δ over the training dataset and the choice of the parameters θ1 , ..., θK,
-人- --
R[φ] - R[φ]
,-人一	-入一	-入一	,,.	-,-	,,.	-,-	- 一
(R[φ] —	Rse [Φ])	+ (Rse[Φ]	— Rse[Φ*]) +	(Rse[Φ*]	- R[Φ*])	+ (R[Φ*]	- R[Φ])
<
2βLMK + 2,2log 4
√n
2βLMK + 2,2 log 4
√n
4βLMK + 4/2log 4
□
Lemma 11. Let μ be a probability distribution on ∆. For any η > 0, with probability at least 1 一 η
over xι,..., Xs drawn i.i.d. from μ, it holds that
k S X Xi- Ex〜μ[x]∣∣2 ≤ √s (I + 22 log η )
(22)
Proof. Define u(xι,…，xs) = ∣∣ ɪ PS=ι Xi 一 E[x] ∣∣2. By using Jensen,s inequality, we have
s
,——：——	1二
E[u(x)] ≤ √E[u2(X)] = t E[∣sE
i=1
Xi - E[X]k2] = dS(EkXk2-kE[X]k2) ≤ √s.
Next, for xι,…，XM and Xk, we have
∣u(xi,…，Xs) - U(X1,…，Xk,…，Xs)∣
1s	1 s
Ik SEXi-e[x]∣2 -k S ( E Xi + Xk)-e[x]∣2∣
i=1
i=1,i6=k
1s 1 s
≤ kSEXi-s( E Xi+Xk)∣2
i=1	i=1,i6=k
_	∣∣Xk - Xkk2
S
V 2
S.
Now we can use McDiarmid’s inequality to bound u(X), which gives
1	sε2
P[u(x) - √= ≥ ε] ≤ P[u(x) - Eu(X) ≥ ε] ≤ exp(———).
(23)
The result follows by setting η to the right hand side and solving ε.
□
Now we are ready to prove Theorem 2.
Proof of Theorem 2. Let φo ∈ Fp such that R[φ0] < infφ∈Fp R[φ] + 4. By Lemma 11, with
probability at least 1 - 3,
j=1
；θk) - g(Xi； θk)k2 ≤
1 + ,2log 3Kn
√s
， 1 ≤ i ≤ n， 1 ≤ k ≤ K，
(24)
19
Under review as a conference paper at ICLR 2021
hold simultaneously. So with probability at least 1 - 3, for every φ = PK=I Wkg(x; θk) ∈ Fθ, it
holds that
[Remp[φ] -Rse[Φ]∣
11 X[1(X Wk [S X f(Xi + δijk; θk)],yi) - l(X Wkg(xi； θk),yi)]|
i=1	k=1	j=1
k=1
n x k x wk[ I x 〃xi+δijk; θk) - g(xi; θk)]k2
i=1	k=1	j=1
Ln K 1 s
n〉2£wk k SEf (χi+δijk ； θk)- g(xi； θk )∣∣2
i=1 k=1
nK
L XX Wk
n
j=1
1 + J2log 3Kn
i=1 k=1
l(i + q2iθg
√s
√s
3Kn∖
η ) △
, ε1 .
η
By Lemma 10, with probability at least 1 - 3, for every φ ∈ F§, it holds that
Rse[φ]-R[φ]∣≤ T + 三2 , ε2.
Let φ* be the minimizer of R over Fθ. By Lemma 4, with probability at least 1 — 3, for K ≥
Mkφokp(1 + ,2log 3)2,
R[φ*]-
R[Φo] < 2Lq∏ξ 4∣mm (1+J2bg 3 )2,
ε3.
≤
≤
≤
So with probability at least 1 - , it holds that
-人- --
R[φ]- φ∈FP R[φ]
，一”八、	__ r ʌ, .	, _	「八r	_	「r、	, _	「r	_	r
(R[φ] - Rse [φD + (Rse [φ] - Remp [φD + (Remp [φ] - Remp [φ D
+ (Remp[Φ*] - Rse[Φ*]) + (Rse[Φ*]-冗炉])+ (汽炉]-R[Φθ]) + (R[Φθ]-
<
inf R[φ])
φ∈Fp
ε
已 2 + ει + 0 + ει + 已 2 + ε3 + 4
ε
2ει + 2ε2 + ε3 + 4.
256L4kφokpM(1 + J2 log 2)2	64(2βLMK+,8 log 22)2	64L2(1 + ,2 log 爷)2
When K > ------------14—V-----J, n > -----------3-------J, S > --------石----------,We
have
R[φ] - inf R[φ] < ε.	(25)
φ∈Fp
If R[φo] = infφ∈Fp R[φ], which means ∣∣φo∣∣p is independent of ε, K = Ω(ε4).	□
B Algorithms
B.1	Adaptive prediction algorithm
The entire adaptive prediction algorithm is shown in Algorithm 1. It is modified from Inoue (2019) to
generalize to weighted ensembles. The exit condition is the weighted version of the confidence-level-
based early-exit condition in Inoue (2019). The algorithm accelerates the evaluation of the ensemble
function f and the smoothed operation g(x) = Eδ [f(x + δ)] remains the same, so it does not affect
the Monte Carlo estimation and certification procedure of smoothed classifiers.
20
Under review as a conference paper at ICLR 2021
Algorithm 1 Adaptive prediction for weighted ensembling
1:	Input: Ensembling weight w ∈ RK, candidate model parameters θ ∈ ΘK, significance level α,
threshold T , data point x
2:	Compute Z = Φ-1(1 -邕)
3:	Set ∏ as the permutation of indices that sorts W in descending order and i J 0
4:	repeat
5:	Set i J i + 1
6:	Compute the w∏i-th local prediction p∏ J (p∏i,ι, ∙ ∙ ∙ ,P∏i,M) ∈ △
7:	ComputePik J "piWnjpπj,k	卜=ι,[,…M
j=1 wπj
8:	Compute ki J arg maxk pi,k
1	∖∕∑j = 1 Wnj IPj = I Wnj (p∏j,ki -pi,ki )2
9:	untilP1,k1 > TorPi,k > 1 + Z PiTWn V ------------PiTjWπ.--------,i > 1 ori = K
10:	return k and pi,k, k = 1, 2, .…M
B.2	Detailed SWEEN algorithm
Algorithm 2 SWEEN
1:	Input: Training set j^trai∏, evaluation set peval, Ensembling weight W ∈ RK, candidate model
parameters θ = {θ1, ..., θK} ∈ ΘK.
2:	Initialize θ1, ..., θK, W
3:	for i = 1 to K do
4:	Train candidate models θi using Ptrain.
5:	end for
6:	Construct SWEEN model gsween(∙; θ, W) = PK=I Wkg(∙; θk)
7:	Train W using j^eval
8:	return W and θ1, ..., θK
C S upplementary material for experiments
C.1 Detailed settings and hyper-parameters
We perform all experiments on CIFAR-10 and SVHN with a single GeForce GTX 1080 Ti GPU. For
the experiments on ImageNet, we use eight V100 GPUs.
For training the SWEEN models on CIFAR-10 and SVHN, we divide the training set into two parts,
one for training candidate models, and the other for solving weights. We employ 2,000 images for
solving weights on CIFAR-10 and 3000 images for solving weights on SVHN. For ImageNet, we use
the whole training set to train candidate models and 1/1000 of the training set to solve weights.
For Gaussian data augmentation training, all the models are trained for 400 epochs using SGD on
CIFAR-10 and SVHN. The models on ImageNet are trained for 90 epochs. The learning rate is
initialized set as 0.01, and decayed by 0.1 at the 150th/300th epoch.
For MACER training, we use the same hyper-parameters as Zhai et al. (2020), i.e., we use k =
16, β = 16.0, γ = 8.0, and we use λ = 12.0 for σ = 0.25 and λ = 4.0 for σ = 0.50. We train
the models for 440 epochs, the learning rate is initialized set as 0.01, and decayed by 0.1 at the
200th/400th epoch.
C.2 RESULTS ON SVHN
To further evaluate our method, we also experiment on SVHN. The results in Table 5 show that
SWEEN models outperform the upper envelopes of their corresponding candidate models as well.
Figure 2 plots the results on CIFAR-10 and SVHN for comparison.
21
Under review as a conference paper at ICLR 2021
Figure 2: Comparing SWEEN models to the upper envelopes of their corresponding candidate models.
All models are trained via the standard training. (Left) The SWEEN-3 model on CIFAR-10. (Middle)
The SWEEN-7 model on CIFAR-10. (Right) The SWEEN-7 model on SVHN.
Table 5: Certified accuracy (%) and ACR on SVHN. All models are trained via standard training. UE
stands for the upper envelope of candidate models.
σ	Model	0.00	0.25	0.5	0.75	1.00	1.25	1.50	1.75	2	ACR
0.25	UESWEEN-7	90.3	74.6	53.4	29.5	0	0	0	0	0	0.517
	SWEEN-7	91.0	76.4	56.8	34.7	0	0	0	0	0	0.547
0.50	UESWEEN-7	72.7	58.1	42.1	28.4	17.7	11.0	6.5	3.1	0	0.498
	SWEEN-7	72.8	59.2	43.9	29.4	19.8	11.9	7.3	3.7	0	0.524
C.3 SWEEN models using candidates with identical architectures
The SWEEN-3 and SWEEN-7 models are all using candidate models with diverse architectures. For a
more comprehensive result, we also experiment with SWEEN models using candidates with identical
architectures. For σ ∈ {0.25, 0.5, 1.0}, We train 8 ResNet-110 models using different random seeds
on CIFAR-10 via the standard training. We then use these models to ensemble SWEEN models.
The results are shown in Table 6 and Figure 3. We can see that SWEEN is still effective in this
scenario and significantly boosts the performance compared to candidate models.
We also run experiments on ImageNet using models with identical structure but with different random
initialization. We train 3 ResNet-50 on ImageNet via the standard training to ensemble the SWEEN
models. Table 7 shows the results. The improvement of SWEEN is substantial compared with the
AVG and UE results.
Figure 3: Radius-accuracy curves of SWEEN models and their candidate models. All candidate
models are using the ResNet-110 architecture and trained via the standard training. (Left) σ = 0.25.
(Middle) σ = 0.50. (Right) σ = 1.00.
22
Under review as a conference paper at ICLR 2021
Table 6: ACA (%) and ACR on CIFAR-10. All candidate models are ResNet-110s trained via the
standard training. UE stands for the upper envelope, which shows the largest ACA and ACR among
the candidate models. AVG stands for the average ACA or ACR of candidate models.
σ	Model	0.00	0.25	0.5	0.75	1.00	1.25	1.50	1.75	2.00	ACR
	AVG	79.9	67.2	50.3	33.5	0	0	0	0	0	0.491
0.25	UE	80.4	68.3	52.0	34.6	0	0	0	0	0	0.496
	SWEEN	83.5	73.0	60.4	43.8	0	0	0	0	0	0.572
	AVG	68.4	58.0	46.1	34.5	24.4	16.2	9.7	4.4	0	0.568
0.50	UE	69.7	59.3	47.1	35.7	24.9	17.6	10.8	5.1	0	0.581
	SWEEN	71.3	63.3	53.1	44.0	32.6	22.9	15.8	9.2	0	0.691
	AVG	51.9	45.0	37.8	30.9	24.7	18.7	13.5	9.9	7.1	0.558
0.50	UE	53.0	46.0	38.6	31.8	25.5	19.3	14.1	10.5	7.7	0.566
	SWEEN	54.1	47.3	41.0	34.7	27.6	22.9	16.7	12.2	9.2	0.623
Table 7: ACA (%) and ACR on ImageNet. All candidate models are ResNet-50s trained via the
standard training. The SWEEN model here contains 3 ResNet-50s. UE stands for the upper envelope,
which shows the largest ACA and ACR among the candidate models. AVG stands for the average
ACA or ACR of candidate models.
σ	Model	0.00	0.25	0.5	0.75	1.00	1.25	1.50	1.75	2.00	ACR
	AVG	56.8	52.1	46.1	42.3	37.5	32.8	28.1	21.6	0	0.723
0.50	UE	57.2	52.4	46.4	42.4	37.8	33.0	28.2	21.8	0	0.727
	SWEEN	60.0	55.2	50.2	46.0	42.6	37.8	33.2	28.4	0	0.816
C.4 Adaptive prediction ensembling
To alleviate the higher execution cost introduced by SWEEN, we apply the previously mentioned
adaptive prediction algorithm to speed up the certification. Experiments are conducted on the
SWEEN-7 models via the standard training on CIFAR-10 and the results are summarized in Table
8. It can be observed that the adaptive prediction successfully reduce the number of evaluations.
However, the performance of the adaptive prediction models is only slightly worse than their vanilla
counterparts.
Table 8: ACA (%) and ACR on CIFAR-10. All models are trained via the standard training. * means
the upper envelope of candidate models.
σ	Model	0.00	0.25	0.5	0.75	1.00	1.25	1.50	1.75	ACR	#evals/img
0.25	Normal	84.2	72.0	58.7	43.0	0	0	0	0	0.560	700,700
	Adaptive	84.3	71.5	57.6	41.2	0	0	0	0	0.549	283,727
0.50	Normal	71.2	63.0	52.2	41.9	31.2	22.9	15.3	8.3	0.678	700,700
	Adaptive	70.9	62.8	52.3	41.6	31.1	22.8	14.5	7.8	0.672	382,426
C.5 The scatter plot of the certified accuracy
This section plots the scatter diagram of the certified accuracy of test data points for SWEEN-7
versus ResNet-110 in Figure 4. Most of the points lie under the line y = x, implying that SWEEN-7
performs superior to ResNet-110.
23
Under review as a conference paper at ICLR 2021
。二 JəNSəɑ
Figure 4: The scatter diagram of the certified accuracy of test data points for SWEEN-7 versus
ResNet-110. σ = 0.50.
C.6 SWEEN versus adversarial attacks
We further investigate the performance of SWEEN models versus AutoAttack (Croce & Hein, 2020),
which is an ensemble of four diverse attacks to reliably evaluate robustness. Similar to Salman et al.
(2019a), we used 128 samples to estimate the smoothed classifier. We share the results below in Table
9. It can be seen that SWEEN can improve the empirical robustness as well.
Table 9: Certified accuracy and empirical accuracy versus AutoAttack on CIFAR-10. All candidate
models are trained via the standard training.
σ	Model	0.00	0.25	0.5	0.75	1.00
SWEEN-3 (certified)	70.9	61.4	50.8	38.3	27.7
SWEEN-3 (AA)	75.0	67.0	58.9	48.4	39.9
0.50 ResNet-20 (AA)	72.5	64.7	55.4	46.2	37.0
ResNet-26 (AA)	74.5	65.4	57.3	46.3	35.7
ResNet-32 (AA)	73.8	64.5	55.3	45.0	35.3
C.7 MACER TRAINING ON CIFAR-10
In this section, we plot the radius-accuracy curves for SWEEN models with candidate models trained
by MACER on CIFAR-10 in Figure 5.
D Figures
24
Under review as a conference paper at ICLR 2021
0.0
o.oo
0.25	0.50	0.75	1.00	1.25	1.50	1.75	2.00
radius
radius
Figure 5: Radius-accuracy curves for SWEEN models with candidate models trained by MACER on
CIFAR-10. (Left) σ = 0.25. (Right) σ = 0.50.
1.0
0.8
0.6
0.4
0.2
0.0
----LeNet
AIexNet
AOaJnOOe pφ≡七① ɔ
0.00	0.25	0.50	0.75	1.00	1.25	1.50	1.75	2.00
radius
Figure 6: Radius-accuracy curves w.r.t. the SWEEN-7 model and all its candidate models under
σ = 0.50. All models are trained via the standard training.
25
Under review as a conference paper at ICLR 2021
Figure 7: Radius-accuracy curves w.r.t. the SWEEN-3 model and all its candidate models under
σ = 0.50. All models are trained via the standard training.
Figure 8: Radius-accuracy curves w.r.t. the SWEEN-7 model, the SWEEN-3 model and the ResNet-
110 under σ = 0.50. All models are trained via the standard training.
26