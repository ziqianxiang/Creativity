Under review as a conference paper at ICLR 2021
Efficient Long-Range Convolutions for Point
Clouds
Anonymous authors
Paper under double-blind review
Ab stract
The efficient treatment of long-range interactions for point clouds is a challenging
problem in many scientific machine learning applications. To extract global infor-
mation, one usually needs a large window size, a large number of layers, and/or a
large number of channels. This can often significantly increase the computational
cost. In this work, we present a novel neural network layer that directly incorpo-
rates long-range information for a point cloud. This layer, dubbed the long-range
convolutional (LRC)-layer, leverages the convolutional theorem coupled with the
non-uniform Fourier transform. In a nutshell, the LRC-layer mollifies the point
cloud to an adequately sized regular grid, computes its Fourier transform, mul-
tiplies the result by a set of trainable Fourier multipliers, computes the inverse
Fourier transform, and finally interpolates the result back to the point cloud. The
resulting global all-to-all convolution operation can be performed in nearly-linear
time asymptotically with respect to the number of input points. The LRC-layer is a
particularly powerful tool when combined with local convolution as together they
offer efficient and seamless treatment of both short and long range interactions.
We showcase this framework by introducing a neural network architecture that
combines LRC-layers with short-range convolutional layers to accurately learn the
energy and force associated with a N -body potential. We also exploit the induced
two-level decomposition and propose an efficient strategy to train the combined
architecture with a reduced number of samples.
1	Introduction
Point-cloud representations provide detailed information of objects and environments. The develop-
ment of novel acquisition techniques, such as laser scanning, digital photogrammetry, light detection
and ranging (LIDAR), 3D scanners, structure-from-motion (SFM), among others, has increased
the interest of using point cloud representation in various applications such as digital preservation,
surveying, autonomous driving (Chen et al., 2017), 3D gaming, robotics (Oh & Watanabe, 2002), and
virtual reality (Park et al., 2008). In return, this new interest has fueled the development of machine
learning frameworks that use point clouds as input. Historically, early methods used a preprocessing
stage that extracted meticulously hand-crafted features from the point cloud, which were subsequently
fed to a neural network (Chen et al., 2003; Rusu et al., 2008; Rusu et al., 2009; Aubry et al., 2011),
or they relied on voxelization of the geometry (Savva et al., 2016; Wu et al., 2015; Riegler et al.,
2017; Maturana & Scherer, 2015). The PointNet architecture (Qi et al., 2017) was the first to handle
raw point cloud data directly and learn features on the fly. This work has spawned several related
approaches, aiming to attenuate drawbacks from the original methodology, such as PointNet++ (Qi
et al., 2017), or to increase the accuracy and range of application (Wang et al., 2019; Zhai et al., 2020;
Li et al., 2018; Liu et al., 2019).
Even though such methods have been quite successful for machine learning problems, they rely on
an assumption of locality, which may produce large errors when the underlying task at hand exhibits
long-range interactions (LRIs). To capture such interactions using standard convolutional layers,
one can use wider window sizes, deeper networks, and/or a large number of features, which may
increase the computational cost significantly. Several approaches have been proposed to efficiently
capture such interactions in tasks such as semantic segmentation, of which the ideas we briefly
summarize below. In the multi-scale type of approaches, features are progressively processed and
merged. Within this family, there exist several variants, where the underlying neural networks can
1
Under review as a conference paper at ICLR 2021
be either recursive neural networks (Ye et al., 2018), convolutional layers (Xu et al., 2019; Xu
et al., 2018) or autoencoders (Yang et al., 2018; Deng et al., 2018). Some works have proposed
skip connections, following an U-net (Ronneberger et al., 2015) type architecture (Zhou & Tuzel,
2018; Qi et al., 2017), while others have focused on using a tree structure for the clustering of the
points (Klokov & Lempitsky, 2017; Zeng & Gevers, 2018; Gadelha et al., 2018), or using an reference
permutohedral lattices to compute convolutions (Jampani et al., 2016) whose results are interpolated
back to the point cloud (Su et al., 2018). Although these methods have been shown to be successful
in a range of applications, when the task at hand presents symmetries, such as rotation, translation,
and permutation invariance, there is no systematic framework to embed those symmetries into the
algorithmic pipelines. Another line of work, relies on interpreting the point cloud as a graph and use
spectral convolutions (Bruna et al.; Defferrard et al., 2016), whose cost can scale super-linearly when
dealing with LRIs.
In applications of machine learning to scientific computing, several classical multilevel matrix
factorizations have been rewritten in the context of machine learning (Kondor et al., 2014), which
have been adapted to handle long-range interactions in the context of end-to-end maps using voxelized
geometries in (Fan et al., 2019b;a; Khoo & Ying, 2019; Fan & Ying, 2019) resulting in architectures
similar to U-nets (Ronneberger et al., 2015), which have been extended to point clouds in (Li et al.,
2020). Due to underlying voxelization of the geometry, it may be difficult for these networks to
generalize when the resolution of the voxelization changes.
The efficient treatment of LRI for point clouds is also a prominent problem in many physical
applications such as molecular modeling and molecular dynamics simulation. While long-range
electrostatic interactions are omnipresent, it has been found that effectively short-ranged models
can already describe the N -body potential and the associated force field (Behler & Parrinello, 2007;
Zhang et al., 2018a;b) for a wide range of physical systems. There have also been a number of
recent works aiming at more general systems beyond this regime of effective short-range interactions,
such as the work of Ceriotti and co-workers (Grisafi & Ceriotti, 2019; Grisafi et al.; Nigam et al.,
2020; Rossi et al., 2020), as well as the works of (Yao et al., 2018; Ko et al., 2009; Hirn et al., 2017;
Rupp et al., 2012; Huo & Rupp; Deng et al., 2019; Bereau et al., 2018; Zhang et al., 2019). The
general strategy is to build parameterized long-range interactions into the kernel methods or neural
network models, so that the resulting model can characterize both short-range, as well as long-range
electrostatic interactions. In the neural network context, the computational cost of treating the LRIs
using these methods can grow superlinearly with the system size.
The idea of this work is aligned with the approaches in the molecular modeling community, which
constructs a neural network layer to directly describe the LRI. In particular, we present a new long-
range convolutional (LRC)-layer, which performs a global convolutional operation in nearly-linear
time with respect to number of units in the layer. By leveraging the non-uniform Fourier transform
(NUFFT) (Dutt & Rokhlin, 1993; Greengard & Lee, 2004; Barnett et al., 2019) technique, the
LRC-layer implements a convolution with a point-wise multiplication in the frequency domain with
trainable weights known as Fourier multipliers. The NUFFT is based on the regular fast Fourier
transform (FFT) (Cooley & Tukey, 1965) with a fast gridding algorithms, to allow for fast convolution
on unstructured data. This new LRC-layer provides a new set of descriptors that can seamlessly
satisfy relevant symmetries. For instance, when the kernel of the LRI is rotationally invariant, such
symmetry can be directly built into the parameterization of the Fourier kernel. Such descriptors can
be used in tandem with the descriptors provided by short-range convolutional layers to improve the
performance of the neural network.
Efficient training of a neural network with the LRC-layer for capturing the information of LRIs is
another challenging problem. Short-range models can often be trained with data generated with a
relatively small computational box (called the small-scale data), and they can be seamlessly deployed
in large-scale systems without significantly increasing the generalization error. On the other hand,
long-range models need to be trained directly with data generated in a large computational box (called
the large-scale data), and the generation process of such large-scale data can be very expensive. For
instance, in molecular modeling, the training data is often generated with highly accurate quantum
mechanical methods, of which the cost can scale steeply as O(N α), where N is the system size and
α ≥ 3. Therefore it is desirable to minimize the number of samples with a large system size. In many
applications, the error of the effective short-range model is already modestly small. This motivates us
to propose a two-scale training strategy as follows. We first generate many small-scale data (cheaply
2
Under review as a conference paper at ICLR 2021
and possibly in parallel), and train the network without the LRC-layer. Then we use a small number
of large-scale data, and perform training with both the short- and long-range convolutional layers.
In order to demonstrate the effectiveness of the LRC-layer and the two-scale training procedure,
we apply our method to evaluate the energy and force associated with a model N -body potential
that exhibit tunable short- and long-range interactions in one, two and three dimensions. The input
point cloud consists of the atomic positions, and the output data include the N -body potential,
local potential, and the force (derivative of the N -body potential with respect to atomic positions).
In particular, the local potential and the force can be viewed as point clouds associated with the
atomic positions. The evaluation of the N -body potential is a foundational component in molecular
modeling, and LRI plays an important role in the description of ionic systems, macroscopically
polarized interfaces, electrode surfaces, and many other problems in nanosciences (French et al., 2010).
Our result verifies that the computational cost of the long-range layer can be reduced from O(N1 2)
using a direct implementation, to O(N) (up to logarithmic factors) using NUFFT. Furthermore,
we demonstrate that the force, i.e. the derivatives of the potential with respect to all inputs can be
evaluated with O(N) cost (up to logarithmic factors). In terms of sample efficiency, we find that
for the model problem under study here, the two-scale training strategy can effectively reduce the
number of large-scale samples by over an order of magnitude to reach the target accuracy. This can
be particularly valuable in the context of molecular modeling, where accurate data are often obtained
from first principle electronic structure calculations. Such calculations are often very expensive for
large scale systems, and the number of large-scale samples is thus limited.
2	Long-range Convolutional Layer
Convolutional layers are perhaps the most important building-block in machine learning, due to their
great success in image processing and computer vision. A convolutional layer convolves the input,
usually an array, with a rectangular mask containing the trainable parameters. When the mask can be
kept small (for example while extracting localized features), the convolution layer is highly efficient
and effective. A different way for computing a convolution is to use the convolutional theorem as
follows: (1) compute the Fourier transform of the input, (2) multiply with the Fourier transform of the
mask, i.e.m the Fourier multiplier, and (3) inverse Fourier transform back. In this case, the trainable
parameters are the DOFs of the Fourier multipliers and the Fourier transforms are computed using the
fast Fourier transform (FFT). This alternative approach is particularly attractive for smooth kernels
with large support (i.e., smooth long-range interactions) because the computational cost does not
increase with the size of the mask. To the best of our knowledge, this direction has not been explored
for LRIs and below we detail now to apply this to point clouds.
Given a point cloud {xi}iN=1 ⊂ Rd and scalar weights {fi}iN=1, we consider the problem of computing
the quantity Ui := PN=ι φθ(Xi - Xj)fj at each Xi. Here the function φθ(∙) is the kernel with a
generic trainable parameter θ. At first glance the cost of this operation scales as O(N 2): we need to
evaluate ui for each point Xi, which requires O(N) work per evaluation. By introducing a generalized
function f (y) = Pi f「δ(y — Xi) and defining a function U(X) = ʃ φθ(X - y)f (y)dy, one notices
that ui is the value of u(X) at X = Xi. The advantage of this viewpoint is that one can now invoke the
connection between convolution and Fourier transform
U⑻=φθ(k) ∙f(k),	⑴
ʌ
where φθ(k) is a trainable Fourier multiplier. This approach is suitable for point clouds since the
trainable parameters are decoupled from the geometry of the point cloud. To make this approach
practical, one needs to address two issues: (1) the non-uniform distribution of the point cloud and (2)
ʌ
how to represent the multiplier φθ (k).
Non-uniform distribution of the point cloud Equation 1 suggests that one can compute the
convolution directly using the convolution theorem, which typically relies on the FFT to obtain a
low-complexity algorithm. Unfortunately, {Xi}iN=1 do not form a regular grid, thus FFT can not be
directly used. We overcome this difficulty by invoking the NUFFT1 (Dutt & Rokhlin, 1993), which
serves as the corner-stone of our instance of the LRC-layer2.
1See Appendix C.2 for further details.
2We point out, that one could in practice use an fast summation algorithm, such as the fast multipole method
(FMM) introduced by Greengard & Rokhlin (1987), to evaluate ui . This would results in the same complexity if
3
Under review as a conference paper at ICLR 2021
Algorithm 1 Long-range convolutional layer
Input: {xi}N=ι, {fi}N=ι	N
Output: {xi}iN=1, {ui}iN=1, where ui = PjN=1 fjφθ(xi - xj).
1:	Define the generalized function: f(x) = PjN=1 fjδ(x - xj)
2:	Mollify the Dirac deltas: fτ (x) = PjN=1 fjgτ(x - xj), where gτ is defined in Appendix C.2
3:	Sample in a regular grid: f (χ') = PN=i gτ(x' - Xj) for χ' in grid of size LFFT in each dim
4:	Compute FFT: Fτ (k) = FFT(fτ)(k)
5:	Re-scale the signal: F(k) = Pnek2τFr (k)
ʌ
6:	Multiply by Fourier multipliers: v(k) = φθ(k) ∙ F(k)
7:	Re-scale the signal: ^-τ(k) = Pnek2τv(k)
8:	Compute IFFT: U-T(xg) = IFFT(V-T)(x) for X' on the regular grid
9:	Interpolate to the point cloud: Ui = U(Xi) = U-T * gτ(Xi)
The LRC-layer is summarized in Alg. 1, where τ is chosen following Dutt & Rokhlin (1993). The
inputs of this layer are the point cloud {Xi}iN=1 and the corresponding weights {fi}iN=1. The outputs
are Ui ≡ U(Xi) for i = 1, ..., N. The number of elements in the underlying grid NFFT = LdFFT is
chosen such that the kernel is adequately sampled and the complexity remains low. As shown in
Appendix C.5, one only needs a relatively small LFFT. Even though the precise number is problem-
specific, given that the goal is to approximate LRIs that are supposedly smooth, it can be captured
with a relatively small number of Fourier modes.
The LRC-layer is composed of three steps: (1) It computes the Fourier transform from the point cloud
to a regular grid using the NUFFT algorithm (lines 2 - 5 in Alg. 1 and showcased in Fig. 2). (2) It
multiplies the result by a set of trainable Fourier multipliers (line 6 in Alg. 1). (3) It computes the
inverse Fourier transform from the regular grid back to the point cloud (lines 7 - 9 in Alg. 1).
Within the LRC-layer in Alg. 1, the only trainable component is the parameter θ of the Fourier
ʌ
multiplier φθ(k). The remaining components, including the mollifier g「(∙) and the Cartesian grid size,
are taken to be fixed. One can, in principle, train them as well, but it comes with a much higher cost.
Among the steps of Alg. 1, the sampling operator, the rescaling operator, the interpolation operator,
and the Fourier transforms, are all linear and non-trainable. Therefore, derivative computations of
backpropagation just go through them directly.
Alg. 1 is presented in terms of only one single channel or feature dimension, i.e., fj ∈ R and Ui ∈ R.
However, it can be easily generalized to multiple channels, for example fj ∈ Rd1 and Ui∈ Rd2. In
ʌ
this case, the Fourier multiplier φθ(k) at each point k is a d2 × d1 matrix, and all Fourier transforms
are applied component-wise.
Representation of the Fourier multiplier A useful feature of the LRC-layer is that it is quite easy
to impose symmetries on the Fourier multipliers. For example, if the convolution kernel φθ(∙) is
constrained to have parity symmetry, rotational symmetry, smoothness or decay properties, these
ʌ
constraints can be imposed accordingly on the coefficients of the Fourier multipliers φθ(k). When the
size of the training data is limited, it is often necessary to reduce the number of trainable parameters
in order to regularize the kernel. For example, we may parameterize the Fourier multiplier as a
linear combination of several predetermined functions on the Fourier grid. This is the procedure
used in molecular modeling (Grisafi & Ceriotti, 2019; Yao et al., 2018; Ko et al., 2009), and also in
our numerical examples in equation 7. We also remark that the LRC-layer described here can be
applied to point clouds a way similar to a standard convolution layer applied to images and multiple
LRC-layers can be composed on top of each other.
the kernel is fixed. However, in order for the kernel to be trainable, this would require a different algorithm for
each iteration, including the computation of the derivatives, thus increasing the computational cost and rendering
the implementation significantly more cumbersome.
4
Under review as a conference paper at ICLR 2021
ft
X	N	N
{(fi，xi )}i=i -k fτ (X)= X fj gτ(X - xj )-fτ(X' )=£gτ(X' - Xj )
j=1	j=1
F (k) = A ek2T Fτ(k) —	F") = FFT(fτ )(k)
Figure 1: Diagram of the NUFFT. Starting from the cloud point {xi }N=1, We form the mollified
function fτ, sample it in a regular grid, compute the Fourier transform FT (k) of the sampled function.
Finally in order to obtain F(k), We rescale the signal to undo the spatial convolution.
3	LEARNING THE N -BODY POTENTIAL
To demonstrate the effectiveness of the LRC-layer, We consider the problem of learning the energy
and force associated With a model N -body potential in the context of molecular modeling. As
mentioned in Section 1, the potential evaluation often invokes expensive ab-initio calculations that
one Would like to bypass for efficiency reasons.
The setup of this learning problem is as folloWs. First, We assume access to a black-box model
potential, Which consists of both short- and long-range interactions. HoWever, internal parameters of
the potential are inaccessible to the training architecture and algorithm. A set of training samples
are generated by the model, Where each sample consists of a configuration of the points {xi } along
With the potential and force. Second, We set up a deep neural netWork that includes (among other
components) the LRC-layer for addressing the long-range interaction. This netWork is trained With
stochastic gradient type of algorithms using the collected dataset and the trained netWork can be used
for predicting the potential and forces for neW point cloud configurations. These tWo components are
described in the folloWing tWo subsections in detail.
3.1	Model problem and Data Generation
Model We suppose that Ω = [0, L]d, and We denote the point cloud by X = {xi }n=1 ⊂ Ω ⊂ Rd, for
d = 1, 2, or 3. We define the total energy, the local potential and the forces acting on particle j by
U = 工	ψ(xi- Xj),	Uj (X) =工ψ(xi-x),	and	Fj = -∂χ Uj (x)∣x=Xj,⑵
1≤i<j≤N	i6=j
respectively, Where the interaction kernel ψ(r) is a smooth function, besides a possible singularity at
the origin and decreases as kr k → ∞.
Sampling We define a snapshot as one configuration3 of particles, x' = {xj'] }jN=1, together with
the global energy U ['] and the forces F['], where ' is the index representing the number in the
training/testing set. We sample the configuration of particles x' randomly, with the restriction that
two particles can not be closer than a predetermined value δmin in order to avoid the singularity. After
an admissible configuration is computed we generate the energy and forces following Appendix B.
This process is repeated until obtaining Nsample snapshots.
3For the sake of clarity, we suppose that the number of particles at each configuration is the same.
5
Under review as a conference paper at ICLR 2021
3.2	Architecture
Our network architecture consists of separate descriptors for the short- interactions and long-range
interactions, respectively. To capture the short-range interaction, we compute a local convolution
using for each point only its neighboring points within a ball of predetermined radius. For the
long-range interactions, we compute an all-to-all convolution using the LRC-layer introduced in
Section 2, whose output is distributed to each particle and then fed to a sequence of subsequent layers.
Short-range descriptor For a given particle xi , and an interaction radius R, we define Ii , the
interaction list ofxi, as the indices j such that kxi - xj k < R, i.e., the indices of the particles that are
inside a ball of radius R centered at xi . Thus for each particle xi we build the generalized coordinates
si,j = xi - xj , and the short-range descriptor
Dsi r = X fθ (si,j),	(3)
j∈Ii
where fθ : Rd → Rmsr is a function represented by a neural network specified in Appendix C.1,
where msr is the number of short-range features. By construction fθ(s) is smooth and it satisfies
fθ(s) = 0 for ksk > R.
Long-range descriptor We feed the LRC-layer with the raw point cloud represented by {xi}iN=1
with weights {fi}iN=1, which for simplicity can be assumed to be equal to one here, i.e.,
fi = 1 for i = 1, ..., N. The output of the layer is a two-dimensional tensor uk(xi) with
i = 1, . . . , N and k = 1, . . . , Kchnls. Then for each xi, its corresponding slice given by the
vector [u1(xi), u2(xi),…,uKchnls (xi)], is fed to a function gθ : RKchnls → Rmlr, which is repre-
sented by a neural network with non-linear activation functions. Here θ is a generic set of trainable
parameters and mlr is the number of long-range features. The descriptor for particle xi , which
depends on all the other particles thanks to the LRC-layer, is defined by
Dlr = gθ(u1(xi),u2(xi),…，uκchnls(xi))	(4)
Short-range network When only the short-range interaction is present, the short-range descriptor
for each particle is fed particle-wise to a fitting network Fsr : Rmsr → R. In this case Fsr (Dsi r ) only
depends on particle xi and its neighbors. Finally, the contributions from each particle are accumulated
so the short-range neural network (NN) energy and forces are given by
N
UsNrN =	Fsr(Dsir)	and	(FsNrN)j = -∂xjUsNrN	(5)
i=1
respectively (see Fig. 2(left)). The derivatives are computed using Tensorflow (Abadi et al., 2015)
directly. This network as shown by (Zhang et al., 2018b) is rotation, translation, and permutation
invariant (Zaheer et al., 2017).
We point out that this architecture can be understood as a non-linear local convolution: for each
particle i one applies the same function fθ to each of its neighbors. The result is then pooled into the
descriptor Dsir, then processed locally by Fsr (akin to a non-linear convolution with a filter of width
one), and finally pooled globally into UsNrN .
Full-range network When both the short-range and long-range interactions are present, the long
range descriptor and the local descriptor are combined and fed particle-wise to a fitting network
F : Rmsr+mlr → R to produce the overall neural network (NN) energy and forces
N
UNN =	F(Dsir,Dlir),	and	(FNN)j = -∂xj U NN	(6)
i=1
respectively (see Fig. 2(right)). Following Section 2, the long-range descriptor is translation invariant
by design and can be easily made rotation invariant. Furthermore, it is well known (Zaheer et al.,
2017) that this construction is permutation invariant. Further details on the implementation of the
network can be found in Appendix C.3. From the structures shown in Fig. 24, it is clear that we can
recover the first architecture from the second, by zeroing some entries at the fitting network, and
removing the LRC-layer.
4We provide more detailed schematics in Fig. 6 and Fig. 7 in Appendix C.1
6
Under review as a conference paper at ICLR 2021
Figure 2: (left) The short-range network architecture. (right) The full-range network architecture.
Finally, let us comment on the inference complexity of the proposed network where, for simplicity we
assume that O(Kchnls) = O(msr) = O(mlr) = O(1), and that the depth of the neural networks
is O(1). The cost for computing UsNrN is O(N), provided that each particle has a bounded number
of neighbors. The complexity for computing the forces also scales linearly in N , albeit with higher
constants. The complexity of computing both UNN and associated forces5 is O(N + NFFT log NFFT).
4	Numerical results
The loss function is the mean squared error of the forces N 1 ɪ PN=Imple PN=Ill瑁'(χi']) - F['] ∣∣2,
where the i-index runs on the points of each snapshot, and ` runs on the test samples. We also
generate 100 snapshots of data to test the performance of network. This particular loss could lead to
shift the potential energy by up to a global constant, which can be subsequently fixed by including
the error of the energy in the loss (Zhang et al., 2018b). For the testing stage of We use the relative '2
error of the forces as metric, which is defined as erel := JP' i kF['] — FΘΝν (xi'] )k2/ P' i kF['] k2.
The standard training parameters are listed in Appendix C.4.
The experiments shown in the sequel are designed to provide a fair comparison with state-of-the-art
methods for localized interactions. They showcase that, by adding a single LRC-layer, one can
outperform these methods significantly.
The kernels ψ used in the experiment typically exhibit two interaction lengths: ψ(∙) ≡ ɑ1 ψμ1 (•) +
α2ψμ2 (∙), where each of ψμ1 and ψμ2 is either a simple exponential kernel or screened-Coulomb
kernel (also known as the Yukawa kernel). For each of ψμ1 and ψμ2, the superscripts denote the
reciprocal of the interaction length, i.e., length scale 〜μ-1 or 〜μ-1. Without loss of generality,
μ1 > μ2, so that μ1 corresponds to the short-range scale and μ2 the long-range scale. We also assume
that 0 ≤ α2 ≤ α1 and α1 + α2 = 1, so that the effect of the long-range interaction can be smaller
in magnitude compared to that of the short-range interaction. In the special case of α2 = 0, the
kernel exhibits only a single scale 〜μ-1. The precise definition of the kernel depends on the spatial
dimension and boundary conditions, which are explained in Appendix B.
For a fixed set of kernel parameters (μ1,μ2, α1, α2), we consider two types of data: large- and
small-scale data, generated in the domains Ωlr and Ωsr respectively (details to be defined in each
experiment).
The Fourier multiplier within the LRC-layer is parameterized as
工公	4πβ
φβ入 (k) =呼+12,
(7)
where β and λ are trainable parameters. This is a simple parameterization, and a more complex
model can be used as well with minimal changes to the procedure. For all experiments shown below,
two kernel channels are used and as a result there are only four trainable parameters in the LRC-layer.
The numerical results aim to show namely two properties: i) the LRC-layer is able to efficiently
capture LRIs, and ii) the two-scale training strategy can reduce the amount of large-scale data
significantly. To demonstrate the first property, we gradually increase the interaction length of the
kernel. The accuracy of the short-range network with a fixed interaction radius is supposed to decrease
rapidly, while using the LRC-layer improves the accuracy significantly. To show the second property,
we generate data with two interaction lengths and train the full-range network using the one- and
5See Appendix C.2 and C.3 for further details.
7
Under review as a conference paper at ICLR 2021
Table 1: Relative testing error for trained screened-Coulomb type 1D models with α1 = 1, α2 = 0,
and varying μι. Notice that μ2 can be arbitrary here given that α2 = 0.
	μι	0.5	1.0	2.0	5.0	10.0
short-range network	0.05119	0.02919	0.00597	0.00079	0.00032
full-range network	0.00828	0.00602	0.00336	0.00077	0.00054
Figure 3: (left) Testing error of the trained 1D model with respect to the number of snapshots using
the one- and two-scale training strategies using data generated with the screened-Coulomb potential
and parameters μι = 5.0, μ2 = 0.5 (right) normalized wall-time for the LRC and the direct all-to-all
computation.
two-scale strategies. Finally, we also aim to demonstrate that the LRC-layer is competitive against a
direct convolution in which the all-to-all computation is performed explicitly.
1D In the first set of experiments, the domain Ω = [0,5], N = 20 and Nsample = 1000, where
Nsample is the number of snapshots and N is the total number of points in each snapshot. For the
kernel, We set a? and vary μι to generate datasets at different interaction lengths. For each dataset We
train both short-range and full-range networks using the one-scale data. The results are summarized in
Table 1, where we can observe that as the characteristic interaction length increases, the accuracy of
the short-range network decreases while using the full-range network can restore the accuracy. This
experiment shows that local networks are often highly accurate when the interactions are localized,
but the accuracy quickly deteriorates as the interaction length increases (i.e. as μι decreases).
For the second set of experiments we used two sets of kernel parameters: one heavily biased towards
a localized interaction length, and another in which both interaction lengths are equally weighted.
For each set of kernel parameters, we generate 10,000 small-scale snapshots using Ωsr = [0, 5] and
N = 20, and a large number of large-scale snapshots using Ωlr = [0, 50] and N = 200 particles.
The interaction radius R = 1.5, δmin = 0.05, and NFFT is 501. We train the network with the one-
and two-scale training strategies described in the prequel. Fig. 3 (left) depicts the advantage of using
the two-scale training strategy: we obtain roughly the same accuracy at a fraction of the number of
large-scale training samples. We observe that when the number of large-scale training samples is
sufficiently large, the resulting test accuracy is independent of the training strategy. We also observe
that the training dynamics is stable with respect to different random seeds.
We compare the LRC-layer with a direct all-to-all computation.We benchmark the wall time of both
layers, with increasingly number of particles. To account for implementation effects we normalize
the wall times in Fig. 3 (right) and the results corroborate the complexity claims made in Section 2.
2D We perform the same experiments as in the one-dimensional case. We fix Ω = [0,15]2, N = 450
and Nsample = 10000. The results are summarized in Table 2, which shows that as μ decreases, the
full-range network outperforms the short-range one.
For the second set of experiments, R = 1.5, δmin = 0.05, and NFFT is 312. For the small-scale
data, Ωsr = [0, 3]2, N = 18, and Nsample = 10,000. For the large-scale data, Ωlr = [0,15]2 ,
N = 450. Similarly to the 1D case, we train the networks with both strategies using different amounts
of large-scale data. The results summarized in Fig. 4 show that the two-scale strategy efficiently
captures the long-range interactions with only a small number of the long-range training samples.
8
Under review as a conference paper at ICLR 2021
Table 2: Relative testing error for trained screened-Coulomb type 2D models with α1 = 1, α2 = 0,
and varying μι. Again μ2 can be arbitrary given that α2 = 0.
	μι	1.0	2.0	5.0	10.0
short-range network	0.07847	0.02332	0.00433	0.00242
full-range network	0.00785	0.00526	0.00363	0.00181
Figure 4: Testing error of the trained 2D model with respect to the number of snapshots using the
one- and two-scale training strategies using both screened-Coulomb and exponential potentials with
μι = 10, μ2 = 1 : (left) aι = 0.9, and a2 = 0.1; and (right) aι = 0.5, and a2 = 0.5.
Analogously to the 1D case, we can observe that for sufficiently large-scale training samples the
resulting test accuracy is identical regardless of the training strategy used. Also similar to Fig. 3 (left),
we find that the lowest achievable test error is larger in Fig. 4 (right, with a larger α2) than that in
Fig. 4 (left, with a smaller α2). Nonetheless, we observe that the test error of the two-scale training
strategy becomes less sensitive with respect to the number of training samples when α2 becomes
larger, i.e. the LRI becomes more prominent.
3D The domain Ω is [0,3]3 with 2 points in each of the 27 unit cells. The other parameters are the
interaction radius R = 1.0, δmin = 0.1, and Nsample = 1000. The Fourier domain used is of size
NFFT = 253 . The results in Table 3 demonstrate that full-range network is capable of maintaining
good accuracy for a wide range of characteristic interactions lengths.
5	Conclusion
We have presented an efficient long-range convolutional (LRC) layer, which leverages the non-
uniform fast Fourier transform (NUFFT) to reduce the cost from quadratic to nearly-linear with
respect to the number of degrees of freedom. We have also introduced a two-scale training strategy
to effectively reduce the number of large-scale samples. This can be particularly important when
the generation of these large-scale samples dominates the computational cost. While this paper
demonstrates the effectiveness of the LRC-layer for computing the energy and force associated with a
model N -body potential, we expect the LRC-layer to become a useful component in designing neural
networks for modeling real chemical and materials systems, where the LRI cannot be accurately
captured using short ranged models. We also expect that the LRC-layer can be a useful tool for a
wide range of machine learning (such as regression and classification) tasks.
Table 3: Relative testing error for trained exponential type 3D models with α1 = 1, α2 = 0, and
varying μι. Again μ2 can be arbitrary given that α2 = 0.
	μι	5	7.5	10
short-range network	0.06249	0.01125	0.00175
full-range network	0.00971	0.00411	0.00151
9
Under review as a conference paper at ICLR 2021
References
M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. Corrado, A. Davis, J. Dean,
M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz,
L. Kaiser, M. Kudlur, J. Levenberg, D. Mane, R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster,
J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P Tucker, V. Vanhoucke, V. Vasudevan, F. Viegas,
O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng. TensorFlow: Large-scale
machine learning on heterogeneous systems, 2015.
M. Aubry, U. Schlickewei, and D. Cremers. The wave kernel signature: A quantum mechanical
approach to shape analysis. In 2011 IEEE International Conference on Computer Vision Workshops
(ICCV),pp.1626-1633, 2011.
A. H. Barnett, J. Magland, and L. af Klinteberg. A parallel nonuniform fast Fourier transform library
based on an “exponential of semicircle" kernel. SIAM J. Sci. Comput., 41(5):C479-C504, 2019.
J. Behler and M. Parrinello. Generalized neural-network representation of high-dimensional potential-
energy surfaces. Phys. Rev. Lett., 98:146401, 2007.
T. Bereau, R. A. DiStasio, A. Tkatchenko, and O. A. von Lilienfeld. Non-covalent interactions across
organic and biological subsets of chemical space: Physics-based potentials parametrized from
machine learning. J. Chem. Phys., 148(24):241706, 2018.
J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun. Spectral networks and locally connected networks
on graphs. arXiv:1312.6203.
D. Chen, X. Tian, Y. Shen, and O. Ming. On visual similarity based 3D model retrieval. Computer
Graphics Forum, 22(3):223-232, 2003.
X. Chen, H. Ma, J. Wan, B. Li, and T. Xia. Multi-view 3D object detection network for autonomous
driving. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp.
6526-6534, 2017.
J. W. Cooley and J. W. Tukey. An algorithm for the machine calculation of complex Fourier series.
Math. Comput., 19(90):297-301, 1965.
M. Defferrard, X. Bresson, and P. Vandergheynst. Convolutional neural networks on graphs with
fast localized spectral filtering. In Advances in Neural Information Processing Systems 29, pp.
3844-3852. 2016.
H. Deng, T. Birdal, and S. Ilic. PPF-FoldNet: Unsupervised learning of rotation invariant 3D local
descriptors. In Proceedings of the European Conference on Computer Vision (ECCV), September
2018.
Z. Deng, C. Chen, X.G. Li, and S. P. Ong. An electrostatic spectral neighbor analysis potential for
lithium nitride. NPJ Comput. Mater., 5, 2019.
A. Dutt and V. Rokhlin. Fast fourier transforms for nonequispaced data. SIAM J. Sci. Comput., 14(6):
1368-1393, 1993.
Y Fan and L. Ying. Solving optical tomography with deep learning. arXiv:1910.04756, 2019.
Y. Fan, J. Feliu-Faba, L. Lin, L. Ying, and L. Zepeda-Nunez. A multiscale neural network based on
hierarchical nested bases. Res. Math. Sci., 6(2):21, Mar 2019a.
Y. Fan, L. Lin, L. Ying, and L. Zepeda-Nunez. A multiscale neural network based on hierarchical
matrices. Multiscale Model. & Sim., 17(4):1189-1213, 2019b.
Roger H. French, V. Adrian Parsegian, Rudolf Podgornik, Rick F. Rajter, Anand Jagota, Jian Luo,
Dilip Asthagiri, Manoj K. Chaudhury, Yet Ming Chiang, Steve Granick, Sergei Kalinin, Mehran
Kardar, Roland Kjellander, David C. Langreth, Jennifer Lewis, Steve Lustig, David Wesolowski,
John S. Wettlaufer, Wai Yim Ching, Mike Finnis, Frank Houlihan, O. Anatole Von Lilienfeld,
Carel Jan Van Oss, and Thomas Zemb. Long range interactions in nanoscale science. Reviews of
Modern Physics, 82(2):1887-1944, 2010. ISSN 00346861. doi: 10.1103/RevModPhys.82.1887.
10
Under review as a conference paper at ICLR 2021
M. Gadelha, R. Wang, and S. Maji. Multiresolution tree networks for 3d point cloud processing. In
Proceedings of the European Conference on Computer Vision (ECCV), September 2018.
L. Greengard and J. Lee. Accelerating the nonuniform fast fourier transform. SIAM Review, 46(3):
443-454, 2004.
L.	Greengard and V. Rokhlin. A fast algorithm for particle simulations. J. Comput Phys., 73:325-348,
1987.
A. Grisafi and M. Ceriotti. Incorporating long-range physics in atomic-scale machine learning. J.
Chem. Phys., 151(20):204105, 2019.
A. Grisafi, J. Nigam, and M. Ceriotti. Multi-scale approach for the prediction of atomic scale
properties. arXiv:2008.12122.
M.	Hirn, S. Mallat, and N. Poilvert. Wavelet scattering regression of quantum chemical energies.
Multiscale Model Simul., 15(2):827-863, 2017.
H.	Huo and M. Rupp. Unified representation of molecules and crystals for machine learning.
arXiv:1704.06439.
V.	Jampani, M. Kiefel, and P. V. Gehler. Learning sparse high dimensional filters: Image filtering,
dense CRFs and bilateral neural networks. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), June 2016.
Y.	Khoo and L. Ying. SwitchNet: A neural network model for forward and inverse scattering
problems. SIAM J. Sci. Comput., 41(5):A3182-A3201, 2019.
D. Kingma and J. Ba. Adam: a method for stochastic optimization. In Proceedings of the International
Conference on Learning Representations (ICLR), May 2015.
R. Klokov and V. Lempitsky. Escape from cells: Deep Kd-networks for the recognition of 3D point
cloud models. In 2017 IEEE International Conference on Computer Vision (ICCV), pp. 863-872,
2017.
T. W. Ko, J. A. Finkler, S. Goedecker, and J. Behler. A fourth-generation high-dimensional neural net-
work potential with accurate electrostatics including non-local charge transfer. arXiv:2009.06484,
2009.
R. Kondor, N. Teneva, and V. Garg. Multiresolution matrix factorization. volume 32 of Proceedings
of Machine Learning Research, pp. 1620-1628, 2014.
Y. Li, R. Bu, M. Sun, W. Wu, X. Di, and B. Chen. PointCNN: Convolution on x-transformed points.
In Advances in Neural Information Processing Systems 31, pp. 820-830. 2018.
Z. Li, N. Kovachki, K. Azizzadenesheli, B. Liu, K. Bhattacharya, A. Stuart, and A. Anandkumar.
Multipole graph neural operator for parametric partial differential equations. arXiv:2006.09535,
2020.
Y. Liu, B. Fan, S. Xiang, and C. Pan. Relation-shape convolutional neural network for point cloud
analysis. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp.
8887-8896, 2019.
D. Maturana and S. Scherer. Voxnet: A 3D convolutional neural network for real-time object
recognition. In 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),
pp. 922-928, 2015.
J. Nigam, S. Pozdnyakov, and M. Ceriotti. Recursive evaluation and iterative contraction of N-body
equivariant features. J. Chem. Phys., 153(12):121101, 2020.
Y.J. Oh and Y. Watanabe. Development of small robot for home floor cleaning. In Proceedings of the
41st SICE Annual Conference, volume 5, pp. 3222-3223, 2002.
11
Under review as a conference paper at ICLR 2021
Y. Park, V. Lepetit, and W. Woo. Multiple 3D object tracking for augmented reality. In Proceedings
of the 7th LEEE/ACM International Symposium on Mixed and Augmented Reality,pp. 117-120,
2008.
C. R. Qi, H. Su, K. Mo, and L. J. Guibas. Pointnet: Deep learning on point sets for 3D classification
and segmentation. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
pp. 77-85, 2017.
C. R. Qi, L. Yi, H. Su, and L. J. Guibas. Pointnet++: Deep hierarchical feature learning on point
sets in a metric space. In Advances in Neural Information Processing Systems 30, pp. 5099-5108,
2017.
G. Riegler, A. O. Ulusoy, and A. Geiger. Octnet: Learning deep 3D representations at high resolutions.
In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6620-6629,
2017.
O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical image
segmentation. In Medical Image Computing and Computer-Assisted Intervention - MICCAI2015,
pp. 234-241, Cham, 2015. Springer International Publishing.
K. Rossi, V. Juraskova, R. Wischert, L. Garel, C. Corminboeuf, andM. Ceriotti. Simulating solvation
and acidity in complex mixtures with first-principles accuracy: the case of CH3SO3H and H2O2
in phenol. J. Chem. Theory Comput., 16(8):5139-5149, 2020.
M. Rupp, A. Tkatchenko, K. Muller, and OA. Von Lilienfeld. Fast and accurate modeling of molecular
atomization energies with machine learning. Phys. Rev. Lett., 108(5):058301, 2012.
R. B. Rusu, N. Blodow, Z. C. Marton, and M. Beetz. Aligning point cloud views using persistent
feature histograms. In 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems,
pp. 3384-3391, 2008.
R.B. Rusu, N. Blodow, and M. Beetz. Fast point feature histograms (FPFH) for 3D registration.
In Proceedings of the 2009 IEEE International Conference on Robotics and Automation, pp.
1848-1853, 2009.
M. Savva, F. Yu, H. Su, A. Kanezaki, T. Furuya, R. Ohbuchi, Z. Zhou, R. Yu, S. Bai, X. Bai, M. Aono,
A. Tatsuma, S. Thermos, A. Axenopoulos, G. Th. Papadopoulos, P. Daras, X. Deng, Z. Lian, B. Li,
H. Johan, Y. Lu, and S. Mk. Large-scale 3D shape retrieval from shapenet core55. In Eurographics
Workshop on 3D Object Retrieval, 2016.
H. Su, V. Jampani, D. Sun, S. Maji, E. Kalogerakis, M. Yang, and J. Kautz. SPLATNet: Sparse lattice
networks for point cloud processing. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR), pp. 2530-2539, 2018.
L.	Wang, Y. Huang, Y. Hou, S. Zhang, and J. Shan. Graph attention convolution for point cloud
semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), June 2019.
Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X.Tang, and J. Xiao. 3D shapenets: A deep representation
for volumetric shapes. In 2015 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 1912-1920, 2015.
M.	Xu, W. Dai, Y. Shen, and H. Xiong. MSGCNN: Multi-scale graph convolutional neural network
for point cloud segmentation. In 2019 IEEE Fifth International Conference on Multimedia Big
Data (BigMM), pp. 118-127, 2019.
Y. Xu, T. Fan, M. Xu, L. Zeng, and Y. Qiao. SpideCNN: Deep learning on point sets with param-
eterized convolutional filters. In Proceedings of the European Conference on Computer Vision
(ECCV), September 2018.
Y. Yang, C. Feng, Y. Shen, and D. Tian. FoldingNet: Point cloud auto-encoder via deep grid
deformation. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
pp. 206-215, 2018.
12
Under review as a conference paper at ICLR 2021
K. Yao, J. E. Herr, D. W. Toth, R. Mckintyre, and J. Parkhill. The tensorMol-0.1 model chemistry: a
neural network augmented with long-range physics. Chem. Sci., 9:2261-2269, 2018.
X. Ye, J. Li, H. Huang, L. Du, and X. Zhang. 3D recurrent neural networks with context fusion for
point cloud semantic segmentation. In Proceedings of the European Conference on Computer
Vision (ECCV), September 2018.
M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. R. Salakhutdinov, and A. J. Smola. Deep sets.
pp. 3391-3401, 2017.
W. Zeng and T. Gevers. 3DContextNet: K-d tree guided hierarchical learning of point clouds using
local and global contextual cues. In Proceedings of the European Conference on Computer Vision
(ECCV) Workshops, September 2018.
Z. Zhai, X. Zhang, and L. Yao. Multi-scale dynamic graph convolution network for point clouds
classification. IEEE Access, 8:65591-65598, 2020.
L. Zhang, J. Han, H. Wang, R. Car, and W. E. Deep potential molecular dynamics: A scalable model
with the accuracy of quantum mechanics. Phys. Rev. Lett., 120:143001, Apr 2018a.
L. Zhang, J. Han, Ha. Wang, W. Saidi, R. Car, and W. E. End-to-end symmetry preserving inter-
atomic potential energy model for finite and extended systems. In Advances in Neural Information
Processing Systems 31, pp. 4441-4451. 2018b.
L. Zhang, M. Chen, X. Wu, H. Wang, W. E, and R. Car. Deep neural network for the dielectric
response of insulators. arXiv:1906.11434, 2019.
Y. Zhou and O. Tuzel. Voxelnet: End-to-End learning for point cloud based 3D object detection. In
2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4490-4499,
2018.
A Notation
A table of notations is summarized in Table 4.
B Data Generation
We provide further details about the data generation process and how the parameter μ dictates the
characteristic interaction length.
Exponential kernel: Suppose Ω be the torus [0, L]d and that X = {χi}N=ι ⊂ Ω ⊂ Rd for d = 1, 2,
or 3. The exponential kernel is defined as
ψμ(X - y) = e-μkx-yk,	(8)
where k ∙ k is the Euclidean norm over the torus. Following Section 3.1 we define the total energy
and the potential as
N U = Ee-μkχi-Xj k i<j	and	Uj(X)	N 二 Ee-μkg-χk, i6=j	(9)
respectively. The forces are given by				
Fj = -∂xj Uj (Xj) =	N -X i6=j	Xi - Xj kxi - xjk	μe-μkxi-χjk.	(10)
Screened-Coulomb kernel: In 3D, the screened-Coulomb potential with free space boundary condi-
tion is given by
ψ”(X- y) = 4∏k⅛e-μkx-yk
(11)
13
Under review as a conference paper at ICLR 2021
Table 4: Symbols introduced in the current paper with their corresponding meaning.
Notation
Symbol	Meaning
Data	
d Ω = [0,L]d ⊂ Rd {Xi}N=ι ⊂ Ω N Nsample ψμ μ U F- Fj		Spatial dimension of the problem Computational Domain Point cloud Number of points in the point cloud Number of snapshots for training Interaction kernel Inverse characteristic interaction length Potential Forces exerted over the j-th particle
Networks	
Di F θ fθ gθ R		Descriptor associated to Xi Fitting Network Generic trainable parameters Trainable function inside the descriptor Trainable function inside the fitting network Interaction radius
LRC-layer	
gτ T FFT, IFFT φθ φθ lfft NFFT = LdFT .		Mollifier of the Dirac deltas defined in equation 20 Broadening factor in the mollifier Fast Fourier transform and its inverse Kernel with trainable parameters θ Fourier transform of the kernel Number of Fourier modes per dimension Total number of Fourier modes
Over the torus [0, L]d, the kernel ψμ(x - y) is the Green's function Gμ(x, y) defined via
∆Gμ(x, y) - μ2Gμ(x, y) = -δy(x),	(12)
with the periodic boundary condition. In order to compute the screened-Coulomb potential numeri-
cally, a spectral method is used: in particular,
ψμ(X - y) = Gμ(x,y) = FT (Il e2	2 Xnk)) ,	(13)
kkk2 + μ2
where F-1 stands for the inverse Fourier transform and χ(k) is a smoothing factor, usually Gaussian,
to numerically avoid the Gibbs phenomenon. Similar to the exponential case, the parameter μ controls
the localization of the potential. In addition, the derivatives are taken numerically in the Fourier
domain.
Visualization: To visualize the relation between μ and the characteristic interaction length in 1D,
consider a given particle, e.g., x100 and compute the force contribution from the other particles. Fig. 5
shows that force contribution is extremely small outside a small interaction region for μ = 5.0 while
the interaction region for μ = 0.5 is much larger.
C Details of architecture and training
C.1 Short-range Descriptor
Here we specify the structure of Di introduced in Section 3.2. For a given particle xi, and an
interaction radius R, define the interaction list Ii of xi as the set of indices j such that kxi - xj k < R,
where ∣∣ ∙ ∣∣ stands for the distance over the torus [0, L]d. To simplify the discussion, we assume that
there exists a maximal number of neighbors NmaxNeigh for each xi . We stack the neighbors in a
tensor whose dimensions are constant across different particles. This value is chosen to be sufficiently
14
Under review as a conference paper at ICLR 2021
Figure 5: The force contribution to particle x100 from other particles. Results are shown for two
different characteristic interaction lengths.
large to cover the number of elements in the interaction list. If the cardinality of Ii is less than
NmaxNeigh, we pad the tensor with dummy values.
In the 1D case the generalized coordinates are defined as
si,j = kxi - xjk,
and	ri,j =	1~~∏
kxi - xj k
(14)
forj ∈ Ii. We introduce two fully-connected neural networks fθ1 , fθ2 : R+ → Rmsr/2, where each
consists of five layers with the number of units doubling at each layer and ranging from 2 to 32. The
activation function after each layer is tanh and the initialization follows Glorot normal distribution.
For particle xi the short-range descriptor is defined as the concatenation of
Dl,sr= ∑fθι (^i,j)^i,j	and	。2乒=∑ fθ2 (^i,j)^i,j,	(15)
j∈Ii	j∈Ii
where *,j, Sij are the normalized copies of r*j and Sij with mean zero and standard deviation
equals to one. The mean and standard deviation are estimated by using a small number of snapshots.
We multiply the network,s output fθ by *,j (which is zero if j is a dummy particle). This procedure
enforces a zero output for particles not in the interaction list. The construction satisfies the design
requirement mentioned in Section 3.2.
In the short-range network, one concatenates the two descriptor above and feeds them particle-wise
to the short-range fitting network. The fitting network Fsr : Rmsr → R is a residual neural network
(ResNet) with six layers, each with 32 units. The activation function and initialization strategy are
the same as the ones for the short-range descriptors. Fig. 6 shows the detailed architecture of the
short-range network.
NN
UsNrN =	F(Dsir) =	F(D1i,sr,D2i,sr)	(16)
i=1	i=1
In 2D and 3D, there is a slight difference of generalized coordinates: we compute
xi - xj	1
si,j =	and	ri,j = μ	,,	(17)
kxi - xjk	kxi - xjk
where si,j is a vector now. The local descriptors are defined in the following forms:
Dkr= X fθι (Si,j)r-i,j	and	Di,sr = X fθ2 (^i,j)^i,j	(18)
j ∈Ii	j ∈Ii
C.2 NUFFT
In this section we provide further details for the NUFFT implementation. Suppose that the input of
the NUFFT is given by {xi}iN=1 ⊂ Rd, where each point has a given associated weight fi. The first
15
Under review as a conference paper at ICLR 2021
Figure 6: The structure of short-range network for 1D case.
step is to construct the weighted train of Dirac deltas as
N
f(x) = Xfjδ(x-xj).
j=1
(19)
We point out that in some of the experiments fj simply equals to 1. One then defines a periodic
Gaussian convolution kernel
gτ(x) = E e-kx-'Lk2/4τ,	(20)
'∈Zd
where L is the length of the interval and τ determines the size of mollification. In practice a good
choice is T = 12( 2πL.T )2 (Dutt & Rokhlin, 1993), where LFFT is the number of points in each
dimension and NFFT = LdFFT . We define
fτ (x)
f * gτ (X) = /
[0,L]d
N
f(y)gτ(x - y)dy =	fjgτ(x - xj).
j=1
With the Fourier transform defined as
Fτ(k)
Ld /oW
fτ(x)e-i2πk∙χ∕L dx
for k ∈ Zd, we compute its discrete counterpart
Fτ (k) ≈
NFFT
〜 1
NFFT
E	fτ (LmlLFFT) e-i2nk-m/LFFT
m∈[0,LFFT -1]d
N
E	E fjgτ (Lm/LFFT - Xj) e-i2πk∙WLFFT
m∈[0,LF
FT-1]d j=1
(21)
(22)
(23)
(24)
1
This operation can be done in O(NFFT log(NFFT)) steps, independently of the number of inputs.
Once this is computed, one can compute the Fourier transform of f at each frequency point by
F(k) = (T)d/2 ekkk2TK(k)
(25)
Once the Fourier transform of the Dirac delta train is ready, we multiply it by the Fourier multiplier
ʌ
φ(k), which is the Fourier transform of φ:
ʌ
V(k) = φ(k)F (k)
(26)
16
Under review as a conference paper at ICLR 2021
In the next sage, one needs to compute the inverse transform, and evaluate into the target points {xi}.
First we deconvolve the signal
V-τ(k) = (TY" ekkk2τV(k)
and compute the inverse Fourier transform
U-T(X) = E	v-τ (k)eik∙x.
k∈[0,NFFT -1]d
Next, we interpolate to the point cloud
u (Xj ) = U-τ * gτ (Xj )=
1
Ld J	u-τ (x)gτ (Xj — x) dx
〜 1
NFFT
Σ
m∈[0,LFFT -1]
u-τ (Lm/LFFT ) gτ (xj - Lm/LFFT )
d
(27)
(28)
(29)
(30)
Even though in the current implementation all the parameters of the NUFFT are fixed, they can in
principle be trained along with the rest of the networks. This training, if done naively increases
significantly the computational cost. How to perform this operation efficiently is a direction of future
research.
Derivatives For the computation of the forces in equation 5 one needs to compute the derivatives of
the total energy UNN with respect to the inputs, in nearly-linear time. The main obstacle is how to
compute the derivatives of the LRC-layer with respect to the point-cloud efficiently. To simplify the
notation, we only discuss the case that d = 1, but the argument can be seamlessly extended to the
case when d > 1.
Recall that ui = PjN=1 φθ(Xi - Xj)fj, then the Jacobian of the vector u with respect to the inputs is
given by
(VWl	dui _1 -fj φθ (Xi-Xj),	if j = i,	∕3n
(VU)i,j := ∂Xj = t Pk=ifkΦθ(Xi-Xk), if j = i.	(31)
As it will be explained in the sequel, for the computation of the forces in equation 5 one needs to
compute the application of the Jacobian of u to a vector. For a fixed vector v ∈ RN , the product
(Vu) ∙ V can be written component-wise as
((VU) ∙ v)，= — Evj fj φθ (Xi-Xj)+ViE fj φθ(Xi- Xj),
j 6=i	j6=i
NN
= -	vjfjφ0θ(Xi -Xj) +vi	fjφ0θ(Xi - Xj),
j=1	j=1
where we have added ±vifiφ0(0) in the last equation and then distributed it within both sums. Let us
define the following two long-range convolutions
NN
wi = -	vj fj φ0θ (Xi	-	Xj ),	and	pi	=	fj φ0θ (Xi	- Xj),	(32)
j=1	j=1
each of which can be performed in O(N + NFFT log NFFT) steps using the NUFFT algorithm
combined with the convolution theorem. In this case the derivative of φ can be computed numerically
in the Fourier domain to a very high accuracy. Now one can leverage the expression above to rewrite
(Vu) ∙ v as
((Vu) ∙ v)i = Wi + vipi,	(33)
which can then be computed in nearly-linear time. The same is also true for v ∙ (Vu).
C.3 Long-range Descriptor
As mentioned before, the output of the LRC-layer is given by {u(Xi)}iN=1. For each particle we feed
the output u(Xi) to the long-range descriptor network hθ : R → Rmlr, whose structure is the same
17
Under review as a conference paper at ICLR 2021
as the local descriptor fθ mentioned in appendix C.1 except that the activation function is taken to be
ReLU. The long-range descriptor, defined as
Dli r = gθ(u(xi))	(34)
for the particle xi is concatenated with the corresponding short-range descriptor (which it is itself
the concatenation of two short-range descriptors) and fed together to the total fitting network F :
Rmsr+mlr → R. The results are then added together to obtain the total energy
N
UNN =	F(Dsir,Dlir).	(35)
i=1
It is clear that the energy can be evaluated in nearly-linear complexity.
In what follows we show that the force computation is also of nearly-linear. For simplicity we focus
on the one-dimensional network and assume that Kchnls = 1, O(msr) = O(mlr) = O(1) and
that the depth of the neural networks is O(1). As defined in the prequel the forces are given by
F NN = -Vχ U NN, Which can be written component wise as
N
FjNN = -∂xjUNN = -	∂1F(Dsir,Dlir)∂xjDsir+∂2F(Dsir,Dlir)gθ0(ui)∂xjui ,	(36)
i=1
or in a more compact fashion as
FNN = -VUNN = — (vsr ∙ Dsr + Vir ∙ Vu) .	(37)
Here vsr, and vlr are vectors defined component-wise as (vsr)i = ∂1F(Dsir, Dlir), and (vlr)i =
∂2F(Dsir, Dli r)gθ0 (ui). In addition (Dsr)i,j = ∂xj Dsi r and Vu is defined above.
The first term in the right-hand side is easy to compute, given that Dsr is sparse: the i, j entry
is non-zero only if the particle xi is in the interaction list of xj . Given that the cardinality of the
interaction list is bounded, Dsr has O(N) non-zero entries in which each entry requires O(1) work,
thus the first term in the right-hand side of equation 37 can be computed in O(N). At first glance
the complexity of second term seems to be much higher. However, as discussed above, by using
equation 33, we can apply the matrix (or its transpose) to a vector in O(N + NFFT log NFFT) time
and the computation of vector vlr requires O(1) work per entry, thus resulting in a complexity
of O(N + NFFT log NFFT) for computing the second term in equation 37. Finally, adding both
contributions together results in an overall O(N + NFFT log NFFT) complexity for the forces.
To summarize, both the computation of the energy and the forces can be performed in O(N) time.
C.4 Training
We use the Adam optimizer (Kingma & Ba, 2015) along with an exponential scheduler. The learning
rate with the initial learning rate taken to be 0.001 and, for every 10 epochs, it decreases by a factor of
0.95. In order to balance the computational time and the accuracy, a multi-stage training is adopted,
where at each stage we modify the batch-size and the number of epochs. In particular, four stages are
used: we start using a batch size of 8 snapshots and train the network 200 epochs and then at each
stage we double both the size of the batch size and the number of epochs. In the two-scale training
strategy, the same training parameters defined above are used for each stage.
C.5 DEPENDENCY ON NFFT
We measure the impact of NFFT on the approximation error, using a couple of examples in the one-
and two-dimensional settings.
For the one-dimensional case, we test a Screened-CouIomb type potential with parameters μι = 5.0,
μ2 = 0.5, αι = 0.5, α2 = 0.5, and Nsample = 1000. The domain Ω is [0,50] and N = 200. We
run the one-scale training procedure with varying NFFT (the number of Fourier multipliers), starting
from NFFT = 63 and doubling them until NFFT = 501. Table 5 shows that the errors are relatively
insensitive to the value of NFFT. The accuracy achieved by the architecture without the LRC-layer
(denoted as None in Tables 5) is added in order to demonstrate that the architecture is indeed capturing
the LRIs.
18
Under review as a conference paper at ICLR 2021
Figure 7: The structure of full-range network.
Table 5: Error with respect to NFFT in the 1D case
NFFT	None	63	125	251	501
Relative testing error	0.06143	0.00536	0.00546	0.00545	0.00539
For the two-dimensional case, a SCreened-Coulomb type potential is tested with μι = 10.0, μ2 = 1.0,
αι = 0.9, α2 = 0.1. Here Ω = [0, 5]2, N = 50 and Nsample = 1000. Starting with NFFT = 212,
we steadily increase its value and repeat the same training procedure. The results are summarized in
Table 6 where one observes the same trend as in the one-dimensional case.
Table 6: Error with respect to NFFT in the 2D case
NFFT	None	2P	312	452	632
Relative testing error	0.01872	0.00202	0.00168	0.00153	0.00177
In addition, we recall that the Fourier multipliers are parametrized following
φ (k) —	4πβ
φβ,λ(k) = kkk2 + λ2,
(38)
where β and λ are two trainable parameters with λ providing a measure of the decay in space.
Therefore, NFFT only determines the number of Fourier modes and not the parameters of the ansatz.
As long as the Fourier kernel is properly sampled, the method is able to compute the correct
characteristic interaction length.
One can observe this phenomenon in the experiment above, in which we extract the terminal value
after training of the parameters λ1 and λ2 that correspond to the two channels in the LRC-layer,
as summarized in Table 7. We observe that the value of λ2 is very close to that of μ2, which is
responsible for the LRIs even for small values of NFFT .
19
Under review as a conference paper at ICLR 2021
Table 7: Values of parameters λ1 and λ2 after training with respect to NFFT
	1D case				2D case			
NFFT	63	125	251	501	212	312	452	632
λl	2.697	3.689	4.181	4.599	3.608	3.664	3.096	2.955
λ	0.522	0.525	0.517	0.519	0.926	1.039	1.088	1.082
20