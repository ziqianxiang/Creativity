Under review as a conference paper at ICLR 2021
Federated Learning’ s Blessing:
FedAvg has Linear Speedup
Anonymous authors
Paper under double-blind review
Ab stract
Federated learning (FL) learns a model jointly from a set of participating devices without
sharing each other’s privately held data. The characteristics of non-i.i.d. data across
the network, low device participation, high communication costs, and the mandate that
data remain private bring challenges in understanding the convergence of FL algorithms,
particularly in regards to how convergence scales with the number of participating devices.
In this paper, We focus on Federated Averaging (FedAvg)-arguably the most popular and
effective FL algorithm class in use today-and provide a unified and comprehensive study
of its convergence rate. Although FedAvg has recently been studied by an emerging line
of literature, it remains open as to hoW FedAvg’s convergence scales With the number of
participating devices in the fully heterogeneous FL setting-a crucial question Whose ansWer
Would shed light on the performance of FedAvg in large FL systems. We fill this gap
by providing a unified analysis that establishes convergence guarantees for FedAvg under
three classes of problems: strongly convex smooth, convex smooth, and overparameterized
strongly convex smooth problems. We shoW that FedAvg enjoys linear speedup in each
case, although With different convergence rates and communication efficiencies. While
there have been linear speedup results from distributed optimization that assumes full
participation, ours are the first to establish linear speedup for FedAvg under both statistical
and system heterogeneity. For strongly convex and convex problems, We also characterize
the corresponding convergence rates for the Nesterov accelerated FedAvg algorithm, Which
are the first linear speedup guarantees for momentum variants of FedAvg in the convex
setting. To provably accelerate FedAvg, We design a neW momentum-based FL algorithm
that further improves the convergence rate in overparameterized linear regression problems.
Empirical studies of the algorithms in various settings have supported our theoretical results.
1	Introduction
Federated learning (FL) is a machine learning paradigm Where many clients (e.g., mobile devices
or organizations) collaboratively train a model under the orchestration of a central server (e.g.,
service provider), While keeping the training data decentralized (Smith et al. (2017); Kairouz et al.
(2019)). In recent years, FL has sWiftly emerged as an important learning paradigm (McMahan et al.
(2017); Li et al. (2020a))-one that enjoys Widespread success in applications such as personalized
recommendation (Chen et al. (2018)), virtual assistant (Lam et al. (2019)), and keyboard prediction
(Hard et al. (2018)), to name a feW-for at least three reasons: First, the rapid proliferation of smart
devices that are equipped With both computing poWer and data-capturing capabilities provided the
infrastructure core for FL. Second, the rising aWareness of privacy and the explosive groWth of
computational poWer in mobile devices have made it increasingly attractive to push the computation
to the edge. Third, the empirical success of communication-efficient FL algorithms has enabled
increasingly larger-scale parallel computing and learning With less communication overhead.
Despite its promise and broad applicability in our current era, the potential value FL delivers is coupled
With the unique challenges it brings forth. In particular, When FL learns a single statistical model
using data from across all the devices While keeping each individual device’s data isolated (Kairouz
et al. (2019)), it faces tWo challenges that are absent in centralized optimization and distributed
(stochastic) optimization (Zhou & Cong (2018); Stich (2019); Khaled et al. (2019); Liang et al.
(2019); Wang & Joshi (2018); WoodWorth et al. (2018); Wang et al. (2019); Jiang & AgraWal (2018);
Yu et al. (2019b;a); Khaled et al. (2020); Koloskova et al. (2020); WoodWorth et al. (2020b;a)):
1)	Data (statistical) heterogeneity: data distributions in devices are different (and data cannot be
shared);
1
Under review as a conference paper at ICLR 2021
''^"—~^^__ Objective function Participation	~ 		^——	Strongly Convex	Convex		Overparameterized general case	Overparameterized linear regression
Full		 O( N1T + E2)		1	, NE2] √NT + T)	O(exp(-ET))	O(exp(-N))广
Partial	O (K + E2)	Zt	E2	, KE2 y~ √KT + T)	O(exp(-ET))	O(exP(-KT ))t
Table 1: Our convergence results for FedAvg and accelerated FedAvg in this paper. Throughout the paper, N is
the total number of local devices, and K ≤ N is the maximal number of devices that are accessible to the central
server. T is the total number of stochastic updates performed by each local device, E is the local steps between
two consecutive server communications (and hence T/E is the number of communications). t In the linear
regression setting, we have K = κι for FedAvg and K = Kfκιfo for momentum accelerated FedAvg (FedMaSS),
where κι and 7κιK are condition numbers defined in Section G. Since κι ≥ K, this implies a speedup factor of
∖J~^o for accelerated FedAvg.
2)	System heterogeneity: only a subset of devices may access the central server at each time both
because the communications bandwidth profiles vary across devices and because there is no central
server that has control over when a device is active (the presence of “stragglers”).
To address these challenges, Federated Averaging (FedAvg) McMahan et al. (2017) was proposed as
a particularly effective heuristic, which has enjoyed great empirical success. This success has since
motivated a growing line of research efforts into understanding its theoretical convergence guarantees
in various settings. For instance, Haddadpour & Mahdavi (2019) analyzed FedAvg (for non-convex
smooth problems satisfying PL conditions) under the assumption that each local device’s minimizer
is the same as the minimizer of the joint problem (if all devices’ data is aggregated together), an
overly restrictive assumption that restricts the extent of data heterogeneity. Very recently, Li et al.
(2020b) furthered the progress and established an O(T1) convergence rate for FedAvg for strongly
convex smooth Federated learning problems with both data and system heterogeneity. A similar
result in the same setting Karimireddy et al. (2019) also established an O(T) result that allows for a
linear speedup when the number of participating devices is large. At the same time, Huo et al. (2020)
studied the Nesterov accelerated FedAvg for non-convex smooth problems and established an O( ^1=)
convergence rate to stationary points.
However, despite these very recent fruitful pioneering efforts into understanding the theoretical
convergence properties of FedAvg, it remains open as to how the number of devices-particularly the
number of devices that participate in the computation-affects the convergence speed. In particular, is
linear speedup of FedAvg a universal phenomenon across different settings and for any number of
devices? What about when FedAvg is accelerated with momentum updates? Does the presence of
both data and system heterogeneity in FL imply different communication complexities and require
technical novelties over results in distributed and decentralized optimization? These aspects are
currently unexplored or underexplored in FL. We fill in the gaps here by providing affirmative
answers.
Our Contributions We provide a comprehensive and unified convergence analysis of FedAvg and
its accelerated variants in the presence of both data and system heterogeneity. Our contributions are
threefold.
First, we establish an O(1∕KT) convergence rate under FedAvg for strongly convex and smooth
problems and an O(1∕√KT) convergence rate for convex and smooth problems (where K is the
number of participating devices), thereby establishing that FedAvg enjoys the desirable linear speedup
property in the FL setup. Prior to our work here, the best and the most related convergence analysis is
given by Li et al. (2020b) and Karimireddy et al. (2019), which established an O(T1) convergence
rate for strongly convex smooth problems under FedAvg. Our rate matches the same (and optimal)
dependence on T, but also completes the picture by establishing the linear dependence on K, for
any K ≤ N , where N is the total number of devices, whereas Li et al. (2020b) does not have linear
speedup analysis, and Karimireddy et al. (2019) only allows linear speedup close to full participation
(K = O(N)). As for convex and smooth problems, there was no prior work that established the
O(√τ) rate under both system and data heterogeneity. Our unified analysis highlights the common
elements and distinctions between the strongly and convex settings.
Second, we establish the same convergence rates-O(l∕KT) for strongly convex and smooth problems
and O(1∕√KT) for convex and smooth problems-for Nesterov accelerated FedAvg. We analyze the
accelerated version of FedAvg here because empirically it tends to perform better; yet, its theoretical
2
Under review as a conference paper at ICLR 2021
convergence guarantee is unknown. To the best of our knowledge, these are the first results that
provide a linear speedup characterization of Nesterov accelerated FedAvg in those two problem
classes (that FedAvg and Nesterov accelerated FedAvg share the same convergence rate is to be
expected: this is the case even for centralized stochastic optimization). Prior to our results here,
the most relevant results Yu et al. (2019a); Li et al. (2020a); Huo et al. (2020) only concern the
non-convex setting, where convergence is measured with respect to stationary points (vanishing of
gradient norms, rather than optimality gaps). Our unified analysis of Nesterov FedAvg also illustrates
the technical similarities and distinctions compared to the original FedAvg algorithm, whereas prior
works (in the non-convex setting) were scattered and used different notations.
Third, we study a subclass of strongly convex smooth problems where the objective is over-
parameterized and establish a faster O(exp(-KKT)) convergence rate for FedAvg, in contrast to the
O(exp(-T)) rate for individual solvers Ma et al. (2018). Within this class, We further consider the
linear regression problem and establish an even sharper rate under FedAvg. In addition, we propose
a new variant of accelerated FedAvg based on a momentum update of Liu & Belkin (2020)-MaSS
accelerated FedAvg-and establish a faster convergence rate (compared to if no acceleration is used).
This stands in contrast to generic (strongly) convex stochastic problems where theoretically no
rate improvement is obtained when one accelerates FedAvg. The detailed convergence results are
summarized in Table 1.
Connections with Distributed and Decentralized Optimization Federated learning is closely re-
lated to distributed and decentralized optimization, and as such it is important to discuss connections
and distinctions between our work and related results from that literature. First, when there is neither
system heterogeneity, i.e. all devices participate in parameter averaging during a communication
round, nor statistical heterogeneity, i.e. all devices have access to a common set of stochastic gra-
dients, FedAvg coincides with the “Local SGD” of Stich (2019), which showed the linear speedup
rate O(1/N T) for strongly convex and smooth functions. Woodworth et al. (2020b) and Woodworth
et al. (2020a) further improved the communication complexity that guarantees the linear speedup
rate. When there is only data heterogeneity, some works have continued to use the term Local SGD
to refer to FedAvg, while others subsume it in more general frameworks that include decentralized
model averaging based on a network topology or a mixing matrix. They have provided linear speedup
analyses for strongly convex and convex problems, e.g. Khaled et al. (2020); Koloskova et al. (2020)
as well as non-convex problems, e.g. Jiang & Agrawal (2018); Yu et al. (2019b); Wang & Joshi
(2018). However, these results do not consider system heterogeneity, i.e. the presence of stragglers
in the device network. Even with decentralized model averaging, the assumptions usually imply
that model averages over all devices is the same as decentralized model averages based on network
topology (e.g. Koloskova et al. (2020) Proposition 1), which precludes system heterogeneity as
defined in this paper and prevalent in FL problems. For momentum accelerated FedAvg, Yu et al.
(2019a) provided linear speedup analysis for non-convex problems, while results for strongly convex
and convex settings are entirely lacking, even without system heterogeneity. Karimireddy et al. (2019)
considers both types of heterogeneities for FedAvg, but their rate implies a linear speedup only
when the number of stragglers is negligible. In contrast, our linear speedup analyses consider both
types of heterogeneity present in the full federated learning setting, and are valid for any number
of participating devices. We also highlight a distinction in communication efficiency when system
heterogeneity is present. Moreover, our results for Nesterov accelerated FedAvg completes the picture
for strongly convex and convex problems. For a detailed comparison with related works, please refer
to Table 2 in Appendix Section B.
2 Setup
In this paper, we study the following federated learning problem:
mwin F (w) , XkN=1 pkFk (w) ,
(1)
where N is the number of local devices (users/nodes/workers) and pk is the k-th device’s weight sat-
isfying pk ≥ 0 and PkN=1 pk = 1. In the k-th local device, there are nk data points: x1k, x2k, . . . , xknk .
The local objective Fk(∙) is defined as: Fk(W)，n^ Pn= 1' (w; Xk), where ' denotes a user-
specified loss function. Each device only has access to its local data, which gives rise to its own
3
Under review as a conference paper at ICLR 2021
local objective Fk. Note that we do not make any assumptions on the data distributions of each local
device. The local minimum Fk = minw Fk(W) can be far from the global minimum of Eq (1) (data
heterogeneity).
2.1	The Federated Averaging (FedAvg) Algorithm
We first introduce the standard Federated Averaging (FedAvg) algorithm which was first proposed
by McMahan et al. (2017). FedAvg updates the model in each device by local Stochastic Gradient
Descent (SGD) and sends the latest model to the central server every E steps. The central server
conducts a weighted average over the model parameters received from active devices and broadcasts
the latest averaged model to all devices. Formally, the updates of FedAvg at round t is described as
follows:
k	k	k	vtk+1	ift+ 1	∈/ IE,	2
vt+1 =	Wt	- αtgt,k,	Wt+1	= Pk∈St+1qkvtk+1	ift+1	∈IE,	(2)
where Wtk is the local model parameter maintained in the k-th device at the t-th iteration and
gt,k := VF1fc(wk, ξ) is the stochastic gradient based on ξ, the data point sampled from k-th
device’s local data uniformly at random. IE = {E, 2E, . . . } is the set of global communication
steps, when local parameters from a set of active devices are averaged and broadcast to all devices.
We use St+1 to represent the (random) set of active devices at t + 1. qk is a set of averaging weights
that are specific to the sampling procedure used to obtain the set of active devices St+1.
Since federated learning usually involves an enormous amount of local devices, it is often more
realistic to assume only a subset of local devices is active at each communication round (system
heterogeneity). In this work, we consider both the case of full participation where the model
is averaged over all devices at each communication round, in which case qk = pk for all k and
wtk+1 = PkN=1 pkvtk+1 if t + 1 ∈ IE, and the case of partial participation where |St+1| < N.
With partial participation, we follow Li et al. (2020a); Karimireddy et al. (2019); Li et al. (2020b) and
assume that St+1 is obtained by one of two types of sampling schemes to simulate practical scenarios.
One scheme establishes St+1 by i.i.d. sampling the devices with probability pk with replacement,
and uses qk = -K, where K = ∣St+ι∣, while the other scheme samples St+ι uniformly i.i.d. from
all devices without replacement, and uses qk = PkN. Both schemes guarantee that gradient updates
in FedAvg are unbiased stochastic versions of updates in FedAvg with full participation, which is
important in the theoretical analysis of convergence. Because the original sampling scheme and
weights proposed by McMahan et al. (2017) lacks this nice property, it is not considered in this paper.
For more details on the notations and setup as well as properties of the two sampling schemes, please
refer to Section A in the appendix.
2.2	Assumptions
We make the following standard assumptions on the objective function F1, . . . , FN. Assumptions 1
and 2 are commonly satisfied by a range of popular objective functions, such as `2 -regularized logistic
regression and cross-entropy loss functions.
Assumption 1 (L-smooth). Fι, ∙∙∙ , FN are all L-smooth: forall V and W, Fk(V) ≤ Fk(w) + (v 一
w)TVFk(w) + l∣∣v 一 wk2.
Assumption 2 (Strongly-convex). Fι, ∙∙∙ , FN are all μ -StrOngIy convex: for all V and w, Fk (v) ≥
Fk (w) + (v — w)T VFk (w) + 2 ∣∣v — w∣2
Assumption 3 (Bounded local variance). Let ξtk be sampled from the k-th device’s local
data uniformly at random. The variance of stochastic gradients in each device is bounded:
EllVFk(Wk ,ξk) — VFk(Wk )∣∣2 ≤ σ2 ,for k = 1,…，N and any wk. Let σ2 := PN=I Pkσ2.
Assumption 4 (Bounded local gradient). The expected squared norm of stochastic gradients is
uniformly bounded. i.e., E ∣∣ VFk (wk ,ξk) ∣∣2 ≤ G2 ,for all k = 1,...,N and t = 0,...,T — 1.
Assumptions 3 and 4 have been made in many previous works in federated learning, e.g. Yu
et al. (2019b); Li et al. (2020b); Stich (2019). We provide further justification for their gen-
erality. As model average parameters become closer to w*, the L-smoothness property im-
plies thatEkVFk(Wk,ξk)k2 andEIlVFk(Wk,ξ) — VFk(Wk)∣∣2 approachEkVFk(W*,ξik)∣∣2 and
4
Under review as a conference paper at ICLR 2021
Ek VFk(w* ,ξk) - VFk(w*)k2. Therefore, there is no substantial difference between these assump-
tions and assuming the bounds at w* only Koloskova et al. (2020). Furthermore, compared to
assuming bounded gradient diversity as in related work Haddadpour & Mahdavi (2019); Li et al.
(2020a), Assumption 4 is much less restrictive. When the optimality gap converges to zero, bounded
gradient diversity restricts local objectives to have the same minimizer as the global objective, contra-
dicting the heterogeneous data setting. For detailed discussions of our assumptions, please refer to
Appendix Section B.
3 Linear S peedup Analysis of FedAvg
In this section, we provide convergence analyses of FedAvg for convex objectives in the general
setting with both heterogeneous data (statistical heterogeneity) and partial participation (system
heterogeneity). We show that for strongly convex and smooth objectives, the convergence of the
optimality gap of averaged parameters across devices is O(1/K T), while for convex and smooth
objectives, the rate is O(1/√KT). Our results improve upon Li et al. (2020b); Karimireddy et al.
(2019) by showing linear speedup for any number of participating devices, and upon Khaled et al.
(2020); Koloskova et al. (2020) by allowing system heterogeneity. The proofs also highlight similari-
ties and distinctions between the strongly convex and convex settings. Detailed proofs are deferred to
Appendix Section E.
3.1	Strongly Convex and Smooth Objectives
We first show that FedAvg has an O(1∕KT) convergence rate for μ-strongly convex and L-smooth
objectives. The result relies on a technical improvement over the analysis in Li et al. (2020b).
Moreover, it implies a distinction in communication efficiency that guarantees this linear speedup for
FedAvg with full and partial device participation. With full participation, E can be chosen as large as
O( dT∕N) without degrading the linear speedup in the number of workers. On the other hand, with
partial participation, E must be O(1) to guarantee O(1/K T) convergence.
Theorem 1. Let WT = PN=I PkWT in FedAvg, VmaX = maxk Npk, and set decaying learning
rates at, = *(3)with Y = max{32κ, E} and K = L. Then under Assumptions 1 to 4 with full
device participation,
EF (Wt ) - F *
O (KVmaXσ/μ + KEG/μ
I NT +	τ2
and with partial device participation with at most K sampled devices at each communication round,
EF(WT) — F *
O ( KE2G2/μ + KVmaXσ/μ + κ2E2G2/μ
V —KT — + -NT — + —T2
Proof sketch. Because our unified analyses of results in the main text follow the same framework
with variations in technical details, we first give an outline of proof for Theorem 1 to illustrate the
main ideas. For full participation, the main ingredient is a recursive contraction bound
EIlWt+1 - w*k2 ≤ (I- μαt)Ekwt - w*k2 + α2 NVm axσ2 + 6a3LE2G2
where the O(αt3E2G2) term is the key improvement over the bound in Li et al. (2020b), which has
O(a2E2G2) instead. We then use induction to obtain a non-recursive bound on EkWT - w*∣2,
which is converted to a bound on EF (WT) - F * using L-smoothness. For partial participation,
an additional term O(Kra2E2G2) of leading order resulting from sampling variance is added to
the contraction bound. To facilitate the understanding of our analysis, please refer to a high-level
summary in Appendix C.
Linear speedup. We compare our bound with that in Li et al. (2020b), which is O( NNT + KET + ETG).
Because the term ETG2 is also O(1∕T) without a dependence on N, for any choice of E their bound
cannot achieve linear speedup. The improvement of our bound comes from the term K ETG ∕μ, which
5
Under review as a conference paper at ICLR 2021
now is O(E2/T 2) and so is not of leading order. As a result, all leading terms scale with 1/N in the
full device participation setting, and with 1/K in the partial participation setting. This implies that
in both settings, there is a linear speedup in the number of active workers during a communication
round. We also emphasize that the reason one cannot recover the full participation bound by setting
K = N in the partial participation bound is due to the variance generated by sampling.
Communication Complexity. Our bound implies a distinction in the choice of E between the full
and partial participation settings. With full participation, the term involving E, O(E2/T2), is not
of leading order O(1/T), so we can increase E and reduce the number of communication rounds
without degrading the linear speedup in iteration complexity O(1∕NT), as long as E = O(，T/N),
since then O(E2/T 2) = O(1/N T) matches the leading term. This corresponds to a communication
complexity of T/E = O(√NT). In contrast, the bound in Li et al. (2020b) does not allow E to
scale with √T to preserve O(1∕T) rate, even for full participation. On the other hand, with partial
participation, KEKGr'μ is also a leading term, and so E must be O⑴.In this case, our bound
still yields a linear speedup in K, which is also confirmed by experiments. The requirement that
E = O(1) in order to achieve linear speedup in partial participation cannot be removed for our
sampling schemes, as the term KEKGr " comes from variance in the sampling process, which is
O(E2/T 2). In Proposition 1 in Section E of the appendix, we provide a problem instance where the
dependence of the sampling variance on E is tight.
Comparison with related works. To better understand the significance of the obtained bound, we
compare our rates to the best-known results in related settings. Haddadpour & Mahdavi (2019) proves
a linear speedup O(1/KT) result for strongly convex and smooth objectives1, with O(K1/3T 2/3)
communication complexity with non-i.i.d. data and partial participation. However, their results build
on the bounded gradient diversity assumption, which implies the existence of W that minimizes all
local objectives (see discussions in Section 2.2 and Appendix B), effectively removing statistical
heterogeneity. The bound in Koloskova et al. (2020) matches our bound in the full participation
case, but their framework excludes partial participation (Koloskova et al., 2020, Proposition 1). The
result of Karimireddy et al. (2019) applies to the full FL setting, but only has linear speedup when
K = O(N), i.e. close to full participation, whereas our result has linear speedup for any number of
participating devices. When there is no data heterogeneity, i.e. in the classical distributed optimization
paradigm, communication complexity can be further improved, e.g. Woodworth et al. (2020b;a),
but such results are not directly comparable to ours since we consider the setting where individual
devices have access to different datasets.
3.2	Convex Smooth Objectives
Next we provide linear speedup analysis of FedAvg with convex and smooth objectives and show
that the optimality gap is OQNKrT). This result complements the strongly convex case in the
previous part, as well as the non-convex smooth setting in Jiang & Agrawal (2018); Yu et al. (2019b);
Haddadpour & Mahdavi (2019), where O(1∕√KT) results are given in terms of averaged gradient
norm, and it also extends the result in Khaled et al. (2020), which has linear speedup in the convex
setting, but only for full participation.
Theorem 2. Under Assumptions 1,3,4 and constant learning rate ɑt = O( ypN), FedAvg satisfies
min F(Wt) — F (w*) = O
ν2	σ2
max
Nnt
NE2LG2
+ 一τ一
withfull participation, and with partial device participation with K sampled devices at each commu-
nication round and learning rate αt = O(√ K),
min F(Wt) — F(w*)
O
(ν‰Q + EG + KE2LG2)
√KT	√KT	τ )
The analysis again relies on a recursive bound, but without contraction:
EIlWt+1 — w*k2 + αt(F(Wt) — F(w*)) ≤ E∣∣Wt — w*∣∣2 + α2NVmaXσ2 + 6α3E2LG2
1 Their result applies to a larger class of non-convex objectives that satisfy the Polyak-Lojasiewicz condition.
6
Under review as a conference paper at ICLR 2021
which is then summed over time steps to give the desired bound, with αt =O(VZ N).
Choice of E and linear speedup. With full participation, as long as E = O(T 1/4/N 3/4), the con-
vergence rate is OQNNT) with O(N3/4T3/4) communication rounds. In the partial participation
setting, E must be O(1) in order to achieve linear speedup of OQNKrT). This is again due to
the fact that the sampling variance EkWt - Vtk2 =O(α2E2G2) cannot be made independent of
E, as illustrated by Proposition 1. See also the proof in Section E for how the sampling variance
and the term E2G2∕√KT are related.OUr result again demonstrates the difference in communi-
cation complexities between full and partial participation, and is to our knowledge the first result
on linear speedup in the general federated learning setting with both heterogeneous data and partial
participation for convex objectives.
4 Linear S peedup Analysis of Nesterov Accelerated FedAvg
A natural extension of the FedAvg algorithm is to use momentum-based local updates instead of local
SGD updates in order to accelerate FedAvg. As we know from stochastic optimization, Nesterov
and other momentum updates fail to provably accelerate over SGD (Liu & Belkin (2020); Kidambi
et al. (2018); Liu et al. (2018); Yuan & Ma (2020)). This is in contrast to the classical acceleration
result of Nesterov-accelerated gradient descent over GD. Thus in the FL setting, the best provable
convergence rate for FedAvg with Nesterov updates is the same as FedAvg with SGD updates.
Nevertheless, Nesterov and other momentum updates are frequently used in practice, in both non-FL
and FL settings, and are observed to perform better empirically. In fact, previous works such as Stich
(2019) on FedAvg with vanilla SGD uses FedAvg with Nesterov or other momentum updates in their
experiments to achieve target accuracy. Because of the popularity of Nesterov and other momentum-
based methods, understanding the linear speedup behavior of FedAvg with such local updates is
important. To our knowledge, the only convergence analyses of FedAvg with momentum-based
stochastic updates focus on the non-convex smooth case Huo et al. (2020); Yu et al. (2019a); Li et al.
(2020a), and no results existed in the convex smooth settings. In this section, we complete the picture
by providing the first O(1∕KT) and OQNKrT) convergence results for Nesterov-accelerated
FedAvg for convex objectives that match the rates for FedAvg with SGD updates. Detailed proofs of
convergence results in this section are deferred to Appendix Section F.
4.1	Strongly Convex and Smooth Objectives
The Nesterov Accelerated FedAvg algorithm follows the updates:
vtk+1 = wtk - αtgt,k ,
wk	vtk+1 + βt (vtk+1 - vtk)
t+1	Pk∈St+1 qk vtk+1 +βt(vtk+1 -vtk)
ift+1 ∈∕IE,
if t + 1 ∈ IE ,
where gt,k := VFk(Wt, ξ) is the stochastic gradient sampled on the k-th device at time t, and qk
again depends on participation and sampling schemes.
Theorem 3. Let VT
αt = 6 t+γ, βt-1 =
participation,
PkN=1 pk VTk in Nesterov accelerated FedAvg, and set learning rates
____________3___________
14(t+γ)(l- t+6γ) maχ{μ,l} -
Then under Assumptions 1,2,3,4 with full device
EF (VT) - F *
KVmaXσ2∕μ + κ2E2G2∕μ
—NT — +	T
and with partial device participation with K sampled devices at each communication round,
EF(VT) - F* = O (KVmax j/" + K
E2G2∕μ κ2E2G2∕μ
KT — +
T2
Similar to FedAvg, the key step in the proof of this result is a recursive contraction bound, but
different in that it involves three time steps, due to the update format of Nesterov SGD (see Lemma 7
in Appendix F.1). Then we can again use induction and L-smoothness to obtain the desired bound.
To our knowledge, this is the first convergence result for Nesterov accelerated FedAvg in the strongly
convex and smooth setting. The same discussion about linear speedup of FedAvg applies to the
Nesterov accelerated variant. In particular, to achieve O(1∕NT) linear speedup, T iterations of the
algorithm require only O(√NT) communication rounds with full participation.
7
Under review as a conference paper at ICLR 2021
4.2	Convex Smooth Objectives
We now show that the optimality gap of Nesterov-accelerated FedAvg has O(1∕√KT) rate for
convex and smooth objectives. This result complements the strongly convex case in the previous part,
as well as the non-convex smooth setting in HUo et al. (2020); Yu et al. (2019a); Li et al. (2020a),
where a similar O(1/√KT) rate is given in terms of averaged gradient norm.
Theorem 4. Set learning rates αt = βt = O(ypN). Then under Assumptions 1,3,4 Nesterov
accelerated FedAvg with full device participation has rate
min F (Vt) - F *
(vmax。2
√NT
NE2LG2
T-
O
+
and with partial device participation with K sampled devices at each communication round,
min F(Vt) - F*
ν2 σ2	E2G2
o	ma^ +	+
V √kt	√kt
KE2LG2
T-
We emphasize again that in the stochastic optimization setting, the optimal convergence rate that
FedAvg wtih Nesterov udpates can achieve is the same as FedAvg with SGD updates. However, due
to the popularity and superior performance of momentum methods in practice, it is still important
to understand the linear speedup behavior of such FedAvg variants. Our results in this section fill
exactly this gap.
I I I I
ɛ Mcoscffs fco LΦAE3Z
ɛ Mcoscffs fco LΦAE3Z
3 3
O O
1 1
X X
3 2
MCO≡C2- J。LΦAE3Z
I I
I I
I I I I
MCO-SLVW- %LΦAE3Z
Number of workers (N)
(a) Strongly convex objective
I I I I
MCO-SLVW- %LΦAE3Z
ιo∙	io*
Number of workers (N)
(b) Convex smooth objective
0'
X
Tl) Mcosvlvw- ho LΦAE3Z
3 3
O O
1 1
X X
3 2
E Mcaslvw- ho LΦAE3Z
ιo∙	io*
Number of workers (N)
(c) Linear regression
Figure 1: The linear speedup of FedAvg in full participation, partial participation, and the linear
speedup of Nesterov accelerated FedAvg, respectively.
8
Under review as a conference paper at ICLR 2021
5 Numerical Experiments
In this section, we empirically examine the linear speedup convergence of FedAvg and Nesterov
accelerated FedAvg in various settings, including strongly convex function, convex smooth function,
and overparameterized objectives, as analyzed in previous sections.
Setup. Following the experimental setting in Stich (2019), we conduct experiments on both synthetic
datasets and real-world dataset w8a Platt (1998) (d = 300, n = 49749). We consider the distributed
objectives F (w) = PkN=1 pkFk (w), and the objective function on the k-th local device includes
three cases: 1) Strongly convex objective: the regularized binary logistic regression problem,
Fk(W) = N1k PNkI log(1 + exp(-ykWTXk) + 2l∣w∣∣2. The regularization parameter is set to
λ = 1/n ≈ 2e - 5. 2) Convex smooth objective: the binary logistic regression problem without
regularization. 3) Overparameterized setting: the linear regression problem without adding noise
to the label, Fk(W) = N PNI(WTXk + b - yk)2.
Linear speedup of FedAvg and Nesterov accelerated FedAvg. To verify the linear speedup conver-
gence as shown in Theorems 1 2 3 4, we evaluate the number of iterations needed to reach -accuracy
in three objectives. We initialize all runs with W0 = 0d and measure the number of iterations to
reach the target accuracy . For each configuration (E, K), we extensively search the learning rate
from min(ηo, Inct), where no ∈ {0.1,0.12,1, 32} according to different problems and C can take
the values c = 2i ∀i ∈ Z. As the results shown in Figure 1, the number of iterations decreases as
the number of (active) workers increasing, which is consistent for FedAvg and Nesterov accelerated
FedAvg across all scenarios. For additional experiments on the impact of E, detailed experimental
setup, and hyperparameter setting, please refer to the Appendix Section I.
9
Under review as a conference paper at ICLR 2021
References
Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via over-
parameterization. arXiv preprint arXiv:1811.03962, 2018.
Fei Chen, Zhenhua Dong, Zhenguo Li, and Xiuqiang He. Federated meta-learning for recommenda-
tion. arXiv preprint arXiv:1802.07876, 2018.
Farzin Haddadpour and Mehrdad Mahdavi. On the convergence of local descent methods in federated
learning. arXiv preprint arXiv:1910.14425, 2019.
Andrew Hard, Chloe M Kiddon, Daniel Ramage, Francoise Beaufays, Hubert Eichner, Kanishka Rao,
Rajiv Mathews, and Sean Augenstein. Federated learning for mobile keyboard prediction, 2018.
URL https://arxiv.org/abs/1811.03604.
Zhouyuan Huo, Qian Yang, Bin Gu, Lawrence Carin Huang, et al. Faster on-device training using
new federated momentum algorithm. arXiv preprint arXiv:2002.02090, 2020.
Prateek Jain, Sham M Kakade, Rahul Kidambi, Praneeth Netrapalli, and Aaron Sidford. Accelerating
stochastic gradient descent. In Proc. STAT, volume 1050, pp. 26, 2017.
Peng Jiang and Gagan Agrawal. A linear speedup analysis of distributed deep learning with sparse and
quantized communication. In Advances in Neural Information Processing Systems, pp. 2525-2536,
2018.
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurelien Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances
and open problems in federated learning. arXiv preprint arXiv:1912.04977, 2019.
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank J Reddi, Sebastian U Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for on-device federated
learning. arXiv preprint arXiv:1910.06378, 2019.
A Khaled, K Mishchenko, and P Richtarik. Tighter theory for local sgd on identical and heterogeneous
data. In The 23rd International Conference on Artificial Intelligence and Statistics (AISTATS 2020),
2020.
Ahmed Khaled, Konstantin Mishchenko, and Peter Richtarik. First analysis of local gd on hetero-
geneous data. NeurIPS Workshop on Federated Learning for Data Privacy and Confidentiality,
2019.
Rahul Kidambi, Praneeth Netrapalli, Prateek Jain, and Sham Kakade. On the insufficiency of existing
momentum schemes for stochastic optimization. In 2018 Information Theory and Applications
Workshop (ITA), pp. 1-9. IEEE, 2018.
Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian U Stich. A
unified theory of decentralized sgd with changing topology and local updates. arXiv preprint
arXiv:2003.10422, 2020.
Monica S Lam, Giovanni Campagna, Silei Xu, Michael Fischer, and Mehrad Moradshahi. Protecting
privacy and open competition with almond: an open-source virtual assistant. XRDS: Crossroads,
The ACM Magazine for Students, 26(1):40-44, 2019.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated optimization in heterogeneous networks. MLSys, 2020a.
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of
fedavg on non-iid data. ICLR, 2020b.
Xianfeng Liang, Shuheng Shen, Jingchang Liu, Zhen Pan, Enhong Chen, and Yifei Cheng. Variance
reduced local sgd with lower communication complexity. arXiv preprint arXiv:1912.12844, 2019.
Chaoyue Liu and Mikhail Belkin. Accelerating sgd with momentum for over-parameterized learning.
ICLR, 2020.
10
Under review as a conference paper at ICLR 2021
Tianyi Liu, Zhehui Chen, Enlu Zhou, and Tuo Zhao. Toward deeper understanding of noncon-
vex stochastic optimization with momentum using diffusion approximations. arXiv preprint
arXiv:1802.05155, 2018.
Wei Liu, Li Chen, Yunfei Chen, and Wenyi Zhang. Accelerating federated learning via momentum
gradient descent. IEEE Transactions on Parallel and Distributed Systems, 2020.
Siyuan Ma, Raef Bassily, and Mikhail Belkin. The power of interpolation: Understanding the
effectiveness of sgd in modern over-parametrized learning. ICML, 2018.
H Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, et al. Communication-efficient
learning of deep networks from decentralized data. Proceedings of the 20 th International
Conference on Artificial Intelligence and Statistics (AISTATS), 2017.
Eric Moulines and Francis R Bach. Non-asymptotic analysis of stochastic approximation algorithms
for machine learning. In Advances in Neural Information Processing Systems, pp. 451-459, 2011.
Deanna Needell, Rachel Ward, and Nati Srebro. Stochastic gradient descent, weighted sampling, and
the randomized kaczmarz algorithm. In Advances in neural information processing systems, pp.
1017-1025, 2014.
J Platt. Fast training of support vector machines using sequential minimal optimization, in, b.
scholkopf, c. burges, a. smola,(eds.): Advances in kernel methods-support vector learning, 1998.
R Tyrrell Rockafellar. Convex analysis. Number 28. Princeton university press, 1970.
Mark Schmidt and Nicolas Le Roux. Fast convergence of stochastic gradient descent under a strong
growth condition. arXiv preprint arXiv:1308.6370, 2013.
Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet S Talwalkar. Federated multi-task
learning. In Advances in Neural Information Processing Systems, pp. 4424-4434, 2017.
Sebastian U Stich. Local sgd converges fast and communicates little. ICLR, 2019.
Thomas Strohmer and Roman Vershynin. A randomized kaczmarz algorithm with exponential
convergence. Journal of Fourier Analysis and Applications, 15(2):262, 2009.
Jianyu Wang and Gauri Joshi. Cooperative sgd: A unified framework for the design and analysis of
communication-efficient sgd algorithms. arXiv preprint arXiv:1808.07576, 2018.
Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K Leung, Christian Makaya, Ting He, and
Kevin Chan. Adaptive federated learning in resource constrained edge computing systems. IEEE
Journal on Selected Areas in Communications, 37(6):1205-1221, 2019.
Blake Woodworth, Kumar Kshitij Patel, and Nathan Srebro. Minibatch vs local sgd for heterogeneous
distributed learning. arXiv preprint arXiv:2006.04735, 2020a.
Blake Woodworth, Kumar Kshitij Patel, Sebastian U Stich, Zhen Dai, Brian Bullins, H Brendan
McMahan, Ohad Shamir, and Nathan Srebro. Is local sgd better than minibatch sgd? arXiv
preprint arXiv:2002.07839, 2020b.
Blake E Woodworth, Jialei Wang, Adam Smith, Brendan McMahan, and Nati Srebro. Graph oracle
models, lower bounds, and gaps for parallel stochastic optimization. In Advances in neural
information processing systems, pp. 8496-8506, 2018.
Hao Yu, Rong Jin, and Sen Yang. On the linear speedup analysis of communication efficient
momentum sgd for distributed non-convex optimization. ICML, 2019a.
Hao Yu, Sen Yang, and Shenghuo Zhu. Parallel restarted sgd with faster convergence and less
communication: Demystifying why model averaging works for deep learning. In Proceedings of
the AAAI Conference on Artificial Intelligence, volume 33, pp. 5693-5700, 2019b.
Honglin Yuan and Tengyu Ma. Federated accelerated stochastic gradient descent. Advances in Neural
Information Processing Systems, 33, 2020.
11
Under review as a conference paper at ICLR 2021
Kun Yuan, Bicheng Ying, and Ali H Sayed. On the influence of momentum acceleration on online
learning. The Journal of Machine Learning Research ,17(1):6602-6667, 2016.
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530, 2016.
Fan Zhou and Guojing Cong. On the convergence properties of a k-step averaging stochastic gradient
descent algorithm for nonconvex optimization. IJCAI, 2018.
12
Under review as a conference paper at ICLR 2021
A Additional Notations and Bounds for Sampling Schemes
In this section, we introduce additional notations that are used throughout the proofs. Following com-
mon practice, e.g. Stich (2019); Li et al. (2020b), We define two virtual sequences Vt = PN=I PkVk
and Wt = PN=ι Pkwk, where we recall the FedAvg updates from (2):
Vtk+1 = wtk - αtgt,k ,
k
Vt+1
k∈St+1 qk Vt+1
if t + 1 ∈/ IE ,
ift+ 1 ∈IE.
The following observations apply to FedAvg updates, while Nesterov accelerated FedAvg requires
modifications. For full device participation or partial participation with t ∈ ZE, note that Vt =
Wt = PN=I Pkvtk. For partial participation with t ∈ IE, Wt = Vt since Vt = PN=I PkVk while
Wt = Pk∈st qkwk. However, we can use unbiased sampling strategies such that EStWt = V Note
that Vt+ι is one-step SGD from Wt.
Vt+1 = Wt — αtgt,	(3)
where gt = PkN=1Pkgt,k is the one-step stochastic gradient averaged over all devices.
gt,k = VFk (Wk,ξk),
Similarly, we denote the expected one-step gradient gt = Eξt [gt] = PN=I pkEξkgt,k, where
Eξkgt,k = VFk (Wk),	(4)
and ξt = {ξtk}kN=1 denotes random samples at all devices at time step t.
Since in this work we also consider the case of partial participation, the sampling strategy to
approximate the system heterogeneity can also affect the convergence. Here we follow the prior
works Li et al. (2020b) and Li et al. (2020a) and consider two types of sampling schemes that
guarantee ESt Wt = Vt. The sampling scheme I establishes St+ι by i.i.d. sampling the devices
according to probabilities Pk with replacement, and setting qk = K. In this case the upper bound of
expected square norm of Wt+ι — Vt+ι is given by (Li et al., 2020b, Lemma 5):
ESt+1 kWt+1 - Vt+1k2 ≤ Ka2E2G2.	(5)
The sampling scheme II establishes St+1 by uniformly sampling all devices without replacement and
setting qk = PkN, in which case we have
Est+ι kWt+1 — Vt+ιk2 ≤ KN-弋a2E2G2.	(6)
K (N— 1)
We summarize these upper bounds as follows:
ESt+1 kWt+1 - Vt+1k2 ≤ Ka2E2G2∙	⑺
and this bound will be used in the convergence proof of the partial participation result.
B Comparison of Convergence Rates with Related Works
In this section, we compare our convergence rate with the best-known results in the literature (see
Table 2). In Haddadpour & Mahdavi (2019), the authors provide O(1/N T ) convergence rate of non-
convex problems under Polyak-Lojasiewicz (PL) condition, which means their results can directly
apply to the strongly convex problems. However, their assumption is based on bounded gradient
diversity, defined as follows:
A(W)— Pk Pk kvFk(W)k2
A(W)= k PkPkVFk(W)k2 ≤ B
This is a more restrictive assumption comparing to assuming bounded gradient under the case of target
accuracy → 0 and PL condition. To see this, consider the gradient diversity at the global optimal
13
Under review as a conference paper at ICLR 2021
W, i.e., Λ(w*) = P Pkk晨Fk(W)k2. For Λ(w*) to be bounded, it requires ∣∣VF1k (w*)∣∣2 = 0, ∀ k.
k λ^k Pk V Fk (W) 2
This indicates w* is also the minimizer of each local objective, which contradicts to the practical
setting of heterogeneous data. Therefore, their bound is not effective for arbitrary small -accuracy
under general heterogeneous data while our convergence results still hold in this case.
In Karimireddy et al. (2019), the linear speedup convergence rate of FedAvg are provided for strongly
convex, general convex, and non-convex problems under full participation setting. However, their
rate does not enjoy linear speedup for any number of devices while our results apply to any valid
K ≤ N. For example, they provides an optimality gap of O ((1 一 K)E/T)for the strongly convex
case (Karimireddy et al., 2019, Theorem V). With partial participation, and when K = O(1), their
convergence rate is O(E/T) which does not have linear speedup. Under partial participation, the
FedAvg analyses in Karimireddy et al. (2019) requires E = O(1). For example, the strongly
convex result O((1 — N)E/T) in Theorem V is O(E∕T) when K = O(1) and is O(E∕NT) when
K = O(N). In either case, to achieve a O(1/T) convergence rate, it requires E = O(1) as well.
Similar conclusion also holds for the general convex problem.
Reference	Convergence rate		E		NOnUD	Participation	Extra Assumptions	Setting
FedAvgLi et al. (2020b)	o( E2)	O(1)	✓	Partial	Bounded gradient	Strongly convex
FedAvgHaddadpour & Mahdavi (2019)		O( K1T )		-O(K-1/3T 2/3 )1	✓相	Partial	Bounded gradient diversity	Strongly convex §
FedAvgKoloskova et al. (2020)		O( NT)		-O(N-1/2T1/2)-	✓	Full	Bounded gradient	Strongly convex
FedAvgKarimireddy et al. (2019)	O( NT )r	O(N-1/2 τ 1/2)tt-	✓	Partial	Bounded gradient dissimilarity	Strongly convex
FedAVg/N-FedAvg (our work)		O( KT )		-O(N-1∕2T 1∕2)≠-	✓	Partial	Bounded gradient	Strongly convex
FedAvgKhaled et al. (2020)	O( √Nt)	O(N-3/2T1/2)	✓	Full	Bounded gradient	Convex
FedAvgKoloskova et al. (2020)	O(√Nt)	O(N-3/4T1/4)	✓	Full	Bounded gradient	Convex
FedAvgKarimireddy et al. (2019)	O( √Nt )”	O(N-3/4 T1/4)H-	✓	Partial	Bounded gradient dissimilarity	Convex
FedAvg/N-FedAvg (our work)	O ( √Kt )	O(N-3/4T1/4 产	✓	Partial	Bounded gradient	Convex
FedAvg	O (eχp(-ENT)) 一	O(T β)	✓	Partial	Bounded gradient	Overparameterized LR
FedMass	O (exp(-E√⅜K)Γ	O(T β)	✓	Partial	Bounded gradient	Overparameterized LR
Table 2: A high-level summary of the convergence results in this paper compared to prior state-of-
the-art FL algorithms. This table only highlights the dependence on T (number of iterations), E
(the maximal number of local steps), N (the total number of devices), and K ≤ N the number of
participated devices. κ is the condition number of the system and β ∈ (0, 1). We denote Nesterov
accelerated FedAvg as N-FedAvg in this table.
t This E is obtained under i.i.d. setting.
^ This E is obtained under full participation setting.
§ In Haddadpour & Mahdavi (2019), the convergence rate is for non-convex smooth problems with
PL condition, which also applies to strongly convex problems. Therefore, we compare it with our
strongly convex results here.
计 The bounded gradient diversity assumption is not applicable for general heterogeneous data when
converging to arbitrarily small -accuracy (see discussions in Sec B).
计 Although the results in Karimireddy et al. (2019) is applicable for partial participation setting,
their results only achieve linear speedup under full participation setting K = N while we show
linear speedup convergence for K ≤ N (see discussions in Sec B). The E in the table is obtained
under full participation. Under partial participation, the communication complexity is E = O(1).
C A High-level Summary of FedAvg analysis
To facilitate the understanding of our analysis and highlight the improvement of our work comparing
to prior arts, we summarize the general steps used in the proofs across the various settings. In this
section, we take the strongly convex case as an example to illustrate our analysis. The corresponding
proof for general convex functions follows the same framework.
One step progress bound
This step establishes the progress of distance (∣Wt — w* ∣∣2) to optimal solution after one step SGD
update (see line 9, Alg 1), as the following equation shows:
Ekwt+1 — w*∣2 ≤ O(ηtE∣Wt — w*∣2 + α2σ2∕N + α3E2G2).
14
Under review as a conference paper at ICLR 2021
Algorithm 1 FEDAVG: Federated Averaging
1:	Server input: initial model w0, initial step size α0, local steps E.
2:	Client input:
3:	for each round r = 0,1,…,R, where r = t * E do
4:	Sample clients St ⊆ {1, ..., N}
5:	Broadcast w to all clients k ∈ St
6:	for each client k ⊆ St do
7:	initialize local model wtk = w
8:	for t = r * E + 1, . . . , (r + 1) * E do
kk
9:	wtk+1 = wtk - αtgt,k
10:	end for
11:	end for
12:	Average the local models at server end: Wt = P,k∈st wk.
13:	end for
The above bound consists of three main ingredients, the distance to optima in previous step (with
ηt ∈ (0, 1) to obtained a contraction bound), the variance of stochastic gradients in local clients
(second term), the variance across different clients (third term). Notice that the third term in this
bound is the primary source of improvement in the rate. Comparing to the bound in Li et al. (2020b),
we improve the third term from O(αt2E2G2) to O(αt2E2G2), which enables the linear speedup in
the convergence rate.
Iterative deduction
This step uses the one step progress bound iteratively to connect the the current distance to optimal
solution with the initial distance (∣∣Wo - w* k2), as follows:
E∣∣Wt+ι - w*k2 ≤ O(EkWO- w*k2T).
Then we can use the distance to optima to upper bound the optimality gap (F (wt) - F * ≤ O(1/T)),
as follows:
E(F (Wt))- F * ≤O(E∣∣Wt- w*k2).
The convergence rate of the optimality gap is equally obtained as the convergence rate of the distance
to optima.
From full participation to partial participation
There are three sources of variances that affect the convergence rate. The first two sources come from
the variances of within local clients and across clients (second and third term in one step progress
bound). The partial participation, which involves a sampling procedure, is the third source of variance.
Therefore, comparing to the rate in full participation, this will add another term of variance into the
convergence rate, where we follow a similar derivation as in Li et al. (2020b).
D Technical lemmas
To facilitate reading, We first summarize some basic properties of L-smooth and μ-strongly convex
functions, found in e.g. Rockafellar (1970), which are used in various steps of proofs in the appendix.
Lemma 1. Let F be a convex L-smooth function. Then we have the following inequalities:
1.	Quadratic upper bound: 0 ≤ F(w) — F(w0) — WF(w0), W — w0i ≤ L ∣∣w — w0k2.
2.	Coercivity: L∣∣VF(w) - VF(w0)∣2 ≤hVF(W) - VF(w0), W — w0).
3.	Lower bound: F (w) ≥ F (w0) + (VF(w0), W — w0) + 2L ∣∣VF (w) — VF (w0)∣2. In particular,
∣VF (w)∣2 ≤ 2L(F (w) - F(w*)).
4.	Optimality gap: F(w) - F(w*) ≤hVF (w), w - w*i.
Lemma 2. Let F be a μ-strongly convex function. Then
F(w) ≤ F(w0) + hVF(w0), w — w0) + LkVF(W) — VF(w0)∣2
2μ
15
Under review as a conference paper at ICLR 2021
F(W) — F(w*) ≤
2μ kVF (w)k2
E Proof of Convergence Results for FedAvg
E.1	Strongly Convex Smooth Objectives
To organize our proofs more effectively and highlight the significance of our results compared to
prior works, we first state the following key lemmas used in proofs of main results and defer their
proofs to later.
Lemma 3 (One step progress, strongly convex). Let Wt = PN=I Pk wk, and suppose ourfunctions
satisfy Assumptions 1,2,3,4, and set step size ɑt = *(3)with Y = max{32κ, E} and K = L, then
the updates of FedAvg with full participation satisfy
EIlWt+ι - w*ll2 ≤ (I- Mat)EkWt- w*∣∣2 + α2NVmαxσ2 + 6E2La3G2.
We emphasize that the above lemma is the key step that allows us to obtain a bound that improves
on the convergence result of Li et al. (2020b) with linear speedup. Its proof will make use of the
following two results.
Lemma 4 (Bounding gradient variance (Lemma 2 Li et al. (2020b)) ). Given Assumption 3, the
upper bound of gradient variance is given as follows,
N
Ekgt-gtk2 ≤ XPkσ2.
k=1
Lemma 5 (Bounding the divergence of wtk (Lemma 3 Li et al. (2020b)) ). Given Assumption 4,
and assume that at is non-increasing and at ≤ 2at+E for all t ≥ 0, we have
N
E XPk ∣∣wt - wkk2 ≤ 4E2a2G2.
k=1
We now restate Theorem 1 from the main text and then prove it using Lemma 3.
Theorem 1.	Let WT = PN=I PkWT in FedAvg, VmaX = maxk NPk, and Set decaying learning
rates at = *(九)with Y = max{32κ, E} and K = L. Then under Assumptions 1,2,3,4 WithfUll
device participation,
EF (WT) - F * = O ( KVmNT2/〃 + METG2/")
and with partial device participation with at most K sampled devices at each communication round,
WPVW、 P* C (κE2G2∕μ I κVmaXb2∕μ I κ2E2G2∕μ)
EF (WT)-F = O( KT + NT + ~T2— J
Proof. The road map of the proof for full device participation contains three steps. First, we establish
a recursive relationship between E∣Wt+ι - w*∣2 and EkWt - w*∣2, upper bounding the progress of
FedAvg from step t to step t + 1. Second, We show that EkWt - w*∣2 = O(VmaχN '" + EILG2∣μ)
by induction using the recursive relationship from the previous step. Third, we use the property of
L-smoothness to bound the optimality gap by EkWt - w*∣2.
By Lemma 3, we have the following upper bound for the one step progress:
EkWt+1 - w*k2 ≤ (1 - Mat)EkWt- w*k2 + a2 NVm axσ2 + 6E2La3G2.
16
Under review as a conference paper at ICLR 2021
We show next that EkWt - w*k2 = O(IVmaxN / + E LG / ) using induction. To simplify the
presentation, We denote C ≡ 6E2LG2 and D ≡ NVmaχσ2. Suppose that We have the bound
EIlWt - w*k2 ≤ b ∙ (αtD + α2C) for some constant b and learning rates ah Then the one step
progress from Lemma 3 becomes:
EllWt+ι — w* ∣2 ≤ (b(1 — μαt) + αt)αtD + (b(1 — μαt) + αt)α2C
To establish the result at step t+1, it remains to choose at and b such that (b(1-μαt)+αt)αt ≤ bαt+1
and (b(1 - μαt) + at)a2 ≤ ba2+1. If we let a = μt+γ) where Y = max{E, 32κ} (choice of Y
required to guarantee the one step progress) and set b = 4, we have:
444	4
EI-吟)+ at)at = C(I-干)+ μw^y) μt+γ) ≤ bμ(t+γ + i) =bαt+1
2 t+Y-2	16	16	2
(b(I- μat) + at)at = b(-τ+γr)μ2wγy ≤ %(t + γ+ 1)2 = bat+1
where we have used the following inequalities:
t + Y - 1 ≤	1	t + Y - 2 ≤	1	∀ ≥ I
(t + γ)2 - (t + Y + 1)	(t + γ)3 - (t + Y +1)2 Y -
Thus we have established the result at step t + 1 assuming the result is correct at step t:
EIIWt+1 - W* k2 ≤ b ∙ (at+1D + a2+1C)
At step t = 0, we can ensure the following inequality by scaling b with ckw0 -w* k2 for a sufficiently
large constant c:
∣∣Wo - W*∣2 ≤ b ∙ (aoD + a0C) = b ∙ (ɪD + -^CC)
μY	μ2Y2
It follows that
EIIWt- W*k2 ≤ c∣W0 - W*k24(Dat + CaoC)	(8)
μ
for all t ≥ 0.
Finally, the L-smoothness of F implies
E(F(WT)) — F* ≤ τ^E∣Wτ — W*∣2
≤ —c∣Wo — W*∣2-(DaT + CaT)
2	μ
= 2cIW0 - W* I2κ(DaT + Ca2T)
≤ 2ckW0 - w*k2κ _μ(T: Y) ∙ NNVmaxσ2 + 6E2LG2 ∙ (μ(T: Y) )2_
=O(μKNNVmaχσ2 ∙ T■ + κμE2G2 ∙ T)
where in the first line, we use the property of L-smooth function (see Lemma 1), and in the second
line, we use the conclusion in Eq (8).
With partial participation, the update at each communication round is now given by weighted averages
over a subset of sampled devices. When t +1 ∈ IE, Vt+ι = Wt+ι, while when t + 1 ∈ ZE, we have
EWt+ι = Vt+ι by design of the sampling schemes (Li et al. (2020b), Lemma 4), so that
EIlWt+ι - w*∣2 = EIlWt+ι - Vt+1 + Vt+1 - w*∣2
=EkWt+ι — Vt+ι∣∣2 + E∣∣Vt+ι — w*I2
This in particular implies Ekvt — w*∣∣2 ≤ Ekwt — w*∣∣2 for all t. Since Vt = PN=IPkVk always
averages over all devices, the full participation one step progress result Lemma 3 applied to Vt implies
EkVt+1 - w*∣∣2 ≤ E(I- μαt)kvt - w*∣∣2 + 6E2La3G2 + a2 NVm aχσ2
17
Under review as a conference paper at ICLR 2021
≤ E(I- μαt)kwt - w*k2 + 6E2La3G2 + α2 NVm axσ2
The bound for E∣∣Wt+ι - Vt+ι ∣∣2 for the two sampling schemes We consider is provided in Eq (7),
and applying it we can write the one step progress for partial participation as
EIlWt+1 - w*k2 ≤ (I- μat)Ekwt - w*k2 + a2 而 Vm axσ2 + -V7a2E2G2 + 6E2La3G2, ⑼
NK
and the same arguments using induction and L-smoothness as the full participation case implies
WpVW、 pl* C(KVmaxσ /μ κE2G2Λ« κ2E2G2j¼∖
EF(WT) - F = O( —NT— + —KT— + —T2-)
□
E.1.1 Deferred proofs of key lemmas
Here we first rewrite the proofs of lemmas 4 and 5 from Li et al. (2020b) with slight modifications
for the consistency and completeness of this work, since later we will use modified versions of these
results in the convergence proof for Nesterov accelerated FedAvg.
Proof of lemma 4.
NN
Ekgt- gtk2 = Ekgt- Egtk2 = XPkkgt,k - Egt,kIl2 ≤ XPkσ2
k=1	k=1
□
Proofoflemma 5. Now We bound E PN=I Pk ∣∣Wt - wtkk2 following Li et al. (2020b). Since com-
munication is done every E steps, for any t ≥ 0, we can find a t0 ≤ t such that t - t0 ≤ E - 1 and
wko = Wtofor all k. Moreover, using at is non-increasing and at。≤ 2at for any t - to ≤ E - 1,
we have
N
E XPk kwt - Wk k2
k=1
N
=E X Pk kwk - wto - (Wt - wto )k2
k=1
N
≤e X Pk kWk - Wto k2
k=1
N
=EXPkkWtk -Wtk0k2
k=1
N	t-1
=EXPkk-Xaigi,kk2
k=1	i=t0
N	t-1
≤2XPkEXEai2kgi,kk2
k=1	i=t0
N
≤2XPkE2at20G2
k=1
≤4E2 at2G2
□
18
Under review as a conference paper at ICLR 2021
Based on the results of Lemma 4, 5, we now prove the upper bound of one step SGD progress. This
proof improves on the previous work Li et al. (2020b) and is the first to reveal the linear speedup of
convergence of FedAvg.
Proof of lemma 3. We have
kwt+1 - w*k2 = k(Wt - αtgt) - w*k2 = k(Wt - αtgt - w*) - αt(gt - gJk2
=∣∣Wt - w* - αtgtk2 +2αt{Wt - w* - αtgt, gt - gt∖ + α2∣∣gt - gt∣∣2
S--------{z-------} S-------------{z-----------} S------y-----}
A1	A2	A3
where we denote:
Ai = kwt - w* - atgtk2
A2 = 2athwt - w* - atgt, gt - gti
A3 = a2kgt - gtk2
By definition of gt and g (See Eq (4)), We have EA2 = 0. For A3, We have the following upper
bound (see Lemma 4):
N
α2Ekgt- gtk2 ≤ a2 XPkσk
k=1
Next We bound A1 :
kwt - w* - atgtk2 = kwt - w*∣2 +2hwt - w*, -atgti + I∣atgtk2
and we will show that the third term ∣∣atgtk2 Can be canceled by an upper bound of the second term,
Which is one of major improvement comparing to prior art Li et al. (2020b). The upper bound of
second term can be derived as follows, using the strong convexity and L-smoothness of Fk :
-2αthwt - w*, gti
N
=-2at XPkhwt- w*, RFk(Wit))
k=1
NN
=-2at XPkhWt- wk, VFk(wk)i - 2at XPkhwk - w*, VFt(wk))
k=1	k=1
N	NN
≤ - 2at XPkhWt- Wk, VFk(Wk))+ 2at XPk(Fk(w*) - Fk(Wk))- atμXPk∣∣wf - w*∣2
k=1	k=1	k=1
N
≤2at XPk	Fk(wk) -	Fk(Wt)	+ -∣∣wt	- Wk∣∣2 + Fk(w*) -	Fk(wk)
k=1
N
-atμ∣ XPkWk - w*∣2
k=1
NN
=atLXPkkwt - Wkk2 +2at XPk [Fk(w*) - Fk(wt)] - atμ∣wt - w*∣2
k=1	k=1
We record the bound we have obtained so far, as it will also be used in the proof for convex case:
N
Ekwt+1 - w*k2 ≤E(1 - μat)kwt - w*∣∣2 + at,L XPkkwt - Wk∣∣2
k=1
NN
+ 2at XPk [Fk(w*) - Fk(wt)] + a2 XP2kσ2 + a2kgtk2	(IO)
k=1	k=1
For the term 2at Pk=IPk [Fk(w*) - Fk(wt)], which is negative, we can ignore it, but this yields a
suboptimal bound that fails to provide the desired linear speedup. Instead, we upper bound it using
the following derivation:
N
2at XPk [Fk(w*) - Fk(wt)]
k=1
19
Under review as a conference paper at ICLR 2021
≤2αt [F(Wt+ι) - F(Wt)]
≤2αtEhVF(Wt), Wt+ι - Wti + αtLEkWt+ι - Wt∣∣2
=-2α2EhVF(Wt), gti + α3LEkgtk2
=-2α2EhVF (Wt), gti + α3LEkgtk2
=- α2 [kVF(Wt)k2 + kgtk2 -kVF(Wt)- gtk2] + α3LEkgt∣∣2
=-α2 kVF(Wt)k2 + kgtk2-kVF(Wt) - XPkVF(wM∣2 + α3LE∣∣gt∣∣2
k
≤-α2 kVF(Wt)k2 + kgtk2 - XPkkVF(Wt) - VF(wk)∣∣2 +。3力园||由『
≤-α2 kVF(Wt)k2 + llgtk2 - L2 XPkIlwt - WkIl2 +。〃园山『
k
≤ -α2kgtk2 + α2L2 XPkkWt- WkIi2 + α3LEkgtk2 - α2kVF(wt)k2
k
where we have used the smoothness of F twice.
Note that the term -a； ∣gtk2 exactly cancels the a； ∣gtk2 in the bound in Eq (10), So that plugging
in the bound for -2αt(Wt - w* , gj, We have So far proved
NN
EkWt+1 - w*k2 ≤ E(1 - μat)kWt - w*∣2 + atLXPkkWt- Wk∣∣2 + a； XPkσ2
k=1	k=1
N
+ a；L2 XPk∣∣Wt - Wkk2 + a3LEkgtk2 - a2kVF(Wt)k2	(11)
k=1
Under ASSumption 4, We have Ekgtk2 ≤ G2. Furthermore, We can check that our choice of at
satisfies at is non-increasing and a ≤ 2at+E, so we may plug in the bound EPN=I Pk ∣∣Wt 一
Wtk k2 ≤ 4E2at2G2 to the above inequality (See Lemma 5).
Therefore, we can conclude that, with Vmax ：= N ∙ maxk Pk and Vmin ：= N ∙ mink Pk,
EkWt+1 - w*∣2
N
≤E(1 - μat)kWt - w*∣2 + 4E2La3G2 + 4E2L2a4G2 + 02 XPkkσ2 + a；LG2
k=1
=E(1 — μat) kWt — w* k2 + 4E2La3G2 + 4E2L2a4G2 + a2 N2)：(PkN)2σ2 + a；LG2
k=1
1N
≤E(1- μat)kwt - w*∣2+4E2La3G2+4E2L2a4G2+a2 N2 Vm ax £。2+a3LG2
k=1
≤E(1 - μat)kwt - w*∣2 + 6E 2La3G2 + a2 NVm axσ2
where in the last inequality we use σ2 = PN=I Pkσ2, and that by construction at satisfies Lat ≤ 1.
□
One may ask whether the dependence on E in the term KEKGT ∕μ can be removed, or equivalently
whether PkPkkWk - Wtk2 = O(1∕T2) Can be independent of E. We provide a simple counterex-
ample that shows that this is not possible in general.
Proposition 1. There exists a dataset such that if E = O(Tβ) for any β > 0 then	k Pk kWtk -
wtk2 = Ω(τ2-2β).
20
Under review as a conference paper at ICLR 2021
Proof. Suppose that We have an even number of devices and each Fk(W) = ^^ Pn= 1(xk - w)2
contains data points Xk = w*,k, with n ≡ n. Moreover, the w*,k's come in pairs around the origin.
As a result, the global objective F is minimized at w* = 0. Moreover, if we start from W0 = 0, then
by design of the dataset the updates in local steps exactly cancel each other at each iteration, resulting
in Wt = 0 for all t. On the other hand, if E = Tβ, then starting from any t =O(T) with constant
step size O( T), after E iterations of local steps, the local parameters are updated towards w*,k with
∣∣wk+Ek2 = Ω((Tβ ∙ T)2) = Ω(T2-2β). This implies that
X Pk llwk+E - wt+E k2 = X Pk kwk+E k2
kk
=a( T 2-2β)
which is at a slower rate than 击 for any β > 0. Thus the sampling variance E∣wt+1 - Vt+11∣2 =
Ω(PkPkEkWk+ι - wt+11∣2) decays at a slower rate than 齐,resulting in a convergence rate slower
than O(Tt) with partial participation.	□
E.2 Convex Smooth Objectives
In this section we provide the proof of the convergence result for FedAvg with convex and smooth
objectives. The key step is a one step progress result analogous to that in the strongly convex case,
and their proofs share identical components as well.
Lemma 6 (One step progress, convex case). Let Wt = PN=I PkWk in FedAvg. Under assump-
tions 1,3,4, the following bound holds for all t:
E∣∣Wt+ι - w*k2 + αt(F(Wt) - F(w*)) ≤ EkWt- w*∣2 + α2NVmaXσ2 + 6α3E2LG2
Proof. The first part of the proof follows directly from Eq (10) in the proof of Lemma 3. Setting
μ = 0 in Eq (10) (since we are in the convex setting instead of strongly convex), we obtain
N
kWt+1 - w*k2 ≤ ∣∣Wt - w*k2 + αtLXPk∣∣Wt - Wk∣∣2
k=1
NN
+ 2% X Pk [Fk (w*)- Fk (Wt)] + α2kgtk2 + α2 X Pk σk
k=1	k=1
The difference of this bound with that in the strongly convex case is that we no longer have a
contraction factor of 1 - μαt in front of ∣∣Wt - w* k2. In the strongly convex case, we were able to
cancel α2∣gtk2 with 2ɑt PN=IPk [Fk(w*) - Fk(Wt)] and obtain only lower order terms. In the
convex case, we use a different strategy and preserve PN=I Pk [Fk(w*) - Fk (Wt)] in order to obtain
the desired optimality gap.
We have
kgtk2 = k XPkVFk(Wk)k2
k
=k XPkVFk(Wk) - XPkVFk(Wt) + XPkVFk(Wt)k2
kkk
≤ 2∣ XPkVFk(Wk) - XPkVFk(Wt)k2 + 2∣ XPkVFk(Wt)∣2
kk	k
≤ 2L2 XPk∣∣wk - Wtk2 + 2∣ XPkVFk(Wt)k2
kk
=2L2 XPk∣∣wk - Wtk2 + 2∣VF(Wt)k2
k
21
Under review as a conference paper at ICLR 2021
using VF(w*) = 0. Now using the L smoothness of F, We have ∣∣VF(Wt)II2 ≤ 2L(F(Wt)-
F(w*)), so that
l∣Wt+ι - w*k2
NN
≤∣Wt - w*k2 + at L X Pk ∣∣Wt - Wk k2 + 2αt X Pk [Fk (w*) - Fk (Wt)]
k=1	k=1
N
+ 2a2L2 XPkkWk - wtk2 + 4a2L(F(Wt)- F(w*)) + a2 Xpkσ2
k	k=1
NN
= IlWt- w*k2 + (2a2L2 + atL) XPk∣∣Wt - Wk∣∣2 + a XPk [Fk(w*) - Fk(Wt)]
k=1	k=1
N
+ a2 XPkσ2 + at(I- 4atL)(F(W*) - F(Wt))
k=1
Since F(w*) ≤ F(Wt), as long as 4aJ ≤ 1, We can ignore the last term, and rearrange the
inequality to obtain
∣∣Wt+ι - w*k2 + at (F (Wt) - F (w*))
NN
≤∣wt - w*∣2 + (2α2L2 + atL)XPkkWt- WkIl2 + a2 XP2kσk
k=1	k=1
3N	N
≤∣wt- w*∣k + 2 atL X Pk l∣wt - Wk ∣∣k + a2 X Pk σk
k=1	k=1
The same argument as before yields E PN=I Pk ∣∣Wt - Wk ∣∣k ≤ 4E2a2G2 which gives
N
∣∣Wt+ι - w*∣k + at(F(Wt) - F(w*)) ≤ ∣∣Wt - w*∣k + a2 XPkσ2 + 6a3E2LG2
k=1
≤ llwt - w* ∣2 + a NVmaXσ2 + 6a3E2LG2
□
With the one step progress result, we can now prove the convergence result in the convex setting,
which we restate below.
Theorem 2.	Under assumptions 1,3,4 and Constant learning rate at = O(ypNN), FedAvg satisfies
.口L、 似 *、	C(VmaXσ2	NE2 LG2 ∖
minF(Wt)-F (W) = O[-√NT- +
with full participation, and with partial device participation with K sampled devices at each commu-
nication round and learning rate at
min F(wt) - F(w*) = O (VmaQ + EkGk + KEkLG2
t≤τ ( t)	( )	\ √KT + √KT + T
Proof. We first prove the bound for full participation. Applying Lemma 6, we have
llwt+1 - w*∣2 + at(F(Wt)- F (w*)) ≤ ∣∣wt - w*∣2 + a NVmaXσ + 6a3E2LG2
Summing the inequalities from t = 0 to t = T , we obtain
T	TT
X at(F (Wt)- F (w*)) ≤ ι∣wo- w*ιι2 + X a2 ∙ NVmaXσ + X a3 ∙ 6E 2LG2
t=0	t=0	t=0
22
Under review as a conference paper at ICLR 2021
so that
m≤inF(Wt) - F(w*) ≤ ^t1- Hlwo- w*k2 + Xα2 ∙ NnVmaxσ2 + Xα3 ∙ 6E2LG2
≤	t=0 αt	t=0	t=0
By setting the constant learning rate at ≡ JT, We have
m≤inF(Wt)- F(W) ≤ √nNT ∙ kwo - w*k2 + √= T ∙
≤	1——∙ ∣∣W0 - w*k2 + 1——T ∙
Nnt	nt
=(∣∣W0 — w*k2 + Vmax σ2) 1——+
max
NT
V2 σ2	N E2 LG2
=O( m0^ H--------)
ι √NT	T
・ ɪ ν2 σ2 +	1 T (JN )36E2LG2
N maX + √NT (V T) LG
• NVmaxσ2 + T 6E2LG2
6E2LG2
For partial participation, the one step progress bound in Lemma 6 is updated in a similar manner as
the strongly convex case in (9) to incorporate the sampling variance. More precisely, with partial
participation,
Ekwt+1 - w*k2 = Ekwt+1 - Vt+ι + Vt+ι - w*k2
=Ekwt+ι - Vt+ι∣2 + E∣Vt+ι - w*k2,
where Ewt+ι = Vt+ι for all t, by the unbiasedness of our sampling schemes. Since Vt =
PkN=1 pkvtk always averages over all devices, the full participation one step progress bound in
Lemma 6 applied to Vt implies
EIlvt+ι - w*ll2 + αt(F(Vt)- F(w*)) ≤ EllVt- w*ll2 + a2NVmaxσ2 + 6a3E2LG2
≤ Ekwt- w*∣∣2 + a2 NVmaxσ2 +6a3E2LG2
The bound for Ε∣Wt+ι — Vt+ι ∣∣2 for the two sampling schemes we consider is provided in Eq (7),
and applying it to the above bound We can Write the one step progress for partial participation as
Ellwt+1 - w*∣∣2 + αt(F(Wt)- F(w*)) ≤ Ekwt- w*∣∣2 + a2(NVmaxσ2 + C) + 6E2La3G2,
where C =2E2G2 or N-K 今 E2G2 depending on the sampling scheme.
Summing up the one-step progress over t,
minF(Wt) - F(w*) ≤ ≡T1—
t≤T	t=o at
so that with at = ʌ/Kf, we have
T1	T
Ilwo - w*l∣2 + a2 ∙ ( NVmaxσ2 + C) + ɪs a3 • 6E2LG2 卜
t=0	t=0
n_ jVmaxσ2	E2G2 ɪ KE2LG2、
min F(Wt)- F(w)=O(-√kf+√κτ+—t—).
□
F Proof of Convergence Results for Nesterov Accelerated
FedAvg
F.1 Strongly Convex Smooth Objectives
Recall that the Nesterov accelerated FedAvg follows the updates
Vk _ wk_co	Wk — ∫vk+1 + βt(vk+1-vk)	if t + 1 ∈ IE,
Vt+1 = wt - atgt,k, wt+1 = Pk∈St+1 qk Vtk+1 + βt(Vtk+1 - Vtk) ift+1∈IE.
23
Under review as a conference paper at ICLR 2021
The proofs of convergence results for Nesterov Accelerated FedAvg consists of components that are
direct analogues of the FedAvg case. We first state these analogue results before proving the main
theorem. Like before, the proofs of the lemmas are deferred to after the main proof.
Lemma 7 (One step progress, Nesterov). Let Vt = PN=I PkVk in Nesterov accelerated FedAvg,
and suppose our functions satisfy Assumptions 1,2,3,4, and set step sizes αt = 6∙^, βt-ι
μ t+γ
14(t+γ)(1-t+γ )max{μ,1} With Y = maxG2κ, E} and K
FedAvg satisfy
L, the updates of Nesterov accelerated
EllVt+1 - w*k2 ≤ E(1 - μαt)(1 + βt-i)2∣∣Vt - w*∣∣2 + 20E2Lα3G2 + (1 - αtμ)β2-ik(Vt-i - w")∣∣2
+ α2 NVmaxσ + 2βt-1(1 + βt-I)(I - atM) IlVt - w*∣∣∙ kVt-1 - w*k
The one step progress result makes use of the same bound on the gradient variance in Lemma 4, as
well as a divergence bound analogous to Lemma 5, which we state below.
Lemma 8 (Bounding the divergence of wtk , Nesterov). Given Assumption 4, and assume that αt is
non-increasing, at ≤ 2at+E, and 2β2-ι + 2a2 ≤ 1/2 for all t ≥ 0, wt = PN=I PkWk in Nesterov
accelerated FedAvg satisfies
N
E XPkkWt- Wkk2 ≤ 16(E - 1)2αt2G2.
k=1
Theorem 3. Let VT
αt = 6 t+γ, βt-1 =
participation,
PkN=1PkVkT in Nesterov accelerated FedAvg and set learning rates
___________3___________
14(t+γ)(1-t+γ) max{μ,1} *
Then under Assumptions 1,2,3,4 with full device
EF (VT) - F * = O ( KVmNT2
/μ + κ2E2G2∕μ
T2
and with partial device participation with K sampled devices at each communication round,
νpf- ʌ F*	(κνmaxb2∕μ I κE2G2∕μ I κ2E2G2∕μ
EF(VT) - F = O ( NT + KT + -Ti—
Proof* We first prove the result for full participation. Applying the one step progress bound in
Lemma 7, we have
EkVt+1 - w*∣∣2 ≤ E(I- μαt)(1 + βt-1)2kVt- w*∣∣2 + 20E2La3G2 + (1 - αtμ)β2-1k(νt-1 - w*)k2
+ a2 NVmaxσ2 + 2βt-1(1 + βt-I)(I - atM)kVt - w*∣∣∙ ||Vt-1 - w*k
Recall that We require αt0 ≤ 2at for any t - to ≤ E - 1, Lat ≤ 1, and 2β2-ι + 2α2 ≤ 1/2 in order
for Lemmas 8 and 7 to hold, which we can check by definition of αt and βt .
We show next that Ekvt - w*k2 = O( VmaxN / + E LG " ) by induction. Assume that we have
shoWn
Ekvt- w*k2 ≤ b(Ca2 + Dat)
for all iterations until t, where C = 20E2LG2, D = NVmaχσ2, and b is some constant to be chosen
later. For step sizes recall that we choose at = 6t+γ and βt-ι = 皆伯 ∣ …/). 弋)max{μi} where
γ = max{32κ, E}, so that βt-1 ≤ at and
63
(I- μαt)(1 + 14βt-1) ≤(I- G )(1+ (t + γ)(1-点))
6	3	3	_	μat
t + γ t + γ t + γ	2
24
Under review as a conference paper at ICLR 2021
Moreover, EkVt-ι - w*∣∣2 ≤ b(Cα2-i + Dαt-ι) ≤ 4b(C02 + Dat) with the chosen step sizes.
Therefore the bound for EkVt+1 - w* k2 can be further simplified with
2βt-i(1 + βt-i)(1 - atμ)Ekvt - w*k ∙ ∣∣Vt-i - w*k ≤ 4βt-i(1 + βt-i)(1 - «tμ) ∙ b(Cα2 + Dat)
and
(1 - αtμ)β2-ιEk(vt-i - w*)∣2 ≤ 4(1 - atμ)β2-ι ∙ b(Ca2 + Dat)
so that
EllVt+i - w*∣∣2 ≤ (1 - Mat)((I + βt-1)2 + 4βt-i(1 + βt-i) + 4β2-1) ∙ b(Ca2 + Dat)
+ 20E 2Lo3G2 + a2 NVmaXσ2
≤ E(I - μat)(1 + 14βt-i) ∙ b(Ca2 + Dat) + 20E2LaiGi2 + a2 NVmaXσ
≤ b(1 -号)(Ca2 + Dat) + Ca； + Da2
=(b(1 - ^ɪ) + at)a2C + (b(1 - ^ɪ) + at)atD
and so it remains to choose b such that
(b(1 - "2^)+ at)at ≤ bat+i
(b(1 - μ~2^~)+at)at ≤ ba2+i
from which we can conclude E∣Vt+i - w*∣2 ≤ a2+iC + at+iD.
With b = 6, we have
/	μat、	、 八, / 3 、	6	、	6
(I)(I- ɪ) + at)at = (I)(IT E)+ μt+γ)μt+γ
=(bt + Y - 3 +	6	)	6
t + γ	μ(t + γ)μ μ(t + γ)
≤ b( t+γ-l )^ɪʒ
— t + Y >(t + Y)
6
≤ bμ^m =bat+i
where we have used (++γ-1 ≤ 7+i+τ.
Similarly
(b(1 - μ∣-t)+at)a2=(b(1 - (:)+—夕;j(夕;j2
2	t + Y	μ(t + Y) μ(t + Y)
=(bt + Y - 3 +	6	)(	6	)2
t + Y	μ(t + Y) μ(t + Y)
=b( t+2^)(	θ	)2
t + Y ”μ(t + Yy
36	2
≤ bμ2(t + Y +1)2 = bat+1
where we have used
i
t+γ-2 < _________
(t+γ)3 ≤ (t+γ+1)2 .
Finally, to ensure ∣∣vq - w* ∣2 ≤ b(Ca2 + Dao), we can rescale b by c∣vo - w* ∣2 for some c. It
follows that EkVt - w*∣2 ≤ b(Ca2 + Dat) for all t ≥ 0. Using the L-smooothness of F,
E(F (VT)) - F * = E(F (Vt ) - F (w*))
≤ 77EkVT — w*∣2 ≤ —c∣vq — w*∣2-(DaT + CaT)
2	2	μ
25
Under review as a conference paper at ICLR 2021
3c∣∣ vo — w* k2κ(Daτ + CaT)
≤ 3c∣∣vo — w* ∣∣2κ
一 6
.μ(τ + Y)
1 ʊ ,r2
• Nνmaxσ
+20E2LG2 ∙ (Wb )2
O(K ɪ νmaχσ2 • 1 + KE2G2 •
μ N	T μ
With partial participation, the same argument with an added term for sampling error yields
EF(WT) - F* = O(KmT/μ + KEK^ + κ2ETG2μ)
□
F.1.1 Deferred proofs of key lemmas
Proofoflemma 8. The proof of bound for E PN=I Pk IlWt — wtk k2 in the Nesterov accelerated
FedAvg follows a similar logic as in Lemma 5, but requires extra reasoning. Since communication is
done every E steps, for any t ≥ 0, we can find a to ≤ t such that t — to ≤ E — 1 and Wko = Wto for
all k. Moreover, using αt is non-increasing, αt0 ≤ 2αt, and βt ≤ αt for any t — t0 ≤ E — 1, we have
NN
EXPkIlwt - Wkk2 = EXPkkwk -wto - (Wt-wto)k2
k=1	k=1
N
≤ EXPkkWk - Wto k2
k=1
N
=EXPkIWtk-Wtk0I2
k=1
N	t-1	t-1
=EXPkI Xβi(vik+1-vik)-Xαigi,kI2
k=1	i=t0	i=t0
N	t-1	N	t-1
≤2XPkEX(E-1)αi2Igi,kI2+2XPkEX(E-1)βi2I(vik+1-vik)I2
k=1	i=t0	k=1	i=t0
N	t-1
≤2XPkEX(E-1)αi2(Igi,kI2+I(vik+1-vik)I2)
k=1	i=t0
N	t-1
≤4XPkEX(E-1)αi2G2
k=1	i=t0
≤ 4(E - 1)2αt2 G2 ≤ 16(E - 1)2αt2G2
where we have used EIvtk - vtk-1 I2 ≤ G2. To see this identity for appropriate αt, βt, note the
recursion
vtk+1 - vtk = Wtk - Wtk-1 - (αtgt,k - αt-1gt-1,k)
Wtk+1 -Wtk = -αtgt,k +βt(vtk+1 - vtk)
so that
vtk+1 - vtk = -αt-1gt-1,k + βt-1(vtk - vtk-1) - (αtgt,k - αt-1 gt-1,k)
= βt-1(vtk - vtk-1) - αtgt,k
Since the identity vtk+1 - vtk = βt-1(vtk - vtk-1) - αtgt,k implies
EIvtk+1-vtkI2 ≤ 2βt2-1EIvtk - vtk-1I2 + 2αt2G2
as long as αt, βt-1 satisfy 2βt2-1 + 2αt2 ≤ 1/2, we can guarantee that EIvtk - vtk-1 I2 ≤ G2 for all
k by induction. This together with Jensen's inequality also gives Ekvt - Vt-1∣∣2 ≤ G2 for all t. □
26
Under review as a conference paper at ICLR 2021
Now we are ready to prove the one step progress result for Nesterov accelerated FedAvg. The first
part of the proof is identical to that of the FedAvg case, while the main recursion takes a different
form.
Proof of lemma 7. We again have
I∣vt+1 - w*k2 = Il(Wt - atgt) - w*k2
and using exactly the same derivation as the FedAvg case, we can obtain the following bound (same
as Eq (11) in the proof of Lemma 3):
NN
EIIwt+1 - w*k2 ≤ E(1 - μαt)∣wt - w*∣∣2 + αtL XPk∣∣Wt - Wk||2 + α2 XPkσ2
k=1	k=1
N
+ α2L2 XPkkwt- Wkk2 + α3LE∣gt∣2 - α2∣∣VF(Wt)∣2
k=1
Different from the FedAvg case, We no longer have wt = Vt. Instead,
kwt - w*k2 = Ilvt + βt-i(Vt - Vt-i) - w*k2
=k(1 + βt-ι)(vt - w*) - βt-1(vt-1 - w*)k2
=(1 + βt-ι)2kvt - w*k2 - 2βt-ι(1+ βt-ι)hvt - w*,vt-ι - w*i + β2-ιk(vt-ι - w*)k2
≤ (I + βt-1)2kvt - w*k2 + 2βt-1(1 + βt-I)Ilvt- w"∣∣∙ kvt-1 - w*k + β2-ik(vt-1 - w*)k2
which gives a recursion involving both V and vt-1:
N
llvt+1 - w*∣∣2 ≤ (1 - αtμ)(1 + βt-i)2Ivt - w*∣∣2 + 2(1 - αtμ)βt-i(1 + βt-i)∣∣vt - w*∣∣∙ ∣∣vt-i - w*∣∣ + α2 XPkσ2
k=1
N
+ β2-ι(1 - αtμ)l (Vt-I- w")l2 + αtL X Pk IIwt- Wk ∣∣2 + α2L2 X Pk IIwt- Wk Il2 + α3LG2
k=1	k
and we will using this recursive relation to obtain the desired bound.
We can check that our choice of αt and βt satisfy αt is non-increasing, αt ≤ 2αt+E, and 2βt2-1 +
2α2 ≤ 1/2 for all t ≥ 0, so that we can apply the bound from Lemma 8 on E Pk=I Pk ∣∣wt - Wkk2
to conclude that, with VmaX ：= N ∙ maxk Pk,
E∣∣vt+1 - w*∣∣2 ≤ E(1 - μαt)(1 + βt-ι)2∣∣vt - w*∣∣2 + 16E2La3G2 + 16E2L2α4G2 + at3LG1
N
+ (1 - αtμM2-ι∣∣(vt-ι - w")l2 + α2 Xpkσk + 2βt-ι(I + βt-I)(I- atμ)lvt - w*l∣∙ llvt-ι - w*ll
k=1
≤ E(I - μαt)(1 + βt-Q2∣∣vt- w*Il2 + 20E2La3G2 + (1 - αtμ)β2-ιi(vt-ι - w*)∣2
+ a2 NVmaXσ + 2βt-1(1 + βt-I)(I - atμ)∣vt - w*∣∣∙ ∣∣vt-1 - w* ∣∣
where we have used σ2 = Pk Pkσ2, and by construction our at satisfies Lat ≤ ɪ.	□
F.2 Convex Smooth Objectives
In this section we provide proof of the convergence result for Nesterov accelerated FedAvg with
convex and smooth objectives. Unlike with the FedAvg algorithm, where convex and strongly convex
results share identical components, the proof for the convergence result in the convex setting for
Nesterov FedAvg uses a change of variables, although the general ideas are in the same vein: we
have a one step progress bound for E∣wt+ι - w*∣2 + ηt(F(wt) - F(w*)), which is then used to
form a telescoping sum that gives an upper bound on mint≤τ F(wt) - F(w*).
27
Under review as a conference paper at ICLR 2021
Lemma 9 (One step progress, convex case, Nesterov). Let Wt = PN=I PkWk in Nesterov accel-
erated FedAvg, and define η = j-αt^. Under assumptions 1,3,4, thefollowing bound holdsfor all
1	β2
Ekwt+1-w k + ηt(F (Wt)-F (w )) ≤ EkWt-W k +32LEαt ηtG + ηt Vmax Nσ +2ηt ι-βt G
Theorem 4. Set learning rates αt = βt
O(∖PN). Then under Assumptions 1,3,4 NeSterov
accelerated FedAvg with full device participation has rate
min F(Wt)- F* = O (VmNT2 + NETG2)，
and with partial device participation with K sampled devices at each communication round,
.F(—、 尸	C(Vmaxσ2 ,E2G2, KE2 LG2 ∖
min F(Wt) — F = O	+H.
t≤τ t	V √KT	√KT	T )
Proof. Applying the bound from Lemma 9, with η = ɪ-^ We have
1	β2
EIIWt+ɪ — W ∣∣2 + ηt(F(Wt) — F(W )) ≤ EkWt — W ∣∣2 + 32LEatηtG2 + ηtVmax—σ2 + 2ηt---G
N	1 - βt
Summing the inequalities from t = 0 to t = T, we obtain
T	T 1	T	T	β2
Ent(F(Wt)- F(W*)) ≤ ∣∣wo - w*∣2 + y^η2 ∙ NVmaxσ + y^ηtα2 ∙ 32LE2G2 + E2ηt 1 _tβ G2
t=0	t=0 N	t=0	t=0	1 - βt
so that
1	T 1	T	T	β2
minF(Wt) - F(w*) ≤ —T— I∣wo - W*k2 + £n2 ∙而“maxσ2 + fnt*∙ 32LE2G2 + ∑S2ηtr-⅛G2
t≤T	tT=0 ηt	t=0	N	t=0	t=0	1 -βt
By setting the constant learning rates at ≡ qN and βt ≡ CqN so that ηt = ɪ-t^ =1 v√n ≤
2 J N, we have
min F(Wt) — F(w*)
≤	1_∙ kw0 - w*k2 + -J= T ∙ N ∙ — Vmaxσ2 + -ɪT(ʌ/N)332LE2G2 + -J= T(ʌ/N)3G2
_ 2√NT 0	√NT	T N max √NT V T7	√NT 'Nt，
=(9 kw0 - w*k2 + 2Vmaxb2 ) √== + — (32LE 2G2 + 2G2)
2	NT T
= O(Vmaxσ2	NE 2LG21
=(-√NF + -T —)
Similarly, for partial participation, we have
1	T1	T
min F(Wt) - F(W*) ≤ —T- I kw0 - w*k2 + Eα2 ∙ ( NVmaxσ2 + C) + Eα3 ∙ 6E2LG2
≤	t=0 at	t=0	t=0
where C = KE2G2 or N-K aE2G2, so that with αt ≡ NK and βt ≡ c√ T, we have
min F (Wt)- F (w*)= O(
Vmaxσ2	E2G2	KE2LG2
√KT + √KT + -T-)
□
28
Under review as a conference paper at ICLR 2021
F.2.1 Deferred proofs of key lemmas
Proofoflemma 9. Define Pt := ɪ-t^ [wt - wt-1 + αtgt-ι] = 11β(Vt — vt-1) for t ≥ 1 and 0
for t = 0. We can check that
——	，—	—.-	Qt
wt+ι + Pt+1 = Wt + Pt - ---rgt
1	- Pt
Now we define Zt ：= Wt + Pt and ηt = ɪJa^ for all t, so that we have the recursive relation
zt+ι = zt - ηtgt
Now
I∣zt+1 - w*k2 = ∣∣(zt - ηtgt) - w*k2
=I(Zt - ηtgt - w*) - ηt(gt - gt)k2
=A1 + A2 + A3
where
Ai = IIZt - w* - ηtgtk2
A2 = 2ηt(Zt - w* - ηtgt, gt - St)
a3 = η2kgt -gtk2
where again EA2 = 0 and EA3 ≤ η2 Pk pkσk. For Ai we have
Ilzt - w* - ηtgtk2 = Ilzt - w*k2 +2hzt - w*, -ηtgti + ∣∣ηtgtk2
Using the convexity and L-smoothness of Fk,
-2ηt(Zt - w*, gt)
N
=-2ηt XPkhZt - w*, VFk(Wk))
k=1
NN
=-2ηt XPk hZt - wk, VFk (Wk))- 2ηt XPk M - w*, VFk (Wk))
k=1	k=1
NN	N
=-2ηt XPkhZt - Wt, VFk(Wk))- 2ηt XPk(Wt - Wk, VFk(Wk)) - 2ηt XPk hwk - w*, VFk(Wk))
k=1	k = 1	k=1
NN	N
≤ -2ηt XPkhZt - Wt, VFk(Wk))- 2ηt XPk®- Wk, VFk(Wk)) +2ηt XPk(Fk(w*) - Fk(Wk))
k=1	k = 1	k=1
N
≤ 2ηt XPk Fk(Wk) - Fk(Wt) + 2∣∣wt - Wkk2 + Fk(w*) - Fk(Wk)
k=1	L	-
N
-2ηt XPk hZt - wt, VFk (Wk))
k=1
NN	N
=ηtLXPkIIwt- Wk∣∣2 + 2ηt XPk [Fk(w*) - Fk(wt)] - 2ηt XPkhZt - Wt, VFk(Wk))
k=1	k = 1	k=1
which results in
NN
Ekwt+1 - w*I2 ≤ ElIwt- w*I2 + ηtLXPkIIWt- Wk∣∣2 + 2ηt XPk [Fk(w*) - Fk(Wt)]
k=1	k=1
NN
+ η2kgtk2 + η2 XPkσ2 - 2ηt XPk8-wt, VFk(Wk))
k=1	k=1
29
Under review as a conference paper at ICLR 2021
AsbeforeJIgtk2 ≤ 2L2 PkPkkWk - Wtk2 +4L(F(Wt)- F(w*)), so that
N
η2kgtk2 + ηt XPk [Fk(Wio- Fk(Wt)] ≤ 2L2η2 XPkkwtk - wtk2 + ηt(1 - 4ηtL)(F(Wio- F(Wt))
≤ 2L2η2 XPkkWk - Wtk2
k
for ηt ≤ 1/4L. Using PiN=IPk∣∣Wt - Wkk2 ≤ 16E2α2G2 and PN=IPkσ2 ≤ VmaxNσ2, it follows
that
NN
EkWt+ι - w*∣∣2 + ηt(F(Wt)- F(w*)) ≤ EkWt- w*k2 + (ηtL + 2L2η2) XPkkWt- Wkk2 + η2 XPkσk
k=1	k=1
N
-2ηt XPk hzt - Wt, VFk (Wk)i
k=1
≤ EkWt- w* k2 + 32LE2 α2ηtG2 + η2νmax Nσ2
N
-2ηt XPk hzt - Wt, VFk (Wk)i
k=1
if ηt ≤ 2L. It remains to bound EPN=IPk(Zt - Wt, VFk(wk)i. Recall that Zt - Wt =
τ-βtβt [Wt - Wt-1 + αtgt-ι] = τ∣2β;(Vt - Vt-ι) and Ekvt - Vt-1k2 ≤ G2, EkVFk(Wk)k2 ≤ G2.
Cauchy-Schwarz gives
N	N	l__________
EXPk(Zt- Wt, VFk(wk)i ≤ XPkPEkZt- Wtk2 ∙ JEkVFk(Wk)k2
k=1	k=1
≤
βt2
1 - βt
G2
Thus
1	β2
Ekwt+1 - W k2 + ηt (F (Wt) - F (W )) ≤ EkWt - W k2 + 32LE2α2ηtG2 + η2Vmax 方 σ2 + 2ηt--W G2
N	1 - βt
□
G Geometric Convergence of FedAvg in the Overparameterized
Setting
Overparameterization is a prevalent machine learning setting where the statistical model has much
more parameters than the number of training samples and the existence of parameter choices with zero
training loss is ensured Allen-Zhu et al. (2018); Zhang et al. (2016). Due to the property of automatic
variance reduction in overparameterization, a line of recent works proved that SGD and accelerated
methods achieve geometric convergence Ma et al. (2018); Moulines & Bach (2011); Needell et al.
(2014); Schmidt & Roux (2013); Strohmer & Vershynin (2009). A natural question is whether such
a result still holds in the federated learning setting. In this section, we provide the first geometric
convergence rate of FedAvg for the overparameterized strongly convex and smooth problems, and
show that it preserves linear speedup at the same time. We then sharpen this result in the special case
of linear regression. Inspired by recent advances in accelerating SGD Liu et al. (2020); Jain et al.
(2017), we further propose a novel momentum-based FedAvg algorithm, which enjoys an improved
convergence rate over FedAvg. Detailed proofs are deferred to Appendix Section H. In particular, we
do not need Assumptions 3 and 4 and use modified versions of Assumptions 1 and 2 detailed in this
section.
30
Under review as a conference paper at ICLR 2021
G. 1 Geometric Convergence of FedAvg in the Overparameterized Setting
Recall the FL problem minw PN=I PkFk(w) with Fk(w) = ^^ P；=1 '(w; Xk). In this section, We
consider the standard Empirical Risk Minimization (ERM) setting where ` is non-negative, l-smooth,
and convex, and as before, each Fk(W) is L-smooth and μ-strongly convex. Note that l ≥ L. This
setup includes many important problems in practice. In the overparameterized setting, there exists
W ∈ argminw PN=IPkFk(w) such that '(w*; Xk) = 0 for all Xk. We first show that FedAvg
achieves geometric convergence with linear speedup in the number of workers.
Theorem 5.	In the overparameterized setting, FedAvg with communication every E iterations and
constant SteP size α = O(E 而——+LNN-V ∙)) has geometric convergence:
EF (WT) ≤ L(I - a)T kw0 - w*k2 = O (L exP (-Eμ7-_I NN _ “—?) ∙ kw0 - w*k2)
2	E lνmax + L(N
- νmin)
Linear speedup and Communication Complexity The linear speedup factor is on the order of
O(N∕E) for N ≤ O(L), i.e. FedAvg with N workers and communication every E iterations
provides a geometric convergence speedup factor of O(N∕E), for N ≤ O(L). When N is above
this threshold, however, the speedup is almost constant in the number of workers. This matches the
findings in Ma et al. (2018). Our result also illustrates that E can be taken O(Tβ) for any β < 1
to achieve geometric convergence, achieving better communication efficiency than the standard FL
setting. We emphasize again that compared to the single-server results in Ma et al. (2018), the
difference of our result lies in the factor of N in the speedup, which cannot be obtained if one simply
applied the single-server result to each device in our problem.
G.2 Overparameterized Linear Regression Problems
We now turn to quadratic problems and show that the bound in Theorem 5 can be improved to
O(exp(-ENK.t)) for a larger range of N. We then propose a variant of FedAvg that has provable
acceleration over FedAvg with SGD updates. The local device objectives are now given by the
sum of squares Fk (w)= 壶 Pn=I(WTXk - Zk)2, and there exists w* such that F(w*) ≡ 0. Two
notions of condition number are important in our results: κ1 which is based on local Hessians, and
κ, which is termed the statistical condition number Liu & Belkin (2020); Jain et al. (2017). For
their detailed definitions, please refer to Appendix Section H. Here we use the fact K ≤ κι. Recall
νmax = maxk Pk N and νmin = mink Pk N.
Theorem 6.	For the overParamterized linear regression Problem, FedAvg with communication every
E iterations with constant step size α = O(E 而——十μNN-V ∙)) has geometric convergence:
EF (WT) ≤ O
NT
(L eXP(- E(VmaxKI + (N -Vmm))	-
When N = O(κι), the convergence rate is O((1 - EKr)T) = O(exp(-ENT)), which exhibits
linear speedup in the number of workers, as well as a 1∕κι dependence on the condition number κι.
Inspired by Liu & Belkin (2020), we propose the MaSS accelerated FedAvg algorithm (FedMaSS):
k	utk - η1kgt,k
wt+1 =	Pk∈St+1 utk -η1kgt,k
if t + 1 ∈/ IE ,
ift+1 ∈IE,
utk+1 = wtk+1 +γk(wtk+1 -wtk) +η2kgt,k.
When η2k ≡ 0, this algorithm reduces to the Nesterov accelerated FedAvg algorithm. In the next
theorem, we demonstrate that FedMaSS improves the convergence to O(exp(-ENTK)). To our
knowledge, this is the first acceleration result of FedAvg with momentum updates over SGD updates.
Theorem 7. For the overparamterized linear regression problem, FedMaSS with communication
_ Z, 1、	1--
every E iterations and constant step sizes ηj1 = O( E m——十μNN-V ∙n) ),η2 = η+⅛2 ,γ = π⅛
√ κ 1⅛	√κ 1 κ
has geometric convergence:
NT
EF(WT) ≤ O LexP(-^7-----------L-N-------------ττ)kw0 - w k2 .
E(Vmax κ1κK + (N - Vmin))
31
Under review as a conference paper at ICLR 2021
Speedup of FedMaSS over FedAvg To better understand the significance of the above result, we
briefly discuss related works on accelerating SGD. Nesterov and Heavy Ball updates are known
to fail to accelerate over SGD in both the overparameterized and convex settings Liu & Belkin
(2020); Kidambi et al. (2018); Liu et al. (2018); Yuan et al. (2016). Thus in general one cannot
hope to obtain acceleration results for the FedAvg algorithm with Nesterov and Heavy Ball updates.
Luckily, recent works in SGD Jain et al. (2017); Liu & Belkin (2020) introduced an additional
compensation term to the Nesterov updates to address the non-acceleration issue. Surprisingly, we
show the same approach can effectively improve the rate of FedAvg. Comparing the convergence rate
of FedMass (Theorem 7) and FedAvg (Theorem 6), when N = O(√κικ), the convergence rate is
O((I - E√⅛)T) = O(exp(-E√Tκ)) as oppoSedtO O(exp(-箫)). SinCe κι ≥ κ, this implies
a speedup factor of PF for FedMaSS. On the other hand, the same linear speedup in the number of
workers holds for N in a smaller range of values.
H	Proof of Geometric Convergence Results for
Overparameterized Problems
H. 1 Geometric Convergence of FedAvg for general strongly convex and
SMOOTH OBJECTIVES
Theorem 5. For the overparameterized setting with general strongly convex and smooth objectives,
FedAvg with local SGD updates and communication every E iterations with constant step size
α = 2E ιν——+LNN-V .)gives the exponential convergence guarantee
EF(Wt) ≤ L(I - μα)tkw0 - w*k2 = O(eχp(-2μEτ-_I LNV _ “—、t) ∙ kw0 - w*k2)
2	2E lνmax + L(N - νmin)
Proof. To illustrate the main ideas of the proof, we first present the proof for E = 2. Let t - 1 be a
communication round, so that Wk-I = W1. We show that
I∣wt+1 - W* k2 ≤ (1 - αtμ)(1 - at-iμ)kWt-i - w*∣∣2
for appropriately chosen constant step sizes αt, αt-1. We have
∣∣Wt+ι - W*k2 = Il(Wt - αtgt) - W*k2
=IIWt - W* k2 - 2αthWt - w*, gti + (Ot ∣∣gtk2
and the cross term can be bounded as usual using μ-convexity and L-smoothness of Fk
-2(tEt(Wt - w*, gti
N
=-2(t XPkhWt - w*, VFfc(Wk)i
k=1
NN
=-2(t XPkhWt - w,, VFk(Wk)i - 2(t XPkhWt - w*, VFk(Wk))
k=1	k=1
N	NN
≤ -2αt X Pk hWt - Wk, VFk(Wk ))+2(t X Pk (Fk (w*) - Fk (Wk))- αt.μ X Pk IlWk - W*∣2
k=1	k=1	k=1
N
≤ 2(t	Pk
k=1
Fk(Wk) - Fk(Wt) + LIIWt - Wk∣∣2 + Fk(W*) - Fk(Wk)
N
-( μ∣l X Pk(Wk- w*)∣∣2
k=1
NN
(tL XPkIlwt- Wk ∣∣2 + 2(t XPk [Fk(w*) - Fk (Wt)] - (tμ∣∣Wt - w*∣∣2
k=1	k=1
32
Under review as a conference paper at ICLR 2021
NN
=atLEpkkwt - Wkk2 - 2at£PkFk(Wt)- αtμ∣∣Wt - w*∣∣2
k=1	k=1
and so
N
E∣∣Wt+ι - w*k2 ≤ E(1 - atμ)kWt - w*∣∣2 - 2a.tF (Wt) + a2 ∣∣gtk2 + aj X Pk IIWt- Wk ∣∣2
k=1
Applying this recursive relation to ∣∣Wt - w*∣2 and using ∣∣Wt-ι - Wk-Ik2 ≡ 0, We further obtain
E∣Wt+ι - W*k2 ≤ E(1 - αtμ) ((1 - a1μ)kWt-i - W*∣2 - 2a-F(Wt-i) + a2-i∣gt-i∣∣2)
N
-2a1-F(Wt) + a⑶gtll2 + a,L XPk∣∣Wt - Wk ∣∣2
k=1
Now instead of bounding Pk=I Pk ∣∣Wt - Wk ∣∣2 using the arguments in the general convex case, we
follow Ma et al. (2018) and use the fact that in the overparameterized setting, w* is a minimizer of
each '(w, Xk) and that each ' is l-smooth to obtain ∣∣VF1k(Wt-1, ξk-1)∣∣2 ≤ 2l(Fk(Wt-ι,ξk-ι)-
Fk(w*,ξk-ι)), where recall Fk(w, ξk-ι) = '(w, ξkT), so that
NN
Epkkwt - wkIl2 = Epkkwt-1 - at-igt-i - Wk-I + at-igt-i,k∣∣2
k=1	k=1
N
=	Pkat2-1∣gt-1 - gt-1,k ∣2
k=1
N
= at2-1 XPk(∣gt-1,k∣2 - ∣gt-1∣2)
k=1
N
=a2-i XPk∣VFk(wt-i,ξk-i)k2 - a2-ikgt-ik2
k=1
N
≤ a2-ι XPk2l(Fk(wt-1,ξ3) - Fk(W*,ξ3)) - a2-1∣gt-1k2
k=1
again using wt-ι = Wk-1. Taking expectation with respect to g^-i's and using the fact that
F (W* ) = 0, we have
NN
EtT XPkkwt - Wkk2 ≤ 2lα2-i XPkFk(wt-i) - a2-i∣gt-ik2
k=1	k=1
=2la2-1F (wt-i) - a2-i∣gt-i ∣2
Note also that
N
kgt-ik2 = k XPkVFk(wt-1,ξk-1 )k2
k=1
while
N	NN
kgtk2 = k X Pk VFk (Wk 芯)k2 ≤ 2∣ X Pk VFk (Wt 芯)k2 +2∣ X Pk(VFk (wt,ξt I-NFk (wk,ξk))∣2
k=1	k=1	k=1
NN
≤ 2∣ XPkVFk(wt,ξk)∣2 + 2XPkl2∣wt - Wk∣∣2
k=1	k=1
Substituting these into the bound for kwt+i - w*∣2, We have
33
Under review as a conference paper at ICLR 2021
E∣∣Wt+ι - w*k2 ≤ E(1 — αtμ)((1 - αt-iμ)kW1 - w*∣∣2 - 2α-ιF(Wt-I) + α2-ikgt-i∣∣2)
N
-	2αtF(Wt) + 2α2k XPkVFk(Wt,ξk)k2 + ⑵％2―商 十 °t。2—/)(2lF(Wt-I)- |叵1『)
k=1
=E(1 - αtμ)(1 - αt-iμ)∣∣Wt-i - w*∣∣2
N
-	2αt(F(Wt)- αtk XPkVFkBt芯)『)
k=1
-	2αt-i(1 - atμ) ((1 - " W + MiL )F(Wt-I)一号k XPkVFk(Wt-i,ξ3)k2)
from which we can conclude that
EIlWt+1 - W*k2 ≤ (1 - atμ)(1 - at-iμ)E∣∣Wt-i - W*∣∣2
if we can choose αt, αt-1 to guarantee
N
E(F(Wt) - atk XpkVFk(Wt,ξk)∣2) ≥ 0
k=1
lat-1 (2l at + ati)
1 — atμ
N
)F(Wt-I)- t-k k XPk VFk (Wt-1,ξk-1) k2
k=1
≥0
Note that
N	NN
Etk X Pk VFk(Wt,ξk )k2 = EthX Pk VFk (Wt,ξk), X Pk VFk(Wt君))
k=1	k=1	k=1
NN
=X Pk EtkVFk(Wt,ξk )k2 + XX Pj PkEthVFk(Wt,ξk), VFj (Wt,ξj )i
k=1	k=1 j 6=k
NN
=XPkEtkVFk(Wt,ξk)k2 + XXPjPkhVFk(Wt), VFj(Wt)i
k=1	k=1 j 6=k
N	NN	N
=XPkEtkVFk(Wt,ξk)k2 + XXPjPkhVFk(Wt), VFj(W∕- XPk∣∣VFk(Wt)k2
k=1	k=1 j=1	k=1
N1
≤ EPk EtkVFk(Wt,ξk )k2 + k EPkVFk (Wt)k2 - NVmink EPkVFk (Wt)k2
k=1	k	k
N1
=∑PkEtkVFk(Wt,ξk)k2 + (1- NVmm)kVF(Wt)k2
k=1
and so following Ma et al. (2018) if We let at = min{ F , ”一 Rq-T} for a q ∈ [0,1] to be
2lνmax 2L(1-N Vmin)J
optimized later, we have
N
Et(F(Wt) - αtk XPkVFk(Wt,ξk)k2)
k=1
N
≥ Et X Pk Fk(Wt) - at
k=1
1
EPkEtkVFk(Wt,ξk)k2 + (1 - NVmin)kVF(Wt)k2
k=1
34
Under review as a conference paper at ICLR 2021
N1	1
≥ Et ɪ2pk (qFk(wt, ξt ) - αt NVmaXIl▽& (Wt, ξt )k ) + ((1 - q)F (Wt)- αt (I- NVmin)IlVF (Wt)Il )
k=1
N1	1
≥ qEt∑Pk(Fk(Wt,ξk) - 2IVFk(wt,ξk)k2) + (1-q)(F(Wt) — — ∣VF(wt)k2)
k=1
≥0
again using w* optimizes Fk(w, ξk) with Fk(W*,ξjk) = 0.
MaximiZing at = min{ 27qVNaX , 2L(j∕nin) } 0ver q ∈ [0, 1], we see that q = IVIaax+ 黑N-Viain)
results in the fastest convergence, and this translates to at = 2IV——+L(N-V ,)∙ Next we claim that
αt-1 = c2 lVaaχ + LNN-Vlnin)	g^an^S
E(1 -
lαt-1 (2l αt + αtL)
1 — at μ
)F (Wt-i)一
N
--k Il X PkVFk (Wt-1 ,ξk-i)k2 ≥ 0
k=1
Note that by scaling a— by a constant C ≤ 1 if necessary, we can guarantee lαt-1(；-；『3L) ≤ ι,
and so the condition is equivalent to
N
F(Wt-I)- at-ik XPkVFk(Wt-i,ξk-ι)k2 ≥ 0
k=1
which was shown to hold with at-ι ≤ ɪ 而——+L(N-V ∙).
For the proof of general E ≥ 2, we use the following two identities:
NN
IlgtIl2 ≤ 2k XPkVFk(Wt,ξk)∣∣2 + 2XPkl2∣IWt- WkIl2
k=1	k=1
NN
E X Pk ∣∣Wt - Wk Il2 ≤ E2(1 + 2l2a2-ι) X Pk Wt-i - Wk-Ik2 + 8a2-ι lF (Wt-I)- 2。2-1恒1||2
k=1	k=1
where the first inequality has been established before. To establish the second inequality, note that
NN
EPk IIwt — Wk Il2 = EPk ∣∣Wt-i — at-1 gt-1 — Wk-I + at-igt-i,k∣∣2
k=i	k=i
N
≤ 2XPk (|瓯-1 - Wk-Ik2 +Iat-igt-i - at-igt-i,kI2
k=i
and
XPkIgt-i,k - gt-iI2 = XPk(Igt-i,kI2 - Igt-iI2)
kk
=XPkkVFk(Wt-ι,ξk-ι) + VFk(Wk-1,ξk-1)-VFk(Wt-ι,ξk-ι)I2 -Igt-ιI2
k
≤ 2 X Pk (kVFk (Wt-i,ξk-i)k2 + llWk-i - Wt-ik2) - kgt-1k2
k
so that using the l-smoothness of `,
N
EXPkkwt- Wkk2
k=i
N
≤ E2(1 + 2l2a2-1) X Pkkwt-I- Wk-Ik2 +4a2-i X PkkVFk (Wt-1, ξk-i)k2 - 2a2-1 kgt-1k2
k=i	k
35
Under review as a conference paper at ICLR 2021
N
≤ E2(l + 2∕2α2-1) XPkkWt-1 — Wk-Ik2 +4a2-12/ Xpk(Fk(wt-1,ξk-1) - Fk(w*,ξ3)) — 2α2-ιkgt-ik2
k=1	k
N
=E2(1 + 2l202-i) XPkkWt-I- Wk-Ik2 + 8。2-1加(Wt-I)- 2α2-1 kgt-ik2
k=1
Using the first inequality, we have
E∣∣Wt+ι — W*k2 ≤ E(1 - αtμ)kWt — w"∣2
N
-2αtF(Wt) + 2α2k XPkVFk(Wt,ξk)∣∣2
k=1
N
+ (2α2l2 + αtL) Xpk IlWt- Wk ∣∣2
k=1
and we choose at and at-ιsuch that E(F(Wt)- αtk PlkN=IPkVFk(Wt,ξk)k2) ≥ 0 and (2α2l2 +
atL) ≤ (1 - atμ)(2a2-1/2 + at-ιL)∕3. This gives
N
E∣∣Wt+ι - W*k2 ≤ E(1 - atμ)[(1 - at-iμ)kWt-i - W*∣∣2 - 2a-ιF(Wt-I) + 2a2-1k XPkVFk(Wt-i,ξk-1)k2
k=1
NN
+ (2a2-ιl2 + at-iL)(XPkIlWt-I- Wk-Ik2 + XPkIlWt- Wk∣∣2"3]
k=1	k=1
Using the second inequality
NN
XPkkWt - Wkk2 ≤ E2(1 + 2l2a2-i) XPkkWt-I- Wk-Ik2 + 8a2-ilF(Wt-I)- 2a2-ikgt-ik2
k=1	k=1
and that 2(1 + 2l2α2-ι) ≤ 3, 2a2-ιl2 + at-ιL ≤ 1, we have
E∣∣Wt+ι - W*k2 ≤ E(1 - atμ)[(1 - at-iμ)kWt-i - W*∣∣2
N
-2at-iF(Wt-I) + 2a2-ik XPkVFk(Wt-ι,ξ3)∣∣2 + 8a2-ilF(Wt-I)
k=1
N
+ (2a2-il2 + at-1L)(2 XPkkWt-I- Wk-Ik2)]
k=1
and if at-i is chosen such that
N
(F(Wt-I)- 4at-ilF(Wt-i)) - at-ik XPkVFk(Wt-i,ξk-i)k2 ≥ 0
k = 1
and
(2a2-1l2 + at-1L)(I - at-iμ) ≤ (2a2-2l2 + at-2L)/3
we again have
N
E∣∣Wt+i - W*k2 ≤ E(1 - atμ)(1 - at-iμ)[kWt-i - W*∣∣2 + (2a2-2l2 + at-2L) ∙ (2 XPk∣∣Wt-i - Wk-Ik2)∕3]
k=1
Applying the above derivation iteratively τ < E times, we have
E∣∣Wt+ι - W*k2 ≤ E(1 - αtμ)…(1 - at-τ+ιμ)[(1 - at-τμ)∣∣Wt-τ - W*∣∣2
36
Under review as a conference paper at ICLR 2021
N
-2αt-τF(Wt-τ) + 2αLk XPkVFk(Wt-T, ξ3)∣∣2 + MaLTIF(Wt-τ)
k=1
N
+ (2at-τl2 + αt-τL)((T + I) Xpk IIwt-T- Wk-Tll2)]
k=1
as long as the step sizes at-τ are chosen such that the following inequalities hold
(2α2-τI2 + at-τL)(I - at-τμ) ≤ (2a2-τ-1l2 + at-τ-1L)∕3
2(1 + 2l2a2-τ) ≤ 3
2α2-τ l2 + at-τ L ≤ 1
N
(F(Wt-τ) - 4ταt-τIF(Wt-τ))- αt-τk XPkPFk(Wt-T,ξk-τ)『≥ 0
k=1
We can check that setting αt-τ = C:τ⅛T TV——+LN-V ∙)for some small constant C satisfies the
requirements.
Since communication is done every E iterations, Wt0 = Wk for some to > t - E , from which we
can conclude that
t-t0 -1
EkWt- w*∣∣2 ≤ ( Y (1 - μat-τ))∣∣Wt0 - w*∣∣2
τ =1
≤ (1 - ¥-------J INN-------7)t-t0 llWto - w*∣∣2
E lVmax + L(N - Vmin)
and applying this inequality to iterations between each communication round,
EllWt - w*∣∣2 ≤ (1 - c-μ--- N-----------Γ)t|W0 - w*∣∣2
E lVmax + L(N — Vmin)
=O(exp(指 j----- INN--------^t))IM - w*∣∣2
E lVmax + L(N - Vmin )
With partial participation, we note that
EIlWt+ι - w*∣∣2 = E∣Wt+ι - vt+ι + vt+ι - w*∣∣2
=E∣Wt+ι - Vt+ι∣2 + E∣Vt+ι - w*∣∣2
=K X PkEkWk+ι- wt+ι∣∣2 + EkVt+ι- w*∣∣2
k
and so the recursive identity becomes
E∣∣Wt+ι - w*k2 ≤ E(1 - αtμ)…(1 - αt-τ+ιμ)[(1 - αt-τμ)∣∣Wt-τ - w*∣∣2
N
-2at-τF(Wt-T) + 2α2-τk XPkVFk(Wt-τ, ξk-τ)k2 + 8τα2-τIF(Wt-T)
k=1
1N
+ (2αt-τl + at-τL + K )((τ +1) EPk ∣∣wt-τ - wt-τ k )]
k=1
which requires
(2α2-τl + αt-τL + V7)(1 - at-τμ) ≤ (2a2-τ-1l2 + at-τ-1L + -^]Ii3
K	K
2(1 + 2l2α2-τ) ≤ 3
2α2-τl + αt-τL + K ≤ 1
37
Under review as a conference paper at ICLR 2021
N
(F(Wt-T) — 4ταt-τIF(Wt-T)) — at-Tk XPk^Fk(Wt-τ芯-T)k2 ≥ 0
k=1
to hold. Again setting at- = Cτ++ι 五——+N-V .)for a possibly different constant from before
satisfies the requirements.
Finally, using the L-smoothness of F,
F(WT) — F(w*) ≤ LEkwT — w*k2 =O(Lexp(-%~-ɪ----------TT))kw0 — w*k2
2	E lνm
ax + L(N
— νmin )
□
H.2 Geometric Convergence of FedAvg for Overparameterized Linear
Regression
We first provide details on quantities used in the proof of results on linear regression in Section G. The
local device objectives are now given by the sum of squares Fk (w)=+ Pn= I(WTXk - Zk)2, and
there exists w* such that F(w*) ≡ 0. Define the local Hessian matrix as Hk := n^ Pn= 1 Xk(Xk)t,
and the stochastic Hessian matrix as Hk := ξk (ξk)T, where ξk is the stochastic sample on the kth
device at time t. Define l to be the smallest positive number such that Ekξtk k2ξtk(ξtk)T lHk for all
k. Note that l ≤ maxk,j kxk ∣∣2. Let L and μ be lower and upper bounds of non-zero eigenvalues of
Hk. Define κι := l∕μ and K := L∕μ.
Following Liu & Belkin (2020); Jain et al. (2017), We define the statistical condition number K as the
smallest positive real number such that E Pk Pk HkH -1HK tk ≤
κKH. The condition numbers κ1 and
κK are important in the characterization of convergence rates for FedAvg algorithms. Note that κ1 > κ
and κ1 > κK.
Let H = Pk PkHk. In general H has zero eigenvalues. However, because the null space of H and
range of H are orthogonal, in our subsequence analysis it suffices to project Wt — w* onto the range
of H, thus we may restrict to the non-zero eigenvalue of H.
A useful observation is that we can use w*T Xjk — zjk ≡ 0 to rewrite the local objectives as Fk (w)
1 hw — w*, Hk(w — w*)i ≡ 1 IlW — w*∣Hk:
1	nk
Fk (W) =  Σ^(wT xk,j — zk,j — (w*T xk,j — zk,j ))2
=1 hw — w*, Hk(w — w*)i = 2∣w — w*∣Hk
nk
Mk X((W — w*)T Xkj )2
so that F(w) = 1 ∣∣w — w* ∣∣H.
Finally, note that EHk = nk Pn=I Xk(Xk)t = Hk and gt,k = VFk(wk, ξk) = Hk(Wk — w*)
while gt = pN=ιPkVFk(Wk,ξk) = PlkLIPkHk(Wk- w*) andgt = PN=IPkHk(Wk- w*)
Theorem 6. For the overparamterized linear regression problem, FedAvg with communication every
E iterations with constant step size α = O(E 而——+N-V .)) has geometric convergence:
NT
ef(WT) ≤ O LexP( — Vy-----------7^--------ττ)kw0 - W k2 .
E (νmax κ1 + (N — νmin))
Proof. We again show the result first when E = 2 and t — 1 is a communication round. We have
∣∣Wt+ι — w*k2 = k(wt — αtgt) — w*k2
=∣∣Wt — w* k2 — 2athwt — w*, gti + a2 ∣∣gt∣2
and
—2atEthwt — w*, gti
38
Under review as a conference paper at ICLR 2021
N
=-2αt XPkhWt- w*, VFk(Wk)i
k=1
NN
=-2αt XPkhWt- wk, VFk(Wk)〉- 2αt XPk hwtk - w*, VFk(Wk)
k=1	k=1
NN
=-2αt XPkhWt- Wk VFk(Wk)i - 2αt XPk hWt - w*, Hk(Wit - w*)〉
k=1	k=1
NN
=-2α∣ XPkhwt- wtk, VFk(wf)i- 4α∣ XPkFk(Wk)
k=1	k=1
NN
≤ 2αt XPk(Fk(Wk)- Fk(wt) + - Ilwt- Wk ∣∣2) - 4αt XPkFk (Wk)
k=1	k=1
N	NN
=αtL^Pk Ilwt- wfk2 - 2at£ Pk Fk (Wt)- 2αt EPk Fk(Wk)
k=1	k=1	k=1
NN	N
=αtL X Pk Ilwt- wf∣∣2 - at X Pk h(wt - w*), Hk(wt - w*)〉一 2at X Pk Fk (Wk)
k=1	k=1	k=1
and
N
∣gt∣2 = IXPkHk(Wk - W*)∣2
k=1
NN
=Il XPkHk(wt - w*) + XPkHk(Wk - wt)∣∣2
k=1	k=1
NN
≤ 2∣ XPkHk(wt - w*)∣2 + 2∣ XPkHk(Wk- Wt)∣2
k=1	k=1
which gives
NN
EIIwt+1 - W*∣2 ≤ EIIwt- W*∣2 - at XPkhwt - w*, Hkw∣ - w*〉+ 2a2∣ XPkHk(w∣ - w*)∣2
k=1	k=1
NN	N
+ atL XPkIlwt- Wk∣∣2 + 2a21 XPkHk(wk - wt)∣∣2 - 2at XPkFk(Wk)
k=1	k=1	k=1
following Ma et al. (2018) we first prove that
NN
Ellwt- w*∣∣2 - at XPkh(wt - w*), Hk(wt - w*)〉+ 2a2∣∣ XPkHk(wt - w*)∣∣2
k=1	k=1
N
≤ (1 — X7-E-)EIwt - w*∣∣2
8(νmaxκ1 + (N -
νmin))
With appropriately ChOSen at. Compared to the rate O( '“max + LNN-Vmin ) ) = θ VmaχKι + ^-Vmin)K )
for general strongly convex and smooth objectives, this is an improvement as linear speedup is now
available for a larger range of N .
We have
N
EtIl XPkHk(wt- w*)∣∣2
k=1
NN
=EthXPkHk(wt - W*), XPkHk(wt - W*)i
k=1	k=1
39
Under review as a conference paper at ICLR 2021
NN
X Pk EtkHk (Wt- w*)k2 + XX Pj Pk EthHk (Wt- w*), Hj (Wt- w*)i
k=1	k=1 j 6=k
NN
XpkEtkHk(Wt- w*)k2 + XXPjPkEthHk(Wt- w*), Hj(Wt- w*)i
k=1	k=1 j 6=k
N	NN	N
=XPkEtkHk(Wt- W*)k2 + XXPjPkEthHk(Wt- W*), Hj(Wt- W*)i - XPkkHk(Wt - w*)∣∣2
k=1	k=1 j=1	k=1
NN
=XPkEtkHk(Wt- W*)k2 + k XPkHk(Wt- W*)k2 - XPkkHk(Wt- w*)∣∣2
k=1	k	k=1
N1
≤ ∑>kEtkHk(Wt - W*)∣∣2 + k EPkHk(Wt - W*)∣∣2 - NVmmk EPkHk(Wt - W*)∣∣2
k=1	k	k
1N	1
≤ NVmaX	Pk EtkHt (Wt- W 州 +(1 - NVmin )k	PkH (Wt- W )k
k=1	k
1N	1
≤ NVmaXl	Pk h(Wt - W ), H (Wt - W )i + (1 - NVmin)k	PkH (Wt - W )k
k=1	k
=N VmaXlh(Wt - W*), H(Wt - W*)i +(1 - N Vmin)hWt - W*, H2 (Wt - W*))
using kHkk ≤ l.
Now we have
NN
EkWt- W*k2 - at XPkh(Wt - w*), Hk(Wt- W*)) +2α21∣ XPkHk(Wt- w*)∣∣2
k=1	k=1
hWt - w*, (I - atH + 2a2( VNxlH + N -Nmin H2))(Wt- w*))
and it remains to bound the maximum eigenvalue of
(I - atH + 2a2( VN/H + N-VmnH2))
and we bound this following Ma et al. (2018). If we choose at <
h,-----N------r-then
2(Vmaxl +(N-Vmin)L) ,
-atH + 2a2( VN/H + N-VmnH2) Y 0
and the convergence rate is given by the maximum of 1 - at λ + 2a2 (VNxl λ + N^Nmin λ2) maximized
over the non-zero eigenvalues λ of H. To select the step size at that gives the smallest upper bound,
we then minimize over at, resulting in
min
α,<_____「N_______厂
2(Vmaxl +(N-Vmin)L)
max
λ>0:∃v,Hv=λv
{l-atλ + 2a2( Rλ +
Since the objective is quadratic in λ, the maximum is achieved at either the largest eigenvalue λmaX
of H or the smallest non-zero eigenvalue λmin of H.
When N ≤ L4-1λaxl + 4Vmin, i.e. when N = O(l∕λmin) = O(κι), the optimal objective value is
achieved at λmin and the optimal step size is given by at = 4(ν——1+(N-V ∙ )λ ∙ ). The optimal
convergence rate (i.e. the optimal objective value) is equal to 1 - 8(ν——ι+N-Vn. )λ ∙ ) = 1 -
1(V——Kl +(N-V ∙ )). This implies that when N = O(κι), the optimal convergence rate has a
linear speedup in N. When N is larger, this step size is no longer optimal, but we still have
1 - 1 (V——Kl +(N-V ∙ )) as an upper bound on the convergence rate.
40
Under review as a conference paper at ICLR 2021
Now we have proved
EIlwt+1 - w*∣∣2 ≤ (1 - I  -------------^)Ekwt - w*∣∣2
8 (VmaXKI + (N - νmin))
N	N	N
+ αtL XPkIlwt - Wk∣∣2 +2atk XP赳(Wk - wt)∣∣2 - 2αt XPkFk(Wk)
k=1	k=1	k=1
Next we bound terms in the second line using a similar argument as the general case. We have
NN
202k XPkHHk(Wk - wt)∣∣2 ≤ 2α2l2 XPkkwt- Wk∣∣2
k=1	k=1
and
NN
EXPk ∣∣Wt - Wk ∣∣2 ≤ E2(1 + 2l2α2-1) XPkkwt-I- Wk-1∣2 + 8αt-1IF(Wt-1)
k=1	k=1
=4α2-1lhWt-1 — w*, H(Wt-1 — W*))
and if at, at-1 satisfy
atL + 2α2 ≤ (1 - 8(VmaχK1 IN -Vmin)) 乂“'L +	LN/
2(1 + 2l2α2-1) ≤ 3
atL + 2α2 ≤ 1
we have
E∣∣Wt+1 - W*k2
1N	N
≤ (1 -石 7---- (N------^^)[EkWt-1 - W k - αthWt-1 - W , HWt-1 - W i + 2αt k EPkH t (Wt - W )k
8 (VmaXK1 + (N - Vmin))	M
N
+ (at-1L + 2α2-1) ∙ 2 XPkkWt-1 - Wk-Ik2 + 4α2-1lhWt-1 - W*, H(Wt-1 - w*)》]
k=1
and again by choosing a1
C8(v——l+(NN-ν .)1.)for a small constant c, we can guarantee that
Ekwt-I — w*∣2 — αt-1(Wt-1 — w*, HWt-1 — w*》
N
+2α2-1k XPkHk-1(Wt-1 - w*)k2 +4α2-1l(Wt-1 - w*, H(Wt-I- w*)》
k=1
N	Q
≤ (1 - c— ———----------τ--)EkWt-1 - w*k2
16(VmaXI + (N - Vmin)λmin)
For general E, we have the recursive relation
Ekwt+1 - w*∣2 ≤ E(1 - c∣τ-------τ√7--------^)…(1 - %^7----------ττχ?-------ττ)[kwt-τ - w*k2
8 (VmaXKI + (N - Vmin))	8τ (VmaXKI + (N - Vmin))
N
-αt-τ CWt-T - w*,Hwt-T- w*》+ 2α2-τk XPkHk-T(Wt-T- w*)k2
k=1
+ 4τα2-1 l<wt-1 - w*, H(wt-1 - w*)》
N
+ (2α2-τl2 + at-τL)((T +1) XPk∣∣wt-τ - Wk-Tk2)]
k = 1
as long as the step sizes are chosen αt-T = C——?十(NLV ..)such that the following inequal-
ities hold
(2α2-TI2 + at-TL) ≤ (1 - αt-Tμ)(2α2-T-1l2 + αt-T-1L)∕3
41
Under review as a conference paper at ICLR 2021
2(1 + 2l2αt2-τ) ≤ 3
2αt2-τ l2 + αt-τ L ≤ 1
and
Ilwt-T - W* k2 - αt-τhwt-τ - w, Hwt-T - w*i
N
+ 2α2-τk XPkHJt-T(Wt-T - w*)k2 +4τα2-ilhWt-i - w*, H(wt-1 - w*)i
k=1
/	N	.1,o
≤ (I-C8(τ+1)(VmaχKι + (N -Vmm)) )EkWt-T-W k
which gives
Ekwt-WIF ≤ (1 - c8e (VmaxKI +N -Vmin))	-
=O(eXP(-i(VmaxKi +NN - Vmin)) ^^0 - wI^
and With partial participation, the same bound holds with a possibly different choice of c.	□
H.3 Geometric Convergence of FedMaSS for Overparameterized Linear
Regression
Theorem 7. For the overparamterized linear regression problem, FedMaSS with communication
一，,1 1	1--
every E iterations and constant step sizes ηj1 = O( E 记——+N-V ,)),η2 = ；1 二K ,γ = ι+√1K
√κ 1 κ	√K] K
has geometric convergence:
EF (wτ) ≤ O
(L exp(---------/ NT----------- )kw0 — w*∣∣21 .
∖	E(Vmax√K1K + (N - Vmin))	J
Proof. The proof is based on results in Liu & Belkin (2020) which originally proposed the MaSS
algorithm. Note that the update can equivalently be written as 1
1 = (1 - αk)vtk + αkutk - δkgt,k
wtk+1 =
utk - ηkgt,k
if t + 1 ∈/ IE
PkN=1 pk utk - ηkgt,k	ift+ 1 ∈ IE
k
k	αk k	1 k
ut+1 =	vt+1 +	wt+1
1	+ αk	1 + αk
where there is a bijection between the parameters ι+ααk = Yk,ηk = η1, n；+Oak胪 =ηk, and We
further introduce an auxiliary parameter vtk, which is initialized at v0k. We also note that when
ηk
δk = OOk, the update reduces to the Nesterov accelerated SGD. This version of the FedAvg algorithm
with local MaSS updates is used for analyzing the geometric convergence.
As before, define the virtual sequences wt = PN=I PkWk, Vt = PN=I Pk Vk, Ut = PN=I Pk Uk ,and
gt = PN=I PkEgt,k. We have Egt = Et and wt+1 = Ut -ηtgt, Vt+1 = (1 - αk Wt + akwt - δkgt,
and ut+1 = ι+aok vt+1 + ι+1ak wt+1.
We first prove the theorem with E = 2 and t - 1 being a communication round. We have
kvt+1- w*ιιH-1
=k(1 - α)Vt + αut - δXPkHk(Uk - w*) - w*kH-ι
k
=k(1- α)vt + αut- w*ι∣H-ι + δ2k X PkHk (Uk - w*)∣∣H-ι
k
42
Under review as a conference paper at ICLR 2021
-26〈£PkHk(Uk - w*), (1 - α)vt + aut - w*)∏-ι
k
≤k∣(1- α)Vt + αUt- w*哈-1 + 2δ2k EPkIHk(Ut- w*)哈-1 + 2δ2∣∣ EPkHIk(Ut- Uk)哈-1
'	A	}	k	k
A	'---------V-----------'
B
-2δ(EPkHHk(Ut - w*), (1 - α)Vt + αUt - w*)∏-ι
k
X----------------------------------------/
C
-2δ(XPkHik(Uk - Ut), (1 - α)Vt + αUt - w*)∏-ι
k
Following the proof in Liu & Belkin (2020),
EA ≤ E(1 - α)∣∣Vt - w*∣∣H-ι + α∣∣Ut - w*kH-ι
≤ E(I - Q)IlVt- w*ι∣H-ι +—IlUt- w*ιι2
μ
using the convexity of the norm ∣∣ ∙ ∣∣∏-ι and that μ is the smallest non-zero eigenvalue of H.
Now
EB ≤ 2δ2(νmax N 而+ N -Nmin )∣(Ut - w*)∣H
using the folowing bound:
E EPkHik HT EPkHik	= EEPkHikHTHik+£PkPjHikHTHHj
∖ k	)	∖ k	)	k	k=j
W VmaxNE XPkHkHTHk + XPkPjHkHTHj
k	k=j
=VmaxNEXPkHkHTHk + XPkPjHkHTHj- XPkHkHTHk
k	k,j	k
W Vmax Nn E X PkHkHTHk + H - Nn Vmin X PkHkHTHk
kk
W Vmax Nn E X PkHkHTHk + H - Nn Vmin(X Pk Hk)HT(X Pk Hk )
k	k	k
=VmaxNE XPkHkHTHk + N -Vmin H
k
1 N - Vmin
W Vmax -NKH + N H
where we have used E Pk PkHkHTHk ≤ KH by definition of K and the operator convexity of the
mapping W → WHTW.
Finally,
EC = -E2"EPkHk(Ut - w*), (1 - Q)Vt + QUt - w*〉h-i
k
=-2δ(XPkHk(Ut - w*), (1 - Q)Vt + QUt - w*)h-i
k
=-2δ((Ut — w*), (1 — Q)Vt + QUt — w*)
1-Q
=-2δ{(Ut - w ), Ut - W +-(Ut - wt))
Q
=-2δ∣Ut - w*∣2 +  --δ(∣wt - w*∣2 - ∣∣Ut - w*∣2 - ∣∣wt - Ut∣2)
Q
43
Under review as a conference paper at ICLR 2021
≤ 1"-αδ∣∣Wt - w*∣∣2 - 1■-αδ∣∣Ut - w*∣∣2
α	α
where we have used
(1 - Q)Vt + aut
=(1 - α)((1 + Q)Ut - Wt)∕α + QUt
1_	1-Q_
=-Ut-------Wt
Q Q
and the identity that -2(a, b)= ∣∣a∣∣2 + ∣∣b∣∣2 - ∣∣a + b∣∣2.
It follows that
Ellvt+1 - w*kH-ι
≤ (1 - Q)Ilvt - w*∣∣H-ι + ɪ—-δkwt - w*∣∣2
Q
+ (-------δ)kut - w*∣∣2 + 262 (VmaX k K +	Nmm )11(Ut - w*)∣∣H
μ Q	NN
+ 2δ2k XPkH(ut - Uk幅-1
k
-2δ(XPkHk (Uk - Ut), (1 - Q)vt + QUt - w*)h-i
k
On the other hand,
E∣wt+ι - w*∣∣2 = EkUt- w* - ηfp 赳(Ut- w*)∣∣2
k
=EkUt- w*k2 - 2nkUt - w*kH + η2k XPkHHk(Ut- w*)12
k
≤ EkUt - w*k2 - 2M|Ut - w*kH + η2(VmaX n' + L	N mm )|Ut - w*∣∣2
where we use the following bound:
=EE Pk IH k H k+∑ Pk Pj IH k 田
k	k=j
W VmaxNNE XPkHHkHk + XPkPjHkHj
k	k=j
=VmaxNE XPkHkHk + XPkPjHkHj - XPkHkHk
k	k,j	k
W VmaxNNE XPkHkHk + H2 - N Vmin XPkHkHk
kk
W VmaxNE XPkHkHk + H2 - NVmin(XPkHk)(£PkHk)
k	k	k
=VmaxNE XPkHkHk + N -NVmin H2
k
W VmaxɪIH + LN -Vmin H
max N	N
again using that W → W2 is operator convex and that EHkHk W lHk by definition of l.
44
Under review as a conference paper at ICLR 2021
Combining the bounds for E∣∣Wt+ι - w*∣∣2 and EkVt+ι - w*kH-,
δ
E-∣∣wt+ι - W k2 + ∣∣vt+ι - W ∣∣H-ι
α
≤ (1- Q)IlVt- w*ιιH-ι +----δkwt- w*ιι2 + (— δ)kut- w*ιι2
α	μ
+ (2δ2(VmaX Nκ +	N min ) 一 2ηδ∕α + η2δ(νmaχ Nl + L-N min )/Q)Ilut - w"∣2
+ 2δ2k XPkHk(ut- Uk幅-1
k
+ δL X Pk I (Ut- Uk 幅-1
k
Following Liu & Belkin (2020) if we choose step sizes so that
α - δ ≤ 0
μ
2δ2(νmaχNK + N NVmm ) - 2ηδ∕α + η2δ(νmaχNl + LN NVmm )∕α ≤ 0
or equivalently
α∕δ ≤ μ
2αδ(VmaX NK +	N min ) + η(η(VmaX Nl + L----N min ) - 2) ≤ 0
the second and third terms are negative. To optimize the step sizes, note that the two inequalities
imply
2	1 N - Vmin	1 N - Vmin
α ≤ η(2 - η(VmaXNl + L----N----))μ∕2(VmaXNK + N-------)
and maximizing the right hand side with respect to η, which is quadratic, We see that η ≡ 1∕( VmaX N l+
L N -Nmin) maximizes the right hand side, with
Q≡
1
J2(VmaX N K + K N-Nmn )(VmaX N 而 + N-Nmny
Qη
-=---:-------77-
μ	Q(VmaXN方+-Nmin )
Note that Q = /	1	= = O(-7N≡) when N = O(min{方，κι∕κ}).
,2(Vmax N Kl+K N-Nmn )(VmaxN 芯+ N-Nmn )	"
Finally, to deal with the terms 2δ2∣ Pk PkHHk(ut - Uk)IlH-ι + δL PkPk∣∣(ut - Uk)∣∣H-ι, we can
use Jensen
2δ2∣ EPk Hk (ut - Uk)∣H-ι + sL£pkk(ut - uk )∣H-ι
kk
≤ (2δ2l2 + δL) XPkkut- Uk∣H-ι
k
=(2δ2l2 + δL) XPkk ʌVt + ɪwt - (ʌvk + ɪWk)∣H-ι
1+Q 1+Q 1+Q 1+Q
k
≤ (2δ2l2 + δL)(2(1+α)2δ2 + 2(匕)2η2) XPkklHk-ι(Ut-ι - w*)∣∣2
Q	Qk
≤ (2δ2l2 + δL)(2(ʌ)2δ2 + 2(-^)2η2)l2k(Ut-ι - w*)k2
1+Q	1+Q
45
Under review as a conference paper at ICLR 2021
which Canbe combined with the terms with k(Ut-ι - w*)∣∣2 in the recursive expansion of Eδ IIWt -
w*k2 + kvt- w*kH-ι:
E—kwt- w*ιι2 + IlVt- w*ιιH-ι
α
≤ (1- Q)IlVt-ι- w*ιιH-ι+---------δkwt-ι- w*ιι2 +(— δ)kut-ι- w*ιι2
α	μ
+ (2δ2( VmaX NK +	N min ) - 2ηδ∕α + η2δ(νmax Nl + L------N min ”Q)IIut-1 - w*∣∣2
and the step sizes can be chosen so that the resulting coefficients are negative. Therefore, we have
shown that
EIIwt+1 - w*k2 ≤ (1 - α)2kwt-i - w*k2
where Q
O(min{κK, κ1∕κ}).
____________________1___________________
,2(Vmaχ N K +K N-Nmn )(Vmax N 芯+ N-Nmn)
O( Vmax√^+N-Vmin ) When N
For general E > 1, choosing η = c/E(VmaXNl + L N-Vmin) for some small constant C results in
α = O(——/	fv 1	fv ) and this guarantees that
E √(Vmax Nn Kι + K N -Nmin )(Vmax N ^+	Nmin )
ElIwt — w* I2 ≤ (1 — α)t I wo — w* I2
for all t.
□
I Details on Experiments and Additional Results
We describe the precise procedure to reproduce the results in this paper. As we mentioned in
Section 5, we empirically verified the linear speed up on various convex settings for both FedAvg
and its accelerated variants. For all the results, we set random seeds as 0, 1, 2 and report the best
convergence rate across the three folds. For each run, we initialize w0 = 0 and measure the number
of iteration to reach the target accuracy . We use the small-scale dataset w8a Platt (1998), which
consists of n = 49749 samples with feature dimension d = 300. The label is either positive one or
negative one. The dataset has sparse binary features in {0, 1}. Each sample has 11.15 non-zero feature
values out of 300 features on average. We set the batch size equal to four across all experiments. In
the next following subsections, we introduce parameter searching in each objective separately.
I.1	Strongly Convex Objectives
We first consider the strongly convex objective function, where we use a regularized binary logistic
regression with regularization λ = 1/n ≈ 2e - 5. We evenly distributed on 1, 2, 4, 8, 16, 32 devices
and report the number of iterations/rounds needed to converge to -accuracy, where = 0.005.
The optimal objective function value f* is set as f* = 0.126433176216545. This is determined
numerically and we follow the setting in Stich (2019). The learning rate is decayed as the ηt =
min(ηo, -+), where we extensively search the best learning rate C ∈ {2-1co, 2-2co, c0, 2c0, 22c0}.
In this case, we search the initial learning rate η0 ∈ {1, 32} and c0 = 1/8.
I.2	Convex Smooth Objectives
We also use binary logistic regression without regularization. The setting is almost same as its
regularized counter part. We also evenly distributed all the samples on 1, 2, 4, 8, 16, 32 devices. The
figure shows the number of iterations needed to converge to -accuracy, where = 0.02. The
optiaml objective function value is set as f* = 0.11379089057514849, determined numerically. The
learning rate is decayed as the ηt = min(ηo,意),where we extensively search the best learning rate
C ∈ {2-1C0, 2-2C0, C0, 2C0, 22C0}. In this case, we search the initial learning rate η0 ∈ {1, 32} and
C0 = 1/8.
46
Under review as a conference paper at ICLR 2021
I.3	Linear regression
For linear regression, we use the same feature vectors from w8a dataset and generate ground truth
[w*, b*] from a multivariate normal distribution with zero mean and standard deviation one. Then We
generate label based on yi = Xtw* + b*. This procedure will ensure we satisfy the over-parameterized
setting as required in our theorems. We also evenly distributed all the samples on 1, 2, 4, 8, 16, 32
devices. The figure shows the number of iterations needed to converge to -accuracy, where = 0.02.
The optiaml objective function value is f * = 0. The learning rate is decayed as the η = min(η0,洋),
where we extensively search the best learning rate c ∈ {2-1 c0, 2-2c0, c0, 2c0, 22c0}. In this case,
we search the initial learning rate η0 ∈ {0.1, 0.12} and c0 = 1/256.
I.4	Partial Participation
To examine the linear speedup of FedAvg in partial participation setting, we evenly distributed data
on 4, 8, 16, 32, 64, 128 devices and uniformly sample 50% devices without replacement. All other
hyperparameters are the same as previous sections.
I.5	Nesterov accelerated FedAvg
The experiments of Nesterov accelerated FedAvg (the update formula is given as follows) uses the
same setting as previous three sections for vanilia FedAvg.
ytk+1 = wtk - αtgt,k
wk =	(ytk+1 +βt(ytk+1 -ytk)	ift+	1	∈/	IE
t+1 —	lpk∈st+ι (yk+ι + βt(yk+ι- ykk))	if t +	1	∈	工E
We set βt = 0.1 and search αt in the same way as ηt in FedAvg.
I.6 THE IMPACT OF E.
In this subsection, we further examine how does the number of local steps (E) affect convergence. As
shown in Figure 2, the number of iterations increases as E increase, which slow down the convergence
in terms of gradient computation. However, it can save communication costs as the number of rounds
decreased when the E increases. This showcase that we need a proper choice of E to trade-off the
communication cost and convergence speed.
47
Under review as a conference paper at ICLR 2021
I I
ɛ Mcoscffs fco L*AE3Z
10*
Local steps (E)
I I
ɛ Mcoscffs fco L*AE3Z
io*
Local steps (E)
Mco≡cvw- %L*AE3Z
ιo1
Local steps (E)
I I
cetSPUnal J。>ιMlUlnN
cetSPUnal J。>ιMlUlnN
cetSPUnal J。>ιMlUlnN
•	IO1
Local steps (E)
(c) Linear regression
Ioe	io*
Local steps (E)
(a)	Strongly convex objective
Ioe	io*
Local steps (E)
(b)	Convex smooth objective
Figure 2: The convergence of FedAvg w.r.t the number of local steps E.
48