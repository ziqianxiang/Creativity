Under review as a conference paper at ICLR 2021
A Probabilistic Model for Discriminative and
Neuro-Symbolic Semi-Supervised Learning
Anonymous authors
Paper under double-blind review
Ab stract
Strong progress has been achieved in semi-supervised learning (SSL) by combining
several underlying methods, some that pertain to properties of the data distribution
p(x), others to the model outputs p(y|x), e.g. minimising the entropy of unlabelled
predictions. Focusing on the latter, we fill a gap in the standard text by introducing
a probabilistic model for discriminative semi-supervised learning, mirroring the
classical generative model. Several SSL methods are theoretically explained by our
model as inducing (approximate) strong priors over parameters of p(y|x). Applying
this same probabilistic model to tasks in which labels represent binary attributes,
we also theoretically justify a family of neuro-symbolic SSL approaches, taking a
step towards bridging the divide between statistical learning and logical reasoning.
1	Introduction
In semi-supervised learning (SSL), a mapping is learned that predicts labels y for data points x from
a dataset of labelled pairs (xl, yl) and unlabelled xu. SSL is of practical importance since unlabelled
data are often cheaper to acquire and/or more abundant than labelled data. For unlabelled data to
help predict labels, the distribution of x must contain information relevant to the prediction (Chapelle
et al., 2006; Zhu & Goldberg, 2009). State-of-the-art SSL algorithms (e.g. Berthelot et al., 2019b;a)
combine underlying methods, including some that leverage properties of the distribution p(x), and
others that rely on the label distribution p(y|x). The latter include entropy minimisation (Grandvalet
& Bengio, 2005), mutual exclusivity (Sajjadi et al., 2016a; Xu et al., 2018) and pseudo-labelling (Lee,
2013), which add functions of unlabelled data predictions to a typical discriminative supervised loss
function. Whilst these methods each have their own rationale, we propose a formal probabilistic
model that unifies them as a family of discriminative semi-supervised learning (DSSL) methods.
Neuro-symbolic learning (NSL) is a broad field that looks to combine logical reasoning and statistical
machine learning, e.g. neural networks. Approaches often introduce neural networks into a logical
framework (Manhaeve et al., 2018), or logic into statistical learning models (Rocktaschel et al., 2015).
Several works combine NSL with semi-supervised learning (Xu et al., 2018; van Krieken et al., 2019)
but lack rigorous justification. We show that our probabilistic model for discriminative SSL extends
to the case where label components obey logical rules, theoretically justifying neuro-symbolic SSL
approaches that augment a supervised loss function with a function based on logical constraints.
Central to this work are ground truth parameters {θx}x∈X of the distributions p(y|x), as predicted by
models such as neural networks. For example, θx may be a multinomial parameter vector specifying
the distribution over all labels associated with a given x. Since each data point x has a specific label
distribution defined by θx, sampling from p(x) induces an implicit distribution over parameters, p(θ).
If known, the distribution p(θ) serves as a prior over all model predictions, θx: for labelled samples it
may provide little additional information, but for unlabelled data may allow predictions tobe evaluated
and the model improved. As such, p(θ) provides a potential basis for semi-supervised learning. We
show that, in practice, p(θ) can avoid much of the complexity of p(x) and have a concise analytical
form known a priori. In principle, p(θ) can also be estimated from the parameters learned for
labelled data (fitting the intuition that predictions for unlabelled data should be consistent with those
of labelled data). We refer to SSL methods that rely on p(θ) as discriminative and formalise them
with a hierarchical probabilistic model, analogous to that for generative approaches. Recent results
(Berthelot et al., 2019b;a) demonstrate that discriminative SSL is orthogonal and complementary to
methods that rely on p(x), such as data augmentation and consistency regularisation (Sajjadi et al.,
2016b; Laine & Aila, 2017; Tarvainen & Valpola, 2017; Miyato et al., 2018).
1
Under review as a conference paper at ICLR 2021
We consider the explicit form of p(θ) in classification with mutually exclusive classes, i.e. where
each x only ever pairs with a single y and y |x is deterministic. By comparison of their loss functions,
the SSL methods mentioned (entropy minimisation, mutual exclusivity and pseudo-labelling) can
be seen to impose continuous relaxations of the resulting prior p(θ) and are thus unified under our
probabilistic model for discriminative SSL. We then consider classification with binary vector labels,
e.g. representing concurrent image features or allowed chess board configurations, where only certain
labels/attribute combinations may be valid, e.g. according to rules of the game or the laws of nature.
Analysing the structure of p(θ) here, again assuming y|x is deterministic, we show that logical rules
between attributes define its support. As such, SSL approaches that use fuzzy logic (or similar) to
add logical rules into the loss function (e.g. Xu et al., 2018; van Krieken et al., 2019) can be seen
as approximating a continuous relaxation of p(θ) and so also fall under our probabilistic model for
discriminative SSL. Our key contributions are:
•	to provide a probabilistic model for discriminative semi-supervised learning, comparable to that
for classical generative methods, contributing to current theoretical understanding of SSL;
•	to consider the analytical form of the distribution over parameters p(θ), by which we explain
several SSL methods, including entropy minimisation as used in state-of-art SSL models; and
•	to show that our probabilistic model also unifies neuro-symbolic SSL in which logical rules over
attributes are incorporated (by fuzzy logic or similar) to regularise the loss function, providing
firm theoretical justification for this means of integrating ‘connectionist’ and ‘symbolic’ methods.
2	Background and related work
Notation: xli ∈ Xl, yil ∈Y lare labelled data pairs, i ∈{1...Nl}; xju ∈ Xu, yju ∈ Y uare unlabelled data
samples and their (unknown) labels, j ∈{1...Nu}; X, Y are domains of x and y; x, y are random
variables of which x, y are realisations. θx parameterises the distribution p(y|x), and is a realisation
of a random variable θ. To clarify: for each x, an associated parameter θx defines a distribution over
associated label(s) y |x; and p(θ) is a distribution over all such parameters.
2.1	Semi-supervised learning
Semi-supervised learning is a well established field, described by a number of surveys and taxonomies
(Seeger, 2006; Zhu & Goldberg, 2009; Chapelle et al., 2006; van Engelen & Hoos, 2020). SSL
methods have been categorised by how they adapt supervised learning algorithms (van Engelen
& Hoos, 2020); or their assumptions (Chapelle et al., 2006), e.g. that data of each class form
a cluster/manifold, or that data of different classes are separated by low density regions. It has
been proposed that all such assumptions are variations of clustering (van Engelen & Hoos, 2020).
Whilst ‘clustering’ itself is not well defined (Estivill-Castro, 2002), from a probabilistic perspective
this suggests that SSL methods assume p(x) to be a mixture of conditional distributions that are
distinguishable by some property, e.g. connected dense regions. This satisfies the condition that for
unlabelled x to help in learning to predict y from x, the distribution of x must contain information
relevant to the prediction (Chapelle et al., 2006; Zhu & Goldberg, 2009). In this work, we distinguish
SSL methods by whether they rely on direct properties of p(x), or on properties that manifest in p(θ),
the distribution over parameters of p(y|x; θx), for X 〜P(X). State-of-art models (Berthelot et al.,
2019b;a) combine methods of both types.
A canonical SSL method that relies on explicit assumptions of p(x) is the classical generative model:
P(Xl,Yl,XU)= Z p(Ψ,∏)p(xl|Y 1,Ψ)p(yll∏)X-PVN P(XTYu,Ψ)p(yul∏)⑴
Jψ,∏	L Y u∈Y Nu_____________________}
"^^^^^^^^■}
p(Xu∣ψ,π)
Parameters ψ, π of P(x|y) and P(y) are learned from labelled and unlabelled data, e.g. by the EM
algorithm, and predictions P(y |x) =P(x|y)P(y)/P(x) follow by Bayes’ rule. Figure 1 (left) shows the
corresponding graphical model. Whilst generative SSL has an appealing probabilistic rationale, it is
rarely used in practice, similarly to its counterpart for fully supervised learning, in large part because
P(x) is often complex yet must be accurately described (Grandvalet & Bengio, 2005; Zhu & Goldberg,
2009; Lawrence & Jordan, 2006). However, properties of P(x) underpin data augmentation and
consistency regularisation (Sajjadi et al., 2016b; Laine & Aila, 2017; Tarvainen & Valpola, 2017;
Miyato et al., 2018), in which true x samples are adjusted, using implicit domain knowledge of
P(x|y), to generate artificial samples of the same class, whether or not that class is known. Other SSL
methods consider P(x) in terms of components P(x|z), where z is a latent representation useful for
2
Under review as a conference paper at ICLR 2021
Figure 1: Graphical models for: generative SSL (left); discriminative SSL (previous (Chapelle et al.,
2006)) (centre); discriminative SSL (ours) (right). Shading variables are observed (else latent).
predicting y (Kingma et al., 2014; Rasmus et al., 2015). We focus on a family of SSL methods that
add a function of the unlabelled data predictions to a discriminative supervised loss function, e.g.:
• Entropy minimisation (Grandvalet & Bengio, 2005) assumes classes are “well separated”. As
a proxy for class overlap, the entropy of unlabelled data predictions is added to a discriminative
supervised loss function `sup :
l	uu
'MinEnt⑹=- XX yi,k log θki - XX θkj log θkj
(2)
ik
1----------
` sup
jk
}
•	Mutual exclusivity (Sajjadi et al., 2016a; Xu et al., 2018) assumes no class overlap, i.e. correct
predictions form ‘one-hot’ vectors. Viewed as vectors of logical variables z, such outputs exclu-
sively satisfy the logical formula Wk (zk Vj6=k zj ). A function based on the formula applies to
unlabelled predictions:
'MutExc(θ) = 'sup - Xi log X θXu Y(1-θXu )
(3)
k	k0 6=k
xu
•	Pseudo-labelling (Lee, 2013) assumes that predicted classes kj (t) =arg maxk θkj for unlabelled
data xju at iteration t, are correct (at the time) and treated as labelled data:
u
u
'Pseudo(θ,t) = 'sUp — ∑lθg∑ lk=kj(t)θj
(4)
j
j
k
These methods, though intuitive, lack a probabilistic rationale comparable to that of generative models
(Eq. 1). Summing over all labels for unlabelled samples is of little use (Lawrence & Jordan, 2006):
p(Yl|Xl,Xu)=
θ
p(θ)p(Yl|Xl,θ) PyUP(YUXu,θ)
p(θ)p(Y l|Xl, θ).	(5)
θ
|
}
*{z
=1
Indeed, under the associated graphical model (Fig. 1 (centre)), parameters θ of p(Yl|Xl, θ) are
provably independent of Xu (Seeger, 2006; Chapelle et al., 2006). Previous approaches to breaking
this independence include introducing additional variables to Gaussian Processes (Lawrence & Jordan,
2006), or an assumption that parameters of p(y|x) are dependent on those of p(x) (Seeger, 2006).
Taking further the (general) assumption of (Seeger, 2006), we provide a probabilistic model for
discriminative SSL (DSSL), analogous and complementary to that for generative SSL (Eq. 1).
2.2 Neuro-symbolic learning
Neuro-symbolic learning (NSL) aims to bring together statistical machine learning, e.g. neural
networks, and logical reasoning (see Garcez et al. (2019) for a summary). Approaches often either
introduce statistical methods into a logical framework (e.g. Rocktaschel & Riedel, 2017; Manhaeve
et al., 2018); or combine logical rules into statistical learning methods (Rocktaschel et al., 2015;
Ding et al., 2018; Marra et al., 2019; van Krieken et al., 2019; Wang et al., 2019). A conceptual
framework for NSL (Valiant, 2000; Garcez et al., 2019) places statistical methods within a low-level
perceptual component that processes raw data (e.g. performing pattern recognition), the output of
which feeds a reasoning module, e.g. performing logical inference (Fig. 2). This structure surfaces
in various works (e.g. Marra et al., 2019; Wang et al., 2019; van Krieken et al., 2019; Dai et al.,
2019), in some cases taking explicit analytical form. Marra et al. (2019) propose a 2-step graphical
model (their Fig. 1) comprising a neural network and a “semantic layer”, however logical constraints
are later introduced as a design choice (their Eq. 2), whereas in our work they are a natural way to
parameterise a probability distribution. The graphical model for SSL of van Krieken et al. (2019)
(their Fig. 1) includes a neural network component and a logic-based prior. However, knowledge base
3
Under review as a conference paper at ICLR 2021
Perception
Data
Reasoning
(x,y) (x,y)
(x,y) (x,y) (χ,y)
Figure 2: A general framework for neuro-symbolic learning combining statistical learning (perception)
and logical rules (reasoning) (Valiant, 2000; Garcez et al., 2019). We draw an analogy to our
probabilistic model for discriminative SSL (§3), in which p(θ) can be defined with logical rules (§5).
rules directly influence labels (y) of unlabelled data (only), whereas in our model, rules govern the
parameters (θx) of all label distributions, i.e. p(y|x; θx), ∀x. Where van Krieken et al. (2019) view
probabilities as “continuous relaxations” of logical rules, we show such rules can be used to define
the support of the prior p(θ) in a hierarchical probabilistic model for DSSL, which therefore provides
a theoretical basis for neuro-symbolic semi-supervised learning. We note that many other works
consider related latent variable models (e.g. Mei et al. (2014) implement logical rules as constraints
in a quasi-variational Bayesian approach) or structured label spaces (see e.g. Zhu & Goldberg (2009)
for a summary), however we restrict the scope of this review to SSL applications.
3 A probabilistic model for discriminative SSL
Label(s) y∈ Y that occur with a given x can be viewed as samples drawn from p(y|x; θx), a distribution
over the label space with parameter θx. For example, in k-class classification p(y|x) is a multinomial
distribution over classes, fully defined by a mean parameter θx ∈ ∆k, on the simplex in Rk. Every
x ∈ X has an associated label distribution and so corresponds to a single ground truth parameter θx
(in some domain Θ). Thus, there exists a well defined (deterministic) function f : X →Θ, f(x) =θx.
Predictive models, e.g. neural networks, typically learn to approximate f: given x, they output θx, an
estimate of θx. Note that the label y itself is not predicted, e.g. in the k-class classification example, if
x occurs with multiple distinct labels across the dataset, their mean θx = E[y|x] is learned. Since each
X corresponds to a parameter θx, sampling X 〜P(X) induces an implicit distribution over parameters
p(θ). In the k-class classification example, p(θ) is a distribution over mean parameters defined on
the simplex ∆k (e.g. a Dirichlet distribution). Importantly, for any model learning to predict θx,
p(θ) serves as a prior distribution over its expected outputs. For a labelled data point, p(θ) may add
little information further to the label, however for unlabelled data, p(θ) provides a way to evaluate a
uu
prediction θx and so train the model, i.e. by updating it to increase p(θx ). We will show (Sec. 4)
that under a particular assumption, the analytical form of p(θ) is known a priori. In general, the
empirical distribution of predictions for labelled data p(θx ) might sufficiently approximate p(θ).
Formalising, let: θX = {θx }xl∈Xl be the set of parameters ofp(y|xl) for all xl ∈ Xl; and θXu be
defined similarly. Treating θx as a latent random variable with hierarchical prior distributionp(θ∣ɑ),
parameterised by α, the conditional distribution of the data factorises (analogously to Eq. 5) as:
P(Y lXX Xu=L…产)p(θ
χl∣θχl)p(θXl∣α) PYup(Yu产)p(产∣θx^)p(θx^∣α)
'--------V---------}
=1

P	p(α) p(Y l∣θχl )p(θχl∣α) P(GX u∣α),
Ja,Xx
(6)
.
where θx= fω(x) represent estimates of (ground truth) θx, and fω : X →Θ is a family of functions
with weights ω, e.g.aneural network. We replacep(Y∣X,θx) by p(Y∣θx) as θx fully defines p(y|x).
The distribution p(θx∣θx), over predictions given ground truth parameters, reflects model accuracy
(conceptually a noise or error model) and is expected to vary over X. For labelled data, on which
the model is trained, we assume (in row 2) that θx closely approximates θx, i.e. p(θx∣ θx) ≈δgχ-χχ.
For unlabelled data, p(θx | θx) is unknown but assumed to increase as predictions approach the true
parameter. p(θx | α) = fθx p(θx | θx)p(θx ∣α) can be interpreted as a relaxation of the prior applied to
predictions (a perspective we take going forwards), with equality to the prior in the limiting case
p(θx | θx) = δθχ-χχ. Fig. 1 (right) shows the corresponding graphical model. Taken together, the
relationship fω(X) = θx, the prior p(θ∣α) and the assumed closeness between θx and θx, break the
4
Under review as a conference paper at ICLR 2021
independence noted previously (Sec. 2). Without fω, a sample xu reveals nothing ofp(y|xu; θxu);
without p(θx ∣α), predictions can be made but not evaluated or improved. Interpreting terms of Eq. 6:
•	p(Yl∣ θX) encourages labelled predictions θx to approximate parameters of p(y∣χl);
•	p(θX | α) allows α to capture the distribution over θx, e.g. to approximatep(θ∣α); and
•	p(θXu | α) allows predictions θxu on unlabelled data to be evaluated under prior knowledge of
p(θ∣α), or from its approximation learned from labelled data (as above).
Maximum a posteriori estimates of θx are given by optimising Eq. 6, e.g. in K-class classification
.
by minimising the following objective with respect to ω (classes indexed by k, recall θx = fω (x)):
CDSSL⑹=-XXyi,klogθxi - Xlogp(θxi|a) - Xlogp(θxuIa)	⑺
The p(θ∣a) terms can be interpreted as regularising a supervised learning model. However, unlike
typical regularisation, e.g. 'ι, '2, here it applies to model outputs θx not weights ω. Fundamentally,
p(θ) provides a relationship between data samples that enables SSL, as an alternative to p(x).
A natural question arises: given that SSL has fewer y than x by definition, why consider SSL methods
that depend on p(y|x) rather than p(x)? Fortunately, the two options are not mutually exclusive,
but rather orthogonal and can be combined, as in recent approaches (Berthelot et al., 2019b;a).
Furthermore, the structure of p(θ) is often far simpler than that of p(x) and may be known a priori,
thus applying DSSL can be straightforward. We analyse the form of p(θ) in several cases in Sec. 4.
To relate discriminative and generative SSL, we highlight the inherent symmetry between them.
Restating the joint distributions behind Eq.s 1 and 6 (see Appendix B for details) as:
p(Yl, Xl, Xu) =L φγp(∏)p(xl∣ψγl)p(ψγ: YlI∏) XP(Xu∣ψγu)p(ψγ: YUI∏)
p(Yl, X,Xu) =Z	p(α)p(Y11 θχl)p(θχl, X l∣α) X p(Y T θx u)p(θxu, Xu∣a)
α,θX	Yu
[Gen.]
[Disc.]
reflects a similar hierarchical structure in which one element of the data (y in the former, x in the
latter) acts to ‘index’ a distribution over the other (see superscript to ψ or θ, resp.).
To have a little understanding of p(θ), we note that f(x) = θx (assumed differentiable) gives a
relationshipp(θ) = ∣ J∣p(x), for J the Jacobian matrix Ji,j =翁.Thus, if p(x) = Pkp(x∣y = k)∏k
is a mixture distribution with class probabilities πk =p(y=k), thjen p(θ) is also:
p(θ) = IJIp(X) = IJ | Ep(XIy=k)πk = E | J|p(x|y=k)πk = £p(e|y=k)π.	□
kk	k
Thus any cluster/mixture assumption of p(x) applies also to p(θ); and class conditional distributions
p(θIy) over ground truth parameters must differ sufficiently for classification to be possible.
4	Applications of dis criminative semi-supervised learning
Implementing Eq. 6 requires a description of p(θ), ideally in analytic form. Such form depends
heavily on two properties of the data: (i) the label domain Y being continuous or discrete; and (ii)
y Ix being stochastic or deterministic. Further, discrete labels may represent (a) K distinct classes as
‘one-hot’ vectors y ∈ {ek}k∈{1..K}, where each distribution p(yIx) is parameterised by θx ∈ ∆K (the
simplex), θkx =p(y=kIx); or (b) K binary (non-exclusive) features with y ∈ {0, 1}K (combinations
of which give 2K distinct labels), where θx∈ ∆2 , θkx = p(yk = 1Ix). Table 1 shows examples for
combinations of these factors that determine the form of p(θ). Italicised cases are discuss in detail.
Table 1: Task and data properties affecting the distribution p(θ) over parameters of p(yIx; θ).
Domain Y	Discrete (classification)		Continuous (regression)
Map x → y	Distinct classes	Non-exclusive features	
Stochastic	Mix of Gaussians	-	-
Deterministic	MNIST, SVHN CIFAR, Imagenet	Animals w/attributes Sudoku completion Knowledge Base completion	Image-to-image translation
5
Under review as a conference paper at ICLR 2021
Figure 3: The distribution p(θ) for a mix of 2 univariate Gaussians (varying class separation).
Stochastic classification, distinct classes (y ∈ {ek}k, θx ∈ ∆K): To see how p(x) and p(θ) can
relate, we consider a mixture of two 1-dimensional equivariant Gaussians: p(x) =Pk πk p(x|y = k),
k ∈{0,1}, where x|y = k 〜N(μk,σ2). Here, p(θ) canbe derived in closed form (see Appendix A):
p⑻=Pk=O πk Vzi2 ∣μι-μ0∣ exp{a(log θ )2 + (bk - 1)lθg θl + (-bk - 1)lθg θ0 + Ck}
X----------------------------------------------------------------------------}
{^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
p(θly=k)
for coefficients a, bk, ck. As expected (Sec. 3), p(θ) is a mixture with the same class probabilities as
p(x). Fig. 3 shows plots of P(X) and p(θ) for different separation of class means μk, illustrating how
the former determines the latter. Just as parameters of p(x) could be revised if a set of unlabelled data
samples Xu failed to fit the model, their predictions θx together with p(θ) offer a similar opportunity.
As class means diverge, class overlap reduces and p(θ) tends towards a limiting discrete distribution.
Note that, while here both p(x) and p(θ) are known analytically, this is not typically the case and
p(x) may be highly complex, however p(θ) may still have a concise analytical form.
Deterministic classification, distinct classes (y ∈ {ek}k, θx ∈ {ek}k): Often in classification, each
x associates (materially) with only one class label y, i.e. no other label y0 6=y appears with that x; thus
classes are mutually exclusive and y|x is deterministic. This applies in popular image classification
datasets, e.g. MNIST, CIFAR and ImageNet. Where so, θkx =p(y = k|x) ∈ {0, 1} and ground truth
parameters (as well perhaps as labels) form one-hot vectors θx ∈ {ek}k⊂ ∆K. It follows that each
class conditional p(θ∣y = k) is (approximately) a delta function δθ-ek at a vertex of the simplex ∆K:
p(θ) = Ekp(y=k) p(θ∣y=k) ≈ Eknk δθ-ek.
(8)
To clarify, for any x ∈ X, the corresponding parameter θx is always one-hot (the ‘1’ indicating
the single corresponding label y), ruling out stochastic parameters that imply the same x can have
multiple labels. Note that, irrespective of the complexity of p(x), p(θ) is defined concisely. However,
this distribution is discontinuous and lacks support over almost all of ∆K, i.e. p(θ) =0 for any θ 6=ek,
making it unsuitable for gradient-based learning methods. However, a continuous approximation to
p(θ) is obtained by relaxing each delta component to a suitable function over ∆K. Such relaxation
can be interpreted as estimating a noise or error model p(θx∣θx) of predictions given true parameters
(see Sec 3). From Eqs 2, 3 and 4 and Fig. 4, the unlabelled loss components of the SSL methods
entropy minimisation (Grandvalet & Bengio, 2005), mutual exclusivity (Sajjadi et al., 2016a; Xu
et al., 2018) and pseudo-labelling (Lee, 2013) can be seen to impose (un-normalised) continuous
relaxations p(θ) of the discrete p(θ). (Note: such p(θ) need not be normalised in practice since
a weighting term in the loss function renders any proportionality constant irrelevant.) We thus
theoretically unify these methods under the probabilistic model for discriminative SSL (Eqs. 6, 7).
Deterministic classification, non-exclusive features (y ∈ {0, 1}K, θ ∈ {0, 1}K): In some classifi-
cation tasks, label vectors y ∈ {0, 1}K represent multiple (K) binary attributes of x, e.g. features
present in an image, a solution to Sudoku, or the relations connecting subject and object entities in
a knowledge base. As in those examples, y|x can be deterministic. Where so, for a given x* and
its (unique) label y*, the conditional distribution p(y∣x*) equates to the indicator function ly-y*,
as parameterised by θx* = y*. Thus, all (true) parameters θx must be at vertices of the simplex
{0,1}K ⊂ ∆2 (analogous to one-hot vectors previously). It follows that p(θ∣y) = δθ-y and so
p(θ) = Pyπy δθ-y is a weighted sum of point probability masses at θ ∈ {0, 1}K. A continuous
6
Under review as a conference paper at ICLR 2021
Figure 4: UnsuPervised loss components of entropy minimisation (Eq. 2), mutual exclusivity (Eq. 3)
and pseudo-labelling (Eq. 4) (exponentiated for comparison to probabilities), seen as continuous
relaxations p(θ) of the discrete distribution p(θ), for deterministic y|x with distinct classes.
relaxation of p(θ) is again required for gradient based learning. The case becomes more interesting
when considering logical relationships that can exist between attributes (Sec. 5). Note that any
θ ∈ {0, 1}K⊂ ∆2 in the support of p(θ) (2K points in a continuous space) corresponds one-to-one
with a label y ∈ {0, 1}K. As such, the distribution p(θ) could potentially be learned from unpaired
labels y 〜p(y), a variation of typical SSL (We leave this direction to future work).
5	Neuro-symbolic semi-supervised learning
In classification with non-exclusive binary features, certain feature combinations may be impossible,
e.g. an animal having both legs and fins, three kings on a chess board, or knowledge base entities
being related by capital_city_of but not city_in. Where so, the support of p(y|x) for any x is confined
to a data-specific set of valid labels V, a subset of all plausible labels P= {0, 1}K, i.e. p(y|x) =0,
∀y ∈ P\V. If y|x is deterministic, there is a 1-1 correspondence between y and θ ∈ {0, 1}K (Sec. 4),
and we use V, P to refer to both labels y and parameters θ that are valid or plausible (resp.). Thus:
双θIa) = XP(y)P(θly) = X πyδθ-y ,	⑼
y∈V	y∈V
where α= {V, ΠV} and ΠV= {πy = P(y)}y∈V are marginal label probabilities. (Note that Eq, 9 also
holds for any ‘larger’ set V0, where V⊆V0 ⊆P.) As in the examples mentioned, the set of valid labels
V may be constrained, even defined, by a set of rules, e.g. mutual exclusivity of certain attributes,
rules of a game, or relationships between entity relations. Importantly, if a set of rules constrain V,
Eq. 9 shows that they constrain the support of P(θ), directly connecting them to the distribution
used in discriminative semi-supervised learning (Eqs 6, 7). This is appealing since logical rules
possess certainty (cf the uncertain generalisation of statistical models, e.g. neural networks) and their
universality may allow a large set V to be defined relatively succinctly. To focus on p(θ)'s support,
we drop πy and consider probability mass (replacing δθk -c with Kronecker delta δθkc), to define:
s(θ) = X δθy = X Y δθk1 Y δ(1-θk)1 ,	(10)
y∈V	y∈V k:yk =1	k:yk=0
where each term in the summation effectively evaluates whether θ matches a valid label y ∈ V,
i.e. s(θ) = 1 if θ ∈ V, else s(θ) = 0. Restricting to plausible θ ∈ P and defining logical variables
Zk ^⇒ (δθk ι = 1), it can be seen that Eq. 10 is equivalent to a IogicaIformuIa in propositional logic:
_	^ zk ^ zk ,	(11)
y∈V k：(yk = 1)	k：-(yk = 1)
which evaluates to True ⇔ θ ∈ V ⇔ s(θ) = 1. Comparing Eqs. 10 and 11 shows a relationship
between logical and mathematical operations common in fuzzy logic and neuro-symbolic literature
(e.g. Bergmann, 2008; Serafini & Garcez, 2016; van Krieken et al., 2019). Here, True maps to 1, False
to 0, ∧ to multiplication, ∨ to addition, and where zk corresponds to δθk1 = 1 (a function of θk), zk
maps to δ(1-θk)1 = 1 (the same function applied to 1-θk). In fact, for any (m-ary) propositional logic
operator o(Xι …Xm), e.g. Xi ⇒ X?, several functional representations Po :[0,1]m→ [0,1] exist,
taking binary inputs, corresponding to Xi ∈ {True, False}, and outputting PO = 1 if ◦ evaluates to
True, else 0 (Bergmann, 2008; Marra et al., 2019). The functional representation for a logical formula
composed of several logical operators is constructed by compounding the functional representations
of its components. Where two logical formulae are equivalent, then their functional representations
are equivalent in that each evaluates to 1 iff the logical formula is True, else 0. As such, any set of
logical rules that define V are equivalent to Eq. 11, and can be converted to a functional representation
equivalent to s(θ) in Eq. 10, restricted to θ ∈P.
7
Under review as a conference paper at ICLR 2021
fins ⇔ - legs
fins ⇒ tail
tail ⇒ (legs ∨ fins)
qδ(θ) = {0lθ ∈ P\v
qg(θ),θ ∈ [0,1]K
Figure 5: An illustration of the correspondence between logical rules and the support of p(θ). (top
left) All plausible values of θ if y |x is deterministic, i.e. θ restricted to the vertices (Sec. 4). (bottom
left) an example set of logical rules over label attributes. (centre) All valid values of θ under the rules,
as encoded in qδ(θ), a function over P that defines the support of p(θ). (right) qg(θ), a relaxation of
qδ(θ), defined over [0, 1]K, the gradient of which can “guide” unlabelled predictions towards valid θ.
Thus, logical rules can be converted into a function qδ(θ) (defined for θ ∈P= {0, 1}K) that evaluates
whether a binary vector is in V, the support of p(θ), i.e. qδ(θ) = 1θ∈v. Fig. 5 (left, centre) gives a
simple illustration. As in previous cases, gradient-based learning requires a relaxation of this function
defined over the domain of model predictions [0, 1]K. This is achieved by replacing the use of δθk1
with any function g(θk) : [0, 1] → [0, 1], g(1) = 1, g(0) = 0 (a relaxation of δθk1). By choosing g
continuous, the resulting qg(θ) : [0, 1]K→ [0, 1] is continuous and satisfies qg(θ) = s(θ) = 1 for
valid θ ∈ V, and qg(θ) = s(θ) = 0 for invalid θ ∈ P\V, providing a continuous relaxation of p(θ),
∀θ ∈ [0, 1]K (Fig. 5, right), up to probability weights πy (see Appendix C). Thus the distribution p(θ)
required for DSSL (Eqs. 6, 7), can be approximated by a functional representation of logical rules.
In practice, the choice g(θk) = θk from fuzzy logic (Bergmann, 2008) is often used (e.g. Serafini &
Garcez, 2016; van Krieken et al., 2019; Marra et al., 2019). Applying this choice directly to Eq. 10
gives the semantic loss (Xu et al., 2018), which is thus probabilistically justified and unified under
the model for discriminative SSL. Under the same DSSL model, p(θ) can also be learned from the
labelled data; justifying the use of logical techniques, such as abduction (Wang et al., 2019; Dai et al.,
2019), to extract rules consistent with observed labels, i.e. that entail V.
Many works combine functional representations of logical formulae with statistical machine learning.
We have shown that such methods are theoretically justified and that logical rules fit naturally
into a probabilistic framework, i.e. by defining the support of p(θ), the distribution necessary for
discriminative semi-supervised learning.
6 Conclusion
In this work, we present a hierarchical probabilistic model for discriminative semi-supervised learning,
complementing the analogous model for classical generative SSL methods. Central to this model are
the parameters θx of distributions p(y|x; θx), as often predicted by neural networks. The distribution
p(θ) over those parameters serves as a prior over the outputs of a predictive model for unlabelled data.
Depending on properties of the data, in particular whether y|x is deterministic, the analytical form of
p(θ) may be known a priori. Whilst not explored in this paper, the model for DSSL shows that an
empirical estimate of p(θ) might also be learned from labelled data predictions (or indeed unpaired
labels). In cases where labels reflect multiple binary attributes, logic relationships may exists between
attributes. We show how such rules fit within the same probabilistic model for DSSL, providing
a principled means of combining logical reasoning and statistical machine learning. Logical rules
can be known a priori and imposed, or potentially learned from the data. Our single model for
discriminative semi-supervised learning probabilistically justifies and unifies families of methods
from the SSL and neuro-symbolic literature, and accords with a general architecture proposed for
neuro-symbolic computation (Valiant, 2000; Garcez et al., 2019), comprising low level perception and
high level reasoning modules (Fig 2). In future work, we plan to consider the more complicated case
where y |x is stochastic (i.e. combining aleatoric uncertainty); to make more rigorous the notion of a
noise orerror model (i.e. capturing epistemic uncertainty), and to extend the principled combination
of statistical machine learning and logical reasoning to supervised learning scenarios.
8
Under review as a conference paper at ICLR 2021
References
Merrie Bergmann. An introduction to many-valued and fuzzy logic: semantics, algebras, and
derivation systems. Cambridge University Press, 2008.
David Berthelot, Nicholas Carlini, Ekin D Cubuk, Alex Kurakin, Kihyuk Sohn, Han Zhang, and
Colin Raffel. Remixmatch: Semi-supervised learning with distribution matching and augmentation
anchoring. In International Conference on Learning Representations, 2019a.
David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin A
Raffel. Mixmatch: A holistic approach to semi-supervised learning. In Advances in Neural
Information Processing Systems, 2019b.
Olivier Chapelle, Bernhard Scholkopf, and Alexander Zien. Semi-Supervised Learning. The MIT
Press, 2006.
Wang-Zhou Dai, Qiuling Xu, Yang Yu, and Zhi-Hua Zhou. Bridging machine learning and logical
reasoning by abductive learning. In Advances in Neural Information Processing Systems, 2019.
Boyang Ding, Quan Wang, Bin Wang, and Li Guo. Improving knowledge graph embedding using
simple constraints. In Proceedings of the Annual Meeting of the Association for Computational
Linguistics, 2018.
Vladimir Estivill-Castro. Why so many clustering algorithms: a position paper. ACM SIGKDD
explorations newsletter, 4(1):65-75, 2002.
Artur d’Avila Garcez, Marco Gori, Luis C Lamb, Luciano Serafini, Michael Spranger, and Son N
Tran. Neural-symbolic computing: An effective methodology for principled integration of machine
learning and reasoning. Journal of Applied Logics, 6(4):611-631, 2019.
Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Advances
in Neural Information Processing Systems, 2005.
Durk P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. Semi-Supervised
Learning with Deep Generative Models. In Advances in Neural Information Processing Systems,
2014.
Samuli Laine and Timo Aila. Temporal Ensembling for Semi-Supervised Learning. In International
Conference on Learning Representations, 2017.
Neil D Lawrence and Michael I Jordan. Gaussian processes and the null-category noise model.
Semi-Supervised Learning, pp. 137-150, 2006.
Dong-Hyun Lee. Pseudo-label: The simple and efficient semi-supervised learning method for deep
neural networks. In Workshop on challenges in representation learning, International Conference
on Machine Learning, 2013.
Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc De Raedt.
Deepproblog: Neural probabilistic logic programming. In Advances in Neural Information
Processing Systems, 2018.
Giuseppe Marra, Francesco Giannini, Michelangelo Diligenti, and Marco Gori. Integrating learning
and reasoning with deep logic models. In Joint European Conference on Machine Learning and
Knowledge Discovery in Databases, 2019.
Shike Mei, Jun Zhu, and Jerry Zhu. Robust regbayes: Selectively incorporating first-order logic
domain knowledge into bayesian models. In International Conference on Machine Learning, 2014.
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual Adversarial Training:
A Regularization Method for Supervised and Semi-Supervised Learning. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 41(8):1979-1993, 2018.
Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. Semi-supervised
learning with ladder networks. In Advances in Neural Information Processing Systems, 2015.
9
Under review as a conference paper at ICLR 2021
Tim Rocktaschel and Sebastian Riedel. End-to-end differentiable proving. In Advances in Neural
Information Processing Systems, 2017.
Tim Rocktaschel, Sameer Singh, and Sebastian Riedel. Injecting logical background knowledge
into embeddings for relation extraction. In Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies, 2015.
Mehdi Sajjadi, Mehran Javanmardi, and Tolga Tasdizen. Mutual exclusivity loss for semi-supervised
deep learning. In IEEE International Conference on Image Processing, 2016a.
Mehdi Sajjadi, Mehran Javanmardi, and Tolga Tasdizen. Regularization with Stochastic Transforma-
tions and Perturbations for Deep Semi-Supervised Learning. In Advances in Neural Information
Processing Systems, 2016b.
Matthias Seeger. A taxonomy for semi-supervised learning methods. Technical report, MIT Press,
2006.
Luciano Serafini and Artur d’Avila Garcez. Logic tensor networks: Deep learning and logical
reasoning from data and knowledge. arXiv preprint arXiv:1606.04422, 2016.
Antti Tarvainen and Harri Valpola. Mean Teachers are Better Role Models: Weight-averaged
Consistency Targets Improve Semi-Supervised Deep Learning Results. In Advances in Neural
Information Processing Systems, 2017.
Leslie G Valiant. A neuroidal architecture for cognitive computation. Journal of the ACM, 47(5):
854-882, 2000.
Jesper E van Engelen and Holger H Hoos. A survey on semi-supervised learning. Machine Learning,
109(2):373-440, 2020.
Emile van Krieken, Erman Acar, and Frank van Harmelen. Semi-supervised learning using differen-
tiable reasoning. Journal of Applied Logics—IfCoLog Journal of Logics and their Applications, 6
(4):633-653, 2019.
Po-Wei Wang, Priya L Donti, Bryan Wilder, and Zico Kolter. SATNet: Bridging deep learning
and logical reasoning using a differentiable satisfiability solver. In International Conference on
Machine Learning, 2019.
Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy van den Broeck. A semantic loss function
for deep learning with symbolic knowledge. In International Conference on Machine Learning,
2018.
Xiaojin Zhu and Andrew B Goldberg. Introduction to semi-supervised learning. Synthesis lectures
on artificial intelligence and machine learning, 3(1):1-130, 2009.
10
Under review as a conference paper at ICLR 2021
APPENDIX A	DERIVATION OF p(θ) FOR A MIXTURE OF GAUSSIANS
For a general mixture distribution:
θk = p(y=k|X) = σ(log P P(XIy=kT)—);
∖	Ek，=k P(XIy=k>k"
dθχ = θx(I-峪(dxlogP(XIy=k)- X P P(Xy=K	“ dxlogP(XIy=k0))
dX	k06=k	k006=k P(XIy = k )πk00
which, in our particular case, become:
θx=σ(log ∏ο + μσμ X - 2 (μ - μ0)),	dXx = θx(i - θx)(μ - μ0).
Rearranging the former gives X in terms of θ. Substituting into P(θ) = IJ IP(x) gives:
P(O) = X πk qi2 ∣μι- μ0∣ exp{a(log θ0 )2 + (bk - I)Iog θ1 + (-bk - I)Iog θ0 + Ck}
k=0	、------------------------------{z------------------------------}
p(θ∣y=k)
with COeffiCients：	a =	2g-1)2 ,	bk =	μ⅛0	+ (μισμo)2 (-	log	∏1),	Ck = - ^-
Appendix B	Reconciling Equations (1) and [Gen.]
P(Xl,Yl,Xu)=
ψ,π
=Z
ψ,π
=Z
ψ,π
=Z
ψ,π
P(ψ, π)P(XlIY l, ψ)P(Y lIπ)	P(XuIY u, ψ)P(Y uIπ)
Yu
(1)
P(π)P(ψγl,ΨYU)P(Xl∣Yl,ΨYl)P(Yl∣π) XP(XTYu,ΨYU)P(YU∣π)
Yu
P(π)P(Xl∣Yl,ψγl)P(ψγ: Yl∣π) XP(XTYu, ψγu)P(ψγ: YTn)
γU
P(π)P(XlIψγ l)P(ψγ l, Y lIπ) XP(XuIψγU)P(ψγU, Y uIπ)	[Gen.]
γU
ExplanatiOn： EaCh term ψγ parameterises a distributiOn Of the fOrmP(XIY, ψγ). ThOse distribu-
tiOns are COnditiOnal On the labels Y , henCe we attaCh that label tO the respeCtive parameter tO identify
the COrrespOndenCe. SuCh parameters are referred tO COlleCtively as ψ in line 1. Line 2 separates
them and identifies where eaCh OCCurs elsewhere. SinCe labels Y and their assOCiated parameters
ψ γ gO hand in hand, they are prObabilistiCally interChangeable： we COuld think Of drawing eaCh
label y frOm a pOOl Of k labels (and the parameter ψy COmes with it), Or draw a parameter ψy frOm a
pOOl Of k parameters. This explains the last 2 lines. FOr Clarity, nOte that in P(Xu IYu, ψγ U), Yu
Can be COnsidered redundant, given the parameter Of the distributiOn, the identity Of the label Of that
distributiOn is irrelevant.
APPENDIX C	JUSTIFICATION FOR CONSIDERING ONLY THE SUPPORT OF p(θ)
In seCtiOn 5, we fOCus On the support Of P(θ) defined by the set Of valid binary veCtOrs V, ignOring
the COrrespOnding Class prObabilities P(y) = πy ∈ ΠV. The disCriminative SSL methOds analysed
(see Eqs 2, 3, 4) ignOre Class weights alsO. PraCtiCal reasOns fOr dOing are (i) that they may nOt be
knOwn, and (ii) that unless attributes are independent (P(y) = Qk P(yk)), Class prObabilities dO nOt
faCtOrise aCrOss dimensiOns equivalently tO the suppOrt (Eq. 10). We briefly COnsider the validity and
impliCatiOns Of COnsidering Only the suppOrt Of P(θ).
Validity： Regardless Of whether Capturing all aspeCts Of P(θ) is preferable, COnsidering Only its
suppOrt is valid sinCe it is equivalent tO assuming a unifOrm distributiOn Over the suppOrt. The
resulting apprOximatiOn tO P(θ) might be COnsidered a “partially-uninfOrmative” priOr.
11
Under review as a conference paper at ICLR 2021
Implications: Considering only the support of p(θ) may be sufficient for the purposes of DSSL,
since where p(θ) provides a prior over unlabelled predictions, it is not used alone. If we had the full
(discrete) p(θ) and it alone were used to predict labels for unlabelled data, a maximum likelihood
approach would simply assign the most common label to all unlabelled data points. However, p(θ)
is used in conjunction with a supervised model that learns to approximates f(x) = θx to gives
predictions θx, taking class probabilities into account. To the extent the model generalises, its
predictions on unlabelled data should correlate with (i.e. be close to) their true values θx. Therefore a
function qg (θ), that is a continuous relaxation of the support of p(θ), helps by guiding predictions θx
to nearby valid values of θ, which should to some extent reflect the correct labels. Intuitively, the
prior class weights may be useful for data samples where the model is highly uncertain, where the
best option may again be to choose the most popular class. For well balanced classes, ignoring πy
should have little impact.
12