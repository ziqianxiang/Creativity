Under review as a conference paper at ICLR 2021
Task-similarity	Aware	Meta-learning
through Nonparametric Kernel Regression
Anonymous authors
Paper under double-blind review
Ab stract
This paper investigates the use of nonparametric kernel-regression to obtain a task-
similarity aware meta-learning algorithm. Our hypothesis is that the use of task-
similarity helps meta-learning when the available tasks are limited and may con-
tain outlier/ dissimilar tasks. While existing meta-learning approaches implicitly
assume the tasks as being similar, it is generally unclear how this task-similarity
could be quantified and used in the learning. As a result, most popular meta-
learning approaches do not actively use the similarity/dissimilarity between the
tasks, but rely on availability of huge number of tasks for their working. Our con-
tribution is a novel framework for meta-learning that explicitly uses task-similarity
in the form of kernels and an associated meta-learning algorithm. We model the
task-specific parameters to belong to a reproducing kernel Hilbert space where the
kernel function captures the similarity across tasks. The proposed algorithm iter-
atively learns a meta-parameter which is used to assign a task-specific descriptor
for every task. The task descriptors are then used to quantify the task-similarity
through the kernel function. We show how our approach conceptually generalizes
the popular meta-learning approaches of model-agnostic meta-learning (MAML)
and Meta-stochastic gradient descent (Meta-SGD) approaches. Numerical experi-
ments with regression and classification tasks show that our algorithm outperforms
these approaches when the number of tasks is limited, even in the presence of out-
lier or dissimilar tasks. This supports our hypothesis that task-similarity helps
improve the meta-learning performance in task-limited and adverse settings.
1	Introduction
Meta-learning seeks to abstract a general learning rule applicable to a class of different learning
problems or tasks, given the knowledge of a set of training tasks from the class (Finn & Levine,
2018; Denevi et al., 2018; Hospedales et al., 2020; Grant et al., 2018; Yoon et al., 2018). The setting
is such that the data available for solving each task is often severely limited, resulting in a poor
performance when the tasks are solved independently from each other. This also sets meta-learning
apart from the transfer learning paradigm where the focus is to transfer a well-trained network from
existing domain to another (Pan & Yang, 2010). While existing meta-learning approaches implicitly
assume the tasks as being similar, it is generally unclear how this task-similarity could be quantified
and used in the learning. As a result, most popular meta-learning approaches do not actively use the
similarity/dissimilarity between the tasks, but rely on availability of huge number of tasks for their
working. In many practical applications, the number of tasks could be limited and the tasks may not
always be very similar. There might even be ‘outlier tasks’ or ‘out-of-the-distribution tasks’ that are
less similar or dissimilar from the rest of the tasks. Our conjecture is that the explicit incorporation
or awareness of task-similarity helps improve meta-learning performance in such task-limited and
adverse settings.
The goal of this paper is to test this hypothesis by developing a task-similarity aware meta-learning
algorithm using nonparametric kernel regression. Specifically, our contribution is a novel meta-
learning algorithm called the Task-similarity Aware Nonparametric Meta-Learning (TANML) that:
•	Explicitly employs similarity across the tasks to fast adapt the meta-information to a given
task, by using nonparametric kernel regression.
1
Under review as a conference paper at ICLR 2021
•	Models the parameters of a task as belonging to a reproducing kernel Hilbert space
(RKHS), obtained by viewing the popular meta-learning of MAML and Meta-SGD ap-
proaches through the lens of linear/kernel regression.
•	Uses task-descriptors through a kernel function to quantify task-similarity/dissimilarity.
•	Offers a general framework for incorporating task-similarity in the meta-learning process.
Though we pursued the algorithm with a specific choice of the task-descriptors, the pro-
posed RKHS task-similarity aware framework can be extended to other formulations.
We wish to emphasize that our goal is not to propose another meta-learning algorithm that outper-
forms the state-of-the-art, but rather to investigate if task-similarity can be explicitly incorporated
and used to advantage in a meaningful manner. We show how this is achieved as the consequence
of viewing the popular MAML and Meta-SGD formulations through the lens of nonparametric ker-
nel regression. In order to keep the comparison fair on an apple-to-apple level, we compare the
performance of TANML with that of MAML and Meta-SGD algorithms.
1.1	Mathematical overview of the proposed task-similarity aware framework
Given pairs of data (xk, yk) ∈ Rnx X Rny where k ∈ {1,2, ∙∙∙ , K} generated by an unknown data
source, we are interested in learning a predictor Rnx × RD 3 (x, θ) 7→ f(x, θ) ∈ Rny from the
given data. For example, f(x, θ) could be a function defined by an artificial neural network (ANN).
We collect pairs of data in X = (χ1,χ2, ∙∙∙ ,χκ) and Y = (y1,y2, ∙∙∙ ,yκ) and define the loss
function RKnx × RKny × RD 3 (X, Y, θ) 7→ L(X, Y, θ) ∈ R which we then minimize with respect
to θ. This constitutes the training of the predictor. In the case of a ANN, L(X, Y, θ) ∈ R could be
the mean-square loss or the cross-entropy function. The data X, Y used for training is referred to as
ʌ
the training data. Let θ denote the optimal value of θ obtained from training. Given a new x ∈ Rnx ,
ʌ ʌ
We use y = f (x, θ) to predict y. ThegoodneSS of θ is evaluated using y 一 y on ajequence of pairs
of new data called the test data X, Y, defined similarly as X and Y, but with K number of data
pairs. The training of the predictor for the given data source is defined as a task.
Now, consider that we are interested in carrying out several such tasks for data coming from different
but similar sources. Let 匕 Yi, Xi, Yi, i_ = 1, ∙∙∙ ,Ttr denote the data from Ttr different data-
sources, and defined similarly as X, Y, X, Y above. We refer to the training of the predictor for
data Xi, Yi, Xi, Yi as the ith training task, and θi is referred to as the parameter for the task. Meta-
ʌ
learning captures similarities across the tasks by learning a common θ (which we denote by θ0) from
the data of these Ttr tasks (called the meta-training data), such that θ0 can be quickly adapted to train
a predictor for data from new and different but similar data-sources. Depending on howθ is obtained
from θ0, various meta-learning algorithms exist (Denevi et al., 2018; Finn & Levine, 2018; Allen
et al., 2019). The performance of the meta-learning algorithm is evaluated on previously unseen
data from several other similar sources Xiv, Yv, Xiv, Yv, i = 1, ∙∙∙ ,Tv (called the meta-test data)
defined similarly to XLY, X, Y — this constitutes the meta-test phase. The training of the predictor
for test data Xiv, Yv, XyVi, YVi is referred to as the ith test task, θvv denotes the parameter for the ith
test task. In the existing meta-learning approaches, both θi and θiv are obtained by adapting θ0 using
the gradient of L(Xi, Yi, θ) and L(Xiv, Yiv, θ), respectively, evaluated at θ0.
In our work, we propose a meta-learning algorithm where θi explicitly uses a similarity between
the ith training task and all the training tasks. Similarly, the parameters θiv for the test tasks also
use explicitly a similarity between the ith test task and all the training tasks. As specified later, we
define this task-similarity between two tasks through kernel regression, and our algorithm learns the
kernel regression coefficients Ψ as meta-parameters in addition to θ0 .
A motivating example Let us now consider a specific loss function given by L(X, Y, θ) =
PkK=1 kyk 一 f(xk, θ)k22 . Training for tasks independently with limited training data will typically
result in a predictor that overfits to X , Y, and generalizes poorly to Xy, Yy . MAML-type meta-
learning approaches (Finn et al., 2017) solve this by inferring the information across tasks in the
form of a good initialization θ0- specialized/adapted to a new task using the adaptation function
RD × RKnx × RKny 3 (θ0, X, Y) 7→gMAML(θ0,X,Y) ∈ RD defined as:
gMAML(θ0, X, Y) , θθ 一 αVθoL(X, Y,θθ)
2
Under review as a conference paper at ICLR 2021
The parameters for the training and test tasks as obtained through adaptation of θ0 as
θi = gMAML(θo, Xi, Yi), i =1,…，Ttr, and θV = gMAML(。0, Xiv,YV), i =1,…，T.
The meta-parameter θ0 is learnt by iteratively taking a gradient descent with respect to the test loss
on the training tasks given by PTI L(Xi, Yi, gMAML(θo, Xi, Yi)). The parameters for a task are
obtained directly from θ0 and does not make use of any information from the other training tasks.
As a result, the common θ0 learnt during the meta-training treats all tasks equally - the algorithm
implicitly assumes similarity of all tasks, but is not able to discern or quantify the degree of similarity
or dissimilarity among the tasks. In contrast, our algorithm involves an adaptation function gTANML
(to be defined later) that explicitly uses a notion of similarity between the tasks to predict parameters
fora task. As a result, we expect that our approach helps train predictors even when the data-sources
that are not very similar to each other. In our numerical experiments in Section 4, we see that this is
indeed the case the sinusoidal function as the data source.
1.2	Related work
The structural characterization of tasks and use of task-dependent knowledge has gained interest
in meta-learning recently. Edwards & Storkey (2017) proposed a variational autoencoder based
approach to generate task/dataset statistics used to measure similarity. Ruder & Plank (2017) con-
sidered domain similarity and diversity measures in the context of transfer learning (Ruder & Plank,
2017). The study of how task properties affect the catastrophic forgetting in continual learning was
pursued by Nguyen et al. (2019). Lee et al. (2020) proposed a task-adaptive meta-learning approach
for classification that adaptively balances meta-learning and task-specific learning differently for ev-
ery task and class. Bayesian approaches have been proposed to capture the similarity across tasks in
the form of task hyperpriors (Yoon et al., 2018; Finn et al., 2018; Grant et al., 2018; Rothfuss et al.,
2020). Task-similarity defined through effective sample size has been used to develop a new off-
policy algorithm for meta-reinforcement learning (Fakoor et al., 2020). It was shown by Oreshkin
et al. (2018) that the performance few-shot learning shows significant improvements with the use of
task-dependent metrics. While the use of kernels or similarity metrics is not new in meta-learning,
they are typically seen in the context of defining relations between the classes or samples within a
given task (Qiao et al., 2018; Rusu et al., 2019; Vinyals et al., 2016; Snell et al., 2017; Oreshkin et al.,
2018; Fortuin & Ratsch, 2019; Goo & Niekum, 2θ2θ). Qiao et al. (2018) use similarity metrics in the
activation space to predict parameters for novel categories in few-shot learning with zero-training.
Information-theoretic ideas have also been used in the study of the topology and the geometry of
task spaces by Nguyen et al. (2019); Achille et al. (2018). Achille et al. (2019) construct vector rep-
resentations for tasks using partially trained probe networks, based on which task-similarity metrics
are developed. Task descriptors have been of interest specially in vision related tasks in the context
of transfer learning (Zamir et al., 2018; Achille et al., 2019; Tran et al., 2019). Recently, neural tan-
gent kernels were been proposed for asymptotic analysis of meta-learning for infinitely wide neural
networks by considering gradient based kernels across tasks by Wang et al. (2020).
The work of Wang et al. (2020) is the closest in spirit to our work in that they consider kernels across
meta-learning tasks. However, the premise of their work is very different from ours. The aim of their
work is to show how global convergence behaviour of popular MAML type task-specific adaptation
can be assymptotically described using specific kernels, when every task involves training deep
neural networks of asymptotically infinite or very large widths. Our premise on the other hand is
entirely different - we consider a task-specific adaptation that actively employs similarity of tasks
in the form of valid kernel functions, in order to improve meta-learning performance. Our work does
not make assumptions on the nature of the kernel, the structure of the learner, or its dimensions.
2 Review of MAML and Meta-SGD
To facilitate our analysis, we first review MAML and Meta-SGD approaches and highlight the rel-
evant aspects necessary for our discussion. We shall then show how these approaches lead to the
definition of a generalized meta-SGD and consequently, to our TANML approach.
2.1	Meta Agnostic Meta-Learning
Model-agnostic meta-learning proceeds in two stages iteratively. As discussed in the motivating
example, the parameter θ for the ith training task Xi, Yi, Xi, Yi, i = 1, ∙∙∙ ,Ttr is obtained by
3
Under review as a conference paper at ICLR 2021
applying the adaptation function gMAML to θ0 as θi = gMAML (θ0, Xi, Yi). This is called the inner
update. Once θi is obtained for all the training tasks, θ0 is then updated by running one gradient
descent step on the total test-loss given by PTI L(Xi, Yi, 9maml(Θo, %, Yi)). This is called the
outer update. Each outer update involves Ttr inner updates corresponding to the Ttr training tasks.
The outer updates are run for Niter iterations. This constitutes the meta-training phase of MAML,
described in Algorithm 1. Once the meta-training phase is complete and θ0 is learnt, the parameters
for a new test task are obtained by applying the inner update on the training data of the test task.
We note here that MAML described in Algorithm 1 is the first-order MAML (Finn et al., 2018), as
opposed to the general MAML where the inner update may contain several gradient descent steps.
We note that when we talk of MAML in this paper, we always refer to the first-order MAML. A
schematic of MAML is presented in Figure 1.
Algorithm 1: Model agnostic meta-learning (MAML)
Initialize θ 0
for Niter iterations do
for i = 1,…，Ttr do
I gMAML(θo, XiJi)= θ0 — αVθo L(XiJi,θ0) [Innerupdate]
end
θo = θo — βVθo PTIL(Xi, Yi,gMAML(θo, Xi, Yi)) [Outer update]
end
2.2	Meta-Stochastic Gradient Descent (Meta-SGD)
Meta stochastic gradient descent (Meta-SGD) is a variant of MAML that learns the component-wise
step sizes for the inner update jointly with θ0 . Let α denote the vector of step-sizes for the different
components of θ. As with MAML, the meta-training phase of Meta-SGD also involves an inner and
an outer update. The outer update computes the values of θ0 and α; the inner update computes the
parameter values θi using the adaptation function RD × RD × RKnx × RKny 3 (θ0, α, Xi, Yi) 7→
gMSGD(θ0, α, Xi, Yi) ∈ RD defined as
gMSGD(θo,α, Xi, Yi)，θo - α ∙ Ve°L(Xi, Yi,θo),
where ∙ operator denotes the point-wise vector product. The outer update is run for
Niter iterations. The meta-training phase for Meta-SGD is described in Algorithm 2:
Algorithm 2: Meta-stochastic gradient descent
Initialize [θ0 , α]
for Niter iterations do
for i = 1,…，Ttr do
I gMSGD(θo,α, Xi, Yi) = θo — α ∙ Ve°L(Xi, Yi,θo)	[Inner update]
end
[θo,α] = [θo,α] - βV[θo© PTIL(Xi, Yi, 9msgd(Θo, α, Xi, Yi)) [Outer update]
end
The predictor for the ith test task is then trained by applying the inner update on Xiv , Yiv , using the
values of θ0 and α obtained in the meta-training phase.
We notice that the inner update is expressible as gMSGD (θ0, α, Xi, Yi) = W>zi (θ0) where
W, [I, -diag(α)]	and	zi(θ0) , θ0> Vθ0 L(Xi, Yi, θ0)>>.	(1)
The matrix W> denotes the transpose of W, I denotes the identity matrix, and diag(α) denotes the
diagonal matrix whose diagonal is equal to the vector α. We refer to zi(θ0) as the task descriptor
of the ith training task. Thus, gMSGD (θ0, α, Xi, Yi) takes the form of a linear predictor for θi with
zi (θ0) as the input and regression coefficients W. The adaptation gMSGD (θ0, α, Xi, Yi) can be
generalized to the case of W being a full matrix that is to be learnt from the training tasks. This
generalization results in the adaptation function RD × RD×2D × RKnx × RKny 3 (θ0, W, X, Y) 7→
gGMSGD(θ0, W, X, Y) ∈ RD given by
gGMSGD(θ0, W, Xi, Yi) = W>zi(θ0) =W1>θ0+W2>Vθ0L(Xi,Yi,θ0)
4
Under review as a conference paper at ICLR 2021
where W1 , W2 ∈ RD×T are the submatrices of W such that W = [W1 W2]. Expressed
in this manner, we notice how gGMSGD performs a parameter update similar to a second-
order gradient update with W2 taking a role similar to the Hessian matrix. We refer to
the resulting meta-learning algorithm as the Generalized Meta-SGD described in Algorithm 3.
The second term Ω(W) in the outer loop cost function is a regularization that ensures W is
bounded and avoids Ovefitting. On setting μ = 0 and using W as defined in equation 1,
the Generalized Meta-SGD reduces to the Meta-SGD. The Generalized Meta-SGD is thus a
more general form of MAML arrived at by viewing MAML/Meta-SGD as a linear regression.
Algorithm 3: Generalized Meta-SGD
Initialize [θo, W ∈ R2d×d]
for Niter iterations do
for i = 1,…，Ttr do
I gGMSGD(θo, W, Xi, Yi) = W>Zi(θo) [Inner update]
end
[θ0, W] = [θo, W] - βV[θo,w] (PTrIL(Xi, Yi,gGMSGD(θ0, W, Xi, Yi)) + μΩ(W))
end
3 Task-similarity Aware Meta-Learning
It is well known that the expressive power of linear regression is limited due to both its linear nature
and the finite dimension of the input. Further, since the dimension of linear regression matrix W
grows quadratically with the dimension of θ, a large amount of training data would be necessary
to estimate it. A transformation of linear regression in the form of ’kernel substitution’ or ’kernel
trick' results in the more general nonparametric or kernel regression (Bishop, 2006; SchOlkOPf &
Smola, 2002). Kernel regression essentially performs linear regression in an infinite dimensional
space making it a simple yet powerful and effective nonlinear approach. This motivates us to use
kernel regression model as the natural next step from the Generalized Meta-SGD developed in the
earlier section. By generalizing the linear regression model in gGMSGD, we propose an adaptation
function RD × RTtr×D × RKnx × RKny 3 (θ0, Ψ, X, Y) 7→ gTANML (θ0, Ψ, X, Y) ∈ RD in the
form of nonparametric or kernel regression model given by
Ttr
gTANML (θ0, Ψ, Xi, Yi) = X ψj k(zi (θ0), zj (θ0)) = Ψ>k(θ0, i),	(2)
j=1
where k : R2D × R2D 7→ R denotes a valid kernel function1, k(θ0, i) ,
[k (zi(θo),zι(θo)),…，k (zi(θo),zτtr(θo))]> is the vector with kernel values between the ith
training task and all the Ttr training tasks, and Ψ = [ψι, ∙∙∙ , ψτtr] is the matrix of kernel re-
gression coefficients stacked along the columns. The kernel coefficient matrix Ψ and the parameter
θ0 are learnt in the meta-training phase by iteratively performing an outer update as in the case of
the Generalized Meta-SGD. The computed Ψ and θ0 are then used to train the predictor for a new
test task by applying the inner update on its training data. We call our approach Task-similarity
Aware Nonparametric Meta-Learning (TANML) since the kernel measures the similarity between
tasks through the task-descriptors. As we show in the Appendix, TANML reduces to Meta-SGD
and MAML for specific choices of the kernel k and the regression coefficient matrix ψ.
The kernel regression in equation 2 models θi as belonging to the space of functions defined as H:
H
)∙-v	∙-v
θ : θ
Ttr
X ψik(zi(θo),Zi0(θo)), Ψi0 ∈ RD,
i0=1
i0 = 1,…,Ttr
(3)
The space H is referred to as the reproducing kernel Hilbert space (RKHS) associated with the
kernel k(∙, ∙). We refer the reader to (Hofmann et al., 2008) and (Scholkopf & Smola, 2002) for
further reading on RKHS. The space H has an important structure: each function in H uses the
1A valid kernel function is one that results in the kernel matrix evaluated for any number of datapoints to be
symmetric and positive-semidefinite cf. (Bishop, 2006)
5
Under review as a conference paper at ICLR 2021
______ meta-learning
——task descriptor-,
.... kernel } adaPtation
computation
Figure 1: Left: Schematic ofMAML. Right: Schematic of the TANML. Only the computation of θι
is shown to keep the diagram uncluttered.
information (the coefficients ψ) from allthe Ttr training tasks weighted by the kernel that essentially
quantifies a similarity or correlation between the tasks through the task-descriptors defined earlier.
While all meta-learning approaches use similarity implicitly, the number of works actively using
similarity with training data at test time are limited (Fakoor et al., 2020). Computing the optimal
values of the kernel coefficients Ψ and θ0 , which forms the meta-training phase, is then equivalent
to solving the functional minimization problem:
arg min (X L(Xi, Yi, θ) + μkθkH ),
θo,θ∈H ∖W1
where the regularization term is the squared-norm in the RKHS which promotes smoothness and
controls overfitting, μ being the regularization constant. The squared-norm in an RKHS is defined as
kθkH , PTI PT=I *%0k(zi(θo), Zi0(θo)) = Ψ>K(θo)Ψ; and K(θo) ∈ RTtr ×t" is the matrix
of kernels evaluated across all the training tasks. This novel connection between meta-learning
and RKHS obtained from TANML could potentially help in the mathematical understanding of
existing algorithms, and help develop new meta-learning algorithms in the light of the RKHS theory
(Hofmann et al., 2008; Scholkopf & Smola, 2002).
The meta-training phase for TANML is described in Algorithm 4, where We use Ω(Ψ) =
Ψ>K(θ0)Ψ. In general, other regularizations such as `1 or `2 norms could also be used. We
also note from equation 2 that the TANML approach is a general framework: any kernel and any
task-descriptor which meaningfully captures the information in the task could be employed. What
constitutes a meaningful descriptor for a task is an open question; while there have been studies
on deriving features and metrics for understanding the notion of similarity between data sources or
datasets, they have mostly been domain-specific and often require separate ’probe’ neural networks
for the extraction of features (Kim et al., 2019). The particular form of the task-descriptors used
in our derivation is the result of taking MAML/Meta-SGD as a starting point, and follows natu-
rally from analyzing them through the lens of linear and kernel regression. A schematic describ-
ing the task-descriptor based TANML and the intuition behind its working is shown in Figure 1.
Algorithm 4: Task-similarity Aware Meta Learning
Initialize [θ0,Ψ ∈ RTtr×D]
for Niter iterations do
for i = 1,…，Ttr do
I gτANML(θo,ψ, Xi, Yi) = Ψ>k(θo,i) [Inner update]
end
[θo, Ψ] = [θo, Ψ] - βV[θo,ψ] PT=riL(Xi, Yi,gτANML(θo, Ψ, Xi,Yi))+ μΩ(Ψ) [Outer
update]
end
On the choice of kernels and sequential training While the expressive power of kernels is im-
mense, it is also known that the performance could vary depending on the choice of the kernel
function(Scholkopf & Smola, 2002). The kernel function that works best for a dataset is usually
found by trial and error. A possible approach is to use multi-kernel regression where one lets the
data decide which of the pre-specified set of kernels are relevant (Sonnenburg & Schafer, 2005;
6
Under review as a conference paper at ICLR 2021
Gonen & AlPaydin, 2011). Domain-specific knowledge may also be incorporated in the choice of
kernels. In our analysis, we use two of the popular kernel functions: the Gaussian or the radial basis
function (RBF) kernel, and the cosine kernel.
We note that since MAML and Meta-SGD and similar approaches perform the inner update inde-
pendently for every task, they naturally admit a sequential or batch based training. Since TANML
uses an inner update in the form of a nonparametric kernel regression, it inherits one of the limita-
tions of kernel-based approaches - that all training data is used simultaneously for every task. As
a result, the task losses and the associated gradients for all the training tasks are used at every inner
update of TANML. One way to overcome this limitation would be the use of online or sequential
kernel regression techniques (Lu et al., 2016; Sahoo et al., 2019; Vermaak et al., 2003). We will
pursue this in our future work.
4 Numerical experiments
We evaluate the performance of TANML and compare it with MAML and Meta-SGD on two syn-
thesized regression datasets, five real-world time-series prediction problems from the Physionet
2012 Challenge dataset (Silva et al., 2012; Rothfuss et al., 2020), and on few-shot classification
dataset Omniglot (Lake et al., 2015). The synthesized regression tasks have been used previously
by previous works (Denevi et al., 2018; Finn et al., 2017; 2018) in meta-learning as a baseline
for evaluating the performance on regression tasks. In every experiment, the predictor f(x, θ) is
the output of a fully-connected four-layer feed-forward neural network, with Rectified linear unit
(ReLU) as the activation function; θ is the vector of all the weights and biases in the neural network
ʌ
-the predicted output is a scalar f or vector y, for the regression and classification tasks, respec-
tively. We consider two kernel functions for TANML: the Gaussian kernel k(zi (θ0), zi0 (θ0)) =
exp (-∣∣zi(θo)- zio(Θo)k2∕σ2), and the cosine kernel k(zi(θo),z"(θo)) = |彘(；：)>雷0(篇.In
order that the structural similarities are better expressed, we update kernel regression for the pa-
rameters of the different layers separately. This is because using a single adaptation function all
components of θi might result in certain parameters dominating the kernel regression, specially
when the dimension of the parameters becomes large. Hence, we perform the adaptation sepa-
rately for components of θ corresponding to the different layers l = 1,…，L using the adaptation
functions RDl × RDl×TtrRKnx × RKny 3 (θ0,l, Ψl, X,Y) 7→ gTANML,l (θ0,l, Ψl,X,Y) ∈ RDl
for the parameter θi,l belonging to the lth network layer: θi,l = gTANML,l (θ0,l , Ψl, Xi, Yi) =
PTt= ι ψio,ι k(zi(θo,B),Zi0 (θo,ι)), l = 1,…，L. The NMSE performance on the meta-test set is
obtained by averaging over 30 Monte Carlo realizations of tasks. For the regression tasks, the per-
formance of the various meta-learning approaches are compared using the normalized mean-squared
,	,	△ pTv∣ PK 1(yk - yk )2
error (NMSE) on the test tasks: NMSE，乙i=1 ±k=1 Yk_yk-
Pi= ι PK=I yk
. The numerical details of the ex-
periments not mentioned in the manuscript, such as the learning rate and other hyper-parameters,
are given in the appendix for space constraints.
Experiment 1 We consider the task of training linear predictors of the form f (x, θ) = θ>x. The
task data pairs (x, y) ∈ R16 × R are generated by a linear model y = β>x + e. The regression
coefficient vector β for different tasks is randomly sampled with equal probability from two isotropic
Gaussian distributions on β: with means β0 = -4 and β0 = 4, where 4 denotes the vector of all
fours. The additive noise e is assumed to be white and drawn from the standard normal distribution
and uncorrelated with x, which is distributed as the multivariate normal distribution of size 16. We
consider two cases of Ttr = 32 and Ttr = 64 training tasks, Each task with K = 4 samples in
training and test sets. We evaluate the performance of the MAML, Meta-SGD, and TANML on a
test set of Tv = 64 tasks. The NMSE test performance is reported in Table 1. We observe that
both MAML and Meta-SGD perform very poorly in comparison to TANML; Meta-SGD performs
slightly better than MAML. Further, we observe that TANML with the Cosine kernel performs
the best among the four algorithms. The superior performance of TANML could be ascribed its
the nonlinear nature with the gradients enter the estimation through the kernels. The adaptation
function involves terms with products of different gradients acting in the spirit of a higher order
method unlike MAML/Meta-SGD that use a first order adaptation. This also corroborates with the
findings of the recent theoretical work by Saunshi et al. (2020), where they show that MAML-type
approaches can fail under convex settings (as is the case in this experiment). It is also interesting to
7
Under review as a conference paper at ICLR 2021
Algorithm	MAML	Meta-SGD	TANML-GaUssian	TANML-Cosine
Ttr = 32	0.95	0.91	0185	0079
Ttr = 64	0.91	0.86	0.15	0.070
Table 1: NMSE on test tasks for the regression experiment 1.
Algorithm	Experiment 2a 10% oUtlier		Experiment 2a 20% outlier		Experiment 2b 10% OUtlier		Experiment 2b 20% OUtlier	
Ttr	256	512	256	512	256	512	256	512
MAML	0.83	0.77	ɪ7F	0.74	-0:89-	0.81	-0:83-	0.76
Meta-SGD	0.92	1.04	0.81	0.93	1.5	0.92	1.06	0.93
TANML-Gaussian	0.4	0.41	0.38	0.38	0.76	0.60	0.73	0.58
TANML-Cosine	0.37	0.35	0.30	0.26	0.44	0.38	0.47	0.33
Table 2: NMSE on test tasks for regression experiment 2.
note that the value of θ0 we obtain for TANML almost coincides with 0, which is the value for θ0
that theoretically minimizes the average error for this problem. We also find that both cosine and
Gaussian kernels converge typically in about 5000 iterations, whereas MAML and Meta-SGD do
not show improvement in NMSE even after 30000 iterations.
Experiment 2 In this experiment, we consider the task of training of non-linear predictors which
correspond to a fully connected ANN. We consider data pairs (x, y) ∈ R × R generated from the
sinusoidal data source y = A sin(ωx), where x is drawn randomly from the interval [-1, 1], and
A and ω differ across tasks. We do not use the knowledge that the data comes from a sinusoidal
source while training the predictors. We are given K = 4 shots or data-pairs in each task. In order
to illustrate the potential of TANML in using the similarity/ dissimilarity among tasks, we consider
a fixed fraction of the tasks to be outliers, that is, generated from a non-sinusoidal data source
in both meta-training and meta-test data, as described next. We consider two different regression
experiments:
(1)	Experiment 2a - Fixed frequency varying amplitude: The data for the different tasks generated
from sinusoids with A drawn randomly from (0, 1], setting ω = 1. The outlier task data generated
as y(x) = Ax.
(2)	Experiment 2b - Fixed amplitude varying frequency: The data for the different tasks gener-
ated from sinusoids with ω randomly drawn from [1, 1.5], setting A = 1. The outlier task data is
generated as y(x) = ωx.
We perform the experiments with the number of meta-training tasks equal to Ttr = 256 and Ttr =
512. The NMSE performance on test tasks obtained by averaging over 100 Monte Carlo realizations
of tasks is reported Table . We observe that TANML outperforms both MAML and Meta-SGD in test
prediction by a significant margin even when the fraction of the outlier tasks is 10% and 20%. This
clearly supports our intuition that an explicit awareness or notion of similarity aids in the learning,
specially when the number of training tasks is limited. We also observe that on an average TANML
with the cosine kernel performs better than the Gaussian kernel. We note that the performance of
the approaches in Experiment 2a is better than that in Experiment 2b. This is because there is higher
variation among the tasks (changing frequency) than in Experiment 2a (changing amplitudes). We
also observe that the performance improves slightly as Ttr increases.
Experiment 3 In this experiment, we consider the the regression task of time-series prediction on
the ICU patient dataset from the Physionet 2012 challenge. The dataset consists of measurements
of various vital characteristics of different patients monitored over a period of 48 hours, logged
in at various non-uniform time instants. For a given vital characteristic, the time-series of every
individual patient forms a task: the time of measurement and the measured value are the input and
output, respectively. The goal of the experiment is to predict the time series for new unseen patients
given the measurements taken during the first 24 hours. The experiment is done in five different
experiment settings corresponding to five different vital characteristics(V1 to V5 ). Since our interest
is in evaluating the performance in the limited task setting, we consider 100 tasks each for the meta-
training, meta-validation, and meta-testing. Further details of the implementation are given in the
Appendix. The NMSE values obtained for the test tasks are shown in Table 3. We observe that in all
the experiments TANML with the Gaussian kernel results in the least NMSE, though we also note
8
Under review as a conference paper at ICLR 2021
Algorithm	V1	V2	V3	V4	V5
MAML	0.56	0.50	0.12	0.13	1.2
Meta-SGD	0.03	0.18	0.04	0.03	0.63
TANML-Cosine	0.13	0.25	0.05	0.06	0.56
TANML-Gaussian	0.03	0.12	0.04	0.02	0.42
Table 3: NMSE on test tasks for regression experiment on Physionet 2012 dataset.
Algorithm	Experiment 4a: Ttr = 50	Experiment 4b: Ttr = 150
MAML	16	182
Meta-SGD	18.4	19.5
TANML-Gaussian	19.6	22
TANML-Cosine		23.2			241	
Table 4: Test accuracy % on Omniglot dataset.
that the performance of Meta-SGD also coincides with that of TANML in some of the experiments.
On comparison with results from Experiment 2, we observe that while Meta-SGD shows significant
improvement over MAML, it exhibits severe instability in the presence of outliers. On the other
hand, we observe that TANML performs good prediction in both the experiments.
Ablation Study An ablation study of some aspects of TANML is given in Section B of the Ap-
pendix. The study is made on the data from Experiment 3.
Few-shot learning We now consider the application of our approach to few-shot learning on the
character classification data from the Omniglot dataset. We consider the case of 5-way 1-shot learn-
ing: that is each task consists of a 5-class problem where each class is given two samples: one for
training and the other for validation. The classes correspond to different written characters /symbols
of a language, the input is the image in a gray-scale value. Given one training image per class, the
goal of each task is to build a 5-way classifier and evaluate its performance on another set of five
images. Unlike the state-of-the-art approaches where the goal is to perform few-shot learning over
a large number of training tasks (Li et al., 2017), we restrict our experiments to the limited task
setting. We consider two settings, where we use Ttr = 50 and Ttr = 100 meta-training tasks, and
evaluate the performance on a test set of 100 tasks. The cross-entropy loss is used as the objective
function for training. The test performance is measured in terms of the accuracy defined as the ratio
of correctly classified samples to the total number of samples in each task and is reported in Table
4. We observe that TANML with both the cosine and the Gaussian kernel outperform MAML and
Meta-SGD. We note that the accuracy values are low due to the limited task setting that we have
considered. Nevertheless, the experiments demonstrate the potential of TANML to improve few-
shot learning in extremely data-limited scenarios. We predict a similar trend to be exhibited even
when the number of training tasks is large.
5 Conclusion
We proposed a task-similarity aware meta-learning algorithm that explicitly quantifies and employs
a similarity between tasks through nonparametric kernel regression. We showed how our approach
brings a novel connection between meta-learning and reproducing kernel Hilbert spaces. Our hy-
pothesis was that an explicit incorporation of task-similarity helps improve the meta-learning per-
formance in the task-limited setting with possible outlier tasks. Experiments with regression and
classification tasks support our hypothesis, and our algorithm was shown to outperform the popular
meta-learning algorithms by a significant margin. The aim of the current contribution was to inves-
tigate how task-similarity could be meaningfully employed and used to advantage in meta-learning.
To that end, we wish to reiterate that the study is an ongoing one and the experiments considered
in this paper are in no way exhaustive. An important next step for our approach is also the use of
online/sequential kernel regression techniques to run our algorithm in a sequential or batch-based
manner and scale to scenarios with large number of tasks. The nonparametric kernel regression
framework also opens doors to a probablistic or Bayesian treatment of meta-learning that we plan to
pursue in the recent future.
9
Under review as a conference paper at ICLR 2021
References
Alessandro Achille, Glen Mbeng, and Stefano Soatto. Dynamics and reachability of learning tasks.
2018.
Alessandro Achille, Michael Lam, Rahul Tewari, Avinash Ravichandran, Subhransu Maji, Char-
less C. Fowlkes, Stefano Soatto, and Pietro Perona. Task2vec: Task embedding for meta-
learning. In 2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019,
Seoul, Korea (South), October 27 - November 2, 2019, pp. 6429-6438. IEEE, 2019. doi:
10.1109/ICCV.2019.00653. URL https://doi.org/10.1109/ICCV.2019.00653.
Kelsey R. Allen, Evan Shelhamer, Hanul Shin, and Joshua B. Tenenbaum. Infinite mixture proto-
types for few-shot learning. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceed-
ings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019,
Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pp. 232-
241. PMLR, 2019. URL http://proceedings.mlr.press/v97/allen19b.html.
C. M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics).
Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006. ISBN 0387310738.
Giulia Denevi, Carlo Ciliberto, Dimitris Stamos, and Massimiliano Pontil. Learning to learn around
A common mean. In Advances in Neural Information Processing Systems 31: Annual Con-
ference on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018,
Montreal, Canada, pp. 10190-10200, 2018. URL http://papers.nips.cc/paper/
8220-learning-to-learn-around-a-common-mean.
Harrison Edwards and Amos J. Storkey. Towards a neural statistician. In 5th International Confer-
ence on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference
Track Proceedings. OpenReview.net, 2017. URL https://openreview.net/forum?id=
HJDBUF5le.
Rasool Fakoor, Pratik Chaudhari, Stefano Soatto, and Alexander J. Smola. Meta-q-learning, 2020.
Chelsea Finn and Sergey Levine. Meta-learning and universality: Deep representations and gradient
descent can approximate any learning algorithm. In 6th International Conference on Learn-
ing Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference
Track Proceedings. OpenReview.net, 2018. URL https://openreview.net/forum?id=
HyjC5yWCW.
Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation
of deep networks. In Proceedings of the 34th International Conference on Machine Learning,
ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, pp. 1126-1135, 2017. URL http:
//proceedings.mlr.press/v70/finn17a.html.
Chelsea Finn, Kelvin Xu, and Sergey Levine. Probabilistic model-agnostic meta-
learning. In Advances in Neural Information Processing Systems 31: Annual Confer-
ence on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018,
Montreal, Canada, pp. 9537-9548, 2018. URL http://papers.nips.cc/paper/
8161-probabilistic-model-agnostic-meta-learning.
Vincent FortUin and Gunnar Ratsch. Deep mean functions for meta-learning in gaussian processes.
CoRR, abs/1901.08098, 2019. URL http://arxiv.org/abs/1901.08098.
M. Gonen and E. Alpaydin. Multiple kernel learning algorithms. J. Mach. Learn. Res., 12:2211-
2268, July 2011.
Wonjoon Goo and Scott Niekum. Local nonparametric meta-learning. 2020.
Erin Grant, Chelsea Finn, Sergey Levine, Trevor Darrell, and Thomas Griffiths. Recasting gradient-
based meta-learning as hierarchical bayes, 2018.
Thomas Hofmann, Bernhard Scholkopf, and Alexander J. Smola. Kernel methods in machine
learning. Ann. Statist., 36(3):1171-1220, 06 2008. doi: 10.1214/009053607000000677. URL
https://doi.org/10.1214/009053607000000677.
10
Under review as a conference paper at ICLR 2021
Timothy Hospedales, Antreas Antoniou, Paul Micaelli, and Amos Storkey. Meta-learning in neural
networks: A survey, 2020.
Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, S. M. Ali Eslami, Dan Rosenbaum,
Oriol Vinyals, and Yee Whye Teh. Attentive neural processes. CoRR, abs/1901.05761, 2019.
URL http://arxiv.org/abs/1901.05761.
Brenden M. Lake, Ruslan Salakhutdinov, and Joshua B. Tenenbaum. Human-level concept learning
through probabilistic program induction. Science, 350(6266):1332-1338,2015. ISSN 0036-8075.
doi: 10.1126/science.aab3050. URL https://science.sciencemag.org/content/
350/6266/1332.
Haebeom Lee, Hayeon Lee, Donghyun Na, Saehoon Kim, Minseop Park, Eunho Yang, and Sung Ju
Hwang. Learning to balance: Bayesian meta-learning for imbalanced and out-of-distribution
tasks. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa,
Ethiopia, April 26-30, 2020. OpenReview.net, 2020. URL https://openreview.net/
forum?id=rkeZIJBYvr.
Zhenguo Li, Fengwei Zhou, Fei Chen, and Hang Li. Meta-sgd: Learning to learn quickly for
few shot learning. CoRR, abs/1707.09835, 2017. URL http://arxiv.org/abs/1707.
09835.
Jing Lu, Steven C. H. Hoi, Jialei Wang, Peilin Zhao, and Zhiyong Liu. Large scale online kernel
learning. J. Mach. Learn. Res., 17:47:1-47:43, 2016. URL http://jmlr.org/papers/
v17/14-148.html.
Cuong V. Nguyen, Alessandro Achille, Michael Lam, Tal Hassner, Vijay Mahadevan, and Ste-
fano Soatto. Toward understanding catastrophic forgetting in continual learning.	CoRR,
abs/1908.01091, 2019. URL http://arxiv.org/abs/1908.01091.
Boris N. Oreshkin, PaU Rodrlguez Lopez, and Alexandre Lacoste. TADAM: task de-
pendent adaptive metric for improved few-shot learning. In Samy Bengio, Hanna M.
Wallach, Hugo Larochelle, Kristen Grauman, Nicolo Cesa-Bianchi, and Roman Gar-
nett (eds.), Advances in Neural Information Processing Systems 31: Annual Conference
on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018,
Montreal, Canada, pp. 719-729, 2018. URL http://papers.nips.cc/paper/
7352-tadam-task-dependent-adaptive-metric-for-improved-few-shot-learning.
S. J. Pan and Q. Yang. A survey on transfer learning. IEEE Transactions on Knowledge and Data
Engineering, 22(10):1345-1359, 2010.
Siyuan Qiao, Chenxi Liu, Wei Shen, and Alan L. Yuille. Few-shot image recognition by predicting
parameters from activations. In 2018 IEEE Conference on Computer Vision and Pattern Recogni-
tion, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018, pp. 7229-7238, 2018. doi: 10.1109/
CVPR.2018.00755. URL http://openaccess.thecvf.com/content_cvpr_2018/
html/Qiao_Few-Shot_Image_Recognition_CVPR_2018_paper.html.
Jonas Rothfuss, Vincent Fortuin, and Andreas Krause. Pacoh: Bayes-optimal meta-learning with
pac-guarantees, 2020.
Sebastian Ruder and Barbara Plank. Learning to select data for transfer learning with bayesian opti-
mization. In Martha Palmer, Rebecca Hwa, and Sebastian Riedel (eds.), Proceedings of the 2017
Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen,
Denmark, September 9-11, 2017, pp. 372-382. Association for Computational Linguistics, 2017.
doi: 10.18653/v1/d17-1038. URL https://doi.org/10.18653/v1/d17-1038.
Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero,
and Raia Hadsell. Meta-learning with latent embedding optimization. In 7th International Con-
ference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019, 2019.
URL https://openreview.net/forum?id=BJgklhAcK7.
Doyen Sahoo, Steven C. H. Hoi, and Bin Li. Large scale online multiple kernel regression with
application to time-series prediction. ACM Trans. Knowl. Discov. Data, 13(1):9:1-9:33, 2019.
doi: 10.1145/3299875. URL https://doi.org/10.1145/3299875.
11
Under review as a conference paper at ICLR 2021
Nikunj Saunshi, Yi Zhang, Mikhail Khodak, and Sanjeev Arora. A sample complexity separation
between non-convex and convex meta-learning. ArXiv, abs/2002.11172, 2020.
Bemhard Scholkopf and Alexander Johannes Smola. Learning with Kernels: SuPPor vector ma-
chines, regularization, optimization, and beyond. Adaptive computation and machine learning se-
ries. MIT Press, 2002. ISBN 9780262194754. URL https://www.worldcat.org/oclc/
48970254.
Ikaro Silva, George Moody, Daniel J Scott, Leo A Celi, and Roger G Mark. Predicting in-
hospital mortality of icu patients: The physionet/computing in cardiology challenge 2012. Com-
puting in cardiology, 39:245-248, 20l2. URL https://pubmed.ncbi.nlm.nih.gov/
24678516.
Jake Snell, Kevin Swersky, and Richard Zemel. Prototypical networks for few-shot learn-
ing. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vish-
wanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems 30, pp.
4077-4087. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/
6996-prototypical-networks-for-few-shot-learning.pdf.
G. Sonnenburg, S.and Ratsch and C. Schafer. A general and efficient multiple kernel learning algo-
rithm. Proc. Int. Conf. Neural Inf. Process. Syst., pp. 1273-1280, 2005.
Anh T. Tran, Cuong V. Nguyen, and Tal Hassner. Transferability and hardness of supervised
classification tasks. In 2019 IEEE/CVF International Conference on ComPuter Vision, ICCV
2019, Seoul, Korea (South), October 27 - November 2, 2019, pp. 1395-1405. IEEE, 2019. doi:
10.1109/ICCV.2019.00148. URL https://doi.org/10.1109/ICCV.2019.00148.
Jaco Vermaak, Simon J. Godsill, and Arnaud Doucet. Sequential bayesian kernel re-
gression. In Sebastian Thrun, Lawrence K. Saul, and Bernhard SchoIkoPf (eds.), Ad-
vances in Neural Information Processing Systems 16 [Neural Information Processing Sys-
tems, NIPS 2003, December 8-13, 2003, Vancouver and Whistler, British Columbia,
Canada], pp. 113-120. MIT Press, 2003. URL http://papers.nips.cc/paper/
2362-sequential-bayesian-kernel-regression.
Oriol Vinyals, Charles Blundell, Tim Lillicrap, Koray Kavukcuoglu, and Daan Wierstra. Match-
ing networks for one shot learning. In Advances in Neural Information Processing Systems
29: Annual Conference on Neural Information Processing Systems 2016, December 5-10,
2016, Barcelona, SPain, pp. 3630-3638, 2016. URL http://papers.nips.cc/paper/
6385-matching-networks-for-one-shot-learning.
Haoxiang Wang, Ruoyu Sun, and Bo Li. Global convergence and induced kernels of gradient-based
meta-learning with neural nets, 2020.
Jaesik Yoon, Taesup Kim, Ousmane Dia, Sungwoong Kim, Yoshua Bengio, and
Sungjin Ahn. Bayesian model-agnostic meta-learning. In S. Bengio, H. Wallach,
H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neu-
ral Information Processing Systems, volume 31, pp. 7332-7342. Curran Associates,
Inc., 2018. URL https://proceedings.neurips.cc/paper/2018/file/
e1021d43911ca2c1845910d84f40aeae- Paper.pdf.
Amir R. Zamir, Alexander Sax, William Shen, Leonidas J. Guibas, Jitendra Malik, and Silvio
Savarese. Taskonomy: Disentangling task transfer learning. In The IEEE Conference on Com-
Puter Vision and Pattern Recognition (CVPR), June 2018.
12
Under review as a conference paper at ICLR 2021
A Connection of TANML to Meta-SGD and MAML
We note that in the case when the kernel is the linear kernel k(zi(θ0), zi0 (θ0)) = zi(θ0)>zi0 (θ0),
TANML becomes the special case of Generalized Meta-SGD proposed in Section 2.2. This is be-
cause kernel regression and GMSGD further reduces to the Meta-SGD when the linear regression
matrix W is constrained to be of the form as in equation 1 and the regularization μ in the outer
loop is set to zero. When regression coefficients of the GMSGD are fixed to W = [I, -αI], we
obtain the MAML, which is a fixed linear transform acting on the task-descriptor. Thus, TANML
reduces to the specific cases of Meta-SGD and MAML, when the kernel is the linear kernel and the
regularization parameter μ in the outer-loop is set to zero.
Let us again consider the adaptation rule of the TANML:
Ttr
gTANML(θ0,Ψ,X,Y)=Xψjk(zi(θ0),zj(θ0))=Ψ>k(θ0,i)
j=1
In the case of linear kernel, we have that k(zi (θ0), zj(θ0)) = zi(θ0)>zj (θ0). Then, we have that
k(θ0, i) = Z>(θ0)z(θ0, i)
where Z(θ0) is the matrix of the task descriptors of all the training tasks arranged column-wise. This
gives that
gTANML(θ0, Ψ, X, Y) = Ψ>k(θ0, i) = Ψ>Z>(θ0)z(θ0, i)
In the case when Ψ>Z(θ0)> = [I - diag(α)], we get that
gTANML(θ0,Ψ,X,Y) = Ψ>Z>(θ0)z(θ0, i) = [I - diag(α)]z(θ0, i) = gMSGD
That is, when Ψ = (Z(θo))"l - diag(α)]>, gTANML = gMSGD, where f denotes the pseudo-inverse
operation. In other words, TANML with the kernel regression matrix constrained to be of the form
Ψ = (Z(θo))“l - diag(α)]> and with no regularization or μ reduces to the Meta-SGD.
Further, by the same argument, we have that in the case when TANML with Ψ given by the fixed
matrixΨ = (Z(θo))*[I - aI]>, gives
gTANML = gMSGD
This also helps gives an intuition on why behaviour of the TANML might perform better - MAML
and Meta-SGD are obtained by restricting the set of possible Ψ to a constrained set. In contrast,
TANML obtains Ψ through unconstrained search over RTtr ×D .
Thus, MAML and Meta-SGD are obtained as special cases of TANML, when the kernel is the linear
or the simple inner-product kernel, and the regression matrix Ψ takes special forms.
B Ablation study
We consider the study of the influence of two aspects on TANML:
B .1 Regularization parameter μ
As in the case of any regularized estimation or modelling approach, the motivation of including
the regularization parameter μ is to avoid the overfitting for ψ, specially in the task-limited setting.
Keeping all other parameters unchanged, We vary μ and the resulting test NMSE is shown in Table
5.
We observe that both a very large μ ora very small μ degrades the test performance. This is because
unlike MAML and Meta-SGD, the since TANML estimates more number of parameters from the
same training data, it tends to quickly overfit the training data to almost zero error. Hence, a nonzero
value of μ helps curtail the overfit. However, setting μ to a large value biases the parameters such
that very little learning takes place beyond the initial few meta-iterations resulting also in a poor test
performance. Thus, We see the best test prediction being acheived with μ set to 0.01.
13
Under review as a conference paper at ICLR 2021
μ μ	V1 Cosine	V1 Gaussian	V3 Cosine	V3 Gaussian	V4 Cosine	V4 Gaussian
5	0.63	-0:56-	0.39	-031-	0.52	-0:63-
0.1	0.34	0.08	0.06	0.04	0.05	0.05
0.01	0.13	0.03	0.05	0.04	0.06	0.02
0.001	0.32	0.08	0.1	0.07	0.08	0.06
Table 5: Effect of μ for regression experiment on Physionet 2012 dataset for Ex1, Ex2, Ex3.
This in turn indicates that the regularization helps TANML perform better than MAML and Meta-
SGD by avoiding overfitting to the training data. This is perhaps why TANML exhibits a superior
performance in comparison with the other two methods - as we have seen in Section A of the
Appendix, MAML and Meta-SGD are obtained when TANML uses a linear kernel and zero regu-
larization.
14
Under review as a conference paper at ICLR 2021
C Numerical Experiments
We compare four different approaches: MAML, Meta-SGD, TANML-Cosine, TANML-Gaussian.
All the algorithms were trained for 60000 meta-iterations, where each meta-iteration outer update
uses the entire set of training tasks, and not as a stochastic gradient descent. All the experiments
were performed on either NVIDIA Tesla K80 GPU on Microsoft Azure Platform.
D	Experiment 1 hyperparameters
In this experiment, we use a linear predictor of dimension 16, same as the input dimension. Each
task has four training input-output pairs and 4 test input-output pairs, that is, K = 4. Input x ∈ R16
is drawn from N(0, I), the additive noise e is white and drawn from N (0, 1).
D.1 MAML
•	Inner update learning rate: α: 0.01
•	Outer update learning rate: 5 × 10-4
•	Optimizer: Adam
D.2 Meta- S GD
•	Inner update learning rate α: learnt, initialized with values randomly drawn from
[0.001, 0.01]
•	Outer update learning rate for θ0: 5 × 10-4
•	Outer update learning rate for α: 1 × 10-6
•	Optimizer: Adam
D.3 TANML-GAUSSIAN
•	Outer update learning rate for θ0: 1 × 10-3
•	Outer update learning rate for Ψ: 5 × 10-5
∙	μ = 0.1
•	σ1 2 = 0.5
•	Optimizer: Adam
D.4 TANML-Cosine
•	Outer update learning rate for θ0 = θ0: 5 × 10-4
•	Outer update learning rate for Ψ: 1 × 10-5
∙	μ = 0.1
•	Optimizer: Adam
D.5 Experiment 2 Hyper-parameters
The hyper-parameters for the four approaches are listed below. The learning-rate parameters were
chosen such that the training error converged without instability.
(1) Experiment 2a - Fixed frequency varying amplitude: The data for the different tasks generated
from sinusoids with A drawn randomly from (0, 1], setting ω = 1. The outlier task data generated
as y(x) = Ax.
(2) Experiment 2b - Fixed amplitude varying frequency: The data for the different tasks gener-
ated from sinusoids with ω randomly drawn from [1, 1.5], setting A = 1. The outlier task data is
generated as y(x) = ωx.
15
Under review as a conference paper at ICLR 2021
D.6 MAML
•	Inner update learning rate: α: 0.01
•	Outer update learning rate: 5 × 10-4
•	Total ANN layers: 4 with, 2 hidden layers
•	Non-linearity: ReLU
•	Optimizer: Adam
D.7 Meta- S GD
•	Inner update learning rate α: learnt, initialized with values randomly drawn from
[0.001, 0.01]
•	Outer update learning rate for θ0: 5 × 10-4
•	Outer update learning rate for α: 1 × 10-6
•	Total ANN layers: 4 with, 2 hidden layers
•	Non-linearity: ReLU
•	Optimizer: Adam
D.8 TANML-Gaussian
•	Outer update learning rate for θ0: 1 × 10-3
•	Outer update learning rate for Ψ: 5 × 10-5
∙	μ = 0.1
•	σ2 = 0.5
•	Total ANN layers: 4 with, 2 hidden layers
•	Non-linearity: ReLU
•	Optimizer: Adam
D.9 TANML-Cosine
•	Outer update learning rate for θ0 = θ0: 5 × 10-4
•	Outer update learning rate for Ψ: 1 × 10-5
∙	μ = 0.1
•	Total ANN layers: 4 with, 2 hidden layers
∙	Non-linearity: ReLU
∙	Optimizer: Adam
E Experiment 3 hyperparameters
For every task, we use half of the samples for training data, and the remaining half for the validation.
In the case of test tasks, the training set consists of samples from the first half of the time series-the
goal is to predict the rest of the time series. In the case of training tasks, the training and validation
sets are drawn randomly from the entire time-series. We consider only those patients which have at
least four measurements. In order to minimize the dynamic range of the measurements, we divided
all the true measurements by 150. The time was measured in minutes. The five vital characteristics
considered are(Silva et al., 2012):
∙	V1 : Blood urea nitrogen
∙	V2 : Creatinine
∙	V3 : Invasive diastolic arterial blood pressure
∙	V4 : Urine
16
Under review as a conference paper at ICLR 2021
•	V5 : Heart-rate
The number of datapoints in each task varies from 4 to 48. The tasks with number of datapoints less
than four are not considered.
The following hyper-parameters settings were using in all the five vital characteristics.
E.1 MAML
•	Inner update learning rate: α: 10-3
•	Outer update learning rate: 5 × 10-3
•	Total ANN layers: 4 with, 2 hidden layers, 8 neurons per layer
•	Non-linearity: ReLU
•	Optimizer: Adam
E.2 META-SGD
•	Inner update learning rate α: learnt, initialized with values randomly drawn from
[0.001, 0.01]
•	Outer update learning rate for θ0: 5 × 10-3
•	Outer update learning rate for α: 1 × 10-5
•	Total ANN layers: 4 with, 2 hidden layers, 8 neurons per layer
•	Non-linearity: ReLU
•	Optimizer: Adam
E.3 TANML-Gaussian
•	Outer update learning rate for θ0: 1 × 10-3
•	Outer update learning rate for Ψ: 5 × 10-5
∙	μ = 0.01
•	σ2 = 1
•	Total ANN layers: 4 with, 2 hidden layers
•	Non-linearity: ReLU
•	Optimizer: Adam
E.4 TANML-COSINE
•	Outer update learning rate for θ0 = θ0: 5 × 10-4
•	Outer update learning rate for Ψ: 1 × 10-5
∙ μ = 0.01
•	Total ANN layers: 4 with, 2 hidden layers
∙	Non-linearity: ReLU
∙	Optimizer: Adam
F	Experiment 4 hyperparameters
We use two separate sets from training and test tasks as considered by Finn & Levine (2018). The
images are resized to 64× 64 dimensions.
17
Under review as a conference paper at ICLR 2021
F.1 MAML
•	Inner update learning rate: α: 10-3
•	Outer update learning rate: 5 × 10-3
•	Total ANN layers: 4 with, 2 hidden layers, 8 neurons per layer
•	Non-linearity: ReLU
•	Optimizer: Adam
F.2 Meta-SGD
•	Inner update learning rate α: learnt, initialized with values randomly drawn from
[0.001, 0.01]
•	Outer update learning rate for θ0: 5 × 10-4
•	Outer update learning rate for α: 1 × 10-5
•	Total ANN layers: 4 with, 2 hidden layers, 8 neurons per layer
•	Non-linearity: ReLU
•	Optimizer: Adam
F.3 TANML-Gaussian
•	Outer update learning rate for θ0: 1 × 10-3
•	Outer update learning rate for Ψ: 5 × 10-5
∙	μ = 0.01
•	σ2 = 1
•	Total ANN layers: 4 with, 2 hidden layers
•	Non-linearity: ReLU
•	Optimizer: Adam
F.4 TANML-COSINE
•	Outer update learning rate for θ0 = θ0: 5 × 10-4
•	Outer update learning rate for Ψ: 1 × 10-5
∙ μ = 0.01
•	Total ANN layers: 4 with, 2 hidden layers
∙	Non-linearity: ReLU
∙	Optimizer: Adam
18