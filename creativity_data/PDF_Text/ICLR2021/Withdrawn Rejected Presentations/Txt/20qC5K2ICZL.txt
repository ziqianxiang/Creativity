Under review as a conference paper at ICLR 2021
Robust Learning via Golden Symmetric Loss
of (un)Trusted Labels
Anonymous authors
Paper under double-blind review
Ab stract
Learning robust deep models against noisy labels becomes ever critical when
today’s data is commonly collected from open platforms and subject to adversarial
corruption. The information on the label corruption process, i.e., corruption matrix,
can greatly enhance the robustness of deep models but still fall behind in combating
hard classes. In this paper, we propose to construct a golden symmetric loss (GSL)
based on the estimated confusion matrix as to avoid overfitting to noisy labels and
learn effectively from hard classes. GSL is the weighted sum of the corrected
regular cross entropy and reverse cross entropy. By leveraging a small fraction of
trusted clean data, we estimate the corruption matrix and use it to correct the loss as
well as to determine the weights of GSL. We theoretically prove the robustness of
the proposed loss function in the presence of dirty labels. We provide a heuristics
to adaptively tune the loss weights of GSL according to the noise rate and diversity
measured from the dataset. We evaluate our proposed golden symmetric loss on
both vision and natural language deep models subject to different types of label
noise patterns. Empirical results show that GSL can significantly outperform the
existing robust training methods on different noise patterns, showing accuracy
improvement up to 18% on CIFAR-100 and 1% on real world noisy dataset of
Clothing1M.
1	Introduction
Diverse datasets collected from the public domain which power up deep learning models present new
challenges - highly noisy labels. It is not only time consuming to collect labels but also difficult to
ensure a consistent label quality due to various annotation errors (Patrini et al., 2017) and adversarial
attacks (Goodfellow et al., 2015). The large capacity of deep learning models enables effective
learning from complex datasets but also suffers from overfitting to the noise structure in the dataset.
The curse of memorization effect (Jiang et al., 2018) can degrade the accuracy of deep learning
models in the presence of highly noisy labels. For example, in (Zhang et al., 2017) the accuracy
of AlexNet to classify CIFAR10 images drops from 77% to 10%, when there are randomly flipped
labels.
Designing learning models that can robustly train on noisy labels is thus imperative. To distill the
impact of noisy labels, the related work either filters out suspiciously noisy data, derives robust
loss functions or tries to proactively correct labels. Symmetric Cross entropy Loss (SCL) is shown
effective in combating label noise especially for hard classes by combing the regular with the reverse
cross entropy. The former avoids overfitting and the latter is resilient to label noise. Given its
promising results, there is yet to have a clear principle on how to weight the regular and reverse
cross entropy terms, e.g., at different noise rates and patterns. In contrast, Distilling (Li et al., 2017)
and Golden Loss Correction (GLC) (Hendrycks et al., 2018) advocate to use a small clean data to
improve the estimated corruption matrix. Specifically, GLC trains the deep model on both a clean
and noisy set, whose loss is corrected through the corruption matrix. While the clean set is evenly
chosen from all classes, the corrupted labels may appear unevenly across classes depending on the
noise pattern (Xiao et al., 2015). As the corrected loss of GLC does not differentiate the difficulty of
classes, it may not learn those hard classes effectively.
We propose GSL constructing the golden symmetric loss that dynamically weights regular/reverse
cross entropy and corrects the label prediction based on the estimated corruption matrix. Similar to
1
Under review as a conference paper at ICLR 2021
NoiSe
--------1*
GLC
-----“
SCL
-----1	,*
GSL
—
“
(a) Corruption matrix
(b) Confusion matrix
Figure 1: Noise corruption matrix and confusion matrices of predictions for CIFAR-10 with 60%
symmetric label noise.

“



“
“
.
一-
GLC, GSL leverages clean data to estimate the corruption matrix which is used to correct labels
and decide the weights of the golden symmetric loss. As such, GSL can effectively differentiate the
difficulty level of classes by adjusting the weights and mitigate the impact of noise overfitting via the
golden symmetric cross entropy. Specifically, we use the noise rate and noise diversity to adaptively
tune the weights of modified cross entropy and reverse cross entropy. We prove that modified cross
entropy by using confusion matrix is noise tolerant same as the reverse cross entropy.
Motivation example. We demonstrate the advantages and disadvantages of GLC and SCL, and the
their combination (the proposed GSL) through the example of learning convolution networks on
CIFAR-10 injected with 60% symmetric noise. The experimental setup is detailed in §6. Figure 1
shows the corruption matrix of the injected noise and the confusion matrices from the predictions
of SCL, GLC, and GSL. Even if the injected noise is symmetric across all classes (see Figure 1a),
prediction errors are distributed asymmetrically across the classes (see Figure 1b). Though GLC can
achieve a lower average error rate than SCL (reflected in darker diagonal elements on average), it
performs worse in hard classes, e.g., class 4 (cat) and class 6 (dog) (difference in blue shades across
the diagonal elements). By setting up proper weights for two types of cross entropy, GSL is able to
achieve both superior average and per class accuracy.
2	Related Work
Enhancing the robustness of deep models against noisy labels is an active research area. The
massive datasets needed to train deep models are commonly found corrupted, (Wang et al., 2018),
severely degrading the achievable accuracy, (Zhang et al., 2017). The impact of label noise on deep
neural networks is first characterized by the theoretical testing accuracy over a limited set of noise
patterns (Chen et al., 2019). (Vahdat, 2017) suggest an undirected graph model for modeling label
noise in deep neural networks and indicate symmetric noise to be more challenging than asymmetric.
Solutions of the prior art can be categorized into three directions: (i) filtering out noisy labels: (Malach
& Shalev-Shwartz, 2017; Han et al., 2018b; Yu et al., 2019; Wang et al., 2018); (ii) correcting noisy
labels: (Patrini et al., 2017; Hendrycks et al., 2018; Li et al., 2017); and (iii) deriving noise resilient
loss functions: (Ma et al., 2018; Konstantinov & Lampert, 2019).
Noise Resilient Loss Function. The loss function is modified to enhance the robustness to label noise
by introducing new loss functions, (Ghosh et al., 2017; Wang et al., 2019), or adjusting the weights
of noisy data instances, (Ren et al., 2018b; Konstantinov & Lampert, 2019; Ma et al., 2018). Mean
Absolute Error (MAE) (Ghosh et al., 2017; Zhang & Sabuncu, 2018) and General Cross Entropy
loss (Zhang & Sabuncu, 2018) are proposed as a noise resilient alternative but at the cost of slow
convergence. To avoid overfitting to noise, D2L (Ma et al., 2018) uses the subspace dimensionality to
assign weights to each data point, whereas Konstantinov (Konstantinov & Lampert, 2019) determines
the loss weights based on the trustworthiness level of data sources. (Wang et al., 2019) propose
symmetric cross-entropy loss that combines a new term of reverse cross entropy with traditional
cross entropy via constant weights on both terms. Meta-Weight-Net (Shu et al., 2019) re-weights
samples during optimizing loss function in the training process by using a multi-layer perceptron to
predict the weight of each sample. With the same perspective, (Ren et al., 2018a) uses the similarity
of samples to the clean instances in the validation set for re-weighting them in loss function.
2
Under review as a conference paper at ICLR 2021
Label correction. To avoid the data reduction caused by filtering, label correction methods adjust the
predicted/given labels by using only noisy labels (Patrini et al., 2017; Tanaka et al., 2018) or jointly
with a small fraction of trusted data (Veit et al., 2017; Han et al., 2018a; Li et al., 2017; Hendrycks
et al., 2018). Reed et al. train the classifier by the “new” labels combining the raw and predicted labels
without access to label ground truth. (Patrini et al., 2017) estimate the noise confusion matrix by first
training a classifier on the noisy labels and then using the softmax probabilities. (Veit et al., 2017)
acquire human-verified labels to train a cleaning network for correcting noisy labels of multi-label
classification problems. (Han et al., 2018a) estimate the noise transition probability by incorporating
human assistance. (Li et al., 2017) and (Hendrycks et al., 2018) leverage a small set of clean data to
estimate noise corruption matrix from the clean and noisy sets, respectively. DivideMix (Li et al.,
2020) is a semi-supervised method, including two networks and Gaussian Mixture Model for sample
selection.
The proposed GSL combines resilient loss function and label correction by curating a small fraction
of trusted data. We solicit a subset of informative data instances to estimate the confusion matrix and
provide a minimum supervision on noisy labels. We also provide a heuristic to adaptively tune the
weights of golden symmetric loss according to the noise characteristics of the dataset.
3	Golden S ymmetric Loss
Consider the classification problem having dataset DD = {(xn,yn)}N=ι where Xn ∈ X ⊂ Rd denotes
thenth observed sample, and yn ∈ Y := {1,…,K} the corresponding given label over K classes.
Hereon n is ignore for the simplicity. y is affected by label noise. The label corruption process is
characterised by a corruption matrix Cij = P(y = j|y = i) for i = 1,...,K and j = 1,...,K
where y is the true label. Synthetic noise patterns are expressed as a label corruption probability ε
plus a noise label distribution. Let g(∙, θ) denote a neural network-based classifier parameterized by
θ. For each data point x, f (∙, θ) predicts the probability for each class label k: p(k∣x) = LKz
j=1 e j
where zj are the logits.
Symmetric Cross Entropy. Let q(k|x) denote the ground truth probability distribution over the K
class labels where q(k|x) = 1 for k equal to the true class y and q(k|x) = 0 for all k 6= y. The cross
entropy loss ('ce) and reverse cross entropy loss1 ('rce) for sample X are:
KK
'ce = -E q(k∣x)logp(k∣x), 'rce = - £p(k|x)log q(k∣x).	(1)
k=1	k=1
(Wang et al., 2019) combine cross entropy and reverse cross entropy into the symmetric cross entropy:
Isl = α 'ce + β 'rce
(2)
where α and β are hyperparameters. On the one hand cross entropy loss is not robust to noise (Ghosh
et al., 2017) but achieves good convergence (Zhang & Sabuncu, 2018). On the other hand reverse
cross entropy is tolerant to noise (Wang et al., 2019).
Estimating Noise Corruption Matrix. We estimate the noise corruption matrix as in (Hendrycks
et al., 2018). The method fosters training a first classifier g(∙, Θ) on noisy data to approximate the
elements Cij of the noise corruption matrix via a small fraction of trusted data D with known true
label y. Practically given Ai the subset of trusted data with label of class i {Ai ⊂ D : y = i}, the
elements of C can be approximated by:
ʌ
Cij
P(y = j∖y = i) ≈ 木
E g(y=j ∖χ, Θ)
x∈Ai
(3)
where g(y = j ∖x, Θ) denotes predicted probability of X having class label j. That is Cij is computed
as the mean predicted probability of class j for all trusted data points having true label of class i.
Training with Corrected Labels. Let C be the estimated noise corruption matrix. Using the
method in (Patrini et al., 2017), we increase the noise resilience by correcting the predictions of the
1To avoid problems with the logarithm, zero values of q are replaced by a small positive value, i.e. 10-4.
3
Under review as a conference paper at ICLR 2021
Qoooo
0 8 6 4 2
>UE⊃uura ⅛ΦH
Sym: rce only
—Sym: both
—Bimodal: ce only
—Bimodal: rce only
—Bimodal: both
0∙l-------1-------1-------1--------1-------
O 5	10	15	20	25
Enoch
Qoooo
0 8 6 4 2
1
>UE⊃uura ⅛ΦH
0、	，	，	，	，
0	5	10	15	20	25
Enoch
(b) α,β-tuning: best/worst (ε = 80%)
(a) Different loss corrections (ε = 70%)
Figure 2: Impact of loss correction and α,β-tuning on a 2-layer FC network trained on Twitter data.
classifier using C. Let P be the corrected predicted probabilities P = CTp, i.e. for data point x:
p(k∣x) = PK=ι Cikp(i∣x) for k = 1,...,K.We enhance the regular cross entropy term. Applying
the prediction correction to both terms holds lower benefits. We evaluate this empirically with
extensive experiments on datasets of text, i.e. Twitter in Figure. 2a, and images, i.e. CIFAR10 and
CIFAR100 in Appendix A.Experiment details can be found in §6. We consider different datasets,
noise rates, noise types and fractions of trusted data. We see that in all cases, except one with a
difference < 0.3%, correcting only the cross entropy (ce-only) holds better results than correcting
only the reverse cross entropy (rce-only) or correcting both. Focusing on Figure. 2a, ce-only improves
accuracy by up to 5% and 8% for bimodal and symmetric noise, respectively. In case of CIFAR-10 and
CIFAR-100 datasets the improvements are more pronounced with up to 11% and 50% respectively.
Golden Symmetric Loss. Towards a more effective and robust learning we propose to leverage the
estimated noise corruption matrix C to tune the two loss terms based on the observed noise pattern.
α and β can significantly impact the final model accuracy. Tuning these parameters is no mean feat
as different datasets affected by different noise patterns benefit from different optimal values (Wang
et al., 2019). Again we show this behavior by training a 2-layer FC neural network on the Twitter
dataset under eleven different (α, β) combinations and two noise patterns with 80% noise. Figure. 2b
reports for each noise pattern the evolution over the training epochs of the test accuracy for the best
and worst (α, β)-pair. For bimodal noise even with a small number of trials, the impact of (α, β)
ranges from an accuracy close to 60% all the way down to almost 0%. Moreover only few (two out
of eleven) (α, β)-pairs hold accuracy close to 60%. For symmetric noise the tuning impact is lower
(limited between 70% and 80%) but the best and worst (α, β)-pair differ from the bimodal noise case.
This underlines both the importance and difficulty of tuning (α, β). Motivated by the high impact of
α and β, we propose to dynamically weight the regular and reverse cross entropy terms. Let A() and
B() be weighting functions mapping C → R We define a new loss function:
'gsl = A(C) 'ce + B(C) 'rce	(4)
We call this new loss function golden symmetric loss. A() and B() should capture not only the
intensity of the noise pattern, but also the diversity of the noise pattern (see Figure. 2b).
Determining Weights of Golden Symmetric Loss (A() and B()). In general the more intense and
asymmetric the noise pattern, the lower the weight values should be. Since the final loss function
learns from both dirty and clean data (see next paragraph), lower values of α and β reduce the
influence of dirty data over the one of clean data. Hence, we design A() and B() to capture both
noise intensity and diversity. The intensity is given by the noise rate ε ∈ [0, . . . , 1], i.e. one minus
the average of the diagonal elements of C. The diversity is measured via Jain’s fairness index
J(x1, x2, . . . , xn) , (Pin=n xi)2/nPin=n xi2. We choose J because it bounds the diversity on a similar
scale as ε between 1 (all equal, full symmetry) down to 1/n (highest asymmetry). We apply J on all
the K(K - 1) noise, i.e. off the diagonal, elements of C:
J
(Pi=I Pj=1,j=i
Cj )2
K (K - 1) Pi=I Ej=Ij=CK
(5)
4
Under review as a conference paper at ICLR 2021
Figure 3: Training process of GSL divided into two steps.
For symmetric noise J = 1, the more asymmetric the smaller J. Final weights proportional to J, ε.
Putting It All Together. As a final step, to maximize the utility of the trusted data, we foster D as
additional trusted training data for f(). Since D contains the true labels y no prediction correction is
applied. Hence, the overall loss function for data points from both D and D is:
l = (-A© ∑K=1 q(k∣x) log(PK=ι Cikp(i∣x)) - B(C) PK=IP(k|x) log q(k∣x), X e D
- PkK=1 q(k|x) log p(k|x),	x ∈ D.
(6)
Figure. 3 summarises visually the training process divided into two main steps: (i) estimating noise
corruption matrix through the first network g trained on untrusted dataset D and (ii) training classifier
f on both untrusted D and trusted D through the golden symmetric loss.
4 Theoretical Analysis
We prove that the cross entropy loss with label correction is noise tolerant under the definition put
forth by (Ghosh et al., 2017; Manwani & Sastry, 2013) and extending prior art results. Let the
risk of classifier f and loss function % under clean labels be R(f) = Eχ,y'ce(f (x), y) and the
risk under noise rate ε be Rε(f) = Eχ,y'ce(f (x), y). E indicates the expectation taken over the
random variables indicated as its subscripts. With prediction correction via C, the risk becomes
Rε(f,C) = Eχ,y'ce(CTf(x),y). Let f* and f； be the global minimizers of R(f) and Rε(f),
respectively, and C* = p(y∣y) and C be the true and estimated noise confusion matrices, respectively.
Theorem 4.1. In a multi-class classification problem, 'ce with prediction correction is noise tolerant
under symmetric label noise ifthe noise rate ε < tjK-∆A, where ∆A = PK=I 'ce(C*Tf (x),k) —
K- ∆R	一
PK=I 'ce(CTf (x), k), and ∆R is the difference of risk minimization between optimal classifier
and f. And 'ce with prediction correction is also noise tolerant under flip noise when noise rate
εyk ≤ (1 + ∆Wy ) — εy (1 + ∆Wy ) where ε^ and εyk are the correct and flipped class probabilities,
respectively.
The proof is based on the risk minimization framework aiming to show under which condition
R；(f *, C*) — R；(f, C) ≤ 0, i.e. the loss function is robust to noise. The detailed steps of the
proof can be found in Appendix C. The condition ε < LK-A is a generalization of the previous
K 一 ∆R
boundε< K-by (Ghosh et al., 2017). Without label correction ∆A = 0 which corresponds to the
previous result. Label correction improves the robustness by allowing higher noise rates, i.e. with
label correction ∆∆R ≥ 0 and hence KK-I ≤ /-A . Similar observations hold for flip noise bound.
∆R
5
Under review as a conference paper at ICLR 2021
5	Experimental Setup
Dataset, Architecture and Parameters. We consider two types of datasets: vision and text analysis.
For vision, we use convolution neural networks (CNN) to classify CIFAR-10 and CIFAR-100 with
injected label noise and Clothing1M as real world noisy dataset. For text, we use fully connected
neural networks to classify noisy Twitter and Stanford Sentiment Treebank (SST). In principle, we
use the same network architecture on all comparative approaches across different noise resilience
techniques. In addition, we test the original network from the respective papers too and report the
best results among the two.
•	CIFAR-10 (Krizhevsky et al., 2009). It contains 60K images classified into 10 classes: 50K as a
training set and 10K as validation set. We use the architecture of Wide-ResNet by (Zagoruyko &
Komodakis, 2016) with depth 28 and a widening factor 10 and train it with SGD with Nesterov
momentum and a cosine learning rate schedule (Loshchilov & Hutter). For GSL, we first train f
for 75 epochs to obtain the noise corruption matrix. Then we train g for 120 epochs.
•	CIFAR-100 (Krizhevsky et al., 2009). It contains 60K images classified into 100 classes: 50K as
training set and 10K as the validation set. We use the same Wide-ResNet architecture used for
CIFAR-10. For GSL, we train the f and g networks for 75 and 200 epochs, respectively.
•	Clothing1M (Xiao et al., 2015). This is a real world dataset with label noise. It includes images
scrapped from the Internet classified into 14 categories. We resize and crop each image to
224 × 224 pixels. This dataset contains 47K and 10K images for training and testing, respectively.
These two sets have both given (scrapped) and true (human-checked) labels. We use ResNet-50
pretrained with ImageNet and further train for 10 epochs with batch size 32, SGD optimizer,
momentum 0.9, weight decay 10-3, and learning rate 10-3 which is divided by 10 after 5 epochs.
•	Twitter (Gimpel et al., 2011). The Twitter dataset includes 1,827 tweets annotated with 25 POS
tags split in 1000 tweets as training set, 327 tweets as development set and 500 tweets as test set.
We add development set to training set, and consider it as a training set. We use a 2-layer fully
connected network with 256 hidden neurons each and GELU nonlinearity as activation function.
We train f with Adam for 15 epochs with batch size 64 and learning rate of 0.001. We train g for
25 epochs. To regularize all linear output layer, we use `2 weight decay with λ = 5 × 10-5.
•	Stanford Sentiment Treebank (Socher et al., 2013). The SST dataset includes single sentence
movie reviews. We use the 2-class version, including 6911 reviews in the training set, a develop-
ment set with 872 reviews, and 1821 reviews in the test set. We augment the training set by using
development set. We learn 100-dimensional word vectors from scratch for a vocab size of 10000.
We train a word-averaging model with an affine output layer using Adam optimizer for 5 epochs
for network f and 10 epochs for network g. The batch size and learning rate are 50 and 0.001,
respectively. To regularize all linear output layer, we use `2 weight decay with λ = 1 × 10-4.
Noise Corruption. We consider symmetric noise and two different asymmetric noises, namely flip
and bimodal. Symmetric noise corrupts the true label into a random other labels with equal probability
based on the noise rate. The flip noise is generated by flipping the original label to a paired other class
with a specific probability. The bimodal noise imitates targeted adversarial attacks (Goodfellow et al.,
2015). Specifically, the true labels are corrupted into two neighborhoods centered on two targeted
classes, each of which follows truncated normal distribution, NT (μ, σ, a,b). μ specifies the target
and σ controls the spread. a and b simply define the class label boundaries. For CIFAR-10 we target
class 3 and 7, for CIFAR-100 class 30 and 70, for Twitter class 6 and 18, and for SST class 0 and 1.
Instead, Clothing1M is already affected by real world label noise and left untouched.
6	Evaluation
In this section, we empirically compare GSL against state of the art noise resilient networks on noisy
vision and text data. We aim to show the effectiveness of GSL via testing accuracy on diverse and
challenging noise patterns. Our target evaluation metric is the accuracy achieved on the clean testing
set, i.e. not affected by noise.
6
Under review as a conference paper at ICLR 2021
Table 1: Vision analysis: test accuracy(%) of real-world noisy Clothing1M, and CIFAR10/CIFAR100
corrupted with 30% and 60% noise for different noise resilient networks. Best results in bold.
CIFAR-10
Noise Rate	Noise Pattern	GSL GLC SCL	Forward	B ootstrap	sgForward	Co-teaching+
30% _	Sym.	92.75_ 89.60	83.56 _	_ J4.06_ _		75:78 __		91.03			76.53	
~}0%~	Bimodal	92.892 189∙20 282.83 ］	［关.84］［	二］7574 二	［二 9124 ］二	［二 74.97 二1
~0%%~	——Flip ——	90.66— ^91.09" ^ 81:52 —	--78.55^ 一	7890 — —	90:81	7975
60% _	Sym.	88.94_ 81.60	73.67 _	_ ^54.37_ _		59.15 __		88.10			63:84	
~~6%%~	Bimodal	87.852 184.80 ɪ59:84 ］	［46.702 I	［二47J0 二	［二限蛇］二	［二 58709 二1
一~60% 一	——Flip ——	S4.97一 —80.33 —56:65 —	—49.45——	5929 —	8224	65108
	CIFAR-100							
Noise Rate	Noise Pattern	GSL GLC SCL	Forward	B ootstrap	sgForward	Co-teaching+
J0%_	Sym.	75.80	61.80 58.66 _	_ 40.80_ _		43.30 __		72.63 			53:94	
~}0%~	Bimodal	76.382 161.40 ］47:62 I	［45.222 I	二［4246 二	［二 73:87 ］二	［二 55722 丁1
~~30%~	——Flip ——	75.57― —75.23 ^55:23 —	-34.70——	55:08 —	76:03	58786
60% _	Sym.	68.31_ 51.30	29.63 _	_ 19.83 _		16:90 _ _		67.01			38:0?	
~05O%2	Bimodal	65.742 ［48.90 130:01 ］	［19.572 I	［二 10:47 ］］	二［63；39 ］二	［二 34.09 二1
一~60% 一	一—Flip ——	49.2T -66.96 —40:61 —	—38.63——	3814 —	67：93	4099
	ClothingIM							
Noise		GSL GLC SCL	Forward	B ootstrap	sgForward	Co-teaching+
Real World		74.86	73.91	70.78	70.04	67.87	73.96	70.33
6.1	Vision Analysis
We compare GSL against four noise resilient networks from the state of the art: GLC (Hendrycks
et al., 2018), SCL (Wang et al., 2019), FORWARD (Patrini et al., 2017), BOOTSTRAP (Reed et al.) and
Co-teaching+ (Yu et al., 2019). In addition, we extend Forward by adding reverse cross-entropy
based on SCL and loss correction through the confusion matrix same as GLC, called sgForward.
For training GSL, Co-teaching+, sgForward and GLC, we use PyTorch v1.4.0. For all other
methods, we use Keras v2.2.4 and Tensorflow v1.13.0.We assume 10% of trusted data is available for
GSL, GLC and sgForward. Table 1 summarizes the testing accuracy for all combinations of noise
patterns and comparative approaches.
For CIFAR-10, GSL achieves the highest accuracy among all resilient networks except for flip noise
with 30% noise rate. s gForward is the closest rival to GSL because both use the same mechanism
in the loss function. Besides, GSL has 2 to 8% higher accuracy than GLC, demonstrating the benefit
of introducing symmetric cross-entropy, especially in high noise rates. In terms of comparison
between GSL and SCL, the accuracy difference is even more visible, implying the benefit of using
corruption matrix to assign weights on two terms in symmetric cross-entropy. We note that SCL
uses an 8-layer CNN with 6 convolutional layers followed by 2 fully connected layers instead of a
Wide ResNet because of the superior results. SCL performs particularly worse in 60% bimodal noise
because this is a more challenging pattern and has no access to the corruption matrix. Moreover,
our method can still obtain 11 to 30% higher test accuracy than Co-teaching+ that uses two deep
networks concurrently.
CIFAR-100 is more challenging than CIFAR-10 due to the larger number of classes. GSL achieves
the highest accuracy except for flip noise with 30% rate, and sgForward is the second best result
among other competitors. Although for flip noise with 30% rate sgForward performs better than
GSL, the improvement of GSL is more significant than sgForward compared to the CIFAR-10
dataset. The largest difference (more than 2%) in accuracy between the GSL and s gForward
methods is with bimodal noise. In case of 60% symmetric noise, GSL achieves the accuracy of
68%, whereas GLC and SCL trail far behind. Moreover, given the difficulty of training a robust
classifier for CIFAR-100 with 60% label noise, it is worth mentioning that SCL can achieve similar
performance as GLC that is given 10% of trusted data in case of 30% symmetric noise. This also
indicates the effectiveness of symmetric cross entropy in learning hard classes even without trusted
7
Under review as a conference paper at ICLR 2021
data. However, when facing extremely noisy labels and patterns, the small amount of trusted data can
greatly improve the robustness of the classifier but not necessarily the symmetric cross entropy.
Seen from the high accuracy compared to GLC and SCL, GSL effectively uses the trusted data to
correct symmetric cross entropy loss and improve the learning on the hard classes. GSL performs
slightly better with symmetric noise than with bimodal and flip noise that is more challenging for
CIFAR-10. In the CIFAR-100, GSL works better on the asymmetric noise rather than symmetric.
For Clothing1M dataset, as shown in Table 1, GSL obtains the highest test accuracy compared
to other methods. Same as CIFAR-10 and CIFAR-100, s gForward achieves a relatively good
performance. The difference between GSL and SCL comes from the effectiveness of corruption
matrix that makes the regular cross entropy robust.
Table 2: Text analysis: average accuracy (%) of variants combining loss correction and symmetric
cross entropy. Results averaged across entire range of noise rates [0, 100]. Best accuracy in bold.
	Noise	Percent	GSL GLC	gForward	TMatrix	sgForward	sTMatrix
	Pattern	Trusted					
	Sym.	1	79.27 66.46	53.36	76.69	78.76	78.95
	Sym.	5	81.85 77.18_	_ _ 59,47_ _	_ _ 79,86_ _		8124 _ _	_ _ J1.30_ _
	Bimodal	1——	'75774 — 67.05^	——52772"一	——77.92- 一	75.64 ——	——76.64
	Bimodal	5	84.14	78.39_	_ _ 60,57_ _	_ _ 80,87_ _		80,30 _ _	_ _ J0.39_ _
	^ ^ Flip"—	1——	'75752 ^ 83.2Γ	——3歹37— 一	——86.21- 一	73.83 ——	——73.30
	Flip	5	80.35 85.81	48.64	86.34	79.79	80.07
	Sym.	0.1	74.38 73.21	7220~~	73.73	72.20	73.84
	Sym.		75.89 _ 72.88_	_ _ 73,40_ _	_ _ 75,39_ _		72,89 _ _	_ _ 75.12_ _
H S S	Bimodal	0 ^0.Γ 一	'74.81 — 74.80^	——72777 ^ 一	——74.07^ 一	72.73 ——	——74.06
	Bimodal		74.66 _ 74.61_	_ _ 72,07_ _	_ _ 74,24_ _		71.76 _ _	_ _ 73.90_ _
	^ ^ Flip"—	0 ^0.Γ 一	'7531 — 74.13—	——49748 ^ 一	——74.88- 一	49.47 ——	——74.95
	Flip	1	76.44 74.59	50.29	76.27	49.81	75.76
6.1.1 Text Analysis
We evaluate GSL on text datasets of Twitter and SST, against resilient networks that leverage
corruption matrix, namely GLC and Forward. Both GSL and GLC use the trusted data for
estimating the corruption matrix, wheres the original Forward (Patrini et al., 2017) relies solely
on the noisy data. As the proposed loss of golden symmetric cross entropy is general and can be
combined with different resilient networks, we hence use following four variations of loss correction
and symmetric cross entropy on the existing work:
•	Forward gold (GFORWARD): we replace the estimation of the corruption matrix by the identity
matrix on trusted samples and apply loss correction through the confusion matrix.
•	True corruption matrix (TMATRIX): we directly use the true corruption matrix and apply loss
correction through it.
•	Forward gold with symmetric cross entropy (S GFORWARD): we extend the corrected loss of
gForward to the corrected symmetric cross entropy as in the GSL.
•	True corruption with symmetric cross entropy (STMATRIX): we apply golden symmetric cross
entropy and the true corruption matrix instead of the estimated matrix.
We extensively evaluate GSL, GLC gForward, TMatrix, s gForward, and sTMatrix on
Twitter and SST, with label corruption ranging from 0% to 100%. We also vary the percentage of
trusted data among 1% and 5%. We summarize the average accuracy across 11 noise rates in Table 2.
Twitter. GSL consistently achieves the highest average accuracy in most cases. Compared to GLC,
GSL has significant higher accuracy for Twitter corrupted with symmetric and bimodal noises, but
the difference diminishes with increasing amounts of trusted data. When the percent of trusted data is
low, say, 1%, GLC is unable to estimate the corruption matrix accurately nor to correct the loss, seen
by the difference between GLC and TMatrix.
SST. Here, the classification involves only two classes and turns out to be less challenging than the
Twitter case. The difference among the different comparative approaches considered is smaller than
8
Under review as a conference paper at ICLR 2021
for Twitter. For instance, though GSL consistently achieves the best average accuracy in almost
all cases, the difference between GSL and GLC is around 1-3%. Again, we see that GSL visibly
outperforms GLC on low amounts of trusted data because of using cross entropy and the difference
among them becomes limited. We note that TMatrix and gForward collapse under Flip noise.
7	Conclusion
To enhance the robustness of deep models against by label noise, we propose GSL that features on
correcting the symmetric cross entropy loss by the noise corruption matrix. GSL uses a small fraction
of trusted data to accurately estimate the corruption matrix, and further determine the weights applied
on regular and reverse cross entropy. GSL learns deep networks from trusted samples through regular
cross entropy and from untrusted noisy samples through golden symmetric cross entropy. We prove
that the cross entropy corrected by the corruption matrix is noise robust. To adapt to noise patterns of
dataset, we heuristically set the weights of golden symmetric loss based on the corruption matrix.
We extensively evaluate GSL on vision and text analysis under diversified noise rates and patterns.
Evaluation results show that GSL can achieve a remarkable accuracy improvement, i.e., from 2 to
18% on CIFAR benchmarks and real world noisy data, compared to methods that either correct loss
or leverage symmetric cross entropy.
References
Pengfei Chen, Benben Liao, Guangyong Chen, and Shengyu Zhang. Understanding and utilizing
deep neural networks trained with noisy labels. In ICML, pp.1062-1070, 2019.
Aritra Ghosh, Himanshu Kumar, and P. S. Sastry. Robust loss functions under label noise for deep
neural networks. In AAAI, pp. 1919-1925, 2017.
Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein,
Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A Smith. Part-of-speech tagging
for twitter: Annotation, features, and experiments. In ACL, pp. 42-47, 2011.
Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. In ICLR, 2015.
Bo Han, Jiangchao Yao, Gang Niu, Mingyuan Zhou, Ivor W. Tsang, Ya Zhang, and Masashi Sugiyama.
Masking: A new perspective of noisy supervision. In NeurIPs, pp. 5841-5851, 2018a.
Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi
Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. In
NeurIPS, pp. 8527-8537, 2018b.
Dan Hendrycks, Mantas Mazeika, Duncan Wilson, and Kevin Gimpel. Using trusted data to train
deep networks on labels corrupted by severe noise. In NeurIPS, pp. 10456-10465, 2018.
Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. Mentornet: Learning data-
driven curriculum for very deep neural networks on corrupted labels. In ICML, pp. 2309-2318,
2018.
Nikola Konstantinov and Christoph Lampert. Robust learning from untrusted sources. In ICML,
volume 97, pp. 3488-3498, 2019.
Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10/100 (Canadian Institute for Advanced
Research). 2009. URL http://www.cs.toronto.edu/~kriz/cifar.html.
Junnan Li, Richard Socher, and Steven C.H. Hoi. Dividemix: Learning with noisy labels as semi-
supervised learning. In ICLR, 2020.
Yuncheng Li, Jianchao Yang, Yale Song, Liangliang Cao, Jiebo Luo, and Li-Jia Li. Learning from
noisy labels with distillation. In IEEE International Conference on Computer Vision ICCV, pp.
1928-1936, 2017.
Ilya Loshchilov and Frank Hutter. SGDR: stochastic gradient descent with warm restarts. In ICLR.
9
Under review as a conference paper at ICLR 2021
Xingjun Ma, Yisen Wang, Michael E. Houle, Shuo Zhou, Sarah M. Erfani, Shu-Tao Xia, Sudanthi
N. R. Wijewickrema, and James Bailey. Dimensionality-driven learning with noisy labels. In
ICML,pp. 3361-3370, 2018.
Eran Malach and Shai Shalev-Shwartz. Decoupling” when to update” from” how to update”. In
NeurIPS, pp. 960-970, 2017.
N. Manwani and P. S. Sastry. Noise tolerance under risk minimization. IEEE Transactions on
Cybernetics, 43(3):1146-1151, 2013. doi: 10.1109/TSMCB.2012.2223460.
Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making
deep neural networks robust to label noise: A loss correction approach. In IEEE CVPR, pp.
1944-1952, 2017.
Scott E. Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew
Rabinovich. Training deep neural networks on noisy labels with bootstrapping. In ICLR 2015,
Workshop Track Proceedings.
Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples for
robust deep learning. ICML, 2018a.
Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples for
robust deep learning. In ICML, pp. 4331-4340, 2018b.
Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou, Zongben Xu, and Deyu Meng. Meta-weight-
net: Learning an explicit mapping for sample weighting. In NIPS, pp. 1919-1930, 2019.
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng,
and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment
treebank. In conference on empirical methods in natural language processing, pp. 1631-1642,
2013.
Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, and Kiyoharu Aizawa. Joint optimization framework
for learning with noisy labels. In IEEE CVPR, pp. 5552-5560, 2018.
Arash Vahdat. Toward robustness against label noise in training deep discriminative neural networks.
In NeurIPS, pp. 5596-5605, 2017.
Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin, Abhinav Gupta, and Serge J. Belongie.
Learning from noisy large-scale datasets with minimal supervision. In CVPR, pp. 6575-6583,
2017.
Yisen Wang, Weiyang Liu, Xingjun Ma, James Bailey, Hongyuan Zha, Le Song, and Shu-Tao Xia.
Iterative learning with open-set noisy labels. In IEEE CVPR, pp. 8688-8696, 2018.
Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey. Symmetric cross
entropy for robust learning with noisy labels. In IEEE ICCV, pp. 322-330, 2019.
Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive noisy
labeled data for image classification. In IEEE CVPR, pp. 2691-2699, 2015.
Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor W Tsang, and Masashi Sugiyama. How does
disagreement help generalization against label corruption? In ICML, pp. 7164-7173, 2019.
Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. In Proceedings of the British
Machine Vision Conference 2016, BMVC 2016, York, UK, September 19-22, 2016, 2016.
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. In ICLR, 2017.
Zhilu Zhang and Mert R. Sabuncu. Generalized cross entropy loss for training deep neural networks
with noisy labels. In NeurIPS, pp. 8792-8802, 2018.
10
Under review as a conference paper at ICLR 2021
Table 3: Accuracy (%) of different gold fraction on CIFAR-10
Noise rate = 30%									
Label correction	Bimodal			Symmetric			Flip		
	5%	10%	15%	5%	10%	15%	5%	10%	15%
ce only	90.06	91.50	92.53	90.17	91.70	92.50	89.96	91.27	92.58
rce only	84.67	88.46	89.30	84.82	88.11	89.98	81.70	86.79	88.40
both	83.25	87.45	89.30	83.43	87.70	89.46	78.00	85.42	88.21
Noise rate = 60%									
Label correction	Bimodal			Symmetric			Flip		
	5%	10%	15%	5%	10%	15%	5%	10%	15%
ce only	83.06	88.43	90.52	85.79	89.19	90.19	80.03	82.64	85.80
rce only	81.73	86.86	89.07	81.54	86.63	88.98	68.29	80.22	84.35
both	79.83	85.79	88.63	80.27	86.22	88.53	63.63	82.19	83.18
Table 4: Accuracy (%) of different gold fraction on CIFAR-100
Noise rate = 30%									
Label correction	Bimodal			Symmetric			Flip		
	5%	10%	15%	5%	10%	15%	5%	10%	15%
ce only	71.66	73.90	75.20	71.69	74.24	75.11	74.78	75.46	77.01
rce only	25.90	61.44	67.15	26.15	61.19	67.14	23.75	59.68	65.33
both	23.37	57.52	64.30	23.58	57.36	63.76	19.74	54.50	61.20
Noise rate = 60%									
Label correction	Bimodal			Symmetric			Flip		
	5%	10%	15%	5%	10%	15%	5%	10%	15%
ce only	58.42	66.96	69.41	55.22	66.87	69.46	65.20	68.33	70.41
rce only	54.35	67.24	69.41	24.90	58.72	64.39	14.43	46.09	68.75
both	24.35	55.18	61.19	25.62	55.16	61.46	12.46	36.76	50.83
Appendix
A	Training with Corrected Labels: Vision Results
Here we present the extensive results of our empirical evaluation on training with corrected labels
for the vision datasets. This complements the results presented in §3. We compare the impact of
correcting labels only on the cross entropy term (ce only), only on the reverse cross entropy term
(rce only), or both. Table 3 and Table 4 show the achieved accuracy for CIFAR-10 and CIFAR-100,
respectively, under two noise rates, 30% and 60%, three different noise types, symmetric, bimodal
and flip, and three fractions of trusted data, 5%, 10% and 15%. For each noise scenario the best case is
highlighted in bold. ce only achieves the highest accuracy in all cases except one. Under 60% bimodal
noise on CIFAR-100 with 10% trusted data rce only is slightly better by 0.28 percent points. More in
general, rce only typically performs second best and both achieves the worst accuracy. Focusing on
ce only over the other two, the gain tends to increase with the difficulty of the noise scenarios, i.e.
with higher number of classes, higher noise rates and less trusted data. ce only outperforms the other
two by up to 11.74 percent points for CIFAR-10 and up to 51.03 percent points for CIFAR-100.
B Text Analysis on Twitter and SST Datasets with Varying Noise
Rates
Figure 4 shows how the accuracy changes with respect to different noise rates on the Twitter and
SST datasets. GSL and GLC are provided with one percent trusted data. In contrast, GSL can
effectively use the symmetric cross entropy to overcome the limitation of low trusted data. This also
explains why sTMatrix always trails closely behind GSL by using the true confusion matrix and
symmetric entropy loss. One may further improve STMATRIX by using the optimal weights of A
11
Under review as a conference paper at ICLR 2021
and B according to the true corruption matrix, instead of estimated corruption matrix of GSL. The
Twitter dataset highlights well the differences (see Figure 4a). The SST dataset is an easier problem
with only two classes and all methods are able to perform equally well (see Figure 4b).
Qoooo
0 8 6 4 2
1
GLC
——gForward
---TMatrix
——SgForward
---STMatrix
Qoooo
0 8 6 4 2
>UE⊃uura ⅛ΦH
20	40	60	80	100
Noise ratio
(a) Twitter
20	40	60	80	100
Noise ratio
(b) SST
Figure 4: Testing accuracy on text datasets with varying noise rates (1% trusted data).
C Proof of Robustness of Cross Entropy Loss with Label
Correction Theorem 4.1
Theorem 4.1. In a multi-class classification problem, 'ce with prediction correction is noise tolerant
under symmetric label noise ifthe noise rate ε < tjK-∆A, where ∆A = PK=I 'ce(C*Tf (x),k) —
K- ∆R	=
PK=I 'ce(CTf (x), k), and ∆R is the difference of risk minimization between optimal classifier
and f. And 'ce with prediction correction is also noise tolerant under flip noise when noise rate
εyk ≤ (1 + ∆Wy ) — εy (1 + ∆Wy ) where εk and εyk are the correct and flipped class probabilities,
respectively.
Proof. For symmetric noise:
Rε(f, C) = Eχ,y'ce(CTf (x), y) = EχEy∣χEy∣χ,y'ce(CTf (x), y)
=Eχ,y [(1 — ε)'ce(CTf (x), y) + K-1 X /CT f(χ), k))]
k6=y
K
=Eχ,y [(1 — ε)'ce(CT f (x), y) + K-1 X 'ce(CTf (x), k) — 'ce(CT f (x),y))]
k=1
K
=(1 — ε)R(f (x, C) + K-I(X 'ce(CTf(x), k) — R(f,C))
k=1
εK ε K
=R(f, C)(1 —	) +	(E'ce(CTf (x),k))
K— 1 K— 1
k=1
(7)
Let A(CTf (x), y) = PK=I 'ce(CTf(x),k). Then We Can rewrite (7) as Rε(f, C) = (1 —
KK )R(f, C) + K- A(C Tf (x), y),thus:
Rε(f *, C*) — Rε(f, C) = (1 - -- )(R(f *, C*) — R(f, C))
K — 1 '-----------{z--------}
∆R
+ √-τ (A(C*Tf*(x),y) - A(CTf (x),y))
K — 1 ×---------------{z--------------}
∆A
12
Under review as a conference paper at ICLR 2021
where ∆R ≤ 0, because f * is the global minimizer for R and C * the optimal noise confusion matrix.
Similarly, ∆A ≤ 0 because for the optimal case we can say A(C*Tf *(x), y) ≈ 0. 'ce with label
correction is robust to noise when Rε(f *, C*) - Rε(f, C) ≤ 0. This is true when:
εK	ε
Rε(f *, C*) — Rε(f, C) = (I- K-I)∆R + K-I∆A
=∆R	εK	ε	∆R≤0 -E δr + K-I δa≤ 0==⇒
1-	^K- +	AA ≥ 0⇒ K - 1 + K - 1 ∆R ≥
1≥	ε	∆A K-I(K- ∆R)⇒
ε≤
K - I
K - ∆A
(9)
With no label correction, C is missing in ∆A and the two terms become equal, i.e. ∆A = 0. In this
condition the bound becomes ε < KK1 as found by (Ghosh et al., 2017) for cross-entropy without
label correction. Since Δrr ≥ 0, ε < K-1 ≤ j-A the new bound can be seen as generalization of
∆R
the previous bound. ∆A should also be less than one to ensure a meaningful bound on ε, avoiding
scenarios of noise rate greater than 1.
For asymmetric flip noise, I - εy is the probability of a label being correct (i.e., k = y), and the noise
condition εyk < I - εy generally states that a sample x has a higher probability (I - εy) of being
classified correctly as class y, rather than the probability (εyk) of being classified incorrectly as class
k 6= y.
Rε(f, C) = Eχ,y'ce(CT f (x), y) = EχEy∣χEy∣χ,y'ce(CT f (x), y)
=Eχ,y [(1 - εy )'ce(C T f(χ),y) + X εyk 'ce (C T f(x),k)]
k6=y
K
=Ex,y[(1-εy)(X'ce(CTf(x),k)-X'ce(CTf(x),y))+Xεyk'ce(CTf(x),k)]
k=1	k6=y	k6=y
K
= Ex,y[(1 - εy) X 'ce(CT f(x), k) + X(1 - εy - εyk)'ce(CT f(x), k)]
k=1	k6=y	(10)
Similar to the symmetric case We require that Rε(f *, C*) - Rε(f, C) ≤ 0 for the loss to be robust
to noise:
Rε(f *, C *) — Rε(f,C) = Eχ,y [(1 — εy )(X 'ce(C*T f *(χ),k),-噎(CT f (x),k))
k=1	ʌw	'
+ X(1 - εy - εyk ) 'ce(C*T f *(x),k) - 'ce(CT f(x),k)] ≤ 0
k=y	∆Wk
(11)
13
Under review as a conference paper at ICLR 2021
where ∆Wy ≤ 0 and ∆Wk ≤ 0 because C * is the optimal noise confusion matrix. Rewriting (11):
	K Eχ,y [X(1 - Sy )∆Wy + X Syk ∆W k ] ≤ 0⇒ k=1	k=y K X(I-Sy )∆Wy + χ(1 - Sy - Syk)∆Wk ≤ 0 ⇒ ∆Wy - Sy ∆Wy ≤ - ∆W k + Sy ∆W k + Syk ∆W k ^^	() 柒-U ≥-ι + Sy + Syk ⇒ ZWy - Sy(以y + 1) ≥Syk-1
According to (12), the bound is εyk ≤ (1 + ^WWy) - £y(ι + ^WWy). With no label correction
∆Wy 二	0 0 and the bound becomes Syk < 1 - Sy as found by prior art.
□
14