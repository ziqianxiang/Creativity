Under review as a conference paper at ICLR 2021
Robust Learning for Congestion-Aware Rout-
ING
Anonymous authors
Paper under double-blind review
Ab stract
We consider the problem of routing users through a network with unknown con-
gestion functions over an infinite time horizon. On each time step t, the algorithm
receives a routing request and must select a valid path. For each edge e in the se-
lected path, the algorithm incurs a cost cte = fe (xte) + ηet, where xte is the flow on
edge e at time t, fe is the congestion function, and ηet is a noise sample drawn from
an unknown distribution. The algorithm observes cte , and can use this observation
in future routing decisions. The routing requests are supplied adversarially.
We present an algorithm with cumulative regret O(|E|t2/3), where the regret on
each time step is defined as the difference between the total cost incurred by our
chosen path and the minimum cost among all valid paths. Our algorithm has
space complexity O(|E|t1/3) and time complexity O(|E| log t). We also validate
our algorithm empirically using graphs from New York City road networks.
1	Introduction
Modern navigation applications such as Google Maps and Apple Maps are critical tools in large
scale mobility solutions that route billions of users from their source to their destination. In order to
be effective, the application should be able to accurately estimate the time required to traverse each
road segment (edge) along the user route in the road network (graph): we call this the cost of the
edge. In general, the cost of an edge also depends on the current traffic level (the flow) on the edge.
Furthermore, costs may scale differently on different edges: a highway can tolerate more traffic than
a small residential street. We model this using congestion functions that map traffic flows to edge
costs.
Usually, cost information is not readily available to the routing engine and can only be inferred
indirectly. For example, this can be done using location pings from vehicles, or with loop detectors
that record when vehicles cross a particular marker. All realistic methods of measuring the cost of an
edge (such as those above) require the presence of a vehicle that reports this information back to the
routing platform. In this paper, we assume that whenever a vehicle traverses an edge, we observe the
time spent on the edge. We can then use this observation in future routing decisions. This induces
a natural exploration/exploitation trade-off: we may wish to send vehicles on underexplored routes,
even if those routes currently seem suboptimal.
In this paper, we propose a learning model for congestion-aware routing, and present an algorithm
which seeks to minimize the total driving time across all vehicles. Our algorithm applies to arbitrary
networks and arbitrary (Lipschitz-continuous) congestion functions, even when observations are
noisy. The algorithm is also robust to changes in traffic conditions in a strong sense: we show that
even when request endpoints are chosen adversarially and even when traffic congestion on the edges
is updated adversarially between requests, our algorithm learns an optimal routing policy.
1.1	Model
Consider a directed graph (V, E). Each edge e has a deterministic and fixed (but unknown) conges-
tion function fe : R≥0 → R≥0. We assume each fe is L-Lipschitz continuous and nondecreasing,
with L known. For simplicity, we also assume that fe(0) = 0 for all e ∈ E (if not, we can simply
translate and extend the function appropriately).
1
Under review as a conference paper at ICLR 2021
We consider an infinite horizon of time steps, starting from t = 0. At each time t, a new car arrives.
An adversary tells us the current amount of flow on each edge, and the source and destination of the
new car. Let xte be the flow on edge e at time t and let Pt be the set of paths between the source and
destination for the time t arrival. Let xtmax = maxe,t xte. We must choose how to route the car, i.e.,
we must select a path pt ∈ Pt. Based on our choice ofpt, we incur a cost based on the flow and the
congestion functions on the edges in our chosen path:
ct = X fe (xte)
e∈pt
For each e ∈ pt, we observe cte = fe (xte) + ηet , where ηet is a random variable with expectation 0.
The distribution of ηet is unknown, and can vary between edges and time steps. The distributions can
be correlated across edges, as long as for a given edge, all the individual samples (i.e., ηe1 , ηe2, . . . )
are independent. We assume that there exists β such that ηt ∈ [-β∕2, β∕2] for all edges e and times
t, and that β (or an upper bound on β) is known.
The optimal cost at time t is
Ct = min X fe(Xe)
p∈Pt
e∈p
so the regret of our algorithm over the first t time steps is
t
Rt = X E[Ct - Ctt]
r=1
where the expectation is over the randomness in the noise samples. Note also that we do not include
the noise we observe in the objective function, since the noise has expectation 0.
Any algorithm with sublinear regret can be said to learn an optimal routing policy: if Rt = o(t),
then E[Ct - Ctt] must shrink as t goes to infinity, i.e., the difference between our algorithm’s cost and
the optimal cost must go to 0 on average.1 In this paper, We give an algorithm with regret O(t2/3).
1.2	Our contribution
Our main result is the following theorem:
Theorem 1.1. The expected regret of Algorithm 1 after t time steps is
Rt = o (t2/3 ∙ |E| log XmaxGepIogt + XmaxL))
The space complexity and time complexity on time step tare O(|E|t1/3 log xtmax) andO |E|(log t+
log log Xtmax) + SP(|E|, |V |) , respectively.
Here SP(|E|, |V |) denotes the time complexity of computing the shortest path between two vertices
in a graph with nonnegative weights. For example, this can be done by Dijkstra’s algorithm in time
O(|E|+VlogV).
We also validate our algorithm’s performance using graphs from New York City road networks.
1.3 Related work
Comparison with multi-armed bandits. Perhaps the simplest model of exploration vs exploita-
tion is the classical multi-armed bandit (MAB) problem (Slivkins, 2019). A MAB instance consists
of n arms, each with an unknown but fixed distribution. At each time step, the algorithm selects
an arm and observes a reward drawn randomly from that arm’s distribution. Several algorithms ob-
taining regret O(√t) are known, and this is also known to be the best possible, UP to logarithmic
factors.
1Note that E[ct - c" may not monotonically decrease: a sublinear regret algorithm can still incur large
errors sporadically, as long as the the frequency of the large errors goes to 0.
2
Under review as a conference paper at ICLR 2021
Our routing model generalizes the MAB problem. In particular, when the graph consists ofn parallel
edges, the congestion functions are constant, and each edge has a single fixed noise distribution, our
model reduces to the MAB problem: each edge is an arm, and the reward distribution for each edge
is (the negative of) the congestion constant plus the noise distribution. Our model can be thought of
as extending the MAB problem to the case where (1) each reward distribution has a parameter (in
our case, the flow), and (2) the arms are edges in an arbitrary graph and their usage is constrained
according to paths in the graph. We believe that routing is the most natural application of this model,
but there could be other applications as well.
Since our problem is strictly harder than the MAB problem, we know that regret o( ʌ/t) is impossible.
We conjecture that even regret Θ(√t) is impossible for our problem, but leave this as an open
question.
Comparison with other routing work. Our work is also related to the body of literature on short-
est paths under uncertainty, in which it is typically assumed that edge lengths follow known inde-
pendent distributions. A canonical problem is to find an s-t path whose length is below a threshold
L with highest probability. When the edge length distributions are Gaussian, Nikolova et al. (2006)
present a quasi-polynomial time algorithm for this problem via connections to quasi-convex maxi-
mization. A related probing problem is the Canadian Traveler Problem (Nikolova & Karger, 2008;
Papadimitriou & Yannakakis, 1991), where the length of an edge is revealed when we reach one of
its end-points and the goal is to minimize the expected cost. There are no efficient algorithms known
for this problem, except under special assumptions such as no backtracking (Bnaya et al., 2009).
Awerbuch & Kleinberg (2004) study a conceptually similar adaptive routing problem. In their ver-
sion, there is no noise in the observations, but the algorithm observes only the total cost of the
path, and not the cost of each individual edge. Their model also does not have the same notion
of a parametrized congestion function. Although their model is technically distinct from ours, it is
noteworthy that they also obtain a regret bound of O(t2/3). A number of subsequent works have
also sought to apply bandit algorithms to shortest path selection problems in the domain of network
signal routing (Chen & Ji, 2005; GyOrgy et al., 2007; Liu & Zhao, 2012; Zou et al., 2014; Talebi
et al., 2018). Moreover, there is a long line of other works broadly dealing with regret minimization
in Internet routing and congestion control settings (Dong et al., 2015; 2018; Jiang et al., 2016; 2017;
Talebi et al., 2018).
Similar works apply bandit algorithms to shortest path selection have also been applied to traffic
route planning (Chorus, 2010; de Oliveira Ramos et al., 2017). However, these works differ from
ours in that they do not consider the more general congestion functions that we consider in our
model. A more recent work (Zhou et al., 2019) considers a similar routing problem, labeled the
Multi-Armed Bandit On-Time Arrival Problem. In this setting, regret is quantified in terms of on-
time arrival reliability, and the arms are joint route and departure times. Kveton et al. (2014) also
study (among other applications) a routing setting in the context of matroid bandits, but this work
also assumes static edge costs and does not factor in congestion.
Routing in the presence of congestion functions has been studied in the context of selfish routing
Roughgarden & Tardos (2002) and in the atomic congestion games setting Awerbuch et al. (2005);
Christodoulou & Koutsoupias (2005). The difference from our setting is that the congestion games
model and selfish routing models assume drivers have full information about the costs in the network
and route themselves on an optimal path. In our setting costs are learned as time progresses and there
is a centralized routing control as given by navigation applications.
2	Description of the algorithm
In this section, we define and give intuition for our algorithm for learning an optimal routing policy.
2.1	Intuition behind the algorithm
On each step, the algorithm uses past observations to form an estimate for the cost of each edge
at the current flow, i.e., an estimate for fe (xte). It then selects the shortest path according to these
estimated costs.
3
Under review as a conference paper at ICLR 2021
The heart of the algorithm is the cost estimation scheme. There are two sources of error in this
estimation: we may not have observed this exact flow before (type 1 error), and noise (type 2 error).
For type 1 error, suppose all the observations we use are based on flows y such that |y - xte | ≤ ε.
Then Lipschitz continuity implies that |fe(y) - fe(xte)| ≤ εL, and so if ε is small, this aspect of our
estimation should be accurate.
However, we do not actually observe fe(y): instead, we observe fe (y) + ηy, where ηy is a random
noise term with expectation 0. Even if we have observed the exact flow xte before, this noise will
prevent us from having a perfect estimate. However, the more observations we use to form our
estimate, the less impact the noise has: we can use Hoeffding’s Inequality to show that | Py ηy |
goes to 0 quickly as the number of observations grows, and thus our type 2 error shrinks. But as
we increase the number of observed flows y that we use (for a fixed time step), we also (in general)
increase the maximum distance maxy |y - xte|. Concretely, if k(ε, x) is the number of observations
based on flows within ε ofx, then k(ε, x) is weakly increasing with ε. This is diametrically opposed
to our plan for the type 1 error.
In order for the average error to approach 0 as t increases, we will have to carefully manage this
tradeoff. We will need to ensure that the number of observations we use for estimation tends to
infinity, but also that the maximum distance tends to 0. Intuitively, this should be possible: if
observations are somewhat uniformly distributed across edges and across the flow spectrum, then
We should have Θ(t) observations per edge and Θ(tε/Xmax) observations on every interval of size ε
(treating |E| asaconstant here). Setting ε to be something like Θ(t-1/2) would lead to Θ( ʌ/t/Xmax)
observations being used for each estimation with a maximum distance of Θ(t-1/2), which fits our
requirements.
Observations are of course not guaranteed to be uniform, and can even be adversarial. For example,
suppose we have observed many flows less than 1 on some edge e, but no flows above 1. When
estimating the cost of a flow less than 1, we are in good shape (if those observations are uniformly
distributed, say). But suppose we are asked to estimate the cost for flow 2: we may incur a large
estimation error, since we have no information about that portion of the flow spectrum.
But our lack of information also implies that so far we have not incurred any error in that part of the
flow spectrum, since we have never used it! The more we use part of the flow spectrum on a given
edge (i.e., our chosen path used that edge at a flow in that range), the more error we incur, but the
more we learn. Thus we will need an analysis that is decomposable across edges and across the flow
spectrum: for each interval I, we need to bound our cumulative error over all estimation queries that
fall within that interval as a function of the length of the interval and the number of such queries.
There is one more complicating factor: what if we consistently overestimate the cost of a particular
flow, so that we never use it? Then we may repeatedly incur a large error from that flow, without
ever learning about it. For this reason, we will want to ensure that with high likelihood, all of our
estimates are underestimates: this will allow us to bound the regret on a given time step in terms of
the estimation error only on edges in the path that we used.
2.2	Our cost estimation scheme
The cost estimation works roughly as follows. The algorithm maintains a “bucketing” system for
each edge, inspired by hashtables. The interval [0, Xte,max] is partitioned into a set of intervals, with
each interval being a “bucket”. Whenever we observe a new flow, we identify which bucket that
flow falls into, and use all the observations in that bucket to estimate the cost. (We also subtract a
term proportional to √log t in order to ensure that we get an underestimate with high probability;
this is similar to the Upper Confidence Bound algorithm for multi-armed bandits.) We then observe
the resulting cost for this flow (for this edge), and insert it into the bucket. If we observe a flow that
falls outside of our bucketing system, we create a new depth 0 bucket so that the observed flow falls
into our new bucket.
If the number of elements in the bucket surpasses a certain threshold, we split it into two new buckets
(whose associated intervals are equal length). The threshold depends on the depth (i.e., how many
times one of its ancestors was split). We denote the “lifetime” of a bucket at depth m by and we
denote it by h(m). Our analysis will be “decomposable” across buckets: we will bound the total
error any single bucket of depth m can contribute over the course of its lifetime.
4
Under review as a conference paper at ICLR 2021
Let bte be the bucket we used for estimating the cost of edge e at time t. The smaller the interval
associated with this bte, the smaller the error of type 1: if our estimation only uses observed flows y
within this interval, and the interval has length ε, then the type 1 error is at most εL, since our target
flow xte is also in the interval. This incentivizes us to make h(m) small, so that we can more quickly
we get to buckets with small interval lengths. If we only cared about type 1 error (i.e., if there were
no noise) choosing h(m) = 1 would be optimal.
On the other hand, the more observations stored in bte, the smaller type 2 error. This incentivizes us
to make h(m) large, so that each bucket contains a large number of observations for a larger portion
of its lifetime. If we only cared about type 2 error (i.e., if fe were constant), choosing h(m) = ∞
would be optimal. This is exactly the tradeoff we discussed in Section 2.1. Eventually, h(m) = 22m
will give us the best regret bound.
2.3	Defining the algorithm
Algorithm 1 provides pseudocode for our algorithm. We use Be to denote the entire bucketing
system for edge e. We treat Be as a set, whose elements are “buckets”. Each bucket b supports the
following operations:
|b| → returns the number of (flow, cost) pairs stored in b
dom(b) → returns the interval [w, z] ⊆ [0, K] associated with b
depth(b) → returns the depth of bucket b
estimate(b) → returns the cost estimate based on the current observations stored in b
create(m, [w, z]) → returns a new empty bucket b with dom(b) = [w, z] and depth(b) = m
INSERT(b, (y, cy)) → inserts the flow y and its associated observed cost cy into b
The first four operations will simply be numerical fields stored in b. We also assume that the create
operation takes constant time and space, and that the aforementioned four fields are initialized ap-
propriately (estimate(b) should be 0). However, we will need to implement INSERT ourselves in
order to ensure that it is done in an efficient fashion (hence the differing font). In general, we will
reserve the variables w, z for dom(b), y for arbitrary elements of b, and x = xte for the proposed
flow on the current time step.
To limit space usage, we will not actually “store” each relevant observation in the bucket; instead,
we will simply incorporate it into the estimate field that we store. However, in the analysis, it will
be useful to use “y ∈ b” to denote that a particular observation (y, cy) has been used in that bucket.
For each y ∈ b, let ηy denote the noise sample associated with this observation. Note that ηy is not
known to the algorithm; we will simply use this notation in our analysis. Also, let len(dom(b))
denote the length of the domain, i.e., z - w if dom(b) = [w, z].
We can think of the bucketing system in terms of binary trees. Each bucket of depth 0 is a “root”,
and whenever we split a bucket, we create two “children”. Thus Be is essentially a forest of binary
trees, where each node represents a bucket. Any bucket b ∈ Be has exactly one ancestor of depth 0.
3	Experiments
In this section, we empirically validate the algorithm’s performance on graphs from New York City
road networks. We first describe the methodology, and then reflect on the results.
3.1	Methodology
We used two different graphs, corresponding to different regions within New York City. Graph
1 consisted of 303 vertices and 657 edges, and Graph 2 consisted of 429 vertices and 1204
edges.Congestion functions with domain [0, 1] were generated randomly for each run of the al-
gorithm, with each congestion function consisting of three pieces of slope chosen uniformly from
[0, 1]. Uniform noise distributions were used for all runs, with varying values of β. The algorithm
was initialized with L = 1 and α = 2β2 . On each time step, the following steps were performed:
1.	Independently sample a uniformly random flow xte in [0, 1] for each edge e.
5
Under review as a conference paper at ICLR 2021
Algorithm 1 Algorithm for learning an optimal social routing policy.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
function ROUTINGALGORITHM(E, L, α, h)
for each e ∈ E do
Be J {create(0, [0,1])} . Start with a single bucket of depth 0 and constant length
for each t ∈ N>0 do
xte J proposed flow on edge e
for each e ∈ E do
ute J ESTIMATEEDGECOST(xte, Be, L, α)
pt J arg minp∈Pt Pe∈p ute
selectRoute(pt), observe cost cte ∀e ∈ pt
for each e ∈ pt do
UPDATEBUCKETS(xte, Be, cte, h)
1:	function ESTIMATEEDGECOST(x, B, L, α, t)
2:	if ∃b ∈ B s.t. X ∈ dom(b) and |b| > 0 then
3:	return max(0, estimate(b) 一，|b|-1 lnta)
4:	else
5:	return 0
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
1:
2:
3:
4:
5:
6:
7:
8:
function UPDATEBUCKETS(y, cy , B, h)
if ∃b ∈ B s.t. y ∈ dom(b) then	. Insert our observation into the corresponding bucket
INSERT(b, (y, cy))
m J depth(b)
if |b| > h(m) then	. Split the bucket ifit is too big
[w, z] J dom(b)
bi J Create(m + 1, [w, w+z])
b2 J Create(m + 1, [w+z, z])
INSERT(b1, (y, cy)) . Insert the observation into new buckets so they aren’t empty.
INSERT(b2, (y, cy))	. Type 1 error is still proportional to the domain lengths.
Be J (Be \ b) ∪{bl}∪{b2}
else	. This flow does not fall into any bucket: create a new depth 0 bucket
ymax J max ∪b∈Be dom(b)
b J Create 0, [ym
ax, 2x]
Be J Be ∪ {b}
function INSERT(b, (y, cy))
[w, z] J dom(b)
if y < w then	. y 6∈ dom(b) is possible if we created b on this time step
uy = cy
else
uy = cy - L(y - w)
|b| ∙ estimate(b) + Uy
estimate(b) J-----------------------
|b| + 1
|b|J|b|+1
. This is a running average of {uy : y ∈ b}
2.	Independently sample a uniformly random noise term ηt ∈ [-β∕2, β∕2] for each edge e.
3.	Independently sample a uniformly random source and destination from the graph.
4.	Compute the path chosen pt chosen by our algorithm.
5.	Compute Ct-Ct = P,e∈pt fe (xe)-minp∈Pt Pe∈p fe(xe) and record the cumulative regret
Rt.
Each run was characterized by the following parameters:
1.	Time horizon (either 100,000 or 1,000,000)
2.	The graph used (Graph 1 or Graph 2)
6
Under review as a conference paper at ICLR 2021
3.	The noise parameter β ∈ {0, .01, .02, .05, .1, .2, .5}.2
Figure 1 shows the results of all runs.
3.2 Results
All runs of the algorithm display the general behavior we would hope to see: concavity of the
cumulative regret curve. Also as expected, higher noise levels lead to both larger absolute regret,
and weaker concavity: learning takes longer. Most of the runs display substantial concavity within
100,000 time steps, but some the β = .5 runs (on both graphs) require closer to 200,000 steps in
order for the concavity to clearly manifest.
With regards to absolute regret, β has a dramatic effect. On the extremes, the total regret for β = 0
after 1,000,000 time steps is less than 5,000 for Graph 1 and less than 9,000 for Graph 2. (The regret
for Graph 1 tends to larger, due to the graph being larger.) However, for β = .5, the regret after
100,000 time steps is already more than 12,000 and 20,000 for Graph 1 and Graph 2, respectively.
If we look at the average regret for β = 0 over 1,000,000 time steps, we get <.005 and <.009
for Graphs 1 and 2, respectively. Since the expected cost of each edge on a given time step is .25
(expected flow is .5, expected slope is .5), we view this as quite good. In contrast, for β = .5,
the average regret over 1,000,000 time steps is > .48 and >.88 for Graphs 1 and 2 respectively.
Relative to the average edge cost of .25, we view this as quite poor. This behavior again matches
our expectations.
Finally, we note that there are many other experimental parameters that we have not included in
these plots. For example: non-i.i.d flows, non-i.i.d. sources and destinations, non-i.i.d. congestion
functions, congestion functions with different numbers of pieces, congestion functions with different
Lipschitz constants, other noise distributions, correlated noise, and many more. We have indeed
tested many of these, but due to space constraints, there is a limit to the number of plots we can
include in the paper. We assure the reader that we have yet to find a parameter combination that
causes unexpected behavior from the algorithm.
4 Conclusion
In this paper, we presented an algorithm which learns an optimal routing policy for any graph, any
(Lipschitz continuous) congestion functions, and any (bounded) noise distribution, and adversarial
routing requests (i.e., source, destination, and the current flow on each edge). Our algorithm has
cumulative regret O(|E|t2/3).
There are many interesting directions for future work. The first relates to the dependence on t in
the regret bound. Since our problem generalizes the multi-armed bandit problem, We immediately
inherit a Ω(ʌ/t) lower bound. However, that still leaves substantial room to improve the dependence
on t. It Would also be interesting to improve the dependence on |E|. We have made several Worst-
case assumptions in this paper that are perhaps overly pessimistic: for example, neighboring edges
may have correlated congestion functions, and flows do not change arbitrarily between time steps.
On the empirical side, we evaluated our algorithm using real-world graphs, but synthetic congestion
functions. Future experiments could use real data for the congestion functions as well: either by fit-
ting a congestion function to the data, or by randomly sampling data points to simulate a congestion
function.
2With regards to the chosen range of β values, note that the expected maximum cost on each edge is .5,
since the domain of each fe is [0, 1] and the expected slope of each piece is .5. Thus in some sense, β = .5
represents “as much noise as signal”, β = .2 represents “2/5 as much noise as signal”, and so on.
7
Under review as a conference paper at ICLR 2021
6000
12000
Graph 1
Graph 2
120000
0	25000	50000	75000	100000
90000
60000
30000
wfe①J ①>=-nluno
0	25000	50000	75000	100000
方济①J①>=-nluno
0	250000	500000	750000
Time step
1000000
Figure 1: the experimental performance of Algorithm 1. The x-axis in each plots is the time step,
and the y-axis is the cumulative regret. There are eight plots, each consisting of four curves, each
with different noise levels. Each curve is a single run of the algorithm. The upper four plots have
time horizons of 100,000, and the bottom four have time horizons of 1,000,000. All plots in the left
column use Graph 1, and all plots in the right column use Graph 2. Finally, since we tested seven
values of β, we separated them into two different plots to avoid overcrowding a single plot. For
example, the top two plots in the left column have the same time horizon of 100,000 and both use
Graph 1. The top left plot contains the lower noise levels (0, .01, .02, .05), and the second-from-
the-top left contains the higher noise levels (.05, .1, .2, .5). Note that β = .05 is included in both to
allow visual comparison between the plots.
0	250000	500000	750000
Time step
1000000
8
Under review as a conference paper at ICLR 2021
References
Baruch Awerbuch and Robert D Kleinberg. Adaptive routing with end-to-end feedback: Distributed
learning and geometric approaches. In Proceedings of the thirty-sixth annual ACM symposium on
Theory ofcomputing, pp. 45-53, 2004.
Baruch Awerbuch, Yossi Azar, and Amir Epstein. The price of routing unsplittable flow. In Pro-
ceedings of the 37th Annual ACM Symposium on Theory of Computing, Baltimore, MD, USA,
May 22-24, 2005, pp. 57-66, 2005.
Zahy Bnaya, Ariel Felner, and Solomon Eyal Shimony. Canadian traveler problem with remote
sensing. In IJCAI 2009, 2009.
Anthony Chen and Zhaowang Ji. Path finding under uncertainty. Journal of Advanced Transporta-
tion, 39(1):19-37, 2005.
Caspar Chorus. Regret theory-based route choices and traffic equilibria. Transportmetrica, 8, 01
2010. doi: 10.1080/18128602.2010.498391.
George Christodoulou and Elias Koutsoupias. The price of anarchy of finite congestion games. In
Proceedings of the 37th Annual ACM Symposium on Theory of Computing, Baltimore, MD, USA,
May 22-24, 2005, pp. 67-73, 2005.
Gabriel de Oliveira Ramos, Bruno Castro da Silva, and Ana L. C. Bazzan. Learning to minimise
regret in route choice. In Kate Larson, Michael Winikoff, Sanmay Das, and Edmund H. Dur-
fee (eds.), Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems,
AAMAS 2017, Sao Paulo, Brazil, May 8-12, 2017,pp. 846-855. ACM, 2017.
Mo Dong, Qingxi Li, Doron Zarchy, Philip Brighten Godfrey, and Michael Schapira. PCC: re-
architecting congestion control for consistent high performance. In 12th USENIX Symposium on
Networked Systems Design and Implementation, NSDI 15, Oakland, CA, USA, May 4-6, 2015,
pp. 395-408. USENIX Association, 2015.
Mo Dong, Tong Meng, Doron Zarchy, Engin Arslan, Yossi Gilad, Brighten Godfrey, and Michael
Schapira. PCC vivace: Online-learning congestion control. In Sujata Banerjee and Srinivasan Se-
shan (eds.), 15th USENIX Symposium on Networked Systems Design and Implementation, NSDI
2018, Renton, WA, USA, April 9-11, 2018, pp. 343-356. USENIX Association, 2018.
Andras Gyorgy, Tamas Linder, Gabor Lugosi, and Gyorgy Ottucsak. The on-line shortest path
problem under partial monitoring. J. Mach. Learn. Res., 8:2369-2403, 2007.
Junchen Jiang, Rajdeep Das, Ganesh Ananthanarayanan, Philip A. Chou, Venkat N. Padmanabhan,
Vyas Sekar, Esbjorn Dominique, Marcin Goliszewski, Dalibor Kukoleca, Renat Vafin, and Hui
Zhang. Via: Improving internet telephony call quality using predictive relay selection. In Pro-
ceedings of the ACM SIGCOMM 2016 Conference, Florianopolis, Brazil, August 22-26, 2016,
pp. 286-299, 2016.
Junchen Jiang, Shijie Sun, Vyas Sekar, and Hui Zhang. Pytheas: Enabling data-driven quality
of experience optimization using group-based exploration-exploitation. In Aditya Akella and
Jon Howell (eds.), 14th USENIX Symposium on Networked Systems Design and Implementation,
NSDI 2017, Boston, MA, USA, March 27-29, 2017, pp. 393-406. USENIX Association, 2017.
Branislav Kveton, Zheng Wen, Azin Ashkan, Hoda Eydgahi, and Brian Eriksson. Matroid bandits:
Fast combinatorial optimization with learning. In Proceedings of the Thirtieth Conference on
Uncertainty in Artificial Intelligence, UAI 2014, Quebec City, Quebec, Canada, July 23-27, 2014,
pp. 420-429, 2014.
Keqin Liu and Qing Zhao. Adaptive shortest-path routing under unknown and stochastically varying
link states. In 10th International Symposium on Modeling and Optimization in Mobile, Ad Hoc
and Wireless Networks (WiOpt), Paderborn, Germany, May 14-18, 2012, pp. 232-237. IEEE,
2012.
9
Under review as a conference paper at ICLR 2021
Evdokia Nikolova and David R. Karger. Route planning under uncertainty: The canadian traveller
problem. In Dieter Fox and Carla P. Gomes (eds.), Proceedings of the Twenty-Third AAAI Confer-
ence OnArtificial Intelligence, AAAI2008, Chicago, Illinois, USA, July 13-17, 2008,pp. 969-974.
AAAI Press, 2008.
Evdokia Nikolova, Jonathan A. Kelner, Matthew Brand, and Michael Mitzenmacher. Stochastic
shortest paths via quasi-convex maximization. In Yossi Azar and Thomas Erlebach (eds.), Al-
gorithms - ESA 2006, 14th Annual European Symposium, Zurich, Switzerland, September 11-13,
2006, Proceedings, volume 4168 of Lecture Notes in Computer Science, pp. 552-563. Springer,
2006.
Christos H. Papadimitriou and Mihalis Yannakakis. Shortest paths without a map. Theoretical
Computer Science, 84(1):127 - 150, 1991.
_ _ _ / _ _ . . _ _ .. . . . . . . .
Tim Roughgarden and EVa Tardos. HoW bad Is selfish routing? J. ACM, 49(2):236-259, 2002.
Aleksandrs Slivkins. Introduction to multi-armed bandits. arXiv preprint arXiv:1904.07272, 2019.
Mohammad Sadegh Talebi, ZhenhUa Zou, Richard Combes, Alexandre Proutiere, and Mikael Jo-
hansson. Stochastic online shortest path routing: The Value of feedback. IEEE Trans. Autom.
Control., 63(4):915-930, 2018. doi: 10.1109/TAC.2017.2747409. URL https://doi.org/
10.1109/TAC.2017.2747409.
Jinkai Zhou, Xuebo Lai, and Joseph ChoW. Multi-armed bandit on-time arriVal algorithms for se-
quential reliable route selection under uncertainty. Transportation Research Record Journal of
the Transportation Research Board, 2673:673-682, 04 2019. doi: 10.1177/0361198119850457.
Zhenhua Zou, Alexandre ProUtiere, and Mikael Johansson. Online shortest path routing: The value
of information. In American Control Conference, ACC 2014, Portland, OR, USA, June 4-6, 2014,
pp. 2142-2147. IEEE, 2014.
A Proof of Theorem 1.1
In this section, We prove our main theorem:
Theorem 1.1. The expected regret of Algorithm 1 after t time steps is
Rt = O k2/3 ∙ |E| log Xmax (βPogt + XmaxL))
The space complexity and time complexity on time step t are O(|E|t1/3 log xtmax) andO |E|(log t+
log log Xtmax) + SP(|E|, |V |) , respectively.
We restate the algorithm beloW for the reader’s convenience.
Our first lemma upper bounds the distance betWeen tWo floWs associated With the same bucket.
Lemma A.1. Consider an arbitrary edge e and bucket b ∈ Be, let (X, cx) ∈ b, and let y ∈ dom(b)
(but not necessarily y ∈ b). If m = depth(b), then |X - y| ≤ Xtmax /2m-1.
Proof. Let b0 be the unique depth 0 ancestor of b. If b has depth m, then dom(b) must have length
exactly len(dom(b0))/2m, since the domain length is halved Whenever the depth is incremented.
Since len(dom(b0)) ≤ Xtmax, We have len(dom(b)) ≤ Xtmax/2m.
If X ∈ dom(b), then |X - y| ≤ Xtmax/2m and We are done. If not, then X must have been inserted
on the time step that b Was created. Let b00 be the parent of b. In this case, X ∈ dom(b00). By
construction, dom(b) ⊂ dom(b0), so We have X, y ∈ dom(b00). Finally, since b0 has depth m - 1,
len(dom(b0O)) ≤ Xmax/2m-1, so |x - y| ≤ Xmax/2m-1.	□
Lemma A.2 is a standard concentration equality due to Hoeffding. Lemma A.3 is essentially a
restatement of Hoeffding’s Lemma for our setting.
10
Under review as a conference paper at ICLR 2021
Algorithm 1 Algorithm for learning an optimal social routing policy.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
function ROUTINGALGORITHM(E, L, α, h)
for each e ∈ E do
Be J {create(0, [0,1])} . Start with a single bucket of depth 0 and constant length
for each t ∈ N>0 do
xte J proposed flow on edge e
for each e ∈ E do
ute J ESTIMATEEDGECOST(xte, Be, L, α)
pt J arg minp∈Pt Pe∈p ute
selectRoute(pt), observe cost cte ∀e ∈ pt
for each e ∈ pt do
UPDATEBUCKETS(xte, Be, cte, h)
1:	function ESTIMATEEDGECOST(x, B, L, α, t)
2:	if ∃b ∈ B s.t. X ∈ dom(b) and |b| > 0 then
3:	return max(0, estimate(b) 一，|b|-1 lnta)
4:	else
5:	return 0
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
1:
2:
3:
4:
5:
6:
7:
8:
function UPDATEBUCKETS(y, cy , B, h)
if ∃b ∈ B s.t. y ∈ dom(b) then	. Insert our observation into the corresponding bucket
INSERT(b, (y, cy))
m J depth(b)
if |b| > h(m) then	. Split the bucket ifit is too big
[w, z] J dom(b)
bi J Create(m + 1, [w, w+z])
b2 J Create(m + 1, [w+z, z])
INSERT(b1, (y, cy)) . Insert the observation into new buckets so they aren’t empty.
INSERT(b2, (y, cy))	. Type 1 error is still proportional to the domain lengths.
Be J (Be \ b) ∪{bl}∪{b2}
else	. This flow does not fall into any bucket: create a new depth 0 bucket
ymax J max ∪b∈Be dom(b)
b J Create 0, [ym
ax, 2x]
Be J Be ∪ {b}
function INSERT(b, (y, cy))
[w, z] J dom(b)
if y < w then	. y 6∈ dom(b) is possible if we created b on this time step
uy = cy
else
uy = cy - L(y - w)
|b| ∙ estimate(b) + Uy
estimate(b) J-----------------------
|b| + 1
|b|J|b|+1
. This is a running average of {uy : y ∈ b}
Lemma A.2 (Hoeffding’s Inequality). Let X1, . . . , Xn be independent random variables each sup-
ported on an interval of length β > 0 and let X = n PNi Xi. Thenfor any ε > 0,
Pr[∣^X — E[X]∣ >ε] ≤ exp (-n^)
Lemma A.3. Fix an edge e and a bucket b ∈ Be. With probability at least 1 - δ,
1
即 X ηy ≤β
ln δ-i
11
Under review as a conference paper at ICLR 2021
Proof. If β = 0, the claim is trivially true. Otherwise, since E[ηy] = 0, and all ηy are independent
for a given edge, Hoeffding’s Inequality gives us
Pr
1 L	∕ln δ-11	∕β2 ln δ-1
同 y∈b ηy >βv 而]≤ exp(τbτ
-2∣b∣、.
下==δ
as required.
□
We will now start the process of bounding the costs incurred by our algorithm. Moving forward, we
will need to separately handle the time steps where xte does not fall into any bucket we have, and we
must create a new depth 0 bucket (on line 14 of UPDATEBUCKETS). Let Te be the set of time steps
t where (1) e ∈ pt, (2), ∃r < t such that e ∈ pr (i.e., this is not the first we are using this edge), and
(3) we do not create a new depth 0 bucket. The reader can think of Te as the set of time steps when
edge e is used in a “normal” way.
Throughout the analysis, for each e ∈ E and time t, let bte denote the bucket that is used on line
3 of ESTIMATEEDGECOST, if such a bucket exists. For each t ∈ Te, we are guaranteed that bte
exists, since Condition 3 above ensures that there exists b ∈ Be with xte ∈ dom(b), and Condition 2
ensures that ∣b∣ > 0. Throughout the proof, we will use ∣bte ∣ to denote the number of observations in
the bucket on that time step, before inserting the new element (if one is inserted).
Also, for each e ∈ E and time t, let Ze(t) be the indicator variable that ∣ 击 Py∈∕ ηy ∣ ≤
p∣be∣-1 lntα = βp∣be∣-1 lnta/e2. (If % does not exist, let Ze(t) = 1). Note that by Lemma A.3,
Pr[Ze(t) = 1] ≥ 1 - La/β.
The next lemma states that as long as ζe(t) = 1, our algorithm’s estimate ute will always be an
underestimate of the true cost fe(xte).
Lemma A.4. Fix a time t and edge e. If ζe(t) = 1, then fe(xte) ≥ ute.
Proof. If ute = 0, then trivially ute ≤ fe(xte). Thus assume ute > 0. This implies t ∈ Te, and so
bte exists. For each y ∈ bte, define uy as in the INSERT function in Algorithm 1, and let [w, z] =
dom(bte). For brevity, let x = xte. Note that x ≥ w and thus fe(x) ≥ fe(w). Also recall that
cy = fe(y) + ηy by definition. We first claim that fe(x) ≥ uy - ηy for all y ∈ bte.
Case 1:	w > y. Then x > y, so we have uy - ηy = cy - ηy = fe(y) ≤ fe(x), as required.
Case 2:	y ≥ w. Then uy -ηy = cy -ηy -L(y-w) = fe(y) -L(y-w). Because fe is L-Lipschitz,
we have fe(y) ≤ fe(w) + L(y - w), so
uy - ηy = fe(y) - L(y - w)
≤ fe(w) +L(y -w) - L(y - w)
≤ fe(x)
Therefore
fe(x) ≥ ∣bt∣ X(uy - ηy )
e y∈bte
=∣⅛ X uy
e y∈bte
1
≥ ∣bt∣ Tuy
e y∈bte
-⅛ XXeηy
ηy
y∈bte
-ɪ X
照二
Since ζe(t) = 1 by assumption, we get
fe(Xe) ≥ 焉 X uy — ρ∣be∣-ιln tα = estimate(be) - ρ∣be∣-1 ln tα
e y∈bte
Since U > 0, We have ue = estimate^) - ,∣be∣-1 lntα. Thus fe(xe) ≥ ue as required. □
12
Under review as a conference paper at ICLR 2021
Lemma A.5 states that if t ∈ Te and ζe(t) = 1, then our estimate ute also shouldn’t be too much
more than fe(xte).
Lemma A.5. Fix a time t ∈ Te and edge e, and let m = depth(bte). If ζe(t) = 1, then
Xt	L ,----------：-----
fe(xte) ≤ Ue + ʒma-r + 2P∣be∣-1 ln tα
Proof. As before, for each y ∈ bte, define uy as in INSERT, let [w, z] = dom(bte), and let x = xte
for brevity. We first claim that fe(x) ≤ uy - ηy + L(x - y) for all y ∈ bte. Since x ≥ w and fe is
L-Lipschitz, we have fe(x) ≤ fe(w) + L(x - w).
Case 1:	y ≥ w. Then fe(w) ≤ fe(y) by monotonicity, so
fe(x) ≤ fe(y) + L(x - w)
= cy - ηy + L(x - y) + L(y - w)
= uy - ηy + L(x - w)
≤ uy - ηy + 21-mxtmaxL
where the last step follows from Lemma A.1.
Case 2:	w > y.3 Then fe(w) ≤ fe(y) + L(w - y), so
fe(x) ≤ fe(y) + L(w - y) + L(x - w)
= cy - ηy + L(x - y)
≤ uy - ηy + L(x - y)
≤ uy - ηy + 21-mxtmaxL
again using Lemma A.1 on the last step. Therefore
fe(x) ≤
而 X (Uy- ηy + 21-mxmɑxL)
e y∈bte
2ImXImaXL + 而 X Uy -而 X ny
|be | y∈bte	|be | y∈bte
≤ 21-mχtm,axL + estimate(be) + jbtɪ
Eny + √∣be∣-1 lnt- -√∣be∣-1 lnt-
y∈bte
Since Ue = max(0, estimate(b)—，网Tlnta), We have estimate(b)—，网Tlntα ≤ u[.
Als0, । 由 Py∈bt ny | ≤ ∙∖∕∣be∣-1 lnta, since Ze(t) = 1 by assumption. Therefore
fe(X) ≤ Ue+2i-mxmαxL+7b1tτ X ny + PlbeITlntɑ
e y∈bte
≤ Ue + 21-mxmaxL + 2P∣be∣-1lntɑ
□
The next lemma is a simple bound on the maximum floWs on time steps When We create a neW depth
0 bucket. This Will be needed later to bound the error on those time steps.
Lemma A.6. Fix an edge e ∈ E and a time step t > 0. Let t0 , . . . , tk be the time steps up
to and including time t on which a new depth 0 bucket is created in Be (where t0 = 0). Then
k ≤ 1 +logXtmax. Furthermore, Pik=1 Xtek ≤ 2Xtmax.
3This means that y is actually not in dom(bte). This only happens if y Was inserted into bte on the time step
When bte Was created.
13
Under review as a conference paper at ICLR 2021
Proof. Assume t0 < t1, . . . , < tk. Let ymr ax = max(∪b∈Ber dom(b)), where Ber denotes the set
of buckets for edge e at the beginning of time step r. This is the maximum flow that falls into
any bucket in Be at time r Note that ymr+a1x = ymr ax for all r 6∈ {t1 , . . . , tk}. Furthermore, for
r ∈ {t1, . . . , tk}, we have ymr+a1x = 2xre > ymr ax. Therefore for each i ∈ {1, . . . , k},
ymti+a1x = 2xtei > 2ymti ax
Thus for all i,j ∈ {1, k} with i ≤ j, ymtjax > 2j-i. In particular,
ytk	> 2k yt0	= 2i
ymax	ymax
where ymt0ax = 1 is because we initialize Be with a single bucket corresponding to the interval [0, 1].
We know that ytk+1 = 2xtek-1 ≤ 2xt , so 2k ≤ 2xt . Therefore |Dt| = k ≤ 1 + log xt .
max	max	max	e	max
Finally,
kk
X x2 = 2 X ym+
tk+1
ymax
≤
2
k1
X ɪ
2k-i
i=1
ytk+1
≤ mτaxx
≤	2
≤ 2xt
max
as required.
□
Lemma A.7 gives our first bound on the cumulative regret of the algorithm. This bound is quite
complex, and it will take substantial work later on to show that this bound is in fact O(t2/3).
Lemma A.7. Assume α = 2β2. Then for all t, we have
Rt ≤
|E ιxmaxL(π2+ 18)
xtmaxL
max
2de 2_^ ∖2depth(be)-1
r=1 e∈pr
+ 2plbel-1ln ta)
6
Proof. We first prove a lower bound on E[c", the expected cost incurred by the optimal algorithm.
By definition,琮 =minp∈Pt Pee∈p fe(Xte), so Lemma A.4, We have fe(x2) ≥ Ue with probability
at least 1 - t-a/e. For brevity, let δ = t-α/β. Since Ct ≥ 0 always, We have
Ed] ≥ (I- δ) ∙ min X ue
p t e∈p
Next, we prove an upper bound on E[ct ], the expected cost incurred by our algorithm. Note that
E[ct] = X fe(xte) = X	fe(xte) + X	fe(xte)
e∈pt	e∈p^t∈Te	e∈pt.t∈Te
We will first handle the first term, and then the second term. Since fe is L-Lipschitz and
fe(0) = 0, we have fe(x) ≤ xtmaxL for allx ≤ xtmax. Since xte ≤ xtmax, we have
fe(xte) ≤ xtmaxL as a broad upper bound for all cases. If t ∈ Te, then Lemma A.5 implies that
fe(xe) ≤ Ue + 21-depth(be)xtmaχL + 2,阿|-1 ln tα With probability at least 1 - δ. Also recall that
pt = arg minp∈Pt Pe∈p ute by definition. Thus
Xt	L
E	fe(χe) ≤ E δxtmaχL+(1- δ) (ue+「菽)-i + 2p∣be∣-ιin力。)
e∈p.t∈Te	e∈pt L	」
≤ δ∣E ∣χtmaxL+(1 -δ) ∙ min X Ue+(1 -δ) X (2dX⅛-ι+2Pibei-1 ln t")
e∈p	e∈pt
≤ δIEixtmaxL +(1 - δ) ∙ min X Ue + X (2dX⅛)-1 + 2pMFln^a)
e∈p	e∈pt
14
Under review as a conference paper at ICLR 2021
NeXLfor Ee∈%t?Te fe(Xe) We have
X	fe (xe ) ≤ X
xe,max L = |{e ∈ pt : t 6∈ Te }|xte
,max L
e∈p.t∈Te	e∈pot∈Te
Combining this with our upper bound on E[c", We get
E[ct - c" ≤∣{e ∈ Pt : t∈ Te}∣xe,maχL + IEtxml2x" + X (27：*(机-1 + 2,讹1-1 ln ta)
e∈pt
Summing the second term gives us4
X EamXL = IEIxmaxL X r12 ≤ IEIxmaxL X	= ^m^
r=1	r=1	r=1
For the first term, we further divide time steps t 6∈ Te into (1) time steps where we create a new
depth 0 bucket, and (2) time steps where we use edge e for the first time. For case (1), let Qe denote
the set of these time steps. Recall that we only create a depth 0 bucket when the current flow xte
does not fall into any bucket we already have. In particular, that implies it is the maximum flow
we have seen on this edge: formally, t ∈ Qe implies xte = xte,max. For case (2), let ze(t) be the
indicator variable which takes on value 1 if t is the first time that e is used, and 0 otherwise. Since
this happens at most once per edge, we have Ptr=1 ze(r) ≤1 for all e ∈ E. Therefore,
tt
L X Ke ∈ Pr : r ∈ TeHxr,max = L X xe,max(Ke ： r ∈ QeH + Ke ∈ Pr : ze(r) = IH)
r=1	r=1
tt
≤ L X I{e : r ∈ Qe}Ixe + L X xe,max X ze(r)
r=1	r=1	e∈pr
t
≤ LX X xre + L X X xtmaxze(r)
e∈E r≤tιr∈Qe	e∈Er=1
≤ L X X xre + IEIxtmaxL
e	max
e∈Ε r≤t;r∈Qe
≤ L	2xtmax + IEIxtmaxL (Lemma A.6)
e∈E
= 2IE Ixtmax L + IEIxtmaxL
= 3IE IxtmaxL
Putting this all together, we get
as required.
t
Rt =XE[ct-
r=1
Let Set be the set of buckets associated with edge e that have existed up to and including time t, and
let At(b) = {r ≤ t : e ∈ Pr and bte = b} be the set of time steps that we used bucket b. We know
4 Note that we could have chosen any α ≥ 2β2 and simply obtained a different constant.
15
Under review as a conference paper at ICLR 2021
that every time we use edge e (i.e., e ∈ pt), we use exactly one bucket bte. Thus we can rewrite the
bound from Lemma A.7 as
Rt ≤ lElxmaχj6(π2 +12) + XX X	(2⅛⅛ι + 2p^F1in^α)
e∈E b∈Set r∈At (b)
Note that we use |ber| instead of |b| in order to denote the size of the bucket on time step r specifically.
Let Rt(b) = Pr∈At(b) (21-depth(b)χmaχL + 2p|b|-1 ln tα) be the total regret incurred by bucket
b, and let Rt (e) = Pb∈St Rt (b) be the total regret incurred by edge e. The rest of the proof is
devoted to bounding Rt(e); after we have done so, we can simply sum this bound across all edges.
We next give a brief proof of a standard inequality that will be useful to us.
Lemma A.8. For all n, pn=ι √i ≤ 2√n∙
Proof. The proof is by induction n. The base case ofn = 1 is trivial, so consider an arbitrary n > 1
and assume the claim holds forn - 1. Then
X √i = √n+X √i
i=1	i=1
2	C 1——-
≤	---/	+ 2√n - 1
n+ n- 1
=2(√n - √n — 1) + 2√n — 1
=2√n
as required.	□
We will now bound the maximum regret a single bucket of depth m can contribute.
Lemma A.9. Let b ∈ Set be a bucket with depth m∙ Then
Rt (b) ≤ 4√h(m)ln tα + XmaxLhIm)
Proof∙ Substituting m = depth(b), Rt(b) is defined by
Rt(b) ≤ 飞m廿㈤1 +2 X √∣b∣-1lnt”
r∈At (b)
Next, observe that |At(b)| ≤ h(m): |b| = 1 initially, and once |b| > h(m), we split it into two new
buckets and never use it again. Thus we can rewrite the above bound to sum over the number of
elements in b:
Rt(b) ≤
t	|At (b)|
χmxL⅛≡ + 2√1n而 X -1
2m-1	J √i
i=1
XmaxLh(m)
2m-1
≤
____h(m)]
+ 2√ιnτα X -1
J √i
i=1
≤ Xmam-h(m)+ 4√h(m) lntα (Lemma A.8)
as required.
□
Next, we will analyze a linear program which will be useful in bounding the total regret contributed
by a single edge.
16
Under review as a conference paper at ICLR 2021
Lemma A.10. Consider the following linear program, parameterized by t, n and k:
max
x1,...,xn∈R≥0
n
X2km
xm
m=1
(1)
n
s.t. X 22m-3xm ≤ t
m=1
xm ≤ 2m ∀m ∈ {1, . . . , n}
Assume 0 ≤ k < 2, and let (x1, . . . , xn) be an optimal solution, and suppose xm > 0. Then for all
i < m, xi = 2i.
Proof. Suppose not, and let δ = min(xm, 2i - xi) > 0. Define a new solution (y1 , . . . , yn) by
yi = Xi + 22i-3 , ym = Xm ― 22m-3 , and yj = Xj for j ∈ {i, m}.
We first claim that y is feasible. We have ym ≥ xm - δ ≥ 0, and yi ≤ xi + δ ≤ 2i . Since yj = xj
forj 6∈ {i, m}, we have 0 ≤ Xj ≤ 2j for all j. Also, we have
n
X yj22j-3 = (Xi + 2213) ∙ 22i-3 + 即-22mδ-3) 22m-3 + X Xj22j-3
j=1	j 6∈{i,m}
= Xi22i-3 + δ + Xm22m-3 - δ + X Xj22j-3
j6∈{i,m}
n
= X Xj22j-3
j=1
which must be at most t, since (X1, . . . , Xn) is assumed to be feasible.
Finally, we claim that (y1, . . . , yn) has a better objective value. We have:
nn
X2kjyj - X 2kjXj = yi2ki + ym2km - Xi2ki - Xm2km
j=1	j=1
ki	km
=2kiχ∙ +  ____+ XE2km___________2kiχ∙ _ 2kmχ〜
A Xi + 22i + Xm^	22m	A Xi	A	Xm
δδ
--TT-TT— - -TT-TT-
2(2-k)i 2(2-k)m
Since 2 - k > 0 and m > i, we have 2(2-k)i < 2(2-k)m . Thus the above expression is strictly
positive. Therefore (y1, . . . , yn) has a higher objective value, which contradicts the optimality of
(X1, ..., Xn).	□
For now, we are primarily interested in k = 1. Let g(t, n) denote the maximum value of Program 1
for parameters t and n, with k = 1. Lemma A.10 implies that for a fixed t, n actually does not
matter, assuming it is sufficiently large: the Pnm=1 22m-3Xm ≤ t constraint will be saturated by
smaller values of m, so any additional variables will always have value 0. Formally, for all t, there
exists nt such that g(t, nt) = g(t, n) for all n ≥ nt. Thus we can simply take n to be large enough
and write g(t) = g(t, nt). For example, nt = t suffices.
The next lemma bounds the total regret contributed each “tree”, i.e., a set of buckets that share a
depth 0 ancestor. Also, at this point we will substitute in h(m) = 22m.
Lemma A.11. Fix an edge e and time t. Let S ⊆ Set be a set of buckets which all have the same
depth 0 ancestor. Then
X Rt(b) ≤ (4√nα +2XmaxL)g(t)
b∈S
Proof. Let Xm denote the number of buckets b ∈ S of depth m. Letting h(m) = 22m, Lemma A.9
implies that
Rt(b) ≤ 4Ph(m)lnt" + XmaxLhJm) = (4√nα +2XmaxL)2m
17
Under review as a conference paper at ICLR 2021
Thus
___	____ nt
X Rt(b) ≤ (4√nα + 2xtmaχL) X Xm2m
b∈Bej	m=0
We next claim that (x1, . . . , xm) is feasible for Program 1. We know that xm ≤ 2m, since
within a single binary tree, there are at most 2m nodes of depth m. It remains to show that
t≥ Pnt 22m-3
t≥	m=1	xm .
Note that all buckets of depth at least 1 come in pairs: spending h(m - 1) steps on a bucket of depth
m - 1 creates two buckets of depth m. Thus the number of time steps we spent on buckets of depth
m - 1 is exactly Xm ∙ h(m - 1) = 22m-2Xm = 22m-3xm. Thus the total number of time steps is
bounded by
nt
t≥ X 22m-3xm
m=1
as required.
Therefore (xι,..., Xm) is a feasible solution to Program 1, and Pb∈s Rt(b) is at most (4√ln tα +
2xtmaχL) times the objective value of Program 1 for (xi,..., xm,). Since the objective value for
(xi,..., Xm) is at most the optimal objective value g(t), We have Pb∈s Rt(b) ≤ (4√lntα +
2xmaχL)g⑴.	□
We are noW ready to bound the total regret contributed by a single edge.
Lemma A.12. For all e, t, we have
Rt(e) ≤ (I +log Xmax)(4√lntα + 2XmaxL)g⑴
Proof. Let S1 , . . . , Sq be a partition of Set such that each Si contains exactly one depth 0 bucket,
and all buckets in Si have the same depth 0 ancestor. (i.e., each Si constitutes a single binary tree).
By Lemma A.6, q ≤ 1 + log Xtmax. Therefore
q
Rt(e) =	Rt(b)
i=1 b∈Si
q ________
≤ X(4√lntα + 2XmaxL)g(t) (Lemma A.11)
i=1
=q(4√ln tα + 2XmaxL)g⑴
≤ (1 +log Xmax)0√lntα + 2XmaxL)g(t)
as required.	□
We are almost done. One of our last remaining tasks is to bound g(t): the optimal objective value of
Program 1.
Lemma A.13. For all t, we have g(t) ≤ 2812/3.
Proof. Fix a time t, and let (X1, . . . , Xn) be an optimal solution to Program 1 for parameter t. Let
m be the minimum integer so that Pim=1 22i-32i > t. Then there exists i ≤ m so that Xi < 2i : oth-
erWise, Pim=1 22i-3Xi = Pim=1 22i-32i > t by assumption, Which Would imply that (X1, . . . , Xn) is
infeasible.
Since there exists i ≤ m so that Xi < 2i, Lemma A.10 implies that Xi = 0 for all i > m. Therefore
g(t) = Pin=1 2iXi = Pim=1 2iXi = Pim=1 22i.
By definition of m, We have t ≥ Pim=-11 22i-32i = Pim=-11 23i-3 ≥ 23m-9. Therefore
3m - 9 ≤ log t
18
Under review as a conference paper at ICLR 2021
Therefore
m ≤ ɪ log t + 3
m ≤log t1/3 + 3
m
g(t)≤X22i
i=1
≤ 422m
_ 3
≤ 422log t1/3 +6
_ 3
=4 ∙ 26 ∙ t2/3
28
=2τ M
as required.
□
Our last lemma analyzes space and time complexity of our algorithm.
Lemma A.14. The space complexity and time complexity of Algorithm 1 on time step t are
O(|E|t1/3 log xtmax) and O |E|(logt+log log xtmax) + ShortestPath(|E|, |V |) , respectively.
Proof. For the space complexity, note that each bucket b requires a constant amount of space: it
simply needs to store |b|, dom(b), depth(b), and estimate(b), each of which take constant space.
Thus the space complexity is the total number of buckets at time t. In fact, we will bound |Set |, the
number of buckets that have existed at any time up to time t for edge e. As in Lemma A.12,
let S1 , . . . , Sq be a partition of Set such that each Si contains exactly one depth 0 bucket, and all
buckets in Si have the same depth 0 ancestor. We claim that |Si| ≤ t1/3 for all i.
We will show this using Program 1, but now with k = 0 instead of k = 1:
max
x1 ,...,xn∈R≥0
n
xm
m=1
(2)
n
s.t. X 22m-3xm ≤ t
m=1
xm ≤ 2m ∀m ∈ {1, . . . , n}
The analysis proceeds similarly to Lemmas A.11 and A.13. Let g0(t) be the optimal objective value
for Program 2 with parameter t. We claim that |Set| ≤ g0(t). Let xm denote the number of buckets of
depth m that have existed up to and including time t for this edge. Since the constraints in Program 2
are the same as in Program 1, we already showed in the proof of Lemma A.12 that (x1 , . . . , xn) is
feasible for Program 2. Since |Set| = Pnm=1 xm, we have |Set| ≤ g0(t).
It remains to bound g0(t). Let m be the minimum integer such that Pim=1 22i-32i > t. Then as
argued in Lemma A.13, m ≤ log t1/3 + 3. Thereforeg0(t) ≤ Pim=1 xm ≤ Pim=1 2m ≤ 2m+1, so
g0(t) ≤ 2log t1/3+4 = O(t1/3)
By Lemma A.6, q ≤ 1 + log xtmax. Therefore the total number of buckets for edge e at time t is at
most
q
|Set| =	|Si|
i=1
≤ q ∙ O(t1∕3)
= O(log xtmaxt1/3)
19
Under review as a conference paper at ICLR 2021
and thus the total space complexity is O(|E| log xtmaxt1/3).
For the time complexity, each time step involves two tasks that may take non-constant time: com-
puting ute for each e ∈ E, and computing arg minp∈Pt Pe∈p ute. Once the first task has been done,
the second task can by running any shortest path algorithm on the directed graph (E, V ) where edge
e has nonnegative weight ute; this takes time ShortestPath(|E|, |V |).
For the first task, there are two parts that may take non-constant time. The first part is searching
for a bucket b such that y ∈ b. The buckets correspond to non-overlapping intervals, so this can be
done by keeping the buckets in sorted order and using binary search. This approach yields a time
complexity of O(log |Set|) = O(log t+log log xtmax) per edge and thus O(|E|(log t+log log xtmax))
total. Note that to keep the buckets in sorted order, creating a bucket now requires us to insert it into
the right place in the ordering. Using a self-balancing binary tree, this be done in time O(log |Set|)
per operation as well (and at most two buckets are created per edge per time step).
The second part that may take non-constant time is computing ymax = max ∪b∈Be dom(b) , if
applicable. If the buckets are stored in sorted order, this can be done in constant time by looking at
the last bucket in the ordering. This yields the desired bound.	□
We are finally ready to prove Theorem 1.1.
Theorem 1.1. The expected regret of Algorithm 1 after t time steps is
Rt = O (t2∕3 ∙ |E| log xmax(βpl°gi + XmaxL))
The space complexity and time complexity on time step t are O(|E|t1/3 log xtmax) andO |E|(log t+
log log xtmax) + SP(|E|, |V |) , respectively.
Proof. We have
Rt ≤ lElxmaxL(π2 + 12) + X Rt(e) (Lemma A.7)
6
e∈E
≤ lElxmaxL(π2 + 12) + X(1+logXmax)(4√nF + 2xmaxL)g(t) (LemmaA.12)
e∈E
=lElxmaxL(π2 + 12) + ∣E∣(1+lοgXmax)(4√nF + 2XmaxL) ∙ 2812/3 (LemmaA.13)
Plugging in α = 2β2 as in Lemma A.7 gives us
Rt ≤ |E|XmaxL(n2 + 12) + ∣E∣(1 + log Xmax)(4β√m7 + 2xtmaxL) ∙	t2/3
=O (|E| log Xmaxepl°gt + XmaxL)t2/3)
Combining this with Lemma A.14 proves the theorem.
□
20