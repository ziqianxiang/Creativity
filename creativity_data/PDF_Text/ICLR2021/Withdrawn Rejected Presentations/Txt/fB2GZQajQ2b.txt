Under review as a conference paper at ICLR 2021
Information-Theoretic Odometry Learning
Anonymous authors
Paper under double-blind review
Ab stract
In this paper, we propose a unified information-theoretic framework for odometry
learning, a crucial component of many robotics and vision tasks such as navigation
and virtual reality where 6-DOF poses are required in real time. We formulate
this problem as optimizing a variational information bottleneck objective func-
tion, which eliminates pose-irrelevant information from the latent representation.
The proposed framework provides an elegant tool for performance evaluation and
understanding in information-theoretic language. Specifically, we bound the gener-
alization errors of the deep information bottleneck framework and the predictability
of the latent representation. These provide not only a performance guarantee but
also practical guidance for model design, sample collection, and sensor selection.
Furthermore, the stochastic latent representation provides a natural uncertainty
measure without the needs for extra structures or computations. Experiments on
two well-known odometry datasets demonstrate the effectiveness of our method.
1	Introduction
Odometry aims to predict six degrees of freedom (6-DOF) poses from motion sensors. It is a
fundamental component of a wide variety of robotics and vision tasks including simultaneous
localization and mapping (SLAM), automatic navigation, and virtual reality (Durrant-Whyte &
Bailey, 2006; Fuentes-Pacheco et al., 2015; Taketomi et al., 2017). In particular, visual and visual-
inertial odometry have attracted a lot of attention over recent years due to the low cost and easy
setup of cameras and inertial measurement unit (IMU) sensors. Odometry is challenging due to the
difficulties to model the complexity and diversity of real-world scenarios from a limited number of
on-board sensors. Furthermore, since odometry is essentially a time-series prediction problem, how
to properly handle time dependency and environment dynamics presents further challenges.
Current visual odometry solutions fall into geometry constraint based methods and deep learning
based methods. Though successful in many real-world scenarios, the performance of geometry-
based approaches can be limited when their underlying assumptions, such as static environments,
discriminative visual features and brightness constancy, are violated. Furthermore, their hard-
coded systems require extensive parameter tuning under different environments and non-trivial
synchronization and initialization. Deep learning-based methods have recently attracted interest by
learning from large-scale datasets (Wang et al., 2017; Clark et al., 2017; Xue et al., 2019; Yang et al.,
2020). Well-trained deep networks effectively capture the inherent complexity and diversity of the
training data, thus holding promise for addressing the limitations of geometry based approaches.
Although existing deep odometry learning methods have performed competitively against their
geometry counterparts, they still fail to satisfy some basic requirements. First, due to the broad range
of scenarios where odometry is required, odometry systems are expected to be easily compatible with
various configurations and settings such as multiple sensors and dynamic environments. Besides,
the common existence of data degeneration, such as from hardware malfunctions and unexpected
occlusions, requires a safe and robust system in which a proper uncertainty measure is desirable for
self-awareness of anomalies and system bias. Moreover, theoretical analyses of current black box
deep odometry models, such as generalizability on unseen test data and extendibility to extra sensors,
are still obscure but essential for understanding and assessing the model performance.
Here we devise a unified odometry learning framework from an information-theoretic perspective,
which well addresses the above issues. Our work is motivated by the recent successes of deep
variational inference and learning theory based on mutual information (MI). Specifically, we translate
1
Under review as a conference paper at ICLR 2021
the odometry problem to optimizing an information bottleneck (IB) objective function where the latent
representation is formulated as a bottleneck between observations and poses. In doing so, we eliminate
the pose-irrelevant information from the latent representation to achieve better generalizability.
Modeling by MI constraints provides a flexible way to account for different aspects of the problem
and quantify their effectiveness in information-theoretic language. This framework is also attractive
in that the operations are performed on the probabilistic distribution of the latent representation,
which naturally provides an uncertainty measure for interrogating data quality and system bias.
More importantly, the information-theoretic formulation allows us to leverage information theory to
investigate the theoretical properties of the proposed method. Our theoretical findings not only benefit
the evaluation of the model performance but also provide insights for subsequent research. We obtain
a theoretical guarantee of the proposed framework by deriving an upper bound of the generalization
error w.r.t. the IB objective function under mild network and loss function conditions. We show
that the latent space dimensionality also bounds the generalization error, providing a theoretical
explanation for the complexity-overfitting trade-off in the latent representation space. When test data
is biased, our result shows that the growing rate of d should not exceed that of n/log(n), where d is
the latent space dimensionality and n is the sample size. We further quantify the usefulness of a latent
representation for pose prediction using the MI between the representation and poses. In doing so, we
prove a lower bound for this MI given extra sensors, which reveals the conditions required for a sensor
to theoretically guarantee a performance gain. It is noteworthy that our theoretical results hold not
only for the odometry problem but also for a wider variety of problems that share the same Markov
chain assumption and the IB objective function. A connection between our information-theoretic
framework and geometry based methods is further established for deeper insights.
The main contributions of this paper are (1) we propose information-theoretic odometry learning
by leveraging the IB objective function to eliminate pose-irrelevant information from the latent
representation; (2) we develop the theoretical performance guarantee of the proposed framework by
deriving upper bounds on the generalization error w.r.t. IB and the latent space dimensionality as
well as a lower bound on the MI between the latent representation and poses; and (3) we empirically
verify the effectiveness of our method on the well-known KITTI and EuRoC datasets and show how
the intrinsic uncertainty benefits failure detection and inference refinement.
2	Related Work
Deep representation for odometry learning: Leveraging deep neural networks to learn compact
feature representation from high-dimension sensor data has been proven effective for odometry.
Kendall et al. (2015) proposed PoseNet by using neural networks for camera relocalization, based
upon which Wang et al. (2017) introduced a recurrent module to model the temporal correlation
of features for visual odometry. Subsequently, Xue et al. (2019) further considered a memory and
refinement module to address the prediction drift caused by error accumulation. Recently, deep
learning-based odometry has also been extended to the multi-sensor configuration. Clark et al. (2017)
extended the DeepVO framework to incorporate IMU data by leveraging an extra recurrent network
for learning better feature representation. A recent study by Chen et al. (2019) investigated more
effective and robust sensor fusion via soft and hard attention for visual-inertial odometry. Apart
from end-to-end learning, there are also trends in unsupervised learning (Zhou et al., 2017; Yin
& Shi, 2018; Ranjan et al., 2019; Bian et al., 2019) and the combination of learned features with
geometry methods (Zhan et al., 2019; Yang et al., 2020). We refer readers to Chen et al. (2020) for a
more detailed discussion of current methods. These deep odometry learning methods have achieved
promising performance. However, theoretical understandings remain obscure: (1) how to learn a
compact representation with a theoretically guaranteed generalizability when test data is biased and
(2) in what conditions extra sensors can benefit the pose prediction problem.
Information bottleneck: Information bottleneck (IB) provides an appealing tool for deep learning
by learning an informative and compact latent representation (Tishby et al., 2000; Tishby & Zaslavsky,
2015; Shwartz-Ziv & Tishby, 2017). To address the intractability of MI calculation, Alemi et al.
(2017) proposed to optimize a variational bound of IB for deep learning, which was successfully
applied to many tasks including dynamics learning (Hafner et al., 2020), task transfer (Goyal et al.,
2019), and network compression (Dai et al., 2018). Partly inspired by these developments, we
for the first time propose an IB-based framework for odometry learning and derive an optimizable
2
Under review as a conference paper at ICLR 2021
(a) Classic Odometry Learning
(b) DeterminiStic-StochaStic IB Odometry Learning
Figure 1: (a) The classic learning-based odometry framework, where 6-DOF poses are directly
predicted from deterministic latent representations. (b) The proposed information bottleneck (IB)
framework for odometry learning. h and S are the deterministic and stochastic components, respec-
tively. Superscripts o and P represent the observation- and pose-level transition models. Red solid
arrows denote the pose regressor and red dashed arrows denote the bottleneck constraints. Output
arrows from a shaded stochastic representation represent samples from the learned latent distribution.
variational bound for this sequential prediction problem. The derivation can be more delicate if we
incorporate more constraints, potentially from geometric and kinematic insights. We further adopt the
determinisitic-stochastic separation as in Chung et al. (2015); Hafner et al. (2019; 2020), while ours
differs in that our derivation of the variational bound allows modeling two transition models separately,
each with a determinisic component to improve model capacity. Moreover, though IB-based methods
have shown to be effective for learning a compact representation, the underpinning generalizability
theory remains unclear. The generalization error bounds for general learning algorithms have been
studied in Xu & Raginsky (2017) in information-theoretic language. This work was subsequently
extended by Zhang et al. (2018) to explain the generalizability of deep neural networks. However,
their results are not applicable to the IB-based methods, which will be addressed in this paper.
Uncertainty modeling for odometry learning: Modeling uncertainty to deal with extreme cases
like hardware malfunctions and unexpected occlusions, is crucial for a reliable and robust odometry
system. It can be categorized into model-intrinsic epistemic uncertainty and data-dependent aleatoric
uncertainty, which have been studied in the Bayesian deep learning literature (MacKay, 1992; Gal &
Ghahramani, 2016; Kendall & Gal, 2017). For odometry, Wang et al. (2018) and Yang et al. (2020)
captured the aleatoric uncertainty by imposing a probabilistic distribution on poses and used the
second moment prediction as an uncertainty measure. Recently, Loquercio et al. (2020) showed that
a combined epistemic-aleatoric uncertainty framework (Kendall & Gal, 2017) could improve the
performance on several robotics tasks such as motion and steering angle predictions. In contrast to
them, our framework provides a built-in and efficient uncertainty measure that accounts for both
uncertainty types. We empirically demonstrate how to use this uncertainty measure to evaluate data
quality and system biases. Accordingly, we propose a refined inference procedure that discards highly
uncertain results to improve pose prediction accuracy.
3	Information-Theoretic Odometry Learning
Odometry aims to predict the relative 6-DOF pose ξt between two consecutive observations
{ot(-m1):t }mM=1 from M sensors (e.g. camera, IMU and lidar), where t is the time index. This
pose prediction problem can be formulated as ξt = g({ot(-m1):t}mM=1, Θ), where g is the mapping
function of an odometry system and Θ is the parameter set of g . Classic deep odometry learning
methods model g by neural networks and learn Θ from training data. Furthermore, they usually use a
recurrent module to model the motion dynamics of the observation sequence. Figure 1(a) shows a
typical procedure shared by representative deep odometry learning methods.
3
Under review as a conference paper at ICLR 2021
In many settings, observations are of high dimensionality, such as images and lidar 3D points.
Geometry methods use low-dimensional features to represent observations, while learning-based
methods learn a representation from training data. However, both features may contain pose-irrelevant
information that are specific to certain sensor domain. Retaining such information encourages the
model to overfit the training data and yield poor generalization performance. Since parsimony is
preferred in machine learning, it is expected to eliminate those pose-irrelevant information.
To this end, we tackle this problem by explicitly introducing a constraint on the pose-irrelevant
information. Specifically, we quantify the pose-irrelevance and the usefulness of a latent repre-
sentation for pose prediction from an information-theoretic perspective. By assuming the latent
representation St at time t is drawn from a Gaussian distribution, the MII({o^T}M=ι∖∣sι^τ∣ξi:T)
and the MII(ξi:T||si：T) can provide quantitative measures for the aforementioned two aspects.
Accordingly, given a sequence of observations {o∖mT}M=ι and pose annotations gi：T from time 1 to
T, our information-theoretic odometry learning problem is:
maxΘ J ⑼=I (ξ1,T ||s1:T ) - YI ({o1m)}mM=1||s1:T lξ1:T ),	⑴
where γ controls the trade-off between the two MI terms. By Equation 1, the latent representation
si:T essentially provides an information bottleneck between poses and observations, which eliminates
pose-irrelevant information from the observations. Due to the high dimensionality of the observation
space, it is non-trivial to calculate the two MI. Thus we optimize a variational lower bound instead:
T
J (⑼ ≥J0(θ)	=	EsLT ,{θ1m)}M=1,ξl:T Xt=I(Jre -YJbottleneck)],	⑵
Jpose	=	log qθ(gt|st),	(3)
Jbottleneck	=	Dkl [pφ (st∣{o"t}M=ι ,st-i )|扇(st∣ξt,st-i)]∙	(4)
The detailed derivation is provided in the Appendix. This lower bound consists of a variational
pose regressor qθ(ξt∣st), an observation-level transition model Pφ(st∣{o(m)"mM=ι, st-ι), and a
pose-level transition model q^(st∣ξt, st-ι), all modeled by neural networks. For simplicity, we
denote the representations from the observation-level and pose-level transition models sto and stp ,
respectively. In practice, sto is used for the pose regressor. Intuitively, minimizing the KL divergence
in Equation 4 forces the distribution of sto to approximate that of stp which does not encode the
observation information at time t, thus regularizing sto for containing pose-irrelevant information.
Stochastic-only transition models, however, may compromise model performance due to uncertainty
accumulation during the sampling process. To address this problem, we further introduce a deter-
ministic component according to Chung et al. (2015) and Hafner et al. (2019). In doing so, we
reformulate the two transition models in the KL divergence in Equation 4 as:
ObSerVation-level ： Pφ(4 solho), ho = f o(ho-ι, {o(m):t}mM=i, so-ι, sp-ι),	⑸
pose-level : qψ(Sp|hp), hp = fp(hp-i, ξt, so-i, sp-i).	⑹
We use two deterministic functions fo and fp for observation- and pose-level transtions, respectively,
which are modeled by recurrent neural networks. Both sto-i and stp-i are used for the two deteministic
transition functions to help to reduce the KL divergence between the distributions of sto and stp .
Ground-truth 6-DOF poses are fed into fp during the training phase while for testing we use predicted
poses to provide a runtime estimate of stp. Figure 1(b) shows the overall framework of our method.
Since we model the latent representation in the probabilistic space, the variance of the latent represen-
tation naturally provides an uncertainty measure. We empirically show how this intrinsic uncertainty
reveals data quality and system bias in Section 5.3. Of note is that it is straight forward to extend the
proposed information-theoretic framework to different problem settings. We can add arbitrary linear
MI constraints into the proposed objective and derive similar variational bounds to satisfy different
requirements such as dynamics-awareness in complex environments.
4	Theoretical Analysis
Formulating a problem in information-theoretic language enables us to analyze the proposed method
by exploring elegant tools in information theory (Cover & Thomas, 1991) and related results in
4
Under review as a conference paper at ICLR 2021
learning theory (Xu & Raginsky, 2017; Zhang et al., 2018). In this work, we show that the MI
between the bottleneck and observations as well as the latent space dimensionality upper bound the
expected generalization error, which provides not only insights into the generalizability of the method
but also a performance guarantee. To our knowledge, this is the first time that such generalization
bounds have been derived for IB by using a general loss function other than cross-entropy (Vera et al.,
2018). By replacing the general loss function with the cross-entropy, our bound is tighter than that
obtained by Vera et al. (2018) in terms of the sample size. We further derive a lower bound on the
MI between the latent representation and poses given extra sensors, which suggests what features
make a sensor useful for pose prediction in information-theoretic language. The connection between
information bottleneck and geometry based methods is also established to provide further insights.
4.1	Generalization B ound for Information Bottleneck
Xu & Raginsky (2017) and Zhang et al. (2018) obtained the generalization bound w.r.t. the MI
between input data X and learning parameters Θ for general learning algorithms and neural networks.
However, what IB regularizes is the MI between X and the latent representation. To derive a
generalization bound for the IB objective function, we first prove a relationship between these two
kinds of MI in Lemma 2 under the Markov chain X → S → ξ, an underlying assumption for IB.
Lemma 1. If X → S → ξ forms a Markov chain and assume ξ = g(X, Θ) is a one-to-one function
w.r.t. X and Θ, then we have
I(X, S) ≥ I(X, ξ)= I(X, Θ) + Eθ[H(X∣θ)] ≥ I(X, Θ).	(7)
Lemma 2 enables us to extend the generalizability results for neural networks regarding
I(X, Θ) (Zhang et al., 2018) to the IB setting, leading to the following theoretical counterpart:
Theorem 1. Assuming X → S → ξ is a Markov chain, the loss function l(X, Θ) is sub-σ-Gaussian
distributed1 and the prediction function ξ = g(X, Θ) is a one-to-one function w.r.t. the input data
and network parameters Θ, we have the following upper bound for the expected generalization error:
L 1	2σ2
E[R(⑼-RT(⑼]≤ exp(-2%NE(X⑸,
(8)
where L, η, and n are the effective number of layers causing information loss, a constant smaller
than 1, and the sample size, respectively. R(Θ) = EX〜D [l(X, Θ)] is the expected loss value given
Θ and Rt(Θ) = 1 En=I l(Xi, Θ) is a sample estimate of R(Θ) from the training data.
The difference between our result and previous work is that we bound the generalization error
by I(X, S) which is minimized in Equation 1 rather than I(X, Θ) which is hard to evaluate. By
Theorem 3, we show that minimizing the MI between the bottleneck and observations tightens
the upper bound on the expected generalization error and thus provides a theoretical performance
guarantee. It is worth noting that our theoretical results apply not only to our odometry learning
setting but also to a wider variety of tasks which use the IB method. This bound also implies that a
larger sample size and a deeper network lead to better generalization performance, which is consistent
with the results in Xu & Raginsky (2017) and Zhang et al. (2018). The detailed proof and further
discussion of Lemma 2 and Theorem 3 can be found in the Appendix.
4.2	Generalization B ound for Latent Dimensionality
We further investigate the generalizability w.r.t. model complexity in terms of the cardinality and
dimensionality of the latent representation space under the IB framework.
Corollary 1. Given the same assumptions in Theorem 3 and let |S| be the cardinality of the latent
representation space, we have
L 1 2σ2
E[R(⑼-RT(O)] ≤ eχp(-2 ιogη W—ιogιS 1.
1Recall that a random variable l is sub-σ-Gaussian distributed if E[eλ(l-E[l])] ≤
(9)
λ2σ2
e, ∀ λ ∈ R.
5
Under review as a conference paper at ICLR 2021
It is well recognized that a large model complexity can impair the model generalizability. We reveal
this complexity-overfitting trade-off in Corollary 3, where the expected generalization error is upper
bounded by the cardinality of the latent representation space. Considering the model design and
sample collection, Corollary 3 indicates that the growing rate of log|S | should not exceed that of n to
avoid an exploded generalization error bound.
Corollary 2. Given the same assumptions in Theorem 3 and assume S lies in a d-dimensional sub-
space of the latent representation space, supsi∈Si ||si|| ≤ M, ∀i ∈ [1, d] and S can be approximated
by a densely quantized space, the following generalization bound holds:
E[R(⑼-RT⑼] ≤ exp(-2iog1)σydion(d)+2log(2M)d+n/|-d(n).	(IO)
In practice, it is usually difficult to evaluate log|S| in Corollary 3 numerically. Therefore, we leverage
the quantization trick used in Xu & Raginsky (2017) to reduce the upper bound to a function w.r.t.
the dimensionality dof the latent representation space. The result is given in Corollary 4, which
suggests that the growing rate of d should not exceed that of n/log(n). It is worth noting that this
result holds not only for IB but also for a broader range of encoder-decoder models under the Markov
chain assumption on X → S → ξ.
4.3	Predictability Bound for Extra Sensors
Odometry performance is highly dependent on the sensors deployed, yet it remains non-trivial to
select informative sensors that guarantee a performance gain. In this section, we address this problem
using information-theoretic language under our proposed framework.
Theorem 2. If ({o(m)}mM=1, o(M+1)) → S → ξ forms a Markov chain, then we have,
I(ξ∣∣s) ≥I®{o(m)}m=i)+i@o(M+i)i{o(m)}m=i)-i(o(M+i)ii{o(m)}m=ι∣ξ).(“)
Theorem 4 suggests that if a new sensor o(M+1) is useful for pose prediction, the MI between o(M+1)
and poses given existing sensors should be large. Meanwhile, it is preferred to have a small MI
between {o(m)}(mM=)1 and o(M+1) given pose information. In other words, a heterogenous sensor
that shares little pose-irrelevant information with existing sensors is desirable. The information gain
between I (ξ ||o(M+1)|{o(m)}M=i) and I(o(M+1)||{o(m)}M=∕ξ) provides a theoretical guarantee
for the performance of the learned latent representation.
4.4	Connection with Geometry Methods
More generally, an odometry system can be modeled as h(zk,j,vk,Xk) → (Xk,pj) where
zk,j,vk,xk,xk and Pj are observations, noise, prior pose, posterior pose, and latent state,
respectively. At this level, the bottleneck MI I(zkj,vk∣∣Pj∣Xk) = H[h(zk,j, Vk,Xk)∣χ^k]-
H[h(zk,j, Vk, ^Xk)∣x^k,zkj,vk] is the extra entropy (∆H) introduced by (zkj,Vk), which differs
for different h. Factor graph based methods use optimization over L2 costs as h, where pj is inferred
landmark and a Gaussian noise is assumed. ∆H in this case is implied in the noise variance which
corresponds to the pre-specified weight of each cost function. Learning based methods learn h from
data where pj is the latent feature. Minimizing ∆H means reducing the uncertainty from noise and
inexact learned function forms. The same analysis applies to kinematic function for xXk. Besides,
filter-based methods can also be included in by following the same logic. Take the kinematics part
of Kalman filter (linear Gaussian system) as an example: Xk = Akxk-i + Uk + Wk, where the
prior xk is the latent state and the variance of xk-i and Wk are ∑k-1 and R, respectively. Then
I(uk,Wk∖∖xk) = 2ln(∣Ak∑k-ιAT + R|/|Ak∑k-ιAT|), suggesting that a smaller bottleneck MI
corresponds to a relatively smaller noise variance.
5	Experiments
We tested our method on the well-known KITTI (Geiger et al., 2013) and EuRoC (Burri et al.,
2016) datasets. Since most existing supervised methods are not open source, we re-implemented
6
Under review as a conference paper at ICLR 2021
LUO4-0」
U04B-SUB-
Table 1: Test results on KITTI and EuRoC. We
report the average RMSES for translation and rota-
tion, respectively. ↑: Results of MSCKF on KITTI
and OKVIS on EuRoC are from Chen et al. (2019).
Model	KITTI		EuRoC	
	t(m)	r(o)	t(m)	r(o)
DeepVO	0.0658	0.0942	0.0323	0.2114
InfoVO	0.0607	0.0869	0.0310	0.2061
MSCKF/OKVISt	0.116	0.044	0.0283	0.0402
VINet	0.0629	0.0453	0.0281	0.0729
SoftFusion	0.0629	0.0517	0.0281	0.0672
HardFusion	0.0618	0.0447	0.0285	0.0740
InfoVIO	0.0580	0.0416	0.0276	0.0744
SoftInfoVIO	0.0618	0.0438	0.0272	0.0743
HardInfoVIO	0.0559	0.0454	0.0291	0.0763
Uo-Ieoj
* PoS 0
Pos 1
PoS 2
Pos 3
pos 4
0.0105	0.0110	0.0115	0.0120
Average latent variance
.・⅞•
UO4B-SUB-
Average latent variance
Figure 2: Visualization of intrinsic uncertainty
vs. rotation and translation. Top: KITTI. Bot-
tom: EuRoC. ↑: rotation for turning left or
right. t translation towards the forward direc-
tion. pos: the evaluated position.
the representative state-of-the-art methods including DeepVO (Wang et al., 2017), VINet (Clark
et al., 2017), and two attention-based visual-inertial methods recently proposed by Chen et al.
(2019), namely, SoftFusion and HardFusion, as our baselines. All models shared the same network
architecture for a fair comparison. We also conducted extensive ablation studies on the deterministic
component, the sample size, extra sensors and the intrinsic uncertainty measure.
5.1	Datasets and Experimental Settings
The KITTI odometry dataset consists of 11 real-world car driving videos and calibrated ground-truth
6-DOF pose annotations. The EuRoC dataset was instead collected from a MAV in two buildings,
resulting in 11 sequences of different difficulties by manually adjusted obstacles. For visual-inertial
experiments, we manually aligned the 100 Hz IMU records in the raw KITTI dataset to the 10 Hz
image sequences using the corresponding timestamps. The image and IMU sequences in EuRoC were
downsampled to 10 Hz and 100 Hz, respectively. We split the training and test datasets following
the recent work by Chen et al. (2019). Our implementation was based on PyTorch (Steiner et al.,
2019) and we will release the source code package and the trained models. We used GRU (Cho
et al., 2014) to model the deterministic transitions and IMU records. Pretrained FlowNet was used
to extract features from image data (Dosovitskiy et al., 2015; Ilg et al., 2017). The other parts were
modeled by MLP layers. More details are given in the Appendix.
5.2	Main Results
We implemented our visual-inertial framework using three fusion strategies proposed in Chen et al.
(2019), namely InfoVIO, SoftInfoVIO, and HardInfoVIO. We also included two traditional visual-
inertial odometry methods for comparison, i.e., OKVIS (Leutenegger et al., 2015) for EuRoC and
MSCKF (Hu & Chen, 2014) for KITTI. OKVIS is not used for KITTI due to the lack of accurate
time synchronization between images and IMU data. Following Sturm et al. (2012) and Chen et al.
(2019), we report the average root mean squared errors (RMSEs) of translation and rotation. The
results are given in Table 1. Our results support the effectiveness of IB w.r.t. the generalizability to
test data. Specifically, our basic models (InfoVO/InfoVIO) outperformed all baselines w.r.t. both
metrics on KITTI and the translation error on EuRoC. Visual odometry models performed well for
translation prediction while incorporating IMU significantly improved the rotation results. Since the
MAV trajectories are challenging w.r.t. rotation, the traditional method (OKVIS) still outperformed
the other methods, although our result was competitive with the other learning-based baselines.
Our re-implementation achieved a better result on KITTI compared with Chen et al. (2019) but the
performance on EuRoC degraded. Since EuRoC is much more challenging than KITTI, reducing the
performance gap on EuRoC may require more carefully designed training strategies. Comparisons
between the two datasets are given in the Appendix. We will fine-tune on EuRoC in a future study.
Ablation studies: Extensive ablation studies were conducted to examine the effects of (1) the
deterministic component, (2) sample size and (3) extra sensors. Key observations include: (1)
7
Under review as a conference paper at ICLR 2021
Table 2: Results on KITTI by evaluating at different
positions in a clip.
t(m)	pos-0	pos-1	pos-2	pos-3	pos-4
DeepVO	0.0734	0.0681	0.0661	0.0658	0.0659
InfoVO	0.0689	0.0631	0.0618	0.0608	0.0604
VINet	0.0683	0.0645	0.0645	0.0632	0.0615
InfoVIO	0.0671	0.0602	0.0586	0.0580	0.0572
r(o)	pos-0	pos-1	pos-2	pos-3	pos-4
DeepVO	0.0970	0.0949	0.0939	0.0940	0.0951
InfoVO	0.0904	0.0881	0.0871	0.0869	0.0872
VINet	0.0463	0.0455	0.0454	0.0454	0.0456
InfoVIO	0.0427	0.0417	0.0420	0.0420	0.0421
Average latent variance	AVerage latent variance
Figure 3: Visualization of intrinsic uncer-
tainty for degraded data on KITTL ↑: rota-
tion for turning left or right. J: translation
towards the forward direction.
Without the deterministic component, both translation and rotation performance dropped significantly;
(2) A larger sample size reduces both the uncertainty and prediction errors; and (3) IMU is more
‘useful’ than cameras for rotation prediction while cameras are more crucial than IMU for translation
prediction, according to the discussions on Theorem 2. Detailed results are provided in the Appendix.
5.3	What Does the Intrinsic Uncertainty Mean?
We next used the average variance of the stochastic latent representation as an intrinsic uncertainty
measure and empirically showed how this uncertainty reveals the system properties and data degra-
dation. We found some interesting relationships between the uncertainty and poses, i.e., larger
turning angles and smaller forward distances lead to higher uncertainty, as shown in Figure 2. The
reason can be that a large forward parallax provides more distinctive matching features for pose
prediction while a large turning angle instead dramatically reduces the shared visible areas and
results in difficulties to achieve accurate prediction. Our analysis suggests a practical data collection
guideline, i.e., augmenting the uncertain parts of the pose distribution.
Uncertainty w.r.t. the evaluated position in a clip: We trained and evaluated the odometry model
in a clip-wise manner. Surprisingly, the evaluated position for a frame-pair in consecutive clips
significantly affected the intrinsic uncertainty, as shown in Figure 2. This makes sense in that
when evaluated at a latter position of a clip, the prediction model can leverage more information
accumulated from former observations, thus leading to more confident predictions. In Table 2, we
show that, in general, a larger uncertainty results in a higher prediction error. The result also holds
for the deterministic DeepVO and VINet baselines, implying that this is a structural system problem
in the clip-wise recurrent models. Based on this observation, we propose a simple refinement strategy
that eliminates results from the most uncertain position (pos-0) and averagely ensembles the rest. We
report the refined evaluation results for all models in our main results and ablation studies.
Failure-awareness: We show that the intrinsic uncertainty measure is failure-aware, which is crucial
for a robust odometry system. We present the results from noisy and missing data on KITTI in
Figure 3. Our model becomes more uncertain as the data degrades. The uncertainty reaches highest
when the data is missing, as expected. More interestingly, for InfoVIO the quality of IMU data
dominates the uncertainty, implying that current learned models focus more on IMU data and that a
better image encoder is desirable. Degradation details and extended results are given in the Appendix.
6	Conclusion
This paper targets odometry learning by proposing an information-theoretic framework that leverages
an IB-based objective function to eliminate the pose-irrelevant information. A recurrent deterministic-
stochastic transition model is introduced to facilitate the modeling of time dependency of the observa-
tion sequences. The proposed framework can be easily extended to different problem settings and
provide not only an intrinsic uncertainty measure but also an elegant theoretical analysis tool for eval-
uating the system performance. We derive generalization error bounds for the IB-based method and a
predictability lower bound for the latent representation given extra sensors. They provide theoretical
performance guarantees for the proposed framework, and more generally, information-bottleneck
based methods. Extensive experiments on KITTI and EuRoC support our discoveries.
8
Under review as a conference paper at ICLR 2021
References
Alexander A. Alemi, Ian Fischer, Joshua V. Dillon, and Kevin Murphy. Deep variational information
bottleneck. In ICLR 2017 : International Conference on Learning Representations 2017, 2017.
JiaWang Bian, Zhichao Li, Naiyan Wang, Huangying Zhan, Chunhua Shen, Ming-Ming Cheng, and
Ian Reid. Unsupervised scale-consistent depth and ego-motion learning from monocular video. In
NeurIPS 2019: Thirty-third Conference on Neural Information Processing Systems, pp. 35-45,
2019.
Lars Buesing, TheoPhane Weber, Sebastien Racaniere, S. M. Ali Eslami, Danilo Jimenez Rezende,
David P. Reichert, Fabio Viola, Frederic Besse, Karol Gregor, Demis Hassabis, and Daan Wier-
stra. Learning and querying fast generative models for reinforcement learning. arXiv preprint
arXiv:1802.03006, 2018.
Michael Burri, Janosch Nikolic, Pascal Gohl, Thomas Schneider, Joern Rehder, Sammy Omari,
Markus W Achtelik, and Roland Siegwart. The euroc micro aerial vehicle datasets. The Interna-
tional Journal of Robotics Research, 35(10):1157-1163, 2016.
Pratik Chaudhari, Anna Choromanska, Stefano Soatto, Yann LeCun, Carlo Baldassi, Christian Borgs,
Jennifer Chayes, Levent Sagun, and Riccardo Zecchina. Entropy-sgd: Biasing gradient descent
into wide valleys. international conference on learning representations, 2019(12):124018, 2017.
Changhao Chen, Stefano Rosa, Yishu Miao, Chris Xiaoxuan Lu, Wei Wu, Andrew Markham, and
Niki Trigoni. Selective sensor fusion for neural visual-inertial odometry. In 2019 IEEE/CVF
Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10542-10551, 2019.
Changhao Chen, Bing Wang, Chris Xiaoxuan Lu, Niki Trigoni, and Andrew Markham. A survey on
deep learning for localization and mapping: Towards the age of spatial machine intelligence. arXiv
preprint arXiv:2006.12567, 2020.
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for
statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in
Natural Language Processing (EMNLP), pp. 1724-1734, 2014.
Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron Courville, and Yoshua Bengio. A
recurrent latent variable model for sequential data. In NIPS’15 Proceedings of the 28th International
Conference on Neural Information Processing Systems - Volume 2, pp. 2980-2988, 2015.
Ronald Clark, Sen Wang, Hongkai Wen, Andrew Markham, and Niki Trigoni. Vinet: Visual inertial
odometry as a sequence to sequence learning problem. In Thirty-First AAAI Conference on
Artificial Intelligence, pp. 3995-4001, 2017.
Thomas M. Cover and Joy A. Thomas. Elements of information theory. 1991.
Bin Dai, Chen Zhu, and David Wipf. Compressing neural networks using the variational information
bottelneck. In ICML 2018: Thirty-fifth International Conference on Machine Learning, pp.
1135-1144, 2018.
Alexey Dosovitskiy, Philipp Fischery, Eddy Ilg, Philip Hausser, Caner Hazirbas, Vladimir Golkov,
Patrick van der Smagt, Daniel Cremers, and Thomas Brox. Flownet: Learning optical flow with
convolutional networks. In 2015 IEEE International Conference on Computer Vision (ICCV), pp.
2758-2766, 2015.
H. Durrant-Whyte and T. Bailey. Simultaneous localization and mapping: part i. IEEE Robotics &
Automation Magazine, 13(2):99-110, 2006.
Jorge Fuentes-Pacheco, Jose Ruiz-Ascencio, and Juan Manuel Rendbn-Mancha. Visual simultaneous
localization and mapping: a survey. Artificial Intelligence Review, 43(1):55-81, 2015.
Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: representing model
uncertainty in deep learning. In ICML’16 Proceedings of the 33rd International Conference on
International Conference on Machine Learning - Volume 48, pp. 1050-1059, 2016.
9
Under review as a conference paper at ICLR 2021
A Geiger, P Lenz, C Stiller, and R Urtasun. Vision meets robotics: The kitti dataset. The International
JournalofRoboticsResearch, 32(11):1231-1237, 2013.
Anirudh Goyal Alias Parth Goyal, Riashat Islam, DJ Strouse, Zafarali Ahmed, Hugo Larochelle,
Matthew Botvinick, Sergey Levine, and Yoshua Bengio. Infobot: Transfer and exploration via the
information bottleneck. In ICLR 2019 : 7th International Conference on Learning Representations,
2019.
Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, and James
Davidson. Learning latent dynamics for planning from pixels. In ICML 2019 : Thirty-sixth
International Conference on Machine Learning, pp. 2555-2565, 2019.
Danijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mohammad Norouzi. Dream to control: Learning
behaviors by latent imagination. In ICLR 2020 : Eighth International Conference on Learning
Representations, 2020.
Jwu-Sheng Hu and Ming-Yuan Chen. A sliding-window visual-imu odometer based on tri-focal
tensor geometry. In 2014 IEEE International Conference on Robotics and Automation (ICRA), pp.
3963-3968, 2014.
Eddy Ilg, Nikolaus Mayer, Tonmoy Saikia, Margret Keuper, Alexey Dosovitskiy, and Thomas Brox.
Flownet 2.0: Evolution of optical flow estimation with deep networks. In 2017 IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), pp. 1647-1655, 2017.
Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer
vision. In NIPS’17 Proceedings of the 31st International Conference on Neural Information
Processing Systems, pp. 5580-5590, 2017.
Alex Kendall, Matthew Grimes, and Roberto Cipolla. Posenet: A convolutional network for real-time
6-dof camera relocalization. In 2015 IEEE International Conference on Computer Vision (ICCV),
pp. 2938-2946, 2015.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In ICLR 2014 : International
Conference on Learning Representations (ICLR) 2014, 2014.
Stefan Leutenegger, Simon Lynen, Michael Bosse, Roland Siegwart, and Paul Furgale. Keyframe-
based visual-inertial odometry using nonlinear optimization. The International Journal of Robotics
Research, 34(3):314-334, 2015.
Antonio Loquercio, Mattia Segu, and Davide Scaramuzza. A general framework for uncertainty
estimation in deep learning. In 2020 IEEE International Conference on Robotics and Automation
(ICRA), 5(2):3153-3160, 2020.
David J. C. MacKay. A practical bayesian framework for backpropagation networks. Neural
Computation, 4(3):448-472, 1992.
Valentin Peretroukhin and Jonathan Kelly. Dpc-net: Deep pose correction for visual localization.
international conference on robotics and automation, 3(3):2424-2431, 2017.
Ben Poole, Sherjil Ozair, Aaron van den Oord, Alexander Alemi, and George Tucker. On variational
bounds of mutual information. In ICML 2019 : Thirty-sixth International Conference on Machine
Learning, pp. 5171-5180, 2019.
Anurag Ranjan, Varun Jampani, Lukas Balles, Kihwan Kim, Deqing Sun, Jonas Wulff, and Michael J.
Black. Competitive collaboration: Joint unsupervised learning of depth, camera motion, optical
flow and motion segmentation. In 2019 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 12240-12249, 2019.
Ravid Shwartz-Ziv and Naftali Tishby. Opening the black box of deep neural networks via information.
arXiv preprint arXiv:1703.00810, 2017.
10
Under review as a conference paper at ICLR 2021
Benoit Steiner, Zachary DeVito, Soumith Chintala, Sam Gross, Adam Paszke, Francisco Massa, Adam
Lerer, Gregory Chanan, Zeming Lin, Edward Yang, Alban Desmaison, Alykhan Tejani, Andreas
Kopf, James Bradbury, Luca Antiga, Martin Raison, Natalia Gimelshein, Sasank Chilamkurthy,
Trevor Killeen, Lu Fang, and Junjie Bai. Pytorch: An imperative style, high-performance deep
learning library. In NeurIPS 2019 : Thirty-third Conference on Neural Information Processing
Systems,pp. 8026-8037, 2019.
Jrgen Sturm, Nikolas Engelhard, Felix Endres, Wolfram Burgard, and Daniel Cremers. A benchmark
for the evaluation of rgb-d slam systems. In 2012 IEEE/RSJ International Conference on Intelligent
Robots and Systems, pp. 573-580, 2012.
Takafumi Taketomi, Hideaki Uchiyama, and Sei Ikeda. Visual slam algorithms: a survey from 2010
to 2016. IPSJ Transactions on Computer Vision and Applications, 9(1):16, 2017.
Naftali Tishby and Noga Zaslavsky. Deep learning and the information bottleneck principle. In 2015
IEEE Information Theory Workshop (ITW), pp. 1-5, 2015.
Naftali Tishby, Fernando C. N. Pereira, and William Bialek. The information bottleneck method.
Proc. 37th Annual Allerton Conference on Communications, Control and Computing, 1999, pp.
368-377, 2000.
Matias Vera, Pablo Piantanida, and Leonardo Rey Vega. The role of the information bottleneck in
representation learning. In 2018 IEEE International Symposium on Information Theory (ISIT), pp.
1580-1584, 2018.
Sen Wang, Ronald Clark, Hongkai Wen, and Niki Trigoni. Deepvo: Towards end-to-end visual odom-
etry with deep recurrent convolutional neural networks. In 2017 IEEE International Conference
on Robotics and Automation (ICRA), pp. 2043-2050, 2017.
Sen Wang, Ronald Clark, Hongkai Wen, and Niki Trigoni. End-to-end, sequence-to-sequence
probabilistic visual odometry through deep neural networks:. The International Journal of Robotics
Research, 37:513-542, 2018.
Aolin Xu and Maxim Raginsky. Information-theoretic analysis of generalization capability of learning
algorithms. In 31st Annual Conference on Neural Information Processing Systems, NIPS 2017, pp.
2524-2533, 2017.
Fei Xue, Xin Wang, Shunkai Li, Qiuyuan Wang, Junqiu Wang, and Hongbin Zha. Beyond tracking:
Selecting memory and refining poses for deep visual odometry. In 2019 IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR), pp. 8575-8583, 2019.
Nan Yang, Lukas von Stumberg, Rui Wang, and Daniel Cremers. D3vo: Deep depth, deep pose and
deep uncertainty for monocular visual odometry. arXiv preprint arXiv:2003.01060, 2020.
Zhichao Yin and Jianping Shi. Geonet: Unsupervised learning of dense depth, optical flow and
camera pose. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.
1983-1992, 2018.
Huangying Zhan, Chamara Saroj Weerasekera, Jiawang Bian, and Ian D. Reid. Visual odometry
revisited: What should be learnt? arXiv preprint arXiv:1909.09803, 2019.
Jingwei Zhang, Tongliang Liu, and Dacheng Tao. An information-theoretic view for deep learning.
arXiv preprint arXiv:1804.09060, 2018.
Tinghui Zhou, Matthew Brown, Noah Snavely, and David G. Lowe. Unsupervised learning of
depth and ego-motion from video. In 2017 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 6612-6619, 2017.
11
Under review as a conference paper at ICLR 2021
A Appendix
A. 1 Derivation of the Variational Lower B ound
By the well-established variational bounds for mutual information (MI) (Kingma & Welling, 2014;
Alemi et al., 2017; Poole et al., 2019), we directly have a lower bound and a upper bound for the first
and second MI in Equation 1, respectively:
I(&：T||s1：T) ≥ EsLT,ξLτ[log q(&：Tls1:T儿	(12)
IHoIm)}M=1||S1：Tlξ1:T) ≤ E{o(m)}M= ]&:T[DKL[P(SLTKoIm)}M=I,ξ1:T)|Iq(SLT归上T)]]. (13)
Also, it is straightforward to show that Ex,y [f (x)] = Ex [f (x)] if f (x) is a function that does not
depend on y:
Ex,y [f (x)] =	p(x, y)f (x)dxdy =	[ p(x)p(y|x)dy]f (x)dx
=	p(x)[ p(y|x)dy]f (x)dx =	p(x)f (x)dx = Ex[f(x)].
(14)
(15)
Thus, We change the subscripts of the expectations in Equations 12-13 to si：T, ξ±T, {o1m)}M=「For
simplicity, we omit the subscripts and denote {o(1m:T)}mM=1 as o1:T in the rest of the derivation. We
assume Markov property for this sequence processing problem. Then the right-hand side (RHS) of
Equation 12 becomes:
E[log q(ξ1：τ|si：T)] = E[log Y q(ξtlst)] = E[Xlog q(ξtlst)].	(16)
t=1	t=1
The formulation of information bottleneck implies that ξ → o → S forms a Markov chain, since
the feature encoder for S only depends on the input data o (Tishby et al., 2000; Alemi et al., 2017).
Therefore, We have p(si：T|oi：T,ξi:T) = p(si：T|oi：T). Then by Equation 15 and the Markov
assumption, the KL divergence term inside the expectation in the RHS of Equation 13 becomes:
Dkl[p(s1:T |o1:T, ξl:T )∣∣q(si:T ∣ξl:T )]
Z P(si:TIoi7,ξi:T)logP(Si-Tlo1,T,ξVT) dsi：T
Js1:T	q(si:T lξ1,T)
∕i:TP(SLT lo1,T ,ξ1,T )logp(≡⅛T
dS1T
T
P	P(S1:T|oi：T,ξi:T)log Y P Stt °t-1,t, st-1 dsi,T
Jsi:T	十[q(st lξt ,st-1)
1:T	t=1
T
LFSTio1：T, ξ1,T)X l/qts：-；;-;-	dsi：T
(17)
(18)
(19)
(20)
(21)
T
Es1:T [log
t=1
P(StIot-i:t, St-1)
q(stlξt ,St-1)
T
]=XEst [log
t=1
P(StIot-1：t, St-1)
q(stlξt, St-1)
(22)
]
T
DKL[P(StIot-1:t, St-1)IIq(StIξt, St-1)]
t=1
(23)
By sending Equation 16 and Equation 23 to Equation 12 and Equation 13,respectively, We obtain the
loWer bound of the information bottleneck objective for odometry learning (Equation 2-4).
Remark: All variational IB-based methods origin from Alemi et al. (2017) (Equations 12-13).
HoWever, applying IB into a specific domain is non-trivial. The challenge lies in the derivation
of proper variational bounds based on specific properties of each problem. This derivation can be
12
Under review as a conference paper at ICLR 2021
more delicate if we incorporate more constraints, potentially from geometric and kinematic insights.
Besides, we differ from Dai et al. (2018) and Goyal et al. (2019) in that sequential observations are
modeled. From this perspective, our development related to Hafner et al. (2019) and Hafner et al.
(2020), from which we further borrowed the motivation of the deterministic component, which by
itself is rooted from Chung et al. (2015) and Buesing et al. (2018). Ours differs in that we model the
two transition models (Equation 4) separately, each with a deterministic component to improve model
capacity (Figure 1(b) and Equations 5-6). Moreover, we theoretically prove that constraining the IB
objective essentially upper bounds the expected generalization error and establish the connection
between IB and geometry methods, which provides deeper insights into IB-based methods.
A.2 Proof of Lemmas, Theorems, and Corollaries
Lemma 2. If X → S → ξ forms a Markov chain and assume ξ = g(X, Θ) is a one-to-one function
w.r.t. X and Θ, then we have
I(X||S) ≥ I(X∣∣ξ) = I(X∣∣θ) + Eθ[H(X∣θ)] ≥ I(XI∣θ).	(24)
Proof: By assuming that g is a one-to-one function, We have p(ξ) = p(x, θ) for an instantiation
g : x, θ → ξ for ξ = g(X, Θ). Then We have:
I(Xllξ) = p pP(x,ξ)log
xξ
p(x, ξ)
p(x)p(ξ)
dxdξ
(25)
Z Z	p(x, (χ0, θ))ιogp(x,(X ,0θ)) dχd(χ0, θ)
x (x0 ,θ)	p(x)p(x0, θ)
p(x, (x, θ))
( 6)P(x, (x,θ))logp(x)p(x θ) d(x,θ)
+ ZZ	P(X, (χ0,θ))logp(x;(X ,0θ)) dχd(χ0,θ).
x (x0 6=x,θ)	p(x)p(x0, θ)
(26)
(27)
(28)
Because ∀x 6= x0, p(x, (x0, θ)) = 0 and lim alog(a) = 0, We have:
a→0
/ /"W)p(x, (X θ))logP(X)PXχ0θ)) dxd(χ0,θ)=0.
(29)
By p(x, (x, θ)) = p(x|x, θ)p(x, θ) = p(x, θ), we have:
p(x, (x, θ))
J(x,θ)P3 (x,θ))l0gp(x)p(x,θ) d(x,θ)
∕χ,jx,θ)l0gp⅛(⅛ d(x,θ)
J	p(x, θ)log ɪ d d(x, θ) = J Jp(x, θ)log [)dxdθ.
(30)
(31)
(32)
By combining Equation 29 and Equation 32 With Equation 28, I (X ∣∣ξ) becomes:
I(Xllξ) = 〃 p(x,θ)logPX dxdθ.
(33)
Recall the definition of I(X∣∣Θ):
I(Xl∣Θ) = / ∕p(x,θ)log
p(x, θ)
dxdθ = / Pp(x, θ)logPx^J dxdθ
x θ	p(x)
(34)
p(x)p(θ )
13
Under review as a conference paper at ICLR 2021
Therefore we have:
I(X∣∣θ) - I(X∣∣ξ) = / Ip(X,θ.)log(xW)dxdθ
=J Jp(θ)p(x∣θ)log(x∣θ)dxdθ
=—pp(θ)[- P p(x∣θ)log(x∣θ)dx]dθ
θx
=—Eθ[H(x∣θ)] ≤ 0
(35)
(36)
(37)
(38)
Because X → S → ξ forms a Markov chain, We have I(X∣∣ξ) ≤ I(X||S). Then by Equation 38,
Lemma 2 holds.
Theorem 3. Assuming X → S → ξ is a Markov chain, the loss function l(X, Θ) is sub-σ-Gaussian
distributed* 2 and the prediction function ξ = g(X, Θ) is a one-to-one function w.r.t. the input data
and network parameters Θ, we have the following upper bound for the expected generalization error:
L 1	2σ2
E[R(O)- RT(O)]≤ exp(-2叫MkI(X忖,
(39)
where L, η, and n are the effective number of layers causing information loss, a constant smaller
than 1, and the sample size, respectively. R(Θ) = EX〜D [l(X, Θ)] is the expected loss value given
Θ and Rt(Θ) = 1 En=I l(Xi, Θ) is a sample estimate of R(Θ) from the training data.
Proof: Assume the loss function l(X, O) is sub-σ-Gaussian distributed, Xu & Raginsky (2017) has
proven that the folloWing bound holds for general algorithms With learning parameter set O:
E[R(⑼-Rt(Θ)] ≤ J212I(X∣∣Θ).
(40)
Zhang et al. (2018) extended this result to the setting of neural netWorks and derived the generalization
bound for a neural netWork that has L layers causing information loss:
L 1 2σ2
E[R(O) - RT(O)] ≤ exp(-2 GF (RM
(41)
Where η is a constant smaller than 1. By Lemma 2 and Equation 41, Theorem 3 holds.
More discussions on Lemma 2 and Theorem 3 The result of Zhang et al. (2018) is interesting in
that it provides an explanation for Why deeper netWorks lead to better performance. HoWever, the
expected generalization errors in Xu & Raginsky (2017) and Zhang et al. (2018) are both bound by
I (X ||O), Which remains difficult to evaluate in practice. Though their results give a lot of insights
into the generalizability of algorithms in information-theoretic language, it is non-trivial to minimize
I(X ||O) explicitly to control the generalization error bound.
We move one step further by extending their results to I(X||S), the mutual information betWeen input
data and latent representations, Which itself can be bounded by various Well-established variational
bounds (Poole et al., 2019) and optimized during training. Our result provides an explanation for the
empirical generalization ability of the information bottleneck method, Which explicitly minimizes
I(X||S). By minimizing I(X||S), We are actually tightening the upper bound of the generalization
error, thus leading to better generalization performance.
A related Work by Vera et al. (2018) proved a similar result for information bottleneck: "Let F be a
class of encoders. Then, for every PXY and every δ ∈ (0, 1), With probability at least 1- δ over the
choice of Sn 〜PXY the following inequality holds YQU∣χ ∈ F:
εgap(Qu∣x, Sn) ≤ Aδ JI(PXIIQuix)* + √ + O(",	(42)
where (Aδ,Bδ,Cδ) are quantities independent of the data set Sn : Aδ := P^Bδ)(1 +
1/PlXI),Bδ :=2+ Jlog(中)and Cδ := 2∣U|e-1 + B§PMlogPYgminy. εgap(Qu∣χ,Sn
λ2σ2
2Recall that a random variable l is sub-σ-Gaussian distributed if E[eλ(l-E[l])] ≤ e~^2~
, ∀λ∈ R.
14
Under review as a conference paper at ICLR 2021
is the generalization gap which is defined as |Lemp(QU|X, Sn) - -L(QU |X)|. L(QU |X) and
Lemp (QU |X, Sn) are the true risk and the empirical risks, respectively." We refer readers to Vera
et al. (2018) for more details on their result.
Our result differs from that of Vera et al. (2018) in that: (1) Equation 42 only applies to the
cross-entropy loss function, while our result holds for a broader range of loss functions under the
sub-σ-Gaussian assumption; (2) we provide a tighter generalization bound compared with that of
Vera et al. (2018) in terms of sample rate (√n vs. lo√(nn)); (3) For regression problems and for a large
latent space, Aδ and Cδ in Equation 42 could be large due to the positive dependency on |Y | and |U|.
Besides, PX(； .)and PY(； .)might also be large in practice, resulting in a loose bound for the
generalization error.
Remark: We now give more discussions on the assumptions of Theorem 3: (1) A Markov chain
X → S → ξ is implicitly implied by neural networks with encoder-decoder structures, since the
decoder only takes the encoder output as its input and thus does not depend on X given S . The
information bottleneck model, that takes the bottleneck S as the encoder output as well as the
decoder input, is essentially encoder-decoder structured. Therefore, the Markov chain assumption
on X → S → ξ also holds for the information bottleneck methods. (2) As discussed in Xu &
Raginsky (2017), the sub-σ-Gaussian assumption actually implies a broad range of loss function.
For instance, as long as a loss function l is bounded, i.e., l(∙, ∙) ∈ [a,b], then it is guaranteed to be
sub-σ-Gaussian distributed with σ = b-a (XU & Raginsky, 2017). The network loss landscape
consists of multiple local minima, flat or sharp, and most deep learning methods assume a local
Gaussian distribution by using L2 loss (Chaudhari et al., 2017). Sub-σ-Gaussian is more general
and provides several superiority over the commonly used Gaussian assumption. Chaudhari et al.
(2017) claimed that a flat local minimum is preferred for deep learning optimization algorithms
due to the robustness towards parameter perturbations. Sub-σ-Gaussian can well represent such flat
local regions, e.g. the almost-flat bounded uniform distribution is sub-σ-Gaussian distributed. It
is also worth noting that considering the density of local minima (Chaudhari et al., 2017), σ is not
necessarily large for local regions, which can be a concern for the tightness of the generalization
bound. Another appealing property is that the sum of sub-σ-Gaussian is still sub-σ-Gaussian, i.e. it
can fit a larger region with multiple local minima. (3) The one-to-one function assumption can be
conservative due to the complexity of real-world data. For many applications, we may use pretrained
models to extract high-level features and use these features as input data. For example, a pretrained
FlowNet (Dosovitskiy et al., 2015; Ilg et al., 2017) is usually used in deep odometry learning methods.
The input data part of this assumption could arguably hold under such circumstances. Considering
the prediction part of this assumption, the cardinality of the space of ξ could be sufficiently large for
regression problems and for classification problems, the cardinality of the prediction space could also
be large since we usually predict the probabilities of each category. Extending the results to a looser
assumption on the network function remains an interesting direction for future research.
Corollary 3. Given the same assumptions in Theorem 3 and let |S| be the cardinality of the latent
representation space, we have
L 1	2σ2
E[R⑼-RT(O)]≤ exp(-2log/W^lMSt
(43)
Proof: The relationship between mutual information, entropy and the cardinality of the variable space
is well recognized, as given in Cover & Thomas (1991):
I(X||S) = H(S) - H(S|X) ≤ H(S) ≤ log|S|.	(44)
By Equation 44 and Theorem 3, Corollary 3 holds.
Corollary 4. Given the same assumptions in Theorem 3 and assume S lies in a d-dimensional sub-
space of the latent representation space, supsi∈Si ||si|| ≤ M, ∀i ∈ [1, d] and S can be approximated
by a densely quantized space, the following generalization bound holds:
E[R(⑼-RT(o)] ≤ eχp(-2 ιogη)σ^ dl0∣≡+2log(2M)d+^g(n).	附
15
Under review as a conference paper at ICLR 2021
Proof: We use the same quantization trick in Xu & Raginsky (2017). We define the covering number
κ(r, S) as the cardinality of the smallest set S0 ⊂ S s.t. ∀s ∈ S, ∃s0 ∈ S0 with ||s - s0|| ≤ r.
Assume supsi∈Si ∣∣s∕∣ ≤ M,∀i ∈ [1,d] and let r = 1∕√n, We have K ≤ (2M√dn)d (XU &
Raginsky, 2017). We give a proof below for this result, which is omitted in Xu & Raginsky (2017):
We first construct S ⊂ S that satisfies Nsi ∈ Si, ∃Si ∈ Si With ||si - s/| ≤ √ι, ∀i ∈ [1,d], where
i denotes the dimension of the d-dimensional subspace. Then S also satisfies that ∀s ∈ S, ∃sS ∈
S with:
||s - sS||
(46)
For i-th dimension, by the assumption that supsi∈Si ||si|| ≤ M, we have si ∈ [-M, M]. We can
uniformly separate the value range [-M, M] into r∕√d intervals. Since each interval has length 力,
we can construct a Si with cardinality |Si| = ^2√ by including all middle points of the intervals. Let
r = √n, we have |Si | = 2M√dn. We then construct a S by repeating this process for all dimensions.
By the denifition of κ(r, S) and Equation 46, we have:
d	d
κ(r, S) ≤ |SS| =Y|Si| = Y 2M √dn = (2M √dn)d.	(47)
i=1	i=1
When n → ∞, we have r → 0, S0 → S, and κ(r, S) → |S|. Therefore, by assuming S can be
approximated by such a densely quantized space and by Equation 47 and Corollary 3, we have:
E[R(⑼-RT(Θ)] ≤ exp(-Llog-)∖ 2σ-log(2M√dn,)d	(48)
2η n
= exp(-Llog ~)σS dlog(d) + 2log(2M) d + -ττdr^.	(49)
2 η	n	n	n/log(n)
Therefore, Corollary 4 holds.
Theorem 4. If ({o(m)}mM=1 , o(M+1)) → S → ξ forms a Markov chain, then we have,
I(ξ∣∣S) ≥ I(ξ∣∣{o(m)}m=1) +1(ξ∣lo(M+1)∣{o(m)}m=ι) -1(o(M+1)||{o(m)}m=ι∣ξ).	(50)
Proof: From Cover & Thomas (1991), the following two lemmas hold (Lemma 3 and Lemma 4):
Lemma 3. The inequality for conditional mutual information:
I(X2∣∣X1∣ξ) ≥ I(ξ∣∣X2|X1) - I(ξ∣∣X2) + I(X1∣X2).	(51)
Lemma 4. If (X1 , X2) → S → ξ forms a Markov chain, we have:
I(ξ∣∣Xι) +1(ξ∣∣X2) ≤ I(ξ∣∣S) +1(X1∣X2).	(52)
By Lemma 3 and Lemma 4, we have:
I(ξ∣∣S) ≥ I(ξ∣∣Xι) + I(ξ∣∣X2)-I(X1∣X2)	(53)
≥ I(ξ∣∣Xι) + I(ξ∣∣X2|X1) - I(X2∣∣X1∣ξ).	(54)
Let X1 and X2 denote {o(m)}mM=1 and o(M+1), respectively. Then by Equation 54, Theorem 4 holds.
16
Under review as a conference paper at ICLR 2021
A.3 Detailed Experimental Settings and More Results
A.3.1 Detailed Network Architecture
The overall network can be separated into four components: (1) Observation encoders: For image
observation, we first extract the output from the out_conv6_1 layer of a pretrained FlowNet2S (Ilg
et al., 2017) model as an intermediate high-level feature, which is then flattened and fed into three
MLP layers that have feature size 1024 to obtain image features. Note that the last MLP layer does
not use the non-linear activation. For IMU data, we use a two-layer GRU model that has feature size
1024 to extract IMU features; (2) Deterministic transition models: For observation-level transition,
we first fuse the observation features and concatenate the fused feature with sto-1 and stp-1 from last
time step. For VINet and InfoVIO, we fuse the features directly by concatenation. For SoftFusion and
SoftInfoVIO, we use the same soft fusion strategy proposed in Chen et al. (2019). For HardFusion
and HardInfoVIO, we also use the same hard fusion strategy proposed in Chen et al. (2019) while
the gumbel temperature linearly degrades from 1 to 0.5 in the first 150 epochs during training and
is fixed to 0.5 for testing. For pose-level transition, we tile the 6-DOF poses eight times to a vector
of length 48, which is then also concatenated with sto-1 and stp-1. Ground-truth 6-DOF poses are
used during training while the predicted poses are used during testing. The concatenated features
are then fed into a MLP and a GRU layer to obtain hto and htp , respectively. (3) Stochastic state
estimators: The deterministic states are fed into two MLP layers to obtain the mean and standard
error vectors of the stochastic representation, both with size 128. Note that the last MLP layer does
not use the non-linear activation. To avoid a trivial solution, we set the minimum standard error to 0.1
and only predict the residue, where the softplus function is used to guarantee a positive residue. We
further use the reparameterization trick proposed in Kingma & Welling (2014) to sample from the
stochastic representation distributions, which enables gradient backpropagation through the stochastic
representations. (4) Pose regressor: We feed the sampled observation-level representation sto into
three MLP layers to obtain the translation and rotation prediction results. Both translation and rotation
share the first two MLP layers, while we use two separate MLP layers without non-linear activation
for translation and rotation, respectively.
All MLP layers with non-linear activation use the Relu function. And all MLP layers except those in
observation encoders have feature size 256 and 512 for KITTI and EuRoC, respectively. The state size
is set to 128 and 256 for KITTI and EuRoC, respectively. For all baseline models (DeepVO, VINet,
SoftFusion, and HardFusion), we remove the pose-level transitions and stochatic state estimators and
directly feed hto into the pose regressor for prediction.
A.3.2 Detailed Training and Evaluation S trategies
We used the same training and test splits as Chen et al. (2019). For KITTI, we used sequences
00, 01, 02, 04, 06, 08, and 09 for training and the rest for testing. For EuRoC, we used sequence
MH_04_difficult for testing and the rest for training. KITTI odometry dataset does not contain
synchronized IMU data. Therefore, we manually aligned the 100 Hz IMU records in the raw
KITTI data to the 10 Hz image sequences using the corresponding timestamps. EuRoC provides
synchronized image and IMU data, collected at 20 Hz and 200 Hz, respectively. Following the
practice of previous work (Chen et al., 2019; Clark et al., 2017), we downsampled the image and
IMU data in EURoC to 10 Hz and 100 Hz. By assuming a Gaussian distribution for q®(ξt∣st), We
reduced the optimization of Equation 3 to minimizing the L2-norm of the pose errors, resulting in the
folloWing loss function:
N
L = X α∣∣t-印 + β ||r-r||,	(55)
n=1
where t and t are the ground-truth and predicted translation. r and r are the ground-truth and predicted
rotation. We used Euler angles as the quantitative rotation measure. α and β are the translation
and rotation error weights, respectively, which were set to 1 and 100 for KITTI and 100 and 20 for
EuRoC empirically. We predicted the mean and variance of the stochastic representation st and set
the minimum variance to be 0.01 to avoid a trivial solution. We set γ in Equation 1 to balance the
bottleneck effect. All modeled were trained for 300 epochs using mini-batches of 16 clips containing
five frames each. We set an initial learning rate to 1e-4, which was reduced to 1e-5 and 5e-6 at epoch
150 and 250 to stabilize the training process.
17
Under review as a conference paper at ICLR 2021
We trained and evaluated the odometry model in a clip-wise manner. For evaluation, we use a sliding
window strategy s.t. the evaluated clips are overlapped, which means a frame-pair can appear at
different positions in a clip. As discussed in Section 5.3, we use a refinement strategy that eliminates
the results from the first position and averagely ensembles the rest, which leads to better performance.
Following Sturm et al. (2012) and Chen et al. (2019), the averaged root mean squared errors (RMSEs)
were used for evaluating both translation and rotation performance.
Remark I: We tested the effectiveness of our method in the supervised odometry learning framework,
which requires ground-truth pose labels. In odometry, a good thing is that ground-truth can be
obtained from carefully setup sensor suits, which reduces human labors in annotations. Furthermore,
two recent research trends may also mitigate this problem, i.e. embodied methods that utilize
simulated environments and domain adaptation techniques, and unsupervised learning methods that
utilize geometry constraints and train the model jointly with other auxiliary tasks. It is worth noting
that our proposed method improves on the representation level and can also be applied in these fields
to obtain better latent representations.
Remark II: In odometry learning, we usually use Euler angles or quaternions for rotation representa-
tion rather than SO(3) as implied SE(3) due to the redundant parameters in the rotation matrix and the
orthogonal constraint. We adopt Euler angles in our experiments and assume a Gaussian distribution
in this vector space. Though 3D von Mises-Fisher distribution and 4D-Bingham distribution can be
arguably more appropriate to model Euler angles and quaternions respectively, it it non-trivial to
evaluate and use them for training in practice.
Remark III: In terms of the choice of hyperparameters like , β, and γ, we basically followed the
initial setup of prior works such as Wang et al. (2017); Chen et al. (2019); Hafner et al. (2020) and
perform a non-intensive and small-range grid searching. More elegant methods such as relying on the
covariance estimates (Peretroukhin & Kelly, 2017) can be considered in future study and applications
to new datasets
A.3.3 Comparison between KITTI and EuRoC
KITTI dataset is collected from an autonomous driving car in outdoor scenarios while EuRoC dataset
is collected from a MAV in two indoor buildings. Thus these two datasets have different statistics,
which may require different network design and training strategy finetuning for each dataset. More
specifically, since KITTI is collected during driving, the camera poses mainly contains forward
translations and left/right rotations, while for EuRoC, the camera poses from a MAV can have more
diverse translation and rotation distribution. As shown in Table 3, since the moving speed of a car is
higher than a MAV, the translation scale of KITTI is also larger, while the rotation scale of EuRoC is
larger than that of KITTI due to the motion features of MAV.
Table 3: Dataset statistics of KITTI and EuRoC, where the averaged L2-norm values are summarized.
x, y, z correspond to the coordinnate system used in KITTI, where x denotes the forward axis, y
denotes the upward axis, and z denotes the rightward axis. t and r are the overall L2-norm values for
the translation and rotation vectors, respectively.
	tx(m)	ty(m)	tz (m)	t(m)	rx(o)	ry(o)	rz(o)	r(o)
KITTI	0.0143	0.0195	0.9666	0.9676	0.1217	0.5381	0.1084	0.6255
EuRoC	0.0388	0.0218	0.0358	0.0660	1.0338	0.8559	0.7403	1.8660
Training a good model for EuRoC is more challenging than for KITTI. The reasons are four-folds: (1)
Compared with the similar-looking scenarios in KITTI that mainly contains street views, the scenarios
in EuRoC are more diverse, including an intrustrial machine hall and an office room; (2) EuRoC
sequences have different difficulty levels by manually adjusted obstacles, which means more carefully
designed training strategies such as curriculum learning can be used to improve the performance;
(3) The videos collected in EuRoC only contain gray-scale images while those in KITTI contain
RGB images instead. Considering the FlowNet model was pretrained using RGB images, the domain
gap for using gray-scale images should also be taken into account for better performance; (4) The
translation scale of EuRoC is much smaller, which can cause difficulty for accurate prediction.
18
Under review as a conference paper at ICLR 2021
A.3.4 More Ablation Experiments
Effect of the deterministic component: We conducted stochastic-only ablation experiments to ex-
amine the effect of the deterministic component in Equation 5-6 by removing the deterministic nodes
in Figure 1(b). We implemented two versions depending on whether the observation- and pose-level
latent representations (so and sp ) were both used as the recurrent network state (StochasticVO/VIO-d),
or not (StochasticVO/VIO-s). Results are given in Table 4. Without the deterministic component,
both translation and rotation performance dropped significantly, which supports the effectiveness of
the deterministic component.
Remark: For stochastic-only models, we remove the stochastic state estimators and let the GRU layer
in the deterministic transition models directly output the means and standard error residues of the
stochastic representation. For state transitions, we then used sampled states as the transitioned state
context for the transition model at next time step. We give more details of the two implementations
below. StochasticVO/VIO-d is short for "stochastic VO/VIO with double transition states", which
used (sto-1 , stp-1 ) as the transition state from last time step for both observation- and pose-level
transitions. StochasticVO/VIO-s is short for "stochastic VO/VIO with single transition states", which
used (sto-1, sto-1) and (stp-1 , stp-1) as the transition state from last time step for observation- and
pose-level transitions, respectively.
Table 4: Results of the stochastic-only models on KITTI.
Model	t(m)	r(o)
StochasticVO-s	0.0758	0.0931
StochasticVO-d	0.0783	0.0899
rnfoVO (full)	0.0607	0.0869
StochasticVrO-s	0.0714	0.0512
StochasticVrO-d	0.0734	0.0507
rnfoVrO (full)	0.0580	0.0416
Effect of the sample size: We study the effect of the sample size by using different ratios rn of
training samples for training the model. Recall that we let the minimum variance to be 0.01 to avoid
a trivial solution, which sets a empirical lower bound of the uncertainty. Table 5 shows that a larger
sample size reduces both the uncertainty and prediction errors. An interesting observation from our
results is though more training samples still benefit the prediction performance, the average variance
or the uncertainty measure does not reduce after half of the dataset is added. We suspect that this
may be due to the fact that KITTI sequences exhibit quite similar patterns (mostly road driving
scenarios). Thus half samples are sufficient for the model to be "familiar" with the dataset and reach
the uncertainty margin. While if the training samples are not sufficient enough, e.g. 1/4 of total
samples, the variance increases significantly.
Table 5: Results of varied sample sizes on KrTTL rn,: the ratio of training samples. σ2: the averaged
variance of the latent representation.
rn	t(m)	r(o)	σ2
1/4	0.1977	0.1040	0.0109
1/2	0.0602	0.0644	0.0101
3/4	0.0589	0.0544	0.0102
full	0.0580	0.0416	0.0102
Effect of extra sensors: Motivated by Theorem 4 and our failure-awareness analysis, we study the
performance gain of rMU given images and vice versa. The comparison between rnfoVO and rnfoVrO
provides the performance gain of rMU given images. Similarly, to study the performance gain of
images given rMU, We trained an rMU-only model, denoted as rnforO, which is then compared with
rnfoVrO. The results are summarized in Table 6, which implying that rMU is more ‘useful’ than
cameras for rotation prediction while cameras are more crucial than rMU for translation prediction.
19
Under review as a conference paper at ICLR 2021
Moreover, IMU provides a larger performance gain in EuRoC than KITTI, which is consistent with
fact that the synchronization in EuRoC between IMU and ground-truth poses are more accurate. We
also observed that InfoIO performs poorly in KITTI. The large performance gain of images given
IMU in KITTI w.r.t. both translation and rotation might also result from the inaccurate alignment of
IMU records from the raw KITTI dataset to the image and ground-truth pose sequences.
Table 6: Performance gain of IMU given images and images given IMU.
Model	KITTI		EuRoC	
	t(m)	r(O)	t(m)	r(o)
InfoIO	0.2069	0.1164	0.0667	0.0740
InfoVO	0.0607	0.0869	0.0310	0.2061
InfoVIO	0.0580	0.0416	0.0276	0.0744
A.3.5 More Uncertainty Results
We show the full uncertainty results of InfoVIO for KITTI and EuRoC in Figure 4. Since the
translations along x and y axes and the rotations around x and z axes are relatively small in KITTI
dataset, their uncertainties do not show a clear pattern. While for the translation along the forward
axis and the rotation around the upward axis (turning left/right), a clear negative and a clear positive
relationship is observed for each motion. The reason for this can be that a large forward parallax
provides more distinctive matching features for pose prediction while a large turning angle instead
dramatically reduces the shared visible areas and results in difficulties to achieve accurate prediction.
For the EuRoC dataset, we observed a consistent positive relationship for all three rotations, which
makes sense in that the MAV rotations are more uniformly distributed along the three axes. The
negative relationship in the translation results of EURoC is more obscure than that of KITTL partly
due to the difficulties in accurately predicting MAV translations, as discussed in A.3.3.
(a) Uncertainty Results for KITTI
(b) Uncertainty Results for EuRoC
Figure 4: Full uncertainty results of InfoVIO for (a) KITTI and (b) EuRoC. The top and bottom rows
represent translation and rotation results. The first, second, and third columns represent x, y, and
z, respectively. x, y, Z are with respect to the coordinate system in KITTL pos-i means the result is
evaluated at the i-th position in a clip.
Remark: There is also a line of work that attempts to combine learning based methods with geometry
based pipelines (Peretroukhin & Kelly, 2017; Yang et al., 2020), where uncertainty plays an important
role by serving as a quality measure to properly weigh the learned results. The recent successful work
by Yang et al. (2020) used learned aleatoric uncertainty to integrate learned results into the DVO
pipeline and achieves SOTA performance in monocular odometry. Our work makes contribution in
that we do not explicitly learn the variance of final prediction, but use the variance of the intrinsic
latent state instead as the uncertainty measure, which we empirically show that can capture the
epistemic uncertainty as well and holds the potential to provide a better fusion guidance. It remains
an interesting future research direction to see whether our uncertainty measure can really benefit this
hybrid pipeline that combines the merits of both learning and geometry methods.
20
Under review as a conference paper at ICLR 2021
A.3.6 Detailed Settings and Results for Failure-Awareness Experiments
We considered two failure cases, namely, degradations with noisy data and missing data. We add
Gaussian noise with mean 0 and standard error 0.1 to the observations in test dataset to create noisy
data. For missing data, we replace the observations by this Gaussian noise.
(a) Uncertainty Results with Noisy/MiSSing Data for KITTI
(b) Uncertainty Results with Noisy/Missing Data for EURoC
Figure 5: Uncertainty results of InfOVIO on both noisy and missing data for (a) KITTI and (b)
EuRoC. The top and bottom rows represent translation and rotation results. The first, second, and
third columns represent x, y, and z, respectively. x, y, Z are with respect to the coordinate system in
KITTL Blue, orange, and green circles denote results from normal data, noisy data, and missi2ng
data, respectively. Both images and IMU records were degraded.
(a) Uncertainty Results with Noisy Data for KITTI
(b) Uncertainty Results with Noisy Data for EURoC
Figure 6: Uncertainty results of InfoVIO on noisy data for (a) KITTI and (b) EuRoC. The top and
bottom rows represent translation and rotation results. The first, second, and third columns represent
x, y, and z, respectively. x, y, z are with respect to the coordinate system in KITTI. Blue, orange,
green, and red circles denote results from normal data and degraded data with images, IMU, and both
images and IMU being noisy, respectively.
(a) Uncertainty Results with Missing Data for KITTI
(b) Uncertainty Results with Missing Data for EuRoC
Figure 7: Uncertainty results of InfOVIO on missing data for (a) KITTI and (b) EuRoC. The top and
bottom rows represent translation and rotation results. The first, second, and third columns represent
x, y, and z, respectively. x, y, Z are with respect to the coordinate system in KITTI. Blue, orange,
green, and red circles denote results from normal data and degraded data with images, IMU, and both
images and IMU missing, respectively.
The results are shown in Figure 5, Figure 6, and Figure 7. Our models becomes more uncertain as the
data degrades. The uncertainty reaches the highest when the data is missing, as expected. A more
21
Under review as a conference paper at ICLR 2021
interesting observation is that the quality of IMU data dominates the uncertainty for both KITTI and
EuRoC, implying that current image encoders are not trained well enough and a better image encoder
is desirable to fully utilize visual information. Also, data degradation on IMU records leads to higher
uncertainty in EuRoC than in KITTI. We suspect this is because the synchronization between the
ground-truth poses and IMU records are more accurate in EuRoC than in KITTI. These observations
support that the intrinsic uncertainty measure provides a practical tool for failure diagnosis, such as
noises, sensor malfunctions, and even mis-synchronization between sensors.
22