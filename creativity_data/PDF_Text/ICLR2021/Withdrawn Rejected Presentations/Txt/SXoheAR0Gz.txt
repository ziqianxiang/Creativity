Under review as a conference paper at ICLR 2021
Fast Partial Fourier Transform
Anonymous authors
Paper under double-blind review
Ab stract
Given a time-series vector, how can we efficiently compute a specified part of
Fourier coefficients? Fast Fourier transform (FFT) is a widely used algorithm that
computes the discrete Fourier transform in many machine learning applications.
Despite the pervasive use, FFT algorithms do not provide a fine-tuning option for
the user to specify one’s demand, that is, the output size (the number of Fourier
coefficients to be computed) is algorithmically determined by the input size. Such
a lack of flexibility is often followed by just discarding the unused coefficients
because many applications do not require the whole spectrum of the frequency
domain, resulting in an inefficiency due to the extra computation.
In this paper, we propose a fast Partial Fourier Transform (PFT), an efficient algo-
rithm for computing only a part of Fourier coefficients. PFT approximates a part
of twiddle factors (trigonometric constants) using polynomials, thereby reducing
the computational complexity due to the mixture of many twiddle factors. We de-
rive the asymptotic time complexity of PFT with respect to input and output sizes,
as well as its numerical accuracy. Experimental results show that PFT outperforms
the current state-of-the-art algorithms, with an order of magnitude of speedup for
sufficiently small output sizes without sacrificing accuracy.
1	Introduction
How can we efficiently compute a specified part of Fourier coefficients of a given time-series vector?
Discrete Fourier transform (DFT) is a crucial task in several application areas, including anomaly
detection (Hou & Zhang (2007); Rasheed et al. (2009); Ren et al. (2019)), data center monitoring
(Mueen et al. (2010)), and image processing (Shi et al. (2017)). Notably, in many such applications,
it is well known that the DFT results in strong “energy-compaction” or “sparsity” in the frequency
domain. That is, the Fourier coefficients of data are mostly small or equal to zero, having a much
smaller support compared to the input size. Moreover, the support can often be specified in practice
(e.g., a few low-frequency coefficients around the origin). These observations arouse a great interest
in an efficient algorithm capable of computing only a specified part of Fourier coefficients. Ac-
cordingly, various approaches have been proposed to address the problem, which include Goertzel
algorithm (Burrus & Parks (1985)), Subband DFT (Hossen et al. (1995); Shentov et al. (1995)), and
Pruned FFT (Markel (1971); Skinner (1976); Nagai (1986); Sorensen & Burrus (1993); Ailon &
Liberty (2009)).
In this paper, we propose a fast Partial Fourier Transform (PFT), an efficient algorithm for com-
puting a part of Fourier coefficients. Specifically, we consider the following problem: given a
complex-valued vector a Ofsize N, a non-negative integer M, and an integer μ, estimate the Fourier
coefficients of a for the interval [μ - M,μ + M]. The resulting algorithm is of remarkably simple
structure, composed of several “smaller” FFTs combined with linear pre- and post-processing steps.
Consequently, PFT reduces the number of operations to O(N + M log M), which is, to the best
of our knowledge, the lowest arithmetic complexity achieved so far. Besides that, most subroutines
of PFT are the already highly optimized algorithms (e.g., matrix multiplication and FFT), thus the
arithmetic gains are readily turned into actual run-time improvements. Furthermore, PFT does not
require the input size to be a power of 2, unlike many other competitors. This is because the idea
of PFT derives from a modification of the Cooley-Tukey algorithm (Cooley & Tukey, 1965), which
also makes it straightforward to extend the idea to a higher dimensionality.
Through experiments, we show that PFT outperforms the state-of-the-art FFT libraries, FFTW by
Frigo & Johnson (2005) and Intel Math Kernel Library (MKL) as well as Pruned FFTW, with an
order of magnitude of speedup without sacrificing accuracy.
1
Under review as a conference paper at ICLR 2021
2	Related Work
We describe various existing methods for computing partial Fourier coefficients.
Fast Fourier transform. One may consider just using Fast Fourier transform (FFT) and discarding
the unnecessary coefficients, where FFT efficiently computes the full DFT, reducing the arithmetic
cost from naive O(N2) to O(NlogN). Such an approach has two major advantages: (1) it is
straightforward to implement, and (2) the method often outperforms the competitors because it di-
rectly employs FFT which has been highly optimized over decades. Therefore, we provide extensive
comparisons of PFT and FFT both theoretically and through run-time evaluations. Experimental
results in Section 4.2 show that PFT outperforms the FFT when the output size is small enough
(< 10%) compared to the input size.
Goertzel algorithm. Goertzel algorithm (Burrus & Parks (1985)) is one of the first methods devised
for computing only a part of Fourier coefficients. The technique is essentially the same as comput-
ing the individual coefficients of DFT, thus requiring O(MN) operations for M coefficients of an
input of size N. Specifically, theoretical analysis represents “the M at which the Goertzel algorithm
is advantageous over FFT” as M < 2logN (Sysel & Rajmic (2012)). For example, with N = 222,
the Goertzel algorithm becomes faster than FFT only when M < 44, while PFT outperforms FFT
for M < 219 = 524288 (Figure 1b). A few variants which improve the Goertzel algorithm have
been proposed (e.g., Boncelet (1986)). Nevertheless, the performance gain is only by a small con-
stant factor, thus they are still limited to rare scenarios where a very few number of coefficients are
required.
Subband DFT. Subband DFT (Hossen et al. (1995); Shentov et al. (1995)) consists of two stages
of algorithm: Hadamard transform that decomposes the input sequence into a set of smaller subse-
quences, and correction stage for recombination. The algorithm approximates a part of coefficients
by eliminating subsequences with small energy contribution, and manages to reduce the number of
operations to O(N + M log N). Apart from the arithmetic gain, however, there is a substantial
issue of low accuracy with the Subband DFT. Indeed, experimental results in Hossen et al. (1995)
show that the relative approximation error of the method is around 10-1 (only one significant figure)
regardless of output size. Moreover, the Fourier coefficients can be evaluated to arbitrary numerical
precision with PFT, which is not the case for Subband DFT. Such limitations often preclude one
from considering the Subband DFT in applications that require a certain degree of accuracy.
Pruned FFT. FFT pruning (Markel (1971); Skinner (1976); Nagai (1986); Sorensen & Burrus
(1993); Ailon & Liberty (2009)) is another technique for the efficient computation of partial Fourier
coefficients. The method is a modification of the standard split-radix FFT, where the edges (opera-
tions) in a flow graph are pruned away if they do not affect the specified range of frequency domain.
Besides being almost optimized (it uses FFT as a subroutine), the FFT pruning algorithm is exact
and reduces the arithmetic cost to O(N log M). Thus, along with the full FFT, the pruned FFT is
reasonably the most appropriate competitor of PFT. Through experiments (Section 4.2), we show
that PFT consistently outperforms the pruned FFT, significantly extending the range of output sizes
for which partial Fourier transform becomes practical.
Finally, we mention that there have been other approaches but with different settings. For example,
Hassanieh et al. (2012a;b) and Indyk et al. (2014) propose Sparse Fourier transform, which esti-
mates the top-k (the k largest in magnitude) Fourier coefficients of a given vector. The algorithm is
useful especially when there is prior knowledge of the number of non-zero coefficients in frequency
domain. Note that our setting does not require any prior knowledge of the given data.
Applications of FFT. We outline various applications of Fast Fourier transform, to which partial
Fourier transform can potentially be applied. FFT has been widely used for anomaly detection (Hou
& Zhang (2007); Rasheed et al. (2009); Ren et al. (2019)). Hou & Zhang (2007) and Ren et al. (2019)
detect anomalous points of a given data by extracting a compact representation with FFT. Rasheed
et al. (2009) use FFT to detect local spatial outliers which have similar patterns within a region
but different patterns from the outside. Several works (Pagh (2013); Pham & Pagh (2013); Malik
& Becker (2018)) exploit FFT for efficient operations. Pagh (2013) leverages FFT to efficiently
compute a polynomial kernel used with support vector machines (SVMs). Malik & Becker (2018)
propose an efficient tucker decomposition method using FFT. In addition, FFT has been used for
fast training of convolutional neural networks (Mathieu et al. (2014); Rippel et al. (2015)) and an
efficient recommendation model on a heterogeneous graph (Jin et al. (2020)).
2
Under review as a conference paper at ICLR 2021
3	Proposed Method
3.1	Overview
We propose PFT, an efficient algorithm for computing a specified part of Fourier coefficients. The
main challenges and our approaches are as follows:
1.	How can we extract essential information for a specified output? Considering that only
a specified part of Fourier coefficients should be computed, we need to find an algorithm
requiring fewer operations than the direct use of conventional FFT. This is achievable by
carefully modifying the Cooley-Tukey algorithm, finding twiddle factors (trigonometric
factors) with small oscillations, and approximating them via polynomials (Section 3.2.1).
2.	How can we reduce approximation cost? The approach given above involves an approx-
imating process, which would be computationally demanding. We propose using a base
exponential function, by which all data-independent factors can be precomputed, enabling
one to bypass the approximation problem during the run-time (Sections 3.2.2 and 3.3).
3.	How can we further reduce numerical computation? We carefully reorder operations
and factorize terms in order to alleviate the complexity of PFT. Such techniques separate
all data-independent factors from data-dependent factors, allowing further precomputation.
The arithmetic cost of the resulting algorithm is O(N + M log M), where N and M are
input and output size descriptors, respectively (Sections 3.4 and 3.5.1).
3.2	Approximation of twiddle factors
The key of our algorithm is to approximate a part of twiddle factors with small oscillations by using
polynomial functions, reducing the computational complexity of DFT due to the mixture of many
twiddle factors. Using polynomial approximation also allows one to carefully control the degree of
polynomial (or the number of approximating terms), enabling fine-tuning the output range and the
approximation bound of the estimation. Our first goal is to find a collection of twiddle factors with
small oscillations. This can be achieved by slightly adjusting the summand of DFT and splitting the
summation as in the Cooley-Tukey algorithm (Section 3.2.1). Next, using a proper base exponential
function, we give an explicit form of approximation to the twiddle factors (Section 3.2.2).
3.2.1	Twiddle factors with small oscillations
Recall that the DFT of a complex-valued vector a of size N is defined as follows:
a — jχ a e-2πimn∕N
am =	ane	,
n∈[N]
(1)
where [ν] denotes {0,1,…,ν - 1} fora positive integer V (in this paper, We follow the convention
of viewing a vector V = (vo, vι, ∙∙∙ , vν-ι) of Size V as a finite sequence defined on [ν]). Assume
that N = pq for two integers p, q > 1. The Cooley-Tukey algorithm re-expresses (1) as
^m =E E a,qk+Lπ…” =EEaqk+le 'F'rnl/N ∙ e i2ττimk/p,
k∈[p] l∈[q]	k∈[p] l∈[q]
(2)
yielding two collections of twiddle factors, namely {e-2niml/N}ι∈[q] and {e-2nimk/p}ke[p]. Con-
sider the problem of computing αm for -M ≤ m ≤ M, where M ≤ N/2 is a non-
negative integer. In this case, note that the exponent of e-2niml/N ranges from -2∏iM(q — 1)/N
to +2πiM(q — 1)/N and that the exponent of e-2nimk/p ranges from -2πiM(P — 1)/p to
+2∏iM(p - 1)/p. Here (P-Il))/N 〜 ɪ, meaning that the first collection contains twiddle factors
with smaller oscillations compared to the second one. Typically, a function with smaller oscillation
results in a better approximation via polynomials. In this sense, it is reasonable to approximate the
first collection of twiddle factors in (2) with polynomial functions, thereby reducing the complexity
of the computation due to the mixture of two collections of twiddle factors. Indeed, one can further
reduce the complexity of approximation: we slightly adjust the summand in (2) as follows.
am
e-πim∕p
k∈[p] l∈[q]
aqk+l
e,-2πim(l-q∕2)∕N e,-2πimk∕p
(3)
In (3), we observe that the range of exponents of the first collection {e-2πim(I-q/2)/N限⑷ of
twiddle factors is [-∏iM∕p, +∏iM∕p], a contraction by a factor of around 2 when compared with
[-2π iM (q - 1)/N, +2πiM (q - 1)/N], hence the twiddle factors with even smaller oscillations.
There is an extra twiddle factor e-nim/p in (3). Note that, however, it depends on neither k nor l, so
the amount of the additional computation is relatively small.
3
Under review as a conference paper at ICLR 2021
3.2.2	Base exponential function
The first collection of twiddle factors in (3) consists of q distinct exponential functions. One can
apply approximation process for each function in the collection; however, this would be time-
consuming. A more plausible approach is to 1) choose a base exponential function euix for a fixed
u ∈ R, 2) approximate euix using a polynomial, and 3) exploit a property of exponential functions:
the laws of exponents. Specifically, suppose that we obtained a polynomial P(x) that approximates
euix on |x| ≤ ∣ξ∣, where u, ξ ∈ R \ {0}. Consider another exponential function evix, where v = 0.
Since evix = eui(vx/u), the re-scaled polynomial P(vx/u) approximates evix on |x| ≤ ∣uξ∕v∣. This
observation indicates that once We find an approximation P to euix on |x| ≤ ∣ξ∣ for properly se-
lected U and ξ, all elements belonging to {e-2πim(l-q∕2)∕N}仁团 Can be approximated by re-scaling
P. Fixing a base exponential function also enables precomputing a polynomial that approximates
it, so that one can bypass the approximation problem during the run-time. We further elaborate this
idea in a rigorous manner after giving a few definitions (see Definitions 3.1 and 3.2).
Let k ∙ ∣∣r be the uniform norm (or supremum norm) restricted to a set R ⊆ R, that is, kf kR =
sup{|f (x)| : x ∈ R} and Pα be the set of polynomials on R of degree at most α.
Definition 3.1. Given a non-negative integer α and non-zero real numbers ξ, u, we define a polyno-
mial Pα,ξ,u as the best approximation to euix out of the space Pa under the restriction |x| ≤ ∣ξ∣:
Pα,ξ,u ：= argmin ∣∣P(x) - euixk∣x∣≤∣ξ∣,
P∈Pα
and Pα,ξ,u = 1 when ξ = 0 or u = 0.
Smirnov & Smirnov (1999) proved the unique existence of Pα,ξ,u. A few techniques called minimax
approximation algorithms for computing the polynomial are reviewed in Fraser (1965).
Definition 3.2. Given a tolerance > 0 and a positive integer r ≥ 1, we define ξ(, r) to be the
scope about the origin such that the exponential function eπix can be approximated by a polynomial
of degree less than r with approximation bound :
ξ(e,r) := sup{ξ ≥ 0 : ∣Pr-i,ξ,∏(x) - eπix∣∣χ∣≤ξ ≤ e}.
We express the corresponding polynomial as Pr-ι,ξ(e,r),∏(x) = Pj∈[r] W3r_1,j ∙ xj.	□
In Definition 3.2, we choose eπix as a base exponential function. The rationale behind is as fol-
lows. First, using a minimax approximation algorithm, we precompute ξ(, r) and {we,r-1,j}j∈[r]
for several tolerance e,s (e.g. 10-1,10-2,∙…)and positive integer r's (typically 1 ≤ r ≤ 25).
When N, M, p and are given, we find the minimum r satisfying ξ(, r) ≥ M/p. Then, by the pre-
ceding argument, it follows that the re-scaled polynomial function Pr-1,ξ(e,r),π (-2x(l - q /2)/N)
approximates e-2πix(I-q∕2"N on |x| ≤ 12@ Nq/2)∙ M | for each l ∈ [q] (note that if l - q∕2 = 0,we
have 12(l-q/2) ∙ M | = ∞). Here 12(l-q/2) ∙ M | = 12-q ∙ M| ≥ M for all l ∈ [q]. Therefore, we
obtain a polynomial approximation on |m| ≤ M for each twiddle factor in {e-2^im^l-q/2')/N}ι∈[q],
namely {Pr-ι ξ(e r) ∏(-2m(l - q∕2)∕N)}ι∈[q]. Then, it follows from (3) that
^m ≈ Lm XXaqk+l Pr-1,ξ(e,r),π (-2m(l - q/2)/N) ∙ e 2πimk∕p,	⑷
k∈[p] ι∈[q]
which gives an estimation of the coefficient am for -M ≤ m ≤ M.
3.3	Arbitrarily centered target ranges
In the previous section, we have focused on the problem of calculating am, for m belonging to
[-M, M]. We now consider a more general case: let us use the term target range to indicate the
range where the Fourier coefficients should be calculated, and Rμ,M to denote [μ - M, μ + M] ∩ Z,
where μ ∈ Z. Note that the previously given method works only when our target range is centered at
μ = 0. A slight modification of the algorithm allows the target range to be arbitrarily centered. One
possible approach is as follows: given a complex-valued vector x of size N, we define y as yn =
Xn ∙ e-2πiμn∕N. Then, the Fourier coefficients of X and y satisfy the following relationship:
= = X X -2πiμn∕N	-2πimn∕N = X X	-2ni(m+*)n/N = X
ym = / / Xn e	e	= / / Xn e	= xm+μ.
n∈[N]	n∈[N]
Thus, the problem of calculating Xm for m ∈ R*,m is equivalent to calculating ym, for m ∈ Ro,m,
to which our previous method can be applied. This technique, however, requires extra N multiplica-
4
Under review as a conference paper at ICLR 2021
tions due to the computation of y. A better approach, where one can bypass the extra process during
the run-time, is to exploit the following lemma (see Appendix A.1 for the proof).
Lemma 1. Given a non-negative integer α, non-zero real numbers ξ, u, and a real number μ, the
following equality holds:
euiμ ∙ Pα,ξ,u(x - μ) = arg min ∣∣P(x) - euixk∣χ-μ∣≤∣ξ∣.
P∈Pα

This observation implies that, in order to obtain a polynomial approximating euix on |x - μ∣ ≤ ∣ξ∣,
We first find a polynomial P approximating euix on |x| ≤ ∣ξ∣, then translate P by -μ and multiply
it with the scalar euiμ. Applying this process to the previously obtained approximation polynomi-
als (see Section 3.2.2) yields {e-2πiμ(I-q∕2"N ∙ Pr-ι,ξ(e,r),∏(-2(m - μ)(l - q∕2)∕N)}ι∈[q]. We
substitute these polynomials for the twiddle factors {e-2nim(l-q/2)/N}k@ in (3), which gives the
following estimation of ^m for m ∈ R*,m, where k ∈ [p], l ∈ [q], and j ∈ [r]:
e-πim∕p χ aqk+ι e-2πiμ(I-q/2)/N .。—^,「拓(-2(m - μ)(l - q/2)/N) ∙ e-2πimk∕p
k,l
=e-πim∕p X aqk+l e-2πiμ(I-q/2)/N X We—j (-2(m - μ)(l - q/2)/N)j ∙ e-2πimk∕p ⑸
k,l	j
=e-πim∕p XXaqk+l e-2πi"(I-q/2)/N We,r-I,j ((m - μ)∕p)j(1 - 2l∕q)j ∙ e-2πimk∕p.
3.4	Efficient Summations
We have found that three main summation steps (each being over j, k and l) take place when com-
puting the partial Fourier coefficients. Note that in (5), the innermost summation Pj is moved to
the outermost position, and the term -2(m - μ)(l - q∕2)∕N is factorized into two independent
terms, (m - μ)∕p and 1 - 2l∕q. Interchanging the order of summations and factorizing the term
result in a significant computational benefit; we elucidate what operator we should utilize for each
summation and how we can save the arithmetic costs from it. As we will see, the innermost sum over
l corresponds to a matrix multiplication, the second sum over k can be viewed as multiple DFTs,
and the outermost sum over j is an inner product. For the first sum, let A = (ak,l ) = aqk+l and
B = (bι,j) = e-2πiμ(l-q∕2"N We,r-ι,j (1 - 2l∕q)j, so that (5) can be written as follows:
e-πim∕p X ((m - μ)∕p)j X e-2nimk/p X a^j.
j∈[r]	k∈[p]	l∈[q]
Here, note that the matrix B is data-independent (not dependent on a), and thus can be precom-
puted. Indeed, we have already seen that {we,r-1,j}j∈[r] can be precomputed. The other fac-
tors e-2πiμ(l-q∕2"N and (1 - 2l∕q)j composing the elements of B can also be precomputed if
(N, M, μ,p, E) is known in advance. Thus, as long as the setting (N, M, μ,p, E) is unchanged, we
can reuse the matrix B for any input data a once the configuration phase of PFT is completed
(Algorithm 1). We shall denote the multiplication A × B as C = (ck,j ):
e-πim∕p X ((m - μ)∕p)j X Ck,j ∙ e-2nimk/p.	(6)
j∈[r]	k∈[p]
For each j ∈ [r],the summation Cmj = Pk∈[p] Ck,j∙ e-2^imk^p isaDFT ofsize p. We perform FFT
r times for this computation, which yields the following estimation of am, for m ∈ R*,m:
e-πim∕p X ((m -μ)∕p)j
• Cmj.	(7)
j ∈[r]
Note that Cmj is a periodic function of period P with respect to m, so we use the coefficient at m
modulo p if m < 0 or m ≥ p. Thus, the mth Fourier coefficient of a can be estimated by the inner
product of ((m - μ)∕p)j and Cmj with respect to j, followed by a multiplication with the extra
twiddle factor e-nim/p (we also precompute ((m - μ)∕p)j and e-πim∕p). The full computation is
outlined in Algorithm 2. By these summation techniques, the arithmetic complexity is reduced to
O(N + M log M) from naive O(MN), as described in Section 3.5.
3.5 Theoretical analysis
We present theoretical analysis on the time complexity of PFT and its approximation bound.
5
Under review as a conference paper at ICLR 2021
Algorithm 1: Configuration phase of PFT
input : Input size N, output descriptors M and μ, divisor p, and tolerance E
output: Matrix B, divisor p, and numbers of rows and columns, q and r
ι q J N/p
2	r J min{r ∈ N : ξ(e, r) ≥ M/p}	// Use precomputed ξ(e, r)
3	for (l, j) ∈ [q] × [r] do
4	B B[l,j] J e-2πiμ(l-q∕2"N ∙ we,r-ι,j ∙ (1 一 2l∕q)j // Use precomputed we,r-ι,j
5	end
Algorithm 2: Computation phase of PFT
input : Vector a of size N, output descriptors M and μ, and configuration results B,p,q,r
output: Vector E(a) of estimated Fourier coefficients of a for [μ 一 M, μ + M]
1	A[k, l] J aqk+l for k ∈ [p] and l ∈ [q]
2	CJA×B
3	for j ∈ [r] do
4	I Ch j] J FFT(C[∙,j])	// FFT of j-th column of C
5	end
6	for m ∈ [μ — M, μ + M ] do
7	I E(a)[m] J e-πim∕p Pj=0((m — μ)∕p)j ∙ (C[m%p,j]
8	end
3.5.1 Time complexity
We analyze the time complexity of PFT. Theorem 2 (see Appendix A.2 for the proof) shows that
the time cost T(N, M) of PFT, where N and M are input and output size descriptors, respectively,
is bounded by O(N + M log M). Note that the theorem presumes that all prime factors of N have
a fixed upper bound. Yet, in practice, this necessity is not a big concern because one can readily
control the input size with basic techniques such as zero-padding or re-sampling. Moreover, we
empirically find that even if N has a large prime factor, PFT still shows a promising performance
(see Section 4.2). In Theorem 2, note that a positive integer is called b-smooth if none of its prime
factors is greater than b. For example, the 2-smooth integers are equivalent to the powers of 2.
Theorem 2.	Fix a tolerance E > 0 and an integer b ≥ 2. If N is b-smooth, then the time complexity
T(N, M) of PFT has an asymptotic upper bound O(N + M log M).
3.5.2 Approximation bound
We now give a theoretical approximation bound of the estimation via the polynomial P . We denote
the estimated Fourier coefficient of a as E(a). Theorem 3 (see Appendix A.3 for the proof) states
that the approximation bound over the target range is data-dependent of the total weight kak1 of the
original vector and the given tolerance e, where ∣∣ ∙ ∣∣ι denotes the 'ι norm.
Theorem 3.	Given a tolerance E > 0, the following inequality holds for PFT:
Ila -E(a)kRμ,M ≤kakι∙ e.	□
4 Experiments
Through experiments, the following questions should be answered:
•	Q1. Run-time cost (Section 4.2). How quickly does PFT compute a part of Fourier coef-
ficients compared to other competitors without sacrificing accuracy?
•	Q2. Effect of hyper-parameter p (Section 4.3). How do the different choices of divisor p
of input size N affect the overall performance of PFT?
•	Q3. Effect of different precision (Section 4.4). How do the different precision settings
affect the run-time of PFT?
•	Q4. Anomaly detection (Section 4.5). How well does PFT work for a practical application
employing FFT (anomaly detection)?
4.1	Experimental setup
Machine. A machine with Intel Core i7-6700HQ @ 2.60GHz and 8GB of RAM is used.
Datasets. We use both synthetic and real-world datasets listed in Table 1.
6
Under review as a conference paper at ICLR 2021
Table 1: Detailed information of datasets.
Dataset	Type	Size	Description
{Sn }1 2n2=12	Synthetic	2n	Vectors of random real numbers between 0 and 1
Urban Sound1	Real-world	32000	Various sound recordings in urban environment
Air Condition2	Real-world	19735	Time-series vectors of air condition information
Competitors. We compare PFT with two state-of-the-art FFT algorithms, FFTW and MKL, as well
as Pruned FFTW. All of them are implemented in C++.
1.	FFTW: FFTW3 is one of the fastest public implementation for FFT, offering a hardware-
specific optimization. We use the optimized version of FFTW 3.3.5, and do not include the
pre-processing for the optimization as the run-time cost.
2.	MKL: Intel Math Kernel Library4 (MKL) is a library of optimized math routines including
FFT, and often shows a better run time result than the FFTW. All the experiments are
conducted with an Intel processor for the best performance.
3.	pFFT: pFFT5 is a pruned version of FFTW designed for fast computation of a subset of
the outputs. The algorithm uses the optimized FFTW as a subroutine.
4.	PFT (proposed): we use MKL BLAS routines for the matrix multiplication, MKL DFTI
functions for the batch FFT computation, and Intel Integrated Performance Primitives (IPP)
library for the post-processing steps such as inner product and element-wise multiplication.
Measure. In all experiments, we use single-precision floating-point format, and the parameters p
and are chosen so that the relative `2 error is strictly less than 10-6, which ensures that the overall
estimated coefficients have at least 6 significant figures. Explicitly,
Relative '2 Error = SPmP |am -E(PmE < 10—6,
V	工m∈R |am|
where a is the actual coefficient, E(a) is the estimation of a, and R is the target range. Section 4.4 is
an exception, where we investigate different settings, varying the precision to 10-4 or 10-2.
4.2	Run-time cost
Run time vs. input size. Wefix the target range to R0,29 and evaluate the run time of PFT vs. input
sizes N : 212,213,…,222. Figure 1a shows how the four competitive algorithms scale with varying
input size, wherein PFT outperforms the others if the output size is sufficiently smaller (< 10%)
than the input size. Consequently, PFT achieves up to 19× speedup compared to its competitors.
Due to the overhead of the O(N) pre- and O(M ) post-processing steps, PFT runs slower than FFT
when M is close to N so the time complexity tends to O(N + N log N).
Run time vs. output size. We fix the input size to N = 222 and evaluate the run time of PFT vs.
target ranges Ro,29 ,Ro,2ιo, ∙∙∙ , Ro,2i8. The result is illustrated as a run time vs. output size plot
(recall that |R0,M | ' 2M) in Figure 1b. Note that the run times of FFTW and MKL do not benefit
from the information of output size. We also observe that the pruned FFT (pFFT) shows only a
modest improvement compared to the full FFTs, while PFT significantly extends the range of output
sizes for which partial Fourier transform becomes practical.
Real-world data. When it comes to real-world data, it is not generally the case that the size of an
input vector is a power of 2. Notably, PFT still shows a promising performance regardless of the
fact that the input size is not a power of 2 or even it has a large prime factor: a strong indication
that our proposed technique is robust for many different applications in real-world. Urban Sound
dataset contains various sound recording vectors of size N = 32000 = 28 × 53. We evaluate the run
time of PFT vs. output size ranging from 100 to 6400. Figure 2a illustrates the result, wherein PFT
outperforms the competitors if the output size is small enough compared to the input size. On the
other hand, Air Condition dataset is composed of time-series vectors of size N = 19735 = 5 × 3947.
Note that N has only two non-trivial divisors, namely 5 and 3947, forcing one to choose p = 3947
in any practical settings; if we choose p = 5, the ratio M/p often turns out to be too large, which
1https://urbansounddataset.weebly.com/urbansound8k.html
2https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction
3http://www.fftw.org/index.html
4http://software.intel.com/mkl
5http://www.fftw.org/pruned.html
7
Under review as a conference paper at ICLR 2021
(a)
2-7
100
(a) Run time vs. Input size(Target range:R 0,29)
10.
)sm(emit nuR
212 213 214 215 216 217 218 219 220 221 222
Input size
Run time vs. Output size(N=32000)
4- 5-
22
)sm(emit nuR
200	400	800	1600	3200	6400
Output size
)sm(emit nUR
(b) Run time vs. Output size (InPUt size: 222)
32
16 8 4
)sm(emit nuR
Output size
Figure 1: (a) Run time vs. input size for target range R0,29 with {Sn}2n2=12 datasets, and (b) run
time vs. output size for S22 . PFT runs faster than the competitors if the output size is small enough
(< 10%) compared to the input size. Note that PFT consistently outperforms the pruned FFT.
RUn time vs. OUtPUt Size (N=19735)
X----X----X-----X----X----X----X-----X
H----------1---------1---------1---------1---------1---------1--------F
8.8 ×	o
-oʃ	七 PFT
∕θ	毋 FFTW
T MKL
125 250 500 1000 2000 4000 8000 16000
OUtPUt size
Figure 2: Run time vs. output size results for (a) Urban Sound dataset and (b) Air Condition
dataset. PFT outperforms the competitors regardless of the fact that the input size is not a power of
2 (N = 28 × 53) or even it has a large prime factor (N = 5 × 3947).
results in a poor performance (see Section 4.3 for more discussion of the optimal choice of p). The
run time of PFT vs. output size ranging from 125 to 16000 is evaluated in Figure 2b (pFFT is
not included in the figure since it consistently runs slower than FFTW). It is noteworthy that PFT
still outperforms its competitors even in such pathological examples, implying the robustness of our
algorithm for various real-world situations.
4.3	EFFECT OF HYPER-PARAMETER p
To investigate the effect of different choices of p, we fix N = 222 and vary the ratio M/p from
1/32 to 4 for target ranges R0,29, R0,210,…,R0,218. Table 2 shows the resulting run times, where
the bold highlights the best choice of M/p for each M, and the missing entries are due to worse
performance than FFT. One crucial observation is as follows: with the increase of output size, the
best choice of M/p also increases or, equivalently, the optimal value of p tends to remain stable.
Intuitively, this is the consequence of “balancing” the three summation steps (Section 3.4): when
M N, the most computationally expensive operation is the matrix multiplication with O(rN)
time cost, and thus, M/p should be small so that the r decreases, despite a sacrifice in the batch FFT
step requiring O(rp log p) operations (Appendix A.2). As the M becomes larger, however, more
concern is needed regarding the batch FFT and post-processing steps, so the parameter p should
not change rapidly. This observation indicates the possibility that the optimal value of p can be
algorithmically auto-selected given a setting (N, M, μ, e), which We leave as a future work.
4.4	Effect of different precision
We investigate the trade-off between accuracy and running time of PFT. To do this, we fix N = 222
and change the precision goal from 10-6 to 10-4 or 10-2 for target ranges R0,29, R0,210, ∙一，
R0,218. Table 3 shows the results, where the parenthesized number is the ratio of run times of each
setting to 10-6. Note that the run time of PFT is reduced by up to 17% or 27% when the precision
goal is set to 10-4 or 10-2, respectively. This observation indicates that one may readily benefit
from the trade-off, especially when the fast evaluation is of utmost importance albeit with a slight
sacrifice in accuracy.
8
Under review as a conference paper at ICLR 2021
Table 2:	Averag	e run time (ms) of PFT			for N 二	222 with different settings of M/p and M .				
M/p						M				
	25 * * * 9	210	211	212	213	-214	215	216	217	218
1/32	1.273	1.394	1.634	2.303	5.659	14.121	-	-	-	-
1/8	2.674	1.608	1.332	1.491	1.860	3.020	7.711	-	-	-
1/2	2.627	3.738	2.717	1.678	1.526	1.881	2.707	5.740	14.715	-
1	2.677	2.685	3.805	2.808	1.687	1.692	2.164	3.530	7.749	-
2	4.005	2.723	2.731	3.533	2.878	1.949	1.940	2.821	5.556	12.534
4	4.090	4.295	2.986	2.983	4.108	3.275	2.365	2.929	5.411	11.924
Table 3: Average run time (ms) of PFT for N = 222 with different precision settings.
Precision	M									
	29	210	211	212	213	214	215	216	217	218
10-6	1.273	1.295	1.332	1.491	1.526	1.692	1.940	2.821	5.411	11.924
10-4	1.249	1.278	1.293	1.329	1.400	1.607	1.872	2.469	4.590	9.927
	(.98)	(.99)	(.97)	(.89)	(.92)	(.95)	(.96)	(.88)	(.85)	(.83)
10-2	1.238	1.244	1.251	1.277	1.343	1.512	1.740	2.297	4.058	8.733
	(.97)	(.96)	(.94)	(.86)	(.88)	(.89)	(.90)	(.81)	(.75)	(.73)
Figure 3: Top-20 anomalous points detected in Air Condition time-series data, where each red dot
denotes a detected anomaly position. Note that replacing FFT with PFT does not change the result
of the detection, still reducing the overall time complexity.
4.5	Anomaly detection
We demonstrate an example of how PFT is applied to practical applications. Here is one simple but
fundamental principle: replace the “perform FFT and discard unused coefficients” procedure with
“just perform PFT”. Considering the anomaly detection method proposed in Rasheed et al. (2009),
where one first performs FFT and then inverse FFT with only a few low-frequency coefficients to
obtain an estimated fitted curve, we can directly apply the principle to the method. To verify this
experimentally, we use a time-series vector from Air Condition dataset, and set the target range as
R0,125 (' 250 low-frequency coefficients). Note that, in this setting, PFT results in around 8×
speedup compared to the conventional FFT (see Figure 2b). The top-20 anomalous points detected
from the data are presented in Figure 3. In particular, we found that replacing FFT with PFT does
not change the result of top-20 anomaly detection, with all its computational benefits.
5	Conclusions
In this paper, we propose PFT (fast Partial Fourier Transform), an efficient algorithm for computing
a part of Fourier coefficients. PFT approximates some of twiddle factors with relatively small os-
cillations using polynomials, reducing the computational complexity of DFT due to the mixture of
many twiddle factors. Experimental results show that PFT outperforms the state-of-the-art FFTs as
well as pruned FFT, with an order of magnitude of speedup without accuracy loss, significantly ex-
tending the range of applications where partial Fourier transform becomes practical. Future works
include optimizing the implementation of PFT; for example, the optimal divisor p of input size N
might can be algorithmically auto-selected. We also believe that hardware-specific optimizations
would further increase the performance of PFT.
9
Under review as a conference paper at ICLR 2021
References
Nir Ailon and Edo Liberty. Fast dimension reduction using rademacher series on dual bch codes.
Discrete & Computational Geometry, 42(4):615, 2009.
C Boncelet. A rearranged dft algorithm requiring n 2/6 multiplications. IEEE transactions on
acoustics, speech, and signal processing, 34(6):1658-1659,1986.
C Sidney Burrus and TW Parks. and Convolution Algorithms. Citeseer, 1985.
James W Cooley and John W Tukey. An algorithm for the machine calculation of complex fourier
series. Mathematics of computation, 19(90):297-301, 1965.
W. Fraser. A survey of methods of computing minimax and near-minimax polynomial approx-
imations for functions of a single independent variable. J. ACM, 12(3):295-314, 1965. doi:
10.1145/321281.321282. URL https://doi.org/10.1145/321281.321282.
M. Frigo and S. G. Johnson. The design and implementation of fftw3. Proceedings of the IEEE, 93
(2):216-231, 2005.
Haitham Hassanieh, Piotr Indyk, Dina Katabi, and Eric Price. Simple and practical algorithm for
sparse fourier transform. In Proceedings of the twenty-third annual ACM-SIAM symposium on
Discrete Algorithms, pp. 1183-1194. SIAM, 2012a.
Haitham Hassanieh, Piotr Indyk, Dina Katabi, and Eric Price. Nearly optimal sparse fourier trans-
form. In Proceedings of the forty-fourth annual ACM symposium on Theory of computing, pp.
563-578, 2012b.
AN Hossen, Ulrich Heute, OV Shentov, and SK Mitra. Subband dft—part ii: accuracy, complexity
and applications. Signal Processing, 41(3):279-294, 1995.
Xiaodi Hou and Liqing Zhang. Saliency detection: A spectral residual approach. In CVPR. IEEE
Computer Society, 2007.
Piotr Indyk, Michael Kapralov, and Eric Price. (nearly) sample-optimal sparse fourier transform. In
Proceedings of the twenty-fifth annual ACM-SIAM symposium on Discrete algorithms, pp. 480-
499. SIAM, 2014.
Jiarui Jin, Jiarui Qin, Yuchen Fang, Kounianhua Du, Weinan Zhang, Yong Yu, Zheng Zhang, and
Alexander J. Smola. An efficient neighborhood-based interaction model for recommendation on
heterogeneous graph. CoRR, abs/2007.00216, 2020.
Osman Asif Malik and Stephen Becker. Low-rank tucker decomposition of large tensors using
tensorsketch. In NeurIPS, pp. 10117-10127, 2018.
J Markel. Fft pruning. IEEE transactions on Audio and Electroacoustics, 19(4):305-311, 1971.
Michael Mathieu, Mikael Henaff, and Yann LeCun. Fast training of convolutional networks through
ffts. In 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB,
Canada, April 14-16, 2014, Conference Track Proceedings, 2014.
Abdullah Mueen, Suman Nath, and Jie Liu. Fast approximate correlation for massive time-series
data. In SIGMOD, pp. 171-182. ACM, 2010.
Keinosuke Nagai. Pruning the decimation-in-time fft algorithm with frequency shift. IEEE transac-
tions on acoustics, speech, and signal processing, 34(4):1008-1010, 1986.
Rasmus Pagh. Compressed matrix multiplication. ACM Trans. Comput. Theory, 5(3):9:1-9:17,
2013.
Ninh Pham and Rasmus Pagh. Fast and scalable polynomial kernels via explicit feature maps. In
KDD, pp. 239-247. ACM, 2013.
10
Under review as a conference paper at ICLR 2021
Faraz Rasheed, Peter Peng, Reda Alhajj, and Jon G. Rokne. Fourier transform based spatial outlier
mining. In Intelligent Data Engineering and Automated Learning - IDEAL 2009, 10th Interna-
tional Conference, Burgos, Spain, September 23-26, 2009. Proceedings, volume 5788 of Lecture
Notes in Computer Science,pp. 317-324. Springer, 2009.
Hansheng Ren, Bixiong Xu, Yujing Wang, Chao Yi, Congrui Huang, Xiaoyu Kou, Tony Xing, Mao
Yang, Jie Tong, and Qi Zhang. Time-series anomaly detection service at microsoft. In KDD, pp.
3009-3017. ACM, 2019.
Oren Rippel, Jasper Snoek, and Ryan P Adams. Spectral representations for convolutional neural
networks. In Advances in neural information processing systems, pp. 2449-2457, 2015.
OV Shentov, SK Mitra, Ulrich Heute, and AN Hossen. Subband dft—part i: Definition, interpreta-
tion and extensions. Signal Processing, 41(3):261-277, 1995.
Sheng Shi, Runkai Yang, and Haihang You. A new two-dimensional fourier transform algorithm
based on image sparsity. In 2017 IEEE International Conference on Acoustics, Speech and Signal
Processing, ICASSP 2017, New Orleans, LA, USA, March 5-9, 2017, pp. 1373-1377. IEEE, 2017.
D Skinner. Pruning the decimation in-time fft algorithm. IEEE Transactions on Acoustics, Speech,
and Signal Processing, 24(2):193-194, 1976.
Georgey S Smirnov and Roman G Smirnov. Best uniform approximation of complex-valued func-
tions by generalized polynomials having restricted ranges. Journal of approximation theory, 100
(2):284-303, 1999.
Henrik V Sorensen and C Sidney Burrus. Efficient computation of the dft with only a subset of input
or output points. IEEE transactions on signal processing, 41(3):1184-1200, 1993.
Petr Sysel and Pavel Rajmic. Goertzel algorithm generalized to non-integer multiples of fundamental
frequency. EURASIP Journal on Advances in Signal Processing, 2012(1):56, 2012.
11
Under review as a conference paper at ICLR 2021
A	Proofs
A.1 Proof of Lemma 1
Proof. Let Q = argminp∈pa ∣∣P(x) - euixk ∣x-μ∣≤∣ξ∣. We first observe the following equation:
Q = argmin IlP(X)-euixk∣χ-μ∣≤∣ξ∣
P∈Pα
=argmin l∣P(x + μ) - eui(x+μ)k∣x∣≤∣ξ∣
P∈Pα
=argmin Ile-Uiμ ∙ P(X + μ) - euixk∣x∣≤∣ξ∣,
P∈Pα
where the third equality holds since ∣e-uiμ∣ = 1. Recall that the polynomial Pα,ξ,u is defined by
argminp∈pct ∣∣P(x) 一 euixk∣χ∣≤∣ξ∣. If Q(X) ∈ Pα, it is clear that e-uiμ ∙ Q(X 十 μ) ∈ Pa because
translation and non-zero scalar multiplication on a polynomial do not change its degree. Therefore,
by the uniqueness of the best approximation (Smirnov & Smirnov, 1999), we have
e-uiμ ∙Q(x + μ)= Pα,ξ,u(x),
which yields Q(X) = euiμ ∙ Pa,ξ,u(x - μ), and hence the proof.	□
A.2 Proof of Theorem 2
Proof. We first claim that the following statement holds: let b ≥ 2; if N is b-smooth and M ≤ N is
a positive integer then there exists a positive divisor P of N satisfying M∕∖fb ≤ p < √^M. Indeed,
suppose that none of N,s divisors belongs to [M∕√b, VbM). Let 1 = pi < p2 < •…< pd = N
be the enumeration of all positive divisors of N in increasing order. It is clear that pi < √bM and
M/Vb < pd since b ≥ 2 and 1 ≤ M ≤ N. Then, there exists an i ∈ {1, 2, ∙∙∙ , d - 1} so that Pi <
M/Vb andpi+i ≥ 小bM. Since N is b-smooth andPi < N, at least one of 2pi, 3pi,…,bpi must be
a divisor of N. However, this is a contradiction because we have pi+i/pi > (√bM )(M∕Vb)-i = b,
so none of 2pi, 3pi, •…,bpi can be a divisor of N, which completes the proof.
Exploiting the above property, we manage to reduce the time complexity of PFT to a functional
form dependent of only N and M . We follow the convention in counting FFT operations, assuming
that all data-independent elements such as configuration results B, p, q, r and twiddle factors are
precomputed, and thus not included in the run-time cost. We begin with the construction of the
matrix A. For this, we merely interpret a as an array representation for A of size p × q = N (line
1 in Algorithm 2). Also, recall that the matrix B can be precomputed as described in Section 3.4.
For the two matrices A of size p × q and B of size q × r, standard matrix multiplication algorithm
has running time of O(Pqr) = O(r ∙ N) (line 2 in Algorithm 2). Next, the expression (6) contains r
DFTs of size p, namely Cmj = Pk∈[p] ck,j ∙ e-2nimk/p for each j ∈ [r]. We use FFT r times for the
computation, then it is easy to see that the time cost is given by O(r ∙p logp) (lines 3-5 in Algorithm
2). Finally, there are 2M + 1 coefficients to be calculated in (7), each requiring O(r) operations,
giving an upper bound O(r ∙ M) for the running time (lines 6-8 in Algorithm 2). Combining the
three upper bounds, we formally express the time complexity T(N, M) of PFT as
T(N, M) = Ο(r ∙ (N + PlogP + M)).
Note that r is only dependent of and M/p by its definition (Algorithm 1). Therefore, when is
fixed, T (N, M ) is dependent of the choice of p. By the preceding argument, we can always find a
divisor P of N such that M∕√b ≤ p < √bM, implying that M/p is tightly bounded, and thus, so
is r. It follows that p = Θ(M) and r = Θ(1), which leads to the following asymptotic upper bound
for T (N, M ) with respect to N and M:
T(N, M) = O(N+ MlogM),
hence the proof.
□
12
Under review as a conference paper at ICLR 2021
A.3 PROOF OF THEOREM 3
Proof. Let v = -2(l - q/2)/N. By the estimation in (5), the following holds:
M-E (a)kRμ,M = k X aqk+ι (eπivm - eπivμ ∙ Rf乳⑺,∏ (v(m - μ)))e-2nimk/%-"im^meR^
k,l
≤ X k%k+ι (eπivm -i∙ Prf氢⑺,∏(v(m - μ)))e-2πimk∕%-πim∕pkmeR”,M
k,l
=X |aqk+l| •忖i"m-μ) - Pr-1,ξ(e,r),∏ (v(m - 〃))||m%,M ,
k,l
since we have |e-2nimk/p| = |e-nim/p| = ∣e-πivμ∣ = 1. If l ranges from 0 to q — 1, then |v| ≤
2(q∕2)∕N = 1/p, and thus, M|v| ≤ M/p ≤ ξ(e, r). We extend the domain of the function
eπiv(m-μ) -Pr-i,ξ(e,r),π(v(m — μ)) from m ∈ Rμ,M = [μ — M, μ + M] ∩Z to x ∈ [μ — M, μ+M]
(note that extending domain never decreases the uniform norm), and replace v(x - μ) with χ0, from
which it follows that
Ila -E(a)kRμ,M ≤ X |aqk+l| ∙ ∣∣eπiv(x-μ) - pr-1,ξ(e,r),π(v(x - μ))∣∣∣x-μ∣≤M
k,l
=E |aqk+l| ∙ ∣∣eπix - pr-1,ξ(e,r),π (XO)IlW ∣≤M ∣v∣
k,l
≤〉： |aqk+l 1 ∙ Ienx - pr-1,ξ(e,r),π (x )∣∣x0∣≤ξ(gr)
k,l
≤Σ>qk+l k E
k,l
=IaIi ∙ e,
where the second inequality holds since M|v| ≤ ξ(e,r), hence the desired result.	□
13