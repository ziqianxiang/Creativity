Under review as a conference paper at ICLR 2021
Latent Causal Invariant Model
Anonymous authors
Paper under double-blind review
Ab stract
Current supervised learning can learn spurious correlation during the data-fitting
process, imposing issues regarding interpretability, out-of-distribution (OOD) gen-
eralization, and robustness. To avoid spurious correlation, we propose a Latent
Causal Invariance Model (LaCIM) which pursues causal prediction. Specifically,
we introduce latent variables that are separated into (a) output-causative factors and
(b) others that are spuriously correlated to the output via confounders, to model
the underlying causal factors. We further assume the generating mechanisms from
latent space to observed data to be causally invariant. We give the identifiable claim
of such invariance, particularly the disentanglement of output-causative factors
from others, as a theoretical guarantee for precise inference and avoiding spurious
correlation. We propose a Variational-Bayesian-based method for estimation and
to optimize over the latent space for prediction. The utility of our approach is
verified by improved interpretability, prediction power on various OOD scenarios
(including healthcare) and robustness on security.
1	Introduction
Current data-driven deep learning models, revolutionary in various tasks though, heavily rely on i.i.d
data to exploit all types of correlations to fit data well. Among such correlations, there can be spurious
ones corresponding to biases (e.g., selection or confounding bias due to coincidence of the presence of
the third factor) inherited from the data provided. Such data-dependent spurious correlations can erode
the (i) interpretability of decision-making, (ii) ability of out-of-distribution (OOD) generalization,
i.e., extrapolation from observed to new environments, which is crucial especially in safety-critical
tasks such as healthcare, and (iii) robustness to small perturbation (Goodfellow et al., 2014).
Recently, there is a Renaissance of causality in machine learning, expected to pursue causal prediction
(SchOlkopf, 2019). The so-called “causality” is pioneered by Judea Pearl (Pearl, 2009), as a math-
ematical formulation of this metaphysical concept grasped in the human mind. The incorporation
of a priori about cause and effect endows the model with the ability to identify the causal structure
which entails not only the data but also the underlying process of how they are generated. For causal
prediction, the old-school methods (Peters et al., 2016; Buhlmann, 2018) causally related the output
label Y to the observed input X, which however is NOT conceptually reasonable in scenarios with
sensory-level observed data (e.g. modeling pixels as causal factors of Y does not make much sense).
For such applications, we rather adopt the manner in Bengio et al. (2013); Biederman (1987) to relate
the causal factors of Y to unobserved abstractions denoted by S, i.e., Y — fy (S, εy) via mechanism
fy. We further assume existence of additional latent components denoted as Z, that together with
S generates the input X via mechanism fχ as X J fx(S, Z,εχ). Taking image classification as an
example, the S and Z respectively refer to object-related abstractions (e.g., contour, texture, color)
and contextual information (e.g., light, view). Such an assumption is similarly adopted in the literature
of nonlinear Independent Components Analysis (ICA) (Hyvarinen and Morioka, 2016; Hyvarinen
et al., 2019; Khemakhem, Kingma and Hyvarinen, 2020; Teshima et al., 2020) and latent generative
models (Suter et al., 2019), which are however without separation of output (y)-causative factors
(a.k.a, S) and other correlating factors (a.k.a, Z) that can both be learned in data-fitting process.
We encapsulate these assumptions into a novel causal model, namely Latent Causal Invariance Model
(LaCIM) as illustrated in Fig. 1, in which we assume the structural equations fx (associated with
S, Z → X), fy (associated with S → Y) to be the Causal Invariant Mechanisms (CIMe) that hold
under any circumstances with P(S, Z) allowed to be varied across domains. The incorporation of these
1
Under review as a conference paper at ICLR 2021
priories can explain the spurious correlation embedded in the back-door path from Z to Y (contextual
information to the class label in image classification). To avoid learning spurious correlations, our
goal is to identify the intrinsic CIMe fx , fy . Specifically, we first prove the identifiability (i.e., the
possibility to be precisely inferred up to an equivalence relation) of the CIMe. Notably, far beyond the
scope in existing literature (Khemakhem, Kingma and Hyvarinen, 2020), our results can implicitly,
and are the first to disentangle the output-causative factors (a.k.a, S) from others (a.k.a, Z) for
prediction, to ensure the isolation of undesired spurious correlation. Guaranteed by such, we propose
to estimate the CIMe by extending the Variational Auto-encoder (VAE) (Kingma and Welling, 2014)
to the supervised scenario. For OOD prediction, we propose to optimize over latent space under
the identified CIMe. To verify the correctness of our identifiability claim, we conduct a simulation
experiment. We further demonstrate the utility of our LaCIM via high explainable learned semantic
features, improved prediction power on various OOD scenarios (including tasks with confounding
and selection bias, healthcare), and robustness on security.
We summarize our contribution as follows: (i) Methodologically, we propose in section 4.1 a latent
causal model in which only a subset of latent components are causally related to the output, to avoid
spurious correlation and benefit OOD generalization; (ii) Theoretically, we prove the identifiability
(in theorem 4.3) of CIMe fx, fy from latent variables to observed data, which disentangles output-
causative factors from others; (iii) Algorithmically, guided by the identifiability, we in section 4.3
reformulate Variational Bayesian method to estimate CIMe during training and optimize over latent
space during the test; (iv) Experimentally, LaCIM outperforms others in terms of prediction power
on OOD tasks and interpretability in section 5.2, and robustness to tiny perturbation in section 5.3.
2	Related Work
The invariance/causal learning proposes to learn the assumed invariance for transferring. For the
invariance learning methods in Krueger et al. (2020) and Scholkopf (2019), the “invariance” can
refer to stable correlation rather than causation, which lacks the interpretability and impedes its
generalization to a broader set of domains. For causal learning, Peters et al. (2016); Buhlmann
(2018); Kuang et al. (2018); Heinze-Deml and Meinshausen (2017) assume causal factors as observed
input, which is inappropriate for sensory-level observational data. In contrast, our LaCIM introduces
latent components as causal factors of the input; more importantly, we explicitly separate them
into the output-causative features and others, to avoid spurious correlation. Further, we provide the
identifiability claim of causal invariant mechanisms. In independent and concurrent works, Teshima
et al. (2020) and Ilse et al. (2020) also explore latent variables in causal relation. As comparisons,
Teshima et al. (2020) did not differentiate S from Z ; and Ilse et al. (2020) proposed to augment
intervened data, which can be intractable in real cases.
Other works which are conceptually related to us, as a non-exhaustive review, include (i) transfer
learning which also leverages invariance in the context of domain adaptation (Scholkopf et al., 2011;
Zhang et al., 2013; Gong et al., 2016) or domain generalization (Li et al., 2018; Shankar et al., 2018);
and (ii) causal inference (Pearl, 2009; Peters et al., 2017) which proposes a structural causal model to
incorporate intervention via “do-calculus” for cause-effect reasoning and counterfactual learning; (iii)
latent generative model which also assumes generation from latent space to observed data (Kingma
and Welling, 2014; Suter et al., 2019) but aims at learning generator in the unsupervised scenario.
3	Preliminaries
Problem Setup & Notation Let X, Y respectively denote the input and output variables. The training
data {De}e∈Etrain are collected from the set of multiple environments Etrain, where each domain
_	. _ 一 ■ -一	c ，_-八	一- _ _	_ - ,	-	i i rl	_
e is associated with a distribution P (X, Y) over XXY and De = {xf, yf, de}i∈[ne] 〜 P with
[k] := {1, ..., k} for any k ∈ Z+. The de ∈ {0, 1}m denotes the one-hot encoded domain index for
e, where 1 ≤ m := Etrain ≤ n := Pe∈Etrain ne. Our goal is to learn a model f : X 7→ Y that
learns output (y)-causative factors for prediction and performs well on the set of all environments
E ⊃ Etrain, which is aligned with existing OOD generalization works (Arjovsky et al., 2019; Krueger
et al., 2020). We use respectively upper, lower case letter and Cursive letter to denote the random
variable, the instance and the space, e.g., a is an instance in the space A of random variable A. The
[f]A denotes the f restricted on dimensions of A. The Sobolev space Wk,p(A) contains all f such
that RA ∂Afα A=a pda < ∞, ∀α ≤ k.
2
Under review as a conference paper at ICLR 2021
Structural Causal Model. The structural causal model (SCM) is defined as the causal graph assigned
with structural equations. The causal graph encodes the assumptions in missing arrows in a directed
acylic graph (DAG): G = (V, E) with V, E respectively denoting the node set and the edge set. The
P a(k) denotes the set of parent nodes of Vk for each Vk ∈ V and the X → Y ∈ E indicates the
causal effect of X on Y. The structural equations {Vk J fk(Pa(k),εk)}Vk∈V, quantify the causal
effects shown in the causal graph G. By assuming independence among exogenous variables {εk}k,
the Causal Markov Condition states that P({Vk = vk}Vk∈V) = ΠkP(Vk = vk|Pa(k) = pa(k)). A
back-door path from Va to Vb is defined as a path that ends with an arrow pointing to Va (Pearl, 2009).
4	Methodology
We build our causal model associated with Causal Invariant Mechanism (CIMe, i.e., fx , fy) and a
priori about the generating process in section 4.1, followed by our identifiability result for CIMe in
section 4.2. Finially, we introduce our learning method to estimate CIMe in section 4.3.
4.1	LaTENT CAUSAL INVARIANCE MODEL
We introduce latent variables to model the abstrac-
tions/concepts that play as causal factors that generate the
observed variables (X, Y), which is more reasonable than
assuming the X as the direct cause of Y in scenarios with
sensory-level data. We explicitly separate the latent variables
into two parts: the S and Z that respectively denote the y
(output)-causative and y-non-causative factors, as shown by
the arrow S → Y in Fig. 1. Besides, the X and Y are re-
spectively generated by S, Z and S, via structural equations
(with noise) fx , fy , which are denoted as Causal Invariant
Mechanisms (CIMe) that hold across all domains. The out-
put Y denotes the label generated by human knowledge,
e.g., the semantic shape, the contour to discern the object,
etc. Hence, we assume the Y as the outcome/effect of these
high-level abstractions (Biederman, 1987) rather than the
cause (detailed comparison with Y → S is left in supple-
mentary 7.7.1). We call the model associated with the causal
Figure 1: The DAG for LaCIM.
The variables marked by white (gray)
color represent the unobserved (ob-
served) variables. Each arrow repre-
sents the causal effect from the vari-
able it points from on the one it points
to. The C denotes the confounder of
S, Z, which are the causal factors of
X, Y . The D denotes the domain in-
dex, which varies across domains and
characterizes the distribution of C .
graph in Fig. 1 as Latent Causal Invariance Model (LaCIM), with formal definition given in Def. 4.1.
As an illustration, we consider the image classification in which X, Y denote the image and the class
label. Instead of X, i.e., the pixels, it is more reasonable to assume the causal factors (of X, Y) as
latent concepts (S, Z) that can denote light, angle, the shape of the object to generate X following
the physical mechanisms. Among these concepts, only the ones that are causally related to the object,
i.e., S (e.g., shape) are causal factors of the object label, i.e., Y. Following the physical or natural
law, the mechanisms S, Z → X, S → Y invariantly hold across domains. The S := Rqs , Z := Rqz
denote the space of S, Z, with Pe(S, Z) (that characterizes the correlation between S and Z) varying
across E (e.g., the object is more associated with a specific scene than others).
We assume that the y-non-causative factor (i.e., Z) is associated with (but not causally related to) S,Y
through the confounder C, which is allowed to take a specific value for each sample unit. Therefore,
the back-door path Z — C → S → Y induces the correlation between Z and Y in each single domain.
Rather than invariant causation, this correlation is data-dependent and can vary across domains, which
is known as “spurious correlation”. In real applications, this spurious correlation corresponds to the
bias inherited from data, e.g. the contextual information in object classification. This domain-specific
S-Z correlation, can be explained by the source variable D, which takes a specific and fixed value for
each domain and functions the prior of distribution of the confounder C , as illustrated in Fig. 1. This
source variable D can refer to attributes/parameters that characterize the distribution of S, Z in each
domain. When such attributes are unobserved, we use the domain index as a substitute. Consider
the cat/dog classification task as an illustration, the animal in each image is either associated with
the snow or grass. The S, Z respectively denote the concepts of animals and scenes. The D denotes
the sampler, which can be described by the proportions of scenes associated with the cat and those
associated with the dog. The D generates the C that denotes the (time, weather) to go outside and
3
Under review as a conference paper at ICLR 2021
collect samples. Since each sampler may have a fixed pattern (e.g. gets used to going out in the sunny
morning (or in the snowy evening)), the data he/she collects, may have sample selection bias (e.g.
with dogs (cats) more associated with grass (snow) in the sunny morning (or snowy evening) ). In
this regard, the scene concepts Z can be correlated with the animal concepts S, and also the label Y .
Definition 4.1 (LaCIM). The Latent Causal Invariance Model (LaCIM) for e ∈ E is defined as a
SCM characterized by (i) the causal graph, i.e., the G = (V, E) with V = {C, S, Z, X, Y } and
E = {C → S, C → Z, Z → X, S → X, S → Y }; and (ii) structural equations with causal mech-
anisms {fc, fz,fs,fχ,fy} embodying the quantitative causal information: C J fc(de, εc),z J
fz(c,εz), S J fs(c,εs); X J fχ(s,z,εχ); y J fy (s,εy), in which {£」—,ε,s,εχ,εy} are indepen-
dent exogenous variables that induce pfc (c|de), pfz (z|c), pfs (s|c), pfx (x|s, z), pfy (y|s). The CIMe
fx, fy are assumed to be invariant across E. We call the environment-dependent parts: Pe(S, Z) and
Pe (S, Z |X ) as S, Z -prior and S, Z -inference in the following.
Remark 1. We denote LaCIM-ds and LaCIM-d as two versions of LaCIM, with the source variable
ds with practical meaning (e.g. attributes or parameters of P(S, Z)) observed or not. The observation
of ds can be possible in some applications (e.g., age, gender that characterizes population in medical
diagnosis). As for the LaCIM-d with ds unobserved, we use domain index D as a substitute.
Denote C as the space of C. We assume that the C is finite union of disjoint sets {Cr}rR=1, i.e.
C := ∪rR=1Cr, such that for any cr,i 6= cr,j ∈ Cr, it holds that p(s, z|cr,i) = p(s, z|cr,j) for any (s, z).
Returning to the cat/dog classification example, the C denotes the range of time to collect samples, i.e.,
00 : 00-24 : 00. The C can be divided into several time periods C1, ..., CR, such that the proportion of
concepts of (animal,scene) given any c in the same period is unchanged, e.g., the dog often comes
up on the grass in the morning. Further, since p(x, y|s, z) = p(x|s, z)p(y|s) is invariant, we have
for each Cr that p(x, y|cr,i) = p(x, y|s, z)p(s, z|cr,i)dsdz = p(x, y|s, z)p(s, z |cr,j)dsdz =
p(x, y∣Cr,j) for any (x, y). That is, the {p(x, y∣Cr}cr∈cr for each (x, y) collapse to a single point,
namely p(x, y|cr). In this regard, we have pe(x, y) := p(x, y|de) = PrR=1 p(x, y|cr)p(cr |de).
Besides, we assume the Additive Noise Model (ANM) for X, i.e., fx(s, z, εx) = fx(s, z) + εx (we
replace fχ with fχ without loss of generality), which has been widely adopted to identify the causal
factors (Janzing et al., 2009; Peters et al., 2014; Khemakhem, Kingma and Hyvarinen, 2020). We need
to identify the CIMe (i.e., fx, fy), guaranteed by the identifiability that ensures the learning method to
distinguish S from Z to avoid spurious correlation, as presented in section 4.2. Traditionally speaking,
the identifiability means the parameter giving rise to the observational distribution pθ? (x, y∣de) can
be uniquely determined, ι.e., pθ(x, y∣de) = p©(x, y∣de) =⇒ θ = θ. Instead of strict uniqueness,
we rather identify an equivalent class of θ? (in Def. 4.2) that suffices to disentangle the y-causative
features S from Z to avoid learning spurious correlation. To achieve this goal, we first narrow our
interest in case when p(s, z∣c) is exponential family in Eq. (1), in which we can respectively identify
the S, Z up to linear and point-wise transformations given by theorem 4.3; then we generalize to any
p(s, z ∣c) as long as it belongs to Sobolev space, as explained in theorem 4.4.
A reformulated VAE is proposed to learn the CIMe practically. For generalization, note that the
gap between two environments in terms of prediction given x, i.e., Epe2 [Y |X = x] - Epe1 [Y |X =
x] = RS pe2 (s|x) - pe1 (s|x)pfy (y|s)ds, is mainly due to the inconsistency of S, Z-inference, i.e.,
pe(s, z∣x) 6= pe0 (s, z∣x) for e0 6= e (for details please refer to theorem 7.1 in supplement 7.1).
Therefore, one cannot directly apply the trained {pe(s, z∣x), pe(y∣x)}e∈Etrain to the inference model
of new environment, i.e. pe0 (s, z∣x),pe0 (y∣x) for e0 ∈/ Etrain. To solve this problem and generalize to
new environment, we note that since pfx (x∣s, z) and pfy (y∣s) are shared among all environments, we
propose to inference s, z that give rise to the test sample x via maximizing the identified pfx (x∣s, z),
as a pseudo-likelihood ofx given (s, z), rather than using S, Z-inference model which is inconsistent
among environments. Then, we feed estimated s into invariant predictor pfy (y∣s) for prediction.
4.2	Identifiability of Causal Invariant Mechanisms
We present the identifiability claim about the CIMe fx , fy, which implicitly distinguishes the y-
causative factors (a.k.a, S) from others (a.k.a, Z) for prediction, to provide a theoretical guarantee for
avoiding spurious correlations. Notably, the S and Z play “asymmetric roles” in terms of generating
process, as reflected in additional generating flow from S to Y . This “information intersection”
property of S, i.e., f-1(y) = [f-1]s(x) for any (x, y) ∈ fχ(S, Z) X fy(S) if y = fy(s) + Ey, is
exploited to disentangle S from Z. Such a disentanglement analysis, is crucial to causal prediction
4
Under review as a conference paper at ICLR 2021
XTit,j(ti)Γtc,i,j +Bi(ti) - Atc,i fort = s,z, ande ∈ E,	(1)
but lacked in existing literature about identifiability, such as those identifying the discrete latent
Confounders (Janzing, Sgouritsa, Stegle, Peters and SchOlkopf, 2012; Sgouritsa et al., 2013); or those
relying on ANM assumption (Janzing, Peters, Mooij and Scholkopf, 2012); linear ICA (Eriksson
and Koivunen, 2003); (Khemakhem, Kingma and Hyvarinen, 2020; Khemakhem, Monti, Kingma
and Hyvarinen, 2020; Teshima et al., 2020) (Please refer to supplement 7.6 for more broad reviews).
Besides, our analysis extends the scope of Khemakhem, Kingma and Hyvarinen (2020) to categorical
Y and general forms of P(S, Z|C = c) that belongs to Sobolev space, in theorem 4.4. Note that our
analysis does NOT require observing the original source variable ds .
We first narrow our interest to a family class of LaCIM denoted as Pexp in which any p ∈ Pexp
satisfies that (i) the S, Z belong to the exponential family; and that (ii) the Y is generated from the
ANM. We will show later that Pexp can approximate any P(S, Z|c) ∈ Wr,2(S × Z) for some r ≥ 2:
PeXP = {LaCIM with y = fy(s) + εy,p(s,z∖c) := PTz,rz (ζ∣c)pτs,rs(s∣c)}
qt
with pTt,Γt (t) := exp
i=1	j=1
where {Tit,j (ti)}, {Γtc,i,j} denote the sufficient statistics and natural parameters, {Bi}, {Atc,i} de-
note the base measures and normalizing constants to ensure the integral of distribution equals
to 1. Let	Tt(t)	:=	[Tl(tι),...,Tqt(tqt)]	∈	Rkt×qt	(Ti(ti)	:= [Wι(ti),...,T%(ti)],∀i	∈	㈤)，
γC := [ΓC,1,..., rc,qt] ∈ Rkt×qt (rc,i ：=[「c,i,i,...,rc,i,kt],∀i ∈ [qt]). We define the 〜p-identifiability
for θ := {fx, fy, Ts, Tz} as:
Definition 4.2 (〜p-identifiability). We define a binary relation on the parameter space of X XY:
θ 〜P θ if there exist two sets OfPermutatlOn matrices and vectors, (Ms,a§) and (Mz, a%) for S and
z respectively, such that for any (x, y) ∈ X × Y,
Ts([f-1]s(X)) = MsTs([f-1]s(x)) + as, Tz([f-1]ζ(x)) = MzTz([f-1]Z(x)) + az,
Pfy (y∖[f-1]s(X)) =Pfy (y\[f-1]s(X)),
We say that θ is 〜P-identifiable, if for any θ, Pe (x, y) = Pf (x, y) ∀e ∈ Etrain, implies θ 〜P θ.
It can be shown that 〜P satisfies the reflective property (θ 〜P θ), the symmetric property (if θ 〜P θ
then θ 〜P θ), and the transitive property (if θɪ 〜P θ2 and θ2 〜P θ3, then θɪ 〜P θ3), and hence is an
equivalence relation (details in supplement 7.2). This definition states that the S, Z can be identified
up to permutation and point-wise transformation, which is sufficient for disentanglement of S and
identifying the predicting mechanism Pfy (y∖[fx-1]S (X)). Specifically, the definition regarding fx
implies the separation of S and Z unless the extreme case when S can be represented by Z, i.e.,
there exists a function h : S → Z such that [fx-1]S(X) = h([fx-1]Z(X)). This definition is inspired
by but beyond the scope of unsupervised scenario considered in nonlinear ICA (Hyvarinen et al.,
2019; Khemakhem, Kingma and Hyvarinen, 2020) to further distinguish of S from Z. Besides, the
Pfy (y∖[f-1 ]s (x)) = Pfy (y∖[f-1 ]s (x)) further guarantees the identifiability of prediction: predict
using fy (s) with S obtained from fχ. The following theorem presents the 〜p-identifiability for Pexp:
Theorem 4.3 (〜p-identifiability). For θ in the LaCIM Pe (x, y) ∈ PeXP for any e ∈ Etrain, we
assume that i) CIMe satisfies that fx , fx0 and fx00 are continuous and that fx , fy are bijective; ii)
the Tit,j are twice differentiable for any t = s, z, i ∈ [qt], j ∈ [kt]; iii) the exogenous variables
satisfy that the characteristic functions of εx , εy are almost everywhere nonzero. Under the diversity
condition on A := [Pd>e1 , ..., Pd>em]> ∈ Rm×R with Pde := [P(c1∖de), ...,P(cR∖de)] that the A and
[Γtc=s,z - Γtc=s,z]T, ..., [Γtc=s,z - Γtc=s,z]T T have full column rank for both t = s and t = z, we
have that the θ := {fχ,fy, Ts, Tz} are『identifiable.
The bijectivity of fx and fy have been widely assumed in Janzing et al. (2009); Peters et al. (2014;
2017); Khemakhem, Kingma and Hyvarinen (2020); Teshima et al. (2020) as a basic condition
for identifiability. It naturally holds for fx to be bijective since the latent components S, Z, as
high-level abstractions which can be viewed as embeddings in auto-encoder (Kramer, 1991), lies in
lower-dimensional space compared with input X which is supposed to have more variations, i.e.,
(qs + qz < qx). For categorical Y , the fy which generates the classification result, i.e., P(y = k∖s) =
[fy ]k (s)/ (Pk [fy ]k (s)), will be shown later to be identifiable.
5
Under review as a conference paper at ICLR 2021
The diversity condition implies that i) m ≥ R ≥ max(kz * qz,k§ * q§) + 1; and that ii) different
environments are variant enough in terms of S-Z correlation (which is also assumed in Arjovsky et al.
(2019)), as a necessary for the invariant one to be identified. As noted in the formulation, a larger m
would be easier to satisfy the condition, which agrees with the intuition that more environments can
provide more complementary information for the identification of the invariant mechanisms.
Remark 2. The dimensions of the ground-truth S, Z are unknown, making the check about whether
m is large enough impossible. Besides, in some real applications, the training environments are
passively observed and may not satisfy the condition. However, we empirically find the improvement
of LaCIM in terms of both OOD prediction and interpretability, if the multiple environments provided
are diverse enough. Besides, a training environment can be the mixture of many sub-environments,
which motivates to splitting the data according to their source ID or clustering results (Teney et al.,
2020) to obtain more environments, making the condition easier to satisfy.
Extension to the general form of LaCIM. We generalize the identifiable result in theorem 4.3 to
any LaCIM as long as its P(S, Z|C = c) ∈ Wr,2 (S × Z) (for some r ≥ 2) and categorical Y , in
the following theorem. This is accomplished by showing that any such LaCIM can be approximated
by a sequence of distributions in Pexp, motivated by the facts in Barron and Sheu (1991) that the
exponential family is dense in the set of distributions with bounded support, and in Maddison et al.
(2016) that the continuous variable with multinomial logit model can be approximated by a series of
distributions with i.i.d Gumbel noise as the temperature converges to infinity.
Theorem 4.4 (Asymptotic 〜p-identifiability). Consider a LaCIM satisfying that pfx(x∣s, Z) and
pfy (y|s) are smooth w.r.t s, z and s respectively. For each e and c ∈ C, suppose Pe(S, Z|C = c) ∈
Wr,2(S × Z)forsome r ≥ 2, we have that P is asymptotically 〜P-identifiable defined as: ∀ e > 0,
∃ 〜p-identifiablePθ ∈ Pexp, s.t. dp°k(pe(x, y),Pe(x,y)) < e,∀e ∈ Etrain, (x,y) ∈X ×Y 1.
4.3	Causal Supervised Variational Auto-Encoder
Guided by identifiability, we first provide the training method to learn fx , fy by reformulating VAE
in a supervised scenario, followed by optimization over latent space for inference and test.
Training. To learn the CIMe and pfx (x|s, z),pfy (y|s) for invariant prediction, we implement the
generative model to fit {pe(x, y)}e∈Etrain, which has been guaranteed by theorem 4.3, 4.4 to be able
to identify the ground-truth predicting mechanism. Specifically, we reformulate the objective of
VAE, as a generative model proposed in (Kingma and Welling, 2014), in supervised scenario. For
unsupervised learning, the VAE introduces the variational distribution qψ parameterized by ψ to
approximate the intractable posterior by maximizing the following Evidence Lower Bound (ELBO):
-Lφ,ψ = Ep(X) [Eqψ(z∣x) log pφ(Z,Z) ], as a tractable surrogate of maximum likelihood Ep(X) logPφ(χ).
Specifically, the ELBO is less than and equal to Ep(x) log pφ (x) and the equality can only be achieved
when qψ(z∣x)= pφ(z∣x). Therefore, maximizing the ELBO over pφ and qψ will drive ⑴ qψ(z∣x) to
learnpφ(z∣x); (ii) pφ to learn the ground-truth modelP (including pφ(x∣z) to learnp(x∣z)).
In our supervised scenario, we introduce the variational distribution qψe (s, z|x, y) and the correspond-
ing ELBO for any e is -Lφ,ψ=Epe(χ,y) [Eqψ(s,z∣χ,y) log 第(：；：,：)].Similarly, minimizing Lφ,ψ can
drivepφ(x∣s, z),Pφ(y∣s) to learn the CIMe (i.e. Pfx (x|s, z),Pfy (y∣s)), and also qψ (s, z|x, y) to learn
pφ(s,z∣x, y). In other words, the qψ can inherit the properties ofpφ. Aspφ(s,z∣χ,y)=隔与匕篇⑸，)
for our DAG in Fig. 1, we can similarly reparameterize qψ (s, z|x, y) as qψ(SAx)-)®". According
qψ y x
to Causal Markov Condition, we have that pφ(χ,y,s,z) = pφ(χ∣s, z)pφ(s, z)pφ(y∣s). Substituting
the above reparameterizations into the ELBO with qψ(y|s) replaced by pφ(y∣s), the Lφ ψ can be
rewritten as:
小	e	Pφ(y∣s) 1 Pφ(xls,z)pφ(s,z)]
Lφ,ψ = Epe (X,y)[- log qψ (y|x) - Eqψ(S,z|x) qψ (y∣χ) log —qψ (s,z∣χ)—卜	⑵
where qψ(y|x) = RS qψ(s∣x)pφ(y∣s)ds. The overall loss function is: Lφ,ψ = pe∈Etrain Lφ,ψ.
The training datasets {De}e∈Etrain are applied to optimize prior model Peφ(s, z), inference
1The dpok denotes the Pokorov distance and limn→∞ dpok(μn,μ) → 0 ^⇒ μn → μ.
6
Under review as a conference paper at ICLR 2021
Table 1: MCC of identified latent variables. Average over 20 times for each data.
	Data #1	Data #2	Data #3	Data #4	Data #5	Average
	Z S	Z S	Z S	Z S	Z S	Z	S
	 pool-LaCIM	0.28 0.58	0.38 0.66	0.34 0.77	0.34 0.79	0.36 0.75	0.34	0.71
LaCIM-ds (Ours, m = 5)	0.81 0.86	0.81 0.87	0.85 0.87	0.73 0.78	0.86 0.87	0.82	0.85
LaCIM-d (Ours, m = 3)	0.62 0.88	0.63 0.83	0.70 0.78	0.69 0.81	0.71 0.84	0.67	0.83
LaCIM-d (Ours, m = 5)	0.64 0.82	0.75 0.80	0.76 0.83	0.79 0.90	0.75 0.85	0.74 ↑ 0.84 ↑
LaCIM-d (Ours, m = 7)	0.70 0.89	0.81 0.90	0.82 0.88	0.84 0.83	0.90 0.85	0.81 ↑ 0.87 ↑
model qψ(s,z∣x) and generative models pφ(x∖s,z),pφ(y|s) in Eq. (2). The generative models
Pφ(x|s, z'),pφ(y∖s') are shared among all environments, while the pφ(s, z),qψ(s,z∣x) are respec-
tively pφ(s, z|dse), qψ (s, z|x, dse) and pφ(s, z|de), qψ (s, z|x, de) for LaCIM-ds and LaCIM-d.
Inference & Test. When dse0 can be acquired during test for e0 ∈ Etest , we can predict y as
argmaxypφ(y∖x, des0) = qψ (s∖x, des0)pφ(y∖s)ds. Otherwise, for LaCIM-d with ds unobserved,
we first optimize s, z via (s?, z?) := arg maxs,z logpφ(x∖s, z) and predict y as arg maxy qψ(y∖s?).
Specifically, we adopt the strategy for optimization in Schott et al. (2018) that we first sample initial
points and select the one with the maximum logpφ(x∖s, z), then we optimize for 50 iterations using
Adam. The implementation details and optimization effect are shown in supplement 7.9.
5 Experiments
We evaluate LaCIM on (I) synthetic data to verify the identifiability in theorem 4.3; (II) OOD
challenges: object classification with sample selection bias (Non-I.I.D. Image dataset with Contexts
(NICO)); Hand-Writing Recognition with confounding bias (Colored MNIST (CMNIST)); prediction
of Alzheimer’s Disease (Alzheimer’s Disease Neuroimaging Initiative (ADNI www.loni.ucla.
edu/ADNI); (III) Robustness on detecting images with small perturbation (FaceForensics++).
5.1 Simulation
To verify the identifiability claim and effectiveness of our learning method, we implement LaCIM
on synthetic data. The data generating process is provided in Supplement 7.8. The domain index
D ∈ Rm is denoted as a one-hot encoded vector with m = 5. To verify the utility of training on
multiple domains (m > 1), we also conduct LaCIM by pooling data from all m domains together,
namely pool-LaCIM for comparison. We randomly generate m = 5 datasets and run 20 times for
each. We compute the metric mean correlation coefficient (MCC) adopted in Khemakhem, Kingma
and Hyvarinen (2020) to measure the goodness of identifiability under permutation by introducing
cost optimization to assign each learned component to the source component. This measurement is
aligned with the goal of -p-identifiability, which allows us to distinguish S from Z. Table 5.1 shows
the superiority of our LaCIM-d, LaCIM-ds over pool-LaCIM in terms of the CIMe relating to S, Z
under permutation, by means of multiple diverse experiments. Besides, we consider LaCIM-d on
m = 3, 5, 7 with the same total number of samples. It yields that more environments can perform
better; and that even m = 3 still performs much better than pool-LaCIM. To illustrate the learning
effect, we visualize the learned Z in Fig. 7.8, with S left in supplement 7.8 due to space limit.
(b)pLaCIM(z∖x,y,ds)
(c)pLaCIM(z∖x,y,d)
(d) pφ? (z∖ds)
Figure 2: Visualization of Z. From left to right are: estimated posterior by pool-LaCIM, LaCIM-ds,
LaCIM-d and the ground-truth. As shown, the LaCIM-ds (Fig.(b)) and LaCIM-d (Fig.(c)) can identify
the ground truth distribution of Z (i.e., pφ? (z∖ds)) up to permutation and point-wise transformation,
which validates the claim in theorem 4.3.
(a) ppool-LaCIM (z ∖x, y)
7
Under review as a conference paper at ICLR 2021
5.2 Real-world OOD Challenge
We present our LaCIM’s results on three OOD tasks, with different environments associated with
different values of ds . We implement both versions of LaCIM, i.e., LaCIM-ds and LaCIM-d, with
task-dependent definition of ds . In CMNIST, the ds (digit color) is a fully observed confounder, and
LaCIM-ds in this case is the ceiling of LaCIM-d under the same implementation. In NICO and ADNI,
the LaCIM-d even outperform LaCIM-ds, when the source variables are only partially observed.
Dataset. We describe the datasets as follows (the X denote image; the Y denote label):
NICO: we evaluate the cat/dog classification in “Animal” dataset in NICO, a benchmark for non-i.i.d
problem in He et al. (2019). Each animal is associated with “grass”,“snow” contexts with different
proportions, denoted as ds ∈ R4 (cat,dog in grass,snow). We set m = 8 and m = 14. The C, Z, S
respectively denote the (time,whether) of sampling, the context and semantic shape of cat/dog.
CMNIST: We relabel the digits 0-4 and 5-9 as y = 0 and y = 1, based on MNIST. Then we color
pe (1 - pe) of images with y = 0 (y = 1) as green and color others as red. We set m = 2 with
pe1 = 0.9, pe2 = 0.8. The des is pe to describe the intensity of spursiou correlation caused by color.
We do not flip y with 25% like Arjovsky et al. (2019) 2, since doing so will cause the digit correlated
rather than causally related to the label, which is beyond our scope. The Z, S respectively represent
the color and number. The C can also denote (time,whether) for which the painter draws the number
and color, e.g., the painter tends to draw red 0 more often than green 1 in the sunny morning.
ADNI. The data are obtained from the ADNI databaset, the Y := {0, 1, 2} with 0,1,2 respectively
denoting AD, Mild Cognitive Impairment (MCI) and Normal Control (NC). The X is Magnetic
resonance imaging (sMRI). We set m = 2. We consider two types of ds : Age and TAU (a biomarker
Humpel and Hochstrasser (2011)). The S (Z) denote the disease-related (-unrelated) brain regions.
The C denotes the hormone level that can affect the brain structure development.
Compared Baselines. We compare with (i) Cross-Entropy (CE) from X → Y (CE X → Y ), (ii)
domain-adversarial neural network (DANN) for domain adaptation Ganin et al. (2016), (iii) Maximum
Mean Discrepancy with Adversarial Auto-Encoder (MMD-AAE) for domain generalization Li et al.
(2018), (iv) Domain Invariant Variational Autoencoders (DIVA) Ilse et al. (2019) (v) Selecting Data
Augmentation (SDA) Ilse et al. (2020), (vi) Invariant Risk Mnimization (IRM) Arjovsky et al. (2019),
(vii) CE (X, ds) → Y , (viii) VAE with causal graph C → V → {X, Y } with V mixing S, Z and
we call it sVAE for simplicity. We only implement SDA on CMNIST, since the intervened-data
generation of SDA requires explicitly extracting the S, Z, which is intractable in ADNI and NICO.
For fair comparison, we keep the model capacity (numer of parameters) in the same level.
Implementation Details. For each domain e, we implement the reparameterization with ρes , ρez :
s0, z0 = ρes(s), ρze(z), to transform the pe(s, z) into isotropic Gaussian; then the generative models
are correspondingly modified as {pφ(x∣(ρe)-1(s), (Pz)-1 (z)),Pφ(y∣(ρS)-1(s))} according to rule of
change of variables. The optimized parameters are {{qψ (s,z∣χ)}e,pφ(χ∣s, z),pψ(y∖s), {Pe=s,z}e},
with the encoder qψe (s, z|x) being sequentially composed of: i) the sequential of Conv-BN-ReLU-
MaxPool blocks that shared among Etrain , followed by ii) the sequential of ReLU-FC for the mean
and log-variance of S, Z that are specific to e. The structure of Pte=s,z is FC-ReLU-FC. The decoder
pφ(x∖s, z) is the sequential of upsampling, several TConv-BN-ReLU blocks and Sigmoid. The
predictor pφ(y∖s) is sequential of FC→BN→ReLU blocks, followed by Softmax (or Sigmoid) for
classification. The network structure and the output channel size for CMNIST, NICO and ADNI
are introduced in supplement 7.11, 7.12, 7.13, Tab. 13, 14. We implement SGD as optimizer: with
learning rate (lr) 0.5 and weight decay (wd) 1e-5 for CMNIST; lr 0.01 with decaying 0.2× every
60 epochs, wd 5e-5 for NICO and ADNI (wd is 2e-4). The batch-size are set to 256, 30 and 4 for
CMNIST, NICO, ADNI. The “FC”, ”BN” stand for Fully-Connected, Batch-Normalization.
Results. We report accuracy over three runs for each method. As shown in Tab. 2 3 our LaCIM-d
performs comparable and better than others on all applications, except the 99.3 achieved by SDA on
CMNIST, which is comparable to the result on the original MNIST. This is because during training,
2We also conduct this experiment with flipping y in supplementary 7.11.
3OnNICO, we implement ConvNet with Batch Balancing as a specifically benchmark in He et al. (2019).
The results are 60 ± 1 on m = 8 and 62.33 ± 3.06 on m = 14.
8
Under review as a conference paper at ICLR 2021
the SDA implemented data augmentation with random colors, which decorrelate the color-label.
When S cannot be explicitly extracted in general case, the SDA is not tractable.
Discussions. The advan-
tage over invariant learn-
ing method (IRM) and CE
(X, ds) → Y which also
takes ds into prediction can
be contributed to the identifi-
cation of true causal mecha-
nisms. Further, the improve-
ment over sVAE is benefited
from our separation of y-
causative factors (a.k.a, S)
from others to avoid spu-
rious correlation. Besides,
as shown from results on
Table 2: Accuracy (%) of OOD prediction. Average over three runs.
Dataset MethOd^^^	NICO		CMNIST	ADNI (m = 2)	
	m = 8	m = 14	m = 2	C : Age	C : TAU
CE X → Y	60.67 ± 2.52	59.00 ± 1.73	97.87 ± 0.19	63.06 ± 2.26	64.58 ± 0.90
DANN	59.33 ± 4.93	60.00 ± 2.65	97.42 ± 0.13	60.84 ± 1.83	64.58 ± 0.90
MMD-AAE	61.33 ± 2.89	66.33 ± 3.21	81.23 ± 7.80	62.43 ± 2.42	65.62 ± 0.00
DIVA	60.67 ± 2.08 一	58.67 ± 1.53-	97.97 ± 0.19	61.37 ± 3.30-	65.10 ± 0.90-
SDA	-	-	99.37 ± 0.03	-	-
IRM	61.67 ± 4.16	65.00 ± 3.00	98.18 ± 0.22	63.49 ± 1.59	65.10 ± 0.90
CE X, ds → Y	57.33 ± 6.03	64.00 ± 1.00	98.03 ± 0.27	62.43 ± 0.92	65.62 ± 0.00
sVAE	59.67 ± 3.79	64.33 ± 0.58	97.89 ± 0.61	63.67 ± 1.87	66.67 ± 0.91
LaCIM-ds (Ours)	62.00 ± 1.73	68.00 ± 2.64	98.81 ± 0.14	65.08 ± 1.59	66.14 ± 0.91
LaCIM-d (Ours)	62.67 ± 0.58	68.67 ± 2.64	98.78 ± 0.20	64.44 ± 0.96	68.23 ± 0.90
NICO, a larger m (with the total number of samples n fixed) can bring further benefit, which
may due to the easier satisfaction of the diversity condition in theorem 4.3. One thing worth particular
mention is that on NICO and ADNI (when ds denotes TAU), our LaCIM-d performs comparable and
even better than LaCIM-ds, due to the existence of unobserved partial variables. For example, each
ds only contains one attribute each time in ADNI. For completeness, we conduct experiments with
fully observed confounders in supplement 7.13. Besides, we apply our method on intervened data,
the result of which can validate more robustness of LaCIM, as shown in supplement 7.12.
Interpretability. We visualize learned S as side proof of interpretability. Specifically, we select the
s* that has the highest correlation With y among all dimension of S, and visualize the derivatives of
s* with respect to the image. For CE X → y and CE (x, ds) → y, We visualize the derivatives of
predicted class scores With respect to the image. As shoWn in Fig. 5.2, LaCIM (the 4th column) can
identify more explainable semantic features, which verifies the identifiability and effectiveness of the
learning method. Supplement 7.12 provides more results.
(a) Cat on grass
(b) Cat on snow
(c) Dog on grass
(d) Dog on snow
Figure 3: Visualization via gradient Simonyan et al. (2013). From the left to right: original image,
CEX → Y,CE(X,ds) → Y and LaCIM-ds.
5.3 Robustness on Security
We consider the DeepFake-related security problem,
which targets on detecting small perturbed fake im-
ages that can spread fake news. The Rossler et al.
(2019) provides FaceForensics++ dataset from 1000
Youtube videos for training and 1,000 benchmark
images from other sources (OOD) for testing. We
split the train data into m = 2 environments accord-
ing to video ID. The considerable result in Tab. 5.3 verifies potential value on security.
Table 3: Accuracy (%) of robustness on Face-
Forensics++. Average over three runs.
CE X → Y	IRM	LaCIM-d (OUrS)
82.8 ± 0.99	83.4 ± 0.59	84.47 ± 0.90
6 Conclusions & Discussions
We incorporate the causal structure as prior knowledge in proposed LaCIM, by introducing: (i) latent
variables and explicitly separate them into y-causative factors (a.k.a, S) and others (a.k.a, Z) which
are spuriously correlated with the output; (ii) the source variable ds that explains the distributional
inconsistency among domains. When the environments are diverse and much enough, we can
successfully identify the causal invariant mechanisms, and also y-causative factors for prediction
without a mix of others. Our LaCIM shows potential value regarding robustness to OOD tasks with
confounding bias, selection bias and others such as healthcare and security. A possible drawback of
our model lies in our requirement of the number of environments (which may be not satisfied in some
scenarios) for identifiability, and the relaxation of which is left in the future work.
9
Under review as a conference paper at ICLR 2021
References
Arjovsky, M., Bottou, L., Gulrajani, I. and Lopez-Paz, D. (2019), ‘Invariant risk minimization’, arXiv preprint
arXiv:1907.02893.
Barron, A. R. and Sheu, C.-H. (1991), ‘Approximation of density functions by sequences of exponential families’,
The Annals of Statistics pp. 1347-1369.
Bellot, A. and van der Schaar, M. (2020), ‘Generalization and invariances in the presence of unobserved
confounding’, arXiv preprint arXiv:2007.10653 .
Ben-David, S., Blitzer, J., Crammer, K. and Pereira, F. (2007), Analysis of representations for domain adaptation,
in ‘Advances in neural information processing systems’, pp. 137-144.
Ben-Tal, A., El Ghaoui, L. and Nemirovski, A. (2009), Robust optimization, Vol. 28, Princeton University Press.
Bengio, Y. (2017), ‘The consciousness prior’, arXiv preprint arXiv:1709.08568 .
Bengio, Y., Courville, A. and Vincent, P. (2013), ‘Representation learning: A review and new perspectives’,
IEEE Transactions on Pattern Analysis and Machine Intelligence 35(8), 1798-1828.
Biederman, I. (1987), ‘Recognition-by-components: a theory of human image understanding.’, Psychological
review 94(2), 115.
BUhlmann, P. (2018), 'Invariance, causality and robustness'，arXivpreprint arXiv:1812.08233 .
Davies, M. (2004), ‘Identifiability issues in noisy ica’, IEEE Signal processing letters 11(5), 470-473.
Dobler, C. et al. (2015), 'Stein's method of exchangeable pairs for the beta distribution and generalizations',
Electronic Journal of Probability 20.
Eriksson, J. and Koivunen, V. (2003), Identifiability and separability of linear ica models revisited, in 'Proc. of
ICA', Vol. 2003, pp. 23-27.
Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M. and Lempitsky, V.
(2016), 'Domain-adversarial training of neural networks', Journal of Machine Learning Research 17, 1-35.
Gatys, L. A., Ecker, A. S. and Bethge, M. (2015), 'A neural algorithm of artistic style', arXiv preprint
arXiv:1508.06576.
Gong, M., Zhang, K., Liu, T., Tao, D., Glymour, C. and Scholkopf, B. (2016), Domain adaptation with
conditional transferable components, in 'International Conference on Machine Learning', pp. 2839-2848.
Goodfellow, I. J., Shlens, J. and Szegedy, C. (2014), 'Explaining and harnessing adversarial examples', arXiv
preprint arXiv:1412.6572 .
Grother, P. J. (1995), 'Nist special database 19 handprinted forms and characters database', National Institute of
Standards and Technology .
Guerreiro, R. and Bras, J. (2015), 'The age factor in Alzheimer's disease', Genome medicine 7(1), 106.
He, Y., Shen, Z. and Cui, P. (2019), 'Towards non-i.i.d. image classification: A dataset and baselines', arXiv
preprint arXiv:1906.02899 .
Heinze-Deml, C. and Meinshausen, N. (2017), 'Conditional variance penalties and domain shift robustness',
arXiv preprint arXiv:1710.11469 .
Hoyer, P., Janzing, D., Mooij, J. M., Peters, J. and Scholkopf, B. (2008), 'Nonlinear causal discovery with
additive noise models', Advances in neural information processing systems 21, 689-696.
Huang, J., Gretton, A., Borgwardt, K., Scholkopf, B. and Smola, A. J. (2007), Correcting sample selection bias
by unlabeled data, in 'Advances in Neural Information Processing Systems', pp. 601-608.
Humpel, C. and Hochstrasser, T. (2011), 'Cerebrospinal fluid and blood biomarkers in Alzheimer's disease',
World journal of psychiatry 1(1), 8.
Hyvarinen, A. and Morioka, H. (2016), Unsupervised feature extraction by time-contrastive learning and
nonlinear ica, in 'Advances in Neural Information Processing Systems', pp. 3765-3773.
Hyvarinen, A. and Pajunen, P. (1999), 'Nonlinear independent component analysis: Existence and uniqueness
results', Neural Networks 12(3), 429-439.
10
Under review as a conference paper at ICLR 2021
Hyvarinen, A., Sasaki, H. and Turner, R. (2019), Nonlinear ICA using auxiliary variables and generalized
contrastive learning, in 'The 22nd International Conference on Artificial Intelligence and Statistics,, pp. 859-
868.
Ilse, M., Tomczak, J. M. and Forre, P. (2020), 'Designing data augmentation for simulating interventions,, arXiv
preprint arXiv:2005.01856 .
Ilse, M., Tomczak, J. M., Louizos, C. and Welling, M. (2019), 'DIVA: Domain invariant variational autoencoders,,
arXiv preprint arXiv:1905.10427 .
Janzing, D., Peters, J., Mooij, J. and Scholkopf, B. (2009), Identifying confounders using additive noise models,
in 'Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI 2009),, AUAI Press,
pp. 249-257.
Janzing, D., Peters, J., Mooij, J. and Scholkopf, B. (2012), 'Identifying confounders using additive noise models’,
arXiv preprint arXiv:1205.2640 .
Janzing, D., Sgouritsa, E., Stegle, O., Peters, J. and Scholkopf, B. (2012), 'Detecting low-complexity unobserved
causes,, arXiv preprint arXiv:1202.3737 .
Johansson, F. D., Sontag, D. and Ranganath, R. (2019), Support and invertibility in domain-invariant representa-
tions, in 'The 22nd International Conference on Artificial Intelligence and Statistics,, pp. 527-536.
Kang, G., Dong, X., Zheng, L. and Yang, Y. (2017), 'Patchshuffle regularization,, arXiv preprint
arXiv:1707.07103.
Khemakhem, I., Kingma, D. P. and Hyvarinen, A. (2020), Variational autoencoders and nonlinear ICA: A
unifying framework, in 'Proceedings of the 23th International Conference on Artificial Intelligence and
Statistics (AISTATS-23),, Vol. 108, AISTATS Committee, PMLR, Palermo, Italy.
Khemakhem, I., Monti, R. P., Kingma, D. P. and Hyvarinen, A. (2020), 'Ice-beem: Identifiable conditional
energy-based deep models,, arXiv preprint arXiv:2002.11537 .
Kingma, D. P. and Welling, M. (2014), Auto-encoding variational Bayes, in 'Proceedings of the International
Conference on Learning Representations (ICLR 2014),, ICLR Committee, Banff, Canada.
Kocaoglu, M., Shakkottai, S., Dimakis, A. G., Caramanis, C. and Vishwanath, S. (2018), 'Entropic latent variable
discovery,, arXiv preprint arXiv:1807.10399 .
Kramer, M. A. (1991), 'Nonlinear principal component analysis using autoassociative neural networks,, AIChE
journal 37(2), 233-243.
Krueger, D., Caballero, E., Jacobsen, J.-H., Zhang, A., Binas, J., Priol, R. L. and Courville, A. (2020), 'Out-of-
distribution generalization via risk extrapolation (rex),, arXiv preprint arXiv:2003.00688 .
Kuang, K., Cui, P., Athey, S., Xiong, R. and Li, B. (2018), Stable prediction across unknown environments, in
'Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining,,
pp. 1617-1626.
Lee, C. M., Hart, C., Richens, J. G. and Johri, S. (2019), 'Leveraging directed causal discovery to detect latent
common causes,, arXiv preprint arXiv:1910.10174 .
Li, D., Yang, Y., Song, Y.-Z. and Hospedales, T. M. (2017), 'Learning to generalize: Meta-learning for domain
generalization,, arXiv preprint arXiv:1710.03463 .
Li, H., Jialin Pan, S., Wang, S. and Kot, A. C. (2018), Domain generalization with adversarial feature learning,
in 'Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,, pp. 5400-5409.
Maddison, C. J., Mnih, A. and Teh, Y. W. (2016), 'The concrete distribution: A continuous relaxation of discrete
random variables,, arXiv preprint arXiv:1611.00712 .
Madry, A., Makelov, A., Schmidt, L., Tsipras, D. and Vladu, A. (2017), 'Towards deep learning models resistant
to adversarial attacks,, arXiv preprint arXiv:1706.06083 .
Magliacane, S., van Ommen, T., Claassen, T., Bongers, S., Versteeg, P. and Mooij, J. M. (2018), Domain
adaptation by using causal inference to predict invariant conditional distributions, in 'Advances in Neural
Information Processing Systems,, pp. 10846-10856.
Marcos, D., Volpi, M. and Tuia, D. (2016), Learning rotation invariant convolutional filters for texture classifica-
tion, in '2016 23rd International Conference on Pattern Recognition (ICPR),, IEEE, pp. 2012-2017.
11
Under review as a conference paper at ICLR 2021
Mortimer, J. A. (1997), ‘Brain reserve and the clinical expression of Alzheimer’s disease.’, Geriatrics (Basel,
Switzerland) 52, S50-3.
Muandet, K., Balduzzi, D. and Scholkopf, B. (2013), Domain generalization via invariant feature representation,
in ‘International Conference on Machine Learning’, pp. 10-18.
Pan, S. J., Tsang, I. W., Kwok, J. T. and Yang, Q. (2010), ‘Domain adaptation via transfer component analysis’,
IEEE Transactions on Neural Networks 22(2), 199-210.
Pearl, J. (2009), Causality, Cambridge university press.
Peters, J., Buhlmann, P. and Meinshausen, N. (2016), 'Causal inference by using invariant prediction: identifica-
tion and confidence intervals’, Journal of the Royal Statistical Society: Series B (Statistical Methodology)
78(5), 947-1012.
Peters, J., Janzing, D. and Scholkopf, B. (2017), Elements of causal inference: foundations and learning
algorithms, MIT press.
Peters, J., Mooij, J. M., Janzing, D. and Scholkopf, B. (2014), 'Causal discovery with continuous additive noise
models’, Journal of Machine Learning Research 15(1), 2009-2053.
Rojas-Carulla, M., Scholkopf, B., Turner, R. and Peters, J. (2018), 'Invariant models for causal transfer learning’,
The Journal of Machine Learning Research 19(1), 1309-1342.
Romeijn, J.-W. and Williamson, J. (2018), 'Intervention and identifiability in latent variable modelling’, Minds
and machines 28(2), 243-264.
Rossler, A., Cozzolino, D., Verdoliva, L., Riess, C., Thies, J. and Nieβner, M. (2019), Faceforensics++: Learning
to detect manipulated facial images, in 'Proceedings of the IEEE International Conference on Computer
Vision’, pp. 1-11.
Sagawa, S., Koh, P. W., Hashimoto, T. B. and Liang, P. (2019), 'Distributionally robust neural networks for group
shifts: On the importance of regularization for worst-case generalization’, arXiv preprint arXiv:1911.08731 .
Scholkopf, B. (2019), 'Causality for machine learning’, arXivpreprint arXiv:1911.10500 .
Scholkopf, B., Janzing, D., Peters, J. and Zhang, K. (2011), 'Robust learning via cause-effect models’, arXiv
preprint arXiv:1112.2738 .
Schott, L., Rauber, J., Bethge, M. and Brendel, W. (2018), 'Towards the first adversarially robust neural network
model on mnist’, arXiv preprint arXiv:1805.09190 .
Sgouritsa, E., Janzing, D., Peters, J. and Scholkopf, B. (2013), Identifying finite mixtures of nonparametric
product distributions and causal inference of confounders, in 'Proceedings of the 29th Conference on
Uncertainty in Artificial Intelligence (UAI 2013)’, AUAI Press, pp. 556-575.
Shankar, S., Piratla, V., Chakrabarti, S., Chaudhuri, S., Jyothi, P. and Sarawagi, S. (2018), Generalizing
across domains via cross-gradient training, in 'Proceedings of the International Conference on Learning
Representations (ICLR 2018)’.
Shimizu, S., Hoyer, P. O. and Hyvarinen, A. (2009), 'Estimation of linear non-gaussian acyclic models for latent
factors’, Neurocomputing 72(7-9), 2024-2027.
Shorten, C. and Khoshgoftaar, T. M. (2019), 'A survey on image data augmentation for deep learning’, Journal
of Big Data 6(1), 60.
Silva, R., Scheine, R., Glymour, C. and Spirtes, P. (2006), 'Learning the structure of linear latent variable
models’, Journal of Machine Learning Research 7(Feb), 191-246.
Simonyan, K., Vedaldi, A. and Zisserman, A. (2013), 'Deep inside convolutional networks: Visualising image
classification models and saliency maps’, arXiv preprint arXiv:1312.6034 .
Sugiyama, M., Suzuki, T., Nakajima, S., Kashima, H., von Bunau, P. and Kawanabe, M. (2008), 'Direct
importance estimation for covariate shift adaptation’, Annals of the Institute of Statistical Mathematics
60(4), 699-746.
Suter, R., Miladinovic, D., Scholkopf, B. and Bauer, S. (2019), Robustly disentangled causal mechanisms:
Validating deep representations for interventional robustness, in 'International Conference on Machine
Learning’, pp. 6056-6065.
12
Under review as a conference paper at ICLR 2021
Tan, M. and Le, Q. V. (2019), ‘Efficientnet: Rethinking model scaling for convolutional neural networks’, arXiv
preprint, arXiv:1905.11946 .
Taylor, L. and Nitschke, G. (2017), ‘Improving deep learning using generic data augmentation’, arXiv preprint
arXiv:1708.06020.
Teney, D., Abbasnejad, E. and Hengel, A. v. d. (2020), ‘Unshuffling data for improved generalization’, arXiv
preprint arXiv:2002.11894 .
Teshima, T., Sato, I. and Sugiyama, M. (2020), ‘Few-shot domain adaptation by causal mechanism transfer’,
arXiv preprint arXiv:2002.03497 .
Vina, J. and Lloret, A. (2010), ‘Why women have more Alzheimer’s disease than men: gender and mitochondrial
toxicity of amyloid-β peptide,, Journal ofAlzheimer's disease 20(s2), S527-S533.
Worrall, D. E., Garbin, S. J., Turmukhambetov, D. and Brostow, G. J. (2017), Harmonic networks: Deep
translation and rotation equivariance, in ‘Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition,, pp. 5028-5037.
Xie, C., Chen, F., Liu, Y. and Li, Z. (2020), ‘Risk variance penalization: From distributional robustness to
causality,, arXiv preprint arXiv:2006.07544 .
Zhang, C., Bengio, S., Hardt, M., Recht, B. and Vinyals, O. (2016), ‘Understanding deep learning requires
rethinking generalization,, arXiv preprint arXiv:1611.03530 .
Zhang, K., Scholkopf, B., MuandeL K. and Wang, Z. (2013), Domain adaptation under target and conditional
shift, in ‘International Conference on Machine Learning,, pp. 819-827.
Zhao, H., Combes, R. T. d., Zhang, K. and Gordon, G. J. (2019), ‘On learning invariant representation for
domain adaptation,, arXiv preprint arXiv:1901.09453 .
13
Under review as a conference paper at ICLR 2021
7 Supplementary Materials
7.1	O.O.D Generalization error Bound
Denote Ep [y |x] := Y yp(y|x)dy for any x, y ∈ X ×Y. We have Epe [y|s] = Y yp(y|s)dy according
to that p(y|s) is invariant across E, we can omit pe in Epe [y|s] and denote g(S) := E[Y |S]. Then,
the OOD bound Epe1 (y|x) - Epe2 (y|x), ∀(x, y) is bounded as follows:
Theorem 7.1 (OOD genearlization error). Consider two LaCIM Pe1 and Pe2, suppose that their
densities , i.e., pe1 (s|x) and pe2 (s|x) are absolutely continuous having support (-∞, ∞). For any
(x, y) ∈ X × Y, assume that
•	g(S) is a Lipschitz-continuous function;
•	∏χ(s) := .el(S∣χ) is differentiable and Epei [∏x(S)∣g(S) 一 μι ∣] < ∞ With μι :=
Epe1 [g(S)|X = x] = RS g(s)pe1 (s|x)ds;
then we have ∣E.eι (y|x) — Epe2 (y∣x)∣ ≤ ∣∣g0k∞k∏Xk∞Var.eι (S|X = x)∙
When e1 ∈ Etrain and e2 ∈ Etest, the theorem 7.1 describes the error during generalization on e2
for the strategy that trained on e1 . The bound is mainly affected by: (i) the Lipschitz constant of g,
i.e., ∣g∣∞; (ii) ∣πx0 ∣∞ which measures the difference between pei (s, z) and pe2 (s, z); and (iii) the
Varpei (S|x) that measures the intensity of x → (s, z). These terms can be roughly categorized into
two classes: (i),(iii) which are related to the property of CIMe and gave few space for improvement;
and the (ii) that describes the distributional change between two environments. Specifically for the
first class, the (i) measures the smoothness of E(y|s) with respect to s. The smaller value of ∣g0∣∞
implies that the flatter regions give rise to the same prediction result, hence easier transfer from
e1 to e2 and vice versa. For the term (iii), consider the deterministic setting that εx = 0 (leads to
Varpei (S |x) = 0), then s can be determined from x for generalization if the f is bijective function.
The term (ii) measures the distributional change between posterior distributions pei (s|x) and pe2 (s|x),
which contributes to the difference during prediction: ∣E.eι (y|x) — Epe2 (y|x)∣ = JS(pe1 (s|x)—
pei (s|x))pfy (y|s)ds. Such a change is due to the inconsistency between priors pei (s, z) and pe2 (s, z),
which is caused by different value of the confounder ds .
Proof. In the following, we will derive the upper bound
∣∣Epei [Y|X=x] — Epe2 [Y|X=x] ∣∣ ≤ ∣g0∣∞∣πx0 ∣∞ Varpei (S|X=x),
where ∏χ(s) =: )：(：|：) and g(s) is assumed to be Lipschitz-continuous.
To begin with, note that
E[Y|X] = E[E(Y |X, S)|X]
E[g(S)|X]=
g(s)p(s|x)ds.
Let p1(s|x) = pei (s|x), p2(s|x) = pe2 (s|x). For ease of notations, we use P1 and P2 denote the
distributions with densities pι(s∣χ) and P2(s∣χ) and suppose Si 〜 Pi and S? 〜 P2, where X is
omitted as the following analysis is conditional on a fixed X=x.
Then we may rewrite the difference of conditional expectations as
Epe2[Y|X=x] —Epei[Y|X=x] = E(g(S2)) — E(g(Si)),
where E[g(Sj))] =	g(s)pj(s|x)ds denotes the expectation over Pj.
Let μι := Epei [g(S)∣X = x] = E[g(S1)] = R g(s)pι(s∣x)ds. Then
Epe2 [YIX = X] — Epei [YX = X]= E(g(S2)) — E(g(Si)) = E [g(S2) — μι].
Further, we have the following transformation
e [g(S2) — μι]
/(g(s) — μι)∏χ(s)pι(s∣x)ds = E [(g(S1) — μ1)∏x(S1)].
(3)
14
Under review as a conference paper at ICLR 2021
In the following, we will use the results of the Stein kernel function. Please refer to Definition 7.2 for
a general definition. Particularly, for the distribution Pi 〜pι(s∣x), the Stein kernel τι(s) is
1s
Ti(S) = E ∕∞(E(Si)- t)pi(t|x)dt，
(4)
where E(Si) = JS ∙ pi(s∣χ)ds. Further, we define (Ti ◦ g)(s) as
1s	1
(Ti ◦ g)(S) = p√7R ∕∞(E(g(Si))-g(t))pi (t|x)dt=P^R
/	(μι - g(t))pι(t∣x)dt. (5)
Under the second condition listed in Theorem 7.1, we may apply the result of Lemma 7.3. Specifically,
by the equation (8), we have
E [(g(Si) - μι)∏x(Sι)] = E [(τι ◦ g)(Si)∏X(Si)].
Then under the first condition in Theorem 7.1, we can obtain the following inequality by Lemma 7.4,
E [(τ1 ◦ g)(S1)πx0 (S1)]= E
(τi ◦g) 0
二 πx
τi
τ1	(S1) ≤ E
IS^(Si)I ∙∣∏χτι(Si)
τ1
(6)
≤ kg0k∞E [| (∏XTi)(Si)|] ≤ kg0k∞k∏Xk∞E[∣Ti(Si)∣].
In the following, We show that the Stein kernel is non-negative, which enables E [∣τi(Si)∣]=
E [τi(Si)]. According to the definition, τi(s) = Pl'⑻ R-∞(E(Si) — t)pi(t∣x)dt, where E(Si) =
f∞∞ t ∙ pi(t∣x)dt. Let Fi(S) = J-∞pi(t∣x)dt be the distribution function for Pi. Note that
s E(Si)pi(t|x)dt = Fi(s)E(Si) =Fi(s)E(Si),
-∞
「tpi(t∣x)dt	=	Fi(s)	[S	tpi(tx-dt	= Fi(S)E(Si∣Si	≤	s)	≤	Fi(S)E(Si),
-∞	-∞ Fi(S)
The last inequality is based on E(S1|S1 ≤ s) - E(S1) ≤ 0 that can be proved as the following
dt - [∞ tpi(t∣x)dt
-∞ Fi(s)	-∞
1	—1 ) pι(t∣x)dt — / tpι(t∣x)dt
Fi (s)	s
≤ s/	(F；S) — l) pι(t∣x)dt — s [	Pi(t∣x) = 0.
Therefore, τι(s) ≥ 0 and hence E[∣τι(Sι)∣] = E [τι(Sι)] in (6).
Besides, by equation (9), the special case of Lemma 7.3, we have
E[τi(Si)] = Var(Si) = Varpe1(S|X = x).
To sum up,
E [(τi ◦ g)(Si)∏X(Si)] ≤ kg0k∞k∏xk∞E [τi(Si)] = kg0k∞IInxk∞ VarpeI (SX = x).
□
Definition 7.2 (the Stein Kernel TP of distribution P). Suppose X 〜P with density p. The Stein
kernel of P is the function x 7→ TP (x) defined by
tp (X)=p(X) ∕∞(E(X)-y)p(y)dy,
(7)
where Id is the identity function for Id(x) = x. More generally, for a function h satisfying
E[|h(X)|] < ∞, define (TP ◦ h)(x) as
(TP ◦ h)(x) = p(X)—(E(h(X))-h(y))p(y)dy.
15
Under review as a conference paper at ICLR 2021
Lemma 7.3. For a differentiable function 夕 such that E[| (τp ◦ h)(x)夕 0(X )|] < ∞, we have
E [(τp ◦ K)(x)φ0(X)] = E[(h(X) - E(h(X))夕(X)].
Proof. Let μh =: E(h(X)). As E(h(X) - μ%) = 0,
(8)
(τP ◦ h)(x) =
(μh - h(y))p(y)dy
--ʒ	(μh - h(y))p(y)dy.
p(x) x
Then
Z0∞
(τp ◦ h)(x)φ0(x)p(x)dx + / (TP ◦ h)(x)φ0(x)p(x)dx
∞0
=	/	(μh - h(y))p(y)φ0(x)dydx -	(μh - h(y))p(y)φ0(χ)dydχ
-∞ -∞	0 x
Z-0∞Zy
Z-0∞Z0
0
(μh - h(y))p(y)^(χ)dχdy -
(h(y) - μh)p(y)φ∖x)dxdy +
Z∞Z
00
Z∞Z
00
y
(μh - h(y))p(y)^(x)dxdy
(h(y) - μh)p(y)φ∖x)dxdy
/ (h(y) - μh)p(y) ( / /(x)dx) dy= / (My)- μQp(y)W(y)-中(Oy)dy
-∞	0	-∞
∞ (h(y) - μh)p(y)(ψ(y))dy=E[(h(X) - E(h(X))中(X)]
-∞
Particularly, taking h(X) = X and 夕(X) = X - E(X), We immediately have
E(τP (X)) = Var(X)	(9)
□
Lemma 7.4. Assume that E(|X |) < ∞ and the density p is locally absolutely continuous on
(-∞, ∞) and h is a Lipschitz continuous function. Then we have |fh| ≤ kh0k∞ for
,ʌ	(TP ◦ h)(χ) _ R-x∞(E(h(x)) - h(y))p(y)dy
fh (X)=	TP (x)	=	R-∞(E(X )-y)p(y)dy
Proof. This is a special case of Corollary 3.15 in Dobler et al. (2015), taking the constant C = 1. 口
7.2	Proof of the Equivalence of Definition 4.2
Proposition 7.5. The binary relation ~p defined in Def. 4.2 is an equivalence relation.
Proof. The equivalence relation should satisfy three properties as folloWs:
•	Reflexive property: The θ ~p θ with Mz, Ms being identity matrix and a§, az being 0.
•	SymmtrlC property: If θ ~p θ, then there exists block permutation matrices Mz and Ms
such that
Ts([fx]s1(x)) = MsTs([fx]-1(x)) + as, Tz([fx]Z1 (X)) = MzTz([f⅛1(x)) + az,
Pfy (y|[fx]-1 (X))= Pfy (y|[fx]-1(x)).
The we have Ms-1 and Mz-1 are also block permutation matrices and such that:
Ts([fXm(X)) = MjTs([fχ]-1(x)) + (-as), Ts([fx]-1(x)) = M-ITs([fχ]-1(x)) + Jaz),
Pfy (ylf⅛1 (X)) =Pfy (y|[fx]-1(X)).
Therefore, we have θ ~p θ.
16
Under review as a conference paper at ICLR 2021
•	Transitive property: if θι 〜P θ? and θ2 〜P θ3 with θi := {fχ,fy, Ts,1, Tz,1, Γs,i, Γz,i},
then we have
Ts,1((fx1,s)-1(x))=Ms1Ts,2((fx2,s)-1(x))+as1,
Tz,1((fx1,z)-1(x)) = Mz1Tz,2((fx2,z)-1(x)) + az2,
Ts,2((fx2,s)-1(x))=Ms2Ts,3((fx3,s)-1(x))+as2,
Tz,2((fx2,z)-1(x)) = Mz2Tz,3((fz3)-1(x)) + a3x,z
for block permutation matrices Ms1, Mz1, Ms2, Mz2 and vectors as1, as2, az1, az2. Then we have
Ts,1((fx1,s)-1(x)) =Ms2Ms1Ts,3((fx3,s)-1(x))+(Ms2as1)+as2,
Tz,1((fx1,z)-1(x)) = Mz2Mz1Tz,3((fx3,z)-1(x)) + (Mz2a1z) + az2.
Besides, it is apparent that
pfy1(y|(fx1)s-1(x)) =pfy2(y|(fx2)s-1(x)) =pfy3(y|(fx3)s-1(x)).	(10)
Therefore, we have θι 〜P θ3 since M2Ms1 and MZMz are also permutation matrices.
With above three properties satisfied, we have that 〜P is a equivalence relation.	□
7.3	Proof of Theorem 4.3
In the following, we write pe(x, y) as p(x, y|de) and also Γtc=s,z := Γt=s,z(de), Sc,i =
Si (de), Zc,i = Zi (de). To prove the theorem 4.3, we first prove the theorem 7.6 for the sim-
plest case when c|de = de, then we generalize to the case when C := ∪rCr. The overall roadmap is
as follows: we first prove the 〜a-identifiability in theorem 7.9, and the combination of which with
lemma 7.12, 7.11 give theorem 7.6 in the simplest case when c|de = de. Then we generalize the case
considered in theorem 7.6 to the more general case when C := ∪rCr.
Theorem 7.6 (〜p-identifiability). For θ in the LaCIMpθ (x,y) ∈ PeXP for any e ∈ Etrain, we assume
that (1) the CIMe satisfies that fx, fx0 and fx00 are continuous and that fx, fy are bijective; (2) that
the Tit,j are twice differentiable for any t = s, z, i ∈ [qt], j ∈ [kt]; (3) the exogenous variables
satisfy that the characteristic functions of εx , εy are almost everywhere nonzero; (4) the number of
environments, i.e., m ≥ max(qs * ks, qz * kz) + 1 and [Γd=2s,z 一 Γd=ιs,z,…,[d=1/ 一 Γd=ιs,z] have
full column rank for both t = s and t = z, we have that the parameters θ := {fx, fy , Ts , Tz} are
〜P identifiable.
To prove theorem 7.6, We first prove the 〜A-identifiability that is defined as follows:
Definition 7.7 (〜A-identifiability). The definition is the same with the one defined in 4.2, with
Ms , Mz being invertible matrices which are not necessarily to be the permutation matrices in
Def. 4.2.
Proposition 7.8. The binary relation 〜A defined in Def. 7.7 is an equivalence relation.
Proof. The proof is similar to that of proposition 7.5.	□
The following theorem states that any LaCIM that belongs to PeXP is 〜A-identifiable.
Theorem 7.9 (〜A-identifiability). For θ in the LaCIM peθ (x, y) ∈ PeXP for any e ∈ Etrain, we
assume (1) the CIMe satisfies that fx, fy are bijective; (2) the Tit,j are twice differentiable for any t =
s, z, i ∈ [qt], j ∈ [kt]; (3) the exogenous variables satisfy that the characteristic functions of εx, εy
are almost everywhere nonzero; (4) the number of environments, i.e., m ≥ max(qs * ks, qz * kz) + 1
and [Γtde2 一 Γtde1 ]T, ..., [Γtdem 一 Γtde1 ]T T have full column rank for t = s, z, we have that the
parameters {fχ,fy, Ts, Tz } are 〜P identifiable.
Proof. Suppose that θ = {fχ, fy, Ts, Tz} and θ = {fχ, gy, Ts, Tz} share the same observational
distribution for each environment e ∈ Etrain, i.e.,
Pfx,fy,τs,rs,τz ,rz(X,yIde) = Pfx,fy ,τ s,r s,τ z ,r Z(X,yIde).	(II)
17
Under review as a conference paper at ICLR 2021
Then we have
Pfχ,fy ,ts,γs,tz ,γz (XIde) = Pffy ,Ts,γs,Tz ,Γz (XIde)
(12)
=⇒ J	PfX (x∖s, z)pts,γs,tz,γz (s,z∖de)dsdz = J	Pf (x∖s, z)pt s Γ s T z Γ z (s,z∖de)dsdz
×	×	(13)
Pεx (x - X)pts,γs,tz,ΓZ (f-1 (X)Ide)Vol Jf-1 (X)dx
=/ pεχ (x - x)pT S Γ S T Z Γ Z (f x (x) ∖ d )volJf-1 (x) dx
X
(14)
(15)
Pts,γs,tz,γz,fx (x∖de)Pεx (x - X)dX = / PTs,γs,t Z,γ Z,fx(XIde)Pεx(x - X)dX	(16)
---⇒ (PTS,Γs,Tz ,Γz ,fx * Pεx )(x∣de) = (PT s,Γ S,T Z ,Γ Zfj * Pεx (χ∖de)
=⇒ F [pt∙
=⇒ f [pr
IS
IS
,Γs,Tz,Γz ,fx ](,ω)ψεx (ω) = F [pTs,Γs,Tz,Γz ,fx ](.ω)ψεχ (ω)
,γs,tz,γz ,fx]3 = F[pTs,Γs,Tz ,Γz ,fx ](ω)
=⇒ pts,γs,tz,γz,fx(XIde) = PTS,Γs,Tz,Γ z,fx(XIde)
(17)
(18)
(19)
(20)
where volJf (X) := det( Jf (X)) for any square matrix X and function f with “J” standing for the
Jacobian. ThePts,γs,tz,γz,fx(x) in Eq. (16) is denoted aspts,γs,tz,「(f-1(x∖de)volJf-ι (x). The
’*’ in Eq. (17) denotes the convolution operator. The F[∙] in Eq. (18) denotes the Fourier transform,
where φεx (ω) = F[Pεx](ω). Since we assume that the φεx (ω) is non-zero almost everywhere, we
can drop it to get Eq. (20). Similarly, we have that:
Pfy ,ts,γs (y∖de) = Pfy ,t s,γ s 3∖d°)
Pfy (y∖s)pτs,rs (s∖de)ds = / Pfy (y∖s)PT S,Γs(s∖de)ds
P%(y - y)pτs,r (f-1(y)∖de)volJf-ι (y)dy
=/ Pεy (y - y)Pτ S Γs (f-1(y)∖de)volJg-ι (y)dy
Y	,
PTS,rs,fy ⑸才加为(y — y)dy = (PT s,γ s,fy (y∖de)Pεy (y — y)dy
=⇒ (PTS,Γs,fy * Pεy )3∖de) = (PTS,ΓS,fy * Pεy )3∖de)
---⇒ F [pTs,Γs,fy ](ω)夕 Ey (ω) = F [pT S,Γ S ,f y ](ω)^≡y (ω)
=⇒ F [pTs,Γs,fy ](ω) = F [PT S,Γs,fy ](M
=⇒ pTs,Γs,fy(y) = pTs,Γs,fy (y)，
and that
(21)
(22)
(23)
(24)
(25)
(26)
(27)
(28)
(29)
pfx,fy Ts,Γs,Tz,Γz (x,y∖de) = Pffy ,T s,Γs,T Z ,Γ Z (x,y∖de)
(30)
I	PfX(X |s, Z)Pfy (y∖s)PTS,ΓS,TZ ,ΓZ (S,z∖de )dsdz
S×Z
= /	Pf(XIs,z)Pf (y∖s)PT S Γs T z Γz(s,z∖de)dsdz
J s×z	y	,,,
Pε(v - V)pts,γs,tz,rz(h-1(v)∖de)volJh-ι(v)dv
=J pε(v - V)PT s Γ s T z Γ z (h I(V)Ide )volJh-1 (V)dv
(31)
(32)
(33)
/	Pts,γs,tz,ΓZ,h,c(v∖d)pε(v - v)dv = /	PTS Γs T Z ΓZ h.(v∖de)pε(v - v)dv (34)
S×Z	s×z ,,,,,
=⇒ (PTS,Γs,Tz ,Γz ,h * Pε)(v) = (PTS,Γs,Tz ,Γz ,h * Pε)(v)
(35)
18
Under review as a conference paper at ICLR 2021
=⇒ F[pτs,rs,τz,rz,h](ω)夕ε(ω) = F[pTs,γS,tZ,γZ,h](ω)夕ε(ω)
=⇒ F[pτs,rs,τz,rz,h](M = F[pTs, γs, Tz, γz,h](M
=⇒ PTS,γs,TN,rz,h(v) = PTS,γs,TN,rz,h(v),
(36)
(37)
(38)
where V := [xτ,yτ]τ, ε :=归>,ε>]>, h(v) = [[fχ]-1(x)>, f-1(y)>]>. According to Eq. (29), we
have
qs	ks
IogvolJfy (y) + E IOgBWy))- ɪɑg 4(疗)+∑ R (f-1(9))「3 (de)
i=1	j=1
logvolJfy (y) +
ks
+ Σ Tj (狐1(y))r3 (de) I
(39)
Suppose that the assumption (4) holds, then we have
eɪʌ	一	一s	一 彳	eι∖
gfH 俨)〉+ X log A^ = (TS(f-1(y)),F (de ))+ X log A^
(40)
e1	e
for all k ∈	[m], where Γ(d)	=	Γ(d)	- Γ(de1).	Denote	bs(k)	=	Pi	<	He) for k ∈	[m],	then
Ai (d k ) Ai (deɪ )
we have
Γs,τTs(f-1(y)) = F,τTs(f-1(y)) + 1,	(41)
Similarly, from Eq. (20) and Eq. (38), there exists bz, b§ such that
Γs,τTs([fχ]-1(x))+ Γz,τTz ([fχ]-1(x)) = Γs,τT s([f]-1(x)) + rz,τTz ([f ]-1(x)) + bz + bs,
(42)
eɪ	e
where bz(k) = Pi Zi k (Zi k)for k ∈[m];and that,
Zi(U k) Zi (	)
---C ^T	-1	--5∙ ^T	-1	— s,τ ~	〜 T	— z,τ 〜	〜 T	〜	〜
Γ , Tf (y)) + Γ , Tz ([f-1 ]z (x)) = Γ	Ts(f-1(y)) + Γ	Tz ([f-1]Z (x)) + bz + b,.
(43)
Substituting Eq. (41) to Eq. (42) and Eq. (43), we have that
Γz,τTz([f-1]Z(y)) = Γz,τTz(f1 ]z(y)) + bz, Γs,τTs([f-1]s(y)) = Γ，''型。/-%(y)) + bs.
(44)
According to assumption (4), the Γs,τ and Γz,τ have full column rank. Therefore, we have that
Tz([f-1]Z(x)) = (ΓzΓz,τ)T Γz,τTZ([f-1]Z(x))+ (FΓz,τ)T bz	(45)
Ts([f-1]s(x)) = (FFT)T rs,τTs([f-1]s(x))+ (ΓsΓs,T)T bs.	(46)
Ts(f-1(y)) = (ΓsΓs,τ)-1 F,τTs(f-1(y))+ (ΓsFT)T bs.	(47)
Denote Mz := (FΓz,τ)-1 Γ[ Ms := (FrS,τ)-1 F" and as = (ΓTs,T)T bs, az =
Z z,τ -1
(Γ Γ b bz. The left is to prove that MZ and MS are invertible matrices. Denote x = f-1(χ).
Applying the (Khemakhem, Kingma and Hyvarinen, 2020, Lemma 3) we have that there exists k§
points x1,...,xks, X1, ...,xkz such that ((TS)">氐(x1)),..., (Ts)i([f-1]5i (xks))) for each i ∈
[qs] and ((TZ)i([f-1]Zi(XI)),..., (TZ)i([fT1]Si(XkZ))) for each i ∈ ㈤ are IinearIy independent.
19
Under review as a conference paper at ICLR 2021
By differentiating Eq.(45) and Eq.(46) for each Xi with i ∈ [q§] and Xi with i ∈ [qz] respectively,
we have that
(JTs (XI),..∙, JTs (Xks )) = Ms (JTsof-1ofx (XI)，…，JTsof-Iof (Xks D	(48)
(JTz(XI),…,JTz(Xkz )) = Mz (JTz of-1。/. (XI),…,JTz of-1ofx (X Z) ” .	(49)
The linearly independence of ((Ts)0i([fx-1]Si(Xi1)), ..., (Ts)0i([fx-1]Si(Xiks))	and
((TZ)i([f-1]Zi(XI)),…,(TZ)i([f-1]Si(Xkz))) imply that the (JTs(XI),…,JTs (Xks)) and
(JTz(X1),…，JTz (Xkz)) are invertible, which implies the invertibility of matrix Ms and MZ. The
rest is to prove Pfy (y∣[fχ]-1(X)) = Pfy (y∣[fx]-1(X)). ThiS Can be shown by applying Eq. (31) again.
Specifically, according to Eq. (31), we have that
I Pε. (x - X)P(y|[fx]-1(X))PTs ,Γs,Tz ,Γz(f-1 (X)Ide)VOlJf-1 (X)dX
X
=P Pεχ(x — X)p(y∣[fX]-1(x))PTs,rs,Tz,rz(f-1(x)∣de)volJf-ι(X)dx.	(50)
X
DenOte lTs,Γs,Tz ,Γz ,fy ,fχ,y (x) := Pfy (y|[fx]-1(X))PTs,Γs,Tz ,Γz (f-1 (X)Ide)VOlJf-1 (x), we have
p	Pεχ(x -	x)lTs,Γs,Tz,Γz ,fy ,fχ,y (X)dX = /	Pε. (x -	X)IT s	Γs	T z	Γz	fy	fx y (x)dX	(51)
XX
=⇒(ITs ,Γs,Tz ,Γz,fy,fχ,y * Pεχ )(XIde) = (lT s,Γs ,T z ,Γz ,fy ,fx,y * PεX)(XIde)
=⇒F [lT s,Γs,T z ,Γz ,fy ,fx,y ](ω)^εκ (ω) = F [lTs,Γs,Tz ,Γz,fy,fx,y ](ω)^εκ (ω)
=⇒F [lTs,Γs,Tz ,Γz ,fy ,fχ,y ](ω) = F [lT s ,Γs,T z ,Γz,fy,fχ,y ](ω)
=⇒lTs,Γs,Tz ,Γz ,fy ,fχ,y (x) = lT s,Γs,T z ,Γz ,fy,fx,y (X)
=⇒Pfy (yI[fx]S-1(X))PTs,Γs,Tz,Γz(f-1(X)Ide)vOlJfx-1 (X)
=Pfy(y| [fx]s (X))PTs,Γs,Tz,rz(f (X)Id )vol Jf-I (X).
Taking the lOg transformation on both sides of Eq. (56), we have that
lOgPfy(yI[fx]S-1(X)) + lOgPTs,Γs,Tz,Γz(f-1(X)Ide) + lOg vOlJfx-1 (X)
=log Pfy(yI[fχ ]-1(x)) + log PT s,rs,T z,rz (f-1(X)Ide) +logvolJf—1 (x).
Subtracting Eq. (57) with y2 from Eq. (57) with y1, we have
Pfy (y2 I[fχ]-1(χ)) = Pfy (y2I[fX]-1(X))
Pfy (y1I[fx]-1(X))	Pfy(y1I[fχ]-1(χ))
=⇒ f Pfy — (X)) d = f Pfy 侬 I[fX]-1 (X)) d
JYPfy(y1I[fχ]-1 (χ)) y2 - JYPfy(y1I[fχ]-1(χ)) y2
=⇒Pfy (y1I[fx]-1(X)) = Pfy (y1I[fx]-1(X)),
for any y1 ∈ Y . This completes the proof.
(52)
(53)
(54)
(55)
(56)
(57)
(58)
(59)
(60)
□
Understanding the assumption (4) in Theorem 7.9 and 7.6. Recall that we assume the con-
founder ds in LaCIM is the source variable for generating data in corresponding domain. Here we
also use the C to denote the space of ds (since ds := c), then we have the following theoretical
conclusion that the as long as the image set of C is not included in any sets with Lebesgue measure 0,
the assumption (4) holds. This conclusion means that the assumption (4) holds generically.
Theorem 7.10. Denote ht=s,Z (d) := (Γt1,1(d) - Γt1,1(de1 ), ..., Γtq ,k (d) - Γt1,1(de1 )) , h(C) :=
hs(S)㊉ hζ (Z) ⊂ Rqz *kz ㊉ Rqs*ks ,then assumption (4) holds if h(C) is not included in any
zero-measure set of Rqz*kz ㊉ Rqs*ks. Denote rs := qs * ks and r2 := qζ * kz∙
20
Under review as a conference paper at ICLR 2021
Proof. With loss of generality, we assume that rs ≤ rz . Denote Q as the set of integers
q such that there exists de2 , ..., dq+1 that the rank([hz (de2), ..., hz (deq+1 )]) = min(q, rz) and
rank([hs(de2), ..., hs(deq+1)]) = min(q, rs). Denote u := max(Q). We discuss two possible
cases for u, respectively:
•	Case 1. u < rs ≤ rz. Then there exists de2 , ..., deu+1 s.t. hz (de2), ..., hz (deu+1)
and hs(de2), ..., hs (deu+1) are linearly independent. Then ∀c, we have hz (d) ∈
L(hz (de2), ..., hz (deu+1)) or hs(d) ∈ L(hs (de2), ..., hs (deu+1)). Therefore, so we have
hz (d)㊉ hs(d) ∈ [L(hz (de2 ),...,hz (deu+1))㊉ Rrs ] ∪ [Rrz ㊉ L(hs(de2 ),...,hs(deu+1))],
which has measure 0 in Rrz ㊉ Rrs.
•	Case 2. rs ≤ u < rz. Then there exists de2, ..., deu+1 s.t. hz (de2), ..., hz (deu+1 ) are
linearly independent and rank([hs(de1 ), ..., hs(deu )]) = rs. Then ∀c, we have hz (d) ∈
L(hz(de1),…,hz(deu+1)), which means that hz(d)㊉ hs(d) ∈ L(hz(de1),..., hz(deu+1))㊉
Rrs, which has measure 0 in Rrz ㊉ Rrs.
The above two cases are contradict to the assumption that h(C) is not included in any zero-measure
setof Rrz ㊉ Rrs.	□
Lemma 7.11. Consider the cases when ks ≥ 2. Then suppose the assumptions in theorem 7.9 are
satisfied. Further assumed that
•	The sufficient statistics Tis,j are twice differentiable for each i ∈ [qs] andj ∈ [ks].
•	fy is twice differentiable.
Then we have Ms in theorem 7.9 is block permutation matrix.
Proof. Directly applying (Khemakhem, Kingma and Hyvarinen, 2020, Theorem 2) with fχ, A, b, T, X
replaced by fy,Ms,as, Ts,y.	□
Lemma 7.12. Consider the cases when ks = 1. Then suppose the assumptions in theorem 7.9 are
satisfied. Further assumed that
•	The sufficient statistics Tis are not monotonic for i ∈ [qs].
•	g is smooth.
Then we have Ms in theorem 7.9 is block permutation matrix.
Proof. Directly applying (Khemakhem, Kingma and Hyvarinen, 2020, Theorem 3) with fχ, A, b, T, X
replaced by fy,Ms,as, Ts,y.	□
Proof of Theorem 7.6. According to theorem 7.9, there exist invertible matrices Ms and Mz such
that
T(f-1(x)) = AT(f-1(x)) + b
Ts([f-1]s (x)) = MST s([f-1]s (x)) + as
Ts(f-1 (y)) = MST s(f-1(y)) + as,
where T = [Ts,>, Tz,>]>, and
Ms	0
0	Mz	.
(61)
By further assuming that the sufficient statistics Tis,j are twice differentiable for each i ∈ [qs] and
j ∈ [ks] for ks ≥ 2 and not monotonic for ks = 1. Then we have that Ms is block permutation
matrix. By further assuming that Tiz,j are twice differentiable for each i ∈ [nz] and j ∈ [kz] for
kz ≥ 2 and not monotonic for kz = 1 and applying the lemma 7.11 and 7.12 respectively, we have
that A is block permutation matrix. Therefore, Mz is also a block permutation matrix.	□
21
Under review as a conference paper at ICLR 2021
Proof of Theorem 4.3. We consider the general case when C := ∪rR=1Cr, in which each Cr can be
simplified as a representative point Cr. For environment de, let Pde = [P(C = ci ∣de),…,P(C =
cR|de)] be the vector of probability mass of C in the environment de. And Etrain has m environments
with indexes de1, ∙∙∙ , dem. The latent factors (S, Z) belongs to the exponential family distribution
p(s,z∖c) = PTz,rz(d)(z)pτs,rs(d)(s)∙ Suppose that θ = {fχ,fy, Ts, Tz} and θ = {fx, gy, Ts, Tz}
share the same observational distribution for each environment, i.e., pθ(x, y∖de) = p^(x, y∖de), then
we have that
RR
X Pθ (x,y∣Cr )P(C = Cr∖de) = X Pθ(x,y∖cr )P(C =CR∣de).	(62)
r=1	r=1
Let ∆χ,y = [Pθ(x,y∖cι) — Po(x,y∖cι),…，Pθ(x,y∖cm) — P§(x, y∖cm)]T, then Eq. (62) can be written
as A∆x,y = 0. Denote A := Pd>e1 ∈ Rm×R. According the diversity condition, we have that A
and the [[Γt(c2)-Γt(cι)]T,…，[Γt(cm)-Γt(cι)]T]t have full column rank, therefore we have that
∆χ,y = 0, i.e. pθ(x, y∖cr) = p^(x, y∖cr) for each r ∈ [R]. The left proof is the same with the one in
theorem 7.6.	□
7.4 Proof of Theorem 4.4
Proof of Theorem 4.4. Due to Eq. (62), it is suffices to prove the conclusion for every cr ∈ {cr}r∈[R].
Motivated by Barron and Sheu (1991, Theorem 2) that the distribution pe (s, z) defined on bounded
set can be approximated by a sequence of exponential family with sufficient statistics denoted
as polynomial terms, therefore the Tt=s,z are twice differentiable hence satisfies the assumption
(2) in theorem 4.3 and assumption (1) in lemma 7.11. Besides, the lemma 4 in Barron and Sheu
(1991) informs us that the KL divergence between pθ0 (s, z∖cr) (θ0 := (fx, fy, Tz, Ts, Γz0, Γs0)
andpθ1(s, z∖cr) (θ1 := (fx, fy,Tz, Ts, Γz1, Γs1) (thepθ0(s, z∖cr),pθ1(s, z∖cr) belong to exponential
family with polynomial sufficient statistics terms) can be bounded by the `2 norm of [(Γs (cr ) —
Γs1(cr))>, (Γz0(cr) — Γz1 (cr))>]>. Therefore, ∀ > 0, there exists a open set of Γ(cr) such that
the DKL(p(s, z∖cr),pθ(s, z∖cr)) < . Such an open set is with non-zero Lebesgue measurement
therefore can satisfy the assumption (4) in theorem 4.3, according to result in theorem 7.10. The left is
to prove that for anyp defined by a LaCIM following Def. 4.1, there is a sequence of {pm}n ∈ Pexp
such that the dPok (p, pn) → 0 that is equivalent to pn →d p. For any A, B, we consider to prove that
In =∆ p(x ∈ A,y ∈ B∖cr) —pn(x ∈ A, yn ∈ B∖cr) → 0,	(63)
where pn (x ∈ A, yn ∈ B∖cr) = S Zp(x ∈ A∖s, z)p(yn ∈ B∖s)pn(s, z∖cr)dsdz with
(i)	= eχp((fy,i(s)+ "/Tn	i = 1 k
yn()= Pi exp((fy,i(s)+ εy,i)∕Tn) )	=…k
(64)
for y ∈ Rk denoting the k-dimensional one-hot vector for categorical variable and εy,1,...,k are
Gumbel i.i.d. According to (Maddison et al., 2016, Proposition 1) that the yn(i) →d y(i) with
eχp(fy,i (s))
p(y(i) = ]) =	777 ,^^ʌv, as Tn → 0.
i eχp((fy,i(s))
As long as fy is smooth, we have that the p(yn∖s) is continuous. We have that
In= p(x ∈ A, y ∈ B∖cr) — p(x ∈ A∖s, z)p(yn∈ B∖s)pn(s, z∖cr)dsdz
≤ p(x ∈ A, y ∈ B∖cr) —p(x ∈ A, yn∈ B∖cr)
+ IP(X ∈ A,yn ∈ B" Zs× JX ∈ As,z)p(yn ∈ BIs)Pn(S,z|Cr)dsdz
(65)
p(x ∈ A∖s, z) (p(y ∈ B∖s) — p(yn ∈ B∖s))p(s, z∖cr)dsdz
S×Z
p(x ∈ A∖s, z)p(yn∈ B∖s) (p(s, z∖cr) —pn(s, z∖cr))
S×Z
22
Under review as a conference paper at ICLR 2021
P(X ∈ A∣s,z)(p(y ∈ B∣s) - p(yn ∈ B∣s))p(s,z∣Cr)dsdzI
Ms×Mz	1
X----------------------------------------------------------/
{z^
In, 1
P(X ∈ A∣s, z) (p(y ∈ B∣s) - p(yn ∈ B∣s))p(s, z∣cr)dsdzI
(Ms×Mz )cr	1
X-----------------------------------------------------------------/
^{^≡
In, 2
p(x ∈ A∣s, z)p(yn ∈ BIS)(P(S,Z∣Cr) - Pn(S, Z∣Cr )) I
Ms×Mz	1
X-------------------------------------------------------/
^{^≡
In, 3
I /	P(X ∈ A|s, z)p(yn ∈ B∣s)(p(s, Z∣Cr ) - pn(s,z∖βr)) I .
(Ms×Mz )cr	1
X------------------------------------------------------------/
(66)
{z^
In,4
For In,ι, if y is itself additive model with y = fy (S) + εy, then we just set yn = y, then we have
that In,ι = 0. Therefore, we only consider the case when y denotes the categorical variable with
softmax distribution, i.e., Eq. (65). NCr ∈ C := {c1,..., cr} and ∀e > 0, there exists Mc and Mzr
such that p(s, z ∈ Mz × McrICr) ≤ e; Denote MS δ IJm=IMcr and Mz = IJm=IMy, we have
that p(s, Z ∈ MS × Mz ∣c) ≤ 2e for all Cr ∈ C. Since ∀s1 ∈ Ms, ∃Nι such that ∀n ≥ Ni, we have
that I p(y ∈ B∣s1) - p(y ∈ B∣s1)∣ ≤ e from that yn → y. Besides, there exists open set Oi such
that ∀s ∈ Osi and
Ip(y ∈ B∣s1) -p(y ∈ B∣s1)∣ ≤ e, ^pyn, ∈ B∣s1) -p(yn ∈ B∣s1)∣ ≤ e.
Again, according to Heine-Borel theorem, there exists finite s, namely s1,..., Sl such that MS U
∪i=ιO(si). Then there exists N = max{Nι ,…，NSJ such that ∀n ≥ N, we have that
Ip(y ∈ B∣s) - p(yn ∈ B∣s) i ≤ 3e, ∀s ∈ Ms.	(67)
Therefore, InJ ≤ JM ×m 3ep(x ∈ A∣s, z)p(s, z∣c)dsdz ≤ 3e. Hence, InJ → 0 as n → ∞.
Besides, we have that In,2 ≤ JM ×m 2ep(s, z∣Cr )dsdz ≤ 2e. Therefore, we have that I J5×3-P(X ∈
A∣s, z)(p(y ∈ B∣s) — p(yn ∈ B∣s))p(s, z∣Cr)dsdzI → 0 as n → ∞. For In,3, we have that
In,3 = i /	p(x ∈ A∣s,z)p(yn ∈ BIS)I(s, Z ∈ MS × MZ) (p(s,Z∣Cr) - Pn(S, Z∣Cr )) dsdz
Ms ×Mz
i JM ×M P(X ∈ 川与勿汉枢 ∈ BIS)P(S,z∣cr) (P(S,z ∈ MS × MZ ∣Cr) -
X------------------------------------------V-----------------------------------------
In,3,1
/
+
Jms×M 认X ∈ A∣s,z)p(yn ∈ BIS)P(S,z∣cr) (p(s,z ∈ MS × Mz∣Cr) - DdSdZ .
X
^z∖∣f^~
In,3,2
/
(68)
The In,3,1 ≤ 士. Denote p(s, z∣Cr) := P(S嫌;Z∈M,×∈Ms∣;MZ), according to ( Barron and Sheu,
c	p1 s,Z ∈ j VlS × N cr J
1991, Theorem 2), there exists a sequence of Pn(s, z∣c) defined on a compact support MS × MZ such
that ∀Cr ∈ C , we have that
Pn(s,Z∣Cr ) → p(s, Z∣Cr ).
Applying again the Heine-Borel theorem, we have that ∀e, ∃N such that ∀n ≥ N, we have
Ip(s,Z∣Cr ) - Pn(S, Z∣Cr ) ] ≤ e,
(69)
23
Under review as a conference paper at ICLR 2021
which implies that In,3,2 → 0 as n → ∞ combining with the fact that p(x, y|s, z) is continuous with
respect to s, z. For In,4, we have that
z
p(x ∈ A|s, z)p(yn ∈ B|s)p(s, z|cr) ≤
/
Ms ×Mz
p(s, z|cr) ≤ ,	(70)
where the first equality is from that the pn(s, z|cr) is defined on Ms × Mz. Then we have that
p(x ∈ A|s, z)p(yn ∈ B|s) (p(s, z|cr) - pn(s, z|c)) → 0, as n → ∞.
The proof is completed.
(71)
□
7.5 REPARAMETERIZATION FOR LACIM-d
We provide an alternative training method to avoid parameterization of prior p(s, z|de) to increase
the diversity of generative models in different environments. Specifically, motivated by Hyvarinen
and Pajunen (1999) that any distribution can be transformed to isotropic Gaussian with the density
denoted by pGau , we have that for any e ∈ Etrain , we have
pe (x, y) =	pfx (x|s, z)pfy (y|s)p(s, z|de)dsdz
S×Z
=ZS Zp(XI(Pe)T (SO), (Pz 厂I(ZO))P(y|Ps(SO))PGaU(S0, ZO)ds'dz',
with s0, z0 := ρz(s), Pz(z)〜N(0, I). We can then rewrite ELBO for LaCIM-d for environment e
as:
Lφ,ψ,ρe = Epe(x,y) - log qψ (y|x)
工 W I" W	qψ ⑶(Pe)T(S)) ]c o∙PΦ((Pe )-1(S), (Pz )-1(Z))PGaU(S,z)
+ Epe(χ,y) [-EqΨ(s,zlχ)	qψ(y∣χ)	log	qψMX)	J.
(72)
7.6	Identifiability
Earlier works that identify the latent confounders rely on strong assumptions regarding the causal
structure, such as the linear model from latent to observed variable or ICA in which the latent
component are independent Silva et al. (2006), or noise-free model Shimizu et al. (2009); Davies
(2004). The Hoyer et al. (2008); Janzing, Peters, Mooij and Scholkopf (2012) extend to the additive
noise model (ANM) and other causal discovery assumptions. Although the Lee et al. (2019) relaxed
the constraints put on the causal structure, it required the latent noise is with small strength, which
does not match with many realistic scenarios, such as the structural MRI of Alzheimer’s Disease
considered in our experiment. The works which also based on the independent component analysis
(ICA), i.e., the latent variables are (conditionally) independent, include Davies (2004); Eriksson
and Koivunen (2003); recently, a series of works extend the above results to deep nonlinear ICA
(Hyvarinen and Morioka, 2016; Hyvarinen et al., 2019; Khemakhem, Kingma and Hyvarinen, 2020;
Khemakhem, Monti, Kingma and Hyvarinen, 2020; Teshima et al., 2020). However, these works
require that the value of confounder of these latent variables is fixed, which cannot explain the spurious
correlation in a single dataset. In contrast, our result can incorporate these scenarios by assuming
that each sample has a specific value of the confounder. Other works assume discrete distribution
for latent variables, such as Janzing, Sgouritsa, Stegle, Peters and Scholkopf (2012); Kocaoglu et al.
(2018); Sgouritsa et al. (2013). However, in the literature, no existing works can disentangle the
prediction-causative features from others, in the scenario of avoiding spurious correlation in order for
OOD generalization.
7.7	Comparison with existing works
7.7.1	Y →SORS→Y?
Many existing works Rojas-Carulla et al. (2018); Khemakhem, Monti, Kingma and Hyvarinen (2020);
Ilse et al. (2020; 2019) assumed Y → S(X) as the causal direction. Such an difference from ours
24
Under review as a conference paper at ICLR 2021
can mainly be contributed to the generating process of Y . Different understanding leads to different
causal graph. The example of digital hand-writing in Peters et al. (2017) provides a good explanation.
Consider the case that the writer is provided with a label first (such as ”2”) before writing the digit
(denoted as X), then it should be Y → X . Consider another case, when the writing is based on the
incentive (denoted as S) of which digit to write, then the writer record the label Y and the digit X
concurrently, in which case it should be X — S → Y. For Y → S, the Y is thought to be the source
variable that generates the latent components and is observed before X. In contrast, we define Y as
ground-truth labels given by humans. Taking image classification as an example, it is the human
that give the classification of all things such as animals. In this case, it can be assumed that the label
given by humans are ground-truth labels. This assumption can be based by the work Biederman
(1987) in the field of psychology that humans can factorize the image X by many components due
to the powerful perception learning ability of human beings. These components which denoted as
S, can be accurately detected by humans, therefore we can approximately assume that it is the S
generating the label Y. Consider the task of early prediction in Alzheimer’s Disease, the disease label
is given based on the pathological analysis and observed after the MRI X . Such a labelling outcome
can be regarded as the ground-truth which itself is defined by medical science. The corresponding
pathology features, as the evidences for labelling, can also thought as the generators of X . In these
cases, it is more appropriate to assume the Y as the outcome than the cause. For example, the Peters
et al. (2016); Kuang et al. (2018) assumed XS → Y. As an adaptation to sensory-level data such as
image, we assume S → Y with S are latent variables to model high-level explanatory factors, which
coincides with existing literature Teshima et al. (2020). Another difference lies in the definition of Y.
The Invariant Risk Minimization (we will give a detailed comparison later) Arjovsky et al. (2019)
assumes that X → S → Y by defining the Y as the label with noise. The S denoted as the extracted
hidden components by observer.
7.7.2	Comparisons with data augmentation & architecture design
The goal of data augmentation Shorten and Khoshgoftaar (2019) is increase the variety of the data
distribution, such as geometrical transformation Kang et al. (2017); Taylor and Nitschke (2017),
flipping, style transfer Gatys et al. (2015), adversarial robustness Madry et al. (2017). On the other
way round, an alternative kind of approaches is to integrate into the model corresponding modules
that improve the robustness to some types of variations, such as Worrall et al. (2017); Marcos et al.
(2016).
However, these techniques can only make effect because they are included in the training data for
neural network to memorize Zhang et al. (2016); besides, the improvement is only limited to some
specific types of variation considered. As analyzed in Xie et al. (2020); Krueger et al. (2020), the data
augmentation trained with empirical risk minimization or robust optimization Ben-Tal et al. (2009)
such as adversarial training Madry et al. (2017); Sagawa et al. (2019) can only achieve robustness on
interpolation (convex hull) rather than extrapolation of training environments.
7.7.3	Comparisons with existing works in domain adaptation
Apparently, the main difference lies in the problem setting that (i) the domain adaptation (DA) can
access the input data of the target domain while ours cannot; and (ii) our methods need multiple
training data while the DA only needs one source domain. For methodology, our LaCIM shares
insights but different with DA. Specifically, both methods assume some types of invariance that relates
the training domains to the target domain. For DA, one stream is to assume the same conditional
distribution shared between the source and the target domain, such as covariate shift Huang et al.
(2007); Ben-David et al. (2007); Johansson et al. (2019); Sugiyama et al. (2008) in which P (Y|X)
are assumed to be the same across domains, concept shift Zhang et al. (2013) in which the P(X|Y)
is assumed to be invariant. Such an invariance is related to representation, such as Φ(X) in Zhao
et al. (2019) and P(Y∣Φ(X)) in Pan et al. (2010); Ganin et al. (2016); Magliacane et al. (2018).
However, these assumptions are only distribution-level rather than the underlying causation which
takes the data-generating process into account. Taking the image classification again as an example,
our method first propose a causal graph in which the latent factors are introduced as the explana-
tory/causal factors of the observed variables. These are supported by the framework of generative
model Khemakhem, Kingma and Hyvarinen (2020); Khemakhem, Monti, Kingma and Hyvarinen
(2020); Kingma and Welling (2014); Suter et al. (2019) which has natural connection with the causal
25
Under review as a conference paper at ICLR 2021
graph Scholkopf (2019) that the edge in the causal graph reflects both the causal effect and also the
generating process. Until now, perhaps the most similar work to us are Romeijn and Williamson
(2018) and Teshima et al. (2020) which also need multiple training domains and get access to a few
samples in the target domain. Both work assumes the similar causal graph with us but unlike our
LaCIM, they do not separate the latent factors which can not explain the spurious correlation learned
by supervised learning Ilse et al. (2020). Besides, the multiple training datasets in Romeijn and
Williamson (2018) refer to intervened data which may hard to obtain in some applications. We have
verified in our experiments that explicitly disentangle the latent variables into two parts can result in
better OOD prediction power than mixing them together.
7.7.4	Comparisons with domain generalization
For domain generalization (DG), similar to the invariance assumption in DA, a series of work
proposed to align the representation Φ(X) that assumed to be invariant across domains Li et al.
(2017; 2018); Muandet et al. (2013). As discussed above, these methods lack the deep delving of the
underlying causal structure and precludes the variations of unseen domains.
Recently, a series of works leverage causal invariance to enable OOD generalization on unseen
domains, such as Ilse et al. (2019) which learns the representation that is domain-invariant. Notably,
the Invariant Causal Prediction Peters et al. (2016) formulates the assumption in the definition of
Structural Causal Model and assumes that Y = XS βS? + εY where εY satisfies Gaussian distribution
and S denotes the subset of covariates of X. The Rojas-Carulla et al. (2018); Buhlmann (2018) relaxes
such an assumption by assuming the invariance of fy and noise distribution εy in Y J fy (XS, εy)
which induces P(Y|XS). The similar assumption is also adopted in Kuang et al. (2018). However,
these works causally related the output to the observed input, which may not hold in many real
applications in which the observed data is sensory-level, such as audio waves and pixels. It has
been discussed in Bengio et al. (2013); Bengio (2017) that the causal factors should be high-level
abstractions/concepts. The Heinze-Deml and Meinshausen (2017) considers the style transfer setting
in which each image is linear combination of shape-related variable and contextual-related variable,
which respectively correspond to S and Z in our LaCIM in which the nonlinear mechanism (rather
than linear combination in Heinze-Deml and Meinshausen (2017)) is allowed. Besides, during
testing, our method can generalize to the OOD sample with intervention such as adversarial noise
and contextual intervention.
Recently, the most notable work is Invariant Risk Minimization Arjovsky et al. (2019), which will be
discussed in detail in the subsequent section.
7.7.5	Comparisons with Invariant Risk Minimization Arjovsky et al. (2019) and
REFERENCES THERE IN
The Invariant Risk Minimization (IRM) Arjovsky et al. (2019) assumes the existence of invariant
representation Φ(X) that induces the optimal classifier for all domains, i.e., the E[Y |P a(Y)] is
domain-independent in the formulation of SCM. Similar to our LaCIM, the Pa(Y) can refer to latent
variables. Besides, to identify the invariance and the optimal classifier, the training environments also
need to be diverse enough. As aforementioned, this assumption is almost necessary to differentiate
the invariance mechanism from the variant ones. To learn such an invariance, a regularization function
is proposed.
The difference of our LaCIM with IRM lies in two aspects: the direction of causal relation and the
methodology. For the direction, as aforementioned in section 7.7.1, the IRM assumes X → S rather
than the S, Z → X in our LaCIM. This is because the IRM defines Y as label with noise while
ours definie the Y as the ground-truth label hence should be generated by the ground-truth hidden
components that generating S. Such an inconsistency can be reflected by experiment regarding to
the CMNIST in which the number is the causal factors of the label Y, rather than only invariant
correlation. Besides, in terms of methodology, the theoretical claim of IRM only holds in linear case;
in contrast, the CIMe fx , fy are allowed to be nonlinear.
Some other works share the similar spirit with or based on IRM. The Risk-Extrapolation (REx)
Krueger et al. (2020) proposed to enforce the similar behavior of m classifiers with variance of
which proposed as the regularization function. The work in Xie et al. (2020) proposed a Quasi-
distribution framework that can incorporate empirical risk minimization, robust optimization and
26
Under review as a conference paper at ICLR 2021
REx. It can be concluded that the robust optimization only generalizes the convex hull of training
environments (defined as interpolation) and the REx can generalize extrapolated combinations of
training environments. This work lacks model of underlying causal structure, although it performs
similarly to IRM experimentally. Besides, the Teney et al. (2020) proposed to unpool the training
data into several domains with different environment and leverages Arjovsky et al. (2019) to learn
invariant information for classifier. Recently, the Bellot and van der Schaar (2020) also assumes the
invariance to be generating mechanisms and can generalize the capability of IRM when unobserved
confounder exist. However, this work also lacks the analysis of identifiability result.
We finish this section with the following summary of methods in section 7.7.4 and the IRM, in terms
of causal factor, invariance type, direction of causal relation, theoretical judgement and the ability to
generalize to intervened data.
Table 4: Our LaCIM with related works.
	Causal Factor	Direction	Invariance Type	Theoretical Judgement	Intervention
PeterSetal.( )16) 一	Subset of covariates X	XS → Y	Linear model with Gaussian noise	Identifiability	Yes
ROjaS-CarUuaetal ( .018)	Subset of covariates X	XS → Y	Linear Model	-	-
Kuang et al. ( 018)	Subset of covariates X	XS → Y	Nonlinear	Confounder Balancing	-
BUhIma (	)	Subset of covariates X	XS → Y	Nonlinear	Identifiability	-
:a (201 )	Latent variables S	X → S → Y	Linear	Identifiability	-
LaCIM (Ours)	一	Latent variables S, Z	S,Z → X, S → Y ∙	Nonlinear	Identifiability	Yes
7.8	Implementation Details and More Results for Simulation
Data Generation We set m = 5, ne = 1000 for each e. The generating process of ds ∈ Rqds ,
Z ∈ Rqz, S ∈ Rqs, X ∈ Rqx and Y ∈ Rqy is introduced in the supplement 7.8. We set qds = qs =
qz = qy = 2 and qx = 4. For each environment e ∈ [m] with m = 5, we generate 1000 samples
De = {xi,yi} i" RPfχ(x∣s,z)pfy(y∣s)pe(s,z∣de)dsdz. The d = (N(0,Iqds ×qds) +5 * e) * 2；
the s,z∖ds 〜N [μΦ?,Z (S,z|dS),σφ?,Z(S,z|dS)) with μφ?,Z = Aμ,z * de and logσΦ?,Z = Aσ,z * de
(Aμ,z, Aeσ,z are random matrices); the x∖s,z 〜N (μφχ (x∖s,z),σφ? (x∖s,z)) with μφ? Z = h(Aμ,3 *
h(Aμ,2 * h(Aμ,2 * [s>,z>]>]))) and logσφ? Z = h(Aχ,3 * h(Aχ,2 * h(A4,2 * [s>,z>]>]))) (h is
LeakyReLU activation function with slope = 0.5 and Aμ,i=1,2,3,Aσ,i=1,2,3 are random matrices); the
y∖s is similarly to x∖s, Z with Aμ,i=1,2,3,Aσ,i=1,2,3 respectively replaced by Aμ,i=1,2,3,Aσ,i=1,2,3.
Implementation Details We parameterize pθ(S, z∖d), qφ(S, z∖x, y, d), pθ(x∖S, z) and pθ(y∖S) as 3-
layer MLP with the LeakyReLU activation function. The Adam with learning rate 5 × 10-4 is
implemented for optimization. We set the batch size as 512 and run for 2,000 iterations in each trial.
Visualization. As shown from the visualization of S is shown in Fig. 7.8, our LaCIM can identify
the causal factor S.
(b) pLaCIM(S∖x, y, de)
(c) pLaCIM(S∖x, y, de)
(a) ppool-LaCIM(S∖x, y)
(d) pφ? (S∖de)
Figure 4: Visualization of S. From left to right are: estimated posterior by pool-LaCIM:
ppool-LaCIM (S∖x, y), by LaCIM with c as input: pLaCIM(S∖x, y, de), by LaCIM with D as input:
pLaCIM(S∖x, y,d); the ground-truth pφ? (S∖de).
The setting when C can take a value in a sample-level. We consider the generation process of De
as De = {xi,yi} \'N ∕pfx(x∖s,z)pfy(y∖s)p(s,z∖c)p(c∖de)dsdzdc, with q。：= 2. The generation
is the same except that the after obtaining de, we additionally generate c with c := N(de , I). The
results are summarized in Tab. 7.8.
27
Under review as a conference paper at ICLR 2021
Table 5: MCC of identified latent variables forpe(x, y) = p(x|s, z)p(y|s)p(s, z|c)p(c|de)dcdsdz.
Average over 20 times for each data.
	Data #1	Data #2	Data#3	Data #4	Data #5	Average
	Z S	Z S	Z S	Z S	Z S	Z	S
	 pool-LaCIM	0.26 0.61	0.26 0.67	0.44 0.70	0.51 0.78	0.58 0.77	0.41	0.71
LaCIM-ds (Ours, m = 3)	0.70 0.79	0.72 0.79	0.69 0.74	0.74 0.85	0.64 0.88	0.70	0.81
LaCIM-ds (Ours, m = 5)	0.73 0.85	0.70 0.89	0.85 0.91	0.81 0.84	0.83 0.93	0.78 ↑ 0.89 ↑
LaCIM-ds (Ours, m = 7)	0.92 0.90	0.83 0.90	0.84 0.93	0.85 0.94	0.83 0.90	0.86 ↑ 0.91 ↑
7.9 IMPLEMENTATION DETAILS FOR OPTIMIZATION OVER S, Z
Recall that We first optimize s*,z* according to
s*,z* = arg max logpφ(x∣s, z).
s,z
We first sample some initial points from each posterior distribution qψe (s|x) and then optimize for 50
iterations. We using Adam as optimizer, With learning rate as 0.002 and Weight decay 0.0002. The
Fig. 7.9 shoWs the optimization effect of one run in CMNIST. As shoWn, the test accuracy keeps
groWing as iterates. For time saving, We chose to optimize for 50 iterations.
Figure 5: The optimization effect in CMNIST, starting from the point With initial sampling from
inference model q of each branch. As shoWn, the test accuracy increases as iterates.
7.10	Implementations For Baseline
For the CE X → Y and the CE X, ds → Y , they both composed of tWo parts: (i) feature extractor,
folloWed by (ii) classifier. The netWork structure of the feature extractor for CE X → Y is the same
With that of our encoder; While the extracted features for CE X, d → Y is the concatenation of the
features encoded from X → S, Z via the netWork With the same netWork structure of our encoder;
and the netWork With the same structure of our prior netWork for LaCIM-d. The netWork structures of
the classifier for both methods are the same to that of our Pφ(y∣s). The IRM and SDA adopt the same
structure as CE X → Y . DANN adopt the same structure of CE X → Y and a additional domain
classifier which is the same as that of pφ(y∣s). SVAE adopt the same structure as LaCIM-⅛ with the
exception that the pφ(y∣s) is replaced by pφ(y∣z, s). MMD-AAE adopt the same structure of encoder,
decoder and classifier as LaCIM-d and a additional 2-layer MLP with channel 256-256-dimz is used
to extract latent z. The detailed number of parameters and channel size on each dataset for each
method are summarized in Tab. 13, 14.
7.11	Supplementary for Colored MNIST
Implementation details The network structure for inference model is composed of two parts, with
the first part shared among all environments and multiple branches corresponding to each environment
28
Under review as a conference paper at ICLR 2021
for the second part. The network structure of the first-part encoder is composed of four blocks, each
block is the sequential of Convolutional Layer (Conv), Batch Normalization (BN), ReLU and max-
pooling with stride 2. The output number of feature map is accordingly 32, 64, 128, 256. The second
part network structure that output the mean and log-variance of S, Z is Conv-bn-ReLU(256) →
Adaptive (1) → FC(256, 256) → ReLU → FC(256, qt=s,z) with FC stands for fully-connected layer.
The structure of ρt=s,z in Eq. (72) is FC(qt, 256) → ReLU → FC(256, qt). The network structure for
generative model Pφ(χ∣s, Z) is the sequential of three modules: (i) UPsamPling with stride 2; (ii) four
blocks of Transpose-Convolution (TConv), BN and ReLU with respective output dimension being
128, 64, 32, 16; (iii) Conv-BN-ReLU-Sigmoid with number of channels in the outPut as 3, followed
by croPPing steP in order to make the image with the same size as inPut dimension, i.e., 3 × 28 × 28.
The network structure for generative modelpφ(y∣s) is commposed of FC (512) → BN → ReLU →
FC (256) → BN → ReLU → FC (|Y|). The qt=s,z is set to 32. We imPlement SGD as oPtimizer with
learning rate 0.5, weight decay 1e - 5 and we set batch size as 256. The total training ePoch is 80.
We first exPlain why we do not fliP y with 25% in the manuscriPt, and then Provide further exPloration
of our method for the setting with fliPPing y.
Invariant Causation v.s. Invariant Correlation by Flipping y in Arjovsky et al. (2019) The y is
further fliPPed with 25% to obtain the final label in IRM setting and this steP is omitted in ours. The
difference lies in the definition of invariance. Our LaCIM defines invariance as the causal relation
between S and the label Y , while the one in IRM can be correlation. As illustrated in Handwritting
SamPle Form in Fig. 7.11 in Grother (1995), the generting direction should be Y → X. If we
denote the variable by flipping Y as Y (a.k.a, the final label in IRM), then the causal graph should be
X J Y → Y. In this case, the Y is correlated rather than causally related to the digit X. For our
LaCIM, we define the label as interpretable human label (which can approximate to y for any image
x) and represented by Y in our experiments. The reason why we do not define the Y as ground-truth
label is that (i) the prediction is only based on the extracted components of image which may be
determined not only by the ground-truth label; (ii) the learning of ground-truth is interpretable that
relevant to human. For example, if a writer is provided with digit “2” but he wrote it mistakenly
as “4”, then it is more interpretable that we can predict the digit as “4” rather than “2”. For the
digit with ambiguous label from the perspective of image, even if we predict it mistakenly, it is also
interpretable in terms of prediction given the information of only digit. Returning back to the IRM
setting, the label is flipping without reference to the semantic shape of digit. Therefore, the flipping
may happen to noiseless digits rather than noisy and unsure ones, making the shape of number less
semantically related to the label.
Experiment with IRM setting We further conduct the experiment on IRM setting, with the final
label y defined by flipping original label with 25%, and further color pe proportions of digits with
corresponding color-label mapping. If we assume the original ground-truth label to be the effect of
the digit number of S, then the anti-causal relation with Z and Y can make the identifiability of S
difficult in this flipping scenario. Note that the causal effect between S and Y is invariant across
domains, therefore we adopt to regularize the branch of inferring S to be shared among inference
models for multiple environments. Besides, we regularize the causal effect between S and Z to be
shared among different environments via pairwise regularization. The combined loss is formulated
as:
Γ mm
LΨ,Φ = LΨ,Φ + 2m ΣΣ IlE(X,y)~pei(x,y) [y∣x] ― E(x,y)~pej (x,y)[y|x] k2,
m i=1 j=1
with qψe (s, z|x) in Eq. (72) factorized as qψze(z)qψs (s) and ρs shared among m environments. The
appended loss is coincide with recent study Risk-Extropolation (REx) in Krueger et al. (2020), with
the difference of separating y-causative factors S from others. We name such a training method as
LaCIM-REx. For implementation details, in addition to shared encoder regarding S, we set learning
rate as 0.1, weight decay as 0.0002, batch size as 256. we have thatp(y|x) = JS qψs (s∖χ)pψ(y∖ρs(s))
for any x. We consider two settings: setting#1 with m2 and pe1 = 0.9, pe2 = 0.8; and setting#2 with
m= 4 with pe1 = 0.9, pe2 = 0.8, pe3 = 0.7, pe4 = 0.6. We only report the number of IRM since
the cross entropy performs poorly in both settings. As shown, our model performs comparably with
LaCIM-ds and better than IRM Arjovsky et al. (2019) due to separation of S znd Z.
29
Under review as a conference paper at ICLR 2021
DΛΓE

Th⅛ RTηpk ol KUd♦岫，■ bsdD⅞ uUst*d ⅛T 喉 U t蝴维的KMkr KC^piilMM of Sd P皿Led auα⅛eι
UHl JtiUM P‰* 训■“人 (DuaW叫 c⅛nc⅞tn ju 垛* Imxkm ikai 叩 gσ b«bv.
01232”89 —	D1∙∏4V7 仆	(H "456789
h∕J⅝√.Γ⅛7g√f Le∕**⅛z"^^1 I 0/3 3 m而
Z N5HHGE GNTWQTiKFLPOHnRVDIA
I 228。Q£2* y W & TKFLyQH产JEy»3百	^i
Pfcl p+b l⅛v βlcπ⅛5 kxt u Ihc bc«t below:
wS ɑ* *肚 q♦" °,"ud 8卬K io «« 2 form ■ IKg jwtfκt UlKRl ββnb岫 Jitfii懂、加We damG
ZfMqvLiiljl prcπde- fa? Be 4∞∣w⅛ħ Mttpvamcik U>c ∣ejmal WdEecl Knd HCUr« kk D1∙mod^∣ MLTbmTt
的sr Pmt⅛ty 命 owl∙t∙ ad	Uu» CDMSTITbION % <∣w Utilud Sm^ M AMim
川导寺也佻日小色M 抖缶〃叫夕甘W? MS相
&「纳里川0广* ParPL)ΛuθWf £5+加5+EJ
Ms"e d。力? S 十 IC -tVa MUld+y	山dt 04 ¼,d
色QrX MON。€「包门弓© ； pcomo+g WhW Λ‹t∏⅜rq L V>dl⅛f¾
OtiMfYdVCe4吊电 §I宅SSWS OPRi/"≠y +8 CiUrr
S卫Re> a∖N。。干 0。$叶军「1>ι 4o OrdQE a八4
⅛¾-⅛bl l⅛⅛ ¼⅛ 色02$丁［TUTgw per Ake
On∖t⅛ 4	β>A ,∣⅛ rn«r∣t⅛..
Figure 6: Hand-writting Sample Form. The writer print the digit/character (i.e., X) with the label
(i.e., Y ) provided first.
Table 6: Accuracy (%) of Colored MNIST on IRM setting in Arjovsky et al. (2019). Average over
three runs.
	IRM	LaCIM-ds (Ours)	LaCIM-REx (Ours)
m = 2	67.15 ± 3.79	-68.16 ± 2.13-	67.57 ± 1.37
m = 4	69.37 ± 1.14	69.55 ± 1.60	69.50 ± 0.57
7.12 Supplementary for NICO
Implementation Details Due to size difference among images, we resize each image into 256×256.
The network structure of pθ(z, s∣⅛), qφ(z, s|x, ds),Pθ(x|z, s),pθ(y|s) for cat/dog classification is
the same with the one implemented in early prediction of Alzheimer’s Disease with exception of
3D convolution/Deconvolution replaced by 2D ones. For each model, we train for 200 epochs using
sgd, with learning rate (lr) set to 0.01, and after every 60 epochs the learning rate is multiplied by lr
decay parameter that is set to 0.2. The weight decay coefficients parameter is set to 5 × 10-4. The
30
Under review as a conference paper at ICLR 2021
Table 7: Training and test environments (characterized by ds)
I cat% on grass		dog% on grass	cat% on snow	cat% on snow
I	Training Environment				
Env#1 (des1 )	0.6	0.4	0.1	0.9
Env#2 (des2)	0.8	0.2	0.1	0.9
Env#3 (des3)	0.5	0.5	0.2	0.8
Env#4 (des4 )	0.8	0.2	0.2	0.8
Env#5 (des5 )	0.7	0.3	0.2	0.8
Env#6 (des6)	0.8	0.2	0.3	0.7
Env#7 (des7)	0.7	0.3	0.3	0.7
Env#8 (des8)	0.9	0.1	0.3	0.7
Env#9 (des9)	04	06	0.3	0.7
Env#10 (des10)	0.6	0.4	0.3	0.7
Env#11 (des11)	0.5	0.5	0.4	0.6
Env#12 (des12)	0.4	0.6	0.4	0.6
Env#13 (des13)	0.7	0.3	0.4	0.6
Env#14 (des14)	0.8	0.2	0.4	0.6
I	Testing Environment				
Env Test dtsest	0.2	0.8	0.8	0.2
Table 8: Comparison on constructed interventional dataset in terms of ACC.
Method	CE X → Y	IRM	DANN	NCBB	MMD-AAE	DIVA	LaCIM-d
ACC	52.50 一	50.00	49.17	49.17	49.17 一	50.00	55.00
batch size is set to 30. The training environments which is characterized by c can be referenced in
Table 7.12. For visualization, we implemented the gradient-based method Simonyan et al. (2013) to
visualize the neuron (in fully connected layer for both CE x → y and CE (x, ds) → y; in s layer for
LaCIM-ds) that is most correlated to label y.
The ds for m environments We summarize the ds ofm = 8 and m = 14 environments in Table 7.12.
As shown, the value of ds in the test domain is the extrapolation of the training environments, i.e., the
dtsest is not included in the convex hull of {dei }i1=41.
More Visualization Results Fig. 7 shows more visualization results.
Results on Intervened Data. We test our model and the baseline on intervened data, in which each
image is generated by intervention on Z, i.e., taking a specific value of Z. This intervention breaks
the correlation between S and Z , thus the distribution of which can be regarded as a specific type of
OOD. Specifically, we replace the scene of an image with the scene from the another image, as shown
in Fig. 8. We generate 120 images, including 30 images of types: cat on grass, dog on grass, cat on
snow, and dog on grass. We evaluate LaCIM-d, CE X → Y , IRM, DANN, NCBB, MMD-AAE, and
DIVA methods on this intervened dataset. As shown in Tab 9, our LaCIM-d can performs the best
among all methods, which validate the robustness of our LaCIM.
7.13 Disease Prediction of Alzheimer’ s Disease
Dataset Description. The dataset contains in total 317 samples with 48 AD, 75 NC, and 194 MCI.
Denotation of Attributes ds. The C ∈ R9 includes personal attributes (e.g., age Guerreiro and Bras
(2015), gender Vina and Lloret (2010) and education years Mortimer (1997) that play as potential
Table 9: Comparison on constructed interventional dataset in terms of ACC.
Method	CE X → Y	IRM	DANN	NCBB	MMD-AAE	DIVA	LaCIM-d
ACC	52.50 一	50.00	49.17	49.17	49.17 一	50.00	55.00
31
Under review as a conference paper at ICLR 2021
Figure 7: Visualization on the NICO via gradient-based method Simonyan et al. (2013) for CE
X → Y , CE (X, ds) → Y and LaCIM. The selected images are (a) cat on grass, (b) cat on snow, (c)
dog on grass and (d) dog on snow.
risks of AD), gene (ε4 allele), and biomarkers (e.g., changes of CSF, TAU, PTAU, amyloidβ , cortical
amyloid deposition (AV45) Humpel and Hochstrasser (2011)).
Implementation Details For LaCIM-ds, we parameterize inference model qψ (s, z|x, ds),
Pφ(s,z∣ds), pφ(x|z, s) and pφ(y|s) and S, Z ∈ R64. For qψ(s, z∣x,ds), We concatenate outputs
of feature extractors of X and ds : the feature extractor for x is composed of four Convolution-Batch
32
Under review as a conference paper at ICLR 2021
Dog on snow
Cat on snow
Dog on grass
Cat on grass
Figure 8: The constructed interventional dataset which includes of dog on snow, dog on grass, cat on
snow, and dog on grass.
Normalization-ReLU (CBNR) blocks and four Convolution-Batch Normalization-ReLU-MaxPooling
(CBNR-MP) blocks with structure 64 BNR → 128 CBNR-MP → 128 CBNR → 256 CBNR-MP
→ 256 CBNR → 512 CBNR-MP → 512 CBNR → 1024 CBNR-MP; the feature extractor of c is
composed of three Fully Connection-Batch Normalization-ReLU (FC-BNR) blocks with structure
128 → 256 → 512. The concatenated features are further transformed by four 64 FC-BNR to generate
μs,z(x, ds) and logσs,z(x, ds). For the prior model pθ(s, z|ds), it shares the same structure with-
out feature extractor of x. For Pφ(χ∣s, z), the network is composed of three DeConvolution-Batch
Normalization-ReLU (DCBNR) blocks and three Convolution-Batch Normalization-ReLU (CBNR)
blocks, followed by a convolutional layer, with structure 256 DCBNR → 256 CBNR → 128 DCBNR
→ 128 CBNR → 64 DCBNR → 64 CBNR → 48 Conv. For pφ(y ∣s),the network is composed of 256
FC-BNR → 512 FC-BNR → 3 FC-BNR. For prior model pψ(s,z∖ds)Ngzg, diag(σ2,z(ds)))
the μs,z(x, ds) and logσs,z(x, d§) are parameterized by Multi Perceptron Neural Network (MLP).
The decoders pφ(x∖s, z) are pφ(y∖s) parameterized by Deconvolutional neural network. For all
methods, we train for 200 epochs using SGD with weight decay 2 × 10-4 and learning rate 0.01 and
is multiplied by 0.2 after every 60 epochs. The batch size is set to 4. For each variable in biomarker
vector C ∈ R9, each person may have multiple records, and we take its median as representative to
avoid extreme values due to device abnormality.
As for LaCIM-d, we adopt the same decoder pφ(x∖z, s) and classifier pφ(y∖s). For qψ(s, z∖x, d),
We adopt the same network for the shared part; for the part specific to each domain, μs,z(χ, d)
and log σs,z (x, d) are generated by the sub-network which is composed of 1024 FC-BNR → 1024
FC-BNR → qz,s FC-BNR. The z, S can be reparameterized by μs,z(x, d) and log σs,z(x, d) are fed
into a sub-network which is composed of qz,s FC-BNR → 1024 FC-BNR → qz,s FC-BNR to get
rid of the constraint of Gaussian distribution. Then the reconstructed images and predicted label are
computed by pφ(x∖z, s) and pφ(y∖s) which have the same network structure of LaCIM-C with the
z, s.
33
Under review as a conference paper at ICLR 2021
Table 10: Training and test environments (characterized by c) in early prediction of AD
	Training Env#1	Training Env#1	Test
		Age		
	 Number of AD	17	17	14
Number of MCI	76	83	35
Number of NC	34	27	14
Average value of ds (years):	68.75	72.78	81.74
		TAU			
Number of AD	11	22	15
Number of MCI	75	78	41
Number of NC	40	27	18
Average value of ds:	215.34	286.69	471.72
The ds variable in training and test. The selected attributes include Education Years, Age, Gender
(0 denotes male and 1 denotes female), AV45, amyloidβ and TAU. We split the data into m = 2
training environments and test according to different value of ds. The Tab. 7.13 describes the data
distribution in terms of number of samples, the value of ds (Age and TAU).
7.13.1	Experiments with Complete Observable Source Variable
In image-based diagnosis, the personal attributes, genes and biomarkers are often available. Therefore,
we consider the setting when ds can be fully observed. In this case, the value of ds is person-by-
person. Therefore, the number of environments m is equal to the number of samples. In this case, the
dataset turns to {xi, yi, dis}in=1. The expected risk turns to:
Lψ,φ = Ep(x,y|ds)
1 p φ s ∖ π7	「PΦ(yls) i	Pφ(χls,z)Pφ(s,zldsW∖
-logqψ(ylx,ds)-Eqψ(s,z∣χ,ds) [qψ(yR⅛)log	qψ(s,z∣χ,ds)	JJ.
(73)
And the corresponding empirical risk is:
Lψ,φ = n ― log qψ (yi|xi, ds,i) ― Eqψ(s,z∣Xi,ds,i)
qψ (yi|S)
qψ (yi lxi , ds,i )
log Pφ (Xi|s,Z)Pφ(S,zlds,i) -ll
qψ(s,z∣χi,ds,i)	JJ .
(74)
The ds here is re-defined as the 9-dimensional vector that includes all attributes, genes and biomarkers
mentioned above. We re-split the data into 80% train and 20% test, according to different average
value of specific variable in the whole vector ds .
The ds variable in training and test We implemented OOD tasks in which the value of ds is
different between training and test. Specifically, we repeatedly split the dataset into the training and
the test according to a selected attribute in ds for three times. The average value of these attributes in
train and test are recorded in Table 7.13.1.
Experimental Results We conduct OOD experiments with source variables Age, Gender, amyloidβ
and TAU different between training data and the test. The results are shown in Table 12.
7.14 Supplementary for Deepfake
Implementation Details. We implement data augmentations, specifically images with 30 angle
rotation, with flipping horizontally with 50% probability. We additionally apply random compressing
techniques, such as JpegCompression. For inference model, we adopt Efficient-B5 Tan and Le (2019),
with the detailed network structure as: FC(2048, 2048) →BN→ReLU→ FC(2048, 2048) → BN
→ ReLU → FC(2048, qt=s,z). The structure of reparameterization, i.e., ρt=s,z is FC(qt=s,z, 2048)
→ BN→ ReLU → FC(2048, 2048) → BN → ReLU → FC(2048, qt=s,z). The network structure
for generative model, i.e., Pψ (xlS, z) is TConv-BN-ReLU(qt=s,z, 256) → TConv-BN-ReLU(256,
128) → TConv-BN-ReLU(128, 64)→ TConv-BN-ReLU(64, 32) → TConv-BN-ReLU(32, 32) →
TConv-BN-ReLU(32, 16) → TConv-BN-ReLU(16, 16) → Conv-BN-ReLU(16, 3) → Sigmoid,
34
Under review as a conference paper at ICLR 2021
Table 11: Training and test environments (characterized by c) in early prediction of AD
	Education Years	Age	Gender(0/1)	AV45	amyloidβ	TAU
		Setting #1					
	 Training	15.34	70.56	1.29	1.21	745.61	249.38
Test	19.44	81.74	1.83	1.56	1322.47	471.72
	Setting #2					
Training	15.34	70.62	1.29	1.21	743.01	250.21
Test	19.43	81.19	1.83	1.57	1332.94	446.67
	Setting #3					
Training	15.34	70.62	1.29	1.21	743.39	254.7
Test	19.44	81.19	1.83	1.56	1331.4	446.9
Table 12: Accuracy (%) of OOD prediction on ADNI. Average over three runs.
^^^^ACC (%) Method^^^^_	Setting#1	Setting#2	Setting#3	Setting#1	Setting#2	Setting#3
OOD source		EduCation YearS					AV45			
CE X → Y	61.9 ± 0.0	66.7 ± 1.6	63.0 ± 0.9	67.7 ± 0.9	66.1 ± 3.3	66.1 ± 1.8
DANN	62.4 ± 0.9	62.4 ± 0.9	63.0 ± 1.8	64.6 ± 0.9	67.2 ± 0.9	66.1 ± 0.9
CE (X, ds) → Y	67.2 ± 1.8	66.7 ± 3.2	63.0 ± 1.8	66.1 ± 3.3	66.1 ± 1.8	64.0 ± 0.9
sVAE	67.2 ± 0.9	67.2 ± 0.9	67.2 ± 0.9	65.6 ± 1.8	66.7 ± 2.7	65.1 ± 1.6
LaCIM-ds (Ours)	69.8 ± 1.6	68.8 ± 0.9	69.8 ± 1.6	69.3 ± 1.8	67.7 ± 0.9	67.7 ± 0.0
OOD source		Age					Gender			
CE X → Y	63.6 ± 2.6	65.6 ± 6.0	64.8 ± 4.7	60.5 ± 0.9	60.5 ± 1.8	60.5 ± 0.9
DANN	60.8 ± 1.8	58.7 ± 0.0	58.7 ± 0.0	58.5 ± 1.5	61.5 ± 0.0	60 ± 1.5
CE (X, ds) → Y	60.4 ± 2.9	64.5 ± 2.4	64.4 ± 3.8	63.2 ± 0.9	65.6 ± 1.8	64.1 ± 0.9
sVAE	58.2 ± 0.9	60.0 ± 1.8	58.7 ± 1.6	64.1 ± 0.9	65.6 ± 1.8	64.1 ± 0.9
LaCIM-ds (Ours)	64.0 ± 2.4	70.4 ± 2.4 66.1 ±3.7		65.6 ± 0.9	67.2 ± 1.8	68.2 ± 0.9
^^^^ACC (%) Method^^^^^	Setting#1	Setting#2	Setting#3	Setting#1	Setting#2	Setting#3
OOD source		amyloidβ					TAU			
CE X → Y	59.2 ± 0.9	63.5 ± 4.2	63.1 ± 5.1	64.6 ± 0.9	64.1 ± 0.0	66.0 ± 1.1
DANN	60.8 ± 0.9	60.8 ± 0.9	60.8 ± 0.9	64.6 ± 0.9	65.1 ± 0.9	64.6 ± 0.9
CE (X, ds) → Y	64.6 ± 1.8	64.6 ± 3.7	64.2 ± 2.4	64.6 ± 0.9	66.7 ± 0.9	67.0 ± 1.3
sVAE	66.1 ± 0.9	64.6 ± 0.9	63.5 ± 3.2	68.2 ± 0.9	68.8 ± 2.7	67.2 ± 1.6
LaCIM-ds (Ours)	68.3 ± 1.6	66.1 ± 1.8	65.6 ± 2.4	69.8 ± 0.9	71.4 ± 1.8	68.8 ± 0.0
followed by cropping the image to the same size 3 × 224 × 224. We set qt=s,z as 1024. We implement
SGD as optimizer, with learning rate 0.02, weight decay 0.00005, and run for 9 epochs.
35
UnderreVieW as a ConferenCe PaPersICLR 2021
Table 13: General framework table for our method and baselines on Data ∈ {CMNIST, NICO, ADNI, DeepFakej Dataset. We denote the dimension of 2 or %s as
diι∏z∕s. We list the output dimension (e.g. the channel number) of each module, if it is different from the one in Tab. 14.
Dataset	CEX → Y	CEX,d →Y	MMD-AAE	DANN	DIVA	LaClM-ds	LaCI M-d
Data:CMNIST	Encθata FC(256,dims) Dec-CE^ata	EnCpat a；EnCgata FC(512,dimz) Dec-CEθata	Encθata FC-BN-ReLU(256,256) FC(256,256) → Z Dec^ata!De⅞ata	Encθata DANN-CLS? at a； DANN-CLS? at a	p^ata(x∖zd,zx,zy) βtaC¾∣rf) P需tag W) q跣a 3㈤ fcta(¾l≈) 说 S JI/)	EnCpat a；EnCgata FC-BN-ReLU(512,256) FC(256,dimss) Dec, at a ； DeCg ata prior: EnCgata	Enc^ata EnC 票t a χ m Φ⅛a X m Decθ^tajDecθata
# of Params	1.12M	1.16M	1.23M	ElM	1.69M	1.09M	0.92M
hyper-Params	irrδ∏ wd:0.00005	lrr02 wd: 0.0005	Ir: 0.01 wd: 0.0001	IrrOJ wd: 0.0002	Ir: 0.001 wd: 0.00001	irrδ∏ wd: 0.0001	Ir: 0.01 wd: 0.0002
Data: NICO	Enc^ata FC(1024,dims) Dec-CE^ata	EncData.EncData FC(512,dimz) Dec-CEθata	EncJata FC-BN-ReLU(l 024,1024) FC(1024,1024) → Z DeC，at a； DeCgata	EncJata DANN-CLS? at a； DANN-CLS? at a	P^ata(x∖zd, Zχ , Zy ) ■匕(Zdm) P”％ 历) 端F㈤ fcta(¾l≈) Cta(⅞ι≈)	EnCpat a；EnCgata FC(1536,dimss) Dec, at a ； DeCg ata prior: EnCgata	Encθata ∙gncData X m _ Γ)2∣a ①票ta χ m Dec,at a ；DeCgata
# of Params (rn, = 8)	18.08M	19.0IM	19.7OM	19.13M	「4.86M	16.31M	18.25M
# of Params (m = 14)	18.08M	19.0IM	19.7OM	26.49M	14.87M	18.08M	19.7OM
hyper-Params	Ir: 0.01 wd: 0.0002	Ir: 0.01 wd: 0.0002	Ir: 0.2 wd: 0.0001	Ir: 0.05 wd: 0.0005	Ir: 0.001 wd: 0.0001	Ir: 0.01 wd: 0.0005	Ir: 0.01 wd: 0.0001
Data:ADNI	Enc^ata FC(1024,dims) Dec-CE^ata	EnCpat a；EnCgata FC(1536,dims) DeC-CE,at a	Enc^ ata FC-BN-ReLU(l 024,1024) FC(1024,1024) → Z DecθatajDecθata	Enc^ ata DANN-CLS? at a； DANN-CLS? at a	p^ata(x∖zd,zx,zy) .Fm) Pθyta^y∖y) ⅛ta(^l≈) βta(¾l≈) Cta(⅜ι≈)	EncData.EncData FC(1536,dimss) Dec^ata!De⅞ata prior: EnCgata	Encθata EnC 票t a χ m Φ⅛a X m Decθ^tajDecθata
# of Params	28.27M	28.27M	36.68M	30.21 M	33.22M	33.07M	37.78M
hyper-Params	Ir: 0.01 wd: 0.0002	Ir: 0.01 wd: 0.0002	Ir: 0.005 wd: 0.0002	Ir: 0.01 wd: 0.0002	Ir: 0.005 wd: 0.0001	Ir: 0.005 wd: 0.0002	Ir: 0.01 wd: 0.0002
3
6
Under review as a conference paper at ICLR 2021
Table 14: Network Structure of Modules used in our method and baselines.
Method		CMNIST		NICO	ADNI
EncxData	Conv-BN-ReLU(diminput,64,3,1,1) MaxPool(2) Conv-BN-ReLU(64,128,3,1,1) MaxPool(2) Conv-BN-ReLU(128,256,3,1,1) MaxPool(2) Conv-BN-ReLU(256,256,3,1,1) AdaptivePool(1) Flatten()	Conv-BN-ReLU(diminput,128,3,1,1) Conv-BN-ReLU(128,256,3,2,0) MaxPool(2) Conv-BN-ReLU(256,256,3,1,1) Conv-BN-ReLU(256,512,3,1,1) MaxPool(2) Conv-BN-ReLU(512,512,3,1,1) Conv-BN-ReLU(512,512,3,1,1) MaxPool(2) Conv-BN-ReLU(512,512,3,1,1) Conv-BN-ReLU(512,1024,3,1,1) AdaptivePool(1) Flatteno	Conv3d-BN-ReLU(diminput,128,3,1,1) Conv3d-BN-ReLU(128,256,3,2,0) MaxPool(2) Conv3d-BN-ReLU(256,256,3,1,1) Conv3d-BN-ReLU(256,512,3,1,1) MaxPool(2) Conv3d-BN-ReLU(512,512,3,1,1) Conv3d-BN-ReLU(512,512,3,1,1) MaxPool(2) Conv3d-BN-ReLU(512,512,3,1,1) Conv3d-BN-ReLU(512,1024,3,1,1) AdaptivePool(1) Flatten()
DecxData	UnFlatten() Upsample(2) Tconv-BN-ReLU(diminput,128,2,2,0) Tconv-BN-ReLU(128,64,2,2,0) Tconv-BN-ReLU(64,32,2,2,0) Tconv-BN-ReLU(32,16,2,2,0) Conv(16,3,3,1,1) Sigmoid() Cropping(28)	UnFlatten() Upsample(16) Tconv-BN-ReLU(diminput,256,2,2,0) Conv-BN-ReLU(256,256,3,1,1) Tconv-BN-ReLU(256,128,2,2,0) Conv-BN-ReLU(128,128,3,1,1) Tconv-BN-ReLU(128,64,2,2,0) Conv-BN-ReLU(64,64,3,1,1) Tconv-BN-ReLU(64,32,2,2,0) Conv-BN-ReLU(32,32,3,1,1) Conv(32,3,3,1,1) Sigmoid()	UnFlatten() Upsample(6) Tconv3d-BN-ReLU(diminput,256,2,2,0) Conv3d-BN-ReLU(256,256,3,1,1) Tconv3d-BN-ReLU(256,128,2,2,0) Conv3d-BN-ReLU(128,128,3,1,1) Tconv3d-BN-ReLU(128,64,2,2,0) Conv3d-BN-ReLU(64,64,3,1,1) Tconv3d-BN-ReLU(64,64,2,2,0) Conv3d-BN-ReLU(64,64,3,1,1) Conv3d(64,1,3,1,1) Sigmoid()
EncData	FC-BN-ReLU(d,128) FC-BN-ReLU(128, 256)	FC-BN-ReLU(d, 256) FC-BN-ReLU(256, 512) FC-BN-ReLU(512,512)	FC-BN-ReLU(d, 256) FC-BN-ReLU(256, 512) FC-BN-ReLU(512, 512)
DecData	FC-BN-ReLU(dimz,s, 512) FC-BN-ReLU(512, 256) FC(256,2)	FC-BN-ReLU(dimz ,s ,512) FC-BN-ReLU(512, 256) FC(256,2)	FC-BN-ReLU(dimz,s, 512) FC-BN-ReLU(512, 256) FC(256,2)
Dec-CEData	FC-BN-ReLU(dimz,s, 512) FC-BN-ReLU(512, 256) FC(256,2)	FC-BN-ReLU(dimz,s ,1024) FC-BN-ReLU(1024, 2048) FC(2048,2)	FC-BN-ReLU(dimz,s, 512) FC-BN-ReLU(512, 256) FC(256,2)
DANN-CLSData	FC-BN-ReLU(256, 32) FC-BN-ReLU(32, 2)	FC-BN-ReLU(1024, 2048) FC-BN-ReLU(2048, 2)	FC-BN-ReLU(1024,1024) FC-BN-ReLU(1024, 2)
ΦData z,s	FC-ReLU(dimz,s,256) FC-ReLU(256,dimz,s)	FC-ReLU(dimz,s ,1024) FC-ReLU(1024,,dimz,s)	FC-ReLU(dimz,s,1024) FC-ReLU(1024,,dimz,s)
EncData z,s	FC-ReLU(256, 256) 	FC-ReLU(256,dimz,s)		FC-ReLU(1024,1024) FC-ReLU(1024, dimz,s)	FC-ReLU(1024,1024) FC-ReLU(1024, dimz,s)
PData(Xlzd,zχ,Zy)	FC-BN-ReLU(1024) UnFlatten() Upsample(8) TConv-BN-ReLU(64,128,5,1,0) Upsample(24) TConv-BN-ReLU(128,256,5,1,0) Conv(256, 256*3,1,1,0)	FC-BN-ReLU(1024) UnFlatten() Upsample(16) TConv-BN-ReLU(64,128,5,1,0) Upsample(64) TConv-BN-ReLU(128,256,5,1,0) Upsample(256) Conv(256, 3,1,1,0)	FC-BN-ReLU(1024) UnFlatten() Upsample(8) TConv3d-BN-ReLU(16,64,5,1,0) Conv3d-BN-ReLU(64,128,3,1,1) Upsample(24) TConv3d-BN-ReLU(128,128,5,1,0) Conv3d-BN-ReLU(128,128,3,1,1) Upsample(48) Conv3d-BN-ReLU(128,32,3,1,1) Conv3d(32, 1,1,1,0)
PData(ZdId) PData(Zy Iy)	FC-BN-ReLU(dimd,y ,64) FC(64,64); FC(64,64)	FC-BN-ReLU(dimd,y ,64) FC(64,64); FC(64,64)	FC-BN-ReLU(dimd,y, 64) FC(64,64); FC(64,64)
qφdta(zd |x) qφDxata(ZxIx) qφDyata(ZyIx)	Conv-BN-ReLU(3,32,5,1,0) MaxPool(2) Conv-BN-ReLU(32,64,5,1,0) MaxPool(2) Flatten() FC(1024, 64); FC(1024, 64) Data	Conv-BN-ReLU(3,32,3,2,1) MaxPool(2) Conv-BN-ReLU(32,64,3,2,1) MaxPool(2) Conv-BN-ReLU(64,64,3,2,1) MaxPool(2) Flatten() FC(1024, 64); FC(1024, 64) Data	Conv3d-BN-ReLU(1,64,3,2,1) Conv3d-BN-ReLU(64,128,3,1,1) MaxPool(3) Conv3d-BN-ReLU(128,256,3,1,1) Conv3d-BN-ReLU(256,256,3,1,1) MaxPool(2) Conv3d-BN-ReLU(256,256,3,1,1) Conv3d-BN-ReLU(256,128,3,1,1) MaxPool(2) Flatten() FC(1024, 64); FC(1024, 64) Data
37