Under review as a conference paper at ICLR 2021
ACT: Asymptotic Conditional Transport
Anonymous authors
Paper under double-blind review
Ab stract
We propose conditional transport (CT) as a new divergence to measure the dif-
ference between two probability distributions. The CT divergence consists of the
expected cost of a forward CT, which constructs a navigator to stochastically trans-
port a data point of one distribution to the other distribution, and that of a backward
CT which reverses the transport direction. To apply it to the distributions whose
probability density functions are unknown but random samples are accessible, we
further introduce asymptotic CT (ACT), whose estimation only requires access to
mini-batch based discrete empirical distributions. Equipped with two navigators
that amortize the computation of conditional transport plans, the ACT divergence
comes with unbiased sample gradients that are straightforward to compute, making
it amenable to mini-batch stochastic gradient descent based optimization. When
applied to train a generative model, the ACT divergence is shown to strike a good
balance between mode covering and seeking behaviors and strongly resist mode
collapse. To model high-dimensional data, we show that it is sufficient to modify
the adversarial game of an existing generative adversarial network (GAN) to a
game played by a generator, a forward navigator, and a backward navigator, which
try to minimize a distribution-to-distribution transport cost by optimizing both the
distribution of the generator and conditional transport plans specified by the navi-
gators, versus a critic that does the opposite by inflating the point-to-point transport
cost. On a wide variety of benchmark datasets for generative modeling, substituting
the default statistical distance of an existing GAN with the ACT divergence is
shown to consistently improve the performance.
1	Introduction
Measuring the difference between two probability distributions is a fundamental problem in statistics
and machine learning (Cover, 1999; Bishop, 2006; Murphy, 2012). A variety of statistical distances
have been proposed to quantify the difference, which often serves as the first step to build a gener-
ative model. Commonly used statistical distances include the KUllback-Leibler (KL) divergence
(KUllback and Leibler, 1951), JenSen-Shannon (JS) divergence (Lin, 1991), and Wasserstein dis-
tance (Kantorovich, 2006). While being widely used for generative modeling (Kingma and Welling,
2013; Goodfellow et al., 2014; Arjovsky et al., 2017; Balaji et al., 2019), they all have their own
limitations. The KL divergence, directly related to both maximum likelihood estimation and varia-
tional inference, is amenable to mini-batch stochastic gradient descent (SGD) based optimization
(Wainwright and Jordan, 2008; Hoffman et al., 2013; Blei et al., 2017). However, it requires the
two probability distributions to share the same support, and hence is often inapplicable if either of
them is an implicit distribution whose probability density function (PDF) is unknown (Mohamed and
Lakshminarayanan, 2016; Huszar, 2017; Tran et al., 2017; Yin and Zhou, 2018). The JS divergence
is directly related to the mini-max loss of a generative adversarial net (GAN) when the discriminator
is optimal (Goodfellow et al., 2014). However, it is difficult to maintain a good balance between the
generator and discriminator, making GANs notoriously brittle to train. The Wasserstein distance is a
widely used metric that allows the two distributions to have non-overlapping supports (Villani, 2008;
Santambrogio, 2015; Peyre and Cuturi, 2019). However, it is challenging to estimate in its primal
form and generally results in biased sample gradients when its dual form is employed (Arjovsky et al.,
2017; Bellemare et al., 2017; Bottou et al., 2017; BinkOWSki et al., 2018; Bernton et al., 2019).
To address the limitations of existing measurement methods, we introduce conditional transport
(CT) as a new divergence to quantify the difference between two probability distributions. We
1
Under review as a conference paper at ICLR 2021
refer to them as the source and target distributions and denote their probability density functions
(PDFs) as pX (x) and pY (y), respectively. The CT divergence is defined with a bidirectional
distribution-to-distribution transport. It consists of a forward CT that transports the source to target
distribution, and a backward CT that reverses the transport direction. Our intuition is that given a
source (target) point, it is more likely to be transported to a target (source) point closer to it. Denoting
d(x, y) = d(y, x) as a learnable function and c(x, y) = c(y, x) ≥ 0, where the equality is true
when x = y, as the point-to-point transport cost, the goal is to minimize the transport cost between
two distributions. The forward CT is constructed in three steps: 1) We define a forward “navigator”
as π(y | x) = e-d(x,y)pY (y)/ e-d(x,y)pY (y)dy, a conditional distribution specifying how likely
a given source point x will be transported to distribution pY (y) via path x → y; 2) We define
the cost of a forward x-transporting CT as c(x, y)π(y | x)dy, the expected cost of employing
the forward navigator to transport x to a random target point; 3) We define the total cost of the
forward CT as pX (x) c(x, y)π(y | x)dydx, which is the expectation of the cost of a forward
x-transporting CT with respect to pX (x). Similarly, we construct the backward CT by first defining
a backward navigator as π(x | y) = e-d(x,y)pX (x)/ e-d(x,y) pX (x)dx and then its total cost as
pY (y) c(x, y)π(x | y)dxdy. Estimating the CT divergence involves both π(x | y) and π(y | x),
which, however, are generally intractable to evaluate and sample from, except for a few limited
settings where both pX (x) and pY (y) are exponential family distributions conjugate to e-d(x,y).
To apply the CT divergence in a general setting where we only have access to random samples from
the distributions, we introduce asymptotic CT (ACT) as a divergence measure that is friendly to
mini-batch SGD based optimization. The ACT divergence is the expected value of the CT divergence,
whose pX (x) and pY (y) are both replaced with their discrete empirical distributions, respectively
supported on N independent, and identically distributed (iid) random samples from pX (x) and M
iid random samples from pY (y). The ACT divergence is asymptotically equivalent to CT divergence
when both N → ∞ and M → ∞. Intuitively, it can also be interpreted as performing both a forward
one-to-M stochastic CT from the source to target and a backward one-to-N stochastic CT from the
target to source, with the expected cost providing an unbiased sample estimate of the ACT divergence.
We show that similar to the KL divergence, ACT provides unbiased sample gradients, but different
from it, neither pX (x) nor pY (y) needs to be known. Similar to the Wasserstein distance, it does
not require the distributions to share the same support, but different from it, the sample estimates of
ACT and its gradients are unbiased and straightforward to compute. In GANs or Wasserstein GANs
(Arjovsky et al., 2017), having an optimal discriminator or critic is required to unbiasedly estimate the
JS divergence or Wasserstein distance and hence the gradients of the generator (Bottou et al., 2017).
However, this is rarely the case in practice, motivating a common remedy to stabilize the training
by carefully regularizing the gradients, such as clipping or normalizing their values (Gulrajani et al.,
2017; Miyato et al., 2018). By contrast, in an adversarial game under ACT, the optimization of the
critic, which manipulates the point-to-point transport cost c(x, y) but not the navigators’ conditional
distributions for X → y and X J y, has no impact on how ACT is estimated. For this reason, the
sample gradients stay unbiased regardless of how well the critic is optimized.
To demonstrate the use of the ACT (or CT) divergence, we apply it to train implicit (or explicit)
distributions to model both 1D and 2D toy data, MNIST digits, and natural images. The implicit
distribution is defined by a deep generative model (DGM) that is simple to sample from. We focus on
adapting existing GANs, with minimal changes to their settings except for substituting the statistical
distances in their loss functions with the ACT divergence. We leave tailoring the network architectures
to the ACT divergence to future study. More specifically, we modify the GAN loss function to an
adversarial game between a generator, a forward navigator, and a backward navigator, which try to
minimize the distribution-to-distribution transport cost by optimizing both the fake data distribution
pY (y) and two conditional point-to-point navigation-path distributions π(y | X) and π(X | y), versus
a critic that does the opposite by inflating the point-to-point transport cost c(X, y). Modifying an
existing (Wasserstein) GAN with the ACT divergence, our experiments show consistent improvements
in not only quantitative performance and generation quality, but also learning stability.
2	Conditional Transport with Generator, Navigators, and Critic
Denote X as a data taking its value in RV . In practice, we observe a finite set X = {Xi}|iX=1| , consisting
of |X | data samples assumed to be iid drawn from pX (X). Given X, the usual task is to learn a
distribution to approximate pX (X), explaining how the data in X are generated. To approximate
2
Under review as a conference paper at ICLR 2021
PX (x),we consider a DGM defined as y = Ge (e), e 〜p(e), where Ge is a generator that transforms
noise E 〜p(e) via a deep neural network parameterized by θ to generate random sample y ∈ RV.
While the PDF of the generator, denoted as pe(y), is often intractable to evaluate, it is straightforward
to draw y 〜pe(y) with Ge. Denote both μ(dx) = PX(x)dx and V(dy) = pe(y)dy as continuous
probability measures over RV, with μ(RV) = RRV PX (x)dx = 1 and V(RV) = RRV Pe(y)dy = 1.
The Wasserstein distance in its primal form can be defined with Kantorovich’s optimal transport
problem (Kantorovich, 2006; Villani, 2008; Santambrogio, 2015; Peyre and Cuturi, 2019):
W(μ, V)=min∏∈∏(",ν){RRv×rv c(x, y)∏(dx, dy)} = min∏∈∏(",ν){E(x,y)〜∏(x,y)[c(x, y)]}, (1)
where the minimum is taken over Π(μ, ν), defined as the set of all possible joint probability measures
π on RV X RV, with marginals π(A, RV) = μ(A) and π(RV, A) = V(A) for any Borel set A ⊂ RV.
When c(x, y) = kx - y k, we obtain the Wasserstein-1 distance, also known as the Earth Mover’s
distance, for which there exists a dual form according to the Kantorovich duality as
WI (μ, V) =Supf ∈Lipi {Ex〜PX(x)[f (X)] — Ey〜PY(y)[fW)]},
where f is referred to as the “critic” and Lip1 denotes the set of all 1-Lipschitz functions (Villani,
2008). Intuitively, the critic f plays the role of “amortizing” the computation of the optimal transport
plan. However, as it is difficult to ensure the 1-Lipschitz constraint, one often resorts to approximations
(Arjovsky et al., 2017; Gulrajani et al., 2017; Wei et al., 2018; Miyato et al., 2018) that inevitably
introduce bias into the estimation of W1 and its gradient (Bellemare et al., 2017; Bottou et al., 2017).
2.1	Forward and Backward Navigators and Conditional Transport Plans
Constraining π ∈ Π(μ, v), the Wasserstein distance satisfies W(μ, V) = W(v, μ). By contrast, the
proposed divergence allows ∏ ∈ Π(μ, V). Denote Tφ(∙) ∈ RH as a neural network based function,
transforming its input in RV into a feature vector in RH, and d(h1, h2) as a function that measures
the difference between h1 , h2 ∈ RH . We introduce a forward CT, whose transport cost is defined as
Cφ,e(μ → V) = Ex〜PX(X)Ey〜∏φ(y |x)[c(X, y)], πφ(y | X) = R ：-&(%(比),%(甘))pθ(y)dy ,	(2)
where πφ (y | x) will be analogized to the forward navigator that defines the forward conditional
transport plan. Similarly, we introduce the backward CT, whose transport cost is defined as
Cφ,e(μ J V) = Ey〜Pθ(y)Eχ〜∏φ(χ |y)[c(X, y)]， πφ(X | y) = R ；-d(Tφ(χ),丁嫉⑺)；X(Xx)dχ ,	⑶
where πφ(X | y) will be analogized to a backward navigator. We now define the CT problem as
minΦ,e {Cφ,e(μ, ν)} , Cφ,e(μ, ν) 哩 2Cφ,e(μ → V) + 1 Cφ,e(μ - V),	(4)
where Cφ,e (μ, ν) = Cφ,e (ν, μ) will be referred to as the CT divergence between μ and ν.
Lemma 1. If y 〜Pe(y) is equal to X 〜PX(x) in distribution and Tφ is chosen such that
e-d∏φ(X),〃(y)) = i(x = y), where 1(∙) is an indicatorfunction, then both the the joint probability
measure π defined with PX (x)πφ(y | x) in (2) and that with Pe (y)∏φ(X | y) in (3) are in Π(μ, V).
Lemma 2. If y 〜Pe(y) is equal to X 〜PX(x) in distribution, then Cφ,e(μ, ν) = Cφ,e(μ → V)=
Cφ,e(μ J ν) ≥ W(μ, V) = 0, where the equality Can be achieved if e-d(Tφ(X),Tφ(y" = 1(x = y).
The proofs are deferred to Appendix A. Note in general, before both θ and φ reach their optimums,
the conditions specified in Lemmas 1 and 2 are not satisfied and the joint probability measure π
defined with PX (X)∏φ(y | x) or Pe(y)∏φ(X | y) is not restricted to be in Π(μ, ν), and hence it is
possible for Cφ,e(μ → ν), Cφ,e(μ J ν), or Cφ,e(μ, ν) to go below W(μ, ν) during training.
2.2	Asymptotic Conditional Transport
Computing the CT divergence requires either knowing the PDFs of both navigators πφ(y | X)
and πφ(X | y), or being able to draw random samples from them. However, usually neither is
true unless both Pe(y) and PX (X) are known and conjugate to e-d(Tφ(X),Tφ(y)). For example, if
d(Tφ(X), Tφ(y)) = kφX — φyk22 = (X — y)T (φT φ)(X — y), where φ ∈ RV×V is a full-rank
matrix, and both PX (X) and Pe(y) are multivariate Gaussian distributions, then one may show that
both πφ(y | X) and πφ(X | y) are multivariate Gaussian distributions. In the experimental results
3
Under review as a conference paper at ICLR 2021
section, we will provide a univariate normal distribution based toy examples for illustration. Below
we show how to apply the CT divergence in a general setting that only requires access to random
samples of both x and y. While knowing neitherpX(x) norpθ(y), we can obtain mini-batch based
empirical probability measures μN and VM, as defined below, to guide the optimization of Gθ in an
iterative manner. With N random observations sampled without replacement from X, we define
μN = N Pi=1 δχi, {χι,..., XN }⊆X	(5)
as an empirical probability measure for x. Similarly, with M random samples of the generator, we
define an empirical probability measure for y as
^m = M PM δy,, yj = Gθ(与),e产p(e) .	(6)
Substituting pθ(y) in (2) with VM (y), the continuous forward navigator becomes a discrete one as
πΦ(y | X) = PM=I πm(yj |χ, φ)δy°, πm(yj |χ, φ) = pMe-d(Tφ(⅞¾j∖j,))∙	⑺
Thus the cost ofa forward CT becomes
Cφ,θ (μ -→ VM ) = EX〜PX (X)Ey〜∏φ(y | x) [c(x, y)] = EX〜PX (x) [Cφ,θ (X -→ VM)],
where Cφ,θ(x → VM) = pM=1 c(x, y∕∏M(yj | x, φ).	(8)
Similarly, we have the backward navigator and the cost of backward CT as
πΦ(χ | y) = PN=I πn(Xi | y, φ)δXi, πn(Xi | y, φ) = P(Tφ((Ti)(XT)；%(“》,	⑼
CΦ,θ (μN J V) = Ey~Pθ(y)Ex〜∏φ(x | y) [c(X, y)] = Ey~p. (y) [CΦ,θ(μN J y)],
where Cφ,θ(^n J y) =. PN=Ic(Xi, y)∏N(Xi | y, φ).	(10)
Combining both the forward and backward CTs, we define the asymptotic CT (ACT) problem as
minφ,θ{Cφ,θ(μ, ν, N, M)},	(11)
where Cφ,θ (μ, ν, N, M) is the ACT divergence defined as
Cφ,θ(μ,ν, n,m) = 2E	iid [ Jcφ,θ(μ → VM)] + 2E iid [ Jcφ,θ(μN J V)].	(12)
2	yiM 〜pθ(y)	2 xi：n 〜PX(x)
Lemma 3. The ACT divergence is asymptotic that limN,M→∞ Cφ,θ (μ, v,N,M) = Cφ,θ (μ, V).
Lemma 4. With Xi：N iidPX (x) and y±M '〜Pθ(y) and drawing X 〜μN(x) and y 〜 VM (y), an
unbiased sample estimator of the ACT divergence can be expressed as
Lφ,θ(Xi：N, yi：M) = 1 PM=i c(x, yj)∏M(yj | x, Φ) + 1 PN=IcW, y)∏N(Xi | y, Φ).	(13)
Intuitively, the first term in the summation can be interpreted as the expected cost of following the
forward navigator to stochastically transport a random source point X to one of the M randomly
instantiated “anchors” of the target distribution. The second term shares a similar interpretation. Note
in optimal transport, the Wasserstein distance W(μ, v) in its primal form, shown in (1), is in general
intractable to compute. To use the primal form, one often resorts to the sample Wasserstein distance
defined as W (μN ,Vm ), computing which, however, requires solving a combinatorial optimization
problem (Peyre and Cuturi, 2019). To make W(∕^n,Vm) practical to compute, one remedy is
to smooth the optimal transport plan between Rn and VM with an entropic regularization term,
resulting in the Sinkhorn distance that still requires to be estimated with an iterative procedure, whose
convergence is sensitive to the entropic regularization coefficient (Cuturi, 2013; Genevay et al., 2016;
2018; Xie et al., 2020). When the entropic regularization coefficient goes to infinity, we recover
maximum mean discrepancy (MMD), which is considered as the metric for minimization, evaluated
in a kernel space found by the adversarial mechanism in MMD-GAN (Li et al., 2015; 2017). By
contrast, equipped with two navigators, the ACT can directly compute a forward point-to-distribution
transport cost, denoted as Cφ,θ(x → VM) in (8), and a backward one, denoted as Cφ,θ(μN J y)
in (10), which are then combined to define an unbiased sample estimator, as shown in (13), of the
ACT divergence. Intuitively, the navigators play the role of “amortizing” the computation of the
conditional transport plans between two empirical distributions, removing the need of using an
iterative procedure to estimate the transport cost. From this amortization perspective, the navigators
for ACT are analogous to the critic for the Wasserstein distance in its dual form.
Lemma 5. Another unbiased sample estimator fully using the data in mini-batches Xi：N and yi：M,
computing an amortized transport cost between two empirical distributions, can be expressed as
lφ,θ(xi：N, yi：M) = PN=I PJM=I c(χi, yj) (2Nπm(yj xi, φ) + 2Mπn(Xi | yj, φ)) ∙	(14)
4
Under review as a conference paper at ICLR 2021
2.3 Critic based Adversarial Feature Extraction
A naive definition of the transport cost between x and y is some distance between their raw feature
vectors, such as c(x, y) = kx - yk22, which, however, often poorly reflects the difference between
high-dimensional data residing on low-dimensional manifolds. For this reason, with cosine dissim-
ilarity (Salimans et al., 2018), We introduce a critic Tn(∙), parameterized by η, to help define an
adversarial transport cost between two high-dimensional data points, expressed as
cη(x, y) = 1 - cos(Tη(x),Tη(y)),	cos(h1, h2) d=ef.
|hT h2∣
hT hi
(15)
Intuitively, to minimize the distribution-to-distribution transport cost, the generator tries to mimic
true data and both navigators try to optimize conditional path distributions. By contrast, the critic
does the opposite by inflating the point-to-point transport cost.
In summary, given the training data set X, to train the generator Gθ, forWard navigator πφ(y | x),
backWard navigator πφ(x | y), and critic Tη, We propose to solve a mini-max problem as
min maxE	iid	[Lφ,θ,η (x1:N, {Gθ(j)}jM=1)],	(16)
φ,θ n	xi:N⊆X, €i:M 〜p(e)L φ, , n	j j 1
Where Lφ,θ,η is defined the same as in (13) or (14), except that We replace c(xi, yj) in them
With cη(xi, yj ) shoWn in (15) and draW y1:M using reparameterization as in (6), Which means
y1:M =. {Gθ(ej)}M=1. We train φ and θ with SGD using Vφ,θLφ,θ,v(x1：N, {Gθ(5)}^=1)) and, if
the critic is employed, train η with stochastic gradient ascent using VnLφ,θ,η(x1：N, {Gθ(Wj)}M=1)).
Note in existing critic-based GANs, how well the critics are optimized are directly related to how
accurate and stable the gradients can be estimated. By contrast, regardless of how well the critic
is optimized to inflate cn(x, y), Lemma 4 shows the sample estimate Lφ,θ,n (x1:N, {Gθ(Wj)}jM=1)
of the ACT divergence and its gradients stay unbiased. Thus in ACT one can also train the critic
parameter η using a different loss other than (16), such as the cross-entropy discriminator loss used in
vanilla GANs to discriminate between x and Gθ(W). This point will be verified in our ablation study.
3	Experimental Results
CT divergence for toy data: As a proof of concept, we illustrate optimization under the CT
divergence in 1D, with x, y, φ, θ ∈ R. We consider a univariate normal distribution based example:
P(X)= N(O, I), pθ(U)= N(O,eθ), c(χ,y) = (χ — y)2, d(Tφ(X), Tφ(y)) = (x-yφ) .	(17)
Thus θ = 0 is the optimal solution that makes V = μ. Denote σ(a) = 1/(1 + e-a) as the sigmoid
function, we have analytic forms of the Wasserstein distance as W2 (μ, V)2 = (1 — e2 )2, forward and
backward navigators as ∏φ(y | x) = N(σ(θ — φ)x, σ(θ — φ)eφ) and ∏φ(x | y) = N(σ(-φ)y, σ(φ)),
and forward and backward CT costs as Cφ,θ(μ → V) = σ(φ — θ)(eθ + σ(φ — θ)) and Cφ,θ(μ J
V) = σ(φ)(1 + σ(φ)eθ) (see Appendix B.1 for more details). Thus when applying gradient descent
to minimize the CT divergence Cφ,θ(μ, ν), we expect the generator parameter θ → 0 as long as
the learning rate of the navigator parameter φis appropriately controlled to prevent eφ → 0 from
happening too soon. This is confirmed by Fig. 1, which shows that long before eφ approaches zero, θ
has already converged close to zero. This suggests that the navigator parameter φ mainly plays the role
in assisting the learning of θ. It is also interesting to observe that the CT divergences keep descending
towards zero even when W2 (μ, V)2 has already reached close to zero. As θ and φ converge towards
their optimal solutions under the CT divergence, we can observe that Cφ,θ (μ → V) and Cφ,θ (μ J V)
are getting closer. Moreover, Cφ,θ(μ, V) initially stays above W2(μ, v)2 = (1 — e2 )2 but eventually
becomes very close to W2(μ, V)2, which agrees what Lemma 2 suggests. The second and third
subplots describe the descent trace on the gradient of the CT cost with respect to (w.r.t.) θ and φ,
respectively, while the fourth to six subplots show the forward, backward, and bi-directional CT costs,
respectively, against θ when eφ is optimized close to its optimum (see Fig. 8 for analogous plots for
additional values of eφ). It is interesting to notice that the forward cost is minimized at eθ > 1, which
implies mode covering, and the backward cost is minimized at eθ → 0, which implies mode seeking,
while the bi-directional cost is minimized at around the optimal solution eθ = 1; the forward CT cost
5
Under review as a conference paper at ICLR 2021
Figure 1: Illustration of minimizing the CT divergence Cψ,θ(μ, ν) between N(0,1) and N(0,eθ). Left:
Evolution of the CT divergence, its parameters and forward and backward costs, and corresponding Wasserstein
distance; Middle: Gradients of the CT w.r.t. θ or φ. The 2D trace of (θ, eφ) is marked with red arrows. Right:
The forward, backward, and CT values against θ when eφ is optimized to a small value, which show combining
forward and backward balances mode covering and seeking, making it easier for θ to move towards its optimum.
exhibits a flattened curve on the right hand side of its minimum, adding the backward CT cost to
which not only moves that minimum left, making it closer to θ = 0, but also raises the whole curve
on the right hand side, making the optimum of θ become easier to reach via gradient descent.
We further consider a 1D example to illustrate the properties of the conditional transport distributions
of the navigators, and analyze the risk for them to degenerate to point mass distributions when
optimized under the CT or ACT divergence. We defer the details to Appendix B.2 and Fig. 9.
ACT for 1D toy data: We move on to model the empirical samples from a true data distribution,
for which it is natural to apply the ACT divergence. To parameterize ACT, we apply a deep neural
network to generator Gθ and another one to Tφ that is shared by both navigators. We consider the
squared Euclidean (i.e. L22) distance to define both cost c(x, y) and distance d(h1, h2).
----C强DOS, GSMe)
----C(⅛go f 65000)
----C(Msodo4-Wsboo)
----W⅛(μso(M), 65000)2
Figure 2: Illustration of how minimizing the ACT diver-
gence between the empirical distribution of a generator and
that of a bimodal Gaussian mixture, whose 5000 random
samples are given, helps optimize the generator distribu-
tion towards the true one. Top: Plots of the ACT diver-
gence C(^n, VM), forward ACT cost C(μN → VM), back-
ward ACT cost C(^n — ^m), and Wasserstein distance
W2(μN, ^m)2, where N = M = 5000. Bottom: The PDF
of the true data distribution μ(dx) = PX (x)dx (red) and the
generator distribution ν(dy) = pθ (y)dy (blue, visualized via
kernel density estimation) at different training iterations.
We first consider a 1D example, where X
consists of |X | = 5, 000 samples xi ∈ R
of a bimodal Gaussian mixture pX (x) =
4N(x; -5,1) + 4N(x; 2,1). We illus-
trate in Fig. 2 the training with unbiased
sample gradients Vφ,θLφ,θ(X,yi：M) of
the ACT divergence shown in (14), where
yj = Gθ(j). The top panel shows the
ACT divergence, its backward and forward
costs, and Wasserstein distance between
the empirical probability measures ∕^n and
VM defined as in (5) and (6). We set
M = N and hence W2(βχ,Vγ)2 can be
exactly computed by sorting the 1D ele-
ments of xi：N and yi：N (Peyre and Cuturi,
2019). We first consider N = |X | = 5000.
Fig. 2 (Top) shows that the ACT divergence
converges close to W2(μχ,Vγ)2 and the
forward and backward costs move closer
to each other and can sometime go below
W2(μx, VY)2. Fig.2 (Bottom) shows that minimizing the ACT divergence successfully drives the
generator distribution towards true data density: From the left to right, we can observe that initially
the generator is focused on fitting a single mode; at around the 500th iteration, as the forward and
backward navigators are getting better, they start to help the generator locate the missing mode and
we can observe a blue density mode starts to form over there; as the generator and both navigators
are getting optimized, we can observe that the generator clearly captures both modes and the fitting is
getting improved further; finally the generator well approximates the data density. Under the guidance
of the ACT divergence, the generator and navigators are helping each other: An optimized generator
helps the two navigators to train and realize the missing mode, and the optimized navigators help
the generator locate under-fitted regions and hence better fit the true data density. Given the same
X, below we further consider setting N = 20, 200, or 5000 to train the generator, using either the
Wasserstein distance W2(μN, VN)2 or ACT divergence Lφ,θ(xi：N, yi：N) as the loss function.
As shown in the right column of Fig. 3, when the mini-batch size N is as large as 5000, both
Wasserstein and ACT lead to a well-trained generator. However, as shown in the left and middle
columns, when N is getting much smaller, we can observe that the generator trained with Wasserstein
6
Under review as a conference paper at ICLR 2021
W (Mini-batch size =20) Ad(Mini-batchsize =20)	W (Mini-batch size =200)	ACT(MinHbatChSiZe =200)	W(MinHbatChSiZe =5000)	Ad (Mini-batch size = 5000)
Figure 3: Top: Plot of the sample Wasserstein distance W2(μ5000, ^5000)2 against the number of training
epochs, where the generator is trained With either W2(μN, VN)2 or the ACT divergence between μN and VN,
with the mini-batch size set as N = 20 (left), N = 200 (middle), or N = 5000 (right); one epoch consists of
5000/N SGD iterations. Bottom: The fitting results of different configurations, where the KDE curves of the
data distribution and the generative one are marked in red and blue, respectively.
clearly underperforms that trained with ACT, especially when the mini-batch size becomes as small
as N = 20. While the Wasserstein distance W(μ, V) in theory can well guide the training of a
generative model, the sample Wasserstein distance W(μN, VN), whose optimal transport plan is
locally re-computed for each mini-batch, could be sensitive to the mini-batch size N, which also
explains why in practice the sample Wasserstein-based generative models are difficult to train and
desire a large mini-batch size (Salimans et al., 2018). On the contrary, ACT amortizes its conditional
transport plans through its navigators, whose parameter φ is globally updated across mini-batches,
leading to a well-trained generator whose performance has low sensitivity to the mini-batch size.
ACT for 2D toy data: We further conduct experiments on four representative 2D datasets:
8-Gaussian mixture, Swiss Roll, Half Moons, and 25-Gaussian mixture, whose results are shown in
Figs. 10-13 of Appendix B.3. We apply the vanilla GAN (Goodfellow et al., 2014) and Wasserstein
GAN with gradient penalty (WGAN-GP) (Gulrajani et al., 2017) as two representatives of mini-max
DGMs that require solving a mini-max loss to train the generator. We then apply the generators
trained under the sliced Wasserstein distance (SWD) (Deshpande et al., 2018) and ACT divergence
as two representatives of mini-max-free DGMs. Compared to mini-max DGMs, which require an
adversarially learned critic in order to train the generator, one clear advantage of mini-max-free
DGMs is that the generator is stable to train without the need of an adversarial game. On each 2D
data, we train these DGMs as one would normally do during the first 15k iterations. We then only
train the generator and freeze all the other learnable model parameters, which means we freeze the
discriminator in GAN, critic in WGAN, and the navigator parameter φ of the ACT divergence, for
another 15k iterations. Fig. 10 illustrates this training process on the 8-Gaussian mixture dataset,
where for both mini-max DGMs, the mode collapse issue deteriorates after the first 15k iterations,
while the training for SWD remains stable and that for ACT continues to improve. Compared to
SWD, our method covers all 8 data density modes and moves the generator much closer to the true
data density. On the other three datasets, the ACT divergence based DGM also exhibits good training
consistency, high stability, and and close-to-optimal data generation, as shown in Appendix B.3.
Resistance to mode collapse: We
use a 8-Gaussian mixture to empiri-
cally evaluate how well a DGM re-
sists mode collapse. Unlike the data
in Fig. 10, where 8 modes are equally
weighted, here the mode at the left
lower corner is set to have weight ρ
while the other modes are set to have
the same weight of 1-7ρ. We set X
with 5000 samples and the mini-batch
size as N = 100. When ρ is low-
ered to 0.05, its corresponding mode
GAN	WGAN-GP	SWD	ACTgUrS)	True
Figure 4: Comparison of the generation quality on 8-Gaussian
mixture data: one of the 8 modes has weight ρ and the rest modes
have equal weight as 1-ρ.
is shown to be missed by GAN, WGAN, and SWD-based DGM, while well kept by the ACT-based
DGM. As an explanation, GANs are known to be susceptible to mode collapse; WGAN and SWD-
based DGMs are sensitive to the mini-batch size, as when ρ equals to a small value, the samples from
this mode will appear in the mini-batches less frequently than those from any other mode, amplifying
their missing mode problem. Similarly, when ρ is increased to 0.5, the other modes are likely to be
7
Under review as a conference paper at ICLR 2021
Y=I	γ=0.75	γ=0.5	γ=0.25	γ=O
Figure 5: Fitting 1D bi-modal Gaussian (top) and 2D
8-Gaussian mixture (bottom) by interpolating between
the forward ACT (γ = 1) and backward ACT (γ = 0).
missed by the baseline DGMs, while the ACT-based DGM does not miss any modes. The resistance
of ACT to mode dropping can be attributed to the amortized computation of its conditional transport
plans provided by the navigators, whose parameter is optimized with SGD over mini-batches and, as
indicated by Fig. 3, is robust to estimate across a wide rage of mini-batch sizes.
Forward and backward analysis: To empiri-
cally analyze the roles played by the forward and
backward ACTs in training a DGM, we mod-
ify (12) to define ACTγ, where γ ∈ [0, 1] is
the interpolation weight from the forward ACT
cost to the backward one, which means ACTγ
reduces to the forward ACT when γ = 1, to
backward ACT when γ = 0, and to the ACT
in (12) when γ = 0.5. Fig. 5 shows the fitting
results of ACTγ on the same 1D bi-modal Gaus-
sian mixture used in Fig. 2 and 2D 8-Gaussian
mixture used in Fig. 10; the other experimental
settings are kept the same. Comparing the results of different γ in Fig. 5 suggests that minimizing
the forward transport cost only encourages the generator to exhibit mode covering behaviors, while
minimizing the backward transport cost only encourages mode seeking/dropping behaviors; by
contrast, combining both costs provides a user-controllable balance between mode covering and
seeking, leading to satisfactory fitting performance, as shown in columns 2 to 4. Note that for a
fair comparison, we stop the fitting at the same iteration; in practice, we find if training with more
iterations, both γ = 0.75 and γ = 0.25 can achieve comparable results as γ = 0.5. Allowing the
mode covering and seeking behaviors to be controlled by tuning γ is an attractive property of ACTγ .
We leave the theoretical analysis of the mode covering/seeking behaviors of ACTγ for future study.
ACT for natural images: We conduct a variety of experiments on natural images to evaluate the
performance and reveal the properties of DGMs optimized under the ACT divergence. We consider
three widely-used image datasets, including CIFAR-10 (Krizhevsky et al., 2009), CelebA (Liu et al.,
2015), and LSUN-bedroom (Yu et al., 2015), and compare the results of DGMs optimized with the
ACT divergence against DGMs trained with the vanilla GAN and its various generalizations.
Note different from previous experiments on toy data, where the transport cost c(x, y) can be defined
by directly comparing x and y, for natural images, whose differences in raw pixel values are often
not that meaningful, We need to compare Tn(x) and Tn(y), where Tn(∙) is a critic that plays the role
of adversarial feature extraction, as discussed in Section 2.3. In particular, we use (15) to define the
transport cost as cn(x, y) = 1 - cos(Tn(x), Tn(y)). To parameterize the navigators, we also set
d(Tφ(x), Tφ(y)) = 1 - cos(Tφ(x), Tφ(y)). We test with the architecture suggested in Radford et al.
(2015) as a standard CNN backbone and also apply the architecture in Miyato et al. (2018) as the
ResNet (He et al., 2016) backbone. Specifically, we use the same architecture for the generator, and
slightly modify the output dimension of the discriminator architecture as 2048 for both Tn of the
critic and Tφ used by the two navigators. We train this model with (16) and (14), and to keep close to
the corresponding backbone’s original experiment setting, we set N = M = 64 for all experiments.
We summarize in Table 1 the Frechet inception distance (FID) of Heusel et al. (2017) on all datasets
and Inception Score (IS) of Salimans et al. (2016) on CIFAR-10. Both FID and IS are calculated
using a pre-trained inception model (Szegedy et al., 2016). Lower FID and higher IS scores indicate
better image quality. We observe that ACT-DCGAN and ACT-SNGAN, which are DCGAN and
SNGAN backbones optimized with the ACT divergence, convincingly outperform DCGAN and
SNGAN, respectively, suggesting that ACT is compatible with standard GANs and WGANs and
generally helps improve generation quality. Moreover, ranked among the Top 3 on all datasets,
ACT-SNGAN performs on par with the best benchmarks on CIFAR-10 and CelebA, while slightly
worse on LSUN. The qualitative results shown in Fig. 6 are consistent with quantitative results in
Table 1. To additionally show how ACT works for more complex generation tasks, we show in Fig. 7
example higher-resolution images generated by ACT-SNGAN on LSUN bedroom and CelebA-HQ.
Note ACT brings consistent improvement to DCGAN and SNGAN by neither improving their network
architectures nor gradient regularization. Thus it has great potential to work in conjunction with other
state-of-the-art architectures or methods, such as BigGAN (Brock et al., 2018), self-attention GANs
(Zhang et al., 2019), BigBiGAN (Donahue and Simonyan, 2019), progressive training (Karras et al.,
8
Under review as a conference paper at ICLR 2021
Table 1: Comparison of generative models on CIFAR-10, CelebA and LSUN. (Top-3 are in bold)
Method	FreChet Inception Distance (FID, lower is better)			Inception Score (higher is better)
	CIFAR-10	CelebA	LSUN-bedroom	CIFAR-10
WGAN (Arjovsky et al., 2017)	51.3± 1.5	37.1±1.9	73.3±2.5	6.9±0.1
WGAN-GP (Gulrajani et al., 2017)	19.0±0.8	18.0±0.7	26.9±1.1	7.9±0.1
MMD-GAN (Li et al., 2017)	73.9±0.1	-	-	6.2±0.1
Cramer-GAN (Bellemare et al., 2017)	40.3±0.2	31.3±0.2	54.2±0.4	6.4±0.1
CTGAN (Wei et al., 2018)	17.6±0.7	15.8±0.6	19.5±1.2	5.1±0.1
OT-GAN (Salimans et al., 2018)	32.5±0.6	19.4±3.0	70.5±5.3	8.5±0.1
SWG (Deshpande et al., 2018)	33.7±1.5	21.9±2.0	67.9±2.7	-
Max-SWG (Deshpande et al., 2019)	23.6±0.5	10.1±0.6	40.1±4.5	-
SWGAN (WUet al.,2019)	17.0±1.0	13∙2±0.7	14.9±1.0	-
DCGAN (Radford et al., 2015)	30.2±0.9	52.5±2.2	61.7±2.9	6.2±0.1
DCGAN backbone + ACT divergence (ACT-DCGAN)	24.8±1.0	29.2±2.0	37.4±2.5	7.5±0.1
SNGAN (Miyato et al., 2018)	21.5±1.3	21.7±1.5	31.1±2.1	8.2±0.1
SNGAN backbone + ACT divergence (ACT-SNGAN)	18.0±0.7	11.3±1.0	24.2±1.8	8.7±0.1
Figure 6: Generated samples of the deep generative model that adopts the backbone of SNGAN but is optimized
with the ACT divergence on CIFAR-10, CelebA, and LSUN-Bedroom. See Appendix B for more results.
Figure 7: Analogous plot to Fig. 6 for Left: LSUN-Bedroom (128x128) and Right: CelebA-HQ (256x256).
2018), self-supervised learning (Chen et al., 2019), and data augmentation (Karras et al., 2020; Zhao
et al., 2020a;b), which we leave for future study. As the paper is primarily focused on constructing
and validating a new divergence measure, we have focused on demonstrating its efficacy on toy data
and benchmark image data with moderate resolutions. We have focused on adapting DCGAN and
SNGAN under ACT, and we leave to future work using the ACT to optimize a big DGM, such as
BigGAN, that is often trained for high-resolution images with a substantially bigger network and
larger mini-batch size and hence requires intensive computation that is not easy to afford.
4	Conclusion
We propose conditional transport (CT) as a new divergence to measure the difference between two
probability distributions, via the use of both forward-path and backward-path point-to-point condi-
tional distributions. To apply CT to two distributions that have unknown density functions but are easy
to sample from, we introduce the asymptotic CT (ACT) divergence whose estimation only requires
access to empirical samples. ACT amortizes the computation of its conditional transport plans via its
navigators, removing the need of a separate iterative procedure for each mini-batch, and provides
unbiased mini-batch based sample gradients that are simple to compute. Its minimization, achieved
with the collaboration between the generator, forward navigator, and backward navigator, is shown to
be robust to the mini-batch size. In addition, empirical analysis suggests the combination weight of
the forward and backward CT costs can be adjusted to encourage either model covering or seeking
behaviors. We further show that a critic can be integrated into the point-to-point transport cost of ACT
to adversarially extract features from high-dimensional data without biasing the sample gradients. We
apply ACT to train both a vanilla GAN and a Wasserstein GAN. Consistent improvement is observed
in our experiments, which shows the potential of the ACT divergence in more broader settings where
quantifying the difference between distributions plays an essential role.
9
Under review as a conference paper at ICLR 2021
References
Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein generative adversarial networks.
In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages
214-223, 2017.
Yogesh Balaji, Hamed Hassani, Rama Chellappa, and Soheil Feizi. Entropic GANs meet VAEs:
A statistical approach to compute sample likelihoods in GANs. In International Conference on
Machine Learning, pages 414-423, 2019.
Marc G Bellemare, Ivo Danihelka, Will Dabney, Shakir Mohamed, Balaji Lakshminarayanan, Stephan
Hoyer, and Remi Munos. The Cramer distance as a solution to biased Wasserstein gradients. arXiv
preprint arXiv:1705.10743, 2017.
Espen Bernton, Pierre E Jacob, Mathieu Gerber, and Christian P Robert. On parameter estimation
with the Wasserstein distance. Information and Inference: A Journal of the IMA, 8(4):657-676,
2019.
Christopher M Bishop. Pattern Recognition and Machine Learning. springer, 2006.
Mikolaj BinkOWski, Dougal J. Sutherland, Michael Arbel, and Arthur Gretton. Demystifying
MMD GANs. In International Conference on Learning Representations, 2018. URL https:
//openreview.net/forum?id=r1lUOzWCW.
David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisticians.
Journal of the American statistical Association, 112(518):859-877, 2017.
Leon Bottou, Martin Arjovsky, David Lopez-Paz, and Maxime Oquab. Geometrical insights for
implicit generative modeling. arXiv preprint arXiv:1712.07822, 2017.
Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training for high fidelity
natural image synthesis. arXiv preprint arXiv:1809.11096, 2018.
Ting Chen, Xiaohua Zhai, Marvin Ritter, Mario Lucic, and Neil Houlsby. Self-supervised GANs via
auxiliary rotation loss. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pages 12154-12163, 2019.
Thomas M Cover. Elements of Information Theory. John Wiley & Sons, 1999.
Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. In Advances in
Neural Information Processing Systems, pages 2292-2300, 2013.
Ishan Deshpande, Ziyu Zhang, and Alexander G Schwing. Generative modeling using the sliced
Wasserstein distance. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pages 3483-3491, 2018.
Ishan Deshpande, Yuan-Ting Hu, Ruoyu Sun, Ayis Pyrros, Nasir Siddiqui, Sanmi Koyejo, Zhizhen
Zhao, David Forsyth, and Alexander G Schwing. Max-sliced Wasserstein distance and its use for
GANs. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages
10648-10656, 2019.
Jeff Donahue and Karen Simonyan. Large scale adversarial representation learning. In Advances in
Neural Information Processing Systems, pages 10542-10552, 2019.
Aude Genevay, Marco Cuturi, Gabriel Peyre, and Francis Bach. Stochastic optimization for large-
scale optimal transport. In Advances in Neural Information Processing Systems, pages 3440-3448,
2016.
Aude Genevay, Gabriel Peyre, and Marco Cuturi. Learning generative models with Sinkhorn
divergences. In International Conference on Artificial Intelligence and Statistics, pages 1608-1617,
2018.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural
Information Processing Systems, pages 2672-2680, 2014.
10
Under review as a conference paper at ICLR 2021
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville.
Improved training of Wasserstein GANs. In Advances in Neural Information Processing Systems,
pages 5767-5777, 2017.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pages 770-778, 2016.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
GANs trained by a two time-scale update rule converge to a local Nash equilibrium. In Advances
in Neural Information Processing Systems, pages 6626-6637, 2017.
Matthew D Hoffman, David M Blei, Chong Wang, and John Paisley. Stochastic variational inference.
The Journal of Machine Learning Research, 14(1):1303-1347, 2013.
Ferenc Huszar. Variational inference using implicit distributions. arXiv preprint arXiv:1702.08235,
2017.
Leonid V Kantorovich. On the translocation of masses. Journal of Mathematical Sciences, 133(4):
1381-1382, 2006.
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of GANs for
improved quality, stability, and variation. In International Conference on Learning Representations,
2018.
Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Training
generative adversarial networks with limited data. arXiv preprint arXiv:2006.06676, 2020.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua
Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations,
ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL
http://arxiv.org/abs/1412.6980.
Diederik P Kingma and Max Welling. Auto-encoding variational Bayes. arXiv preprint
arXiv:1312.6114, 2013.
Alex Krizhevsky et al. Learning multiple layers of features from tiny images. 2009.
Solomon Kullback and Richard A Leibler. On information and sufficiency. The Annals of Mathemati-
cal Statistics, 22(1):79-86, 1951.
Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document
recognition. Proceedings of the IEEE, 86(11):2278-2324, Nov 1998. ISSN 0018-9219. doi:
10.1109/5.726791.
Chun-Liang Li, Wei-Cheng Chang, Yu Cheng, Yiming Yang, and BarnabaS Poczos. MMD GAN:
Towards deeper understanding of moment matching network. In Advances in Neural Information
Processing Systems, pages 2203-2213, 2017.
Yujia Li, Kevin Swersky, and Rich Zemel. Generative moment matching networks. In International
Conference on Machine Learning, pages 1718-1727, 2015.
Jianhua Lin. Divergence measures based on the Shannon entropy. IEEE Transactions on Information
theory, 37(1):145-151, 1991.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In
Proceedings of the IEEE international conference on computer vision, pages 3730-3738, 2015.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for
generative adversarial networks. In International Conference on Learning Representations, 2018.
Shakir Mohamed and Balaji Lakshminarayanan. Learning in implicit generative models. arXiv
preprint arXiv:1610.03483, 2016.
Kevin P Murphy. Machine Learning: A Probabilistic Perspective. MIT Press, 2012.
11
Under review as a conference paper at ICLR 2021
Gabriel Peyre and Marco CUtUrL Computational optimal transport. Foundations and Trends in
Machine Learning,11(5-6):355-607, 2019.
Alec Radford, LUke Metz, and SoUmith Chintala. UnsUpervised representation learning with deep
convolUtional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki CheUng, Alec Radford, and Xi Chen.
Improved techniqUes for training GANs. In Advances in Neural Information Processing Systems,
pages 2234-2242, 2016.
Tim Salimans, Han Zhang, Alec Radford, and Dimitris Metaxas. Improving GANs Using optimal
transport. arXiv preprint arXiv:1803.05573, 2018.
Filippo Santambrogio. Optimal Transport for Applied Mathematicians: Calculus of Variations, PDEs,
andModeling, volume 87. Birkhauser, 20l5.
Christian Szegedy, Vincent VanhoUcke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking
the inception architecture for computer vision. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pages 2818-2826, 2016.
Dustin Tran, Rajesh Ranganath, and David Blei. Hierarchical implicit models and likelihood-free
variational inference. In Advances in Neural Information Processing Systems, pages 5523-5533,
2017.
Cedric Villani. Optimal Transport: Old and New, volume 338. Springer Science & Business Media,
2008.
Martin J Wainwright and Michael Irwin Jordan. Graphical models, exponential families, and
variational inference. Now Publishers Inc, 2008.
Xiang Wei, Boqing Gong, Zixia Liu, Wei Lu, and Liqiang Wang. Improving the improved training
of Wasserstein GANs: A consistency term and its dual effect. In International Conference on
Learning Representations, 2018.
Jiqing Wu, Zhiwu Huang, Dinesh Acharya, Wen Li, Janine Thoma, Danda Pani Paudel, and Luc Van
Gool. Sliced Wasserstein generative models. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pages 3713-3722, 2019.
Yujia Xie, Xiangfeng Wang, Ruijia Wang, and Hongyuan Zha. A fast proximal point method for
computing exact Wasserstein distance. In Uncertainty in Artificial Intelligence, pages 433-453.
PMLR, 2020.
Mingzhang Yin and Mingyuan Zhou. Semi-implicit variational inference. In International Conference
on Machine Learning, pages 5660-5669, 2018.
Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong Xiao. LSUN:
Construction of a large-scale image dataset using deep learning with humans in the loop. arXiv
preprint arXiv:1506.03365, 2015.
Han Zhang, Ian Goodfellow, Dimitris Metaxas, and Augustus Odena. Self-attention generative
adversarial networks. In International Conference on Machine Learning, pages 7354-7363.
PMLR, 2019.
Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang. The unreasonable
effectiveness of deep features as a perceptual metric. In CVPR, 2018.
Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han. Differentiable augmentation for
data-efficient GAN training. arXiv preprint arXiv:2006.10738, 2020a.
Zhengli Zhao, Zizhao Zhang, Ting Chen, Sameer Singh, and Han Zhang. Image augmentations for
GAN training. arXiv preprint arXiv:2006.02595, 2020b.
12
Under review as a conference paper at ICLR 2021
A Proofs
ProofofLemma 1. If y 〜pθ(y) is equal to X 〜PX(x) in distribution, then PX (x) = pθ(x) for
any x ∈	RV .	For (2) we have	pX(x)πφ(y |	x)dy	= pX (x)	πφ(y	| x)dy	= pX (x)	and
e /	/ ∖ 、八 e e e	e-d(τφ(x),Tφ(y))pθ(y)
P PX(x)πΦ(y | X)dx = J PX(X) R e-d(Tφ(χ)TΦ⑻)pθ(y)dy
/	e-d(τφ(x),Tφ(y))pX (χ)
Pe R-T e-d(TΦ(X),TΦ(J))Pθ(y)dy
dx
dx.
If ed(Tφ(x),Tφ(y)) = 1(X = y), then we further have
/	e-d(Tφ(χ),Tφ(y))PX(χ) d _ /	1(x = y)PX(x) d _ f _ 、Px	(x) d
J R	e-d(Tφ(χ),Tφ(y))Pθ(y)dydx = J	R 1(x = y)Pθ(y)dydx = J	I(X = y)dx	= 1
and hence it is true that
PX (X)πφ(y | X)dX = Pθ(y).
Similarly, for (3) We have ʃp(y)∏φ(χ | y)dx = p(y) and can prove Jpθ(y)∏φ(x | y)dy =
PX(x) given these two conditions.	□
ProofofLemma 2. Since c(x, y) ≥ 0 by definition, we have Cφ,θ(μ → V) ≥ 0 and Cφ,θ(μ J V) ≥
0. When μ = ν, it is known that W(μ, V) = 0. If y 〜pθ(y) is equal to X 〜PX(x) in distribution,
which means PX(x) = pθ(x) andPX(y) = pθ(y) for any x, y ∈ RV and μ = V, then we have
CΦ,θ (μ → V)
Il
e-d(Tφ(x),Tφ(y))PX (X)Pθ(y)
J J c(X, y) R e-d(Tφ(x),Tφ(y))Pθ(y)dy d^y
/ /	e-d(Tφ(y),τφ(X))PX(y)Pθ(X)
c c c(y, X) R e-dT(y),TΦ(x))pθ(X)dX	y
/ /	e-d(Tφ(y),Tφ(X))Pθ (y)PX (X)
c c c(y, X) R e-d(Tφ(y),Tφ(x))PX(X)dX	y
e-d(Tφ(X),Tφ(y))PX (X)
J Jc(X，y)Pe(y) R e-d(%x),Tφ(y))PX(X)dXdXdy
ZZc
c(X, y)PX(X)πφ(y | X)dXdy
(X, y)Pθ(y)πφ(X | y)dXdy
CΦ,θ(μ J V)
and hence Cφ,θ (μ, V) = Cφ,θ (μ -→ V) = Cφ,θ (μ j- V) ≥ 0 = W (μ, V).
If e-d(Tφ(X),Tφ(y)) = 1(X = y), since c(X, X) = 0 by definition, we have
Cφ,θ (μ → V)= H	c(X,	y)	1(：	=	SPX (X)P； 丁	dXdy
1(X = y)Pθ (y)dy
=/ /	c(X,	y)I(X	=	y；X((X)pθ(y)	dXdy
= c(X, y)1(X = y)Pθ(y)dXdy
= Z c(X,X)Pθ(X)dX
= 0.
□
13
Under review as a conference paper at ICLR 2021
ProofofLemma 3. According to the strong law of large numbers, when M → ∞, VM (A)
M PM=11(yj ∈ A) converges almost surely to
1M
M Σ2Eyj〜pθ(y)[1(yj ∈ A)]
j=1
pθ(y)dy
A
ν(A)
and hence Cφ,θ(μ → VM) converges to Cφ,θ(μ → ν). Therefore, Ey 绫Pgg)[。6,。(μ → VM)]
converges to Cφ,θ(μ → V). Similarly, we can prove that as N → ∞, EW ^d⑺[Cφ,θ(μN J V)
converges to Cφ,θ(μ J V). Therefore, Cφ,θ(μ, ν, N, M) defined in (12) converges to 11 Cφ,θ(μ →
V) + 2Cφ,θ(μ J V) = Cφ,θ(μ, V) as N)M → ∞.	□
Proof of Lemma 4.
Cφ,θ (μ, V, N, M) = 2E	iid [ [ [Cφ,θ (μ → VM )] + 2E iid [ [ [Cφ,θ (μN J V)]
2 yiM 〜pθ(y)	2 xi：N 〜PX(χ)
=2E ( i iid [ [ [Cφ,θ(X → VM)] + 1E iid , , z ʌ [Cφ,θ (μN J y)]
2 X〜PX(χ), yi：：M 〜pθ(y)	2 xi：N 〜pχ(χ), y〜pθ(y)
=2Ex~pN(X)ExiMi⅛χ(x), yi：MiidPθ(y) [Cφ,θ(X → "m)]
+ 2Ey~pM(y)EXi：NiidPX (x), yi：Mi〜dPθ(y) [Cφ,θ (μN J y)]
=EX 〜PN (x), y 〜PM (y)Exi：Nifid pχ (x), yι Mi沿 Pθ (y) 1C Cφθ (X → VM ) + 2 Cφ,θ (μN J y)] . (18)
Plugging (8) and (10) into the above equation concludes the proof.
□
Proof of Lemma 5. Solving the first expectation of (18), we have
Cφ,θ (μ,V, N, M)
=Exi：NifdPX (x), yi：MiidPθ(y) h2N PN Cφθ (Xi → " + 2M PM Cφθ ("N J yj)] .
Plugging (8) and (10) into the above equation concludes the proof.
□
B S upplementary Experiment Results
B.1	Additional details for the univariate normal toy example shown in (17)
For the toy example specified in (17), exploiting the normal-normal conjugacy, we have an analytical
conditional distribution for the forward navigator as
(X - y )	C
∏φ(y | x) H e --2e^N(y; 0, e )
8N(x; y,eφ)N(y[0,eθ)
N
(eθ
(eθ + eΦ x,
eφeθ )
eθ + eφ )
and an analytical conditional distribution for the backward navigator as
πφ(x |y)
H e- 2eφ N(x; 0,1)
H N(y; x, eφ)N(x; 0, 1)
N
y	eφ	A
1 + eφ , 1 + eφ )
14
Under review as a conference paper at ICLR 2021
Plugging them into (2) and (3), respectively, and solving the expectations, we have
eφ	θ	eφ	2
Cφ,θ (μ → V)= Ex〜N(0,1) [eθ + eφ (e + . + eφ X /
=「似 +I
eθ + eφ eθ + eφ
Cφ,θ (μ J V) = Ey〜N(0,eθ)
eφ	eφ	2
1 + eφ (1 + 1 + eφ y )
$ eθ ).
eφ
1 + eφ
1+
Figure 8: For the univariate normal based toy example specified in (17), we plot the forward,
backward, and CT values against θ at four different values of φ, which show combining forward and
backward balances mode covering and seeking, making it easier for θ to move towards its optimum.
15
Under review as a conference paper at ICLR 2021
B.2	Analysis of conditional transport plans on 1D mixture
We consider a 1D example to illustrate the properties of the conditional transport plans of the
navigators, and analyze the risk for them to degenerate to point mass distributions when optimized
under the CT or ACT divergence. We consider two representative scenarios that both seem to pose a
high risk for the conditional transport distributions to degenerate. In the first scenario, we consider
both the source and target distributions as a mixture of a point mass and a Gaussian distribution,
where the location of the point mass and the center of the Gaussian are far away from each other; we
obtain the analytic forms of the conditional transport plans under the CT divergence, and analyze
the properties of the empirical conditional transport plans under the ACT divergence. In the second
scenario, we consider both the source and target distributions as discrete distributions; we make the
support of each distribution contain an outlier supporting point far away from all the other supporting
points. In this scenario, we are essentially learning how to transport between two discrete sets.
B.2. 1 Conditional transport between two point-mass-and-Gaussian mixture
DISTRIBUTIONS
Below we consider the first scenario, where we assume
pX (x) = ρδ-1 + (1 - ρ)N (-1000, 1)
and
pY (y) = ρδ1 + (1 - ρ)N (1000, 1),
where ρ ∈ [0, 1] is the probability for x = -1 and y = 1. We construct this specific example to check
whether there is a danger that the forward CT distribution π(y | x) will degenerate to a point mass
distribution that concentrates its probability mass at y = 1. Setting d(Tφ(x), Tφ(y))=(工，,Via
the definition of the conditional transport distributions and the property of the normal distribution, we
can show that
π(y | x,φ) =
ρr(y,X)	δ1 +
ρr(y,x) + 1 - P
1 - P
pr(y,x) + 1 -
~ρ N(μ,σ2),
r(y, x)
def. N(y; μ,σ2)
=N (y;1000,1)
μ def. 1000
eφ
1 + eφ + X1 + eφ ,
2 def. e
σ =	.
1 + eφ
(19)
1
Similarly, for the backward CT, we can show that
π(X | y,φ)
ρr0(y,χ)	δ +
Pr0(y, X) + 1 - P -1
_______1 - P_______
Pr0(y, X) + 1 - P
J =. N(X; "") , μ =.-1000上^ + y-ɪ-, σ2 =. -^--.
N(x; -1000,1),户	1 + eφ	y 1 + eφ ,	1 + eφ
(20)
As shown in the top panel of Fig. 9, it is clear that when φ → ∞, we haVe π(y = 1 | X) = P and
when φ → -∞, we haVe π(y = 1 | X) = 0. Assuming P = 0.01 and X = -1000, when φ = 15, we
haVe πφ(y = 1 | X = -1000) = 0.0157 and πφ(y = 1 | X = -1) = 0.0116; when φ = -1.095945,
we haVe πφ(y = 1 | X = -1000) = 0.0626 and πφ(y = 1 | X = -1) = 1. These analyses suggest
that as long the naVigator parameter φ is chosen appropriately, the conditional transport distributions
π(X | y, φ) and π(y | X, φ) will not degenerate to a point mass distribution.
Next we analyze the degeneration risk if using the ACT between pX (X) = Pδ-1+(1-P)N(-1000, 1)
and pY (y) = Pδ1 + (1 - P)N (1000, 1), in which case we assume we don’t know pX (X) and pY (y)
but can access random samples from them. In ACT, we would approximate π(y | X) with
πm(y|x) =.X -e~~2e".瓯，yj%PY(y).	QI)
j=ι PM=I e-ʒj
EVen if φ is set at a Value such that the forward CT distribution πφ(y = 1 | X) → 1, under ACT,
as long as 1 ∈/ {y1, . . . , yM}, X will surely not be transported to y = 1 and will instead be
transported to a yj that is drawn from N (1000, 1); note 1 ∈/ {y1, . . . , yM} happens with probability
QjM=1 P (yj 6=1)=(1-P)M,whichis as large as 36.6% when P = 0.01 and M = 100. Therefore,
mini-batch based optimization under the ACT diVergence would further reduce the risk for the
conditional transport plans to degenerate.
16
Under review as a conference paper at ICLR 2021
Conditional transport mapping π(y = l∣x= -1)
Conditional transport mapping π(y= l∣x= -1000)
Conditional transport mapping π(x= - l∣y= 1)
Conditional transport mapping π(x= - l∣y= 1000)
Figure 9: Top: The risk for the forward and backward conditional transport plans to degenerate
w.r.t. the value of φ based on CT analysis. Bottom: The forward conditional transport plan between
two discrete sets of S = 500 points; among the S data points, one point is an outlider. The ACT
navigators are optimized with SGD over mini-batches, whose elements are randomly sampled (with
replacement) from their corresponding discrete sets and the mini-batch size varies from 50 to 500.
B.2.2 ACT between two discrete distributions with outlier supports
Below we consider the second scenario, where we assume two discrete distributions supported on
S = 500 data points as
1 S- 1 -1
PX(X) = sδ-ι +	Xx iχ^,
i=1
where Xi iid N(-1000,1), and
1 S 1 S-1
PY(y) = Sδι + -ɪ 工 δy,
i=1
where yi 野 N(1000,1). In this scenario, we Win be optimizing the navigator parameters using SGD
over mini-batches, and apply the navigators optimized with a mini-batch size of N to calculate the
conditional transport plans between the two discrete sets of S = 500 data points. More specifically,
we use (14) as the loss to train the navigator parameter φ (note here both distributions are fixed
and there is no generator to train), with the mini-batch size set as N = M = 50, 200, 400, or
500. Each mini-batch consists of two sets of M data points iid drawn from their corresponding
discrete distributions (i.e., sampled without replacement from their corresponding discrete sets). With
the navigator parameter φ optimized under the ACT divergence, the bottom panel of Fig. 9 reports
the forward conditional transport plan from the Gaussian to PY, i.e., (π(y1 | X, φ), . . . , π(yS | X, φ)),
where X 〜N(—1000,1) and φ is learned with four different mini-batch sizes. There results suggest
that even though for two discrete distributions whose supporting points contain outliers, there is a
low risk for the conditional transport plans optimized under ACT to degenerate.
17
Under review as a conference paper at ICLR 2021
B.3	More results on 2D toy datasets
We visualize the results on the 8-Gaussian mixture and three additional 2D toy datasets. Compared to
the 8-Gaussian mixture dataset, the mode collapse issue ofboth GAN and WGAN-GP becomes more
severe on the Swiss-Roll, Half-Moon, and 25-Gaussian datasets, while ACT consistently shows good
and stable performance on all of them.
5k iters
IOk iters
15k iters
2Ok iters
25k iters
3Ok iters
True
z‹e
dqN4αM CIMS"1-no)h-o4
* ʌ
Figure 10: On a 8-Gaussian mixture data, comparison of generation quality and training stability
between two mini-max deep generative models (DGMs), including vallina GAN and Wasserstein
GAN with gradient penalty (WGAN-GP), and two mini-max-free DGMs, whose generators are
trained under the sliced Wasserstein distance (SWD) and the proposed ACT divergence, respectively.
The critics of GAN and WGAN-GP and the navigators of ACT are fixed after 15k iterations. The
first column shows the true data density.
z<e dqN4αM CIMS"1-no)h-o4
Figure 11: Analogous plot to Fig. 10 for the Swiss-Roll dataset.
18
Under review as a conference paper at ICLR 2021
z<e dqN<<5ΛΛ GΛΛS (号。)I-O4
Figure 12: Analogous plot to Fig. 10 for the Half-M∞n dataset.
N4(5dqN40MQΛΛS (gno)l-υ4
Figure 13: Analogous plot to Fig. 10 for the 25-Gaussian mixture dataset.
19
Under review as a conference paper at ICLR 2021
We also illustrate the data points and generated samples with empirical samples, shown in Fig. 14.
The first column shows the generated samples (marked in blue) and the samples from data distribution
(marked in red). To visualize how the feature extractor Tφ used by both navigators works, we set its
output dimension as 1 and plot the logits in the third and fifth columns and map the corresponding
data (in the second column) and generated samples (in the fourth column) with the same color.
Similarly, we visualize the GAN’s generated samples and logits produced by its discriminator in
Fig. 15. We can observe that the discriminator maps the data to very close values. Specifically, in
both the 8-Gaussian mixture and 25-Gaussian mixture cases, when the mode collapse occurs, the
logits of the missed modes have similar value to the those in the other modes. This property results in
GAN’s mode collapse problem and it is commonly observed in GANs. Different from the GAN case,
the navigator in our ACT model maps the data with non-saturating logits. We can observe in various
multi-mode cases, different modes are assigned with different values by the navigator. This property
helps ACT to well resist the mode collapse problem and stabilize the training.
IOOOOO-
IOOOOO-
7S0β0-
tSM0-
√
sβooo-
sβooo-
O.7S-
02S∙
UOOO
UOOO
-O4 -0Λ -oa tΛ 02 OA OΛ OΛ
UOOO
^x∙x
^x∙x
LSWO
L>4∞
10000
LOOOO
Otnmtta
-13 -1Λ -04 M Cs 1Λ
-1.0 -OS g OS 1Λ IS
Figure 14: Visual results of ACT for generated samples (blue dots) compared to real samples (red
dots) on Swiss Roll, Half Moons, 8-Gaussian mixture, and 25-Gaussian mixture. The second and
third columns map the data points and their corresponding navigator logits by color; The fourth and
fifth columns map the generated points and their corresponding navigator logits by color.
-iq -δs Ob 心


-«4 -0Λ -02 Ob Oa ΛΛ «4 «4
6
Iio
2⅛
3⅛
4⅛
SW
-Oa -t>2 oa 02 oλ o£ OA ιa



20
Under review as a conference paper at ICLR 2021
14»-
14»-
«.IS-
MS-
om-
3-
Φ2S-
0M-
08-
√
-OiS-
-OiS-
-0Λ-
-0Λ-
-0.7S-
-Ok
& -0Λ -0Λ Ob Oa 0Λ «« «4
OS-
0Λ∙
0Λ-
«3-
03-
02-
M-
0-1-
M-
-0.1-
-0-2-
-0Λ -02 Ob oa 6* «« «4 14
20-
13-
1Λ-
OS-
-M -0Λ -02 tΛ 02 OA 0Λ 0Λ
0∙2Sβ-
-M -Oi Ob Oi 6" «« «4 14
1Λ-
5Λ-	⅛
M- *
0»
-ix) ʤ Ob
-1Λ -β3 M Cs 1Λ
-1Λ -04 g OS 1Λ
ov>mtta
data
ov>tntvi
Figure 15: Visual results of GAN for generated samples (blue dots) compared to real samples (red
dots) on Swiss Roll, Half Moons, 8-Gaussian mixture, and 25-Gaussian mixture. The second and the
third columns map the data points and their corresponding discriminator logits by color; The fourth
and fifth columns map the generated points and the corresponding discriminator logits by color.

0S∙
Φta
o⅛wa⅛d
-«4 -0Λ -0a Ob Oa 0Λ «4 «4
«4M-
ΛMβ-
amt-
«4«2-
MS*-
«4M-

-ooca-
f∙βθ*.
7、》*-«、《2-心8YJlM-OZβγ"∙一θJtt2-OJtta
IΛ-
«2S«-
13-
21
Under review as a conference paper at ICLR 2021
B.4	Results for ablation study
Transport cost in pixel space vs. feature space We visualize the difference of using the transport
cost in the pixel space and in the feature space here. In both Figs. 16 and 17, we test with MNSIT and
CIFAR-10 data and with the L2 distance and cosine dissimilarity as the transport cost, respectively.
For the MNIST dataset, due to its simple data structure, ACT can still be trained to generate
meaningful digits, though some digits appear blurry. On the CIFAR-10, we can observe the model
fails to generate any class of CIFAR images. As the dimensionality of the input space increases,
using the distance in the pixel space as transport cost might lose the essential information for the
transport and increases the training complexity of the navigator.
Pixel-。: 2,7(IS)
PiXeI-£2:171.9 (FID)
夕 qJ
X7 / / 5
√ I / 7 7
1 / On ∖
OIIOO
/ I 夕 g 4
q。)”
0 17 3/
√
夕
7 73/
3q44GS4 3
O 319 G/3a
70 0 53gx1
1∕∕W3∕ΛΛSX
5/夕 gs/ / 7
s4>y夕，r∙2G
oɪsgɔ-lCxq
PiXeMoS:138.4(FID)
7 6

Figure 16:	Visual results of generated samples on MNIST and CIFAR-10 using pixel-wise transport
cost, with DCGAN (standard CNN) backbone.
Pixel-cos
PiXeH2
Pixel-cos
PiXeI-£2
ΓΓrΓΓΓΓΓ
i≡
ΓΓΓΓΓΓΓΓ
"
Figure 17:	Visual results of generated samples on MNIST and CIFAR-10 using pixel-wise transport
cost, with SNGAN (ResNet) backbone. The Inception and FID scores are not shown due to poor
visual quality.
PerceptuaI-ACT (initialization) PerceptuaI-ACT (fix aftertraining)
PerceptuaI-ACT (fix)
Perceptual-energy distance (fix)
6 3
0 4
X Q
5 O
β5 B
? q
o g
∕D6N∕6，£)
√7oe ∕r⅛ Γ~z)8 弓


I ΩD β S
4 2 M。夕，3
5^ q 5 O 2 a 3
q 0/ 6 3
3 Q S夕媪Jb
3 0，？	Q /	g
P 3	Q	G	OG。
夕 q	t	&
Figure 18:	Visual results of generated samples with the perceptual similarity (Zhang et al., 2018)
with four different training configurations.
We also consider using the perceptual similarity (Zhang et al., 2018) to define the cost function. Here
we test with four configurations: 1) Apply a fixed and pre-trained perceptual loss to calculate the
distance between the data and generated samples, use that distance as the point-to-point cost, and
calculate ACT to train the generator; 2) Apply a fixed and pre-trained perceptual loss to calculate
22
Under review as a conference paper at ICLR 2021
Table 2: FID comparison for ACT-DCGAN and ACT-SNGAN on CIFAR-10 with different cost and
architecture.
-Standard CNN-		L2 -pixel	transport cost c(x, y) cos-pixel L22-feature		cos-feature
Navigator cost	L22	171.9	138.4	27.1	24.8
d(Tφ(x),Tφ(y))	cos	157.9	136.2	25.3	25.0
-ResNet-		L22-pixel	transport cost c(x, y) cos-pixel	L22-feature		cos-feature
Navigator cost	L22	237.2	297.1	22.8	21.6
d(Tφ(x),Tφ(y))	cos	293.1	252.7	19.8	18.0
the energy distance between the data and generated samples to train the generator; 3) Apply the
pre-trained perceptual loss as cost and fine-tune with ACT to train the generator; 4) Apply the
pre-trained perceptual loss as cost, fine-tune it with ACT to train the generator, and then fix it for 20
more training epochs. We report the visual results of these 4 configurations in Fig. 18. As shown,
fixing the metric and calculate the distance (either ACT or energy distance) in the feature space
does not show good generation results. An explanation could be the pretrained perceptual loss is
not trained on the generation task and hence might not be compatible with the learning objective.
Thus the cost could not feedback useful signal to guide the generator. Using the energy distance
as in Bellemare et al. (2017) shows similar results. We further use the perceptual network as the
initialization of our critic Tη , and train with ACT by maximizing the cost for 40 epochs on MNIST,
which produce good-quality generations as shown in the third column. Then we fix the training of
this critic and train the generator for 20 more epochs, which lead to degraded generation quality. We
expect the generation quality will get worse as the training under the fixed critic continues.
Using alternative cost function We also test ACT with different configurations. As discussed in
previous sections, the defined cost may also affect the training of the model. Here we vary the choice
of transport cost cη (x, y) and the navigator cost d(Tφ(x), Tφ(y)). For both cost, we test with L22
distance and cosine dissimilarity. Moreover, we also compare the effects of distance in the original
pixel space and the feature space (equipped with critic Tη). The results in Table 2 highlight the
importance of the cost in the feature space when dealing with high-dimensional image data. Moreover,
compared to the L22 distance, the cosine dissimilarity is observed to improve the model when applied
as transport and navigator cost, especially with ResNet architecture.
Training the critic with the discriminator loss of a vanilla GAN Contrary to the existing critic-
based GANs, the sample estimates of ACT divergence and its gradient are unbiased regardless
of how well the critic is trained. We thus keep the same experiment settings and train the ACT-
DCGAN model’s critic with the discriminator loss of standard GANs, i.e. Ex〜Pd [- log(Tη (x)] +
Ex〜Pg [— log(1 — Tn(x))]. The results in Fig. 19 shows that ACT works well in conjunction with
the alternative critic training. The quantitative and qualitative on MNIST, CIFAR-10, CelebA, and
LSUN are shown in Fig. 19. We can observe the quality of generated samples, while clearly not as
good as training the critic with the ACT divergence, can still catch up with some of the benchmarks
in Table 1.
Inception Score: 8.3
FID:43.5
FID: 34.3
FID:39.4
Figure 19: Visual results of using a standard cross-entropy discriminator loss in lieu of ACT diver-
gence to train the critic of ACT.
23
Under review as a conference paper at ICLR 2021
B.5 More results on image datasets
For the experiments on the image datasets, we provide more visual results in this part. Apart from
the datasets described in the experiment part, we also test the capacity of single-channel image
generation with the MNIST dataset. Considering the inception score and the FID score are designed
for RGB natural images, we also calculate the inception score of the real testing sets for reference.
The presented methods are all able to generate meaningful digits on MNIST. If we take a closer look
at the digits, the digits generated with L2 cost is less natural than the one with cosine cost. Moreover,
we show both unconditional and conditional generation results on CIFAR-10. For both unconditional
and conditional generation, our proposed method achieves good quantitative and qualitative results.
DCGAN: 8.9
DCGAN+ACT-L2:8.9
DCGAN+ACT-cos: 9.1
Real: 9.8
x∙7∕3nlo 7¾∙
Ole>7 q %r6。
Gin/d3l?G
70 65/a 夕？
y⅛√a 7÷-∕∕,a
O 74 / 7G Y Oo
夕，7彳 4 05Q
37cx-98v}3/
Λ x∙4fo i。
o0A397sa
Q85∕d7q4
s7αNG 4
7976r3 7。
IWaDCrS)4A
r‰∕oo∕72
σ5ql
7GDzGΓ>0q
u73 S a ” ¢3
vbʃ-"夕 B23f
f*0o,z7 73 9
l.d W37夕 Z 2
37 5 9分，√s
Figure 20:	Unconditional generated samples and inception scores of MNIST, with DCGAN (standard
CNN) backbone.
DCGAN+ACT-N: 30.7
DCGAN+ACT-cos: 25.0
Real
DCGAN: 30.4
D ,蠹。G嚏ru
:三m
i⅛L⅛:上海
♦ Ti式海也串≠
、
国力r箝≡团金
au∙Q4 L
.,l"，‘一 ∙κ
Figure 21:	Unconditional generated samples and FIDs of CIFAR-10, with DCGAN (standard CNN)
backbone.
SNGAN (ResNet): 24.2
SNGAN (ReSNet)+ ACT-N: 22.7
SNGAN (ResNet) + ACT-cos:19.1
Figure 22: Unconditional generated samples and FIDs of CIFAR-10, with SNGAN (ResNet) back-
bone.
24
Under review as a conference paper at ICLR 2021
SNGAN (ResNet): 21.5
SNGAN (ReSNet) + ACT∙cos: 18.0
SNGAN (ReSNet)+ACT42:19.8
Figure 23: Conditional generated samples and FIDs of CIFAR-10, with SNGAN (ResNet) backbone.
Real	DCGAN: 52.5	DCGAN + ACT-L2:33.2	DCGAN + ACT∙cos: 29.2
Figure 24: Generated samples and FIDs of CelebA, with DCGAN (standard CNN) backbone.
Real
SNGAN: 21.7
SNGAN (ReSNet)+ ACT-L2:18.3
SNGAN(ReSNet)+ACT-cos: 11.3
Figure 25: Generated samples and FIDs of CelebA, with SNGAN (ResNet) backbone.
Real
DCGAN: 61.7
DCGAN+ ACM2:52.4
DCGAN+ACT∙cos: 37.4
Figure 26:	Generated samples and FIDs of LSUN, with DCGAN (standard CNN) backbone.
25
Under review as a conference paper at ICLR 2021
Real
SNGAN: 31.1
SNGAN(ReSNet)+ ACM2:29.5
SNGAN(ReSNet)+ACT-cos: 24.2
Figure 27:	Generated samples and FIDs OfLSUN, with SNGAN (ResNet) backbone.
26
Under review as a conference paper at ICLR 2021
B.6 Experiment Details
Preparation of datasets We apply the commonly used training set of MNIST (50K images, 28 × 28
pixels) (Lecun et al., 1998), CIFAR-10 (50K images, 32 × 32 pixels) (Krizhevsky et al., 2009), CelebA
(about 203K images, resized to 64 × 64 pixels) (Liu et al., 2015), and LSUN bedrooms (around 3
million images, resized to 64 × 64 pixels) (Yu et al., 2015). The images were scaled to range [-1, 1].
For MNIST, when calculate the inception score, we repeat the channel to convert each gray-scale
image into a RGB format.
Network architecture and hyperparameters For the network architectures presented here, the
slopes of all lReLU functions in the networks are set to 0.1 by default. For toy experiments, typically
10, 000 update steps are sufficient. However, our experiments show that the DGM optimized with
the ACT divergence can be stably trained at least over 500, 000 steps (or possibly even more if
allowed to running non-stop) regardless of whether the navigators are frozen or not after a certain
number of iterations, where the GAN’s discriminator usually diverges long before reaching that many
iterations even if we do not freeze it after a certain number of iterations. For all image experiments,
the output feature dimension of the navigators and that of the critic (i.e., Tφ(∙), Tn (∙) ∈ Rm) are set
to m = 2048. All models are able to be trained on a single GPU, such as NVidia GTX 1080-TI in
our experiments, with 150, 000 generator updates (for CIFAR-10 we apply 50, 000 iterations).
To keep close to the configuration of the DCGAN and SNGAN experiments setting, we use the the
Adam optimizer (Kingma and Ba, 2015) with learning rate α = 2 × 10-4 and β1 = 0.5, β2 = 0.99
for the parameters of the generator, navigators, and critic. On the DCGAN backbone, we let all
the modules update with the same frequency; while on the SNGAN backbone, the critic is updated
once per 5 generator updating steps. The performance might be further improved with more careful
fine-tuning. For example, the learning rate of the navigator parameter could be made smaller than
that of the generator parameter. The true data minibatch size is fixed to N = 64 for all experiments.
Moreover, with this batch-size we let the generated sample size M the same as minibatch size N for
ACT computation and we have monitored the average time for each update step on a single NVidia
GTX 1080-TI GPU: On CIFAR-10, each update step takes around 0.1s and 0.2s for DCGAN and
SNGAN, respectively; For DCGAN and SNGAN backbone trained with ACT divergence each update
step takes around 0.4s and 0.7s. On CelebA and LSUN, each update takes 0.6s and 0.7s for DCGAN
and SNGAN, respectively; when trained with ACT, the elapsed time for each update increases to 3.3s
and 3.6s, respectively.
Table 3:	Network architecture for toy datasets (V indicates the dimensionality of data).
(a) Generator Gθ	(b) Navigator Tφ / Discriminator Dφ
€ ∈ R50 〜N(0,1)	X ∈ RV
50 → 100, dense, IReLU	2 → 100, dense, IReLU
100 → 50, dense, lReLU	100 → 50, dense, lReLU
50 → V , dense, linear	50 → 1, dense, linear
27
Under review as a conference paper at ICLR 2021
Table 4:	DCGAN architecture for the CIFAR-10 dataset (h = w = 4).
(a) Generator Gθ
e ∈ R128 〜N(0,1)
128 → 4 × 4 × 512, dense, linear
4 X 4, Stride=2 deconv. BN 256 ReLU
4 × 4, Stride=2 deconv. BN 128 ReLU
4 × 4, stride=2 deconv. BN 64 ReLU
3 × 3, Stride=1 conv. 3 Tanh
(b) Navigator Tφ / Critic Tη
「「 3 3 3 32 × 32 × 3
X ∈ [-1,1]________________
3	X 3, stride=1 Conv 64 IReLU
4	× 4, Stride=2 conv 64 lReLU
3 X 3, stride=1 Conv 128 lReLU
4 X 4, Stride=2 conv 128 lReLU
3 X 3, stride=1 Conv 256 lReLU
4 X 4, Stride=2 Conv 256 lReLU
3 X 3, stride=1 conv. 512 lReLU
h X w X 512 → m, denSe, linear
Table 5: DCGAN arChiteCture for the CelebA and LSUN dataSetS (h = w = 4).
(a) Generator Gθ	(b) Navigator Tφ / CritiC Tη
e ∈ R128 〜N(0,1)	r 6 1 -∣64×64×3 	X ∈ [-1,1]	
128 → 4 X 4 X 1024, denSe, linear 4 X 4, stride=2 deconv. BN 512 ReLU	4 X 4, stride=2 Conv 64 lReLU 4 X 4, Stride=2 Conv BN 128 lReLU
4 X 4, stride=2 deconv. BN 256 ReLU	4 X 4, stride=2 Conv BN 256 lReLU
4 X 4, stride=2 deconv. BN 128 ReLU	3 X 3, stride=1 Conv BN 512 lReLU
4 X 4, stride=2 deconv. BN 64 ReLU	h X w X 512 → m, denSe, linear
3 X 3, Stride=1 Conv. 3 Tanh
Table 6: ReSNet arChiteCture for the CIFAR-10 dataSet.
(a) Generator Gθ	(b) Navigator Tφ / CritiC Tη
e ∈ R128 〜N(0,1)	「「 3 3 3 32 × 32 × 3 X ∈ [-1,1]
128 → 4 X 4 X 256, denSe, linear	ResBlock down 128
ResBlock UP 256	ResBlock down 128
ResBlock UP 256	ResBlock 128
ResBlock UP 256	ResBlock 128
BN, ReLU, 3 X 3 conv, 3 Tanh	ReLU
Global Sum pooling
h = 128 → m, denSe, linear
28
Under review as a conference paper at ICLR 2021
Table 7: ResNet architecture for the CelebA and LSUN datasets.
(a) Generator Gθ	(b) Navigator Tφ / Critic Tη
e ∈ R128 〜N(0,1)	r 6 6 -∣ 64 × 64 × 3 X ∈ [-1,1]	
128 → 4 × 4 × 1024, dense, linear	ResBlock down 128
ResBlockUP 512	ResBlock down 256
ResBlock up 256	ResBlock down 512
ResBlock up 128	ResBlock down 1024
ResBlock up 64	ReLU
BN, ReLU, 3 X 3 conv, 3 Tanh	Global sum pooling
h = 1024 → m, dense, linear	
Table 8: ResNet architecture for the LSUN-128 dataset.
(a) Generator Gθ	(b) Navigator Tφ / Critic Tη
e ∈ R128 〜N(0,1)	r 6 6 -∣ 64 × 64 × 3 X ∈ [-1,1]	
128 → 4 × 4 × 1024, dense, linear	ResBlock down 128
ResBlock up 1024	ResBlock down 256
ResBlock up 512	ResBlock down 512
ResBlock up 256	ResBlock down 1024
ResBlock up 128	ResBlock 1024
ResBlock up 64	ReLU
BN, ReLU, 3 × 3 conv, 3 Tanh	Global sum pooling
h = 1024 → m, dense, linear
Table 9: ResNet architecture for the CelebA-HQ dataset.
(a) Generator Gθ	(b) Navigator Tφ / Critic Tη
e ∈ R128 〜N(0,1)	r 6 6 -∣ 64 × 64 × 3 X ∈ [-1,1]	
128 → 4 × 4 × 1024, dense, linear	ResBlock down 128
ResBlock up 1024	ResBlock down 256
ResBlock up 512	ResBlock down 512
ResBlock up 512	ResBlock down 512
ResBlock up 256	ResBlock down 1024
ResBlock up 128	ResBlock 1024
ResBlock up 64	ReLU
BN, ReLU, 3 × 3 conv, 3 Tanh	Global sum pooling
h = 1024 → m, dense, linear
29