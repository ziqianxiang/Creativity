Under review as a conference paper at ICLR 2021
Simulation of Human and Artificial Emotion
(SHARE)
Anonymous authors
Paper under double-blind review
Ab stract
The framework for Simulation of Human and Artificial Emotion (SHArE) de-
scribes the architecture of emotion in terms of parameters transferable between
psychology, neuroscience, and artificial intelligence. These parameters can be de-
fined as abstract concepts, as with structural equation modeling or granularized
down to the voltage levels of individual neurons. This model enables emotional
trajectory design for humans which may lead to novel therapeutic solutions for
various mental health concerns. For artificial intelligence, this work provides a
compact notation which can be applied to neural networks as a means to observe
the emotions and motivations of machines.
1 Introduction
Emotion has been characterized through the use of basic emotions, categorical theory, componential
theory, and higher-dimensional models. [1] These models face the trade-off between simplicity and
accuracy of representation. Moreover, many of these models require the definition and tuning of
parameters outside of those contained in the existing agent under consideration. However, the tools
necessary to represent emotion with high-fidelity in simple terms exist in the agents themselves.
In a space which contains all weights and biases of an agent’s mind, motion from one point to
another is commonly called learning. Therapy and guided emotion design [2] correspond to the
emotion-specific case of learning. Therefore, the process of affect improvement can be considered
as a trajectory design problem. In order to design such trajectories, such a space must first be
constructed and the connection to emotions, established. Fortunately, convergence of the fields of
natural language processing [3, 4], sentiment analysis [5, 6], and emotion recognition [7, 8] has
allowed for a deeper understanding of the nature and causes of human emotion.
In contrast, the field of artificial intelligence overflows with examples of detection and production
of human affect [9-11], but uncharted potential still remains for the exploration of the mental state
and emotions of artificially-intelligent machines themselves. The well-established mathematics of
artificial intelligence provides a solid foundation for exploration.
~
V
S
D«
J・
C・
~
M
t
Figure 1: The agent’s processing system in a given environment.
Upon observation of a sufficient number of trajectories, principles of traversal dynamics can be
postulated. For example, to predict when an apple will hit the ground, a deep neural network trained
with a large data set containing pictures of apples at various points of descent will likely arrive at the
correct answer with high accuracy. Alternatively, Newton’s formulation of gravitation will likely
yield a similar result for the computational cost of a few multiplication and addition operations.
In general, many analytical formulations have been discovered through the observation of specific
parameters and analysis of the interaction between those parameters.
1
Under review as a conference paper at ICLR 2021
In the same spirit of simplicity, this work considers an agent which perceives an external stimulus (S)
produced by its environment (M). (Figure 1) This external stimulus, following classification (C), is
represented as a internal stimulus (s) in the agent,s mind. This internal stimulus is then evaluated
in the judgment (J) stage to determine whether the stimulus is helpful or harmful in terms of the
core values (v) of the agent. Following this appraisal, the agent makes a decision (D) and performs
an action (α). The action of the agent, and other agents, on the environment generates new external
stimuli and the process repeats. The agent’s interaction with its environment is thus described as
a =(D ◦ J ◦ C )(1)	(1)
where the environment generates stimuli as follows
S = M (a)	(2)
From this, an agent,s emotion can be represented by three components: degree of perception (∆s),
valence (ηi,c), and perceived correlation (ρi,j).
These variables can be used to analytically study trends based on relative differences between values
defined, even if the exact values characterizing a psychological condition are not known. Moreover,
this framework can be extended beyond the functionally-defined networks presented to represent
traditional brain circuits by projecting stimuli and appraisals into bases corresponding to the appro-
priate cortices. The variables in the following sections are described briefly as to not restate the body
of literature which is available.
To provide the initial foundation, in this work, the static case is considered.
2	Perception
Perception begins with the detection and vectorization of stimuli. This is followed by classification
and appraisal. The classification and judgement neuroware, i.e. network models, will be considered
at a fixed time in the following sections. However, the dynamic case can be considered to determine
how these networks evolve over time through the use of traditional methods for machine learning
and reinforcement-based learning. A single unit of neuroware approximates the concept of a meme,
whether a weight or a bias, as in Figure 2, or a partial derivative of the associated functions, as
considered later.
Figure 2: Neuroware illustration: Weights and biases of the output layer of an MNIST digit classifi-
cation network. Positive and negative values are blue and red respectively with saturation and size
indicating magnitude.
2.1	Stimulus (S)
Stimuli (D initiate the process of perception. The term stimulus response (s(n)) is given to the
output of a neuron layer, but this response itself can be considered a stimulus for the next layer. A
stimulus value can correspond to abstract properties such as the distance between two individuals
or to the response of a specific neuron to a specific cone in a specific eye of a given individual. In
the case of the latter, a more complete model can be created from such a recording as with research
at Neuralink [12], but depending on the purpose of the application, the level of detail in the former
may be sufficient. Equation 3 shows the general vector form ofa stimulus. For ease of presentation,
each element amplitude is the inner product of the vector representation of a known concept and a
perceived stimulus. During implementation, information can be compressed to a more minimal basis
depth for the representation of perceived stimuli. The natural language processing field provides the
tools necessary for this process. Basis elements can be used to construct prototypes in the simple
case and statistical ensemble techniques provide a means of analyzing exemplars.
1= X ∣Sni1n	(3)
n
2
Under review as a conference paper at ICLR 2021
Stimuli are considered in relation to a reference bias to determine emotional trajectory. Stimulus se-
quence is a key factor in that given the case of a family member living (reference bias) and a family
member being dead (stimulus), the emotional response to the trajectory of the family member dying
differs from the response to a family member coming back to life. The stimulus-space representa-
tion of the zero vector |0i in core value space, discussed later, is considered as the reference bias
(sref) for the scope of this work for simplicity. However, this can be extended to non-zero biases
by considering the quantities defined here with respect to the resultant quantities. The difference
between the reference state and the current state is the degree of perception (∆si).
Si = hsi |s
δSi = hsi|(s - Sref)
(4)
(5)
Real stimuli, manifest variables which can be measured directly, are denoted by & while S indicates
internal stimulus responses conceived by the agent. In general, a perceived stimulus within the as-
sociation horizon of a known stimulus will be associated with the known stimulus. Consequently,
an agent’s stimulus space constellation may detect a stimulus where two stimuli conceptually over-
lap. (Figure 3) As such, learning results in effective quantization of real world stimuli in terms of
sufficiently proximal internal stimuli with a certain degree of confidence.
Pasta
Figure 3: Stimuli: "eat," "homework," and proximal concepts in stimulus space. The association
horizons of the first two are denoted by dotted lines.
2.2	CLASSIFICATION (C(n))
The classification function (C(n)) projects a stimulus from its representation in one perception layer
(S(n-1)) to the next (S(n)). This process is visualized in Figure 4.
s(n)
Cs)(SST))
X ∣sjn)iσjn)(Wj(n) ∙ SST) + bjn))
j
(6)
Multi-layer classification, i.e. mapping from one category to another, can thus be written using
successive composition as follows:
n
k=1
(7)
3
Under review as a conference paper at ICLR 2021
Figure 4: Example classification network with internal stimuli labeled.
n
Q c (k) = c (n) ◦... ◦ C ⑵◦ C ⑴	⑻
k=1
S⑼三S	(9)
2.2.1	FOCUS
A finite number of objects can be considered in working memory for appraisal at a given moment.
This ablity to focus is represented by modulation of the classification weights and bias along the j
axis as a group. This is the link between arousal and degree of perception.
2.2.2	PERCEIVED CORRELATION (ρi,j)
Perceived correlation is the association of two stimuli in the same layer. Assuming recurrence, a
stimulus (Si) in a given layer may have influenced the detection of another stimulus (Sj) in the current
layer. Without recurrence, all stimulus excitations in a given layer are perceived as coincident, but
not necessarily related. However, if detection of one stimulus excites the perception of another, this
implies perceived correlation.
∂Sj
ρi,j =师	(IO)
Perceived correlation is defined in Equation 10 as the effective relative change associating stimulus
Sj with stimulus Si , given its presence (Si0) in a previous layer.
2.3	JUDGEMENT (J)
The judgement function (J), as presented in Equation 11, is responsible for the estimation of core
value fulfilment with respect to the presence of a given internal stimulus.
J(S) = X ∣Vciσc(Wc ∙ S + bc)	(11)
c
2.3.1	CORE VALUES (V)
The core value vector is defined as the last layer of stimulus response prior to the decision to perform
an action. Core values can be conceptual, e.g. autonomy, aesthetic, status, community well-being
or more physical, e.g. the state of a single pain receptor in the thumb of the left hand. This vector
parallels cost and reward optimization in machines and is key in terms of determining what the agent
is able to detect and judge in its environment. In essence, an agent trained to recognize cats may
not be general-purpose, not because it is not able, but because it sees no need. In humans, selection
of the value bases is often due to culture, i.e. correlations in the neuroware of a given population.
Formation and reinforcement of core values are further explored in other works. [13, 14]
4
Under review as a conference paper at ICLR 2021
V = E ∣vjvc = (J ◦ C)(S)
c
(12)
2.3.2	VALENCE (ηi,c)
The parameter ηi,c represents the valence ofa stimulus (si) as perceived by the agent under consider-
ation with respect to core value vc. Stimuli may include inanimate stimuli, other agents, or the agent
under consideration itself. The incorporation of multi-agent and high-association-radix interactions
may allow for a more detailed perspective and evaluation of higher-order emotions. However, for
the scope of this work, it is sufficient to estimate the net effect of these interactions as the subset
presented. The definition of first-order valence is shown in Equation 13.
∂vc
ηi,c =国
(13)
2.3.3	PERCEIVED VALENCE (γi)
Perceived valence (toward stimulus i), is defined as the perceived core value response to two stimuli
and a given trajectory, given a certain degree of perception of stimulus i.
Yi = X |vci dvc δSi = X MJniQSi
dsi
(14)
For each core value, amplitude of the change in value fulfilment is defined as follows:
Yi,c = hvc lYi
(15)
The valence of the agent under consideration as perceived by an external agent can often be related
to the valence (ηi,c) of the external agent as perceived by the agent under consideration through the
use of an influence function [15].
⑻	(b)	(C)
Figure 5: Sentiment maps for (a) guilt, (b) fear, and (c) anger. Positive, neutral, and negative
valence are indicated by blue, black, and red outlines, respectively. Positive and negative degree of
perception are indicated by solid and dashed outlines, respectively.
c
c
2.4	Emotion
Emotion, in the realm of perception, is an ultra-fast appraisal ofa given stimulus. Basic emotions, as
presented by Ekman et al [16] (Table 1), are approximated here as shown in Table 2. The case of sur-
prise is considered later. The table considers one core value for simplicity of presentation. Positive
and negative signs are used without explicit values to indicate flexibility of use with the multitude
of scales available for these parameters. [15, 17, 18] In essence, emotions are considered as regions
defined by the null clines of the core value vector space (ηi,c = 0) considered in conjunction with
the degree to which a certain object is perceived (∆Si) and its correlation with other stimuli (ρi,j).
Extension to multi-stimulus emotions, e.g., anger, envy, leverages the addition of coupling terms
which imply perceived correlation of stimuli. Sentiment maps representing the contents of Table 2
are shown in Figure 5. A graphical representation of the interaction between the model factors is
shown in Figure 6.
5
Under review as a conference paper at ICLR 2021
Table 1: Several emotions as defined by Ekman et al. [16]
Emotion	Description
Fear	“The response to the threat of harm, physical or psychological”
Sadness	“The response to the loss of an object or person to which you are very attached.”
Disgust	“Repulsion by the sight, smell, or taste of something; disgust may also be pro- voked by people whose actions are revolting or by ideas that are offensive.”
Happiness	“Feelings that are enjoyed, that are sought by the person. There are a number of quite different enjoyable emotions, each triggered by a different event, involving a different signal and likely behavior”
Anger	“The response to interference with our pursuit of a goal We care about. Anger can also be triggered by someone attempting to harm us (physically or psycho- logically) or someone We care about”
-Guilt-	“The response when a person regrets having violated an agreement, principle, or value”
Table 2: Parameter states for various emotions. Positive and negative signs indicate the sign of the
parameter relative to a reference stimulus.
	Self		Stimulus 1			Stimulus 2	
	Worth	Eff.	VaL	Deg.	Corr.	VaL	Deg.
Emotion	αc	βc	ηι,c	∆sι	P1,2	η2,c	∆S2
Fear		0	-	+			
Sadness		0	+	-			
Disgust			-	-+-			
Happiness	+	+	+	+			
Anger			-	+	-	+	-
Guilt	-						
2.4.1 Self Worth (α)
Self esteem is considered, for the scope of this work, as comprising self worth and self efficacy. Self
worth (Equation 16) is defined as the core value response to self-associated stimuli. Due to the self-
associative nature of this parameter, the loss ofa favorite team or an insult directed toward a family
member may be felt depending on the degree of attachment as characterized by the association
weights of the classification and judgement functions. [19, 20] This parameter can be considered in
a context similar to perceived valence in which the only difference is the direction of perception, i.e.
toward self or externally-directed.
Self worth, for the scope of this work, is considered as a vector with elements which represent
evaluations of self (stimulus s0) with respect to each core value.
α
Xlvci 孩δS0
c
(16)
For each core value, the amplitude of self-associated change in value fulfilment is:
ac = hvc∣α
(17)
2.4.2 EFFICACY (f)
Efficacy (Equation 18) is defined as the ability ofan agent to generate a stimulus given an action.
Zn=X ㈤ ∂∂ai "n
i
(18)
6
Under review as a conference paper at ICLR 2021
Figure 6: The relationship between parameters presented.
Self-efficacy is the agent’s perception of its own efficacy.
(19)
2.4.3 Relative Self Efficacy (β)
Relative self efficacy (Equation 20) is defined as the core value response to the agent’s perception
of its ability (s-1) to act on its environment and generate a desired stimulus. in the case of relative
self efficacy, the agent considers its perception of its own actions (s-1) relative to the actions of all
other forces in the environment (s-1,ref). The classification function determines the agent’s ability
to differentiate between its own actions and the actions of other forces in its environment. For a
planning example, this stimulus may be a coefficient representing the agent’s characterization of its
environment which it uses to throttle its action on its environment in order to achieve a goal.
β=X lvci ∂svcι δs-1
c-
(20)
βc = hvc∣β	(21)
The presence of a given stimulus is seldom a core value in and of itself. However, an agent can learn
to deeply associate stimuli and responses and form heuristics for core values. [21] if a given stimulus
set is heavily associated to a given core value, the stimulus will be pursued as if it is the core value
itself. consequently, if the heuristic records a high valence for a proxy stimulus for which an agent
perceives itself to have low efficacy, this could potentially contribute to a state of anxiety. Where
valence and self worth metrics are lower across the board, this may present itself, in conjunction
with other factors, as depression. in contrast, a high relative self efficacy to efficacy ratio due to
poor configuration of the perception weights is shown by the Dunning-Kruger Effect.
in general, the equations present provide a concise method of representing human emotion for the
purpose of expediting the process of treatment discovery. For example, if desiring to boost low self
esteem due to low relative self-efficacy, Equation 19, Equation 20, and Equation 22 present many
avenues. The agent can change its actions (∆a0), change its focus (C), change What it believes
about the stimuli in focus (J), learn the skill better (f。)，change its goals (Vref), or change its envi-
ronment (M). Similar densely-packed conclusions can be seen from the other equations. HoWever,
although these conclusions can be seen from a static perspective, trajectory design for modification
of the functions and parameters lies in the realm of dynamics. For further exploration of neuroWare
applications in psychology, see Appendix A.
V = (J ◦ C ◦ M)(①	(22)
7
Under review as a conference paper at ICLR 2021
3	Action
3.1	DECISION (D)
The decision function contains the agent’s policies for action. The Q function, as seen in rein-
forcement learning, can be represented by the composed functions in the cycle between action and
appraisal.
3.2	ACTION (a)
Action can be the expenditure of money, attention, energy, time, social capital, health, or some other
resource or, in a more directly biological sense, the excitation of a motor neuron. Actions (a) in
this model are generated with decision function (D), which depends on an agent’s decisiveness (σi),
priorities W, core values (V) and biases (bi) (Equation 23). This function drives the observed parts
of personality.
D(V) = X ∣ao,iiσi(Wi ∙ v + bi)	(23)
i
Each action (<⅛,i) exists in the total set of channels through which the agent can act ®). Note, for
cases in which the agent is the only actor on the system, i.e. a = ⅛3, the subscript can be omitted.
a.0 = X αo,i∣ao,ii = D(v)	(24)
i
In the case presented by Keltner, Kogan, et al. [22], when the core value benefit Bact is greater
than a threshold cost Cact, an agent engages in some prosocial behavior. For detailed derivation, see
Appendix B.
a = a0,1 |a0,1i
= σ(	Wc,1vc + b1)|a0,1i
c	(25)
=	1|a0,1i for Bact > Cact
0|a0,1i otherwise
Indecision arising from dilemma is the case in which actions are evaluated through the lens of two
or more core values and conflict occurs in the decision and activation process or where the perceived
benefit fluctuates above and below the action threshold. Similar conflict can occur during activation
of opposing signals in core value space. This is known as cognitive dissonance, where ∂v1 < 0.
4	ENVIRONMENT (M)
The environment function represents all factors external to the agent under consideration, e.g. the
laws of physics, social norms, and the thoughts and feelings of other individuals. Certain agent-
environment boundary nuances are considered later.
n
M = O M(k) = M⑺。...◦ M⑵◦ M⑴	(26)
k=1
The agent’s environment exists as a representation of the exchange of stimuli and actions to and
from the agent. The agent is implicitly interacting with two environments: its real environment and
its perception of this environment.
8
Under review as a conference paper at ICLR 2021
4.1	REAL ENVIRONMENT (M)
4.1.1	Physical Interaction
The real environment function represents the environment in which the agent exists. This function
can contain different laws of physics, other agents, or other factors with which the agent interacts.
For example, given a time step ∆t and assuming no air drag, the scenario of Sir Isaac Newton’s
perception of an apple falling can be characterized by the following environment function (Equation
28). In this particular case, the feedback of the system is considered as the action vector.
S = a(t + ∆t) = M (a(t)) = M α(t)
(27)
ΓX01	1
S = X 0 =	∆t
一[x0」	1∕2(∆t)2
0
1
∆t
x0
X o
x0
(28)
0
0
1
4.1.2	Emotional Interaction
Interaction of one agent with another can be characterized by coupling the decision function of the
agent to the perception function of another agent and vice versa as shown in Figure 7. This is to, in
effect, consider an external agent to be the environment of the agent under consideration.
Figure 7: Interaction between two agents.
Emotion is transferred by way of the senses. In the case of communication between humans, the
transfer mechanisms typically include prosody, body language, facial expressions, and word choice.
So(t + ∆t) = ⅛0,1(t) = roso(t) + I1,0(s1(t)) + bjo
(29)
Sι(t + ∆t) = a1,1(t) = ri sι(t) + Io,ι(so(t)) + bjι	(30)
Affect trajectory analysis for two agents can be written in the form seen in Equation 29 and Equation
30, which parallels the formulation postulated by Gottman et al. [15] with I1,o defined accordingly
to account for the influence of stimulus S1 on the agent. See Appendix C for detailed derivation.
However, degeneracy exists in the original model in that many emotional states could produce the
same final action. Moreover, the same scalar result in experiment may lead to different actions. This
framework, with its fully vectorial form, extends to higher dimensions of emotion and decision.
9
Under review as a conference paper at ICLR 2021
4.2	PERCEIVED ENVIRONMENT (MP)
The perceived environment is the approximation of the real environment function with which the
agent believes itself to be interacting. Divergence of this environment from the real environment
function may relate to dementia and schizotypal disorders.
While the agent may not possess control over space and time or the ability to predict the future
in the real environment, experience often generates expectations which are captured by the local
derivatives (spatial or temporal) of the perceived environment function. The predicted state of the
core value projection with the highest likelihood is known as an expectation. The emotion known
as surprise is characterized by deviation of the real environment’s effect on the core value projec-
tion from the expectation. The degree of surprise is directly correlated to the degree of deviation
of these values. Avoidance of parts of reality where steep negative emotional trajectories are pre-
dicted may approximate a trauma response in humans and machines. Where the real environment
function provides feedback, this corresponds to reinforcement learning. Where the perceived envi-
ronment function provides feedback, this corresponds to planning. It follows then that this feedback
process can be indirectly hijacked to inject neuroware into an agent. See Appendix D for ethical
considerations.
4.3	Rewards (S)
Rewards in this model, as with reinforcement learning, are taken to be stimulus appraisals which are
believed to be associated with a perceived action. [23]
5	Conclusion
Emotions presented in this model depend on core value derivatives with respect to perceived stimuli
in conjunction with stimulus associations and degree of perception. In general, action on a system
generates a stimulus.
S = M (a)	(31)
This external stimulus is then classified as a internal stimulus.
S = C③
(32)
This internal stimulus is then appraised by an agent.
V =(J ◦ C )(S)
(33)
This appraisal leads to action.
a = (D ◦ J ◦ C )d)
(34)
The action then results in the generation of new stimuli. Emotion can then be mapped onto a basis
set characterized by three types of parameters. Valence results from the evaluation of a stimulus
with respect to a given core value.
∂vc
ηi,c =匹
Perceived correlation accounts for the association of stimuli.
∂Sj
Piij =匹
Degree of perception determines effective arousal.
δSi = hsi| (S - Sref)
(35)
(36)
(37)
With a lower degree of detail, this framework approximates interaction of an agent with concep-
tual prototypes. With finer detail, this model can be granularized down to the level of neurons.
Moreover, with the use of neural networks in this model, emotions of existing AIs can be directly
computed without the definition and tuning of additional parameters. This may lead to considera-
tions for ethical treatment of AI agents. The definition of emotions as proposed makes provision
for higher-order emotions than those commonly considered, which provides additional flexibility in
designing treatment plans for patients. Principally, the static case presented lays the foundation for
emotion architecture dynamics and the observation and design of emotional trajectories in human
and artificial agents.
10
Under review as a conference paper at ICLR 2021
References
[1]	Thomas M. Moerland, Joost Broekens, and Catholijn M. Jonker. “Emotion in reinforcement
learning agents and robots: a survey”. en. In: Machine Learning 107.2 (Feb. 2018), pp. 443-
480.
[2]	Asma Ghandeharioun, Daniel McDuff, Mary Czerwinski, and Kael Rowan. “EMMA: An
Emotion-Aware Wellbeing Chatbot”. In: 2019 8th International Conference on Affective
Computing and Intelligent Interaction (ACII). Cambridge, United Kingdom: IEEE, Sept.
2019, pp. 1-7.
[3]	Jeffrey Pennington, Richard Socher, and Christopher Manning. “Glove: Global Vectors for
Word Representation”. en. In: Proceedings of the 2014 Conference on Empirical Methods in
Natural Language Processing (EMNLP). Doha, Qatar: Association for Computational Lin-
guistics, 2014, pp. 1532-1543.
[4]	Kyunghyun Cho et al. “Learning Phrase Representations using RNN Encoder-Decoder for
Statistical Machine Translation”. en. In: Proceedings of the 2014 Conference on Empirical
Methods in Natural Language Processing (EMNLP). Doha, Qatar: Association for Computa-
tional Linguistics, 2014, pp. 1724-1734.
[5]	Yoon Kim. “Convolutional Neural Networks for Sentence Classification”. en. In: Proceedings
of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP).
Doha, Qatar: Association for Computational Linguistics, 2014, pp. 1746-1751.
[6]	Matthew Peters et al. “Deep Contextualized Word Representations”. en. In: Proceedings of the
2018 Conference of the North American Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, Volume 1 (Long Papers). New Orleans, Louisiana:
Association for Computational Linguistics, 2018, pp. 2227-2237.
[7]	R. Chinmayi, G. Jayachandran Nair, Mantha Soundarya, D. Sai Poojitha, Gayathri Venu-
gopal, and Jishnu Vijayan. “Extracting the features of emotion from EEG signals and classify
using affective computing”. In: 2017 International Conference on Wireless Communications,
Signal Processing and Networking (WiSPNET). Chennai: IEEE, Mar. 2017, pp. 2032-2036.
[8]	William G. Christ. “Voter Preference and Emotion: Using Emotional Response to Classify
Decided and Undecided Voters1”. en. In: Journal of Applied Social Psychology 15.3 (May
1985), pp. 237-254.
[9]	Jun Yang, Rui Wang, Xin Guan, Mohammad Mehedi Hassan, Ahmad Almogren, and Ahmed
Alsanad. “AI-enabled emotion-aware robot: The fusion of smart clothing, edge clouds and
robotics”. en. In: Future Generation Computer Systems 102 (Jan. 2020), pp. 701-709.
[10]	Yu Luo, Jianbo Ye, Reginald B. Adams, Jia Li, Michelle G. Newman, and James Z. Wang.
“ARBEE: Towards Automated Recognition of Bodily Expression of Emotion in the Wild”.
en. In: International Journal of Computer Vision 128.1 (Jan. 2020), pp. 1-25.
[11]	Meng-Ju Han, Chia-How Lin, and Kai-Tai Song. “Robotic Emotional Expression Generation
Based on Mood Transition and Personality Model”. In: IEEE Transactions on Cybernetics
43.4 (Aug. 2013), pp. 1290-1303.
[12]	Elon Musk and Neuralink. “An Integrated Brain-Machine Interface Platform With Thousands
of Channels”. en. In: Journal of Medical Internet Research 21.10 (Oct. 2019), e16194.
[13]	R.E. Nordquist, P. Voorn, J.G. de Mooij-van Malsen, R.N.J.M.A. Joosten, C.M.A. Pennartz,
and L.J.M.J. Vanderschuren. “Augmented reinforcer value and accelerated habit formation
after repeated amphetamine treatment”. en. In: European Neuropsychopharmacology 17.8
(July 2007), pp. 532-540.
[14]	Ariel Knafo and Shalom H. Schwartz. “Identity formation and parent-child value congru-
ence in adolescence”. en. In: British Journal of Developmental Psychology 22.3 (Sept. 2004),
pp. 439-458.
[15]	John Gottman, Catherine Swanson, and Kristin Swanson. “A General Systems Theory of
Marriage: Nonlinear Difference Equation Modeling of Marital Interaction”. en. In: Personal-
ity and Social Psychology Review 6.4 (Nov. 2002), pp. 326-340.
[16]	Paul Ekman and Daniel Cordaro. “What is Meant by Calling Emotions Basic”. en. In: Emo-
tion Review 3.4 (Oct. 2011), pp. 364-370.
[17]	Chetashri Bhadane, Hardi Dalal, and Heenal Doshi. “Sentiment Analysis: Measuring Opin-
ions”. en. In: Procedia Computer Science 45 (2015), pp. 808-814.
11
Under review as a conference paper at ICLR 2021
[18]	Sanne Schoenmakers, Markus Barth, Tom Heskes, and Marcel van Gerven. “Linear recon-
struction of perceived images from human brain activity”. en. In: NeuroImage 83 (Dec. 2013),
pp. 951-961.
[19]	Laura Germine, Taylor Leigh Benson, Francesca Cohen, and Christine I’Lee Hooker.
“Psychosis-proneness and the rubber hand illusion of body ownership”. en. In: Psychiatry
Research 207.1-2 (May 2013), pp. 45-52.
[20]	Paul M. Jenkinson and Catherine Preston. “New reflections on agency and body ownership:
The moving rubber hand illusion in the mirror”. en. In: Consciousness and Cognition 33 (May
2015), pp. 432-442.
[21]	Amos Tversky and Daniel Kahneman. “Judgment under uncertainty: Heuristics and biases.”
In: Science 185.4157 (1974). Place: US Publisher: American Assn for the Advancement of
Science, pp. 1124-1131.
[22]	Dacher Keltner, Aleksandr Kogan, Paul K. Piff, and Sarina R. Saturn. “The Sociocultural
Appraisals, Values, and Emotions (SAVE) Framework of Prosociality: Core Processes from
Gene to Meme”. en. In: Annual Review of Psychology 65.1 (Jan. 2014), pp. 425-460.
[23]	Chris L. Baker, Rebecca Saxe, and Joshua B. Tenenbaum. “Action understanding as inverse
planning”. en. In: Cognition 113.3 (Dec. 2009), pp. 329-349.
A	Neuroware Applications
Each stimulus leads to a classification (S = C(s)), each classification leads to a judgement (V =
J(s)), and eachjudgement leads to a decision (a = D(v)). All layers of this collection of networks
have associated weights and biases.
For simplicity, consider a set of social norms which stipulate that for every stimulus, there is an
expected classification which is associated with an expected judgement which merits a specific ac-
tion. In such a context, given a three-layer neural network, the matrices which define the standard
of normalcy (Figure 8(a)) would be diagonal matrices, implying a 1:1 association from one layer to
the next. Mild background weights and biases account for the potential for priming based on the
presentation of other stimuli.
a= (D ◦ J ◦ C )(α)	(38)
It is worth noting that similar states could produce the symptoms described, i.e. these states are
not the only such states which can produce these symptoms, but rather, are samples in a larger set.
Moreover, these illustrations provide a means of producing symptoms externally, but more in-depth
medical research is necessary to determine the internal states and dynamic transitions characterizing
these conditions.
A.1 Schizophrenia
In the abnormal case of the classification matrix, to encounter one stimulus and believe it to be
another is to hallucinate, whether by exposure to a drug which tunes the bias levels or by the inher-
ent wiring of the network. This off-diagonal feature is seen in the classification matrix of Figure
8(b)(C). In the judgement matrix, which indicates the perceived accomplishment of a certain goal,
an off-diagonal element implies the correlation of a desired goal to a stimulus which is unrelated
according to social norms. This is typically called delusion and is shown in the judgement matrix of
Figure 8(b)(J). In the decision matrix, off-diagonal elements correspond to the evaluation of stimuli
followed by the pursuit of a different course of action than socially expected given a certain value
excitation. The absence of on-diagonal elements in many areas implies the failure to perform ex-
pected actions while performing unexpected actions. Within the context of this framework, when
a high degree of efficacy is realized, this is often called creativity. This deviation from the norm is
shown in the decision matrix of Figure 8(b)(D).
A.2 Depression
With trouble focusing, a slight modulation of the classification elements may occur, but without
hallucinatory symptoms, the classification matrix remains relatively similar to that of the direct-
12
Under review as a conference paper at ICLR 2021
correlation case. (Figure 8(c)(C)) In judgement, a negative bias in the network gives rise to unful-
filled values or unmet needs. Low-magnitude weights further limit the ability of outside influence
to overcome this bias. (Figure 8(c)(J)) Similarly, the negative bias in the decision matrix lowers the
desire to act and the low-magnitude weights limit the ability of the internal state to drive action.
(Figure 8(c)(D))
A.3 Psychopathy
With lower background values for off-diagonal weights in the classification matrix, a network is
less susceptible to priming and is more calculating. (Figure 8(d)(C)) With one associated core value
which is affected by the outside world, outside stimuli are most readily seen as means to fulfill this
value and not in their expected context. (Figure 8(d)(J)) Moreover, when these values are processed,
either the action taken as a result of stimuli considered in the context of an abnormal value is not
expected or due to a lack of correlation between some values and actions, certain expected actions
are not executed at all. (Figure 8(d)(D))
A.4 OCD
High-intensity, off-diagonal elements in the judgement matrix (Figure 8(e)(J)) can cause an agent to
judge one stimulus as if it was another even if lucidity is maintained, i.e. the classification matrix
remains directly correlated. (Figure 8(e)(C)) The feeling of processing one element with the same
emotional intensity as if it were another while in an improper context tends toward obsession. Ac-
tion triggered by high-intensity weighting on the action matrix with improper context tends toward
compulsion. (Figure 8(e)(D))
B	Prosocial Action
The case of an agent executing a prosocial action is considered, assuming two core values and a
single action. Given an agent faced with a decision to act or not act in a way which potentially
benefits itself (Vself = Bself) and/or another agent (Vother = K ∙ Brec). This implies empathy
represented by the retention of a section of neuroware which is able to evaluate stimuli in terms of
the values of the other agent. The judgement function introduces the agent’s reaction to this outcome
in the form of the K term which serves as the η parameter.
The benefit with respect to the core values following prioritization is shown in Equation 42 as a
generalized case of the model presented by Keltner, Kogan, et al. [22] D0 accounts for biases for or
against the action which are agnostic of the recipient, Bself is the perceived benefit to self, Cinact
is the cost of inaction, K describes the relationship between the recipient and the agent, Brec is the
perceived benefit to the recipient, and Bact is the net benefit of the action. For the case of a binary
activation function, the action becomes the quantity shown in Equation 43.
W =[M0 ∙ D0	M0]	(39)
Vself
Vother
b = M0 ∙ (D0 + Cinact)
Bact =	WciVc + bi
c
=M 0 ∙ (D0 ∙ (I + Bself) + K ∙ Brec + Cinact)
(40)
(41)
(42)
13
Under review as a conference paper at ICLR 2021
DJC
,..W*:
(A)	∖
.∙.
(b)
.∙.
(c)
(d)
(e)
Figure 8: The neuroware of several agents: weights and biases of the classification, judgement, and
decision network layers for example cases which resemble (a) direct correlation, (b) schizophrenia,
(c) depression, (d) psychopathy, and (e) OCD. Weights are shown as matrices and biases are shown
as the last column of each matrix. Positive and negative values are blue and red respectively with
saturation and size indicating magnitude.
14
Under review as a conference paper at ICLR 2021
When the core value benefit is greater than a threshold cost Cact, the agent engages in some prosocial
behavior.
a = α0,1 |a0,1i
= σ(	Wc,1vc + b1)|a0,1i
c	(43)
=	1|a0,1 i f or Bact > Cact
0|a0,1 i otherwise
C Emotional Interaction
Consider a two-neuron classification layer which has a weight matrix
W = r00 10	(44)
and a bias
be = [0]	(45)
The activation function of the first neuron is a transparent function (multiplication by one) and the
activation function of the second neuron is a function I1,0. The judgement layer is considered to
have a transparent activation function with the addition of a bias term bJ0 representing processing
with respect to a single core value.
Given a stimulus
s0
Si
(46)
and the assumption that the stimulus perceived contains the total system state, the output of the
judgement function would be
V0 = ro⅛0 + Iι,o(sι) + bj 0	(47)
With a transparent decision function, the agent executes an action through a single actuator
说,1 = vo	(48)
The stimuli which result from feedback are the agent’s perception of its own mood in Equation 49
and the agent’s perception of the expression of the other agent’s mood.
So(t + ∆t) = ɑo,i(t)
(49)
si(t + ∆t) = ɑi,i(t) = ri si(t) + Io,ι(so(t)) + bji	(50)
D Ethical Considerations
In the dynamics realm, there exist sequences of stimuli, i.e. experiences, which can grow the diam-
eter of the association horizon of a given stimulus. Beyond a certain degree of belief aggregation,
other stimuli are sufficiently associated with it such that the agent’s actions are largely a reaction to
this stimulus. When considering a stimulus with a negative correlation to the other elements of self
worth (α) and relative self efficacy (β), traversal of its association horizon by a sufficient number
internal stimuli often results in suicide. Conversely, there exist sequences of stimuli which can de-
crease the relative diameter ofa stimulus association horizon or increase the diameter of others such
that the relative effect of a given stimulus is lessened. These value-formation and value-dilution
sequences can be used to treat patients or to efficiently train neural networks.
With the potential for malicious or exploitative sequences, machines which are constantly learning
may require security patches which account for the potential injection of toxic correlations. For
stability, community votes on the policies of safety-critical or judicial AIs, may help remove bias
from networks purely trained on past examples.
15
Under review as a conference paper at ICLR 2021
In the dynamic case, generative adversarial techniques may be useful in expanding the range of
stimuli with which an agent can cope. The therapeutic case may present an efficient method for the
incremental treatment of trauma. Beyond this, the discovery of rectification circuit architecture may
lead to the design of neuroware which is resilient to negatively-valenced stimuli.
Work remains for the optimal design of stimuli which, upon perception, produce actions and reac-
tions which, when perceived, are detected as the original stimuli produced. Further study of this
self-replicating behavior with this framework may clarify the nature of such eigenstimuli, i.e. habit
triggers, and psychoimmunostatic viruses. Work in socioimmunodynamics may present avenues for
the creation of treatments which mutate and evolve to keep pace with viruses in a given population.
These possibilities may require great care to ensure ethical treatment of agents under consideration.
16