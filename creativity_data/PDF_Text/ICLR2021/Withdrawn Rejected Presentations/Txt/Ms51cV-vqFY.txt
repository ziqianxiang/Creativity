Under review as a conference paper at ICLR 2021
Meta-Semi:	A Meta-learning Approach for
Semi-supervised Learning
Anonymous authors
Paper under double-blind review
Ab stract
Deep learning based semi-supervised learning (SSL) algorithms have led to
promising results in recent years. However, they tend to introduce multiple tun-
able hyper-parameters, making them less practical in real SSL scenarios where the
labeled data is scarce for extensive hyper-parameter search. In this paper, we pro-
pose a novel meta-learning based SSL algorithm (Meta-Semi) that requires tuning
only one additional hyper-parameter, compared with a standard supervised deep
learning algorithm, to achieve competitive performance under various conditions
of SSL. We start by defining a meta optimization problem that minimizes the loss
on labeled data through dynamically reweighting the loss on unlabeled samples,
which are associated with soft pseudo labels during training. As the meta problem
is computationally intensive to solve directly, we propose an efficient algorithm to
dynamically obtain the approximate solutions. We show theoretically that Meta-
Semi converges to the stationary point of the loss function on labeled data under
mild conditions. Empirically, Meta-Semi outperforms state-of-the-art SSL algo-
rithms significantly on the challenging semi-supervised CIFAR-100 and STL-10
tasks, and achieves competitive performance on CIFAR-10 and SVHN.
1	Introduction
The recent success of deep learning in supervised tasks is fueled by abundant annotated training data
(Krizhevsky et al., 2012; Simonyan & Zisserman, 2014; Szegedy et al., 2015; LeCun et al., 2015;
He et al., 2016; Huang et al., 2019). However, collecting precise labels in practice is usually very
time-consuming and costly. In many real-world applications, only a small subset of all available
training data are associated with labels (Oliver et al., 2018; Verma et al., 2019). Semi-supervised
learning (SSL) is a learning paradigm that aims to improve model performances by simultaneously
leveraging labeled and unlabeled data (Zhu et al., 2003; Chapelle et al., 2006; Turian et al., 2010).
In the context of deep learning, many successful SSL methods incorporate unlabeled data by per-
forming unsupervised consistency regularization (Laine & Aila, 2016; Tarvainen & Valpola, 2017;
Miyato et al., 2018; Verma et al., 2019; Berthelot et al., 2019). In specific, they first add small per-
turbations to the unlabeled samples, and then enforce the consistency between the model predictions
on the original data and the perturbed data. Though impressive performance has been achieved, the
state-of-the-art consistency based algorithms tend to introduce multiple tunable hyper-parameters.
The final performance of the algorithms is usually conditioned on setting proper values for these
hyper-parameters. However, in real semi-supervised learning scenarios, hyper-parameter searching
is usually unreliable as the annotated data are scarce, leading to high variance when cross-validation
is adopted (Oliver et al., 2018). This problem will become even more serious if the performance
of the algorithm is sensitive to the hyper-parameter values. Furthermore, since the searching space
grows exponentially with respect to the number of hyper-parameters (Bergstra & Bengio, 2012), the
computational cost may become unaffordable for modern deep learning algorithms.
Another challenge to develop practical and robust deep SSL algorithms is how to exploit the labeled
data more efficiently, as these data, although being scarce, have the precise and reliable annotations.
Consistency based SSL algorithms (Laine & Aila, 2016; Tarvainen & Valpola, 2017; Miyato et al.,
2018; Verma et al., 2019; Berthelot et al., 2019) usually model the labeled and unlabeled data in sep-
arate terms in the loss function, where the unlabeled data receives no supervision, at least explicitly,
from the former, leading to an inefficient use of the labeled data.
1
Under review as a conference paper at ICLR 2021
In this paper, we propose a meta-learning based SSL algorithm, named Meta-Semi, to efficiently ex-
ploit the labeled data, while requiring tuning only one additional hyper-parameter to achieve impres-
sive performance under various conditions. The proposed algorithm is based on a simple intuition:
if the network is trained with correctly “pseudo-labeled” unannotated samples, the final loss on
labeled data should be minimized. To be specific, we start by explicitly defining a meta reweighting
objective: finding the optimal weights1 for different pseudo-labeled samples to train a network, such
that the final loss on labeled data is minimized. Note that the problem is computationally intensive
to be directly solved via optimization algorithms. Therefore, we propose an approximated formula-
tion, based on which a closed form solution can be obtained. We show theoretically that one meta
gradient step is sufficient to obtain the approximate solutions at each iteration. Finally, we propose
a dynamical weighting algorithm to reweight pseudo-labeled samples with 0-1 weights. Theoretical
analysis shows that our method converges to the stationary point of the supervised loss function.
Our algorithm is empirically validated on widely used image classification benchmarks (CIFAR-10,
CIFAR-100, SVHN and STL-10) with modern deep networks (e.g., CNN-13 and WRN-28). Meta-
Semi outperforms state-of-the-art SSL algorithms, including ICT (Verma et al., 2019) and MixMatch
(Berthelot et al., 2019), on the challenging CIFAR-100 and STL-10 SSL tasks significantly, while
achieves slightly better performance than them on CIFAR-10. Besides, Meta-Semi is complementary
to consistency based methods, i.e., performing consistency regularization in our algorithm further
improves the performance. Moreover, sensitivity test on the only tunable hyper-parameter of Meta-
Semi shows that the algorithm is quite robust to different hyper-parameter values.
2	Related Work
Consistency based semi-supervised learning has been extensively studied in the context of deep
learning in recent years (Sajjadi et al., 2016; Laine & Aila, 2016; Tarvainen & Valpola, 2017; Miyato
et al., 2018; Verma et al., 2019). These methods leverage unlabeled data by adding an unsupervised
regularization term to the standard supervised loss: LS + wLUS, where LS is the conventional loss
on labeled data, LU S is the loss contributed by unlabeled data which is usually defined as a measure
of discrepancy between the model predictions on the original unlabeled samples and their perturbed
counterparts, and w is a pre-defined coefficient. Existing approaches have proposed different ways
to generate the perturbations for LUS, including data augmentation (Bachman et al., 2014; Laine &
Aila, 2016; Sajjadi et al., 2016), adversarial noise (Miyato et al., 2018), Dropout (Park et al., 2018),
data interpolation (Verma et al., 2019), etc. To enhance the model stability, an exponential mov-
ing average (EMA) on parameters or predictions is often adopted (Laine & Aila, 2016; Tarvainen
& Valpola, 2017). The effectiveness of these approaches is conditioned on the proper setting of
the coefficient w. As recent methods (Berthelot et al., 2019; 2020) usually integrate multiple regu-
larization techniques, finding the proper hyperparameter setting becomes a challenging problem in
practice, especially in SSL scenarios where few samples are available for cross-validation.
Other semi-supervised learning algorithms. Early work on SSL can be categorized into cluster
assumption based methods (Joachims, 2003; 1999) and graph assumption based methods (Zhu et al.,
2003; Bengio et al., 2006). For deep learning based SSL, (Kingma et al., 2014; Odena, 2016)
propose to train deep generators using both the labeled and unlabeled data to estimate the data
distribution. Pseudo label based method (Lee, 2013) is also widely used in deep SSL. It progressively
uses the highly confident model predictions to generate pseudo labels for unlabeled samples during
training. Minimizing the entropy of the model prediction on unlabeled data is also proven effective
for SSL (Grandvalet & Bengio, 2005; Miyato et al., 2018).
Meta learning. Since Meta-Semi follows a meta-learning paradigm, we briefly review the existing
work on this topic. The idea of meta-learning is motivated by the goal of ‘learning to learn better’
(Lake et al., 2017; Andrychowicz et al., 2016). Meta-learning algorithms usually define a meta
optimization problem to extract information from the learning process. For example, using the loss
on a small amount of trustable data as the meta-objective is widely adopted in few-shot learning
(Ravi & Larochelle, 2017; Ren et al., 2018a). MAML (Finn et al., 2017) proposes to minimize the
meta loss directly via gradient descents. To address the challenge that naively minimizing the meta
objective requires performing multiple meta update steps iteratively for every ‘real’ update step on
model parameters, (Ren et al., 2018b) propose an online approximation method to make the meta
training process more tractable. The proposed algorithm is similar to that in (Ren et al., 2018b), but
1Throughout the paper, the term “weights” always refer to the coefficients that we use to reweight each
individual unlabeled sample, instead of referring to the parameters of neural networks.
2
Under review as a conference paper at ICLR 2021
our contributions lie in several important aspects. First, we exploit the labeled data more efficiently
in SSL by leveraging the meta-reweighting method, which not only reduces the required number of
tunable hyper-parameters, but also effectively improves the performance. As far as we know, this
idea has not been explored in the literature. Second, we propose a novel dynamical re-weighting
process that is tailored for SSL. This is non-trivial since directly applying the method in (Ren et al.,
2018b) to SSL leads to inferior results (see: Table 1). Third, we provide a theoretical convergence
analysis in the context of SSL, which utilizes different proof techniques from (Ren et al., 2018b).
3	Method
In this section, we introduce the details of our Meta-Semi algorithm. Different from most exist-
ing methods that leverage unsupervised consistency regularization, we propose to solve the SSL
problem in a meta-learning paradigm. As an overview, we first compute the cross-entropy loss of
unlabeled samples using their corresponding pseudo labels. Then we reweight the loss on each unla-
beled sample by solving a meta optimization problem that minimizes the supervised loss of labeled
samples. As directly solving the meta problem is computationally intractable, we propose an ap-
proximation method to dynamically obtain the 0-1 approximate solutions, which only requires one
meta gradient descent step. In addition, theoretical guarantees are provided to show that our method
converges to the stationary point of the supervised loss.
3.1	Meta Optimization Problem
We start by presenting the weighted loss function of our method, and defining a meta optimization
problem to determine the value of the weight for each unlabeled sample.
Suppose that the networks are trained with stochastic gradient descent (SGD). At each iteration, we
sample a mini-batch of labeled samples X = {(xi, yi)} together with a mini-batch of unlabeled
samples U = {(uj, y)j)}, where Xi and yi represent the ith labeled sample and its associated ground
truth label, respectively, and Uj and y^j represent the jth unlabeled sample and its pseudo label, re-
spectively. Following earlier work (Verma et al., 2019; Berthelot et al., 2019), we use the MixUp
augmentation (Zhang et al., 2018) to generate a mixed version of the inputs to improve the gener-
alization performance, instead of directly using X and U. The augmented mini-batch of training
samples are denoted by X = {(xi, y∕} and U = {(uj, yj)}. We defer the details on generating
pseudo labels and obtaining X and U to Section 3.3.
Consider training a deep network with parameters θ. We first feed an unlabeled sample Uj into the
network, producing its predictionP(Uj ∣θ). Then We calculate the cross-entropy loss L(yj∙,p(Uj∙ ∣θ))
using the corresponding soft pseudo label yj∙. The loss of this sample is further reweighed by
Wjj ∈ [0, 1] to construct the final loss function
Lmeta = —≈1—
P∖U∖ wj
j=1 j
Without loss of generality, we assume Lmeta
~
∣-^∖u∖
Ej=IWjL(yj,p(U j lθ)).
,,
(1)
I7∕l
0 when Pj=I Wj = 0. The weight scalar Wj is
determined by minimizing the meta loss on the labeled data. To illustrate that, we first consider
training the network with a similar weighted loss
i77i
θj(w) = arg min X∖u∖, WjL(yj ,p(Uj Ie)),	⑵
θ	j=1
where θj (w) is the optimal solution that minimizes the weighted loss. Obviously, it is a function
of the weight vector w = [W1, W2, . . .]T. Then the weights wj is solved by minimizing the loss on
labeled data X with θj (w), namely
wj =	argmin	1 L(yi,P(Xi∣θ*(w))).
i1
Wj ∈[0,1],j=1,…,∖U∖
(3)
Intuitively, our aim is to find a subset of pseudo-labeled samples, which, if used for training, are
the most beneficial in terms of the generalization performance. The labeled data are leveraged to
determine if each pseudo-labeled sample should be used, instead of directly being used for train as
most existing SSL algorithms do (Laine & Aila, 2016; Tarvainen & Valpola, 2017; Miyato et al.,
2018; Verma et al., 2019; Berthelot et al., 2019). We argue that this is a more effective approach to
exploit the supervision information.
3.2	Approximating the Meta Solution
To solve the meta optimization problem Eqs. (2) and (3) efficiently, we introduce a method to
obtain an approximate solution. At tth step in the training process, consider estimating θj (w) by
3
Under review as a conference paper at ICLR 2021
performing M times of gradient descents starting from current values of network parameters θt :
θM ≈ θ*(W), θ0 = θt,
d Pj=I WjL(yj ,p(U jlθJ)
∂θtm
,m = 0, 1, . . . , M - 1,
(4)
(5)
where αt is the learning rate. As SGD has proven to be effective for optimizing deep networks, θM
is a reliable alternate of θ* (W) as long as M is sufficiently large.
Given that θ*(w) can be estimated by θM, a naive method of approximating w* is to further esti-
mate the gradient VwPiXIL(yi,p(X∕θ*(w))) with θM, and then repeatedly update W following
similar gradient based optimization algorithms. However, it is computationally intensive to do that
since updating W for N times requires MN steps of gradient descents on the network parameters.
To get a efficient estimate of W*, we propose a dynamic approximation approach in the following.
First, to reduce the iterations of updating w, we exploit a first order Taylor approximation of Eq. (3)
at w = 0:
W*≈ arg min WT
wj ∈[0,1],j=1,...,∣UV∣
∂ PiXI L(y,,p(Xi BM))
∂w
(6)
w=0
t
Notably, θM is obtained using the gradients of the weighted loss according to Eq. (5), and thus it is
differentiable with respect to wj . As the optimization objective in Eq. (6) is linear, it is straightfor-
ward to derive the solution:
I1
wj* ≈ wjt =
III0
∂ Pi=1 L(yi,p(Xi∣θM))
dwj
d Pi=I L(yi,p(Xi∣θMD
dwj
≤0
w=0
(7)
>0
w=0
where wjt denotes the approximate solution of wj*. The required steps of gradient descents are
reduced to M from MN by leveraging Eq. (7). However, the algorithm is still inefficient since a
large M is necessary to get a sufficiently accurate θM. To further reduce the computational cost, an
intriguing property can be leveraged. In the following proposition, we show that the results of Eq.
(7) will remain the same if θM is replaced by θ1. In other words, Eq. (7) can be precisely solved
using θ1 instead of θM, and the former only needs one gradient descent step to obtain.
Proposition 1. Suppose that θM is given by M steps of gradient descents starting from θ0 = θt.
Then we have
__ I -VI	.	. .—t ..
d Pi=I L(y”P(X八θM))
w=0
Proof. See Appendix A.
Γ   I -v I	—t
∂ PiXI l® ,p(Xi∣θι))
,∀ 1 ≤j≤∣U∣.	(8)
w=0
With Proposition 1, we are ready to present the final form of our dynamically reweighting for-
mula:
∂ Pi=1 L(y”P(Xi ∣θ1))
wj =∣
III0
dwj
≤0
w=0
Vl
d Pi=I L(yi,p(xi ∣θI))
dwj
>0
w=0
(9)
As we leverage a meta learning approach to reweight different pseudo-labeled samples, we call our
method Meta-Semi. The pseudo code of Meta-Semi is presented in Algorithm 1. In summary, after
each standard forward step of the pseudo-labeled samples, we first update the parameters with the
loss of all samples weighted by zero. Such a meta updating step does not change the values of
parameters, but construct a differentiable computational graph. Then we calculate the supervised
loss on labeled data, and exploit the computational graph to take the derivative of the supervised
loss with respect to the zero weight, which is called “meta gradient”. Finally, we only use the
pseudo-labeled samples with negative meta gradients to train the network.
Interpretation of meta gradients. A straightforward way to interpret the meta gradients is that
it can be viewed as the influence on the supervised loss when the weight of certain pseudo-labeled
M
□
4
Under review as a conference paper at ICLR 2021
Algorithm 1 The Meta-Semi Algorithm.
1： Initialize: θ0
2: for t = 1 to T do
3： Randomly sample X, U
4：	Generate X, U	〜
5：	Compute P(Uj∙ ∣θt), Uj∙ ∈ U
6:	W — 0, θ0 — θt
∂ P 巴 Wj L(yj,p(u j∣θt))
7：	vθ04--------------∂θt---------
8： θi J θo — at V^t
9：	Compute p(xi∣θ1), Xi ∈ X
10： Meta Gradient: Vj d Pi=I LdwMxi lθ1))
11： wt J sign(max(-Vtw , 0)) (Eq. (9))
-1	__ ∖7^i I	,	,	.	.	.、
12：	LmetaJ ^U	t Pj = I WjL(Jj ,p(U jlθ ))
j =1 wj
13：	θ(t+1) J θt - at dLmta
14： end for
TrajeCtoryof θ.
Average gradients of labeled samples.
. Gradients used for updating θ (w = = 1).
・ ■其・ A Gradients abandoned (呜` =0).
Figure 1： Illustration of Meta-Semi. Herein,
VL(uj) and VL(Xi) denote Vθt L(y^j ,p(uj ∖θt))
and VθtL(Ji,p(Xi∖θt)), respectively. Ourmethod
trains the networks using pseudo-labeled samples
with similar gradient directions to labeled samples.
sample changes slightly around zero during training. In fact, there exists a more intriguing and
interesting interpretation. The meta gradients given in Eq. (9) can be expressed as
∂ PiXI Ly ,p(x i ∣θ 1))
∂wj
w=0
∂ PiXI Ly ,p(x i ∣θ1))-
∂ θ 1	_
w=0
T
αt『P巴L(yi,p(xi∣θ ))	∂Ly,p(uj∣θ D
(10)
which follows from N-^t = PjU=IWkdL(yk ,p(uk lθ0)) and θ1 = θ0 = θt. For the pseudo-unlabeled
sample (Uj∙, yj∙), its meta gradient is negatively proportional to the inner product of the average gra-
dient of labeled samples and the gradient produced by itself. In other words, the sign of the meta
gradient indicates whether the angle between the former and the later is larger than 90 degrees. In-
tuitively, if the pseudo label is correct, the corresponding gradient should guide the model towards
a similar direction to the labeled samples, or at least should not be largely different from the su-
pervised gradient in direction. In essence, Meta-Semi trains networks using pseudo-labeled samples
whose gradient directions are similar to labeled samples. An illustration is shown in Figure 1.
3.3	Implementation Details
Pseudo labels. To obtain high quality pseudo labels for the original unlabeled mini-batch U , we first
apply an exponential moving average (EMA) on model parameters, which has proven to be effective
in providing supervision on unlabeled data (Tarvainen & Valpola, 2017; Verma et al., 2019). Then
we feed every unlabeled sample uj in U into the EMA model, and take the corresponding softmax
prediction as the soft pseudo label yj∙.
MixUp augmentation is an important regularization technique used by state-of-the-art deep SSL
algorithms (Verma et al., 2019; Berthelot et al., 2019). It improves the generalization performance
of models by encouraging the ‘convex’ behavior between different samples. Given a pair of sam-
ples with corresponding annotations (x1, y1) and (x2 , y2), MixUp is performed to generate an
augmented sample via linear interpolation：
X = λxι + (1 — λ)x2,	y = λyι + (1 — λ)y2,
(11)
where λ is sampled from a pre-defined Beta distribution. In Meta-Semi, we leverage MixUp to
generate the mixed training data X and U. Formally, X is obtained from only the labeled set X ：
X = MiXUP(X, ShUffle(X), λ1), λ1 〜Beta(β, β),	(12)
where β is the parameter of the Beta distribution, and it is the only tunable hyper-parameter (exclud-
ing the hyper-parameters of a supervised learning algorithm) in our algorithm. With regards to U,
5
Under review as a conference paper at ICLR 2021
4
3
2
1
0
Epoch	EpOch	EpOch	Epoch
口 ∙	。口 ∙ ∙	1 IT t∙ fA	1	1 Th 1 fEχ, U k%Lmetak2 ∙ f. … t bf ■ ■
Figure 2: Empirical validation of Assumption 1. The value of X,U ； P 八 is estimated at each training
k%tEχ G (X ,θ ) k
epoch using Monte-Carlo sampling with a sample size 500. Results on CIFAR-10 (C10) and CIFAR-100
(C100) with varying numbers of labeled samples are presented. It can be observed that the ratio generally
increases before the 500th epoch, but gradually becomes stable or even decreases in the last part of the training
process when the learning rate approaches 0. Therefore, it is reasonable to assume that Assumption 1 holds.
we ideally want the unlabeled data to extract more information from the labeled samples. Therefore,
we first concatenate X and U together, and then apply the MixUp procedure:
~. ,. .. ..................... . .. , . ... . , .
U = MixUp(W, Shuffle(W), λ2), W = Concat(X,U), λ2 〜Beta(β, β),	(13)
where the one-hot ground truth labels are used for X and the soft pseudo labels are used for U .
Compatibility with consistency based methods. As a matter of fact, Meta-Semi is compatible with
existing consistency based algorithms, and they can be integrated when necessary. To see this, the
regularization term can be simply appended to the loss function with an addition coefficient w:
L
Lmeta + wLconsistency.
(14)
In experiments, we show that although Meta-Semi has already achieved state-of-the-art performance,
its performance is still able to be significantly improved by integrating consistency regularization.
3.4	Convergence Analysis
In this section, we show theoretically that under some mild conditions, our method converges to the
stationary point of the loss on labeled data. To make it clear, we first define the supervised loss on
the labeled mini-batch X:	∣χ∣
G(X, θt)= X'	L(yi,p(Xi∣θt)).	(15)
i=1
Thus, the expected loss on all the labeled data is EXG(X, θt). Then We introduce the definition
of Lipschitz-smooth and a mild assumption stating that the expected norm of gradients used for
updating model parameters will not get too large compared with the gradient of the supervised loss.
Definition 1. A function f : Rn→R is said to be Lipschitz-smooth with constant L if
kVf(x) -Vf(y)k ≤ LIlx - yk, ∀x,y ∈ Rn.
Assumption 1. For all t ≥ 0, there exists a positive scalar σ, such that
Eχ,Uk%tLmetak2≤ σ∣∣%tEXG(X, θt)k2.
In fact, the assumption is not very strong. Roughly, since Lmeta is computed using the ground truth
labels and the pseudo labels based on the prediction of the EMA model, it is usually very close to the
minima of the loss function, especially when the networks tend to be stable with sufficiently large t.
Empirically, we show that Assumption 1 holds in many cases of SSL, which is shown in Figure 2.
Under this condition, the following proposition shows that our method converges to the stationary
point of the loss on labeled data with proper learning rate schedules.
Proposition 2. Assume that the loss function on labeled data G(X, θt) is Lipschitz-smooth with
regards to θt for all X, and that Assumption 1 holds. Suppose also that the learning rate at > 0
satisfies:
∞
lim αt = 0,	αt = ∞.
t→∞
(16)
t=0
Then every limit point of the sequence {θt} generated by Meta-Semi is a stationary point of
一	…二一工、	.
EXG(X, θt), namely,
lim ∣∣X¾tEXG(X,θt)k=0.
t→∞	X
Proof. See Appendix B.
□
6
Under review as a conference paper at ICLR 2021
Table 1: Performance of Meta-Semi and state-of-the-art SSL algorithms with the CNN-13 network. We report
the average test errors and the standard deviations of5 trials. In each setting, the best two results are bold-faced.
Dataset	CIFAR-10	CIFAR-100
Number of Labeled Samples	1000	2000	4000	4000	10000
Supervised	39.95 ± 0.75% 27.67 ± 0.12% 20.42 ± 0.21%	58.31 ± 0.89% 44.56 ± 0.30%
Supervised + MiXUP (Zhang et al., 2018)	31.83 ± 0.65% 24.22 ± 0.15% 17.37 ± 0.35%	54.87 ± 0.07% 40.97 ± 0.47%
Π-model (Laine & Aila, 2016)	28.74 ± 0.48% 17.57 ± 0.44% 12.36 ± 0.17%	55.39 ± 0.55% 38.06 ± 0.37%
Temp-ensemble (Laine & Aila, 2016)	25.15 ± 1.46% 15.78 ± 0.44% 11.90 ± 0.25%	-	38.65 ± 0.51%
Mean Teacher (Tarvainen & Valpola, 2017)	18.27 ± 0.53% 13.45 ± 0.30% 10.73 ± 0.14%	45.36 ± 0.49% 35.96 ± 0.77%
VAr(MiyatoetaL,2018)	18.12 ± 0.82% 13.93 ± 0.33% 11.10 ± 0.24%	--
SNTG (LUoetaL,2018)	18.41 ± 0.52% 13.64 ± 0.32% 10.93 ± 0.14%	-	37.97 ± 0.29%
Learning to Reweight (Ren et al., 2018b)	11.74 ± 0.12%	-	9.44 ± 0.17%	46.62 ± 0.29% 37.31 ± 0.47%
MT + Fast SWA (Athiwaratkun et al., 2019)	15.58%	11.02%	9.05%	-	33.62 ± 0.54%
ICT (Vermaetal.,2019)	12.44 ± 0.57% 8.69 ± 0.15% 7.18 ± 0.24%	40.07 ± 0.38% 32.24 ± 0.16%
Meta-Semi	10.27 ± 0.66% 8.42 ± 0.30% 7.05 ± 0.27%	37.61 ± 0.56% 30.51 ± 0.32%
Meta-Semi + ICT	9.29 ± 0.62% 7.05 ± 0.12% 6.42 ± 0.18%	37.12 ± 0.59% 29.68 ± 0.05%
Table 2: Performance of Meta-Semi with the WRN-28 network. Average test errors and standard deviations of
5 trials are reported. “#HPs” refers to the number of tunable hyper-parameters. The best results are bold-faced.
Methods	#HPS	CIFAR-10					CIFAR-100
		250 Labels	500 Labels	1000 Labels	2000 Labels	4000 Labels	10000 Labels
Mean Teacher (Tarvainen & Valpola, 2017)	2	47.32 ± 4.71% 42.01 ± 5.86%		17.32 ± 4.00%	12.17 ± 0.22%	10.36 ± 0.25%	-
VAr(Miyatoet al., 2018)	2	36.03 ± 2.82% 26.11 ± 1.52%		18.68 ± 0.40%	14.40 ± 0.15%	11.05 v 0.31%	-
MixMatch (Berthelot et al., 2019)	4	11.08 ± 0.87%	9.65 ± 0.94%	7.75 ± 0.32%	7.03 ± 0.15%	6.24 ± 0.06%	30.84 ± 0.29%
Meta-Semi	1	9.40 ± 0.58%	8.18 ± 0.43%	7.34 ± 0.22%	6.58 ± 0.07%	6.10 ± 0.10%	29.69 ± 0.18%
4	Experiments
In this section, we empirically evaluate the effective-
ness of the proposed Meta-Semi method, analyze its
time complexity experimentally, and give sensitivity
tests. The ablation studies are deferred to Appendix C.
All experiments are conducted using a single Nvidia
Titan Xp GPU.
Table 3: Test errors on STL-10. We adopt the
same experimental setups as (Berthelot et al.,
2019). The best result is bold-faced.
Method	STL-10, 1000 labels
SWWAE (Zhao et al., 2015)	25.70%
CC-GAN (Denton et al., 2016)	22.20%
MixMatch (Berthelot et al., 2019)	10.18 ± 1.46%
Meta-Semi	8.03 ± 0.24%
4.1	Experimental Setup
Our experiments are based on four widely used image classification benchmarks, i.e., CIFAR-10/100
(Krizhevsky et al., 2009), SVHN (Netzer et al., 2011) and STL-10 (Coates et al., 2011), and two
modern deep networks, i.e., a 13-layer CNN (CNN-13) and the Wide-ResNet-28 (WRN-28). On
CIFAR and SVHN, we randomly preserve the labels of certain numbers of samples (identical for
each class), and remain all other samples unlabeled. On STL-10, we use pre-defined folds. Due to
spatial limitation, details on data pre-processing, training/validation splitting, training configurations
and baselines are deferred to Appendix D. These settings follow the common practice of SSL (Oliver
et al., 2018; Berthelot et al., 2019; Verma et al., 2019; Tarvainen & Valpola, 2017; Athiwaratkun
et al., 2019). The hyper-parameter β of Meta-Semi is selected among [0.2, 1] on the validation set.
4.2	Main Results
Results on CIFAR with various numbers of labeled samples are presented in Tables 1, 2. It can be
observed that Meta-Semi consistently outperforms state-of-the-art SSL algorithms in terms of gen-
eralization performance, especially with relatively less labeled data and larger numbers of classes.
For example, when using CNN-13, on CIFAR-10 with 4000 labels, Meta-Semi outperforms the
competitive baseline, ICT, by 0.13% in absolute error, while with 1,000 labels on CIFAR-10 and
with 4,000 labels on CIFAR-100, Meta-Semi yields more significant improvements of 2.17% and
2.46%, respectively. A plausible explanation for this phenomenon is that in these challenging cases,
the large majority of training data are unannotated, and thus the consistency regularization terms in
the loss function of consistency based methods dominant the training process. However, minimizing
the consistency loss does not necessarily ensure high generalization performance since the unlabeled
data receives no direct supervision from the labeled data. In contrast, our method exploits labeled
data to perform supervision on unlabeled data, which is more robust for tasks with small labeled
7
Under review as a conference paper at ICLR 2021
Table 4: Test errors on SVHN with varying amount of labeled
data. We report the average results and the standard deviations
of 5 independent experiments. All results are based on CNN-13.
The best results are bold-faced.
Methods	SVHN 500 labels	SVHN 1000 labels
VAT (Miyato et al., 2018)	-	5.42%
Π-model (Laine & Aila, 2016)	6.65 ± 0.53%	4.82 ± 0.17%
Temp-ensemble (Laine & Aila, 2016)	5.12 ± 0.13%	4.42 ± 0.16%
Mean Teacher (Tarvainen & Valpola, 2017)	4.18 ± 0.27%	3.95 ± 0.19%
ICT (Verma et al., 2019)	4.23 ± 0.15%	3.89 ± 0.04%
SNTG (Luo et al., 2018)	3.99 ± 0.24%	3.86 ± 0.27%
Meta-Semi	4.12 ± 0.21%	3.92 ± 0.11%
Meta-Semi + ICT	3.98 ± 0.09%	3.77 ± 0.05%
CIFAR-100 using 10,000 labels. The CNN-
13 network is used. We also report the re-
sults of ICT (Verma et al., 2019).
Table 5: Performance of Meta-Semi v.s. baselines with fixed amount of training time. We report the
mean test errors of both networks on CIFAR-100 with 10,000 labels. The best results are bold-faced.
(a) CNN-13	(b) WRN-28
Training Time	5.0h	7.5h	10.0h	12.6h
ICT (Verma et al., 2019)	33.43%	32.84%	32.61%	32.24%
Meta-Semi	32.73%	31.81%	31.06%	30.84%
Training Time	13.7h	18.3h	22.8h	29.2h
MixMatch (Berthelot et al., 2019)	32.94%	31.91%	31.26%	30.84%
Meta-Semi	31.74%	30.85%	30.50%	30.13%
set. On the other hand, MixMatch utilizes MixUp augmentation to integrate labeled and unlabeled
samples, showing robust performance with less labels as well, but Meta-Semi outperforms itin terms
of test accuracy. Moreover, it is shown that the performance of Meta-Semi can be significantly im-
proved by combining it with consistency generalization. On CIFAR-10 with 2000 labels, CNN-13
based Meta-Semi + ICT outperforms Meta-Semi by 1.37%.
Another important observation is that our method has only 1 tunable hyper-parameter. Provided that
each hyper-parameter has M candidates, the cost of Meta-Semi for hyper-parameter search will be
1/M of VAT and Mean Teacher, and 1/M3 of MixMatch.
Results on STL-10 and SVHN are presented in Table 3 and Table 4, respectively. The results
indicate that the test accuracy of Meta-Semi outperforms MixMatch by more than 2% on STL-10,
and is comparable with state-of-the-art SSL algorithms on SVHN.
4.3	Hyper-parameter Sensitivity
The β parameter for the Beta distribution in MixUp augmentation is the only additional hyper-
parameter that needs to be tuned when Meta-Semi is implemented in new SSL tasks. To study the
sensitivity of our method to β, we vary the value of β, and present the test errors in Figure 3. For
comparison, we also present the results of ICT (Verma et al., 2019) when its two additional hyper-
parameters (β and the unsupervised regularization coefficient w) change among the recommended
candidates provided by the original paper. One can observe that the performance of Meta-Semi is
relatively stable when β ranges from 0.1 to 1. In contrast, ICT is sensitive to both the two hyper-
parameters. It has been shown that hyper-parameter searching is difficult on realistic SSL tasks
(Oliver et al., 2018). Meta-Semi can be more easily applied as it requires less effort for tuning
hyper-parameters.
4.4	EFFICIENCY OF Meta-Semi
Our method generally requires more training time for each iteration as it includes bi-level optimiza-
tion. However, we find that our algorithm converges fast and if we consider a fixed amount of
training time, it still outperforms the others, as shown in Table 5.
5	Conclusion
In this paper, we have presented a novel semi-supervised classification algorithm under the meta-
learning paradigm. The proposed Meta-Semi algorithm is capable of adapting to various SSL tasks
with impressive performance via tuning only one additional hyper-parameter, and empirically we
have observed that the model performance is robust to different settings of this hyper-parameter.
Theoretically, we have provided the convergence analysis to show that Meta-Semi always converges
to a stationary point under mild conditions. On four competitive datasets, Meta-Semi has achieved
state-of-the-art performance compared to existing deep SSL algorithms.
8
Under review as a conference paper at ICLR 2021
References
Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul,
Brendan Shillingford, and Nando De Freitas. Learning to learn by gradient descent by gradient
descent. In NeurIPS,pp. 3981-3989, 2016.
Ben Athiwaratkun, Marc Finzi, Pavel Izmailov, and Andrew Gordon Wilson. There are many con-
sistent explanations of unlabeled data: Why you should average. 2019.
Philip Bachman, Ouais Alsharif, and Doina Precup. Learning with pseudo-ensembles. In NeurIPS,
pp. 3365-3373, 2014.
Yoshua Bengio, Olivier Delalleau, and Nicolas Le Roux. 11 label propagation and quadratic crite-
rion. 2006.
James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of
machine learning research, 13(Feb):281-305, 2012.
David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin Raf-
fel. Mixmatch: A holistic approach to semi-supervised learning. In NeurIPS, 2019.
David Berthelot, Nicholas Carlini, Ekin D Cubuk, Alex Kurakin, Kihyuk Sohn, Han Zhang, and
Colin Raffel. Remixmatch: Semi-supervised learning with distribution alignment and augmenta-
tion anchoring. In ICLR, 2020.
Dimitri P Bertsekas. Nonlinear programming. Athena Scientific, 1997.
O. Chapelle, B. Scholkopf, and A. Zien. Semi-Supervised Learning. Adaptive computation and
machine learning. MIT Press, Cambridge, MA, USA, September 2006.
Adam Coates, Andrew Ng, and Honglak Lee. An analysis of single-layer networks in unsupervised
feature learning. In AISTATS, pp. 215-223, 2011.
Emily Denton, Sam Gross, and Rob Fergus. Semi-supervised learning with context-conditional
generative adversarial networks. arXiv preprint arXiv:1611.06430, 2016.
Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation
of deep networks. In ICML, pp. 1126-1135. JMLR. org, 2017.
Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In
NeurIPS, pp. 529-536, 2005.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In CVPR, pp. 770-778, 2016.
Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E Hopcroft, and Kilian Q Weinberger.
Snapshot ensembles: Train 1, get m for free. In ICLR, 2017.
Gao Huang, Zhuang Liu, Geoff Pleiss, Laurens Van Der Maaten, and Kilian Weinberger. Convo-
lutional networks with dense connectivity. IEEE transactions on pattern analysis and machine
intelligence, 2019.
Thorsten Joachims. Transductive inference for text classification using support vector machines. In
ICML, volume 99, pp. 200-209, 1999.
Thorsten Joachims. Transductive learning via spectral graph partitioning. In AAAI, pp. 290-297,
2003.
Durk P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. Semi-supervised
learning with deep generative models. In Advances in neural information processing systems, pp.
3581-3589, 2014.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
Technical report, Citeseer, 2009.
9
Under review as a conference paper at ICLR 2021
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convo-
Iutional neural networks. In NeurIPS, pp.1097-1105, 2012.
Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. arXiv preprint
arXiv:1610.02242, 2016.
Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building
machines that learn and think like people. Behavioral and brain sciences, 40, 2017.
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436, 2015.
Dong-Hyun Lee. Pseudo-label: The simple and efficient semi-supervised learning method for deep
neural networks. In ICML Workshop on Challenges in Representation Learning, volume 3, pp.
2, 2013.
Ilya Loshchilov and Frank Hutter. Sgdr: Stochastic gradient descent with warm restarts. arXiv
preprint arXiv:1608.03983, 2016.
Yucen Luo, Jun Zhu, Mengxi Li, Yong Ren, and Bo Zhang. Smooth neighbors on teacher graphs
for semi-supervised learning. In CVPR, pp. 8896-8905, 2018.
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a
regularization method for supervised and semi-supervised learning. IEEE transactions on pattern
analysis and machine intelligence, 41(8):1979-1993, 2018.
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Read-
ing digits in natural images with unsupervised feature learning. In NuerIPS Workshop on Deep
Learning and Unsupervised Feature Learning, 2011.
Augustus Odena. Semi-supervised learning with generative adversarial networks. arXiv preprint
arXiv:1606.01583, 2016.
Avital Oliver, Augustus Odena, Colin A Raffel, Ekin Dogus Cubuk, and Ian Goodfellow. Realistic
evaluation of deep semi-supervised learning algorithms. In NeurIPS, pp. 3235-3246, 2018.
Sungrae Park, JunKeon Park, Su-Jin Shin, and Il-Chul Moon. Adversarial dropout for supervised
and semi-supervised learning. In AAAI, 2018.
Sachin Ravi and Hugo Larochelle. Optimization as a model for few-shot learning. In ICLR, 2017.
Mengye Ren, Eleni Triantafillou, Sachin Ravi, Jake Snell, Kevin Swersky, Joshua B Tenenbaum,
Hugo Larochelle, and Richard S Zemel. Meta-learning for semi-supervised few-shot classifica-
tion. In ICLR, 2018a.
Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples for
robust deep learning. In ICML, 2018b.
Mehdi Sajjadi, Mehran Javanmardi, and Tolga Tasdizen. Regularization with stochastic transforma-
tions and perturbations for deep semi-supervised learning. In NeurIPS, pp. 1163-1171, 2016.
Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556, 2014.
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Du-
mitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In
CVPR, pp. 1-9, 2015.
Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consis-
tency targets improve semi-supervised deep learning results. In NeurIPS, pp. 1195-1204, 2017.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. Word representations: a simple and general method
for semi-supervised learning. In ACL, pp. 384-394. Association for Computational Linguistics,
2010.
10
Under review as a conference paper at ICLR 2021
Vikas Verma, Alex Lamb, Juho Kannala, Yoshua Bengio, and David Lopez-Paz. Interpolation con-
sistency training for semi-supervised learning. In IJCAI, 2019.
Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. Mixup: Beyond empiri-
cal risk minimization. In ICLR, 2018.
Junbo Zhao, Michael Mathieu, Ross Goroshin, and Yann Lecun. Stacked what-where auto-encoders.
arXiv preprint arXiv:1506.02351, 2015.
Xiaojin Zhu, Zoubin Ghahramani, and John D Lafferty. Semi-supervised learning using gaussian
fields and harmonic functions. In ICML,pp. 912-9l9, 2003.
11
Under review as a conference paper at ICLR 2021
Appendix： META-Semi: A Meta-learning Approach for
Semi-supervised Learning
a Proof of Proposition 1
This section provides the proof of proposition 1.
Proposition 1. Suppose that θM is given by M times of gradient descents starting from θ0 = θt.
Then we have
__Iel .	.	.—t ..
d Pi=I L(yi,P(xi∣θM))
=M
w=0
Γ   I -VI	—t
∂ Pi=1 L(yi,p(Xi∣θι))
,∀I≤j≤∣U∣.	(17)
w = 0-
t	t	17/1	t
Proof. According to the updating rule θM = θM-1 -atV^t PJI WkL(yk,p(uk ∣θm-1)), we
^M-1
obtain:
∂ Pi=1 L(y,,p(Xi∣θM))
T21
[wwi∖
∂ £1=也负加词椁))^
而M	-
w=0
t	17/1	t
∂Pi=]L(yi,p(Xi∣θM))	讥θM-ι-α vθM_1pk=ι WkLyk,p(Uk∣θM-I)))TI
Jl
∣w=0
T
∂PiX1 L(yi,p(xiWtM)),
d θM
∂θt	M
υθM-1	t
∂wj - Q T
j	k = 1
^^^^^t
dwkvθtt. L(yk ,p(uk ∣θM-I)) ∂wk
M — 1	k
∂wk	∂Wj
(18)
(19)
(20)
.. .	.一	.一t
))∂Vθt L(yk,p(uk∣θM-1))
M M-I
+
C ._,	▼ / 八 /〜 .ʒrt \
∂wkVθt L(yk,p(uk ∣θM-I,
M M-I
一	..	.—t	..
υVθM-L(yk,P(Uk∖θM-I))
—
w=0
(21)
∂ Pi=1L(y,p(Xi∣θM))^
∂θM	-
-Qt
∂ Pi=1L(yi,p(Xi∣θt))
∂θt
_ t∂L(yj,p(uj∣θt))
∂θt
w=0
∂ EiXIL(yi,p(Xi∣θt))
∂θt
Ct ”(y ,p(u j∣θt))
-2Q	∂θ
w=0
T
∂ Pi=1L(yi,p(Xi∣θt))
∂θt
_ MCt∂L(yj,p(Uj∣θt))
-M	∂θt
w=0
一	.一t
∂L(yj,p(uj ∣θm-I))
|U|	,
+ wk
k=1
∂ θM-1
一	..	.一t
∂ Vθt L(yk ,p(uk ∣θM-1))
M-1
I_ _ I /l .	.	1 T_	........
M t api=1L(yi,p(xi∣θt))	aL(yj,p(uj∣θt))
∂θt	∂θt
(22)
w=0
(23)
(24)
(25)
(26)
12
Under review as a conference paper at ICLR 2021
In the above, the Eq. (23) is obtained as We have θM = θM-ι = ... = θ0 when W = 0. The Eq.
(25) follows repeatedly using Eqs. (18-23). Let M = 1, we have
∂ PiXI L(yi,p(Xi∣θ1))
= -αt
w=0
∂ Pi=IL(yi,p(Xi∣θt))] TJ ∂L(yj ,p(Uj ∣θt))-
∂θt	∂ θt
By combining Eq. (26) and Eq. (27), we prove the desired proposition.
(27)
□
B Proof of Proposition 2
This Section provides the proof of Proposition 2. In our proof, the MixUp augmentation is consid-
ered since it is an important part of our algorithm. We begin with a Lemma (Bertsekas, 1997) based
on the definition of Lipschitz-smooth.
Definition 1. A continuously differentiable function f : Rn → R is said to be Lipschitz-smooth with
constant L if
kVf (x) - Vf (y)k ≤ Lkx - yk, ∀x, y ∈ Rn.
Lemma 1. Assume that the continuously differentiable function f : Rn → R is Lipschitz-smooth
with the scalar L. Then
f(x + y) ≤ f(x) + yτVf (x) + L∙kyk2,∀x,y ∈ Rn.
Then we introduce a mild assumption to restrict the expected norm of the gradients. The assumption
is empirically shown to be generally held in semi-supervised learning.
To clearly present the assumption and the proof, we first define two new symbols. Suppose that the
supervised loss on the labeled mini-batch X at tth step is denoted by
1X1
G(X, θt) = X L(yi,p(Xi∣θt)).	(28)
i=1
In addition, we denote the dynamically weighted loss of pseudo-labeled samples by
~
1	∣u∣
F (X, U, θt) = Lmeta =	— X wj^j ,p(Uj ∣θt)),	(29)
|jU=|1wjtj=1
—,~ -〜. _ . .	_17/1	.
Note that we assume F(X, U, θt) = 0 if Pj=I wjt = 0. Then we have the following assumption.
Assumption 1. For all t ≥ 0, there exists a positive scalar σ, such that
Eχ,Uk%tF(X,U, θt)k2≤ σkVθtEXG(X, θt)k2.
Now we are ready to present the detailed proof. Our proof is partially inspired by the proof of
convergence for gradient based methods with diminishing stepsize provided by (Bertsekas, 1997).
Proposition 2. Assume that the loss function on labeled data G(X, θt) is Lipschitz-smooth with
regards to θt for all X, and that assumption 1 holds. Suppose also that the learning rate at > 0
satisfies:
∞
lim αt = 0,
t→∞
αt = ∞.
t=0
(30)
Then every limit point of the sequence {θt} generated by Meta-Semi is a stationary point of
EXG(X, θt), namely,
lim ∣∣XθtEXG(X,θt)k=0.
t→∞	X
13
Under review as a conference paper at ICLR 2021
T* ， EI » « - TT 1 .	∙	1 1	♦∙1 1 1	∙ . ∙ 1	1 .	τ5
Proof. The MixUp data augmentation needs to be considered because it is leveraged to generate X
and U from the original data. On the basis of the original labeled samples X and unlabeled samples
U (associated with original pseudo labels), we have
~ _一 _ ............................ , .
X = MiXUP(X, ShUffle(X), λ1), λ1 〜Beta(α, α),
(31)
W = Concat(X, U),	(32)
U = MixUp(W, Shuffle(W ),λ2),λ2 〜Beta(α,α).	(33)
Given that the MiXUP aUgmentation is Performed between the mini-batch and itself with certain
random permUtation, we define the expected loss over all possible permUtations by
G(X, θt,λι)=~	E	G(X, θt)
X∈MixUρ(X, Shuffle (X ),λι)
1X1	(34)
=一	E	X L(yi,p(Xi∣θt)),
X∈MixUp(X,Shuffle(X),λι)分=]
L 〜	-1
_	∣u∣
F(X, X,U, θt,λ2) = ~	E	X Wj F(X,U, θt)
U∈MixUρ(W,Shuffle(W),λ2) j = ι
∣u∣
=~	E	X WtjL(Oj,p(U W\),
U∈MixUρ(W,Shuffle(W),λ2) j=ι
(35)
where the first argument X of F(∙) is used for determining the dynamic weights of pseudo-labeled
samples. Then We solve G and F in a closed form. Consider the following problem: N different
items are paired to the same N items. Obviously, there are N! modes of pairing in total. If we
fix certain pair, we will have (N - 1)! modes of pairing left. Therefore, if we combine all N!
possible pairing modes together, we will find that any item is paired to every item (including itself)
for (N - 1)! times. Similarly, in our problem, it is easy to obtain
G(X, θt, λI) = ∣X! X (IXI - 1)!fij(θt, λI) = X X fij(θt, λI),	(36)
xi,xj ∈X	xi,xj ∈X
where xi , xj are the original samples that can be either labeled or unlabeled. The loss of the aug-
mented sample generated by performing MixUp augmentation between xi and xj with λ1 is denoted
by fij(θt, λ1). In a similar way, we can obtain
F(X, X,U, θt,λ2) = ɪ X	Wtj(λ2) fij(θt,λ2),	(37)
IU I xi,xj∈X∪U
where Witj(λ2) is the dynamic weight determined by
Witj(λ2)
(1	[%tG(X, θt)]τ[%t fij(θt, λ2)] ≥ 0
[0	[%tG(X, θt)]T[%tfij(θt,λ2)] < 0
(38)
Now, consider the following inequation
1	I" ∣u∣
[%tG(X, θt)]T[%tF(X,U, θt)] = -EU- [%tG(X, θt)]T X Wj[%tL(yj,p(Uj∣θt))]
j=1 Wjt	j=1
1
≥
一 |U|
[%t G(X, θt)]T
.1U1	,
X wj Mt L(yj ,p(Uj Iet))]
j=1
(39)
(40)
14
Under review as a conference paper at ICLR 2021
1 ʌ . -i ∙	. 1	.	1^∕	T τ ，、N 、 CI i`n	Γ∙ .∖	A .
By taking the expectation over U ∈ MixUp(W, Shuffle(W), λ2), we further obtain
E	[%，G(X, θt)]τ[%F(X,U, θt)]
——.	ʃ . . . ʃ . . . l
U∈MixUp(W,Shufle(W),λ2)
≥ 士格G(X, θt)]T[%tF(X, X,U, θt, λ2)]
|U|
=Tq^l	X	Wtj (λ2) [^θtG(X, θt)]T [%t fij (θt, λ2 )]
|U | xi,xj∈X∪U
≥ τ∩7^ X Wtj (尢)[诏t G(X, θt)]τ [诏t fij (θt, λ2)]
|U | xi,xj∈X
≥ ττ‰2 X [%tG(X, θt)]τ[%tfij(θt, λ2)]
|U |2 xi,xj∈X
I Vl
=T∩72 [%t G(X, θt)]T[%t G(X, θt, λ2)].
|U|2
Then by taking the expectation over X ∈ MixUp(X, Shuffle(X), λι), We have
~	E	~	E	[%，G(X, θt)]τ[%，F(X,U, θt)]
X∈MixUp(X,Shuffle(X),λι) U∈MixUp(W,Shuffle(W),λ2)
I Vl
≥ T~772 [%t G(X, θt, λ1 )],[%t G(X, θt, λ2)].
|U|2
(41)
(42)
(43)
(44)
(45)
(46)
(47)
(48)
Finally, We take the expectation over λ1, λ2 and all possible batches X,U . FolloWing from the
convexity of ∣∣∙k2, we have E(k∙k2) ≥ ∣∣E(∙)k2. Therefore, we obtain
Eχ,U[%，G(X, θt)]τ[%F(X,U, θt)] ≥需EX,U∣%tEλG(X,θt,λ)∣2	(49)
≥ 算 ∣∣%t EX ,u EλG(X, θt ,λ)∣2	(50)
|U|2
≥∣UX2k%，EXG(X, θt)k2,	(51)
where Inequality (49) is obtained as λ1, λ2 are mutually independent. Then we consider the updating
rule of the stochastic gradient descent (SGD) algorithm:
∆θ = θt+1 — θt = —at%，F(X,U, θt).	(52)
Assume that the loss function on labeled data G(X, θt) is Lipschitz-smooth with the constant L.
Following Lemma 1, we have
G(X, θt+1) ≤ G(X, θt) + [%G(X, θt)]τ∆θ + 2 ∣∆θ∣2	(53)
=G(X, θt) + at [1 atL||%，F(X,U, θt)∣2-[%，G(X, θt)]τ[%F(X,U, θt)].
(54)
Take the expectation over all possible X , U, and thus we obtain the following inequality using As-
sumption 1 and Inequality (51):
EXG(X, θt+1) ≤ EXG(X, θt) + at
1 atσL-&
2	|U|2
k%，EXG(X, θt)∣2.
(55)
As at → 0, there exists some positive constant C such that for all t greater than some index t, we
have
EXG(X, θt+1) ≤ EXG(X, θt) — atck%，EXG(X, θt)∣2, ∀t ≥ t.	(56)
15
Under review as a conference paper at ICLR 2021
We see that {EχG(X, θt)} is monotonically decreasing for all t ≥ t. As G(∙) is computed using
the cross-entropy loss over the predictions of networks, it follows EXG(X, θt) ≥ 0. Therefore,
{EχG(X, θt)} converges to a finite value. By adding Inequality (56) over all t > t,we obtain
∞
CXαtk%tEXG(X, θt)k2≤ EXG(X, θt) - lim EXG(X, θt) < ∞.	(57)
t=t
It cannot exist an > 0 such that k%tEXG(X,θt)k2> E for all t greater than some t. If so, as
Pt∞=0 αt = ∞, the left side of Inequality (57) will come to infinity. Therefor, we must have:
liminf∣∣XθtEXG(X, θt)∣∣=0∙
t→∞	X
(58)
T .< Cll ♦	∙ 11 1	. 1 . 1 ∙	I I X—7 ττn	/ τ5 Λ≠ ∖ I I ∕∖ T-1∙ . 1	.1	.
In the following, we will show that lim supt→∞ ∣∣X¾t EX G(X, θt)k= 0. Firstly, assume the contaary,
namely
limsup∣∣XθtEXG(X, θt)∣∣≥ e > 0.	(59)
t→∞
Let {mj} and {nj} be the sequences of indexes such that
mj < nj < mj+1 ,	(60)
I < k%*EXG(X, θt)k, mj ≤ t < nj,	(61)
E
k%tEXG(X, θt)k≤ 3, nj- ≤ t < mj+ι∙	(62)
Since G(X, θt) is Lipschitz-smooth, it is easy to see that EXG(X, θt) is also Lipschitz-smooth.
Suppose that the corresponding Lipschitz constant is L0. Let j be a sufficiently large index such that
∞2
X atk%tEXG(X, θt)k2< Q 厂10 ∙	(63)
9 σL
t=mj	Y
For any j ≥ j and any m with mj ≤ m ≤ nj 一 1, we have
nj-1
k%njEXG(X, θnj) -%mEXG(X, θm)k≤ X k%t+1 EXG(X, θt+1)-%tEXG(X, θt)k
t=m
(64)
nj-1
≤ L0 X kθt+1 - θtk
t=m
nj-1
X
αtk%tF(X,U, θt)k∙
t=m
By taking the expectation over X , U, we have
nj -1
k%njEXG(X,θnj)-%mEXG(X,θm)k≤ L0 X αtEX,u∣%tF(X,U,θt)∣
t=m
nj-1
≤√σL0 X αtk%tEXG(X, θt)k
t=m
≤ 37刀 X αt∣∣XθtexG(X, θt)k2
t=m
/ 3√σL0	I2
≤ -1- 9√σL0
I
=-
3,
(65)
(66)
(67)
(68)
(69)
(70)
(71)
16
Under review as a conference paper at ICLR 2021
where Inequality (69) follows from Inequality (61) and Inequality (68) follows from
Eχ,U∣∣%tF(X,U, θt)k≤ ,Eχ,u∣∣%tF(X,U, θt)k2 ≤ √σ∣∣%EXG(X, θt)∣∣∙	(72)
Thus, we have
..  _	_ , ~	..  _ _ , ~ 一、.. €	2c	—
∣∣XθmEXG(X, θm)k≤ k%njEXG(X, θnj)k+w ≤ -3-, ∀j ≥ j,mj≤ m ≤ % - 1∙	(73)
As the inequality holds for all m ≥ m j, We finally obtain
2	-
kXθmEXG(X, θm)k≤ v, ∀m ≥ mj,	(74)
3
Which contradicts Inequality (59), implying that
liminf∣∣Xθt EX G(X, θt)k=limsup∣∣Xθt EX G(X, θt )k= 0.	(75)
t→∞	X	t→∞	X
Therefore, We prove that limt→∞k%tEXG(X, θt)k= 0.	□
C Ablation Study
To provide additional insights into our
method, We further conduct the ablation
experiments by removing or altering the
components of Meta-Semi. The results are
shoWn in Table 6. It can be seen that param-
eter EMA and performing MixUp on un-
labeled data are both important techniques
to achieve high generalization performance.
The observation is consistent With (Verma
et al., 2019). In addition, if all pseudo-
labeled samples are Weighted by the con-
stant 1, Meta-Semi is equivalent to a con-
sistency based algorithm, Which also shoWs
effective performance.
Table 6: Ablation study results. We report the test
errors on CIFAR-100 With 4,000 and 10,000 labels.
The CNN-13 netWork is used.
Ablation	CIFAR-100	CIFAR-100 4000 labels	10000 labels
Without parameter EMA One-hot pseudo labels	47.68 ± 0.27% 37.15 ± 1.02% 41.52 ± 0.51% 32.78 ± 0.41%
MixUp on unlabeled data only MixUp on labeled data only Without MixUp	37.69 ± 0.50% 30.56 ± 0.39% 45.90 ± 0.15% 36.11 ± 0.21% 46.71 ± 0.05% 35.98 ± 0.69%
ReWeighting With the constant 1 ReWeighting With -1 and 1	40.26 ± 0.64% 32.17 ± 0.14% 45.41 ± 0.38% 36.39 ± 0.44%
Meta-Semi Meta-Semi + ICT	37.61 ± 0.56% 30.51 ± 0.32% 37.12 ± 0.59% 29.68 ± 0.05%
D Details of Experiments
Datasets. (1) The CIFAR-10 / CIFAR-100 datasets consist of 60,000 32x32 colored images of 10 /
100 classes, 50,000 for training and 10,000 for test. FolloWing the common practice of SSL (Oliver
et al., 2018; Berthelot et al., 2019; Verma et al., 2019; Tarvainen & Valpola, 2017; AthiWaratkun
et al., 2019), We hold out 5k images from the training set as the validation set. Images are nor-
malized With channel means and standard deviations for pre-processing. Then data augmentation is
performed by 4x4 random translation folloWed by random horizontal flip (He et al., 2016; Huang
et al., 2019). On CIFAR-10, We preserve 100, 200 and 400 labels per class respectively, correspond-
ing to 1000, 2000, 4000 labeled samples in total. All other samples are unlabeled. We randomly
split the dataset for 5 times to conduct multiple experiments, and report the mean test errors as-
sociated With standard deviations. Similarly, On CIFAR-100, evaluation is performed With 40 and
100 randomly preserved labeled samples per class. (2) SVHN consists of 32x32 colored images
of digits. 73,257 images for training, 26,032 images for testing and 531,131 images for additional
training are provided. FolloWing (Luo et al., 2018; Tarvainen & Valpola, 2017), We merely perform
random 2x2 translation to augment the training set, and hold out 1,000 images for validation. Sim-
ilar to CIFAR, We randomly preserve 500 and 1,000 labels for experiments. (3) STL-10 (Coates
et al., 2011) contains 5,000 training examples divided into 10 predefined folds With 1000 examples
each, and 100,000 unlabeled images draWn from a similar—but not identical—data distribution. All
the samples are 96x96 colored images. We use the same experimental protocol as (Berthelot et al.,
2019).
Networks. Our experiments are based on a 13-layer CNN (CNN-13) and the Wide-RestNet-28-2
(WRN-28) netWork. The CNN-13 netWork has been adopted as the standard model for experiments
17
Under review as a conference paper at ICLR 2021
by state-of-the-art SSL algorithms (Verma et al., 2019; Tarvainen & Valpola, 2017; Athiwaratkun
et al., 2019; Miyato et al., 2018; Luo et al., 2018; Park et al., 2018). Following (Verma et al., 2019),
we remove the Gaussian noise layer and the dropout layer in the network. Other methods use these
techniques if mentioned in their original papers, which provide stronger regularization. Some recent
works adopt the WRN-28 network (Oliver et al., 2018; Berthelot et al., 2019) in their experiments.
We also implement Meta-Semi with WRN-28 to present comparisons with them.
Large Validation Set. We note that the validation set we use may be relatively large in some settings
(e.g. 5,000 for validation on CIFAR-10 with 1,000 labeled examples). However, since most prior
SSL methods do so, we simply follow them to produce comparable results with them in the paper.
On the other hand, as discussed in the sensitivity test, our method is less sensitive to the only tunable
hyper-parameter β and thus requires less validation efforts. To further demonstrate this point, we
perform a four-fold cross-validation on CNN-13 based Meta-Semi with 1,000 labeled samples on
CIFAR-10 to search for the optimal β. Our method achieves a test error of 10.96 ± 0.56%, which is
slightly higher than the 10.27 ± 0.66% of using addition 5,000 labeled samples for validation, but
still significantly outperforms baselines.
Training details. The CNN-13 network uses the SGD optimizer with a Nesterov momentum of
0.9. The L2 regularization coefficient is set to 1e-4, and the initial learning rate is set to 0.1. For
all experiments with CNN-13, we train the network for 600 epochs using the cosine learning rate
annealing technique (Loshchilov & Hutter, 2016; Huang et al., 2017; Verma et al., 2019). The
batch size of labeled samples and unlabeled samples are set to 25 and 75 respectively. To generate
pseudo labels for unlabeled samples, we use an exponential moving average on model parameters
with a decay rate of 0.999. For WRN-28, we adopt exactly the same training details as (Berthelot
et al., 2019) except for the batch size: we use 32 for labeled samples and 96 for unlabeled samples.
The ratio of labeled/unlabeled samples in each mini-batch is always set to 1:3 in Meta-Semi, which
consistently achieves excellent performance on the validation set, and does not need to be tuned for
the specific SSL task.
Baselines. Our method is compared with several state-of-the-art baselines including SSL algorithms
and a meta-reweighting method.
•	Π-model (Laine & Aila, 2016) enforces the model predictions to remain the same when
different augmentation and dropout modes are performed.
•	Temp-ensemble (Laine & Aila, 2016) attaches a soft pseudo label for each unlabeled sam-
ple by performing a moving average on the historical predictions of networks.
•	Mean Teacher (MT) (Tarvainen & Valpola, 2017) establishes a teacher network by per-
forming exponential moving average on the parameters of the model, and leverages the
teacher networks to produces supervision for unlabeled data.
•	Virtual Adversarial Training (VAT) (Miyato et al., 2018) adds adversarial perturbations to
the samples and enforce the model to have the same predictions on perturbed samples and
the original samples.
•	Smooth Neighbors on Teacher Graphs (SNTG)(Luo et al., 2018) constructs a teacher graph
to regularize the feature distribution of unlabeled samples.
•	Learning to Reweight (Ren et al., 2018b) proposes to reweight different training samples
by solving a similar meta-learning problem to us. Since their original algorithm requires
labels of all the training, we adopt a version modified for SSL in this paper. In specific,
we retain our approach of generating pseudo-labeled samples, but use their reweighting
strategy.
•	MT + Fast SWA (Athiwaratkun et al., 2019) is an improved MT algorithm using a fast
stochastic weight averaging optimizer.
•	Interpolation Consistency Training (ICT) (Verma et al., 2019) encourages the prediction on
an interpolation of unlabeled samples to be consistent with the interpolation of the predic-
tions on those points. They first use MixUp augmentation in deep SSL.
•	MixMatch (Berthelot et al., 2019) is a holistic deep SSL approach that integrates various
dominant consistency regularization techniques.
18
Under review as a conference paper at ICLR 2021
We implement these methods in the same codebase, and search for the best hyper-parameters for
them on the validation set according to the recommendations provided by their original papers.
Notably, for MixMatch (Berthelot et al., 2019), we fix the sharpening temperature T = 0.5 and the
number of unlabeled augmentations K = 2, and adjust the α parameter for Beta distribution and the
unsupervised loss coefficient λ^, as suggested by the paper. We first reproduce the CIFAR-10 results
of MixMatch reported by their paper, and then tune a and λ^ on the validation set of CIFAR-100.
19