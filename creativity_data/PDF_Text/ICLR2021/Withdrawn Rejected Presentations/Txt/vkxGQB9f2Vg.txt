Under review as a conference paper at ICLR 2021
Fourier Stochastic Backpropagation
Anonymous authors
Paper under double-blind review
Ab stract
Backpropagating gradients through random variables is at the heart of numerous
machine learning applications. In this paper, we present a general framework for
deriving stochastic backpropagation rules for any distribution, discrete or contin-
uous. Our approach exploits the link between the characteristic function and the
Fourier transform, to transport the derivatives from the parameters of the distribu-
tion to the random variable. Our method generalizes previously known estimators,
and results in new estimators for the gamma, beta, Dirichlet and Laplace distribu-
tions. Furthermore, we show that the classical deterministic backproapagation rule
and the discrete random variable case, can also be interpreted through stochastic
backpropagation.
1	Introduction
Deep neural networks with stochastic hidden layers have become crucial in multiple domains, such
as generative modeling (Kingma & Welling, 2013; Rezende et al., 2014; Mnih & Gregor, 2014),
deep reinforcement learning (Sutton et al., 2000), and attention mechanisms (Mnih et al., 2014). The
difficulty encountered in training such models arises in the computation of gradients for functions of
the form L(θ) := Ez〜p@ [f (z)] with respect to the parameters θ, thus needing to backpropagate the
gradient through the random variable z. One of the first and most used methods is the score function
or reinforce method (Glynn, 1989; Williams, 1992), that requires the computation and estimation of
the derivative of the log probability function. For high dimensional applications however, it has been
noted that reinforce gradients have high variance, making the training process unstable (Rezende
et al., 2014).
Recently, significant progress has been made in tackling the variance problem. The first class of
approaches dealing with continuous random variables are reparameterization tricks. In that case a
standardization function is introduced, that separates the stochasticity from the dependency on the
parameters θ. Thus being able to transport the derivative inside the expectation and sample from a
fixed distribution, resulting in low variance gradient (Kingma & Welling, 2013; Rezende et al., 2014;
Titsias & Lazaro-Gredilla, 2014; Ruiz et al., 2016; Naesseth et al., 2017; Figurnov et al., 2018). The
second class of approaches concerns discrete random variables, for which a direct reparameterization
is not known. The first solution uses the score function gradient with control variate methods to
reduce its variance (Mnih & Gregor, 2014; Gu et al., 2016). The second consists in introducing
a continuous relaxation admitting a reparameterization trick of the discrete random variable, thus
being able to backpropagate low-variance reparameterized gradients by sampling from the concrete
distribution (Jang et al., 2016; Maddison et al., 2016; Tucker et al., 2017; Grathwohl et al., 2018).
Although recent developments have advanced the state-of-the-art in terms of variance reduction and
performance, stochastic backpropagation (i.e computing gradients through random variables) still
lacks theoretical foundation. In particular, the following questions remain open: How to develop
stochastic backpropagation rules, where the derivative is transferred explicitly to the function f for
a broader range of distributions? And can the discrete and deterministic cases be interpreted in
the sense of stochastic backpropagation? In this paper, we provide a new method to address these
questions, and our main contributions are the following:
•	We present a theoretical framework based on the link between the multivariate Fourier
transform and the characteristic function, that provides a standard method for deriving
stochastic backpropagation rules, for any distribution discrete or continuous.
1
Under review as a conference paper at ICLR 2021
•	We show that deterministic backpropagation can be interpreted as a special case of stochastic
backpropagation, where the probability distribution pθ is a Dirac delta distribution, and that
the discrete case can also be interpreted as backpropagating a discrete derivative.
•	We generalize previously known estimators, and provide new stochastic backpropagation
rules for the special cases of the Laplace, gamma, beta, and Dirichlet distributions.
•	We demonstrate experimentally that the resulting new estimators are competitive with
state-of-the art methods on simple tasks.
2	Background & Preliminaries
Let (E, λ) be a d-dimensional measure space equipped with the standard inner product, and f be a
square summable positive real valued function on E ,that is, f: E → R+, with JE |f (z)∣2λ(dz) < ∞.
Let pθ be an arbitrary parameterized probability density on the space E. We denote by 夕θ its
T
characteristic function, defined as:夕θ(ω) := Ez〜p@ [eiω z]. We denote by f the Fourier transform of
the function f defined as:
ʌ
f(ω):
F{f}(ω) =
E
T
f(z)e-iωTzλ(dz).
(1)
The inverse Fourier transform is given in this case by:
f(z) :
F -1{f}(z)=lκ J(ω)eiωTz μ(dω),
(2)
where μ(dω) represents the measure in the Fourier domain. In this paper We treat the cases where
E = Rd for which μ(dω)=杳什,and the case where E is a discrete set, for which the measure
μ is defined as: μ(dω) = l[ω ∈ [-π, π]d] (d^. Throughout the paper, we reserve the letter i to
denote the imaginary unit: i2 = -1. To denote higher order derivatives of the function f, we use the
multi-index notation (Saint Raymond, 2018). For a multi-index n = (n1, ..., nd) ∈ Nd, we define:
∂|n|
dz := ∂zn1 …∂zdd
dd
where |n|=	nj and ωn :=	ωjnj .
j=1	j=1
To clarify the multi-index notation, let us consider the example where d = 3, and n = (1, 0, 2), in
this case:
∂3
∂Zn =	2 and, ωn = ωι"3∙
z	∂z1 ∂z32	3
The objective is to derive stochastic backpropagation rules, similar to that of (Rezende et al., 2014), for
functions of the form: L(θ) := Ez〜p@ [f (z)], for any arbitrary distribution pθ, discrete or continuous.
3	Fourier Stochastic Backpropagation
Stochastic backpropagation rules similar to that of (Rezende et al., 2014) can in fact be derived for
any continuous distribution, under certain conditions on the characteristic function. In the following
theorem we present the main result of our paper concerning the derivation of Fourier stochastic
backpropagation rules.
Theorem 1.	(Continuous Stochastic Backpropagation) Let f ∈ C∞ (Rd, R+ ), under the condition
that Vθ log 夕 θ is a holomorphic function of iω, then there exists a unique {an(θ)}n∈Nd ∈ R such
that:
VθL = Ean(θ)Egpe [∂nf(Z)].	⑶
∣n∣≥0
Where {an(θ)}n∈Nd are the Taylor expansion coefficients of Vθ log 夕θ(ω):
Vθ log 夕θ(ω) = X an(θ)(iω)n.	(4)
∣n∣≥0
2
Under review as a conference paper at ICLR 2021
Proof. Let us rewrite L in terms of f :
L(θ) =
pθ(z)f (z)λ(dz)
P Pθ (Z)FT [f](z)λ(dz)
Ldf 3 L Pθ (ZlTz λ(dz)μ(dω)
(5)
Fubini’s theorem
Jd f(ω)φθ(ω)μ(dω).
By introducing the derivative under the integral sign, and using the reinforce trick (Williams, 1992)
applied to 夕θ, where Vθ夕θ(ω)=夕θ(ω)Vθ log 夕θ(ω), equation 5 becomes:
Vθ L
/
Rd
P/ ʌ /	∖L7 1 .	/	∖	/ 7 ∖
f (ω)夕θ(ω)Vθ log 夕θ(ω)μ(dω).
(6)
Under analyticity conditions of the gradient of the log characteristic function, we can expand the
gradient term V log 夕θ (ω), in terms of Taylor series around zero as:
Vθ log 夕θ(ω) = E an(θ)(iω)n.
∣n∣≥0
(7)
Putting everything together, and replacing the characteristic function by its expression, the gradient
of L becomes:
VθL
Ldf3 L Pθ (z)eiωT z
^X an(θ)(iω)nμ(dω)λ(dz).
∣n∣≥0
(8)
By rearranging the sums using Fubini’s theorem a second time, we obtain the following expression
for the gradient:
VθL = Ez〜Pθ F-1 ω ω→ E an(θ)(iω)n∕(ω" (z)
一 [∣n∣≥0一
=X an(θ)EZ〜Pθ [f-1 {ω → (iω)n∕(ω)} (z)i	(9)
∣n∣≥0
=X an(θ)EZ〜Pθ [∂zf(z)].
∣n∣≥0
Q.E.D
Identically, we can follow the same procedure for discrete random variables. We suppose that Pθ
factorizes over disjoint cliques of the dependency graph, where each dimension zj takes values in a
discrete space V al(Zj). In theorem 2 we derive the result concerning the discrete case.
Theorem 2.	(Discrete Stochastic Backpropagation) Let E be a discrete space: E = Qjd=1 V al(Zj ),
and C the set of disjoint cliques of the dependency graph over Z, that is,
Pθ (Z) =	Pθ (Zc)
c∈C
then,
VθL =XX
Vθpθ(Zc)EZ-C〜pθ [Df (Z-c, Zc)].	(10)
c∈C zc = zC
Where:
•	zc: represents the normalizing assignment P(z*) = 1 一 EzC=z* P(Zc).
3
Under review as a conference paper at ICLR 2021
•	Df (Z-c, Zc) := f (Z-c, Zc) - f (Z-c,z*).
(11)
Proof. The characteristic function for the factored distribution is given by:
ψθ(ω) = Y / (ωc],	ψg')(ωc) = X pθ(Zc)eiωTzc + (1- X pθ(zc) j eiωTZc.	(12)
c∈C	ZC=ZC	∖	ZC = ZC	)
Thus the gradient of the log characteristic function becomes:
T	TC
(c)	eiωCT ZC - eiωCT ZCC
Vθ log * (ωcc)=工 VθPθ (Zc) -----(c---—
ZC=ZC	L *θ (ωc)
By plugging this expression to equation 6, we obtain:
VθL =XX
Vθpθ(Zc) / Y *θc0)(ωc0) [eiωTZc - eiωTZC ] f(ω)μ(dω)
c∈C ZC 6=ZCC	c0 6=c
=	Vθpθ(Zc)Ez-C〜pθ [Df(z-c,zc)].
c∈C ZC 6=ZCC
(13)
(14)
Q.E.D
The estimator of equation 10 has been derived in the literature through Rao-BlackWellization of the
score function gradient, and it has been known under different names (Titsias & Lazaro-Gredilla,
2015; Asadi et al., 2017; Cong et al., 2019). Theorem 2 shoWs that the discrete case can also be
seen as backpropagating a derivative of the function f, in this case a discrete derivative given by
equation 11.
4 Applications of Fourier Stochastic Backpropagation
Following from the previous section, we derive the stochastic backpropagation estimators for certain
commonly used distributions.
The multivariate Gaussian distribution: In this casepθ(z) = N(z; μθ, ∑θ). The log characteristic
function is given by: log *(ω) = iμTω + 2Tr [∑θi2ωωτ]. Thus by applying theorem 1, we recover
the stochastic backpropagation rule of (Rezende et al., 2014):
Vθ L = EZ 〜pg
{(¾θ) Vzf(z)+2Tr ](d∂θθ)v2f(Z)]},
(15)
where, VZ and V2Z, represent the gradient and hessian operators.
The multivariate Dirac distribution: pθ(Z) = δaθ (Z), the log characteristic function of the Dirac
distribution is given by: log *θ(ω) = iωTaθ. Thus the stochastic backpropagation rule of the Dirac
is given by:
VθL =(察)TEz~δa0 [Vzf(z)]=(需)T Vzf(aθ),
∂θ	θ	∂θ
(16)
resulting in the classical backpropagation rule. In other words, the deterministic backpropagation
rule is a special case of stochastic backpropagation where the distribution is a Dirac delta distribution.
This result provides a link between probabilistic graphical models and classical neural networks. We
investigate this link further in Appendix A.
The multivariate Bernoulli: pθ(Z) = Qjd=1 B(Zj; πθ(j)), where πθ(j) = P[Zj = 1]. By applying
theorem 2, we obtain the local expectation gradient of (Titsias & Lazaro-Gredilla, 2015):
d ∂π(j )
VθL = E ~∂θ~Ez-j~Pθ [f (z-j,1)- f (z-j, 0)].	(17)
j=1 ∂θ
4
Under review as a conference paper at ICLR 2021
The multivariate categorical: pθ(z) = Qjd=1 cat(zj; πθ(j)), where the dimensions are independent
and take values in the set {1, ..., K}. Similarly to the Bernoulli case, we obtain the following
stochastic backpropagation rule:
d K-1 ∂	(j)
Vθ L = XX -∂k- Ez-j~pθ [Df (z-j, k)].
j =1k=1
(18)
The Laplace distribution: pθ(Z) = L(z; μe, bθ), in this case the log characteristic function is the
following: log 夕θ(ω) = iμθω - log(1 + bω2), using the Taylor series expansion for the function
X → ι-χ, we get the following stochastic backpropagation rule for the Laplace distribution:
∞
j L=喝 EZIdz (Z)
1 -bθ
喘~∂θ
ΣbθnEz [d2nf (Z).
(19)
n=1
+
The gamma distribution: pθ(Z) = Γ(z; kθ,μθ), the log characteristic function of the Gamma
distribution is given by: log 夕θ(ω) = -kθ log(1 - iμθω). By expanding it using Taylor series of the
logarithm function, we obtain the following stochastic backpropagation rule:
∞
VθL = X
n=1
1 ∂kθ + kθ 也]
n ∂θ μθ ∂θ _|
μθ EZ〜Pθ
篝(Z)I .
dzn
(20)
The estimator of equation 20 gives a stochastic backpropagation rule for the gamma distribution
and, hence also applies by extension to the special cases of the exponential, Erlang, and chi-squared
distributions.
The beta distribution: pθ(z) = Beta(z; αθ, βθ), in this case the characteristic function is the
confluent hypergeometric function:夕θ(ω) = 1 F1(a&; a& + βθ; iω). A series expansion of the
gradient of the log of this function is not trivial to derive. However, we can use the parameterization
linking the gamma and beta distributions to derive a stochastic backpropagation rule. Indeed, if
Zi 〜Γ(αθ, 1) and Z2 〜Γ(βθ, 1), then Z = g(Z1,Z2) = ^1+^-〜Beta(αθ, βθ). By substituting in
the gamma stochastic backpropagation rule, we obtain:
vθL=X n {⅛θ %© ]⅛n (ζι⅛)]+dβθ Eζ1,ζ2 [⅛n (ζ⅛)]}.
(21)
The Dirichlet distribution: pθ(z) = Dir(z; K, αθ), following the same procedure, as for the beta
distribution and using the following parameterization: Zk = PK Z with, Zk 〜Γ(αθk), 1), we
obtain:
∞
vθ L = X -
n
n=i
Zj
(22)
5	Tractable cases & Approximations of Fourier Stochastic
Backpropagation
The Fourier stochastic backpropagation gradient as presented in previous sections presents two major
computational bottlenecks for non-trivial distributions. The first is the computation of infinite series,
and the second is evaluating higher order derivatives of the function f . Depending on the application,
the function f could be chosen in order to bypass the computational bottlenecks. A trivial example,
is if the higher order derivatives of the function f vanish at a certain order: ∂zn f = 0. Another
example, is the exponential function f(z) = exp(T z). From the fact that it obeys the following
partial differential equation f (Z) = Ejf (z), one can deduce that the stochastic backpropagation
rule reduces in this case to:
VθL = Vθ log ψθ (i) EZ〜Pθ [f (z)]	(23)
In most real world applications however, the infinite sum will not often reduce to a tractable expression
such as that of the exponential. An example of this case is the evidence lower bound of a generative
5
Under review as a conference paper at ICLR 2021
ωll*jθω□uπlμπl> 6o-∣
d = 1
d = 100
IOOOO 20000 30000 40000 50000
Steps
0	10000 20000 30000 40000 50000	0	10000 20000 30000 40000 50000
Steps	Steps
Figure 1: Training loss and log variance of the gradients for the different estimators for f (z) =
Pjd=1(zj -)2ford∈ {1, 10, 100}.
model with Bernoulli observations. In this case, the natural solution is to truncate the sum up to a
finite order. The assumption (although it might be wrong), is that the components associated to higher
frequencies of the spectrum of the gradient of the log characteristic function, do not contribute as
much. And by analogy to the signal processing field, we apply a Low-pass filter to eliminate them. In
this case the gradient of the log characteristic function of equation 7 becomes:
Vθ log ψθ(ω)=工 an(θ)(iω)n + o((iω)N).	(24)
n≤N
6	Experiments
In our experimental evaluations, we test the stochastic backpropagation estimators of equations 19
and 20 for the gamma and Laplace distributions. In the case of the gamma estimator, we use toy
examples where we can derive exact stochastic backpropagation rules without truncating the infinite
sum. As for the Laplace stochastic backpropagation rule, we test the estimator in the case of Bayesian
logistic regression with Laplacian priors and variational posteriors on the weights. We compare our
estimators with the pathwise (Jankowiak & Karaletsos, 2019; Jankowiak & Obermeyer, 2018), and
score function estimators, in addition to the weak reparameterization estimator in the gamma case
(Ruiz et al., 2016). We do not use control variates in our setup, the goal is to verify the exactness of
the proposed infinite series estimators and how they compare to current state-of-the-art methods in
simple settings. In all our experiments, we use the Adam optimizer to update the weights (Kingma &
Ba, 2014), with a standard learning rate of 10-3. In all the curves, we report the mean and standard
deviation for all the metrics considered over 5 iterations.
6.1	Toy problems
In the toy problem setting, we test the gamma stochastic backpropagation rule following the same
procedure as (Mohamed et al., 2019). we consider the following cases:
Toy problem 1: L(θ) = EZ〜pθ |||z - e||2], where Pθ(z) = Qd=I Γ(zj; kj,μj), θ = {k, μ}, and
= .49. In this case, we only need to compute the first and second order derivatives of the function
f.
Toy problem 2: L(θ) = EZ〜pθ
Pjd=1 exp(-Zj )
, in this case, the infinite sum transfers to ,
which results in the following estimator: VθL = Vθ log φθ (∣) EZ〜pθ [f (z)].
In figures 1 and 2 we report the training loss and log variance of the gradient across iterations of gra-
dient descent for different values of the dimension d ∈ {1, 10, 100}. The stochastic backpropagation
estimator converges to the minimal value in all cases faster than the other estimators and the variance
of the gradient is competitive with the pathwise gradient.
6
Under review as a conference paper at ICLR 2021
au"pabωll*jm-0 φucra□ra> 6o-∣
Steps
Figure 2:	Training loss and log variance of the gradients for the different estimators for f (z) =
Pjd=1 exp(-zj) for d ∈ {1, 10, 100}.
S CTC-C-SH
.4.5.6.7
Oooo
O 20000	40000
Steps
①。Ueμe> 60-
2 4 6 8
O 20000	40000
Steps
.9.87
O O ∩
—Score function
----Reparameterization
---- Stochastic backpropagation (N=I) ^
Stochastic backpropagation (N=4)
Stochastic backpropagation (N=8)
O 20000	40000
Steps
Figure 3:	Bayesian Logistic Regression with Laplacian priors
6.2 Bayesian logistic regression with Laplacian Priors
We evaluate the Laplace stochastic backpropagation estimator using a Bayesian logistic regression
model (Jaakkola & Jordan, 1997), similarly to (Mohamed et al., 2019). In our case, we substitute the
normal prior and posterior on the weights with Laplace priors and posteriors. We adopt the same
notations of (Murphy, 2012), where the data, target and weight variables are respectively: xn ∈ Rd ,
yn ∈ {-1, 1}, and w. The probabilistic model in our case is the following:
d
p(w) =	L(wj, 0, 1)	p(y|x,w) = σ(yxTw),	(25)
j=1
where σ represents the sigmoid function. We consider Laplacian variational posteriors of the form
pθ(W) = Qd=1 L(wj, μj, bj), with θ = {μ, b}. The evidence lower bound of a single sample is
given by:
L(Xn,yn；θ) = Ew〜Pθ [logσ(ynxTw)] - DKL[Pθ|[p],	(26)
where the Kullback-Leibler divergence between the two Laplace distributions is the following:
& (	- lμjl	]
Dkl [Pθ ||p] =	M|+bje-bj TOg bj- 1 1
j=1
(27)
We test the model on the UCI women’s breast cancer dataset (Dua & Graff, 2017), with a batch size
of 64 and 50 samples from the posterior to evaluate the expectation. In the case of the stochastic
backpropagation estimator we truncate the infinite series for the scale parameter b of equation 19
to N = 4 and N = 8. In figure 3, we report the training evidence lower bound, the log variance
of the gradient, and the accuracy computed on the entire dataset for the different estimators. The
stochastic backpropagation estimator converges faster than the considered estimators and the variance
is significantly lower. We also notice that the truncation level of the infinite series for the scale
parameter has little effect on the outcome. In figure 4, we report the bias and variance of the estimator
at different values of the truncation level, for a fixed parameter value during the training phase
(epoch=100). The bias and variance do not vary much, with the truncation level in this case, this
7
Under review as a conference paper at ICLR 2021
0.0015
⅛j 0.0010
0.0005
Score function
Reparameterization
e0.10
I 0.05
truncation level
6000
Steps
8000	10000
Figure 4: (Left) Bias and variance of the gradient for different values of the truncation level at a fixed
parameter value. (Right-top) Mean square error between the Laplace gradient estimator and the score
function and reparameterization estimators across iterations. (Right-bottom) Norm of the gradient
estimators.
result confirms the intuition of neglecting higher frequencies presented in section 5. In addition, we
compare the mean squared error between the Laplace stochastic backpropagation estimator and the
score function and reparameterization estimators. As shown in figure 4 the mean squared error is
small, thus the values of the gradients across iterations are close. However, the reparameterization
gradient is closer to our estimator than the score function gradient, probably due to the fact that the
reparameterization gradient is more stable and has lower variance.
7	Related work & Discussion
Computing gradients through stochastic computation graphs has received considerable attention from
the community, due to its application in many fields. The first general approach that provides a closed
form solution for any probability distribution is the score function method (Glynn, 1989; Williams,
1992; Sutton et al., 2000; Schulman et al., 2015). The main inconvenience of this approach, is that
it results in high variance gradients when the dimension of the random variable becomes high. In
order to bypass this issue, the second approach consisted of designing control variates to reduce the
variance of the score function estimator (Paisley et al., 2012; Weaver & Tao, 2013; Mnih & Gregor,
2014; Ranganath et al., 2014; Tokui & Sato, 2017). In addition to the score function gradient, it
was proposed to use an importance weighted estimator instead of the classical score function with a
multi-sample objective (Mnih & Rezende, 2016; Burda et al., 2015).
The second class of approaches is that concerning reparameterization tricks (Kingma & Welling, 2013;
Rezende et al., 2014). Through the decoupling of the computation of the gradient from the expectancy,
reparameterization tricks have shown that they provide low-variance gradients using often a single
sample. The issue for these methods is the necessity to find a reparameterization for each probability
distribution. Certain distributions such as the Gaussian are easy to reparametrize but others like
the gamma are not. In addition, discrete random variables do not admit an easy reparameterization
as well. Recently, these issues has been partially solved through implicit reparameterization, the
generalized reparameterization gradient, and the pathwise gradient (Ruiz et al., 2016; Figurnov
et al., 2018; Jankowiak & Obermeyer, 2018). For the discrete case, continuous relaxations that are
reparameterizable have been proposed and combined with control variate methods (Gu et al., 2016;
Maddison et al., 2016; Jang et al., 2016; Tucker et al., 2017; Grathwohl et al., 2018).
Our approach, in contrast provides a new broad family of stochastic backpropagation rules derived
using the Fourier transform. One interesting aspect of our approach is the fact that the weighting an
is separated from the expectation of the higher order derivatives of the function f . Thus the sampled
variable does not intervene in the weighting in contrast to other methods such as reparameterization
and pathwise gradients. In addition, if the function f contains weakly correlated terms, by applying
the derivative, some random variables would be eliminated. Thus the estimators of the higher order
derivatives would be sampled with respect to the derivation variable (and other correlated variables),
which would result in lower variance.
It is worth noting that deriving stochastic backpropagation rules using the Fourier transform has been
proposed for the Gaussian case (Fellows et al., 2018). In our work, we extend it to non Gaussian
distributions by way of the characteristic function, and exploiting the invariance of the functional
inner product under Fourier transformation (Parseval’s theorem).
8
Under review as a conference paper at ICLR 2021
8	Conclusion
In conclusion, in this paper we presented a new method to compute gradients through random variables
for any probability distribution, by explicitly transferring the derivative to the random variable using
the Fourier transform. Our approach, gives a framework to be applied for any distribution, where the
gradient of the log characteristic function is analytic, resulting in a new broad family of stochastic
backpropagation rules, that are unique for each distribution.
References
Kavosh Asadi, Cameron Allen, Melrose Roderick, Abdel-rahman Mohamed, George Konidaris,
Michael Littman, and Brown University Amazon. Mean actor critic. stat, 1050:1, 2017.
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. arXiv
preprint arXiv:1509.00519, 2015.
Yulai Cong, Miaoyun Zhao, Ke Bai, and Lawrence Carin. Go gradient for expectation-based
objectives. arXiv preprint arXiv:1901.06020, 2019.
Dheeru Dua and Casey Graff. UCI machine learning repository, 2017. URL http://archive.
ics.uci.edu/ml.
Matthew Fellows, Kamil Ciosek, and Shimon Whiteson. Fourier policy gradients. arXiv preprint
arXiv:1802.06891, 2018.
Mikhail Figurnov, Shakir Mohamed, and Andriy Mnih. Implicit reparameterization gradients. In
Advances in Neural Information Processing Systems, pp. 441-452, 2018.
Peter W Glynn. Optimization of stochastic systems via simulation. In Proceedings of the 21st
conference on Winter simulation, pp. 90-105, 1989.
Will Grathwohl, Dami Choi, Yuhuai Wu, Geoff Roeder, and David Duvenaud. Backpropagation
through the void: Optimizing control variates for black-box gradient estimation. 2018.
Shixiang Gu, Sergey Levine, Ilya Sutskever, and Andriy Mnih. Muprop: Unbiased backpropagation
for stochastic neural networks. 2016.
Tommi Jaakkola and Michael Jordan. A variational approach to bayesian logistic regression models
and their extensions. In Sixth International Workshop on Artificial Intelligence and Statistics,
volume 82, 1997.
Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with gumbel-softmax. arXiv
preprint arXiv:1611.01144, 2016.
Martin Jankowiak and Theofanis Karaletsos. Pathwise derivatives for multivariate distributions. In
The 22nd International Conference on Artificial Intelligence and Statistics, pp. 333-342, 2019.
Martin Jankowiak and Fritz Obermeyer. Pathwise derivatives beyond the reparameterization trick. In
International Conference on Machine Learning, pp. 2235-2244, 2018.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114, 2013.
Brenden M Lake, Russ R Salakhutdinov, and Josh Tenenbaum. One-shot learning by inverting a
compositional causal process. In Advances in neural information processing systems, pp. 2526-
2534, 2013.
Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010. URL http://yann.
lecun.com/exdb/mnist/.
9
Under review as a conference paper at ICLR 2021
Chris J Maddison, Andriy Mnih, and Yee Whye Teh. The concrete distribution: A continuous
relaxation of discrete random variables. 2016.
Andriy Mnih and Karol Gregor. Neural variational inference and learning in belief networks.
In Proceedings of the 31st International Conference on International Conference on Machine
Learning-Volume 32,pp. II-1791, 2014.
Andriy Mnih and Danilo J Rezende. Variational inference for monte carlo objectives. arXiv preprint
arXiv:1602.06725, 2016.
Volodymyr Mnih, Nicolas Heess, Alex Graves, et al. Recurrent models of visual attention. In
Advances in neural information processing systems, pp. 2204-2212, 2014.
Shakir Mohamed, Mihaela Rosca, Michael Figurnov, and Andriy Mnih. Monte carlo gradient
estimation in machine learning. arXiv preprint arXiv:1906.10652, 2019.
Kevin P Murphy. Machine learning: a probabilistic perspective. MIT press, 2012.
CA Naesseth, FJR Ruiz, SW Linderman, and DM Blei. Reparameterization gradients through
acceptance-rejection sampling algorithms. In Proceedings of the 20th International Conference on
Artificial Intelligence and Statistics, AISTATS 2017, 2017.
Radford M Neal. Connectionist learning of belief networks. Artificial intelligence, 56(1):71-113,
1992.
John Paisley, David Blei, and Michael Jordan. Variational bayesian inference with stochastic search.
arXiv preprint arXiv:1206.6430, 2012.
Rajesh Ranganath, Sean Gerrish, and David Blei. Black box variational inference. In Artificial
Intelligence and Statistics, pp. 814-822. PMLR, 2014.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and
approximate inference in deep generative models. In International Conference on Machine
Learning, pp. 1278-1286, 2014.
Francisco R Ruiz, Michalis Titsias RC AUEB, and David Blei. The generalized reparameterization
gradient. In Advances in neural information processing systems, pp. 460-468, 2016.
Xavier Saint Raymond. Elementary introduction to the theory of pseudodifferential operators,
chapter 1, pp. 2-3. Routledge, 2018.
John Schulman, Nicolas Heess, Theophane Weber, and Pieter Abbeel. Gradient estimation using
stochastic computation graphs. In Advances in Neural Information Processing Systems, pp. 3528-
3536, 2015.
Richard S Sutton, David A McAllester, Satinder P Singh, and Yishay Mansour. Policy gradient meth-
ods for reinforcement learning with function approximation. In Advances in neural information
processing systems, pp. 1057-1063, 2000.
Michalis Titsias and Miguel Lazaro-Gredilla. Doubly stochastic variational bayes for non-conjugate
inference. In International conference on machine learning, pp. 1971-1979, 2014.
Michalis Titsias and Miguel Lazaro-Gredilla. Local expectation gradients for black box variational
inference. In Advances in neural information processing systems, pp. 2638-2646, 2015.
Seiya Tokui and Issei Sato. Evaluating the variance of likelihood-ratio gradient estimators. In
International Conference on Machine Learning, pp. 3414-3423, 2017.
George Tucker, Andriy Mnih, Chris J Maddison, John Lawson, and Jascha Sohl-Dickstein. Rebar:
Low-variance, unbiased gradient estimates for discrete latent variable models. In Advances in
Neural Information Processing Systems, pp. 2627-2636, 2017.
Lex Weaver and Nigel Tao. The optimal reward baseline for gradient-based reinforcement learning.
arXiv preprint arXiv:1301.2315, 2013.
Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement
learning. Machine learning, 8(3-4):229-256, 1992.
10
Under review as a conference paper at ICLR 2021
Dataset	Model	REBAR	RELAX	BSB (S=1)	BSB (S=5)	BSB (S=10)
	one layer SBN	-114.14 ± 0.44	-114.55 ± 0.48	-110.87 ± 0.2	-110.70 ± 0.11	-110.59 ± 0.08
MNIST	two layer SBN	-101.33 ± 0.04	-101.09 ± 0.07	-99.74 ± 0.3	-100.44 ± 0.28	-100.66 ± 0.21
	Bern. VAE	-127.76 ± 0.84	-128.06 ± 2.66	-107.4 ± 1.47	-108.46 ± 0.37	-109.19 ± 1.31
	one layer SBN	-123.66 ± 0.05	-123.82 ± 0.17	-113.53 ± 0.21	-114.34 ± 0.16	-114.37 ± 0.19
Omniglot	two layer SBN	-117.81 ± 0.17	-117.89 ± 0.04	-102.05 ± 0.19	-102.16 ± 0.09	-102.29 ± 0.14
	Bern. VAE	-136.83 ± 0.31	-136.53 ± 0.32	-126.94 ± 0.81	-128.69 ± 0.34	-129.48 ± 0.38
Table 1: Test likelihood for the Bernoulli stochastic backpropagation (BSB) estimator compared to
the REBAR and RELAX estimators. We report the mean and standard deviation over 5 runs.
A The Dirac Distribution: the link between neural networks and
PROBABILISTIC GRAPHICAL MODELS
Figure 5: A hidden variable probabilistic model, where the observed variables are the data x and
target y, with L hidden stochastic layers h(1:L) .
In this section, we explore the connection between neural networks and probabilistic graphical models
following from the stochastic backpropagation rule of the Dirac delta distribution. To this end, let us
consider the probabilistic graphical model of figure 5. The observed random variables in this model
are denoted x and y representing the data and target variables. We place the analysis in a supervised
learning context, but the argument is valid for unsupervised models as well. As usual the goal is
to maximize the log likelihood for the data samples (x, y), which is intractable, given that we need
to integrate over the hidden variables. However using variational inference, we can maximize an
evidence lower bound of the form:
L(θ;x,y) = Eh(LL)〜qθ(∙∣x) [logp(y,h(1:L),x)i + H[qθ(∙∣x)]	(28)
As suggested in the Dirac stochastic backpropagation rule, let us assume that the variational posteriors
and priors are Dirac delta distribution of the form:
qθ(h(I+I)Ih(I))= p(h(I+I)Ih(I)) = δa(i+υ(w(i+i)Th(i)+b(i))(h(I+1))	VO ≤ l ≤ L - 1	(29)
where, the a(l), W(l), and b(l) represent respectively the activation functions, the weights and biases
for layer l, with the convention x := h(0) . Under these assumptions, the Kullback-Leibler divergence
term is equal to zero, and the evidence lower bound reduces to the the log-likelihood of a classical
neural network:
L(θ; x, y) = logp(yIgθ(x)),	with,	gθ (x) = a(L) (W (L) ( a(1) (W (1)x + b(1))...)
Thus, when using neural networks we are indirectly using a probabilistic graphical model and making
the strong assumption that the hidden layers follow a parameterized Dirac distribution knowing the
previous layer.
B Experiments using discrete stochastic backpropagation
We evaluate the Bernoulli and Categorical Stochastic Backpropagation estimators (BSB and CSB)
of equations 17 and 18 on standard generative modeling benchmark tasks, using the MNIST and
Omniglot datasets (LeCun & Cortes, 2010; Lake et al., 2013). We use the REBAR, RELAX,
and Gumbel-softmax (or Concrete) estimators as baselines for our comparison (Jang et al., 2016;
Maddison et al., 2016; Tucker et al., 2017; Grathwohl et al., 2018). The Bernoulli stochastic
backpropagation is compared to the REBAR and RELAX estimators for three models: the sigmoid
belief network of one and two stochastic hidden layers (Neal, 1992) and the variational autoencoder.
11
Under review as a conference paper at ICLR 2021
One Layer SBN	Two Layer SBN
'0OOQoQQ
0 1 2 3 4 5 6
1111111
-------
(S 6u-u-l
auφ-pe"©£ jo 8u--e> 60-
O 20000 40000 60000 80000 IOOOOO120000
Steps
-170
0	20000 40000 60000 80000 100000120000
Steps
——BSB (S=I)
——BSB (S=5)
——BSB (S=IO)
REBAR
——RELAX
auφ-pe"©£ jo 8u--e> 60-
O 20000 40000 60000 80000 IOOOOO120000
Steps
(a 6~~al
Bern. VAE
20000 40000 60000 80000 100000 120000
Steps
auφ-pe"©£°φuu---e> 60-
20000 40000 60000 80000 100000120000
Steps

Figure 6: The training evidence lower bound on the MNIST training set (top) and the log variance of
the gradient (bottom) over 5 runs. Comparison with the REBAR and RELAX estimators.
Dataset	Model	Gumbel-softmax	CSB (S=1)	CSB (S=5)	CSB (S=10)
MNIST	one layer	-113.46 ± 0.59	-107.48 ± 0.37	-107.24 ± 0.31	-107.33 ± 0.13
	Cat. VAE	-122.97 ± 5.68	-103.49 ± 0.73	-102.68 ± 0.63	-101.78 ± 0.88
Omniglot	one layer	-125.76 ± 0.24	-122.49 ± 0.80	-122.98 ± 0.30	-122.98 ± 0.21
	Cat. VAE	-140.25 ± 1.99	-130.20 ± 004	-131.66 ± 0.84	-131.63 ± 1.05
Table 2: Test likelihood for the categorical stochastic backpropagation (CSB) estimator, compared to
the Gumbel-softmax estimator. We report the mean and standard deviation over 5 runs.
In this case, we adopt the same architectures as (Grathwohl et al., 2018). The categorical stochastic
backpropagation estimator is compared to the Gumbel-softmax estimator (Maddison et al., 2016;
Jang et al., 2016) using two models: a variational autoencoder and a single layer belief network with
categorical priors. In this case, we set the dimension of the hidden layer to d = 20 and the number of
modalities for each dimension to K = 10.
All models are trained using the ADAM optimizer (Kingma & Ba, 2014) using a standard learning rate
α = 10-4 and batch size of 100. We train the models for 500 epochs on the MNIST dataset and 100
epochs on the Omniglot dataset, longer learning epochs leads to overfitting and lower performance
on the test sets for all estimators and models. We perform 5 iterations of training in all experiments
and we report the mean and standard deviation of each performance metric considered.
For all models and estimators, we report the mean marginal test likelihood in tables 1 and 2 for
both datasets. The test likelihood is estimated via importance sampling using 200 samples from the
variational posterior. In all cases the stochastic backpropagation estimator, a control variate free
method outperforms the baselines. In the case of the one layer sigmoid belief network the BSB
estimator exhibits an increase of performance of about 4 nats in the case of the MNIST dataset and
10 nats in the case of the Omniglot dataset. We also vary the number of samples used to estimate
the expectation in the stochastic backpropagation rule S ∈ {1, 5, 10}. We notice that using a single
sample estimate does not hurt performance and leads to a faster training process.
We estimate the mean variance of the gradients w.r.t the parameters of the models using exponential
moving averages of the first and second moments computed by the ADAM optimizer. The BSB
estimator significantly outperforms the REBAR, RELAX estimators in terms of variance reduction
with a difference of about 2 nats in the case of sigmoid belief networks, and 1 nat in the case of the
categorical variational autoencoder on the mnist dataset, leading to a more stable training process as
shown in figures 6 and 7.
Finally, we evaluate the computational overhead of the categorical stochastic backpropagation
estimator compared the Gumbel-softmax estimator. We compare the two estimators in terms of
execution time of one epoch of training. The comparison is done using GPU implementations on
12
Under review as a conference paper at ICLR 2021
(36u-≡ejl
Figure 7: Training evidence lower bound and the log vari-
ance of the gradient for the categorical VAE on the MNIST
dataset.
Model	GS	CSB (S=1)	CSB (S=5)	CSB (S=10)
one Linear layer	4.11 (s)	6.32 (s)	10.93 (s)	16.83 (s)
Cat. VAE	4.13 (s)	7.32 (s)	13.29 (s)	21.94 (s)
Table 3: Execution time of one epoch
of training on the mnist dataset per es-
timator, per model.
a NVIDIA GeForce RTX 2080 Ti GPU, where the stochastic backpropagation rule of equation
equation 18 is vectorized, thus leveraging the parallel batch treatment of the GPU. As shown in table
3, the Gumbel-softmax method is faster than stochastic backpropagation (S = 1) by a difference of
about 3 seconds per training epoch. This is due to the forward passes performed to compute each of
the terms in equation equation 18. The variance reduction and the increase in performance outweigh
however the computational cost.
13