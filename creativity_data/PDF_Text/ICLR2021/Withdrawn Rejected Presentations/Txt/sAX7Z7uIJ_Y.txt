Under review as a conference paper at ICLR 2021
Calibrated	Adversarial	Refinement for
Stochastic Semantic Segmentation
Anonymous authors
Paper under double-blind review
Ab stract
Ambiguities in images or unsystematic annotation can lead to multiple valid so-
lutions in semantic segmentation. To learn a distribution over predictions, recent
work has explored the use of probabilistic networks. However, these do not neces-
sarily capture the empirical distribution accurately. In this work, we aim to learn a
multimodal predictive distribution, where the empirical frequency of the sampled
predictions closely reflects that of the corresponding labels in the training set. To
this end, we propose a novel two-stage, cascaded strategy for calibrated adversar-
ial refinement. In the first stage, we explicitly model the data with a categorical
likelihood. In the second, we train an adversarial network to sample from it an
arbitrary number of coherent predictions. The model can be used independently
or integrated into any black-box segmentation framework to facilitate learning of
calibrated stochastic mappings. We demonstrate the utility and versatility of the
approach by attaining state-of-the-art results on the multigrader LIDC dataset and
a modified Cityscapes dataset. In addition, we use a toy regression dataset to show
that our framework is not confined to semantic segmentation, and the core design
can be adapted to other tasks requiring learning a calibrated predictive distribution.
1	Introduction
Real-world datasets are often riddled with ambiguities, allowing for multiple valid solutions for
a given input. These can emanate from an array of sources, such as ambiguous label space (Lee
et al., 2016), sensor noise, occlusions, and inconsistencies or errors during manual data annotation.
Despite this problem, the majority of the research encompassing semantic segmentation focuses on
optimising models that assign a single prediction to each input image (Ronneberger et al., 2015;
JggoU et al., 2017; TakikaWa et al., 2019; Chen et al., 2017a;b; 2016a;b; 2015). These are often
incapable of capturing the entire empirical distribution of outputs. Moreover, since they optimise for
a one-fits-all solUtion, noisy labels can lead to incoherent predictions and therefore compromise their
reliability (Lee et al., 2016).
Ideally, in sUch sitUations one WoUld Use a model that can sample mUltiple consistent hypotheses,
captUring the different modalities of the groUnd trUth distribUtion, and leverage Uncertainty information
to identify potential errors in each. FUrther, the sampled predictions shoUld accUrately reflect the
occUrrence freqUencies of the labels in the training set; that is, the predictive distribUtion shoUld
be calibrated (GUo et al., 2017; KUll et al., 2019). SUch a system WoUld be particUlarly UsefUl for
hypothesis-driven reasoning in hUman-in-the-loop semi-aUtomatic settings. For instance, large scale
manUal annotation of segmentation map is very laboUr-intensive—each label in the Cityscapes dataset
takes on average 1.5 hoUrs to annotate (Cordts et al., 2016). Alternatively, having a hUman operator
manUally selecting from a set of aUtomatically generated label proposals coUld accelerate this process
dramatically. In addition, combining Uncertainty estimates With sampling of self-consistent labels,
can be Used to focUs the annotator’s attention to ambigUoUs regions, Where errors are likely to occUr,
thereby improving safety.
Several approaches have been proposed to captUre label mUltimodality in image-to-image translation
tasks (HUang et al., 2018; Lee et al., 2018; ZhU et al., 2017a; Bao et al., 2017; Zhang, 2018), With only
a feW of them applied on stochastic semantic segmentation (Kohl et al., 2018; 2019; BaUmgartner
et al., 2019; HU et al., 2019; Kamnitsas et al., 2017; RUpprecht et al., 2017; Bhattacharyya et al.,
2018). These methods have the capacity to learn a diverse set of labels for each inpUt, hoWever, they
1
Under review as a conference paper at ICLR 2021
are either limited to a fixed number of samples (Kamnitsas et al., 2017; Rupprecht et al., 2017), return
uncalibrated predictions, or do not account for uncertainty.
In this work, we tackle all three challenges by introducing a two-stage cascaded strategy. In the first
stage we estimate pixelwise class probabilities and in the second, we sample confident predictions,
calibrated relatively to the distribution predicted in the first stage. This allows us to obtain both
uncertainty estimates as well as self-consistent label proposals. The key contributions are 1:
•	We propose a novel cascaded architecture that constructively combines explicit likelihood
modelling with adversarial refinement to sample an arbitrary number of confident, and
self-consistent predictions given an input image.
•	We introduce a novel loss term that facilitates learning of calibrated stochastic mappings
when using adversarial neural networks. To our knowledge this is the first work to do so.
•	The proposed model can be trained independently or used to augment any pretrained black-
box semantic segmentation model, endowing it with a multimodal predictive distribution.
2	Related work
Straightforward strategies towards learning multiple predictions include ensembling (Lakshmi-
narayanan et al., 2017; Kamnitsas et al., 2017) or using multiple prediction heads (Rupprecht
et al., 2017). Even though these approaches can capture a diverse set of sampled predictions, they are
limited to only a fixed number of samples. Alternatively, a probability distribution over the outputs
can be induced by activating dropout during test time (Gal and Ghahramani, 2016a). This method
does offer useful uncertainty estimates over the pixel-space (Mukhoti and Gal, 2018), however, Isola
et al. (2017) and Kohl et al. (2018) have demonstrated that it introduces only minor stochasticity in
the output and returns incoherent samples.
Bhattacharyya et al. (2018) identify the maximum likelihood learning objective as the cause for this
phenomenon in dropout Bayesian neural networks (Gal and Ghahramani, 2016b). They postulate that
under cross entropy optimisation, all sampled models are forced to explain all the data, and thereby
converge to the mean solution. To counter that, they propose to replace the cross entropy with and
adversarial loss term parametrising a synthetic likelihood (Rosca et al., 2017), thereby making it
conducive to multimodality. In contrast to this method, our approach is simpler to implement as it is
not cast in the framework of variational Bayes, which requires the specification of weight priors and
variational distribution family.
Kohl et al. (2018) take an orthogonal approach in combining a U-Net (Ronneberger et al., 2015) with
a conditional variational autoencoder (cVAE) (Kingma and Welling, 2013) to learn a distribution over
semantic labels. In Kohl et al. (2019) and Baumgartner et al. (2019) the authors build on Kohl et al.
(2018) to improve the diversity of the samples by modelling the data on several scales of the image
resolution. Nonetheless, these methods do not explicitly calibrate the predictive distribution in the
pixel-space, and consequently do not provide reliable aleatoric uncertainty estimates (Kendall and
Gal, 2017; Choi et al., 2018; Gustafsson et al., 2019). Hu et al. (2019) address this shortcoming by
using the intergrader variability as additional supervision. A major limitation of this approach is the
requirement of a-priori knowledge of all the modalities of the data distribution. For many real-world
datasets, however, this information is not readily available.
In the more general domain of image-to-image translation, alternative methods employ hybrid models
that use adversarially trained cVAEs (Zhu et al., 2017a; Bao et al., 2017) to learn a distribution over a
latent code, capturing multimodality, in order to sample diverse and coherent predictions. A common
hurdle in conditional generative adversarial network (cGAN) approaches is that simply incorporating
a noise vector as an additional input often results in mode collapse. This occurs due to the lack
of regularisation between the noise input and generator output, allowing the generator to learn to
ignore the noise vector (Isola et al., 2017). This issue is commonly resolved by using supplementary
cycle-consistency losses (Huang et al., 2018; Lee et al., 2018; Zhu et al., 2017a; Bao et al., 2017), as
proposed by Zhu et al. (2017b) or with alternative regularisation losses on the generator (Yang et al.,
2018). However, none of these methods explicitly address the challenge of calibrating the predictive
distribution.
1Code is publicly available at <URL OMITTED FOR ANONYMITY>
2
Under review as a conference paper at ICLR 2021
3	Preliminaries
Given an input image x ∈ RH×W ×C,
wise class label y ∈ {1, . . . , K}H×W
semantic segmentation refers to the task of predicting a pixel-
. For a dataset of N image and label pairs, D = {xi, yi}iN=1,
the conditional distribution pD(y | x) can be explicitly modelled through a likelihood qθ(y | x),
parametrised by a convolutional neural network F with weights θ, and activated by a softmax func-
tion (Ronneberger et al., 2015; JegoU et al., 2017). One simple, yet effective way to learn the class
probabilities is to express y ∈ {0, 1}H ×W ×K as a one-hot encoded label, and set qθ as a pixelwise
factorised categorical distribUtion, given by:
HWK
qθ (y I X) = YYY Fθ (χ)j.	(1)
ij k
The parameters θ are then optimised by minimising the cross entropy between pD and qθ, defined as:
Lce(D, θ) = -EpD(x,y)[log qθ(y | x)].
(2)
When trained with Eq. (2), Fθ learns an approximation of EpD [y | x] (Bishop, 2006) that captUres
the pixelwise class probabilities over the label corresponding to a given inpUt. This accommodates
the qUantification of the amoUnt of noise inherent to the data, also referred to as aleatoric Uncertainty,
which can be obtained by compUting the entropy of the oUtpUt of Fθ, H(Fθ (x)) (Kendall and Gal,
2017). FUrther, the final segmentation map is typically obtained by applying the argmax fUnction
along the class dimension of the predicted probabilities. However, dUe to its deterministic natUre, this
approach is Unable to prodUce mUltiple alternative predictions for the same inpUt image. On the other
hand, direct sampling from qθ yields incoherent semantic maps, as for noisy datasets, maximising the
factorised likelihood resUlts in Unconfident predictions in regions of inter-label inconsistencies, e. g.
fUzzy object boUndaries, exemplified later in the model overview diagram in Fig. 1.
The aforementioned limitations can be partially addressed by adapting the framework of generative
adversarial networks (GANs) (Goodfellow et al., 2014) to the context of conditional semantic
segmentation, as proposed by LUc et al. (2016). Formally, this involves training a binary discriminator
network D to optimally distingUish between groUnd trUth and predictions, while concUrrently training
a generative network G to maximise the probability that prediction samples G(x) are perceived as
real by D. Importantly, in contrast to explicit pixelwise likelihood maximisation, the adversarial
setUp learns an implicit sampler throUgh G, capable of modelling the joint pixel configUration of the
synthesised labels, and captUring both local and global consistencies present in the groUnd trUth.
In practice, the generator loss is often complemented with the pixelwise loss from Eq. (2) to improve
training stability and prediction qUality (LUc et al., 2016; Ghafoorian et al., 2018; Samson et al., 2019).
However, we argUe that the two objective fUnctions are not well aligned in the presence of noisy data.
While the categorical cross entropy optimises for a single solUtion for each inpUt x, thUs encoUraging
high entropy in qθ(y | x) within noisy regions of the data and calibrating the predictive distribUtion,
the adversarial term allows mUltiple solUtions while optimising for low entropy, label-like oUtpUt.
Therefore combining these losses in an additive manner, and enforcing them on the same set of param-
eters can be sUboptimal. This issUe can be mitigated to some extent by a schedUled downscaling of
Lce , however, the residUal conflict between the two losses adversely affects the optimisation process.
4	Method
4.1	Calibrated adversarial refinement
In this work, we propose to avert potential conflict between the cross entropy and adversarial losses
by decoUpling them in a two-stage cascaded architectUre consisting of a calibration network Fθ
optimised with Lce from Eq. (2), the oUtpUt of which is fed to a refinement network Gφ . Gφ is
then optimised with an adversarial loss term, parametrised by an aUxiliary discriminator Dψ trained
with a binary cross entropy loss. To accoUnt for the mUltimodality in the labels, we additionally
condition the refinement network on an extraneous noise variable E 〜N(0,1). In practice, we
also condition the refinement network and the discriminator on inpUt x, however, we do not show
this explicitly for notational convenience. More formally, using the non-saturated version of the
3
Under review as a conference paper at ICLR 2021
Figure 1: Model overview with an illustrative example where red and blue pixels are vertically
segmented. A fuzzy boundary in the input image x allows for multiple valid ground truth labels yi .
First, the calibration network maps the input to a calibrated pixelwise distribution over the labels.
This is then fed into the refinement network which samples an arbitrary number of diverse, crisp label
proposals yr1ef, . . . , yrMef. To ensure calibration, the average of the final predictions is matched with the
calibration target from the first stage through the Lcal loss. Additionally, the aleatoric uncertainty can
be readily extracted from the calibration target, e. g. by computing the entropy H(Fθ(x)).
adversarial loss (Goodfellow et al., 2014), the objectives for the refinement and discriminator networks
respectively are given by:
Ladv(D, θ, φ) = -EpD(x,y),p()[log Dψ(Gφ(Fθ(x), ))],	(3)
LD(D, θ, φ, ψ) = -EpD(x,y),p()[log (1 - Dψ(Gφ(Fθ(x), ))) + log Dψ(y)].	(4)
To calibrate the predictive distribution, we impose diversity regularisation on Gφ by introducing a
novel loss term that encourages the sample average Gφ(Fθ(x)) := Ep(e)[Gφ(Fθ(x), e)] to match the
class probabilities predicted by Fθ (x). Here, Gφ(Fθ (x)) serves as an approximation of the implicit
predictive distribution of the refinement network. To this end, we define an auxiliary fully-factorised
categorical likelihood qφ as:
HWK
qφ(y | Fθ (x)) = YYY GΦ(Fθ (χ))y,jkk,	⑸
ij k
where φ is optimised by minimising the Kullback-Leibler divergence KL(qφ || qθ).2 Since both qφ
and qθ are categorical distributions, the divergence can be computed exactly. We coin this loss term
as the calibration loss, defined as:
Lcal (D, θ, φ) = EpD Eqφ [log qφ (y | Fθ(x)) - logqθ(y | x)].	(6)
Since Lcal optimises through Gφ(Fθ(x)) rather than a single sampled prediction, the model is not
restricted to learning a single mode-averaging solution for each input x, and is therefore more
compatible with Ladv . The total loss for the refinement network then becomes:
LG(D, θ, φ) = Ladv(D, θ, φ) + λLcal(D, θ, φ),	(7)
where λ ≥ 0 is an adjustable hyperparameter. Fig. 1 shows the interplay of Fθ, Gφ and Dψ and the
corresponding loss terms.
Intuitively, the calibration network Fθ serves three main purposes. It accommodates the extraction of
sample-free aleatoric uncertainty maps. It provides Gφ with an augmented representation of x enclos-
ing probabilistic information about y. Finally, it sets a calibration target used by Lcal to regularise the
2The choice of divergence is heuristically motivated and can be changed to fit different use-case requirements.
We delegate theoretical and experimental analysis of other divergences to future work.
4
Under review as a conference paper at ICLR 2021
predictive distribution of Gφ, in a cycle-consistent manner (Zhu et al., 2017b). The refinement net-
work can then be interpreted as a stochastic sampler, modelling the inter-pixel dependencies to draw
self-consistent samples from the explicit likelihood provided by the calibration network. Thus both
the pixelwise class probability and object coherency are preserved. This approach leads to improved
mode coverage and training stability, and increased convergence speed, as demonstrated in Section 5.
4.2	Practical considerations
An important consequence of the loss decomposition is that the weights of Fθ can be kept fixed,
while the adversarial pair Gφ and Dψ are being trained. This allows Fθ to be pretrained in isola-
tion, consequently lowering the overall peak computational burden and improving training stability
(See Algorithms 1 and 2 in Appendix A.1 for an outline of the training and inference procedures).
Further, computing LCal requires a Monte Carlo estimation of Gφ (Fθ (x)), where the quality of the
loss feedback increases with the sample count. However, modern deep learning frameworks allow
for the samples to be subsumed in the batch dimension, and can therefore be efficiently computed
on GPUs. We also note that on noisy data points, the trained model does not require to be provided
with all solutions for a given input. Instead, during training a random input-label pair is sampled,
and the model automatically learns to identify cases where the input is ambiguous. Finally, our
method can augment any existing black-box model B for semantic segmentation, furnishing it with a
multimodal predictive distribution. This can be done by conditioning Fθ on the output of B, which
we demonstrate in Section 5.2.2.
5	Experiments
5.1	1D bimodal regression
We give intuitive insight into the mechanics of the proposed calibration loss by designing and
experimenting on a simple one-dimensional regression task. To create the dataset, an input x ∈ [0, 1]
is mapped to y ∈ R as follows:
，.5 - b + 3	X ∈ [0, 0.4)
y=	(-1)b(-1.25x + 1) + , x∈ [0.4, 0.8)	(8)
、3	x ∈ [θ.8,1]
where b 〜BernoUlli(π) and e 〜N(0, σ). We generate 9 different scenarios by varying the degree
of mode selection probability π ∈ {0.5, 0.6, 0.9} and the mode noise σ ∈ {0.01, 0.02, 0.03}.
0.6-
0.4-
0.2-
A 0.0-
-0.2-
-0.4-
-0.6-
(b)
Fθ (X)
——Gφ (Fθ (X))
Gφ (Fθ (X), e)
POOqHZHIgOI-Ep ①怜
(a)
0.2	0.4	0.6	0.8
X
(C)
Figure 2: (a) Median and interquartile range (iqr) over the data log-likelihood, averaged over all
9×5×2 experiments. (b) High bias and noise configuration (π = 0.9, σ = 0.03) with calibration
loss. The ground truth target is shown as black dots and the predicted samples as light blue dots.
The predictions average in dark blue matches the calibration target in red. The discriminator output
is shown in the background in shades of red (real) and blue (fake). (c) The same experiment
configuration but without the proposed calibration loss, resulting in a mode collapse.
5
Under review as a conference paper at ICLR 2021
For every data configuration, we use a 4-layer MLP for each of Fθ, Gφ and Dψ, and train with and
without calibration loss by setting the coefficient λ in Eq. (7) to 1 or 0, respectively. All runs are
trained with a learning rate of 1e-4, and each experiment is repeated five times. Note that unlike the
categorical likelihood used in semantic segmentation tasks, we employ a Gaussian likelihood with
fixed scale of 1. This changes the formulation of both Eqs. (2) and (6) to mean squared error losses
between ground truth labels y and predictions y for £巨 and between the output of the calibration
network Fθ (x) and the average of multiple predictions Gφ (F⅛ (x)) for LCal (see Appendix A.2).
The results, depicted in Fig. 2, illustrate that when using calibration loss, the optimisation process
shows improved stability, converges faster and results in better calibrated predictions, in comparison
to the non-regularised baseline. The effect is more pronounced in data configurations with higher
bias. Further plots of the individual experiments are presented in Appendix B.1.
5.2	Stochastic semantic segmentation
In this section we examine the capacity of our model to learn shape and class multimodality in
real-world segmentation datasets. We begin by sharing essential implementation details below.
Network architectures For the calibration network Fθ, we use the encoder-decoder architecture
from SegNet (Badrinarayanan et al., 2017). For Gφ, we designed a U-Net-style (Ronneberger et al.,
2015) architecture with 4 down- and upsampling blocks, each consisting of a convolutional layer,
followed by a batch normalisation layer (Ioffe and Szegedy, 2015), a leaky ReLU activation, and
a dropout layer (Srivastava et al., 2014) with 0.1 dropout probability. We use a base number of 32
channels, doubled or halved at every down- and upsampling transition. To propagate the sampled
noise vector to the output, we inject it into every upsampling block of the network in an affine manner.
To do so, we project the noise vector using two fully connected layers into scale and residual matrices,
with the same number of channels as the feature maps at the points of injection, and use these matrices
to adjust the channel-wise mean and variance of the activations. This is similar to the mechanism
used for adaptive instance normalisation (Huang and Belongie, 2017). We base the architecture for
Dψ on that used in DC-GAN (Radford et al., 2015) except that we remove batch normalisation. Any
deviations from this setup are described in the corresponding sections.
Training details We utilise the Adam optimiser (Kingma and Ba, 2014) with an initial learning rate
of 2e-4 for Fθ and Gφ, and 1e-5 for Dψ. The learning rates are linearly decayed over time and we
perform scheduled updates to train the networks. Additionally, the discriminator loss is regularised
by using the R1 zero-centered gradient penalty term (Mescheder et al., 2018). For a detailed list of
hyperparameter values, see Appendix A.1.
Metrics Following Kohl et al. (2018; 2019), Huang et al. (2018) and Baumgartner et al. (2019), we
use the Generalised Energy Distance (GED) (Szekeiy and Rizzo, 2013) metric:
DG2ED(pD, qφ) =2Es 〜qφ,y 〜PD[d(s,y)] - Es,s，〜qφ [d(
s,s )] - Ey,y0~PD[d(y, y0)],	(9)
where d(s, y) = 1 - IoU(s, y). As an additional metric, we follow Kohl et al. (2019) in using the
Hungarian-matched IoU (HM-IoU) (Kuhn, 2005). In contrast to GED, which naively computes
diversity as 1-IoU between all possible pairs of ground truth or sampled predictions, HM-IoU finds
the optimal 1:1 matching between all labels and predictions, and therefore is more representative of
how well the learnt predictive distribution fits the ground truth.
All experiments are performed in triplicate and we report results as mean and standard deviation.
Further details regarding the exact implementation of the GED and HM-IoU metrics for each
experiment can be found in Appendix A.3.
5.2.1	Learning shape diversity on the LIDC dataset
The Lung Image Database Consortium (LIDC) (Armato III et al., 2011) dataset consists of 1018
thoracic CT scans from 1010 lung cancer patients, graded independently by four expert annotators.
We use the 180×180 crops from the preprocessed version of the LIDC dataset used and described
in Kohl et al. (2018). The dataset is split in 8882, 1996 and 1992 images in the training, validation
and test sets respectively. All models are trained on lesion-centered 128×128 crops where at least one
of the four annotations indicates a lesion. The final evaluation is performed on the provided test set.
6
Under review as a conference paper at ICLR 2021
Table 1: Mean GED and HM-IoU scores on LIDC. Top section: approaches using the original data splits
defined by Kohl et al. (2018), which we also adhere to; middle: approaches using random data splits;
bottom: the Lce-regularised baseline and our Lcal-regularised cGAN. The three central columns show
the GED score computed with 16, 50 and 100 samples, respectively. The rightmost column shows the
HM-IoU score, computed with 16 samples. The arrows ↑ and ] indicate if higher or lower score is better.
Method	GED1 (16)	GED 1 (50)	GED 1 (100)	HM-IoU ↑ (16)
Kohl et al. (2018)	0.320 ± 0.030	—	0.252 ± N/A1	0.500 ± 0.030
Kohl et al. (2019)	0.270 ± 0.010	—	—	0.530 ± 0.010
Hu et al. (2019)	—	0.267 ± 0.012	—	—
Baumgartner et al. (2019)	—	—	0.224±N/A2	—
cGAN+Lce	0.639 ± 0.002	—	—	0.477 ± 0.004
cGAN+Lcal	0.264 ± 0.002	0.248 ± 0.004	0.243 ± 0.0042	0.592 ± 0.005
1 This score is taken from Baumgartner et al. (2019).
2 Note that when following the data split methodology used in Baumgartner et al. (2019) and computing the
GED (100) metric, we achieve a score of 0.228 instead of 0.243 (see Appendix A.3).
Figure 3: LIDC validation samples. From left to right: an input image x, followed by the four ground
truth annotations yj ... yjt, the mean of the labels ygt, the output of the calibration network Fθ (x),
the mean of the six refinement network samples y∙ef, shown in columns y《f... y6f.
To assess the accuracy and diversity of samples generated by our model we examine how well the
learnt conditional distribution captures the shape diversity of lesion segmentations in the dataset. We
pretrain Fθ(x) with Lce in isolation, fix its weights, and then train Gφ with LG, where we estimate
Lcal with 20 samples from Gφ. Further experiments with varying sample size are disclosed in Table 3
in Appendix B.2. As a control experiment, we train using the same architecture but replace Lcal in
the refinement network loss function with a cross entropy loss Lce, as used in Luc et al. (2016).
The Lcal -regularised model performs on par with other state-of-the-art methods w. r. t. the GED score,
and outperforms them on the HM-IoU score (only available for Kohl et al. (2018; 2019)). Numerical
results are summarised in Table 1. The diversity and fidelity of sampled predictions are illustrated
in Fig. 3. In contrast, the Lce-regularised baseline collapses the predictive distribution, showing no
perceptible diversity in the samples (see Fig. 10b in Appendix B.2.3), which results in a stark increase
in the mean GED score, and decrease in the HM-IoU score, as shown in the bottom section of Table 1.
5.2.2	Learning a calibrated distribution on a multimodal Cityscapes dataset
The Cityscapes dataset contains 1024×2048 RGB images of urban scenes, and their corresponding
segmentation maps. It consists of 2975 training, 500 validation and 1525 test images. Following Kohl
et al. (2018), we use the version of the Cityscapes dataset with 19 semantic classes and downsampled
images and segmentation maps at a spatial resolution of 256×512. They establish controlled multi-
modality by augmenting the dataset with 5 new classes: sidewalk2, person2, car2, vegetation2 and
road2, introduced by flipping their original counterparts with probabilities 8/17, 7/17, 6/17, 5/17 and
4/17, respectively (see Fig. 4a). Following Kohl et al. (2018), we report results on the validation set.
7
Under review as a conference paper at ICLR 2021
road
sidewalk
building
wall
fence
pole
traffic light
traffic sign
vegetation
terrain
Sky
person
rider
car
truck
bus
train
motorcycle
bicycle
sidewalk2
person2
car2
vegetation2
road2
unlabeled
(a)
Entropy (bits)
c
Figure 4: (a) Input images overlaid with the corresponding labels. (b) Samples obtained from the
refinement network. (c) Aleatoric uncertainty computed as the entropy of the calibration output.
To demonstrate that our approach can be easily integrated on top of any existing black-box segmenta-
tion model B , we employ the network from TensorFlow DeepLab Model Zoo (2020), trained on the
official Cityscapes dataset, which achieves a mIoU of 0.79 on the test set. We utilise its predictions as
input to our calibration network, Fθ, which consists of 5 convolutional blocks, each composed of
a 3×3 convolutional layer, followed by a batch normalisation layer, a leaky ReLU activation, and a
dropout layer with 0.1 dropout rate. We pretrain the calibration network in isolation, and subsequently
apply it in inference mode while adversarially training the refinement network. We use a batch size
of 16, and train with LG, estimating Lcal with 7 samples from Gφ. The same baseline as in the
LIDC experiment is employed, where we replace Lcal with Lce . As a second control experiment we
completely omit the calibration network and instead condition the refinement network on the known
ground truth pixelwise categorical distribution over the label. This allows us to directly evaluate the
quality of sampling administered from the refinement network.
When training the refinement network with an additional cross entropy loss instead of the calibration
loss Lcal , the predictive distribution collapses, making the output deterministic. Conversely, when
we train our refinement network with Lcal , the learnt predictive distribution is well adjusted, with
high diversity and reconstruction quality, significantly outperforming the current state-of-the-art,
as shown in Table 2. Fig. 4b displays representative sampled predictions from our model for three
input images, and Fig. 4c illustrates the corresponding aleatoric uncertainty maps extracted from
Fθ(x). The learnt multimodality and noise in the dataset is reflected by regions of high uncertainty,
where objects belonging to the different stochastic classes consistently display distinct shades of red,
corresponding to their respective flip probabilities. Finally, we show that when using the ground truth
pixelwise distribution as the input to the refinement network, we attain an almost perfect GED score
(0.038 ± 0.00).
881771766175T7417
ytilibaborP eSiwlexi
I	I	ground truth
I	I	calibration network
I	I	refinement network
refinement network
(with ground truth)
Sidewalk2 PerSon2
car2 Vegetation2 road2
Figure 5: Calibration of the pixelwise probabil-
ities of the five stochastic classes. Note that the
calibration network (in orange) is conditioned on
black-box predictions.
Table 2: Mean GED scores on the modi-
fied Cityscapes. Top section: competing
model; middle: Lcal-regularised cGAN and
Lce -regularised baseline; bottom: ground
truth calibrated cGAN. The GED scores are
computed using 16 samples.
Method	GED
Kohl et al. (2018)	0.206 ± N/A
cGAN+Lcai cGAN+Lce	0.164 ± 0.01 0.632 ± 0.07
cGAN+Lcai (gtf-	0.038 ± 0.00
≡


8
Under review as a conference paper at ICLR 2021
Since we manually set the flip probabilities for each stochastic class in this dataset, we can directly
assess the calibration of our model by comparing the ground truth probabilities to the predicted
probabilities from the calibration or refinement network. For Fθ We use the mean confidence values
for each class, and for Gφ we obtain the empirical class probabilities via Gφ(Fθ(x)), computed from
16 samples (see Appendix A.4 for more details). The ensuing results are shown qualitatively in Fig. 5,
which illustrates the calibration of our models on the stochastic classes, evaluated over the entire
dataset. This demonstrates that our models are well calibrated, with the calibration offset, computed
as the absolute difference between the ground truth and predicted probabilities, being approximately
6% in the worst case (class "car2" for the calibration network). Note that the average calibration
offset for Fθ(x) across the stochastic classes is 1.6%. Further, the ground truth conditioned baseline
is almost perfectly calibrated, reflecting the near-optimal GED score reported in Table 2. Thus, we
demonstrate that Gφ learns calibrated refinement of the predictions from Fθ , where the quality of the
final predictive distribution depends on the quality of Fθ(x).
In order to further scrutinise the calibration qual-
ity of Fθ(x), we construct a reliability diagram and
compute the corresponding expected calibration error
(ECE), as proposed by Guo et al. (2017). To create
the diagram each pixel is considered independently
and the associated class confidences are binned into
10 equal intervals of size 0.1. We then compute the ac-
curacy for all predictions in each bin. Fig. 6 shows the
reliability diagram for the calibration network, where
the orange bars depict the calibration gap, defined as
the difference between the mean confidence for each
interval and the corresponding accuracy. The corre-
sponding ECE score amounts to 2.15%. Note that
this also considers the average calibration error com-
puted for the stochastic classes, where we randomly
sample the labels according to the defined probabili-
ties. Hence, we confirm that Fθ (x) is well calibrated.
Figure 6: Reliability diagram for the calibra-
tion network. ECE = 2.15%.
An important outstanding issue in our approach is that the calibration network may not perfectly
capture the class-probabilities, e. g. for the car2 category in Fig. 5. The limitations of modern neural
networks with respect to calibration, as well as possible solutions, are well studied (Guo et al., 2017;
Kull et al., 2019; Zhang et al., 2020). Miscalibration has been attributed to several factors, such as
long-tailed data distributions, out-of-distribution inputs, specific network architectural elements or
optimising procedures. However, since our approach seeks to calibrate relative to the calibration
target, and none of the aforementioned issues directly interfere with this process, we consider the
problem of absolute calibration to be beyond the scope of this work. Nevertheless we emphasise on
its importance for further improving the sample quality.
6 Conclusion
In this work, we developed a novel framework for semantic segmentation capable of learning a
calibrated multimodal predictive distribution, closely matching an estimation of the ground truth
distribution of labels. We attained improved results on a modified Cityscapes dataset and competitive
scores on the LIDC dataset, indicating the utility of our approach on real-world datasets. We also
showed that our approach can be easily integrated into an off-the-shelf, deterministic, black-box
semantic segmentation model, enabling sampling an arbitrary number of plausible segmentation maps.
By providing multiple valid label proposals and highlighting regions of high data uncertainty, our
approach can be used to identify and resolve ambiguities, diminishing risk in safety-critical systems.
Therefore, we expect our approach to be particularly beneficial for applications such as map making
for autonomous driving or computer-assisted medical diagnostics. Finally, even though the primary
focus of this work is semantic segmentation, we demonstrated its versatility through an illustrative
toy regression problem, alluding to a broader applicability beyond semantic image segmentation.
9
Under review as a conference paper at ICLR 2021
References
Stefan Lee, Senthil Purushwalkam Shiva Prakash, Michael Cogswell, Viresh Ranjan, David Crandall, and Dhruv
Batra. Stochastic multiple choice learning for training diverse deep ensembles. In Advances in Neural
Information Processing Systems, pages 2119-2127, 2016.
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image
segmentation. In International Conference on Medical image computing and computer-assisted intervention,
pages 234-241. Springer, 2015.
Simon J6gou, MiChal DrozdzaL David Vazquez, Adriana Romero, and Yoshua Bengio. The one hundred layers
tiramisu: Fully convolutional densenets for semantic segmentation. In Proceedings of the IEEE conference
on computer vision and pattern recognition workshops, pages 11-19, 2017.
Towaki Takikawa, David ACuna, Varun Jampani, and Sanja Fidler. Gated-sCnn: Gated shape Cnns for semantiC
segmentation. In Proceedings of the IEEE International Conference on Computer Vision, pages 5229-5238,
2019.
Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. Deeplab:
SemantiC image segmentation with deep Convolutional nets, atrous Convolution, and fully ConneCted Crfs.
IEEE transactions on pattern analysis and machine intelligence, 40(4):834-848, 2017a.
Liang-Chieh Chen, George Papandreou, Florian SChroff, and Hartwig Adam. Rethinking atrous Convolution for
semantiC image segmentation. arXiv preprint arXiv:1706.05587, 2017b.
Liang-Chieh Chen, Yi Yang, Jiang Wang, Wei Xu, and Alan L Yuille. Attention to sCale: SCale-aware semantiC
image segmentation. In CVPR, 2016a.
Liang-Chieh Chen, Jonathan T Barron, George Papandreou, Kevin Murphy, and Alan L Yuille. SemantiC image
segmentation with task-speCifiC edge deteCtion using Cnns and a disCriminatively trained domain transform.
In CVPR, 2016b.
Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. SemantiC image
segmentation with deep Convolutional nets and fully ConneCted Crfs. In ICLR, 2015.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On Calibration of modern neural networks. In
Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1321-1330. JMLR.
org, 2017.
Meelis Kull, Miquel Perello Nieto, Markus Kangsepp, Telmo Silva Filho, Hao Song, and Peter Flach. Beyond
temperature sCaling: Obtaining well-Calibrated multi-Class probabilities with diriChlet Calibration. In Advances
in Neural Information Processing Systems, pages 12295-12305, 2019.
Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe
Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In
Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3213-3223, 2016.
Xun Huang, Ming-Yu Liu, Serge Belongie, and Jan Kautz. Multimodal unsupervised image-to-image translation.
In Proceedings of the European Conference on Computer Vision (ECCV), pages 172-189, 2018.
Hsin-Ying Lee, Hung-Yu Tseng, Jia-Bin Huang, Maneesh Singh, and Ming-Hsuan Yang. Diverse image-to-
image translation via disentangled representations. In Proceedings of the European conference on computer
vision (ECCV), pages 35-51, 2018.
Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A Efros, Oliver Wang, and Eli Shechtman.
Toward multimodal image-to-image translation. In Advances in neural information processing systems, pages
465-476, 2017a.
Jianmin Bao, Dong Chen, Fang Wen, Houqiang Li, and Gang Hua. Cvae-gan: fine-grained image generation
through asymmetric training. In Proceedings of the IEEE International Conference on Computer Vision,
pages 2745-2754, 2017.
Yongqi Zhang. Xogan: One-to-many unsupervised image-to-image translation. arXiv preprint arXiv:1805.07277,
2018.
Simon Kohl, Bernardino Romera-Paredes, Clemens Meyer, Jeffrey De Fauw, Joseph R Ledsam, Klaus Maier-
Hein, SM Ali Eslami, Danilo Jimenez Rezende, and Olaf Ronneberger. A probabilistic u-net for segmentation
of ambiguous images. In Advances in Neural Information Processing Systems, pages 6965-6975, 2018.
10
Under review as a conference paper at ICLR 2021
Simon AA Kohl, Bernardino Romera-Paredes, Klaus H Maier-Hein, Danilo Jimenez Rezende, SM Eslami,
Pushmeet Kohli, Andrew Zisserman, and Olaf Ronneberger. A hierarchical probabilistic u-net for modeling
multi-scale ambiguities. arXiv preprint arXiv:1905.13077, 2019.
Christian F Baumgartner, Kerem C Tezcan, Krishna Chaitanya, Andreas M Hotker, Urs J Muehlematter, Khoschy
Schawkat, Anton S Becker, Olivio Donati, and Ender Konukoglu. Phiseg: Capturing uncertainty in medical
image segmentation. In International Conference on Medical Image Computing and Computer-Assisted
Intervention, pages 119-127. Springer, 2019.
Shi Hu, Daniel Worrall, Stefan Knegt, Bas Veeling, Henkjan Huisman, and Max Welling. Supervised uncertainty
quantification for segmentation with multiple annotations. In International Conference on Medical Image
Computing and Computer-Assisted Intervention, pages 137-145. Springer, 2019.
Konstantinos Kamnitsas, Wenjia Bai, Enzo Ferrante, Steven McDonagh, Matthew Sinclair, Nick Pawlowski,
Martin Rajchl, Matthew Lee, Bernhard Kainz, Daniel Rueckert, et al. Ensembles of multiple models and
architectures for robust brain tumour segmentation. In International MICCAI Brainlesion Workshop, pages
450-462. Springer, 2017.
Christian Rupprecht, Iro Laina, Robert DiPietro, Maximilian Baust, Federico Tombari, Nassir Navab, and
Gregory D Hager. Learning in an uncertain world: Representing ambiguity through multiple hypotheses. In
Proceedings of the IEEE International Conference on Computer Vision, pages 3591-3600, 2017.
Apratim Bhattacharyya, Mario Fritz, and Bernt Schiele. Bayesian prediction of future street scenes using
synthetic likelihoods. In International Conference on Learning Representations, 2018.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty
estimation using deep ensembles. In Advances in neural information processing systems, pages 6402-6413,
2017.
Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in
deep learning. In international conference on machine learning, pages 1050-1059, 2016a.
Jishnu Mukhoti and Yarin Gal. Evaluating bayesian deep learning methods for semantic segmentation. arXiv
preprint arXiv:1811.12709, 2018.
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional
adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pages 1125-1134, 2017.
Yarin Gal and Zoubin Ghahramani. Bayesian convolutional neural networks with bernoulli approximate
variational inference. ICLR workshop track, 2016b.
Mihaela Rosca, Balaji Lakshminarayanan, David Warde-Farley, and Shakir Mohamed. Variational approaches
for auto-encoding generative adversarial networks. arXiv preprint arXiv:1706.04987, 2017.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.
Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer vision? In
Advances in neural information processing systems, pages 5574-5584, 2017.
Sungjoon Choi, Kyungjae Lee, Sungbin Lim, and Songhwai Oh. Uncertainty-aware learning from demonstration
using mixture density networks with sampling-free variance modeling. In 2018 IEEE International Conference
on Robotics and Automation (ICRA), pages 6915-6922. IEEE, 2018.
Fredrik K Gustafsson, Martin Danelljan, and Thomas B Schon. Evaluating scalable bayesian deep learning
methods for robust computer vision. arXiv preprint arXiv:1906.01620, 2019.
Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using
cycle-consistent adversarial networks. In Proceedings of the IEEE international conference on computer
vision, pages 2223-2232, 2017b.
Dingdong Yang, Seunghoon Hong, Yunseok Jang, Tianchen Zhao, and Honglak Lee. Diversity-sensitive
conditional generative adversarial networks. In International Conference on Learning Representations, 2018.
Christopher M Bishop. Pattern recognition and machine learning. springer, 2006.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing
systems, pages 2672-2680, 2014.
11
Under review as a conference paper at ICLR 2021
Pauline Luc, Camille Couprie, Soumith Chintala, and Jakob Verbeek. Semantic segmentation using adversarial
networks. arXiv preprint arXiv:1611.08408, 2016.
Mohsen Ghafoorian, CedriC Nugteren, Ndra Baka, Olaf Booij, and Michael Hofmann. El-gan: Embedding loss
driven generative adversarial networks for lane detection. In Proceedings of the European Conference on
Computer Vision (ECCV), pages 0-0, 2018.
Laurens Samson, Nanne van Noord, Olaf Booij, Michael Hofmann, Efstratios Gavves, and Mohsen Ghafoorian.
I bet you are wrong: Gambling adversarial networks for structured semantic segmentation. In Proceedings of
the IEEE International Conference on Computer Vision Workshops, pages 0-0, 2019.
Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. Segnet: A deep convolutional encoder-decoder
architecture for image segmentation. IEEE transactions on pattern analysis and machine intelligence, 39(12):
2481-2495, 2017.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing
internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a
simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1):
1929-1958, 2014.
Xun Huang and Serge Belongie. Arbitrary style transfer in real-time with adaptive instance normalization. In
Proceedings of the IEEE International Conference on Computer Vision, pages 1501-1510, 2017.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional
generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980,
2014.
Lars Mescheder, Andreas Geiger, and Sebastian Nowozin. Which training methods for gans do actually converge?
arXiv preprint arXiv:1801.04406, 2018.
Gdbor J SzCkely and Maria L Rizzo. Energy statistics: A class of statistics based on distances. Journal of
statistical planning and inference, 143(8):1249-1272, 2013.
Harold W Kuhn. The hungarian method for the assignment problem. Naval Research Logistics (NRL), 52(1):
7-21, 2005.
Samuel G Armato III, Geoffrey FMcLennan, Luc Bidaut, Michael F McNitt-Gray, Charles R Meyer, Anthony P
Reeves, Binsheng Zhao, Denise R Aberle, Claudia I Henschke, Eric A Hoffman, et al. The lung image
database consortium (lidc) and image database resource initiative (idri): a completed reference database of
lung nodules on ct scans. Medical physics, 38(2):915-931, 2011.
TensorFlow DeepLab Model Zoo. Pretrained model: xception71_dpc_cityscapes_trainfine, 2020. URL
download.tensorflow.org/models/deeplab_cityscapes_xception71_trainfine_
2018_09_08.tar.gz.
Jize Zhang, Bhavya Kailkhura, and T Han. Mix-n-match: Ensemble and compositional methods for uncertainty
calibration in deep learning. arXiv preprint arXiv:2003.07329, 2020.
Alex Graves. Practical variational inference for neural networks. In Advances in neural information processing
systems, pages 2348-2356, 2011.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mo-
hamed, and Alexander Lerchner. beta-VAE: Learning Basic Visual Concepts with a Constrained Variational
Framework. Iclr, 2(5):6, 2017.
Anders Boesen Lindbo Larsen, S0ren Kaae S0nderby, Hugo Larochelle, and Ole Winther. Autoencoding beyond
pixels using a learned similarity metric. arXiv preprint arXiv:1512.09300, 2015.
Danijar Hafner, Dustin Tran, Timothy Lillicrap, Alex Irpan, and James Davidson. Noise contrastive priors for
functional uncertainty. arXiv preprint arXiv:1807.09289, 2018.
Christos Louizos, Xiahan Shi, Klamer Schutte, and Max Welling. The functional neural process. arXiv preprint
arXiv:1906.08324, 2019.
12
Under review as a conference paper at ICLR 2021
Appendices
A Implementation details
In this section we describe the overall training procedure and delve into the training and evaluation details for
the stochastic segmentation experiments on the LIDC dataset and the modified Cityscapes dataset.
A.1 Training procedure
Algorithm 1 outlines the practical procedure used to pretrain the calibration network, and the subsequent training
of the refinement network. Even though the two networks can be trained end-to-end at once, in our experiments
we use the two-step training procedure to stabilise the training and reduce the memory consumption on the GPU.
This way we are able to fit larger batches and/or more samples for the estimate of Lcal. Algorithm 2 shows the
inference procedure for obtaining M output samples.
Algorithm 1 Model training with calibration network pretraining
require: training data D, number of samples M, learning rate η, calibration loss scale λ;
1:	procedure TRAINING(D , M, η, λ)
2:	while not converged do	. Pretraining of Fθ
3:	Sample batch {x, y}t ∈ D
4:	Update θt+ι With -ηνθtLce({x,y}t,θt)
5:	end while
6:	while not converged do	. Adversarial training of Gφ and Dψ
7:	Sample batch {x, y}t ∈ D
8:	for i = 1, 2, . . . , M do
9:	Sample yiet = Gφt (Fθ*(xt),3 where G 〜N(0,1)
10:	end for _
11:	COmPUte Gφ(Fθ(X))t =焉 PM=1 *	_
12:	Compute Lcal(Xt,θ* ,φt) = Pj (G φ(Fθ (x))t (log Gφ (Fθ (x))t - log Fθ*(xt )))ijk
13:	Update φt+ι	with	-ηVφ,	(Lg(θ*', φt,{x, y}t)	+	λLcal(xt, θ*,	φt))	, ,
14:	Update ψt+ι with -ηVψtLD(θ*, φt, ψt,{x, y}t)
15:	end while
16:	end procedure
Algorithm 2 Inference procedure
	require: test data point x, number of samples M;	
1:	procedure INFERENCE(X, M)	.Using θ* and φ* from Algorithm 1
2:	for i = 1, 2, . . . , M do	
3:	Sample yref = Gφ*(Fθ*(x) G) where G	〜N (0,1)
4:	end for	
5:	end procedure	
Notice that any off-the-shelf optimisation algorithm can be used to update the parameters θ, φ and ψ. For the
segmentation experiments, we utilise the Adam optimiser (Kingma and Ba, 2014) with β1 = 0.5, β2 = 0.99
and weight decay of 5e-4. Fθ is trained with a learning rate of 2e-4 which is then lowered to 1e-4 after
30 epochs. Gφ and Dψ are updated according to a schedule, where Gφ is updated at every iteration, and Dψ
is trained in cycles of 50 iterations of weight updating, followed by 200 iterations with fixed weights. The
refinement network is trained with an initial learning rate of 2e-4, lowered to 1e-4 after 30 epochs, whereas
the discriminator has an initial learning rate of 1e-5, lowered to 5e-6 after 30 epochs. Additionally, we utilise
the R1 zero-centered gradient penalty term (Mescheder et al., 2018), to regularise the discriminator gradient
on real data with a weight of 10. Other hyperparameter specifics such as the batch-size and whether we inject
stochasticity via random noise samples or latent code samples, depend on the experiment and are disclosed in
the respective sections below or in the main text.
13
Under review as a conference paper at ICLR 2021
A.2 1D bimodal regression
In the following we derive the mean squared error form of the cross entropy and calibration losses used in
experiment Section 5.1 under the assumption that the likelihood model for qθ and qφ is a univariate Gaussian
distribution with a fixed unit variance. Using the setup from Eq. (2) it then follows that:
Lce(D, θ) = -EpD(x,y)[log N (y | Fθ(x), 1)]	(10)
=2EpD(χ,y)[(y - Fθ(x))2] + const.	(11)
Based on the definition of the calibration loss in Eq. (6) we show that:
Lcal(D,θ,φ) = EpD [KL (N (y ∣ Gφ(Fθ(x)), 1)∣∣N (y | Fθ(x), 1))]	(12)
=EpD hEN (y∣Gφ(Fθ (x)), 1) [log N (y I Gφ(Fθ (X)), 1) - log My | Fθ (X)J)]]	(13)
EpD EN (y∣Gφ(Fθ (x)), 1) - 2 (y - Gφ(Fe(Xy)) + 2 (y - Fθ(X))2	+ const	(14)
EpD EN(y∣Gφ(Fθ(x)), 1) yGΦ(Fe(X))- 2Gφ(Fe(Xy))- yFe(x) + 2Fe(χ)2	+ const
(15)
EpD Gφ(Fe(x))2 - 2Gφ(Fe(x))2 - Gφ(Fe(X))Fe(X) + JFe(X)2 +const	(16)
2EpD [(Gφ(Fe(X))- Fe(X)) ] + const.	(17)
A.3 LIDC
Architectures For the calibration network, Fe, we use the encoder-decoder architecture from SegNet (Badri-
narayanan et al., 2017), with a softmax activation on the output layer.
Training During training, we draw random 180×180 image-annotation pairs, and we apply random horizontal
flips and crop the data to produce 128×128 lesion-centered image tiles. All of our models were implemented in
PyTorch and trained for 80k iterations on a single 32GB Tesla V100 GPU.
We train all our models for the LIDC experiments using 8-dimensional noise vectors in the cGAN experiments,
or latent codes in the cVAE-GAN experiments. This value was empirically found to perform well, sufficiently
capturing the shape diversity in the dataset. Additionally, in the refinement networks loss, we set the weighting
parameter λ in the total generator loss, defined in Eq. (7) in the main text, so as to establish a ratio of
LG : Lcal = 1 : 0.5, where LG is the adversarial component of the loss, and Lcal is the calibration loss
component. In practice, the actual weights used are 10 for LG, and 5 for Lcal.
Evaluation Following Kohl et al. (2018), Kohl et al. (2019), Huang et al. (2018), and Baumgartner et al.
(2019) We use the Generalised Energy Distance (GED) (Sz6kely and Rizzo, 2013) metric, given as:
DG2ED (pD , qφ) = 2E
s~qφ ,y~pD [d(s, y)] - Es,s0〜qφ [d(s, s0)] - Ey,y0〜pD [d(y, y0)],	(18)
Where d(s, y) = 1 - IoU(s, y). Intuitively, the first term of Eq. (18) quantifies the disparity betWeen sampled
predictions and the ground truth labels, the second term—the diversity betWeen the predictions, and the third
term—the diversity betWeen the ground truth labels. It is important to note that the GED is a sample-based metric,
and therefore the quality of the score scales With the number of samples. We approximate the expectations With
all 4 ground truth labels (y 〜PD) and 16, 50 or 100 samples from the model (s 〜qφ) for each input image x.
As Kohl et al. (2019) have pointed out, even though the GED metric is a good indicator for hoW Well the
learnt predictive distribution fits a multimodal ground truth distribution, it can reWard high diversity in sampled
predictions even if the individual samples do not shoW high fidelity to the ground truth distribution. As an
alternative metric that is less sensitive to such degenerate cases, Kohl et al. (2019) propose to use the Hungarian-
matched IoU (HM-IoU), Which finds the optimal 1:1 IoU matching betWeen ground truth samples and sampled
predictions. FolloWing Kohl et al. (2019), We duplicate the set of ground truth labels so that the number of both
ground truth and predicted samples are 16, and We report the HM-IoU as the average of the best matched pairs
for each input image.
In the main text We shoW the evaluated performance With both GED and HM-IoU metrics over the entire test
set and compute the IoU on only the foreground of the sampled labels and predictions. In the case Where both
14
Under review as a conference paper at ICLR 2021
the matched up label and prediction do not show a lesion, the IoU is set to 1, so that a correct prediction of the
absence of a lesion is rewarded.
Note that the methods of Baumgartner et al. (2019) and Hu et al. (2019), whose GED scores we report in Table 1,
use test sets that differ from the original splits defined in Kohl et al. (2018), which are used in Kohl et al.
(2018; 2019) and our work. Baumgartner et al. (2019) uses a random 60:20:20 split for the training, testing
and validation sets, and 100 samples to compute the GED score, whereas Hu et al. (2019) use a random
70:15:15 split and 50 samples to compute the GED score. Due to the lack of reproducibility, we do not consider
this the conventional way of benchmarking. Therefore, in Table 1 we only report the scores for our models
evaluated on the original splits. Nevertheless, we also trained and tested our cGAN+Lcal model on the split
methodology defined by Baumgartner et al. (2019) to enable a fairer comparison. This improved our GED score
from 0.243 ± 0.004 to 0.228 ± 0.009, while the HM-IoU, evaluated using 16 samples, remained similar at
0.590 ± 0.007 (in the original splits we achieved an HM-IoU score of 0.592 ± 0.005). This shows that different
random splits can significantly affect the final performance w. r. t. GED score, while HM-IoU appears to be a
more robust metric.
A.4 Cityscapes
Architectures For the calibration network Fθ, we design a small neural network with 5 convolutional blocks,
each comprised of a 3×3 convolutional layer, followed by a batchnorm layer and a leaky ReLU activation. The
network is activated with a softmax function.
Training During training, we apply random horizontal flips, scaling and crops of size 128×128 on the
image-label pairs. All of our models were implemented in PyTorch and trained for 120k training iterations on a
single 16GB Tesla V100 GPU.
We train all our models for the modified Cityscapes experiments using 32-dimensional noise vectors. Similarly
to the LIDC experiments, this value was empirically found to perform well, however, it can be further tuned. As
commonly practiced, we use the ignore-masks provided by the Cityscapes dataset to filter out the cross entropy,
calibration and adversarial losses during training on the unlabelled pixels. Similarly to our LIDC experiment, we
use a weight of 10 for LG, and 5 for Lcal in the refinement networks loss.
Evaluation The GED metric for Cityscapes is implemented as described in the appendix of Kohl et al. (2018)
and evaluated across the entire validation set. In this dataset we have full knowledge of the ground truth class
distribution and therefore we compute the GED metric by using the probabilities of each mode directly, as
follows:
DG2ED (pD , qφ) = 2E
s2qφ,y2pD [d(s, y)w(y)]
-Es,s0〜qφ d(s, s0)
-Ey,y0〜PDd(y, y0)w(y)w(y0), (19)
where w(∙) is a function mapping the mode of a given label y to its corresponding probability mass. The distance
d(s, y) is computed using the average IoU of the 10 switchable classes only, as done in Kohl et al. (2018). In the
cases where none of the switchable classes are present in both the ground truth label and the prediction paired up
in d(s, y), the distance score is not considered in the expectation. We use 16 samples to compute the GED score.
For the calibration results presented in Fig. 5, Section 5.2.2 in the main text, we compute the calibration network
class-probabilities using the raw predictions of Fθ (x). We obtain class masks by computing the overlap between
the ground truth labels and the black-box predictions for each class. Using these masks we then compute the
average class-wise probabilities. The probabilities for the refinement network Gφ were computed as the average
over 16 samples. Here the class masks are obtained by finding the pixels that are specified as the class of interest
in the ground truth labels.
15
Under review as a conference paper at ICLR 2021
B Additional experiment results
To reinforce the results reported in Section 5 we present supplementary results for the bimodal regression
experiment and the LIDC and Cityscapes segmentation experiments.
B.1 1D bimodal regression
Fig. 7 shows the data log-likelihoods for the 9 data configurations for varying mode bias π ∈ {0.5, 0.6, 0.9}
and mode noise σ ∈ {0.01, 0.02, 0.03} trained with and without the calibration loss Lcal. Each experiment is
repeated 5 times and the individual likelihood curves are plotted in Fig. 7b and Fig. 7d respectively. The results
show that high bias is harder to learn, reflected by a slowed down convergence, however, the Lcal-regularised
model shows greater robustness to weight initialisation. In contrast the non-regularised GAN exhibits mode
oscillation expressed as a fluctuation of higher likelihood (one mode is covered) and lower one (between modes).
0	100 200 300 400 500 0 100 200 300 400 500 0 100 200 300 400 500
σ = 0.01	σ = 0.02	σ = 0.03
Mode spread
0	100 200 300 400 500 0 100 200 300 400 500 0 100 200 300 400 500
σ = 0.01	σ = 0.02	σ = 0.03
Mode spread
(a)
0 100 200 300 400 500 0 100 200 300 400 500 0 100 200 300 400 500
σ = 0.01	σ = 0.02	σ = 0.03
Mode spread
(C)
(b)
0	100 200 300 400 500 0 100 200 300 400 500 0 100 200 300 400 500
σ = 0.01	σ = 0.02	σ = 0.03
Mode spread
(d)
Figure 7: Log-likelihood curves for 5 runs on each of the 9 data configurations. (a) No calibration
loss (λ = 0), averaged. (b) No calibration loss, individual runs. (c) With calibration loss (λ = 1),
averaged. (d) With calibration loss, individual runs.
16
Under review as a conference paper at ICLR 2021
B.2 LIDC
B.2.	1 Qualitative Analysis
To further examine our Lcal -regularised cGAN model trained on the LIDC dataset, we illustrate representative
qualitative results in Fig. 8 and Fig. 9. For every input image x, we show the ground truth labels yg1t , . . . , yg4t
provided by the different expert annotators, overlaying the input image, in the first four columns, and 6 randomly
sampled predictions yr1ef, . . . , yr6ef in the last six columns. From left to right, the three columns with the dark
blue background in the center of the figures show the average ground truth predictions ygt, the output of the
calibration network Fθ (x) and the average of 16 sampled predictions from the refinement network yref. Our
results show that even though there is a significant variability between the refinement network samples for a
given input image, %ef is almost identical to the calibration target Fθ(x), due to the diversity regularisation
enforced by the calibration loss Lcal .
(x, ygt)	(χ, y gt)	(χ, y gt)	(χ, Vgt)	ygt	Fθ (X)	y3	y2	y L	y L	y4或	y Ief	y 修
0.00	0.25	0.50	0.75	1.00
Figure 8: Qualitative results on LIDC samples for the Lcal-regularised cGAN model.
17
Under review as a conference paper at ICLR 2021
(X, ygt)	(X, y gt)	(X, y gt)	(XX Vgt)	ygt	Fθ (X)	y3	y2	y L	y L	y4或	y Ief	y 修
0.00	0.25	0.50	0.75	1.00
Figure 9: Qualitative results on LIDC samples for the Lcal-regularised cGAN model.
From the qualitative results in Fig. 8 and Fig. 9, it can be seen that the calibration target Fθ (x) does not always
capture well the average of the ground truth distribution ygt, affecting the fidelity of the predictive distribution of
the refinement network Gφ. This further highlights the importance of future work on improving the calibration
of Fθ , e. g. implementing the approaches of Guo et al. (2017); Kull et al. (2019).
18
Under review as a conference paper at ICLR 2021
B.2.2	Tuning the number of refinement network samples
Table 3: Mean GED and HM-IoU scores on LIDC for the Lcal-regularised cGAN with 1, 5, 10, 15
and 20 samples. The number of samples used to compute the GED score is denoted in the parentheses
in the header of each column. The arrows ↑ and J denote if higher or lower score is better.
Method	GED J (16)	GED J (50)	GED J (100)	HM-IoU ↑ (16)
cGAN+Lcal (1)	0.644 ± 0.033	0.643 ± 0.033	0.643 ± 0.033	0.494 ± 0.013
cGAN+Lcal (5)	0.278 ± 0.000	0.257 ± 0.002	0.252 ± 0.001	0.585 ± 0.003
cGAN+Lcal (10)	0.277 ± 0.003	0.257 ± 0.003	0.250 ± 0.003	0.589 ± 0.007
cGAN+Lcal (15)	0.271 ± 0.002	0.250 ± 0.001	0.245 ± 0.003	0.593 ± 0.002
cGAN+Lcal (20)	0.264 ± 0.002	0.248 ± 0.004	0.243 ± 0.004	0.592 ± 0.005
To investigate the effect of the number of samples used to compute Lcal on the learnt predictive distribution,
we experimented on the Lcal-regularised cGAN model using 5, 10, 15 or 20 samples from the refinement
network Gφ during training. As a control experiment, we also train the same model using one sample. Our
results, reported in Table 3, show that increasing the number of samples improves the quality of the predictive
distribution, whereas using only one sample collapses it. This is expected because increasing the number of
samples reduces the variance of the sample mean Gφ and refines the approximation qφ of the implicit predictive
distribution realised by Gφ (x, ). Since in our implementation we reuse the samples from Gφ in the adversarial
component LG of the total refinement network loss LG, the discriminator Dψ interacts with a larger set of
diverse fake samples during each training iteration, thus also improving the quality of LG .
It is important to note that the benefit of increasing the sample size on the quality of Lcal highly depends on the
intrinsic multimodality in the data. In theory, if the number of samples used matches or exceeds the number
of ground truth modes for a given input, it is sufficient to induce a calibrated predictive distribution. However,
we usually do not have a priori access to this information. Conversely, if the sample size is too small, the Lcal
loss may introduce bias in the predictive distribution. This could lead to mode coupling or mode collapse, as
exemplified in our control experiment with one sample.
In the LIDC dataset, even though we have access to four labels per input image, we argue that the dataset exhibits
distributed multimodality, where a given pattern in the input space, e. g. in a patch of pixels, can be associated to
many different local labels throughout the dataset. As a result, an input image may correspond to more solutions
than the four annotations provided. Therefore increasing the number of samples to more than four shows further
improvement in performance. This however can come at the cost of decreased training speed which can be
regulated by tuning the sample count parameter while considering the system requirements.
B.2.3	Inducing multimodality in latent variable models on the LIDC dataset
To examine whether conditioning the source of stochasticity in our model on the input is beneficial, we adapt
our framework in order to learn a distribution over a latent code z using variational inference (Graves, 2011).
Following most of the existing work on stochastic semantic segmentation (Kohl et al., 2018; 2019; Hu et al.,
2019; Baumgartner et al., 2019), we maximise a modified lower bound on the conditional marginal log-likelihood,
through a variational distribution q(z | x, y). This is realised by minimising the loss function in Higgins et al.
(2017), given by:
LELBO(x,y) = -Eq(z|x,y)[log p(y | x, z)] + β KL(q(z | x,y) || p(z)) ≥ - log p(y | x),	(20)
where β controls the amount of regularisation from a prior distribution p(z) on the approximate posterior
q(z | x, y). Both q(z | x, y) and p(z) are commonly taken as factorised Gaussian distributions.
To this end, we compare our cGAN model to two baselines where the refinement network Gφ is given as a
cVAE-GAN (Larsen et al., 2015). In the first one, we train Gφ by complementing the adversarial loss LG
with Eq. (20), using β ∈ {0.1, 1, 10} and a fixed standard normal prior. In the second, we introduce a calibration
network and train Gφ using Eq. (7). This does not necessitate specifying a prior.
For a fair comparison, we use the same core models for all of our experiments, introducing only minor
modifications to the refinement network to convert the deterministic encoder into a probabilistic one with
Gaussian output. This is achieved by splitting the output head of the encoder so as to predict the mean and
standard deviation of the encoded distribution (Kingma and Welling, 2013; Kendall and Gal, 2017). Instead
of using random noise sampled from a standard Gaussian as our source of stochasticity, the decoder of the
refinement network is now injected with latent codes sampled from the Gaussian distribution encoded for each
input image. To train the model, we pretrain the Fθ in isolation, and subsequently apply it in inference mode
while training Gφ. We use a batch size of 32, an 8-dimensional latent code, and use 20 samples to compute Lcal.
19
Under review as a conference paper at ICLR 2021
Table 4: GED and H-IoU scores on LIDC. The top section shows the Lce-regularised baseline and
the Lcal-regularised cGAN; the bottom section shows baseline and Lcal-regularised cVAE-GANs. All
Lcal-regularised models are trained using 20 samples. The three central columns show the GED score
computed with 16, 50 and 100 samples, respectively. The last column shows the HM-IoU score,
computed with 16 samples. The arrows ↑ and ] indicate whether higher or lower score is better.
Method	GED 1 (16)	GED 1 (50)	GED 1 (100)	HM-IoU ↑ (16)
cGAN+Lce	0.639 ± 0.002	—	—	0.477 ± 0.004
cGAN+Lcal	0.264 ± 0.002	0.248 ± 0.004	0.243 ± 0.004	0.592 ± 0.005
cVAE-GAN (β=0.1)	0.577 ± 0.095	—	—	0.484 ± 0.006
cVAE-GAN (β=1)	0.596 ± 0.078	—	—	0.474 ± 0.005
cVAE-GAN (β=10)	0.609 ± 0.061	—	—	0.482 ± 0.010
cVAE-GAN+Lcal (β=0)	0.272 ± 0.006	0.252 ± 0.006	0.246 ± 0.006	0.593 ± 0.003
We show that the cVAE-GAN model trained with Lcal instead of the traditional complexity loss term,
KL(q(z | x, y) || p(z)) from Eq. (20) is able to learn a distribution over segmentation maps, and performs
similarly to our cGAN+Lcal model. This is important because it abrogates the need for specifying a latent-space
prior, which is often selected for computational convenience, rather than task relevance (Hafner et al., 2018;
Louizos et al., 2019). On the other hand, our cVAE-GAN models trained using the KL-divergence complexity
term showed limited diversity, even for large β values. The results, shown quantitatively in the bottom part
of Table 4, and qualitatively in Fig. 10a, demonstrate that the interaction between LG and Lcal can sufficiently
induce a multimodal predictive distribution in latent variable models, and indicate that for the purpose of
stochastic semantic segmentation the use of a probabilistic encoder is not strictly required.
(b)
Figure 10: LIDC validation samples for the (a) cVAE-GAN and (b) cGAN+Lce baseline model.
20
Under review as a conference paper at ICLR 2021
B.3 Cityscapes
Vegeta
road2
unlabeled
Person2
traffic
traffic sign
vegetation
terrain
sky
person
rider
car
truck
bus
road j
sidewalk j
building ]
WalU
fence ]
(S∙-q) Xdo-uw
(S∙-q) XdO-uw
Figure 11: 10 input images, the corresponding aleatoric maps from the calibration network and 16
samples from the refinement network. For visualisation purposes, the samples are split into 8 per row.
B.3.1	Qualitative Analysis
In this section we provide additional qualitative results for the Lcal-regularised cGAN model trained on the
modified Cityscapes dataset (Kohl et al., 2018). In Fig. 11, we show 16 randomly sampled predictions for
representative input images x, and their corresponding aleatoric uncertainty maps, obtained by computing the
entropy of the output of the calibration network, H(Fθ(x)), as done in Kendall and Gal (2017). The predicted
samples are of high quality, evident by object coherence and crisp outlines, and high diversity, where all classes
are well represented. Our model effectively learns the entropy of the ground truth distribution in the stochastic
classes (sidewalk, person, car, vegetation and road), as their distinct entropy levels are captured as different
21
Under review as a conference paper at ICLR 2021
shades of red in the entropy maps, corresponding to the different flip probabilities (8/17, 7/17, 6/17, 5/17 and 4/17
respectively). Additionally, it can be seen that edges or object boundaries are also highlighted in the aleatoric
uncertainty maps, which reflects inconsistency during manual annotation, which often occurs on input pixels
that are difficult to segment.
Fig. 12d shows the entropy of the predictive distribution of the refinement network Gφ, H (Gφ (Fθ (x))), where
Gφ(Fθ(x)) is computed as the average of 16 samples from Gφ. Our results demonstrate that H(Gφ(Fθ(x)))
is similar to H(Fθ (x)), depicted in Fig. 12c, as encouraged by the Lcal regularisation. Notice that object
boundaries are also highlighted in H (Gφ(Fθ (x))), indicating that our model captures shape ambiguity as well
as class ambiguity. However, some uncertainty information from H(Fθ (x)) is not present in H(Gφ(Fθ (x))),
e. g. the entropy of the different stochastic classes are not always consistent across images, as evident from the
different shades of red seen for the road class in Fig. 12d. We expect that increasing the number of samples
from the refinement network will improve the aleatoric uncertainty estimates. Nevertheless, the sample-free
estimate extracted from Fθ (x) is cheaper to obtain and more reliable than the sample-based average from Gφ,
highlighting an important benefit of our cascaded approach.
Finally, we illustrate in Fig. 12e the high confidence of the predictions from the refinement network Gφ(Fθ(x)),
reflected by their low entropy, H(Gφ (Fθ (x))). This is attributed to the adversarial component in the refinement
loss function, which encourages the predictions to assume a one-hot representation, matching the ground truth
annotationsRven though each prediction of the refinement network is highly confident, the average of the
predictions Gφ(Fθ(x)) is calibrated, as shown in Fig. 12d. This is a clear illustration of the advantage of
complementing the adversarial loss term LG with the calibration loss term Lcal in the training objective for the
refinement network.
22
Under review as a conference paper at ICLR 2021
(e)
Figure 12: (a) Three input images overlaid with the corresponding labels; (b) Incoherent samples
from the predictive distribution of the calibration network; (c) The aleatoric maps from the calibration
network; (d) Aleatoric maps computed as the entropy of the average of 16 predictions of the refinement
network; (e) The entropy of one sample of the refinement network output for each input image.
23