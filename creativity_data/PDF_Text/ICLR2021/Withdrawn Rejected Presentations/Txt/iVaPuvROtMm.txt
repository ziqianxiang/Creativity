Under review as a conference paper at ICLR 2021
Learning Stochastic Behaviour from Aggregate Data
Anonymous authors
Paper under double-blind review
Abstract
Learning nonlinear dynamics from aggregate data is a challenging problem since
the full trajectory of each individual is not available, namely, the individual ob-
served at one time point may not be observed at next time point, or the identity
of individual is unavailable. This is in sharp contrast to learning dynamics with
trajectory data, on which the majority of existing methods are based. We pro-
pose a novel method using the weak form of Fokker Planck Equation (FPE) to
describe density evolution of data in a sampling form, which is then combined
with Wasserstein generative adversarial network (WGAN) in training process. In
such a sample-based framework we are able to study nonlinear dynamics from
aggregate data without solving the partial differential equation (PDE). The model
can also handle high dimensional cases with the help of deep neural networks. We
demonstrate our approach in the context of a series of synthetic and real-world data
sets.
1	Introduction
In the context of a dynamic system, Aggregate data refers to the data sets that full trajectory of
each individual is not available, meaning that there is no known individual level correspondence.
Typical examples include data sets collected for DNA evolution, social gathering, density in control
problems, bird migration during which it is impossible to identify individual bird, and many more.
In those applications, some observed individuals at one time point may be unobserved at the next
time spot, or when the individual identities are blocked or unavailable due to various technical and
ethical reasons. Rather than inferring the exact information for each individual, the main objective
of learning dynamics in aggregate data is to recover and predict the evolution of distribution of all
individuals together. Trajectory data, in contrast, is a kind of data that we are able to acquire the
information of each individual all the time, although some studies considered the case that some
individual trajectories are partially missing. However, the identities of those individuals, whenever
they are observable, is always assumed available. For example, stock price, weather, customer
behaviors and most training data sets for computer vision and natural language processing.
There are many popular models to learn dynamics of full-trajectory data. Typical ones include Hidden
Markov Model (HMM)(Alshamaa et al., 2019; Eddy, 1996), Kalman Filter (KF)(Farahi & Yazdi,
2020; Harvey, 1990; Kalman, 1960) and Particle Filter (PF) (Santos et al., 2019; Djuric et al., 2003),
as well as the models built upon HMM, KF and PF(Deriche et al., 2020; Fang et al., 2019; Hefny
et al., 2015; Langford et al., 2009), they all require full trajectories of each individual, which may
not be applicable in the aggregate data situations. On the other side, only a few methods are focused
on aggregated data in the recent learning literature. In the work of Hashimoto et al. (2016), authors
assumed that the hidden dynamic of particles follows a stochastic differential equation(SDE), in
particular, they use a recurrent neural network to parameterize the drift term. Furthermore, Wang
et al. (2018) improved traditional HMM model by using an SDE to describe the evolving process of
hidden states. To the best of our knowledge, there is no method directly learning the evolution of the
density of objects from aggregate data yet.
We propose to learn the dynamics of density through the weak form of Fokker Planck Equation (FPE),
which is a parabolic partial differential equation (PDE) governing many dynamical systems subject to
random noise perturbations, including the typical SDE models in existing studies. Our learning is
accomplished by minimizing the Wasserstein distance between predicted distribution given by FPE
and the empirical distribution from data samples. Meanwhile we utilize neural networks to handle
higher dimensional cases. More importantly, by leveraging the framework of Wasserstein Generative
1
Under review as a conference paper at ICLR 2021
Adversarial Network (WGAN) (Arjovsky et al., 2017), our model is capable of approximating the
distribution of samples at different time points without solving the SDE or FPE. More specifically,
we treat the drift coefficient, the goal of learning, in the FPE as a generator, and the test function
in the weak form of FPE as a discriminator. In other words, our method can also be regarded as a
data-driven method to estimate transport coefficient in FPE, which corresponds to the drift terms in
SDEs. Additionally, though we treat diffusion term as a constant in our model, it is straightforward
to generalize it to be a neural network as well, which can be an extension of this work. We would
like to mention that several methods of solving SDE and FPE (Weinan et al., 2017; Beck et al., 2018;
Li et al., 2019) adopt opposite ways to our method, they utilize neural networks to estimate the
distribution P(x, t) with given drift and diffusion terms.
In conclusion, our contributions are:
•	We design an algorithm that is able to recover the density evolution of nonlinear dynamics
via minimizing the Wasserstein discrepancy between real aggregate data and our generated
data.
•	By leveraging the weak form of FPE, we are able to compute the Wasserstein distance
directly without solving the FPE.
•	Finally, we demonstrate the accuracy and the effectiveness of our algorithm by several
synthetic and real-world examples.
2	Proposed Method
2.1	Fokker Planck Equation for the density evolution
Figure 1: State model of the stochastic process Xt
We assume the individuals evolve in a pattern in the space RD as shown in Figure 1. One example
satisfying SuCh process is the stochastic differential equation(SDE), which is also known as the ltð
process (0ksendal, 2003): dXt = g(Xt, t)dt + σdWt. Here dXt represents an infinitesimal change
of {Xt} along with time increment dt, g(∙, t) = (g 1(∙, t),…,gD(∙, t))T is the drift term (drifting vector
field) that drives the dynamics of the SDE, σ is the diffusion constant, {Wt} is the standard Brownian
Motion. Then the probability density of {Xt} is governed by the Fokker Planck Equation(FPE)
(Risken & Caugheyz, 1991), as stated below in Lemma 1.
Lemma 1. Suppose {XJ solves the SDE dXt = g(Xt, t)dt + σdWt, denote P(∙, t) as the probability
density of the random variable Xt. Then p(x, t) solves the following equation:
dp(xτ1 = X -∂Xi hgi(x，t)P(χ,t)i+1 σ2 ∑ ∂X2 p(χ,t)	⑴
i=1	i=1
As a linear evolution PDE, FPE describes the evolution of density function of the stochastic process
driven by a SDE. Due to this reason, FPE plays a crucial role in stochastic calculus, statistical physics
and modeling (Nelson, 1985; Qi & Majda, 2016; Risken, 1989). Its importance is also drawing more
attention among statistic and machine learning communities (Liu & Wang, 2016; Pavon et al., 2018;
Rezende & Mohamed, 2015). In this paper, we utilize the weak form of FPE as a basis to study
hidden dynamics of the time evolving aggregated data without solving FPE.
Our task can be described as: assume that the individuals evolve with the process indicated by Figure
1, which can be simulated by ltð process. Then given observations xt along time axis, we aim to
recover the drift coefficient g(x, t) in FPE, and thus we are able to recover and predict the density
evolution of such dynamic. For simplicity we treat g(x, t) as a function uncorrelated to time t, namely,
2
Under review as a conference paper at ICLR 2021
g(x, t) = g(x). Notice that though evolving process of individuals can be simulated by Itδ process, in
reality since we lose identity information of individuals, the observed data become aggregate data,
thus we need a new way other than traditional methods to study the swarm’s distribution.
2.2	Weak Form of Fokker Planck Equation
Given FPE stated in Lemma 1, if we multiply a test function f ∈ H01(RD) on both sides of the FPE,
then the integration on both sides leads to:
Z d∂p-f (x)dX = ZX -∂X hg(x)P(x, t)] f(x)dX + 1 σ2 Z X -X2P(x, t)f(x)dx.
Then integrating by parts on the right hand side leads to the weak form of FPE:
Jf d X
i	12
g (x)-χ f (x)P(x, t)dx + 2σ
f (X) P(X, t)dX.
where H01(RD) denote the Sobolev space. The first advantage of weak solution is that the solution of
a PDE usually requires strong regularity and thus may not exist in the classical sense for a certain
group of equations, however, the weak solution has fewer regularity requirements and thus their
existence are guaranteed for a much larger classes of equations. The second advantage is that the weak
formulation may provide new perspectives for numerically solving PDEs (Zienkiewicz & Cheung,
1971),(Sirignano & Spiliopoulos, 2018) and (Zang et al., 2019) etc.
Suppose the observed samples at time points tιn-1 and tm are following true densities P(∙, tιn-1) and
p(∙, tm). Consider the following SDE
dXt= gω(Xt)dt + σdWt, tm-1 ≤ t ≤ tm X如-1 〜P(∙, Im-1)	(2)
Here gωis an approximation to the real drift term g, in our research, we treat gω as a neural network
with parameters ω . Let us now denote P(∙, t) as the density of Xt.
Then it is natural to compute and minimize the discrepancy between our approximated density P(∙, Im)
and true density P(∙, Im), within this process, we are optimizing gω and thus will recover the true drift
term g. In our research, we choose the Wasserstein-1 distance as our discrepancy function (Villani,
2008) (Arjovsky et al., 2017). Now we apply Kantorovich-Rubinstein duality (Villani, 2008), this
leads to:
W1(P(∙, tm), P(∙, tm)) = sup {Eg〜P(x,tm)[f(Xr)] - Exg〜P(x,tfn)[f(Xg)]}	(3)
IV f k≤1
The first term Exr〜P(χ,tm)[f(xr)] in Equation (3) can be conveniently computed by Monte-Carlo
method since We are already provided with the real data points Xr 〜P(∙, tm). To evaluate the second
term, we first approximate P(∙, tm) by trapezoidal rule (Atkinson, 2008):
,、	7 ,	∆ A t ∕∂ P (x, tm -1)	- P (x, Im )∖	LA,,,	/八
P(x, tm) ≈ P(x, tm-1) + y I----t-------+ --t-	here At = tm - tm-i.	(4)
And thus we can compute:
Q	「勺 Vl f Z-Z ʌ^z ,	_LAt ( ∂ ∂P(x, tm-1) Qz ɪ ∂ ∂P(x, tm)勺 M \ …
Exg〜P(∙,tm)[f(xg)] ≈ f(x)P(x, tm-1)dX + y	——∂t——f(x)dX + -∂t-f(x)dX (5)
In the above Equation (5), the second and the third term on the right-hand side can be reformulated
via the weak form of FPE and we are able to derive a computable formulation for W1(P(∙, tm), P(∙, tm)).
Furthermore, we can use Monte-Carlo method to approximate the expectations in (5). the first and
the second terms can be directly computed via data points from P(∙, tm-1). For the third term, we need
to generate samples from P(∙, tm), to achieve this, we apply Euler-Maruyama scheme (Kloeden &
Platen, 2013) to SDE (2) in order to acquire our desired samples Xtm:
Xtm =	Xtm-I	+	gω(Xtm-1)At +	σ √AtZ	here N 〜N(0, I),	Xtm-I	〜P(∙, tm-1).	(6)
Here N(0, I) is the standard Gaussian distribution on RD . Now we summarize these results in
Proposition 1:
3
Under review as a conference paper at ICLR 2021
Proposition 1. For a set of points X = {x(1), ..., x(N)} in RD. We denote:
'f(X) = N X*ω(x(k))∂>k)) + 2σ2X Mf(xk)))
k=1 i=1	i=1	i
then at time point tm, the Wasserstein distance between P(∙, tm) and P(∙, tm) can be approximated by:
{ 1 N	1 N JB ∆ t 人	~	)
W1( p (∙,tm ), p (∙, tm )) ≈ SUP ]讨 2 fX tm)) - N 2 f (X tm )ι) - E Vf (Xm -1) + F (X m )))
H f k≤1 INQ	Nt=	Z
Here {X tIm -1} ~ PG tm-1), {X (1)} ~ p (∙, tm) and we denote Xm-1 = {X tmj-ι,..., X tN)J, Xm = {X tm),.., X (N)},
where each X(k) is computed by Euler-Maruyama Scheme (6).
2.3 Wasserstein Distance on Time Series
In real cases, it is not realistic to observe the data at arbitrary two consecUtive time nodes, esPecially
when ∆t is small. To make oUr model more flexible, we shoUld extend oUr formUlation so that we are
able to PlUg in observed data at arbitrary time Points. To be more Precise, sUPPose we observe data
set Xtn = {X(1),..., X(N)} at J + 1 different time points 10,11,..., tj. And We denote the generated data
Setas Xtn = {X (1),...,X(N)}, here each X(/ is derived from the n-step Euler-Maruyama scheme:
Xtj = Xtj-1+ gω(Xtj-1)∆t + σ √∆tz, with Z 〜N(0, I) 0 ≤ j ≤ n, Xt0 〜p(∙, 10)	(7)
Let US denote p(∙, t) as the solution to FPE (1) with g replaced by gω and with initial condition p(∙, 10)=
P(∙, 10), then the approximation formula for evaluating the Wasserstein distance W1(p(∙, tn), p(∙, tn)) is
provided in the following proposition:
Proposition 2. Suppose we keep all the notations defined as above, then we have the approximation:
(1 N	1 N	∆ t	n-1
F ∑f(Xtk))- F ∑f(X(k))- F(Ff(X0) + Ff(Xn) + 2∑Ff(Xs))
N k=1	n N k=1	0	2	s=1
Minimizing the Objective Function: Based on Proposition 2, we obtain objective function by
summing up the accumulated Wasserstein distances among J observations along the time axis. Thus,
our ultimate goal is to minimize the following objection function:
(J	( N	N N	n-1	ʌʌ
min 岳 sup {1 Xfn (X tk)) - ɪ Xfn (X 却 - ∣t (FI (X 0) + FI (X n) + 22 FI (X S)用
gω [n=1 IMfnk≤1[N 自	N 自	2	£
Notice that since we have observations on J distinct time points(despite the initial point), for each
time point we compute Wasserstein distance with the help of the dual function fn, thus we will
involve J test functions in total. In our actual implementation, we will choose these dual functions as
neural networks. We call our algorithm Fokker Planck Process(FPP), the entire procedure is shown
in Algorithm 1. We also provide an error analysis in Appendix.
3	Experiments
In this section, we evaluate our model on various synthetic and realistic data sets by employing
Algorithm 1. We generate samples Xt and make all predictions base on Equation (6) starting with X0.
Baselines: We compare our model with two recently proposed methods. One model (NN) adopts
recurrent neural network(RNN) to learn dynamics directly from observations of aggregate data
(Hashimoto et al., 2016). The other one model (LEGEND) learns dynamics in a HMM framework
(Wang et al., 2018). The baselines in our experiments are two typical representatives that have state-
of-the-art performance on learning aggregate data. Furthermore, though we simulate the evolving
process of the data as a SDE, which is on the same track with NN, as mentioned before, NN trains its
RNN via optimizing Sinkhorn distance (Cuturi, 2013), our model starts with a view of weak form of
PDE, focuses more on WGAN framework and easier computation.
4
Under review as a conference paper at ICLR 2021
Algorithm 1 Fokker Planck Process Algorithm
Require: Initialize fθn (1 ≤ n ≤ J), gω
Require: Set fn as the inner loop learning rate for fθn and g as the outer loop learning rate for gω
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
for # training iterations do
for k steps do
for observed time ts in {t1, ..., tJ} do
Compute the generated data set Xts from Euler-Maruyama scheme (7) for 1 ≤ S ≤ J
Acquire data sets Xts = {X(I),…,X(N)} from real distribution P(∙, ts) for 1 ≤ S ≤ J
end for
For each dual function fθn , compute:
F = Fθn (Xto) + Fθn (Xtn) + 2 P"n-} F,„ (X,，)
Update each f „ by θn 一 θn + C川(N PN=1 fen(Xt：)) - N P3 fe„(Xt?)-号Fn)
end for
Update gω by ω 一 ω - cSV。(PJ =1(N fθ„(X(k)) - N fθ„(Xt?)-黑F))
end for
3.1	Synthetic Data
We first evaluate our model on three synthetic data sets which are generated by three artificial
dynamics: Synthetic-1, Synthetic-2 and Synthetic-3.
Experiment Setup: In all synthetic data experiments, we set the drift term g and the discriminator
f as two simple fully-connected networks. The g network has one hidden layer and the f network
has three hidden layers. Each layer has 32 nodes for both gand f. The only one activation function
We choose is Tanh. Notice that since We need to calculate 嚷,the activation function of f must be
twice differentiable to avoid loss of weight gradient. In terms of training process, we use the Adam
optimizer (Kingma & Ba, 2014) With learning rate 10-4. Furthermore, We use spectral normalization
to realize kVfk ≤ 1(Miyato et al., 2018). We initialize the Weights With Xavier initialization(Glorot &
Bengio, 2010) and train our model by Algorithm 1.
Synthetic-1:
X0 ~ N(0, ∑o),	Xt +∆t = Xt - (AXt + b)∆t + σ √∆tN(0,1)
Synthetic-2:
X0 〜N(0, ∑o),	Xt+∆t = Xt - G∆t + σ √∆N(0,1)
G=
六 NNN(X 1 - μ11)+ σ12 NNN(X1 - μ21)
0
0
σ^ NNN (X2 - μ12) + σ12 NNN2 (x2 - μ22)
-71-	exp I-(X1-/211)2 - (X1 -/212)2 ], N2 = -L- exp I-(XL-φ22 - X-]
√2∏σ1	k	2σ2	2σ2	)	√2∏σ?	k	2σ2	2σ2	)
Synthetic-3 (Van der Pol oscillator (Li, 2018)):
X0 〜N(0, ∑0)
X 1+∆t = X1 + 10k2 - 3(X1)3 + X 1)∆t + σ√∆N(0,1)
X2+δt = X2 + 3(1 - X 1)∆t + σ √∆tN(0,1)
The data size at each time point is N = 2000, the dimension of the data is D = 2. We treat 1200
data points as the training set and the other 800 data points as the test set. In Synthetic-1, the data is
folloWing a simple linear dynamic, Where A = [(4, 0), (0, 1)], b = [-12, -12]T. We let ∆t = 0.01,
σ = 1, Σ0 = [(1, 0), (0, 1)]. We utilize true X0, X20 and X200 in training process and predict the
5
Under review as a conference paper at ICLR 2021
(a) Syn-1
at 10∆t	(b) Syn-1
at 50∆t	(c) Syn-1: at 500∆t	(d) Syn-2: at 2∆t	(e) Syn-2: at 4∆t
(f) Syn-2: at 10∆t	(g) Syn-3: at 10∆t	(h) Syn-3: at 30∆t	(i) Syn-3: at 50∆t
Figure 2: Comparison of generated data(blue) and ground truth(red) of Synthetic-1((a) to (c)),
Synthetic-2((d) to (f)) and Synthetic-3((g) to (i)). In each case, it finally converges to a stationary
distribution.
distributions of x50 and x500. In Synthetic-2, the data is following a complex nonlinear dynamic.
We let ∆t = 0.01, σ = σ1 = σ2 = 1, μ1 = [15,15]T and μ2 = [-15, -15]T. We utilize true x0, x3
and x6 in training process and predict x2, x4 and x10. In Synthetic-3, ∆t = 0.01, σ = 1, we utilize
true x3, x7 and x20 in training process then predict the distributions of x10, x30 and x50. We also
consider cases in higher dimensions: D = 6 and 10. In each high dimensional case, to be convenience,
we set every two dimensions follow the dynamics of low dimensional case(D = 2) in each data set.
Notice that in Syn-2 and Syn-3, xlt represents the i-th dimension of Xt.
Results: We first show the capability of our model for learning hidden dynamics of low-dimensional
(d = 2) data. As visualized in Figure 2, the generated data(blue) covers all areas of ground truth(red),
which demonstrates that our model is able to precisely learn the dynamics and correctly predict the
future distribution of data. The samples we predict converge to stationary distributions finally (as the
ground truths suggest). We then evaluate three models using Wasserstein distance as error metric for
both low-dimensional (d = 2) and high-dimensional (d = 6, 10) data. As reported in Appendix Table
1, our model achieves lower Wasserstein error than the two baseline models in all cases.
3.2	Realistic Data - RNA Sequence of Single CELL
In this section, we evaluate our model on a realistic biology data set called Single-cell RNA-seq(Klein
et al., 2015), which is typically used for learning the evolvement of cell differentiation. The cell
population begins to differentiate at day 0 (D0). Single-cell RNA-seq observations are then sampled
at day 0 (D0), day 2 (D2), day 4 (D4) and day 7 (D7). At each time point, the expression of 24,175
genes of several hundreds cells are measured (933, 303, 683 and 798 cells on D0, D2, D4 and D7
respectively). Notice that there is only whole group’s distribution but no trajectory information of
each gene on different days. We pick 10 gene markers out of 24,175 to make a 10 dimensional data
set. In first task we treat gene expression at D0, D4 and D7 as training data to learn the hidden
dynamic and predict the distribution of gene expression at D2. In second task we train the model
with gene expression at D0, D2 and D4, then predict the distribution of gene expression at D7. We
plot the prediction results of two out of ten markers, i.e. Mt1 and Mt2 in Figure 3.
Experiment Setup: We set both f and g as fully connected three-hidden-layers neural networks,
each layer has 64 nodes. The only activation function we choose is Tanh. The other setups of neural
networks and training process are the same with the ones we use in Synthetic data. Notice that in
realistic cases, ∆t and T/∆t become hyperparameters, here We choose ∆t = 0.05, T/∆t = 35, which
means the data evolves 10∆t from D0 to D2 , then 10∆t from D2 to D4 and finally 15∆t from D4 to D7.
For preprocessing, we apply standard normalization procedures (Hicks et al., 2015) to correct batch
effects and use non-negative matrix factorization to impute missing expression levels(Hashimoto
et al., 2016; Wang et al., 2018).
6
Under review as a conference paper at ICLR 2021
(a) D2 of Mt1 (b) D7 of Mt1 (c) D2 of Mt2 (d) D7 of Mt2
(e) Correlation on D2 (f) Correlation on D7 (g) W-loss of Mt1, D2(h) W-loss of Mt1, D7
Figure 3: (a) and (b): Wasserstein loss as iteration increases of Mt1. (c) to (f): The performance
comparision among different models on D2 and D7 of Mt1 and Mt2. (g) and (h): True (red) and
predicted (blue) correlations between Mt1(x-axis) and Mt2(y-axis) on D2 (left) and D7 (right).
Results: As shown in Table 1 in Appendix, when compared to other baselines, our model achieves
lower Wasserstein error on both Mt1 and Mt2 data, which proves that our model is capable of learning
the hidden dynamics of the two studied gene expressions. In Figure 3 (a) to (d), we visualized the
predicted distributions of the two genes. The distributions of Mt1 and Mt2 predicted by our model
(curves in blue) are closer to the true distributions (curves in red) on both D2 and D7. Furthermore,
our model precisely indicates the correlations between Mt1 and Mt2, as shown in Figure 3 (e) and (f),
which also demonstrates the effectiveness of our model since closer to the true correlation represents
better performance. In Figure 3 (g) and (h), we see that with simpler structure, the training process of
our model is easier with least computation time.
3.3	Realistic Data - DAily Trading VoLUME
In this section we would like to demonstrate the performance of our model in financial area. Trading
volume is the total quantity of shares or contracts traded for specified securities such as stocks, bonds,
options contracts, future contracts and all types of commodities. It can be measured on any type of
security traded during a trading day or a specified time period. In our case, daily volume of trade is
measured on stocks. Predicting traded volume is an essential component in financial research since
the traded volume, as a basic component or input of other financial algorithms, tells investors the
market’s activity and liquidity. The data set we use is the historical traded volume of the stock "JPM".
The data covers period from January 2018 to January 2020 and is obtained from Bloomberg. Each
day from 14:30 to 20:55, we have 1 observation every 5 minutes, totally 78 observations everyday.
Our task is described as follows: given first two years data, we use the traded volume at 14:30, 14:40,
15:05, 15:20 and 16:20 as training data, namely, x0, x2, x7, x10, x22 to train our model, then for next
100 days we predict traded volume at 14:35, 15:15, 15:35 and 16:15, namely, x1, x9, x13, x21. One
of baselines we choose is classical rolling means(RM) method, which predicts intraday volume of a
particular time interval by the average volume traded in the same interval over the past days. The
other one baseline is a kalman filter based model (Chen et al., 2016) that outperforms all available
models in predicting intrady trading volume.
Experiment Setup: Following similar setup as we did for RNA data set, we utilize the same
structures for neural networks here. For hyperparameters we set ∆t = 0.02, T /∆t = 22, which means
it takes one single ∆t from xt to xt+1 . For preprocessing, we rescale data by taking natural logarithm
of trading volume, which is a common way in trading volume research. We conduct experiments on
two groups to show advantages of our method, for first group we train our model on complete data
set, in this case the data has full trajectory; for second group we manually delete some trajectories
of the data, for instance, we randomly kick out some samples of x0, x2, x7, x10, x22 then follow the
same procedures of training and prediction.
Results: We present prediction results in Figure 4. As shown in first four figures, with full trajectory,
prediction made by RM is almost a straight line, the prediction value bouncing up and down within a
7
Under review as a conference paper at ICLR 2021
(a) Comparison on 14:35 (b) Comparison on 15:15 (c) Comparison on 15:35 (d) Comparison on 16:15
(e) Comparison on 14:35 (f) Comparison on 15:15 (g) Comparison on 15:35 (h) Comparison on 16:15
Figure 4: (a) to (d): Group A: with full trajectory of training data, predictions of traded volume in
next 100 days, RM(yellow) fails to capture the regularities of traded volume in time series, kalman
filter based model(green) fails to capture noise information and make reasonable predictions, our
model(blue) is able to seize the movements of traded volume and yield better predictions. (e) to (h):
Group B: predictions of our model without full trajectory.
very small range, thus this model cannot capture the volume movements, namely, regularities existing
in the time series; prediction made by the Kalman filter based model captures the regularities better
than RM model, but it fails to deal with noise component existing in the time series, thus some
predictions are out of a reasonable range. Traded volume predicted by our model is closer to the real
case, moreover, our model captures regularities meanwhile gives stable predictions. Furthermore,
without full trajectory, Kalman filter based model fails to be applied here and RM model still fails to
capture the regularities, we randomly drop half of the training samples and display predictions made
by our model in last four figures of Figure 4, we see our model still works well.
4	Discussions
In this section we discuss the limitations and extension of our model.
An essential challenge for recovering the drift term: Mathematically it is impossible to recover
the exact drift term of an SDE if we are only given the information of density evolution on certain
time intervals, because there might be infinitely many drift functions to induce the same density
evolution. More precisely, suppose p(x, t) solves FPE (equation 1), consider the following equation
D ∂ i	σ2 D	∂2
0 = - H 匹 3(羽 t) P (x，t))+ H g 端 p (x，t)
(8)
One can prove, under mild assumptions, that there are infinitely many vector fields u(x, t) =
(u1(x, t), ..., uD(x, t)) solving equation (8). One can check that the solution to FPE (1) with drift
term g(x, t) + u(x, t) is still P(x, t), i.e. the vector field u(x, t) will never affect the density evolution
of the dynamic. This illustrates that given the density evolution P(∙, t), the solution for drift term is
not necessarily unique. This is clearly an essential difficulty of determining the exact drift term from
the density. In this study, the main goal is to recover the entire density evolution (i.e. interpolate the
density between observation time points) and predict how will the density evolve in the future. As a
result, although we cannot always acquire the exact drift term of the dynamic, we can still accurately
recover and predict the density evolution. This is still meaningful and may find its application in
various scientific domains.
8
Under review as a conference paper at ICLR 2021
(a) Training data
(b) Prediction at t1
(c) Prediction at t3
(d) Vector field
Figure 5: Results of learning curl field:(a): the whole distribution is indicated by green, from which
we choose subsets for training purpose, training samples at t0 , t1 , t2 and t3 are indicated by pink,
orange, red and brown respectively. (b) and (c):the prediction at t1 and t3 are indicated by blue points.
(d): The vector field generated by our model.
(a) Prediction at t10	(b) Prediction at t30	(c) Prediction at t50
Figure 6: Results of learning diffusion coefficient.
Curl Field: The drift function we showed in the numerical experiments will apparently cause the
evolution of the distribution. If the drift function is a curl, namely g = V × F, then the distribution
does not change, is it still possible to learn the density evolution? The answer is yes. To demonstrate
this point of view, we simulate a curl field (y, -x) induced by A = [(0, 1), (-1, 0)] on a Gaussian
distribution (indicated by green points in Figure 5 (a)), here we set noise part as 0. Realizing that our
learning is based on samples but not on the density, suppose we observe samples at four time points
which does not perfectly follow the distribution (indicated by four colors: pink(t0), orange(t1), red(t2)
and brown(t3) in Figure 5 (a)), we learn and predict the distribution at t1 and t3 (indicated by blue
points in Figure 5 (b) and (c)). We also show the vector field learned by our model in Figure 5 (d).
We see that the predictions and vector field all satisfy the correct curl field pattern.
Learning Diffusion Coefficient: Our framework also works for learning unknown diffusion coeffi-
cient in the ltð process. As an extension of our work, if We approximate the diffusion coefficient with
a neural network ση (with parameters η), we revise the operator F as:
N N	( D	A	D	D 1	刀 2	ʌ
(F(X) = N X X giω(x(())dxf (x(())+ X(X 2(σηj(x(()))2)后fx))
N k=1	i=1	∂xi	i=1	j=1 2	∂xi
(9)
which can be derived by the same technique we used to derive Proposition 1. We test this formulation
on a synthetic data set, where we only consider diffusion influence, namely, drift term in Equation
(8) is ignored. We set the ground truth of diffusion coefficient as σ = [(1, 0), (0, 2)]. We design the
neural network as a simple one fully connected layer with 32 nodes, then show our result in Figure 6,
we see that the predictions(blue) follow the same pattern as the ground truth(red) does.
5 Conclusion
In this paper, we formulate a novel method to recover the hidden dynamics from aggregate data. In
particular, our work shows one can simulate the evolving process of aggregate data as an ltð process,
in order to investigate aggregate data, we derive a new model that employs the weak form of FPE
as well as the framework of WGAN. Furthermore, in Appendix we prove the theoretical guarantees
of the error bound of our model. Finally we demonstrate our model through experiments on three
synthetic data sets and two real-world data sets.
9
Under review as a conference paper at ICLR 2021
References
D. Alshamaa, A. Chkeir, F. Mourad-Chehade, and P. Honeine. Hidden markov model for indoor
trajectory tracking of elderly people. In IEEE Sensors Applications Symposium (SAS), 2019.
Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein gan. In arXiv preprint
arXiv:1701.07875, 2017.
Kendall E Atkinson. An introduction to numerical analysis. John wiley & sons, 2008.
C. Beck, S. Becker, P. Grohs, N. Jaafari, and A. Jentzen. Solving stochastic differential equations and
kolmogorov equations by means of deep learning. 2018.
R. Chen, Y. Feng, and D. Palomar. Forecasting intraday trading volume: a kalman filter approach. In
Available at SSRN 3101695, 2016.
M. Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. In Advances in Neural
Information Processing Systems, 2013.
M. Deriche, A. A. Absa, A. Amin, and B. Liu. A novel approach for salt dome detection and tracking
using a hybrid hidden markov model with an active contour model. Journal of Electrical Systems,
16(3):276-294, 2020.
P. M. Djuric, J. H. Kotecha, J. Zhang, Y. Huang, T. Ghirmai, M. F. Bugallo, and J. Miguez. Particle
filtering. IEEE Signal Processing Magazine, 20(5):19-38, 2003.
S.	R. Eddy. Hidden markov models. Current Opinion in Structural Biology, 6(3):361-365, 1996.
Y. Fang, C. Wang, W. Yao, X. Zhao, H. Zhao, and H. Zha. On-road vehicle tracking using part-based
particle filter. IEEE Transactions on Intelligent Transportation Systems, 20(12):4538-4552, 2019.
F. Farahi and H. S. Yazdi. Probabilistic kalman filter for moving object tracking. Signal Processing:
Image Communication, 82, 2020.
X. Glorot and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks.
In International Conference on Artificial Intelligence and Statistics, 2010.
A. C. Harvey. Forecasting, structural time series models and the Kalman filter. Cambridge University
Press, 1990.
T.	Hashimoto, D. Gifford, and T. Jaakkola. Learning population-level diffusions with generative rnns.
In International Conference on Machine Learning, pp. 2417-2426, 2016.
A. Hefny, C. Downey, and G. J. Gordon. Supervised learning for dynamical system learning. In
Neural Information Processing Systems, 2015.
S.	C. Hicks, M. Teng, and R. A. Irizarry. On the widespread and critical impact of systematic bias
and batch effects in single-cell rna-seq data. bioRxiv, 2015.
R. E. Kalman. A new approach to linear filtering and prediction problems. arXiv preprint
arXiv:1805.04099, 1960.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2014.
A.M. Klein, L. Mazutis, I. Akartuna, N. Tallapragada, A. Veres, V. Li, L. Peshkin, D.A. Weitz, and
M.W. Kirschner. Droplet barcoding for single-cell transcriptomics applied to embryonic stem cells.
Cell, 161(5):1187-1201, 2015.
Peter E Kloeden and Eckhard Platen. Numerical solution of stochastic differential equations, vol-
ume 23. Springer Science & Business Media, 2013.
J. Langford, R. Salakhutdinov, and T. Zhang. Learning nonlinear dynamic models. In International
Conference on Machine Learning, pp. 593-600, 2009.
W.C. Li, S. Liu, H. Zha, and H. Zhou. Parametric fokker-planck equation. In Geometry science of
information, 2019.
10
Under review as a conference paper at ICLR 2021
Y. Li. A data-driven method for the steady state of randomly perturbed dynamics. arXiv preprint
arXiv:1805.04099, 2018.
Q. Liu and D. Wang. Stein variational gradient descent: A general purpose bayesian inference
algorithm. In Neural Information Processing Systems,pp. 2378-2386, 2016.
G. N. Milstein and M. V. Tretyakov (eds.). Stochastic numerics for mathematical physics. Springer
Science & Business Media, 2013.
T.	Miyato, T. Kataoka, M. Koyama, and Y. Yoshida. Spectral normalization for generative adversarial
networks. arXiv preprint arXiv:1802.05957, 2018.
E. Nelson. Quantum fluctuations. Princeton University Press, 1985.
Bernt 0ksendal. Stochastic differential equations. In Stochastic differential equations, pp. 65-84.
Springer, 2003.
M. Pavon, E. G. Tabak, and G. Trigila. The data-driven schroedinger bridge. arXiv preprint
arXiv:1806.01364, 2018.
D.	Qi and A.J. Majda. Low-dimensional reduced-order models for statistical response and uncertainty
quantification: Two-layer baroclinic turbulence. Journal of the Atmospheric Sciences, 73(12):
4609-4639, 2016.
D.J. Rezende and S. Mohamed. Variational inference with normalizing flows. In arXiv preprint
arXiv:1505.05770, 2015.
H. Risken. The fokker-planck equation. Springer Series in Synergetics, 18:4609-4639, 1989.
H. Risken and T.K. Caugheyz (eds.). The fokker-planck equation: Methods of solution and application.
Springer, 1991.
N. P. Santos, V. Lobo, and A. Bernardino. Unmanned aerial vehicle tracking using a particle filter
based approach. In IEEE Underwater Technology (UT), 2019.
Justin Sirignano and Konstantinos Spiliopoulos. Dgm: A deep learning algorithm for solving partial
differential equations. Journal of computational physics, 375:1339-1364, 2018.
C. Villani. Optimal transport: old and new, volume 338. Springer Science & Business Media, 2008.
Y. Wang, B. Dai, L. Kong, S. M. Erfani, J. Bailey, and H. Zha. Learning deep hidden nonlinear
dynamics from aggregate data. In Uncertainty in Artificial Intelligence, 2018.
E.	Weinan, J. Han, and A. Jentzen. Deep learning-based numerical methods for high-dimensional
parabolic partial differential equations and backward stochastic differential equations. In Commu-
nications in Mathematics and Statistics, pp. 349-380, 2017.
Y. Zang, G. Bao, X. Ye, and H. Zhou. Weak adversarial networks for high-dimensional partial
differential equations. In arXiv preprint arXiv:1907.08272, 2019.
O.C. Zienkiewicz and I.K. Cheung. The Finite Element Method in Engineering Science. McGraw-
Hill European Publishing Programme. McGraw-Hill, 1971. ISBN 9780070941380. URL https:
//books.google.com/books?id=B99RAAAAMAAJ.
11
Under review as a conference paper at ICLR 2021
A Appendix
Table 1: The Wasserstein error of different models on Synthetic-1/2/3 and RNA-sequence data sets.
Data	Task	Dimension	-NN^^	LEGEND	Ours
		2	-1.37^^	0.44	0.05
	X50	6	4.79	2.32	0.06
Syn-1		10	9.13	2.89	0.10
		2	0.84^^	0.18	0.03
	X500	6	3.28	0.30	0.03
		10	8.05	1.79	0.09
		2	5.53^^	1.27	0.05
	X4	6	9.97	4.20	0.08
Syn-2		10	16.51	6.08	0.12
		2	-1.68^^	0.53	0.05
	X10	6	4.84	1.08	0.07
		10	9.23	2.85	0.11
		2	4.13^^	1.29	0.08
	X30	6	6.40	3.16	0.17
Syn-3		10	11.76	8.53	0.25
		2	3.05^^	0.87	0.12
	X50	6	6.72	1.52	0.16
		10	9.81	3.55	0.23
RNA-Mt1	D2	10 二	33.86	10.28	4.23
	-D7-	10	12.69	7.21	2.92
RNA-Mt2	-D2-	10	31.45	13.32	4.04
	D7	10	11.58	7.89	1.50
B	Error Analysis
In this section, we provide an error analysis of our model. Suppose the hidden dynamics is driven
by gr(x), the dynamics that We learn from data is gf (x), then original It6 process, EUler processes
computed by true gr and estimated gf are:
dX = g(X)dt + σdW
X r+∆ t = Xr + gr (xr )∆ t + σ √∆N (0,1)
xf+At = Xxt + gf (xxt )∆t + σ √∆tN(0,1)
Where X is the groUnd trUth, Xr is compUted by trUe gr and Xf is compUted by estimated gf .
Estimating the error between original It6 process and its Euler form can be very complex, hence We
cite the conclUsion from (Milstein & Tretyakov, 2013) and focUs more on the error betWeen original
form and our model.
Lemma 2. With the same initial Xt0 = Xt0 = X0, if there is a global Lipschitz constant K which
satisfies:
I g(χ, t) - g(y, t )l≤ K ∣χ - y∣
then after n steps, the expectation error between Itd process Xtn and Euler forward process Xr is:
E|xtn - Xrn∣≤ K(1 + E|X0∣2)1∕2∆t
Lemma 2 illustrates that the expectation error between original It6 process and its Euler form is not
related to total steps n but time step ∆t.
12
Under review as a conference paper at ICLR 2021
Proposition 3. With the same initial x0, suppose the generalization error of neural network g is ε
and existence of global Lipschitz constant K:
Ig (χ) - g(y)l≤ κ ∣χ - y∣
then after n steps with step size ∆t = T/n, the expectation error between Ito process Xtn and
approximated forward process xtf is bounded by:
E|xtn - XfI≤ K(eKT -1) + K(1 + E∣X0∣2)1∕2∆t	(10)
Proposition 3 implies that besides time step size ∆t, our expectation error interacts with three factors,
generalization error, Lipschitz constant of g and total time length. In our experiments, we find the
best way to decrease the expectation error is reducing the value of K and n.
C Proofs
C.1 Proof of Proposition 1
Proof. Suppose x(∖) and x(:)ι are our observed samples at tm and tm-1 respectively, then expectations
could be approximated by:
Ex 〜P (X, tm )[ f (X)]
ʃ f (x)p(x, tm)dX ≈
1N
n Xf (X m)
=1
(11)
Ex 〜P (x, tm )[ f (X)] = ʃ
=Z
f (x)p(x, tm)dX
p(X, tm-1) + 广 华)dT dX
tm-1	∂t
f(x)p(x, tm-i)dX + f f(x) /	dP(XdTdX
tm-1
1 3一小	tm	a { D ∂「：	】1 CD ∂2	}
≈ Ng f(X%-I) + J f(X)Im十石乐 hgω(X)P(X，T)i+ 2σ W∂x2P(XHdτdX
|	{z	}
z
I
(12)
Then for the second term I above, it is difficult to calculate directly, but we can use integration by
parts to rewrite I as:
I
「D
tm
门X
tm-1
tm-1
i=1
∂ i	1 2 Di	∂2
-f(X)∂xgω(X)P(X,τ) + 2σ ʌf(x)∂x2 P(X,τ) dXdT
「D
f f X giω(x)P(X
tm-1
tm-1
i=1
K)"+2σ2X P(X，T)高f (X)
dXdT
tm
1,:
tm-1
「D
D .	∂
Ex 〜p(x,τ)	/	g ω(X)^- f(X)	+ Ex 〜p(x,τ)
∂xi
i=1
1	2型 八
2	σ X 遍f(X) dT
i=1 i
tm
≈t
tm-1
1 N D	∂	1 D ∂2
NX(Xgω(X )酝f )+ 2σX竭f )
dT
(13)
=1
i=1
i=1
N
/ D
D
To approximate the integral from tm-1 to tm , we adopt trapezoid rule, then we could rewrite the
expectation in Equation (12) as:
13
Under review as a conference paper at ICLR 2021
1 N	八、	Z ∖ 1" D , 小 ∂ 八、	1 一 D ∂2	小
Ex~P(x,tm)[f(x)] ≈ N X f (左加-1) + 5 N X X g七(X加-1)赤八X加-1) + 2σ X 游 f (X加T)
k =1	L k =1 i =1	i	i =1 Ali
IN D	A	ID 22	Yl
+ N XX gω(xQ ∂xf (x Q+ 2σ X 游 f (XQ
k=1 i=1	i=1 i	n
1 N 、	A t r	~ r
=N X f (Xtm-1) + V [F(Xm-1) + Ff (XIn)]	(14)
N k=1	2
We subtract (11) by (14) to finish the proof.	□
C.2 Proof of Proposition 2
Proof. Given initial X10, We generate X11, X12, X13 … Xtn sequentially by Equation (6). Then the
expectations can be rewritten as:
1N
Eχ~P(x,tn)[f(x)] = J f(x)P(x, t)dX ≈ Ngf(Xtk))
(15)
1 n	rt 1 1 n ∖ D	A	1 D	内2
Ex~P(XM)[f(X)] ≈ N X f(Xt/) + fto N XlXgω(X)匹f(X)+ 2σ X ∂Xi∂Xjf(X RdT
rt2 1 n ∖ 2	α	1	JL 0
+ ʃ N X X gω(x()而f (X()+ 2 σ X 必f (X()dT + …
JAiN k=1 L i =1	0Xi	2	i =1	0Xi	J
i 1 N ∖ JL	A	1	JL	#	1
T-IN XIXgω(X ())vx ())+2σ X 数f (X ( WT	(16)
which is:
N
Ex~P(x,tn)[f(X)] ≈ N X f(Xt?) + B %(X0) + Ff(X1)] + B %(X1) + (Ff(X2)] + ...
+ 2 ∖Ff (Xn-1) + Ff (Xn)]	(17)
Finally it comes to:
1 N	a t	n-1	、
Eχ~P(X,tn)[f(X)] ≈ N ∑f(X(7) + 工 Ff(X0) + Ff(Xn) + 2» F(XS)	(18)
We subtract (15) by (18) to finish the proof.	□
C.3 Proof of Error ANAIySIS
Proof. The proof process of Lemma 2 is quite long and out of the scope of this paper, for more details
please see first two chapters in reference book (Milstein & Tretyakov, 2013). While for the proof of
Proposition 3, with initial X and first one-step iteration:
(X r0 = X10
Xtf0 = Xt0
X r1 = X r + gr (X r,)ʌ t + σ √AtN (0,1)
XitI= X t + gf (X t0)A t + σ √AN (0,1)
(19)
(20)
14
Under review as a conference paper at ICLR 2021
Then we have:
E|xr - X11 = E|x10 - X101= 0	(21)
E∣xt1 - xf∣ = E∣xr0 - xft0 + gr(XQAt - gf (Xf)∆t + σ √∆tN(0,1) - σ √∆N(0,1)|
≤ E∣x；0 - xt0∣+E∣gr(xr0) - gf (xt0)∣∆t
=e∣ gr (x r,)- gf (x rɔ+gf(x rɔ- gf(X f )∣A t
≤ E∣gr(Xr0) - gf (Xr,)∣At + E∣gf (xr0) - gf (xf )∣At
≤ SAt + E∣gf (xr0) - gf (xf )∣At
=εA t+e∣ g f (X(I)(X r- X 力IA t	(X(I ∈ [x r, X t0])
≤ sAt + KE∣x；0 - xf ∣At
=εA t	(22)
Follow the pattern we have:
Xr2 = Xr1 + gr (x r1)A t + σ √AtN (0,1)
X ft2 = xf + gf (x f1)A t + σ √AtN (0,1)
X r =X r-1+gr (x r-I)A t+σ VAtN QI)
X ftn = Xt-1 + gf (x ftn _1)A t + σ √AtN (0,1)
(23)
(24)
Which leads to:
E∣xr2 - Xf ∣ = E∣xr1 - Xf + gr(xr1)At - gf (xf )At + σ √AtN(0,1) - σ √AtN(0,1)∣
≤ E∣xr1 - Xf ∣+E∣gr(Xr1) - gf (Xf)∣At
≤ E∣xrh - xf ∣+εAt + KE∣xrh - Xf ∣At
≤ (1 + K A t )εA t + εA t	(25)
n-1
EIXrI - X fn ∣≤ εA t X(1 + K A t)i	(26)
i=0
Now let S = P n-1(1 + K A t)i, then consider followings:
S( K A t) = S (1 + K A t) - S
n	n-1
=	(1 + KAt)i -	(1 + KAt)i
i=1	i=0
= (1 + KAt)n - 1
T
=(1 + K-)n - 1
≤ eKT - 1	(27)
Finally we have:
E∣xr - xfn∣≤ K(eK - 1)	(28)
E∣ x tn - x f∣ ≤ K (eKT-I) + K (1 + E∖ xo ∣2)1∕2A t	(29)
□
15