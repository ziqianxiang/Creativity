Under review as a conference paper at ICLR 2021
Spatially Decomposed Hinge Adversarial Loss
by Local Gradient Amplifier
Anonymous authors
Paper under double-blind review
Ab stract
Generative Adversarial Networks (GANs) have achieved large attention and great
success in various research areas, but it still suffers from training instability. Re-
cently hinge adversarial loss for GAN is proposed that incorporates the SVM mar-
gins where real and fake samples falling within the margins contribute to the loss
calculation. In a generator training step, however, fake samples outside of the mar-
gins that partially include unrealistic local patterns are ignored. In this work, we
propose local gradient amplifier(LGA) which realizes spatially decomposed hinge
adversarial loss for improved generator training. Spatially decomposed hinge ad-
versarial loss applies different margins for different spatial regions extending over-
all margin space toward all fake samples asymmetrically. Our proposed method
is evaluated on several public benchmark data sets compared to state of the art
methods showing outstanding stability in training GANs.
1 INTRODUCTION
Generative Adversarial Networks (Goodfellow et al., 2014) have achieved large attention and great
success in various research areas since it was introduced. GAN consists of two adversarial networks
(Generator and Discriminator) that are trained alternately. Discriminator is trained to distinguish
between real and generated fake samples. On the other hand, generator is trained based on the
feedback from the discriminator to make fake samples that are classified as real by the discriminator.
Thanks to its practical performance of adversarial training strategy, GAN evolved to various fields
such as image to image translation(Isola et al., 2017; Wang et al., 2018; Park et al., 2019), super
resolution(Ledig et al., 2017), text to image generation(Zhang et al., 2017), etc.
As the utilization of GAN has been expanded, it faces limited performance with images of increased
complexity and diversity in its visual characteristics. As a result, huge networks and datasets are built
that, in turn, make it more difficult to train GAN. WGAN(Arjovsky et al., 2017) changes Jensen-
Shannon divergence based adversarial loss to Earth-Mover distance based adversarial loss. This
prevents it from causing vanishing gradient when GAN has optimal Discriminator. In order to use
wGAN adversarial loss, Lipschitz constraint must be satisfied. WGAN-GP(Gulrajani et al., 2017)
satisfies Lipschitz constraint by adding gradient penalty to regularization term, and SNGAN(Miyato
et al., 2018) satisfies Lipschitz constraint through spectral normalization. McGAN (Mroueh et al.,
2017) defines wGAN adversarial loss as mean feature matching. GeometricGAN(Lim & Ye, 2017)
applies hyper-plane of soft-margin SVM to wGAN (Arjovsky et al., 2017) by hinge adversarial loss
so that the discriminator of GAN maximizes margin between two classes. The authors mention that
GeometricGAN converges to a Nash equilibrium between discriminator and generator. Hinge adver-
sarial loss (Tran et al., 2017; Lim & Ye, 2017) applied to the discriminator lets real and fake samples
falling within the SVM margins contribute to the loss, which increases training performance. In a
generator training step, however, fake samples outside of the margins that partially include unrealis-
tic local patterns are ignored in the training.
In this work, we propose spatially decomposed hinge adversarial loss for improved generator train-
ing. Spatially decomposed hinge adversarial loss applies different margins for different spatial re-
gions extending overall margin space toward all fake samples asymmetrically. To this end, we
implement a local gradient amplifier (LGA). Spatially decomposed hinge adversarial loss works
as respective gradient amplifiers in a fake sample in our method. Gradient of unrealistic region is
amplified, while gradient of realistic region is sustained. Our decomposed hinge loss is a training
1
Under review as a conference paper at ICLR 2021
scheme of dividing target goal of generating a real sample into separate multiple optimization of
local regions.
Consider a case in which more than a half of generated image including most of foreground region
looks realistic, however, remaining part is unrealistic. Practical policy for faster and stable con-
vergence is encouraging update for such unrealistic region while keeping all other realistic image
regions. Our proposed decomposed hinge adversarial loss locally amplifies the gradients of unreal-
istic regions allowing spatially adapted loss calculation and generator network update. This kind of
approach is reasonable in training a generative network because there is no fixed target image that
has to be globally optimal in spatial image space. Instead, perceptually acceptable local image parts
could be seamlessly combined building a local optimal generated image.
The contributions of our proposed work are as follows. 1) We propose spatially decomposed hinge
adversarial loss for generator training that improves the convergence and stability of GAN main-
taining perceptual image generation performance. 2) We propose Local Gradient Amplifier(LGA)
to effectively implement our spatially decomposed hinge adversarial loss in GAN. Since the struc-
ture of LGA is simple and works with any given networks, it can be easily adopted to various other
GANs. 3) Extensive evaluation experiments show that spatially decomposed hinge adversarial loss
makes generator converge faster and represent complex and diverse images better.
2 Related Works
2.1	wGAN and Lipschitz Constraint
Training GAN is min-max game in which generator G and discriminator D compete with objective
function below. Discriminator tries to distinguish between real and fake samples, and generator tries
to deceive the discriminator.
min max
GD
E [log(D(x))] - E [log(1 - D(G(z)))]
X〜Pr
Z〜Pz
(1)
where x and z indicate real samples and random latent vectors, respectively. In general, if discrimi-
nator is too accurate, generator is difficult to acquire direction of training due to vanishing gradient
problem. wGAN shows that Jensen-Shannon divergence causes gradient vanishing when GAN has
optimal discriminator. wGAN design a discriminator loss using Earth-Mover distance so that GAN
is capable of reflecting distance required to move fake distribution to real distribution.
EMD = inf	E(χ,y)〜Y||x - y||
γ∈ Q(Pr ,Pg )
(2)
where (Pr, Pg) denotes the set of all joint distributions, and γ(x, y) indicates joint distribution.
However it is difficult to calculate joint distribution for all real and fake samples for calculating
EMD. Minimizing the EMD transforms nice equation through Kantovich-Rubinstein duality to ex-
clude joint distribution.
min max E [D(x)] - E [D(G(z))]
(3)
In wGAN, critic (Discriminator of wGAN) no longer calculates probabilities of samples. Critic
searches for decision boundary which can distinguish between two classes. This solves gradient
vanishing that occurs when GAN has optimal discriminator. In order to use minimizing problem of
EMD as maximizing problem, discirminator must satisfy ||f ||Lip ≤ 1(kantovich-Rubinstein dual-
ity). Lipschitz constraint for critic f is as follows.
||f(x)-f(x0)||
||x - x0||
≤1
(4)
wGAN constrains weights of Discriminator to exist in [-c, c] space through weight clipping to
satisfy Lipschitz constraint. WGAN-GP(Gulrajani et al., 2017) argue that weight clipping frequently
causes over fitting, and training is affected too much by hyper-parameter c. WGAN-GP suggests
gradient penalty to satisfy Lipschitz constraint. They add gradient penalty as regularization term of
critic loss.
L = E [D(x)] - E [D(G(z))] + λ E [(∣∣VχD(X)∣∣2 - 1)2]
X〜Pr	Z〜Pz	^〜Px
(5)
2
Under review as a conference paper at ICLR 2021
Gradient penalty finds a random sample X between real and fake samples. This X is located in
direction in which fake sample is to be learned. So making VχD(X) ≤ 1 for all random samples X,
Lipschitz constraint can be satisfied through entire learning process. SNGAN(Miyato et al., 2018)
focuses on Lipschitz’s inequality ||g1 ◦ g2||Lip ≤ ||g1 ||Lip ◦ ||g2||Lip. They argue that if each layer
of discriminator satisfies Lipschitz constraint, discriminator can satisfy Lipschitz constraint as well.
L+1
||f ||Lip ≤ Y ||hl-1 7→ Wlhl-1 ||Lip	(6)
l=1
For a linear layer g(hl) = W lhl, Lipschitz norm of g is ||g||Lip = suphlσ(Wl) = σ(Wl) and
σ(W l) is the largest singular value of Wl . SNGAN satisfies Lipschitz constraint by dividing all
Discriminator’s layer by its σ(Wl).
WSN(Wl) ：= Wl/σ(Wl)	(7)
2.2	Hinge Adversarial Loss
wGAN makes Discriminator build a decision boundary to distinguish between two classes, not prob-
ability. This prevents GAN from having gradient vanishing when Discriminator is optimal. How-
ever, it is difficult to find an appropriate decision boundary when real and fake samples are not
clearly separable. Tran et al. (2017), Lim & Ye (2017) propose hinge adversarial loss with soft
margin SVM (Scholkopf et al., 2002), (Cortes & Vladimir, 1995) that is applied to the decision
boundary of Discriminator. When designing critic of wGAN, channel of last convolution layer is
set to 1. Thus, output of critic is a single n × n feature map. McGAN (Mroueh et al., 2017), which
inspired GeoGAN, fixes output of critic as a single 1 × 1 feature map, so that the final convolu-
tion layer w acts as a weighted sum. The critic of McGAN can be expressed as the product of the
final convolution layer v and Φζ(gθ(zi)), remaining layers of critic excluding v. Loss function of
McGAN is as follows.
L(v, ζ, θ) =
1n	1n
(v,n X φζ(Xi)- n X φζ (gθ (Zi)))
i=1	i=1
(8)
where v, ζ, θ are weight parameters of Last conv layer, discriminator, generator respectively. h i
indicates inner product. As a result, final output of McGAN’s critic is transformed into an equation
comparing mean features of Φζ (Xi) and Φζ (g(zi)) through weighted sum v. GeoGAN sets last
convolution layer w as decision function of SVM. Discriminator learns to maximize margin between
two classes, and generator learns to move fake samples toward real class plane. However, because
L(v, ζ, θ) searches for decision boundary with hard margin, this makes it difficult to search for
optimal decision boundary when fake and real samples are intermixed. GeoGAN adapts soft margin
SVM to resolve the problem. The primal form of the soft margin SVM is as follows.
mmin 2 ||v||2 + C Xi(ξi + ξi0)	(9)
subject to hv, Φζ (Xiyi + b ≥ 1 一 ξi, i = 1,…，n
hv, φζ(gθ(Zi)) + b ≤ ξi 一 1, i = 1,…，n	(10)
ξi,ξ0 ≥ 0,	i = 1,…，n
where ξi is value of how far each sample is out of class plane, and C is a hyper-parameter that
determines how much classification mistakes are reflected. We can make the problem of optimizing
objective function f(X) under the constraint g(X) = 0 into an equation through Lagrange Multiplier
method F(x, y) = f (x) + y * g(X).
1	2	1n
min 2C-||v|| + -EmaX(0, 1 -〈v, Φζ(x/)
v,b	2Cn	n i=1
1n
+--y~^maX(0,1 + hv,Φζ(gθ(Zi))i)
(11)
i=1
Hinge adversarial loss constrains D(X) to greater than 1 and D(G(Z)) to less than -1. Such con-
straints ignore values of samples properly classified in each class. However, it gives penalties for
3
Under review as a conference paper at ICLR 2021
One Tensor
Figure 1: Discriminator with Local Gradient Amplifier (LGA) for the implementation of spatially
decomposed hinge adversarial loss
misclassified samples proportional to the distance from the class boundary. This hinge adversarial
loss not only makes discriminator more focused on misclassified samples, but also makes the loss
easier to control than conventional adversarial loss by setting the decision boundary to 0.
3 Proposed Method
Our proposed spatially decomposed hinge adversarial loss is defined as follows.
LD = - E [min(0, -1 + D(x))] - E [min(0, -1 - D(G(z))]
X〜Pr	Z〜Pz
LG = - E [Di,j(G(z))] ≈ - E [DLGA(G(z))]
(12)
where discriminator loss LD is identical to the traditional hinge adversarial loss for GAN. In gener-
ator loss LG, Di,j represents discriminator output calculated from (i, j)th feature value of the final
feature map Y ∈ Rn×n . we approximate Di,j by DLGA where LGA represents our Local Gradient
Amplifier as illustrated in Figure 1. In the back-propagation process of traditional GANs, gradients
are equally propagated backward from the feature map of discriminator. In this case, entire spatial
regions of the generator that created current fake images will be updated without any spatial priority
and, as a result, regardless of whether particular spatial region in the generator contributed to the
unrealistic part of the fake image or not. The output value of discriminator can be either a simple
scalar value of 1 × 1 or a feature map ofn × n. If the last layer of discriminator is a 1 × 1 convolution
layer with a single filter, output will be a single n × n feature map. We focus on this last layer v
that operates as a decision function determining real or fake locally. By using v , we implement our
Local Gradient Amplifier.
DLGA in the calculation of LG, we build an amplification map A ∈ Rn×n by duplicating final
feature map Y ∈ Rn×n. And we adjust A so that a value greater than 1 becomes 1.
Ai,j = min(Yi,j, 1)	(13)
We perform pixel-wise multiplication with amplification map and original final feature map.
ʌ	，- ∙、
Y = Y Θ A	(14)
Note that Y is created to calculate only LG and train generator. Based on the amplification, gradient
of Y is calculated as follows, with which we amplify gradients that propagate to locally unrealistic
area in a generated image.
dLG	dLG
dYj = IF × Aij
(15)
4
Under review as a conference paper at ICLR 2021
0	200	400	600	800	1000
Epochs
(a) CIFAR-10
0	200	400	600	800	1000
Epochs
(b) STL-IO
O 20000	40000	60000	80000
Iterations
(c) LSUN bedroom
Oooooooo
87654321
υ.J8lΛQe
(d) CeIebA
Figure 2: FID scores on various data sets. All trainings are conducted with WGAN-GP and RM-
SProp. The resolutions of generated images are 32 × 32 for CIFAR10 and STL10 and 64 × 64 for
CelebA and LSUN bedroom.
4	Experimental evaluation
4.1	Implementation Details
We conduct experimental evaluation on various benchmark data sets; CIFAR-10, STL-10, CelebA,
and LSUN bedroom. For LSUN bedroom and CelebA, we set generator to make 64 × 64 images. For
CIFAR-10 and STL-10, 32 × 32 images are generated. We use Adam optimizer with β1 = 0, β2 =
0.9. We have observed that learning process becomes unstable when momentum decay term β1 is
large, so we only use RMSProp term in our tests. We use gradient penalty and spectral normalization
to satisfy Lipschitz constraint. Weight clipping is used only to reproduce GeoGAN(Lim & Ye,
2017). The hyperparameter λ of gradient penalty was set to 10 in default WGAN-GP only, and 1 for
other experiments. WGAN-GP with LGA 4 × 4 and 8 × 8 mean final output of critic is set to 4 × 4
and 8 × 8 feature map, respectively. We apply our LGA to these final feature maps. WGAN-GP with
zero LGA 4 × 4 means an experiment in which gradient, which is propagated to filters of Generator
that contributed realistic area, is completely blocked by setting Ai,j = min(Yi,j , 0). For spectral
normalization, we experiment only LGA 4 × 4. Resnet based SNGAN makes Φζ (x) which is input
of last layer v into a c×1×1 feature through global sum pooling. We apply 2 × 2 average pooling
with stride 2 to apply LGA, maintaining the role of global sum pooling of SNGAN. To maintain
the role of global sum pooling of SNGAN, we multiply the output of average pooling by 64. For
quantitative evaluation, We calculate Frechet inception distance (HeUsel et al., 2017) and Inception
score. Experiments are performed with 10k real samples and 10k fake samples except experiments
on STL-10. For STL-10, We evaluate netWorks With 5k real samples and 10k fake samples due to
the lack of training data. Table (1) and (2) summarize all of our experimental results.
5
Under review as a conference paper at ICLR 2021
Table 1: FID score comparison on four benchmark data sets
Method	CIFAR-10	STL-10	CelebA	LSUN bedroom
GeoGAN	36.14	49.95	13.96	48.58
wGAN-GP	22.59	55.40	11.15	64.01
WGAN-GP + hinge loss	23.30	69.72	16.07	57.12
WGAN-GP + LGA 4 × 4	19.31	43.41	18.85	53.46
WGAN-GP + zero LGA 4 × 4	20.20	45.61	8.59	52.08
WGAN-GP + LGA 8 × 8	16.61	35.83	7.68	42.17
Table 2: Inception score and FID score of SNGAN based evaluation
Method	CIFAR-10	STL-10 Inception score FID Inception score FID
SNGAN SNGAN + LGA	8.3	17.33	7.2	36.05 8.5	18.16	7.3	34.02
4.2	Results on Cifar- 1 0 and Stl-10
We conduct experiments on CIFAR-10 and STL-10 with WGAN-GP based networks for 100 epochs.
Figure 2 (a), (b) show FID scores on CIFAR-10 and STL-10. We measure FID score every 10
epochs. For generating 32 × 32 image, after around 50 epochs, networks without LGA do not
decrease the score as the training progressed. On the other hand, networks with LGA show better
and stable FID score decrease as the number of epochs increased. In Figure 2, prior methods diverge
after they show converging curves on Cifar10. We calculate average and std of FID scores within
20% of lowest FID from respective lowest FID score positions for Stl-10: wGAN-GP(64.6%(3.6)),
wGAN-GP with hinge(74.0%(6.6)), LGA 4 × 4(54.6%(3.8)), LGA zero4 × 4(58.3%(3.3)), LGA
8 × 8(52.5%(3.4)). After 200 epochs, some tests without LGA look to have mode collapse. These
mode collapses are found not only with WGAN-GP based previous networks but also in SNGAN
based previous networks. Figure 3 shows both mode collapsed and unstable sample results appeared
over 100 epochs. Figure 5 shows results after 1000 epochs. WGAN-GP with hinge loss produces
blurry images, but other networks with LGA generate clean and diverse samples at 1000 epochs.
(You can check the occurrence of mode collapse at Figure 6 in appendix.)
4.3	Results on CelebA and LSUN bedroom
For LSUN bedroom, we train our networks 2 epochs, and measure FID score every 1000 iterations.
And for CelebA, we train our networks 50 epochs, and measure FID score every epoch. Figure 2 (c),
(d) show FID score on LSUN bedroom and CelebA. For generating 64 × 64 image, we observe the
networks with LGA converge faster than others. In training LSUN bedroom, WGAN-GP with LGA
8 × 8 takes 21000 iterations until it reach 100 FID score, but WGAN-GP takes 37000 iterations. In
training CelebA, WGAN-GP converges 5 epochs slower than WGAN-GP with LGA 8 × 8. Figure 4
shows generated image samples. WGAN-GP with LGA for both data sets shows faster convergence
with higher diversity in generated images.
4.4	Results on Spectral Normalization
SNGAN(Miyato et al., 2018) shows remarkable result on CIFAR-10 and STL-10 through resnet
based networks. We incorporate LGA 4 × 4 to the networks. Table 2 shows quantitative evaluation
results of original SNGAN and SNGAN with LGA 4 × 4. In these experiment we evaluate using
Inception Score(Salimans et al., 2016) and FID. For CIFAR-10, we train our networks 50000 iter-
ations to reproduce SNGAN’s results. For STL-10, we train our networks only 10000 iterations,
6
Under review as a conference paper at ICLR 2021
because we observe mode collapse after 20000 iterations on original SNGAN. Figure 6 in appendix
shows mode collapse on STL-10. We generates 32 × 32 images both CIFAR-10 and STL-10.
塞温罕圉二
Figure 3: Intermediate results of Training with STL10 and CFIAR10. When training highly complex
dataset without LGA, Generator often produces patterns which look like mode collapse.
Figure 4: Intermediate results of Training with LSUN bedroom and CelebA. When generating 64 ×
64 images, LGA shows much faster convergence than previous methods.
7
Under review as a conference paper at ICLR 2021
Figure 5: Generated images with WGAN-GP based network on CIFAR-10. Without LGA, Genera-
tor produces image with poor representation.
照周幅E斤3f幽4∙
国■悔肝官穿帆堂;L
m E3⅛l w⅛H / T
嵬∙1E雇 SHB-'
F曰&的■《就
“钗飞力鸣不通/目
■■割∙∙∙∙IS∙∙
就IS*曹甦疆■即侪礴
二,工0∏F短r三麋
ULF碧匕IHK^⅛
军&般降Ξ^"E^≡ɑ
星曦选事巴&ES注餐0
海即PI第麴*UiaX代
4«陶■;；.『二建」
加0眶总第傲国SSSln
K糕甚篝R∙K3∙“建
『居E号个♦雷磁■,
已汛LJ知屋」或0ιi承
詹后A嗒Ela察FJg。
■却窃取¥
Z 二 K :
国巴镌
■B昱
Q『南忑
aIM匿■■
beb∙
-百a*
Sl^
5	Conclusion
In this paper, we propose Local Gradient Amplifier(LGA) which realizes spatially decomposed
hinge adversarial loss for improved generator training. Structure of LGA is simple and easy to adopt
in various networks. By using LGA, we can train GAN more quickly and stably.
8
Under review as a conference paper at ICLR 2021
References
Martin Arjovsky, Chintala Soumith, and BottoU Leon. Wasserstein gan. arxiv:1701.07875, 2017.
Corinna Cortes and Vapnik Vladimir. Support-vector networks. Machine learning, 20.3:273-297,
1995.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. NIPS, 2014.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C. Courville. Im-
proved training of wasserstein gans. NIPS, 2017.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a two time-scale update rule converge to a local nash equilibrium. NIPS, 2017.
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with
conditional adversarial networks. CVPR, 2017.
Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro
Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, and Wenzhe Shi. Photo-
realistic single image super-resolution using a generative adversarial network. CVPR, 2017.
JaeHyun Lim and JongChul Ye. Geometric gan. arxiv:1705.02894, 2017.
Takero Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization
for generative adversarial networks. ICLR, 2018.
Youssef Mroueh, Tom Sercu, and Vaibhava Goel. Mcgan: Mean and covariance feature matching
gan. ICML, 2017.
Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu. Semanitc image synthesis with
spatially-adaptive normalization. CVPR, 2019.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.
Improved techniques for training gans. NIPS, 2016.
Bernhard Scholkopf, Alexander J. Smola, and Francis Bach. Learning with kernels: SuPPort vector
machines, regularization, optimization, and beyond. MIT Press, 2002.
Dustin Tran, Rajesh Ranganath, and David M. Blei. Deep and hierarchical implicit models.
arXiv:1702.08896, 2017.
Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan Catanzaro. High-
resolution image synthesis and semantic manipulation with conditional gans. CVPR, 2018.
Han Zhang, Tao Xu, Hongsheng Li, shaoting Zhang, Xiaogang Wang, Xiaolei Huang, and Dimi-
tirs N. Metaxas. Stackgan: Text to photo-realistic image synthesis with stacked generative adver-
sarial networks. CVPR, 2017.
A Additional Experiment results
9
Under review as a conference paper at ICLR 2021
with LGA
without LGA
IOk iterations
20k iterations
30k iterations
40k iterations
5θk iterations
Figure 6: Generated images with SNGAN based network on STL-10. We can see original SNGAN
occurs mode collapse when training with long iterations.
10
Under review as a conference paper at ICLR 2021
IOOepoch;
IOOOepoch;
nF嘘 A□d∙≡*κ
-I ≡Bi^^
lstei≡^^⅛
蜀JN■兽目M7蹲要
ipm ɪ^sa
r 窿・卷木■
E⅜∙制淡一|鹘
WGAN-GP
WGAN-GP with hinge loss
‰EΣl 空a簿QHE1≡
βlss3s^
* επnlRai
漕滕5网同¥¥界什
WGAN-GP with LGA 4x4
Figure 7: Generated images with WGAN-GP based network on CIFAR-10. For CIFAR-10, we train
our networks with 1000 epochs.
11
Under review as a conference paper at ICLR 2021
IOOepochs
1OOOepochs
QA”展≡爆豆≡≡般
ħ/ S *>HF
ES在蜜代XKHI施O
RBHPBB^nn
吧3IEH灌事笈Al鬣
∕q∖q∙7s国国<
BSQAEM 酒D『
WGAN-GP with zero LGA 4x4
Figure 7: Generated images with WGAN-GP based network on CIFAR-10. For CIFAR-10, we train
our networks with 1000 epochs.
一三-蜜，，KvB-∙SG
.f ;嵬国u—
BΞEΓ"≡*≡溺西勇
WN 金■-E EBH
Sewiis
一 ∙ £、.$ 鸨kH
蒯h⅛i13Ξs* 第工穿
iHBQΠ i≡
海£网SBES≡a∙
12
Under review as a conference paper at ICLR 2021
CelebA	LSUN bedroom
WGAN-GP with LGA 8x8
Figure 8: Generated images with WGAN-GP based network on CelebA and LSUN bedroom. For
CelebA, we train our networks with 50 epochs. For LSUN bedroom, we train our networks with 2
epochs.
13