Under review as a conference paper at ICLR 2021
Computing Preimages of Deep Neural Net-
works with Applications to Safety
Anonymous authors
Paper under double-blind review
Ab stract
To apply an algorithm in a sensitive domain it is important to understand the set of
input values that result in specific decisions. Deep neural networks suffer from an
inherent instability that makes this difficult: different outputs can arise from very
similar inputs.
We present a method to check that the decisions of a deep neural network are as in-
tended by constructing the exact, analytical preimage of its predictions. Preimages
generalize verification in the sense that they can be used to verify a wide class of
properties, and answer much richer questions besides. We examine the function-
ing and failures of neural networks used in robotics, including an aircraft collision
avoidance system, related to sequential decision making and extrapolation.
Our method iterates backwards through the layers of piecewise linear deep neural
networks. Uniquely, we compute all intermediate values that correspond to a
prediction, propagating this calculation through layers using analytical formulae
for layer preimages.
1	Introduction
Folk wisdom holds that although deep neural networks (DNNs) can achieve excellent predictive
accuracy, reasoning about their performance is difficult, even for experts. Our goal is to enable non-
expert stakeholders, such as clinical health workers, investors, or military commanders to build trust
a statistical model in high-stakes environments. To do this, we posit that decisionmakers want to
understand a model in both directions, both from inputs to outputs, but also being able to start with
hypothetical outputs, and understand the inputs that lead to them.
In this paper, we develop an equivalent, but much simpler, representation of a certain class of DNN
classifiers. This representation, which requires only a basic numeracy to productively interact with,
can be used by domain experts to build intuition and trust. We apply this method to a reinforcement
learning agent trained to solve the cart-pole problem, and find that a DNN implementing a successful
policy makes a particular type of mistake on 24% of the mass of the 1/8th of the state space for
which we know the optimal action (Section 3.2). We also show how using the preimage in place
of verification can yield a more efficient and interpretable end-to-end system for analyzing aircraft
collision avoidance systems (Section 3.3).
1.1	Previous work
DNNs have the property that knowing the output tells us very little about the input it corresponds to.
This is most apparent in image classifiers, where totally different outputs can arise from inputs that
are visually indistinguishable (Szegedy et al. (2014)). We build upon the mathematical framework
developed for verifying DNNs that grew out of a desire to prove the absence of adversarial examples,
for example Tjeng et al. (2017) and Wong & Kolter (2017). However, we depart from these studies
along with Katz et al. (2017), being more oriented towards small DNNs that map to and from low-
dimensional spaces with considerable structure. These DNNs arise especially in systems which
interoperate with the physical world, for example mapping measurements of positions and velocities
to movements. Table 1 orients our work to the literature.
1
Under review as a conference paper at ICLR 2021
Commonly called	What is computed	Examples
Verification	(f, X,Y) → 1f-1(Y)∩X=0(= 1f(X)∩Y=O)	Wong & Kolter (2017)
Reachability	(f, X) 7→ f(X)	Yang et al. (2020)
Inversion	(f, y) 7→ f-1({y})	Carlsson et al. (2017)
Preimage	(f,Y )→ f-1(Y)	This paper
Table 1: A taxonomy of previous work on inversion and verification. Here f : Rn1 → RnL is
a DNN, X ⊆ Rn1 , x ∈ Rn1 , Y ⊆ RnL , and y ∈ RnL . f-1 is its inverse in the sense that
f-1(Y) = {x : f(x) ∈ Y}.
We have phrased verification in this unusual fashion to facilitate comparison with the other points.
Stated in the familiar application to image classifiers X would be an epsilon ball around an input,
and Y would be the halfspace where one coordinate is higher than all others.
Verification ultimately amounts to a simple yes or no, and so answering higher-level questions typ-
ically requires many verifications: for example, Katz et al. (2017) describes a suite of 45 tests, and
image classifiers often wish to verify the absence of adversarial examples around the entire train-
ing set. Yang et al. (2020) is an interesting extension to verification in that it computes the entire
image of, say, an epsilon ball around a data point, and not just whether it intersects with a decision
boundary.
Reasoning forward, about the outputs that can arise from inputs, is only half of the picture. Carlsson
et al. (2017) and Behrmann et al. (2018) are oriented backwards, they attempt to reconstruct the
inputs that result in an output. These related papers study the statistical invariances that nonlinear
layers encode. Behrmann et al. (2018) examines the preimage of a single point through a single
ReLU layer, analyzing stability via an approximation-based experiment. Carlsson et al. (2017)
analyzes the preimage of a single point through the repeated application of a nonlinearity, purely
theoretically. Our paper looks at the preimage of non-singleton subsets of the codomain, which is
much more practically useful, and requires considerable extension to their approaches.
2	Method
Our method is easily stated: build up the preimage of a DNN from the preimage of its layers, using
simple analytical formulae. We start by developing some properties of the preimage operator, then
we describe the class of sets that we compute the preimage of, and finally we discuss the class of
DNNs that our algorithm addresses.
2.1	Properties of preimages
Lemma 1 shows how to build up the preimage of a DNN from the preimages of its constitutent
layers.
Lemma 1 (Preimage of composition is reversed composition of preimages). For functions fj :
Rnj → Rnj+1 ,
(f'+k ◦ f'+k-1 ◦ ... ◦ f`)-1 = f-1 ◦ ... ◦ f-1k-i ◦ f-1k.	⑴
Secondly, we mention an intuitive property of f-1 that is handy for building up the preimage of any
set from the preimages of any partition of that set.
Lemma 2 (Preimage of union is union of preimages).
f-1 (∪N=ιSi) = ∪N=ιf-1(Si ).
2.2	Polytopes
Our method is not applicable to arbitrary sets Y, but rather sets that, roughly, have piecewise linear
boundaries. The basic building block of these sets are polytopes.
2
Under review as a conference paper at ICLR 2021
Definition 1 (Polytope). A polytope in Rn is a set that can be written as {x ∈ Rn : b - Ax ≥ 0}
for some m ∈ N, b ∈ Rm, and A ∈ Rm×n.
Put more simply: a polytope is the intersection of half-planes. Definition 1 does not require that
polytopes be bounded, but polytopes are convex. Sets with linear boundaries, though they may be
non-convex, can decomposed into the union of polytopes. We term such sets region-unions, and the
set of polytopes which comprise them, regions.
Definition 2 (Region and region-union). For N ∈ N, bi ∈ Rmi, Ai ∈ Rmi×n, with mi ∈ N, a
region is
{{x : bi - Aix ≥ 0} ; i = 1, . . . , N} .	(2)
A region-union is a set ∪r∈R r for some region R.
Region-unions are interesting because the the preimage polytopes under piecewise linear functions
are regions-unions. However, we need to also keep information on how to form a region-union,
hence the notion of a region. It is trivial to observe that if R1 and R2 are regions, then R1 ∪ R2 is
likewise a region, and correspondingly for region-unions.
2.3	Linear and ReLU polytope preimages
In this section, we give formulae for the preimage of linear and ReLU functions, giving significant
content to Lemma 1. The preimage of polytopes under linear mappings are polytopes:
Lemma 3 (Preimage of Linear layer).
(x 7→ Wx + a)-1 ({x : b - Ax ≥ 0}) = {x : (b - Aa) - AWx ≥ 0}.	(3)
ReLU is a piecewise linear function, so if we carefully treat the portions of the domain on which it
exhibits different behavior, we obtain a similar formulation for each:
Lemma 4 (Preimage of ReLU layer).
ReLU-1 ({x : b - Ax ≥ 0})
=	[	{x : b - Adiag(ν)x ≥ 0, -diag(1 - ν)x ≥ 0, diag(ν)x ≥ 0} .	(4)
ν∈{0,1}n
To understand Lemma 4 let s(x) be the vector given by s(x)i = 1 if xi ≥ 0 and zero otherwise.
Then diag(s(x))x = ReLU(x). This expression separates x 7→ ReLU(x) into a pattern of signs
over its coordinates and x itself. This means that once we restrict attention to a set on which the
sign does not change, we can apply familiar linear algebra routines to compute the preimage set,
akin to Lemma 3. The nonnegative values are denoted by ν ∈ {0, 1}n in the above, and the set of
X such that Xi ≥ 0 ^⇒ Vi = 1 is given by diag(ν)x ≥ 0. Similarly, Xi ≤ 0 ^⇒ Vi = 0 for
i = 1, 2, . . . , n if and only if -diag(1 - ν)x ≥ 0. Equation 4 follows by partitioning Rn into the 2n
sets where each coordinate is nonnegative or not.
Computing the preimage of a ReLU layer is unavoidably intractable at scale, though the problem
exhibits considerable structure. We expect that it is possible to compute the preimage of networks
of a similar scale to those that can be completely verified, such as small image-scale networks.
Preimages are most insightful and useful when the inputs and outputs have definite interpretation 一
application areas where the need for massive networks is less.
2.4	The sufficiency of linear and ReLU layers
In familiar terms a DNN classifier might consist of some “feature building” modules, say composed
of alternating convolution and maxpooling, then flattened, and passed onto the prediction logic
consisting of alternating linear and ReLU layers, possibly including dropout or batch normalization,
and concluding with a softmax function to normalize the predictions to a probability distribution.
Resnets (He et al. (2016)) do not strictly fit this pattern, bu can be handled with similar reasoning
(see Appendix B).
3
Under review as a conference paper at ICLR 2021
How do the results of Section 2.3 suffice to invert such DNNs? Firstly, under our convention that
layers operate on flat tensors, flattening is superfluous. Next, dropout affects inference only through
the weights - this layer can be omitted entirely in computing the preimage. Convolution is es-
sentially linear. Maxpool is straightforwardly rewritten in terms of the ReLU and linear function.
{x : b - Asoftmax(x) ≥ 0} is not a polytope. However, if the classification alone suffices then the
softmax layer can be elided entirely since arg maxj xj = arg maxj softmax(x)j.
3	Experiments
3.1	Two moons classification
To cultivate some intuition about the preimage of a DNN we start by examining a classic test prob-
lem in nonlinear classification. We fita DNN f : [-3, +3]2 → R2 consisting of two nonlinear layers
with eight neurons each on an instance of the “two moons” dataset. This data is shown in Figure 1a
(further details of details of f and the data are in Section D.1). Figure 1b plot the corresponding
logits, along with the sets to be inverted {x : xi 空 χ2} ⊆ R2. Figure 1c shows the CorresPOnd-
ing preimages, with different hues of the same color corresponding to different sign patterns ν in
Equation 4.
(a)	(b)
(c)
Figure 1: Inversion of a simple DNN R2 7→ R2 fit to the “two moons” data shown in Figure 1a.
In Figure 1b are the logits from a simple DNN corresponding to each data point computed with
an inference pass, along with the decision boundary. Figure 1c shows the preimages comprised of
polytopes that form the region-union.
3.2	Cart-pole reinforcement learning agent
In the “cart pole” control problem a pole is balanced atop a cart which moves along a one dimen-
sional track (Figure 2). Gravity pulls the pole downward, the falling of the pole pushes the cart,
and external movement of the cart pushes the pole in turn. The control problem is to keep the pole
upright by accelerating the cart.
In the formulation of Brockman et al. (2016) controller inputs are: the position of the cart, x, ve-
locity of the cart X, the angle of the pole θ from upright, and the angular velocity of the pole θ.
Possible actions are to accelerate the cart in the positive or negative x direction. The reward envi-
ronment encourages balancing by a unit reward per period before failure, where failure means that
the pole is not sufficiently upright (θ ∈ [-π∕15, +∏∕15]), or the cart not near enough the origin
(x ∈ [-2.4, +2.4]). We have no prescribed limits for X and θ, but Via a methodology described in
Section D.2.1, we interpret these states as taking values in [-3.0, +3.0] × [-3.5, +3.5].
Consider a still cart and pole (X = θ = 0), with the cart left of zero (x ≤ 0) and the pole left of
vertical (θ ≤ 0). Keeping x and θ near zero is preferable, since these are further from failure, so
moving left will steady θ but worsen x. Nonzero velocities make this reasoning more complicated,
but one configuration is unambiguous: if X ≤ 0,x ≤ 0,θ ≥ 0,θ ≥ 0, then pushing right is clearly
4
Under review as a conference paper at ICLR 2021
Figure 2: The state space of the cart pole prob-
lem, schematically. Here x ≤ 0 (the cart is left
of the origin), X ≤ 0 (the cart is moving left-
ward), θ ≥ 0 (the pole is right of vertical), and
θ ≥ 0 (the pole is moving rightward).
Figure 3: Projection of subsets of the domain
where the wrong action is taken, with the hue of
the area being proportional to the volume of the
wrong sets, divided by the volume of the projec-
tion.
the correct action. Figure 2 gives depicts a value in this orthant. Let D+1 = (-∞, 0]2 × [0, ∞)2,
and correspondingly, let D-1 = [0, +∞)2 × (-∞, 0]2.
We fit a one hidden layer neural network control function f : R4 → R2 using policy gradient
reinforcement learning. Details of this calculation are in Section D.2. This agent achieves its goal
of balancing the pole: in 1000 trials of 200 periods, (x, θ) remains uniformly in [-.75, +.75] ×
[-.05, +.05] with very low velocities. Nonetheless there are many states for which pushing right is
clearly the correct action, but for which the DNN controller predicts -1: in the same simulation of
1000 trials of 200 steps, roughly 7% of actions performed by the agent fail this sanity check. This
behavior is not a numerical fluke - it holds if We consider states only nonnegligibly interior to D+ι
and D-1, and also ifwe only count predictions that are made with probability greater than .51. One
such pockets of counterintuitive behavior is
[-2.399, -1.462] × [-2.922, -2.262] × [+1.798 × 10-8,+0.1067] × [+1.399, +1.728] ⊆
D+1 ∩ f-1({x ∈ R2 : x1 > x2}).
We find this box large - for example the first coordinate comprises almost 20% of that dimension
of the state space. The size of this box is even more suprising because it is inscribed Within a larger
polytope (using the algorithm of Bemporad et al. (2004)) that has a volume about 40 times larger.
The total volume in R4 of these sets is 3% of the state space volume, and thus 24% of the volume
of D-1 ∪ D+1. Figure 3 parses this surprising fact a bit further by plotting the projection of the
four-dimensional domain onto the (x, θ) plane. The hue of the gray is proportional to the volume of
the four-dimensional polytope divided by the volume of the tWo-dimensional projection, so darker
areas mean more (X, θ) mass that is wrong. Since the entirety of the second and fourth quadrants
are grey at every (x, θ) ∈ [-2.4, +2.4] X [-∏∕15, +∏∕15] there are some (X, θ) where the wrong
action will be taken.
3.3 Collision avoidance systems
The final application shows how to use domain knowledge to anticipate dangerous behavior of a
DNN in a complex modelling domain.
5
Under review as a conference paper at ICLR 2021
3.3.1	Background
Aircraft automated collision avoidance systems (ACAS) are navigational aids that use data on air-
craft positions and velocities to issue guidance on evasive actions to prevent collisions with an intrud-
ing aircraft. The ACAS developed in Kochenderfer & Chryssanthacopoulos (2011) uses dynamic
programming to formulate the optimal control of a partially observed Markov process, and issues
advisories to optimize a criterion that penalizes near collisions and raising false or inconsistent
warnings. Unfortunately, evaluating the policy function is too resource-intensive to run on certified
avionics hardware. Small DNNs have been been found to be adequate approximators that require
little storage and can perform inference quickly. A downside of this approximation is that even accu-
rate DNNs can give very wrong predictions on some inputs - Katz et al. (2017), for example show
that when another aircraft is nearby and approaching from the left, a DNN-based approximation
need not advise the correct action of turning right aggressively.
Verification can check that one-step behavior in a DNN-based ACAS behaves as intended. However,
it cannot answer higher level questions like “will a near-collision occur if this policy is followed?”
The idea of Julian & Kochenderfer (2019) is to verify dynamic properties of such systems by com-
bining single-step verification with worst-case assumptions about randomness in state transitions
and (constrained) behavior of other aircraft.
3.3.2	Discretize and verify: Julian & Kochenderfer (2019)
In Julian & Kochenderfer (2019), the state con-
sists of x and y distances between the two aircraft,
and an angle of approach angle between them, ψ.
The actions are five turning advisories: (1) “clear
of conflict” (COC), (2) weak left [turn] (WL), (3)
strong left (SL), (4) weak right (WR), and (5)
strong right (SR). The initial condition is given by
the boundary of the domain where the distance of
the intruding aircraft are at their maxima. Transi-
tion dynamics are denoted by Ψ(a, S), a set-valued
function which gives the set of states that are reach-
able from states in S under action a. Ψ encom-
passes both randomness in the transition, and be-
havior of the other aircraft. The change in (x, y) is
controlled by the angle between the crafts, and the
update to the angle is the difference between the
turning of the two crafts, with some randomness.
To compute the states that can arise under a pol-
icy, the idea is to begin from an initial set of states
that are known to be reachable, and to iteratively
append states that are reachable from any of those
the set of states that we wish to preclude.
g	Volume fraction
40	0.05128
80	0.02532
120	0.01681
160	0.01267
200	0.01005
Table 2: Quantifying the inefficiency of dis-
cretization: Each of the three dimensions,
(x, y, ψ) is discretized into a grid of size g, so
that the domain is partitioned into g3 cubes.
We present the fraction of the cubes for which
all eight corners of this cube do not evaluate to
the same prediction, which is a sufficient con-
dition for the cell to intersect with a decision
boundary.
states, until a fixed point is reached. U denotes
This idea is formalized by Julian & Kochenderfer (2019) as Algorithm 1. Because multiple advi-
sories will be issued whenever a cell straddles the decision boundary, the discretized algorithm will
wrongly include some states as reachable since a worst-case analysis needs to take account of all
reachable states. Table 2 gives an indication of the magnitudes of overestimation, presenting how
much of the state space will lead to multiple advisories under a simple discretization scheme.
Julian & Kochenderfer (2019) do not use an equispaced grid, but the basic point - that discretization
error cannot be made negligible - is an inescapable feature of this approach. And any false positives
in a single-step decision function will be amplified in the dynamic analysis, as more reachable states
at one point time lead to even more reachable points at the next step, so a 1% overestimation at
one step may be compounded to considerably more through the dynamics. Coincidentlly, Julian &
Kochenderfer (2019) are able to reach a usable solution, but are unable to guarantee the absence of
near collisions under some realistic parameter configuations.
Note how the cells can be traversed in any order. This is a simple way to see that this algorithm is
not fully using the spatial structure of the problem. Next, we incorporate this knowledge.
6
Under review as a conference paper at ICLR 2021
Data: Maximum distance set Ro, policy f, an “unsafe set” U, transition dynamics Ψ,
encounter length T .
Result: Guaranteed to not reach an unsafe state from R0 under policy f ?
initialization: t = 0, done = False;
Partition the state space into cells c ∈ C ;
while not done do
t=t+1;
Rt = 0;
for C ∈ C such that C ∩ Rt-1 = 0 do
for i such that f(c) ∩ {x : xi ≥ xj for j 6= i} 6= 0 do
for C0 ∈ C such that C0 ∩ Ψ(i, C) 6= 0 do
I Rt -Rt ∪ C0
end
end
end
done = Rt == Rt-1 orU ∩Rt 6= 0 ort > T.
end
RetUrn Rt ∩ U == 0___________________________________________________________________
Algorithm 1: Algorithm from Julian & Kochenderfer (2019) for computing whether an unsafe
set U can be reached under a policy f beginning from R0 under transition dynamics Ψ.
3.3.3	Our preimage-based alternative
Rather than looping first the domain, then over actions at those points, Algorithm 2 loops over
actions and, using the preimage, computes all reachable points under that action.
Data: Ro, f, U, Ψ, T.
Result: Guaranteed to not reach an unsafe state from R0 under policy f ?
initialization: t = 0, done = False;
for i = 1, 2, . . . , nL do
I Ξi = f-* 1({x : Xi ≥ Xj for j = i})
end
while not done do
t=t+1;
Rt = 0;
for i = 1, 2, . . . , nL do
I Rt -Rt ∪ ψ(i, m ∩ Rt-I);
end
done = Rt == Rt-1 orU∩Rt 6= 0 ort > T.
end
RetUrn U ∩Rt == 0.	.__________________________________________
Algorithm 2: Our preimage-based, exact algorithm for computing the dynamically reachable
states in an ACAS.
While Algorithm 2 is exact - it will never wrongly say that a state can be reached - the accuracy of
Algorithm 1 is ultimately controlled by the number of cells, |C|. This is because it is necessary to
perform nL verifications for each reachable cell, and the number of reachable cells is proportional
to |C|. Let V denote the cost of a verification. Verification is known to be NP-complete (Katz et al.
(2017)), so V dominates all others calculation such as computing intersections or evaluating Ψ(i, C).
Thus, the computational cost of Algorithm 1 is O(|C|V nL). In Algorithm 2 must initially compute
ul preimages which dominates the entire calculation, which consists of relatively fast operations 一
applying the dynamics and computing intersections up to T times, for T a number around 40.
Let P denote the cost of computing a preimage, then Algorithm 2 is O(P nL). So whilst it dispenses
with the need to solve O(|C|) verifications, but may be more intractable if P is significantly higher
than V . Let the dimensions of the nonlinear layers in aDNN be n`i, then because in the worst case it
is necessary to check each nonlinearity, each of which can be independently in a negative or positive
configuration, V = O(2 i n`i ). Exact verification for even a single cell is impossible at present for
7
Under review as a conference paper at ICLR 2021
+25 -∣--------------------------------
干
+20 -
—5 H	I	I	I	I	I	I
-5	0	+5	+10	+15	+20	+25	+30
Figure 4: An encounter plot showing the optimal action at each (x, y) distance configuration for
a fixed angle of approach, indicated by the perpendicular orientation of the red (intruder) aircraft.
Distances are measured in kilofeet.
large networks. We believe that preimages can be computed roughly (within a small constant factor)
as easily as a verification - P =O(V). We are currently developing this conjecture formally, the
idea is that, as shown in Lemma 4, each nonlinear layer ' generates up to 2n'i sets, the preimage of
which must be computed through earlier layers.
In any case, as is true of any exponentially hard problem, the practical tractability of both P and V
hinges importantly upon theoretical arguments showing that not all 2n configurations of the nonlin-
earities of an n-dimensional layer can be achieved (Serra et al. (2017); Hanin & Rolnick (2019), and
clever implementations that take account of the structure of the problems (e.g. Tjeng et al. (2017);
Katz et al. (2017)).
The distinction between the two algorithms is made clearer by examining an encounter plot such
as Figure 4. Encounter plots are concise summarizations of the policy function, here depicting the
possible advisories, for a fixed angle of approach (which is here conveyed by the orientation of the
red aircraft relative to the black). This figure, which replicates Figure 4 of Julian & Kochenderfer
(2019), differs from it in a crucial respect: it is depicts the analytically-computed preimage of the
five sets where each of the advisories are issued (details of the experiment are in Section D.3). The
shaded areas arise from plotting polytopes, as in Algorithm 2. Julian & Kochenderfer (2019), on
the other hand, produce such plots by evaluating the predictions of the network on a fine grid. The
different manner in which the plots are produced is an exact analogue of the different way that the
networks are summarized and analyzed through time.
4 Conclusion
In many areas, safety and interpretation inhibit the use of DNNs, because their use still requires
a good deal of indirect experimentation and oversight to have confidence that it will not act in an
unintuitive way. This paper has proposed computing the preimage of the decisions of a DNN as an
intuitive diagnostic that can help to anticipate problems and help domain experts gain trust in a DNN,
even if they are unable to formally articulate what makes a DNN trustworthy. In order to do this, we
developed the preimage of a DNN and presented an algorithm to compute it. We demonstrated the
utility of the preimage to understand counterintuitive behavior from a cart pole agent, and to more
precisely characterize the set of states that would be reachable in an existing application of DNNs
to aircraft automated collision avoidance systems.
8
Under review as a conference paper at ICLR 2021
References
David Avis. A Revised Implementation of the Reverse Search Vertex Enumeration Algorithm,
pp. 177-198. Birkhauser Basel, Basel, 2000. URL https://doi.org/10.1007/
978-3-0348-8438-9_9.
C. Bradford Barber, David P. Dobkin, David P. Dobkin, and Hannu Huhdanpaa. The quickhull
algorithm for convex hulls. ACM Trans. Math. Softw., 22(4):469-483, December 1996. ISSN
0098-3500. URL http://doi.acm.org/10.1145/235815.235821.
Jens Behrmann, Soren Dittmer, Pascal FemseL and Peter Maaβ. Analysis of Invariance and Ro-
bustness via Invertibility of ReLU-Networks. arXiv e-prints, Jun 2018. URL http://arxiv.
org/abs/1806.09730.
Alberto Bemporad, Carlo Filippi, and Fabio D. Torrisi. Inner and outer approximations of polytopes
using boxes. Computational Geometry, 27(2):151 - 178, 2004. URL https://doi.org/
10.1016/S0925-7721(03)00048-8.
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and
Wojciech Zaremba. Openai gym. 2016. URL http://arxiv.org/abs/1606.01540.
Benno Bueler, Andreas Enge, and Komei Fukuda. Exact Volume Computation for Polytopes: A
Practical Study, pp. 131-154. Birkhauser Basel, Basel, 2000. URL https://doi.org/10.
1007/978-3-0348-8438-9_6.
Stefan Carlsson, Hossein Azizpour, and Ali Sharif Razavian. The preimage of rectifier network
activities. 2017. URL https://openreview.net/pdf?id=HJcLcw9xg.
Komei Fukuda. Lecture: Polyhedral computation, 2014. URL https://inf.ethz.ch/
personal/fukudak/lect/pclect/notes2014/PolyComp2014.pdf.
Komei Fukuda and Alain Prodon. Double description method revisited. In Michel Deza, Rein-
hardt Euler, and Ioannis Manoussakis (eds.), Combinatorics and Computer Science, pp. 91-111,
Berlin, Heidelberg, 1996. Springer Berlin Heidelberg. URL https://doi.org/10.1007/
3-540-61576-8_77.
Boris Hanin and David Rolnick. Deep ReLU Networks Have Surprisingly Few Activation Patterns.
arXiv e-prints, Jun 2019. URL https://arxiv.org/abs/1906.00904.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp.
770-778, 2016. URL https://doi.org/10.1109/CVPR.2016.90.
Kyle Julian, Jessica Lopez, Jeffrey Brush, Michael Owen, and Mykel Kochenderfer. Policy compres-
sion for aircraft collision avoidance systems. In 2016 IEEE/AIAA 35th Digital Avionics Systems
Conference (DASC), pp. 1-10, 09 2016. URL https://doi.org/10.1109/DASC.2016.
7778091.
Kyle D. Julian and Mykel J. Kochenderfer. Guaranteeing safety for neural network-based aircraft
collision avoidance systems. IEEE/AIAA 38th Digital Avionics Systems Conference (DASC),
2019. URL https://doi.org/10.1109/DASC43569.2019.9081748.
Guy Katz, Clark Barrett, David L. Dill, Kyle Julian, and Mykel J. Kochenderfer. Reluplex: An
efficient smt solver for verifying deep neural networks. In Rupak Majumdar and Viktor Kuncak
(eds.), Computer Aided Verification. Springer International Publishing, 2017. URL https://
doi.org/10.1007/978-3-319-63387-9_5.
Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. arXiv e-prints,
Dec 2014. URL http://arxiv.org/abs/1412.6980.
Mykel J. Kochenderfer and James P. Chryssanthacopoulos. Robust Airborne Collision Avoidance
through Dynamic Programming. Massachusetts Institute of Technology, Lincoln Labo-
ratory, Project Report ATC-371, 2011. URL https://www.ll.mit.edu/sites/
default/files/publication/doc/2018-12/Kochenderfer_2011_ATC-371_
WW-21458.pdf.
9
Under review as a conference paper at ICLR 2021
Thiago Serra, Christian Tjandraatmadja, and Srikumar Ramalingam. Bounding and Counting Linear
Regions of Deep Neural Networks. arXiv e-prints, Nov 2017. URL http://arxiv.org/
abs/1711.02114.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna Estrach, Dumitru Erhan, Ian
Goodfellow, and Robert Fergus. Intriguing properties of neural networks. January 2014. URL
http://arxiv.org/abs/1312.6199. 2nd International Conference on Learning Repre-
sentations, ICLR 2014 ; Conference date: 14-04-2014 Through 16-04-2014.
Vincent Tjeng, Kai Xiao, and Russ Tedrake. Evaluating Robustness of Neural Networks with Mixed
Integer Programming. arXiv e-prints, Nov 2017. URL http://arxiv.org/abs/1711.
07356.
Eric Wong and Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. arXiv e-prints, Nov 2017. URL http://arxiv.org/abs/1711.
00851.
Kai Y. Xiao, Vincent Tjeng, Nur Muhammad Shafiullah, and Aleksander Madry. Training for Faster
Adversarial Robustness Verification via Inducing ReLU Stability. ICLR 2019, Sep 2018. URL
http://arxiv.org/abs/1809.03008.
Xiaodong Yang, Hoang-Dung Tran, Weiming Xiang, and Taylor Johnson. Reachability Analysis for
Feed-Forward Neural Networks using Face Lattices. arXiv e-prints, art. arXiv:2003.01226, 2020.
URL https://arxiv.org/abs/2003.01226.
Hao Zhou, Jose M. Alvarez, and Fatih Porikli. Less is more: Towards compact CNNs. In European
Conference on Computer Vision,pp. 662-677, Amsterdam, the Netherlands, October 2016. URL
https://doi.org/10.1007/978-3-319-46493-0_40.
10
Under review as a conference paper at ICLR 2021
A Proofs
A.1 PROOF OF LEMMA 1
Proof. Unroll Equation 1. Let S ⊆ Rn'+fc be arbitrary.
(f'+k ◦ f'+k-ι ◦ ... ◦ f')-1(S)
={x : (f'+k ◦ f'+k-i O . . . o f')(x) ∈ S}
={x ： f'+k((f'+k-1 o f'+k-2 o . . . o fe)(x)) ∈ S}
={x ： (f'+k-1 o f'+k-2 o ... o fe)(x) ∈ f-1k (S)}
.	(5)
.
.
={x :	(f'+1	o f')(X) ∈ (f-2	o ...	o f-1k-1	o f-1k)(S)}
={x :	f'(x)	∈ (f-11 o f-2 o	... o	f-1k-i o	f-1k )(S)}
= (f-1o ... o f-1k-i o f` + k)-1(S).
□
A.2 Proof of Lemma 2
Proof.
X ∈ f-1(UN=ISi) ^⇒
f (x) ∈ UN=ISi Q⇒
f (x) ∈ Si or f (x) ∈ S2 or ... or f (x) ∈ SN ^⇒
X ∈ f-1(S1) or X ∈ f-1(S2) ∈ S2 or ... or X ∈ f T(SN) ^⇒
X ∈uN=if-1(Si).
□
Note that an identical argument shows that f_1 (∩N=1S, = ∩N=ιf T(Si). ThiS can be useful in
some applications where where Si can be wrtten as Ψ ∩ Ξi - writing UiSi as Ψ ∩ Ui Ξi may be more
efficient.
B The inverse of a residual block
The key function in a residual block is
x → W2ReLU(W1x) + x.
Combining arguments similar to Lemma 3 and Lemma 4, we have that
Lemma 5 (Preimage of residual block).
(Z → W2ReLU(W1z) + z)-1({x : b — AX ≥ 0})
={x : b — A(W2ReLU(W1x) + x) ≥ 0}
(6)
= U {x : b — A(W2diag(ν)W1 + I)x ≥ 0, —diag(1 — ν)W1x ≥ 0, diag(ν)W1x ≥ 0}.
ν∈{0,1}n
C	Collecting this all up
Section 2.1, Section 2.2, Section 2.3, and Section 2.4 together give us a recipe for inverting a wide
class of image sets (region-unions) for a wide class of DNNs (those which can be written as the
composition of linear and ReLU functions). To summarize the steps are:
11
Under review as a conference paper at ICLR 2021
1.	Put the network into “standard form”:
(a)	Embed any transformations that are “off” at inference time, such as dropout or batch
normalization into the weights.
(b)	Rewrite the network in flattened form, for example replacing 3 × 32 × 32 tensors by
3072 × 1 vectors. This is a convention to facilitate our polytope formulation.
(c)	Rewrite all transformations as compositions of linear and ReLU functions. For exam-
ple, convolution and average pooling are linear functions. Maxpooling, hard tanh, and
leaky ReLU can be written as the composition of linear and ReLU functions.
2.	Let f = fL ◦ fL-1 ◦ . . . ◦ f1 denote the network in this form.
3.	Let RL = ∪i∆i be the image set that we wish to invert, for example RL = ∆1 = {x :
x1 ≥ x2 } ⊆ R2 in a binary classifier.
4.	Compute fL-1(∆i) for all i, using Lemma 3 or Lemma 4.
5.	Each term above is a region-union, thus ∪ifL-1(∆i) is a region-union.
6.	By Lemma 2, RL-1 , fL-1 (RL) = ∪ifL-1(∆i).
7.	RL-1 is a region-union, so apply the same argument to compute RL-2 , fL--11 (RL-1) =
fL--11(fL-1(RL)).
8.	Repeat for ` = L - 2, . . . , 1 to compute R0 = f1-1(R1) = . . . = (f1-1 ◦ f2-1 ◦ . . . ◦
fL-1)(RL).
9.	Appeal to Equation 1 to conclude that R0 = f-1 (RL).
D Details of experiments
D.1 Section 3.1
The dataset of 500 observations is generated using the scikit-learn function
sklearn.datasets.make_moons with noise = .2.
Weights are initialized according to a uniform (-√in features, +√in features) distribution (the Py-
Torch default), and were run for 1000 epochs of with a batch size of 128. Gradient steps were
chosen by the adam optimizer (Kingma & Ba (2014)) with learning rate of 0.005 and (β1, β2) =
(0.9, 0.999).
D.2 Section 3.2
Our experiment is based upon the “CartPole-v1” environment from Brockman et al. (2016). The
fitting procedure is based upon the Monte Carlo policy gradient vignette from the PyTorch project,1
with a considerably simplified control policy, consisting of DNN wih only five hidden units.
D.2.1 Velocity magnitude
As far as We can tell, there is no single best methodology for computing IlmitS on the velocities (X, θ)
in the cart pole problem. In premise, very high velocities could be supported by the discretization
scheme, but these are unlikely to be achieved by any feasible sequence of actions. If We restrict
attention to limits described by actions, hoW should We characterize the set of actions We consider?
For example, should We simply observe the behavior of some non-optimized agent? Should We
deliberate construct agents to pursue velocity-maxmizing strategies? Should We force agents to
have the same initialization as that prescribed in the fitting?
We concluded that an interpretable baseline Which gave quantitative bounds robust to details of
ParametenzatiOnS would be best. For this, we chose our limits on X, θ as the values that answer
the question “hoW fast can the cart and pole be moving if We start from rest With the cart all the
1https://github.com/pytorch/examples/blob/master/reinforcement_
learning/reinforce.py
12
Under review as a conference paper at ICLR 2021
0	5	10
Figure 5: The evolution of the cart pole state under a policy which continually accelerates left until
failure (when θ ≥ n/15), starting from rest, with the cart near the right boundary and the pole near
its right boundary ((x, X, θ, θ) = (2.39,0, -.20,0)).
0	5	10
way to the right, and the pole all the way to the left, and continually push left until failure?”. This
experiment is plotted in Figure 5, where We see that the implied limits are ±3.0 and ±3.5 for X and
θ, respectively.
In addition to being easy to envision and interpret, a policy that pushes in a uniform direction is
a natural boundary between benigh “dumb” policies and those that more actively seek to exercise
worst-case scenarios through some deliberately degenerate behavior.
These limits largely agree with three the other candidates we considered:
•	The same experiment, although constrained to obey the same initialization as in Brockman
et al. (2016) (these limits are tighter, understandably, roughly 2.25, 2.75 respectively).
•	A simple one-parameter agent which (starting from an initialization near the origin) seeks
out high velocities by beginning to push in a uniform direction, then switches to the oppo-
site direction.
•	The most extreme values emitted from a small (and hence exhibitting more erratic behavior
early on the in the fitting) DNN that is able to eventually achieve good performance.
13
Under review as a conference paper at ICLR 2021
D.3 Section 3.3
The analysis presented in Section 3.3 is based entirely on data generated by Julian & Kochenderfer
(2019)’s system that formulates and solves dynamic programs to deliver lookup tables of optimal
collision avoidance behavior in the same manner as the FAA’s proprietary software. Our DNN
modelling is somewhat different, however, and whilst we think that our results can be interpreted
within their framework, in this section we detail the aspects of our analysis that differ from Julian &
Kochenderfer (2019)’s.
D.3.1 Fitting - Optimization Criterion
The first manner in which our approach is different is the fitting criterion: Julian & Kochender-
fer (2019) issue advisories as a function of position and velocities indirectly: by first fitting the
continuation value to taking each action, and then choosing the action with the highest predicted
continuation value. This oblique approach is understandable: this work is the continuation of an
extended project to build (Kochenderfer & Chryssanthacopoulos (2011)) and compress the Q-table
(Julian et al. (2016), Katz et al. (2017)).
And although the Q-values themselves have some interpretation, issuing advisories requires only
knowing the greatest. We hypothesize that it is easier to solve a problem which recognizes an
invariance of the prediction to any increasing transformation. And that is What We find - by replacing
Julian et al. (2016)’s mean-squared-error-based criterion with cross entropy loss to directly model the
optimal decision, We are able to achieve better performance With smaller netWorks. one statement
of the improvement is that Julian & Kochenderfer (2019) use a five layer fully connected layers With
25 neurons each to achieve an accuracy of 97% to 98%. We are able to achieve comparable accuracy
With a two layer 25 neuron fully connected netWork (a netWork of the same size targetting MSE loss
only attains an accuracy around 93%).
Why is anything less than complete fidelity to the Q-table acceptable in an approximation? The
ansWer seems tobe tWofold: firstly the Q-table is itself not perfect, because of discretization artifacts.
one can observe physically implausible saWtooth-like decision boundaries that arise from a coarse
grid in the top plot of Julian & Kochenderfer (2019) Figure 4. The second is that accuracy alone
does not capture the genuine metric of goodness, for example in the bottom plot of Figure 4 of
Julian & Kochenderfer (2019) We see a highly accurate netWork that exhibits unusual “islands” of
SR completely encompassed by a region of WR that are both not present in the ground truth, and also
prescibe a conceptually Wrong relationship (a pilot could be initially advised a strong right turn, then
after some period of lessened danger have it doWngraded to a Weak right, only to have it re-upgraded
to a strong right, seemingly although the danger continues to lessen). The correct metric seems to
rather be plausibility of the prescribed encounter plot. These observation leads us to not Worry too
much about small differences in model accuracies in favour of plausibility of the encounter plots.
D.3.2 Fitting - Symmetry
The second manner in Which our approach differs from Julian & Kochenderfer (2019) is in
the domain being fitted. Julian & Kochenderfer (2019) fixed a lookup table over (x, y, ψ) ∈
[-56000, +56000]2 × [-π, +π). HoWever, if We let Q : R3 → R5 denote the Q-function as a
function of the state s = (x, y, ψ), then the physics of the problem insure that
	+1	0	0	0	0
+1	0	0	0	0+10	0
Q(Tis)= ToQ(S) where Ti =	0	-10	and To =	0+10	0	0
0	0	-1	0	0	0	0	+1
	0	0	0	+1	0
This relationship clearly only Works for aprev = CoC, but similar symmetries Will exist more gen-
erally. Thus, strictly speaking, half of the lookup table is unneeded, and moreover it Would seem
Wasteful to ask a netWork to learn (What We already knoW to be) the same thing tWice. Thus, our
method is to only fit f over (x, y, ψ) ∈ [-56000, +56000]2 × [0, +π), and When needed to infer
f (s) = Tof (Tis) for s = (x, y, ψ) With ψ < 0. in so doing, We halve the data set size, but leave
other data fitting parameter unchanged.
14
Under review as a conference paper at ICLR 2021
To continue the analysis above describing comparable performance from smaller networks, exploit-
ing symmetry enables us to achieve accuracy above 97% from a one layer, 24 neuron network. For
computational ease, Figure 4 is computed on a 16 neuron network that achieves about 96% accuracy.
D.3.3 INVERSION - PROJECTION
Figure 4 was formed by taking the fitted n0 = 3 DNN, fixing ψ to a given value, and inverting the
resultant n0 = 2 DNN (if W1, b1 denote the weights and bias of the original DNN, then projecting
onto the W10 = W1 0 1 , b01 = b1 + ψW1 0 .
E	Additional Computational Details
Definition 1, as well as Lemma 3 and Lemma 4 worked with what is known as the H representation
of a polytope. What Fukuda (2014) terms the “Minkowski-Weyl Theorem” states that there is an
equivalent representation, as the Minkowski sum of (1) a convex combination of vertices, and (2) a
conic combination of some rays.
Definition 3 (Polytope (V representation)). A polytope in Rn is a set that can be written as
∑>Vi + £ Vj rj : λi ≥0,Vj ≥0,E% = 1
Iij	i
for some vi ∈ Rn , rj ∈ Rn.
The Minkowski-Weyl Theorem assures us that Definition 3 is equivalent to Definition 1.
To introspect on DNNs it is handy to have both the H and V representation of the preimage. Unfor-
tunately, computing the V representation from the H representation is computationally challenging,
both theoretically and practically. Analyzing formally the computational complexity of the problem
is technical, and also complicated by a host of special cases, but roughly speaking:
•	Evidently the complexity of the problem depends not only on the size of the input, but also
the output.
•	Small inputs can have large outputs. For example, a cube in d dimensions has an H repre-
sentation with 2d rows, but 2d vertices.
•	In general, there are no known algorithms that have polynomial time complexity in the
input and output size.
•	For some polytopes, there are algorithms that have polynomial time and space complexity
in the input and output. However, but this is still exponentially large in the dimension of
the polytopes, again because output size can be exponentially large in the input size.
The more precise statements of this summary can be found in Fukuda (2014), Section 9.
Our problem may lie in some more easily-solved subclass of problems (though the fact that even
simple geometric objects like cubes exhibit exponential growith of the output as a function of the
input dimension makes this perhaps less likely). Our review of the theoretical literature was unsuc-
cessful int this regard, and empirically we observed empirically that the runtime of our calculation
did rise at an exponential-like rate with the dimension of the input. Thus: we did not find the
naive approach of computing the H representation of the preimage, then computing from that the V
representation to be practical.
Happily, when W is full rank, we can give the V representation corollary of Lemma 3.
15
Under review as a conference paper at ICLR 2021
Lemma 6. Suppose that W isfull-rank, and let W * be its pseudoinverse and W⊥ be a basisfor the
nullspace (with kth column Wk⊥) then, for λi ≥ 0,νj ≥0, iλi=1:
Wx + a = ɪ2 Viλi + ɪ2 rj Vj ^⇒
ij
x= X(W*vi - a)λi + X(W*rj)νj + X Wk⊥γk
=X(W*vi-a)λi+X(W*rj)νj+XWk⊥γk++X(-1×Wk⊥)γk-
where γk- ≥ 0, γk+ ≥ 0.
This is a V representation with vertices (W*vi - a) and rays (W*rj), Wk⊥, -1 × Wk⊥.
Checking the rank of W, computing the pseudoinverse, and computing a basis for the nullspace are
all quick and standard linear-algebraic routines.
For example, in our experiments were were unable to come anywhere near computing the V rep-
resentation of a an MNIST classifier (n0 = 784) directly using a standard software such as cdd
(Fukuda & Prodon (1996)). However, for networks with n`-1 ≥ n` for all ` ≥ 1 (which in our
simple fitting procedure, was sufficient to insure that W would be full-rank), it was quite possible
using Lemma 6: (1) compute the V representation of the polytopes to be inverted (these will be ten
dimensional, and highly structured), then (2) apply Equation 7 iteratively backwards.
E.1 Polytope dimension
One slightly subtle point is that the terms in Equation 4 overlap at the boundaries, for example
if b ≥ 0 then the origin is in fact contained in every term in the union. In this work, we only
form full dimensional polytopes, roughly those which have strictly positive n-dimensional volume.
Removing lower-dimensional sets does not change the union, so this does not substantively change
the preimage. A study which was more explicitly interested in the details of decision boundaries
might not want do make such a restriction. Some more discussion of this point is in Section E.1.
We mentioned in Section 2.4 that our analyses restrict attention to polytopes that have full dimension.
Formally, the dimension of a polytope is the maximum number of affinely independent points in that
polytope, minus one. And a full dimensional polytop in Rd is one with dimension d. Geometrically,
sets which are not full dimensional lie on the boundary between sets, and if they have a nonempty
preimage, it will lie on a boundary shared by another polytope, which does have full dimension.
This idea is made clearer by explaining how we check if a polytope has full-dimension. Algorithm
8.4 from Section 8.3 of Fukuda (2014) states that {x : b - Ax ≥ 0} is full-dimensional iff the
optimization problem
maximize κ subject to Ax + 1κ ≤ b, κ ≥ 1.	(8)
achieves a positive criterion. Here 1 is a conformable column vector of ones, representing the
intuition that it is possible to loosen all inequality conditions by a strictly positive amount, meaning
that there is some volume interior to the polytope. The ancillary condition that κ ≤ 1 is used to
keep the problem well-conditioned.
Empirically, most sets in the region-union comprising Equation 4 are not full dimensional, and as
soon as we know that an element of a preimage region is not full dimensional, we need not consider it
anymore. Future will will use more careful analysis to detect analytically when sets must necessarily
be less than full dimensional, but for now we query each of the 2n subsets of the region-union. Thus
most of our computational time is spent in calculations of the form of Equation 8. We tested both
Mosek and Gurobi as software for solving linear programs such as Equation 8, and found Gurobi to
be faster.
16
Under review as a conference paper at ICLR 2021
Hidden layer widths	Accuracy	# parameters	Storage (MB)	Time (s)
8	0.973	42	1.105	0.205
12	0.975	62	35.256	2.907
16	0.974	82	985.767	52.912
4→4	0.972	42	0.260	0.269
6→6	0.967	74	6.764	3.205
8→8	0.971	114	42.089	26.256
4→4→4	0.969	62	3.125	1.802
6→6→6	0.968	116	279.138	117.248
4→4→4→4	0.973	82	43.695	27.253
E.2 Polytope volume
In low dimensions, computing the volume of a polytope from its V form is fast and space efficient.
In the analysis presented in Section 3.2, we used the Qhull software which implements the Quickhull
algorithm (Barber et al. (1996)) via scipy.spatial.ConvexHull. This computation scales
poorly with dimension, however, for instance in our experiments it stopped being usable around ten
dimensions. Bueler et al. (2000) gives some “why” and “how” about this difficulty.
In high dimensions analysis of volumes seems difficult. However, if we already plan to compute the
V representation of the preimage - also a highly complex operation - we may be able to compute
the volume “for free”. Avis (2000) shows how to compute the volume as a byproduct of his algo-
rithm for converting between H and V representation (solve the vertex enumeration problem), and it
seems quite plausible that the same ideas could be adapted to other algorithms that solve the vertex
enumeration problem as well. We hope to investigate this further and possibly incorporate it into
our software.
E.3 Clock time to solve problems of varying sizes
In this section, we give a sense of the computational difficulty of inverting a DNN. The general
finding is that for simple problems, one layer networks of around 16 neurons, two layer networks of
about 8 neurons apiece, or three layer networks of about six neurons apiece are easily inverted on
a low-powered laptop, but the rate of growth is empirically very fast. Certainly even the five layer,
25 neurons apiece networks employed in Julian & Kochenderfer (2019) are out of reach under the
current implementation.
We do not use any multiprocessing, though the essential computation, checking polytope emptiness,
is embarassingly parallel.
We perform ten fittings and compute preimages per size, and report the average model accuracy, time
to compute the preimage, and standard deviation of each. To get a sense of the space complexity,
we also present the disk storage necessary to hold both the H and V forms of a complete preimage
partitiion (pickled dense numpy arrays of float64s). Since we do not re-tune hyperparameters
across runs, accuracy is solely indicative.
All timings were performed on a 1.6 GHz Dual-Core Intel Core i5 CPU.
A more formal analysis of the complexity of the computation will follow in future work, as will
speed improvements from a more sophisiticated logic for handling empty preimage regions, along
with further experimentation on “tricks” such as sophisticated regularization or clever initialization
schemes that might enable greater modelling capacity without increasing the scale of the network
(e.g. Zhou et al. (2016) or Xiao et al. (2018)).
The problem is as described in Section 3.1, with further detail given in Section D.1.
17