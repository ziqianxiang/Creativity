Under review as a conference paper at ICLR 2021
Self-Supervised Time Series Representation
Learning by Inter-Intra Relational Reason-
ING
Anonymous authors
Paper under double-blind review
Ab stract
Self-supervised learning achieves superior performance in many domains by ex-
tracting useful representations from the unlabeled data. However, most of tradi-
tional self-supervised methods mainly focus on exploring the inter-sample struc-
ture while less efforts have been concentrated on the underlying intra-temporal
structure, which is important for time series data. In this paper, we present Self-
Time: a general Self-supervised Time series representation learning framework,
by exploring the inter-sample relation and intra-temporal relation of time series to
learn the underlying structure feature on the unlabeled time series. Specifically,
we first generate the inter-sample relation by sampling positive and negative sam-
ples of a given anchor sample, and intra-temporal relation by sampling time pieces
from this anchor. Then, based on the sampled relation, a shared feature extraction
backbone combined with two separate relation reasoning heads are employed to
quantify the relationships of the sample pairs for inter-sample relation reasoning,
and the relationships of the time piece pairs for intra-temporal relation reasoning,
respectively. Finally, the useful representations of time series are extracted from
the backbone under the supervision of relation reasoning heads. Experimental re-
sults on multiple real-world time series datasets for time series classification task
demonstrate the effectiveness of the proposed method. Code and data are publicly
available 1.
1 Introduction
Time series data is ubiquitous and there has been significant progress for time series analysis (Das,
1994) in machine learning, signal processing, and other related areas, with many real-world applica-
tions such as healthcare (Stevner et al., 2019), industrial diagnosis (Kang et al., 2015), and financial
forecasting (Sen et al., 2019).
Deep learning models have emerged as successful models for time series analysis (Hochreiter &
Schmidhuber, 1997; Graves et al., 2013; Shukla & Marlin, 2019; Fortuin et al., 2019; Oreshkin
et al., 2020). Despite their fair share of success, the existing deep supervised models are not suitable
for high-dimensional time series data with a limited amount of training samples as those data-driven
approaches rely on finding ground truth for supervision, where data labeling is a labor-intensive and
time-consuming process, and sometimes impossible for time series data. One solution is to learn
useful representations from unlabeled data, which can substantially reduce dependence on costly
manual annotation.
Self-supervised learning aims to capture the most informative properties from the underlying struc-
ture of unlabeled data through the self-generated supervisory signal to learn generalized representa-
tions. Recently, self-supervised learning has attracted more and more attention in computer vision by
designing different pretext tasks on image data such as solving jigsaw puzzles (Noroozi & Favaro,
2016), inpainting (Pathak et al., 2016), rotation prediction(Gidaris et al., 2018), and contrastive
learning of visual representations(Chen et al., 2020), and on video data such as object tracking
(Wang & Gupta, 2015), and pace prediction (Wang et al., 2020). Although some video-based ap-
1Anonymous repository link.
1
Under review as a conference paper at ICLR 2021
I	Positive SamPle	Inter-sample Relation
Anchor Sample	f
Negative Sample
L
Sample Relation:	Positive	"" Negative
Temporal Relation: I^^^Short-term I^^^Middle-term	Long-term
Intra-temporal Relation
Figure 1: Exploring inter-sample relation, and multi-scale intra-temporal relation of time series.
Here, an example of 3-scale temporal relations including short-term, middle-term and long-term
temporal relation is given for illustration.
proaches attempt to capture temporal information in the designed pretext task, time series is far dif-
ferent structural data compared with video. More recently, in the time series analysis domain, some
metric learning based self-supervised methods such as triplet loss (Franceschi et al., 2019) and con-
trastive loss (Schneider et al., 2019; Saeed et al., 2020), or multi-task learning based self-supervised
methods that predict different handcrafted features (Pascual et al., 2019a; Ravanelli et al., 2020) and
different signal transformations (Saeed et al., 2019; Sarkar & Etemad, 2020) have emerged. How-
ever, few of those works consider the intra-temporal structure of time series. Therefore, how to
design an efficient pretext task in a self-supervised manner for time series representation learning is
still an open problem.
In this work, we present SelfTime: a general self-supervised time series representation learning
framework. Inspired by relational discovery during self-supervised human learning, which attempts
to discover new knowledge by reasoning the relation among entities (Goldwater et al., 2018; Patac-
chiola & Storkey, 2020), we explore the inter-sample relation reasoning and intra-temporal relation
reasoning of time series to capture the underlying structure pattern of the unlabeled time series data.
Specifically, as shown in Figure 1, for inter-sample relation reasoning, given an anchor sample, we
generate from its transformation counterpart and another individual sample as the positive and nega-
tive samples respectively. For intra-temporal relation reasoning, we firstly generate an anchor piece,
then, several reference pieces are sampled to construct different scales of temporal relation between
the anchor piece and the reference piece, where relation scales are determined based on the temporal
distance. Note that in Figure 1, we only show an example of 3-scale temporal relations including
short-term, middle-term, and long-term relation for an illustration, whereas in different scenarios,
there could be different temporal relation scale candidates. Based on the sampled relation, a shared
feature extraction backbone combined with two separate relation reasoning heads are employed to
quantify the relationships between the sample pairs or the time piece pairs for inter-sample relation
reasoning or intra-temporal relation reasoning, respectively. Finally, the useful representations of
time series are extracted from the backbone under the supervision of relation reasoning heads on the
unlabeled data. Overall, SelfTime is simple yet effective by conducting the designed pretext tasks
directly on the original input signals.
Our main contributions are three-fold: (1) we present a general self-supervised time series represen-
tation learning framework by investigating different levels of relations of time series data including
inter-sample relation and intra-temporal relation. (2) We design a simple and effective intra-temporal
relation sampling strategy to capture the underlying temporal patterns of time series. (3) We con-
duct extensive experiments on different categories of real-world time series data, and systematically
study the impact of different data augmentation strategies and temporal relation sampling strategies
on self-supervised learning of time series. By comparing with multiple state-of-the-art baselines,
experimental results show that SelfTime builds new state-of-the-art on self-supervised time series
representation learning.
2	Related Work
Time Series Modeling. In the last decades, time series modeling has been paid close attention with
numerous efficient methods, including distance-based methods, feature-based methods, ensemble-
based methods, and deep learning based methods. Distance-based methods (Berndt & Clifford,
2
Under review as a conference paper at ICLR 2021
1994; Gorecki & Euczak, 2014) try to measure the similarity between time series using Euclidean
distance or Dynamic Time Warping distance, and then conduct classification based on 1-NN classi-
fiers. Feature-based methods aim to extract useful feature for time series representation. Two typical
types including bag-of-feature based methods (Baydogan et al., 2013; Schafer, 2015) and shapelet
based methods (Ye & Keogh, 2009; Hills et al., 2014). Ensemble-based methods (Lines & Bagnall,
2015; Bagnall et al., 2015) aims at combining multiple classifiers for higher classification perfor-
mance. More recently, deep learning based methods (Karim et al., 2017; Ma et al., 2019; Cheng
et al., 2020) conduct classification by cascading the feature extractor and classifier based on MLP,
RNN, and CNN in an end-to-end manner. Our approach focuses instead on self-supervised represen-
tation learning of time series on unlabeled data, exploiting inter-sample relation and intra-temporal
relation of time series to guide the generation of useful feature.
Relational Reasoning. Reasoning the relations between entities and their properties makes signifi-
cant sense to generally intelligent behavior (Kemp & Tenenbaum, 2008). In the past decades, there
has been an extensive researches about relational reasoning and its applications including knowl-
edge base (Socher et al., 2013), question answering (Johnson et al., 2017; Santoro et al., 2017),
video action recognition (Zhou et al., 2018), reinforcement learning (Zambaldi et al., 2019), and
graph representation (Battaglia et al., 2018), which perform relational reasoning directly on the con-
structed sets or graphs that explicitly represent the target entities and their relations. Different from
those previous works that attempt to learn a relation reasoning head for a special task, inter-sample
relation reasoning based on unlabeled image data is employed in (Patacchiola & Storkey, 2020) to
learn useful visual representation in the underlying backbone. Inspired by this, in our work, we
focus on time series data by exploring both inter-sample and intra-temporal relation for time series
representation in a self-supervised scenario.
Self-supervised Learning. Self-supervised learning has attracted lots of attention recently in dif-
ferent domains including computer vision, audio/speech processing, and time series analysis. For
image data, the pretext tasks including solving jigsaw puzzles (Noroozi & Favaro, 2016), rotation
prediction (Gidaris et al., 2018), and visual contrastive learning (Chen et al., 2020) are designed for
self-supervised visual representation. For video data, the pretext tasks such as frame order validation
(Misra et al., 2016; Wei et al., 2018), and video pace prediction (Wang et al., 2020) are designed
which considering additional temporal signal of video. Different from video signal that includes
plenty of raw feature in both spatial and temporal dimension, time series is far different structural
data with less raw features at each time point. For time series data such as audio and ECG, the metric
learning based methods such as triplet loss (Franceschi et al., 2019) and contrastive loss (Schneider
et al., 2019; Saeed et al., 2020), or multi-task learning based methods that predict different hand-
crafted features such as MFCCs, prosody, and waveform (Pascual et al., 2019a; Ravanelli et al.,
2020), and different transformations of raw signal (Sarkar & Etemad, 2020; Saeed et al., 2019) have
emerged recently. However, few of those works consider the intra-temporal structure of time series.
Therefore, how to design an efficient self-supervised pretext task to capture the underlying structure
of time series is still an open problem.
3	Method
Given an unlabeled time series set T = {tn}nN=1, where each time series tn = (tn,1, ...tn,T)T
contains T ordered real values. We aim to learn a useful representation zn = fθ (tn) from the
backbone encoder fθ (∙) where θ is the learnable weights of the neural networks. The architecture of
the proposed SelfTime is shown in Figure 2, which consists of an inter-sample relational reasoning
branch and an intra-temporal relational reasoning branch. Firstly, taking the original time series
signals and their sampled time pieces as the inputs, a shared backbone encoder fθ(∙) extracts time
series feature and time piece feature to aggregate the inter-sample relation feature and intra-temporal
relation feature respectively, and then feeds them to two separate relation reasoning heads r*(∙) and
rφ(∙) to reason the final relation score of inter-sample relation and intra-temporal relation.
3.1	Inter-sample Relation Reasoning
Formally, given any two different time series samples tm and tn from T, we randomly generate two
sets ofK augmentations A(tm) = {t(mi)}iK=1 and A(tn) = {t(ni)}iK=1, where t(mi) and t(ni) are the i-th
3
Under review as a conference paper at ICLR 2021
Input
Backbone Sample	Relation	Relation
Encoder Feature	Feature Reasoning Head
Output
6u'≡oseωa;
-euo--ωa
-e,lodEl,eU-
6u=oseωα
-eu。一~-ωα
-dEes~u-
■ Positive Relation ?
■ Negative Relation
■ Relation Class 1
■ Relation Class 2
• ∙ ∙
■ Relation Class C
Figure 2: Architecture of SelfTime.
augmentations of tm and tn respectively. Then, we construct two types of relation pairs: positive
relation pairs and negative relation pairs. A positive relation pair is (t(mi) , t(mj) ) sampled from the
same augmentation set A(tm), while a negative relation pair is (t(mi), t(nj)) sampled from different
augmentation sets A(tm) and A(tn). Based on the sampled relation pairs, we use the backbone
encoder fθ to learn the relation representation as follows: Firstly, we extract sample representations
zm(i) = fθ(t(mi)), zm(j) = fθ(t(mj)), and zn(j) = fθ(t(nj)). Then, we construct the positive relation
representation [z(i), Zm)], and the negative relation representation [zm, zP)], where [∙, ∙] denotes
the vector concatenation operation. Next, the inter-sample relation reasoning head r*(∙) takes the
generated relation representation as input to reason the final relation score h2mj-ι=rμ([zmm), Zm)D
for positive relation and h2ij) = r*([Zm), Zj)D for negative relation, respectively. Finally, the
inter-sample relation reasoning task is formulated as a binary classification task and the model is
trained with binary cross-entropy loss Linter as follows:
2N K K
Linter = - £££("8 ∙ lθg(h") + (1 — yj ∙ lθg(1 — hfj)))	⑴
n=1 i=1 j =1
where yn(i,j ) = 1 for the positive relation and yn(i,j ) = 0 for the negative relation.
3.2	Intra-temporal Relation Reasoning
To capture the underlying temporal structure along the time dimension, we try to explore the intra-
temporal relation among time pieces and ask the model to predict the different types of temporal
relation. Formally, given a time series sample tn = (tn,1, ...tn,T)T, we define an L-length time piece
pn,u oftn starting at time step u as a contiguous subsequence pn,u = (tn,u,tn,u+1, ..., tn,u+L-1)T.
Firstly, we sample different types of temporal relation among time pieces as follows: Randomly
sample two L-length pieces pn,u and pn,v of tn starting at time step u and time step v respectively.
Then, the temporal relation between pn,u and pn,v is assigned based on their temporal distance
du,v, e.g., for similarity, we define the temporal distance du,v = |u — v| as the absolute value of the
difference between two starting step u and v. Next, we define C types of temporal relations for each
pair of pieces based on their temporal distance, e.g., for similarity, we firstly set a distance threshold
as D = bT/Cc, and then, if the distance du,v of a piece pair is less than D, we assign the relation
label as 0, if du,v is greater than D and less than 2D, we assign the relation label as 1, and so on
until we sample C types of temporal relations. The details of the intra-temporal relation sampling
algorithm are shown in Algorithm 1.
Based on the sampled time pieces and their temporal relations, we use the shared backbone encoder
fθ to extract the representations of time pieces firstly, where Zn,u = fθ(pn,u) and Zn,v = fθ(pn,v).
Then, we construct the temporal relation representation as [Zn,u , Zn,v]. Next, the intra-temporal
relation reasoning head rφ(∙) takes the relation representation as input to reason the final relation
score hnu,v) = rφ([zn,u, Zn,v]). Finally, the intra-temporal relation reasoning task is formulated
as a multi-class classification problem and the model is trained with cross-entropy loss Lintra as
4
Under review as a conference paper at ICLR 2021
follows:
N
Lintra = - X yn(u,v)
n=1
l	exp(hnt,v))
gPC=ι eχp(hnu,v))
(2)
By jointly optimizing the inter-sample relation
reasoning objective (Eq. 1) and intra-temporal
relation reasoning objective (Eq. 2), the final
training loss is defined as follows:
Linter + Lintra
(3)
Algorithm 1: Temporal Relation Sampling.
Require:
tn: A T -length time series.
pn,u,pn,v: two L-length pieces of tn.
C : Number of relation classes.
An overview for training SelfTime is given
in Algorithm 2 in Appendix A. SelfTime
is an efficient algorithm compared with the
traditional contrastive learning models such
as SimCLR. The complexity of SimCLR is
O(N 2K2), while the complexity of SelfTime
is O(NK2) + O(NK), where O(NK2) is the
complexity of inter-sample relation reasoning
module, and O(NK) is the complexity of intra-
temporal relation reasoning module. It can
be seen that SimCLR scales quadratically in
both training size N and augmentation number
K. However, in SelfTime, inter-sample relation
reasoning module scales quadratically with the
number of augmentations K , and linearly with
the training size N, and intra-temporal relation
reasoning module scales linearly with both augmentations and training size.
Ensure:
yn(u,v) ∈ {1, 2, ..., C}: The label of the tem-
poral relation between pn,u and pn,v .
1:	du,v = |u-v|,D= bT/Cc
2:	if du,v ≤ D then
3:	yn(u,v) = 0
4:	else if ʤ ≤ 2 * D then
5:	yn(u,v)	=	1
6:	...
7:	else if du,v ≤ (C - 1) * D then
8:	yn(u,v)	=C-2
9:	else
10:	yn(u,v)	=	C-	1
11:	end if
12:	return yn(u,v)
L
4	Experiments
4.1 Experimental Setup
Datasets. To evaluate the effectiveness of the proposed method, in the experiment, we use three categories time series including four public datasets CricketX, UWaveGes- tureLibraryAll (UGLA), DodgerLoopDay (DLD), and InsectWingbeatSound (IWS) from the UCR Time Series Archive2 3 4 (Dau et al., 2018), along with two real-world	Category	Dataset	Sample	Length	Class
	Motion	CricketX	-780-	-300-	~~Γ2-
		UWaveGestureLibraryAll	4478^^	-945-	-8-
	Sensor	DodgerLoopDay	-158-	-288-	-7-
		InsectWingbeatSound	2200	-256-	-T1-
	Device	MFPT	2574	1024	15
		XJTU	一	1920	1024	15
	Table 1: Statistics of Datasets.				
bearing datasets XJTU3 and MFPT4 (Zhao et al., 2020). All six datasets consist of various num-
bers of instances, signal lengths, and number of classes. The statistics of the datasets are shown in
Table 1.
Time Series Augmentation The data augmentations for time series are generally based on random
transformation in two domains (Iwana & Uchida, 2020): magnitude domain and time domain. In
the magnitude domain, transformations are performed on the values of time series where the values
at each time step are modified but the time steps are constant. The common magnitude domain
based augmentations include jittering, scaling, magnitude warping (Um et al., 2017), and cutout
(DeVries & Taylor, 2017). In the time domain, transformations are performed along the time axis
that the elements of the time series are displaced to different time steps than the original sequence.
The common time domain based augmentations include time warping (Um et al., 2017), window
slicing, and window warping (Le Guennec et al., 2016). More visualization details of different
augmentations are shown in Figure 3.
2https://www.cs.ucr.edu/~eamonn/time_series_data_2018/
3 https://biaowang.tech/xjtu- sy- bearing- datasets/
4 https://www.mfpt.org/fault- data- sets/
5
Under review as a conference paper at ICLR 2021
	Original	Jittering	Scaling	Cutout
-0.25 -0.50 -0.75				0.00 H				
0	100	200 300	0	100	200 300	0	100	200 300	0	100	200 300 Magnitude Warping	Time Warping	Window Slicing	Window Warping				
-0.25 -0.50 -0.75	0	100 200 30	O	0	100 200 30	≡IV1m" 0	0	100 200 30	磐WU* D	0	100 200 300
Figure 3: Data augmentations examples from CricketX dataset. The blue solid line is the original
signal and the red dotted lines are the transformations.
Baselines. We compare SelfTime against several state-of-the-art methods of self-supervised repre-
sentation learning:
•	Supervised consists of a backbone encoder as the same with SelfTime and a linear classifier,
which conducts fully supervised training over the whole networks.
•	Random Weights is the same as Supervised in the architecture, but freezing the backbone’s
weights during the training and optimizing only the linear classifier.
•	Triplet Loss (Franceschi et al., 2019) is an unsupervised time series representation learning
model that uses triplet loss to push a subsequence of time series close to its context and
distant from a randomly chosen time series.
•	Deep InfoMax (Hjelm et al., 2019) is a framework of unsupervised representation learning
by maximizing mutual information between the input and output of a feature encoder from
the local and global perspectives.
•	Forecast (Jawed et al., 2020) is a semi-supervised time series classification model that
leverages features learned from the self-supervised forecasting task on unlabeled data. In
the experiment, we throw away the supervised classification branch and use only the fore-
casting branch to learn the representations of time series.
•	Transformation (Sarkar & Etemad, 2020) is a self-supervised model by designing transfor-
mation recognition of different time series transformations as pretext task.
•	SimCLR (Chen et al., 2020) is a simple but effective framework for self-supervised rep-
resentation learning by maximizing agreement between different views of augmentation
from the same sample via a contrastive loss in the latent space.
•	Relation (Patacchiola & Storkey, 2020) is relational reasoning based self-supervised repre-
sentation learning model by reasoning the relations between views of the sample objects as
positive, and reasoning the relations between different objects as negative.
Evaluation. As a common evaluation protocol, linear evaluation is used in the experiment by train-
ing a linear classifier on top of the representations learned from different self-supervised models to
evaluate the quality of the learned embeddings. For data splitting, we set the training/validation/test
split as 50%/25%/25%. During the pretraining stage, we randomly split the data 5 times with differ-
ent seeds, and train the backbone on them. During the linear evaluation, we train the linear classifier
10 times on each split data, and the best model on the validation dataset was used for testing. Finally,
we report the classification accuracy as mean with the standard deviation across all trials.
Implementation. All experiments were performed using PyTorch (v1.4.0) (Paszke et al., 2019).
A simple 4-layer 1D convolutional neural network with ReLU activation and batch normalization
(Ioffe & Szegedy, 2015) were used as the backbone encoder fθ for SelfTime and all other base-
lines, and use two separated 2-layer fully-connected networks with 256 hidden-dimensions as the
inter-sample relation reasoning head r* and intra-temporal relation reasoning head rφ respectively
(see Table 4 in Appendix B for details). Adam optimizer (Kingma & Ba, 2015) was used with a
learning rate of 0.01 for pretraining and 0.5 for linear evaluation. The batch size is set as 128 for
all models. For fair comparison, we generate K = 16 augmentations for each sample although
6
Under review as a conference paper at ICLR 2021
UorlelUJojSlJe」二SL
Inter-sample Relation
Intra-temporal Relation
Figure 5: Linear evaluation on CricketX under individual or composition of data augmentations.
For all columns but the last, diagonal entries correspond to single transformation, and off-diagonals
correspond to composition of two transformations (applied sequentially). The last column reflects
the average over the row.
more augmentation results in better performance (Chen et al., 2020; Patacchiola & Storkey, 2020).
More implement details of baselines are shown in Appendix D. More experimental results about the
impact of augmentation number K are shown in Appendix E.
4.2	Ablation Studies
In this section, we firstly investigate the impact of different
temporal relation sampling settings on intra-temporal relation
reasoning. Then, we explore the effectiveness of inter-sample
relation reasoning, intra-temporal relation reasoning, and their
combination (SelfTime), under different time series augmen-
tation strategies. Experimental results show that both inter-
sample relation reasoning and intra-temporal relation reason-
ing achieve remarkable performance, which helps the network
to learn more discriminating features of time series.
u 93
< 77
S
Sfi 61
0 45
0.1 0.15 0.2 0.25 0.3 0.35 0.4
Piece Size (L∕T)
67 y
65岂
63 S
61 二
Temporal Relation Sampling. To investigate the different Figure 4： Impact of different tem-
settings of temporal relation sampling strategy on the impact poral relation class numbers and
of linear evaluation performance, in the experiment, we set piece sizes on CricketX dataset.
different numbers of temporal relation class C and time piece
length L. Specifically, to investigate the impact of class number, we firstly set the piece length
L = 0.2 * T as 20% of the original time series length, then, We vary C from 2 to 8 during the
temporal relation sampling. As shown in Figure 4, we show the results of parameter sensitivity
experiments on CricketX, Where blue bar indicates class reasoning accuracy on training data (Class
ACC) and broWn line indicates the linear evaluation accuracy on test data (Linear ACC). With the
increase of class number, the Linear ACC keeps increasing until C = 5, and We find that a small
value C = 2 and a big value C = 8 result in Worse performance. One possible reason behind this
is that the increase of class number drops the Class ACC and makes the relation reasoning task too
difficult for the netWork to learn useful representation. Similarly, When set the class number C = 3
and vary the piece length L from 0.1 * T to 0.4 * T, We find that the Linear ACC groWs up With
the increase of piece size until L = 0.3 * T, and also, either small value or big value of L Will drop
the evaluation performance, Which makes the relation reasoning task too simple (With high Class
ACC) or too difficult (With loW Class ACC) and prevents the netWork from learning useful semantic
representation. Therefore, as consistent With the observations of self-supervised studies in other
domains (Pascual et al., 2019b; Wang et al., 2020), an appropriate pretext task designing is crucial
for the self-supervised time series representation learning. In the experiment, to select a moderately
difficult pretext task for different datasets, We set {class number (C), piece size (L/T)} as {3, 0.2}
for CricketX, {4, 0.2} for UWaveGestureLibraryAll, {5, 0.35} for DodgerLoopDay, {6, 0.4} for
InsectWingbeatSound, {4, 0.2} for MFPT, and {4, 0.2} for XJTU. More experimental results on
other five datasets for parameter sensitivity analysis are shoWn in Appendix E.
7
Under review as a conference paper at ICLR 2021
Method	Dataset					
	CricketX	UGLA	DLD	IWS	MFPT	XJTU
Supervised	62.44±1.53	87.83±0.32	37.05±1.61	66.23±0.45	80.29±0.8	95.9±0.42
Random Weights	36.9±0.92	70.01±1.68	32.95±2.57	52.85±1.36	46.68±2.35	52.58±4.67
Triplet Loss (FranCesChi et al., 2019)	40.01±2.64	71.41±1.1	41.37±2.47	53.61±2.82	47.87±2.97	53.31±3.43
Deep InfoMax (Hjelm et al., 2019)	49.16±3.03	73.88±2.37	38.95±2.47	55.99±1.31	58.99±2.72	76.27±1.83
Forecast (Jawed et al., 2020)	44.59±1.09	75.7±0.9	38.74±3.05	54.89±1.99	52.6±1.65	62.28±2.55
Transformation (Sarkar & Etemad, 2020)	52.12±2.02	75.41±0.27	35.47±1.56	59.68±1.2	60.33±3.29	85.08±2.01
SimCLR (Chen et al., 2020)	59.0±3.19	74.9±0.92	37.74±3.8	56.19±0.98	71.81±1.21	88.84±0.63
Relation (Patacchiola & Storkey, 2020)	65.3±0.43	80.87±0.78	42.84±3.23	62.0±1.49	73.53±0.65	95.14±0.72
SelfTime (ours)	68.6±0.66	84.97±0.83	49.1±2.93	66.87±0.71	78.48±0.94	96.73±0.76
Table 2: Linear evaluation of representations learned by different models on different datasets.
Impact of Different Relation Modules and Data Augmentations. To explore the effectiveness of
different relation reasoning modules including inter-sample relation reasoning, intra-temporal rela-
tion reasoning, and their combination (SelfTime), in the experiment, we systematically investigate
the different data augmentations on the impact of linear evaluation for different modules. Here, we
consider several common augmentations including magnitude domain based transformations such
as jittering (Jit.), cutout (Cut.), scaling (Sca.), magnitude warping (M.W.), and time domain based
transformations such as time warping (T.W.), window slicing (W.S.), window warping (W.W.). Fig-
ure 5 shows linear evaluation results on CricketX dataset under individual and composition of trans-
formations for inter-sample relation reasoning, intra-temporal relation reasoning, and their combina-
tion (SelfTime). Firstly, we observe that the composition of different data augmentations is crucial
for learning useful representations. For example, inter-sample relation reasoning is more sensitive
to the augmentations, and performs worse under Cut., Sca., and M.W. augmentations, while intra-
temporal relation reasoning is less sensitive to the manner of augmentations, although it performs
better under the time domain based transformation. Secondly, by combining both the inter-sample
and intra-temporal relation reasoning, the proposed SelfTime achieves better performance, which
demonstrates the effectiveness of considering different levels of relation for time series representa-
tion learning. Thirdly, we find that the composition from a magnitude-based transformation (e.g.
scaling, magnitude warping) and a time-based transformation (e.g. time warping, window slicing)
facilitates the model to learn more useful representations. Therefore, in this paper, we select the
composition of magnitude warping and time warping augmentations for all experiments. Similar
experimental conclusions also hold on for other datasets. More experimental results on the other
five datasets for evaluation of the impact of different relation modules and data augmentations are
shown in Appendix F.
4.3	Time Series Classification
In this section, we evaluate the proposed method by comparing with other state-of-the-arts on time
series classification task. Firstly, we conduct linear evaluation to assess the quality of the learned
representations. Then, we evaluate the performance of all methods in transfer learning by training
on the unlabeled source dataset and conduct linear evaluation on the labeled target dataset. Finally,
we qualitatively evaluate and verify the semantic consistency of the learned representations.
Linear Evaluation. Following the previous studies (Chen et al., 2020; Patacchiola & Storkey,
2020), we train the backbone encoder for 400 epochs on the unlabeled training set, and then train
a linear classifier for 400 epochs on top of the backbone features (the backbone weights are frozen
without back-propagation). As shown in Table 2, our proposed SelfTime consistently outperforms
all baselines across all datasets. SelfTime improves the accuracy over the best baseline (Relation)
by 5.05% (CricketX), 5.06% (UGLA), 14.61% (DLD), 7.85% (IWS), 6.73% (MFPT), and 1.67%
(XJTU) respectively. Among those baselines, either global features (Deep InfoMax, Transforma-
tion, SimCLR, Relation) or local features (Triplet Loss, Deep InfoMax, Forecast) are considered
during representation learning, they neglect the essential temporal information of time series ex-
cept Triplet Loss and Forecast. However, by simply forecasting future time pieces, Forecast cannot
capture useful temporal structure effectively, which results in low-quality representations. Also, in
Triplet Loss, a time-based negative sampling is used to capture the inter-sample temporal relation
among time pieces sampled from the different time series, which is cannot directly and efficiently
capture the intra-sample temporal pattern of time series. Different from all those baselines, Self-
Time not only extracts global and local features by taking the whole time series and its time pieces
8
Under review as a conference paper at ICLR 2021
Method	Source →Target					
	UGLA→CricketX	CricketX→UGLA	IWS→DLD	DLD→IWS	XJTU→MFPT	MFPT→XJTU
Supervised	31.31±2.76	71.85±1.2	22.9±2.55	44.31 ±3.25	63.15±2.08-	82.58±3.98
Random Weights	36.9±0.92	70.01 ±1.68	32.95±2.57	52.85±1.36	46.68 ±2.35	52.58±4.67
Triplet Loss (FranCeSChi et al., 2019)	30.08±4.66	55.32±2.51	34.67±3.12	45.22±3.09	53.75 ±2.96-	59.24±3.02
Deep InfoMax (Hjelm et al., 2019)	45.92±2.3	64.2±4.19	37.42±1.99	47.75±1.74	56.75 ±0.77	77.14±3.14
Forecast (Jawed et al., 2020)	32.67 ±0.86	72.42±1.17	25.47±2.93	55.39±1.36	53.08±2.75	61.74±3.92
Transformation (Sarkar & Etemad, 2020)	39.24±2.25	70.4±1.98	30.0±1.66	57.71±0.83	54.71±1.68	69.81±8.03
SimCLR (Chen et al., 2020)	45.48 ±3.46	65.67 ±2.91	36.21±1.02	36.2±4.03	63.11±2.0	81.62±3.95
Relation (Patacchiola & Storkey, 2020)	52.55 ±2.67	75.67 ±0.54	36.0±1.52	56.29±1.82	70.27±1.14	92.77±1.15
SelfTime (ours)	55.04±2∙58	77.77±035	45.0±1.48	57.8±133	75.06±1.84	93.79±2∙46
Table 3: Domain transfer evaluation by training with self-supervision on the unlabeled source data
and linear evaluation on the labeled target data (e.g. source→target: UGLA→CricketX).
Triplet Loss
Deep InfomaX	Forecast
Transformation
SimCLR	Relation	SelfTime
Figure 6: t-SNE visualization of the learned feature on UGLA dataset. Different colors indicate
different labels.
as inputs during feature extraction, but also captures the implicit temporal structure by reasoning
intra-temporal relation among time pieces.
Domain Transfer. To evaluate the transferability of the learned representations, we conduct exper-
iments in transfer learning by training on the unlabeled source dataset and conduct linear evaluation
on the labeled target dataset. In the experiment, we select two datasets from the same category as
the source and target respectively. As shown in Table 3, experimental results show that our SelfTime
outperforms all the other baselines under different conditions. For example, SelfTime achieves an
improvement over the Relation by 4.73% on UGLA→CricketX transfer, and over Deep InfoMax
20.2% on IWS→DLD transfer, and over Relation 6.81% on XJTU→MFPT transfer, respectively,
which demonstrates the good transferability of the proposed method.
Visualization. To qualitatively evaluate the learned representations, we use the trained backbone to
extract the features and visualize them in 2D space using t-SNE (Maaten & Hinton, 2008) to verify
the semantic consistency of the learned representations. Figure 6 shows the visualization results
of features from the baselines and the proposed SelfTime on UGLA dataset. It is obvious that
by capturing global sample structure and local temporal structure, SelfTime learns more semantic
representations and results in better clustering ability for time series data, where more semantic
consistency is preserved in the learned representations by our proposed method.
5 Conclusion
We presented a self-supervised approach for time series representation learning, which aims to ex-
tract useful feature from the unlabeled time series. By exploring the inter-sample relation and intra-
temporal relation, SelfTime is able to capture the underlying useful structure of time series. Our
main finding is that designing appropriate pretext tasks from both the global-sample structure and
local-temporal structure perspectives is crucial for time series representation learning, and this find-
ing motivates further thinking of how to better leverage the underlying structure of time series.
Our experiments on multiple real-world datasets show that our proposed method consistently out-
performs the state-of-the-art self-supervised representation learning models, and establishes a new
state-of-the-art in self-supervised time series classification. Future directions of research include ex-
ploring more effective intra-temporal structure (i.e. reasoning temporal relation under the time point
level), and extending the SelfTime to multivariate time series by considering the causal relationship
among variables.
9
Under review as a conference paper at ICLR 2021
References
Anthony Bagnall, Jason Lines, Jon Hills, and Aaron Bostrom. Time-series classification with cote:
the collective of transformation-based ensembles. IEEE Transactions on Knowledge and Data
Engineering, 27(9):2522-2535, 2015.
Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi,
Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al.
Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261,
2018.
Mustafa Gokce Baydogan, George Runger, and Eugene Tuv. A bag-of-features framework to clas-
sify time series. IEEE transactions on pattern analysis and machine intelligence, 35(11):2796-
2802, 2013.
Donald J Berndt and James Clifford. Using dynamic time warping to find patterns in time series. In
KDD workshop, volume 10, pp. 359-370. Seattle, WA, USA:, 1994.
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for
contrastive learning of visual representations. In Proceedings of the 37th international conference
on machine learning (ICML), 2020.
Ziqiang Cheng, Yang Yang, Wei Wang, Wenjie Hu, Yueting Zhuang, and Guojie Song. Time2graph:
Revisiting time series modeling with dynamic shapelets. In Proceedings of the AAAI Conference
on Artificial Intelligence, AAAI, pp. 3617-3624, 2020.
Samarjit Das. Time series analysis, volume 10. Princeton university press, Princeton, NJ, 1994.
Hoang Anh Dau, Eamonn Keogh, Kaveh Kamgar, Chin-Chia Michael Yeh, Yan Zhu, Shaghayegh
Gharghabi, Chotirat Ann Ratanamahatana, Yanping, Bing Hu, Nurjahan Begum, Anthony Bag-
nall, Abdullah Mueen, Gustavo Batista, and Hexagon-ML. The ucr time series classification
archive, October 2018. https://www.cs.ucr.edu/~eamonn/time_series_data_
2018/.
Terrance DeVries and Graham W Taylor. Improved regularization of convolutional neural networks
with cutout. arXiv preprint arXiv:1708.04552, 2017.
Vincent Fortuin, Matthias HUser, Francesco Locatello, Heiko Strathmann, and Gunnar Ratsch. Som-
vae: Interpretable discrete representation learning on time series. In 7th International Conference
on Learning Representations, ICLR, 2019.
Jean-Yves Franceschi, Aymeric Dieuleveut, and Martin Jaggi. Unsupervised scalable representation
learning for multivariate time series. In Advances in Neural Information Processing Systems, pp.
4650-4661, 2019.
Spyros Gidaris, Praveer Singh, and Nikos Komodakis. Unsupervised representation learning by
predicting image rotations. In 6th International Conference on Learning Representations, ICLR,
2018.
Micah B Goldwater, Hilary Don, Moritz J F Krusche, and Evan J Livesey. Relational discovery in
category learning. Journal of Experimental Psychology: General, 147(1):1-35, 2018.
Tomasz Gorecki and Maciej Euczak. Non-isometric transforms in time series classification using
dtw. Knowledge-Based Systems, 61:98-108, 2014.
Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. Speech recognition with deep recur-
rent neural networks. In 2013 IEEE international conference on acoustics, speech and signal
processing, ICASSP, pp. 6645-6649, 2013.
Jon Hills, Jason Lines, Edgaras Baranauskas, James Mapp, and Anthony Bagnall. Classification of
time series by shapelet transformation. Data Mining and Knowledge Discovery, 28(4):851-881,
2014.
10
Under review as a conference paper at ICLR 2021
R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam
Trischler, and Yoshua Bengio. Learning deep representations by mutual information estimation
and maximization. In 7th International Conference on Learning Representations, ICLR, 2019.
SePP Hochreiter and Jurgen Schmidhuber. Long short-term memory. Neural computation, 9(8):
1735-1780,1997.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.
Brian Kenji Iwana and Seiichi Uchida. Time series data augmentation for neural networks by time
warPing with a discriminative teacher. arXiv preprint arXiv:2004.08780, 2020.
Shayan Jawed, Josif Grabocka, and Lars Schmidt-Thieme. Self-suPervised learning for semi-
suPervised time series classification. In Pacific-Asia Conference on Knowledge Discovery and
Data Mining, PAKDD, PP. 499-511. SPringer, 2020.
Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C Lawrence Zitnick, and
Ross Girshick. Clevr: A diagnostic dataset for comPositional language and elementary visual
reasoning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
CVPR, PP. 2901-2910, 2017.
Myeongsu Kang, Jaeyoung Kim, Linda M Wills, and Jong-Myon Kim. Time-varying and multires-
olution enveloPe analysis and discriminative feature analysis for bearing fault diagnosis. IEEE
Transactions on Industrial Electronics, 62(12):7749-7761, 2015.
Fazle Karim, Somshubra Majumdar, Houshang Darabi, and Shun Chen. Lstm fully convolutional
networks for time series classification. IEEE access, 6:1662-1669, 2017.
Charles KemP and Joshua B Tenenbaum. The discovery of structural form. Proceedings of the
National Academy of Sciences, 105(31):10687-10692, 2008.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic oPtimization. In 3th Interna-
tional Conference on Learning Representations, ICLR, 2015.
Arthur Le Guennec, Simon Malinowski, and Romain Tavenard. Data Augmentation for Time Series
Classification using Convolutional Neural Networks. In ECML/PKDD Workshop on Advanced
Analytics and Learning on Temporal Data, 2016.
Jason Lines and Anthony Bagnall. Time series classification with ensembles of elastic distance
measures. Data Mining and Knowledge Discovery, 29(3):565-592, 2015.
Qianli Ma, Wanqing Zhuang, and Garrison Cottrell. TriPle-shaPelet networks for time series classi-
fication. In 2019 IEEE International Conference on Data Mining (ICDM), PP. 1246-1251. IEEE,
2019.
Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine
learning research, 9(Nov):2579-2605, 2008.
Ishan Misra, C Lawrence Zitnick, and Martial Hebert. Shuffle and learn: unsuPervised learning
using temPoral order verification. In European Conference on Computer Vision, ECCV, PP. 527-
544. SPringer, 2016.
Mehdi Noroozi and Paolo Favaro. UnsuPervised learning of visual rePresentations by solving jigsaw
Puzzles. In European Conference on Computer Vision, ECCV, PP. 69-84. SPringer, 2016.
Boris N Oreshkin, Dmitri CarPov, Nicolas ChaPados, and Yoshua Bengio. N-beats: Neural basis
exPansion analysis for interPretable time series forecasting. In 8th International Conference on
Learning Representations, ICLR, 2020.
Santiago Pascual, Mirco Ravanelli, Joan Serra, Antonio Bonafonte, and Yoshua Bengio. Learning
Problem-agnostic sPeech rePresentations from multiPle self-suPervised tasks. In Proc. of the Conf.
of the Int. Speech Communication Association (INTERSPEECH), PP. 161-165, 2019a.
11
Under review as a conference paper at ICLR 2021
Santiago Pascual, Mirco Ravanelli, Joan Serra, Antonio Bonafonte, and Yoshua Bengio. Learning
Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks. In Proc. of the
Conf. ofthe Int. Speech Communication Association (INTERSPEECH),pp. 161-165, 2019b.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style,
high-performance deep learning library. In Advances in neural information processing systems,
NeurIPS, pp. 8026-8037, 2019.
Massimiliano Patacchiola and Amos Storkey. Self-supervised relational reasoning for representation
learning. arXiv preprint arXiv:2006.05849, 2020.
Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros. Context
encoders: Feature learning by inpainting. In Proceedings of the IEEE conference on computer
vision and pattern recognition, CVPR, pp. 2536-2544, 2016.
Mirco Ravanelli, Jianyuan Zhong, Santiago Pascual, Pawel Swietojanski, Joao Monteiro, Jan Trmal,
and Yoshua Bengio. Multi-task self-supervised learning for robust speech recognition. In IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6989-6993,
2020.
Aaqib Saeed, Tanir Ozcelebi, and Johan Lukkien. Multi-task self-supervised learning for human
activity detection. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous
Technologies, 3(2):1-30, 2019.
Aaqib Saeed, Flora D Salim, Tanir Ozcelebi, and Johan Lukkien. Federated self-supervised learning
of multi-sensor representations for embedded intelligence. IEEE Internet of Things Journal, 2020.
Adam Santoro, David Raposo, David G Barrett, Mateusz Malinowski, Razvan Pascanu, Peter
Battaglia, and Timothy Lillicrap. A simple neural network module for relational reasoning. In
Advances in neural information processing systems, NIPS, pp. 4967-4976, 2017.
Pritam Sarkar and Ali Etemad. Self-supervised learning for ecg-based emotion recognition. In
ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP), pp. 3217-3221. IEEE, 2020.
Patrick Schafer. The boss is concerned with time series classification in the presence of noise. Data
Mining and Knowledge Discovery, 29(6):1505-1530, 2015.
Steffen Schneider, Alexei Baevski, Ronan Collobert, and Michael Auli. wav2vec: Unsupervised
pre-training for speech recognition. In Proc. of the Conf. of the Int. Speech Communication
Association (INTERSPEECH), pp. 3465-3469, 2019.
Rajat Sen, Hsiang-Fu Yu, and Inderjit S Dhillon. Think globally, act locally: A deep neural net-
work approach to high-dimensional time series forecasting. In Advances in Neural Information
Processing Systems, NeurIPS, pp. 4837-4846, 2019.
Satya Narayan Shukla and Benjamin M Marlin. Interpolation-prediction networks for irregularly
sampled time series. In 7th International Conference on Learning Representations, ICLR, 2019.
Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. Reasoning with neural
tensor networks for knowledge base completion. In Advances in neural information processing
systems, NIPS, pp. 926-934, 2013.
ABA Stevner, Diego Vidaurre, Joana Cabral, K Rapuano, S0ren F0ns Vind Nielsen, Enzo Tagli-
azucchi, Helmut Laufs, Peter Vuust, Gustavo Deco, Mark W Woolrich, et al. Discovery of key
whole-brain transitions and dynamics during human wakefulness and non-rem sleep. Nature
communications, 10(1):1-14, 2019.
Terry T Um, Franz MJ Pfister, Daniel Pichler, Satoshi Endo, Muriel Lang, Sandra Hirche, Urban
Fietzek, and Dana Kulic. Data augmentation of wearable sensor data for parkinson,s disease
monitoring using convolutional neural networks. In Proceedings of the 19th ACM International
Conference on Multimodal Interaction, pp. 216-220, 2017.
12
Under review as a conference paper at ICLR 2021
	Layer Description	Output Tensor Dim.
#0	Input time series (or time piece)	1 × T (or 1 × L)
Backbone Encoder		
#1	Conv1D(1, 8, 4, 2, 1)+BatchNorm+ReLU	8 × T/2 (or 8 × L/2)
#2	ConvID(8,16, 4, 2,1)+BatchNorm+ReLU	16 × T/4 (or 16 × L/4)
#3	ConvID(16, 32,4, 2,1)+BatchNorm+ReLU	32 × T/8 (or 32 × L/8)「
#4	ConvID(32, 64,4, 2,1)+BatchNorm+ReLU +AvgPool1D+Flatten+Normalize	64
Inter-Sample Relation Reasoning Head		
#1	Linear+BatchNorm+LeakyReLU	256
#2	Linear+Sigmoid	1
Intra-Temporal Relation Reasoning Head		
#1	Linear+BatchNorm+LeakyReLU	256
#2	Linear+Softmax	C
Table 4: Implementation detail of SelfTime. Here, we denote 1D convolutional layer as
ConvID(in_channels, out_channels, kerneLsize, stride, padding).
Jiangliu Wang, Jianbo Jiao, and Yun-Hui Liu. Self-supervised video representation learning by pace
prediction. In European conference on computer vision, ECCV, 2020.
Xiaolong Wang and Abhinav Gupta. Unsupervised learning of visual representations using videos.
In Proceedings of the IEEE international conference on computer vision, ICCV, pp. 2794-2802,
2015.
Donglai Wei, Joseph J Lim, Andrew Zisserman, and William T Freeman. Learning and using the ar-
row of time. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
CVPR, pp. 8052-8060, 2018.
Lexiang Ye and Eamonn Keogh. Time series shapelets: a new primitive for data mining. In Pro-
ceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data
mining, KDD, pp. 947-956, 2009.
Vinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor Babuschkin, Karl
Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart, et al. Deep reinforcement learning
with relational inductive biases. In 7th International Conference on Learning Representations,
ICLR, 2019.
Zhibin Zhao, Tianfu Li, Jingyao Wu, Chuang Sun, Shibin Wang, Ruqiang Yan, and Xuefeng Chen.
Deep learning algorithms for rotating machinery intelligent diagnosis: An open source benchmark
study. arXiv preprint arXiv:2003.03315, 2020.
Bolei Zhou, Alex Andonian, Aude Oliva, and Antonio Torralba. Temporal relational reasoning in
videos. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 803-818,
2018.
A Pseudo-code of S elfTime
The overview of training process for SelfTime is summarized in Algorithm 2.
B	Architecture Diagram
SelfTime consists of a backbone encoder, a inter-sample relation reasoning head, and a intra-
temporal relation reasoning head. The detail architectural diagrams of SelfTime are shown in Table
4.
C Data Augmentation
In this section, we list the configuration details of augmentation used in the experiment:
13
Under review as a conference paper at ICLR 2021
Algorithm 2: SelfTime
Require:
Time series set T = {tn}nN=1.
fθ : Encoder backbone.
rμ: Inter-sample relation reasoning head.
rφ: Intra-temporal relation reasoning head.
Ensure:
fθ: An updated encoder backbone.
1	: for tm , tn ∈ T do
2	:	Generate two augmentation sets A(tm) and A(tn)
3	:	Sample positive relation pair (t(mi), t(mj)) and negative
	relation pair (t(mi), t(nj)) from A(tm) and A(tn)
4	:	zm(i) = fθ (t(mi))	. Sample representation
5	:	zm = fθ (t(mj) )	. Sample representation
6	:	zn(j) = fθ (t(nj) )	. Sample representation
7	h2ij-1 = rμ([zm , zm )])	. Reasoning score of positive relation
8	h2ij) = rμ([zm , zP)])	. Reasoning score of negative relation
9	:	Sample time piece relation pair (pn,u , pn,v) by Algorithm 1
10	:	zn,u = fθ(pn,u)	. Time piece representation
11	:	zn,v = fθ (pn,v)	. Time piece representation
12	hnu,v) = rφ([zn,u, Zn,v])	. Reasoning score of intra-temporal relation
13	: end for
14	Linter = - Pn=I P= PK=收中)∙ lθg(hij"
	+(1 - y(i,j)) ∙ log(1 - hni,j)))	. Inter-sample relation reasoning loss
15	Lintra = - PN=I 期'*' ∙ log「*%；"、	. Intra-temporal relation reasoning loss c=1 exp(hn )
16	Update fθ, rj and rφ by minimizing
L = Linter + Lintra
17: return encoder backbone fθ, throw away r*, and rφ
14
Under review as a conference paper at ICLR 2021
Jittering: We add the gaussian noise to the original time series, where noise is sampled from a
Gaussian distribution N (0, 0.2).
Scaling: We multiply the original time series with a random scalar sampled from a Gaussian distri-
bution N (0, 0.4).
Cutout: We replace a random 10% part of the original time series with zeros and remain the other
parts unchanged.
Magnitude Warping: We multiply a warping amount determined by a cubic spline line with 4 knots
on the original time series at random locations and magnitudes. The peaks or valleys of the knots
are set as μ = 1 and σ = 0.3 (Um et al., 2017).
Time Warping: We set the warping path according to a smooth cubic spline-based curve with 8
knots, where the random magnitudes is μ = 1 and a σ = 0.2 for each knot (Um et al., 2017).
Window Slicing: We randomly crop 80% of the original time series and interpolate the cropped
time series back to the original length (Le Guennec et al., 2016).
Window Warping: We randomly select a time window that is 30% of the original time series length,
and then warp the time dimension by 0.5 times or 2 times (Le Guennec et al., 2016).
D Baselines
Triplet Loss5 (Franceschi et al., 2019) We download the authors’ official source code and use the
same backbone as SelfTime, and set the number of negative samples as 10. We use Adam optimizer
with learning rate 0.001 according to grid search and batch size 128 as same with SelfTime.
Deep InfoMax6 (Hjelm et al., 2019) We download the authors’ official source code and use the same
backbone as SelfTime, and set the parameter α = 0.5, β = 1.0, γ = 0.1 through grid search. We
use Adam optimizer with learning rate 0.0001 according grid search and batch size 128 as same with
SelfTime.
Forecast7 (Jawed et al., 2020) Different from the original multi-task model proposed by authors,
we throw away the supervised classification branch and use only the proposed forecasting branch
to learn the representation in a fully self-supervised manner. We use Adam optimizer with learning
rate 0.01 according to grid search and batch size 128 as same as SelfTime.
Transformation8 (Sarkar & Etemad, 2020) We refer to the authors’ official source code and reim-
plement it in PyTorch by using the same backbone and two-layer projection head as same with
SelfTime. We use Adam optimizer with learning rate 0.001 according to grid search and batch size
128 as same with SelfTime.
SimCLR9 (Chen et al., 2020) We download the authors’ official source code by using the same
backbone and two-layer projection head as same with SelfTime. We use Adam optimizer with
learning rate 0.5 according grid search and batch size 128 as same as SelfTime.
Relation10 (Patacchiola & Storkey, 2020) We download the authors’ official source code by using
the same backbone and relation module as same with SelfTime. For augmentation, we set K = 16,
and use Adam optimizer with learning rate 0.5 according to grid search and batch size 128 as same
with SelfTime.
E Parameter Sensitivity
Figure 7 shows the impact of different augmentation number K on all datasets. It’s obvious that more
augmentations result in better performance, which demonstrates that introducing more reference
5https://github.com/White-Link/UnsupervisedScalableRepresentationLearningTimeSeries
6https://github.com/rdevon/DIM
7https://github.com/super-shayan/semi-super-ts-clf
8https://code.engineering.queensu.ca/17ps21/SSL-ECG
9https://github.com/google-research/simclr
10https://github.com/mpatacchiola/self-supervised-relational-reasoning
15
Under review as a conference paper at ICLR 2021
2	4	8	16	32	48	64	2	4	8	16	32	48	64
XJTU
-∏ I I I I I 厂
一♦_一--∙-∙
一1_	-----
b i
2	4	8	16	32	48	64
81
U79
。75
73
Number of augmentations (K)
Figure 7: Impact of augmentation number K .
99
U 97
U 95
<93
91
Number of augmentations (K)
samples (including positive samples and negative samples) for the anchor sample raises the power
of relational reasoning.
Figure 8 shows the impact of different temporal relation class numbers and piece sizes on other five
datasets: UWaveGestureLibraryAll, DodgerLoopDay, InsectWingbeatSound, MFPT, and XJTU,
where the blue bar indicates class reasoning accuracy on training data (Class ACC) and the brown
line indicates the linear evaluation accuracy on test data (Linear ACC). We find an interesting phe-
nomenon is that both small values of class number C or piece size L/T , and big values C or L/T ,
result in worse performance. One possible reason behind this is that the increase of class number
drops the Class ACC and makes the relation reasoning task too simple (with high Class ACC) or too
difficult (with low Class ACC) and prevents the network from learning useful semantic representa-
tion. Therefore, an appropriate pretext task designing is crucial for the self-supervised time series
representation learning. In the experiment, to select a moderately difficult pretext task for different
datasets, we set {class number (C), piece size (L/T)} as {4, 0.2} for UWaveGestureLibraryAll, {5,
0.35} for DodgerLoopDay, {6, 0.4} for InsectWingbeatSound, {4, 0.2} for MFPT, and {4, 0.2} for
XJTU.
F	Ablation S tuty
In this section, we additionally explore the effectiveness of different relation reasoning modules
including inter-sample relation reasoning, intra-temporal relation reasoning, and their combina-
tion (SelfTime) on other five datasets including UWaveGestureLibraryAll, DodgerLoopDay, In-
sectWingbeatSound, MFPT, and XJTU. Specifically, in the experiment, we systematically inves-
tigate the different data augmentations on the impact of linear evaluation for different modules.
Here, we consider several common augmentations including magnitude domain based transforma-
tions such as jittering (Jit.), cutout (Cut.), scaling (Sca.), magnitude warping (M.W.), and time do-
main based transformations such as time warping (T.W.), window slicing (W.S.), window warping
(W.W.). Figure 9 and Figure 10 show linear evaluation results on five datasets under individual and
composition of transformations for inter-sample relation reasoning, intra-temporal relation reason-
ing, and their combination (SelfTime). As similar to the observations from CricketX, firstly, we
observe that the composition of different data augmentations is crucial for learning useful represen-
tations. For example, inter-sample relation reasoning is more sensitive to the augmentations, and
performs worse under Cut., Sca., and M.W. augmentations, while intra-temporal relation reason-
ing is less sensitive to the manner of augmentations on all datasets. Secondly, by combining both
the inter-sample and intra-temporal relation reasoning, the proposed SelfTime achieves better per-
formance, which demonstrates the effectiveness of considering different levels of relation for time
series representation learning. Thirdly, overall, we find that the composition from a magnitude-
16
Under review as a conference paper at ICLR 2021
2 2 2 2
8 7 6 5
(U
8< SSBD
(⅛ΦH)
Bφu∑j
Piece Size ( L∕T)
QSR)
Bφuπ
5 3 19
8 8 8 7
80
1 9
9 7
Class Number ( C)
(U
ɔɔɑ SSB
(a) UWaveGestureLibraryAll
9 8 7 6 5
Piece Size ( L∕T)
QSφ匕
8<⅛φ⊂-l-
5 3 19 7
5 5 5 4 4
cra.JF)
ɔuv ωωωο
αsφ匕
8VJBΦUΠ
4 3 2 10
5 5 5 5 5
8 14 7 0
9 9 8 7 7
cra.JF)
V SSB0
Class Number ( C)
(b) DodgerLooPDay
(U
ɔɔɑ SSB
6 8 0 2 4
8 7 7 6 5
9 7 5 3 1
6 6 6 6 6
(U
8< SSBD
(ttφH)
8<⅛φ⊂-1-
(ttφ匕
8<⅛φ⊂-^
0 6 2 8 4
7 6 6 5 5
Class Number ( C)
(c) InSectWingbeatSound
QSφ匕
ɔBφuπ
8 4 0 6 2
7 7 7 6 6
(U一巴匕
ɔuv SSBD
(⅛φ匕
ɔBφuπ
6 4 2 0 8
7 7 7 7 6
8
2
Ooooo
8 7 6 5 4
(U一巴匕
ɔuv SS33
7
6
5
4
3
Class Number ( C)
(d) MFPT
Class Number ( C)
craΛO
uu< SSB
13 5 7
7 6 5 4
Piece Size ( L∕T)
8<⅛φ⊂-1-
0 8 6 4 2
9 8 8 8 8
αsφL)
(e) XJTU
Figure 8: Impact of different temporal relation class numbers and piece sizes on other five datasets.
17
Under review as a conference paper at ICLR 2021
2nd transformation
Jit. Cut. Sea. M.W. T,W. W.S. W.W.
Inter-sample Relation
2nd transformation
Jit Cut. Sea. M.W. T.W. W.S. W.W.
2nd traπsfoπnatjon
Jit. Cut Sea. M.W. T.W. W,S. W,W.
79.4 78.3 79.2 ⅛T 79.4 79.5 79.0
78.0 日
78.6 ≡
79.2 国	；；
78.8 N国回国79.7
77,6 79.6 国剪 79.7 日
78.6
Intra-temporal Relation
(a) UWaveGestureLibraryAll
2nd transformation
Jit. Cut. Sea. M.W. T.W, W,S, W.W. Avg.
77.6 78.2 78.6 79.2 79.0 77.0 78.4 78.3
SelfTime
81.2
82.6
83.1
81.7
80.7
81.1
84
80
7β
72
68
Inter-sample Relation	Intra-temporal Relation	SelfTime
(b) DodgerLoopDay
(c) InsectWingbeatSound
Figure 9: Linear evaluation on UWaveGestureLibraryAll, DodgerLoopDay, and InsectWingbeat-
Sound datasets under individual or composition of data augmentations. For all columns but the last,
diagonal entries correspond to single transformation, and off-diagonals correspond to composition
of two transformations (applied sequentially). The last column reflects the average over the row.
based transformation (e.g. scaling, magnitude warping) and a time-based transformation (e.g. time
warping, window slicing) facilitates the model to learn more useful representations. Therefore, in
this paper, we select the composition of magnitude warping and time warping augmentations for all
datasets, although other compositions might result in better performance.
18
Under review as a conference paper at ICLR 2021
uoqeιUJojSUe4-S=
62.7 66.7 68.3 64.3
2nd transformation
Cut. Sea. M.W. T.W. W.S. W.W.
2nd transformation
Cut Sea. M.W. T.W. W.S. W.W.
Uo-«IuJoJSuaη ISb
63.7 65.4
2nd transformation
Cut. Sea. M.W. T.W. W.S. W.W.
77.6
77.5
69.2
68.2
67.6
Avg.
69.1
69.2
Inter-sample Relation
Intra-temporal Relation
(a) MFPT
SelfTime
2nd transformation
Jit Cut Sea. M.W. T,W. W.S. W.W.
82.3 84.3 85.2
88.0 85.9
86.1 81.3
86.6 84.3
85.2 Q	1 89.2
84,3 88.0 国团鼠 89.3
81.3	79.9 83.5	85 8
84.5
82.9
85.7
86.3
92.3
90.7
88.2
84.7
81.7
85.6 87.6 84.8
86.0 89.5 86.1
87.9 84.9 85.2
85.2 82.8 87.1
Avg.
83.2
86.6
84.2
87.6
85.6
85.0
85.9
2nd transformation
Jit. Cut. Sea. M.W. T.W, W,S, W,W.
88.8	g 87.5
83.9 阴阴 89.9 Efj

Inter-sample Relation
Intra-temporal Relation
(b) XJTU
SelfTime
Figure 10: Linear evaluation on MFPT and XJTU datasets under individual or composition of data
augmentations. For all columns but the last, diagonal entries correspond to single transformation,
and off-diagonals correspond to composition of two transformations (applied sequentially). The last
column reflects the average over the row.
19