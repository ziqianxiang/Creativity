Under review as a conference paper at ICLR 2021
On the Certified Robustness for Ensemble
Models and Beyond
Anonymous authors
Paper under double-blind review
Ab stract
Recent studies show that deep neural networks (DNN) are vulnerable to adver-
sarial examples, which aim to mislead DNNs to make arbitrarily incorrect pre-
dictions. To defend against such attacks, both empirical and theoretical defense
approaches have been proposed for a single ML model. In this work, we aim
to explore and characterize the robustness conditions for ensemble ML models.
We prove that the diversified gradient and large confidence margin are sufficient
and necessary conditions for certifiably robust ensemble models under the model-
smoothness assumption. We also show that an ensemble model can achieve higher
certified robustness than a single base model based on these conditions. To our
best knowledge, this is the first work providing tight conditions for the ensemble
robustness. Inspired by our analysis, we propose the lightweight Diversity Regu-
larized Training (DRT) for ensemble models. We derive the certified robustness of
DRT based ensembles such as standard Weighted Ensemble and Max-Margin En-
semble following the sufficient and necessary conditions. Besides, to efficiently
calculate the model-smoothness, we leverage adapted randomized model smooth-
ing to obtain the certified robustness for different ensembles in practice. We show
that the certified robustness of ensembles, on the other hand, verifies the neces-
sity of DRT. To compare different ensembles, we prove that when the adversarial
transferability among base models is high, Max-Margin Ensemble can achieve
higher certified robustness than Weighted Ensemble; vice versa. Extensive exper-
iments show that ensemble models trained with DRT can achieve the state-of-the-
art certified robustness under various settings. Our work will shed light on future
analysis for robust ensemble models.
1 Introduction
Deep neural networks (DNN) have been widely applied in various applications, such as image clas-
sification (Krizhevsky, 2012; He et al., 2016), face recognition (Taigman et al., 2014; Sun et al.,
2014), and natural language processing (Vaswani et al., 2017; Devlin et al., 2019). However, it is
well-known that DNNs are vulnerable to adversarial examples (Szegedy et al., 2013; Carlini & Wag-
ner, 2017; Xiao et al., 2018), and it has raised great concerns especially when they are deployed in
the safety-critical applications such as autonomous driving and facial recognition.
To defend against such attacks, several empirical defenses have been proposed (Papernot et al.,
2016b; Buckman et al., 2018; Madry et al., 2018); however, many of them have been attacked again
by strong adaptive attackers (Athalye et al., 2018; Tramer et al., 2020). On the other hand, the
certified defenses (Wong & Kolter, 2018; Cohen et al., 2019) have been proposed to provide certi-
fied robustness guarantees for given ML models, so that no additional attack can break the model
under certain conditions. For instance, randomized smoothing has been proposed as an effective de-
fense providing certified robustness (Lecuyer et al., 2019; Li et al., 2019; Cohen et al., 2019; Yang
et al., 2020). Compared with other certified robustness approaches such as linear bound propaga-
tion (Weng et al., 2018; Mirman et al., 2018) and interval bound propagation (Gowal et al., 2019),
randomized smoothing provides a way to smooth a given DNN efficiently and does not depend on
the neural network architecture.
However, existing defenses mainly focus on the robustness of a single ML model, and it is unclear
whether an ensemble ML model could provide additional robustness. In this work, we aim to char-
1
Under review as a conference paper at ICLR 2021
acterize the conditions for a robust ensemble and answer the question from both theoretical and
empirical perspectives. In particular, we analyze the standard Weighted Ensemble (WE) and Max-
Margin Ensemble (MME) protocols, and prove the necessary and sufficient conditions for robust
ensemble models under mild model-smoothness assumptions. Under these conditions, we can see
that an ensemble model would be more robust than each single base model. The intuitive illustration
of their certified robust radius is in Fig 1. Our analysis shows that diversified gradient and large
confidence margins of base models would lead to higher certified robustness for ensemble models.
Inspired by our analysis, we propose Diversity-Regularized
Training, a lightweight regularization-based ensemble train-
ing approach. We derive certified robustness for both WE
and MME trained with DRT, and realize model-smoothness
assumption via randomized smoothing. We analyze differ-
ent smoothing protocols and prove that Ensemble Before
Smoothing provides higher certified robustness. We further
prove that when the adversarial transferability among base
models is high, MME is more robust than WE.
Figure 1 : illustration of a robust ensemble.
We evaluate DRT on a wide range of datasets including MNIST, CIFAR-10, and ImageNet. Exten-
sive experiments show that DRT can achieve higher certified robustness compared with the state-
of-the-art baselines with similar training cost as training a single model. Furthermore, when we
combine DRT with existing robust models as the base models, DRT can achieve the highest certified
robustness to our best knowledge.
We summarize our main ContribUtions as follows: 1) We provide the necessary and sufficient Con-
ditions for robust ensemble models including Weighted Ensemble (WE) and Max-Margin Ensem-
ble (MME) under the model-smoothness assumptions. We prove that an ensemble model is more
robust than a single base model under the model-smoothness assumption. Our analysis shows that
diversified gradients and large confidence margins of base models are the keys to robust ensembles.
2) Based on our analysis, we propose DRT, a lightweight regularization-based training approach,
containing both Gradient Diversity Loss and Confidence Margin Loss. 3) We derive certified robust-
ness for ensemble models trained with DRT. The analysis of certified robustness further reveals the
importance of DRT. Under mild conditions, we further prove that when the adversarial transferabil-
ity among base models is high MME is more robust than WE. 4) We conduct extensive experiments
to evaluate the effectiveness of DRT on various datasets, which show that DRT can achieve the best
certified robustness with similar training time as a single ML model.
Related work. DNNs are known vulnerable to adversarial examples (Szegedy et al., 2013). To
defend against such attacks, several empirical defenses have been proposed (Papernot et al., 2016b;
Madry et al., 2018). For ensemble models, existing work mainly focuses on empirical robust-
ness (Pang et al., 2019; Li et al., 2020; Srisakaokul et al., 2018) where the robustness is measured
by accuracy under existing attacks and no certifiable robustness guarantee could be provided or en-
hanced; or certify the robustness for a vanilla weighted ensemble (Zhang et al., 2019; Liu et al.,
2020) using either LP-based (Zhang et al., 2018) verification or randomized smoothing but without
diversity enforcement. In this paper, we aim to prove that the gradient diversity and base model
margin are two key factors for certified ensemble robustness and based on these key factors, we
propose a training approach to enhance the certified robustness of model ensemble.
Randomized smoothing (Cohen et al., 2019) has been proposed to provide certified robustness for
a single ML model. It achieved the state-of-the-art certified robustness on large ImageNet and
CIFAR-10 dataset under L2 norm. Several approaches have further improved it by: (1) choosing
different smoothing distributions for different Lp norms (Dvijotham et al., 2019; Zhang et al., 2020;
Yang et al., 2020), and (2) training more robust smoothed classifiers, using data augmentation (Co-
hen et al., 2019), unlabeled data (Carmon et al., 2019), adversarial training (Salman et al., 2019),
regularization (Li et al., 2019; Zhai et al., 2019), and denoising (Salman et al., 2020). However,
within our knowledge, there is no work studying how to customize randomized smoothing for en-
semble models. In this paper, we compare and select a good randomized smoothing strategy to
improve the certified robustness of the ensemble.
In this paper, we mainly focus on the certified robustness under L2 norm. Though randomized
smoothing suffers from difficulties when it comes to L∞ norm (Yang et al., 2020; Kumar et al.,
2
Under review as a conference paper at ICLR 2021
2020), the analysis of certified robustness and the training approach DRT can be further extended to
other Lp norms.
2 DIVERSITY-REGULARIZED TRAINING
In this section, we will first provide the robustness conditions for the standard Weighted Ensemble
and Max-Margin Ensemble. Using the robustness condition, we can compare the certified robust-
ness of the ensemble models and a single base model. The comparison shows that under model-
smoothness assumptions, the ensemble models are more robust in terms of their certified robustness.
Motivated by the key factors in the robustness conditions, we then propose Diversity-Regularized
Training.
Notations. Throughout the paper, we consider the classification task with C classes. We first
define the classification scoring function f : Rd 7→ ∆C, which maps the input to a confidence
vector, and f (x)i represents the confidence for the ith class. We mainly focus on the confidence
after normalization, i.e., f(x) ∈ ∆C = {p ∈ RC≥0 : kpk1 = 1} is in the probability simplex. To
characterize the confidence margin between two classes we define fy1/y2 (x) := f (x)y1 - f (x)y2.
The corresponding prediction F : Rd 7→ [C] is defined by F(x) := arg maxi∈[C] f(x)i. We are
also interested in the runner-up prediction F(2)(x) := argmaXi∈[c]j=F®)f (x)i.
In this paper, we mainly consider the model robustness against the L2-bounded perturbations.
Definition 1 (r-Robustness). For a prediction function F : Rd 7→ [C] and input x0, if any instance
x ∈ {x0 + δ : kδk2 ≤ r} satisfies F(x) = F(x0), we say model F is r-robust (at point x0).
We map existing certified robustness (Cohen et al., 2019) to r-Robustness in Appendix B.1.
2.1	Robustness Conditions for Ensemble Models
An ensemble model contains N base models {fi}iN=1, where Fi and Fi(2) are their top and runner-up
predictions respectively. The ensemble prediction is denoted by M : Rd 7→ [C], which is computed
based on outputs of base models following certain ensemble protocols. In this paper, we consider
both Weighted Ensemble (WE) and Maximum Margin Ensemble (MME).
Definition 2 (Weighted Ensemble (WE)). Given N base models {fi}iN=1, and the weight vector
{wi}iN=1 ∈ R+N, the Weighted Ensemble is constructed as MWE: Rd 7→ [C] such that for any input
x0:
N
MWE(x0) := arg max	wjfj(x0)i.	(1)
i∈[C] j=1
Definition 3 (Max-Margin Ensemble (MME)). Given N base models {fi}iN=1, for input x0, the
Max-Margin Ensemble model MMME : Rd 7→ [C] is defined by
MMME(x0) := Fc(x0)
where
arg max
i∈[N]
fi(x0)Fi(x0) - fi(x0)F(2)(x0)
(2)
c
WE sums up the weighted confidence scores of base models {fi}iN=1 with weight vector {wi}iN=1,
and predicts the class with the highest value. WE is commonly-used (Zhang et al., 2019; Liu et al.,
2020). Max-Margin Ensemble chooses the base model with the largest confidence margin between
the top and the runner-up classes, which is a direct extension from max-margin training (Huang
et al., 2008).
2.1.1	General Robustness Conditions
For WE, since it predicts the class with the highest aggregated confidence, we can easily observe its
sufficient and necessary conditions for the certified robustness.
Proposition 1 (Robustness Condition for WE). Consider an input x0 ∈ Rd with ground-truth label
y0 ∈ [C], and a Weighted Ensemble model MWE constructed by base models {fi}iN=1 with weights
{wi}iN=1. Suppose MWE(x0) = y0. Then, the ensemble MWE is r-robust at point x0 if and only if
for any x ∈ {x0 + δ : kδk2 ≤ r}, minyi∈[C] PjN=1 wjfjy0/yi(x) ≥ 0.
3
Under review as a conference paper at ICLR 2021
For MME, however, the model prediction is decided by the base model with the largest confidence
margin. This “maximum” is a discrete operator and poses challenges especially in the multi-class
setting. We cannot assert that the model predicts the true label by simply looking at the margins
between only the true label and other labels unless carefully filtering out possible violated cases. In
the following theorem, through careful analysis of the layout of confidence scores (e.g. enumerating
the cases where y0 is the top class, runner-up class, or one of other classes, see details in Lemmas B.1
and B.2), we present a succinct but sufficient and necessary condition for MME robustness.
Theorem 1 (Robustness Condition for MME). Consider an input x0 ∈ Rd with ground-truth label
y0 ∈ [C]. Let MMME be an MME defined over base models {fi}iN=1. Suppose: (1) MMME(x0) =
y0; (2) for any x ∈ {x0 + δ : kδk2 ≤ r}, given any base model i ∈ [N], either Fi (x) = y0
(2)
or Fi (x) = y0. Then, the ensemble MMME is r-robust at point x0 if and only if for any x ∈
{x0 +δ : kδk2 ≤ r},
max min	fiy0/yi (x) ≥ max min	fiyi/y0 (x).	(3)
i∈[N] yi∈[5'∙yi=yo	一 i∈[N] y0∈[C]"i=yo
In above theorem, the yi ’s and yi0 ’s are associated with each base model fi and are respectively
minimized among all the C classes except class y0 . We defer the proof to Appendix B.2. This
theorem along with the intermediate lemmas in the proof serves as the foundation for our subsequent
analysis.
2.1.2	Diversified Gradients and Large Confidence Margin Conditions
The conditions in Proposition 1 and Theorem 1 are rather general and involve x ∈ {x0 + δ :
kδ k2 ≤ r}, which is challenging to verify for neural networks due to its non-convexity. In this
section, we adapt the above conditions for DNNs based on confidence scores and gradient of base
models at input x0, showing the diversified gradients and large confidence margin are the sufficient
and necessary conditions for ensemble robustness.
Definition 4 (β-Smoothness). A differentiable function f : Rd 7→ RC is β-smooth, if for any
x, y ∈ Rd and any output dimension j ∈ [C], Ef(Xj-ryf (yjk2 ≤ β.
The definition of β-smoothness is inherited from optimization theory literature, and is equivalent to
the curvature bound in certified robustness literature (Singla & Feizi, 2020). Note that smaller β
indicates smoother models, and when β = 0 the model is linear.
For Weighted Ensemble, we have the following robustness conditions.
Theorem 2	(Gradient and Confidence Margin Conditions for WE Robustness). Given input x0 ∈
Rd with ground-truth label y0 ∈ [C], and MWE as a WE defined over base models {fi }iN=1 with
weights {wi}iN=1. MWE(x0) = y0. All base models fi ’s are β-smooth.
•	(Sufficient Condition) The MWE is r-robust at point x0 if for any yi 6= y0,
N	NN
Il X Wj VxfjOTy (XO)IL ≤ r X Wj fy0∕yi (XO) - βr X Wj,	⑷
•	(Necessary Condition) If MWE is r-robust at point x0, for any yi 6= y0,
N	NN
IIX WjVxfy0∕yi(xo)∣∣2 ≤ r X WjfT0∕yi (xo)+βr X wj.	(5)
The proof directly follows from our general robustness conditions and Taylor expansion at x0 .
For Max-Margin Ensemble with two base models, we derive the following robustness conditions.
Theorem 3	(Gradient and Confidence Margin Conditions for MME Robustness). Given input x0 ∈
Rd with ground-truth label y0 ∈ [C], and MMME as an MME defined over base models {f1, f2}.
MMME (x0) = y0. Both f1 and f2 are β-smooth.
•	(Sufficient Condition) The MMME is r-robust at point x0 if for any y1, y2 ∈ [C] such that
y1 6= y0 and y2 6= y0,
IlVxfy0∕y1(xo) + VxfT0∕y2(x0)k2 ≤ r(fT0∕y1(xo)+ fT0∕y2(XO))- 2βr.	(6)
4
Under review as a conference paper at ICLR 2021
•	(Necessary Condition) Suppose X ∈ {xo + δ : ∣∣δ∣∣2 ≤ r}, and for i ∈ {1, 2} either
Fi(x) = y0 or Fi(2) (x) = y0. If MMME is r-robust at point x0, for any y1, y2 ∈ [C] such
that y1 6= y0 and y2 6= y0,
IIVxfy0/yi (χo) + Vxfyo/y2 (χ0)k2 ≤ 1(fyo/yi(xo)+ My(xo))+ 2βr. (7)
The proof combines the proof procedure of Theorem 1 with Taylor expansion at x0 . We remark that
for MME, it is challenging to extend the theorem to the case with n > 2 base models. The reason
is that the “maximum” operator in MME poses difficulties for expressing the robust condition in
succinct form of continuous function. Therefore, Taylor expansion is unable to apply. However, the
general tendency should be the same.
We also derive the robustness conditions for a single model for comparison in Appendix B.3.
Comparison of ensemble and single-model robustness. The preceding theorems enable the anal-
ysis on comparing the certified robustness for an ensemble and a single ML model.
Corollary 1 (Comparison of Ensemble and Single-Model Robustness). Given an input x0 ∈ Rd
with ground-truth label y0 ∈ [C]. Suppose we have two β-smooth base models {f1, f2}, which are
both r-robust at point x0. For any ∆ ∈ [0, 1):
•	(Weighted Ensemble) Define Weighted Ensemble MWE by base models {f1, f2} with weights
{w1, w2}.	Suppose MWE(x0) = y0.	If for any label yi 6= y0, the base models’
smoothness β ≤ ∆ ∙ min{fy0/yi(xo),fy0/yi(x0)}∕(c2r2), and the gradient cosine similarity
CoshVχfy0∕yi (xo), Vχfy0∕yi (xo)i ≤ cos θ, then the MWE is at least R-robust at Xo with
R = r ∙ ； - . (1 — Cwe (1 — Cos θ))-1/2 , where	(8)
2wι w2fy0∕yi (XO) fy0∕yi (XO)	-△	-1/2
CWE = "1彗0 (Wifyo∕yi(χo)+W2fyo∕yi(XO))2, C = max{8 (I- CWE(I-Cos θ))	, 1}.
•	(Max-Margin Ensemble) Define Max-Margin Ensemble MMME by base models {f1 , f2}. Sup-
pose MMME(xo) = yo. If for any label y1 6= yo and y2 6= yo, the base models’
smoothness β ≤ ∆ ∙ min{fyo/y1 (xo),fyo/y2(xo)}∕(c2r2), and the gradient cosine similarity
CoshVxfy0∕y1 (xo), Vχfy0∕y2 (xo)i ≤ cos θ, then the MMME is at least R-robust at xo with
R = r ∙ 1 + ' (1 — CMME(I — cosθ))-1∕2 ,where	(9)
2fy0∕y1 (XO) fy0∕y2 (XO)	ι-△	-1/2
CMME = y1,y2m1in2=yο f7y‰)+72y07y‰)F, C = max{ E (I- CMME(I-Cos θ))	, 1}.
The above corollary reveals the connection between an ensemble and single-model robustness. As
We can see, When cos θ < 1 - C(4^产(C is either CWE or Cmme), R > r. When the base
models are smooth enough (β → 0+ so ∆ → 0+), in Equations (8) and (9), the RHS → 1-.
As long as the cosine similarity of base models’ gradients are not close to 1, this condition can
be easily satisfied, i.e., the ensemble models achieve higher certified robustness than base models.
Furthermore, the diversity of gradients measured by cosine similarity is important for improving
ensemble robustness. We defer the proof to Appendix B.4. Next, we discuss the implications of our
theoretical analysis.
Key factors for the certified robustness of an ensemble. We observe that smaller magnitude of
joint gradients (e.g. k Pj=I Wj Vχf；0/yi (xo) k 2 (Theorem 2) or ∣∣Vχfy0/y 1 (xo)+Vχfy0/y2 (xo) k2
(Theorem 3)) indicates smaller LHS in Equations (4) to (7). Since these robustness condition has
the form LHS ≤ RHS, it implies that the robustness condition is easier to be satisfied for current
radius r, i.e., the certified robust radius r could be improved. Therefore, smaller magnitude of joint
gradients leads to higher certified ensemble robustness.
Inspired from loW of cosines:	for any tWo vectors a, b,	ka + bk2	=
1/2
kak22 + kbk22 + 2kak2kbk2 Cosha, bi 1/2, the smaller magnitude of joint gradients can be
achieved by smaller gradient magnitude of base models or larger diversity (in terms of smaller
5
Under review as a conference paper at ICLR 2021
cosine similarity) between the gradient of base models. Therefore, constraining the magnitude of
joint gradient is equivalent to improving gradient diversity and reducing base models’ gradient
magnitude, and they both contribute to improved ensemble robustness.
We can also observe that large confidence margins, such as PjN=1 wjfjy0/yi (x0) (Theorem 2) and
f1y0/y1 (x0) + f2y0/y2(x0) (Theorem 3), directly lead to larger RHS in Equations (4) to (7). It again
implies that the robustness condition becomes easier to be satisfied and larger robust radius r can be
achieved. Thus, increasing confidence margins can lead to higher ensemble robustness.
Comparison between ensemble and single-model robustness. As the discussion following Corol-
lary 1 reveals, when the base models are smooth enough, the ensemble model is more robust than the
base models. Moreover, we prove that certified robustness of ensembles is positively correlated with
the base model (gradient) diversity, which is aligned with existing empirical observations (Tramer
et al., 2017; Pang et al., 2019).
2.2 DIVERSITY-REGULARIZED TRAINING
Inspired by the above key factors for the certified ensemble robustness, we propose the Diversity-
Regularized Training. In particular, let x0 be a training sample, DRT contains the following two
regularization terms in the objective function to minimize:
•	Gradient Diversity Loss (GD Loss):
LGD(xo)ij = IlVxfy0/yi2)(X0)+ Vxf7/yj2) (xo)∣∣2.	(10)
•	Confidence Margin Loss (CM Loss):
LCM(x0)ij =fiyi(2)/y0(x0)+fjyj(2)/y0(x0).	(11)
In Equations (10) and (11), y0 is the ground-truth label of x0, and yi(2) (or yj(2)) is the runner-up
class of base model Fi (or Fj). Intuitively, for each model pair (i, j) where i, j ∈ [N] and i 6= j,
the GD Loss encourages the joint gradient, i.e., gradient vector sum between model i and j, to be
small. Note that the gradient computed here is actually the gradient difference between different
labels. As our theorems reveal, it is the gradient difference between different labels instead of pure
gradient itself that matters, which improves previous understanding of gradient diversity (Pang et al.,
2019; Demontis et al., 2019). The GD Loss encourages both large gradient diversity and small base
models’ gradient magnitude in a naturally balanced way, and encodes the interplay between gradient
magnitude and direction diversity. Compared with GD Loss, solely regularizing the base models’
gradient would hurt the model’s benign accuracy, and solely regularizing gradient diversity is hard
to realize due to the boundedness of cosine similarity.
The CM Loss encourages the large margin between the true and runner-up classes for base models.
Both regularization terms are directly motivated by our analysis, and the detailed implementation
process can be found in Section 4.
3	Robustness for S mo othed ML Ensembles
To compute the certified robustness for different ensemble models based on Theorems 2 and 3,
we need to ensure the model smoothness which is challenging. Thus, in this section, we apply an
adapted randomized model smoothing to compute certified robustness for general ensembles based
on our conditions. We focus on Ensemble Before Smoothing (EBS) strategy: first construct the
ensemble M from base models, then smooth M’s prediction. M could be either MWE or MMME.
We also consider another strategy as smoothing base models first then ensemble. The analysis of
these two strategies which proves EBS is more robust is deferred to Appendix C.
3.1	Certified Robustness of Ensembles via Randomized Smoothing
To derive the certified robustness of both MME and WE, we first define the statistical robustness and
confidence for the single model and ensemble models.
Definition 5 ((, p)-Statistical Robust). Given a random variable and model F : Rd 7→ [C], at
point x0 with ground truth label y0, we call F is (, p)-statistical robust if Pr(F (x0+) = y0) ≥ p.
6
Under review as a conference paper at ICLR 2021
Note that based on Theorem B.1, When E 〜N(0, σ2Id), if F is (e, p)-statistical robust at point xo,
the smoothed model GF over F is (σΦ-1(p))-robust at point x0.
Definition 6 ((E, λ, p)-WE Confident). Let MWE be Weighted Ensemble defined over base models
{fi}iN=1 With Weights {wi}iN=1. Ifat point x0 With ground-truth y0 and random variable E, We have
Pr max Xwifi(x0 + )yj ≤ λXwi (1 - fi(x0 + )y0) = 1 -p, (12)
We call Weighted Ensemble MWE (E, λ, p)-WE confident at point x0.
Definition 7 ((E, λ, p)-MME Confident). Let MMME be a Max-Margin Ensemble over {fi}iN=1. If
at point x0 With ground-truth y0 and random variable E, We have
Pr	max	fi(x0 + )yj ≤ λ(1 - fi(x0 + )y0)
、[N] Iyj ∈[CM=y0	j	))
We call Max-Margin Ensemble MMME (E, λ, p)-MME confident at point x0.
1 - p,
(13)
Note that the confidence of every single model lies in the probability simplex, and λ reflects the
confidence portion that a Wrong prediction class can take beyond the true class (1 - fi (x0 + E)).
NoW We are ready to present the certified robustness for different ensemble models.
Theorem 4 (Certified Robustness for WE). Let E be a random variable supported on Rd. Let MWE
be a Weighted Ensemble defined over {fi}iN=1 with weights {wi}iN=1. The MWE is (E, λ1,p)-WE
confident. Let x0 ∈ Rd be the input with ground-truth label y0 ∈ [C]. Assume {fi(x0 + E)y0 }iN=1,
the confidence scores across base models for label y0, are i.i.d. and follow symmetric distribution
with mean μ and variance s2, where μ >(1 + λ-1)-1. We have
Pr(MWE(χ0 + E)= yO) ≥ 1 - P - j! rτ∣ ∙   -----------2 ∙	(14)
e	kwk1	2 (μ -(1 + A-1)-)
Theorem 5 (Certified Robustness for MME). Let E be a random variable supported on Rd. Let
MMME be a Max-Margin Ensemble defined over {fi}iN=1. The MMME is (E, λ2, p)-MME confident.
Let x0 ∈ Rd be the input with ground-truth label y0 ∈ [C]. Assume {fi(x0 + E)y0}iN=1, the
confidence scores across base models for label y0, are i.i.d. and follow symmetric distribution with
mean μ where μ > (1 + λ-1)-1. Define Sf = Var(mini∈[N] fi(xo + e)y0). We have
s2f
Pr(MMME(X0 + E) = yo) ≥ 1 - P---；--------------ɪ.	(15)
6	2 (μ -(I”-1)-1)
The condition μ > 1/(1 + λ-1) guarantees normal performance of a model, which is the sufficient
condition for the standard setup pA > pB as in (Cohen et al., 2019)). For comparison, We also derive
certified robustness for a single model in Proposition D.1. We defer the proofs to Appendix D.1.
Based on our theoretical analysis above, we draw additional implications on the connections between
the certified robustness and different losses. For Confidence Margin Loss, which aims at increasing
the confidence margin of ensembles by enlarging that of base models, from Theorems 4 and 5, we
can see that small λ (λ1 in WE and λ2 in MME) results in large Pr(M(x0 + E) = y0), i.e., large
certified robustness. For Standard Training Loss, which increases base models’ confidence of true
class, we can view it as increasing the average confidence score, μ, and its effectiveness is revealed
from Theorems 4 and 5.
3.2 Comparison for the Certified Robustness of Ensembles
The unified form of certified robustness above allows us to compare it for different ensembles.
Corollary 2 (Comparison of Certified Robustness). Let E be a random variable supported on Rd.
Over base models {fi}iN=1, let MMME be Max-Margin Ensemble, and MWE the Weighted Ensem-
ble with weights {wi}iN=1. Let x0 ∈ Rd be the input with ground-truth label y0 ∈ [C]. Assume
{fi(x0 + E)y0 }iN=1, the confidence scores across base models for label y0, are i.i.d. and follow
symmetric distribution with mean μ and variance s2, where μ > max{(1 + λ-1)-1, (1 + λ-1)-1}.
Define sf2 = Var(mini∈[N] fi (x0 + E)y0 ) and assume sf < s.
7
Under review as a conference paper at ICLR 2021
(16)
• When
• When
λ2<λ-1((ssf(μ —a”-1)-1)+1-"	- 1)，
for any weights {wi}iN=1, MWE has higher certified robustness than MMME.
λ2 >λ-1
for any weights {wi}iN=1, MMME has higher certified robustness than MWE.
(17)
Here, the certified robustness is given by Theorems 4 and 5.
Appendix D.2 entails the detailed proofs. Note that given λ1 is the weighted average and λ2 the
maximum over λ's of all base models, λι/λ2 reflects the adversarial transferability (PaPernot et al.,
2016a) among base models under the same p: If the transferability is high the confidence scores of
base models are similar (λ's are similar), and thus λι is large resulting in large λ1∕λ2. On the other
hand, when the transferability is low, the confidence scores are diverse (λ's are diverse), and thus
λι is small resulting in small λ1∕λ2. Based on our theoretical analysis We can see that MME is
more robust when the transferability is high; WE is more robust when the transferability is low. In
APPendix D.3, we also Prove that under certain distribution of fi(x0 + )y0, when N is sufficiently
large, the MME always more robust. APPendix D.4 entails the numerical evaluations.
4	Experimental Evaluation
In order to make a fair comParison with existing work (Cohen et al., 2019; Salman et al., 2019), we
evaluate our aPProach on different datasets: MNIST (LeCun et al., 2010), CIFAR-10 (Krizhevsky,
2012), and ImageNet (Deng et al., 2009). We show that by training MME/WE with DRT, our model
can achieve the state-of-the-art certified robustness.
4.1	Experimental Setup
Baselines: We mainly consider two state-of-the-art baselines for certified robustness: 1) Gaussian
smoothing (Cohen et al., 2019), which trains a smoothed classifier by aPPlying Gaussian augmenta-
tion. 2) SmoothAdv (Salman et al., 2019), which integrates adversarial training on the soft aPProxi-
mation. The comParison with more baselines can be found in APPendix E.4.
Model structures: For each base model in our ensemble, we follow the same configuration of the
baselines: LeNet (LeCun et al., 1998) for MNIST, ResNet-110 and ResNet-50 (He et al., 2016) for
CIFAR-10 and ImageNet datasets.
Training: We smooth the N base models ofan ensemble following the baselines (Cohen et al., 2019;
Salman et al., 2019). For each input xo with ground truth yo, we use xo + E with E 〜 N(0, σ2Id) as
training input for each base model. We call two base models fi , fj valid model pair at (xo , yo) if
both Fi(xo + E) and Fj (xo + E) predict yo. For every valid model pair, we apply GD Loss and CM
Loss with ρ1 and ρ2 as the weight parameters. The final training loss of an ensemble is as below:
L =	Lstd (xo + E, yo)i +ρ1	LGD (xo + E)ij +ρ2	LCM(xo+E)ij. (18)
i∈[N]	i,j∈[N],i6=j	i,j∈[N],i6=j
Fi(x0+)=y0	Fi(x0+)=y0
Fj (x0+)=y0	Fj (x0+)=y0
The standard training loss Lstd (xo + E, yo)i of each base model fi is either cross-entropy loss in
(Cohen et al., 2019; Yang et al., 2020), or adversarial training loss in (Salman et al., 2019). We leave
more training details in Appendix E.
Robustness Certification: During certification, we apply the MME orWE ensemble protocols over
the trained base models {fi}N=ι to obtain ensemble M, then smooth M with noise E 〜 N (0, σ2Id).
We report the standard certified accuracy under different L2 radius r as our evaluation metric (Co-
hen et al., 2019) (more implementation details in Appendix E).
8
Under review as a conference paper at ICLR 2021
Table 1: The certified accuracy under different radius r for MNIST dataset.
Radius r
I 0.00 I 0.25 I 0.50 I 0.75 ∣ 1.00 ∣ 1.25 ∣ 1.50 ∣ 1.75 ∣ 2.00 ∣ 2.25 ∣ 2.50
Gaussian (Cohen et al., 2019)	99.1	97.9	96.6	94.7	90.0	83.0	68.2	46.6	33.0	20.5	11.5
SmoothAdv (Salman et al., 2019)	99.1	98.4	97.0	96.3	93.0	87.7	80.2	66.3	43.2	34.3	24.0
MME (GaUssian)	99.2	98.4	96.8	94.9	90.5	84.3	69.8	48.8	34.7	23.4	12.7
DRT + MME (GaUssian)	99.5	98.6	97.5	95.5	92.6	86.8	75.2	55.8	44.8	38.0	27.0
MME (SmoothAdv)	99.2	98.2	97.3	96.4	93.2	88.1	80.6	67.9	44.8	35.0	25.2
DRT + MME (SmoothAdv)	99.2	98.4	97.6	96.7	93.1	88.5	83.2	68.9	48.2	39.2	33.5
WE (Gaussian)	99.2	98.4	96.9	94.9	90.6	84.5	70.4	49.0	35.2	23.7	12.9
DRT + WE (Gaussian)	99.5	98.6	97.4	95.6	92.6	86.9	75.4	55.8	44.6	38.2	27.2
WE (SmoothAdv)	99.1	98.2	97.4	96.4	93.4	88.2	81.1	67.9	44.7	35.2	24.9
DRT + WE (SmoothAdv)	99.1	98.4	97.6	96.7	93.4	88.5	83.3	69.6	48.3	39.4	33.5
Table 2: The certified accuracy under different radius r for CIFAR-10 dataset.
Radius r	0.00	0.25	0.50	0.75	1.00	1.25	1.50	1∙75	2.00
Gaussian (Cohen et al., 2019)	78.9	64.4	47.4	33.7	23.1	18.3	13.6	10.5	7.3
SmoothAdv (Salman et al., 2019)	68.9	61.0	54.4	45.7	34.8	28.5	21.9	18.2	15.7
MME (GaUssian)	80.8	68.2	53.4	38.4	29.0	19.6	15.6	11.6	8.8
DRT + MME (Gaussian)	81.4	70.4	57.8	43.8	31.6	26.2	22.4	18.8	16.6
MME (SmoothAdv)	71.4	64.5	57.6	48.4	36.2	29.8	23.9	19.5	16.2
DRT + MME (SmoothAdv)	72.6	67.2	60.2	50.4	39.4	35.8	30.4	24.0	20.1
WE (Gaussian)	80.8	68.4	53.6	38.4	29.2	19.7	15.9	11.8	8.9
DRT + WE (Gaussian)	81.5	70.4	57.9	44.0	31.7	26.2	22.5	19.1	16.8
WE (SmoothAdv)	71.8	64.6	57.8	48.5	36.2	29.6	24.2	19.6	16.0
DRT + WE (SmoothAdv)	72.6	67.0	60.2	50.5	39.5	36.0	30.3	24.1	20.3
4.2	Experimental Results
In our experiments, we consider ensemble models consisting of three base models on MNIST,
CIFAR-10, and ImageNet datasets. We observe that when training MME or WE (using different
base models) with DRT, they can achieve the state-of-the-art certified robustness.
The evaluation results on MNIST are shown in Table 1. We observe that the certified accuracy can
be improved slightly by applying the MME or WE compared with a single base model (aligned with
Corollary 1). After training with DRT, the improvements become significant and the DRT-trained
ensemble models can achieve the highest certified accuracy under every radius r . In particular,
DRT ensemble model can surpass the base model’s certified accuracy around 7% under large radius
r = 2.50. We further compare the certified robustness of WE and MME in Appendix D.4.
On CIFAR-10 the evaluation results are shown in Table 2. Similarly, we can see that the DRT-based
ensemble model can achieve the best certified robustness under different radius r (more experimen-
tal details are in Appendix E.2). Note that the DRT-based ensemble with Gaussian smoothed base
models can achieve comparable results to SmoothAdv with less training time (detailed efficiency
analysis is in Appendix E.2). We defer the results on ImageNet to Appendix E.3 and put all discus-
sions about hyper-parameters under different settings in Appendix E.
5	Conclusion
In this paper, we explore and characterize the robustness conditions for ensemble ML models the-
oretically, and propose DRT for training a robust ensemble in practice. Our analysis provides the
justification of the regularization-based training approach DRT, as well as why an ensemble model
could have higher robustness compared with a single model. Especially, we show that smaller mag-
nitude of joint gradients, and the large confidence margins are the key factors that contribute to high
certified robustness of an ensemble. We further compare the certified robustness of two types of en-
sembles: Weighted Ensemble and Max-Margin Ensemble under the randomized smoothing regime.
Extensive experiments show that the ensemble models trained with DRT can achieve higher certified
robustness than existing approaches.
9
Under review as a conference paper at ICLR 2021
References
Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of se-
curity: Circumventing defenses to adversarial examples. In International Conference on Machine
Learning,pp. 274-283, 2018.
Jacob Buckman, Aurko Roy, Colin Raffel, and Ian Goodfellow. Thermometer encoding: One hot
way to resist adversarial examples. In International Conference on Learning Representations,
2018.
Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In 2017
ieee symposium on security and privacy (sp), pp. 39-57. IEEE, 2017.
Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John C Duchi, and Percy S Liang. Unlabeled
data improves adversarial robustness. In Advances in Neural Information Processing Systems, pp.
11192-11203, 2019.
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified adversarial robustness via randomized
smoothing. In International Conference on Machine Learning, pp. 1310-1320, 2019.
Ambra Demontis, Marco Melis, Maura Pintor, Matthew Jagielski, Battista Biggio, Alina Oprea,
Cristina Nita-Rotaru, and Fabio Roli. Why do adversarial attacks transfer? explaining transfer-
ability of evasion and poisoning attacks. In 28th {USENIX} Security Symposium ({USENIX}
Security 19), pp. 321-338, 2019.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hi-
erarchical image database. In 2009 IEEE conference on computer vision and pattern recognition,
pp. 248-255. Ieee, 2009.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep
bidirectional transformers for language understanding. In NAACL-HLT (1), 2019.
Krishnamurthy Dj Dvijotham, Jamie Hayes, Borja Balle, Zico Kolter, Chongli Qin, Andras Gy-
orgy, Kai Xiao, Sven Gowal, and Pushmeet Kohli. A framework for robustness certification of
smoothed classifiers using f-divergences. In International Conference on Learning Representa-
tions, 2019.
Sven Gowal, Krishnamurthy Dj Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan
Uesato, Relja Arandjelovic, Timothy Mann, and Pushmeet Kohli. Scalable verified training for
provably robust image classification. In Proceedings of the IEEE International Conference on
Computer Vision, pp. 4842-4851, 2019.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
Kaizhu Huang, Haiqin Yang, Irwin King, and Michael R Lyu. Maxi-min margin machine: learning
large margin classifiers locally and globally. IEEE Transactions on Neural Networks, 19(2):260-
272, 2008.
Alex Krizhevsky. Learning multiple layers of features from tiny images. University of Toronto, 05
2012.
Aounon Kumar, Alexander Levine, Tom Goldstein, and Soheil Feizi. Curse of dimensionality on
randomized smoothing for certifiable robustness. In International Conference on Machine Learn-
ing, 2020.
Yann LeCun, Leon Bottou, YoshUa Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Yann LeCun, Corinna Cortes, and CJ Burges. Mnist handwritten digit database. ATT Labs [Online].
Available: http://yann.lecun.com/exdb/mnist, 2, 2010.
10
Under review as a conference paper at ICLR 2021
Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified
robustness to adversarial examples with differential privacy. In 2019 IEEE Symposium on Security
and Privacy (SP),pp. 656-672. IEEE, 2019.
Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Certified adversarial robustness with
additive noise. In Advances in Neural Information Processing Systems, pp. 9464-9474, 2019.
Yueqiao Li, Hang Su, Jun Zhu, and Jun Zhou. Boosting the robustness of capsule networks with
diverse ensemble. In 2020 10th International Conference on Information Science and Technology
(ICIST), pp. 247-251. IEEE, 2020.
Chizhou Liu, Yunzhen Feng, Ranran Wang, and Bin Dong. Enhancing certified robustness of
smoothed classifiers via weighted model ensembling. arXiv preprint arXiv:2005.09363, 2020.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. In International Conference on
Learning Representations, 2018.
Matthew Mirman, Timon Gehr, and Martin Vechev. Differentiable abstract interpretation for prov-
ably robust neural networks. In International Conference on Machine Learning, pp. 3578-3586,
2018.
Tianyu Pang, Kun Xu, Chao Du, Ning Chen, and Jun Zhu. Improving adversarial robustness via
promoting ensemble diversity. arXiv preprint arXiv:1901.08846, 2019.
Nicolas Papernot, Patrick McDaniel, and Ian Goodfellow. Transferability in machine learning: from
phenomena to black-box attacks using adversarial samples. arXiv preprint arXiv:1605.07277,
2016a.
Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami. Distillation as a
defense to adversarial perturbations against deep neural networks. In 2016 IEEE Symposium on
Security and Privacy (SP), pp. 582-597. IEEE, 2016b.
Hadi Salman, Jerry Li, Ilya Razenshteyn, Pengchuan Zhang, Huan Zhang, Sebastien Bubeck, and
Greg Yang. Provably robust deep learning via adversarially trained smoothed classifiers. In
Advances in Neural Information Processing Systems, pp. 11292-11303, 2019.
Hadi Salman, Mingjie Sun, Greg Yang, Ashish Kapoor, and J Zico Kolter. Black-box smoothing: A
provable defense for pretrained classifiers. arXiv preprint arXiv:2003.01908, 2020.
Saeed Saremi and Rupesh Srivastava. Provable robust classification via learned smoothed densities.
arXiv preprint arXiv:2005.04504, 2020.
Sahil Singla and Soheil Feizi. Second-order provable defenses against adversarial attacks. In Inter-
national Conference on Machine Learning, 2020.
Siwakorn Srisakaokul, Yuhao Zhang, Zexuan Zhong, Wei Yang, Tao Xie, and Bo Li. Muldef:
Multi-model-based defense against adversarial examples for neural networks. arXiv preprint
arXiv:1809.00065, 2018.
Yi Sun, Xiaogang Wang, and Xiaoou Tang. Deep learning face representation from predicting
10,000 classes. In Proceedings of the IEEE conference on computer vision and pattern recogni-
tion, pp. 1891-1898, 2014.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.
Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, and Lior Wolf. Deepface: Closing the gap to
human-level performance in face verification. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pp. 1701-1708, 2014.
Florian Tramer, Nicolas Papernot, Ian Goodfellow, Dan Boneh, and Patrick McDaniel. The space
of transferable adversarial examples. arXiv preprint arXiv:1704.03453, 2017.
11
Under review as a conference paper at ICLR 2021
Florian Tramer, Nicholas Carlini, Wieland Brendel, and Aleksander Madry. On adaptive attacks to
adversarial example defenses. arXiv preprint arXiv:2002.08347, 2020.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Eukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information
processing systems,pp. 5998-6008, 2017.
Lily Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel, Duane Boning,
and Inderjit Dhillon. Towards fast computation of certified robustness for relu networks. In
International Conference on Machine Learning, pp. 5276-5285, 2018.
Eric Wong and Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. In International Conference on Machine Learning, pp. 5286-5295, 2018.
Chaowei Xiao, Jun-Yan Zhu, Bo Li, Warren He, Mingyan Liu, and Dawn Song. Spatially trans-
formed adversarial examples. In International Conference on Learning Representations, 2018.
URL https://openreview.net/forum?id=HyydRMZC-.
Greg Yang, Tony Duan, Edward Hu, Hadi Salman, Ilya Razenshteyn, and Jerry Li. Randomized
smoothing of all shapes and sizes. In International Conference on Machine Learning, 2020.
Runtian Zhai, Chen Dan, Di He, Huan Zhang, Boqing Gong, Pradeep Ravikumar, Cho-Jui Hsieh,
and Liwei Wang. Macer: Attack-free and scalable robust training via maximizing certified radius.
In International Conference on Learning Representations, 2019.
Dinghuai Zhang, Mao Ye, Chengyue Gong, Zhanxing Zhu, and Qiang Liu. Black-box certifica-
tion with randomized smoothing: A functional optimization based framework. arXiv preprint
arXiv:2002.09169, 2020.
Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efficient neural net-
work robustness certification with general activation functions. In Advances in neural information
processing systems, pp. 4939-4948, 2018.
Huan Zhang, Minhao Cheng, and Cho-Jui Hsieh. Enhancing certifiable robustness via a deep model
ensemble. arXiv preprint arXiv:1910.14655, 2019.
12
Under review as a conference paper at ICLR 2021
Table 3: Main Theoretical Results.
I Weighted Ensemble Max-Margin Ensemble Single Model
General	General Condition	Proposition 1	Theorem 1	Fact B.1
Robustness (Section 2)	Gradient and Confidence Margin Condition	Theorem 2	Theorem 3	Proposition B.1
	Comparison	Corollary 1		
Robustness with Rand. Smooth.	Certified Robustness	Theorem 4	Theorem 5	Proposition D.1
(Section 3)	Comparison		Corollary 2	Appendix D.4
A Table of Theoretical Results
For a quick index for the theoretical results, we refer the readers to Table 3.
B Formal Definitions and Proofs of Robustness Conditions
In this appendix, we discuss the connection between r-robustness and certified robustness given by
randomized smoothing, and the detailed proofs of the robustness conditions in Section 2.
B.1	r-ROBUSTNESS AND RANDOMIZED SMOOTHING
In this subsection, we discuss the connection between r-robustness and the certified robustness given
by randomized smoothing (Cohen et al., 2019).
In randomized smoothing, each input’s prediction is given by the most probable prediction after
adding noise. Formally, let E 〜 N(0, σ2Id) be a Gaussian random variable, from model prediction
F, we can define the smoothed classifier GF : Rd 7→ [C] where GF (x) = arg maxj∈[C] gF (x)j:
gF (x)j :=	E 2	1[F(x+E) =j] = Pr 2 (F(x+E) =j).
SN (0,σ2Id)	SN (0,σ2Id)
Intuitively, the confidence score for each class is given by the probability of predicting that class
under noised inputs.
Theorem B.1 (Simplified; Certified Robustness via Randomized Smoothing; Cohen et al. (2019)).
At point xo, let E 〜N(0, σ2Id), a Smoothed model GF is r-robust, where
r := σΦ-1(gF (x0)GF(x0)),	(19)
and Φ-1 is the inverse function of Gaussian CDF.
We remark that a tighter certified radius is r0 := σ (φ-1(g* (x0)g 余(⑦。))一Φ-1 (g* ⑶。)〃¢)的。)) ≥
r, while for the ease of sampling, the Equation (19) is used more often in the literature. In Sec-
tions 3 and 4, we use Equation (19) for analysis and empirical evaluation, and these results can be
generalized to the tighter radius r0 easily.
B.2	General Robustness Conditions
Proposition 1 (Robustness Condition for WE). Consider an input x0 ∈ Rd with ground-truth label
y0 ∈ [C], and an ensemble model MWE constructed by base models {fi}iN=1 with weights {wi}iN=1.
Suppose MWE(x0) = y0. Then, the ensemble MWE is r-robust at point x0 if and only if for any
x ∈ {x0 +δ : kδk2 ≤ r},
N
min	Xwjfy0/yi(x) ≥ 0.	(20)
yi∈[CM=y0^ jJj	——
j=1
Proof of Proposition 1. According the the definition of r-robust, we know MWE is r-robust if and
only if for any point x := x0 + δ where kδk2 ≤ r, MWE(x0 + δ) = y0, which means that for any
13
Under review as a conference paper at ICLR 2021
other label yi 6= y0, the confidence score for label y0 is larger or equal than the confidence score for
label yi . It means that
NN
wjfj (x)y0 ≥	wjfj (x)yi
j=1	j=1
for any x ∈ {x0 + δ : kδ k2 ≤ r}. Since this should hold for any yi 6= y0, we have the necessary
and sufficient condition
N
min	X wjfy0/yi (x) ≥ 0.	(20)
yi∈[CM=y0 J jJj ――
j=1
□
Theorem 1 (Robustness Condition for MME). Consider an input x0 ∈ Rd with ground-truth label
y0 ∈ [C]. Let MMME be an MME defined over base models {fi}iN=1. Suppose: (1) MMME(x0) =
y0; (2) for any x ∈ {x0 + δ : kδk2 ≤ r}, given any base model i ∈ [N], either Fi (x) = y0
(2)
or Fi (x) = y0. Then, the ensemble MMME is r-robust at point x0 if and only if for any x ∈
{x0 +δ : kδk2 ≤ r},
max min	fiy0/yi (x) ≥ max min	fiyi/y0 (x).	(3)
i∈[N ] yi∈[C]%=yo i	i∈[N ] yi ∈[C]"=yo
The theorem states the sufficient and necessary robustness condition for MME. We divide the two
directions into the following two lemmas and prove them separately. We mainly use the alternative
form of Equation (3) as such in the following lemmas and their proofs:
max min	fiy0 /yi (x) + min min	fiy0/yi (x) ≥ 0.	(3)
i∈[N] yi∈[c]：yi=yo	i∈[N] y0∈C]∙∙yi=yo
Lemma B.1 (Sufficient Condition for MME). Let MMME be an MME defined over base models
{fi}iN=1. For any input x0 ∈ Rd, the Max-Margin Ensemble MMME predicts MMME (x0) = y0 if
max min	fiy0/yi (x0) + min min	fiy0/yi (x0) ≥ 0.	(3)
i∈[N] yi∈[c]m=yo i	i∈[N] y0∈C]∙∙yi=y° i
Proof of Lemma B.1. For brevity, for i ∈ [N], we denote yi := Fi(x0), yi0 := Fi(2) (x0) for each
base model’s top class and runner-up class at point x0 .
Suppose MMME (x0) 6= y0, then according to ensemble definition (see Definition 3), there exists
c ∈ [N], such that MMME(x0) = Fc(x0) = yc, and
∀i ∈ [N], i 6= c, fc(x0)yc/yc0 > fi(x0)yi/yi0.	(21)
Because yc 6= y0, we have fc(x0)y0 ≤ fc(x0)yc0 , so that fc(x0)yc/y0 ≥ fc(x0)yc/yc0 . Now con-
Sider any model f where i ∈ [N], we would like to show that there exists y* = yo, such that
fi(xo)yi∕y0 ≥ fi(xo)y0∕y*:
•	If yi = yo, let y* := yi ,trivially fi(xo)yi/yi = fi(xo)y"y* ；
•	If yi	=	yo, and y0 = yo, we let y*	:=	y0,	then	fi(xo)yi/y0	= fi(xo)yi/y*	≥	f (xo)y0/y*;
•	Ifyi	6=	y0, but yi0 = y0, we let y*	:=	yi,	then	fi(x0)yi∕yi0	= fi(x0)yi∕y0	≥	fi(x0)y0∕yi =
fi(xo)y0/y*.
Combine the above findings with Equation 21, we have:
∀i∈ [N], i 6=c, ∃yc* ∈ [C]andyc* 6= yo, ∃yi* ∈ [C]andyi* 6= yo, fc(xo)yc*/y0 >fi(xo)y0/yi*.
Therefore, its negation
∃i∈ [N], i 6= c, ∀yc* ∈ [C]andyc* 6= yo, ∀yi* ∈ [C]andyi* 6= yo, fc(xo)y0/yc* +fi(xo)y0/yi* ≥0
(22)
14
Under review as a conference paper at ICLR 2021
implies M(x0) = y0. Since Equation (22) holds for any y* and y*, the equation is equivalent to
∃i ∈ [N], i 6= c, min	fc (x0)y0/yc (x0) +	min	fi(x0)y0/yi0 (x0) ≥ 0.
yc∈[c]=yc=yo	y0 ∈[CY-y0=yo
The existence qualifier over i can be replaced by maximum:
min	fc (x0)y0/yc (x0) + max min	fi(x0)y0/yi0 (x0) ≥ 0.
yc∈[C]∙∙yc=yo	i∈[N] y0∈[CY-y0=yo
It is implied by
max min	fiy0/yi (x0) + min min	fiy0/yi0(x0) ≥ 0.	(3)
i∈[N] yi∈[cY-yi=yo	i∈[N] y0∈[cY-y0=yo
Thus, Equation (3) is a sufficient condition for MMME(X0) = yo.	□
Lemma B.2 (Necessary Condition for MME). For any input x0 ∈ Rd, if for any base model
i ∈ [N], either Fi(x0) = y0 or Fi(2) (x0) = y0, then Max-Margin Ensemble MMME predicting
MMME(x0) = y0 implies
max min	fiy0/yi (x0) + min min	fiy0/yi0 (x0) ≥ 0.	(3)
i∈[N] yi∈[C∙yi=yo	i∈[N] y0∈[C∖.y'0=yo
Proof of Lemma B.2. Similar as before, for brevity, for i ∈ [N], we denote yi := Fi(x0), yi0 :=
Fi(2)(x0) for each base model’s top class and runner-up class at point x0.
Suppose Equation (3) is not satisfied, it means that
∃c ∈ [N ], ∃y: ∈ [C ] and y=yo, ∀i ∈ [N ], ∃y* ∈ [C ] and yi = yo, ff/y° (xo) > f'/y (xo).
•	If yc = yo, then fCc/y0(xo) ≤ 0, which implies that fy"yi (xo) < 0, and hence Fi(XO)=
yo. Moreover, we know that fiyi/yi (xo) = fiyi/y0 (xo) ≥ fiyiy/y0 (xo) > fcy0/ycy (xo) ≥
fcy0/yc(Xo) = fcyc/yc(Xo) so M(Xo) 6= Fc(Xo) = yo.
•	If yc 6= yo, i.e., yc0 = yo, then fcyc/y0(Xo) ≥ fcycy/y0(Xo) > fiy0/y1y(Xo). If Fi(Xo) =
yo, then fiy0/yi (Xo) ≥ fiy0/yi (Xo) = fiyi/yi (Xo). Thus, fcyc/yc (Xo) = fcyc/y0 (Xo) >
fiyi/yi(Xo). As the result, M(Xo) = Fc(Xo) 6= yo.
For both cases, we show that MMME (Xo) 6= yo, i.e., Equation (3) is a necessary condition for
M(XO)= yo.	□
Proof of Theorem 1. Lemmas B.1 and B.2 are exactly the two directions (necessary and sufficient
condition) of MMME predicting label yo at point X. Therefore, if the condition (Equation (3)) holds
for any X ∈ {xo + δ : kδ∣∣2 ≤ r}, the ensemble MMME is r-robust at point x°; vice versa. □
For comparison, here we list the trivial robustness condition for single model.
Fact B.1 (Robustness Condition for Single Model). Consider an input Xo ∈ Rd with ground-truth
label yo ∈ [C]. Suppose a model F satisfies F(Xo) = yo. Then, the model F is r-robust at point Xo
if and only if for any X ∈ {Xo + δ : kδ k2 ≤ r},
min	fy0/yi (X) ≥ 0.
yi∈[C];yi=yo
The fact is apparent given that the model predicts the class with the highest confidence.
15
Under review as a conference paper at ICLR 2021
B.3	Gradient and Confidence Margin-Based Condition
We can concertize the preceding general robustness condition by gradients and confidence margins
of base models leveraging Taylor expansion.
Theorem 2 (Gradient and Confidence Margin Condition for WE Robustness). Given input x0 ∈ Rd
with ground-truth label y0 ∈ [C], and MWE as a WE defined over base models {fi}iN=1 with weights
{wi}iN=1. MWE(x0) = y0. All base model fi ’s are β-smooth.
•	(Sufficient Condition) MWE is r-robust at point x0 if for any yi 6= y0,
N	NN
∣∣X Wj Vxfjy0/"(X012 ≤ r χ Wj f”(xo)- βr X wj.	⑷
j=1	2	j=1	j=1
•	(Necessary Condition) If MWE is r-robust at point x0, then for any yi 6= y0,
N	NN
∣∣X wj Vxfj/o//i (χo)∣∣2 ≤ r X wj fjyo0yi (XO)+βr χ wj-.	⑸
j=1	j=1	j=1
Proof of Theorem 2. From Taylor expansion with Lagrange remainder and the β-smoothness as-
sumption on the base models, we have
NN
Xwjfjyo0yi(X0) - r∣∣XwjVxfjyo0yi(X0)
j=1	j=1
-1 r2 N
2 j=1
N
≤ min	X wjfyo/yi (X)
—x"∣x-xok2≤r J j j ' '
j=1
NN	N
≤ X wj- fjyo0yi (χo)- r∣∣X wj- Vxfjyo/yi (χo)∣∣ + 2 Tr X(2βwj),
j=1	j=1	2	j=1
(23)
where the term --r2 PN=ι(2βwj) and -r2 PN=∖(2βwj) are bounded from Lagrange remain-
der. From Proposition 1, the sufficient and necessary condition of WE’s r-robustness is
PjN=1 wjfjyo/yi (X) ≥ 0 for any yi ∈ [C] such that yi 6= y0, and any X = X0 + δ where kδk2 ≤ r.
PlUgging this term into Equation (23) we get the theorem.	□
Theorem 3 (Gradient and Confidence Margin Condition for MME Robustness). Given input X0 ∈
Rd with ground-truth label y0 ∈ [C], and MMME as an MME defined over base models {f1, f2}.
MMME(X0) = y0. Both f1 and f2 are β-smooth.
•	(Sufficient Condition) If for any y1, y2 ∈ [C] such that y1 6= y0 and y2 6= y0,
kVxfyo/y1(x0)+ Vχfyo0y2(χ0)k2 ≤ 1(fyo/y1(x0)+ fyo0y2(xo))- 2βr, ⑹
then MMME is r-robust at point X0.
•	(Necessary Condition) Suppose for any X ∈ {x0 + δ : ∣∣δ∣∣2 ≤ r}, for any i ∈ {1, 2},
(2)
either Fi(X) = y0 or Fi (X) = y0. If MMME is r-robust at point X0, then for any
y1, y2 ∈ [C] such that y1 6= y0 and y2 6= y0,
kVxfyo/y1(x0)+ Vxfyo/y2(χ0)k2 ≤ 1(fyo/y1(x0)+ fyo/y2(χ0)) + 2βr ⑺
r
Proof of Theorem 3. We prove the sufficient condition and necessary condition separately.
•	(Sufficient Condition)
From Lemma B.1, since there are only two base models, we can simplify the sufficient
condition for MMME(X) = y0 as
min
/i∈[c]9i=yo
fyo/yi(X)+/o ∈m-/y0(X) ≥0.
16
Under review as a conference paper at ICLR 2021
In other words, for any y1 6= y0 and y2 6= y0,
f1y0/y1(x)+f2y0/y2(x) ≥0.	(24)
With Taylor expansion and smoothness assumption, we have
min	f1y0/y1(x) +f2y0/y2(x)
xRx-x0k2≤r
≥fy0∕y1(xo)+ fy0∕y2(x0)-rkVχfy"y1(x0) + Vχ∕y/y2(x0)k2 - 1 ∙ 4βr2.
Plugging this into Equation (24) yields the sufficient condition. In the above equation,
the term 一 ɪ ∙ 4βr2 is bounded from Lagrange remainder. Here, the 4β term comes from
the fact that f1y0/y1 (x) + f2y0/y2(x) is (4β)-smooth since it is the sum of difference of
β-smooth function.
•	(Necessary Condition)
From Lemma B.2, similarly, the necessary condition for MMME(x) = y0 is simplified to:
for any y1 6= y0 and y2 6= y0,
f1y0/y1(x)+f2y0/y2(x) ≥0.	(24)
Again, from Taylor expansion, we have
min	f1y0/y1(x)+f2y0/y2(x)
x：kx-X0k2≤r
≤fy%1(x0)+ fyo/y2(X0)-rkVxfyo/yi(X0)+ Vxfyo/y2(x0)k2 + 1 ∙ 4βr2.
Plugging this into Equation (24) yields the necessary condition. In the above equation, the
term + 11 ∙ 4βr2 is bounded from Lagrange remainder. The 4β term appears because of the
same reason as before.
□
To compare the robustness of ensemble models and the single model, we show the corresponding
conditions for single-model robustness.
Proposition B.1 (Gradient and Confidence Margin Conditions for Single-Model Robustness).
Given input x0 ∈ Rd with ground-truth label y0 ∈ [C]. Model F(x0) = y0, and it is β -smooth.
•	(Sufficient Condition) If for any y1 ∈ [C] such that y1 6= y0,
kVxfyo/yi(xo)k2 ≤ 1 fy"y1(x0) — βr,	(25)
r
F is r-robust at point x0.
•	(Necessary Condition) If F is r-robust at point x0, for any y1 ∈ [C] such that y1 6= y0,
kVχfyo/yi (xo )k1 ≤ 1 fy"y1(x0) + βr.	(26)
r
Proof of Proposition B.1. This proposition is apparent given the following inequality from Taylor
expansion
fy0/yi (χo)-rkVχfyo/yi (x0)k2-βr2 ≤	min	fy0/yi (x) ≤ fy0/yi (xo)-rkVχfy0/yi (xo)k1+βr2
X：kx一X0k2≤r
and the necessary and sufficient robust condition in Fact B.1.	□
17
Under review as a conference paper at ICLR 2021
B.4	Compare Certified Robustness of Ensemble Model and S ingle Models
Corollary 1 (Comparison of Ensemble and Single-Model Robustness). Given an input x0 ∈ Rd
with ground-truth label y0 ∈ [C]. Suppose we have two β-smooth base models {f1, f2}, which are
both r-robust at point x0. For any ∆ ∈ [0, 1):
•	(Weighted Ensemble) Define Weighted Ensemble MWE with base models {f1 , f2}. Sup-
pose MWE (x0)	= y0.	If for any label yi 6= y0, the base models’ smooth-
ness β ≤ ∆ ∙ min{fy0∕yi(xo),fy0/yi(xo)}∕(c2r2), and the gradient cosine similarity
CoshVχfy0∕yi(xo), ηVχfy0∕yi(xo)i ≤ cos θ, then the MWE With weights {w1,w2} is at least
R-robust at point x0 with
R = r ∙ ； + ； (1 — Cwe(1 - Cos θ))-1/2, where	(8)
2w — mirι 2wι w2fy0∕yi (XO)fy0/"' (XO) C— rp …r1-∆ 门 「	-	-./ nʌʌ-1/2 1】
CWE = y黑=yo (Wifyo∕yi(χo)+W2fyo∕yi(XO))2, C = max{8 (I- CWE(I-Cos 知 ,1}.
•	(Max-Margin Ensemble) Define Max-Margin Ensemble MMME with the base models {f1, f2}.
Suppose MMME(x0) = y0. If for any label y1 6= y0 and y2 6= y0, the base models’
smoothness β ≤ ∆ ∙ min{fyo/y1 (xo),fyo/y2(xo)}∕(c2r2), and the gradient cosine similarity
CoshVxfy0∕y1 (xo), Vχfy0∕y2 (xo)i ≤ cos θ, then the MMME is at least R-robust at point xο
with
R = r ∙ 1 + ∆ (1 - CMME(I - cos θ))-1/2, where	(9)
2f	_ min	2fy0∕y1 (XO)fy0∕y2 (XO)	C _	1 1-∆ ∩	「	-	「Cie 小「1/2 I ɔ
CMME = myn： (fy0∕y1 (χ0)+fy0∕y2(xo))2,c = max{ 1+∆ (I - CMME(I -Cosθ))	,1}.
y1 ,y2 6=yO
Proof of Corollary 1. We first prove the theorem for Weighted Ensemble. For arbitrary yi 6= y0, we
have
llwiVxfyo/yi (χo) + w2Vxfyo/yi (χ0)k2
√w2kVxfyo/yi (χo)k2+w2kVxfyo/yi (χo)k2 + 2wiw2(vxfyo/yi(xo),fyo/yi(xo)i
(≤) 1 ∙ (1 + Ji) qw2fyo/yi(χ0)2 + w2fyo/yi(χ0)2 + 2wiw2fyo/yi(xo)fyo/yi(χo)cosθ
=1 ∙ (1 + δ ) y (wifyo/yi (xo) + W2 fyo/yi (xo)^ - 2(1 - cos θ)wιfy0/yi (x0)w2 f2yo/yi (xo)
(iii.)
≤ - ∙ (1 + c2) √1 - (1 - cos Θ)Cwe (WIfyO/yi (xo) + W2fy0∕yi (xo))
where (i.) follows from the necessary condition in Proposition B.1; (ii.) uses the condition on β;
and (iii.) replaces 2w1w2f1yO/yi(x0)f2yO/yi(x0) leveraging CWE. Now, we define
K := 1 + ∆ (1 - CWE(I - Cos θ)) /2 .
All we need to do is to prove that MWE is robust within radius Kr. To do so, from Equation (4), we
upper bound ||wiVxfyO/yi (xo) + w2^xfyO/yi (x0)k2 by K1r (wιfy"yi (xo) + w2fyO/yi (x。))-
18
Under review as a conference paper at ICLR 2021
βKr(w1 + w2):
kwiVxfy0/yi (χo) + w2Vxfy0/yi (χ0)k2
≤ r ∙ (1 + C) P1 - (1—cos θ)CwE (wιfy0∕yi (XO)+w fy0∕yi (XO D
≤ r(I+Δ)ρ1 — (1 — cos θ)CwE (wιfy0∕yi (XO)+w2fy0∕yi (XO))
=r ∙ I』「- △»	…(wιfy0∕yi(χο)+w2fy"yi(χο))
r 1+∆ (1 — (1 — cos θ)CWE)
=KKr(1 — ∆) (wιfy0/yi(XO)+ WfyM(xo))
≤KKr (wιfy0∕yi(xο)+ W2fy0∕yi(xο) — ∆min{fy0∕yi(xο),fy0∕yi(x0)}(w1 + W2)).
Notice that ∆min{fy0∕yi(xo), f20y (xo)} ≥ βc2r2 from β's condition, so
kw1Vxf1y0∕yi(XO) +w2Vxf2y0∕yi(XO)k2
≤K1r (wιfy0∕yi(xo) + W2fy0∕yi(xo) — βc2r2(wι + W2))
=~Fτ~ (wιfy0∕yi (XO)+w2fy0∕yi (XO)) — βKr(wι+w2 ∙
Kr	K2
≤-ɪ (wιfy0∕yi(xo) + W2fy0∕yi(xo)) — βKr(wι + W2).
Kr
From Equation (4), the theorem for Weighted Ensemble is proved.
Now we prove the theorem for Max-Margin Ensemble. Similarly, for any arbitrary y1 , y2 such that
y1 6= yO, y2 6= yO, we have
kVxf1y0∕y1(XO)+Vxf2y0∕y2(XO)k2
≤ r ∙ (1 + C) ρ1 — (1—cos θ) Cmme (fy0∕y1 (XO) + fy 0∕y2 (XO)).
Now we define
K0 := 1+△(I - CMME(I - cosθ)) ∕2.
Again, from β's condition We have ∆ min{fy0∕y1 (xo), fy0y (xo)} ≥ βc2r2 and
kVxf1y0∕y1(XO)+Vxf2y0∕y2(XO)k2
≤Kr (fy0∕yi (xo) + f" (XO))- 2βK0r.
From Equation (6), the ensemble is (K 0r)-robust at point XO, i.e., the theorem for Max-Margin
Ensemble is proved.	□
Discussion
Optimizing Weighted Ensemble. As We can observe from Corollary 1, We can adjust the Weights
{w1 , w2 } for Weighted Ensemble to change CWE and the certified robust radius (Equation (8)).
Then comes the problem of Which set of Weights can achieve the highest certified robust radius.
Since larger CWE results in higher radius, We need to choose
(w1OP T, w2OP T ) = arg max min
w1 ,w2 yi :yi 6=y0
2w1w2fWy" (XO)fy0∕yi (Xo)
(wιf!0y (xo) + w2f” (Xo))2
19
Under review as a conference paper at ICLR 2021
Since this quantity is scale-invariant, we can fix w1 and optimize over w2 to get the optimal weights.
In particular, if there are only two classes, we have a closed-form solution
(WOPT WOPT) = arg InaX	2w1w2My1 (XofyO/y1 (XO)
tw, twI arg miax
wι,w2 (Wfyo/yi(x0)+ W2/r/yi (X0))2
—{k ∙ /y0∕y1 (X0), k ∙ /y0∕y1 (X0): k ∈ R+},
and corresponding CWE achieves the maximum 1/2.
For a special case—average weighted ensemble, we get the corresponding certified robust radius by
setting w1 = w2 and plug the yielded
CWE
yimi=yο f0⅛x+⅛⅛⅛ 6 (0,1/2].
into Equation (8).
Comparison between ensemble and single-model robustness. We expand the discussion in Sec-
tion 2.1. The similar forms of R in the corollary allow us to discuss the Weighted Ensemble and
Max-Margin Ensemble together. Specifically, we let C be either CWE or CMME, then
R = r ∙ 1j-δ (1 - C(1 - cos θ))-1∕2.
Since when R > r, both ensembles have higher certified robustness than the base models, we solve
this condition for cos θ:
R>r
0 (1-∆) >1 - C(I - Cosθ)
4∆
O cos θ ≤ 1 - C(1 + ∆)2.
Notice that C ∈ (0, 1/2]. From this condition, we can easily observe that when the gradient cosine
similarity is smaller, it is more likely that the ensemble has higher certified robustness than the base
models. When the model is smooth enough, according to the condition on β , we can notice that ∆
would be close to zero. As a result, 1 - C(4^产 is close to 1. Thus, unless the gradient of base
models is (or close to) colinear, it always holds that the ensemble (either WE or MME) has higher
certified robustness than the base models.
20
Under review as a conference paper at ICLR 2021
C Analysis of Ensemble Smoothing Strategies
In Section 3 we mainly use the adapted randomized model smoothing strategy which is named
Ensemble Before Smoothing (EBS). We also consider Ensemble After Smoothing (Ensemble After
Smoothing). Through the following analysis, we will show Ensemble Before Smoothing is generally
better than Ensemble After Smoothing which justifies our choice of the strategy.
We formally define Ensemble Before Smoothing strategy as below:
Definition C.1 (Strategy: Ensemble Before Smoothing (EBS)). Let M be an ensemble model
over base models {fi}iN=1. Let be a random variable. The EBS ensemble GM : Rd 7→ [C] at input
x0 ∈ Rd is defined by:
GM(x0) = arg max Pr(M(x0 + ) = j).	(27)
j∈[C]
We define the Ensemble After Smoothing strategy accordingly:
Definition C.2 (Strategy: Ensemble After Smoothing (EAS)). Let M be an ensemble model over
base models {fi}iN=1. Let be a random variable. The EAS ensemble HM : Rd 7→ [C] at input
x0 ∈ Rd is defined as:
HM (x0) := GFc (x0) where c = argmaxgFi(x0)GF (x0).	(28)
i∈[N]	Fi
Here, c is the index of the smoothed base model selected.
Remark. In EBS, we first construct a model ensemble M based on base models using WE or MME
protocol, then apply randomized smoothing on top of the classifier. The classifier predicts the most
frequent class of M when the input follows distribution x0 + .
In EAS, we use to construct smoothed classifiers for base models respectively. Then, for given
input x0, the ensemble agrees on the base model which has the highest probability for its predicted
class.
C.1 Certified Robustness
In this subsection, we characterize the certified robustness when using both strategies.
C.1.1 Ensemble Before Smoothing
Proposition C.1 (Certified Robustness for Ensemble Before Smoothing). Let GM be an ensemble
constructed by EBS strategy. The random variable e 〜N(0,σ2Id). Then the ensemble GM is
r-robust at point x0 where
r := σΦ-1 gM (x0)GM(x0) .	(29)
Here, gM (x0)j = Pr(M(x0 + ) = j).
The proposition is a direct application of Theorem B.1.
C.1.2 Ensemble After Smoothing
Theorem C.1 (Certified robustness for Ensemble After Smoothing). Let HM be an ensemble con-
Structed by EAS strategy over base models {fi}N=ι. The random variable E 〜N(0, σ2Id). Let
y0 = HM (x0). For each i ∈ [N], define
ri :
if GFi (x0) = y0
if GFi (x0) 6= y0
Then the ensemble HM is r-robust at point x0 where
r := maxi∈[N] ri + mini∈[N] ri
(30)
2
21
Under review as a conference paper at ICLR 2021
Remark. The theorem appears to be a bit counter-intuitive — picking the best smoothed model in
terms of certified robustness cannot give strong certified robustness for the ensemble. As long as
the base models have different certified robust radius (i.e., ri ’s are different), the r, certified robust
radius for the ensemble, is strictly inferior to that of the best base model (i.e., max ri). Furthermore,
if there exists a base model with wrong prediction (i.e., ri ≤ 0), the certified robust radius r is
strictly smaller than half of the best base model.
Proofof Theorem C.1. Without loss of generality, We assume ri > r > •… >『n . Let the PertUr-
bation added to x0 has L2 length δ.
When δ ≤ rN, since Picking any model alWays gives the right Prediction, the ensemble is robust.
Whenrn < δ ≤ r1+rN, the highest robust radius with wrong prediction is δ -rn , and we can
still guarantee that model f1 has robust radius at least r1 - δ from the smoothness of function
X → gFι (X)G余(xo) (SaIman et al., 2019). Since ri - δ ≥ r1-rN ≥ δ -『n, the ensemble will
agree on f1 or other base model with correct prediction and still gives the right prediction.
When δ > r1+rN, suppose /n is a linear model and only predicts two labels (which achieves the
tight robust radius bound according to Cohen et al. (2019)), then fN can have robust radius δ - rN
for the wrong prediction. At the same time, for any other model fi which is linear and predicts
correctly, the robust radius is at most r — δ. Since r — δ < ri — δ < r1-rN < δ -『n, the ensemble
can probably give wrong prediction.
In summary, as we have shown, the certified robust radius can be at most r. For any radius δ > r,
there exist base models which lead the ensemble HM (xo+δe) to predict the label other than yo. □
C.2 Comparison of Two Strategies
In this subsection, we compare the two ensemble strategies when the ensembles are constructed
from two base models.
Corollary C.1 (Smoothing Strategy Comparison). Given MMME, a Max-Margin Ensemble con-
structedfrom base models {fa,fb}. Let e 〜N(0,σ2Id). Let GMMME be the EBS ensemble,
and HM	be the EAS ensemble. Suppose at point X0 with ground-truth label y0, GF (X0) =
GFb (X0) = y0, gFa (X0) > 0.5, gFb (X0) > 0.5.
Let δ be their probability difference for class y0, i.e, δ := |gF (X0)y0 - gF (X0)y0 |,. Let pmin be
the smaller probability for class y0 between them, i.e., pmin := min{gF (X0)y0 , gF (X0)y0 }. We
denote p to the probability of choosing the correct class when the base models disagree with each
other; denote pab to the probability of both base models agreeing on the correct class:
p := Pr (MMME(X0 + ) = y0 | Fa(X0 + ) 6= Fb(X0 + ) and (Fa(X0 + ) = y0 orFb(X0 + ) = y0)) ,
pab := Pr (Fa (X0 + ) = Fb (X0 + ) = y0 ) .
We have:
1.	If P > 1/2+ (2 + 4(Pmin - Pab)∕δ)-i,『g >『h.
2.	Ifp≤ 1/2, rH ≥rG.
Here, 『G is the certified robust radius of GM	computed from Equation (29); and 『H is the
certified robust radius of HM	computed from Equation (30).
Remark. Since P is the probability where the ensemble chooses the correct prediction between two
base model predictions, with Max-Margin Ensemble, we think P > 1/2 with non-trivial margin.
The quantity Pmin - Pab and δ both measure the base model’s diversity in terms of predicted label
distribution, and generally they should be close. As a result, 1/2 +(2 + 4(Pmin - Pab)∕δ)-i ≈
1/2 + 1/6 = 2/3, and case (1) should be much more likely to happen than case (2). Therefore, EBS
usually yields higher robustness guarantee. We remark that the similar tendency also holds with
multiple base models.
22
Under review as a conference paper at ICLR 2021
Proof of Corollary C.1. For convenience, define pa := gF (x0)y0 , pb := gF (x0)y0, where pa =
pb + δ and pmin = pb .
From Proposition C.1 and Theorem C.1, we have
IrG := 2 ∙ 2Φ-1 (Pr(MMME(X0 + E)= yo)) , rH := 2 (Φ-1(pa) + Φ-1(pb)).
Notice that Pr(MMME(x0 + ) = y0) = pab + p(pa +pb -2pab), we can rewrite rG as
rG = 2 ∙ 2Φ-1(pab + p(pa + Pb - 2pab)).
1.	When P > 1/2 +(2 + 4(pm® - Pab)∕δ)-1,
since
> 1 ,_______1_______ = 1 ,________δ_______ = Pa + Pb + δ - 2pab =	Pa - Pab
P 2	2 +	4(pmin-pab)	2	2δ + 4(Pb	- Pab)	2(Pa	+ Pb - 2Pab)	Pa	+ Pb -	2Pab,
δ
We have Pab + P(Pa + Pb - '2Pab) > Pa. Therefore, γg > σΦ-1(Pa). Whereas, th ≤ σ∕2 ∙
2Φ-1(Pa) = σΦ-1(Pa). So rG > rH.
2.	When P ≤ 1/2,
Pab + P(Pa + Pb - 2Pab) ≤ Pab + 1/2 ∙ (Pa + Pb - ?Pab) = (Pa + Pb)∕2.
Therefore, rG ≤ σΦ-1((Pa + Pb)/2). Notice that Φ-1 is convex in [1/2, +∞), so Φ-1(Pa) +
Φ-1(Pb) ≥ 2Φ-1((Pa + Pb)/2), i.e., rH ≥ rG.
□
23
Under review as a conference paper at ICLR 2021
D Proofs and Experiments of Robustness for Smoothed ML
Ensemble
In this appendix, we provide the detailed proofs and discussions for the results in Sections 3.1
and 3.2. Moreover, to present a more intuitive understanding, we show both numerical and realistic
experiments for the theorems.
D. 1 Certified Robustness via Randomized Smoothing
First, using the notion of (, p)-Statistical Robust (Definition 5), we prove the certified robustness
of the single model and ensembles under the i.i.d. assumption of the confidence scores. As noted
in Section 3.1 and Appendix B.1, when follows some distribution such as N (0, σ2Id), we can
translate the statistical robustness guarantee to r-robustness guarantee of the smoothed classifier.
The following lemma is frequently used in our following proofs:
Lemma D.1. Suppose the random variable X satisfies EX > 0, Var(X) < ∞ and for any x ∈ R+,
Pr(X ≥ EX + x) = Pr(X ≤ EX - x), then
Pr(X ≤ 0) ≤ 2Vw.
Proof of Lemma D.1. Apply Chebyshev’s inequality on random variable X and notice that X is
symmetric, then We can easily observe this lemma.	□
D.1.1 Certified Robustness for Single Model
As the start point, We first shoW a direct proposition stating the certified robustness guarantee of the
single model.
Definition D.1 ((, λ, p)-Single Confident). Given a classification model F. If at point x0 With
ground-truth label y0 and the random variable , We have
Pr max f(x0 + )yj ≤ λ(1 - f(x0 +)y0) = 1 -p,
e ∖yj ∈[CE=yo
We call F (, λ, p)-single confident at point x0.
Proposition D.1 (Certified Robustness for Single Model). Let be a random variable. Let F be
a classification model, which is (, λ3, p)-single confident. Let x0 ∈ Rd be the input with ground-
truth yo ∈ [C]. Suppose f (xo + w)y° follows symmetric distribution with mean μ and variance S,
where μ > (1 + λ-1)-1. We have
s2
Pr(F(x0 + e)= y0) ≥ 1 - P- 2(μ - (1 + λ-1)-i)2 .
Proof of Proposition D.1. We consider the distribution of quantity Y := f(x0 + )y0 - λ3 (1 -
f(x0 + )y0). Since the model F is (, λ3 , p)-single confident, With probability 1 -p, Y ≤ f(x0 +
e)yo - maxyj∈[c[yj=yo f (xo + ʤ. We note that since
EY =(1 + λ3)μ - λ3, Var(Y) = (1 + λ3)2s2,
from Lemma D.1,
s2
r(	≤ ) ≤ 2(μ -(1 + λ-1)-1 )2 .
Thus,
Pr(F (xo + ) = yo) = 1 - Pr(F (xo + ) 6= yo)
1 - Pr f(xo + )y0
max	f(xo + )yj < 0
yj E[c]：yj=yo	.
—
≥ 1 - p - Pr(Y ≤ 0)
s2
≥ 1 — P---------------；--—
—	2(μ - (1 + λ-1)-1 )2
□
24
Under review as a conference paper at ICLR 2021
D.1.2 Certified Robustness for Ensembles
Now we are ready to prove the certified robustness of the Weighted Ensemble and Max-Margin
Ensemble (Theorems 4 and 5).
In the following text, we first define statistical margins for both WE and MME, and point out their
connections to the notion of (, p)-Statistical Robust. Then, we reason about the expectation, vari-
ance, and tail bounds of the statistical margins. Finally, we derive the certified robustness from the
statistical margins.
Definition D.2 (X1 ; Statistical Margin for WE MWE). Let MWE be Weighted Ensemble defined
over base models {fi}iN=1 with weights {wi}iN=1. Suppose MWE is (, λ1, p)-WE-confident. We
define random variable Xi which is depended by random variable e:
N
XI(W) = (I + λI) X Wj fj (XO + W)yo - λ1 IIwI11.	(31)
j=1
Definition D.3 (X2 ; Statistical Margin for MME MMME). Let MMME be Max-Margin Ensem-
ble defined over base models {fi}iN=1. Suppose MMME is (W, λ2, p)-MME-confident. We define
random variable X? which is depended by random variable w:
X2(w):= (1 + λ2) ( max fi(xo + w)yo + min fi(xo + w)y0 ) — 2λ?.	(32)
i∈[N]	i∈[N]
We have the following observation:
Lemma D.2. For Weighted Ensemble,
一 ,. , . . 一 ， ，、
Pr (MWE(xo + W)= yo) ≥ 1 — P — Pr (XI(W) < 0).
For Max-Margin Ensemble,
Pr (MMME(xo + W)= yo) ≥ 1 — P — Pr (X2(W) < 0).
Proof of Lemma D.2. (1) For Weighted Ensemble, we define the random variable X1:
N
X1(W) :=	min	Xwjfjy0/yi(xo + W).
yi∈[C];yi=yo L
j=1
Since MWE is (W, λ1, P)-WE-confident, from Definition 6, with probability 1 — P, we have
N
X1 (W) ≥	wj (fj (xo + W)y0 — λ2(1 — fj (xo + W)y0 ))
j=1
N
= (1 + λ2)	wj fj (xo + W)y0 — λ1 IwI1 = X1 (W).
j=1
Therefore,
Pr(MWE(xo + W)= yo) = Pr(XI(W) ≥ 0) ≥ 1 — P — Pr(X2(w) < 0).
(2) For Max-Margin Ensemble, we define the random variable X2 :
X2 (W) := max	min	fiy0/yi (xo + W) + min min	fiy0/yi (xo + W).
i∈[N] yiE[c]：yi=yo	i∈N] yi∈[c]%=y0
Similarly, since MMME is (W, λ2, P)-MME-confident, from Definition 7, with probability 1 —P, we
have
X2(W) ≥ max (fi(xo + W)y0 — λ2(1 — fi(xo + W)y0)) + min (fi(xo + W)y0 — λ2(1 — fi(xo + W)y0))
i∈[N]	i∈[N]
=(1+λ2) (m0χ fi(χo+w)yo+mnfi(χo+w)y) 一 ?人?=x2©.
25
Under review as a conference paper at ICLR 2021
Moreover, from Lemma B.1, we know
Pr(M(xo + e) = yo) ≥ Pr(X2(∙) ≥ 0) ≥ 1 - P - Pr(X2(∙) < 0).
□
As the result, to quantify the statistical robustness of two types of ensembles, we can analyze the
distribution of statistical margins X1 and X2 .
Lemma D.3 (Expectation and variance of Xi and X2). Let Xi and X2 be defined by Definition D.2
and Definition D.3 respectively. Assume {fi (x0 + )y0 }iN=1 are i.i.d. and follow symmetric distri-
bution with mean μ and variance S. Define Sf = Var(mi□i∈[N] fi(xo + w)y0). We have
EXι(w)=(1 + λ1)kwk1μ - λ1kwk1, Var JXι(e) = (1 + λι)2s2∣∣w∣∣2,
EXz(w) =2(1 + λ2)μ — 2λ2,	VarXz(w) ≤ 4(1 + λ2)2sf.
Proof of Lemma D.3.
N
EXι(w) = (1 + λι) XEwjfj(xo + e)yo - λ1kwk1 = (1 + λ1)kwk1μ - λι∣∣wkι;
j=i
N
VarXi(a) = (1 + λ1)2 X w2Var(fj(xo + e)y0) = (1 + λ1)2s2∣w∣2.
j=i
According to the symmetric distribution property of {fi(x0 + )y0}iN=i, we have
EXz(∙) = E(1 + λ2) (mαχ fi(xo + )y0 + min fi(x0 + )y0 - 2λ2
= 2(1 + λ2)μ - 2λ2.
Also, due the symmetry, we have
Var min fi(xo + )y0 = Var max fi(xo + )y0	= sf2.
As a result,
VarX2(∙ ≤ (1 + λ2)2 ∙ 4sf.
□
From Lemma D.3, now with Lemma D.1, we are ready to derive the statistical robustness lower
bound for WE and MME.
Theorem 4 (Certified Robustness for WE). Let be a random variable supported on Rd. Let MWE
be a Weighted Ensemble defined over {fi}iN=i with weights {wi}iN=i. The MWE is (, λi,p)-WE
confident. Let xo ∈ Rd be the input with ground-truth label yo ∈ [C]. Assume {fi(xo + )y0}iN=i,
the confidence scores across base models for label yo, are i.i.d. and follow symmetric distribution
with mean μ and variance s2, where μ > (1 + λ-1)-i. We have
∣w∣2	s2
Pr(MWE(XO + W) =	yO)	≥ 1 - P -	2 ∙ -；----------T-2	.	(14)
-	kwk1 2 (μ -(1 +	λ-1)-1)2
Theorem 5 (Certified Robustness for MME). Let W be a random variable. Let MMME be a Max-
Margin Ensemble defined over {fi}iN=i. The MMME is (W, λ2,P)-MME confident. Let xO ∈ Rd
be the input with ground-truth label yO ∈ [C]. Assume {fi(xO + W)y0}iN=i, the confidence scores
across base models for label yo, are i.i.d. and follow symmetric distribution with mean μ where
μ > (1 + λ-1)-i. Define Sf = Var(mini∈[N] fi(xo + e)y0). We have
Pr(MMME(xo + W) = yo) ≥ 1 -P -
-
s2
sf
2 (μ - (1 + λ-1))
(15)
26
Under review as a conference paper at ICLR 2021
Proof of Theorems 4 and 5. Combining Lemmas D.1 to D.3, We get the theorem.	口
Remark. Theorems 4 and 5 provide two statistical robustness lower bounds for both types of ensem-
bles, Which is shoWn to be able to translate to certified robustness.
For the Weighted Ensemble, noticing that Xi is the weighted sum of several independent variables,
We can further apply McDiarmid’s Inequality to get another bound
Pr(MWE(x0 + ) = y0) ≥ 1 - p - exp
(_ 2 kwkɪ
Lkwk2
(μ - (1 + λ-i)
which is tighter than Equation (14) when kwk21 /kwk22 is large. For average weighted ensemble,
kwk21/kwk22 = N . Thus, when N is large, this bound is tighter.
Both theorems are applicable under the i.i.d. assumption of confidence scores. The another assump-
tion μ > max{(1 + λ-1)-i, (1 + λ-1)-1} insures that both ensembles have higher probability of
predicting the true class rather than other classes, i.e., the ensembles have non-trivial clean accuracy.
D.2 Comparison of Certified Robustness
We first show and prove an important lemma. Then, based on the lemma and Theorems 4 and 5, we
derive the comparison corollary.
Lemma D.4. For μ, λ1,λ2, C > 0, when max{λι∕(1 + λι), λ2∕(l + λ2)} < μ ≤ 1, and C < 1,
we have
μ - (λ2 1 + I)T
μ - (λι1 + I)T
λ1 < λ-i
λ2 <λ2
μ -
λ2	A
1 + λ2 )
+1-
(33)
< C Q
Proof of Lemma D.4.
μ 一 (% 1 + I)T < C
μ - (λ11 + I)T
^⇒
1
C
^⇒
λ2 1 + 1 λ-1 +1
> μ(1 - C)
λi∕λ2
C-1
λ21 + λ1∕λ2	λ21 +1
-μ(CT - I)
—
^⇒
<λ-1(C-1(λ⅛-μ + μ
1
μ - λ-1 + 1
λ1 <
λ2
¥ <
λ2
λ1 (1-μ + C-1
λ2
^⇒
^⇒
□
Now we can show and prove the comparison corollary.
Corollary 2 (Comparison of Certified Robustness). Let be a random variable supported on Rd.
Over base models {fi}iN=1, let MMME be Max-Margin Ensemble, and MWE the Weighted Ensem-
ble with weights {wi}iN=1. Let x0 ∈ Rd be the input with ground-truth label y0 ∈ [C]. Assume
{fi(x0 +)y0 }iN=1, the confidence scores across base models for label y0, are i.i.d, and follow sym-
metric distribution with mean μ and variance s2, where μ > max{(1 + λ-1)-1, (1 + λ-1)-1}.
Define sf2 = Var(mini∈[N] fi (x0 + )y0) and assume sf < s.
27
Under review as a conference paper at ICLR 2021
• When
¥ <
λ2
(1 + λ-1)	) + 1 - μ
(16)
for any weights {wi}iN=1, MWE has higher certified robustness than MMME.
• When
λ1 >λ-1((√NNSf (μ- (1 + λ-1)T) + 1 -μ!	- 1J
for any weights {wi}iN=1, MMME has higher certified robustness than MWE.
(17)
Here, the certified robustness is given by Theorems 4 and 5.
Proof of Corollary 2. (1) According to Lemma D.4, we have
λ1
λ2
< λ2-1
f (μ -(1 + λ-1) 1)
+1-
μ - (λ2 1 + I)T . sf
⇒-----；------ < -
μ - (λ1 + 1)- S
SkwJμ -(λ-1 + 1)-1	Sf
Vkwk2 μ — (λ-1 + 1)-1 s
—kwk2 ________s2_______
"wk2 ∙ 2 (μ-(1 + N)-1)2
s
2
f
(1+λ-1)-1)2
According to Theorems 4 and 5, we know the RHS in Equation (14) is larger than the RHS in
Equation (15), i.e., MWE has higher certified robustnesss than MMME.
(2)	According to Lemma D.4, we have
λ2 >λ-1
s
ASf
>---f
+ λ-1)	) + 1 - μ)	- 1
μ - (λ2 1 + I)T
μ - (λ1 1 + I)T
kwk2 μ -(λ-1 + 1)-1
Ilwk2 μ — (λ-1 + 1)T
-1
>Sf
s
kwk2
kwk1
s2
s2
sf
2 (μ —(1 + λ
2.
According to Theorems 4 and 5, we know the RHS in Equation (15) is larger than the RHS in
Equation (14), i.e., MMME has higher certified robustnesss than Mwe.	□
Remark. As we can observe in the proof, there is a gap between Equation (16) and Equation (17)
——When λ∖∕λ2 lies in between RHS ofEquation (16) and RHS OfEquation (17), it is undetermined
which ensemble protocol has higher robustness. Indeed, this uncertainty is caused by the adjustable
weights {wi }iN=1 of the Weighted Ensemble. If we only consider the average ensemble, then this
gap is closed:
λ1
λ2
MMME more robust
Z
MWE more robust
28
Under review as a conference paper at ICLR 2021
In the corollary, we assume that sf < s. Note that s2 is the variance of single variable and sf2 is
the variance of minimum of N i.i.d. variables. For common symmetry distributions, along with
the increase of N, sf shrinks in the order of O(1/N B) where B ∈ (0, 2]. Thus, as long as N is
large, the assumption will always hold. An exception is that when these random variables follow
the exponential distribution, where sf does not shrink along with the increase of N . However,
since these random variables are confidence scores which are in [0, 1], they cannot obey exponential
distribution.
D.3 A Concrete Case: Uniform Distribution
As shown by Saremi & Srivastava (2020) (Remark 2.1), when the input dimension d is large, the
Gaussian noise e 〜N(0, σ2Id) ≈ Unif(σ√dSd-ι), i.e., xo + e is highly uniformly distributed on
the (d - 1)-sphere centered at x0. Motivated by this, we study the case where the confidence scores
{fi(x0 + )y0 }iN=1 are also uniformly distributed.
Under this additional assumption, we can further make the certified robustness for the single model
and both ensembles more concrete.
D.3.1 Certified Robustness for Single Model
Proposition D.2 (Certified Robustness for Single Model under Uniform Distribution). Let be
a random variable supported on Rd. Let F be a classification model, which is (, λ3, p)-single
confident. Let x0 ∈ Rd be the input with ground-truth y0 ∈ [C]. Suppose f (x0 + )y0 is uniformly
distributed in [a, b]. We have
Pr(F(xo + e) = yo) ≥ 1 - P - clip ( 1/(1 + λ3 )~a),
b-a
where clip(x) = max(min(x, 1), 0).
Proof of Proposition D.2. We consider the distribution of quantity Y := f(xo + e)y0 - λ3(1 -
f(xo + e)y0). Since the model F is (e, λ3, p)-single confident, with probability 1 -p, Y ≤ f(xo +
e" - maxyj曰勺9.=#。f (xo + e)y.. At the same time, because f (xo + e)y° follows the distribution
U([a, b]),
Y = (1 + λ3)f (xo + e)y0 - λ3
follows the distribution U ([(1 + λ3)a - λ3, (1 + λ3)b - λ3]). Therefore,
Pr(Y ≤ 0)=cliP (λ⅛(≡⅞).
As the result,
Pr S + e)yo- yj∈max=yof(xo + e)yj ≤0) ≤P+Clip (λ⅞⅛⅛λ⅛)),
which is exactly
Pr(F(xo + e) = yo) ≥ 1 - P - CliP ( ：3[，+ λ3)a ) =1 - P - CliP ( 1/(1 + λ3 ) - OJ).
(1 + λ3)(b - a)	b - a
□
D.3.2 Certified Robustness for Ensembles
Still, we define X1(e) and X2(e) according to Definitions D.2 and D.3. Under the uniform distribu-
tion assumption, we have the following lemma.
Lemma D.5 (Expectation and Variance of X1 and X2 under Uniform Distribution). Let X1 and X2
be defined by Definition D.2 and Definition D.3 respectively. Assume that under the distribution ofe,
29
Under review as a conference paper at ICLR 2021
the base models’ confidence scores for true class {fi(x0 + )y0}iN=1 are pairwise i.i.d and uniformly
distributed in range [a, b]. We have
E XI(W) = 2(I + λ1)kwk1(a + b) - λ1 kwk1, Var XI(W) = 12(I + λ1)2kwk2(b - a)2,
42	1
E χ2(W) = (I + λ2)(a + b) - 2λ2,	Var χ2(W) ≤ (I + λ2) N +1 (N + 2 - N +ιj (b
)2 .
ProofofLemma D.5. We start from analyzing Xi. From the definition
N
XI(W) ：=(1+ λI) Ewj fj (x0 + W)yo - λ1∣∣wk1
j=1
where {fi(x0 + )y0 }iN=1 are i.i.d. variables obeying uniform distribution U ([a, b]),
a+b	1
EXi(W) = (1 + λi)kwki-ɪ - λikwki = -(1 + λι)kwki(a + b) - λι∣∣w∣∣ι,
N1	1
Var XI(W) = (I + λi) X wj —(b - - = —(1 + λ1) kwk2(b --.
12	12
j=1
(31)
Now analyze the expectation ofX2. By the symmetry of uniform distribution, we know
_ ʌ , .	, , -、__________ ， . 一- ,. .,	-、 一一
EX?(w) =	(1	+ λ2)	∙ 2E fi(xo +	W)yo	— 2λ2	= (1 +	λ2)(- +	b) — 2λ2.
To reason about the variance, we need the following fact:
Fact D.1. Let x1 , x2 , . . . , xn be uniformly distributed and independent random variables. Specifi-
cally, for each 1 ≤ i ≤ n, Xi 〜U([-, b]). Then we have
Var I min Xi ∣ = Var ( max Xi ∣ =---
1≤i≤n	1≤i≤n	n + 1

1
n + 1
(b - )2 .
Observing that each i.i.d. fi(x0 + W)y0 is eXactly identical to Xi in Fact D.1, we have
Var (max fi(x0+W)yo+ms fi (x0+WJ ≤ N+r (n⅜2 - N+ι)(b - -)2.
Therefore,
VarX2(W) ≤ (1 + λ2)2	2―2——(b - -)2.
2--1	2 N + 1 NN + 2 N +1 /	)
□
Proof of Fact D.1. From symmetry of uniform distribution, we know Var (min1≤i≤n Xi) =
Var (max1≤i≤n Xi). So here we only consider Y := min1≤i≤n Xi. Its CDF F and PDF f can
be easily computed:
F(y) = 1-Pr min Xi ≥ y
=1-
(b - y)n-1
f (y) = F (y) = n' (b - -)n , where y ∈ [-, b].
Hence,
E Y =Zb yf (y)dy =…y)n + (n + 1;(b- "尸1
a	(b - )n
b--
n + 1
a
b
+
30
Under review as a conference paper at ICLR 2021
E Y2=Za y2f (y)dy=Za ny2 ⅜y⅛- dy

—
y2b
a
+2
=-(产)>]+ 4i (-	y + / VC dy) Ib
b -a	a n + 1	(b -a)n	(b -a)n	a
=-(b-yY 2∣b	,	2	(_(b- y)n+1 -	1	(b-y)n+2) Ib
Ib — a y Ia	n +11	(b — a)n	9 n +	2 (b — a)n	) Ia
22
=a + n+1(b - a)a +(n +1)(n + 2) (b - a) .
As the result, Var Y = EY2 - (EY)2 = n++ι (n+2 - n++r) (b - α)2.
□
Now, similarly, we use Lemma D.1 to derive the statistical robustness lower bound for WE and
MME. We omit the proofs since they are direct applications of Lemma D.5, Lemma D.1, and
Lemma D.2.
Theorem D.1 (Certified Robustness for WE under Uniform Distribution). Let MWE be a Weighted
Ensemble defined over {fi}iN=1 with weights {wi}iN=1. Let x0 ∈ Rd be the input with ground-
truth label y0 ∈ [C]. Let be a random variable supported on Rd. Under the distribution of ,
suppose {fi(x0 + )y0}iN=1 are i.i.d. and uniformly distributed in [a, b]. The MWE is (, λ1,p)-WE
confident. Assume a+b > [十；-]. We have
d K2
Pr(MWE(XO + €) = yo) ≥ 1 - P-——,
12
where
Mt
kwk2,
K1
b-a
a+b _	1
F - 1+λτr
(34)
Theorem D.2 (Certified Robustness for MME under Uniform Distribution). Let MMME be a Max-
Margin Ensemble over {fi}iN=1. Let x0 ∈ Rd be the input with ground-truth label y0 ∈ [C]. Let € be
a random variable supported on Rd. Under the distribution of €, suppose {fi (x0 + €)y0}iN=1 are i.i.d.
and uniformly distributed in [a, b]. MMME is (€, λt,p)-MME confident. Assume a+b >	1-ι.
2	1+λ2
We have
Pr(MMME(XO + €) = yo) ≥ 1 - P------N 2 ,
4
2	2	1	b-a	(35)
Where CN = NTl (N^ - N+lJ ,K2 =喏-=.
2	1+λ-1
D.3.3 Comparison
Now under the uniform distribution, we can also have the certified robustness comparison.
Corollary D.1 (Comparison of Certified Robustness under Uniform Distribution). Over base mod-
els {fi}iN=1, let MMME be Max-Margin Ensemble, and MWE the Weighted Ensemble with weights
{wi}iN=1. Let XO ∈ Rd be the input with ground-truth label yO ∈ [C]. Let € be a random variable
supported on Rd. Under the distribution of€, suppose {fi(XO + €)y0}iN=1 are i.i.d. and uniformly
distributed with mean μ. Suppose MWE is (€, λι,p)-WE confident, and MMME is (e, λ2,p)-MME
confident. Assume μ > max
(
1	1
1+λ-1, 1+λ-1
.
• When
λ1 <λ-1]((N+1)rNN25-τ⅛)+1-μ!->	(36)
MWE has higher certified robustness than MMME.
31
Under review as a conference paper at ICLR 2021
• When
λ1
λ2
> λ2-1
(37)
MMME has higher certified robustness than MWE.
• When
N>6 1-
μ(i + λ-1)
(38)
for any λ1, MMME has higher or equal certified robustness than MWE.
Here, the certified robustness is given by Theorems D.1 and D.2.
ProofofCorollary D.1. First, We notice that a uniform distribution with mean μ can be any distri-
bution U([a, b]) where (a + b)/2 = μ. We replace μ by (a + b)/2.
Then (1) and (2) follow from Lemma D.4 similar to the proof of Corollary 2.
(3)	Since
1
N > 6 1 — -------K
μ(i + λ-1)
μ- T⅛) +1-μ
μ - T⅛) + 1-μ
-1
<1
-1
< 1,
the RHS of Equation (37) is smaller than 0. Thus, for any λι, since λι/λ2 > 0, the Equation (17) is
satisfied. According to (2), MMME has higher certified robustnesss than Mwe.	口
Remark. Comparing to the general corollary (Corollary 2), under the uniform distribution, we have
an additional finding that when N is sufficiently large, we will always have higher certified robust-
ness for Max-Margin Ensemble than Weighted Ensemble. This is due to the more efficient variance
reduction of Max-Margin Ensemble than Weighted Ensemble. As shown in Lemma D.5, the quan-
tity VarX(w)∕(EX(w))2 for Weighted Ensemble is Ω(1∕N), while for Max-Margin Ensemble is
O(1/N 2). As the result, when N becomes larger, Max-Margin Ensemble has higher certified ro-
bustness.
We use uniform assumption here to give an illustration in a specific regime. Since the assumption
may not hold exactly in practice, we think it would be an interesting future direction to generalize
the analysis to other distributions such as the Gaussian distribution that corresponds to locally linear
classifiers. The result from these distribution may be derived from their specific concentration bound
for maximum/minimum i.i.d. random variables as discussed at the end of Appendix D.2.
D.4 Numerical Experiments
To validate and give more intuitive explanations for our theorems, we present some numerical ex-
periments.
D.4. 1 Ensemble Comparison from Numerical Sampling
As discussed in Section 3.2, λ1∕λ2 reflects the transferability across base models. It is challenging
to get enough amount of different ensembles of various transferability levels while keeping all other
variables controlled. Therefore, we simulate the transferability of ensembles numerically by varying
λ1∕λ2 (see the definitions of λι and λ2 in Definitions 6 and 7), and sampling the confidence scores
{fi(xo + e)yo} and {maxj∈[c]j=yo fi(xo + e)j} under determined λι and λ2. For each level
of λ1∕λ2, with the samples, we compute the certified robust radius r using randomized smooth-
ing (Theorem B.1) and compare the radius difference of Weighted Ensemble and Max-Margin En-
semble. According to Corollary 2 in Section 3.2, we should observe the tendency that along with
32
Under review as a conference paper at ICLR 2021
(a) # of base models N = 3
(b) # of base models N = 10
(c) # of base models N = 20
Figure 2: Signed certified robust radius difference between MME and WE by λ∖∕λ? under different
numbers of base models N. Here we fix λ2 to be 0.95 and uniformly sample λ1 ∈ [0.8, 0.95). The
confidence score for the true class on each base model is uniformly sampled from [a, b], where a
is sampled from [0.3, 1.0) and b is sampled from [a, 1.0) uniformly for each instance. Blue points
correspond to the negative radius difference (i.e., WE has larger radius than MME) and Red points
correspond to the positive radius difference (i.e., MME has larger radius than WE).
the increase of transferability λ1 /λ2 , Max-Margin Ensemble would gradually become better than
Weighted Ensemble.
Figure 2 verifies the trends: with the increase of λ1∕λ2, MME model tends to achieve higher certified
radius than WE model. Moreover, We notice that under the same λ1∕λ2, with the larger number of
base models N, the MME tends to be relatively better compared with WE. This is because we
sample the confidence score uniformly and under the uniform distribution, MME tends to be better
than WE when the number of base models N becomes large, according to Corollary D.1.
The concrete number settings of λ1, λ2, and the sampling interval of confidence scores are entailed
in the caption of Figure 2.
D.4.2 Ensemble Comparison from Certified Robustness Plotting
In Corollary D.1, we derive the concrete certified robustness for both ensembles and the single
model under i.i.d. and uniform distribution assumption. In fact, from the corollary, we can directly
compute the certified robust radius without sampling, as long as we assume the added noise is
Gaussian. In Figure 3, we plot out such certified robust radius for the single model, the WE, and the
MME.
Concretely, in the figure, we assume that the true class confidence score for each base model is
i.i.d. and uniformly distributed in [a, b]. The Weighted Ensemble is (, λ1, 0.01)-WE confident; the
Max-Margin Ensemble is (, λ2, 0.01)-MME confident; and the single model is (, λ3, 0.01)-MME
confident. We guarantee that λ1 ≤ λ3 ≤ λ2 to simulate the scenario that ensembles are based
on the same set of base models to make a fair comparison. We directly apply the results from our
analysis (Theorem D.1, Theorem D.2, Proposition D.2) to get the statistical robustness for single
model and both ensembles. Then, we leverage Theorem B.1 to get the certified robust radius (with
σ = 1.0, N = 100000 and failing probability α = 0.001 which are aligned with realistic setting).
The x-axis is the number of base models N and the y-axis is the certified robustness. We note that N
is not applicable to the single model, so we plot the single model’s curve by a horizontal red dashed
line.
From the figure, we observe that when the number of base models N becomes larger, both ensembles
perform much better than the single model. We remark that when N is small, the ensembles have
0 certified robustness mainly because our theoretical bounds for ensembles are not tight enough
with the small N . Furthermore, we observe that the Max-Margin Ensemble gradually surpasses
Weighted Ensemble when N is large, which conforms to our Corollary D.1. Note that the left
sub-figure has smaller transferability λ1∕λ2 and the right subfigure has larger transferability λ1∕λ2,
it again conforms to our Corollary 2 and discussion in Section 3.2 that in the left subfigure the
Weighted Ensemble is relatively more robust than the Max-Margin Ensemble.
33
Under review as a conference paper at ICLR 2021
SSafSnqOH P9ci=!pθο
0.2
Certified Robustness Comparison
(a = 0.2, b = 0.3fΛ1 = 0.29, Λ2 = 0.31fΛ3 = 0.30)
1.0
WE
MME
Single Model
Certified Robustness Comparison
SSafSnqOH P9ci=!pθο
WE
MME
Single Model
0.0
5	10	15	20	25	30
# of Base Models (Af)
(a)	[a, b]	=	[0.2, 0.3], λ1 = 0.29, λ2
0.31, λ3 = 0.30.
ON
0.0
5	10	15	20	25	30
# of Base Models (Af)
(b)	[a, b] = [0.3, 0.4], λ1 = 0.48, λ2
0.50, λ3 = 0.49.


Figure 3: Comparison of certified robustness (in terms of certified robust radius) of Max-Margin
Ensemble, Weighted Ensemble, and single model under concrete numerical settings. The y-axis
is the certified robustness and the x-axis is the number of base models. The confidence score for
the true class is uniformly distributed in [a, b]. The Weighted Ensemble (shown by blue line) is
(, λ1, 0.01)-WE confident; the Max-Margin Ensemble (shown by green line) is (, λ2, 0.01)-MME
confident; and the single model (shown by red line) is (, λ3, 0.01)-MME confident.
D.4.3 Ensemble Comparison from Realistic Data
We study the correlation between transferability λ1∕λ2 and whether Weighted Ensemble or Max-
Margin Ensemble is more certifiably robust using realistic data.
By varying the hyper-parameters of DRT, we find out a setting where over the same set of base
models, Weighted Ensemble and Max-Margin Ensemble have similar certified robustness, i.e., for
about half of the test set samples, WE is more robust; for another half, MME is more robust. We
collect 1, 000 test set samples in total. Then, for each test set sample, we compute the transferability
λ1 /λ2 and whether WE or MME has the higher certified robust radius. We remark that λ1 and λ2
are difficult to be practically estimated so we use the average confidence portion as the proxy:
• For WE,
λ] = E maxyj∈[c]yj=yo Pi=I Wfi(XO + Oyj
PN=I Wi(I - fi(XO + C)yo )
• For MME,
∖	_m mzmaxyj∈[4yj=y0fi(χo + Dyj
入2 — IEC mιax	,	,	、、	.
i∈[N ]	(1 -fi(XO + C)y0 )
Now we study the correlation between
X :— λ1∕λ2 - RHS ofEquation (17) and Y :— 1[MME has higher certified robustness].
To do so, we draw the ROC curve where the threshold on X does binary classification on Y. The
curve and the AUC score is shown in Figure 4. From the ROC curve, we find that X and Y are
apparently positively correlated since AUC — 0.66 > 0.5, which again verifies Corollary 2. We re-
mark that besides X, other factors such as non-symmetric or non-i.i.d. confidence score distribution
may also play a role.
34
Under review as a conference paper at ICLR 2021
Figure 4: ROC curve of the 1[MME has higher certified robustness] classification task with the
threshold variable X .
E Experiment Details
Evaluation metric: We use the certified test set accuracy at each radius r as our evaluation metric,
which is defined as the fraction of the test set samples that the smoothed classifier can certify the
robustness within the L2 ball of radius r. Since the computation of the accurate value of this metric
is intractable, we report the approximate certified test accuracy (Cohen et al., 2019) sampled through
the Monte Carlo procedure. For each sample, the robustness certification holds with probability at
least 1 - α. Following the literature, we choose α = 0.001, n0 = 100 for Monte Carlo sampling
during prediction phase, and n = 100, 000 for Monte Carlo sampling during certification phase.
E.1 MNIST
Baseline models’ hyper-parameter configuration: We choose the number of noise samples per
instance m = 2 and Gaussian smoothing parameter σ ∈ {0.25, 0.5, 1.0} for all the training methods.
For SmoothAdv, we consider the attack to be 10-step L2 PGD attack with perturbation scale δ = 1.0
without pretraining and unlabelled data augmentation. We reproduced similar results to their paper
by using their open-sourced code1.
Training details: We use LeNet architecture and trained each base model for 90 epochs. For the
training optimizer, we use the SGD-momentum with the initial learning rate α = 0.01. The learning
rate is decayed for every 30-epochs with decay ratio γ = 0.1 and the batch size equals to 256. For
DRT experiments, we start our training with the small learning rate α = 5 × 10-4 and finetune the
base models for another 90 epochs. During the training, we find too large regularization weights
may cause the model’s training collapse on MNIST. We turn to use small DRT hyper-parameters
ρ1 , ρ2 and report the one with the best certified accuracy on each radius r.
Certified accuracy curve: Figure 6 and Figure 7 show the certified accuracy curve with different
base model type and smoothing parameter σ among the range of the radius r. We can notice that
while simply applying MME or WE can improve the certified accuracy slightly, DRT could help
boost the certified accuracy on each radius r with a significant scale.
DRT hyper-parameters: We investigate the DRT hyper-parameters ρ1 ∈ {0.1, 0.2, 0.3, 0.5, 1.0}
and ρ2 ∈ {0.5, 1.0, 2.0, 5.0} corresponding to different smoothing parameter σ ∈ {0.25, 0.5, 1.0}.
Here we put the detailed results for every hyper-parameter setting in Tables 4 to 6 and bold the
numbers with the highest certified accuracy on each radius r among all the tables with different
σ's. From the experiments, We found that the GD loss's weight ρι can have the major influence on
the ensemble model’s functionality: if we choose larger ρ1, the model will achieve slightly worse
certified accuracy on small radius r, but better certified accuracy on large r. We cannot choose too
large ρ1 on small σ cases (e.g., σ = 0.25). Otherwise, the training procedure will collapse. Here we
show the DRT-based model’s approximate certified accuracy with different ρ1 in Figure 5.
1https://github.com/Hadisalman/smoothing-adversarial/
35
Under review as a conference paper at ICLR 2021
Table 4: DRT-(ρ1, ρ2) model’s certified accuracy under different radius r on MNIST dataset.
Smoothing parameter σ = 0.25.
Radius r	Pi	P2	0.00	0.25	0.50	0.75
Gaussian (Cohen et al., 2019)	-	-	^99T	^979^	^966^	^930^
SmoothAdv (Salman et al., 2019)	-	-	99.1	98.4	97.0	96.3
MME (Gaussian)	-	-			^968^	^936^
	ɪr	^0^		-98.3-	^97^	ɪr
DRT + MME (Gaussian)	0.1	0.5	99.5	98.6	97.1	94.8
	0.2	0.5	99.5	98.5	97.4	95.1
MME (SmoothAdv)	-	-			^973^	-96.4-
	ɪr	^0^	^99T	^984^	^97^	-96.4"
DRT + MME (SmoothAdv)	0.1	0.5	99.1	98.3	97.6	96.7
	0.2	0.5	99.1	98.4	97.5	96.6
WE (Gaussian)	-	-			^969^	^937^
	ɪr	^0^	~99S~	^984^	^973^	ɪr
DRT + WE (Gaussian)	0.1	0.5	99.5	98.6	97.1	94.9
	0.2	0.5	99.5	98.5	97.3	95.3
WE (SmoothAdv)	-	-			^974^	-96.4-
	ɪr	^0^	~91Γ	^984^	^97^	^96T^
DRT + WE (SmoothAdv)	0.1	0.5	99.1	98.2	97.6	96.6
	0.2	0.5	99.0	98.4	97.5	96.7
Alternatively, we found that the CM loss’s weight ρ2 can have positive influence on model’s perfor-
mance: the larger ρ2 we choose, the better certified accuracy we can get. Choosing large ρ2 does
not harm model’s functionality too much, but the improvement we received will become marginal.
For MNIST, (σ,ρ1,ρ2) ∈ {(0.25, 0.1, 0.2), (0.5, 0.5, 5.0), (1.0, 1.0, 5.0)} are good combinations.
Efficiency Analysis: We regard the execution time per mini-batch as our efficiency criterion. For
MNIST with batch size equals to 256, DRT with the Gaussian smoothing base model only requires
1.04s to finish one mini-batch training to achieve the comparable results to the SmoothAdv method
which requires 1.86s. Moreover, DRT with the SmoothAdv base model requires 2.52s per training
batch but achieves much better results. The evaluation is on single NVIDIA GeForce GTX 1080 Ti
GPU.
Auα},I nuuq Pa _M—_t① ɔ
0.∞	0.25	0.50
Radius
1.50	1.75	2.00
(a) σ = 0.5
DRT+MME
DRT+MME
DRT+MME
DRT+MME
DRT+MME
Auα},I nuuq Pa _M—_t① ɔ
Radius
(b) σ = 1.0
Figure 5: Effect of ρ1 : Comparison of approximate certified accuracy of DRT models on MNIST
with different GD Loss’s weight ρ1.
1.5	2.0


E.2 CIFAR- 1 0
Baseline models’ hyper-parameter configuration: We choose the number of noise samples per
instance m = 2 and Gaussian smoothing parameter σ ∈ {0.25, 0.5, 1.0} for all the training methods.
36
Under review as a conference paper at ICLR 2021
Table 5: DRT-(ρ1, ρ2) model’s certified accuracy under different radius r on MNIST dataset.
Smoothing parameter σ = 0.50.
Radius r	Pi	P2	0.00	0.25	0.50	0.75	1.00	1.25	1.50	1.75
Gaussain (Cohen et al., 2019)	-	-	^990^^	97.7	96.4	94.7	90.0	83.0	68.2	43.5
SmoothAdv (Salman et al., 2019)	-	-	98.6	98.0	97.0	95.4	93.0	87.7	80.2	66.3
MME (Gaussian)	-	-	99.0	97.7	96.8	94.9	90.5	84.3	69.8	48.5
	-02"	^0-	99.1	98.4	97.2	95.2	92.6	86.5	74.3	54.1
	0.2	5.0	99.1	98.6	97.1	95.3	92.6	86.2	74.0	54.3
DRT + MME (Gaussian)	0.5	2.0	99.2	98.3	97.4	95.5	92.1	86.4	74.7	55.6
	0.5	5.0	99.0	98.2	97.3	95.1	91.6	84.8	73.7	52.4
	1.0	5.0	99.1	98.2	97.2	95.2	92.2	85.8	74.4	54.4
MME (SmoothAdv)	-	-	98.6	98.0	97.0	95.5	93.2	88.1	80.6	67.8
	-0Γ"	^0Γ^	98.4	97.8	97.0	95.5	92.7	87.7	80.9	67.9
	0.1	1.0	98.4	97.9	97.0	95.5	92.9	88.1	80.8	67.2
	0.1	5.0	98.5	98.2	97.0	95.4	93.1	88.4	81.2	68.3
	0.2	0.5	98.4	97.7	97.2	95.3	92.3	87.7	79.3	68.4
	0.2	2.0	98.4	97.6	97.1	95.3	92.3	87.8	80.2	67.7
DRT + MME (SmoothAdv)	0.2	5.0	98.4	97.8	97.1	95.2	93.0	87.9	80.3	68.3
	0.3	5.0	98.4	97.5	97.1	95.0	92.4	87.7	79.7	68.3
	0.5	2.0	98.5	97.3	96.6	94.3	91.6	86.7	79.5	68.6
	0.5	5.0	98.4	97.5	96.9	94.6	92.0	87.5	80.1	67.8
	1.0	5.0	98.2	97.3	96.8	94.5	91.9	87.4	80.0	67.6
WE (Gaussian)	-	-	99.0	97.8	96.8	94.9	90.6	84.5	70.4	48.2
	^02"	^0-	99.2	98.4	97.2	95.2	92.5	86.2	74.3	53.5
	0.2	5.0	99.1	98.6	97.1	95.3	92.6	86.4	74.2	54.4
DRT + WE (Gaussian)	0.5	2.0	99.2	98.3	97.4	95.6	92.1	86.5	74.7	55.3
	0.5	5.0	99.1	98.2	97.1	95.1	91.7	85.4	73.5	51.0
	1.0	5.0	99.1	98.2	97.2	95.2	92.2	85.9	75.1	55.3
WE (SmoothAdv)	-	-	98.7	98.0	97.0	95.5	93.4	88.2	81.1	67.9
	^0Γ"	^0Γ^	98.4	97.8	97.0	95.5	92.7	87.8	80.6	68.1
	0.1	1.0	98.5	97.9	97.0	95.5	93.1	88.0	81.2	67.7
	0.1	5.0	98.5	98.2	97.0	95.4	93.3	88.5	81.4	68.6
	0.2	0.5	98.4	97.7	97.2	95.4	92.3	87.6	79.7	68.0
	0.2	2.0	98.4	97.6	97.1	95.3	92.3	87.8	80.6	68.1
DRT + WE (SmoothAdv)	0.2	5.0	98.4	97.9	97.1	95.1	93.4	88.2	80.4	69.1
	0.3	5.0	98.4	97.5	97.1	95.0	92.4	87.9	79.9	69.3
	0.5	2.0	98.4	97.3	96.6	94.3	91.8	86.7	79.6	68.1
	0.5	5.0	98.4	97.5	96.9	94.7	92.0	87.7	79.7	67.7
	1.0	5.0	98.4	97.7	97.0	95.2	92.6	88.4	81.1	68.2
For SmoothAdv, we consider the attack to be 10-step L2 PGD attack with perturbation scale δ =
1.0 without pretraining and unlabelled data augmentation. We also reproduced the similar results
mentioned in baseline’s papers.
Training details: We use ResNet-110 architecture for each base model and train them for 150
epochs. During the training, We utilize the SGD-momentum with the initial learning rate α = 0.1,
which is decayed for every 50-epochs with ratio γ = 0.1. For DRT experiments, we start the training
with the learning rate α = 5 × 10-3 and finetune our base models for another 150 epochs.
Certified accuracy curve: Figure 8 and Figure 9 show the certified accuracy curve with different
base model type and smoothing parameter σ among the range of the radius r. We can see the same
trends: Applying the MME/WE mechanism will give a slight improvement and DRT can help make
this improvement to be significant.
DRT hyper-parameter: We studied the DRT hyper-parameter ρ ∈ {0.1, 0.2, 0.5, 1.0, 1.5} and
ρ2 ∈ {0.5, 2.0, 5.0} corresponding to different σ ∈ {0.25, 0.5, 1.0} and put the detailed results in
Tables 7 to 9. We bold the numbers with the highest certified accuracy on each radius r among
all the tables with different σ's. The results show the similar conclusion about the choosing of ρι
and ρ2. (σ, ρ1, ρ2) ∈ {(0.25, 0.1, 0.5), (0.5, 1.0, 5.0), (1.0, 1.5, 5.0)} could be the good choices on
CIFAR-10 dataset.
37
Under review as a conference paper at ICLR 2021
Table 6: DRT-(ρ1, ρ2) model’s certified accuracy under different radius r on MNIST dataset.
Smoothing parameter σ = 1.00.
Radius r	Pi	P2	0.00	0.25	0.50	0.75	1.00	1.25	1.50	1.75	2.00	2.25	2.50
Gaussain Smoothing	-	-	96.5	94.3	91.1	87.0	80.2	71.8	60.1	46.6	33.0	20.5	11.5
SmoothAdv	-	-	95.3	93.5	89.3	85.6	80.4	72.8	63.9	54.6	43.2	34.3	24.0
MME (Gaussian)	-	-	96.4	94.8	91.3	87.7	80.8	73.5	61.0	48.8	34.7	23.4	12.7
	O55~	ɪð-	96.0	93.9	90.1	86.3	80.7	73.2	63.0	52.0	38.9	26.9	15.6
DRT + MME (Gaussian)	0.5	5.0	95.8	94.1	90.0	86.6	80.4	72.9	62.4	51.3	40.0	27.8	16.5
	1.0	5.0	95.3	93.1	89.7	85.8	80.0	72.7	62.9	52.0	39.8	28.5	17.6
MME (SmoothAdv)	-	-	95.4	93.4	89.3	86.1	80.7	73.1	65.0	55.0	44.8	35.0	25.2
	OQT~	ɪð-	94.1	91.9	88.6	84.5	79.4	72.4	63.4	54.0	45.0	36.6	27.3
	0.2	5.0	94.1	91.6	88.9	84.4	79.3	72.3	63.2	54.2	46.1	36.9	28.5
DRT + MME (SmoothAdv)	0.5	2.0	92.8	91.3	87.7	83.2	77.3	71.2	62.2	53.3	45.5	37.0	29.7
	0.5	5.0	92.5	91.2	88.0	83.5	78.5	71.2	62.2	53.8	45.2	37.7	29.2
	1.0	5.0	92.1	90.0	86.3	81.3	76.2	69.4	61.1	54.0	46.4	38.6	31.1
WE (Gaussian)	-	-	96.3	94.9	91.3	87.7	80.7	73.5	61.1	49.0	35.2	23.7	12.9
	-0Γ^	ɪð-	95.9	93.9	90.2	86.3	80.7	73.2	63.2	51.9	38.6	27.0	15.5
WE + MME (Gaussian)	0.5	5.0	95.9	94.1	90.0	86.4	80.4	73.1	62.3	51.7	39.8	27.5	16.4
	1.0	5.0	95.4	93.1	89.7	85.8	80.0	72.7	62.9	52.1	39.9	28.5	17.8
WE (SmoothAdv)	-	-	95.2	93.4	89.4	86.2	80.8	73.3	64.8	55.1	44.7	35.2	24.9
	-02^"	ɪð-	94.2	91.9	88.6	84.5	79.6	72.5	63.7	53.9	44.9	36.4	27.3
	0.2	5.0	94.2	91.6	88.9	84.4	79.3	72.5	63.3	54.3	45.9	36.9	28.7
DRT + MME (SmoothAdv)	0.5	2.0	92.6	91.3	87.7	83.1	77.5	71.1	62.4	53.3	45.3	36.7	29.3
	0.5	5.0	92.5	91.2	88.0	83.4	78.5	71.1	62.3	53.7	45.3	37.8	29.5
	1.0	5.0	92.1	90.0	86.4	81.4	76.3	69.7	61.1	54.0	46.4	38.4	31.0
Table 7: DRT-(ρ1 , ρ2) model’s certified accuracy under different radius r on CIFAR-10 dataset.
Smoothing parameter σ = 0.25.
Radius r	Pi	P2	0.00	0.25	0.50	0.75
Gaussain Smoothing	-	-	78.9	~44A~	T74^	30.6
SmoothAdv	-	-	68.9	61.0	54.4	45.7
MME (Gaussian)	-	-	80.8		^4Γ	37.4
	ɪr	~5Γ	81.4	704T	-576^	43.4
DRT + MME (Gaussian)	0.2	0.5	78.8	69.2	57.8	43.8
	0.5	2.0	73.3	61.7	51.0	39.3
	0.5	5.0	66.2	57.1	46.2	34.4
MME (SmoothAdv)	-	-	71.4		-576^	48.4
	ɪr	^0^	72.6		602Γ	50.3
DRT + MME (SmoothAdv)	0.2	0.5	71.8	66.5	59.3	50.4
	0.5	0.5	68.2	64.3	58.2	48.9
WE (Gaussian)	-	-	80.7	-68.3-	-536^	37.5
	ɪr	^0^	81.5	^704^	57.7	43.4
DRT + WE (Gaussian)	0.2	0.5	78.8	69.3	57.9	44.0
	0.5	2.0	73.4	61.7	51.0	39.2
	0.5	5.0	66.2	57.1	46.1	34.5
WE (SmoothAdv)	-	-	71.8	-64.6-	ɪg-	48.5
	ɪr	^0^	72.6	-67.0-	~02Γ	50.3
DRT + WE (SmoothAdv)	0.2	0.5	71.9	66.5	59.4	50.5
	0.5	0.5	68.2	64.3	58.4	49.1
Efficiency Analysis: We also use the execution time per mini-batch as our efficiency criterion. For
CIFAR-10 with batch size equals to 256, DRT with the Gaussian smoothing base model requires
3.82s to finish one mini-batch training to achieve the competitive results to 10-step PGD attack
based SmoothAdv method which requires 6.39s. All the models are trained in parallel on 4 NVIDIA
GeForce GTX 1080 Ti GPUs.
38
Under review as a conference paper at ICLR 2021
Table 8: DRT-(ρ1 , ρ2) model’s certified accuracy under different radius r on CIFAR-10 dataset.
Smoothing parameter σ = 0.50.
Radius r	Pi	P2	0.00	0.25	0.50	0.75	1.00	1.25	1.50	1.75
Gaussain Smoothing	-	-	68.2	57.1	44.9	33.7	23.1	16.3	10.0	5.4
SmoothAdv	-	-	60.6	54.2	47.9	41.2	34.8	28.5	21.9	17.1
MME (Gaussian)	-	-	69.5	59.6	47.3	38.4	29.0	19.6	13.3	7.6
	-02"	ɪð-	69.7	61.0	50.9	40.3	30.8	22.5	15.8	10.0
	0.2	5.0	68.0	59.9	50.0	40.8	30.1	22.1	15.2	9.6
	0.5	2.0	67.8	58.5	49.0	39.9	31.6	23.4	16.1	10.2
DRT + MME (Gaussian)	0.5	5.0	65.5	58.4	49.0	40.1	31.2	23.6	16.5	10.2
	1.0	2.0	64.5	55.8	47.5	39.4	31.1	23.6	14.8	9.3
	1.0	5.0	62.2	54.1	46.5	38.8	29.7	22.8	16.6	11.0
MME (SmoothAdv)	-	-	61.0	54.8	48.7	42.2	36.2	29.8	23.9	19.1
	^02"	ʒɪ	62.2	56.4	50.3	43.4	37.5	26.7	24.6	19.4
DRT + MME (SmoothAdv)	0.5	5.0	61.9	56.2	50.3	43.5	37.6	31.8	24.8	19.6
	1.0	5.0	61.4	55.9	50.0	43.2	37.4	32.0	25.4	19.9
WE (Gaussian)	-	-	69.4	59.7	47.5	38.4	29.2	19.7	13.3	7.5
	^0Γ"	ɪð-	69.7	61.2	50.8	40.2	30.8	22.4	15.9	10.0
	0.2	5.0	68.0	59.9	50.1	40.8	30.1	22.1	15.4	9.7
	0.5	2.0	67.8	58.5	49.2	39.8	31.7	23.5	16.2	10.4
DRT + WE (Gaussian)	0.5	5.0	65.5	58.4	49.1	40.3	31.3	24.2	16.4	10.3
	1.0	2.0	64.6	55.9	47.5	39.6	31.0	24.0	14.8	9.4
	1.0	5.0	62.3	54.2	46.6	38.8	29.8	22.9	16.6	10.9
WE (SmoothAdv)	-	-	61.1	54.8	48.8	42.3	36.2	29.6	24.2	19.0
	^0Γ"	ʒɪ	62.2	56.3	50.3	43.4	37.5	26.9	24.7	19.3
DRT + WE (SmoothAdv)	0.5	5.0	61.9	56.2	50.2	43.4	37.9	31.8	25.0	19.6
	1.0	5.0	61.5	56.0	50.1	43.3	37.5	32.2	25.6	19.9
Table 9: DRT-(ρ1 , ρ2) model’s certified accuracy under different radius r on CIFAR-10 dataset.
Smoothing parameter σ = 1.00.
Radius r	Pi	P2	0.00	0.25	0.50	0.75	1.00	1.25	1.50	1.75	2.00
Gaussain Smoothing	-	-	48.9	42.7	35.4	28.7	22.8	18.3	13.6	10.5	7.3
SmoothAdv	-	-	47.8	43.3	39.5	34.6	30.3	25.0	21.2	18.2	15.7
MME (Gaussian)	-	-	50.2	44.0	37.5	30.9	24.1	19.3	15.6	11.6	8.8
	-0Γ"	ʒɪ	49.4	44.2	37.8	31.6	25.4	22.6	18.2	14.4	12.4
DRT + MME (Gaussian)	1.0	5.0	49.8	44.4	39.0	31.6	25.6	22.6	18.2	15.0	12.0
	1.5	5.0	48.0	42.4	36.4	30.4	26.2	22.0	18.4	15.4	12.8
MME (SmoothAdv)	-	-	48.2	43.7	40.1	35.4	31.3	26.2	22.6	19.5	16.2
	-0Γ"	ʒɪ	48.2	43.9	40.1	35.4	31.5	26.7	22.9	19.8	16.8
	0.5	5.0	48.1	43.8	40.3	35.7	31.8	26.9	23.1	20.1	17.5
DRT + MME (SmoothAdv)	1.0	5.0	47.9	43.6	39.8	35.6	31.7	26.9	23.2	20.2	17.6
	1.5	5.0	47.8	43.4	39.5	35.4	31.6	26.7	23.1	20.4	18.1
WE (Gaussian)	-	-	50.4	44.1	37.5	30.9	24.2	19.2	15.9	11.8	8.9
	-0Γ"	ʒɪ	49.5	44.3	37.8	31.8	25.6	22.5	18.2	14.4	12.3
DRT + WE (Gaussian)	1.0	5.0	49.8	44.4	39.1	31.7	25.6	22.8	18.4	15.1	12.1
	1.5	5.0	48.2	42.5	36.6	30.4	26.1	22.1	18.2	15.7	12.6
WE (SmoothAdv)	-	-	48.2	43.7	40.2	35.4	31.5	26.2	22.7	19.6	16.0
	-0Γ"	ʒɪ	48.2	43.8	40.2	35.3	31.6	26.8	23.0	19.9	16.7
	0.5	5.0	48.2	43.8	40.5	35.7	31.9	26.8	23.3	20.2	17.5
DRT + WE (SmoothAdv)	1.0	5.0	47.8	43.6	39.9	35.5	31.7	26.9	23.3	20.1	17.5
	1.5	5.0	47.8	43.4	39.6	35.4	31.4	26.7	23.0	20.4	18.0
E.3 ImageNet
For ImageNet, we utilize ResNet-50 architecture and train each base model for 90 epochs using
the SGD-momentum optimizer. The initial learning rate α = 0.1. The learning rate is decayed
for every 30-epochs with decay ratio γ = 0.1. We tried different Gaussian smoothing parameter
σ ∈ {0.50, 1.00}, and consider the best hyper-parameter configuration for different σ in the baseline
models. We explored the DRT hyper-parameter ρ1 ∈ {0.5, 1.0, 1.5}, ρ2 ∈ {1.0, 2.0, 5.0} in our
experiments and started with the learning rate α = 5 × 10-3 during the DRT. Table 10 shows the
39
Under review as a conference paper at ICLR 2021
(a) σ = 0.25
(c) σ = 1.00
Figure 6:	Comparison of approximate certified accuracy among different Gaussian-smoothing based
methods with various smoothing parameter σ ∈ {0.25, 0.50, 1.00} on MNIST.
O.
O.
OJ)
0.2
g	0Λ
Radius
1°∙
(a) σ = 0.25
SmoothAdv
MME (SmoothAdv)
——DRT+MME (SmoothAdvl
WE (SmoothAdv)
——DRT+WE (SmoothAdv)
(b) σ = 0.50
(c) σ = 1.00
Figure 7:	Comparison of approximate certified accuracy among different SmoothAdv based meth-
ods with various smoothing parameter σ ∈ {0.25, 0.50, 1.00} on MNIST.
(a) σ = 0.25
(b) σ = 0.50
(c) σ = 1.00
Figure 8:	Comparison of approximate certified accuracy among different Gaussian-smoothing based
methods with various smoothing parameter σ ∈ {0.25, 0.50, 1.00} on CIFAR-10.
14)
ɑ-a
3	——DRT+MME (SmoothAdv)
3 ——WE (SmoothAdv)
——DRT+WE (SmoothAdv)
0Λ
0Λ 0.2 g 0Λ 0Λ
Radius
0.7	SmoothAdv
(c) σ = 1.00
(a) σ = 0.25	(b) σ = 0.50
Figure 9:	Comparison of approximate certified accuracy among different SmoothAdv based meth-
ods with various smoothing parameter σ ∈ {0.25, 0.50, 1.00} on CIFAR-10.
results. We observe the same trends that MME or WE can improve the certified robustness on each
radius r. Due to the computation cost of training the DRT ensemble model on ImageNet, we can
40
Under review as a conference paper at ICLR 2021
Table 10: The certified accuracy under different radius r for ImageNet dataset.
Radius r	0.00	0.50	1.00	1.50	2.00	2.50	3.00
Gaussian (Cohen et al., 2019)	57	46	37	29	19	15	12
SmoothAdv (Salman et al., 2019)	54	49	43	37	27	25	20
MME (Gaussian)	58	47	38	31	21	16	14
DRT + MME (Gaussian)	52	46	42	34	24	19	18
MME (SmoothAdv)	55	50	44	38	27	26	21
DRT + MME (SmoothAdv)	49	44	42	37	29	27	22
WE (GaUSSian)	58	47	38	31	21	17	14
DRT + WE (Gaussian)	52	46	41	33	24	19	18
WE (SmoothAdv)	55	50	44	38	28	26	22
DRT + WE (SmoothAdv)	49	44	42	36	29	27	22
Table 11: Certified accuracy comparison with other baseline methods for MNIST dataset.
Radius r	0.00	0.25	0.50	0.75	1.00	1.25	1.50	1.75	2.00	2.25	2.50
Gaussian (Cohen et al., 2019)	99.1	97.9	96.6	94.7	90.0	83.0	68.2	46.6	33.0	20.5	11.5
SmoothAdv (Salman et al., 2019)	99.1	98.4	97.0	96.3	93.0	87.7	80.2	66.3	43.2	34.3	24.0
MACER (Zhai et al., 2019)	99.2	98.5	97.4	94.6	90.2	83.5	72.4	54.4	36.6	26.4	16.5
Stability (Li et al., 2019)	99.3	98.6	97.1	93.8	90.7	83.2	69.2	46.8	33.1	20.0	11.2
Diversity-Regularized Training	99.5	98.6	97.6	96.7	93.4	88.5	83.3	69.6	48.3	39.4	33.5
Table 12: Certified accuracy comparison with other baseline methods for CIFAR-10 dataset.
Radius r	0.00	0.25	0.50	0.75	1.00	1.25	1.50	1.75	2.00
Gaussian (Cohen et al., 2019)	78.9	64.4	47.4	33.7	23.1	18.3	13.6	10.5	7.3
SmoothAdv (Salman et al., 2019)	68.9	61.0	54.4	45.7	34.8	28.5	21.9	18.2	15.7
MACER (Zhai et al., 2019)	79.5	68.8	55.6	42.3	35.0	27.5	23.4	20.4	17.5
Stability (Li et al., 2019)	72.4	58.2	43.4	27.5	23.9	16.0	15.6	11.4	7.8
SWEEN (Liu et al., 2020)	84.2	72.0	60.3	46.6	37.2	29.2	24.6	22.0	19.1
Diversity-Regularized Training	81.5	70.4	60.2	50.5	39.5	36.0	30.4	24.1	20.3
only try one sub-optimal hyper-parameter setting for DRT and the result shows that DRT cannot
bring more improvements on MME/WE results. We plan to select more suitable hyper-parameters
for DRT to obtain better results on the ImageNet task.
E.4 Comparison with other baselines
We compare our Diversity-Regularized Training with other baselines on MNIST and CIFAR-10
dataset. Baselines are: (1) Gaussian smoothing (Cohen et al., 2019): Training a smoothed classifier
by applying Gaussian augmentation. (2) SmoothAdv (Salman et al., 2019): Integrating adversarial
training on the soft approximation. (3) MACER (Zhai et al., 2019): Adding the regularization term
to maximize the certified radius R = σ (PA - PB) on training instances. (4) Stability (Li et al.,
2019): Adding the adversarial perturbation by maintaining the Stability on classification results.
(5) SWEEN (Liu et al., 2020): Building the weighted ensemble model by composing the base
models of different architectures.
For all baselines, we choose the best certified accuracy for each radius r as reported in their pa-
pers. We do not consider the model trained by additional (unlabeled) data. Results are shown in
Table 11 and Table 12. We can see that we achieve the best certified accuracy on every r on MNIST
dataset and achieve comparable or better results compared to the best certified accuracy on CIFAR-
10 dataset.
41
Under review as a conference paper at ICLR 2021
Table 13: Certified accuracy achieved by training with GD Loss (GDL) or Confidence Margin Loss
(CML) for CIFAR-10 dataset.
Radius r	0.00	0.25	0.50	0.75	1.00	1.25	1.50	1.75	2.00
MME (Gaussian)	80.8	68.2	53.4	38.4	29.0	19.6	15.6	11.6	8.8
GDL + MME (Gaussian)	81.0	69.0	55.6	41.9	30.4	24.8	20.1	16.9	14.7
CML + MME (Gaussian)	81.2	69.4	54.4	39.6	29.2	21.6	17.0	13.1	12.8
DRT + MME (Gaussian)	81.4	70.4	57.8	43.8	31.6	26.2	22.4	18.8	16.6
E.5 The effects of GD Loss and Confidence Margin Loss
We studied the effects of GD Loss and Confidence Margin Loss separately by setting ρ1 = 0 or
ρ2 = 0 but tuning another parameter only. We did this ablation study on CIFAR-10 dataset with
ensemble of Gaussian-smoothed base models and the results are shown in Table 13.
We observed that both GD Loss (GDL) and Confidence Margin Loss (CML) could have positive
effects on improving the certified accuracy while GDL plays a major role in the larger radius. While
combining these two regularization loss together as our DRT loss, the ensemble model could achieve
the best certified accuracy among all the radii.
42