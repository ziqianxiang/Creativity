Under review as a conference paper at ICLR 2021
Sobolev Training for the Neural Network So-
lutions of PDEs
Anonymous authors
Paper under double-blind review
Ab stract
Approximating the numerical solutions of partial differential equations (PDEs)
using neural networks is a promising application of deep learning. The smooth
architecture of a fully connected neural network is appropriate for finding the so-
lutions of PDEs; the corresponding loss function can also be intuitively designed
and guarantees the convergence for various kinds of PDEs. However, the rate
of convergence has been considered as a weakness of this approach. This paper
introduces a novel loss function for the training of neural networks to find the
solutions of PDEs, making the training substantially efficient. Inspired by the
recent studies that incorporate derivative information for the training of neural
networks, we develop a loss function that guides a neural network to reduce the
error in the corresponding Sobolev space. Surprisingly, a simple modification of
the loss function can make the training process similar to Sobolev Training al-
though solving PDEs with neural networks is not a fully supervised learning task.
We provide several theoretical justifications for such an approach for the viscous
Burgers equation and the kinetic Fokker-Planck equation. We also present several
simulation results, which show that compared with the traditional L2 loss func-
tion, the proposed loss function guides the neural network to a significantly faster
convergence. Moreover, we provide the empirical evidence that shows that the
proposed loss function, together with the iterative sampling techniques, performs
better in solving high dimensional PDEs.
1	Introduction
Deep learning has achieved remarkable success in many scientific fields, including computer vision
and natural language processing. In addition to engineering, deep learning has been successfully
applied to the field of scientific computing. Particularly, the use of neural networks for the numerical
integration of partial differential equations (PDEs) has emerged as a new important application of
the deep learning.
Being a universal approximator (Cybenko, 1989; Hornik et al., 1989; Li, 1996), a neural network
can approximate solutions of complex PDEs. To find the neural network solution of a PDE, a neural
network is trained on a domain wherein the PDE is defined. Training a neural network comprises the
following: feeding the input data through forward pass and minimizing a predefined loss function
with respect to the network parameters through backward pass. In the traditional supervised learning
setting, the loss function is designed to guide the neural network to generate the same output as the
target data for the given input data. However, while solving PDEs using neural networks, the target
values that correspond to the analytic solution are not available. One possible way to guide the neural
network to produce the same output as the solution of the PDE is to penalize the neural network to
satisfy the PDE itself (Sirignano & Spiliopoulos, 2018; Berg & NyStrom, 2018; Raissi et al., 2019;
Hwang et al., 2020).
Unlike the traditional mesh-based schemes including the finite difference method (FDM) and the
finite element method (FEM), neural networks are inherently mesh-free function-approximators.
Advantageously, as mesh-free function-approximators, neural networks can avoid the curse of di-
mensionality (Sirignano & Spiliopoulos, 2018) and approximate the solutions of PDEs on complex
geometries (Berg & Nystrom, 2018). Recently, HWang et al. (2020) showed that neural networks
could approximate the solutions of kinetic Fokker-Planck equations under not only various kinds
1
Under review as a conference paper at ICLR 2021
of kinetic boundary conditions but also several irregular initial conditions. Moreover, they showed
that the neural networks automatically approximate the macroscopic physical quantities including
the kinetic energy, the entropy, the free energy, and the asymptotic behavior of the solutions. Further
issues including the inverse problem were investigated by Raissi et al. (2019); Jo et al. (2020).
Although the neural network approach can be used to solve several complex PDEs in various kinds
of settings, it requires relatively high computational cost compared to the traditional mesh-based
schemes in general. To resolve this issue, we propose a novel loss function using Sobolev norms
in this paper. Inspired by a recent study that incorporated derivative information for the training of
neural networks (Czarnecki et al., 2017), we develop a loss function that efficiently guides neural
networks to find the solutions of PDEs. We prove that the H 1 and H2 norms of the approximation
errors converge to zero as our loss functions tend to zero for the 1-D Heat equation, the 1-D viscous
Burgers equation, and the 1-D kinetic Fokker-Planck equation. Moreover, We show via several
simulation results that the number of epochs to achieve a certain accuracy is significantly reduced
as the order of derivatives in the loss function gets higher, provided that the solution is smooth. This
study might pave the way for overcoming the issue of high computational cost when solving PDEs
using neural networks.
The main contributions of this work are threefold: 1) We introduce novel loss functions that en-
able the Sobolev Training of neural networks for solving PDEs. 2) We prove that the proposed
loss functions guarantee the convergence of neuarl networks in the corresponding Sobolev spaces
although it is not a supervised learning task. 3) We empirically demonstrate the effect of Sobolev
Training for several regression problems and the improved performances of our loss functions in
solving several PDEs including the heat equation, Burgers’ equation, the Fokker-Planck equation,
and high-dimensional Poisson equation.
2	Related works
Training neural networks to approximate the solutions of PDEs has been intensively studied over
the past decades. For example, Lagaris et al. (1998; 2000) used neural networks to solve Ordinary
Differential Equations (ODEs) and PDEs on a predefined set of grid points. Subsequently, Sirignano
& Spiliopoulos (2018) proposed a method to solve high-dimensional PDEs by approximating the
solution using a neural network. They focused on the fact that the traditional finite mesh-based
scheme becomes computationally intractable when the dimension becomes high. However, because
neural networks are mesh-free function-approximators, they can solve high-dimensional PDEs by
incorporating mini-batch sampling. Furthermore, the authors showed the convergence of the neural
network to the solution of quasilinear parabolic PDEs under certain conditions.
Recently, Raissi et al. (2019) reported that one can use observed data to solve PDEs using physics-
informed neural networks (PINNs). Notably, PINNs can solve a supervised regression problem
on observed data while satisfying any physical properties given by nonlinear PDEs. A significant
advantage of PINNs is that the data-driven discovery of PDEs, also called the inverse problem,
is possible with a small change in the code. The authors provided several numerical simulations
for various types of nonlinear PDEs including the Navier-Stokes equation and Burgers’ equation.
The first theoretical justification for PINNs was provided by Shin et al. (2020), who showed that a
sequence of neural networks converges to the solutions of linear elliptic and parabolic PDEs in L2
sense as the number of observed data increases. There also exists a study aiming to enhance the
convergence of PINNs (van der Meer et al., 2020).
Additionally, several works related deep neural networks with PDEs but not by the direct approx-
imation of the solutions of PDEs. For instance, Long et al. (2018) attempted to discover the hid-
den physics model from data by learning differential operators. A fast, iterative PDE-solver was
proposed by learning to modify each iteration of the existing solver (Hsieh et al., 2019). A deep
backward stochastic differential equation (BSDE) solver was proposed and investigated in Weinan
et al. (2017); Han et al. (2018) for solving high-dimensional parabolic PDEs by reformulating them
using BSDE.
The main strategy of the present study is to leverage derivative information while solving PDEs via
neural networks. The authors of Czarnecki et al. (2017) first proposed Sobolev Training that uses
derivative information of the target function when training a neural network by slightly modifying
2
Under review as a conference paper at ICLR 2021
the loss function. They showed that Sobolev Training had lower sample complexity than regular
training, and therefore it is highly efficient in many applicable fields, such as regression and policy
distillation problems. We appropriate the concept of Sobolev Training to develop a loss function for
the efficient training of a neural network for solving PDEs.
3	Loss function
We consider the following Cauchy problem of PDEs:
Pu =	f,	(t, x)	∈ [0, T] X Ω,	(3.1)
Iu =	g,	(t, x)	∈ {0} × Ω,	(3.2)
Bu =	h,	(t,x)	∈ [0,T] × ∂Ω,	(3.3)
where P denotes a differential operator; I and B denote the initial and boundary operators, respec-
tively; f , g, and h denote the inhomogeneous term, and initial and boundary data, respectively. In
most studies that reported the neural network solutions of PDEs, a neural network was trained on
uniformly sampled grid points {(ti,xj)}NNt=NIx ∈ [0,T] × Ω, which were completely determined
before training. One of the most intuitive ways to make the neural network satisfy PDEs (3.1)-(3.3)
is to minimize the following loss functional:
Loss(unn ; p)
kPu
nn - fkLP([0,T]×Ω) + IIIunn - gkLP(Ω) + kBunn - hkLp([0,T]×∂Ω),
where unn denotes the neural network and p = 1 or 2, as they have been the most commonly used
exponents in regression problems in previous studies. Evidently, an analytic solution u satisfies
Loss(u) = 0, and thus one can conceptualize a neural network that makes Loss(unn) = 0 a
possible solution of PDEs (3.1)-(3.3). This statement is in fact proved for second-order parabolic
equations with the Dirichlet boundary condition in Jo et al. (2020), and for the Fokker-Planck equa-
tion with inflow and specular reflective boundary conditions in Hwang et al. (2020). Both the proofs
are based on the following inequality:
Ilu — unn∣L∞(0,TZ2(Ω)) ≤ CLoSS(unn； 2),
for some constant C, which states that minimizing the loss functional implies minimizing the ap-
proximation error.
The main concept behind Sobolev Training is to minimize the error between the output and the target
function, and that between the derivatives of the output and those of the target function. However,
unlike the traditional supervised regression problem, neither the target function nor its derivative is
provided while solving PDEs via neural networks. Thus, a special treatment is required to apply
Sobolev Training for solving PDEs using neural networks. In this and the following sections, we
propose several loss functions and prove that they guarantee the convergence of the neural network
to the solution of a given PDE in the corresponding Sobolev space. Therefore, the proposed loss
functions play similar roles to those in Sobolev Training.
We define the loss function that depends on the Sobolev norm Wk,p as follows:
LossGE (unn； k,P,l, q) = |||P (unn(t, ∙)) - f (t, ∙)k W ι,q g)([ k,p([Q TD ,	(3.4)
LossIC (unn； l,q) = ∣Iunn(t,x) - g(x)∣∣W ι,q g),	(3.5)
LossBC (Unn； k,P,l,q) = ||kBunn(t, ∙) - h(t, ∙)kW ι,q (∂Ω)lw kp([Q 邛)∙	(3.6)
Remark 3.1. Here, Loss(T0O) TAL (unn) = LossGE(unn； 0, 2, 0, 2) + LossIC(unn； 0, 2) +
LossBC (unn； 0, 2, 0, 2) coincides with the traditional L2 loss function employed by Sirignano &
SpiIiopouIos (2018); Berg & Nystrom (2018); Raissi et al.(20l9); Hwang et al. (2020).
When we train a neural network, the loss functions (3.4)-(3.6) are computed by Monte-Carlo ap-
proximation. Because the grid points are uniformly sampled, the loss functions are approximated as
follows:
LossGE (unn； k, p, l, q) ≈
T ∣Ω∣
NtNx
Nt
XX
∣β∣≤k i=1
dβ	Nx
而 E Σ∣DaP (unn(ti,Xj ))— Dfti.Xj )|q
∣α∣≤l j = l
3
Under review as a conference paper at ICLR 2021
∣ΩI 一二.一	,
LossIC (Unn； l,q) ≈ NE El。Unn(O,Xj) - D g(xj )lq,
xX ∣α∣≤lj = 1
p
T T 一 一 .	T l∂Ωl L 也 dβ L L ,—	,	.	____ …
LossBC (Unn； k,p,l,q) ≈ N N~ ) :): dtβ〉:〉: |D unn(ti, Xj) - D h(ti, Xj) |	,
t B ∣β∣≤ki=1	∣α∣≤lxj∈∂Ω
where α and β denote the conventional multi-indexes, and D denotes the spatial derivatives.
4	Theoretical Results
In this section, we theoretically validate our claim that our loss functions guarantee the convergence
of the neural network to the solution of a given PDE in the corresponding Sobolev spaces, and
that they play a similar role to those in Sobolev Training while solving PDEs via neural networks.
Throughout this section, we will denote the strong solution of each equation by U, neural network
solution by Unn, and Sobolev spaces W 1,2 and W2,2 by H1 and H2, respectively. All the proofs
are provided in the Appendix.
4.1	The heat equation and Burgers’ equation
We define the following three total loss functions for the heat equation and Burgers’ equation:
Loss(T0O) TAL (Unn) = LossGE(Unn； 0, 2, 0, 2) + LossIC (Unn； 0, 2) + LossBC (Unn； 0, 2, 0, 2),
(4.1)
LossT OT AL (Unn) = LossGE (Unn； 0, 2, 0, 2) + LossI C (Unn； 1, 2) + LossBC (Unn； 0, 2, 0, 2),
(4.2)
(2)
LossT OT AL (Unn) = LossGE (Unn； 1, 2, 0, 2) + LossI C (Unn； 2, 2) + LossBC (Unn； 0, 2, 0, 2).
(4.3)
We then obtain the following convergence theorem:
Theorem 4.1.	(Proofs are provided in (A.5) for the heat equation, and (A.8) for Burgers’ equation)
For the following 1-D heat and Burgers’ equations:
The heat equation	Burgers, equation
Ut 一 UXX = 0 in (0,T] X Ω,- u(0, x) = uo(x) on Ω, u(t, x) = 0 on [0, T] × ∂Ω,	Ut + uuχ — νuχχ = 0 in (0, T] × Ω, u(0, x) = Uo(x) on Ω, U(t, x) = 0 on [0, T] × ∂Ω,
there hold, provided that Unn is smooth,
0maT ku(t) - unn(t)kL2(Ω) → 0 as LoSSTOTAL
→ 0,
eSS SUP ∣∣u(t) - Unn(t)kH 1(Ω) → 0 as LossTO TAL → 0，
0≤t≤T	0
eSSSUp ∣∣u(t) - Unn(t)∣H2(Ω) → 0 as LossTOTAL → 0.
0≤t≤T
4.2 THE FOKKER-PLANCK EQUATION
For the Fokker-Planck equation, We need additional parameters for a new input variable v. We
define the following two total loss functions for the Fokker-Planck equation:
(0;FP)
LossT OT AL(Unn) = LossGE (Unn； 0, 2, 0, 2, 0, 2) + LossI C (Unn； 0, 2, 0, 2)
+ LossBC (Unn； 0, 2, 0, 2, 0, 2),	(4.4)
4
Under review as a conference paper at ICLR 2021
LossT OT AL(unn) = LossGE (unn; 0, 2, 1, 2, 1, 2) + LossI C (unn; 1, 2, 1, 2)
+ LossBC(unn; 0, 2, 0, 2, 0, 2).	(4.5)
We then have the following convergence theorem:
Theorem 4.2.	(Proofs are provided in (A.10) and (A.12)) For the 1-D Fokker-Planck equation with
the periodic boundary condition:
ut +	vux	- β(vu)v - quvv	=	0, for (t, x, v) ∈ [0, T] × [0, 1] ×	R,
u(0, x, v)	=	u0 (x, v), for (x, v) ∈ [0, 1] × R,
∂tα,x,vu(t, 1,v) - ∂tα,x,v u(t, 0, v) = 0, for (t, v) ∈ [0,T] × R,
there hold, under assumptions (A.50) and (A.51),
(0;FP)
sup Ilu⑴-Unn⑴IlL2(Ω×[-V,V]) → 0 as LossTOTAL → 0,
0≤t≤T
sup ∣∣u(t) - unn⑴kH1(Q;L2([-V,V])) → 0 as LossTOTAL → 0.
0≤t≤T
Remark 4.3. The theorems in this section imply that the proposed loss functions guarantee the
convergence of neural networks in the corresponding Sobolev spaces, thereby coinciding with the
main idea of Sobolev Training.
Remark 4.4. The theorems in this section cannot be directly generalized to the high-dimensional
cases because even the 2-dimensional case starts involving the convexity of the boundary. Though
it has also been shown that the Fokker-Planck operator has strong hypoellipticity and the solutions
to the boundary problems are smooth even in the higher dimensional case, the proof requires long
rigorous mathematical analysis. For more information, see Hwang et al. (2018; 2019).
Remark 4.5. Because we cannot access the label (which corresponds to the analytic solution) on the
interior grid, solving PDEs using a neural network is not a fully supervised problem. Interestingly,
by incorporating derivative information in the loss function, the proposed approach enables Sobolev
Training even if neither the labels nor the derivatives of the target function are provided.
5 Experimental Results
In this section, we provide experimental results for toy examples that comprise several regression
problems and various kinds of differential equations, including the heat equation, Burgers’ equa-
tion, the kinetic Fokker-Planck equation, and high-dimensional Poisson's equation. We employ a
fully connected neural network, which is a natural choice for function approximation. We use the
hyperbolic tangent function as a nonlinear activation function. Although ReLU (x) = max(0, x) is
a frequent choice in modern machine learning, it is not appropriate for solving PDEs because the
second derivatives of the neural network vanish.
In appreciation of Automatic Differentiation, we can easily compute derivatives of any order of
a neural network with respect to input data despite the compositional structure; see Baydin et al.
(2017) and references therein. We implemented our neural network using PyTorch, a widely used
deep learning library (Paszke et al., 2019). For the numerical experiments, we used a neural net-
work with three hidden layers each of which had d-256-256-256-1 neurons, where d denotes the
input dimension. We used the ADAM optimizer (Kingma & Ba, 2014), a popular gradient-based
optimizer.
To see whether our loss functions performed more efficiently than the traditional L2 loss function
introduced in Remark 3.1, we made everything maintain the same except the loss function. We
compared the loss functions on the basis of L2 (Ω) test error for the toy examples, absolute relative
test error for the high-dimensional Poisson equation, and L∞(0, T; L2(Ω)) test error for the other
PDEs. For each loss function, we recorded the number of epochs required to meet a certain error
threshold and the test error. Considering the randomness due to network initialization, we repeated
the training a hundred times. Conversely, we initialized a hundred different neural networks with
uniform initialization and trained them in the same manner. To compute the test error, we used ana-
lytic solutions for the Heat equation, Burgers’ equation, and the high-dimensional Poisson equation,
and a numerical solution from Wollman & Ozizmir (2008) for the kinetic Fokker-Planck equation.
5
Under review as a conference paper at ICLR 2021
5.1	Toy examples
First, we consider two simple regression problems with target functions sin(x) and ReLU (x), re-
spectively. For these toy examples, we define the loss functions as follows:
L2 loss = kunn(x) - y(x)k22,
H1 loss =	kunn(x) -	y(x)k22 +	ku0nn(x)	-	y0(x)k22,
H2 loss =	kunn(x) -	y(x)k22 +	ku0nn(x)	-	y0(x)k22 +	ku0n0n(x)	- y00(x)k22,
where y(x) denotes either sin(x), or ReLU (x). We uniformly sampled a hundred grid points from
[0, 2π] for training sin(x). Similarly, we uniformly sampled a hundred grid points from [-1, 1]
for training ReLU (x). We expected the training to become fast using higher order derivatives as
many as possible when training sin(x) and ReLU (x). Figure 1 confirms our assumption to be true.
Interestingly, although ReLU (x) is not twice weakly differentiable at only one point x = 0, the H2
loss does not facilitate the training.
ReLU(x) / Number of Epochs	ReLU(x) / Error Plot	ReLU(x) / Time Plot
Number of Epochs	Number of Epochs	Loss functions
Figure 1: First row: results for sin(x), Second row: results for ReLU (x). First column: Histograms
generated from the repeated training of neural networks for training sin(x), and ReLU (x). Second
column: Test L2 errors. Third column: Average training time for each loss function to achieve
certain error threshold. Error bars are for standard deviations. The thresholds for the error are set to
10-4.
In order to explore the nature of Sobolev Training, we design more complicated toy examples.
Consider the target functions sin(kx), for k = 1, 2, ..., 5, and ReLU (kx) = max(0, kx), for
k = 1, 2, 3..., 10. As k increases, the target functions and their derivatives contain drastic changes
in their values, so it is difficult to learn those functions. We hypothesize that in Sobolev Training,
the training becomes faster since we give explicit label for the derivatives and it becomes easier to
capture the drastic changes in the derivatives. This is empirically shown to be true in Figure 2. We
train neural networks to approximate sin(kx), and ReLU(kx) for different k and record the number
of training epochs to achieve certain error threshold which can be regarded as a difficulty of the
problem. As one can see in Figure 2, the difficulty changes little to no when we train with H1 and
H2 losses while the difficulty increases with k when L2 loss is used. This implies that the difficulty
of training barely changes in Sobolev Training even the target function has stiff changes. The same
observations are made when solving PDEs. The improvement of our loss functions compare to L2
loss function are more dramatic for Burgers’ equation (which has stiff solution (Raissi et al., 2019))
than for the heat equation, with the initial condition of f2 (which has a higher frequency) than with
the initial condition of f 1 initial condition in the Fokker-PlanCk equation, and as k increases for the
high-dimensional Poisson equation 7.
5.2	The heat equation & B urgers’ equation
We now demonstrate the results of the Sobolev Training of the neural networks for solving PDEs. We
begin with the 1-D heat equation, and Burgers’ equation, which is the simplest PDE that combines
both the nonlinear propagation effect and diffusive effect. Burgers’ equation often appears as a
6
Under review as a conference paper at ICLR 2021
Figure 2: Average number of epochs to make error less than 10-3 increases in L2 loss as k increases.
However, when we use H1, and H2 losses, required number of epochs increases much more slowly
or stays the same as k increases.
simplification of a more complex and sophisticated model, such as the NaVier-Stokes equation. The
equations with the homogeneous Dirichlet boundary condition read as follows:
The Heat equation	Burgers, equation
ut - uxx = 0 in (0, 10] × [0, π], u(0, X) = sin(X) on [0, π], u(t, X) = 0 on [0, 10] × {0, π}.	Ut + Uux — 0.2Uxx = 0 in (0, 0.01] × [0,1], u(0, X) = - sin(πX) on [0, 1], 	u(t,χ) = 0 on [0, 0.01] × {0,1}.
The heat equation attains a unique analytic solution u(t, x) = sin(x) exp(-t); an analytic solution
of Burgers’ equation is proVided in BasdeVant et al. (1986).
Although Sirignano & Spiliopoulos (2018) indicated that iteratiVe random sampling reduces the
computational cost, we fixed the grid points before training because we aimed to compare the effi-
ciency of our loss function with that of the traditional one. For the heat equation and the Burgers’
equation, We uniformly sampled the grid points {ti, Xj }Nt=N1x from (0, T] X Ω, where Nt and Nx
denote the number of samples for interior t and x, respectiVely. For the initial and boundary condi-
tions, we sampled the grid points from {t = 0, Xj },1 ∈ {0} × Ω and {ti, Xj }Nt=NB ∈ [0, T] × ∂Ω,
respectively, where NB denotes the number of grid points in ∂Ω. Here, we set Nt ,Nx, NB = 31.
The testing data were also uniformly sampled from the domain of the PDEs.
The L2, H1, and H2 losses are the Monte-Carlo approximations of (4.1), (4.2), and (4.3), respec-
tively, for the heat equation and Burgers’ equation. Working on achieving a smooth solution, we
observed that the H2 loss performed the best, followed by the H1 loss and then the L2 loss in both
accuracy, and computation time. We show the corresponding results in Figure 3.
5.3	The Fokker–Planck equation
The kinetic Fokker-Planck equation describes the dynamics of a particle whose behavior is similar
to that of the Brownian particle. The Fokker-Planck operator has a strong regularizing effect not
just in the velocity variable but also in the temporal and the spatial variables by the hypoellipticity.
The Fokker-Planck equation has been considered in numerous physical circumstances including the
Brownian motion described by the Uhlenbeck-Ornstein processes.
We provide two simulation results for different initial conditions for the 1-D Fokker-Planck equation
with the periodic boundary condition. For the Fokker-Planck equation, we adopted the idea of
sampling from Hwang et al. (2020). Because it is practically difficult to consider the entire space
for the v ∈ R variable, we truncated the space for v as [-5, 5]. We then uniformly sampled the grid
points {ti, Xj ,vk }NNt,N=XINv from (0, T ] × Ω × [-5, 5], where Nv denotes the number of samples for
v . The grid points for the initial and periodic boundary conditions were accordingly sampled. The
truncated equation reads as follows:
ut + vux - β(vu)v - quvv = 0, for (t, X, v) ∈ (0, 3] × [0, 1] × [-5, 5],
u(0, X, v) = f(X, v), for (X, v) ∈ [0, 1] × [-5, 5],
∂tα,x,vu(t,1,v) - ∂tα,x,vu(t,0,v) = 0, for (t, v) ∈ [0, 3] × [-5, 5],
7
Under review as a conference paper at ICLR 2021
Figure 3: First row: results for the heat equation. Second row: results for Burgers’ equation. First
column: Histograms for the heat and Burgers’ equation generated from a hundred neural networks
for each loss function. Second column: Test L∞ (0,T; L2 (Ω)) errors. Third column: Average
training time for each loss function to achieve certain error threshold. Error bars are for standard
deviations. The thresholds for the error are set to 10-5 .
Where f(X,v) 认 e^er fι(X,v) = R-5eχχp-⅞dv, or f2 (x,v) = R0 /-((>:忆::/刖,
and β = 0.1, q = 0.1.
A numerical solution on the test data Was computed by a method shoWn by Wollman & Ozizmir
(2008) and used for computing the test error. L2 loss and H1 loss denote the Monte-Carlo approx-
imations of (4.4) and (4.5), respectively. The values of Nt, Nx, and Nv Were set to be 31, and the
grid points were uniformly sampled. Expectedly, a solution of the Fokker-Planck equation could be
estimated substantially faster using our loss function in both cases. We have provided the detailed
results in Figure 4.
b(x, V) Error Plot
Figure 4: First row: results for f1 initial condition. Second row: results for f2 initial condition.
First column: Histograms generated from a hundred neural networks for each loss function. Second
column: Test L∞ (0, T; L2 (Ω)) errors. Third column: Average training time for each loss function
to achieve certain error threshold. Error bars are for standard deviations. The thresholds for the
errors for the initial conditions f1(X, v), and f2(X, v) are set to 10-4, and 10-3, respectively.
5.4	The High-dimensional Poisson equation
The Poisson equation serves as an example problem in the recent literature; see Weinan & Yu (2018);
Hsieh et al. (2019); Zang et al. (2020). In this section, we provide empirical results to demonstrate
8
Under review as a conference paper at ICLR 2021
that the proposed loss functions perform satisfactorily when equipped with iterative sampling for
solving high-dimensional PDEs; see Sirignano & Spiliopoulos (2018) for more information. Con-
vergence result similar to those of in section 4 for the Poisson equation is given in section A.4. We
consider the following high-dimensional Poisson equation with the Dirichlet boundary condition:
π2 d	π
—4u = ɪ ^X sin( —Xi), for X ∈ Ω = (0,1)d,
4 i=1	2
d
U = ɪ2sin(qXi), for X ∈ ∂Ω,
i=1	2
where X = (χ1,χ2,…，Xd) ∈ Ω. One can readily prove that U(X) = Pid=1 sin(∏2Xi) is a strong
solution. We compare the following three loss functions with each other:
Loss(0;Poisson) (U ) ossT OT AL	(Unn)	LossGE (Unn; 0, 2) + LossBC (Unn; 0, 2),	(5.1)
Loss(1;Poisson) (U ) ossT OT AL	(Unn)	LossGE (Unn; 1, 2) + LossBC (Unn; 0, 2),	(5.2)
Loss(2;Poisson) (U ) ossT OT AL	(Unn)	LossGE (Unn; 1, 2) + LossBC (Unn; 1, 2).	(5.3)
Notably, the aforementioned loss functions have the variable X only. Table 1 presents the relative
errors on a predefined test set for d = 10, 50, and 100. Evidently, in all cases, the proposed loss
functions outperform the traditional L2 loss function. More detailed experimental results are given
in section B.
Table 1: Average of the relative errors of a hundred neural networks for the high-dimensional Pois-
son's equations. We uniformly sampled 500 data points from Ω for each epoch and trained the neural
networks in 10000 epochs at a learning rate 10-4.
Dimension	(0;P oisson) LossTOTAL	L	(1;P oisson) LossTOTAL	L	(2;P oisson) LossT OT AL
10	0.38%	022%	0.22%
50	2.00%	1.74%	1.52%
100	3.15%	3.06%	2.89%
6 Discussion and Conclusion
Inspired by Sobolev Training, we proposed novel loss functions, which efficiently guided the training
of neural networks for solving PDEs. We theoretically justified that the proposed loss functions
guaranteed the convergence of a neural network to a solution of PDEs in the corresponding Sobolev
spaces. We also discussed that the proposed theorems imply that the training becomes Sobolev
Training by slightly modifying the loss function, although the process of estimating neural network
solutions of PDEs is not fully supervised.
In addition to the toy examples, which showed the exceptional speed of Sobolev Training, we pro-
vided empirical evidences demonstrate that our loss functions expedited the training more than the
traditional L2 loss function. We believe that this can solve the problem associated with the high
costs involved in estimating the neural network solutions of PDEs. Moreover, our experiments on
high-dimensional problems showed that the proposed loss function performed better when equipped
with iterative grid sampling. The histograms in Figure 1-4 indicate that our loss function provided
more stable training in that it reduced the variance in the distribution of the number of epochs (e.g.,
for the Burgers’ equation, L2 loss: 3651±812, H1 loss: 995±71, and H2 loss: 331±15). Thus,
the training, when governed by our loss function, became robust to the random initialization of the
weights.
References
Cea Basdevant, M Deville, P Haldenwang, JM Lacroix, J Ouazzani, R Peyret, Paolo Orlandi, and
AT Patera. Spectral and finite difference solutions of the Burgers equation. Computers & Fluids,
14(1):23-41,1986.
9
Under review as a conference paper at ICLR 2021
Atilim Gunes Baydin, Barak A Pearlmutter, Alexey Andreyevich RadUL and Jeffrey Mark Siskind.
Automatic differentiation in machine learning: a survey. The Journal of Machine Learning Re-
search,18(1):5595-5637, 2017.
Yassine Benia and Boubaker-Khaled Sadallah. Existence of solutions to Burgers equations in do-
mains that can be transformed into rectangles. Electron. J. Differential Equations, pp. Paper No.
157, 13, 2016.
Jens Berg and Kaj Nystrom. A unified deep artificial neural network approach to partial differential
equations in complex geometries. Neurocomputing, 317:28-41, 2018.
George Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics of Con-
trol, Signals and Systems, 2(4):303-314, 1989.
Wojciech M Czarnecki, Simon Osindero, Max Jaderberg, Grzegorz Swirszcz, and Razvan Pascanu.
Sobolev training for neural networks. In Advances in Neural Information Processing Systems, pp.
4278-4287, 2017.
Lawrence C. Evans. Partial differential equations. American Mathematical Society, Providence,
R.I., 2010. ISBN 9780821849743 0821849743.
Jiequn Han, Arnulf Jentzen, and E Weinan. Solving high-dimensional partial differential equations
using deep learning. Proceedings of the National Academy of Sciences, 115(34):8505-8510,
2018.
Kurt Hornik, Maxwell Stinchcombe, Halbert White, et al. Multilayer feedforward networks are
universal approximators. Neural Networks, 2(5):359-366, 1989.
Jun-Ting Hsieh, Shengjia Zhao, Stephan Eismann, Lucia Mirabella, and Stefano Ermon. Learning
neural PDE solvers with convergence guarantees. arXiv preprint arXiv:1906.01200, 2019.
Hyung Ju Hwang, Juhi Jang, and Jaewoo Jung. The Fokker-Planck equation with absorbing bound-
ary conditions in bounded domains. SIAM J. Math. Anal., 50(2):2194-2232, 2018. ISSN 0036-
1410. doi: 10.1137/16M1109928. URL https://doi.org/10.1137/16M1109928.
Hyung Ju Hwang, Juhi Jang, and Juan J. L. Velazquez. On the structure of the singular set for the
kinetic Fokker-Planck equations in domains with boundaries. Quart. Appl. Math., 77(1):19-70,
2019. ISSN 0033-569X. doi: 10.1090/qam/1507. URL https://doi.org/10.1090/qam/
1507.
Hyung Ju Hwang, Jin Woo Jang, Hyeontae Jo, and Jae Yong Lee. Trend to equilibrium for the kinetic
Fokker-Planck equation via the neural network approach. Journal of Computational Physics, pp.
109665, 2020.
Hyeontae Jo, Hwijae Son, Hyung Ju Hwang, and Eun Heui Kim. Deep neural network approach to
forward-inverse problems. Networks & Heterogeneous Media, 15(2):247-259, 2020.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Isaac E Lagaris, Aristidis Likas, and Dimitrios I Fotiadis. Artificial neural networks for solving
ordinary and partial differential equations. IEEE Transactions on Neural Networks, 9(5):987-
1000, 1998.
Isaac E Lagaris, Aristidis C Likas, and Dimitris G Papageorgiou. Neural-network methods for
boundary value problems with irregular boundaries. IEEE Transactions on Neural Networks, 11
(5):1041-1049, 2000.
Xin Li. Simultaneous approximations of multivariate functions and their derivatives by neural net-
works with one hidden layer. Neurocomputing, 12(4):327-343, 1996.
Zichao Long, Yiping Lu, Xianzhong Ma, and Bin Dong. Pde-net: Learning pdes from data. In
International Conference on Machine Learning, pp. 3208-3216, 2018.
10
Under review as a conference paper at ICLR 2021
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-
performance deep learning library. In Advances in Neural Information Processing Systems, pp.
8024-8035, 2019.
Maziar Raissi, Paris Perdikaris, and George E Karniadakis. Physics-informed neural networks: A
deep learning framework for solving forward and inverse problems involving nonlinear partial
differential equations. Journal of Computational Physics, 378:686-707, 2019.
Yeonjong Shin, Jerome Darbon, and George Em Karniadakis. On the convergence and generaliza-
tion of physics informed neural networks. arXiv preprint arXiv:2004.01806, 2020.
Justin Sirignano and Konstantinos Spiliopoulos. Dgm: A deep learning algorithm for solving partial
differential equations. Journal of Computational Physics, 375:1339-1364, 2018.
Remco van der Meer, Cornelis Oosterlee, and Anastasia Borovykh. Optimally weighted loss func-
tions for solving pdes with neural networks. arXiv preprint arXiv:2002.06269, 2020.
E Weinan and Bing Yu. The deep ritz method: a deep learning-based numerical algorithm for solving
variational problems. Communications in Mathematics and Statistics, 6(1):1-12, 2018.
E Weinan, Jiequn Han, and Arnulf Jentzen. Deep learning-based numerical methods for high-
dimensional parabolic partial differential equations and backward stochastic differential equa-
tions. Communications in Mathematics and Statistics, 5(4):349-380, 2017.
Stephen Wollman and Ercument Ozizmir. A deterministic particle method for the vlasov-fokker-
planck equation in one dimension. Journal of Computational and Applied Mathematics, 213(2):
316-365, 2008.
Yaohua Zang, Gang Bao, Xiaojing Ye, and Haomin Zhou. Weak adversarial networks for high-
dimensional partial differential equations. Journal of Computational Physics, pp. 109409, 2020.
A Proofs for the Theorems in Section 4
We begin with the basic definitions of Sobolev spaces. We excerpt the definitions from Evans (2010).
Definition A.1. Suppose u, v ∈ Ll1oc (U) and α is a multiindex. We say that v is the αth-weak
derivative of u, written
Dαu = v,
provided
/ uDαφdx = (-1)'a' j vφdx,
for all test functions φ ∈ Cc∞ (U).
Now we define the Sobolev space. Fix 1 ≤ p ≤ ∞ and let k be a nonnegative integer.
Definition A.2. The Sobolev space Wk,p(U) consists of all locally integrable functions u : U → R
such that for each multiindex a with |a| ≤ k, Da exists in the weak sense and belongs to LP(U).
Note that ifp = 2, we usually write Hk (U) = W k,2(U) (k = 0, 1, 2, ...).
The Sobolev norms are defined as follow:
Definition A.3. If u ∈ Wk,P(U), we define its norm to be
kuk	=/(P∣a∣≤k RU1DWpdx)" (I ≤ P ≤∞),
W ,t(U))— (p∣a∣≤k eSSSUPu Ou1 (P = ∞).
Finally, we define a notion of convergence in Sobolev spaces.
Definition A.4. Let {um}m∞=1, u ∈ W k,P(U). We say um converges to u in Wk,P(U) provided
lim kum - ukWk,p(U) = 0.
m→∞
11
Under review as a conference paper at ICLR 2021
A. 1 The heat equation
We denote the strong solution of the heat equation
ut - Uxx = 0 in (0, T] × ω,
u(0, x) = uo(x) on Ω,
u(t, x) = 0 on [0, T] X ∂Ω,
by u and the neural network solution by unn . Then, v = u - unn satisfies:
Vt - Vxx = f (t, x) in (0,T] × Ω,
v(0,x) = g(x) on Ω,	(A.1)
v(t, x) = 0 on [0, T] × ∂Ω,
for some f, and g. Here, we can set the boundary to be zero by multiplying B(x), where B(x) is a
smooth function satisfying B(x) = 0, x ∈	. Then the following holds:
6= 0, X ∈ Ω
Theorem A.5. (Theorem 7.1.5 in Evans (2010)) If g ∈ H2 (Ω),ft ∈ L2(0,T; L2(Ω)) ,then,
0mt≤τ kv(t)kL2(Ω)		≤	CI(IIfkL2(0,T Z2(Ω))	+ llgkL2(Ω)),	(A.2)
ess sup kV 0≤t≤τ	(t)kH0 (Ω)	≤	C2(IIfkL2(0,T Z2(Ω))	+ llgkHi(Ω)),	(A.3)
ess sup kV 0≤t≤τ	(t)kH2 (Ω)	≤	C3(IIfkH1(0,T ;L2(Q))	+ llgkH2(Ω)),	(A.4)
for some C1 , C2 , C3.
By applying above theorem to (A.1), we get the results of Theorem 4.1.
Remark A.6. The left hand sides in (A.2) - (A.4) are the errors of neural networks in corresponding
norms, and the right hand sides are the losses (4.1) - (4.3) for the heat equation, respectively. This
implies that the proposed loss functions are the upper bounds of the errors in the Sobolev spaces, and
by minimizing them, we can expect the effect of Sobolev Training when solving PDEs with neural
networks.
In the rest of this section, We will show the similar results for Burgers, equation and the Fokker-
Planck equation.
A.2 Burgers’ equation
We consider the strong solution U of the following Burgers equation in a bounded interval Ω = [a, b],
∂tu	+ UdxU —	∂xu = 0 in Ω,	(A.5)
u = 0 on ∂Ω,	(A.6)
and the corresponding neural network solution Unn satisfying
∂tUnn	+	Unn ∂x Unn	- ∂x Unn	= f in	Ω,	(A.7)
Unn	= 0 on	∂Ω.	(A.8)
with the inital data u(0, ∙) and Unn(0, ∙), respectively.
The following proposition ensures the existence of a strong solution to the initial boundary value
problem (A.5)-(A.6) (see Benia & Sadallah (2016)). Here, we multiply B(x) to Unn(t, x) in order
to meet the boundary condition. We use the notation . where the relation A . B stands for
A ≤ CB, where C denotes a generic constant.
Proposition A.7. (Theorem 1.2 in Benia & Sadallah (2016)) Let U0 ∈ H01. Then there exists a time
T * = T *(uo) > 0 such that the problem (A.5)-(A.6) with initial data uo has a unique solution of U
satisfying
U ∈ L2(0,T*; H2(Ω)) ∩ C([0,T*); H1(Ω)),
Ut ∈ L2(0,T*;L2(Ω)).
Furthermore, if T* < ∞, then IlUkHi(Ω) → ∞ as t → T*.
12
Under review as a conference paper at ICLR 2021
We will show that the following theorem holds.
Theorem A.8. Let U and Unn be strong solutions of(A.5)-(A.6) and (A.7)-(A.8) respectively, on the
time interval [0, T]. For w := unn - u, following statements are valid.
(1)
There exists a continuous function
F0 = Fo (kw(0, Bk2,/ kfk2dt∕ kdxuk2dt)
such that
T
sup kwk22 +	k∂xwk22dt ≤ F0 → 0,
0≤t≤T	0
as
T
kw(0,∙)k2, / kfk2dt → 0.
0
(2)
There exists a continuous function
FI = FI (kw(O, ∙)kH,/ kfk2dt,/ Ildxul∣2dt)
such that
T
sup kwk2H1 +	k∂xwk2H1 + k∂twk22dt ≤ F1 → 0,
o≤t≤T	o
(A.9)
as
T
kw(0, ∙)kH1,	kfk2dt → 0.
0
(3)
There exists a continuous function
F = F2 kw(0, ∙)kH2/kfk2 + Mtfk2dt,0≤UPτkdxuk2 + 0T kdtuk2dt
such that
sup (kwkH2 + kwt
0≤t≤T
T
k∂xwk2H2 dt ≤ F2 → 0,
(A.10)
as
T
kw(0, ∙)kH2,	kfk2 + k∂tfk2dt → 0.
0
Remark A.9. By the Morrey's embedding theorem and the Poincare's inequality, for f ∈ H1(Ω),
we have the following inequality,
kfk2∞ . kfk22+kfxk22 . kfxk22,
(A.11)
Throughout the proof, we widely use (A.11).
Proof. Subtracting (A.5) from (A.7), we get equations of w as follows.
Wt — Wxx + Wwx + Wux + uwx = f in Ω,
W = O on ∂Ω,
w(0, ∙) = g in Ω.
(A.12)
(A.13)
(A.14)
By multiplying W to (A.12) and integrating by parts in Ω, We have
2 d kWk2 + llWxk2
(A.15)
13
Under review as a conference paper at ICLR 2021
fw -	w2wx -	w2ux - uwwx + wwx,
5
XIk0.
k=1
Now we estimate the terms on the right hand side of (A.15). Applying the Young’s inequality, the
Holder's inequality, the Sobolev inequality, and thd Poincare inequality, we have
I10	≤ IfI2IwI2. IfI22+IwI22 .IfI22+IwxI22,	(A.16)
I20	11	1 =J	3w = 3w3(b) - 3w3(a) = 0,	(A.17)
I30	≤ IwI∞ IwI2 Iux I2 . Iwx I2 IwI2 Iux I2, . IuxI22IwI22 + IwxI22,	(A.18)
I40	≤ IuI∞IwI2IwxI2. IuxI22IwI22 + IwxI22,	(A.19)
I50	= w(b)wx (b) - w(a)wx(a) = 0,	(A.20)
for any small e > 0. Applying estimates (A.16)-(A.20) to (A.15), We have the following inequality
ddtkwk2 + Mxk2.3k2IM2 + kfk2,
(A.21) and the Gronwall inequality imply that
sup kwk22	.	eR0Tkuxk22dt	kgk22 +Z	kfk22dt	.
0≤t≤T	0
(A.21)
(A.22)
Let us denote
Z kuxk22dt = β
0
Now we integrate (A.21) between 0 andT and drop the term w(T)22 on the left-hand side to obtain
TT
kwxk2dt. kgk22 +	kuxk22kwk22+kfk22dt
00
.(βeβ+1) kgk22+ZTkfk22dt .
This completes the proof of (1) of Theorem A.8.
Next, by multiplying -Wxx to (A.12) and integrating by parts in Ω, we obtain
2 加 I∣wxk2 + Ilwxx I∣2
= -	fwxx +	wwxwxx + uxwwxx +	uwxwxx +	wtwx,
5
= X Ik1.
k=1
Similarly to (A.16)-(A.20), we estimate the terms on the right hand side of (A.24).
(A.23)
(A.24)
I11	≤	IfI2IwxxI22. IfI22+IwxxI22,	(A.25)
I21	≤	IwI∞IwxI2IwxxI2 . IwxI4 + IwxxI22,	(A.26)
I31	≤	IwI∞ Iux I2 Iwxx I2 . IuxI2 IwxI2 + Iwxx I2,	(A.27)
I41	≤	IuI∞ Iwx I2 Iwxx I2 . Iux I2 Iwx I2 + IwxxI2,	(A.28)
I51	=	wt(b)wx(b) - wt(a)wx(a) = 0.	(A.29)
14
Under review as a conference paper at ICLR 2021
for any small e > 0. Applying estimates (A.25)-(A.29) to (A.24), We have the following inequality
ddt kwχk2 + kwxx k2. (kwχk2 + kuχk2)kwχk2 + kfk2.
It follows from (A.23), (A.30), and the Gronwall inequality that
(A.30)
sup kwxk22	.	eR0T kwxk22+kuxk22dt	kgxk22 +Z	kfk22dt
0≤t≤T	0
.eβeF0 kgxk22+ZTkfk22dt .
(A.31)
In a similar way to (A.23), there exists a function FI = FI(IIfllL2(0,τ炉)，l∣g∣∣H 1 ,β) SUch that
Z T IwxxI22dt. F1.
0
(A.32)
(2) of Theorem A.8 follows from (A.31), (A.32), and the fact that
wt = f + wxx - wwx - wux - uwx .
(A.33)
Finally, we differentiate (A.12) with respect to t, then we obtain
wtt - wxxt + wtwx + wwxt + wtux + wuxt + utwx + uwxt = ft
wt = 0
wt(0) = f + gxx - ggx - gu0x - u0gx
By multiplying Wt to (A.34) and integrating by parts in Ω, we have
2 dt llwtk2 + llwxtk2
in Ω,
on ∂Ω,
in Ω.
(A.34)
(A.35)
(A.36)
(A.37)
=	ftwt -	wt2wx -	wwtwxt -	wt2ux
-	wwtuxt -	utwtwx -	uwtwxt +	wtwxt,
8
=XIk2.
k=1
Terms on the right hand side of (A.37) are estimated by
I12≤ lftl2lwtl2. lftl22+lwxtl22,
I22 ≤ lwt l∞ lwt l2 lwx l2 . lwx l22 lwt l22 + lwxt l22,
I32 ≤ lwl∞lwtl2lwxtl2 . lwxl22lwtl22 +lwxtl22,
I42 ≤ lwtl∞lwtl2luxl2 . luxl22lwtl22 +lwxtl22,
I5 + I6	=	wwxtut	≤ lwl∞ lut l2 lwxt l2 . lut l2 lwtl2 + lwxtl2,
Jω
I72≤ lul2lwtl2lwxtl2. luxl22lwtl22+lwxtl22,
I82 = 0.
(A.38)
(A.39)
(A.40)
(A.41)
(A.42)
(A.43)
(A.44)
for any small > 0. Applying estimates (A.38)-(A.44) to (A.37), we have the following inequality
dtIwtk2 + Iwxtk2. (Iwxk2 + Iuxk2 + Iutk2) Iwtk2 + llftl2.
It follows from (A.36), (A.45) and the Gronwall inequality that
sup IwtI22.eR0Tkwxk22+kuxk22+kutk22dt Iwt(0)I22+ZTIftI22
0≤t≤T	0
(A.45)
(A.46)
15
Under review as a conference paper at ICLR 2021
eγeF0 kf0k22+kgxxk22+kgxk42+ku0xk22kgxk22+ZTkftk22dt .
where
γ = Z	kux k2 + kutk2dt.
0
In a similar way to the proof of (2) of Theorem A.8, (3) of Theorem A.8 follows from (A.33) and
(A.46). This completes the proof of the Theorem.
□
A.3 THE FOKKER-PLANCK EQUATION
A.3.1 Boundary loss design
Define the loss function for the periodic boundary condition as
LossBC
XZ dtZ dv ∣∣∂tα,x,v f nn (t, 1,v;m,w, b) - ∂tα,x,vf nn(t, 0, v; m,w,b)∣∣2
∣α∣ = 1j0	L5
≈ N^ X ∣∂αχ,v f nn(ti, 1,Vk ； m,w,b)- ∂α,χ,v f nn(ti, 0,Vk； m,w,b)∣2 . (A.47)
i,k ∣α∣ = 1,i,k
A.3.2 The Fokker–Planck equation in a periodic interval
In this section, we introduce an L2 energy method for the Fokker-Planck equation and introduce
a regularity inequality for the solutions to the equation. Throughout the section, we will abuse the
notation and use both notations ∂zu and uz for the same derivative of u with respect to z.
We consider the Fokker-Planck equation in a periodic interval [0, 1]:
ut + vux - β(vu)v - quvv = 0, for (t, x, v) ∈ [0, T] × [0, 1] × R,
u(0, x, v) = u0(x, v), for (x, v) ∈ [0, 1] × R, and
(A.48)
∂tα,x,vu(t, 1,v) - ∂tα,x,v u(t, 0, v) = 0, for (t, v) ∈ [0,T] × R,
for any 3-dimensional multi-index α SUchthat∣ɑ∣ ≤ 1 and a given initial distribution uo = uo(x,v).
Now we consider the Fokker-Planck equation that the corresponding neural network solution unn
would satisfy:
(unn)t + v (unn )x - β(vunn )v - q(unn)vv = f for (t, x, v) ∈ [0, T] × [0, 1] × [-5, 5],
unn(0, x,v) = g, for (x, v) ∈ [0, 1] × [-5, 5],
XZTdtZ5 dv∣∣(∂tα,x
∣a∣ = √0	-55
,v unn)(t, 1, v) - (∂tα,x,v unn
∣2
)(t, 0, v)∣∣ ≤ L,
(A.49)
for any 3-dimensional multi-index α such that ∣ɑ∣ ≤ 1 and given f = f (t, x, v), g = g(x, v), and
a constant L > 0. Suppose that f, g and h are C1 functions. Also, we suppose that the a priori
solutions u and unn are sufficiently smooth; indeed, we require them to be in Ct1,,x1,,v2 .
For the a priori solution u and unn to equation A.48 and equation A.49, assume that if |v| is suffi-
ciently large, then we have that for some sufficiently small > 0,
t(SuPJdax,v u(t, ∙, ±5) - dαx,v Unn(t, ∙ ±5升 L2 ([0,1]) ≤ £,
for |a| ≤ 1 and a = (0,0,2). Also, suppose that
|d0x,vu(t,x, ±5)|, |dax,vunn(t,x, ±5)| ≤ C,
(A.50)
(A.51)
for some C < ∞ for ∣ɑ∣ ≤ 1 and α = (0,0, 2). Now We introduce the following theorem on the
energy estimates:
16
Under review as a conference paper at ICLR 2021
Theorem A.10. Let u and unn be the classical solutions to equation A.48 and equation A.49,
respectively. Then we have
sup kunn(t) - u(t)k22 +2(q - ε)	k∂vunn(s) - ∂vu(s)k22ds
0≤t≤T	0
≤ (kg- uok2 + 2) exp
ι + 22β2
T
T +	kf(s)k22ds+2qCT,
0
for any ε ∈ (0, q), where L, u0, f, g, β, q, m, , and C are given in equation A.48-equation A.51.
Proof. Define w d=ef unn - u. Then by equation A.48 and equation A.49, w satisfies
wt + vwx - βvwv - qwvv = f for (t, x, v) ∈ [0, T] × [0, 1] × [-5, 5],
w(0, x, v) = w0, for (x, v) ∈ [0, 1] × [-5, 5],
(A.52)
where w0 d=ef g - u0 . By multiplying w to equation A.52 and integrating with respect to dxdv, we
have
JJ	∣w∣2dχdv + JJ	vwχwdxdv -JJ	qwvvWdXdv
=
[0,1]×[-5,5]
Then we take the integration by parts and obtain that
f wdxdv +	βvwv wdxdv.
1 -11'
2dt	[0,1]×[-5,5]
∣w∣2dxdv + ɪ / dv v(w(t, 1, v)2
2 -5
-w
(t, 0, v)2)
+q	∣wv ∣2dxdv
〃
[0,1]×[-5,5]
f wdxdv +	βvwv wdxdv
+q wv (t, x, 5)w(t, x, 5)dx - q wv (t, x, -5)w(t, x, -5)dx
=e I1 + I2 + I3 + I4 .
We first define
A(t) d=ef
1 ∕55
-5
dv v(w(t, 1, v)2
- w(t, 0, v)2)
We now estimate I1-I4 on the right-hand side. By the Holder inequality and Young,s inequality, We
have
∣iι∣≤kfk2kwk2 ≤ 1 kfk2 + 2kwk2,
where we denote
khk2 =def	∣h∣2dxdv.
Similarly, we observe that
∣I2∣≤ 5βkWvk2kwk2 ≤ εkWvk2 + 25β2kwk2,
for a sufficiently small ε > 0 as ∣v ∣ ≤ 5. By equation A.50, we have
∣I3 + I4 ∣ ≤ qkwv (t, ∙, 5)kLχ kw(t, ∙, 5) - w(t, ∙, -5)kLχ
+ qkwv (t, ∙, 5) - wv (t, ∙, -5)kLχ kw(t, ∙, -5)kLχ ≤ 2qeC.
17
Under review as a conference paper at ICLR 2021
Altogether, we have
—kwk2 + 2(q - ε)kwv ∣∣2 ≤ IIfk2 + (1 +	) ιιwι∣2 + A(t) + 2qeC.
dt	2ε
We integrate with respect to the temporal variable on [0, t] and obtain
kw(t)k22 +2(q -ε)Z kwv(s)k22ds
0
≤ kw(0)k2 + ∕t (kf(s)∣2 + (1 + 25β2) kw(s)k2 + A(S) + 2qeCbs∙
By equation A.493, we have
/t A⑹ ds ≤ L.
Thus, by the Gronwall inequality, We have
kw(t)k22 +2(q -ε)	kwv(s)k22ds
≤ (kw0k2 + L) eχp
1+筝
t + Z kf (s)k22 ds + 2qC t,
0
where w0(x, v) = g(x, v) - u0(x, v). This completes the proof for the theorem.
□
Regarding the derivatives ∂tw and ∂xw we can obtain the similar estimates as follows.
Corollary A.11. Let u and unn be the classical solutions to equation A.48 and equation A.49,
respectively. Assume that equation A.51 holds. Then for z = t or x we have
T
sup ∣∂zunn(t) - ∂zu(t)∣22 + 2(q - ε)	∣∂v∂zunn (s) - ∂v∂zu(s)∣22ds
0≤t≤T	0
≤ H∣∂z g - ∂z uo∣2 + L∖ exp
25β2
1 + -2T
T
T +	∣∂zf(s)∣22ds+2qCT,
0
for any ε ∈ (0, q), where L, u0, f, g, β, q, m, , and C are given in equation A.48-equation A.51.
Proof. For both ∂z = ∂t and ∂x, we take ∂z onto equation A.52 and obtain
(∂zw)t + v(∂zw)x - βv(∂zw)v - q(∂zw)vv = ∂zf for (t, x, v) ∈ [0,T] × [0, 1] × [-5, 5],
(∂zw)(0, x, v) = (∂zw)0, for (x, v) ∈ [0, 1] × [-5, 5],
(A.53)
where (∂z w)0 d=ef ∂zg - ∂zu0. Then the proof is the same as the one for Theorem A.10 for ∂zw
replacing the role of w. This completes the proof.	□
Finally, we can also obtain the regularity estimates for the derivative ∂vw as follows:
Theorem A.12. Let u and unn be the classical solutions to equation A.48 and equation A.49,
respectively. Assume that equation A.51 holds. Then we have
sup ∣∂v
unn (t) -
0≤t≤T
∂v u(t)∣22 + 2(q - ε)
ZT
0
∣∂vv unn (s) - ∂vvu(s)∣2ds
≤ (L + ∣∂xg - ∂xu0∣22 + ∣∂vg - ∂vu0∣22)exp
2+-f ) T
ZT
0
+
(∣∂xf(s)∣22+∣∂vf(s)∣22)ds+4qCT,
for any ε ∈ (0, q), where L, u0, f, g, β, q, m, , and C are given in equation A.48-equation A.51.
18
Under review as a conference paper at ICLR 2021
Proof. we take ∂v onto equation A.52 and obtain
(∂vw)t + wx + v(∂vw)x - βv(∂vw)v - q(∂vw)vv = ∂vf,
for (t, x, v) ∈ [0, T] × [0, 1] × [-5, 5],
(A.54)
Where (∂vW)0 d=ef ∂vg - ∂vu0. By multiplying ∂vW to equation A.54 and integrating With respect to
dxdv , We have
JJ	∣∂vw∣2dxdv + JJ	ν(∂vw)χ(∂vw)dxdν
-	q(∂v W)vv ∂v Wdxdv
=	(-Wx + ∂vf)∂vWdxdv +	βv(∂vW)v∂vWdxdv.
Then We take the integration by parts and obtain that
1d	2
2 加 〃口 i1×τ∕Wvldxdv
+ 2/	(v(∂v w)2(t, 1, v) — v(∂v w)2(t, 0,v)) dv
+q	|Wvv |2 dxdv
=	∂vfWvdxdv +	βvWvvWvdxdv
+q	Wvv (t, x, 5)Wv (t, x, 5)dx — q	Wvv (t, x, —5)Wv (t, x, —5)dx
—	WxWv dxdv d=ef I1 + I2 + I3 + I4 + I5 .
We first define
B(t) d=ef
dv d dv v(∂vw(t, 1, v)2 — ∂vw(t, 0, v)2).
2 -5
We now estimate I1-I4 on the right-hand side. We now estimate I1-I5 on the right-hand side. By
the Holder inequality and Young's inequality, We have
∣Il∣ ≤ k∂v fk2 kwvk2 ≤ 1 k∂vfk2 + 2 kwvk2,
where we denote
∣h∣2 =def	|h|2dxdv.
Similarly, we observe that
|I2| ≤ 5β ∣∣wvv k2kwv k2 ≤ εkwvvk2 +--4^- kwvk2,
for a sufficiently small ε > 0 as |v| ≤ 5. By equation A.50 and equation A.51, We have
|I3 + I41 ≤ q∣wvv(t, ∙, 5)∣LX kwv(t, ∙, 5) - Wv(t, ∙, -5)∣LX
+ q∣wvv(t, ∙, 5) 一 Wvv(t, ∙, -5)∣LX l∣wv(t, ∙, -5)∣LX ≤ 2qeC.
Finally, we have
田 ≤kWχk2 kWv k2 ≤ 1 kWx k2 + 2 kWv k2.
Altogether, We have
*IlWvk2 + 2(q — ε)kwvvk2 ≤ Ildvf∣∣2 + IlWxlI2 +(2+	) ∣∣wv∣∣2 + 亏 + 2qeC.
dt	2ε	2
19
Under review as a conference paper at ICLR 2021
Then we take the integration with respect to the temporal variable on [0, t] and obtain that
kwv(t)k22 + Z ds 2(q - ε)kwvv (s)k22
0
≤ kwv(0)k2 + ∣ot ds (k∂vf (s)k2 + kwχ(s)k2 +(2+ 22β2) kwv(s)k2 + B(S) + 2q。).
By equation A.493, we have
ZQ ds B(S) ≤ 2.
Thus, by the Gronwall inequality, We have
kwv(t)k22 +2(q -ε) Z kwvv(S)k22dS
0
≤ (2 + k∂vwok2)exp
25β2
2+-2T
t + t(kwx(S)k22 + k∂vf(S)k22)dS+2qCt, (A.55)
0
where ∂vw0(x, v) = g(x, v) - u0(x, v). Then we use Corollary A.11 for an upper-bound of
k∂xw(S)k22 and obtain that
Z kwx(S)k22dS
0
≤ ɑ + ∣∣∂χg — ∂χuok2)exp
Then by equation A.55, we obtain that
ι + -f
T
T +	k∂xf(S)k22dS+2qCT.
0
sup kwv (t)k22 + 2(q -ε) Z kwvv(S)k22dS
0≤t≤T	0
≤ (L + k∂χwok2 + k∂vwok2)eχp [(2+")T
T
+	(k∂xf(S)k22+ k∂vf(S)k22)dS+4qCT,
0
where ∂vw0(x, v) = ∂vg(x, v) - ∂vu0(x, v). This completes the proof for the theorem.
□
A.4 The Poisson equation
We consider the Poisson equation equation with Dirichlet boundary condition:
-4u = f in Ω,
U = g on ∂Ω.
Suppose there exists
g ∈ H2(Ω) s.t.g∣∂Ω = g	(A.56)
Then, the equation can be written by:
~ _
—4v = f in Ω,
V = 0 on ∂Ω,
where V = u—g, f = f—4g. Therefore, we assume the homogeneous Dirichlet boundary condition
provided (A.56).
Now, let u be a strong solution of
—4u = f in Ω,
U = 0 on ∂Ω,
(A.57)
20
Under review as a conference paper at ICLR 2021
and let unn be a neural network such that
-4unn = fnn in ω,
Unn = 0 On ∂Ω.
(A.58)
Here, we can set the boundary to be zero by multiplying B(x), where B(x) is a smooth function
satisfying B(x) = 0, x ∈	. By subtracting (A.58) from (A.57), we get
[=0, X ∈ Ω
-4(U - Unn) = (f - fnn) in ω,
U — Unn = 0 On ∂Ω.
(A.59)
Then we apply belOw theOrem tO (A.59) tO get the cOnvergence results.
Theorem A.13. (Theorem 6.3.5 in Evans (2010)) Let m be a nonnegative integer. Suppose that
U ∈ H1(Ω) is a weak solution ofthe boundary-value problem (A.57). Assume ∂Ω is Cm+2. Then,
kUkHm + 2(Q) ≤ C(IIfkHm(Ω) + 11^^9)}	(A.6O)
Furthermore, ifU is the unique solution of A.57, then
||UkHm+2(Ω) ≤ CIlfIlHm(Ω).	(A.61)
By applying (A.61) tO (A.59), we Obtain
∣∣u - UnnIlHm+2(Ω) ≤ Ckf - fnn∣∣Hm(Ω)∙
where the right hand side cOrrespOnds tO LossGE (Unn; m, 2).
21
Under review as a conference paper at ICLR 2021
B Additional Experimental Results
B.1	Dependency on learning rates
In this subsection, we show several experiments that shows the proposed loss functions generally
performs better in different learning rates. We first show the results for Burgers’ equation. In
Figure 5, we show the test errors versus training epochs plot for different learning rates. We used
10-3 , 10-4 , 10-5 as learning rates and we observe that H2 loss performs best followed by H1 and
L2 loss functions.
Figure 5: Test errors as training goes for different learning rates.
We next present the similar experiments for the high-dimensional Poisson equation. We trained 30
neural networks with different initializations with different learning rates. The average errors are
presented in Figure 6. As the same in the Burgers’ equation, our loss functions performs better than
the traditional one in all learning rates.
Figure 6: Test errors as training goes for different learning rates.
B.2	High-dimensional Poisson equation
In this subsection, we consider the high-dimensional Poisson equation with different boundary con-
dition. In subsection 5.1, we pointed out that the ”difficulty” of learning sin(kx) increases as k
increases. As a generalization of the argument, we consider the following PDEs:
(kπ)2 d kπ
-4u =	工 sin(工Xi), for X ∈ Ω = (0,1)d,
i=1
∖	kπ
U = sιn(--xi), for X ∈ ∂Ω,
i=1	2
for d=10, k = 1,3, and 5. As one can see in Figure 7, the improvement of Sobolev training gets bigger
as k increases. This observation coincides with the one in section 5, as we expected. Moreover, we
present the comparison of training time to meet a certain error value for different loss functions in
Figure 7. The result shows that it is advantageous to use the proposed loss functions in time, even in
high-dimensional case.
22
Under review as a conference paper at ICLR 2021
1 / Time Plot
——LOSS卷系产。e
——Loss<⅛^≡≡on>
—L。SS 用铲 ℃>
Figure 7: Left column: Test errors as training goes for different values of k. Right column: Required
Training Time to achieve a certain test error.
23