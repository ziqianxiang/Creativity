Under review as a conference paper at ICLR 2021
The Heavy-Tail Phenomenon in SGD
Anonymous authors
Paper under double-blind review
Ab stract
In recent years, various notions of capacity and complexity have been proposed for
characterizing the generalization properties of stochastic gradient descent (SGD) in
deep learning. Some of the popular notions that correlate well with the performance
on unseen data are (i) the ‘flatness’ of the local minimum found by SGD, which
is related to the eigenvalues of the Hessian, (ii) the ratio of the stepsize η to the
batch size b, which essentially controls the magnitude of the stochastic gradient
noise, and (iii) the ‘tail-index’, which measures the heaviness of the tails of the
network weights at convergence. In this paper, we argue that these three seemingly
unrelated perspectives for generalization are deeply linked to each other. We claim
that depending on the structure of the Hessian of the loss at the minimum, and
the choices of the algorithm parameters η and b, the SGD iterates will converge
to a heavy-tailed stationary distribution. We rigorously prove this claim in the
setting of quadratic optimization: we show that even in a simple linear regression
problem with independent and identically distributed Gaussian data, the iterates
can be heavy-tailed with infinite variance. We further characterize the behavior of
the tails with respect to algorithm parameters, the dimension, and the curvature. We
then translate our results into insights about the behavior of SGD in deep learning.
We finally support our theory with experiments conducted on both synthetic data
and fully connected neural networks.
1	Introduction
The learning problem in neural networks can be expressed as an instance of the well-known population
risk minimization problem in statistics, given as follows:
minχ∈Rd F(x) := Ez〜D[f(x,z)],	(1.1)
where z ∈ Rp denotes a random data point, D is a probability distribution on Rp that denotes the
law of the data points, x ∈ Rd denotes the parameters of the neural network to be optimized, and
f : Rd × Rp 7→ R+ denotes a measurable cost function, which is often non-convex in x. While this
problem cannot be attacked directly since D is typically unknown, if we have access to a training
dataset S = {z1, . . . , zn} with n independent and identically distributed (i.i.d.) observations, i.e.,
Zi 〜Lia D for i = 1,...,n, we can use the empirical risk minimization strategy, which aims at
solving the following optimization problem (Shalev-Shwartz & Ben-David, 2014):
minx∈Rd f(x) := f(x, S) := (1/n) Xin=1 f(i) (x),	(1.2)
where f(i) denotes the cost induced by the data point zi . The stochastic gradient descent (SGD)
algorithm has been one of the most popular algorithms for addressing this problem:
Xk = Xk-1 - ηVjfk(xk-ι),	where ^fk(X) = (I/b) X C Pf (i)(x).	(1.3)
i∈—yi∈Ωk
Here, k denotes the iterations, η > 0 is the stepsize (also called the learning-rate), Vf is the stochastic
gradient, b is the batch-size, and Ωk ⊂ {1,...,n} is a random subset with ∣Ωk∣ = b for all k.
Even though the practical success of SGD has been proven in many domains, the theory for its
generalization properties is still in an early phase. Among others, one peculiar property of SGD that
has not been theoretically well-grounded is that, depending on the choice of η and b, the algorithm
can exhibit significantly different behaviors in terms of the performance on unseen test data.
A common perspective over this phenomenon is based on the ‘flat minima’ argument that dates
back to Hochreiter & Schmidhuber (1997), and associates the performance with the ‘sharpness’
or ‘flatness’ of the minimizers found by SGD, where these notions are often characterized by the
magnitude of the eigenvalues of the Hessian, larger values corresponding to sharper local minima
1
Under review as a conference paper at ICLR 2021
(Keskar et al., 2016). Recently, Jastrzebski et al. (2017) focused on this phenomenon as well and
empirically illustrated that the performance of SGD on unseen test data is mainly determined by the
stepsize η and the batch-size b, i.e., larger n/b yields better generalization. Revisiting the flat-minima
argument, they concluded that the ratio n/b determines the flatness of the minima found by SGD;
hence the difference in generalization. In the same context, SimSekli et al. (2019b) focused on the
statistical properties of the gradient noise (Vfk (x) - Vf (x)) and illustrated that under an isotropic
model, the gradient noise exhibits a heavy-tailed behavior, which was also confirmed in follow-up
studies (Zhang et al., 2019). Based on this observation and a metastability argument (Pavlyukevich,
2007), they showed that SGD will ‘prefer’ wider basins under the heavy-tailed noise assumption,
without an explicit mention of the cause of the heavy-tailed behavior.
In another recent study, Martin & Mahoney (2019) introduced a new approach for investigating the
generalization properties of deep neural networks by invoking results from heavy-tailed random
matrix theory. They empirically showed that the eigenvalues of the weight matrices in different layers
exhibit a heavy-tailed behavior, which is an indication that the weight matrices themselves exhibit
heavy tails as well (Ben Arous & Guionnet, 2008). Accordingly, they fitted a power law distribution
to the empirical spectral density of individual layers and illustrated that heavier-tailed weight matrices
indicate better generalization. Very recently, SS imsSekli et al. (2020) formalized this argument in a
mathematically rigorous framework and showed that such a heavy-tailed behavior diminishes the
‘effective dimension’ of the problem, which in turn results in improved generalization. While these
studies form an important initial step towards establishing the connection between heavy tails and
generalization, the originating cause of the observed heavy-tailed behavior is yet to be understood.
In this paper, we argue that these three seemingly unrelated perspectives for generalization are deeply
linked to each other. We claim that, depending on the choice of the algorithm parameters n and b,
the dimension d, and the curvature of f (to be precised in Section 3), SGD exhibits a ‘heavy-tail
phenomenon’, meaning that the law of the iterates converges to a heavy-tailed distribution. We
rigorously prove that, this phenomenon is not specific to deep learning and in fact it can be observed
even in surprisingly simple settings: we show that when f is chosen as a simple quadratic function
and the data points are i.i.d. from an isotropic Gaussian distribution, the iterates can still converge to
a heavy-tailed distribution with arbitrarily heavy tails, hence with infinite variance. We summarize
our contributions as follows:
1.	When f is a quadratic, we prove that: (i) the tails become monotonically heavier for increasing
curvature, increasing n, or decreasing b, hence relating the heavy-tails to the ratio n/b and the
curvature, (ii) the law of the iterates converges exponentially fast towards the stationary distribution
in the Wasserstein metric, (iii) there exists a higher-order moment (e.g., variance) of the iterates
that diverges at most polynomially-fast, depending on the heaviness of the tails at stationarity.
2.	We support our theory with experiments conducted on both synthetic data and neural networks. Our
experimental results confirm our theory on synthetic setups and also illustrate that the heavy-tail
phenomenon is also observed in fully connected multi-layer neural networks.
To the best of our knowledge, these results are the first of their kind to rigorously characterize the
empirically observed heavy-tailed behavior of SGD with respect to n, b, d, and the curvature, with
explicit convergence rates. 1
2	Technical Background
Heavy-tailed distributions with a power-law decay. In probability theory, a real-valued random
variable X is said to be heavy-tailed if the right tail or the left tail of the distribution decays slower
1We note that in a concurrent work, which very recently appeared on arXiv, Hodgkinson & Mahoney (2020)
showed that heavy tails with power laws arise in more general Lipschitz stochastic optimization algorithms that
are contracting on average for strongly convex objectives near infinity with positive probability. Our Theorem 1
and Lemma 14 are more refined as we focus on the special case of SGD with Gaussian data, where we are able
to provide constants which explicitly determine the tail index as an expectation over data and SGD parameters
(see also eqn. (3.6)). Due to the generality of their framework, (Hodgkinson & Mahoney, 2020, Thm 1) is
more implicit and it cannot provide such a characterization of these constants, however it can be applied to
other algorithms beyond SGD. All our other results (including Theorem 2 — monotonicity of the tail-index and
Corollary 9 - central limit theorem for the ergodic averages) are all specific to SGD and cannot be obtained
under the framework of Hodgkinson & Mahoney (2020). We encourage the readers to refer to (Hodgkinson &
Mahoney, 2020) for the treatment of more general stochastic recursions.
2
Under review as a conference paper at ICLR 2021
than any exponential distribution. We say X has heavy (right) tail if limx→∞ P(X ≥ x)ecx = ∞ for
any c > 0. 2 Similarly, an Rd-valued random vector X has heavy tail if uTX has heavy right tail for
some vector u ∈ Sd-1, where Sd-1 := {u ∈ Rd : kuk = 1} is the unit sphere in Rd.
Heavy tail distributions include α-stable distributions, Pareto distribution, log-normal distribution
and the Weilbull distribution. One important class of the heavy-tailed distributions is the distributions
with power-law decay, which is the focus of our paper. That is, P(X ≥ x)〜c0x-a as X → ∞ for
some c0 > 0 and α > 0, where α > 0 is known as the tail-index, which determines the tail thickness
of the distribution. Similarly, we say that the random vector X has power-law decay with tail-index
a if for some u ∈ Sd-1, We have P(UT X ≥ x)〜cox-α, for some co ,α> 0.
Stable distributions. The class of α-stable distributions are an important subclass of heavy-tailed
distributions with a power-law decay, which appears as the limiting distribution of the generalized
CLT for a sum of i.i.d. random variables with infinite variance (L6vy, 1937). A random variable X
follows a symmetric α-stable distribution denoted as X 〜SɑS(σ) if its characteristic function takes
the form: E [eitX] = exp (-σɑ∣t∣α), t ∈ R, where σ > 0 is the scale parameter that measures the
spread of X around 0, and α ∈ (0, 2] is known as the tail-index, and SαS becomes heavier-tailed as
α gets smaller. The probability density function of a symmetric α-stable distribution, α ∈ (0, 2], does
not yield closed-form expression in general except for a few special cases. When α = 1 and α = 2,
SαS reduces to the Cauchy and the Gaussian distributions, respectively. When 0 < α < 2, α-stable
distributions have their moments being finite only up to the order α in the sense that E[|X|p] < ∞ if
and only if p < α, which implies infinite variance.
Wasserstein metric. For anyp ≥ 1, define Pp(Rd) as the space consisting of all the Borel probability
measures ν on Rd with the finite p-th moment (based on the Euclidean norm). For any two Borel
probability measures ν1, ν2 ∈ Pp(Rd), we define the standard p-Wasserstein metric (Villani, 2009):
Wp(ν1, ν2) := (inf E [kZ1 - Z2 kp])1/p, where the infimum is taken over all joint distributions of
the random variables Z1 , Z2 with marginal distributions ν1 , ν2 respectively.
3	Setup and Main Theoretical Results
Before stating our theoretical results in detail, let us informally motivate our main method of analysis.
Suppose that the initial SGD iterate x0 is in the domain of attraction3 of a local minimum x? of f
and the function f is smooth and well-approximated by a quadratic function in this basin. Under
this assumption, by considering a first-order Taylor approximation of Vf(i) (x) around x?, we have
Vf (i)(x) ≈ Vf (i)(x?) + V2f (i)(x?)(X - x?). By using this approximation, we can approximate
the SGD recursion (1.3) as follows:
Xk ≈ xk-ι - (η∕b)Xi∈Ωkv2f ⑶(X?)xk—i + (n/b)Xig (v2f ⑴(x?)x? - Vf ⑴(x?))
=:(I - (η∕b)Hk) xk-1 + qk,	(3.1)
where I denotes the identity matrix of appropriate size. Here, our main observation is that the SGD
recursion can be approximated by a linear stochastic recursion, which gives us access to the tools
from implicit renewal theory for investigating its statistical properties (Kesten, 1973; Goldie, 1991).
In a renewal theoretic context, the object of interest would be the matrix (I - ηHk), whose statistical
properties determine the behavior ofxk: depending on the moments of this matrix, xk can have heavy
or light tails, or might even diverge.
In this study, we focus on the tail behavior of the SGD dynamics by analyzing it through the lens
of implicit renewal theory. As, the recursion (3.1) is obtained by a quadratic approximation of the
component functions f(i), which arises naturally in linear regression, we will consider a simplified
setting and rigorously study this dynamics in the case of linear regression.
We would like to underline that, in our analysis, the Taylor approximation (3.1) is not crucial. Indeed,
we can easily extend our theory to more general non-linear recursions by imposing strict statistical
assumptions on the loss function (which can be chosen non-convex) and the data distribution (Mirek,
2011). Unfortunately, such assumptions would either be trivially false for deep learning problems,
2A real-valued random variable X has heavy (left) tail if limx→∞ P(X ≤ -x)ec|x| = ∞ for any c > 0.
3We say x0 is in the domain of attraction of a local minimum x? , if gradient descent iterations to minimize f
started at x0 with sufficiently small stepsize converge to x? as the number of iterations goes to infinity.
3
Under review as a conference paper at ICLR 2021
e.g., (Mirek, 2011) or cannot be verified in practice, e.g., (Hodgkinson & Mahoney, 2020). In order to
be able to provide explicit results with clear assumptions, we limit our scope to quadratic optimization,
which turns out to be already fairly technical. We leave the analysis of the general case as a natural
next step of our work.
We now consider the case when f is a quadratic, which arises in linear regression:
min F(x) ：= (1∕2)E(a,y)〜D ∣^(aTx - y)[ ,	(3.2)
x∈Rd
where the data (a, y ) comes from an unknown distribution D with support Rd × R. Assume we
have access to i.i.d. samples (ai,yi) from the distribution D where Vf(i)(x) = a,i(OTX - yi) is
an unbiased estimator of the true gradient VF(x). The curvature, i.e. the value of second partial
derivatives, of this objective around a minimum is determined by the Hessian matrix E(aaT) which
depends on the distribution of a. In this setting, SGD with batch size b leads to the iterations
xk = Mkxk-1 +	qk with Mk	:= I - (η∕b)Hk,	Hk	:=	aiaiT,	qk	:=	(η∕b)	aiyi	,
i∈ /i∈Ωk	i∈ /i∈Ωk
(3.3)
where Ωk := {b(k - 1) + 1, b(k - 1) + 2,..., bk} with ∣Ωk | = b. Here, for simplicity, we assume
that we are in the one-pass regime (also called the streaming setting (Frostig et al., 2015; Jain et al.,
2017)) where each sample is used only once without being recycled. Our purpose in this paper is
to show that heavy tails can arise in SGD even in simple settings such as when the input data ai
is Gaussian, without the necessity to have a heavy-tailed input data4. Consequently, we make the
following assumptions on the data throughout the paper:
(A1) a% 〜N(0, σ2Id) are i.i.d.
(A2) yi are i.i.d. with a continuous density whose support is R with all the moments finite.
Assumption (A2) would be satisfied in many cases, for instance when yi is normally distributed on R.
Note that by Assumption (A1), the matrices Mk = I - ηHk are i.i.d. and the Hessian matrix of the
objective (3.2) satisfies E(aaT) = σ2Id where the value of σ2 determines the curvature around a
minimum; smaller (larger) σ2 implies the objective will grow slower (faster) around the minimum
and the minimum will be flatter (sharper) (see e.g. Dinh et al. (2017)). We introduce
h(s) := limk→∞ (EkMkMk-1... M1ks)1/k ,	(3.4)
which arises in stochastic matrix recursions (see e.g. Buraczewski et al. (2014)) where ∣∣ ∙ ∣∣ denotes
the matrix 2-norm (i.e. largest singular value of a matrix). Since EkMkks < ∞ for all k and s > 0,
we have h(s) < ∞. Let us also define
Πk := MkMk-1 . . . M1 and ρ := limk→∞(2k)-1 log largest eigenvalue of ΠkT Πk . (3.5)
The latter quantity is called the top Lyapunov exponent of the stochastic recursion (3.3). Furthermore,
if ρ exists and is negative, it can be shown that a stationary distribution of the recursion (3.3) exists.
In the Appendix (see Lemma 14), we show that under our assumptions,
ρ=Elog∣(I-(η∕b)H)e1∣ ,	h(s)=E[∣(I-(η∕b)H)e1∣s]	forρ<0,	(3.6)
where H is a matrix with the same distribution as Hk, and e1 is the first basis vector.
In the following, we show that the limit density has a polynomial tail with a tail-index given precisely
by α, the unique critical value such that h(α) = 1. The result builds on adapting the techniques de-
veloped in stochastic matrix recursions (Alsmeyer & Mentemeier, 2012; Buraczewski et al., 2016) to
our setting. Our result shows that even in the simplest setting when the input data is Gaussian without
any heavy tail, SGD iterates can lead to a heavy-tailed stationary distribution with an infinite variance.
To our knowledge, this is the first time such a phenomenon is proven in the linear regression setting.
Theorem 1. Consider the SGD iterations (3.3). If ρ < 0, then SGD iterations admit a unique
stationary distribution x∞ which satisfy
limt→∞ tαP (UTx∞ > t) = eα(u), U ∈ Sd-1,	(3.7)
for some positive and continuous function eα on the unit sphere Sd-1, where α is the unique positive
value such that h(α) = 1.
4Note that if the input data is heavy-tailed, the stationary distribution of SGD automatically becomes heavy-
tailed, see Buraczewski et al. (2012) for details. In our context, the challenge is to identify the occurrence of the
heavy tails when the distribution of the input data is light-tailed, such as a simple Gaussian distribution.
4
Under review as a conference paper at ICLR 2021
As Martin & Mahoney (2019); SimSekn et al. (2020) provide both numerical and theoretical evidence
showing that the tail-index of the density of the network weights is closely related to the generalization
performance, where smaller tail-index indicates better generalization, a natural question of practical
importance is how the tail-index depends on the parameters of the problem including the batch size,
dimension and the stepsize. We prove that larger batch sizes lead to a lighter tail (i.e. larger α), which
links the heavy tails to the observation that smaller b yields improved generalization in a variety of
settings in deep learning (Keskar et al., 2016; Panigrahi et al., 2019; Martin & Mahoney, 2019). We
also prove that smaller stepsizes lead to larger α, hence lighter tails, which agrees with the fact that
the existing literature for linear regression often choose η small enough to guarantee that variance of
the iterates stay bounded (Dieuleveut et al., 2017b; Jain et al., 2017).
Theorem 2. The tail-index α is strictly increasing in batch size b and strictly decreasing in stepsize η
and variance σ2 provided that α ≥ 1. Moreover, the tail-index α is strictly decreasing in dimension d.
Next result characterizes the tail-index α depending on the choice of the batch size b, the variance σ2,
which determines the curvature around the minimum and the stepsize; in particular we show that if
the stepsize exceeds an explicit threshold, the stationary distribution will become heavy tailed with
an infinite variance.
Proposition 3. Let %丁讥 =σ2(d+b+i) ∙ Thefollowing holds： (i) There exists ηmaχ > ηcrit such that
for any ηcrit < η < ηmax, Theorem 1 holds with tail index 0 < α < 2. (ii) If η = ηcrit, Theorem 1
holds with tail index α = 2. (iii) If η ∈ (0, ηcrit), then Theorem 1 holds with tail index α > 2.
Relation to first exit times. Proposition 3 implies that, for fixed η and b, the tail-index α will be
decreasing with increasing σ. Combined with the first-exit-time analyses of SS imsSekli et al. (2019b);
Nguyen et al. (2019), which state that the escape probability from a basin becomes higher for smaller
α, our result implies that the probability of SGD escaping from a basin gets larger with increasing
curvature; hence providing an alternative view for the argument that SGD prefers flat minima.
Three regimes for stepsize. Theorems 1-2 and Proposition 3 identify three regimes: (I) convergence
to a limit with a finite variance if ρ < 0 and α > 2; (II) convergence to a heavy-tailed limit with
infinite variance if ρ < 0 and α < 2; (III) ρ > 0 when convergence cannot be guaranteed. For
Gaussian input, if the stepsize is small enough, smaller than ηcrit, by Proposition 3, ρ < 0 and α > 2,
therefore regime (I) applies. As we increase the stepsize, there is a critical stepsize level ηcrit for
which η > ηcrit leads to α < 2 as long as η < ηmax where ηmax is the maximum allowed stepsize
for ensuring convergence (corresponds to ρ = 0). A similar behavior with three (learning rate)
stepsize regimes was reported in Lewkowycz et al. (2020) and derived analytically for one hidden
layer linear networks with a large width. The large stepsize choices that avoids divergence, so called
the catapult phase for the stepsize, yielded the best generalization performance empirically, driving
the iterates to a flatter minima in practice. We suspect that the catapult phase in Lewkowycz et al.
(2020) corresponds to regime (II) in our case, where the iterates are heavy-tailed, which might cause
convergence to flatter minima as the first-exit-time discussions suggest (SS imsS ekli et al., 2019a).
Moment Bounds and Convergence Speed. Theorem 1 is of asymptotic nature which characterizes
the stationary distribution x∞ of SGD iterations with a tail-index α. Next, we provide non-asymptotic
moment bounds for xk at each k-th iterate, and also for the limit x∞ .
Theorem 4. (i) If the tail-index α ≤ 1, then for any p ∈ (0, α), we have h(p) < 1 and
Ekxkkp ≤ (h(p))kEkxokp + 1 - ,(pFEkqιkp.	(3.8)
1	- h(p)
(ii)	If the tail-index α > 1, then for any p ∈ (1, α), we have h(p) < 1 and for any > 0 such that
(1 + )h(p) < 1, we have
Ekxkkp ≤ ((1 + e)h(p))kEkxokp + 1-((1+ e)h(P))k (：，)p-1 J(1： ')Ekqιkp.	(3.9)
1 - (1 + e)h(p)	((1 + e)P-T - 1)P
Theorem 4 shows that when p < α the upper bound on the p-th moment of the iterates converges
exponentially to the p-the moment of q1 when α ≤ 1 and a neighborhood of the p-moment of q1
when α > 1, where q1 is defined in (3.3). By letting k → ∞ and applying Fatou’s lemma, we can
also characterize the moments of the stationary distribution.
5
Under review as a conference paper at ICLR 2021
Corollary 5. (i) If the tail-index α ≤ 1, then for any p ∈ (0, α), Ekx∞ kp ≤ ι-h(p)EkqIkp, where
h(p) < 1. (ii) If the tail-index α > 1, then for any p ∈ (1, α), we have h(p) < 1 and for any > 0
P
such that (1 + e)h(p) < 1, we have Ekx∞kp ≤〔_门 J MF、(1+')P 1-(1+>EkqIkp∙
1 (1+e)h(p) ((1+e) P-1 -1)P
Next, we will study the speed of convergence of the k-th iterate xk to its stationary distribution x∞
in the Wasserstein metric Wp for any 1 ≤ p < α.
Theorem 6. Assume α > 1. Let νk, ν∞ denote the probability laws of xk and x∞ respectively.
Then Wp(Vk,ν∞) ≤ (h(p))k∕pWp(ν0, ν∞), for any 1 ≤ p < a, where the convergence rate
(h(p))1/p ∈ (0, 1).
Theorem 6 shows that in case α < 2 the convergence to a heavy tailed distribution occurs relatively
fast, i.e. with a linear convergence in the p-Wasserstein metric. We can also characterize the constant
h(p) in Theorem 6 which controls the convergence rate as follows:
Corollary 7. When η < %丁沆 =σ2(d+b+i) ,the tail-index a > 2,
W2(νk,ν∞) ≤ (1 - 2ησ2 (1 - n/nCrit))kk/ W2(ν0, ν∞).	(3.10)
Theorem 6 works for any p < α. At the critical p = α, Theorem 1 indicates that Ekx∞ kα = ∞,
and therefore has Ekxkkα → ∞ as k → ∞, 5 which serves as an evidence that the tail gets heavier
as the number of iterates k increases. By adapting the proof of Theorem 4, we have the following
result stating that the moments of the iterates of order α go to infinity but this speed can only be
polynomially fast.
Proposition 8. Given the tail-index α, we have Ekx∞kα = ∞. Moreover, Ekxk kα = O(k) if α ≤ 1,
andEkxkkα = O(kα) if α > 1.
It may be possible to leverage recent results on the concentration of products of i.i.d. random matrices
(Huang et al., 2020; Henriksen & Ward, 2020) to study the tail of xk for finite k, which can be a
future research direction.
Extension to non-Gaussian data. Our main purpose in Theorem 1 is to show that heavy tails
can arise even in the simplest setting when the input is Gaussian. However, Proposition 1 extends
naturally if the input ai is not necessarily Gaussian. For example, if we assume that the distribution
of ai has support of Rd and has a finite second moment, it can be checked that our proof technique
for Theorem 1 will be still applicable and Theorem 1 will hold with h(s) defined by (3.4). The only
difference is that when input is not Gaussian, the explicit formula (3.6) for h(s) will not hold as an
equality but it will become an inequality, i.e.
h(S) ≤ h(S) := E[k(I - (n/b)H)eιks],	(34I)
where h(s) is defined by (3.4). This inequality is just a consequence of sub-multiplicativity of matrix
products appearing in (3.4). If α is such that h(α) = 1, then by (3.11), α is a lower bound on the tail
index α that satisfies h(α) = 1 where h is defined as in (3.4). In other words, when the input is not
Gaussian, We have α ≤ α and therefore α serves as a lower bound on the tail index. Furthermore,
Theorem 2 will also apply in the sense that α. a will be strictly increasing in batch size b and strictly
increasing in stepsize n and variance σ2 provided that a ≥ 1.
Extension to non-quadratic optimization. We note that extending our results beyond quadratic
optimization is possible, if the gradients have asymptotic linear growth. For example, consider the
cost F(x) = E['(aτX - y)] with loss function '. The choice of '(z) = ∣∣z∣∣2∕2 is the standard linear
regression setting where the gradient of F is an affine function of X and in this case ∣∣VF(x) - Σχ∣∣
is bounded if we choose Σ = E[aaT]. Theorem 1 will hold as long as there exists a matrix Σ such
that kVF (X) - ΣXk stays bounded even if the function ` is not a quadratic function, the proof is
straightforward and would be based on verifying that the conditions of (Mirek, 2011, Theorem 1.4)
hold in the setting of Theorem 1. This type of optimization problems arises for instance in robust
regression where the objective is F(X) = E[(aT X - b)2] + λg(X) with a penalty function g(X) whose
gradient is bounded and a tunable parameter λ. The boundedness of the gradient of g(X) results in
at-most linear growth of g(X) and allows robustness to outliers where the parameter λ can be used to
adjust the robustness level desired. Examples for the choice of g(X) include the smoothly clipped
5Otherwise, one can construct a subsequence xnk that is bounded in the space Lα converging to x∞ which
would be a contradiction.
6
Under review as a conference paper at ICLR 2021
absolute deviation (SCAD) penalty (Loh & Wainwright (2015)), Huber loss (Huber, 1992) or the
exponential squared loss when g(x) = 1 - exp(-kxk2/c) where c is a tuning parameter.
Generalized Central Limit Theorem for Ergodic Averages. When α > 2, by Corollary 5, second
moment of the iterates xk are finite, in which case central limit theorem (CLT) says that if the
cumulative sum of the iterates SK = PkK=1 xk is scaled properly, the resulting distribution is
Gaussian. In the case where α < 2, the variance of the iterates is not finite; however in this case, we
derive the following generalized CLT (GCLT) which says that if the iterates are properly scaled, the
limit will be an α-stable distribution. This is stated in a more precise manner as follows.
Corollary 9. Assume ρ < 0 so that Theorem 1 holds. Then, we have the following:
(i)	If α ∈ (0, 1) ∪ (1, 2), then there is a sequence dK = dK (α) and a function Cα : Sd-1 7→ C such
that as K → ∞ the random variables K- 1 (SK 一 dκ) converge in law to the α-Stable random
variable with characteristic function Υα (tv) = exp(tαCα(v)), for t > 0 and v ∈ Sd-1.
(ii)	Ifα = 1, then there are functions ξ, τ : (0, ∞) 7→ R and C1 : Sd-1 7→ C such that as K → ∞ the
random variables K-1SK 一 Kξ K-1 converge in law to the random variable with characteristic
function Υ1 (tv) = exp (tC1 (v) + ithv, τ (t)i), for t > 0 and v ∈ Sd-1.
(iii)	If α = 2, then there is a sequence dK = dK (2) and a function C2 : Sd-1 7→ R such that as
K → ∞ the random variables (K log K)-2 (SK — dκ) converge in law to the random variable
with characteristic function Υ2(tv) = exp t2C2(v) , for t > 0 and v ∈ Sd-1.
(iv)	If α ∈ (0,1), then dK = 0, and if α ∈ (1, 2], then dK = Kx, where X = JRd xν∞ (dx).
In addition to its evident theoretical interest, Corollary 9 has also an important practical implication:
estimating the tail-index of a generic heavy-tailed distribution is a challenging problem (see e.g.
Clauset et al. (2009); Goldstein et al. (2004); Bauke (2007)); however, for the specific case of α-stable
distributions, accurate and computationally efficient estimators, which do not require the knowledge
of the functions Cα, τ, ξ, have been proposed (Mohammadi et al., 2015). Thanks to Corollary 9, we
will be able to use such estimators in our numerical experiments, as we will detail in the next section.
We finally note that the gradient noise in SGD is actually both multiplicative and additive (Dieuleveut
et al., 2017b;a); a fact that is often discarded for simplifying the mathematical analysis. In the linear
regression setting, we have shown that the multiplicative noise Mk is the main source of heavy-tails,
where a deterministic Mk would not lead to heavy tails.6 In the light of our theory, in Appendix A, we
discuss in detail the recently proposed stochastic differential equation (SDE) representations of SGD
in continuous-time and argue that, compared to classical SDEs driven by a Brownian motion (e.g.,
(Jastrzebski et al., 2017; Cheng et al., 2019), SDEs driven by heavy-tailed α-stable LeVy processes
(e.g., (SimSekIi et al., 2019b)) are more adequate when α < 2.
4	Experiments
In this section, we present our experimental results on both synthetic and real data, in order to
illustrate that our theory also holds in finite-sum problems (besides the streaming setting). Our main
goal will be to illustrate the tail behavior of SGD by varying the algorithm parameters: depending on
the choice of the stepsize η and the batch-size b, the iterates do converge to a heavy-tailed distribution
(Theorem 1) and the behavior of the tail-index obeys Theorem 2.
Synthetic experiments. In our first setting, we consider a simple synthetical setup, where we assume
that the data points follow a Gaussian distribution. We will illustrate that the SGD iterates can become
heavy-tailed even in this simplistic setting where the problem is a simple linear regression with all
the variables being Gaussian. More precisely, we will consider the following model:
xo ~N(0,σ2I),	ai ~N(0,σ2I),	y∕ai,xo ~N (a>x。，。：) ,	(4.1)
where x0, ai ∈ Rd, yi ∈ R for i = 1, . . . , n, and σ, σx, σy > 0.
In our experiments, we will need to estimate the tail-index α of the stationary distribution ν∞ . Even
though several tail-index estimators have been proposed for generic heavy-tailed distributions in
the literature (Paulauskas & Vaiciulis, 2011), we observed that, even for small d, these estimators
can yield inaccurate estimations and require tuning hyper-parameters, which is non-trivial. We
6E.g., if Mk is deterministic and qk is Gaussian, then xk is Gaussian for all k, and so is x∞ if the limit exists.
7
Under review as a conference paper at ICLR 2021
circumvent this issue thanks to the GCLT in Corollary 9: since the average of the iterates is
guaranteed to converge to a multivariate α-stable random variable, we can use the tail-index
estimators that are specifically designed for stable distributions. By following Tzagkarakis et al.
(2018); Simsekli et al. (2019b), We use the estimator proposed by Mohammadi et al. (2015), which is
fortunately agnostic to the scaling function Cα. The details of this estimator are given in Appendix B.
To be able to benefit from the CLT,
we are required to compute the
average of the ‘centered’ iterates:
K-1Ko PK=K-K0 + 1 (Xk - X), where
K0 is a ‘burn-in’ period aiming to
discard the initial phase of SGD,
and the mean of ν∞ is given by
X = RRd xν∞(dx) = (A>A)-1A>y
as long as α > 17, where the i-th
row of A ∈ Rn×d contains ai> and
y = [y1 , . . . , yn ] ∈ Rn . We then repeat
this procedure 1600 times for different
initial points and obtain 1600 different
random vectors, whose distributions
are supposedly close to an α-stable
distribution. Finally, we run the tail-index
Figure 1: Behavior of α with (a) varying stepsize η and
batch-size b, (b) d and σ, (c) under RMSProp.
estimator of Mohammadi et al. (2015) on these random vectors to estimate α.
In our first experiment, we investigate the tail-index α of the stationary measure ν∞ for varying
stepsize η and batch-size b. We set d = 100 first fix the variances σ = 1, σx = σy = 3, and generate
{ai , yi }in=1 by simulating the statistical model. Then, by fixing this dataset, we run the SGD recursion
(3.3) for a large number of iterations and vary η from 0.02 to 0.2 and b from 1 to 20. We also set
K = 1000 and K0 = 500. Figure 1(a) illustrates the results. We can observe that, increasing η and
decreasing b both result in decreasing α, where the tail-index can be prohibitively small (i.e., α < 1,
hence even the mean of ν∞ is not defined) for large η . Besides, we can also observe that the tail-index
is in strong correlation with the ratio η∕b.
In our second experiment, we investigate the effect of d and σ on α. In Figure 1(b) (left), we set
d = 100, η = 0.1 and b = 5 and vary σ from 0.8 to 2. For each value of σ, we simulate a new dataset
from by using the generative model and run SGD with K, K0. We again repeat each experiment 1600
times. We follow a similar route for Figure 1(b) (right): we fix σ = 1.75 and repeat the previous
procedure for each value of d ranging from 5 to 50. The results confirm our theory: α decreases for
increasing σ and d, and we can observe that for a fixed b and η the change in d can abruptly alter α.
In our final synthetic data experiment, we investigate how the tails behave under adaptive optimization
algorithms. We replicate the setting of our first experiment, with the only difference that we replace
SGD with RMSProp (Hinton et al., 2012). As shown in Figure 1(c), the ‘clipping’ effect of RMSProp
as reported in Zhang et al. (2019) prevents the iterates become heavy-tailed and the vast majority of
the estimated tail-indices is around 2, indicating a Gaussian behavior. On the other hand, we repeated
the same experiment with the variance-reduced optimization algorithm SVRG (Johnson & Zhang,
2013), and observed that for almost all choices of η and b the algorithm converges near the minimizer
(with an error in the order of 10-6), hence the stationary distribution ν∞ seems to be a degenerate
distribution, which does not admit a heavy-tailed behavior. Regarding the observed link between
heavy-tails and generalization (Martin & Mahoney, 2019; SimSekli et al., 2020), this behavior of
RMSProp and SVRG might be related to their ineffective generalization performance as reported in
Keskar & Socher (2017); Defazio & Bottou (2019).
Experiments on fully connected neural networks. In the second set of experiments, we investigate
the applicability of our theory beyond the quadratic optimization problems. Here, we follow the
setup of SS imsSekli et al. (2019a) and consider a fully connected neural network with the cross entropy
7The form of X can be verified by noticing that E[xk] converges to the minimizer of the problem by the
law of total expectation. Besides, our GCLT requires the sum of the iterates to be normalized by (K-K >∕α ；
however, for a finite K, normalizing by K-KO results in a scale difference, to which our tail-index estimator is
agnostic.
8
Under review as a conference paper at ICLR 2021
(a) MNIST
(b) CIFAR10
Figure 2: Results on FCNs. Different markers represent different initializations with the same η, b.
loss and ReLU activation functions on the MNIST and CIFAR10 datasets. We train the models by
using SGD for 10K iterations and we range η from 10-4 to 10-1 and b from 1 to 10. Since it would
be computationally infeasible to repeat each run thousands of times as we did in the synthetic data
experiments, in this setting We follow a different approach based on (i) (SimSekli et al., 2019a) that
suggests that the tail behavior can differ in different layers of a neural network, and (ii) (De Bortoli
et al., 2020) that shows that in the infinite width limit, the different components of a given layer of a
two-layer fully connected network (FCN) becomes independent. Accordingly, we first compute the
average of the last 1K SGD iterates, whose distribution should be close an α-stable distribution by
the GCLT. We then treat each layer as a collection of i.i.d. α-stable random variables and measure
the tail-index of each individual layer separately by using the the estimator from Mohammadi et al.
(2015). Figure 2 shows the results for a three-layer network (with 128 hidden units at each layer) ,
whereas we obtained very similar results with a two-layer network as well. We observe that, while the
dependence of a on n/b differs from layer to layer, in each layer the measured α correlate very-well
with the ratio n/b in both datasets.
Experiments on VGG networks. In
our last set of experiments, we evalu-
ate our theory on VGG networks (Si-
monyan & Zisserman, 2015) with 11
layers (10 convolutional layers with
max-pooling and ReLU units, followed
by a final linear layer), which contains
10M parameters. We follow the same
procedure as we used for the fully con-
nected networks, where we vary n from
10-4 to 1.7 × 10-3 and b from 1 to 10.
The results are shown in Figure 3. Sim-
ilar to the previous experiments, we ob-
serve that α depends on the layer. For
the intermediate layers (Layers 2-8),
the tail index correlates well with the
Layer:2
Layer:3
Layer:4
Layer:11
0	1	2	0	1	2	0	1	2
10-3	Xi。-3	TIIb Xi。-3	nib xi0-3
ratio n/b, whereas the first and last two Figure 3: Results on VGG networks. The values of α that
convolutional layers (Layers 9 and 10) exceeded 2 is truncated to 2 for visualization purposes.
exhibit a Gaussian behavior (α ≈ 2).
On the other hand, the tail-index of the last layer (which is linear) does not correlate with either n or b.
These observations provide further support for our theory and show that the heavy-tail phenomenon
also occurs in neural networks, whereas α is potentially related to n and b in a more complicated way.
5	Conclusion and Future Directions
We studied the tail behavior of the SGD in a quadratic optimization problem and showed that
depending on the curvature, n, and b, the iterates can converge to a heavy-tailed random variable. We
further supported our theory with experiments conducted on fully connected neural networks and
illustrated that our results would also apply to more general settings and hence provide new insights
about the behavior of SGD in deep learning. This study also brings up a number of future directions.
(i) Our proof techniques are for the streaming setting, where each sample is used only once. However,
in practice SGD is typically implemented on the finite-sum problem (1.2) with multiple passes over
the data. Extending our results to this scenario and investigating the effects of finite-sample size on
the tail index and generalization would be an interesting future research direction. (ii) We suspect
that the tail index of the SGD iterates may have an impact on the time required to escape a saddle
point and this can be investigated further as another future research direction.
9
Under review as a conference paper at ICLR 2021
References
Alnur Ali, Edgar Dobriban, and Ryan J Tibshirani. The implicit regularization of stochastic gradient
flow for least squares. arXiv preprint arXiv:2003.07802, 2020.
Gerold Alsmeyer and Sebastian Mentemeier. Tail behaviour of stationary solutions of random differ-
ence equations: the case of regular matrices. Journal of Difference Equations and Applications, 18
(8):1305-1332, 2012.
Heiko Bauke. Parameter estimation for power-law distributions by maximum likelihood methods.
The European Physical Journal B, 58(2):167-173, 2007.
Gerard Ben Arous and Alice Guionnet. The spectrum of heavy tailed random matrices. Communica-
tions in Mathematical Physics, 278(3):715-751, 2008.
Jean Bertoin. Levy Processes. Cambridge University Press, 1996.
Dariusz Buraczewski, Ewa Damek, and Mariusz Mirek. Asymptotics of stationary solutions of
multivariate stochastic recursions with heavy tailed inputs and related limit theorems. Stochastic
Processes and Their Applications, 122(1):42-67, 2012.
Dariusz Buraczewski, Ewa Damek, Yves Guivarc’h, and Sebastian Mentemeier. On multidimensional
Mandelbrot cascades. Journal of Difference Equations and Applications, 20(11):1523-1567, 2014.
Dariusz Buraczewski, Ewa Damek, and Tomasz Przebinda. On the rate of convergence in the Kesten
renewal theorem. Electronic Journal of Probaiblity, 20(22):1-35, 2015.
Dariusz Buraczewski, Ewa Damek, and Thomas Mikosch. Stochastic Models with Power-Law Tails.
Springer, 2016.
Pratik Chaudhari and Stefano Soatto. Stochastic gradient descent performs variational inference, con-
verges to limit cycles for deep networks. In International Conference on Learning Representations,
2018.
Xiang Cheng, Dong Yin, Peter L Bartlett, and Michael I Jordan. Stochastic gradient and langevin
processes. arXiv preprint arXiv:1907.03215, 2019.
Aaron Clauset, Cosma Rohilla Shalizi, and Mark EJ Newman. Power-law distributions in empirical
data. SIAM Review, 51(4):661-703, 2009.
Valentin De Bortoli, Alain Durmus, Xavier Fontaine, and Umut Simsekli. Quantitative propagation
of chaos for sgd in wide neural networks. arXiv preprint arXiv:2007.06352, 2020.
Aaron Defazio and Leon Bottou. On the ineffectiveness of variance reduced optimization for deep
learning. In Advances in Neural Information Processing Systems, pp. 1755-1765, 2019.
Aymeric Dieuleveut, Alain Durmus, and Francis Bach. Bridging the gap between constant step size
stochastic gradient descent and Markov chains. arXiv preprint arXiv:1707.06386, 2017a.
Aymeric Dieuleveut, Nicolas Flammarion, and Francis Bach. Harder, better, faster, stronger con-
vergence rates for least-squares regression. The Journal of Machine Learning Research, 18(1):
3520-3570, 2017b.
Laurent Dinh, Razvan Pascanu, Samy Bengio, and Yoshua Bengio. Sharp minima can generalize for
deep nets. In Proceedings of the 34th International Conference on Machine Learning-Volume 70,
pp. 1019-1028. JMLR. org, 2017.
Holger Fink and Claudia Kluppelberg. Fractional L6vy-driven Ornstein-Uhlenbeck processes and
stochastic differential equations. Bernoulli, 17(1):484-506, 2011.
Roy Frostig, Rong Ge, Sham M Kakade, and Aaron Sidford. Competing with the empirical risk
minimizer in a single pass. In Conference on Learning Theory, pp. 728-763, 2015.
Charles M Goldie. Implicit renewal theory and tails of solutions of random equations. Annals of
Applied Probability, 1(1):126-166, 1991.
10
Under review as a conference paper at ICLR 2021
Michel L Goldstein, Steven A Morris, and Gary G Yen. Problems with fitting to the power-law
distribution. The European Physical Journal B-Condensed Matter and Complex Systems, 41(2):
255-258, 2004.
Amelia Henriksen and Rachel Ward. Concentration inequalities for random matrix products. Linear
Algebra and its Applications, 594:81-94, 2020.
Geoffrey Hinton, Nitish Srivastava, and Kevin Swersky. Overview of mini-batch gradient descent.
Neural Networks for Machine Learning, Lecture 6a, 2012. URL http://www.cs.toronto.
edu/~hinton/coursera/lecture6/lec6.pdf.
SePP Hochreiter and Jurgen Schmidhuber. Flat minima. Neural Computation, 9(1):142, 1997.
Liam Hodgkinson and Michael W Mahoney. Multiplicative noise and heavy tails in stochastic
oPtimization. arXiv preprint arXiv:2006.06293, 2020.
Wenqing Hu, Chris Junchi Li, Lei Li, and Jian-Guo Liu. On the diffusion aPProximation of nonconvex
stochastic gradient descent. Annals of Mathematical Science and Applications, 4(1):3-32, 2019.
De Huang, Jonathan Niles-Weed, Joel A. TroPP, and Rachel Ward. Matrix concentration for Products.
arXiv preprint arXiv:2003.05437, 2020.
Peter J Huber. Robust estimation of a location Parameter. In Breakthroughs in statistics, PP. 492-518.
SPringer, 1992.
Prateek Jain, Sham M Kakade, Rahul Kidambi, Praneeth NetraPalli, and Aaron Sidford. Accelerating
stochastic gradient descent. In Proc. STAT, volume 1050, PP. 26, 2017.
StanislaW Jastrzebski, Zachary Kenton, Devansh Arpit, Nicolas Ballas, Asja Fischer, Yoshua Bengio,
and Amos Storkey. Three factors influencing minima in SGD. arXiv preprint arXiv:1711.04623,
2017.
Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using Predictive variance
reduction. In Advances in Neural Information Processing Systems, PP. 315-323, 2013.
Nitish Shirish Keskar and Richard Socher. ImProving generalization Performance by sWitching from
Adam to SGD. arXiv preprint arXiv:1712.07628, 2017.
Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter
Tang. On large-batch training for deeP learning: Generalization gaP and sharP minima. arXiv
preprint arXiv:1609.04836, 2016.
Harry Kesten. Random difference equations and reneWal theory for Products of random matrices.
Acta Mathematica, 131:207-248, 1973.
Paul L6vy. Theorie de l,addition des variables al6atoires. Gauthiers-Villars, Paris, 1937.
Aitor LeWkoWycz, Yasaman Bahri, Ethan Dyer, Jascha Sohl-Dickstein, and Guy Gur-Ari. The large
learning rate Phase of deeP learning: the cataPult mechanism. arXiv preprint arXiv:2003.02218,
2020.
Qianxiao Li, Cheng Tai, and Weinan E. Stochastic modified equations and adaPtive stochastic
gradient algorithms. In Proceedings of the 34th International Conference on Machine Learning,
PP. 2101-2110, 06-11 Aug 2017.
Po-Ling Loh and Martin J WainWright. Regularized m-estimators With nonconvexity: Statistical and
algorithmic theory for local oPtima. The Journal of Machine Learning Research, 16(1):559-616,
2015.
StePhan Mandt, MattheW D. Hoffman, and David M. Blei. A variational analysis of stochastic
gradient algorithms. In International Conference on Machine Learning, PP. 354-363, 2016.
Charles H Martin and Michael W Mahoney. Traditional and heavy-tailed self regularization in neural
netWork models. arXiv preprint arXiv:1901.08276, 2019.
11
Under review as a conference paper at ICLR 2021
Mariusz Mirek. Heavy tail phenomenon and convergence to stable laws for iterated Lipschitz maps.
Probability Theory and Related Fields,151(3-4):705-734, 2011.
Mohammad Mohammadi, Adel Mohammadpour, and Hiroaki Ogata. On estimating the tail index
and the spectral measure of multivariate α-stable distributions. Metrika, 78(5):549-561, 2015.
Charles M Newman. The distribution of Lyapunov exponents: Exact results for random matrices.
Communications in Mathematical Physics, 103(1):121-126, 1986.
Thanh Huy Nguyen, Umut Simsekli, Mert Gurbuzbalaban, and Gael Richard. First exit time analysis
of stochastic gradient descent under heavy-tailed gradient noise. In Advances in Neural Information
Processing Systems, pp. 273-283, 2019.
Bernt 0ksendal. Stochastic Differential Equations: An Introduction with Applications. Springer
Science & Business Media, 2013.
Abhishek Panigrahi, Raghav Somani, Navin Goyal, and Praneeth Netrapalli. Non-Gaussianity of
stochastic gradient noise. arXiv preprint arXiv:1910.09626, 2019.
Vygantas Paulauskas and Marijus Vaiciulis. Once more on comparison of tail index estimators. arXiv
preprint arXiv:1104.1242, 2011.
Ilya Pavlyukevich. Cooling down L6vy flights. Journal ofPhysics A: Mathematical and Theoretical,
40(41):12299-12313, 2007.
Shai Shalev-Shwartz and Shai Ben-David. Understanding Machine Learning: From Theory to
Algorithms. Cambridge University Press, 2014.
Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. In ICLR, 2015.
Umut Simgekli, Mert Gurbuzbalaban, Thanh Huy Nguyen, Gael Richard, and Levent Sagun. On
the heavy-tailed theory of stochastic gradient descent for deep neural networks. arXiv preprint
arXiv:1912.00018, 2019a.
Umut Sg imsgekli, Levent Sagun, and Mert Gurbuzbalaban. A tail-index analysis of stochastic gradient
noise in deep neural networks. In International Conference on Machine Learning, pp. 5827-5837,
2019b.
Umut Sgimsgekli, Ozan Sener, George Deligiannidis, and Murat A Erdogdu. Hausdorff dimen-
sion, stochastic differential equations, and generalization in neural networks. arXiv preprint
arXiv:2006.09313, 2020.
George Tzagkarakis, John P Nolan, and Panagiotis Tsakalides. Compressive sensing of tempo-
rally correlated sources using isotropic multivariate stable laws. In 2018 26th European Signal
Processing Conference (EUSIPCO), pp. 1710-1714. IEEE, 2018.
CCdricVillani. Optimal Transport: Old and New. Springer, Berlin, 2009.
Jingzhao Zhang, Sai Praneeth Karimireddy, Andreas Veit, Seungyeon Kim, Sashank J Reddi,
Sanjiv Kumar, and Suvrit Sra. Why ADAM beats SGD for attention models. arXiv preprint
arXiv:1912.03194, 2019.
Zhanxing Zhu, Jingfeng Wu, Bing Yu, Lei Wu, and Jinwen Ma. The anisotropic noise in stochastic
gradient descent: Its behavior of escaping from minima and regularization effects. arXiv preprint
arXiv:1803.00195, 2018.
12
Under review as a conference paper at ICLR 2021
A A Note on Stochastic Differential Equation Representations
for SGD
In recent years, a popular approach for analyzing the behavior of SGD has been viewing it as
a discretization of a continuous-time stochastic process that can be represented via a stochastic
differential equation (SDE)(Mandt et al., 2016; Jastrzebski et al., 2017; Li et al., 2017; HU et al.,
2019; ZhU et al., 2018; Chaudhari & Soatto, 2018; SimSekli et al., 2019b). While these SDEs have
been useful for understanding different properties of SGD, their differences and functionalities have
not been clearly understood. In this section, in the light of our theoretical results, we will discuss in
which situation their choice would be more appropriate. We will restrict ourselves to the case where
f (x) is a quadratic function; however, the discussion can be extended to more general f .
The SDE approximations are often motivated by first rewriting the SGD recursion as follows:
χk+ι = Xk - η^fk+ι (Xk) = Xk - nW (Xk) + ηUk+ι(χk),	(A.1)
where Uk (x) := Vfk (x) - Vf (x) is called the stochastic gradient noise . Then, based on certain
statistical assumptions on Uk, we can view (A.1) as a discretization of an SDE. For instance, if we
assume that the gradient noise follows a Gaussian distribution, whose covariance does not depend
on the iterate Xk, i.e., nU ≈ √ηZk where Zk 〜 N(0, σznI) for some constant σz > 0, We can
see (A.1) as the Euler-Maruyama discretization of the following SDE with stepsize η (Mandt et al.,
2016):
dXt = -Vf (Xt)dt + √ησzdBt,	(A.2)
where Bt denotes the d-dimensional standard Brownian motion. This process is called the Ornstein-
Uhlenbeck (OU) process (see e.g. 0ksendal (2013)), whose invariant measure is a Gaussian distribu-
tion. We argue that this process can be a good proxy to (3.3) only when α ≥ 2, since otherwise the
SGD iterates will exhibit heavy-tails, whose behavior cannot be captured by a Gaussian distribution.
As we illustrated in Section 4, to obtain large α, the step-size η needs to be small and/or the batch-size
b needs to be large. However, it is clear that this approximation will fall short when the system exhibits
heavy tails, i.e., α < 2. Therefore, for the large η∕b regime, which appears to be more interesting
since it often yields improved test performance (Jastrzebski et al., 2017), this approximation would
be inaccurate for understanding the behavior of SGD. This problem mainly stems from the fact that
the additive isotropic noise assumption results in a deterministic Mk matrix for all k. Since there is
no multiplicative noise term, this representation cannot capture a potential heavy-tailed behavior.
A natural extension of the state-independent Gaussian noise assumption is to incorporate the covari-
ance structure of Uk. In our linear regression problem, we can easily see that the covariance matrix
of the gradient noise has the following form:
σ2
∑u(x) = Cov(Uk|x)=石diag(X ◦ x),	(A.3)
where ◦ denotes element-wise multiplication and σ2 is the variance of the data points. Therefore,
we can extend the previous assumption by assuming Zk |x 〜N(0, η∑u(x)). It has been observed
that this approximation yields a more accurate representation (Cheng et al., 2019; Ali et al., 2020;
Jastrzebski et al., 2017). Using this assumption in (A.1), the SGD recursion coincides with the
Euler-Maruyama discretization of the following SDE:
dxt = -Vf (Xt)dt + vζη∑u (Xt) dBt
=—(A>Axt — A>y) dt + ∖J ；diag(xt)dBt,	(A.4)
where =d denotes equality in distribution. The stochasticity in such SDEs is called often called
multiplicative. Let us illustrate this property by discretizing this process and by using the definition
of the gradient and the covariance matrix, we observe that (noting that Nk 〜N(0, I))
xk+1 = xk - η (A>Axk - A>y) + γ -b-diag(xkINk+1
=(I - ηA>A + pσ2η2∕b diag(Nk+ι)) Xk - ηA>y,	(A.5)
13
Under review as a conference paper at ICLR 2021
where we can clearly see the multiplicative effect of the noise, as indicated by its name. On the other
hand, we can observe that, thanks to the multiplicative structure, this process would be able to capture
the potential heavy-tailed structure of SGD. However, there are two caveats. The first one is that,
in the case of linear regression, the process is called a geometric (or modified) Ornstein-Uhlenbeck
process which is an extension of geometric Brownian motion. One can show that the distribution of
the process at any time t will have lognormal tails. Hence it will be accurate only when the tail-index
α is close to the one of the lognormal distribution. The second caveat is that, for a more general cost
function f, the covariance matrix is more complicated and hence the invariant measure of the process
cannot be found analytically, hence analyzing these processes for a general f can be as challenging
as directly analyzing the behavior of SGD.
The third way of modeling the gradient noise is based on assuming that it is heavy-tailed. In
particular, We can assume that ηU ≈ n1/aLk where [Lk]i 〜 SaS(σLη(α-1)∕α) for all i = 1,...,d.
Under this assumption the SGD recursion coincides with the Euler discretization of the following
L6vy-driven SDE (SimsekIi et al., 2019b):
dxt = -Vf (xt)dt + σLη(α-1"αdLα,	(A.6)
where La denotes the α-stable LeVy process with independent components (see Section A.1 for
technical background on LeVy processes and in particular α-stable LeVy processes). In the case of
linear regression, this processes is called a fractional OU process (Fink & Kluppelberg, 2011), whose
inVariant measure is also an α-stable distribution with the same tail-index α. Hence, eVen though it
is based on an isotropic, state-independent noise assumption, in the case of large n/b regime, this
approach can mimic the heaVy-tailed behaVior of the system with the exact tail-index α. On the other
hand, Buraczewski et al. (2016) (Theorem 1.7 and 1.16) showed that if Uk is assumed to heaVy tailed
with index α (not necessarily SαS) then the process xk will inherit the same tails and the ergodic
aVerages will still conVerge to an SαS random Variable, hence generalizing the conclusions of the
SαS assumption to the case where Uk follows an arbitrary heaVy-tailed distribution.
A.1 Technical background： LEVY processes
LeVy motions (processes) are stochastic processes with independent and stationary increments, which
include Brownian motions as a special case, and in general may haVe heaVy-tailed distributions (see
e.g. Bertoin (1996) for a surVey). Symmetric α-stable LeVy motion is a LeVy motion whose time
increments are symmetric α-stable distributed. We define Ltα, a d-dimensional symmetric α-stable
LeVy motion as follows. Each component of Ltα is an independent scalar α-stable LeVy process
defined as follows:
(i)	L0α = 0 almost surely;
(ii)	For any to < tι < …< tN, the increments La — La I are independent, n = 1,2,...,N;
(iii)	The difference La — La and Lo-S have the same distribution: SɑS((t 一 s)1/a) for s < t;
(iV)	Lta has stochastically continuous sample paths, i.e. for any δ > 0 and s ≥ 0, P(|Lta - Lsa| >
δ) → 0 as t → s.
When α = 2, we obtain a scaled Brownian motion as a special case, i.e. La = √2Bt, so that the
difference Lta - Lsa follows a Gaussian distribution N(0, 2(t - s)).
B	Tail-Index Estimation
In this study, we follow Tzagkarakis et al. (2018); SimSekIi et al. (2019b), and make use of the recent
estimator proposed by Mohammadi et al. (2015).
Theorem 10 (Mohammadi et al. (2015) corollary 2.4). Let {Xi}iK=1 be a collection of strictly stable
random variables in Rd with tail-index α ∈ (0, 2] andK = K1 ×K2. Define Yi = PjK=11 Xj+(i-1)K1
for i ∈ J1, K2K. Then, the estimator
d1	1	1 K2	1 K
α , log瓦(k2 Xlog kYik- κ Xlog kXik)，	(B.1)
14
Under review as a conference paper at ICLR 2021
converges to 1∕a almost surely, as K → ∞.
As this estimator requires a hyperparameter K1, at each tail-index estimation, we used several values
for K1 and we used the median of the estimators obtained with different values of K1 . We provide
the codes in the supplement, where the implementation details can be found. For the neural network
experiments, We used the same setup as provided in the repository of SimSekli et al. (2019b).
C Proofs of Main Results
C.1 Proof of Theorem 1
Proof of Theorem 1. The proof folloWs from (BuraczeWski et al., 2016, Thm 4.4.15) Which goes
back to (Alsmeyer & Mentemeier, 2012, Theorem 1.1) and Kesten (Kesten, 1973, Theorem 6). See
also (Goldie, 1991; BuraczeWski et al., 2015). We recall that We have the stochastic recursion:
xk = Mk xk-1 + qk,	(C.1)
Where the sequence (Mk, qk) are i.i.d. distributed as (M, q) and for each k, (Mk, qk) is independent
of xk-1. To apply (BuraczeWski et al., 2016, Thm 4.4.15), it suffices to have the folloWing conditions
being satisfied:
1.	M is invertible With probability 1.
2.	The matrix M has a continuous Lebesgue density that is positive in a neighborhood of the
identity matrix.
3.	ρ < 0 and h(α) = 1.
4.	P(Mx + q = x) < 1 for every x.
5.	E kM kα(log+ kMk +log+kM-1k) < ∞.
6.	0 < Ekqkα < ∞.
All the conditions are satisfied under our assumptions. In particular, Condition 1 and Condition 5
are proved in Lemma 18, and Condition 2 and Condition 4 folloW from the fact that M and q have
continuous distributions. If ρ < 0, then by Lemma 15, We have h(0) = 1, h0(0) = ρ < 0 and h(s)
is convex in s, and moreover by Lemma 16, We have lim infs→∞ h(s) > 1. Therefore, there exists
some α ∈ (0, ∞) such that h(α) = 1, Which gives Condition 3. Finally, Condition 6 is satisfied by
the definition of q and by the Assumptions (A1)-(A2).	□
C.2 Proof of Theorem 2
Proof of Theorem 2. We Will split the proof of Theorem 2 into tWo parts:
(I)	We Will shoW that the tail-index α is strictly decreasing in stepsize η and variance σ2 provided
that α ≥ 1.
(II)	We Will shoW that the tail-index α is strictly increasing in batch size b provided that α ≥ 1.
(III)	We Will shoW that the tail-index α is strictly decreasing in dimension d.
First, let us prove (I). Let a := ησ2 > 0 be given. Consider the tail-index α as a function of a, i.e.
α(a) := min{s : h(a, s) = 1} ,
Where h(a, s) = h(s) With emphasis on dependence on a.
By assumption, α(a) ≥ 1. The function h(a, s) is convex function of a (see Lemma 19 for s ≥ 1
and a strictly convex function of s for s ≥ 0). Furthermore, it satisfies h(a, 0) = 1 for every a ≥ 0
and h(0, s) = 1 for every s ≥ 0. We consider the curve
C := {(a, s) ∈ (0, ∞) × [1, ∞] : h(a, s) = 1} .
15
Under review as a conference paper at ICLR 2021
This is the set of the choice of a, which leads to a tail-index s where s ≥ 1. Since h is smooth in both
a and s, we can represent s as a smooth function of a, i.e. on the curve
h(a, s(a)) = 0 ,
where s(a) is a smooth function of a. We will show that s0(a) < 0; i.e. ifwe increase a; the tail-index
s(a) will drop. Pick any (a*, s*) ∈ C, it will satisfy h(a*, s*) = 1. We have the following facts:
(i)	The function h(a, s) = 1 for either a = 0 or s = 0. This is illustrated in Figure 4 with a
blue marker.
(ii)	h(a*, S) < 1 for s < s*. This follows from the convexity of h(a*, S) function and the fact
that h(a*, 0) = 1, h(a*, s* ) = 1. From here, We see that the function h(a*, S) is increasing
at s = s* and We have its derivative
∂h
(a~(a*, s*) > 0.
∂S
(iii)	The function h(a, S*) is convex as a function of a by Lemma 19, it satisfies h(0, S*) =
h(a*, S*) = 1. Therefore, by convexity h(a, S*) < 1 for a ∈ (0, S*); otherwise the function
h(a, s*) would be a constant function. We have therefore necessarily.
∂h
~a~(a*, s*) > 0.
∂a
By convexity of the function h(a, s*), We have also h(a, s*) ≥ h(a*, s*) + ∂h(a*,s*)(a -
a*) > h(a*,s*) = 1. Therefore, h(a,s*) > 1 for a > a*. Then, it also follows that
h(a, S) > 1 for a > a* and S > S* (otherwise if h(a, S) ≤ 1, we get a contradiction
because h(0, S) = 1, h(a*, S) > 1 and h(a, S) ≤ 1 is impossible due to convexity). This is
illustrated in Figure 4 where we mark this region as a rectangular box where h > 1.
(iv)	By similar arguments we can show that the function h(a, S) < 1 if (S, a) ∈ (0, a*) × [1, S*).
Indeed, if h(a, S) ≥ 1 for some (S, a) ∈ [1, S*) × (0, a*), this contradicts the fact that
h(0, S) = 1 and h(a*, S) < 1 proven in part (ii). This is illustrated in Figure 4 where inside
the rectangular box on the left-hand side, we have h < 1.
Figure 4: The curve h(a, S) = 1 in the (a, S) plane
Geometrically, we see from Figure 4 that the curve S(a) as a function of a, is sandwiched between
two rectangular boxes and has necessarily S0(a) < 0. This can also be directly obtained rigorously
from the implicit function theorem; if we differentiate the implicit equation h(a, S(a)) = 0 with
respect to a, we obtain
∂h	∂h	0
(a- (a*, s*) + ^τj~(a*, s*)s (a*) = 0 .
∂a	∂S
From parts (ii) - (iii), We have ∂h (a*, s*) and ∂S (a*,s*) > 0. Therefore, We have
S0(a*)
Ba
祭(a
S*)
S*)
<0,
(C.2)
—
16
Under review as a conference paper at ICLR 2021
which completes the proof for s* ≥ 1.
Next, let us prove (II). With slight abuse of notation, we define the function h(b, s) = h(s) to
emphasize the dependence on b. We have
h(b, s)
e1
(C.3)
where we used Lemma 14. When s ≥ 1, the function x 7→ kxks is convex, and by Jensen’s inequality,
we get for any b ≥ 2 and b ∈ N,
s
h(b, s) = E
b X (占 XajaT 卜
≤E
1b
b X
i=1
1b
1 X E
b
i=1
I - bɪ X jj
j6=i
I - 占 X j
j6=i
h(b- 1, s),
where we used the fact that ai are i.i.d. Indeed, from the condition for equality to hold in Jensen’s
inequality, and the fact that ai are i.i.d. random, the inequality above is a strict inequality. Hence
when d ∈ N for any s ≥ 1, h(b, s) is strictly decreasing inb. By following the same argument as in
the proof of (I), we conclude that the tail-index α is strictly increasing in batch size b.
Finally, let us prove (III). Let us show the tail-index α is strictly decreasing in dimension d. Since ai
are i.i.d. and a% ~ N(0, σ2Id), by Lemma 25,
h(s) = E ](l — 等 + a2X2 + a2XY广
b	b2	b2
(C.4)
where X, Y are independent chi-square random variables with degree of freedom b and d - 1
respectively. Notice that h(s) is strictly increasing in d since the only dependence of h(s) on d is via
Y, which is a chi-square distribution with degree of freedom (d-1). By writing Y = Z2 +---------+Zd-ι,
where Zi 〜N(0,1) i.i.d., it follows that h(s) is strictly increasing in d. Hence, by similar argument
as in (I), we conclude that α is strictly decreasing in dimension d.	口
Remark 11. When d = 1 and ai are i.i.d. N(0, σ2), we can provide an alternative proof that the
tail-index α is strictly increasing in batch size b. It suffices to show that for any s ≥ 1, h(s) is strictly
decreasing in the batch size b. By Lemma 25 when d = 1,
h(b,s)= E "(1-竿X + ⅛4X2 + ⅞4XY广#
b	b2	b2
(C.5)
where h(b, s) is as in (C.3) and X, Y are independent chi-square random variables with degree of
freedom b and d - 1 respectively. When d = 1, we have Y ≡ 0, and
h(b,s)= E "(1-竿X + ⅞4X21
(C.6)
E h-卑 X
b
Since X is a chi-square random variable with degree of freedom b, we have
h(b, s) = E
T XZ『#
(C.7)
17
Under review as a conference paper at ICLR 2021
where Zi are i.i.d. N(0, 1) random variables. When s ≥ 1, the function x 7→ |x|s is convex, and by
Jensen’s inequality, we get for any b ≥ 2 and b ∈ N
s
h(b, s) = E
1b
b X
i=1
1 -总 X Zj
j6=i
≤E
1b
b X
i=1
2
ησ2
b - 1
2
ησ2
b - 1
XZjs
j 6=i
XZjs
j 6=i
h(b - 1, s),
where we used the fact that Zi are i.i.d. Indeed, from the condition for equality to hold in Jensen’s
inequality, and the fact that Zi are i.i.d. N(0, 1) distributed, the inequality above is a strict inequality.
Hence when d = 1 for any s ≥ 1, h(b, s) is strictly decreasing in b.
C.3 Proof of Proposition 3
Proofof Proposition 3. WeneXtProve(i). When η =%忧=σ2(d+b+i), that is ησ2(d+b +1) = 2b,
it follows from the proof of Proposition 23 that
P ≤ 1log E 1 -
2 b	24 b b
2ησ2	2	η2σ4
~~b~>JziI + ~bτ 工 Z^(zi1 zj1 +	+ zidzjd)zi1zj1
i=1	i=1 j=1
0.
(C.8)
Note that	Since 1 -	^n- Pi=I	z2ι	+	ηb2σ	Pi=I	Pj = I(Zi1zj1	+ •…+	zidzjd)zi1zj1	is random,
the inequality above is a strict inequality from Jensen’s inequality. Thus, when η = ηcrit, i.e.
ησ2 (d + b + 1) = 2b, ρ < 0. By continuity, there eXists some δ > 0 such that for any 2b <
ησ? (d + b + I) < 2b + δ, i.e. ηcrit < η < ηmaχ, Where ηmaχ := ηcrit + σ2(d+b+1), Wehave ρ < 0.
Moreover, when ησ2(d + b + 1) > 2b, i.e. η > ηcrit, we have
2ησ2 b	2 η2σ4 b b
h(2) = EiI--------b— z .zi1 + ■-b2- 上上(ZiIzjI +	+ zidzjd)zi1zj1
b i=1	b i=1 j=1
=1 — 2ησ2 + ɪɪ——(d + b + 1) ≥ 1,
b
Which imPlies that there eXists some 0 < α < 2 such that h(α) = 1.
Finally, let us Prove (ii) and (iii). When ησ2 (d + b + 1) ≤ 2b, i.e. η ≤ ηcrit, We have h(2) ≤ 1,
Which imPlies that α > 2. In Particular, When ησ2 (d + b + 1) = 2b, i.e. η = ηcrit, the tail-indeX
α = 2.
C.4 Proof of Theorem 4 and Corollary 5
Proof of Theorem 4. We recall that
xk = Mkxk-1 + qk,	(C.9)
Which imPlies that
kxkk ≤ kMkxk-1k + kqkk.	(C.10)
(i) If the tail-indeX α ≤ 1, then for any 0 < p < α, We have h(p) = EkMke1 kp < 1 and moreover
by Lemma 20,
kxkkp≤ kMkxk-1kp + kqkkp.	(C.11)
Due to spherical symmetry of the isotropic Gaussian distribution, the distribution of 唯『does
not depend on the choice of X ∈ Rd∖{0}. Therefore, 喂广-1k and ∣∣χk-ι∣∣ are independent, and
18
Under review as a conference paper at ICLR 2021
kM广-jk has the same distribution as ∣∣Mkeι ∣∣, where eι is the first basis vector. It follows that
Ekxkkp ≤ EkMke1kpEkxk-1kp + Ekqkkp,	(C.12)
so that
E∣xk∣p ≤ h(p)E∣xk-1∣p + E∣q1∣p,	(C.13)
where h(p) ∈ (0, 1). By iterating over k, we get
Ekxk kp ≤ (h(p))kE∣xokp + 1 - (h(PT Ekq"F	(C.14)
1 - h(p)
(ii) If the tail-index α > 1, then for any 1 < p < α, by Lemma 20, for any > 0, we have
p
(1 + e) P-1 — (1+ e)
kxk kp ≤ (1 + e)∣Mkxk-1 kp + k7+j-I ( + P) kqk kp,
((1 + e) p-1 — 1)
which (similar as in (i)) implies that
p
(1 + e) P-1 — (1 + e)
Ekxkkp ≤ (1 + e)E∣MkeιkpE∣xk-ikp + 17+j-1 ( + p)Ekqkkp,
((1 + e)p=1 — 1)
so that
p
(1 + e) P-1 — (1 + e)
Ekxkkp ≤ (1 + e)h(p)Ekxk-Ikp + kτ+-)~I ( + p)Ekqιkp.
((1 + -)pτ - 1)
We choose - > 0 so that (1 + -)h(p) < 1. By iterating over k, we get
Ekxkkp ≤ ((1 + -)h(ρ))kEkxokp +1 7 ((1+ -)h(p))k (1+ -)P-T J (1+ PEkqιkp.
1 — (1 + -)h(p)	((1 + -) P-τ - 1y
The proof is complete.
(C.15)
(C.16)
(C.17)
(C.18)
□
Remark 12. In general, there is no closed-form expression for Ekq1 kp in Theorem 4. We provide an
upper bound as follows. When p > 1, by Jensen’s inequality, we can compute that
Ekq1kp = ηpE
≤ ηbp XXEkaiyikp = ηpE[∣yιlp kaιkp],
i=1
(C.19)
1b
b Eaiyi
i=1
and when p ≤ 1, by Lemma 20, we can compute that
≤
ηp XX Ekaiyikp
i=1
ηpE [|y1|p ka1kp].
(C.20)
ProofofCorollary 5. It follows from Theorem 4 by letting k → ∞ and applying Fatou,s lemma. □
C.5 Proof of Theorem 6, Corollary 7, Proposition 8 and Corollary 9
Proofof Theorem 6. For any νo, Vo ∈ Pp(Rd), there exists a couple xo 〜 νo and xo 〜 Vo indepen-
dent of (Mk, qk)k∈N and Wp)(Vo, Vo) = E∣∣xo — xokp. We define xk and xk starting from xo and xo
respectively, via the iterates
xk = Mkxk-1 + qk,	(C.21)
xVk = MkxVk-1 +qk,	(C.22)
and let νk and νVk denote the probability laws of xk and xVk respectively. For any p < α, since
EkMkkα = 1 and Ekqk kα < ∞, we have νk, νVk ∈ Pp(Rd) for any k. Moreover, we have
xk — xVk = Mk(xk-1 — xVk-1),	(C.23)
19
Under review as a conference paper at ICLR 2021
Due to spherical symmetry of the isotropic Gaussian distribution, the distribution of 唯『does
not depend on the choice of X ∈ Rd∖{0}. Therefore, kM：([k---Xk-j)k and IIxk-I - Xk-ιk are
independent, and kMk(xk---以-I)k has the same distribution as ∣∣Mkeι∣, where eι is the first basis
kxk-1 -xk-1 k
vector. It follows from (C.23) that
Ekxk - xkkp ≤ E [∣Mk(xk-ι - xk-ι)kp]
=E[∣Mk eιkp] E [∣xk-ι - xk-ikp]
=h(p)E [∣xk-i - xk-ikp],
which by iterating implies that
Wp(Vk, Vk) ≤ Ekxk- xkkp ≤ (h(p))kE∣xo - xokp = (h(p))kWp(νo, Vo).	(C.24)
By letting Vo = ν∞, the probability law of the stationary distribution x∞, We conclude that
k
(h(p))1/q	Wp(Vo, V∞).	(C.25)
Finally, notice that 1 ≤ p < α, and therefore h(p) < 1. The proof is complete.	□
ProofofCoroUary 7. When ησ2 < 壮^^, by Proposition 3, the tail-index a > 2, by taking P = 2,
24
and using h(2) = 1 - 2ησ2 + η^- (d + b + 1) < 1 (see Proposition 3), it follows from Theorem 6
that
2	k/2
W2(νk,ν∞ ) ≤ (1 - 2ησ2 (1 - ^2b^ (d + b +1)))	W2(ν0, ν∞).	(C∙26)
□
Remark 13. Consider the case ai are i.i.d. N (0, σ2Id). In Theorem 4, Corollary 5 and Theorem 6,
the key quantity is h(p) ∈ (0, 1), where p < α. We recall that
h(p)=E](1- 2aX+a2X 2+a2XY 广
(C.27)
where a = ησ2, X, Y are independent chi-square random variables with degree of freedom b and
d - 1 respectively. The first-order approximation of h(p) is given by
h(p)〜1 + pE [- 2O-X + a2X2 + a2XY1 = 1 + P [-2a + a (b + 2) + a (d - 1)] < 1,
2 b	b2	b2	2	b	b
(C.28)
provided that a = ησ2 < d+2+ι which occurs if and only if α > 2. In other words, when
ησ2 < d+b+ι, α > 2 and
2	ησ2(b + d+ 1)
h(p)〜1 - pησ2 ( 1------2b----- I < 1.
(C.29)
On the other hand, when ησ2 ≥ d+匕,p < ɑ ≤ 2, and the second-order approximation of h(p) is
given by
h(p)〜1 + pE -
2a a2 2	a2
万X+庐X 2+庐XY +
—E [(-2-X+a2 X 2+a2 XY 丁
+ d+ 1)	2 -p	2a	a2	a2	2
1+qa	-1 - TE -万X+庐X 2+庐 xy
and we computed before in (E.55) that for small a = ησ2 and large d,
E ](-2-X+a2 X 2+a XY)
b b2	b2
〜4a- (b + 2) + a4(b + 2)d2 -
+ 2)d, (C.30)
20
Under review as a conference paper at ICLR 2021
and therefore with a = ησ2,
-a(b + d + 1)	(2 - p)a(b + 2) a2 2 a
h(P)〜1 -Pa (	2b +1 +	2qb	1+ + 而d2 - bd))< 1，(C.31)
provided that 1 ≤ a(b+b+1) < 1 + (2-p2a(b+2) (1 + 总 d2 一 a °.
Proof of Proposition 8. First, we notice that it follows from Theorem 1 that Ekx∞ kα = ∞. To see
this, notice that limt→∞ tαP(e1Tx∞ > t) = eα(e1), where e1 is the first basis vector in Rd, and
P(kx∞ k ≥ t) ≥ P(e1T x∞ ≥ t), and thus
∞
0
∞
0
Ekx∞kα
tP(kx∞kα ≥ t)dt
tP(kx∞k ≥ t1/a)dt
∞.
(C.32)
By following the proof of Theorem 4 by letting q= α in the proof, one can show the following.
(i)	If the tail-index α ≤ 1, then we have
Ekx∞kα ≤ Ekx0kα + kEkq1kα,	(C.33)
which grows linearly in k.
(ii)	If the tail-index α > 1, then for any > 0, we have
(1 + e)k 一 1(1 + E)α-ι 一 (1 + E)
Ekxkkα ≤ (1 + E)kEkxokα + (ɪ)——(7+-)-I ( + α)EkqIka = O(k),	(C.34)
E	((1 + E)α-1 - 1)
which grows exponentially in k for any fixed E > 0. By letting E → 0, we have
Ekxkka = (1 + E)kEkxoka + (1 + O(E))((1 + E)k - 1)(。一；"Ekqιka.
Therefore, it holds for any sufficiently small E > 0 that,
Ekxkka ≤ (1+^ (Ekxoka + (α - 1)a-1Ekqιka).
We Can optimize (IM- over the choice of e > 0, and by choosing E = ɪ-a, which goes to Zero as k
goes to ∞, we have (1+⅛)- = (1 + kαα)k (k—α)α = O(ka), and hence
Ekxkkα = O(kα),	(C.35)
which grows polynomially in k. The proof is complete.	□
Proof of Corollary 9. The result is obtained by a direct application of (Mirek, 2011, Theorem 1.15)
to the recursions (3.3) where it can be checked in a straightforward manner that the conditions for
this theorem hold.	□
D	Supporting Lemmas
In this section, we present a few supporting lemmas that are used in the proofs of the main results of
the paper as well as the additional results in the Appendix.
First, we recall that the iterates are given by xk = Mkxk-1 + qk, where (Mk, qk) are i.i.d. and Mk
is distributed as I 一 bH, where H = Pb=ι a%aT and qk is distributed as b Pb=ι aiyi, where a，i and
yi are i.i.d. satisfying the Assumptions (A1)-(A2).
We can compute ρ and h(s) as follows where ρ and h(s) are defined by (3.5) and (3.4).
Lemma 14. ρ can be characterized as:
P = E log Il(I - 三 H "I，	(D.1)
and h(s) can be characterized as:
h(s) = E h∣∣(l 一 MH)eι∣∣],	(D.2)
provided that ρ < 0.
21
Under review as a conference paper at ICLR 2021
Proof. It is known that the Lyapunov exponent defined in (3.5) admits the alternative representation
P := Iim 1 log l∣Xk k ,	(D.3)
k→∞ k
where Xk := ∏kXo with ∏k := MkMk-ι... Mi andXo := xo (see (Newman, 1986, eqn. (2))).
We will compute the limit on the right-hand side of (D.3). First, we observe that due to spherical
symmetry of the isotropic Gaussian distribution, the distribution of 八溜? does not depend on the
choice of X ∈ Rd∖{0} and is i.i.d. over k with the expectation E(∣Meι∣) = E(∣ (I 一 ηH) eι∣)
where we chose X = e1 . Therefore,
1 log kXk k- 1 log kXok = 1 XX log 严' = 1 XX log kMixi-1k
k	k	k i=l kxi-ik k = kxi-ik
is an average of i.i.d. random variables and by the law of large numbers we obtain
P = kli→∞ 1log kxkk = ENI-bH)小
From (D.3), we conclude that this proves (D.1). It remains to prove (D.2). We consider the function
h(S)
lim
k→∞
(E Br Y/k
I kXok* s *7
where the initial point Xo = xo is deterministic. In the rest of the proof, we will show that for ρ < 0,
h(S) = h(S) where h(S) is given by (3.4) and h(S) is equal to the right-hand side of (D.2); our proof
is inspired by the approach of Newman (1986). We will first compute h(s) and show that it is equal
to the right-hand side of (D.2). Note that we can write
kxk ks = YY kMixi-iks
百=L kXi-iks .
This is a product of i.i.d. random variables with the same distribution as that of kMe1 ks due to the
spherical symmetry of the input ai. Therefore, we can write
h(s)= lim (E抖Y/” = M (E YY	eiks)
k→∞	kXoks	k→∞	i=1
=E [∣Meιks]= E h∣∣(I - bH)ei『],	(D.4)
where we used the fact that Miei are i.i.d. over i. It remains to show that h(s) = h(s) for ρ < 0.
Note that jj∣θjjs ≤ ∣∣∏k∣s, and therefore from the definition of h(s) and h(s), we have immediately
h(s) ≥ h(s)	(D.5)
for any s > 0. We will show that h(s) ≤ h(s) when ρ < 0. We assume ρ < 0. Then, Theorem 1
is applicable and there exists a stationary distribution X∞ with a tail index α such that h(α) = 1.
We will show that h(α) = 1. First, the tail density admits the characterization (3.7), and therefore
X∞ ∈ Ls for S < α, i.e. the S-th moment of X∞ is finite. Similarly due to (3.7), X∞ ∈/ Ls for S > α.
Since h(α) = 1, it follows from (D.5) that we have h(α) ≤ 1. However if h(α) < 1, then by the
continuity of the h function there exists ε such that h(S) < 1 for every S ∈ (α - ε, α + ε) ⊂ (0, 1).
From the definition of h(s) then this would imply that E(∣Xk ∣∣s) → 0 for every S ∈ (α - ε,α + ε).
On the other hand, by following a similar argument to the proof technique of Corollary 5, it can be
shown that the S-th moment of X∞ has to be bounded,8 which would be a contradiction with the fact
that X∞ 6∈ Ls for S > α. Therefore, h(α) ≥ 1. Since h(α) = 1, (D.5) leads to
h(α) = h(α) = 1.	(D.6)
8Note that the proof of Corollary 5 establishes first that x∞ has a bounded s-th moment provided that
s
h(s) = E [kM e1 ks] < 1 and then cites Lemma 14 regarding the equivalence h(s) = h(s).
22
Under review as a conference paper at ICLR 2021
We observe that the function h is homogeneous in the sense that if the iterations matrices Mi are
replaced by cMi where c > 0 is a real scalar, h(s) will be replaced by hc(s) := csh(s). In other
words, the function
hc(s) := limk→∞ (Ek(cMk)(cMk-1)... (cM1)ks)1/k	(D.7)
clearly satisfies hc(s) = Csh(S) by definition. A similar homogeneity property holds for h(s): If
the iterations matrices Mi are replaced by cMi, then h(s) will be replaced by hc(s) := csh(s). We
will show that this homogeneity property combined with the fact that h(α) = h(α) = 1 will force
h(s) = h(s) for any s > 0. For this purpose, given s > 0, we choose C = 1/Vh(s). Then, by
considering input matrix cMi instead of Mi and by following a similar argument which led to the
identity (D.6), we can show that hc(s) = Csh(s) = 1. Therefore, hc(s) = hc(s) = 1. This implies
directly h(s) = h(s).
□
Next, we show the following property for the function h.
Lemma 15. We have h(0) = 1, h0(0) = ρ and h(s) is strictly convex in s.
Proof. By the expression of h(s) from Lemma 14, it is easy to check that h(0) = 1. Moreover, we
can compute that
h0(s) = E hlog (KI-bH) TD KI- bH )e1『i,	(D.8)
and thus
h0(0) = ρ.	(D.9)
Moreover, we can compute that
h00(s) = E (log (∣∣(I - bH) eι∣∣))2∣∣(I - IH "|] >。，	。⑼
which implies that h(s) is strictly convex in s.	口
In the next result, we show that lim infs→∞ h(s) > 1. This property, together with Lemma 15
implies that if ρ < 0, then there exists some α ∈ (0, ∞) such that h(α) = 1. Indeed, in the proof of
Lemma 16, we will show that lim infs→∞ h(s) = ∞.
Lemma 16. We have lim inf s→∞ h(s) > 1.
Proof. We recall from Lemma 14 that
h(s)= E∣∣(l- bH)eι∣∣s,
(D.11)
23
Under review as a conference paper at ICLR 2021
where e1 is the first basis vector in Rd and H = Pib=1 aiaiT, and ai = (ai1, . . . , aid) are i.i.d.
distributed as N(0, σ2Id). We can compute that
E
E
E NTH) e「E
η
b
aiOT )(l—b X aiOT! ej
2 s/2
!s/2
E I (l - 2η X a2ι + 3 X X(aiiaji +----+。‘”。川)。’1。八)
i=1
i=1 j=1
Γ / / n b ʌ 2	η2 b b	∖ s/2
E I ((1 — b 工 a2ι J + η2ɪ2 ∑Z(ai2aj2 +-------------+ aidajd)aiiaji J
≥ E 2s/21 η2	b b
b2 Pi=1 P j = 1 (ai2aj2 +	+aidajd)ail aj1≥2
2s/2P
η2 b b
京	^3(ai2aj2 + …+ aidajd)ai1aj1 ≥ 2 I → ∞,
b i=1 j=1
as s → ∞.
□
In the next result, we show that the inverse of M exists with probability 1, and provide an upper
bound result, which will be used to prove Lemma 18.
Lemma 17. M-1 exists with probability 1. Moreover, we have
E [(log+kM-1k)2i ≤ 8.
Proof. Note that M is a continuous random matrix, by the assumption on the distribution of ai .
Therefore,
P(M-1 does not exist) = P(det M = 0) = 0.	(D.12)
Note that the singular values of M-1 are of the form |1 — boh|-1 where oh is a singular value of
H and we have
TCrO	if η H 『2i
(IOg+ kMTk)2 = {(k(I-bH)-ik)2 if 0/H=J 2I.	(D.13)
We consider two cases 0 = b H = I and I = b H = 2I. We compute the conditional expectations
for each case:
E [(log+∣∣M-1∣∣)2 ∣0 =三H = I i = E ](log(I —三H )-1) ∣0 =三H Y I (D.14)
≤ E [(2bkHk)2∣0 = MH = I	(Pg
≤ 4,	(D.16)
where in the first inequality we used the fact that
log(I — X)-1 = 2X	(D.17)
24
Under review as a conference paper at ICLR 2021
for a symmetric positive semi-definite matrix X satisfying 0 W X Y I (the proof of this fact is
analogous to the proof of the scalar inequality log(ι-1χ) ≤ 2x for 0 ≤ x < 1). By a similar
computation,
E (log+kM-1k)2 I I W bH W 2I
≤E
≤E
E
YI ,
2I
W bHY 2I
E
E
where in the last inequality We used the fact that (ηH)-1 W I for I W ηH Y 2I. If we apply the
inequality (D.17) to the last inequality for the choice of X = (bH)-1, we obtain
E k WYH)-T[∣ l2i W(bH)-1γ i
2
≤ E 2 (.H)	∣ 11 W (*H) γ I ≤ 4 .	(D.18)
Combining (D.16) and (D.18), it follows from (D.13) that Elog+ ∣∣MTk ≤ 8.	口
In the next result, we show that a certain expected value that involves the moments and logarithm of
kMk, and logarithm of kM-1 k is finite, which is used in the proof of Theorem 1.
Lemma 18.
E [kMkα (log+ ∣∣M∣∣ + log+ kM-1k)] < ∞ ∙
Proof. Note that M = I 一 bH, where H = Pb a%* in distribution. Therefore for any s > 0,
E[kMks] = E
b
一 b X aiαT
i=1
<∞,
(D.19)
I
since all the moments of ai are finite by the Assumption (A1). This implies that
E[∣∣M∣∣α (log+IlMI1)] < ∞ ∙
By Cauchy-Schwarz inequality,
E[∣M∣α (log+ kM-1k)] ≤(E [∣Mk2α] E [(log+∣M-1k)2i)1/2 < ∞,
where we used Lemma 17.	口
In the next result, we show a convexity result, which is used in the proof of Theorem 2 to show that
the tail-index α is strictly decreasing in stepsize η and variance σ2.
Lemma 19. For any given positive semi-definite symmetric matrix H fixed, the function FH :
[0, ∞) → R defined as
Fh(a) ：= k(I 一 aH) eιks
25
Under review as a conference paper at ICLR 2021
is Convexfor S ≥ 1. Itfollows that for given b and d with H = b Pb=1 agaT, thefunCtion
h(a,s) := E [FH (a)] = EKI - aH) e1∣∣s	(D.20)
is a Convex funCtion ofafor a fixed s ≥ 1.
Proof. We consider the case s ≥ 1 and consider the function
GH(a):=k(I-aH)e1k,
and show that it is convex for H 0 and it is strongly convex for H 0 over the interval [0, ∞). Let
a1 , a2 ∈ [0, ∞) be different points, i.e. a1 6= a2. It follows from the subadditivity of the norm that
GH
ai + a，2
-2-
I - ai+a2H) eι
≤
(I- a 1eι∣∣+∣ι
2GH(aI) + 2GH(a2),
2 - ? H
e1
which implies that GH (a) is a convex function. On the other hand, the function g(x) = xs is convex
for s ≥ 1 on the positive real axis, therefore the composition g(GH (a)) is also convex for any H
fixed. Since the expectation of random convex functions is also convex, we conclude that h(s) is also
convex.	□
The next result is used in the proof of Theorem 4 to bound the moments of the iterates.
Lemma 20. (i) Given 0 < p ≤ 1, for any x, y ≥ 0,
(x + y )p ≤ xp + yp .	(D.21)
(ii) Given p > 1, for any x, y ≥ 0, and any > 0,
p
(1 + e) p-1 — (1+ e)
(X + y)p ≤ (1 + e)xp + i7+-)-I ( + P) yp.	(D.22)
((1 + e)p-1 - 1)
Proof. (i) If y = 0, then (x + y)p ≤ xp + yp trivially holds. If y > 0, it is equivalent to show that
(y+1)p ≤ (力+1,	(D.23)
which is equivalent to show that
(x + 1)p ≤ xp + 1, for any x ≥ 0.	(D.24)
Let F(x) := (x + 1)p - xp - 1 and F(0) = 0 and F0 (x) = p(x + 1)p-1 - pxp-1 ≤ 0 since p ≤ 1,
which shows that F(x) ≤ 0 for every x ≥ 0.
(ii) If y = 0, then the inequality trivially holds. If y > 0, by doing the transform x 7→ x/y and y 7→ 1,
it is equivalent to show that for any x ≥ 0,
p
(1 + e) p-1 — (1 + e)
(1 + x)p ≤ (1 + e)xp + (7+-)-I ( + P).	(D.25)
((1 + e)p-1 - 1)
To show this, we define
F(x) := (1 + x)P - (1 + )xP,	x ≥ 0.	(D.26)
Then F0(x) = p(1 + x)p-1 — p(1 + e)xp-1 so that F0(x) ≥ 0 if X ≤ ((1 + E)p-1 — 1)-1, and
F0(x) ≤ 0 if x ≥ ((1 + E)P-1 - 1)-1. Thus,
max F(X) = F
x≥0
1
(1 + E) P-1 - 1
(1 + E) p-1 - (1 + E)
((1 + e)p-1 -1)P .
The proof is complete.
□
(D.27)
26
Under review as a conference paper at ICLR 2021
E Additional Technical Results
We recall that the iterates are given by xk = Mkxk-1 + qk, where (Mk, qk) are i.i.d. copies of (M, q)
where M = I - bH with H = Pb=1 agaf in distribution and q = η Pb=1 aiyi, where ai and yi
are i.i.d. satisfying the Assumptions (Al)-(A2).
We first obtain more explicit expressions for ρ and h(s) under the Assumption (A1).
Proposition 21. We have
P =2 E log 1 —
2 b	24 b b
2ησ2	2	η2σ4
b	ziι zi1	+	b2~	ʌ,	(z	^(zi1zj1 +	+	ZidZjd)zi1zj1	,
i=1	i=1 j=1
(E.1)
and for any s ≥ 0,
Γ (	2ησ? b	η2σ4 b b	∖ s/2
h(S) = E111 —b- E * + -P-	(Zi1Zj1+ ∙∙∙ + zidzjd) zi1zj1 I I
i=1	i=1 j=1
(E.2)
where Zi := (zii, Zi2,..., Zid)〜N(0, Id), 1 ≤ i ≤ b are i.i.d.
Proof. By the expression ofρ from Lemma 14, we can compute that
P = EIogKI - bH) e1∣∣
=1E log∣∣(I-bH) eι∣∣2
2 E log eT (I -
2 E log 1 —
i=1
2η T T
^b^e1', aiai e1 +
i=1
b
ai aiT	e1
i=1
2b	b
ηT	T	T
b2e1 Z^aiai Z^aiai el
i=1	i=1
b
ηT
b2^aiai
2 E log
2 b	24 b b
2ησ2	2	η2σ 4
1------b~ ʌ,zil +	b2~ 上 / ^(zi1zj1 +	+ zidZjd)Zi1zj1 ,
i=1	i=1 j=1
where Zi = (Zii,Zi2,..., Zid)〜N(0, Id), 1 ≤ i ≤ b are i.i.d. Similarly, by the expression of h(s)
from Lemma 14, we have
h(s)= E∣∣(I- bH)eι∣∣s
Γ (	2	2 b	2 4 b b	∖'s/
E 1(1 -牛 Xz2i + % XX(ZiIZji+ …+ ZidZjd)Zi1Zj1 I I
i=1	i=1 j=1
□
Remark 22. It follows from Proposition 21 that P, h(s) and hence the tail-index α depends on η and
σ2 only via its product ησ2.
We have seen in Theorem 1 that the iterates converge to a heavy-tailed distribution with tail-index
α ∈ (0, ∞) provided that P < 0. When the data ai are i.i.d. in general, it is not easy to check whether
P < 0 holds. For the Gaussian data (Assumption (A1)), it is possible to characterise the region of the
parameters η, b, d, σ2 in which P < 0. We first state the following result, which provides a sufficient
(but not necessary) condition for P < 0.
Proposition 23. P < 0 provided that
ησ2(d + b+ 1) < 2b.
(E.3)
27
Under review as a conference paper at ICLR 2021
Proof. We recall from Proposition 21 that
1	2ησ2 b 2 η2σ4	b b
P =2E log	1----b- zil+ zi1	+-b2~	(ZiIzjI	+ …+ Zidzjd)zi1zj1	,	(E.4)
i=1	i=1 j =1
where Zi = (zii,..., zid)〜N(0, Id), 1 ≤ i ≤ b. Note that the function x → log X is concave, and
by Jensen’s inequality, we have
ρ ≤ 2log E
1-
2ησ2 b 2
—∑z2!
i=1
η2σ4 b b
+--b2~〉,〉J(ZiIzjI + •…+ Zidzjd)zi1zj1
b i=1 j=1
(E.5)
We can compute that
b
E Xzi21	= bE[z121 ] = b,
i=1
(E.6)
and
bb
E ɪ2 y^(zi1zj1 + ,,, + zidzjd)zi1zj1
i=1 j=1
ɪ2 (zi1zj1 + …+ zidzjd)zi1zj1
1≤i6=j≤b
bE [(z2i + …+ zld)zl1] + b(b - I)E [(z11z21 + …+ z1dz2d)z11z21]
bE[z4∕ + b(d -1) (E[z2ι])2 + b(b - i)E[z2ιz2ι]
3b+b(d- 1)+b(b- 1) = b(d+b+ 1),
where we used the property that zi = (zij, 1 ≤ j ≤ d) are i.i.d. and zij are i.i.d. N(0, 1) and
E[z121	] = 1, E[z141 ] = 3.	(E.7)
Hence, we conclude that ρ < 0 provided that
1 — 2ησ2 + ɪɪ—— (d + b + 1) < 1,
b
which is equivalent to
ησ2 (d + b + 1) < 2b.
The proof is complete.
(E.8)
(E.9)
□
Remark 24. It is worth pointing out that ρ < 0 does not hold for arbitrary model parameters. In
particular, we can compute that
ρ=2 E log I(1 -
2 E log I 1-
b2
zi21
i=
b2
zi21
i=
1	η2 σ4 d
≥ 2 E log I % X
k=2
izik
24 b b	d
+	£ £ zi1zj1 £ zik zjk
i=1 j=1	k=2
+ 嗒 XX (XX Qi)
k=2 i=1
2
log阡
2
1d
+ 2 E log I∑
k=2
izik
28
Under review as a conference paper at ICLR 2021
Note that conditional on zi1, 1 ≤ i ≤ b,
Xb
ZiiZik 〜N (θ, Xb zi21 ,	(E.10)
i=1	i=1
are i.i.d. for k = 2, . . . , d. Therefore,
1E log [XY] = 2 E log X + 2 log E log Y,
(E.11)
where X is a chi-square random variable with degree of freedom b and Y is a chi-square random
variable with degree of freedom (d - 1). Therefore, we can compute that
1	1 ∞	X 2 Te-2
2ElogX = 2 / Iog(X)^Γ2Tdx
、	1	/*1	b-1 —x T
≥ —7----	Iog(X)X2 1e 2 dx
≥ 2b+1Γ(b) J0	g( )
11
≥ 2i+Γ(2) Lbg(X)X2-1dx = 2
Similarly, we can
provided that
show that 2 E log Y ≥ -^-ι----1--------. Hence, we conclude that P ≥ 0
2 "ɪ-1(d-1)2Γ( d21)
≥ bexp { 2b-1b2Γ(b) + 2d-1 -1(d - 1)2Γ(d-1) }.
(E.12)
Next, we provide alternative formulas for h(s) and ρ for the Gaussian data (Assumption (A1)) which
is used for some technical proofs.
Lemma 25. For any s > 0,
h(s)=E ((ι- ησ2X)2+⅞4XY! /,
and
P = 2E log ((1- ητX) + ⅞4xy!#,
where X, Y are independent and X is chi-square random variable with degree of freedom b and Y is
a chi-square random variable with degree of freedom (d - 1).
Proof. We can compute that
Γ /	2	2 b	2 4 b b	ʌ s/2
h(s) = E 1(1 - VrfziI + ηbσ-∑ E(ZiIZjI+ •…+ ZidZjd)Zi1zj1 ) I
i=1	i=1 j=1
2b	24b b	d
E I ( 1 - 丁 X Z21 + 方 XX (Z21Z21 + ZiIzjI X
i=1	i=1 j=1	k=2
"
ZikZjk
e|/1-2ησ2 X z2i+n2σ4 (X 2力2+% X
EK(I-胃 X Z21!+ T X (X ZiiZik!)
Xi=b1
s/2
!『
Zi1 Zik
29
Under review as a conference paper at ICLR 2021
Note that conditional on zi1, 1 ≤ i ≤ b,
bb
X ZiIZik 〜N 0, X Z21
i=1	i=1
are i.i.d. for k = 2, . . . , d. Therefore, we have
(E.13)
h(s) = E
(1- P X Z21! + * X (X Qik)
2 s/2
2 b	2	24b	d
1 - ησ- X Z2ι	+ % X Z2ι X Xk
i=1	i=1 k=2
s/2
where xk are i.i.d. N(0, 1) independent of zi1, i = 1, . . . , b. Hence, we have
E
h(s)
s/2
b d	\s/2l
X Z21X Xk)
i=1	k=2
where X, Y are independent and X is chi-square random variable with degree of freedom b and Y is
a chi-square random variable with degree of freedom (d - 1).
Similarly, we can compute that
P=2 E
24b b	d
+ η~2Γ £ £ ZiIZjI £ ZikZjk
i=1j =1	k=2
24d
+修X
Xb Z Z !
Zi1 Zik
2 E
2 E
log h T X R
Z21 )2
k2
2+小)#,
where X, Y are independent and X is chi-square random variable with degree of freedom b and Y is
a chi-square random variable with degree of freedom (d - 1). The proof is complete.
□
In Theorem 1, we showed the existence of the tail-index α. For the Gaussian data (Assumption (A1)),
we can provide some explicit bound on the tail-index α provided some explicit technical conditions
hold. Next, we provide a technical condition under which the tail-index α ∈ (0, 4]. (See also
Proposition 3 for a technical condition under which the tail-index α ∈ (0, 2].)
Proposition 26. There exists some 0 < α ≤ 4 such that h(α) = 1 provided that
2b > ησ2 (d + b + 1)
2η2 σ4
≥ 2b - 2ησ2(b + 2) + -ɪ-(b + 2)(b + d +3)
1 η3 σ6	1 η3 σ6	η3 σ 6
-2~lρ~(b + 2)(b + 4)(b + 6) - 2-b2-(b + 2)(d -1) —b2~(b + 2)(b + 4)(d - 1).
Proof. It follows from Lemma 25 that
h(4) = E
2 + '* XY !2
30
Under review as a conference paper at ICLR 2021
where X, Y are independent and X is chi-square random variable with degree of freedom b and Y is
a chi-square random variable with degree of freedom (d - 1). We can further compute that
+2E K- ησ2 x )2 ηbσ4 XY-
(E.14)
First, we can compute that
ι - 4ησ2 EX ]+6η22σ4 e1x，- 4η3σ6 e[x 3]+* e[x ” (e」5)
We recall the formula for the m-th moment of a chi-square distribution with degree of freedom k
given by 2mΓ(m + 2)∕Γ(2), which is 2m2 (2 + 1)…(2 + (m - 1)) when m isapositive integer.
Since X is chi-square distributed with degree of freedom b, we have
E[X ] =2 ∙ 2 = b,
E[X2] = 22 ∙ b (b + 1)= b(b + 2),
E[X3] = 23 ∙ b (b + 1 +2)= b(b + 2)(b + 4),
E[X4] = 24 ∙ b (b + 1	+2	+3‰ b(b + 2)(b + 4)(b + 6),
which implies that
E [(1 -呼 X Y]=-"? + 6η2σ4 (b+2) - T (b+2)(b+4) + ⅛8 (b+2)(b+4)(b+6).
b	b	b2	b3
(E.16)
Second, we can compute that
E [ ηbσ8 χ2γ2 = ηbσ8 E [χ2] e[y 2]=ηbσ8 帅+2)(d -1*,+1)=ηbσ8 伯+2)(解一»
(E.17)
where we used the fact that Y is independent of X and Y is chi-square distributed with degree of
freedom d - 1 so that E[Y2] = (d - 1)(d + 1).
Third, we can compute that
2E ∣(1 - T X 了 T XY
=2E [η2σ4XY] + 2E [η4σ8X3Y] - 4E [η3σ6X2Y
b2	b4	b3
=2η2σ4(d - 1)+ 2η4σ8(b + 2)(b + 4)(d - 1) - 4η3σ6(b + 2)(d - 1).
b	b3	b2
Putting everything together, we have
h(4) = 1 - 4ησ2 + 6η2σ4(b + 2) - 4η32σ6(b + 2)(b + 4) + η4f8(b + 2)(b + 4)(b + 6)
b	b2	b3
+ηbσ8 (b+2)(d2 -1)
+ 2^——(d — 1) + 2" 3 (b + 2)(b + 4)(d — 1) — 44^	(b + 2)(d — 1),
b	b3	b2
31
Under review as a conference paper at ICLR 2021
and h(4) ≥ 1 if and only if
1 - 4ησ2 + 6η2σ4(b + 2) - 4η3σ6(b + 2)(b + 4) + ⅛8(b + 2)(b + 4)(b + 6)
b	b2	b3
+η4σ8 (b+2)(d2-1)
+ 2η2σ4(d — 1)+ 2η4σ8(b + 2)(b + 4)(d - 1) - 4η3σ6(b + 2)(d - 1) ≥ 1,
b	b3	b2
which is equivalent to
- 2b + ησ2 (3b + 6) + ησ2(d - 1)
-2ηbσ4(b + 2)(b + 4) + 1 η3σ6(b + 2)(b + 4)(b + 6) + 2η3σ6(b + 2)(d2 - 1)
b	2b	2b
+ η3σ6(b + 2)(b + 4)(d - 1) - 2η2σ4(b + 2)(d - 1) ≥ 0,
b2	b
which is equivalent to
- 2b + ησ2(d + b + 1) ≥ -2ησ2 (b + 2)
+ 2ηbσ4(b + 2)(b + 4) - 1 η3σ6(b + 2)(b + 4)(b + 6) - 2η3σ6(b + 2)(d2 - 1)
b	2b	2b
-η3σ6(b + 2)(b + 4)(d - 1)+ 2η2σ4(b + 2)(d - 1).
b2	b
Finally, recall that ρ < 0 if 2b > ησ2(d + b + 1) and h(4) ≥ 1 implies there exists some 0 < α ≤ 4
such that h(α) = 1. The proof is complete.	口
Let us define Ds,b as the set consisting of (η, σ) such that
Ds,b := {(η, σ) : ησ2(d + b + 1) < 2b and h(s) ≥ 1}.
We have shown in Proposition 23 that ρ < 0 provided that ησ2(d + b + 1) < 2b. Therefore, if
(η, σ) ∈ Ds,b, then the tail-index α ∈ (0, s]. In Proposition 26, we characterised the set D4,b. In the
next proposition, we show that D4,b is non-trivial, i.e., D4,b is not an empty set.
Proposition 27. D4,b is not an empty set. In particular, it includes the pairs (η, σ) such that
a。	≤ ησ2	2
d + b + 1 - b d + b + 1
(E.18)
for some ac ∈ (0, 2) such that F(ac) = 0 and F(a) ≤ 0 for any ac ≤ a ≤ 2, where
F(a)：= 2 - a - ,	,	(b + 2)+ /7,7, n2 (b + 2)(b + d + 3)
d+b+ 1	(d+b+ 1)2
1 a3	1 a3
-2(d + b +1)3 (b + 2)(b + 4)(b + 6)- 2(d + b +1)3 (b + 2)(d - 1)
—
a3
(d + b +1)3
(b+2)(b+4)(d-1).
Proof. We aim to show that there exist some η, σ such that
2
2 >ησ- (d + b +1)
≥ 2 - 2ησ2(b + 2) +2⅞4(b + 2)(b + d +3)
b	b2
1 η3σ6	1 η3σ6	η3σ6
-2~b3~(b + 2)(b + 4)(b + 6) - 2~b3~(b + 2)(d - 1)-b3~(b + 2)(b + 4)(d - 1).
32
Under review as a conference paper at ICLR 2021
Let ησ~ (d + b +1) = a. Then, it suffices to show that there exists some a < 2 such that
≥ 2 - i . i , 1 (b + 2)+ /1 , a I n2(b + 2)(b + d + 3)
d + b + 1	(d + b + 1)2
1	α3	1	a3	C
-2(d + b +1)3 (b + 2)(b + 4)(b + 6) - 2(d + b +1)3 (b + 2)(d - 1
—
a3
(d + b +1)3
(b + 2)(b + 4)(d - 1).
Let us define
F(°):=2 - a -在*i(b + 2) + "W(b + 2)(b + d +3)
1 a3	1 a3
-2(d + b +1)3 (b + 2)(b + 4)(b + 6) - 2(d + b +1)3 (b + 2)(d - 1)
a3
-EE(b + 2)(b + 4)(d-1).
Then, we can check that F(0) = 2 > 0 and
一、	4	8	,
F ⑵=-El(b + 2) + FW(b + 2)(b + d + 3)
-(d+b4+1)3(b+2)(b+4)(b+6) - (d+b4+1)3(b+2)(d2 -1)
8
-(d+τ+>(b+2)(b+4)(d-1),
so that
(4^b u^2J F(2) = -(d + b + 1)2 + 2(d + b + 1)(b + d + 3)
4(b + 2)
-(b + 4)(b + 6) - (d2 - 1) - 2(b + 4)(d - 1)
= d2 + b2 + 1 + 2d + 2b + 2bd + 4d + 4b + 4
-b2 - 10b - 24 - d2 + 1 - 2bd - 8d +2b + 8
=-2d - 2b - 10 < 0.
Thus, F(2) < 0. Hence, we conclude that there exists some 0 < ac < 2 such that F(aj = 0 and
F (a) ≤ 0 for any ac ≤ a ≤ 2. Then, for any
ac ≤ n (d + b + 1) < 2,	(E.19)
b
we have (η, σ) ∈ D4,b. The proof is complete.	□
Recall that D2m,b consists of (η, σ) such that
D2m,b = {(η, σ) : ησ2(d + b + 1) < 2b and h(2m) ≥ 1}.
Since D4,b = 0 and D4,b ⊆ D2m,b for any m ≥ 2. Indeed, we can characterises the set D2m,b in the
following proposition.
Proposition 28. GiVen any m ∈ N, there exists some 0 < α ≤ 2m such that h(α) = 1 provided that
ησ2(d + b + 1) < 2b and
X X (m Y)
k=0 j=0、 J 'J)
rj2(m-k)+j σ4(m-k)+2j
b2(m-k)+j
(-1)j 2j+2(m-k)
Γ(j + m - k + b)Γ(m - k + 与1)
γ( b)
Γ(专1)
≥ 1.
33
Under review as a conference paper at ICLR 2021
Proof. By applying Lemma 25, we can compute that
h(2m) = E
m
X
k=0
m
X
k=0
m
X
k=0
b2(m-k)
2(m-k)σ4(m-k)
b2(m-k)
2(m-k)σ4(m-k)
b2(m-k)
X )2+⅞4 XY !m
2(m-k)σ4(m-k)
E ](1 - ησ2X) Xm-kYm-k
X2k	2jk)
j=0
X2k	2jk)
j=0
ηjσ2j
(-1)j ηj E[Xj+m-k Ym-k ]
(-1)j ησ j 2j+m-k
b b	bj
Xm X2k	mk)2jk)
k=0 j=0
r(j + m - k + b ) 2m-k「(m - k + ⅛1)
Γ( b )	Γ( d-1 )
η2(m-k)+jσ4(m-k)+2j
b2(m-k)+j
∙ (-1)j 2j + 2(m-k)
Γ(j + m - k + b)Γ(m - k + d-1)
r（ b）
Γ(d-1)
where we used the formula for the moments of chi-square distribution, that is, the m-th moment of a
chi-square distribution with degree of freedom k is given by 2mΓ(m + 2 )∕Γ( k).
Previously, we have provided some upper bounds on the tail-index α under some technical conditions
on the model parameters. Next, let us provide an upper bound for the tail-index α without relying on
any additional technical conditions.
Proposition 29. The tail-index α is upper bounded by:
I P
α ≤ max 2,
II	E
2ησ2X + ⅛4X2 + ⅛4XY ≤ 0
-2ησ2 X + ηbσ4 X2 + ηbσ4 XY)十
(E.20)
where X, Y are independent and X is a chi-square random variable with degree of freedom b and Y
is a chi-square random variable with degree of freedom (d - 1).
Proof. We recall that
1 = h(α) = E [fl - 2ησ2X + η2σ4X2 + η2σ4XY『
b	b2	b2
(E.21)
where X, Y are independent and X is a chi-square random variable with degree of freedom b and Y
is a chi-square random variable with degree of freedom (d - 1). Note that for any x ≥ 0 and α ≥ 2,
(1 + x)2 ≥ 1 + α2x. Therefore,
1 ≥ E(1-午X + η⅛4 X2 + η⅛4XY
1-2ηbσ2 X+ η2σ4 X2 + η2σσ4 XY ≥0
≥ E M + 2 f-平 X + η⅛4 X2 + ⅞4 XY
铲 x+η22σ4 x2+η22σ4 χγ ≥o
pf-午 X+η2σ4 X 2+⅞4 XY ≥ 0
+ α E Jf-午 X + ⅞4 X2 + ⅞4 XY)+
2	b	b2	b2
which yields the desired result. The proof is complete.
□
α
2
□
34
Under review as a conference paper at ICLR 2021
Remark 30. (i) Note that it follows from Lemma 25 that we have
P = 2 E log
2 + ηb∏
where X, Y are independent and X is chi-square random variable with degree of freedom b and Y is
a chi-square random variable with degree of freedom (d - 1). Therefore, we have
ρ
2
+看Xy
b _ 1	_ X d_ 1 _ 1	_ y
x2-1e-2 yF 1e-2
——d ;-----Mn------dxdy.
2bΓ(b) 2d-1Γ(d-1)
(E.22)
In particular, when d = 1, we have Y ≡ 0 and
ρ
∞ log
0
1-
2
ησ2
~x
x 2 Te-2
22 Γ( b)
dx.
(E.23)
(ii) Note that it follows from Lemma 25 that we have
h(s) =E
where X, Y are independent and X is chi-square random variable with degree of freedom b and Y is
a chi-square random variable with degree of freedom (d - 1). Therefore, we have
h(s)
∞∞
00
b _ ι _ x d_1 _ ι _ y
x2 1e 2 y 2	1e 2
——d---；----dx-------dxdy.
22Γ(b) 2⅛1 Γ(d-1)	y
In particular, when d = 1, we have Y ≡ 0 and
h(s)
2
1 - ησ- X
b
S x2-1e-2
22Γ(b)
dx.
(E.24)
∞
0
So far, we have studied various properties of the tail-index α, including the monotonicity on stepsize,
noise variance, batch size and the dimension, as well as some quantitative bounds. In general, there is
no simple closed-form formula for the tail-index α. Next, we will obtain some approximations for
the tail-index α in various asymptotic regimes. First, we provide a rigorous first-order approximation
for the tail-index α when it is less than and close to 2.
Proposition 31. Let a := ησ2 and ac := d+b+i. Then the tail-index satisfies:
ɑ〜
4
2 - 丁(a - ac),
Fc
(E.25)
for any a J ac, where
Fc= E [(1- 2acX + alX2 + aXY) log (1- 2acX + *X2 + α2XY[] > 0, (E.26)
b	b2	b2	b	b2	b2
where X, Y are independent and X is a chi-square random variable with degree of freedom b and Y
is a chi-square random variable with degree of freedom (d - 1).
Proof of Proposition 31. Let us define a = ησ2. In Proposition 3, we showed that there exists some
δ > 0 such that for any 2b ≤ a(d +b + 1) < 2b + δ, ρ < 0 and there exists some 0 < α ≤ 2, such
that h(α) = 1. In particular, when a = ac := d+b+1, the tail-index α = 2. Consider the tail-index
α = α(a) as a function of a. Then, we have
1 = h(α) = E (1 - 2aX + alX2 + alXY
b b2	b2
(E.27)
35
Under review as a conference paper at ICLR 2021
where X, Y are independent and X is a chi-square random variable with degree of freedom b and Y
is a chi-square random variable with degree of freedom (d - 1). By differentiating (E.27) w.r.t. a, we
get
0 = E 1 ∂α log (l - 2aX + a2X2 + a2XY) e2 log(1-2aX+ a2X2 + a2XY)
2 ∂a	b	b2	b2
+ α -bX + ⅜aX2 + 瑞XY	e2iog(ι-2baX+aχ2+a!XY)#
2 1 -竿X + a2X2 + a2XY	J,
which implies that
∂ɑ
∂a
=______________-2E [-bX + ⅜2cX2 + 替XH_____________ (E 28)
a=ac	E [(1 -普X + ⅛X2 + *XY) log (1 -华X + ⅛X2 + 霄XY)i,	.
where we used the fact that α = 2 when a = ac . Note that the function x 7→ x log x is convex, and
22
by Jensen's inequality and the fact that 1 - 2bc X + bcX2 + bc XY is not constant，We have
E ](ι - 2αc X+a2 X2+a2XY W (1 - 2ac X+a2 X2+a2XY)
> e [(1 - 2ac X+a2 X2+a2 XY Ulog E ](1-2ac X+a2 X2+a2 XY)]=°∙
Moreover, We can compute that
-2E [-2∙X + 2acX2 + 2acXY] = -2 [-2+2ac (b + 2) + 2ac (d- 1)] = -4.
Hence, We conclude that
for any a J。心 where
FC ：=e	[(1 -	2ac X+a2 X2+a2 XY)	l°g (1 - 2ac X+a2 X2+a2 XY)]	> 0.(e.30)
b b2	b2	b	b2 b2
□
4
α 〜2 - ʒ=Na - ac),
Fc
(E.29)
Next, we derive an approximation for the tail-index α when it is close to zero.
Proposition 32. Let a := ησ2 and P = ρ(a) emphasizing the dependence on a. Define a* :
inf {a > 0 : ρ(a) = 0}. Then, we have
α 〜c*(a* — a),
(E.31)
as a ↑ a* , where
c* := 4E
-bX + 答X2 + 皆XY ] L
∙ E
1 -智 X + 耨 X2 + a XY J V
where X, Y are defined in Proposition 31.
2	-1
(log (1 -与X+a*X 2+a* xy ))])
(E.32)
Proof of Proposition 32. The tail-index α is uniquely determined by
1 = h(α) = E ](1 - 2aX + a2X2 + a2XY) /	,	(E.33)
where a = ησ2 and X, Y are independent and X is chi-square random variable with degree of
freedom b and Y is a chi-square random variable with degree of freedom (d - 1). It is clear that α
depends on η and σ only via a := ησ2. In Proposition 3, we showed that there exists some δ > 0
36
Under review as a conference paper at ICLR 2021
such that for any 2b ≤ a(d +b + 1) < 2b + δ, ρ < 0 and there exists some 0 < α ≤ 2, such that
h(α) = 1. Let ρ = ρ(a) with emphasis on the dependence of ρ on a = ησ2. In Proposition 23, we
showed that ρ < 0 provided that a(d +b + 1) < 2b. On the other hand, we showed in Remark 24
that ρ ≥ 0 for any a ≥ b exp	+
d — 1	1	,	1
2 -ɪ-1(d-1)2Γ( T)
. Therefore, there exists some
critical value a* > 0 such that ρ(a) < 0 for every a < a* and ρ(a*) = 0. It is clear that as a → a*,
α → 0. We are interested in studying the tail-index α when α is close to zero. By differentiating
(E.33) w.r.t. a, we get
1 ∂α	2a	a2 2 a2
0 = E 2 而 log(1 - Tx + 庐X + 庐xy
+ α -bX + 2aX2 + IaXY	Jeαlog(ι-带x+aX2+
21 - 2a x + a2 x2 + a2 XY)
and by differentiating w.r.t. a again, we get
1 ∂α	2a	a2 2	a2
0 = E 2 而 log(1 - TX + 庐X + 庐XY
+E
α -bX + 瑞X2 + 得XY !2
+ 2 1 - 2a X + a2X2 + a2XY J
[1 ∂⅛ log (1- 2aX + aX2 + aXY) e2
2 ∂a2	b b2	b2
e
+E
∂α - b X + 瑞 X2 + 瑞 XY
∂a 1 -华 X + 惊X2 + a2XY
+E
At a = a* , α
• e 2 log
ɑɪ - -bX + 患X2 + 患XY ʌ e
2 拓 U - 2aX + %X2 + 患XY J e
0 and P = 2E ^og(1 - 2bLX + 耨 X2 + 耨XY)] = 0, which implies that
0 = 4(α0(a*))2E
X + α∣ X2 + o∣ xy ))
b2 b2
+ α0(a*)E
-b X + 普 X2 + 普 XY
1 -等X + ⅛X2 + ⅛XY
1
which implies that
α0(a*)
-4E
—2 X+ 筌 X2 + 筌 XY
72	∑2
1-皆 X + 金 X2 + aɪ XY
(log (1 -等X + 居X2 + ⅛XY))2
(E.34)
E
and therefore
α〜一
E
4E
—b X + 含 X2 + 筌 XY
Z	22	22
1-弩 X + af X2 + af XY
(log (1 -等X + ⅛X2 + 除XY))2
(a(a* - a)
(E.35)
as a ↑ a*.
□
When the dimension d is large, we can use Proposition 31 and Proposition 32 to obtain a more explicit
approximation for the tail-index α when it is between 0 and 2.
37
Under review as a conference paper at ICLR 2021
Theorem 33. When the dimension d is large, the tail-index satisfies:
d3	2	2b
α 〜2 - 4b(b + 2) Vσ - d + b +1) ,
(E.36)
GyzWw 2b V 八"2	2b , 8b(b+2)
for any d+b+1 ≤ ησ < d+b+1 + d3-
Note that in Theorem 33 the approximation 2 -4位；2)(ησ2 一 μ+^) decreases from 2 to 0
as ησ2 increases from d+2⅛1 to d+b+1 + 吗+2), which is an approximation of a*. Moreover,
the approximation 2 一4^?；?)(ησ2 — d+b+ι) is strictly decreasing in d, η, and σ2 and strictly
increasing in b. This is consistent with the monotonicity results we have shown before.
ProofofTheorem 33. When ησ2 increases from a，c = d+b+ι to a*, where a* = inf{a > 0 : ρ(a)=
0}, the tail-index decreases from 2 to 0. When d ↑ ∞, a* → 0 and ac → 0, and hence it suffices to
show that
d3	2	2b
α 〜2 - 4b(b + 2) “ - d+b+1
(E.37)
as d ↑ ∞ and ησ2 J d+2+ι, and a* 〜d+2b+ι + 鲂,，+", and when d ↑ ∞ and ησ2 ↑ d+2+ι + 8&(d+2)
d3	2	2b
α 〜2 - 4b(b + 2) Vσ - d+b+1
(E.38)
We will prove (E.37) in Corollary 34 which is a corollary of Proposition 31 when d ↑ ∞ and we will
prove (E.38) in Corollary 35 which is a corollary of Proposition 32 when d ↑ ∞.
When the dimension d is large, we have the following result as a corollary of Proposition 31.
Corollary 34. The tail-index satisfies:
d3
α 〜2------------
4b(b + 2)
(E.39)
as d ↑ ∞ and ησ2 J d+b+ι.
22
ProofofCoroUary 34. As d ↑ ∞, a© J 0, We have 2acX + bcX2 + bcXY → 0 in probability, and
using log(1 + x)〜X - x2 so that (1 + x)log(1 + x)〜(1 + x)x - x2, we have
Fc 〜E [(1- 2acx + aχ2 + aχγ) (-华χ + aχ2 + aχγ)]
b b2	b2	b	b2	b2
- - E
2
X+a2 X 2+a2 χY )2
W- d+M，
□
2E 卜干X+a2 X 2+a2 XY 7
38
Under review as a conference paper at ICLR 2021
Next, we can compute that
E ](-2ac X+a2 X2+a2 XY)2
b	b2	b2
4a2	a4	a4	4a3	2a4	4a3
=若E[X2] + bcE[X4] + b4E[X2Y2]-请E[X3] + 24cE[X3Y]-请E[X2Y]
4a2	a4	a4
=~2rb(b + 2) + b4b(b + 2)(b + 4)(b + 6) + b4b(b + 2)(d - I)
-433b(b + 2)(b + 4) + 2a4b(b + 2)(b + 4)(d - 1)-号b(b + 2)(d - 1)
_ 16b(b + 2)	16b(b + 2)(b + 4)(b + 6)	16b(b + 2)(d2 - 1)
=(d + b + 1)2 +	(d + b + 1)4	+ ―(d + b +1)4—
32b(b + 2)(b + 4)	32b(b + 2)(b + 4)(d - 1)	32b(b + 2)(d - 1)
--+	--
(d + b + 1)3	+	(d + b + 1)4	(d + b + 1)3
16b(b + 2)
(d+b+1)4
(d + b + 1)2 + (b + 4)(b + 6) + d2 - 1
-2(b+4)(d+b+1)+2(b+4)(d- 1) -2(d+b+1)(d- 1)
32b(b + 2)
〜 ---------
d3
as d ↑ ∞, where We used the formulas for the moments of chi-square random variables, and a 〜 *
for d ↑ ∞. Therefore, it follows from Proposition 31 that we have
d3	2b
α 〜2 - 4bW2) W- El )，	(E.40)
as d ↑ ∞ and ησ2 J d+2+. The proof is complete.	□
When the dimension d is large, we have the following result as a corollary of Proposition 32.
Corollary 35. When d ↑ ∞ and ησ2 ↑ a* 〜 ^2+ + 8b(d+2) ,the tail-index satisfies
d3	2	2b
α 〜2 - 4b(b + 2) " - d + b +1
Proof of Corollary 35. Note that by the definition of a* ,
0 = ρ(a*) = 2E log (1 —b*X + b*X2 + b*XY)].
(E.41)
(E.42)
When the dimension d is large, i.e. d ↑ ∞, we have Y ↑ ∞ in probability, and thus a* → 0. This
22
implies that -午X + / X2 → 0 in probability, and hence we must have 甫XY → 0 as well. It
follows that
1	2a*	a2 a2
0 〜2E --b*X + b*X2 + b*XY ,	(E.43)
which implies that as d ↑ ∞,
2b
b* 〜bc := , . , . 1 ,	(E.44)
d+b+1
39
Under review as a conference paper at ICLR 2021
where We used E [-2ac-X + 患X2 + 耨Xy] = 0. Note that when a = ac, α =
close to zero, and to get a finer approximation, using log(1 + x)〜X - x2, we get
2, which is not
-2a2 X+a2 X2+
a2
尊XY
a2
法XY
4E
4E
X + aX 2 +
2	22
X + b2X 2 + b2 XY)
22
bc xY )
2a* V , a2- v2 I
-^Tx + 尊 X +
2
a2
而XY
where we used from the proof of Corollary 34 that
8b(b + 2)
-d3-
E ](-牛 X+a2 X2+a2 XY Y
b	b2	b2
32b(b + 2)
〜 -----------
d3
as d ↑ ∞. Let us write a2 = a + , then as → 0, we have
0〜-E
2
-牛 X + a X2 + aXY
b x + b2 X + b2 XY
+ 1E - bX +
8b(b + 2)
-d3-
, (E.45)
0〜
2E
—
〜
〜
2E
2E
-? X+a2 X2+
—
—
1
2
鲁X2 +鲁XY卜
—
and we can compute that
E [-IX+眷 X2 + 得 XY
-2	2ac	2a
b+贴+2)+
2,
(E.46)
which implies that
8b(b + 2)
F〜
d3
(E.47)
Hence, we have
4E [-bX + 卷X2 + 咨XY]
X + 除 X2 + ⅛ XY )2
4E[-b X + 窄 X2 + 窄 XY]
E
E
X+a∣ X2+等
We recall that
- ησ2
ac + - ησ2
4e]-bX +篙 X2 + 篙 XY^
8,
(E.48)
α〜
〜
2
and from the proof of Corollary 34, we have
2ac	a2
E	- -aX+铲2+
22
bc XY )
32b(b + 2)
〜 -----------
d3
as d ↑ ∞, where we used the formulas for the moments of chi-square random variables, and 期 〜2b
for d ↑ ∞. Hence, we conclude that
8d3
2b
α 〜-----；------------------+
32b(b + 2) Id + b + 1 +
8b¾P - ησ2
(E.49)
when d ↑ ∞ is large and ησ2 ↑ d+2⅛Γ + 8”+2). The proof is complete by noticing that
8d3
2b
32b(b + 2) Id + b + 1 +
8¾P - ησ2
d3
2------：------
4b(b + 2)
ησ2-	.	(E.50)
□
40
Under review as a conference paper at ICLR 2021
Remark 36. We have already obtained an approximation of α when α lies between 0 and 2 and the
dimension d is large (see Theorem 33). Fix the dimension d and batch size b, when a = ησ2 → 0,
the tail-index α → ∞. Let us derive an approximation for the tail-index α in this asymptotic regime.
We recall that the tail-index α is uniquely determined by
1 = h(α) = E ∖(1 - 2O-X + aX2 + aXYU
b	b2	b2
(E.51)
where a = ησ2 and X, Y are independent and X is chi-square random variable with degree of
freedom b and Y is a chi-square random variable with degree of freedom (d - 1). We apply the
■	, ■ α α ,	∖rv∕9 α . a . α (α-1) 9 ,	,
approximation (1 + x)α/2 〜1 + 2X + 2-^-2--x2 to get:
午 X + T X2 + ⅞4 XY
+」E K-午 X + ⅞4 X 2 + η⅛4 XYYl
2	b	b2	b2
Assume that ησ2 is small and ignore the higher-order terms, we get
α	2E
2 〜1 +--
=1 + 4ησb-2⅜4(b2 +2b)- 2⅜4b(d- 1)
一	辛(b2 +2b)
Hence, we conclude that as ησ2 → 0, the tail-index satisfies
1 d-1
ησ2(b + 2) + 2 - 2(b + 2).
2b
d-1
α 〜....-------+ 1 -------.
ησ2(b + 2)	b + 2
(E.52)
1 〜1 +—E
2
E
2
b
Note that the approximation “a22b+2)+1 一 d-1 is StrictIy increasing in b, and strictly decreasing in
η, σ2 and d, which is consistent with what we have shown before. If ησ2 = 壮+^, we know from
Proposition 3 that the tail-index α = 2. Indeed, by plugging ησ1 = d+bpɪ into the right hand side of
(E.52), we get
2b	d _ 1 _ 2b(d + b + 1) d 一 1
ησ2(b + 2)+ b + 2	2b(b + 2) + b + 2	，
(E.53)
which is consistent with Proposition 3.
Remark 37. The approximation in (E.52) is good if ησ2 is small, and every other model parameter
is fixed. When ησ2 is small, and dimension d is large, a finer approximation is given by
α 2E 号 X 一 2E / X2 + / XY
2 〜1 + -4-——j----L--------ɪ,	(E.54)
2	E (-⅞σ2 X + ⅞4 X2 + 啥 XY)
and we can compute that
e"( T X+η2σ4 X2+T XY 厂
4-2	-4	-4
=^b2-b(b + 2) + b4 b(b + 2)(b + 4)(b + 6) + b4 b(b + 2)(d - 1)
--b3-b(b + 2)(b	+ 4)	+—b4-b(b + 2)(b + 4)(d 一	1)-b3~b(b + 2)(d 一	1)
〜-22~b(b	+ 2) + b4b(b +	2)d2-菸b(b + 2)d,	(E.55)
41
Under review as a conference paper at ICLR 2021
where a = ησ2. Hence, we obtain the approximation:
α 1 l	4ησb - 2ηbσ~(b2 + 2b) - 2ηbσ~b(d - I)
〜1 +	,,
2	4⅞σ4b(b + 2) + 窄8b(b + 2)d2 - 4η3σ6b(b + 2)d,
which yields that the tail-index α can be approximated as:
2b	4(d + b + 1)
α 〜2 +--------------------o  -------o-  ---------------o~~i------:—o—
ησ2(b + 2)(1 + ησd2 -喑d)	(b + 2)(4 + 窄d2 - 唁d
(E.56)
(E.57)
42