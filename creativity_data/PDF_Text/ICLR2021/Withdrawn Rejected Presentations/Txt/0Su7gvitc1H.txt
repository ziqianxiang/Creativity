Under review as a conference paper at ICLR 2021
ARMCMC: Online Model Parameters full
probability Estimation in Bayesian Paradigm
Anonymous authors
Paper under double-blind review
Ab stract
Although the Bayesian paradigm provides a rigorous framework to estimate the
full probability distribution over unknown parameters, its online implementation
can be challenging due to heavy computational costs. This paper proposes Adap-
tive Recursive Markov Chain Monte Carlo (ARMCMC) which estimates full
probability density of model parameters while alleviating shortcomings of con-
ventional online approaches. These shortcomings include: being solely able to
account for Gaussian noise, being applicable to systems with linear in the param-
eters (LIP) constraint, or having requirements on persistence excitation (PE). In
ARMCMC, we propose a variable jump distribution, which depends on a tempo-
ral forgetting factor. This allows one to adjust the trade-off between exploitation
and exploration, depending on whether there is an abrupt change to the parame-
ter being estimated. We prove that ARMCMC requires fewer samples to achieve
the same precision and reliability compared to conventional MCMC approaches.
We demonstrate our approach on two challenging benchmark: the estimation of
parameters in a soft bending actuator and the Hunt-Crossley dynamic model. Our
method shows at-least 70% improvement in parameter point estimation accuracy
and approximately 55% reduction in tracking error of the value of interest com-
pared to recursive least squares and conventional MCMC.
1	Introduction
Bayesian methods are powerful tools to not only obtain a numerical estimate of a parameter but
also to give a measure of confidence (KU´mierCzyk et al., 2019; Bishop, 2006; Joho et al., 2013). In
particular, Bayesian inferences calculate the probability distribution of parameters rather than a point
estimate, which is prevalent in frequentist paradigms (Tobar, 2018). One of the main advantages of
probabilistic frameworks is that they enable decision making under uncertainty (Noormohammadi-
Asl & Taghirad, 2019). In addition, knowledge fusion is significantly facilitated in probabilistic
frameworks; different sources of data or observations can be combined according to their level of
certainty in a principled manner (Agand & Shoorehdeli, 2019). Nonetheless, Bayesian inferences
require high computational effort for obtaining the whole probability distribution and prior general
knowledge on noise distribution before estimation.
One of the most effective methods for Bayesian inferences is the Markov Chain Monte Carlo
(MCMC) methods. In the field of system identification, MCMC variants such as the one recently
proposed by Green (2015) are mostly focused on offline system identification. This is partly due
to computational challenges which prevent real-time use (Kuindersma et al., 2012). The standard
MCMC algorithm is not suitable for model variation since different candidates do not share the same
parameter set. Green (1995) first introduced reversible jump Markov chain Monte Carlo (RJMCMC)
as a method to address the model selection problem. In this method, an extra pseudo random variable
is defined to handle dimension mismatch. There are further extensions of MCMC in the literature,
however, an online implication of it has yet to be reported.
Motion filtering and force prediction of robotic manipulators are important fields of study with inter-
esting challenges suitable for Bayesian inferences to address (Saar et al., 2018). Here, measurements
are inherently noisy, which is not desirable for control purposes. Likewise, inaccuracy, inaccessibil-
ity, and costs are typical challenges that make force measurement not ideal for practical use (Agand
et al., 2016). Different environmental identification methods have been proposed in the literature
1
Under review as a conference paper at ICLR 2021
for linear and Gaussian noise (Wang et al., 2018); however, in cases of nonlinear models like Hunt-
Crossley that does not have Gaussian noise (e.g. impulsive disorder), there is no optimal solution for
the identification problem. Diolaiti et al. (2005) proposed a double-stage bootstrapped method for
online identification of the Hunt-Crossley model, which is sensitive to parameter initial conditions.
Carvalho & Martins (2019) proposed a method to determine the damping term in the Hunt-Crossley
model. A neural network-based approach was introduced to control the contact/non-contact Hunt-
Crossley model in (Bhasin et al., 2008)
This paper proposes a new technique, Adaptive Recursive Markov Chain Monte Carlo (ARMCMC),
to address address certain weaknesses of traditional online identification methods, such as only being
appllicable to systems Linear in Parameter (LIP), having Persistent Excitation (PE) requirements,
and assuming Gaussian noise. ARMCMC is an online method that takes advantage of the previous
posterior distribution, given that there is no sudden change in the parameter distribution. To achieve
this, we define a new variable jump distribution that accounts for the degree of model mismatch
using a temporal forgetting factor. The temporal forgetting factor is computed from a model mis-
match index and determines whether ARMCMC employs modification or reinforcement to either
restart or refine parameter distribution. As this factor is a function of the observed data rather than
a simple user-defined constant, it can effectively adapt to the underlying dynamics of the system.
We demonstrate our method using two different examples: soft bending actuator and Hunt-Crossley
model and show favorable performance compared to state-of-the-art baselines.
The rest of this paper is organized as follows: In Sec. 2, introductory context about the Bayesian
approach and MCMC is presented. Sec 3 is devoted to presenting the proposed ARMCMC approach
in a step-by-step algorithm. Simulation results on a soft bending actuator with empirical results on a
reality-based model of a soft contact environment capturing a Hunt-Crossley dynamic are presented
in Sec. 4. Lastly, the final remarks and future directions are concluded in Sec 5.
2	Preliminaries
2.1	Problem Statement
In the Bayesian paradigm, estimates of parameters are given in the form of the posterior probabil-
ity density function (pdf); this pdf can be continuously updated as new data points are received.
Consider the following general model:
Y =F(X,θ)+ν,
(1)
where Y , X, θ, and ν are concurrent output, input, model parameters and noise vector, respectively.
To calculate the posterior probability, the observed data along with a prior distribution are combined
via Bayes’ rule (Khatibisepehr et al., 2013). The data includes input/output data pairs (X, Y ). We
will be applying updates to the posterior pdf using batches of data points; hence, it will be convenient
to partition the data as follows:
Dt = {(X, Y )tm , (X, Y )tm + 2 ,…，(X, Y )tm + Ns + l},	⑵
where Ns = Ts/T is the number of data points in each data pack with T, Ts being the data and
algorithm sampling times, respectively. This partitioning is convenient for online applications, as
Dt-1 should have been previously collected so that the algorithm can be executed from tm to tm +
Ns+1 or algorithm time step t. Ultimately, inferences are completed attm+Ns+2. Fig. 1 illustrates
the timeline for the data and the algorithm. It is worth mentioning that the computation can be done
in parallel by rendering the task of the adjacent algorithm step (e.g. phase A of algorithm t, phase
B of algorithm t - 1 and phase C of algorithm t - 2 can all be done simultaneously) According to
Bayes’ rule and assuming data points are independent and identically distributed ( i.i.d) in equation 1,
we have
P (θt∣[Dt-1,Dt])=
P(Dt ∣θt,Dt-1) P(θtDt-1)
R P (D1∣θt,Dtτ)P(θtDtτ)dθt
(3)
where θt denotes the parameters at current time step. P(θt∣Dt-1) is the prior distribution over
parameters, which is also the posterior distribution at the previous algorithm sampling time.
P(DW, DtT) is the likelihood function which is obtained by the one-step-ahead prediction:
Y t∣t-1
F (Dt-1, θt),
(4)
2
Under review as a conference paper at ICLR 2021
to
Phase:	A ►
…	tm + Ns + 1	…
B	C
Algorithm Data
Interval Interval
G	t — 1
t + 1 ------------►
3
Figure 1: Timeline for data and different phase of ARMCMC algorithm. For algorithm at time t:
Phase (A) Data collection [pack Ns data points], Phase (B) Running [apply the method on the data
pack], (C) Execution [update the algorithm results on parameters].
where Yt|t-1 is the prediction of the output in (1). If the model in (4) is valid, then the difference
between the real output and predicted should be measurement noise, (i.e., Yt|t-1 - Yt|t-1 = V).
Therefore, the model parameter may be updated as follows:
tm +Ns +1
P(Dt∣θt,Dt-1) =	Y	PV(Ytlt-1 - Ytlt-r),	(5)
tm+1
where Pν is the probability distribution of noise. Note that there is no restriction on the type of noise
probability distribution.
Remark 1: As it was mentioned before, there is no need to know the exact probability distribution
of noise. This probability distribution can be simply substituted with a Gaussian distribution, if one
has minimal knowledge of the mean and variance of the data which can be easily obtained with
preprocessing (Bishop, 2006).
2.2	Markov Chain Monte Carlo
MCMC is often employed to compute the posterior pdf numerically. The multidimensional inte-
gral in (3) is approximated by samples drawn from the posterior pdf. The samples are first drawn
from a different distribution called proposal distribution, denoted q(.), which can be sampled easier
compared to the posterior. Brooks et al. (2011) discuss different types of MCMC implementations
which may employ various proposal distributions and corresponding acceptance criteria. The main
steps of the Metropolis-Hastings algorithm are listed as follows (Ninness & Henriksen, 2010):
1.	Set initial guess θ0 while P(θ0 |Y) > 0 for iteration k = 1,
2.	Draw candidate parameter θe, at iteration k, from the proposal distribution, q(θcnd∖θk-ι)
3.	Compute the acceptance probability,
P (θcnd∖D)q(θk-1 ∖θcnd)
9MT)= min"""。) — )}，	⑹
4.	Generate a uniform random number γ in [0, 1],
5.	‘Accept’ candidate ifγ ≤ α and ‘ignore’ it ifγ > α,
6.	Set iteration to k + 1 and go to step 2.
2.3	Precision and reliability
Two important notions in probabilistic framework to compare results are precision () and reliability
(δ). The former represents the proximity of a sample to the ground truth, and the latter represents
the probability that an accepted sample lies within of the ground truth.
Lemma: Let Pk be k samples from MCMC, and E(Pk) denote its expected value. According to
Chernoff bound (Tempo et al., 2012), given , δ ∈ [0, 1], if the number of samples (k) satisfies
12
k ≥ 否log(T-7)，	⑺
then P rn{Pk - E(Pk)} ≤ o ≥ δ.
3
Under review as a conference paper at ICLR 2021
Algorithm 1 ARMCMC
Assumptions: 1) roughly noise mean (μν) 2) roughly noise variance (σν) 3) desired precision and
reliability (0, δ0) 4) desired threshold for model mismatch (ζth)
Goal: Online calculation of parameters posterior distribution given the consecutive t-th pack of
data (P(θtDt))
Initialization: Prior knowledge for θ10 , n=0
Consider desire precision and reliability (, δ)
repeat
Put to = n * Ns + 1 from (2), n++
Add new data pack to dataset Dt
Model mismatch index: ζ t from (10)
if ζt < ζth then
Reinforcement: set prior knowledge equal to the latest posterior of previous pack
Temporal forgetting factor: λt from (9)
else
Modification: set prior knowledge θ1n
Temporal forgetting factor: λt = 0
end if
Set minimum iteration kmin from (12)
for k = 1 to kmax do
Proposal distribution:
•	draw λk 〜U(0,1)
•	Variable jump distribution: qkt (.) from (8)
Draw θtk 〜qk(J
Acceptance rate: α(.) from (6)
Draw Y 〜U(0,1)
if γ ≤ α then
‘Accept’ the proposal
end if
end for
Wait to build Dkk0m+Ns+1 (algorithm sample time)
until No data is obtained
3 ARMCMC algorithm
At each time interval, ARMCMC recursively estimates the posterior distribution by drawing sam-
ples. The number of samples drawn is constrained by the desired precision and reliability, and the
real-time requirement. On the other hand, the maximum number of data points in each data pack,
Ns , is limited by the frequency of model variation, and the minimum is confined by the shortest
required time such that the algorithm is real-time. We propose a variable jump distribution that en-
ables both enriching and exploring. This will necessitate the definition of the temporal forgetting
factor as a measure to reflect current underlying dynamics of the data. In other words, this parame-
ter will show the validity of the previous model for the current data. We also prove that ARMCMC
achieves the same precision and reliability with fewer samples compared to the traditional MCMC.
Algorithm 1 summarizes ARMCMC.
3.1	Variable jump distribution
We propose a variable jump distribution (also known as a proposal distribution) to achieve faster
convergence, thereby enabling real-time parameter estimation:
qkWM-CDI)	λk ≤ λt,	(8)
where θkk -1 is the (k - 1)-th parameter sample which is given by the t-th data pack throughout the
MCMC evaluation. Averaging the second half of this quantity will construct θk. P (θk-1 |Dk-1) is
the posterior distribution of the parameters at the previous algorithm time step, and N (μ0 ,σν) is a
Gaussian distribution with μ0,σν computed using sample-based mean and variance of Dt-1.
4
Under review as a conference paper at ICLR 2021
The hyperparameter λt (temporal forgetting factor), is an adaptive threshold for the t-th pack that
takes inspiration from in the classical system identification terminology; it regulates how previous
knowledge affects the posterior distribution. Smaller values of λt intuitively means that there may
be a large sudden change in θ, and thus more exploration is needed. Conversely, larger values of
λt is appropriate when θ is changing slowly, and thus previous knowledge should be exploited. As
more data is obtained, better precision and reliability can be achieved.
3.2	Temporal forgetting factor
Depending on whether the distribution of the parameter θ has changed significantly, a new sample
can be drawn according to the modification or the reinforcement mode. Reinforcement is employed
to make the identified probability distribution more precise when itis not undergoing sudden change.
Modification is employed otherwise to re-identify the distribution ”from scratch”. Therefore, we
define a model mismatch index, denoted ζt, such that when it surpasses a predefined threshold (ζt >
ζth), modification is applied. In other respects, if ζt ≤ ζth, then ζt is used to determine λt as follows:
λt = e-lμν-ζt |,	(9)
where μν is an estimation of the noise mean, by calculation of the expected value in relation (1).
Note that employing modification is equivalent to setting λt = 0. The model mismatch index ζt
itself is calculated by averaging the errors of the previous model given the current data:
Ns
- E (F (Dt(n), θ))
θ∈θt-1
Remark 2: The model mismatch index accounts for all sources of uncertainty in the system. To
calculate ζth, one needs to precalculate the persisting error between the designated modeled and
measured data. In other words, ζth is basically an upper bound for the unmodeled dynamics, distur-
bances, noises, and any other source of uncertainty in the system.
Remark 3: To avoid numerical issues, the summation of probability logarithms are calculated. In
addition, each pair in the algorithm time sample is weighted based on its temporal distance to con-
current time. Therefore Eq. (5) is modified as
ζt = 1/Ns X ynt
n=1
,ζ0=∞	(10)
(11)
tm +Ns +1
log(P(∙)) = X	log PV (et),
tm+1
where ρ ∈ [0, 1] is a design parameter that reflects the volatility of the model parameters, and
et = [et1, ..., etn, ..., etN ]. For systems with fast-paced parameters, ρ should take larger values. We
are trying to solve the Bayesian optimization problem that gives us the pdf of the model parameters
(θ), when given the data pairs in the presence of uncertainty.
3.3 Minimum required evaluation
Theorem 1. Let and δ be the desired precision and reliability. . Furthermore, it can be assumed
that the initial sample has enough number of evaluations (as in (7)). To satisfy the inequality in Eq.
(7), the minimum number of samples k in ARMCMC is calculated using this implicit relation:
12
kmin = 2Z2 log(λt(1 - δ) + 2(1 - λt)e-2^2(i-λt)kmin ).
(12)
Proof. Samples from previous pdf: According to the variable jump distribution in (8), given k sam-
ples, the expected number of samples drawn from the previous posterior probability (P(θ∣Dt)) is
λtk. By assumption, the algorithm has already drawn at least k samples in the previous algorithm
time-step. Consequently, by (7), the expected number of samples with distances less than from
E(Pk ) drawn from a previous distribution is at least λkδ.
5
Under review as a conference paper at ICLR 2021
Samples from Gaussian: By (8), there are k0 = (1 - λt)k samples drawn in expectation. According
to (13), we have Pr {Pk - E(Pk)} ≤	≥ δ0, where δ0 is given by rearranging (7):
δ0 = 1 - 2e-22k0 .
(13)
Thus, the expected number of samples with distances less than fromE(Pk) are at least δ0(1 -λt)k.
Overall reliability: The total expected number of samples with distances less than from E(Pk) is
the summation of the two parts mentioned above. Hence it is obtained through dividing by k:
δ1
(λtkδ) + (δo(1 - λt)k)
k
(14)
Given the new obtained reliability, which is greater than the desired one, helps us decrease the
number of evaluations. For the sake of illustration, Fig. 2 presents the minimum required number of
evaluations with respect to λ for different precisions and reliabilities. As it can be seen, the MCMC
is equal to ARMCM if λ is always set to one. The number of evaluations in ARMCMC mitigates as
the validity of the previous model increases.	口
Figure 2: Kmin with respect to λ for some values of , δ in ARMCMC. (for λ = 0 evaluation for
ARMCMC is equivalent to MCMC)
4 Results
In this section, we demonstrate the priority of the proposed approach given two different examples.
First, we employ the proposed method to identify the soft bending actuator model and compare
the results with a Recursive Least Squares (RLS). In the second example, we evaluate it on the
Hunt-Crossley model given reality-based data and compare it with a simple MCMC and RLS.
4.1	Simulation Results
For this part, we consider the dynamic model of a fluid soft bending actuator. The dynamic is given
by the following relation: (Wang et al., 2019)
α = qi(p - Patm) - Q2& - q3ɑ
Uc Sign(Ps - P) v⅜s - p| =q4p + q5pp, Ud = 0	(15)
Ud Sign(P - Patm) √∣p - Patml = q6p + q7pP, Uc = 0,
where α is the angle of the actuator, Uc, Ud are the control inputs, and P, Ps , Patm are the current,
compressor and atmosphere pressure respectively. For this example, we assume q1 = 1408.50, q2 =
132.28, q3 = 3319.40 are known and Patm = 101.3kPa, Ps = 800kPa. We are trying to identify the
four other parameters (q4, ..., q7). To this end, we assume the hybrid model below:
U Sign(Ps - P) vz∣Ps - P∣ = θιP + θ2PP, U = {uc, Ud}	(16)
6
Under review as a conference paper at ICLR 2021
≈≡∙ 1
⅞o.8
0.6
0.4
0.2
O
1.6
1.4
1.2
(b) Angle of the actuator
Figure 3: Comparison of RLS and AR-MAPS for soft bending actuator
(a) Parameter variation for RLS and AR-MAPS
As the range of these parameters are small, we scale the input vector by the factor of 107 for RLS.
Given the input (uc, Ud) and the output (p,p), We want to identify the parameter and estimate the
current angle of actuator knowing its initial position at the origin. The data sample time is T = 1
ms and each data pack includes 100 samples which results in an algorithm sample time equal to
Ts = 0.1 sec. The point estimation obtained by considering the mode at the modification phase
and the medium during the reinforcement phase in ARMCMC is denoted as AR-MAPS. The point
estimate results for the parameter estimation are shown in Fig. 3a. The true parameters are q5 =
-2.14 × 10-4,q6 = 6.12 × 10-9,q7 = -9.76 × 10-5,q8 = -1.90 × 10-9. The second norm of
the parameters’ errors are 0.0235, 6.0053 × 10-7 for θ1 , θ2 in RLS and 0.0089, 1.1840 × 10-7 in
AR-MAPS, respectively. Moreover, the estimation of the angle is plotted in Fig. 3b.
4.2	Empirical Results
In this section, we demonstrate ARMCMC by identifying parameters of the Hunt-Crossley model,
which represents an environment involving a needle contacting soft material. The needle is mounted
as an end-effector on a high-precision translational robot, which switches between two modes: free
motion and contact. Due to abrupt changes in the model parameters when the contact is established
or lost, online estimation of the force is extremely challenging.
4.2	. 1 Contact dynamic model
Consider the dynamic of contact as described by the Hunt-Crossley model which is more consistent
with the physics of contact than classical linear models such as Kelvin-Voigt (Haddadi & Hashtrudi-
Zaad, 2012). In order to overcome the shortcomings of linear models, Hunt & Crossley (1975)
proposed the following hybrid/nonlinear model :
fe(x(t)) =
∫Ke Xp (t) + Be Xp (t)X(t)
0
X(t) ≥ 0
X(t) < 0,
(17)
in which Ke , BeXp denote the nonlinear elastic and viscous force coefficients, respectively. The
parameter p is typically between 1 and 2, depending on the material and the geometric properties
of contact. Also x(t), X(t), fe are the current position, velocity (as inputs X) and contact force (as
output (Y in (1)) ofa needle near or inside the soft material, with X ≥ 0 representing the needle being
inside. This needle can move freely in open space or penetrate the soft material; the forces on this
needle are modeled using the Hunt-Crossley model. The practical problem we consider is to estimate
the force at the tip of the needle by identifying the model parameters. Ke , Be , p are three unknown
parameters (θ in Eq. (1)) that needs to be estimated. An online estimate of environment force plays
a pivotal role in stable interaction between robotic manipulators and unknown environments.
7
Under review as a conference paper at ICLR 2021
To make the parameters ready for the regression problem we have
lθg(fe) = Iog(Kexs + BexSxIp),
lθg(fe) =P log(xs) + log(Ke + Bexs).
(18)
We will use the RLS method proposed in (Haddadi & Hashtrudi-Zaad, 2012) as a baseline of com-
parison where it is needed to make the assumption that Be/KxS << 1. It should be noticed
that the vector of parameters (θ) in the following relation are not independent, which may lead to
divergence. With this assumption, we have
log(1+ Be/Kexs) ≈ Be/Kexs,
lθg(fe) = P lθg(xs)+log(Ke) + Be/Kexs∙
φ =[1,x s,ln(xs)],
θ =[log(Ke), Be/Ke, P]T .
(19)
(20)
4.2.2	Setup
The data structure is same as previous simulation. Prior knowledge of all three parameters
(Ke,Be,p) are initialized to N(1,0.1) (a normal distribution with μ = 1 and σ = 0.1) More-
over, more data is collected, the spread of the posterior pdf decreases. A bit after 5 seconds, the
needle goes outside of the soft material, and experiences zero force; this is equivalent to all param-
eters being set to zero. The color-based visualization of probability distribution over time is used
for the three parameters in Fig. 4a. During the period of time that the whole space is blue (zero
probability density), there is no contact and the parameter values are equal to zero.
Since we are taking a Bayesian approach, we are able to estimate the entire posterior pdf. However,
for the sake of illustration, the point estimates are computed by using AR-MAPS method which
is shown in Fig. 4b for the time-varying parameters θ1 = Ke , θ2 = Be , θ3 = P. During the
times that RLS results are chattering due to the use of saturation (if not, the results would have
diverged), the needle is transitioning from being inside the soft material to the outside or vice versa.
In addition, due to the assumption(19), performance can deteriorate even when there is no mode
transition. Furthermore, in the RLS approach, estimated parameters suddenly diverged during free
motion, since the regression vectors are linear dependent. In contrast, with the Bayesian approach,
this issue can be easily resolved. The result of ARMCMC is presented in Fig. 5, which shows the
force estimation with two different identification approaches. This probability of interest can be
easily obtained by deriving the parameter density at one’s disposal.
4.2.3	Quantitative Comparison
Quantitative details of comparing a naive point estimate of the ARMCMC algorithm by averaging
the particles (AR-APS) and the RLS method are listed in Table 1. This reveals more than a 70%
improvement in the precision of all model parameters throughout the study by using the Mean Ab-
solute Error (MAE) criteria and also more than a 55% improvements in the second norm of force
estimation error. Among parameters, the viscose (Be) has the largest error in the RLS method since
it is underestimated due to the restrictive assumption in Eq. (19). The AR-MAPS approach uplifts
the performance of the parameter identification and the force estimation.
We also compare ARMCMC to MCMC. For the algorithm to run in real-time, MCMC requires more
time to converge. For this example, with λ = 0.7, the value of Kmin is 15000 for MCMC but only
6000 for ARMCMC (more than two times faster) with = 0.01, δ = 0.9. Two approaches that can
be used to fix this drawback are to reduce the number of samples, which results in worse precision
and reliability compared to ARMCMC, or to increase the algorithm sample time which would cause
more delay in the estimation result and slower responses to changes in the parameter.
5 Conclusions
This paper presented an algorithm for an online identification of full probability distribution of
model parameters in a Bayesian paradigm using an adaptive recursive MCMC. Due to the abrupt
8
Under review as a conference paper at ICLR 2021
(a) Probability distribution using ARMCMC.
(b) Model parameters point estimation in AR-MAPS.
Figure 4: Estimation of model parameters (θ1 = Ke, θ2 = Be, θ3 =P) for Hunt-CrOSSley
—∙— MCMC (N=5∞0)
--MCMC (T=2∞ms)
RLS
AR-MAPS
-2.5
-3
O 2	4	6	8	10	12	14	16	18	20
Time (Sec)
Figure 5: Force prediction error in RLS, AR-APS, and MCMC
Table 1: Comparison of RLS Haddadi & Hashtrudi-Zaad (2012) and point estimate of ARMCMC
and MCMC for environment identification.
Errors	MAE Ke		MAE Be	MAE p	RMS Fe (MN)
RLS		0.5793	0.9642	0.3124	51.745
MCMC (N=5000)		0.6846	0.8392	0.3783	76.695
MCMC (Ts	0.2)	0.7294	0.9964	0.4195	101.88
AR-APS		0.0774	0.0347	0.0945	33.774
AR-MAPS		0.0617	0.0316	0.0756	31.659
change of model parameters such as contact with a soft environment when it is established/lost, con-
ventional approaches suffer from low performance. Empirical results on the Hunt-Crossley model
as a nonlinear hybrid dynamic model was compared with a well-known conventional identification
process and revealed proficiency of the proposed algorithm. The proposed method provides a sys-
tematic strategy for handling abrupt changes which relaxes the pre-requirement conditions in the
parameters. As future work, deploying a fully probabilistic framework from identification to control
and a decision-making stage is considered to exploit the full potentials of the Bayesian optimization.
Additionally, employing a method to compensate the delay will be taken into consideration.
9
Under review as a conference paper at ICLR 2021
References
Niki Abolhassani, Rajni Patel, and Mehrdad Moallem. Needle insertion into soft tissue: A survey.
Medical Engineering and Physics, 29(4):413-431, 2007.
Pedram Agand and Mahdi Aliyari Shoorehdeli. Adaptive model learning of neural networks with
uub stability for robot dynamic estimation. In 2019 International Joint Conference on Neural
Networks (IJCNN), pp. 1-6. IEEE, 2019.
Pedram Agand, Hamid D Taghirad, and Ali Khaki-Sedigh. Particle filters for non-gaussian hunt-
crossley model of environment in bilateral teleoperation. In 4th International Conference on
Robotics and Mechatronics (ICROM), pp. 512-517. IEEE, 2016.
S Bhasin, K Dupree, PM Patre, and WE Dixon. Neural network control of a robot interacting with an
uncertain hunt-crossley viscoelastic environment. In Dynamic Systems and Control Conference,
volume 43352, pp. 875-882, 2008.
Christopher M Bishop. Pattern recognition. Machine Learning, 128, 2006.
Steve Brooks, Andrew Gelman, Galin Jones, and Xiao-Li Meng. Handbook of markov chain monte
carlo. CRC press, 2011.
Andre S Carvalho and Jorge M Martins. Exact restitution and generalizations for the hunt-crossley
contact model. Mechanism and Machine Theory, 139:174-194, 2019.
Noah J Cowan, Ken Goldberg, Gregory S Chirikjian, Gabor Fichtinger, Ron Alterovitz, Kyle B
Reed, Vinutha Kallem, Wooram Park, Sarthak Misra, and Allison M Okamura. Robotic needle
steering: Design, modeling, planning, and image guidance. In Surgical Robotics, pp. 557-582.
Springer, 2011.
Nicola Diolaiti, Claudio Melchiorri, and Stefano Stramigioli. Contact impedance estimation for
robotic systems. IEEE Transactions on Robotics, 21(5):925-935, 2005.
Peter J Green. Reversible jump markov chain monte carlo computation and bayesian model deter-
mination. Biometrika, 82(4):711-732, 1995.
Peter L Green. Bayesian system identification of a nonlinear dynamical system using a novel variant
of simulated annealing. Mechanical Systems and Signal Processing, 52:133-146, 2015.
Amir Haddadi and Keyvan Hashtrudi-Zaad. Real-time identification of hunt-crossley dynamic mod-
els of contact environments. IEEE transactions on robotics, 28(3):555-566, 2012.
KH Hunt and FRE Crossley. Coefficient of restitution interpreted as damping in vibroimpact. Jour-
nal of applied mechanics, 42(2):440-445, 1975.
Dominik Joho, Gian Diego Tipaldi, Nikolas Engelhard, Cyrill Stachniss, and Wolfram Burgard.
Nonparametric bayesian models for unsupervised scene analysis and reconstruction. Robotics:
Science and Systems VIII, pp. 161, 2013.
Shima Khatibisepehr, Biao Huang, and Swanand Khare. Design of inferential sensors in the process
industry: A review of bayesian methods. Journal of Process Control, 23(10):1575-1596, 2013.
Scott Kuindersma, Roderic Grupen, and Andrew Barto. Variational bayesian optimization for run-
time risk-sensitive control. Robotics: Science and Systems VIII, 2012.
TomaSz KU6mierczyk, Joseph Sakaya, and Arto Klami. Variational bayesian decision-making for
continuous utilities. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d Alche-Buc, E. Fox, and
R. Garnett (eds.), Advances in Neural Information Processing Systems 32, pp. 6392-6402. Curran
Associates, Inc., 2019.
Brett Ninness and Soren Henriksen. Bayesian system identification via markov chain monte carlo
techniques. Automatica, 46(1):40-51, 2010.
Ali Noormohammadi-Asl and Hamid D Taghirad. Multi-goal motion planning using traveling sales-
man problem in belief space. Information Sciences, 471:164-184, 2019.
10
Under review as a conference paper at ICLR 2021
Kaur Aare Saar, Fabio Giardina, and Fumiya Iida. Model-free design optimization of a hopping
robot and its comparison with a human designer. IEEE Robotics and Automation Letters, 3(2):
1245-1251,2018.
Roberto Tempo, Giuseppe Calafiore, and Fabrizio Dabbene. Randomized algorithms for analysis
and control of uncertain systems: with applications. Springer Science & Business Media, 2012.
Felipe Tobar. Bayesian nonparametric spectral estimation. In S. Bengio, H. Wallach, H. Larochelle,
K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing
Systems 31, pp. 10127-10137. Curran Associates, Inc., 2018.
Beilun Wang, Arshdeep Sekhon, and Yanjun Qi. A fast and scalable joint estimator for integrat-
ing additional knowledge in learning multiple related sparse Gaussian graphical models. In
Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th International Conference on
Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 5161-5170,
Stockholmsmassan, Stockholm Sweden, 10-15 Jul 2018. PMLR.
Tao Wang, Yunce Zhang, Zheng Chen, and Shiqiang Zhu. Parameter identification and model-
based nonlinear robust control of fluidic soft bending actuators. IEEE/ASME Transactions on
Mechatronics, 24(3):1346-1355, 2019.
A Appendix
According to Abolhassani et al. (2007), a nonlinear hybrid model based on a reality-based soft
environment is considered as follows:
fe = fst(x,t,tp) + ffr(x,X) + fct(x,t,tp),
(21)
where x is the needle tip position and tp is the latest time of puncture. Initial position of the envi-
ronment is assumed to be at the origin. The stiffness of the force (fst) belongs to a pre-puncture and
the friction (ffr) and cutting forces (fct) belong to a post-puncture. The stiffness force is modeled
using a nonlinear Hunt-Crossley model:
(0	x < 0
fst(x, t, tp) = Kexp (t)	0 ≤ x ≤ x1, t < tp	(22)
(0	X > X2,t ≥ tp
where Ke,p are the same parameters defined in (17). The maximum depth that the soft environment
yields before the puncture and its position after it is denoted by x1, x2, respectively (0 < x2 < x1).
In this study, the needle can insert up to 16.65, 10.21 mm before and after penetration. A friction
model is inspired from modified Karnopp model.
ffr(x,x)
Cnsgn(X) + Bexpx
max(Dn, Fa)
max(Dp, Fa)
Cpsgn(X) + Bexpx
X ≤ —∆v∕2
-∆v∕2 <x ≤ 0
0 < x < ∆v∕2
x ≥ ∆v∕2
(23)
where Cn = —11.96 × 10-3 and Cp = 10.57 × 10-3 are negative and positive values of dynamic
friction, Dn = —0.01823 and Dp = 0.01845 are negative and positive values of static friction, and
Be,P are same as Eq. (17). The relative velocity between the needle and tissue is denoted by x, and
∆v∕2 = 0.005 is the value below where the velocity is considered to be zero, and Fa is the sum of
non-frictional applied forces. The cutting force is considered as a static force constant for the tissue
and the needle geometry if soft tissues are not inhomogeneous and anisotropic Cowan et al. (2011)
fct (x, t, tp )
00.94
x ≤ x1 , t < tp
x > x2 , t ≥ tp
(24)
According to the previous relations, the system is considered as a hybrid model while providing
both free motion and in-contact environment. The manipulator is a translational mechanism with
a friction, slip, and hysteresis loop for the actuator. To present the superiority of the proposed
algorithm, the results are compared with the RLS method presented in (Haddadi & Hashtrudi-Zaad,
2012). To prevent the results of RLS from divergence in model mismatch sequences, saturation is
applied in the outputs of the identifier.
11