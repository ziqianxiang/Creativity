Under review as a conference paper at ICLR 2021
Improved Communication Lower Bounds
for Distributed Optimisation
Anonymous authors
Paper under double-blind review
Ab stract
Motivated by the interest in communication-efficient methods for distributed ma-
chine learning, we consider the communication complexity of minimising a sum of
d-dimensional functions PiN=1 fi(x), where each function fi is held by one of the
N different machines. Such tasks arise naturally in large-scale optimisation, where
a standard solution is to apply variants of (stochastic) gradient descent. As our main
result, We show that Ω(Ndlog d∕ε) bits in total need to be communicated between
the machines to find an additive -approximation to the minimum of PiN=1 fi(x).
The result holds for deterministic algorithms, and randomised algorithms under
some restrictions on the parameter values. Importantly, our lower bounds require
no assumptions on the structure of the algorithm, and are matched within constant
factors for strongly convex objectives by a new variant of quantised gradient de-
scent. The lower bounds are obtained by bringing over tools from communication
complexity to distributed optimisation, an approach we hope will find further use
in future.
1	Introduction
The ability to distribute the processing of large-scale data across several computing nodes has been
one of the main technical enablers of recent progress in machine learning, and the last decade has
seen significant research effort dedicated to efficient distributed optimisation. One specific area of
interest is communication reduction for distributed machine learning. Recently, several algorithms
have been proposed to reduce the communication footprint of popular methods in machine learning
and optimisation, in particular gradient descent and stochastic gradient descent; see e.g. Arjevani &
Shamir (2015); Alistarh et al. (2017); Suresh et al. (2017); Tang et al. (2019) for recent work, and
Ben-Nun & Hoefler (2019) for a survey. Despite this extensive work, less is known about theoretical
limits of communication complexity of optimisation, especially in terms of lower bounds on the
minimal number of bits which machines need to transmit to jointly solve an optimisation problem.
In this paper, we study this question in a classical distributed optimisation setting, where data is split
among N which that can communicate by sending point-to-point messages to each other. Given
input dimension d, and a domain D ⊆ Rd, each machine i is given an input function fi : D → R,
and the machines need to jointly minimise the sum PiN=1 fi(x), e.g. the empirical risk, with either
deterministic or probabilistic guarantees on the output. The setting is a standard way to model the
distributed training of machine learning models. For instance, if the individual loss functions are
assumed to be (strongly) convex, we can model a classic regression setting, whereas if the function is
non-convex, we can model distributed training of deep neural networks.
In this context, the key question is: what is the minimal number of bits which need to be exchanged
for this optimisation procedure to be successful, and how does this number depend on the properties
of the functions fi, and the parameters N and d?
1.1	Our results
Setting. We consider this question in the classic message-passing model, where N nodes commu-
nicate by sending messages to each other; specifically, each message is sent to a single receiver and
not seen by the other nodes. Our complexity measure is the total number of bits sent by all the nodes.
1
Under review as a conference paper at ICLR 2021
Given this complexity measure, the model is equivalent (up to a constant factor) to a model where
all messages are relayed via a special coordinator node, known in communication complexity as the
coordinator model and in machine learning as the parameter server model (Li et al., 2014).
For convenience of presentation, we set D = [0, 1]d, and consider a problem where each node i is
given an input function fi : [0, 1]d → R, and the task is to approximate the minimum of the sum
of the functions. That is, the coordinator needs to output z ∈ [0, 1]d and an estimate r ∈ R for the
minimum function value such that
N	N	NN
Xfi(z) ≤	inf dXfi(x) +ε and	Xfi(z) ≤ r ≤ Xfi(z) +ε.	(1)
Specifically, this models a standard distributed machine learning setting where we require one of
the nodes to return the optimised final model, as well as the final value of the loss function. When
proving lower bounds, we allow the nodes to compute arbitrary values that depend on the input
functions and operate on real numbers; only the amount of communicated bits is limited. The precise
definition is somewhat subtle, so we defer the details of the model to Section 2.
Lower bounds for convex functions. We show that, even if the input functions fi at the nodes
are promised to be quadratic functions X → βo∣∣χ — x*k2 for a constant βo > 0, finding a solution
satisfying (1) deterministically requires
Ω (Nd log -) total bits to be communicated,
where β = βoN is the smoothness parameter of PN=I fi, for parameters satisfying1 βd∕ε = Ω(1).
For randomised algorithms, we give a lower bound of
Ω (Nd log -β^-) total bits to be communicated,
for parameters satisfying βd∕N2ε = Ω(1). While this lower bound is slightly weaker due to the
additional dependence in N, in most practical settings the number of parameters d will be significantly
larger than the number of machines N, multiplied by the error tolerance ε. (Specifically, in most
practical settings N《1000, whereas ε ≤ 10-3. More generally, it is sufficient that d = Ω(N2+δ)
for constant δ > 0, for the randomised lower bound to match the deterministic one asymptotically.)
At a very high level, our results generalise the Tsitsiklis & Luo (1987) idea of linking the communica-
tion complexity with the number of quadratic functions with distinct minima in the domain. To extend
this approach to the multi-node case N > 2 and to randomised (stochastic) algorithms, we build con-
nections to results and techniques from communication complexity. Such connections have not to our
knowledge been explored in the context of (real-valued) optimisation tasks, despite reductions from
communication complexity being a standard lower bound technique e.g. in distributed computing
(Das Sarma et al., 2012; Abboud et al., 2016; Drucker et al., 2014). Our work thus provides a model
and a basic toolkit for applying communication complexity results to distributed optimisation, which
should also be useful for understanding other optimisation tasks.
Extensions. While, for convenience, we work with functions over [0, 1]d, our bounds immediately
extend to arbitrary convex domains, as long as we can bound the number of functions with distinct
minima in the domain. Beyond strongly convex and smooth functions, we also show that for
non-convex λ-Lipschitz functions, solving (1) requires
N exp (ω (dlog -)) total bits communicated.
The main takeaway from this result is that for non-convex objectives, one can induce exponentially
higher communication cost by building convoluted input families where the coordinator is required
to essentially learn all local input functions of the nodes.
1The constant hidden by Ω(1) in the parameter dependency is at most πe < 8.6 in all lower bounds.
2
Under review as a conference paper at ICLR 2021
Optimal upper bound. To complement our lower bound, we show that for strongly convex and
strongly smooth functions, finding a solution to (1) can be done deterministically with
O (NdK log K log -) total bits communicated,
where PN=I fi is α-strongly convex and β-strongly smooth, and K = β∕α is the condition number.
This algorithm matches our lower bound for constant condition number. It is a variant of deterministic
quantised gradient descent (MagnUSSOn et al., 2019). However, to achieve a tight bound, we need
to (a) ensure that our gradient quantisation is sufficiently parsimonious, using O(d log K) bits per
gradient, and (b) avoid all-to-all exchange of gradients. For (a), we specialise a recent lattice-based
quantisation scheme which allows arbitrary centering of iterates (Alistarh et al., 2020), and for (b),
we use two-stage quantisation approach, where the nodes first send their quantised gradients to the
coordinator, and the coordinator then broadcasts the carefully quantised sum back to nodes.
1.2 Related work
Message-passing versus broadcast. There are two communication models frequently used in both
communication complexity and distributed optimisation: the first is the message-passing model we
focus on, and the second is the broadcast or blackboard model, where each message sent by a node
is seen by all nodes. The broadcast model is more powerful than the message-passing model: lower
bounds for broadcast model apply also for message-passing, but upper bounds for broadcast do
not directly translate to message passing. Arguably, message-passing model is closer to reality, as
constant-cost, high-bandwidth broadcast mechanisms do not exist in real systems.
Optimisation lower bounds. The first communication lower bounds for a variant of (1) were given
in the seminal work of Tsitsiklis & Luo (1987), who study optimising sums of convex functions
in a two-machine setting. For deterministic algorithms, they prove that Ω(dlog(β0d∕ε)) bits are
necessary. Zhang et al. (2013) use a nearly identical argument to give a Ω(d log(β0d∕ε)) lowerbound
for randomised algorithms in the broadcast model. (See also Table 1 in the Appendix.)
The basic intuition behind these lower bounds is that a node without information about the input
needs to receive Ω(dlog(β0d∕ε)) bits, as otherwise the node cannot produce sufficiently many
different output distributions to cover all possible locations of the minimum (cf. Lemma 2.) It
is worth emphasising that their bound is on the received bits of the output node, and does not
directly imply anything for other nodes; for example, an algorithm where each node transmits
O ((d log(βod∕ε))∕N) bits is not ruled out by these previous results. Generalising their approach to
match our results seems challenging, as we would have to (a) explicitly require that all nodes output
the solution, and (b) ensure that no node can use their local input as a source of extra information.
Our study was inspired in part by the recent work of Vempala et al. (2020), who characterised the
communication complexity of solving linear systems, linear regression, and related problems, over
bounded integer matrices. The results are based on communication complexity arguments, similarly
to our lower bound. However, there are some notable technical differences: first, the arbitrary real
functions we consider do not have a natural binary encoding, and therefore their approach would
not directly extend to our setting. Second, the approximation ratio for linear regression is defined
multiplicatively in their work, whereas we consider additive approximations. Both formulations are
popular in terms of upper bounds, with the additive error formulation being arguably more popular in
the context of machine learning applications. Overall, our results complement theirs, enriching the
landscape of lower bounds for distributed optimisation.
Statistical estimation lower bounds. In statistical estimation, nodes receive random samples from
some input distribution, and must infer properties of the input distribution, e.g. its mean. Specifically,
for mean estimation, there are statistical limits on how good an estimate one can obtain from limited
number of samples, although inputs are drawn from a distribution instead of adversarially. Concretely,
the results of Shamir (2014) and Suresh et al. (2017) apply only to restricted types of protocols. Garg
et al. (2014) and Braverman et al. (2016) give lower bounds for Gaussian mean estimation, where
each node receives s samples from a d-dimensional Gaussian distribution with variance σ2 . The latter
reference shows that to achieve the minimax rate σ2d∕Ns on mean squared error requires Ω(Nd)
total communication. These results do not imply optimal lower bounds for our setting.
3
Under review as a conference paper at ICLR 2021
Lower bounds on round and oracle complexity. Beyond bit complexity, one previous setting
assumes that nodes can transmit vectors of real numbers, while restricting the types of computation
allowed for the nodes. This is useful to establish bounds for the number of iterations required for
convergence of distributed optimisation algorithms (Arjevani & Shamir, 2015; Scaman et al., 2017),
but does not address the communication cost of a single iteration. A second related but different
setting assumes the nodes can access their local functions only via specific oracle queries, such as
gradient or proximal queries, and bound the number of such queries required to solve an optimisation
problem (Woodworth & Srebro, 2016; Woodworth et al., 2018).
Upper bounds. There has been a tremendous amount of work recently on communication-efficient
optimisation algorithms in the distributed setting. Due to space constraints, we focus on a small
selection of closely-related work. One critical difference relative to practical references, e.g. Alistarh
et al. (2017), is that they usually assume gradients are provided as 32-bit inputs, and focus on reducing
the amount of communication by constant factors, which is reasonable in practice. One exception is
Suresh et al. (2017), who present a series of quantisation methods for mean estimation on real-valued
input vectors. Recently, Alistarh et al. (2020) studied the same problem, focusing on replacing the
dependence on input norm with a variance dependence. We adapt their scheme for our upper bound.
Tsitsiklis & Luo (1987) gave a deterministic upper bound in a two-node setting, with
O(Kdlog(κd)log(βd∕ε)) total communication cost. Recently, Magnusson et al. (2019) extended this
to N-node case in the broadcast model, with O(NKdlog(κd)log(βd∕ε)) total communication cost.
For randomised algorithms and constant condition number, better upper bound of O(Nd log(βd∕ε))
total communication cost in the broadcast model follows by using QSGD stochastic quantisation (Al-
istarh et al., 2017) plugged into stochastic variance-reduced gradient descent (SVRG) (Johnson &
Zhang, 2013). See Kiinstner (2017) for a detailed treatment. (See also Table 2 in the Appendix.)
2	Preliminaries and background
Coordinator model. We consider communication protocols in the classic coordinator model (Dolev
& Feder, 1992; Phillips et al., 2012; Braverman et al., 2013). In this model, we have N nodes as well
as a separate coordinator node. The task is to compute the value of a function Γ : BN → A, where
B and A are arbitrary input and output domains; each node i = 1, 2, . . . , N receives an input bi ∈ B.
There is a communication channel between each of the nodes and the coordinator, and nodes can
communicate with the coordinator by exchanging binary messages. The coordinator has to output the
value Γ(b1, b2, . . . , bN). Furthermore, all nodes, including the coordinator, have access to a stream of
private random bits.
More precisely, we assume without loss of generality that computation is performed as follows:
(1)	Initially, each node i = 1, 2, . . . , N receives the input bi. The coordinator and nodes
i = 1, 2, . . . , N receive independent and uniformly random binary strings r, ri ∈ {0, 1}c,
respectively, where c is a constant.
(2)	The computation then proceeds in sequential rounds, where in each round, (a) the coordinator
first takes action by either outputting an answer, or sending a message to a single node i,
and (b) the node i that received a message from the coordinator responds by sending a a
message to the coordinator.
A transcript for a node is a list of the messages it has sent and received. A protocol Π is a mapping
giving the actions of the coordinator and the nodes; for the coordinator, the next action is a function
of its transcript so far and the private random bits r, and for node i, the next action is a function of
its input bi , its transcript so far and the private random bits ri . The protocol Π also determines the
number of random bits the nodes receive.
We say that a protocol Π computes Γ : BN → A with error p if for all (b1, b2, . . . , bN) ∈ BN, the
output of Π is Γ(b1, b2, . . . , bN) with probability at least 1 - p. The communication complexity of a
protocol Π is the maximum number of total bits transmitted by all nodes, i.e. the total length of the
transcripts, on any input (b1, b2, . . . , bN) ∈ BN and any private random bits of the nodes.
While the model definition may appear restrictive, the protocol restrictions do not matter when the
complexity measure is the total number of bits exchanged. Any algorithm using parallel synchronous
4
Under review as a conference paper at ICLR 2021
or even asynchronous communication can be transformed into a sequential protocol by sequentialising
the communication steps to occur one after the other. Likewise, algorithms using all-to-all message-
passing can be transformed to the coordinator model, by routing all messages via the coordinator.
The transformation incur at most constant factor overhead.
Finally, observe that the model is nonuniform, i.e. each protocol is defined only for specific functions
Γ : BN → A and specific input and output sets B and A. As such, we do not need to impose any
requirements on the computability of the protocol actions, rather these can be arbitrary functions.
Any uniform algorithm working for a range of parameters induces a series of nonuniform protocols,
so lower bounds for coordinator model translate to uniform algorithms.
Communication complexity. We now recall some basic definitions and results from communica-
tion complexity. In the following, we assume that sets B and A are finite, as this is the standard
setting of communication complexity.
For a function Γ : BN → A, the deterministic communication complexity CC(Γ) is the minimum com-
munication complexity of a deterministic protocol computing Γ. Likewise, the δ-error randomised
communication complexity RCCδ(Γ) is the minimum communication complexity of a protocol that
computes Γ with error probability δ .
For a distribution μ over BN, We define the δ-error μ-distributional communication complexity
of Γ, denoted by Dμ(Γ), as the minimum communication complexity of a deterministic protocol
that computes Γ with error probability δ when the input is drawn from μ. Similarly, the δ-error
μ-distributional expected communication complexity of Γ, denoted by ED,(Γ), is the minimum
expected communication cost of a protocol that computes Γ with error probability δ, where the
expectation is taken over input drawn from μ and the random bits of the protocol.
Yao’s Lemma (Yao, 1977) relates the distributional communication complexity to the randomised
communication complexity; see Woodruff & Zhang (2017) for a proof in the coordinator model.
Lemma 1 (Yao’s Lemma). Forfunction Γ and δ > 0, we have RCCδ(Γ) ≥ max* D，(1).
Properties of convex functions. Recall that a continuously differentiable function f is
β-(strongly) SmOOth if	INf (X)- ▽/(y)k2 ≤ βkx - y∣∣2 ,
α-strongly convex if	(Vf(X) 一 Vf (y))T(x - y) ≥ α∣x - y∣2
for all x and y in the domain of f . For α-strongly convex and β-strongly smooth function f, we
Say that f has condition number K = β∕α. If fι is αι-strongly convex and βι-strongly smooth and
f2 is α2-strongly convex and β2-strongly smooth, then f1 + f2 is (α1 + α2 )-strongly convex and
(β1 + β2 )-strongly smooth.
A quadratic function f(X) = βkX - yk22 + C is β-strongly convex and β-strongly smooth. For ε > 0,
if f(χ) ≤ ε, then ||x - χ"∣∣2 ≤ (ε∕β)1/2. A sum of quadratics F(X) = P：=i aj IlX - yj ∣∣2, where
yj ∈ Rd and aj ≥ 0 for j = 1,2,...,k,is a quadratic function F(x) = AkX - x*∣2 + C, where C
is a constant and x* = P：=i ajyj/A is the minimum of F.
Point packing. We will make use of the following elementary result, which bounds the number of
points we can pack into [0, 1]d while maintaining a minimum distance between all points.
Lemma 2 (Tsitsiklis & Luo (1987)). For δ > 0 and d ≥ 1, there is a set of points S ⊆ [0, 1]d with
∣∣x — y∣2 > δ for all distinct x, y ∈ S, and |S| ≥ (d1∕2∕Cδ)d, where C = (πe∕2)1/2 is a constant.
3	Lower bounds
3.1	Deterministic lower bound for quadratic functions
We start with a warm-up result, proving a lower bound against deterministic protocols. Essentially, we
show that even recognising if all the nodes have the same input function is hard. Recall that in the N-
player equality over universe of size d, denoted by EQd,N, each player i is given an input bi ∈ {0, 1}d,
5
Under review as a conference paper at ICLR 2021
and the task is to decide if all players have the same input. That is, EQd,N (b1, . . . , bN) = 1 if all inputs
are equal, and 0 otherwise. It is known (Vempala et al., 2020) that the deterministic communication
complexity of EQd,N is CC(EQd,n) = Ω(Nd).
Theorem 3. Given parameters N, d, ε, βo and β = βoN satisfying dβ∕ε = Ω(1), any deterministic
protocol solving (1) for quadratic input functions x 7→ β0 kx - x0 k22 has communication complexity
Ω(Ndlog(βd∕ε)).
Proof. Assume Π is a deterministic protocol solving (1) with communication complexity CΠ . We
show that Π can then solve N-party equality over a universe of size D = Ω(dlog(βd∕ε)), implying
Cn = Ω(ND) = Ω(Ndlog(βd∕ε)).
More specifically, let S be the set given by Lemma 2 with δ = (ε∕2β)1/2, and let D =「log |S|]=
Θ(dlog(βd∕ε)). Note that since we assume dβ∕ε = Ω(1), the set S has at least two elements and
D ≥ 1. For technical convenience, assume |S| = 2D, and identify each binary string b ∈ {0, 1}D
with an element τ (b) ∈ S.
Next, assume that each node i is given a binary string bi ∈ {0, 1}D as input, and we want to compute
EQD,N(b1, b2, . . . , bN). The nodes simulate protocol Π with input function fi for node i, where
fi(x) = β0kx - τ(bi)k22. Let us denote F = Pid=1 fi. Upon termination of the protocol, the
coordinator learns a point y ∈ [0,1]d satisfying F(y) ≤ F(x*) + ε and an estimate r ∈ R satisfying
r ≤ F(y) + ε, where x* is the true global minimum. The coordinator can now adjudicate equality
based on F(y) as follows:
(1)	If all inputs bi are equal, then the functions fi are also equal, and F(x*) = 0. In this case,
we have F(y) ≤ 2ε, and the coordinator outputs 1.
(2)	If there are nodes i and j such that i 6= j, then for all points x ∈ [0, 1]d, we have fi(x) +
fj (x) > 2ε by the definition of S, and thus F(x*) > 2ε. In this case, we have r > 2ε, and
the coordinator outputs 0.
Since communication is only used for the simulation of Π, this computes EQD,N (b1, b2, . . . , bN)
with Cn total communication, completing the proof.	□
3.2	Randomised lower bound for quadratic functions
We now prove our main result, by giving a lower bound for communication complexity of any
algorithm solving (1) that holds even for randomised protocols, albeit with a slightly weaker bound.
Theorem 4. Given parameters N, d, ε, βo and β = βoN satisfying dβ∕N 2ε = Ω(1), any protocol
solving (1) for quadratic input functions x 7→ β0 kx - x0 k22 has communication complexity
Ω(Ndlog(βd∕Nε)).
Discussion. As this is our main result, we pause to discuss its implications. First, this result is more
general than Theorem 3, as it applies to stochastic algorithms such as SGD or SVRG Johnson &
Zhang (2013), which are arguably more popular in practice. The price for the increased generality is
the additional N factor in the denominator of the log, which appears due to technical requirements
in the reduction. Finally, we note that the constant lower bound on dβ∕N2ε is the relatively small
eπ < 8.6, and that this lower bound is likely to hold in most practical settings of interest, as d is
usually quite large, and ε is usually quite small.
Proof overview. To formally apply communication complexity tools, will prove a lower bound
for a discretised version of (1)- where both the input and output sets are finite - which will imply
Theorem 4. Let N, d, ε, and β be fixed, assume dβ∕N2ε = Ω⑴,and
(1)	let S be the set given by Lemma 2 with δ = 3N(ε∕β)1/2, and
(2)	let T ⊆ [0, 1]d be an arbitrary finite set of points such that for any x ∈ [0, 1]d, there is a
point t ∈ T with ∣∣x 一 t∣∣ ≤ (ε∕4β)1/2.
6
Under review as a conference paper at ICLR 2021
By assumption dβ∕N2ε = Ω(1), the set S has size at least 2. Let D = 「log |S|] =
Θ(dlog(βd∕Nε)). Again, for convenience, assume 2D = |S|, and identify each binary string
b ∈ {0, 1}D with an element τ(b) ∈ S.
Definition 5. Given parameters N, d, ε, β, we define the problem MEANεd,,βN as follows:
一 The node inputs arefrom {0,1}D, and
- Valid outputs for input (b1,b2,...,bN) are points t ∈ T that satisfy the condition ∣∣x* 一
t∣∣2 ≤ (ε∕β)1/2, where x* = PN=I T(bi)/N is the average over inputs.
First, we observe that any algorithm for solving (1) can be used to solve MEANεd,,βN.
Lemma 6. For fixed N, d, ε, β0 and β = β0N, any randomised protocol solving (1) for quadratic
functions x 7→ β0∣x 一 x0 ∣22 with error probability 1/3 has communication complexity at least
RCC1/3(MEANd,N/4).
The natural next step is to prove a lower bound on the communication complexity of MEANεd,,βN. We
do this by using an instance of the symmetrisation technique of Phillips et al. (2012), via reduction to
the expected communication complexity of a two-party communication problem where one player
has to learn the complete input of the other player. Specifically, in the two-player problem called
2-BITSd, player 1 (Alice) receives a binary string b ∈ {0, 1}d, of length d, and the task is for player
2 (Bob) to output b. Let ζp be a distribution over binary strings b ∈ {0, 1}d where each bit is set to 1
with probability p and to 0 with probability 1 一 p. The following lower bound for 2-BITSd is known,
and holds even for protocols with public randomness, i.e. when Alice and Bob have access to the
same string of random bits:
Lemma 7 (Phillips et al. (2012)). ED1∕3(2-BITSd) = Ω(dplogPT).
Lemma 8. For N, d, ε, and β satisfying dβ∕N2ε = Ω(1), we have
RCC1/3(MEANd,N) = Ω(N ∙ ED：/3(2-BITSD)) = Ω(Ndlog(βd∕Nε)).
Due to space constraints, we defer the proofs of Lemmas 6 and 8 to Appendix A.1. Theorem 4
now follows immediately from Lemmas 6 and 8. The result can be generalised for arbitrary convex
domains D ⊆ Rd as Ω(N log s), given a point packing bound S for D as in Lemma 2.
3.3 Lower bound for non-convex functions
We now show a simple lower bound for optimisation over non-convex objective functions. Specifically,
we construct a set of hard input functions as follows. Let ε, d and β be constant satisfying dβ∕ε =
Ω(1), and consider the set S given by Lemma 2 with δ = 2ε∕β. This gives a set S with size
at least (βd1∕2∕2Cε)d = exp(Ω(dlog(βd)∕ε). Let us identify the points in S with elements of
{1, 2, . . . , |S|}. For a binary string b ∈ {0, 1}|S|, define the function fb by
fb(x)
β∣x 一 s∣2
ε
if ∣x 一 s∣2 < ε∕β for s with bs = 1,
otherwise.
Since the distance between points in S is at least 2ε∕β, the functions fT are well-defined, continuous
and β-Lipschitz. The proof works by reduction from N -player set disjointness (Braverman et al.,
2013); we defer the details to Appendix B.
Theorem 9. Given parameters N, d, ε and β satisfying dβ∕ε = Ω(1) and (βd1∕2∕2Cε)d =
ω(log N), any protocol solving (1) with error probability δ > 0 when the inputs are guaranteed to be
functions f for b ∈ {0,1}|S| has communication complexity Nexp(Ω(dlog(βd)∕ε)).
4 Tight deterministic upper b ound
We now present a deterministic algorithm which matches our lower bound for constant condition
number, in the coordinator model. We follow the general structure of communication-reduced algo-
rithms, e.g. MagnUSSOn et al. (2019): the nodes collectively execute an instance of gradient descent
7
Under review as a conference paper at ICLR 2021
(GD), where they carefully quantise their updates, accumulated at a coordinator. The algorithm relies
on two new technical ingredients to achieve optimality: 1) we use two-step quantisation to avoid
(inherently suboptimal) all-to-all communication; 2) we remove a superfluous log d factor in the
communication by employing a lattice-based quantisation scheme allowing for arbitrary centring
of the gradient estimates to be averaged (Alistarh et al., 2020). The second step causes non-trivial
complications, as this scheme may fail if inputs are too far apart.
Preliminaries. We assume that the input functions of each node i is fi : {0, 1}d → R, which is
α0-strongly convex and β0-strongly smooth. This implies that F = PiN=1 is α-strongly convex and
β-strongly smooth for α = Nα0 and β = Nβ0 . Consequently, the functions fi and F have condition
number bounded by K = β∕α. Furthermore, We assume that the local functions f all have minimum
value inf x∈[0,1]d fi (x) = 0, and thus range [0, β0d].
We aim to reach the global minimum x? of the sum PiN=1 fi (x) by starting from an arbitrary point
x0 ∈ [0, 1]d, and applying a surrogate of the GD update
N
χ(t+1) = χ(t) - Y E Vfi(χ(t)), where γ > 0 is the learning rate parameter.
i=1
It is well-known, e.g. Bubeck (2015), that GD converges at an exponential rate in (1 - 1∕κ).
The algorithm has each node generate gradients of its local function fi , and quantise them in a
carefully-parametrised way. Specifically, the quantisation we use works in a setting where the nodes
all know a point q ∈ [0,1]d, and the points to be quantised are in the vicinity of q - in the algorithm,
the point q will be the previous quantised gradient. The quantisation is parametrised by R, the
maximum distance between the input point and q, and by ε, the maximum quantisation error we wish
to tolerate.
Corollary 10 (Alistarh et al. (2020)). Let R and ε be fixed positive parameters, and q ∈ Rd be an
estimate vector, and B ∈ N be the number of bits used by the quantisation scheme. Then, there exists
a deterministic quantisation scheme, specified by a function Qε,R : Rd × Rd → Rd, an encoding
function encε,R : Rd → {0, 1}B, and a decoding function decε,R : Rd × {0, 1}B → Rd, with the
following properties:
(1)	(Validity.) decε,R (q, encε,R(x)) = Qε,R(x, q) for all x, q ∈ Rd with kx - qk2 ≤ R.
(2)	(Accuracy.) kQε,R (x, q) - xk2 ≤ ε for all x, q ∈ Rd with kx - qk2 ≤ R.
(3)	(Cost.) If ε = λR for any λ < 1, the bit cost of the scheme satisfies B = O(d log λ-1).
Algorithm description. We now describe the algorithm, and overview its guarantees. The full
description and analysis are available in Appendix C. We assume that the constants α and β are known
to all nodes, so the parameters of the quantised gradient descent can be computed locally, and use W
to be an upper bound on the diameter on the convex domain D, e.g. W = d1/2 if D = [0, 1]d. We
assume that the initial iterate x(0) is arbitrary, but the same at all nodes, and set the initial quantisation
estimates q(0) and qi(0) at each i as the origin.
The algorithm proceeds in rounds t = 1, 2, . . . , T. At the beginning of round t + 1, each node i
knows the values of the iterate x(t), the previous global quantised gradient q(t), and its local quantised
gradient qi(t); the coordination knows all these values. We define the following parameters for the
algorithm. Let γ = β-1 and ξ = (1 - κ-1) be the step size and convergence rate of gradient descent,
and let W be such that ∣∣χ0 - x*k ≤ W. We define
K = 2∕ξ, δ = ξ(1-ξ)∕4,	μ = δK + ξ,	R⑴=βKWμt.
Assuming K ≥ 2, we have μ < 1, ξ ≥ 1/2 and K ≥ 1. At step t, nodes perform the following steps:
(1)	Each node i updates its iterate as x(t+1) = x(t) - γq(t).
(2)	Each node i computes its local gradient over x(t+1), and transmits it in quantised form to
the coordinator as follows. Let ε1 = δR(t+1)∕(2N) and ρ1 = R(t+1)∕N.
8
Under review as a conference paper at ICLR 2021
(a)	Node i computes Vfi(χ(t+1)) locally, and sends message m% = encε1,ρ1 (Vfi(χ(t+1)))
to the coordinator.
(b)	The coordinator receives messages mi for i = 1, 2, . . . , N, and decodes them as
qi(t+1) = decε1,ρ1 (qi(t), mi). The coordinator then computes r(t+1) = PiN=1 qi(t+1).
(3)	The coordinator sends the quantised sum of gradients to all other nodes as follows. Let
ε2 = δR(t+1)∕2 and ρ2 = (1 + δ∕2)R(t+1).
(a)	The coordinator sends the message m = encε2,ρ2 (r(t+1)) to each node i.
(b)	Each node decodes the coordinator’s message as q(t+1) = decε2,ρ2 (q(t) , m).
Guarantees. The key technical trick behind the algorithm is the extremely careful choice of
parameters for quantisation at every step. This balances the fact that the quantisation has to be fine
enough to ensure optimal GD convergence, but coarse enough to ensure optimal communication cost.
Overall, the algorithm ensures the following guarantees, whose proof is provided in Appendix C.
Theorem 11. Let ε > 0, a dimension d, and a convex domain D ⊆ Rd of diameter W be fixed.
Given N nodes, each assigned a function fi : D → R such that F = PiN=1 fi is α-strongly convex
and β-smooth, the above algorithm converges to a point X(T) with ∣∣F(X(T)) 一 F(x*)∣∣2 ≤ ε using
O (NdK log K log β^- ) bits of communication.
5 Discussion and future work
We have provided the first tight bounds on the communication complexity of optimising sums of
quadratic functions in theN-party model with a coordinator. Our results are algorithm-independent,
and immediately imply the same lower bound for the practical parameter server and decentralised
models of distributed optimisation.
In terms of future work, we expect that the randomised lower bound could be improved to match
the deterministic one even for small d, possibly via reduction from a suitable gap problem in
communication complexity (e.g. Chakrabarti & Regev (2011)). Another avenue for future work is
to investigate tight upper and lower bounds in the case where the functions being optimised are not
quadratics, as isolating the “right” dependency on the condition number does not appear immediate.
Finally, understanding the exact complexity of optimisation in the broadcast model remains open.
References
Amir Abboud, Keren Censor-Hillel, and Seri Khoury. Near-linear lower bounds for distributed
distance computations, even in sparse networks. In Proc. 30th International Symposium on
Distributed Computing (DISC 2016),pp. 29-42. Springer, 2016. doi: 10.1007/978-3-662-53426-
7_3.
Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic. QSGD: Communication-
efficient SGD via gradient quantization and encoding. In Advances in Neural Information Process-
ing Systems, pp. 1709-1720, 2017.
Dan Alistarh, Saleh Ashkboos, and Peter Davies. Distributed mean estimation with optimal error
bounds, 2020. arXiv:2002.09268 [cs.LG].
Yossi Arjevani and Ohad Shamir. Communication complexity of distributed convex learning and
optimization. In Advances in Neural Information Processing Systems 28 (NIPS 2015), pp. 1756-
1764, 2015.
Tal Ben-Nun and Torsten Hoefler. Demystifying parallel and distributed deep learning: An in-depth
concurrency analysis. ACM Computing Surveys (CSUR), 52(4):1-43, 2019.
Mark Braverman, Faith Ellen, Rotem Oshman, Toniann Pitassi, and Vinod Vaikuntanathan. A tight
bound for set disjointness in the message-passing model. In Proc. 54th Annual Symposium on
Foundations of Computer Science (FOCS 2013), pp. 668-677. IEEE, 2013.
9
Under review as a conference paper at ICLR 2021
Mark Braverman, Ankit Garg, Tengyu Ma, Huy L Nguyen, and David P Woodruff. Communication
lower bounds for statistical estimation problems via a distributed data processing inequality. In
Proceedings of the 48th Annual ACM symposium on Theory of Computing (STOC 2016), pp.
1011-1020, 2016.
Sebastien Bubeck. Convex Optimization: Algorithms and Complexity. now Publishers, 2015.
Amit Chakrabarti and Oded Regev. An optimal lower bound on the communication complexity of
gap-hamming-distance. In Proc. 43rd ACM Symposium on Theory of Computing (STOC 2011),
New York, NY, USA, 2011. Association for Computing Machinery. ISBN 9781450306911.
doi:10.1145/1993636.1993644.
Atish Das Sarma, Stephan Holzer, Liah Kor, Amos Korman, Danupon Nanongkai, Gopal Panduran-
gan, David Peleg, and Roger Wattenhofer. Distributed verification and hardness of distributed
approximation. SIAM Journal on Computing, 41:1235-1265, 2012. doi:10.1137/11085178X.
Danny Dolev and Tomas Feder. Determinism vs. nondeterminism in multiparty communication
complexity. SIAM Journal on Computing, 21(5):889-895, 1992.
Andrew Drucker, Fabian Kuhn, and Rotem Oshman. On the power of the congested clique model. In
Proc. 33rd ACM Symposium on Principles of Distributed Computing (PODC 2014), pp. 367-376,
2014. doi:10.1145/2611462.2611493.
Ankit Garg, Tengyu Ma, and Huy Nguyen. On communication cost of distributed statistical estimation
and dimensionality. In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q.
Weinberger (eds.), Advances in Neural Information Processing Systems 27 (NIPS 2014), pp.
2726-2734. Curran Associates, Inc., 2014.
Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance
reduction. In Advances in neural information processing systems, pp. 315-323, 2013.
Frederik Kunstner. Fully quantized distributed gradient descent. Master S thesis, Ecole polytechnique
fe´ de´ rale de Lausanne, 2017. URL http://infoscience.epfl.ch/record/234548.
Mu Li, David G Andersen, Jun Woo Park, Alexander J Smola, Amr Ahmed, Vanja Josifovski, James
Long, Eugene J Shekita, and Bor-Yiing Su. Scaling distributed machine learning with the parameter
server. In Proc. 11th USENIX Symposium on Operating Systems Design and Implementation
(OSDI 2014), pp. 583-598, 2014.
S. Magnusson, H. Shokri-Ghadikolaei, and N. Li. On maintaining linear convergence of distributed
learning and optimization under limited communication. In Proc. 53rd Asilomar Conference on Sig-
nals, Systems, and Computers (ACSSC 2019), 2019. doi:10.1109/IEEECONF44664.2019.9049052.
Jeff M Phillips, Elad Verbin, and Qin Zhang. Lower bounds for number-in-hand multiparty com-
munication complexity, made easy. In Proc. 23rd Annual ACM-SIAM symposium on Discrete
Algorithms (SODA 2012), pp. 486-501, 2012.
Kevin Scaman, Francis Bach, SebaStien Bubeck, Yin Tat Lee, and Laurent Massoulie. Optimal
algorithms for smooth and strongly convex distributed optimization in networks. In Proceedings of
the 34th International Conference on Machine Learning (ICML 2017), pp. 3027-3036, 2017.
Ohad Shamir. Fundamental limits of online and distributed algorithms for statistical learning and
estimation. In Advances in Neural Information Processing Systems 27 (NIPS 2014), pp. 163-171,
2014.
Ananda Theertha Suresh, Felix X Yu, Sanjiv Kumar, and H Brendan McMahan. Distributed mean
estimation with limited communication. In Proceedings of the 34th International Conference on
Machine Learning (ICML 2027), pp. 3329-3337. JMLR. org, 2017.
Hanlin Tang, Chen Yu, Xiangru Lian, Tong Zhang, and Ji Liu. DoubleSqueeze: Parallel stochastic
gradient descent with double-pass error-compensated compression. In Proc. 36th International
Conference on Machine Learning (ICML 2019), volume 97, pp. 6155-6165, 2019.
10
Under review as a conference paper at ICLR 2021
John N Tsitsiklis and Zhi-Quan Luo. Communication complexity of convex optimization. Journal of
Complexity, 3(3):231-243,1987.
Santosh S. Vempala, Ruosong Wang, and David P. Woodruff. The communication complexity of
optimization. In Proceedings of the 2020 ACM-SIAM Symposium on Discrete Algorithms (SODA
2020), pp. 1733-1752, 2020. doi:10.1137/1.9781611975994.106.
David P. Woodruff and Qin Zhang. When distributed computation is communication expensive.
Distributed Computing, 30(5):309-323, 2017. doi:10.1007/s00446-014-0218-3.
Blake E Woodworth and Nati Srebro. Tight complexity bounds for optimizing composite objectives.
In Advances in Neural Information Processing Systems 29 (NIPS 2016), pp. 3639-3647, 2016.
Blake E Woodworth, Jialei Wang, Adam Smith, Brendan McMahan, and Nati Srebro. Graph oracle
models, lower bounds, and gaps for parallel stochastic optimization. In Advances in Neural
Information Processing Systems 31 (NIPS 2018), pp. 8496-8506, 2018.
Andrew Chi-Chin Yao. Probabilistic computations: Toward a unified measure of complexity. In Proc.
18th Annual Symposium on Foundations of Computer Science (FOCS 1977), pp. 222-227, 1977.
doi:10.1109/SFCS.1977.24.
Yuchen Zhang, John Duchi, Michael I Jordan, and Martin J Wainwright. Information-theoretic
lower bounds for distributed statistical estimation with communication constraints. In Advances in
Neural Information Processing Systems 26 (NIPS 2013), pp. 2328-2336, 2013.
11
Under review as a conference paper at ICLR 2021
Table 1: Comparison of existing lower bounds on total communication required to solve (1). ‘BC’
denotes results for broadcast model, and ‘MP’ denotes results for message-passing model. Note that
lower bounds for the broadcast model also apply to the message-passing model.
Problem	Lower bound	Model		
Quadratic optimisation	Ω(dlog 等)	2-node	Det.	Tsitsiklis & Luo (1987)
	Ω(dlog 等)	BC	Rand.	Garg et al. (2014)
	Ω(Ndlog βεd)	MP	Det.	§3.1
	Ω(Nd log NI)	MP	Rand.	§3.2
Gaussian mean estimation	Ω(Nd∕ log N)	BC	Rand.	Garg et al. (2014)
	Ω(Nd)	BC	Rand.	Braverman et al. (2016)
Table 2: Upper bounds for distributed optimisation over β-smooth, α-strongly convex input functions
with condition number κ. ‘BC’ denotes results for broadcast model, and ‘MP’ denotes results for
message-passing model. Note that upper bounds for the message-passing model also apply to the
broadcast model, but not vice versa.
Input functions	Upper bound	Model		
Constant κ	O(Ndlog βεd)	BC	Rand.	Alistarh et al. (2017); Kunstner (2017)
General	O(Kdlog(κd) log βεd)	2-node	Det.	Tsitsiklis & Luo (1987)
	O(Nκdlog(κd) log βεd)	BC	Det	Magnusson et al. (2019)
	O(Ndκ log κ log βεd)	MP	Det.	§4
A Omitted proofs, Section 3.2
A.1 Proof of Lemma 6
Proof of Lemma 6. Let Π be protocol solving (1) with communication complexity C and error
probability 1/3. We show that We can use it to solve MEANd,N/4 with total communication cost C
and error probability 1/3, implying the claim. Given input (b1,b2, ...,bN) for MEANd'N/4, nodes
can simulate the protocol Π with input functions fi (x) = β0 kx - τ(bi)k22 . By the properties of
quadratic functions, We have F(x) = PN=I fi(x) = β||x - χ*∣∣2 + C, where x* = PN=I TNi).
Thus, the output y of Π satisfies ky - x*∣2 ≤ (ε∕β)1/2. The coordinator now outputs the closest
point t ∈ T to y. We therefore have
|x* -1∣2 = |x* - y + y -1∣2 ≤ ∣χ* - y∣2 + ky -1∣2 ≤ 2(ε∕β)1/2 = (4ε∕β)”.
□
A.2 Proof of Lemma 8
Proofof Lemma 8. Let μ denote a distribution on QN=ι{0,1}D, where each D-bit string is selected
uniformly at random, and let ζ be uniformly random on {0, 1}D. We will prove that
Dμ∕3(MEANd,N) = Ω(N ∙ ED1/3(2-BITSD)).
Since ED1/3(2-BITSD) = Ω(D) by Lemma 7, the claim follows by Yao,s Lemma.
12
Under review as a conference paper at ICLR 2021
Suppose now that we have a deterministic protocol Π1 for MEANεd,,βN with worst-case communication
cost C and error probability 1/3 on input distribution μ. Given ∏ι, We define a 2-player protocol ∏2
with public randomness for 2-BITSD as follows; assume that Alice is given b ∈ {0, 1}D as input.
(1)	Alice and Bob pick a random index i ∈ [N] uniformly at to select a random i node using
the shared randomness. Without loss of generality, We can assume that the picked node Was
node i = 1.
(2)	Alice and Bob simulate protocol Π1, With Alice simulating node 1 and Bob simulating
the coordinator and nodes 2, 3, . . . , N. For the inputs b1, b2, . . . , bN to Π1, Alice sets
b1 = x, and Bob selects the inputs b2 , b3 , . . . , bN uniformly at random by using the public
randomness. Messages Π1 sends betWeen the coordinator and node 1 are communicated
betWeen Alice and Bob, and all other communication is simulated by Bob internally.
(3)	Once the simulation is complete, Bob knoWs the output t ∈ T of Π1 Which satisfies
IIt- z*∣∣2 ≤ (ε∕β)1/2, where z* = PN=I T(bi)/N.
As the final step, We shoW that Bob can noW recover Alice’s input from t. Lety = PiN=2 τ (bi)/(N -1)
be the weighted average of points τ(b2), τ(b3), . . . , τ(bN ). We now have that Nz* - (N - 1)y =
τ(b1) by simple calculation.
Since ∣∣t - z*∣2 ≤ (ε∕β)1/2, itfollows that
I(Nt - (N - 1)y) - τ (b1)I2 = INt - (N - 1)y - Nz* + Nz* - τ (b1)I2
= ∣Nt-Nz*+Nz* -(N-1)y-τ(b1)∣2
= IlNt- Nz*∣∣2 = NIIt- z*∣∣2 ≤ N(ε∕β)1/2.
Since the distance between any two points in S is at least 3N(ε∕β)1/2, we have that T(bi) is the
only point from S within distance (ε∕β)1/2 from Nz — (N — 1)y. As Bob knows both Z and
T(b2), T(b3), . . . , T(bN ) after the simulation, he can recover the point x1 and thus infer Alice’s input.
Now let us analyse the expected cost of Π2 under input distribution ζ . First, observe that since the
simulation runs ∏ι on input distribution μ, the output y is correct with probability 2/3, and thus the
output of Π2 is correct with probability 2∕3. Now let CΠ1 be the worst-case communication cost
of Π1 and let CΠ1 (b1, . . . , bN ) and CΠ1,i(b1, . . . , bN ) denote the total communication cost and the
communication used by node i in Π1 on input b1 , . . . , bN , respectively. Finally, let CΠ2 (b, r) be a
random variable giving the communication cost of Π2 on input b and random bits r.
Now we have that
Ebι,r [C∏2 (b1,r)] =	X	2D Er[C∏2 (b1,r)]
b1∈{0,1}D
Σ
b1∈{0,1}D
1N
2D	XX
b2 ,...,bN i=1
C∏1,i(b1,..., bN)
-N 2(n T)D
1	1N
N ΣS	2NDECni,i(b1,...，bN)
N X	2ND CnI (bi,b2, ...,bN )
b1 ,b2 ,...,bN
V4 X 1 C = CΠ1
≤ N	2ND Cn1 = N
b1 ,b2 ,...,bN
Since Eg,β [C& (bi,r)] ≥ ED1∕3(2-BITSd), and the argument holds for any protocol ∏ι solving
MEANεd,,βN with error probability 1∕3, we have that
D1/3(MEANd；N) ≥ N ∙ ED1/3(2-BITSD),
completing the proof.
□
13
Under review as a conference paper at ICLR 2021
B Lower bound for non-convex functions, full version
We now show a simple lower bound for optimisation over non-convex objective functions. We reduce
from the N -player set disjointness over universe of size d, denoted by DISJd,N: each player i is given
an input bi ∈ {0, 1}d, and the coordinator needs to output 0 if there is a coordinate ` ∈ [d] such that
bi(`) = 1 for all i ∈ [N], and 1 otherwise.
Theorem 12 (Braverman et al. (2013)). For δ > 0, N ≥ 1 and d = ω(log N), the randomised
communication complexity OfSet disjointness is RCCδ(DISJd,n) = Ω(Nd).
Again consider for fixed ε, d and β the set S given by Lemma 2 with δ = 2ε∕β. This gives a set S
with size at least (βd"∕2Cε)d = exp(Ω(dlog(βd)∕ε). Let US identify the points in S with indices
in [|S|]. For a binary string b ∈ {0, 1}|S|, define the function fb by
fb(x)
β kx - sk2
ε
if kx - sk2 < ε∕β for s with bs = 1,
otherwise.
Since the distance between points in S is at least 2ε∕β, the functions fb are well-defined, continuous
and β-Lipschitz.
Theorem 9. Given parameters N, d, ε and β satisfying dβ∕ε = Ω(1) and (βd"2∕2Cε)d =
ω(log N), any protocol solving (1) with error probability δ > 0 when the inputs are guaranteed to be
functions f for b ∈ {0,1}|S| has communication complexity Nexp(Ω(dlog(βd)∕ε)).
Proof. Assume there is a protocol Π with the properties stated in the claim, and worst-case commu-
nication cost CΠ. We now show that we can use Π to solve set disjointness over universe of size |S|
with CΠ total communication, which implies
Cn ≥ RCCδ(DISJ∣s∣,n) = Ω(Nexp(Ω(dlog(βd)∕ε)),
yielding the claim.
First, we observe that for b1, b2, . . . bN ∈ {0, 1}|S| that all contain 1 in some position s, then we have
PiN=1 fbi (x) = 0. Otherwise, for any point x ∈ [0, 1]d, consider the closest point s ∈ S to x; there
is at least one bi with bs = 0, and for that function fbi (x) = ε by definition. Thus, if b1, b2, . . . bN
are a YES-instance for set disjointness, then infx∈[0,1]d PiN=1 fbi (x) ≥ ε, and if b1, b2, . . . bN are a
NO-instance, then infx∈[0,1]d PiN=1 fbi (x) = 0.
By definition, Π can be used to distinguish between the two cases, and thus to solve set disjointness.
□
C Description and analysis of the upper bound, full version
We now describe in detail our deterministic upper bound. Our algorithm uses quantised gradient
descent, loosely following the outline of Magnusson et al. (2019). However, there are two crucial
differences. First, we use a carefully-calibrated instance of the quantisation scheme of Alistarh et al.
(2020) to remove a log d factor from the communication cost, and second, we use use two-step
quantisation to avoid all-to-all communication.
Preliminaries on gradient descent. We will assume that the input functions fi : [0, 1]d → R are
α0-strongly convex and β0-strongly smooth. This implies that F = PiN=1 fi is α-strongly convex
and β-strongly smooth for α = Nα0 and β = Nβ0 . Consequently, the functions fi and F have
condition number bounded by κ = β∕α. Furthermore, we assume that the local functions fi all have
minimum value inf x∈[0,1]d fi(x) = 0, and thus range [0, β0d].
Gradient descent optimises the sum PiN=1 fi(x) by starting from an arbitrary point x(0) ∈ [0, 1]d,
and applying the update rule
N
χ(t+i) = χ(t) — γ ^X Vfi(x(t)),
i=1
14
Under review as a conference paper at ICLR 2021
where γ > 0 is a parameter.
Let x* denote the global minimum of F. We use the following standard result on the convergence of
gradient descent; see e.g. Bubeck (2015).
Theorem 13. For γ = β-1, we have that kx(t+1) - x* k2 ≤ (1 - κ-1)kx(t) - x* k2.
Preliminaries on quantisation. For compressing the gradients the nodes will send to coordinator,
we use the recent quantisation scheme of Alistarh et al. (2020). Whereas the original uses randomised
selection of the quantisation point to obtain a unbiased estimator, we can use a deterministic version
that picks an arbitrary feasible quantisation point (e.g. the closest one). This gives the following
guarantees:
Corollary 10 (Alistarh et al. (2020)). Let R and ε be fixed positive parameters, and q ∈ Rd be an
estimate vector, and B ∈ N be the number of bits used by the quantisation scheme. Then, there exists
a deterministic quantisation scheme, specified by a function Qε,R : Rd × Rd → Rd, an encoding
function encε,R : Rd → {0, 1}B, and a decoding function decε,R : Rd × {0, 1}B → Rd, with the
following properties:
(1)	(Validity.) decε,R (q, encε,R(x)) = Qε,R(x, q) for all x, q ∈ Rd with kx - qk2 ≤ R.
(2)	(Accuracy.) kQε,R (x, q) - xk2 ≤ ε for all x, q ∈ Rd with kx - qk2 ≤ R.
(3)	(Cost.) If ε = λR for any λ < 1, the bit cost of the scheme satisfies B = O(d log λ-1).
C.1 Algorithm description
We now describe the algorithm, and overview its guarantees. We assume that the constants α and
β are known to all nodes, so the parameters of the quantised gradient descent can be computed
locally, and use W to be an upper bound on the diameter on the convex domain D, e.g. W = d1/2 if
D = [0, 1]d. We assume that the initial iterate x(0) is arbitrary, but the same at all nodes, and set the
initial quantisation estimate qi(0) at each i as the origin.
The algorithm proceeds in rounds t = 1, 2, . . . , T. At the beginning of round t + 1, each node i
knows the values of the iterate x(t), the global quantisation estimate q(t), and its local quantisation
estimate qi(t) for i = 1, 2, . . . , N. We define the following parameters for the algorithm. Let γ = β-1
and ξ = (1 - κ-1) be the step size and convergence rate of gradient descent, and let W be such that
kx(0) - x* k ≤ W. We define
K = 2∕ξ, δ = ξ(1-ξ)∕4,	μ = δK + ξ,	R⑴=βKWμt.
Assuming K ≥ 2, we have μ < 1, ξ ≥ 1/2 and K ≥ 1. At step t, nodes perform the following steps:
(1)	Each node i updates its iterate as x(t+1) = x(t) - γq(t).
(2)	Each node i computes its local gradient over x(t+1), and transmits it in quantised form to
the coordinator as follows. Let ε1 = δR(t+1)∕(2N) and ρ1 = R(t+1) ∕N.
(a)	Node i computes Vfi(χ(t+1)) locally, and sends message mi = encει,ρι (Vfi(χ(t+1)))
to the coordinator.
(b)	The coordinator receives messages mi for i = 1, 2, . . . , N, and decodes them as
qi(t+1) = decε1,ρ1 (qi(t), mi). The coordinator then computes r(t+1) = PiN=1 qi(t+1).
(3)	The coordinator sends the quantised sum of gradients to all other nodes as follows. Let
ε2 = δR(t+1)∕2 and ρ2 = (1 +δ∕2)R(t+1).
(a)	The coordinator sends the message m = encε2,ρ2 (r(t+1)) to each node i.
(b)	Each node decodes the coordinator’s message as q(t+1) = decε2,ρ2 (q(t), m).
After round T, all nodes know the final iterate x(T). The nodes compute their local value fi(x(T)),
and send an approximate value to the coordinator; specifically, each node computes a partition of the
range [0, β0d] into segments of length ε∕N, and sends the index of the smallest segment endpoint r
satisfying r ≥ fi(x(T)) to the coordinator.
15
Under review as a conference paper at ICLR 2021
C.2 Analysis
For simplicity, we will split the analysis into two parts. The first describes and analyses the algorithm
in an abstract way; the second part describes the details of implementing it in the coordinator model.
For technical convenience, assume κ ≥ 2; for smaller condition numbers, we can run the algorithm
with κ = 2.
Convergence. Let γ = β-1, let x(0) ∈ [0, 1]d, qi(0) ∈ Rd and qi(0) ∈ Rd for i = 1, 2, . . . , N be
arbitrary initial values. From the algorithm description, we see that the update rule for our quantised
gradient descent is
x(t+1) = x(t) - γq(t) ,
q(t+1) = Q^^fi(x^t+1)), q(t), R(t+1)∕N, δR(t+1)∕(2N)),
r(t+1)
N
X qi(t+1),
i=1
q(t+1) = Q(r(t+1),q(t), (1 + δ∕2)mt+D,δmt+D∕2).
Lemma 14. The inequalities
kx⑴-x*k2 ≤ μtW,	(Q1)
kVfi(x(t)) - q(t)k2 ≤ δR(t)∕(2N) ,	(Q2)
kVF(X⑴)-q㈤k2 ≤ δR㈤	(Q3)
hold for all t, assuming that they hold for x(0), q(0) and qi(0) for i = 1, 2, . . . , N.
Proof. We apply induction over t; we assume that all the inequalities hold for t, and prove that they
also hold for t + 1. Since we assume the inequalities hold for t = 0, the base case is trivial.
Convergence (Q1): We have
∣∣x(t+1) - x*k2 = kx(t) - Yq⑴ + γVF(X⑴)-YVF(X㈤)+ x*∣∣2
≤ kγq(t) - γVF(X⑴)∣2 + k(x(t) - γVF(x(t))) - x*∣∣2
≤ YkVF(X⑴)-q㈤∣2 + ξ∣χ㈤-X*∣2
≤ β-1δR(t) + ξμtW
=β-1δβKμt W + ξμtW
=(δK + ξ)μtW = μt+1W.
Local quantisation (Q2): First, let us observe that to prove that (Q2) holds for t + 1, it is sufficient
to show kVfi(X(t+1)) - qi(t) k2 ≤ R(t+1)∕N, as the claim then follows from the definition of qi(t+1)
and Corollary 10. We have
kVfi(X(t+1))-qi(t)k2 = kVfi(X(t+1)) -Vfi(X(t))+Vfi(X(t)) -qi(t)k2
≤ kVfi(X(t+1)) -Vfi(X(t))k2+kVfi(X(t)) -qi(t)k2
≤ β0kX(t+1) -X(t)k2 +δR(t)∕N
≤ βo(∣Kt+1)- X*∣∣2 + ∣X㈤-X*∣∣2) + δR(t)∕N
≤ 2β0μtW + δR(t)∕N
=2βμtW∕N + δβKμtW∕N
=(2∕K + δ)Kβμt W∕N
=(ξ + δ)KβμtW∕N
≤ (ξ + δK)KβμtW∕N = Kβμt+1W∕N = R(t+1)∕N.
16
Under review as a conference paper at ICLR 2021
Global quantisation (Q3): To prove (Q3), we start by giving two auxiliary inequalities. First, we
prove that ∣NF(x(t+1)) — r(t+1) k2 ≤ δR(t+1)∕2:
NN
RF(Xs)-r(t+1)k2 = kχ Vfi(X(M)- Xq(t+1)k2
i=1	i=1
N
≤ XkVfi(X(t+1)) - qi(t+1)k2
i=1
≤ NδR(t+1)∕(2N) = δR(t+1)/2 .
Next, we want to prove ∣∣r(t+1) 一 q(t+1) k2 ≤ δR(t+1)∕2. Again, it is sufficient to show ∣∣r(t+1) 一
q(t) ∣∣2 ≤ (1 + δ∕2)R(t+1), as the claim then follows from the definition of q(t+1) and Corollary 10.
We have
∣r(t+1) - qi(t)∣2 = ∣r(t+1) +VF(X(t+1)) - VF(X(t+1)) +VF(X(t)) -VF(X(t)) - q(t)∣2
≤ ∣r(t+1) - VF(X(t+1))∣2 + ∣VF(X(t+1)) - VF (X(t))∣2 + ∣VF (X(t)) - q(t)∣2
≤ δR(t+1)∕2 + β∣∣x(t+1) - X⑴ ∣2 + δR㈤
≤ δR(t+1)∕2 + R(t+1) = (1 + δ∕2)R(t+1),
where the last inequality follows from the argument used in the proof of (Q2).
Finally, putting things together, we have
∣VF(X(t+1)) - q(t+1)∣2 = ∣VF(X(t+1)) - r(t+1) + r(t+1) -q(t+1)∣2
≤ ∣VF(X(t+1)) - r(t+1)∣2 + ∣r(t+1) - q(t+1)∣2
≤ δR(t+1)∕2 + δR(t+1)∕2 = δR(t+1),
completing the proof.	□
Lemma 15. For any ε > 0 and t ≥ 2κ log W^, we have ∣∣x(t) — x*∣ ≤ ε.
Proof. By Lemma 14, we have ∣∣x(t) — x*∣2 ≤ μtW = (1 — (1 — μ))tW ≤ e-(1-μ)tW. Assuming
t ≥ ⅛ log WF.we have
e-(1-μ)tW ≤ e-(1-μ)(1-μ)-1 log W/£W = elog £/WW = εW∕W = ε .
The claim follows by observing that ι-μ = 2κ by definition.	□
Communication cost. Finally, we analyse the distributed implementation described at the be-
ginning of this section, and analyse its total communication cost. Recall that we assume that the
parameters α and β are known to all nodes, so the parameters of the quantised gradient descent can
be computed locally, and use W = d1/2. Note that W is the only parameter depending on the input
domain, so the algorithm also applies for arbitrary convex domain D ⊆ Rd, setting W to be the
diameter of D.
Since δ < 1, we have by Lemma 10 that the each of the messages sent by the nodes has length at
most O(d log δ-1) bits. Assuming κ ≥ 2, we have
2κ
log δ 1 = log ɪ--ι ≤ log 8κ .
Since the nodes send a total of 2N messages of O(d log κ) bits each, the total communication cost of
a single round is O(N d log κ) bits.
To get ∣∣F(X(T)) - F(x*)∣∣2 ≤ ε, we need ∣x(T) - x*∣ ≤ (ε∕β)2. By Lemma 15, selecting
T = O(2κ log βw) is sufficient. Finally, using W = O(d1/2), we have that the total communication
cost of the optimisation is O(NdK log K log βd). For the transmission of the local function values
fi(XT), there are at most (β0d + 1)N∕ε possible values, so each node needs to send O (log βd∕ε)
bits.
17