Under review as a conference paper at ICLR 2021
DISENTANGLED GENERATIVE CAUSAL
REPRESENTATION LEARNING
Anonymous authors
Paper under double-blind review
ABSTRACT
This paper proposes a Disentangled gEnerative CAusal Representation (DEAR)
learning method. Unlike existing disentanglement methods that enforce indepen-
dence of the latent variables, We consider the general case where the underlying
factors of interests can be causally correlated. We show that previous methods
with independent priors fail to disentangle causally correlated factors. Motivated
by this finding, we propose a new disentangled learning method called DEAR that
enables causal controllable generation and causal representation learning. The key
ingredient of this new formulation is to use a structural causal model (SCM) as the
prior for a bidirectional generative model. The prior is then trained jointly with
a generator and an encoder using a suitable GAN loss incorporated with super-
vision. Theoretical justification on the proposed formulation is provided, which
guarantees disentangled causal representation learning under appropriate condi-
tions. We conduct extensive experiments on both synthesized and real datasets to
demonstrate the effectiveness of DEAR in causal controllable generation, and the
benefits of the learned representations for downstream tasks in terms of sample
efficiency and distributional robustness.
1	INTRODUCTION
Consider the observed data X from a distribution qχ on X ⊆ Rd and the latent variable Z from
a prior Pz on Z ⊆ Rk. In bidirectional generative models (BGMs), we are normally interested
in learning an encoder E : X → Z to infer latent variables and a generator G : Z → X to
generate data, to achieve both representation learning and data generation. Classical BGMs include
Variational Autoencoder (VAE) (Kingma & Welling, 2014) and BiGAN (Donahue et al., 2017). In
representation learning, it was argued that an effective representation for downstream learning tasks
should disentangle the underlying factors of variation (Bengio et al., 2013). In generation, it is highly
desirable if one can control the semantic generative factors by aligning them with the latent variables
such as in StyleGAN (Karras et al., 2019). Both goals can be achieved with the disentanglement of
latent variable z, which informally means that each dimension of Z measures a distinct factor of
variation in the data (Bengio et al., 2013).
Earlier unsupervised disentanglement methods mostly regularize the VAE objective to encourage
independence of learned representations (Higgins et al., 2017; Burgess et al., 2017; Kim & Mnih,
2018; Chen et al., 2018; Kumar et al., 2018). Later, Locatello et al. (2019) show that unsupervised
learning of disentangled representations is impossible: many existing unsupervised methods are
actually brittle, requiring careful supervised hyperparameter tuning or implicit inductive biases. To
promote identifiability, recent work resorts to various forms of supervision (Locatello et al., 2020b;
Shu et al., 2020; Locatello et al., 2020a). In this work, we also incorporate supervision on the
ground-truth factors in the form stated in Section 3.2.
Most of these existing methods are built on the assumption that the underlying factors of variation
are mutually independent. However, in many real world cases the semantically meaningful factors of
interests are not independent (Bengio et al., 2020). Instead, semantically meaningful high-level vari-
ables are often causally correlated, i.e., connected by a causal graph. In this paper, we prove formally
that methods with independent priors fail to disentangle causally correlated factors. Motivated by
this observation, we propose a new method to learn disentangled generative causal representations
called DEAR. The key ingredient of our formulation is a structured causal model (SCM) (Pearl et al.,
1
Under review as a conference paper at ICLR 2021
2000) as the prior for latent variables in a bidirectional generative model. With some background
knowledge on the binary causal structure, the causal prior is then learnedjointly with a generator and
an encoder using a suitable GAN (Goodfellow et al., 2014) loss. We establish theoretical guarantees
for DEAR to learn disentangled causal representations under appropriate conditions.
An immediate application of DEAR is causal controllable generation, which can generate data from
any desired interventional distributions of the latent factors. Another useful application of disen-
tangled representations is to use such representations in downstream tasks, leading to better sample
complexity (Bengio et al., 2013; Scholkopf et al., 2012). Moreover, it is believed that causal disen-
tanglement is invariant and thus robust under distribution shifts (Scholkopf, 2019; Arjovsky et al.,
2019). In this paper, we demonstrate these conjectures in various downstream prediction tasks for
the proposed DEAR method, which has theoretically guaranteed disentanglement property.
We summarize our main contributions as follows:
•	We formally identify a problem with previous disentangled representation learning methods using
the independent prior assumption, and prove that they fail to disentangle when the underlying
factors of interests are causally correlated.
•	We propose a new disentangled learning method, DEAR, which integrates an SCM prior into a
bidirectional generative model, trained with a suitable GAN loss.
•	We provide theoretical justification on the identifiability of the proposed formulation.
•	Extensive experiments are conducted on both synthesized and real data to demonstrate the effec-
tiveness of DEAR in causal controllable generation, and the benefits of the learned representations
for downstream tasks in terms of sample efficiency and distributional robustness.
2	Other related work
GAN-based disentanglement methods. Existing methods, including InfoGAN (Chen et al., 2016)
and InfoGAN-CR (Lin et al., 2020), differ from our proposed formulation mainly in two folds. First
they still assume an independent prior for latent variables, so suffer from the same problem with
previous VAE-based methods mentioned above. Besides, the idea of InfoGAN-CR is to encourage
each latent code to make changes that are easy to detect, which actually applies well only when
the underlying factors are independent. Second, InfoGAN as a bidirectional generative modeling
method further requires variational approximation apart from adversarial training, which is inferior
to the principled formulation in BiGAN and AGES (Shen et al., 2020) that we adopt.
Causality with generative models. CausalGAN (Kocaoglu et al., 2018) and a concurrent work
(Moraffah et al., 2020) of ours, are unidirectional generative models (i.e., a generative model that
learns a single mapping from the latent variable to data) that build upon a cGAN (Mirza & Osin-
dero, 2014). They assign an SCM to the conditional attributes while leave the latent variables as
independent Gaussian noises. The limit of a CGAN is that it always requires full supervision on
attributes to apply conditional adversarial training. And the ground-truth factors are directly fed into
the generator as the conditional attributes, without an extra effort to align the dimensions between
the latent variables and the underlying factors, so their models have nothing to do with disentangle-
ment learning. Moreover their unidirectional nature makes it impossible to learn representations.
Besides they only consider binary factors whose consequent semantic interpolations appear non-
smooth, as shown in Appendix D. CausalVAE (Yang et al., 2020) assigns the SCM directly on the
latent variables, but built upon iVAE (Khemakhem et al., 2020), it adopts a conditional prior given
the ground-truth factors so is also limited to fully supervised setting.
3	PROBLEM SETTING
3.1	Generative model
We first describe the probabilistic framework of disentangled learning with supervision. We follow
the commonly assumed two-step data generating process that first samples the underlying generative
factors, and then conditional on those factors, generates the data (Kingma & Welling, 2014). Dur-
ing the generation process, the generator induces the generated conditional pg(x∣z) and generated
joint distribution PG(x, Z) = Pz(z)pg(x∣z). During the inference process, the encoder induces the
encoded conditional qE (z∣x) which can be a factorized Gaussian and the encoded joint distribution
2
Under review as a conference paper at ICLR 2021
qE(x, Z) = qχ(x)qE(z|x). We consider the following objective for generative modeling:
Lgen = Dkl (qE (x,z),PG (x,z)),	(1)
which is shown to be equivalent to the evidence lower bound used in VAEs UP to a constant, and
allows a closed form only with factorized Gaussian prior, encoder and generator (Shen et al., 2020).
Since constraints on the latent space are required to enforce disentanglement, it is desired that the
distribution family of qE(x,z) and Pg(x, z) should be large enough, especially for complex data
like images. Normally more general implicit distributions are favored over factorized Gaussians in
terms of expressiveness (Karras et al., 2019; Mescheder et al., 2017). Then minimizing (1) requires
adversarial training, as discussed detailedly in Section 4.3.
3.2	Supervised REGULARIZER
To guarantee disentanglement, we incorporate supervision when training the BGM, following the
similar idea in Locatello et al. (2020b) but with a different formulation. Specifically, let ξ ∈ Rm
be the underlying ground-truth factors of interests of x, following distribution pξ, and yi be some
continuous or discrete observation of the underlying factor ξi satisfying ξi = E(y∕x) for i =
1 ,...,m. For example, in the case of human face images, yi can be the binary label indicating
whether a person is young or not, and ξι = E(yι∣x) = P(yi = 1|x) is the probability of being
young given one image x.
Let E(x) be the deterministic part of the stochastic transformation E(x), i.e., E(X) = E(E(X) |x),
which is used for representation learning. We consider the following objective:
L(E,G) = Lgen(E,G) + λLsup(E),	⑵
where Lsup = Em=I Eχ,y [CE(Ei(x),yi)[ if yi is the binary or bounded continuous label of the i-th
factor ξi, where CE(l,y) = y log σ(l) + (1 - y)log(1 - σ(l)) is the cross-entropy loss with σ(∙)
being the sigmoid function; Lsup = Em=I Eχ,y [Ei(x) — yi]2 if yi is the continuous observation of
ξi, and λ > 0 is the coefficient to balance both terms. We empirically find the choice of λ quite
insensitive to different tasks and datasets, and hence set λ = 5 in all experiments. Estimating of
Lgen requires the unlabelled dataset {x1,...,xn} while estimating Lsup requires a labeled dataset
{(Xj ,yj) : j = 1 ,...,Ns } where Ns can be much smaller than N.
In contrast, Locatello et al. (2020b) propose the regularizer Lsup = Em=I Eχ,z[CE(EEi(x), Zi)[ in-
volving only the latent variable Z which is a part of the generative model, without distinguishing
from the ground-truth factor ξ and its observation y. Hence they do not establish any theoretical jus-
tification on disentanglement. Besides, they adopt a VAE loss for Lgen with an independent prior,
which suffers from the unidentifiability problem described in the next section.
3.3	UNIDENTIFIABILITY WITH AN INDEPENDENT PRIOR
Intuitively, the above supervised regularizer aims at ensuring some alignment between factor ξ and
latent variable z. We start with the definition of a disentangled representation following this intuition.
Definition 1 (Disentangled representation). Given the underlying factor ξ ∈ Rm of data X, a deter-
ministic encoder E is said to learn a disentangled representation with respect to ξ if ∀i = 1 ,...,m,
there exists a 1-1 function gi such that Ei(X) = gi(ξi). Further, a stochastic encoder E is said to be
disentangled wrt ξ If its deterministic part E(x) is disentangled wrt ξ.
As stated above, we consider the general case where the underlying factors of interests are causally
correlated. Then the goal becomes to disentangle the causal factors. Previous methods mostly use an
independent prior for z, which contradicts with the truth. We make this formal through the following
proposition, which indicates that the disentangled representation is generally unidentifiable with an
independent prior.
Proposition 1. Let E* be any encoder that is disentangled wrt ξ. Let b* = LsuP (E*), a =
minG Lgen(E*,G), and b = min{(E,G)：Lgen=0} LsuP(E). Assume the elements of ξ are con-
nected by a causal graph whose adjacency matrix A° is not a zero matrix. Suppose the prior
Pz is factorized, i.e., Pz(z) = ∩k=ι Pi(Zi). Then we have a > 0, and either when b* ≥ b or
b* < b and λ < b-a^ , there exists a solution (E',G') such that for any generator G, we have
L(E',G') < L(E*,G).
3
Under review as a conference paper at ICLR 2021
All proofs are given in Appendix A. This proposition directly suggests that minimizing (2) favors
the solution (E', G') over one with a disentangled encoder E*. Thus, with an independent prior We
have no way to identify the disentangled solution with λ that is not large enough. However, in real
applications it is impossible to estimate the threshold, and too large λ makes it difficult to learn the
BGM. In the following section we propose a solution to this problem.
4	Causal disentanglement learning
4.1	Generative model with A causal prior
We propose to use a causal model as the prior Pz. Specifically we use the generalized nonlinear
Structural Causal Model (SCM) proposed by Yu et al. (2019) as follows
Z = f((I - AT)Th(e)):= Fe (e),	(3)
where A is the weighted adjacency matrix of the directed acyclic graph (DAG) upon the k elements
of z (i.e., Aij = 0 if and only if Zi is the parent of Zj), e denotes the exogenous variables following
N(0, I), f and h are element-wise nonlinear transformations, and β = (f,h, A) denotes the set
of parameters of f, h and A, with the parameter space B. Further let 1a = I(A = 0) denote the
corresponding binary adjacency matrix, where I is the element-wise indicator function.
When f is invertible, (3) is equivalent to
f-1(z) = ATfT(Z) + h(e)	(4)
which indicates that the factors Z satisfy a linear SCM after nonlinear transformation f, and enables
interventions on latent variables as discussed later. The model structure is presented in Figure 1.
Note that different from our model where Z is the latent variable following the prior (3) with the goal
of causal disentanglement, Yu et al. (2019) proposed a causal discovery method where variables Z
are observed with the aim of learning the causal structure among z.
Inference
Generation
e
（SCM）
X
Z-k
Data
Encoder
Latent
Generator ≡--XC
Data
Figure 1:	Model structure of a bidirectional generative model (BGM) with an SCM prior.
In causal structure learning, the graph is required to be acyclic. Zheng et al. (2018) propose an
equality constraint whose satisfaction ensures acyclicity and solve the problem with augmented
Lagrangian method, which however leads to optimization difficulties (Ng et al., 2020). In this paper,
to avoid dealing with the non-convex constraint but focus on disentangling, we assume to have
some prior knowledge of the binary causal structure. Specifically, we assume the super-graph of
the true binary graph 1a* is given, the best case of which is the true graph while the worst is that
only the causal ordering is available. Then we learn the weights of the non-zero elements of the prior
adjacency matrix that indicate the sign and scale of causal effects, jointly with other parameters using
the formulation and algorithm described in later sections. To incorporate structure learning methods
and jointly learn the structure from scratch with guarantee of identifiability could be explored in
future work. An ablation study is done in Appendix B regarding this prior knowledge.
To enable causal controllable generation, we use invertible f and h and describe the mechanism to
generate images from interventional distributions of latent variables. Note that interventions can be
formalized as operations that modify a subset of equations in (4) (Pearl et al., 2000). Suppose we
would like to intervene on the i-th dimension of z, i.e., Do(z, = c), where C is a constant. Once we
have latent factors Z inferred from data x, i.e., Z = E(x), or sampled from prior Pz, we follow the
intervened equations in (4) to obtain z' on the left hand side using ancestral sampling by performing
(4) iteratively. Then we decode the intervened latent factor z' to generate the sample G(z'). In
Section 5.1 we define the two types of interventions of most interests in applications.
Another issue of the model is the latent dimension, to handle which we propose the so-called com-
posite prior. Recall that m is the number of generative factors that we are interested to disentangle,
4
Under review as a conference paper at ICLR 2021
e.g., all the semantic concepts related to some field, where m tends to be smaller than the total num-
ber M of generative factors. The latent dimension k of the generative model should be no less than
M to allow a sufficient degree of freedom in order to generate or reconstruct data well. Since M is
generally unknown in reality, We set a sufficiently large k, at least larger than m which is a trivial
lower bound of M. The role of the remaining k - m dimensions is to capture other factors necessary
for generation whose structure is not cared or explicitly modeled. Then we propose to use a prior
that is a composition of a causal model for the first m dimensions and another distribution for the
other k — m dimensions to capture other factors necessary for generation, like a standard Gaussian.
4.2	Formulation and identifiability of disentanglement
In this section, we present the formulation of DEAR and establish the theoretical justification of it.
Compared with the BGM described in Section 3.1, here we have one more module to learn that is
the SCM prior. Thus Pg(x, Z) becomes Pg,f(x, Z) = PF(z)pg(x∣z) where PF(Z) or pβ(Z) denotes
the marginal distribution of Fe (E) with E 〜N(0, I). We then rewrite the generative loss as follows
Lgen(E,G,F ) = Dkl(qe (x,z),PG,F (x,z)).	(5)
Then we propose the following formulation to learn causal generative causal representations:
min L(E,G, F):= Lgen(E,G,F) + λLsup(E).	(6)
E,G,F	J	'
In order to achieve causal disentanglement, we make two assumptions on the causal model. Assump-
tion 1 supposes a sufficiently large capacity of the SCM in (3) to contain the underlying distribution
Pξ, which is reasonable due to the generalization of the nonlinear SCM. Assumption 2 states the
identifiability of the true causal structure 1a° of ξ, which is applicable given the true causal order-
ing under basic Markov and causal minimality conditions (Pearl, 2014; Zhang & Spirtes, 2011).
Assumption 1 (SCM capacity). The underlying distribution pξ belongs to the distribution family
{pβ : β ∈ B}, i.e., there exits βo = (fo, h0, A°) such thatpξ = pβo.
Assumption 2 (Structure identifiability). For all β = (f, h, A) ∈ B with Pe = pβo, it holds that
1A = 1Ao.
The following theorem then guarantees that under appropriate conditions the DEAR formulation can
learn the disentangled representations defined in Definition 1.
Theorem 1. Assume the infinite capacity Of E and G. Further under Assumption 1-2, DEAR for-
mulation (6) learns the disentangled encoder E*. Specifically, we have gi(ξi) = σ-1(ξi) if CE loss
is used for the supervised regularizer, and gi(ξi) = ξi if L? loss is used.
Note that the identifiability we establish in this paper differs from some previous work on the pa-
rameter identifiability, e.g., Khemakhem et al. (2020). We argue that to learn disentangled repre-
sentations, the form in Definition 1, i.e., the existence but not the uniqueness of gis, is sufficient
to identify the relation among the representations and the data. In contrast, parameter identifiability
may not be achievable in many cases like over-parametrization. Thus the identifiability discussed
here is more realistic in terms of the goal of disentangling. Later we provide empirical evidence to
support the theory directly through the application in causal controllable generation.
4.3	Algorithm
In this section we propose the algorithm to solve the formulation (6). The SCM prior PF (z) and
implicit generated conditional pg(x∣z) make (5) lose an analytic form. Hence we adopt a GAN
method to adversarially estimate the gradient of (5). We parametrize Eφ(x) and Gθ (z) by neural
networks. Different from Shen et al. (2020), the prior also involves learnable parameters. We present
in the following lemma the gradient formulas of (5).
LemmaL Let r(x,z) = q(x,z)∕p(x,z) and D(x,z) = log r(x,z). Then we have
Vθ Lgen = -Ez~pβ (z)[s(x,z)VχD(x,z)τ∣χ = Gθ (z)Vθ Gθ(z)],
P φ Lgen = Eχ~qχRz D(x,z)τ∣z = Eφ(x)VφEφ(x)],	(7)
▽eLgen = -EJs(x, z)(VχD(x, z)τVβG(Fe(e)) + NzD(x, Z)T%Fe(e))∣X=GeFe吗，
where s(x,z) = eD(x,z) is the scaling factor.
5
Under review as a conference paper at ICLR 2021
We then estimate the gradients in (7) by training a discriminator Dψ via empirical logistic regression:
minΨ'[ ∣⅛ Σ(x,z)∈Se log(1 + e-Dψ, (x,z)) + ∣⅛i Σ(x,z)∈S9 log(1 + eDψ'(x,Z))], where Se and Sg
are finite samples from Qe (x, z) and PG (x, z) respectively, leading to a GAN approach.
Based on above, We propose Algorithm 1 to learn disentangled generative causal representation.
Algorithm 1: Disentangled gEnerative cAusal Representation (DEAR) Learning
Input: training set {xι,..., XN, yι,..., yNs}, initial parameters φ, θ, β, ψ, batch-size
n
while not convergence do
1
2
3
4
5
6
7
8
9
10
for multiple steps do
Sample {xι,..., Xn} from the training set, {6ι,..., en,} from N(0, I)
Generate from the causal prior Zi = Fe &),i = 1,...n
Update ψ by descending the stochastic gradient:
1 ∑n=1 Vψ
+ e-Dψ 3i,EΦ(Xi)))+log(1 +
eD ψ (Ge(Zi),Zi))]
Sample {xι,.. . ,Xn,yι,... ,yns}, {βι,..., βn} as above; generate Zi = Fe(/)
Compute θ-gradient: - 1 £乙 s(Gθ(zi),Zi)RθDψ(Gθ(zi),zi)
Compute φ-gradient: 1 £鼠 VφDψ(xi,Eφ(xi)) + / En=I vΦLsup(Φ; Xi,yi)
Compute β-gradient: -1 Ei=ι S(G(Zi),ZiNeDψ(Gθ(Fe(ei)),Fβ(G))
Update parameters φ, θ, β using the gradients
Return: φ, θ, β
Remark: without loss of generality, assume the first Ns samples in the training set and the first
ns samples in each mini-batch has available labels; ns may vary across different iterations.
5 Experiments
We evaluate our methods on two datasets. The first one is a synthesized dataset Pendulum similar
to the one in Yang et al. (2020). As shown in Figure 3, each image is generated by four contin-
uous factors: Pendulum-angle, lightjangle, shadow Jength and shadow _position whose underlying
structure is given in Figure 2(a) following physical mechanisms. To make the dataset realistic, we
introduce random noises when generating the two effects from the causes, representing the mea-
surement error. We further introduce 20% corrupted data whose shadow is randomly generated,
mimicking some environmental disturbance. The sample sizes for training, validation and test Set
are all 6,724.1
The second one is a real human face dataset CelebA (Liu et al., 2015), containing 202,599 images
with 40 labelled binary attributes. Among them we consider two groups of causally correlated
factors shown in 2(b,c). We believe these two datasets are diverse enough to assess our methods. All
the details of experimental setup and architectures are given in Appendix C.
(c) CelebA-Attractive
(a) Pendulum	(b) CelebA-Smile
Figure 2:	Underlying causal structures.
5.1	Controllable generation
We first investigate the performance of our methods in disentanglement through applications in
causal controllable generation (CG). Traditional CG methods mainly manipulate the independent
generative factors (Karras et al., 2019), while we consider the general case where the factors are
causally correlated. With a learned SCM as the prior, we are able to generate images from any
desired interventional distributions of the latent factors. For example, we can manipulate only the
1The Pendulum dataset will be released as a causal disentanglement benchmark soon.
6
Under review as a conference paper at ICLR 2021
cause factor while leave its effects unchanged. Besides, the BGM framework enables controllable
generation either from scratch or a given unlabeled image.
We consider two types of intervention. In traditional traversals, We manipulate one dimension of the
latent vector while keep the others fixed to either their inferred or sampled values (Higgins et al.,
2017). A causal view of such operations is an intervention on all the variables by setting them as
constants with only one of them varying. Another interesting type of interventional distribution is
to intervene on only one latent variable, i.e., Pdo(Zi=c) (z). The proposed SCM prior enables us to
conduct such intervention though the mechanism given in Section 4.1.
Figure 3-4 illustrate the results of causal controllable generation of the proposed DEAR and the
baseline method with an independent prior, S-β-VAE (Locatello et al., 2020b). Results from other
baselines including S-TCVAE, S-FactorVAE (which essentially make no difference due to the inde-
pendence assumption) and CausalGAN are given in Appendix D. Note that we do not compare with
unsupervised disentanglement methods because of fairness and their lack of justification.
In each figure, we first infer the latent representations from a test image in block (c). The traditional
traversals of two models are given in blocks (a,b). We see that in each line when manipulating one
latent dimension, the generated images from our model vary only in a single factor, indicating that
our method can disentangle the causally correlated factors. It is worth pointing out that we are the
first to achieve the disentanglement between the cause and its effects, while other methods tend to
entangle them. In block (d), we show the results of intervention on the latent variables representing
the cause factors, which clearly show that intervening on a cause variable changes its effect variables.
Results in Appendix D further show that intervening on an effect node does not influence its cause.
Since the underlying factors are causally correlated, all previous quantitative metrics for disentan-
glement no longer apply. We provide more qualitative traversals in Appendix D to show the overall
performance. A quantitative metric for causal disentanglement is worth exploring in future work.
Figure 3: Results of causal controllable generation on Pendulum.
Figure 4: Results of causal controllable generation on CelebA.
7
Under review as a conference paper at ICLR 2021
Table 1: Sample efficiency and test accuracy with different training sample sizes. DEAR-lin and -nlr denote
the model with linear and nonlinear f. Line 1 is unsupervised; 2-3 are semi-supervised; others are supervised.
(a) CelebA				(b) Pendulum		
Method	100(%)	10,000(%)	Eff(%)	100(%)	all(%)	Eff(%)
ResNet	68.06±o.i9	79.51±0.3i	85.59±o.27	79.71±o.98	90.64±i.57	87.97±2.ii
DEAR-Iin-10%	78.09±o.59	79.54±o.4i	98.18±o.49	88.93±i.40	93.18±o.i8	95.43±i.33
DEAR-nlr-10%	80.30±0.24	80.87±o.i2	99∙29±o.23	87.65±o.46	91.27±o.2i	96.03±o.29
ResNet-pretrain	76.84±2.o8	83.75±o.93	91.74±i.98	79.59±o.93	89.16±i.60	89.28±o.59
S-VAE	77.07±i.42	79.87±i.67	96.49±i.68	84.16±o.69	90.89±o.28	92.60±o.49
S-β-VAE	71.78±i.99	76.63±o.24	93.67±2.4i	79.95±i.65	87.87±o.52	90.98±i.47
S-TC-VAE	77.10±2.o8	81.63±o.20	94.45±2.72	85.36±ι.ιι	90.33±o.33	94.51±ι.3i
DEAR-lin	83.51±o.77	84.92±o.ii	98.34±0.8i	90.21 ±0.94	93.31±o.i4	96.68±o.89
DEAR-nlr	84.44±o.48	85.10±o.09	99∙23±o.5i	90.62±o.32	92.57±o.08	97∙93±o.29
5.2	Downstream task
The previous section verifies the good disentanglement performance of DEAR. In this section,
equipped with DEAR, We investigate and demonstrate the benefits of learned disentangled causal
representations in sample efficiency and distributional robustness.
We state the downstream tasks. On CelebA, we consider the structure CelebA-Attractive in Fig-
ure 2(c). We artificially create a target label T = 1 if young =1, gender=0, receding -hairline=0,
make工P =1, chubby=0, eye Jbag=0, and T = 0 otherwise, indicating one kind of attractiveness as a
slim young woman with makeup and thick hair.2 On the pendulum dataset, we regard the label of
data corruption as the target T, i.e., T = 1 if the data is corrupted and T = 0 otherwise. We consider
the downstream tasks of predicting the target label. In both cases, the factors of interests in Figure
2(a,c) are causally related to T, which are the features that humans use to do the task. Hence it is
conjectured that a disentangled representation of these causal factors tends to be more data efficient
and invariant to distribution shifts.
5.2.1	Sample efficiency
For a BGM including the previous state-of-the-art supervised disentangling methods S-VAEs (Lo-
catello et al., 2020b) and DEAR, we use the learned encoder to embed the training data to the latent
space and train a MLP classifier on the representations to predict the target label. Without an en-
coder, one normally needs to train a convolutional neural network with raw images as the input.
Here we adopt the ResNet50 as the baseline classifier which is the architecture of the BGM encoder.
Since disentangling methods use additional supervision of the generative factors, we consider an-
other baseline that is pretrained using multi-label prediction of the factors on the same training set.
To measure the sample efficiency, we use the statistical efficiency score defined as the average test
accuracy based on 100 samples divided by the average accuracy based on 10,000/all samples, fol-
lowing Locatello et al. (2019). Table 1 presents the results, showing that DEAR owns the highest
sample efficiency on both datasets. ResNet with raw data inputs has the lowest efficiency, although
multi-label pretraining improves its performance to a limited extent. S-VAEs have better efficiency
than the ResNet baselines but lower accuracy under the case with more training data, which we think
is mainly because the independent prior conflicts with the supervised loss as indicated in Proposition
1, making the learned representations entangled (as shown in the previous section) and less infor-
mative. Besides, we also investigate the performance of DEAR under the semi-supervised setting
where only 10% of the labels are available. We find that DEAR with fewer labels has comparable
sample efficiency with that in the fully supervised setting, with a sacrifice in accuracy that is yet still
comparable to other baselines with more supervision.
2Note that the definition of attractiveness here only refers to one kind of attractiveness, which has nothing
to do with the linguistic definition of attractiveness.
8
Under review as a conference paper at ICLR 2021
Table 2: Distributional robustness. The worst-case and average test accuracy
(a) CelebA	(b) Pendulum
Method	WorstAcc(%)	AvgAcc(%)	WorstAcc(%)	AvgAcc(%)
ResNet	59.12±i.78	82.12±o.26	60.48±2.73	87.40±o.89
DEAR-Iin-10%	-71.40±o.47-	^^81.04±o.i4	63.93±i.33-	^^89.70±o.63
DEAR-nlr-10%	70.44±i.02	81.94±o.3i	65.59±i.90	90.19±0.63
ReSNet-multi	~^59.17±4.o2^^	^^82.05±o.25	61.70±4.o2^^	^^87.20±i.oo
S-VAE	60.54±3.48	79.51±o.58	20.78±4.45	84.26±ι.3i
S-β-VAE	63.85±2.09	80.82±o.i9	44.12±9.73	86.99±i.78
S-TC-VAE	64.93±3.30	81.58±o.i4	35.50±5.57	86.64±ι.i5
DEAR-lin	76.05±o.70	83.56±o.09	74∙95±i.26	93.61±o.i3
DEAR-nlr	71.37±o.66	83.81±o.08	72.48±o.74	93.11±o.i4
5.2.2	Distributional robustness
We manipulate the training data to inject spurious correlations between the target label and some
spurious attributes. On CelebA, We regard mouthqpen as the spurious factor; on Pendulum, We
choose background^color ∈ {blue(+), white(-)}. We manipulate the training data such that the
target label is more strongly correlated with the spurious attributes, i.e., the target label and the
spurious attribute of 80% of the examples are both positive or negative, while those of 20% examples
are opposite. For example, in the manipulated training set, 80% smiling examples in CelebA have
an open mouth; 80% corrupted examples in Pendulum are masked with a blue background. The test
set however does not have these correlations, leading to a distribution shift.
Intuitively these spurious attributes are not causally correlated to the target label, but normal in-
dependent and identically distributed (IID) based methods like empirical risk minimization (ERM)
tend to exploit these easily learned spurious correlations in prediction, and hence face performance
degradation when the such correlation no longer exists during test. In contrast, causal factors are
regarded invariant and thus robust under such shifts. Previous sections justify both theoretically and
empirically that DEAR can learn disentangled causal representations. We then apply those represen-
tations by training a classifier upon them, which is conjectured to be invariant and robust. Baseline
methods include ERM, multi-label ERM to predict target label and all the factors considered in dis-
entangling to have the same amount of supervision, and S-VAEs that can not disentangle well in the
causal case.
Table 2 shows the average and worst-case (Sagawa et al., 2019) test accuracy to assess both the over-
all classification performance and distributional robustness, where we group the test set according
to the two binary labels, the target one and the spurious attribute, into four cases and regard the one
with the worst accuracy as the worst-case, which usually owns the opposite correlation to the train-
ing data. We see that the classifiers trained upon DEAR representations outperform the baselines
in both metrics. Particularly, when comparing the worst-case accuracy with the average one, we
observe a slump from around 80 to around 60 for other methods on CelebA, while DEAR enjoys
an acceptable small decline. These results support the above conjecture and the benefits of causal
disentanglement in distributional robustness.
6 Conclusion
This paper showed that previous methods with the independent latent prior assumption fail to learn
disentangled representation when the underlying factors of interests are causally correlated. We then
proposed a new disentangled learning method called DEAR with theoretical guarantees. Extensive
experiments demonstrated the effectiveness of DEAR in causal generation, and the benefits of the
learned representations for downstream tasks.
REFERENCES
Martin Arjovsky, Leon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization.
arXiv preprint arXiv:1907.02893, 2019.
9
Under review as a conference paper at ICLR 2021
Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new
perspectives. IEEE transactions on pattern analysis and machine intelligence, 35(8):1798-1828,
2013.
Yoshua Bengio, Tristan Deleu, NaSim Rahaman, Rosemary Ke, SebaStien Lachapelle, Olexa Bila-
niuk, Anirudh Goyal, and Christopher PaL A meta-transfer objective for learning to disentangle
causal mechanisms. In ICLR, 2020.
Christopher P Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nicholas Watters, Guillaume Des-
jardins, and Alexander Lerchner. Understanding disentangling in beta-vae. NIPS Workshop of
Learning Disentangled Features, 2017.
Tian Qi Chen, Xuechen Li, Roger B. Grosse, and David K. Duvenaud. Isolating sources of disen-
tanglement in variational autoencoders. In NeurIPS, 2018.
Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan:
Interpretable representation learning by information maximizing generative adversarial nets. In
Advances in neural information processing systems, pp. 2172-2180, 2016.
Jeff Donahue, Philipp Krahenbuhl, and Trevor Darrell. Adversarial feature learning. In ICLR, 2017.
Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Alex Lamb, Martin Arjovsky, Olivier Mastropi-
etro, and Aaron C. Courville. Adversarially learned inference. In ICLR, 2017.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural infor-
mation processing systems, pp. 2672-2680, 2014.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778,2016.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick,
Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a
constrained variational framework. In ICLR, 2017.
Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative
adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pp. 4401T410, 2019.
Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen. Variational autoen-
coders and nonlinear ica: A unifying framework. In International Conference on Artificial Intel-
ligence and Statistics, pp. 2207-2217, 2020.
Hyunjik Kim and Andriy Mnih. Disentangling by factorising. In ICML, 2018.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In ICLR, 2014.
Murat Kocaoglu, Christopher Snyder, Alexandros G Dimakis, and Sriram Vishwanath. Causalgan:
Learning causal implicit generative models with adversarial training. In ICLR, 2018.
Abhishek Kumar, Prasanna Sattigeri, and Avinash Balakrishnan. Variational inference of disentan-
gled latent concepts from unlabeled observations. In ICLR, 2018.
Felix Leeb, Yashas Annadani, Stefan Bauer, and Bernhard Scholkopf. Structural autoencoders im-
prove representations for generation and transfer. arXiv preprint arXiv:2006.07796, 2020.
Zinan Lin, Kiran K Thekumparampil, Giulia Fanti, and Sewoong Oh. Infogan-cr and modelcentral-
ity: Self-supervised model training and selection for disentangling gans. In ICML, 2020.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild.
In Proceedings of the IEEE international conference on computer vision, pp. 3730-3738, 2015.
10
Under review as a conference paper at ICLR 2021
F. Locatello, S. Bauer, M. Lucic, G. Raetsch, S. Gelly, B. SchOlkopf, and O. Bachem. Chal-
lenging common assumptions in the UnsuPervised learning of disentangled representations. In
Proceedings of the 36th International Conference on Machine Learning (ICML), volume 97
of Proceedings of Machine Learning Research, pp. 4114-4124. PMLR, June 2019. URL
http://proceedings.mlr.press∕v97∕lOcatello19a.html.
Francesco Locatello, Ben Poole, Gunnar Ratsch, Bernhard Scholkopf, Olivier Bachem, and Michael
Tschannen. Weakly-supervised disentanglement without compromises. In ICML, 2020a.
Francesco Locatello, Michael Tschannen, Stefan Bauer, Gunnar Ratsch, Bernhard Scholkopf, and
Olivier Bachem. Disentangling factors of variation using few labels. In ICLR, 2020b.
Lars Mescheder, Sebastian Nowozin, and Andreas Geiger. Adversarial variational bayes: Unifying
variational autoencoders and generative adversarial networks. In Proceedings of the 34th Inter-
national Conference on Machine Learning-Volume 70, pp. 2391-2400. JMLR. org, 2017.
Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv preprint
arXiv:1411.1784, 2014.
Raha Moraffah, Bahman Moraffah, Mansooreh Karami, Adrienne Raglin, and Huan Liu. Can:
A causal adversarial network for learning observational and interventional distributions. arXiv
preprint arXiv:2008.11376, 2020.
Ignavier Ng, AmirEmad Ghassami, and Kun Zhang. On the role of sparsity and dag constraints for
learning linear dags. arXiv preprint arXiv:2006.10201, 2020.
Judea Pearl. Probabilistic reasoning in intelligent systems: networks ofplausible inference. Elsevier,
2014.
Judea Pearl et al. Models, reasoning and inference. Cambridge, UK: CambridgeUniversityPress,
2000.
Ali Razavi, Aaron van den Oord, and Oriol Vinyals. Generating diverse high-fidelity images with
vq-vae-2. In Advances in Neural Information Processing Systems, pp. 14866-14876, 2019.
Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust
neural networks for group shifts: On the importance of regularization for worst-case generaliza-
tion. arXiv preprint arXiv:^911.08731, 2019.
Bernhard Scholkopf. Causality for machine learning. arXiv preprint arXiv:1911.10500, 2019.
Bernhard Scholkopf, Dominik Janzing, Jonas Peters, Eleni Sgouritsa, Kun Zhang, and Joris Mooij.
On causal and anticausal learning. In ICML, 2012.
Xinwei Shen, Tong Zhang, and Kani Chen. Bidirectional generative modeling using adversarial
gradient estimation. arXiv preprint arXiv:2002.09161, 2020.
Rui Shu, Yining Chen, Abhishek Kumar, Stefano Ermon, and Ben Poole. Weakly supervised disen-
tanglement with guarantees. In ICLR, 2020.
Mengyue Yang, Furui Liu, Zhitang Chen, Xinwei Shen, Jianye Hao, and Jun Wang. Causalvae:
Structured causal disentanglement in variational autoencoder. arXiv preprint arXiv:2004.08697,
2020.
Yue Yu, Jie Chen, Tian Gao, and Mo Yu. Dag-gnn: Dag structure learning with graph neural
networks. In ICML, 2019.
Han Zhang, Ian Goodfellow, Dimitris Metaxas, and Augustus Odena. Self-attention generative
adversarial networks. In International Conference on Machine Learning, pp. 7354-7363. PMLR,
2019.
Jiji Zhang and Peter Spirtes. Intervention, determinism, and the causal minimality condition. Syn-
these, 182(3):335-347, 2011.
11
Under review as a conference paper at ICLR 2021
Shengjia Zhao, Jiaming Song, and Stefano Ermon. Learning hierarchical features from generative
models. In ICML,2017.
Xun Zheng, Bryon Aragam, Pradeep K Ravikumar, and Eric P Xing. Dags with no tears: Continuous
optimization for structure learning. In Advances in Neural Information Processing Systems, pp.
9472-9483,2018.
12
Under review as a conference paper at ICLR 2021
APPENDIX A Proofs
A.1 Proof of Proposition 1
Proof. On one hand, by the assumption that the elements of ξ are connected by a causal graph whose
adjacency matrix is not a zero matrix. Then exist i = j such that ξi and ξj are not independent,
indicating that the probability density of ξ cannot be factorized. Since E* is disentangled wrt ξ,
by Definition 1, ∀i = 1,...,m there exists gi such that E* (x) = gi(ξi). This implies that the
probability density of E* (x) is not factorized.
On the other hand, notice that the distribution family of the latent prior is {pz : Pz is factorized}.
Hence the intersection of the marginal distribution families of Z and E*(x) is an empty set. Then
the joint distribution families of (x, E *(x)) and (G(z),z) also have an empty intersection.
We know that Lgen(E,G) = 0 implies qE(x,z) = Pg(x, z) which contradicts the above. Therefore,
We have a = minG Lgen(E*, G) > 0.
Let (E', G') be the solution of the optimization problem min{(E,G)：Lgen=0} LsuP(E). Then We have
L' = L(E', G') = λb, and L* = L(E*, G) ≥ a + λb* > λb* for any generator G. When b* ≥ b
We directly have L' < L*. When b* < b and λ is not large enough, i.e., λ < b-a^, We have
L' <L*.	□
A.2 Proof of Theorem 1
Proof. Assume E is deterministic.
On one hand, for each i = 1,...,m, first consider the cross-entropy loss
Lsup,i (E)
E(χ,y)
[CE(Ei(X),yi)] = /
p(x)p(y∕x)(yi log σ(Ei(x))+(1-yi )log(1-σ(Ei(x))))dxdyi,
where p(y∕x) is the probability mass function of the binary label yi given x, characterized by
P(yi = 1|x) = E(y∕x) and P(yi = 0|x) = 1 - E(y∕x). Let
∂⅛⅛ = ∕p(X)P(yi|x) (yiσ(Ei)(i-σ(Ei)) - T-⅛)) dxdyi = 0
Then we know that E* (x) = σ-1(E(y∕x)) = σ-1(ξi) minimizes Lsup,i.
Consider the L2 loss
Lsup,i(φ) = E(x,y)[Ei(x) - yi]2
/P(X)P(yi∣x)∣∣Ei(x) - yi∣∣2dxdyi.
Let
dLsup,i
∂Ei(x)
∕p(x)p(yi∣x)(Ei(x) - yi)dxdyi
0.
2
Then we know that E* (x) = E(yi∣x) = ξi minimizes Lsup,i in this case.
On the other hand, by Assumption 1 there exists βo = (f0,h0,A0) such that pξ = pβ0. Then the
distribution of E*(x) is given by pβ* with β* = (g ◦ f0,h0,A0). Assumption 2 ensures that there
is no β' = (f',h',A') such that A' = A° but pβ' = pβ*. Let F * = F0*. Further due to the
infinite capacity of G, we have the distribution family of Pg,f* (x, z) contains qE* (x, z). Then by
minimizing the loss in (6) over G, we can find G* such that Pg*,f* (x, z) matches qE* (x, z) and
thus Lgen(E*, G*,F*) reaches 0.
Hence minimizing L = Lgen + λLsup, which is the DEAR formulation (6), leads to the solution with
E* (x) = gi(ξi) with gi(ξi) = σ-1(ξi) if CE loss is used, and gi(ξi) = ξi if L2 loss is used, and the
true binary adjacency matrix.
For a stochastic encoder, we establish the disentanglement of its deterministic part as above, and
follow Definition 1 to obtain the desired result.	□
13
Under review as a conference paper at ICLR 2021
A.3 Proof of Lemma 1
We follow the same proof scheme as in Shen et al. (2020) where the only difference lies in the
gradient Wrt the prior parameter β. To make this paper self-contained, We restate some proof steps
here using our notations.
Let U ∙ Il denote the vector 2-norm. For a scalar function h(x,y), let Vxh(X,y) denote its gradient
with respect to x. For a vector function g(x, y), let Vxg(x, y) denote its Jacobi matrix with respect to
x. Given a differentiable vector function g(x) : Rk → Rk, we use V ∙ g(x) to denote its divergence,
defined as
V ∙ g(X) ：= G d[g(X) j
g(X)L 与 ∂[xj ,
where [x j denotes the j-th component of x. We know that
/ V ∙ g(x)dx = 0
for all vector function g(x) such that g(∞) = 0. Given a matrix function w(x) =
(w1(x),... ,wι(x)) : Rk → Rk×l where each Wi(X),i = 1 ...,l is a k-dimensional differentiable
vector function, its divergence is defined as V Tw(X) = (V TwI(X),..., V Twl(X)).
To prove Lemma 1, we need the following lemma which specifies the dynamics of the generator joint
distribution Pg(x, z) and the encoder joint distribution Pe(x, z), denoted by pθ(x, z) and pφ(x, z)
here.
Lemma 2. Using the definitions and notations in Lemma 1, we have
Vθpθ,β(x,z) = -VχPθ,β(x,z)Tgθ(x) - pθ,β(x,z)V ∙ gθ(x),
Vφqφ(x,z) = -Vzqφ(x,z)τeφ(z) - qφ(x,z)V ∙ eφ(z),
⑻
⑼
/洛小
VePθ,β(x,z) = Vxpθ,β(x,z)Tfe(x) - VzPθ,β(x,z)Tfe(z) -Pθ,β(x,z)V ∙ (%(z),	(10)
for all data X and latent variable Z, where gθ(Gθ(z, E)) = VθGθ(z, E), eφ(Eφ(x, E)) =
, , , .. , . ~ ,., ,... .., ,..
VφEφ(x, E), fβ(Fe(e)) = VeFe(e), and fβ(G(Fe(E))) = VeG(Fe(e)).
ProofofLemma 2. We only prove (10) which is the distinct part from Shen et al. (2020).
Let l be the dimension of parameter β. To simplify notation, let random vector Z = Fe (E) and
X = G(Z) ∈ Rd and Y = (X, Z) ∈ Rd+k, and let P be the probability density of Y. For each
i = 1,...,l, let ∆ = δei where eg is a l-dimensional unit vector whose i-th component is one and
all the others are zero, and δ is a small scalar. Let Z' = Fe+δ(e), X' = G(Z') and Y' = (X', Z')
so that Y' is a random variable transformed from Y by
Y' = Y +
f(X)))∆ + o(δ).
Let p' be the probability density of Y'. For an arbitrary y' = (X',z') ∈ Rd+k, let y' = y +
/Fjq、
(fβ(z))∆ + o(δ) and y = (x, z). Then we have
P'(y') = P(y)l det(dy'∕dy)∣-1
=p(y)l det(Id + (Vffl(x), Vfe(z))τ∆ + o(δ))∣-1
=P(y)(i + ∆τV ∙ (fe(x),fe(z))τ + o(δ))-1
=P(y)(i- ∆τV ∙(fe (x),fe (z))τ + o(δ))
=p(y) - ∆τp(y')V ∙ (fe(X′),fe(z'))τ + o(δ)
=P(y') - ∆τ(fe(x′),fe(z')) ∙ Vx‛p(x',z) - ∆τp(y')(V ∙ f⅛(x'), V ∙ fe(z'))τ + o(δ).
14
Under review as a conference paper at ICLR 2021
Since y' is arbitrary, above implies that
p'(x,z) = p(x,z) - ∆τ(fβ(x),fβ(Z)) ∙ Nχp(x,z), Vzp(x,z))T ∙ Vχp(x, z)
-∆τp(x,z)(V ∙ fβ (x'), V ∙ fβ(z'))τ + o(δ)
for all x ∈ Rd,z ∈ Rk and i = 1,...,l, leading to (10) by taking δ → 0, and noting that P = Pe
and p' = Pβ+∆. Similarly We can obtain (8) and (9).	□
Proof of Lemma 1. Recall the objective DκL(q,p) = ʃ q(x, z) log(p(x, z)∕q(x, z))dxdz. Denote
its integrand by l(q,p). Let I2(q,p) = ∂l(q,p)/∂p. We have
Ve l(q(x,z),p(x,z)) = 12 (q(x,z),p(x,z))Vβ Pθ,β (x,z)
where Vepθ,β (x, z) is computed in Lemma 2.
Besides, we have
Vx ∙ [I2(q,p)p(χ,z)fe(x)] = l2(q,p)p(χ,z)V ∙ fe(x)
'f
+12(q,p)Vχp(χ,z) ∙ fe (x)
‘—7 '
+ Vxl2(q,p)p(x,z)fe (x),
Vz ∙ [I2(q,p)p(x,z)fe(z)] = l2(q,p)p(x,z)V ∙ fe(Z)
+12(q,p)Vp(x,z) ∙ fe(z)
+ Vl2(q,p)p(x,z)fe (z).
Thus,
Ve Lgen = / Ve l(q(x,z),p(x,z))dxdz = / p(x,z)[Vχl2 (q,p)fe (x) + Vz I2(q,p)fe (z)]
where we can compute Vχl2(q,p) = s(x, z)VχD(x, z) and Vχl2(q,p) = s(x,z)VzD(x,z).
Hence
Ve Lgen = —E(x,z)~p(x,zJs(X,z)(VχD(x,z)Tfe (x) + Vz D(x, z)τfe (z))]
=-Ejs(X,z)(VχD(x,Z)TVe G(Fe (e)) + Vz D(x,z)TVeFe (e))∣X=G∕Fβ㈤)].
where the second equality follows reparametrization.	□
Lemma 3. For any a, b ∈ R (a < b), the set of continuous piece-wise linear function P is dense in
C [a, b] where the metric d(f, g) = Supx曰& 丛 |f (x) — g(x) |. Note that P is defined as
P = ∪h∈{(b-a)∕n∣n∈N+}Ph
{(b-a) /h-1
k +	Wi (x — a — ih) 1(x ≥ a + ih) Wi, k ∈ R > ,
i=0	,
where H here is floor function.
Proof. Since [a, b] is compact, any function f ∈ C [a, b] is uniform continuous, i.e., ∀e > 0, there
exists δ > 0 such that
|x - y| < δ =⇒ If(X)- f(y)| < “2∙
Let [a,b] = ∪N-1 [an,bn], and gn(x) be a linear function, such that
a，n = a + nh,
bn = a + (n + 1)h,
gn(an) = f (an),
gi(bn) = f (bn),
Nh = b — a.
15
Under review as a conference paper at ICLR 2021
Assume that h < δ. For any X ∈ [an,bn], we have
If(X)- gi(X)I ≤ Imin {If(X)- f (an)1 + Igi(X)- gi(On)Ijf(X)- Abn)I + Igi(X)- gi (bn)|}
≤ Igi (an) - gi(bn)I + min {If (x) - f (an)I, If (x) - f(bn)I}
≤ If (an) - f (bn) I + min {If (x) - f (an) I, If (X) - f (bn)I}
< e.
Thus,
SUP	If (x) - gn(X)I < &
x∈[an ,bn]
We define
N-1
g(X) = E gn(X)l(X ∈ [an,bn])
n=1
which is obvious that g(X) ∈ Ph ⊂ P. And We have
sup If (x) - g(X)I < e
x∈[a,b]
Therefore, P is dense in C [a, b] and Ph is e-dense.
□
APPENDIX B	Learning the structure
As mentioned in Section 4.1, our DEAR algorithm requires the prior knowledge on the super-graph
of the true graph over the underlying factors of interests. The experiments shown in the main text
are all based on the assumption that the true graph is given. In this section We investigate the
performance of the learned weighted adjacency matrix and present an ablation study on different
extents of prior knowledge on the structure.
B .1 Given THE TRUE graph
Figure 5 shows the learned weighted adjacency matrices when the true binary structure is given,
whose weights show sensible signs and scalings consistent with common knowledge. For example,
smile and its effect mouthqpen are positively correlated. The corresponding element in the weighted
adjacency A03 of (a) turns out positive, which makes sense. Also gender (the logit of male) and its
effect make-up are negatively correlated. Then A13 of (b) turns out negative.
B.2 Given the true causal ordering
Consider the Pendulum dataset, whose ground-truth structure is given in Figure 2(a). Consider
a causal ordering Pendulum-angle, lightjangle, shadow .position, ShadowJength, given which we
start with a full graph whose elements are randomly initialized around 0 as shown in Figure 6(a).
Figure 6 presents the adjacency matrices learned by DEAR at different training epochs, from which
we see that it eventually obtains the learned structure that nearly coincides with the one learned given
the true graph shown in Figure 5(c). This experiment shows the potential of DEAR to incorporate
structure learning methods to learn the latent causal structure from scratch, which will be explored
in future research.
(a) CelebA-Smile
(b) CelebA-Attractive
(c) Pendulum
Figure 5: Learned adjacency matrices for different underlying structures.
16
Under review as a conference paper at ICLR 2021
APPENDIX C	Implementation details
In this section We state the details of experimental setup and the network architectures used for all
experiments.
Preprocessing and hyperparameters. We pre-process the images by taking a center crops of
128 × 128 for CelebA and resizing all images in CelebA and Pendulum to the 64 × 64 resolution.
We adopt Adam with βι = 0, β2 = 0.999, and a learning rate of 1 × 10-4 for D, 5 × 10-5 for E, G
and F, and 1 × 10-3 for the adjacency matrix A. We use a mini-batch size of 128. For adversarial
training in Algorithm 1, we train the D once on each mini-batch. The coefficient λ of the supervised
regularizer is set to 5. We use CE supervised loss for both CelebA with binary observations of the
underlying factors and Pendulum with bounded continuous observations. Note that L2 loss works
comparable to CE loss on Pendulum. In downstream tasks, for BGMS with an encoder, we train a
two-level MLP classifier with 100 hidden nodes using Adam with a learning rate of 1 × 10-2 and a
mini-batch size of 128. Models were trained for around 150 epochs on CelebA and 600 epochs on
Pendulum on NVIDIA RTX 2080 Ti.
Network architectures. We follow the architectures used in Shen et al. (2020). Specifically, for
such realistic data, we adopt the SAGAN (Zhang et al., 2019) architecture for D and G. The D
network consists of three modules as shown in Figure 7 and detailed described in (Shen et al.,
2020). Details for newtork G and Dx are given in Figure 7 and Table 3. The encoder architecture is
the ResNet50 (He et al., 2016) followed by a 4-layer MLP of size 1024.
Implementation of the SCM. Recall the nonlinear SCM as the prior
Z = f((I- AT)Th(e)) ：= Fe(e).
We find Gaussians are expressive enough as unexplained noises, so we set h as the identity map-
ping. As mentioned in Section 4.1 we require the invertibility of f. We implement both linear and
nonlinear ones. For a linear f, we formally refer to
f (z) = Wz + b,
where W and b are learnable weights and biases. Note that W is a diagonal matrix to model the
element-wise transformation. Its inverse function can be easily computed by
f-1(z) = WT(Z - b).
For a non-linear f, we use piece-wise linear functions defined by
Na
f(i)(z(i)) = w0i)z(i) + E w(i)(z(i) - a)1(z⑴ ≥ ai) + b⑶
t=1
where ∙(i) denote the i-th dimension of a vector or a vector-function, a0 < aι < •一 < aNa are
points of division, and 1(∙) is the indicator function. From its denseness shown in lemma 3, the
family of such piece-wise linear functions is expressive enough to model general element-wise non-
linear invertible transformations.
Experimental details for baseline methods. We reproduce the S-VAEs including S-VAE, S-β-
VAE and S-TCVAE using E and G with the same architecture as ours and adopt the same opti-
mization algorithm for training. The coefficient for the independence regularizer is set to 4 since we
(a) Epoch 0
(b) Epoch 100
(c) Epoch 200
Figure 6: Learned adjacency matrices at different training epochs, starting from a random initializa-
tion.
(d) Epoch 500
17
Under review as a conference paper at ICLR 2021
notice that setting a larger independence regularizer hurts disentanglement in the correlated case.
For the supervised regularizer, We use λ = 1000 for a balance of generative model and supervision.
The ERM ResNet is trained using the same optimizer with a learning rate of 1 × 10-4.
Figure 7: (a) Architecture of the discriminator D(x,z); (b) A residual block (UP scale) in the
SAGAN generator where we use nearest neighbor interpolation for Upsampling; (c) A residual
block (down scale) in the SAGAN 祖SCriminator.
(b)
(C)
Table 3: SAGAN architecture (k = 100 and Ch = 32).
(a) Generator	(b) Discriminator module Dx
Input: Z ∈ Rk 〜N(0,I)	Input: RGB image X ∈ R64×64×3
Linear → 4 X 4 X 16ch	ResBlock down Ch → 2ch
ResBloCkUP 16ch → 16ch	Non-Local Block (64 X 64)
ResBloCkUP 16ch → 8ch	ResBlock down 2ch → 4ch
ResBlock up 8ch → 4ch	ResBlock down 4ch → 8 ch
Non-LoCal Block (64 X 64)	ResBlock down 8ch → 16ch
ResBlock up 4ch → 2 ch	ResBlock 16ch → 16ch
BN, ReLU, 3 X 3 ConV 2 ch → 3	ReLU, Global average pooling (fx)
Tanh	Linear → 1 (sx)
APPENDIX D	Additional results of causal controllable
GENERATION
In this section we present more qualitative results of causal controllable generation on two datasets
using DEAR and baseline methods, including S-VAEs (Locatello et al., 2020b) and CausalGAN
(Kocaoglu et al., 2018). We consider three underlying structures on two datasets: Pendulum in
Figure 2(a), CelebA-Smile in Figure 2(b), and CelebA-Attractive in Figure 2(c).
18
Under review as a conference paper at ICLR 2021
Figure 8: Results of DEAR. Note that the ordering of the representations matches that of the indices in Figure
2. On the left We show the traditional latent traversals (the first type of intervention stated in Section 5.1). On
the right we show the results of intervening on one latent variable from which we see the consequent changes
of the others (the first type of intervention). Specifically intervening on the cause variable influences the effect
variables while intervening on effect variables makes no difference to the causes.
19
Under review as a conference paper at ICLR 2021
(b) S-TCVAE (CelebA-Attractive)
(a) S-TCVAE (CelebA-Smile)
(d) S-FaCtorVAE (CelebA-Attractive)
(C) S-FactorVAE (CelebA-Smile)
后番卷
rl L88s
窜&»&&
r I I J-
(e) S-β-VAE (CelebA-Smile)
Figure 9: Traversal results of baseline methods. We see that (1) entanglement occurs; (2) some
factors are not detected (traversing on some dimensions of the latent vector makes no difference in
the decoded images.) Besides, the generated images from VAEs are blurry.

(f) S-β-VAE (CelebA-Attractive)
20
Under review as a conference paper at ICLR 2021
(a) CaUsalGAN (CelebA-Smile)
(b) CausalGAN (CelebA-Attractive)
Figure 10: Traversal results of baseline methods. CausalGAN uses the binary binary factors as the
conditional attributes, so the traversals appear some sudden changes. In contrast, We regard the logit
of binary labels as the underlying factors and hence enjoy smooth manipulations. In addition, the
controllability of CausalGAN is also limited, since entanglement still exists. Results of S-VAEs are
explained in Figure 9.
21