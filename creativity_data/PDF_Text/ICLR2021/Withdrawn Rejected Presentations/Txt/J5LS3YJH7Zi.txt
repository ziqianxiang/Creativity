Under review as a conference paper at ICLR 2021
CaLFADS: latent factor analysis of dynami-
CAL SYSTEMS IN CALCIUM IMAGING DATA
Anonymous authors
Paper under double-blind review
Ab stract
Dynamic latent variable modelling has provided a powerful tool for understand-
ing how populations of neurons compute. For spiking data, such latent variable
modelling can treat the data as set of point-processes, due to the fact that spik-
ing dynamics occur on a much faster timescale than the computational dynamics
being inferred. In contrast, for other experimental techniques the slow dynam-
ics governing the observed data are similar in timescale to the computational dy-
namics that researchers want to infer. An example of this is in calcium imaging
data, where calcium dynamics can have time timescales on the order of hundreds
of milliseconds. As such, the successful application of dynamic latent variable
modelling to modalities like calcium imaging data will rest on the ability to dis-
entangle the higher- and shallower-level dynamical systems’ contributions to the
data. To-date, no techniques have been developed to directly achieve this. Here
we solve this problem by extending recent advances using sequential variational
autoencoders for dynamic latent variable modelling of neural data. We solve the
problem of disentangling higher- and shallower-level dynamics by incorporating
a ladder architecture that can infer a hierarchy of dynamical systems. Using some
built-in inductive biases for calcium dynamics, we show that we can disentan-
gle calcium flux from the underlying dynamics of neural computation. First, we
demonstrate with synthetic calcium data that we can correctly disentangle an un-
derlying Lorenz attractor from calcium dynamics. Next, we show that we can
infer appropriate rotational dynamics in spiking data from macaque motor cortex
after it has been converted into calcium fluorescence data via a calcium dynam-
ics model. Finally, we show that our method applied to real calcium imaging
data from primary visual cortex in mice allows us to infer latent factors that carry
salient sensory information about unexpected stimuli. These results demonstrate
that variational ladder autoencoders are a promising approach for inferring hier-
archical dynamics in experimental settings where the measured variable has its
own slow dynamics, such as calcium imaging data. Our new, open source tool,
thereby provides the neuroscience community with the ability to apply dynamic
latent variable modelling to a wider array of data modalities.
1	Introduction
Dynamic latent variable modelling has been a hugely successful approach to understanding the func-
tion of neural circuits. For example, it has been used to uncover previously unknown mechanisms
for computation in the motor cortex (Churchland et al., 2012; Pandarinath et al., 2018), somatosen-
sory cortex (Wei et al., 2019b), and hippocampus (Chaudhuri et al., 2019). However, the success
of this approach is largely limited to datasets where the observed variables have dynamics whose
timescales are much faster than the dynamics of the underlying computations. This is the case, for
example, with spiking data, where the dynamics governing the generation of individual spikes are
much faster than the dynamics of computation across the circuit. This makes it possible to charac-
terise the observed data, e.g. the spiking data, as a set of point-processes that can be used directly
for inferring latent variables.
However, many datasets in the life sciences are generated by a hierarchy of dynamical systems,
wherein the shallower-level dynamical systems that directly generate the observed data have tempo-
ral dynamics whose timescales overlap with that of the deeper-level dynamical system to be inferred.
1
Under review as a conference paper at ICLR 2021
A clear example of this is in-vivo calcium imaging data, which is widely used in neuroscience.
Thanks to advances in imaging technology and genetically encoded calcium indicators, calcium
imaging enables monitoring of the activity of large populations of genetically targeted neurons in
awake behaving animals (Yang & Yuste, 2017; Lin & Schnitzer, 2016). However, calcium imaging
introduces an additional layer of a relatively slow dynamical system between the computations oc-
curring in the brain and the measurements that neuroscientists make. This problem is outlined in
Figure 1A, in which calcium fluorescence observations, x, depend on the state of calcium flux, z1 ,
which is governed by a shallower-level dynamical system with temporal dynamics on the order of
hundreds of milliseconds. These dynamics are driven, in part, by perturbations due to spikes, u1,
which are themselves governed by a computational state, z2, with a similar timescale in its dynamics
to the calcium flux (and which itself can be perturbed independently by unknown inputs, u2, that may
also have slow dynamics). Due to the overlap in timescales, it is impossible to identify immediately
which components of the calcium fluorescence data are driven by the dynamics of calcium flux, and
which are driven by the deeper-level latent dynamics of neural computation. Ideally, neuroscientists
would have a method for inferring both the shallower-level calcium dynamics and the deeper-level
computational dynamics in order to uncover the hierarchical dynamical systems that generated their
data. Such a tool would be significantly benefit the systems neuroscience community.
Currently, these problems are treated separately. For situations where the observed data can be
treated as a point process, we have good techniques for inferring the deeper-level dynamics. For
example, recent applications of sequential variational autoencoders have seen great success in in-
ferring underlying computations from extracellular spiking data (Pandarinath et al., 2018). This
technique, named Latent Factor Analysis of Dynamical Systems (LFADS), has improved neuro-
scientists’ ability to infer underlying neural computations from spiking data, e.g. it has been used
to identify latent rotational reaching dynamics and to decode reaching behaviour of macaques and
humans with higher fidelity than other techniques.
Although LFADS has significantly advanced our ability to analyze neural data in the form of spike
trains, it does not address the problem highlighted above for calcium imaging, wherein the calcium
dynamics introduce an additional shallower-level dynamical system whose timescale overlaps with
the timescale of neural computation. Theoretically, this problem could be solved independently by
first inferring spikes from calcium data, whether by deconvolution (e.g., OASIS) (Friedrich et al.,
2017), variational inference (e.g., DeepSpike) (Speiser et al., 2017), dynamic programming (Deneux
et al., 2016), or any other method (Berens et al., 2018; Pachitariu et al., 2018; Evans et al., 2019;
Wei et al., 2020), and then applying LFADS. However, this approach treats each calcium trace as
a completely independent variable when inferring calcium dynamics. This ignores correlations in
population activity that inform the separation of calcium dynamics (which are independent of popu-
lation activity) from computational dynamics (which are not independent of population activity). If
this separation is sub-optimal, then inference of the deeper-level system will be impaired.
Here, we address this problem by extending LFADS with a variational ladder autoencoder architec-
ture (Zhao et al., 2017) that folds the calcium dynamics inference into the larger inference problem
(Fig. 1B). Our system, CaLFADS, incorporates inductive biases for calcium dynamics and, thanks
to the ladder architecture, is able to infer the deeper-level dynamical system better than an approach
that treats inference of calcium dynamics and deeper-level dynamics as separate problems. For
further discussion on how CaLFADS relates to previous work, see Appendix B.
First, we show using synthetic data that we are able to reconstruct ground-truth latent dynamics from
synthetic calcium traces. Next, we apply CaLFADS to spiking data from macaque motor cortex that
has been converted into calcium fluorescence traces using a calcium dynamics model. We show
that we are able to recover rotational dynamics from this “calcified” data just as LFADS identifies
rotational dynamics from spiking data. Finally, we show using real 2-photon calcium imaging data
from mouse primary visual cortex that CaLFADS can identify deeper-level latent factors that carry
information about unexpected visual stimuli. Altogether, our work shows the benefits of incorpo-
rating the calcium dynamics inference procedure into the larger inference problem. It also provides
neuroscientists with a new, open-source tool for analyzing calcium imaging data in order to identify
deeper-level dynamics. Given the importance of calcium imaging to modern systems neuroscience,
we believe that CaLFADS will be a very useful analysis tool for the community. Furthermore, our
CaLFADS could be adapted to other neuroscience data modalities, such as fMRI data which, like
calcium imaging, comprises both fast deeper-level latent brain dynamics and slower shallower-level
blood oxygen measurement dynamics (Ollinger et al., 2001). Beyond this, we believe that our ap-
2
Under review as a conference paper at ICLR 2021
proach may be applicable to other life sciences domains, for example insurance claim modelling,
where better identifying the relatively slow dynamics underlying the observed variables, such as
claim submission distributions over time, could improve forecasting accuracy (Schmidt, 2014).
Figure 1: A) Hierarchy of dynamical systems (Top). schema of calcium and Lorenz dynamics
(Bottom). B) Schema of our hierarchical model. Latent dynamics model in blue, calcium dynamics
model in red.
2	Model
CaLFADS extends the variational ladder autoencoder (VLAE) approach (Zhao et al., 2017) with
RNNs (Fig 1B), which enables inference of hierarchical latent dynamical systems1. The full di-
rected acyclic graph for CaLFADS can be found in Figure S1. The VLAE approach to inferring
hierarchies removes the sequential dependence of each latent variable, and instead loads parts of a
flat latent code with more abstract features using more expressive neural networks (see appendix C
for more background on VLAEs). For CaLFADS, this means we separate the shallower-level infer-
ence and the deeper-level inference into parallel pathways for inference and generation (1B, orange
arrow), and subsequently, recombines these levels in the generative network (1B, pink arrow). This
approach has two major advantages: 1) It solves the problem of latent variable collapse in which all
latent features are loaded onto the lowest-order variables in the hierarchy. 2) It retains a very sim-
ple formulation for the variational/evidence lower bound (ELBO) that is easily reparameterisable
(S0nderby et al., 2016; Zhao et al., 2017).
1Supporting code for this submission can be found at https://anonymous.4open.science/
repository/63e5b8d1- 31b7- 408a- 99dc- a55980c2a1ca
3
Under review as a conference paper at ICLR 2021
CaLFADS infers the dynamics and unknown events (e.g. spikes) that determine the calcium fluores-
cence signal (Fig 1B, red network nodes), and the underlying computational dynamical system that
controls these events (Fig 1B, blue network nodes), through successive encoding and decoding lay-
ers in which latent variable distributions are modelled in separated ‘rungs’ of the ladder architecture.
This VLAE architecture enables CaLFADS to disentangle the shallower-level calcium dynamics and
the deeper-level computational dynamics. Algorithm 1 provides details on the forward pass of CaL-
FADS. Additionally, we provide a complete description of the model in Appendix D. Briefly, layers
of Gated Recurrent Units (GRUs) create a deterministic hierarchical embedding of the data in the
inference network (Fig 1B, above the dashed line). These embeddings are then concatenated with
time-shifted, layer-specific deterministic projections of the latent state. This concatenated set of
activities is then linearly transformed into the parameters of a factorised Gaussian posterior distribu-
tion for the latent variables in the generative network (Fig 1B, below the dashed line). This process
provides the inference network with information about the history of the latent states via feedback
connections (Fig 1B, purple feedback arrows).
As in any variational autoencoder (VAE) system, latent states are sampled from the posterior distri-
butions determined by the inference network. For the inference of the computational dynamical sys-
tem, these latent states represent the initial conditions (g2,t0) and unknown inputs (u2,t) to a learned
dynamical system modelled discretely by a GRU in the generative network (g2,t). The hidden state
of this GRU is then linearly transformed into a set of potentially low-dimensional time-varying la-
tent factors (f t). Concurrently, the latent states for the calcium dynamics (zt) are concatenated with
the dynamic factors from the layer above (ft), and undergo a linear transformation followed by a
rectified-exponential non-linearity f(x) = ReLU (exp(x) - 1) to provide an approximation to spike
counts (u1,t). This non-linearity was chosen as a continuous relaxation to discrete calcium transient
amplitudes inspired by the static distribution of amplitudes extracted via OASIS (Wei et al., 2019a).
In our case, we model approximate spike counts using a log-normal distribution with truncation at 0.
The approximate spike counts are then used as inputs to an order 1 autoregressive (AR(1)) process
model of calcium dynamics (g1,t). Since we found that the loss function was extremely sensitive
to changes in the AR(1) model parameters, these parameters were fixed using values empirically
derived from the OASIS-deconvolution algorithm (Friedrich et al., 2017). While it is possible to
transform calcium dynamics into fluorescence using nonlinear models of fluorescence indicator ki-
netics (Speiser et al., 2017; Deneux et al., 2016), we found that using the AR(1) process to model the
transformation of spike counts to fluorescence was sufficient for accurate reconstruction of the latent
space, even in synthetic data with nonlinear calcium transient generation. Model hyperparameters
for different datasets are shown in table S1.
2.1	Loss function and Training
One of the advantages of using VLAEs is that because the stochastic nodes operate in parallel, the
ELBO formulation is the same as that for standard VAEs despite the hierarchical latent space (Zhao
et al., 2017). As such, the CaLFADS cost function remains very similar to that of LFADS. It is
described in Algorithm 2. One key addition to the LFADS loss function is that because the data is
fluorescence data, which includes normal emissions noise, and the inferred shallower-level factors
are calcium concentrations, the likelihood function of the data given the estimated calcium concen-
tration, P(χt∣Xt), is modelled as a Gaussian distribution Xt 〜N(Xt, σ2), where σ2 is determined
by OASIS. Another key addition is that although spike counts u1,t are not modelled discretely, their
probability distribution given the inferred spike rates, P(uι,t∣λt), is modelled as an approximate
PoiSSon process such that log(P(uι,t∣λt)) ≈ uι,t log(λt) - (λt + uι,t). The approximation results
from the use of an L1 norm on the spikes, instead of the log-gamma term that would normally be
used in a Poisson process, which was necessary because most of the data sits within a range that
is poorly handled by the log-gamma function. The use of this approximate Poisson process pro-
vides an additional regularization term in the cost function, which acts as an inductive bias to ensure
that the inferred spike trains in the shallower-level dynamical system are constrained to follow the
dynamics of the deeper-level dynamical system’s spike rates λt. Per the VLAE framework, the
shallower-level and deeper-level latent variables are treated as independent, with hierarchy imposed
in the deterministic paths, i.e., Q(g1,t, g2,t=0, u2,t|x) = Q(g1,t|x)Q(g2,t=0|x)Q(u2,t|x)
Parameters of CaLFADS were optimised with ADAM, with an initial learning rate of 0.01. Learning
rates were decreased by a factor of 0.95 when plateaus in training error were detected. As in LFADS
training, KL and L2 terms in the cost function were ‘warmed up’, i.e., hada weight wl∈(1,2) between
4
Under review as a conference paper at ICLR 2021
0 and 1 applied that gradually increased (Bowman et al., 2016; S0nderby et al., 2016). Warm-up for
the deeper parameters (l = 2, blue modules in Figure 1) was delayed until warm-up for shallower
parameters (l = 1, red modules in Figure 1) was completed. We found in preliminary tests that this
delayed warm-up sequence was necessary for good hierarchical inference compared to simultaneous
warm-up. As with aggressive inference network training methods (He et al., 2019), this prevents
issues with training of the deeper-level dynamical system parameters converging more slowly than
the shallower-level dynamical system parameters in the initial stages of training.
3	Results
3.1	Lorenz Attractor Synthetic data
3.1.1	Data Description
As an initial test of CaLFADS, we examined its ability to infer the hierarchical dynamical systems
of synthetic calcium fluorescence data generated from a simple model of spiking neurons. We
examined synthetic data generated from a network with a Lorenz attractor embedded in its dynamics.
This tests our ability to recover a ground-truth deeper-level dynamical system from the data, and has
been used as a benchmark by many others (Zhao & Park, 2017; Pandarinath et al., 2018; Clark et al.,
2019; She & Wu, 2019; Koppe et al., 2019).
In this system, network dynamics were used to generate a set of spike rates in simulated neurons. We
then used a model of calcium dynamics and emissions noise to transform the spikes into synthetic
fluorescence data. We tested CaLFADS on data generated from two models of synthetic calcium
dynamics: a simple linear model equivalent to an AR(1) process, and a nonlinear model in which
an AR(1) process is transformed by a Hill function nonlinearity. We then added white noise to the
resulting traces. This procedure is described in more detail in Appendix H.
3.1.2	Model Comparison
We measured the performance of CaLFADS by computing R2 goodness-of-fit with the embedded
Lorenz attractor state variables. We also measured the ability of CaLFADS to reconstruct other
ground-truth variables in the synthetic data (spike counts, spike rates, and fluorescence traces) using
R2, but these were not as critical for assessing model performance.
CaLFADS performance was compared against two baselines. First, we use LFADS with a Gaus-
sian likelihood observation model to account for fluorescence (Gaussian-LFADS). Second, we con-
sider the situation where spike counts are first estimated separately using the OASIS deconvolution
algorithm (Friedrich et al., 2017), a robust, popular, and computationally inexpensive method of
spike extraction widely used by systems neuroscientists (Pachitariu et al., 2018; Evans et al., 2019).
LFADS is then used to infer the deeper-level dynamical system and reconstruct the spike rates from
the deconvolved spike trains. We refer to this approach as OASIS+LFADS throughout.
Table 1 compares R2 goodness-of-fit in reconstructing ground-truth dynamic latent variables in
held-out validation data. Table 1 shows CaLFADS is able to reconstruct the Lorenz attractor state
for synthetic data with either linear or nonlinear synthetic calcium models (see Table 1 caption
for significance test results). Indeed, the inclusion of nonlinearities in calcium dynamics does
not affect CaLFADS ability to reconstruct the Lorenz attractor state as much as it does with OA-
SIS+LFADS. CaLFADS is also better able to reconstruct other network state variables compared to
OASIS+LFADS as can also be seen in Table 1. However, it is worth noting that high accuracy in
reconstructing other network state variables does not appear to be necessary for accurate reconstruc-
tion of the underlying Lorenz attractor. This indicates that CaLFADS is better suited to handling
uncertainty due to spike-timing and is capable of separating sources of slow dynamics to recon-
struct the embedded latent space. Example outputs of CaLFADS and OASIS+LFADS are shown in
Appendix I.1 and I.2.
Note that CaLFADS reconstructs the Lorenz dynamics almost as well as LFADS does when ap-
plied to the spiking data. Of course, it is to be expected that LFADS applied to true spiking data
performs better than CaLFADS, since there is an additional source of observation noise from the
generation of fluorescence transients. But, the fact we can get very close to the same level of perfor-
5
Under review as a conference paper at ICLR 2021
Table 1: Comparison of model performance (R2 mean+sem) on synthetic Lorenz datasets generated
with 15 different seeds. A hyphen indicates that the variable cannot be compared, as the model does
not infer it. The top row is italicised as the performance of LFADS on this task is considered the
upper limit, having no additional observation noise from fluorescence. Results of paired t-tests for
testing significance of differences in performance between OASIS+LFADS and CaLFADS within
seeds for a) linear calcium model: Lorenz state - t14 = 2.85, p = 0.013; Spike Counts - t14 = 20.67,
p < 0.001; Rates - t14 = 4.81, p < 0.001; Fluorescence - t14 = 16.2, p < 0.001. b) nonlinear
calcium model: Lorenz state - t14 = 3.29, p = 0.005; Spike Counts - t14 = 17.16, p < 0.001;
Rates - t14 = 6.35, p < 0.001; Fluorescence - t14 = 11.16, p < 0.001.
Calcium	Model	Lorenz state	Spike Counts	Firing Rates	Fluorescence
NA	LFADS	0.975 ± 0.001	-	0.956 ± 0.003	-
Linear	Gaussian-LFADS	0.818 ± 0.005	-	0.701 ± 0.004	-
	OASIS+LFADS	0.960 ± 0.001	0.580 ± 0.006	0.912 ± 0.002	0.807 ± 0.005
	CaLFADS	0.965 ± 0.001	0.817 ± 0.007	0.937 ± 0.002	0.909 ± 0.003
Nonlinear	Gaussian-LFADS	0.808 ± 0.005	-	0.650 ± 0.006	-
	OASIS+LFADS	0.877 ± 0.003	0.351 ± 0.004	0.682 ± 0.005	0.843 ± 0.004
	CaLFADS	0.902 ± 0.006	0.561 ± 0.010	0.756 ± 0.008	0.932 ± 0.005
mance indicates that CaLFADS is effective at performing the same inference on calcium data that
LFADS performs on spiking data. We speculate that the uncertainty over AR1 process parameters is
overcome in CaLFADS by constraining the reconstructed spike counts with the latent dynamics to
make the inference of the observed dynamics process “population-aware”, something which cannot
be done when using LFADS applied to spike counts obtained by OASIS deconvolution. This may
mitigate errors in spike count reconstruction that occur by deconvolution due to the absence of infor-
mation about whole-network dynamics. Thus, CaLFADS can use population-level dynamics when
conducting the inference of network variables, and this helps it to separate out the shallower-level
dynamics more accurately.
3.2	Rotational Dynamics in Monkey Motor Cortex
Next, we wanted to test CaLFADS on a real neural dataset to which LFADS has previously been ap-
plied, and successfully used to uncover meaningful latent dynamics. Specifically, it has been shown
previously that rotational dynamics underlie neuronal responses in monkey and human motor cortex
during reaching behaviour (Churchland et al., 2012). LFADS has been successful in uncovering
these known rotational dynamics for single-trial spikes recorded from primary motor cortex (M1)
and dorsal premotor cortex (PMd) in macaques (Pandarinath et al., 2018). To test whether CaLFADS
could do the same, we took the original spiking data and converted it into semi-synthetic calcium
traces, using the same model of calcium dynamics that was used for synthetic data generation in
the previous sections (Fig 2A). We used data from the monkey electrophysiology dataset previously
described, along with the reaching task, by Churchland et al. (2012), which was kindly provided
to us by the original authors. Briefly, monkeys were trained to reach a target under 108 different
reach conditions while multi-electrode recordings were made in M1 and PMd. Reaches started from
a specified location on a screen, and monkeys were rewarded for correctly reaching toward a target
while avoiding on-screen obstacles (Fig 2B).
First, to replicate the previous LFADS results, we applied jPCA (Churchland et al., 2012) to
condition-averaged firing rates (trial averages for each of the 108 reach conditions), as well as single-
trial firing rates inferred from spike data using LFADS. jPCA is a dimensionality reduction technique
that finds orthogonal projections capturing rotational dynamics that explain variability in firing rates.
The original LFADS paper showed that rotational dynamics explained a large amount of the vari-
ance in firing rates. As in the original papers, We identified both condition-averaged (Fig 2C - top)
and single-trial (Fig 2C - bottom) rotational dynamics from firing rates inferred by LFADS, which
explained a large amount of the variance (R2 = 0.81), thereby replicating the original findings.
Then, we evaluated our CaLFADS model in uncovering the rotational dynamics of both condition-
averaged and single trials from firing rates. As shown in Fig 2, our model also successfully uncovers
rotational dynamics from calcium traces, explaining a large amount of variance (R2 = 0.78) for both
6
Under review as a conference paper at ICLR 2021
A
C LFADS (spikes) D CaLFADS (fluor) E OASIS+LFADS (fluor)
POJ6B-Jω>τuo≡puoo -3」Y(U-6U-S
projection onto JPC1
projection onto JPC1
(a.u.)
projection onto jPC1
(a.u.)
Figure 2: A) Schematic for the process of converting spikes to calcium traces, and B) for the reaching
task. C) Rotational dynamics inferred from condition-averaged (Top) and single-trial spikes (Bot-
tom) using LFADS. D) Rotational dynamics inferred from condition-averaged (Top) and single-trial
calcium traces (Bottom) using CaLFADS. E) Rotational dynamics inferred from condition-averaged
(Top) and single-trial calcium traces (Bottom) using OASIS+LFADS. Traces are coloured based on
their initial state values along jPC1 (from green to red for increasingly larger values)
condition-averaged (Fig 2D - top) and single trials (Fig 2D - bottom). These results demonstrate
that CaLFADS is capable of identifying latent dynamics in real neural data, similar to LFADS, even
when the spiking data is transformed by calcium dynamics and emissions noise. We also found that
the OASIS+LFADS approach was not as successful as CaLFADS in uncovering rotational dynam-
ics, explaining only half the variance (R2 = 0.53, Fig 2E). This result corroborates the importance
of the hierarchical modelling of calcium and neuronal dynamics in CaLFADS.
3.3	Unexpected Stimulus Detection in Mouse Primary Visual Cortex
Finally, we wanted to test CaLFADS on an entirely new calcium imaging dataset, to determine
whether CaLFADS can infer dynamic computational factors that carry information about relevant
features of the outside world. We chose to analyse data from mouse primary visual cortex (VisP),
a region widely studied in systems neuroscience research where calcium imaging is a standard tool.
There is evidence that the visual cortex of mammals performs a predictive function, anticipating
expected stimuli (Dayan et al., 1995; Rao & Ballard, 1999; Fiser et al., 2016; Leinweber et al., 2017).
As a result, unexpected stimuli can induce perturbations in network dynamics (Fiser et al., 2016;
Leinweber et al., 2017). Thus, we wanted to determine whether CaLFADS could infer dynamic
computational factors that carry information distinguishing unexpected from expected visual stimuli.
To this end, we trained CaLFADS on calcium imaging data from the mouse visual cortex collected
by the Allen Institute for Brain Science (for a detailed description, see Appendix J.1). While awake
behaving mice were presented with visual stimuli on a screen (Fig 3A), calcium fluorescence re-
sponses in cortical layer 2/3 of VisP were recorded using 2-photon microscopy (Fig 3B). The mice
were familiarised with sequences of stimulus frames that followed simple probabilistic rules. Briefly,
each sequence consisted of four randomised Gabor pattern frames followed by a grey screen (A, B,
C, D, grey) with orientations drawn for each trial from the same distribution. After familiarization
with this sequence, the expected D frame was replaced in 10% of trials by a Gabor pattern (E)
with orthogonal orientations (Fig 3C). CaLFADS inferred smooth latent factors that did not show
signs of over-fitting to noise (Appendix J.2, Fig S7). To determine if salient information about these
unexpected stimulus features was present in the inferred factors from CaLFADS, we trained a non-
linear decoder to classify whether the inferred factors came from a trial with an expected D frame
or an unexpected E frame (for details, see Appendix J.3). We also trained the non-linear decoder on
factors inferred by OASIS+LFADS, and on fluorescence traces reduced in dimensionality with prin-
7
Under review as a conference paper at ICLR 2021
Figure 3: A) Schematic of 2-photon calcium imaging recording setup. Mice are head-fixed on a
running wheel under the imaging objective, and visual stimuli are projected onto a screen to the side,
B) 2-photon calcium imaging recording plane, C) Schematic example of visual stimuli for expected
(A-B-C-D-grey) and unexpected (A-B-C-E-grey) trials. D) Average recall (mean ± sem) of expected
vs. unexpected trials across non-linear decoders trained on principal components of fluorescence
traces (0.815 ± 0.011, green), Gaussian-LFADS factors (0.500 ± 0.000, blue), OASIS+LFADS
factors (0.810 ± 0.005, purple), and CaLFADS factors (0.871 ± 0.004, maroon). All pairs but one
(fluor. vs. OASIS+LFADS factors, marked with n.s.) were significantly different at p < 0.05 in
2-tailed independent t-tests with Bonferroni correction for multiple comparisons.
cipal components analysis. To compare the models fairly, despite the imbalance between expected
and unexpected trial frequencies, we measured average recall. We find that using the CaLFADS
factors leads to the highest performance on stimulus-trial identity decoding, with the average re-
call being significantly higher than when OASIS+LFADS factors are used (Fig 3D). This indicates
that CaLFADS infers latent dynamics from real visual cortex calcium imaging data that reflect the
predictability of visual stimuli, corroborating the ability of CaLFADS to infer meaningful dynamic
factors in real data.
4	Discussion
In this paper we presented CaLFADS, a hierarchical recurrent variational autoencoder model ca-
pable of reconstructing latent computational dynamics. We confirmed CaLFADS’ ability to recon-
struct known underlying dynamics using synthetic datasets where ground-truth was known. We also
showed that CaLFADS is able to infer sensorimotor dynamics from real neural recordings. This
indicates that CaLFADS is a promising method for analyzing calcium imaging data in neuroscience.
There are two key advantages of CaLFADS over the use of deconvolution of calcium traces fol-
lowed by application of LFADS. The first is that we can obtain measures of the uncertainty in both
the latent dynamics, and the latent spike counts. The second is that CaLFADS performs better than
OASIS+LFADS when nonlinearities in calcium dynamics are present, as is the case in real experi-
mental data where there are many sources of calcium influx related to spikes.
We designed CaLFADS to fit into a much broader class of artificial neural network models, namely
sequential variational ladder autoencoders, in which different layers of recurrent neural networks
can be used to infer and generate different layers of a hierarchical dynamical system. In this sense,
this class of models is modular and composable, meaning it could be readily adapted to other do-
mains. For example, it should be possible to replace LFADS as the deeper-level dynamical system
model with any other differentiable model. Likewise the same is true for our AR1 based model of
calcium dynamics: we could replace the calcium dynamics model with other models as required by
the experimental set-up. Furthermore, there is no need to stop at two layers in the hierarchy; the
brain is comprised of many interconnected recurrent neural networks sending long range signals to
one another, and it should be possible to add in additional modules to capture additional hierarchies
and dynamics within the brain.
In summary, CaLFADS is a new, open source tool for inferring hierarchical dynamics from calcium
imaging data that also has great potential for being modified and applied to other data modalities.
This could be of real benefit to the thousands of neuroscience laboratories around the world con-
ducting calcium imaging experiments.
8
Under review as a conference paper at ICLR 2021
References
Laurence Aitchison, Lloyd Russell, Adam M Packer, Jinyao Yan, Philippe Castonguay, Michael
Hausser, and Srinivas C Turaga. Model-based bayesian inference of neural activity and connec-
tivity from all-optical interrogation of a neural circuit. In I. Guyon, U. V. Luxburg, S. Bengio,
H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information
Processing Systems, volume 30, pp. 3486-3495. Curran Associates, Inc., 2017.
A. Anonymous. Identifying the role of top-down feedback connections in cortical learning and
inference (AIBS openscope grant proposal), 2018.
Philipp Berens, Jeremy Freeman, Thomas Deneux, Nikolay Chenkov, Thomas McColgan, Artur
Speiser, Jakob H. Macke, Srinivas C. Turaga, Patrick Mineault, Peter Rupprecht, Stephan Ger-
hard, Rainer W. Friedrich, Johannes Friedrich, Liam Paninski, Marius Pachitariu, Kenneth D.
Harris, Ben Bolte, Timothy A. Machado, Dario Ringach, Jasmine Stone, Luke E. Rogerson, Nico-
las J. Sofroniew, Jacob Reimer, Emmanouil Froudarakis, Thomas Euler, Miroslav Roman RosOn,
Lucas Theis, Andreas S. Tolias, and Matthias Bethge. Community-based benchmarking improves
spike rate inference from two-photon calcium imaging data. PLOS Computational Biology, 14
(5):1-13, 05 2018. doi: 10.1371/journal.pcbi.1006157.
Samuel R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and Samy Bengio.
Generating sentences from a continuous space. In Proceedings of The 20th SIGNLL Conference
on Computational Natural Language Learning, pp. 10-21, Berlin, Germany, August 2016. Asso-
ciation for Computational Linguistics. doi: 10.18653/v1/K16-1002.
Rishidev Chaudhuri, Berk Gergek, Biraj Pandey, Adrien Peyrache, and Ila Fiete. The intrinsic attrac-
tor manifold and population dynamics of a canonical cognitive circuit across waking and sleep.
Nature Neuroscience, 22(9):1512-1520, September 2019. doi: 10.1038/s41593-019-0460-x.
Number: 9 Publisher: Nature Publishing Group.
T. W. Chen, T. J. Wardill, Y. Sun, S. R. Pulver, S. L. Renninger, A. Baohan, E. R. Schreiter, R. A.
Kerr, M. B. Orger, V. Jayaraman, L. L. Looger, K. Svoboda, and D. S. Kim. Ultrasensitive
fluorescent proteins for imaging neuronal activity. Nature, 499(7458):295-300, 2013.
Mark M. Churchland, John P. Cunningham, Matthew T. Kaufman, Justin D. Foster, Paul Nuyu-
jukian, Stephen I. Ryu, and Krishna V. Shenoy. Neural population dynamics during reaching.
Nature, 487(7405):51-56, July 2012. doi: 10.1038/nature11129. Number: 7405 Publisher: Na-
ture Publishing Group.
David G. Clark, Jesse Livezey, and Kristofer E. Bouchard. Unsupervised discovery of tempo-
ral structure in noisy data with dynamical components analysis. In Hanna M. Wallach, Hugo
Larochelle, Alina Beygelzimer, Florence d,Alche—Buc, Emily B. Fox, and Roman Garnett (eds.),
Advances in Neural Information Processing Systems 32: Annual Conference on Neural Informa-
tion Processing Systems 2019, NeurIPS 2019, 8-14 December 2019, Vancouver, BC, Canada, pp.
14267-14278, 2019.
Peter Dayan, Geoffrey E. Hinton, Radford M. Neal, and Richard S. Zemel. The Helmholtz machine.
Neural Comput., 7(5):889-904, September 1995. doi: 10.1162/neco.1995.7.5.889.
Saskia EJ de Vries, Jerome A Lecoq, Michael A Buice, Peter A Groblewski, Gabriel K Ocker,
Michael Oliver, David Feng, Nicholas Cain, Peter Ledochowitsch, Daniel Millman, et al. A
large-scale standardized physiological survey reveals functional organization of the mouse visual
cortex. Nature Neuroscience, 23(1):138-151, 2020.
Thomas Deneux, Attila Kaszas, Gergely Szalay, Gergely Katona, TamaS Lakner, Amiram Grinvald,
BaIazS Rozsa, and Ivo Vanzetta. Accurate spike estimation from noisy calcium signals for ultrafast
three-dimensional imaging of large neuronal populations in vivo. Nature Communications, 7(1):
12190, July 2016. doi: 10.1038/ncomms12190.
Mathew H. Evans, Rasmus S. Petersen, and Mark D. Humphries. On the use of calcium deconvolu-
tion algorithms in practical contexts. bioRxiv, 2019. doi: 10.1101/871137.
9
Under review as a conference paper at ICLR 2021
A. Fiser, D. Mahringer, H. K. Oyibo, A. V. Petersen, M. Leinweber, and G. B. Keller. Experience-
dependent spatial expectations in mouse visual cortex. Nature Neuroscience, 19(12):1658-1664,
2016.
Johannes Friedrich, Pengcheng Zhou, and Liam Paninski. Fast online deconvolution of calcium
imaging data. PLOS Computational Biology, 13(3):e1005423, March 2017.
Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Rezende, and Daan Wierstra. Draw: A recurrent
neural network for image generation. volume 37 of Proceedings of Machine Learning Research,
pp. 1462-1471, Lille, France, 07-09 Jul 2015. PMLR.
Junxian He, Daniel Spokoyny, Graham Neubig, and Taylor Berg-Kirkpatrick. Lagging inference net-
works and posterior collapse in variational autoencoders. In International Conference on Learning
Representations, 2019.
Daniel Hernandez, Antonio Khalil Moretti, Ziqiang Wei, Shreya Saxena, John Cunningham, and
Liam Paninski. Nonlinear evolution via spatially-dependent linear dynamics for electrophysiol-
ogy and calcium data, 2020.
J. Homann, S. A. Koay, A. M. Glidden, D. W. Tank, and M. J. Berry. Predictive coding of novel
versus familiar stimuli in the primary visual cortex. bioRxiv, pp. 17, 2017. doi: 10.1101/197608.
Elke Kirschbaum, Manuel Hauβmann, Steffen Wolf, Hannah Sonntag, Justus Schneider, Sheha-
beldin Elzoheiry, Oliver Kann, Daniel Durstewitz, and Fred A Hamprecht. LemoNADe: Learned
motif and neuronal assembly detection in calcium imaging videos. In International Conference
on Learning Representations, 2019.
Georgia Koppe, Hazem Toutounji, Peter Kirsch, Stefanie Lis, and Daniel Durstewitz. Identifying
nonlinear dynamical systems via generative recurrent neural networks with applications to fmri.
PLOS Computational Biology, 15(8):1-35, 08 2019. doi: 10.1371/journal.pcbi.1007263.
Marcus Leinweber, Daniel R. Ward, Jan M. Sobczak, Alexander Attinger, and Georg B. Keller. A
Sensorimotor Circuit in Mouse Cortex for Visual Flow Predictions. Neuron, 95(6):1420-1432.e5,
September 2017. doi: 10.1016/j.neuron.2017.08.036. Publisher: Elsevier.
Michael Z Lin and Mark J Schnitzer. Genetically encoded indicators of neuronal activity. Nature
neuroscience, 19(9):1142, 2016.
JM Ollinger, M Corbetta, and GL Shulman. Separating processes within a trial in event-related
functional mri. Neuroimage, 13(1):218-229, 2001.
Marius Pachitariu, Carsen Stringer, and Kenneth D. Harris. Robustness of Spike Deconvolution for
Neuronal Calcium Imaging. The Journal of Neuroscience, 38(37):7976-7985, September 2018.
Chethan Pandarinath, Daniel J. O’Shea, Jasmine Collins, Rafal Jozefowicz, Sergey D. Stavisky,
Jonathan C. Kao, Eric M. Trautmann, Matthew T. Kaufman, Stephen I. Ryu, Leigh R. Hochberg,
Jaimie M. Henderson, Krishna V. Shenoy, L. F. Abbott, and David Sussillo. Inferring single-trial
neural population dynamics using sequential auto-encoders. Nature methods, 15(10):805-815,
October 2018.
Rajesh P. N. Rao and Dana H. Ballard. Predictive coding in the visual cortex: a functional interpre-
tation of some extra-classical receptive-field effects. Nature Neuroscience, 2(1):79-87, January
1999. doi: 10.1038/4580. Number: 1 Publisher: Nature Publishing Group.
Thorsten Schmidt. Catastrophe insurance modeled by shot-noise processes. Risks, 2(1):3-24, 2014.
Qi She and Anqi Wu. Neural dynamics discovery via gaussian process recurrent neural networks.
In Amir Globerson and Ricardo Silva (eds.), Proceedings of the Thirty-Fifth Conference on Un-
certainty in Artificial Intelligence, UAI 2019, Tel Aviv, Israel, July 22-25, 2019, pp. 159. AUAI
Press, 2019.
Casper Kaae S0nderby, Tapani Raiko, Lars Maal0e, S0ren Kaae S0nderby, and Ole Winther. Ladder
Variational Autoencoders. In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett
(eds.), Advances in Neural Information Processing Systems 29, pp. 3738-3746. Curran Asso-
ciates, Inc., 2016.
10
Under review as a conference paper at ICLR 2021
Artur Speiser, Jinyao Yan, Evan W Archer, Lars Buesing, Srinivas C Turaga, and Jakob H Macke.
Fast amortized inference of neural activity from calcium imaging data with variational autoen-
coders. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and
R. Garnett (eds.), Advances in Neural Information Processing Systems 30, pp. 4024-4034. CUr-
ran Associates, Inc., 2017.
XUe-Xin Wei, Ding ZhoU, Andres Grosmark, Zaki Ajabi, Fraser Sparks, Pengcheng ZhoU,
Mark Brandon, Attila Losonczy, and Liam Paninski. A zero-inflated gamma model for post-
deconvolved calciUm imaging traces. bioRxiv, 2019a. doi: 10.1101/637652.
Ziqiang Wei, Hidehiko Inagaki, NUo Li, Karel Svoboda, and ShaUl DrUckmann. An orderly single-
trial organization of popUlation dynamics in premotor cortex predicts behavioral variability. Na-
ture Communications, 10(1):216, JanUary 2019b. doi: 10.1038/s41467-018-08141-6. NUmber: 1
PUblisher: NatUre PUblishing GroUp.
Ziqiang Wei, Bei-JUng Lin, Tsai-Wen Chen, Kayvon Daie, Karel Svoboda, and ShaUl DrUckmann.
A comparison of neUronal popUlation dynamics measUred with calciUm imaging and electrophys-
iology. PLOS ComputationalBiology, 16(9):1-29, 09 2020. doi: 10.1371∕journal.pcbi.1008198.
Weijian Yang and Rafael YUste. In vivo imaging of neUral activity. Nature methods, 14(4):349,
2017.
Shengjia Zhao, Jiaming Song, and Stefano Ermon. Learning Hierarchical FeatUres from Deep Gen-
erative Models. In International Conference on Machine Learning, pp. 4091-4099, JUly 2017.
YUan Zhao and Il Memming Park. Variational Latent GaUssian Process for Recovering Single-Trial
Dynamics from PopUlation Spike Trains. Neural Computation, 29(5):1293-1316, March 2017.
11
Under review as a conference paper at ICLR 2021
A Variable Glossary
Table S1: Glossary of variables, with descriptions and dimensionality across datasets
Variable	Description	Dimensions			
		Lorenz	RNN	M1/PMd	V1
xt	Fluorescence signal	30	50	202	96
h1,t	Calcium dynamics embedding encoder state	128	64	200	128
h2,t	Computational dynamics embedding encoder state	64	128	100	128
c1,t	Calcium dynamics embedding controller state	128	64	200	128
c2,t	Computational dynamics embedding controller state	0	128	0	64
g1,t	Calcium dynamics embedding state	100	64	200	128
z2,t	Computational dynamics embedding state	64	200	100	200
u1,t	Approximate spike counts	30	50	202	96
u2,t	Computational dynamics perturbations	0	1	0	1
g1,t	Calcium dynamics	30	50	202	96
ft	Dynamic factors	3	20	40	32
Xt	Reconstructed fluorescence signal	30	50	202	96
12
Under review as a conference paper at ICLR 2021
B	Related Work and Contribution
This work brings together two important strands of computational neuroscience research that have
been of interest to the machine learning community, namely probabilistic latent factor models of
neural dynamics and inference of spikes in calcium fluorescence traces. We solve these two prob-
lems as a hierarchical inference problem using variational ladder autoencoders. We give a brief
introduction to variational ladder autoencoders in Appendix C.
LFADS is a power latent factor model of neural dynamics proposed by Pandarinath et al. (2018).
It is an extension of the sequential variational autoencoder DRAW (Gregor et al., 2015) applied
to spiking data that adds an additional RNN to the encoder architecture to infer unknown initial
conditions to a generator RNN. This enables interpretation of the generative model as a nonlinear
dynamical system that generates observed spikes. Low dimensional projections of the generator
hidden state (latent factors) were found to be capable of decoding single-trial reaching movements
with very high accuracy. This was a hugely influential and important contribution to the field of
neuroscience as it demonstrated a means to find latent dynamical systems that solved computational
tasks required for executing behaviour. However, LFADS could not be applied to neural data where
the spiking was itself unknown, as in two-photon calcium imaging.
DeepSpike by Speiser et al. (2017) is a variational autoencoder adapted from MLSpike, a proba-
bilistic model of calcium fluorescence recordings (Deneux et al., 2016). It was a contribution to the
SpikeFinder competition (Berens et al., 2018) in which participants were given the task of inferring
an unknown spike train from calcium fluorescence recordings. Unlike in most two-photon record-
ings, these data also included ground-truth whole-cell electrophysiology, i.e., ground-truth spike
trains. While other techniques had higher performance, it was the first attempt at solving this prob-
lem using variational inference. One issue with this model is that it used a Bernoulli distribution to
model the latent spike train. Since this is not reparameterisable, Speiser et al. (2017) needed to use
a high variance Monte Carlo objective to train the model. The use of this objective means it would
not scale well to 2-photon measurements from many cells. Furthermore, such a model does not
capture how neurons can spike multiple times within the time-bin of a typical two-photon imaging
experiment.
We note some similarities between our generative model and Aitchison et al. (2017). A key differ-
ence here is that we try to find nonlinear latent dynamics, whereas their model comprises a linear
dynamical system in the latent space. Furthermore, theirs is a fully Bayesian approach, whereas
CaLFADS has many more deterministic components.
We also note the capabilities of VIND (Hernandez et al., 2020) in inferring non-linear latent dynam-
ics in wide-field calcium imaging data, which has insufficient spatial resolution to observe individual
cells. Hernandez et al. (2020) propose a variational inference technique in which latent dynamics are
modelled by a locally linear dynamical system and find informative latent trajectories in the recorded
smoothed population activity. We note however that this approach is not used to infer latent dynam-
ics in two-photon recordings, where it would be necessary to disentangle calcium dynamics from
population dynamics.
Finally, the variational autoencoder LeMoNADe proposed by Kirschbaum et al. (2019) similarly
proposes an end-to-end system of inferring latent activities from calcium imaging. In contrast to
CaLFADS, they are attempting to infer the presence of neuronal ensembles, sets of cells grouped
together by their activities. While this is a related goal to inferring a latent dynamical system,
there is no requirement for the latent factors to be as interpretable as in LeMoNADe. Furthermore,
the neuronal ensembles identified by LeMoNADe were not demonstrated to help solve relevant
behavioural tasks. However, LeMoNADe were the first to demonstrate how neuronal activities could
be modelled by a continuous relaxation to the Bernoulli distribution using the Gumbel-Softmax
trick.
CaLFADS ties together this related work. We propose a hierarchical variational autoencoder capable
of inferring latent dynamic factors in calcium imaging data by separating shallower-level calcium
dynamics and deeper-level computational dynamics. We propose a novel continuous relaxation
to spike counts that allows an arbitrary number of spikes to be counted within the typically low
sampling rate of calcium fluorescence recordings (10-30 Hz). We also propose a novel KL annealing
technique for allowing hierarchical latent dynamics to be inferred.
13
Under review as a conference paper at ICLR 2021
C Introduction to Variational Ladder Autoencoders
Variational Ladder Autoencoders were proposed as a way to ensure that higher- and lower-level
features could be stored in different parts of the latent state. They propose a ladder architecture
in which more expressive networks sit deeper in the hierarchy and no hierarchy is assumed among
latent variables directly. For layers 1 : L in the hierarchy
P(z1,..., zL) =YP(zl)	(1)
Q(zl|x)=fl(hl)	(2)
hl = gl(hl-1)	(3)
where h0 = x, and gl and fl are neural networks with increasing degrees of expressivity as l
increases. This encourages more abstract features to be represented in certain portions of the latent
state.
This is in contrast to traditional hierarchical autoencoders that assume a Markovian structure in the
latent variables
L-1
P(x,z) = P(x|z1) Y P(zl|zl+1)P(zL)	(4)
l=1
The key insight from (Zhao et al., 2017) is that under idealised assumptions for sampling and
optimization of the ELBO, the ELBO for hierarchical VAEs is optimised by minimizing only
DKL(Q(z1 |x)||P (z1 |x)). This means that traditional hierarchical VAEs will load all representa-
tions onto the lowest level of the hierarchy.
In contrast, by splitting the latent code by abstractness and parameterising the factorised posterior
distribution with increasingly expressive functions, the VLAE can be trained with the simple ELBO
formulation used in non-hierarchical VAEs.
14
Under review as a conference paper at ICLR 2021
D	CaLFADS probabilistic model
Here we outline the assumed probabilistic model for CaLFADS. In doing so, we will briefly review
the model of LFADS (Pandarinath et al., 2018) and the extensions that make it possible to infer
dynamic latent variables from calcium fluorescence traces.
D.1 LFADS Generative Model
LFADS assumes that neural activity x is generated from a low dimensional non-linear dynamical
system with unknown initial conditions subjected to unknown control inputs. The state of the low-
dimensional non-linear dynamical system is modelled by the hidden state gt of a Gated Recurrent
Unit receiving control inputs ut . The prior for the initial conditions g0 is assumed to be normal with
mean μg° and variance σg°. External inputs are assumed to have an autoregressive process prior
with process mean μu, process variance σU, and time constant Tχ,
P (gt) = N(μgo ,σgo)	⑸
P(UI)= N (μχ,σ2)	(6)
-1	-1
P(UtIUt-i) = N(μu + eTU (Ut-1 - μu), σU(1 - eTU))	(7)
gt = GRU (gt-1, Ut)	(8)
The hidden states of the GRU are then projected to a low-dimensional set of factors ft
ft = Wfgt + bf	(9)
In Pandarinath et al. (2018), the neural activity being modelled was single-trial spikes extracted from
electrophysiological data in macaque motor cortex. LFADS assumes a simple observation model for
spiking data where the spike count observed in a given time-bin xt follows an independent Poisson
process parameterised by the instantaneous firing rate λt . To obtain the instantaneous firing rate,
low-dimensional factors ft are linearly projected to the dimensionality of the data and a non-linearity
enforcing positivity is applied, in this case the exponential function
λt = exp(Wλft +bλ)
P(xt Iλt) = Poisson(λt)
(10)
(11)
D.2 Calcium Fluorescence Generative Model
Before describing how the low dimensional dynamic factors are used to generate calcium fluores-
cence data, we first describe our probabilistic model for calcium fluorescence transients. We assume
that calcium fluorescence transients are generated by an autoregressive process ct occluded by white
emissions noise and perturbed by an unknown spike train st .
Probabilistic models of unknown spike counts in calcium fluorescence data typically assume a
Bernoulli distribution, or some continuous approximation thereof (Speiser et al., 2017). This is
somewhat problematic given that fluorescence is sampled at a rate of 10-30 Hz, leaving time-bins
large enough to observe more than one spike per time-bin. Recently, Wei et al. (2019a) demonstrated
that spike counts inferred by the deconvolution algorithm OASIS (Friedrich et al., 2017) could be
closely modelled by a zero-inflated gamma model. Similar to this, we modelled spike counts using
a similar continuous approximation
P (St) = ReLU (LogNormal(μst ,σ2J — 1)	(12)
This approximation is easily reparameterisable since we can sample from a lognormal distribution by
transforming samples from a normal distribution with an exponential function. The ReLU function
and subtraction of 1 from samples ensures that many counts are zero. In contrast, since the zero-
inflated gamma model which is a mixture distribution, it would require modelling a hierarchical
discrete-continuous latent variable which is not as simply reparameterisable for backpropagation.
15
Under review as a conference paper at ICLR 2021
Spike counts are then used to perturb an autoregressive process modelling the slow decay of calcium
fluorescence after a spike. A simple autoregressive model for calcium fluorescence is the AR(1)
process. With discretised time, this can be modelled with Euler updates
ct = ct-1(1 - β) + αst	(13)
where β = 位,with ∆t the size of time bin and Tc the decay of calcium fluorescence, and with
τc
∆t < τc. α is a constant gain term controlling the effect of spikes on fluorescence.
A nonlinear function modelling dye kinetics d(∙) can then be applied. For these experiments We
have not done so, but it would be a relatively simple extension. As such, the observation model for
fluorescence F becomes
P(Ft|ct) = N (d(ct), σF2)	(14)
where in our case, d(ct) = ct .
D.3 CaLFADS generative model
To tie LFADS and our observation model for calcium fluorescence together, we will adjust the
notation slightly to make the hierarchical positioning of latent variables clearer. The variables of
the deeper-level model of LFADS are denoted by the subscript l = 2, whereas the variables of the
shallower-level model of observed calcium fluorescence are denoted by the subscript l = 1. For
consistency and notation simplicity, we denote variables that are the state ofa dynamical system by
gl,t and inputs to the dynamical system as ul,t.
We observe neural activity x in the form of single-trial calcium fluorescence traces. We assume that
fluorescence follows a simple autoregressive process gl=1 perturbed by an unknown set of spike
counts ul=1 and subject to additive white emissions noise. We also assume that spike counts ul=1
are influenced by the state of a nonlinear dynamical system with unknown initial conditions gl=2,t=0
and unknown inputs ul=2 .
As in LFADS, the nonlinear dynamical system is modelled by a GRU. The hidden state of the GRU
gl=2,t is projected to a low-dimensional set of factors ft
P(g2,0)= N (μg2,o eg2,。)	(15)
P(U2,I)= N(μu2 ,σ22)	(16)
-1	-1
P(U2,t|u2,t-1) = N (μu2 + e τu2 (U2,t-1 - μu2 ), σU2(I - e τu2))	(17)
g2,t = GRU (gl,t-1, U2,t)	(18)
ft = Wf g2,t + bf	(19)
For spike counts to be informed by the dynamic factors ft , we sample spike counts according to
Zt 〜P(zt) = N(μz,σZ)	(20)
U1,t = ReLU (exp(Ws[zt, ft] +bs) - 1)	(21)
using the continuous approximation to spike counts described in section D.2.
Although this factorization separates the generation of approximate spikes counts from the dynamic
latent factors, for the formulation of the loss function we treat U1,t as if it is generated from a
homogeneous Poisson process with intensity λt = exp(Wλft + bλ), i.e.,
P(uι,t∣λt) ≈ Poisson(λt)
(22)
We then use these approximated spikes counts to perturb the state gl=1,t ofan AR(1) process
g1,t = g1,t-1(1 - β) + αU1,t	(23)
The likelihood of the observed fluorescence in a given time bin xt is then modelled as normal
random variable with a mean dependent on the state of the AR(1) process.
P(xt |g1,t) =N(d(g1,t),σx2)	(24)
where again d(∙) is an optional function modelling dye kinetics. In our case d(gι,t) = gι,t.
16
Under review as a conference paper at ICLR 2021
D.4 CaLFADS inference network
The inference network of CaLFADS parameterises the approximate posterior distributions
Q(g2,0|x), Q(u2,t|x) and Q(z|x). As per the ladder architecture (Zhao et al., 2017) these poste-
rior distributions take the form
Q(z|x) = qθ(pφ(x))	(25)
Q(u2,0|x) = rψ(pφ(x))	(26)
where p(∙), q(∙), r(∙) are neural networks parameterised by φ, θ, ψ respectively. The Combina-
tion of latent space factorization and parameter sharing ensures that dynamics can be disentangled
effectively.
As in LFADS, the approximate posterior distribution over the initial conditions to the nonlinear
dynamical system Q(g2,0) is parameterised separately using a bidirectional Gated Recurrent Unit
Q(g2,o|X)= Ng2,。,σg2,0)	(27)
μg2,0 = Wμg2,0hg2,0 + bμg2,0	(28)
σg2,0 = exp(1 Wσg2,0 hg2,0 + bσg2,0)	(29)
where hg2,0 is the final hidden state of a bidirectional Gated Recurrent unit
hg2,0 = [hgT2,0,fwd, hg02,0,bwd]	(30)
htg2,0 = BiGRU(htg-2,10,Xt)	(31)
= GRU ([htg-2,10,f wd, htg+2,10,bwd], Xt)	(32)
where htg2,0,fwd is the state of a GRU running forward sequentially over the input, and htg2,0,bwd is
the state of a GRU running backward sequentially over the data.
The functions fφ (∙), gθ(∙), hψ (∙) are modelled by pairs of recurrent neural networks. AsinLFADS,
we use bidirectional GRUs followed by unidirectional controller GRUs receiving representations
from the generative network. The bidirectional GRU is defined as before
h1u,t = BiGRU(h1u,t-1,Xt)	(33)
h2u,t = BiGRU(h2u,t-1,h1,t)	(34)
From this point the inference model splits into the two levels of the hierarchy. The hidden state htu
is passed through the a controller GRU which takes feedback from the generated samples
c1,t = GRU (c1,t-1, [h1u,t, ut-1])	(35)
c2,t = GRU(c2,t-1, [h2u,t,ft-1])	(36)
The states of the controller GRU are then linearly transformed onto the parameters of a normal
distribution
Q(ZtIX) = N (μzt ,σ2t)	(37)
Q(U2,t|x) = N (μ2,t,σ2,t)	(38)
μzt = Wμz cι,t + bμz	(39)
σzt =exp(2 Wσz cι,t + bσz)	(40)
μu2,t = Wμu2 c2,t + bμu2	(41)
σu2,t =exp(1 Wσu2 c2,t + bσu2)	(42)
17
Under review as a conference paper at ICLR 2021
D.5 CaLFADS loss function
To construct the cost function of CaLFADS, we start from the evidence lower bound (ELBO)
P(x)
≥ Ez,u2,g2,0〜Q(z,U2,g2,0∣x) [log P (x,Ul∣X,λ)]	(43)
- DKL(Q(z,u2,g2,0|x)||P(z,u2,g2,0))
= -LELBO
where X denotes the observed data and X denotes the reconstructed data.
With our model, this factorises as
-LELBO = Ez,U2,g2,0~Q(z,U2,g2,o|x)[log P(XIX)]	(44)
EU2,g2,0~Q(Z,U2,g2,o|x) [lOg P (U1 N]
-	DKL(Q(u2,g2,0|X)||P(u2,g2,0))
-	DKL(Q(z|X)||P(z))
Since u1,t is a continuous random variable that we are treating as if it came from an independent,
homogeneous Poisson process with parameter λt , we approximate the log-likelihood with
log P (uι∣λ) = X log P (uι,t∣λt)	(45)
≈	u1,t log λt - λ - u1,t = -Lspike	(46)
t
This approximation is very similar to the true log-likelihood of a Poisson distribution. The key
difference is that the log-factorial term over the observations is replaced with the identity over the
observations, i.e., log u1,t! ≈ u1,t. In deep learning applications, the log-factorial is often dropped
entirely from the Poisson log-likelihood (see e.g., the Pytorch implementation and default setting2).
It is sometimes replaced with a shifted log-gamma function log k! ≈ log Γ(k + 1) or an approxi-
mation via Stirling,s formula log k! ≈ 1 log 2πk. Since Stirling,s formula blows UP near zero, and
since log-gamma function has a local minimum between zero and one we decided against using
these.
However, we observe that this term helPs to enforce sParsity in the observations. Since this is
desirable for inferred sPike counts, we rePlace this term with what is essentially the L1 norm of u1,t,
since by construction u1,t is forced to be Positive.
The remaining terms of the ELBO were not aPProximated in any sPecial way. As such we breakdown
LELBO as follows,
Lrecon = - EZ,U2,g2,0~Q(Z,U2,g2,0 |x) [log P (XIx)]	(47)
KL1 = DKL(Q(z|x)||P (z))	(48)
KL2 = DKL(Q(u2 , g2,0Ix)IIP(u2 , g2,0))	(49)
The final cost function of CaLFADS becomes
LCaLF ADS = Lrecon + Lspikes + wKL1 LKL1 + wKL2 LKL2	(50)
where wKL1 and wKL2 are KL warmuP terms that are tyPically used in training variational au-
toencoders. These terms slowly transition the model from a traditional autoencoder to a variational
autoencoder, which helPs to Prevent Pathological behaviour where the KL terms are minimised too
early in training. This tyPically results in the model then generating trivial solutions. In our case, we
use a staggered KL warm-uP in which wKL1 linearly increases from 0 to 1 over ePochs 0-100, then
wKL2 linearly increases from 0 to 1 over ePochs 100-200. This allows the model to converge to a
solution that overfits sPikes to the fluorescence data first, then gradually regularises this ProPosed
set of sPikes by ensuring they are well exPlained by the low-dimensional latent factors.
2https://pytorch.org/docs/stable/generated/torch.nn.PoissonNLLLoss.html
18
Under review as a conference paper at ICLR 2021
E CaLFADS Directed Acyclic Graph
Figure S1: Directed acyclic graph for hierarchical model. Solid arrows denote deterministic map-
pings, open arrows denote sampling steps.
19
Under review as a conference paper at ICLR 2021
F CaLFADS forward method pseudocode
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
Algorithm 1: Forward method for CaLFADS
ForWard;
Input : Fluorescence (dF/F) traces x with dimensions TxN
Output: Denoised dF/F x, Inferred spike train uι,t, Inferred dynamic factors f
[hlf=w0,t=1:T , hlb=w0d,t=1:T] = xt=1:T
for t — 1 to T do
for l - 1 to 2 do
fwd	fwd fwd bwd
hl,t = GRU (h2,t-1, [h1,t , E1,t ])
bwd	bwd	fwd bwd
hl,T -t = GRU (h2,T -t+1, [h1,T-t, h1,T-t])
end
end
μg2,t=0 = Denseahf,w+ι, h2w0d])
σg2,t=0 = exp(0.5Dense([hf2,wTd+1, hb2w,0d]))
g2,t=0 〜N(μg2,t=o ,σg2,t=0)
ft=0 = Dense(g2,t=0)
for t — 1 to T do
c1,t = GRU(c1,t-1, [h2u,,tfwd, h2u,,tbwd, u1,t-1])
c2,t = GRU(c2,t-1, [hlu,,tfwd, h2u,,tbwd, ft-1])
μu2,t = Dense(C21
σu22,t = exp(Dense(c2,t))
u2,t ~N(μu2,t ,σ22,t )
g2,t = GRU (g2,t-1, u2,t)
ft = Dense(g2,t)
λt = exp(0.5Dense(ft))
μzι,t = Dense(Cι,t)
σz21,t = exp(0.5Dense(c1,t))
zι,t 〜N(μzι,t ,σZ1,t)
u1,t = ReLU(exp(Dense([z1,t, ft]) - 1))
g1,t = AR1(g1,t-1, u1,t)
Xt = DyeKinetiCs (g 1 ,t)
end
20
Under review as a conference paper at ICLR 2021
1
2
3
4
5
6
7
G CaLFADS loss function pseudocode
Algorithm 2: Loss function for CaLFADS
CaLFADS Loss FUnction;
Input : Fluorescence (dF/F) traces x, reconstructed dF/F x, Intensity function λ, Inferred
spikes uι, Posterior distribution [〃g2,t=°,©g?*=。, 〃密,，，b”?"，〃z,, σzj
Output: Loss L
Lrecon = -Ez 〜Q(z∣x)[logP (XIx)]
Lspike =-Ez,g2,U2~Q(z,g2,U2 |x) [lθg(u1 lλ)]
LKL1 = w1DKL(Q(z|x)|P(z))
LKL? = w2DKL(Q(g2, u2|x)|P(g2, u2))
L
Lrecon
return L
+ Lspike + LKL1 + LKL?
21
Under review as a conference paper at ICLR 2021
H Synthetic Data Generation
As discussed in the main text, synthetic calcium fluorescence data was generated by embedding a
Lorenz Attractor in the dynamics of a spiking neural network. Two models of calcium dynamics
were then used to transform spikes to calcium transients, with additive emissions noise added to the
resulting traces.
The Lorenz Attractor is a nonlinear dynamical system with 3 states x1, x2, x3 commonly used to
study chaotic dynamics. The dynamical system is defined by,
dx1 	= dt	σ(x2 - x1)		(51)
dx2 	= dt	= x1(ρ	- x3) - x2	(52)
dx3 	= dt	x1x2	- βx3.	(53)
(54)
This system was parameterised in its typical chaotic regime with σ = 10, β = 8/3, ρ = 28. These
states were then normalised to have a mean of zero and a range of [-1, 1].
The state of this system x was then randomly projected onto the firing rate of a population ofN = 30
neurons,
λt = exp(Wxt + b)	(55)
with W 〜N(0, √= I), and b = 1. Spike counts in time-bin t for neuron i Si were then sampled
using a Poisson distribution
Si,t 〜Poisson(λi,t∆t	(56)
where ∆t is the width of a time-bin. For our simulations, we used ∆t = 0.1s.
Calcium fluorescence traces were then modelled in one of two ways. The first method modelled
calcium concentration in neuron i ci as an exponentially decaying variable with time constant τ =
0.3 and perturbations by spikes
dc
dt
-ci
------+ si.
τ
(57)
Fluorescence was then modelled by adding white emissions noise with standard deviation σF = 0.2.
Ft = Ct + Et	E 〜N(0,σF)
(58)
The second method for generating synthetic calcium traces added an intermediary step between
calcium influx and observed fluorescence. As previously, spikes were integrated with a slow-varying
exponentially decaying variable cas described in Equation 57. A hill function was used to capture
the nonlinear binding kinetics of calcium to the indicator dye,
dt
Cn
1+ YCn
(59)
with hill coefficient n = 2, and γ = 0.0001. These parameters were chosen based on parameter fits
in Deneux et al. (2016). Finally white noise was added to these resulting traces to provide synthetic
fluorescence traces,
Ft = dt + Et
E 〜N(0, σF)
(60)
22
Under review as a conference paper at ICLR 2021
I CaLFAD S example outputs and scatter plots on synthetic
BENCHMARK DATASETS
I.1	Lorenz Attractor: Linear Calcium Model
CaLFADS Example Output
ɑ Time (s) ɪθ
ɑ Time (s) ɪɑ
° Reconstruction ə
-1 Reconstruction ɪ
OASIS+LFADS Example Output
Au.≥p 4。CWnou, 一 ds
E12£n」l
- 1 Reconstruction 12
G Spike Counts
9 1
Figure S2(Top), S3(Bottom): Example traces of A) Observed Fluorescence, B) Spike Rates, C)
Spike Counts, D) Dynamic Factors. Red: Ground-truth, Blue: Reconstructed. Scatter plots compar-
ing reconstructed and ground-truth of E) Observed Fluorescence, F), Spike Rates, G) Spike Counts,
H) Lorenz State
Figure S2 shows examples of the performance of CaLFADS in reconstructing the fluorescence traces
(Fig S2A), spike rates (Fig S2B), spike counts (Fig S2C) and Lorenz attractor states (Fig S2D) when
using a linear model of synthetic calcium dynamics. Visually, it can be seen that the model achieves
a very close fit to the fluorescence traces, spike rates, and Lorenz dynamics. The model also captures
spike-timing, with these spike trains appearing smoothed.
For comparison, Figure S3 show examples of OASIS+LFADS reconstructions. A key difference is
that the spike counts are not smooth as spike counts are discretised from the deconvolved transient
amplitudes, and there is greater variance in reconstruction quality at high spike rates as shown by
23
Under review as a conference paper at ICLR 2021
the scatter plot in Figure S3F. Nevertheless, OASIS+LFADS also provides a good fit to fluorescence
traces, spike rates, spike counts and lorenz dynamics.
I.2	Lorenz Attractor: Nonlinear Calcium Model
Reconstruction
Figure S4(Top), S5(Bottom): Example traces of A) Observed Fluorescence, B) Spike Rates, C)
Spike Counts, D) Dynamic Factors. Red: Ground-truth, Blue: Reconstructed. Scatter plots compar-
ing reconstructed and ground-truth of E) Observed Fluorescence, F), Spike Rates, G) Spike Counts,
H) Lorenz State
Figure S4 shows examples of the performance of CaLFADS in reconstructing the fluorescence traces
(Fig S4A), spike rates (Fig S4B), spike counts (Fig S4C) and Lorenz attractor states (Fig S4D) when
using a nonlinear model to generated synthetic calcium traces. As with the linear calcium model,
it can be seen that the model achieves a close reconstruction of to the Lorenz dynamics. However,
the reconstructions of other network variables have deteriorated to a much greater extent. A similar
trend can be seen in Figure S5 for OASIS+LFADS.
24
Under review as a conference paper at ICLR 2021
J Mouse VisP dataset, decoding network and example factors
CaLFADS example output
OASIS+LFADS example output
Sp
α>ti4 Λ4>:PV Λi>-d< A±∙>t5v
Time (s)
B
Figure S6(Top), S7(Bottom): A) 6 samples of actual and reconstructed fluorescence traces (S6A,
left column) and 6 samples of fluorescence traces (S6A right column and S7A), B) 6 samples of
inferred spike count traces corresponding to the fluorescence traces in A (right column, for S6A),
C) 12 samples of inferred latent factor traces.
J.1 Mouse VisP dataset
The 2-photon calcium imaging data used here is part of the OpenScope project dataset (Anonymous,
2018), collected by the Allen Institute for Brain Science (AIBS) in Seattle, WA. All animal proce-
dures were approved by the Institutional Animal Care and Use Committee at the AIBS. Neuronal
activity was recorded in head-fixed, awake Cux2-Cre mice on a running wheel (de Vries et al., 2020)
(Fig 3A) expressing the calcium indicator GCamP6f (Chen et al., 2013) in layer 2/3 pyramidal cells
of VisP (Fig 3B). The mice were first habituated to a repeating, expected stimulus over 6 days, after
which unexpected trials were introduced. The stimuli were adapted from (Homann et al., 2017). In
each expected trial, 4 consecutive sets of 30 Gabor patches appeared in sequence for 300 ms each,
followed by 300 ms of grey screen (A, B, C, D, grey). For each set, the locations and sizes of the
25
Under review as a conference paper at ICLR 2021
Gabor patches were held constant within a session. However, within each trial, each Gabor patch’s
orientation was sampled from a von Mises distribution, with trial mean sampled from {0, 45, 90,
135}° and standard deviation 0.25°. In expected trials, occurring 10% of the time, the D set was
replaced with a distinct set E, with its own locations and sizes. In addition, the Gabor patch orien-
tations for E sets were sampled from a von Mises distribution with mean shifted positively by 90°
(Fig 3C). Processed fluorescence (dF/F) traces were extracted from the calcium imaging recordings
for the putative neurons identified, as described in (de Vries et al., 2020).
J.2 Mouse VisP data: example outputs
Figures S6 and S7 show samples of actual fluorescence traces (A), the corresponding inferred spike
count traces (B), and inferred latent factors (C) generated as the output of the CaLFADS and OA-
SIS+LFADS models, respectively. Figure S6A additionally shows examples of reconstructed and
actual fluorescence traces (A, left column). As can be seen in the figures, the inferred latent factors
of CaLFADS are smoother and less noisy compared to those of the OASIS+LFADS. This is impor-
tant as the quality of the inferred factors is crucial for decoding purposes, such as the classification
task described in Appendix J.3.
J.3 Mouse VisP decoding network and example factors
Figure S7: Schema of the non-linear model trained to decode expected vs. unexpected stimulus
trials. Example latent factors inferred by CaLFADS are plotted for an expected (blue) and an unex-
pected (red) trial. Each stimulus frame (A, B, C, D/E, grey) is labelled, and its onset and offset in
the trial are marked with dotted lines. Latent factors are passed through GRU and linear modules
(green), followed by a sigmoid decision function.
Figure S7 shows a schematic of the non-linear model used to decode from the latent factors whether
a trial contained an expected or unexpected frame (decoding performances reported in Fig 3D). In
short, the non-linear decoder comprised of a single-layer GRU, followed by a linear layer and a
sigmoid decision function. We show an example set of latent factors (Figure S7 left) inferred in
expected (blue) and unexpected (red) trials. From these, one can see that CaLFADS was able to
infer smooth latent factors from the calcium imaging data that did not show signs of over-fitting to
noise.
26