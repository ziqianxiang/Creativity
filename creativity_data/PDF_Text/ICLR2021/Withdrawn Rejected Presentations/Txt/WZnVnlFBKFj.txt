Under review as a conference paper at ICLR 2021
Federated Learning With Quantized Global
Model Updates
Abstract
We study federated learning (FL), which enables mobile devices to utilize
their local datasets to collaboratively train a global model with the help of
a central server, while keeping data localized. At each iteration, the server
broadcasts the current global model to the devices for local training, and
aggregates the local model updates from the devices to update the global
model. Previous work on the communication efficiency of FL has mainly
focused on the aggregation of model updates from the devices, assuming
perfect broadcasting of the global model. In this paper, we instead consider
broadcasting a compressed version of the global model. This is to further
reduce the communication cost of FL, which can be particularly limited
when the global model is to be transmitted over a wireless medium. We
introduce a lossy FL (LFL) algorithm, in which both the global model and
the local model updates are quantized before being transmitted. We ana-
lyze the convergence behavior of the proposed LFL algorithm assuming the
availability of accurate local model updates at the server. Numerical ex-
periments show that the proposed LFL scheme, which quantizes the global
model update (with respect to the global model estimate at the devices)
rather than the global model itself, significantly outperforms other exist-
ing schemes studying quantization of the global model at the PS-to-device
direction. Also, the performance loss of the proposed scheme is marginal
compared to the fully lossless approach, where the PS and the devices
transmit their messages entirely without any quantization.
1	Introduction
Federated learning (FL) enables wireless devices to collaboratively train a global model by
utilizing locally available data and computational capabilities under the coordination of a
parameter server (PS) while the data never leaves the devices McMahan & Ramage (2017).
In FL with M devices the goal is to minimize a loss function F(θ) = EM=I BmFm (θ) with
respect to the global model θ ∈ Rd, where Fm (θ) = B1— Eu∈b f (θ, U) is the loss function
at device m, with Bm representing device m's local dataset of size Bm, B，EM=I Bm, and
f (∙, ∙) is an empirical loss function. Having access to the global model θ, device m utilizes
its local dataset and performs multiple iterations of stochastic gradient descent (SGD) in
order to minimize the local loss function Fm (θ). It then sends the local model update to the
server, which aggregates the local updates from all the devices to update the global model.
FL mainly targets mobile applications at the network edge, and the wireless communication
links connecting these devices to the network are typically limited in bandwidth and power,
and suffer from various channel impairments such as fading, shadowing, or interference;
hence the need to develop an FL framework with limited communication requirements be-
comes more vital. While communication-efficient FL has been widely studied, prior works
mainly focused on the devices-to-PS links, assuming perfect broadcasting of the global model
to the devices at each iteration. In this paper, we design an FL algorithm aiming to reduce
the cost of both PS-to-device and devices-to-PS communications. To address the importance
of quantization at the PS-to-device direction, we highlight that some devices simply may
not have the sufficient bandwidth to receive the global model update when the model size is
relatively large, particularly in the wireless setting, where the devices are away from the base
station. This would result in consistent exclusion of these devices, resulting in significant
performance loss. Moreover, the impact of quantization in the device-to-PS direction is less
severe due to the impact of averaging local updates at the PS.
1
Under review as a conference paper at ICLR 2021
Related work There is a fast-growing body of literature on the communication efficiency
of FL targeting restricted bandwidth devices. Several studies address this issue by consid-
ering communications with rate limitations, and propose different compression and quan-
tization techniques Konecny et al. (2016); McMahan et al. (2017); Konecny & Richtarik
(2018); Dowlin et al. (2016); Konecny et al. (2015); Lin et al. (2018b); He et al. (2018); M.
M. Amiri & Giinduz (2020), as well as performing local updates to reduce the frequency
of communications from the devices to the PS Lin et al. (2018a); Stich (2019). Statisti-
cal challenges arise in FL since the data samples may not be independent and identically
distributed (iid) across devices. The common sources of the dependence or bias in data
distribution are the participating devices being located in a particular geographic region,
and/or at a particular time window P. Kairouz et al. (2019). Different approaches have
been studied to mitigate the effect of non-iid data in FL McMahan et al. (2017); Hsieh et al.
(2019); Li et al. (2020a); Wang et al. (2020); Eichner et al. (2019); Zhao et al. (2018). Also,
FL suffers from a significant variability in the system, which is mainly due to the hardware,
network connectivity, and available power associated with different devices Li et al. (2019).
Active device selection schemes have been introduced to alleviate significant variability in
FL systems, where a subset of devices share the resources and participate at each iteration
of training Kang et al. (2019); Nishio & Yonetani (2019); Amiri et al. (2020b); Yang et al.
(2020; 2019). There have also been efforts in developing convergence guarantees for FL
under various scenarios, considering iid data across the devices Stich (2019); Wang & Joshi
(2019); Woodworth et al. (2019); Zhou & Cong (2018); Koloskova et al. (2020), non-iid data
Koloskova et al. (2020); Li et al. (2020a); Haddadpour & Mahdavi (2019); Li et al. (2020c),
participation of all the devices Khaled et al. (2020); Wang et al. (2019); Yu et al. (2018);
Huo et al. (2020), or only a subset of devices at each iteration Li et al. (2020b); Karimireddy
et al. (2020); Rizk et al. (2020); Li et al. (2020c); Amiri et al. (2020a), and FL under limited
communication constraints Amiri et al. (2020a); Recht et al. (2011); Alistarh et al. (2018).
FL with compressed global model transmission has been studied recently in Caldas et al.
(2019); Tang et al. (2019) aiming to alleviate the communication footprint from the PS to
the devices. The global model parameters are relatively skewed/diverse and the efficiency
of quantization diminishes significantly when the peak-to-average ratio of the parameters is
large. To overcome this, in Caldas et al. (2019) the PS first employs a linear transform in
order to spread the information of the global mo del vector more evenly among its dimensions,
and broadcasts a quantized version of the resultant vector, and the devices apply the inverse
linear transform to estimate the global model. We highlight that this approach requires
a relatively high computational overhead due to employing the linear transform at the
PS and its inverse at the devices, where this overhead grows with the size of the model
parameters. Furthermore, the performance evaluation in Caldas et al. (2019) is limited
to the experimental results On the other hand, in Tang et al. (2019) the PS broadcasts
quantized global model with error accumulation to compensate the quantization error.
Our contributions With the exception of Caldas et al. (2019); Tang et al. (2019), the
literature on FL considers perfect broadcasting of the global model from the PS to the
devices. With this assumption, no matter what type of local update or device-to-PS com-
munication strategy is used, all the devices are synchronized with the same global model
at each iteration. In this paper, we instead consider broadcasting a quantized version of
the global model update by the PS, which provides the devices with a lossy estimate of
the global mo del (rather than its accurate estimate) with which to perform local training.
This further reduces the communication cost of FL, which can be particularly limited for
transmission over a wireless medium while serving a massive number of devices. Also, it
is interesting to investigate the impact of various hyperparameters on the performance of
FL with lossy broadcasting of the global model since FL involves transmission over wire-
less networks with limited bandwidth. We introduce a lossy FL (LFL) algorithm, where
at each iteration the PS broadcasts a compressed version of the global model update to all
the devices through quantization. To be precise, the PS exploits the knowledge of the last
global model estimate available at the devices as side information to quantize the global
mo del update. The devices recover an estimate of the current global model by combin-
ing the received quantized global model update with their previous estimate, and perform
local training using their estimate, and return the local mo del updates, again employing
2
Under review as a conference paper at ICLR 2021
quantization. The PS updates the global model after receiving the quantized local model
updates from the devices. We provide convergence analysis of the LFL algorithm investigat-
ing the impact of lossy broadcasting on the performance of FL. Numerical experiments on
the MNIST and CIFAR-10 datasets illustrate the efficiency of the proposed LFL algorithm.
We observe that the proposed LFL scheme, which leads to a significant communication cost
saving, provides a promising performance with no visible gap to the performance of the
fully lossless scenario where the communication from both PS-to-device and device-to-PS
directions is assumed to be perfect. Also, it is illustrated that the proposed LFL scheme
significantly outperforms the schemes introduced in Caldas et al. (2019) and Tang et al.
(2019) considering compression from the PS to devices.
The proposed LFL algorithm differs from the approaches in Caldas et al. (2019); Tang et al.
(2019), since we propose broadcasting the global model update, with respect to the previous
estimate at the devices, rather than the global model itself. We remark that the global model
update has less variability/variance and peak-to-average ratio than the global model (see
Figure 2), and hence, for the same communication load, the devices can have a more accurate
estimate of the global model. However, this would require all the devices to track the global
model at each iteration, even if they do not participate in the learning process by sending
their local update. We argue that broadcasting the global model update to the whole
set of devices, rather than a randomly chosen subset, would introduce limited additional
communication cost as broadcasting is typically more efficient than sending independent
information to devices. Moreover, in practice, the subset of participating devices remain
the same for a number of iterations, until a device leaves or joins. Our algorithm can easily be
adopted to such scenarios by sending the global model, rather than the model update, every
time the subset of devices changes. Also, compared to the approach in Caldas et al. (2019),
the LFL algorithm requires a significantly smaller computational overhead. Furthermore,
unlike Caldas et al. (2019), we provide an in-depth convergence analysis of the proposed LFL
algorithm. The advantage of the proposed LFL algorithm over the approaches introduced in
Caldas et al. (2019); Tang et al. (2019) is shown numerically, where, despite its significantly
smaller communication load, it provides considerably higher accuracy.
Notation The set of real numbers is denoted by R. For x ∈ R, |x| returns the absolute
value of x. For a vector of real numbers x, the largest and the smallest absolute values
among all the entries of x are represented by max {|x|} and min {|x|}, respectively. For an
integer i, we let [i]，{1, 2,...,i}. The 12-norm of vector X is denoted by ∣∣x∣∣2∙
2	Lossy Federated Learning (LFL) Algorithm
We consider a lossy PS-to-device transmission, in which the PS sends a compressed version
of the global model to the devices. This reduces the communication cost, and can be
particularly beneficial when the PS resources are limited, and/or communication takes place
over a constrained bandwidth medium. We denote the estimate of the global model θ(t) at
the devices by θ(t), where t represents the global iteration count. Having recovered θ(t), the
devices perform a τ -step SGD with respect to their local datasets, and transmit their local
mo del updates to the PS using quantization while accumulating the quantization error.
2.1	Global Model Broadcasting
In the proposed LFL algorithm, the PS performs stochastic quantization similarly to the
QSGD algorithm introduced in Alistarh et al. (2017) with a slight modification to broadcast
the information about the global model to the devices. In particular, at global iteration t,
the PS aims to broadcast the global model update θ(t) - θ(t - 1) to the devices. We present
the stochastic quantization technique we use, denoted by Q(∙, ∙), in Appendix A.
Lemma 1. For the quantization function φ (x,q) and vector Q(X,q) given in (21b) and
(22), respectively, we have
Eφ [φ(χ,q)] = χ, Ejφ2(χ,q)] ≤ X2 + 1 /(4q2),	(1a)
E. [Q(χ,q)] = x, EjIlQ(X,q)∣∣2] ≤ ∣∣χ∣∣2 + εd∣∣χ∣∣2 /(4q2),	(1b)
3
Under review as a conference paper at ICLR 2021
Algorithm 1 LFL
1:	for t = 0, . . . , T - 1 do
• Global model broadcasting
2:	PS broadcasts Q(θ(t) — θ(t — 1), qι)
3:	θ(t) = θ(t — 1) + Q(θ(t) — θ(t — 1), qι)
• Local update aggregation
4:	for m = 1, . . . , M in parallel do
5:	Device m transmits Q(∆θm(t) + δm(t), q2) = Q(θ^+1(t) — θ(t) + δm(t), q2)
6:	end for
7:	θ(t +1)= ^t) + ΣM=1 BmQam (t) + δm (t), q2)
8:	end for
where EW represents expectation with respect to the quatization function φ (∙, ∙), and 0 ≤ ε ≤
1 is defined as ε，(max {|x|} — min {∣x∣})2 / ∣∣x∣∣2 ■
The proof of Lemma 1 is provided in Appendix B. We highlight that the value of ε depends
on the skewness of the magnitudes of the entries of x, where it increases for a more skewed
entries with a higher variance. We have ε = 0, if and only if all the entries of x have the
same magnitude, and ε = 1, if and only if x has only one non-zero entry.
Given a quantization level q 1, the PS broadcasts Q(θ(t) — θ(t — 1), q 1) to the devices at
global iteration t. Then the devices obtain the following estimate of θ(t):
θ( t ) = θ( t — 1)+ Q(θ( t) — θ( t — 1), q 1),	(2)
which is equivalent to θ(t) = θ(0) + Et==1 Q(θ(i) — θ(i — 1), q 1), where we assumed that
^Λ/∕^ι∖	Λ /∕^ι∖ TIT	j Jl Jl	∙	j 1 1	1 1	C J 1	1	1	Z-⅜ / Λ / ∙∖ ^Λ / ∙
θ(0) = θ(0). We note that, having the knowledge of the compressed vector Q θ(i) — θ(i —
1), q 1), ∀i ∈ [t], the PS can also track θ(t) at each iteration.
2.2 Local Update Aggregation
ArI	♦公/，、1♦	c	j ι	ICr^'4cι	j ι ∙ j ι j	ι
After recovering θ(t), device m performs a τ -step local SGD, where the i-th step corresponds
to θm+1(t) = θm(t)— ηm(t)▽ Fm (θm(t),ξm(t)), i ∈ [τ], Where θm(t) = θ(t), and ξm(t)
denotes the local mini-batch chosen uniformly at random from the local dataset Bm . It
then aims to transmit local model update ∆θm (t) = θm+1 (t) — θ(t) through quantization
with error compensation and transmits Q ∆θm(t) + δm(t), q2 using a quantization level
q2, where δm (t) retains the quantization error, and is updated as
δ m (t +1)= ∆θ m (t) + δ m (t) — Qa m (t) + δ m (t), q 2) ,	(3)
where we set δm(0) = 0. Having received Q ∆θm(t) + δm(t), q2 from device m, ∀m ∈ [M],
the PS updates the global model as
θ( t +1)= θ( t) + 工 M= 1 Bmm Q(∆θ m (t) + δ m (t), q 2) .	(4)
Algorithm 1 summarizes the proposed LFL algorithm.
Remark 1. We do not consider error compensation at the PS with LFL since we have ob-
served performance degradation numerical ly when compensating the quantization error at the
PS. We argue that LFL natural ly accumulates the quantization error at the PS since it sends
the quatized global model update with respect to the last global model estimate at the devices.
We further highlight that the proposed approach is not limited to any specific quantization
technique, and any compression technique can be used within the proposed framework.
3	Convergence Analysis of LFL Algorithm
Here we analyze the convergence behaviour of LFL, where for simplicity of the analysis,
we assume that the devices can transmit their local updates, aθm(t), ∀m, accurately/in a
lossless fashion to the PS, and focus on the impact of lossy broadcasting on the convergence.
4
Under review as a conference paper at ICLR 2021
3.1	Preliminaries
We denote the optimal solution minimizing loss function F(θ) by θ*, and the minimum loss
as F *, i.e., θ*，argmin® F (θ), and F *，F (θ*). We also denote the minimum value of the
local loss function at device m by Fm. We further define Γ，F * - E M=I Bm Fm, where
Γ ≥ 0, and its magnitude indicates the bias in the data distribution across devices.
For ease of analysis, we set ηmi (t) = η(t). Thus, the i-th step SGD at device m is given by
θm+1 (t) = θm(t)-η(t)▽ Fm(θm(t)篇(t)), «∈ [内,m∈ [m],	⑸
where θm(t) = θ(t), given in (2). Device m transmits the local model update
∆θm(t) = θτ+1(t)-。(t) = -η(t)工：=1VFm (θm(t),ξm(t)) , m ∈ [M],	(6)
and the PS updates the global model as
θ( t+1)=% t) - η (t)工 M=1 工 T=1 BBm V Fm (θ m (t), ξm (t )).	⑺
Assumption 1. The expected squared l2 -norm of the stochastic gradients are bounded, i.e.,
EJIlVFm(θm(t),ξm(t))∣∣2] ≤G2,	∀i∈ [刁,∀m∈ [m], ∀t.	⑻
Assumption 2. The loss functions F1, . . . , FM are L-smooth; that is, ∀v, w ∈ Rd,
2(Fm(V)- Fm(W)) ≤ 2〈v - W, VFm(w))+ L I∣v - w∣∣2 , ∀m ∈ [M].	(9)
3.2	Strongly Convex Loss Function
Here We provide convergence analysis assuming that the loss functions Fι,..., FM are μ-
strongly convex; that is, ∀v , W ∈ Rd ,
2( Fm (v) - Fm (w)) ≥ 2(V - W, V Fm (W)) + 〃 Ilv - w∣∣2 , ∀ m ∈ [ M ].	(10)
In the following theorem, whose proof is provided in Appendix C, we present the convergence
rate of the LFL algorithm assuming that the devices can send their local updates accurately.
Theorem 1. Let 0 < η(t) ≤ min {1, μτ }, ∀t. We have
E[l∣θ(t)-θ*∣2] ≤ (∏二4i))∣∣θ(0)-θ*∣∣2 +∑ j=0B j ∏ 1+14 i),	(IIa)
where
4	i)，1 - μη (i)(T - η (i)(T -1)),	(lib)
B(i) , (I- μη(i)(T - η(i)(T -1))) (η(i 2：：TG) εd + η2(i)(τ2 + T - I)G2
+ (i + μ(1 - η(i))) η2(i)G2T(T- 16(2T-1) + 2η(i)(T - 1)Γ,	(iic)
for some 0 ≤ ε ≤ 1, and the expectation is with respect to the stochastic gradient function
and stochastic quantization.
Corollary 1. From the L-Smoothness of the loss function, for 0 < η(t) ≤ min {1, μT }, ∀t,
and a total of T global iterations, it fol lows that
E [ F (θ( T))] - F * ≤ L E[∣∣θ( T) - θ*∣2 ]
≤L (∏T-14i)) Iθ(0) - θ*I2 + L ET- B(j) ∏T-1 4i),	(12)
2	i=0	2	j=0	i=j+1
where the last inequality fol lows from (11a). Considering η(t) = η and T = 1, we have
E [ F (θ( T))] - F * ≤ 2(1 - μη )t ∣θ(0) - θ*∣2
+ L((1 -μη)(4d) + 1)(1 - (1 -μη)T)(ηGΓ).	(13)
5
Under review as a conference paper at ICLR 2021
Asymptotic convergence analysis Here we show that, for a decreasing learning rate
over time, such that lim t →∞ η (t) = 0, and given small enough ε, lim T →∞ E [ F (θ( T))] — F * =
0. For 0 < η(t) ≤ min{1, μT}, We have 0 ≤ A(t) < 1, and limT→∞ ∩T- A(i) = 0. For
simplicity, assume η(t) = ^^, for constant values a and β. For j》0, B(j) → 0, and for
limited j values, ∩ T=-j+ι A (i) → 0, and so, according to (12), lim T →∞ E [ F (θ( T))] — F * = 0.
3.3 Non-Convex Loss Function
Next, We provide convergence guarantees of the proposed LFL scheme for L-smooth and non-
convex loss functions F1 , . . . , FM . For the non-convex case, We provide a Weaker notion of
convergence Liu & Wright ( 2015) limT→∞ E[ ∣∣VF(θ(T))∣∣2 ] → 0. In the following theorem,
We bound
T-1
t=0
η(t)
ET-1 η(t)E[ ∣VF(θ(t))∣2 ] with the proof provided in Appendix F.
1
Theorem 2. Performing the LFL algorithm for T ≥ 1 global iterations assuming that the
PS receives the local model updates accurately leads to
1	T-1
…Sη (t )E[ ∣v FO t"≤
2 F(θ(0)) — F*
2Γ
+ T E T-01 η (t)
T E T:01 η (t)
T-1
+ E^ S ()(n(t)(2T-1)L+2)εdτL
9 £
+ 2G2τL
tT=-01 η2(t)
+ L2G2(T — 1)(2T — 1) Et=0 7(t
3 E T:01 η (t)
(14)
Σ
晨1 η (t)
Choice of ε We highlight that ε appears in the convergence analysis of the LFL algorithm
in inequalities (45), (63), in which we have
E ](max {∣ S M=I S T=1 B V Fm (θm (t - 1) ,ξm (t - 1)) ∣}
-min {∣S M=IS：=iB V Fm (θ m (t - 1), ξm (t - 1)) ∣})2
≤ εE NS M:IS L B V Fm (θ m (t - 1), ξm (t - 1)) I 口,	(15)
which follows from (26b), where we note that
θ(t) -。(t - 1) = -η(t - 1) SM=1 ST=1 BvFm (θm(t - 1), ξm(t - 1)) ∙	(16)
On average the entries of θ(t) - θ(t - 1), given in (16), are not expected to have very diverse
magnitudes. Thus, the inequality in (15) should hold for a relatively small value of ε. We
have observed numerically that ε ≈ 10-3 satisfies inequality (15) for the LFL algorithm.
Impact of number of local SGD steps T For the non-convex case, assuming η(t) = η,
∀t, it is easy to verify that the upper bound on T Et=o1 E[ ∣∣VF(θ(t))∣∣2 ], given in Theorem
2, is simplified as follows:
h ( t ) =--+ a o + a ι T + a 2 T2,	(17)
T
where
a-1
a1
2(F(0)-F*+Γ)	η2L2G2
,	ητ , a o,	,
,(2-ηL)ηLG2(1+易)，a2,η2L2G2(∣+2q∣)∙
(18)
We have dh(T)/dT = -a-1 /T2 + a1 + 2a2T, where we note that a1 + 2a2 ≥ 0. For relatively
small a-1 values, particularly a-1 ≤ a1 + 2a2 , h(T) increases with T, and T = 1 minimizes
6
Under review as a conference paper at ICLR 2021
Table 1: CNN architecture for image classification on MNIST and CIFAR-10.
	MNIST			CIFAR-10	
3 × 3 convolutional layer, 32 channels, ReLU activation, same padding	3 × 3 convolutional layer, 32 channels, ReLU activation, same padding
	3 × 3 convolutional layer, 32 channels, ReLU activation, same padding
2 × 2 max pooling	
3 × 3 convolutional layer, 64 channels, ReLU activation, same padding	dropout with probability 0.2
	3 × 3 convolutional layer, 64 channels, ReLU activation, same padding
	3 × 3 convolutional layer, 64 channels, ReLU activation, same padding
2 × 2 max pooling	
3 × 3 convolutional layer, 64 channels, ReLU activation, same padding	dropout with probability 0.3
	3 × 3 convolutional layer, 128 channels, ReLU activation, same padding
	3 × 3 convolutional layer, 128 channels, ReLU activation, same padding
2 × 2 max pooling	
fully connected layer with 128 units, ReLU activation	dropout with probability 0.4
softmax output layer with 10 units	
h (T); that is, When the training is started close to the optimal solution (F (0)-F * is relatively
small), and/or η is relatively large, τ = 1 may be the best choice. On the other hand, for
relatively large a-1 values, the best τ can be the nearest integer to the positive solution of
(a1 + 2a2τ)τ2 - a-1 = 0.
4 Numerical Experiments
Here We investigate the performance of the proposed LFL algorithm for image classification
on both MNIST LeCun et al. (1998) and CIFAR-10 Krizhevsky & Hinton (2009) datasets
utilizing ADAM optimizer Kingma & Ba (2017). We consider M = 40 devices, and We mea-
sure the performance as the accuracy With respect to the test samples, called test accuracy.
Network architecture We train different convolutional neural netWorks (CNNs) With
MNIST and CIFAR-10 datasets. The architectures of these CNNs are described in Table 1.
Data distribution We consider tWo data distribution scenarios. In the non-iid scenario,
We split the training data samples With the same label (from the same class) to M/10 disjoint
subsets (assume that M is divisible by 10). We then assign each subset of data samples,
selected at random, to a different device. In the iid scenario, We randomly split the training
data samples to M disjoint subsets, and assign each subset to a distinct device. We consider
non-iid and iid data distributions While training using MNIST and CIFAR-10, respectively.
State-of-the-art approaches We consider tWo approaches With lossy broadcasting intro-
duced in Caldas et al. (2019) and Tang et al. (2019) as the state-of-the-art approaches. With
the scheme in Caldas et al. (2019), referred to as lossy transformed global model (LTGM),
the PS first employs a linear transform to project the global model. It then quantizes the
resultant vector after the linear transform, and sends the quantized vector to the devices.
The devices employ the inverse of the linear transform and use the recovered vector for
local training. As suggested in Caldas et al. (2019), We consider Walsh-Hadamrd trans-
form and employ the stochastic quantization scheme presented in Appendix A at the PS.
On the other hand, With the approach studied in Tang et al. (2019), referred to as lossy
global model (LGM), the PS directly quantizes the global model plus the quantization error
accumulated from the previous iterations and shares the quantized global model With the
devices, While updating the qunatization error. For fairness, We consider the quantization
7
Under review as a conference paper at ICLR 2021
(a) MNIST with non-iid data
Figure 1: Test accuracy using MNIST and CIFAR-10 for training with local mini-batch size
∖ξm(t)∣ = 500 and ∖ξm(t)∣ = 250, respectively.
(b) CIFAR-10 with iid data
scheme presented in Appendix A with the LGM scheme, and assume the same technique
for transmission in the device-to-PS direction introduced in Section 2.2.
Benchmark approaches We consider the performance of the lossless broadcasting (LB)
scenario, where the devices receive the current global model accurately, and perform the
quantization with error compensation approach as described in Section 2.2. We highlight
that this approach requires transmission of RLB = 33d bits from the PS, where we assume
that each entry of the global mo del is represented by 33 bits. Thus, the saving ratio in the
communication bits of broadcasting from the PS using LFL versus LB is
RLB _	33d	(a)	33
RQ	64 + d (I + log2(q 1 + I))	1 + log2(q 1 + I)
(19)
where (a) follows assuming that d》1. We further consider the performance of the fully
lossless approach, where in addition to having the accurate global model at the devices, we
assume that the PS receives the local mo del updates from the devices accurately.
In Figure 1 we illustrate the performance of different approaches for non-iid and iid scenarios
using MNIST and CIFAR-10, respectively, for training with M = 40 devices. Figure 1a
demonstrates test accuracy of different approaches for non-iid data using MNIST with local
mini-batch size ∖ξm(t) ∖ = 500 and number of local iterations T = 4. We set q2 = 2 for all
the approaches where the devices perform quantization, and q1 = 2 for the LFL and LGM
schemes. We observe that the proposed LFL algorithm with (q1 , q2) = (2, 2) performs as well
as the fully lossless and LB approaches, despite a factor of 12.77 savings in the number of bits
that need to be broadcast compared to the LB approach. This illustrates the efficiency of
the LFL algorithm for the non-iid scenario providing significant communication cost savings
without any visible performance degradation. On the other hand, the performance of the
LGM algorithm drops after an intermediate number of training iterations, which shows that
the quantization level q1 = 2 does not provide the devices with an accurate estimate of the
global mo del to rely on for local training. This is particularly more harmful in later iterations
as the algorithm approaches the optimal point where a more accurate estimate of the global
mo del is required for training. We highlight that the proposed LFL algorithm resolves this
deficiency with the LGM algorithm through quantizating the global model update rather
than the global model providing a more accurate estimate of the global mo del to the devices
even with a relatively small quantization level q1 = 2. Throughout our experiments, we
found that the random linear transform with the LTGM scheme is not highly efficient
in providing a transformed vector with a relatively small peak-to-average ratio, and the
quantization level q1 should be relatively large to guarantee that the algorithm succeeds
in learning. Therefore, we set q1 = 50 for the LTGM scheme, which is a relatively large
quantization value. The advantage of the proposed LFL algorithm over the LTGM and
LGM algorithms for the non-iid scenario can be clearly seen in the figure.
A similar observation is made in Figure 1b illustrating the perforance of different approaches
for iid data using CIFAR-10 with local mini-batch size ∖ξia (t) ∖ = 250 and number of local
iterations τ = 5. The the LFL algorithm with (q1, q2) = (5, 3) provides ×9.2 smaller com-
munication load compared to LB with q2 = 3 without any visible performance degradation
8
Under review as a conference paper at ICLR 2021
IO1
lθ-ɪ
10-3
10-5
IO-7
Peak-to-average ratio
EmPiriCaLyarianCe	一 . “
-M----*-ʌ κ- -H- LTGM -H- LGM -→- LFL
ιo2
IO0
10-2
IoT
10"«
10-β
Peak-to-average ratio
0	50	100	150	200	250	300	350	400
Global iteration count, t
(b) CIFAR-10 with iid data

0	50	100	150	200	250	300	350	400
Global iteration count, t
(a) MNIST with non-iid data
Figure 2: Empirical variance and peak-to-average ratio of the vector quantized at the PS.
with respect to the fully lossless and LB approaches. It also significantly outperforms the
LGM algorithm with (q1 , q2) = (5, 3), which shows the advantage of quantizing the global
model update rather than the global model for iid data. We also observe that the accuracy
level of the LTGM algorithm drops significantly after around 200 global iterations even for
a large quantization level q1 = 1000, which shows the deficiency of the linear transform to
provide a relatively small peak-to-average ratio for the transformed vector.
In Figure 2, we investigate the empirical variance and the peak-to-average ratio of the
vector (considering absolute values of its entries) to be quantized at the PS with different
schemes for the experimental settings used in Figure 1. This result is provided to better
justify the benefits of the proposed LFL scheme over LGM and LTGM shown in Figure
1. We observe that the global model update, which is quantized at the PS with LFL, has
significantly smaller empirical variance than the global model, which is quantized at the PS
with LGM. This justifies the improvement of LFL over LGM reflecting smaller quantization
error when quantizing the global model update rather than the global model, particularly
towards the end of training, where the empirical variance of the global model with LGM has
an increasing trend over time. Also, both the empirical variance and the peak-to-average
ratio of the transformed vector with LTGM increases over time, particularly for training on
CIFAR-10. This illustrates that the quantization error increases with time, which may be
more harmful towards the end of training while approaching the optimal solution. We note
that the relatively small empirical variance of the transformed vector with LTGM is due to
the linear transform applied at the PS which scales down the entries of the global model
vector. The relatively large peak-to-average ratio indicates that the quantized vector with
LTGM may not provide an accurate estimate of the actual transformed vector at the PS.
5 Conclusion
FL is demanding in terms of bandwidth, particularly when deep networks with huge numbers
of parameters are trained across a large number of devices. Communication is typically the
major bottleneck, since it involves iterative transmission over a bandwidth-limited wireless
medium between the PS and a massive number of devices at the edge. With the goal of
reducing the communication cost, we have studied FL with lossy broadcasting, where, in
contrast to most of the existing work in the literature, the PS broadcasts a compressed
version of the global model to the devices. We have considered broadcasting quantized
global model updates from the PS, which can be used to estimate the current global model
at the devices for local SGD iterations. The PS aggregates the quantized local model
updates from the devices, according to which it updates the global model. We have derived
convergence guarantees for the proposed LFL algorithm to analyze the impact of lossy
broadcasting on the FL performance assuming accurate local model updates at the PS.
Numerical experiments have shown the efficiency of the proposed LFL algorithm in providing
an accurate estimate of the global model to the devices, where it performs as well as the fully
lossless and LB approaches for both non-iid and iid data despite the significant reduction in
the communication load. It also significantly outperforms the LTGM Caldas et al. (2019)
and LGM Tang et al. (2019) algorithms studying compression in the PS-to-device direction
thanks to quantizing the global model update rather than the global model at the PS.
9
Under review as a conference paper at ICLR 2021
References
D. Alistarh, D. Grubic, J. Z. Li, R. Tomioka, and M. Vojnovic. QSGD: Communication-
efficient SGD via randomized quantization and encoding. In Advances in Neural Infor-
mation Processing Systems (NIPS), pp. 1709-1720, Long Beach, CA, December 2017.
D. Alistarh, T. Hoefler, M. Johansson, S. Khirirat, N. Konstantinov, and
C. Renggli. The convergence of sparsified gradient methods. [Online].
https://arxiv.org/pdf/1809.10505.pdf, September 2018.
M. M. Amiri, D. Gundiiz, S. R. Kulkarni, and H. V. Poor. Convergence of Up-
date aware device scheduling for federated learning at the wireless edge. [Online].
https://arxiv.org/pdf/2001.10402.pdf, May 2020a.
M.	M. Amiri, D. Guinduiz, S. R. Kulkarni, and H. V. Poor. Update aware device scheduling
for federated learning at the wireless edge. In Proc. IEEE International Symposium on
Information Theory (ISIT), Los Angeles, CA, USA, June 2020b.
S. Caldas, J. Konecny, H. B. McMahan, and A. Talwalkar. Expanding the
reach of federated learning by reducing client resource requirements. [Online].
https://arxiv.org/pdf/1812.07210.pdf, January 2019.
N.	Dowlin, R. Gilad-Bachrach, K. Laine, K. Lauter, M. Naehrig, and J. Wernsing. Cryp-
toNets: Applying neural networks to encrypted data with high throughput and accuracy.
In Proc. International Conference on Machine Learning (ICML), pp. 201-210, New York,
NY, USA, 2016.
H.	Eichner, T. Koren, H. B. McMahan, N. Srebro, and K. Talwar. Semi-cyclic stochastic
gradient descent. [Online]. https://arxiv.org/pdf/1904.10120.pdf, April 2019.
F.	Haddadpour and M. Mahdavi. On the convergence of local descent methods in federated
learning. [Online]. https://arxiv.org/pdf/1910.14425.pdf, December 2019.
Lie He, An Bian, and Martin Jaggi. COLA: Decentralized linear learning. In Proc. Confer-
ence on Neural Information Processing Systems (NeurIPS), Montreal, Canada, 2018.
K.	Hsieh, A. Phanishayee, O. Mutlu, and P. B. Gibbons. The non-IID data quagmire of
decentralized machine learning. [Online]. https://arxiv.org/pdf/1910.00189.pdf, December
2019.
Z. Huo, Q. Yang, B. Gu, L. Carin, and H. Huang. Faster on-device training using new
federated momentum algorithm. [Online]. https://arxiv.org/pdf/2002.02090.pdf, February
2020.
J. Kang, Z. Xiong, D. Niyato, H. Yu, Y.-C. Liang, and D. I. Kim. Incentive design for efficient
federated learning in mobile networks: A contract theory approach. In Proc. IEEE VTS
Asia Pacific Wireless Communications Symposium (APWCS), pp. 1-5, Singapore, August
2019.
S. P. Karimireddy, S. Kale, M. Mohri, S. J. Reddi, S. U. Stich, and A. T.
Suresh. SCAFFOLD: Stochastic controlled averaging for federated learning. [Online].
https://arxiv.org/pdf/1910.06378.pdf, February 2020.
A. Khaled, K. Mishchenko, and P. Richtarik. First analysis of local GD on heterogeneous
data. [Online]. https://arxiv.org/pdf/1909.04715.pdf, March 2020.
D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv:1412.6980v9
[cs.LG], January 2017.
A. Koloskova, N. Loizou, S. Boreiri, M. Jaggi, and S. U. Stich. A unified the-
ory of decentralized sgd with changing topology and local updates. [Online].
https://arxiv.org/pdf/2003.10422.pdf, March 2020.
10
Under review as a conference paper at ICLR 2021
J. Konecny and P. Richtarik. Randomized distributed mean estimation: Accuracy vs com-
munication. Frontiers in Applied Mathematics and Statistics, 4, December 2018.
J. Konecny, B. McMahan, and D. Ramage. Federated optimization: Distributed optimiza-
tion beyond the datacenter. arXiv:1511.03575 [cs.LG], November 2015.
J. Konecny, H. B. McMahan, F. X. Yu, P. Richtarik, A. T. Suresh, and D. Bacon. Federated
learning: Strategies for improving communication efficiency. In Proc. NIPS Workshop on
Private Multi-Party Machine Learning, Barcelona, Spain, 2016.
A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. In
Technical Report, University of Toronto, 2009.
Y. LeCun, C. Cortes, and C. Burges. The MNIST database of handwritten digits.
http://yann.lecun.com/exdb/mnist/, 1998.
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith. Federated learning: Challenges, methods,
and future directions. [Online]. https://arxiv.org/pdf/1908.07873.pdf, August 2019.
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith. Federated opti-
mization in heterogeneous networks. [Online]. https://arxiv.org/pdf/1812.06127.pdf, April
2020a.
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith. FedDANE: A
federated newton-type method. [Online]. https://arxiv.org/pdf/2001.01920.pdf, January
2020b.
X. Li, K. Huang, W. Yang, S. Wang, and Z. Zhang. On the convergence of FedAvg on
non-IID data. [Online]. https://arxiv.org/pdf/1907.02189.pdf, February 2020c.
T. Lin, S. U. Stich, and M. Jaggi. Don’t use large mini-batches, use local SGD. [Online].
https://arxiv.org/pdf/1808.07217.pdf, October 2018a.
Y. Lin, S. Han, H. Mao, Y. Wang, and W. J. Dally. Deep gradient compression: Reducing the
communication bandwidth for distributed training. arXiv:1712.01887v2 [cs.CV], February
2018b.
J. Liu and S. J Wright. Asynchronous stochastic coordinate descent: Parallelism and con-
vergence properties. SIAM Journal on Optimization, 25(1):351-376, 2015.
M. M. Amiri and D. Giindiiz. Machine learning at the wireless edge: Distributed stochastic
gradient descent over-the-air. IEEE Transactions on Signal Processing, 68:2155 - 2169,
April 2020.
H. B. McMahan and D. Ramage. Federated learning: Collaborative machine learning with-
out centralized training data. https://www.googblogs.com/federated-learning-col laborative-
machine-learning-without-centralized-training-data/, April 2017.
H. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas. Communication-
efficient learning of deep networks from decentralized data. In Proc. AISTATS, 2017.
T. Nishio and R. Yonetani. Client selection for federated learning with heterogeneous re-
sources in mobile edge. In IEEE International Conference on Communications (ICC),
pp. 1-7, Shanghai, China, May 2019.
P. Kairouz et al. Advances and open problems in federated learning. [Online].
https://arxiv.org/pdf/1912.04977.pdf, December 2019.
B. Recht, C. Re, S. Wright, and F. Niu. Hogwild: A lock-free approach to paralleliz-
ing stochastic gradient descent. In Advances in Neural Information Processing Systems
(NIPS), pp. 693-701, 2011.
E. Rizk, S. Vlaski, and A. H. Sayed. Dynamic federated learning. [Online].
https://arxiv.org/pdf/2002.08782.pdf, May 2020.
11
Under review as a conference paper at ICLR 2021
S. U. Stich. Local sgd converges fast and communicates little. [Online].
https://arxiv.org/pdf/1805.09767.pdf, May 2019.
H. Tang, X. Lian, C. Yu, T. Zhang, and J. Liu. DoubleSqueeze: Parallel stochastic gra-
dient descent with double-pass error-compensated compression. In Proc. International
Conference on Machine Learning (PMLR), Long Beach, CA, 2019.
J.	Wang and G. Joshi. Cooperative SGD: A unified framework for the design and analysis of
communication-efficient sgd algorithms. [Online]. https://arxiv.org/pdf/1808.07576.pdf,
January 2019.
S.	Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and K. Chan. Adaptive
federated learning in resource constrained edge computing systems. IEEE Journal on
Selected Areas in Communications, 47(6):1205-1221, June 2019.
T.	Wang, J.-Y. Zhu, A. Torralba, and A. A. Efros. Dataset distillation. [Online].
https://arxiv.org/pdf/1811.10959.pdf, February 2020.
B. Woodworth, J. Wang, A. Smith, H. B. McMahan, and N. Srebro. Graph ora-
cle models, lower bounds, and gaps for parallel stochastic optimization. [Online].
https://arxiv.org/pdf/1805.10222.pdf, February 2019.
H. H. Yang, A. Arafa, T. Q. S. Quek, and H. V. Poor. Age-based scheduling policy for fed-
erated learning in mobile edge networks. [Online]. https://arxiv.org/pdf/1910.14648.pdf,
October 2019.
H. H. Yang, Z. Liu, T. Q. S. Quek, and H. V. Poor. Scheduling policies for federated
learning in wireless networks. IEEE Transactions on Communications, 68(1):317-333,
January 2020.
H. Yu, S. Yang, and S. Zhu. Parallel restarted sgd with faster convergence and less
communication: Demystifying why model averaging works for deep learning. [Online].
https://arxiv.org/pdf/1807.06629.pdf], November 2018.
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. Fed-
erated learning with non-IID data. arXiv:1806.00582 [cs.LG], June 2018.
F. Zhou and G. Cong. On the convergence properties of a K-step averaging stochastic gradi-
ent descent algorithm for nonconvex optimization. In Proc. International Joint Conference
on Artificial Intel ligence (IJCAI), pp. 3219-3227, Stockholm, Sweden, July 2018.
12
Under review as a conference paper at ICLR 2021
A Stochastic quantization
Given x ∈ Rd, with the i-th entry denoted by xi , we define
xmax , max {|x|} ,	(20a)
xmin , min {|x|}.	(20b)
Given a quantization level q ≥ 1, we have
Q (xi, q) , sign (Xi ) ∙ (xmin + (xmax - xmin) ∙ ψ (	'	' , q)) , for i ∈ [d],	(21a)
xmax - xmin
where φ(∙, ∙) is a quantization function defined in the following. For 0 ≤ x ≤ 1 and q ≥ 1,
let l ∈ {0, 1, . . . , q - 1} be an integer such that x ∈ [l/q, (l + 1)/q). We then define
中 (x,q) , {(/+ 1)/q,
with probability 1 - (xq - l),
with probability xq - l.
(21b)
We define
Q(X, q)，[Q(χι, q),…，Q(χd, q)]T,	(22)
and we highlight that it is represented by
RQ = 64 + d (1 + log2(q + 1)) bits,	(23)
where 64 bits are used to represent xmax and xmin, d bits are used for sign(xi), ∀i ∈ [d],
and d log2(q + 1) bits represent φ ((| xj — x min)/( x max — x min) ,q), ∀ i ∈ [ d ]. We note that
we have modified the QSGD scheme proposed in Alistarh et al. (2017) by normalizing the
entries of vector X with xmax - xm® rather than ∣∣x∣∣2∙
B Proof of Lemma 1
Given φ (x, q) in (21b), we have
Eφ [ψ(x, q)] = (-) (1 + l — xq) + (--------) (xq - l) = x.
Also, we have
Eφ [φ2 (x, q)] = (一) (1 + l — xq) + (--------) (xq — l) = -2 (—l2 + 2lxq + xq — l)
=x + ( (xq — l) (1 — xq + l) ≤ x + ^^^,,
q2	4q2
(24)
(25)
where (a) follows since (xq — l) (1 — xq + l) ≤ 1/4. According to (24), (25) and the definition
of Q(X, q) given in (22), it follows that
Eφ [Q(X, q)] = X,	(26a)
Eφ[llQ(x ,q )l∣2 ]=工d- E φ [ | Q (xi,q )|2 ] = (X max - x min)2 工"- E φ ∖ ψ 2(	1 Jmin ,q)]
i=1	i=1	xmax — xmin
+ dxmin + 2xmin (xmax - xmin))： , ɪ Eφ [ψ (
≤ (xmax - xmin)2 £「]((
xmax — x
|xi | — xmi
| xi | — xmin	)]
x max - x min
+ dxmin + 2xmin): . ɪ ( | xi | - xmin )
2 + d (Xmax:Xmin)2 ≤ 同2 + εd^χ42,
2	4q2	2	4q2
(26b)
where (b) follows from (24) and (25), and (c) follows since ε = (xmax — xmin)2 / ∣∣x∣∣2.
13
Under review as a conference paper at ICLR 2021
C Proof of Theorem 1
We have
E [∣∣θ(t + 1) - θ*∣∣2] =E [∣^(t) - θ* ∣□ + EH忙M=I Tδθm(t) ∣口
+ 2E 飘t) - θ*,工M=I Bm∆θm(t)〉.	(27)
In the following, we bound the last two terms on the right hand side (RHS) of (27). From
the convexity of 小股，it follows that
E
工 M=ι Bm δθ m(t )∣∣ J ≤ 工 M=ι BmE Uδθ m (t 明
=η2 (t W M=I Bm E ]∣ 区:=” Fm (θ m(t), ξn (t)) ∣∣2 ]
≤ η2 (t) T 工 M=1 工 L Bm E ”▽ Fm (θ m (t) ,ξm (t ))∣∣2] ≤> η 2( t) τ2 G2,
where (a) follows from Assumption 1.
We rewrite the third term on the RHS of (27) as follows:
2E Mt) - θ* , ΣM=I Bmδθm (t)〉]
=2 η (t)工 m=i Bm E [(θ* - 0( t),工 L ▽ Fm (θ m (t), ξm (t ))》]
=2 η (t)工 M=1 Bm E [(θ* - θ( t) Z Fm ® t), ξm (t )))]
+2 η (t)工 m=i Bm E [<θ* - θ( t),工Ti=2 ▽ Fm (θ m (t), ξm (t ))〉].
We have
2η(t)工M=1 BmE [(θ* - θ(t) ZFm (θ(t),ξm (t))〉]
=2η(t) EM=I BmE [(θ* - θ(t)NFm(θ(t))》]
≤ 2η(t) EM=1 BmE Fm(θ*) - Fm (θ(t)) - 2 ∣∣θ(t) - θ*∣∣2
=2η(t) (F* - E [F(θ(t))] - μE[ ∣∣ θ(t) - θ*∣∣2 ])
≤ -μη(t)e[∣∣ θ(t) - θ*∣∣2],
(28)
(29)
(30)
where (a) follows since Eg [VFm (θm(t),ξm(t))] = VFm (θm(t)), Vi,m, (b) is the result of
assuming μ -strongly loss functions, and (c) follows since F * ≤ F (θ( t)), V t.
Lemma 2. For 0 < η(t) ≤ 1, we have
2 η (t) E m=1 Bm E [(θ* - θ(t), E ：=2 V Fm (θ m (t), ξm (t ))》]
≤- μη (t )(1 - η (t))(T - 1)E ∣∣θ( t) - θ*∣∣2j + η 2( t)(T - 1) G2
+ (1+ μ(1 - η(t)))η2(t)G2
τ (τ — 1)(2 τ — 1)
+ 2η(t)(T - 1)Γ.
(31)
Proof. See Appendix D.
□
6
14
Under review as a conference paper at ICLR 2021
By substituting (30) and (31) in (29), it follows that
2E
M t )-θ* ,工 m=ι T ʌθ m( t “
≤ -μη(t)(T — η(t)(T - I))E l∣θ(t) - θ
"口
+ η 2( t)(T - 1) G2
ʌ
+ (1+ μ(1 - η(t)))η2(t)G2 T(T- 1)(2T- 1 + 2η(t)(τ - 1)Γ,
(32)
which, together with the inequality in (28), leads to the following upper bound on
E [©(t + 1) — θ*∣∣2], when substituted into (27):
E Mt + 1) - θ*∣∣2]
≤ (1 - μη(t)(T - η(t)(T - 1))) E ∣^(t) - θ*∣∣2j + η2(t)(t2 + t - 1) G2
+ (1+ μ(1 - η(t)))η2(t)G2 T(T - 1)(2T - I) + 2η(t)(T - 1)Γ. (33)
Lemma 3. For θ(t) given in (2), we have
E ∣∣θ(t) - θ*∣□ ≤ E [∣∣θ(t) - θ*∣∣2] + (η(t -gI)TG)2εd.	(34)
for some 0 ≤ ε ≤ 1.
Proof. See Appendix E.	□
According to Lemma 3, the inequality in (34) can be rewritten as follows:
E [∣∣θ(t + 1) - θ*∣∣2] ≤ (1 - μη(t)(τ - η(t)(τ - 1))) E [∣∣θ(t) - θ*∣g
+ (1 - μη(t)(T - η(t)(T -1))) (η(1	:G) εd + η2(t)(τ2 + T -1)G2
2q1(t)
+ (1+ μ(1 - η(t)))η2(t)G2 T(T-皆T- I) + 2η(t)(τ - 1)Γ.	(35)
Theorem 1 follows from the inequality in (35) having 0 < η(t) ≤ min 1, V , Vt.
D Proof of Lemma 2
We have
2η(t) ∑M=I B ∑[2 E [(θ* - θ(t), ▽ Fm (%(t),媒(t))》]
=2η(t)工M=I 生工T=2 E [(θm(t) - θ(t)ZFm (θm(t), ξm(t))〉]
+2 η (t)工 M=1 Bm ∑ τ=2 e [(θ* - θ m (t) Z Fm (θ m (t), ξm (t»]. 即
We first bound the first term on the RHS of (36). We have
2 η (t)工 M=1 Bm Σ T=2 e [(θ m (t) - θ( t), ▽ Fm (θ m (t) ,ξm (t 力]
≤ η (t) Em=i B ET=2E ]志 ∣θ m (t)-做t )∣∣2+η (t) W Fm (θ m (t), ξm (t)) ∣∣2
≤Σ M=1 B E T=2E ]l∣θ m (t )-θ(t )∣□ + η 2(t)(τ - 1) G 2,	(37)
15
Under review as a conference paper at ICLR 2021
where (a) follows from Assumption 1. We have
M n r	「	2^∣
⅛ ~m^工E ∣∣θm(t)-"(t)∣∣2
m =1	i=2	L	」
=η2(t) M 与 EE ]∣忙：=”Fm (j(t)舄(t))∣∣2F) η2(t)G2TlT -臂一 1), (38)
where (b) follows from the convexity of ∣∣∙∣∣2 and Assumption 1. Plugging (38) into (37)
yields
2η(t) EM=1 B E：=2 E [<%(t) - θ(t), ▽ Fm (%(t),ξm(t))〉]
≤ η2 (t) G2 T(T - 1.2 T - I) + η2 (t)(T - 1) G2.	(39)
For the second term on the RHS of (36), we have
2η(t) EM=1 Bm E：=2 E 阿-%(t), ▽ Fm (%(t), ξm(t))》]
=2 η (t) E M=1 B E ：=2 E [<θ* -θ m (t) Z Fm (θ m (t ))》]
≤2 η (t) E M=1B E L E [ Fm (θ*) - Fm (θm (t)) - 2 ∣∣θm (t) - θ* ∣∣2]
=2 η (t) E M=I B EL2E [ Fm (θ*) - Fm + Fm - Fm (% (t)) - 21∣% (t) - θ* ∣∣2]
=2 η (t)( t - 1)γ+2 η (t) E M=1 B E ：=2 (Fm-E [ Fm (θm (t))])
-μη (t) EM=I B E ：=2E [∣∣θ m (t)- θ*∣∣2]
≤2 η (t)(τ - 1)Γ - μη (t) E M=1B E τ=2E [∣∣θ m (t) - θ* ∣∣2],	(40)
where (a) follows since Eξ [VFm (θ(t), ξm(t))] = VFm (θ(t)), Vi, m, t; (b) follows from as-
suming that the loss functions are μ-strongly convex; and (c) follows since Fm ≤ Fm(θm(t)),
Vm. We have
-∣∣θ m (t) - θ*∣∣2 = -∣∣θ m (t)-祖 t )∣∣2 -阿 t) - θ*∣∣2 - 2<% (t)-祖 t),祖 t) - θ*
(a) Il	Il2 Il	Il2	1 Il	Il2	Il	Il2
≤ - ∣∣θm (t)- θ(t )I∣2 - ∣∣θ(t)- θt+词 ∣∣θm (t)- θ(t )I∣2+η(t) μt)- θt
= -(1-η (t)) ∣∣θ(t)- θ*∣∣2 + (木-ι)∣∣θm(t)- θ t )∣∣2,	(41)
where (a) follows from Cauchy-Schwarz inequality. Plugging (41) into (40) yields
号 E M=1 E T=2 E [<θ* - θ m (t), v Fm (θ m (t) ,ξm (t ))〉]
≤ -μη(t)(1 - η(t))(τ - 1) ∣∣θ(t) - θ* ∣∣j + μ(1 - η(t))η2(t)G2 T(T-臂T- I) + 2η(t)(τ - 1)Γ,
(42)
where we used the inequality in (38) and η(t) ≤ 1. Plugging (39) and (42) into (36) completes
the proof of Lemma 2.
16
Under review as a conference paper at ICLR 2021
E Proof of Lemma 3
We have
E ∣^(t) - θ*∣∣2j = E ∣^(t)∣∣2 + E MlI2] - 2E 画t),叫
=E ∣^(t)∣∣2 + E [∣∣"∣2]- 2E[(θ(t),θ*>],	(43)
where (a) follows since
E ^(t)] = E ^(t - 1)] + E [Q(θ(t)-%t - 1), q 1)] = E [θ(t)],	(44)
where the last equality follows from (26a). In the following, we upper bound E
We have
θ(t )∣∣2
E Mt )∣∣2
=E ∣∣θ(t- 1)∣∣2] + E ∣∣Q(θ(t)- θ(t- 1),q 1)∣∣2j
+ 2E [例t - 1), Q(θ(t) - θ(t - 1),qJ〉]
≤E ]M(t - 1fl+E ]∣∣θ(t)- θ(t - 1fl+皆E
+2
≤)E [lθ( t )∣∣2] +4qdt E ∣∣θ( t) - θ( t - 1)
(45)
where (a) follows from (26) for some 0 ≤ ε(t) ≤ 1 defined as
E (max I ∣θ( t) — θ(t — 1) JI — min ∣∣θ( t) — θ(t — 1)∣})
ε (t)， -----------------r--------------⅛.--------------,
E ]∣∣θ( t) - θ( t -1)∣∣ J
noting that
ʌ	Mr J、B
θ(t) - θ(t - 1) = -η (t - 1) 工工 Bl▽ Fm (θm (t - 1) ,ξim (t - 1)),
m=1i=1
(46)
(47)
and in (b) we define ε，maxt{ε(t)}. According to (47), from the convexity of ∣∣∙∣2, it follows
that
-	2^∣	M T R
E ∣∣θ( t) - θ( t - 1)∣∣2 ≤ η 2( t - 1)工工-m e[∣∣V Fm (% (t - 1) Wm (t - 1))∣∣2]
-	」	m =1 i =1
≤ η2(t - 1)τ2G2,	(48)
where (a) follows from Assumption 1. Accordingly, (45) reduces to
E ∣∣θ(t)∣∣2 ≤ E [∣θ(t)∣2] + (η(t -qI)TG)2εd.	(49)
Substituting the above inequality into (43) yields
E ∣∣ θ(t) - θ*∣∣2j ≤ E Mt)∣2] + E [∣θ*∣2]- 2E[®t), e*〉] + (η(t -:TG)2εd
=E [∣θ(t) - θ*∣2] + (η(t -qI)TG)2εd.	(50)
17
Under review as a conference paper at ICLR 2021
F Proof of Theorem 2
According to the L-smoothness of the loss functions F1 , . . . , Fm , we have
F(θ(t + 1)) — F(θ(t)) ≤ ®t +1) — θ(t), ▽ F(θ(t))〉+ L。。(t + 1) — θ(t川2 .	(51)
In the following we bound the average of the two terms on the RHS of the above inequality.
Lemma 4. We have
E[(θ( t +1)-θ( t), ▽ F (θ( t ))〉] ≤ ( η( t -21) τGL )2( W；T- I))
+ η 3( t) L 2 G 2 T(T- 16(2 T- I) — η2τ e[∣∣V F (θ( t ))∣∣2]. (52)
Proof. See Appendix G.	口
Lemma 5. We have
E[ ∣∣θ(t + 1) - θ(t)∣∣2 ] ≤ 2η2(t)T2G2 + (η(t - I)TG)22εd.	(53)
2q1
Proof. See Appendix I.
□
Substituting the results in Lemmas 4 and 5 into (51) yields
η(t)e[∣∣VF(θ(t))∣∣2] ≤ 2(E[F(θ(t))] - E[F(θ(t +1))])
+ (η(t- I)G)2(η(t)(2T - 1)L + 2)εdTL + 2η2(t)G2tL + η3(t)L2G2 (T - 1)(2T - I).
2q1	3
(54)
For any T , by summing the above inequality over t we have
T-1	2
E η(t)E[∣∣VF(θ(t))|2] ≤TF(θ(0)) - E[F(θ(T))])
t=0	T
+ E (η(t- I)G)2(η(t)(2t - 1)L + 2)εdTL
t=0	2q1
+ 2G2TL e η2(t) + L2G2 (T- /T- I) E' η3(t).
t=0	t=0
We bound the first term on the RHS of the above inequality as follows:
MB
F(θ(0)) - E[F(θ(T))] ≤ F(θ(0)) - 工 BmFm
m=1
MB
F(θ(0)) - F* + F* - £ BmFm = F(θ(0)) - F* +Γ.
m=1
(55)
(56)
Substituting the above results in (55) and dividing both sides of the inequality in (55) by
tT=-01 η(t) complete the proof of Theorem 2.
18
Under review as a conference paper at ICLR 2021
G Proof of Lemma 4
We have
E[(θ(t +1) - θ(t)ZF(θ(t))〉] = E[(θ(t +1) - θ(t) - θ(t) + 就t), ▽ F(θ(t))〉]
=E[<θ(t + 1) - θ(t)NF(θ(t))〉] - E[(θ(t) - θ(t), ▽ F(θ(t))〉]
=E[<θ(t + 1) - θ(t)NF(θ(t))〉] - E[(θ(t) - θ(t - 1) - Q(θ(t) - θ(t - 1), q 1) NF(θ(t))〉]
=E[<θ(t + 1) - θ(t)ZF(θ(t))〉]
M τ B
=E[〈-η(t)工工-m▽ Fm (%(t)) NF(θ(t))》]
=1 i=1
T M -
=-η(t)E [〈▽ F(θ(t))NF(θ(t))〉] -η(t)工 E 卜工-Bm▽ Fm (落(t)) NF(θ(t))〉], (57)
i=2	m =1
where (a) follows since Eφ [Q(x, q 1)] = x and the fact that θ(t) — θ(t — 1) is indepen-
dent of the stochastic quantization Q(θ(t) — θ(t — 1), q 1), and Eξ [VFm (θim(t),ξm(t))]=
VFm (θm(t)), Vi, m, results (b). We bound the first term on the RHS of (57) as follows:
-η(t)e[(vf(θ(t)), vF(θ(t))〉] = *(e[∣∣vf(θ(t)) -vF(θ(t))112] -e[∣∣vF(θ(t))∣∣2]
-e[∣∣vf(θ(tMl") ≤ η2Le[∣∣θ(t) - θ(t)∣∣2] - *e[∣∣vF(θ(t))∣∣2]. (58)
Lemma 6. We have
e[∣∣θ(t) - θ(t)∣∣2] ≤ (η(t -q}G)2εd.	(59)
Proof. See Appendix H.	□
Plugging (59) into (58) yields
-η (t )E[〈V F (θ( t)), V F (θ( t ))〉] ≤ ( η (t -21" )2( εd2t)-萼 E[∣∣V F (θ( t ))∣∣2].
1	(60)
The second term on the RHS of (57) is bounded as follows:
-η (t) £ E [ W — V Fm (θ m (t)), V F (θ( t ))》]
i=2 m=1
τ	M	2	M	2
ηt ∑ E[∣∣	∑	— V Fm	(θ m	(t)) - V F (θ(t ))∣∣2	-1∣	E	- V Fm	Gm	(t)) ∣∣2	- ∣∣v F(θ(t ))∣∣2]
i=2	m=1	m=1
τM	2
≤ ηV E(E[∣∣E -Bm (V Fm (θ m (t))-v Fm (θ(t )))∣∣2] -E[∣∣v F (θ(t ))∣∣2])
i=2	m=1
(a)
≤
—
η (t)( JI) e[∣∣v f (θ( t ))∣2]
≤ "L2 E E -mm∣θ m (t) - θ( t )∣∣2 -η (t)( T-1) E[∣∣v F(θ( t ))∣2]
i=2 m=1
≤ η (t) L2 E E -m (iiθm (t) - θ( t )∣∣2 + ∣∣θ( t) - θ( t )∣∣2) -η (t)( T-1) E[∣∣v F (θ( t ))∣∣2]
i=2 m=1
≤ η 3( t) L 2 G2 T(T- I)6(2T- I) + ( η^≡ )2 εdη (t)(T- 1) - η≡pa E[||V F (θ( t ))|白,
6	12 q 1	/	2
(61)
19
Under review as a conference paper at ICLR 2021
where (a) follows from the convexity of ∣∣∙∣∣2, and (b) follows from (38) and (59). Plugging
(60) and (61) into (57) yields
E[(θ( t + 1) - θ( t), ▽ F (θ( t ))〉] ≤ ( η (t -q)TGL )2(二(1)
+ η3(t)L2G2 T(T- 16(2T- I) - η(2)τe[∣NF(θ(t))∣∣2] ∙ (62)
H Proof of Lemma 6
We have
E[∣∣θ( t )-0( t )∣∣2] = E[∣∣θ( t)-就 t -1) - Q (θ( t )-0( t - 1) ,q 1)∣∣2]
=e]∣∣θ(t) - θ(t -1)∣∣2] + e[∣∣Q(θ(t) - θ(t-1),q 1)∣∣2]
-2E]θ(t) - θ(t - 1), Q(θ(t) - θ(t - 1), qi)〉]
=-E[∣∣θ(t) - θ(t-1)∣∣2] + e[∣∣Q(θ(t) - θ(t- 1),q 1)∣∣2]
≤ -q.E[∣∣θ(t)- θ(t -1)∣∣2]
Ud	M B	2ι
=疗e[∣∣η(t-1) C 工~β ▽ Fm(θm(t-1),ξm(t-1)) ∣∣2]
"1	m=1i=1
≤(辿” )2 皿	(63)
2q1
where (a) follows since θ(t) — θ(t — 1) is independent of the stochastic quantization Q (θ(t)—
θ(t - 1), qi) and Eφ [Q(x, qi)] = x, the second inequality in (1b) leads to (b), and (c) is the
result of the convexity of ∣∣∙^2 and Assumption 1.
I Proof of Lemma 5
We have
E[∣∣θ(t + 1) - θ(t)∣∣2] ≤ 2E[∣∣θ(t + 1) - θ(t)∣∣2] + 2E[∣∣θ(t) - θ(t)∣∣2].	(64)
For the first term on the RHS of the above inequality, we have
MT	2
2E[∣∣θ( t + 1) - θ( t )∣2] = 2E[∣∣ η (t)工工曾▽ Fm (θ ^ (t)总(t)) ∣∣J
m =1 i =1
(a)	M ʃ
≤ 2η2(t)T 工工 Be[∣∣VFm (%(t),ξm(t))∣∣2]
m=1 i=1
≤ 2η2(t)t2G2,	(65)
where (a) and (b) follow from the convexity of ∣∙∣2 and Assumption 1, respectively. Plugging
(65) and (59) into (64) yields
E[∣∣θ(t + 1) - θ(t)∣∣2] ≤ 2η2(t)T2G2 + (η(t -qI)TG)22εd.	(66)
20