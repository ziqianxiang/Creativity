title,year,conference
 Towards better understanding ofgradient-based attribution methods for deep neural networks,2017, arXiv preprint arXiv:1711
 Network dissection:Quantifying interpretability of deep visual representations,2017, In Proceedings of the IEEE conferenceon computer vision and pattern recognition
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Understanding deep networks via extremal per-turbations and smooth masks,2019, In Proceedings of the IEEE International Conference on ComputerVision
 Interpretable explanations of black boxes by meaningful perturba-tion,2017, In Proceedings of the IEEE International Conference on Computer Vision
 Interpretation of neural networks is fragile,2019, InProceedings of the AAAI Conference on Artificial Intelligence
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Second order derivatives for network pruning: Optimal brainsurgeon,1993, In Advances in neural information processing systems
 A fast learning algorithm for deep beliefnets,2006, Neural Computation
 A baseline for shapely values inmlps: from missingness to neutrality,2020, arXiv preprint arXiv:2006
 Optimal brain damage,1990, In Advances in neuralinformation processing systems
 Snip: Single-shot network pruningbased on connection sensitivity,2018, arXiv preprint arXiv:1810
 A unified approach to interpreting model predictions,2017, In Advancesin Neural Information Processing Systems
 Local interpretable model-agnostic explanationsfor music content analysis,2017, In ISMIR
 Explaining nonlinear classification decisions with deep Taylor decomposition,0031, PatternRecognition
 On the number of linearregions of deep neUral networks,2014, In Advances in Neural Information Processing Systems
 On the imporance ofsingle directions for generalization,2018, In 6th International Conference on Learning Representations
 Feature visualization,2017, Distill
 Restricting the flow: Informationbottlenecks for attribution,2020, In International Conference on Learning Representations
 A value for n-person games,1953, Contributions to the Theory of Games
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 When explanations lie: Why many modified bpattributions fail,2019, arXiv
 Visualizing the impact of feature attributionbaselines,2020, Distill
 Multilayer convolutional sparsemodeling: Pursuit and dictionary learning,2018, IEEE Transactions on Signal Processing
 The many shapley values for model explanation,2020, 37thInternational Conference on Machine Learning
 Interpret neural networks by identifying criticaldata routing paths,2018, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Visualizing and understanding convolutional networks,2014, InEuropean conference on computer vision
 Revisiting the Importance of IndividualUnits in CNNs via Ablation,2018, jun 2018
 Visualizing deep neural net-work decisions: Prediction difference analysis,2019, In 5th International Conference on LearningRepresentations
