title,year,conference
 Deep equilibrium models,2019, In H
 Enhanced LSTMfor natural language inference,1657, In Proceedings of the 55th Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers)
 Named entity recognition with bidirectional lstm-cnns,2016, Trans
 Long short-term memory,0899, Neural Comput
 Recurrent continuous translation models,2013, In Proceedings of the2013 Conference on Empirical Methods in Natural Language Processing 
 Albert: A lite bert for self-supervised learning of language representations,2020, In InternationalConference on Learning Representations
 Effective approaches to attention-basedneural machine translation,2015, In Proceedings of the 2015 Conference on Empirical Methods inNatural Language Processing
 Attention is all you need,2017, In I
 Chinese NER using lattice LSTM,2018, In Proceedings of the 56th AnnualMeeting of the Association for Computational Linguistics (Volume 1: Long Papers)
 Text classificationimproved by integrating bidirectional LSTM with two-dimensional max pooling,2016, In Proceedingsof COLING 2016
