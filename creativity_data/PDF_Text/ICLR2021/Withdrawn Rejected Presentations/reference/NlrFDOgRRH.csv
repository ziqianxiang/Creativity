title,year,conference
 When is multitask learning effective? semantic Se-quence prediction under varying data conditions,2016, arXiv preprint arXiv:1612
 Promoting poor features to supervisors: Some inputs workbetter as outputs,1997, In Advances in Neural Information Processing Systems
 Class-balanced loss based oneffective number of samples,2019, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Associative longshort-term memory,2016, arXiv preprint arXiv:1602
 Recurrent independent mechanisms,2019, arXiv preprint arXiv:1909
 Neural turing machines,2014, arXiv preprintarXiv:1410
 Hybrid computing using a neural network with dynamic external memory,2016, Nature
 Dynamic neural turingmachine with continuous and discrete addressing schemes,2018, Neural computation
 Tracking the worldstate with recurrent entity networks,2016, arXiv preprint arXiv:1612
 Long short-term memory,1997, Neural computation
 In search of the engram,1950, 1950
 Self-attentive associative memory,2020, arXiv preprintarXiv:2002
 Layer normalization,2016, arXiv preprintarXiv:1607
 Metalearned neuralmemory,2019, In Advances in Neural Information Processing Systems
 Recurrent relational networks,2018, In Advances inNeural Information Processing Systems
 Scaling memory-augmented neural networks with sparsereads and writes,2016, In Advances in Neural Information Processing Systems
 Semi-supervised multitask learning for sequence labeling,2017, arXiv preprintarXiv:1704
 Relational recurrent neuralnetworks,2018, In Advances in neural information processing systems
 End-to-end memory networks,2015, In Advancesin neural information processing systems
 Learning longer-term depen-dencies in rnns with auxiliary losses,2018, arXiv preprint arXiv:1803
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Pointer networks,2015, In Advances in neuralinformation processing systems
 Memory networks,2014, arXiv preprintarXiv:1410
 As in Franke et al,2021, (2018)
