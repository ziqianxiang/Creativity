title,year,conference
 Byzantine stochastic gradient descent,2018, In Advancesin Neural Information Processing Systems
 How tobackdoor federated learning,2020, In International Conference on Artificial Intelligence and Statistics
 Analyzing federatedlearning through an adversarial lens,2019, In International Conference on Machine Learning
 Machine learning with adversaries: Byzan-tine tolerant gradient descent,2017, In Advances in Neural Information Processing Systems
 Practical secure aggregation for privacy-preserving machine learning,2017, In Proceedings of the 2017 ACM SIGSAC Conference on Computerand Communications Security
 Draco: Byzantine-resilient distributed training via redundant gradients,2018, arXiv preprint arXiv:1803
 Quantum entropy scoring for fast robust mean estimationand improved outlier detection,2019, In Advances in Neural Information Processing Systems
 Local model poisoning attacksto byzantine-robust federated learning,2019, arXiv preprint arXiv:1911
 Eine neue herleitung des exponentialgesetzes in der wahrscheinlichkeit-srechnung,1922, Mathematische Zeitschrift
 Federated learning: Collaborative machine learning with-out centralized training data,2017, Google Research Blog
 The hidden vulnerability of dis-tributed learning in byzantium,2018, arXiv preprint arXiv:1802
 Robust learning: Information theory and algorithms,2018, PhD thesis
 Data poisoning attacks on federatedmachine learning,2020, arXiv preprint arXiv:2004
 Byzantine-robust distributedlearning: Towards optimal statistical rates,2018, arXiv preprint arXiv:1803
 Defending against saddle pointattack in byzantine-robust distributed learning,2019, In International Conference on Machine Learning
 Sta-tistical model aggregation via parameter matching,2019, In Advances in Neural Information ProcessingSystems
 Bayesian nonparametric federated learning of neural networks,2019, arXivpreprint arXiv:1905
