title,year,conference
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning
 Evasion attacks against machine learning at test time,2013, In Joint Europeanconference on machine learning and knowledge discovery in databases
 Cnn-cert: An efficientframework for certifying robustness of convolutional neural networks,2019, In Proceedings of the AAAIConference on Artificial Intelligence
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 Training verified learners with learned ver-ifiers,2018, arXiv preprint arXiv:1805
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 On the effectiveness of interval bound propagation fortraining verifiably robust models,2018, arXiv preprint arXiv:1810
 Certifiedrobustness to adversarial examples with differential privacy,2019, In 2019 IEEE Symposium on Securityand Privacy (SP)
 Second-order adversarial attack andcertifiable robustness,2018, arXiv preprint arXiv:1809
 Fastenedcrown: Tightened neural network robustness certificates,2020, In Proceedings of the AAAI Conferenceon Artificial Intelligence
 Differentiable abstract interpretation for prov-ably robust neural networks,2018, In International Conference on Machine Learning
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Certified defenses against adversarial exam-ples,2018, arXiv preprint arXiv:1801
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, InAdvances in Neural Information Processing Systems
 Boosting robustness certifica-tion of neural networks,2018, In International Conference on Learning Representations
 An abstract domain for cer-tifying neural networks,2019, Proceedings of the ACM on Programming Languages
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Evaluating robustness of neural networks with mixedinteger programming,2017, arXiv preprint arXiv:1711
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Scaling provable adversarialdefenses,2018, In Advances in Neural Information Processing Systems
 Training for fasteradversarial robustness verification via inducing relu stability,2018, arXiv preprint arXiv:1809
 Feature denoisingfor improving adversarial robustness,2019, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Efficient neural net-work robustness certification with general activation functions,2018, In Advances in neural informationprocessing systems
 Towards stable and efficient training of verifiably robust neural networks,2019, InInternational Conference on Learning Representations
 Bridging modeconnectivity in loss landscapes and adversarial robustness,2020, arXiv preprint arXiv:2005
