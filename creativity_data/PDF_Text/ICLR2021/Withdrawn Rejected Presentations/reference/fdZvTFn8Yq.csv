title,year,conference
 The effects of adding noise during backpropagation training on a generalizationperformance,1996, Neural computation
 The global optimisation problem: an introduction,1978, In L
 BOHB: Robust and efficient hyperparameter opti-mization at scale,2018, In International Conference on Machine Learning
 Efficient and robust automated machine learning,2015, In Advances in neural informationprocessing systems
 Scalable meta-learning for bayesian optimiza-tion,2018, arXiv preprint arXiv:1802
 Probabilistic model-agnostic meta-learning,2018, InAdvances in Neural Information Processing Systems
 Bayesian optimization for materials design,2016, In Information Sciencefor Materials Discovery and Design
 Conditional neural processes,2018, InInternational Conference on Machine Learning
 Neural processes,2018, arXiv preprint arXiv:1807
 Automated Machine Learning,2019, Springer
 Learning to warm-start bayesian hyperparameteroptimization,2017, arXiv preprint arXiv:1710
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Automatic exPloration of machinelearning exPeriments on oPenml,2018, arXiv preprint arXiv:1806
 Virtual vs,2017, real: Trading off simulations and Physical exPerimentsin reinforcement learning with Bayesian oPtimization
 Measures of multivariate skewness and kurtosis with aPPlications,0006, Biometrika
 Bayesian oPtimization for contextualPolicy search,2015, In Proceedings of the Second Machine Learning in Planning and Control of RobotMotion Workshop
 Emulationof Physical Processes with emukit,2019, In Second Workshop on Machine Learning and the PhysicalSciences
 Scalable hyperpa-rameter transfer learning,2018, In Advances in Neural Information Processing Systems
 Taking thehuman out of the loop: A review of bayesian optimization,2015, Proceedings of the IEEE
 Openml: A collaborativescience platform,2013, In Joint european conference on machine learning and knowledge discovery indatabases
 Meta-learning: A survey,2018, arXiv preprint arXiv:1810
 Functional approximation by feed-forward networks: a least-squares approach togeneralization,1994, IEEE transactions on Neural Networks
 Learning hyperparameter optimization initializa-tions,2015, In 2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)
 Scalable gaussian process-basedtransfer surrogates for hyperparameter optimization,2018, Machine Learning
 Fast contextadaptation via meta-learning,2019, In International Conference on Machine Learning
