title,year,conference
 Risk-sensitive reinforcement learning: A constrained optimizationviewpoint,2018, CoRR
 Constrained policy optimization,2017, InProceedings of the 34th International Conference on Machine Learning
 An optimistic perspective on offlinereinforcement learning,2019, In NeurIPS Deep Reinforcement Learning Workshop
 Risk-aversetrust region optimization for reward-volatility reduction,2019, CoRR
 Convex Optimization,0521, Cambridge University Press
 Risk-constrainedreinforcement learning with percentile risk criteria,2017, J
 SBEED:convergent reinforcement learning with nonlinear function approximation,2018, In Proceedings of the35th International Conference on Machine Learning
 Provablyefficient safe exploration via primal-dual policy optimization,2020, CoRR
 D4RL: datasets fordeep data-driven reinforcement learning,2020, CoRR
 Addressing function approximation error inactor-critic methods,2018, In Proceedings of the 35th International Conference on Machine Learning
 Off-policy deep reinforcement learning withoutexploration,2019, In Proceedings of the 36th International Conference on Machine Learning
 Generative adversarial networks,2014, CoRR
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, In Proceedings of the35th International Conference on Machine Learning
 Generative adversarial imitation learning,2016, In Advances in NeuralInformation Processing Systems 29: Annual Conference on Neural Information Processing Systems2016
 Imitation learning via off-policy distributionmatching,2019, CoRR
 Stabilizing off-policyq-learning via bootstrapping error reduction,2019, In Advances in Neural Information ProcessingSystems 32: Annual Conference on Neural Information Processing Systems 2019
 Conservative q-learning for offlinereinforcement learning,2020, arXiv preprint arXiv:2006
 Batch policy learning under constraints,2019, InProceedings of the 36th International Conference on Machine Learning
 End-to-end training of deepvisuomotor policies,2016, J
 Toward minimax off-policy value estima-tion,2015, In Proceedings of the Eighteenth International Conference on Artificial Intelligenceand Statistics
 Continuous control with deep reinforcement learning,2016, In4th International Conference on Learning Representations
 Breaking the curse of horizon: Infinite-horizon off-policy estimation,2018, In Advances in Neural Information Processing Systems 31: AnnualConference on Neural Information Processing Systems 2018
 Policy optimizationvia importance sampling,2018, In Advances in Neural Information Processing Systems 31: AnnualConference on Neural Information Processing Systems 2018
 Reinforcement learning via fenchel-rockafellar duality,2020, CoRR
 Dualdice: Behavior-agnostic estimation ofdiscounted stationary distribution corrections,2019, In Advances in Neural Information ProcessingSystems 32: Annual Conference on Neural Information Processing Systems 2019
 Algaedice:Policy gradient from arbitrary experience,2019, CoRR
 Estimating divergence functionalsand the likelihood ratio by convex risk minimization,2010, IEEE Trans
 Eligibility traces for off-policy policyevaluation,2000, In Proceedings of the Seventeenth International Conference on Machine Learning(ICML 2000)
 Off-policy temporal difference learning withfunction approximation,2001, In Carla E
 Markov Decision Processes: Discrete Stochastic Dynamic Programming,0471, JohnWiley Sons
 Trust regionpolicy optimization,2015, In Proceedings of the 32nd International Conference on Machine Learning
 Multivariate stochastic approximation using a simultaneous perturbation gradientapproximation,1992, IEEE TRANSACTIONS ON AUTOMATIC CONTROL
 Batch learning from logged bandit feedback throughcounterfactual risk minimization,2015, J
 Counterfactual risk minimization: Learning from loggedbandit feedback,2015, In Proceedings of the 32nd International Conference on Machine Learning
 Reward constrained policy optimization,2019, In7th International Conference on Learning Representations
 High confidence policyimprovement,2015, In Francis R
 Stable policy optimization viaoff-policy divergence regularization,2020, In Ryan P
 Gendice: Generalized offline estimation ofstationary values,2020, In 8th International Conference on Learning Representations
 Generalized off-policy actor-critic,2019, In Advances in Neural Information Processing Systems 32: Annual Conference onNeural Information Processing Systems 2019
 Assuming that state action samples are drawn i,2018,i
