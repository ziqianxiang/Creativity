title,year,conference
 Differentially PrivateMixture of Generative Neural Networks,2017, In International Conference on Data Mining (ICDM)
 Obfuscated Gradients Give a False Senseof Security: Circumventing Defenses to Adversarial Examples,2018, In International Conference onMachine Learning (ICML)
 Poisoning Attacks against Support Vector Ma-chines,2012, In International Conference on Machine Learning (ICML)
 GAN-Leaks: A Taxonomy of MembershipInference Attacks against GANs,2020, In ACM SIGSAC Conference on Computer and CommunicationsSecurity (CCS)
 Generative Adversarial Nets,2014, In Annual Conference onNeural Information Processing Systems (NIPS)
 Explaining and Harnessing AdversarialExamples,2015, In International Conference on Learning Representations (ICLR)
 LOGAN: Evaluating Pri-vacy Leakage of Generative Models Using Generative Adversarial Networks,2019, Symposium onPrivacy Enhancing Technologies Symposium
 PATE-GAN: Generating Synthetic Datawith Differential Privacy Guarantees,2019, OpenReview
 Trojaning Attack on Neural Networks,2019, In Network and Distributed System SecuritySymposium (NDSS)
 Updates-Leak: Data Set Inference and Reconstruction Attacks in Online Learning,2020, In USENIX SecuritySymposium (USENIX Security)
 Lossy Image Compression withCompressive Autoencoders,2017, In International Conference on Learning Representations (ICLR)
 Show and Tell: A NeuralImage Caption Generator,2015, In IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
