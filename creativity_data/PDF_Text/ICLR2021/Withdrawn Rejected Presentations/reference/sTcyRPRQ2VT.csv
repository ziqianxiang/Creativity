title,year,conference
 Neural machine translation by jointlylearning to align and translate,2014, arXiv preprint arXiv:1409
 Learning phrase representations using rnn encoder-decoderfor statistical machine translation,2014, arXiv preprint arXiv:1406
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Unsupervised ontology ac-quisition from plain texts: the ontogain system,2010, In International Conference on Application ofNatural Language to Information Systems
 Anew metric for probability distributions,2003, IEEETransactions on Information theory
 Graphrel: Modeling text as relational graphs for jointentity and relation extraction,2019, In Proceedings of the 57th Annual Meeting of the Association forComputational Linguistics
 Creating train-ing corpora for nlg micro-planning,2017, In 55th annual meeting of the Association for ComputationalLinguistics (ACL)
 exbert: A visual analysis tool toexplore learned representations in transformers models,2019, arXiv preprint arXiv:1910
 Exploring thelimits of language modeling,2016, arXiv preprint arXiv:1602
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Harnessing relationships for domain-specificsubgraph extraction: A recommendation use case,2016, In 2016 IEEE International Conference on BigData (Big Data)
 Automatic gener-ation of the domain module from electronic textbooks: method and validation,2013, IEEE transactionson knowledge and data engineering
 Deep learning,2015, nature
 A survey on deep learning for named entityrecognition,2020, IEEE Transactions on Knowledge and Data Engineering
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Effective approaches to attention-based neural machine translation,2015, arXiv preprint arXiv:1508
 Wisdom ofCroWds for robust gene network inference,2012, Nature methods
 Relation extraction: Perspective from convolutional neuralnetworks,2015, In Proceedings of the 1st Workshop on Vector Space Modeling for Natural LanguageProcessing
 Glove: Global vectors for wordrepresentation,2014, In Empirical Methods in Natural Language Processing (EMNLP)
 Parsing english intoabstract meaning representation using syntax-based machine translation,2015, In Proceedings of the2015 Conference on Empirical Methods in Natural Language Processing
 Modeling relations and their mentions with-out labeled text,2010, In Joint European Conference on Machine Learning and Knowledge Discoveryin Databases
 Molecular transformer: A model for uncertainty-calibrated chemicalreaction prediction,2019, ACS Central Science
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Unsuperviseddomain ontology learning from text,2016, In International Conference on Mining Intelligence andKnowledge Exploration
 Analyzing the structure of attention in a transformer languagemodel,2019, arXiv preprint arXiv:1906
 Docred: A large-scale document-level relation extraction dataset,2019, arXivpreprint arXiv:1906
 Data mining and analysis: fundamental concepts and algo-rithms,2014, Cambridge University Press
 Relation classification viaconvolutional deep neural network,2014, In Proceedings of COLING 2014
 Extracting relational facts byan end-to-end neural model with copy mechanism,2018, In Proceedings of the 56th Annual Meeting ofthe Association for Computational Linguistics (Volume 1: Long Papers)
 Position-aware attention and supervised data improve slot filling,2017, In Proceedings of the 2017 Conferenceon Empirical Methods in Natural Language Processing
 Joint extractionof entities and relations based on a novel tagging scheme,2017, arXiv preprint arXiv:1706
 Attention-basedbidirectional long short-term memory networks for relation classification,2016, In Proceedings of the54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)
