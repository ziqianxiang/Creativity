title,year,conference
 A comparison of regression models for pre-diction of graduate admissions,2019, In 2019 International Conference on Computational Intelligencein Data Science
 Variance reduction for faster non-convex optimization,2016, InInternational conference on machine learning
 Optimization methods for large-scale machinelearning,2018, SIAM Review
 A selective overview of deep learning,2019, arXiv preprintarXiv:1904
 Deep learning,2016, MIT press
 SGD: General analysis and improved rates,2019, In International Conference on MachineLearning
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Flat minima,1997, Neural Computation
 Three factors influencing minima in SGD,2017, arXiv preprintarXiv:1711
 Accelerating stochastic gradient descent using predictive variancereduction,2013, In Advances in Neural Information Processing Systems
 Better theory for sgd in the nonconvex world,2020, arXiv preprintarXiv:2002
 Efficient backprop,2012, InNeural networks: Tricks ofthe trade
 Non-convex finite-sum optimization viaSCSG methods,2017, In Advances in Neural Information Processing Systems
 Efficient mini-batch training forstochastic optimization,2014, In Proceedings of the 20th ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining
 The moments of products of quadratic forms in normal variables,1978, Instituut voorActuariaat en Econometrie
 Generalizationerror bounds for optimization algorithms via stability,2016, arXiv preprint arXiv:1609
 Generalization bounds of SGLD for non-convex learning: Two theoretical viewpoints,2018, In Conference On Learning Theory
 Adding gradient noise improves learning for very deep networks,2015, arXiv preprintarXiv:1511
 A stochastic gradient method with an expo-nential convergence rate for finite training sets,2012, In Advances in Neural Information ProcessingSystems
 Minimizing finite sums with the stochasticaverage gradient,2017, Mathematical Programming
 Best practices for convolutional neural networks appliedto visual document analysis,2013, In Seventh International Conference on Document Analysis andRecognition
 A bayesian perspective on generalization and stochastic gradientdescent,2017, arXiv preprint arXiv:1710
 Optimization for deep learning: theory and algorithms,2019, arXiv preprintarXiv:1912
 Variance reduction for stochasticgradient optimization,2013, In Advances in Neural Information Processing Systems
 Character-level convolutional networks for text clas-Sification,2015, In Advances in Neural Information Processing Systems
 A hitting time analysis of stochastic gradientlangevin dynamics,2017, In Conference on Learning Theory
