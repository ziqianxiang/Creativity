title,year,conference
 Surprise-based intrinsic motivation for deep reinforcementlearning,2017, arXiv preprint arXiv:1703
 Differential entropy estimation by particles,2011, IFAC ProceedingsVolumes
 Solving rubik’s cube with arobot hand,2019, arXiv preprint arXiv:1910
 Layer normalization,2016, arXiv preprintarXiv:1607
 Agent57: Outperforming the atari human benchmark,2020, arXivpreprint arXiv:2003
 Never giveup: Learning directed exploration strategies,2020, arXiv preprint arXiv:2002
 The im algorithm: A variational approach to informationmaximization,2003, In Advances in neural information processing systems
 Successor features for transfer in reinforcement learning,2017, In Advances in neuralinformation processing systems
 Transfer in deep reinforcement learning using successor featuresand generalised policy improvement,2018, In International Conference on Machine Learning
 Skip context tree switching,2014, In InternationalConference on Machine Learning
 Dota 2 with large scaledeep reinforcement learning,2019, arXiv preprint arXiv:1912
 Universal successor features approximators,2018, arXiv preprintarXiv:1812
 Openai gym,2016, arXiv preprint arXiv:1606
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Exploration by random networkdistillation,2018, arXiv preprint arXiv:1810
 Generative pretraining from pixels,2020, In Proceedings of the 37th InternationalConference on Machine Learning
 A simple framework forcontrastive learning of visual representations,2020, arXiv preprint arXiv:2002
 Improved baselines with momentumcontrastive learning,2020, arXiv preprint arXiv:2003
 Contingency-aware exploration in reinforcement learning,2018, arXiv preprintarXiv:1811
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Go-explore: a newapproach for hard-exploration problems,2019, arXiv preprint arXiv:1901
 Diversity is all you need:Learning skills without a reward function,2018, arXiv preprint arXiv:1802
 Stochastic neural networks for hierarchical reinforce-ment learning,2017, arXiv preprint arXiv:1704
 Variational intrinsic control,2016, arXivpreprint arXiv:1611
 Noise-contrastive estimation: A new estimation principlefor unnormalized statistical models,2010, In Proceedings of the Thirteenth International Conference onArtificial Intelligence and Statistics
 Dimensionality reduction by learning an invariantmapping,2006, In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPR’06)
 Provably efficient maximum entropyexploration,2019, In International Conference on Machine Learning
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Momentum contrast forunsupervised visual representation learning,2019, arXiv preprint arXiv:1911
 Using pre-training can improve model robustnessand uncertainty,2019, arXiv preprint arXiv:1901
 Long short-term memory,1997, Neural computation
 Vime:Variational information maximizing exploration,2016, In Advances in Neural Information ProcessingSystems
 Reinforcement learning with unsupervised auxiliary tasks,2016, arXivpreprint arXiv:1611
 Information theory and statistical mechanics,1957, Physical review
 The nearest neighbor information estimator is adaptivelynear minimax rate-optimal,2018, In Advances in neural information processing systems
 Never stoplearning: The effectiveness of fine-tuning in robotic reinforcement learning,2020, 2020
 Model-basedreinforcement learning for atari,2019, arXiv preprint arXiv:1903
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Image augmentation is all you need: Regularizingdeep reinforcement learning from pixels,2020, arXiv preprint arXiv:2004
 Imagenet classification with deep convolu-Honal neural networks,2012, In Advances in neural information processing Systems
 Deep successorreinforcement learning,2016, arXiv preprint arXiv:1606
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 On a measure of the information provided by an experiment,1956, The Annals ofMathematical Statistics
 Competitive experience replay,2019, arXivpreprint arXiv:1902
 Exploration in model-based reinforcement learning by empirically estimating learning progress,2012, In Advances in neuralinformation processing systems
 Count-based exploration with thesuccessor representation,2018, arXiv preprint arXiv:1807
 A possibility for implementing curiosity and boredom inmodel-building neural controllers,1991, 1991
 Learning word embeddings efficiently with noise-contrastiveestimation,2013, In Advances in neural information processing systems
 Human-level controlthrough deep reinforcement learning,2015, nature
 A policy gradient method for task-agnosticexploration,2020, arXiv preprint arXiv:2007
 Policy invariance under reward transformations: Theory andapplication to reward shaping,1999, In ICML
 Self-imitation learning,2018, arXiv preprintarXiv:1806
 Representation learning with contrastive predictivecoding,2018, arXiv preprint arXiv:1807
 Count-based explorationwith neural density models,2017, arXiv preprint arXiv:1703
 Intrinsic motivation systems for au-tonomous mental development,2007, IEEE transactions on evolutionary computation
 Estimation of renyi entropy and mutual informa-tion based on generalized nearest-neighbor graphs,2010, In Advances in Neural Information ProcessingSystems
 Curiosity-driven explorationby self-supervised prediction,2017, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition Workshops
 Deep contextualized word representations,2018, arXiv preprint arXiv:1802
 Languagemodels are unsupervised multitask learners,2019, 2019
 Curious model-building control systems,1991, In Proc
 Trust regionpolicy optimization,2015, In International conference on machine learning
 Proximal policyoptimization algorithms,2017, arxiv 2017
 A mathematical theory of communication,2001, ACM SIGMOBILE mobilecomputing and communications review
 Dynamics-awareunsupervised discovery of skills,2019, arXiv preprint arXiv:1907
 Model-based active exploration,2019, InInternational Conference on Machine Learning
 Masteringthe game of go with deep neural networks and tree search,2016, nature
 Ensemble estimators for multivariate entropyestimation,2013, IEEE transactions on information theory
 Curl: Contrastive unsupervised representationsfor reinforcement learning,2020, arXiv preprint arXiv:2004
 Intrinsic motivation and automatic curricula via asymmetric self-play,2017, arXiv preprintarXiv:1703
 Planning to be surprised: Optimal bayesian ex-ploration in dynamic environments,2011, In International Conference on Artificial General Intelligence
 dm_control: Software and tasks forcontinuous control,2020, arXiv preprint arXiv:2006
 Conditionalimage generation with pixelcnn decoders,2016, In Advances in neural information processing systems
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Learning latent state representa-tion for speeding up exploration,2019, arXiv preprint arXiv:1905
 Grandmaster level instarcraft ii using multi-agent reinforcement learning,2019, Nature
 Unsupervised control through non-parametric discriminative rewards,2018, arXivpreprint arXiv:1811
 Visualizing and understanding convolutional networks,2014, InEuropean conference on computer vision
 Curiosity-driven experience prioritization via density estimation,2019, arXivpreprint arXiv:1902
99 32 Adam 0,1600,0001 0
