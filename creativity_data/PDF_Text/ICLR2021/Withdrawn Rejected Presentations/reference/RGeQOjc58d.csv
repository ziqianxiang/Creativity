title,year,conference
 Proximalmean-field for neural network quantization,2019, ICCV
 Square attack:a query-efficient black-box adversarial attack via random search,2020, In European Conference onComputer Vision
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Proxquant: Quantized neural networks via proximaloperators,2019, ICLR
 Impact of low-bitwidth quantizationon the adversarial robustness for embedded neural networks,2019, In 2019 International Conference onCyberworlds (CW)
 Towards evaluating the robustness of neural networks,2017, In IEEESymposium on Security and Privacy
 Adversarial attacks and defences: A survey,2018, arXiv preprint arXiv:1810
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, ICML
 The logbarrier adversarial attack:making effective use of decision boundary information,2019, In Proceedings of the IEEE InternationalConference on Computer Vision
 Attacking binarized neural networks,2018, InInternational Conference on Learning Representations
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In Proceedings of the thirteenth international conference on artificial intelligence andstatistics
 Gradient masking causes clever to overestimate adversarial perturbation size,2018, arXivpreprint arXiv:1804
 EXplaining and harnessing adversarialeXamples,2014, arXiv preprint arXiv:1412
 Defensive quantization: When efficiency meets robustness,2019, InInternational Conference on Learning Representations
 Bidirectional self-normalizing neuralnetworks,2020, arXiv preprint arXiv:2006
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Adversarialrobustness toolbox v1,2018, 0
 Automatic differentiation inPyTorch,2017, 2017
 Resurrecting the sigmoid in deeplearning through dynamical isometry: theory and practice,2017, In Advances in neural informationprocessing systems
 Adversarial robustness through locallinearization,2019, In Advances in Neural Information Processing Systems
 Xnor-net: Imagenetclassification using binary convolutional neural networks,2016, ECCV
 Foolbox: A python toolbox to benchmark therobustness of machine learning models,2017, arXiv preprint arXiv:1707
 Exact solutions to the nonlinear dynamicsof learning in deep linear neural networks,2013, arXiv preprint arXiv:1312
 Empir: Ensembles of mixed precisiondeep networks for increased robustness against adversarial attacks,2020, In International Conference onLearning Representations
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 On adaptive attacks toadversarial example defenses,2020, arXiv preprint arXiv:2002
 Evaluating the robustness of neural networks: An extreme value theory approach,2018, InInternational Conference on Learning Representations
 Quantization networks,2019, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Hessian-based analysisof large batch training and robustness to adversaries,2018, In Advances in Neural Information ProcessingSystems
 Trust region basedadversarial attack on neural networks,2019, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
