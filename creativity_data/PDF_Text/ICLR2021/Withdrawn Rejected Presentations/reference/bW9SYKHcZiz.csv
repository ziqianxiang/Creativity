title,year,conference
 Bottom-up and top-down attention for image captioning and vqa,2018, In CVPR
 Uniter: Learning universal image-text representations,2020, In ECCV
 Vse++: Improving visual-semantic embeddings with hard negatives,2017, In BMVC
 Poly-encoders: Architec-tures and pre-training strategies for fast and accurate multi-sentence scoring,2020, In ICLR
 Stacked cross attention forimage-text matching,2018, In ECCV
 Unicoder-vl: Auniversal encoder for vision and language by cross-modal pre-training,2020, In AAAI
 Visualbert: A simpleand performant baseline for vision and language,2019, In arXiv
 Microsoft coco: Common objectsin context,2014, In arXiv
 Vilbert: Pretraining task-agnostic visiolin-guistic representations for vision-and-language tasks,2019, In NIPS
 Training millionsof personalized dialogue agents,2018, In EMNLP
 Im2text: Describing images using 1 millioncaptioned photographs,2011, In NIPS
 A new approach to cross-modal multimedia retrieval,2010, InICME
 Lxmert: Learning cross-modality encoder representations from trans-formers,2019, In EMNLP
 Attention is all you need,2017, In NIPS
 Dc-bert: De-coupling question and document for efficient contextual encoding,2020, In SIGIR
