title,year,conference
 Unified rational protein engineering withsequence-based deep representation learning,2019, Nature methods
 Proteinnet: a standardized data set for machine learning of pro-tein structure,2019, BMC bioinformatics
 The protein data bank,2000, Nucleic acids research
 Bigself-supervised models are strong semi-supervised learners,2020, Advances in Neural InformationProcessing Systems
 Text data augmentation made simple by leveraging nlp cloud apis,2018, arXiv preprintarXiv:1812
 High-resolution epitope mapping of hgh-receptor interactions byalanine-scanning mutagenesis,1989, Science
 BERT: Pre-training of Deep Bidirectional Trans-formers for Language Understanding,2018, arXiv preprint arXiv:1810
 Unsupervised representation learning by predicting imagerotations,2018, ICLR
 Dimensionality reduction by learning an invariant map-ping,2006, In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPRâ€™06)
 Modeling aspects of the language of lifethrough transfer-learning protein sequences,2019, BMC bioinformatics
 Evaluating protein transfer learning with tape,2019, In Advancesin Neural Information Processing Systems
 Accelerating protein design using autoregressivegenerative models,2019, bioRxiv
 Biological structure and function emerge from scaling unsupervisedlearning to 250 million protein sequences,2019, bioRxiv
 Unsupervised data augmentation for consistency training,2019, arXiv preprintarXiv:1904
 Data noising as smoothing in neural network language models,2019, In 5thInternational Conference on Learning Representations
 Character-level convolutional networks for text classification,2015, InAdvances in neural information processing systems
