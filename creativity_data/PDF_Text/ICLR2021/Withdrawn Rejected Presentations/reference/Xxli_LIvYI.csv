title,year,conference
 Stronger generalization boundsfor deep nets via a compression approach,2018, In ICML
 Data-dependent coresets for compressing neural networks with applications to generalizationbounds,2019, In International Conference on Learning Representations
 SiPPing neuralnetworks: Sensitivity-informed provable pruning of neural networks,2019, October 2019b
 Algorithmic regularization in learning deep homogeneousmodels: Layers are automatically balanced,2018, In S
 Gradient descent finds globalminima of deep neural networks,2018, CoRR
 Minimal random code learning:Getting bits back from compressed model parameters,2018, September 2018
 Provable filterprUning for efficient neUral networks,2019, ICLR 2020
 Learning sparse neUral networks throUghL0 regUlarization,2017, December 2017
 Comparing rewinding and fine-tUning in neUralnetwork prUning,2020, March 2020
 Lossless compression of deep neUralnetworks,2020, JanUary 2020
