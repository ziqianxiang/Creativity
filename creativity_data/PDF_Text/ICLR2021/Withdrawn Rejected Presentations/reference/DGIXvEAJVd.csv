title,year,conference
 Fine-grained Analysisof Sentence Embeddings Using Auxiliary Prediction Tasks,2017, In ICLR
 Understanding intermediate layers using linear classifier probes,2017, InICLR Workshop
 Multimodal Distributional Semantics,2014, JAIR
 Beyond Triplet Loss: A DeepQuadruplet Network for Person Re-identification,2017, In CVPR
 TextWorld: A Learning Environment for Text-based Games,2018, CoRR
 DeepChess: End-to-End Deep Neural Network forAutomatic Learning in Chess,2016, In International Conference on Artificial Neural Networks (ICANN)
 BERT: Pre-training of DeepBidirectional Transformers for Language Understanding,2019, In NAACL
 What BERT is Not: Lessons from a New Suite of Psycholinguistic Diagnostics forLanguage Models,2020, TACL
 Recurrent World Models Facilitate Policy Evolution,2018, In NeurIPS
 Teaching Machines to Read and Comprehend,2015, In NeurIPS
 Grounded Language Learning in a Simulated 3DWorld,2017, CoRR
 The Goldilocks Principle: ReadingChildren’s Books with Explicit Memory Representations,2016, In ICLR
 Understanding GroundedLanguage Learning Agents,2017, CoRR
 Long short-term memory,1997, Neural computation
 Adam: A method for stochastic oPtimization,2014, In ICLR
 Unifying Visual-Semantic Embeddingswith Multimodal Neural Language Models,2014, CoRR
 Assessing the Ability of LSTMs to Learn Syntax-Sensitive DePendencies,2016, TACL
 Mixed PrecisionTraining,2018, In ICLR
 A CorPus and Cloze Evaluation for DeePer Understandingof Commonsense Stories,2016, In NAACL
 An Analysis of the Utility of ExPlicit Negative ExamPles toImProve the Syntactic Abilities of Neural Language Models,2020, In ACL
 Like a Baby: Visually SituatedNeural Language Acquisition,2019, In ACL
 Information-Theoretic Probing for Linguistic Structure,2020, In ACL
 LanguageModels are Unsupervised Multitask Learners,2019, 2019
 What do you learnfrom context? Probing for sentence structure in contextualized word representations,2019, In ICLR
 Attention is All you Need,2017, In NeurIPS
 Memory Networks,2015, In ICLR
 Huggingface’s transformers: State-of-the-artnatural language processing,2019, ArXiv
 Encoder-Agnostic Adaptation for Conditional Language Generation,2019, CoRR
