title,year,conference
 Convex optimization,2004, Cambridge university press
 Mixed precision training of convolutional neural networks using integer operations,2018, InInternational Conference on Learning RepreSentationS
 Proportionate adaptive algorithms for network echo can-cellation,2006, IEEE TranSactionS on Signal ProceSSing
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Deep learning withlimited numerical precision,2015, In International Conference on Machine Learning
 Mask r-cnn,2017, In Proceedings oftheIEEE international conference on computer vision
 Norm matters: efficient and accuratenormalization schemes in deep networks,2018, In Advances in Neural Information Processing Systems
 Analysis of quantized models,2019, In InternationalConference on Learning Representations
 Quantization and training of neural networks forefficient integer-arithmetic-only inference,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Trained quantization thresholds foraccurate and efficient fixed-point inference of deep neural networks,2020, In I
 A com-parative study on transformer vs rnn in speech applications,2019, In 2019 IEEE Automatic SpeechRecognition and Understanding Workshop (ASRU)
 Mixed precisiontraining,2018, In International Conference on Learning Representations
 Memory-driven mixed lowprecision quantization for enabling deep network inference on microcontrollers,2020, InI
 Per-tensor fixed-point quantization of the back-propagationalgorithm,2019, In 7th International Conference on Learning Representations
 Accumulation bit-width scaling for ultra-low precision training ofdeep networks,2019, In International Conference on Learning Representations
 Aquantization-friendly separable convolution for mobilenets,2018, In 2018 1st Workshop on EnergyEfficient Machine Learning and Cognitive Computing for Embedded Applications (EMC2)
 And the bitgoes down: Revisiting the quantization of neural networks,2020, In Eighth International Conferenceon Learning Representations
 Mixed precision dnns: All you need is a goodparametrization,2020, In International Conference on Learning Representations
 Train-ing deep neural networks with 8-bit floating point numbers,2018, In Advances in neural informationprocessing systems
 Training and inference with integers in deepneural networks,2018, In International Conference on Learning Representations
 Dorefa-net: Train-ing low bitwidth convolutional neural networks with low bitwidth gradients,2016, arXiv preprintarXiv:1606
