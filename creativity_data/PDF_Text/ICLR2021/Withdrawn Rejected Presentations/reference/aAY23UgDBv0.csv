title,year,conference
 Cubature kalman filters,2009, IEEE Transactions on automaticcontrol
 State-space models’ dirty little secrets: even simplelinear gaussian models can have estimation problems,2016, Scientific reports
 Switching linear dynamics for varia-tional bayes filtering,2019, In International Conference on Machine Learning
 Accurate and diverse sampling of sequencesbased on a “best of many” sample objective,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Conditional flow variational autoencoders for structured sequence prediction,2019, arXivpreprint arXiv:1908
 Pattern recognition and machine learning,2006, springer
 Infogan:Interpretable representation learning by information maximizing generative adversarial nets,2016, InAdvances in neural information processing systems
 Empirical evaluation ofgated recurrent neural networks on sequence modeling,2014, arXiv preprint arXiv:1412
 A recurrent latent variable model for sequential data,2015, In Advances in neural informationprocessing systems
 Gru-ode-bayes: Continuousmodeling of sporadically-observed time series,2019, In Advances in Neural Information ProcessingSystems
 Sequential neural modelswith stochastic layers,2016, In Advances in neural information processing systems
 A disentangled recognitionand nonlinear dynamics model for unsupervised learning,2017, In Advances in Neural InformationProcessing Systems
 Deep state space modelsfor nonlinear system identification,2020, arXiv preprint arXiv:2003
 Generative temporal models with memory,2017, arXivpreprint arXiv:1702
 Z-forcing: Training stochastic recurrent networks,2017, In Advances in neuralinformation processing systems
 Long short-term memory,1997, Neural computation
 A new approach to linear filtering and prediction problems,1960, 1960
 Deep variationalbayes filters: Unsupervised learning of state space models from raw data,2017, In 5th InternationalConference on Learning Representations
 Social-bigat: Multimodal trajectory forecasting using bicycle-gan and graph attentionnetworks,2019, In Advances in Neural Information Processing Systems
 Professor forcing: A new algorithm for training recurrent networks,2016, InAdvances In Neural Information Processing Systems
 Auto-encoding sequentialmonte carlo,2018, In International Conference on Learning Representations
 Desire: Distant future prediction in dynamic scenes with interacting agents,2017, InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Infogail: Interpretable imitation learning from visualdemonstrations,2017, In Advances in Neural Information Processing Systems
 Adap-tive density estimation for generative models,2019, In Advances in Neural Information ProcessingSystems
 Conditional generative adversarial nets,2014, arXiv preprintarXiv:1411
 Tree-structured recurrentswitching linear dynamical systems for multi-scale modeling,2018, In International Conference onLearning Representations
 Deep state space models for time series forecasting,2018, In Advances in neuralinformation processing systems
 Sequence level train-ing with recurrent neural networks,2016, In 4th International Conference on Learning Representations
 Sophie: An attentive gan for predicting paths compliant to social and physical con-straints,2019, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 A numerical-integration perspective ongaussian filters,2006, IEEE Transactions on Signal Processing
 Statespace lstm models with particle mcmc inference,2017, arXiv preprint arXiv:1711
