title,year,conference
 Infinite mixture prototypesfor few-shot learning,2019, arXiv preprint arXiv:1902
 Unsupervised state representation learning in atari,2019, In Advances in Neural InformationProcessing Systems
 A theoretical analysis of contrastive UnsUpervised representation learning,2019, arXiv preprintarXiv:1902
 Openai gym,2016, arXiv preprint arXiv:1606
 A simple framework forcontrastive learning of visual representations,2020, arXiv preprint arXiv:2002
 Crosstransformers: spatially-aware few-shottransfer,2020, arXiv preprint arXiv:2007
 Neural scenerepresentation and rendering,2018, Science
 Conditional neural processes,2018, arXiv preprintarXiv:1807
 Neural processes,2018, arXiv preprint arXiv:1807
 Onthe transfer of inductive bias from simulation to the real world: a new disentanglement dataset,2019, InAdvances in Neural Information Processing Systems
 Convolutional conditional neural processes,2020, 2020
 Noise-contrastive estimation: A new estimation principlefor unnormalized statistical models,2010, In Proceedings of the Thirteenth International Conference onArtificial Intelligence and Statistics
 Soft actor-critic: Off-policy maxi-mum entropy deep reinforcement learning with a stochastic actor,2018, arXiv preprint arXiv:1801
 Array program-ming with numpy,2020, Nature
 Momentum contrast forunsupervised visual representation learning,2019, arXiv preprint arXiv:1911
 Learning deep representations by mutual information estimationand maximization,2018, arXiv preprint arXiv:1808
 Attentive neural processes,2019, arXiv preprint arXiv:1901
 Jupyternotebooks-a publishing format for reproducible computational workflows,2016, In ELPUB
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Meta-learning withdifferentiable convex optimization,2019, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Meta-sgd: Learning to learn quickly for few-shotlearning,2017, arXiv preprint arXiv:1707
 Self-supervised prototypical transferlearning for few-shot classification,2020, arXiv preprint arXiv:2006
 Representation learning with contrastive predictivecoding,2018, arXiv preprint arXiv:1807
 Transductiveepisodic-wise adaptive metric for few-shot learning,2019, In Proceedings of the IEEE InternationalConference on Computer Vision
 Optimization as a model for few-shot learning,2016, 2016
 Prototypical networks for few-shot learning,2017, InAdvances in neural information processing systems
 Contrastive multiview coding,2019, arXiv preprintarXiv:1906
 Whatmakes for good views for contrastive learning,2020, arXiv preprint arXiv:2005
 On mutualinformation maximization for representation learning,2019, arXiv preprint arXiv:1907
 Python 3 Reference Manual,1441, CreateSpace
 Matching networks for oneshot learning,2016, In Advances in neural information processing systems
 Understanding contrastive representation learning through align-ment and uniformity on the hypersphere,2020, arXiv preprint arXiv:2005
 Metafun: Meta-learning with iterative functional updates,2019, arXiv preprint arXiv:1912
 Split-brain autoencoders: Unsupervised learningby cross-channel prediction,2017, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
