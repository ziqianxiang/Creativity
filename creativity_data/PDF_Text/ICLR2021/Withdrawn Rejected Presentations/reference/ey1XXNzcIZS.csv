title,year,conference
 Transfer of training: A review and directions for futureresearch,1988, Personnel psychology
 Conditional computationin neural networks for faster models,2015, arXiv preprint arXiv:1511
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Multitask learning,1997, Machine learning
 The best of bothworlds: Combining recent advances in neural machine translation,2018, In Proceedings of the 56thAnnual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)
 A survey of model compression and accelerationfor deep neural networks,2017, arXiv preprint arXiv:1710
 A unified architecture for natural language processing: Deepneural networks with multitask learning,2008, In Proceedings of the 25th international conference onMachine learning
 Depth-adaptive transformer,2019, arXivpreprint arXiv:1910
 Beyond english-centricmultilingual machine translation,2020, arXiv preprint arXiv:2010
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Evaluating the supervised and zero-shot per-formance of multi-lingual translation models,2019, arXiv preprint arXiv:1906
 Google's multilingual neuralmachine translation system: Enabling zero-shot translation,2017, Transactions of the Association forComputational Linguistics
 Sequence-level knowledge distillation,2016, In Proceedings of the2016 Conference on Empirical Methods in Natural Language Processing
 Sentencepiece: A simple and language independent subwordtokenizer and detokenizer for neural text processing,2018, arXiv preprint arXiv:1808
 In-vestigating multilingual nmt representations at scale,2019, arXiv preprint arXiv:1909
 Gshard: Scaling giant models with conditionalcomputation and automatic sharding,2020, arXiv preprint arXiv:2006
 Snr: Sub-network routingfor flexible parameter sharing in multi-task learning,2019, In Proceedings of the AAAI Conference onArtificial Intelligence
 Continuous multilinguality With language vectors,2016, arXivpreprint arXiv:1612
 A call for clarity in reporting BLEU scores,2018, In Proceedings of the Third Conferenceon Machine Translation: Research Papers
 Exploring the limits of transfer learning With a unified text-to-texttransformer,2019, arXiv preprint arXiv:1910
 Latent multi-task ar-chitecture learning,2019, In Proceedings of the AAAI Conference on Artificial Intelligence
 Leveraging monolingual data With self-supervision for multilingualneural machine translation,2020, arXiv preprint arXiv:2005
 Multilingual neural machine trans-lation with knowledge distillation,2019, arXiv preprint arXiv:1902
 Emerging language spaces learned from massively multilingual corpora,2018, arXivpreprint arXiv:1802
 Large scale parallel docu-ment mining for machine translation,2010, In Proceedings of the 23rd International Conference onCOmputatiOnal Linguistics
 Three strategies to im-prove one-to-many multilingual translation,2018, In PrOceedings Of the 2018 COnference On EmpiricalMethOds in Natural Language PrOcessing
 Condconv: Conditionally parameter-ized convolutions for efficient inference,2019, In Advances in Neural InfOrmatiOn PrOcessing Systems
