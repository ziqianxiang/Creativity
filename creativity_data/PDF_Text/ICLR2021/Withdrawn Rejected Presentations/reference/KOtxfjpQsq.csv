title,year,conference
 Pattern recognition and machine learning,2006, springer
 Learning phrase representations using RNN encoder-decoderfor statistical machine translation,2014, In Proc
 In Proc,2018, CoRL
 Rl 2 : Fastreinforcement learning via slow reinforcement learning,2017, In Proc
 Meta-learning and universality: Deep representations and gradientdescent can approximate any learning algorithm,2018, In Proc
 Model-agnostic meta-learning for fast adaptationof deep networks,2017, In Proc
 Bayesian reinforcementlearning: A survey,2015, FOUndatiOnS and TrendsÂ® in MaChine Learning
 Meta-reinforcement learning of structured exploration strategies,2018, In Proc
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, In Proc
 Explicit explore-exploit algorithms in continuous state spaces,2019, In Proc
 In Proc,2019, NeUrIPS
 Deep variationalreinforcement learning for POMDPs,2018, In Proc
 Unsu-pervised curricula for visual meta-reinforcement learning,2019, In Proc
 Robust and efficienttransfer learning with hidden parameter Markov decision processes,2017, In Proc
 Adam: A method for stochastic optimization,2015, 2015
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2017, In Proc
 Stochastic latent actor-critic:Deep reinforcement learning with a latent variable model,2019, arXiv PrePrint arXiv:1907
 In Proc,2019, NeUrIPS
 A simple neural attentive meta-learner,2018, In Proc
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 Neural network dynamics for model-baseddeep reinforcement learning with model-free fine-tuning,2018, In Proc
 Deep online learning via meta-learning:Continual adaptation for model-based RL,2019, In Proc
 Generalized hidden parameterMDPs transferable model-based RLina handful of trials,2020, In Proc
 EPOpt: LearningRobust Neural Network Policies Using Model Ensembles,2017, In Proc
 Efficient off-policymeta-reinforcement learning via probabilistic context variables,2019, In Proc
 Searching for activation functions,2017, arXivPrePrint arXiv:1710
 Promp: Proximalmeta-policy search,2019, In Proc
 Meta reinforcement learningwith latent variable Gaussian processes,2018, arXiv PrePrint arXiv:1803
 Simple principles of metalearning,1996, TeChniCaIreport IDSIA
 Monte-Carlo planning in large POMDPs,2010, In Proc
 Some considerations on learning to explore via meta-reinforcement learning,2018, arXivPrePrintarXiV:1803
 TOWardS GeneraIizatiOn and EffiCienCy in ReinfOrCement Learning,2019, PhD thesis
 Model-based RLin contextual decision processes: PAC bounds and exponential improvements over model-freeapproaches,2019, In Proc
 Model predictive path integral controlusing covariance variable importance sampling,2015, arXiv PrePrint arXiv:1509
 VariBAD: A very good method for Bayes-adaptive deep RL via meta-learning,2020, In Proc
	Assume that the	rollout process in which the	policy and	dynamics canbe switched to other ones at time step tsw,2019,	Letting two probabilities be p1 andp2
 27 and 35 into Eq,2019, 34
