title,year,conference
 Unsupervisedlabel noise modeling and loss correction,2019, In International Conference on Machine Learning(ICML)
 Massively multilingual sentence embeddings for zero-shotcross-lingual transfer and beyond,2018, CoRR
 Mixmatch: A holistic approach to semi-supervised learning,2019, In H
 Vicinal risk minimization,2001, InT
 XNLI: evaluating cross-lingual sentence representations,2018, CoRR
 A structural probe for finding syntax in word representa-tions,2019, In Proceedings of the 2019 Conference of the North American Chapter of the Association forComputational Linguistics: Human Language Technologies
 Universal language model fine-tuning for text classification,2018, InProceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume1: Long Papers)
 Contextual augmentation: Data augmentation by words with paradigmaticrelations,2018, In Proceedings of the 2018 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies
 Cross-lingual language model pretraining,2019, Advances inNeural Information Processing Systems (NeurIPS)
 Dividemix: Learning with noisy labels as semi-supervised learning,2020, In International Conference on Learning Representations
 Roberta: A robustly optimized BERT pretrainingapproach,2019, CoRR
 Learned in translation:Contextualized word vectors,2017, In Advances in Neural Information Processing Systems
 Distributed representationsof words and phrases and their compositionality,2013, In C
 Cross-lingualname tagging and linking for 282 languages,2017, In Proceedings of the 55th Annual Meeting of theAssociation for Computational Linguistics (Volume 1: Long Papers)
 Glove: Global vectors for wordrepresentation,2014, In EMNLP’14
 Regularizingneural networks by penalizing confident output distributions,2017, CoRR
 Deep contextualized word representations,2018, In NAACL
 Improving language under-standing by generative pre-training,2018, 2018
 Languagemodels are unsupervised multitask learners,2019, 2019
 Improving neural machine translation mod-els with monolingual data,2016, In Proceedings of the 54th Annual Meeting of the Associationfor Computational Linguistics (Volume 1: Long Papers)
 No more pesky learning rate guessing games,2015, CoRR
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
 Attention is all you need,2017, In I
 Huggingface’stransformers: State-of-the-art natural language processing,2019, ArXiv
 Conditional BERT contextualaugmentation,2018, CoRR
 mixup: Beyond empiricalrisk minimization,2018, In International Conference on Learning Representations
 Tri-training: exploiting unlabeled data using three classifiers,2005, IEEETransactions on Knowledge and Data Engineering
