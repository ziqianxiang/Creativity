title,year,conference
 Tractable nonparametric bayesian infer-ence in poisson processes with gaussian process intensities,2009, In ICML
 Layer normalization,2016, arXiv:1607
 Stochastic Geometry,2006, Springer
 Exchangeable generative modelswith flow scans,2020, In AAAI
 Statistical inference,2002, Duxbury Pacific Grove
 Neural networks with cheap differential operators,2019, InNIPS
 Neural ordinary differ-ential equations,2018, In NIPS
 Friendship and mobility: user movement inlocation-based social networks,2011, In ACM SIGKDD
 An introduction to the theory of point processes: Volume I: Elementarytheory and methods,2007, 2007
 Nice: Non-linear independent components esti-mation,2015, ICLR Workshop
 Density estimation using Real NVP,2017, InICLR
 Augmented neural odes,2019, In NIPS
 Neural spline flows,2019, InNIPS
 Made: Masked autoencoderfor distribution estimation,2015, In ICML
 Anode: Unconditionally accurate memory-efficientgradients for neural odes,2019, In IJCAI
 FFJORD:Free-form continuous dynamics for scalable reversible generative models,2019, In ICLR
 node2vec: Scalable feature learning for networks,2016, In KDD
 Deep residual learning for image recog-nition,2016, In CVPR
 Learning differentialequations that are easy to solve,2020, arXiv:2007
 Adam: A method for stochastic optimization,2015, In ICLR
 Auto-encoding variational bayes,2014, In ICLR
 EqUivariant flows: exact likelihood generative learningfor symmetric densities,2020, In ICML
 Gradient-based learning applied todocument recognition,1998, IEEE
 Settransformer: A framework for attention-based permutation-invariant neural networks,2019, In ICML
 Exchangeable neuralode for set modeling,2020, In NeurIPS
 Variational inference for gaussianprocess modulated poisson processes,2015, In ICML
 Beyond finite layer neural networks:Bridging deep architectures and numerical differential equations,2018, In ICML
 The neural hawkes process: A neurally self-modulating multi-variate point process,2017, In NIPS
 An introduction to simulation-based inference forspatial point processes,2003, In Spatial statistics and computational methods
 Janossy pooling:Learning deep permutation-invariant functions for variable-size inputs,2019, In ICLR
 Polygen: An autoregressivegenerative model of 3d meshes,2020, arXiv:2002
 Estimation of interaction potentials of marked spatialpoint patterns through the maximum likelihood method,1985, Biometrics
 Masked autoregressive flow for densityestimation,2017, In NIPS
 Normalizing flows for probabilistic modeling and inference,2019, arXiv:1912
 The conditional intensity of general point processes and an application toline processes,1974, ZeitschriftfUr Wahrscheinlichkeitstheorie Und Verwandte Gebiete
 Pointnet: Deep learning on point setsfor 3d classification and segmentation,2017, In CVPR
 Statistical mechanics: Rigorous results,1969, W
 Pointgrow: Autoregressivelylearned point cloud generation with self-attention,2020, In IEEE WACV
 Hamiltonian generative networks,2020, In ICLR
 Attention is all you need,2017, In NIPS
 Model-based learning forpoint pattern data,2018, Pattern Recognition
 On thelimitations of representing functions on sets,2019, In ICML
 3d shapenets: A deep representation for volumetric shapes,2015, In CVPR
 Graphrnn: Generatingrealistic graphs with deep auto-regressive models,2018, In ICML
 Deep sets,2017, In NIPS
 FSPool: Learning set representations withfeaturewise sort pooling,2020, In ICLR
 Adaptive checkpoint adjoint method for gradient estimation in neural ode,2020, InICML
 10 is called an affine transformation,2019, Instead
 First step is to build an inhomogeneous transformation — aneural network that acts on individual points xi ∈ Rd,2015, This is the use case from above
 8 is defined as a sum of all the contributions from other points in the set,2021, Weapply a function h : Rd → Rd to each point xi to get hi 
