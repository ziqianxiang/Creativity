title,year,conference
 Successor features for transfer in reinforcement learning,2017, In Advances in neuralinformation processing Systems
 Transfer in deep reinforcement learning usingsuccessor features and generalised policy improvement,2018, In International Conference on MachineLearning
 Fast reinforcementlearning with generalized policy updates,2020, Proceedings of the National Academy of Sciences
 Exploration with unreliable intrinsicreward in multi-agent reinforcement learning,2019, CoRR
 Deep coordination graphs,2020, In Proceedingsof Machine Learning and Systems (ICML)
 Universal successor features approximators,2018, arXiv preprintarXiv:1812
 Empirical evaluation ofgated recurrent neural networks on sequence modeling,2014, arXiv preprint arXiv:1412
 Improving generalization for temporal difference learning: The successor representa-tion,1993, Neural Computation
 Noisy networks for exploration,2018, In International Conference onLearning Representations (ICLR)
 Concrete dropout,2017, In Advances in Neural InformationProcessing Systems (NIPS)
 Coordinated reinforcement learning,2002, InICML
 Successor features based multi-agent rl forevent-based decentralized mdps,2019, In Proceedings of the AAAI Conference on Artificial Intelligence
 Fast task inference with variational intrinsic successor features,2019, arXiv preprintarXiv:1906
 Intrinsic social motivation via causal influ-ence in multi-agent RL,2018, CoRR
 Multi-agent reinforcement learning as a rehearsal fordecentralized planning,2016, NeurocomPuting
 Deep successorreinforcement learning,2016, arXiv PrePrint arXiv:1606
 Truly batch apprenticeship learningwith deep successor features,2019, arXiv PrePrint arXiv:1903
 Advantages and limitations of using suc-cessor features for transfer in reinforcement learning,2017, arXiv PrePrint arXiv:1708
 Autocurricula and the emergenceof innovation from social interaction: A manifesto for multi-agent intelligence research,2019, CoRR
 Maven: Multi-agentvariational exploration,2019, In Advances in Neural Information Processing Systems
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 The uncertainty Bell-man equation and exploration,2018, In Proceedings of the 35th International Conference on MachineLearning (ICML)
 A review of cooperative multi-agent deep rein-forcement learning,2019, arXiv PrePrint arXiv:1908
 Generalization and exploration via randomizedvalue functions,2016, In Proceedings of the 33rd International Conference on International Conferenceon Machine Learning (ICML)
 Biasing coevolutionary search for optimal multiagentbehaviors,2006, IEEE Transactions on Evolutionary ComPutation
 Curiosity-driven explorationby self-supervised prediction,2017, In Proceedings of the 34th International Conference on MachineLearning (ICML)
 Weighted qmix: Expandingmonotonic value function factorisation,2020, arXiv PrePrint arXiv:2006
 Monotonic value function factorisation for deep multi-agent reinforcementlearning,2020, arXiv PrePrint arXiv:2003
 Universal value function approxima-tors,2015, In International conference on machine learning
 Qtran: Learn-ing to factorize with transformation for cooperative multi-agent reinforcement learning,2019, arXivpreprint arXiv:1905
 Value-decompositionnetworks for cooperative multi-agent learning,2017, arXiv preprint arXiv:1706
 Multi-agent reinforcement learning: Independent vs,1993, cooperative agents
 Deep reinforcement learning with double q-learning,2016, In Proceedings of the 13th AAAI Conference on Artificial Intelligence
 Qplex: Duplex duelingmulti-agent q-learning,2020, arXiv preprint arXiv:2008
 Influence-based multi-agent ex-ploration,2020, In International Conference on Learning Representations
 Duelingnetwork architectures for deep reinforcement learning,2016, In International conference on machinelearning
 Multiagent soft q-learning,2018, arXiv preprintarXiv:1804
 Visual semantic planning using deep successor representations,2017, In Proceedingsof the IEEE international conference on computer vision
