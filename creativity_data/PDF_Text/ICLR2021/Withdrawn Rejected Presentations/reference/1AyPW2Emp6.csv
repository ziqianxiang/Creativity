title,year,conference
 Provably minimally-distorted adver-sarial examples,2017, arXiv preprint arXiv:1709
 Certified adversarial robustness via randomizedsmoothing,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Efficientand accUrate estimation of lipschitz constants for deep neUral networks,2019, In Advances in NeuralInformation Processing Systems
 On the effectiveness of intervalboUnd propagation for training verifiably robUst models,2018, arXiv preprint arXiv:1810
 CertifiedrobUstness to adversarial examples with differential privacy,2019, In 2019 IEEE Symposium on Securityand Privacy (SP)
 Certified adversarial robUstness withadditive noise,2019, In Advances in Neural Information Processing Systems
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, InAdvances in Neural Information Processing Systems
 Evaluating robustness of neural networks withmixed integer programming,2019, In International Conference on Learning Representations
 Lipschitz regularity of deep neural networks: analysis andefficient estimation,2018, In Advances in Neural Information Processing Systems
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Recurjac: An efficient recursive algorithm forbounding jacobian matrix of neural networks and its applications,2019, In Proceedings of the AAAIConference on Artificial Intelligence
