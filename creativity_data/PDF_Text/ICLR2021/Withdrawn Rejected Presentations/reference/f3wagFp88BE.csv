title,year,conference
 Threat of adversarial attacks on deep learning in computer vision:A survey,2018, IEEEAccess
 Layer normalization,2016, arXiv preprintarXiv:1607
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Certified adversarial robustness via randomizedsmoothing,2019, arXiv preprint arXiv:1902
 Histograms of oriented gradients for human detection,2005, In CVPR
 Adversarial examples are a naturalconsequence of test error in noise,2019, arXiv preprint arXiv:1901
 Batchnormalization is a cause of adversarial vulnerability,2019, arXiv preprint arXiv:1905
 Adversarial spheres,2018, arXiv preprint arXiv:1801
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Deep residual learning for image recog-nition,2016, In CVPR
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In ICML
 Revisiting batch normaliza-tion for practical domain adaptation,2016, arXiv preprint arXiv:1603
 Towards understanding regularizationin batch normalization,2018, arXiv preprint arXiv:1809
 The curse of concentrationin robust learning: Evasion and poisoning attacks from concentration of measure,2019, In Proceedingsofthe AAAI Conference on Artificial Intelligence
 Batch-instance normalization for adaptively style-invariantneural networks,2018, In Advances in Neural Information Processing Systems
 Adversarial robustness through locallinearization,2019, In Advances in Neural Information Processing Systems
 Learning multiple visual domains withresidual adapters,2017, In NIPS
 Adver-sarially robust generalization requires more data,2018, In Advances in Neural Information ProcessingSystems
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 A boundary tilting persepective on the phenomenon of adversarialexamples,2016, arXiv preprint arXiv:1608
 Instance normalization: The missing in-gredient for fast stylization,2016, arXiv preprint arXiv:1607
 Group normalization,2018, In ECCV
 Intriguing properties of adversarial training at scale,2019, arXiv preprintarXiv:1906
 Defense against adversarial attacks using feature scattering-basedadversarial training,2019, In Advances in Neural Information Processing Systems
 Fixup initialization: Residual learning withoutnormalization,2019, arXiv preprint arXiv:1901
 introduced a methodology to extract feature datasets from models,1500, In particular thedatasets DR
