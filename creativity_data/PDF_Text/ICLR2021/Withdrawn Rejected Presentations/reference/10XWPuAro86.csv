title,year,conference
 Inverse modeling of the ocean and atmosphere,2005, Cambridge University Press
 The geometric foundationsof Hamiltonian Monte Carlo,2017, Bernoulli
 Sample-efficient reinforcement learning with stochastic ensemble value expansion,2018, In Advances in NeuralInformation Processing Systems
 Matrix completion with noise,2010, Proceedings of the IEEE
 Harnessing structures in big data via guaranteed low-rank matrixestimation: Recent theory and fast algorithms via convex and nonconvex optimization,2018, IEEESignal Processing Magazine
 Pilco: A model-based and data-efficient approach to policysearch,2011, In International Conference on Machine Learning (ICML)
 Benchmarking deepreinforcement learning for continUoUs control,2016, In International Conference on Machine Learning(ICML)
 Hoeffdingâ€™s lemma for markov chains and its applicationsto statistical learning,2018, arXiv preprint arXiv:1802
 CUrvatUre and concentration ofHamiltonian Monte Carlo in high dimensions,2014, arXiv:1407
 ConstrUcting basis fUnctions from directed graphs for valUefUnction approximation,2007, In Proceedings of the 24th international conference on Machine learning
 Nonparametric stochasticcompositional gradient descent for q-learning in continuous markov decision problems,2018, arXivpreprint arXiv:1804
 Sample-efficient deep reinforcement learning viaepisodic backward update,2019, In Advances in Neural Information Processing Systems
 Metropolized independent sampling with comparisons to rejection sampling and impor-tance sampling,1996, Statistics and Computing
 Feedback regularization andgeometric pid control for trajectory tracking of mechanical systems: Hoop robots on an inclinedplane,2017, In 2017 American Control Conference (ACC)
 A Geometric PID Control Framework forMechanical Systems,2016, arXiv:1610
 Convergence of Q-learning: A simple proof,2001, Institute Of Systems and Robotics
 Human-level controlthrough deep reinforcement learning,2015, Nature
 MCMC using Hamiltonian dynamics,2011, Handbook of Markov Chain MonteCarlo
 Involutive MCMC: A UnifyingFramework,2020, arXiv:2006
 Value function approximation via low-rank models,2015, arXiv:1509
 Probabilistic differential dynamic programming,2014, InAdvances in Neural Information Processing Systems
 Sample efficient reinforcement learningvia low-rank matrix estimation,2020, arXiv:2006
 Mastering the game of Gowithout human knowledge,2017, Nature
 On the convergence of smooth regularized approximate valueiteration schemes,2020, Advances in Neural Information Processing Systems
 Reinforcement learning: An introduction,2018, MIT press
 Learning from delayed rewards,1989, PhD thesis
 Solving a low-rank factorization model for matrixcompletion by a nonlinear successive over-relaxation algorithm,2012, Mathematical ProgrammingComputation
 Parallel matrix factorization for low-rank tensorcompletion,2013, arXiv:1312
 A regularized approach to sparse optimal policy inreinforcement learning,2019, In Advances in Neural Information Processing Systems
 Harnessing structures for value-based planningand reinforcement learning,2020, In International Conference on Learning Representations (ICLR)
 Roll-back Hamiltonian Monte Carlo,2017, arXiv:1709
 Optimizing chemical reactions with deepreinforcement learning,2017, ACS Central Science
