title,year,conference
 Representation learning: A review and newperspectives,0162, IEEE Trans
 A simple framework forcontrastive learning of visual representations,2020, arXiv preprint arXiv:2002
 Unsupervised visual representation learningby context prediction,2015, In Proceedings of the 2015 IEEE International Conference on ComputerVision (ICCV)
 Decaf: A deep convolutional activation feature for generic visual recognition,2014, In Proceedingsof the 31st International Conference on Machine Learning
 Dynamic task prioriti-zation for multitask learning,2018, In ECCV
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In 2015 IEEE International Conference onComputer Vision (ICCV)
 Using pre-training can improve model robustnessand uncertainty,2019, In ICML
 Learning deep representations by mutual information estimationand maximization,2019, In ICLR
 Albert: A lite bert for self-supervised learning of language representations,2020, In ICLR
 Representationlearning using multi-task deep neural networks for semantic classification and information re-trieval,2015, In Proceedings of the 2015 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies
 Multi-task deep neural networksfor natural language understanding,2019, In Proceedings of the 57th Annual Meeting of the Associationfor Computational Linguistics
 Vilbert: Pretraining task-agnostic visiolinguis-tic representations for vision-and-language tasks,2019, In Advances in Neural Information ProcessingSystems
 Distributed representa-tions of words and phrases and their compositionality,2013, In Proceedings of the 26th InternationalConference on Neural Information Processing Systems
 Unsupervised learning of visual representions by solving jigsawpuzzles,2016, In ECCV
 Learning and transferring mid-levelimage representations using convolutional neural networks,2014, 2014 IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 Contextencoders: Feature learning by inpainting,2016, 2016 IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Glove: Global vectors for wordrepresentation,2014, In Empirical Methods in Natural Language Processing (EMNLP)
 To tune or not to tune? adapting pretrainedrepresentations to diverse tasks,2019, In Proceedings of the 4th Workshop on Representation Learningfor NLP
 An overview of multi-task learning in deep neural networks,2017,	ArXiv
 CNN featuresoff-the-shelf: an astounding baseline for recognition,2014, In CVPR DeepVision workshop
 Vl-bert: Pre-training of generic visual-linguistic representations,2020, In International Conference on LearningRepresentations
 A survey on multi-task learning,2017, ArXiv
 A novel clickmodel and its applications to online advertising,2010, In Proceedings of the Third ACM InternationalConference on Web Search and Data Mining
