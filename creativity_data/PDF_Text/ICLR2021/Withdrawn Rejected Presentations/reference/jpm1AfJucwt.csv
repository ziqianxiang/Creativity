title,year,conference
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Global sparse momentumsgd for pruning very deep neural networks,2019, In NeurIPS
 Gradient flow in sparse neural networksand how lottery tickets win,2020, arXiv preprint arXiv:2010
 The state of sparsity in deep neural networks,2019, arXivpreprint arXiv:1902
 Fastapproximate natural gradient descent in a kronecker factored eigenbasis,2018, In NIPS
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In AISTATS
 Second order derivatives for network Pruning: OPtimal brainsurgeon,1993, In NIPS
 Delving deeP into rectifiers: SurPassinghuman-level Performance on imagenet classification,2015, In ICCV
 DeeP residual learning for imagerecognition,2016, In CVPR
 Identity maPPings in deeP residualnetworks,2016, In ECCV
 On “natural” learning and Pruning in multilayered PercePtrons,2000, Neural Computation
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In ICML
 Learning multiple layers of features from tiny images,2009, 2009
 Optimal brain damage,1990, In NIPS
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 A signal propagationperspective for pruning neural networks at initialization,2019, arXiv preprint arXiv:1906
 SNIP: Single-Shot Network Pruning basedon Connection Sensitivity,2019, In ICLR
 Learning sparse neural networks throughl_0 regularization,2017, arXiv preprint arXiv:1712
 Optimizing neural networks with kronecker-factored approximatecurvature,2015, In ICML
 Variational dropout sparsifies deep neuralnetworks,2017, In ICML
 Importance estimation forneural network pruning,2019, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Rectified linear units improve restricted boltzmann machines,2010, InICML
 Automatic differentiation inpytorch,2017, 2017
 Comparing rewinding and fine-tuning inneural network pruning,2020, In ICLR
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Woodfisher: Efficient second-order approximations for modelcompression,2020, arXiv preprint arXiv:2004
 Pruning neural networkswithout any data by iteratively conserving synaptic flow,2020, arXiv preprint arXiv:2006
 Eigendamage: Structured pruningin the kronecker-factored eigenbasis,2019, arXiv preprint arXiv:1905
 Picking winning tickets before training bypreserving gradient flow,2020, In ICLR
 Aggregated residualtransformations for deep neural networks,2017, In CVPR
