title,year,conference
 Thevulnerability of learning to adversarial perturbation increases with intrinsic dimensionality,2017, In2017 IEEE Workshop on Information Forensics and Security (WIFS)
 Obfuscated Gradients Give a False Sense ofSecurity: Circumventing Defenses to Adversarial Examples,0970, 2018
 Decision-Based Adversarial Attacks: ReliableAttacks Against Black-Box Machine Learning Models,1712, arXiv:1712
 Towards Evaluating the Robustness of Neural Networks,2016, InSecurity and Privacy (SP)
 HopSkipJumpAttack: A Query-EfficientDecision-Based Attack,2019, arXiv:1904
 Query-efficient hard-label black-box attack: An optimization-based approach,2019, International Conferenceon Learning Representations
 SIGN-OPT: A QUERY-EFFICIENT HARD-LABEL ADVERSARIAL ATTACK,2020, The InternationalConference on Learning Representations (ICLR)
 Certified Adversarial Robustness via Ran-domized Smoothing,1902, arXiv:1902
 Explaining and Harnessing AdversarialExamples,1412, 2014
 Black-box Adversarial Attackswith Limited Queries and Information,1804, arXiv:1804
 The Robust ManifoldDefense: Adversarial Training using Generative Models,2019, arXiv:1712
 Sensible Adversarial Learning,2020, 2020
 Learning Multiple Layers of Features from Tiny Images,2009, pp
 Zeroth-Order Online Alternating DirectionMethod of Multipliers: Convergence Analysis and Applications,2018, In Proceedings of the 21stInternational Conference on Artificial Intelligence and Statistics (AISTATS) 2018
 DeepFool: a simpleand accurate method to fool deep neural networks,1511, 2015
 Practical Black-Box Attacks against Machine Learning,2017, Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Defense-gan: Protecting classifiersagainst adversarial attacks using generative models,2018, In International Conference on LearningRepresentations
 Defense-GAN: Protecting Classifiersagainst Adversarial Attacks using Generative Models,2018, pp
 Intriguing properties of neural networks,1312, pp
 A Boundary Tilting Persepective on the Phenomenon of AdversarialExamples,2016, arXiv:1608
 On Adaptive Attacksto Adversarial Example Defenses,2002, arXiv:2002
 Stealing Machine Learning Models via Prediction APIs,2016, 2016
 Defense Against Adversarial Attacks Using Feature Scattering-based Adversarial Training,2019, In H
 Adversarial Interpolation Training: A simple approach for improvingmodel robustness,2020, 2020
