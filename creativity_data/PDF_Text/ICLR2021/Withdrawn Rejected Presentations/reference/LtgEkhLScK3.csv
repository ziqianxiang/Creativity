title,year,conference
 Reinforcement learning from a mixture of interpretableexperts,2020, CoRR
 Neuronlike adaptive elements thatcan solve difficult learning control problems,1983, IEEE Trans
 Openai gym,2016, CoRR
 Feudal reinforcement learning,1992, In NeurIPS
 Multiple model-basedreinforcement learning,2002, Neural Comput
 The reactor:A sample-efficient actor-critic architecture,2017, CoRR
 Adaptive mixturesof local experts,1991, Neural Comput
 Adaptive mixturesof local experts,1991, Neural Comput
 Adam: A method for stochastic optimization,2015, In ICLR
 Continuous control with deep reinforcement learning,2016, In ICLR
 Variational mixtures of gaussian processes for classification,2017, In IJCAI
 Automatic discovery of subgoals in reinforcement learningusing diverse density,2001, In ICML
 Q-cut - dynamic discovery of sub-goals inreinforcement learning,2002, In ECML
 Asynchronous methods for deep reinforcementlearning,2016, In ICML
 PGQ: combiningpolicy gradient and q-learning,2016, CoRR
 Terrain-adaptive locomotion skills usingdeep reinforcement learning,2016, ACM Trans
 Reinforcement learning of motor skills with policy gradients,2008, NeuralNetworks
 Proximal policyoptimization algorithms,2017, CoRR
 Compositional planning using optimal option models,2012, In ICML
 Reinforcement learning - an introduction,1998, Adaptivecomputation and machine learning
 Policy gradientmethods for reinforcement learning with function approximation,1999, In NeurIPS
 Mixtures of gaussian processes,2000, In NeurIPS
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,1861, volume 80
 Feudal networks for hierarchical reinforcement learning,2017, In ICML
 DAC: the double actor-critic architecture for learningoptions,2019, In NeurIPS
99replay buffer size	106alpha	0,2015,2batch size	100polyak (Ï„)	0
