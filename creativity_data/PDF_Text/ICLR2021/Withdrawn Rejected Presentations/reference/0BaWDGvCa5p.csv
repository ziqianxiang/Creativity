title,year,conference
 Last-iterate convergence rates for min-maxoptimization,2019, arXiv preprint arXiv:1906
 Towards principled methods for training generative adversarialnetworks,2017, In 5th International Conference on Learning Representations
 The Cramer distance as a solution to biased Wassersteingradients,2017, CoRR
 Pros and cons of gan evaluation measures,2019, Computer Vision and Image Understanding
 Convex optimization: Algorithms and complexity,2017, Foundations and Trends inMachine Learning
 Mode regularized generativeadversarial networks,2017, In International Conference on Learning Representations
 Training GANs withoptimism,2018, In International Conference on Learning Representations
 Adversarially learned inference,2017, In 5th International Conference onLearning Representations
 Convergence of learning dynamics instackelberg games,2019, CoRR
 Escaping from saddle pointsâ€”online stochasticgradient for tensor decomposition,2015, In Conference on Learning Theory
 Avariational inequality perspective on generative adversarial networks,2019, In International Conferenceon Learning Representations (ICLR 2019)
 Adam: A method for stochastic optimization,2015, In InternationalConference for Learning Representations
 Interaction matters: A note on non-asymptotic local convergenceof generative adversarial networks,2019, In The 22nd International Conference on Artificial Intelligenceand Statistics
 Geometric gan,2017, arXiv preprint arXiv:1705
 On gradient descent ascent for nonconvex-concave minimaxproblems,2020, In 37th International Conference on Machine Learning
 Hybrid block successive ap-proximation for one-sided non-convex min-max problems: algorithms and applications,2020, IEEETransactions on Signal Processing
 Guidedevolutionary strategies: augmenting random search with surrogate gradients,2019, In InternationalConference on Machine Learning
 A second-order equilibrium in nonconvex-nonconcavemin-max optimization: Existence and algorithm,2020, arXiv preprint arXiv:2006
 Leastsquares generative adversarial networks,2017, In Proceedings of the IEEE International Conference onComputer Vision
 The numerics of gans,2017, In Advances inNeural Information Processing Systems
 Unrolled generative adversarialnetworks,2017, In 5th International Conference on Learning Representations
 Spectral normalization forgenerative adversarial networks,2018, In International Conference on Learning Representations
 A unified analysis of extra-gradient andoptimistic gradient methods for saddle point problems: Proximal point approach,2020, In InternationalConference on Artificial Intelligence and Statistics
 Gradient descent GAN optimization is locally stable,2017, InAdvances in Neural Information Processing Systems
 Cesari convergence of the gradient method ofapproximating saddle points of convex-concave functions,1978, In Doklady Akademii Nauk
 Non-convex min-max optimization:Provable algorithms and applications in machine learning,2018, arXiv preprint arXiv:1810
 On the convergence of adam and beyond,2019, arXivpreprint arXiv:1904
 Improving GANs using optimaltransport,2018, In International Conference on Learning Representations
 Veegan:Reducing mode collapse in gans using implicit variational learning,2017, In Advances in NeuralInformation Processing Systems
 Efficientalgorithms for smooth minimax optimization,2019, NeurIPS
 On solving minimax optimization locally: Afollow-the-ridge approach,2020, In International Conference on Learning Representations
2 and dropout regularization of 0,1024,2 at each layer
