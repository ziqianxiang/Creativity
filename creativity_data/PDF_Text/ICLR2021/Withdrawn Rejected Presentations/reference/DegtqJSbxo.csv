title,year,conference
 Towards evaluating the robustness of neural networks,2017, In 2017ieee symposium on security and privacy (sp)
 Imagenet: A large-scale hierarchicalimage database,2009, In 2009 IEEE Conference on Computer Vision and Pattern Recognition
 A study and comparison of human and deep learning recogni-tion performance under visual distortions,2017, In 2017 26th international conference on computercommunication and networks (ICCCN)
 Ex-ploring the landscape of spatial robustness,2019, In International Conference on Machine Learning
 Adversarial examples are a naturalconsequence of test error in noise,2019, arXiv preprint arXiv:1901
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Benchmarking neural network robustness to common cor-ruptions and perturbations,2019, arXiv preprint arXiv:1903
 Geometric robustness of deepnetworks: analysis and improvement,2018, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Testing robustness againstunforeseen adversaries,2019, arXiv preprint arXiv:1908
 Learning multiple layers of features from tiny images,2009, 2009
 Increasing the robustness of dnns against image corruptions byplaying the game of noise,2020, arXiv preprint arXiv:2001
 Robust local features forimproving the generalization of adversarial training,2019, arXiv preprint arXiv:1909
 Is robustnessthe cost of accuracy?-a comprehensive study on the robustness of 18 deep image classificationmodels,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Thelimitations of adversarial training and the blind-spot attack,2019, arXiv preprint arXiv:1901
 Interpreting adversarially trained convolutional neural net-works,2019, arXiv preprint arXiv:1905
 A large-scaleattribute dataset for zero-shot learning,2018, arXiv preprint arXiv:1804
