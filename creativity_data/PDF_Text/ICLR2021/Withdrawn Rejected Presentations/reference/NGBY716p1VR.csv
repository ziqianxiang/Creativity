title,year,conference
 Square attack:a query-efficient black-box adversarial attack via random search,2019, arXiv preprint arXiv:1912
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2017, arXiv preprint arXiv:1712
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 On evaluating adversarial robustness,2019, arXiv preprintarXiv:1902
 Certified adversarial robustness via randomizedsmoothing,2019, arXiv preprint arXiv:1902
 Minimally distorted adversarial examples with a fast adaptiveboundary attack,2019, arXiv preprint arXiv:1907
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, arXiv preprint arXiv:2003
 Adual approach to scalable verification of deep networks,2018, arXiv preprint arXiv:1803
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2017, arXiv preprint arXiv:1711
 Learning multiple layers of features from tiny images,2009, 2009
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Certifiedrobustness to adversarial examples with differential privacy,2018, arXiv preprint arXiv:1802
 Certified adversarial robustness withadditive noise,2019, In Advances in Neural Information Processing Systems
 Mixed precisiontraining,2017, arXiv preprint arXiv:1710
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 Certified defenses against adversarialexamples,2018, arXiv preprint arXiv:1801
 Overfitting in adversarially robust deep learning,2020, arXivpreprint arXiv:2002
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Output diversified initialization for adversarialattacks,2020, arXiv preprint arXiv:2003
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 On adaptive attacks toadversarial example defenses,2020, arXiv preprint arXiv:2002
 Mixtrain: Scalable training of formallyrobust neural networks,2018, arXiv preprint arXiv:1811
 On theconvergence and robustness of adversarial training,2019, In International Conference on MachineLearning
 Scaling provable adversarialdefenses,2018, arXiv preprint arXiv:1805
 Fast is better than free: Revisiting adversarial training,2019, InInternational Conference on Learning Representations
 Feature denoisingfor improving adversarial robustness,2019, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Wide residual networks,2016, arXiv preprint arXiv:1605
 You only propagateonce: Accelerating adversarial training via maximal principle,2019, In Advances in Neural InformationProcessing Systems
 Efficient neural networkrobustness certification with general activation functions,2018, In Advances in Neural InformationProcessing Systems
