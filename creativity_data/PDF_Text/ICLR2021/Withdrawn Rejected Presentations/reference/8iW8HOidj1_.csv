title,year,conference
 Online optimization in x-armed bandits,2009, In Advances in Neural Information Processing Systems
 Progressive strategies for monte-carlo tree search,2008, New Mathematics andNatural Computation
 Continuous upper confidence trees,2011, In International Conference on Learning and IntelligentOptimization
 Efficient selectivity and backup operators in monte-carlo tree search,2006, In Internationalconference on computers and games
 Addressing function approximation error inactor-critic methods,2018, arXiv preprint arXiv:1802
 Shaping belief states with generative environment models for rl,2019, In Advances in NeuralInformation Processing Systems
 World models,2018, arXiv preprint arXiv:1803
 Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor,2018, arXiv preprintarXiv:1801
 Dream to control: Learningbehaviors by latent imagination,2019, arXiv preprint arXiv:1912
 Learning latent dynamics for planning from pixels,2019, In International Conference onMachine Learning
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Stochastic latent actor-critic:Deep reinforcement learning with a latent variable model,2019, arXiv preprint arXiv:1907
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Sample-based planning for contin-uous action markov decision processes,2011, In ICAPS
 A0c: Alpha zero incontinuous action space,2018, arXiv preprint arXiv:1805
 Neural network dynamics for model-baseddeep reinforcement learning with model-free fine-tuning,2018, In 2018 IEEE International Conferenceon Robotics and Automation (ICRA)
 Stochastic backpropagation andapproximate inference in deep generative models,2014, arXiv preprint arXiv:1401
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Mastering the game of gowithout human knowledge,2017, nature
 Reinforcement learning: An introduction,2018, MIT press
 Q-learning in enor-mous action spaces via amortized approximate maximization,2020, arXiv preprint arXiv:2001
