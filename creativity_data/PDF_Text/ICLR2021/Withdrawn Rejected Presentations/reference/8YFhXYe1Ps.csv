title,year,conference
 Sanitychecks for Saliency maps,2018, In Advances in Neural Information Processing Systems
 Evaluat-ing saliency map explanations for convolutional neural networks: A user study,2020, In Proceedings ofthe 25th International Conference on Intelligent User Interfaces
 Two4two dataset,2020, Under Review
 On pixel-wise explanations for non-linear classifier decisions by layer-wiserelevance propagation,2015, PLoS ONE
 Explaining image classifiersby counterfactual generation,2019, In ICLR
 This lookslike that: deep learning for interpretable image recognition,2019, In Advances in neural informationprocessing systems
 Neural ordinarydifferential equations,2018, Advances in Neural Information Processing Systems
 Nice: Non-linear independent componentsestimation,2015, CoRR
 Density estimation using real nvp,2016, arXivpreprint arXiv:1605
 Ultraviolet-induced pigmentary changes: benefits and hazards,1986, Current problems indermatology
 Towards aUtomatic concept-basedexplanations,2019, In Advances in Neural Information Processing Systems
 CoUnterfactUal visUalexplanations,2019, ArXiv
 Metrics for explainable ai:Challenges and prospects,2018, arXiv preprint arXiv:1812
 i-revnet: Deep invertiblenetworks,2018, In International Conference on Learning Representations
 Glow: Generative flow with invertible 1x1 convolutions,2018, ArXiv
 Deep learning face attributes in the wild,2015, InProceedings of International Conference on Computer Vision (ICCV)
 Generative classifiers as abasis for trustworthy computer vision,2020, arXiv preprint arXiv:2007
 Graphnvp: An invertibleflow model for generating molecular graphs,2019, arXiv preprint arXiv:1905
 Layer-wise relevance propagation: an overview,2019, In ExplainableAI: interpreting
 ”why should i trust you?”: Explaining thepredictions of any classifier,2016, Proceedings of the 22nd ACM SIGKDD International Conference onKnowledge Discovery and Data Mining
 Explanation byprogressive exaggeration,2020, In International Conference on Learning Representations
 When explanations lie: Why many modified bpattributions fail,2020, In Proceedings of the 37th International Conference on Machine Learning
 Smoothgrad:removing noise by adding noise,2017, arXiv: 1706
 Approximation capabilities of neural odesand invertible residual networks,2019, arXiv: Learning
