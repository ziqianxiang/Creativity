title,year,conference
 Unsupervised labelnoise modeling and loss correction,2019, In ICML
 A closer look at memorization in deep netWorks,2017, In ICML
 Model compression,2006, In KDDM
 Maximum-entropy fine grainedclassification,2018, In NeurIPS
 Training deep neural-netWorks using a noise adaptationlayer,2017, In ICLR
 Semi-supervised learning by entropy minimization,2005, InNeurIPS
 Co-teaching: Robust training of deep neural netWorks With extremely noisy labels,2018, InNeurIPS
 Deep residual learning for image recog-nition,2016, In CVPR
 Using trusted data to traindeep netWorks on labels corrupted by severe noise,2018, In NeurIPS
 Distilling the knoWledge in a neural netWork,2015, InNeurIPS Deep Learning and Representation Learning Workshop
 Mentornet: Learning data-driven curriculum for very deep neural netWorks on corrupted labels,2018, In ICML
 Learning multiple layers of features from tiny images,2009, 2009
 Deep learning,2015, Nature
 Pseudo-label: The simple and efficient semi-supervised learning method for deepneural netWorks,2013, 2013
 Cleannet: Transfer learning forscalable image classifier training With label noise,2018, In CVPR
 Learning fromnoisy labels With distillation,2017, In ICCV
 Dimensionality-driven learning with noisy labels,2018, In ICML
" Decoupling ""when to update"" from ""how to update""",2017, InNeurIPS
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In CVPR
 Regularizingneural networks by penalizing confident output distributions,2017, In ICLR Workshop
 Deep co-training for semi-supervised image recognition,2018, In ECCV
 Training deep neural networks on noisy labels with bootstrapping,2015, In ICLR Workshop
 Fitnets: Hints for thin deep nets,2015, In ICLR
 Learning representations by back-propagating errors,1986, Nature
 Selfie: Refurbishing unclean samples for robustdeep learning,2019, In ICML
 Learning from noisy labels with deep neural networks,2014, arXivpreprint arXiv:1406
 Rethinkingthe inception architecture for computer vision,2016, In CVPR
 Joint optimization frame-work for learning with noisy labels,2018, In CVPR
 Learningfrom noisy large-scale datasets with minimal supervision,2017, In CVPR
 Symmetric crossentropy for robust learning with noisy labels,2019, In ICCV
 Combating noisy labels by agreement: A jointtraining method with co-regularization,2020, In CVPR
 Learning from massive noisylabeled data for image classification,2015, In CVPR
 Disturblabel: Regularizing cnnon the loss layer,2016, In CVPR
 Variational label enhancement,2020, In ICML
 Safeguarded dynamic label regres-sion for noisy supervision,2019, In AAAI
 Revisiting knowledge distillationvia label smoothing regularization,2020, In CVPR
 Regularizing class-wise predictions viaself-knowledge distillation,2020, In CVPR
 Deep mutual learning,2018, In CVPR
 Generalized cross entropy loss for training deep neural networkswith noisy labels,2018, In NeurIPS
