title,year,conference
 Theoretical analysis of auto rate-tuning by batchnormalization,2019, In International Conference on Learning Representations
 Layer normalization,2016, arXiv preprintarXiv:1607
 A quantitative analysis of the effect of batch normal-ization on gradient descent,2019, volume 97 of Proceedings of Machine Learning Research
 Language modeling with gatedconvolutional networks,2017, volume 70 of Proceedings of Machine Learning Research
 Gradient descent learnsone-hidden-layer CNN: Donâ€™t be afraid of spurious local minima,1339, volume 80 of Proceedings ofMachine Learning Research
 Optimization theory for relu neural networkstrained with normalization layers,2020, In International Conference on Machine Learning
 Implicit bias of gradient descenton linear convolutional networks,2018, In S
 Neural tangent kernel: Convergence andgeneralization in neural networks,2018, In S
 The implicit bias of gradient descent on nonseparable data,2019, volume 99of Proceedings of Machine Learning Research
 Gradient descent aligns the layers of deep linear networks,2019, InInternational Conference on Learning Representations
 Directional convergence and alignment in deep learning,2020, arXivpreprint arXiv:2006
 Bilinear attention networks,2018, In S
 Positional normalization,2019, In H
 Towards understanding regularizationin batch normalization,2019, In International Conference on Learning Representations
 Gradient descent maximizes the margin of homogeneous neural net-works,2020, In International Conference on Learning Representations
 Convergence of gradient descent on separable data,2019, volume 89 ofProceedings of Machine Learning Research
 Rethinking normalization andelimination singularity in neural networks,2019, arXiv preprint arXiv:1911
 Spherical perspective on learning with batch norm,2020, arXiv preprint arXiv:2006
 Weight normalization: A simple reparameterization toaccelerate training of deep neural networks,2016, In D
 How does batchnormalization help optimization? In S,2018, Bengio
 Robust large margindeep neural networks,2017, IEEE Transactions on Signal Processing
 The implicit bias of gradient descent on sep-arable data,2018, In International Conference on Learning Representations
 Implicit regularization of normalization methods,2019, arXiv preprintarXiv:1911
