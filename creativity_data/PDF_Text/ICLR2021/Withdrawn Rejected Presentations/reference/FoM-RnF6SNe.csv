title,year,conference
 Solving rubik’s cube with a robot hand,2019, arXiv preprint arXiv:1910
 Playing hard exploration gamesby watching youtube,2018, In Advances in Neural Information Processing Systems
 Unifying count-basedexploration and intrinsic motivation,2016, In Advances in Neural Information Processing Systems
 Unifying count-basedexploration and intrinsic motivation,2016, In Advances in Neural Information Processing Systems
 Large-scale study ofcuriosity-driven learning,2018, arXiv preprint arXiv:1808
 Exploration by random network distillation,2018, arXivpreprint arXiv:1810
 Go-explore: a new approach forhard-exploration problems,2019, arXiv preprint arXiv:1901
 Action and perception as divergenceminimization,2020, arXiv preprint arXiv:2009
 Vime: Variationalinformation maximizing exploration,2016, In Advances in Neural Information Processing Systems
 Inverse reinforcement learning through structuredclassification,2012, In F
 On the dirichlet distribution,2016, Master’s thesis
 On a measure of the information provided by an experiment,1956, The Annals ofMathematical Statistics
 Human-level control through deep reinforcementlearning,2015, Nature
 Variational information maximisation for intrinsically motivatedreinforcement learning,2015, In Advances in neural information processing systems
 Intrinsic motivation systems for autonomous mentaldevelopment,2007, IEEE transactions on evolutionary computation
 Curiosity-driven exploration by self-supervisedprediction,2017, In Proceedings of the IEEE Conference on Computer Vision and Pattern RecognitionWorkshops
 Making the world differentiable: On using self-supervised fully recurrent neuralnetworks for dynamic reinforcement learning and planning in non-stationary environments,1990, 1990
 Proximal policy optimizationalgorithms,2017, arXiv preprint arXiv:1707
 Planning to explore viaself-supervised world models,2020, arXiv preprint arXiv:2005
 Model-based active exploration,2018, arXiv preprintarXiv:1810
 Mastering the game of go without human knowledge,2017, Nature
 Planning to be surprised: Optimal bayesian explorationin dynamic environments,2011, In International Conference on Artificial General Intelligence
 On bonus-basedexploration methods in the arcade learning environment,2020, 2020
 Meta-world: A benchmarkand evaluation for multi-task and meta reinforcement learning,2019, arXiv preprint arXiv:1910
 Atari-head: Atari humaneye-tracking and demonstration dataset,2019, ArXiv
 Maximum entropy inverse reinforcementlearning,2008, In Proc
