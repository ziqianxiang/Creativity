title,year,conference
 Privacy-preserving neural representationsof text,2018, In Proceedings of the 2018 Conference on Empirical Methods in Natural LanguageProcessing
 Ranking a stream of news,2005, InProceedings of the 14th international conference on World Wide Web
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 On adversarial examples for character-level neuralmachine translation,2018, arXiv preprint arXiv:1806
 Hotflip: White-box adversarial examplesfor text classification,2018, In ACL
 Black-box generation of adversarial textsequences to evade deep learning classifiers,2018, In 2018 IEEE Security and Privacy Workshops (SPW)
 Explaining and harnessing adversarialexamples,2015, In ICLR
 Teaching machines to read and comprehend,2015, In Advances in neuralinformation processing systems
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Is bert really robust? a strong baseline fornatural language attack on text classification and entailment,2019, arXiv
 Spanbert:Improving pre-training by representing and predicting spans,2020, Transactions of the Association forComputational Linguistics
 Textbugger: Generating adversarial textagainst real-world applications,2018, arXiv preprint arXiv:1812
 Bert-attack: Adversarialattack against bert using bert,2020, arXiv preprint arXiv:2004
 Towards robust and privacy-preserving text rep-resentations,2018, In Proceedings of the 56th Annual Meeting of the Association for ComputationalLinguistics
 Multi-task deep neural networks fornatural language understanding,2019, In Proceedings of the 57th Annual Meeting of the Association forComputational Linguistics
 Delving into transferable adversarial examplesand black-box attacks,2016, arXiv preprint arXiv:1611
 Differentially private representation for nlp: Formalguarantee and an empirical study on privacy and fairness,2020, arXiv preprint arXiv:2010
 Towards differentially private text repre-sentations,2020, In Proceedings of the 43rd International ACM SIGIR Conference on Research andDevelopment in Information Retrieval
 Passage re-ranking with bert,2019, arXiv preprintarXiv:1901
 Towards reverse-engineering black-box neuralnetworks,2019, In Explainable AI: Interpreting
 Knockoff nets: Stealing functionalityof black-box models,2019, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACM onAsia conference on computer and communications security
 Discrimination-aware data mining,2008, InProceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and datamining
 Membership inference attacksagainst machine learning models,2017, In 2017 IEEE Symposium on Security and Privacy (SP)
 Information leakage in embedding models,2020, arXivpreprint arXiv:2004
 Intriguing properties of neural networks,2014, In ICLR
 Imitation attacks and defenses for black-box machinetranslation systems,2020, arXiv preprint arXiv:2004
 Stealing hyperparameters in machine learning,2018, In 2018IEEE Symposium on Security and Privacy (SP)
 Privacy risk in machine learning:Analyzing the connection to overfitting,2018, In 2018 IEEE 31st Computer Security FoundationsSymposium (CSF)
 Understandingdeep learning requires rethinking generalization,2017, In ICLR
 Character-level convolutional networks for textclassification,2015, In Advances in neural information processing systems
