title,year,conference
 Learning the task allocation game,2006, In Proceedings of the fifthinternational joint conference onAutonomous agents and multiagent Systems
 Deep elastic networks with model selection formulti-task learning,2019, In Proceedings of the IEEE International Conference on Computer Vision
 Routing networks with co-training for continual learning,2020, arXiv preprint arXiv:2009
 Learning factored representations in a deepmixture of experts,2013, arXiv preprint arXiv:1312
 Pathnet: Evolution channels gradient descent in superneural networks,2017, arXiv preprint arXiv:1701
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In International Conference on Machine Learning
 Adaptive mixtures oflocal experts,1991, Neural computation
 Adam: A method for stochastic optimization,2018, In InternationalConference on Learning Representations
 Gumbel-matrix routing for flexible multi-task learning,2019, arXiv preprint arXiv:1910
 Flexible multi-task networks by learning parameter allocation,2020, 2020
 Cross-stitch networks formulti-task learning,2016, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Efficient neural architecture searchvia parameters sharing,2018, In International Conference on Machine Learning
 Diversity and depth in per-example routing models,2018, InInternational Conference on Learning Representations
 An overview of multi-task learning in deep neural networks,2017, arXiv preprintarXiv:1706
 Latent multi-task ar-chitecture learning,2019, In Proceedings of the AAAI Conference on Artificial Intelligence
 Learning to share visual appearancefor multiclass object detection,2011, In CVPR 2011
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, InInternational Conference on Learning Representations
 Adashare: Learning what to share for efficientdeep multi-task learning,2019, arXiv preprint arXiv:1911
 Residual networks behave like ensembles ofrelatively shallow networks,2016, In Advances in neural information processing systems
 Understanding and improving information trans-fer in multi-task learning,2020, arXiv preprint arXiv:2005
 Fashion-mnist: a novel image dataset for benchmark-ing machine learning algorithms,2017, arXiv preprint arXiv:1708
 Learning what toshare: Leaky multi-task network for text classification,2018, In Proceedings of the 27th InternationalConference on Computational Linguistics
 Deep multi-task representation learning: A tensor factori-sation approach,2017, In International Conference on Learning Representations
