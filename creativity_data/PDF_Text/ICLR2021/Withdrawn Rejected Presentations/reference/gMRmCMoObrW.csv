title,year,conference
 Deep variational informationbottleneck,2017, International Conference on Learning Representations
 Representation learning: A review and newperspectives,2013, IEEE Transactions on Pattern Analysis and Machine Intelligence
 Understanding disentangling in β-vae,2018, arXiv: Machine Learning
 A simple frameworkfor contrastive learning of visual representations,2020, arXiv: 2002
 Emnist: an extension ofmnist to handwritten letters,2017, arXiv:1702
 Momentum contrast forunsupervised visual representation learning,2019, arXiv: 1911
 β-vae: Learning basic visual concepts with a con-strained variational framework,2017, International Conference on Learning Representations
 Unsupervised feature extraction by time-contrastive learningand nonlinear ica,2016, Advances in Neural Information Processing Systems
 Nonlinear independent component analysis: existence anduniqueness results,1999, Neural Networks
 Nonlinear ica using auxiliary variables andgeneralized contrastive learning,2019, International Conference on Artificial Intelligence and Statistics
 Variational autoencoders and nonlin-ear ica: A unifying framework,2020, International Conference on Artificial Intelligence and Statistics
 Disentangling by factorising,2018, International Conference on MachineLearning
 Adam: A method for stochastic optimization,2015, InternationalConference on Learning Representations
 Auto-encoding variational bayes,2014, International Conferenceon Learning Representations
 Buildingmachines that learn and think like people,2017, Behavioral and Brain Sciences
 Nice: Non-linear independent componentsestimation,2015, arXiv: 1410
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Challengingcommon assumptions in the unsupervised learning of disentangled representations,2019, InternationalConference on Machine Learning
 Learning factorial codes by predictability minimization,1992, Neural Computation
 Recent advances in autoencoder-basedrepresentation learning,2018, arXiv preprint arXiv:1812
 Towards better understandingof disentangled representations via mutual information,2020, arXiv: 1911
