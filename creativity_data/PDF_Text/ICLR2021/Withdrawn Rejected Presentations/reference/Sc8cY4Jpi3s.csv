title,year,conference
 Tensorflow: A system for large-scalemachine learning,2016, In 12th USENIX Symposium on Operating Systems Design and Implementation(OSD116)
 Disentangling adaptivegradient methods from learning rates,2020, arXiv preprint arXiv:2002
 Geometric means,2004, Linear algebra and itsapplications
 Distributed second-order optimization using kronecker-factored approximations,2017, In International conference on machine learning
 Aprogressive batching l-bfgs method for machine learning,2018, In International Conference on MachineLearning
 Trust region methods,2000, SIAM
 Large scaledistributed deep networks,2012, Advances in Neural Information Processing Systems 25
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Fastapproximate natural gradient descent in a Kronecker factored eigenbasis,2018, In Advances in NeuralInformation Processing Systems
 Faster sgd using sketched conditioning,2015, arXiv preprintarXiv:1506
 Deep learning withlimited numerical precision,2015, In International Conference on Machine Learning
 Shampoo: Preconditioned stochastic tensoroptimization,2018, In Proceedings of the 35th International Conference on Machine Learning
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 On “natural” learning and pruning in multilayered perceptrons,2000, Neural Computation
 In-datacenter performance analysisof a tensor processing unit,2017, In Computer Architecture (ISCA)
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Learning multiple layers of features from tiny images,2009, 2009
 Limitations of the empirical fisher approximationfor natural gradient descent,2019, In Advances in Neural Information Processing Systems
 Optimizing neural networks with Kronecker-factored approximatecurvature,2015, In International conference on machine learning
 Mlperf training benchmark,2019, arXivpreprint arXiv:1910
 Adaptive bound optimization for online convexoptimization,2010, COLT 2010
 Deeplearning recommendation model for personalization and recommendation systems,2019, arXiv preprintarXiv:1906
 Updating quasi-newton matrices with limited storage,1980, Mathematics of computation
 Numerical computing with IEEE floating point arithmetic,2001, SIAM
 Distributed equivalent substitution training for large-scalerecommender systems,2020, In Proceedings of the 43rd International ACM SIGIR Conference onResearch and Development in Information Retrieval
 Online learning and online convex optimization,2012, Foundations and Trends inMachine Learning
 Mesh-tensorflow: Deeplearning for supercomputers,2018, In Advances in Neural Information Processing Systems
 Attention is all you need,2017, In Advances in Neural InformationProcessing Systems
 Developing a recommendation benchmark for mlperf training and inference,2020, arXiv preprintarXiv:2003
 Sub-sampled newton methods with non-uniform sampling,2016, In Advances in Neural Information ProcessingSystems
 Large batch optimization for deep learning:Training bert in 76 minutes,2019, arXiv preprint arXiv:1904
