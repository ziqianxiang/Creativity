title,year,conference
  Extragradient approach to the solution of two person non-zero sum games,2003,  InOptimization and Optimal Control
 Open-ended learning in symmetric zero-sum games,2019, arXiv preprintarXiv:1901
 Dota 2 with large scaledeep reinforcement learning,2019, arXiv preprint arXiv:1912
 Multiagent learning using a variable learning rate,2002, ArtificialIntelligence
 Names for games: Locating 2× 2 games,2015, Games
  An overview of recent progress in thestudy of distributed multi-agent coordination,2012, IEEE Transactions on Industrial informatics
 On nash equilibria in stochasticgames,2004, In International Workshop on Computer Science Logic
   Computing nash equilibria:  Approximation andsmoothed complexity,2006, In 2006 47th Annual IEEE Symposium on Foundations of Computer Science(FOCS’06)
 Learning tocommunicate with deep multi-agent reinforcement learning,2016, In Advances in Neural InformationProcessing Systems
 Learning with opponent-learning awareness,2018, In Proceedings of the 17th InternationalConference on Autonomous Agents and MultiAgent Systems
 A survey of learn-ing in multiagent environments: Dealing with non-stationarity,2017, arXiv preprint arXiv:1707
 Ganstrained by a two time-scale update rule converge to a local nash equilibrium,2017, In Advances in neuralinformation processing systems
 A unified game-theoretic approach to multiagent reinforcementlearning,2017, In Advances in Neural Information Processing Systems
 Convergent multiple-timescales reinforcement learning algorithmsin normal form games,2003, The Annals of Applied Probability
 On the impossibility of global convergence in multi-loss optimization,2020, arXiv preprintarXiv:2005
 Stableopponent shaping in differentiable games,2018, arXiv preprint arXiv:1811
  Continuous control with deep reinforcement learning,2015,  arXivpreprint arXiv:1509
 Finite-time last-iterateconvergence for multi-agent learning in games,2020, arXiv preprint arXiv:2002
  Playing large games using simplestrategies,2003, In Proceedings of the 4th ACM conference on Electronic commerce
   Markov games as a framework for multi-agent reinforcement learning,1994,   InMachine learning proceedings 1994
 Computing approximate equilibria in sequential adversarial games byexploitability descent,2019, In IJCAI 2019
 Multi-agentactor-critic for mixed cooperative-competitive environments,2017, In Advances in neural informationprocessing systems
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 A generalized training approach formultiagent learning,2019, arXiv preprint arXiv:1909
 Equilibrium points in n-person games,1950, Proceedings of the national academy ofsciences
   QMIX: monotonic value function factorisation for deep multi-agentreinforcement  learning,2018,   CoRR
 Trust regionpolicy optimization,2015,  CoRR
 Proximal policyoptimization algorithms,2017,   CoRR
   Stochastic games,1953,   Proceedings of the national academy of sciences
  Nash convergence of gradient dynamicsin general-sum games,2000,  In Proceedings of the Sixteenth conference on Uncertainty in artificialintelligence
 Qtran: Learningto factorize with transformation for cooperative multi-agent reinforcement learning,2019, arXiv preprintarXiv:1905
 Multi-agent reinforcement learning: Independent vs,1993, cooperative agents
 Equilibrium finding via asymmetric self-play reinforce-ment learning,2018, Deep Reinforcement Learning Workshop NeurIPS 2018
 Multiplayer support for the arcade learning environment,2020, arXivpreprint arXiv:2009
 A generalised methodfor empirical game theoretic analysis,2018,  In Proceedings of the 17th International Conference onAutonomous Agents and MultiAgent Systems
 Grandmaster level instarcraft ii using multi-agent reinforcement learning,2019, Nature
 Methods for empirical game-theoretic analysis,2006, In AAAI
 Mean field multi-agentreinforcement learning,2018, arXiv preprint arXiv:1802
 α α-rank: Practicallyscaling α-rank through stochastic optimisation,2019, arXiv preprint arXiv:1909
 Multi-agent learning with policy prediction,2010, In AAAI
  Nash equilibria noncooperative games,2013,
002        THE  LEARNING  RATE  FOR  BEST  RESPONSE  STEPBEST  RESPONSE  INTERACTIONS                                      5            NUMBER  OF  GRADIENT  STEPS  FOR  BEST  RESPONSE  STEPKL COEFFICIENT                                                                  0,2013,001        THE  KL DIVERGENCE  COEFFICIENT  IN  CALCULATING  LOSSENTROPY  COEFFICIENT                                                      0
