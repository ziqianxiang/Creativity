title,year,conference
 Birdsnap: Large-scale fine-grained visual categorization of birds,2014, In IEEE Conferenceon Computer Vision and Pattern Recognition (CVPR)
 Training stochastic model recognition algorithms as networks can lead to maximummutual information estimation of parameters,1990, In Advances in neural information processingsystems
 Angular visual hardness,2019, arXiv preprint arXiv:1912
 On empirical comparisons of optimizers for deep learning,2019, arXiv preprint arXiv:1910
 Separability and geometry ofobject manifolds in deep neural networks,2020, Nature communications
 Autoaugment:Learning augmentation strategies from data,2019, In Proceedings of the IEEE conference on computervision and pattern recognition
 An exploration of softmax alternatives belonging to thespherical loss family,2015, arXiv preprint arXiv:1511
 Arcface: Additive angular marginloss for deep face recognition,2019, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Robust loss functions under label noise for deepneural networks,2017, arXiv preprint arXiv:1712
 Estimating information flow in deep neural networks,2018, arXiv preprintarXiv:1810
 On calibration of modern neuralnetworks,2017, In International Conference on Machine Learning
 DeeP residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Benchmarking neural network robustness to commoncorruPtions and Perturbations,2019, ICLR
 Natural adversarialexamPles,2019, arXiv preprint arXiv:1907
 The many faces of robustness: A criticalanalysis of out-of-distribution generalization,2020, arXiv preprint arXiv:2006
 Evaluation of neural architectures trained with square loss vs cross-entroPy in classification tasks,2020, arXiv preprint arXiv:2006
 Learning deeP networks from noisy labels withdroPout regularization,2016, In 2016 IEEE 16th International Conference on Data Mining (ICDM)
 SuPervised contrastive learning,2020, arXiv preprintarXiv:2004
 Similarity of neuralnetwork rePresentations revisited,2019, arXiv preprint arXiv:1905
 On controllable sParse alternatives to softmax,2018, In Advancesin Neural Information Processing Systems
 Large-margin softmax loss for convolu-tional neural networks,2016, In ICML
 SPhereface: DeePhyPersPhere embedding for face recognition,2017, In Proceedings of the IEEE conference on computervision and pattern recognition
 A metric learning reality check,2020, arXiv preprintarXiv:2003
 Cats and dogs,2012, In IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition
 L2-constrained softmax loss for discrimina-tive face verification,2017, arXiv preprint arXiv:1703
 Neural network classifiers estimate bayesian a posterioriprobabilities,1991, Neural computation
 Prototypical networks for few-shot learning,2017, InAdvances in neural information processing systems
 Striving forsimplicity: The all convolutional net,2014, arXiv preprint arXiv:1412
 Rethinkingthe inception architecture for computer vision,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Dropout training as adaptive regularization,2013, InAdvances in neural information processing systems
 Cosface: Large margin cosine loss for deep face recognition,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Regularization matters: Generalization andoptimization of neural nets vs their induced kernel,2019, In Advances in Neural Information ProcessingSystems
 On overfitting and the effective number of hidden units,1993, In Proceedings of the1993 connectionist models summer school
 Deep cosine metric learning for person re-identification,2018, In 2018IEEE winter conference on applications of computer vision (WACV)
 Sun database:Large-scale scene recognition from abbey to zoo,2010, In IEEE Conference on Computer Vision andPattern Recognition (CVPR)
 Wide residual networks,2016, In Edwin R
 mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
0 Â± 0,2021,06	93
