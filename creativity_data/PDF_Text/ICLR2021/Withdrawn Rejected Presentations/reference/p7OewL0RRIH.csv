title,year,conference
 How tobackdoor federated learning,2018, arXiv preprint arXiv:1807
 Machine learning with adversaries: Byzantinetolerant gradient descent,2017, In Advances in Neural Information Processing Systems
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, arXiv preprint arXiv:1712
 Distributed statistical machine learning in adversarial settings:Byzantine gradient descent,2017, Proceedings of the ACM on Measurement and Analysis of ComputingSystems
 Badnets: Identifying vulnerabilities in themachine learning model supply chain,2017, arXiv preprint arXiv:1708
 Federated learning: Strategies for improving communication efficiency,2016, arXivpreprint arXiv:1610
 Learning multiple layers of features from tiny images,2009, 2009
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 On the convergence offedavg on non-iid data,2019, arXiv preprint arXiv:1907
 Asynchronous federated learning withdifferential privacy for edge intelligence,2019, arXiv preprint arXiv:1912
 Trojaning attack on neural networks,2017, 2017
 Safa: a semi-asynchronous protocol forfast federated learning with low overhead,2019, arXiv preprint arXiv:1910
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, arXiv preprint arXiv:1708
 Generalized byzantine-tolerant sgd,2018, InternationalConference on Machine Learning
 Asynchronous federated optimization,2019, arXiv preprintarXiv:1903
 Zeno++: Robust fully asynchronous sgd,2019, arXivpreprint arXiv:1903
 Byzantine-robust distributedlearning: Towards optimal statistical rates,2018, arXiv preprint arXiv:1803
 Defending against saddle pointattack in byzantine-robust distributed learning,2018, arXiv preprint arXiv:1806
 Federatedlearning with non-iid data,2018, arXiv preprint arXiv:1806
