title,year,conference
 Scalable methods for 8-bit training ofneural networks,2018, In Advances in Neural Information Processing Systems
 Shifted and squeezed 8-bit floating point format for low-precision training of deep neuralnetworks,2020, In International Conference on Learning Representations
 Mixed precision training of convolutional neuralnetworks using integer operations,2018, In International Conference on Learning Representations
 Imagenet: A large-scalehierarchical image database,2009, In Conference on Computer Vision and Pattern Recognition
 Deep residual learning for image recog-nition,2018, In Conference on Computer Vision and Pattern Recognition
 Densely connectedconvolutional networks,2017, In Conference on Computer Vision and Pattern Recognition
 Bfloat16 - hardware numerics definition white paper,2018, 2018
 Flexpoint: An adaptive numerical formatfor efficient training of deep neural networks,2017, In Advances in neural information processingsystems
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in neural information processing systems
 Mixed precision training,2018, In International Conference on LearningRepresentations
 Very deep convolutional networks for large-scale imagerecognition,2015, In International Conference on Learning Representations
 Going deeper with convolutions,2015, InComputer Vision and Pattern Recognition
 Dorefa-net: Training low bitwidthconvolutional neural networks with low bitwidth gradients,2016, In CoRR
