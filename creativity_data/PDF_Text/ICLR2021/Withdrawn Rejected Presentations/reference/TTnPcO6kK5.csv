title,year,conference
 Speech recognition with deep re-current neural networks,2013, In Acoustics
 Deep residual learning for image recog-nition,2016, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Improving generalization performance by switching fromAdam to SGD,2017, In CoRR
 Adam: A method for stochastic optimization,2015, In Proceedingsof the 3rd International Conference on Learning Representations (ICLR)
 Learning multiple layers of features from tiny images,2009, InTechnical report
 Gradient-based learning applied todocument recognition,1998, In Proceedings of the IEEE
 Adaptive gradient methods with dynamicbound of learning rate,2019, In Proceedings of International Conference on Learning Representations(ICLR)
 On the convergence of Adam and beyond,2018, InProceedings of International Conference on Learning Representations (ICLR)
 On the importance of initial-ization and momentum in deep learning,2013, In Proceedings of the 30th International Conference onMachine Learning(ICML)
 AEGD: adaptive gradient decent with energy,2020, 2020
 RMSprop: Divide the gradient by a running average of itsrecent magnitude,2012, In COURSERA: Neural networks for machine learning
 ADADELTA: An adaptive learning rate method,2012, In CoRR
