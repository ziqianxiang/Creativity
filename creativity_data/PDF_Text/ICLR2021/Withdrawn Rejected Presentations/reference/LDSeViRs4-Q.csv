title,year,conference
 Threat of adversarial attacks on deep learning in computer vision:A survey,2018, IEEEAccess
 Mma training: Directinput space margin maximization through adversarial training,2019, In International Conference onLearning Representations
 AdverTorch v0,2019,1: An adversarial robustnesstoolbox based on pytorch
 Robust physical-world attacks on deep learningvisual classification,2018, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Assessing threat of adversarial examples ondeep neural networks,2016, In 2016 15th IEEE International Conference on Machine Learning andApplications (ICMLA)
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Soft biometric privacy: Retaining biometric utility of face imageswhile perturbing gender,2017, In 2017 IEEE International joint conference on biometrics (IJCB)
 Virtual adversarial training: aregularization method for supervised and semi-supervised learning,2018, IEEE transactions on patternanalysis and machine intelligence
 Automatic differentiation inpytorch,2017, 2017
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 On adaptive attacks toadversarial example defenses,2020, arXiv preprint arXiv:2002
 A direct approach to robust deep learning using adversarial net-works,2019, arXiv preprint arXiv:1905
 Group normalization,2018, In Proceedings of the European conference oncomputer vision (ECCV)
