title,year,conference
 There are many consis-tent explanations of unlabeled data: Why you should average,2018, arXiv preprint arXiv:1806
 Laplacian eigenmaps and spectral techniques for embedding andclustering,2002, In Advances in neural information processing systems
 Mixmatch: A holistic approach to semi-supervised learning,2019, In Advances in NeuralInformation Processing Systems
 Shortest-path kernels on graphs,2005, In Fifth IEEEinternational conference on data mining (ICDMâ€™05)
 Libsvm: A library for support vector machines,2011, ACMtransactions on intelligent systems and technology (TIST)
 Convolutional kernel networks for graph-structureddata,2020, arXiv preprint arXiv:2003
 Bigself-supervised models are strong semi-supervised learners,2020, arXiv preprint arXiv:2006
 Convolutional networks on graphs for learning molecularfingerprints,2015, In Advances in neural information processing systems
 On graph kernels: Hardness results and efficientalternatives,2003, In Learning theory and kernel machines
 Neuralmessage passing for quantum chemistry,2017, arXiv preprint arXiv:1704
 Inductive representation learning on large graphs,2017, InAdvances in neural information processing systems
 Contrastive multi-view representation learning ongraphs,2020, In Proceedings of International Conference on Machine Learning
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Learning deep representations by mutual information estimationand maximization,2018, arXiv preprint arXiv:1808
 The multiscale laplacian graph kernel,2016, In Advances in NeuralInformation Processing Systems
 Pseudo-label: The simple and efficient semi-supervised learning method for deepneural networks,2013, In Workshop on challenges in representation learning
 Virtual adversarial training: Aregularization method for supervised and semi-supervised learning,1939, IEEE Transactions on PatternAnalysis and Machine Intelligence
 Self-distillation amplifies regularizationin hilbert space,2020, arXiv preprint arXiv:2002
 graph2vec: Learning distributed representations of graphs,2017, arXiv preprintarXiv:1707
 Representation learning with contrastive predictivecoding,2018, arXiv preprint arXiv:1807
 Quantumchemistry structures and properties of 134 kilo molecules,2014, Scientific data
 Semi-supervised self-training of objectdetection models,2005, 2005
 Facenet: A unified embedding for facerecognition and clustering,2015, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization,2019, arXiv preprintarXiv:1908
 On mutualinformation maximization for representation learning,2019, arXiv preprint arXiv:1907
 Deep graph infomax,2018, arXiv preprint arXiv:1809
 Manifold mixup: Better representations by interpolating hidden states,2019, InInternational Conference on Machine Learning
 Deep graph kernels,2015, In Proceedings of the 21th ACMSIGKDD International Conference on Knowledge Discovery and Data Mining
 Artificial intelligence incovid-19 drug repurposing,2020, The Lancet Digital Health
