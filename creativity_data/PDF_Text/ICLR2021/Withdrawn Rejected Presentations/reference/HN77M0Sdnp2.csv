title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Continuously differentiable exponential linear units,2017, arXiv preprintarXiv:1704
 Enhancing robustnessof machine learning systems via data transformations,2018, In CISS
 Thermometer encoding: One hotway to resist adversarial examples,2018, In ICLR
 Autoaugment:Learning augmentation Policies from data,2019, In CVPR
 Stochastic activation Pruning for robust adversarial de-fense,2018, In ICLR
 Batchnormalization is a cause of adversarial vulnerability,2019, arXiv preprint arXiv:1905
 Convergenceof adversarial training in overParametrized networks,2019, In NeurIPS
 ExPlaining and harnessing adversarialexamPles,2015, In ICLR
 Countering adversarialimages using inPut transformations,2018, In ICLR
 DeeP residual learning for image recog-nition,2016, In CVPR
 DeeP networks withstochastic dePth,2016, In ECCV
 Adversarial machine learning at scale,2017, In ICLR
 Defense against adversarial attacksusing high-level representation guided denoiser,2018, In CVPR
 Towards robust neural networksvia random self-ensemble,2018, In ECCV
 Generating accurate pseudo-labels in semi-supervised learning and avoiding overconfidentpredictions via hermite polynomial activations,2020, In CVPR
 Magnet: a two-pronged defense against adversarial examples,2017, InCCS
 Mish: A self regularized non-monotonic neural activation function,2019, arXiv preprintarXiv:1908
 Adversarial robustness may be at odds with simplicity,2019, arXiv preprintarXiv:1901
 Improving adversarial robustness viapromoting ensemble diversity,2019, In ICML
 Mixup inference: Better exploiting mixup to defend adversarialattacks,2020, In ICLR
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In SP
 Practical black-box attacks against machine learning,2017, In AsiaCCS
 Deflectingadversarial attacks with pixel deflection,2018, In CVPR
 Adversarial robustness through locallinearization,2019, In NeurIPS
 Searching for activation functions,2017, arXivpreprint arXiv:1710
 Improved adversarial robustness by reducing open space riskvia tent activations,2019, arXiv preprint arXiv:1908
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, In ICLR
 Certifying some distributional robustness withprincipled adversarial training,2018, In ICLR
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2018, In ICLR
 Is robustnessthe cost of accuracy?-a comprehensive study on the robustness of 18 deep image classificationmodels,2018, In ECCV
 Intriguing properties of neural networks,2014, In ICLR
 Efficientnet: Rethinking model scaling for convolutional neural net-works,2019, In ICML
 Defensivedropout for hardening deep neural networks under adversarial attacks,2018, In ICCAD
 On theconvergence and robustness of adversarial training,2019, In ICML
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In ICLR
 One man’s trash is another man’s treasure: Resisting adversarialexamples by adversarial examples,2020, In CVPR
 Intriguing properties of adversarial training at scale,2020, In ICLR
 Mitigating adversarialeffects through randomization,2018, In ICLR
 Feature denoisingfor improving adversarial robustness,2019, In CVPR
 Self-training with noisy student im-proves imagenet classification,2020, In CVPR
 Aggregated residual trans-formations for deep neural networks,2017, In CVPR
 Neural architecture search With reinforcement learning,2016, In ICLR
