title,year,conference
 Linear coupling: An ultimate unification of gradient andmirror descent,2014, arXiv preprint arXiv:1407
 Learning to learn by gradient descent by gradientdescent,2016, In Advances in neural information processing systems
 Mirror descent and nonlinear projected subgradient methods forconvex optimization,2003, Operations Research Letters
 Large-scale machine learning with stochastic gradient descent,2010, In Proceedings ofCOMPSTAT’2010
 A discussion of random methods for seeking maxima,1958, Operations research
 A geometric alternative to nesterov’s acceleratedgradient descent,2015, arXiv preprint arXiv:1506
 Bohb: Robust and efficient hyperparameter optimiza-tion at scale,2018, arXiv preprint arXiv:1807
 A tutorial on bayesian optimization,2018, arXiv preprint arXiv:1807
 Gradientlessdescent: High-dimensional zeroth-order optimization,2019, arXiv preprint arXiv:1911
 Generative adversarial networks,2014, Advances in neuralinformation processing systems
 A stochasticderivative free optimization method with momentum,2019, arXiv preprint arXiv:1905
 Theory of the backpropagation neural network,1992, In Neural networks forperception
 Convnets with smooth adaptiveactivation functions for regression,2017, Proceedings of machine learning research
 Population based trainingof neural networks,2017, arXiv preprint arXiv:1711
 Automatic and simultaneous adjustment of learning rate andmomentum for stochastic gradient descent,2019, arXiv preprint arXiv:1908
 Darts: Differentiable architecture search,2018, arXivpreprint arXiv:1806
 Zeroth-orderstochastic variance reduction for nonconvex optimization,2018, In Advances in Neural InformationProcessing Systems
 Scalable gradient-based tuningof continuous regularization hyperparameters,2016, In International conference on machine learning
 Self-tuningnetworks: Bilevel optimization of hyperparameters using structured best-response functions,2019, arXivpreprint arXiv:1903
 Gradient-based hyperparameter optimizationthrough reversible learning,2015, In International Conference on Machine Learning
 Simple random search provides a competitiveapproach to reinforcement learning,2018, arXiv preprint arXiv:1803
 Stochastic proximal gradient descent with acceleration techniques,2014, In Advances inNeural Information Processing Systems
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACM onAsia conference on computer and communications security
 Practical bayesian optimization of machinelearning algorithms,2012, In Advances in neural information processing systems
 Gaussian process opti-mization in the bandit setting: No regret and experimental design,2009, arXiv preprint arXiv:0912
 A coordinate gradient descent method for nonsmooth separableminimization,2009, Mathematical Programming
