title,year,conference
 Information dropout: Learning optimal representations through noisycomputation,2018, In IEEE Transactions on Pattern Analysis and Machine Intelligence
 Seeing 3D chairs: exemplar part-based2D-3D alignment using a large dataset of CAD models,2014, In CVPR
 Learning representations by maximizing mutualinformation across views,2019, In Advances in Neural Information Processing Systems
 Representation learning: A review and new perspectives,2013, InIEEE Transactions on Pattern Analysis and Machine Intelligence
 Under-standing disentangling in Î²-VAE,2018, arXiv:804
 A framework for the quantitative evaluation of disentangledrepresentations,2018, In International Conference on Learning Representations
 Structured disentangled representations,2018, In AISTATS
 Learning with a Wasserstein loss,2015, InAdvances in Neural Information Processing Systems
 GANs trained by a twotime-scale update rule converge to a local Nash equilibrium,2017, In Advances in Neural InformationProcessing Systems
 beta-VAE: Learning basic visual concepts with a constrained variational framework,2017, InInternational Conference on Learning Representations
 Towards adefinition of disentangled representations,2018, arXiv:1812
 Disentangling by factorising,2018, In International Conference on Machine Learning
 Adam: a method for stochastic optimization,2015, In International Conference onLearning Representations
 Auto-encoding variational Bayes,2014, In International Conference onLearning Representations
 Variational inference of disentangled latent conceptsfrom unlabeled observations,2018, In International Conference on Learning Representations
 Learning methods for generic object recognition with invarianceto pose and lighting,2004, In IEEE Computer Society Conference on Computer Vision and PatternRecognition
 Deep learning face attributes in the wild,2015, In InternationalConference on Computer Vision
 Challengingcommon assumptions in the unsupervised learning of disentangled representations,2019, In InternationalConference on Machine Learning
 Estimating divergence functionals and the likelihoodratio by penalized convex risk minimization,2008, In Advances in Neural Information ProcessingSystems 20
 Sinkhorn autoencoders,2018, arXiv:1810
 Stochastic backpropagation and approximate inferencein deep generative models,2014, In International Conference on Machine Learning
 Practical and consistentestimation of f-divergences,2019, In Advances in Neural Information Processing Systems
 Learning disentangled representations WithWasserstein Auto-Encoders,2018, In ICLR Workshop
 Density ratio matching under the Bregman divergence: Aunified frameWork of density ratio estimation,2011, In Annals of the Institute of Statistical Mathematics
 The information bottleneck method,1999, In Annual AllertonConference on Communication
 Wasserstein Auto-Encoders,2018, In InternationalConference on Learning Representations
 On mutual informationmaximization for representation learning,2020, In International Conference on Learning Representations
 Discovering structure in high-dimensional data through correlationexplanation,2014, In Advances in Neural Information Processing Systems
 Optimal Transport: Old and New,2008, Springer Berlin Heidelberg
 InfoVAE: Balancing learning and inference in variational autoen-coders,2019, In AAAI Conference on Artificial Intelligence
