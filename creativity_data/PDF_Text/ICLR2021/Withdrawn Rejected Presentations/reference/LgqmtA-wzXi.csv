title,year,conference
 Online bandit learning against an adaptive adversary:from regret to policy regret,2012, arXiv preprint arXiv:1206
 Stochastic multi-armed-bandit problem with non-stationary rewards,2014, In Advances in neural information processing systems
 An empirical evaluation of thompson sampling,2011, In Advances inneural information processing systems
 Learning phrase representations using rnn encoder-decoderfor statistical machine translation,2014, In EMNLP
 Adapting multi-armed bandits policies to contextual bandits scenarios,2018, arXiv preprintarXiv:1811
 A dynamic allocation index for the sequential design of experiments,1974, Progress instatistics
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Long short-term memory,0899, Neural Comput
 ContextUal semibandits via sUpervisedlearning oracles,2016, In Advances In Neural Information Processing Systems
 Rotting bandits,2017, In Advances in neural informationprocessing systems
 Combinatorial sleeping bandits with fairness constraints,2019, IEEETransactions on Network Science and Engineering
 MUlti-armed bandit strategies for non-stationaryreward distribUtions and delayed feedback processes,2019, arXiv preprint arXiv:1902
 Deep bayesian bandits showdown: Anempirical comparison of bayesian deep networks for thompson sampling,2018, arXiv preprintarXiv:1802
 Rot-ting bandits are no harder than stochastic ones,2019, In The 22nd International Conference on ArtificialIntelligence and Statistics
 On the likelihood that one unknown probability exceeds another in view ofthe evidence of two samples,1933, Biometrika
 Comparing exploration strategiesfor q-learning in random stochastic mazes,2016, In 2016 IEEE Symposium Series on ComputationalIntelligence (SSCI)
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
