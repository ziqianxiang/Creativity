title,year,conference
 A theory of learning from different domains,2010, Machine learning
 Introduction to statistical learning the-ory,2003, In Summer School on Machine Learning
 Autoaugment:Learning augmentation strategies from data,2019, In Proceedings of the IEEE conference on computervision and pattern recognition
 Fast comPutation of wasserstein barycenters,2014, 2014
 A kerneltheory of modern data augmentation,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Adaptive data aug-mentation for image classification,2016, In 2016 IEEE International Conference on Image Processing
 Visual attention consistencyunder image transforms for multi-label image classification,2019, In IEEE Conference on ComputerVision and Pattern Recognition
 Augmix: A simple data processing method to improve robustness and uncertainty,2020, In8th International Conference on Learning Representations
 Consistency-based semi-supervisedlearning for object detection,2019, In Advances in Neural Information Processing Systems
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Learning noise-invariant representations forrobust speech recognition,2018, In 2018 IEEE Spoken Language Technology Workshop (SLT)
 Improv-ing robustness without sacrificing accuracy with patch gaussian augmentation,2019, arXiv preprintarXiv:1906
 To-wards deep learning models resistant to adversarial attacks,2018, In 6th International Conference onLearning Representations
 Regularization with stochastic transfor-mations and perturbations for deep semi-supervised learning,2016, In Advances in neural informationprocessing systems
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Equivariant transformer networks,2019, arXiv preprintarXiv:1901
 Theoretical analysis of adversarial learning: Aminimax approach,2019, In Advances in Neural Information Processing Systems
 Topics in optimal transportation,2003, Number 58
 Learning robust representations byprojecting superficial statistics out,2019, In 7th International Conference on Learning Representations
 High frequency component helps explainthe generalization of convolutional neural networks,2020, In Computer Vision and Pattern Recognition(CVPR)
 Implicit semanticdata augmentation for deep networks,2019, In Advances in Neural Information Processing Systems
 Unsupervised dataaugmentation,2019, arXiv preprint arXiv:1904
 Hyper-class augmented and regular-ized deep learning for fine-grained image classification,2015, In Proceedings of the IEEE conferenceon computer vision and pattern recognition
 Invariance-inducing regularization usingworst-case transformations suffices to boost accuracy and spatial robustness,2019, In Advances inNeural Information Processing Systems
 Making convolutional networks shift-invariant again,2019, arXiv preprintarXiv:1904
 Adversarial autoaugment,2020, In InternationalConference on Learning Representations
 Regularizing neuralmachine translation by target-bidirectional agreement,2019, In Proceedings of the AAAI Conference onArtificial Intelligence
 Improving the robustness of deepneural networks via stability training,2016, In Proceedings of the ieee conference on computer visionand pattern recognition
