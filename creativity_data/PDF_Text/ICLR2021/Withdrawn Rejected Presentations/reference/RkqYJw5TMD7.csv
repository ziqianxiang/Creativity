title,year,conference
 Obfuscated gradients give a false senseof security: Circumventing defenses to adversarial examples,2018, In Jennifer G
 A theory of learning from different domains,2010, Machine learning
 Learningbounds for domain adaptation,2008, In Advances in neural information processing systems
 Unlabeled dataimproves adversarial robustness,2019, In Hanna M
 Joint distributionoptimal transportation for domain adaptation,2017, In Advances in Neural Information ProcessingSystems
 Domain-adversarial training of neuralnetworks,2017, In Gabriela Csurka (ed
 Beyond pertur-bations: Learning guarantees with arbitrary adversarial test examples,2020, CoRR
 Defense against the dark arts: An overview of adversarial example securityresearch and future research directions,2018, CoRR
 A research agenda: Dynamic models to defend against correlated attacks,2019, CoRR
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Detecting change in data streams,2004, In VLDB
 Learning transferable featureswith deep adaptation networks,2015, arXiv preprint arXiv:1502
 Stochastic hyperparameter optimization through hypernet-works,2018, CoRR
 To-wards deep learning models resistant to adversarial attacks,2018, In 6th International Conference onLearning Representations
 Evaluating prediction-time batch normalization for robustness under covariateshift,2020, arXiv preprint arXiv:2006
 Adver-sarially robust generalization requires more data,2018, In Advances in Neural Information ProcessingSystems
 A DIRT-T approach to unsuperviseddomain adaptation,2018, In 6th International Conference on Learning Representations
 Test-timetraining with self-supervision for generalization under distribution shifts,2020, In ICML
 Statistical learning theory,1998, Wiley
 Fullytest-time adaptation by entropy minimization,2020, CoRR
