title,year,conference
 Efficient explorationthrough bayesian deep q-networks,2018, In 2018 Information Theory and Applications Workshop (ITA)
 OpenAI Gym,2016, arXiv preprint arXiv:1606
 Learning from conditional distributionsvia dual embeddings,2017, In Artificial Intelligence and Statistics
 Coindice:Off-policy confidence interval estimation,2020, In Advances in Neural Information Processing Systems
 The linear programming approach to approximatedynamic programming,2003, Operations research
 Model-based bayesian exploration,2013, arXivpreprint arXiv:1301
 The maxq method for hierarchical reinforcement learning,1998, In ICML
 Importance sampling for fair policy selec-tion,2017, Grantee Submission
 Doubly robust policy evaluation and learning,2011, arXivpreprint arXiv:1103
 Pac-bayesian model selection for reinforcement learning,2010, InAdvances in Neural Information Processing Systems
 Accountable off-policy evaluation withkernel bellman statistics,2020, arXiv preprint arXiv:2008
 Bayesian reinforcementlearning: A survey,2016, arXiv preprint arXiv:1609
 Bootstrapping with models: Confidence intervalsfor off-policy evaluation,2016, arXiv preprint arXiv:1606
 Vime:Variational information maximizing exploration,2016, In Advances in Neural Information ProcessingSystems
 Off-policy evaluation via off-policy classification,2019, In Advances in Neural InformationProcessing Systems
 A Theory of Model Selection in Reinforcement Learning,2017, PhD thesis
 Abstraction selection in model-based reinforcementlearning,2015, In International Conference on Machine Learning
 Near-bayesian exploration in polynomial time,2009, In Proceedings ofthe 26th annual international conference on machine learning
 A linearly relaxedapproximate linear program for markov decision processes,2017, CoRR
 Breaking the curse of horizon: Infinite-horizon off-policy estimation,2018, In Advances in Neural Information Processing Systems
 Reinforcement learning via fenchel-rockafellar duality,2020, arXiv preprintarXiv:2001
 DualDICE: Behavior-agnostic estimationof discounted stationary distribution corrections,2019, In Advances in Neural Information ProcessingSystems
 The uncertainty bellmanequation and exploration,2018, In International Conference on Machine Learning
 Model selection in contextual stochastic bandit problems,2020, arXiv preprintarXiv:2003
 Hyperparameter selection for offline reinforcementlearning,2020, arXiv preprint arXiv:2007
 Eligibility traces for off-policy policyevaluation,2000, In Proceedings of the 17th International Conference on Machine Learning
 Lectures on stochastic Program-ming: modeling and theory,2014, SIAM
 A hilbert space embedding fordistributions,2007, In International Conference on Algorithmic Learning Theory
 Data-efficient off-policy policy evaluation for reinforcementlearning,2016, In International Conference on Machine Learning
 High confidence policyimprovement,2015, In International Conference on Machine Learning
 Off-policy evaluation viathe regularized lagrangian,2020, In Advances in Neural Information Processing Systems
 Optimal Information Processing and Bayesâ€™s Theorem,1988, The American Statistician
 GenDICE: Generalized offline estimationof stationary values,2020, In International Conference on Learning RePresentations
 Bayesian inference with posterior regularization and ap-plications to infinite latent svms,2014, J
