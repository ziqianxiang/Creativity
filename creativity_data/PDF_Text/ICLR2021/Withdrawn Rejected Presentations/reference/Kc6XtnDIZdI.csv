title,year,conference
 Remixmatch: Semi-supervised learning with distribution alignment and augmenta-tion anchoring,2019, arXiv
 Mixmatch: A holistic approach to semi-supervised learning,2019, In NeurIPS
 Randaugment: Practical automateddata augmentation with a reduced search space,2019, arXiv
 Model-agnostic meta-learning for fast adaptationof deep networks,2017, In ICML
 Dynamic few-shot visual learning without forgetting,2018, InCVPR
 Boostingfew-shot visual learning with self-supervision,2019, arXiv
 Label propagation for deep semi-supervised learning,2019, In CVPR
 Temporal ensembling for semi-supervised learning,2016, arXiv
 Pseudo-label: The simple and efficient semi-supervised learning method for deepneural networks,2013, In ICMLW
 Finding task-relevant features for few-shot learning by category traversal,2019, In CVPR
 Automatic differentiation inpytorch,2017, 2017
 Few-shot image recognition by predictingparameters from activations,2018, In CVPR
 Meta-learning with implicitgradients,2019, arXiv
 Meta-learning for semi-supervised few-shot classifica-tion,2018, arXiv
 Imagenet large scale visualrecognition challenge,2015, IJCV
 Meta-learning with latent embedding optimization,2018, arXiv
 Regularization with stochastic transforma-tions and perturbations for deep semi-supervised learning,2016, In Neurips
 Prototypical networks for few-shot learning,2017, InNeurIPS
 Meta-transfer learning for few-shotlearning,2019, In CVPR
 Mean teachers are better role models: Weight-averaged consis-tency targets improve semi-supervised deep learning results,2017, In NeurIPS
 Interpolation con-sistency training for semi-supervised learning,2019, arXiv
 Matching networks for oneshot learning,2016, In NeurIPS
 Self-training with noisy studentimproves imagenet classification,2019, arXiv
 mixup: Beyond empiricalrisk minimization,2017, arXiv
