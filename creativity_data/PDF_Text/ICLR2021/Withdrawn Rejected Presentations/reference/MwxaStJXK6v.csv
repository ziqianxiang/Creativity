title,year,conference
 Model-based reinforcement learning with a gener-ative model is minimax optimal,2020, In Conference on Learning Theory(COLT)
 Minimax pac bounds on thesample complexity of reinforcement learning with a generative model,2013, Machine learning
 Residual algorithms: Reinforcement learning with function approximation,1995, InMachine Learning Proceedings 1995
 A finite time analysis of temporal differencelearning with linear function approximation,2018, In Conference on Learning Theory (COLT)
 Finite-time analysis of Q-learning with linear function approximation,2019, arXiv preprint arXiv:1905
 Finite-sample analysis of stochastic approximation using smooth convex envelopes,2020, arXiv preprintarXiv:2002
 A tale of two-timescale reinforcement learning withthe tightest finite-time bound,2020, In Proceedings of the AAAI Conference on Artificial Intelligence
 Finite-time analysis and restarting scheme for linear two-time-scale stochastic ap-proximation,2019, arXiv preprint arXiv:1912
 Q-learning with UCB exploration issample efficient for infinite-horizon MDP,2019, arXiv preprint arXiv:1901
 A theoretical analysis of deep Q-learning,2019, arXiv preprint arXiv:1901
 Double Q-learning,2010, In Advances in Neural Information Processing Systems(NeurIPS)
 Deep reinforcement learning with double q-learning,2016, In Proc
 Minimax optimal reinforcement learning for dis-counted MDPs,2020, arXiv preprint arXiv:2010
 Rainbow: Combining improvements indeep reinforcement learning,2018, In Proc
 Convergence of stochastic iterativedynamic programming algorithms,1994, In Advances in Neural Information Processing Systems(NeurIPS)
 Efficiently solving MDPs with stochastic mirror descent,2020, arXiv preprintarXiv:2008
 Finite timeanalysis of linear two-timescale stochastic approximation with markovian noise,2020, arXiv preprintarXiv:2002
 A unified switching system perspective and ODE analysis of Q-learning algorithms,2019, arXiv preprint arXiv:1912
 Periodic Q-learning,2020, arXiv preprint arXiv:2002
 Sample complexity of asynchronousQ-learning: Sharper analysis and variance reduction,2020, arXiv preprint arXiv:2006
 Convergence of Q-learning: A simple proof,2001, Institute of Systems and Robotics
 An analysis of reinforcement learningwith function approximation,2008, In Proceedings of the 25th international conference on Machinelearning
 Finite-time analysis of asynchronous stochastic approximationand Q-learning,2020, arXiv preprint arXiv:2002
 Near-optimal time and samplecomplexities for solving discounted markov decision process with a generative model,2018, arXivpreprint arXiv:1806
 Adaptive discretization for episodicreinforcement learning in metric spaces,2019, Proceedings of the ACM on Measurement and Analysisof Computing Systems
 High-Dimensional Statistics: A Non-Asymptotic Viewpoint,2019, Cambridge Seriesin Statistical and Probabilistic Mathematics
 Stochastic approximation with cone-contractive operators: Sharp '∞-boundsfor Q-learning,2019, arXiv preprint arXiv:1905
 Primal-dual π learning: Sample complexity and sublinear run time for ergodicmarkov decision problems,2017, arXiv preprint arXiv:1710
 Momentum Q-learningwith finite-sample convergence guarantee,2020, arXiv preprint arXiv:2007
 Finite-time analysis for double Q-learning,2020, arXiv preprint arXiv:2009
 A finite-time analysis of Q-learning with neural network function ap-proximation,2019, arXiv preprint arXiv:1912
 Two time-scale off-policy td learning: Non-asymptotic analysis over markovian samples,2019, arXiv preprint arXiv:1909
 Q-learning with logarithmic regret,2020, arXiv preprintarXiv:arXiv:2006
 A dou-ble deep Q-learning model for energy-efficient edge scheduling,2018, IEEE Transactions on ServicesComputing
 Human-like autonomous vehiclespeed control by deep reinforcement learning with double Q-learning,2018, In Proc
