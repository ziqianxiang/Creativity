title,year,conference
 Learning to learn via self-critique,2019, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Robust solutions ofoptimization problems affected by uncertain probabilities,2013, Management Science
 On the optimization of a synaptic learning rule,1992, InOptimality in Artificial and Biological Neural Networks
 Generalizing from several related classification tasks to a newunlabeled sample,2011, In Advances in Neural Information Processing Systems (NIPS)
 Robust Wasserstein profile inference and applications tomachine learning,2016, arXiv preprint arXiv:1610
 A systematic study of the class imbalance problem inconvolutional neural networks,2018, Neural Networks
 LEAF:A benchmark for federated settings,2019, In Workshop on Federated Learning for Data Privacy andConfidentiality
 Federated meta-learning with fast convergence andefficient communication,2018, arXiv preprint arXiv:1802
 EMNIST: An extension of MNIST to handwrittenletters,2017, arXiv preprint arXiv:1702
 Domain adaptation for visual applications: A comprehensive survey,2017, arXiv preprintarXiv:1702
 Statistics of robust optimization: A generalized empiricallikelihood approach,2016, arXiv preprint arXiv:1610
 Data-driven distributionally robust optimization using the Wassersteinmetric: Performance guarantees and tractable reformulations,2015, arXiv preprint arXiv:1505
 Unsupervised domain adaptation by backpropagation,2015, In InternationalConference on Machine Learning (ICML)
 Conditional neural processes,2018, In International Conference on Machine Learning(ICML)
 Nightmare at test time: Robust learning by feature deletion,2006, InInternational Conference on Machine Learning (ICML)
 In search of lost domain generalization,2020, arXiv preprintarXiv:2007
 Deep residual learning for image recognition,2016, In Conference onComputer Vision and Pattern Recognition (CVPR)
 Benchmarking neural network robustness to common corruptionsand perturbations,2019, In International Conference on Learning Representations (ICLR)
 Learning to learn using gradient descent,2001, In InternationalConference on Artificial Neural Networks (ICANN)
 Unsupervised learning via meta-learning,2019, In International Conferenceon Learning Representations (ICLR)
 Empirical Bayestransductive meta-learning with synthetic gradients,2020, In International Conference on LearningRepresentations (ICLR)
 Batch normalization: Accelerating deep network training by reducinginternal covariate shift,2015, In International Conference on Machine Learning (ICML)
 Categorical reparameterization with Gumbel-softmax,2017, In InternationalConference on Learning Representations (ICLR)
 Improving federated learning personalization viamodel agnostic meta learning,2019, arXiv preprint arXiv:1909
 Be like water: Robustnessto extraneous variables via adaptive feature normalization,2020, arXiv preprint arXiv:2002
 Auto-encoding variational Bayes,2014, In International Conference onLearning Representations (ICLR)
 Learning multiple layers of features from tiny images,2009, Technical report
 The parable of Google flu: Traps in big dataanalysis,2014, Science
 Domain generalization with adversarial feature learning,2018, InConference on Computer Vision and Pattern Recognition (CVPR)
 Learning to self-train forsemi-supervised few-shot classification,2019, In Advances in Neural Information Processing Systems(NeurIPS)
 Revisiting batch normalization for practical domainadaptation,2017, In International Conference on Learning Representations Workshop (ICLRW)
 Real-time edge intelligence in the making: A collaborative learningframework via federated meta-learning,2020, arXiv preprint arXiv:2001
 Robust classification under sample selection bias,2014, In Advances in NeuralInformation Processing Systems (NIPS)
 Learning to propagate labels:Transductive propagation network for few-shot learning,2019, In International Conference on LearningRepresentations (ICLR)
 Challengingcommon assumptions in the unsupervised learning of disentangled representations,2019, In InternationalConference on Machine Learning (ICML)
 The Concrete distribution: A continuous relaxation of discreterandom variables,2017, In International Conference on Learning Representations (ICLR)
 Communication-efficient learningof deep networks from decentralized data,2017, In International Conference on Artificial Intelligenceand Statistics (AISTATS)
 Meta-learning update rules forunsupervised representation learning,2019, In International Conference on Learning Representations(ICLR)
 Distributional smoothing with virtualadversarial training,2015, arXiv preprint arXiv:1507
 Agnostic federated learning,2019, In International Conference onMachine Learning (ICML)
 Evaluat-ing prediction-time batch normalization for robustness under covariate shift,2020, arXiv preprintarXiv:2006
 Dataset Shift in MachineLearning,2009, The MIT Press
 Optimization as a model for few-shot learning,2017, In International Conferenceon Learning Representations (ICLR)
 Fast and flexible multi-taskclassification using conditional neural adaptive processes,2019, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Stochastic backpropagation and approximate inferencein deep generative models,2014, In International Conference on Machine Learning (ICML)
 Classifier adaptation at prediction time,2015, In Conference on Computer Visionand Pattern Recognition (CVPR)
 Meta-learning with memory-augmented neural networks,2016, In International Conference on Machine Learning (ICML)
 Improving robustnessagainst common corruptions by covariate shift adaptation,2020, arXiv preprint arXiv:2006
 Relay backpropagation for effective learning of deep convolutionalneural networks,2016, In European Conference on Computer Vision (ECCV)
 Prototypical networks for few-shot learning,2017, In Advances inNeural Information Processing Systems (NIPS)
 Improving CNN classifiers by estimating test-time priors,2019, In IEEE InternationalConference on Computer Vision (ICCV)
 Test-time training with self-supervisionfor generalization under distribution shifts,2020, In International Conference on Machine Learning(ICML)
 Statistical Learning Theory,1998, Wiley New York
 Matching networks for oneshot learning,2016, In Advances in Neural Information Processing Systems (NIPS)
 Fully test-time adaptation by entropyminimization,2020, arXiv preprint arXiv:2006
 A survey of unsupervised deep domain adaptation,2020, ACM Transactions onIntelligent Systems and Technology (TIST)
 One-shot imitation from observinghumans via domain-adaptive meta-learning,2018, In Robotics: Science and Systems (RSS)
 MetaGAN: An adversarial approach tofew-shot learning,2018, In Advances in Neural Information Processing Systems (NeurIPS)
