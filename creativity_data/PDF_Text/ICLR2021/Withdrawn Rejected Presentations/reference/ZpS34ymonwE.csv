title,year,conference
 On Adversarial Patch Attacks Against Semantic Segmentation,2020, In InternationalJoint Conferences on Artificial Intelligence Organization (IJCAI)
 Synthesizing robust adversarialexamples,2018, In International Conference on Machine Learning (ICML)
 APRICOT: A Dataset of PhysicalAdversarial Attacks on Object Detection,2020, In 16th European Conference on Computer Vision(ECCV)
 Adversarial patch,2017, InConference on Neural Information Processing System (NIPS)
 Robust physical adversarialattack on Faster R-CNN object detector,2018, CoRR
 Cer-tified defenses for adversarial patches,2020, In International Conference on Learning Representations
 Robust Physical-World Attacks on Deep LearningVisual Classification,2018, In Computer Vision and Pattern Recognition (CVPR)
 Model-agnostic meta-learning for fast adaptationof deep networks,2017, In International Conference on Machine Learning (ICML)
 Explaining and Harnessing AdversarialExamples,2015, In International Conference on Learning Representations (ICLR)
 Scalable verified training forprovably robust image classification,2019, In The IEEE International Conference on Computer Vision(ICCV)
 Learning universal adversarial perturbations with generative models,2018, In2018 IEEE Security and Privacy Workshops (SPW)
 Deep residual learning for imagerecognition,2016, In Computer Vision and Pattern Recognition (CVPR)
 Benchmarking neural network robustness to commoncorruptions and perturbations,2019, International Conference on Learning Representations (ICLR)
 On physical adversarial patches for object detection,2019, InternationalConference on Machine Learning (Workshop)
 Adversarial camera stickers: A physical camera-based attack on deep learning systems,2019, International Conference on Machine Learning (ICML)
 Improvingrobustness without sacrificing accuracy with patch gaussian augmentation,2019, CoRR
 UniversalAdversarial Perturbations Against Semantic Image Segmentation,2017, International Conference onComputer Vision (ICCV)
 DeepFool: a simple andaccurate method to fool deep neural networks,2016, In Computer Vision and Pattern Recognition(CVPR)
 Universaladversarial perturbations,2017, In IEEE Conference on Computer Vision and Pattern Recognition
 Fast feature fool: A data independentapproach to universal adversarial perturbations,2017, In Proceedings of the British Machine VisionConference (BMVC)
 Generalizable data-free objectivefor crafting universal adversarial perturbations,2018, arXiv preprint arXiv: 1801
 Defending against universalperturbations with shared adversarial training,2019, In The IEEE International Conference on ComputerVision (ICCV)
 Playing the Game of UniversalAdversarial Perturbations,2018, arXiv:1809
 Weight standardization,2019, arXivpreprint arXiv:1903
 Attacking optical flow,2019, InInternational Conference on Computer Vision (ICCV)
 Yolov3: An incremental improvement,2018, CoRR
 Accessorize to a Crime:Real and Stealthy Attacks on State-of-the-Art Face Recognition,2016, In Proceedings of the 2016 ACMSIGSAC Conference on Computer and Communications Security
 Adversarial generativenets: Neural network attacks on state-of-the-art face recognition,2017, December 2017
 On the effectiveness of low frequencyperturbations,2019, International Joint Conference on Artificial Intelligence (IJCAI)
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations (ICLR)
 Fooling automated surveillance cameras: adversar-ial patches to attack person detection,2019, In Conference on Computer Vision and Pattern Recognition(Workshop)
 Defending against physically realizable attackson image classification,2020, In International Conference on Learning Representations (ICLR)
 Making an Invisibility Cloak: RealWorld Adversarial Attacks on Object Detectors,2020, In 16th European Conference on Computer Vision(ECCV)
 Intriguing properties of adversarial training at scale,2020, In InternationalConference on Learning Representations (ICLR)
 Improved Adversarial Training via Learned Optimizer,2020, In 16thEuropean Conference on Computer Vision (ECCV)
 PatchAttack: ABlack-box Texture-based Attack with Reinforcement Learning,2020, In 16th European Conference onComputer Vision (ECCV)
 Design and Interpretation of UniversalAdversarial Patches in Face Detection,2020, In 16th European Conference on Computer Vision (ECCV)
 You only propagateonce: Accelerating adversarial training via maximal principle,2019, In Advances in Neural InformationProcessing Systems 32
