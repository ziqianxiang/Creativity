title,year,conference
 A Learning Rule for Asynchronous Perceptrons with Feedback in a CombinatorialEnvironment,1990, In Artificial Neural Networks: Concept Learning
 Deep equilibrium models,2019, In Advances in NeuralInformation Processing Systems
 Multiscale deep equilibrium models,2020, In Advancesin Neural Information Processing Systems
 Neural ordinarydifferential equations,2018, In Advances in neural information processing systems
 NAIS-Net: Stable Deep NetWorks from Non-Autonomous Differential Equations,2018, arXiv:1804
 Compressed sensing,2006, IEEE Transactions on information theory
 Barron Spaces and the Compositional Function Spaces for NeuralNetWork Models,1906, arXiv:1906
 Spatially Adaptive Computation Time for Residual NetWorks,2017, pp
 The Reversible ResidualNetWork: Backpropagation Without Storing Activations,1707, arXiv:1707
 Adaptive Computation Time for Recurrent Neural NetWorks,1603, arXiv:1603
 Highway and Residual Networks learnUnrolled Iterative Estimation,2017, In Proceedings of the 5th International Conference on LearningRepresentations
 Learning fast approximations of sparse coding,2010, In Proceedings ofthe 27th International Conference on International Conference on Machine Learning
 Stable Architectures for Deep Neural Networks,1361, Inverse Problems
 Delving Deep into Recti-fiers: Surpassing Human-Level Performance on ImageNet Classification,2015, pp
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Deep Unfolding: Model-Based Inspirationof Novel Deep Architectures,1409, arXiv:1409
 Untersuchungen zu dynamischen neuronalen Netzen,1991, PhD thesis
 Learning Deep ResNet Blocks Se-quentially using Boosting Theory,2018, In International Conference on Machine Learning
 Deep Networks withStochastic Depth,2016, In Bastian Leibe
 Neural Networks with Recurrent Generative Feedback,2007, arXiv:2007
 Fast readout of objectidentity from macaque inferior temporal cortex,2005, Science
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, arXiv preprint arXiv:1502
 Disentangling neural mechanismsfor perceptual grouping,2020, In International Conference on Learning Representations
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Learning Multiple Layers of Features from Tiny Images,2009, Technical report
 Brain-Like Object Recognition with High-PerformingShallow Recurrent ANNs,2019, In H
 MNIST handwritten digit database,2010, 2010
 Stable and expressive recurrent vision models,2005, arXiv:2005
 Spectral Normalizationfor Generative Adversarial Networks,2018, In International Conference on Learning Representations
 A Bayesian Perspective of Convolutional Neural Networks through a Deconvolutional Gen-erative Model,1811, arXiv:1811
 patchwork: The Composer of Plots,2019, 2019
 Generalization of back-propagation to recurrent neural networks,1987, Physicalreview letters
 Improving Transformer Models by Reordering theirSublayers,2020, arXiv:1911
 Predictive coding in the visual cortex: a functional in-terpretation of some extra-classical receptive-field effects,1546, Nature Neuroscience
 Stochastic Backpropagation andApproximate Inference in Deep Generative Models,2014, In International Conference on MachineLearning
 Learning Implicitly Recurrent CNNs Through ParameterSharing,2019, In International Conference on Learning Representations
 DescTools: Tools for Descriptive Statistics,2020, 2020
 Recurrent Convolutional NeuralNetworks: A Better Model of Biological Object Recognition,2017, Frontiers in Psychology
 Highway networks,2015, arXivpreprintarXiv:1505
 Python 3 Reference Manual,2009, CreateSpace
 ResidUal Networks Behave Like En-sembles of Relatively Shallow Networks,2016, In D
 tidyr: Tidy Messy Data,2019, 2019
 dplyr: A Grammar of DataManipulation,2019, 2019
 Interpretable Recurrent Neural Net-works Using Sequential Sparse Recovery,1611, arXiv:1611
 Early recurrent feedback facilitates visualobject recognition under challenging conditions,2014, Frontiers in psychology
 Spectral norm regularization for improving the generalizabilityof deep learning,2017, arXiv preprint arXiv:1705
 Wide Residual Networks,1605, arXiv:1605
 Feedback networks,2017, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
