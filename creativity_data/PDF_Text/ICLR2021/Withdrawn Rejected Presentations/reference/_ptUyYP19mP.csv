title,year,conference
 Human-levelcontrol through deep reinforcement learning,2015, nature
 Agent57: Outperforming the atari human benchmark,2020, arXivpreprint arXiv:2003
 Grandmasterlevel in starcraft ii using multi-agent reinforcement learning,2019, Nature
 Masteringthe game of go with deep neural networks and tree search,2016, nature
 Mastering the game of gowithout human knowledge,2017, nature
 Openai gym,2016, arXiv preprint arXiv:1606
 Deepstack: Expert-level artificialintelligence in heads-up no-limit poker,2017, Science
 Curiosity-driven explorationby self-supervised prediction,2017, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition Workshops
 Exploration by random networkdistillation,2018, arXiv preprint arXiv:1810
 Count-based explo-ration with neural density models,2017, arXiv preprint arXiv:1703
 Nevergive up: Learning directed exploration strategies,2020, arXiv preprint arXiv:2002
 Sched-uled intrinsic drive: A hierarchical take on intrinsically motivated exploration,2019, arXiv preprintarXiv:1903
 Hierarchical RL using an ensem-ble of proprioceptive periodic policies,2019, In International Conference on Learning Representations
 Go-explore: anew approach for hard-exploration problems,2019, arXiv preprint arXiv:1901
 Learning with amigo: Adversarially motivated intrinsiC goals,2020, arXivpreprint arXiv:2006
 Infobot: Transfer and exploration via the in-formation bottleneck,2019, arXiv preprint arXiv:1901
 First return thenexplore,2020, arXiv preprint arXiv:2004
 A frontier-based approach for autonomous exploration,1997, In Proceedings 1997IEEE International Symposium on Computational Intelligence in Robotics and AutomationCIRA '97
 Frontier-based exploration using multiple robots,1998, In Proceedings of the secondinternational conference on Autonomous agents
 Frontier based exploration for autonomousrobot,2018, arXiv preprint arXiv:1806
 Incentivizing exploration in reinforcementlearning with deep predictive models,2015, arXiv preprint arXiv:1507
 Emi: Ex-ploration with mutual information,2018, arXiv preprint arXiv:1810
 Vime:Variational information maximizing exploration,2016, In Advances in Neural Information ProcessingSystems
 Surprise-based intrinsic motivation for deep reinforcementlearning,2017, arXiv preprint arXiv:1703
 Model-based active exploration,2019, InInternational Conference on Machine Learning
 All else being equal be empow-ered,2005, In European Conference on Artificial Life
 Variational intrinsic control,2016, arXivpreprint arXiv:1611
 Variational information maximisation for intrinsi-cally motivated reinforcement learning,2015, In Advances in neural information processing systems
 Diversity is all you need:Learning skills without a reward function,2018, arXiv preprint arXiv:1802
 Reinforcement learning with unsupervised auxiliary tasks,2016, arXivpreprint arXiv:1611
 Efficient exploration via state marginal matching,2019, arXiv preprint arXiv:1906
 Deep exploration viabootstrapped dqn,2016, In Advances in neural information processing systems
 Rainbow: Combining improvements indeep reinforcement learning,2017, arXiv preprint arXiv:1710
 GeP-Pg: Decoupling exploration and ex-ploitation in deep reinforcement learning algorithms,2018, arXiv preprint arXiv:1802
 Intrinsically motivated goal explo-ration processes with automatic curriculum learning,2017, arXiv preprint arXiv:1708
 Directed exploration for reinforcement learning,2019, arXivpreprint arXiv:1906
 Self-imitation learning,2018, arXiv preprintarXiv:1806
 Hindsight experience re-play,2017, In Advances in neural information processing systems
 Curriculum learning,2009, InProceedings of the 26th annual international conference on machine learning
 Teacher-student curriculum learn-ing,2019, IEEE transactions on neural networks and learning systems
 Un-supervised curricula for visual meta-reinforcement learning,2019, In Advances in Neural InformationProcessing Systems
 Reverse cur-riculum generation for reinforcement learning,2017, arXiv preprint arXiv:1707
