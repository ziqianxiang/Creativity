title,year,conference
 Gluonts:Probabilistic time series models in python,2019, arXiv preprint arXiv:1906
 Fast multivariate spatio-temporal analysis via low ranktensor learning,2014, In Advances in neural information processing systems
 Co-evolutionary multi-task learning with predictiverecurrence for multi-step chaotic time series prediction,2017, Neurocomputing
 Tada: trendalignment with dual-attention multi-task recurrent neural networks for sales prediction,2018, In 2018 IEEEInternational Conference on Data Mining (ICDM)
 Generating long sequences with sparsetransformers,2019, arXiv preprint arXiv:1904
 Funnel-transformer: Filtering out sequentialredundancy for efficient language processing,2020, arXiv preprint arXiv:2006
 Time series forecasting using sequence-to-sequence deeplearning framework,2018, In 2018 9th International Symposium on Parallel Architectures
 Spatiotemporal multi-graph convolution network for ride-hailing demand forecasting,2019, In Proceedings of the AAAI Conference onArtificial Intelligence
 Lstm recurrent networks learn simple context-free and context-sensitivelanguages,2001, IEEE Transactions on Neural Networks
 A study of time series models arima and ets,2017, Available at SSRN 2898968
 Transformers are rnns: Fastautoregressive transformers with linear attention,2020, arXiv preprint arXiv:2006
 Reformer: The efficient transformer,2020, arXiv preprintarXiv:2001
 Metalearners for estimating heterogeneoustreatment effects using machine learning,2019, Proceedings of the national academy of sciences
 Enhancingthe locality and breaking the memory bottleneck of transformer on time series forecasting,2019, In Advances inNeural Information Processing Systems
 Geoman: Multi-level attention networksfor geo-sensory time series prediction,2018, In IJCAI
 Temporal fusion transformers for interpretablemulti-horizon time series forecasting,2019, arXiv preprint arXiv:1912
 Deep state space models for time series forecasting,2018, In Advances in neural informationprocessing systems
 Efficient attention: Attentionwith linear complexities,2018, arXiv preprint arXiv:1812
 The kpss stationarity test as a unit root test,1992, Economics Letters
 Sequence to sequence learning with neural networks,2014, InAdvances in neural information processing systems
 A spatial-temporal multitask collaborative learning model formultistep traffic flow prediction,2018, Transportation Research Record
 Language models with transformers,2019, arXiv preprintarXiv:1904
 Linformer: Self-attention with linearcomplexity,2020, arXiv preprint arXiv:2006
 A multi-horizon quantilerecurrent forecaster,2017, arXiv preprint arXiv:1711
 HUggingface's transformers: State-of-the-artnatural language processing,2019, ArXiv
 Spatio-temporal graph transformer networks forpedestrian trajectory prediction,2020, arXiv preprint arXiv:2005
 Temporal regularized matrix factorization for high-dimensional time series prediction,2016, In Advances in neural information processing systems
 Spatial-temporal graph attention networks: A deep learning approachfor traffic forecasting,2019, IEEE Access
 Time series forecasting using a hybrid arima and neural network model,2003, Neurocomputing
 Short-term traffic flow prediction based onspatio-temporal analysis and cnn deep learning,2019, Transportmetrica A: Transport Science
 Deep and confident prediction for time series at uber,2017, In 2017 IEEEInternational Conference on Data Mining Workshops (ICDMW)
