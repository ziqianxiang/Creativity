title,year,conference
 Openai gym,2016, arXiv preprint arXiv:1606
 Learning robust rewards with adversarial inverse reinforce-ment learning,2017, arXiv preprint arXiv:1710
 Addressing function approximation error inActor-Critic methods,2018, arXiv preprint arXiv:1802
 Soft Actor-Critic: Off-Policy maximum entropy deep reinforcement learning with a stochastic actor,2018, arXiv preprintarXiv:1801
 Rainbow: Combining improvements indeep reinforcement learning,2017, arXiv preprint arXiv:1710
 Generative adversarial imitation learning,2016, In Advances in NeuralInformation Processing Systems
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Actor-critic algorithms,2000, In Advances in neural informationprocessing systems
 Image augmentation is all you need: Regularizingdeep reinforcement learning from pixels,2020, arXiv preprint arXiv:2004
 Discor: Corrective feedback in reinforcementlearning via distribution correction,2020, arXiv preprint arXiv:2003
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Human-level controlthrough deep reinforcement learning,2015, Nature
 Asynchronous methods for deep reinforcementlearning,2016, In International Conference on Machine Learning
 Safe and efficient Off-Policy reinforcement learning,2016, arXiv preprint arXiv:1606
 Reinforcement learning via Fenchel-Rockafellar duality,2020, arXiv preprintarXiv:2001
 AlgaeDICE:Policy gradient from arbitrary experience,2019, arXiv preprint arXiv:1912
 Estimating divergence functionals andthe likelihood ratio by convex risk minimization,2008, arXiv preprint arXiv:0809
 Remember and forget for experience replay,2018, arXiv preprintarXiv:1807
 Eligibility traces for off-policy policy evaluation,2000, Computer Science Department Faculty
 Off-policy temporal-difference learning withfunction approximation,2001, In ICML
 Prioritized experience replay,2015, arXivpreprint arXiv:1511
 Off-Policy Actor-Critic with shared experiencereplay,2019, arXiv preprint arXiv:1909
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Deepmind control suite,2018, arXiv preprintarXiv:1801
 An analysis of Temporal-Difference learning withfunction approximation,0018, IEEE transactions on automatic control
 Boosting soft Actor-Critic: Emphasizing recent experience withoutforgetting the past,2019, arXiv preprint arXiv:1906
 Sample efficient Actor-Critic with experience replay,2016, arXiv preprintarXiv:1611
