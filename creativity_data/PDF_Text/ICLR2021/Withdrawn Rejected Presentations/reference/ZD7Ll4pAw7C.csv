title,year,conference
 Segnet: A deep convolutional encoder-decoder architecture for image segmentation,2017, IEEE transactions on pattern analysis and machineintelligence
 Autoaugment:Learning augmentation strategies from data,2019, In Proceedings of the IEEE conference on computervision and pattern recognition
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv preprint arXiv:1708
 Global sparse momen-tum sgd for pruning very deep neural networks,2019, In Advances in Neural Information ProcessingSystems
 Learning to prune deep neural networks via layer-wiseoptimal brain surgeon,2017, In Advances in Neural Information Processing Systems
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In Proceedings of the thirteenth international conference on artificial intelligence andstatistics
 Applications of the fkg inequality and its relatives,1983, In Mathematical Programming TheState of the Art
 Second order derivatives for network pruning: Optimal brainsurgeon,1993, In Advances in neural information processing systems
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In Proceedings of the IEEE internationalconference on computer vision
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Soft filter pruning for acceleratingdeep convolutional neural networks,2018, arXiv preprint arXiv:1808
 Filter pruning via geometric medianfor deep convolutional neural networks acceleration,2019, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 The analysis of partial differential operators,1983, Springer
 Network trimming: A data-drivenneuron pruning approach towards efficient deep architectures,2016, arXiv preprint arXiv:1607
 Squeeze-and-excitation networks,2018, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Dianet: Dense-and-implicitattention network,2019, arXiv preprint arXiv:1905
 Perceptual losses for real-time style transfer andsuper-resolution,2016, In European conference on computer vision
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Optimal brain damage,1990, In Advances in neuralinformation processing systems
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Eagleeye: Fast sub-net evaluationfor efficient neural network pruning,2020, arXiv preprint arXiv:2007
 Pruning filters forefficient convnets,2016, arXiv preprint arXiv:1608
 Spatial group-wise enhance: Improving semantic featurelearning in convolutional networks,2019, arXiv preprint arXiv:1905
 Drop-activation: Implicit parameter reduction andharmonic regularization,2018, arXiv preprint arXiv:1811
 Instance enhancement batchnormalization: an adaptive regulator of batch noise,2019, arXiv preprint arXiv:1908
 Rethinking class-discrimination based cnn channelpruning,2020, arXiv preprint arXiv:2004
 Joint multi-dimension pruning,2020, arXiv preprint arXiv:2005
 Learn-ing efficient convolutional networks through network slimming,2017, In Proceedings of the IEEEInternational Conference on Computer Vision
 Rethinking the value ofnetwork pruning,2018, arXiv preprint arXiv:1810
 Sgdr: Stochastic gradient descent with warm restarts,2016, arXivpreprint arXiv:1608
 An entropy-based pruning method for cnn compression,2017, arXivpreprint arXiv:1706
 Thinet: A filter level pruning method for deep neuralnetwork compression,2017, In Proceedings of the IEEE international conference on computer vision
 Alphagan: Generative adversarialnetworks for natural image matting,2018, arXiv preprint arXiv:1807
 Importance estimationfor neural network pruning,2019, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Importance estimationfor neural network pruning,2019, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 BAYESIAN LEARNING FOR NEURAL NETWORKS,1995, PhD thesis
 Unsupervised representation learning with deepconvolutional generative adversarial networks,2015, arXiv preprint arXiv:1511
 Faster r-cnn: Towards real-time objectdetection with region proposal networks,2015, In Advances in neural information processing systems
 Comparing fine-tuning and rewinding in neuralnetwork pruning,2020, In International Conference on Learning Representations
 Exact solutions to the nonlinear dynam-ics of learning in deep linear neural networks,2013, arXiv preprint arXiv:1312
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Luck matters: Understanding trainingdynamics of deep relu networks,2019, arXiv preprint arXiv:1905
 Aggregated residual trans-formations for deep neural networks,2017, In Proceedings of the IEEE conference on computer visionand pattern recognition
 Empirical evaluation of rectified activations inconvolutional netWork,2015, arXiv preprint arXiv:1505
 Deep image matting,2017, In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition
 Rethinking the smaller-norm-less-informativeassumption in channel pruning of convolution layers,2018, In International Conference on LearningRepresentations
 Wide residual netWorks,2016, arXiv preprintarXiv:1605
 Adadelta: an adaptive learning rate method,2012, arXiv preprint arXiv:1212
 Since Eq,2021, (9) and Eq
