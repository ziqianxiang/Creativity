title,year,conference
 Safe model-basedreinforcement learning with stability guarantees,2017, In NIPS
 Data-efficient model-basedreinforcement learning with deep probabilistic dynamics models,2018, In NIPS 2018
 Multi-task deep reinforcement learning with popart,2018, In AAAI
 Bootstrap estimated uncertainty of the environmentmodel for model-based reinforcement learning,2019, In AAAI
 Not all samples are created equal: Deep learning withimportance sampling,2018, In ICML
 Modeling the long term future in model-based reinforcement learning,2019, In ICLR
 Bayesian multi-task reinforcement learning,2010, InICML
 PIC: permutation invariant critic formulti-agent deep reinforcement learning,2019, In 3rd Annual Conference on Robot Learning
 Actor-mimic: Deep multitask and transferreinforcement learning,2015, CoRR
 Progressive neural networks,2016, ArXiv
 Prioritized experience replay,2016, InInternational Conference on Learning Representations
 The bottle-neck simulator: A model-based deep reinforcement learning approach,2018, ArXiv
 Distral: Robust multitask reinforcementlearning,2017, In NIPS
 Learning valuesacross many orders of magnitude,2016, In NIPS
 Multi-task reinforcement learning: ahierarchical bayesian approach,2007, In ICML ’07
 Algorithmic framework formodel-based reinforcement learning with theoretical guarantees,2019, ArXiv
 Improvingsample efficiency in model-free reinforcement learning from images,2019, ArXiv
 Towards sample efficient reinforcement learning,2018, In IJCAI
 The goal of task t is to aggregate modelsin a federated learning experiment over a subset of clients Ut ⊆ U ,2021, At each step n
