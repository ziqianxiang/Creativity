title,year,conference
 Deep speech 2: End-to-end speech recognition in english and mandarin,2016, In International conference on machine learning
 Deep equilibrium models,2019, In Advances in NeuralInformation Processing Systems
 Neural networks and principal component analysis: Learning fromexamples without local minima,1989, Neural networks
 Large scale GAN training for high fidelitynatural image synthesis,2019, In International Conference on Learning Representations
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Recurrent stacking of layers for compact neural machine translationmodels,2019, In Proceedings of the AAAI Conference on Artificial Intelligence
 Identity matters in deep learning,2017, In International Conference forLearning Representations
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Adam: A method for stochastic optimization,2015, In InternationalConference for Learning Representations
 Deep linear networks with arbitrary loss: All local minima areglobal,2018, In International conference on machine learning
 GShard: Scaling giant models with conditionalcomputation and automatic sharding,2020, arXiv preprint arXiv:2006
 Japanese and Korean voice search,2012, In IEEE InternationalConference on Acoustics
 Exponential convergence time of gradient descent for one-dimensional deep linearneural networks,2019, In Conference on Learning Theory
 Mesh-TensorFlow: Deeplearning for supercomputers,2018, In Advances in Neural Information Processing Systems
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Global convergence of gradient descent for deep linearresidual networks,2019, In Advances in Neural Information Processing Systems
 On layer normalization in the transformer architec-ture,2020, In International Conference on Machine Learning
 Large batch optimization for deeplearning: Training bert in 76 minutes,2020, In International Conference on Learning Representations
