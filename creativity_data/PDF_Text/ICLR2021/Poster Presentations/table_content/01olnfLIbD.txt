Table 1: CIFAR-10 ablation. ε = 16, budget is 1%. Differentiable data augmentation is able toreplace a large 8-model ensemble, without increasing computational effort.
Table 2: CIFAR-10 Comparison to other poisoning objectives with a budget of 1% within ourframework (columns 1 to 3), for a 6-layer ConvNet and an 18-layer ResNet. MetaPoison* denotes thefull framework of Huang et al. (2020). Each cell shows the avg. poison success and its standard error.
Table 3: Results on the benchmark of Schwarzschild et al. (2020). Avg. accuracy of poisoned CIFAR-10 (budget 1%, ε = 8) over 100 trials is shown. (*) denotes rows replicated from Schwarzschild et al.
Table 4: Target/poison class pairs generated from the initial random seeds for ImageNet experiments.
Table 5: Target/poison class pairs generated from the initial random seeds for ImageNet experiments.
Table 6: Outlier detection is close to random-guessing for poison detection on CIFAR-10.
Table 7: Average poisoning success under victim training data ablation. In the first regime, victimablation, a proportion of the victim’s training data (clean + poisoned) is selected randomly and thenthe victim trains on this subset. In the second regime, pretrained + victim ablation, the pretrainednetwork is trained on a randomly selected proportion of the data, and then the victim chose a newrandom subset of clean + poisoned data on which to train. All results averaged over 5 runs onImageNet.
Table 8:	CIFAR-10 ablation runs. ε = 16, budget is 1%. All values are computed for ResNet-18models.
Table 9:	CIFAR-10 ablation runs. ε = 16, budget is 1% with default parameters, modifying only thenumber of targets and budget.
Table 10: CIFAR-10 baseline clean validation accuracy. ε = 16, budget is 1%. All values arecomputed for ResNet-18 models as in the baseline plot in section 5.1.
