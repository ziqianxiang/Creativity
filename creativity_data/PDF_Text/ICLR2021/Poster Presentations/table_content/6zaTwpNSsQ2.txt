Table 1: Kulisch accumulator examples.
Table 2: Final Validation Accuracy (%) on CIFAR datasets for ResNet-18.
Table 3: Training Accuracy (%) on CIFAR-10 for VGG16 and log quantization.
Table 4: Top-1 accuracy (%) of reduced precision (RP) training on ImageNet for ResNet-18 models.
Table 5: Baseline FP32 v BM8 training on Image, Language and Object Detection models.
Table 6: Logic area and power of singlecycle fused multiply-Add (FMA) and 4x4 array multipliers. Synthesized at 750 MHz with Cadence RTL Compiler 14.11 and 28nm cell library.
Table 7: Comparison of Block Minifloat number formats.
Table 8: Comparison of Block Minifloat (BM) and Block Floating Point (BFP) number formats trained on ImageNet with ResNet-18 model.
Table 9: Synthesized logic area and power of single-cycle fused multiply-Add (FMA) at 750 MHz on 28nm chip.
Table 10: Synthesized logic area and power of 4x4 systolic array multipliers at 750 MHz on 28nm chip.
Table 11: Component breakdown and logic area for different 8-bit BM formats.