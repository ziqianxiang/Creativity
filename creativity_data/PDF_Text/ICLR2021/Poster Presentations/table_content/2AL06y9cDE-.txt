Table 1: Experimental results on ResNet-20 from standard training.
Table 2: Experimental results on robustly trained networks.
Table 3: Accuracy comparision of CLC-NN and reactive defense in Eq. (12), with attack = 2 / 4 / 8.
Table 4: ResNet for Both CIFAR-10 and CIFAR-100Structure	ConfigurationInitial Layer	Conv2d (input channel = 3, output channel = 16, kernel size = 3 X 3), BatchNorm2d(channel = 16), Relu()Residual Block 1	{Conv2d (input channel = 16, output channel = 16, kernel size = 3 × 3), BatchNorm2d(channel = 16), Relu(), Shortcut。} ×6Residual Block 2	Conv2d (input channel = 16, output channel = 32, kernel size = 3 × 3), BatchNorm2d(channel = 16), Relu(), Shortcut(), {Conv2d (input channel = 32, output channel = 32, kernel size = 3 × 3), BatchNorm2d(channel = 32), Relu(), Shortcut()} × 5Residual Block 3	Conv2d (input channel = 32, output channel = 64, kernel size = 3 × 3), BatchNorm2d(channel = 64), Relu(), Shortcut(), {Conv2d (input channel = 64, output channel = 64, kernel size = 3 × 3), BatchNorm2d(channel = 64), Relu(), Shortcut()} ×5Final Layer	Fully Connected (64,10)In the specific case, when all θt are orthogonal,Yt : = max(1 + κ(θs)2)kI - θTθs∣∣2s≤t= 0.
Table 5: Convolutional Auto-EncodersStructure	Configuration				Encoder	Conv2d (input channel = ci, output channel = c2, kernel size = 4 X 4, stride = 2 × 2, padding = 1 × 1 ), ELU(alpha=1), BatchNorm2d(channel = c2), Conv2d (input channel = c2, output channel = c3, kernel size = 4 × 4, stride = 2 × 2, padding = 1 × 1 ), ELU(alpha=1).				Decoder	COnvTranSPose2d (input channel = c3, output channel = c2, kernel size = 4 × 4, stride = 2 × 2, padding = 1 × 1), ELU(alpha=1), ConvTranspose2d (input channel = c2, output channel = c1, kernel size = 4 × 4, stride = 2 × 2, padding = 1 × 1),				Auto-encoder Index		0	1	2	3Channel Dimensions [c1, c2, c3]		[3, 18, 36]	[16, 36, 72]	[16, 36, 72]	[32, 128, 256]•	For the nonlinear embedding: we train 4 convolutional auto-encoders for the input space, outputsof the initial layer and residual blocks 1, 2. All of the embedding functions are trained individually.
Table 6: Experimental results on DenseNet-40 from standard training.
Table 7: Comparison between CLC-NN and layer-wise projection.
