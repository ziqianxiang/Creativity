Table 1: AUC of Robustness-Sr and Robustness-Sr for various explanations on different datasets.
Table 2: AUC of the Insertion and Deletion criteria for various explanations on different datasets.
Table 3: AUC of Robustness-Sr and RobUStneSS-Sr for Greedy-AS and its variants. The higher thebetter for RobUStneSS-Sr; the lower the better for RobUStneSS-Sr.
Table 4: The proposed Greedy-AS versus other explanations under various criteria with Studentâ€™st-test at 95% confidence level.
Table 5: AUC of the Insertion and Deletion criteria with different reference values for variousexplanations on MNIST. The higher the better for Insertion; the lower the better for Deletion.
Table 6: AUC of the Insertion and Deletion criteria with different reference values for variousexplanations on ImageNet. The higher the better for Insertion; the lower the better for Deletion.
Table 7: Rank correlation between explanations with respect to original and randomized model.
Table 8: Sensitivity of Different Explanations.
Table 9: AUC of the different evaluation criteria for various explanations on Yahoo!Answers. Thehigher the better for Robustness-Sr and Insertion; the lower the better for Robustness-Sr and Deletion.
Table 10: Precision of Explanations with User Labeled Ground Truth	p@1	p@2	P@3	P@4	P@5	mAPGreedy-AS	0.83	0.78	0.78	0.75	0.68	0.76Grad	0.83	0.70	0.72	0.67	0.61	0.71IG	0.83	0.67	0.56	0.52	0.50	0.61SHAP	0.73	0.75	0.61	0.58	0.51	0.64LOO	0.67	0.67	0.52	0.48	0.45	0.56EG	0.90	0.75	0.69	0.67	0.63	0.73Anchor	0.93	-	-	-	-	-CFX	0.83	0.68	0.67	0.61	0.57	0.67Random	0.17	0.27	0.28	0.29	0.27	0.25Q Runtime AnalysisWe show below the average runtime (wall clock time) of different methods for computing explanationfor a single image on MNIST and ImageNet. For Greedy and Greedy-AS, we show the time neededto compute the top-20% relevant features.
Table 11: Runtime of Different Explanations.
