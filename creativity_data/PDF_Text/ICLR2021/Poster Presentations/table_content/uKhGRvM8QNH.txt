Table 1: Experiments on MS COCO2017 with the proposed distillation method.
Table 2: Experiments on MS COCO2017 with the proposed distillation method on Mask RCNN.
Table 3: Comparison between our methods and other distillation methods. Note that we don’tcompare our methods with Chen’s and Wang’s methods on RetinaNet because their methods can notbe utilized in one-stage models. ResNet50 is utilized as backbone in these models.
Table 4: Ablation study of the three distillation loss.
Table 5: Results of differenttypes of non-local moduleson Faster RCNN (ResNet50backbone).
Table 6: Ablation study on the spatial attention and channel attention.
Table 7: Experiments on MS COCO2017 with our method on small backbones.
Table 8: Experiments on Cityscapes with our method.
Table 9: Comparision on methodology and application.
