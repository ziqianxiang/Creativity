Table 1: Ablation for multi-stage cross-attention. The results for different stages of the cross-attention are reported for the AVE and ActivityNet1.2 datasets. The comparison with the uni-modalapproach shows the impact of leveraging the multi-modality and the cross-attention.
Table 2: Ablations for the consistency losses and open-max classifier. Consistency losses: Thelower part of the table shows the impact of each of the two consistency losses, when used with theopen-max classifier. Open-max vs soft-max: The results for the soft-max are also shown, whichdemonstrates the advantage of foreground/background modelling by the open-max classification onboth the datasets. The model with 2-stage cross-attention is used.
Table 3: Impact of dense skip con-	Table 4: Comparison		of the number	of FLOPS andnections: Ablation studies on dense skip connection in terms of average of mAP@[0.5:0.05:0.95] for the Activi- tyNet1.2 dataset. For 2-stage model, no,	the average mAP@[0.5:0.05:0.95] on the ActivityNet1.2 dataset for visual-only, 1-stage, and 2-stage models. dx × dx are the dimensions for the cross-correlation matrix W.				Method	dx	No. FLOPS	Avg. mAPskip, and dense connections are verified.					Visual-only	1024	2.3 × 106	22.1				Method	Avg. mAP	1-stage	1024	3.5×106	24.1w/o skip connection	24.1	2-stage	1024	4.0×106	26.0w/ skip connection	24.9	Visual-only	512	1.2×106	21.0w/ dense skip connection	26.0	2-stage	512	1.7×106	25.9catenation. Even this naive fusion yields higher performance than the uni-modal methods on theAVE dataset. However, that is not the case with more challenging task of the action localization onActivityNet1.2 dataset. Furthermore, all the later stages improve considerably over 0-stage and theuni-modal cases, for the both datasets. The 2-stage cross-attention achieves the best performancefor the both datasets (more in Appendix A). Interestingly, even with the minimal audio cue in Ac-tivityNet1.2 (avg. mAP of audio only is 7.8%), the proposed audio-visual features improve the avg.
Table 5: Comparison of the proposed method with the state-of-the-art fully and weakly-supervisedmethods (separated by ‘/’) on the AVE dataset. Snippet-level accuracy (%) is reported.
Table 6: Comparison of our method with the state-of-the-art action localization methods on theActivityNet1.2 dataset. The mAPs (%) at different IoU thresholds and average mAP across the IoUthresholds are reported. * indicates audio-visual models. ?experiment done using author,s code.
Table 7: Comparing 2-stage and 3-stage models: Training of 3-stage model is analyzed with skipconnections in comparison to the 2-stage model.
Table 8: Need for multi-stage: Ablation study on the size of the dimension for the cross-correlationmatrix W ∈ Rdx,u×dx,v for 1-stage model on the AVE dataset. 2-stage model with W ∈ R1024×1024is the proposed.
Table 9: For 0-3 stage models, ablation analysis on consistency losses for open-max (O-0, O-I, O-II,and O-III) classifiers on the AVE and the ActivityNet1.2 datasets. O-III of 2-stage is the proposed.
