Table 1: Accuracy and stability results with and without label smoothing on ImageNet-1K. Herewe show (1-SStability), which denotes the aggregated intra-class variance (the lower the better). Rednumbers are the quantitative values of the erased information by label smoothing.
Table 2: Image classification results on ImageNet-1K, CUB200-2011 and iMaterialist product recog-nition (in Appendix D). The teacher networks with label smoothing are denoted by “✓”. We reportaverage over 3 runs for all the teacher network training and StUdent distihation.______________________ImageNet-1K (Standard):				Teacher	w/ LS	Acc. (Top1∕Top5)	Student	Acc. (Top1∕Top5)ReSNet_50	X	76.056 ± 0.119/92.791 ± 0.106	ResNet-18 ResNet-50	71.425 ± 0.038/90.185 ± 0.075 76.325 ± 0.068/92.984 ± 0.043esι∖eι-	✓	76.128 ± 0.069/92.977 ± 0.030	ResNet-18 ResNet-50	71.816 ± 0.017/90.466 ± 0.074 77.052 ± 0.030/93.376 ± 0.015CUB200-2011 (Fine-grained):				Teacher	w/ LS	Acc.(Top1∕Top5)		Student	Acc. (Top1∕Top5)ResNet-50	X	79.931 ± 0.037/94.370 ± 0.064	ResNet-18 ResNet-50	77.116 ± 0.086/93.241 ± 0.108 80.910 ± 0.033/94.738 ± 0.114	✓	81.497 ± 0.035/95.043 ± 0.112	ResNet-18 ResNet-50	78.382 ± 0.099/93.621 ± 0.120 82.355 ± 0.050/95.440 ± 0.075datasets: ImageNet-1K (Deng et al., 2009), CUB200-2011 (Wah et al., 2011a) and iMaterialistproduct recognition challenge data (in Appendix D). We adopt ResNet-{50/101} as teacher networksand ResNet-{18/50/101} as students, respectively. More experimental settings are in Appendix A.
Table 3: Teacher results on the long-tailed ImageNet-LT, Places365-LT and iNaturalist 2019 val set.
Table 4: Te increasing Teacher ResNet-18		✓	-/-	27.466/48.781	73.597/88.779			▲ Top-I • Top-5 Z	,acher results on the curated ImageNet dataset when	1.6 the number of classes. ImageNet-100	ImageNet-500	ImageNet-IK	- 0.8 w/ LS Acc. (Top1/Top5) Acc. (Top1/Top5) Acc. (Top1/Top5)	g X	82.380/95.520	73.521/91.642	69.758/89.076	CQ					✓	82.740/95.440	74.123/92.004	69.606/89.372		0		IResNet-101	-X	82.000/94.340	81.712/95.080	77.374/93.546					✓	83.400/95.300	82.020/95.300	77.836/93.662		-0.8 100	500 1K #class Figure 9: Acc. downtrend.		Average (↑)	↑0.880∕0.440	↑0.455∕0.291	↑0.155∕0.206 8 Conclusion					We empirically demonstrated that label smoothing could both decrease the variance (i.e., erase relativeinformation between logits) and lower mean predictive values (i.e., make prediction less confident)within a category, but it does not impair the relation distribution across different categories. Ourresults on image classification, binary neural networks, and neural machine translation indicate thatlabel smoothing is compatible with knowledge distillation and this finding encourages more carefulto understand and utilize the relationships of label smoothing and knowledge distillation in practice.
Table 5:OvervieW of Six datasets USed in our experiments. a indicates the Pareto distribution value.
Table 6: Distillation results using inferior teachers on the long-tailed iNaturalist 2019 (Van Horn et al.,2018).
Table 7: Image classification results on ImageNet-1K, CUB200-2011 and iMaterialist product recog-nition. The teacher networks with label smoothing are denoted by “✓”. We report average over 3runs for ReSNet-50 as the teacher network on both teacher training and knowledge distillation.
Table 8: ImageNet results on the same student structure with different teachers. “Long” indicates wetrain with more budget (160 epochs), the default is 90. “R50 and R18” are ResNet-50/18, respectively.
Table 9: Distillation results with different ratios of the combination with hard labels and soft labels.
Table 10: Accuracy and inter-class stability results with and without label smoothing on ImageNet-1K.
