Table 1: Performances on CIFAR-10. GPU days do not include the evaluation cost of the final architecture; NAS-BOWL results from 4 random seeds on a single NVIDIA GeForce RTX 2080 Ti.				Algorithm	Avg. Error	Best Error	#Params(M)	GPU DaysGP-NAS (Li et al., 2020)	-	3.79	3.9	1DARTS(v2) (Liu et al., 2018a)	2.76±0.09	-	3.3	4ENASt (Phametal.,2018)	-	2.89	4.6	6ASHA(Li and Talwalkar, 2019)	3.03±0.13	2.85	2.2	9Random-WS (Xie et al., 2019)	2.85±0.08	2.71	4.3	10BANANAS (White et al., 2019)	2.64	2.57	-	12BOGCN (Shi et al., 2019)	-	2.61	3.5	93*LaNett (Wang et al., 2019)	2.53±0.05	-	3.2	150NAS-BOWL	2.61±o.08	2.50	3.7	3↑: expanded search space from DARTS. *: estimated by us.-:			not reported.	It is evident that NAS-BOWL outperforms all baselines on all NAS-Bench tasks in achieving bothlowest validation and test errors. The experiments with noisy observations further show that even ina more realistic setup with noisy objective function observations, NAS-BOWL still performs verywell as it inherits the robustness against noise from the GP. The preliminary experiments on transferlearning also show that motifs contain extremely useful prior knowledge that may be transferredto warm-start a related task: notice that even the architectures at the very start without any searchalready perform well - this is particularly appealing, as in a realistic setting, searching directly onlarge-scale datasets like ImageNet from scratch is extremely expensive. While further experimental
Table 2: Regression Performance (i.t.o rank correlation) of additive kernelsKernel	N101	FloWer-102WL + MLP	0.871±0.02	0.813±0.018WLt	0.862±0.03	0.804±0.018MLPt	0.458±0.07	0.492±0.12↑: Taken directly from Table 3.
Table 3: Regression performance (i.t.o Spearman’s rank correlation) of different graph kernels.
