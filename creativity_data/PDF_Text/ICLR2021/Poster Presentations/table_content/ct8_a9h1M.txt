Table 1:	Results on noisy MNIST with MLP.
Table 2:	Results on CIFAR-100 with WRN.
Table 3:	Results on ImageNet with ResNet-18.
Table 4: Accuracy and PAvPU on visual question answering.
Table 5: Model size comparison among different methods.
Table 6: Complete results on MNIST with MLP	Original Data		Noisy Data		Accuracy	PAVPU(0.01 /0.05/0.1)	Accuracy	PAVPU(0.01 /0.05/0.1)MC dropout - Bernoulli	98.62	98.25 / 98.39 / 98.44	86.36	84.29/ 85.63 / 86.10MC dropout - Gaussian	98.67	98.23 / 98.41/ 98.46	86.31	83.99 / 85.64 / 86.03Concrete dropout	98.61	98.43/ 98.50 / 98.57	86.52	85.98 / 86.77/ 86.92Bayes By Backprop	98.44	98.26/ 98.42/ 98.56		86.55	86.89/ 87.13/ 87.26Bernoulli Contextual Dropout	99.08(0.04)	98.74(0.17) / 98.92(0.08) / 99.09(0.08)	87.43(0.39)	87.75(0.24) / 87.81(0.23) / 87.89(0.25)Gaussian Contextual Dropout	98.92(0.09)	98.71(0.02)/98.90(0.08)/99.03(0.07)	87.35(0.33)	87.64(0.19) / 87.72(0.29) / 87.78(0.32)Table 7: Loglikelihood on original MNIST with MLP.
Table 7: Loglikelihood on original MNIST with MLP.
Table 8: Complete results on CIFAR-10 with WRN	Original Data		Noisy Data		Accuracy	PAVPU(0.01/0.05/0.1)	Accuracy	PAvPU(0.01∕0.05∕0.1)MC dropout - Bernoulli	94.58	78.73 /82.34 /84.21	79.51	72.89 / 74.43 / 75.04MC dropout - Gaussian	93.81	92.59 / 93.24 / 93.85	79.33	80.43 / 81.24 / 82.31Concrete dropout	94.60	73.51 /78.41 /81.01		79.34	72.72 / 73.89 / 74.72Bernoulli Contextual Dropout	95.92(0.10)	95.25(0.23) / 95.74(0.12)/ 96.02(0.16)	81.49(0.19)	82.56(0.50) / 83.28(0.31) / 83.91(0.28)Gaussian Contextual Dropout	96.04(0.1)	95.42(0.07)/ 95.85(0.07)/ 96.10(0.06)	81.64(0.31)	82.38 (0.41) / 82.80(0.36) / 83.43(0.36)Table 9: Complete log likelihood results on CIFAR-10 with WRN	Cifar-10		Original data	Noisy dataMC dropout - Bernoulli	-1.91	-1.93MC dropout - Gaussian	-1.54	-1.72CONCRETE DROPOUT	-1.98	-2.0Bernoulli Contextual Dropout	-1.24	-1.47Gaussian Contextual Dropout	-1.19	-1.51Table 10: Complete results on CIFAR-100 with WRN	Original Data		Noisy Data		Accuracy	PAVPU(0.01 /0.05/0.1)	Accuracy	PAVPU(0.01 /0.05/0.1)MC dropout - Bernoulli	79.03	56.90 /61.54/64.14	52.01	53.86 / 54.25 / 54.63
Table 9: Complete log likelihood results on CIFAR-10 with WRN	Cifar-10		Original data	Noisy dataMC dropout - Bernoulli	-1.91	-1.93MC dropout - Gaussian	-1.54	-1.72CONCRETE DROPOUT	-1.98	-2.0Bernoulli Contextual Dropout	-1.24	-1.47Gaussian Contextual Dropout	-1.19	-1.51Table 10: Complete results on CIFAR-100 with WRN	Original Data		Noisy Data		Accuracy	PAVPU(0.01 /0.05/0.1)	Accuracy	PAVPU(0.01 /0.05/0.1)MC dropout - Bernoulli	79.03	56.90 /61.54/64.14	52.01	53.86 / 54.25 / 54.63MC dropout - Gaussian	76.63	77.35 / 78.05 / 78.26	51.38	56.83 / 57.02 / 57.31Concrete dropout	79.19	59.45 /64.14/66.63		51.58	57.62 / 56.61/ 55.89Bernoulli Contextual Dropout	80.85(0.05)	81.04(0.28)/81.56(0.31)/81.86(0.21)	53.64(0.45)	58.29(0.30) / 58.63(0.50) / 59.36(0.49)Gaussian Contextual Dropout	80.93 (0.18)	81.43(0.1)/ 81.69(0.16)/ 82.02(0.14)	53.72(0.34)	58.01(0.6) / 58.49(0.43) / 58.95(0.37)19Published as a conference paper at ICLR 2021E	TABLES AND FIGURES FOR p-VALUE 0.01, 0.05 AND 0.1F	Qualitative Analysis
Table 10: Complete results on CIFAR-100 with WRN	Original Data		Noisy Data		Accuracy	PAVPU(0.01 /0.05/0.1)	Accuracy	PAVPU(0.01 /0.05/0.1)MC dropout - Bernoulli	79.03	56.90 /61.54/64.14	52.01	53.86 / 54.25 / 54.63MC dropout - Gaussian	76.63	77.35 / 78.05 / 78.26	51.38	56.83 / 57.02 / 57.31Concrete dropout	79.19	59.45 /64.14/66.63		51.58	57.62 / 56.61/ 55.89Bernoulli Contextual Dropout	80.85(0.05)	81.04(0.28)/81.56(0.31)/81.86(0.21)	53.64(0.45)	58.29(0.30) / 58.63(0.50) / 59.36(0.49)Gaussian Contextual Dropout	80.93 (0.18)	81.43(0.1)/ 81.69(0.16)/ 82.02(0.14)	53.72(0.34)	58.01(0.6) / 58.49(0.43) / 58.95(0.37)19Published as a conference paper at ICLR 2021E	TABLES AND FIGURES FOR p-VALUE 0.01, 0.05 AND 0.1F	Qualitative AnalysisIn this section, we include the Q-Q plots of the output probabilities as the normality test for theassumptions of two-sample t-test. In Figure 7, we test the normality of differences between highestprobabilities and second highest probabilities on WRN model with contextual dropout trained onthe orignal CIFAR-10 dataset. In Figure 8, we test the normality of highest probabilities and secondhighest probabilities (separately) on VQA model with contextual dropout trained on the originalVQA-v2 dataset. We use 20 data points for the plots.
