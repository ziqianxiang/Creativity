Table 1: Examples of generating an augmentation sentence under the sensitive topic “gender”.
Table 2: Performance of debiased embeddings on Pretrained BERT and BERT post SST-2.
Table 3: Performance of debiased embeddings on BERT post CoLA and BERT post QNLI.
Table 4: Comparison of average debiasing per-formance on pretrained BERTMethod	Bias DegreeBERT origin (Devlin et al., 2019)	0.354FastText (Bojanowski et al., 2017)	0.565BERT word (Bolukbasi et al., 2016)	0.861BERT simPle (May et al., 2019)	0.298Sent-Debias (Liang et al., 2020)	0.256FairFil- (Ours)	0.179FairFil (Ours)	0.150For the ablation study, we also report the results of FairFil without the debiasing regularizer, as inFairF- . Only with the contrastive learning framework, FairF- already reduces the bias effectivelyand even achieves better effect size than the FairF on some of the SEAT tests. With the debiasingregularizer, FairF has better average SEAT effect sizes but slightly loses in terms of the downstreamperformance. However, the overall performance of FairF and FairF- shows a trade-off betweenfairness and representativeness of the filter network.
