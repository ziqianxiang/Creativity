Table 1: Three random examples from LTLRandom35 training set. The first line shows the LTLformula and the symbolic trace in mathematical notation. The second line shows the syntacticrepresentation (in Polish notation):LTL formula	satisfying symbolic traceO((dUC)UOOd) ∧ o(b ∧」(-dUC)) = &XUUdcXXdX&b!U!dc	true (b ∧ —c ∧ —d) (—c ∧ d) d (true)ω 1;&&b!c!d;&!cd;d;{l}-0((0 e ∧ (trueU b) ∧ OC) U c) !XU&&XeU1bXcc	true (-b ∧ —c) (-b)ω 1;&!b!c;{!b}0 — ((—c ∧ d) UOd) X!U&!CdXd		true (c ∨ —d) (—d) (true)ω 1;|c!d;!d; {1}FigUre7: Size distributions in the LTLUnsolved254 test set： on the x-axis is the size of the formulas;on the y-axis the number of formulas.
Table 2: Syntactic accuracy and semantic accuracy of different Transformers, tested onLTLRandom35: Layers refer to the size of the encoder and decoder stacks; Heads refer to thenumber of attention heads; FC size refers to the size of the fully-connected neural networks insidethe encoder and decoders.
