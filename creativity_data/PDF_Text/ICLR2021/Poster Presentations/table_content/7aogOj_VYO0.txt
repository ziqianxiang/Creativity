Table 1: Test accuracy (in %) with varying choices of privacy bound . The numbers under symbol ∆denote the improvement over GP baseline.
Table 2: Hyperparameter values used in Appendix A.
Table 3: Validation accuracy (in %) on CIFAR10 with varying choices of . We train a private linearmodel on top of the features from a ReSNet152 model, which is pre-trained on unlabeled ImageNet.
Table 4: Computational and memory costs of a single power iteration in Algorithm 1. The computationcost is measured by the number of floating point operations. The memory cost is measured by thenumber of floating-point numbers we need to store. ‘GEP+PG’ denotes GEP with parameter groupingand g denotes the number of groups. Notations: k, m, n, and p are the dimension of anchor subspace,number of anchor gradients, number of private gradients, and the model dimension, respectively.
Table 5: Test accuracy on CIFAR10 with different choices of auxiliary datasets. The privacy guaranteeis (8,10-5)-DP. We report the average accuracy of five runs with standard deviations in brackets.
Table 6: Test accuracy on CIFAR10 with different sizes of auxiliary dataset. The privacy guarantee is(8, 10-5)-DP. We report the average accuracy of five runs with standard deviations in brackets.
