Table 1: Comparison with state of the arts on VOC12 val set (w/ pixel-level labeled data andunlabeled data). We use the official training set (1.4k) as labeled data, and the augmented set (9k)as unlabeled data.
Table 2: Comparison with state of the arts on VOC12 val set (w/ pixel-level labeled data andunlabeled data) using low-data splits. The exact numbers of pixel-labeled images are shown inbrackets. All the methods use ResNet-101 as backbone except CCT (Ouali et al., 2020), which usesResNet-50. * indicates implementation from Ke et al. (2020), ** indicates implementation fromFrench et al. (2020).
Table 3: Comparison with state of the arts on VOC12 val set (w/ pixel-level labeled data and image-level labeled data). We use the official training set (1.4k) as labeled data, and the augmented set (9k) as image-level labeled data.				Table 4: Comparison with state of the arts on VOC12 val set with pixel-level labeled data and image-level labeled data. Four ratios of pixel-level labeled examples are tested. Both CCT (Ouali et al., 2020) and our method use ResNet-50 as backbone.		Method	Model	Network	mIoU (%)			WSSN (Papandreou et al., 2015) GAIN (Li et al., 2018)	DeepLab-CRF DeepLab-CRF-LFOV	VGG16 VGG16	64.60 60.50			MDC (Wei et al., 2018) DSRG (Huang et al., 2018)	DeepLab-CRF-LFOV DeepLabv2	VGG16 VGG16	65.70 64.30	Split	CCT	PseudoSegGANSeg (Souly et al., 2017) FickleNet (Lee et al., 2019) CCT (Ouali et al., 2020)	FCN DeepLabv2 PSP-Net	VGG16 ResNet-101 ResNet-50	65.80 65.80 73.20	1/2 1/4	66.80 67.60	73.51 71.79PseudoSeg (Ours)	DeepLabv3+	ResNet-50	73.80	1/8	62.50	69.15				1/16	51.80	65.444.2	Experiments using pixel-level labeled data and image-level labeled dataSimilar to semi-supervised learning using pixel-level labeled data and unlabeled data, we firstdemonstrate the efficacy of our method by comparing it with a strong supervised baseline. Asshown in Figure 4, the proposed method consistently improves the strong baseline on both datasets.
Table 5: Comparison to alternative pseudo labeling strategies. We conduct experiments using1/4, 1/8, 1/16 of the pixel-level labeled data, the exact numbers of images are shown in the brackets.
Table 6: Comparison with self-training. We use our supervised baseline as the teacher to generateone-hot pseudo labels, following Zoph et al. (2020).
Table 7: Improving fully supervised model with extra data. No test-time augmentation is used.
Table 8: Full results of 1/16 split in VOC12.
Table 9: Benchmarking state-of-the-art weakly supervised semantic segmentation methods.
Table 10: Performance analysis over T.	Temperature (T)	mIoU (%)0.1	71.110.3	70.110.5 (default)	71.220.7	72.371.0 (no sharpening)	68.15G Experiments on CityscapesIn this section, we conduct additional experiments on the Cityscapes dataset (Cordts et al., 2016).
Table 11: Experiments on Cityscapes (w/ pixel-level labeled data and unlabeled data).
Table 12: Per-class performance analysis on Cityscapes (w/ pixel-level labeled data andunlabeled data).
