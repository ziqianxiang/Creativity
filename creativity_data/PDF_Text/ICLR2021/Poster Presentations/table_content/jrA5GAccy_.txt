Table 1: Summary of (empirical) IRM vs. ERM for finite hypothesis class HΦ. : slack in IRM con-straints, ν: approximation w.r.t optimal risk, δ: failure probability, Etr: set of training environments,n: data dimension, p: degree of the generative polynomial, L, L0 : bound on loss & its gradients.
Table 2: Comparison of ERM vs IRM: CS-CMNISTP(Ye = 1, Ce = P(Ye = 1, Ce = P(Ye = 0, Ce = P(Ye = 1, Ce =	0|Xge) = 0|Xge) = P(Ye = 1|Yge = 1)P(Ce = 0|Ye = 1) = 0.75βe 0|Xge) = 0|Xge) = P(Ye = 0|Yge = 1)P(Ce = 0|Ye = 0) = 0.25(1 -βe)P(Ye = 1|Xe) P(Ye = 1|Xe) P(Ye = 1|Xe) P(Ye = 1|Xe)	3βe	(14) =P(Ye = 1|Xe, Ce = 0) = —β— I	Ig,	'	2βe + 1 = 0.25 (For environment 1) = 0.428 (For environment 2) = 0.964 (For environment 2)B.2	Graphical model for anti-causal CMNIST In Figure 4, we provide the graphical model forAC-CMNIST described in equation 10 (for G = 1).
Table 3: Comparison of ERM vs IRM: AC-CMNISTP(Ye	1,Ce=	1|Xge) =P(Ye	1,Ce=	1|Xge) = P(Ye = 1|Yge = 1)P(Ce =P(Ye	0, Ce =	1|Xge) =P(Ye	1,Ce=	1|Xge) = P(Ye = 0|Yge = 1)P(Ce =P(Ye	1|Xe)	3βe =P(Ye = 1|X e,Ce = 1) = —β— I	Ig,	7	2βe + 1P(Ye	1|Xe)	= 0.25 (For environment 1)P(Ye	1|Xe)	= 0.428 (For environment 2)P(Ye	1|Xe)	= 0.964 (For environment 2)1|N =0) = 0.75βe1|N = 1) = 0.25(1 - βe)(16)C.2 Graphical model for confounded CMNIST. In Figure 4, we provide the graphical model forconfounded CMNIST described in equation 10 (for G = 0).
Table 4: Comparison of ERM vs IRM: CF-CMNISTMethod	Number of samples	Test errorERM	1000	65.38 ± 0.56IRM	1000	66.98 ± 0.61ERM	5000	62.92 ± 0.99IRM	5000	61.09 ± 1.74ERM	10000	62.08 ± 1.19IRM	10000	51.46 ± 1.22ERM	30000	60.48 ± 0.42IRM	30000	34.96 ± 1.47ERM	60000	59.70 ± 0.72IRM	60000	32.80 ± 0.55Table 5: Comparison of ERM vs IRM: HB-CMNIST7.2.2	RegressionWe use the same structure for the generative model as described by Arjovsky et al. (2019). We workwith the four different variants on the same lines as CMNIST (covariate shift based, confounded,anti-causal, hybrid). The comparisons in Arjovsky et al. (2019) were for anti-causal and hybridmodels. The general model is written asHe 一 N(0,σ2ls)Xe 一 N(0,σ2ls)+ Wh→ιHe
Table 5: Comparison of ERM vs IRM: HB-CMNIST7.2.2	RegressionWe use the same structure for the generative model as described by Arjovsky et al. (2019). We workwith the four different variants on the same lines as CMNIST (covariate shift based, confounded,anti-causal, hybrid). The comparisons in Arjovsky et al. (2019) were for anti-causal and hybridmodels. The general model is written asHe 一 N(0,σ2ls)Xe 一 N(0,σ2ls)+ Wh→ιHeYe 一 We→yXe + N(0, σ2) + Wh→yHeXe 一 Wy→2Ye + N(0, Is) + Wh-2He(20)He is the hidden confounder, Xe = [X1e, X2e] is the observed covariate vector, Ye is the label. Dif-ferent W’s correspond to the weight vectors that multiply with the covariates and the confounders.
Table 6: Comparison of ERM vs IRM: n = 10 CS-regressionMethod	Number of samples	Model estimation errorERM	50	1.48 ± 0.15IRM	50	0.59 ± 0.10ERM	200	0.30 ± 0.03IRM	200	0.20 ± 0.03ERM	500	0.14 ± 0.01IRM	500	0.15 ± 0.02ERM	1000	0.10 ± 0.02IRM	1000	0.09 ± 0.01ERM	1500	0.07 ± 0.01IRM	1500	0.10 ± 0.01ERM	2000	0.07 ± 0.01IRM	2000	0.07 ± 0.01Table 7: Comparison of ERM vs IRM: n = 10 CF-regression7.3 Proofs for the PropositionsIn the results to follow, we will rely on Hoeffding’s inequality. We restate the inequality below forconvenience.
Table 7: Comparison of ERM vs IRM: n = 10 CF-regression7.3 Proofs for the PropositionsIn the results to follow, we will rely on Hoeffding’s inequality. We restate the inequality below forconvenience.
Table 8: Comparison of ERM vs IRM: n = 10 AC-regressionMethod	Number of samples	Model estimation errorERM	50	1.81 ± 0.19IRM	50	1.13 ± 0.18ERM	200	0.87 ± 0.09IRM	200	0.68 ± 0.10ERM	500	0.83 ± 0.09IRM	500	0.67 ± 0.07ERM	1000	0.76 ± 0.07IRM	1000	0.61 ± 0.05ERM	1500	0.77 ± 0.07IRM	1500	0.63 ± 0.05ERM	2000	0.74 ± 0.07IRM	2000	0.58 ± 0.05Table 9: Comparison of ERM vs IRM: n = 10 HB-regressionProposition 7. If' is square loss, andAssumptions 1,2 hold, then m ◦ Φ* solves the OOD problem(equation 1).
Table 9: Comparison of ERM vs IRM: n = 10 HB-regressionProposition 7. If' is square loss, andAssumptions 1,2 hold, then m ◦ Φ* solves the OOD problem(equation 1).
