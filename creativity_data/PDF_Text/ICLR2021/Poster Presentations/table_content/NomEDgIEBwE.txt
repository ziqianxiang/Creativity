Table 1: Test loss when linear regressionis used to predict α from z on CIFAR-10.
Table 2: Comparative best test accuracy of various self-supervized representation learning tech-niques, evaluated using linear classification.
Table 3: Results for representation learning on CIFAR-100 with MoCo v2 as the base contrastivelearning method, with gradient regularization in isolation and in combination with feature averaging.
Table 4: Hyperparameters used for CIFAR-10, CIFAR-100 and SpirographIn YIQ format, we can adjust hue of an image by θ = 2παhue by multiplying with a rotation matrix10	0Rθ =	0 cos θ - sin θ	(46)0 sin θ cos θTherefore, our hue adjustment is given byxhue = TRGB Rαhue TY IQ x	(47)where the matrices operate on the three colour channels of x and in parallel over all spatial dimen-sions. Each operation is followed by pointwise clipping of pixel values to the range [0, 1].
Table 5:	Hyperparameters for gradient penalty calculationParameterEvaluation modelEvaluation lossWeight decayOptimizationCIFAR-10Linear classificationCross entropy loss10-5L-BFGS 500 stepsSpirographLinear regressionMean squared error10-8L-BFGS 500 stepsTable 6:	Hyperparameters for model evaluationF.2.4 EvaluationWe use our representations as features in linear classification and regression tasks. We train theselinear models with L-BFGS with hyperparameters as shown in Table 6 on the training set and eval-
Table 6:	Hyperparameters for model evaluationF.2.4 EvaluationWe use our representations as features in linear classification and regression tasks. We train theselinear models with L-BFGS with hyperparameters as shown in Table 6 on the training set and eval-uate performance on the test set.
Table 7:	The test loss when a linear regression model is used to predict α from z on CIFAR-100.
Table 8:	Invariance metrics for Spirograph. We present the conditional variance, and the test losswhen a linear regression model is used to predict α from z. The reference value is Meani Var(αi).
Table 9: The raw values used to Produce Figure 3(c). Each of the downstream tasks is a generativeParameters. Values are the test mean square error ± 1 s.e. from 3 runs.
