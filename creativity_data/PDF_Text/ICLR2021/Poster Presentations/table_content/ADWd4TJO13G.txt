Table 1: Time complexity per epoch (of assimilation, where applicable) for n samples of d features,k components of d nodes, T tasks, and nm replay samples per task. Derivations in Appendix C.
Table 2: Average final performance across tasks using factored linear models—accuracy for FERAand Landmine (higher is better) and RMSE for Schools (lower is better). Standard errors after ±.
Table 3: Average final accuracy across tasks using soft layer ordering. Standard errors after ±.
Table 4: Average final accuracy across all tasks using soft gating. Standard errors after the ±.
Table 5: Average final accuracy across tasks on the Combined data set. Each column shows accuracyon the subset of tasks from each given data set, as labeled. Standard errors after ±.
Table D.1: Average final accuracy across tasks on the compositional Objects data set using soft layerordering. Column labels indicate which component was held out for final tasks. Std. errors after ±.
Table E.2: Data set details summary.
Table F.3: Number of learned components. Standard errors reported after the ±.
Table F.4: Number of tasks that reuse a component. A task reuses a component if its accuracy dropsby more than 5% relative when the component is dropped. Standard errors reported after the ±.
Table G.5: Average final accuracy across tasks on the Combined data set. Each column showsaccuracy on the subset of tasks from each given data set, as labeled. Standard errors after ±.
