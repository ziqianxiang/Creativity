Table 1: Flexibility. Top-1 image classifi-cation error rate with varying sub-bands onCIFAR-100. Mixing low-pass and high-passobtains the best result. Adding cu and cphelps improve the result.
Table 2: Effectiveness. Top-1 image clas-sification error rate with varying kernel sizeon CIFAR-100. Kernel size 5 achieves betterresult.
Table 3: Effectiveness. Top-1 image classi-fication error rate with various pooling meth-ods on CIFAR-100. LiftDownPool outper-forms baselines.
Table 4: Generalizability of LiftDownPool on ImageNet. LiftDownPool outperforms alternativepooling methods, no matter what ConvNet backbone is used. ? means the numbers are based onrunning the code provided by authors. Others are based on our re-implementation.
Table 5: Out-of-distribution robustness of LiftDownPool on ImageNet-C and ImageNet-P. Lift-DownPool is more robust to corruptions and perturbations compared to baselines.
Table 6: LiftUpPool for Semantic Segmentation on PASCAL-VOC12 based on SegNet with varying uP-	Table 7: Semantic Segmentation with	pooling methods.	DeepLabV3Plus on PASCAL-VOC12with various pooling methods. Lift-DownPool performs best.
