Table 1: GLUE Benchmark datasets used for evaluation.
Table 2: Few-shot learning test results on the GLUE benchmark where we have N=20,100,1000labeled examples for training. Reported results are the mean and the standard deviation of the testaccuracies of the top 3 models based on validation accuracy out of 10 random training set samples,along with p-values for each experiment.
Table 3: Results on the GLUE benchmark for robustness across noisy augmented training sets.
Table 4: Sample of augmented examples with different noise levels for the robustness experimentshown in Table 3. Higher temperature (T) corresponds to more noise in the augmented training set.
Table 5: Test results on the validation set of GLUE benchmark. We compare fine-tuning RoBERTa-Large with CE with and without SCL. Best hyperparameter configuration picked based on averagevalidation accuracy. We report average accuracy across 10 seeds for the model with best hyperparam-eter configuration, its standard deviation, and p-values.
Table 6: Ablation study on performance and training speed shown as average updates per second(Avg ups/sec) for fine-tuning RoBERTa-Base with respect to the batch size (Bsz).
Table 7: Generalization of the SST-2 task model (fine-tuned using the full training set) to relatedtasks (Amazon-2, Yelp-2) where there are 20 labeled examples for each class.
Table 8: Test results on the validation set of GLUE benchmark. We compare fine-tuning RoBERTa-Large with CE with and without SCL, CE+CE and the two-stage method of Khosla et al. (2020). Besthyperparameter configuration is picked based on the average validation accuracy. We report averageaccuracy across 10 seeds for the model with the best hyperparameter configuration, its standarddeviation, and p-values. CE+CE refers to the case where we replace SCL loss with the CE loss butkeep l2 normalization and temperature scaling.
Table 9: Ablation on performance and fine-tuning speed shown as average updates per second (Avgups/sec) for fine-tuning RoBERTa-Base with respect to the batch size (Bsz). CE+CE refers to thecase where we replace SCL loss with the CE loss but keep l2 normalization and temperature scaling.
Table 10: Few-shot learning test results on the GLUE benchmark where we have N=20,100,1000labeled examples for fine-tuning. Reported results are the mean and the standard deviation of thetest accuracies of the top 3 models based on the validation accuracy out of 10 random training setsamples, along with p-values for each experiment. CE+CE refers to the case where we replace SCLloss with the CE loss but keep l2 normalization and temperature scaling.
