Table 1: A comparison between one-class classifiers based on self-supervised learning. Previousworks [20, 21] train one-class classifiers using augmentation prediction with geometric transforma-tions (e.g. Lrot) and determine outliers using augmentation classifiers (pq). We learn representationsusing proxy tasks of different self-supervised learning methods, such as contrastive learning (Lclr),and build simple one-class classifiers, such as KDE or OC-SVM, on learned inlier representations.
Table 2: We report the mean and standard deviation of one-class classification AUCs averaged overclasses oVer 5 runs. The best methods are bold-faced for each setting. The per-class AUCs arereported in Appendix A.5. All methods are implemented and eValuated under the same condition.
Table 4: Image-level detection and pixel-level localization AUCs on MVTec anomaly detectiondataset [31]. We run experiments 5 times with different random seeds and report the mean andstandard deviations. We bold-face the best entry of each row and those within the standard deviation.
Table 5: One-class classification results using different one-class classifiers on rotation-augmentedcontrastive representations. In addition to OC-SVM and KDE, both of which with RBF kernels, wetest with the linear OC-SVM and the Gaussian density estimator (GDE).
Table 6: Performance of single and ensemble models of distribution augmented contrastive represen-tations on CIFAR-10. For each augmented distribution, we report the mean and standard deviationof single model performance (“single model”) and that of ensemble model whose ensemble score isaggregated from 5 models trained with different random seeds (“ensemble of 5 models”). “Ensembleof 5” aggregates score from 5 models with different augmentation distributions.
Table 7: One-class classification results using different representations and one-class classifiers. Wereport the mean and standard deViation oVer 5 runs of AUCs aVeraged oVer classes. The best methodsare bold-faced for each setting.
Table 8: Per-class one-class classification AUCs on CIFAR-10.
Table 9: Per-class one-class classification AUCs on CIFAR-20.
Table 10: Per-class one-class classification AUCs on Fashion MNIST.
Table 11: Per-class one-class classification AUCs on Cat-vs-Dog.
Table 12: Image-level detection and pixel-level localization AUC results on MVTec anomaly de-tection dataset. We run experiments 5 times with different random seeds and report the mean andstandard deviations. We bold-face the best entry of each row and those within the standard deviation.
