Table 1: Mean Average Precision (MAP) of alignment methods on a subset of XLING BLI with1K supervision dictionaries, retrieval method is nearest neighbors. Benchmark results obtainedfrom Glavas et al. (2019) in which (∣) PROC was evaluated without preprocessing and RCSLS wasevaluated with Centering + Length Normalization (C+L) preprocessing. Full results for XLING 1Kcan be found in Appendix Table 8.
Table 2: Mean Average Precision (MAP) of alignment methods on a subset of XLING BLI with 5Ksupervision dictionaries, retrieval method is nearest neighbors. Benchmark results obtained fromGlavas et al. (2019) in which (*) Proc-B was reported using a 3K seed dictionary, (∣) PROC wasevaluated without preprocessing and RCSLS was evaluated with (C+L) preprocessing. Full resultsfor XLING 5K can be found in Appendix Table 7.
Table 3: TED-CLDC micro-averaged F1 scores using a CNN model with embeddings from differentalignment methods. Evaluation follows Glavas et al. (2019), (*) signifies language pairs for whichunsupervised methods were unable to yield successful runs.
Table 4: MNLI test accuracy using an ESIM model with embeddings from different alignmentmethods. Evaluation follows Glavas et al. (2019), (*) signifies language pairs for which unsupervisedmethods were unable to yield successful runs.
Table 5: Average alignment time; sup. approaches use a 5Kdictionary. FIPP+SL augments with additional 10K samples.
Table 6: XLING 5K (EN-DE)MAP for Linear, RCSLS, andFIPP alignment methods on em-beddings of differing dimension-ality.
Table 7: Mean Average Precision (MAP) of alignment methods on XLING with 1K supervisiondictionaries, retrieval method is nearest neighbors. Benchmark results obtained from Glavas et al.
Table 8: Mean Average Precision (MAP) of alignment methods on XLING with 5K supervisiondictionaries, retrieval method is nearest neighbors. Benchmark results obtained from Glavas et al.
Table 9: Top 10 pairings by cosine similarity when using aSelf-Learning framework on the English-French languagepair.
Table 10: Smallest and Largest Deviations of FIPP from Orthogonal Solution, XLING BLI 1K and5K17Published as a conference paper at ICLR 2021D.2 Effect of Inner Product Filtering on Word-level AlignmentIn FIPP, Inner Product Filtering is used to find common geometric information by comparing pairwisedistances between a source and target language. To illustrate this step with translation word pairs, inthe Table below we show the 5 words with the largest and smallest fraction of zeros, i.e. the "leastand most filtered", in the binary filtering matrix ∆ during alignment between English (En) and Italian(It). The words which are least filtered tend to have an individual word sense, i.e. proper nouns, whilethose which are most filtered are somewhat ambiguous translations. For instance, while the Englishword "securing" can be translated to the Italian word "fissagio", depending on the context the Italianwords "garantire", "assicurare" or "fissare" may be more appropriate.
Table 11: Most and Least Filtered word pairs during FIPP’s Inner Product Filtering for English-ItalianalignmentD.3 Monolingual Task Performance of Aligned EmbeddingsAs FIPP does not perform an orthogonal trans-form, it modifies the inner products of word vec-tors in the source embedding which can impactperformance on monolingual task accuracy. Weevaluate the aligned embedding learned using∙-vFIPP, Xs , on monolingual word analogy tasksand compare these results to the original fastTextembeddings Xs . In Table 3, we compare mono-lingual English word analogy results for English∙-vembeddings Xs which have been aligned to aTurkish target embedding using FIPP. Evalua-tion of the aligned and original source embed-dings on multiple English word analogy experi-ments show that aligned FIPP embeddings retainperformance on monolingual analogy tasks.
Table 12: Monolingual Analogy Task Performancefor English embedding before/after alignment toTurkish embedding.
Table 13: FIPP Ablation study of Mean Average Precision(MAP) on XLING 1K and 5K BLI task.
Table 14: Mean Average Precision (MAP) of alignment methods on XLING with 1K supervisiondictionaries using either Iterative Normalization (IN) (Zhang et al., 2017) or Isotropic Preprocessing(IP).
Table 15: Mean Average Precision (MAP) of alignment methods on XLING with 5K supervisiondictionaries using either Iterative Normalization (IN) (Zhang et al., 2017) or Isotropic Preprocessing(IP).
Table 16: Mean Average Precision (MAP) of FIPP on XLING 5K and 1K supervision dictionariesusing with either weighted procrustes (WP) or procrustes (P) rotation.
Table 17: Mean Average Precision (MAP) of FIPP and Procrustes on XLING with 1K supervisiondictionaries using with either (CSLS) or Nearest Neighbors (P) retrieval criteria.
Table 18: Mean Average Precision (MAP) of FIPP and Procrustes on XLING with 5K supervisiondictionaries using with either (CSLS) or Nearest Neighbors (P) retrieval criteria.
