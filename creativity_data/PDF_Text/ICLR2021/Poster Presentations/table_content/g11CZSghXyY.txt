Table 1: BatchEnsemble with en-semble size 4 on ImageNet.
Table 2: Results for Wide ResNet-28-10 BatchEnsemble on in- and out-of-distribution CIFAR-10/100with various data augmentations, averaged over 3 seeds. AugMix: AugMix + BatchEnsemble;AugMixup: AugMix + Mixup BatchEnsemble; AugCAMixup: AugMix + CAMixup BatchEnsem-ble. Adding Mixup to AugMix model increases test accuracy and corrupt accuracy at the cost ofcalibration decay on testset. CAMixup bridges this gap with only a minor drop in accuracy.
Table 3: Hyperparameters we used in Section 3 regarding to BatchEnsemble. The difference betweenCIFAR-10 and CIFAR-100 is l2, random_sign_init and whether to use SyncEnsemble_BN.
Table 4: CIFAR-10 resUlts for Wide ResNet-28-10 BatchEnsemble (Wen et al., 2020) (BE), averagedover 5 seeds. This table is Used to sUPPlement Fig. 5.
Table 5: CIFAR-100 resUlts for Wide ResNet-28-10 BatchEnsemble (Wen et al., 2020) (BE), averagedover 5 seeds. This table is Used to sUPPlement Fig. 5.
Table 6: Mixup/AugMix/AugMixup/AugCAMixup on deep ensembles. We can conclude that Mixupworsens ensemble predictions in deep ensembles as well as in BatchEnsemble. This suggests we canuse CAMixup on deep ensembles as well. However, the improvement is not as obvious as it is onBatchEnsemble, leading to the fact that AugMix is the most calibrated (in- and out-of-distribution)data augmentation strategy on deep ensembles.
Table 7: Results for Wide ResNet-28-10 BatchEnsemble (Wen et al., 2020) and Deep Ensembles onCIFAR-10 and CIFAR-10-C, averaged over 3 seeds. This table is used to supplement Fig. 12Mixup on testset is even larger than what ECE reflects in Fig. 5. Table 7 demonstrates the specificnumbers used in Fig. 12.
