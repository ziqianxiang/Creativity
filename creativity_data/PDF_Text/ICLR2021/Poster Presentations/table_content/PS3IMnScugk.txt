Table 1: Results on the scan dataset. (a) Comparison of R&R with previous work. Connecting lines indicatethat model components are inherited from the parent (e.g. the row labeled recomb-2 also includes resampling).
Table 2: F1 score for morphological analysis on rare (FUT+PST) and frequent (OTHER) word forms. R&Rvariants with 1- and 2-prototype recombination (shaded in grey) consistently match or outperform both ano-augmentation baseline and GECA; recomb-1 + resampling is best overall. Bold numbers are not significantlydifferent from the best result in each column under a paired t-test (p < 0.05 after Bonferroni correction; nothingis bold if all differences are insignificant). The novel portion of the table shows model accuracy on exampleswhose exact tag set never appeared in the training data. (There were no such words in the test set for the SpanishOTHER.) Differences between GECA and the best R&R variant (recomb-1 + resampling) are larger than in thefull evaluation set. *The Spanish past tense was used as a development set.
Table 3: Exact Match Accuracy	Spanish			Swahili		Turkish		FUT+PST*	OTHER		fut+pst	OTHER	fut+pst	OTHERbaseline	0.078 ±0.029	0.63	±0.09	0.107 ±0.034	0.532 ±0.029	0.067 ±0.020	0.57 ±0.04geca	0.072 ±0.019	0.63	±0.05	0.039 ±0.011	0.496 ±0.027	0.052 ±0.014	0.54 ±0.08geca + resampling	0.16 ±0.04	0.65	±0.05	0.27 ±0.08	0.52 ±0.04	0.12 ±0.04	0.554 ±0.029learned aug	0.063 ±0.012	0.65	±0.04	0.066 ±0.034	0.52 ±0.04	0.074 ±0.021	0.57 ±0.04learned aug + resampling	0.098 ±0.021	0.65	±0.05	0.29 ±0.06	0.480 ±0.035	0.092 ±0.029	0.54 ±0.06recomb-1	0.063 ±0.017	0.674 ±0.021		0.061 ±0.017	0.520 ±0.028	0.055 ±0.021	0.554 ±0.030recomb-1 + resampling	0.13 ±0.04	0.64 ±0.04		0.29 ±0.04	0.48 ±0.04	0.15 ±0.04	0.52 ±0.06recomb-2	0.061 ±0.010	0.656 ±0.030		0.08 ±0.06	0.524 ±0.026	0.073 ±0.019	0.58 ±0.05recomb-2 + resampling	0.108 ±0.021	0.64 ±0.05		0.18 ±0.04	0.542 ±0.035	0.067 ±0.026	0.55 ±0.06Table 4: F1 Accuracy	Spanish		Swahili		Turkish		fut+pst∗	OTHER	fut+pst	OTHER	fut+pst	OTHERbaseline	0.609 ±0.025	0.873 ±0.034	0.746 ±0.013	0.897 ±0.005	0.561 ±0.032	0.867 ±0.015geca	0.606 ±0.019	0.871 ±0.017	0.722 ±0.018	0.884 ±0.007	0.565 ±0.034	0.856 ±0.028geca + resampling	0.675 ±0.017	0.870 ±0.022	0.802 ±0.023	0.892 ±0.010	0.65 ±0.05	0.850 ±0.019learned aug	0.597 ±0.021	0.871 ±0.024	0.737 ±0.010	0.897 ±0.011	0.58 ±0.04	0.853 ±0.026learned aug + resampling	0.646 ±0.007	0.872 ±0.028	0.826 ±0.013	0.887 ±0.010	0.637 ±0.032	0.835 ±0.034
Table 4: F1 Accuracy	Spanish		Swahili		Turkish		fut+pst∗	OTHER	fut+pst	OTHER	fut+pst	OTHERbaseline	0.609 ±0.025	0.873 ±0.034	0.746 ±0.013	0.897 ±0.005	0.561 ±0.032	0.867 ±0.015geca	0.606 ±0.019	0.871 ±0.017	0.722 ±0.018	0.884 ±0.007	0.565 ±0.034	0.856 ±0.028geca + resampling	0.675 ±0.017	0.870 ±0.022	0.802 ±0.023	0.892 ±0.010	0.65 ±0.05	0.850 ±0.019learned aug	0.597 ±0.021	0.871 ±0.024	0.737 ±0.010	0.897 ±0.011	0.58 ±0.04	0.853 ±0.026learned aug + resampling	0.646 ±0.007	0.872 ±0.028	0.826 ±0.013	0.887 ±0.010	0.637 ±0.032	0.835 ±0.034recomb-1	0.596 ±0.020	0.884 ±0.010	0.727 ±0.012	0.893 ±0.010	0.557 ±0.032	0.868 ±0.010recomb-1 + resampling	0.663 ±0.029	0.874 ±0.014	0.812 ±0.017	0.886 ±0.011	0.67 ±0.04	0.84 ±0.04recomb-2	0.598 ±0.019	0.874 ±0.007	0.730 ±0.023	0.894 ±0.008	0.581 ±0.035	0.865 ±0.024recomb-2 + resampling	0.658 ±0.012	0.872 ±0.015	0.778 ±0.011	0.897 ±0.007	0.609 ±0.032	0.850 ±0.029G.1.2 hints=8Main 8-prototype F1 results are provided in the body of the paper. Here we provide exact matchresults and an extra set of comparisons to the VAE model.
Table 5: Exact Match Accuracy	Spanish		Swahili		Turkish		FUT+PST*	OTHER	fut+pst	OTHER	fut+pst	OTHERbaseline	0.151 ±0.017	0.65 ±0.04	0.15 ±0.04	0.554 ±0.034	0.23 ±0.06	0.55 ±0.04geca	0.136 ±0.030	0.638 ±0.026	0.15 ±0.05	0.55 ±0.06	0.21 ±0.05	0.550 ±0.032geca + resampling	0.249 ±0.034	0.64 ±0.04	0.25 ±0.05	0.532 ±0.033	0.27 ±0.07	0.524 ±0.026learned aug	0.163 ±0.030	0.652 ±0.033	0.18 ±0.05	0.560 ±0.026	0.23 ±0.04	0.548 ±0.019learned aug + resampling	0.181 ±0.026	0.590 ±0.032	0.34 ±0.06	0.552 ±0.029	0.24 ±0.04	0.53 ±0.05recomb-1	0.155 ±0.018	0.628 ±0.020	0.161 ±0.017	0.560 ±0.025	0.22 ±0.04	0.538 ±0.025recomb-1 + resampling	0.218 ±0.032	0.616 ±0.034	0.35 ±0.04	0.53 ±0.04	0.30 ±0.04	0.52 ±0.04recomb-2	0.131 ±0.028	0.634 ±0.027	0.19 ±0.11	0.56 ±0.04	0.24 ±0.05	0.528 ±0.032recomb-2 + resampling	0.203 ±0.035	0.63 ±0.05	0.27 ±0.07	0.552 ±0.031	0.25 ±0.05	0.54 ±0.06Table 6: F1 Accuracy (VAE model)	Spanish		Swahili		Turkish		fut+pst∗	OTHER	fut+pst	OTHER	fut+pst	OTHERlearned aug + resampling +vae	0.689 ±0.018	0.859 ±0.010	0.845 ±0.014	0.896 ±0.011	0.730 ±0.032	0.850 ±0.015recomb-1 + resampling +vae	0.717 ±0.014	0.870 ±0.007	0.843 ±0.014	0.898 ±0.010	0.736 ±0.030	0.859 ±0.031recomb-2 + resampling +vae	0.710 ±0.008	0.865 ±0.012	0.824 ±0.015	0.896 ±0.011	0.751 ±0.027	0.848 ±0.027G.1.3 hints= 1 6Table 7: Exact Match Accuracy
Table 6: F1 Accuracy (VAE model)	Spanish		Swahili		Turkish		fut+pst∗	OTHER	fut+pst	OTHER	fut+pst	OTHERlearned aug + resampling +vae	0.689 ±0.018	0.859 ±0.010	0.845 ±0.014	0.896 ±0.011	0.730 ±0.032	0.850 ±0.015recomb-1 + resampling +vae	0.717 ±0.014	0.870 ±0.007	0.843 ±0.014	0.898 ±0.010	0.736 ±0.030	0.859 ±0.031recomb-2 + resampling +vae	0.710 ±0.008	0.865 ±0.012	0.824 ±0.015	0.896 ±0.011	0.751 ±0.027	0.848 ±0.027G.1.3 hints= 1 6Table 7: Exact Match Accuracy	Spanish		Swahili		Turkish		FUT+PST*	OTHER	FUT+PST	OTHER	FUT+PST	OTHERbaseline	0.27 ±0.05	0.65 ±0.04	0.28 ±0.06	0.544 ±0.029	0.40 ±0.04	0.614 ±0.032geca	0.26 ±0.06	0.65 ±0.06	0.26 ±0.05	0.530 ±0.028	0.37 ±0.05	0.570 ±0.035geca + resampling	0.34 ±0.05	0.63 ±0.04	0.32 ±0.07	0.506 ±0.034	0.42 ±0.05	0.590 ±0.035learned aug	0.25 ±0.04	0.65 ±0.04	0.32 ±0.06	0.538 ±0.028	0.39 ±0.04	0.58 ±0.05learned aug + resampling	0.230 ±0.035	0.61 ±0.04	0.42 ±0.06	0.54 ±0.04	0.42 ±0.05	0.578 ±0.027recomb-1	0.27 ±0.05	0.63 ±0.06	0.32 ±0.05	0.55 ±0.04	0.35 ±0.06	0.60 ±0.05recomb-1 + resampling	0.28 ±0.04	0.61 ±0.07	0.418 ±0.035	0.548 ±0.023	0.35 ±0.06	0.56 ±0.04recomb-2	0.22 ±0.06	0.62 ±0.07	0.28 ±0.04	0.56 ±0.04	0.40 ±0.06	0.596 ±0.024recomb-2 + resampling	0.262 ±0.025	0.61 ±0.07	0.405 ±0.028	0.53 ±0.04	0.43 ±0.06	0.61 ±0.04Table 8: F1 Accuracy
Table 7: Exact Match Accuracy	Spanish		Swahili		Turkish		FUT+PST*	OTHER	FUT+PST	OTHER	FUT+PST	OTHERbaseline	0.27 ±0.05	0.65 ±0.04	0.28 ±0.06	0.544 ±0.029	0.40 ±0.04	0.614 ±0.032geca	0.26 ±0.06	0.65 ±0.06	0.26 ±0.05	0.530 ±0.028	0.37 ±0.05	0.570 ±0.035geca + resampling	0.34 ±0.05	0.63 ±0.04	0.32 ±0.07	0.506 ±0.034	0.42 ±0.05	0.590 ±0.035learned aug	0.25 ±0.04	0.65 ±0.04	0.32 ±0.06	0.538 ±0.028	0.39 ±0.04	0.58 ±0.05learned aug + resampling	0.230 ±0.035	0.61 ±0.04	0.42 ±0.06	0.54 ±0.04	0.42 ±0.05	0.578 ±0.027recomb-1	0.27 ±0.05	0.63 ±0.06	0.32 ±0.05	0.55 ±0.04	0.35 ±0.06	0.60 ±0.05recomb-1 + resampling	0.28 ±0.04	0.61 ±0.07	0.418 ±0.035	0.548 ±0.023	0.35 ±0.06	0.56 ±0.04recomb-2	0.22 ±0.06	0.62 ±0.07	0.28 ±0.04	0.56 ±0.04	0.40 ±0.06	0.596 ±0.024recomb-2 + resampling	0.262 ±0.025	0.61 ±0.07	0.405 ±0.028	0.53 ±0.04	0.43 ±0.06	0.61 ±0.04Table 8: F1 Accuracy	Spanish		Swahili		Turkish		fut+pst∗	OTHER	fut+pst	OTHER	fut+pst	OTHERbaseline	0.733 ±0.014	0.881 ±0.012	0.811 ±0.018	0.893 ±0.011	0.750 ±0.026	0.875 ±0.021geca	0.736 ±0.019	0.884 ±0.018	0.800 ±0.024	0.889 ±0.012	0.74 ±0.04	0.863 ±0.019geca + resampling	0.782 ±0.024	0.867 ±0.012	0.830 ±0.021	0.885 ±0.013	0.794 ±0.032	0.865 ±0.018learned aug	0.738 ±0.020	0.877 ±0.008	0.816 ±0.024	0.893 ±0.012	0.752 ±0.024	0.868 ±0.020learned aug + resampling	0.745 ±0.019	0.870 ±0.012	0.866 ±0.016	0.894 ±0.013	0.787 ±0.031	0.863 ±0.021
Table 8: F1 Accuracy	Spanish		Swahili		Turkish		fut+pst∗	OTHER	fut+pst	OTHER	fut+pst	OTHERbaseline	0.733 ±0.014	0.881 ±0.012	0.811 ±0.018	0.893 ±0.011	0.750 ±0.026	0.875 ±0.021geca	0.736 ±0.019	0.884 ±0.018	0.800 ±0.024	0.889 ±0.012	0.74 ±0.04	0.863 ±0.019geca + resampling	0.782 ±0.024	0.867 ±0.012	0.830 ±0.021	0.885 ±0.013	0.794 ±0.032	0.865 ±0.018learned aug	0.738 ±0.020	0.877 ±0.008	0.816 ±0.024	0.893 ±0.012	0.752 ±0.024	0.868 ±0.020learned aug + resampling	0.745 ±0.019	0.870 ±0.012	0.866 ±0.016	0.894 ±0.013	0.787 ±0.031	0.863 ±0.021recomb-1	0.738 ±0.021	0.877 ±0.019	0.820 ±0.018	0.896 ±0.014	0.735 ±0.033	0.874 ±0.026recomb-1 + resampling	0.770 ±0.020	0.867 ±0.023	0.872 ±0.005	0.892 ±0.010	0.778 ±0.024	0.861 ±0.022recomb-2	0.716 ±0.019	0.876 ±0.022	0.815 ±0.017	0.897 ±0.016	0.752 ±0.034	0.873 ±0.017recomb-2 + resampling	0.765 ±0.023	0.868 ±0.021	0.856 ±0.015	0.888 ±0.016	0.808 ±0.018	0.868 ±0.027G.2 Significance TestsTables 9, 10 and 11 sho the p-values for pairwise differences between the baseline and prototype-basedmodelsTable 9:	Turkish language p-values for paired t-test in PST+FUT tenses for the average F1 (micro) scores overseveral runs without Bonferronni correction.
Table 9:	Turkish language p-values for paired t-test in PST+FUT tenses for the average F1 (micro) scores overseveral runs without Bonferronni correction.
Table 10:	Spanish language p-values for paired t-test in PST+FUT tenses for the average F1 (micro) scores overseveral runs without Bonferronni correction.
Table 11:	Swahili language p-values for paired t-test in PST+FUT tenses for the average F1 (micro) scores overseveral runs without Bonferronni correction.
Table 12:	Comparison of generative and unconditional model predictions with and without data augmentation.
