Table 1: The relevance metrics and their evaluation results. For the model randomization test, theresults that passed the test are colored. For the identical class test and identical subclass test, theresults with the five highest average evaluation scores are colored. The details of the relevancemetrics, the evaluation criteria, and the evaluation procedures can be found in Sections 1.2, 3, and 4,respectively.
Table 2: Average Spearman rank correlation coefficients ± std. of each similarity function for modelrandomization test. The metrics prefixed with ♦ are the ones we have repaired. The results with theaverage score in the 95% confidence interval of the null distribution that the correlation is zero, whichis [-0.088, 0.088], are colored.
Table 3: Average success rate ± std. of each relevancy metric for identical class test. The metricsprefixed with ♦ are the ones we have repaired. The results with the average success rate over 0.5 arecolored.
Table 4: Average success rate ± std. of each relevancy metric for identical subclass test. The metricsprefixed with ♦ are the ones we have repaired. The results with the average success rate over 0.5 arecolored.
Table 5: Average success rate ± std. of each relevancy metric for top-10 identical class test. Themetrics prefixed with ♦ are the ones we have repaired. The results with the average success rate over0.5 are colored.
Table 6: Average success rate ± std. of each relevancy metric for top-10 identical subclass test. Themetrics prefixed with ♦ are the ones we have repaired. The results with the average success rate over0.5 are colored.
Table 7: Relevant instances selected for random test inputs with correct predictions using severalrelevance metrics on AGNews with LSTM. Out-of-vocabulary words are followed by [unk].
Table 8: Relevant instances selected for random test inputs with incorrect predictions using severalrelevance metrics on AGNews with LSTM. Out-of-vocabulary words are followed by [unk].
