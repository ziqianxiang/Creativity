Table 1: Performance evaluation of various approaches for IF games in Jericho (Hausknecht et al.,2020). Handicaps leveraged in each algorithm are described in the table. Valid Action indicateswhether an algorithm uses a valid action handicap provided by Jericho as a hard constraint for theeffective action space or as a soft constraint via entropy loss over the valid actions (Ammanabrolu& Hausknecht, 2020). Resettable indicates whether an algorithm requires a resettable simulator, i.e.
Table 2: Experimental results of the policy improvement with PUCT and MC-LAVE on Zork1.
Table 3: Illustrative examples of search results of PUCT and MC-LAVE on bottleneck state inZork1 (See Figure 1). Q(h, a) denotes the average of Monte-Carlo returns, ∏θ(a|o) representspolicy prior, N(h, a) represents visit count of each action, Lφ(a) represents language-driven explo-ration bonus of MC-LAVE. cPUCT = 200 and cLAVE = 0.1 are used for the exploration constants.
Table 4: Configurations of MC-LAVE-RL used in our experimental results. Hyperparameters inthe upside of the table were globally adapted in the planning-learning framework and the otherhyperparameters are used only in the MCTS planning phase.
Table 5: Experimental results comparing soft and hard constraints of valid action handicap. KG-A2C (Soft/Hard) indicates the use of valid action handicap as a (soft constraint via entropy loss overthe valid actions/hard constraint for the effective action space). All results indicate averages andstandard errors over 5 independent runs.
Table 6: An illustrative example of search results of MC-LAVE on bottleneck state in Zork1 (seeFigure 1) with modifying the action ‘take lantern’ to ‘get lantern’. The above result withthe action ‘take lantern’ is the same as in Table 3. Q(h, a) denotes the average of Monte-Carlo returns, ∏θ(a|o) represents policy prior, N(h, a) represents visit count of each action, Lφ(a)represents language-driven exploration bonus of MC-LAVE. Note that some differences in Q(h, a)and N(h, a) between results are due to two independent simulation runs.
