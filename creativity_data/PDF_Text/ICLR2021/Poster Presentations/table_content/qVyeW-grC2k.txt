Table 1: Experimental results on Long-Range Arena benchmark. Best model is in boldface and sec-ond best is underlined. All models do not learn anything on Path-X task, contrary to the Pathfindertask and this is denoted by FAIL. This shows that increasing the sequence length can cause seriouslydifficulties for model training. We leave Path-X on this benchmark for future challengers but donot include it on the Average score as it has no impact on relative performance. Important: Theseresults always represent the results at the time of ICLR submission and are not modified forarchival purposes. Please see appendix in arxiv version of this paper for updated snapshots ornew runs of this leaderboard with new settings and use that for paper comparisons.
Table 2: Benchmark results of all Xformer models with a consistent batch size of 32 across allmodels. We report relative speed increase/decrease in comparison with the vanilla Transformer inbrackets besides the steps per second. Memory usage refers to per device memory usage acrosseach TPU device. Benchmarks are run on 4x4 TPU V3 Chips. We report inference speeds in thesupplementary material.
Table 3: Test and train accuracy of different models on Image Classification task.
Table 4: Speed (Steps per second) on running inference. Benchmarked on 4x4 TPU V3 chips witha batch size of 32 (1 example per core). Results are computed on Xformers with 4 layers, 8 heads,128 hidden size. Similar to training, we include realistic evaluation time which includes pipelineops, and batching into the overall time.
Table 5: Number of training steps to reach N% validation accuracy where N = {30, 35}.
Table 6: Experimental results on Long-Range Arena benchmark. Best model is in boldface and sec-ond best is underlined. All models do not learn anything on Path-X task, contrary to the Pathfindertask and this is denoted by FAIL. This shows that increasing the sequence length can cause seriouslydifficulties for model training. We leave Path-X on this benchmark for future challengers but do notinclude it on the Average score as it has no impact on relative performance.
Table 7: Experimental results on Long-Range Arena benchmark. Best model is in boldface and sec-ond best is underlined. All models do not learn anything on Path-X task, contrary to the Pathfindertask and this is denoted by FAIL. This shows that increasing the sequence length can cause seriouslydifficulties for model training. We leave Path-X on this benchmark for future challengers but do notinclude it on the Average score as it has no impact on relative performance.
