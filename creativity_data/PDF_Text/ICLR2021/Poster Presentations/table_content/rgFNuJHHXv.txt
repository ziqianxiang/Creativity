Table 1: A summary of the datasets considered in this paper. The right-most column indicateswhether the dataset has a preferred pose.
Table 2: Min. & mean FreChet distances (lower is better) of generated ROtMNIST samples, evalu-ated at every 1K generator iterations. All evaluations are visualized in Appendix A Figure 6.
Table 3: FID evaluation (lower is better) of all real-world datasets across ablations andaugmentation-based baseline comparisons. - indicates an inapplicable setting for the method.
Table 4: Kernel Inception Distance results for Map2Sat translation on the Maps dataset. Lower isbetter.	_________________________________________________________________Setting	KIDPix2Pix (Isolaetal., 2017)	0.1584 ± 0.0026Pix2Pix (Isola et al., 2017) (optimized)	0.0663 ± 0.0038CNN in G, G-CNN in D	0.0333 ± 0.0005G-CNN in G and D	0.0399 ± 0.0024B	Image-to-Image TranslationTo show the generic utility of equivariance in generative adversarial network tasks, we present apilot study employing p4-equivariance in supervised image-to-image translation to learn mappingsbetween visual domains. Using the popular Pix2Pix model of Isola et al. (2017) as a baseline,we replace both networks with p4-equivariant models. For completeness, we also evaluate whetheremploying p4-equivariance in just the discriminator achieves comparable results to modifying bothnetworks, as in the natural image datasets in the main text.
Table 5:	Architectures used for the standard generator and discriminator in the Rotated MNISTexperiments.
Table 6:	Architectures used for the p4-equivariant generator and discriminator in the Rotated MNISTexperiments.
Table 7:	Architectures used for the standard generator and discriminator in the ANHIR experiments.
Table 8:	Architectures used for the p4m-equivariant generator and discriminator in the ANHIRexperiments.
Table 9: Architectures used for the standard generator and discriminator in the LYSTO experiments.
Table 10: Architectures used for the p4m-equivariant generator and discriminator in the LYSTOexperiments.
Table 11:	Architectures used for the standard generator and discriminator in the CIFAR-10 experi-ments.
Table 12:	Architectures used for the p4-equivariant generator and discriminator in the CIFAR-10experiments.
Table 13:	Architectures used for the standard generator and discriminator in the Food-101 experi-ments.
Table 14: Architectures used for the p4-equivariant generator and discriminator in the Food-101experiments.
Table 15: Architectures used for the standard generator and discriminator in the Pix2Pix experi-ments. Each DownBlock consists of a 3 × 3 ConVolution, 2× AVerage Pool, Batch Normalization,and Leaky ReLU actiVation. Each UpBlock consists of 2× nearest-neighbors upsampling, 3 × 3ConVolution, Batch Normalization, and Leaky ReLU actiVation.
Table 16: Architectures used for the p4-equivariant generator and discriminator in the Pix2Pix exper-iments. Each DownBlock consists of a 3 × 3 p4-convolution, 2× Average Pool, p4-Batch Normal-ization, and Leaky ReLU activation. Each UpBlock consists of 2× nearest-neighbors upsampling,3 × 3 p4-Convolution, p4-Batch Normalization, and Leaky ReLU activation.
