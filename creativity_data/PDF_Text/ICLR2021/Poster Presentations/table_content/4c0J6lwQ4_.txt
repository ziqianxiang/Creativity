Table 1: Interpolation performance versus percent observed time points on PhysioNetModel	Mean Squared Error (×10-3)RNN-VAE	13.418 ± 0.008	12.594 ± 0.004	11.887 ± 0.005	11.133 ± 0.007	11.470 ± 0.006L-ODE-RNN	8.132 ± 0.020	8.140 ± 0.018	8.171 ± 0.030	8.143 ± 0.025	8.402 ± 0.022L-ODE-ODE	6.721 ± 0.109	6.816 ± 0.045	6.798 ± 0.143	6.850 ± 0.066	7.142 ± 0.066mTAND-Full	4.139 ± 0.029	4.018 ± 0.048	4.157 ± 0.053	4.410 ± 0.149	4.798 ± 0.036Observed %	50%	60%	70%	80%	90%sampling. We also compare to several encoder-decoder approaches. The full list of model variants isbriefly described below. We use a Gated Recurrent Unit (GRU) (Chung et al., 2014) module as therecurrent network throughout. Architecture details can be found in Appendix A.3.
Table 2: Classification Performance on PhysioNet, MIMIC-III and Human Activity datasetModel	AUC Score		Accuracy	time per epoch	PhysioNet	MIMIC-III	Human Activity	RNN-Impute	0.764 ± 0.016	0.8249 ± 0.0010	0.859 ± 0.004	0.5RNN-∆t	0.787 ± 0.014	0.8364 ± 0.0011	0.857 ± 0.002	0.5RNN-Decay	0.807 ± 0.003	0.8392 ± 0.0012	0.860 ± 0.005	0.7RNN GRU-D	0.818 ± 0.008	0.8270 ± 0.0010	0.862 ± 0.005	0.7Phased-LSTM	0.836 ± 0.003	0.8429 ± 0.0035	0.855 ± 0.005	0.3IP-Nets	0.819 ± 0.006	0.8390 ± 0.0011	0.869 ± 0.007	1.3SeFT	0.795 ± 0.015	0.8485 ± 0.0022	0.815 ± 0.002	0.5RNN-VAE	0.515 ± 0.040	0.5175 ± 0.0312	0.343 ± 0.040	2.0ODE-RNN	0.833 ± 0.009	0.8561 ± 0.0051	0.885 ± 0.008	16.5L-ODE-RNN	0.781 ± 0.018	0.7734 ± 0.0030	0.838 ± 0.004	6.7L-ODE-ODE	0.829 ± 0.004	0.8559 ± 0.0041	0.870 ± 0.028	22.0mTAND-Enc	0.854 ± 0.001	0.8419 ± 0.0017	0.907 ± 0.002	0.1mTAND-Full	0.858 ± 0.004	0.8544 ± 0.0024	0.910 ± 0.002	0.2mean AUC than mTAND-Full, the differences are not statistically significant. Further, as shown onthe PhysioNet classification problem, mTAND-Full is more than an order of magnitude faster thanthe ODE-based methods.
Table 3: Ablation with time embeddingDataset	Time Embedding	AUC ScorePhysioNet	Positional Encoding Learned Time Embedding	0.845 ± 0.004 0.858 ± 0.004MIMIC-III	Positional Encoding Learned Time Embedding	0.843 ± 0.001 0.854 ± 0.002Since mTANs are fundamentally continuous-time interpolation-based models, we perform an ablationstudy by comparing mTANs with the IP-nets (Shukla & Marlin, 2019). IP-Nets use several semi-parametric RBF interpolation layers, followed by a GRU to model irregularly sampled time series. Inthis framework, we replace the RBK kernel with a learnable similarity kernel using mTAND module,the corresponding model is mTAND-Enc. Table 4 compares the performance of the two methods onclassification task on PhysioNet, MIMIC-III and Human Activity dataset. We report the average AUCscore over 5 runs. Table 4 shows that learning the similarity kernel using mTAND module performsas well or better than using a fixed RBF kernel.
Table 4: Comparing interpolation kernelsDataset	Model	AUC ScorePhysioNet	IP-Nets mTAND-Enc	0.819 ± 0.006 0.854 ± 0.001MIMIC-III	IP-Nets mTAND-Enc	0.839 ± 0.001 0.842 ± 0.001Human Activity	IP-Nets mTAND-Enc	0.869 ± 0.007 0.907 ± 0.002A.2 Synthetic Interpolation ExperimentsTo demonstrate the capabilities of our model on the interpolation task, we generate a synthetic datasetconsisting of 1000 trajectories each of 100 time points sampled over t ∈ [0, 1]. We fix 10 referencepoints and use RBF kernel with a fixed bandwidth of 100 for constructing local interpolations at100 time points over [0, 1]. The values at the reference points are drawn from a standard normaldistribution.
Table 5: Synthetic Data: Mean Squared ErrorLatent Dimension	Model	Reconstruction	Interpolation	L-ODE-ODE	0.0209	0.057110	mTAND-Full	0.0088	0.0409	L-ODE-ODE	0.0191	0.054120	mTAND-Full	0.0028	0.0335Table 5 compares the proposed model with best performing baseline Latent-ODE with ODE encoder(L-ODE-ODE) on reconstruction and interpolation task. For both the tasks, we condition on the 20irregularly sampled time points and reconstruct the input points (reconstruction) and the whole set of100 time points (interpolation). We report the mean squared error on test set.
