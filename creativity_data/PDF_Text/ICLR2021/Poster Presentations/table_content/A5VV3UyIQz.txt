Table 1: Mean AUC (over all classes and 5 seeds per class) for Fashion-MNIST, CIFAR-10, andImageNet. Results from existing literature are marked with an asterisk (Bergman and Hoshen, 2020;Golan and El-Yaniv, 2018; Hendrycks et al., 2019b; Ruff et al., 2020a).
Table 2: Pixel-wise mean AUC scores for all classes of the MVTec-AD dataset (Bergmann et al.,2019). For competitors we include the baselines presented in the original MVTec-AD paper andpreviously published works from peer-reviewed venues that include the MVTec-AD benchmark. Thecompetitors are Self-Similarity and L2 Autoencoder (Bergmann et al., 2019), AnoGAN (Schleglet al., 2017; Bergmann et al., 2019), CNN Feature Dictionaries (Napoletano et al., 2018; Bergmannet al., 2019), Visually Explained Variational Autoencoder (Liu et al., 2020), Superpixel Masking andInpainting (Li et al., 2020), Gradient Descent Reconstruction with VAEs (Dehaene et al., 2020), andEncoding Structure-Texture Relation with P-Net for AD (Zhou et al., 2020).
Table 3: Mean AUC (over all classes and 5 seeds per class) for CIFAR-10 and neural networks withvarying receptive field size.
Table 4: Pixel-wise mean AUC (over all classes and 5 seeds per class) for MVTec-AD and neuralnetworks with varying receptive field size.
Table 5: Pixel-wise mean AUC (over all classes and 5 seeds per class) for MVTec-AD and differentÏƒ.
Table 6: AUC scores for all classes of Fashion-MNIST (Xiao et al., 2017).
Table 7: AUC scores for all classes of CIFAR-10 (Krizhevsky et al., 2009).
Table 8: AUC scores for 30 classes of ImageNet (Deng et al., 2009).
