Table 1: The robust accuracy of ResNets and CapsNets are shown under popular attacks on CIFAR10and SVHN datasets. Vote-Attack is much more effective than Caps-Attack and compatible withdifferent underlying attacks.
Table 2: The robustness of CapsNets with different training schemes on CIFAR10 and SVHNdatasets: Vote-Attack is also effective to attack models with adversarial training; It can also beapplied to improve adversarial training.
Table 3: The averaged time required by each attack to create an adversarial example is reported onCIFAR10 test dataset. Vote-Attack requiring less time is more efficient than Caps-Attacks.
Table 4: Different attacks are applied to circumvent the class-conditional reconstruction adversarialdetection method on FMNIST dataset. The attack success rate and undetected rate (S/R) are re-ported for each attack. The integration of Vote-Attack in the detection-aware attack increases boththe attack success rate and the undetected rate significantly.
Table 5: The `0, `1, and `2 norms of perturbations created by different attacks are shown on CI-FAR10 dataset. Overall, the perturbations created by our Vote-Attack have similar norms to theones by Caps-Attack.
Table 6: The `0, `1, and `2 norms of perturbations created by different attacks are shown on SVHNdataset. In 'âˆž -attack methods, the perturbations created by our Vote-Attack have similar norms tothe ones by Caps-Attack. In `2 -attack methods, our Vote-attack can find smaller perturbations tofool the underlying classifier.
Table 7: The targeted attack success rates (%) are shown on CIFAR10 and SVHN datasets. Inthe targeted attack setting, our Vote-Attack is significantly more effective than Caps-Attack whencombined with popular attacks.
Table 8: The transferability of adversarial examples created on CNNs and CapsNets on CIFAR10dataset: the ones created on CNNs are more transferable than on CapsNets; the ones created withVote-Attack are more transferable than the ones with Caps-Attack.
Table 9: When inPutS are affine-tranSformed in CIFAR10 dataSet, the Vote-Attack iS Still moreeffective to create adverSarial examPleS than CaPS-Attack.
Table 10: The test accuracy on the dataset with untransformed images and the one on the datasetwith transformed images are reported (in %). CapsNet achieves better transformtation robustnessthan the original CNN baseline. The robust accuracy of different models are also reported underdifferent attacks. We can observe that it is more effective to attack Votes instead of output capsulesin CapsNet.
Table 11: Different attacks are applied to circumvent the class-conditional reconstruction adversarialdetection method. The attack success rate and undetected rate (S/R) are reported for each attack. Onall the three popular datasets, the integration of Vote-Attack in the detection-aware attack increasesboth the attack success rate and the undetected rate significantly.
