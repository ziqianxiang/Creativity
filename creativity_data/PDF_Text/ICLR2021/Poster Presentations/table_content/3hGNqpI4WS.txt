Table 1: Comparison of BREMEN to the existing offline methods on static datasets. Each cell shows the averagecumulative reward and their standard deviation, where the number of samples is 1M, 100K, and 50K, respectively.
Table 2: Evaluation on D4RL MuJoCo locomotion datasets. The normalized score of BREMEN are averagedover 4 random seeds. We refer the score of MOPO (Yu et al., 2020) and CQL (Kumar et al., 2020) from theiroriginal papers. Other results are cited from Fu et al. (2020). BREMEN achieves the best and competitive scorein several domains, while none of the algorithms beats all other methods.
Table 3: Reward function and termination in rollouts in the experiments. We remove all contact informationfrom observation of Ant, basically following Wang et al. (2019).
Table 4: Hyper-parameters of BREMEN in deployment-efficient settings.
Table 5: Hyper-parameters of BCQ.
Table 6: Hyper-parameters of BRAC.
Table 7: Comparison of BREMEN to the existing offline methods in offline settings, namely, BC, BCQ (Fujimotoet al., 2019), and BRAC (Wu et al., 2019). Each cell shows the average cumulative reward and their standarddeviation with 5 seeds. The maximum steps per episode is 1,000. Five different types of exploration noise areintroduced during the data collection, eps1, eps3, gaussian1, gaussian3, and random. BRAC applies a primalform of KL value penalty, and BRAC (max Q) means sampling multiple actions and taking the maximumaccording to the learned Q function.
