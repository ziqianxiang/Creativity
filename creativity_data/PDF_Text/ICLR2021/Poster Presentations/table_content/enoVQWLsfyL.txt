Table 1: Our learned views (Ours) enable comparable transfer performance to expert views(Expt) on CIFAR-10. Suite of transfer tasks using pretrained representations from CIFAR-10 forboth the SimCLR and InstDisc pretraining setups. Numbers are percent accuracy with the exceptionof CelebA which is F1. FaMNIST stands for FashionMNIST.
Table 2: Our learned views significantly outperform existing views for speech transfer tasks.
Table 3: Our learned views significantly outperform existing views for activity recognition onwearable sensor data. Our method learns superior representations across a large range of distortionbudgets e, although budgets that are too strong prevent learning. Linear evaluation accuracy forResNet18 models trained on Pamap2 with SimCLR. “Spectral” refers to view functions applieddirectly to the spectrogram (Park et al., 2019).
Table 4: Our method enables superior results in a semi-supervised setting where labels fordata from only one participant are available. Validation accuracy for activity recognition onPamap2. Supervised Learning refers to training a randomly initialized model on the labeled datauntil convergence. Pretrain & Transfer refers to training a linear classifier off of the best pretrainedmodel above. 1 or 7 Participants refers to the number of participants comprising the training set.
