Table 1: Summary statistics of datasets and model performance. For the accuracy of our best C&Smodel compared to the state-of-the-art GNN method (see text), we report the change in the numberof parameters and the accuracy. We also list the training time with time to compute the spectral em-bedding in parentheses (even if not used in the best model). Our methods require fewer parameters,are typically more accurate, and are fast to train. Also see Tables 2 and 3.
Table 2: Performance of our C&S framework, using only the training labels as ground truth in finalprediction smoothing (Equation (4)). Further improvements can be made by including ground truthvalidation labels (Table 3). The Email dataset has no raw node features, so some methods are notevaluated. APPNP ran out of memory (OOM) on the products dataset.
Table 3: Performance of C&S, using both training and validation labels as ground truth in the finalprediction smoothing (cf. Equation (4), Table 2).
Table 4: C&S with GNN base predictions.
Table 5: Performance of our C&S framework with and without the final prediction smoothing. Incases where final prediction smoothing is used, only ground truth training are used.
Table 6: Comparison of models with and without spectral embeddings, using only ground truthtraining labels for final prediction smoothing within C&S.
