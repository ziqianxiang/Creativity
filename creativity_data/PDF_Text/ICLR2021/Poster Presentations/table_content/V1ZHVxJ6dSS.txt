Table 1: Results on QP task for 100 variables, 50 equality constraints, and 50 inequality constraints.
Table 2: Results on our simple nonconvex task for 100 variables, 50 equality constraints, and 50inequality constraints, with details as in Table 1. Since this problem is nonconvex, we use IPOPTas the classical optimizer. DC3 is differentiable and about 9× faster than IPOPT, giving a near-optimal objective value and constraint satisfaction, in contrast to baseline deep learning-based meth-ods which result in significant constraint violations.
Table 3: Results on ACOPF over 100 test instances. We compare the performance of DC3 andother algorithms according to the metrics described in Table 1. We find again that baseline methodsviolate feasibility (as shown in red), while DC3 gives a feasible and near-optimal output about 10×faster than the PYPOWER optimizer, even assuming that PYPOWER is fully parallelized.
Table A.1: Results on QP task for 100 variables and 50 inequality constraints, as the number ofequality constraints varies as 10, 30, 50, 70, 90. We compare the performance of DC3 and otheralgorithms according to objective value and maximum equality/inequality constraint violations av-eraged across test instances. (Standard deviations across 5 runs are shown in parentheses.) Wefind that neural network baselines give significantly inferior performance (shown in red) across allproblems.
Table A.2: Results on QP task for 100 variables and 50 equality constraints. The number of inequal-ity constraints varies as 10, 30, 50, 70, 90. Content and interpretation as in Table A.1.
