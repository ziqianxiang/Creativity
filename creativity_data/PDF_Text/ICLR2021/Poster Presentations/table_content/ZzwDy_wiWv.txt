Table 1: Effect of proposed losses (LFM and LSR) and position of distillation on the test set ofCIFAR-100.
Table 2: KL divergence between teacher and student, and cross-entropy between student and groundtruth on the test Set of CIFAR-100. Teacher's top-1 accuracy is 79.50%.	.____________Method	KL div. with teacher	Cross-entropy with label	Top-1 (%)Student	03964	0.9383	-7697-KD	0.5818	0.9492	78.35AT	0.5406	0.9049	78.06LFM	03701	01980	-7805-LSR	0.4828	0.8418	79.10LFM+LSR	0.4597		0.8247	79.58Table 3: L2 DiStanCe ∣∣hτ - hs ∣∣2 , and NMI CalCUlated on the test Set of CIFAR-100.
Table 3: L2 DiStanCe ∣∣hτ - hs ∣∣2 , and NMI CalCUlated on the test Set of CIFAR-100.
Table 4: Transferability of representations from CIFAR100 to STL-10 and CIFAR100 by freezingf S and training a linear classifier on top. Top 1 (%) accuracy is provided.
Table 5: Top-1 accuracy (%) of various knowledge distillation methods on CIFAR-10.
Table 6:	Top-1 accuracy (%) of various knowledge distillation methods on CIFAR-100.
Table 7:	Comparison with state-of-the-art on ImageNet.
Table 8: Real-to-binary distillation results on CIFAR-100: a real-valued teacher ResNet-34 is used todistill a binary student. Real-to-binary distillation results on ImageNet-1K: a real-valued ResNet-18is used to distill a binary student. OFD result might be suboptimal.
Table 9: Facial landmark detection with ResNet50 as teacher and ResNet8 as student. KD is adaptedby using an L2 loss instead of a KL loss to measure the discrepancy between the teach and studentpredictions.
Table 10: Evaluation of different loss functions for LSR in terms of Top-1 accuracy on CIFAR-100.
Table 11: Top-1 accuracy (%) of combining our method with KD and AT on CIFAR-100.
Table 12: Distillation experiment with the same architectures (Tian et al., 2020): Top-1 accuracy(%) on CIFAR-100. The student models were trained with a teacher of the same architecture. Wereport average over 3 runs as in (Tian et al., 2020).
Table 13: Distillation experiment with different architectures (Tian et al., 2020): Top-1 accuracy(%) on CIFAR-100. The student models were trained with a teacher of different architecture. Wereport average over 3 runs as in (Tian et al., 2020).
