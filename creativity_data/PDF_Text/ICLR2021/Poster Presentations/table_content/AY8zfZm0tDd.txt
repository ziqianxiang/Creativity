Table 1: REDQ hyperparametersParameter	ValueShared	optimizer	Adam (Kingma & Ba, 2014)learning rate	3∙10-4discount (Y)	0.99target smoothing coefficient (ρ)	0.005replay buffer size	106number of hidden layers for all networks	2number of hidden units per layer	256mini-batch size	256nonlinearity	ReLUrandom starting data	5000REDQ	ensemble size N	10in-target minimization parameter M	2UTD ratio G	20OFENet	random starting data	20,000OFENet number of pretraining updates	100,000
Table 2: Sample efficiency comparison of SAC and REDQ. The numbers show the amount of datacollected when the specified performance level is reached. The last two columns show how manytimes REDQ and REDQ-OFE are more sample efficient than SAC in reaching that performance.
Table 3: Performance comparison of REDQ, REDQ-OFE, MBPO and SAC. The numbers show theperformance achieved when the specific amount of data is collected. The last two columns show theratio of REDQ or REDQ-OFE performance compared to SAC and MBPO performance.
Table 4: Number of parameters in millions. REDQ uses the same network structure and ensemblesize for all four environments. The difference in the number of parameters comes from the fact thatthe environments have very different observation and action dimensions, which will affect the sizeof the input and output layers of the networks.
