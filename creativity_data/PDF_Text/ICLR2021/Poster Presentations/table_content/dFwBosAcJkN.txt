Table 1: ImageNet-100 ac-curacies against the unionof five threat models (L∞ ,L2 , JPEG, StAdv, and Re-ColorAdv) for different ad-versarially trained (AT) clas-sifiers and a single modeltrained using PAT.
Table 2: Accuracies against various attacks for models trained with adversarial training and PerceptualAdversarial Training (PAT) variants on CIFAR-10. Attack bounds are 8/255 for L∞, 1 for L2 , 0.5for PPGD/LPA (bounded with AlexNet), and the original bounds for StAdv/ReColorAdv. Manifoldregularization is from Jin and Rinard (2020). See text for explanation of all terms.
Table 3: Comparison of adversarial training against narrow threat models and Perceptual AdversarialTraining (PAT) on ImageNet-100. Accuracies are shown against seven attacks with the mediumbounds from Table 4. PAT greatly improves accuracy (33% vs 12%) against the union of the narrowthreat models despite not training against any of them. See text for explanation of all terms.
Table 4: Bounds and results from the perceptual study. Each threat model was evaluated with a small,medium, and large bound. Bounds for L2, L∞, and JPEG attacks (first three rows) are given assuminginput image is in the range [0, 255]. Perceptibility (perc.) is the proportion of natural input-adversarialexample pairs annotated as “different” by participants. Strength (str.) is the success rate whenattacking a classifier adversarially trained against that threat model (higher is stronger). Perceptualattacks (PPGD and LPA, see Section 4) are externally bounded with AlexNet. All experiments onImageNet-100.
Table 5: Accuracy of a PAT-trained ResNet-50 on ImageNet-100 against various perceptual adversarialattacks. PPGD and LPA attacks are shown self-bounded and externally-bounded with AlexNet. Wealso experimented with two different perceptual projection methods (see Appendix A.4). Boundsare = 0.25 for self-bounded attacks and = 0.5 for externally-bounded attacks, since the LPIPSdistance from AlexNet tends to be about twice as high as that from ResNet-50.
Table 6: Accuracies against various attacks for models in the PAT ablation study. Attack bounds are8/255 for L∞, 1 for L2, 0.5 for PPGD/LPA, and the original bounds for StAdv/ReColorAdv.
Table 7: Accuracies against various attacks for PAT-trained models on CIFAR-10, with and without aprojection step during training.
Table 8: Accuracies against various attacks for classifiers on CIFAR-10 trained with self- andAlexNet-bounded PAT using various bounds.
Table 9: Results of our experiments training against StAdv and ReColorAdv on CIFAR-10 withdouble the default bounds. Columns are identical to Table 2.
Table 10: Robustness of classifiers trained with adversarial training and PAT against commoncorruptions in the CIFAR-10-C dataset. Results are reported as relative mCE (lower is better). PATimproves robustness against common corruptions overall and for three of the specific perturbationcategories.
Table 11: Robustness of classifiers trained with adversarial training and PAT against commoncorruptions in the ImageNet-100-C dataset. Results are reported as relative mCE (lower is better).
Table 12: Hyperparameters for the adversarial training experiments on CIFAR-10 and ImageNet-100.
