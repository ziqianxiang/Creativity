Table 1: Performance showing the occurrence of robust overfitting across datasets and the effectiveness ofour proposed remedies with ResNet-18. The difference between best and final robust accuracy indicates degra-dation in performance during training. We pick the checkpoint which has the best robust accuracy on thevalidation set. The best results and the smallest performance differences are marked in bold.
Table 2: Controlled experiments on CIFAR-10. The difference between best and final robust accuracy indicatesdegradation in performance during training. We pick the checkpoint which has the best robust accuracy onthe validation set. The best results and the smallest performance difference are marked in bold.
Table 3: Controlled experiments across different architecture on CIFAR-10/100 under '∞ adversary. Thedifference between best and final robust accuracy indicates degradation in performance during training. Wepick the checkpoint which has the best robust accuracy on the validation set. The best results and the smallestperformance difference are marked in bold.
Table 4: Evaluation under improved attacks on CIFAR-10/100 with ResNet-18. The difference between bestand final robust accuracy indicates degradation in performance during training. We pick the checkpoint whichhas the best robust accuracy under PGD-20 attack on the validation set. The best results and the smallestperformance difference are marked in bold.
Table 5: Ablation studies on CIFAR-10 with ResNet-18. Compared with Baseline (PGD-AT) methods, theperformance improvements and degradations by adding each component are reported in red and blue numbers.
Table 6: Ablation of label smoothing versus KD on CIFAR-10.
Table A7: Comparative Experiment on CIFAR-100, we follow the same setting and compare with the baselineresult from (Rice et al., 2020). Best refers to the model with best robust accuracy during training and Final isan average of accuracy over last 5 epochs.
Table A8: Performance showing the occurrence of robust overfitting and effectiveness of our proposed reme-dies with ResNet-18 on SVHN. The difference between best and final robust accuracy indicates degradation inperformance during training. We pick the checkpoint which has the best robust accuracy on validation dataset.
Table A9: Ablation of Transfer attack. The accuracy on unseen model is the accuracy of unseenmodel with adversarial images generated by source models from different settings and the accuracyfrom unseen model means the opposite. We generated adversarial images for all test images onCIFAR-10 With '∞ PGD-20. Baseline represents the PGD-AT methods.
Table A10: Ablation of SWA on CIFAR-10.Best refers to the model selected with best robustaccuracy on validation dataset and Final is the model at the end of training process.
