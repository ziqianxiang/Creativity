Table 1: Classification accuracy on 4-class rotation and IN-100 under linear evaluation protocol.
Table 2: Evaluation on multiple downstream tasks. Our method demonstrates superior generaliz-ability and transferability with increasing number of augmentations.
Table 3: Evaluation on datasets of real-world corruptions. Rotation augmentation is beneficialfor ON-13, and texture augmentation if beneficial for IN-C-100.
Table 4: Comparisons of LooC vs. MoCo trained with all augmentations.
Table 5: Comparisons of concatenating features from different embedding spaces in LooC++jointly trained on color, rotation and texture augmentations. Different downstream tasks show non-identical preferences for augmentation-dependent or invariant representations.
Table 6: Leave-one-out vs. add-one Augmentation. *: Default (none add-one) augmentation strat-egy.
Table 7: Results of models trained on 1000 category ImageNet and fine-tuned on iNat-1k followinglinear classification protocol.
