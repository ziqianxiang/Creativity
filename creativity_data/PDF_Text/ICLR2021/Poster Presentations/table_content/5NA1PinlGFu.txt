Table 1: We contrast the different components of unconditional self-attention with self-attention conditioned oncontext C ∈ RM×N×D. Learnable parameters specific to conditioning are denoted by U and U∙ ∈ RD×D.
Table 2: We outperform various state-of-the-art colorization models both on FID (left) and human evaluation(right). We obtain the FID scores from (Ardizzone et al., 2019) and the human evaluation results from(Guadarrama et al., 2017). ColTran-B is a baseline Axial Transformer that conditions via addition and ColTran-Sis a control experiment where we train ColTran core (See: 4.1) on smaller 28 × 28 colored images.
