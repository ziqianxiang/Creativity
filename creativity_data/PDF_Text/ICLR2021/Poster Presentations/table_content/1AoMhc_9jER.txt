Table 1: The extreme sparsity of the matching net-works and the FID score of best subnetworks, foundby iterative pruning and one-shot pruning. OMPG :one-shot prune the generator. OMPGP : one-shotprune generator/discriminator.
Table 2: The FID score of best subnetworks and theextreme sparsity of matching networks found by Ran-dom Pruning, Random Rickets, and iterative magni-tude pruning.
Table 3: Rewinding results. SExtreme : Extreme spar-sity where matching subnetworks exist. FIDBest : Theminimal FID score of all subnetworks. FID89% : TheFID score of subnetworks at 89% sparsity.
Table 4: Results of late rewinding experiments. θ0 : train the target model from the same random initializationas the source model; θr : train from random initialization; θBest : train from the weights of trained sourcemodel. Baseline: full model trained on STL-10.____________________________________________________Model I Baseline ∣ IMPG (S = 67.23%) ∣ IMPGD (S = 73.79%) ∣ IMPKD (S = 73.79%)Metrics ∣ FIDBest ∣ FIDBest Matching? ∣ FIDBest Matching? ∣ FIDBest Matching?θ0		116.7	X	121.8	×	120.1	×θr	115.3	119.2	×	113.1	X	115.5	XθBest		204.7	×	163.0	×	179.1	×The FID score of different settings is shown in Table 4. Subnetworks initialized by θ0 and usingmasks generated by IMPG can be trained to achieve comparable results to the baseline model. Sur-prisingly, random re-initialization θ00 shows better transferability than using the same initializationθ0 in our transfer settings and outperforms the full model trained on STL-10, indicating that thecombination of θ0 and the mask generated by IMPGD is more focused on the source dataset andconsequently has lower transferability.
Table 5: Results on other GAN models on CIFAR-10. FIDFull: FID score of the full model. FIDBest:The minimal FID score of all subnetworks. FIDExtreme : The FID score of matching networks atextreme sparsity level. AutoGAN-A/B/C are three representative GAN architectures represented inthe official repository (https://github.com/VITA-Group/AutoGAN)Model	Benchmark	FIDfu11 (Sparsity)	FIDBest (Sparsity)	SEXtreme (SParSity)DCGAN (Radford et al., 2016)	CIFAR-10	57.39 (0%)	49.31 (20.0%)	54.48 (67.2%)WGAN-GP (Gulrajani et al., 2017)	CIFAR-10	19.23 (0%)	16.77 (36.0%)	17.28 (73.8%)ACGAN (Odena et al., 2017)	CIFAR-10	39.26 (0%)	31.45 (36.0%)	38.95 (79.0%)GGAN (Lim & Ye, 2017)	CIFAR-10	38.50 (0%)	33.42 (20.0%)	36.67 (48.8%)ProjGAN (Miyato & Koyama, 2018)	CIFAR-10	31.47 (0%)	28.19 (20.0%)	31.31 (67.2%)SAGAN (Zhang et al., 2019)	CIFAR-10	14.73 (0%)	13.57 (20.0%)	14.68 (48.8%)AutoGAN(A) (Gong et al., 2019)	CIFAR-10	14.38 (0%)	14.04 (36.0%)	14.04 (36.0%)AutoGAN(B) (Gong et al., 2019)	CIFAR-10	14.62 (0%)	13.16(20.0%)	14.20 (36.0%)AutoGAN(C) (Gong et al., 2019)	CIFAR-10	13.61 (0%)	13.41 (48.8%)	13.41 (48.8%)DiffAugGAN (Zhao et al., 2020b)	CIFAR-10	8.23 (0%)	8.05 (48.8%)	8.05 (48.8%)Table 6: Results on other GAN models on Tiny ImageNet. FIDFull : FID score of the full model.
Table 6: Results on other GAN models on Tiny ImageNet. FIDFull : FID score of the full model.
Table A7: The F8 and F1/8 score of the full net-work, best subnetworks and the matching net-works at extreme sparsity. We used the officialcodes to calculate recall, precision, F8 and F1/8 .
