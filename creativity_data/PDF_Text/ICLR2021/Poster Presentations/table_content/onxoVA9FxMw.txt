Table 1: Overview of PEs. Px or P (x) is the x-th absolute/relative position vector (the latter isparameterized by sinusoidal functions). The newly-proposed PEs in this paper are in bold.
Table 2: Quantitative measurement of the properties (monotonicity, translation invariance, symme-try, and direction balance 10). For these property indicators, the smaller the number, the better theproperty is met. 0 denotes that the property is ideally satisfied. Direction balance denotes the ra-tio between the sum of attention values for forward attending and backward attending. 1 meansit is fully-balanced in directions. We have indicated the numbers that most closely correspond tosatisfaction properties and direction balance for each group in bold.
Table 3: Experiments on GLUE. The evaluation metrics are following the official GLUE benchmark(Wang et al., 2018). The best performance of each task is bold.
Table 4: Performance (average and standard deviation in 5 runs) on dev of SQuAD V1.1 and V2.0.
Table 5: Pearson correlations between the properties and evaluated tasks, evaluating on BERT mod-els with 13 position embeddings. The positive (negative) numbers denote to which degree the per-formance of the task positively (negatively) correlate(s) to violating the property. This shows thatviolating local monotonicity and translation invariance is harmful, while violating symmetry (anddirection-balance) is beneficial. Best correlation values are in bold for each row.
Table 6: Detailed Experimental SettingsTraining	pre-training from scratch	max Length	epoch	learning rate	batch sizeBERT-base on 128 length	X	128	5	5e-5	64BERT-base on 512 length	X	512	2	5e-5	512BERT-medium on 128 length	✓	128	10	5e-5	128BERT-medium on 512 length	✓	512	2	5e-5	512GLUE	-	128	3	2e-5	32SQuAD	-	384	3	3e-5	32We perform five runs for SQuAD and GLUE benchmark. The results in GLUE are for the lastcheckpoint during fine-tuning while SQuAD takes the best one for every 1000 steps. Finally, wecalculate the average over 5 runs. All these settings are the same for all PEs. We use MismatchedMNLI. In GLUE (Wang et al., 2018), the train and dev are somewhat adversarial: training samples(in train and dev) containing the same sentence usually have opposite labels. Models may get worsewhen it overfits in the train set, resulting in unexpected results. Therefore, we exclude WNLI tocalculate average in the last column in Tab. 3. The fine-tuning parameters are using default valuesin Huggingface project Wolf et al. (2019).
Table 7: Quantitative measurement of the properties for models of machine translation, languagemodels.
