Table 1: Adversarially-trained models are less biased towards recognizing textures than natural ones.
Table 2: Robust models transfer better than natural ones on low resolution and low pass filteredvariants of Caltech101. This table shows the test accuracy after fine-tuning three convolutionalblocks of the robust model (kδ k2 ≤ 3) and the natural model on a low resolution (Low-Res) or alow pass filtered (Low-Pass) version of Caltech101. We lowered the resolution to 32x32 and zeroedout the top 1,024 (〜14%) frequencies, respectively.
Table 3: Hyper-parameter summary for all fine-tuned source modelsLearning rate	Batch size	Momentum	Weight decay	LR decay	LR decay schedule	Fine-tuned adversarially?0.1	128	0.9	5 X 10-4	10x	1/3, 2/3 epochs	NoThe learning rate decays to a tenth of it’s current value every 33 or 50 epochs, which corresponds to1/3 of the total fine-tuning epochs, as shown in Table 4. Also, the test accuracy frequency refers tohow often is the test accuracy computed, in epochs. So, for example, if the test accuracy frequencyis 20, then we check the test accuracy after epoch 1, 21, 41, ..., 81, and 100.
Table 4: Batch summary for every target dataset and source modelNumber of images	Fine-tuning epochs	Number of random seeds	Test accuracy frequency (epochs)	LR decay schedule100	100	20	=	20	33/66200	100	20	20	33/66400	100	20	20	33/66800	100	20	20	33/661,600	100	20	20	33/663,200	150	10	10	50/1006,400	150	10	10	50/10012,800	150	5	10	50/10025,600	150	5	10	50/100All	150	1	10	50/100Sk = {20000000+(100000i)∣i ∈ {0, 1, ∙∙∙ ,k - 1}}.
Table 5: Summary of source models trained on ImageNet, which we consider for transfer learning.
Table 6: Summary of the source and target datasets.
Table 7: Summary of the test accuracy on target datasets after fine-tuning three blocks (nine convo-lutional layers) except for the rightmost column, which shows the non-transferred model trained onthe entire network. Reported average test accuracy for all cases where the model is fine-tuned withless than the entire training set.
