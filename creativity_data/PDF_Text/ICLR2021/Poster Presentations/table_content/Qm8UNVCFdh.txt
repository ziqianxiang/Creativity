Table 1: Target task results. We compare the performance of our learned representation frommovement and gaze cues with a recent self-supervised baseline MoCo (He et al., 2020) (which istrained on our data). Note that the MoCo baseline is trained using only visual data (‘vis’). Weevaluate the performance on a variety of different target tasks.
Table 2: Ablation of the visual loss. The result of using an autoencoder for the visual loss. Were-train the models for the five target tasks. Latt, Lmove and Lnce are the ones used in Eq. 3.
Table 3: Body part movement prediction. We investigate the correlation of the movement andattention by using the human gaze as an additional input to predict the body part movements.
Table 4: Ablation of body parts. We show how the performance on the target tasks changes whenwe ignore a body part during representation learning.
Table 5: Results of pre-training with ImageNet. We provide the results of full supervision forpre-training using ImageNet and also the MoCo model trained on ImageNet data.
