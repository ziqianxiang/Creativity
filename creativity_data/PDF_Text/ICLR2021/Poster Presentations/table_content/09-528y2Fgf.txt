Table 1: GLUE scores on dev set. All settings are pre-trained by BERT-Base (110M) model with16GB data. TUPE-Amid (TUPE-Rmid) is the intermediate 300k-step checkpoint of TUPE-A (TUPE-R).
Table 2: Hyperparameters for the pre-training and fine-tuning.
Table 3: GLUE scores on dev set. Different models are pre-trained in the BERT-Large setting (330M)with 16GB data. TUPE-Largemid is the intermediate 300k-step checkpoint of TUPE-Large.
Table 4: GLUE scores on dev set. Different models are pre-trained in the ELECTRA-Base setting(120M) with 16GB data. Electra-TUPEmid is the intermediate 600k-step checkpoint of ELECTRA-TUPE.
