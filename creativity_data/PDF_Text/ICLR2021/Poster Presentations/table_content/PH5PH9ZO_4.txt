Table 1: Our work solves two key problems to find optimal adversarial perturbations - site-selection andsite-perturbation. The BASELINE method refers to (Ramakrishnan et al., 2020). The perturbation strength kis the maximum number of sites which an attacker can perturb. Higher the the Attack Success Rate (ASR),better the attack; the converse holds for F1 score. Our formulation (Eq. 2), solved using two methods -alternate optimization (AO) and joint optimization (JO), along with randomized smoothing (RS), shows aconsistent improvement in generating adversarial programs. Differences in ASR, marked in blue, are relativeto Baseline. The results on a Java dataset are tabulated in Table 4, Appendix.
Table 2: We employ an AT setup to trainseq2 seq with the attack formulation we propose.
Table 3: We present an additional example which contrasts the advantages of different aspects ofour formulation. In Figure 1, we saw how selecting an optimal site led to the optimal local variable(qisrc) being found. In this example, we show how randomized smoothing, a key solution wepropose to ease optimization, helps in finding the best variable. In this case, just finding the optimalsite is not enough to flip the classifier’s decision (call). Smoothing however enables to find a localvariable datetime which flips the classifier’s decision to create.
Table 4: Performance of our formulation on a dataset containing Java programs (Alon et al., 2018).
Table 5: False positive rates of the model under different attacks.
Table 6: The effect of variable names, function parameter names, and print statements on the robustness of thelearned model. These results correspond to the Python dataset.
