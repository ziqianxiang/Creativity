Figure 1: The upper left is a dialogue example between user and system with its turn-level and dialogue-levelbelief states on the upper right. The lower left are valid user utterance variations generated by VS and CoCowith their corresponding belief states derived from the original ones on the right.
Figure 2: The overall pipeline of CoCo. The very left part represents the training phase of utterance generationmodel, where the concatenation of USyS and Lt is processed by the encoder, which the decoder then conditionson to generate the user utterance UUSr. The input and output of this model is shown within the box at thelower-left. The right part depicts the inference phase, where the counterfactual goal generator first modifies theoriginal belief Lt fed from the left part into a new one Lt, which is then fed to the trained utterance generatoralong with the same conversation history to generate UUSr by beam search followed by filtering undesiredutterances. Note that conversational turns in inference phase don,t have to originate from training phase.
Figure 3: Joint goal accuracy (%) across different methods. "Original” refers to the results on the originalheld-out test set. * denotes results obtained from in-domain unseen slot-value dictionary (I). VS, CoCo andCoCo+ results use out-of-domain slot-value dictionary (O). For brevity, We omit CoCo and CoCo+ resultsusing in-domain slot-value dictionary. See Appendix C for the full results. freq, neu, and rare indicate whichslot-combination dictionary is used. Lower bound refers to the percentage of correct predictions on turns withempty turn-level belief state over original held-out test set.
Figure 4: Comparison of retrained DST models (indicated by ◊ ) on CoCo+(rare)-augmented training dataWith their counterparts trained on original MultiWOZ train split.
Figure 5: Slot-level accuracy analysis of TRIPPY. ”Ori-TriPPy-Clean”(blue) and ”Ori-TripPy-CoCo+(rare)”(orange) denote TripPy (trained on original MUltiWOZ training data) when evaluated against original testset and CoCo+(rare) generated test set, respectively. ”Aug-TripPy-CoCo+(rare)” (green) indicates slot-levelaccuracy of TripPy after data augmentation (see Section 5.4 for further details) when evaluated against test setgenerated by CoCo+(rare).
Figure 6: Joint goal accuracy (%) across different methods. “Original” refers to the results on theoriginal held-out test set. * denotes results obtained from in-domain unseen slot-value dictionary (I)while other results use out-of-domain slot-value dictionary (O). freq, neu, and rare indicate whichslot-combination dictionary is used.
Figure 7: Zero-shot generation ability of CoCo on flight domain, which is never seen during training.
Figure 8:	A success and failure example generated by CoCo with different slot-value combinations.
Figure 9:	An example generated by CoCo with correct predictions by Trade, SimpleTOD andTripPy without retraining.
Figure 10: An example generated by CoCo with incorrect predictions by Trade, SimpleTOD andTripPy without retraining.
Figure 11:	An example from original MultiWOZ test set, which is predicted incorrectly by originalTrade, SimpleTOD and TRIPPY, is corrected by their retraining counterparts.
Figure 12:	An example generated by CoCo(rare) evaluation set, which is predicted incorrectly byoriginal Trade, SimpleTOD and TripPy, is corrected by their retraining counterparts.
