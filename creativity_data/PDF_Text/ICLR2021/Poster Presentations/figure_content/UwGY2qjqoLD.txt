Figure 1: Heating up a planar decision boundary of a 5-layer MLP over time. The amounts of radiatedheat reflect the geometry of the decision boundary: size, density, curvature.
Figure 2: A planar 2-class dataset that alternates along a circle. (Left) A depiction of the planarcircle-like dataset and the corresponding decision boundary of a 5-layer MLP. (Center) Brownianpaths starting at a data point x and killed upon impacting the decision boundary/opposite class.
Figure 3: A visual depiction of decision boundaries and saturation τ for 5-layer MLP models with20 and 100 hidden units trained over a planar "circular" dataset (depicted in grey). For each datasample X the ball B(x, r) is selected so that the relative volume μ(x, r) is 0.1. According to Lemma3.2 a flat decision boundary would correspond to τ ≈ 3.32. (Left) The saturation τ exhibits abi-modal behaviour with peaks around the values 3 and 4.3. These correspond to data points squeezedbetween thin elongated regions that locally closely resemble the flat case, or tinier "pockets" withhigher curvature, respectively. (Right) The saturation τ is more closely concentrated around 4.3 and,accordingly, the decision boundary mainly consists of smaller "pockets" of higher curvature.
Figure 4: Results for a Wide-ResNet 28-10 and a LeNet-5 trained on CIFAR10 and MNIST, respec-tively. Different boxplots correspond to different training strategies: ordinary, adversarial, with noiseor with a Brownian augmentation. Data is collected over 1000 test data points, where each radius r isselected so that the relative error volume μ equals 1%. Left-to-right the columns correspond to theisocapacitory saturation T, the radius r realizing μ = 1% and the isoperimetric saturation. Finally,red punctured horizontal lines indicate the corresponding values for flat decision boundaries.
Figure 5: Examples illustrating the interplay between isoperimetric and isocapacitory saturation inhigh dimensions. (Left) Slightly bending a flat decision boundary N0 causes significant changes in τwith the isoperimetric inequality still being very close to optimal: N+ (resp. N-) leads to a increase(resp. decrease) in τ (cf. also Fig. 6). (Right) Small "pockets" near the data sample x can also causelarge Brownian hitting probabilities (hence, large τ values) with still well-saturated isoperimetricbounds.
Figure 6: A continuation on Fig. 5: Isocapacitory and isoperimetric saturation while slightly bendingthe decision boundary (N- and N+ in Fig. 5). In this plot the decision boundary N- , N+ is a cap ofa larger sphere with radius R (set initially to 15r) in dimension 3072 (corresponding to CIFAR10).
Figure 7: The isocapacitory saturation τ of a flat error set. Given a point x, the computation takesplace in B(x, r) with r = 1. The distance to the flat decision hyperplane is given on the x-axis, whilethe y-axis gives τ . Curve labeling indicates the respective dimension. There appears to be a thresholddividing between the regimes τ ≈ 2 and τ → ∞.
Figure 8: Further model cases and plots of the isocapacitory saturation τ . (Left) Isocapacitorysaturation of cone in terms of the opening angle (radians). (Right) Isocapacitory saturation of wedgein terms of the opening angle (radians). Curve labels indicate the respective dimension. Again oneobserves concentration of measure as the volume of the cone decreases to 0 exponentially fast interms of the dimension n: this is why we plot the opening angle around π in this case. Furthermore,cones and wedges with an opening angle of almost π behave like hyperplanes in terms of saturation.
Figure 9: Cylindrical "spike" of height h and radius ρ inside the ball B(x, r).
Figure 10: “Soft” definition of curvature given by the inverse radius of the osculating sphere.
Figure 11: Moving the piece Pv near the tip of the obstacle and reattaching it far away as Pvreduces the hitting probability, but preserves volume.
Figure 12: Covering by cuboids of side length δ.
Figure 13: The statistics obtained from the Residual Networks with 32, 44 and 56 layers on theCIFAR10 dataset. For this experiment we considered the Brownian particles with average displace-ment equal to the radius of sphere with relative volume μ = 0.01, where μ is defined according toequation (2) in the main text. The considered quantities are (Left) the probability of a Brownianparticle to collide with the decision boundary, (Center Left) the isocapacitory bound, i.e. the ratioof said probability versus relative volume μ, (Center Right) the radius of the obtained sphere equalto the RMSD of the particle and (Right) the saturation of the isoperimetric bound. We observeconsistent behavior of the shown quantities for all three models. The trend of isoperimetric saturation(although, not so concentrated as in the case of WRN and LeNet-5, Fig. 4) as well as the increase ofdistances r are present. Again the isocapacitory saturation does not appear to follow a distinguishedconcentration around the case of a flat decision boundary despite the overall increase in flatness: hereboth noisy and adversarial training seem to deliver a decrease in τ. In fact, the heat imprint of theordinarily trained model exhibits a "flatter" behaviour in terms of τ .
Figure 14: Statistics for a convolutional neural network with four convolutional and two linearlayers applied to the MNIST dataset. This particular convolutional model shows that not everyarchitecture/training/dataset instance displays the distinguished trend in increasing the isoperimetricsaturation - however, even in this scenario the isoperimetric saturation is quite sharp. Similar to otherexperiments above, the isocapacitory saturation τ on the other hand does not concentrate to such anextent.
Figure 15: Typical examples of the CIFAR-10 dataset used to train the models. From left to right,the clean image, a PGD adversarial example, a Gaussian perturbation (σ2 = 0.4) and the terminalpoint of a Brownian random walk (undirected attack) immediately after colliding with the decisionboundary are shown. The comparison between the PGD adversarial example and the right pictureemphasize the degree to which spikes in the decision boundary deviate from the average distancebetween boundary and clean example.
Figure 16: Evaluation of the accuracies of the LeNet-5 (MNIST) models during a range of attacks.
