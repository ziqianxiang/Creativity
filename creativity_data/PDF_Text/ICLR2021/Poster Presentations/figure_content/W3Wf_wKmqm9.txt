Figure 1: (a) A continuous spectrum of paths allow the mouse to reach its goal faster, at an increased riskof disturbing the cat and being eaten. (b) Q* (with Y = 0.99) needs to be learned more accurately thanC * to act optimally. The goal g can be reached in h* = 5 steps from s, So that Q* (s,g,a*) = 0.995 andQ*(s,g, a-) = 0.997; while C*(s, a*, g, h*) = 1 and C*(s, a-,g, h*) = 0.
Figure 2: Graphical model depicting trajectories fromP∏(∙∣∙,g,h)(∙∣so = s,ao = a). Gray nodes denote fixed Val-ues, and white nodes stochastic ones. Nodes a, g and s arenon-stochastic simply because they are conditioned on, notbecause they are always fixed within the environment. Notethat the values of h decrease deterministically. Nodes corre-sponding to horizons could be separated from states, but arenot for a more concise graph.
Figure 3: Experimental environments, from left to right: frozen lake, Dubins’ car, FetchPickAndPlace-v1and HandManipulatePenFull-v0. Arrows represent actions (only their direction should be considered, theirmagnitude is not representative of the distance travelled by an agent taking an action). See text for description.
Figure 4: (a) Multimodal policies recovered by C-learning in frozen lake for different values of h for reaching(G) from (S) (top); unimodal policies recovered by GCSL and HER (bottom). (b) Heatmaps over the goalspace of maxa C * (s,a,g,h) with a fixed S and h for Dubins' car, with h = 7 (top), h = 15 (middle)and h = 25 (bottom). (c) Trajectories learned by C-learning (top), GCSL (middle) and HER (bottom) forDubins’ car. (d) Success rate throughout the training for Dubins’ car (top), FetchPickAndPlace-v1 (middle)and HandManipulatePenFull-v0 (bottom) for C -learning (blue), HER (red) and GCSL (green).
Figure 5: Partitioning of environments into easy (green), medium (yellow) and hard (red) goals to reach from agiven starting state (blue). The left panel shows mini maze, and the right shows Dubins’ car.
Figure 7: Success rate throughout training of C-learning (blue) and TDMs (red) in FetchPickAndPlace-v1 (left)and HandManipulatePenFull-v0 (right).
