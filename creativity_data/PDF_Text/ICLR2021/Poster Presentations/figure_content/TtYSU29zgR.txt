Figure 1: Illustration of the difference between the a) greedy coupling and the b) optimal coupling.
Figure 2: Mean and standard deviation return of the evaluation policy over 10 rollouts and 10 seeds,reported every 10k environment steps. The return is in term of the environment’s original reward.
Figure 3: Mean of the Wasserstein distance between the state-action distribution of the evaluationpolicy and the state-action distribution of the expert over 10 rollouts and 10 seeds. Agents weretrained with 11 demonstrations. For PWIL, we include the upper bound on the Wasserstein distancebased on the greedy coupling defined in Equation (4).
Figure 4: Mean and standard deviation of the evaluation performance of PWIL and variants at the1M environment interactions mark (2.5M for Humanoid). Results are computed over 10 seeds and 10episodes for each seed.
Figure 6: We present the average and standard deviation of evaluation performance of PWIL onthe door environment. Metrics are computed every 10k environment steps and aggregated over 10seeds and 10 rollouts. Left: the imitation returns of the agent. Center: Wasserstein distance in theembedding space to expert demonstrations. Right: Success rate of the agent, i.e. ratio of episodeswhere the agent manages to open the door.
Figure 7: Mean and standard deviation of the imitation return of the agent. We perform 10 rolloutsover 10 seeds every 10k environment steps over 1M steps. The return here is in term of the rewarddefined with Equation (6). Top row: 1 demonstration, middle row: 4 demonstrations, bottom row 11demonstrations.
Figure 8: Mean and standard deviation of the original environment returns of the evaluation policyover 10 rollouts and 10 seeds, reported every 10k environment steps over 1M steps. Top row: 1demonstation, middle row: 4 demonstrations, bottom row: 11 demonstrations.
Figure 9: Mean and standard deviation of the Wasserstein distance between the state-action distri-bution of the evaluation policy and the state-action distribution of the expert over 10 rollouts and10 seeds, reported every 10k environment steps. We include the upper bound on the Wassersteindistance based on the greedy coupling defined in Equation (4). Top row: 1 demos, middle row: 4demos, bottom row: 11 demos.
Figure 10: Evaluation performance of different variants of PWIL over 10 rollouts and 10 seeds, re-ported every 10k environment steps over 1M steps. The return is in term of the environment’s originalreward. Top row: 1 demonstration, middle row: 4 demonstrations, bottom row: 11 demonstrations.
Figure 11: Mean and standard deviation of the evaluation performance of PWIL-D4PG, PWIL-SACand PWIL-TD3 at the 1M environment interactions mark (2.5M for Humanoid). Results are computedover 10 seeds and 10 episodes for each seed.
Figure 12: Kendall’s tau score of theencoding network on the train and vali-dation sets. An iteration corresponds to1000 gradient updates.
Figure 13: PWIL example rundown. We drop the dependency on the action. The example task has anhorizon T = 2, and the demonstration set has D = 4 elements. We take f : c 7→ exp (-c).
