Figure 1: WideResNet 28-10 on CIFAR-10/CIFAR-100. Red: Ensembles without Mixup; Blue:Ensembles with Mixup; Orange: Individual models in ensembles without Mixup. (a) & (b): ApplyingMixup to different ensemble methods leads to consistent improvement on test accuracy. (c) & (d):Applying Mixup to different ensemble methods harms calibration. Averaged over 5 random seeds.
Figure 2: Reliability diagrams on CIFAR-100 with a WideResNet 28-10.
Figure 3: ECE and Error on CIFAR-10 with label smoothing on MC Dropout, Deep Ensembles, andBatchEnsemble. ECE degrades with label smoothing, particularly when it is more aggressive (â‰¥ 0.2).
Figure 4: Left: An illustration of the proposed CAMixup data augmentation. Selected per-classtest accuracies are showed in brown. Overall test accuracy is 96.2% on CIFAR-10; Right: Numberof epochs (out of 250) where CAMixup enables Mixup for selected classes in BatchEnsemble.
Figure 5: WideResNet 28-10 on CIFAR-10/CIFAR-100. Red: Ensembles without Mixup; Blue: En-sembles with Mixup; Green: Our proposed CAMixup improves both accuracy & ECE of ensembles.
Figure 6: WideResNet 28-10 on CIFAR-10-C.
Figure 7: Performance on BatchEnsemble under dataset shift. Mixup and AugMixup improveaccuracy and calibration under shift but significantly worsen in-distribution calibration. Our proposedCAMixup and AugCAMixup improve accuracy and calibration.
Figure 8: Softmax probabilities surface of different ensemble methods (ensemble size 4) in the inputspace after training on synthetic data. Deep ensemble is over-confident in the area around origin.
Figure 9: Left: Reliability diagrams on CIFAR-100 with a WideResNet 28-10. Our proposedCAMixup successfully fixes the under-confidence of Mixup BatchEnsemble, leading to better calibra-tion. (b) & (c): Red: Ensembles without Mixup; Blue: Ensembles with Mixup; Green: Our proposedCAMixup does not harm the out-of-distribution performance.
Figure 10: Reliability diagrams on CIFAR-10 and CIFAR-100. Both plots show that AugMix doesnot lead to under-confidence when combined with ensembles. However, if we combine AugMixwith Mixup (AugMixup), the compounding under-confidence issue still exists, leading to suboptimalcalibration. Our proposed AugCAMixup corrects this underconfidence bias.
Figure 11: WideResNet-28-10 Deep Ensembles with Mixup on CIFAR-10. We plotted the reliabilitydiagram of ensemble and individual predictions. Besides ECE, we also plotted other calibrationmetrics such as ACE, SCE and TACE proposed in Nixon et al. (2019). All metrics verify theconclusion that Mixup + Ensembles leads to under-confidence on testset.
Figure 12:	WideResNet 28-10 on CIFAR-10 and CIFAR-10-C, averaged over 3 random seeds. SKCE:Squared kernel calibration error computed in Widmann et al. (2019). DCE: Debiased calibrationerror in Kumar et al. (2019). Red: Ensembles without Mixup; Blue: Ensembles with Mixup; Green:Ensembles with CAMixup (ours). Both SKCE and DCE give consistent rankings on calibrationerror to the ranking in Fig. 5 and Fig. 6. This plot shows that our proposed CAMixup is effective inreducing Mixup calibration error when combined with ensembles.
Figure 13:	Combining CAMixup and Temperature Scaling further improves test ECE.
Figure 14:	WideResNet 28-10 on CIFAR-10 and CIFAR-10-C. Green: Class based CAMixup. Purple:Forgetting count based CAMixup. Forgetting count based CAMixup outperforms class based Mixupin most metrics across BatchEnsemble and MC-dropout.
