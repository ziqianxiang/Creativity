Figure 1: Two variants of ACE. Dashed and solid arrows represent selection mechanism and classi-fication networks, respectively. The colored, dashed arrows represent the selection decision obtainedby thresholding either the output of the selection network or the entropy. Based on this selection,we output either the result of the certification-network hbθ (red) or the core-network htθ (blue).
Figure 2: Natural and certified accuracy of different COLT trained models on CIFAR-10 with ∞ =2/255. We compare individual Conv3 networks (yellow dots), trained with COLT and varyingnatural loss components, with different ACE models (squares) based on an EfficientNet-B0 core-network (purple) and different certification-networks (triangles): Conv3 with DeepZ certification(teal) and Conv3 with MILP certification (blue). Further up and to the right is better. The horizontaldistance between the yellow and teal line is the increase in natural accuracy due to using ACE insteadof changing the natural loss component int COLT training.
Figure 3: Natural and certified accuracy on CIFAR-10 with ∞ = 8/255. We compare individ-ual Conv5 networks (yellow dots), trained with CROWN-IBP and varying natural loss components,with different ACE models (squares) based on an EfficientNet-B0 core-network (purple) and differ-ent certification-networks (triangles): CROWN-IBP trained Conv5 from Zhang et al. (2020) (red),CROWN-IBP trained Conv5 with κend = 0.5 (teal) and IBP trained Conv3 (blue). All selection-networks are IBP trained.
Figure 4: Natural and certified accuracy on TinyImageNet with ∞ = 1/255. We compare theLiRPA trained networks from Xu et al. (2020) WideResNet (black triangle), DenseNet (teal),ResNeXt (yellow), and CNN7+BN (red) with an ACE model (black squares) using the sameLiRPA trained WRN as certification-network and as feature extractor for the otherwise IBP trainedselection-network. The ACE model uses an EfficientNet-B0 core-network (purple).
Figure 5: Natural and adversarial accuracy for twoACE networks: one with SelectionNet + Conv3 andone with entropy selection + Conv2. We evaluateclassification networks on the full test set and itssubsets selected by the two selection mechanisms.
Figure 6: Width of the entropy range overadmissible perturbations. Samples are de-noted as adversarial if we can successfullyattack the certification-network and non-adversarial otherwise.
Figure 7: Natural and certified accuracy on CIFAR-10 with ∞ = 2/255. We compare individualConv5 networks (yellow dots), trained with CROWN-IBP and varying natural loss components, withdifferent ACE models (squares) based on an EfficientNet-B0 core-network (purple) and differentcertification-networks (triangles): CROWN-IBP trained Conv5 (teal) and IBP trained Conv3 (black).
Figure 8: Natural and certified accuracy on CIFAR-10 at ∞ = 2/255. ACE networks using a COLTtrained Conv3 network directly from Balunovic & Vechev (2020) as certification network and threedifferent selection networks, certified using DeepZ (dots) or MILP (squares).Selection networkstransferred from a different Conv3 network (teal), trained on certifiable correctness (brown) and onadversarial correctness (yellow).
Figure 9: Natural and certified accuracy of different COLT trained models on CIFAR-10 with∞ = 2/255. We compare individual Conv3 networks (yellow dots), trained with COLT and varyingnatural loss components, with ACE models (squares) using the same Conv3 certification-network(triangles), but different core-networks: a naturally trained EfficientNet-B0 (blue) and an adversari-ally trained EfficientNet-B0 (teal).
Figure 10: Illustration of the transformer for the exponential function for, from left to right t = xlb,minimum area: t = tcrit, t = xub and minimum area while strictly positive: t = tcrit,2 .
Figure 11: Illustration of the transformer for the logarithmic function for, from left to right t = xlb,minimum area: t = tcrit and t = xub .
Figure 12: Comparison of the looseness of various versions of the entropy transformer over thestandard deviation σ of the entries of the input zonotope error coefficient matrix drawn from thedistribution N (0, σ2). Adv is a lower bound to the optimal looseness obtained by adversariallyattacking the input region, described by the input zonotope.
