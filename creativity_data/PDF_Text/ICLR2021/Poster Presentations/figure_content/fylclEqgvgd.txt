Figure 1: Contact prediction pipeline. The Transformer is first pretrained on sequences from a largedatabase (Uniref50) via Masked Language Modeling. Once finished training, the attention mapsare extracted, passed through symmetrization and average product correction, then into a regression.
Figure 2: Left: Language modeling validation perplexity on holdout of Uniref50 vs. contact pre-cision over the course of pre-training. ESM-1b was trained with different masking so perplexitiesbetween the versions are not comparable. Right: Long range P@L performance distribution ofESM-1b vs. Gremlin. Each point is colored by the log of the number of sequences in the MSA usedto train Gremlin.
Figure 3: Gremlin (trRosetta) performance binned by MSA depth. For comparison, ESM-1b perfor-mance is also shown for the sequences in each bin.
Figure 4: Logistic regression weights trained only on contacts in specific ranges: local [3, 6), shortrange [6, 12), medium range [12, 24), long range [24, ∞).
Figure 5: Results on 15 CASP13 FM Domains colored by Neff.
Figure 6: (a) Gridsearch on logistic regression over number of training examples and number reg-ularization penalty. Values shown are long range P@L over a validation set of 20 proteins. (b)Per-head and layer weights of the logistic regression on the best ESM-1b model.
Figure 7: Short, medium, and long range P@L performance distribution of ESM-1b vs. Gremlin.
Figure 8:	Gremlin performance binned by MSA depth using both ESM (top) and trRosetta (bottom)MSAs. For comparison, ESM-1b performance is also shown for the sequences in each bin.
Figure 9:	Distribution of contact perplexity when evaluating different sequences from the sameMSA. The x-axis shows the index of each sequence, sorted in ascending order by hamming distancefrom the query sequence (query sequence is always index 0). The y-axis shows long range P@L.
Figure 10: L2 norm of weights for 3-classsecondary structure prediction by Transformerlayer.
Figure 11: Calibrated probability of a real con-tact given predicted probability of contact overall test proteins.
Figure 12: Distribution of precision for all reported statistics using 100 different logistic regressionmodels. Each regression model is trained on a random sample of N = 1, 10, 20 proteins.
Figure 13: (a) Distribution of Manhattan distance between the coordinates of predicted contactsand the nearest true contact at various thresholds of minimum P(Contact) A distance of zero cor-responds to a true contact. (b) Actual counts of predictions by Manhattan distance across the fulldataset (note y-axis is in log scale).
Figure 14: Illustration of two modes for ESM-Ib where significant numbers of spurious contacts arepredicted. (a) Predicted contacts which do occur in the full homodimer complex, but are not presentas intra-chain contacts. (b) CTCF protein contacts. A small band of contacts near the 30-residue off-diagonal is predicted by ESM-1b. This band, along with additional similar bands are also predictedby Gremlin.
Figure 15: Robustness of ESM-1b and TAPE models to insertions of Alanine at the beginning,middle, and end of sequence0 1 2 4 8 16 32 64 128 256Insertion Lengthis a homodimer and these contacts are present in the inter-chain contact map. This suggests thatsome ‘highly incorrect’ false positives may instead be picking up on inter-chain contacts. Fig. 14bshows an example of a repeat protein, for which evolutionary coupling methods are known to pickup on additional ‘bands’ of contacts (Espada et al., 2015; Anishchenko et al., 2017). Multiple bandsare visible in the Gremlin contact map, while only the first band, closest to the diagonal, is visiblein the ESM-1b contact map. More analysis would be necessary to determine the frequency of thesemodes, along with additional potential modes.
Figure 16: Left: Average change in contact precision vs. number of finetuning epochs over 380proteins. Right: Real and predicted contacts before and after evolutionary finetuning for 1a3a andavGFP. For 1a3a, long range P@L improves from 54.5 to 61.4. For avGFP, long range P@L im-proves from 7.9 to 11.4.
Figure 17: Contacts for 3qhp from Gremlin trained on pseudo-MSA generated by ESM-1b, com-pared to real and ESM-1b predicted contacts. The generated MSA achieves a long-range P@L of52.2 while the attention maps achieve a precision of 76.7.
