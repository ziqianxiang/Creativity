Figure 1: (A) Probabilistic scene graph representation. Each node represents an entity in the scene, and is as-sociated with an appearance variable. Each edge is associated with a pose variable that specifies the coordinatetransformation between the child node and the parent node. (B) Spatial attention during inference. We firstdecompose the scene into high-level objects, and then attend to each object to figure out the constituent parts.
Figure 2: Visualization of inferred scene graphs on 2D Shapes dataset.
Figure 3: Visualization of inferred scene graphs on Compositional CLEVR dataset.
Figure 5: (A) Objects sampled from GSGN learned prior. (B) Objects sampled from SPACE-O prior. (C)Scenes sampled from GSGN learned prior.
Figure 6: Comparison of data efficiency inpart-whole relationship.
Figure 7: Visualization of scene graphs inferred by GSGN-Mem on Compositional CLEVR dataset.
Figure 8: Learned memory of primitive parts. Each column corresponds to one slot. The first row shows thedecoded mask that captures the shape of the parts. The remaining rows are samples from the learned prior thatfill in plausible color, material, and lighting effects.
Figure 9: CNN architectures of (A) PresPoseApprPri(3), (B) PresPoseEnc(3), and (C) ApprEnc(3) used in ourthree-level GSGN. To implement GSGN-9, in which the maximum out-degree is 9, we just need to change thelayers in green so that the output feature maps have spatial size 3 Ã— 3.
Figure 10: CNN architectures of (A) BgPri and (B) BgEnc used in our three-level GSGN.
Figure 11: Segmentation results produced by Superpixel Hierarchy.
Figure 12: Visualization of inferred scene graphs on seven-part Compositional CLEVR dataset.
