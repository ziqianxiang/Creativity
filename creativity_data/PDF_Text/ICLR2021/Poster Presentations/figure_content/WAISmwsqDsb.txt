Figure 1: Architecture for the DINO framework. The Forward network performs a translation fromthe source to the target domain. The Reverse network performs the opposite translation and assignsan energy based on the its ability to recover source domain samples from real and generated samples.
Figure 2: The emphasis placed by the Reverse network (discriminator) on generated samples duringtraining.
Figure 3: Bidirectional training using the DINO framework. The two players are trained for both thegenerator and discriminator objectives. The top half of the diagram shows training with the greenplayer as the generator and the bottom of the diagram shows its training as the discriminator. In bothcases the blue player assumes the opposite role.
Figure 4: DINO framework architecture used for video-driven speech reconstruction. The Forwardnetwork (generator) takes a video as input and outputs a waveform. The Reverse network (dis-criminator) takes as input a waveform and outputs a video. Components that make up the Forwardnetwork are shown in blue and components belonging to the Reverse network are shown in green.
Figure 5:	Architecture used in the DINO framework for image-to-image translation experiments.
Figure 6:	The architecture of the Video Encoder (a) and Audio Encoder (b) used in the Forwardnetwork for video-to-audio translation.
Figure 7: The model for the Reverse network of the DINO framework when performing video-drivenspeech reconstruction.
Figure 8: Examples where the annotations in the segmentation map are not consistent with the realimage. However, the generated images will remain true to the segmentation map since they areconstructed from it.
Figure 9: Examples of images generated with and without an L1 reconstruction loss. The L1 lossimproves diversity both in the case of Pix2Pix and our proposed approach. Models trained withoutthis loss will generate faces with similar attributes (e.g. hair color, skin color, age).
Figure 10: Example showing how the balancing used in BEGAN fails to produce realistic images.
Figure 11: Image translation performed on the CelebAMask-HQ dataset. Translation is performedin the direction label → photo.
Figure 12: Image translation performed on the cityscapes dataset. Translation is performed in thedirection label → photo.
Figure 13: Examples of generated waveforms and their respective spectrograms. The real waveformand spectrogram is presented for comparison.
