Figure 1: (left, middle) expected squared error vs sample size n for kernel ridge regressionestimators with different kernels on f； and with two different budgets on optimizationdifficulty λmin (the minimum regularization parameter allowed). (right) ridge regressionwith one or two layers of random ReLU features on f2, with different scalings of the numberof “neurons” at each layer in terms of n.
