Figure 1: ALFWorld: Interactive aligned text andembodied worlds. An example with high-level textactions (left) and low-level physical actions (right).
Figure 2: BUTLER Agent consists of three modular components. 1) BUTLER::BRAIN: a text agentpre-trained with the TextWorld engine (indicated by the dashed yellow box) which simulates anabstract textual equivalent of the embodied world. When subsequently applied to embodied tasks,it generates high-level actions that guide the controller. 2) BUTLER::Vision: a state estimator thattranslates, at each time step, the visual frame vt from the embodied world into a textual observationot using a pre-trained Mask R-CNN detector. The generated observation ot, the initial observationo0, and the task goal g are used by the text agent the to predict the next high-level action at. 3)BUTLER::Body: a controller that translates the high-level text action at into a sequence of one ormore low-level embodied actions.
Figure 3: BUTLER::Brain: The text agent takesthe initial/current observations o0âˆ•ot, and goal g togenerate a textual action at token-by-token.
Figure 5: Beam search for recovery actions.
Figure 6: Domain Analysis: The performance of an expert across various environments.
