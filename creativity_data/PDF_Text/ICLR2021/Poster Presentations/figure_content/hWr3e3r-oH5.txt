Figure 1: The proposed architecture has two parts: modality fusion and open-max classification.
Figure 2: Visualization of class activation sequences for the target actions in two example videos:The ground-truth segments are shown in (a). The class activation sequences obtained without Lcontand Lpseu are shown in (b), which improve and get better aligned to the ground-truth segments whenthese continuity losses are used as shown in (c). The activation is depicted in gray-scale, where lowerintensity indicates more strong activation.
Figure 3: Visualization of the action localization result for an example video from ActivityNet1.2.
Figure 4: Qualitative results for action localization. Ground-truth (green), prediction by the visual-only method (orange), and prediction by the proposed method (blue) are shown. Class activationsequences are visualized below each prediction, darker shade means higher activation.
Figure 5: Examples where localization performance is degraded by audio.
