Figure 1: Comparison between NSSNN and HNN regarding the network design and predictionresults of a vortex flow example.
Figure 2: Comparisons of training and validation losses with different ω in the training process. Thesolid and dashed lines represent training and validation losses respectively. The networks are trainedby (a) the clean dataset, (b) the dataset with noise 〜 0.05U(-1,1), and (c) the dataset with noise〜0.4U(-1,1).
Figure 3: Comparisons of validation losses with different training loss functions in the trainingprocess. The red solid and dashed lines represent the networks trained by L1 loss function andvalidated by L1 and MSE respectively; the blue solid and dashed lines represent the networks trainedby MSE and validated by L1 and MSE respectively. The networks are trained by (a) the clean dataset,(b) the dataset With noise 〜0.05U(-1,1), and (C) the dataset With noise 〜0.4U(-1,1).
Figure 4: Comparisons of validation losses With different dt in the training proCess. (a), (b), and (C)are trained based on different time spans Ttrain = 0.01, 0.1, and 0.2, respeCtively.
Figure 5: Comparison of prediction results of (q, p) for the spring system H = 0.5(q2 + p2) fromt = 0 to t = 200 with (q0,p0) = (0, -3). The time span of the datasets are Ttrain = 0.4 (first row)and Ttrain = 1 (second row). The five columns are five different methods NeuralODE, HNN, IHNN,HRK, and NSSNN, respectively. The red line denotes the ground truth; the blue line denotes theprediction, which are perfectly overlapping in NSSNN. The prediction ability of HNN and IHNNimproves significantly with the decreasing of Ttrain of the dataset which however may be hard toobtain in the actual experimental measurements.
Figure 6: Comparison of prediction results of (q, p) for the Tao’s system H = 0.5(q2 + 1)(p2 + 1)from t = 0 to t = 20000 with (q0,p0) = (0, -3). The network is trained by the dataset with noise〜0.05U(—1,1), and the time span of the dataset is Ttrain = 0.2. The red line denotes the groundtruth; the blue line denotes the prediction, which are perfectly overlapping in NSSNN.
Figure 7: Taylor and Leapfrog vortex. We generate results of Taylor vortex and Leapfrop vortexusing NSSNN and HNN, and compare them with the ground truth. 6000 vortex elements are usedwith corresponding initial vorticity conditions of Taylor vortex and Leapfrop vortex.
Figure 8: (a) The forward pass of an NSSNN is composed of a forward pass through a differentiablesymplectic integrator as well as a backpropagation step through the model. (b) The schematic diagramof NSSNN.
Figure 9: Comparison of different ω (from left to right columns) with (a) and (e) ω = 0, (b) and(f) ω = 0.8, (c) and (g) ω = 0.9, (d) and (h) ω = 10 in the symplectic integrator for nonseparableHamiltonian H = (q2 + 1)(p2 + 1)/2. The upper row: projection of a trace [q(t), p(t), x(t), y(t)]with [q(0), p(0), x(0), y(0)] = (-3, 0, -3, 0) onto the q - p plane. The bottom row: deviation= k(q, p) - (x, y)k2 between (q, p) and (x,y).
