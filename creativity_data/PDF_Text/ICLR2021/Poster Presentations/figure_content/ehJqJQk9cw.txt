Figure 1: Classification accuracy of FL frameworks with 100 clients over latent distributions.
Figure 2: FedFomo client-to-client weights over time and across different FL settings. We reliablyupweight clients with the same training and target distributions.
Figure 3: Ablations over ε-greedy exploration and number of models downloaded on CIFAR-10.
Figure 4: Top Personalization on target distri-bution 6= that of local training data. BottomFedFomo upweights other clients with localdata 〜target distribution (5 latent non-IID dist.)	CIFAR-10	CIFAR-100Local Training	20.39 ± 3.36	7.40 ± 1.31FedAvg	23.11 ± 2.51	13.06 ± 1.48FedAvg + Data	42.15 ± 2.16	24.98 ± 4.98FedProx	39.79 ± 8.57	14.39 ± 2.85LG-FedAvg	38.95 ± 1.85	18.50 ± 1.10MOCHA	30.80 ± 2.60	13.73 ± 2.83Clustered FL	29.73 ± 3.67	19.75 ± 1.58Per-FedAvg	39.8 ± 5.38	21.30 ± 1.35pFedMe	43.7 ± 7.27	25.41 ± 2.33Ours (n=5)	64.06 ± 2.80	34.43 ± 1.48Ours (n=10)	63.98 ± 1.81	40.94 ± 1.62Table 3: Out-of-client distribution evaluationwith 5 latent distributions and 15 clients.
Figure 5: Left: Even with privacy-preserving updates, FedFomo still uncovers the underlying datadistributions at large. Right We gain privacy benefits without substantial drop in performance.
Figure 6: Client-to-client weights over time when personalizing for non-local target distributions.
Figure 7: Client-to-client weights over time when personalizing for local target distributions.
Figure 8: Visual overview for generating latent distributions using image classification datasets.
Figure 9: In-distribution accuracy over validation split ratio.
