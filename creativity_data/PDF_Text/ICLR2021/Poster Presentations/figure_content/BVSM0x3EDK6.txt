Figure 1: Top: Illustration that RandConv randomize local texture but preserve shapes in the image. Middle:First column is the input image of size 2242 ; following columns are convolutions results using random filtersof different sizes k. Bottom: Mixing results between an image and one of its random convolution results withdifferent mixing coefficients α.
Figure 2: Average accuracy and 5-run variance of MNIST model on MNIST-M, SVHN, SYNTHand USPS. Studies for: (a) original data fraction p for RCimg; (b) multiscale design (1-n refers tousing scales 1,3,..,n) for RCimg,p=0.5 (orange) and RCmix (blue); (c) consistency loss weight λ forRCimg1-7,p=0.5 (orange) and RCmix1-7 (blue).
Figure 3: t-SNE feature embedding visualization for digit datasets for models trained on MNISTwithout (top) and with our RCmix1-7,λ=10 approach (bottom). Different colors denote different classes.
Figure 4: Left: An image with texture and shapes at different scales; Middle: The output of RandConv witha small filter size which largely preserves the shapes of the stones. Right: The output of RandConv with alarge filter size distorts the shape of the stones as well.
Figure 5: Examples of the RandConv mixing variant RCmix7 on images of size 2242 with different mixingcoefficients α. When α = 1, the output is just the original image input;when α = 0, we use the output of therandom convolution layer as the augmented image.
Figure 6: RandConv data augmentation examples on images of size 2242. First column is the input image;following columns are convolution results using random filters of different sizes k. We can see that the smallerfilter sizes help maintain the finer shapes.
