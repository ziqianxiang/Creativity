Figure 1: Calibration graphs for an uncalibrated DenseNet-40 (Huang et al. (2017)) trained on CIFAR-10for top-1 class with a KS error of 5.5%, and top-1 accuracy of 92.4% on the test set. Here (a) shows the plotof cumulative score and probability versus the fractile of the test set, (b) shows the same information with thehorizontal axis warped so that the cumulative-score graph is a straight line. This is created as scatter plotsof cumulative (score, score): blue and (score, probability): orange. If the network is perfectly calibrated, theprobability line will be a straight line coincident with the (score, score) line. This shows that the network issubstantially overestimating (score) the probability of the computation. (c) and (d) show plots of (non-cumulative)score and probability plotted against fractile, or score. How these plots are produced is described in section 4.
Figure 2: The result of the spline calibration method, on the example given in fig 1 for top-1calibration. A recalibration function γ : IR → IR is used to adjust the scores, replacing fk (x) withγ (fk (x)) (see section 4.2). As is seen, the network is now almost perfectly calibrated when testedon the “calibration” set (top row) used to calibrate it. In bottom row, the recalibration function istested on a further set “test”. It is seen that the result is not perfect, but much better than the one infig 1d. It is also notable that the improvement in calibration is achieved without any loss of accuracy.
Figure 3: Top-2 predictions, Uncalibrated. Calibration graphs for an uncalibrated DenseNet-40 (Huanget al. (2017)) trained on CIFAR-10 for top-2 class with a KS error of 3.343% on the test set. Here (a) showsthe plot of cumulative score and probability versus the fractile of the test set, (b) shows the same informationwith the horizontal axis warped so that the cumulative-score graph is a straight line. This is created as scatterplots of cumulative (score, score): blue and (score, probability): orange. If the network is perfectly calibrated,the probability line will be a straight line coincident with the (score, score) line. This shows that the network issubstantially overestimating (score) the probability of the computation. (c) and (d) show plots of (non-cumulative)score and probability plotted against fractile, or score. How these plots are produced is described in Section 4 ofmain paper.
Figure 4: Top-2 predictions, Calibrated. The result of the spline calibration method, on the example given infig 3 for top-2 calibration. A recalibration function γ : IR → IR is used to adjust the scores, replacing fk (x)with γ(fk (x)) (see Section 4 of main paper). As is seen, the network is now almost perfectly calibrated whentested on the “calibration” set (top row) used to calibrate it. In bottom row, the recalibration function is testedon a further set “test”. It is seen that the result is not perfect, but much better than the original results in fig 3d.
Figure 5: Top-3 predictions, Uncalibrated. Calibration graphs for an uncalibrated DenseNet-40 trained onCIFAR-10 for top-3 class with a KS error of 1.277% on the test set. Here (a) shows the plot of cumulativescore and probability versus the fractile of the test set, (b) shows the same information with the horizontal axiswarped so that the cumulative-score graph is a straight line. (c) and (d) show plots of (non-cumulative) scoreand probability plotted against fractile, or score.
Figure 6: Top-3 predictions, Calibrated. The result of the spline calibration method, on the example given infig 5 for top-3 calibration. A recalibration function γ : IR → IR is used to adjust the scores, replacing fk (x)with γ(fk (x)). As is seen, the network is now almost perfectly calibrated when tested on the “calibration” set(top row) used to calibrate it. In bottom row, the recalibration function is tested on a further set “test”. It isseen that the result is not perfect, but much better than the original results in fig 5d.
Figure 7: Within-top-2 predictions, Uncalibrated. Calibration graphs for an uncalibrated DenseNet-40trained on CIFAR-10 for within-top-2 predictions with a KS error of 2.256% on the test set. Here (a) showsthe plot of cumulative score and probability versus the fractile of the test set, (b) shows the same informationwith the horizontal axis warped so that the cumulative-score graph is a straight line. (c) and (d) show plots of(non-cumulative) score and probability plotted against fractile, or score.
Figure 8: Within-top-2 predictions, Calibrated. The result of the spline calibration method, on the examplegiven in fig 7 for within-top-2 calibration. A recalibration function γ : IR → IR is used to adjust the scores,replacing fk (x) with γ(fk (x)). As is seen, the network is now almost perfectly calibrated when tested on the“calibration” set (top row) used to calibrate it. In bottom row, the recalibration function is tested on a further set“test”. It is seen that the result is not perfect, but much better than the original results in fig 7d.
Figure 9: Within-top-3 predictions, Uncalibrated. Calibration graphs for an uncalibrated DenseNet-40trained on CIFAR-10 for within-top-3 predictions with a KS error of 0.983% on the test set. Here (a) showsthe plot of cumulative score and probability versus the fractile of the test set, (b) shows the same informationwith the horizontal axis warped so that the cumulative-score graph is a straight line. (c) and (d) show plots of(non-cumulative) score and probability plotted against fractile, or score.
Figure 10: Within-top-3 predictions, Calibrated. The result of the spline calibration method, on the examplegiven in fig 9 for within-top-3 calibration. A recalibration function γ : IR → IR is used to adjust the scores,replacing fk (x) with γ(fk (x)). As is seen, the network is now almost perfectly calibrated when tested on the“calibration” set (top row) used to calibrate it. In bottom row, the recalibration function is tested on a further set“test”. It is seen that the result is not perfect, but much better than the original results in fig 9d.
