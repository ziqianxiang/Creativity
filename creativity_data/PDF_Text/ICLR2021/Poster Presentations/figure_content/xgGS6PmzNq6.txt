Figure 1: Comparison with adversarial training method (Bose & Hamilton, 2019b) in terms of thetradeoff between utility and fairness. Left: UNC28; Right: Citeseer. Blue points denote FairAdjwith different T2 values, red points represent (Bose & Hamilton, 2019b) with different λ values.
Figure 2: Diversity and utility in recommendations. Left: UNC28; Right: Citeseer. X-axis ‘propor-tion’ means we investigate the top x% valued links and check the ratio between inter and intra linksthat presented in y-axis.
Figure 3: An illustrative graph example with two protected groups S0 and S1. All vertices have self-loop. The expectation gap shrinks after mean aggregation. Here, ∣Ev〜U [v∣v ∈ So] — Ev〜U [v∣v ∈Si] ∣ = 20, σ = 2 and all link weights are equal. After aggregation, ∣Ev〜U [Agg(v)∣v ∈ So]—Ev〜U[Agg(v)∣v ∈ Si]∣ = ∣6.15 — (—6.15)∣ = 12.3 < 20.
Figure 4: Case 1: The maximal deviation term O(σ) is not negligible. Here σ = 100 and all linkweights are equal. All vertices have self-loop. |E。〜U[v|v ∈ So] - Ev〜U[v|v ∈ Si]| = 0. But aftermean-aggregation, |Ev〜U[Agg(v)∣v ∈ So] - Ev〜U[Agg(v)∣v ∈ Si]| = |5 - 25| = 20 > 0.
Figure 5: Case 2: The contraction coefficient α equals to 1. This happens when the graph is acomplete bipartite graph. Mean-aggregation fully exchanges the sensitive information and the gap oftwo groups remains unchanged.
Figure 6: Compare to adversarial training on vertex representations. Left: Oklahoma97; Right: Cora.
Figure 7: Diversity and utility in recommendations. Left: Oklahoma97; Right: Cora.
Figure 8: Evaluations on balance of clusters. Left: Oklahoma97; Right: UNC28.
