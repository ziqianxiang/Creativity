Figure 1: We explore a design space consisting of three design classes: (a) Single convolutionalnetwork models, (b) Depth-equivalent ensembles, and (c) Width-equivalent ensembles. The twoensemble design classes are created by distributing either the width factor or the depth correspondingto the single network amongst the ensemble networks while keeping the other factor fixed.
Figure 2:	The Ensemble Switchover Threshold (EST) occurs consistently across various networkarchitectures and data sets. Beyond this resource threshold, ensemble designs outperform singlenetwork models.
Figure 3:	Ensembles arrive at lower test error rates than single network models after the EST hasbeen reached.
Figure 4:	The Ensemble Switchover Threshold moves to the right as we increase the number ofnetworks in the ensemble.
Figure 5:	When ensemble designs can provide better accuracy, they can also do so faster than singlenetwork models (missing bars indicate that designs cannot reach single network model accuracy).
Figure 6:	Depth-equivalent ensembles take longer to train per epoch as compared to single networkmodels. Width-equivalent ensembles take comparable time.
Figure 7:	Width-equivalent ensembles take comparable time to single network models for inference.
Figure 8:	Both classes of ensemble models are significantly more memory efficient.
Figure A: Ensembles arrive at lower test error rates than single network models after the EST hasbeen reached.
Figure E: We break down per epoch training time into: (i) time spent per layer and (ii) total numberof layers. We observe that the total number of layers in the model more significantly determines theper epoch training time as compared to the width.
Figure F: Depth-equivalent (deq) ensembles take longer to train per epoch as compared to singlenetwork models. Width-equivalent ensembles (weq) take comparable time.
Figure G: Ensemble models take longer to perform inference.
Figure H: Ensemble models are significantly more memory efficient.
Figure I: We observe the same accuracy and resource related trends for DenseNets trained onImageNet32, a downsampled version of the ImageNet-1k data set (Chrabaszcz et al., 2017).
Figure J: We observe the same accuracy and resource related trends for ResNets trained on CIFAR-100with agressive data augmentation to mimic underfitting scenario. In particular, we use RandAugmentwith N = 2andM = 14 (Cubuk et al., 2020).
Figure K: We repeat our experiments with different total training budgets and set up the learningrate schedule proportionally for every budget. Here we show results for training DenseNets on theCIFAR-10 data set. We observe the same trend as the total budget increase, ensembles provide betteraccuracy and can train faster.
