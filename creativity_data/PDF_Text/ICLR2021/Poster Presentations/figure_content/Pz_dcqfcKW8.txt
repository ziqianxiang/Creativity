Figure 1: A simplified illustration of the similarity and difference between Streaming ASR and Full-context ASR networks. Modern end-to-end streaming and full-context ASR models share most ofthe neural architectures and training recipes in common, with the most significant difference in theASR encoder (highlighted). Streaming ASR encoders are auto-regressive models, with each pre-diction of the current timestep conditioned on previous ones (no future context). We show examplesof feed-forward layer, convolution layer and self-attention layer in the encoder of streaming andfull-context ASR respectively. With Dual-mode ASR, we unify them without parameters overhead.
Figure 2: Dual-mode convolution and average pooling layer for Dual-mode ASR.
Figure 3: Dual-mode self-attention layer.
Figure 4: Two speech-text pair comparison of Dual-model ASR models trained with and withoutinplace distillation by visualization of their streaming emission lattices. X-axis represents the speechinput frames while Y-axis represents the text output labels (tokens). Inplace distillation significantlyreduces emission latency of streaming mode in Dual-mode ASR models which is critical in real-world applications.
