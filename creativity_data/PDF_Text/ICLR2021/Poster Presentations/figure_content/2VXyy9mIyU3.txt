Figure 1: Dynamic sample sieves. Green circlesare clean examples. Red hexagons are corruptedexamples.
Figure 2: Loss distributions of training on CIFAR-10 with 40% symmetric noise (symm.) or 40%instance-based noise (inst.). The loss is given by '(f ⑴(Xn), yn) + 'cR(f (t)(xn)) - α%t as (4). CESieve represents the dynamic sample sieve with standard cross-entropy loss (without CR).
Figure 3: F-score comparisons on CIFAR10 under symmetric (Symm.) and instance-based (Inst.)ILl . I-	2∙Pre∙Re	lʌ C	Pn∈ [N] ɪ(Vn=1，yn = yn)	Λ P1	Pn∈[N ] l(vn=1,yn = yn)label noise. F-SCOre : = 2PPW，where Pre :=	pn]∈[N] l(Vn = 1)	，and Re :=	Pn∈[N]l(yn=yn)	.
Figure 4: Comparing our regularization with entropy regularization .
Figure 5: One example of CORES2. L(t): Indices of sieved clean examples. H(t): Indices ofsieved corrupted examples.。工⑴：={(xn,yn) : n ∈ L(t)}, Da(t)：= {(xn,yn) : n ∈ H(t)},DX,H(τ) := {xn : n ∈ H(τ)}.
Figure 6: Analyzing how the value of β influences the division. We set β = 0.5,2,10 for lower,proper, and higher beta settings, respectively.
