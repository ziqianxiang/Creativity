Figure 1: Two possible generative mappings thattransform distribution P to distribution Q.
Figure 2: Comparison of convergence ofW2GN (ours), MM-1, MM-2 approaches.
Figure 3: Images decoded from standard Gaussian latent noise (1st row) and decoded from the samenoise transferred by our cycle monotone map (2nd row).
Figure 4: Results of image-to-image style transfer by ConvICNN, 128 × 128 pixel images.
Figure 5: General architecture of an Input Convex Neural Network.
Figure 6: Dense Input Convex Neural Network.
Figure 7: Convolutional Input Convex Neural Network. All convolutional layers have 128 channels.
Figure 8: Convergence stages of our algorithm applied to fitting cycle monotone mappings (forwardand inverse) between distributions P (Gaussian) and Q (Mixture of 8 Gaussians).
Figure 9: Mixture of 100 GaUssians Q and distribution Vψθ ◦ P fitted by our algorithm.
Figure 10: ToV distributions fitted bv OUr algorithm.
Figure 11: An example of a "torn" generative mapping to a SwiSS Roll by a gradient of ICNN withReLU activationS.
Figure 12: Comparison of convergence speed of W2GN, MM-1 and MM-2 approaches in dimensionsD = 64, 256, 1024, 4096.
Figure 13: The pipeline of latent space mass transport.
Figure 14: Images decoded from standard Gaussian latent noise (1st row) and decoded from the samenoise transferred by our cycle monotone map (2nd row).
Figure 15: A pair of main principal components of CelebA Autoencoder’s latent space. From left toright: Z 〜N(0, I) [blue], mapped Z by W2GN [red], true autoencoders latent space [green]. PCAdecomposition is fitted on autoencoders latent space [green].
Figure 16: Results of Color Transfer between high resolution images (≈ 10 megapixel) by a pixel-wise cycle monotone mapping.
Figure 17: Results of Color Transfer between images by a pixel-wise cycle monotone mapping.
Figure 18: A pair of main principal components of feature spaces. From left to right: MNIST featurespace, mapped USPS features by W2GN, original USPS feature space. PCA decomposition is fittedon MNIST features. Best viewed in color (different colors represent different classes of digits 0 - 9).
Figure 19: Schematically presented image-to-image style transfer by a pair of ConvICNN fitted byour method.
Figure 20: Additional results of image-to-image style transfer on Winter2Summer and Photo2Monetdatasets.
Figure 21: Cases when the cycle monotone image-to-image style transfer by ConvICNN on Win-ter2Summer dataset works not well, 128 × 128 pixel images.
