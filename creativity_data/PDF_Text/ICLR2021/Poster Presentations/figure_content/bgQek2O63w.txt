Figure 1: Dangers of using non-robust representation learning. We use a non-robust self-supervisedlearning technique to learn image representations (i.e., BYOL; Grill et al., 2020). The right-handside shows Cifar- 1 0 images closest (in representation space using cosine similarity) to the queryimage on the left. The top row demonstrates that, when given an unmodified image of an airplane,the nearest matches resemble that query image either visually or semantically. The bottom rowdemonstrates that a seemingly identical image can be used to retrieve images of animals which areboth visually and semantically far from the query image.
Figure 2: Flow diagram that highlights the difference between BYOL and BYORL. Whereas BYOLdirectly tries to maximize the cosine similarity between q(z; θ) and z0, BYORL first executes anadversarial attack to retrieve an alternative image v.
Figure 3: Accuracy under `2 attack of size e = 128/255 for different CIFAR- 1 0 models as a functionof the ratio of available labels. Panel a restricts the available data to Cifar- 1 0 only (labeled andunlabeled), while panel b uses 500K additional unlabeled images extracted from 80M-TinyImages.
Figure 4: Accuracy under '∞ attack of size e% % %Ooo5 4 3Aue.Jnuue IS£ ISnqoa-∙- BYORLUAT-FT1%	2%	5% 10% 20%	50% 100%Percentage of labeled training data(b)	Cifar-1 0 and 80M-TinyImages8/255 for different CIFAR- 1 0 models as a functionof the ratio of available labels. Panel a restricts the available data to Cifar- 1 0 only (labeled andunlabeled), while panel b uses 500K additional unlabeled images extracted from 80M-TinyImages.
Figure 5: Accuracy on Cifar- 1 0 for different strengths of the color augmentation. Panel a shows theaccuracy under '∞ attacks of size e = 8/255, while panel b shows the corresponding clean accuracy.
Figure 6: Accuracy under '∞ attack of size e = 8/255 for different CIFAR-100 models as a functionof the ratio of available labels. The available data is restricted to Cifar- 1 00 only (labeled andunlabeled).
Figure 7: Clean accuracy of same models presented in Fig. 3.
Figure 8: Clean accuracy of same models presented in Fig. 4.
Figure 9: Loss landscapes around different Cifar- 1 0 test images. It is generated by varying the inputto the model, starting from the original input image toward either the worst attack found using PGD(u direction) or a random Rademacher direction (v direction). The loss used for these plots is themargin loss zy - maxi6=y zi (i.e., a misclassification occurs when this value falls below zero). Themodel used is the BYORL model trained against `2 perturbations on both CIFAR- 1 0 and a subset of80M-TINYIMAGES. The circular-shape represents the projected `2 ball of size = 128/255 aroundthe nominal image.
Figure 10: Loss landscapes around the clean image of different Cifar- 1 0 test images. It is generatedby varying the input to the model, starting from the original input image toward either the worstattack found using PGD (u direction) or a random Rademacher direction (v direction). The loss usedfor these plots is the margin loss zy - maxi6=y zi (i.e., a misclassification occurs when this valuefalls below zero). The model used is the BYORL model trained against '∞ perturbations on bothCIFAR-10 and a subset of 80M-TINYIMages. The diamond-shape represents the projected '∞ ballof size = 8/255 around the nominal image.
