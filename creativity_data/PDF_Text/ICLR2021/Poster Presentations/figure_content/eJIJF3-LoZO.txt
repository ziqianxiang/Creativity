Figure 1: Along each concept dimension, COMET learns concept embeddings using independentconcept learners and compares them to concept prototypes. COMET then effectively aggregatesinformation across concept dimensions, assigning concept importance scores to each dimension.
Figure 2: The effect of number of concepts on COMET’s performance. COMET consistentlyimproves performance when we gradually increase number of concept terms.
Figure 3: (Left) Quantitatively, on the Tabula Muris dataset COMET’s global importance scores agreewell with the ground truth important Gene Ontology terms estimated using differentially expressedgenes. (Right) Qualitatively, on the CUB dataset importance scores correctly reflect the most relevantbird features.
Figure 4: Top row shows images with beak concept embeddings most similar to the prototypical beak.
Figure 5:	Examples of automatically extracted landmarks using (Zhang et al., 2018) on the CUB1dataset.
Figure 6:	Examples of COMET's local explanations on the CUB dataset. Concepts are rankedaccording to the highest local concept similarity scores. Qualitatively, local importance scorescorrectly reflect the most relevant bird features.
Figure 7: Images ranked according to the distance of their belly concept embedding to the bellyconcept prototype. Most similar images (top) and most distant images (bottom). Images closest tothe prototype have clearly visible belly part that visually looks like prototypical belly of a chippingsparrow, whereas most distant images do not have belly part clearly visible.
