Figure 1: Left: On the I-Maze environment (see Sec. 5.1), there is a clear sample efficiency advan-tage of the Gated Transformer-XL (GTrXL) (Parisotto et al., 2019), which rapidly reaches 100%success rate compared to the LSTM. Center: When the x-axis is changed to wall-clock time, theLSTM becomes the more efficient model. Right: Table showing, for both 32-dim. LSTM and 4-layer GTrXL, (1) percentage of time the learner spends waiting for new on-policy trajectory datafrom distributed actor processes, (2) how many environment steps are processed per second (SPS)on a single actor process. We can see that for the much more computationally expensive transformer,the learner is spending a majority of its time idling and this is due to the order-of-magnitudes sloweractor inference. Plots averaged over 3 seeds, all run using reference machine A (Appendix B).
Figure 2: Top: An overview of distributed Actor-Learner Distillation, showing the processes asboxes and communication as arrows (data flow shown as blue arrows, parameter flow as orange).
Figure 3: Left: On the Meta-Fetch environment with 3 objects, we evaluated the importance ofthe ”Distillation steps per RL step” ratio. Shown on the left, as we increased this ratio we clearlyobserved an improved sample efficiency in the Actor-Learner Distillation procedure, until saturationat a ratio of 10. However, higher ratios came at the cost of substantial increase in wall-clock time, asthe high number of distillation steps quickly becomes the bottleneck of the system’s speed. Right:Parallelizing the distill processes using HOGWILD! improved the DpRL ratio without causing aslowdown in system speed. enabling an increase in data efficiency without a decrease in systemspeed, as shown in this result on 9x9 I-Maze.
Figure 4: Results on the 9 × 9 I-Maze environment for all models. Left: x-axis as number ofenvironment steps. Right: x-axis as wallclock time. All curves have 3 seeds. Obtained on referencemachine A (App. B).
Figure 5: Results on the Meta-Fetch environment with 4 objects. Left: y-axis as environment returns(objects fetched correctly per episode). Right: y-axis as success rate (all 4 objects fetched correctlyat least once in an episode). All curves have 3 seeds. Obtained on reference machine B (App. B).
Figure 6: Left: Value distillation consistently provides a slight improvement to results. Results herewere taken over a hyperparameter sweep with either value distillation enabled or disabled, and thebest performing curves were chosen from each setting. Center, Right: Plotting per-seed curves(Center) of results in 15 × 15 I-Maze reveals that the Asymm. AC and LSTM baseline spend asignificant amount of time achieving a mean success rate around 0.5 (quantified in the right-handbar plot). A success of 0.5 suggests both models have learnt to enter a goal but are not yet able to usetheir memory to make the inference between goal entered and indicator identity. In contrast ALDand GTrXL rapidly learn to reach a perfect return of 1 and do not spend much time near 0.5.
Figure 7: Left: Example of the 15 × 15-size I-Maze environment, with the indicator in this casebeing red. Center: An example of the agent observation, which is a 3-pixel-wide egocentric beamstarting in the direction of the agent’s orientation. The agent cannot see behind itself or throughwalls. Right: Example of the Meta-Fetch environment with 4 randomly located objects shown inbrown. The agent is shown in orange with its orientation indicated by the direction of the arrow.
Figure 8: Full wall-clock time curves. Top: 9x9 I-Maze success rate. Left: Meta-Fetch reward.
Figure 9: Per-seed curves for 9x9 I-Maze.
