Figure 1: Learned per-example training weights on Rotated MNIST. We visualise rotated digits and ro-tation distributions from both the datasets. We plot the learned example weights at iteration 500 of studenttraining as a function of rotation after discretising based on digit rotation. In the non-overlapping case (left),examples closer to the decision boundary are weighted most. When classes overlap (right), the more representa-tive examples with greater rotation are weighted highly and examples in the overlap region are downweighted,which is sensible as examples in the overlap region are less indicative of the class label.
Figure 2: Example weight curricula can speed up training. Test-set accuracy curves on CIFAR10/100 whenusing curriculum commentaries, non-curriculum commentaries, and no commentaries, during student networktraining. The learned curriculum commentary network which generates per-iteration example weights results inlearning speed improvements. This learning speed improvement holds when the student network is trained formany more steps than the number of inner loop update steps used during commentary network training (1500steps). This demonstrates that the commentaries generalise to longer training times.
Figure 3: Example weight curricula generalise across network architectures. Using a learned curriculumcommentary network trained with a simple 2 block CNN student, we apply these example weights to train twoResNet architectures. This gives improved test set accuracy curves for ResNet students also, indicating that thecommentaries generalise across architectures.
Figure 4: The learned blending augmentation is related to the class error rate. On digit 1s, a class withlow average error rate, the learned augmentation blends in large amounts of other digits so as to maximise thelearning signal. On digits with higher average error rates, such as 7s and 8s, the level of blending is very low soas to focus on classifying the class alone (rather than making the task more complex by adding another digit).
Figure 5: Blending proportions for selected CIFAR10 and CIFAR100 classes reveal interesting insights.
Figure 6: Learned attention masks highlight salient image regions for classification. We learn a com-mentary network to produce image attention masks on several image datasets, and the masks are qualitativelysensible in all cases. On Coloured MNIST, where the image label is determined by the red digit, the masksfocus on the red digit. On a dataset of chest X-rays, the masks focus on the chest cavity, which is the appropri-ate reason for detecting the condition in question (cardiomegaly). On CIFAR10/100, the masks are focused onimportant regions, such as the faces of animals, the hump of the camel, and the bodies of vehicles.
Figure 7: Learned masks on CUB dataset are primarily focused on the bird, rather than the background.
