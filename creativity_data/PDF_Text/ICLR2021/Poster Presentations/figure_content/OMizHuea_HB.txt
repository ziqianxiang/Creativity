Figure 1: (a) We extend contrastive learning to the cross-modal scenario and adapt momentumcontrast (MoCo) (He et al., 2020) to the dictionary update. Different from all existing work, Wepropose an active learning idea to the negative sampling. (b) To sample negatives, we use thegradient space of our key encoders to estimate the uncertainty of each candidate in audio/visualpools, and take a diverse set of negatives in that space using the k-MEANS++Ï„ algorithm.
Figure 2:	Effects of random sampling and active sampling on the number of categories.
Figure 3:	The effect of a) mutual information (Spatial-MultiOmniglot) and b) dictionary size on theaccuracy of classification (UCF101).
Figure 4:	Probability of sampling unique nega-tives (instances from different categories) in therandom vs. active sampling conditions. We com-pute the probabilities by averaging the number ofunique categories across iterations and dividingthem by their batch size.
Figure 5:	Center frames of video clips and their gradient norms selected by active sampling andrandom sampling.
Figure 6: Distribution of Kinetics-700 (Carreira et al., 2019) categories sorted by the predictionaccuracy.
