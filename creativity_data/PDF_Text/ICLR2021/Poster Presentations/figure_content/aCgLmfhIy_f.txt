Figure 1: The t-SNE visualization of relation representations and corresponding prototypes learnedby our model. In the right part, siï¼š6 are examples of input statements, where red and blue representthe head and tail entities, and the italics in parenthesis represents the relation between them.
Figure 2: An illustration of thegeometric explanation. Stars rep-resent prototypes and circles rep-resent statements.
Figure 3: Impact of # of relation typesFigure 4: Impact of # of instances per typeof relation types or amount of instances of each relation in training data. As shown in the figures,pre-trained relation encoders outperform the basic BERTEM model when short of training data.
Figure 4: Impact of # of instances per typeof relation types or amount of instances of each relation in training data. As shown in the figures,pre-trained relation encoders outperform the basic BERTEM model when short of training data.
Figure 5: A t-SNE visualization of the relation repre-sentations and prototypes of SemEval data.
Figure 6: A set of toy experiments on iris dataset to illustrate the distortion of decision boundaries forinstance-level and prototype-level learning.
