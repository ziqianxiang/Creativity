Figure 1: Implicit under-parameterization. Schematic diagram depicting the emergence of an effective rankcollapse in deep Q-learning. Minimizing TD errors using gradient descent with deep neural network Q-functionleads to a collapse in the effective rank of the learned features Φ, which is exacerbated with further training.
Figure 2: Offline RL. srankδ (Φ) and performance of neural FQI on gridworld, DQN on Atari and SAC onGym environments in the offline RL setting. Note that low rank (top row) generally corresponds to worse policyperformance (bottom row). Rank collapse is worse with more gradient steps per fitting iteration (T= 10 VS.
Figure 3: Data Efficient Online RL. srankδ (Φ) and performance of neural FQI on gridworld, DQN on Atariand SAC on Gym domains in the online RL setting, with varying numbers of gradient steps per environmentstep (n). Rank collapse happens earlier with more gradient steps, and the corresponding performance is poor.
Figure 4: (a) Fitting error for Q* prediction for n = 10 Vs n = 200 steps in Figure 3 (left). Observe that rankcollapse inhibits fitting Q* as the fitting error rises over training while rank collapses. (b) TD error for varyingvalues of n for Seaquest in Figure 3 (middle). TD error increases with rank degradation. (c) Q-networkre-initialization in each fitting iteration on gridworld. (d) Trend of srankδ (Φ) for policy evaluation based onbootstrapped updates (FQE) vs Monte-Carlo returns (no bootstrapping). Note that rank-collapse still persistswith reinitialization and FQE, but goes away in the absence ofbootstrapping.
Figure 5: Trend of srankδ (Φ) V.s. error on log scaleto the projected TD fixed point. A drop in srankδ (Φ)(shown as blue and yellow circles) corresponds to acorresponding increase in distance to the fixed point.
Figure 6: (a): srankδ (Φ) (top) and performance (bot-tom) of FQI on gridworld in the offline setting with200 gradient updates per fitting iteration. Note reducedrank collapse and higher performance with the regular-izer Lp (Φ). (b): Lp (Φ) mitigates the rank collapse inDQN and CQL in the offline RL setting on Atari.
