Figure 1: AdaSpeech.
Figure 2: (a) The overall structure of acoustic condition modeling. (b) Utterance-level acousticencoder. (c) Phoneme-level acoustic encoder, where phoneme-level mel means the mel-framesaligned to the same phoneme are averaged. (d) Phoneme-level acoustic predictor, where phonemehiddens is the hidden sequence from the phoneme encoder in Figure 1. ‘Conv1D (m, n)’ means thekernel size and stride size in 1D convolution is m and n respectively. ‘LN’ means layer normalization.
Figure 4: (a) The visualization of utterance-level acoustic vectors for several speakers (each numberin the legend represents a speaker ID in LibriTTS datasets). (b) The MOS of different adaptation dataon LJSpeech and VCTK.
