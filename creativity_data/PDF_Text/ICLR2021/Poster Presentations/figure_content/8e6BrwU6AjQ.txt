Figure 1: We study visual counting. Different from previous works that perform explicit, symboliccounting (left), we propose an implicit, holistic counter, MoVie, that directly modulates convolutions(right) and can outperform state-of-the-art methods on multiple benchmarks. Its simple design alsoallows potential generalization beyond counting to other visual reasoning tasks (bottom).
Figure 2: Overview of MoVie which can be placed on top of any convolutional features. The mod-ule consists of several modulated convolutional bottlenecks. Each bottleneck is a simple modifiedversion of the residual bottleneck, with an additional modulation block before the first convolution.
Figure 3: MoVie as a counting module for VQA. (a) A high-level overview of the current VQAsystems, image i and question q are fused to predict the answer a. (b) A naive approach to includeMoVie as a counting module: directly add pooled features V (with one FC to match dimensions) toi. (c) Our final design to train with two auxiliary losses on i and v, while during testing only usingthe joint branch aj. Shaded areas are used for both train and test; white areas are train-only.
Figure 4: Visualizations of attention maps on images and questions for several complex examples inTallyQA. First two rows show successful cases, and last two shows four failure ones. Best viewedin color on a computer screen. See text for detailed explanations.
Figure 5: Visualization of where MoVie helps MCAN for different question types on VQA 2.0 valset. We compute the probability by assigning each question to MoVie based on similarity scores(see Sec. E for detailed explanations). The top contributed question types are counting related,confirming that state-of-the-art VQA models that perform global fusion are not ideally designed forcounting, and the value of MoVie with local fusion. Best viewed on a computer screen with zoom.
Figure 6: Similar to Fig. 5 but with Pythia. Best viewed on a computer screen with zoom.
