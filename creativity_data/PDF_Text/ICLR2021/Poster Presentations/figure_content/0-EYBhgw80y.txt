Figure 1: Illustration of the normalized embedding space learned with MoPro. Samples from the same classgather around their class prototype, whereas OOD samples are separated from in-distribution samples. Labelcorrection and OOD removal are achieved based on a sample’s distance with the prototypes.
Figure 2: Proposed weakly-supervised learning framework. We jointly optimize a prototypical contrastive lossusing momentum prototypes, an instance contrastive loss using momentum embeddings, and a cross-entropyloss using pseudo-labels. The pseudo-label for a sample is generated based on its original training label, themodel’s prediction, and the sample’s distance to the prototypes.
Figure 3: Examples of randomly selected out-of-distribution samples filtered out by our method. The originaltraining labels are shown below the images.
Figure 4: Examples of randomly selected samples with noisy labels corrected by our method. The originaltraining labels are shown in red and corrected pseudo-labels are shown in green.
