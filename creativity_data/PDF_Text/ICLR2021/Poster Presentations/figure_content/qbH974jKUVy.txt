Figure 1: Testing generalisation in image reconstruction. (a) An illustration of different testsof combinatorial generalisation for the three-dimensional case (i.e., three generative factors). Theblank cells represent combinations that the model is trained on. Coloured cells represent noveltest combinations that probe different forms of generalisation: Recombination-to-Element (red),ReCombination-to-Range (green) and Extrapolation (blue) - see main text for details. (b) EaCh rowshows an example of training and test stimuli for testing a form of generalisation. In the top row,training set excludes ellipses in the bottom-right corner at less than 120Â° though they are present atthe bottom-right Corner at other rotations. In the middle row, training set exCludes squares in theright side of the image though other shapes and rotations are present at this location and squares areseen at all other combinations of rotations and translations. In the bottom row, training set excludesall shapes on the right side of the image.
Figure 2: Image reconstruction and disentanglement for the dSprites dataset (a) Top row showsexamples of input images and the four rows below show reconstructions by four different models.
Figure 3: Disentanglement vs reconstruction NLL. The relation between the level of disentan-glement and the performance of the model. Performance of the training data is plotted along withperformance in the test (generalisation) data. Disentanglement does not provide any help in perfor-mance for the end-to-end models. The ground truth decoder (GTD) is less affected, yet it is still thecase that it fails to generalize (see Figure 2 and Figure 4).
Figure 4: Image reconstructions and disentanglement for the Shapes3D dataset. We use thesame layout as in Figure 2. a) Reconstruction examples for each of the three generalisation condi-tions. For the first condition, the model has not seen magenta floors with purple cylinders, yet it isable to reconstruct them properly. For the second condition, it has not seen magenta oblong shapes,yet it has seen it in other colors and it has seen magenta on other shapes. Finally, the in the thirdcondition magenta floors have never been seen during training. b) Example Hinton diagrams of thecoefficients used to compute disentanglement. Diagram in each row corresponds to the model in thesame row in (a). Sparse matrices are better and the perfect one (up to permutation) is shown at thebottom.
Figure 5: Image composition task. (a) An example of the composition task. In this case, the shapeof the output must match the transform and the rest of the values must match the reference. (b)The general architecture used, based on the standard VAE. The model uses the same encoder onboth images. Then a transform takes latent representation samples and combines them to produce atransformed representation. This is used to produce the transformed image.
Figure 6: Image composition generalisation results (a) Each column shows an example trial whichconsists of a reference image, an action, a transform image and the transformed (output) image. Weshow examples of both training and test trials. Each of the training trials results in the correct(expected) transformed image, while each of the test trials shows a failure. (b) Visualisation of thedegree of disentanglement for three conditions by the model. The sparse representation reflects thehigh level of disentanglement achieved by these models in this task.
Figure 7: Disentanglement scores for dSprites. The disentanglement analysis results for thedSprites dataset. The scores for each of the metrics evaluated by the DCI framework: disentan-glement (left), overall disentanglement (middle) and completeness (right) for each of the conditions.
Figure 8: Hinton diagrams for dSprites dataset. The matrices of coefficients computed by theframework plotted as Hinton diagrams. These are used to obtain the quantitative scores in the panelabove. They offer a qualitative view of how the model is disentangling. On the left is how perfectdisentanglement looks in this framework.
Figure 9: Reconstructions for the dSprites dataset. For each condition and model, these are somereconstruction examples for both training and testing. There is general success and failure in theRecombination to Element (top) and Extrapolation (bottom) conditions, respectively. For this lastcondition, the models seem to reproduce the closest instance they have seen, which tranlated tothe middle of the image. For the Recombination to range (middle), the models tend to resort togenerating a blob at the right location, minimising their pixel-level error.
Figure 10: Disentanglement analysis for Shapes3D. The disentanglement analysis results for the3D Shapes dataset. The scores for each of the metrics evaluated by the DCI framework (Eastwood &Williams, 2018): disentanglement (left), overall disentanglement (middle) and completeness (right)for each of the conditions.
Figure 11: Hinton diagrams for 3DShapes dataset. The matrices of coefficients computed bythe framework plotted as Hinton Diagrams. As discussed in the main text, these matrices offera qualitative view of how the model is disentangling. In general, sparse matrices indicate higherdisentanglement. It is clear from these diagrams that the degree of disentanglement varies over abroad range for the tested models.
