Figure 1: The overview of Capsule Networks: the CapsNet architecture consists of four components,i.e., primary capsule extraction, voting, routing, and class-conditional reconstruction.
Figure 2: The left-to-right columns correspond to statistics of predictions on clean images, underCaps-Attack, and under Vote-Attack, respectively. The first row corresponds to the statistics onground-truth classes, and the second row corresponds to the classes with the largest output proba-bilities that are not ground-truth (L-NGT) classes. In each subplot, the x-axis indicates the cosinesimilarity value between the vote o外 and the output capsule Vj. The blue histogram shows thepercentage of votes falling in bins divided by the similarity values in x-axis. The green histogramcorresponds to the strength of votes (the averaged length of the votes Uj∣i). The red curve presentsthe averaged weight (i.e., cij, see Equation (2)) of votes at each bin. Please refer to the main contextfor more in-depth analysis of this figure.
Figure 3: This figure shows the clean images and the corresponding adversarial images createdby Caps-Attack and Vote-Attack in a targeted setting. The attack target class is set to the digit 0.
Figure 4: The first subfigure shows clean test images of the SVHN dataset. The second subfigureshows the adversarial images created by Caps-Attack. Different rows correspond to different weightsto reduce reconstruction error in Equation (6) (i.e., the second attack step in detection-aware attackmethod). Some images are flipped, and some hard ones are not. The images in the third subfigureare the adversarial images created by Vote-Attack. There is no obvious visual difference between theadversarial examples created by the two attacks. To be noted that the images are randomly selected(not cherry picked).
