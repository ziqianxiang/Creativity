Figure 1: Confidential and Private Collaborative (CaPC) Learning Protocol: (ɪɑ Querying party Pi* sendsencrypted query q to each answering party Pi, i = i*. Each Pi engages in a secure 2-party computation protocolto evaluate Enc(q) on Mi and outputs encrypted logits Enc(ri). ^b Each answering party, Pi, generates arandom vector ιri, and sends Enc(ri - ri) to the querying party, Pi*, who decrypts to get r — ιri. ^c Eachanswering party Pi runs Yao,s garbled circuit protocol (Yi) with querying party Pi* to get Si for Pi* and Si forPi s.t. Si + Si is the one-hot encoding of argmax of logits. Each answering party sends Si to the privacyguardian (PG). The PG sums Si from each Pi and adds Laplacian or Gaussian noise for DP. The querying partysums Si from each Yi computation. The PG and the querying party run Yao,s garbled circuit Ys to obtainargmax of querying party and PG,s noisy share. The label is output to the querying party.
Figure 2: Using CaPC to improve model performance. Dashed lines represent mean accuracy.
Figure 3: Using CaPC with active learning to improve balanced accuracy under non-uniformdata distribution. Dashed lines are balanced accuracy (BA). We observe that all sampling strategiessignificantly improve BA and the best active learning scheme can improve BA by a total of 9.94percentage-points (an additional 0.8 percentage points over Random sampling) on CIFAR10 (left)and a total of 5.67 percentage-points (an additional 0.38) on SVHN (right).
Figure 4: Accuracy gain for balanced SVHNusing CaPC versus number of parties and pri-vacy budget, ε. With more parties, we can achievea higher accuracy gain at a smaller bound on ε.
Figure 5: Using CaPC to improve each party,s model performance on the CIFAR10 dataset.
Figure 6: Using CaPC to improve each party,s model performance on the SVHN dataset. Weobserve that all querying parties (QPs) see a net increase overall, with nearly every class seeingimproved performance.
Figure 7: Using CaPC to improve each party,s heterogeneous model performance on the SVHNdataset. Each querying party adopts a different model architecture (1 of 3) and ∣ of all answeringparties adopt each model architecture. All model architectures see benefits from using CaPC.
Figure 8: Using CaPC to improve model performance on balanced MNIST on Fashion-MNIST.
Figure 9: Using active learning to improve CaPC fairness. We observe that underrepresentedclasses are sampled more frequently than in a random strategy.
Figure 10: Using CaPC with active learning to improve balanced accuracy under non-uniformdata distribution. Dashed lines are balanced accuracy (BA). We observe that all sampling strategiessignificantly improve BA and the best active learning scheme can improve BA by a total of 10.10percentage-points (an additional 0.45 percentage points over Random sampling) on MNIST (left)and a total of 10.94 percentage-points (an additional 2.48) on Fashion-MNIST (right).
Figure 11: Tuning the amount of noise (σ) in CaPC. We tune the amount of Gaussian noise thatshould be injected in the noisy argmax mechanism by varying the standard deviation. We choosethe highest noise: σ = 7 for CIFAR10, σ = 40 for SVHN, MNIST, and Fashion-MNIST, withouthaving a significant impact on the model accuracy, allowing a minimal privacy budget expenditurewhile maximizing utility. We train 50 models for CIFAR10 and 250 models for SVHN, mNiST, andFashion-MNIST.
Figure 12: Accuracy gain for balanced MNISTusing CaPC versus number of parties and pri-vacy budget, ε. With more parties, we can achievea higher accuracy gain at a smaller bound on ε.
Figure 13: Measuring the CPU, Network (NET), and Memory (MEM) usage over time forCaPC. We use the CryptoNet-ReLU model provided by HE-transformer (Boemer, 2020) and sar (Go-dard, 2020) (System Activity Report) to perform this micro-analysis. We label the steps accordingto the CaPC protocol shown in Figure 1. The network usage reaches its peaks during execution ofReLU and then MaxPool, where the intermediate feature maps have to be exchanged between thequerying and answering parties for the computation via garbled circuits.
