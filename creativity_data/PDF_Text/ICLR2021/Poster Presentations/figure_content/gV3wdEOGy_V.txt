Figure 2: Visualization of the image embeddings of MiCE on CIFAR-10 with t-SNE. Different colorsdenote the different ground-truth class labels (unknown to the model). The cluster ACC is shown inthe parenthesis. MiCE learns a clear cluster structure that matches the latent semantics well. Bestview in color.
Figure 3: The histogram of (left) approximate posterior distributions of MiCE at the initial andfinal stage of training and (right) the predicted cluster labels obtained during testing. Here, we trainand evaluate the model using CIFAR-10 which has 10 classes and 60,000 images. We divide theprobability distribution into 10 discrete bins. Best view in color.
Figure 4: Visualization of the image embeddings of MiCE (upper row) and MoCo (lower row) onCIFAR-10 with t-SNE. Different colors correspond to various cluster labels obtained based on theposterior distribution (MiCE) or spherical k-means (MoCo). The embeddings of MiCE depict a clearcluster structure, as shown in (c). In contrast, the structure in (f) is ambiguous for a large portion ofdata and it does not match the cluster labels well.
Figure 5: Visualization of the image embeddings of MiCE (upper row) and MoCo (lower row) onCIFAR-10 with t-SNE. Different colors denote the different ground-truth class labels (unknown tothe model). Comparing to MoCo, the clusters learned by MiCE better correspond with the underlyingclass semantics.
