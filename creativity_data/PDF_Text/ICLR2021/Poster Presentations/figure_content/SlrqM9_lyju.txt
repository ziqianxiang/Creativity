Figure 1: Comparison of different LR schedules in training ResNet-50 on ImageNet (a, b), and the Transformerbase model (c, d). When training ResNet-50, AutoLRS, CLR, SGDR, and the original LR achieve 75.9% top-1accuracy at epoch 74, 70, 88, and 90, respectively. When training Transformer base, AutoLRS, SGDR, andoriginal achieve 27.3 BLEU score (uncased) at step 69,000, 91,000, 98,000, respectively. CLR (the best we wereable to find) achieves 27.2 BLEU score at step 99,000.
Figure 2: Comparison of different LR schedules and training loss in pre-training BERTBASE.
Figure 3: Fitting the time-series of loss by exponential model when training ResNet-50 on ImageNet.
Figure 4: Examples of forecasting the loss series by various time-series forecasting models when trainingResNet-50 on ImageNet. Our simple exponential prediction model yields the least mean squared error (MSE)among all the models.
Figure 5: The loss sequence in Figure 3c and its quadratic spline smoothing result after 1, 5, and 10 iterations ofour spline smoothing.
Figure 6: BO's posterior of the black-box objective function after exploring i LRs (red dots ∙) determined byEq. (3) at an early stage and a late stage during the training of ResNet-50 on ImageNet. The dashed lines showthe mean function μi(η) (indicating the predicted validation loss of applying LR η for T steps) and the shadedareas show the standard deviation σi (η) (indicating the prediction uncertainty) in the form of μi (η) ± σi (η).
