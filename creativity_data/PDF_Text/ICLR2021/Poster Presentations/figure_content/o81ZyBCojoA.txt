Figure 1: RA of meta-models trained by stan-dard MAML, R-MAMLboth and R-MAMLoutversus PGD attacks of different perturbationsizes during meta-testing. Results show that ro-bustness regularized meta-update with standardfine-tuning (namely, R-MAMLout) has alreadybeen effective in promotion of robustness.
Figure 2: Visualization of a randomlyselected neuron’s inverted input attri-bution maps (IAMs) under differentmeta-models. The first row shows theseed images. The second-fourth rowsshow IAMs corresponding to modelstrained by MAML, R-MAMLboth ,and R-MAMLout , respectively. Ex-cept MAML, R-MAMLboth andR-MAMLout all catch high-levelfeatures from the data.
Figure S1:	Visualization of a randomly selected neuron’s inverted input attribution maps (IAMs) before fine-tuning and after fine-tuning in meta-testing. The model is obtained by R-MAMLout . The second row showsIAMs of the model before fine-tuning. The third row shows IAMs of the model after fine-tuning. One canfind that the difference between the IAMs before fine-tuning and after fine-tuning is small, suggests that robustmeta-update itself can provide the robustness adaptation without additional adversarial training.
Figure S2:	RA versus (testing-phase) PGD attacks at different values of perturbation strength . Here therobust models are trained by R-MAMLout-TRADES and R-MAMLout . Each method trains two models underthe training attack strength of = 2, 4, respectively. Results show that R-MAMLout -TRADES has the abilityto defend stronger attacks than R-MAMLout .
Figure S3: Performance of R-MAMLout(TRADES) and AQ (Goldblum et al., 2019) on Omniglotversus number of classes in each task (from 5 to 20 ways): (a) RA. (b) SA.
