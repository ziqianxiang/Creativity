Figure 1: Computation graphs of loss function examples: (a) Cross-entropy loss; (b, C) Searchedloss candidates with comparable performance to Cross-entropy loss; (d) Searched best-performedloss named CSE-Autoloss-Acls.
Figure 2: An overview of the proposed CSE-AUtoloss pipeline. Our CSE-AUtoLoss first generatesa large amount of candidate loss functions by assembling formulations based on the well-designedsearch space. Then CSE-Autoloss filters out more than 99% divergent, training-unfriendly, or poor-performed loss candidates by evaluating them with the proposed convergence-simulation modules,i.e. convergence property verification and model optimization simulation, which verifies mathemat-ical property and optimization quality. After that, K top-performing loss functions are selected toevaluate on the proxy task to further obtain top-P loss candidates as parents to derive offspring forthe next generation. Please see more details about CSE-Autoloss in Algorithm 1.
Figure 4: Visualization of the CSE-Autolossand vanilla evolution search for FCOS, wherethe evaluated loss individuals are scatteredas orange and blue respectively. With ourconvergence-simulation modules, the number ofevaluated loss candidates is largely reduced.
Figure 3: Evaluation results of popular hand-crafted loss combinations and CSE-Autoloss-Awith Faster R-CNN R-50 on COCO val. Differ-ent loss functions have various convergence be-haviors, and CSE-Autoloss-A achieves the bestperformance compared with other loss combi-nations by a large margin.
