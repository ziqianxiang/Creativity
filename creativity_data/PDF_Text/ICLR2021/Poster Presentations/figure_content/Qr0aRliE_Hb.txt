Figure 1: Illustration of the augmented policy approximatorThe systems use a continuous action space for precision prediction. At each time step t,the continuousaction at is mapped to the discrete bit value bk for layer k using bk = round(bmin - 0.5 + ak X(bmax - bmin + 1)). The reward function is computed using R = λ × (accquant - accorigin).
Figure 2:	Results for search stage. Top Row: Accuracy. Middle Row: Coefficient of Variance (CV).
Figure 3:	Finetune accuracy. (Horizontal dashed line: the original accuracy without quantization.)Figure 3 illustrates the accuracy results of the finetune stages for three different precision settings:the one selected by P-ADRL; the one selected by HAQ+E and the one selected by the original HAQ.
Figure 4:	The bit value of each layer for (a) CifarNet (left) and AlexNet (right), (b) ResNet20 and (c)ResNet50. The methods for quantization are ADRL and HAQ.
Figure 5:	The bit values being selected in each search episode for the four networks.
