Figure 1: Average nuclear norm across factorized layers of ResNet20 during CIFAR-10 trainingwhen initialized regularly (left) and using SI (center); the dotted line is the upper bound on thenuclear norm regularized by weight-decay (2). The right plot track the same quantities for the caseof regular weight-decay across different rank-scales. “no decay (normalized)” normalizes matrixfactors after each step to have the same norm as “Frobenius decay ” (detailed in Section 3.3).
Figure 2: Comparison of weight-decay and FD at different regularization levels (left) and differentrank-scales (center and right) when training factorized ResNets on CIFAR.
Figure 3: Traces depicting training of low-rank ResNet-20 with different decay settings; “no decay(normalized)” normalizes matrix factors after each step to have the same norm as “Frobenius decay.”The effective step size (right) is the average over convolution layers i of η{}UiViT }2F.
Figure 4: Transformer performance onIWSLT-14 as a function of regulariza-tion (top) and compression (bottom).
