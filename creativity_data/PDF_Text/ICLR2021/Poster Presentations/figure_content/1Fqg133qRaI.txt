Figure 1: Synthetic results on 10242 resolution of our model, trained from scratch on single RTX2080-Ti GPU, with only 1000 images. Left: 20 hours on Nature photos; Right: 10 hours on FFHQ.
Figure 2: The causes and challenges for trainingGAN in our studied conditions.
Figure 3: The structure of the skip-layer excitation module and the Generator. Yellow boxes repre-sent feature-maps (we show the spatial size and omit the channel number), blue box and blue arrowsrepresent the same up-sampling structure, red box contains the SLE module as illustrated on the left.
Figure 4: The structure and the forward flow of the Discriminator. Blue box and arrows representthe same residual down-sampling structure, green boxes mean the same decoder structure.
Figure 6: Latent space back-tracking and interpolation.
Figure 5: Qualitative comparison between our model and StyleGAN2 on 10242 resolutiondatasets. The left-most panel shows the training images, and the right two panels show the un-curated samples from StyleGAN2 and our model. Both models are trained from scratch for 10 hourswith a batch-size of 8. The samples are generated from the checkpoint with the lowest FID.
Figure 7: Style-mixing results from our model trained for only 5 hours on single GPU.
