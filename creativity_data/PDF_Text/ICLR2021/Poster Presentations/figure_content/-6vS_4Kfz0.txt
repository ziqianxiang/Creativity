Figure 1: Workflow of Graph RL agent mapping weights (W) and activations (A) of each layer of atrained neural network workload to various on-board memory components (e.g. DRAM, SRAM).
Figure 2: EGRL Architecture: EA and PG operate concurrently via a shared replay buffer. EAcomprises sub-populations of GNN and Boltzmann policies. PG policy periodically migrates to EA.
Figure 3: Speedup for different workloads, normalized to the heuristic compiler performance. EGRLconsistently outperforms all baselines. Error bars indicate standard deviation over n = 5 runs.
Figure 5: UMAP projection illustrating mappings that achieve compiler-competitive performance(speedup of ã€œ1), the best mappings, and the compiler's mapping (highlighted with a red arrow).
Figure 6: Memory map shifts Top: For each memory unit on the y-axis, the corresponding row showshow EGRL changed the distribution of tensors originally mapped to it by the compiler. Bottom:Memory maps from the compiler vs the best ones found by EGRL for ResNet-50 and ResNet-101.
