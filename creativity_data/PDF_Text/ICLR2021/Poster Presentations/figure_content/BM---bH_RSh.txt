Figure 1: An example of the neural network-based recommendation system: the deeplearning recommendation model (DLRM),proposed by Naumov et al. (2019).
Figure 2: Results on RS prediction model com-pression by different methods on the Criteo AILabs Ad Kaggle dataset.
Figure 3: Results on RS prediction model com-pression by different methods on the Criteo AILabs Ad Terabyte dataset.
Figure 4: Results on RS input feature selectionby different methods on the Criteo AI Labs AdKaggle dataset.
Figure 5: Results on RS input feature selectionby different methods on the Criteo AI Labs AdTerabyte dataset.
Figure 6: The number of pruned features/neurons for each layer during the training process usingUMEC with Rbudget = 0.5 ×pf(W0) on the Criteo AI Labs Ad Kaggle dataset, wherepf(W0) denotesthe Flops of the original dense model. For the input layer, the mentioned dense model has 27 featuresin total. For the two hidden layers, it has 512 and 256 neurons respectively. The convergency of thebinary cross entropy (BCE) loss during training is shown in Figure 7 in the appendix.
Figure 7: The convergency of the bi-nary cross entropy (BCE) loss duringtraining using UMEC with Rbudget =0.5 × pf (W0), where pf (W0) denotesthe Flops of the original dense model.
Figure 8: Results on the pipeline with a cas-cade of input feature selection and predictionmodel compression, and comparison with thecorresponding jointly optimized framework.
Figure 9: Results on the pipeline with a cas-cade of embedding dimension reduction andprediction model compression, and compari-son with the corresponding jointly optimizedframework.
