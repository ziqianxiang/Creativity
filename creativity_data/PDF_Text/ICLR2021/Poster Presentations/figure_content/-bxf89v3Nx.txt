Figure 1: Illustration of a conditional distribution P(Y |X) with scalar feature and target. We considera Gaussian predictive model P, obtained by ordinary least squares regression with 100 training datapoints (orange dots). Empirically the predicted quantiles on 50 validation data points appear close tobeing calibrated, although model P is uncalibrated according to Definition 1. Using the frameworkin this paper, on the same validation data a statistical test allows us to reject the null hypothesis thatmodel P is calibrated at a significance level of α = 0.05 (p < 0.05). See Appendix A.1 for details.
Figure 2: Empirical test errors for 500 data sets of n ∈ {4, 16, 64, 256, 1024} samples from modelswith targets of dimension d = 10. The dashed black line indicates the set signficance level α = 0.05.
Figure 3: Mean squared error (MSE), average negative log-likelihood (NLL), SKCEk (SKCE(biased)), and p-value approximation (p-value) of ten Gaussian predictive models for the Friedman 1regression problem versus the number of training iterations. Evaluations on the training data set(100 samples) are displayed in green and orange, and on the test data set (50 samples) in blue andpurple. The green and blue line and their surrounding bands represent the mean and the range of theevaluations of the ten models. The orange and purple lines visualize the evaluations of their ensemble.
Figure 4:	Data generating distribution P(Y|X) and predicted distribution P(Y|X) of the linearregression model. Training data is indicated by orange dots.
Figure 5:	Cumulative probability versus quantile level for the linear regression model on the validationdata (orange curve). The green curve indicates the theoretical ideal for a quantile-calibrated model.
Figure 6: Mean absolute error and variance of 500 calibration error estimatesn ∈ {4,16, 64, 256,1024} samples from the calibrated model of dimension d = 1.
Figure 7: Mean absolute error and variance of 500 calibration error estimates forn ∈ {4,16, 64, 256,1024} samples from the calibrated model of dimension d = 10.
Figure 8: Mean absolute error and variance of 500 calibration error estimates10-1∙2-- -MO Oɪ II①u8lu10-2∙4-10-3∙2-10-4∙o-10-4.8_# sampleso SKCE ---SKCE (B = 2)SKCE (B = √n) O SKCE (B = n)time [s]①uueue>Figure 9:	Mean absolute error and variance of 500 calibration error estimates for data sets ofn ∈ {4,16, 64, 256,1024} samples from the uncalibrated model of dimension d = 10.
Figure 9:	Mean absolute error and variance of 500 calibration error estimates for data sets ofn ∈ {4,16, 64, 256,1024} samples from the uncalibrated model of dimension d = 10.
Figure 10:	Empirical test errors for 500 data sets of n ∈ {4, 16, 64, 256, 1024} samples from modelswith targets of dimension d = 1. The dashed black line indicates the set signficance level α = 0.05.
Figure 11:	Empirical test errors for 500 data sets of n ∈ {4, 16, 64, 256, 1024} samples from modelswith targets of dimension d = 10. The dashed black line indicates the set signficance level α = 0.05.
Figure 12: Estimates of different accuracy and calibration measures of ten Gaussian predictive modelsfor the Friedman 1 regression problem versus the number of training iterations. Evaluations on thetraining data set (100 samples) are displayed in green and orange, and on the test data set (50 samples)in blue and purple. The green and blue line and their surrounding bands represent the mean and therange of the evaluations of the ten models. The orange and purple lines visualize the evaluations oftheir ensemble.
