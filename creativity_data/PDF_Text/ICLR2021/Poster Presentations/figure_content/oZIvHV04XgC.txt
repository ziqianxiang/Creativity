Figure 1: Online contextualized few-shot learning. A) Our setup is similar to online learning,where there is no separate testing phase; model training and evaluation happen at the same time. Theinput at each time step is an (image, class-label) pair. The number of classes grows incrementally andthe agent is expected to answer “new” for items that have not yet been assigned labels. Sequencescan be semi-supervised; here the label is not revealed for every input item (IabeIed/unlabeled shownby red solid/grey dotted boxes). The agent is evaluated on the correctness of all answers. Themodel obtains learning signals only on labeled instances, and is correct if it predicts the label ofpreviously-seen classes, or ‘new’ for new ones. B) The overall sequence switches between differentlearning environments. While the environment ID is hidden from the agent, inferring the currentenvironment can help solve the task.
Figure 2: Sample online contextualized few-shot learning sequences. A) RoamingOmniglot. Redsolid boxes denote labeled examples of Omniglot handwritten characters, and dotted boxes denoteunlabeled ones. Environments are shown in colored labels in the top left corner. B) Image framesamples of a few-shot learning sequence in our RoamingRooms dataset collected from a randomwalking agent. The task here is to recognize and classify novel instance IDs in the home environment.
Figure 4: Contextual prototypical memory.
Figure 5: Few-shot classification accuracy over time. Left: RoamingOmniglot. Right: Roamin-gRooms. Top: Supervised. Bottom: Semi-supervised. An offline logistic regression (Offline LR)baseline is also included, using pretrained ProtoNet features. It is trained on all labeled examplesexcept for the one at the current time step.
Figure 7: Additional statistics about our RoamingRooms dataset.
