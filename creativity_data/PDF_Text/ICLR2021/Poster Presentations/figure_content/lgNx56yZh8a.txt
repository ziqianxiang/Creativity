Figure 1: Reliability diagrams, expected calibration error (ECE), maximum calibration error (MCE),and Brier Score (BRI) for 5-shot 5-way tasks on CUB (additional calibration results can be found inAppendix I). Metrics are computed on 3,000 random tasks from the test set. The last two plots areour proposed method.
Figure 2: Accuracy (↑) and Brier Score Q) When corrupting both support and query with Gaussiannoise on 5-way 5-shot tasks. Quantitative results may be found in Appendix J.
Figure 3: Average AUROC (↑) for out-of-episode detection. The AUC is computed separately foreach episode and averaged across 1,000 episodes. Bars indicate a 95% bootstrapped confidenceinterval.
Figure 4: Histogram and kernel density estimate of confidence for randomly generated functionsamples fc 〜N(0,1). Normalized output probabilities were computed for C = 5 and a histogramof maxc p(y = c|f) was computed for 50,000 randomly generated simulations.
Figure 5: Plot of L(f | y = 1), where f3 is clamped to 0. The Gaussian likelihood penalizes configu-rations far away from (f1, f2) = (1, -1). Logistic softmax is much flatter compared to softmax andhas visibly different contours. One-vs-Each is visually similar to the softmax but penalizes (f1 , f2)near the origin slightly more.
Figure 6: Plot of posterior p(f | y = 1), where f3 is clamped to 0. The mode of each posteriordistribution is similar, but each differs slightly in shape. Gaussian is more peaked about its mode,while logistic softmax is more spread out. One-vs-Each is similar to softmax, but is slightly moreelliptical.
Figure 7: Training points (colored points) and maximum predictive probability for various like-lihoods on the Iris dataset. The Gaussian likelihood produces more warped decision boundariesthan the others. Logistic softmax tends to produce lower confidence predictions, while one-vs-eachproduces larger regions of greater confidence than the others.
Figure 8: Comparison across likelihoods in terms of test predictive accuracy, Brier score, expectedcalibration error (computed with 10 bins), and ELBO. Results are averaged over 200 randomlygenerated splits for each training set size (1, 2, 3, 4, 5, 10, 15, 20, 25, and 30 examples per class).
Figure 9: Reliability diagrams, expected calibration error, maximum calibration error, and Brierscores for 5-shot 5-way tasks on mini-Imagenet, Omniglot→EMNIST, and mini-Imagenet→CUB.
