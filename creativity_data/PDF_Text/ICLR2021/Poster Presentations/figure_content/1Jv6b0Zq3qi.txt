Figure 1:	Virtual ensemblewhere γ is regularization parameter. If the number of all possible trees is finite (a natural assumptiongiven that the training dataset is finite), then the SGLB parameters θ(t) at each iteration form aMarkov chain that weakly converges to the stationary distribution, also called the invariant measure:pβ(θ) U exp(-βL(θ∣D) - βγkΓθ∣∣2),	(13)where Γ = ΓT > 0 is an implicitly defined regularization matrix which depends on a particular treeconstruction algorithm (Ustimenko & Prokhorenkova, 2020).
Figure 2:	Uncertainty for synthetic regression dataset with two categorical features. Inside the heart(white region on the first figure) there are no training examples.
Figure 3: Uncertainty for synthetic classification dataset■ 0.035■ 0.030■ 0.025■ 0.020■ 0.015-0.010-0.005(a) Heart SGLB KU■ 0.00035■ 0.00030■ 0.00025■ 0.000200.00015-0.00010-0.00005-012345678(b) Heart VSGLB KU(c) Spiral SGLB KU(d) Spiral vSGLB KU
Figure 4: Comparison of SGLB and vSGLB knowledge uncertainty estimatesOn both “heart” and “spiral” datasets, we observed that the absolute values of knowledge uncertaintyare much smaller than of data uncertainty and therefore contribute very little to total uncertainty.
