Figure 1: Illustration of Convex Potential Flow. (a) Data x drawn from a mixture of Gaussians. (b) Learnedconvex potential F. (C) MeSh grid distorted by the gradient map of the convex potential f = VF. (d) Encodingof the data via the gradient map z = f (x). Notably, the encoding is the value of the gradient of the convexpotential. When the curvature of the potential function is locally flat, gradient values are small and this resultsin a contraction towards the origin.
Figure 2: Memory for training CIFAR-10.
Figure 4: Approximating optimal transport map via maximum likelihood (minimizing KL divergence). In thefirst figure on the left we show the data in 2 dimensions. The datapoints are colored according to their horizontalvalues (x1 ). The flows fiaf and fcp are trained to transform the data into a standard Gaussian prior. In thefigures on the right, we plot the expected quadratic transportation cost versus the KL divergence for differentnumbers of dimensionality. During training the KL is minimized, so the curves read from the right to the left.
Figure 3: Learning toy densities.
