Figure 1: A standard language-conditioned rl architecture (left) and our proposed lgb architecture (right).
Figure 3: Skill Learning: (a) SR per bucket. (b): C, LP and P estimated by a decstr agent. (c): ablationstudy. Medians and interquartile ranges over 10 seeds for DECSTR and 5 seeds for others in (a) and (c). Starsindicate significant differences to DECSTR as reported by Welch’s t-tests with α = 0.05 (Colas et al., 2019b).
Figure 4: Object-centered modular architecture for the policy.
Figure 5: The lgb-c baseline samples target positions for each block (example for a pyramid here).
Figure 6: Comparison decstr and lgb -c in the skill learning phase.
Figure 7: Evolution of the content of buckets from automatic bucket generation: epoch 1 (2400 episodes, left),50 (middle) and 100 (right). Each pie chart corresponds to one of the 35 valid configurations. It representsthe distribution of the bucket attributions of that configuration across 10 runs. Blue, orange, green, yellow,purple represent automatically generated buckets 1 to 5 respectively (increasing order of difficulty) and greyrepresents undiscovered configurations. Goals are organized according to their expert bucket attributions in theExpert Buckets condition (top-bottom organization).
Figure 8: Learning trajectories of 6 DECSTR agents.
