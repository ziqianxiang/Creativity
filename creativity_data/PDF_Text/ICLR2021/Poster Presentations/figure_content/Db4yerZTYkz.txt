Figure 1: Both shape and texture are essential cues for object recognition, and biasing towards eitherone degenerates model performance. As shown above, when classifying this fur coat image, theshape-biased model is confounded by the cloth-like shape therefore predict it as a poncho, and thetexture-biased model confuses it as an Egyptian cat because of the misleading texture. Nonetheless,our debiased model can successfully recognize it as a fur coat by leveraging both shape and texture.
Figure 2: Illustration of the our training pipeline for acquiring (a) a shape-biased model, (b) atexture-biased model, and (c) a shape-texture debiased model. Specifically, these models share thesame training samples, i.e. images with conflicting texture and shape information, generated by styletransfer between two randomly selected images; but apply distinct labelling strategies: in (a) & (b),labels are determined by the images that provides shape (or texture) information in style transfer, forguiding models to learn more shape (or texture) representations; in (c), labels arejointly determinedby the pair of images in style transfer, for avoiding bias in representation learning.
Figure 3: The shape-biased model and the texture-biased model attend on complementary CUeS forpredictions. We use Class Activation Mapping to visualize which image regions are attended bymodels. Redder regions indicates more attentions are paid by models.
Figure 4: The shape-biased model and the texture-biased model are good/bad at classifying differentobject categories. We sort these object categories according to the model,s corresponding top-1accuracy, where the righter one indicates a lower accuracy achieved by the model.
Figure 5: Illustration of the data preparation pipeline of our shape-texture debiased neural networktraining on the semantic segmentation task.
