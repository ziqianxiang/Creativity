Figure 1: Given different scenarios, models predict widespread moral sentiments. Predictions andconfidences are from a BERT-base model. The top three predictions are incorrect while the bottomthree are correct. The final scenario refers to Bostrom (2014)’s paperclip maximizer.
Figure 2:	Justice examples from Impartiality and Desert subtasks. Justifications are labeled as“reasonable” if annotators could easily imagine an everyday reasonable person in a usual circumstancestating the justification. Examples without strong consensus are excluded from the dataset.
Figure 3:	Virtue Ethics examples. Models must predict whether a character trait fits the scenario.
Figure 4: Deontology examples. The Re-quests subtask has models predict whetherthe purported exemption is reasonable. TheRoles subtask has models predict whether thepurported subresponsibility is reasonable.
Figure 5: Utilitarianism examples. Examples consist of ranked scenarios where one scenario isoften more pleasant and less painful than the other scenario for an everyday person under usualcircumstances. Models are fine-tuned to predict the pleasantness of each scenario.
Figure 6: The utility values of scenarios assigned by a RoBERTa-large model. Utility values are notground truth values and are products of the model’s own learned utility function. RoBERTa-large canpartially separate between pleasant and unpleasant states for diverse open-world inputs.
Figure 7:	The utility values of scenarios assigned by a RoBERTa-large model. Utility values are notground truth values and are products of the model’s own learned utility function. RoBERTa-largecan partially separate between pleasant and unpleasant states for diverse open-world inputs. This listbelow contains a mixture of reasonable and unreasonable utility rankings.
Figure 8:	An expanded list of utility values produced by the RoBERTa-large model. This list containsa mixture of possibly reasonable and unreasonable utility rankings. Note that although “jdkfjlsd” ismeaningless, the utility function U is not endowed with a reject option. We leave that to future work.
Figure 9: ETHICS average performance slowly increases with model size.
Figure 10:	Long Commonsense Morality Example (Label: Clearly In the Wrong).
Figure 11:	Long Commonsense Morality Example (Label: Not Clearly In the Wrong).
Figure 12:	Long Commonsense Morality Example (Label: Ambiguous).
Figure 13: Impartiality collection form.
Figure 14: Desert collection form.
Figure 15: Virtue Ethics collection form.
Figure 16: Deontology collection form.
Figure 17: Utilitarianism collection form.
Figure 18:	Commonsense Morality collection form.
Figure 19:	Utilitarianism Qualification Form (Part 1).
Figure 20:	Utilitarianism Qualification Form (Part 2).
Figure 21:	Utilitarianism Qualification Form (Part 3).
Figure 22:	Utilitarianism Qualification Form (Part 4).
