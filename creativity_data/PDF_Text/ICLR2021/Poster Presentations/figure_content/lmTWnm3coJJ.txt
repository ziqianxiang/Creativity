Figure 1: Dynamic patterns (mean±std) of instantaneousmetrics (top) and exponential moving average (EMA) metrics(bottom) when applying Alg. 2 that alternates between super-vised learning on given labels and self-supervision on pseudolabels. Larger gap between curves in each plot is better.
Figure 2: RoCL (Algorithm 1) vs. RoCLBase without any curriculum (Algorithm 2 in Appendix) during thetraining of ResNet34 on CIFAR10 containing 60% symmetric noises on labels.
Figure 3: RoCL (Algorithm 1) vs. RoCLBase without any curriculum (Algorithm 2 in Appendix) during thetraining of ResNet34 on CIFAR10 containing 80% symmetric noises on labels.
Figure 4: RoCL (Algorithm 1) vs. RoCLBase without any curriculum (Algorithm 2 in Appendix) during thetraining of ResNet34 on CIFAR100 containing 60% symmetric noises on labels.
Figure 5: RoCL (Algorithm 1) vs. RoCLBase without any curriculum (Algorithm 2 in Appendix) during thetraining of ResNet34 on CIFAR100 containing 80% symmetric noises on labels.
Figure 6: Illustration of Eq. (9) and visualization of our choice for g(∙) and the resulted Tt when T = 50. Weuse g(∙) = tanh(∙) (which can be other "S”-ShaPe functions) and σ = 0.95 in our experiments. Here, We mapthe points on the black curve in the left plot to the points on the red curve in the right plot. Each gray point onthe bottom of the left plot is from the T evenly spaced x-coordinates between the x-interval [g-1 (-σ), g-1 (σ)].
Figure 8: Ablation study: RoCL vs. its variants during the training of ResNet34 on CIFAR10 containing80% symmetric noises on labels.
Figure 10: Ablation study: RoCL vs. its variants during the training of ResNet34 on CIFAR100 containing80% symmetric noises on labels.
