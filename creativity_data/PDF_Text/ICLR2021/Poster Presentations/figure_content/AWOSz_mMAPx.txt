Figure 1: Experimental results for the Dirac-GAN game of Section 5.
Figure 2: CIFAR-10 FIDμ∖τ	1	2	4	8	1610	:14.6	11.7	10.7	10.1	11.21	13.1/8.5	10.3/6.8	8.8/6.1	8.0/5.8	8.1/6.2Figure 3: CelebA FIDlatter does not. The eigenvalues of the Jacobian with regularization μ = 0.3 presented in Figure 1cexplains this behavior since the imaginary parts are non-zero with τ = 8 and zero with τ = 16,while the eigenvalue with the minimum real part is greater at τ = 8 than at τ = 16. This highlightsthat some oscillatory behavior in the dynamics is not always harmful for convergence. For μ = 1and τ = 1, Figures 1a and 1b show that even though τ -GDA does not cycle since the eigenvaluesof the Jacobian are purely real, the trajectory converges slowly to the equilibrium. Indeed, for eachregularization parameter, the eigenvalues of JT (θ*, ω*) split after becoming purely real and thenconverge toward the eigenvalues of S1 (J (θ*, ω *)) and -τD2 f(θ*, ω *). Since S1 (J (θ *, ω *)) α 1∕μand -τD2f (θ*, ω*) Y τμ, there is a trade-off between the choice of regularization μ and thetimescale separation τ on the conditioning of the Jacobian matrix that dictates the convergence rate.
Figure 3: CelebA FIDlatter does not. The eigenvalues of the Jacobian with regularization μ = 0.3 presented in Figure 1cexplains this behavior since the imaginary parts are non-zero with τ = 8 and zero with τ = 16,while the eigenvalue with the minimum real part is greater at τ = 8 than at τ = 16. This highlightsthat some oscillatory behavior in the dynamics is not always harmful for convergence. For μ = 1and τ = 1, Figures 1a and 1b show that even though τ -GDA does not cycle since the eigenvaluesof the Jacobian are purely real, the trajectory converges slowly to the equilibrium. Indeed, for eachregularization parameter, the eigenvalues of JT (θ*, ω*) split after becoming purely real and thenconverge toward the eigenvalues of S1 (J (θ*, ω *)) and -τD2 f(θ*, ω *). Since S1 (J (θ *, ω *)) α 1∕μand -τD2f (θ*, ω*) Y τμ, there is a trade-off between the choice of regularization μ and thetimescale separation τ on the conditioning of the Jacobian matrix that dictates the convergence rate.
Figure 4: Experimental results for the quadratic game defined in (52) of Section K.1 and presentedin Example 1. Figures 4a and 4b show trajectories of the players coordinate pairs (x11, x21) and(x21 , x22) for a range of learning rate ratios, respectively. Figures 4c shows the distance from theequilibrium along the learning paths. Figures 4e, 4f, and 4g show the trajectories of the eigenvalues,the real parts of the eigenvalues, and the imaginary parts of the eigenvalues for the JT (x*) as afunction of the τ , respectively.
Figure 5: Experimental results for the polynomial game defined in (53) of Section K.2 and presentedin Example 2. Figures 5a and 5b show trajectories of the players coordinate pairs (x11, x21) and(x21, x22) for a range of learning rate ratios, respectively. Figures 5d, 5e, and 5f show the trajectoriesof the eigenvalues, the real parts of the eigenvalues, and the imaginary parts of the eigenvalues forJT (x*) as a function of the T, respectively where x* is the non-equilibrium critical point.
Figure 6: Experimental results for the polynomial game defined in (54) of Section K.3. Figures 6aprovides a 3d view of the cost function -f (x1 , x2) along with the cost contours and critical pointlocations. Figure 6b shows trajectories of τ -GDA for a range of learning rate ratios given an initial-ization around the differential StaCkelberg equilibrium (x；,x5) = (-11.03, -11.03). Figures 6cand 6d show the evolution of the eigenvalues from JT (x*) as a function of T where x* is the differ-ential StaCkelberg equilibrium (x1； , x2；) = (-11.03, -11.03).
Figure 7:	Experimental results for the polynomial game defined in (54) of Section K.3. In Figure 7a,we overlay the trajectories from Figure 6b produced by τ -GDA onto the vector field generated bythe choice of timescale separation selection τ . The shading of the vector field is dictated by itsmagnitude so that lighter shading corresponds to a higher magnitude and darker shading correspondsto a lower magnitude. Figure 7b demonstrates the effect of timescale separation on the region ofattractions around critical points by coloring points in the strategy space according to the equilibriumτ -GDA converges. We remark that areas without coloring indicate where τ -GDA did not converge inthe time horizon.
Figure 8:	Experimental results for the torus game defined in (55) of Appendix K.4. In Figure 8a,we overlay multiple trajectories produced by τ -GDA onto the vector field generated by the choiceof timescale separation selection τ . The shading of the vector field is dictated by its magnitude sothat lighter shading corresponds to a higher magnitude and darker shading corresponds to a lowermagnitude. Figure 8b demonstrates the effect of timescale separation on the regions of attractionaround critical points by coloring points in the strategy space according to the equilibrium τ -GDAconverges. We remark that areas without coloring indicate where τ -GDA did not converge in thetime horizon.
Figure 9: Experimental results for the Dirac-GAN game defined in (56) of Appendix K.5. Figure 9ashows trajectories of T-GDA for T ∈ {1, 4, 8,16} with regularization μ = 0.3 and T = 1 withregularization μ = 1. Figure 9b shows the distance from the equilibrium along the learning paths.
Figure 10: Experimental results for the generative adversarial network formulation for learning acovariance matrix defined by the cost from (58) of Section K.6. Figures 10a, 10b, and 10c showthe distance from the equilibrium along the learning paths of τ -GDA with d = 1. Figures 10d, 10e,and 10f show the trajectories of the eigenvalues of JT (x*) as a function of the T, respectively.
Figure 11: Experimental results for learning a covariance matrix defined by the cost from (58) ofSection K.6. We overlay the trajectories produced by τ -GDA onto the vector field generated by thechoices of T and μ. The shading of the vector field is dictated by its magnitude so that lighter shadingcorresponds to a higher magnitude and darker shading corresponds to a lower magnitude.
Figure 12: KL-divergence between generated and real data for a mixture of Gaussians.
Figure 13: CIFAR-10 FID scores with regularization μ = 10 in Figure 13a and μ = 1 in Figure 13b.
Figure 14: CelebA FID scores with regularizationμ = 10 in Figure 14a and μ = 1 in Figure 14b.
Figure 15:	FID Scores on CIFAR-10 and CelebA.
Figure 16:	Generated sample images with τ = 4 and β = 0.9999Layer	Output Size	FilterFully Connected Reshape	-512 ∙ 4∙4 512 × 4 × 4	256 → 512 ∙ 4 ∙ 4Resnet-Block NN-Upsampling	256 × 4 × 4― 256 × 8 × 8	512 → 256 → 256Resnet-Block NN-Upsampling	128 × 8 × 8― 128 × 16 × 16	256 → 128 → 128Resnet-Block NN-Upsampling	64 × 16 × 16 64 × 32 × 32	128 → 64 → 64Resnet-Block Conv2D	64 × 32 × 32 3 × 64 × 64	-64 → 64 → 64- 64 1 3Layer	Output Size	FilterConv2D	64 × 32 × 32	3 — 64Resnet-Block Avg-Pool2D	64 × 32 × 32 64 × 16 × 16	-64 → 64 → 64-Resnet-Block Avg-Pool2D	128 × 16 × 16 128 × 8 × 8	64 → 64 → 128Resnet-Block Avg-Pool2D	256 × 8 × 8- 256 × 4 × 4	128 → 128 → 256Resnet-Block Fully Connected	512 × 4 × 4- 512 ∙ 4∙4	256 → 256 → 512 512 ∙ 4 ∙ 4 → 1(b) Discriminator Network Architecture(a) Generator Network ArchitectureFigure 17: Network Architectures for GAN experiments on CIFAR-10 and CelebAHyperparameter	Value(s)Objective	NSGANBatch Size	64Latent Distribution	Z ∈ R256
Figure 17: Network Architectures for GAN experiments on CIFAR-10 and CelebAHyperparameter	Value(s)Objective	NSGANBatch Size	64Latent Distribution	Z ∈ R256Generator Learning Rate	CIFAR-10: 0.0001; CelebA: 0.00005Timescale Separation T	CIFAR-10: {1, 2, 4, 8}; CelebA: {1, 2, 4, 8,16}Learning Rate Decay	(1+ x)-0∙005Optimizer	RMSpropRMSprop Smoothing Constant a	0.99RMSprop e	10-8Regularization μ	{1,10}EMA Parameter β		{0.99, 0.999, 0.9999}	Figure 18: Hyperparameters for GAN experiments on CIFAR-10 and CelebAL Alternative Proof of Theorem 3 via T* Construction FROMTheorem 1in order to highlight the utility of Theorem 1 along with future directions of obtaining values ofT* for structured games, we revisit the proof of Theorem 3 and derive the result directly from theconstruction. The purpose of this section is to illustrate that the structure of equilibria considered inTheorem 3 can be exploited to obtain the value of τ* for the entire class of games using properties
Figure 18: Hyperparameters for GAN experiments on CIFAR-10 and CelebAL Alternative Proof of Theorem 3 via T* Construction FROMTheorem 1in order to highlight the utility of Theorem 1 along with future directions of obtaining values ofT* for structured games, we revisit the proof of Theorem 3 and derive the result directly from theconstruction. The purpose of this section is to illustrate that the structure of equilibria considered inTheorem 3 can be exploited to obtain the value of τ* for the entire class of games using propertiesof the Kronecker product and sum.
