Figure 1: Distribution of model decision scores on test samples from a synthetic dataset of Sagawaet al. (2020b), comprising two labels with two subgroups each (left panel). The scores are expectedto be > 0 iff the label is positive. We train a linear model with complexity controlled by its numberof features m. For the overparameterised setting m = 104 (left), within each class, rare subgroupsconsistently appear on the wrong side of the decision boundary. Correcting this bias via post-hocscore translation improves the worst-subgroup error as the model complexity is increased (right).
Figure 2: Two-dimensional tSNE visualisation of test embeddings as produced by overparameterisedmodels. Within each class, samples from each of the two subgroups tend to be closely clustered.
Figure 3: Distributions of model decision scores f+1(x) - f-1(x) on test samples on waterbirdsand celebA, comprising two labels with two sub-groups each. The rare and dominant subgroup scoredistributions largely differ, with the former often on the incorrect side of the decision boundary (i.e.,with decision scores < 0 for positive samples, and > 0 for negative samples). Notably, the scores forrare subgroups tend to be shifted compared to those for dominant subgroups.
Figure 4: Performance of baseline (ERM) and threshold correction (THR) on synth and waterbirdsdatasets, with fixed input representations. We vary the feature dimensionality m between 101 and104, and plot the average and worst-subgroup error on both the train and test set over 5 independenttrials. For the baseline, the worst-case error devolves as m increases. For threshold correction, bothaverage and worst-case error steadily improve on the test set. Of salience is that overparameterisation(large m) aids worst-subgroup performance under post-hoc correction.
Figure 5: Effect of tuning classification threshold ta for synth, when m = 104. The case ta = 0corresponds to the baseline. Modifying ta systematically trades off performance on the rare subgroupscompared to the dominant ones (left). By choosing the thresholds to minimise the worst-subgrouperror, the resulting score distributions are aligned for rare and dominant subgroups (right).
Figure 6:	Two-dimensional tSNE visualisation of test embeddings as produced by an overparame-terised model trained to minimise group-based DRO.
Figure 7: Histograms of model scores on test samples on various datasets, comprising two labels withtwo sub-groups each. In general, there are differences in the distributions for the rare and dominantsubgroup scores, with the former often lying on the incorrect side of the decision boundary.
Figure 8:	Histograms of model scores on train samples on various datasets, comprising two labelswith two sub-groups each. In general, while there are differences in the distributions for the rare anddominant subgroup scores, nearly all such scores are on the correct side of the decision boundary.
Figure 9:	Histograms of model scores on test samples on synth as number of projection features mis varied. We see that as the model complexity increases, there is a steady increase in the separationof decision scores between the rare and dominant subgroups for a label. This is in keeping withoverparameterisation exacerbating worst-subgroup error.
Figure 10:	Evolution of histograms of model scores on test samples on celebA. The distinctionbetween the scores amongst subgroups of the positive class is visible even after early stopping. Withincreased training epochs, there is a systematic shift of the negative scores, as the network becomesincreasingly confident on them.
Figure 11:	Evolution of histograms of model scores on test samples on waterbirds.
Figure 12:	Histograms of model scores on test samples on celebA with various strenghts of regulari-sation. Increasing the strength is seen to favourably impact the scores on the negative class, for boththe dominant and rare subgroups.
Figure 13:	Histograms of model scores on test samples on waterbirds with various strengths ofregularisation. Increasing the strength is seen to favourably impact the scores on the negative class,for both the dominant and rare subgroups.
Figure 14:	Histograms of model scores on test samples on synth, with and without subsamplingper Sagawa et al. (2020a). Subsampling is seen to make the scores equitable across the subgroups.
Figure 15:	Performance of baseline and threshold correction on synth. We vary the fraction ofmajority samples pmaj . This is seen to adversely affect the performance of ERM. However, thresholdcorrection can effectively reduce this error, albeit at the expense of higher variance.
Figure 16:	Histograms of model scores on test samples on synth, for various values of fraction ofmajority samples pdom . As this fraction becomes larger, the rare subgroups see progressive shift intheir scores compared to the dominant ones.
