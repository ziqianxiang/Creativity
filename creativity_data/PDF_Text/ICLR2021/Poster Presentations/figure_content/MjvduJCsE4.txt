Figure 1: Investigating the calibration of Gaussian process classification with CNN-GP kernels.
Figure 2: Uncertainty metrics across shift levels on CIFAR10 using NNGP-R. CNN kernels performbest as well as being more robust to corruption. See the supplement for numerical values at eachquartile as well as a comparison to the NTK (Fig. S3). All methods remain well calibrated for allintensities of shifts, with C-NNGP-R performing best, and significantly better than methods in Ovadiaet al. (2019); contrast against their Fig. 2 and S4.
Figure 3: Uncertainty metrics across shift levels on CIFAR10 using NNGP-LL with EfficientNet-B3embedding. We observe that more complex neural kernels (convolution and self-attention NNGPs)can have higher performance while being more robust to corruptions compared to replacing last layerto Bayesian linear regression (Riquelme et al., 2018). See Fig. S9 for the comparison to the NTK.
Figure S1: Investigating the calibration of Gaussian process classification with NNGP kernels asin Fig. 1, where we find similar results. (left column) Histogram of the confidence of the posteriordistribution for each test point. We compare the NNGP-C and a finite width NN on an identicallydistributed test set (CIFAR10) and an OOD test set (SVHN). (middle column) Performance, NNGP-C is solid and NN dashed, under increasing distributional shift given by the CIFAR10 fog corruption.
Figure S2:	We compare NNGP-C and a finite width NN on an identically distributed test set(CIFAR10) and an OOD test set (SVHN). We plot a histogram of the entropy of the predicteddistribution for each example in the test set. (top row) Fully connected network architectures.
Figure S3:	Uncertainty metrics across shift levels on CIFAR10 using NNGP-R and NTK-R. CNNkernels perform best as well as being more robust to corruption. The NTK corresponding to the samearchitecture shows similar robustness properties.
Figure S4:	Comparison of NNGP-R based confidence measures on CIFAR10 corruptions usingC-NNGP-R. Left column uses temperature scaling based on a validation set whereas right columnuses T = 1. We see that softmax confidence requires adjusting temperature which is equivalent tomodifying prior variance to be calibrated whereas exact and pairwise heuristic confidence is calibratedwithout needing to modify the prior variance.
Figure S5: Uncertainty metrics across corruption levels on CIFAR10 using NNGP-LL withEfficientNet-B3 embedding. Baseline NNs are trained on CIFAR10 with parameters of body networkfixed. See Table 3 for quartile comparison and Fig. S6 and Table S3 for comparison with fine tuningof all the embeddingâ€™s weights. Fig. S7 compares use of NNGP and RBF kernel for NNGP-LLsettings.
Figure S6:	Uncertainty metrics across corruption levels on CIFAR10 using NNGP-LL withEfficientNet-B3 embedding. Baseline NNs are either last layer (LL) trained on CIFAR10 withparameters for body networks fixed or where all the weights are fine tuned (FT). Quartile comparisonscan be found in Table S3.
Figure S7:	Comparison of NNGP-LL using NNGP head Vs RBF GP head on EfficientNet-B3embedding. While there are slight advantage of using NNGP head over RBF-GP overall they provideVery similar benefits as corruption intensity increase.
Figure S8:	Uncertainty metrics across corruption leVels on CIFAR10 using NNGP-LL with MetaInitembedding. Baseline NNs are compared with Vanilla training, temperature scaling and ensembles.
Figure S9:	Comparison between NNGP-LL and NTK-LL with varying embeddings and neuralkernels.
