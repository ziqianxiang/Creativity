Figure 2: Visualization on top 20 percent rele-vant features provided by different explanationson MNIST. We see Greedy-AS highlights bothcrucial positive and pertinent negative featuressupporting the prediction.
Figure 3: Visualization of different explanationson ImageNet, where the predicted class for eachinput is “Maltese”, “hippopotamus”, “zebra”,and “Japanese Spaniel”. Greedy-AS focusesmore compactly on objects.
Figure 4: Explanations on a text classification model which correctly predicts the label “sport”.
Figure 5: Visualization of targeted explanation. For each input, we highlight relevant regionsexplaining why the input is not predicted as the target class. We see the explanation changes in asemantically meaningful way as the target class changes.
Figure 6: Greedy-AS and other existing methods on MNIST.
Figure 7: Greedy-AS and other existing methods on ImageNet.
Figure 8: Greedy-AS and other existing methods on Yahoo!Answers.
Figure 10: Greedy-AS and other existing methods on MNIST.
Figure 11: Greedy-AS and other existing methods on ImageNet.
Figure 12: Greedy-AS and other existing methods on Yahoo!Answers.
Figure 13: Ranking among different explanations. From left to right: MNIST Insertion/Deletion;ImageNet Insertion/Deletion. Rankings correspond to the relative rank among all methods, i.e. 1 - 9.
Figure 14: Evaluation curves of Insertion criteria on MNIST with different reference values.
Figure 15: Evaluation curves of Deletion criteria on MNIST with different reference values.
Figure 16: Evaluation curves of Insertion criteria on ImageNet with different reference values.
Figure 17: Evaluation curves of Deletion criteria on ImageNet with different reference values.
Figure 18: Visualization of different explanations on MNIST. The highlighted pixels are the top 20%relevant pixels selected by different methods. We see that Greedy-AS focuses both on crucial positiveand pertinent negative regions.
Figure 19: Visualization of different explanations on ImageNet. We see that Greedy-AS focusesmore compactly on the areas containing the actual objects being classified.
Figure 20: Comparisons between different methods for targeted explanation against different targetclasses on MNIST. We note that Oramas et al. (2019) could not handle arbitrarily specified targetclass and thus is not available to produce different explanations for different target classes.
Figure 21:(b) Insertion (random baseline)(c) Insertion (zero baseline)(e) Deletion (random baseline)(f) Deletion (zero baseline)Evaluation curves on Yahoo!Answers dataset.
