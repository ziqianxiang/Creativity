Figure 1: Condition number of NTK κN exhibitsnegative correlation with the test accuracy of archi-tectures in NAS-Bench201 (Dong & Yang, 2020).
Figure 2: Example of linearregions divided by a ReLUnetwork1Following Raghu et al. (2017); MOntUfar (2017); Serra et al. (2018); Hanin & Rolnick (2019a;b);Xiong et al. (2020), we first introduce the following definition of activation patterns and linear regionsfor ReLU CNNs.
Figure 3: Number of linear regions RN ofarchitectures in NAS-Bench201 exhibits pos-itive correlation with test accuracies.
Figure 5: Pruning trajectory on NAS-Bench-201(top) and DARTs search space (bottom). Number “0”indicates the supernet N0 before any pruning, whichis of high expressivity but poor trainability.
Figure 6: Normal and Reduction cells discovered by TE-NAS on CIFAR-10.
Figure 7: Normal and Reduction cells discovered by TE-NAS on imageNet.
Figure 8: Depth and width preference of (a) KN and (b) RN on DARTs Search Space.
Figure 9: Summation of ranking of KN and RN exhibitsstronger (negative) correlation with the test accuracy of architec-tures in NAS-Bench201 (Dong & Yang, 2020).
Figure 10: The correlation between test accuracy and thetraining accuracy in NAS-Bench201 (Dong & Yang, 2020).
