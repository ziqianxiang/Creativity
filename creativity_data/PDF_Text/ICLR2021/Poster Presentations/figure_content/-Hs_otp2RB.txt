Figure 1: Adversarial attacks on CelebA for differentmodels. Here we start with the image of Hugh Jackmanand introduce an adversary that tries to produce recon-structions that look like Anna Wintour. This is done byapplying a distortion (third column) to the original imageto produce an adversarial input (second column). We cansee that the adversarial reconstruction for the Vanilla VAElooks substantially like Wintour, indicating a successfulattack. Adding a regularisation term using the β-TCVAEproduces an adversarial reconstruction that does not looklike Wintour, but it is also far from a successful recon-struction. The hierarchical version of a β-TCVAE (whichWe call Seatbelt-VAE) is sufficiently hard to attack that theoutput under attack still looks like Jackman, not Wintour.
Figure 2: [Left] density plot of ∣∣σφ(x) ∣∣2 (the norm of the encoder standard deviation) for a VAE, aβ-VAE and a β-TCVAE each trained on CelebA, β = 10. The β-VAE's posterior variance saturates,while the β-TCVAE,s does not and as such is able to induce more overlap. [Right] the likelihood(logpθ(x∣z)) and ELBO for both as a function of β. Clearly the model quality degrades to a lesserdegree for the TC-penalised models under increasing β .
Figure 3: Attacker’s achieved loss ∆KL (i.e. Eq (1) with r = DKL) for β-TCVAE for different βvalues and datasets. Higher loss indicates more robustness. Shading corresponds to the 95% CIproduced by attacking 20 images for each combination of dz = {4, 8, 16, 32, 64, 128} and taking 50geometrically distributed values of λ between 2-20 and 220 (giving 1000 total trials). Note that theloss axis is logarithmic. β > 1 clearly induces a much larger loss for the adversary relative to β = 1for all datasets.
Figure 4: DKL Latent space attacks only on rotation of a heart-shaped dSprite for β-TCVAEs(dz = 64) and Seatbelt-VAEs (L = 2) for β = {1, 2}. The attacks are conducted by applyinga distortion (third column of each image) to the original image (top first column) to produce anadversarial input (bottom second column of each image) to try to cause the output of the target image(bottom first column). Here we show the most successful adversarial distortion in terms of adversarialloss for each model. It is apparent that Seatbelt-VAEs are the most resilient to attack. Note that thedistortions plots (bottom right) are scaled to [0,1] for ease of viewing.
Figure 5: Plots showing the robustness of Seatbelt-VAEs (L=4) and β-TCVAEs models for differentvalues of β for three different attack methods: a) Latent space attack via DKL in Eqs (1,10), b)Attack via the model output as in Eq 2, and c) Latent space attack via the 2-Wasserstein (W2)distance in Eqs (1,10). Note that the β-TCVAE with β = 1 corresponds to a vanilla VAE andthat L > 1 β = 1 models correspond to hierarchical baselines. We show the negative adversariallikelihood of a target image Xt given an attacked latent representation Z for Faces (1st Col) andChairs (3rd Col) respectively. Larger values of -logpθ(xt∣z*) mean less successful adversarialattacks. We also show the adversarial loss ∆ in 2nd and 4th cols, which have a logarithmic axis.
Figure 6: Effect of varying β on the reconstructions of TC-penalised models. In sub-figures (a) and(b) we plot the final ELBO of TC-penalised models trained on the Chairs and 3D faces, calculatedwithout the β penalisation applied during training. Shading gives the 95% CI over variation due tovariation of dz = {32, 64, 128} for β-TCVAE and also L = {2, 3, 4, 5} for Seatbelt. As β increasesL degrades more slowly for Seatbelt-VAE, relative to β-TCVAE, (c) serves as a visual confirmationof these results. The top row shows CelebA input data. The bottom row, the reconstructions froma Seatbelt-VAE with L = 4 and β = 20, clearly maintains facial identity better than those from aβ-TCVAE, the middle row: many of the individuals’ finer facial features lost by the β-TCVAE aremaintained by the Seatbelt-VAE.
