Figure 1: (a) Hidden state feature extraction is performed by a neural networks using individualnode features propagated via GPR. Note that both the GPR weights Yk and parameter set {θ} ofthe neural network are learned simultaneously in an end-to-end fashion (as indicated in red). (b)-(c)The learnt GPR weights of the GPR-GNN on real world datasets. Cora is homophilic while Texas isheterophilic (Here, H stands for the level of homophily defined below). An interesting trend may beobserved: For the heterophilic case the weights alternate from positive to negative with dampeningamplitudes (more examples are provided in Section 5). The shaded region corresponds to a 95%confidence interval.
Figure 3: Figure (a)-(d) shows the learnt GPR weights by GPR-GNN with random initialization oncSBM, dense split. The shaded region indicates 95% confidence interval.
Figure 2: Accuracy of tested models oncSBM. Error bars indicate 95% confi-dence interval.
Figure 4: Figures (a)-(d) show the learned GPR weights of our GPR-GNN method with randominitialization on various datasets, for dense splitting. Figures (e)-(f) show the learned weights ofour GPR-GNN method with initialization δkκ on cSBM(φ = -1), for dense splitting. The shadedregion indicates a 95% confidence interval.
Figure 5: A simple example demonstrating how GPR-GNN escapes over-smoothing.
Figure 6: A simple example for explaining the insufficiency of homophily measure H(G).
Figure 7: Figures (a)-(i) show the learned GPR weights by GPR-GNN with random initializationon cSBM, dense splitting. The shaded region indicates a 95% confidence interval.
Figure 8:	Figures (a)-(j) show the learned GPR weights by GPR-GNN with random initialization onvarious benchmark datasets, dense splitting. The shaded region indicates a 95% confidence interval.
Figure 9:	Learned GPR weights by GPR-GNN with initialization Yk = δkK (last step) on variousbenchmark datasets, dense splitting. The shaded region indicates a 95% confidence interval. Also,please check Table 8. Note that the GPR weights {γk}kK=0 are identical to {-γk}kK=0 in terms ofgraph filtering.
Figure 10:	The dynamics of learning GPR weights with random initialization on various benchmarkdatasets, dense splitting. The shaded region indicates a 95% confidence interval.
