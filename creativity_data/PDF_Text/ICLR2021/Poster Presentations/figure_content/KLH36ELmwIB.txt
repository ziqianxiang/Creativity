Figure 1: Schematic illustration about (a) DARTSand (b) the proposed DARTS-, featuring an auxil-iary skip connection (thick red line) with a decayrate β between every two nodes to remove the po-tential unfair advantage that leads to performancecollapse.
Figure 2: Tendency of trainable coef-ficient β (initialized with {0, 0.5, 1})of the skip connection in ResNet50 andtest accuracy (inset figure) vs. epochs.
Figure 3: Comparison of the validation accuracy landscape of (a) DARTS and (b) DARTS- w.r.t. αon CIFAR-10 in S3. Their contour maps are shown respectively in (c) and (d), where we set thestep of contour map as 0.1. The accuracy of the derived models are 94.84% (a,c) and 97.58% (b,d),while the maximum Hessian eigenvalues are similarly high (0.52 and 0.42)To analyze the efficacy of DARTS-, we plot the validation accuracy landscape w.r.t architecturalweights α, and find that auxiliary connection smooths the landscape and thus stabilizes the search-ing stage. Specifically, we choose two random directions and apply normalized perturbation on α(following Li et al. 2018a). As shown in Figure 3, DARTS- is less sensitive to the perturbation thanDARTS, and the contour map of DARTS- descends more gently.
Figure 4: The evolution of maximal eigenvalues of DARTS- when searching in different searchspaces S0-S4 on CIFAR-10 (a) and CIFAR-100 (c). We run each experiment 3 times on differentseeds. (b) DARTS-’s growing Hessian eigenvalues don’t induce poor performance. Among thesampled five models, the one corresponding to the highest eigenvalue has the best performance.
Figure 5: Training five models sampled every 10 epochs during DARTS- searching process. SeeFig 4 (b) for the corresponding eigenvalues.
Figure 6:	The training loss curve of the over-parameterized network on CIFAR-10 in S3 with differ-ent initial β0 .
Figure 7:	More visualization of validation accuracy landscapes of DARTS (a,b) and DARTS- (e,f)w.r.t. the architectural weights α on CIFAR-10 in S0. Their contour maps are shown respectivelyin (c,d) and (g,h). The step of contour map is 0.1. The inferred models by DARTS- have higheraccuracies (97.50%, 97.49%) than DARTS (97.19%, 97.20%).
Figure 8: More visualization of validation accuracy landscapes of DARTS (a,b) and DARTS- (e,f)w.r.t. the architectural weights α on CIFAR-10 in S3. Their contour maps are shown respectively in(c,d) and (g,h). The step of contour map is 0.1.
Figure 9:	The best found normal cell and reduction cell in search spaces S0-S4 on CIFAR-10 dataset.
Figure 10:	Architecture of DARTS-A searched on ImageNet dataset.
Figure 11: The best found normal cell and reduction cell in search spaces S0-S4 on CIFAR-100dataset.
Figure 12: Found normal cells and reduction cells by P-DARTS (Chen et al., 2019b) without prior(M=2) in the DARTS’ standard search space on CIFAR-10 dataset.
Figure 13:	Found normal cells and reduction cells by P-DARTS (Chen et al., 2019b) with theproposed auxiliary skip connections in the DARTS’ standard search space on CIFAR-10 dataset.
Figure 14:	Found normal cells and reduction cells by PC-DARTS (Xu et al., 2020) without channelshuffling in the DARTS’ standard search space on CIFAR-10 dataset.
Figure 15:	Found normal cells and reduction cells by PC-DARTS (Xu et al., 2020) with the pro-posed auxiliary skip connections in the DARTS’ standard search space on CIFAR-10 dataset.
Figure 16: Keep βskipon CIFAR-10 dataset.
Figure 17: Best cells found when decaying βskip in the last 50 epochs during the DARTS- searchingfor 150 and 200 epochs respectively in the DARTS search space on CIFAR-10.
Figure 18:	Decaying βskip in the last 50 epochs during the DARTS- searching for 150 epochs in S2on CIFAR-10 dataset.
Figure 19:	Decaying βskip in the last 50 epochs during the DARTS- searching for 200 epochs in S2on CIFAR-10 dataset.
Figure 20: Decaying βskip in the last 50 epochs during the DARTS- searching for 150 epochs in S3on CIFAR-10 dataset.
Figure 21: Decaying βskip in the last 50 epochs during the DARTS- searching for 200 epochs in S3on CIFAR-10 dataset.
