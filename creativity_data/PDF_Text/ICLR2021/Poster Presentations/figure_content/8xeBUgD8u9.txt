Figure 1: (a): A hypernetwork h(e, θ) produces the weights ψ of a recurrent main network fconditioned on e. (b): Here, we illustrate a hypernetwork-based CL approach versus a weight-importance method (such as EWC). Both methods start learning a second task from a commonsolution ψ1 . EWC is rigid along certain directions in weight space, which leads to a trade-offsolution ψ2EWC when seeking good optima for the upcoming task (cf. Farquhar and Gal (2018)).
Figure 2: Variants of the Copy Task. (a): Example pattern of the basic Copy Task where input andoutput patterns are identical. (b): In Padded Copy Task, the input is padded with zeros, but the outputconsists only of the pattern itself, i.e. to (a). (c): In Permuted Copy, the output is a time-permutedversion of the presented input in (a). (d): In the Pattern Manipulation Task (r = 1), the outputcorresponds to an XOR operation between the original input (a) and a permuted version of the input(c). The blue rectangle highlights this operation for two specific bits.
Figure 3: (a) Intrinsic dimensionality per timestep of the 256-dimensional RNN hidden space htfor the basic Copy Task, where input and pattern lengths are tied (i = p). The stop bit (dotted blackline) is shown at time t = 0 (Mean ± SD, n = 5). (b) Same as (a) for the Padded Copy Task,where the pattern length is fixed (p = 5) but input length i varies. In (a) and (b), dimensionalityof the hidden state space increases only during input pattern presentation. (c) Mean Fisher values(weight-importance values in Online EWC) of recurrent weights after learning the Copy Task (solidline, p = 5, 10, ...40) or the Padded Copy Task (dotted line, p = 5) independently for an increasingset of sequence lengths i (Mean ± SD, n = 5).
Figure 4:	Mean final accuracies for four SplitSequential-SMNIST experiments, each compris-ing five tasks (Mean ± SEM, n = 10).
Figure 5:	Mean final accuracies for Split-AudioSet experiments with varying number ofclasses and tasks.
