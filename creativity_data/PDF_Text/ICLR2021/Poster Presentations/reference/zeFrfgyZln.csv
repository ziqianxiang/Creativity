title,year,conference
 Variance reduction inSGD by distributed importance sampling,2015, arXiv preprint arXiv:1511
 MS MARCO: A human generated MAchine ReadingCOmprehension dataset,2016, arXiv preprint arXiv:1611
 Pre-training tasks forembedding-based large-scale retrieval,2020, In Proceedings of the 8th International Conference on LearningRepresentations
 A simple framework for contrastivelearning of visual representations,2020, In Proceedings of the 37th International Conference on Machine Learning
 Improved baselines with momentum contrastivelearning,2020, arXiv preprint arXiv:2003
 Deeper text understanding for IR with contextual neural language modeling,2019, InProceedings of the 42nd International ACM SIGIR Conference on Research and Development in InformationRetrieval
 Understanding BERT rankers under distillation,2020, In Proceedings ofICTIR ’20: The 2020 ACM SIGIR International Conference on the Theory of Information Retrieval
 Complementing lexical retrieval with semantic residualembedding,2020, arXiv preprint arXiv:2004
 Acceleratinglarge-scale inference with anisotropic vector quantization,2020, arXiv preprint arXiv:1908
 Noise-contrastive estimation: A new estimation principle for Unnormal-ized statistical models,2010, In Proceedings of the Thirteenth International Conference on Artificial Intelligenceand Statistics
 REALM: Retrieval-aUgmentedlangUage model pre-training,2020, arXiv preprint arXiv:2002
 Poly-encoders: ArchitectUres andpre-training strategies for fast and accUrate mUlti-sentence scoring,2020, In Proceddings of 8th InternationalConference on Learning Representations
 Billion-scale similarity search With GPUs,2017, arXiv preprintarXiv:1702
 TriviaQA: A large scale distantly supervisedchallenge dataset for reading comprehension,2017, In Proceedings of the 55th Annual Meeting of the Associationfor Computational Linguistics
 Not all samples are created equal: Deep learning with impor-tance sampling,2018, In Proceedings of the 35th International Conference on Machine Learning
 Generalization throughmemorization: Nearest neighbor language models,2020, In Proceedings of the 8th International Conference onLearning Representations
 ColBERT: Efficient and effective passage search via contextualized lateinteraction over BERT,2020, In Proceedings of the 43rd International ACM SIGIR conference on research anddevelopment in Information Retrieval
 Relevance-based language models,2017, In ACM Special Interest Group onInformation Retrieval (SIGIR) Forum
 Retrieval-augmented generation for knowledge-intensive nlp tasks,2020, arXiv preprint arXiv:2005
 RoBERTa: A robustly optimized BERT pretraining approach,2019, arXivpreprint arXiv:1907
 An introduction to neural information retrieval,2018, Foundations and Trends® inInformation Retrieval
 Passage re-ranking with BERT,2019, arXiv preprint arXiv:1901
 Document expansion by query prediction,2019, arXivpreprint arXiv:1904
 GLUE: A multi-task benchmark and analysis platform for natural language understanding,2019, In 7th International Conference onLearning Representations
 Unsupervised feature learning via non-parametric in-stance discrimination,2018, In Proceedings of 2018 IEEE Conference on Computer Vision and Pattern Recognition
 End-to-end neural ad-hoc rankingwith kernel pooling,2017, In Proceedings of the 40th International ACM SIGIR Conference on Research andDevelopment in Information Retrieval
 Transformer-XH:Multi-evidence reasoning with extra hop attention,2020, In Proceedings of the 8th International Conference onLearning Representations
 BERT-QE: Contextualized queryexpansion for document re-ranking,2020, pp
 6 and Fig,2019, 7 show many interesting patterns of the learned representation space
