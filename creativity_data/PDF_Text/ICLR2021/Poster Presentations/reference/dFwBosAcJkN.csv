title,year,conference
 Evasion Attacks against Machine Learning at Test Time,2013, In Hendrik Blockeel
 Intriguing properties of neural networks,2014, In International Conference on Learning Representations
 Adversarial examples in the physical world,2016, arXiv preprintarXiv:1607
 Adversarial examplesfor semantic segmentation and object detection,2017, In Proceedings of the IEEE International Conference onComputer Vision
 Explaining and Harnessing Adversarial Examples,2015, InInternational Conference on Learning Representations
 Towards DeepLearning Models Resistant to Adversarial Attacks,2018, In International Conference on Learning Representations
 A Rotation and aTranslation Suffice: Fooling CNNs with Simple Transformations,2017, arXiv preprint arXiv:1712
 Wasserstein Adversarial Examples via Projected SinkhornIterations,1902, arXiv preprint arXiv:1902
 Spatially TransformedAdversarial Examples,2018, arXiv preprint arXiv:1801
 Semantic Adversarial Examples,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition Workshops
 Functional Adversarial Attacks,2019, In NeurIPS
 Big but Imperceptible AdversarialPerturbations via Semantic Manipulation,2019, arXiv preprint arXiv:1904
 Constructing Unrestricted Adversarial Examples withGenerative Models,2018, In Proceedings of the 32nd International Conference on Neural Information ProcessingSystems
 Adversarial Attacks Beyond the Image Space,1711, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Adversarial Robustness Against the Union of MultiplePerturbation Models,1909, arXiv:1909
 Adversarial Training and Robustness for Multiple Pertur-bations,2019, In H
 Testing Robustness Against UnforeseenAdversaries,2019, arXiv preprint arXiv:1908
 Unrestricted adversarialexamples,2018, arXiv preprint arXiv:1809
 Image quality assessment: from error visibility tostructural similarity,1941, IEEE Transactions on Image Processing
 The Unreasonable Effectivenessof Deep Features as a Perceptual Metric,2018, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Towards Evaluating the Robustness of Neural Networks,2017, In 2017 IEEESymposium on Security and Privacy (SP)
 Adversarial machine learning at scale,2016, ArXiv
 On the Suitability of Lp-norms for Creating and PreventingAdversarial Examples,2018, arXiv:1802
 Semantic Adversarial Perturbations using Learnt Represen-tations,2020, arXiv:2001
 Towards Feature Space AdversarialAttack,2020, arXiv:2004
 Manifold Regularization for Locally Stable Deep Neural Networks,2020, March 2020
 Confidence-Calibrated Adversarial Training: Generalizing toUnseen Attacks,2020, arXiv:1910
 Complex WaveletStructural Similarity: A New Image Similarity Index,1941, IEEE Transactions on Image Processing
 ImageNet Classification withDeep Convolutional Neural Networks,2012, In F
 Learning Multiple Layers of Features from Tiny Images,2009, Technicalreport
 Reliable evaluation of adversarial robustness with an ensemble of diverseparameter-free attacks,2020, In ICML
 Benchmarking neural network robustness to common corruptions andperturbations,2019, Proceedings of the International Conference on Learning Representations
 On the Limitation of ConvolutionalNeural Networks in Recognizing Negative Images,2017, In 16th IEEE International Conference on MachineLearning and Applications (ICMLA)
 TheLimitations of Adversarial Training and the Blind-Spot Attack,2019, International Conference on LearningRepresentations
 Instance adaptive adversarial training: Improved accuracytradeoffs in neural nets,1910, arXiv:1910
 RobustnessMay Be at Odds with Accuracy,2019, arXiv:1805
 Deep Residual Learning for Image Recognition,2016, InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition
