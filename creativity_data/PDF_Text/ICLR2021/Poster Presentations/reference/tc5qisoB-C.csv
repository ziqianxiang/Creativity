title,year,conference
 Hindsight experience replay,2017, In Advances inneural information processing systems
 The option keyboard: Combining skills in reinforCementlearning,2019, In Advances in Neural Information Processing Systems
 Discriminative learning for differing training and testdistributions,2007, In Proceedings of the 24th international conference on Machine learning
 Improving generalization for temporal difference learning: The successor representation,1993, NeuralComputation
 Goal-conditioned imitation learning,2019, InAdvances in Neural Information Processing Systems
 Adversarially learned inference,2016, arXiv preprint arXiv:1606
 Visual fore-sight: Model-based deep reinforcement learning for vision-based robotic control,2018, arXiv preprintarXiv:1812
 Search on the replay buffer: Bridging plan-ning and reinforcement learning,2019, In Advances in Neural Information Processing Systems
 Rewriting history with inverserl: Hindsight inference for policy improvement,2020, arXiv preprint arXiv:2002
 Curriculum-guided hindsight experiencereplay,2019, In Advances in Neural Information Processing Systems
 Diagnosing bottlenecks in deep q-learning algo-rithms,2019, arXiv preprint arXiv:1902
 D4rl: Datasets for deep data-drivenreinforcement learning,2020, arXiv preprint arXiv:2004
 Addressing function approximation error in actor-criticmethods,2018, arXiv preprint arXiv:1802
 Learning to reach goals without reinforcement learning,2019, arXiv preprint arXiv:1912
 Temporal differ-ence variational auto-encoder,2018, arXiv preprint arXiv:1806
 Relay policy learning:Solving long-horizon tasks via imitation and reinforcement learning,2019, arXiv preprint arXiv:1910
 Soft actor-critic: Off-policy maximumentropy deep reinforcement learning with a stochastic actor,2018, arXiv preprint arXiv:1801
 Variational inference using implicit distributions,2017, arXivpreprint arXiv:1702
 On the convergence of stochastic iterative dynamicprogramming algorithms,1994, Neural computation
 Learning to achieve goals,1993, In IJCAI
 Reinforcement learning and control as probabilistic inference: Tutorial and review,2018, arXivpreprint arXiv:1805
 Reinforcement learning without ground-truth state,2019, arXivpreprint arXiv:1905
 Breaking the curse of horizon: Infinite-horizonoff-policy estimation,2018, In Advances in Neural Information Processing Systems
 Learning latent plans from play,2020, In Conference on Robot Learning
 Near-optimal representation learning for hierar-chical reinforcement learning,2018, arXiv preprint arXiv:1810
 Dualdice: Behavior-agnostic estimation of discountedstationary distribution corrections,2019, In Advances in Neural Information Processing Systems
 Goal-aware prediction: Learning to model what matters,2020, arXivpreprint arXiv:2007
 Planning with goal-conditioned policies,2019, InAdvances in Neural Information Processing Systems
 Self-imitation learning,2018, arXiv preprintarXiv:1806
 Thermodynamics as a theory of decision-making with information-processing costs,2013, Proceedings of the Royal Society A: Mathematical
 Maximum entropy gain exploration forlong horizon multi-goal reinforcement learning,2020, arXiv preprint arXiv:2007
 Temporal difference models: Model-free deeprl for model-based control,2018, arXiv preprint arXiv:1802
 Skew-fit: State-covering self-supervised reinforcement learning,2019, arXiv preprint arXiv:1903
 Data-efficient deep reinforcement learning fordexterous manipulation,2017, arXiv preprint arXiv:1704
 Semi-parametric topological memory for naviga-tion,2018, arXiv preprint arXiv:1803
 Universal value function approximators,2015, InInternational conference on machine learning
 Universal value density estimation for imitation learning and goal-conditioned reinforcement learning,2020, arXiv preprint arXiv:2002
 Loss is its own reward: Self-supervisionfor reinforcement learning,2016, arXiv preprint arXiv:1612
 Amortised map inferencefor image super-resolution,2016, arXiv preprint arXiv:1610
 Policy continuation with hindsight inversedynamics,2019, In Advances in Neural Information Processing Systems
 Learning to predict by the methods of temporal differences,1988, Machine learning
 Universal option models,2014, InAdvances in Neural Information Processing Systems
 Deepmind control suite,2018, arXiv preprintarXiv:1801
 dm_control: Software and tasks for continuous control,2020, arXivpreprint arXiv:2006
 Generative adversarialnets from a density ratio estimation perspective,2016, arXiv preprint arXiv:1610
 Modeling purposeful adaptive behavior with the principle of maximum causal entropy,2010, 2010
