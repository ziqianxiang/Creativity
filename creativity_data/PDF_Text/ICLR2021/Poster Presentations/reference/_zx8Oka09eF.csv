title,year,conference
 In search of the real inductive bias: Onthe role of implicit regularization in deep learning,2015, In ICLR (WOrkShop)
 The role ofover-parametrization in generalization of neural networks,2019, In International COnferenCe on LearningRePreSentations
 Gradient descent provably optimizesover-parameterized neural networks,2019, In International COnference on Learning RePreSentations
 A convergence theory for deep learning via over-parameterization,2019, In International Conference on Machine Learning
 Neural tangent kernel: Convergence andgeneralization in neural networks,2018, In AdVanceS in neural information PrOceSSing systems
 Deep neural networks as gaussian processes,2017, arXiv PrLPrint arXiv:1711
 Theoretical insights into the optimizationlandscape of over-parameterized shallow neural networks,2018, IEEE TranSactiOnS on InfOrmatiOnTheory
 Kernel and rich regimes in overparametrized models,2020, arXivPrePrint arXiv:2002
 Reconciling modern machine-learning practice and the classical bias-variance trade-off,2019, PrOcaedingS of the NatiOnal AcademyOfSciences
 Exploring sparsity in recurrentneural networks,2017, ArXiv
 Deep rewiring:Training very sparse deep networks,2018, ArXiv
 Fast sparse convnets,2019, ArXiv
 The state of sparsity in deep neural networks,2019, ArXiv
 SNIP: single-shot network pruningbased on connection sensitivity,2018, CoRR
 Deep residual learning for imagerecognition,2016, In PrOCeedingS of the IEEE conference on COmPUter ViSiOn and Pattem recognition
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE conference on COmPUter ViSiOn and Patternrecognition
 Kernel methods for deep learning,2009, In AdVanCeS in neuralinformation PrOCeSSing systems
