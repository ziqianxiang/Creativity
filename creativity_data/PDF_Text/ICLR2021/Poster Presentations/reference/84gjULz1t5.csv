title,year,conference
 QSGD:Communication-efficient sgd via gradient quantization and encoding,2017, In Advances in NeuralInformation Processing Systems
 Gossip consensus algorithmsvia quantized communication,2010, Automatica
 Decentralized stochastic optimizationand gossip algorithms with compressed communication,2019, In Proceedings of the 36th InternationalConference on Machine Learning
 On linear convergence of two decentralized algorithms,2019, arXiv preprintarXiv:1906
 Can decentralizedalgorithms outperform centralized algorithms? a case study for decentralized parallel stochasticgradient descent,2017, In Advances in Neural Information Processing Systems
 DLM: Decentralized linearized alternatingdirection method of multipliers,2015, IEEE Transactions on Signal Processing
 A double residual compression algorithm forefficient distributed learning,2020, The 23rd International Conference on Artificial Intelligence andStatistics
 Moniqua: Modulo quantized communication in decentralizedSGD,2020, In Proceedings of the 37th International Conference on Machine Learning
 On maintaining linear convergence ofdistributed learning and optimization under limited communication,2020, IEEE Transactions on SignalProcessing
 Distributed learningwith compressed gradient differences,2019, arXiv preprint arXiv:1901
 Distributed subgradient methods for multi-agent optimiza-tion,2009, IEEE Transactions on Automatic Control
 An exact quan-tized decentralized gradient descent algorithm,2019, IEEE Transactions on Signal Processing
 1-bit stochastic gradient descent andapplication to data-parallel distributed training of speech DNNs,2014, In Interspeech 2014
 D2 : Decentralized training overdecentralized data,2018, In Proceedings of the 35th International Conference on Machine Learning
 Deepsqueeze:Decentralization meets error-compensated compression,2019, CoRR
 DoubleSqueeze: Parallel stochasticgradient descent with double-pass error-compensated compression,2019, In Proceedings of the 36thInternational Conference on Machine Learning
 Distributed asynchronous deterministicand stochastic gradient optimization algorithms,1986, IEEE transactions on automatic control
 Accelerated primal-dual algorithms fordistributed smooth convex optimization over networks,2020, In International Conference on ArtificialIntelligence and Statistics
 Exact diffusion for distributed opti-mization and learningâ€”part i: Algorithm development,2018, IEEE Transactions on Signal Processing
 8 andFig,2021, 9
 From Alg,2021, 1
