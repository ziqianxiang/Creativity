title,year,conference
 Towards characterizing divergence in deep q-learning,2019, ArXiv
 An optimistic perspective on offlinereinforcement learning,2020, In International Conference on Machine Learning (ICML)
 On the optimization of deep networks: Implicitacceleration by overparameterization,2018, arXiv preprint arXiv:1802
 Implicit regularization in deep matrixfactorization,2019, In Advances in Neural Information Processing Systems
 The arcade learning envi-ronment: An evaluation platform for general agents,2013, J
 Interference and generalization in temporaldifference learning,2020, arXiv preprint arXiv:2003
 Least-squares temporal difference learning,1999, In ICML
 Neural temporal-difference and q-learningprovably converge to global optima,2019, arXiv preprint arXiv:1905
 The linear programming approach to approximate dynamic programming:Theory and application,2002, PhD thesis
 Greenâ€™s functions with applications,2015, CRC Press
 Error propagation for approximatepolicy and value iteration,2010, In Advances in Neural Information Processing Systems (NIPS)
 Revisiting fundamentals of experience replay,2020, arXiv preprintarXiv:2007
 Rl un-plugged: Benchmarks for offline reinforcement learning,2020, 2020
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, CoRR
 Neural tangent kernel: Convergence and gen-eralization in neural networks,2018, In Advances in Neural Information Processing Systems 31
 Reinforcement learning with unsupervised auxiliary tasks,2016, arXivpreprint arXiv:1611
 Discor: Corrective feedback in reinforcementlearning via distribution correction,2020, arXiv preprint arXiv:2003
 Conservative q-learning for offlinereinforcement learning,2020, arXiv preprint arXiv:2006
 The utility of sparse representationsfor control in reinforcement learning,2018, CoRR
 Self-distillation amplifies regularizationin hilbert space,2020, arXiv preprint arXiv:2002
 On the closeness of eigenvalues and singular values for almost normal matrices,1975, LinearAlgebra and its Applications
 Mastering the game of gowithout human knowledge,2017, nature
 Connecting optimization and regulariza-tion paths,2018, In Advances in Neural Information Processing Systems
 Fast gradient-descent methods for temporal-difference learningwith linear function approximation,2009, In International Conference on Machine Learning (ICML)
 Differentiating the singular value decomposition,2016, Technical report
 A finite-time analysis of q-learning with neural network function ap-proximation,2019, arXiv preprint arXiv:1912
 Kernel-based least squares policy iteration for reinforcementlearning,2007, IEEE Transactions on Neural Networks
 Harnessing structures for value-based planningand reinforcement learning,2019, arXiv preprint arXiv:1909
 A theoretical analysis of deep q-learning,2020, InLearning for Dynamics and Control
 Can temporal-differenceand q-learning learn representation? a mean-field theory,2020, arXiv preprint arXiv:2006
