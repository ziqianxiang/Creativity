title,year,conference
 Fine-Grained Analysisof Optimization and Generalization for Overparameterized Two-Layer Neural Networks,2019, InInternational Conference on Machine Learning
 Fine-grained analysis ofoptimization and generalization for overparameterized two-layer neural networks,2019, arXiv preprintarXiv:1901
 Massively multilingualneural machine translation in the wild: Findings and challenges,2019, 2019
 Multitask learning,1997, Machine learning
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 The next generation of the penn worldtable,2015, American economic review
 Approximation capabilities of multilayer feedforward networks,1991, Neural networks
 Adaptive mixtures oflocal experts,1991, Neural computation
 One model to learn them all,2017, arXiv preprint arXiv:1706
 Multitasking capability versus learning efficiency in neural network ar-chitectures,2017, In CogSci
 Exploring the Limits of Transfer Learning with a UnifiedText-to-Text Transformer,2019, arXiv:1910
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, arXivpreprint arXiv:1701
 Sharper bounds for gaussian and empirical processes,1994, The Annals of Probability
 Smalland practical bert models for sequence labeling,2019, arXiv preprint arXiv:1909
 A survey on multi-task learning,2017, arXiv preprint arXiv:1707
