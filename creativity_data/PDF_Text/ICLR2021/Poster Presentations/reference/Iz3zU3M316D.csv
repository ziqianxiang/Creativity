title,year,conference
 Theoretical analysis of auto rate-tuning by batchnormalization,2019, In International Conference on Learning Representations (ICLR)
 Layer normalization,2016, arXiv preprintarXiv:1607
 Learning de-biasedrepresentations with biased representations,2020, In International Conference on Machine Learning
 Riemannian approach to batch normalization,2017, In Advances inNeural Information Processing Systems
 Autoaugment:Learning augmentation policies from data,2018, arXiv preprint arXiv:1805
 Transformer-xl: Attentive language models beyond a fixed-length context,2019, arXiv preprintarXiv:1901
 Incorporating nesterov momentum into adam,2016, In International Conference onLearning Representations (ICLR) workshop
 Optimization theory for relu neural networkstrained with normalization layers,2020, In International Conference on Machine Learning
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In Proceedings of the thirteenth international conference on artificial intelligence andstatistics
 Deep pyramidal residual networks,2017, In Proceedingsof the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Rexnet: Diminishing represen-tational bottleneck on convolutional neural network,2020, arXiv preprint arXiv:2007
 Deep residual learning for image recog-nition,2016, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Natural adversarialexamples,2019, arXiv preprint arXiv:1907
 Norm matters: efficient and accuratenormalization schemes in deep networks,2018, In Advances in Neural Information Processing Systems
 Deep networks withstochastic depth,2016, In European conference on computer vision
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In International Conference on Machine Learning (ICML)
 NSML: Meet the MLaaS platformwith a real-world case study,2018, arXiv preprint arXiv:1810
 Proxy anchor loss for deep metriclearning,2020, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations (ICLR)
 Learning multiple layers of features from tiny images,2009, In Tech Report
 Evaluation of algorithmsusing games: The case of music tagging,2009, In International Society for Music Information RetrievalConference (ISMIR)
 Gradient-based learning appliedto document recognition,1998, Proceedings of the IEEE
 Microsoft COCO: Common objects in context,2014, In EuropeanConference on Computer Vision (ECCV)
 On the variance of the adaptive learning rate and beyond,2020, In International Conference onLearning Representations (ICLR)
 SSD: Single shot multibox detector,2016, In European Conference on ComputerVision (ECCV)
 SGDR: Stochastic gradient descent with warm restarts,2016, arXivpreprint arXiv:1608
 Pointer sentinel mixturemodels,2016, arXiv preprint arXiv:1609
 Deep metric learning via liftedstructured feature embedding,2016, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition (CVPR)
 On the convergence of adam and beyond,2018, InInternational Conference on Learning Representations (ICLR)
 Weight normalization: A simple reparameterization to acceleratetraining of deep neural networks,2016, In Advances in neural information processing systems
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition (CVPR)
 How does batch normal-ization help optimization? In Advances in Neural Information Processing Systems,2018, 2018
 Facenet: A unified embedding for facerecognition and clustering,2015, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition (CVPR)
 Very deep convolutional networks for large-scale imagerecognition,2015, In International Conference on Learning Representations (ICLR)
 On the importance of initializa-tion and momentum in deep learning,2013, In International Conference on Machine Learning (ICML)
 Efficientnet: Rethinking model scaling for convolutional neuralnetworks,2019, arXiv preprint arXiv:1905
 Instance normalization: The missing in-gredient for fast stylization,2016, arXiv preprint arXiv:1607
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Speech commands: A dataset for limited-vocabulary speech recognition,2018, arXivpreprint arXiv:1804
 Automatic music tagging with harmoniccnn,2019, In Late Breaking Demo in the International Society for Music Information Retrieval Conf
 Toward interpretable music tagging with self-attention,2019, arXiv preprint arXiv:1906
 Visualizing and understanding self-attention basedmusic tagging,2019, ICML Workshop on Machine Learning for Music Discovery
 Data-driven harmonic filters for audiorepresentation learning,2020, In International Conference on Acoustics
 Evaluation of cnn-based automaticmusic tagging models,2020, arXiv preprint arXiv:2006
 Group normalization,2018, In Proceedings of the European Conference onComputer Vision (ECCV)
 Large batch training of convolutional networks,2017, arXivpreprint arXiv:1708
 Large batch optimization for deep learn-ing: Training bert in 76 minutes,2019, arXiv preprint arXiv:1904
 Wide residual networks,2016, In The British Machine VisionConference (BMVC)
 Adabelief optimizer: Adapting stepsizes by the belief in observedgradients,2020, Advances in Neural Information Processing Systems
 at P					9-Class ImageNet			,2014,999	
