title,year,conference
 Robust constrainedmodel predictive control using linear matrix inequalities,1996, Automatica
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 Solving Rubik’s Cube with aRobot Hand,2019, arXiv preprint arXiv:1910
 Robust Reinforcement Learning,2005, Neural Computation
 Policy Iterations on the Hamilton-Jacobi-IsaacsEquation for H∞ State Feedback Control With Input Saturation,2006, IEEE Transactions on AutomaticControl
 A game theoretic algorithm to computelocal stabilizing solutions to HJBI equations in nonlinear H∞ control,2009, Automatica
 Neural-network-based zero-sum game for discrete-timenonlinear systems via iterative adaptive dynamic programming algorithm,2013, Neurocomputing
 Simultaneous policy update algorithms for learning the solution oflinear continuous-time H∞ state feedback control,2013, Information Sciences
 Off-Policy Reinforcement Learning for H∞ ControlDesign,2014, IEEE Transactions on Cybernetics
 A robust stability approach to robot reinforcement learningbased on a parameterization of stabilizing controllers,2017, In 2017 IEEE International Conference onRobotics and Automation (ICRA)
 Robust Adversarial Rein-forcement Learning,2017, In Proceedings of the 34th International Conference on Machine Learning
 Stability-certified reinforcement learning: A control-theoretic perspec-tive,2018, arXiv preprint arXiv:1810
 Neural Lyapunov Control,2019, In Advances in NeuralInformation Processing Systems
 H∞ Model-free ReinforcementLearning with Robust Stability Guarantee,2019, CoRR
 Policy Optimization for H2 Linear Control with H∞ Ro-bustness Guarantee: Implicit Regularization and Global Convergence,2020, In Learning for Dynamicsand Control
 Safe Exploration in Finite MarkovDecision Processes with Gaussian Processes,2016, In Advances in Neural Information ProcessingSystems
 Reachability-based safe learning with Gaussian processes,2014, In53rd IEEE Conference on Decision and Control
 Safe Exploration and Optimizationof Constrained MDPs Using Gaussian Processes,2018, In Proceedings of the AAAI Conference onArtificial Intelligence
 Constrained Policy Optimization,2017, InProceedings of the 34th International Conference on Machine Learning
 Efficient Exploration for Constrained MDPs,2018, In2018 AAAI Spring Symposia
 Projection-BasedConstrained Policy Optimization,2020, In International Conference on Learning Representations
 OptNet: Differentiable Optimization as a Layer in Neural Net-works,2017, In Proceedings of the 34th International Conference on Machine Learning
 Differentiable Learning of Submodular Models,2017, In Advancesin Neural Information Processing Systems
 Differentiable Submodular Maximiza-tion,2018, In Proceedings of the 27th International Joint Conference on Artificial Intelligence
 Nonlinear Dynamical Systems and Control: ALyapunov-Based Approach,2011, Princeton University Press
 Introduction to Stochastic Control Theory,1971, Elsevier
 A primal-dual semi-definite programmingapproach to linear quadratic control,2001, IEEE Transactions on Automatic Control
 Proximal PolicyOptimization Algorithms,2017, arXiv preprint arXiv:1707
 Convex Optimization,2004, Cambridge University Press
 Projection algorithms and monotone operators,1996, PhD thesis
