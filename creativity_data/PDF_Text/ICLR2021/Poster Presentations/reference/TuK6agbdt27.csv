title,year,conference
 Learning togeneralize to new compositions in image understanding,2016, arXiv preprint arXiv:1608
 Layer normalization,2016, arXiv preprintarXiv:1607
 Meta-learning deep energy-based memory models,2020, In International Conference on Learning Representations
 Transformer-xl: Attentive language models beyond a fixed-length context,2019, arXiv preprintarXiv:1901
 Dynamic connections in neural networks,1982, Biological cybernetics
 Connectionism and cognitive architecture: A critical analy-sis,1988, Cognition
 Discovering latent causes in reinforcementlearning,2015, Current Opinion in Behavioral Sciences
 Neural turing machines,2014, arXiv preprintarXiv:1410
 Long Short-Term Memory,1997, Neural Computation
 Learning to learn using gradient descent,2001, In LectureNotes on Comp
 Neural networks and physical systems with emergent collective computationalabilities,1982, Proceedings of the national academy of sciences
 Learning graphical state transitions,2017, In International Conference on LearningRepresentations
 Sparse distributed memory,1988, MIT press
 Tensor decompositions and applications,2009, SIAM review
 Bidirectional associative memories,1988, IEEE Transactions on Systems
 Dynamic evaluation of neuralsequence models,2018, In Jennifer Dy and Andreas Krause (eds
 Dense associative memory for pattern recognition,2016, In Advancesin neural information processing systems
 Ask me anything: Dynamic memory networksfor natural language processing,2016, In Maria Florina Balcan and Kilian Q
 Still not systematic after all these years: On the compositionalskills of sequence-to-sequence recurrent networks,2017, CoRR
 Buildingmachines that learn and think like people,2017, Behavioral and Brain Sciences
 Self-attentive associative memory,2020, arXiv preprintarXiv:2002
 Gated graph sequence neuralnetworks,2016, In International Conference on Learning Representations
 On the state of the art of evaluation in neural languagemodels,2017, CoRR
 Pointer sentinel mix-ture models,2017, In International Conference on Learning Representations
 Regularizing and optimizing LSTMlanguage models,2018, In International Conference on Learning Representations
 Differentiable plasticity: training plastic neu-ral networks with backpropagation,2018, In Jennifer Dy and Andreas Krause (eds
 Backpropamine: trainingself-modifying neural networks with differentiable neuromodulated plasticity,2019, In InternationalConference on Learning Representations
 Recurrentneural network based language model,2010, In Eleventh annual conference of the international speechcommunication association
 A simple neural attentivemeta-learner,2018, In International Conference on Learning Representations
 Asynchronous methods for deep reinforcementlearning,2016, In International conference on machine learning
 A connectionist symbol manipulator that discovers the structureof context-free languages,1993, In Advances in neural information processing systems
 Metalearned neuralmemory,2019, In Advances in Neural Information Processing Systems
 Connectionism and the problem of systematicity,1995, PhD thesis
 Hopfieldnetworks is all you need,2020, arXiv preprint arXiv:2008
 The perceptron: a probabilistic model for information storage and organizationin the brain,1958, Psychological review
 Learning to reason with third order tensor products,2018, InAdvances in Neural Information Processing Systems (NeurIPS)
 Memory integration: neural mechanisms and impli-cations for behavior,2015, Current opinion in behavioral sciences
 Turing computability with neural nets,1991, Applied MathematicsLetters
 Tensor product variable binding and the representation of symbolic structures inconnectionist systems,0004, Artif
 Symbolic functions from neural computation,2012, Phil
 End-to-end memory networks,2015, In Advancesin neural information processing systems
 The tensor memory hypothesis,2017, ArXiv
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Memory networks,2015, In International Conferenceon Learning Representations
 Non-holographicassociative memory,1969, Nature
 Learning to update auto-associative memory in recurrent neural net-works for improving sequence memorization,2017, arXiv preprint arXiv:1709
 Virtually every sentence contains precisely one fact,2018, Because of that
