title,year,conference
 Neural machine translation by jointlylearning to align and translate,2015, In 3rd International Conference on Learning Representations
 Hierarchical generative modeling for controllable speechsynthesis,2018, In International Conference on Learning Representations
 Glow-tts: A generative flow fortext-to-speech via monotonic alignment search,2020, arXiv preprint arXiv:2005
 Adam: A method for stochastic optimization,2015, In ICLR (Poster)
 Glow: Generative flow with invertible 1x1 convolutions,2018, InAdvances in neural information processing Systems
 Im-proved variational inference with inverse autoregressive flow,2016, In Advances in neural informationprocessing systems
 Nanoflow: Scalable normalizing flows with sub-linear parameter complexity,2020, arXiv preprint arXiv:2006
 Biva: A very deep hierarchy oflatent variables for generative modeling,2019, In Advances in neural information processing systems
 Spectral normalizationfor generative adversarial networks,2018, In International Conference on Learning Representations
 Waveflow: A compact flow-based model forraw audio,2019, arXiv preprint arXiv:1912
 Fastspeech 2: Fast andhigh-quality end-to-end text-to-speech,2020, arXiv preprint arXiv:2006
 Natural tts synthesis by con-ditioning wavenet on mel spectrogram predictions,2018, In 2018 IEEE International Conference onAcoustics
 Laddervariational autoencoders,2016, In Advances in neural information processing systems
 Efficiently trainable text-to-sPeechsystem based on deep convolutional networks with guided attention,2018, In 2018 IEEE InternationalConference on Acoustics
 Nvae: A deep hierarchical variational autoencoder,2020, arXiv preprintarXiv:2007
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Tacotron: Towards end-to-end speech synthesis,2017, InProc
 In Proc,2019, Interspeech 2019
 Making convolutional networks shift-invariant again,2019, In Proceedings of the 36thInternational Conference on Machine Learning
