title,year,conference
 Convex multi-task feature learn-ing,2008, Machine learning
 Nonnegative sparse pcawith provable guarantees,2014, In International Conference on Machine Learning
 Greedy layerwise learning can scaleto imagenet,2019, In International conference on machine learning
 Globally optimal gradient descent for a convnet with gaussianinputs,2017, arXiv preprint arXiv:1702
 Unifying nuclearnorm and bilinear factorization approaches for low-rank matrix decomposition,2013, In Proceedingsof the IEEE International Conference on Computer Vision
 Global convergence of frank wolfe on one hidden layernetworks,2020, arXiv preprint arXiv:2002
 Cone-constrained principal componentanalysis,2014, In Advances in Neural Information Processing Systems
 Convex optimization for shallow neural networks,2019, In 2019 57thAnnual Allerton Conference on Communication
 Convex duality of deep neural networks,2020, arXiv preprintarXiv:2002
 Training convolutional relu neural networks in polynomial time:Exact convex optimization formulations,2020, arXiv preprint arXiv:2006
 An algorithm for quadratic programming,1956, Naval researchlogistics quarterly
 Learning two-layer neural networks withsymmetric inputs,2018, arXiv preprint arXiv:1810
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In Proceedings of the IEEE internationalconference on computer vision
 Decorrelated batch normalization,2018, In Proceedingsof the IEEE Conference on Computer Vision and Pattern Recognition
 Neural tangent kernel: Convergence and gen-eralization in neural networks,2018, In Advances in neural information processing systems
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Characterization of completely positive graphs,1993, DiscreteMathematics
 All local minima are global for two-layer relu neural networks:The hidden convex optimization landscape,2020, arXiv preprint arXiv:2006
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 On dropout and nuclear norm regularization,2019, arXiv preprintarXiv:1905
 On the implicit bias of dropout,2018, arXiv preprintarXiv:1806
 In search of the real inductive bias: On therole of implicit regularization in deep learning,2014, arXiv preprint arXiv:1412
 Neural networks are convex regularizers: Exact polynomial-time con-vex optimization formulations for two-layer networks,2020, arXiv preprint arXiv:2002
 Guaranteed minimum-rank solutions of linearmatrix equations via nuclear norm minimization,2010, SIAM review
 Convex regulariza-tion behind neural reconstruction,2020, arXiv preprint arXiv:2012
 Maximum-margin matrix factorization,2005, InAdvances in neural information processing systems
 An introduction to hyperplane arrangements,2004, Geometric combinatorics
