title,year,conference
 Deep equilibrium models,2019, In Advances in NeuralInformation Processing Systems
 Multiscale deep equilibrium models,2020, arXiv preprintarXiv:2006
 Spectrally-normalized margin bounds forneural networks,2017, In Advances in Neural Information Processing Systems
 Neural ordinarydifferential equations,2018, In Advances in neural information processing systems
 Lipschitz certificates for neural network struc-tures driven by averaged activation operators,2019, arXiv preprint arXiv:1903
 Efficientand accurate estimation of lipschitz constants for deep neural networks,2019, In Advances in NeuralInformation Processing Systems
 Stability-certified reinforcement learning: A control-theoretic perspec-tive,2018, arXiv preprint arXiv:1810
 Lipschitz constant estimation of neural networksvia sparse polynomial optimization,2019, In International Conference on Learning Representations
 Certified defenses against adversarial exam-ples,2018, In International Conference on Learning Representations
 Foolbox: A python toolbox to benchmarkthe robustness of machine learning models,2017, In Reliable Machine Learning in the Wild Workshop
 Intriguing properties of neural networks,2014, In 2nd InternationalConference on Learning Representations
 Lipschitz-margin training: Scalable certifi-cation of perturbation invariance for deep neural networks,2018, In Advances in neural informationprocessing systems
 Lipschitz regularity of deep neural networks: analysis andefficient estimation,2018, In Advances in Neural Information Processing Systems
 Towards fast computation of certified robustness for relu networks,2018, InInternational Conference on Machine Learning
 Monotone operator equilibrium networks,2020, arXiv preprintarXiv:2006
 On lipschitz bounds of general convolutionalneural networks,2019, IEEE Transactions on Information Theory
