title,year,conference
 Explaining deep neural networks with a poly-nomial time algorithm for shapley value approximation,2019, In International Conference on MachineLearning
 Improving queryefficiency of black-box adversarial attack,2020, In ECCV
 Towards evaluating the robustness of neural networks,2017, In 2017ieee symposium on security and privacy (sp)
 Learning variational word masks to improve the interpretability ofneural text classifiers,2020, In EMNLP
 Generating hierarchical explanations on text clas-sification via feature interaction detection,2020, In ACL
 L-shapley and c-shapley:Efficient model interpretation for structured data,2018, In arXiv:1808
 Zoo: Zeroth order opti-mization based black-box attacks to deep neural networks without training substitute models,2017, InarXiv:1708
 Ead: Elastic-net attacksto deep neural networks via adversarial examples,2018, In AAAI
 Dual pathnetworks,2017, In Advances in neural information processing systems
 Detecting statistical interactions with additivegroves of trees,2008, In ICML
 Why do adversarial attacks transfer? explaining transfer-ability of evasion and poisoning attacks,2019, In 28th USENIX Security Symposium USENIX Security19)
 Evading defenses to transferable adversarialexamples by translation-invariant attacks,2019, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Adversarialcamouflage: Hiding physical-world attacks with natural styles,2020, In CVPR
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Deep residual learning for image recog-nition,2016, In CVPR
 Squeeze-and-excitation networks,2018, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Enhancingadversarial example transferability with an intermediate level attack,2019, In Proceedings of the IEEEInternational Conference on Computer Vision
 Black-box adversarial attacks withlimited queries and information,2018, In ICML
 Feature space perturbations yield moretransferable adversarial examples,2019, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Transferable perturbations ofdeep feature distributions,2020, In International Conference on Learning Representations
 Explaining explanations: Axiomatic featureinteractions for deep networks,2020, arXiv preprint arXiv:2002
 Towards hierarchical im-portance attribution: Explaining compositional semantics for neural sequence models,2020, In ICLR
 Imagenet classification with deep convo-lutional neural networks,2012, pp
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Learning trans-ferable adversarial examples via ghost networks,2020, In Proceedings of the AAAI Conference onArtificial Intelligence
 Delving into transferable adversarial exam-ples and black-box attacks,2016, ICLR
 Characterizing adversarial subspaces usinglocal intrinsic dimensionality,2018, In ICLR
 Under-standing adversarial attacks on deep learning based medical image analysis systems,2021, PatternRecognition
 Beyond word importance: Contextual decompositionto extract interactions from lstms,2018, In ICLR
 Practical black-box attacks against machine learning,2017, In arXiv:1602
 Game-theoretic understanding of adversarially learned features,2021, arXivpreprint arXiv:2103
 A value for n-person games,1953, In Contributions to the Theory of Games
 Very deep convolutional networks for large-scale imagerecognition,2015, In ICLR
 Hierarchical interpretations for neural networkpredictions,2019, In ICLR
 One pixel attack for fooling deepneural networks,2017, In arXiv:1710
 The many shapley values for model explanation,2019, arXivpreprint arXiv:1908
 Axiomatic attribution for deep networks,2017, InInternational Conference on Machine Learning
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 On theconvergence and robustness of adversarial training,2019, In ICML
 Skip connections matter:On the transferability of adversarial examples generated with resnets,2020, In International Conferenceon Learning Representations
 Understanding and enhancing the transferability of adver-sarial examples,2018, arXiv preprint arXiv:1802
 Building interpretable interaction trees for deep nlp models,2021, In AAAI
 Game-theoretic interactions of differentorders,2020, arXiv preprint arXiv:2010
 Interpreting andboosting dropout from a game-theoretic view,2021, In ICLR
 Interpreting multivariateinteractions in dnns,2021, In AAAI
 Learning transferable architecturesfor scalable image recognition,2018, In Proceedings of the IEEE conference on computer vision andpattern recognition
 The computational cost of the Shapley-based interaction-reduction loss isrelatively low,2008, Because of the efficiency axiom of the Shapley value
