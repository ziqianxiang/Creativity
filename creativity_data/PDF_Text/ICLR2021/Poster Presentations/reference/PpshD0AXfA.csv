title,year,conference
 The infinite hidden markov model,2002, InAdvances in neural information processing systems
 Sylvesternormalizing flows for variational inference,2018, arXiv preprint arXiv:1803
 Solution of vandermonde systems of equations,1970, Mathematics ofcomputation
 Data-driven approach for creating syntheticelectronic medical records,2010, BMC medical informatics and decision making
 Nice: Non-linear independent componentsestimation,2014, arXiv preprint arXiv:1410
 Density estimation using real nvp,2016, arXivpreprint arXiv:1605
 Neural spline flows,2019, InAdvances in Neural Information Processing Systems
 Generating sequences with recurrent neural networks,2013, arXiv preprint arXiv:1308
 Flow++: Improving flow-based generative models with variational dequantization and architecture design,2019, arXiv preprintarXiv:1902
 Emerging convolutions for generativenormalizing flows,2019, arXiv preprint arXiv:1901
 Neural autoregressiveflows,2018, International Conference on Machine Learning (ICML)
 A matrix theory proof of the discrete convolution theorem,1971, IEEE Transactions on Audio andElectroacoustics
 Bidirectional rnn for medical event detection in electronichealth records,2016, In Proceedings of the conference
 Glow: Generative flow with invertible 1x1 convolutions,2018, InAdvances in neural information processing systems
 Normalizing flows: An introduction and reviewof current methods,2020, IEEE Transactions on Pattern Analysis and Machine Intelligence
 Structured inference networks for nonlinear statespace models,2017, AAAI
 Professor forcing: A new algorithm for training recurrent networks,2016, InAdvances in neural information processing Systems
 Theoretical insights into memorization ingans,2018, In Neural Information Processing Systems Workshop
 Wavenet: A generative model for rawaudio,2016, arXiv preprint arXiv:1609
 Discrete-time signal processing,1999, Pearson Education India
 Masked autoregressive flow for densityestimation,2017, In Advances in Neural Information Processing Systems
 Assessinggenerative models via precision and recall,2018, In Proceedings of the 32nd International Conferenceon Neural Information Processing Systems
 Bidirectional recurrent neural networks,1997, IEEE transactions onSignal Processing
 Veegan:Reducing mode collapse in gans using implicit variational learning,2017, In Advances in NeuralInformation Processing Systems
 Quant gans: Deep generation offinancial time series,2020, Quantitative Finance
 Latent normalizing flows for discrete sequences,2019, arXivpreprint arXiv:1901
