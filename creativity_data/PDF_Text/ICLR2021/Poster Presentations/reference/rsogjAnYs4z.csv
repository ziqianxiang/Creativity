title,year,conference
 Tensorflow: A system for large-scale machine learning,2016, In 12th USENIXsymposium on operating systems design and implementation (OSD116)
 Stochastic gradient learning in neural networks,1991, Neuro Nimes
 Optimization methods for large-scale machinelearning,2018, Siam Review
 Gradient descent provably optimizesover-parameterized neural networks,2019, ICLR
 Mini-batch stochastic approximation meth-ods for nonconvex stochastic composite optimization,2016, Mathematical Programming
 SNIP: Single-shot network pruningbased on connection sensitivity,2019, ICLR
 A signal propaga-tion perspective for pruning neural networks at initialization,2020, ICLR
 Learning overparameterized neural networks via stochastic gradientdescent on structured data,2018, NeurIPS
 Pruning algorithms-a survey,1993, Neural Networks
 Measuring the effects of data parallelism on neural network training,2019, JMLR
 Picking winning tickets before training bypreserving gradient flow,2020, ICLR
 Stochastic nonconvex optimization with large minibatches,2017, arXivpreprint arXiv:1709
 Which algorithmic choices matter at which batch sizes? insightsfrom a noisy quadratic model,2019, NeurIPS
 Why gradient clipping acceleratestraining: A theoretical justification for adaptivity,2020, ICLR
