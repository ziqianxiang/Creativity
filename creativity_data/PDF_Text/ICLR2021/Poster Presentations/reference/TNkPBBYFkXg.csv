title,year,conference
 Qsgd:Communication-efficient sgd via gradient quantization and encoding,2017, In Advances in NeuralInformation Processing Systems
 Siloed federatedlearning for multi-centric histopathology datasets,2020, In Domain Adaptation and RepresentationTransfer
 Layer normalization,2016, arXiv preprintarXiv:1607
 Demystifying parallel and distributed deep learning: An in-depthconcurrency analysis,2019, ACM Computing Surveys (CSUR)
 Towardsfederated learning at scale: System design,2019, arXiv preprint arXiv:1902
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Federated learning for mobilekeyboard prediction,2018, arXiv preprint arXiv:1811
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, arXiv preprint arXiv:1502
 Communication-efficient distributed sgd with sketching,2019, In Advances in Neural Information Processing Systems
 Improving federated learning per-sonalization via model agnostic meta learning,2019, arXiv preprint arXiv:1909
 Adaptive gradient-based meta-learning methods,2019, In Advances in Neural Information Processing Systems
 Federated learning: Strategies for improving communication efficiency,2016, arXivpreprint arXiv:1610
 Learning multiple layers of features from tiny images,2009, 2009
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Lotteryfl:Personalized and communication-efficient federated learning with lottery ticket hypothesis onnon-iid datasets,2020, arXiv preprint arXiv:2008
 Fedmd: Heterogenous federated learning via model distillation,2019, arXivpreprint arXiv:1910
 Threats to federated learning: A survey,2020, arXiv preprintarXiv:2003
 Three approaches forpersonalization with applications to federated learning,2020, arXiv preprint arXiv:2002
 Exploiting unintendedfeature leakage in collaborative learning,2019, In 2019 IEEE Symposium on Security and Privacy (SP)
 Pointer sentinel mixturemodels,2016, arXiv preprint arXiv:1609
 Federated multi-tasklearning,2017, In Advances in Neural Information Processing Systems
 Efficientnet: Rethinking model scaling for convolutional neuralnetworks,2019, arXiv preprint arXiv:1905
 Splitfed: Whenfederated learning meets split learning,2020, arXiv preprint arXiv:2004
 Instance normalization: The missing in-gredient for fast stylization,2016, arXiv preprint arXiv:1607
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Federated evaluation of on-device personalization,2019, arXiv preprint arXiv:1910
 Group normalization,2018, In Proceedings of the European conference oncomputer vision (ECCV)
 Assisted learning: a framework for multi-organization learning,2020, NeurIPS 2020 (spotlight)
 Wide residual networks,2016, arXiv preprintarXiv:1605
 Federatedlearning with non-iid data,2018, arXiv preprint arXiv:1806
 Deep leakage from gradients,2019, In Advances in NeuralInformation Processing Systems
