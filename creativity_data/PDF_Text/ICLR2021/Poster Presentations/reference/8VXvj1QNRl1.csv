title,year,conference
 Discovering interpretable representationsfor both deep generative and discriminative models,2018, In International Conference on MachineLearning
 Rezero is all you need: Fast convergence at large depth,2020, arXiv preprintarXiv:2003
 Training with noise is equivalent to tikhonov regularization,1995, Neural computation
 Generating sentences from a continuous space,2015, arXiv preprint arXiv:1511
 Understanding disentangling in beta-VAE,2018, arXiv preprintarXiv:1804
 Improving generalization for temporal difference learning: The successor representa-tion,1993, Neural Computation
 A framework for the quantitative evaluation of disen-tangled representations,2018, In International Conference on Learning Representations
 Conditional variance penalties and domain shiftrobustness,2017, arXiv preprint arXiv:1710
 beta-VAE: Learning basic visual concepts with aconstrained variational framework,2017, In International Conference on Learning Representations
 Darla: Improving zero-shot trans-fer in reinforcement learning,2017, In International Conference on Machine Learning
 Unsupervised feature extraction by time-contrastive learningand nonlinear ica,2016, In Advances in Neural Information Processing Systems
 Nonlinear independent component analysis: Existence anduniqueness results,1999, Neural Networks
 Nonlinear ica using auxiliary variablesand generalized contrastive learning,2019, In International Conference on Artificial Intelligence andStatistics
 Sim-to-real via sim-to-sim: Data-efficient robotic grasping via randomized-to-canonical adaptation networks,2019, In Proceedings ofthe IEEE Conference on Computer Vision and Pattern Recognition
 Disentangling by factorising,2018, In International Conference onMachine Learning
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Auto-encoding variational Bayes,2014, In International Conferenceon Learning Representations
 Variational inference of disen-tangled latent concepts from unlabeled observations,2018, In International Conference on LearningRepresentations
 Learning methods for generic object recognition withinvariance to pose and lighting,2004, In IEEE Conference on Computer Vision and Pattern Recognition
 Challenging common assumptions in the unsupervised learning of disentangled repre-sentations,2019, In International Conference on Machine Learning
 Weakly-supervised disentanglement without compromises,2020, arXiv preprintarXiv:2002
 Domain generalization via invariantfeature representation,2013, In International Conference on Machine Learning
 Sim-to-real transfer ofrobotic control with dynamics randomization,2018, In 2018 IEEE international conference on roboticsand automation (ICRA)
 Deep visual analogy-making,2015, In Advancesin Neural Information Processing Systems
 Stochastic backpropagation andapproximate inference in deep generative models,2014, arXiv preprint arXiv:1401
 Learning deep disentangled embeddings with the f-statisticloss,2018, In Advances in Neural Information Processing Systems
 Towards causal representation learning,2021, arXiv preprintarXiv:2102
 Weakly supervised disen-tanglement with guarantees,2019, arXiv preprint arXiv:1910
 Creating artificial neural networks that generalize,1991, Neuralnetworks
 Laddervariational autoencoders,2016, In Advances in neural information processing systems
 On disentangled representations learned fromcorrelated data,2020, arXiv preprint arXiv:2006
