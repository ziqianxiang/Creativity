title,year,conference
 Striving for simplicity in off-policydeep reinforcement learning,2019, arXiv preprint arXiv:1907
 Value-iteration based fitted policy iteration:learning with a single trajectory,2007, In 2007 IEEE international symposium on approximate dynamicprogramming and reinforcement learning
 Increasingthe action gap: New operators for reinforcement learning,2016, In Thirtieth AAAI Conference onArtificial Intelligence
 Extrapolating beyond sub-optimal demonstrations via inverse reinforcement learning from observations,2019, In Proceedings ofthe International Conference on Machine Learning
 Revisiting fundamentals of experience replay,2020, arXiv preprintarXiv:2007
 Off-policy deep reinforcement learning withoutexploration,2019, In International Conference on Machine Learning
 Safe policy improvement by minimiz-ing robust baseline regret,2016, In Advances in Neural Information Processing Systems
 Bounded parameter markov decision processes,1997, InEuropean Conference on Planning
 Provable benefit of orthogonal initialization in opti-mizing deep linear networks,2020, arXiv preprint arXiv:2001
 Imitation learning: Asurvey of learning methods,2017, ACM Computing Surveys (CSUR)
 Robust dynamic programming,2005, Mathematics of Operations Research
 Way off-policy batch deep reinforcement learning ofimplicit human preferences in dialog,2019, arXiv preprint arXiv:1907
 Minimax confidence interval for off-policy evaluation and policyoptimization,2020, arXiv preprint arXiv:2002
 Approximately optimal approximate reinforcement learning,2002, InICML
 Morel: Model-based offline reinforcement learning,2020, arXiv preprint arXiv:2005
 Conservative q-learning for offlinereinforcement learning,2020, arXiv preprint arXiv:2006
 Batch reinforcement learning,2012, Reinforcementlearning
 Safe policy improvement withbaseline bootstrapping,2019, In International Conference on Machine Learning
 Bandit algorithms,2020, Cambridge University Press
 Provably good batch reinforce-ment learning without great exploration,2020, arXiv preprint arXiv:2007
 Empirical bernstein bounds and sample variance penal-ization,2009, arXiv preprint arXiv:0907
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 Safe policy improvement withsoft baseline bootstrapping,2019, In Joint European Conference on Machine Learning and KnowledgeDiscovery in Databases
 Robust control of markov decision processes with uncertaintransition matrices,2005, Operations Research
 Trust regionpolicy optimization,2015, In International conference on machine learning
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Safe policy improvement with anestimated baseline policy,2019, arXiv preprint arXiv:1909
 The optimizerâ€™s curse: Skepticism and postdecision surprisein decision analysis,2006, Management Science
 Reinforcement learning: An introduction,2018, MIT press
 High confidence policyimprovement,2015, In International Conference on Machine Learning
 Deep reinforcement learning with double q-learning,2016, In Thirtieth AAAI conference on artificial intelligence
 Blending autonomous exploration andapprenticeship learning,2011, In Advances in Neural Information Processing Systems
 Critic regularizedregression,2020, arXiv preprint arXiv:2006
 Minatar: An atari-inspired testbed for thorough and reproduciblereinforcement learning experiments,2019, arXiv preprint arXiv:1903
 Mopo: Model-based offline policy optimization,2020, arXiv preprintarXiv:2005
 The imitation algorithm simply returns the policy which takes actions inproportion to their observed frequencies in the dataset,1000, For the UA pessimistic algorithm
