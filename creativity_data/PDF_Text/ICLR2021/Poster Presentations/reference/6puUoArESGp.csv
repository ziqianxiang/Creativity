title,year,conference
 Concept Saliency Maps to Visualize Relevant Featuresin Deep Generative Models,2019, In ICMLA
 Human-centered tools for coping withimperfect algorithms during medical decision-making,2019, In CHI
 Measurementerror in nonlinear models: a modern perspective,2006, CRC press
 Global and local interpretability for cardiac MRI classification,2019, In MICCAI
 Towards automatic concept-basedexplanations,2019, In NeurIPS
 Deep learning,2016, MIT press
 Regression concept vectors for bidirec-tional explanations in histopathology,2018, In Understanding and Interpreting Machine Learning inMedical Image Computing Applications
 InteractiveNaming for Explaining Deep Neural Networks: A Formative Study,2018, arXiv:1812
 Deep IV: A flexible approach forcounterfactual prediction,2017, In ICML
 Deep residual learning for imagerecognition,2016, In CVPR
 A benchmark for interpretabilitymethods in deep neural networks,2019, In NearIPS
 Adam: A method for stochastic optimization,2014, arXiv:1412
 Concept Bottleneck Models,2020, In ICML
 Interpretability beyond classification output: Semanticbottleneck networks,2019, arXiv:1907
 Interpretable AI for Deep Learning- BasedMeteorological Applications,2019, In American Meteorological Society Annual Meeting
