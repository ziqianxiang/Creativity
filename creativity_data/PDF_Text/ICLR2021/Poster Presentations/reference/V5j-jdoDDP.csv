title,year,conference
 On the robustness of interpretability methods,2018, arXivpreprint arXiv:1806
 On pixel-wise explanations for non-linear classifier decisions by layer-wiserelevance propagation,2015, PloS one
 Real time image saliency for black box classifiers,2017, In Advances inNeural Information Processing Systems
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Interpretable explanations of black boxes by meaningful perturba-tion,2017, In Proceedings of the IEEE International Conference on Computer Vision
 Safety verification of deep neuralnetworks,2017, In International Conference on Computer Aided Verification
 Abduction-based explanations formachine learning models,2019, In Proceedings of the AAAI Conference on Artificial Intelligence
 Mnist handwritten digit database,2010, 2010
 A rate-distortion frameworkfor explaining neural network decisions,2019, arXiv preprint arXiv:1905
 Learning attitudes and attributes from multi-aspectreviews,2012, In 2012 IEEE 12th International Conference on Data Mining
 RISE: randomized input sampling for explanation of black-box models,2018, CoRR
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In Proceedings of the IEEE international conference on computer vision
 Smoothgrad:removing noise by adding noise,2017, arXiv preprint arXiv:1706
 Visualizing the impact of feature attributionbaselines,2020, Distill
 Axiomatic attribution for deep networks,2017, In DoinaPrecup and Yee Whye Teh (eds
 Going deeper with convolutions,2015, InProceedings of the IEEE conference on computer vision and pattern recognition
