title,year,conference
 Analysis of sgd with biased gradient estimators,2020, arXivpreprint arXiv:2008
 Towardsfederated learning at scale: System design,2019, arXiv preprint arXiv:1902
 Leaf: A benchmark for federated settings,2018, arXiv preprint arXiv:1812
 On the outsized importance of learning rates in local updatemethods,2020, arXiv preprint arXiv:2007
 Shrinkage algorithms for mmsecovariance estimation,2010, IEEE Transactions on Signal Processing
 Emnist: Extending mnistto handwritten letters,2017, In 2017 International Joint Conference on Neural Networks (IJCNN)
 A tutorial on multilabel learning,2015, ACM Computing Surveys(CSUR)
 Federated learning for mobilekeyboard prediction,2018, arXiv preprint arXiv:1811
 The no-u-turn sampler: adaptively setting path lengths inhamiltonian monte carlo,2014, J
 The non-iid data quagmire ofdecentralized machine learning,2019, arXiv preprint arXiv:1910
 Advancesand open problems in federated learning,2019, arXiv preprint arXiv:1912
 Scaffold: Stochastic controlled averaging for on-device federatedlearning,2019, arXiv preprint arXiv:1910
 Mime: Mimicking centralized stochastic algorithms infederated learning,2020, arXiv preprint arXiv:2008
 Learning multiple layers of features from tiny images,2009, 2009
 On the convergence offedavg on non-iid data,2019, arXiv preprint arXiv:1907
 Metropolized independent sampling with comparisons to rejection sampling and impor-tance sampling,1996, Statistics and computing
 A complete recipe for stochastic gradient mcmc,2015, InAdvances in Neural Information Processing Systems
 Machine learning: a probabilistic perspective,2012, MIT press
 Mcmc using hamiltonian dynamics,2011, Handbook of markov chain monte carlo
 FedSplit: an algorithmic framework for fast federatedoptimization,2020, arXiv preprint arXiv:2005
 Some methods of speeding up the convergence of iteration methods,1964, USSRComputational Mathematics and Mathematical Physics
 Adaptive federated optimization,2020, arXiv preprintarXiv:2003
 A shrinkage approach to large-scale covariance matrixestimation and implications for functional genomics,2005, Statistical applications in genetics andmolecular biology
 Tackling the objectiveinconsistency problem in heterogeneous federated optimization,2020, arXiv preprint arXiv:2007
 Privacy for free: Posterior sampling andstochastic gradient monte carlo,2015, In International Conference on Machine Learning
 Minibatch vs local sgd for heterogeneousdistributed learning,2020, arXiv preprint arXiv:2006
 A re-examination of text categorization methods,1999, In Proceedings of the22nd annual international ACM SIGIR conference on Research and development in informationretrieval
 Parallel restarted sgd with faster convergence and lesscommunication: Demystifying why model averaging works for deep learning,2019, In Proceedings ofthe AAAI Conference on Artificial Intelligence
 Federatedlearning with non-iid data,2018, arXiv preprint arXiv:1806
 The burn-in steps Were not included,1000, Fordimensionality 10
