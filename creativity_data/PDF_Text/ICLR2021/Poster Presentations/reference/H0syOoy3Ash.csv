title,year,conference
 Orthogonal polynomials in the complex plane and on the real line,1997, In FieldsInstitute Communications
 Nonlinear acceleration of mo-mentum and primal-dual algorithms,2018, arXiv preprint arXiv:1810
 Introduction to modern cryptography,2014, CRC press
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations
 The extragradient method for finding saddle points and other problems,1976, Matecon
 Stochastic Hamiltonian gradient methods for smooth games,2020, arXivpreprint arXiv:2007
 Information-based complexity of convex programming,1995, Lecture Notes
 Introductory Lectures on Convex Optimization,2004, Springer
 Halting time is pre-dictable for large models: A universality property and average-case analysis,2020, arXiv preprintarXiv:2006
 Average-case acceleration through spectral density estima-tion,2020, In Proceedings of the 37th International Conference on Machine Learning
 Universal average-case optimality of Polyak momentum,2020, InProceedings of the 37th International Conference on Machine Learning
 The proof follows directly from Theorem 4,2021,2 and Proposition D
