title,year,conference
 Generating natural language adversarial examples,2018, arXiv preprint arXiv:1804
 Synthesizing robust adversarialexamples,2017, arXiv preprint arXiv:1707
 Unrestricted adversarialexamples via semantic manipulation,2020, In International Conference on Learning Representations
 Evasion attacks against machine learning at test time,2013, In Joint Europeanconference on machine learning and knowledge discovery in databases
 Adver-sarial objects against lidar-based autonomous driving systems,2019, arXiv preprint arXiv:1907
 Certified adversarial robustness via randomizedsmoothing,2019, arXiv preprint arXiv:1902
 Provable robustness against all adversarial Lp-perturbations forp â‰¥ 1,2019, arXiv preprint arXiv:1905
 Autoaugment:Learning augmentation strategies from data,2019, In Proceedings of the IEEE conference on computervision and pattern recognition
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv preprint arXiv:1708
 Robust physical-world attacks on deep learningvisual classification,2018, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 On the effectiveness of intervalbound propagation for training verifiably robust models,2018, arXiv preprint arXiv:1810
 Achieving robustness in the wild via adversarial mixing with disentangledrepresentations,2019, arXiv preprint arXiv:1912
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Benchmarking neural network robustness to commoncorruptions and perturbations,2019, arXiv preprint arXiv:1903
 Spatial transformer networks,2015, InAdvances in neural information processing systems
 Certified robustness to adversarialword substitutions,2019, arXiv preprint arXiv:1909
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Functional adversarial attacks,2019, In Advances in Neural InformationProcessing Systems
 Adversarialmusic: Real world audio adversary against wake-word detection system,2019, In Advances in NeuralInformation Processing Systems
 Adversarial camera stickers: A physical cameraattack on deep learning classifier,2019, arXiv preprint arXiv:1904
 Fast autoaugment,2019, InAdvances in Neural Information Processing Systems (NeurIPS)
 Adversarial robustness against the union of multipleperturbation models,2019, arXiv preprint arXiv:1909
 Benchmarking robustness in object detection:Autonomous driving when winter is coming,2019, arXiv preprint arXiv:1907
 Adversarial training methods for semi-supervisedtext classification,2016, arXiv preprint arXiv:1605
 Certified defenses against adversarialexamples,2018, arXiv preprint arXiv:1801
 Overfitting in adversarially robust deep learning,2020, arXivpreprint arXiv:2002
 Model-based robust deep learning,2020, arXivpreprint arXiv:2005
 Increasing the robustness of dnns against image corruptions byplaying the game of noise,2020, arXiv preprint arXiv:2001
 A general framework foradversarial examples with objectives,2019, ACM Transactions on Privacy and Security (TOPS)
 Certifying some distributional robustness withprincipled adversarial training,2017, arXiv preprint arXiv:1710
 Cyclical learning rates for training neural networks,2017, In 2017 IEEE Winter Conferenceon Applications of Computer Vision (WACV)
 Confidence-calibrated adversarial training anddetection: More robust models generalizing beyond the attack used during training,2019, arXiv preprintarXiv:1910
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Adversarial training and robustness for multiple perturbations,2019, InAdvances in Neural Information Processing Systems
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2017, arXiv preprint arXiv:1711
 Scaling provable adversarialdefenses,2018, In Advances in Neural Information Processing Systems
 Wasserstein adversarial examples via projectedsinkhorn iterations,2019, arXiv preprint arXiv:1902
 Generating adversarialexamples with adversarial networks,2018, arXiv preprint arXiv:1801
 Spatially transformedadversarial examples,2018, arXiv preprint arXiv:1801
 Randomizedsmoothing of all shapes and sizes,2020, arXiv preprint arXiv:2002
 Wide residual networks,2016, arXiv preprint arXiv:1605
 mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
 Towardsstable and efficient training of verifiably robust neural networks,2019, arXiv preprint arXiv:1906
 The proof here is almost purely algebraic in nature,2021, By definition of q and p
 All models are trained with the Adam optimizerwith momentum 0,2020,9 for 100 epochs with batch size 128 and cyclic learning rate schedule which peaksat 0
