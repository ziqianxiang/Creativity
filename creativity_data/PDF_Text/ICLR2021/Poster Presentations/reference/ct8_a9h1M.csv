title,year,conference
 Adaptive dropout for training deep neural networks,2013, In Advances in NeuralInformation Processing Systems
 Conditional computation in neuralnetworks for faster models,2015, arXiv preprint arXiv:1511
 Estimating or propagating gradients through stochasticneurons for conditional computation,2013, arXiv preprint arXiv:1308
 Weight uncertainty in neuralnetworks,2015, arXiv preprint arXiv:1505
 LearnableBernoulli dropout for Bayesian deep learning,2020, In Artificial Intelligence and Statistics
 Imagenet: A large-scale hierarchicalimage database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Latent alignment and variationalattention,2018, In Advances in Neural Information Processing Systems
 DisARM: An antithetic gradient estimator for binary latentvariables,2020, In Advances in Neural Information Processing Systems 33
 Bayesian attention modules,2020, Advances in NeuralInformation Processing Systems
 Dropout as a Bayesian approximation: Representing model uncertainty indeep learning,2016, In international conference on machine learning
 Concrete dropout,2017, In Advances in Neural Information ProcessingSystems
 Practical variational inference for neural networks,2011, In Advances in neural information processingsystems
 Delving deep into rectifiers: Surpassing human-levelperformance on imagenet classification,2015, In Proceedings of the IEEE international conference on computervision 
 Improvingneural networks by preventing co-adaptation of feature detectors,2012, arXiv preprint arXiv:1207
 Long short-term memory,1997, Neural computation
 Squeeze-and-excitation networks,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Adam: A method for stochastic optimization,2014, arXiv preprint arXiv:1412
 Auto-encoding variational Bayes,2013, arXiv preprint arXiv:1312
 Variational dropout and the local reparameterization trick,2015, InAdvances in Neural Information Processing Systems
 Learning multiple layers of features from tiny images,2009, Technical report
 Accurate uncertainties for deep learning usingcalibrated regression,2018, arXiv preprint arXiv:1807
 Simple and scalable predictive uncertaintyestimation using deep ensembles,2017, In Advances in Neural Information Processing Systems
 An empirical evaluationof deep architectures on problems with many factors of variation,2007, In Proceedings of the 24th internationalconference on Machine learning
 Deep learning,2015, Nature
 Preconditioned stochastic gradient Langevindynamics for deep neural networks,2016, In Thirtieth AAAI Conference on Artificial Intelligence
 L0-ARM: Network sparsification via stochastic binary optimization,2019, In The EuropeanConference on Machine Learning (ECML)
 A practical bayesian framework for backpropagation networks,1992, Neural computation
 Evaluating bayesian deep learning methods for semantic segmentation,2018, arXivpreprint arXiv:1811
 Faster R-CNN: Towards real-time object detectionwith region proposal networks,2015, In Advances in neural information processing systems
 Stochastic backpropagation and approximateinference in deep generative models,2014, In ICML
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, arXiv preprintarXiv:1701
 Kernel implicit variational inference,2018, In International Conference onLearning Representations
 Hydranets: Specialized dynamicarchitectures for efficient inference,2018, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Efficient object localizationusing convolutional networks,2015, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Regularization of neural networks usingdropconnect,2013, In International conference on machine learning
 Thompson sampling via local uncertainty,2019, arXiv preprintarXiv:1910
 Simple statistical gradient-following algorithms for connectionist reinforcement learning,1992, InReinforcement Learning
 Empirical evaluation of rectified activations in convolutionalnetwork,2015, arXiv preprint arXiv:1505
 ARM: Augment-REINFORCE-merge gradient for discrete latent variablemodels,2018, Preprint
 Wide residual networks,2016, arXiv preprint arXiv:1605
