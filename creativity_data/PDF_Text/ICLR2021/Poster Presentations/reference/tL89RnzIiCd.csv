title,year,conference
 Information capacity of the Hopfield model,1985, IEEE Transactionson Information Theory
 A compact vocabulary of paratope-epitope interactionsenables predictability of antibody-antigen binding,2019, bioRxiv
 Sharp bounds for the lambert w function,2018, Integral Transforms and SpecialFunctions
 Support vector machines for multiple-instancelearning,2003, In S
 Neural machine translation by jointly learning to align andtranslate,2015, ArXiv
 MEMO: a deep network for flexible combination of episodicmemories,2020, ArXiv
 A new mechanical approach to handle generalized Hopfieldneural networks,2018, Neural Networks
 Convex Analysis and Monotone Operator Theory in HilbertSpaces,2017, Cham: Springer International Publishing
 Convex Optimization,2009, Cambridge University Press
 Random forests,2001, Machine Learning
 On the number of spurious memories in the Hopfield model,1990, IEEETransactions on Information Theory
 Multiple instance learning: a surveyof problem characteristics and applications,2018, Pattern Recognition
 ELECTRA: Pre-training text encoders asdiscriminators rather than generators,2020, ArXiv
 Support-vector networks,1995, Machine learning
 Frustratingly short attention spans in neurallanguage modeling,2017, ArXiv
 Universal transformers,2019, ArXiv
 BERT: pre-training of deep bidirectionaltransformers for language understanding,2018, ArXiv
 BERT: pre-training of deep bidirectional trans-formers for language understanding,2019, In Proceedings of the 2019 Conference of the North AmericanChapter of the Association for Computational Linguistics: Human Language Technologies
 Solving the multiple instance problem withaxis-parallel rectangles,1997, Artificial Intelligence
 Immunosequencing identifies signatures ofcytomegalovirus exposure history and HLA-mediated effects on the T cell repertoire,2017, NatureGenetics
 On the properties of the softmax function with application in game theory andreinforcement learning,2017, ArXiv
 Analysis on Polish Spaces and an Introduction to Optimal Transportation,1108, LondonMathematical Society Student Texts
 Neural message passing forquantum chemistry,2017, In Proceedings of the 34th International Conference on Machine Learning(ICML)
 Neural turing machines,2014, ArXiv
 Permutation-equivariant neuralnetworks applied to dynamics prediction,2016, arXiv
 Untersuchungen ZU dynamischen neuronalen Netzen,1991, Diploma thesis
 Long short-term memory,1997, Neural Comput
 Neurons with graded response have collective computational properties like those oftwo-state neurons,1984, Proceedings of the National Academy of Sciences
 Semi-supervised classification with graph convolutional networks,2017, ArXiv
 Self-normalizing neural networks,2017, InAdvances in Neural Information Processing Systems
 Self-normalizing neural networks,2017, ArXiv
 Dense associative memory for pattern recognition,2016, In D
 Dense associative memory is robust to adversarial inputs,2018, NeuralComputation
 Large associative memory problem in neurobiology and machinelearning,2020, ArXiv
 The SIDER database of drugs and side effects,2016, NucleicAcids Research
 Deep learning,2015, Nature
 Variations and extension of the convex-concave procedure,2016, Optimization andEngineering
 On the storage capacity of nonlinear neural networks,1997, Neural Networks
 The capacity of the Hopfieldassociative memory,1987, IEEE Trans
 Automatic differentiation in PyTorch,2017, In Workshop in Advances in Neural InformationProcessing Systems (NeurIPS)
 PointNet: Deep learning on point sets for 3dclassification and segmentation,2017, In IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Curran Associates Inc,2017,
 Convergence properties of the softassignquadratic assignment algorithm,1999, Neural Computation
 Deep learning with sets and point clouds,2016, arXiv
 Learning to reason with third order tensor products,2018, In S
 Enhancing thetransformer with explicit relational encoding for math problem solving,2019, arXiv
 Deep learning in neural networks: An overview,2015, Neural Networks
 On the convergence of the concave-convex procedure,2009, InY
 End-to-end memory networks,2015, In C
 End-to-end memory networks,2015, ArXiv
 Reinforcement Learning: An Introduction,2018, MIT Press
 Analytic theory of the ground state properties ofa spin glass,1980, I
 Synthesizer: Rethinking self-attention in transformer models,2020, ArXiv
 Storage capacity of attractor neural networks withdepressing synapses,2002, Phys
 Attention is all you need,2017, In I
 Solving the multiple-instance problem: A lazy learning approach,2000, In Proceedings of the17th International Conference on Machine Learning (ICML)
 Revisiting multiple instance neural networks,2018, PatternRecognition
 immuneSIM: tunable multi-feature simulation of B- and T-cell receptor repertoiresfor immunoinformatics benchmarking,2020, Bioinformatics
 Memory networks,2014, ArXiv
 Modern Hopfield networks and attention forimmune repertoire classification,2020, ArXiv
 Modern Hopfield networks and attention forimmune repertoire classification,2020, In Advances in Neural Information Processing Systems
 HuggingFaceâ€™s transformers: State-of-the-art natural languageprocessing,2019, ArXiv
 On the convergence properties of the em algorithm,1983, Ann
 Improved expressivity through dendritic neural networks,2018, InS
 SpiderCNN: Deep learning on point sets withparameterized convolutional filters,2018, In V
 The concave-convex procedure,2003, Neural Computation
 Set distribution networks: agenerative model for sets of images,2020, arXiv
 Learning to update auto-associative memory in recurrent neural networks forimproving sequence memorization,2017, ArXiv
