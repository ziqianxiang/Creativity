title,year,conference
 An optimistic perspective on offlinereinforcement learning,2020, In International Conference on Machine Learning
 Model-based offline planning,2020, arXiv preprintarXiv:2008
 Analysis of representationsfor domain adaptation,2007, In Advances in Neural Information Processing Systems
 OpenAI Gym,2016, arXiv preprint arXiv:1606
 Deep reinforcement learn-ing in a handful of trials using probabilistic dynamics models,2018, In Advances in Neural InformationProcessing Systems
 D4RL: Datasets for deepdata-driven reinforcement learning,2020, arXiv preprint arXiv:2004
 Off-policy deep reinforcement learning withoutexploration,2019, In International Conference on Machine Learning
 Off-policy deep reinforcement learning by bootstrapping thecovariate shift,2019, In AAAI Conference on Artificial Intelligence
 Doubly robust off-policy value evaluation for reinforcement learning,2016, InInternational Conference on Machine Learning
 MOReL: Model-based offline reinforcement learning,2020, In Advances in Neural Information Processing Systems
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Conservative Q-learning for offlinereinforcement learning,2020, In Advances in Neural Information Processing Systems
 Batch reinforcementlearning with hyperparameter gradients,2020, In International Conference on Machine Learning
 Breaking the curse of horizon: Infinite-horizon off-policy estimation,2018, In Advances in Neural Information Processing Systems
 Representation balancing MDPs for off-policy policy evaluation,2018, InAdvances in Neural Information Processing Systems
 Off-policy policy gradient withstate distribution correction,2019, arXiv preprint arXiv:1904
 Deployment-efficient reinforcement learning via model-based offline optimization,2020, arXiv preprintarXiv:2006
 On the method of bounded differences,1989, Surveys in combinatorics
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 Black-box off-policy estimation for infinite-horizon reinforcement learning,2020, In International Conference on Learning Representations
 Integral probability metrics and their generating classes of functions,1997, Advances inApplied Probability
 DualDICE: Behavior-agnostic estimationof discounted stationary distribution corrections,2019, In Advances in Neural Information ProcessingSystems
 AlgaeDICE:Policy gradient from arbitrary experience,2019, arXiv preprint arXiv:1912
 Eligibility traces for off-policy policy evaluation,2000, Computer Science DepartmentFaculty Publication Series
 Swish: a self-gated activation function,2017, arXivpreprint arXiv:1710
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Estimating individual treatment effect: gener-alization bounds and algorithms,2017, In International Conference on Machine Learning
 Overcoming model bias for robust offlinedeep reinforcement learning,2020, arXiv preprint arXiv:2008
 Data-efficient off-policy policy evaluation for reinforcementlearning,2016, In International Conference on Machine Learning
 GenDICE: Generalized offline estimationof stationary values,2020, In International Conference on Learning Representations
 A representation module isa feed-forward network with two hidden layers that takes the state-action pair as input and outputsrepresentation through the tanh activation function,1000, The dynamics module is a single hidden layernetwork that takes representation as input and outputs parameters of diagonal Gaussian distributionpredicting state difference and reward
