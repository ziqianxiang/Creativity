title,year,conference
 TensorFlow: A System for Large-scale Machine Learning,2016, In Proceedings of the 12th USENIX Conference on Operating SystemsDesign and Implementation
 ACM Trans,2019, Graph
 Chameleon:Adaptive code optimization for expedited deep neural network compilation,2020, In 8th InternationalConference on Learning Representations
 Opentuner: an extensible framework for pro-gram autotuning,2014, In JoSe Nelson Amaral and Josep Torrellas (eds
 Finite-time analysis of the multiarmed banditproblem,2002, Mach
 Dynamic assortment with demand learning for seasonal consumergoods,2007, Management Science
 MXNet: A Flexible and Efficient Machine Learning Libraryfor Heterogeneous Distributed Systems,2015, arXiv preprint arXiv:1512
 TVM:an automated end-to-end optimizing compiler for deep learning,2018, In 13th USENIX Symposium onOperating Systems Design and Implementation
 cuDNN: Efficient Primitives for Deep Learning,2014, arXiv preprintarXiv:1410
 Discrepancy-based algorithms for non-stationary rested bandits,2017, arXiv preprint arXiv:1710
 emcee: the mcmchammer,2013, Publications of the Astronomical Society of the Pacific
 Deep residual learning for image recog-nition,2016, In 2016 IEEE Conference on Computer Vision and Pattern Recognition
 Probability inequalities for sums of bounded random variables,1994, In The CollectedWorks of Wassily Hoeffding
 The value of knowing a demand curve: Bounds on regretfor online posted-price auctions,2003, In 44th Annual IEEE Symposium on Foundations of ComputerScience
 Mlir: A compilerinfrastructure for the end of mooreâ€™s law,2020, arXiv preprint arXiv:2002
 Adatune: Adaptive tensor program com-pilation made efficient,2020, In Hugo Larochelle
 Training kinetics in 15 minutes: Large-scale distributed trainingon videos,2019, arXiv preprint arXiv:1910
 Hyper-parameter tuning under a budget con-straint,2019, In Sarit Kraus (ed
 Bandits for tax-onomies: A model-based approach,2007, In Proceedings of the 2007 SIAM International Conferenceon Data Mining
 Some aspects of the seqUential design of experiments,1952, Bulletin of the AmericanMathematical Society
 Megatron-lm: Training mUlti-billion parameter langUage models Using model par-allelism,2019, CoRR
 Very deep convolUtional networks for large-scale im-age recognition,2015, In 3rd International Conference on Learning Representations
 Tensor com-prehensions: Framework-agnostic high-performance machine learning abstractions,2018, CoRR
 Machine learning at facebook: Understand-ing inference at the edge,2019, In 2019 IEEE International Symposium on High Performance ComputerArchitecture (HPCA)
 Machine learning at facebook: Understand-ing inference at the edge,2019, In 2019 IEEE International Symposium on High Performance ComputerArchitecture (HPCA)
 Yet another accelerated SGD:resnet-50 training on imagenet in 74,2019,7 seconds
 Large batch training of convolutional networks,2017, arXivpreprint arXiv:1708
 ReducingBERT pre-training time from 3 days to 76 minutes,2019, CoRR
 Deepcpu: Serving rnn-baseddeep learning models 10x faster,2018, In Haryadi S
 Accelerating large scale deep learning inference throughdeepcpu at microsoft,2019, In 2019 USENIX Conference on Operational Machine Learning
 Ansor : Generat-ing high-performance tensor programs for deep learning,2020, CoRR
