Published as a conference paper at ICLR 2021
Local Search Algorithms for	Rank-
Constrained Convex Optimization
Kyriakos Axiotis	Maxim Sviridenko
MIT	Yahoo! Research NYC
kaxiotis@mit.edu	sviri@verizonmedia.com
Ab stract
We propose greedy and local search algorithms for rank-constrained convex opti-
mization, namely solving min	R(A) given a convex function R : Rm×n →
rank(A)≤r *
R and a parameter r*. These algorithms consist of repeating two steps: (a) adding
a new rank-1 matrix to A and (b) enforcing the rank constraint on A. We refine
and improve the theoretical analysis of Shalev-Shwartz et al. (2011), and show
that if the rank-restricted condition number of R is κ, a solution A with rank
O(r* ∙ min{κlog R(O)-R(A ), κ2}) and R(A) ≤ R(A*) + C can be recovered,
where A* is the optimal solution. This significantly generalizes associated results
on sparse convex optimization, as well as rank-constrained convex optimization
for smooth functions. We then introduce new practical variants of these algorithms
that have superior runtime and recover better solutions in practice. We demon-
strate the versatility of these methods on a wide range of applications involving
matrix completion and robust principal component analysis.
1	Introduction
Given a real-valued convex function R : Rm×n → R on real matrices and a parameter r* ∈ N,
the rank-constrained convex optimization problem consists of finding a matrix A ∈ Rm×n that
minimizes R(A) among all matrices of rank at most r*:
min	R(A)	(1)
rank(A)≤r*
Even though R is convex, the rank constraint makes this problem non-convex. Furthermore, it is
known that this problem is NP-hard and even hard to approximate (Natarajan (1995); Foster et al.
(2015)).
In this work, we propose efficient greedy and local search algorithms for this problem. Our contri-
bution is twofold:
1.	We provide theoretical analyses that bound the rank and objective value of the solutions
returned by the two algorithms in terms of the rank-restricted condition number, which is
the natural generalization of the condition number for low-rank subspaces. The results are
significantly stronger than previous known bounds for this problem.
2.	We experimentally demonstrate that, after careful performance adjustments, the proposed
general-purpose greedy and local search algorithms have superior performance to other
methods, even for some of those that are tailored to a particular problem. Thus, these
algorithms can be considered as a general tool for rank-constrained convex optimization
and a viable alternative to methods that use convex relaxations or alternating minimization.
The rank-restricted condition number Similarly to the work in sparse convex optimization, a
restricted condition number quantity has been introduced as a reasonable assumption on R. If we
let ρr+ be the maximum smoothness bound and ρr- be the minimum strong convexity bound only
along rank-r directions of R (these are called rank-restricted smoothness and strong convexity re-
spectively), the rank-restricted condition number is defined as Kr = ρ+. If this quantity is bounded,
ρr
1
Published as a conference paper at ICLR 2021
one can efficiently find a solution A with R(A) ≤ R(A*) + E and rank r = O(r* ∙左丁十丁*RO)) using
a greedy algorithm (Shalev-Shwartz et al. (2011)). However, this is not an ideal bound since the
rank scales linearly with RO), which can be particularly high in practice. Inspired by the analogous
literature on sparse convex optimization by Natarajan (1995); Shalev-Shwartz et al. (2010); Zhang
(2011); Jain et al. (2014) and more recently Axiotis & Sviridenko (2020), one would hope to achieve
a logarithmic dependence or no dependence at all on RO). In this paper We achieve this goal by
providing an improved analysis showing that the greedy algorithm of Shalev-Shwartz et al. (2011)
in fact returns a matrix of rank of r = O(r* ∙ Kf* log RO)). We also provide a new local search
algorithm together with an analysis guaranteeing a rank of r = O(r* ∙ K2-+r*). Apart from signifi-
cantly improving upon previous work on rank-restricted convex optimization, these results directly
generalize a lot of work in sparse convex optimization, e.g. Natarajan (1995); Shalev-Shwartz et al.
(2010); Jain et al. (2014). Our algorithms and theorem statements can be found in Section 2.
Runtime improvements Even though the rank bound guaranteed by our theoretical analyses is
adequate, the algorithm runtimes leave much to be desired. In particular, both the greedy algorithm
of Shalev-Shwartz et al. (2011) and our local search algorithm have to solve an optimization problem
in each iteration in order to find the best possible linear combination of features added so far. Even
for the case that R(A) = 2 P (M - A) j, this requires solving a least squares problem on ∣Ω∣
(ij)EQ
examples and r2 variables. For practical implementations of these algorithms, we circumvent this
issue by solving a related optimization problem that is usually much smaller. This instead requires
solving n least squares problems with total number of examples ∣Ω∣, each on r variables. This not
only reduces the size of the problem by a factor ofr, but also allows for a straightforward distributed
implementation. Interestingly, our theoretical analyses still hold for these variants. We propose an
additional heuristic that reduces the runtime even more drastically, which is to only run a few (less
than 10) iterations of the algorithm used for solving the inner optimization problem. Experimental
results show that this modification not only does not significantly worsen results, but for machine
learning applications also acts as a regularization method that can dramatically improve generaliza-
tion. These matters, as well as additional improvements for making the local search algorithm more
practical, are addressed in Section 2.3.
Roadmap In Section 2, we provide the descriptions and theoretical results for the algorithms
used, along with several modifications to boost performance. In Section 3, we evaluate the proposed
greedy and local search algorithms on optimization problems like robust PCA. Then, in Section 4
we evaluate their generalization performance in machine learning problems like matrix completion.
2	Algorithms & Theoretical Guarantees
In Sections 2.1 and 2.2 we state and provide theoretical performance guarantees for the basic greedy
and local search algorithms respectively. Then in Section 2.3 we state the algorithmic adjustments
that we propose in order to make the algorithms efficient in terms of runtime and generalization
performance. A discussion regarding the tightness of the theoretical analysis is deferred to Ap-
pendix A.4.
When the dimension is clear from context, we will denote the all-ones vector by 1, and the vector
that is 0 everywhere and 1 at position i by 1i. Given a matrix A, we denote by im(A) its column
span. One notion that we will find useful is that of singular value thresholding. More specifically,
k
given a rank-k matrix A ∈ Rm×n with SVD P σiubvl~τ such that σι ≥ ∙∙∙ ≥ σk, as well as an
i=1
r
integer parameter r ≥ 1, we define Hr(A) = P σlulvl> to be the operator that truncates to the r
l=1
highest singular values of A.
2.1	Greedy
Algorithm 1 (Greedy) was first introduced in Shalev-Shwartz et al. (2011) as the GECO algorithm.
It works by iteratively adding a rank-1 matrix to the current solution. This matrix is chosen as the
2
Published as a conference paper at ICLR 2021
rank-1 matrix that best approximates the gradient, i.e. the pair of singular vectors corresponding
to the maximum singular value of the gradient. In each iteration, an additional procedure is run to
optimize the combination of previously chosen singular vectors.
In Shalev-Shwartz et al. (2011) guarantee on the rank of the solution returned by the algorithm is
r * κr+r *RO). The main bottleneck in order to improve on the RO) factor is the fact that the analysis
is done in terms of the squared nuclear norm of the optimal solution. As the worst-case discrepancy
between the squared nuclear norm and the rank is R(0)/, their bounds inherit this factor. Our
analysis works directly with the rank, in the spirit of sparse optimization results (e.g. Shalev-Shwartz
et al. (2011); Jain et al. (2014); Axiotis & Sviridenko (2020)). A challenge compared to these works
is the need for a suitable notion of “intersection” between two sets of vectors. The main technical
contribution of this work is to show that the orthogonal projection of one set of vectors into the span
of the other is such a notion, and, based on this, to define a decomposition of the optimal solution
that is used in the analysis.
Algorithm 1 Greedy
1	: procedure GREE DY(r ∈ N : target rank)
2	:	function to be minimized R : Rm×n → R
3	:	U ∈ Rm×0	. Initially rank is zero
4	:	V ∈ Rn×0
5	:	for t = 0 . . . r - 1 do
6	σuv› J HIER(UV>))	. Max singular value σ and corresp. singular vectors u, V
7	U J (Uu)	. Append new vectors as columns
8	:	VJ(V v)
9	:	U, V J OPTIMIZE(U, V)
10	:	return UV>
11	: procedure OPTIMIZE(U ∈ Rm×r , V ∈ Rn×r)
12	:	X J arg min R(UXV>) X∈Rr×r
13	:	return UX, V
Theorem 2.1 (Algorithm 1 (greedy) analysis). Let A* be any fixed optimal solution of (1) for some
function R and rank bound r*, and let e > 0 be an error parameter. For any integer r ≥ 2r* ∙
Kr+r* log R(0)—R(A), if we let A = GREEDY(r) be the solution returned by Algorithm 1, then
R(A) ≤ R(A* ) + . The number of iterations is r.
The proof of Theorem 2.1 can be found in Appendix A.2.
2.2	Local Search
One drawback of Algorithm 1 is that it increases the rank in each iteration. Algorithm 2 is a modifi-
cation of Algorithm 1, in which the rank is truncated in each iteration. The advantage of Algorithm
2 compared to Algorithm 1 is that it is able to make progress without increasing the rank of A,
while Algorithm 1 necessarily increases the rank in each iteration. More specifically, because of the
greedy nature of Algorithm 1, some rank-1 components that have been added to A might become
obsolete or have reduced benefit after a number of iterations. Algorithm 2 is able to identify such
candidates and remove them, thus allowing it to continue making progress.
Theorem 2.2 (Algorithm 2 (local search) analysis). Let A* be any fixed optimal solution of (1)
for some function R and rank bound r*, and let > 0 be an error parameter. For any integer
r ≥ r* ∙ (1 + 8κ2+r*), if we let A = LOCAL_SEARCH(r) be the solution returned by Algorithm 2,
then R(A) ≤ R(A*) + e The number ofiterations is O (r*κr+r* log R(0)—R(A)).
The proof of Theorem 2.2 can be found in Appendix A.3.
3
Published as a conference paper at ICLR 2021
Algorithm 2 Local Search
1 2 3 4 5 6 7 8 9 10 11 12 13 14	procedure LOCAL_SEARCH(r ∈ N : target rank) :	function to be minimized R : Rm×n → R U J 0m×r	. Initialize with all-zero solution V J 0n×r :	for t = 0 . . . L — 1 do	. Run for L iterations :	σuv> J H1(VR(UV>)) . Max singular value σ and corresp. singular vectors u, v :	U, V J TRUNCATE(U, V)	. Reduce rank of UV> by one :	U J (U u)	. Append new vectors as columns :	VJ (V v) :	U, V J OPTIMIZE(U, V) :	return UV> : procedure TRUNCATE(U ∈ Rm×r, V ∈ Rn×r) :	UΣV> J SVD(Hr-1(UV>))	. Keep all but minimum singular value :	return UΣ, V
2.3	Algorithmic adjustments
Inner optimization problem The inner optimization problem that is used in both greedy and local
search is:
min R(UXV>) .	(2)
X ∈Rr×r
It essentially finds the choice of matrices U0 and V 0, with columns in the column span of U and V
respectively, that minimizes R(U 0V 0>). We, however, consider the following problem instead:
min R(UV >) .	(3)
V ∈Rn×r
Note that the solution recovered from (3) will never have worse objective value than the one re-
covered from (2), and that nothing in the analysis of the algorithms breaks. Importantly, (3) can
usually be solved much more efficiently than (2). As an example, consider the following objec-
tive that appears in matrix completion: R(A) = 1 P (M - A)j for some Ω ⊆ [m] X [n]. If
(i,j)∈Ω
We let ∏ω(∙) be an operator that zeroes out all positions in the matrix that are not in Ω, we have
VR(A) = —∏ω(M — A). The optimality condition of(2) now is U>∏ω(M — UXV>)V = 0 and
that of (3) is U>∏ω(M - UV>) = 0. The former corresponds to a least squares linear regression
problem with ∣Ω∣ examples and r2 variables, while the latter can be decomposed into n independent
systems U> ( P L1> ] UVj = U>∏ω (M 1j), where the variable is Vj which is the j-th
\i：(i,j)EQ	J
column of V . The j -th of these systems corresponds to a least squares linear regression problem
with |{i : (i,j) ∈ Ω}∣ examples and r variables. Note that the total number of examples in all
systems is P |{i : (i,j) ∈ Ω}∣ = ∣Ω∣. The choice of V here as the variable to be optimized is
j∈[n]
arbitrary. In particular, as can be seen in Algorithm 3, in practice we alternate between optimizing U
and V in each iteration. It is worthy of mention that the OPTIMIZE_Fast procedure is basically the
same as one step of the popular alternating minimization procedure for solving low-rank problems.
As a matter of fact, when our proposed algorithms are viewed from this lens, they can be seen as
alternating minimization interleaved with rank-1 insertion and/or removal steps.
Singular value decomposition As modern methods for computing the top entries of a singular
value decomposition scale very well even for large sparse matrices (Martinsson et al. (2011); Szlam
et al. (2014); Tulloch (2014)), the “insertion” step of greedy and local search, in which the top
entry of the SVD of the gradient is determined, is quite fast in practice. However, these methods
are not suited for computing the smallest singular values and corresponding singular vectors, a step
required for the local search algorithm that we propose. Therefore, in our practical implementations
we opt to perfom the alternative step of directly removing one pair of vectors from the representation
UV> . A simple approach is to go over all r possible removals and pick the one that increases the
4
Published as a conference paper at ICLR 2021
Algorithm 3 Fast inner Optimization
1:	procedure OPTIMIZE_Fast(U ∈ Rm×r, V ∈ Rn×r ,t ∈ N : iteration index of algorithm)
2:	if t mod 2 = 0 then
3:	X — arg min R(XV>)
X∈Rm×r
4:	return X, V
5:	else
6:	X J arg min R(UX>)
X∈Rn×r
7:	return U, X
objective by the least amount. A variation of this approach has been used by Shalev-Shwartz et al.
(2011). However, a much faster approach is to just pick the pair of vectors U1i, V1i that minimizes
kU1ik2kV1ik2. This is the approach that we use, as can be seen in Algorithm 4.
Algorithm 4 Fast rank reduction
1:	procedure TRUNCATE-FAST(U ∈ Rm×r,V ∈ Rn×r)
2:	i J arg min kU1ik2kV1ik2
i∈[r]
3:	return (u[m],[i,i-i] U[m],[i+ι,r]), (V⅛,[i,i-i] %n],[i+ι,r])	. Remove column i
After the previous discussion, we are ready to state the fast versions of Algorithm 1 and Algorithm 2
that we use for our experiments. These are Algorithm 2.3 and Algorithm 5. Notice that we initialize
Algorithm 5 with the solution of Algorithm 2.3 and We run it until the value of R(∙) stops decreasing
rather than for a fixed number of iterations.
Algorithm 2.3 (Fast Greedy). The Fast Greedy algorithm is defined identically as Algorithm 1, with
the only difference that it uses the OPTIMIZE_Fast routine as opposed to the OPTIMIZE routine.
Algorithm 5 Fast Local Search
1	procedure FAST_LOCAL_SEARCH(r ∈ N : target rank)
2	:	function to be minimized R : Rm×n → R
3	U, V J solution returned by FAST_GREEDY(r)
4	:	do
5	:	Uprev , Vprev J U, V
6	σuv› J HIER(UV>))	. Max singular value σ and corresp. singular vectors u, V
7	U, V J TRUNCATE_FAST(U, V)	. Reduce rank of UV> by one
8	:	U J (U u)	. Append new vectors as columns
9	:	VJ(V v)
10	U, V J OPTIMIZE_FAST(U, V, t)
11	:	while R(UV>) < R(UprevVp>rev)
12	:	return Uprev Vp>rev
3	Optimization Applications
An immediate application of the above algorithms is in the problem of low rank matrix recovery.
Given any convex distance measure between matrices d : Rm×n × Rm×n → R≥0, the goal is
to find a low-rank matrix A that matches a target matrix M as well as possible in terms of d:
min	d(M, A) This problem captures a lot of different applications, some of which we go over
rank(A)≤r*
in the following sections.
5
Published as a conference paper at ICLR 2021
3.1	Low-rank approximation on observed set
A particular case of interest is when d(M, A) is the Frobenius norm of M - A, but only applied to
entries belonging to some set Ω. In other words, d(M, A) = 2∣∣∏ω(M - A)IlF . We have compared
our Fast Greedy and Fast Local Search algorithms with the SoftImpute algorithm of Mazumder et al.
(2010) as implemented by Rubinsteyn & Feldman (2016), on the same experiments as in Mazumder
et al. (2010). We have solved the inner optimization problem required by our algorithms by the
LSQR algorithm Paige & Saunders (1982). More specifically, M = UV > + η ∈ R100×100, where
η is some noise vector. We let every entry of U, V, η be i.i.d. normal with mean 0 and the entries
of Ω are chosen i.i.d. uniformly at random over the set [100] X [100]. The experiments have three
parameters: The true rank r* (of UV>), the percentage of observed entries P = ∣Ω∣∕104, and the
Signal-to-noise ratio SNR. We measure the normalized MSE, i.e. ∣∣∏ω(M - A)IlF/∣∣∏ω(M)∣∣F∙
The results can be seen in Figure 1, where it is illustrated that Fast Local Search sometimes returns
significantly more accurate and lower-rank solutions than Fast Greedy, and Fast Greedy generally
returns significantly more accurate and lower-rank solutions than SoftImpute.
(a) r =5, P = 0.2, SNR = 10
(b) r* = 6, p = 0.5, SNR = 1
Figure 1: Objective value error vs rank in the problem of Section 3.1.
3.2	Robust principal component analysis (RPCA)
The robust PCA paradigm asks one to decompose a given matrix M as L + S, where L is a low-
rank matrix and S is a sparse matrix. This is useful for applications with outliers where directly
computing the principal components of M is significantly affected by them. For a comprehensive
survey on Robust PCA survey one can look at Bouwmans et al. (2018). The following optimization
problem encodes the above-stated requirements:
min ∣M - L∣0
rank(L)≤r*
(4)
where ∣X∣0 is the sparsity (i.e. number of non-zeros) ofX. As neither the rank constraint or the `0
function are convex, CandeS et al. (2011) replaced them by their usual convex relaxations, i.e. the
nuclear norm ∣∙∣* and 'ι norm respectively. However, We opt to only relax the 'o function but not
the rank constraint, leaving us with the problem:
min ∣M - L∣1
rank(L)≤r*
(5)
In order to make the objective differentiable and thus more well-behaved, we further replace the `1
x2/2	if |x| ≤ δ
norm by the Huber loss Hδ (x) =	, thus getting: min	Hδ (M -
δ∣x∣ - δ2∕2 otherwise	rank(L)≤r* j
L)ij . This is a problem on which we can directly apply our algorithms. We solve the inner opti-
mization problem by applying 10 L-BFGS iterations.
In Figure 2 one can see an example of foreground-background separation from video using robust
PCA. The video is from the BMC 2012 dataset Vacavant et al. (2012). In this problem, the low-
rank part corresponds to the background and the sparse part to the foreground. We compare three
6
Published as a conference paper at ICLR 2021
algorithms: Our Fast Greedy algorithm, standard PCA with 1 component (the choice of 1 was picked
to get the best outcome), and the standard Principal Component Pursuit (PCP) algorithm (Candes
et al. (2011)), as implemented in Lin et al. (2010), where we tuned the regularization parameter λ to
achieve the best result. We find that Fast Greedy has the best performance out of the three algorithms
in this sample task.
Figure 2: Foreground-background separation from video. From left to right: Fast Greedy with
rank=3 and Huber loss with δ = 20. Standard PCA with rank=1. Principal Component Pursuit
(PCP) with λ = 0.002. Both PCA and PCP have visible ”shadows” in the foreground that appear as
”smudges” in the background. These are less obvious in a still frame but more apparent in a video.
4	Machine Learning Applications
4.1	Regularization techniques
In the previous section we showed that our proposed algorithms bring down different optimization
objectives aggressively. However, in applications where the goal is to obtain a low generalization
error, regularization is needed. We considered two different kinds of regularization. The first method
is to run the inner optimization algorithm for less iterations, usually 2-3. Usually this is straightfor-
ward since an iterative method is used. For example, in the case R(A) = 21∣Πω (M- A) k F the inner
optimization is a least squares linear regression problem that we solve using the LSQR algorithm.
The second one is to add an `2 regularizer to the objective function. However, this option did not
provide a substantial performance boost in our experiments, and so we have not implemented it.
4.2	Matrix Completion with Random Noise
In this section we evaluate our algorithms on the task of recovering a low rank matrix UV > after
observing Πω(UV> + η), i.e. a fraction of its entries with added noise. As in Section 3.1, we use
the setting of Mazumder et al. (2010) and compare with the SoftImpute method. The evaluation
metric is the normalized MSE, defined as ( P (UV> - A)i2j )/( P (UV>)i2j ), where A is the
(i,j )∈ Ω	(i,j )∈ Ω
predicted matrix and UV> the true low rank matrix. A few example plots can be seen in Figure 3 and
a table of results in Table 1. We have implemented the Fast Greedy and Fast Local Search algorithms
with 3 inner optimization iterations. In the first few iterations there is a spike in the relative MSE of
the algorithms that use the OptimizE-Fast routine. We attribute this to the aggressive alternating
minimization steps of this procedure and conjecture that adding a regularization term to the objective
might smoothen the spike. However, the Fast Local Search algorithm still gives the best overall
performance in terms of how well it approximates the true low rank matrix UV> , and in particular
with a very small rank—practically the same as the true underlying rank.
7
Published as a conference paper at ICLR 2021
(a) k = 5, p = 0.2, SNR = 10
(b) k = 6, p = 0.5, SNR = 1
Figure 3: Test error vs rank in the matrix completion problem of Section 4.2. Bands of ±1 standard
error are shown. Note that SoftImpute starts to overfit for ranks larger than 12 in (a). The “jumps”
at around rank 5-7 happen because of overshooting (taking too large a step) during the insertion the
rank-1 component in both Fast Greedy and Fast Local Search. More specifically, these implemen-
tations only apply 3 iterations of the inner optimization step, which in some cases are too few to
amend the overshooting. However, after a few more iterations of the algorithm the overshooting
issue is resolved (i.e. the algorithm has had enough iterations to scale down the rank-1 component
that caused the overshooting).
Algorithm	random_error_13	random_error_1	random_error_2
SoftImpute (Mazumder et al. (2010))	0.1759/10	0.2465/28	0.2284/30~~
FaSt Greedy (Algorithm 2.3)	0.0673/30	0.1948/13	-0.1826/21
Fast Local Search (Algorithm 5)	0.0613/14	0.1952/15	-0.1811/15
Table 1: Lowest test error for any rank in the matrix completion problem of Section 4.2, and associ-
ated rank returned by each algorithm. In the form error/rank.
4.3	Recommender Systems
In this section we compare our algorithms on the task of movie recommendation on the Movielens
datasets Harper & Konstan (2015). In order to evaluate the algorithms, we perform random 80%-
20% train-test splits that are the same for all algorithms and measure the mean RMSE in the test set.
If We let Ω ⊆ [m] X [n] be the set of user-movie pairs in the training set, We assume that the true
user-movie matrix is low rank, and thus pose (1) with R(A) = 1 ∣∣∏ω(M 一 A)IlF. We make the
folloWing slight modification in order to take into account the range of the ratings [1, 5]: We clip the
entries of A between 1 and 5 when computing VR(A) in Algorithm 2.3 and Algorithm 5. In other
words, instead of ∏ω(A — M) we compute the gradient as ∏o(clip(A, 1, 5) 一 M). This is similar
to replacing our objective by a Huber loss, with the difference that we only do so in the steps that
we mentioned and not the inner optimization step, mainly for runtime efficiency reasons.
The results can be seen in Table 2. We do not compare with Fast Local Search, as we found that
it only provides an advantage for small ranks (< 30), and otherwise matches Fast Greedy. For
the inner optimization steps we have used the LSQR algorithm with 2 iterations in the 100K and
1M datasets, and with 3 iterations in the 10M dataset. Note that even though the SVD algorithm
by Koren et al. (2009) as implemented by Hug (2020) (with no user/movie bias terms) is a highly
tuned algorithm for recommender systems that was one of the top solutions in the famous Netflix
prize, it has comparable performance to our general-purpose Algorithm 2.3.
Finally, Table 3 demonstrates the speedup achieved by our algorithms over the basic greedy imple-
mentation. It should be noted that the speedup compared to the basic greedy of Shalev-Shwartz et al.
(2011) (Algorithm 1) is larger as rank increases, since the fast algorithms scale linearly with rank,
but the basic greedy scales quadratically.
8
Published as a conference paper at ICLR 2021
Algorithm	MovieLens 100K	MovieLens 1M	MovieLens 10M
NMF(Lee&Seung(200f)F	0.9659	0.9166	0.8960
SoftImpute	1.0106	0.9599	0.957
Alternating Minimization	0.9355	0.8732	0.8410
SVD (Koren et al.(2009)T~	0.9533	0.8743	0.8315
FaSt Greedy (Algorithm 2.3)	0.9451	0.8714	0.8330
Table 2: Mean RMSE and standard error among 5 random splits for 100K and 1M with standard
errors < 0.01, and 3 random splits for 10M with standard errors < 0.001. The rank of the prediction
is set to 100 except for NMF where it is 15 and Fast Greedy in the 10M dataset where it is chosen
to be 35 by cross-validation. Alternating Minimization is a well known algorithm (e.g. Srebro
et al. (2004)) that alternatively minimizes the left and right subspace, and also uses Frobenius norm
regularization. For SoftImpute and Alternating Minimization we have found the best choice of
parameters by performing a grid search over the rank and the multiplier of the regularization term.
We have found the best choice of parameters by performing a grid search over the rank and the
multiplier of the regularization term. We ran 20 iterations of Alternating Minimization in each case.
Algorithm	Figure 3 (a)	Movielens 100K	Movielens 1M
SOftImPUte	-	10.6	二	9.4	40.6 -
Alternating Minimization	189	252.0	11414
Greedy (Shalev-Shwartz et al. (2011))	188	418.4	4087.3
Fast Greedy	102	43.4	244.2
Fast Local Search	10.8	―	46.1	263.0
Table 3: Runtimes (in seconds) of different algorithms for fitting a rank=30 solution in various
experiments. Code written in python and tested on an Intel Skylake CPU with 16 vCPUs.
It is important to note that our goal here is not to be competitive with the best known algorithms
for matrix completion, but rather to propose a general yet practically applicable method for rank-
constrained convex optimization. For a recent survey on the best performing algorithms in the
Movielens datasets see Rendle et al. (2019). It should be noted that a lot of these algorithms have
significant performance boost compared to our methods because they use additional features (meta
information about each user, movie, timestamp of a rating, etc.) or stronger models (user/movie
biases, ”implicit” ratings). A runtime comparison with these recent approches is an interesting
avenue for future work. As a rule of thumb, however, Fast Greedy has roughly the same runtime as
SVD (Koren et al. (2009)) in each iteration, i.e. O(∣Ω∣r), where Ω is the set of observable elements
and r is the rank. As some better performing approaches have been reported to be much slower
than SVD (e.g. SVD++ is reported to be 50-100x slower than SVD in the Movielens 100K and 1M
datasets (Hug (2020)), this might also suggest a runtime advantage of our approach compared to
some better performing methods.
5	Conclusions
We presented simple algorithms with strong theoretical guarantees for optimizing a convex function
under a rank constraint. Although the basic versions of these algorithms have appeared before,
through a series of careful runtime, optimization, and generalization performance improvements
that we introduced, we have managed to reshape the performance of these algorithms in all fronts.
Via our experimental validation on a host of practical problems such as low-rank matrix recovery
with missing data, robust principal component analysis, and recommender systems, we have shown
that the performance in terms of the solution quality matches or exceeds other widely used and
even specialized solutions, thus making the argument that our Fast Greedy and Fast Local Search
routines can be regarded as strong and practical general purpose tools for rank-constrained convex
optimization. Interesting directions for further research include the exploration of different kinds of
regularization and tuning for machine learning applications, as well as a competitive implementation
and extensive runtime comparison of our algorithms.
9
Published as a conference paper at ICLR 2021
References
Kyriakos Axiotis and Maxim Sviridenko. Sparse convex optimization via adaptively regularized
hard thresholding. arXiv preprint arXiv:2006.14571, 2020.
Thierry Bouwmans, Sajid Javed, Hongyang Zhang, Zhouchen Lin, and Ricardo Otazo. On the
applications of robust Pca in image and video processing. Proceedings ofthe IEEE, 106(8):1427-
1457, 2018.
EmmanUel J Candes, Xiaodong Li, Yi Ma, and John Wright. Robust principal component analysis?
Journal of the ACM (JACM), 58(3):1-37, 2011.
Steve Fisk. A note on weyl’s inequality. 1996.
Dean Foster, Howard Karloff, and Justin Thaler. Variable selection is hard. In Conference on
Learning Theory, pp. 696-709, 2015.
F Maxwell Harper and Joseph A Konstan. The movielens datasets: History and context. Acm
transactions on interactive intelligent systems (tiis), 5(4):1-19, 2015.
Nicolas Hug. Surprise: A python library for recommender systems. Journal of Open Source Soft-
ware, 5(52):2174, 2020. doi: 10.21105/joss.02174. URL https://doi.org/10.21105/
joss.02174.
Prateek Jain, Ambuj Tewari, and Inderjit S Dhillon. Orthogonal matching pursuit with replacement.
In Advances in neural information processing systems, pp. 1215-1223, 2011.
Prateek Jain, Ambuj Tewari, and Purushottam Kar. On iterative hard thresholding methods for high-
dimensional m-estimation. In Advances in Neural Information Processing Systems, pp. 685-693,
2014.
Yehuda Koren, Robert Bell, and Chris Volinsky. Matrix factorization techniques for recommender
systems. Computer, 42(8):30-37, 2009.
Daniel D Lee and H Sebastian Seung. Algorithms for non-negative matrix factorization. In Advances
in neural information processing systems, pp. 556-562, 2001.
Zhouchen Lin, Minming Chen, and Yi Ma. The augmented lagrange multiplier method for exact
recovery of corrupted low-rank matrices. arXiv preprint arXiv:1009.5055, 2010.
Per-Gunnar Martinsson, Vladimir Rokhlin, and Mark Tygert. A randomized algorithm for the de-
composition of matrices. Applied and Computational Harmonic Analysis, 30(1):47-68, 2011.
Rahul Mazumder, Trevor Hastie, and Robert Tibshirani. Spectral regularization algorithms for learn-
ing large incomplete matrices. The Journal of Machine Learning Research, 11:2287-2322, 2010.
Balas Kausik Natarajan. Sparse approximate solutions to linear systems. SIAM journal on comput-
ing, 24(2):227-234, 1995.
Christopher C Paige and Michael A Saunders. Lsqr: An algorithm for sparse linear equations and
sparse least squares. ACM Transactions on Mathematical Software (TOMS), 8(1):43-71, 1982.
Yagyensh Chandra Pati, Ramin Rezaiifar, and Perinkulam Sambamurthy Krishnaprasad. Orthogonal
matching pursuit: Recursive function approximation with applications to wavelet decomposition.
In Proceedings of 27th Asilomar conference on signals, systems and computers, pp. 40-44. IEEE,
1993.
Steffen Rendle, Li Zhang, and Yehuda Koren. On the difficulty of evaluating baselines: A study on
recommender systems. arXiv preprint arXiv:1905.01395, 2019.
Alex Rubinsteyn and Sergey Feldman. fancyimpute: Version 0.0.16, May 2016. URL https:
//doi.org/10.5281/zenodo.51773.
Shai Shalev-Shwartz, Nathan Srebro, and Tong Zhang. Trading accuracy for sparsity in optimization
problems with sparsity constraints. SIAM Journal on Optimization, 20(6):2807-2832, 2010.
10
Published as a conference paper at ICLR 2021
Shai Shalev-Shwartz, Alon Gonen, and Ohad Shamir. Large-scale convex minimization with a low-
rank constraint. In Proceedings of the 28th International Conference on International Conference
on Machine Learning,pp. 329-336, 2011.
Nathan Srebro, Jason Rennie, and Tommi Jaakkola. Maximum-margin matrix factorization. Ad-
vances in neural information processing systems, 17:1329-1336, 2004.
Arthur Szlam, Yuval Kluger, and Mark Tygert. An implementation of a randomized algorithm for
principal component analysis. arXiv preprint arXiv:1412.3510, 2014.
Andrew Tulloch. Fast randomized svd. https://research.fb.com/blog/2014/09/
fast-randomized-svd/, 2014.
Antoine Vacavant, Thierry Chateau, Alexis Wilhelm, and LaUrent Lequievre. A benchmark dataset
for outdoor foreground/background extraction. In Asian Conference on Computer Vision, pp.
291-300. Springer, 2012.
Tong Zhang. Sparse recovery with orthogonal matching pursuit under rip. IEEE Transactions on
Information Theory, 57(9):6215-6221, 2011.
A	Appendix
A. 1 Preliminaries and Notation
Given an positive integer k, we denote [k] = {1, 2, . . . , k}. Given a matrix A, we denote by kAkF
its Frobenius norm, i.e. the `2 norm of the entries of A (or equivalently of the singular values of A).
The following lemma is a simple corollary of the definition of the Frobenius norm:
Lemma A.1. Given two matrices A ∈ Rm×n,B ∈ Rm×n, we have kA + Bk2F ≤
2 QMkF + kBkF).
Proof.
kA+Bk2F=X(A+B)i2j ≤2X(Ai2j+Bi2j)=2(kAk2F+kBk2F)
ij	ij
□
Definition A.2 (Rank-restricted smoothness, strong convexity, condition number). Given a convex
function R ∈ Rm×n → R and an integer parameter r, the rank-restricted smoothness of R at rank
r is the minimum constant ρr+ ≥ 0 such that for any two matrices A ∈ Rm×n , B ∈ Rm×n such that
rank(A - B) ≤ r, we have
R(B) ≤ R(A) + BR(Ah B — Ai + ρ+ kB - AkF ∙
Similarly, the rank-restricted strong convexity of R at rank r is the maximum constant ρr- ≥ 0 such
that for any two matrices A ∈ Rm×n, B ∈ Rm×n such that rank(A - B) ≤ r, we have
R(B) ≥ R(A) + "R(A), B - Ai + p-kB - AkF ∙
Given that ρr+, ρr- exist and are nonzero, the rank-restricted condition number of R at rank r is then
defined as
ρr+
Kr ———―
ρr
Note that ρ+ is increasing and ρ- is decreasing in r. Therefore, even though our bounds are proven
in terms of the constants ρ- and ρ-, these quantities are always at most ρ+ —— Kr as long as r ≥ 2,
ρr	ρr	ρr
and so they directly imply the same bounds in terms of the constant Kr .
11
Published as a conference paper at ICLR 2021
Definition A.3 (Spectral norm). Given a matrix A ∈ Rm×n,
The spectral norm is defined as
we denote its spectral norm by kAk2.
kAk2 = max
x∈Rn
kAxk2
kxk2
Definition A.4 (Singular value thresholding operator). Given a matrix A ∈ Rm×n of rank k, a
singular value decomposition A = UΣV> such that ∑11 ≥ ∑22 ≥ ∙∙∙ ≥ ∑kk, and an integer
1 ≤ r ≤ k, we define Hr (A) = UΣ0V>, here Σ0 is a diagonal matrix with
if i ≤ r
otherwise
In other words, Hr (∙) is an operator that eliminates all but the top r highest singular values of a
matrix.
Lemma A.5 (Weyl’s inequality). For any matrix A and integer i ≥ 1, let σi(A) be the i-th largest
singular value ofA or 0 ifi > rank(A). Then, for any two matrices A, B and integers i ≥ 1,j ≥ 1:
σi+j -1 (A + B) ≤ σi(A) + σj(B)
A proof of the previous fact can be found e.g. in Fisk (1996).
Lemma A.6 (Hrq) optimization problem). Let A ∈ Rm×n be a rank-k matrix and r ∈ [k] be
an integer parameter. Then M = λ Hr (A) is an optimal solution to the following optimization
problem:
maχ, {hA,Mi-λIIMkF}	⑹
rank(M)≤r	2
Proof. Let UΣV> = P Σii UiVi> be a singular value decomposition of A. We note that (6) is
i
equivalent to
min	kA - λM k2F := f (M)	(7)
rank(M)≤r
k
Now, note that f(λHr (A)) = ∣∣A 一 Hr(A)kF = P Σ2i.On the other hand, by applying Weyrs
i=r+1
inequality (Lemma A.5) for j = r + 1,
k+r	k+r	k
f(M) = kA 一 λM k2F = X σi2(A 一 λM) ≥ X(σi+r(A) 一 σr+1(λM))2 = X Σi2i ,
i=1	i=1	i=r+1
where the last equality follows from the fact that rank(A) = k and rank(M) ≤ r. Therefore,
M = λ Hr (A) minimizes (7) and thus maximizes (6).	□
A.2 Proof of Theorem 2.1 (greedy)
We will start with the following simple lemma about the Frobenius norm of a sum of matrices with
orthogonal columns or rows:
Lemma A.7. Let U ∈ Rm×r, V ∈ Rn×r, X ∈ Rm×r, Y ∈ Rn×r be such that the columns ofU
are orthogonal to the columns of X or the columns of V are orthogonal to the columns of Y . Then
kUV> +XY>k2F = kUV>k2F+ kXY>k2F.
Proof. If the columns of U are orthogonal to those of X, then U>X = 0 and if the columns
of V are orthogonal to those of Y , then Y >V = 0. Therefore in any case hUV>, XY >i =
Tr(VU>XY>) = Tr(U>XY>V) = 0, implying
kUV> +XY>k2F = kUV>k2F+ kXY>k2F+2hUV>,XY>i = kUV>k2F+ kXY>k2F
□
12
Published as a conference paper at ICLR 2021
Additionally, we have the following lemma regarding the optimality conditions of (2):
Lemma A.8. Let A = UXV> where U ∈ Rm×r, X ∈ Rr×r, and V ∈ Rn×r, such that X is the
optimal solution to (2). Then for any u ∈ im(U) and v ∈ im(V) we have that hVR(A), uv>i = 0.
Proof. By the optimality condition of 2, we have that
U > VR(A)V = 0
Now, for any u = Ux and v = Vy we have
hVR(A), uv>i = u>VR(A)v =x>U>VR(A)Vy= 0
□
We are now ready for the proof of Theorem 2.1.
Proof. Let At-1 be the current solution UV> before iteration t - 1 ≥ 0. Let u ∈ Rm and v ∈ Rm
be left and right singular vectors of matrix VR(A), i.e. unit vectors maximizing |hVR(A), uv>i|.
Let
Bt = {B|B = At-1 + ηuvT, η ∈ R}.
By smoothness we have
R(At-1)-R(At) ≥ max {R(At-1) - R(B)}
B∈Bt
≥ max 1一(VR(At-I), B - At-Ii- P-1-IIB - At-IkF
B∈Bt	2
≥ max ηhVR(At-1), uv>i - η2
= mη^χ ]ηkVR(At-1)k2 - η2P^j
=kVR(At-ι)k2
2ρ+
where ∣∣ ∙ ∣∣2 is the spectral norm (i.e. maximum magnitude of a singular value).
On the other hand, by strong convexity and noting that
rank(A* 一 At-ι) ≤ rank(A*) + rank(At-ι) ≤ r* + r,
R(A*) — R(At-ι) ≥hVR(At-ι),A^- - 4-0 + 勺∣∣A* — At-IkF .
(8)
Let At-ι = UV > and	A*	=	U *V *>.	We let	口加⑺	=U (U >U)+U >	and	∏im(v)=
V(V>V)+V> denote the orthogonal projections onto the images of U and V respectively. We
now write
A* = U*V*> = (U1 + U2)(V1 +V2)> = U1V1> +U1V2> +U2V*>
where U1 = Πim(U) U* is a matrix where every column ofU* is replaced by its projection on im(U)
and U2 = U* - U1 and similarly V1 = Πim(V)V* is a matrix where every column ofV* is replaced
by its projection on im(V) and V2 = V* - V1. By setting U0 = (-U | U1) and V0 = (V | V1) we
can write
A* - At-1 = U0V0> +U1V2> +U2V*>
where im(U0) = im(U) and im(V0) = im(V). Also, note that
rank(U1V2>) ≤ rank(V2) ≤ rank(V*) = rank(A*) ≤ r*
13
Published as a conference paper at ICLR 2021
and similarly rank(U2V*>) ≤ r*. So now the right hand side of (8) can be reshaped as
WR(At-I), A* - At-ιi + ρ-+rlkA* - At-IkF
={VR(At-1), U0V0> + U1V2> + U2V*>i + P-尸∣∣U0V0> + U1V2> + U2V*>kF
Now, note that since by definition the columns of U0 are in im(U) and the columns of V0 are in
im(V), Lemma A.8 implies that hVR(At-1), U0V0> i = 0. Therefore the above is equal to
hVR(At-1), U1V 2> + U 2V *>i + ρ-+p- ∣∣U 0V 0> + U1V 2> + U 2V *>∣F
≥ hVR(At-1), U1V2>i + hVR(At-1), U2V*>〉+ ρ-+rɪ (∣∣U 1V2>∣F + ∣U2V*>∣F)
≥ 2 min	卜VR(At-1), Mi + 勺∣∣M∣∣f]
rank(M )≤r* I	2
∣Hr*(VR(At-1))kF
=—2-------------------
2ρr+r*
*kVR(At-1)∣∣2
≥ —r ------------
-
ρr+r*
where the first equality follows by noticing that the columns ofV0 and V1 are orthogonal to those of
V2 and the columns of U0 and U1 are orthogonal to those of U2, and applying Lemma A.7. The last
equality is a direct application of Lemma A.6 and the last inequality states that the largest squared
singular value is not smaller than the average of the top r* squared singular values. Therefore we
have concluded that
kVR(At-1 )∣2 ≥ ρ-+r* (R(At-1) — R(A*))
Plugging this back into the smoothness inequality, we get
R(At-1) — R(At) ≥ 二(R(At-1)- R(A*))
2r*κ
or equivalently
R(At)- R(A*) ≤ (1 - *——) (R(At-I)- R(A*)) .
2r κ
Therefore after L = 2r*κ log R(AO)-R(A ) iterations we have
R(AT) - R(A*) ≤
1L
1 - H	(R(AO)-R(A*))
≤ e-2rLκ (R(Ao) - R(A*))
≤
Since A0 = 0, the result follows.
□
A.3 Proof of Theorem 2.2 (local search)
Proof. Similarly to Section A.3, we let At-1 be the current solution before iteration t - 1 ≥ 0.
Let u ∈ Rm and v ∈ Rm be left and right singular vectors of matrix VR(A), i.e. unit vectors
maximizing |hVR(A), uv>i| and let
Bt = {B|B = At-1 + ηuvT - σminxy>, η ∈ R},
14
Published as a conference paper at ICLR 2021
where σmi∏xyτ = At-ι — Hr-ι(At-ι) is the rank-1 term corresponding to the minimum singular
value of At-ι. By smoothness we have
R(At-1)- R(At)
≥ max {R(At-I)- R(B)}
B∈Bt
≥ max [-"R(AtT),B - At-Ii- P2-IIB - At-IllF
B ∈Bt I	/
■ ρ∣-IlnuvT -σminχyTIlF
ιnρ2^ }
=max
η∈R
≥ max
η∈R
=max
η∈R
一(VR(At-I),nuvτ - σminxyTi -
{一〈▽R(At-I),nuJi—n"+ - fi
{n∣NR(At-I)∣∣2 - n2p+ - σminp+}
=kVR(At-ι)∣2
4p+
where in the last inequality we used the fact that (VR(At-ι), XyTi = 0 following from Lemma A.8,
as well as Lemma A.1.
On the other hand, by strong convexity,
R(A*) - R(At-ι) ≥ (VR(At-ι),A* - At-ιi + Prlɪɪ∣∣A* - At-IkF .
Let At-ι = UVT and A* = U*V*τ. We write
A* = U *V *t = (U1 + U 2)(V1 + V 2)t = U1V1T + U1V2T + U 2V *t
where U1 is a matrix where every column of U * is replaced by its projection on im(U) and U2 =
U * - U1 and similarly V1 is a matrix where every column of V * is replaced by its projection on
im(V) and V2 = V * - V1. By setting U0 = (-U | U1) and V0 = (V | V1) we can write
A* - At-1 = U0V0T + U1V2τ + U2V*τ
where im(U0) = im(U) and im(V0) = im(V). Also, note that
rank(U 1V2τ) ≤ rank(V2) ≤ rank(V*) = rank(A*) ≤ r*
and similarly rank(U2V*τ) ≤ r*. So we now have
(VR(At-1 ),A* - At-1i + Prlrɪ∣A* - At-IkF
(VR(At-1), U0V0T + U1V2τ + U2V*τi + p-lr*kU0V0T + U1V2τ + U2V*t∣F
(VR(At-1), U1V2τ + U2V*τi +
(VR(At-1),U 1V2τ + U 2V *τi +
pr∣r*
2
pr+r*
2
∣∣U 0V0T + U1V2τ + U 2V *τ∣F
U 0V OTkF + ∣U 1V2TkF + ∣U 2V *τkF
≥ (VR(At-1), U1V2τi + (VR(At-1), U2V*τi + prlr* (∣∣U 1V2TkF + kU2V*t∣F)
+ PIr* ∣u 0 v OTkF
≥ 2ran嬲 ≤r1VR(At-I),Mi + PT kMkF	PT kU	OTkF
IjHr*(VR(At-1))∣F
一2-----------------
2pr+r*
≥-r* ≡A-≡ +
+ Pl匚 ∣u 0v OTkF
pr+r*
PlC ∣u 0v OTkF
15
Published as a conference paper at ICLR 2021
where the second equality follows from the fact that hVR(At-ι), uv>〉= 0 for any U ∈ im(U), V ∈
im(V ), the third equality from the fact that im(U2) ⊥ im(U0) ∪ im(U1) and im(V 2) ⊥ im(V 0)
and by applying Lemma A.7, and the last inequality from the fact that the largest squared singular
value is not smaller than the average of the top r* squared singular values. Now, note that since
rank(U 1V 1>) ≤ r* < r = rank(UV>),
kU0V0>k2F = kU1V1> -UV>k2F
r
=Xσi2(U1V1> -UV>)
i=1
r
≥ ^X(σi+r* (UVT)- σr* + 1 (UIVIT))2
i=1
r
= X σi2 (UVT )
i=r* +1
≥ (r - r*)σm2 in(U V T)
= (r - r*)σm2 in(At-1) ,
where we used the fact that rank(U1V1T) ≤ r* together with Lemma A.5. Therefore we have
concluded that
kVR(At-ι)∣∣2 ≥ ρ-+r* (R(At-ι) - R(A*)) + (P-+r*2r*r-r*)σ2ιm
Plugging this back into the smoothness inequality and setting K = ρ+ , we get
ρr+r*
R(At-I) - R(At) ≥ 4-7e(R(At-I) - R(A)) + (Pr+Ce	- - ρ+) σ2ιin(At-I)
4r κ	8r κ
≥ 4~e (R(At-I) - R(A*))
4r κ
as long as r ≥ r*(1 + 8eκ2), or equivalently,
R(At) - R(A*) ≤ (1 -占)(R(At-I)- R(A*)).
4r* κ
Therefore after L = 4r*Klog R(AO)-R(A ) iterations we have
R(At) - R(A*) ≤ (1 - 4⅛)L (R(Ao) - R(A*))
≤ e-4rLκe (R(A0) - R(A*))
≤
Since Ao = 0 and K ≤ κr+r*, the result follows.	□
A.4 Tightness of the analysis
It is important to note that the κr+r* factor that appears in the rank bounds of both Theorems 2.1
and 2.2 is inherent in these algorithms and not an artifact of our analysis. In particular, such lower
bounds based on the restricted condition number have been previously shown for the problem of
sparse linear regression. More specifically, Foster et al. (2015) showed that there is a family of
instances in which the analogues of Greedy and Local Search for sparse optimization require the
sparsity to be Ω(s*κ0) for constant error e > 0, where s* is the optimal sparsity and κ0 is the SPar-
sity-restricted condition number. These instances can be easily adjusted to give a rank lower bound
of Ω(r*κr+r*) for constant error e > 0, implying that the K dependence in Theorem 2.1 is tight
for Greedy. Furthermore, specifically for Local Search, Axiotis & Sviridenko (2020) additionally
16
Published as a conference paper at ICLR 2021
showed that there is a family of instances in which the analogue of Local Search for sparse optimiza-
tion requires a sparsity of Ω(s*(κ0)2). Adapting these instances to the setting of rank-constrained
convex optimization is less trivial, but we conjecture that it is possible, which would lead to a rank
lower bound of Ω(r^κ2+r^) for Local Search.
We present the following lemma, which essentially states that sparse optimization lower bounds
for Orthogonal Matching Pursuit (OMP, Pati et al. (1993)) (resp. Orthogonal Matching Pursuit
with Replacement (OMPR, Jain et al. (2011))) in which the optimal sparse solution is also a global
optimum, immediately carry over (up to constants) to rank-constrained convex optimization lower
bounds for Greedy (resp. Local Search).
Lemma A.9. Let f ∈ Rn → R and x* ∈ Rn be an s*-sparse vector that is also a global minimizer
of f. Also, let f have restricted smoothness parameter β at sparsity level S + s* for some S ≥ s*
and restricted strong convexity parameter α at sparsity level s + s*. Then we can define the rank-
constrained problem, with R : Rn×n → R,
mi∏	R(A) := f(diag(A)) + β∣∣A - diag(A)kF ,	(9)
rank(A)≤s*	2
where diag(A) is a vector containing the diagonal ofA. R has rank-restricted smoothness at rank
s + s* at most 2β and rank-restricted strong convexity at rank s + s* at least α. Suppose that we run
t iterations of OMP (resp. OMPR) starting from a solution x, to get solution x0, and similarly run
t iterations of Greedy (resp. Local Search) starting from solution A = diag(x) (where diag(x) is a
diagonal matrix with x on the diagonal) to get solution A0. Then A0 is diagonal and diag(A0) = x0.
In other words, in this scenario OMP and Greedy (resp. OMPR and Local Search) are equivalent.
>Λ /■ TL T . . 1 . Γ∙	1	2 CC	1	C	P / 1 ∙ ∕G∖∖、 C / ⅛ ∖	∙ . 1	IJ	1
Proof. Note that for any solution A of R we have R(A) ≥ f (diag(A)) ≥ f(x*), with equality only
ifAb is diagonal. Furthermore, rank(diag(x*)) ≤ s*, meaning that diag(x*) is an optimal solution
of (9). Now, given any diagonal solution A of (9) such that A = diag(x), we claim that one step of
either Greedy or Local Search keeps it diagonal. This is because
β
VR(A) = diag(Vf (x)) + 2(A — diag(A))= diag(Vf (x)).
Therefore the largest eigenvalue of VR(A) has corresponding eigenvector 1 for some i, which
implies that the rank-1 component which will be added is a multiple of 1i1i>. For the same reason
the rank-1 component removed by Local Search will be a multiple of 1j 1j> for some j. Therefore
running Greedy (resp. Local Search) on such an instance is identical to running OMP (resp. OMPR)
on the diagonal.	□
Together with the lower bound instances of Foster et al. (2015) (in which the global minimum prop-
erty is true), it immediately implies a rank lower bound of Ω(r*κr+r*) for getting a solution with
constant error for rank-constrained convex optimization. On the other hand, the lower bound in-
stances of Axiotis & Sviridenko (2020) give a quadratic lower bound in κ for OMPR. The above
lemma cannot be directly applied since the sparse solutions are not global minima, but we conjec-
ture that a similar proof will give a rank lower bound of Ω(r*κ2+r*) for rank-constrained convex
optimization with Local Search.
A.5 Addendum to Section 4
17
Published as a conference paper at ICLR 2021
Figure 4: One of the splits of the Movielens 100K dataset. We can see that for small ranks the
Fast Local Search solution is better and more stable, but for larger ranks it does not provide any
improvement over the Fast Greedy algorithm.
(a) k = 10, p = 0.5, SNR = 1
(b) k = 10, p = 0.3, SNR = 3
Figure 5: Test error vs rank in the matrix completion problem of Section 4.2. Bands of ±1 standard
error are shown.
18
Published as a conference paper at ICLR 2021
(a) Train error vs rank
(b) Test error vs rank
Figure 6: Performance of greedy with fully solving the inner optimization problem (left) and ap-
plying 3 iterations of the LSQR algorithm (right) in the matrix completion problem of Section 4.2.
k = 5, p = 0.2, SNR = 10. Bands of ±1 standard error are shown. This experiment shows why it
is crucial to apply some kind of regularization to the Fast Greedy and Fast Local Search algorithms
for machine learning applications.
19