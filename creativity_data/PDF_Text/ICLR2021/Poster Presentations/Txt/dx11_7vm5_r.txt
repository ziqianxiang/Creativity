Published as a conference paper at ICLR 2021
Linear Last-iterate	Convergence in Con-
strained Saddle-point Optimization
Chen-Yu Wei, Chung-Wei Lee, Mengxiao Zhang, Haipeng Luo
University of Southern California
{chenyu.wei,leechung,mengxiao.zhang,haipengl}@usc.edu
Ab stract
Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative
Weights Update (OMWU) for saddle-point optimization have received growing
attention due to their favorable last-iterate convergence. However, their behaviors
for simple bilinear games over the probability simplex are still not fully under-
stood — previous analysis lacks explicit convergence rates, only applies to an
exponentially small learning rate, or requires additional assumptions such as the
uniqueness of the optimal solution.
In this work, we significantly expand the understanding of last-iterate convergence
for OGDA and OMWU in the constrained setting. Specifically, for OMWU in
bilinear games over the simplex, we show that when the equilibrium is unique, lin-
ear last-iterate convergence is achieved with a learning rate whose value is set to
a universal constant, improving the result of (Daskalakis & Panageas, 2019b) un-
der the same assumption. We then significantly extend the results to more general
objectives and feasible sets for the projected OGDA algorithm, by introducing a
sufficient condition under which OGDA exhibits concrete last-iterate convergence
rates with a constant learning rate whose value only depends on the smoothness
of the objective function. We show that bilinear games over any polytope satisfy
this condition and OGDA converges exponentially fast even without the unique
equilibrium assumption. Our condition also holds for strongly-convex-strongly-
concave functions, recovering the result of (Hsieh et al., 2019). Finally, we pro-
vide experimental results to further support our theory.
1	Introduction
Saddle-point optimization in the form of minx maxy f(x, y) dates back to (Neumann, 1928), where
the celebrated minimax theorem was discovered. Due to advances of Generative Adversarial Net-
works (GANs) (Goodfellow et al., 2014) (which itself is a saddle-point problem), the question of
how to find a good approximation of the saddle point, especially via an efficient iterative algorithm,
has recently gained significant research interest. Simple algorithms such as Gradient Descent Ascent
(GDA) and Multiplicative Weights Update (MWU) are known to cycle and fail to converge even in
simple bilinear cases (see e.g., (Bailey & Piliouras, 2018) and (Cheung & Piliouras, 2019)).
Many recent works consider resolving this issue via simple modifications of standard algorithms,
usually in the form of some extra gradient descent/ascent steps. This includes Extra-Gradient meth-
ods (EG) (Liang & Stokes, 2019; Mokhtari et al., 2020b), Optimistic Gradient Descent Ascent
(OGDA) (Daskalakis et al., 2018; Gidel et al., 2019; Mertikopoulos et al., 2019), Optimistic Mul-
tiplicative Weights Update (OMWU) (Daskalakis & Panageas, 2019b; Lei et al., 2021), and others.
In particular, OGDA and OMWU are suitable for the repeated game setting where two players
repeatedly propose Xt and yt and receive only Vχf (xt, yt) and Vyf (xt, yt) respectively as feed-
back, with the goal of converging to a saddle point or equivalently a Nash equilibrium using game
theory terminology. One notable benefit of OGDA and OMWU is that they are also no-regret al-
gorithms with important applications in online learning, especially when playing against adversarial
opponents (Chiang et al., 2012; Rakhlin & Sridharan, 2013).
Despite considerable progress, especially those for the unconstrained setting, the behavior of these
algorithms for the constrained setting, where x and y are restricted to closed convex sets X and
1
Published as a conference paper at ICLR 2021
Y respectively, is still not fully understood. This is even true when f is a bilinear function and
X and Y are simplex, known as the classic two-player zero-sum games in normal form, or simply
matrix games. Indeed, existing convergence results on the last iterate of OGDA or OMWU for
matrix games are unsatisfactory — they lack explicit convergence rates (Popov, 1980; Mertikopou-
los et al., 2019), only apply to exponentially small learning rate thus not reflecting the behavior of
the algorithms in practice (Daskalakis & Panageas, 2019b), or require additional conditions such as
uniqueness of the equilibrium or a good initialization (Daskalakis & Panageas, 2019b).
Motivated by this fact, in this work, we first improve the last-iterate convergence result of OMWU
for matrix games. Under the same unique equilibrium assumption as made by Daskalakis &
Panageas (2019b), we show linear convergence with a concrete rate in terms of the Kullback-Leibler
divergence between the last iterate and the equilibrium, using a learning rate whose value is set to a
universal constant.
We then significantly extend our results and consider OGDA for general constrained and smooth
convex-concave saddle-point problems, without the uniqueness assumption. Specifically, We
start with proving an average duality gap convergence of OGDA at the rate of O(1∕√T) af-
ter T iterations. Then, to obtain a more favorable last-iterate convergence in terms of the dis-
tance to the set of equilibria, we propose a general sufficient condition on X , Y, and f, called
Saddle-Point Metric Subregularity (SP-MS), under which we prove concrete last-iterate conver-
gence rates, all with a constant learning rate and without further assumptions.
Our last-iterate convergence results of OGDA greatly generalize that of (Hsieh et al., 2019, The-
orem 2), which itself is a consolidated version of results from several earlier works. The key im-
plication of our new results is that, by showing that matrix games satisfy our SP-MS condition, we
provide by far the most general last-iterate guarantee with a linear convergence for this problem us-
ing OGDA. Compared to that of OMWU, the convergence result of OGDA holds more generally
even when there are multiple equilibria.
More generally, the same linear last-iterate convergence holds for any bilinear games over polytopes
since they also satisfy the SP-MS condition as we show. To complement this result, we construct an
example of a bilinear game with a non-polytope feasible set where OGDA provably does not ensure
linear convergence, indicating that the shape of the feasible set matters.
Finally, we also provide experimental results to support our theory. In particular, we observe that
OGDA generally converges faster than OMWU for matrix games, despite the facts that both prov-
ably converge exponentially fast and that OMWU is often considered more favorable compared to
OGDA when the feasible set is the simplex.
2	Related Work
Average-iterate convergence. While showing last-iterate convergence has been a challenging
task, it is well-known that the average-iterate of many standard algorithms such as GDA and MWU
enjoys a converging duality gap at the rate of O(1/√T) (Freund & Schapire, 1999). A line of works
show that the rate can be improved to O(1/T) using the “optimistic” version of these algorithms
such as OGDA and OMWU (Rakhlin & Sridharan, 2013; Daskalakis et al., 2015; Syrgkanis et al.,
2015). For tasks such as training GANs, however, average-iterate convergence is unsatisfactory
since averaging large neural networks is usually prohibited.
Extra-Gradient (EG) algorithms. The saddle-point problem fits into the more general variational
inequality framework (Harker & Pang, 1990). A classic algorithm for variational inequalities is EG,
first introduced in (Korpelevich, 1976). Tseng (1995) is the first to show last-iterate convergence
for EG in various settings such as bilinear or strongly-convex-strongly-concave problems. Recent
works significantly expand the understanding ofEG and its variants for unconstrained bilinear prob-
lems (Liang & Stokes, 2019), unconstrained strongly-convex-strongly-concave problems (Mokhtari
et al., 2020b), and more (Zhang et al., 2019; Lin et al., 2020; Golowich et al., 2020b).
The original EG is not applicable to a repeated game setting where only one gradient evaluation
is possible in each iteration. Moreover, unlike OGDA and OMWU, EG is shown to have linear
regret against adversarial opponents, and thus itis not a no-regret learning algorithm (Bowling, 2005;
2
Published as a conference paper at ICLR 2021
Golowich et al., 2020a). However, there are “single-call variants” of EG that address these issues.
In fact, some of these versions coincide with the OGDA algorithm under different names such as
modified ArroW-HurWicz method (Popov, 1980) and “extrapolation from the past"(Gidel et al.,
2019). Apart from OGDA, other single-call variants of EG include Reflected Gradient (Malitsky,
2015; Cui & Shanbhag, 2016; Malitsky & Tam) and Optimistic Gradient (Daskalakis et al., 2018;
Mokhtari et al., 2020a). These variants are all equivalent in the unconstrained setting but differ in
the constrained setting. To the best of our knoWledge, none of the existing results for any single-call
variant of EG covers the constrained bilinear case (Which is one of our key contributions).
Error Bounds and Metric Subregularity To derive linear convergence for variational inequality
problems, error bound method is a commonly used technique (Pang, 1997; Luo & Tseng, 1993).
For example, it is a standard approach to studying the last-iterate convergence of EG algorithms
(Tseng, 1995; Hsieh et al., 2020; Azizian et al., 2020). An error bound method is associated With
an error function that gives every point in the feasible set a measure of sub-optimality that is loWer
bounded by the distance of the point to the optimal set up to some problem dependent constant. If
such a error function exists, linear convergence can be obtained. The choice of the error function
depends on the feasible region, the objection function, and the algorithm. Common error functions
include natural residual functions (Iusem et al., 2017; Malitsky, 2019) and gap functions (Larsson &
Patriksson, 1994; Solodov & Tseng, 2000; Chen et al., 2017). Our method to derive the last-iterate
convergence for OGDA can also be vieWed as an error bound method.
Metric subregularity is another important concept to derive linear convergence via some Lipschitz
behavior of a set-valued operator (Leventhal, 2009; Liang et al., 2016; Alacaoglu et al., 2019; Latafat
et al., 2019). Metric subregularity is closely related to error bound methods (Kruger, 2015). In fact,
as We prove in Appendix F, one special case of our condition SP-MS (that alloWs us to shoW linear
convergence) is equivalent to metric subregularity ofan operator defined in terms of the normal cone
of the feasible set and the gradient of the objective. This is also the reason Why We call our condition
Saddle-Point Metric Subregularity. Although metric subregularity has been extensively used in the
literature, to the best of our knoWledge, our Work is the first to use this condition to analyze OGDA.
OGDA and OMWU. Recently, last-iterate convergence for OGDA has been proven in vari-
ous settings such as convex-concave problems (Daskalakis et al., 2018), unconstrained bilinear
problems (Daskalakis & Panageas, 2018; Liang & Stokes, 2019), strongly-convex-strongly-concave
problems (Mokhtari et al., 2020b), and others (e.g. (Mertikopoulos et al., 2019)).
HoWever, the behavior of OGDA and OMWU for the constrained bilinear case, or even the special
case of classic matrix games, appears to be much more mysterious and less understood. Cheung &
Piliouras (2020) provide an alternative vieW on the convergence behavior of OMWU by studying
volume contraction in the dual space. Daskalakis & Panageas (2019b) shoW last-iterate convergence
of OMWU for matrix games under a uniqueness assumption and Without a concrete rate. Although
it is implicitly suggested in (Daskalakis & Panageas, 2019b;a) that a rate of O(1/T 1/9) is possible,
it is still not clear hoW to choose the learning rate appropriately from their analysis. As mentioned,
our results for OMWU significantly improve theirs, With a clean linear convergence rate using a
constant learning rate under the same uniqueness assumption, While our results for OGDA further
remove the uniqueness assumption.
3	Notations and Preliminaries
We consider the folloWing constrained saddle-point problem: minx∈X maxy∈Y f(x, y), Where X
and Y are closed convex sets, and f is a continuous differentiable function that is convex in x for
any fixed y and concave in y for any fixed x. By the celebrated minimax theorem (Neumann, 1928),
We have minx∈X maxy∈Y f(x,y) = maxy∈Y minx∈X f(x, y).
The set of minimax optimal strategy is denoted by X* = argminχ∈χ maxy∈γ f (x, y), and the set
of maximin optimal strategy is denoted by Y* = argmaxy∈γ minχ∈χ f (x, y). It is well-known
that X* and Y* are convex, and any pair (x*, y*) ∈ X* × Y* is a Nash equilibrium satisfying
f(x*, y) ≤ f (x*, y*) ≤ f(x, y*) for any (x, y) ∈ X × Y.
For notational convenience, we define Z = X × Y and similarly Z* = X* × Y*. For a point
Z = (x, y) ∈ Z, we further define f (z) = f(x, y) and F(Z) = Exf (x, y), -Vy f(x, y)).
3
Published as a conference paper at ICLR 2021
Our goal is to find a point Z ∈ Z that is close to the set of Nash equilibria Z*, and We Con-
sider three ways of measuring the closeness. The first one is the duality gap, defined as αf (z) =
maxy0∈Y f(x, y0) - minx0∈X f(x0, y), Which is alWays non-negative since maxy0 ∈Y f(x, y0) ≥
f(x, y) ≥ minx0∈X f(x0, y).
The second one is the distance between Z and Z*. Specifically, for any closed set A, we define the
projection operator ∏a as Π∕(a) = argminao∈A ∣∣a - a0k (throughout this work ∣∣ ∙ ∣∣ represents L2
norm). The squared distance between Z and Z* is then defined as dist2 (z, Z*) = ∣∣z - ∏z* (z) k2.
The third one is only for the case when X and Y are probability simplices, and z* = (x*, y*) is
the unique equilibrium. In this case, we use the sum of Kullback-Leibler divergence KL(x*, x) +
KL(y*, y) to measure the closeness between Z = (x, y) and z*, where KL(x, x0) = PIi Xi ln Xi.
i	xi
With a slight abuse of notation, we use KL(Z, Z0) to denote KL(x, x0) + KL(y, y0).
Other notations. We denote the (d - 1)-dimensional probability simplex as ∆d = {u ∈ Rd+ :
Pid=1 ui = 1}. For a convex function ψ, the corresponding Bregman divergence is defined as
Dψ (u, V) = ψ(u)-ψ(v)-hVψ(v), u-v). If ψ is Y-strongly convex in a domain, then Dψ (u, V) ≥
Y2∣∣u - v∣2 for any u, V in that domain. For U ∈ Rd, we define SUPP(U) = {i : Ui > 0}.
Optimistic Gradient Descent Ascent (OGDA). Starting from an arbitrary point (xb1, yb1) =
(x0, y0) from Z, OGDA with step size η > 0 iteratively computes the following for t = 1, 2, . . .,
xt = ΠX xbt - ηVxf(xt-1, yt-1) ,	xbt+1 = ΠX xbt - ηVxf(xt, yt) ,
yt = ∏γ (bt + ηVy f(χt-ι, yt-ι)),	bt+ι = ∏γ (bt + ηVy f(χt, yt)).
Note that there are several slightly different versions of the algorithm in the literature, which differ
in the timing of performing the projection. Our version is the same as those in (Chiang et al., 2012;
Rakhlin & Sridharan, 2013). It is also referred to as “single-call extra-gradient” in (Hsieh et al.,
2019), but it does not belong to the class of “extra-gradient” methods discussed in (Tseng, 1995;
Liang & Stokes, 2019; Golowich et al., 2020b) for example.
Also note that OGDA only requires accessing f via its gradient. In fact, only one gradient at the
point (xt, yt) is needed for iteration t. This aspect makes it especially suitable for a repeated game
setting, where in each round, one player proposes xt while another player proposes yt. With only the
information of the gradient from the environment (Vxf(xt, yt) for the first player and Vyf(xt, yt)
for the other), both players can execute the algorithm.
Optimistic Multiplicative Weights Update (OMWU). When the feasible sets X andY are prob-
ability simplices ∆M and ∆N for some integers M and N , OMWU is another common iterative
algorithm to solve the saddle-point problem. For simplicity, we assume that it starts from the uni-
form distributions (Xi, bi) = (x0, y0) = (1MM, 1NN), where 1d is the all-one vector of dimension d.
Then OMWU with step size η > 0 iteratively computes the following for t = 1, 2, . . .,
_	Xt,i exp(一η(Vχf (xt-1, yt-iXi)
xi,t	Pj Xt,j exp(一η(Vχf (xt-1, yt-i))j)
=	Xt,i exp(η(Vy f(xt-ι, yt-ι))i)
yt,i	Pj bt,j eχp(η(Vy f(Xt-1, yt-ι))j),
X __ Xt,i exp(一η(Vχf (xt, yt))i)
“+1'i - Pj bt,j eχp(-η(Vx f(Xt, yt))j ) ,
y =	Xt,i exp(η(Vy f (xt, yt))i)
yt+1,i	Pj bt,j eχp(η(Vy f(xt, yt))j).
OMWU and OGDA as Optimistic Mirror Descent Ascent. OMWU and OGDA can be
viewed as special cases of Optimistic Mirror Descent Ascent. Specifically, let regularizer ψ(U)
denote the negative entropy Pi ui lnui for the case of OMWU and (half of) the L2 norm square
1 ∣∣u∣2 for the case of OGDA (so that Dψ(u, V) is KL(u, V) and 11 ∣∣u - v∣2 respectively). Then
using the shorthands Zt = (Xt, yt) and Zbt = (Xbt, ybt) and recalling the notation defined earlier:
Z = X × Y and F(Z) = (Vx f (X, y), -Vy f (X, y)), one can rewrite OMWU/OGDA compactly
as
Zt = argmin
z∈Z
^ ∙
Zt+i = argmin
z∈Z
ηhZ, F(Zt-i)i + Dψ(Z, Zbt) ,
nηhZ, F (Zt)i + Dψ(Z,Zbt)o.
(1)
(2)
4
Published as a conference paper at ICLR 2021
By the standard regret analysis of Optimistic Mirror Descent, we have the following important
lemma, which is readily applied to OMWU and OGDA when ψ is instantiated as the corresponding
regularizer. The proof is mostly standard (see e.g., (Rakhlin & Sridharan, 2013, Lemma 1)). For
completeness, we include it in Appendix B.
Lemma 1. Consider update rules Eq. (1) and Eq. (2) and define dist2p(z, z0) = kx - x0 k2p +
Ily — y0kp. Suppose that ψ satisfies Dψ(z, z0) ≥ 1 distp(z, z0) for some P ≥ 1, and F satisfies
dist2(F(z), F(z0)) ≤ L2distp(z, z0) for q ≥ 1 with 1 + ɪ = 1. Also, assume that η ≤ 志.Then
for any z ∈ Z and any t ≥ 1, we have
nF(Zt)>(Zt - Z) ≤ Dψ(z, Zt) - Dψ(z, bt+1) - Dψ (bt+ι, Zt) - 15Dψ(Zt, Zt) + ~1QDψ(bt, Zt-I).
4	Convergence Results for OMWU
In this section, we show that for a two-player zero-sum matrix game with a unique equilibrium,
OMWU with a constant learning rate converges to the equilibrium exponentially fast. The assump-
tion and the algorithm are the same as those considered in (Daskalakis & Panageas, 2019b), but our
analysis improves theirs in two ways. First, we do not require the learning rate to be exponentially
smaller than some problem-dependent quantity. Second, we explicitly provide a linear convergence
rate. In Section 5, we further remove the uniqueness assumption and significantly generalize the
results by studying OGDA.
In a matrix game we have X = ∆M, Y = ∆N, and f (Z) = x> Gy for some matrix
G ∈ [—1, 1]M×N. To show the last-iterate convergence of OMWU, we first apply Lemma 1
with Dψ (u, V) = KL(u, v), Z = z* (the unique equilibrium of the game matrix G) and
(p, q) = (1, ∞). The constant L can be chosen as 1 since dist2∞(F(Z), F(Z0)) = maxi |(G(y —
y0))i |2 + maxj |(G>(x — x0))j |2 ≤ Iy — y0I21 + Ix — x0I12 = dist21(Z, Z0). Also notice that
F(Zt)> (Zt —Z*) = f(xt,yt) — f(x*, yt) + f(xt, y*) — f(xt, yt) = f (xt, y*) — f(x*,yt) ≥ 0
by the optimality of z*. Therefore, We have when n ≤ 1,
kl(z*, Zt+1) ≤ KL(z*, bt) — KL(bt+ι, Zt)- 15KL(Zt, bt) + 1⅛KL(bt, Zt-1).
Defining Θt = KL(z*, Zt) + 表KL(bt, Zt-1) and Zt = KL(bt+ι, Zt) + KL(Zt, bt), we rewrite the
above as
Θt+1 ≤ Θt — HZt.	(3)
From Eq. (3) itis clear that the quantity Θt is always non-increasing in t due to the non-negativity of
Zt . Furthermore, the more the algorithm moves between round t and round t + 1 (that is, the larger
Zt is), the more Θt decreases.
To establish the rate of convergence, a natural idea is to relate Zt back to Θt or Θt+1 . For example,
if we can show Zt ≥ cΘt+1 for some constant c > 0, then Eq. (3) implies Θt+1 ≤ Θt — 15c Θt+ι,
which further gives Θt+1 ≤(1 + 15C) Θt. This immediately implies a linear convergence rate
for Θt as well as KL(Z*, ZZt) since KL(Z*, ZZt) ≤ Θt.
Moreover, notice that to find such c, it suffices to find a c0 > 0 such that Zt ≥ c0KL(Z*, ZZt+1). This
is because it will then give Zt ≥ 1⅛KL(Zt+1, Zt) + 15Zt ≥ 16KL(Zt+1, Zt) + 15cf KL(z* , Zt+1) ≥
min{1,15c }Θt+1, and thus C，min{1,15c} satisfies the condition.
From the discussion above, we see that to establish the linear convergence of KL(Z*, ZZt), we only
need to show that there exists some c0 > 0 such that KL(ZZt+1, Zt) + KL(Zt, ZZt) ≥ c0KL(Z*, ZZt+1).
The high-level interpretation of this inequality is that when ZZt+1 is far from the equilibrium Z* (i.e.,
KL(Z*, ZZt+1) is large), the algorithm should have a large move between round t and t + 1 making
KL(ZZt+1, Zt) + KL(Zt, ZZt) large.
In our analysis, we use a two-stage argument to find such a c0 . In the first stage, we only show
that KL(ZZt+1, Zt) + KL(Zt, ZZt) ≥ c00KL(Z*, ZZt+1)2 for some c00 > 0, and use it to argue a slower
convergence rate KL(z*, Zt) = O (ɪ). Then in the second stage, we show that after Zt and Zt
become close enough to Z*, we have KL(ZZt+1, Zt)+KL(Zt, ZZt) ≥ c0KL(Z*, ZZt+1) for some c0 > 0.
5
Published as a conference paper at ICLR 2021
This kind of two-stage argument might be reminiscent of that used by Daskalakis & Panageas
(2019b); however, the techniques we use are very different. Specifically, Daskalakis & Panageas
(2019b) utilize tools of “spectral analysis” similar to (Liang & Stokes, 2019) and show that the
OMWU update can be viewed as a “contraction mapping” with respect to a matrix whose eigen-
value is smaller than 1. Our analysis, on the other hand, leverages analysis of online mirror descent,
starting from the “one-step regret bound” (Lemma 1) and making use of the two negative terms that
are typically dropped in the analysis. Importantly, our analysis does not need an exponentially small
learning rate required by (Daskalakis & Panageas, 2019b). Thus, unlike their results, our learning
rate is kept as a universal constant in all stages. The arguments above are formalized below:
Lemma 2. Consider a matrix game f(x, y) = x>Gy with X = ∆M, Y = ∆N, and G ∈
[—1,1]M×N. Assume that there exists a unique Nash equilibrium z* and η ≤ 8. Then, there exists
a constant C1 > 0 that depends on G such that for any t ≥ 1, OMWU ensures
KL(zbt+1,zt)+KL(zt,zbt) ≥ η1 2C1KL(z*, zbt+1)2.
Also, there is a constant ξ > 0 that depends on G (defined in Definition 2) such that as long as
max{kz* — btkι, ∣∣z* — zt∣∣ι} ≤ ηξ, then
KL(zbt+1, zt) + KL(zt,zbt) ≥ η2C2KL(z*, zbt+1)
for another constant C2 > 0 that depends on G.
With Lemma 2 and the earlier discussion, the last-iterate convergence rate of OMWU is established:
Theorem 3. For a matrix game f(x, y) = x>Gy with a unique Nash equilibrium z*, OMWU
with a learning rate η ≤ 1 guarantees KL(z*, Zt) ≤ C3(l + C4)-t, where C3,C4 > 0 are some
constants depending on the game matrix G.
Proofs for this section are deferred to Appendix D, where all problem-dependent constants are spec-
ified as well.1 To the best of our knowledge, Theorem 3 gives the first last-iterate convergence result
for OMWU with a concrete linear rate. We note that the uniqueness assumption is critical for our
analysis, and whether this is indeed necessary for OMWU is left as an important future direction.
5	Convergence Results for OGDA
In this section, we provide last-iterate convergence results for OGDA, which are much more general
than those in Section 4. We propose a general condition subsuming many well-studied cases, un-
der which OGDA enjoys a concrete last-iterate convergence guarantee in terms of the L2 distance
between zt and Z * . The results in this part can be specialized to the setting of bilinear games over
simplex, but the unique equilibrium assumption made in Section 4 and in (Daskalakis & Panageas,
2019b) is no longer needed.
Throughout the section we make the assumption that f is L-smooth:
Assumption 1. For any z, z0 ∈ Z, kF(z) — F(z0)k ≤ Lkz — z0k holds.2
To introduce our general condition, we first provide some intuition by applying Lemma 1 again.
Letting ψ(u) = 2[∣u∣∣2 in Lemma 1, We get that for OGDA, for any Z ∈ Z and any t ≥ 1,
2ηF(Zt)T(Zt - Z) ≤kbt - zk2 - kbt+ι - zk2 - kbt+ι - ztk2 - 16kzt - btk2 + 16Ilbt - zt-1 k2.
Now we instantiate the inequality above with Z = ∏z*(bt) ∈ Z*. Since Z = ∏z*(bt) is an
equilibrium, WehaveF(Zt)>(Zt —Z) ≥ f(xt, yt) —f(x,yt)+f(xt,y) — f(xt, yt) = f(xt, y) —
f(x, yt) ≥ 0 by the convexity/concavity of f and the optimality of Z, and thus
kbt+ι - πzMbt)Il2 ≤ Ilbt - πzMbt)Il2 - kbt+ι - Ztk2 - 16kZt - btk2 + 16Ilbt - Zt-ιk2.
1One might find that the constant C3 is exponential in some problem-dependent quantity T0. However, this
is simply a loose bound in exchange for more concise presentation — our proof in fact shows that when t < T0,
the convergence is of a slower 1/t rate, and when t ≥ T0 , the convergence is linear without this large constant.
2This is equivalent to the condition distq2 (F (z), F (z0)) ≤ L2dist2p (z, z0) in Lemma 1 with p = 2, hence
the same notation L.
6
Published as a conference paper at ICLR 2021
Further noting that the left-hand side is lower bounded by dist2(bt+ι, Z*) by definition, We arrive
at
dist2(bt+ι,Z*) ≤ dist2(bt,Z*) - ∣* - ztk2 - .-btk2 + 1⅛修一zt-ιk2.
Similarly, we define Θt = ∣∣bt - ∏z* (bt)k2 + 116∣∣bt - zt-1k2,Zt = ∣∣bt+ι - ztk2 + ∣∣zt - btk2,
and rewrite the above as
Θt+1 ≤ Θt- 15Zt.	(4)
As in Section 4, our goal now is to lower bound Zt by some quantity related to dist2 (bt+ι, Z*), and
then use Eq. (4) to obtain a convergence rate for Θt. In order to incorporate more general objective
functions into the discussion, in the following Lemma 4, we provide an intermediate lower bound
for Zt, which will be further related to dist2(zbt+1, Z*) later.
Lemma 4. For any t ≥ 0 and z0 ∈ Z with z0 = bt-+ι,, OGDA with η ≤ 志 ensures
2	2	32 2F(zbt+1)>(zbt+1-z0)2+
kzt+l-ztk + kzt-ztk ≥ 81η	kbt+ι-z0∣2	,	⑸
where [a]+ , max{a, 0}, and similarly, for z0 6= zt+1,
2	2	32 2 F(zt+1)>(zt+1 -z0)2+
Ilzt+ι - zt+ιk + Ilzt - zt+ιk ≥ 8iη	∣∣zt+1 - z0∣2	.	(6)
We note that a direct consequence of Lemma 4 is an “average duality gap” guarantee for OGDA
when Z is bounded:
T XX Mzt) = T XX χo∈m 管∈y Sxt，y0) - f(x,yt))=O (η√τ)	⑺
where D , supz,z0∈Z ∣z - z0∣ is the diameter of Z (the duality gap may be undefined when Z is
unbounded). We are not aware of any previous work that gives this result for the constrained case.
See Appendix E for the proof of Eq. (7) and comparisons with previous works.
However, to obtain last-iterate convergence results, we need to make sure that the right-hand side of
Eq. (5) is large enough. Motivated by this fact, we propose the following general condition on f
and Z to achieve so.
Definition 1 (Saddle-Point Metric Subregularity (SP-MS)). The SP-MS condition is defined as: for
any z ∈ Z\Z* with z* = ΠZ* (z),
sup F(z)>(z -IzO) ≥ Ckz - z*∣β+1	(SP-MS)
z0∈Z	∣z - z0∣
holds for some parameter β ≥ 0 and C > 0.
We call this condition Saddle-Point Metric Subregularity because the case with β = 0 is equivalent
to one type of metric subregularity in variational inequality problems, as we prove in Appendix F.
The condition is also closely related to other error bound conditions that have been identified for
variational inequality problems (e.g., Tseng (1995); Gilpin et al. (2008); Malitsky (2019)). Although
these works have shown that under similar conditions their algorithms exhibit linear convergence,
to the best of our knowledge, there is no previous work that analyzes OGDA or other no-regret
learning algorithms using such conditions.
SP-MS covers many standard settings studied in the literature. The first and perhaps the most impor-
tant example is bilinear games with a polytope feasible set, which in particular includes the classic
two-player matrix games considered in Section 4.
Theorem 5.	A bilinear game f(x, y) = x>Gy with X ⊆ RM and Y ⊆ RN being polytopes and
G ∈ RM×N satisfies SP-MS with β = 0.
7
Published as a conference paper at ICLR 2021
We emphasize again that different from Lemma 2, Theorem 5 does not require a unique equilibrium.
Note that we have not provided the concrete form of the parameter C in the theorem (which depends
on X , Y, and G), but it can be found in the proof (see Appendix G).3 The next example shows that
strongly-convex-strongly-concave problems are also special cases of our condition.
Theorem 6.	If f is strongly convex in x and strongly concave in y, then SP-MS holds with β = 0.
Next, we provide a toy example where SP-MS holds with β > 0.
Theorem 7.	Let X = Y , {(a, b) : 0 ≤ a, b ≤ 1, a + b = 1}, n > 2 be an integer, and
f(x, y) = x12n - x1y1 - y12n. Then SP-MS holds with β = 2n - 2.
With this general condition, we are now able to complete the loop. For any value of β , we show the
following last-iterate convergence guarantee for OGDA.
Theorem 8.	Forany η ≤ ɛɪ, ifSP-MS holds with β = 0, then OGDA guarantees linear last-iterate
convergence:
dist2(zt, Z*) ≤ 64dist2(bι, Z*)(1 + C5)-t;	(8)
on the other hand, if the condition holds with β > 0, then we have a slower convergence:
dist2(zt,Z*) ≤ 32
1+4
dist2(zb1,Z*) +2
t-1,
(9)
where C5，min { 1%C , 10.
We defer the proof to Appendix I and make several remarks. First, note that based on a convergence
result on dist2 (zt, Z*), one can immediately obtain a convergence guarantee for the duality gap
αf(zt) as long as f is also Lipschitz. This is because αf (zt) ≤ maxx0,y0 f(xt, y0) - f(x*, y0) +
f(x0, y*) - f(x0, yt) ≤ O(kxt - x*k + kyt - y*k) = O(Jdist2(zt, Z*)), where (x*, y*)=
∏z* (zt). While this leads to stronger guarantees compared to Eq. (7), We emphasize that the latter
holds even without the SP-MS condition.
Second, our results significantly generalize (Hsieh et al., 2019, Theorem 2) which itself is a consol-
idated version of several earlier works and also shows a linear convergence rate of OGDA under a
condition stronger than our SP-MS with β = 0 as discussed earlier. More specifically, our results
show that linear convergence holds for a much broader set of problems. Furthermore, we also show
slower sublinear convergence rates for any value of β > 0, which is also new as far as we know. In
particular, we empirically verify that OGDA indeed does not converge exponentially fast for the toy
example defined in Theorem 7 (see Appendix A).
Last but not least, the most significant implication of Theorem 8 is that it provides by far the most
general linear convergence result for OGDA for the classic two-player matrix games, or more gen-
erally bilinear games with polytope constraints, according to Theorem 5 and Eq. (8). Compared to
recent works of (Daskalakis & Panageas, 2018; 2019b) for matrix games (on OGDA or OMWU),
our result is considerably stronger: 1) we do not require a unique equilibrium while they do; 2) linear
convergence holds for any initial points zb1 , while their result only holds if the initial points are in
a small neighborhood of the unique equilibrium (otherwise the convergence is sublinear initially);
3) our only requirement on the step size is η ≤ ɛɪ ,4 while they require an exponentially small η,
which does not reflect the behavior of the algorithms in practice. Even compared with our result in
Section 4, we see that for OGDA, the unique equilibrium assumption is not required, and we do not
have an initial phase of sublinear convergence as in Lemma 2. In Appendix A, we empirically show
that OGDA often outperforms OMWU when both are tuned with a constant learning rate.
3After the first version of this paper, we found that (Gilpin et al., 2008, Lemma 3) gives a simpler proof
for our Theorem 5. Although their lemma only focuses on the case where the feasible sets are probability
simplices, it can be directly extended to the case of polytopes.
4In fact, any η < 芸 is enough to achieve linear convergence rate for OGDA, as one can verify by going
over our proof. We use η ≤ 矗 simply for consistency with the results for OMWU (where η cannot be set any
larger due to technical reasons).
8
Published as a conference paper at ICLR 2021
5
S
ɪ
-35 l
0
0
-5
-10
-15
-20
-25
-30
0.5
1
1.5
2
2.5
--OMWU-eta=0.1
--OMWU-eta=0.2
OMWU-eta=0.5
--OMWU-eta=1
OMWU-eta=5
OMWU-eta=10
-OGDA-eta=0.125
-OGDA-eta=0.25
-OGDA-eta=0.5
3
x105
Figure 1: Experiments of OGDA and OMWU with different learning rates for a matrix game
f(x, y) = x> Gy. “OGDA/OMWU-eta=n” represents the curve of OGDA/OMWU with learning
rate η. The configuration order in the legend is consistent with the order of the curves. For OMWU,
η ≥ 11 makes the algorithm diverge. The plot confirms the linear convergence of OMWU and
OGDA, although OGDA is generally observed to converge faster than OMWU.
One may wonder what happens if a bilinear game has a non-polytope constraint. It turns out that
in this case, SP-MS may only hold with β > 0, due to the following example showing that linear
convergence provably does not hold for OGDA when the feasible set has a curved boundary.
Theorem 9.	There exists a bilinear game with a non-polytope feasible set such that SP-MS holds
with β = 3, and dist2 (zt, Z*) = Ω(1∕t2) holdsfor OGDA.
This example indicates that the shape of the feasible set plays an important role in last-iterate conver-
gence, which may be an interesting future direction to investigate, This is also verified empirically
in our experiments (see Appendix A).
6 Experiments for Matrix Games
In this section, we provide empirical results on the performance of OGDA and OMWU for matrix
games on probability simplex.5 We include more empirical results in other settings in Appendix A.
We set the size of the game matrix to be 32 × 32, then generate a random matrix with each entry Gij
drawn uniformly at random from [-1, 1], and finally rescale its operator norm to 1. With probability
1, the game has a unique Nash Equilibrium (Daskalakis & Panageas, 2019b).
We compare the performances of OGDA and OMWU. For both algorithms, we choose a series of
different learning rates and compare their performances, as shown in Figure 1. The x-axis represents
time step t, and the y-axis represents ln(KL(z*, zt)) (we observe similar results using dist2(z*, zt)
or the duality gap as the measure; see Appendix A.1). Note that here we approximate z* by running
OGDA for much more iterations and taking the very last iterate. We also verify that the iterates of
OMWU converge to the same point as OGDA.
From Figure 1, we see that all curves eventually become a straight line, supporting our linear conver-
gence results. Generally, the slope of the straight line is larger fora larger learning rate η. However,
the algorithm diverges when η exceeds some value (such as 11 for the case of OMWU). Comparing
OMWU and OGDA, we see that OGDA converges faster, which is also consistent with our theory
if one compares the bounds in Theorem 3 and Theorem 8 (with the value of the constants revealed in
the proofs). We find this observation interesting, since OMWU is usually considered more favorable
for problems defined over the simplex, especially in terms of regret minimization. Our experiments
suggest that, however, in terms of last-iterate convergence, OGDA might perform even better than
OMWU.
5 Note that in this case the projection step of OGDA can be implemented efficiently in O(M ln M+N ln N)
time (Wang & Carreira-Perpinan, 2013).
9
Published as a conference paper at ICLR 2021
Acknowledgments
The authors would like to thank the anonymous reviewers for providing highly constructive com-
ments which bring about significant improvement of the result during the rebuttal phase. CL would
like to thank Yu-Guan Hsieh for many helpful discussions on error bounds and metric subregularity.
The authors are supported by NSF Awards IIS-1755781 and IIS-1943607.
References
Ahmet Alacaoglu, Olivier Fercoq, and Volkan Cevher. On the convergence of stochastic primal-dual
hybrid gradient. arXiv preprint arXiv:1911.00799, 2019.
Walss Azizian, Ioannis Mitliagkas, Simon Lacoste-JUlien, and GaUthier GideL A tight and unified
analysis of gradient-based methods for a whole spectrum of differentiable games. In International
Conference on Artificial Intelligence and Statistics, 2020.
James P Bailey and Georgios PilioUras. MUltiplicative weights Update in zero-sUm games. In Pro-
ceedings of the 2018 ACM Conference on Economics and Computation, 2018.
Michael Bowling. Convergence and no-regret in mUltiagent learning. In Advances in neural infor-
mation processing systems, pp. 209-216, 2005.
YUnmei Chen, GUanghUi Lan, and YUyUan OUyang. Accelerated schemes for a class of variational
ineqUalities. Mathematical Programming, 2017.
YUn KUen CheUng and Georgios PilioUras. Vortices instead of eqUilibria in minmax optimization:
Chaos and bUtterfly effects of online learning in zero-sUm games. In Conference on Learning
Theory, pp. 807-834, 2019.
YUn KUen CheUng and Georgios PilioUras. Chaos, extremism and optimism: VolUme analysis of
learning in games. Advances in Neural Information Processing Systems, 2020.
Chao-Kai Chiang, Tianbao Yang, Chia-JUng Lee, Mehrdad Mahdavi, Chi-Jen LU, Rong Jin, and
ShenghUo ZhU. Online optimization with gradUal variations. In Conference on Learning Theory,
pp. 6-1, 2012.
Shisheng CUi and Uday V Shanbhag. On the analysis of reflected gradient and splitting methods for
monotone stochastic variational ineqUality problems. In 2016 IEEE 55th Conference on Decision
and Control (CDC), 2016.
Constantinos Daskalakis and Ioannis Panageas. The limit points of (optimistic) gradient descent in
min-max optimization. In Advances in Neural Information Processing Systems, pp. 9236-9246,
2018.
Constantinos Daskalakis and Ioannis Panageas. Last-iterate convergence: Zero-sUm games and con-
strained min-max optimization. Smooth Games Optimization and Machine Learning Workshop
(NeurIPS 2019), 2019a.
Constantinos Daskalakis and Ioannis Panageas. Last-iterate convergence: Zero-sUm games and
constrained min-max optimization. Innovations in Theoretical Computer Science, 2019b.
Constantinos Daskalakis, Alan DeckelbaUm, Anthony Kim, et al. Near-optimal no-regret algorithms
for zero-sUm games. Games and Economic Behavior, 2015.
Constantinos Daskalakis, Andrew Ilyas, Vasilis Syrgkanis, and Haoyang Zeng. Training gans with
optimism. In International Conference on Learning Representations, 2018.
Damek Davis. LectUre 5, mathematical programming I, 2016a. Available at people.orie.
cornell.edu/dsd95/teaching/orie6300/lec05.pdf.
Damek Davis. LectUre 6, mathematical programming I, 2016b. Available at people.orie.
cornell.edu/dsd95/teaching/orie6300/lec06.pdf.
10
Published as a conference paper at ICLR 2021
Yoav Freund and Robert E Schapire. Adaptive game playing using multiplicative weights. Games
and Economic Behavior, 29(1-2):79-103, 1999.
GaUthier GideL Hugo Berard, Gaetan Vignoud, Pascal Vincent, and Simon Lacoste-JUlien. A vari-
ational inequality perspective on generative adversarial networks. International Conference on
Learning Representations, 2019.
Andrew Gilpin, Javier Pefia, and TUomas Sandholm. First-order algorithm with o (ln (1/e)) Conver-
gence for e-equilibrium in two-person zero-sum games. In AAAI, 2008.
Noah Golowich, Sarath Pattathil, and Constantinos Daskalakis. Tight last-iterate convergence rates
for no-regret learning in multi-player games. Advances in Neural Information Processing Systems,
2020a.
Noah Golowich, Sarath Pattathil, Constantinos Daskalakis, and Asuman Ozdaglar. Last iterate is
slower than averaged iterate in smooth convex-concave saddle point problems. Conference on
Learning Theory, 2020b.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural infor-
mation processing systems, 2014.
Patrick T Harker and Jong-Shi Pang. Finite-dimensional variational inequality and nonlinear com-
plementarity problems: a survey of theory, algorithms and applications. Mathematical program-
ming, 1990.
Yu-Guan Hsieh, Franck Iutzeler, Jerome Malick, and Panayotis Mertikopoulos. On the convergence
of single-call stochastic extra-gradient methods. In Advances in Neural Information Processing
Systems, 2019.
Yu-Guan Hsieh, Franck Iutzeler, Jerome Malick, and Panayotis Mertikopoulos. Explore aggres-
sively, update conservatively: Stochastic extragradient methods with variable stepsize scaling.
Advances in Neural Information Processing Systems, 2020.
AIfredO N Iusem, Alejandro Jofre, Roberto Imbuzeiro Oliveira, and Philip Thompson. Extragra-
dient method with variance reduction for stochastic variational inequalities. SIAM Journal on
Optimization, 2017.
G. M. Korpelevich. The extragradient method for finding saddle points and other problems. 1976.
Alexander Y Kruger. Error bounds and metric subregularity. Optimization, 2015.
TOrbjOm Larsson and Michael Patriksson. A class of gap functions for variational inequalities.
Mathematical Programming, 1994.
Puya Latafat, Nikolaos M Freris, and Panagiotis Patrinos. A new randomized block-coordinate
primal-dual proximal algorithm for distributed optimization. IEEE Transactions on Automatic
Control, 2019.
Qi Lei, Sai Ganesh Nagarajan, Ioannis Panageas, and Xiao Wang. Last iterate convergence in no-
regret learning: constrained min-max optimization for convex-concave landscapes. The 24nd
International Conference on Artificial Intelligence and Statistics, 2021.
D Leventhal. Metric subregularity and the proximal point method. Journal of Mathematical Analysis
and Applications, 2009.
Jingwei Liang, Jalal Fadili, and Gabriel Peyre. Convergence rates with inexact non-expansive oper-
ators. Mathematical Programming, 2016.
Tengyuan Liang and James Stokes. Interaction matters: A note on non-asymptotic local conver-
gence of generative adversarial networks. In The 22nd International Conference on Artificial
Intelligence and Statistics, 2019.
Tianyi Lin, Chi Jin, Michael Jordan, et al. Near-optimal algorithms for minimax optimization.
Conference on Learning Theory, 2020.
11
Published as a conference paper at ICLR 2021
Zhi-Quan Luo and Paul Tseng. Error bounds and convergence analysis of feasible descent methods:
a general approach. Annals of Operations Research, 1993.
Yu Malitsky. Projected reflected gradient methods for monotone variational inequalities. SIAM
Journal on Optimization, 2015.
Yura Malitsky. Golden ratio algorithms for variational inequalities. Mathematical Programming,
2019.
Yura Malitsky and Matthew K Tam. A forward-backward splitting method for monotone inclusions
without cocoercivity. SIAM Journal on Optimization.
Panayotis Mertikopoulos, Christos Papadimitriou, and Georgios Piliouras. Cycles in adversarial
regularized learning. In Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on
Discrete Algorithms, 2018.
Panayotis Mertikopoulos, Houssam Zenati, Bruno Lecouat, Chuan-Sheng Foo, Vijay Chan-
drasekhar, and Georgios Piliouras. Optimistic mirror descent in saddle-point problems: Going
the extra (gradient) mile. In International Conference on Learning Representations, 2019.
Aryan Mokhtari, Asuman Ozdaglar, and Sarath Pattathil. Convergence rate of O(1/k) for optimistic
gradient and extra-gradient methods in smooth convex-concave saddle point problems. SIAM
Journal on Optimization, 30(4):3230-3251, 2020a.
Aryan Mokhtari, Asuman Ozdaglar, and Sarath Pattathil. A unified analysis of extra-gradient and
optimistic gradient methods for saddle point problems: Proximal point approach. The 22nd Inter-
national Conference on Artificial Intelligence and Statistics, 2020b.
John von Neumann. Zur theorie der gesellschaftsspiele. Mathematische annalen, 1928.
Jong-Shi Pang. Error bounds in mathematical programming. Mathematical Programming, 1997.
Leonid Denisovich Popov. A modification of the arrow-hurwicz method for search of saddle points.
Mathematical notes of the Academy of Sciences of the USSR, 1980.
Sasha Rakhlin and Karthik Sridharan. Optimization, learning, and games with predictable se-
quences. In Advances in Neural Information Processing Systems, pp. 3066-3074, 2013.
Michael V Solodov and Paul Tseng. Some methods based on the d-gap function for solving mono-
tone variational inequalities. Computational optimization and applications, 2000.
Vasilis Syrgkanis, Alekh Agarwal, Haipeng Luo, and Robert E Schapire. Fast convergence of regu-
larized learning in games. In Advances in Neural Information Processing Systems, 2015.
Paul Tseng. On linear convergence of iterative methods for the variational inequality problem. 1995.
Weiran Wang and MigUel A Carreira-Perpinan. Projection onto the probability simplex: An efficient
algorithm with a simple proof, and an application. arXiv preprint arXiv:1309.1541, 2013.
JUnyU Zhang, Mingyi Hong, and ShUzhong Zhang. On lower iteration complexity boUnds for the
saddle point problems. arXiv preprint arXiv:1912.07481, 2019.
12
Published as a conference paper at ICLR 2021
A More Experiment Results
A.1 More empirical results for Matrix Games
Here, we provide more plots for the same matrix game experiment described in Section 6. Specif-
ically, the left plot in Figure 2 shows the convergence with respect to ln ∣∣zt - z*k, while the
right plot shows the convergence with respect to the logarithm of the duality gap ln(αf (zt)) =
ln maxj(G>xt)j - mini(Gyt)i . One can see that the plots are very similar to those in Figure 1.
0
-5
-10
⅞-15
∣-20
-25
-30
-35
1	2	3	4	5	6
x105
0
-5
-10
〜15
X-20
-25
-30
-35
-40
1	2	3	4	5	6
x105
Figure 2: Experiments of OGDA and OMWU with different learning rates on a matrix game
f(x, y) = x>Gy, where we generate G ∈ R32×32 with each entry Gij drawn uniformly at random
from [-1,1] and then rescale G's operator norm to 1. “OGDA/OMwU-eta=n"represents the curve
of OGDA/OMWU with learning rate η. The configuration order in the legend is consistent with the
order of the curves. For OMwU, η ≥ 11 makes the algorithm diverge. The plot confirms the linear
convergence of OMwU and OGDA, although OGDA is generally observed to converge faster than
OMwU.
A.2 Matrix Game on Curved Regions
Next, we conduct experiments on a bilinear game similar to the one constructed in the proof of
Theorem 9. Specifically, the bilinear game is defined by
f(x, y) = X2 yι - x1y2,	X = Y，{(a,b), 0 ≤ a ≤ 2,0 ≤ b ≤ *,an ≤ b}.
For any positive integer n, the equilibrium point of this game is (0, 0) for both x and y. Note that in
Theorem 9, We prove that OGDA only converges at a rate no better than Ω(1∕t2) in this game when
n=2.
Figure 3 shows the empirical results for various values of n. In this figure, We plot ∣∣zt - z*∣
versus time step t in log-log scale. Note that in a log-log plot, a straight line with slope s implies a
convergence rate of order O(ts), that is, a sublinear convergence rate. It is clear from Figure 3 that
OGDA indeed converges sublinearly for all n, supporting our Theorem 9.
A.3 Strongly-convex-strongly-concave Games
In this section, we use the same experiment setup for strongly-convex-strongly-concave games in
(Lei et al., 2021), where
f(x, y) = x21 - y12 + 2x1y1, and X = Y , {(a, b), 0 ≤ a, b ≤ 1, a + b = 1}.
The equilibrium point is (0,1) for both X and y. In Figure 4, we present the log plot of ∣zt-z* ∣ ver-
sus time step t and compare OGDA with OMwU using different learning rates as in Appendix A.1.
The straight line of OGDA implies that OGDA algorithm converges exponentially fast, supporting
Theorem 6 and Theorem 8. Also note that here, OGDA outperforms OMwU, which is different
from the empirical results shown in (Lei et al., 2021). we hypothesize that this is because they use
a different version of OGDA.
13
Published as a conference paper at ICLR 2021
Figure 3: Experiments of OGDA on matrix games with curved regions where f (x, y) = x2y1 -
x1y2, X = Y，{(a, b), 0 ≤ a ≤ 2,0 ≤ b ≤ 击,an ≤ b}, and n = 2, 4, 6, 8. This figure is
a log-log plot of ∣∣zt - z*k versus t, and it indicates sublinear convergence rates of OGDA in all
these games.
(=*ZlaZ=)uɪ
Figure 4: Experiments on a strongly-convex-strongly-concave game where f(x, y) = x21 - y12 +
2xιyι and X = Y，{(a, b), 0 ≤ a, b ≤ 1, a + b = 1}. The figure is showing ln ∣∣zt - /"versus
the time step t. The result shows that OGDA enjoys linear convergence and outperforms OMWU
in this case.
14
Published as a conference paper at ICLR 2021
Figure 5: Experiments of OGDA on a set of games satisfying SP-MS with β > 0, where f (x, y) =
x21n - x1y1 - y12n for some integer n ≥ 2 and X = Y , {(a, b), 0 ≤ a, b ≤ 1, a + b = 1}. The
result shows that OGDA converges to the Nash equilibrium with sublinear rates in these instances.
A.4 AN EXAMPLE WITH β > 0 FOR SP-MS
We also consider the toy example in Theorem 7, where f(x, y) = x21n -x1y1 -y12n for some integer
n ≥ 2 and X = Y , {(a, b), 0 ≤ a, b ≤ 1, a + b = 1}. The equilibrium point is (0, 1) for both x
and y. We prove in Theorem 7 that SP-MS does not hold for β = 0 but does hold for β = 2n - 2.
The point-wise convergence result is shown in Figure 5, which is again a log-log plot of ∣∣zt - z*k
versus time step t. One can observe that the convergence rate of OGDA is sublinear, supporting our
theory again.
A.5 Matrix Games with Multiple Nash Equilibria
Finally, we provide empirical results for OGDA and OMWU in matrix games with multiple Nash
equilibria, even though theoretically we only prove linear convergence results for OMWU assuming
that the Nash equilibrium is unique. We consider the following game matrix
The value of G is 0. To verify this,
maxy∈∆5 x0>Gy = minx∈∆5 x>Gy0
equilibria.
G
0	-1	1	0	0
1	0	-1	0	0
-1	1	0	0 2	0
-1	1	0		-1 2
-1	1	0	-1	
consider x0		=	y0 =	[3
3	1 0 0]. Then we have for
0. Direct calculation gives the following set of Nash
X* = {xo},
Y * = y ∈ δ5 : yι = y = y3;
2 y5 ≤ y4 ≤ 2y5 ∖.
Figure 6 shows the point-wise convergence result. ∏z* (zt) is the projection of Zt on the set of
Nash qquilibria. One can observe from the plots that both OGDA and OMWU achieve linear
convergence rate in this example. We thus conjecture that the uniqueness assumption for Theorem 3
can be further relaxed.
15
Published as a conference paper at ICLR 2021
…OMWU-eta=0.1
…OMWU-eta=0.2
OMWU-eta=0.5
…OMWU-eta=1
OGDAreta=0.125
OGDAreta=0.25
-OGDA-eta=0.5
5 0 5 0 5 0
--1-1-2-2∙3
(0s^.z=)7x
…OMWU-eta=0.1
…OMWU-eta=0.2
OMWU-eta=0.5
…OMWU-eta=1
OGDAreta=0.125
OGDAreta=0.25
-OGDA-eta=0.5
2500 3000 3500	4000 4500 5000
--OMWU-eta=0.l
--OMWU-eta=0.2
OMWU-eta=0.5
--OMWU-eta=l
OGDA-eta=0.125
OGDA-eta=0.25
-OGDA-eta=0.5
2500 3000	3500 4000 4500	5000
Figure 6: Experiments of OGDA and OMWU with different learning rates on a matrix game with
multiple Nash equilibria. "OGDA/OMWU-eta=n" represents the curve of OGDA/OMWU with
learning rate η. We observe from these plots that both OGDA and OMWU enjoy a linear con-
vergence rate, even though we are only able to show the linear convergence of OMWU under the
uniqueness assumption.
16
Published as a conference paper at ICLR 2021
B	Lemmas for Optimistic Mirror Descent
We prove Lemma 1 in this section. To do so, we use the following two lemmas.
Lemma 10. Let A be a convex set and u0 = argminu0∈A {hu0, gi + Dψ (u0, u)}. Then for any
u* ∈ A,
(u0 - u*,g ≤ Dψ(u*, U)- Dψ(u*,u0) - Dψ(u0,u).	(10)
Proof. Since Dψ (u0, U) = ψ(u0) - ψ(u) - (Vψ(u), U — ui, by the first-order optimality condition
of u0, we have
(g + Vψ(u0) — Vψ(u))> (u* — u0) ≥ 0.
On the other hand, notice that the right-hand side of Eq. (10) is
ψ(u* ) - ψ(u) - hVψ(u), u* - ui
-	ψ(u*) + ψ(u0) + hVψ(u0), u* - u0i
-	ψ(u0) + ψ(u) + hVψ(u), u0 - ui
= hVψ(u0) - Vψ(u), u* - u0i.
Therefore, Eq. (10) is equivalent to hg + Vψ(u0) - Vψ(u), u* - u0i ≥ 0, which we have already
shown above.	□
Lemma 11. Suppose that ψ satisfies Dψ (x, x0) ≥ 1 ∣∣x - x0kp for some P ≥ 1, and let u, uι, u2 ∈
A (a convex set) be related by the following:
u1 = argmin {hu0, g1i + Dψ(u0, u)} ,
u0∈A
u2 = argmin {hu0, g2 i + Dψ(u0, u)} .
u0∈A
Then we have
∣u1 - u2∣p ≤ ∣g1 - g2∣q,
where q ≥ 1 and P + 1 = 1.
Proof. By the first-order optimality conditions of u1 and u2, we have
hVψ(u1) - Vψ(u) + g1,u2 - u1i ≥ 0,
hVψ(u2) - Vψ(u) + g2,u1 - u2i ≥ 0.
Summing them up and rearranging the terms, we get
hu2 - u1,g1 -g2i ≥ hVψ(u1) - Vψ(u2), u1 - u2i.	(11)
By the condition on ψ, We have (Vψ(uι),uι - u2i ≥ ψ(uι) - ψ(u2) + 2∣∣uι - u2kp and
hVψ(u2), u2 - uιi ≥ ψ(u2) - ψ(uι) + 1 ∣∣uι - u2kp. Summing them UP we get (Vψ(uι)-
Vψ(u2), u1 - u2i ≥ ∣u1 - u2 ∣2p. Combining this with Eq. (11) we get
hu2 - u1, g1 - g2i ≥ ∣u1 - u2∣2p.
Since hu - uι,gι - g* ≤ ∣∣uι - u2kp∣∣g1 - g2kq by Holder,s inequality, we further get ku -
u2kp ≤ ∣∣gι - g2kq.
Proof of Lemma 1. Considering Eq. (2), and using Lemma 10 with u = zbt, u0 = zbt+1, u* = z,
and g = ηF(zt), we get
ηF(zt)>(zbt+1 - z) ≤ Dψ(z, zbt) - Dψ(z, zbt+1) - Dψ(zbt+1, zbt).
Considering Eq. (1), and using Lemma 10 with u = zbt, u0 = zt, u* = zbt+1, and g = ηF (zt-1),
we get
ηF(zt-1)>(zt-zbt+1) ≤Dψ(zbt+1,zbt)-Dψ(zbt+1,zt) -Dψ(zt,zbt).
17
Published as a conference paper at ICLR 2021
Summing up the two inequalities above, and adding η (F(Zt) - F (Zt-1))> (Zt - ZZt+1) to both
sides, we get
ηF (Zt)>(Zt - Z)
≤Dψ(Z,ZZt)-Dψ(Z,ZZt+1) -Dψ(ZZt+1,Zt)-Dψ(Zt,ZZt)+η(F(Zt)-F(Zt-1))>(Zt-ZZt+1).
(12)
Using Lemma 11 with u = xZt, u1 = xt, u2 = xZt+1, g1 = ηVxf(Zt-1) and g2 = ηVxf(Zt), we
get Ixt - xZt+1 Ip ≤ ηIVxf(Zt-1)-Vxf(Zt)Iq. Similarly, we have Iyt - yZt+1 Ip ≤ ηIVyf(Zt)-
Vyf (ζt-ι)kq. Therefore, by Holder,s inequality, We have
η (F (Zt) - F (Zt-1))> (Zt - ZZt+1)
≤ ηIxt - xZt+1IpIVxf(Zt-1) - Vxf(Zt)Iq + ηIyt - yZt+1IpIVyf(Zt-1) - Vyf(Zt)Iq
≤ η2INχf(Zt-I)- Vχf(Zt)k2 + η2kVyf(Zt-i)- Vyf(Zt)Il2
= η2distq2(F(Zt),F(Zt-1))
≤ η2L2distp2(Zt, Zt-1)
≤ 64distp(Zt, Zt-I).
Continuing from Eq. (12), we then have
ηF (Zt)>(Zt - Z)
(by assumption)
(by our choice of η)
≤ Dψ(z, Zt) - Dψ(z, bt+ι) - Dψ(bbt+ι, Zt) - Dψ(Zt, Zt) + 64distp(Zt, Zt-I)
≤ Dψ(z, Zt) - Dψ(z, bbt+ι) - Dψ(Zt+ι, Zt) - Dψ(Zt, Zt) + 32distp(Zt, Zt) + 32distp(Zt, Zt-I)
(Iu + vI2p ≤ (IuIp + IvIp)2 ≤ 2IuI2p + 2IvIp2)
≤ Dψ(z, zt) - Dψ(z, zt+ι) - Dψ(Zt+ι, Zt) - Dψ(Zt, zt) +16Dψ(Zt, Zt) +16Dψ(Zt, Zt-I)
(by the assumption on ψ)
15	1
=Dψ(Z, Zt) - Dψ(Z, zt+ι) - Dψ (zt+ι, Zt) - 16Dψ(Zt, Zt) +16Dψ(Zt, Zt-I).
This concludes the proof.
□
C An Auxiliary Lemma on Recursive formulas
Here, We provide an auxiliary lemma that gives an explicit bound based on a particular recursive
formula. This Will be useful later for deriving the convergence rate.
Lemma 12. COnSideranon-negative sequence {Bt}t=ι,2,∙∙∙ thatsatisfiesforsomeP > 0 andq > 0,
•	Bt+1 ≤Bt -qBtp++11, ∀t≥1
•	q(1 + p)B1p ≤ 1.
Then Bt ≤ Ct-P, where c = max < Bi,(2)p
Proof. We first prove that Bt+i ≤ Bt - 2 BP+1. Notice that since Bt are all non-negative, by the
first condition, we have Bt+i ≤ Bt ≤ ∙∙∙ ≤ Bi. Using the fundamental theorem of calculus, we
have
BP+i - BP+1 = ZBBt (Ixxp+i) dx =(P +1) ZBBt Xpdx ≤ (P +1)(Bt — Bt+ι)Bp
and thus
Bt+i ≤ Bt - qBtp++ii ≤ Bt - qBtp+i + q(P + 1) (Bt - Bt+i) Btp.
18
Published as a conference paper at ICLR 2021
By rearranging, we get
Bt+1 ≤ (1 - 1 + qqB+ p)Bp ) Bt ≤ (1 一 等)Bt = Bt- qBp+1,
where the last inequality is because q(1 + p)Btp ≤ q(1 + p)B1p ≤ 1.
Below We use induction to prove Bt ≤ Ct- 1, where C = max [Bι,(京)P . This clearly holds
for t = 1. Suppose that it holds for 1,...,t. Note that the function f(Bt) = (1 一 2Bp) Bt is
increasing in	Bt	as f(Bt)	= 1 ―	q(p+1) Bp	≥ 1 ―	q(p+1) Bp	≥	0.	Therefore, we apply the
induction hypothesis and get
Bt+ι ≤ (1 一 qBp) Bt ≤ (1 一 qcpt-1) ct-p
=Ct- 1 一 qcp+1tT- 1 ≤ Ct- 1 一 Ct-I- 1	(P ≤ 22cp+1 by the definition of c)
≤ c(t + 1)-P,
where the last inequality is by the fundamental theorem of calculus:
t-1
—(1+1)-1
Z + 1XT-1 dx ≤ 11-1-P
tp	p
This completes the induction.
□
D Proofs of Lemma 2 and Theorem 3
In this section, we consider f(x, y) = x>Gy with X = ∆M and Y = ∆N being simplex and
G ∈ [—1,1]M×n. We assume that G has a unique Nash equilibrium z* = (x*, y*). The value of
the game is denoted as P = minχ∈χ maxy∈γ x>Gy = maxy∈γ minχ∈χ x>Gy = x*>Gy*.
Before proving Lemma 2 and Theorem 3, in Section D.1, we define some constants for later analysis;
in Section D.2, we state more auxiliary lemmas, which are useful when proving Lemma 2 and
Theorem 3 in Section D.3.
D.1 Some Problem-dependent Constants
First, we define a constant ξ that is determined by G.
Definition 2.
ξ , min min (Gy*)i 一 P, P 一 max (G>x*)i ∈ (0, 1].
[i∈SUPP(x*)	i∈SUPP(y*)	J
The fact ξ ≤ 1 can be shown by:
ξ≤
mini/SUPP(x* ) (Gy )i 一 P + P 一 maxi∕supp(y*) (GTX )i ≤
∣∣Gy*∣∣∞ + ∣∣G>x*∣∣∞ ≤ 1
2	一 ,
2
while the fact ξ > 0 is a direct consequence of Lemma C.3 of Mertikopoulos et al. (2018), stated
below.
Lemma 13 (Lemma C.3 of Mertikopoulos et al. (2018)). Let G ∈ RM×N be a game matrix for a
two-Player zero-SUm game with valUe P. Then there exiStS a NaSh eqUilibriUm (x*, y*) SUch that
(Gy*)i = P	∀i	∈ SUPP(x*),
(Gy*)i > P	∀i	∈/ SUPP(x*),
(G>x*)i = P	∀i	∈ SUPP(y*),
(G>x*)i < P	∀i	∈/ SUPP(y*).
19
Published as a conference paper at ICLR 2021
Below, We define V * (Z) = V * (X) × V * (Y), where
V*(X)，{x : X ∈ Δm, SUPP(X) ⊆ SUPP(X*)}
and
V* (Y) , {y : y ∈ ∆N, SUPP(y) ⊆ SUPP(y*)}.
Definition 3.
Cx ,	min max (X-X*)；Gy,	Cy，	min max X>G(y* - y)
x∈∆m\{x*}y∈v*(Y) Ilx - X*kι	y∈∆N∖{y*}x∈v*(x) ∣∣y* - ykι
Note that in the definition of Cx and Cy, the oUter minimization iS over an oPen Set, which may make
the definition Problematic aS the oPtimal valUe may not be attained. However, the following lemma
ShowS that Cx and Cy are well-defined.
Lemma 14. Cx and Cy are well-defined, and 0 < Cx, Cy ≤ 1.
Proof. We firSt Show Cx and Cy are well-defined. To SimPlify the notationS, we define x*min ,
mini∈SUPP(x*) xi* and X0 , {X : X ∈ ∆M, IX - X*I1 ≥ x*min}, and define ym* in and Y0 Similarly.
We will Show that
Cx
(X - X*)>Gy
min max ―∏---------∏——
x∈X0 y∈V*(Y) IX - X*I1
= min max
y∈Y0 x∈V* (X)
X>G(y* - y)
ky* - ykι
which are well-defined aS the oUter minimization iS now over a cloSed Set. ConSider Cx, it SUfficeS
to Show that for any X ∈ ∆M SUch that X 6= X* and IX - X* I1 < x*min, there exiStS X0 ∈ ∆M SUch
that IX0 - X* I1 = x*min and
(x — X*)>Gy (x0 — X*)>Gy
∣∣x - X*kι -	∣∣x0 - X*kι
(13)
*
In fact, We can simply choose x0 = x* + (x - x*) ∙位〈*h.We first argue that x0 is still in Δm.
For each j ∈ [K], if xj - xj* ≥ 0, we SUrely have x0j ≥ xj* + 0 ≥ 0; otherwiSe, xj* > xj ≥ 0 and
*
thus j ∈ supp(x*) and x* ≥ /丸山，which implies Xj ≥ x* Txj- x*| ∙位匕*.≥ x* - Xmin ≥ 0.
In addition, Pj x0j = Pj xj* = 1. Combining these facts, we have X0 ∈ ∆M.
Moreover, according to the definition ofX0, ∣X0-X* ∣1 = x*min holds. Also, since X* -X and X* -X0
are parallel vectors, Eq. (13) is satisfied. The arguments above show that the Cx in Definition 3 is a
well-defined real number. The case of Cy is similar.
Now we show 0 < Cx, Cy ≤ 1. The fact that Cx, Cy ≤ 1 is a direct consequence of G being
in [-1, 1]M×N. Below, we use contradiction to prove that Cy > 0. First, if Cy < 0, then there
exists y 6= y* such that X*>Gy* < X*>Gy. This contradicts with the fact that (X*, y*) is the
equilibrium.
On the other hand, if Cy = 0, then there is some y 6= y * such that
max X>G(y* - y) = 0.
x∈V* (X)
(14)
20
Published as a conference paper at ICLR 2021
Consider the point y0 = y* +1 (y-y*) (recall the definition of ξ in Definition 2 and that 0 < ξ ≤ 1),
which lies on the line segment between y* and y. Then, for any x ∈ X,
χτGy' =	X	Xi(Gy0)i + X	Xi(Gy0)i
i∈supp(x*)	i∈supp(x* )
≥ X (Xi(Gy*)i	- Xiky0	- y*∣∣ι) + X ɑ	∙ Xi(G(y -	y*))	+ “(Gy*))
i∈supp(x*)	i∈supp(x*) '	/
(using Gij ∈ [-1, -1] for the first part and y0 = y* + ∣ (y - y*) for the second)
≥ X	(Xi(Gy*)i - χi∣∣y0- y*l∣ι) + X	XiP
i ∈supp(x*)	i∈supp(x*)
(using Eq. (14) and (Gy*)i = P for all i ∈ supp(x*))
≥ X	(Xi((Gy* )i-ξ)) + X	XiP
i∈supp(x*)	i∈supp(x*)
(using y0 - y* = ∣(y - y*) and ∣∣y - y*∣∣ι ≤ 2)
≥	XiP +	XiP	(by the definition of ξ)
i∈supp(x*)	i∈supp(x*)
=ρ∙
This shows that minx∈χ xτGy0 ≥ ρ, that is, y0 = y* is also a maximin point, contradicting that
z* is unique. Therefore, Cy > 0 has to hold, and so does CX > 0 by the same argument.	□
Finally, we define the following constant that depends on G:
Definition 4.
ln(MN 八
e , min exp---------------------.
j∈ SuPP (z*)	Zj
D.2 Auxiliary Lemmas
All lemmas stated in this section is for the case f (x, y) = xτGy with Z = Am × Δn and a
unique Nash equilibrium z* = (x*, y*).
Lemma 15. For any Z ∈ Z, we have
max ʃ(Z)T(Z -Z0) ≥ G∣z* - z∣1
z0∈V*(Z)
for C = min{cχ, Cy} ∈ (0,1].
Proof. Recall that P = x*τGy* is the game value and note that
max F (z)τ (z — ZZ)= max (x — x0)τ Gy + xτ G(y0 — y) = max -XZTGy + xτ Gy0
z0∈V*(Z)	z0∈V *(Z)	z0∈V *(Z)
= max (P — x0TGy) + max (XTGy0 — P)
χ0∈V*(X)	y0∈V*(Y) '	/
= max x0>G(y* — y) + max (x — x*)τGy0	(Lemma 13)
χ0∈V*(X)	y0∈V*(Y)
≥ Cy∣∣y* - y∣ι + Cχ∣x* - x∣ι	(by Definition 3)
≥ min{Cχ,Cy}∣Z* - z∣i,
which completes the proof.	□
Lemma 16. For any Z ∈ Z, we have
KL(z*, Z)	≤ X	^^)	+ X	Zi ≤ --1——∣z*-z∣i.
i∈supp(z*) Zi	i∈supp(z*) mini∈supp(Z*)Zi
21
Published as a conference paper at ICLR 2021
Proof. Using the definition of the Kullback-Leibler divergence, we have
KL(x*, x) = ɪ2 x:ln
i
1+
i
≤
i
(Xt - Xi)2
Xi
where the first inequality is by the concavity of the ln(∙) function, and the second inequality is be-
cause ln(1 + u) ≤ u. Considering i ∈ supp(xt) and i ∈/ supp(xt) separately in the last summation,
we have
Σ
i
(Xit - Xi)2
Xi
Σ
i∈supp(x*)
(Xit - Xi)
Xi
2
+X
i∕supp(x* )
(Xi)2
Xi
Σ
i∈supp(x* )
(Xit - Xi)
Xi
2
+	Xi.
i∕supp(x* )
The case for KL(yt , y) is similar. Combining both cases finishes the proof of the first inequality
(recall that KL(zt , z) is defined as KL(xt , x) + KL(yt , y)). The second inequality is straightfor-
ward:
X	(Zr - Zi)2
zi
i∈supp(z* )
+	Zi ≤
i∈supp(z*)
-----------E星
mini∈supp(z*) Zi	i∈supp(z*)
- Zi| +	|Zi|
i∈supp(z* )
mni;^
□
Lemma 17. For η ≤ 8,OMWU guarantees 4b, ≤ zt,i ≤ 3bt,i and 3bt,i ≤ bt+ι,i ≤ 4bt,i..
Proof. This is shown directly by the update of xbt :
Xt,i exp(-η) ≤ X	= Xt,i exp(-η ∙ (Gyt)i)	≤ Xt,i exp (η)
eχp (η)	— "t+1,i — Pj bt,j exp(-η ∙ (Gyt)j) — eχp(-η) .
So by the condition on η, We have 44xt,i ≤ exp(-2η) ∙ xti ≤ Xt+ι,i ≤ exp(2η) ∙ xt,i ≤ 4xt,i. The
cases for xt, bt and yt are similar.	口
Lemma 18. For any two probability vectors u, V, if for ^very entry i, ɪ Ui ≤ Vi ≤ 3 Ui, then
3 Pi ⅛)2 ≤ KL(u, v) ≤ Pi ⅛i)2 ≤ 4.
Proof. Using the definition of the Kullback-Leibler divergence, we have
KL(u, v)=-X ui 喧 ≥-X ui (T
KL(u, V) = -X uiln Ui ≤-x ui (T
1 (Vi - ui)2 ) = 1	(Vi - ui)2
3	u2	J 3 J	Ui	,
(Vi - ui)2 ) = X (Vi - ui)2 ≤ 1
u2	)	ui	4 4
where the first inequality is because ln(1 + a) ≤ a 一 3a2 for -4 ≤ a ≤ 4, and the second inequality
is because ln(1 + a) ≥ a - a2 for - 22 ≤ a ≤ 4. The third inequality is by using the condition
|ui - Vi | ≤ 2 ui.	口
Lemma 19. For all i ∈ supp(zt) and t, OMWU guarantees Zbt,i ≥ ( is defined in Definition 4).
Proof. Using Eq. (3), we have
KL(z*, Zt) ≤ Θt ≤∙∙∙≤ Θι = 46 KL(bι, zo) + KL(z*, bi) = KL(z*, bi),	(15)
where the last equality is because £4 = zo = (IMM, 1N).
22
Published as a conference paper at ICLR 2021
Then, for any i ∈ SUPP(Z*), We have
*∣	1
Zi ln ʌ-
zbt,i
J	*	1	* -	*	*	* -	*	*
≤ 上 Zjln = KL(Z , Zt)—上 Zjln Zj ≤ KL(Z , zι)-上 Zjln Zj
j	zt,j	j	j
X Zj ln ɪ = ln(MN).
j	Zb1,j
Therefore, We conclUde for all t and i ∈ sUPP(Z*), Zbt,i satisfies
Zti ≥ exp --ln(MN)) ≥ min exp - ln(≡ = e.
t,i ≥	Pk Zj ≥ ≥ j∈supp(z*) PI Zj )
□
D.3 Proofs of Lemma 2 and Theorem 3
Proof of Lemma 2. BeloW We consider any Z0 ∈ Z such that suPP(Z0) ⊆ suPP(Z*), that is, Z0 ∈
V*(Z). Considering Eq. (1), and using the first-order oPtimality condition of Zbt+1, We have
(Vψ(bt+ι) - Vψ(bt) + ηF(zt))>(z0 - bt+ι) ≥ 0,
Where ψ(Z) = Pi Zi ln Zi. Rearranging the terms and We get
Z
nF (zt)> (bt+1 - Z0) ≤ (Vψ(bt+ι) - Vψ(bt))> (z0 - bt+ι) = X (Zi -ln -t+ii.
i	Zt,i
(16)
The left hand side of Eq. (16) is loWer bounded as
ηF (Zt)> (Zbt+1 - Z0) = ηF (Zbt+1)> (Zbt+1 - Z0) + η (F (Zt) - F (Zbt+1))> (Zbt+1 -Z0)
≥ ηF (Zbt+1)> (Zbt+1 - Z0) - ηkF (Zt) - F (Zbt+1) k∞kZbt+1 - Z0k1
≥ ηF (Zbt+1)> (Zbt+1 - Z0) - 4η kZt - Zbt+1k1
(kF (Zt) - F (Zbt+1) k∞ ≤ kZt - Zbt+1 k1 ≤ 4)
≥ nF (bt+ι)> (bt+ι - ZO) - 1 Ilzt - bt+ιkι;	⑺ ≤ 1/8)
on the other hand, the right hand side of Eq. (16) is uPPer bounded by
-——,	☆ , Y .
X (Zi - Zt+I,i)ln 4
i	Zt,i
.——,	会I 1:
X	Zi ln ɪʌ - KL(Zt+ι, Zt)
Zti
i∈supp(z*)	,
(suPP(Z0) ⊆ suPP(Z*))
≤
i∈suPP(z* )
^
ln —
Zbt,i
X max {ln(1+ Zt+1f - ",i) ,ln(l+ ",i厂 Zt+1,i
i∈suPP(z* )	t,i	t+1,i
≤ X ln(l+	l⅛1,i-11
i∈suPP(z*)	min{Zbt+1,i,Zbt,i}
≤ 4 X	|bt+1,i - bt,i|
_ 3.	, *、	Zm	.
i∈suPP(z* )
(ln(1 + a) ≤ a and Lemma 17)
Combining the bounds on the tWo sides of Eq. (16), We get
nF(Zt+1)> (Zt+ι -ZO) ≤ 3 X	-+ι;. ∙t,/+2iiZt -bt+ιkι
i∈suPP(z* )	t,i
23
Published as a conference paper at ICLR 2021
Since z0 can be chosen as any point in V * (Z), We further lower bound the left-hand side above using
Lemma 15 and get
ηCkz*—bt+ιkι ≤ 3 x	厢+ι;. %,+2kzt - bt+ιkι
i∈supp(z*)	Nt,i
41
≤ %kzt+1 — Ztki + 2kzt — Zt+ιkι,	(Lemma 19)
4
≤ 3ɪ (kzt+1 - ZtkI + kzt - zt+1kI)	(17)
where the last inequality uses ≤ 1. With the help of Eq. (17), below we prove the desired
inequalities.
Case 1.	General case.
KL(Zbt+1, Zt)+ KL(Zt, Zbt)
≥ 1 kbt+1 - Xtk2 + 2kbt+1 - ytki + 2kxt — btk2 + 2kyt - btki	(PinSker's inequality)
≥ 4kbt+ι - ztkι+ 4kzt - btk2	(a2 + b2 ≥ 2(a +b)2)
≥ 16l∣bt+ι	-	Ztk2 + 8 (kbt+ι - ztk2	+ kzt - btk2)
≥ 16 ∣∣bt+ι	-	zt k2 + A kbt+1 - btk2	(a2 + b2	≥ 1 (a +	b)2 and triangle	inequality)
≥ 32 (Ilbt+ι - ztki + kbt+ι - btkI)2	(a2 + b2 ≥ 2(a + b)2)
≥ 32 ( W) kz* - bt+ιkι	(Eq.(17))
e2η2C 2	e4∕C 2
≥ ——— X e2KL(z*, zt+i)2 = ———KL(z*, zt+i)2.	(Lemma 16 and Lemma 19)
64	64
This proves the first part of the lemma with Ci = e4C2 /64.
Case 2.	The case when max{kz* - btki, kz* - ztki} ≤ 第.
KL(zbt+i,zt)+	KL(zt,zbt)
≥
≥
1 X ( (bt+i,i - zt,i)2 + (zt,j - bt,i)2
3	bt+i,i	zt,i
4 x
i∈/ supp(z* )
(bt+i,i - zt,i)2 + (zt,i - bt,i)2
zbt,i	zbt,i
8 x
i∈/ supp(z* )
(bt+i,i- bt,i)2
bt,i
(Lemma 17 and Lemma 18)
(Lemma 17)
(18)
Below we continue to bound 工心0色*)(zt+1b-zt,"
By the assumption, we have kyt - y*ki ≤ ηξ, which by Lemma 13 and Definition 2 implies
∀i ∈ supp(x*),
∀i ∈/ supp(x*),
(Gyt)i ≤ (Gy*)i + 10ξ = P + 10ξ ≤ P + 10,
(Gyt)i ≥ (Gy*)i - 10ξ ≥ P + ξ - ηξ ≥ P + 10.
24
Published as a conference paper at ICLR 2021
We also have ∣∣bt - x*kι ≤ ¾ξ, so Pj∈supp(x*) bt,j ≤ ηξ. Then, for i ∈ SUPP(X*), We have
^
xt+1,i
Zt,i exp(一η(Gyt)i)
Pj xt,j exp(一η(Gyt))
Zt,i exp(一η(Gyt)i)
Pj∈supp(x*) bt,j eχP(一η(Gyt)j)
bt,i eχp(-η(ρ + 90))
Pj∈supp(x*) bt,j exp(一η(ρ + 1ξj))
Zt,i exp (一喘ηξ
(1- Pj∕supp(x*) Ztj)
bt,i exp (--180ηξ ≤ Z .
where the last inequality is because expS0ιUu) ≤ 1 - 0.5u for U ∈ [0,1]. Rearranging gives
lxt+ι,i - bt,il2、η2ξ2^∙	、η2ξ2
≥ 丁 xt,i ≥ ɪ
xbt,i
xbt+1,i,
where the last step uses Lemma 17. The case for ybt is similar, so we have
|zbt+1,i - zbt,i|2
zbt,i
≥ 室bt+1,i.
Combining this with Eq. (18), we get
KL(Zt+1, Zt) + KL(zt, Zt) ≥ ∖4 X	bt+1,i∙
i∈supp(z* )
(19)
Now we combine two lower bounds of KL(Zbt+1 , Zt) + KL(Zt, Zbt). Using an intermediate step in
Case 1, and Eq. (19), we get
KL(zbt+1,zt) +KL(zt,zbt)
2(KL(bt+ι, Zt) + KL(zt, Zt)) + 2 (KL(Zt+ι, Zt) + KL(zt, Zt))
e2η2C2 I，*	2 ηξ	X ʌ
128 kz - zt+ιkι + T28"	zt+ι,i
i∈supp(z*)
e3η2C2ξ2	1 …	*ll2 l 1 χ ʌ
128 I 春kzt+1 - z k1 + m E	zt+1,i
∖	i∈supp(z*)
e^C 2ξ2	1∣	z*
^^2^ I e kzt+1-z
k2 +	∑	bt+ι,i I
i/supp(z*)	)
(ξ≤ 1,C≤ 1,and≤ 1)
e3η28^KL(z*, Zt+1).
(Lemma 16 and Lemma 19)
≤
≤
≤
≥
≥
≥
This proves the second part of the lemma with C2 = e3C2ξ2∕128.
□
Now we are ready to prove Theorem 3.
Proofof Theorem 3. As argued in Section 4, with Θt = KL(z*, Zt) + 表KL(Zt, zt-ι) and Zt
KL(ZZt+1, Zt) + KL(Zt, ZZt), we have (see Eq. (3))
θt+ι ≤ θt - 15ζt∙
25
Published as a conference paper at ICLR 2021
We the proceed as,
Zt ≥ 2κL(bt+ι, Zt) + 2Zt
≥ 1 KL(bt+ι, Zt) + η-C1 KL(z*, bt+ι)2
(Lemma 2)
≥ 2KL(bt+ι, Zt)2 + η ；1 KL(z*, Zt+ι)2	(by Lemma 17 and Lemma 18)
≥ “ 2 ι (KL(Zt+1, Zt)2 + KL(Z*, bt+1)2)
(C1 = 4C2/64 ≤ 1/64 as shown in the proof of Lemma 2)
≥ 手(KL(bt+ι, Zt) + KL(z*, bt+ι))2
Therefore, θt+ι ≤ θt- 1564C1 θ2+i ≤ θt- 64+⅞MlNθ2+i. Also, recall bi = z0 = (1M, 1N)
and thus Θι = KL(z*, bi) ≤ ln(MN). Therefore, the conditions of Lemma 12 are satisfied with
P = 1 and q = 64号节骨), and We conclude that
≤
t
Where C 0	ac∕lr1(MN) -E(MN) ∖ — 128+2ln(MN)
where C = max Iln(M N ),	15η2 C = =	15η2C1	.
Next we prove the main result. Set Τ0 = 胃端夕.For t ≥ T0, we have using Pinsker's inequality,
kZ* - btk2 ≤ 2kx* - btk2 + 2ky* - btk2 ≤ 4KL(z*, bt) ≤ — ≤ n-ξ-,
T0	100
∣∣Z*-Ztk2 ≤ 2∣∣z*- bt+ιk2 + 2kbt+ι-Ztk2
≤ 4kx* - bt+ιk2 +4kbt+ι - xtk1 + 4∣∣y* - bt+ιk2 +4kbt+ι - ytk2
≤ 8KL(z*, bt+i) + 8KL(bt+1, Zt)
≤ 128Θt+i ≤
128C0	η2ξ2
T0	≤ ^1O0
Therefore, when t ≥ T0, the condition of the second part of Lemma 2 is satisfied, and we have
Zt ≥ 2KL(bt+ι, Zt) + 2Zt
≥ 1 KL(bt+i, Zt) + η-C2KL(z*, bt+i)	(by Lemma2)
≥ η C2 Θt+ι.	(C2 = e3C 2ξ2∕128 ≤ 1/128 as shown in the proof of Lemma 2)
Therefore, when t ≥ To, Θt+ι ≤ Θt - 1532C2 Θt+ι, which further leads to
Θt ≤ Θτο ∙ (1 + ⅛C2
T0-t≤-S*
T0 t ≤ ln(MN) (1 + *C2
T0 -t
where the second inequality uses Eq. (15). The inequality trivially holds for t < T0 as well, so it
holds for all t.
We finish the proof by relating KL(z*, Zt) and Θt+ι. Note that by Lemma 16, Lemma 17, and
Lemma 19, we have
KL(z*, Zt)2 ≤	忖-"≤ 16kZ* -Zf ≤ 4 ( kZ*- bt+i / kbt+i-Zt k2
mini∈supp(z*) z2,i	9e2	I	e2
26
Published as a conference paper at ICLR 2021
We continue to bound the last term as
4
∣∣z*-名+1k2 + kbt+1-ztk2
4
e2
||x* - χt+1k2 + ∣∣y* - bt+1k2 + ∣∣bt+ι - χtk2 + Ilbt+ι - ytk2
≤
e2
W- bt+ι∣2 + ∣y* - bt+ι∣2 + ∣bt+ι - g∣2 + kbt+ι - yt∣2
128 KL(n*, bt+ι)
e2
16
e2
KL(bt+1, zt)
+	16
(同2 ≤∣同1)
(Pinsker,s inequality)
4
128
≤ ^eτ θt+1∙
Combining everything, we get
____	_	Tq — t — 1
KL(Z*, zt) ≤ 卓E ≤ PWMN (1 + %)-
which completes the proof.
□
E Proofs of Lemma 4 and the Sum-of-duality-gap Bound
ProofofLemma 4. Below we consider any z' = zt+1 ∈ Z. Considering Eq. (1) with Dψ (u, v)
1 ∣∣u - v∣2, and using the first-order optimality condition of zt+ι, we have
(bt+1 - bt + ηF(zt))>(z' - zt+ι) ≥ 0,
(zt+ι - zt+1 + ηF(Nt))T(z, - zt+1) ≥ 0∙
Rearranging the terms and we get
(bt+ι - bt)τ(z' - zt+1) ≥ ηF(zt)τ(bt+ι - z')
=ηF(bt+ι)τ(bt+ι - z') + η (F(Zt)- F(bt+ι))τ (bt+ι - z')
≥ ηF(bt+1)τ(bt+1 - z') - ηL∣Zt -"修+1 - z'∣
≥ ηF(bt+ι)τ(bt+ι - z') - 1 IIZt- bt+ι∣∣bt+ι - z'k,
8
and
(zt+1 - zt+1)T(ZO - zt+1) ≥ ηF(Zt)T(Zt+1 - z')
=ηF(Zt+1)T(Zt+1 - z') + η (F(Zt) - F(Zt+I))T (zt+1 - z')
≥ ηF(zt+I)T(Zt+1 - z') - ηLkzt - zt+1∣∣∣∣zt+1 - z'l∣
≥ ηF(Zt+1)T(Zt+1 - z') - 8Ilzt - zt+1llllzt+1 - z'll∙
Here, for both block, the third step uses Holder,s inequality and the smoothness condition Assump-
tion 1, and the last step uses the condition η ≤ 1∕(8L). Upper bounding the left-hand side of the
two inequalities by Izbt+1 - zbtIIzbt+1 - z0I and Izt+1 - zbt+1IIzt+1 - z0I respectively and then
rearranging, we get
Izt+1 - z'I(Izt+1 - btI + 1∣Zt - bt+1∣∣) ≥ ηF(bt+1)τ(bt+1 - z'),
llzt+1 - z'll 6zt+1 - zt+111 + 8∣∣zt - zt+1∣∣) ≥ ηF(zt+I)T(Zt+1 - z').
Therefore, we have
12
IIbt+ι-btk + 8∣zt-bt+ιk) ≥
η2[F (bt+ι)>(bt+ι-z0)]+
12
llzt+ι - zt+ι∣ + 8Ilzt - zt+ι∣∣) ≥
∣bt+ι-z0k2	,
η2[F(zt+ι)>(zt+ι - z')]+
kzt+ι-z0k2
27
Published as a conference paper at ICLR 2021
Finally, by the triangle inequality and the fact (a + b)2 ≤ 2a2 + 2b2, we have
12
Ilbt+ι - bt Il + 8 IIzt - zt+ι∣l)
12
Ilbt+ι - zt+ιk + 8IIzt - zt+ιk)
≤ (nzt- ztii + 8 ιιzt-2+川)
≤ (8Ilzt - bM + 8Ilzt - bt+dl)
≤ 32 (Hzt - zt— + Ilzt - bt+i『),
≤ (8llzt+ι - bt+dl + Ilzt - zt+ill)
9	92
≤(8llzt+i - zt+ill + 8Ilzt - zt+ι∣∣)
≤ 32 (lzt+ι - zt+ill2 + Ilzt - zt+ill2),
which finishes the proof.
□
Next, we use Eq. (4) and Eq. (6) to derive a result on the convergence of “average duality gap”
across time. First, we use the following lemma to relate the right-hand side of Eq. (6) to the duality
gap of zt.
Lemma 20. Let Z be closed and bounded. Then for any z ∈ Z, we have αf (z) ≤
maxz0∈Z F (z)>(z - z0).
Proof. This is a direct consequence of the convexity of f (∙, y) and the concavity of f (x, ∙):
αf (z) =	max	(f(x, y0) -f(x,y)+f(x,y) - f(x0, y))
(x0,y0)∈X ×Y
≤ 一 max -(Vyf(Xy)>(y0-y) + Vxf(Xy)>(x-XO)) = maxF(Z)>(Z-ZO).
(x0,y0)∈X ×Y	z0∈Z
□
With Lemma 20, the following theorem can be proven straightforwardly.
Theorem 21.	Let Z be closed and bounded. Then OGDA with η ≤ 笠 ensures T PT=i αf(zt)
O (η√T)for any T, Where D , suPζR∈ζ l∣z — z0l.
Proof. We first bound the sum of squared duality gap as (recall ζt = Izbt+i - ztI2 + Izt - zbtI2):
T
T
αf(zt)2 ≤	m0 axF (zt)>(zt -
t=i	t=i z ∈Z
zO I2
81
≤——K
3 32η2
T
t=i
- Θt +Θt - Θt+i)
(Lemma 20)
(Lemma 4)
(Eq. (4))
(telescoping)
Finally, by Cauchy-Schwarz inequality, we get T PT=i αf(zt)
O (η√⅛).
≤ T JT PLi αf(zt)2 =
□
28
Published as a conference paper at ICLR 2021
This theorem indicates that αf(zj is converging to zero. A rate of af (zt) = O(η√) would be
compatible with the theorem, but is not directly implied by it. In a recent work, Golowich et al.
(2020b) consider the unconstrained setting and show that the extra-gradient algorithm obtains the
rate af (zt) = O(η√), under an extra assumption that the Hessian of f is also LiPschitz (since
Golowich et al. (2020b) study the unconstrained setting, their duality gap αf is defined only with
respect to the best responses that lie within a ball of radius D centered around the equilibrium). Note
that the extra-gradient algorithm requires more cooperation between the two players compared to
OGDA and is less suitable for a repeated game setting.
F The Equivalence between SP-MS and Metric Subregularity
In this section, we formally that show our SP-MS condition with β = 0 is equivalent to metric
subregularity. Before introducing the main theorem, We introduce several definitions. We let Z* ⊆
Z ⊆ RK (Z* and Z follow the same definitions as in our main text). First, we define the element-
to-set distance function d:
Definition 5. The element-to-set distance function d: RK × 2RK → R is defined as d(z, S) =
inf z0∈S kz - z0k.
The definition of metric subregularity involves a set-valued operator T : Z → 2RK , which maps an
element of Z to a set in RK .
Definition 6. A set-valued operator T is called metric subregular at (z, V) for V ∈ T(Z) if there
exists κ > 0 and a neighborhood Ω of Z such that
d(V, T(z)) ≥ κd(z, T-1 (V))
for all z ∈ Ω, where X ∈ TT(V) ⇔ V ∈ T(x). If Ω = Z, we call T globally metric subregular.
The following definition of normal cone is also required in the analysis:
Definition 7. The normal cone of Z at point Z is N (Z) = {g | g> (Z0 - Z) ≤ 0, ∀Z0 ∈ Z} (we
omit its dependence on Z for simplicity). Equivalently, N(Z) is the polar cone of the convex set
Z - Z (a property that we will use in the proof).
Now we are ready to show that our SP-MS condition with β = 0 is equivalent to metric subregularity
of the operator N + F, defined via: (N + F)(Z) = {g + F (Z) | g ∈ N (Z)}.
Theorem 22.	Let z* ∈ Z* . Then the following two statements are equivalent:
•	(N + F ) is globally metric subregular at (Z* , 0) with κ > 0;
•	For all Z ∈ Z\Z*, maxzθ∈z F(z)> (Z-Z∕∣∣ ≥ κd(z, Z*).
Proof. Let T = N + F . Notice that
Z∈Z* ⇔ F (z)>(Z0 - Z) ≥0 ⇔ - F(Z) ∈N(Z) ⇔ 0∈ (N+F)(Z).
Therefore, 0 ∈ T (Z*) indeed holds, and we have T-1(0) = Z*. This means that the first statement
in the theorem is equivalent to
d(0, T (Z)) ≥ κd(Z,T-1(0)) ⇔ d(0, N (Z) +F(Z)) ≥ κd(Z,Z*).
This inequality holds trivially when Z ∈ Z* . Thus, to complete the proof, it suffices to prove that
d(0,N(Z) + F(Z)) = maxzθ∈z F(z)> ∣∣Z-Z0∣∣ for Z ∈ Z\Z*. To do so, note that
kz-z k
d(0,N(Z)+F(Z))
= d(-F (Z), N (Z))
= k - F(Z) - ΠN ∣z∣(-F (Z))k
=I∣πn o(z)(-F(Z))k
29
Published as a conference paper at ICLR 2021
where N°(z) = {g | g>n ≤ 0, ∀n ∈ N(z)} is the polar cone of N(Z) and the last step is by
Moreau’s theorem. Now consider the projection of -F (z) onto the polar cone N ◦(z):
ΠN ◦(z)(-F (z)) = argmin k -F(z) -yk2
y∈N ◦(z)
=argmin {2F(z)>y + ∣∣y∣∣2}
y∈N ◦(z)
=argmin [2F(Z)Tɪ ∙ ∣∣y∣∣ 十 ||y『]
y∈N ◦(z)	kyk
= argmin	{2λF(z)>Z + λ2},
λ≥0, z∈No(z), kzk = ι
where the last equality is because N°(z) is a cone. Next, we find the Z* and λ* that re-
alize the last argmin operator: notice that the objective is increasing in F(z)>Z, so Z* =
argmi□z∈N。⑶：]团=]{F(z)>z}, and thus λ* = -F(z)>Z* when F(z)>Z* ≤ 0 and λ* = 0
otherwise. Therefore,
kπN ◦ (z)(-F (z))k = λ*=max[0, max	-f (z)>z]∙
I z∈N °(z),kzk = l	J
Note that N(Z) is the polar cone of the conic hull of Z - z. Therefore, N◦ (Z) = (ConicHull(Z -
Z)Y- = ConicHull(Z - Z) and
max 00,	max	-F(z)>z] = max(0, max F(z)>(z——z-ɪ
I , z∈N°(z),kzk = i	( ) J	I , z0∈Z ( ) kz0 - ZIl
Finally, note that when Z ∈ Z\Z*, We have maxzo∈z F(z)>(z - z0) > 0. Combining all the facts
above, We have shown d(0, N(Z) + F(Z)) = maxz，∈z F(z)> (：二4.	□
G	Proof of Theorem 5
Proof of Theorem 5. Let ρ = minx∈X maxy∈Y x>Gy = maxy∈Y minx∈X x>Gy be the game
value. In this proof, we prove that there exists some c > 0 such that
maxx>Gy0 — P ≥ Ckx — Πχ*(x)k	(20)
y0∈Y
for all x ∈ X . Similarly we prove
maxP- x0>Gy ≥ cky -ΠY*(y)k
x0∈X
for all y ∈ Y. Assume that the diameter of the polytope is D < ∞. Then combining the two proves
max -(Z)—(—~^)- ≥ — max F(z)>(z — z0) = — (max x>Gy0 — min x0>Gy∖
Za IlZ-Z0k	≥ D z0	( ) (	) D∖yl y χ0 yj
cc
≥ D (ky - ∏y*(y)k + kx - ∏χ*(χ)k) ≥ D∣z - ∏z* (z)k,
meaning that SP-MS holds with β = 0. We break the proof into following several claims.
Claim 1.	If X, Y are polytopes, then X* and Y* are also polytopes.
ProofofClaim 1. Note that X* = {x ∈ X : maxy∈γ x>Gy ≤ ρ}. Since Y is a polytope,
the maximum is attained at vertices of Y. Therefore, X * can be equivalently written as
x ∈ X : maxy∈V(Y) x>Gy ≤ P , where V(Y) is the set of vertices ofY. Since the constraints of
X * are all linear constraints, X* is a polytope.	□
With Claim 1, we without loss of generality write X* as
X*	= x ∈ RM :	ai>x	≤	bi,	for i = 1, . . . , L,	ci>x	≤	di,	for i = 1, . . . , K}	,
30
Published as a conference paper at ICLR 2021
where the ai>x ≤ bi constraints come from x ∈ X and the ci>x ≤ di constraints come from
maxy∈V(Y) x>Gy ≤ ρ. Below, we refer to ai>x ≤ bi as the feasibility constraints, and ci>x ≤ di
as the optimality constraints. In fact, one can identify the i-th optimality constraint as ci = Gy(i)
and di = ρ, where y(i) is the i-th vertex of Y. This is based on our construction of X* in the proof
of Claim 1. Therefore, K = |V(Y)|.
Since Eq. (20) clearly holds for X ∈ X*, below, we focus on an X ∈ X\X*, and let x*，Πχ* (x).
We say a constraint is tight at x* if ai>x* = bi or ci>x* = di . Below we assume that there are `
tight feasibility constraints at and k tight optimality constraints at X*. Without loss of generality, we
assume these tight constraints correspond to i = 1, . . . , ` and i = 1, . . . , k respectively. That is,
ai>X* = bi ,	for i = 1, . . . , `,
ci>X* = di,	for i = 1, . . . , k.
Claim 2. X violates at least one of the tight optimality constraint at X*.
Proof of Claim 2. We prove this by contradiction. Suppose that X satisfies all k tight optimality
constraints at X*. Then X must violates some of the remaining K - k optimality constraints (oth-
erwise X ∈ X*). Assume that it violates constraints K - n + 1, . . . , K for some 1 ≤ n ≤ K - k.
Thus, we have the following:
ci> X ≤ di for i = 1, . . . K - n;
ci> X > di for i = K - n + 1, . . . , K.
Recall that ci>X* ≤ di for i = 1, . . . , K - n and ci>X* < di for all i = K - n + 1, . . . , K. Thus,
there exists some X0 that lies strictly between X and X* that makes all constraints hold (notice that
x and x* both satisfy all feasibility constraints), which contradicts with Πχ* (x) = x*.	□
Claim 3. maxy0∈γ (x>Gy0 - P) ≥ maxi∈{i,…,k} c>(x - x*).
Proof of Claim 3. Recall that we identify ci with Gy(i) and di = ρ. Therefore,
max (x>Gy0 - ρ)= max	ci>x -	di	≥ max	ci>x -	di	= max	ci> (x	- x*),
y0∈Y	i∈{1,...,|V(Y)|}	i	i	i∈{1,...,k}	i	i	i∈{1,...,k} i
where the last equality is because c>x* = di for i = 1,...,k.	□
Recall from linear programming literature Davis (2016a;b) that the normal cone of X * at x* is
expressed as follows:
⅛k
pi ai + X qi ci :
i=1
pi ≥ 0,	qi ≥ 0 .
The normal cone of X* at x* consists of all outgoing normal vectors of X* originated from x*.
Clearly, x - x* belongs to Nx* . However, besides the fact that x - x* is a normal vector of X*,
we also have the additional constraints that x ∈ X. We claim that in our case, x - x* lies in the
following smaller cone (which is a subset of Nx* ):
Claim 4. x - x* belongs to
(`k	`k
pi ai +	qi ci	: pi ≥	0,	qi	≥ 0,	aj>	pi ai	+	qi ci
i=1	i=1	i=1	i=1
≤ 0, ∀j = 1, . . . , ` .
Proof of Claim 4. As argued above, x - x* ∈ Nx* , and thus x - x* can be expressed as
P'=ι Piai + Pk=I qiCi with Pi ≥ 0, qi ≥ 0. To prove that X - x* ∈ Mχ*, we only need to
prove that it satisfies the additional constraints, that is,
ai> (x - x* ) ≤ 0, ∀i = 1, . . . , `.
31
Published as a conference paper at ICLR 2021
This is shown by noticing that for all i = 1, . . . , `,
a>(X - x*) = (a>x* - bi) + a>(x - x*)
=a> (x* + x — x*) — bi
= ai> x - bi ≤ 0.
(the i-th constraint is tight at x*)
(x ∈ X)
□
Claim 5. x - x* can be written as P'=ι Piai + Pk=I qici With 0 ≤ pi, qi ≤ C0∣∣x - x*k for all
i and some problem-dependent constant C0 < ∞.
*
ProofofClaim 5. Notice that ∣∣χ-χ*k ∈ Mχ* (because 0 = X - x* ∈ Mχ* and Mχ* is a cone).
Furthermore,	kχ-χ*k	∈	{v	∈ RM : ∣∣v∣∣∞ ≤	1}.	Therefore, kχ-χ*k ∈ Mx*	∩ {v ∈	RM	:
kvk∞ ≤ 1}, which is a bounded subset of the cone Mx* .
Below we argue that there exists a large enough C0 > 0 such that
(xχ
i=1
k
pi ai +
i=1
qici : 0 ≤ pi , qi ≤ C0 , ∀i
Mx* ∩{v∈RM : kvk∞ ≤ 1}
P.
)
⊇
To see this, first note that P is a polytope. For every vertex vb of P, the smallest C0 such that vb
belongs to the left-hand side is the solution of the following linear programming:
`k
min0	Cvb0	s.t.	vb =	piai	+	qici,	0 ≤	pi, qi	≤	Cvb0 .
pi ,qi ,Cvb	i=1	i=1
Since vb ∈ Mx* , this linear programming is always feasible and admits a finite solution Cvb0 <
∞. Now let C0 = maxvb∈V(P) Cvb0 , where V(P) is the set of all vertices of P. Then since any
v ∈ P can be expressed as a convex combination of points in V(P), v can be also be expressed as
P'=1 Piai + Pk=I qiCi With 0 ≤ Pi, qi ≤ C0.
To sum up, ∣∣χ-χ*k can be represented as P'=ι Pi a% + Pk=I qiC with 0 ≤ pi,qi ≤ C0. This further
implies that X - x* can be represented as P'=ι Piai + Pk=I qe with 0 ≤ pi,qi ≤ C0kx - x* k.
Notice that C0 only depends on the set of tight constraints at x*.	□
Finally, we are ready to combine all previous claims and prove the desired inequality.
Define Ai，a>(x - x*) and Ci，c>(x - x*). By Claim 5, we can write X - x* as P'=ι Piai +
Pik=1 qici with 0 ≤ Pi, qi ≤ C0kx - x*k, and thus,
`	k	`	k>
X	PiAi	+X	qi Ci	= X	Pi ai	+ X	qici	(x - x*) = kx -	x*k2.
i=1	i=1	i=1	i=1
On the other hand, since x - x* ∈ Mx* by Claim 4, we have
``
X PiAi = X Piai>(x - x*) ≤ 0
i=1	i=1
and
X	qiCi	≤ max	CiX	qi	≤ max	Ci	kC0kx -	x*k,
i∈{1,...,k}	i∈{1,...,k}
i=1	i=1
where in the first inequality we use the fact Pi ≥ 0, and in the second inequality we use the fact
maxi∈{1,...,k} Ci > 0 (by Claim 2) and 0 ≤ qi ≤ C0kx - x* k.
32
Published as a conference paper at ICLR 2021
Combining the three inequalities above, we get
max	Ci
i∈{1,...,k}
≥ 9kx-x*k∙
Then by Claim 3,
max (x>Gy0 - P) ≥
y0∈Y
maχ	Ci ≥ kCkx - x*k.
i∈{1,...,k}	kC
Note that k and C0 only depend on the set of tight constraints at the projection point x*, and there
are only finitely many different sets of tight constraints. Therefore, we conclude that there exists
a constant c > 0 such that maxy0∈Y (x>Gy0 - P) ≥ Ckx - x*k holds for all X and x*, which
completes the proof.	□
H Proof of Theorem 6 and Theorem 7
Proof of Theorem 6. Suppose that f is γ-strongly-convex in x and γ-strongly-concave in y, and let
(x*, y*) ∈ Z*. Then for any (x, y) we have
f(x,y) - f(x*,y) ≤ Vχf(x,y)>(x - x*) - 2kx - x*k2,
f(x,y*) - f(x,y) ≤ Vyf(x,y)>(y* - y) - γky - y*k2.
Summing up the two inequalities, and noticing that f(x, y*) -f(x*, y) ≥ 0 for any (x*, y*) ∈ Z*,
we get
F(z)>(z-z*) ≥ 2kz-z*k2,
and therefore, for z ∈ Z*,
F⅞⅛2 ≥ Ykz-z*k,
kz -z*k	2
which implies SP-MS with β = 0 and C = γ∕2.
□
Proofof Theorem 7. First, We show that f has a unique Nash Equilibrium z* = (x*, y*)=
((0, 1), (0, 1)). As f is a strictly monotone decreasing function with respect to y1, we must have
y1* = 0 and y2* = 1. In addition, if x = (0, 1), maχy∈Y f(x, y) = - miny∈Y y12n = 0. If
x 6= (0, 1), then by choosing y* = (0, 1), f(x, y*) = x12n > 0. Therefore, we have x* = (0, 1),
which proves that the unique Nash Equilibrium is x* = (0, 1), y* = (0, 1).
Second, we show that f satisfies SP-MS with β = 2n - 2. In fact, for any z = (x, y) 6= z*, we
have
>
2nx
F(z)>(z - z*)
2ny
2n-1
10
2n-1
10
- y1
+ x1
x1
X2 — 1
yι
y2 - 1
(Jensen’s inequality)
Note that ∣∣z - z*k =	,x2	+ (1 -	x2)2	+	y1	+ (1 -	y2)2 =	/2x2	+ 2y2.	Therefore, we have
kz-z*k
n — n
C = 22n-2.
≥ 22n-2 kz - z*k2n-1. This shows that f satisfies SP-MS with β = 2n - 2 and
^ □
33
Published as a conference paper at ICLR 2021
I Proof of Theorem 8
Proofof Theorem 8. As argued in Section 5, with Θt = ∣∣bt - ∏z*(bt)∣∣2 + 表∣∣bt - zt-1k2,
ζt = kzbt+1 - ztk2 + kzt - zbtk2, we have (see Eq. (4))
Θt+1 ≤ Θt- 16Zt.	(21)
Below, we relate ζt to Θt+1 using the SP-MS condition, and then apply Lemma 12 to show
(2dist2(bι, Z*)(1 + C5)-t	ɪ
θ ≤ [ (1+4 (4)β) dist2(bι, z*)+2 (蠡)β t-1
if β = 0,
if β > 0,
(22)
where C5 = min {吗尸,ɪ }
the theorem since
as defined in the statement of the theorem. This is enough to prove
dist2(zt,Z*) ≤ ∣zt -ΠZ*(zbt+1)∣2
≤ 2∣zbt+1 -ΠZ*(zbt+1)∣2+2∣zbt+1 - zt∣2
≤ 32Θt+1 ≤ 32Θt.
Next, we prove Eq. (22). We first show a simple fact by Eq. (21):
16	16
Ilzt+1 - zt『≤ Zt ≤	θt ≤ …≤ θι.
15	15
(23)
Notice that
Zt ≥ 2l∣bt+ι
≥ 2l∣bt+ι
≥ 2llbt+ι
-zt|2 + 2 (kzt+ι - zt|2 + Ilzt - zt。2)
-ztk2 + 粤 SUp
81 z0∈Z
[F (bt+1)>(bt+1-z0)] +
lzbt+1 - z0 l2
-ztk2 + 竺η2C2kbt+1- Πζ* (bt+ι)k2(β+1)
81
(Lemma 4)
(SP-MS condition)
≥ min {168IC , 2 (161；) } (kbt+1 - ztk2(β+1) + kbt+1 - nz*(bt+i)k2(e+1))
(by Eq. (23))
≥ min {¾η2C2，1 (32⅛)β} (kbt+1 - ztk2 + kbt+1 - ∏ζ*(bt+ι)k2)β+1
(by Holder's inequality: (aβ+1 + bβ+1 )(1 + 1)β ≥ (a + b)β+1)
≥ min{ C5, 2 ( 4⅛ )卜 β+11
= C0Θtβ++11.
Combining this with Eq. (21), we get
Θt+1 ≤ Θt - C0Θtβ++11
(recall that C5 = min{ 16^C?, 1})
(define C0 = min
β)
(24)
When β = 0, Eq. (24) implies Θt+1 ≤ (1 + C5)-1Θt, which immediately implies Θt ≤ (1 +
C5)-t+1Θ1 ≤ 2Θ1(1 + C5)-t. When β > 0, Eq. (24) is of the form specified in Lemma 12 with
P = β and q = C0. Note that the second required condition is satisfied: C0(β + 1)θf ≤ β+1 ≤ 1.
Therefore, by the conclusion of Lemma 12,
θt ≤max 卜,(Ce)β)t-1=max 卜,(U) β,4θ1 (4)β)t-1
≤
1+4 (4 )〕θ1+2 (Ch y
t-1
Eq. (22) is then proven by noticing that Θ1 = dist2(zb1, Z*).
□
34
Published as a conference paper at ICLR 2021
J Proof of Theorem 9
Proof of Theorem 9. Consider the following 2 × 2 bilinear game with curved feasible sets:
f (x, y) = x>Gy = [x1 x2] 10 -01	yy1 ,
X =	{x :	0 ≤ X1 ≤ 1,	0	≤ X2 ≤ 4, X2 ≥ X12},
Y =	yy :	0 ≤ yι ≤ 1,	0	≤ y2 ≤ 4, y2 ≥ y12}.
Below, we use Claim 1 - Claim 5 to argue that if the two players start from x0 = y0 = xb0 = yb0 =
(1, 4), and use any constant	learning rate η ≤ 64, then the convergence is sublinear in the	sense that
Ilzt — z*k	≥	Ω(1∕t).	Then,	in Claim 6, We show that in this example, SP-MS holds	with	β	=	3.
Claim 1. The unique equilibrium is x* = 0, y* = 0.
When x = 0, clearly maxy0∈Y f(x, y0) = 0. When x 6= 0, we prove maxy0∈Y f(x, y0) > 0
below. If xι = 0, we let y1 = 2xι and y2 = 4x12 (which satisfies y0 ∈ Y), and thus
f(χ, y0) = χ2yl — χιy2 = χι2 ∙ 2χι 一 χι ∙ 4χι2 = 4χι3 > 0.
If xι = 0 but x2 = 0, we let y1 = 1 ,y2 = 4, and thus
f (X, yO) = x2y1 — x1y2 = 1 x2 > 0.
Thus, maxy0∈Y f(x, y0) > 0 if x 6= 0, and x* = 0 is the unique optimal solution for x. By
the symmetry between x and y (because G = —G>), we can also prove that the unique optimal
solution for y is y* = 0.
Claim 2. Suppose that xo = yo = bo = yo = (2, ɪ). Then, at any step t ∈ [T], we have Xt = yt
and xbt = ybt, and all xt, yt, xbt, ybt belong to {u ∈ R2 : u2 = u12}.
We prove this by induction. The base case trivially holds. Suppose that for step t, we have xt = yt,
xbt = ybt, and xt , yt, xbt , ybt ∈ {u ∈ R2 : u2 = u12}. Then consider step t + 1. According to the
dynamic of OGDA, we have
xbt+1 = ΠX xbt — η
—yyt,t1,2	=ΠX	xxbbtt,,12 +— ηηyytt,,21
(25)
xt+1 = ΠX xbt+1 — η
—yt,2	Π	xbt+1,1 + ηyt,2,
yt,1	X xbt+1,2 — ηyt,1
ybt+1 = ΠY ybt + η
xt,2	= Π	ybt,1 + ηxt,2
—xt,1	Y	ybt,2 — ηxt,1
yt+1
ΠY ybt+1 + η
xt,2	= Π	ybt+1,1 + ηxt,2
—xt,1	Y	ybt+1,2 — ηxt,1
According to induction hypothesis, we have xbt+1 = ybt+1, which further leads to xt+1 = yt+1.
Now we prove that for any ：； such that xi ≥ 0, χ2 ≤ 4 and x2 < x12, X1
satisfies that xi = x2. Otherwise, suppose that xi < x2. Then according
value theorem, there exists
〜
xi
〜
x2
that lies in the line segment of
x1
x2
and
xi
x2
ΠX
x1
x2
to the intermediate
such that xei2 = xe2 .
Moreover, as xi ≥ 0, xi ≥ 0, χ2 ≤ 11, e2 ≤ 4, we know that
xi
〜
x2
∈ X . Therefore, we have
kx — Xk < ∣∣x — x∣, which leads to contradiction.
35
Published as a conference paper at ICLR 2021
Now consider xbt+1. According to induction hypothesis, we have (xbt,1 + ηyt,2)2 ≥ xbt2,1 = xbt,2 ≥
xbt,2 - ηyt,1. If equalities hold, trivially we have xbt2+1,1 = xbt2,1 = xbt,2 = xbt+1,2 according to Eq.
(25). Otherwise, as bt,ι + ηyt,2 ≥ 0, bt,2 - ηyt,ι ≤ 4, according to the analysis above, We also have
xbt2+1,1 = xbt+1,2. Applying similar analysis to ybt+1, xt+1 and yt+1 finishes the induction proof.
Claim 3. With η ≤ 64, the following holds for all t ≥ 1,
xt,ι ∈ 2bt,ι, 2bt,ι ,
xbt,1 ∈ xbt-1,1 - 4ηxbt2-1,1, xbt-1,1 + 4ηxbt2-1,1 .
(26)
(27)
We prove the claim by induction on t. The case t = 1 trivially holds. Suppose that Eq. (26) and Eq.
(27) hold at step t. Now consider step t + 1.
Induction to get Eq. (27). According to Claim 2, we have
xbt+1 = ΠX xbt - η
-yyt,t1,2	= ΠX	xxbbtt2,,11 -+ ηηxxtt2,,11
and xbt+1 = (u, u2) for some u ∈ [0, 1/2]. Using the definition of the projection function, we have
xt+1,1 = argmin { (bt,ι + ηx2,ι - u)2 + (b2」一ηxt,ι - u2)2)，argming(u)
u∈[0,1 ]	u∈[0,1 ]
Now we show that argminu∈[°, 1 ] g(u) = argmi□u∈R g(u). Note that
▽g(U) = 2(u - bt,ι - ηx2,ι) + 4u (u2 + ηxt,ι - b2,J ,	(28)
Therefore, when u > ɪ, using xt,ι ≤ 2, we have
▽g(u) > -2ηxt2,1 + 2ηxt,1 ≥ 0,	(29)
which means g(u) > g(2). On the other hand, when u < 0, using bt,ι ≤ 1, we have
▽g(u) < 2u - 4uxbt2,1 ≤ u < 0,	(30)
which means g(u) > g(0). Combining Eq. (29) and Eq. (30), we know that argminu∈[°, 1 ] g(u)=
argminu∈R g(u). Therefore, xbt+1,1 is the unconstrained minimizer of convex function g(u), which
means ▽g(xbt+1,1) = 0. Below we use contradiction to prove that xbt+1,1 ≥ xbt,1 - 4ηxbt2,1. If
xbt+1,1 < xbt,1 - 4ηxbt2,1, we use Eq. (28) and get
▽g(xbt+1,1) = 2(xbt+1,1 - xbt,1 - ηxt2,1) + 4xbt+1,1 xbt2+1,1 +ηxt,1 - xbt2,1
< 2(-4ηb2,ι - ηx2,ι) + 4bt+1,1 (η^t,ι - 8ηb3,1 + 16η2b4,ι)
17
≤ --2ηx2,ι + 4χt+1,1 (2ηbt,ι - 8ηχ3,ι + 16η2b4,ι)	(Eq.(26))
≤ - 127ηb2,ι +4bt+ι,ι (2ηbt,ι + 16η2χ4,ι)
17
≤ --2ηχ2,ι	+ 4(χt,ι	- 4ηχ2,ι)	(2ηχt,1	+	16η2χ4,ι)	(Xt+1,1	<	χt,ι	-	4ηχ2,ι)
=-11 ηb2,ι + 64η2b5,ι - 32η2b3,ι - 256η3b6,ι
≤ - 11 ηb2,ι - 16η2b3,ι - 256η3b6,ι	(bt,ι ≤ 2)
≤ 0,
36
Published as a conference paper at ICLR 2021
which leads to contradiction. Similarly, if xbt+1,1 > xbt,1 + 4ηxbt2,1, we have
Vg(bt+1,1) = 2(Xt+1,1 - bt,1 - ηχ2,ι) + 4bt+1,1 (b2+ι,ι + ηxt,1 - b2,ι)
> 2(4ηb2,ι - ηχ2,ι) + 4bt+ι,ι (ηxt,ι + 8ηχ3,ι + 16η2b4,ι)
≥ 0.	(Eq. (26))
The calculations above conclude that
xbt+1,1 ∈ xbt,1 - 4ηxbt2,1,xbt,1 + 4ηxbt2,1 .	(31)
Induction to get Eq. (26). Similarly, we have
xt+1,1 = argmin { (bt+1,1 + ηx2,ι - u)2 + (b2+ι,ι - ηxt,ι - u2)2}，argmin h(u),
u∈[0,2 ]	u∈[0,1 ]
▽h(U) = 2(u - xt+1,1 - ηx2,ι) + 4u(u2 + ηxt,ι -金2+1」)，
and Vh(χt+1,1) = 0. If xt+1,1 < 2bt+1,1, We have
▽h(Xt+1,I) = 2(Xt+1,1 — bt+1,1 — ηχ2,I) + 4χt+1,1 (x2+1,1 + ηχt,1 — x2+1,1)
< -Xt+1,1 - 2ηx2,1 - 3xt+1,1X2+1,1 + 2ηbt+1,1Xt,1	(xt+1,1 < 2Xt+1,1)
≤ 0.	(η ≤ 614 , xt,1 ≤ 2)
If xt+1,1 > 2xXt+1,1, We also have
▽h(xt+1,1) = 2(xt+1,1 - xXt+1,1 - ηxt2,1) + 4xt+1,1 xt2+1,1 +ηxt,1 - xXt2+1,1
> 2xXt+1,1 - 2ηxt2,1 + 24xXt3+1,1 + 8ηxXt+1,1xt,1	(xt+1,1 > 2xXt+1,1)
≥ 2xXt+1,1 - 2ηxt2,1 + 24xXt3+1,1 + 8η(xXt,1 - 4ηxXt2,1)xt,1	(Eq. (31))
≥ 2Xt+1,1 一 2ηx2,1 + 24X3+1,1 + 8η( 1xt,1 一 4ηX2j)xt,1	(Eq. (26))
= 2xXt+1,1 + 2ηxt2,1 + 24xXt3+1,1 - 32η2xXt2,1xt,1
≥ 2Xt+1,1 + 1 ηX2,1 + 24X3+1,1 - 32η2X2,1xt,1	(Eq. (26))
≥ 0.	⑺ ≤ 614 ,xt,1 ≤ 2)
Both lead to contradiction. Therefore, We conclude that xt+1 ∈ [2Xt+1,1,2Xt+1,1], which finishes
the induction proof.
Claim 4.	xt,1 ≥ xXt,1 - 4ηxXt2,1, for all t ≥ 1.
The case t = 1 holds trivially. For t ≥ 2, We prove this by contradiction. Using the definition of the
projection function, We have:
xt+1,1 = argmin {(Xt+1,1 + nx；/-u)2 + (X2+1,1 - ηxt,1 - u2)2∣，argminh(u).
u∈ [0,1 ]	u∈ [0,1 ]
Similar to the analysis in Claim 3, we have argminu∈[0 1 ] h(u) = argmi□u∈R h(u), which means
that Vh(Xt+1,1) = 0. Note that η ≤ 664 and 0 ≤ Xt, 1 ≤ 11, according to Eq. (26) and Eq. (27), we
have
xt+1,1 ∈
[xt,1 - 4ηx2,1,xt,1 +4ηx2,1] ⊆ 31 Xt,1, 32Xt,1 ,
which means that
xt,1 ∈
2Xt,1, 2Xt,1
16	64
⊆ 33 xt+1,1,3i Xt+1,1 .
(32)
37
Published as a conference paper at ICLR 2021
If xt+1,1 < Xt+1,1 — 4ηb2+ι,ι, We show that Vh(xt+1,1) < 0. In fact,
Vh(Xt+1,I) = 2(Xt+1,1 — bt+1,1 — ηx2,1) + 4xt+1,1 (x2+ι,ι + ηxt,1 — b2+1,l)
<	2(—4ηb2+ι,ι - ηχ2,ι) + 4χt+ι,ι (ηxt,ι - 8ηb3+ι,ι + 16η2b4+ι,ι)
≤ — 42ηb2+ι,ι + 4χt+ι,ι (34ηbt+ι,ι — 8ηχ3+ι,ι + 16η2χ4+ι,ι^	(Eq.(32))
≤ -42ηχ2+ι,ι +4χt+ι,ι (Iηbt+ι,ι + 16η2χ4+ι,ι)
<	-42ηχ2+ι,ι +4(bt+ι,ι - 4ηb2+ι,I) (Ilηbt+ι,ι + 16η2χ4+ι,/)
≤ 64η2Xbt5+1,1 — 32η2Xbt3+1,1 — 256η3Xbt6+1,1
≤ —16η2b3,ι — 256η3b6,ι	(Xt, 1 ≤ 1)
≤ 0,
which leads to contradiction. Therefore, we show that Xt,1 ≥ Xbt,1 — 4ηXbt2,1 for all t ≥ 1.
Claim 5. If η ≤ 64, we have ∣∣zt — z*k ≥ Ω(1∕t).
Now we are ready to prove ∣∣zt — z*∣∣ ≥ Ω(1∕t). Firstwe show bt,1 ≥ 21t for all t ≥ 1 by induction.
The case t = 1 trivially holds. Suppose that it holds at step t. Considering step t + 1, we have
Xbt+1,1 ≥ Xbt,1 — 4ηXbt2,1	(Claim 3)
≥ Xbt,1 —
≥ ɪ — ɪ
- 2t	64t2
(η ≤ 64)
(21t ≤ bt,1 ≤ 1, and X —七x2 is increasing when X ≤ 8)
、	1
≥ 2(t + 1).
Therefore, Xt,1 ≥ 21t, ∀t ≥ 1. This, by Claim 4 and the analysis above, shows that
xt,1 ≥ bt,1 - 4ηxt,1 ≥ 2(t + 1).
Note that according to Claim 1, x* = 0. Therefore, we have ∣∣zt — z*∣ ≥ xt,1 ≥
finishes the proof.
(t ≥ 1)
2W), which
Claim 6. In this example, SP-MS holds with β = 3. This can be seen by the following:
max
z0∈Z
F (z)>(z — z0)
kz — z0k
≥ max F(z)> (z — z0)
max
x0∈X,y0∈Y
x> Gy0 —
χ0>Gy}
χo∈m aχ∈γ{—x1y2+x2y1+x1y2 T y1}
≥ —X1X22 + X22 + y22 — y22y1
(picking y10 = X2 , y20 = X22 , X01 = y2 , X02 = y22)
≥ 2 x2 + 2 y2	(X1,y1 ≤ 1)
≥ 1 (xi + X4 + y4 + y4)	(X2 ≥ {X2,X2},y2 ≥ {y2,y2})
≥ 116(X2 + x2 + y2 + y2)2	(Cauchy-Schwarz)
=ɪ kz — z*k4,	(z* = (0,0,0,0))
16
38
Published as a conference paper at ICLR 2021
which implies β = 3.
□
39