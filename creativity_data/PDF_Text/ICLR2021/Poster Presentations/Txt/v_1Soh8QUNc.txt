Published as a conference paper at ICLR 2021
Learning Energy-Based Models by Diffusion
Recovery Likelihood
Ruiqi Gao
UCLA
ruiqigao@ucla.edu
Yang Song	Ben Poole
Stanford University	Google Brain
yangsong@cs.stanford.edu	pooleb@google.com
Ying Nian Wu
UCLA
ywu@stat.ucla.edu
Diederik P. Kingma
Google Brain
durk@google.com
Ab stract
While energy-based models (EBMs) exhibit a number of desirable properties,
training and sampling on high-dimensional datasets remains challenging. Inspired
by recent progress on diffusion probabilistic models, we present a diffusion re-
covery likelihood method to tractably learn and sample from a sequence of EBMs
trained on increasingly noisy versions of a dataset. Each EBM is trained with
recovery likelihood, which maximizes the conditional probability of the data at a
certain noise level given their noisy versions at a higher noise level. Optimizing re-
covery likelihood is more tractable than marginal likelihood, as sampling from the
conditional distributions is much easier than sampling from the marginal distribu-
tions. After training, synthesized images can be generated by the sampling process
that initializes from Gaussian white noise distribution and progressively samples
the conditional distributions at decreasingly lower noise levels. Our method gener-
ates high fidelity samples on various image datasets. On unconditional CIFAR-10
our method achieves FID 9.58 and inception score 8.30, superior to the majority
of GANs. Moreover, we demonstrate that unlike previous work on EBMs, our
long-run MCMC samples from the conditional distributions do not diverge and
still represent realistic images, allowing us to accurately estimate the normalized
density of data even for high-dimensional datasets. Our implementation is avail-
able at https://github.com/ruiqigao/recovery_likelihood.
1	Introduction
EBMs (LeCun et al., 2006; Ngiam et al., 2011; Kim & Bengio, 2016; Zhao et al., 2016; Goyal et al.,
2017; Xie et al., 2016b; Finn et al., 2016; Gao et al., 2018; Kumar et al., 2019; Nijkamp et al.,
2019b; Du & Mordatch, 2019; Grathwohl et al., 2019; Desjardins et al., 2011; Gao et al., 2020; Che
et al., 2020; Grathwohl et al., 2020; Qiu et al., 2019; Rhodes et al., 2020) are an appealing class of
probabilistic models, which can be viewed as generative versions of discriminators (Jin et al., 2017;
Lazarow et al., 2017; Lee et al., 2018; Grathwohl et al., 2020), yet can be learned from unlabeled
data. Despite a number of desirable properties, two challenges remain for training EBMs on high-
dimensional datasets. First, learning EBMs by maximum likelihood requires Markov Chain Monte
Carlo (MCMC) to generate samples from the model, which can be extremely expensive. Second, as
pointed out in Nijkamp et al. (2019a), the energy potentials learned with non-convergent MCMC
do not have a valid steady-state, in the sense that samples from long-run Markov chains can differ
greatly from observed samples, making it difficult to evaluate the learned energy potentials.
Another line of work, originating from Sohl-Dickstein et al. (2015), is to learn from a diffused
version of the data, which are obtained from the original data via a diffusion process that sequentially
adds Gaussian white noise. From such diffusion data, one can learn the conditional model of the data
at a certain noise level given their noisy versions at the higher noise level of the diffusion process.
After learning the sequence of conditional models that invert the diffusion process, one can then
generate synthesized images from Gaussian white noise images by ancestral sampling. Building on
1
Published as a conference paper at ICLR 2021
Figure 1: Generated samples on LSUN 1282 ChurCh.outdoor (left), LSUN 1282 bedroom (center)
and CelebA 642 (right).
Sohl-DiCkstein et al. (2015), Ho et al. (2020) further developed the method, obtaining strong image
synthesis results.
Inspired by Sohl-DiCkstein et al. (2015) and Ho et al. (2020), we propose a diffusion recovery like-
lihood method to taCkle the Challenge of training EBMs direCtly on a dataset by instead learning a
sequenCe of EBMs for the marginal distributions of the diffusion proCess. The sequenCe of marginal
EBMs are learned with reCovery likelihoods that are defined as the Conditional distributions that in-
vert the diffusion proCess. Compared to standard maximum likelihood estimation (MLE) of EBMs,
learning marginal EBMs by diffusion reCovery likelihood only requires sampling from the Condi-
tional distributions, whiCh is muCh easier than sampling from the marginal distributions. After learn-
ing the marginal EBMs, we Can generate synthesized images by a sequenCe of Conditional samples
initialized from the Gaussian white noise distribution. Unlike Ho et al. (2020) that approximates the
reverse proCess by normal distributions, in our Case the Conditional distributions are derived from
the marginal EBMs, whiCh are more flexible. The framework of reCovery likelihood was originally
proposed in Bengio et al. (2013). In our work, we adapt it to learning the sequenCe of marginal
EBMs from the diffusion data.
Our work is also related to the denoising sCore matChing method of VinCent (2011), whiCh was
further developed by Song & Ermon (2019; 2020) for learning from diffusion data. The training ob-
jeCtive used for diffusion probabilisitiC models is a weighted version of the denoising sCore matChing
objeCtive, as revealed by Ho et al. (2020). These methods learn the sCore funCtions (the gradients
of the energy funCtions) direCtly, instead of using the gradients of learned energy funCtions as in
EBMs. On the other hand, Saremi et al. (2018) parametrizes the sCore funCtion as the gradient of a
MLP energy funCtion, and Saremi & Hyvarinen (2019) further unifies denoising sCore matChing and
neural empiriCal Bayes.
We demonstrate the effiCaCy of diffusion reCovery likelihood on CIFAR-10, CelebA and LSUN
datasets. The generated samples are of high fidelity and Comparable to GAN-based methods. On
CIFAR-10, we aChieve FID 9.58 and inCeption sCore 8.30, exCeeding existing methods of learning
expliCit EBMs to a large extent. We also demonstrate that diffusion reCovery likelihood outperforms
denoising sCore matChing from diffusion data if we naively take the gradients of expliCit energy
funCtions as the sCore funCtions. More interestingly, by using a thousand diffusion time steps, we
demonstrate that even very long MCMC Chains from the sequenCe of Conditional distributions pro-
duCe samples that represent realistiC images. With the faithful long-run MCMC samples from the
Conditional distributions, we Can aCCurately estimate the marginal partition funCtion at zero noise
level by importanCe sampling, and thus evaluate the normalized density of data under the EBM.
2
Published as a conference paper at ICLR 2021
Figure 3: Illustration of diffusion recovery likelihood on 2D checkerboard example. Top: progres-
sively generated samples. Bottom: estimated marginal densities.
2	Background
Let X 〜Pdata(x) denote a training example, and pθ (x) denote a model's probability density func-
tion that aims to approximates pdata(x). An energy-based model (EBM) is defined as:
Pθ(X) = ɪ exp(fθ(X)),	(1)
Zθ
where Zθ = exp(fθ (x))dx is the partition function, which is analytically intractable for high-
dimensional x. For images, we parameterize fθ (x) with a convolutional neural network with a
scalar output.
The energy-based model in equation 1 can, in principle, be learned through MLE. Specifically,
suppose We observe samples xi 〜Pdata(x) for i = 1, 2,..., n. The log-likelihood function is
1n
L⑻=n Σlog Pθ (Xi) = EX-Pdata [log Pθ (X)I.	(2)
i=1
In MLE, We seek to maximize the log-likelihood function, Where the gradient approximately fol-
loWs (Xie et al., 2016b)
-∂θDKL (Pdata llpθ ) = Ex-Pdata ∂θfθ (X) - Ex-Pθ ∂θfθ (X)
(3)
The expectations can be approximated by averaging over the observed samples and the synthesized
samples draWn from the model distribution Pθ (X) respectively. Generating synthesized samples
from Pθ (X) can be done With Markov Chain Monte Carlo (MCMC) such as Langevin dynamics (or
Hamiltonian Monte Carlo (Girolami & Calderhead, 2011)), Which iterates
δ2
xτ+1 = xτ + 5 Vx fθ (xτ) + δ J,
(4)
where T indexes the time, δ is the step size, and WT 〜
N(0, I). The difficulty lies in the fact that for high-
dimensional and multi-modal distributions, MCMC sam-
pling can take a long time to converge, and the sampling
chains may have difficulty traversing modes. As demon-
strated in Figure 2, training EBMs with synthesized sam-
ples from non-convergent MCMC results in malformed
energy landscapes (Nijkamp et al., 2019b), even if the sam-
ples from the model look reasonable. 3
3 Recovery Likelihood	Figure 2: Comparison of learning
EBMs by diffusion recovery likeli-
3.1 FROM MARGINAL TO CONDITIONAL	hood (Ours) versus marginal likelihood
(Short-run).
Given the difficulty of sampling from the marginal density
Pθ (x), following Bengio et al. (2013), we use the recovery likelihood defined by the density of the
3
Published as a conference paper at ICLR 2021
observed sample conditional on a noisy sample perturbed by isotropic Gaussian noise. Specifically,
let X = X + σe be the noisy observation of x, where E 〜N(0, I). Suppose pθ(x) is defined by the
EBM in equation 1, then the conditional EBM can be derived as
pθ(x∣x)
Zzθ⅛exp fθ (X) - 2σ2 kx -xk2
(5)
where Zθ (X) = / exp f (x)-击 ∣∣X - x∣∣2) dx is the partition function of this conditional EBM.
See Appendix A.1 for the derivation. Compared to pθ(x) (equation 1), the extra quadratic term
212 ∣∣X - xk2 inpθ(x|X) constrains the energy landscape to be localized around X, making the latter
less multi-modal and easier to sample from. As We will show later, when σ is small, pθ(x|X) is
approximately a single mode Gaussian distribution, which greatly reduces the burden of MCMC.
A more general formulation is X = ax + σe, where a is a positive constant. In that case, we can let
y = ax, and treat y as the observed sample. Assume pθ(y) = Z exp(fθ(y)), then by change of
variable, the density function of x can be derived as gθ (x) = apθ (ax).
3.2 Maximizing recovery likelihood
With the conditional EBM, assume we have observed samples Xi 〜Pdata(X) and the corresponding
perturbed samples X% = Xi + σ/ for i = 1,…，n. We define the recovery Iog-Iikelihoodfunction as
1n
J (θ) = — £ log pθ MIX %).	⑹
n
i=1
The term recovery indicates that we attempt to recover the clean sample Xi from the noisy sample
Xi. Thus, instead of maximizing L(θ) in equation 2, we can maximize J(θ), whose distributions
are easier to sample from. Specifically, we generate synthesized samples by K steps of Langevin
dynamics that iterates
δ2	1
Xτ +1 = Xτ + 可(Vχfθ(xτ) + -2(X - xτ)) + δeτ.	⑺
2	σ2
The model is then updated following the same learning gradients as MLE (equation 3), because the
quadratic term -212∣∣X - x∣2 is not related to θ. Following the classical analysis of MLE, we can
show that the point estimate given by maximizing recovery likelihood is an unbiased estimator of
the true parameters, which means that given enough data, a rich enough model and exact synthesis,
maximizing the recovery likelihood learns θ such that pdata(X) = pθ(X). See Appendix A.2 for a
theoretical explanation.
3.3	Normal Approximation to Conditional
When the variance of perturbed noise σ2 is small, pθ (x∣X) can be approximated by a normal distri-
bution via a first order Taylor expansion at X. Specifically, the negative conditional energy is
-Eθ(XIX) = fθ(X) - 212∣∣x - xk2	⑻
=fθ(X) + hVχfθ(X), X - Xi- X12∣∣X - X∣2	(9)
2σ2
=-J2 [∣X - (X + σ2Vχfθ(X))∣2] + c,	(10)
2σ2
where c include terms irrelevant of X (see Appendix A.3 for a detailed derivation). In the above
approximation, we do not perform second order Taylor expansion because σ2 is small, and ∣∣X -
x∣2/2σ2 will dominate all the second order terms from Taylor expansion. Thus we can approximate
Pθ(x∣X) by a Gaussian approximationpθ(x∣X):
pθ(x∣X) = N (x; X + σ2Vχfθ(X),σ2) .	(11)
We can sample from this distribution using:
Xgen = X + σ2Vχfθ (X) + σe,	(12)
where E 〜N(0, I). This resembles a single step of Langevin dynamics, except that σe is replaced
by √2σe in Langevin dynamics. This normal approximation has two traits: (1) it verifies the fact
that the conditional density pθ(x∣X) can be generally easier to sample from when σ is small; (2) it
provides hints of choosing the step size of Langevin dynamics, as discussed in section 3.5.
4
Published as a conference paper at ICLR 2021
3.4	Connection to variational inference and score matching
The normal approximation to the conditional distribution leads to a natural connection to diffu-
sion probabilistic models (Sohl-Dickstein et al., 2015; Ho et al., 2020) and denoising score match-
ing (Vincent, 2011; Song & Ermon, 2019; 2020; Saremi et al., 2018; Saremi & Hyvarinen, 2019).
Specifically, in diffusion probabilistic models, instead of modeling pθ(x) as an energy-based model,
it recruits variational inference and directly models the conditional density as
Pθ(x|X)〜N (x + σ1 2Sθ(x),σ2) ,	(13)
which is in agreement with the normal approximation (equation 11), with sθ (x) = Vχfθ(x). On
the other hand, the training objective of denoising score matching is to minimize
2σ2Ep(χ,x)[kx -(X + σ2sθ(X))k2],	(14)
where sθ (x) is the score of the density of X. This objective is in agreement with the objective of
maximizing log-likelihood of the normal approximation (equation 10), except that for normal ap-
proximation, Vχfθ (∙) is the score of density of x, instead of X. However, the difference between the
scores of density of X and X is of O(σ2), which is negligible when σ is sufficiently small (see AP-
pendix A.4 for details). We can further show that the learning gradient of maximizing log-likelihood
of the normal approximation is approximately the same as the learning gradient of maximizing the
original recovery log-likelihood with one step of Langevin dynamics (see Appendix A.5). It indi-
cates that the training process of maximizing recovery likelihood agrees with the one of diffusion
probabilistic models and denoising score matching when σ is small.
As the normal approximation is accurate only when σ is small, it requires many time steps in the
diffusion process for this approximation to work well, which is also reported in Ho et al. (2020)
and Song & Ermon (2020). In contrast, the diffusion recovery likelihood framework can be more
flexible in choosing the number of time steps and the magnitude of σ.
3.5	Diffusion recovery likelihood
As we discuss, sampling from pθ(x|X) becomes simple only when σ is small. In the extreme case
when σ → ∞, pθ(x|X) converges to the marginal distribution pθ(x), which is again highly multi-
modal and difficult to sample from. To keep σ small and meanwhile equip the model with the abil-
ity to generate new samples initialized from white noise, inspired by Sohl-Dickstein et al. (2015)
and Ho et al. (2020), we propose to learn a sequence of recovery likelihoods, on gradually per-
turbed observed data based on a diffusion process. Specifically, assume a sequence of perturbed
observations X0, X1, ..., XT such that
X0 〜Pdata(x)；
Xt+1
1 - σt2+1Xt + σt+1t+1,
t = 0, 1, ...T - 1.
(15)
The scaling factor
1 - σt2+1 ensures that the sequence is a spherical interpolation between the
observed sample and Gaussian white noise. Let yt
conditional EBMs
1 - σt2+1Xt, and we assume a sequence of
PPMXt+1) = ZZθ⅛+)exp (fθMttt- 2⅛kXt+1-ytk” t = 0, 1,...,t- 1, (16)
where fP(yt, t) is defined by a neural network conditioned on t.
We follow the learning algorithm in section 3.2. A question is how to determine the step size
schedule δt of Langevin dynamics. Inspired by the sampling procedure of the normal approximation
(equation 12), we set the step size δt = bσt, where b < 1 is a tuned hyperparameter. This schedule
turns out to work well in practice. Thus the K steps of Langevin dynamics iterates
b2σ2	1
yt+ = yt +	厂(VyfP(yt ,t) +	2 (χt+ι - yt)) + bσte .
2	σt
(17)
Algorithm 1 summarizes the training procedure. After training, we initialize the MCMC sampling
from Gaussian white noise, and the synthesized sample at each time step serves to initialize the
MCMC that samples from the model of the previous time step. See algorithm 2. To show the efficacy
of our method, Figures 3 and 2 display several 2D toy examples learned by diffusion recovery
likelihood.
5
Published as a conference paper at ICLR 2021
Algorithm 1 Training
repeat
Sample t 〜Unif({0,..., T - 1}).
Sample pairs (yt, xt+1).
Set synthesized sample yt- = xt+1.
for T — 1 to K do
Update yt- according to equation 17.
end for
Update θ following the gradients
∂θfθ(yt,t) - ∂θfθ(y- ,t).
until converged.
Algorithm 2 Progressive sampling
Sample XT 〜N(0, I).
for t — T - 1 to 0 do
yt = Xt+1.
for τ — 1 to K do
Update yt according to equation 17.
end for ___________
Xt = yt/ 1 - σt2+1.
end for
return X0 .
4 Experiments
To show that diffusion recovery likelihood is flexible for diffusion process of various magnitudes of
noise, we test the method under two settings: (1) T = 6, with K = 30 steps of Langevin dynamic
per time step; (2) T = 1000, with sampling from normal approximation. (2) resembles the noise
schedule of Ho et al. (2020) and the magnitude of noise added at each time step is much smaller
compared to (1). For both settings, we set σt2 to increase linearly. The network structure of fθ (x, t)
is based on Wide ResNet (Zagoruyko & Komodakis, 2016) and we remove weight normalization. t
is encoded by Transformer sinusoidal position embedding as in (Ho et al., 2020). For (1), we find
that adding another scaling factor ct to the step size δt helps. Architecture and training details are in
Appendix B. Henceforth we simply refer the two settings as T6 and T1k.
4.1	Image generation
Figures 1 and 4 display uncurated samples generated from learned models on CIFAR-10, CelebA
64 × 64, LSUN 64 × 64 and 128 × 128 datasets under T6 setting. The samples are of high fidelity
and comparable to GAN-based methods. Appendix C.5 provides more generated samples. Tables
1 and 3 summarize the quantitative evaluations on CIFAR-10 and CelebA datasets, in terms of
Frechet Inception Distance (FID) (Heusel et al., 2017) and inception scores (Salimans et al., 2016).
On CIFAR-10, our model achieves FID 9.58 and inception score 8.30, which outperforms existing
methods of learning explicit energy-based models to a large extent, and is superior to a majority of
GAN-based methods. On CelebA, our model obtains results comparable with the state-of-the-art
GAN-based methods, and outperforms score-based methods (Song & Ermon, 2019; 2020). Note
that the score-based methods (Song & Ermon, 2019; 2020) and diffusion probabilistic models (Ho
et al., 2020) directly parametrize and learn the score of data distribution, whereas our goal is to learn
explicit energy-based models.
Figure 4: Generated samples on unconditional CIFAR-10 (left) and LSUN 642 ChurCh-outdoor (Cen-
ter) and LSUN 642 bedroom (right).
6
Published as a conference paper at ICLR 2021
Table 1: FID and inception scores on CIFAR-10.
Model	FID]	InCeption↑
GAN-based		
WGAN-GP (Gulrajani et al., 2017)	36.4	7.86 ± .07
SNGAN (Miyato et al., 2018)	21.7	8.22 ± .05
SNGAN-DDLS (Che et al., 2020)	15.42	9.09 ± .10
StyleGAN2-ADA (Karras et al., 2020)	3.26	9.74 ± .05
Score-based		
NCSN (Song & Ermon, 2019)	25.32	8.87 ± .12
NCSN-v2 (Song & Ermon, 2020)	10.87	8.40 ± .07
DDPM (Ho et al., 2020)	3.17	9.46 ± .11
Explicit EBM-Conditional		
CoopNets (Xie et al., 2019)	-	7.30
EBM-IG (Du & MordatCh, 2019)	37.9	8.30
JEM (GrathWohl et al., 2019)	38.4	8.76
Explicit EBM		
Muli-grid (Gao et al., 2018)	40.01	6.56
CoopNets (Xie et al., 2016a)	33.61	6.55
EBM-SR (Nijkamp et al., 2019b)	-	6.21
EBM-IG (Du & MordatCh, 2019)	38.2	6.78
OUrs (T6)	9.58	8.30 ± .11
FID]	InCePtion↑
Setting / Objective
Table 2: Ablation of training objeCtives,
time stePs T and samPling stePs K on
CIFAR-10. K = 0 indiCates that we sam-
Ple from the normal aPProximation.
T=1,K= 180	32.12 T = 1000, K = 0	22.58 T = 1000, K = 0 (DSM) 21.76 T = 6, K	= 10	- T = 6, K	= 30	9.58 T = 6, K	= 50	9.36	6.72 ± 0.12 7.71 ± 0.08 7.76 ± 0.11 - 8.30 ± 0.11 8.46 ± 0.13
Table 3: FID sCores on CelebA 642 .	
Model	FID]
QA-GAN (Parimala & Channappayya, 2019) 6.42 COCO-GAN (Lin et al., 2019)	4.0	
NVAE (Vahdat & Kautz, 2020)	14.74
NCSN (Song & Ermon, 2019) NCSN-v2 (Song & Ermon, 2020)	25.30 10.23
EBM-SR (Nijkamp et al., 2019b) EBM-Triangle (Han et al., 2020) OUrs (T6)	23.02 24.70 5.98
Figure 5: InterPolation results between the leftmost and rightmost generated samPles. For top to
bottom: LSUN ChUrCh.outdoor 1282 ,LSUN bedroom 1282 and CelebA 642.
Table 4: Test bits Per dimension on CIFAR-
10.才 indicates that We estimate the bit per
dimension with the aPProximated log Partition
funCtion instead of analytiCally Computing it.
See seCtion 4.2.
Model	BPD]
DDPM (Ho et al., 2020)	3.70
GloW (Kingma & DhariWal, 2018)	3.35
FloW++ (Ho et al., 2019)	3.08
GPixelCNN (Van den Oord et al., 2016) 3.03
Sparse Transformer (Child et al., 2019)	2.80
DistAug (Jun et al., 2020)	2.56
OUrst (τik)	3.18
Figure 6: Image inpainting on LSUN ChUrCh.outdoor
1282 (left) and CelebA 642 (right). With eaCh bloCk,
the top roW are mask images While the bottom roW
are inpainted images.
Interpolation. As shoWn in Figure 5, our model is Capable of smooth interpolation betWeen tWo
generated samples. SpeCifiCally, for tWo samples x(00) and x(01), We do a sphere interpolation betWeen
7
Published as a conference paper at ICLR 2021
the initial white noise images x(T0) and x(T1) and the noise terms of Langevin dynamics (t,0τ) and (t,1τ)
for every sampling step at every time step. More interpolation results can be found in Appendix C.3.
Image inpainting. A promising application of energy-based models is to use the learned model
as a prior model for image processing, such as image inpainting, denoising and super-resolution
(Gao et al., 2018; Du & Mordatch, 2019; Song & Ermon, 2019). In Figure 6, we demonstrate that
the learned models by maximizing recovery likelihoods are capable of realistic and semantically
meaningful image inpainting. Specifically, given a masked image and the corresponding mask, we
first obtain a sequence of perturbed masked images at different noise levels. The inpainting can be
easily achieved by running Langevin dynamics progressively on the masked pixels while keeping
the observed pixels fixed at decreasingly lower noise levels. Additional image inpainting results can
be found in Appendix C.4.
Ablation study. Table 2 summarizes the results of ablation study on CIFAR-10. We investigate
the effect of changing the numbers of time steps T and sampling steps K. First, to show that
it is beneficial to learn by diffusion recovery likelihood, we compare against a baseline approach
(T = 1, K = 180) where we use only one time step, so that the recovery likelihood becomes
marginal likelihood. The approach is adopted by Nijkamp et al. (2019b) and Du & Mordatch (2019).
For fair comparison, we equip the baseline method the same budget of MCMC sampling as our T6
setting (i.e., 180 sampling steps). Our method outperforms this baseline method by a large margin.
Also the models are trained more efficiently as the number of sampling steps per iteration is reduced
and amortized by time steps.
Next, we report the sample quality of setting T1k. We test two training objectives for this setting: (1)
maximizing recovery likelihoods (T = 1000, K = 0) and (2) maximizing the approximated normal
distributions (T=1000, K=0 (DSM)). As mentioned in section 3.4, (2) is equivalent to the training
objectives of denoising score matching (Song & Ermon, 2019; 2020) and diffusion probabilistic
model (Ho et al., 2020), except that the score functions are taken as the gradients of explicit energy
functions. In practice, for a direct comparison, (2) follows the same implementation as in Ho et al.
(2020), except that the score function is parametrized as the gradients of the explicit energy function
used in our method. (1) and (2) achieve similar sample quality in terms of quantitative metrics,
where (2) results in a slightly better FID score yet a slightly worse inception score. This verifies the
fact that the training objectives of (1) and (2) are consistent. Both (1) and (2) performs worse than
setting T6. A possible explanation is that the sampling error may accumulate with many time steps,
so that a more flexible schedule of time steps accompanied with certain amount of sampling steps is
preferred.
Last, we examine the influence of varying the number of sampling steps while fixing the number
of time steps. The training becomes unstable when the number of sampling steps are not enough
(T = 6, K = 10), and more sampling steps lead to better sample quality. However, since K = 50
does not gain significant improvement versus K = 30, yet of much higher computational cost, we
keep K = 30 for image generation on all datasets. See Appendix C.1 for a plot of FID scores over
iterations.
4.2	Long-run chain analysis
Besides achieving high quality generation, a perhaps equally important aspect of learning EBMs is
to obtain a faithful energy potential. A principle way to check the validity of the learned potential
is to perform long-run sampling chains and see if the samples still remain realistic. However, as
pointed out in Nijkamp et al. (2019a), almost all existing methods of learning EBMs fail in getting
realistic long-run chain samples. In this subsection, we demonstrate that by composing a thousand
diffusion time steps (T1k setting), we can form steady long-run MCMC chains for the conditional
distributions.
First we prepare a faithful sampler for conducting long-run sampling. Specifically, after training the
model under T 1k setting by maximizing diffusion recovery likelihood, for each time step, we first
sample from the normal approximation and count it as one sampling step, and then use Hamiltonian
Monte Carlo (HMC) (Neal et al., 2011) with 2 leapfrog steps to perform the consecutive sampling
steps. To obtain a reasonable schedule of sampling step size, for each time step we adaptively adjust
the step size of HMC to make the average acceptance rate range in [0.6, 0.9], which is computed
8
Published as a conference paper at ICLR 2021
Figure 7: Left: Adjusted step size of HMC over time step. Center: Acceptance rate over time step.
Right: Estimated log partition function over number of samples with different number of sampling
steps per time step. The x axis is plotted in log scale.
over 1000 chains for 100 steps. Figure 7 displays the adjusted step size (left) and acceptance rate
(center) over time step. The adjusted step size increases logarithmically. With this step size schedule,
we generate long-run chains from the learned sequence of conditional distributions. As shown in
Figure 8, images remain realistic for even 100k sampling steps in total (i.e., 100 sampling steps per
time step), resulting in FID 24.89. This score is close to the one computed on samples generated by
1k steps (i.e., sampled from normal approximation), which is 25.12. As a further check, we recruit
a No-U-Turn Sampler (Hoffman & Gelman, 2014) with the same step size schedule as HMC to
perform long-run sampling, where the samples also remain realistic. See Appendix C.2 for details.
More interestingly, given the faithful long-run MCMC sam-
ples from the conditional distributions, we can estimate
the log ratio of the partition functions of the marginal dis-
tributions, and further estimate the partition function of
pθ(y0). The strategy is based on annealed importance sam-
pling (Neal, 2001). See Appendix A.6 for the implementa-
tion details. The right subfigure of Figure 7 depicts the es-
timated log partition function ofpθ(y0) over the number of
MCMC samples used. To verify the estimation strategy and
again check the long-run chain samples, we conduct mul-
tiple runs using samples generated with different numbers
of HMC steps and display the estimation curves. All the
curves saturate to values close to each other at the end, indicating the stability of long-run chain sam-
ples and the effectiveness of the estimation strategy. With the estimated partition function, by change
ofvariable, We can estimate the normalized density of data as gθ (x0) = ʌ/l — σ2pθ (ʌ/l — σ2x0).
We report test bits per dimension on CIFAR-10 in Table 4. Note that the result should be taken with
a grain of salt, because the partition function is estimated by samples and as shoWn in Appendix
A.6, it is a stochastic loWer bound of the true value, that Will converge to the true value When the
number of samples groWs large.
Figure 8: Long-run chain samples
from model-T1k With different total
amount of HMC steps. From left to
right: 1k steps, 10k steps and 100k
steps.
5 Conclusion
We propose to learn EBMs by diffusion recovery likelihood, a variant of MLE applied to diffusion
processes. We achieve high quality image synthesis, and With a thousand noise levels, We obtain
faithful long-run MCMC samples that indicate the validity of the learned energy potentials. Since
this method can learn EBMs efficiently With small budget of MCMC, We are also interested in
scaling it up to higher resolution images and investigating this method in other data modalities in
the future.
Acknowledgement
The Work Was done While Ruiqi Gao and Yang Song Were interns at Google Brain during the summer
of 2020. The Work of Ying Nian Wu is supported by NSF DMS-2015577. We thank Alexander A.
Alemi, Jonathan Ho, Tim Salimans and Kevin Murphy for their insightful discussions during the
course of this project.
9
Published as a conference paper at ICLR 2021
References
Yoshua Bengio, Li Yao, Guillaume Alain, and Pascal Vincent. Generalized denoising auto-encoders
as generative models. In Advances in neural information processing systems, pp. 899-907, 2013.
Tong Che, Ruixiang Zhang, Jascha Sohl-Dickstein, Hugo Larochelle, Liam Paull, Yuan Cao, and
Yoshua Bengio. Your gan is secretly an energy-based model and you should use discriminator
driven latent sampling. arXiv preprint arXiv:2003.06060, 2020.
Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. Generating long sequences with sparse
transformers. arXiv preprint arXiv:1904.10509, 2019.
Guillaume Desjardins, Yoshua Bengio, and Aaron C Courville. On tracking the partition function.
In Advances in neural information processing systems, pp. 2501-2509, 2011.
Yilun Du and Igor Mordatch. Implicit generation and generalization in energy-based models. arXiv
preprint arXiv:1903.08689, 2019.
Chelsea Finn, Paul Christiano, Pieter Abbeel, and Sergey Levine. A connection between generative
adversarial networks, inverse reinforcement learning, and energy-based models. arXiv preprint
arXiv:1611.03852, 2016.
Ruiqi Gao, Yang Lu, Junpei Zhou, Song-Chun Zhu, and Ying Nian Wu. Learning generative con-
vnets via multi-grid modeling and sampling. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pp. 9155-9164, 2018.
Ruiqi Gao, Erik Nijkamp, Diederik P Kingma, Zhen Xu, Andrew M Dai, and Ying Nian Wu. Flow
contrastive estimation of energy-based models. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 7518-7528, 2020.
Mark Girolami and Ben Calderhead. Riemann manifold langevin and hamiltonian monte carlo
methods. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73(2):
123-214, 2011.
Anirudh Goyal Alias Parth Goyal, Nan Rosemary Ke, Surya Ganguli, and Yoshua Bengio. Vari-
ational walkback: Learning a transition operator as a stochastic recurrent net. In Advances in
Neural Information Processing Systems, pp. 4392-4402, 2017.
Will GrathWohL KUan-Chieh Wang, Jorn-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi,
and Kevin Swersky. Your classifier is secretly an energy based model and you should treat it like
one. arXiv preprint arXiv:1912.03263, 2019.
Will GrathWohl, Kuan-Chieh Wang, Jorn-Henrik Jacobsen, David Duvenaud, and Richard Zemel.
Cutting out the middle-man: Training and evaluating energy-based models Without sampling.
arXiv preprint arXiv:2002.05616, 2020.
Roger B Grosse, Siddharth Ancha, and Daniel M Roy. Measuring the reliability of mcmc inference
With bidirectional monte carlo. In Advances in Neural Information Processing Systems, pp. 2451-
2459, 2016.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Im-
proved training of Wasserstein gans. In Advances in neural information processing systems, pp.
5767-5777, 2017.
Tian Han, Erik Nijkamp, Linqi Zhou, Bo Pang, Song-Chun Zhu, and Ying Nian Wu. Joint training
of variational auto-encoder and latent energy-based model. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition, pp. 7978-7987, 2020.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a tWo time-scale update rule converge to a local nash equilibrium. In Advances
in Neural Information Processing Systems, pp. 6626-6637, 2017.
Jonathan Ho, Xi Chen, Aravind Srinivas, Yan Duan, and Pieter Abbeel. FloW++: Improving floW-
based generative models With variational dequantization and architecture design. arXiv preprint
arXiv:1902.00275, 2019.
10
Published as a conference paper at ICLR 2021
Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. arXiv preprint
arXiv:2006.11239, 2020.
Matthew D Hoffman and Andrew Gelman. The no-u-turn sampler: adaptively setting path lengths
in hamiltonian monte carlo. J. Mach. Learn. Res., 15(1):1593-1623, 2014.
Long Jin, Justin Lazarow, and Zhuowen Tu. Introspective classification with convolutional nets. In
Advances in Neural Information Processing Systems, pp. 823-833, 2017.
Heewoo Jun, Rewon Child, Mark Chen, John Schulman, Aditya Ramesh, Alec Radford, and Ilya
Sutskever. Distribution augmentation for generative modeling. In Proceedings of Machine Learn-
ing and Systems 2020, pp. 10563-10576. 2020.
Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Training
generative adversarial networks with limited data. arXiv preprint arXiv:2006.06676, 2020.
Taesup Kim and Yoshua Bengio. Deep directed generative models with energy-based probability
estimation. arXiv preprint arXiv:1606.03439, 2016.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Diederik P Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions.
In Advances in Neural Information Processing Systems, pp. 10215-10224, 2018.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
Technical report, Citeseer, 2009.
Rithesh Kumar, Anirudh Goyal, Aaron Courville, and Yoshua Bengio. Maximum entropy generators
for energy-based models. arXiv preprint arXiv:1901.08508, 2019.
Justin Lazarow, Long Jin, and Zhuowen Tu. Introspective neural networks for generative modeling.
In Proceedings of the IEEE International Conference on Computer Vision, pp. 2774-2783, 2017.
Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, and F Huang. A tutorial on energy-based
learning. Predicting structured data, 1(0), 2006.
Kwonjoon Lee, Weijian Xu, Fan Fan, and Zhuowen Tu. Wasserstein introspective neural networks.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3702-
3711, 2018.
Chieh Hubert Lin, Chia-Che Chang, Yu-Sheng Chen, Da-Cheng Juan, Wei Wei, and Hwann-Tzong
Chen. Coco-gan: generation by parts via conditional coordinating. In Proceedings of the IEEE
International Conference on Computer Vision, pp. 4512-4521, 2019.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Large-scale celebfaces attributes (celeba)
dataset. Retrieved August, 15:2018, 2018.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization
for generative adversarial networks. arXiv preprint arXiv:1802.05957, 2018.
Radford M Neal. Annealed importance sampling. Statistics and computing, 11(2):125-139, 2001.
Radford M Neal et al. Mcmc using hamiltonian dynamics. Handbook of markov chain monte carlo,
2(11):2, 2011.
Jiquan Ngiam, Zhenghao Chen, Pang W Koh, and Andrew Y Ng. Learning deep energy models.
In Proceedings of the 28th international conference on machine learning (ICML-11), pp. 1105-
1112, 2011.
Erik Nijkamp, Mitch Hill, Tian Han, Song-Chun Zhu, and Ying Nian Wu. On the anatomy of mcmc-
based maximum likelihood learning of energy-based models. arXiv preprint arXiv:1903.12370,
2019a.
11
Published as a conference paper at ICLR 2021
Erik Nijkamp, Mitch Hill, Song-Chun Zhu, and Ying Nian Wu. On learning non-convergent short-
run mcmc toward energy-based model. arXiv preprint arXiv:1904.09770, 2019b.
KANCHARLA Parimala and Sumohana and Channappayya. Quality aware generative adversarial
networks. In Advances in Neural Information Processing Systems, pp. 2948-2958, 2019.
Yixuan Qiu, Lingsong Zhang, and Xiao Wang. Unbiased contrastive divergence algorithm for train-
ing energy-based latent variable models. In International Conference on Learning Representa-
tions, 2019.
Benjamin Rhodes, Kai Xu, and Michael U Gutmann. Telescoping density-ratio estimation. Ad-
vances in Neural Information Processing Systems, 33, 2020.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.
Improved techniques for training gans. In Advances in neural information processing systems,
pp. 2234-2242, 2016.
Saeed Saremi and Aapo Hyvarinen. Neural empirical bayes. Journal of Machine Learning Research,
20:1-23, 2019.
Saeed Saremi, Arash Mehrjou, Bernhard Scholkopf, and Aapo Hyvarinen. Deep energy estimator
networks. arXiv preprint arXiv:1805.08306, 2018.
Jascha Sohl-Dickstein, Eric A Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsuper-
vised learning using nonequilibrium thermodynamics. arXiv preprint arXiv:1503.03585, 2015.
Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution.
In Advances in Neural Information Processing Systems, pp. 11918-11930, 2019.
Yang Song and Stefano Ermon. Improved techniques for training score-based generative models.
arXiv preprint arXiv:2006.09011, 2020.
Arash Vahdat and Jan Kautz. Nvae: A deep hierarchical variational autoencoder. Advances in Neural
Information Processing Systems, 33, 2020.
Aaron Van den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex Graves, et al. Con-
ditional image generation with pixelcnn decoders. In Advances in neural information processing
systems, pp. 4790-4798, 2016.
Pascal Vincent. A connection between score matching and denoising autoencoders. Neural compu-
tation, 23(7):1661-1674, 2011.
Jianwen Xie, Yang Lu, Ruiqi Gao, Song-Chun Zhu, and Ying Nian Wu. Cooperative training of
descriptor and generator networks. arXiv preprint arXiv:1609.09408, 2016a.
Jianwen Xie, Yang Lu, Song-Chun Zhu, and Yingnian Wu. A theory of generative convnet. In
International Conference on Machine Learning, pp. 2635-2644, 2016b.
Jianwen Xie, Zilong Zheng, Xiaolin Fang, Song-Chun Zhu, and Ying Nian Wu. Cooperative training
of fast thinking initializer and slow thinking solver for multi-modal conditional learning. arXiv
preprint arXiv:1902.02812, 2019.
Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong Xiao. Lsun:
Construction of a large-scale image dataset using deep learning with humans in the loop. arXiv
preprint arXiv:1506.03365, 2015.
Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. arXiv preprint
arXiv:1605.07146, 2016.
Junbo Zhao, Michael Mathieu, and Yann LeCun. Energy-based generative adversarial network.
arXiv preprint arXiv:1609.03126, 2016.
12
Published as a conference paper at ICLR 2021
A	Extended derivations
A. 1 Derivation of equation 5
Let X = X + σe, where E 〜N(0, I). Given the marginal distribution of
Pθ(x) = ɪ exp(fθ(x)),	(18)
Zθ
We can derive the conditional distribution of X given X as
pθ (χ∣x) = pθ (X)P(X∣χ)∕p(x)	(19)
=1r eχp(fθ(x))	12 n eχp(- 12k∣∣x - xk2"p(X)	QO)
Zθ	(2πσ2) 2	2σ2
= ^1-eχp ffθ(X) 一 χ12 l∣x — x∣2) ,	QI)
Zθ(x)	∖	2σ2	)
where We absorb all the terms that are irrelevant of X as Zθ(X).
A.2 Theoretical understanding
In this subsection, we analyze the asymptotic behavior of maximizing the recovery log-likelihood.
For model class {pθ(x), ∀θ}, suppose there exists θ* such that Pdata = pθ* . According to the
classical theory of MLE, let θ0 be the point estimate by MLE. Then we have θ is an unbiased
estimator of θ* with asymptotic normality:
√n(θo - θ*) →N(0,I0(θ*)-1),	(22)
where Io(θ) = Ex〜p@ [-^2 logpθ (x)] is the Fisher information, and n is the number of observed
samples.
Let θ be the point estimate given by maximizing recovery log-likelihood, we can derive a result in
parallel to that of MLE:
√n(θ - θ*) → N(0,I(θ*)-1),	(23)
where I(θ) = Epθ(x,x) [-V2 logpθ(x|X)]. The relationship between I0(θ) and I(θ) is that
Io(θ) = I (θ) + Epθ(x,x)[-V2 log pθ (X)].	(24)
Thus there is loss of information, but θ is still an unbiased estimator of θ with asymptotic normality.
A.3 Detailed derivation of normal approximation
-Eθ (XIX) = fθ (X) - 2σ2 ι∣x - x∣2	(25)
=fθ(X) + hVxfθ(X), X - Xi - 12k∣∣x - X∣2	(26)
2σ2
=-2σ2 IjlXk2 - 2(x, Xi + ∣∣x∣∣2] + hVxfθ(X), X)一 hVxfθ(X), Xi + fθ(X)	(27)
=-2σσ2 [∣∣x∣∣2- 2hX + σ2Vxfθ(X), x)] - 2σ2∣x∣2-hVxfθ(X), X) + fθ(X) (28)
=-+[∣x - (X + σ2Vxfθ(X))∣2]+ c,	(29)
A.4 DIFFERENCE BETWEEN THE SCORES OF p(x) AND p(X)
For notation clarity, with X = X + e, we let Pbe the distribution of X, and P be the distribution of x.
Then for a smooth testing function with vanishing tails,
E[h(X)] = E[h(x + e)]	(30)
=. E[h(X) + h0(X)E + h00(X)E2∕2]	(31)
= E[h(X)] + E[h00(X)]σ2∕2.	(32)
13
Published as a conference paper at ICLR 2021
Integral by parts,
E[h00(x)] =	h00(x)p(x)dx = -	h0(x)p0(x)dx=	p00(x)h(x)dx.
Thus we have the heat equation
Pe(X) = p(x) + p00(x)σ2∕2.
The score
▽x logp(x) = Nx logp(x) + Vχ log(1 + p00(x)∕p(x)σ2∕2)
=Vχ log p(x) + Vχ[p00(x)∕p(x)]σ2/2.
(33)
(34)
(35)
(36)
Thus the difference between the score of p and peis of the order σ2, which is negligible when σ2 is
small.
A.5 Learning gradients of normal approximation and original recovery
LIKELIHOOD
In this subsection we demonstrate that the learning gradient of maximizing likelihood of the normal
approximation is approximately the same as the gradient of maximizing the original recovery likeli-
hood with one step of Langevin sampling. Specifically, the gradient of the normal approximation of
recovery log-likelihood for an observed Xobs is
vθ (+[kxobs - (X + σ2fθ (X))k2]) = vθ fθ (X)(Xobs - (X + σ2fθ(X)).	(37)
On the other hand, to maximize the original recovery likelihood, suppose We sample Xsyn 〜
pθ (x∣X), then the gradient ascent of the original recovery log-likelihood is
Vθfθ(Xobs) - E[Vθfθ(Xsyn)] = hθ(Xobs) - E[hθ(Xsyn)],	(38)
where hθ(x) = Vθfθ(x). Approximately, if we perform one step of Langevin dynamics from X to
obtain xsyn, i.e., Xsyn = X + σ2fθ (X) + √2σe, and assume fθ(x) is locally linear in x, then
Vθfθ(Xobs) - E[Vθfθ(Xinit)]	(39)
=hθ (Xobs) — E[hθ (X + σ2fθ (X) + σe)]	(40)
=hθ (X) + hθ (X)(xobs — X) — E[hθ (X) + hθ (X)(σ2fθ (X) + σe)]	(41)
=hθ (X)(xobs — (X + σ2fθ (X))	(42)
=Vθ fθ (X)(xobs — (X + σ2fθ (X)).	(43)
Comparing equations 37 and 43, we see that the two gradients agree with each other.
A.6 Estimating the partition function
We can utilize the sequence of learned distributions ofyt (=	1 — σt2+1Xt) to estimate the partition
function. Specifically, the marginal distribution of yt is
pθ (yt) = 1— exp (fθ (yt,t))
Zθ,t
(44)
We can estimate the ratio of the partition functions at two consecutive time steps using importance
sampling
Zθ t
ZiT=Epθ(yt+ι) [exp(fθ (y,t)-fθ (y,t+1))]
1M
M E [exp(fθ (yt+ι,i,t) — fθ (yt+ι,i,t +1))],
i=1
(45)
(46)
14
Published as a conference paper at ICLR 2021
where yt+1,i are samples generated by progressive sampling. Starting from t = T, where pT (x) fol-
lows Gaussian distribution, we can compute log Zθ,t along the reverse path of the diffusion process,
until we reach t = 0:
Zθ,0
T-1
Zθ,τ∏ T
(47)
In practice, since the ratio given by MCMC samples can vary across many orders of magnitude, it is
more meaningful to estimate
T-1
log Zθ,o = log Zθ,t + X log	θ,t
t=0	Zθ,t+1
(48)
Unfortunately, although equation 46 is an unbiased estimator of Zθ,t∕Zθ,t+ι, the logarithm of this
estimator is generally a stochastic lower bound of log(Zθ,t∕Zθ,t+1) (Grosse et al., 2016). However,
as We show below, this bound will gradually converge to an unbiased estimator of log(Zθ,t∕Zθ,t+ι),
as the number of samples becomes large. Specifically, let A be the estimator in equation 46, μ be
the true value of Zθ,t∕Zθ,t+ι. We have E[A] = μ, then by second order Taylor expansion,
Eilog A] = E log μ + μ(A - μ) - 2μ2(A - μ)2
=log μ — 工 Var(A).
2μ2
(49)
(50)
By law of large number, Var(A) → 0 as M → ∞, and thus E[log A] → log μ. This is also
consistent with the estimation curves in the right subfigure of Figure 7: since Var(A) ≥ 0, the
estimation curve increases from below as the number of samples becomes larger. When the curve
becomes stable, it indicates the convergence.
B Experimental details
Model architecture. Our network structure is based on Wide ResNet (Zagoruyko & Komodakis,
2016). Table 5 lists the detailed network structures of various resolutions. The number of ResBlocks
at every level N is a hyperparameter that we sweep over. The values of N for various datasets are
listed in Table 6. Each ResBlock consists of two Conv2D layers. For the second Conv2D layer,
we use zero initialization for the weights, and add a trainable channel-wise scaling parameter to the
output. We remove the weight normalization, and use leaky ReLU (slope = 0.2) as the activation
function in ResBlocks. Spectral normalization (Miyato et al., 2018) is used to regularize parameters
in Conv2D layer, ResBlocks and Dense layer. For encoding time step t, we follow the scheme in
(Ho et al., 2020). Specifically, the time step t is first transformed into sinusoidal embedding, and
then two Dense layers is added. The time embedding is added after the first Conv2D layer of each
ResBlock.
Training. We use Adam (Kingma & Ba, 2014) optimizer for all the experiments. We find that
for high resolution images, using a smaller β1 in Adam help stabilize training. We use learning rate
0.0001 for all the experiments. For the values of β1, batch sizes and the number of training iterations
for various datasets, see Table 6.
Datasets. We use the following datasets in our experiments: CIFAR-10 (Krizhevsky et al., 2009),
CelebA (Liu et al., 2018) and LSUN (Yu et al., 2015). CIFAR-10 is of resolution 32 × 32, and
contains 50, 000 training images and 10, 000 test images. CelebA contains 202,599 face images, of
which 162,770 are training images and 19,962 are test images. For processing, we first clip each
image to 178 X 178 and then resize it to 64 X 64. For LSUN, we use ChUrCh.outdoor and bedroom
categories, which contains 126,227 and 3,033,042 training images respectively. Both categories
contain 300 test images. For processing, we first crop each image to a square image of the smaller
size among the height and weight, and then we resize it to 64 X 64 or 128 X 128. For resizing, we
set antialias to True. We apply horizontal random flip as data augmentation for all datasets during
training.
15
Published as a conference paper at ICLR 2021
Evaluation metrics. We use FID and inception scores as quantitative evaluation metrics of sample
quality. On all the datasets, we calculate FID and inception scores on 50,000 samples using the
original code from Salimans et al. (2016) and Heusel et al. (2017).
Table 5: Model architectures of various solutions. N is a hyperparameter that we sweep over.
(a) Resolution 32 × 32 3 X 3 Conv2D,128	(b) Resolution 64 × 64 3 × 3 Conv2D, 128	(c) Resolution 128 × 128 3 × 3 Conv2D, 128
N ResBloCks,128 Downsample 2 × 2	N ResBlocks, 128 Downsample 2 × 2	N ResBlocks, 128 Downsample 2 × 2
N ResBlocks, 256 Downsample 2 × 2	N ResBlocks, 256 Downsample 2 × 2	N ResBlocks, 256 Downsample 2 × 2
N ResBlocks, 256 Downsample 2 × 2	N ResBlocks, 256 Downsample 2 × 2	N ResBlocks, 256 Downsample 2 × 2
N ResBlocks, 256	N ResBlocks, 256	N ResBlocks, 256
ReLU, global sum Dense 1	Downsample 2 × 2	Downsample 2 × 2
	N ResBlocks, 512	N ResBlocks, 512
	ReLU, global sum Dense 1	Downsample 2 × 2
		N ResBlocks, 512
		ReLU, global sum Dense 1
(d) Time embedding (temb)	(e) ResBlock		
sinusoidal embedding	leakyReLU, 3		× 3 Conv2D
Dense, leakyReLU	+ Dense(leakyReLU(temb))		
Dense	IeakyReLU, 3	× 3 Conv2D
+ input		
Table 6: Hyperparameters of various datasets.
Dataset	N	β1 in Adam	Batch size	Training iterations
CIFAR-10	8	0.9	256	240k
CelebA	6	0.5	128	880k
LSUN ChurCh.outdoor 642	2	0.9	128	960k
LSUN bedroom 642	2	0.9	128	760k
LSUN ChUrCh.outdoor 1282	2	0.5	64	840k
LSUN bedroom 1282	5	0.5	64	580k
C Additional experimental results
C.1 FID scores over iterations
Figure 9 demonstrates FID scores computed on 2,500 samples every 15,000 iterations.
C.2 Long-run Chain sampling with NUTS
As a further check, we use a No-U-Turn Sampler (Hoffman & Gelman, 2014) to perform the long-
run chain sampling, with the same step size schedule obtained for HMC sampler. Figure 10 displays
samples with different number of sampling steps. The samples remain realistic after 100k sampling
steps in total and the FID score remains stable.
16
Published as a conference paper at ICLR 2021
Iteration (×103)

Figure 9: FIDs for different number of Langevin steps.
C
Additional interpolation results
11, 12 and 13
display more examples of interpolation between two generated samples on
CelebA 642, LSUN ChUrch.outdoor 1282 and LSUN bedroom 1282.
Figure 11: Interpolation results between the leftmost and rightmost generated samples on CelebA
64 × 64.

17
Published as a conference paper at ICLR 2021
SB0EE LJH33∣⅛33∣3iSS 当
Figure 13: Interpolation results between the leftmost and rightmost generated samples on LSUN
bedroom 128 × 128.
C.4 Additional image inpainting results
Figures 14 and 15 show additional examples of image inpainting on CelebA 642 and LSUN
ChUrCh.outdoor 1282.
C.5 Additional uncurated samples
Figures 16, 17, 18, 19, 20 and 21 show unCurated samples from the learned models under T6
setting on CIFAR-10, CelebA 642, LSUN ChUrCh.outdoor 1282, LSUN bedroom 1282, LSUN
ChUrCh.outdoor 642 and LSUN bedroom 642 datasets.
18
Published as a conference paper at ICLR 2021
Figure 14: Image inpainting results on CelebA 64 × 64. Top: masked images, bottom: inpainted
images.
Figure 15: Image inpainting results on LSUN Church.outdoor 128 X 128. Top: masked images,
bottom: inpainted images.
19
Published as a conference paper at ICLR 2021
Figure 16: Generated samples on CIFAR-10.
20
Published as a conference paper at ICLR 2021
Figure 17: Generated samples on CelebA 64 × 64.
21
Published as a conference paper at ICLR 2021
Figure 18: Generated samples on LSUN ChurCh.outdoor 128 X 128. FID=9.76
22
Published as a conference paper at ICLR 2021
Figure 19: Generated samples on LSUN bedroom 128 × 128. FID=11.27
23
Published as a conference paper at ICLR 2021
Figure 20: Generated samples on LSUN ChUrCLoUtdoor 64 × 64. FID=7.02
24
Published as a conference paper at ICLR 2021
Figure 21: Generated samples on LSUN bedroom 64 × 64. FID=8.98
25