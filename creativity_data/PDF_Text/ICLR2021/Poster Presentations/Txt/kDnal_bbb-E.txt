Published as a conference paper at ICLR 2021
DialoGraph: Incorporating Interpretable
Strategy-Graph Networks into
Negotiation Dialogues
Rishabh Joshi, Vidhisha Balachandran, Shikhar Vashishth, Alan W Black, Yulia Tsvetkov
Language Technologies Institute
Carnegie Mellon University
{rjoshi2, vbalacha, svashish, awb, ytsvetko}@cs.cmu.edu
Ab stract
To successfully negotiate a deal, it is not enough to communicate fluently: prag-
matic planning of persuasive negotiation strategies is essential. While modern
dialogue agents excel at generating fluent sentences, they still lack pragmatic
grounding and cannot reason strategically. We present DialoGraph, a nego-
tiation system that incorporates pragmatic strategies in a negotiation dialogue us-
ing graph neural networks. DialoGraph explicitly incorporates dependencies
between sequences of strategies to enable improved and interpretable prediction
of next optimal strategies, given the dialogue context. Our graph-based method
outperforms prior state-of-the-art negotiation models both in the accuracy of strat-
egy/dialogue act prediction and in the quality of downstream dialogue response
generation. We qualitatively show further benefits of learned strategy-graphs in
providing explicit associations between effective negotiation strategies over the
course of the dialogue, leading to interpretable and strategic dialogues.1
1 Introduction
Negotiation is ubiquitous in human interaction, from e-commerce to the multi-billion dollar sales
of companies. Learning how to negotiate effectively involves deep pragmatic understanding and
planning the dialogue strategically (Thompson; Bazerman et al., 2000b; Pruitt, 2013).
Modern dialogue systems for collaborative tasks such as
restaurant or flight reservations have made considerable
progress by modeling the dialogue history and structure
explicitly using the semantic content, like slot-value pairs
(Larionov et al., 2018; Young, 2006), or implicitly with
encoder-decoder architectures (Sordoni et al., 2015; Li
et al., 2016). In such tasks, users communicate explicit
intentions, enabling systems to map the utterances into
specific intent slots (Li et al., 2020). However, such map-
ping is less clear in complex non-collaborative tasks like
negotiation (He et al., 2018) and persuasion (Wang et al.,
2019), where user intent and most effective strategies are
hidden. Hence, along with the generated dialogue, the
strategic choice of framing and the sequence of chosen
strategies play a vital role, as depicted in Figure 1. In-
deed, prior work on negotiation dialogues has primarily
focused on optimizing dialogue strategies—from high-
level task-specific strategies (Lewis et al., 2017), to more
Buyer (Human)
My younger bro loves old classics.
/l I , m looking to buy a vinyl player.
Family,
informal
Propose I'm asking 40 for it. ⅛⅛a^
I Damn. That's too much for a	Negative,
“ StUdentlike me. How about 30?	Propose
w w/o Strategy	Not possible. I can do 35.1
O	You' ll have to pick it up. p∖
¾
R	5 Reject I
/ Strategy
Family,
informal,
propose,
trade-in	I------1
:ACCept I
I can do 38 and I' ll throw a coupl(
of Beatles records for your bro.
Seller (BOt)
Figure 1: Both options are equally plausi-
ble and fluent, but a response with effective
pragmatic strategies leads to a better deal.
specific task execution planning (He et al., 2018), to fine-grained planning of linguistic outputs given
1Code, data and a demo system is released at https://github.com/rishabhjoshi/
DialoGraph_ICLR21
1
Published as a conference paper at ICLR 2021
strategic choices (Zhou et al., 2019). These studies have confirmed that it is crucial to control for
pragmatics of the dialogue to build effective negotiation systems.
To model the explicit dialogue structure, prior work incorporated Hidden Markov Models (HMMs)
(Zhai & Williams, 2014; Ritter et al., 2010), Finite State Transducers (FSTs) (Zhou et al., 2020) and
RNNs (He et al., 2018; Shi et al., 2019). While RNN-based models lack interpretability, HMM-
and FST-based approaches may lack expressivity. In this paper, we hypothesize that Graph Neural
Networks (GNNs) (Wu et al., 2020) can combine the benefits of interpretability and expressivity be-
cause of their effectiveness in encoding graph-structured data through message propagation. While
being sufficiently expressive to model graph structures, GNNs also provide a natural means for
interpretation via intermediate states (Xie & Lu, 2019; Pope et al., 2019).
We propose DialoGraph, an end-to-end negotiation dialogue system that leverages Graph At-
tention Networks (GAT) (Velickovic et al., 2018) to model complex negotiation strategies while
providing interpretability for the model via intermediate structures. DialoGraph incorporates the
recently proposed hierarchical graph pooling based approaches (Ranjan et al., 2020) to learn the as-
sociations between negotiation strategies, including conceptual and linguistic strategies and dialogue
acts, and their relative importance in predicting the best sequence. We focus on buyer-seller nego-
tiations in which two individuals negotiate on the price of an item through a chat interface, and we
model the seller’s behavior on the CraigslistBargain dataset (He et al., 2018).2 We demonstrate that
DialoGraph outperforms previous state-of-art methods on strategy prediction and downstream
dialogue responses. This paper makes several contributions. First, we introduce a novel approach to
model negotiation strategies and their dependencies as graph structures, via GNNs. Second, we in-
corporate these learned graphs into an end-to-end negotiation dialogue system and demonstrate that
it consistently improves future-strategy prediction and downstream dialogue generation, leading to
better negotiation deals (sale prices). Finally, we demonstrate how to interpret intermediate struc-
tures and learned sequences of strategies, opening-up the black-box of end-to-end strategic dialogue
systems.
2	DialoGraph
We introduce DialoGraph, a modular end-to-end dialogue system, that incorporates GATs with
hierarchical pooling to learn pragmatic dialogue strategies jointly with the dialogue history. Dialo-
Graph is based on a hierarchical encoder-decoder model and consists of three main components:
(1) hierarchical dialogue encoder, which learns a representation for each utterance and encodes its
local context; (2) structure encoder for encoding sequences of negotiation strategies and dialogue
acts; and (3) utterance decoder, which finally generates the output utterance. Formally, our dialogue
input consists of a sequence of tuples, D = [(u1, da1 , ST1), (u2, da2, ST2), ..., (un, dan, STn)]
where ui is the utterance, dai is the coarse dialogue act and STi = {sti,1, sti,2, . . . , sti,k} is the set
of k fine-grained negotiation strategies for the utterance ui.3 The dialogue context forms the input
to (1) and the previous dialogue acts and negotiation strategies form the input to (2). The overall
architecture is shown in Figure 2. In what follows, we describe DialoGraph in detail.
2.1	hierarchical dialogue encoder
A dialogue context typically comprises of multiple dialogue utterances which are sequential in na-
ture. We use hierarchical encoders for modeling such sequential dialogue contexts (Jiao et al., 2019).
To encode the utterance ut at time t, we use the pooled representations from BERT (Devlin et al.,
2019) to obtain the corresponding utterance embedding et . We then pass the utterance embeddings
through a GRU to obtain the dialogue context encoding till time t, denoted by htU.
2We focus on the seller’s side following Zhou et al. (2019) who devised a set of strategies specific to
maximizing the seller’s success. Our proposed methodology, however, is general.
3For example, in an utterance Morning! My bro destroyed my old kit and I’m looking for a new pair for $10,
the coarse dialogue act is Introduction, and the finer grained negotiation strategies include Proposing price,
Being informal and Talking about family for building rapport.
2
Published as a conference paper at ICLR 2021
Feed
Fo ιward
〈Oss ue5≡-!"Mo-φq-1=s
.lepouuW gue,lwlɔ
Figure 2: Overview of DIALOGRAPH. At time t, utterance ut is encoded using BERT and then
passed to the Dialogue Context Encoder to generate the dialogue representation. This representation
is enriched with the encodings of explicit strategy and dialogue act sequences using the structure
encoders which is then used to condition the Utterance decoder. Please refer to §2 for details.
' utterance
Add & NOnm
Add & NOrm
MUlti-H ead
Attention
1 (uι)
2.2	structure encoder
Our structure encoder is designed to model the graph representations of the strategies and dialogue
acts using GATs and output their structural representations. These structural representations are used
to predict the next set of strategies and dialogue acts and enrich the encoded dialogue representation.
Below we describe the structure encoder for negotiation strategies.
We model the sequence of negotiation strategies, ST = [ST1, ST2, . . . , STt] by creating a directed
graph, where STi is the set of k fine-grained negotiation strategies for the utterance ui . Formally,
we define a graph G(V, E, X) with |E| edges and N = |V| nodes where each node vi ∈ V represents
a particular negotiation strategy for an utterance and has a d-dimensional feature representation
denoted by zi . Z ∈ RN ×d denotes the feature matrix of the nodes and A ∈ RN ×N represents
the adjacency matrix, where N is the total number of nodes (strategies) that have occurred in the
conversation till that point. Therefore, each node represents a strategy-utterance pair.
We define the set of edges as E = {(a, b)}; a, b ∈ V where a and b denote strategies at utterances
ua and ub , present at turns ta and tb, such that tb > ta . In other words, we make a directed edge
from a particular node (strategy in an utterance) to all the consecutive nodes. This ensures a direct
connection from all the previous strategies to the more recent ones.4 In the same way, we form the
graph out of the sequence of dialogue acts. These direct edges and learned edge attention weights
help us interpret the dependence and influence of strategies on each other.
To get the structural representations from the strategy graphs, we pass them through a hierarchical
graph pooling based encoder, which consists of l layers of GAT, each followed by the Adaptive
Structure Aware Pooling (ASAP) layer (Ranjan et al., 2020). As part of the ASAP layer, the model
first runs GAT over the input graph representations to obtain structurally informed representations
of the nodes. Then a cluster assignment step is performed which generates a cluster assignment
matrix, S, which tells the model which nodes come in a similar structural context. After that, the
clusters are ranked and then the graph is pooled by taking the top few clusters as new nodes and
forming edges between them using the existing graph. This way the size of the graph is reduced
at every step which leads to a structurally informed graph representation. We take advantage of
the cluster formulation to obtain the associations between the negotiation strategies, as identified
from the cluster assignment matrix, S. These association scores can later be used to interpret which
strategies are associated with each other and tend to co-occur in similar contexts. Moreover, we
also use the node attention scores from GAT to interpret the influence of different strategies on the
4Appendix C shows an example of the graph obtained from a sequence of strategies.
3
Published as a conference paper at ICLR 2021
representation of a particular strategy, which essentially gives the dependence information between
strategies.
In this way, the structure representation is learned and accumulated in a manner that preserves the
structural information (Ying et al., 2018; Lee et al., 2019). After each pooling step, the graph
representation is summarized using the concatenation of mean and max of the node representations.
The summaries are then added and passed through fully connected layers to obtain the final structural
representation of the strategies htST . We employ a similar structure encoder to encode the graph
obtained from the sequence of dialogue acts, to obtain htda.
2.3	utterance decoder
The utterance decoder uses the dialogue context representation and structural representations of
dialogue acts and negotiation strategies to produce the dialogue response (next utterance). We en-
rich the dialogue representation by concatenating the structural representations before passing it to
a standard greedy GRU (Cho et al., 2014) decoder. This architecture follows Zhou et al. (2020),
who introduced a dynamic negotiation system that incorporates negotiation strategies and dialogue
acts via FSTs. We thus follow their utterance decoder architecture to enable direct baseline com-
parison. For the jth word of utterance ut+1, wtj+1, we condition on the previous word wtj+-11 to
calculate the probability distribution over the vocabulary as ptw+j1 = softmax(GRU(ht, wtj+-11))
where ht = [htu; htST; htda] and [; ] represents the concatenation operator. For encoding the price,
we replace all price information in the dataset with placeholders representing the percentage of the
offer price. For example, we would replace $35 with < price - 0.875 > if the original selling price
is $40. The decoder generates these placeholders which are then replaced with the calculated price
before generating the utterance.
2.4	model training
We use htST to predict the next set of strategies STt+1, a binary value vector which represents
the k-hot representation of negotiation strategies for the next turn. We compute the probability
of the jth strategy occurring in ut+1 as p(stt+1,j |htST) = σ(htST). where σ denotes the sig-
moid operator. We threshold the probability by 0.5 to obtain the k-hot representation. We de-
note the weighted negative log likelihood of strategies LST as the loss function of the task of
next strategy prediction LST = -Pj δj log(p(stt+1,j)) - Pk log(1 - p(stt+1,k)) where the
summation of j are over the strategies present (st0t+1,j = 1) and not present (st0t+1,k = 0) in
the ground truth strategies set, ST0 . Here δj is the positive weight associated with the particular
strategy. We add this weight to the positive examples to trade off precision and recall. We put
δj = # of instances not having strategy j/# of instances having strategy j.
Similarly, we use htda to predict the dialogue act for the next utterance dat+1. Given the target
dialogue act da0t+1 and the class weights ρda for the dialogue acts, we denote the class-weighted
cross entropy loss over the set of possible dialogue acts, LDA = -ρda log(softmax(htda)) . We
pass ht = [htu ; htST ; htda] through a linear layer to predict the negotiation success, which is
denoted by the sale-to-list ratio r = (sale price - buyer target price)/(listed price - buyer target price)
(Zhou et al., 2019). We split the ratios into 5 negotiation classes of equal sizes using the train-
ing data and use those to predict the success of negotiation. Therefore, given the predicted
probabilities for target utterance u0t+1 from §2.3, target ratio class yr0 and the learnable param-
eters Wr and br, we use the cross entropy loss as the loss for the generation task (LNLG) as
well as the negotiation outcome prediction task (LR), thus LNLG = - Pw ∈u0 log(ptw+j 1) and
LR = - Pr∈[1,5] yr0 log(softmax(Wrht + br)). The LR loss optimizes for encoding negotiation
strategies to enable accurate prediction of negotiation outcome.
We use hyperparameters α, β and γ to optimize the joint loss Ljoint , of strategy prediction, dialogue
act prediction, utterance generation and outcome prediction together, using the Adam optimizer
(Kingma & Ba, 2014), to get Ljoint = LNLG + αLST + βLDA + γLR.
4
Published as a conference paper at ICLR 2021
3	Experimental Setup
Dataset: We use the CraigslistBargain dataset5 (He et al., 2018) to evaluate our model. The
dataset was created using Amazon Mechanical Turk (AMT) in a negotiation setting where two work-
ers were assigned the roles of buyer and seller respectively and were tasked to negotiate the price
of an item on sale.The buyer was additionally given a target price. Both parties were encouraged to
reach an agreement while each of the workers tried to get a better deal. We remove all conversations
with less than 5 turns. Dataset statistics are listed in Table 11 in the Appendix.
We extract from the dataset the coarse dialogue acts as described by He et al. (2018). This includes
a list of 10 utterance dialogue acts, e.g., inform, agree, counter-price. We augment this list by
4 outcome dialogue acts, namely, hofferi, haccepti, hrejecti and hquiti, which correspond to the
actions taken by the users. Negotiation strategies are extracted from the data following Zhou et al.
(2019). These include 21 fine-grained strategies grounded in prior economics/behavioral science
research on negotiation (Pruitt, 2013; Bazerman & Neale, 1993; Bazerman et al., 2000a; Fisher et al.,
2011; Lax & Sebenius, 2006; Bazerman et al., 2000b), e.g, negotiate side offers, build rapport, show
dominance. All dialogue acts and strategies are listed in Appendices A and B.
Baselines: DialoGraph refers to our proposed method. To corroborate the efficacy of DI-
aloGraph, we compare it against our implementation of the present state-of-the-art model for the
negotiation task: FST-enhanced hierarchical encoder-decoder model (FeHED) (Zhou et al., 2020)
which utilizes FSTs for encoding sequences of strategies and dialogue acts.6 We also conduct and
ablation study, and evaluate the variants of DialoGraph with different ways of encoding nego-
tiation strategies, namely, HED, HED+RNN, and HED+Transformer. HED completely ignores
the strategy and dialogue act information, whereas HED+RNN and HED+Transformer encode them
using RNN and Transformers (Vaswani et al., 2017) respectively. While HED+RNN is based on
the dialogue manager of He et al. (2018), HED+Transformer has not been proposed earlier for this
task. For a fair comparison, we use a pre-trained BERT (Devlin et al., 2019) model as the utterance
encoder (§2.1) and a common utterance decoder (§2.4) in all the models, and only vary the struc-
ture encoders as described above. The strategies and dialogue acts in RNN and Transformer based
encoders are fed as sequence of k-hot vectors.
Evaluation Metrics: For evaluating the performance on the next strategy prediction and the next
dialogue act prediction task, we report the F1 and ROC AUC scores for all the models. For these
metrics, macro scores tell us how well the model performs on less frequent strategies/dialogue acts
and the micro performance tells us how good the model performs overall while taking the label
imbalance into account. Strategy prediction is a multi-label prediction problem since each utterance
can have multiple strategies. For the downstream tasks of utterance generation, we compare the
models using BLEU score (Papineni et al., 2002) and BERTScore (Zhang et al., 2020). Finally,
we also evaluate on another downstream task of predicting the outcome of negotiation, using the
ratio class prediction accuracy (RC-Acc) (1 out of 5 negotiation outcome classes, as described in
§2.4). Predicting sale outcome provides better interpretability over the progression of a sale and
potentially control to intervene when negotiation has a bad predicted outcome. Additionally, being
able to predict the sale outcome with high accuracy shows that the model encodes the sequence of
negotiation strategies well.
4	Results
We evaluate (1) strategy and dialogue act prediction (intrinsic evaluation), and (2) dialogue genera-
tion and negotiation outcome prediction (downstream evaluation). For all metrics, we perform boot-
strapped statistical tests (Berg-Kirkpatrick et al., 2012; Koehn, 2004) and we bold the best results for
a metric in all tables (several results are in bold if they have statistically insignificant differences).
Strategy and Dialogue Act Prediction: We compare DIALOGRAPH’s effectiveness in encoding
the explicit sequence of strategies and dialogue acts with the baselines, using the metrics described
in §3. Table 1 shows that DialoGraph performs on par with the Transformer based encoder in
5https://github.com/stanfordnlp/cocoa/tree/master/craigslistbargain
6We replace the utterance encoder with BERT for fair comparison. This improved slightly the performance
of the FeHED model compared to results published in Zhou et al. (2020).
5
Published as a conference paper at ICLR 2021
Table 1: Performance of the next strategy and dialogue-act prediction of various models. We report
the F1 and ROC AUC scores. Significance tests were performed as described in §4 and the best
results (along with all statistically insignificant values) are bolded.
Model	Negotiation Strategies						Dialogue Acts				
	F1			ROC AUC			F1			ROC AUC	
	Macro	Micro	Weighted	Macro	Micro	Weighted	Macro	Micro	Weighed	Macro	Weighed
FeHED	17.6	25.6	36.3	55.8	61.7	54.7	20.6	37.4	30.6	76.9	79.2
HED+RNN	23.2	26.7	42.4	65.3	65.3	60.4	33.0	46.2	42.8	83.1	84.2
HED+Transformer	26.3	32.1	43.3	68.2	71.8	61.8	32.5	44.6	42.0	85.6	85.1
DialoGraph	26.1	34.1	43.5	68.1	73.0	61.8	33.4	45.8	43.7	85.6	85.4
strategy prediction macro scores and outperforms it on other metrics. Moreover, both significantly
outperform the FST-based based method, prior state-of-the-art. We hypothesize that lower gains
for dialogue acts are due to the limited structural dependencies between them. Conversely, we
validate that for negotiation strategies, RNNs are significantly worse than DialoGraph. We also
observe that higher macro scores show that DialoGraph and Transformers are able to capture
the sequences containing the less frequent strategies/dialogue acts as well. These results supports
our hypothesis of the importance to encode the structure in a more expressive model. Moreover,
DialoGraph also provides interpretable structures which the other baselines do not. We will
discuss these findings in §5.
Automatic Evaluation on Downstream tasks: In this section, we analyze the impact of DIALO-
Graph on the downstream task of Negotiation Dialogue based on the automatic evaluation metrics
described in §3. In Table 2, we show that DialoGraph helps improve the generation of dialogue
response. Even though DialoGraph attains higher BLEU scores, we note that single-reference
BLEU assumes only one possible response while dialogue systems can have multiple possible re-
sponses to the same utterance. BERTScore alleviates this problem by scoring semantically similar
responses equally high (Zhang et al., 2020). We also find that both Transformer and DialoGraph
have a comparable performance for negotiation outcome prediction, which is significantly better
than the previously published baselines (FeHED and HED+RNN). A higher performance on this
metric demonstrates that our model is able to encode the strategy sequence better and consequently
predict the negotiation outcome more accurately. Additionally, ablation results in Table 3 show that
both strategy and dialogue act information helps DialoGraph in improving dialogue response.
The difference in BERTScore F1 scores in Tables 2 and 3 arises due to different metrics chosen for
early stopping. More details in Appendix D.
Although, both HED+Transformer and DialoGraph are based on attention mechanisms, Dialo-
Graph has the added advantage of having structural attention which helps encode the pragmatic
structure of negotiation dialogues which in turn provides an interpretable interface. The compo-
nents in our graph based encoder such as the GAT and ASAP layer provide strategy influence and
cluster association information which is useful to understand and control negotiation systems. This
is described in more detail in §5. Though transformers have self attention, the architecture is limited
and doesn’t model the structure/dependence between strategies providing only limited understand-
ing. Further, our results show that DialoGraph maintains or improves performance over strong
models like Transformer and has much more transparent interpretability. We later show that Di-
aloGraph performs significantly better than HED+Transformer in human evaluation.
Human Evaluation: Since automatic metrics only give us a partial view of the system, we com-
plement our evaluation with detailed human evaluation. For that, we set up DialoGraph and the
baselines on Amazon Mechanical Turk (AMT) and asked workers to role-play the buyer and ne-
gotiate with a single bot. After their chat is over, we ask them to fill a survey to rate the dialogue
on how persuasive (My task partner was persuasive.), coherent (My task partner’s responses were
on topic and in accordance with the conversation history.), natural (My task partner was human-
like.) and understandable (My task partner perfectly understood what I was typing.) the bot was 7.
Prior research in entailment has shown that humans tend to get better as they chat (Mizukami et al.,
2016; BenUs et al., 2011) and so We restrict one user to Chat with just one of the bots. We further
7We use the setup of https://github.com/stanfordnlp/cocoa/. Screenshots in Appendix H.
6
Published as a conference paper at ICLR 2021
Table 2: Downstream evaluation of negotiation dia- logue generation and negotiation outcome prediction. The best results (along with all statistically insignifi- cant values to those) are bolded.						Table 3: DialoGraph ablation analy- sis. This shows that all the different com- ponents provide complementary benefits. We also evaluate without BERT for com- parison with previously published works.	
Model	Generation				Outcome Prediction		
	BLEU	BERTSCore					
		Precision	Recall	F1	RC-Acc	Model	BERT Score F1
HED	20.9	21.8	22.3	22.1	35.2	DIALOGRAPH	27.4
FeHED	23.7	27.1	26.8	27.0	42.3	w/o Strategy (ST)	26.8
HED+RNN	22.5	22.9	22.7	22.8	47.9	w/o ST, Dialogue Acts (DA)	26.3
HED+Transformer	24.4	27.4	28.1	27.7	53.7	w/o ST, DA, BERT	22.7
DialoGraph	24.7	27.8	28.3	28.1	53.1		
Seller (Bot)
Hey, you need a router? Ui
Informal
U4 Great, will it support laptop?
幺 Nah.. few months only. We're moving... U7
D Definitely both .... $X and we're square U5
2 Oh, it SUPPortS multiple devices … u?
u6 Great! Is there any scratch/damage to it?
Trade In
Informal
u3
Positive
Positive
Concern
u4
u6
Buyer (Human)
Figure 3: Visualization of the learnt latent strategy sequences in DialoGraph where bolder edges
represent higher influence. Here we present only a few edges for brevity and visualize min-max nor-
malized attention values as edge weights to analyze the relative ranking of strategies. For example,
for family at u7, informal of u5 has the most influence followed by propose. We present the full
attention map for this example in Figure 5 in the Appendix.
U2 I Yeah, I WaS Iooking at the Apple router.、
3rd Person
Propose
prune conversations which were incomplete potentially due to dropped connections. Finally, we
manually inspect the conversations extracted from AMT to extract the agreed sale price and remove
conversations that were not trying to negotiate at all.
The results of human evaluations of the resulting 90 dialogues (about 20 per model) are presented
in Table 4. We find that baselines are more likely to accept unfair offers and apply inappropriate
strategies. Additionally, DialoGraph bot attained a significantly higher Sale Price Ratio, which
is the outcome of negotiation, showing that effectively modeling strategy sequences leads to more
effective negotiation systems. Our model also had a higher average total number of turns and words-
per-turn (for just the bots) compared to all baselines, signifying engagement. It was also more
persuasive and coherent while being more understandable to the user. From qualitative inspection
we observe that the HED model generates utterances that are shorter and less coherent. They are
natural responses like “Yes it is”, but generic and contextually irrelevant. We hypothesize that this
is due to the HED model not being optimized to encode the sequence of negotiation strategies
and dialogue acts. We believe that this is the reason for the high natural score for HED. From
manual inspection we see that HED is not able to produce very persuasive responses. We provide an
example ofa dialogue in Appendix F. We see that although HED+Transformer model performs well,
DialoGraph achieves a better sale price outcome as it tries to repeatedly offer deals to negotiate
the price. We see that the HED is unable to understand the user responses well and tends to repeat
itself. Both the FeHED and HED baselines tend to agree with the buyer’s proposal more readily
whereas HED+Transformers and DialoGraph provide counter offers and trade-ins to persuade
the user.
5	Interpreting Learned S trategy Graphs
We visualize the intermediate attention scores generated by the GATs while obtaining the strategy
node representations. These attention scores tell us what strategies influenced the representation of
a particular strategy and can be used to observe the dependence between strategies (cf. Xie & Lu,
7
Published as a conference paper at ICLR 2021
Table 4: Human evaluation ratings on a scale of 1-5 for various models. We also provide the average
sale price ratio (§2.4). Negative ratio means that average sale price was lower than the buyer’s target.
Model	Persuasive	Coherent	Natural	Understandable	Sale Price Ratio	Avg Turns	Avg words/turn
HED	2.50	2.50	4.50	2.50	-2.13	11.00	4.25
FeHED	3.30	3.75	3.70	3.69	0.25	14.30	5.76
HED+RNN	2.81	3.27	3.36	3.27	-3.68	13.90	3.61
HED+Transformer	3.50	3.50	3.70	3.40	-0.07	11.40	4.36
DialoGraph	3.58	3.94	3.75	3.70	0.49	15.72	5.84
Table 5: Examples of strategies and their least / highly associated strategies based on association
scores extracted using the cluster attention scores given by the ASAP layer.
Negotiation Strategy ∣ Least associative strategies	∣ Highly associative strategies
concern hedge propose negative sentiment	certainty (0.1759), trade in (0.228) trade in (0.4367), pos sentiment (0.4501) factive count (0.3878), family (0.416) trade in (0.3089), informal (0.3644)	politeness please (0.7072), politeness gratitude (0.5859) propose (0.5427) friend (0.6218) politeness gratitude (0.5048), trade in (0.5223) family (0.6363), propose (0.6495)
2019; Norcliffe-Brown et al., 2018). We show an example in Figure 3 where for brevity, we present
a subset of few turns and only the top few most relevant edges in the figure. For visualization, we
re-scale the attention values for all incoming edges of a node (strategy) using min-max normaliza-
tion. This is done because the range of raw attention values would differ based on the number of
edges and this allows us to normalize any difference in scales and visualize the relative ranking of
strategies (Yi et al., 2005; Chen & Liu, 2004). We notice that as soon as the first propose at u5 hap-
pens, the strategies completely change and become independent of the strategies before the propose
point. From Figure 3, we see that the edge weight from u4 to u6 is 0.01, signifying very low influ-
ence. We noticed this trend in other examples as well, wherein, the influence of strategies coming
before the first propose turn to strategies coming after that, is very low. A similar phenomenon was
also observed by Zhou et al. (2019) who study the conversations by splitting into two parts based
on the first propose turn. Another interesting thing we note is that the trade-in and propose strate-
gies at u5 seem to be heavily influenced by informal from u3 . Similarly, the informal of u5 was
influenced by positive sentiment from u4 . This indicates that the seller was influenced by previous
informal interactions to propose and trade-in at this turn, and that sellers tend to be more informal
if the conversation partner is positive. In other examples, we see that at a particular utterance, dif-
ferent strategies depend on separate past strategies and also observe that the attention maps usually
demonstrate the strategy switch as soon as the first propose happens, which is similar to what has
been observed by prior work. These examples demonstrate that DialoGraph can model fine-grain
strategies, learn dependence beyond just utterances and give interpretable representations, which
previous baselines, including the FSTs, lack. Specifically, each state of the FST is explicitly rep-
resented by an action distribution which can only be used to see the sequence of strategies and not
observe associations or dependence information which DialoGraph provides.
We utilize these cluster attention scores from the ASAP pooling layer to observe the association
between various strategies which can help us observe strategies with similar contextual behaviour
and structural co-occurrence. We take the average normalized value of the cluster attention scores
between two strategies to obtain the association score between them. In Table 5, we show some
examples of strategies and their obtained association scores. We observe that negative sentiment
tends to be most associated to propose. We hypothesize that this is because that people who disagree
more tend to get better deals. We observe that people do not tend to associate negative sentiment
with trade-in, which is in-fact highly associated with positive sentiment, because people might want
to remain positive while offering something. Similarly, people tend to give vague proposals by
hedging, for instance, I could go lower if you can pick it up, than when suggesting trade-in. Concern
also seems to be least associated with certainty, and most with politeness-based strategies. Thus, we
observe that our model is able to provide meaningful insights which corroborate prior observations,
justifying its ability to learn strategy associations well.
8
Published as a conference paper at ICLR 2021
6	Related Work
Dialogue Systems: Goal-oriented dialogue systems have a long history in the NLP community.
Broadly, goal-oriented dialogue can be categorized into collaborative and non-collaborative sys-
tems. The aim of agents in a collaborative setting is to achieve a common goal, such as travel and
flight reservation (Wei et al., 2018) and information-seeking (Reddy et al., 2019). Recent years
have seen a rise in non-collaborative goal-oriented dialogue systems such as persuasion (Wang
et al., 2019; Dutt et al., 2020; 2021), negotiation (He et al., 2018; Lewis et al., 2017) and strat-
egy games (Asher et al., 2016) due to the challenging yet interesting nature of the task. Prior work
has also focused on decision-making games such as Settlers of Catan (Cuayahuitl et al., 2015) which
mainly involve decision-making skills rather than communication. Lewis et al. (2017) developed the
DealOrNoDeal dataset in which agents had to reach a deal to split a set of items. Extensive work
has been done on capturing the explicit semantic history in dialogue systems (Kumar et al., 2020;
Vinyals & Le, 2015; Zhang et al., 2018). Recent work has shown the advantage of modeling the dia-
logue history in the form of belief span (Lei et al., 2018) and state graphs (Bowden et al., 2017). He
et al. (2018) proposed a bargaining scenario that can leverage semantic and strategic history. Zhou
et al. (2020) used unsupervisedly learned FSTs to learn dialogue structure. This approach, however,
although effective in explicitly incorporating pragmatic strategies, does not leverage the expressive
power of neural networks. Our model, in contrast, combines the interpretablity of graph-based ap-
proaches and the expressively of neural networks, improving the performance and interpretability of
negotiation agents.
Graph Neural Networks: The effectiveness of GNNs (Bruna et al., 2013; Defferrard et al., 2016;
Kipf & Welling, 2017) has been corroborated in several NLP applications (Vashishth et al., 2019),
including semantic role labeling (Marcheggiani & Titov, 2017), machine translation (Bastings et al.,
2017), relation extraction (Vashishth et al., 2018), and knowledge graph embeddings (Schlichtkrull
et al., 2018; Vashishth et al., 2020). Hierarchical graph pooling based structure encoders have been
successful in encoding graphical structures (Zhang et al., 2019). We leverage the advances in GNNs
and propose to use a graph-based explicit structure encoder to model negotiation strategies. Unlike
HMM and FST based encoders, GNN-based encoders can be trained by optimizing the downstream
loss and have superior expressive capabilities. Moreover, they provide better interpretability of the
model as they can be interpreted based on observed explicit sequences (Tu et al., 2020; Norcliffe-
Brown et al., 2018). In dialogue systems, graphs have been used to guide dialogue policy and
response selection. However, they have been used to encode external knowledge (Tuan et al., 2019;
Zhou et al., 2018) or speaker information (Ghosal et al., 2019), rather than compose dialogue strate-
gies on-the-fly. Other works (Tang et al., 2019; Qin et al., 2020) focused on keyword prediction using
RNN-based graphs. Our work is the first to incorporate GATs with hierarchical pooling, learning
pragmatic dialogue strategies jointly with the end-to-end dialogue system. Unlike in prior work,
our model leverages hybrid end-to-end and modularized architectures (Liang et al., 2020; Parvaneh
et al., 2019) and can be plugged as explicit sequence encoder into other models.
7	Conclusion
We present DialoGraph, a novel modular negotiation dialogue system which models pragmatic
negotiation strategies using Graph Attention Networks with hierarchical pooling and learns an ex-
plicit strategy graph jointly with the dialogue history. DialoGraph outperforms strong baselines
in downstream dialogue generation, while providing the capability to interpret and analyze the in-
termediate graph structures and the interactions between different strategies contextualized in the
dialogue. As future work, we would like to extend our work to discover successful (e.g.: good for
the seller) and unsuccessful strategy sequences using our interpretable graph structures.
Acknowledgments
The authors are grateful to the anonymous reviewers for their invaluable feedback, and to Alissa
Ostapenko, Shruti Rijhwani, Ritam Dutt, and members of the Tsvetshop at CMU for their helpful
feedback on this work. The authors would also like to thank Yiheng Zhou for helping with ne-
gotiation strategy extraction and FeHED model. This material is based upon work supported by
the National Science Foundation under Grant No. IIS2007960 and by the Google faculty research
award. We would also like to thank Amazon for providing GPU credits.
9
Published as a conference paper at ICLR 2021
References
Nicholas Asher, Julie Hunter, Mathieu Morey, Benamara Farah, and Stergos Afantenos. Discourse
structure and dialogue acts in multiparty dialogue: the STAC corpus. In Proceedings of the
Tenth International Conference on Language Resources and Evaluation (LREC'16), pp. 2721-
2727, Portoroz, Slovenia, May 2016. European Language Resources Association (ELRA). URL
https://www.aclweb.org/anthology/L16-1432.
Joost Bastings, Ivan Titov, Wilker Aziz, Diego Marcheggiani, and Khalil Sima’an. Graph convolu-
tional encoders for syntax-aware neural machine translation. In Proceedings of the 2017 Confer-
ence on Empirical Methods in Natural Language Processing, pp. 1957-1967, Copenhagen, Den-
mark, September 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1209.
URL https://www.aclweb.org/anthology/D17- 1209.
Max H Bazerman and Margaret Ann Neale. Negotiating rationally. Simon and Schuster, 1993.
Max H Bazerman, Jared R Curhan, Don A Moore, and Kathleen L Valley. Negotiation. Annual
review of psychology, 51(1):279-314, 2000a.
Max H. Bazerman, Jared R. Curhan, Don A. Moore, and Kathleen L. Valley. Negotiation. An-
nual Review of Psychology, 51(1):279-314, 2000b. doi: 10.1146/annurev.psych.51.1.279. URL
https://doi.org/10.1146/annurev.psych.51.1.279. PMID: 10751973.
Stefan Benus, AgUStm Gravano, and Julia HlrSchberg. Pragmatic aspects of temporal accommoda-
tion in turn-taking. Journal of Pragmatics, 43(12):3001-3027, 2011.
Taylor Berg-Kirkpatrick, David Burkett, and Dan Klein. An empirical investigation of statistical
significance in NLP. In Proceedings of the 2012 Joint Conference on Empirical Methods in
Natural Language Processing and Computational Natural Language Learning, pp. 995-1005,
Jeju Island, Korea, July 2012. Association for Computational Linguistics. URL https://www.
aclweb.org/anthology/D12-1091.
Kevin K Bowden, Shereen Oraby, Jiaqi Wu, Amita Misra, and Marilyn Walker. Combining search
with structured data to create a more engaging user experience in open domain dialogue. ICTIR’
17 Workshop on Search-Oriented Conversational AI (SCAI’ 2017), 2017.
Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. Spectral networks and locally
connected networks on graphs. CoRR, abs/1312.6203, 2013. URL http://arxiv.org/
abs/1312.6203.
Keke Chen and Ling Liu. Clustermap: Labeling clusters in large datasets via visualization. In
Proceedings of the Thirteenth ACM International Conference on Information and Knowledge
Management, CIKM ’04, pp. 285-293, New York, NY, USA, 2004. Association for Computing
Machinery. ISBN 1581138741. doi: 10.1145/1031171.1031233. URL https://doi.org/
10.1145/1031171.1031233.
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Hol-
ger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder
for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pp. 1724-1734. Association for Computational Lin-
guistics, 2014. doi: 10.3115/v1/D14-1179. URL http://www.aclweb.org/anthology/
D14-1179.
Heriberto CuayahuitL Simon Keizer, and Oliver Lemon. Strategic dialogue management via deep
reinforcement learning. NIPS’15 Workshop on Deep Reinforcement Learning, 2015.
Michael Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks
on graphs with fast localized spectral filtering. CoRR, abs/1606.09375, 2016. URL http:
//arxiv.org/abs/1606.09375.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep
bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for Computational Linguistics: Human Language
10
Published as a conference paper at ICLR 2021
Technologies, Volume 1 (Long and Short Papers), pp. 4171-4186, Minneapolis, Minnesota, June
2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https:
//www.aclweb.org/anthology/N19-1423.
Ritam Dutt, Rishabh Joshi, and Carolyn Rose. Keeping up appearances: Computational modeling
of face acts in persuasion oriented discussions. In Proceedings of the 2020 Conference on Em-
pirical Methods in Natural Language Processing (EMNLP), pp. 7473-7485, Online, November
2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.605. URL
https://www.aclweb.org/anthology/2020.emnlp-main.605.
Ritam Dutt, Sayan Sinha, Rishabh Joshi, Surya Shekhar Chakraborty, Meredith Riggs, Xinru Yan,
Haogang Bao, and Carolyn Penstein Rose. Resper: Computationally modelling resisting strate-
gies in persuasive conversations. In 16th Conference of the European Chapter of the Association
for Computational Linguistics (EACL), 2021.
Roger Fisher, William L Ury, and Bruce Patton. Getting to yes: Negotiating agreement without
giving in. Penguin, 2011.
Deepanway Ghosal, Navonil Majumder, Soujanya Poria, Niyati Chhaya, and Alexander Gelbukh.
DialogueGCN: A graph convolutional neural network for emotion recognition in conversation. In
Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and
the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp.
154-164, Hong Kong, China, November 2019. Association for Computational Linguistics. doi:
10.18653/v1/D19-1015. URL https://www.aclweb.org/anthology/D19- 1015.
He He, Derek Chen, Anusha Balakrishnan, and Percy Liang. Decoupling strategy and genera-
tion in negotiation dialogues. In Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing, 2018. URL https://www-nlp.stanford.edu/pubs/
he2018decouple.pdf.
Wenxiang Jiao, Haiqin Yang, Irwin King, and Michael R. Lyu. HiGRU: Hierarchical gated re-
current units for utterance-level emotion recognition. In Proceedings of the 2019 Conference
of the North American Chapter of the Association for Computational Linguistics: Human Lan-
guage Technologies, Volume 1 (Long and Short Papers), pp. 397-406, Minneapolis, Minnesota,
June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1037. URL
https://www.aclweb.org/anthology/N19-1037.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR,
abs/1412.6980, 2014.
Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional net-
works. In International Conference on Learning Representations (ICLR), 2017.
Philipp Koehn. Statistical significance tests for machine translation evaluation. In Proceedings
of the 2004 Conference on Empirical Methods in Natural Language Processing, pp. 388-395,
Barcelona, Spain, July 2004. Association for Computational Linguistics. URL https://www.
aclweb.org/anthology/W04-3250.
Gaurav Kumar, Rishabh Joshi, Jaspreet Singh, and Promod Yenigalla. AMUSED: A multi-stream
vector representation method for use in natural dialogue. In Proceedings of The 12th Language
Resources and Evaluation Conference, pp. 750-758, Marseille, France, May 2020. European
Language Resources Association. ISBN 979-10-95546-34-4. URL https://www.aclweb.
org/anthology/2020.lrec-1.94.
George Larionov, Zachary Kaden, Hima Varsha Dureddy, Gabriel Bayomi T Kalejaiye, Mihir
Kale, Srividya Pranavi Potharaju, Ankit Parag Shah, and Alexander I Rudnicky. Tartan: A
retrieval-based socialbot powered by a dynamic finite-state machine architecture. arXiv preprint
arXiv:1812.01260, 2018.
David A Lax and James K Sebenius. 3-D Negotiation: Powerful tools to change the game in your
most important deals. Harvard Business Press, 2006.
11
Published as a conference paper at ICLR 2021
Junhyun Lee, Inyeop Lee, and Jaewoo Kang. Self-attention graph pooling. In Proceedings of the
36th International Conference on Machine Learning, 09-15 JUn 2019.
Wenqiang Lei, Xisen Jin, Min-Yen Kan, Zhaochun Ren, Xiangnan He, and Dawei Yin. Sequicity:
Simplifying task-oriented dialogUe systems with single seqUence-to-seqUence architectUres. In
Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers), pp. 1437-1447, MelboUrne, AUstralia, JUly 2018. Association for CompUtational
LingUistics. doi: 10.18653/v1/P18-1133. URL https://www.aclweb.org/anthology/
P18-1133.
Mike Lewis, Denis Yarats, Yann DaUphin, Devi Parikh, and DhrUv Batra. Deal or no deal? end-
to-end learning of negotiation dialogUes. In Proceedings of the 2017 Conference on Empirical
Methods in Natural Language Processing, pp. 2443-2453, Copenhagen, Denmark, September
2017. Association for CompUtational LingUistics. doi: 10.18653/v1/D17-1259. URL https:
//www.aclweb.org/anthology/D17-1259.
Jiwei Li, Michel Galley, Chris Brockett, Georgios SpithoUrakis, Jianfeng Gao, and Bill Dolan. A
persona-based neUral conversation model. In Proceedings ofthe 54th Annual Meeting ofthe Asso-
ciation for Computational Linguistics (Volume 1: Long Papers), pp. 994-1003, Berlin, Germany,
AUgUst 2016. Association for CompUtational LingUistics. doi: 10.18653/v1/P16-1094. URL
https://www.aclweb.org/anthology/P16-1094.
YU Li, KUn Qian, Weiyan Shi, and ZhoU YU. End-to-end trainable non-collaborative dialog sys-
tem. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-
Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI
Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA,
February 7-12, 2020, pp. 8293-8302. AAAI Press, 2020. URL https://aaai.org/ojs/
index.php/AAAI/article/view/6345.
Weixin Liang, YoUzhi Tian, Chengcai Chen, and ZhoU YU. MOSS: end-to-end dialog system frame-
work with modUlar sUpervision. In The Thirty-Fourth AAAI Conference on Artificial Intelli-
gence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Confer-
ence, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence,
EAAI 2020, New York, NY, USA, February 7-12, 2020, pp. 8327-8335. AAAI Press, 2020. URL
https://aaai.org/ojs/index.php/AAAI/article/view/6349.
Diego Marcheggiani and Ivan Titov. Encoding sentences with graph convolUtional networks for
semantic role labeling. In Proceedings of the 2017 Conference on Empirical Methods in Natu-
ral Language Processing, pp. 1506-1515, Copenhagen, Denmark, September 2017. Association
for CompUtational LingUistics. doi: 10.18653/v1/D17-1159. URL https://www.aclweb.
org/anthology/D17-1159.
Masahiro MizUkami, Koichiro Yoshino, Graham NeUbig, David TraUm, and Satoshi NakamUra.
Analyzing the effect of entrainment on dialogUe acts. In Proceedings of the 17th Annual Meeting
of the Special Interest Group on Discourse and Dialogue, pp. 310-318, Los Angeles, September
2016. Association for CompUtational LingUistics. doi: 10.18653/v1/W16-3640. URL https:
//www.aclweb.org/anthology/W16-3640.
Will Norcliffe-Brown, Stathis Vafeias, and Sarah Parisot. Learning conditioned graph strUctUres for
interpretable visUal qUestion answering. In Advances in neural information processing systems,
pp. 8334-8343, 2018.
Kishore Papineni, Salim RoUkos, Todd Ward, and Wei-Jing ZhU. BleU: a method for aUtomatic
evalUation of machine translation. In Proceedings of the 40th Annual Meeting of the Associa-
tion for Computational Linguistics, pp. 311-318, Philadelphia, Pennsylvania, USA, JUly 2002.
Association for CompUtational LingUistics. doi: 10.3115/1073083.1073135. URL https:
//www.aclweb.org/anthology/P02-1040.
Amin Parvaneh, Ehsan Abbasnejad, Qi WU, and Javen Shi. Show, price and negotiate: A hierarchical
attention recUrrent visUal negotiator. CoRR, abs/1905.03721, 2019. URL http://arxiv.
org/abs/1905.03721.
12
Published as a conference paper at ICLR 2021
P. E. Pope, S. Kolouri, M. Rostami, C. E. Martin, and H. Hoffmann. Explainability methods for
graph convolutional neural networks. In 2019 IEEE/CVF Conference on Computer Vision and
PatternRecognition (CVPR) ,pp.10764-10773, 2019.
Dean G Pruitt. Negotiation behavior. Academic Press, 2013.
Jinghui Qin, Zheng Ye, Jianheng Tang, and Xiaodan Liang. Dynamic knowledge routing network
for target-guided open-domain conversation. Proceedings of the AAAI Conference on Artificial
Intelligence, 34(05):8657-8664, Apr 2020. ISSN 2159-5399. doi: 10.1609/aaai.v34i05.6390.
URL http://dx.doi.org/10.1609/aaai.v34i05.6390.
Ekagra Ranjan, Soumya Sanyal, and Partha P. Talukdar. ASAP: adaptive structure aware pooling
for learning hierarchical graph representations. In The Thirty-Fourth AAAI Conference on Artifi-
cial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence
Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelli-
gence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pp. 5470-5477. AAAI Press, 2020.
URL https://aaai.org/ojs/index.php/AAAI/article/view/5997.
Siva Reddy, Danqi Chen, and Christopher D. Manning. CoQA: A conversational question an-
swering challenge. Transactions of the Association for Computational Linguistics, 7:249-266,
March 2019. doi: 10.1162/tacl_a_00266. URL https://www.aclweb.org/anthology/
Q19-1016.
Alan Ritter, Colin Cherry, and Bill Dolan. Unsupervised modeling of twitter conversations. In Hu-
man Language Technologies: The 2010 Annual Conference of the North American Chapter of the
Association for Computational Linguistics, pp. 172-180, Los Angeles, California, June 2010. As-
sociation for Computational Linguistics. URL https://www.aclweb.org/anthology/
N10-1020.
M. Schlichtkrull, Thomas Kipf, P. Bloem, R. V. Berg, Ivan Titov, and M. Welling. Modeling rela-
tional data with graph convolutional networks. In ESWC, 2018.
Weiyan Shi, Tiancheng Zhao, and Zhou Yu. Unsupervised dialog structure learning. In Proceedings
of the 2019 Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 1797-1807,
Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/
v1/N19-1178. URL https://www.aclweb.org/anthology/N19-1178.
Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. A neural network approach to context-sensitive gen-
eration of conversational responses. In Proceedings of the 2015 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language Technologies, pp.
196-205, Denver, Colorado, May-June 2015. Association for Computational Linguistics. doi:
10.3115/v1/N15-1020. URL https://www.aclweb.org/anthology/N15-1020.
Jianheng Tang, Tiancheng Zhao, Chenyan Xiong, Xiaodan Liang, Eric Xing, and Zhiting Hu. Target-
guided open-domain conversation. In Proceedings of the 57th Annual Meeting of the Associ-
ation for Computational Linguistics, pp. 5624-5634, Florence, Italy, July 2019. Association for
Computational Linguistics. doi: 10.18653/v1/P19-1565. URL https://www.aclweb.org/
anthology/P19-1565.
Leigh L Thompson. The mind and heart of the negotiator, volume 3.
Ming Tu, Kevin Huang, Guangtao Wang, Jing Huang, Xiaodong He, and Bowen Zhou. Select,
answer and explain: Interpretable multi-hop reading comprehension over multiple documents. In
AAAI 2020 (accepted), 2020.
Yi-Lin Tuan, Yun-Nung Chen, and Hung-yi Lee. DyKgChat: Benchmarking dialogue generation
grounding on dynamic knowledge graphs. In Proceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the 9th International Joint Conference on Natural
Language Processing (EMNLP-IJCNLP), pp. 1855-1865, Hong Kong, China, November 2019.
Association for Computational Linguistics. doi: 10.18653/v1/D19-1194. URL https://www.
aclweb.org/anthology/D19-1194.
13
Published as a conference paper at ICLR 2021
Shikhar Vashishth, Rishabh Joshi, Sai Suman Prayaga, Chiranjib Bhattacharyya, and Partha Taluk-
dar. RESIDE: Improving distantly-supervised neural relation extraction using side information.
In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Process-
ing, pp. 1257-1266, Brussels, Belgium, October-November 2018. Association for Computational
Linguistics. URL http://aclweb.org/anthology/D18-1157.
Shikhar Vashishth, Naganand Yadati, and Partha Talukdar. Graph-based deep learning in natural
language processing. In Proceedings of the 2019 Conference on Empirical Methods in Natural
Language Processing and the 9th International Joint Conference on Natural Language Process-
ing (EMNLP-IJCNLP): Tutorial Abstracts, Hong Kong, China, November 2019. Association for
Computational Linguistics.
Shikhar Vashishth, Soumya Sanyal, Vikram Nitin, and Partha Talukdar. Composition-based multi-
relational graph convolutional networks. In International Conference on Learning Representa-
tions, 2020. URL https://openreview.net/forum?id=BylA_C4tPr.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
E ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V. Luxburg,
S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neu-
ral Information Processing Systems 30, pp. 5998-6008. Curran Associates, Inc., 2017. URL
http://papers.nips.cc/paper/7181- attention- is- all- you- need.pdf.
Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua
Bengio. Graph Attention Networks. International Conference on Learning Representations,
2018. URL https://openreview.net/forum?id=rJXMpikCZ. accepted as poster.
Oriol Vinyals and Quoc Le. A neural conversational model. arXiv preprint arXiv:1506.05869, 2015.
Xuewei Wang, Weiyan Shi, Richard Kim, Yoojung Oh, Sijia Yang, Jingwen Zhang, and Zhou Yu.
Persuasion for good: Towards a personalized persuasive dialogue system for social good. arXiv
preprint arXiv:1906.06725, 2019.
Wei Wei, Quoc Le, Andrew Dai, and Jia Li. AirDialogue: An environment for goal-oriented
dialogue research. In Proceedings of the 2018 Conference on Empirical Methods in Natural
Language Processing, pp. 3844-3854, Brussels, Belgium, October-November 2018. Association
for Computational Linguistics. doi: 10.18653/v1/D18-1419. URL https://www.aclweb.
org/anthology/D18-1419.
Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S. Yu. A
comprehensive survey on graph neural networks. IEEE Transactions on Neural Networks and
Learning Systems, pp. 1-21, 2020. ISSN 2162-2388. doi: 10.1109/tnnls.2020.2978386. URL
http://dx.doi.org/10.1109/TNNLS.2020.2978386.
Shangsheng Xie and Mingming Lu. Interpreting and Understanding Graph Convolutional Neural
Network using Gradient-based Attribution Method. arXiv e-prints, art. arXiv:1903.03768, March
2019.
Ji Soo Yi, Rachel Melton, John Stasko, and Julie A. Jacko. Dust & magnet: Multivari-
ate information visualization using a magnet metaphor. Information Visualization, 4(4):239-
256, 2005. doi: 10.1057/palgrave.ivs.9500099. URL https://doi.org/10.1057/
palgrave.ivs.9500099.
Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. Hi-
erarchical graph representation learning with differentiable pooling. In Advances in neural infor-
mation processing systems, pp. 4800-4810, 2018.
S. Young. Using pomdps for dialog management. In 2006 IEEE Spoken Language Technology
Workshop, pp. 8-13, 2006.
Ke Zhai and Jason D. Williams. Discovering latent structure in task-oriented dialogues. In Pro-
ceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers), pp. 36-46, Baltimore, Maryland, June 2014. Association for Computational
Linguistics. doi: 10.3115/v1/P14-1004. URL https://www.aclweb.org/anthology/
P14-1004.
14
Published as a conference paper at ICLR 2021
Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. Per-
sonalizing dialogue agents: I have a dog, do you have pets too? In Proceedings of the 56th
Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp.
2204-2213, Melbourne, Australia, July 2θl8. Association for Computational Linguistics. doi:
10.18653/v1/P18-1205. URL https://www.aclweb.org/anthology/P18-1205.
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. Bertscore: Evalu-
ating text generation with bert. In International Conference on Learning Representations, 2020.
URL https://openreview.net/forum?id=SkeHuCVFDr.
Zhen Zhang, Jiajun Bu, Martin Ester, Jianfeng Zhang, Chengwei Yao, Zhi Yu, and Can Wang.
Hierarchical graph pooling with structure learning. arXiv preprint arXiv:1911.05954, 2019.
Hao Zhou, Tom Young, Minlie Huang, Haizhou Zhao, Jingfang Xu, and Xiaoyan Zhu. Common-
sense knowledge aware conversation generation with graph attention. In Proceedings of the 27th
International Joint Conference on Artificial Intelligence, IJCAI’18, pp. 4623-4629. AAAI Press,
2018. ISBN 9780999241127.
Yiheng Zhou, He He, Alan W Black, and Yulia Tsvetkov. A dynamic strategy coach for effective
negotiation. In Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue, pp.
367-378, Stockholm, Sweden, September 2019. Association for Computational Linguistics. doi:
10.18653/v1/W19-5943. URL https://www.aclweb.org/anthology/W19-5943.
Yiheng Zhou, Yulia Tsvetkov, Alan W Black, and Zhou Yu. Augmenting non-collaborative dialog
systems with explicit semantic and strategic dialog history. In International Conference on Learn-
ing Representations, 2020. URL https://openreview.net/forum?id=ryxQuANKPB.
15
Published as a conference paper at ICLR 2021
A	Dialogue Acts
Here we provide the details about the dialogue acts that we have used to annotate the utterances. 10
are taken from He et al. (2018) and 4 are based on the actions taken by the users. The rule based
acts are extracted using the code provided by them8. The details are in Table 6.
Table 6: The list of dialogue acts that we use to annotate the data.
Meaning	Dialogue Act	Example	Detector
Greetings	intro	I would love to buy	rule
Ask a question	inquiry	Sure, what’s your price	rule
Propose the first price	init-price	I’m on a budget so i could do $5	rule
Proposing a counter price	counter-price	How about $15 and I’ll waive the deposit	rule
Unknown	unknown	Hmm, let me think	rule
Agree with the proposal	agree	That works for me	rule
Disagree with a proposal	disagree	Sorry I can’t agree to that	rule
Answer a question	inform	This bike is brand new	rule
Using comparatives with existing price	vague-price	That offer is too low	rule
Insist on an offer	insist	Still can I buy it for $ 5. I’m on a tight budget	rule
Offer the price	hofferi		agent action
Accept the offer	haccepti		agent action
Reject the offer	hrejecti		agent action
Quit the session	hquiti		agent action
B Negotiation S trategies
Here we provide the details about the 15 Negotiation Strategies (Zhou et al., 2019) and 21 Negotia-
tion Strategies (Zhou et al., 2020) in Tables 7 and 8.
Table 7: The details of 15 Negotiation Strategies proposed by Zhou et al. (2019).
High level Negotiation Rules	Sub Strategy	Example	Detector
Focus on interests, not positions	Describe Product Rephrase product Embellish product Address concerns Communicate interests	The car has leather seats 45k miles -→ less than 50k miles a luxury car with attractive leather seats I’ve just taken it to maintenance I’d like to sell it asap.	classifier classifier classifier classifier classifier
Invent options for mutual gain	Propose Price Do not propose first Negotiate side offers Hedge	HoW about 9k? n/a I can deliver it for you I could come doWn a bit	classifier rule rule rule
Build Trust	Communicate Politely Build rapport Talk informally	Greetings, gratitude, apology, please My kid really liked this bike, but he outgreW it Absolutely, ask aWay!	rule rule rule
Insist on your position	Show dominance Negative Sentiment Certainty words	The absolute highest I can do is 640 Sadly, I simply cannot go under 500 It has always had a screen protector	rule rule rule
8https://github.com/stanfordnlp/cocoa/
16
Published as a conference paper at ICLR 2021
Negotiation Strategies	Train set frequency
first_person_SingUlar-CoUnt	26,121
Pos-Sentiment	24,862
number_of_diff_diC_Pos	18,610
third_Person-singular	17,000
hedge_CoUnt	12,227
number_of_diff_dic_neg	10,402
personal-concern	9,135
propose	8,449
Politeness-greet	6,639
assertive-CoUnt	4,437
neg-sentiment	3,680
factive-CoUnt	3,429
politeness-gratitude	3,171
first_Person_PlUraLCoUnt	2,876
IiwC-Certainty	2,530
liwC_informal	2,396
third_Person-PlUral	1,721
trade_in	883
politeness_please	372
family	201
friend	149
<start>	5,383
Table 8: The details of 21 Negotiation Strategies (<start> added by us) used by Zhou et al.
(2020). These are used to operationalize the 15 strategies using a rule based system (https:
//github.com/zhouyiheng11/augmenting-non-collabrative-dialog/). The frequency
statistics on the train set (5383 conversations) is given. A detailed description regarding the rules used by
prior work to extract these are out of scope of this work, however, we intend to provide the code and extracted
strategies, along with the rule based mapping to the 15 strategies upon acceptance of this work.
C S trategy- Graph Visualization
A visualization of a strategy sequence graph. Refer to §2.2 for more details. We also provide
additional details regarding the number of nodes and edges in our strategy graphs in Table 9.
Customer
Seller (Bot)
Figure 4: Visualization of a strategy sequence graph. The graph connects each strategy with all
previously occurring strategies. Here we present only a few edges for brevity. For example, there
would be two more additional edges from u4 to the strategies of u5 .
17
Published as a conference paper at ICLR 2021
Table 9: We report the number of nodes and edges in our strategy-graphs. Each node corresponds
to a particular utterance-strategy pair.
Feature	Value
Max no. of nodes in graph (total strategies) Avg no. of nodes in graph Max no. of edges in graph Avg no. of edges in graph	86 21 3589 308
D Hyperparameters
We present the hyper-parameters for all the experiments, their corresponding search space and their
final values in Table 10. We also present additional details of our experiments below. We use most
of the hyperparameters from Zhou et al. (2020). Each training run took at most 3 hours on a single
Nvidia GeForce GTX 1080Ti GPU and all the models were saved based on Strategy Macro F1
performance.
For experiments for Table 1 and 2 we saved the best models on best Strategy Macro F1 perfor-
mance (HED being saved on outcome class prediction). This is because we wanted to prioritize and
optimize our final model to capture sequence-structural information owing to our focus on inter-
pretability. While performing ablation studies for Table 3, not all models have structure encoders,
and hence for a fair comparison we chose a metric independent of the different modules for all the
models in ablations. We use the negotiation outcome class prediction (RC-Acc) scores as that opti-
mizes the dialogue for good negotiation outcome, which indirectly helps train the model to capture
the sequence of strategies.
Table 10: Here we describe the search-space of all the hyper-parameters used in our experiments.
Model	Hyper-parameter	Search space	Final Value
All	BERT	-	bert-base-Uncased no fine tuning
All	BERT Dropout	-	0.3
All	Dialogue context embedding	-	300
All	Dialogue context dropout	-	0.1
All	learning-rate (lr)	5e-3,1e-3,5e-4	1e-3
All	max utterances in batch	64,128,256	128
All	weighted strategy loss	True,False	True
All	decay rate (l2)	-	1e-3
All	loss alpha	1,5	1
All	loss beta	-	10
All	loss gamma	-	10
All	projection layers for strategy	-	64
All	projection layers for DA	-	64
HED+RNN	hidden size	64, 300	64
HED+Transformer	hidden size	64,300	300
HED+Transformer	decoder layers	-	6
HED+Transformer	attention heads	1,2	2
HED+Transformer	dropout	0.0, 0.1	0.0
DialoGraph	ASAP pooling ratio	0.2,0.5,0.8	0.8
DialoGraph	hidden dim	64,128	64
DialoGraph	Graph layers	1,2,3	2
DialoGraph	Graph dropout	0.0,0.2	0.0
18
Published as a conference paper at ICLR 2021
E Negotiation Dataset Statistics
In Table 11 we provide the CraiglistBargain dataset statistics along with data sizes after filtering
conversations with less than 5 turns. The maximum and average number of turns in any conversation
is 47 and 9.2 respectively. Also, the maximum and average number of strategies in an utterance is
13 and 3 respectively.
Table 11: Dataset statistics.
Data split	Size
Train conversations	5383
Valid conversations	643
Test conversations	656
Filtered train conversations	4828
Filtered valid conversations	561
Filtered test conversations	567
Vocabulary size	13339
F Example Conversations
Table 12: Examples of the generated dialogues of various models when we keep the buyer utterances
same. We see that DialoGraph gets the best deal for the same dialogue context and is more
persistent. The FeHED and HED models accept offers more readily. We provide more examples of
DIALOGRAPH in Table 13.
Listing Price: 40 Buyer’s Target Price: 36 Title: 2017 NEW Stans 24 and 26 Tubeless Tire Kit	
◎: DIALOGRAPH H: Human	O: HED+Transformer U: Human
<⅛>: Hello	& Hello
X: Hi. Is the tire kit new?	U: Hi. Is the tire kit new?
'史上 Yes it is.	W): Yes it is.
U: Great. My bro destroyed my old kit and I’m looking for new tires.	X: Great. My bro destroyed my old kit and I’m looking for new tires.
<⅛>: I am asking 40 for it.	<⅛>: I am asking 40 for it.
M That’s too much for a student like me. How about 35?	X That's too much for a student like me. How about 35?
<⅛>: I can’t go that low. I could do 38.8 and I will deliver it to you.	(⅛): I can’t go that low. I could do 38 and throw in a warranty.
A: I can come pick it up for 36.	2: I can come pick it up for 36.
O: I can do 37.2 and you have a deal.	O: I can do that.
A: Okay great. Thanks. < offer > 37.2	0∣: Okay great. Thanks. < offer > 36
,2*Ξl: FeHED 0 Human	由:HED A: Human
<⅛>: Hello	O: Hello
R: Hi. Is the tire kit new?	2: Hi. Is the tire kit new?
O: Hi there! Are you interested in the bike?	O: Yes it is.
R: Great. My bro destroyed my old kit and I’m looking for new tires.	2: Great. My bro destroyed my old kit and I’m looking for new tires.
O: I am asking 40 for it.	O: Yes it is.
U That’s too much for a student like me. How about 35?	U: That’s too much for a student like me. How about 35?
<。>:I can do that.	O: I can do that.
U: Okay great. Thanks. < offer > 35	U: Okay great. Thanks. < offer > 35
Final Deal: Graph = 37.2, Trans = 36, FeHED = 35, HED = 35	
19
Published as a conference paper at ICLR 2021
Table 13: More examples of the generated dialogues of DialoGraph.
Listing Price: 40
Buyer’s Target Price: 36
Title: 2017 NEW Stans 24 and 26 Tubeless Tire Kit
必:DIALOGRAPH	: Human
E : Hello
:Hi.
θ : Are you interested in the kit?
*	* : Yes I am interested.
f : I am looking for 40 for it.
*	* : No I am willing to pay 35 for it.
G : I can,t go that low
C : What can you take?
G : I could do 38.8 and I will deliver it to you.
C : I only have 36 please.
f : I can do 37.2 and you can pick it up yourself.
*	# : Sorry i only have 36
，口 : I can do that.
'4 : Okay thank you.
⅛ : < offer > 37.2
4 : Hello
*	':Hi how are you.
f : I am good.
*	* : Is the kit good?
G : yes it is.
C : are you sure?
∖7τ'1": yes. i am willing to negotiate the price.
C : okay how much you willing to sell.
<	77∙l,: it is in great condition. i am asking 40 for it.
K : i will give you 25.
<	⅛fι: i can do 38.8 and you can pick it up.
Q 35
∙θ : i can do 37.2 and you can pick it up.
*	，： 36 last
θ : ok i can do that.
J : < offer > 36
Z : Hello
、，：Hi
心:Hi i see you are interested in my apartment
：i : i Was interested in the tire kit
θ : i m asking 40 for it.
*	* : would you be able to do 35?
f : i m willing to negotiate a little bit. what is your budget?
C : the highest i can go is 36
G : i cant go that low i could do 38.8
C : okay that works
「： < offer > 38.8
G Influence Visualization
Refer to Figure 5.
20
Published as a conference paper at ICLR 2021
SOdl,pttl- PlJOI-JθqEn Ulm.
■s3」olss(uuaa=O dim.
-euxlotτlM=lm.
」e-ΓI6U-Slu OS-IQdIP-I-LPIm.
<usodαjdlnl
IU 3 E-IU 中 SlSOdLn1
SOdl.ypitl- PlJOI-JθqEn uLnl
+Ju n OWJ e - n 6u - SIUOS.Jad Js-Jζ=llrl
2?.E£ 3UlUM= lln
-elωoJULlM=IC
U-l<υp0j-qlnl
4->uαJLU=U 3ωlsodl寸
.IE- n 6 u - SlU OS」3dlp-l 一 lμly
4-"u<υE=UωslModIm
au<u∪u-auφslso dig
」En 6u - SlUos」ə dlp-lΞllg
4->U noulro.ln -dluos.Jφd Js-Jζ= ll∩
4_third_person_singular-
4_pos_sentiment -
5_trade_in ]
5JiwcJnformal -
5_liwc_certainty
5_first_person_singular_count -
5_number_of_diff_dic_pos -
5_pos_sentiment
5_propose ∖
5_f i rst_pe rso n_p I u ra l=c ou n 11
6_third_person_singular ∖
6_pos_sentiment ∖
7_a sse rt i ve_c ou nt ]
7_third_person_singular I
7JedgJCOUntl
7_personal_concern ]
7_first_person_singular_count ∖
7_nu m be r_of_d iff_d i c_neg ∖
7_n u mber_of_diff_clic_pos -I
7_family I
7_pos_sentiment ]
7_first_pe rso n_p Iura LCOUntl
Figure 5: Visualization of the attention map learned by DialoGraph for the example depicted in
Figure 3 in the main paper. We only show it for a few turns for brevity. Here the axis labels represent
the turn and the strategy. Refer to the Figure 3 in the main paper for description.
H Human Evaluation Interface
Negotiation scenario!
You have to negotiate with another user for the price of an item. You are the buyer. Negotiate well!
Instructions
•	Please use natural sentences as much as possible.
。Dot Would $10 work for you?
o Don't do： 10?
•	You can look at the product description at the right and use points from it.
•	Llse the chat box to chat.
•	Do not press enter / return key more than once after typing an utterance. Wait for the response from the bot. That might take a few seconds.
♦	If you run out of time while doing the chat, we will still award you money for the HIT if you made a good effort to complete the task.
•	If you Chat continuously, the chat will most likely end in a few minutes, in about 10 turns.
•	At the end of the chat, after you have come to a conclusion on what to offer, type "<offer> xyz"l where XyZ is the amount in the chat itself.
•	After this, either you or the bot can decide to end the conversation by writing one of "<accept>", "<reject>l,l or "<quit>n (with brackets) in the chat itself.
♦	Note that the chat window will close as soon as either party writes the above and you will reach the survey page.
•	Please close the browser tab after you are done with the HIT.
•	You can resize the chat window by dragging it from the bottom right corner. You can also scroll up and down to see the chat history.
Continue
Figure 6: Screenshot of the introduction for the human evaluation interface.
21
Published as a conference paper at ICLR 2021
Negotiation scenario!
You have to negotiate with another user for the price of an item. You are the buyer. Negotiate well!
Instructions
•	Please use natural sentences as much as possible.
° Do: Would $10 work for you?
O Don't do: 10?
•	You can look at the product description at the right and use points from it.
•	Use the chat box to chat.
•	Do not press enter / return key more than once after typing an utterance. Wait for the response from the bot. That might take a few
seconds.
•	If you run out of time while doing the chat, we will still award you money for the HIT if you made a good effort to complete the
task.
•	If you chat continuously, the chat will most likely end in a few minutes, in about 10 turns.
•	At the end of the chat, after you have come to a conclusion on what to offer, type "<offer> xyz", where xyz is the amount in the
chat itself.
•	After this, either you or the bot can decide to end the conversation by writing one of "<accept>", "<reject>", or "<quit>" (with
brackets) in the chat itself.
•	Note that the chat window will close as soon as either party writes the above and you will reach the survey page.
•	Please close the browser tab after you are done with the HIT.
•	You can resize the chat window by dragging it from the bottom right corner. You can also scroll up and down to see the chat
history.
The Negotiation Scenario
Category: Bike
Craigslist post id : 6118695547
uuid : S.sAk3UrLZEZWragJ6
Your Target Price: 36
Price: 40
Description : I have a NEW Stan's Tubeless tire Conversion kit for sale for 24" AND 26" wheels/tires.
Title: 2017 NEW Stans 24" & 26" Tubeless Tire Kit
Time: 5:44
[11/17/20 22：07：54] <You entered the room.>
[11/17/20 22：07：55] Partner: Hello!!!
I Enter your message here
Figure 7: Screenshot of the chat window for the human evaluation interface.
Instructions
In order to complete this HIT, please answer the fallowing questions about the dialogue that you just completed. Please do not include any
personally identifying information about yourself (or any other PerSCn) in any open text questions on the survey.
Part 1: To what extent do you agree with these statements?
1.1	understood the task perfectly.
•	Strongly Disagree
•	Disagree
•	Neutral
•	Agree
•	Strongly Agree
2.	My task partner was persuasive.
•	Strongly Disagree
•	Disagree
•	Neutral
φ Agree
•	Strongly Agree
3.	My task partner was human-like (natural).
•	Strongly Disagree
•	Disagree
•	Neutral
•	Agree
•	Strongly Agree
4.	My task partner perfectly understood what I was typing.
•	Strongly Disagree
•	Disagree
•	Neutral
•	Agree
•	Strongly Agree
5.	My task partner's responses were on topic and in accordance with the conversation history. (Coherent)
•	Strongly Disagree
•	Disagree
•	Neutral
φ Agree
•	Strongly Agree
Figure 8: Screenshot of the survey for the human evaluation interface.
22