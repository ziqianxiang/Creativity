Published as a conference paper at ICLR 2021
Achieving Linear Speedup with Partial Worker
Participation in Non-IID Federated Learning
Haibo Yang, Minghong Fang, and Jia Liu
Department of Electrical and Computer Engineering
The Ohio State University
Columbus, OH 43210 USA
{yang.5952, fang.841, liu.1736}@osu.edu
Ab stract
Federated learning (FL) is a distributed machine learning architecture that leverages
a large number of workers to jointly learn a model with decentralized data. FL has
received increasing attention in recent years thanks to its data privacy protection,
communication efficiency and a linear speedup for convergence in training (i.e.,
convergence performance increases linearly with respect to the number of workers).
However, existing studies on linear speedup for convergence are only limited to
the assumptions of i.i.d. datasets across workers and/or full worker participation,
both of which rarely hold in practice. So far, it remains an open question whether
or not the linear speedup for convergence is achievable under non-i.i.d. datasets
with partial worker participation in FL. In this paper, we show that the answer
is affirmative. Specifically, we show that the federated averaging (FedAvg) algo-
rithm (with two-sided learning rates) on non-i.i.d. datasets in non-convex settings
achieves a convergence rate O(旷,长1 + T1) for full worker participation and a
convergence rate O(√K + 1) for partial worker participation, where K is the
number of local steps, T is the number of total communication rounds, m is the
total worker number and n is the worker number in one communication round if for
partial worker participation. Our results also reveal that the local steps in FL could
help the convergence and show that the maximum number of local steps can be
improved to T /m in full worker participation. We conduct extensive experiments
on MNIST and CIFAR-10 to verify our theoretical results.
1 Introduction
Federated Learning (FL) is a distributed machine learning paradigm that leverages a large number
of workers to collaboratively learn a model with decentralized data under the coordination of a
centralized server. Formally, the goal of FL is to solve an optimization problem, which can be
decomposed as:
1m
mRdf (X) = m X Fi(X)，
i=1
where Fi(X)，Eξi-Di [Fi(x, ξi)] is the local (non-convex) loss function associated with a local data
distribution Di and m is the number of workers. FL allows a large number of workers (such as edge
devices) to participate flexibly without sharing data, which helps protect data privacy. However, it
also introduces two unique challenges unseen in traditional distributed learning algorithms that are
used typically for large data centers:
• Non-independent-identically-distributed (non-i.i.d.) datasets across workers (data hetero-
geneity): In conventional distributed learning in data centers, the distribution for each worker’s
local dataset can usually be assumed to be i.i.d., i.e., Di = D, ∀i ∈ {1, ..., m}. Unfortunately,
this assumption rarely holds for FL since data are generated locally at the workers based on their
circumstances, i.e., Di 6= Dj, for i 6= j. It will be seen later that the non-i.i.d assumption imposes
significant challenges in algorithm design for FL and their performance analysis.
1
Published as a conference paper at ICLR 2021
•	Time-varying partial worker participation (systems non-stationarity): With the flexibility for
workers’ participation in many scenarios (particularly in mobile edge computing), workers may
randomly join or leave the FL system at will, thus rendering the active worker set stochastic and
time-varying across communication rounds. Hence, it is often infeasible to wait for all workers’
responses as in traditional distributed learning, since inactive workers or stragglers will significantly
slow down the whole training process. As a result, only a subset of the workers may be chosen by
the server in each communication round, i.e., partial worker participation.
In recent years, the Federated Averaging method (FedAvg) and its variants (McMahan et al., 2016;
Li et al., 2018; Hsu et al., 2019; Karimireddy et al., 2019; Wang et al., 2019a) have emerged as a
prevailing approach for FL. Similar to the traditional distributed learning, FedAvg leverages local
computation at each worker and employs a centralized parameter server to aggregate and update the
model parameters. The unique feature of FedAvg is that each worker runs multiple local stochastic
gradient descent (SGD) steps rather than just one step as in traditional distributed learning between
two consecutive communication rounds. For i.i.d. datasets and the full worker participation setting,
Stich (2018) and Yu et al. (2019b) proposed two variants of FedAvg that achieve a convergence
rate of O(mTK + 旷:长丁) with a bounded gradient assumption for both strongly convex and non-
convex problems, where m is the number of workers, K is the local update steps, and T is the total
communication rounds. Wang & Joshi (2018) and Stich & Karimireddy (2019) further proposed
improved FedAvg algorithms to achieve an O(T + √二KT) convergence rate without bounded
gradient assumption. Notably, for a sufficiently large T, the above rates become O( √'T )1, which
implies a linear speedup with respect to the number of workers.1 2 This linear speedup is highly
desirable for an FL algorithm because the algorithm is able to effectively leverage the massive
parallelism in a large FL system. However, with non-i.i.d. datasets and partial worker participation in
FL, a fundamental open question arises: Can we still achieve the same linear speedup for convergence,
i.e., O( √T), with non-i.i.d. datasets and under eitherfull or partial worker participation?
In this paper, we show the answer to the above question is affirmative. Specifically, we show that a
generalized FedAvg with two-sided learning rates achieves linear convergence speedup with non-i.i.d.
datasets and under full/partial worker participation. We highlight our contributions as follows:
•	For non-convex problems, we show that the convergence rate of the FedAvg algorithm on non-i.i.d.
dataset are O (√二KT + T) and O (√= + T) for full and partial worker participation, respectively,
where n is the size of the partially participating worker set. This indicates that our proposed
algorithm achieves a linear speedup for convergence rate for a sufficiently large T. When reduced
to the i.i.d. case, our convergence rate is O(TK + √二长T), which is also better than previous
works. We summarize the convergence rate comparisons for both i.i.d. and non-i.i.d. cases in
Table 1. It is worth noting that our proof does not require the bounded gradient assumption. We
note that the SCAFFOLD algorithm (Karimireddy et al., 2019) also achieves the linear speedup
but extra variance reduction operations are required, which lead to higher communication costs
and implementation complexity. By contrast, we do not have such extra requirements in this paper.
•	In order to achieve a linear speedup, i.e., a convergence rate O( √mlKT), we show that the number
of local updates K can be as large as T/m, which improves the T1/3/m result previously shown in
Yu et al. (2019a) and Karimireddy et al. (2019). As shown later in the communication complexity
comparison in Table 1, a larger number of local steps implies relatively fewer communication
rounds, thus less communication overhead. Interestingly, our results also indicate that the number
of local updates K does not hurt but rather help the convergence with a proper learning rates choice
in full worker participation. This overcomes the limitation as suggested in Li et al. (2019b) that
local SGD steps might slow down the convergence (O(K) for strongly convex case). This result
also reveals new insights on the relationship between the number of local steps and learning rate.
1This rate also matches the convergence rate order of parallel SGD in conventional distributed learning.
2To attain e accuracy for an algorithm, it needs to take O(表)steps with a convergence rate O(√1τ), while
needing O(m1^∙) steps if the convergence rate is O(√=) (the hidden constant in Big-O is the same). In this
sense, one achieves a linear speedup with respect to the number of workers.
2
Published as a conference paper at ICLR 2021
Table 1: Convergence rates of optimization methods for FL.
Dataset	Algorithm6	Convexity7	Partial Worker	Convergence Rate	Communication complexity
	Stich1	SC	X	O（啥+√m薄）	~O( mκ + mK2)―
TTn IID	Yu1	NC	×	O( mK+F)	O( mκ + mK2)
	Wang	NC	×	O( m + √mKT )	O( m + m⅛)
	Stich2	NC	×	O( m + √mκτ)	O( m + m⅛)
	This paper	NC	!	O( T⅛ + √mKT )	O( Kk + mK2)
	Khaled 1	C	X	O( m + √mτ)	O( m + m⅛)一
NON- TTTΛ IID	Yu22	NC	×	O( m- + 一1	) (τκ + √mκT)	O( Km + mK2)
	Li	SC	X	1O( K )m	O( K)
	Karimireddy 3	NC	X	O( T2/3 + √sKT)	O(册 + SM2)
	Karimireddy 4	NC	X	O( T + √mκτ)	o( I+ mK2)
	This paper5	NC	"	O( T+ √mκτ)	Oe+mK2)
1	Full gradients are used for each worker.
2	Local momentum is used at each worker.
3	A FedAvg algorithm with two-sided learning rates. M2 = O⑴ + O(KS(I -m)).S = m (S = n)
for full (partial) worker participation.
4	The SCAFFOLD algorithm in Karimireddy et al. (2019) for non-convex case.
5	The convergence rate becomes O(T + √K) under partial worker participation.
6	Shorthand notation for references: Stich1 := Stich (2018), Yu2 := Yu et al. (2019b), Wang:= Wang &
Joshi (2018), Stich2:= Stich & Karimireddy (2019); Khaled:= Khaled et al. (2019b), Yu2:=Yu et al.
(2019a), Li:= Li et al. (2019b), and Karimireddy:= Karimireddy et al. (2019).
7	Shorthand notation for convexity: SC: Strongly Convex, C: Convex, and NC: Non-Convex.
Notation. In this paper, we let m be the total number of workers and St be the set of active workers
for the t-th communication round with size |St | = n for some n ∈ (0, m]. 3 We use K to denote
the number of local steps per communication round at each worker. We let T be the number of
total communication rounds. In addition, we use boldface to denote matrices/vectors. We let Ht 卜
represent the parameter of k-th local step in the i-th worker after the t-th communication. We use
k∕∣2 to denote the '2-norm. For a natural number m, we use [m] to represent the set {1,…，m}.
The rest of the paper is organized as follows. In Section 2, we review the literature to put our work in
comparative perspectives. Section 3 presents the convergence analysis for our proposed algorithm.
Section 4 discusses the implication of the convergence rate analysis. Section 5 presents numerical
results and Section 6 concludes this paper. Due to space limitation, the details of all proofs and some
experiments are provided in the supplementary material.
2	Related work
The federated averaging (FedAvg) algorithm was first proposed by McMahan et al. (2016) for FL as
a heuristic to improve communication efficiency and data privacy. Since then, this work has sparked
many follow-ups that focus on FL with i.i.d. datasets and full worker participation (also known as
LocalSGD (Stich, 2018; Yu et al., 2019b; Wang & Joshi, 2018; Stich & Karimireddy, 2019; Lin
et al., 2018; Khaled et al., 2019a; Zhou & Cong, 2017)). Under these two assumptions, most of the
theoretical works can achieve a linear speedup for convergence, i.e., O( √二KT) for a sufficiently
large T, matching the rate of the parallel SGD. In addition, LocalSGD is empirically shown to be
communication-efficient and enjoys better generalization performance (Lin et al., 2018). For a
comprehensive introduction to FL, we refer readers to Li et al. (2019a) and Kairouz et al. (2019).
3For simplicity and ease of presentation in this paper, we let |St | = n. We note that this is not a restrictive
condition and our proofs and results still hold for |St | ≥ n, which can be easily satisfied in practice.
3
Published as a conference paper at ICLR 2021
Algorithm 1 A Generalized FedAvg Algorithm with Two-Sided Learning Rates.
Initialize x0
for t = 0,…，T 一 1 do
The server samples a subset St of workers with |St | = n.
for each worker i ∈ St in parallel do
xit,0 = xt
fθr k = 0,…，K - 1 do
Compute an unbiased estimate g；k = PFigk,ξtk) of PFigk).
Local worker update: xit,k+1 = xit,k - ηLgti,k.
end for
Let ∆ti = xit,K - xit,0 = -ηL PkK=-01 gti,k. Send ∆it to the server.
end for
At Server:
Receive ∆it , i ∈ S .
Let δ⅛ = |S| Pi∈S ∆it.
Server Update: xt+1 = xt + η∆t .
Broadcasting xt+1 to workers.
end for
For non-i.i.d. datasets, many works (Sattler et al., 2019; Zhao et al., 2018; Li et al., 2018; Wang et al.,
2019a; Karimireddy et al., 2019; Huang et al., 2018; Jeong et al., 2018) heuristically demonstrated
the performance of FedAvg and its variants. On convergence rate with full worker participation, many
works (Stich et al., 2018; Yu et al., 2019a; Wang & Joshi, 2018; Karimireddy et al., 2019; Reddi et al.,
2020) can achieve linear speedup, but their convergence rate bounds could be improved as shown
in this paper. On convergence rate with partial worker participation, Li et al. (2019b) showed that
the original FedAvg can achieve O(K/T) for strongly convex functions, which suggests that local
SGD steps slow down the convergence in the original FedAvg. Karimireddy et al. (2019) analyzed a
generalized FedAvg with two-sided learning rates under strongly convex, convex and non-convex
cases. However, as shown in Table 1, none of them indicates that linear speedup is achievable
with non-i.i.d. datasets under partial worker participation. Note that the SCAFFOLD algorithm
(Karimireddy et al., 2019) can achieve linear speedup but extra variance reduction operations are
required, which lead to higher communication costs and implementation complexity. In this paper,
we show that this linear speedup can be achieved without any extra requirements. For more detailed
comparisons and other algorithmic variants in FL and decentralized settings, we refer readers to
Kairouz et al. (2019).
3	Linear S peedup of the Generalized FedAvg with Two-Sided
Learning Rates for Non-IID Datasets
In this paper, we consider a FedAvg algorithm with two-sided learning rates as shown in Algorithm 1,
which is generalized from previous works (Karimireddy et al., 2019; Reddi et al., 2020). Here,
workers perform multiple SGD steps using a worker optimizer to minimize the local loss on its own
dataset, while the server aggregates and updates the global model using another gradient-based server
optimizer based on the returned parameters. Specifically, between two consecutive communication
rounds, each worker performs K SGD steps with the worker’s local learning rate ηL . We assume an
unbiased estimator in each step, which is denoted by gti,k = PFi(xit,k, ξti,k), where ξti,k is a random
local data sample for k-th steps after t-th communication round at worker i. Then, each worker sends
the accumulative parameter difference ∆ti to the server. On the server side, the server aggregates all
available ∆it -values and updates the model parameters with a global learning rate η. The FedAvg
algorithm with two-sided learning rates provides a natural way to decouple the learning of workers
and server, thus utilizing different learning rate schedules for workers and the server. The original
FedAvg can be viewed as a special case of this framework with server-side learning rate being one.
In what follows, we show that a linear speedup for convergence is achievable by the generalized
FedAvg for non-convex functions on non-i.i.d. datasets. We first state our assumptions as follows.
4
Published as a conference paper at ICLR 2021
Assumption 1. (L-Lipschitz Continuous Gradient) There exists a constant L > 0, such that
∣∣VFi(x) - VFi(y)k ≤ LkX - y∣∣,∀x, y ∈ Rd, andi ∈ [m].
Assumption 2. (Unbiased Local Gradient Estimator) Let ξti be a random local data sample in the
t-th step at the i-th worker. The local gradient estimator is unbiased, i.e., E[VFi (Xt, ξti)] = VFi (Xt),
∀i ∈ [m], where the expectation is over all local datasets samples.
Assumption 3. (Bounded Local and Global Variance) There exist two constants σL > 0 and σG > 0,
such that the variance of each local gradient estimator is boundedbyE[kVFi(Xt, ξti) -VFi(Xt)k2] ≤
σL2, ∀i ∈ [m], and the global variability of the local gradient of the cost function is bounded by
kVFi(Xt) - Vf(Xt)k2 ≤ σG2, ∀i ∈ [m], ∀t.
The first two assumptions are standard in non-convex optimization (Ghadimi & Lan, 2013; Bottou
et al., 2018). For Assumption 3, the bounded local variance is also a standard assumption. We use a
universal bound σG to quantify the heterogeneity of the non-i.i.d. datasets among different workers.
In particular, σG = 0 corresponds to i.i.d. datasets. This assumption is also used in other works for
FL under non-i.i.d. datasets (Reddi et al., 2020; Yu et al., 2019b; Wang et al., 2019b) as well as in
decentralized optimization (Kairouz et al., 2019). It is worth noting that we do not require a bounded
gradient assumption, which is often assumed in FL optimization analysis.
3.1	Convergence analysis for full worker participation
In this subsection, we first analyze the convergence rate of the generalized FedAvg with two-sided
learning rates under full worker participation, for which we have the following result:
Theorem 1. Let constant local and global learning rates ηL and η be chosen as such that ηL ≤ 8Lk
and ηηL ≤ KL. Under Assumptions 1-3 and WithfUU worker participation, the sequence OfoUtPutS
{Xk } generated by Algorithm 1 satisfies:
min E[∣Vf(xt)k2] ≤ f0-f + Φ,
t∈[T]	cηηL KT
where Φ，1 [LLnm σL + 'KL(0常 + 6KσG)], C is a constant, f，f (x0), f，f (x*) and the
expectation is over the local dataset samples among workers.
Remark 1. The convergence bound contains two parts: a vanishing term Jln-KT as T increases and
a constant term Φ whose size depends on the problem instance parameters and is independent of T.
The vanishing term’s decay rate matches that of the typical SGD methods.
Remark 2. The first part of Φ (i.e., LnnLσLL) is due to the local stochastic gradients at each worker,
which shrinks at rate * as m increases. The cumulative variance of the K local steps contributes to
the second term in Φ (i.e., 5KLLL (σL + 6KσG)), which is independent of m and largely affected
by the data heterogeneity. To make the second part small, an inverse relationship between the local
learning rate and local steps should be satisfied, i.e., ηL = O(KK). Specifically, note that the global
and local variances are quadratically and linearly amplified by K. This requires a sufficiently small
ηL to offset the variance between two successive communication rounds to make the second term in
Φ small. This is consistent with the observation in strongly convex FL that a decaying learning rate is
needed for FL to converge under non-i.i.d. datasets even if full gradients used in each worker (Li
et al., 2019b). However, we note that our explicit inverse relationship between ηL and K in the above
is new. Intuitively, the K local steps with a sufficiently small ηL can be viewed as one SGD step with
a large learning rate.
With Theorem 1, we immediately have the following convergence rate for the generalized FedAvg
algorithm with a proper choice of two-sided learning rates:
Corollary 1. Let ηL = √^L and η = TKm. The convergence rate of the generalized FedAvg
algorithm under full worker participation is mint∈[T] E[kVf (Xt)k22] = O
+ T .
Remark 3. The generalized FedAvg algorithm with two-sided learning rates can achieve a linear
speedup for non-i.i.d. datasets, i.e., a O( √'T) convergence rate as long as T ≥ mK. Although
many works have achieved this convergence rate asymptotically, we improve the maximum number
5
Published as a conference paper at ICLR 2021
of local steps K to T/m, which is significantly better than the state-of-art bounds such as T 1/3/m
shown in (Karimireddy et al., 2019; Yu et al., 2019a; Kairouz et al., 2019). Note that a larger number
of local steps implies relatively fewer communication rounds, thus less communication overhead.
See also the communication complexity comparison in Table 1. For example, when T = 106 and
m = 100 (as used in (Kairouz et al., 2019)), the local steps in our algorithm is K ≤ T/m = 104.
However, K ≤ T1/3 = 1 means that no extra local steps can be taken to reduce communication costs.
m
Remark 4. When degenerated to the i.i.d. case ((JG = 0), the convergence rate becomes O(TK +
√m1κτ), which has a better first term in the bound compared with previous work as shown in Table 1.
3.2	Convergence analysis for partial worker participation
Partial worker participation in each communication round may be more practical than full worker
participation due to many physical limitations of FL in practice (e.g., excessive delays because of too
many devices to poll, malfunctioning devices, etc.). Partial worker participation can also accelerate
the training by neglecting stragglers. We consider two sampling strategies proposed by Li et al.
(2018) and Li et al. (2019b). Let St be the participating worker index set at communication round
t with |St | = n, ∀t, for some n ∈ (0, m]. St is randomly and independently selected either with
replacement (Strategy 1) or without replacement (Strategy 2) sequentially according to the sampling
probabilities pi, ∀i ∈ [m]. For each member in St, we pick a worker from the entire set [m] uniformly
at random with probability Pi =煮,∀i ∈ [m]. That is, selection likelihood for anyone worker i ∈ St
is p = m. Then We have the following results:
Theorem 2. Under Assumptions 1-3 with partial worker participation, the Sequence of outputs
{xk } generated by Algorithm 1 with constant learning rates η and ηL satisfies:
min E[kVf(xt)k2] ≤ f0-f + Φ,
t∈[T]	cηηL KT
where f = f (x0), f = f (x*), and the expectation is over the local dataset samples among workers.
For sampling Strategy 1, let η and ηL be chosen as such that ηL ≤ 8LK, ηηLKL < n-1 and
30K2ηLL2 — LrnL (90K3L2ηL + 3K) < 1. It then holds that:
Φ，1 [粤σL + 3LKηηLσG + (5KηLL2 + ⅛LL3)(σL + 6KσG)
c	2n	2n	2	2n
For sampling Strategy 2, let η and ηL be chosen as such that ηL ≤ 8LK, ηηLKL ≤『m-：) and
10K2ηLL2 — LnnLnmm-nι) (90K3ηLL2 + 3K) < 1. It then holds that:
Φ ,1
c
m — n	5Kn2 L2	m — n
jl+3LKnnL2n(m-i) jg+(^-+15K nnLL 2n(m-i) )(σ+6KσG)
From Theorem 2, we immediately have the following convergence rate for the generalized FedAvg
algorithm with a proper choice of two-sided learning rates:
1
√TKL
Corollary 2. Let nL
and n = √Kn. The convergence rate of the generalized FedAvg
algorithm under partial worker participation and both sampling strategies are:
min
t∈[T]
EkVf(xt)k22 ≤O
+ a
Remark 5. The convergence rate bound for partial worker participation has the same structure but
with a larger variance term. This implies that the partial worker participation through the uniform
sampling does not result in fundamental changes in convergence (in order sense) except for an
amplified variance due to fewer workers participating and random sampling. The intuition is that
the uniform sampling (with/without replacement) for worker selection yields a good approximation
of the entire worker distribution in expectation, which reduces the risk of distribution deviation due
to the partial worker participation. As shown in Section 5, the distribution deviation due to fewer
worker participation could render the training unstable, especially in highly non-i.i.d. cases.
6
Published as a conference paper at ICLR 2021
Remark 6. The generalized FedAvg with partial worker participation under non-i.i.d. datasets can
still achieve a linear speedup O(√nT) with proper learning rate settings as shown in Corollary 2. In
addition, when degenerated to i.i.d. case (σg = 0), the convergence rate becomes O(TK + √=p).
Remark 7. Here, we let |St | = n only for ease of presentation and better readability. We note that
this is not a restrictive condition. We can show that |St | = n can be relaxed to |St | ≥ n, ∀t ∈ [T] and
the same convergence rate still holds. In fact, our full proof in Appendix A.2 is for |St| ≥ n.
4	Discussion
In light of above results, in what follows, we discuss several insights from the convergence analysis:
Convergence Rate: We show that the generalized FedAvg algorithm with two-sided learning rates
can achieve a linear speedup, i.e., an O(二长1) convergence rate with a proper choice of hyper-
parameters. Thus, it works well in large FL systems, where massive parallelism can be leveraged to
accelerate training. The key challenge in convergence analysis stems from the different local loss
functions (also called “model drift” in the literature) among workers due to the non-i.i.d. datasets and
local steps. As shown above, we obtain a convergence bound for the generalized FedAvg method
containing a vanishing term and a constant term (the constant term is similar to that of SGD). In
contrast, the constant term in SGD is only due to the local variance. Note that, similar to SGD,
the iterations do not diminish the constant term. The local variance σL2 (randomness of stochastic
gradients), global variability σG2 (non-i.i.d. datasets), and the number of local steps K (amplification
factor) all contribute to the constant term, but the total global variability in K local steps dominates
the term. When the local learning rate ηL is set to an inverse relationship with respect to the number
of local steps K, the constant term is controllable. An intuitive explanation is that the K small local
steps can be approximately viewed as one large step in conventional SGD. So this speedup and the
more allowed local steps can be largely attributed to the two-sided learning rates setting.
Number of Local Steps: Besides the result that the maximum number of local steps is improved
to K ≤ T/m, we also show that the local steps could help the convergence with the proper hyper-
parameter choices, which supports previous numerical results (McMahan et al., 2016; Stich, 2018;
Lin et al., 2018) and is verified in different models with different non-i.i.d. degree datasets in Section 5.
However, there are other results showing the local steps slow down the convergence (Li et al., 2019b).
We believe that whether local steps help or hurt the convergence in FL worths further investigations.
Number of Workers: We show that the convergence rate improves substantially as the the number
of workers in each communication round increases. This is consistent with the results for i.i.d. cases
in Stich (2018). For i.i.d. datasets, more workers means more data samples and thus less variance
and better performance. For non-i.i.d. datasets, having more workers implies that the distribution
of the sampled workers is a better approximation for the distribution of all workers. This is also
empirically observed in Section 5. On the other hand, the sampling strategy plays an important role
in non-i.i.d. case as well. Here, we adopt the uniform sampling (with/without replacement) to enlist
workers to participate in FL. Intuitively, the distribution of the sampled workers’ collective datasets
under uniform sampling yields a good approximation of the overall data distribution in expectation.
Note that, in this paper, we assume that every worker is available to participate once being enlisted.
However, this may not always be feasible. In practice, the workers need to be in certain states in order
to be able to participate in FL (e.g., in charging or idle states, etc. (Eichner et al., 2019)). Therefore,
care must be taken in sampling and enlisting workers in practice. We believe that the joint design
of sampling schemes and the generalized FedAvg algorithm will have a significant impact on the
convergence, which needs further investigations.
5	Numerical Results
We perform extensive experiments to verify our theoretical results. We use three models: logistic
regression (LR), a fully-connected neural network with two hidden layers (2NN) and a convolu-
tion neural network (CNN) with the non-i.i.d. version of MNIST (LeCun et al., 1998) and one
ResNet model with CIFAR-10 (Krizhevsky et al., 2009). Due to space limitation, we relegate some
experimental results in the supplementary material.
7
Published as a conference paper at ICLR 2021
2 L 6
SOn 6eJl
20	40	60	80	100
Communication Round
2 L 6
SOn 6eJl
dlglts_io, worker number ≡ 100
dlglts_10, worker number ≡ 50
dlglts_io, worker number ≡ 10
dlglts_2, worker number ≡ 100
dlglts_2, worker number ■ 50
dlglts_2, worker number ≡ 10
0	20	40	60	80	100
Communication Round
2 L 6
sσl 6eJJ.
0	20	40	60	80	100
Communication Round
worker number - 100, Ioca I steps ■ 1 epochs
worker number - 100, Ioca I steps ■ 5 epochs
worker number - 100, Ioca I steps " 10 epochs
worker number - 10, local steps ■ 1 epochs
worker number - 10, local steps ■ 5 epochs
worker number - 10, local steps " 10 epochs
6
O
AUeJrOSVl
,0	20	40	60	80	100
Communication Round
(a)	Impact of non-i.i.d. datasets.
:、一JV',',V
AUeJrOSVaφJ.
,0	20	40	60	80	100
Communication Round
(b)	Impact of worker number.
AUeJrOSVaφJ.
0	20	40	60	80	100
Communication Round
(c)	Impact of local steps
---- worker number - 100, Ioca I steps - 1 epochs
---- worker number - 100, Ioca I steps - 5 epochs
---- worker number - 100, Ioca I steps _ 10 epochs
----worker number - IO1 local steps ■ 1 epochs
----worker number ■ IO1 local steps ■ 5 epochs
----worker number ■ 10, local steps ■ 10 epochs
Figure 1: Training loss (top) and test accuracy (bottom) for the 2NN model with hyper-parameters
setting: local learning rate 0.1, global learning rate 1.0: (a) worker number 100, local steps 5 epochs;
(b) local steps 5 epochs; (c) 5 digits in each worker’s dataset.
In this section, we elaborate the results under non-i.i.d. MNIST datasets for the 2NN. We distribute
the MNIST dataset among m = 100 workers randomly and evenly in a digit-based manner such that
the local dataset for each worker contains only a certain class of digits. The number of digits in each
worker’s dataset represents the non-i.i.d. degree. For digits_10, each worker has training/testing
samples with ten digits from 0 to 9, which is essentially an i.i.d. case. For digits_1, each worker has
samples only associated with one digit, which leads to highly non-i.i.d. datasets among workers. For
partial worker participation, we set the number of workers n = 10 in each communication round.
Impact of non-i.i.d. datasets: As shown in Figure 1(a), for the 2NN model with full worker
participation, the top-row figures are for training loss versus communication round and the bottom-
row are for test accuracy versus communication round. We can see that the generalized FedAvg
algorithm converges under non-i.i.d. datasets with a proper learning rate choice in both cases. For
five digits (digits_5) in each worker’s dataset with full (partial) worker participation in Figure 1(a),
the generalized FedAvg algorithm achieves a convergence speed comparable to that of the i.i.d. case
(digits_10). Another key observation is that non-i.i.d. datasets slow down the convergence under the
same learning rate settings for both cases. The higher the non-i.i.d. degree, the slower the convergence
speed. As the non-i.i.d. degree increases (from case digits_10 to case digits_1), it is obvious that
the training loss is increasing and test accuracy is decreasing. This trend is more obvious from the
zigzagging curves for partial worker participation. These two observations can also be verified for
other models as shown in the supplementary material, which confirms our theoretical analysis.
Impact of worker number: As shown in Figure 1(b), we compare the training loss and test accuracy
between full worker participation n = 100 and partial worker participation n = 10 with the same
hyper-parameters. Compared with full worker participation, partial worker participation introduces
another source of randomness, which leads to zigzagging convergence curves and slower convergence.
This problem is more prominent for highly non-i.i.d. datasets. For full worker participation, it can
neutralize the the system heterogeneity in each communication round. However, it might not be
able to neutralize the gaps among different workers for partial worker participation. That is, the
datasets’ distribution does not approximate the overall distribution well. Specifically, it is not unlikely
that the digits in these datasets among all active workers are only a proper subset of the total 10
digits in the original MNIST dataset, especially with highly non-i.i.d. datasets. This trend is also
obvious for complex models and complicated datasets as shown in the supplementary material. The
sampling strategy here is random sampling with equal probability without replacement. In practice,
however, the actual sampling of the workers in FL could be more complex, which requires further
investigations.
8
Published as a conference paper at ICLR 2021
Impact of local steps: One open question of FL is that whether the local steps help the convergence
or not. In Figure 1(c), we show that the local steps could help the convergence for both full and
partial worker participation. These results verify our theoretical analysis. However, Li et al. (2019b)
showed that the local steps may hurt the convergence, which was demonstrated under unbalanced
non-i.i.d. MNIST datasets. We believe that this may be due to the combined effect of unbalanced
datasets and local steps rather than just the use of local steps only.
Table 2: Comparison with SCAFFOLD.
Dataset	IID or Non-IID	Worker selected	Model		SCAFFOLD				This paper		
				# of Round	Communication cost (MB)	Wall-clock time (s)	# of Round	Communication cost (MB)	Wan-ClOCk time (s)
MNIST	IID	n = 10	Logistic	3	036	-032-	3	0.18	-022-
			2NN	3	9.12 —	0.88	3	4.56 —	0.56
			CNN	3	26.64 —	2.23	3	13.32 —	1.57
		n = 100	Logistic	5	0.60 —	0.53	5	0.30 —	0.42
			2NN	5	15.20 —	1.51	8	12.16 —	1.49
			CNN	1	8.88	-079-	1	444	-0.50-
	Non-IID	n =10	Logistic	14	1.68 —	1.48	14	0.84 —	1.16
			2NN	14	42.55	-423-	14	21.28	-246-
			CNN	14	124.34 —	11.12	10	44.41 —	4.92
		n = 100	Logistic	7	0.84 —	0.72	11	0.66 —	0.91
			2NN	7	21.28 —	2.11	17	25.84 —	3.16
			CNN	17	150.98 —	13.50	7	31.08 —	3.51
CIFAR-10	IID	n =10	Resnet18	56	9548.07 —	583.24	44	3751.03 —	256.63
	Non-IID	n = 10	Resnet18	52	8866.06 —	539.50	61	5200.29 —	358.22
Bandwidth = 20MB/s.
Comparison with SCAFFOLD: Lastly, we compare with the SCAFFOLD algorithm (Karimireddy
et al., 2019) since it also achieves the same linear speedup effect under non-i.i.d. datasets. We
compare communication rounds, total communication load, and estimated wall-clock time under the
same settings to achieve certain test accuracy, and the results are reported in Table 2. The non-i.i.d.
dataset is digits_2 and the i.i.d. dataset is digits_10. The learning rates are ηL = 0.1, η = 1.0,
and number of local steps K is 5 epochs. We set the target accuracy = 95% for MNIST and
= 75% for CIFAR-10. Note that the total training time contains two parts: i) the computation
time for training the local model at each worker and ii) the communication time for information
exchanges between the workers and the server. We assume the bandwidth 20 MB/s for both uplink
and downlink connections. For MNIST datasets, we can see that our algorithm is similar to or
outperforms SCAFFOLD. This is because the numbers of communication rounds of both algorithms
are relatively small for such simple tasks. For non-i.i.d. CIFAR-10, the SCAFFOLD algorithm takes
slightly fewer number of communication rounds than our FedAvg algorithm to achieve = 75%
thanks to its variance reduction. However, it takes more than 1.5 times of communication cost and
wall-clock time compared to those of our FedAvg algorithm. Due to space limitation, we relegate the
results of time proportions for computation and communication to Appendix B (see Figure 7).
6	Conclusions and future work
In this paper, we analyzed the convergence of a generlized FedAvg algorithm with two-sided learning
rates on non-i.i.d. datasets for general non-convex optimization. We proved that the generalized
FedAvg algorithm achieves a linear speedup for convergence under full and partial worker participa-
tion. We showed that the local steps in FL could help the convergence and we improve the maximum
number of local steps to T/m. While our work sheds light on theoretical understanding of FL, it
also opens the doors to many new interesting questions in FL, such as how to sample optimally in
partial worker participation, and how to deal with active participant sets that are both time-varying
and size-varying across communication rounds. We hope that the insights and proof techniques in
this paper can pave the way for many new research directions in the aforementioned areas.
Acknowledgements
This work is supported in part by NSF grants CAREER CNS-1943226, CIF-2110252, ECCS-1818791,
CCF-1934884, ONR grant ONR N00014-17-1-2417, and a Google Faculty Research Award.
9
Published as a conference paper at ICLR 2021
References
Leon Bottou, Frank E Curtis, and Jorge NocedaL Optimization methods for large-scale machine
learning. Siam Review, 60(2):223-311, 2018.
Hubert Eichner, Tomer Koren, H Brendan McMahan, Nathan Srebro, and Kunal Talwar. Semi-cyclic
stochastic gradient descent. arXiv preprint arXiv:1904.10120, 2019.
Saeed Ghadimi and Guanghui Lan. Stochastic first-and zeroth-order methods for nonconvex stochastic
programming. SIAM Journal on Optimization, 23(4):2341-2368, 2013.
Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the effects of non-identical data
distribution for federated visual classification. arXiv preprint arXiv:1909.06335, 2019.
Li Huang, Yifeng Yin, Zeng Fu, Shifa Zhang, Hao Deng, and Dianbo Liu. Loadaboost: Loss-based
adaboost federated machine learning on medical data. arXiv preprint arXiv:1811.12629, 2018.
Eunjeong Jeong, Seungeun Oh, Hyesung Kim, Jihong Park, Mehdi Bennis, and Seong-Lyun Kim.
Communication-efficient on-device machine learning: Federated distillation and augmentation
under non-iid private data. arXiv preprint arXiv:1811.11479, 2018.
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurelien Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances
and open problems in federated learning. arXiv preprint arXiv:1912.04977, 2019.
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank J Reddi, Sebastian U Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for on-device federated
learning. arXiv preprint arXiv:1910.06378, 2019.
Ahmed Khaled, Konstantin Mishchenko, and Peter Richtdrik. Better communication complexity for
local sgd. arXiv preprint arXiv:1909.04746, 2019a.
Ahmed Khaled, Konstantin Mishchenko, and Peter Richtdrik. First analysis of local gd on heteroge-
neous data. arXiv preprint arXiv:1909.04715, 2019b.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127, 2018.
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges,
methods, and future directions. arXiv preprint arXiv:1908.07873, 2019a.
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of
fedavg on non-iid data. arXiv preprint arXiv:1907.02189, 2019b.
Tao Lin, Sebastian U Stich, Kumar Kshitij Patel, and Martin Jaggi. Don’t use large mini-batches, use
local sgd. arXiv preprint arXiv:1808.07217, 2018.
H Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, et al. Communication-efficient
learning of deep networks from decentralized data. arXiv preprint arXiv:1602.05629, 2016.
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konecny,
Sanjiv Kumar, and H Brendan McMahan. Adaptive federated optimization. arXiv preprint
arXiv:2003.00295, 2020.
Felix Sattler, Simon Wiedemann, Klaus-Robert Muller, and Wojciech Samek. Robust and
communication-efficient federated learning from non-iid data. IEEE transactions on neural
networks and learning systems, 2019.
Sebastian U Stich. Local sgd converges fast and communicates little. arXiv preprint arXiv:1805.09767,
2018.
10
Published as a conference paper at ICLR 2021
Sebastian U Stich and Sai Praneeth Karimireddy. The error-feedback framework: Better rates for sgd
with delayed gradients and compressed communication. arXiv preprint arXiv:1909.05350, 2019.
Sebastian U Stich, Jean-Baptiste Cordonnier, and Martin Jaggi. Sparsified sgd with memory. In
Advances in Neural Information Processing Systems,pp. 4447-4458, 2018.
Jianyu Wang and Gauri Joshi. Cooperative sgd: A unified framework for the design and analysis of
communication-efficient sgd algorithms. arXiv preprint arXiv:1808.07576, 2018.
Jianyu Wang, Vinayak Tantia, Nicolas Ballas, and Michael Rabbat. Slowmo: Improving
communication-efficient distributed sgd with slow momentum. arXiv preprint arXiv:1910.00643,
2019a.
Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K Leung, Christian Makaya, Ting He, and
Kevin Chan. Adaptive federated learning in resource constrained edge computing systems. IEEE
Journal on Selected Areas in Communications, 37(6):1205-1221, 2019b.
Hao Yu, Rong Jin, and Sen Yang. On the linear speedup analysis of communication efficient
momentum sgd for distributed non-convex optimization. arXiv preprint arXiv:1905.03817, 2019a.
Hao Yu, Sen Yang, and Shenghuo Zhu. Parallel restarted sgd with faster convergence and less
communication: Demystifying why model averaging works for deep learning. In Proceedings of
the AAAI Conference on Artificial Intelligence, volume 33, pp. 5693-5700, 2019b.
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. Federated
learning with non-iid data. arXiv preprint arXiv:1806.00582, 2018.
Fan Zhou and Guojing Cong. On the convergence properties of a k-step averaging stochastic gradient
descent algorithm for nonconvex optimization. arXiv preprint arXiv:1708.01012, 2017.
11
Published as a conference paper at ICLR 2021
A Appendix I: Proofs
In this section, we give the proofs in detail for full and partial worker participation in Section A.1 and
Section A.2, respectively.
A.1 Proof of Theorem 1
Theorem 1. Let constant local and global learning rates ηL and η be chosen as such that ηL ≤ 8Lk
and ηηL ≤ KL. Under Assumptions 1-3 and WithfUU worker participation, the sequence OfoUtPUtS
{xk } generated by Algorithm 1 satisfies:
min E[kVf (xt)k2] ≤ f-f + Φ,
t∈[T]	cηηL KT
where Φ，1 [LLnm °L + 'KL (。； + 6KσG)], C is a constant, f，f (x0), f，f (x*) and the
expectation is over the local dataset samples among workers.
Proof. For convenience, We define ∆t，+ Pm=I △；. Under full device participation (i.e., St =
[m]), it is clear that Z = m1 Pm=I ∆i = At.
Due to the smoothness in Assumption 1, taking expectation of f (xt+1 ) over the randomness at
communication round t, We have:
Et[f (xt+1)] ≤ f (Xt) + (Vf(Xt), Et[xt+ι - xt]) + LEt[∣∣xt+ι - xtk2]
=f(xt)+(Vf (xt),Et[η∆t + ηηLKVf(Xt)- ∙ψilKVf(Xt)]〉+Lη2Et[k∆tk2]
=f (xt)-ηηLK kVf (xt)k2+η (Vf(Xt), Et[∆ t+ηLK Vf (xt)])+Lη2 Et[k∆ tk2].
{z} 2 S{}
A1	A2
(1)
Note that the term A1 in (1) can be bounded as folloWs:
A1 = (Vf(Xt), Et [∆t + ηLKVf (Xt)])
Vf(xt), Et -
m K -1
m XX ηLgi,k + ηLK Vf(Xt)
i=1 k=0
m K -1
Vf(Xt), Et - m XX
i=1 k=0
1m
ηLVFi(Xt*)+ ηLK- X VFi(Xt)
,m
i=1
√-- m K-1
PLKVf (Xt), -m√KEtX X (VFt(xt,k) - VFt(Xt))
(=)ηLK kVf (xt)k2 +
ηL
2Km2
mK-1	2
EtXX VFi(Xt,k)-VFi(Xt)-2κm
=1 k=0
mK -1
EtXXVFi(Xit,k)
i=1k=0
2
啜竽 kVf(xt)k2 + 罗
2	2m
mK -1
XXEtkVFi(Xit,k)-VFi(Xt)k2-
mK-1
2⅛Et XX VFi(Xt,k)
i=1 k=0
2
啜 ηLκ kVf(xt)∣∣2+ηLm2 XX1 EtkXi,k-xtk2-
i=1 k=0
m K -1	2
2⅛Et X X VFi(Xt，k)
i=1 k=0
(≤)7LK(2+15K 2ηL L2)kVf (Xt)k2+5K 2nL L2
mK -1
(σL + 6KσG)-2Km2Et XXVFi(xi,k)
i=1 k=0
2
(2)
12
Published as a conference paper at ICLR 2021
where (a1) follows from that(x, y) = 1 [kx∣∣2 + ∣∣yk2 - ∣∣x - y∣∣2] for X = √r∣∑jK▽/(Xt) and
y = - m√√K Pm=I PKOI(VFi(Xi,k) - VFi (Xt)), (a2) is due to that E[kx1 + …+ Xn k2] ≤
nE[∣xι∣2 +---+ ∣∣Xn∣2] , (a3) is due to Assumption 1 and (a4) follows from Lemma 2.
The term A2 in (1) can be bounded as:
A2 = Et[∣∆ tk2]
m
2
m
Etm χ *
i=1
m
≤ m2Et	X S
(a5)
i=1
m	K-1 i 2
gt,k
i=1 k=0
Xm KX-1(gti,k-VFi(Xti,k))2 +
m	K-1
X X VFi (Xit,k)
i=1 k=0
(≤6) KLσL +
m
m	K-1
VFi (Xit,k)	,
i=1 k=0
(3)
m
2
2
2
where (a5) follows from the fact that E[∣X∣2] = E[∣X - E[X]∣2] + ∣E[X]∣2] and (a6) is due
to the bounded variance assumption in Assumption 3 and the fact that E[∣χι + •…+ Xn∣2]=
E[∣∣xι∣∣2 +----+ ∣∣Xn∣2] if Xis are independent with zero mean and E[gi,j] = VFi(Xtj).
Substituting the inequalities in (2) ofA1 and (3) of A2 into inequality (1), we have:
Et[f(χt+ι)] ≤ f(χt)-ηηLKIIVf(Xt)I∣2+η< Vf(Xt),Et[∆t+ηMVf(xt)] >+Lη2Et[∣∣∆11∣2]
'-------------------------------------------{z---------} 2	'--{z-}
A1	A2
≤ f(Xt) - ηηLK(1 - 15K2ηLL2)∣Vf(Xt)∣2 + LK⅛σL
2	2m
+ 吟LL2(σL + 6KσG) -(小-g)Et XXVFi(X获)
2	2Km2	2m2	,
(≤f (Xt)-ηηLK(1-5K2ηLL2)kVf (Xt)k2+LKη2^σL+5ηK?LL2 (σL+6KσG)
2	2m	2
(≤}f (Xt) - CnnLKkVf(Xt)k2 + LKn ηLσL + 5nKJLL (σL + 6KσG),
2m	2
where (a7) follows from (2Kmm∑ - LmL) ≥ 0 if nnL ≤ KL, (a8) holds because there exists a
constant c > 0 satisfying (1 - 15K2nL L2) > c > 0 if nL < √30KL.
Rearranging and summing from t = 0,…，T - 1, we have:
X^ CnnLKE[Vf (Xt)] ≤ f (X0) - f (XT) + T(nnLK) [LnmLσL + 5Kn2LL2(σL + 6KσG)
which implies,
min E∣Vf (Xt)∣2 ≤ f⅛ +Φ,
t∈[T]	CnnLKT
where Φ = 1 [LmσLL + 5KnLL (σL + 6KσG)]. This completes the proof.
□
13
Published as a conference paper at ICLR 2021
A.2 Proof of Theorem 2
Theorem 2. Under Assumptions 1-3 with partial worker participation, the Sequence of outputs
{xk } generated by Algorithm 1 with constant learning rates η and ηL satisfies:
min E[kVf (xt)k2] ≤ f0-f + Φ,
t∈[T]	cηηL KT
where f = f (x0), f = f (x*), and the expectation is over the local dataset samples among workers.
For sampling Strategy 1, let η and ηL be chosen as such that ηL ≤ 8Lk, ηηLKL < n-1 and
30K2ηLL2 — LrInL (90K3L2ηL + 3K) < 1. It then holds that:
Φ，1 [粤σL + ?LσG + (『+ *四)(σL + 6KσG)1 .
c 2n	2n	2	2n
For sampling Strategy 2, let η and ηL be chosen as such that ηL ≤ 8LK, ηηLKL ≤ n(m]) and
10K2ηLL2 — LnnLnm-ni)(90K3ηLLL2 + 3K) < 1. It then holds that:
1 LηηL 2	m — n 2	5K ηL2 L2	2 3 3 m — n 2	2
φ , C [丁σL+3LKnnL 2n(m — 1) σG+^-^+15K nnLL 2n(m — 1) J(σL+6KσG)
Proof. Let At be defined the same as in the proof of Theorem 1. Under partial device participation,
note that At = At (recall that At，* Pm=I Ai, At = 1 Pi∈st ∆i, and |St| = n). The random-
ness for partial worker participation contains two parts: the random sampling and the stochastic
gradient. We still use EtH to represent the expectation with respect to both types of randomness.
Due to the smoothness assumption in Assumption 1, taking expectation of f(xt+1) over the random-
ness at communication round t:
Et[f(xt+ι)] ≤ f(xt) +〈Vf(xt),Et[xt+ι — XtD + LEt[∣∣xt+ι — xtk2]
=f(xt) + Wf(Xt),Et[nAt + nnLKVf(Xt) - nnLKVf(Xt)])+ Ln2Et[kAtk2]
=f(xt)—nnLKkVf (xt)k2+n (Vf(Xt), EQ+nzK Vf(Xt)D + Ln2 Et[kAtk2]
'---------------------------------------{z------------} 2	X—{—}
A01	A02
(4)
The term A01 in (4) can be bounded as follows: Since ESt [A01] = A1 due to Lemma 1 for both
sampling strategies, we have the same bound as in inequality 2 for A01 :
A01 ≤ nLK(2 + 15K2nLL2)kVf (xt)k2 + 5K2nLL2 (σL + 6KσG)
m K-1	2
-2KmEt XXVFi(xt,k) , (5)
i=1 k=0
For strategy 1: We can bound A02 in (4) as follows.
Note St is an index set (multiset) for independent sampling (equal probability) with replacement in
which some elements may have the same value. Suppose St = {l1 , . . . , ln}.
A02 = Et[kAtk2]
=EtlnX At
2
i∈St
14
Published as a conference paper at ICLR 2021
n Et	x $
2
i∈St
1n
n2Et	X ∆tz
(b1)
z=1
n K-1
X X[gltz,j -PFlz(χltz,j)]
z=1 j =0
(b2) Kη2	2
≤ TL σ+
n K-1
X X PFlz(χltz,j)
z=1 j=0
+
n K-1
X X PFlz(χltz,j )
z=1 j=0
where (b1) follows from the fact that E[kχk2] = E[kχ - E[χ]k2] + kE[χ]k2] and (b2) is due to the
bounded variance assumption 3 and E[∣Ε ++ xnk2] ≤ nE[∣∣χιk2 ++ Ilxnk2].
By letting t = PK=o1 PFi(Xit,j), We have：
n K-1
Et	ΕΣ>Fiz(χtZj)
z=1 j=0
Et	tlz
z=1
=Et	ktlzk2+	tli,tlj
z=1	i6=j;li,lj ∈St
(=b3) Et nktl1 k2 + n(n -1)tl1,tl2
n(n -1)
m2
n(n -1)
m2
ti,tj
i,j∈[m]
m
kXtik2,
i=1
n
2
2
2
2
2
n 2
Where (b3) is due to the independent sampling With replacement.
So We can bound A02 as folloWs.
A02 = Et[k∆tk2]
≤ Kη2σL + 迄 XEtktik2 + (n二萼
n mn	m2n
i=1
Et
m 2
Xti
i=1
(6)
For ti , We have:
mm
XEtktik2=XEt
i=1	i=1
K-1
X PFi(χit,j ) - PFi(χt) + PFi(χt) - Pf(χt) + Pf(χt)
j=0
2
(b4)	m K-1
≤ 3KL2ΣΣEtkχit,j -χtk2 + 3mK2σG2 + 3mK2kPf(χt)k2
i=1 j=0
(b5)
≤ 15mK3L2ηL2(σL2 + 6KσG2 ) +(90mK4L2ηL2 + 3mK 2)kPf (χt)k2 +3mK2σG2 ,
(7)
where (b4) is due to the fact that E[kxι +-+ xnk2] ≤ nE[kxιk2 +-------+ kxnk2], Assumptions 3
and 1, and (b5) folloWs from Lemma 2.
Substituting the inequalities in ( 5) of A01 and ( 6) of A02 into inequality (4), we have:
15
Published as a conference paper at ICLR 2021
Et[f(χt+ι)] ≤ f(χt)-ηηLKkVf(χt)k2+η(Vf(Xt),Et[∆t+ηLKVf(Xt)]>+Lη2e/|A『]
|------------------------------------------------------} 2
|	{Z
A01
≤ f(Xt)- ηηLK(1 - 15K2ηLL2)∣vf(Xt)k2 +
|—-—}
A02
5ηΚ用(σL + 6KσG)
(n - 1)Lη2ηL2	ηηL
2m2n	2Km2
m
Et X ti
i=1
2. LKη2ηL 2 ILnnL Xm	2
+^n^ σL+ιmnτ TEtktik
i=1
+
—
(≤ f (Xt) - ηηLK(1 - 15K2ηLL2)kVf (xt)k2 + 5ηK2ηLL2 (σL + 6KσG)
+ TσL + 嚅L XXEtktik2
i=1
(≤ f(χt4-ηηLK(g - 15K2ηLL2 - LnL(90K3L2rL + 3K))kVf(χt)k2
+ [5ηK2rLL2 + 15K3L3η2ηL] (σ2+6Kσ2)+ LKη2ηLσ2 十空2互近先
+ _	2	+	2n	_|( L+ G)+	2n	L +	2n	G
(b8) f (χt) - cηηLKkVf(χt)k2 +『σL + 竺户σG
2n	2n
+ ηηLK [ 5KfL2 + WLM l(σL + 6KσG),	(8
2	2n
where (b6) follows from ⑺—小；ηL - 2Κ⅛^ ≤ 0 if ηηLKL ≤ n-1, (b7)is due to inequality (7) and
(b8) holds since there exists a constant c > 0 such that [ 11 一 15K2ηLL2 一 LnnL (90K3L2ηL + 3K)] >
c> 0 if 30K2 ηL L2 - LnL (90K 3L2ηL +3K) < 1.	九
Note that the requirement of |St| = ncan be relaxed to |St| ≥ n. With pt ≥ n workers in t-th
communication round, 8 is
Et[f(χt+1)] ≤ f(χt) - cηηLKkVf(χt)k2 + LKn泣σL + 3KLη2ηLσG
2pt	2pt
+ nnLK [ F + 至” ](σL +6KσG)
2	2pt
≤ f(χt) - CnnLKkVf(χt)k2 + LK⅛σL + 竺户• σG
2n	2n
+ nnLK [ 5KnLL2 + 空严](σL +6KσG).
2	2n
That is, the same convergence rate can be guaranteed if at least n workers in each communication
round (no need to be exactly n).
Rearranging and summing from t = 0,…，T - 1, we have the convergence for partial device
participation with sampling strategy 1 as follows:
min E[kVf (χt)k2] ≤ f-⅛ + Φ,
t∈[T]	cnnL KT
where Φ = 1 [LnLσL + 3KLnnLσG + (5KjLL2 + 1美炉)(σL + 6KσG)] and C is a constant.
For strategy 2: Under the strategy of independent sampling with equal probability without replace-
ment. We bound A02 as follows.
A02 = Et[k∆tk2]
=Ml n X δ/
i∈S
16
Published as a conference paper at ICLR 2021
~E Et
n2
-E Et
n2
X ∆it E
i∈St
Xm I{i∈St}∆itE
m	K-1
XI{i∈St}* X[gti,j-VFi(χit,j)]
K-1
2
(b9) ηL2
i=1
m
j=0
K-1
ΣP{i ∈ St} ∑[gi,j -vFi (χt,j)]
i=1	j=0
m K-1
22
+ η2
+ n2
nηL Et ∑∑ gi,j -vFi(χt,j)
I{i ∈ St}	VFi(χit,j)]
i=1	j=0
m	K-1	E
XI{i∈St}XVFi(χit,j)
i=1	j=0
K-1	E
i=1 j=0
(b10) KηE E ηE
≤」L σL +
n	nE
∑I{i ∈ St} E VFi(Xij)
i=1
j=0
K-1
i=1
P{i ∈ St}	VFi(χti,j )
j=0
(9)
m
2
m
2
2
+
+
m
2
where (b9) is due to the fact that E[∣∣χι + …+ xnk2] = E[∣∣χ1k2 + …+ Ilxnk2] if Xis are
independent with zero mean, χi = gti,j - VFi (χti,j) is independent random variable with mean zero,
and P{i ∈ St} = mn. (b10) is due to bounded variance assumption in Assumption 3
Substituting the inequalities in (5) of A01 and (9) of A02 into inequality (4), we have:
Et [f (xt+ι)] ≤ f (xt)-ηηLK kVf (xt)∣∣2+η <Vf(xj Et[∆t +nLK Vf (xt)]〉+Lη2 Et[∣∣∆t ∣∣2]
'-----------------------------------------------{z------------} 2 S----{--'
A01	A02
≤ Vf (xt) - nnLK(2 - 15K2nLL2)kVf (xt)k2 + LKnnnEσL + 5nK2nLL2 (σL + 6KσG)
+ Ln2nL
+ 2n2
m	K-1	2
XP{i ∈ St} X VFi(Xi,j)	- 2K⅛
i=1	j=0
m	K-1	2
XX
VFi(xit,k)
i=1 k=0
/
{z^
A03
Then we bound A03 as follows.
By letting ti = PjK=-01 VFi(xit,j), we have:
m
XEtktik2 ≤ 15mK3L2nL2(σL2 +6KσG2 )+ (90mK4L2nL2 +3mK2)kVf(xt)k2 +3mK2σG2 .
i=1
It then follows that
m
kXtik2=Xktik2+X<ti,tj>
丝) X m∣tik2- 2 X kti- tj k2
i∈[m]	i6=j
m
k X P{i ∈ St}tik2 = X P{i∈ St}ktik2+XP{i,j∈ St} <ti,tj >
i=1	i∈[m]	i6=j
丝) m X ktik2+「X < ti,tj>
i∈[m]	i6=j
17
Published as a conference paper at ICLR 2021
(b=3)n2 X ktik2 -
m
i∈[m]
where (b11) and (b13) are due to the fact that x, y
⅛≡⅛ X kti- tjk2,
1 [kχk2+kyk2-kχ-yk2] ≤ 2[kχk2+kyk2],
(b12) follows from the fact that P{i ∈ St} = m and P{i,j ∈ St}
A0 _ Ln2ηL
3 = 2n2
K-1
k x P{i ∈ St} x VFi(Xt,j)]∣2- 2Km
=m≡¾. Therefore, Wehave
m K-1
i=1
Ln2 nL2	nnL
2m	2Km
j=0
m
)Xktik2+(
i=1
k	VFi(χit,k)k2
i=1 k=0
ηηL	Lη2ηL2 (n - 1)
4Km2	4mn(m - 1)
) kti-tjk2
i6=j
(b=4)( Lη2ηL - Lη2ηL (n — 1)
2m	2n(m - 1)
(b15) Ln2nL	Ln2nL(n - i)
一 0™	2n(m — 1)
m
2m
m
)Xktik2-(
i=1
m
) X ktik2
i=1
ηηL	Lη2ηL2 (n - 1)
2Km2	2mn(m - 1)
)k	tik2
i∈[m]
Ln2nL2 m - n1 ʌ X ktik2,
27n(7 - 1)
where (b14) follows from the fact that k Pi∈[m] tik2 = Pi∈[m] mktik2 - 1 Pi=j kti - tj Il2, and
(b15) is due to the fact that (
Then we have
Tn	Lnn2 (n-1)
_ . .
----k - ----T---.
2Km2	2mn(m-1)
)≥ 0 if nnLKL ≤ ⅛≡⅛.
Et[f(χt+ι)] ≤ f(χt)-ηηLK(2 — 15K2ηLL2-LnnL
m-n
2n(m - 1)
(90K 3ηL L2 + 3K ))kVf(xt)k2
(
m
—
—
—
—
LKη2ηL2
+
2n
σL +3K 2Ln2nL ,7 - nυ σG
2n(m - 1)
+ nnLK(5KrLL + i5KnnL L3 7rm~n∩ )(σL + 6KσG)
2	2n(m - 1)
(b16)
≤ f(χt) - cηηLKkVf(χt)k2 +
LKη2ηL2
2n
σL + 3KLn2nL ；7 - nn σG
2n(m - 1)
+ nnLK (KrnLLL + 15K 2nnL L3
m-n
2n(m - 1)
)(σL2 +6KσG2 ),
(10)
where (b16) holds because there exists a constant c > 0 satisfying (21 一 5K2rLL2 一
LnnL2nm-n1 (90K3ηLL2 + 3K)) > C > 0 if 10κ2ηLL2 - LnnLnm-¾(90K3ηLL2 + 3K) < 1.
Note that the requirement of |St| = n can be relaxed to |St| ≥ n. With pt ≥ n workers in t-th
communication round, 10 is
Et[f(xt+1)] ≤ f(xt) - cηηLKkVf(xt)k2 +
LKη2ηL2
2pt
σL + "5% 2pm¾ σG
+ nnLK (5KrLL + 15K 2nnL L3 瑞~Pyy )(σL + 6KσG)
2	2pt(m - 1)
≤ f(xt) - cηηLKkVf(xt)k2 +
LKη2ηL2
2n
σL + 3KLn2nL ,7 - nυ σG
2n(m - 1)
+ nnLK (5KnLL2 + 15K 2nnLL3
m-n
2n(m - 1)
)(σL2 +6KσG2 )
That is, the same convergence rate can be guaranteed if at least n workers in each communication
round (no need to be exactly n).
18
Published as a conference paper at ICLR 2021
Rearranging and summing from t = 0,…，T - 1, we have the convergence for partial device
participation with sampling strategy 2 as follows:
min E[kVf(xt)k2] ≤ f0-f + Φ,
t∈[T]	cηηL KT
where Φ = 11^LrEL σ +3KLTmm m-n σ2 +(5κηLL +15K2∏γ3 L m-n )(σ2 +6K02 )]
Where φ = c [ 2n σL + 3KLηηL 2n(m-i)σG + (	2	+ 15K ηηLL 2n(m-1) )(σL + 6KσG )」
and C is a constant. This completes the proof.	□
A.2.1 Key Lemmas
Lemma 1 (Unbiased Sampling). For strategies 1 and 2, the estimator ∆t is unbiased, i.e.,
Est [∆t ]=∆ t.
Proof of Lemma 1.
Let St = {tι, ∙∙∙ ,tn} with size n. Both for sampling strategies 1 and 2, each sampling distribution
is identical. Then we have:
1	1 n	1m
EStd = - ESt [ X ∆ti] = - EStX ∆ti] = EStN1] = m X S = δ t.
ti∈St
i=1
i=1
A.3 Auxiliary Lemmas
Lemma 2 (Lemma 4 in Reddi et al. (2020)). For any step-size satisfying ηL ≤ 8Lκ, we can have
the following results:
m
-XE[kχt,k - χtk2] ≤ 5KηL(σL + 6KσG) + 30K2ηLkVf(χt)k2.
m,
i=1
Proof. In order for this paper to be self-contained, we restate the proof of Lemma 4 in (Reddi et al.,
2020) here.
For any worker i ∈ [m] and k ∈ [K], we have:
E[kχit,k -χtk2] = E[kχit,k-1 -χt - ηLgtt,k-1k2]
≤E[kχit,k-1-χt-ηL(gtt,k-1-VFi(χit,k-1)+VFi(χit,k-1)-VFi(χt)+VFi(χt)-Vf(χt)+Vf(χt))k2]
≤ (1 + 2κ-n)E[kxt,k-1 -χtk2] +E[kηL(gtt,
k-1 - VFi(χit,k-1))k2]
2K - 1
+6KE[kηL(VFi(χit,k-1)-VFi(χt))k2]+6KE[kηL(VFi(χt)-Vf(χt)))k2]+6KkηLVf(χt)k2
≤(1+9J 1)E[kχt,k-ι- χtk2]+ηLσL +6KnL L2E[kxt,k-i-xtk2]+6KnL σG+6KknLVf(Xt )k2
2K - 1
=(1 + ι +6KnL乙2)固|国,1 - χtk2] + nLσL + 6KnLσG + 6KknLVf(Xt)k2
2K - 1
≤ (1 + 天二)E[kχi,k-ι - χtk2] + nLσL + 6KnLσG + 6KknLVf(Xt)k2
K-1
Unrolling the recursion, we get:
m	k-1
m XE[kχi,k - χtk2] ≤ X(1 + K-I)p[nLσL + 6KσG + 6KnLknLVf (χt))k2]
i=1	p=0
≤ (K - 1)[(1 + vΛτ)K - 1][nLσL + 6KσG + 6KnL^Vf (χt))k2]
K-1
≤5KnL2(σL2 +6KσG2)+30K2nL2kVf(χt)k2
This completes the proof.	□
19
Published as a conference paper at ICLR 2021
B Appendix II: Experiments
We provide the full detail of the experiments. We uses non-i.i.d. versions for MNIST and CIFAR-10,
which are described as follows:
B.1 MNIST
We study image classification of handwritten digits 0-9 in MNIST and modify the MNIST dataset to
a non-i.i.d. version.
To impose statistical heterogeneity, we split the data based on the digits (p) they contain in their
dataset. We distribute the data to m = 100 workers such that each worker contains only a certain
class of digits with the same number of training/test samples. For example, for p = 1, each worker
only has training/testing samples with one digit, which causes heterogeneity among different workers.
For p = 10, each worker has samples with 10 digits, which is essentially i.i.d. case. In this way, we
can use the digits in worker’s local dataset to represent the non-i.i.d. degree qualitatively. In each
communication round, 100 workers run K epochs locally in parallel and then the server samples n
workers for aggregation and update. We make a grid-search experiments for the hyper-parameters as
shown in Table 3.
Table 3: Hyper-parameters Tuning.
Server Learning Rate	η∈{1,10}
Client Learning Rate	ηL ∈ {0.001, 0.01, 0.1}
Local Epochs	K ∈ {1, 5, 10}
Clients Partition Number	n ∈ {10, 50, 100}
Non-i.i.d. Degree	p∈{1,2,5,10}
We run three models: multinomial logistic regression, fully-connected network with two hidden
layers (2NN) (two 200 neurons hidden layers with ReLU followed by an output layer), convolutional
neural network (CNN), as shown in Table 4. The results are shown in Figures 2, 3 and 4.
Table 4: CNN Architecture for MNIST.
Layer Type	Size
Convolution + ReLU	5 × 5 × 32
Max Pooling	2×2
Convolution + ReLu	5 × 5 × 64
Max Pooling	2×2
Fully Connected + ReLU	1024 × 512
Fully Connected	512 × 10
B.2	CIFAR- 1 0
Unless stated otherwise, we use the following default parameter setting: the server learning rate and
client learning rate are set to η = 1.0 and ηL = 0.1, respectively. The local epochs is set to K = 10.
The total number of clients is set to 100, and the clients partition number is set to n = 10. We use the
same strategy to distribute the data over clients as suggested in McMahan et al. (2016). For the i.i.d.
setting, we evenly partition all the training data among all clients, i.e., each client observes 500 data;
for the non-i.i.d. setting, we first sort the training data by label, then divide all the training data into
200 shards of size 250, and randomly assign two shards to each client. For the CIFAR-10 dataset, we
train our classifier with the ResNet model. The results are shown in Figure 5 and Figure 6.
B.3	Discussion
Impact of non-i.i.d. datasets: Figure 2 shows the results of training loss (top) and test accuracy
(bottom) for three models under different non-i.i.d. datasets with full and partial worker participation
20
Published as a conference paper at ICLR 2021
----dlglts-l,worker number ■ ιoo
----dlglts_2,worker number* IOO
----dlglts_5,worker number* IOO
----dlglts_10,worker number" 100
----dlglts-l,worker number ■ io
----dlglts_2lworleer number" 10
----dlglts_5,worker number" 10
----dlglts_10,worker number" 10
O 20	40	60	80 IOO
Communication Round
O 20	40	60	80 IOO
Communication Round
20	40	60	80 IOO
Communication Round
20	40	60	80 IOO
Communication Round
AUeJrOSVπφl
O 20	40	60	80 IOO
Communication Round
(a) LR
(b) 2NN
20	40	60	80 IOO
Communication Round
(c) CNN
—dS⅛βjι, Iecalwepe= ι
—d⅛its_2, local st»f» = ɪ
—d⅛its_5, local st»f» = ɪ
d⅛its-ι% local stβf>s = ι
digitSJUKal β⅛pβ = 5
digitSJUKal steps = s
gMJs.gi steps = 5
digits-ιo,lαcal steps = s
digits-‰lαcal steps = ιβ
digitSjtgl steps = 10
gMJs.gi steps = ιβ
diβ⅛ ιθ,k>cal steps = ɪθ
Figure 2: Training loss (top) and test accuracy (bottom) for three models on MNIST with hyperpa-
rameters setting: local learning rate 0.1, global learning rate 1.0, local steps 5 epochs.
O 20	40	60	80 IOO
Communication Round
O 20	40	60	80 IOO
Communication Round
20	40	60	80 IOO
Communication Round
20	40	60	80 IOO
Communication Round
20	40	60	80 IOO
Communication Round
20	40	60	80 IOO
Communication Round
(c) CNN
(a) LR
(b) 2NN

Figure 3: Training loss (top) and test accuracy (bottom) for three models on MNIST with hyperpa-
rameters setting: local learning rate 0.1, global learning rate 1.0, worker number 100.
on MNIST. We can see that the FedAvg algorithm converges under non-i.i.d. datasets with a proper
learning rate choice in these cases. We believe that the major challenge in FL is the non-i.i.d. datasets.
For these datasets with a lower degree of non-i.i.d., the FedAvg algorithm can achieve a good result
compared with the i.i.d. case. For example, when the local dataset in each worker has five digits
(p = 5) with full (partial) worker participation, the FedAvg algorithm achieves a convergence speed
comparable with that of the i.i.d. case (p = 10). This result can be observed in Figure 2 for all three
models. As the degree of non-i.i.d. datasets increases, its negative impact on the convergence is
becoming more obvious. The higher the degree of non-i.i.d., the slower the convergence speed. As
the non-i.i.d. degree increases (from case p = 10 to case p = 1), it is obvious that the training loss is
increasing and test accuracy is decreasing. For these with high degree of non-i.i.d., the convergence
curves oscillate and are highly unstable. This trend is more obvious for complex models such for
CNN in Figure 2(c).
Impact of worker number: For full worker participation, the server can have an accurate estimation
of the system heterogeneity after receiving the updates for all workers and neutralize this heterogeneity
in each communication round. However, partial worker participation introduces another source
of randomness, which leads to zigzagging convergence curves and slower convergence. In each
21
Published as a conference paper at ICLR 2021
gMJs.gi steps = 5
digitSJagl steps = S
digits-‰lαcal steps = ιβ
d⅛ιt⅛2,k>cal steps = ιβ
gMjs.gi steps = ιβ
j⅛⅛jo,lβcal scβ∣>s = 10
digits-ι, local = ι
digits工 local st»f» = ɪ
d⅛its_5, local stβf>s = i
d⅛⅛-ιo, IocaUwpe = J
digitS-Lgl stβf>s = 5
dis⅛ 2,k>cal SMS = 5
0	20	40	60	80	100
Communication Round
0	20	40	60	80	100
Communication Round
20	40	60	80	100
Communication Round
0	20	40	60	80	100
Communication Round
(a) LR
0	20	40	60	80	100
Communication Round
(b) 2NN
20	40	60	80	100
Communication Round
(c) CNN
100
200	300	400
Communication Round
(a) IID.
500
Figure 4: Training loss (top) and test accuracy (bottom) for three models on MNIST with hyperpa-
rameters setting: local learning rate 0.1, global learning rate 1.0, worker number 10.
Aue∙ln8<ti31
100
200	300	400
Communication Round
(b) Non-IID.
500
Figure 5: Test accuracy with respect to worker number on CIFAR-10 dataset.
AUeJnUUe-31
—K=I
—K= 5
—K=IO
4
(a) IID.
Figure 6: Test accuracy with respect to different local steps on CIFAR-10 dataset.
(b) Non-IID.
200	300
Communication round
AUeJnUUeπ3.L
communication round, the server can only receive a subset of workers based on the sampling strategy.
So the server could only have a coarse estimation of the system heterogeneity and might not be
able to neutralize the heterogeneity among different workers for partial worker participation. This
problem is more prominent for highly non-i.i.d. datasets. It is not unlikely that the digits in these
datasets among all active workers are only a proper subset of the total 10 digits in the original MNIST
dataset, especially with highly non-i.i.d. datasets. For example, forp = 1 with 10 workers in each
22
Published as a conference paper at ICLR 2021
communication round, it is highly likely that the datasets formed by these ten workers only includes
certain small number of digits (say, 4 or 5) rather than total 10 digits. But for p = 5, it is the
opposite, that is, the digits in these datasets among these 10 workers are highly likely to be 10. So in
each communication round, the server can mitigate system heterogeneity since it covers the training
samples with all 10 digits. This trend is more obvious for complex models and datasets given the
dramatic drop of test accuracy in the result of CIFAR-10 in Figure 5.
The sample strategy here is random sampling with equal probability without replacement. In practice,
the workers need to be in certain states in order to be able to participate in FL (e.g., in charging or idle
states, etc.(Eichner et al., 2019)). Therefore, care must be taken in sampling and enlisting workers in
practice. We believe that the joint design of sampling schemes, number of workers and the FedAvg
algorithm will have a significant impact on the convergence, which needs further investigations.
Impact of local steps: Figure 3 and Figure 4 shows the results of training loss (top) and test accuracy
(bottom) for three models under different local steps with full and partial worker participation
respectively. Figure 6 shows the impact of local steps in CIFAR-10. One open question of FL is
that whether the local steps help the convergence or not. Li et al. (2019b) showed a convergence
rate O(K), i.e., the local steps may hurt the convergence for full and partial worker participation.
In this two figures, we can see that local steps could help the convergence for both full and partial
worker participation. However, it only has a slight effect on the convergence compared to the effects
of non-i.i.d. datasets and number of workers.
Comparison with SCAFFOLD: We compare SCAFFOLD (Karimireddy et al., 2019) with the
generalized FedAVg algorithm in this paper in terms of communication rounds, total communication
overloads and estimated wall-clock time to achieve certain test accuracy in Table 2. We run the
experiments using the same GPU (NVIDIA V100) to ensure the same conditions. Here, we give a
specific comparison for these two algorithms under exact condition. Note that we divide the total
training time to two parts: the computation time when the worker trains the local model and the
communication time when information exchanges between the worker and server. We only compare
the computation time and communication time with a fixed bandwidth 20MB/s for both uploading
and downloading connections. As shown in Figure 7, to achieve = 75%, SCAFFOLD performs
less communication round due to the variance reduction techniques. That is, it spends less time
on computation. However, it needs to communicates as twice as the FedAvg since the control
variate to perform variance reduction in each worker needs to update in each round. In this way, the
communication time would be largely prolonged.
23