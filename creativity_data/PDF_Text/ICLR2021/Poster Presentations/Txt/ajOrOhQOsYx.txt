Published as a conference paper at ICLR 2021
A Wigner-Eckart Theorem for
Group Equivariant Convolution Kernels
Leon Lang*
AMLab, CSL
University of Amsterdam
l.lang@uva.nl
Maurice Weiler
AMLab, QUVA Lab
University of Amsterdam
m.weiler.ml@gmail.com
Ab stract
Group equivariant convolutional networks (GCNNs) endow classical convolu-
tional networks with additional symmetry priors, which can lead to a considerably
improved performance. Recent advances in the theoretical description of GCNNs
revealed that such models can generally be understood as performing convolu-
tions with G-steerable kernels, that is, kernels that satisfy an equivariance con-
straint themselves. While the G-steerability constraint has been derived, it has
to date only been solved for specific use cases - a general characterization of G-
steerable kernel spaces is still missing. This work provides such a characterization
for the practically relevant case of G being any compact group. Our investigation
is motivated by a striking analogy between the constraints underlying steerable
kernels on the one hand and spherical tensor operators from quantum mechanics
on the other hand. By generalizing the famous Wigner-Eckart theorem for spher-
ical tensor operators, we prove that steerable kernel spaces are fully understood
and parameterized in terms of 1) generalized reduced matrix elements, 2) Clebsch-
Gordan coefficients, and 3) harmonic basis functions on homogeneous spaces.
1	Introduction
Undoubtedly, symmetries play a central role in the formulation of physical theories. Any imposed
symmetry greatly reduces the set of admissible physical laws and dynamics. Specifically in quantum
mechanics, the Hilbert space ofa system is equipped with a group representation which specifies the
transformation law of system states. Quantum mechanical operators, which map between different
states, are required to respect these transformation laws. That is, any symmetry transformation of
a state on which they act should lead to a corresponding transformation of the resulting state after
their action. This requirement imposes a symmetry constraint on the operators themselves - only
specific operators can map between a given pair of states.
The situation in equivariant deep learning is remarkably similar to that in physics. Instead of a
physical system, one considers in this case some learning task subject to symmetries. For instance,
image segmentation is usually assumed to be translationally symmetric: a shift of the input image
should lead to a corresponding shift of the predicted segmentation mask. Convolutional networks
guarantee this property via their inherent translation equivariance. The role of the quantum states
is in equivariant deep learning taken by the features in each layer, which are due to the enforced
equivariance endowed with some transformation law. The analog of quantum mechanical operators,
mapping between states, is the neural connectivity, mapping between features of consecutive layers.
As in the case of operators, there is a symmetry (equivariance) constraint on the neural connectivity
- only specific connectivity patterns guarantee a correct transformation law of the resulting features.
In this work we are considering group equivariant convolutional networks (GCNNs), which are con-
volutional networks that are equivariant w.r.t. symmetries of the space on which the convolution is
performed. Typical examples are isometry equivariant CNNs on Euclidean spaces (Weiler & Cesa,
2019) or spherical CNNs (Cohen et al., 2018). Many different formulations of GCNNs have been
proposed, however, it has recently been shown that H -equivariant GCNNs on homogeneous spaces
*This research has been conducted during an internship at QUVA lab, University of Amsterdam.
1
Published as a conference paper at ICLR 2021
H/G can in a fairly general setting be understood as performing convolutions with G-steerable ker-
nels (Cohen et al., 2019b). Convolutional weight sharing hereby guarantees the equivariance under
“translations” of the space while G-steerability is a constraint on the convolution kernel that ensures
its equivariance under the action of the stabilizer subgroup G < H. Although the space of G-
steerable kernels has been characterized for specific choices of groups G and feature transformation
laws, i.e., group representations ρ, see Section 5, no general solution was known so far. This work
characterizes the solution space for arbitrary compact groups G.
Our solution is motivated by the close resemblance of the G-steerability kernel constraint to the
defining constraint of spherical tensor operators (or more general representation operators (Jee-
vanjee, 2011)) in quantum mechanics. The famous Wigner-Eckart theorem describes the general
structure of these operators by Clebsch-Gordan coefficients, with the degrees of freedom given by
reduced matrix elements. By generalizing this theorem, we find a general characterization and pa-
rameterization of G-steerable kernel spaces. For specific examples, like G = SO(3) or compact
subgroups of G = O(2), our kernel space solution specializes to earlier work, e.g., Worrall et al.
(2016); Thomas et al. (2018); Weiler & Cesa (2019). Our main contributions are the following:
•	We present a generalized Wigner-Eckart theorem 4.1 for G-steerable kernels. It describes the
general structure of equivariant kernels in terms of 1) endomorphism bases, which generalize
reduced matrix elements, 2) Clebsch-Gordan coefficients, and 3) harmonic basis functions on
a suitable homogeneous space. In contrast to the usual formulation, we cover any compact
group G and both real and complex representations.
•	Corollary 4.2 explains how to parameterize G-steerable kernels and thus GCNNs.
•	We apply the theorem exemplarily to solve for the kernel spaces for the symmetry groups
SO(2) , Z/2 , SO(3) and O(3) , considering both real and complex representations. Thereby,
we demonstrate that the endomorphism bases, Clebsch-Gordan coefficients, and harmonic
basis functions can usually be determined for practically relevant symmetry groups.
2	Symmetry-constrained Operators and their Matrix Elements
To motivate our generalized Wigner-Eckart theorem, we review quantum mechanical representation
operators and G-steerable kernels with an emphasis on the similarity of their underlying symme-
try constraints. Due to their symmetries, the matrix elements of such operators and kernels are fully
specified by a comparatively small number of reduced matrix elements or learnable parameters, re-
spectively. This reduction is for representation operators described by the Wigner-Eckart theorem.
For clarity, we discuss this theorem in its most popular form, i.e., for spherical tensor operators
(SO(3)-representation operators transforming under irreducible representations).
The Representation Operator Constraint Consider a quantum mechanical system with symme-
try under the action of some group G, for instance rotations. The action of this symmetry group
on quantum states is modeled by some unitary G-representation1 U : G → U(H) on the Hilbert
space H. More specifically, G acts on kets according to ∣ψi → ∣ψ0i := U(g) ∣ψi and on bras ac-
cording to hψ∣ → hψ0∣ := hψ∣ U (g)t, where U (g)* is the adjoint of U (g). Observables of the system
correspond to self-adjoint operators A = AL The expectation value of such an observable in some
quantum state ∣ψi is given by hψ∣A∣ψi ∈ R.
The transformation behaviors of states and observables need to be consistent with each other. As
an example, consider a system consisting of a single, free particle in R3, which is (among other
symmetries) symmetric under rotations G = SO(3). The momentum of the particle in the direc-
tion of the three frame axes is measured by the three momentum operators (P1, P2, P3). Since
the momentum of a classical particle transforms geometrically like a vector, one needs to demand
the same for the momentum observable expectation values. If We denote by Pi := hψ∣Pi∣ψi the
expected momentum in i-direction, this means that the expected momentum of a rotated system
is given by Pi = Pj RijPj = Pj Rijhψ∖P八ψ), where R ∈ SO(3) is an element of the rota-
tion group. This result should agree with the expectation values for rotated system states, that is,
Pi = hψ0|Pi∣ψ0i = hψ∣U(R)PiU(R)∖ψ). As this argument is independent from the particular
choice of state ∖ψi, and making use of the linearity of the operations, this implies a consistency
1Unitary representations are explained in Section 3. The notation U for the operator is distinct from the
notation U of the unitary group U(H).
2
Published as a conference paper at ICLR 2021
constraint Pj RijPj = U(R)Pi U(R), which identifies the collection (P1,P2,P3) as a vector
operator. Other geometric quantities are required to satisfy similar constraints: For instance, en-
ergy is a scalar (i.e., invariant) quantity and the Hamilton operator H is a scalar operator, satisfying
H = U(R) HU(R). Similarly, any matrix valued classical quantity corresponds to a rank (1,1)
CartesiantensoroPerator(Mijjij=1,2,3 subject to Pkl RikMkl(R-1)j = U(R)*MijU(R). The
overarching framework to study such situations is the notion of a representation operator, which we
define as a family of operators (A1 , . . . , AN ) which are required to satisfy the constraint
N
π(g)ij Aj = U(g)*AiU(g)	∀g ∈ G,	(1)
j=1
where π : G → U(CN) is some unitary representation of the symmetry group under consideration.
The examples above correspond to specific choices of representations, namely the trivial represen-
tation π(R) = 1 for scalars, the “standard” representation π(R) = R for vectors and the tensor
product representation ∏(R) = R 0 (R-Iy for matrices. Spherical tensor operators, discussed
below, correspond to the irreps (irreducible representations) of SO(3).
The Steerable Kernel Constraint Convolution kernels of group equivariant CNNs are required to
satisfy a very similar constraint to that in Eq. (1). Before coming to such GCNNs, consider the case
of conventional CNNs, processing image-like signals on a Euclidean space Rd . Such signals are
formalized as c-channel feature maps f : Rd → Kc that assign a c-dimensional feature vector
f(x) ∈ Kc to each point x ∈ Rd, where we allow for K being either of the real or complex numbers
R or C. Each CNN layer maps its input feature map fin : Rd → Kcin via a convolution to an output
feature map fout := K ? fin : Rd → Kcout . Since the convolution maps cin input channels to cout
output channels, the kernel K : Rd → Kcout ×cin is matrix-valued.
Conventional CNNs are translation equivariant, however it is often desirable that the convolution
is equivariant w.r.t. a larger symmetry group, for instance the isometries E(d) of Rd (Weiler &
Cesa, 2019). For simplicity, we consider semidirect product groups of the form (Rd, +) o G, where
G ≤ GL(d) is any compact group. Group elements tg ∈ (Rd, +) o G are uniquely split into a
translation t ∈ (Rd, +) and an element g ∈ G, stabilizing the origin. They act on Rd according to
X → (tg) ∙ X ：= gx + t. The equivariance of a GCNN — which is the analog to the symmetry of
a quantum mechanical system - requires the feature spaces to be endowed with a group action of
the symmetry group. A natural choice is to model the feature spaces as spaces of feature fields, for
instance scalar, vector or tensor fields (Cohen & Welling, 2016b).
Such feature fields are defined as functions f : Rd → V , where the difference to conventional
feature maps is that the space V = Kc of feature vectors is equipped with a group representation
ρ : G → GL(V) of the stabilizer G. The full symmetry group acts on feature fields according
to f → (tg) ∙ f := ρ(g) ◦ f ◦ (tg)-1, which is known as the induced representation of ρ. As
proven in (Weiler et al., 2018a), the most general linear and equivariant map from an input field
fin : Rd → Vin to an output field fout : Rd → Vout is a convolution with a G-steerable kernel
K : Rd → HomK(Vin, Vout) == Kcout×cin. Such kernels take values in the space of linear operators
from Vin to Vout and are required to satisfy the G-steerability (equivariance) constraint
K(gX) = ρout(g) ◦ K(X) ◦ ρin(g)-1	∀g ∈ G, X ∈ Rd .	(2)
One can easily check that a convolution with a G-steerable kernel K is indeed equivariant, i.e.,
satisfies K ? ((tg) ∙ f) = (tg) ∙ (K ?f) for any tg ∈ (Rd, +) o G. This result was later generalized
to feature fields on homogeneous spaces H/G of unimodular locally compact groups H (Cohen
et al., 2019b) and on Riemannian manifolds with structure group G (Cohen et al., 2019a). That
the equivariance of the convolutional network requires G-steerable kernels in any of these settings
underlines the great practical relevance of our results.
The two constraints, Eq. (1) and Eq. (2), are remarkably similar: the left-hand-sides are in both cases
given by a G-transformation of the operator or kernel itself while the right-hand-sides are given by
pre- and postcomposition of the operator or kernel with unitary representations. More details on this
comparison can be found in Appendix C.1.3.
The Wigner-Eckart Theorem for Spherical Tensor Operators All information about a linear
operator A : H → H is encoded by its matrix elements A*" := hμ∣A∣ν)∈ C relative to a
given basis, where ∣ν)∈ H and hμ∣ ∈ H* denote basis elements of the Hilbert space and its
3
Published as a conference paper at ICLR 2021
dual. Similarly, all information about a convolution kernel K is encoded by its matrix elements
Kμν(x) := hμ∣K(x)∣νi ∈ K, where ∣ν)∈ Vin and hμ∣ ∈ Vo=Ut are elements of chosen bases for
the input representation and dual output representation. Considering general operators and ker-
nels, i.e., ignoring the symmetry constraints in Eqs. (1) and (2), all matrix elements are inde-
pendent degrees of freedom. In the case of convolution kernels, they correspond directly to the
Cout ∙ Cin learnable parameters for every point of the kernel. However, if A is a representation op-
erator -or if K is a G-steerable kernel - the symmetry constraints couple the matrix elements
to each other such that they can not be chosen freely anymore. For representation operators,
this statement is made precise by the Wigner-Eckart theorem.
The Wigner-Eckart theorem is best known in its classical form, which applies specifically to spher-
ical tensor operators. These operators are the representation operators for the irreps of SO(3), i.e.,
the Wigner D-matrices Dj : SO(3) → U(C2j+1). As such, spherical tensor operators of rank j
are defined as families Tj = (Tj-j , . . . , Tjj )> of 2j + 1 operators Tjm that satisfy the constraint
Pn=-j Dmn(g) Tn = U(g)t Tm U(g) for any g ∈ SO(3).
In order to express the operators Tjm in terms of matrix elements, we need to fix a basis of H.
Due to the SO(3)-symmetry of Tj, a natural choice are the angular momentum eigenstates2 |lni,
where l ∈ N≥0 and n = -l, . . . , l. For fixed quantum numbers j, l, and J, there are 2j + 1
components Tjm of Tj, 2l + 1 basis kets |lni, and 2J + 1 basis bras hJM|. This implies that there
are (2J + 1)(2j + 1)(2l + 1) different matrix elements hJM| Tjm |lni ∈ C for these quantum
numbers. According to the Wigner-Eckart theorem, all of these matrix elements are fully specified
by one single number (Jeevanjee, 2011):
Theorem 2.1 (Wigner-Eckart theorem for Spherical Tensor Operators). Let j, l, J ∈ N≥0 and
let Tj be a spherical tensor operator of rank j. Then there is a unique complex number, the re-
duced matrix element λ ∈ C (often written hJ kTj kli ∈ C), that completely determines any of the
(2J + 1)(2j + 1)(2l + 1) matrix elements hJM| Tjm |lni by the relation
hJM| Tm |lni = λ ∙hJM\jm;ln).
The coupling coefficients hJM|jm; lni, known as Clebsch-Gordan coefficients, are given by the
projection of the tensor product basis |jm; lni := |jm〉0 |lnion | JM). They are purely algebraic
and therefore independent of the spherical tensor operator Tj .
This result generalizes to arbitrary representation operators of the form in Eq. (1) (Agrawala, 1980).
The similarities between representation operators and G-steerable kernels suggests that a similar
statement might hold for the matrix elements of G-steerable kernels as well. As proven below,
this is indeed the case: our generalized Wigner-Eckart theorem separates their independent degrees
of freedom from purely algebraic relations between mutually dependent matrix elements. It does
therefore give an explicit parametrization of the space of G-steerable kernels.
3	Building Blocks of S teerab le Kernels
This chapter gives a brief introduction to the mathematical concepts that are required to formulate
our Wigner-Eckart theorem for G-steerable kernels. The first two of the following paragraphs ex-
plain why it is w.l.o.g. possible to restrict attention to steerable kernels on homogeneous spaces and
to irreducible representations. The following three paragraphs discuss the building blocks of steer-
able kernels, which are endomorphisms, harmonic basis functions described by the Peter-Weyl the-
orem, and tensor product representations and their Clebsch-Gordan decomposition. An illustration
of the concepts introduced in this chapter is given in Appendix A.
The Restriction to Homogeneous Spaces Convolution kernels are usually defined on a Euclidean
space Rd, i.e., they are functions K : Rd → HomK(Vin, Vout). The G-steerability constraint in
Eq. (2) relates kernel values K(x) at x to kernel values K(gx) at all other points gx on the orbit
Gx := {gx | g ∈ G} of x. To solve the constraint, it is therefore w.l.o.g. sufficient to consider
restrictions of kernels to the individual orbits, from which the full solution on Rd can be assem-
bled (Weiler et al., 2018a). By construction, the orbits have the structure of a homogeneous space:
2The system could in general have further quantum numbers, which we suppress here for simplicity.
4
Published as a conference paper at ICLR 2021
Definition 3.1 (Homogeneous Space, Transitive Action). Let ∙ : G×X → X be a continuous action
of a compact group G on a topological space X. Then X is called a homogeneous space w.r.t. G if
Q = X and if for all x,y ∈ X there is a g ∈ G such that gx = y. The action is then called transitive.
We will in the following w.l.o.g. consider steerable kernels K : X → HomK (Vin, Vout) on such
homogeneous spaces X .
Restriction to Irreducible Unitary Representations The theorems below apply specifically to
unitary representations, that is, representations for which the automorphisms ρ(g) preserve dis-
tances (Knapp, 2002). As asserted by Theorem B.20, this is not really a restriction as every
finite-dimensional linear representation can be considered as being unitary. Thus, we assume
ρ : G → U(V ), where U(V ) is the unitary group, i.e., the group of distance-preserving linear
functions on V . In the case of K = R we say orthogonal instead of unitary and write O(V ).
Additionally, prior research has shown that it is sufficient to solve the kernel constraint in Eq. (2)
for irreducible (unitary) input- and output representations instead of arbitrary finite-dimensional
representations (Weiler & Cesa, 2019). This is possible due to the linearity of the constraint and
the fact that any finite-dimensional unitary representation decomposes by Proposition B.38 into an
orthogonal direct sum of irreps. The solution for general representations can thus be recovered from
the solutions for irreps. More details on these considerations can be found in Section D.1.3.
If two unitary irreps are related by an isometric intertwiner, they are isomorphic; see Definition B.18.
The set of isomorphism classes of unitary irreps of G is denoted by G. We assume that for each
isomorphism class j ∈ G we have picked a representative irrep ρj : G → U(Vj ). We denote by dj
the dimension of Vj-, so that We have Vj = Kdj.
Overall, we can w.l.o.g. replace Rd with X and ρin and ρout by ρl : G → U(Vl) and ρJ : G →
U(VJ), Where X is a homogeneous space and ρl and ρJ are (representatives of isomorphism classes
of) irreducible unitary representations ofG. This leads to our Working definition of steerable kernels,
to Which We restrict from noW on:
Definition 3.2 (Steerable Kernel on a Homogeneous Space W.r.t. Unitary Irreps). Let X be a homo-
geneous space of G and ρl : G → U(Vl) and ρJ : G → U(VJ) be representatives of isomorphism
classes of irreducible unitary representations of G. A G-steerable kernel (on a homogeneous space
and W.r.t. unitary irreps) is any function K : X → HomK(Vl, VJ) such that the folloWing G-
steerability constraint holds:
K(gχ) = PJ(g) ◦ K(X) ◦ Pl(g)-1	∀ g ∈ G, χ ∈ X.	⑶
Endomorphisms An important concept, underlying the reduced matrix elements in the Wigner-
Eckart theorem for spherical tensor operators, is that of endomorphisms of linear representations.
Definition 3.3 (Endomorphism ofa of Linear Representation). Let P : G → GL(V ) be a linear rep-
resentation. An endomorphism of P is a linear map c : V → V Which satisfies c ◦ P(g) = P(g) ◦ c
for all g ∈ G. The space of all endomorphisms ofP is Written EndG,K(V ).
Endomorphisms play a central role in our generalized Wigner-Eckart theorem for steerable kernels.
To get an insight Why this is the case, consider a given steerable kernel K : X → HomK(Vl, VJ).
The post-composition (c ◦ K)(x) := c ◦ (K (x)) of this kernel With any endomorphism c ∈
EndG,K (VJ) is obviously still steerable, i.e., satisfies Eq. (3). A basis of the space of steerable
kernels is therefore partly explained by bases of the endomorphism spaces, and thus occurs in our
general solution. In the folloWing, We Write {cr | r = 1, . . . , EJ} for the basis of EndG,K(VJ),
Where EJ := dim(EndG,K(VJ)) is the dimension of the endomorphism space.3
The Peter-Weyl Theorem and Harmonic Basis Functions A cornerstone in our proof of the
Wigner-Eckart theorem for steerable kernels is Theorem C.7. It states that the space of steerable
kernels, Which are G-equivariant maps K : X → HomK (Vl , VJ), is isomorphic to the space of * 2
3For K = C, Schur’s Lemma D.8 tells us that the endomorphism spaces of irreducible representations are
alWays 1-dimensional, generated by the identity. For K = R, hoWever, one can shoW that they have either 1,
2, or 4 dimensions, see Brocker & Dieck (2003), Theorem II.6.3.
5
Published as a conference paper at ICLR 2021
linear G-equivariant maps of the form Kb : L2K (X) → HomK(Vl , VJ). We are therefore interested
in the representation theory of L2K(X), which is described by the Peter-Weyl theorem.4
Theorem 3.4 (Peter-Weyl Theorem, Existence of Harmonic Basis Functions). Let G be a compact
group and X a homogeneous space. Let G be the set of isomorphism classes of irreducible repre-
sentations. For j ∈ G, let ρj : G → U(Vj ) be a representative with dimension dj = dim(Vj ). Then
there are multiplicities mj ∈ N≥0 with mj ≤ dj, and for each i = 1, . . . , mj there are harmonic
basis functions Yjmi : X → K, m = 1, . . . , dj, such that the following three properties hold:
1.	The Yjmi , for fixed j and i, are steerable (Freeman & Adelson, 1991; Hel-Or & Teo, 1998),
i.e., transformation via g ∈ G can be expressed by shifting basis coefficients with ρj :
Yjmi (g-1x) =	Pdmj0=1ρjm0m(g)Yjmi0(x).
2.	Any square-integrable function f : X → K can be uniquely expanded in terms of harmonic
basis functions, i.e., f = Pj∈Gb Pim=j1 Pdmj=1 λjim Yjmi with coefficients λjim ∈ K.
3.	The Yjmi are an orthonormal system with respect to the scalar product given by integration:
Rx Yjm(x) Yjm0 (x) dx = δjj0 δii δmm0.5
Note the similarity of these properties to those encountered in usual Fourier analysis. Indeed, the
Peter-Weyl theorem can be viewed as describing the harmonic analysis on arbitrary compact groups
and their homogeneous spaces.
Tensor Products and Clebsch-Gordan Coefficients The last ingredients that we need to discuss
are tensor product representations and Clebsch-Gordan coefficients. They appear, roughly speaking,
in the following way: the kernel K can be thought of as being built from harmonic basis functions
Yjmi which transform according to the corresponding irrep ρj . When a harmonic kernel component
of type ρj acts on an input feature field of type ρl, the combination will transform according to
their tensor product Pj 0 ρι. If the convolution should map to an output field of type PJ, not any
harmonic component Yjmi is admissible, but only those for which ρJ appears as a subrepresentation
in the tensor product Pj 0 Pl. The Clebsch-Gordan coefficients encode whether Pj 0 Pl contains PJ,
and, if it does, in which way and how often PJ is embedded in the tensor product. For more details
on the definitions in this section see Appendix D.1.
Definition 3.5 (Tensor product representation). Let P : G → U(V) and ρ: G → U(V) be unitary
representations. Then their tensor product P 0 p: G → U(V 0 V) is defined by: [(ρ 0 ρ)(g)] (v 0
V) = [ρ(g)](v) 0 [ρ(g)](v).
The tensor product Pj 0 Pl of two irreps is itself in general not irreducible anymore. However, as it
is again a unitary representation, it splits by Proposition B.38 into a direct sum of irreducible unitary
subrepresentations. Thus, there is an equivariant isomorphism
CGjl : Vj 0 Vl → MJ∈Gb Ms=1 VJ.
(4)
The integer [J(jl)] is the multiplicity of VJ in Vj 0 Vl, which is zero for all but finitely many J.
The matrix elements of CGjl are denoted as Clebsch-Gordan coefficients:
Definition 3.6 (Clebsch-Gordan Coefficients). Let Yjm 0 Yln be the basis tensors in Vj 0 Vl and let
the basis element YJMs be the copy of YJM with index s in LJ∈Gb L[sJ=(1jl)] VJ. Then the Clebsch-
Gordan coefficients are the matrix elements of CGjl relative to these bases,
hs,JM|jm;lni := YJMsCGjl Yjm 0 Yln,
i.e., the scalar product of CGjl (Yjm 0 Yln) and YM.
4Usually, the Peter-Weyl theorem uses G itself as the homogeneous space and is formulated for complex
representations (Knapp, 2002). However, generalizations to arbitrary homogeneous spaces and real representa-
tions are possible, as we explain in Appendix B.2
5From a representation theoretic viewpoint, the functions Yjmi for fixed j and i span an irreducible subrep-
resentation Vji of the unitary representation λ : G → U(L2K (X)) given by [λ(g)f] (x) := f(g-1x). L2K(X)
then splits into an orthogonal direct sum L2K (X) = Lj∈Gb Lim=j1 Vji. This viewpoint is explained in the
equivalent, more representation theoretic formulation of the Peter-Weyl theorem in Theorem B.22.
6
Published as a conference paper at ICLR 2021
4 A WIGNER-ECKART THEOREM FOR G-STEERABLE KERNELS
Now that we have discussed all of the required ingredients, we are ready for stating our main the-
orem. Intuitively, our Wigner-Eckart theorem identifies exactly those combinations of harmonics,
Clebsch-Gordan coefficients and endomorphisms that, when being assembled together, yield a G-
steerable kernel K : X → HomK (Vl , VJ). The kernel will thereby comprise all those harmonics
Yjm for which the tensor product Vj 0 Vl contains Vj as a factor. The number of possible Com-
binations depends therefore on the number of different isomorphism classes j ∈ Gb for which VJ
appears as a factor in the tensor product, the multiplicity [J(jl)] with which it occurs, and the mul-
tiplicities mj of harmonics Yjmi in the Peter-Weyl decomposition that transform according to ρj .
In addition, each individual combination can subsequently be composed with an endomorphism in
EndG,K (VJ), which increases the number of combinations by a factor of EJ = dim(EndG,K (VJ))
to a total of Λjl := EJ ∙ Pj∈G [J(jl)] ∙ mj. This number is finite, as We explain in Remark D.18.
How are such assembled steerable kernels parameterized? The learnable parameters correspond
to the degrees of freedom in the individual components from which the kernel is built. While the
Clebsch-Gordan coefficients and harmonic basis functions are fixed, the endomorphisms are ele-
ments of the EJ -dimensional vector spaces EndG,K (VJ). The degrees of freedom of a G-steerable
kernel are therefore identified with the choice of endomorphisms.6 This gives a total ofΛJl param-
eters which take values in K. Note that the choice of endomorphisms corresponds directly to the
choice of reduced matrix elements of spherical tensor operators.
For a kernel K : X → HomK(Vl, VJ), we write hJ M |K (x)|lni for the matrix elements of
K(x) ∈ HomK(Vl , VJ) with indices n ≤ dl and M ≤ dJ, see also Definition D.9. Similarly,
endomorphisms c ∈ EndG,K (VJ) have matrix elements hJM|c|JM0i with M, M0 ≤ dJ. We
furthermore write hi,jm∖χ) := Ym(x). Finally, we denote the space of G-steerable kernels by
HomG (X, HomK (Vl, VJ)).
Our main result is the following Wigner-Eckart theorem for G-steerable kernels. Other versions at
different levels of abstraction can be found in Theorems D.13 and D.16.
Theorem 4.1 (Wigner-Eckart Theorem for Steerable Kernels). There is a vector space isomorphism
GKer : M b M M	EndG,K (VJ) → HomG (X, HomK(Vl, VJ)) .	(5)
j ∈G	i=1 s=1
A general steerable kernel K = GKer((cjis)jis) with cjis ∈ EndG,K (VJ) has matrix elements
mj [J (jl)] dj	dJ
hJM∖K(x)∖lni=XXXXX	JMkjisiJM0)∙〈s, JM0∣ jm; ln)∙ ^i,jm∣x) .(6)
j∈G i=1 s=1 m=1 M0 = 1
kernel matrix elements	j∈	endomorphisms
Clebsch-Gordan
harmonics
Proof. We shortly sketch a proof of this theorem. We use the notation HomG,K to denote linear
equivariant maps. The space of steerable kernels can be progressively transformed as follows:
(1)
HomG(X, HomK(Vl,VJ)) = Homg,κ(LK(X), HomK(Vl,VJ))
= HomG,κ(Mj∙∈G Mi:L Vji HomK(Vl,VJ) = Mj∙∈G MJ] HomG,κ(Vj, HomK(VLVJ))
(=)Mj∈G Mm； HomG,κ(Vj 0 % VJ)(=)Mj∙∈G Mm； HomG,k(Mj,∈g Ms=1ji)] VJ 0, VJ)
(==6)Mj∈GbMim=j1M[sJ=(1jl)]HomG,K(VJ,VJ)(==7)Mj∈GbMim=j1M[sJ=(1jl)]EndG,K(VJ)
In (1), we linearize the kernels such that they become representation operators, as detailed in
Theorem C.7. Step (2) applies the representation-theoretic version of the Peter-Weyl Theorem B.22
to decompose L2K(X) in harmonic basis functions. Step (3) makes use of the well-known fact that
linear maps can be described on each direct summand individually. Topological details are explained
6This statement is made precise by the isomorphism GKer, defined in Eq. (5) in Theorem 4.1.
7
Published as a conference paper at ICLR 2021
in Lemma D.20. In (4), we use the hom-tensor adjunction Proposition D.23. In (5), we use the
Clebsch-Gordan decomposition Eq. (4), which provides us with Clebsch-Gordan coefficients. In
(6), we use that nontrivial linear equivariant maps from VJ0 to VJ exist by Schur’s Lemma B.29 only
for J0 = J and, once again, that we can describe linear maps on each direct summand individually.
Finally, in (7) we note that HomG,K (VJ, VJ) = EndG,K(VJ) is the space of endomorphisms. The
formula of the matrix elements Eq. (6) is fully proven in Theorem D.13 by carefully tracing back all
the isomorphisms above.7
Technically, step (1) is the main gap that we had to bridge: it establishes that non-linear kernels on
X can be seen as linear representation operators on L2K (X). Steps (2) to (7) orient at the proof
of the Wigner-Eckart theorem for representation operators by Agrawala (1980). However, it differs
non-trivially from the reference by a) allowing the operator to be non-injective, b) topological con-
siderations, since L2K (X) is not simply a direct sum of irreps but its topological closure, and c) the
possibility to allow for real representations, which is Why We end UP with endomorphisms. □
We obtain the following corollary, which clarifies how steerable kernels can be parameterized:
Corollary 4.2. The space HomG (X, HomK (Vl, VJ)) of steerable kernels is spanned by basis ker-
nels {Kjisr : X → HomK(Vl, VJ) | j ∈ G, i ≤ mj, s ≤ [J (jl)], r ≤ EJ} with matrix elements
hJM1Kjisr (X)Ilni = Xm=I XM0 = 1 (JM∣cr∣ JM 0)<s,JM 0∖jm; ln) ∙ (i,jm∖χ).	⑺
A matrix-expression of the basis kernels from Eq. (7) is given in Eq. (22). Here, cr is one of the
EJ basis endomorphisms of EndG,K (VJ). This means that a general steerable kernel K : X →
HomK(Vι, VJ) is OfthefOrm K = Pj∈G PmI PsJ(Il)] PE=I λjisr ∙ Kjisr with a total of Λj =
Ej ∙ Σj∈G [J(jl)] ∙ mj learnable parameters λjisr∙ ∈ K. Overall, the kernel space can therefore be
parameterized with an isomorphism GKer : KAJl → HomG(X, HomK(VL VJ)).
Proof. We simply choose Kjisr := GKer((cjj0iis0rs0 )j0i0s0) with cjj0iis0rs0=δj0j∙ 6i，i ∙ δsοs ∙ Cr. Clearly,
the cjisr are a basis of Lj∈Gb Lim=j1 L[sJ=(1jl)] EndG,K (VJ), and since GKer is an isomorphism, the
Kjisr form a basis of steerable kernels.	□
Remark 4.3. The matrix elements hJ M |cjis|J M 0i relate to the redUced matrix elements λ ∈ C
of spherical tensor operators as follows: in the case of spherical tensor operators one deals with
complex irreps, whose endomorphism spaces are according to SchUr’s Lemma D.8 generated by
the identity. ConseqUently, sUch endomorphisms c have matrix-elements hJM|c|JM0i = λ δMM0
for some scaling factor λ ∈ C. λ is denoted as the reduced matrix element of the spherical tensor
operator. The analog to λ in oUr Wigner-Eckart theorem are the learnable parameters λjisr ∈ K.
5	Related Work
Harmonic convolUtion kernels date back to at least the early ’80s (HsU & ArsenaUlt, 1982; Rosen
& Shamir, 1988). The term steerable filter was coined in Freeman & Adelson (1991). Hel-Or &
Teo (1998) generalized steerable filters to Lie groUps. Reisert & BUrkhardt (2007) proposed matrix
valUed steerable kernels between representation spaces, which are similar to oUr G-steerable kernels.
Steerable CNNs formUlate GCNNs in the langUage of representation theory and featUre fields. This
design was proposed by Cohen & Welling (2016b), who specifically considered finite groUps, for
which the kernel constraint can be solved nUmerically. Weiler et al. (2018a) introdUced the G-
steerability constraint in the form in Eq. (2) for G = SO(3). The aUthors choose a slightly different
approach to solve the constraint in which they decompose the space HomR(Vl, VJ) = 匕* 0 VJ
instead of Vj 0 ^½ via Clebsch-Gordan coefficients. An essentially equivalent design was simulta-
neoUsly proposed by Thomas et al. (2018), who decomposed Vj 0 Vl as in the present work, see
Appendix E.5. The case of complex valued irreps of SO(2) was investigated by Worrall et al. (2016)
and Wiersma et al. (2020); see Appendix E.1. Weiler & Cesa (2019) solve the constraint for any,
7In Eq. (6) we see terms hi, jm|xi which are not present in the original Wigner-Eckart Theorem 2.1. They
appear through the linearization of steerable kernels by Theorem C.7.
8
Published as a conference paper at ICLR 2021
not necessarily irreducible, representation of the groups O(2), SO(2), DN and CN. Their solution
strategy is based on an expansion of the kernel in the Fourier basis of L2R(S1) and solving for the
Fourier coefficients satisfying the constraint. This is a special case of the strategy that we employ
in the proof of our Wigner-Eckart theorem. de Haan et al. (2020) solve for SO(2)-steerable kernels
by viewing them as invariants of the tensor product representation LR(S 1)* 0 ^½* 0 VJ. As they
use real valued irreps, they can use that the duals are isomorphic to their original counterparts. Our
Wigner-Eckart theorem unifies all of these results in one general framework.
To which use cases does the proposed kernel space solution apply? As argued by Cohen et al.
(2019b), any H-equivariant convolutional network on a homogeneous space H/G needs to satisfy a
G-steerability constraint — if H is locally compact and unimodular. While these works proved the
necessity of steerable kernels, they did not solve the Constraint - a gap which is filled by our Wigner-
Eckart theorem for compact groups G, see also Remark D.15. This framework includes in particular
the popular group convolutions on flat spaces (Cohen & Welling, 2016a) and homogeneous spaces
of compact groups (Kondor & Trivedi, 2018) and Lie groups (Bekkers, 2020), including for instance
the sphere (Cohen et al., 2018). Specifically, if ρin and ρout are chosen to be regular representations
L2K(G), steerable convolutions are equivalent to group convolutions (Weiler & Cesa, 2019).
A related line of work are Clebsch-Gordan Networks (Kondor et al., 2018; Kondor, 2018; Anderson
et al., 2019; Bogatskiy et al., 2020). They apply bilinear equivariant nonlinearities which compute
the tensor products of global irrep features. A subsequent Clebsch-Gordan decomposition disen-
tangles the product features back into irrep features. Note that in this network design, the Clebsch-
Gordan coefficients are used in the nonlinear part, which differs from our use of these coefficients
in the construction of steerable basis kernels, i.e. in the linear part of the network.
6	Example Applications
Cohen et al. (2019b) showed in a fairly general setting that every GCNN is based on G-steerable
kernels. In practice, a basis for the space of G-steerable kernels needs to be determined for param-
eterizing GCNNs. This work determines the general structure of these basis kernels for compact
(point-)symmetry groups G and their homogeneous spaces X: Corollary 4.2 explains that one needs
to determine 1) the irreps ρl of G, 2) harmonic basis functions Yjmi in L2K(X) according to the
Peter-Weyl Theorem 3.4, 3) the Clebsch-Gordan decomposition of Vj 0 Vl, given by the Clebsch-
Gordan coefficients hs, JM |jm; lni, and 4) a basis of endomorphisms cr ∈ EndG,K (VJ) for any
J ∈ Gb. Given these ingredients, they can in a fifth step be put together according to Eq. (7) to obtain
a complete, ΛJl-dimensional basis of G-steerable kernels Kjisr : X → HomK(Vl, VJ).
Appendix E demonstrates this for the examples ofG being SO(2), SO(3), O(3), and Z/2, consider-
ing both real and complex irreps. In any of these cases, we derive the kernel bases following exactly
the five steps outlined above. This procedure can easily be applied to further compact groups, for
instance SU(2) or SU(3), which play an important role in physics applications of deep learning.
7	Conclusions and Future Work
Prior work revealed that group equivariant convolutions generally rely on G-steerable kernels. Our
Wigner-Eckart theorem for G-steerable kernels characterizes them for the practically relevant case of
G being any compact group. The degrees of freedom - or learnable parameters - correspond thereby
precisely to the choice of endomorphisms. This mirrors the situation in quantum mechanics, where
the degrees of freedom of spherical tensor operators are given by reduced matrix elements.
It would be desirable to extend this result to non-compact groups, where the Peter-Weyl Theorem
does not hold anymore. One alternative might be Pontryagin duality (Reiter, 1968), which describes
the Fourier transform on locally compact abelian groups. Furthermore, for many non-compact, non-
abelian groups, one can often find a direct integral decomposition of L2C(G). This generalization of
the Peter-Weyl theorem can be found in Segal (1950) and Mautner (1955). Such generalizations of
our Wigner-Eckart Theorem might lead to a better theoretical understanding of several recent work
(Worrall & Welling, 2019; Bekkers, 2020; Sosnovik et al., 2020; Shutty & Wierzynski, 2020).
Finally, we hope that the analogies between steerable kernels and representation operators appearing
in physics inspire further research in this fascinating crossdisciplinary domain. This could lead to
applications of GCNNs for learning tasks with physical symmetries.
9
Published as a conference paper at ICLR 2021
Acknowledgments
We thank Lucas Lang for discussions on the Wigner-Eckart Theorem and observables in physics
and Patrick Forre for discussions on the link between steerable kernels and representation operators.
Additionally, we are greatful for discussions with Gabriele Cesa on the connection between real and
complex representations of compact groups. Furthermore, we thank Stefan Dawydiak and Terrence
Tao for online discussions on aspects surrounding a real version of the Peter-Weyl theorem. Finally,
we thank Roberto Bondesan, Miranda Cheng, Tom Lieberum, and Rupert McCallum for feedback
on different aspects of our work.
References
Vishnu Agrawala. Wigner-Eckart theorem for an arbitrary group or Lie algebra. Journal of Mathe-
matical Physics, 21, July 1980. doi: 10.1063/1.524639.
Brandon Anderson, Truong-Son Hy, and Risi Kondor. Cormorant: Covariant Molecular Neural
Networks. In Conference on Neural Information Processing Systems (NeurIPS), 2019.
A.V. Arkhangel’skii and M. Tkachenko. Topological Groups and Related Structures. Atlantis studies
in mathematics. Atlantis Press, Jan 2008.
Erik J. Bekkers. B-Spline CNNs on Lie groups. In International Conference on Learning Represen-
tations (ICLR), 2020.
Alexander Bogatskiy, Brandon Anderson, Jan T. Offermann, Marwah Roussi, David W. Miller, and
Risi Kondor. Lorentz Group Equivariant Neural Network for Particle Physics. In International
Conference on Machine Learning (ICML), 2020.
A. Bohm and M. Lowe. Quantum Mechanics: FoundationsandAPPlications. Springer study edtion.
Springer New York, 1993.
N. Bourbaki. General ToPology: ChaPters 1-4. Elements of mathematics. Springer, 1998.
T. Brocker and T. Dieck. Representations of Compact Lie Groups. Graduate Texts in Mathematics.
Springer Berlin Heidelberg, 2003.
Taco Cohen and Max Welling. Group Equivariant Convolutional Networks. In International Con-
ference on Machine Learning (ICML), volume 48, pp. 2990-2999, New York, New York, USA,
20-22 Jun 2016a. PMLR.
Taco Cohen, Maurice Weiler, Berkay Kicanaoglu, and Max Welling. Gauge Equivariant Convo-
lutional Networks and the Icosahedral CNN. In International Conference on Machine Learning
(ICML), volume 97, pp. 1321-1330, Long Beach, California, USA, 09-15 Jun 2019a. PMLR.
Taco S. Cohen and Max Welling. Steerable CNNs. In International Conference on Learning Rep-
resentations (ICLR), 2016b.
Taco S. Cohen, Mario Geiger, Jonas Kohler, and Max Welling. Spherical CNNs. In International
Conference on Learning Representations (ICLR), 2018.
Taco S Cohen, Mario Geiger, and Maurice Weiler. A General Theory of Equivariant CNNs on
Homogeneous Spaces. In Advances in Neural Information Processing Systems (NeuRIPS). 2019b.
John Conway. A Course in Point Set Topology. Jan 2014. doi: 10.1007/978-3-319-02368-7.
Stefan Dawydiak. Is there a Peter-Weyl-Theorem over the real numbers? Mathematics Stack
Exchange, 2020. URL https://math.stackexchange.com/q/3595292.
Pim de Haan, Maurice Weiler, Taco Cohen, and Max Welling. Gauge Equivariant Mesh CNNs:
Anisotropic convolutions on geometric graphs. arXiv e-prints, art. arXiv:2006.00724, 2020.
L. Debnath and P. Mikusinski. Introduction to Hilbert Spaces with Applications. Elsevier Science,
2005.
10
Published as a conference paper at ICLR 2021
William Freeman and Edward Adelson. The Design and Use of Steerable Filters. IEEE Transactions
OnpatternAnalysisandMachineIntelligence (TPAMI), 13:891-906, 10 1991. doi: 10.1109/34.9
3808.
J. Gallier and J. Quaintance. Differential Geometry and Lie Groups: A Second Course. Geometry
and Computing. Springer International Publishing, 2020.
Y. Hel-Or and Patrick C. Teo. Canonical Decomposition of Steerable Functions. Journal of Mathe-
matical Imaging and Vision, 9:83-95, 1998.
Roger A. Horn and Charles R. Johnson. Matrix Analysis. Cambridge University Press, USA, 2nd
edition, 2012.
Yuan-Neng Hsu and H. Arsenault. Optical pattern recognition using circular harmonic expansion.
Applied Optics, 21(22):4016-4019, 1982.
Nadir Jeevanjee. An introduction to tensors and group theoryfor physicists. Birkhauser, New York,
NY, 2011. doi: 10.1007/978-0-8176-4715-5.
R.V. Kadison and J.R. Ringrose. Fundamentals of the Theory of Operator Algebras. Volume I.
Fundamentals of the Theory of Operator Algebras. American Mathematical Society, 1997.
I. Kaplansky. Set Theory and Metric Spaces. AMS Chelsea Publishing Series. AMS Chelsea Pub-
lishing, 2001.
Anthony Knapp. Lie Groups Beyond an Introduction, Second edition, volume 140. Jan 2002. doi:
10.1007/978-1-4757-2453-0.
Risi Kondor. N-body Networks: a Covariant Hierarchical Neural Network Architecture for Learning
Atomic Potentials. arXiv e-prints, art. arXiv:1803.01588, 2018.
Risi Kondor and Shubhendu Trivedi. On the Generalization of Equivariance and Convolution in
Neural Networks to the Action of Compact Groups. In International Conference on Machine
Learning (ICML), Feb 2018.
Risi Kondor, Zhen Lin, and Shubhendu Trivedi. Clebsch-Gordan Nets: a Fully Fourier Space Spher-
ical Convolutional Neural Network. In Conference on Neural Information Processing Systems
(NeurIPS), 2018.
E.	Kowalski. An Introduction to the Representation Theory of Groups. Graduate Studies in Mathe-
matics. American Mathematical Society, 2014.
S.M. Lane, S.J. Axler, Springer-Verlag (Nowy Jork)., F.W. Gehring, and P.R. Halmos. Categories
for the Working Mathematician. Graduate Texts in Mathematics. Springer, 1998.
T.M. MacRobert. Spherical Harmonics: An Elementary Treatise on Harmonic Functions, with
Applications. Methuen, 1947.
F.	I. Mautner. Note on the Fourier inversion formula on groups. Transactions of the American
Mathematical Society, 78:371-384, 1955.
L. Nachbin and L. Bechtolsheim. The Haar integral. University series in higher mathematics. Van
Nostrand, 1965.
Marco Reisert and Hans Burkhardt. Learning Equivariant Functions with Matrix Valued Kernels.
Journal of Machine Learning Research, 8:385-408, Mar 2007.
H.	Reiter. Classical Harmonic Analysis and Locally Compact Groups. Oxford mathematical mono-
graphs. Clarendon P., 1968.
Joseph Rosen and Joseph Shamir. Circular harmonic phase filters for efficient rotation-invariant
pattern recognition. Applied Optics, 27(14):2895-2899, 1988.
I.	E. Segal. An Extension of Plancherel’s Formula to Separable Unimodular Groups. Annals of
Mathematics, 52(2):272-292, 1950.
11
Published as a conference paper at ICLR 2021
Noah Shutty and Casimir Wierzynski. Learning Irreducible Representations of Noncommutative
Lie Groups. arXiv e-prints, art. arXiv:2006.00724, June 2020.
Ivan Sosnovik, MichaI Szmaja, and Arnold Smeulders. Scale-Equivariant Steerable Networks. In
International Conference on Learning Representations (ICLR), 2020.
W.A. Sutherland. Introduction to Metric and Topological Spaces. Open university set book. Claren-
don Press, 1975.
T. Tao. An Introduction to Measure Theory. Graduate studies in mathematics. American Mathemat-
ical Society, 2013.
Terrence Tao. The Peter-Weyl Theorem, and non-abelian Fourier analysis on compact groups, 2011.
URL https://terrytao.wordpress.com/2011/01/23/the-peter-weyl-the
orem-and-non- abelian- fourier- analysis- on- compact- groups/.
Nathaniel Thomas, Tess Smidt, Steven M. Kearnes, Lusann Yang, Li Li, Kai Kohlhoff, and Patrick
Riley. Tensor Field Networks: Rotation- and Translation-Equivariant Neural Networks for 3D
Point Clouds. arXiv e-prints, art. arXiv/1802.08219, 2018.
Maurice Weiler and Gabriele Cesa. General E(2)-Equivariant Steerable CNNs. In Conference on
Neural Information Processing Systems (NeurIPS), 2019.
Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, and Taco S Cohen. 3D Steerable
CNNs: Learning Rotationally Equivariant Features in Volumetric Data. In Advances in Neural
Information Processing Systems (NeuRIPS). 2018a.
Maurice Weiler, Fred Hamprecht, and Martin Storath. Learning Steerable Filters for Rotation Equiv-
ariant CNNs. In Conference on Computer Vision and Pattern Recognition (CVPR), pp. 849-858,
Jun 2018b.
Ruben Wiersma, Elmar Eisemann, and Klaus Hildebrandt. CNNs on Surfaces using Rotation-
Equivariant Features. Transactions on Graphics, 39(4), July 2020. doi: 10.1145/3386569.33
92437.
E.P. Wigner. Gruppentheorie und ihre Anwendung auf die Quantenmechanik der Atomspektren. Die
Wissenschaft. J.W. Edwards, 1944.
Dana P. Williams. The Peter-Weyl Theorem for Compact Groups, 1991. URL https://math.d
artmouth.edu/~dana/bookspapers/pw.pdf.
Daniel Worrall and Max Welling. Deep Scale-spaces: Equivariance Over Scale. In Conference on
Neural Information Processing Systems (NeurIPS). 2019.
Daniel E. Worrall, Stephan J. Garbin, Daniyar Turmukhambetov, and Gabriel J. Brostow. Harmonic
Networks: Deep Translation and Rotation Equivariance. In Conference on Computer Vision and
Pattern Recognition (CVPR), volume abs/1612.04642, 2016.
12
Published as a conference paper at ICLR 2021
Appendix
This appendix contains a detailed and rigorous treatment of the Wigner-Eckart theorem for steerable
kernels, including background knowledge, proofs, and many example applications.
In Chapter A, we shortly look at the simple example SO(2) for motivating the concepts and results
in Section 3.
Everything afterwards, starting with Chapter B, can be read independently of the main paper and
is a self-contained treatment of our investigations. In Chapter B, we start with the foundations of
the representation theory of compact groups. We formulate the Peter-Weyl Theorem B.22, which
tells us how to decompose the space of square-integrable functions on a homogeneous space into
irreducible representations, leading to harmonic basis functions. In the second half, we include a
proof of the more algebraic parts of this theorem. We do this since the theorem is usually only
proven for complex representations in the literature, but we need it for real representation as well.
In Chapter C we investigate steerable kernels and show their similarities to representation operators
from physics and representation theory. In Theorem C.7 we will then proof a precise isomorphism
between steerable kernels and representation operators on the space of square-integrable functions
on a homogeneous space. We call these kernel operators.
In Chapter D we will then formulate and prove the Wigner-Eckart theorem for steerable kernels of
general compact groups D.13. The proof makes in essential parts use of the Peter-Weyl Theorem
and Theorem C.7, and additionally of Schur’s Lemma B.29, the hom-tensor adjunction Proposition
D.23, and the Clebsch-Gordan decomposition of tensor products.
In Chapter E, we then look at specific example applications of our theory. In these examples, we
look at specific compact transformation groups G, specific, relevant homogeneous spaces X of the
group and one of the fields R or C. For this combination we derive a basis for the space of steerable
kernels between arbitrary irreducible input- and output representations of the group. Specifically,
we look at harmonic networks (Worrall et al., 2016), SO(2)-equivariant networks for real represen-
tations (Weiler & Cesa, 2019), Z2-equivariant networks for real representations, SO(3)-equivariant
networks for both real and complex representations (Weiler et al., 2018a; Thomas et al., 2018),
and O(3)-equivariant networks for both real and complex representations. The investigation of Z2-
equivariant CNNs will additionally show that our result is consistent with group convolutional CNNs
for the regular representation (Cohen & Welling, 2016a).
In Chapter F, we summarize some important notions and results from the theory of topological
spaces, metric spaces, normed vector spaces, and (pre-)Hilbert spaces that we use throughout this
appendix.
Chapters B, C, and D contain the bulk of the theoretical work. We recommend the reader to first only
read the first halves of these chapters, Sections B.1, C.1 and D.1, since they contain the formulation
of the most important results and the main intuitions, whereas the second halves of these chapters,
i.e., Sections B.2, C.2 and D.2, mainly contain detailed proofs that can be skipped when going over
the material for the first time.
Contents of the Appendix
A Building Blocks of SO(2)-Steerable Kernels - Running Example for Section 3	19
B Representation Theory of Compact Groups	22
B.1	Foundations of Representation Theory and the Peter-Weyl Theorem ........ 22
B.2	A Proof of the Peter-Weyl Theorem ...................................... 29
C The Correspondence between Steerable Kernels and Representation Operators 40
C.1 Fundamentals of the Correspondence ...................................... 40
C.2 A Proof of the Correspondence between Steerable Kernels and Kernel Operators .	47
13
Published as a conference paper at ICLR 2021
D A Wigner-Eckart Theorem for Steerable Kernels of General Compact Groups	51
D.1	A Wigner-Eckart Theorem for Steerable Kernels and their Kernel Bases ......... 52
D.2	Proof of the Wigner-Eckart Theorem for Kernel Operators ...................... 63
E Example Applications	67
E.1	SO(2)-Steerable Kernels for Complex Representations - Harmonic Networks ...	68
E.2	SO(2)-Steerable Kernels for Real Representations ............................. 70
E.3	Z2-Steerable Kernels for Real Representations ................................ 75
E.4	SO(3)-Steerable Kernels for Complex Representations........................... 79
E.5	SO(3)-Steerable Kernels for Real Representations ............................. 81
E.6	O(3)-Steerable Kernels for Complex Representations ........................... 86
E.7	O(3)-Steerable Kernels for Real Representations .............................. 90
F Mathematical Preliminaries	90
F.1	Topological Spaces, Normed Spaces, and Metric Spaces ......................... 90
F.2	Limits of nets and approximated Dirac delta functions ........................ 94
F.3	Pre-Hilbert Spaces and Hilbert Spaces ........................................ 95
List of Symbols
General Set Theory and Functions
iii
BBAAABBB
∩∪∈I ∈I ∈I⊆(
AATiSiFiAAA
A×B
0
X := Y
intersection of sets A and B
union of sets A and B
intersection of sets Ai
union of sets Ai
union of sets Ai which are disjoint from each other
A is a subset of B
A is a strict subset of B
set of all elements in A which are not in B
Cartesian product of sets or structures (e.g., groups) A, B
empty set
X is defined as Y
〜 often an equivalence relation
[x]	equivalence class with respect to an equivalence relation
1A indicator function of set A
f ◦ g composition of two composable functions f and g
f-1 either the inverse of function f or the preimage function
f|A restriction ofa function f to a subset A
Numbers and Collections of Numbers
N natural numbers including 0
Z integers
R	field of real numbers
C	field of complex numbers
H skew-field of quaternions
K one of the two fields R and C
Kn	n-dimensional canonical vector space over K
X complex conjugate of x
14
Published as a conference paper at ICLR 2021
Groups
G
1,e
0
GoH
CN
DN
SO(d)
O(d)
O(V)
SU(d)
U(d)
U(V)
E(d)
a compact topological group
neutral element of a group with multiplication as operation
neutral element of an additive group
semidirect product of two groups G and H
group of planar rotations of a regular N -gon
group of planar rotations and reflections of a regular N -gon
special orthogonal group in d real dimensions
orthogonal group in d real dimensions
orthogonal group of a real Hilbert space V
special unitary group in d complex dimensions
unitary group in d complex dimensions
unitary group of a complex Hilbert space V
Euclidean motion group in d dimensions
Basic Representation Theory
ρ a linear representation of a group
ρv	The function G → V , g 7→ ρ(g)(v)
ρuv	matrix coefficient of the unitary representation ρ
ρin , ρout	representations of the in-field and out-field, respectively
ρHom	Hom-representation on HomK (V, V 0) of representations ρ
and ρ0
P 0 ρ0	tensor product representation on V 0 V0 of representations
ρ and ρ0
IndGH ρ	induced representation on H or a representation ρ on G
G set of isomorphism classes of unitary representations on G
l an isomorphism class of unitary representations
ρl a representative of isomorphism class l
Vl	vector space on which ρl acts
vli or Yln	fixed chosen orthonormal basis vector of Vl
Vector Spaces and Hilbert Spaces
dim(V)	dimension of K-vectorspace V
V ⊥ W V and W are perpendicular
V = W V and W are isomorphic with respect to their structures
V	W V and W are not isomorphic with respect to their structures
hf |gi	bra-ket notation ofa scalar product on a Hilbert space
hy|f |xi	equivalent to hy|f(x)i for a function f
null(f) null space of f
im(f)	image of f
f * adjoint of the operator f
idV	identity function on V
(Hilbert) Space Constructions from Other Spaces
HomK (V, W) GL(V)	space of K-linear functions from V to W space of invertible K-linear functions from V to itself, sometimes written GL(V, K) in the literature
HomG,K(V,W) HomG (X, W)	space of intertwiners from V to W space of G-equivariant continuous maps from X to W, for a homogeneous space X
EndG,K(V)	space of endomorphisms of V, i.e., intertwiners from V to V
15
Published as a conference paper at ICLR 2021
VgW
Li∈I Vi
Lci∈IVi
spanK (M)
V⊥
Eλ(ψ)
tensor product of two vector spaces over their common field.
Also denotes the tensor product of pre-Hilbert spaces
(orthogonal) direct sum of all Vi
topological closure of the (orthogonal) direct sum of all Vi
vector subspace of a K-vector space spanned by M
orthogonal complement of V
eigenspace of 夕 for eigenvalue λ
Topological Spaces, Metric Spaces, Normed Spaces
T	topology
Ux	open neighborhood of x ∈ X
Ux	set of all open neighborhoods of x ∈ X
limU∈Ux	limit over the directed set of open neighborhoods of x
limk→∞ Xk limit of the sequence (Xk )k
A topological closure of A ⊆ X
kXk	norm of X
|X|	absolute value of X
d(X, X0 )	distance of X, X0 according to metric d
B(X)	-ball around X according to some metric d
Homogeneous Spaces and the Peter-Weyl Theorem
X x* ∈ X Sn μ	a homogeneous space of G arbitrary point n-dimensional sphere in (n + 1)-dimensional space a measure on a compact group G or its Homogeneous Space X
RX LK(X), LK(G)	integral on a space X with respect to its measure Hilbert space of square-integrable functions on X and G with values in K
λ g(X)	unitary representation on L2K(X) or L2K(G) arbitrary lift of X with respect to projection π : G → X, g 7→ gX*
av(f) π* δx	average of f : G → K along cosets lift of functions L2K (X) → L2K(G) Dirac delta function at point X
δU ρlij	approximated Dirac delta function for nonempty open set U abbreviation for ρlvivj for orthonormal basis vectors vi, vj ∈ V Vl
E El Elj	linear span of all matrix coefficients of irreducible unitary representations linear span of all matrix coefficients of ρl linear span of all matrix coefficients ρlij with varying i but fixed j
nl, ml	multiplicity of l in orthogonal decomposition of L2K (G) and L2K(X), respectively
Vli	copy of Vl appearing in the Peter-Weyl decomposition of L2K(X)
pli	canonical projection pli : L2K (X) → Vli and pli : Ll0i0 Vl0i0 → Vli
sinm, cosm Yn rYn Dl l ,, rDll	the functions X 7→ sin(mX) and X 7→ cos(mX) complex- and real-valued version ofa spherical harmonic complex- and real-valued version of Wigner D-matrix
16
Published as a conference paper at ICLR 2021
Kernels and Representation Operators
K kernel K : X → HomK (Vin , Vout)
K ? f convolution of kernel K with input f
K kernel operator or (more generally) representation operator
K : T → HomK(U,V)
Kb	kernel operator Kb : L2K(X) → HomK (Vin, Vout) corre-
sponding to a kernel K
K|X	kernel K|X : X → HomK (Vin , Vout) corresponding to a
kernel operator K
K for a representation operator K : T → HomK(U, V ), this
denotes the corresponding map K : T 0 U → V under the
hom-tensor adjunction
The Wigner-Eckart Theorem
ρl , ρJ Yjm , Yln , YJM	input- and output representations on the spaces Vl and VJ fixed chosen orthonormal basis vectors of the abstract irre- ducible representations Vj , Vl , VJ
hJM|K(x)|lni dl mj	matrix element of K (x) for a kernel K and x ∈ X dimension of l’th irrep Vl as K-vector space number of times Vj is in the Peter-Weyl decomposition of L2K(X)
[J(jl)]	number of times VJ is in the direct sum decomposition of Vj 0 Vl
c, cjis	endomorphisms, mostly on VJ. cjis are endomorphisms ap- pearing in the Wigner-Eckart theorem for steerable kernels
cr	basis endomorphism of ρJ, indexed with index set r = 1, . . . , EJ
hJM|c|JM0i ls, ljis	matrix element at indices M, M 0 for endomorphism c linear equivariant isometric embeddings ls : VJ → Vj 0 Vl and ljis : VJ → Vji 0 Vl
pjis	projection pjis : Vji 0 Vl → VJ corresponding to (i.e.: ad- joint to) the embedding ljis
hs, JM |jm; lni CGJ(jl)s Ym ji	Clebsch-Gordan coefficient corresponding to ls 3-dimensional matrix of Clebsch-Gordan coefficients harmonic basis function, for example, spherical harmonic. Element of Vji ⊆ LK(X)
hi,jm|xi hi, j |xi Rep	shorthand notation for Iimu∈ux (Yjml∖δu). Equal to Ym(x) row vector with entries hi, jm|xi isomorphism between tuples of endomorphisms and kernel operators
GKer	isomorphism between tuples of endomorphisms and steer- able kernels
Kjisr wjisr	basis kernel learnable parameter
17
Published as a conference paper at ICLR 2021
List of Theorems
B.22 Theorem (Peter-Weyl Theorem) ...................................................... 28
B.27 Theorem (Density of Matrix Coefficients) .......................................... 30
C.7 Theorem (Kernel-Operator-Correspondence) ........................................... 46
C.8 Theorem (Kernel-Operator-Correspondence, Restated) ................................. 47
D.11 Theorem (Wigner-Eckart Theorem) ................................................... 56
D.13 Theorem (Wigner-Eckart Theorem for Steerable Kernels) ............................. 58
D.16 Theorem (Steerable Kernel Bases) .................................................. 61
F.24 Theorem (Heine-Borel Theorem) ..................................................... 93
List of Definitions
B.1	Definition (Group, Abelian Group) ................................................. 22
B.2	Definition (Subgroup) ............................................................. 23
B.3	Definition (Group Homomorphism) ................................................... 23
B.4	Definition (Topological Group, Compact Group) ..................................... 23
B.5	Definition (Group Action) ......................................................... 23
B.6	Definition (Orbit) ................................................................ 23
B.7	Definition (Transitive Action, Homogeneous Space) ................................. 23
B.8	Definition (Stabilizer Subgroup) .................................................. 24
B.10	Definition (Linear Representation) ............................................... 24
B.11	Definition (Intertwiner) ......................................................... 24
B.12	Definition (Equivalent Representations) .......................................... 24
B.13	Definition (Invariant Subspace, Subrepresentation, Closed Subrepresentation) . . .	25
B.14	Definition (Irreducible Representation) .......................................... 25
B.15	Definition (Unitary Group) ....................................................... 25
B.16	Definition (Unitary Transformation) .............................................. 25
B.17	Definition (Unitary Representation) .............................................. 25
B.18	Definition (Isomorphism of Unitary Representations) .............................. 25
B.24 Definition (Matrix Coefficients) .................................................. 29
C.1 Definition (Hom-Representation) .................................................... 42
C.3 Definition (Steerable Kernel) ...................................................... 43
C.4 Definition (Representation Operator) ............................................... 44
C.6 Definition (Kernel Operator) ....................................................... 45
D.1 Definition (Tensor Product) ........................................................ 52
D.2 Definition (Tensor Product of pre-Hilbert spaces) .................................. 52
D.3 Definition (Tensor Product Representation) ......................................... 53
D.6 Definition (Clebsch-Gordan Coefficients) ........................................... 54
D.7 Definition (Endomorphism) .......................................................... 55
18
Published as a conference paper at ICLR 2021
D.9	Definition (Matrix Element) ..................................................... 55
D.12	Definition (Reduced Matrix Element) ............................................ 56
E.11	Definition (Real, Complex, and Quaternionic Type Irreducible Representations) . .	83
E.12	Definition (Restriction and Extension) .......................................... 84
E.14	Definition (Real Type Complex Representation) ................................... 84
E.21	Definition (Tensor Product Representation) ...................................... 87
F.1	Definition (Topological Space, Open Sets, Closed Sets) .......................... 90
F.2	Definition (Open Neighborhood) .................................................. 91
F.3	Definition (Hausdorff Space) .................................................... 91
F.4	Definition (Subspace) ........................................................... 91
F.5	Definition (Closure, Density) ................................................... 91
F.6	Definition (Continuous Function, Homeomorphism) ................................. 91
F.7	Definition (Open Cover, Compact Space) .......................................... 91
F.10	Definition (Product Topology) ................................................... 91
F.11	Definition (Quotient Map, Quotient Space) ....................................... 91
F.13	Definition (Norm) ............................................................... 92
F.14	Definition (Metric) ............................................................. 92
F.15	Definition (Convergent Sequence) ................................................ 92
F.16	Definition (Continuity in Metric Spaces) ........................................ 92
F.17	Definition (Uniform Continuity) ................................................. 92
F.19	Definition (Cauchy Sequence) .................................................... 93
F.20	Definition (Complete Metric Space) .............................................. 93
F.21	Definition (Completion) ......................................................... 93
F.23	Definition (Boundedness) ........................................................ 93
F.26	Definition (Partially Ordered Set, Directed Set) ................................ 94
F.28	Definition (Net) ................................................................ 94
F.29	Definition (Convergence of Nets) ................................................ 94
F.30	Definition (Approximated Dirac Delta) ........................................... 94
F.32	Definition (pre-Hilbert Space, Hilbert space) ................................... 95
F.35	Definition (Orthogonality) ...................................................... 95
F.36	Definition (Orthogonal Complement) .............................................. 95
F.39	Definition (Orthonormal System) ................................................. 96
F.40	Definition (Orthonormal Basis) .................................................. 96
F.42	Definition (Adjoint of an Operator) ............................................. 96
A Building Blocks of SO(2)-Steerable Kernels - Running
Example for Section 3
in this short chapter, we briefly explain the components of steerable kernels at the specific exam-
ple of real valued irreps of the circle group SO(2). While this example is quite simple, it shows
19
Published as a conference paper at ICLR 2021
some non-trivial properties like 2-dimensional endomorphism spaces EndSO(2),R (VJ) for J > 0
and a Clebsch-Gordan decomposition in which the multiplicity [J (jl)] can differ from 0 or 1. To
give a quick overview: Example A.1 considers the circle as an orbit and homogeneous space of
SO(2) while Example A.2 introduces the real valued irreps. Their endomorphisms are stated in
Example A.3. As discussed in Example A.4, the Peter-Weyl theorem corresponds here to the usual
Fourier series on S1 . The Clebsch-Gordan decomposition of tensor products of the irreps are dis-
cussed in Example A.5. With these ingredients, we are ready to instantiate the kernel spaces as
described by our Wigner-Eckart Theorem 4.1 for steerable kernels, for which we refer, including
proofs, to Section E.2.
SO(2)-steerable kernels K : R2 → HomR(%n,V0ut) = RcOut ×cin allow for rotation equivariant
convolutions. For instance, a convolution with an SO(2)-steerable kernel on R2 is guaranteed to be
SE(2) = (R2, +) o SO(2) equivariant while a convolution with an SO(2)-steerable kernel on S2
will be SO(3)-equivariant.
Homogeneous Spaces SO(2) acts on the kernel’s domain R2 by rotating it. The orbits of the
action are therefore given by 1) the origin {0} and 2) circles of arbitrary radius. We know that the
kernel constraint can be solved on each orbit individually, and so we can restrict to looking at those.
Since {0} is rather trivial, we specifically consider the circle S1 as a more interesting homogeneous
space.
Example A.1. Consider the circle S1 and the rotation group SO(2). For convenience, we reparam-
eterize both: We view SO(2) as the group of angles φ ∈ R∕2∏Z = [0,2∏]∕o〜2∏ and S1 as the space
R∕2πZ as well. Then the action of SO(2) on S1 is given by φ ∙ X := (φ + x) mod 2π. It is easy to
see that this action is transitive, which makes the circle a homogeneous space of SO(2).
Irreducible Representations As it is sufficient to solve the kernel constraint for irreducible or-
thogonal input- and output representations, we now state a classification of those up to isomorphism.
Example A.2. The irreducible orthogonal representations ρl : SO(2) → O(Vl) of SO(2) are labeled
by indices (“quantum numbers”) l ∈ N≥0. For l = 0, one has the trivial representation with V0 = R
and ρ0(φ) = idR. For l ≥ 1, one has Vl = R2 and
cos(lφ)	- sin(lφ)
ρl(φ) = sin(lφ)	cos(lφ) ,
i.e., rotation matrices of “frequency l ”. The isomorphism classes of irreducible orthogonal repre-
sentations are then given by SO(2) == N≥0.
We are thus in the following considering SO(2)-steerable kernels of the form
K:S1 →HomR(Vl,VJ),
where l, J ≥ 0.
Endomorphisms Remember that if c : VJ → VJ is an endomorphism, i.e., commutes with ρJ,
that c ◦ K is then steerable as well. Thus, we now look at a classification of the endomorphisms of
the irreducible orthogonal representations:
Example A.3. Let G = SO(2) with the irreducible representations ρJ as in Example A.2. Clearly,
the endomorphism space EndSO(2),R(V0) is 1-dimensional, i.e., E0 = 1. For all J ≥ 1, the endo-
morphism space is two-dimensional (EJ = 2) and given by combinations of scalings and rotations8
on VJ = R2. A basis of this space is given by the following two matrices:
c1 = idR2
01	01	,	c2	=	01	-10	,	spanR{c1, c2}	= EndSO(2),K (VJ).
8Another way to imagine this is to identify VJ with the complex plane C. Then an endomorphism is given
by multiplication with an arbitrary complex number.
20
Published as a conference paper at ICLR 2021
That c1 is an endomorphism of ρJ for J ≥ 1 is immediately clear. That the same holds for c2 is
checked by the following simple calculation:
c2 ρJ (φ)
0 -1	cos(J φ) - sin(J φ)	- sin(Jφ)
1	0	sin(J φ)	cos(J φ)	=	cos(J φ)
- cos(J φ)
- sin(J φ)
cos(J φ)
sin(J φ)
- sin(Jφ)	0
cos(J φ)	1
ρJ (φ) c2
The proof that there are no other endomorphisms is sketched in Proposition E.5.
Peter-Weyl and Harmonic Basis Functions Another ingredient that we need to construct SO(2)-
steerable kernels on S1 is the decomposition of L2R(S1) into its irreducible subrepresentations Vji,
which the Peter-Weyl theorems guarantees to exist. Less abstractly, we are interested in an orthonor-
mal set of harmonic (steerable) basis functions on S1 that span LR(S1) - which corresponds to the
usual Fourier series on S1.
Example A.4. As in Example A.1, we assume G = SO(2) and X = S1. A standard result in
harmonic analysis says that square-integrable functions f : S1 → R, i.e., f ∈ L2R(S1), can be
uniquely written as an infinite sum of sine and cosine terms,
f(x)
X∞
aj cos(j x) + bj sin(jx) ,
j=1
(8)
where a0 and aj , bj , j ≥ 1 are real-valued expansion coefficients.
How does this result relate to the harmonic basis functions in the Peter-Weyl theorem 3.4? As stated
above, we have isomorphism classes G = SO(2) = N≥o of ιrreps With representatives Pj. A com-
parison of the Fourier series in Eq. (8) with property 2 in the Peter-Weyl theorem 3.4 suggests the
following identification of harmonic basis functions Yjm and coefficients λjm ,
Y01 =	cos0	=	1 ,	λ01	= a0	for	j	=	0
Yj1 =	cosj	,	λj 1	= aj	for	j	≥	1
Yj2 =	sinj	,	λj2	= bj	for	j	≥	1	,
where we introduced the shorthand notations cosj(x) := cos(jx) and sinj(x) := sin(jx). Note
that we dropped the index i = 1, . . . , mj since mj = 1 for any j ∈ SO(2). As expected, we
have indices m = 1 for j = 0 with dj = dim(V0) = 1 and indices m = 1, 2 for j ≥ 1 with
dj = dim(Vj) = 2. The orthogonality relations in property 3 of the Peter-Weyl theorem hold up
to a simple normalization of these basis functions and are easily checked by explicitly computing
the scalar products. Property 1, i.e., the SO(2)-steerability of the harmonic bases, is trivial for
j = 0. Forj ≥ 1, the standard angle summation formulas for cosines and sines lead to the following
expressions for harmonics that are translated by φ ∈ SO(2):
cosj (x - φ)	= cosj (x) cosj (-φ)	- sinj (x) sinj (-φ)	=	ρj11(φ)	cosj +ρj21 (φ) sinj	(x)
sinj (x - φ)	= cosj (x) sinj (-φ)	+ sinj (x) cosj (-φ)	=	ρj12(φ)	cosj +ρj22(φ) sinj	(x) ,
which is just property 1 in the Peter-Weyl theorem. This is concisely summarized by
(款)(φ-1∙χ) = (Zj)(X- φ) = Pj (φ)>(款)(χ),
which shows that the basis functions Yj1 = cosj and Yj2 = sinj span an invariant subspace Vj of
L2R(S1) under rotations. From a more abstract viewpoint, the Peter-Weyl theorem just states that
LR(S1) splits into the orthogonal direct sum Lj∈s∖2) Vj.
Tensor Products and Clebsch-Gordan Coefficients Finally, we need to investigate the tensor
products of irreducible representations and their decomposition via Clebsch-Gordan coefficients.
They will be used to correctly assemble harmonic basis functions to steerable kernels.
21
Published as a conference paper at ICLR 2021
Example A.5. Remember the irreducible representations ρl : SO(2) → O(Vl) given in Example
A.2. As we prove in Proposition E.4, including a description of the Clebsch-Gordan coefficients,
the tensor products decompose as follows:
V0 0 V0 = Vo, Vj 0 V0 = Vj, V0 0 Vl = Vl, Vj 0 Vl = Vj-ι∣ ㊉ Vj-+1,
where the last isomorphism only holds if j, l ≥ 1 and j 6= l. If j, l ≥ 1 and j = l, then we obtain
Vl 0 Vl = (Vo)2 ㊉ V2l,
i.e., V0 here appears twice in the decomposition of a tensor product of irreducible representations.
We therefore have multiplicities [J (jl)] which are 1 for [0(00)], [j(j0)], [l(0l)], [|j - l|(jl)],
[j + l(jl)] and [2l(ll)] while [0(ll)] = 2. Any other multiplicity is zero.
Wigner-Eckart theorem for SO(2)-steerable kernels With these ingredients one can then deter-
mine all SO(2)-steerable kernels. This is explained in Proposition E.6.
B	Representation Theory of Compact Groups
In this chapter, we outline the main ingredients of the representation theory of compact groups
that we need for our applications to steerable CNNs. Usually, this theory is only developed for
representations over the complex numbers. However, since we want to apply it also to steerable
CNNs using real representations, we need to be a bit more careful. In particular, we need to make
sure that the Peter-Weyl theorem is correctly stated and proven.
The outline is as follows: In Section B.1, we start by stating all the important definitions and con-
cepts from group theory and representation theory of (unitary) representations that are needed for
formulating the Peter-Weyl theorem. After defining Haar measures both for compact groups and
their homogeneous spaces and shortly discussing their square-integrable functions, we formulate the
Peter-Weyl Theorem B.22. In Section B.2, then, we give a proof of this version of the Peter-Weyl
theorem, carefully making sure to not use properties that are only true over C. In some essential
steps, mainly the density of the matrix coefficients in the regular representation, we refer to the lit-
erature, since the proof clearly does not make use of C per se. While we initially only give the proof
for the regular representation, i.e., the space of square-integrable functions on the group itself, we
end this section with a discussion of general unitary representations and, in particular, the space of
square-integrable functions for an arbitrary homogeneous space.
In the whole chapter, let K be the field of real or complex numbers.
B.1	Foundations of Representation Theory and the Peter-Weyl Theorem
B.1.1	Preliminaries of Topological Groups and their Actions
In this section, we define preliminary concepts from topological groups and their actions. This mate-
rial can, for example, be found in detail in Arkhangel’skii & Tkachenko (2008). For the topological
concepts that we use, we refer to Chapter F.1.
Definition B.1 (Group, Abelian Group). A group G = (G, ∙, (∙)-1,e), most often simply written
G, consists of the following data:
1.	A set G of group elements g ∈ G.
2.	A multiplication ∙ : G X G → G, (g,h) → g ∙ h.
3.	An inversion (∙)-1 : G → G, g → g-1.
4.	A distinguished unit element e ∈ G. It is also called neutral element.
They are assumed to have the following properties for all g, h, k ∈ G:
1.	The multiplication is associative: g ∙ (h ∙ k) = (g ∙ h) ∙ k.
2.	The unit element is neutral with respect to multiplication: e ∙ g = g = g ∙ e.
22
Published as a conference paper at ICLR 2021
3.	The inversion of an element multiplied with itself is the neutral element: g ∙ g-1 = g-1 ∙ g =
e.
A group is called abelian if, additionally, the multiplication is commutative: g ∙ h = h ∙ g for all
g,h ∈ G. If this is the case, a group is often written as G = (G, +, -(∙), 0).
If we consider several groups at once, say G and H, then we often do not distinguish their multipli-
cation, inversion, and neutral elements in notation. It will be clear from the context which group the
operation belongs to.
Definition B.2 (Subgroup). Let G be a group and H ⊆ G a subset. H is called a subgroup if:
1.	For all h, h0 ∈ H We have h ∙ h0 ∈ H.
2.	For all h ∈ H we have h-1 ∈ H.
3.	The neutral element e ∈ G is in H.
Consequently, H is also a group with the restrictions of the multiplication and inversion of G to H.
Definition B.3 (Group Homomorphism). Let G and H be groups. A function f : G → H is called
a group homomorphism if it respects the multiplication, inversion, and neutral element, i.e., for all
g, h ∈ G:
1.	f(g ∙ h) = f(g) ∙ f(h).
2.	f(g-1) = f(g)-1.
3.	f(e) = e.
The second and third properties automatically follow from the first and so do not need to be verified
in order to prove that a certain function is a group homomorphism.
Definition B.4 (Topological Group, Compact Group). Let G be a group and T be a topology of the
underlying set of G. Then G = (G, T) is called a topological group (Arkhangel’skii & Tkachenko,
2008) if both multiplication G X G → G, (x,y) → X ∙ y and inversion G → G, x → x-1 are
continuous maps. Additionally, we always assume the topology to be Hausdorff.
A topological group is called compact if the underlying topological space is compact.
From now on, all groups considered are compact topological groups. Furthermore, whenever G is
a finite group, we assume that it is a topological group with the discrete topology, i.e., the topology
with respect to which all subsets of G are open.
We will need the following definition in order to define homogeneous spaces:
Definition B.5 (Group Action). Let G be a compact group and X a topological space. Then a group
action of G on X is a continuous function ∙ : G × X → X with the following properties:
1.	(g ∙ h) ∙ x = g ∙ (h ∙ x) for all g, h, ∈ G and X ∈ X.
2.	e ∙ x = x for all X ∈ X.
We will often simply write gx instead of g ∙ x. Also, note that the multiplication within G is denoted
by the same symbol as the group action on the space X .
Definition B.6 (Orbit). Let ∙ : G × X → X be a group action. Let X ∈ X. Then it,s orbit, denoted
G ∙ x, is given by the set
G ∙ X := {g ∙ X | g ∈ G} ⊆ X.
Definition B.7 (Transitive Action, Homogeneous Space). Let ∙ : G × X → X be a group action.
This action is called transitive if for all x, y ∈ X there exists g ∈ G such that gx = y. Equivalently,
each orbit is equal to X, that is: For all X ∈ X we have G ∙ X = X.
X is called a homogeneous space (with respect to the action) if the action is transitive, X is Haus-
dorff and X = 0.
23
Published as a conference paper at ICLR 2021
The Hausdorff condition and non-emptiness in the definition of homogeneous spaces is needed for
Lemma B.21, which is necessary to even define a normalized Haar measure on a homogeneous
space. Some texts in the literature may define homogeneous spaces without these conditions.
Definition B.8 (Stabilizer Subgroup). Let ∙ : G X X → X be a group action. Let X ∈ X. The
stabilizer subgroup Gx is the subgroup of G given by
Gx := {g ∈ G | gx = x} ⊆ G.
Example B.9. The multiplication of the group G is a group action of G on itself. G is a homoge-
neous space with this action. Furthermore, for each g ∈ G the stabilizers Gg are the trivial subgroup
e.
In general, homogeneous spaces with the property that all stabilizers are trivial are called torsors or
principal homogeneous spaces. Principal homogeneous spaces are topologically indistinguishable
from the group itself.
B.1.2 Linear and Unitary Representations
In this section, we define many of the foundational concepts about linear and unitary representa-
tions (Knapp, 2002; Kowalski, 2014).
Whenever we will consider linear or unitary representations of compact groups, we want those
representations to be continuous. This requires that the vector spaces on which our groups act carry
themselves a topology. Prototypical examples of such vector spaces are (pre-)Hilbert spaces. They
are the main examples of vector spaces considered in this work. Foundational concepts about (pre-
)Hilbert spaces can be found in Chapter F.3. The most important difference between how we view
pre-Hilbert spaces and how it can often be found in the literature is that in this work, scalar products
are antilinear in the first component and linear in the second. This is the convention usually chosen
in physics.
For a vector space V over K let GL(V ) be the group of invertible linear functions from V to V .
Sometimes in the literature, this is also written GL(V, K). The multiplication is given by function
composition and the neutral element by the identity function idV on V .
Definition B.10 (Linear Representation). Let G be a compact group and V be a K-vector space
carrying a topology, for example, a (pre)-Hilbert space. Then a linear representation of G on V is a
group homomorphism ρ : G → GL(V ) which is continuous in the following sense: for all v ∈ V ,
the function
ρv : G → V, g 7→ ρv (g) := ρ(g)(v)
is continuous. From the definition We obtain ρ(e) = idv, ρ(g ∙ h) = ρ(g) ◦ ρ(h) and ρ(g-1)=
ρ(g)-1 for all g, h ∈ G. For simplicity, we also just say representation or G-representation instead
of linear representation. Instead of denoting the representation by ρ, We often denote it by V if the
function ρ is clear from the context.
Note that in this definition, V can be any abstract topological K-vector space With a topology and
does not need to be a space Kn or something similar. Consequently, We usually do not vieW the
functions ρ(g) as matrices, but as abstract linear automorphisms from V to V .
Definition B.11 (IntertWiner). Let ρ : G → GL(V ) and ρ0 : G → GL(V 0) be tWo representations
over the same group G. An intertwiner betWeen them is a linear function f : V → V 0 that is
additionally equivariant With respect to ρ and ρ0 and continuous. Equivariance means that for all
g ∈ G one has f ◦ ρ(g) = ρ0(g) ◦ f, Which means the folloWing diagram commutes:
V	—f→ V 0
P(O)I	ρ,p'gg'1
V	f V 0
Definition B.12 (Equivalent Representations). Let ρ : G → GL(V) and ρ0 : G → GL(V0) be tWo
representations. They are called equivalent if there is an intertWiner f : V → V0 that has an inverse.
That is, there exists an intertWiner f : V0 → V such that f ◦ f = idV and f ◦ f = idV0 .
24
Published as a conference paper at ICLR 2021
In categorical terms, equivalent representations are isomorphic in the category of linear representa-
tions. The reason we do not call them isomorphic is that there is a stronger notion of isomorphism
between representations which we will later use, namely isomorphisms of unitary representations.
Definition B.13 (Invariant Subspace, Subrepresentation, Closed Subrepresentation). Let ρ : G →
GL(V ) be a representation. An invariant subspace W ⊆ V is a linear subspace of V such that
ρ(g)(w) ∈ W for all g ∈ G and W ∈ W. Consequently, the restriction ρ∣w : G → GL(W),
g → ρ(g) | w : W → W is a representation as well, called SubrepresentatiOn of ρ.
A subrepresentation is called closed if W is closed in the topology of V .
Definition B.14 (Irreducible Representation). A representation ρ : G → GL(V ) is called irre-
ducible if V 6= 0 and if the only closed subrepresentations of V are 0 and V itself. An irreducible
representation is also shortly called irrep.
Definition B.15 (Unitary Group). Let V be a pre-Hilbert space. The unitary grOup U(V ) of V is
defined as the group of all linear invertible maps f : V → V that respect the inner product, i.e.,
hf (x)|f (y)i = hx|yi for all x, y ∈ V . It is a group with respect to the usual composition and
inversion of invertible linear maps.
Note that if the field K is the real numbers, then what we call “unitary” is actually called OrthOgO-
nal, and the group would be denoted O(V ). However, the mathematical properties are essentially
the same, and since the term “unitary” is more widely used (as normally, representations over the
complex numbers are considered) we stick with “unitary”.
More generally, we have the following:
Definition B.16 (Unitary Transformation). Let V, V0 be two pre-Hilbert spaces. A unitary transfOr-
matiOn f : V → V0 is a bijective linear function such that hf (x)|f (y)i = hx|yi for all x, y ∈ V .
These can be regarded as isomorphisms between pre-Hilbert spaces.
Note that unitary transformations are in particular isometries, i.e., they keep the distances of vectors
with respect to the metric defined by the scalar product. For the definition of this metric, see the
discussion before and after Definition F.14.
Definition B.17 (Unitary Representation). Let V be a pre-Hilbert space and G a group. Then a
representation ρ : G → GL(V ) is called a unitary representatiOn if ρ(g) ∈ U(V ) for all g ∈ G. We
then write ρ : G → U(V ).
In this whole chapter, the space V of a unitary representation is supposed to be a Hilbert space,
instead of just a pre-Hilbert space. Only in chapter D will we consider unitary representations
on pre-Hilbert spaces. Note that all finite-dimensional pre-Hilbert spaces are already complete by
Proposition F.47, so in these cases, there is no difference. The same proposition also shows that
for finite-dimensional unitary representations, we can ignore the topological closedness condition in
order to check whether it is irreducible. It will later turn out that all irreducible representations of
a compact group are automatically finite-dimensional anyway, see Proposition B.31, so this further
simplifies our considerations.
As before with the unitary group, a unitary representation is actually called “orthogonal representa-
tion” when the field is the real numbers R. U(V ) is then replaced by O(V ). We again stick with
U(V ) whenever the field K is not specified.
Definition B.18 (Isomorphism of Unitary Representations). Let ρ : G → U(V ), ρ0 : G → U(V 0)
be unitary representations and f : V → V 0 an intertwiner. f is called an isOmOrphism (of unitary
representations) if, additionally, f is a unitary transformation. The representations are then called
isomorphic. For this, We write P = ρ0 or V = V0 depending on whether We want to emphasize the
representations or the underlying vector spaces.
We note the following, which we will frequently use: due to the unitarity of ρ(g) for a unitary
representation ρ, we have ρ(g)* = ρ(g)-1, i.e., the adjoint is the inverse. Adjoints are defined in
Definition F.42 and this statement is proven more generally in Proposition F.44. Overall, this means
that hρ(g)(v)∣wi = (v∣ρ(g)-1(w)) for all v, w and g.
In the end, it will turn out that the Peter-Weyl theorem which we aim at is exclusively a statement
about unitary representations. One may then wonder whether this is too restrictive. After all, the
25
Published as a conference paper at ICLR 2021
representations that we consider for steerable CNNs (with precise definitions given in Section C.1)
are not necessarily unitary, and so it is not immediately obvious how the Peter-Weyl theorem will
be able to help for those. However, as it turns out, all linear representations on finite-dimensional
spaces can be considered as unitary, and so the theory applies. We will discuss this in Proposition
B.20 once we understand Haar measures on compact groups.
B.1.3 The Haar Measure, the Regular Representation and the Peter-Weyl
Theorem
Now that we have introduced many notions in the representation theory of compact groups, we can
formulate the most important result, the Peter-Weyl theorem that we will use throughout this work.
In the next section, we will then go through a step-by-step proof of this theorem. The material in this
section is based on Nachbin & Bechtolsheim (1965); Kowalski (2014) and Knapp (2002). We thank
Stefan Dawydiak for a discussion about the Peter-Weyl theorem over the real numbers (Dawydiak,
2020).
We assume that the reader knows what a measure is (Tao, 2013). Let G be a compact group. A
standard result is that there exists a measure μ on G, called a Haar measure that, among other
properties, fulfills the following:
1.	μ(S) can be evaluated for all Borel sets S ⊆ G. Here, the Borel sets form the smallest
so-called σ-algebra that contains all the open sets.
2.	In particular, We can evaluate μ(S) for all open or closed sets S ⊆ G.
3.	The Haar measure is normalized: μ(G) = 1.
4.	μ is left and right invariant: μ(gS) = μ(S) = μ(Sg) for all g ∈ G and S measurable.
5.	μ is inversion invariant: μ(S-1) = μ(S) for all S measurable.
These properties then translate into properties of the associated Haar integral: let f : G → K be
integrable with respect to μ, then we obtain:
1.	G 1dg = 1 for the constant function With value 1.
2.	RG f (hg)dg = RG f (g)dg = RG f (gh)dg for all h ∈ G.
3.	RG f (g-1)dg = RGf(g)dg.
Example B.19 (Finite Groups). If G is a finite group with n elements, then the Haar measure is just
the normalized counting measure which assigns μ(g) = § for all g ∈ G. Each function f : G → K
is then integrable, and its integral is just given by
Lf (g)dg=n X f (g).
In this special case, one can easily verify all properties of Haar measures and Haar integrals stated
above.
With this measure defined, we can already understand why all linear representations on finite-
dimensional spaces can be considered as unitary:
Proposition B.20. Let ρ : G → GL(V ) be a linear representation on a finite-dimensional space
V. Then there exists a scalar product h∙∣∙)ρ : V X V → K that makes (V,〈+)) a Hilbert space and
such that ρ becomes a unitary representation with respect to this scalar product.
Proof. Since V is finite-dimensional, there is an isomorphism of vector spaces to some Kn . Con-
sequently, there is some scalar product(〉)：V × V → K that makes V a Hilbert space. However,
this scalar product does not necessarily make ρ a unitary representation. However, we can define
h∙∣∙iρ : V × V → K by
hvlwiρ :
hρ(g)(v)lρ(g)(w)i dg.
G
That this integral exists is due to the continuity of linear representations and since also the scalar
product is continuous by Proposition F.38. It can easily be checked that this construction makes V a
26
Published as a conference paper at ICLR 2021
Hilbert space. And due to the right invariance of the Haar measure, we can check that ρ is a unitary
representation with respect to this scalar product. Namely, for arbitrary g0 ∈ G we have:
ρ(g0)(v)ρ(g0)(w)ρ = Z ρ(g)ρ(g0)vρ(g)ρ(g0)wdg
=	ρ(gg0)(v)ρ(gg0)(w)dg
G
=	ρ(g)(v)ρ(g)(w)dg
G
=hvlwiρ.
□
Now, for a measure space Y with corresponding measure μ, We can consider the space of square-
integrable functions on Y with values in K, denoted L2K (Y) (the measure is omitted in the notation
since there is usually no ambiguity). In these spaces, functions are identified if they coincide on
a set with measure 0. L2K (Y) is clearly a vector space over K, but it turns out that it can even be
considered to be a Hilbert space as follows:
hf |gi := / f(y)g(y)dy.
Here, the overline means complex conjugation. The Hilbert space properties are easily verified.
In particular, one can consider the space L2K(G) of square-integrable functions on the group G it-
self. Now the claim is that L2K(G) can actually be equipped with a prototypical structure as a unitary
representation over G which makes this space, in some sense, “universal among unitary representa-
tions”. This works with the following canonical representation, called the regular representation:
λ : G → U(L2K(G)), [λ(g)(f)] (g0) := f (g-1g0).
continuity of this map is non-trivial and is, for example, shown in Knapp (2002). However, the
more algebraic properties of being a unitary representation are easy to appreciate. First of all, we
clearly see that λ is a group homomorphism mapping each group element to a linear automorphism.
And finally, the unitarity of this representation can be understood as a direct consequence of the
properties of the Haar measure, where we notably make only use of the left-invariance:
hλ(g)(f)∣λ(g)(h)i = [ [λ(g)(f)](g0) ∙ [λ(g)(h)](g0)dg0
G
=f f (g-1g0) ∙ h(g-1g')dg'
G
=f f (g0)h(g0)dg0
G
= hf|hi.
We saw in Example B.9 that G is a homogeneous space with respect to the action on itself. We can
now ask whether these constructions can also work if X is an arbitrary homogeneous space of G.
This requires us to define a suitable measure on X . This is indeed possible. For a fixed element
x* ∈ X, denote the stabilizer subgroup by H = Gχ* ⊆ G. Then the Hausdorff property of X
allows to write down a homeomorphism between X and G/H, which in turn will allow us to use a
canonical measure on G/H that we study below. We denote cosets gH ∈ G/H by [g].
Lemma B.21. Let X be a homogeneous space of the compact group G and H the stabilizer sub-
group of a fixed element x* ∈ X. Then the map
φ : G/H → X, [g] → gx*
is a homeomorphism. Furthermore, H is topologically closed.
Proof. Let 0 : G → X, g → gx*. This map is equal to the composition of the maps G → G X X,
g → (g, x*) and G × X → X, (g,χ) → gx. Both these are continuous, and thus 0 is continuous as
well. Furthermore, note that if g-1g0 ∈ H, then there is h ∈ H such that g0 = gh, and thus
0(g0) = 0(gh) = (gh)x* = g(hx*) = gx* = 0(g)
27
Published as a conference paper at ICLR 2021
which means that by Proposition F.12, the map 夕：G/H → X, [g] → gx* is a well-defined
continuous map. It is surjective since the action is transitive by definition of a homogeneous space.
Furthermore, it is injective since if gx* = g0x* then x* = (g-1 g0)x* and thus g-1g0 ∈ H, which
means [g] = [g0].
Overall,夕 is a continuous bijective map from G/H to X. Furthermore, G/H is compact since it
is the continuous image of the compact group G under the projection G → G/H, see Proposition
F.8. Since X is Hausdorff by definition of homogeneous spaces,夕 is a homeomorphism according
to Proposition F.9.
Now, since X is Hausdorff and 夕 is a homeomorphism, it follows that G/H is Hausdorff as well.
Then, necessarily, H is a topologically closed subgroup of G, see Bourbaki (1998), Chapter III,
Section 2.5, Proposition 13.	□
Every space G/H where H is topologically closed allows a measure μ with similar properties to
those of G (Nachbin & Bechtolsheim, 1965). Since the stabilizer H is closed and X = G/H by
Lemma B.21, we can do these constructions for X as well, as we outline now. The only properties
that we now miss are the right-invariance and inversion-invariance: We simply can’t ask for them
since G does not naturally act on X from the right and since we cannot invert elements in X . But
left-invariance does hold and this means that
λ : G → LK(X), [λ(g)(f )](χ) ：= f (g-1χ)
makes L2K(X) a unitary representation over G, as can be shown in the exact same way as for L2K(G).
Let G be the set of isomorphism classes of irreducible unitary representations over G. Furthermore,
let ρl : G → Vl be a fixed representative of such an isomorphism class l ∈ Gb. We write isomorphism
classes as “l” (and later also j and J) in order to bring to mind quantum numbers used in quantum
mechanics. Recall from linear algebra that a countable sum of subspaces of a vector space is called
direct if no nontrivial subspace of any of the considered spaces is contained in the sum of all the
other considered spaces.9 Furthermore, recall that two subspaces U, W ⊆ V of a Hilbert space V
are called perpendicular or orthogonal if hu|wi = 0 for all u ∈ U and w ∈ W. We then write
U ⊥ W . We can now formulate the Peter-Weyl theorem. Intuitively, it says that L2K (X) splits into
an orthogonal direct sum of the irreducible unitary representations, where each irreducible unitary
representation appears maximally as often as its own dimension (and may not appear at all):
Theorem B.22 (Peter-Weyl Theorem). Let G be a compact group. Let X be a homogeneous space.
There are numbers ml ∈ N≥0 for all l ∈ Gb and closed-invariant subspaces Vli ⊆ L2K(X) for all
l ∈ Gb and i ∈ {1, . . . , ml} such that the following hold:
1.	Vli == Vl as unitary representations for all i and l.
2.	ml ≤ dim(Vl ) < ∞ for all l.
3.	Vli ⊥ Vl0j whenever l 6= l0 or i 6= j.
4.	Ll∈Gb Lim=l1 Vli is topologically dense in L2K(X), written L2K(X) = Lcl∈Gb Lim=l1 Vli.
Now additionally consider G as a homogeneous space of itself. Then the same holds for L2K (G) as
well, with numbers nl ≤ dim(Vl) < ∞. We additionally have the following:
1.	ml ≤ nl.
2.	If K = C, then nl = dim(Vl).
Note that the representative Vl is not assumed to be embedded in L2K(X). It is just isomorphic, as a
unitary representation, to each of the Vli ⊆ L2K (X).
Example B.23. For G = SO(2) and K = C we have L2C (SO(2)) = Ll∈ZVl1 and all irreducible
representations Vl are 1-dimensional.
9For a vector space V and subspaces (Ui)i∈I, their sum Pi∈I Ui is the set of sums Pi∈J ui with J ⊆ I
finite and ui ∈ Ui for all i. It is itself a subspace of V .
28
Published as a conference paper at ICLR 2021
For G = SO(2) and K = R, we obtain L2R(SO(2)) = Lcl≥0Vl1, and all irreducible representations
Vl with l ≥ 1 are two-dimensional, whereas V0 is one-dimensional. Thus, here we see an example
where the multiplicity of most irreducible representations in the regular representation is 1 and
therefore smaller than their dimension, which cannot happen for representations over the complex
numbers.
Both of these results are standard results in harmonic analysis. These examples are discussed in
more detail, especially with respect to their applications in deep learning, in Section E.1 and E.2.
B.2	A Proof of the Peter-Weyl Theorem
This section presents a proof of the Peter-Weyl theorem, as formulated in Theorem B.22. We mostly
skip the analytical parts of the proof,10 since they are well-presented in the literature and clearly
work over both the real and complex numbers. However, the more algebraic parts of the proof
usually make use of the property of the complex numbers to be algebraically closed, which does
not hold for the real numbers. This is invoked usually both in the proof of a version of Schur’s
lemma, as well as in proving Schur’s orthogonality. We therefore carefully adapt the proof of the
Peter-Weyl theorem in the literature so that it also works over the real numbers, and formulate and
prove versions of Schur’s Lemma B.29 and Schur’s orthogonality B.30 that work in general.
This section can be skipped if the interest is mainly in the applications of the Peter-Weyl theorem.
In this case, the reader is advised to directly move on to Chapter C.
We note the following convention that applies to this section: for all unitary representations ρ : G →
U(V ) that we consider here, V is a Hilbert space (instead of just a pre-Hilbert space).
B.2	. 1 Density of Matrix Coefficients
An important ingredient in the construction of the spaces Vli that appear in the formulation of the
Peter-Weyl Theorem B.22 are matrix coefficients, which together generate those spaces in case that
one considers the regular representation on L2K (G).
Definition B.24 (Matrix Coefficients). Let ρ : G → U(V ) be a unitary representation. A matrix
coefficient is any function of the form
Puv : G → K,g→hu∣ρ(g)(v)i
for arbitrary u, v ∈ V .
The term “matrix coefficient” comes from the analogy to matrix elements of linear maps between
pre-Hilbert spaces of which orthonormal bases are fixed. Later, in Definition D.9 we will also define
the notion of “matrix elements” separately. The term “matrix coefficient” only applies to unitary
representations.
Remark B.25. By definition of linear representations, the function g 7→ ρ(g)(v) is continuous. Thus,
since scalar products of Hilbert spaces are also continuous as functions on V × V , see Proposition
F.38, every matrix coefficient ρuv : G → K is continuous. As a continuous function on a compact
space, it is of course also square-integrable, i.e., ρuv ∈ L2K(G). The Peter-Weyl theorem basically
asserts that these matrix coefficients can be considered as the building blocks of all square-integrable
functions.
Furthermore, one may wonder why there is a complex conjugation in the definition. The reason
for this is that, otherwise, the isomorphism that we will construct in Proposition B.35 is not linear
but conjugate linear. The reason why this can nevertheless be called a matrix coefficient is that this
actually is the matrix coefficient (without complex conjugation) on a conjugate Hilbert space, as
explained in the next Proposition, which we took from Williams (1991).
Proposition B.26. Let ρ : G → U(V ) be a unitary representation on a Hilbert space V with scalar
multiplication ∙v and scalar product h∙∣∙>v. We have thefollowing:
1.	V := V (equality as abelian groups) With ɑ ∙r V := α ∙v V andhu|viv :=hu|v〉is again a
Hilbert space, the so-called conjugate Hilbert space of V.
10I.e., those parts that deal with approximations of square-integrable functions by matrix elements.
29
Published as a conference paper at ICLR 2021
2.	ρ: G → U(V) with ρ(g) .= ρ(g) is again a unitary representation.
3.	For the matrix coefficients, we have Puv (g) = Puv (g).
Proof. All these assertions are easy to check. As a demonstration, we do 3:
Puv (g) = hulρ(g)(v)iV = hulρ(g)(v)iv = Puv (g).
That's What We wanted to show.	口
As a consequence of this proposition, the matrix coefficient Puv (g) is equal to Puv (g), thus being a
“matrix coefficient without complex conjugation above the scalar product” of the conjugate unitary
representation.
Theorem B.27 (Density of Matrix Coefficients). The linear span of the matrix-coefficients of finite-
dimensional, unitary, irreducible representations ofG are dense in L2K(G) for all compact groups
G.
Proof. For K = C, this is shown in Knapp (2002). The same proof, without adaptions, also works
for K = R. Note that the cited proof uses a definition of matrix coefficients without the complex
conjugation. However, Proposition B.26 shows those span the same space, and thus we can apply it
to our situation.	口
B.2.2 Schur’ s Lemma, Schur’s Orthogonality and Consequences
In this section, we state and prove versions of Schur’s lemma and Schur’s Orthogonality (Knapp,
2002) that are valid for both K = R and K = C.
Lemma B.28. Let P . G → U(V) and P0 . G → U(V0) be unitary representations. Furthermore,
let f : V → V0 be an intertwiner. Then the adjoint f * : V0 → V is also an intertwiner
Proof. The adjoint f * : V0 → V is the unique continuous linear function from V0 to V such that,
for all v ∈ V and v 0 ∈ V0, we have
hf(v)|v0i = hv|f*(v0)i.
This always exists according to Definition F.42. Note that with f being an intertwiner and using the
unitarity of the representations, we obtain for allg ∈ G, v ∈ V and v0 ∈ V0:
hv|P(g)f*(v0)i = P(g-1)(v)f*(v0)
= fP(g-1)(v)v0
= P0(g-1)f(v)v0
= hf(v)|P0(g)(v0)i
= hv|f*P0(g)(v0)i
from which we deduce P(g)f * = f *P0(g) from Proposition F.45 for all g ∈ G, i.e., f* is an
intertwiner.	口
Lemma B.29 (Schur’s Lemma for unitary Representations). Assume P . G → U(V) and P0 .
G → U(V0) are irreducible unitary representations with V finite-dimensional. Also assume that
f : V → V0 is an intertwiner Then either f = 0 or there is μ ∈ R>o such that μf is an
isomorphism.
Proof. For this proof, we follow the exposition of Tao (2011). We thank Terrence Tao for confirming
in the discussion below his blogpost that this lemma can also be proven over the real numbers.
Let f* . V0 → V be the adjoint of f, which is also an intertwiner by Lemma B.28. Now, set
2:= f * ◦ f : V → V. As a composition of intertwiners,夕 is also an intertwiner. Furthermore,
for arbitrary composable continuous linear functions between Hilbert spaces one always has (g ◦
30
Published as a conference paper at ICLR 2021
h)* = h* ◦ g* and (g*)* = g, which easily follows from the definition and uniqueness of adjoints.
Consequently, we have
夕* = (f* ◦ f)* = f* ◦ (f*)* = f* ◦ f = Z
and so 夕 is self-adjoint. Thus,(夕(v)|w)= hv∣q(w)) for all v,w ∈ V, from which We conclude
that the matrix of Z corresponding to any orthonormal basis of V is Hermitian or, if K = R, even
symmetric. Such an orthonormal basis exists by Proposition F.41. From the Spectral Theorem for
Hermitian or symmetric matrices (Horn & Johnson, 2012) we conclude that Zis unitarily (or for
real matrices: orthogonally) diagonalizable with only real eigenvalues. Thus, there is an orthogonal
decomposition of V into eigenspaces: V = LλeigenvalueEλ(Z).
Let Eλ (Z) be any eigenspace. We now claim that it is an invariant subspace of ρ. Indeed, for all
g ∈ G and v ∈ Eλ(Z) we have since Zis an intertwiner:
Z(ρ(g)(v)) = ρ(g)(Z(v)) = ρ(g)(λv) = λρ(g)(v).
Since V is finite-dimensional, Eλ(Z) is topologically closed by Proposition F.47, and since V is
irreducible, we necessarily have Eλ(Z) = 0 or Eλ(Z) = V. Since not all eigenspaces can be zero,
we conclude that there is an eigenvalue λ with Eλ(Z) = V, meaning Z= λ idV .
Assume f 6= 0. We now claim that λ > 0. Indeed, note that for all v ∈ V we have
λkvk2 = hZ(v)|vi
= hf* ◦f(v)|vi
= hf(v)|f(v)i
= kf(v)k2.
Thus, if V ∈ V is any vector with f (v) = 0, then We obtain λ = (f Vv)k )2 > 0.
Now define g : V → V0 as g = λ- 1 f. g is clearly still an intertwiner. We can also show it is an
isometry:
hg(v)∣g(w)i = λ-1 hf(v)∣f(w)i
= λ-1 hZ(v)|wi
= λ-1λ hv|wi
= hv|wi .
Note that since V0 is irreducible and f(V) ⊆ V0 topologically closed due to V being finite-
dimensional, we necessarily have that f is surjective. Thus, we have shown that μf with μ := λ-2
is an isomorphism of unitary representations.	□
Proposition B.30 (Schur’s Orthogonality). Let ρ : G → U(V) and ρ0 : G → U(V0) be non-
isomorphic irreducible unitary representations of the compact group G, of which at least one is
finite-dimensional. Let ρuv and ρ0u0v0
due to their continuity. Then they are
be matrix coefficients of them, which are functions in L2K(G)
orthogonal, i.e., ρuv ρ0u0v0 = 0.
Proof. Without loss of generality, we can assume V0 tobe finite-dimensional. Assume that l : V0 →
V is any linear function. We can associate to it the function f : V0 → V given by
f (w0) :
ρ(g)lρ0(g)-1w0dg.
G
For all h ∈ G we have
ρ(h)f ρ0 (h)-1 =	ρ(h)ρ(g)lρ0(g)-1ρ0(h)-1dg
G
=	ρ(hg)lρ0(hg)-1dg
G
=	ρ(g)lρ0(g)-1dg
G
= f,
31
Published as a conference paper at ICLR 2021
and thus ρ(h)f = f ρ0 (h), which means that f is an intertwiner. In this derivation, ρ(h) could be
put insight the integral since ρ(h) is continuous and an integral is a limit over finite sums, which
commutes with the continuous ρ(h). By Schur’s Lemma B.29, we necessarily have f = 0. Now
look at the specific linear function l : V 0 → V given by l(w0) := hv0 |w0i v with the fixed vectors
v, v0 corresponding to the matrix coefficients. We obtain f = 0, for f defined as before, and thus:
0 = hu|f(u0)i = Du	ρ(g)lρ0(g)-1 (u0)dgE
=	uρ(g)lρ0(g)-1(u0) dg
G
= Z	uρ(g) v0ρ0(g)-1(u0) v dg
=/ hulP(g)(v)i ∙ (v0∣ρ0(g)-1(u0)) dg
G
=/ hu|P(O)(V)i ∙ hu0lPtg)(VO)idg
G
=ρ PUV (g')ρ,u'v' (g)dg
G
= PuV∣∣P0u0V0
In this derivation, the integral could be put out of the scalar product since the scalar product is
continuous, see Proposition F.38, and since integrals are certain limits over finite sums, with which
the scalar product commutes.
□
Note that there are more general Schur’s orthogonality relations in the case that K = C, see Knapp
(2002), Corollary 4.10. These then engage with the matrix coefficients of one and the same rep-
resentation. This, together with a version of Schur’s lemma that only holds over C leads to the
strengthening of the Peter-Weyl theorem that shows that the multiplicities nl are given by dim(Vl ).
Proposition B.31. All irreducible unitary representations of a compact group G are finite-
dimensional.
Proof. Assume P : G → U(V ) was an irreducible unitary representation on an infinite-dimensional
space V . Let PuV be any of its matrix coefficients. By Proposition B.30, and since an infinite-
dimensional representation can never be isomorphic to a finite-dimensional representation, PuV is
perpendicular to all matrix coefficients of finite-dimensional irreducible unitary representations. Due
to the linearity of the scalar product, PuV is perpendicular to the whole linear span of these matrix
coefficients and thus to the topological closure of this span. The last step follows from the continuity
of the scalar product, see Proposition F.38. By Theorem B.27 this closure is the whole space L2K(G).
Therefore, PuV is even perpendicular to itself, and thus PuV = 0.
Overall, for arbitrary u,v ∈ V and g ∈ G We obtain 0 = ρuv(g) = (u∣ρ(g)(v)i and thus (by setting
u = P(g)(V)) P(g)(V) = 0 and consequently P(g) = 0. We obtain P = 0, a contradiction. Thus
infinite-dimensional irreducible unitary representations cannot exist.	□
As a consequence, We mention that the finiteness conditions in Schur’s lemma and Schur’s Orthogo-
nality Were not necessary to state since all irreducible unitary representations are finite-dimensional
anyWay. We obtain from this and from Schur’s Lemma B.29 that isomorphism classes and equiva-
lence classes of irreducible unitary representations are one and the same.
B.2.3 A Proof of the Peter-Weyl Theorem for the Regular Representation
In this section, We engage With the Peter-Weyl theorem for the regular representation on L2K(G).
The case of L2K (X) for a homogeneous space X Will be dealt With in Section B.2.4. The core
arguments in the proofs of this section are adapted from Williams (1991).
As before, let G be the set of isomorphism classes of irreducible representations of G. For l ∈ G
let Pl be a representative for the isomorphism class l. Furthermore, for each Pl : G → U(Vl),
32
Published as a conference paper at ICLR 2021
let vl1, . . . , vldim(Vl) be an arbitrary orthonormal basis, which exists due to Proposition F.41 (mostly
written without the superscript, i.e., as v1, v2, . . . , if the corresponding isomorphism class is clear).
Denote ρlij := ρlvivj . Remember that matrix coefficients of unitary representations are continuous
by Remark B.25, and thus functions in L2K(G). Then, let E ⊆ L2K(G) be the linear span of the
matrix coefficients of all irreducible unitary representations. In the next Lemma, we want to show
that E is already spanned by the matrix coefficients corresponding to representatives of isomorphism
classes and their orthonormal bases:
Lemma B.32. We have
E = spanK
| l ∈ Gb,i,j ∈ {1,...,dim(Vl)} .
Proof. First, we show that isomorphic representations don’t add distinct matrix coefficients. Thus,
let P = Pl and let f : V → Vi be the corresponding isomorphism. Then We have ρι(g) ◦ f = f ◦ ρ(g)
and thus, since f is a unitary transformation, ρ(g) = f * ◦ ρι(g) ◦ f, for all g ∈ G, see Proposition
F.44. NoW let u, v ∈ V be arbitrary. We obtain
Puv (g) = hu∣ρ(g)(v)i
=huf*Pl (g)f (V)i
=hf(U)IPi(g)(f (V))i
= Plf(u)f(v) (g),
Which proves the first claim. NoW We Want to shoW that We only need to consider the Plij . Thus, let
u, V ∈ Vl be arbitrary. They alloW for linear combinations
U = Xiλivi,V = Xi μivi
with coefficients λi,μi ∈ K. We obtain:
Puv (g) = hu∣ρι (g)(v)i
=Xi Xj λiμj ∙hvi∣Pi(g)(vj )i
= (XiXj λiμjPij)(g),
thus showing that Piuv is in the linear span of the matrix coefficients corresponding to the orthonormal
basis. This concludes the proof.	□
For an isomorphism class l ∈ G, let Ei
span Piij
| i, j ∈ {1, . . . , dim(Vi )} ⊆ L2K(G) be the
linear subspace of E generated by matrix coefficients corresponding to l. Let furthermore for all j
the space Eij ⊆ Ei be the subspace generated by all Piij for i ∈ {1, . . . , dim(Vi)}. In the next lemma,
we prove that these are actually closed subrepresentations of the regular representation.
Lemma B.33. Forj ∈ {1, . . . , dim(Vi)}, Eij isa closed invariant subspace ofL2K(G). In particular,
Ei is a closed invariant subspace of L2K (G).
Proof. Closedness follows immediately since this space is finite-dimensional and thus complete, see
Proposition F.47. We need to show that λ(g)Piij ∈ Eij for all g ∈ G and all i, j. We can compute
33
Published as a conference paper at ICLR 2021
this directly:
λ(g)ρlij(g0)=ρlij(g-1g0)
=hv∖ρι(gTg'0)(∙vj )i
=hPi(g)(vi)lPi(g0)(vj )i
=(Xi, hvi0lPi(g)(vi)i vi0∣ρι(g0)(vjA
=Xiohvi0 ∣ρι(g)(vi)i∙hvio∣ρι(g0)(vj )i
=Xi0 hvi|pi(gT)(ViO)iρiθj(gO)
=(Xio 宿(gT)Piθj)(g0)
where the coefficients ρii0(g-1) do not depend on g0. Consequently, λ(g)ρij ∈ Ej.	□
Lemma B.34. Let ρ : G → U(V ) and ρ0 : G → U(V 0) be unitary representations, ρ being
irreducible and V 0 6= 0. Furthermore, assume that f : V → V 0 is a surjective intertwiner. Then V 0
is also irreducible and f an equivalence.
Proof. Assume by contradiction that V 0 is reducible. Thus, there is a nontrivial closed invariant
subspace 0 ( W ( V 0 . Now the following can easily be checked:
1.	0(f-1(W)(V.
2.	f-1(W) is an invariant subspace of V .
3.	f-1(W) is a closed subset of V.
Once we have this, we have a contradiction to the fact that V is irreducible.
1 and 2 can be checked by the reader, and 3 follows since V is, as an irreducible representation,
finite-dimensional by Proposition B.31 and thus every subspace is closed by Proposition F.47.
Therefore, we know that V 0 is irreducible. Now use Schur’s Lemma B.29 to conclude that f, being
nonzero, necessarily is an equivalence.	□
Proposition B.35. There is an equivalence of representations flj : Vl → Elj given on the orthonor-
mal basis by fj (Vi) = ρi. Consequently, there is an isomorphism Vi = Ej of unitary representa-
tions.
Proof. We need to show that flj is equivariant. Using the result of the derivation of Lemma B.33,
we compute
flj(ρl(g)(Vi))= flj Xi0 (Vi0∣∣ρl(g)(Vi)Vi0
= Xi0 (Vi0∣∣ρl(g)(Vi)flj(Vi0)
=Xio hvi∣Pi(g-1)(vi0)iPi0j
= Xi0 ρlii0 (g-1)ρli0j
= λ(g)ρlij
= λ(g) flj(Vi) ,
so fj ◦Pi(g') = λ(g)fj for all g ∈ G, which is What We wanted to show. That f isan intertwiner also
requires it to be continuous: this follows since Vl is finite-dimensional, and so all linear functions
on it are continuous.
34
Published as a conference paper at ICLR 2021
Now, that flj is even an equivalence follows from Lemma B.34 by noting that Elj 6= 0. Indeed, if it
was zero then we would have ρlij(g) = 0 for all i, and thus ρ(g) would not be invertible, in contrast
that it is a unitary automorphism.
Thus, there is even an isomorphism % = Ej by Schur's Lemma B.29.	□
Lemma B.36. Let ρ : G → U(V ) be a unitary representation. Let V1 ⊆ V be a subrepresentation.
Then the orthogonal complement V1⊥ is a subrepresentation as well.
Proof. We have hv|v1i = 0 for all v ∈ V1⊥ and all v1 ∈ V1. Now, let g ∈ G be arbitrary. From the
unitarity of ρ we obtain
hρ⑼(V)IvIi = ®p(gT)(V1» = 0.
The last step follows from ρ(g-1)(v1) ∈ V1, which holds since V1 is a subrepresentation. Overall,
this shows ρ(g)(v) ∈ V⊥ as well, and so this is a subrepresentation.	□
Lemma B.37. Let ρ : G → U(V ) be a finite-dimensional unitary representation. Furthermore,
assume that W1 , W2 are irreducible subrepresentations. If they are not isomorphic, then they are
perpendicular, i.e., hw1 |w2i = 0 for all w1 ∈ W1 and w2 ∈ W2.
Proof. Let P : V → W1 be the orthogonal projection from V to W1 , defined as the adjoint of the
canonical inclusion i : W1 → V , i.e., defined by the property
hw1 |P (v)i = hi(w1)|vi = hw1 |vi
for all v ∈ V and w1 ∈ W1 , see also Proposition F.46. We now show that P is equivariant. For all
g ∈ G, v ∈ V and w1 ∈ W1 we have:
〈wi IP(P⑼(V))〉= hwi|P⑼(V)i
= ρ(g-1)(w1)v
=〈P(gT)(WI)IP(V)〉
=〈wi1P⑼(P(V))〉，
where we used in the third step that W1 is a subrepresentation. Since this holds for all w1 ∈ W1, we
obtain P(ρ(g)(V)) = ρ(g)(P (V)) by Proposition F.45 and overall that P is equivariant.
In particular, also the restriction P |W2 : W2 → W1 is equivariant. Since W1 and W2 are not
isomorphic, we obtain by Schur’s Lemma B.29 that P|W2 = 0, i.e., for all w1 ∈ W1 and w2 ∈ W2
we have hw1|w2i = hw1 |P |W2 (w2)i = hw1|0i = 0. Thus, W1 and W2 are perpendicular as
claimed.	□
Proposition B.38. Let ρ : G → U(V ) be any finite-dimensional unitary representation. Then V
decomposes into an orthogonal direct sum
n
V = M Vi
i=1
such that Vi ⊆ V are irreducible subrepresentations of ρ.
Proof. Let V1 be any irreducible subrepresentation of V : This can be obtained by noting that if
V is not already irreducible (in which case V1 = V ), then we find a nontrivial subrepresentation
0 ( W ( V . By iteratively proceeding with W, we eventually need to reach an irreducible
representation since V is finite-dimensional.
Now, let V1⊥ be the orthogonal complement of V1. From Lemma B.36 we know that this is a subrep-
resentation of V . By induction on the dimension of V , and since V1⊥ has strictly smaller dimension,
we can assume that V1⊥ already splits into an orthogonal direct sum of irreducible subrepresentations
V⊥ = Ln=2 Vi, and overall, V = Ln=i Vi is the decomposition We were looking for.	□
The following proposition will not be used now, but we make use ofit later when showing that there
are only finitely many basis kernels in a steerable CNN for a compact group:
35
Published as a conference paper at ICLR 2021
Proposition B.39 (Krull-Remak-Schmidt Theorem). In the situation of Proposition B.38, the or-
thogonal direct sum decomposition is essentially unique. That is, the type and multiplicities of the
irreducible direct summands is always the same.
Proof. If one has one decomposition of V in which an irreducible representation U does not appear,
then it cannot appear in any decomposition since U would be perpendicular to all the irreps in the
decomposition of V by Lemma B.37 and thus zero. Therefore, the types of irreducible representa-
tions is always the same. That the multiplicities are always the same follows by the same argument
and for dimension-reasons.	口
We can now finally prove The Peter-Weyl Theorem B.22 for the case that X = G:
Proof. By Proposition B.38 and Lemma B.33 there is some orthogonal decomposition El =
Lin=l 1 Vli into irreducible invariant subspaces. Now assume that there is an i such that Vli Vl .
By Proposition B.35 this means that Vli Elj for all j = 1, . . . , dim(Vl). By Lemma B.37 we
obtain Vli ⊥ Elj for all j and thus, since Pj Elj = El, we obtain Vli ⊥ El and overall Vli = 0, a
contradiction.
Thus, the assumption was wrong and all Vli in the orthogonal direct sum are isomorphic to Vl.
Now let l 6= l0 and i, j be arbitrary. We have El ⊥ El0 by Proposition B.30, and thus in particu-
lar Vli ⊥ Vl0j. Furthermore, we have nl ≤ dim(Vl) since El = Pjd=im1(Vl) Elj = Lin=l 1 Vli, and
dim(Vl) < ∞ by Proposition B.31.
Moreover, we have Ll∈Gb Lin=l 1 Vli = Ll∈Gb El = E, which is topologically dense in L2K(G) by
Theorem B.27.
Finally, that nl = dim(Vl) ifK = C follows by invoking a stronger version of Schur’s orthogonality
than We have developed, and which works only over the complex numbers (Knapp, 2002).	□
B.2.4 A PROOF OF THE PETER-WEYL THEOREM FOR GENERAL L2K(X)
Now let X be a homogeneous space of G. Then, as mentioned in Section B.1.3, there is a measure
μ on X which is left-G-invariant (Nachbin & Bechtolsheim, 1965) in the sense that we have for all
g ∈ G and all square-integrable functions f ∈ L2K(X):
JX f(g Hdx = JX
(x)dx.
Furthermore, let ∏ : G → X be the projection given by g → gx* for a fixed element x* ∈ X.
One important result is that there is a Fubini-like theorem for evaluation of integrals on G using the
invariant measure on X. Namely, for arbitrary x ∈ X, let g(x) ∈ G be any lift, i.e., any element
in G with ∏(g(x)) = x. This exists since the action is transitive. Let H := Gχ* ⊆ G be the
stabilizer subgroup. For a square-integrable function f	: G → K, we can then construct the average
av(f ) : X → Kby
av(f )(x) :=
H
(g(x)h)dh,
where we integrate using the Haar-measure on H.11 If it is hard to understand why this is called
an average, note that X = G/H, i.e., points in X can be interpreted as cosets of G, and then the
average just averages over cosets.12
This construction is well-defined, i.e., does not depend on the specific choice of the lift g(x). Indeed,
let g(x)0 be another lift of x. Then g(x)0 = g(x)h0 for some h0 ∈ H, since H is the stabilizer
11Such a Haar measure exists since H ⊆ G is a topologically closed subgroup of a compact group by Propo-
sition B.21 and thus compact itself by standard topological results (Conway, 2014). Note that this measure
fulfills μ(H) = 1 and is thus not the same as the restriction of the measure on G to H.
12Here, G/H is the set of equivalence classes in G with respect to the equivalence relation g 〜 g0 if
g-1g0 ∈ H, which has a quotient topology as explained in Definition F.11. The equivalence classes are given
by the cosets gH for g ∈ G.
36
Published as a conference paper at ICLR 2021
subgroup. Consequently, using the invariance of the Haar measure, we see:
f (g(x)0h)dh =	f (g(x)h0h)dh =	f(g(x)h)dh,
and thus the well-definedness of the average av(f) : X → K. Integration of f on the whole of G
is a “complete” average, and thus we can hope that averaging av(f) leads to this complete integral.
This is indeed the case, i.e., av(f) is square-integrable on X and one has (Nachbin & Bechtolsheim,
1965)
f (g)dg =	av(f)(x)dx.
(9)
We will use this important result later in order to see that L2K(X) embeds with good properties into
L2K(G).
We now want to prove the Peter-Weyl theorem for L2K (X). We first present a general argument
showing an orthogonal decomposition of L2K (X) into irreducible subspaces, and then use a specific
argument to deduce that the multiplicities of irreducible subrepresentations are necessarily bounded
by the multiplicities in L2K (G).
Proposition B.40. Let ρ : G → U(V ) be any unitary representation. Then there is a dense subrep-
resentation which splits as an orthogonal direct sum of irreducible subrepresentations.
Proof. We sketch the proof in Kowalski (2014), Corollary 5.4.2. In this book, the proof is done
only for the complex numbers C, but it is obvious that each step carries over without any changes to
arbitrary K ∈ {R, C}. The rough steps are as follows:
1.	From P one builds a function P : LK(G) → HomK(V, V), given by PW)(V)=
Jg 2(g)ρ(g)(v)dg. This is analogous to our construction of kernel operators (special rep-
resentation operators) from kernels, which we will handle in the next chapter, See Theorem
C.7.
2.	Given V ∈ V fixed, one obtains the function ρv : LK(G) → V,夕 → ρ(φ)(v). One can
check easily that this is an intertwiner.
3.	For each finite-dimensional subrepresentation E ⊆ LK(G) the image ρv(E) ⊆ V is a
finite-dimensional subrepresentation of V.
4.	For v 6= 0, using analytical arguments and the Peter-Weyl theorem for L2K (G), one can
prove that there is an E such that ρv(E) ⊆ V is not zero.
Having that, one can use Proposition B.38 in order to deduce that ρv(E) contains an irreducible
subrepresentation, and so does V.
With this at hand, one can proceed inductively as follows: Given an irreducible subrepresentation
V1 ⊆ V, one can consider the orthogonal complement V1⊥, which is by Lemma B.36 again a
subrepresentation of V. Thus, this also has, by the same argument as above, an irreducible subrep-
resentation V2 and so on. By induction (or better: using Zorn’s Lemma), one can then “fill up” V
with orthogonal irreducible subrepresentations, deducing the result.	口
Consequently, since LK(X) carries a unitary representation of G by [λ(g)(夕)](χ):=夕(g-1χ), We
can deduce that it contains a dense subrepresentation which splits as an orthogonal direct sum of
irreducible subrepresentations. But we would like to know more details about this, in particular the
multiplicities of the irreps. For this to work, we want to embed L2K(X) into L2K(G) and thus deduce
a more specific result from the decomposition of L2K(G).
Let as before x* ∈ X be an arbitrary point and let ∏ : G → X be the projection given by ∏(g):=
gx*. Consider the function π* : LK(X) → LK(G) given by ∏*(夕):=夕◦ π. It is unclear a priori
whether this is well-defined: For example, it might be that an f : X → K which is zero outside a
measure 0 set gets lifted to π* (f) : G → K which does not have this property, and thus π* would
not be an actual function.13 Thus, we need some lemmas:
13Remember that functions in L2K(X) for any measurable space X are identified if they agree outside a set
of measure 0.
37
Published as a conference paper at ICLR 2021
Lemma B.41. Let f : X → K be square-integrable. Then we have av(π*(f)) = f.
Proof. Using Eq. (9) and that H is the stabilizer subgroup we compute:
av(∏*(f ))(x)
∏*(f )(g(x)h)dh
H
f (π(g(x)h))dh
H
f (π(g(x)))dh
H
f (x)dh
H
f (x)	1dh
H
f (χ)μ(H)
f (x).
□
Lemma B.42. Let A ⊆ X be any measurable set. Let 1A : X → {0, 1} ⊆ K be its indicator
function. Then π*(1a) = 1∏-ι(A).
Proof. This can easily be checked.
□
Lemma B.43. Let 夕：X → K be zero outside a measure zero set A. Then ∏*(夕)is zero outside
π-1 (A) which is also a measure zero set.
Proof. If g ∈/ π-1 (A) then π(g) ∈/ A and thus:
0 =2(Wg)) = π*(0(g)
which proves the first statement. The second is shown as follows using both Lemmas B.41 and B.42
and Eq. (9):
μ(π-1(A)) = 1 1∏-i(A)(g)dg
G
[π*(1A)(g)dg
G
a av(π*(1a))(x)dx
X
1A (x)dx
X
μ(A)
0,
thus showing what was claimed.
□
Thus, our concern about well-definedness as a function is invalid and we can now prove an embed-
ding result:
Proposition B.44. π* : L2K(X) → L2K(G) is a well-defined intertwiner and a unitary transforma-
tion, i.e.,for all 夕,ψ ∈ LK(X) we have h∏*(0∣∏*(Ψ))LK(G) = QIΨ>lK(x).
Proof. For well-definedness, We still need to show that ∏* (夕)is again square-integrable for square-
integrable 夕：X → K. This is indeed the case due to Eq. (9). Namely, let ∣∏*(夕)|2 : G → K and
38
Published as a conference paper at ICLR 2021
consider its average av(∣∏*Q)∣2). Clearly, We have ∣∏*Q)∣2 = ∏*(3∣2) and thus, using Lemma
B.41, av(∣π*(0∣2) = 32. We obtain:
I l∏*(ψ)∣2(g)dg = a av(∣π*3∣2)(x)dx
GX
=I 3(x)∣2dx
X
< ∞.
Thus, ∏ is not only well-defined but even fulfills ∣∣∏*(夕)kLK(G) = IlHlLK(X), which also shows
the continuity of ∏*. With similar arguments, we show that ∏* respects the whole scalar product,
i.e., is a uniform transformation:
• Π*(ψð (g)dg
I av(π*(夕)• π*(ψ))(x)dx
X
H(x)ψ(x)dx
X
WLK(χ).
The step from the second to the third line follows as before by noting that ∏* (夕)• ∏*(ψ) = ∏*(H • ψ)
and invoking Lemma B.41 again.
The linearity of ∏* is obvious, and the equivariance is done as follows: note that for arbitrary
g,g ∈ G we have ∏(g-1g0) = (g-1g0)χ* = g-1(g0x*) = g-1π(g0) and therefore:
[n* (NgW)MgO) = (Ngw)(WgO))
= H(g-1π(g0))
= H(π(g-1gO))
=π*(ψ)(gTg)
= [λ(g)π*S](g0).
Thus, we shown everything which was to show.	□
Thus, ∏* : LK(X) → LK(G) is an embedding which even preserves the scalar product. We can
therefore view L2K(X) as a subspace: L2K (X) ⊆ L2K (G).14
We can finally complete the proof of the Peter-Weyl Theorem B.22:
Proof of Theorem B.22. Assume that
ml
M M Vli ⊆ L2K (X) ⊆ L2K (G)
l∈Gb i=1
is a dense subspace such that the direct sum is orthogonal, where V^ = % for all l, i. This exists by
Proposition B.40.
Remember that nl denotes the multiplicity of Vl as a subrepresentation in L2K (G). We now want to
show that ml ≤ nl . Since Vli is perpendicular to all El0 with lO 6= l by Lemma B.37, Vli must be
contained in the orthogonal complement of Ll0 6=l El0 . This is exactly El, which we show in a final
lemma after this proof. So Vli ⊆ El for all i. Thus, we obtain the result ml ≤ nl by dimension
reasons. This was all there was left to show.	□
Lemma B.45.
Wehave EI = (Lι="∈G E")⊥
14In this notation, we suppress that this embedding depends on the specific base point x* which was chosen.
For another base point, the embedding differs by a unitary automorphism on L2K(G) as the reader may want to
check.
39
Published as a conference paper at ICLR 2021
Proof. We already know El ⊆ Ll6=l0∈Gb El0 ⊥ from Proposition B.30. Now, assume this inclusion
is not an equality. Then there is v ∈/ El such that v ∈
Ll6=l0∈Gb El0 ⊥. The space spanK (v,El)
does contain an orthonormal basis by Proposition F.41, where the procedure of Gram-Schmidt or-
thonormalization allows starting with an orthonormal basis of El and to fill it up to one of the whole
space spanK (v, El). Thus, we can assume v ∈ El⊥ as well. Overall, v ∈ Ll0∈Gb El0 ⊥, and by
taking topological closure and using that the scalar product is continuous by Proposition F.38, ob-
tain v ∈ Lcl0 ∈GbEl0 ⊥ = (L2K(G))⊥ by the Peter-Weyl theorem for the regular representation. This
means v = 0 ∈ El , a contradiction to v ∈/ El .
Thus, our assumption is wrong and such a vector v cannot exist. We obtain the equality as desired.
□
C The Correspondence between Steerable Kernels and
Representation Operators
In this chapter, we formulate and prove Theorem C.7, which gives a precise one-to-one correspon-
dence between steerable kernels on the one hand, and certain representation operators which we
call kernel operators on the other hand. Representation operators are a representation-theoretic ab-
straction of the scalar, vector and tensor operators from physics, that were explained in Section 2.
The correspondence will allow us to prove a Wigner-Eckart theorem for steerable kernels in Chap-
ter D and, ultimately, to obtain a complete description of steerable kernel bases. We formulate the
correspondence in Section C.1, while Section C.2 gives a detailed and rigorous proof of it.
As in Chapter B, K is either of the two fields R or C.
C.1 Fundamentals of the Correspondence
In Section C.1, we formulate the correspondence between steerable kernels and special represen-
tation operators that we name kernel operators. We do this by first studying steerable CNNs and
the kernel constraint in Section C.1.1, which progressively leads us to consider steerable kernels
on homogeneous spaces of general compact groups in Section C.1.2. This abstract formulation of
steerable kernels will show apparent similarities to the concept of representation operators in Sec-
tion C.1.3. We study them in purely representation-theoretic terms in Section C.1.4. However, they
importantly differ in the fact that steerable kernels are not linear, whereas representation operators
are - this is a difference that We need to bridge. Finally, after defining kernel operators as special
representation operators, we give the formulation of the correspondence in Theorem C.7 in Section
C.1.5 and shortly give some intuitions about Why it is true.
C.1.1 Steerable Kernels and the Restriction to Homogeneous Spaces
The concept of steerable CNNs outlined here folloWs (Weiler et al., 2018a; Weiler & Cesa, 2019).
In a nutshell, they Work as folloWs:
The netWork is supposed to process feature fields f : Rd → Kc With d ∈ N. c is the dimension of
the features themselves, i.e., the number of channels. For example, planar RGB-images correspond
to the case d = 2 and c = 3.
Furthermore, a compact group G (Definition B.4) is considered that acts on Rd, for example, the
special orthogonal group SO(d), the orthogonal group O(d) or the finite groups CN orDN ifd = 2.15
Then for each layer, the input and output features have a certain type, i.e., representation, Which may
differ from layer to layer. That is, the input (and output as Well) consists of a function f : Rd → Kc,
and G acts on Kc With a linear representation ρ, see Definition B.10. This action induces an action
15We Will study some of these groups in the Examples in Chapter E.
40
Published as a conference paper at ICLR 2021
of the semi-direct product (Rd, +) o G on the space of all signals,16 where t ∈ (Rd, +) and g ∈ G:
([IndGdoG Phtg) ∙ f) (X)= ρ(g) ∙ f(g-1(X- t)).
Let the kernel that “maps” between the layers by convolution17 be given by a function
K : Rd → Kcout×cin.
That is, for an input fin : Rd → Kcin, the output fout : Rd → Kcout is given by
fout (X)
[K ?fin] (X) =	K(y)fin(X + y)dy,
Rd
where K(y) ∈ Kcout×cin acts for any y ∈ Rd as a linear transformation from Kcin to Kcout.
The goal is now to find kernels K such that convolution with these kernels commutes with the
induced actions on the input and output fields. That is, for all input fields fin and for all t ∈ Rd and
g ∈ G we want the following property:
K? ([IndGdoG Pin] (tg) ∙ fin) = [IndRdoGPout] (tg) ∙ (K? fin).
It was shown in Weiler et al. (2018a) that a kernel K has this equivariance property if and only if
the kernel satisfies a certain constraint. We are rederiving it here for convenience.
Writing out both sides we obtain the following equality that needs to hold for all fin and all X, t ∈
Rd:
/ K(y)ρin(g)fin(g-1(χ + y - t))dy = Pout(g) /	K(y)fin(g-1 (X -1) + y)dy.
Rd	Rd
Substituting y = g-1y on the left side and using | det g| = 1 due to the compactness of G, and
putting Pout(g) inside the integral on the right side, which is possible due to linearity, we obtain:
R [K(gy)Pin(g)]fin(g-1X - g-1t + y)dy = R [Pout(g)K(y)]fin(g-1X - g-1t + y)dy.
Since this needs to hold for all fields fin, we necessarily have K(gX)Pin (g) = Pout (g)K(X) for all
X ∈ Rd and all g ∈ G and obtain the kernel constraint
K(gX) = Pout(g) ◦ K(X) ◦ Pin(g)-1.	(10)
This work will create a general theory for how to solve this kernel constraint, which means to find a
parameterization for the space of all kernels that fulfill this constraint. We now explain how to make
this problem more tractable: formally, the action of G on Rd is a group action as in Definition B.5.
However, it cannot be transitive as in Definition B.7 since G is compact and Rd is not. Thus Rd
splits into a disjoint union of orbits (Definition B.6), of the action:
Rd =	Xk .
k∈K
That this is a disjoint union can be explained as follows: define the relation 〜on Rd by X 〜χ0
if gX = X0 for some g ∈ G. This is then an equivalence relation, and so Rd splits into a disjoint
union of equivalence classes. One then can show that these equivalence classes are precisely the
orbits of the group action. For example, such orbits take the form of spheres Sd-1 if G = SO(d) or
G = O(d) and the form ofa finite set of points if G = CN or G = DN.
The idea is now that the kernel constraint 10 only constrains the behavior of the kernel at each orbit
individually, and thus a solution on each orbit can be “patched together” to a solution on the whole
16The semidirect product Rd o G can be imagined as the smallest subgroup of the group of all isometries of
Rd that contains both the translations Rd and the transformations G. It is not important to know the abstract
definition of a semidirect product in our context.
17The operation is actually a so-called “correlation”, but the term “convolution” is more widespread in the
deep learning context and we follow this convention.
41
Published as a conference paper at ICLR 2021
of Rd . Indeed, assume that Kk : Xk → Kcout ×cin individually fulfill the kernel constraint, which
means that for all xk ∈ Xk and g ∈ G we have
Kk(gxk) = ρout(g) ◦ Kk(xk) ◦ ρin(g)-1.
Then, define the patch of these orbit-kernels by K : Rd → Kcout ×cin as K(x) = Kk (x) if x ∈ Xk.
This is well-defined since each x is in precisely one orbit. Then clearly, K satisfies the kernel
constraint 10. Moreover, each kernel K which fulfills the kernel constraint emerges from such a
construction, since we can simply set Kk := K|Xk. Overall, we see that we can restrict our attention
to orbits. In Weiler et al. (2018b) and later Weiler et al. (2018a), a discretized implementation is done
where the kernel is discretized into finitely many orbits with a smooth Gaussian radial profile. We
will come back to these practical questions of parameterization in Remark D.19, once we have fully
developed the theory of steerable CNNs.
C.1.2 An Abstract Definition of Steerable Kernels
Motivated by the discussion in the last section, we now define steerable kernels in precise terms and
will stick to that definition throughout this work. The definition will be more abstract than usual in
the deep learning community, but we are rewarded since such an abstract definition makes it easier
to apply representation-theoretic results.
Without loss of generality, we will in the rest of this work only consider kernels on orbits. Thus, let
X := G ∙ X be an arbitrary orbit. We consider steerable kernels K : X → KcOut ×cin. Note that the
restriction of the action G × Rd → Rd to X , written G × X → X , makes X to a homogeneous
space of G, see Definition B.7. Thus, instead of viewing X as a subset of Rd, we view X as an
arbitrary homogeneous space of an arbitrary compact group G. Notably, this framework is more
general than usually studied in the context of steerable CNNs on Rd, since we allow also groups
that are not Lie groups and homogeneous spaces which are not naturally embedded in an Rd, as
well as finite homogeneous spaces of finite groups all at the same time.
Furthermore, we replace Kcin and KcOut by coordinate-independent K-vector spaces Vin and Vout ,
and therefore KcOut ×cin by the space of linear functions from Vin to Vout, written HomK(Vin, Vout).
We assume there are linear representations ρin : G → GL(Vin) and ρout : G → GL(Vout).
Overall, this means that steerable kernels are certain maps K : X → HomK (Vin , Vout). The only
property they need to fulfill is the kernel constraint K(gx) = ρout (g) ◦ K(x) ◦ ρin(g)-1 for all
g ∈ G and x ∈ X . This can be viewed in representation-theoretic terms by defining the Hom-
representation:
Definition C.1 (Hom-Representation). Let ρin : G → GL(Vin) and ρout : G → GL(Vout) be two
finite-dimensional G-representations over the field K. The space HomK(Vin, Vout) of K-linear (not
necessarily G-equivariant) functions from Vin to Vout also carries an induced G-representation, with
action
[ρHom (g)] (f) := ρout(g) ◦ f ◦ ρin(g) .
We call this the Hom-representation.
Remark C.2. Of course, one needs to check that this is indeed a linear representation. Continuity
follows from the continuity of ρin and ρout as follows: the topology on HomK (Vin , Vout) is just
the Euclidean topology of KcOut ×cin coming from a basis of Vin and Vout. In these bases, ρin(g)
and ρout (g) are given by matrices. All matrix coefficients are continuous by Remark B.25. Now, in
order to show that ρHom is continuous, pick a fixed element f ∈ Kcin×cOut . One needs to show that
the map
ρfHom : G → Kcin×cOut , g 7→ ρout (g) ◦ f ◦ ρin(g-1)
is continuous. Since all matrix coefficients are continuous and since also the inversion G → G, g 7→
g-1 is continuous by the definition of a topological group, the map ρfHom is basically just a stacked
linear combination of continuous functions and thus continuous itself.
42
Published as a conference paper at ICLR 2021
The linearity of each ρHom (g) is also clear. So what needs to be checked is that ρHom is a group
homomorphism. And indeed, it is, exploiting the corresponding property of ρin and ρout :
[ρHom(gg0)] (f) = ρout (gg0) ◦ f ◦ ρin(gg0)-1
=ρout(g) ◦ (PoUt(g ) ◦ f ◦ ρin(g )	) ◦ ρin(g)
=[PHom(g)] ( [PHom(g0)] (f))
= [ρHom (g) ◦ ρHom (g )] (f),
and so the claim follows.
With this definition in mind, steerable kernels K : X → HomK(Vin, Vout) are just functions with the
property K(gx) = [ρHom (g)] (K(x)). Summarizing, we have the following abstract definition of
steerable kernels (different from Definition 3.2, we here allow also input- and output representations
that are not irreducible and make explicit reference to the Hom-representation):
Definition C.3 (Steerable Kernel). Let G be any compact group and X be any homogeneous space
of G. Furthermore, let ρin : G → GL(Vin) and ρout : G → GL(Vout) be finite-dimensional repre-
sentations of G. We assume that HomK(Vin, Vout) is equipped with the Hom-representation ρHom.
A G-steerable kernel is an equivariant function K : X → HomK(Vin, Vout), i.e., a function such
that
K(gx) = [ρHom (g)] (K(x))	(11)
for all g ∈ G and x ∈ X. We denote the vector-space of all these kernels by
HomG (X, HomK(Vin,Vout)) = {K : X → HomK(Vin, Vout) | K is steerable } .
Notably, steerable kernels are not linear in a meaningful sense with respect to their input.
That the space of steerable kernels forms a vector space, as claimed in this definition, can easily be
checked.
C.1.3 More Details on the Comparison of Representation Operators and
Steerable Kernels
Steerable kernels satisfy the constraint
K(gx) = ρout(g) ◦ K(x) ◦ ρin(g)-1,	(12)
whereas, as we saw in Section 2, representation operators are collections (A1, . . . , AN) of operators
Ai : H → H that satisfy the constraint
N
π(g, 1 π(g)ijAj = U(g)tAiU(g)	∀ g ∈ G.
j=1
Hereby, U : G → U(H) andπ : G → U(CN ) are unitary representations. Unfortunately, these
equations still look somewhat different from each other. We can make them more similar by invert-
ing g and using the unitarity ofπ (note the swap of j and i and the complex conjugation):
N
V, ιπ(g)jiAj = U(g)AiU(g)t	∀g ∈ G.	(13)
j=1
In order to make the analogy to steerable kernels stronger, we would like to interpret a representation
operator as one object A instead of separate operators Ai , in the same way as a kernel K is one
single object and not just a disjoint collection of linear functions in HomK(Vin, Vout). For this, we
interpret A as a function that assigns to arbitrary vectors in CN an operator. Namely, let {ei } be the
standard basis of CN. We then define A as the unique linear map which is given on basis elements
as follows:
A : ei 7→ Ai .
43
Published as a conference paper at ICLR 2021
We can then deduce the following, where we use the linearity of A in the second step, the definition
of Aj in the third and fifth step, and Eq. (13) in the fourth step:
A(π(g)(ei)) = A( XjHgjiej)
=En⑼jiA(ej)
j
=En(g)jiAj
j
=U (g)AiU (g)t
=U (g)A(ei)U (g)t.
(14)
If now v = Pi λiei is an arbitrary vector in CN, not necessarily a standard basis vector, then from
the linearity of A and Eq. (14) we obtain
A(∏(g)(v)) = U (g)A(v)U (g)-1.	(15)
This equation is essentially the starting point for the definition of a representation operator as it can
be found in Jeevanjee [2011].
This, finally, really looks like Eq. (12). In this comparison, the action of the group G on Rd in deep
learning is replaced by the action of G via ∏ on the space CN. The main difference is that steerable
kernels are not necessarily linear. This difference will be bridged in Theorem C.7.
C.1.4 Representation Operators and Kernel Operators
Now that we have a clear abstract idea of what steerable kernels are and saw strong analogies to
representation operators, we can begin to formulate precise theoretical connections. In this section,
we therefore begin with formulating a purely representation-theoretic and more abstract working
definition of representation operators and will then formulate the main theorem of this chapter,
Theorem C.7.
We come to the main definition, which is directly motivated from Eq. (15). It differs from (Jeevanjee,
2011) by allowing the input- and output representations to differ. We furthermore restrict to finite-
dimensional input- and output representations due to our specific applications. As explained in
Section C.1.3, this new definition furthermore somewhat differs from the one given in Section 2
since now we view representation operators as one object instead of viewing it as a collection of
several linear operators.
Definition C.4 (Representation Operator). Let ρin : G → GL(Vin) and ρout : G → GL(Vout)
be finite-dimensional G-representations. Let λ : G → GL(T ) be a third G-representation,
not necessarily finite-dimensional. Then a representation operator is an intertwiner K : T →
HomK(Vin, Vout), where the right space is equipped with the Hom-representation as in Definition
C.1. We denote the vector space of all these representation operators by
HomG,K(T,HomK(Vin, Vout)) = {K : T → HomK(Vin, Vout) | K is an intertwiner} .
Note that representation operators are by definition linear, which is a requirement that needs to be
satisfied for the standard Wigner-Eckart theorem. We clearly see strong similarities between this
definition and the formalization of steerable kernels in Definition C.3. The main difference is that
we assume representation operators to be linear. This is in notation captured by the subscript K that
we put in the corresponding Hom-space. One may think that there is another difference, namely
coming from the fact that intertwiners are by definition continuous with respect to the topologies
involved. Two things need to be said about this:
1.	First of all, one may wonder what continuity for representation operators actually means.
This can be clarified as follows: By assumption, G-representations are always on vector
spaces with topologies, and thus T has a topology. Furthermore, in Remark C.2 we clarified
the topology on HomK(Vin, Vout). Then, being continuous just means, as always, to be
continuous with respect to the topologies of these two spaces.
44
Published as a conference paper at ICLR 2021
2.	The second remark is that this apparent difference in the requirement of continuity for
steerable kernels and representation operators is actually non-existent. This is explained by
the following Proposition which says that steerable kernels are automatically continuous.
Note that this is not true for steerable kernels that are defined on the domain Rd - in that
case, continuity is only guaranteed when restricting to orbits.
Proposition C.5. Let K : X → HomK (Vin , Vout ) be a steerable kernel. Then K is continuous.
Proof. For brevity, denote V := HomK(Vin,V0ut) and P := ρHom. Let x* ∈ X be any point
and Gχ* the stabilizer corresponding to the action of G on X. Remember the homeomorphism
φ : G/H → X, [g] → gx* from Lemma B.21. Since this is a homeomorphism, the kernel K is
continuous if and only if the composition K ◦夕 is continuous, since then K = (K ◦夕)◦夕-1 is a
composition of continuous functions. Thus, We evaluate K ◦夕：
(K ◦ ψ)([g∖) = KWagD) = K (gx*) = P(O)(K (x*)),
Where in the last step We have used the equivariance of K. Thus, if We set v* := K(x*) ∈ V, then
we obtain the simple relation (K ◦夕)([g]) = ρ(g)(v*). This is by definition just the unique map on
the quotient, G/H → V, coming from Pv* : G → V, g 7→ P(g)(v*). This last map is continuous
by definition of a linear representation. The universal property of quotients Proposition F.12 then
shows that K ◦夕 is continuous as well, and so we are done. All of this is visualized in the following
commutative diagram, where q : G → G/H, g 7→ [g] is the canonical projection：
G/H
□
Thus, the only difference between steerable kernels and representation operators is indeed the lin-
earity. We now look at special representation operators that play the main role in this work：
Definition C.6 (Kernel Operator). Let Pin : G → GL(Vin) and Pout : G → GL(Vout) be finite-
dimensional G-representations. Let λ : G → U(L2K (X)) be the standard unitary representation on
the space of square-integrable functions ofa homogeneous space X, given, as in Section B.1.3, by
[x(g)Q)MgO) = HgTgO)∙
A kernel operator is a representation operator K : L2K(X) → HomK(Vin, Vout). We denote the
space of these by
HomG,K(L2K(X), HomK(Vin, Vout))
= K : L2K(X) → HomK(Vin, Vout) | K is an intertwiner .
Notably, kernel operators are K-linear in their input.
C.1.5 Formulation of the Correspondence between Steerable Kernels and
Kernel Operators
The following Theorem lies at the heart of our investigations and establishes that steerable kernels
can be considered as kernel operators, which we defined as special representation operators. More
precisely, we will give an explicit isomorphism between the space of steerable kernels and the space
of kernel operators.
We shortly explain why the theorem is useful. First of all, using a Wigner-Eckart theorem for
kernel operators that we prove in Theorem D.13, one can explicitly describe a basis B of the space
of kernel operators HomG,K(L2K(X), HomK(Vin, Vout)). Then, since we have an isomorphism of
vector spaces to the space of steerable kernels, one can “carry over” this basis to a basis for the space
of steerable kernels, namely HomG (X, HomK (Vin, Vout)). This basis will then have a convenient
explicit form that we establish in Theorem D.16 and is exactly what we need in order to parameterize
an equivariant neural network layer. We now come to a precise formulation of the theorem：
45
Published as a conference paper at ICLR 2021
Theorem C.7 (Kernel-Operator-Correspondence). Let ρin : G → GL(Vin) and ρout : G →
GL(Vout) be finite-dimensional G-representations and X be a homogeneous space of G. Then
there is an isomorphism
C)
HomG (X, HomK(Vin, Vout))
HomG,K(L2K(X), HomK(Vin, Vout))
G)IX
between the space of steerable kernels on the left and the space of kernel operators on the right. The
two maps are defined as follows:
1. For a steerable kernel K : X →
HomK(Vin, Vout) is given by
HomK (Vin, Vout), the extension Kb : L2K (X) →
Kb(f)
:=	f (x)K (x)dx.
X
2. For a kernel operator K : L2K (X)
HomK(Vin, Vout) is given by
→ HomK(Vin, Vout), the restriction K|X : X →
K|X(x) := lim K(δU).
Hereby, Ux is the directed set of open neighborhoods of x, see Example F.27. δU : X → K
is the approximated Dirac delta function with δu (y) = μU if y ∈ U and δu (y) = 0, else.
The limit is a limit of nets as in Definition F.29.
This theorem requires some explanation. First of all, K is supposed to be a kernel operator, i.e., a
map L2K(X) → HomK(Vin, Vout). Thus, Kb(f) should be a linear function Vin → Vout. The formal
expression of it can indeed be considered as such:
Kb(f) =	f (x)K (x)dx : vin 7→	f(x) [K(x)] (vin)dx ∈ Vout.
(16)
Due to the continuity of K proven in Proposition C.518 and the integrability of f, the function
X → Vout, x 7→ f(x) [K(x)] (vin) is also integrable, meaning the expression in Eq. (16) can be
evaluated. This explains the meaning of the map (∙) m Theorem C.7.
For the map (∙)∣χ in the other direction, We want to shortly explain the intuitions in a more informal
way. For this, we consider Dirac delta functions δx for x ∈ X. Such a “function” δx : X → K
for a point x ∈ X can be imagined as a function taking value infinity at x and zero elsewhere. It
is characterized by the property that X δx(x0)f(x0)dx0 = f(x) for any function f ∈ L2K(X). We
think of δx as being a function in L2K(X), even though technically, it is not in this space. This is
since ∞ ∈/ K.
Now, informally, we can think of the limit K|X (x) = limU ∈Ux K(δU) as being given by K(δx),
the value that K takes at the Dirac delta function δx . This is since the limit of nets progressively
“shrinks down” the open neighborhood U of x. Of course, K(δx) is not really well-defined since
δx ∈/ L2K(X), but we can pretend that it is for gaining intuitions.
Now that we have understood the formulation of the theorem, we might wonder, why should such
a theorem be true? A first intuition comes from an analogy with linear algebra: namely, assume B
is a basis of a K-vector space V and W any other vector space. Then linear maps f : V → W
are in one-to-one correspondence with (not assumed to be linear) functions f : B → W, and this
isomorphism is given by restriction and linear extension:
C)
-------f
Hom(B, W)	HomK(V,W).
_____..
G)IB
18This means that all matrix elements of K(x) for chosen bases of Vin and Vout are continuous.
46
Published as a conference paper at ICLR 2021
Thus, we can think of the homogeneous space X as a “continuous basis” of the space of square-
integrable functions. Sums are then replaced by integrals, and evaluations at a basis element by
evaluations at Dirac delta functions of elements in X .
For the actual proof of Theorem C.7, informally, one direction seems pretty clear from the properties
of the Dirac delta:
Kb X (x) = Kb (δx) =	δx (x0)K (x0)dx0 = K (x).
XX
But the other direction is less obvious: it seems like the space of kernel operators is considerably
larger than the space of steerable kernels, since kernel operators are defined on a larger space. There-
fore it is hard to believe that the construction is also inverse in the other direction. However, it pays
off to ponder a bit more over what the Dirac delta construction does: Basically, we “embed” X
into L2K (X) by means of the Dirac delta functions, i.e., x 7→ δx and, as such, view X as a subset
of L2K (X) (albeit a subset that is only in approximation in that space). Steerable kernels are then
“partial” kernel operators in the sense that they are only defined on this subset X ⊆ L2K (X). What
then needs to be understood is why there is only one unique extension of each steerable kernel K to
a kernel operator K on the whole of L2K(X): if this is understood, then the space of kernel operators
cannot be larger than the space of steerable kernels. And indeed, if there is an extension of K to K
on L2K(X), it has to be unique: each f ∈ L2K(X) can be approximated by finite linear combinations
of scaled indicator functions. Then by linearity of the kernel operator K, we can evaluate K(f) by
knowing K(δU) for scaled indicator functions δU on small measurable sets U. And these approxi-
mate K(x) = K(δx) for x ∈ U arbitrarily well by construction. This determines the behavior of K.
The details of all of this can be found in the next section.
C.2 A Proof of the Correspondence between Steerable Kernels and Kernel
Operators
Here, we give a step-by-step proof of Theorem C.7. The details of this investigation will not be
needed later, and so a reader who is mainly interested in the applications to steerable CNNs can
safely skip reading this section and go on reading Chapter D.
C.2. 1 A Reduction to Unitary Irreducible Representations
In this section, we make the proof more manageable by reducing HomK (Vin, Vout) to an irre-
ducible representation. First, remember that Proposition B.20 shows that there is a scalar product
on HomK (Vin , Vout) such that it’s Hom-representation becomes unitary. Since all norms on finite-
dimensional spaces are equivalent, as is well known, this will not change the topology. Then, we can
decompose HomK(Vin, Vout) into an orthogonal direct sum of irreducible unitary representations by
Proposition B.38. Let Homκ(%n, VoUt) = Ln=ι Vi be SUch a decomposition. We get canonical19
isomorphisms
n
HOmG(X, Homκ(Vin,Vout)) = M HOmG(XM)
i=1
and
n
HomG,K(LK(X), HomK(¾n, Vout)) = MM HomG,K(LK(X), Vi).
i=1
ThUs, we can show Theorem C.7 by showing it for irredUcible Unitary representations instead of
HomK(Vin, Vout). Overall, we have redUced oUr Theorem to the following, simpler statement:
Theorem C.8 (Kernel-Operator-Correspondence, Restated). Let ρ : G → U(V ) be an irreducible
unitary representation and X a homogeneous space of G. Then there is an isomorphism
C)
HomG(X, V )	HomG,K(L2K(X),V )
G)IX
19“Canonical” once the decompositions into irredUcible representations is already chosen.
47
Published as a conference paper at ICLR 2021
1 ■ 1	■	■	/■ II	/■	_ ττ	/ TT τ τ∖	, τ≥∕ r∖	r c( ∖ τ∕/	∖ 7	Ir IX' 一
which is given as follows: for K ∈ HomG (X, V ) we set K(f) = X f (x)K (x)dx and for K ∈
HomG,K (L2K (X), V ) we set K|X (x) = limU ∈Ux K(δU), with δU being an approximated Dirac
delta function as before.
From now on, we assume that X and ρ : G → U(V ) is fixed as in the formulation of Theorem C.8.
—
C.2.2 WELL-DEFINEDNESS OF (∙)
ɪ .	___ CC EI r , ∙	7^∖- TT	/ TT τ τ∖	ττ	/ r 9 / ττ∖ τ λ∖ ■ ιι ι	ι ■ r
Lemma C.9. The function (∙) : HomG(X,V) → HomG,κ(LK(X), V) is well-defined, i.e.: for
an equivariant function K : X → V, the function Kb : L2K(X) → V is linear, equivariant and
continuous.
Proof. Linearity of Kb is clear. Equivariance can be proven using the equivariance of K and the left
invariance of the Haar measure on the homogeneous space X :
Kb (λ(g)f) =	(λ(g)f)(x)K (x)dx
X
=f f(g-1∙x)K(x)dx
X
=f f(x)K(g ∙ x)dx
X
=	f(x) [ρ(g) (K(x))] dx
X
ρ(g)
f (x)K (x)dx
X
ρ(g) Kb (f) .
The action by ρ(g) could be put out of the integral since ρ(g) it is linear and continuous, and since
integrals can be approximated by finite sums.
Now about continuity: By Proposition F.18, we only need to show continuity in 0. Thus, let (fk)k
be a sequence of functions fk ∈ L2K(X) with limk→∞ kfk kL2 = 0. Then we obtain
kKb(fk)kV
fk (x)K (x)dx
V
≤ I |fk(x)| ∙ kK(x)kvdx
X
≤ maX ∣∣K(x0)kv ∙ / ∣fk(x)∣dx,
xX
where the continuity of K proven in Proposition C.5 was used.20 For the right expression, using the
Cauchy-Schwarz inequality Proposition F.34 we obtain
/ ∣fk(x)∣dx = / ∣fk(x)∣∙ 1dx
= |h|fk | | 1i|
≤ kfkIIl2 ∙ ll1kL2
= ∣fk ∣L2.
C	11	∙ ∕' 1 ∙	Wf Il	Cj	1 ∙	Il T≥∕ P ∖ Il	C	11	1 ∙	1	J J
So, overall, if limk→∞ kfk kL2 = 0, then limk→∞ kK(fk)kV = 0 as well, which proves continuity.
□
20since kKk is continuous on X, which is compact by Proposition F.8 as an image of the compact group G,
it has a maximum by Corollary F.25.
48
Published as a conference paper at ICLR 2021
C.2.3 WELL-DEFINEDNESS OF (∙)∣χ
While it is clear that the limit limU∈Ux K(δU) from Theorem C.8 is unique if it exists (Conway,
2014), it is somewhat unclear why it exists in the first place. For this, we need to better understand
the properties of the (approximated) Dirac delta. The most important one is the following, which
we hinted at already in the intuitions we gave before this section: basically, Dirac deltas help for
evaluating continuous functions at specific points:
Lemma C.10. For each x ∈ X and Y : X → K continuous we have limU ∈Ux hδU |Y i = Y (x).
Proof. We have
I hδu |Y i-Y (x)∣
(Y(x0) - Y (x))dx0
Y (x0)dx0 — /	: Y (x)dx0
JU μ(U)
δu(x0)Y(x0)dx0 — μ(U) ∙ ɪ Y(x)
μ(U)
≤ L μ1u)IY(XO)- Y(X)I dx0.
Let > 0. Since Y is continuous in X, there is U ∈ Ux such that Y(X0) ∈ B(Y(X)) for all X0 ∈ U
or, equivalently, IY(X0) — Y (X)I < . Thus, for all U ⊇ U, i.e., all U ≤ U in Ux we obtain
i hδuIY i- Y(X) 1 ≤ ( μ(U)IY(XO)- Y (X)IdX0
≤ ZU μ1u) edX0
=〜μ(u) ∙ μ1u)
=
and consequently limU∈Ux hδUIYi = Y (X).
□
Before we can show the well-definedness of KIX, we first want to get a better description of K. For
this, recall from the Peter-Weyl theorem that L2K(X) = Lcl∈Gb Lim=l1 Vli. With this at our disposal,
we can formulate the following Lemma on the form of intertwiners on L2K(X):
Lemma C.11. Let K : L2K (X) → V be an intertwiner. Let l ∈ Gb be the unique index such that
V = Vli for all i = 1,..., m√. Let Yln, n = 1,..., di be an orthonormal basis of Vli where
dl = dim(Vl ). Then
K(f) = Xml Xdl hYlni If i K(Ylni)
i=1	n=1
for all f ∈ L2K(X).
Proof. We can write f ∈ L2K (X) according to the discussion after Definition F.40 as
f = Xl0∈Gb Xim=l10 X[nl0=]1hYln0iIfiYln0i.
Note that KIVl0i : Vl0i → V is an intertwiner as well, and so by Schur’s Lemma B.29 itis necessarily
zero unless l0 = l is the unique index such that Vli = V. Due to its continuity and linearity, K
commutes with infinite sums and we obtain
K(f) = Xl0∈Gb Xim=l10 X[nl0=]1hYln0iIfiK(Yln0i)
Xm 0	[l ]
l0∈Gb Xi=l1 Xn=1 hYln0iIfiKIVl0i (Yln0i)
= Xim=l1 Xdl=1 hYlni IfiK(Ylni).
□
49
Published as a conference paper at ICLR 2021
Corollary C.12. We have K∣χ (x) = Pm=I P：l=i Xn(X)K(匕n) .In particular, the defining limit
exists.
Proof. Since the Ylni are by the proof of the Peter-Weyl theorem in the finite-dimensional space El
spanned by matrix coefficients of the irreducible representation ρl : G → U(Vl ) and since these
matrix coefficients are continuous by Remark B.25, the Ylni are as finite linear combinations of them
also continuous functions. Thus, from Lemma C.10 and C.11 together we obtain:
K|X(x) = lim K (δU)
U ∈Ux
=Iim Xml1 XdlIh琦∣δuiK(Yn)
U∈Ux	i=1	n=1
=Xml1 XdIJMm M Mi] K(Kn)
i=1	n=1 U∈Ux
=x：i Xn1=1 EH).
The complex conjugation came into play since the order in the scalar product is swapped compared
to Lemma C.10.	□
Thus, since we now know that K|X as a function makes sense, we can finally prove the well-
definedness of K 7→ K|X ,
Lemma C.13. Thefunction (∙)∣χ : HomG,κ(LK(X), V) → HomG(X, V) is well-defined； that is:
for a linear, equivariant and continuous function K : L2K(X) → V, the restriction K|X : X → V
is equivariant.
Proof. We have
K∣X(g ∙x) = Jim K (δu)
U ∈Ugx
= lim K (δgU)
U∈Ux	gU
= lim K (λ(g)δU)
U ∈Ux
= lim ρ(g) [K (δU)]
U ∈Ux
= ρ(g) lim K(δU)
U ∈Ux
= ρ(g) [K|X (x)] ,
where the steps are justified as follows: The first step is just the definition of K|X . The second
step uses that the open neighborhood of gx are precisely the g-translated open neighborhoods of x
since g : X → X is a homeomorphism. The third step is easy to check. The fourth step uses the
equivariance of K. The fifth step uses the continuity of ρ(g), which follows since ρ(g) is a unitary
transformation. The last step is again the definition of K∣χ.	□
C.2.4 (∙) AND (∙)∣χ ARE INVERSE TO EACH OTHER
We can now finish the proof of Theorem C.8 and consequently of Theorem C.7:
ProofofTheorem C.8. After all the preparation, We only need to still show that the maps (∙) and
(∙)∣x are inverse to each other. For KIX = K, i.e., the injectivity of the function K → K and
surjectivity of the function K 7→ K|X , we compute:
Kb IIX (x) = lim Kb (δU)
U ∈Ux
= lim	δU (x0)K (x0)dx0
U∈Ux X
= K (x).
50
Published as a conference paper at ICLR 2021
The last step follows from Lemma C.10 by identifying V = Vl with Kdl and viewing K as consisting
of continuous component functions Kn : X → K, n ∈ {1, . . . , dl}. The continuity ofK was shown
in Proposition C.5.
For showing K|X = K we do a computation using the description of K from Lemma C.11 and the
description of K|X from Corollary C.12:
Kd|X(f) =	f(x)K|X(x)dx
X
=ZX f (χ)( XmlI Xn=I EKdl))dχ
=XmlI xnl=1 UX f (χ)Yw>)K(琦)
= Xim=l1 Xdnl=1 hYlni |fiK(Ylni )
= K(f).
This finally finishes the proof.
□
D	A Wigner-Eckart Theorem for Steerable Kernels of General
Compact Groups
In Chapter C we have seen the most important theoretical insight of this work: steerable kernels on
a homogeneous space X correspond one-to-one to kernel operators (certain representation opera-
tors) on the space of square-integrable functions L2K(X). In this chapter, we will develop the most
important consequence of this correspondence: a Wigner-Eckart theorem for steerable kernels and
consequently a description of a basis for steerable kernels. This works for both fields R and C, for
an arbitrary compact group G, an arbitrary homogeneous space X and arbitrary finite-dimensional
input- and output fields. Additionally, it covers the general theory of equivariant CNNs on homoge-
neous spaces developed in (Cohen et al., 2019b).
In Section D.1 we will work towards formulating the most important theorems. Since these will
involve tensor products, we will start with defining and studying tensor products of pre-Hilbert
spaces and (unitary) representations. Afterward, we will define the Clebsch-Gordan coefficients,
which relate a tensor product of irreducible representations to the irreducible subrepresentations of
this tensor product. This will lead to a formulation of the original Wigner-Eckart theorem similar
as it appears in quantum mechanics, including a proof. The original Wigner-Eckart theorem is
a statement about representation operators on irreducible representations. However, we consider
kernel operators on L2K(X) which is not irreducible. Also, different from the original Theorem, we
also consider representations over the real numbers, which leads to a replacement of reduced matrix
elements by endomorphisms. Therefore we then formulate a generalization of the original theorem.
Then, using the correspondence between kernel operators and steerable kernels from Theorem C.7,
we can transform this into a Wigner-Eckart theorem for steerable kernels and ultimately a statement
about a basis of the space of steerable kernels. We conclude with some remarks about how to use
the basis kernels in practice.
Afterward, in Section D.2, we give the remaining proof of the Wigner-Eckart theorem for kernel
operators, which we omit in the section before. First, we reduce the statement to the dense subspace
of L2K(X) which is a direct sum of all irreducible subrepresentations. We then describe a correspon-
dence between representation operators and intertwiners on a certain tensor product, the so-called
hom-tensor adjunction. Finally, we finish with the full proof of the Wigner-Eckart theorem.
As always, let K be either of the two fields R and C and G be a compact topological group. X is
any homogeneous space of G.
51
Published as a conference paper at ICLR 2021
D.1 A Wigner-Eckart Theorem for Steerable Kernels and their Kernel Bases
D.1.1 Tensor Products of pre-Hilbert Spaces and Unitary Representations
In order to state the Wigner-Eckart theorem, we need the notion of representations on tensor prod-
ucts. This is defined similarly to Hom-representations, see Definition C.1. For this, we first need to
discuss the notion of a tensor product of vector spaces:
Definition D.1 (Tensor Product). Let V and V0 be two vector spaces over K. Then V 0 V0, the
tensor product of V and V0, is a vector space over K with the following properties:
1.	There is a bilinear function 0 : V × V0 → V 0 V0, (v, v0) 7→ v 0 v0. V 0 V0 is generated
by elements of the form v 0 v0 .
2.	It has the following universal property: for any bilinear function β : V X V0 → P into a
vector space P, there is a unique linear function β : V 0 V0 → P given on elements of the
form V 0 v0 by β(v 0 v0) = β(v, v0). In other words, the following diagram commutes:
V	× V 0 -ɪ-s- P
领
V	0 V 0
3.	If V and V0 are finite-dimensional with bases{v1, . . . , vn} ⊆ V and {v10 , . . . , vm0 } ⊆ V0,
then {vi 0 vj0 }i,j ⊆ V 0 V0 is a basis of V 0 V0. In particular, the dimension of V 0 V0 is
n ∙ m.
Property 3 follows from 1 and 2 and would therefore not necessarily be needed in the definition. The
explicit construction of tensor products shall not matter for our purposes since the properties above
characterize itup to isomorphism. The second property stated in the definition is of large importance
since it tells us how we can define linear functions on V0 V0: ifwe have a guess for such a function
夕：V 0 V0 → P (of which we don,t yet know whether its “assignment rule” is well-defined), then
wejust needto test whether the function 0 : V × V0 → P given by 0(v, v0):二夕(V 0 v0) is bilinear.
If it is, then φ is a well-defined linear function. We will use this soon in the following context:
Assume f : V → V and g : V0 → V0 are linear functions. Then we would like to define a function
f 0 g : V 0 V0 → V 0 V0 by (f 0 g)(V 0 V0) = f(V) 0 g(V0). For this to work, we need to test
whether the assignment (V, V0) 7→ f(V) 0 g(V0) is a bilinear function V × V0 → V 0 V0. Clearly,
it is, and so f 0 g is a well-defined linear function! We use this in Definition D.3 in order to define
the tensor product of representations.
Since we actually deal with Hilbert spaces most of the time, we would like to build tensor products
of Hilbert spaces. However, their definition is not completely straightforward since one cannot just
take the tensor product of the underlying vector spaces but needs to additionally build the completion
of the resulting space (Kadison & Ringrose, 1997). Since this complicates the considerations related
to a correspondence we later formulate in Proposition D.23, we go a slightly different route. Instead
of describing the tensor product of Hilbert spaces, we describe the tensor product of pre-Hilbert
spaces, which does not require a completion step. Recall from Definition F.3 that a pre-Hilbert
space is basically a Hilbert space that is not necessarily complete.
Definition D.2 (Tensor Product of pre-Hilbert spaces). Let V, V0 be two pre-Hilbert spaces with
scalar products(•1•)and〈.卜)0. Then the tensor product of vector spaces V 0 V0 can be made into a
pre-Hilbert space using the scalar product which is given on generators by
(V 0 v0|w 0 w0i0 := {v|w)∙ hv0∣w0)0.
This is then anti-linearly extended in the first (i.e., “Bra”), and linearly extended in the second (i.e.,
“Ket”) component.
One can show that this makes V 0 V0 a pre-Hilbert space. For simplicity, we will from now on not
notationally distinguish the different scalar products involved. With this preparation, we can come
to the notion of tensor product representations:
52
Published as a conference paper at ICLR 2021
Definition D.3 (Tensor Product Representation). Let ρ : G → GL(V ) and ρ0 : G → GL(V 0)
be two linear representations, where V and V 0 are pre-Hilbert spaces. Then on the tensor product
V 0 V0 of Pre-Hilbert spaces, We can define the tensor product representation P 0 ρ0 by
P 0 P : G → GL(V 0 VO), g → ρ(g) 0 p(g),
Where ρ(g ) 0 P0(g) : V 0 V0 → V 0 V0 is given on generators by
(P(g) 0 P0(g)) (v0v0) := P(g)(v) 0 P0(g)(v0).
Lemma D.4. The map P 0 P0 : G → GL(V 0 V0) defined above is a linear representation.
Proof. Clearly, each (P 0 P0)(g) is linear and We have (P 0P0)(gg0) = (P0P0)(g) ◦ (P0 P0)(g0).
Thus, for shoWing that it is a linear representation, We need to shoW it is continuous. Assume We
already knew continuity of all maps (P 0 ρ0)v0v : G → V 0 V0, g → [(ρ 0 ρ0)(g)] (V 0 v0). Then
for linear combinations ξ = Pin=1 λi (vi 0 vi0) We obtain using the linearity of (P 0 P0)(g):
(P 0 P0)ξ(g) = (P 0 P0)(g)(ξ)
= (P 0 P0)(g)	Xin=1 λi (vi 0vi0)
= Xin=1 λi(P 0 P0)(g)(vi 0vi0)
= (Xi=1λi(ρ0 P…)(g).
Now, since scalar multiplication and addition in topological vector spaces is continuous, and since
pre-Hilbert spaces are special topological vector spaces, the continuity of (P 0 P0)ξ follows from
that of all (P 0 ρ0产v'.
What,s left is proving the continuity of functions of the form (P 0 P0)v怎v. For notational simplicity,
write f = Pv : G → V and f0 : P0v0, which are both continuous since P and P0 are linear represen-
tations. We want to show that also f 0 f0 : G → V 0 V0 is continuous. We can test continuity in
each point g0 ∈ G separately by Definition F.6. For each g ∈ G we then obtain, with Re being the
real part of a complex number:
k(f0f0)(g)-(f0f0)(g0)k2
=	[f(g) 0 f0(g)	-	f(g)	0	f0(g0)]	+ [f(g) 0 f0(g0)	-	f(g0)	0	f0(g0)]	2
=	f(g) 0	[f0(g)	-	f0(g0)] + [f(g) - f(g0)] 0 f0(g0)2
=	f(g) 0	[f0(g)	-	f0(g0)] 2 + [f(g) - f(g0)] 0 f0(g0)2
+2ReDf(g)0[f0(g)-f0(g0)] [f(g) - f(g0)] 0 f0(g0)E
=kf (g)k2 ∙kf0(g) - f0(go)k2 + kf (g) - f (go)k2 ∙kf0(go)k2
+ 2Re (hf(g)∣f(g) - f(go)i ∙hf0(g) - f (go)∣f0(go)i ).
All in all we see the following: Ifg is sufficiently close to g0, then due to the continuity off, f0, the
scalar product, multiplication in K and the real part, k(f 0 f 0)(g) - (f 0 f0)(g0)k2 gets arbitrarily
close to 0. This shows the continuity of f 0 f 0 and we are done.	□
Lemma D.5. Let P : G → U(V) and P0 : G → U(V0) be unitary representations on pre-Hilbert
spaces. Then also P 0 P0 : G → U(V 0 V0) is a well-defined unitary representation.
Proof. According to Lemma D.4 we only need to check whether all P(g) 0 P0(g) are unitary trans-
formations. This follows immediately from the unitarity of P(g) and P0(g).	□
53
Published as a conference paper at ICLR 2021
D.1.2 The Clebsch-Gordan Coefficients and the Original Wigner-Eckart
Theorem
In this section, we describe the Clebsch-Gordan coefficients and the original Wigner-Eckart theorem.
Except for the proof, we roughly follow Jeevanjee (2011). For the proof, we follow the more general
treatment in Agrawala (1980).21
For our aims, let ρj : G → U(Vj) and ρl : G → U(Vl) be representatives of isomorphism classes of
irreducible unitary representations.22 Then consider their tensor product representation
Pj 0 Pl : G → U(Vj 0 W
which is again a unitary representation according to Lemma D.5. If Vj and Vl are of dimension dj
and dl, respectively, then Vj 0 ^½ is of dimension dj ∙ dl. Since it is a finite-dimensional unitary rep-
resentation, it is itself an orthogonal direct sum of finitely many irreducible unitary representations
by Proposition B.38:
[J(jl)]
Vj0 Vl = M M VJ.
J∈Gb s=1
Here Gb is, as before, the set of isomorphism classes of irreducible unitary representations and [J (jl)]
is the number of times that PJ : G → U(VJ) appears in the direct sum decomposition of Vj 0 Vl.
Note that for most J we have [J (jl)] = 0, and for some J we may have [J (j l)] > 1, see Section
E.2, where it turns out that P0 is contained twice in Pm 0 Pm .
Now, choose - once and for all - orthonormal bases of all involved irreps, which exists according to
Proposition F.41:
{Yjm∣ m =1,...,dj} ⊆ Vj,
{匕n | n =1,...,dl} ⊆ V1,
{YJM | M = 1, . . . , dJ } ⊆ VJ .
This notation is supposed to remind about spherical harmonics since they form a basis for irreducible
representations of the group SO(3). But as mentioned in the footnote, we do not consider these basis
elements to be functions here.
Furthermore, let ls : VJ → Vj 0 Vl be the linear, equivariant and isometric (i.e., scalar product
preserving) embeddings that correspond to the direct sum decomposition of Vj 0Vl into irreps, where
s ranges in {1, . . . , [J(jl)]}. With this in mind, we can define the Clebsch-Gordan coefficients:
Definition D.6 (Clebsch-Gordan Coefficients). The Clebsch-Gordan Coefficients are given by
hs,JM|jm;lni :=ls(YJM)Yjm0Yln.
Note that in the literature, people usually only consider Clebsch-Gordan coefficients of the specific
groups SO(3), SU(2), SU(3) or similar groups appearing in physics. Also note that in the physics
context, there is only one linear, equivariant, isometric embedding ls, which follows directly from
Schur’s Lemma D.8. Therefore, it is sensible that the embedding is usually not part of the notation of
these coefficients. In our case, however, when considering real representations, there can be several
such embeddings ls . This happens if the endomorphism space of VJ is nontrivial. An example is
given by the two-dimensional irreducible representations of SO(2) over the real numbers which we
discuss in Section E.2. Since, however, we do not want to depart too much from the notation usually
considered in physics, we also omit the embedding from the notation. The index s however needs
to be present in order to index the possibly different appearances of VJ in Vj 0 Vl.
With this preparation, we can explain the Wigner-Eckart theorem the way it is usually considered in
physics, as a prelude for the generalization that we consider in the next section.
21It is more general in that it considers arbitrary groups and the situation that the considered irreducible
representation appears several times in a tensor product representation instead of just once.
22Those are a priori not assumed to be embedded in a space of square-integrable functions. For such embed-
ded representations, we write Vji instead.
54
Published as a conference paper at ICLR 2021
In this (and only this!) section, we assume that our field is C, since this is the case considered
in physics. The Wigner-Eckart theorem aims to obtain a description for all possible representa-
tion operators K : Vj → HomC (Vl , VJ). This is, for example, useful for describing state transi-
tions in the electrons of hydrogen atoms. To motivate the generalization in the next section, we
shortly explain the derivation: We can consider the equivalent function K : Vj 0 ^½ → VJ given
by K(vj 0 vl) := [K(vj)] (vl) on the tensor product. As one can compute, and as We Will see in
more generality in Proposition D.23, K : Vj 0 Vl → VJ is an intertWiner, Where on the left We
consider the tensor product representation. We assume, as is the case for G = SO(3) or G = SU(2)
for usual applications in physics, that VJ is exactly once a direct summand of Vj 0 Vl . Then, since
by Schur’s Lemma B.29 there cannot be nontrivial equivariant linear maps betWeen nonisomorphic
irreps, K restricted to each direct summand of Vj 0 Vl vanishes, except the one isomorphic to VJ.
More precisely, assume that
Vj 0 Vl = Vj ㊉ M Vlo
l0
is a decomposition of Vj 0 Vl into copies of irreducible representations, Where each Vl0 is noniso-
morphic to VJ . Then the information contained in K is equal to the information contained in the
restriction K |叮：VJ → VJ. Since it is an intertwiner from a representation to itself, it deserves a
special name. We state the folloWing definition for arbitrary K ∈ {R, C}, since it Will be of crucial
importance in our generalization of the Wigner-Eckart theorem:
Definition D.7 (Endomorphism). Let ρ : G → GL(V ) be a linear representation. An intertwiner
from V to V is called endomorphism. The vector space of endomorphisms is written as
EndG,K(V) := HomG,K(V, V).
A version of Schur’s lemma gives a simple description for endomorphisms of irreducible represen-
tations in the case that the underlying field is the complex numbers C. It makes use of the property
of the complex numbers to be algebraically closed:
Lemma D.8 (Schur’s Lemma). Let ρ : G → GL(V ) be an irreducible representation. If the
underlying field is the complex numbers C, then the set of endomorphisms, i.e., intertwiners from V
to V , only consists of the complex multiples of the identity:
EndG,c(V) = {c ∙ idv | C ∈ C} = C.
Proof. See Jeevanjee (2011).	口
This means that K |vj = C ∙ idvj for some complex number C ∈ C. Now if we let P : Vj 0 ^½ → VJ
be the projection corresponding to the direct sum decomposition of Vj 0 Vl, then we obtain
K = K|vj ◦ p =(C ∙ idvj) ◦ p = c ∙ p.
That is, we have just found out that one complex number, C, is able to completely characterize K
and consequently K! This is basically already the Wigner-Eckart theorem. However, it is useful to
find a formulation that describes K with respect to bases of the different irreducible representations.
For this, we define matrix elements of representation operators. Before we come to the definition,
we introduce some notation: If f : V → V 0 is a linear continuous map between Hilbert spaces, we
set
hy|f|xi := hy|f(x)i
for each x ∈ V and y ∈ V 0 . The symmetry in this notation is supposed to remind about the fact that
f has an adjoint, see Definition F.42, and thus can be applied to y just as well as to x, but we will
not make use of this fact.
Definition D.9 (Matrix Element). Let T , Vl and VJ be unitary representations with orthonormal
bases {Yjm} ⊆ T (with j possibly also varying), {Yln} ⊆ Vl and {YJM} ⊆ VJ, respectively. Let
K : T → HomK(Vl, VJ) be a representation operator. Then it’s matrix elements are given by the
scalars
JMKjmln :=YJMK(Yjm)Yln.
In the same way, if f : Vl → VJ is any linear (not necessarily equivariant) map, then its matrix
elements are given by the scalars
hJM|f|lni :=YJMfYln.
55
Published as a conference paper at ICLR 2021
Remark D.10. We shortly explain this term. Usually, in linear algebra, one has to do with linear
functions f : V → V 0 between vector spaces carrying bases {vj} ⊆ V and {vi0} ⊆ V 0. For each
basis element vj ∈ V one can then find coefficients Aij ∈ K such that
f(vj) = Xi Aijvi0.
The Aij are called the matrix elements of f and characterize f completely. Now if the bases are
orthonormal bases as in Definition F.40, then the coefficients are given by
Aij = hvi0|f(vj)i = hvi0|f|vji .
In a similar way we can understand the matrix elements of a representation operator, only that the
linear function itself depends on a chosen basis vector of Vj . As for linear functions, the matrix
elements of a representation operator completely characterize it.
One last remark: since in this section, VJ appears only once as a direct summand in Vj 0 ^½, we
omit the additional “quantum number” s in the notation for the Clebsch-Gordan coefficients. With
this preparation, we can formulate and prove the original version of the Wigner-Eckart theorem.
Remember that there is a unique complex number C such that K is given by K = c ∙ p fora projection
p : Vj 0 Vl → VJ. We now denote this by hJ kKkli := c.
Theorem D.11 (Wigner-Eckart Theorem). The matrix elements of the representation operator K :
Vj → HomC (Vl , VJ) are given by
(JM∖K,m∖ln) = hJ∣∣K∣∣l> ∙ jM\jm;ln),
with the JM jm; ln being the Clebsch-Gordan coefficients (which are independent from the rep-
resentation operator K).
Proof. Let i : VJ → Vj 0 Vl be the embedding corresponding to the direct sum decomposition of
Vj 0 Vl. It is an adjoint of the projection p : Vj 0 Vl → VJ according to the proof of Proposition
F.46. By what we’ve argued above, there exists some c ∈ C such that:
JM∖∖Kjm∖∖ln = YJM∖∖K(Yjm)∖∖Yln
=<γM∖K(γm 0 Yn)
=(γJM ∖c ∙ P(Ym 0 Yn))
=c <yM∖p(Ym 0 Yn))
=c V(YM )∖Yjm 0 Yn)
=hJkKkli ∙ JJM∖jm-ln).
As a short explanation: in the fifth step it was used that i and p are adjoint to each other, and
consequently, we move from considering the tensor product in VJ to that one in Vj 0 Vl. In the
last step, the definition of the Clebsch-Gordan coefficients was used, and additionally, the notation
hJ kKkli := c that we mentioned before the theorem. The index s is everywhere missing since VJ
appears only once in Vj 0 ^½. This finishes the proof.	□
Definition D.12 (Reduced Matrix Element). The unique number c = hJ kKkli ∈ C in this theo-
rem is called the reduced matrix element. To reiterate, it characterizes the representation operator
completely.
D.1.3 Reduction to Irreducible Unitary Representations
Let G be any compact group and X any homogeneous space of G. Before we state the Wigner-
Eckart Theorem for steerable kernels in the next section, we first want to explain why we can restrict
to the case of irreducible unitary input- and output representations. Our explanations are adapted
from Weiler & Cesa (2019).
Thus, let ρin : G → GL(Vin) and ρout : G → GL(Vout) be general finite-dimensional input- and
output representations. We consider the task of finding a basis for the space of steerable kernels
56
Published as a conference paper at ICLR 2021
HomG (X, HomK(Vin, Vout)). By Theorem B.20 and Proposition B.38, there are equivalences of
representations (i.e., linear isomorphisms that intertwine between the representations)
Qin : Vin → ㊉ Vμ,	QoUt : Vout → ㊉ VV,
μ∈Iin	ν∈Iout
where ρμ : G → U(Vμ) and PV : G → U(VV) are irreducible unitary representations. Both for
the input- and the output representation, the same irrep can appear several times, e.g., there can be
μ = μ such that ρμ = p*，. Now, notice that the map
ΦQout,Qin : HomG (x,Homκ (㊉ Vμ,㊉ VV)) → HomG(X,Homκ(Vin,VOut))
μ∈Iin	ν∈Iout
given for all x ∈ X by
ΦQout,Qin(K)(x) := Qo-u1t ◦ K(x) ◦ Qin
is clearly an isomorphism. Thus, once a basis for the first kernel space is known, we just need to
postcompose and precompose each basis kernel with Qo-u1t and Qin, respectively, in order to get a
basis for the space we actually care about. Furthermore, the map
Ψ ：㊉ ㊉ HomG(X,Homκ(Vμ,VV)) → HomG (x,Hοmκ(㊉ Vμ,㊉ VV))
given by
[Ψ((K ν")ν,μ)(x)]((Vμ)μ) ：= ( X K ""(幻(。“))∈ M 匕,
where X ∈ X and (vμ)μ ∈ Lμ∈ι.n Vμ are arbitrary, is also clearly an isomorphism. It expresses
that we can take a collection of steerable kernels (Kνμ)ν,μ and build with it a block-matrix, which
is steerable again, as can easily be checked. Accordingly, if we have basis kernels for a space
HomG (X, HomK(Vμ, VV)) for some μ, V, then we can, by applying Ψ, map itto block basis kernels
which are zero outside the block with indices V and μ. Overall, by doing this for all μ, ν, we thus
recover a full basis for the space HomG X, HomK Lμ∈I Vμ, LV∈I VV . By applying the
base change ΦQout,Qin from above, we thus get a basis for HomG (X, HomK(Vin, Vout)). In sum-
mary, knowing a basis of steerable kernels for irreducible unitary input- and output representations
gives us one for all finite-dimensional input- and output representations. Finally, note that the trans-
formation of basis kernels using ΦQout ,Qin and Ψ can be done in the network initialization process
and does not need to be performed in each forward pass.
D.1.4 The Wigner-Eckart Theorem for Steerable Kernels
Now that we have seen the Wigner-Eckart theorem in a version similar to how it usually appears in
physics, it is time to state the version which we will need in this work for applications in deep learn-
ing. The treatment is similar to the formulation in Agrawala (1980), which presents a generalization
of the Wigner-Eckart theorem to the case that VJ may appear several times as a direct summand
in the direct sum decomposition of the tensor product. However, this paper still only considers the
Wigner-Eckart theorem for the case of the complex numbers C. If we allow the real numbers as
well, we cannot be sure that endomorphisms of irreducible representations are just given by one
number. This is a complication we will deal with below by allowing matrix elements of general
endomorphisms. Furthermore, we will deal with topological considerations that did not play a role
in Agrawala (1980). And lastly, we transport the theorem over into the nonlinear realm of steerable
kernels.
As discussed in the last section, we can restrict the considerations to (representatives of isomor-
phism classes of) irreducible unitary input- and output representations. Thus, assume the input-
representation to be the irrep ρl : G → U(Vl) and the output-representation to be the irrep
ρJ : G → U(VJ). The idea is now that kernel operators K : L2K(X) → HomK (Vl , VJ) can be
described on each direct summand of the domain individually, and that on each of these summands,
arguments similar to those for the original Wigner-Eckart theorem apply.
57
Published as a conference paper at ICLR 2021
According to the Peter-Weyl Theorem B.22 the space L2K(X) has a dense subset which is a direct
sum of irreducible unitary representations:
mj
L2K(X) = MMVji.
j∈Gb i=1
Each Vji is, as a subrepresentation of L2K(X), isomorphic to Vj. Vj is itself not assumed to be
embedded in L2K(X).
For arbitrary j ∈ Gb, fix once and for all orthonormal bases {Yjmi } ⊆ Vji corresponding to the basis
{Yjm} of Vj-.23 Furthermore, assume that for all S = 1,..., [J(jl)], Pjis : Vji 0 Vl → VJ is a
projection which is an adjoint of the linear equivariant isometric embedding ljis : VJ → Vji 0 ^½.
This is assumed to be aligned with the embeddings VJ → Vj 0 Vl with respect to the isomorphisms
Vj = Vji that underlie the correspondence of basis elements Yjm 〜Ym. What this means is that
the Clebsch-Gordan coefficients with respect to all of these embeddings, for all i, are equal:
ljis(YJM)Yjmi 0Yln = hs,JM|jm;lni.
Now we state and prove the Wigner-Eckart theorem, which gives an explicit description of rep-
resentation operators K : L2K (X) → HomK(Vl, VJ) in terms of endomorphisms of VJ and then
transfers this statement over to a statement about steerable kernels K : X → HomK(Vl, VJ).
Before we state the theorem, we want to shortly explain what to expect: in the derivation of the
original Wigner-Eckart theorem in Section D.1.2, we saw that a kernel operator could be expressed
as K : Vj 0 Vl → VJ . This was in turn equal to K = c ◦ p for an endomorphism c : VJ → VJ and
the projection p corresponding to the appearance of VJ in the direct sum decomposition of Vj 0 Vl .
This time, however, VJ can be found often in L2K(X) 0 Vl, namely:
1.	For each isomorphism class of irreps j ∈ G,
2.	For each appearance i = 1, . . . , mj of the irrep Vj in L2K (X) and
3.	For each appearance s = 1, . . . , [J(jl)] of the irrep VJ in the tensor product representation
Vj 0 Vl. [J(jl)] can be zero, which means that j does not contribute.
We therefore expect K to be a whole sum of compositions of endomorphisms with projections, for
each combination of valid j, i and s. Furthermore, the specific structure of L2K (X) will be exploited
as well by using orthogonal projections from L2K (X) to summands Vji. Overall, we hope this
sufficiently motivates the theorem:
Theorem D.13 (Wigner-Eckart Theorem for Steerable Kernels). We state the theorem in three parts:
1.	(Basis-independent Wigner-Eckart for Kernel Operators) There is an isomorphism of vec-
tor spaces
mj [J (j l)]
Rep : MM M
EndG,K(VJ) → HomG,K(L2K(X),HomK(Vl,VJ))
j∈Gb i=1 s=1
which is given by
mj [J(jl)] dj
[ReP((Cjis)jiS)(P)] (Vl) =XXX X"• Cjis (Pjis(Ym 0 Vl))	(17)
j∈Gb i=1 s=1 m=1
where (Cjis)jis is a tuple of endomorphisms, P : X → K is any square-integrable function
and Vl ∈ Vl is any element.
2.	(Basis-independent Wigner-Eckart for Steerable Kernels) There is an isomorphism of vec-
tor spaces
mj [J (jl)]
GKer : MM M
EndG,K(VJ) → HomG(X, HomK(Vl, VJ))
j∈Gb i=1 s=1
23i is like an additional quantum number in physics.
58
Published as a conference paper at ICLR 2021
which is given by
mj [J(jl)] dj
[GKer((Cjis)jiS)(X)] (Vl) = XXX X hi,jmlxi ∙ Cjis (Pjis(Ym 乳 Vl))
j∈Gb i=1 s=1 m=1
where (Cjis)jis is a tuple of endomorphisms, x ∈ X is any point and Vl ∈ Vl is any
element. Here, hi, jm|xi := limU ∈Ux Yjmi δU , which is according to Proposition C.10
equal to Ym (x).
3.	(Basis-dependent Wigner-Eckart for Steerable Kernels) Let K = GKer((Cjis )jis ) be the
steerable kernel corresponding to the tuple of endomorphisms (Cjis )jis according to the
isomorphism above. Then the matrix elements of K(x) ∈ HomK (Vl, VJ) are explicitly
given by
hJM|K(x)|lni =
mj [J(jl)] dj	dJ
XXXXX (JM∣cjis∣JM'〉＜, JM0∣jm;ιn) ∙ (i, jm∣χ).
j ∈Gb i=1 s=1 m=1 M0=1
(18)
Remark D.14. Before we come to the proof, we have some remarks to make about this theorem:
1.	In line with the usual convention, we call the JM ∣Cjis ∣JM0 the generalized reduced
matrix elements of the representation operator K. Different from the situation in physics,
these can depend nontrivially on the specific basis indices M and M0. If the space of
endomorphisms is 1-dimensional, as is the case when considering representations over C,
then each Cjis is a diagonal matrix, meaning that it is characterized by only one complex
number, for simplicity with the same name Cjis. Then one has hJM∣cjis |JM0)= 5μμ0 ∙
Cjis and the sum over M0 disappears. What this means for the matrix form of basis kernels
of steerable CNNs will be discussed in Corollary D.17.
2.	The coefficients s, JM0 ∣j m; ln are as before the Clebsch-Gordan coefficients. Note that
the input x of K appears only in i, j m∣x . Those two parts of the right-hand side of the
formula are always the same, independent of the kernel K .
3.	The Clebsch-Gordan coefficients are traditionally defined with respect to isometric embed-
dings Ijis : VJ → Vj 0V^ since this makes them less ambiguous. However, we mention that
the property of being isometric is no requirement for the construction of Clebsch-Gordan
coefficients or the proof of the Wigner-Eckart theorem, being equivariant and linear is suffi-
cient. This then means that the copies ls (YJM) do not anymore form an orthonormal basis.
We will use this relaxation in the example in Section E.2, where we do not want to be
bothered with obtaining isometric embeddings.
4.	The names for the isomorphisms in the theorem are meant as follows: Rep is the map
that maps a tuple of endomorphisms to a kernel operator, which is a special representation
operator. GKer maps a tuple of endomorphisms to a G-steerable kernel. It is not meant as
a notation for a kernel in the sense of a nullspace in linear algebra.
5.	Furthermore, a reader with a background in abstract algebra may wonder why we build the
direct sum of spaces of endomorphisms instead of the direct product. The reason is that
a posteriori, it turns out that only finitely many j contribute nontrivially, and so the direct
sum is equal to the direct product. For a proof of the finiteness, see Remark D.18 below.
6.	As a last remark, we want to mention that part 1 of the theorem is not the most gen-
eral version we could do. We chose to formulate the Wigner-Eckart theorem for L2K(X)
specifically since this is the space we use it for. However, an appropriate isomorphism can
probably be formulated for any unitary representation instead ofL2K(X), only that we then
need to take care that we replace direct sums by direct products if the index sets on the left
side are infinite. Additionally, Vl and VJ could be replaced by arbitrary finite-dimensional
representations, and an appropriate adaptation of the theorem would apply. Whether Vl and
VJ could also be replaced by infinite-dimensional unitary representations would need to be
explored, but an extension to such a case seems possible.
59
Published as a conference paper at ICLR 2021
Proof of Theorem D.13. The proof of 1 will be done in Section D.2 since it requires some work.
However, the proofs of 2 and 3 are relatively straightforward once we believe 1 and so we do them
here:
From 1 we know that Rep is an isomorphism. Furthermore, from Theorem C.7 we know that
(∙)∣X : HomG,κ(LK(X),Homκ(%,VJ)) → HomG,κ(X,Homκ(%,VJ))
is an isomorphism as well, and this is given by K|X (x) := limU∈Ux K(δU), where we take the limit
over the directed set of open neighborhoods of x. We define the isomorphism GKer now simply as
the composition, i.e., GKer := 3|x ◦ Rep. This isomorphism is then explicitly given by:
[GKer((cjis)jis)(x)] (vl) = [Rep((cjis)jis)|X (x)] (vl)
= lim [Rep((cjis)jis)(δU)] (vl)
U ∈Ux
mj [J (j l)] dj
=U∈m XXX X (Yjm∣δu〉∙Cjis(Pjis(Ym㊈Vl))
x j∈Gb i=1 s=1 m=1
mj [J (jl)] dj
=XX X X him〈印1必〉]∙Cjis (Pjis(Ym区Vl))
j∈Gb i=1 s=1 m=1	x
mj [J(jl)] dj
=XXXX hi,jm∖χ) ∙ Cjis (Pjis(Ym 乳 Vl)).
j∈Gb i=1 s=1 m=1
This already proves 2. Now, in the following computation, we will use that Cjis ◦ Pjis = Cjis ◦
idVJ ◦Pjis and that, inspired by notation in physics, we can write the identity on VJ as idVJ =
Pmo=i ∣YJM0〉∙〈YJM01. For 3, We then compute
hJM∖K(x)∖lni
=(YJM∣K (x)"〉
= YJM ∣∣ [GKer((Cjis)jis)(x)] (Yln)〉
mj [J (j l)] dj
=XX X X hi,jm∖xi∙ (YjM∣Cjis ◦ Pjis∣Yjm ㊈ Yln〉
j∈Gb i=1 s=1 m=1
mj [J (j l)] dj	dJ
=XX XXX 化巾心(沙以IYM0>∙<γM0∣PjisIYm㊈Yn
j∈Gb i=1 s=1 m=1 M0=1
mj [J (j l)] dj	dJ
=XX X X X <JM∣cjis∣JM0〉∙ (s,JM0∣jm;ln) ∙(i,jm∣χ).
j∈Gb i=1 s=1 m=1 M0=1
In the last step, We used the Clebsch-Gordan coefficients, see Definition D.6 and, as mentioned
before, that Pjis is adjoint to the embedding Ijis : VJ → Vji 0 ^½.	□
Remark D.15. Here, We Want to argue that our kernel space solution also covers that of general
equivariant CNNs on homogeneous spaces (Cohen et al., 2019b). One definition of the kernel space
in that setting is
HomGin×Gout (H, HomK(Vin, Vout))	(19)
= K : H → HomK(Vin, Vout) ∖ K(gouthgin) = ρout (gout) ◦ K(h) ◦ ρin(gin) ,
Where H is a loccally compact group and Gin , Gout ⊆ H are subgroups With input- and output
representations ρin : Gin → GL(Vin) and ρout : Gout → GL(Vout). For compact groups Gin and
Gout, this is covered by our setting as folloWs: We define G := Gout × Gin and g := (gout, gin).
We can define the left action of G on H by g ∙ h := gouthg-11. Furthermore, we can reformulate the
representations of Gin and Gout to representations of the group G by setting ρin : G → GL(Vin)
60
Published as a conference paper at ICLR 2021
with ρin(g) := ρin(gin), and similarly for ρout. We furthermore notice that in Eq. (19) we could
also have inverted gin since that constraint needs to apply to all elements of Gin . Thus, we then see
that the kernel space can be equivalently defined by
HomGin×Gout (H, HomK(Vin, Vout))	(20)
={κ : H → HomK(Vin,V0ut) | K(g ∙ h) = pout(g) ◦ K(h) ◦ pin(g)-1},
which precisely is the kernel constraint of steerable CNNs in Eq. (2). Thus, if we restrict to a
homogeneous space of the action of G on H, we recover steerable kernels as in Definition 3.2 and
can apply Theorem 4.1.
D.1.5 General Steerable Kernel Bases
Now that we have a Wigner-Eckart theorem for steerable kernels, which gives a one-to-one corre-
spondence between steerable kernels and tuples of endomorphisms, we can finally describe what a
basis of the space of steerable kernels looks like. For this, additionally to the notation in the last
section, we assume that {cr | r = 1, . . . , EJ} is a basis of EndG,K (VJ).
Theorem D.16 (Steerable Kernel Bases). A basis of the space of steerable kernels
HomG(X, HomK(Vl, VJ)) is given by
{Kjisr : X → HomK(Vl, VJ) | j ∈ G, i ∈ {1, . . . ,mj}, s ∈ {1, . . . , [J (jl)]}, r = 1, . . . , EJ},
where the basis kernels Kjisr have matrix elements
dj	dJ
hJM |Kjisr (x)|lni =XX
(^JM∖cr∖JM 0)∙〈s, JM 0 jm; ln) ∙ ^i,jm∣x).	(21)
m=1 M0=1
Now, for each M0 ∈ {1, . . . , dJ}, let CGJM(0jl)s be the dj × dl-matrix of Clebsch-Gordan coefficients
hs, JM0|jm; lni, with only m and n varying. Furthermore, let hi, j |xi be the row vector with
entries hi, jm|xi for m = 1, . . . , dj. In matrix-notation with respect to the bases {YJM} ⊆ VJ and
{Yln} ⊆ Vl, we can then express the basis kernel Kjisr (x) : Vl → VJ as follows:
∕hi,j∣xi∙ CGJ(ji)s∖
Kjisr (x) = Cr ∙	:	I .	(22)
∖hi,j ∣χi∙ CG‰)s)
In this formula, all “dots” mean conventional matrix multiplication and cr is by abuse of notation
the matrix of the endomorphism cr.
Proof. For the first statement, note that a basis for Lj∈Gb Lim=j1 L[sJ=(1jl)] EndG,K (VJ) is given by all
the tuples tjisr := (0, . . . , cr, . . . , 0) that have cr at position jis, for all combinations ofj, i, s and r.
Thus, from the isomorphism GKer in the second part of Theorem D.13 we obtain that all Kjisr :=
GKer(tjisr) together form a basis for the space of steerable kernels HomG (X, HomK(Vl, VJ)).
When applying the basis-dependent form in part 3 of that theorem to Kjisr , the first three sums in
Eq. (18) just disappear since tjisr is zero almost everywhere. Furthermore, cjis is replaced by the
basis endomorphism cr . We obtain the claimed result.
For the final statement on the matrix representation, note that
hJM∣Kjisr(x)∣lni = ^X j ] ^X: ] (^JM∣cr∣JM0) ∙〈s, JM0∣jm; ln) ∙〈i,jm|x)
=XdMo=1(JMicriJM 0)Xmmj=I Gjmn,JM 0∣jm; ln)
=cM ∙ (Pmmj=ι <i,jm∣χ) ∙ hs,JM Ijm"ni)M0=ι
=cM ∙ (a，*)∙cJ-n )M,=ι∙
Here, CM is the M'th row of the matrix Cr. The result follows by dropping the indices M and n. □
61
Published as a conference paper at ICLR 2021
The next corollary means that endomorphisms can be ignored if the space of endomorphisms is
1-dimensional, which is in particular the case if K = C.
Corollary D.17. Assume that dim(EndG,K(VJ)) = 1. Then a basis of steerable kernels K : X →
HomK(Vl, VJ) is given by all Kjis with matrices
八 i,j|x).CGj(ji)s\
Kjis(X)=	:	I.	(23)
∖hi,j∣χi∙ CGJ)s)
In particular, this is the case if K = C.
Proof. In this case, a basis for the space of endomorphisms is given by the single endomorphism
c = idVJ. Postcomposition with the identity does not change the matrix, and so the result follows.
For K = C we have dim(EndG,c(VJ)) = 1 by Schur,s Lemma D.8, and thus the result follows. □
We end with two remarks regarding the parameterization of steerable CNNs. The first remark con-
siders the case of steerable CNNs of the form K : X → HomK(Vl, VJ) on a homogeneous space
X . The second remark connects this back to the case that X is an orbit embedded in Rd .
Remark D.18 (Parameterization in the abstract). First of all, we want to understand that there are
only finitely many basis kernels Kjisr . To this end, note that the index sets for i, s, and r are
necessarily finite for all j , and thus we need to understand the finite range of j . A priori, j can run
over the whole set G, which can be infinite. But, as we argue now, for only finitely many j ∈
G we
can have VJ in a direct sum decomposition of Vj 0 ^½, which rescues the finiteness:
Namely, VJ is in the direct sum decomposition of Vj 0 % if and only if the vector space
HomG,K(Vj 0 Vl , VJ) is nonzero by Schur’s Lemma B.29. By the hom-tensor adjunction
that we will show in Proposition D.23 in more generality, this is the case if an only if
HomG,K(Vj, HomK(Vl, VJ)) is nonzero. And finally, this is the case if and only if Vj is in a di-
rect sum decomposition of the representation HomK(Vl , VJ), again by Schur’s lemma. Now, since
HomK(Vl, VJ) is finite-dimensional, this can only be the case for finitely many j, and so we are
done.24
Overall, this means the following: To parameterize an equivariant neural network, one needs arbi-
trary parameters wjisr ∈ K for all combinations of j ∈ G, i ∈ {1, . . . , mj}, s ∈ {1, . . . , [J (jl)]}
and r = 1, . . . , EJ. A general steerable Kernel K : X → HomK(Vl, VJ) then takes the form
K = Xj∈Gb Xim=j1 X[sJ=(1jl)] XrE=J1 wjisrKjisr,
with the basis kernels Kjisr as in Theorem D.16.
Remark D.19 (Parameterization in practice). Remember that our original motivation for the use of
homogeneous spaces in Section C.1.1 was that Rd splits as a disjoint union of homogeneous spaces,
on which the kernel constraint acts separately. For simplicity, we assume that the compact group
acting on Rd is either G = SO(d) or G = O(d), but the general ideas hold also for the finite trans-
formation groups in Rd - the only difference is that in these finite cases, the set of representatives
of orbits becomes larger.
Thus, Rd splits into orbits Rd = Fr≥0 Sn-1 (r), where Sn-1 (r) is the sphere of radius r (with
S(0) = {0} being a single point).
We’ll discuss the orbit X0 = {0}, the origin, separately below. But note that all other orbits are
necessarily homeomorphic to each other and thus can be treated on equal footing. Therefore, let
Sn-1 be the standard sphere with radius 1 and Kjisr : Sn-1 → HomK(Vl , VJ) be basis kernels
for this choice. Then for a general steerable kernel K : Rd → HomK(Vl , VJ) there are arbitrary
functions wjisr : R>0 → K such that, for all x ∈ Rd \ {0}, we have:
K (X)= Xj∈G XmjI XsJ(jl)] XEJ1 wjisr (kxk) ∙ Kjisr
24Of course, for this argument, we need the uniqueness of direct sum decompositions. But this follows if
we assume the Hom-representation to be unitary, which works by Proposition B.20 and then using the Krull-
Remak-Schmidt Theorem, Proposition B.39.
62
Published as a conference paper at ICLR 2021
For x = 0, we might use our heavy theory to solve the kernel constraint, but it is more illuminating
to do it from scratch since this case is so simple: we have K(0) : Vl → VJ, and the kernel constraint
takes the form
K(0) = K(g ∙ 0) = PJ(g) ◦ K(0) ◦ ρι(g)-1
for all g ∈ G, which is equivalent to K(0) ◦ ρl(g) = ρJ (g) ◦ K(0) for all g ∈ G. This just means that
K(0) : Vl → VJ is an intertwiner, and by Schur’s Lemma B.29 it is either 0 if l 6= J or an arbitrary
endomorphism VJ → VJ if l = J. Thus, assuming l = J and choosing basis-endomorphisms
cr : VJ → VJ, there are coefficients wr ∈ K such that
K(0) = X J wr
r=1
cr.
The reader may find it interesting to check that this solution is precisely what is also predicted by
our theory using that LK({0}) = K isjustisomorphic to the trivial representation of G.
All in all, we now know what the most general steerable kernels look like. In practice, one needs
to choose the functions wjisr : R>0 → K. For representations over the real numbers, i.e., with
K = R, one choice is to only consider finitely many radii and Gaussian radial profiles around them.
Then instead of learning the whole function wjisr , one learns finitely many real parameters that
choose “how activated” a basis kernel Kjisr is for a certain radius. This is, for example, the route
taken in Weiler et al. (2018b;a); Weiler & Cesa (2019). If one deals with complex representations,
one usually goes the same route, only that the parameters that choose how “activated” the basis
kernels are will then be complex numbers. One can either parameterize them as a + ib with a real
part a and a complex part b. This intuitively means that a activates the standard version of the kernel
Kjisr, whereas b activates the kernel iKjisr, which can be imagined as a version of the kernel turned
by 90°. One other possibility is to parameterize a complex number as α ∙ eiβ with a scaling factor
α > 0 and a phase shift β. This is the route chosen in Worrall et al. (2016).
In Chapter E we will look at examples of determining the basis kernels Kjisr , which will hopefully
further illuminate the theorem. In the next section, we go back to the theory and prove the remaining
parts of the Wigner-Eckart theorem.
D.2 Proof of the Wigner-Eckart Theorem for Kernel Operators
In this section, we prove the first part of Theorem D.13, the Wigner-Eckart theorem for Kernel
Operators, since we have skipped this in the last section. It is not necessary to read this section
and the reader may wish to directly go to the chapter on examples E. We will make frequent use of
topological concepts from Chapter F.1 in this section.
The strategy is the following: in Section D.2.1, we show that
mj
HomG,κ(LK(X), HomK(Vι, Vj)) = HomG,κ ΘΘVji, HomK(Vl,
j∈Gb i=1
which basically means that we can ignore the “topological closure” of the direct sum which is dense
in L2K(X). This works, intuitively, since kernel operators are continuous, and so they are determined
by what they do on a dense subset. Then, in section D.2.2, we show that
HomG,K
Vji,HomK(Vl,VJ)
=HomG,κ
Vj 0 % ,叮
which is the main step that we need in order to be able to make use of the Clebsch-Gordan coeffi-
cients, namely when we decompose the tensor product. Finally, in Section D.2.3, we finish the proof
of Theorem D.13.
D.2.1 REDUCTION TO A DENSE SUBSPACE OF L2K(X)
In this section, we reduce the statement to representation operators on Lj∈Gb Lim=j1 Vji . For sim-
plicity, we write the double direct sum from now on as Lji .
63
Published as a conference paper at ICLR 2021
Furthermore, remember that Vl and VJ are finite-dimensional, and thus HomK(Vl , VJ) can be iden-
tified with matrices in KdJ ×dl . This space is a Euclidean space and thus has a scalar product and
consequently also a norm, see Chapter F.1. Consequently, each kernel operator is a continuous map
between normed vector spaces, which we’ll use in the following.
A short terminological note: kernel operators are just representation operators on L2K(X) and only
have their name due to the relation to steerable kernels. Thus, the terminological difference to
representation operators in the following reduction result has no further meaning:
Lemma D.20. The restriction map
HomG,K(L2K(X),HomK(Vl, VJ)) → HomG,K M Vji, HomK(Vl, VJ)
given by K 7→ K|L Vji, between kernel operators on the left and representation operators on the
right is an isomorphism.
Proof. First of all, the kernel operators on the left are actually uniformly continuous by Proposition
F.18. Thus, by Lemma F.22, the restriction map is an injection into uniformly continuous representa-
tion operators on Lji Vji. The set of all these maps is equal to the set of all representation operators
by Proposition F.18 again.
Thus, in order to be finished, We only need to see that the unique extension of a representation
operator K : Lji Vji → Homκ(%, VJ) to a continuous function K : LK(X) → HomK(Vι, VJ) is
a kernel operator, Which means it is linear and equivariant.
For linearity, let a ∈ K and f ∈ L2K(X). Let (fk)k be a sequence in Lji Vji that converges to f.
Using the continuity of K and the linearity of K we obtain:
K(a • f )= K( lim (a ∙ fk))
k→∞
=lim K(a ∙ fk)
k→∞
= lim K(a • fk)
k→∞
= lim a • K(fk)
k→∞
a
a
a
•	lim K(fk)
k→∞
•	K( lim fk)
k→∞
•	K(f).
Linearity with respect to addition can be shown similarly. For the equivariance we can argue in
the same way, only that we additionally need to use the continuity of the representations λ : G →
U(LK(X)) and PHom : G → GL(HomK(%,VJ)).	□
D.2.2 The Hom-Tensor Adjunction
Lemma D.21. Let K : li Vli → V be linear and equivariant, where V is an irrep. Then K is
continuous.
Proof. By Schur’s Lemma D.8,25 we know that K factors through the irreducible representations
that are isomorphic to V . That is, let Vj be that irrep and pji : Lli Vli → Vji be the canonical
projections. Then there are intertwiners ci : Vji → V such that K = Pi ci ◦ pji . Each ci is
continuous since it is a linear function between finite-dimensional normed vector spaces. Since also
summation on normed vector spaces is continuous, we only need to show that the projections pji
are continuous.
25Schur’s lemma applies since it is a statement about irreducible representations which are necessarily finite-
dimensional. This means that the continuity condition in the definition of intertwiners is vacuous and thus we
don’t need to worry about K not being continuous a priori.
64
Published as a conference paper at ICLR 2021
This follows from the following fact on how the norm on li Vli is composed from the norms on
each Vli: For an element f = Pli fli ∈ Lli Vli with fli ∈ Vli, we have:
kfk2=X kflik2.
li
The reason for this is that the Vli are perpendicular to each other. Consequently, if (fk)k with
fk ∈ Lli Vli converges to 0, then also (pji(f k))k = (fjki)k converges to 0, which shows the
continuity of Pji in 0 and thus general continuity by Proposition F.18.	口
Remark D.22. Note the curious fact that we cannot get rid of the equivariance condition in the
preceding Lemma. I.e., if we have a linear function K : Ll Vl → V , then we cannot deduce that
K is continuous. We omit the index i for simplicity. If equivariance is no requirement, then we
only deal with vector spaces, which are in general isomorphic to spaces of (maybe infinite) tuples of
elements in K. Thus, let the function K : Ll∈N K → K given by
(Ol)I → W?l ∙ al.
This is linear but not continuous in 0. The latter can be seen by considering the sequence (ak)k with
ak = (0,..., 0,1,0,...) that has value 1 on position k and otherwise only zeros. This sequence
converges to the 0-sequence in norm. However, we have K(ak) = 1 for all k, thus the images do
not converge to 0 = K(0).
From the preceding lemma, we are able to obtain the following alternative description of represen-
tation operators:
Proposition D.23 (Hom-tensor Adjunction). The map
(∙): HomG,κ (Mj. Vji, Homκ(V^, VJ)) → HomG,κ ((Mj. Vji) X VL VJ)
given by
K(Vj 0 Vl) = [K(vj)](vl)
is an isomorphism.
Proof. For continuity, note the following: by straightforward extensions of Lemma D.21, all linear
and equivariant maps Lji Vji → HomK(Vl, VJ) and Lji Vji 0 Vl → VJ are necessarily contin-
uous, and thus we can ignore continuity altogether. The rest of the proof can be done as in Agrawala
(1980). For illustrating the most important part, we show that K is actually equivariant:
KK([(Pj 0 ρl)(g)](vj 0 Vl))= KK([Pj(g)](vj) 0 [ρl(g)] (Vl))
= [K(ρj(g)(Vj))] (ρl(g)(Vl))
= ρHom(g)(K(Vj))(ρl(g)(Vl))
=(PJ(g) ◦ K(Vj) ◦ Pl(g)T) (Pl(g)(Vl))
= ρJ(g)(K(Vj)(Vl))
∕∖∕1二/	∙~,	∖∖
= PJ (g)(K(Vj 0Vl)).
□
Remark D.24. Some readers may wonder why this is called an adjunction. With removing some of
the notation in the Proposition, one has
HomG,κ(T, HomK(U, V)) = Homg,κ(T 0 U, V).
Now, for notational clarity, set F := HomK(U, ∙) and H := (∙) 0 U and remove the subscripts. Then
the formula can be written as
Hom(T, F (V)) = Hom(H (T), V).
With replacing the notation if the Hom-spaces with a scalar product, and the isomorphism sign with
equality, this reads as follows:
hT|F(V)i=hH(T)|Vi.
Similar to adjoints in Hilbert spaces, we can then view F and H as adjoint to each other. In categor-
ical terms, they are a pair of adjoint functors, see Lane et al. (1998).
65
Published as a conference paper at ICLR 2021
D.2.3 Proof of Theorem D.13
After the work done in the prior sections, we are ready to complete the proof of Theorem D.13!
Proof of Theorem D.13. Only the first part of that theorem still needs to be proven. We have the
following string of isomorphisms, which we will explain below:
HomG,κ(LK(X),Homκ(%VJ))= Homα,κ (MjiVji,Homκ(Vι,Vj))
—HomG,K ((Mji Vji)乳 Vl, VJ)
= HomG,κ (M∕V“乳 V1),Vj )
=M HomG,κ (Vji 乳 Vi,Vj )
ji
[j(jl)]
==MM
HomG,K (Vj, Vj)
ji s=1
mj [j (j l)]
= M M M EndG,K(Vj).
j∈Gb i=1 s=1
The steps are justified as follows:
1.	For the first step, use Lemma D.20.
2.	For the second step, use Proposition D.23.
3.	For the third step, use that there is a natural isomorphism (Lji Vji) 0 ^½ = Lji(Vji 0 ^½).
4.	For the fourth step, use that linear equivariant maps can be described on each direct sum-
mand individually (and that we do not need to worry about continuity due to Lemma D.21).
5.	For the fifth step, precompose with the linear equivariant isometric embeddings ljis : Vj →
Vji 0 Vl and use, again, that linear equivariant maps can be described on each direct sum-
mand individually. Furthermore, use Schur’s Lemma B.29 in order to see that the other
summands disappear.
6.	The last step is just a reformulation.
Now, we call the string of isomorphisms from right to left
mj [j(jl)]
Rep : MM M
EndG,K(Vj) → HomG,K(L2K(X),HomK(Vl,Vj))
j ∈Gb i=1 s=1
and are only left with understanding that it is actually given by Eq. (17). For this, we take a tuple
(cjis)jis of endomorphisms and explicitly trace back “where it comes from”. As in Lemma D.21,
letpji : Lj0i0 Vj0i0 → Vji be the canonical projection, which is by Proposition F.46 explicitly given
by Pji3 = Pmj=NYjmIG Ym. FUrthermore, E Pjis : Vji 0 Vl → Vj be the projections corre-
sponding to the embeddings ljis. Then from bottom to top, (cjis)jis gets transformed as follows:
[j(jl)]
(cj is )j is 7→	cj is ◦ Pj is
s=1	ji
mj [j (jl)]
7→ΣΣΣcj is ◦ Pj is ◦ (Pj i 0 idVl )
j∈Gb i=1 s=1
7→ Rep((cj is )j is )
66
Published as a conference paper at ICLR 2021
In the last step, the hom-tensor adjunction Proposition D.23 is used, but in the other direction. As
an illustration, the composition of functions over which we sum can be shown in the following
commutative diagram:
We obtain:
mj [J (jl)]
[Rep((Cjis) jiS)3](Vl) = EEE Icjis ◦ Pjis ◦ (Pji 0 id%)](2 0 Vl)
j∈Gb i=1 s=1
mj [J (jl)]
=	(cjis ◦ Pjis)(Pji(W) 0 vl)
j∈Gb i=1 s=1
mj [J(jl)]	dj
=XX X (cjis ◦ Pjis)	XYjmiWYjmi 0Vl
j∈Gb i=1 s=1	m=1
mj [J (jl)] dj
=XXX X(Yjmk)∙cjis(Pjis(Ym0Vl)).
j∈Gb i=1 s=1 m=1
That, finally, finishes the proof.
□
E	Example Applications
In this chapter, we develop some relevant examples of the theory outlined in prior chapters. All
of these examples are applications of Theorem D.16 and Corollary D.17. These examples are
concerned with the following question: Given a specific field K ∈ {R, C}, compact transforma-
tion group G and homogeneous space X of G, how can a basis of steerable kernels K : X →
HomK(Vl , VJ) for given irreducible representations ρl : G → U(Vl ) and ρJ : G → U(VJ) be
determined? The theorems give an outline for what needs to be done in order to succeed in this task,
and the steps are always as follows:
1.	For each l ∈ Gb, a representative for the isomorphism class of irreducible representations l
needs to be determined. That is, one needs to determine ρl : G → U(Vl ) and an orthonor-
mal basis {Yln | n ∈ {1, . . . , dl}}. We omit the index n if there is only one basis element.
Usually, we have Vl = Kdl and the orthonormal basis is just the standard basis.
2.	The Peter-Weyl Theorem B.22 gives the existence-statement for a decomposition ofL2K(X)
into irreducible subrepresentations. We need an explicit such decomposition, i.e.: we need
to find multiplicities mj-, irreducible subrepresentations Vji = Vj for i ∈ {1,...,mj∙}
and basis functions Yjmi ∈ Vji ⊆ L2K(X) corresponding to the Yjm such that L2K(X) =
Lc	Lmj V
j ∈Gb i=1 Vji.
3.	For each combination of j, l and J in Gb, one needs to find the number of times [J (j l)] that
VJ appears in a direct sum decomposition of Vj 0 Vl. Then, for each s ∈ {1, . . . , [J (jl)]},
and for all basis-indices M, m and n, one needs to determine the Clebsch-Gordan coef-
ficients hs, JM |jm; lni. We omit the index s if VJ appears only once in the direct sum
decomposition of Vj 0 Vl .
4.	For each J one needs to determine a basis {cr | r = 1, . . . , EJ} of the space of endomor-
phisms of VJ, namely EndG,K (VJ).
Once all of this is done, one can then simply write down the basis kernels according to Eq. (22)
or, in case that the space of endomorphisms is 1-dimensional, Eq. (23). The ingredients determined
67
Published as a conference paper at ICLR 2021
above are purely representation-theoretic information about the situation at hand, which hopefully
makes the reader appreciate the results even more: we do not simply determine basis kernels; we
understand in detail, along the way, the representation theory of the group and homogeneous space.
Note that we are not concerned with practical considerations related to how fine-grained to do this
in practice (for example, if the space on which the kernels operate splits into infinitely many orbits).
For such questions, we refer back to Remark D.19.
In the following sections, we discuss harmonic networks (SO(2)-equivariant CNNs with com-
plex representations), SO(2)-equivariant CNNs with real representations, reflection-equivariant net-
works, SO(3)-equivariant CNNs with both complex and real representations, and O(3)-equivariant
CNNs with both complex and real representations. For each of these examples, we go through the
four steps outlined above. We recommend looking at the first example in detail: we conduct it in the
greatest detail and it is the easiest to understand and thus serves as a nice introduction.
E.1	SO(2)-Steerable Kernels for Complex Representations - Harmonic
Networks
Here, we explain how the kernel constraint for harmonic networks (Worrall et al., 2016) can be
solved using our theory. in the case of harmonic networks, we have K = C, G = SO(2), X = S1.
As in most examples that follow, we ignore the solution of the kernel constraint in the origin, since
it is usually easy to solve. For simplifying the formulas, we employ the isomorphism
SO(2) -→ U⑴,	(b -b)→ a + ib
and always write U(1) instead of SO(2). Here, U(1) is the group of rotations of C, i.e., the group
of elements in C with absolute value 1. it is also called the circle group since the group elements lie
on a circle in the complex plane. Note that the change from SO(2) to the isomorphic group U(1) is
done purely for convenience reasons, and SO(2) could be used just as well.
We now go through the four steps outlined above. our statements about the representation theory of
the circle group can be found in Kowalski (2014), chapter 5.
E.1.1 CoNsTRUCTioN oF THE iRREDUCiBLE REpREsENTATioNs oF U(1)
We have U(1) = Z, and for l ∈ Z we can construct a representative ρl : U(1) → U(Vl) as follows:
Vl = C is just the canonical 1-dimensional C-vector space, and ρl is given by
[ρι ⑼] (Z)= gl ∙ z,
where g is regarded as an element in C. one can easily check that this is an irreducible representa-
tion. The orthonormal basis element for each such representation is just given by 1 ∈ C = Vl . This
already answers step 1 of the outline above.
E.1.2 THE pETER-WEYL THEoREM FoR L2C(S1)
For step 2, we need to determine the peter-Weyl decomposition of L2C(S1), where we regard S1
as a subset of C. Let Yl1 : S1 → C be given by Yl1(z) = z-l. Let Vl1 ⊆ L2C(S1) just be given
by its span: Vl1 = spanC(Yl1). We want to see that this is a subrepresentation of L2C(S1). To see
this, remember that the unitary representation on L2C(X) is given by λ : U(1) → U(L2C(S1)) with
[λ(g)H(z)=P(g-1z). We have
[X(g)匕ι] (Z)=匕i(gTz)	=	(gTz)T=	gl	∙	ZT	=	(gl	,匕ι)	(Z)	(24)
and thus λ(g)Yl1 = glYl1 ∈ Vl1, which is what we claimed. since the Vl1 are 1-dimensional, they
are necessarily irreducible for dimension reasons. Now, an important result from Fourier analysis
is that the Yl1 for l ∈ Z actually form an orthonormal basis of L2C(S1) and that, consequently, the
peter-Weyl decomposition of L2C(S1) looks as follows:
C T -τ≈-
L2C(S1) = MVl1.
l∈Z
68
Published as a conference paper at ICLR 2021
From this we see that the multiplicities ml are all given by 1. What is missing is the connection to
the irreps ρl : U(1) → U(Vl), but we have already indicated this in the notation. Namely, the map
fl : Vi → Vii given by z → Z ∙匕 1 is clearly an isomorphism of vector spaces, and due to Eq. (24)
even an isomorphism of representations:
力(PMg)(Z)) = fι(gl ∙ Z)
=(gl ∙ Z) ∙ Yll
=Z ∙ (gl ∙ Yl1)
=Z ∙ (λ(g)(Yli))
=X(g)(Z ∙ Yli)
=λS)(fl(Z)).
Thus, fl ◦ ρl (g) = λ(g) ◦ fl for all g ∈ U(1) and, as claimed, fl turns out to be an isomorphism.
This finishes step 2 of the outline above.
E.1.3 The Clebsch-Gordan Decomposition
For step 3, we proceed as follows: The map
f : Vj Z) Vl → Vj+l, Zj Z) Zl → Zj ∙ Zi
is clearly well-defined and linear by the universal property of tensor products, see Definition D.1.
Furthermore, it is an isometry: namely, since the scalar product in C is just the usual multiplication
(with the left entry being complex conjugated), we obtain
f(Zj Z Zl)f(Zj0 Z Zl0) = ZjZlZj0Zl0
-------------------------------0 0
=Zj Zl ∙ Zj Zl
-------------------------------0 - 0
=ZjZj ∙ ZiZi
=〈Zj|Zj)∙ hZl\Z；)
= Zj Z Zl Zj0 Z Zl0 .
In the last step, we have used the definition of the scalar product on the tensor product, Definition
D.2. Thus, f is an isomorphism of Hilbert spaces. Finally, it also respects the representations since
f ( [(Pj Z Pi)(g)] (Zj Z Zi))= f ( [Pj(g)] (Zj) Z [Pi(g)] (Zi))
=f (gjZj Z giZi)
=gj Zj ∙ glZi
=gj+∙ (Zj Zi)
= [Pj+l (g)] (f (Zj Z Zl))
and thus f ◦ (Pj Z Pl )(g) = Pj+l (g) ◦ f for all g ∈ U(1). Finally, the basis vectors correspond in
the simplest possible way since f(1 Z 1) = 1.
Overall, what we’ve shown is the following: VJ is a direct summand of Vj Z Vl if and only if
J = j + l. If this is the case, we have [J (jl)] = 1 and can thus omit the index s. The only Clebsch-
Gordan coefficient is then given by hJ 1|j1l1i = 1 since the basis elements directly correspond.
E.1.4 ENDOMORPHISMS OF VJ
This is the simplest part: Since we are considering representations over C, Schur’s Lemma D.8 tells
us that EndU(i),C (VJ) is 1-dimensional for each irrep J, and thus we can ignore the endomorphisms
altogether.
E.1.5 Bringing Everything Together
We now show that a basis of steerable kernels K : Si → HomC(Vl, VJ) of the group U(1) is given,
when expressed as 1 × 1-matrix parameterized by Si, by the basis function Yl-J : Si → C. We
69
Published as a conference paper at ICLR 2021
remove the index “1” at the basis function to remove clutter. How can we see this result, using Eq.
(23)?
Note that VJ can only appear as a direct summand of Vj 0 Vl if j = J - l by What we've shown
above. The “matrix” of Clebsch-Gordan coefficients CGJ((J-l)l) is then just the number 1. We can
omit the vacuous indices i and s and obtain that the only basis kernel is given by
Kj-l (x) = hYJ-l∣χi = YJ-i(x)
=X-(J-l)
= x-(l-J)
= Yl-J (x).
This result is precisely equal to the one obtained in the original paper (Worrall et al., 2016). This
concludes our investigations of harmonic networks.
E.2	SO(2)-STEERABLE KERNELS FOR REAL REPRESENTATIONS
In this section, we look at the case K = R, G = SO(2) and X = S1. In the following sections, we
again step by step determine the representation-theoretic ingredients that we need for the application
of our theorem. Compared to Chapter A, which focuses more on the components themselves and
how they relate to the general situation, this section has a stronger focus on actually determining the
final kernels, which also involves the task of determining the Clebsch-Gordan coefficients explicitly.
We remark that the resulting kernels are not new, since Weiler & Cesa (2019) have solved for this
kernel basis already. However, we want to emphasize again that with our method, we learn more
about the representation theory of SO(2) and thus get an overall better conceptual understanding of
how the kernels arise.
Since it will help the presentation of our results, we set SO(2) = R∕2∏Z, i.e., we view SO(2) as a
group of angles. We also set S1 = R∕2∏Z, i.e., we take the interval [0,2∏] as the space where our
functions are defined. Consequently, since we want our Haar measure to be normalized, we have to
put the fraction 2∏ before all of our integrals, different from what we did in our treatment of SO(2)
over C.
Note that since we now consider representations over the real numbers, unitary representations be-
come orthogonal and we write O(V ) instead of U(V ).
E.2. 1 CONSTRUCTION OF THE IRREDUCIBLE REPRESENTATIONS OF SO(2)
The irreps of SO(2) over R are given by ρl : SO(2) → O(Vl), l ∈ N≥0. For l = 0, we have V0 = R
and the action is trivial. For l ≥ 1, Vl = R2 as a vector space. The action is given by
[ρl(φ)](v)= fcθsJlφ) -sin(lφ))∙ V
l	sin(lφ)	cos(lφ)
for φ ∈ SO(2) = R∕2∏Z. The orthonormal basis is in both cases just given by standard basis
vectors.
E.2.2 THE PETER-WEYL THEOREM FOR L2R(S1)
Now we look at square-integrable functions L2R(S1) that we now assume to take real values. As
before, SO(2) acts on this space by (λ(φ)f)(x) = f(x - φ).26 For notational simplicity, we write
cosl for the function that maps x to cos(lx), and analogously for sinl. One then can show the
following, which is a standard result in Fourier analysis:
Proposition E.1. The functions cosl, sinl, l ≥ 1 span an irreducible invariant subspace of L2R(S1)
of dimension 2, explicitly given by
spanR(cosl , sinl ) = α cosl +β sinl | α, β ∈ R
26Note that we have a subtraction now instead of a multiplicative inversion. This is because we view our
group as additive.
70
Published as a conference paper at ICLR 2021
which is isomorphic as an orthogonal representation to Vi by √2cosl → (j) and √2sinl →
10 .27 Furthermore, sin0 = 0 and cos0 = 1 are constant functions and their span is 1-dimensional
and equivariantly isomorphic to V0 by cos0 7→ 1.
Finally, the functions √2 ∙ cosι, √2 ∙ Sinl form an orthonormal basis of LR(SI), i.e., everyfunction
can be written uniquely as a (possibly infinite) linear combination of these basis functions.
When setting Vl1 = spanR(cosl , sinl), we thus obtain a decomposition
C	T	二
LR(S ) = MVl1.
l≥0
Thus, we have ml = 1 for all l ∈ N. All in all, we know everything there is to know about the
Peter-Weyl theorem in our situation.
E.2.3 The Clebsch-Gordan Decomposition
We now do the explicit decomposition of Vj 0 Vi into irreps, which will give Us the Clebsch-Gordan
coefficients that we need. Instead of doing the decomposition in terms of Vj and Vl themselves, in
the proofs we actUally Use the isomorphic images Vj1 and Vi1 in L2R(S1). For doing so, we first
need some trigonometric formUlas in oUr disposal:
Lemma E.2. The sine and cosine functions fulfill the following rules:
1.	cosj+i = cosj cosi - sinj sini.
2.	sinj+i = sinj cosi + cosj sini.
3.	cosj-i = cosj cosi + sinj sini .
4.	sinj-i = sinj cosi - cosj sini.
Proof. The first two are well-known and the last two follow directly from the first two Using sin-j =
一Sinj and cos-j = Cosj.	□
We will need the following general lemma:
Lemma E.3. Let f : V → V0 be an intertwiner between representations ρ : G → GL(V) and
ρ0 : G → GL(V0). Then null(f) = {v ∈ V | f(v) = 0} is an invariant linear subspace ofV.
Proof. This can easily be checked by the reader.
□
As a remark on notation for the following proposition: We write the Clebsch-Gordan coefficients
CGJ(ji)s of irreps VJ, Vj and Vi with dimensions dJ, dj and di as a dJ × (dj × di)-tensor. That is,
it consists of dJ “rows”, each of which is a dj × di-matrix. If VJ appears only once in the tensor
prodUct, we omit the index s as before.
Proposition E.4. We have the following decomposition results:
1.	For j = l = 0 we have V0 0 V0 = V0 and Clebsch-Gordan COeffiCientS CG0(00) = ([1]).
2.	For j = 0, l > 0 we have V0 0 Vi = Vi and Clebsch-Gordan COeffiCientS CGi(oi)=
[1 0]
[0 1] .
3.	For j > 0, l = 0, we get Vj 0 V0 == Vj and Clebsch-Gordan coefficients CGj (j0) =
/ w∖
0
o^ .
∖w_____________________
27 vz2 acts as a normalization.
71
Published as a conference paper at ICLR 2021
4.
For j > l > 0 we get Vj 0 ^½ = Vj-I ㊉ Vj+ι. The ClebsCh-Gordan coefficients are given
by CGj-J
and CGj+ι,(jι)
1
0
0
1
5.
For l > j > 0 we get Vj 0 Vi = V1㊉ Vj+ι. The Clebsch-Gordan coefficients are given
by CG(ι-j)(jι)
1
0
0
-1
(
and CGj+ι,(jι) = I L
6.
For j = l > 0, we get an isomorphism Vι 0 Vι
=V02 ㊉ V2ι.	We obtain the
Clebsch-Gordan coefficients CG0(ιι)1
10
01
CG0(ιι)2
0	干1
±1	0
, and
I	10
CG2ι,(ιι) = I 0
, the last one being the same as the Clebsch-Gordan coefficients
0
/
∖
(
∖
0
0
:)
0
CGj+ι,(jι) from above. In CG0(ιι)1 and CG0(ιι)2, a fourth index is present, namely 1 and
2, respectively. This is the index “s” that was missing in all the prior examples, since this
is the first time an irrep appears more than once in a tensor product decomposition. Note
that for CG0(ιι)2, we have exactly one positive and one negative entry present, but both are
equally valid and mirror the lower halves in CGj-ι,(jι) from part 4 and CGι-j,(jι) from
part 5.
Proof. In the proof, instead of working directly with the irreps ρj : SO(2) → O(Vj ), we use the
isomorphic copies Vj1 in L2R(S1) given in Proposition E.1. Since we think that it does not help
understanding to carry the index “1” in all computations, we omit this index.
The proof of 1, 2, and 3 is clear.
For 4 and 5, consider the (unnormalized) basis {Cosj 0 Cosι, Cosj 0 sinι, sinj 0 Cosι, sinj 0 sinι} of
Vj 0 Vι . Our goal is to express these basis elements with respect to basis elements of invariant
subspaces. We do this by explicitly constructing an isomorphism to a decomposition of irreps. To
that end, let P : Vj 0 ^½ → LR(S1) be given by f 0 g → f ∙ g, which is clearly a well-defined
intertwiner. We get as image of p the set
im(p) = sPanR p(Cosj 0 Cosι), p(Cosj 0 sinι), p(sinj 0 Cosι), p(sinj 0 sinι)
=spanR (Cosj ∙ cosι, Cosj ∙ sinι, sinj ∙ cosι, sinj ∙ sinι).
From Lemma E.2 we obtain:
(a)
(b)
(c)
(d)
p(cosj 0 cosι)	-	p(sinj 0	sinι)	=	cosj+ι ,
p(cosj 0 sinι )	+	p(sinj 0	cosι)	=	sinj+ι ,
p(cosj 0 cosι)	+	p(sinj 0	sinι)	=	cosj-ι ,
p(sinj 0 cosι )	-	p(cosj 0	sinι)	=	sinj-ι .
(25)
Since the right hand sides are linearly independent basis functions of L2R(S1), we obtain:
im(p) = SPanR (Cosj+ι, Sinj+ι, Cosj-I, Sinj-I) = Vj-1∣ ㊉ V+∙
Note for the last step that due to symmetry, cosj-ι = cosι-j and sinj-ι = - sinι-j .
We now specialize to the case of 4, i.e., j > l > 0. In this case, Hj-1∣ = V-ι, and the basis is given
by Cosj-ι and sinj-ι, as in the right hand sides of Eq. (25) (c) and (d). Consequently, Eq. (25) is
already the expansion of the new basis elements with the old, and the coefficients are consequently
the Clebsch-Gordan coefficients.28 More precisely, ifwe want to compute, for example, CGj-ι,(jι),
28Note that for two orthonormal bases in a Hilbert space, when expressing one basis {bi } with respect to
another basis {ci}, then the expansion coefficients are given by the scalar products hcj |bii. Since we work over
72
Published as a conference paper at ICLR 2021
then we observe from (c) that
+1 ∙ P(Cosj 0 Cosl) + 0 ∙ P(Cosj 0 Sinl)
+0 ∙ p(sinj 0 Cosl) + 1 ∙ p(sinj 0 sinl)
from which we can already read the upper half of CGj-l,(jl) as the coefficients in this equation
(which we conveniently visually arranged in the right way). For the lower half, we do proceed the
same for sinj-l, using (d). Then, for CGj+l,(jl), we proceed exactly the same, using parts (a) and
(b). That proves 4.
For 5, we have l > j > 0. In this case, V|j-l| = Vl-j, i.e., the basis is given by Cosl-j = Cosj-l and
sinl-j = - sinj-l. The latter means that in part (d) of Eq. (25), we need to replace sinj-l by sinl-j
and thus change the signs on the left hand side. This change means that CGj+l,(jl) will remain the
same as in 4, the upper half of CGl-j,(jl) will remain the same as the upper half of CGj-l,(jl) from
part 4 since the cosine in part (c) of Eq. (25) is symmetric, and the lower part will flip the signs. This
fully proves 5.
Finally, we prove 6. We have j = l and still consider the same function P. Note that P(Cosj 0 Cosl)+
P(sinj 0 sinl) = 1 and P(sinj 0 Cosl) - P(Cosj 0 sinl) = 0 are constant functions that span the 1-
dimensional trivial representation. Thus, we see that P is a surjection
P ： % 0 % → V0 ㊉ ½l
with null space spanned by sinj 0 Cosl - Cosj 0 sinl. Such a null space is automatically an invariant
subspace as well, and since it is one-dimensional, it also must be isomorphic to the trivial represen-
tation. Overall, this gives us an isomorphism
Vrι 0 Vrι = V02 ㊉ V2l.
From this, we can as before read off the Clebsch-Gordan coefficients. The only thing that changes
is that parts (c) and (d) of Eq. (25) now correspond to two different copies of V0 , which means that
the Clebsch-Gordan coefficients CG0(ll) now split up in two parts CG0(ll)1 and CG0(ll)2. Note that
in the trivial representation, the isomorphism that sends the basis vector to its negative is clearly
equivariant, which means that both combinations of signs that we give in the final formula for
CG0(ii)2 are valid.	口
E.2.4 ENDOMORPHISMS OF VJ
We now describe the endomorphisms of the irreducible representations, our last ingredient:
Proposition E.5. We have EndSO(2),R(V0) == R, i.e., multiplications with all real numbers are
valid endomorphisms of V0. For l ≥ 1, we get
EndSO(2),R(Vl) =	ab	a a, b ∈ R
which is the set of all scaled rotations of R2. When identifying R2 == C, we can also view these
transformations as arbitrary multiplications with a complex number.
As a consequence, idR is a basis for EndSO(2),R(V0) and	01 01 , 10 -01	a basis for
EndSO(2),R(Vl) forl ≥ 1.
Proof Sketch. For l ≥ 1 and an arbitrary matrix E =	ac db	that commutes with all rotation
matrices ρl(φ), i.e., E ◦ ρl(φ) = ρl(φ) ◦ E, one can easily show the constraints a = d and b = -c,
from which the result follows.
the real numbers, the scalar product is symmetric, and these coefficients are thus also the expansion coefficients
when expressing {ci} with {bj}. This is why we do not have to rearrange the expressions in Eq. (25), it simply
doesn’t matter which of the two bases is expanded. Note, however, that our bases are not normalized, and so
the Clebsch-Gordan coefficients differ by a constant if the equation is rearranged. This constant does not matter
for us since we are only interested in a basis of the space of steerable kernels, and constant multiples of bases
are still bases.
73
Published as a conference paper at ICLR 2021
E.2.5 Bringing Everything Together
Now we have done all needed preparation and can solve the kernel constraint explicitly, using the
matrix-form of the Wigner-Eckart theorem for steerable kernels, Theorem D.16. This is, as men-
tioned before, a new derivation of the results in Weiler & Cesa (2019). One can compare with table
8 in their appendix which only differs by (irrelevant) constants.
Proposition E.6. We consider steerable kernels K : S1 → HomR(Vl , VJ), where Vl and VJ are
irreducible representations of SO(2). Then the following holds:
1. For l = J = 0, we get K(x) = a ∙ (1) for every X ∈ S1 and an arbitrary real number
a ∈ R independent of x.
2.
For l = 0, J > 0, a basis for steerable kernels is given by
cosJ
sinJ
and
- sinJ
cosJ
3. Forl > 0 and J = 0, a basis for steerable kernels is given by (cosl sinl), (sinl - cosl).
4.
For l, J > 0, a basis for steerable kernels is given by
- sinJ-l
cosJ-l
-cosJ-l , cosJ+l	sinJ+l ,and - sinJ+l
- sinJ-l	sinJ+l	- cosJ+l	cosJ+l
cosJ-l
sinJ-l
cosJ+l
sinJ+l .
- sinJ-l
cosJ-l
Proof. The proof of 1 is clear.
For 2, note that VJ can only appear in Vj 0V0 if j = J. The relevant Clebsch-Gordan coefficients are
….，……他L...................................
by Proposition E.4 therefore CGJ(J0)= I 卜 .Furthermore, the orthonormal basis of Vji = VJi
U1U
is given by Proposition E.1 up to constants by {cosJ, sinJ}, which we have to write as a row-vector
according to Theorem D.16. Thereby, we can ignore the complex conjugation since we work over
the real numbers. Our final ingredient is the endomorphism basis of VJ, which is by Proposition E.5
given by ci = idR2 and c2 = 10 -01 . Overall, the basis kernels are given by
The result follows.
[cosJ
[cosJ
SinJ] ∙ 0
sinj] ∙
cosJ
sinJ
For 3, We find V0 only in Vj 0 Vl if j = l, and even twice so. The relevant Clebsch-Gordan
coefficients are therefore by Proposition E.4 given by CG0(ll)i
0 -1
10
10
01
and CG0(ll)2
. The basis-functions in Vji = Vli are by Proposition E.1 up to constants {cosl , sinl },
again written as a row-vector. Finally, VJ = V0 has only idR as a basis-endomorphism by Propo-
sition E.5, so this can be ignored altogether by Corollary D.17. We obtain the following basis for
steerable kernels:
[cosl	sinl]
10
01
(1 cosl
[cosl	sinl]
0 -1
10
(1 sinl
1 sinl)
-1 cosl ) .
0
1
/
For 4, we consider only the case l < J. By Proposition E.4 we have
VJ-l 0	Vl	= Ql-j| ㊉	VJ,	Vl+j 0	Vl	=	VJ	㊉	V2l+J,
74
Published as a conference paper at ICLR 2021
i.e., j = J - l and j = l + J leads to a tensor product decomposition containing VJ, but no
other j does. Thus, the relevant Clebsch-Gordan coefficients are by Proposition E.4 the matrices
CGJ,(J-l,l) and CGJ,(l+J,l).
We now consider the first case, i.e., j = J - l. The Clebsch-Gordan coefficients are CGJ,(J-l,l) =
([1 _*	''
CGι+j,(ji) = I b0	1	. The basis functions of V(J-i” are by Proposition E.1 furthermore
U1 0)
given by {cosJ-l , sinJ-l}. Finally, VJ has again the two basis endomorphisms c1 = idR2 and c2
from above. Thus, we obtain the following basis kernel for c1:
[cosJ-i SinJ-i] ∙ 0
0
[cosj-i SinJ-i] ∙ ι
0
-1
1
0
cosJ-i
sinJ-i
- sinJ-i
cosJ-i
(26)
Consequently, for c2 as the basis endomorphism we need to postcompose with c2 and get:
cosJ-i
sinJ-i
- sinJ-i
cosJ-i
=-sinJ-i
cosJ-i
- cosJ-i
- sinJ-i
(27)
These are half of the basis kernels. For the other half, we need to look at the case j = l + J. The
Clebsch-Gordan coefficients are by part 4 of Proposition E.4 given by CGJ,(i+J,i) = CGj-i,(ji) =
∕I"1	0]∖	"
0	1
'O	1 . The basis functions of V(I+j)i are by Proposition E.1 furthermore given by
U1	0)
{cosJ+i, sinJ+i}. For the basis endomorphism c1 we thus get the basis kernel
[cos J+1 SinJ+1] ∙ 0
0
[cosJ+i SmJ+i] ∙ 1
0
1
-1
0
cosJ+i
sinJ+i
sinJ+i
- cosJ+i
(28)
Consequently, for c2 as the basis endomorphism we need to postcompose with c2 and get:
01
cosJ+i
sinJ+i
sinJ+i
- cosJ+i
=-sinJ+i
cosJ+i
cosJ+i
sinJ+i
(29)
Overall, for the case l < J we have determined all four basis kernels in Eqs. (26), (27), (28),
and (29). The cases l = J and l > J can be considered analogously, and in every case the correct
Clebsch-Gordan coefficients have to be picked. By using cosi-J = cosJ-i and sini-J = - sinJ-i,
this will, in the end, always lead to the same final formulas. This result is consistent with Table 8 in
Weiler & Cesa (2019).	口
E.3 Z2-STEERABLE KERNELS FOR REAL REPRESENTATIONS
In this section, we discuss steerable CNNs that use the finite group Z2, which we identify with
({-1, +1}, ∙), for their symmetries. We let this group act on the plane R2 by vertical reflections,
though other choices are possible as well:
This example is simple and one may see it as contrived to apply our relatively heavy theory to it.
We include it mainly as a demonstration that our results can also be applied to non-smooth finite
groups as instances of compact groups. Furthermore, we will fully recover the relationship to the
original group convolutional CNNs from Cohen & Welling (2016a) and thereby demonstrate that all
the different developed theories are consistent with each other.
75
Published as a conference paper at ICLR 2021
E.3.1 THE IRREDUCIBLE REPRESENTATIONS OF Z2 OVER THE REAL NUMBERS
Let ρ : Z2 → GL(V ) be an irreducible real representation. Note that
P(T)O P(T) = P((-I) Y-I)) = P(I) = idV,
and thus ρ(-1) is an involution satisfying the equation ρ(-1)2 - idV = 0. It is well-known from
linear algebra that involutions are diagonalizable, and thus P(-1) leaves 1-dimensional subspaces
invariant. By irreducibility of P this means that V itself needs to be 1-dimensional. Consequently,
we can assume V = R without loss of generality. Note that the computations above mean that we
have
(ρ(-1) - idR) ◦ (ρ(-1) +idR) =0
and thus we need to have P(-1) - idR = 0 or P(-1) + idR = 0. It follows P(-1) = idR
or P(-1) = - idR . Overall, all these investigations mean that we have precisely two irreducible
representations of Z2 up to equivalence. We call them P+ : Z2 → O(V+) and P- : Z2 → O(V-),
where P+(-1) = idR and P-(-1) = - idR and V+ = V- = R.
E.3.2 THE PETER-WEYL THEOREM FOR L2R(X)
Here we do the Peter-Weyl decomposition for L2R(X), where X is one of the two homogeneous
spaces X = {-1, 1} and X = {0} with the obvious actions coming from the groups Z2. This time,
we also discuss orbits with only one point since we later want to get a description of kernels on the
whole of R2 for comparisons with group convolutional CNNs.
We start with X = {-1, 1}. Note that the measure on X is just the normalized counting measure,
and thus all functions f : X → R are square-integrable. We define the two functions
f+ : X → R, f+(x) = 1 for all x ∈ X = {-1, 1},
f- : X → R, f-(x) = xforallx ∈ X = {-1, 1}.
We then define V+1 = spanR(f+) and V-1 = spanR(f-). This gives a decomposition
LR(X) = V+ι ㊉ V-1
since we have for all f ∈ L2R(X)
f_f(1) + f(-1) f J
f =-----2------f+ +
f(1) - f(-1)
. f-.
2
Furthermore, the maps 1 → f+ and 1 → f- give isomorphisms of representations V+ = V+ι and
V- = V-ι, respectively.
Now, assume that X = {0} with the trivial action coming from Z2. Then L2R(X) = V+1 generated
from the function f+ : X → R, f+(0) = 1. As before, 1 7→ f+ gives an isomorphism V+ == V+1.
This concludes the investigations of the Peter-Weyl theorem.
E.3.3 The Clebsch-Gordan Decomposition
We have the following four isomorphisms of representations:
V+ % V+	= V+,	V+	% V-	=	V-,
V- % V+	= V-,	V-	% V-	=	V+,
each time simply given by a % b 7→ ab. It can easily be checked that these are isomorphisms. In
Section E.6.3 the reader can find a proof for similar, sign-dependent isomorphisms for the case that
the group is O(3). For each such isomorphism, there is precisely one Clebsch-Gordan coefficient
and it is just given by 1. Thus, as in the case of harmonic networks in Section E.1.5, we can just
ignore the Clebsch-Gordan coefficients altogether in the final formulas for our basis kernels.
E.3.4 ENDOMORPHISMS OF V+ AND V-
Since V+ and V- are themselves only 1-dimensional, the endomorphism spaces are necessarily 1-
dimensional as well and just given by arbitrary 1 × 1-matrices, i.e., arbitrary stretchings. As in the
example of harmonic networks, we can therefore ignore the endomorphisms as well.
76
Published as a conference paper at ICLR 2021
E.3.5 Bringing Everything Together
Different from the other examples, we will in this section not only engage with the final steerable
kernels on homogeneous spaces but also discuss how these assemble to kernels defined on the whole
plane R2. In the end, we will then also discuss how kernels for the regular representation would look
like.
But first, we engage with the homogeneous spaces. We start with X = {-1, 1} and consider steer-
able kernels K : X → HomR(Vin , Vout) for irreducible Vin and Vout . There are four possibilities
for the input and output representations:
STEERABLE KERNELS K : X → HomR(V+, V+):
V+ can only be in a tensor product V 0 V+ if the sign of V is positive as well. Such a space appears
precisely once in L2R(X) according to Section E.3.2. Since endomorphisms and Clebsch-Gordan
coefficients do not appear by what we’ve shown before, and since complex conjugation doesn’t do
anything over the real numbers, a basis for steerable kernels is just given by the one kernel K+ = f+
itself. Here, we identify HomR(V+, V+) with R since it only consists of 1 × 1-matrices.
STEERABLE KERNELS K : X → HomR (V+ , V- ):
By the same arguments, a basis is given by the one kernel K- = f-.
ST EERABLE KERNELS K : X → HomR (V- , V+ ):
Again, a basis for steerable kernels is given by K- = f- .
ST EERABLE KERNELS K : X → HomR (V- , V- ):
A basis is given by K+ = f+ .
Finally, we also need to engage with the case that X = {0} consists only ofa single point. Similarly
to above, in the “even” case that the signs of input- and output representations agree, a basis is given
by K+ = f+ with f+ (0) = 1. If, however, the signs do not agree, then only K = 0 fulfills the
constrained and the basis is empty.
Now, we assemble this to kernels on the whole ofR2. We saw above that we only need to distinguish
two cases, namely (a) the case that the signs of input and output representation agree and (b) that
they do not.
For case (a), let K : R2 → R be a steerable kernel, where R is isomorphic to the Hom-space
between equal-sign representations. R2 splits disjointly into orbits, namely
n ab , -ba o
for all
a ∈ R≥0 and b ∈ R. If a = 0, then the orbit is just a single point, which means that we have a
vertical line of single-point orbits. The solution above showed that on each orbit, the kernel needs
to be constant (since f+ is constant) and overall this just translates to
for all a ≥ 0 and b ∈ R. Consequently, K is just an arbitrary left-right symmetric kernel.
In the case that the input- and output representations do not share their sign, by the same arguments
we see that K : R2 → R is an arbitrary left-right anti-symmetric kernel which is zero on the vertical
line 0b for arbitrary b ∈ R.
Other than these left-right restrictions, the kernel can be freely learned. Overall, this means that
we learn one “half” of the kernel and can recover the other half by the symmetry property derived
above.
77
Published as a conference paper at ICLR 2021
E.3.6 GROUP CONVOLUTIONAL CNNS FOR Z2
We now investigate what all this means if we consider regular representations instead of irreducible
representations, thus corresponding to group convolutional kernels as in (Cohen & Welling, 2016a).
In this case, we will see an interesting “twist” in the kernel, which makes this example more inter-
esting than one might initially think. The twist emerges as follows: For regular representations, we
consider steerable kernels
K :R2 →HomR(L2R(Z2),L2R(Z2))
Now, there are two relatively canonical bases we can choose in the left and the right space. We
already know from above that {f+, f-} is the basis to choose ifwe want to express steerable kernels
corresponding to irreducible representations. However, for vanilla group convolutional CNNs, the
basis usually chosen is {e+1, e-1} where e+1(x) = δ+1,x and e-1(x) = δ-1,x. We then obtain the
following four base change relations:
f+ = e+1 + e-1,	f- = e+1 - e-1,
Q —If j	Q	J L
e+ι = 2f+ + 2f-,	e-ι = 2f+ - 2f-.
Thus, the base change matrices are given by
Now, assume that K : R2 → HomR(LR(Z2), LR(Z2)) = R2×2 is expressed with respect to the
basis {f+, f-}. If we write K as a matrix
K12
K22
then we know that K11 and K22 map between equal-sign representations and K12 and K21 between
unequal-sign representations. Consequently, from what we’ve found above, K11 and K22 are sym-
metric, whereas K12 and K21 are antisymmetric. What we now want to figure out is how exactly
this translates to a property of the kernel expressed in the basis {e+, e-}.
Thus, let K0 be this corresponding kernel. Then using the base change matrices above we obtain
B ∙ K ∙ BT
1	1 K11	K12
U -1) ∙ KK21 K22
(2 [Ku + K12 + K21 +
∖ 2 [K11 + k12 - k21 -
1-21-2
1-21-2
1 [K11 - K12 + K21 — K22]∖
1 [k11 - K12 - K21 + K22]√
	
What symmetry properties does this kernel obey? In order to understand this, we use the following
convention: for y ∈ R2 we set -y = -yy1 , i.e., the vertically flipped image of y. Then we have,
using the symmetry and anti-symmetry of the entries of the original kernel K:
k22(-y) = 2 [Kιι(-y) - Ki2(-y) - K2i(-y) + K22(Iy)]
=2 [κιι(y) + κi2(y) + K2i(y) + K22(y)]
= K10 1(y),
κ2ι(-y) = 2 [Kιι(-y) + Ki2(-y) - κ2i(-y) - K22(Iy)]
=2 [Kιι(y) - κi2(y) + K2i(y) - K22(y)]
= K10 2 (y).
78
Published as a conference paper at ICLR 2021
Thus the second row of K0 is basically the same as the first, only that the kernels swap with each
other and are internally flipped. This is a special case of the outcome in Cohen & Welling (2016a),
which is also described clearly in Weiler et al. (2018b): in group convolutional kernels which are
steerable with respect to finite groups, the kernels get copied and applied in all orientations de-
manded by the group.
What we would still like to understand is if we can also reverse the direction: That is, assume that
we start with a group convolutional kernel K0 of which we know that K220 (-y) = K101 (y) and
K20 1 (-y) = K10 2 (y) for all y ∈ R2 . If we then do a base change, we would like to know if the
resulting kernel consists of symmetric and antisymmetric entries. Namely, set
KK2111 KK1222 =K
=B-1 ∙ K0 ∙ B
Y -2) ∙仅 1 K22)∙(1 -1)
=(2	[K11 +	KI2	+ K21	+ K22]	1 [K11	-	KI2	+ K21	- K22])
∖[2	[K11 +	KI2	- K21	- K22]	2 [K11	-	KI2	- K21	+ K22力
The reader can easily check that we can deduce that K11 and K22 are symmetric and that K12 and
K21 are anti-symmetric. We have thus fully shown the equivalence of the kernel solutions in the
setting of steerable CNNs compared to the setting of group convolutional CNNs for the specific
group Z2 .
E.4	SO(3)-STEERABLE KERNELS FOR COMPLEX REPRESENTATIONS.
In the first two sections, we have discussed SO(2)-equivariant kernels (i.e., SE(2)-equivariant neural
networks) both over C and R. The situation over Rwas considerably more complicated and required
new arguments. In this section, we will discuss SO(3)-equivariant kernels (i.e., SE(3)-equivariant
neural networks) for complex representations. In Section E.5 we will then look at the real case,
which will essentially give the exact same results, thus differing somewhat from the considerations
about SO(2). Different from the earlier sections, we will from now on be less explicit and care
more about the general properties of the different functions and coefficients we consider. SO(3)-
equivariant networks with real representations have before been implemented in Weiler et al. (2018a)
and Thomas et al. (2018), among others.
E.4. 1 THE IRREDUCIBLE REPRESENTATIONS OF SO(3) OVER THE COMPLEX NUMBERS
In this section, we state the complex irreducible representations of SO(3). We will not state the
matrices explicitly since the matrix elements are considerably more complicated than in the earlier
examples that we saw. For each l ∈ N≥0, there is one irreducible unitary representation
Dl : SO(3) → U(Vl), where Vl = C2l+1.
The matrices Dl (g) for g ∈ SO(3) are called the Wigner D-matrices.29 There are, up to equiva-
lence, no other irreducible representations of SO(3) over C. A reference for all this is the original
work Wigner (1944).
We note that the indices for the dimensions in C2l+1 are -l, -l+1, . . . , l-1, l by general convention.
E.4.2 THE PETER-WEYL THEOREM FOR L2C (S2) AS A REPRESENTATION OF SO(3)
Here, we describe how L2C (S2), considered as a unitary representation via λ : SO(3) →
U(LC(S2)), with [λ(g)夕](x) = φ(g-1x), contains densely a direct sum of irreducible represen-
tations. For doing so, we proceed by first describing spherical harmonics without formulas and
stating their orthonormality properties, and then stating how they transform under rotation. This
will then yield the result. Note that we do not need to describe explicit formulas for the spherical
harmonics, which are again somewhat complicated since we are more interested in their properties
29Here, the letter “D” stands for “Darstellung” which is the German term for “representation”.
79
Published as a conference paper at ICLR 2021
in relation to Hilbert space theory and representation theory. A reference for all this is MacRobert
(1947).
The spherical harmonics are continuous functions Yln : S2 → C for l ∈ N≥0 and n = -l, . . . , l.
Thus, they are elements of L2C (S2). They have the following properties:
1.	DYlnYln00E =δll0δnn0 for all l, l0, n, n0.
2.	The linear span of the spherical harmonics is dense in L2C (S2).
3.	They transform as follows under rotation: λ(g)(Yln) = Pln0=-l Dln0n(g)Yln0 , where
Dln0n(g) are the matrix elements of the Wigner D-matrices defined in Section E.4.1.
Properties 1 and 2 together imply that the spherical harmonics form an orthonormal basis ofL2C(S2),
see Definition F.40. Let
Vl1 := spanC (Yln | n = -l, . . . , l).
Then we already obtain L2C(S2) =	l≥0Vl1. Now, let en ∈ C2l+1 be the n’th standard basis vector,
for n = -l, . . . , l. Then property 3 means that the linear map given on basis vectors by
f : Vl → Vl1, en 7→ Yln
is an isomorphism of unitary representations. More precisely, f is clearly a unitary transformation
and a linear isomorphism, and it is furthermore equivariant on basis vectors since
f (Dl(g)(en)) =f Xln0=-l Dln0n(g)en0
Xl0	0
n0=-l Dln0n(g)f(en0)
= Xln0=-l Dln0n(g)Yln0
= λ(g)(Yln)
= λ(g)(f(en)).
(30)
General equivariance then follows from equivariance on basis vectors. This concludes this section.
E.4.3 The Clebsch-Gordan Decomposition
Explicit formulas for the Clebsch-Gordan coefficients of SO(3) are given in Bohm & LoWe (1993).
The most important fact is the following: There is a decomposition
l+j
Vj 乳 Vl = M Vj
J =|l-j |
of representations. Furthermore, the Clebsch-Gordan coefficients hJM |jm; lni are all real numbers,
a fact that We Will use in Section E.5.
E.4.4 ENDOMORPHISMS OF VJ
As in the case of harmonic netWorks, this is again simple: We are considering representations over
C, and so Schur’s Lemma D.8 tells us that EndSO(3) (VJ) is 1-dimensional for each irrep J. We can
therefore ignore the endomorphisms once again.
E.4.5 Bringing Everything Together
NoW, With all this prior Work, let us determine the equivariant kernels K : S2 → HomC (Vl , VJ) for
the irreducible representations Dl : SO(3) → U(Vl ) and DJ : SO(3) → U(VJ). For this, We use
Eq. (23). Since each Vj appears only once in the direct sum decomposition of L2C (S2) according
to Section E.4.2 and since VJ can only appear once in the direct sum decomposition of a tensor
product Vj 0 Vi according to Section E.4.3 , we do not need the indices i and s. Furthermore, as
80
Published as a conference paper at ICLR 2021
mentioned in the last section, the endomorphisms are trivial, which is why we also do not need the
index r. Overall, we see that we simply have basis kernels Kj : S2 → HomC(Vl, VJ) for all j with
|l - J| ≤ j ≤ l + J.30 They are explicitly given by
八 j∣x)∙CGj(ji)∖
Kj(X)=	.	I
Mixi. CGJjM
for all x ∈ S2. Remembering thathjm|x)= Yjm(x), the individual matrix elements of Kj(x) are
then given by
j
hJM∣Kj(x)∣lni = X hJM∣jm; lni ∙ Yjm(x).
m=-j
This ends the discussion.
E.5	SO(3)-STEERABLE KERNELS FOR REAL REPRESENTATIONS
In this section, we want to argue why the results in the last section transfer over to the real case
as well. Most of the investigations in this section are probably well-known. However, we were
not able to find sources that explicitly explain the representation theory of SO(3) over the real
numbers, and so we develop lots of it here from scratch. We thereby make use of the theory over
C, some results about real spherical harmonics, and the general theory of real and quaternionic
representations outlined in Brocker & Dieck (2003). We need to somewhat turn the order around in
this section in order to develop the results. Therefore we first investigate the Peter-Weyl theorem,
then look at the endomorphism spaces of the appearing irreducible representations and afterward, as
a consequence, show that the representations appearing in the decomposition ofL2R(S2) are already
exhaustive.
E.5.1 THE PETER-WEYL THEOREM FOR L2R(S2) AS A REPRESENTATION OF SO(3)
The most important finding is the following, which is taken from Gallier & Quaintance (2020): One
can do a base change for the spherical harmonics as follows to obtain real versions of them. Namely,
let
f √√2 国n-(-1)nYTn) if n< 0,
r Yln =(匕0	if n = 0,	(31)
f √2 (Yrn + (-1)n Yn if n> 0.
One can then show that these functions are real-valued continuous functions and therefore rYln ∈
L2R(S2). Furthermore, they are an orthonormal basis of this space. We can then, as before, set rVl1
as the span of the rYln ∈ L2R(S2) and obtain a decomposition
L2R(S2) = Mdl≥0rVl1.
We need to understand the transformation properties of these real-valued spherical harmonics under
rotation. To understand this explicitly, we set Bl ∈ C(2l+1)×(2l+1) as the (complex) base change
matrix between the complex and real spherical harmonics. Its entries are given according to Eq. (31)
such that the following relation holds for all n = -l, . . . , l:
l
r Yln = X Bnn ∙ Yln’.
n0=-l
Since for a given l, both the complex and real spherical harmonics are linearly independent, the
matrix Bl is invertible. Let Bl-1 be its inverse. Then it is generally known from linear algebra that
30We saw that VJ is a direct summand of Vj Z ^½ if and only if |l — j| ≤ J ≤ l + j. By doing case
distinctions, one can show that this is the case if and only if |l - J | ≤ j ≤ l + J.
81
Published as a conference paper at ICLR 2021
we also obtain the inverse relation:
l
Yln = X (B-1)n0n ∙rYin.
n0 =-l
Using both these relations and the rotation properties of the complex spherical harmonics from
Section E.4.2 we obtain the following rotation property for the real spherical harmonics:
l
λ(g)(rγln) = X Bnιn∙λ(g)(γn1)
n1 =-l
ll
=X BTn X Dn2n1(g) ∙xn2
n1 =-l	n2 =-l
ll	l
=X BnIn X Dn2n1(g) ∙ X (B-Iynn JYln
n1 =-l	n2 =-l	n0 =-l
l	ll
=XXX (B-I)n0n2 ∙ Dn2n1 (g) ∙ BnIn rYT
n0 =-l n1 =-l n2 =-l
l	00
=E (B-1∙ Dι(g) ∙ Bl )nn ∙r 匕n.
n0=-l
Now if We set TDI (g) := B-1 ∙ Di (g) ∙ Bi, then We obtain the transformation property
l
λ(g)(rYin)= X rDi(g)n0n JYln	(32)
n0=-i
Which is analogous to the one in Section E.4.2.
Lemma E.7. rDi (g) n0n ∈ R for all l ≥ 0, n0, n = -l, . . . , l and g ∈ SO(3).
Proof. Note that since rYin is a real-valued function, the rotation λ(g)(rYin) is real-valued as Well.
Thus, itis in the space L2R(S2). The real spherical harmonics are a basis of this space, Which means
that the coefficients When expanding λ(g)(rYin) in this basis are necessarily real as Well. These
coefficients are precisely given by the rDι(g)n n according to Eq. (32).	□
NoW, We have the choice to vieW rDi as either a real or a complex representation, but first We take
the complex vieWpoint and see it as a function rDi : SO(3) → GL(C2i+1). NotationWise, the
folloWing is important: the “r” in rDi indicates that the elements in this matrix are real but does not
tell us on Which space it acts. This Will alWays be clarified by the context. We have the folloWing:
Lemma E.8. rDi : SO(3) → U(C2i+1) is an irreducible unitary representation and isomorphic to
Di.
Proof. First of all, it is an actual linear representation since
rDi(gg0) = B-1 Di(gg0)Bι = B-1Dι(g)BιB-1Dι(g0)Bι = rDι(g) JDi(g0)
Where We used that Di is a linear representation. NoW since Yin and rYin are both orthonormal
bases of L2C(S2), the base change matrix Bi needs to be a unitary matrix. Consequently, rDi(g) =
Bi-1Di (g)Bi is as a product of unitary transformations itself unitary, Which means that rDi is a
unitary representation. Furthermore, we obtain Bi ∙ rDι(g) = Dι(g) ∙ Bi, which means that Bi
gives an isomorphism rD ι = Di of unitary representations. From the fact that Di is irreducible, we
obtain that rD ι is irreducible as well.	□
Now we take the real viewpoint. Let rVi = R2i+1.
Lemma E.9. rDi : SO(3) → O(rVi) is an irreducible orthogonal representation.
82
Published as a conference paper at ICLR 2021
Proof. rDl (g) is a unitary matrix for each g ∈ SO(3) by Lemma E.8, and since its matrix elements
are real by Lemma E.7, it automatically is an orthogonal matrix. If it was reducible, then there
would be a real base change matrix that brings rDl in a nontrivial block-diagonal shape. However,
this base change would in particular be complex, meaning that we would conclude that the complex
version of the representation rD ι is reducible. But it is not, due to Lemma E.8.	□
Now, remember that L2R(S2) = Lcl≥0rVl1 and that r Vl1 is generated from the real spherical har-
monics. Also, remember that the real spherical harmonics transform as in Eq. (32). Thus, with
the same arguments as in Eq. (30) We obtain rVn = rVι, which is from the preceding lemmas
an irreducible orthogonal representation. Thus, we have found the Peter-Weyl decomposition of
L2R(S2).
E.5.2 ENDOMORPHISMS OF rVJ
In the next section, we will show that the rD J : SO(3) → O(rVJ) already given an exhaustive list
of the irreducible representations of SO(3) over the real numbers. In this section, we first describe
their endomorphism spaces since this will help in showing that there cannot be any other irreducible
representations. Fortunately, the situation is again simple:
Proposition E.10. EndSO(3),R (r VJ) is one-dimensional for each J ≥ 0.
Proof. Let f : r VJ → r VJ be an endomorphism. Since r VJ = R2J+1 we can view f as a matrix in
R(2J +1)×(2J +1). That f is an endomorphism then means
f JDJ(g) = rDJ (g)∙ f
for all g ∈ SO(3). Now note that as a real matrix, f is in particular a complex matrix, i.e., f ∈
C(2J+1)×(2J+1). Also, remember that we can view rDJ also as a complex irreducible representation
rDJ : SO(3) → U(C2J+1) by Lemma E.8. What this means is that f ∈ EndSO(3),C(C2J+1),
which is isomorphic to C by Schur’s Lemma D.8. Thus, f is a complex multiple of the identity.
Since f is a real matrix, it is thus a real multiple of the identity. The result follows.	□
E.5.3 General Notes on the Relation between Real and Complex
Representations
In the next section we show that there can, up to isomorphism, not be other irreducible represen-
tations than the rDl : SO(3) → O(rVl). In order to do so, we first need to better understand the
relationship between real and complex representations of compact groups. These investigations will
carry over to the investigations for O(3) that we do in Section E.6 as well.
The following definition ofa classification of real irreducible representations ofa compact group G
can be found in BrOCker & Dieck (2003), Theorem II.6.7. In this book, it is a theorem, since the
authors give an independent but equivalent definition of these notions.
Definition E.11 (Real, Complex, and Quaternionic Type Irreducible Representations). Let ρ : G →
O(V) be a real irreducible representation ofa compact group G. Then ρ is said to be of
1.	real type if EndG,R(V) == R,
2.	complex type if EndG,R(V) == C and
3.	quaternionic type if EndG,R(V) == H, where H are the quaternions.
Here, these isomorphisms respect both addition and multiplication. The multiplication in the endo-
morphism spaces is thereby given by composition of functions.
Furthermore, BrOCker & Dieck (2003) shows in Theorem II.6.3 that there is no other possibility for
an irreducible real representation, i.e., they can be completely categorized by being of real, complex
or quaternionic type. Additionally, since R, C and H already differ in their R-dimension, it is
enough to check whether the R-dimension of an endomorphism space is 1, 2 or 4 in order to do the
classification.
83
Published as a conference paper at ICLR 2021
In order to compare real and complex representations we need to define two functors between
those:31
Definition E.12 (Restriction and Extension). Let cρ : G → GL(cV ) be a complex representation.
Furthermore, let rρ : G → GL(rV ) be a real representation. Then we define their restriction and
extension as follows:
1.	Set r(cV ) as the R-vector space that has the same underlying abelian group as cV and
the scalar multiplication from R which is the restriction of the multiplication from C. The
restriction r(cρ) : G → GL(r(cV )) is defined as the exact same map as cρ, only that
r(cρ)(g) : r(cV ) → r(cV ) is now viewed as an automorphism of real vector spaces.
2.	We define the extension by e(r V) := C XR T V, where C is regarded as an R-Vector space.
This construction becomes a C-vector space by scalar multiplication Z ∙ (z0 0v) := (zz0)0v.
We can then define e(rρ) : G → GL(e(rV)) by setting e(rρ)(g) := idC X(rρ(g)).
Note that the extension operation doubles the R-dimension, whereas for the restriction it stays equal.
Therefore, we can not hope that these operations are inverse to each other. However, we have the
following, almost as nice statement:
Proposition E.13. For each real representation ρ : G → GL(V) there is a natural isomorphism
r(e(V)) = V ㊉ V of R-representations.
Proof. This is the first statement in Brocker & Dieck (2003), Proposition II.6.1.	口
The following definition is actually not the definition that Brocker & Dieck (2003) formulate. How-
ever, it is an equivalent characterization that follows from their Proposition II.6.6 (vii), (viii) and (ix)
and is more convenient for our needs:
Definition E.14 (Real Type Complex Representation). Let ρ : G → GL(V) be a complex irre-
ducible representation. Then ρ is called of real type if there is an isomorphism of real representations
r(V) = U ㊉ U where
1.	ρU : G → GL(U ) is an irreducible real representation and
2.	r(ρ) : G → GL(r(V)) is the restriction of ρ, as defined in Definition E.12.
Proposition E.15. Assume G is a compact group such that all complex irreducible representations
are of real type. Then also all real irreducible representations are of real type.
Proof. This follows from Brocker & Dieck (2003), Proposition II.6.6 (ii) and (iii).	口
Proposition E.16. Let ρ : G → GL(V) be an irreducible real representation of real type. Then its
extension e(ρ) : G → GL(e(V)) given as in Definition E.12 is an irreducible complex representa-
tion (also of real type).
Proof. This is precisely Brocker & Dieck (2003), Proposition II.6.6(i).	口
E.5.4 THE IRREDUCIBLE REPRESENTATIONS OF SO(3) OVER THE REAL NUMBERS
The rough strategy is to use the fact that the rDl, viewed as complex irreducible representations, are
an exhaustive list of all the complex irreps. Then, using the restriction and extension operators r and
e between real and complex representations, we can show that in the specific case of SO(3), there
can not be any other real irreducible representations than the rDl, viewed as real representations.
Lemma E.17. All complex irreducible representations of SO(3) are of real type.
31We only define these functors on objects and not on morphisms. The reason is that we will never explicitly
use their definitions on morphisms. More details on this can be found in Brocker & Dieck (2003), including
other functors which are needed in the general theory. The reader should not worry if he or she does not know
what a functor is.
84
Published as a conference paper at ICLR 2021
Proof. From Section E.4.1 and Lemma E.8 we know that the rDl : SO(3) → U(C2l+1) give us, up
to equivalence, all the complex irreducible representations of SO(3). According to Definition E.14
we now need to understand that its restriction splits into the direct sum of twice the same irreducible
real representation. We do this as follows:
We can write r(C2l+1) = R2l+1 ㊉(iR)2l+1 = r^½ ㊉ irV^, which is a decomposition of C2l+1 when
viewed as an R-vector space. Then, we can note that both
rDl : SO(3) → O(rVl) and
rDl : SO(3) → O(irVl)
are well-defined R-representations, which follows from the fact that the matrix elements are all real.
Furthermore, the first map is actually an irreducible real representation by Lemma E.9. The second
one is isomorphic to the first since one can show that
i : r % → irVι, a→ i ∙ a
is an isomorphism of real SO(3)-representations. This gives us precisely the splitting of r(C2l+1)
as a representation that We were looking for.	口
Corollary E.18. All irreducible real representations of SO(3) are of real type.
Proof. This follows directly from LemmaE.17 and Proposition E.15.	口
Proposition E.19. The rDl : SO(3) → O(r Vl ) are, up to equivalence, all real irreducible repre-
sentations of SO(3).
Proof. Assume that ρ : SO(3) → GL(V ) is an irreducible real representation of SO(3). It is of
real type by Corollary E.18. By Proposition E.16, the extension e(ρ) : G → GL(e(V )) is an
irreducible complex representation. Since the rD l give us all complex irreducible representations
up to equivalence by Section E.4.1 and Lemma E.8, there is an equivalence of complex SO(3)-
representations e(V) = C21+1 for some l. Since functors respect isomorphisms (and equivalences
are isomorphisms in the categories of G-representations) and the restriction operation is a functor,32
and using Proposition E.13 as well as the proof of Lemma E.17 we obtain:
V ㊉ V = r(e(V)) = r(C2l+1) = r% ㊉ ir% = r% ㊉ r%.
Using the Krull-Remak-Schmidt Theorem B.39, we see that there is an isomorphism of SO(3)-
representations V = r ^½. This finishes the proof.	口
E.5.5 The Clebsch-Gordan Decomposition
We are almost there. The only thing left to understand is the Clebsch-Gordan decomposition. Re-
member the following from Section E.4.3: For the complex irreducible representations there are
decompositions
l+j
Vj 0 V1 =㊉ Vj
J =|l-j |
where on each space, the representations Dj , Dl and Dj are given by the Wigner D-matrices.
Furthermore, the Clebsch-Gordan coefficients are all real. Now, we know that rDl is, as a complex
representation, isomorphic to Dl by Lemma E.8, and such a representation then acts on C2l+1 as
well. Consequently, we also get the decomposition
C2j +1 0 C2l+1 ==
l+j
M	C2j+1
j=|l-j|
of the complex representations rD j and rDl . Obviously, the Clebsch-Gordan coefficients can be
chosen to be exactly the same as before, and thus they are again real.
32The reader does not need to know what a functor is if he or she believes these statements.
85
Published as a conference paper at ICLR 2021
Let the above isomorphism be called f. Now, we can view all involved vector spaces as R-vector
spaces as well. Furthermore, we have subspaces rVj = R2j+1, rVl = R2l+1 and rVJ = R2J+1
which are also invariant under the representations rDj, rDl and rDJ. Consequently, we can just
restrict the isomorphism above to a map
l+j
f|：r Vj 乳r 匕 → ㊉ r VJ.
J=|l-j|
which is well-defined since the Clebsch-Gordan coefficients are real. It needs to be injective, since
it is a restriction of an isomorphism. For dimension reasons, the restriction then needs to be an
isomorphism, and obviously, it has the exact same Clebsch-Gordan coefficients as the original map
f.33
E.5.6 Bringing Everything Together
By what we’ve shown in the last sections, we see that the situation is basically the same as in
Section E.4.5. The only thing that changes is that we now use the real spherical harmonics, and
therefore the complex conjugation disappears. What this overall means is the following: let rDl :
SO(3) → O(rVl) and rDJ : SO(3) → O(rVJ) be the representations determining the input and
output fields. Then a basis for steerable kernels K : S2 → HomR(rVl , rVJ) is given by kernels
Kj : S2 → HomR(rVl, rVJ) for all |l - J| ≤ j ≤ l + J. The matrix elements are given by
j
hJM|Kj(x)∣lni = E hJM jm; ln〉∙ rYm(x).	(33)
m=-j
E.6 O(3)-STEERABLE KERNELS FOR COMPLEX REPRESENTATIONS
In this section, we deal with O(3)-equivariant kernels for complex representations and then, in the
next section, will transport the results over to real representations. In the earlier examples, we saw
that the Peter-Weyl decomposition of L2K (X) always contained each irreducible representation of
the symmetry group exactly once. The example of O(3) is the first in which this is not the case:
parity will play a role in determining which irreducible representations make their way in the space
of square-integrable functions and which do not. Overall, we hope that the example of O(3) is
a sufficient justification for our use of the multiplicities mj of irreducible representations that we
considered in all our theorems. O(3)-equivariant networks are to the best of our knowledge not
described in any published work yet.
E.6. 1 THE IRREDUCIBLE REPRESENTATIONS OF O(3)
The most important observation is the following, after which we can deduce the irreducible repre-
sentations of O(3) from those of SO(3):
Lemma E.20. Let Z2 := ({ — 1, +1}, ∙) be the group with two elements. Then the map
• : Z2 X SO(3) → O(3), (s,g) → Sg
is an isomorphism of groups.
Proof. It is a group homomorphism since s ∈ {—1, +1} can be represented by a multiple of the
identity matrix, and as such it commutes with every matrix g. That • is an isomorphism follows
since all matrices in O(3) either have determinant 1 or —1. The matrices with determinant 1 form
SO(3) and are the image of {+1} × SO(3). The matrices with determinant —1 are the image of
{ —1}× SO(3).	□
Note the fact that for g ∈ SO(3), —g has determinant —1, which we used in the proof. This does
only hold for g ∈ SO(d) with d being odd. Therefore, the above lemma is not true for d even. In the
even case, we obtain a semidirect product and the story complicates somewhat.
33The reason for this is that the standard basis vectors in Ck which are used for the Clebsch-Gordan coeffi-
cients are exactly the standard basis vectors in Rk ⊆ Ck by definition of this embedding.
86
Published as a conference paper at ICLR 2021
Earlier, we already considered tensor product representations of one and the same group. A related
notion is that of tensor product representations of two different groups:34
Definition E.21 (Tensor Product Representation). Let G and H be two compact groups. Let ρG :
G → GL(VG) and ρH : H → GL(VH) be representations of the two groups G and H. Then the
tensor product representation is given by
PG 0 PH : G X H → GL(VG 0 VH),
[(PG 0 PH )(g, h)] (VG 0 VH ) ：= PG(g)(VG)0 PH (h)(vH ).
This is again a linear representation.
Proposition E.22. Representatives of isomorphism classes of irreducible representations of G × H
are given precisely by all the PG0PH, where PG and PH run through representatives of isomorphism
classes of irreducible representations of G and H, respectively.
Proof. This is proven in chapter II, Proposition 4.14 and 4.15 of Brocker & Dieck (2003).	□
It is important to note that the proof of the above proposition uses the property of the complex
numbers to be algebraically closed in crucial steps, and therefore it is unclear how exactly a gener-
alization to representations over the real numbers looks like. Therefore, we will not use the above
proposition in our later considerations for real representations of O(3).
However, in our current situation, we can apply it without problems. This proposition, together with
Lemma E.20, suggests that we should understand the irreducible representations of Z2. We already
saw this for real representations before and essentially obtain the same result:
Lemma E.23. The irreducible representations of Z2 are up to equivalence precisely the following
two, which we state for simplicity only on the generator:
P+ ： Z2 → GL(C), P+(-1) = idC
P- ： Z2 → GL(C), P-(-1) = -idC .
Proof. This can be shown in exactly the same way as in Section E.3.1.	□
Thus we are ready to state our result about the irreducible representations of O(3):
Proposition E.24. The irreducible representations of O(3) are up to equivalence given as follows:
for each l ∈ N≥0 there are precisely two representations Dl+ ： O(3) → U(Vl+) and Dl- ： O(3) →
U(Vl-) with Vl+ = C2l+1 = Vl-, given as follows:
Dl+ (sg) = Dl (g) for all s ∈ Z2, g ∈ SO(3).
Dl-(sg) = sDl(g) for all s ∈ Z2, g ∈ SO(3).
Proof. Remember from Section E.4.1 that the irreducible representations of SO(3) are given by the
Wigner D-matrices Dl . From Lemma E.23 we know that the irreducible representations of Z2 are
given by p+ and p-. From the isomorphism O(3) = Z2 × SO(3) from Lemma E.20 and from
Proposition E.22 we thus obtain that the irreducible representations of O(3) are precisely given by
all P+ 0 Dl and P- 0 Dl. We now show that P- 0 Dl is equivalent to Dl-: We have
P- 0 Dl ： O(3) → GL(C 0 Vl), (P- 0 Dl)(sg)(z 0 V) = sz 0 [Dl (g)] (V).
Now, consider the linear isomorphism f ： C 0 Vl → Vl+, z 0 V 7→ zV. We only need to check that
it is equivariant and are then done:
f ( [(p- 0 Dι)(sg)] (z 0 V)) = f (sz 0 [Dι(g)](v))
=Sz ∙ Dl(g)] (V)
= [sDl (g)](zV)
= [Dl-(Sg)](f(z 0 V)).
The statement about Dι+ can be shown using the exact same map f.	□
34It is not a direct generalization due to the presence of two different group elements being applied.
87
Published as a conference paper at ICLR 2021
E.6.2 THE PETER-WEYL THEOREM FOR L2C(S2) AS REPRESENTATION OF O(3)
The considerations in this section follow almost entirely from Section E.4.2. There we saw that, as
a representation over SO(3), we have a decomposition
LC (S ) = MVl1
l≥0
with the spaces Vl1 being spanned by the spherical harmonics Yln, n = -l, . . . , l. We immediately
see that in L2C(S2), viewed as a representation over O(3), there is not enough space for all the
irreducible representations, since they appear in pairs as shown in Proposition E.24.35 Thus, we
need to figure out which irreducible representations are present and which are not. The core of this
question is answered by the following proposition:
Lemma E.25 (Parity in spherical harmonics). The spherical harmonics obey the following parity
rules:
Yn(Sx) = sl∙ Yn(X)
for all l ≥ 0, n = -l, . . . , l, s ∈ Z2 and x ∈ S2.
Proof. This is a well-known property of the spherical harmonics.
□
Thus, together with Section E.4.2 we get the following transformation behavior of spherical har-
monics under the group O(3), where s ∈ Z2 and g ∈ SO(3):
λ(sg)(Yln) = slλ(g)(Yln)
l
= sl X Dln0n(g)Yln0
n0=-l
l
=X WDTn(g))Yln0
n0=-l
= (Pln0=-l Dln+0n(sg)Yln0, l even
Pln0=-l Dln-0n(sg)Yln0, l odd.
Thus, we obtain the following decomposition of L2C (S2):
LC(S ) = M Vl1+ ㊉ MVl1-.
l≥0	l≥0
l even	l odd
Here, Vιι+ and VH- are generated from the spherical harmonics of order l and We have Vιι+ = ^½+
and Vιι- = Vι- as representations according to the transformation behavior we saw above.
E.6.3 The Clebsch-Gordan Decomposition
Remember from Section E.4.3 that we have a decomposition of SO(3)-representations
ι+j
Vj 乳 Vι = M Vj
j =∖l-j∖
given by real Clebsch-Gordan coefficients. Now for O(3), remember that as vector spaces we have
for all j (and equally for l and J) equalities Vj = Vj- = Vj+, and so we guess that in the iso-
morphism above, we just need to figure out the correct signs in order to be compatible with the
35With this, we mean the following: the irreducible representations of SO(3) already cover L2C (S2). O(3)
has even more irreducible representations than SO(3), so it is a priori clear that they cannot all fit into L2C(S2).
88
Published as a conference paper at ICLR 2021
corresponding representations. The idea is that “multiplying the signs at the left” should lead to the
“sign at the right”, and this paradigm leads us to believe that there are the following isomorphisms:
l+j	l+j
Vj+ 乳 VU = M VJ +,	Vj+ 氧 %- = M Vj-,
J=|l-j|	J =|l-j |
l+j	l+j
Vj-㊈ V1+ = M VJ-,	Vj-乳 Vi- = M VJ +.
J=|l-j|	J =|l-j |
We just show the lower-left isomorphism since the arguments are always the same. So, assume
that f : Vj- 0 ^½ → LJjIl-j∣ Vj is an isomorphism and thus in particular intertwines the given
representations. Now, We take the exact same map f : Vj- 0 ^½+ → LJjIl-j∣ VJ- and only need
to figure out that it is equivariant with respect to the given representations, using the same property
for the original isomorphism we started with:
f ◦ [Dj-(sg) 0 Dl+(sg) = f ◦ [s(Dj(g) 0 Dl(g))]
l+j
= s M DJ(g) ◦ f
J=Il-j I
l+j
=	DJ-(sg) ◦ f.
J =Il-jI
This shows the claim. From these considerations, it also follows that the Clebsch-Gordan coef-
ficients do not in any way depend on the signs of the spaces Vj, Vl, VJ. Thus, we write them
generically as hJM |jm; lni.
E.6.4 ENDOMORPHISMS OF VJ
As always over C, Schur’s Lemma D.8 shows that the endomorphism spaces are 1-dimensional, and
thus we can ignore endomorphisms.
E.6.5 Bringing Everything Together
Now we can finally compute the basis for steerable kernels. The section on the Clebsch-Gordan
decomposition suggests that we need to do a case distinction for this. Namely, the possible kernels
depend on the signs of Vl and VJ . The results basically follow analogously to the results in Section
E.4.5.
STEERABLE KERNELS K : S2 → HomC(Vl+, VJ+):
VJ+ can only be in a tensor product Vj 0 Vl+ if the sign of j is positive. Spaces Vj1+ appear in
the tensor product decomposition of L2C(S2) precisely for even j, according to Section E.6.2. Thus,
a basis for steerable kernels is given by all Kj with even j ∈ |l - J|, . . . , l + J . It has matrix
elements
j
hJM∣Kj(x)∣lni = E hJM|jm; ln〉∙ Yjm(x),
m=-j
exactly as in Section E.4.5.
STEERABLE KERNELS K : S2 → HomC(Vl+, VJ-):
Analogously, a basis for steerable kernels is given by all Kj , with odd j ∈ |l - J |, . . . , l + J .
STEERABLE KERNELS K : S2 → HomC(Vl-, VJ+):
Again, a basis for steerable kernels is given by all Kj with odd j ∈ |l - J |, . . . , l + J .
89
Published as a conference paper at ICLR 2021
STEERABLE KERNELS K : S2 → HomC(Vl-, VJ-):
As in the first case, a basis for steerable kernels is given by all Kj with even j ∈ |l - J|, . . . , l+J .
Thus, we have determined all kernel bases for the group O(3) over the complex numbers. Compared
to SO(3), we see that the kernel spaces get roughly halved. The reason for this is that with a bigger
symmetry group, the kernel needs to obey more rules, which means that the kernel constraint has
fewer solutions.
E.7 O(3)-STEERABLE KERNELS FOR REAL REPRESENTATIONS
Basically, we can argue exactly as in Section E.5.4 in order to transport the results for complex rep-
resentations over to the real world. We shortly sketch the procedure and outcome. As we know from
Section E.3.1, ρ- : Z2 → O(R) and ρ+ : Z2 → O(R) are the only irreducible real representations
of Z2. Thus, for each l ≥ 0 we obtain two irreducible real representations rDl+ : O(3) → O(rVl+)
and rDl- : O(3) → O(rVl-). As before, they also act on complex vector spaces and are as such
isomorphic to the complex irreducible representations of O(3). One can then show as in Lemma
E.17 that all complex irreducible representations are of real type since they split into two copies
of the real version of this representation. Thus, by Corollary E.18, all real irreducible representa-
tions are of real type, and this means that we can proceed exactly as in Proposition E.19 in order
to show that the rDl+ and rDl- are already all the irreducible real representations of O(3) up to
equivalence.
For the Peter-Weyl decomposition of L2R(S2), we only need to note that the real spherical harmonics
emerge with a base change from the complex ones, as seen in Eq. (31), and thus fulfill the same
parity rules as the complex spherical harmonics. This gives us a decomposition
LR(S2)= M(r%+)㊉ M(r%-).
l≥0	l≥0
l even	l odd
For the Clebsch-Gordan coefficients, we again get decompositions
l+j
r V ㊈r 匕=M r Vj
J=|l-j |
where the signs on the left must “multiply to” the signs on the right, as in Section E.6.3. Finally,
the endomorphism spaces must be 1-dimensional since the endomorphism spaces of the complex
versions are 1-dimensional.
Overall, we obtain the same kernels as in Section E.6.5, only that we need to use the real spherical
harmonics as our steerable filters and can get rid of the complex conjugation.
F Mathematical Preliminaries
In this chapter, we state mathematical preliminaries that we use throughout the earlier chapters. In
this whole chapter, K is one of the two fields R or C.
F.1 Topological Spaces, Normed S paces, and Metric Spaces
Since in this work, we want to develop the theory of representations over compact groups, and since
this is a topological property, we need to formulate some topological concepts (Conway, 2014).
Additionally, the vector spaces on which our compact groups act also carry a topology, mostly
coming from their Hilbert space structure.
Definition F.1 (Topological Space, Open Sets, Closed Sets). A topological space (X, T) consists
of a set X and a set T of subsets of X, called the open sets, such that arbitrary unions and finite
intersections of open sets are open. In particular, X and the empty set 0 are open. Closed sets are the
complements of open sets and fulfill dual axioms: arbitrary intersections and finite unions of closed
sets are closed.
90
Published as a conference paper at ICLR 2021
Let in the following X and Y be topological spaces.
Definition F.2 (Open Neighborhood). Let x ∈ X . An open set U ⊆ X is called open neighborhood
of x if x ∈ U .
Definition F.3 (Hausdorff Space). X is called a Hausdorff space if two distinct points can always
be separated by open sets, i.e., for all x, y ∈ X there exist Ux , Uy open such that x ∈ Ux , y ∈ Uy,
and Ux ∩ Uy = 0.
In this work, all topological spaces are Hausdorff.
Definition F.4 (Subspace). Assume A ⊆ X is a subset. Then the set TA := {U ∩ A | U ∈ T} is a
topology for A and thus makes A a topological space as well. It is called a subspace of X .
Whenever we consider a subset of a topological space, it is viewed as a topological space with this
construction.
Definition F.5 (Closure, Density). For A ⊆ X, its closure A is defined as the smallest closed subset
of X that contains A. Equivalently, it is the intersection of all closed_subsets of X containing A,
which is closed by the axioms of a topology. A is called dense in X if A = X.
Definition F.6 (Continuous Function, Homeomorphism). A function f : X → Y is called continu-
ous if preimages of open sets are always open. Equivalently, for each point x0 ∈ X and each open
neighborhood V of f(x0) there is an open neighborhood U ofx0 such that f(U) ⊆ V .
A homeomorphism is a continuous bijective function with a continuous inverse.
Note that compositions of continuous functions are continuous as well.
Definition F.7 (Open Cover, Compact Space). An open cover ofX is a family of open sets {Ui}i∈I
that cover X, i.e., X = Si∈I Ui. X is called compact if all open covers have a finite subcover, that
is: For all open covers {Ui}i∈I there exists a finite subset J ⊆ I such that {Ui}i∈J is still an open
cover of X .
Proposition F.8. If X is compact and f : X → Y is continuous, then f(X) ⊆ Y is compact as
well. In particular, if f surjective, then Y is compact.
Proof. See Sutherland (1975), Proposition 13.15.	□
Proposition F.9. Let f : X → Y be a continuous bijection and assume that X is compact and that
Y is Hausdorff. Then the inverse f-1 is continuous as well and thus f is a homeomorphism.
Proof. See Sutherland (1975), Proposition 13.26.
□
Definition F.10 (Product Topology). The product topology on X × Y is the coarsest (i.e., smallest
in terms of inclusion) topology that makes both projections pX : X × Y → X and pY : X × Y → Y
continuous.
If Z is a third topological space and we have two continuous functions fX : Z → X and fY : Z →
Y , then the function fX × fY : Z → X × Y , z 7→ (fX (z), fY (z)) is continuous as well.
Definition F.11 (Quotient Map, Quotient Space). A continuous function f : X → Y is called a
quotient map if f is surjective and if U ⊆ Y is open if and only if f-1 (U) ⊆ X is open.
Let 〜be any equivalence relation on X and X/〜be the quotient set formed by identifying equiva-
lent elements. Let q : X → X/〜be the canonical function sending each element to its equivalence
class. We define U ⊆ X/〜to be open if q-1(U) ⊆ X is open. Then q is a quotient map and X/〜
is called a quotient space.
Proposition F.12 (Universal property of Quotient Maps). Let q : X → X/〜be a standard quotient
map and f : X → Y be any continuous function such that f (x) = f (x0) whenever X 〜x0. Then
there is a unique ContinUoUSfUnCtion f : X/〜 → Y such that the following diagram commutes:
X —f→ Y
q
X/〜
91
Published as a conference paper at ICLR 2021
f is given on equivalence classes by f ([x]) = f (x).
Proof. See Conway (2014), Proposition 2.8.7.
□
It can be shown that all quotient maps are equivalent to a construction of the form q : X → X/〜.
Namely, for a quotient map f : X → Y, define 〜by X 〜χ0 if f (x) = f (χ0). Then the map
f : X/〜 → Y, [x] → f (x) is a well-defined continuous map by the universal property of quotient
maps Proposition F.12. One can show that this is a homeomorphism. Thus for a quotient map
f : X → Y we also call Y a quotient space.
Our route for defining concrete topologies is in most cases through the existence of inner products
on Hilbert spaces, which will be defined in detail in Definition F.32. Namely, inner products define
norms, which define metrics (Kaplansky, 2001), which in turn define topologies. For this, we need
some definitions:
Definition F.13 (Norm). Let V be a K-vector space, A norm on V is a map ∣∙∣ : V → R≥o with
the following properties for all λ ∈ K and v, w ∈ V :
1.
2.
3.
∣v ∣ = 0 if and only if v = 0.
kλvk = ∣λ∣∙kv∣.
Triangle inequality: ∣v + w∣ ≤ ∣v ∣ + ∣w∣.
If h∙∣∙i : V × V → K is an inner product on a Hilbert space, then it defines a norm ∣∙∣ : V → R≥o
by l∣χ∣ := phχ∣χ).
Definition F.14 (Metric). Let Y be a set. A metric on Y is a function d : Y × Y → R≥0 with the
following properties for all x, y, z ∈ Y :
1.
2.
3.
d(x, y) = 0 if and only if x = y .
Symmetry: d(x, y) = d(y, x).
Triangle inequality: d(x, z) ≤ d(x, y) + d(y, z).
A norm k ∙ k : V → R≥o defines a metric d : V X V → R by setting d(x, y) := ∣∣x - y k. In turn,
a metric defines a topology as follows: open balls are given by all sets of the form B (x) := {y ∈
V | d(x, y ) < } for all x ∈ V and > 0. Open sets are then defined as arbitrary unions of arbitrary
open balls.
Additionally, we need notions about convergence in this work. Since we will deal with them mostly
in the context of metric spaces (with normed vector spaces and Hilbert spaces being special cases,
as explained above), we focus on these notions for metric spaces.
Definition F.15 (Convergent Sequence). Let Y be a metric space. Then a sequence (yk)k in Y is
said to converge to y if for all > 0 there is a k ∈ N such that yk ∈ B(y) for all k ≥ k.
With this in mind, one can give an equivalent definition of continuity that applies to metric spaces:
Definition F.16 (Continuity in Metric Spaces). A function f : Y → Z between metric spaces is
continuous in y ∈ Y if for each sequence (yk)k of points yk ∈ Y converging to a point y ∈ Y,
we also have that the sequence f(yk) converges to f(y). This can be understood in terms of the
function “commuting with limits”:
Iim f(yk) = f ( Iim yk)∙
k→∞	k→∞
Furthermore, f : Y → Z is called continuous if it is continuous in all points y ∈ Y .
Equivalently, the following holds: f : Y → Z is continuous in y ∈ Y if and only of for all > 0
there is a δ > 0 such that f (Bδ(y)) ⊆ B(f (y)).
Definition F.17 (Uniform Continuity). A function f : Y → Z between metric spaces is called
uniformly continuous if for each > 0 there is a δ > 0 such that for all y, y0 ∈ Y with dY (y, y0) < δ
we obtain dY (f (y), f(y0)) < .
92
Published as a conference paper at ICLR 2021
The following is a result we use several times in the main text:
Proposition F.18. Let f : V → V 0 be a linear function between normed vector spaces. Then the
following are equivalent:
1.	f is uniformly continuous.
2.	f is continuous.
3.	f is continuous in 0.
Proof. Trivially, 1 implies 2, which in turn implies 3. Now assume 3, i.e., f is continuous in 0. Let
> 0. Then by continuity in 0, there exists δ > 0 such that for all v ∈ V with kvk = kv - 0k < δ
we obtain kf (v)k = kf (v) - f (0)k < . Now let v, v0 ∈ V be arbitrary with kv - v0 k < δ. Then
by the linearity of f we obtain:
kf(v)-f(v0)k = kf(v-v0)k<e,
which is exactly What We wanted to show.	口
Sometimes, sequences look like they converge since their elements get ever closer to each other.
However, not all such sequences need to converge. Therefore, there is the following notion:
Definition F.19 (Cauchy Sequence). Let Y be a metric space. A sequence (yk)k in Y is a Cauchy
Sequence if for all > 0 there is k ∈ N such that for all k, k0 > k we have d(yk, yk0 ) < .
For example, one can consider the metric space R \ {0} together with the usual metric. Then the
sequence ")卜 is a Cauchy sequence but does not converge since the limit (in R!), which would be
0, is not in R \ {0}. Thus, the following notion is useful:
Definition F.20 (Complete Metric Space). A metric space Y is called complete if every Cauchy
sequence converges.
Definition F.21 (Completion). Let Y be a metric space. A completion of Y is a metric space Y 0
which contains Y as a dense subspace and such that Y 0 is complete.
Proposition F.22 (Universal Property of Completions). Assume that Y ⊆ Y 0 is a pair of metric
spaces, where Y 0 is a completion of Y . Then the following universal property holds:
Let Z be any complete metric space and f : Y → Z be any uniformly continuous function. Then
there is a unique continuous function f0 : Y 0 → Z that extends f, i.e., such that f0|Y = f. f0
furthermore is also uniformly continuous. This can be expressed by the following commutative
diagram, where i : Y → Y 0 is the canonical inclusion:
Y -f-> Z
Ii
Y0
Proof. See, for example, KaPlanSky (2001).	口
Definition F.23 (Boundedness). Let Y be a metric space. A subset A ⊆ Y is called bounded if
there is a constant C > 0 such that d(a, b) ≤ C for all a, b ∈ A.
Theorem F.24 (Heine-Borel Theorem). A subset A ⊆ Kd is compact if and only if it is closed and
bounded.
Proof. See Conway (2014), Theorem 1.4.8.	口
Corollary F.25 (Extreme Value Theorem). Let f : X → R be continuous, where X is any nonempty
compact topological space. Then f has a maximum and a minimum.
Proof. By Proposition F.8, f(X) ⊆ R is compact. By Theorem F.24 this means that f(X) is
closed and bounded. Boundedness means that the supremum is finite and closedness means that
the supremum must lie in f(X), and consequently it is a maximum. For the minimum, the same
arguments apply.	口
93
Published as a conference paper at ICLR 2021
F.2 Limits of nets and approximated Dirac delta functions
In this section, we discuss “limits of nets”, where a net can be imagined as a sequence over an index
set which may be “too big to be handled as a sequence over the natural numbers”. They appear in
the formulation of Theorem C.7. This material can, for example, be found in (Conway, 2014).
Definition F.26 (Partially Ordered Set, Directed Set). Let I be an index set and ≤ a relation on it.
I = (I, ≤) is a partially ordered set if:
1.	≤ is reflexive, i.e., i ≤ i for all i ∈ I.
2.	≤ is antisymmetric, that is: i ≤ j and j ≤ i together imply i = j .
3.	≤ is transitive, that is: i ≤ j and j ≤ k together imply i ≤ k.
A partially ordered set I is called directed if for all i, j ∈ I there exists k ∈ I such that i ≤ k and
j ≤ k.
Example F.27. Clearly, the natural numbers together with the standard order relation form a directed
set.
An important example for our purposes is the following: let Z be any topological space (for example,
a homogeneous space X of a compact group G) and x ∈ Z be any point. Furthermore, define Ux as
the set of open neighborhoods of x, i.e., open sets U ⊆ Z such that x ∈ U. On this set, we define
U ≤ V if U ⊇ V , i.e., by reversed inclusion. Then (Ux, ≤) is a directed set:
1.	Reflexivity is clear since V ⊇ V for all V .
2.	Antisymmetry is clear since U ⊇ V and V ⊇ U together clearly imply U = V .
3.	Transitivity is clear since U ⊇ V and V ⊇ W together clearly imply U ⊇ W.
4.	For directedness, let U, V ∈ Ux . Define W = U ∩ V . Then W ∈ Ux and clearly U ⊇ W
and V ⊇ W , which is what was to show.
Note that Ux is usually not totally ordered, i.e., there are usually U, V ∈ Ux such that neither U ⊇ V
nor V ⊇ U.
Definition F.28 (Net). Let Z be any topological space and I a directed set. Then a net in Z is a
function x : I → Z. We write a net as (xi)i∈I, in analogy to sequences.
Definition F.29 (Convergence of Nets). Let (xi)i∈I be a net in a topological space Z. Let x ∈ Z.
We say that (xi)i∈I converges to x, written limi∈I xi = x, if the following holds: for all open
neighborhoods U of x there is an i0 ∈ I such that for all i ≥ i0 we have xi ∈ U.
Now we define the approximated Dirac delta for the special case that X is a homogeneous space of
a compact group G. Remember that there is a Haar measure μ on X.
Definition F.30 (Approximated Dirac Delta). For 0 = U ⊆ X open, we define the approximated
Dirac delta by δU : X → K with
δU(X) =木∙ 1U(x) = (<⅛ex ∈ U
We have δU ∈ L2K(X).
A priori, it is unclear that open sets have positive measure, which is needed for the well-definedness
of this construction, since otherwise we divide by zero. Thus, we need the following lemma:
Lemma F.31. Let 0 = U ⊆ X be an open set. Then μ(U) > 0.
Proof. Consider the family of open sets (gU)g∈G. That all of these sets are necessarily open follows
since the action G × X → X is continuous, and thus by the definition of a group action, each g ∈ G
induces a homeomorphism X → X, x 7→ gx. Now, since the action is transitive, (gU)g∈G is an
open cover of X, and since X is compact, see Definition F.7, it has an open subcover (gi U)in=1 with
94
Published as a conference paper at ICLR 2021
gi ∈ G. Note that μ(giU) = μ(U) for all i since the measure μ on X is by definition left invariant
under the action of G. Overall, we obtain
nn	n
1 = μ(X) = μ( [ giU) ≤ Xμ(giU) = Xμ(U) = n ∙ μ(U)
i=1	i=1	i=1
and thus μ(U) ≥ n > 0.	□
F.3 Pre-Hilbert Spaces and Hilbert Spaces
Here, we state foundational concepts in the theory of Hilbert spaces (Debnath & Mikusinski, 2005).
Definition F.32 (Pre-Hilbert Space, Hilbert space). A Pre-Hilbert space V = (V,〈+〉) consists of
the following data:
1.	A vector space V over K.
2.	An inner product (J) : V X V → K, (χ,y) →(x|y).
It has the following properties that hold for all x, x0 , y, y0 ∈ V, λ ∈ K:
1.	The inner product is conjugate linear in the first component: hx + x0∣yi = (x∖y) + (x0∣yi
and (λx∖yi = λ hx\y), where λ is the complex conjugate of λ.
2.	The inner product is linear in the second component: hx∖y + y0i = hx∖yi + hx∖y0i and
hx∖λyi = λ hx∖yi.
3.	The inner product is conjugate symmetric: (y∖x) = hx∖y)
4.	The inner product is positive definite: hx∖xi > 0 unless x = 0.
If additionally, the following statement holds, then V is called a Hilbert Space:
5.	V, together with the norm ∣∣∙k : V → V induced from the inner product by ∣∣χk := hx (χ∖χi,
and consequently the metric defined by d(x, y) := kx - yk, is a complete metric space as
in Definition F.20.
Remark F.33. Of course, all Hilbert Spaces are pre-Hilbert spaces, and so all Propositions about
pre-Hilbert spaces in the following apply to Hilbert spaces just as well.
Note that the first property follows from the second and third. We also mention that usually, inner
products on Hilbert spaces are assumed to be linear in the first and conjugate linear in the second
component, in contrast to how we view it. The reason for our choice is that our work is inspired by
connections to physics where our convention is more common. Itis basically the bra-ket convention.
Furthermore, note that if K = R, then conjugate linear maps are linear and thus the inner product
will be linear in both components. Additionally, it will be symmetric instead of only conjugate
symmetric.
Proposition F.34 (Cauchy-Schwartz Inequality). For any two elements v, w in a pre-Hilbert space
V, we have
∖hv∖wi∖ ≤ kvk ∙ kwk.
We have equality if and only if v and w are linearly dependent.
Proof. See Debnath & Mikusinski (2005), Theorem 3.2.9.	□
Definition F.35 (Orthogonality). Two vectors v, w in a pre-Hilbert space V are called orthogonal,
written v ⊥ w, ifhv ∖wi = 0.
Obviously, being orthogonal is a symmetric relation.
Definition F.36 (Orthogonal Complement). Let V be a pre-Hilbert space and W ⊆ V a subset.
v ∈ V is orthogonal to W if hv ∖ wi = 0 for all w ∈ W.
The orthogonal complement of W, denoted W⊥, is the set of all vectors in V that are orthogonal to
W.
95
Published as a conference paper at ICLR 2021
Proposition F.37 (Closedness of Complements). Let W ⊆ V be a subset of a pre-Hilbert space V .
Then W⊥ is a topologically closed linear subspace of V .
Proof. See Debnath & Mikusinski (2005), Theorem 3.6.2.	□
Proposition F.38 (Continuity of Scalar Product). For any pre-Hilbert space V , the scalar product
h∙∣∙i : V X V → K is continuous.
Proof. See Debnath & Mikusinski (2005), Theorem 3.3.12.	□
Definition F.39 (Orthonormal System). A family (vi)i∈I of elements in a pre-Hilbert space is called
orthonormal system if kvi k = 1 for all i ∈ I and vi ⊥ vj for all i 6= j .
Definition F.40 (Orthonormal Basis). An orthonormal system (vi)i∈I in a Hilbert space V is called
orthonormal basis if the linear span of all {vi}i∈I is dense in V. If this is the case, then each v ∈ V
can be uniquely written as
v =	αivi
i∈I
with only countably many αi ∈ K being nonzero. The coefficients are given by αi = hvi|vi.
We stress that while the index set I can be uncountably infinite, the sequence expansions of each
element in V only have countably many entries. It is obvious from the Peter-Weyl Theorem B.22
and this definition that the functions
nYlmi | l ∈ Gb, i ∈ {1, . . . , ml }, m ∈ {1, . . . , dl}o
form an orthonormal basis of L2K(X).
Proposition F.41 (Gram-Schmidt Orthonormalization). For every linearly independent sequence
(yk)k in a pre-Hilbert space V with N ∈ N∪ {∞} elements, one can find an orthonormal sequence
(vk )k in V such that the following holds: for all n ∈ N, n ≤ N, the progressive linear span stays
the same:
spanK(v1 , . . . , vn) = spanK (y1 , . . . , yn).
In particular, since every finite-dimensional Hilbert space has a vector space basis, it necessarily
also has an orthonormal basis.
Proof. See Debnath & Mikusinski (2005), page 110.	□
Definition F.42 (Adjoint of an Operator). Let f : V → V0 be a continuous linear function between
Hilbert spaces. Then there is a unique continuous linear function f * : V0 → V such that for all
v ∈ V and v0 ∈ V0 one has:
hf(v)|v0iV0 = hv|f*(v0)iV.
f * is called the adjoint of f.
The existence of adjoints is, for example, discussed in Debnath & Mikusinski (2005), page 158.
This book only considers the case of operators on a Hilbert space to itself, but these considerations
generalize to the setting with two different Hilbert spaces. One has the following:
Proposition F.43. Let f : V → V0 and g : V0 → V00 be continuous linear functions between
Hilbert spaces. Then:
1.	(f*)* = f.
2.	id*V = idV .
3.	(g ◦ f )* = f * ◦ g*.
Proof. All of these properties follow directly from the uniqueness of adjoints.	□
Proposition F.44. Let f : V → V0 be a unitary transformation between Hilbert spaces, i.e., an
invertible linear function such that hf(v)|f(w)i = hv|wi for all v, w ∈ V. Then the adjoint is the
inverse, i.e., f* = f-1.
96
Published as a conference paper at ICLR 2021
Proof. First of all, the inverse f -1 is again continuous due to the unitarity of f. Furthermore, due
to the unitarity, we obtain
hf(v)|v0i = f(v)f(f-1(v0))
=(vf-1(V0)〉
for all v ∈ V and V ∈ V0. Due to the uniqueness of adjoints, We obtain f-1 = f *.	口
The following proposition is sometimes used in the main text:
Proposition F.45. Let v, w ∈ V be two elements in a pre-Hilbert space such that hv|ui = hw|ui for
all u ∈ V. Then v = w.
Proof. We have
hv - w|ui = hv|ui - hw|ui = 0
for all u ∈ V . In particular, When setting u = v - w We obtain
hv - w|v - wi = 0
and thus V 一 W = 0, i.e., V = w.	口
Proposition F.46 (Orthogonal Projection Operators). Let W ⊆ V be a topologically closed sub-
space of a Hilbert space. Then there is a continuous linear function P : V → W such that for all
V ∈ V and w ∈ W we have
hP (V)|wi = hV|wi .
Furthermore, if W is finite-dimensional and w1, . . . , wn and orthonormal basis, then P is given
explicitly by
n
P(V) =	hwi|Vi wi.
i=1
Proof. That W is topologically closed means that W, With the scalar product inherited from V,
is a complete metric space. Thus, W is a Hilbert space as Well. Therefore, the continuous linear
embedding i : W → V given by w → W has an adjoint i* : V → W by Definition F.42. Set
P := i*. For arbitrary V ∈ V and W ∈ W we obtain:
(P(v)|w)= hi*(v)∣wi
= hV|i(W)i
= hV |Wi .
For the second statement, note that for allj ∈ {1, . . . , n} we have, using that the Wi are orthonormal:
(Xn=1 hwi lvi WiIWj) = Xn=IhWiWhwdwji
= hV|Wji
= hP (V)|Wj i .
By Proposition F.45 and since the Wj generate W we obtain Pin=1 hWi|Vi Wi = P(V) as claimed.
一 □
Proposition F.47. Let (V, h∙∣)) be a finite-dimensional Pre-Hilbert space. Then this space is already
complete and thus a Hilbert space.
In particular, all finite-dimensional subspaces of Hilbert spaces are topologically closed.
Proof. The proof of the Gram-Schmidt orthonormalization in Proposition F.41 does not make use of
the completeness of the Hilbert space, and thus it holds for pre-Hilbert spaces as well. Consequently,
V, being finite-dimensional, has an orthonormal basis. It is thus isomorphic to Kn together with the
standard scalar product, which is well-known to be complete. Thus, V is a Hilbert space.
Now, let W ⊆ V be a finite-dimensional subspace of a Hilbert space V which may be infinite-
dimensional. Then W is a pre-Hilbert space and by what was just shown a Hilbert space. Con-
sequently, all sequences in W which have a limit in V need, by completeness, to have that limit
already in W. This shows that W is topologically closed.	口
97