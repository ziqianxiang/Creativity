Table 1: Comparison of commonly used losses for audio modeling to our proposed `2 + phase loss.
Table 2: Ablation study. The components of the proposed binauralization network improve phaseand amplitude and thereby the overall loss in time-domain.
Table 4: Mean opinion scores of different approaches. Participants were ask to rank cleanliness,spatialization, and overall realism on a Likert scale from 1 to 5.
Table 5: Real-time-factor for offline processing and latency for streaming generation of binauralaudio. The DSP baseline runs on CPU, all other models run on an NVidia Tesla V100.
Table 6: Comparison of the loss formulation from equation 12 and equation 28. While the firstpenalizes phase twice, once implicitly in the time-domain '2-loss and once in the explicit phase lossterm, the latter provides a clear separation between magnitude and phase loss terms.
Table 7: Side-by-side study of DSP vs. our system. Participants were presented two clips, onegenerated with DSP, one with our approach, and were then asked to tell which one they prefer.
Table 8: Generalization to unseen subjects. In a leave-on-subject-out setup, our approach still out-performs the DSP baseline by a significant margin.
Table 9: Effect of the activation function used in the temporal hyper-convolutions.
