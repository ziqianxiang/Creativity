Table 1: Summary of Toxicity classification experiment over 10 restarts	BA	CTF score	PC	BA STD	ACC STDBaseline	0.807±0.002	0.072±0.002	0.621±0.014	0.044±0.003	0.081±0.004SenSeI	0.791±0.005	0.029±0.005	0.773±0.043	0.035±0.003	0.052±0.003SenSR	0.794±0.003	0.043±0.005	0.729±0.044	0.036±0.002	0.059±0.004CLP	0.795±0.006	0.032±0.006	0.763±0.048	0.038±0.003	0.056±0.004Table 2: Summary of Bios classification experiment over 10 restarts	BA	CTF score	PC	Gap RMS	Gap ABSBaseline	0.842±0.002	0.028±0.001	0.942±0.001	0.120±0.004	0.080±0.003SenSeI	0.843±0.003	0.003±0.000	0.977±0.001	0.086±0.005	0.054±0.003SenSR	0.842±0.003	0.004±0.000	0.976±0.001	0.087±0.004	0.054±0.003CLP	0.841±0.003	0.005±0.000	0.974±0.001	0.087±0.005	0.056±0.004approach here to obtain fair metric for training SenSR (Yurochkin et al., 2020) and SenSeI. SeeAppendix B.1 for additional details regarding the fair metric construction in the experiments.
Table 2: Summary of Bios classification experiment over 10 restarts	BA	CTF score	PC	Gap RMS	Gap ABSBaseline	0.842±0.002	0.028±0.001	0.942±0.001	0.120±0.004	0.080±0.003SenSeI	0.843±0.003	0.003±0.000	0.977±0.001	0.086±0.005	0.054±0.003SenSR	0.842±0.003	0.004±0.000	0.976±0.001	0.087±0.004	0.054±0.003CLP	0.841±0.003	0.005±0.000	0.974±0.001	0.087±0.005	0.056±0.004approach here to obtain fair metric for training SenSR (Yurochkin et al., 2020) and SenSeI. SeeAppendix B.1 for additional details regarding the fair metric construction in the experiments.
Table 3: Adult experiment over 10 restarts. Prior methods are duplicated from Yurochkin et al. (2020)	BA,%	S-Con.	GR-Con.	GapRGMS	GapRRMS	GapGmax	GapRmaxSenSR	78.9	.934	.984	.068	.055	.087	.067Baseline	82.9	.848	.865	.179	.089	.216	.105Project	82.7	.868	1.00	.145	.064	.192	.086Adv. debiasing	81.5	.807	.841	.082	.070	.110	.078CoCL	79.0	-	-	.163	.080	.201	.109SenSeI (ρ = 40)	76.8	.945	.963	.043	.054	.053	.064a person’s bio. The dataset consists of 400k textual bio descriptions and the goal is to predict one ofthe 28 occupations. We again use BERT fine-tuned on the train data to obtain bio representations andthen train a 2000 hidden neurons neural networks using each of the fair training methods.
Table 4: Hyperparameter names and notations	notation	name in code	relevant methodsNumber of optimization steps	E	epoch	AllMini-batch size	B	batch_size	AllParameter learning rate η	η	lr	AllSubspace attack step size	s	adv_step	SenSeI, SenSRNumber of subspace attack steps	se	adv_epoch	SenSeI, SenSRFull attack step size	f	l2_attack	SenSeI, SenSRNumber of full attack steps	fe	adv_epoch_full	SenSeI, SenSRAttack budget		ro	SenSeI, SenSRFair regularization strength ρ	P	fair_reg	SenSeI, CLPTable 5: Hyperparameter choices in Toxicity experiment	E	B	η	s	se	f	fe		PBaseline	100k	256	1e-5	—	—	—	—	—	—SenSR	100k	256	1e-5	0.1	10	0	0	0	—SenSeI	100k	256	1e-5	0.1	10	0	0	0	5CLP	100k	256	1e-5	—	—	—	—	—	51https://www.kaggle.com/taindow/bert-a-fine-tuning-example2https://github.com/google-research/bert3We will open-source the code and merge variable names with their abbreviations
Table 5: Hyperparameter choices in Toxicity experiment	E	B	η	s	se	f	fe		PBaseline	100k	256	1e-5	—	—	—	—	—	—SenSR	100k	256	1e-5	0.1	10	0	0	0	—SenSeI	100k	256	1e-5	0.1	10	0	0	0	5CLP	100k	256	1e-5	—	—	—	—	—	51https://www.kaggle.com/taindow/bert-a-fine-tuning-example2https://github.com/google-research/bert3We will open-source the code and merge variable names with their abbreviations16Published as a conference paper at ICLR 2021Table 6: Hyperparameter choices in Bios experiment	E	B	η	s	se	f	fe		ρBaseline	100k	504	1e-6	—	—	—	—	—	—SenSR	100k	504	1e-5	0.1	50	0.01	10	0.1	—SenSeI	100k	504	1e-5	0.1	50	0.01	10	0.1	5CLP	100k	504	1e-5	—	—	—	—	—	5Table 7: Hyperparameter choices in Adult experiment	E	B	η	s	se	f	fe		ρSenSeI	200k	1000	1e-5	5	50	0.001	50	0.01	40
Table 6: Hyperparameter choices in Bios experiment	E	B	η	s	se	f	fe		ρBaseline	100k	504	1e-6	—	—	—	—	—	—SenSR	100k	504	1e-5	0.1	50	0.01	10	0.1	—SenSeI	100k	504	1e-5	0.1	50	0.01	10	0.1	5CLP	100k	504	1e-5	—	—	—	—	—	5Table 7: Hyperparameter choices in Adult experiment	E	B	η	s	se	f	fe		ρSenSeI	200k	1000	1e-5	5	50	0.001	50	0.01	40B.1 Fair metric learning detailsFollowing Yurochkin et al. (2020); Mukherjee et al. (2020) we consider the fair metric of the formdX (x, x0) = (x - x0)TΣ(x - x0). We utilize their sensitive subspace idea writing Σ = I - Pran(A),i.e. an orthogonal complement projector of the subspace spanned by the columns of A ∈ Rd×k . HereA encodes the k directions of sensitive variations that should be ignored by the fair metric (d is thedata dimension), such as differences in sentence embeddings due to gender pronouns in the Biosexperiment or due to identity (counterfactual) tokens in the Toxicity experiment.
Table 7: Hyperparameter choices in Adult experiment	E	B	η	s	se	f	fe		ρSenSeI	200k	1000	1e-5	5	50	0.001	50	0.01	40B.1 Fair metric learning detailsFollowing Yurochkin et al. (2020); Mukherjee et al. (2020) we consider the fair metric of the formdX (x, x0) = (x - x0)TΣ(x - x0). We utilize their sensitive subspace idea writing Σ = I - Pran(A),i.e. an orthogonal complement projector of the subspace spanned by the columns of A ∈ Rd×k . HereA encodes the k directions of sensitive variations that should be ignored by the fair metric (d is thedata dimension), such as differences in sentence embeddings due to gender pronouns in the Biosexperiment or due to identity (counterfactual) tokens in the Toxicity experiment.
