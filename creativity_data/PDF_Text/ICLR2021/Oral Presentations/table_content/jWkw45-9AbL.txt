Table 1: Examples of generations controlled by a discrimina-tor on the class label “very positive”. Reps is the frequency ofthe whole sequence in a corpus of 10k samples. Tokens high-lighted in yellow with different intensities indicates their overallfrequencies in the generated corpus. Generations are trimmed to15 tokens for display purposes. See §H.5 a full list of genera-tions .
Table 2: Distributional and hybrid constraints experiments demonstrating the generality of GDC in dealingWith this mixed type of constraints. ↑/] indicates which direction (increasing/decreasing) improves the targetexpectation. See Appendix §G for convergence curves.
Table 3: Comparison against PPLM (Dathathri et al., 2020) and CTRL (Keskar et al., 2019) on positive andnegative sentiment control. We generate 100 samples for each prefix obtaining a total of 500 samples. Allmetrics shown are averaged across the 500 samples obtained. CTRL refers to the shared setting across allapproaches with temperature T = 1.0 and repetition penalty λrep = 1.0 and CTRL* refers to having T = 0.5and λrep = 1.2. Here, we see a clear advantage of GDC in terms of constraint satisfaction and perplexity anda comparable performance in terms of diversity against PPLM and CTRL.
Table 4: Samples generated from GDC, Plug and Play (Dathathri et al., 2020) and CTRL (Keskar et al., 2019)for both positive and negative experiments. Control codes are omitted for CTRL. Prefixes are underlined.
Table 5: Hyperparameters used throughout all experiments. ∀ denotes common parameters between all trainingmethods or constraints.
Table 6: Words in each profession word list used in the distributional constraints experiments.
Table 7: Randomly selected generations from the hybrid Experiments (3,4,5,6). F indicates that the generationis about a female character. The imposed distributional constraint is Eφf emale (x) = 0.5, while the pointwiseconstraint is Eφart (x) = 1.0, Eφscience(x) = 1.0, etc.
Table 8: Randomly selected generations from the single-word constraint task for the word “Wikileaks” (withoccurrence probability 1/104) highlighted in green. Tokens are highlighted with yellow with different inten-sities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of theconstraint in the sample and reps the number of its repetitions across all generations.
Table 9: Randomly selected generations from the single-word constraint task for the word “Vampire” (withoccurrence probability 1/104) highlighted in green. Tokens are highlighted with yellow with different inten-sities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of theconstraint in the sample and reps the number of its repetitions across all generations.
Table 10: Randomly selected generations from the single-word constraint task for the word “amusing"(Withoccurrence probability 1/104) highlighted in green. Tokens are highlighted with yellow with different inten-sities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of theconstraint in the sample and reps the number of its repetitions across all generations.
Table 11:	Randomly selected generations from the single-word constraint task for the word “Paris” (withoccurrence probability 1/103) highlighted in green. Tokens are highlighted with yellow with different inten-sities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of theconstraint in the sample and reps the number of its repetitions across all generations.
Table 12:	Randomly selected generations from the single-word constraint task for the word “restaurant”(with occurrence probability 1/103) highlighted in green. Tokens are highlighted with yellow with differentintensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction ofthe constraint in the sample and reps the number of its repetitions across all generations.
Table 13:	Randomly selected generations from the single-word constraint task for the word “amazing” (withoccurrence probability 1/103) highlighted in green. Tokens are highlighted with yellow with different inten-sities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of theconstraint in the sample and reps the number of its repetitions across all generations.
Table 14:	Randomly selected generations from the single-word constraint task for the word “Canada” (withoccurrence probability 1/103) highlighted in green. Tokens are highlighted with yellow with different inten-sities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of theconstraint in the sample and reps the number of its repetitions across all generations.
Table 15:	Randomly selected generations from the single-word constraint task for the word “China” (withoccurrence probability 1/102) highlighted in green. Tokens are highlighted with yellow with different inten-sities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of theconstraint in the sample and reps the number of its repetitions across all generations.
Table 16: Randomly selected generations from the single-word constraint task for the word “US” (with occur-rence probability 1/102) highlighted in green. Tokens are highlighted with yellow with different intensities toindicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraintin the sample and reps the number of its repetitions across all generations.
Table 17: Randomly selected generations from the word-list constraint task for the kitchen word-list. Tokensare highlighted with yellow with different intensities to indicate their overall frequencies in the generated cor-pus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitionsacross all generations.
Table 18: Randomly selected generations from the word-list constraint task for the fantasy word-list. Tokensare highlighted with yellow with different intensities to indicate their overall frequencies in the generated cor-pus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitionsacross all generations.
Table 19: Randomly selected generations from the word-list constraint task for the politics word-list. Tokensare highlighted with yellow with different intensities to indicate their overall frequencies in the generated cor-pus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitionsacross all generations.
Table 20: Randomly selected generations from the word-list constraint task for the computers word-list. To-kens are highlighted with yellow with different intensities to indicate their overall frequencies in the generatedcorpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitionsacross all generations.
Table 21: Randomly selected generations from the classifier-based constraint task for very positive sentimentcontrol. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in thegenerated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of itsrepetitions across all generations.
Table 22: Randomly selected generations from the classifier-based constraint task for positive sentiment con-trol. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in thegenerated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of itsrepetitions across all generations.
Table 23: Randomly selected generations from the classifier-based constraint task for very negative sentimentcontrol. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in thegenerated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of itsrepetitions across all generations.
Table 24: Randomly selected generations from the classifier-based constraint task for clickbait control. To-kens are highlighted with yellow with different intensities to indicate their overall frequencies in the generatedcorpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitionsacross all generations.
