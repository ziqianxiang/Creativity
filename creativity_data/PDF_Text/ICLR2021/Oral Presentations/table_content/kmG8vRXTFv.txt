Table 1: Forecasting and identification results on the (a) reaction-diffusion, (b) wave equation, and(c) damped pendulum datasets. We set for (a) a = 1 × 10-3, b = 5 × 10-3, k = 5 × 10-3, for(b) c = 330, k = 50 and for (c) T0 = 6, α = 0.2 as true parameters. log MSEs are computedrespectively over 25, 25, and 40 predicted time-steps. %Err param. averages the results when severalphysical parameters are present. For each level of incorporated physical knowledge, equivalent bestresults according to a Student t-test are shown in bold. n/a corresponds to non-applicable cases.
Table 2: ConvNet architecture in reaction-diffusion and wave equation experiments, used as data-driven derivative operator in APHYNITY and Neural ODE (Chen et al., 2018).
Table 3: Neural network architectures for the damped pendulum experiments. n/a corresponds tonon-applicable cases.
Table 4: Hyperparameters of the damped pendulum experiments.
Table 5: Ablation study comparing APHYNITY to the vanilla augmentation scheme (Wang et al.,2019; Mehta et al., 2020) for the reaction-diffusion equation, wave equation and damped pendulum.
Table 6: Detailed ablation study on supervision and optimization for the reaction-diffusion equation,wave equation and damped pendulum.
Table 7: Results of the dataset of reaction-diffusion with varying (a, b). k = 5 × 10-3 is sharedacross the dataset.
Table 8: Results for the damped wave equation when considering multiple c sampled uniformly in[300, 400] in the dataset, k is shared across all sequences and k = 50.
Table 9: Forecasting and identification results on the damped pendulum dataset with differentparameters for each sequence. log MSEs are computed over 20 predicted time-steps. For each levelof incorporated physical knowledge, equivalent best results according to a Student t-test are shown inbold. n/a corresponds to non-applicable cases.
