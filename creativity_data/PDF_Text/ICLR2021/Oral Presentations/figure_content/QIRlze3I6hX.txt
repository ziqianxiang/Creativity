Figure 1: We propose to learn observation correspondence (blue arrow) and action correspondence (red arrow)across domains using Dynamics Cycle-Consistency. Our applications include: (a) Aligning real robot imageswith simulation states; (b) Aligning actions between environments with different physics parameters (We usedifferent rendering to indicate that the physics are different); (c) Aligning both actions and observations betweenagents at the same time with different morphology.
Figure 2: Model framework: (a) Model for only cross-physics alignment; (b) Model for only cross-modalityalignment; (c) Joint model for cross-modality-and-physics alignment. Red arrows indicate correspondencesbetween actions and blue arrows indicate correspondence between observations.
Figure 3: Ablation study with HalfCheetah. (a) L1 error for different dataset scale; (b) Ablation withdiscriminators; (c) Combining our method with supervised state estimation (using paired image-state data).
Figure 4: Visualization of learnt correspondence from RGB imagesto robot joint states with xArm robot. We render the predictedstates in simulation with green background. While Cycle-GANstruggles to find the correct correspondence, the results of our methodhighlights the importance of dynamics cycle-consistency objective.
Figure 5: Cross-morphology agent introduction. Left: two-leg Cheetah and its three-leg counterpart. Right:three-limb swimmer its four-limb counterpart. Please check out our supplementary video for visualization.
Figure 6: Correspondence visualization for Cycle-GAN baseline and ours. Cycle-GAN model performsnearly the same as the random shuffle baseline while our model can correctly find the correspondence betweenthe image modality and the state modality.
Figure 7: Qualitative visualization for Cyde-GAN baseline and ours. The rendered image (C) from ourmodel prediction looks almost the same like the original input image (a) while Cycle-GAN baseline (b) fails.
