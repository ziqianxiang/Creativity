Figure 1: The illustration of GAIRAT. GAIRAT explicitly gives larger weights on the losses ofadversarial data (larger red), whose natural counterparts are closer to the decision boundary (lighterblue). GAIRAT explicitly gives smaller weights on the losses of adversarial data (smaller red),whose natural counterparts are farther away from the decision boundary (darker blue). The examplesof two toy datasets and the CIFAR-10 dataset refer to Figure 3.
Figure 2: We plot standard training error (Natural) and adversarial training error (PGD-10) overthe training epochs of the standard AT on CIFAR-10 dataset. Left panel: AT on different sizes ofnetwork. The red line represents standard test accuracy by standard training (ST). Right panel: ATon ResNet-18 under different perturbation bounds train .
Figure 3: More attackable data (lighter red and blue) are closer to the class boundary; more guardeddata (darker red and blue) are farther away from the class boundary. Left panel: Two toy examples.
Figure 4: Comparisons ofAT (ω1, red lines) and GAIRAT (ω2, blue lines andω3, yellow lines) usingResNet-18 on the CIFAR-10 dataset. Upper-left panel shows different weight assignment functionsω w.r.t. the geometry value κ. Bottom-left panel reports the training statistic of the standard AT andcalculates the median (dark red circle) and mean (light red cross) of geometry values of all trainingdata at each epoch. Upper-middle and upper-right panels report standard training/test errors androbust training/test errors, respectively. Bottom-middle and bottom-right panels report the lossflatness w.r.t. friendly adversarial test data and most adversarial test data, respectively.
Figure 5: We plot standard training error (the left two panels) and adversarial training error (theright two panels) over the training epochs of the standard AT on CIFAR-10 dataset. Top two panels:standard AT on different sizes of network. Bottom two panels: standard AT on ResNet-18 underdifferent perturbation bound train .
Figure 6: We plot standard training error (the left two panels) and adversarial training error (the righttwo panels) over the training epochs of the standard AT on SVHN dataset. Top two panels: AT ondifferent sizes of network. Bottom two panels: AT on ResNet-18 under different perturbation boundtrain.
Figure 7: Part A 2-d visualizations of the model’s output distribution of natural training data fromtwo separated classes from CIFAR-10 dataset. The degree of the robustness (denoted by the colorgradient) of a datum is calculated based on the least number of iterations κ that PGD requires tofind its misclassified adversarial variant. The light blue and light red points represent attackable datawhich are close to the class boundary; the dark blue and dark red points represent the guarded datawhich are far away from the decision boundary. (Top colorbars corresponds to the value κ)15Published as a conference paper at ICLR 2021Figure 8: Part B - 2-d visualizations of the model’s output distribution on CIFAR-10 dataset.
Figure 8: Part B - 2-d visualizations of the model’s output distribution on CIFAR-10 dataset.
Figure 9: Illustration of the reasons for the issue of robust overfitting.
Figure 10: Comparisons of AT (ω1 , red lines) and GAIRAT (ω2 , blue lines and ω3, yellow lines)using ResNet-18 on SVHN dataset. Upper-left panel shows different instance-dependent weightassignment functions ω w.r.t. the geometry value κ. Bottom-left panel reports the standard ATtraining statistic and calculates the median (dark red circle) and mean (light red cross) of geometryvalues of all training data at each epoch. Upper-middle and upper-right panels report naturaltraining/test errors and robust training/test errors, respectively. Bottom-middle and bottom-rightpanels report the loss flatness w.r.t. friendly adversarial test data and most adversarial test data,respectively.
Figure 11: The training results of standard AT and GAIRAT using pre-activation ResNet-18 underdifferent learning rate schedules on CIFAR-10 dataset. The top panel reports the different learningrate schedules. The four middle panels report the robust test error on adversarial data generatedby PGD-20. The four bottom panels report the standard test error on natural data. The red linesrepresent AT’s results under different learning rate schedules. The brown, green, blue and orangelines represent GAIRAT’s results of different learning rate schedules.
Figure 12:	Comparisons of GAIRAT with different weight assignment functions on CIFAR-10dataset. When GAIRAT takes constant ω = 1 over the training epochs, GAIRAT recovers thestandard adversarial training (AT) (red lines).
Figure 13:	Comparisons of GARAT using the tanh-type weight assignment function (Eq. (6)) withdifferent λ on CIFAR-10 dataset.
Figure 14:	Comparisons of GARAT using the tanh-type weight assignment function (Eq. (6)) withdifferent λ on SVHN dataset.
Figure 15:	Comparisons of GAIRAT (blue lines) with different lengths of the burn-in period onCIFAR-10 dataset. The longer GAIRAT has the burn-in period, the more alike GAIRAT becomesstandard AT (red lines). AT can be seen as GAIRAT with 100 epochs burn-in period. Darker bluelines represent shorter lengths of burn-in period; lighter blue lines represent longer lengths of burn-inperiod.
Figure 16:	Comparisons of different networks (VGG-13, Small CNN and ResNet-18) whichGAIRAT and AT use on CIFAR-10 dataset.
Figure 17: We compare FAT and GAIR-FAT using ResNet-18 on CIFAR-10 dataset using tanh-typeweight assignment function with different λ.
Figure 18:	Comparisons of GAIR-FAT and FAT under different schedules of dynamical τ usingResNet-18 on CIFAR-10 dataset. (τ : 0-1-2) refers to τ starting from 0 and increasing by 1 at Epoch40 and 70, respectively. (τ : 0-2-4) refers to τ starting from 0 and increasing by 2 at Epoch 40and 70, respectively. τ : 0-3-6) refers to τ starting from 0 and increasing by 3 at Epoch 40 and 70,respectively.
Figure 19:	We compare MMA, MART and GAIR-MART with different weight assginment func-tions using ResNet-18 on CIFAR-10.
Figure 20:	Comparison of MART and GAIR-MART training ResNet-18 with Eq. (11) on CIFAR-10dataset.
Figure 21:	Comparison of PGD attacks with different PGD iterations on CIFAR-10 dataset.
