Figure 1: A game of cache within AI2-THOR. a Multiple views of a single agent who, over time, exploresand interacts with objects. b-f The five consecutive stages of cache. In c the agent must choose where to hidethe object at a high level, using its map of the environment to make this choice, while in d the agent must choosewhere to hide the object from a first person viewpoint. In e the object being manipulated is a tomato.
Figure 2: Overview of the neural network architecture for the Cache agent. The trainable components areshown in yellow, the inputs and outputs in pink, and the intermediate OutPuts in blue. Refer to text for details.
Figure 3:	Cache agent. Actions and decisions made during a game of cache. a Hider's trajectory duringexploration. Insets show first person views before and after an open action. b Heatmap displaying the agent'sinitial beliefs of high quality hiding locations. Insets show how this heatmap varies when the seeking agent'sstart position is changed. C Initial beliefs in b are refined by the agent performing explicit mental rollouts ofthe seeking agent. Three trajectories, stopped after 30 steps, are highlighted. Faint white lines are paths fromother simulated trajectories. Insets show rollouts when varying the hiding location and agent starting location.
Figure 4:	Evaluating the cache agent. a,b Frequency that seekers from three points during training (after 0,1∙106, and 4.5∙106 training episodes) find objects hidden by: hiders from the same training points, an automatedexhaustive approach (E=easy, M =medium, H =hard), and humans. Error bars denote 95% CIs. c Results ofour best hider (h4.5e6) and seeker (s4.5e6) competing with humans. Here the mean frequency of finding thehidden object is reported (with 95% CIs) along with the mean number of steps the seeker took to find the hiddenobject (with 95% CIs).
Figure 5: SIR evaluation on synthetic images. Left: test-set losses (averaged first within each scene) of thedifferent models relative to the fully supervised baseline (ImageNet). Values less than 1 indicate performancebetter than that of the ImageNet SIR (stat. significance computed at a <0.01 level using a generalized linearmixed-model). Right: qualitative examples of geometric and affordance-based image predictions using SIR.
Figure 6: SIR evaluation on natural images. Quantitative and qualitative results for natural image tasks.
Figure 7: DIR evaluation. Schematic illustrations, example images from AI2-THOR and numerical results ofour psychologically motivated experiments. All results are for the test set with 95% confidence intervals. SeeSec. F for definitions of plot labels and Sec. 5 for a description of these experiments. Note: (i) X-coordinatesin our line charts are offset slightly from one another so as to improve readability. (ii) Our plots show theperformance of the representations as the amount of data used in training the probing linear classifier increases;but in the main text, we report only the values corresponding to the largest training set sizes considered.
