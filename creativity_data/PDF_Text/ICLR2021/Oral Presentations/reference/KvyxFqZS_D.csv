title,year,conference
 A convergence theory for deep learning via over-parameterization,2019, In Proceedings of the 36th International Conference on Machine Learning
 Convexneural networks,2006, In Advances in neural information processing systems
 Universal approximation to nonlinear operators by neural networkswith arbitrary activation functions and its application to dynamical systems,2019, IEEE Transactionson Neural Networks
 On the global convergence of gradient descent for over-parameterized models using optimal transport,2018, In Advances in Neural Information ProcessingSystems
 Approximation by superpositions ofa sigmoidal function,2019, Mathematics of control
 Analysis of a two-layer neural networkvia displacement convexity,2019, arXiv preprint arXiv:1901
 Wide neural networks of any depth evolve as linear modelsunder gradient descent,2019, In Advances in Neural Information Processing Systems 32
 A mean-field analysis of deepresnet and beyond: Towards provable optimization via overparameterization from depth,2020, arXivpreprint arXiv:2003
 Mean-field theory of two-layers neuralnetworks: dimension-free bounds and kernel limit,2019, arXiv preprint arXiv:1902
 Mean field limit of the learning dynamics of multilayer neural networks,2019, arXivpreprint arXiv:1902
 A rigorous framework for the mean field limit of multi-layer neural networks,2020, arXiv preprint arXiv:2001
 Stochastic particle gradient descent for infinite ensembles,2017, arXivpreprint arXiv:1712
 A note on the global convergence of multilayer neuralnetworks in the mean field regime,2020, arXivpreprint arXiv:2006
 Optimum bounds for the distributions of martingales in banach spaces,2018, The Annals ofProbability
 Landscape connectivity and dropout stability of sgdsolutions for over-parameterized neural networks,2019, arXiv preprint arXiv:1912
 Mean field analysis of neural networks,2018, arXivpreprint arXiv:1805
 Mean field analysis of deep neural networks,2019, arXivpreprint arXiv:1903
 Topics in propagation of chaos,2019, In Ecole d
 On the convergence of gradient descent training for two-layer relu-networksin the mean field regime,2020, arXiv PrePrint arXiv:2005
 Stochastic gradient descent optimizesover-parameterized deep relu networks,2018, arXiv PrePrint arXiv:1811
