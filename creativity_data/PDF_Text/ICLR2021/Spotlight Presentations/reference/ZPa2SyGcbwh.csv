title,year,conference
 Two-temperature logistic regression basedon the tsallis divergence,2019, In AISTATS
 Robust bi-tempered logisticloss based on bregman divergences,2019, In NeurIPS
 Learningfrom noisy large-scale datasets with minimal supervision,2017, In CVPR
 Unsupervisedlabel noise modeling and loss correction,2019, In ICML
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, InNeurIPS
 Food-101-mining discriminative compo-nents with random forests,2014, In ECCV
 On symmetric losses forlearning from corrupted labels,2019, In ICML
 A topological regularizer for classifiers viapersistent homology,2019, In AISTATS
 Beyond class-conditional assumption: A primary attempt to combat instance-dependent label noise,2021, In AAAI
 Learning with boundedinstance- and label-dependent label noise,2020, In ICML
 Using pre-training can improve model robustnessand uncertainty,2019, In ICML
 Modelling class noise with symmetric and asymmetric distributions,2015, InAAAI
 On the resistance of nearest neighbor to random noisylabels,2016, arXiv preprint arXiv:1607
 Robust loss functions under label noise for deepneural networks,2017, In AAAI
 Simple and effective regularization methods for training onnoisily labeled data with generalization guarantee,2020, In ICLR
 Learning multiple layers of features from tiny images,2009, 2009
 Cleannet: Transfer learning for scalableimage classifier training with label noise,2018, In CVPR
 Learning to learn from noisylabeled data,2019, In CVPR
 Learning fromnoisy labels with distillation,2017, In ICCV
 Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels,2018, In ICML
 Dimensionality-driven learning with noisy labels,2018, InICML
 Noise tolerance under risk minimization,2013, IEEE transactions oncybernetics
 Learning from binary labelswith instance-dependent noise,2018, Machine Learning
 Learning withnoisy labels,2013, In NeurIPS
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In CVPR
 Training deep neural networks on noisy labels with bootstrapping,2014, In ICLR Workshop
 Learning with bad training data via iterative trimmed lossminimization,2019, In ICML
 Selfie: Refurbishing unclean samples for robust deeplearning,2019, In ICML
 Joint optimization frameworkfor learning with noisy labels,2018, In CVPR
 Learning with symmetric labelnoise: The importance of being unhinged,2015, In NeurIPS
 Symmetric crossentropy for robust learning with noisy labels,2019, In CVPR
 A topologicalfilter for learning with label noise,2020, In NeurIPS
 Learning from massive noisylabeled data for image classification,2015, In CVPR
 L_dmi: A novel information-theoretic lossfunction for training deep nets robust to label noise,2019, In NeurIPS
 Learning frommultiple annotators with varying expertise,2014, Machine learning
 Probabilistic end-to-end noise correction for learning with noisy labels,2019, InCVPR
 Understandingdeep learning requires rethinking generalization,2017, In ICLR
 Generalized cross entropy loss for training deep neural networkswith noisy labels,2018, In NeurIPS
 Error-bounded correction of noisy labels,2020, In ICML
