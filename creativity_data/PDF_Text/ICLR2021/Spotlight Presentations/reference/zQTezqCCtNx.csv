title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2019, In ICML
 Hilbert-based generativedefense for adversarial examples,2019, In ICCV
 Minimally distorted adversarial examples with a fast adaptiveboundary attack,2020, ICML
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, ICML
 Compression to the rescue: Defending from adversarial attacksacross modalities,2018, In KDD
 Bert: Pre-training of deepbidirectional transformers for language understanding,2019, In NAACL
 Stochastic activation pruning for robust adversarial de-fense,2018, ICLR
 Adversarialcamouflage: Hiding physical-world attacks with natural styles,2020, In CVPR
 Robust physical-world attacks on deep learningvisual classification,2018, In CVPR
 Improved robustness to adversarial examples usinglipschitz regularization of the loss,2018, arXiv preprint arXiv:1810
 Batchnormalization is a cause of adversarial vulnerability,2019, ICML Workshop
 Explaining and harnessing adversarialexamples,2015, In ICLR
 Towards deep neural network architectures robust to adversarialexamples,2014, Computer Science
 Deep residual learning for image recog-nition,2016, In CVPR
 Imbalanced gradients: Anew cause of overestimated adversarial robustness,2020, arXiv preprint arXiv:2006
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In CVPR
 Delving into transferable adversarial exam-ples and black-box attacks,2017, ICLR
 Characterizing adversarial subspaces usinglocal intrinsic dimensionality,2018, In ICLR
 Under-standing adversarial attacks on deep learning based medical image analysis systems,2021, PatternRecognition
 Adversarial neural pruning with latent vulnerability suppres-sion,2020, ICML
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 Defend deep neural networksagainst adversarial examples via fixed anddynamic quantized activation functions,2018, arXiv preprintarXiv:1807
 Overfitting in adversarially robust deep learning,2020, ICML
 Very deep convolutional networks for large-scale imagerecognition,2014, Computer Science
 Harnessing the vulnera-bility of latent layers in adversarially trained models,2019, AAAI
 Intriguing properties of neural networks,2014, ICLR
 On adaptive attacks toadversarial example defenses,2020, arXiv preprint arXiv:2002
 A unifiedapproach to interpreting and boosting adversarial transferability,2021, In ICLR
 Residual convolutional ctc networksfor automatic speech recognition,2017, arXiv preprint arXiv:1702
 On theconvergence and robustness of adversarial training,2019, In ICML
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In ICLR
 A discriminative feature learning approachfor deep face recognition,2016, In ECCV
 Skip connections matter:On the transferability of adversarial examples generated with resnets,2020, In ICLR
 Feature denoisingfor improving adversarial robustness,2019, In CVPR
 Interpreting adversarial examples by activation promotion and suppression,2019, arXiv preprintarXiv:1904
 Wide residual networks,2016, BMVC
 Efficient neuralnetwork robustness certification with general activation functions,2018, In NeurIPS
 Channelsuppressing helps learn high-quality representations with high inter-class separation and intra-classcompactness,2016, Interestingly
