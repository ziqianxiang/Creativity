title,year,conference
 Approximation by superpositions of a sigmoidal function,1989, Mathematics of Control
 BERT: Pre-training of deepbidirectional transformers for language understanding,2019, In Conference of the North AmericanChapter of the Association for Computational Linguistics: Human Language Technologies
 Automatic chemical design using a data-driven continuousrepresentation of molecules,2018, ACS Central Science
 Generative adversarial nets,2014, In Advances in NeuralInformation Processing Systems
 Certification of algorithm 112: position of point relative to polygon,1962, Communicationsof the ACM
 Multilayer feedforward networks areuniversal approximators,1989, Neural Networks
 Learning capability and storage capacity of two-hidden-layer feedforwardnetworks,2003, IEEE Transactions on Neural Networks
 Upper bounds on the number of hidden neurons in feed-forward networks with arbitrary bounded nonlinear activation functions,1998, IEEE Transactions onNeural Networks
 Junction tree variational autoencoder formolecular graph generation,2018, In International Conference on Machine Learning
 Universal approximation with deep narrow networks,2020, In Conferenceon Learning Theory
 Auto-encoding variational bayes,2013, In International Conferenceon Learning Representations
 Multilayer feedforwardnetworks with a nonpolynomial activation function can approximate any function,1993, Neural Networks
 RoBERTa: A robustly optimized BERT pretrainingapproach,2019, arXiv preprint arXiv:1907
 Approximation theory of the MLP model in neural networks,1999, Acta Numerica
 Algorithm 112: position of point relative to polygon,1962, Communications of the ACM
 Benefits of depth in neural networks,2016, In Conference on Learning Theory
 The Jordan-SchGnflies theorem and the classification of surfaces,1992, The AmericanMathematical Monthly
 A proof of the Jordan curve theorem,1980, Bulletin of the London Mathematical Society
 Memory capacity of neural networks with threshold and ReLU activations,2020, arXivpreprint 2001
 Optimal approximation of continuous functions by very deep relu networks,2018, InConference on Learning Theory
