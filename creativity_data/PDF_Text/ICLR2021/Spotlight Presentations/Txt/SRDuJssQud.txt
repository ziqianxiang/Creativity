Published as a conference paper at ICLR 2021
Neural Approximate Sufficient Statistics for
Implicit Models
Yanzhi Chen1； Dinghuai Zhang2*, Michael U. Gutmann1, Aaron Courville2, Zhanxing Zhu3
1The University of Edinburgh, 2MILA, 3Beijing Institute of Big Data Research
Ab stract
We consider the fundamental problem of how to automatically construct summary
statistics for implicit generative models where the evaluation of the likelihood
function is intractable but sampling data from the model is possible. The idea is to
frame the task of constructing sufficient statistics as learning mutual information
maximizing representations of the data with the help of deep neural networks. The
infomax learning procedure does not need to estimate any density or density ratio.
We apply our approach to both traditional approximate Bayesian computation and
recent neural likelihood methods, boosting their performance on a range of tasks.
1	Introduction
Many data generating processes can be well-described by a parametric statistical model that can be
easily simulated forward but does not possess an analytical likelihood function. These models are
called implicit generative models (Diggle & Gratton, 1984) or simulator-based models (Lintusaari
et al., 2017) and are widely used in science and engineering domains, including physics (Sjostrand
et al., 2008), genetics (Jarvenpaa et al., 2018), computer graphics (Mansinghka et al., 2013), robotics
(Lopez-Guevara et al., 2017), finance (Bansal & Yaron, 2004), cosmology (Weyant et al., 2013),
ecology (Wood, 2010) and epidemiology (Chinazzi et al., 2020). For example, the number of
infected/healthy people in an outbreak could be well modelled by stochastic differential equations
(SDE) simulated by Euler-Maruyama discretization but the likelihood function of a SDE is generally
non-analytical. Directly inferring the parameters of these implicit models is often very challenging.
The techniques coined as likelihood-free inference open us a door for performing Bayesian inference
in such circumstances. Likelihood-free inference needs to evaluate neither the likelihood function
nor its derivatives. Rather, it only requires the ability to sample (i.e. simulate) data from the model.
Early approaches in approximate Bayesian computation (ABC) perform likelihood-free inference
by repeatedly simulating data from the model, and pick a small subset of the simulated data close
to the observed data to build the posterior (Pritchard et al., 1999; Marjoram et al., 2003; Beaumont
et al., 2009; Sisson et al., 2007). Recent advances make use of flexible neural density estimators to
approximate either the intractable likelihood (Papamakarios et al., 2019) or directly the posterior
(Papamakarios & Murray, 2016; Lueckmann et al., 2017; Greenberg et al., 2019).
Despite the algorithmic differences, a shared ingredient in likelihood-free inference methods is the
choice of summary statistics. Well-chosen summary statistics have been proven crucial for the
performance of likelihood-free inference methods (Blum et al., 2013; Fearnhead & Prangle, 2012;
Sisson et al., 2018). Unfortunately, in practice it is often difficult to determine low-dimensional and
informative summary statistic without domain knowledge from experts. In this work, we propose a
novel deep neural network-based approach for automatic construction of summary statistics. Neural
networks have been previously applied to learning summary statistics for likelihood-free inference
(Jiang et al., 2017; Dinev & Gutmann, 2018; Alsing et al., 2018; Brehmer et al., 2020). Our approach
is unique in that our learned statistics directly target global sufficiency. The main idea is to exploit
the link between statistical sufficiency and information theory, and to formulate the task of learning
sufficient statistic as the task of learning information-maximizing representations of data. We achieve
this with distribution-free mutual information estimators or their proxies (Szekely et al., 2014; Hjelm
* Equal contribution. Correspondence to Yanzhi Chen (rhythm.cyz@gmail.com) or Dinghuai Zhang
(dinghuai.zhang@mila.quebec). Codes available at: https://github.com/cyz-ai/neural-approx-ss-lfi.
1
Published as a conference paper at ICLR 2021
et al., 2018). Importantly, our statistics can be learned jointly with the posterior, resulting in fast
learning where the two can refine each other iteratively. To sum up, our main contributions are:
•	We propose a new neural approach to automatically extract compact, near-sufficient statistics from
raw data. The approach removes the need for careful handcrafted design of summary statistics.
•	With the proposed statistics, we develop two new likelihood-free inference methods namely SMC-
ABC+ and SNL+. Experiments on tasks with various types of data demonstrate their effectiveness.
2	Background
Likelihood-free inference. LFI considers the task of Bayesian inference when the likelihood function
of the model is intractable but simulating (sampling) data from the model is possible:
π(θ∣Xo) H π(θ)p(xo∣θ)	(1)
'{z~*}
?
where x° is the observed data, ∏(θ) is the prior over the model parameters θ, p(x0 ∣θ) is the (possibly)
non-analytical likelihood function and ∏(θ∣x0) is the posterior over θ. We assume that, while We
do not have access to the exact likelihood, we can still sample (simulate) data from the model
with a simulator: X 〜p(x∣θ). The task is then to infer ∏(θ∣x0) given x° and the sampled data:
D = {θi, Xi}n=ι where θ 〜p(θ), Xi 〜p(x∣θi). Note that p(θ) is not necessarily the prior ∏(θ).
Curse of dimensionality. Different likelihood-free inference algorithms might learn ∏(θ∣x°) in
different ways, nevertheless most existing methods suffer from the curse of dimensionality. For
example, traditional ABC methods use a small subset of D closest to Xo under some metric to
build the posterior (Pritchard et al., 1999; Marjoram et al., 2003; Beaumont et al., 2009; Sisson
et al., 2007), however in high-dimensional space measuring the distance sensibly is notoriously
hard (Sorzano et al., 2014; Xie et al., 2017). On the other hand, recent advances (Papamakarios
et al., 2019; Lueckmann et al., 2017; Papamakarios & Murray, 2016; Greenberg et al., 2019) utilize
neural density estimators (NDE) to model the intractable likelihood or the posterior. Unfortunately,
modeling high-dimensional distributions with NDE accurately is also known to be very difficult
(Rippel & Adams, 2013; Van Oord et al., 2016), especially when the available training data is scarce.
Our interest here is not to design a new inference algorithm, but to find a low-dimensional statistic
s = s(X) that is (Bayesian) sufficient:
∏(θ∣Xo) ≈ ∏(θ∣So) H π(θ)p(So∣θ),	(2)
where s : X → S is a deterministic function also learned from D. We conjecture that the learning
of s(∙) might be an easier task than direct density estimation. The resultant statistic S could then be
applied to a wide range of likelihood-free inference algorithms as we will elaborate in Section 3.2.
3	Methodology
3.1	Neural sufficient statistics
Our new deep neural network-based approach for automatic construction of near-sufficient statistics
is based on the infomax principle, as illustrated by the following proposition (also see Figure 1):
Proposition 1. Let θ 〜 p(θ), X 〜p(x∣θ), and S : X → S be a deterministic function. Then
s = s(x) is a sufficient statistic for p(x∣θ) ifand only if
s = arg max I(θ; S(X)),
S:X →S
where S is deterministic mapping and I(∙; ∙) is the mutual information between random variables.
Proof. We defer the complete proof to the appendix. This proposition is a variant of Theorem 8 in
(Shamir et al., 2010) with an adaption to the likelihood-free inference scenario.	□
This important result suggests that we could find the sufficient statistic s = s(X) for a likelihood
function p(x∣θ) by maximizing the mutual information (MI) I(θ;S) = KL[p(θ,s)kp(θ)p(s)] be-
tween θ and s. Moreover, as our interest is in maximizing MI rather than knowing its precise value,
2
Published as a conference paper at ICLR 2021
Figure 1: Left. Traditional likelihood-free inference algorithm needs handcrafted design of summary
statistic, which requires expert knowledge. Right. Our method automatically mines a low dimensional,
near-sufficient statistic s of x via the infomax principle, which removes the need for careful summary
statistic design. Furthermore, this statistics can be re-learned as the posterior inference proceeds.
we can maximize a non-KL surrogate, which may have an advantage in e.g. estimation accuracy or
computational efficiency (Szekely et al., 2014; Hjelm et al., 2018; Ozair et al., 2019). To this end, We
utilize the following two non-KL estimators:
Jensen-Shannon divergence (JSD) (Hjelm et al., 2018): this non-KL estimator is shoWn to be more
robust than KL-based ones. More specifically, it is defined as:
IJSD(θ; S)=	SUp	Ep(θ,s) [- sp(-T(θ, s))] - Ep(θ)p(s) [sp(T(θ, s))],	⑶
T:Θ×S→R
Where sp(t) = log(1 + exp(t)) is the softplus function. With this estimator, We set up the folloWing
objective for learning the sufficient statistics, Which simultaneously estimates and maximizes the MI:
max L(S,T)=Ep(θ,x)[-sp(-T(θ,S(x)))]-Ep(θ)p(x)[sp(T(θ,S(x))],
S,T
(4)
Where the tWo deterministic mappings S and T are parameterized by tWo neural netWorks. Note that
We have used the laW of the unconscious statistician (LOTUS) from equation 3 to equation 4. The
mini-batch version of this objective is given in the appendix.
Distance correlation (DC) (Szekely et al., 2014): unlike the JSD estimator, this estimator does not
need to learn an additional netWork T, and can be learned much faster. It is defined as:
IDC(θ; s) = _________Ep(e,s)p(e0,s0)[h(：,T)h(S, s0)]_______
'S	pEp(θ)p(θ0) [h2 (θ,θ0)] ∙ PEp(S)p(s0)[h2(s, S0)],
(5)
Where h(a, b) = ka-bk -Ep(b0)[ka-b0k] -Ep(a0)[ka0-bk] +Ep(a0)p(b0)[ka0-b0k]. Similar to
the case of the JSD estimator, We set up the folloWing objective for learning the sufficient statistics:
max L(S)
Ep(θ,x)p(θ0,x0)[h(θ, θ0)h(S(x), S(x0))]
PEp(θ)p(θ0)[h2(θ,θ0)]∙pEp(x)p(χθ)[h2(S(x),S(x0))],
(6)
Where the deterministic mapping S is parameterized by a neural netWork. Again LOTUS is used from
equation 5 to equation 6. The mini-batch version of this objective is given in the appendix.
A comparison betWeen the accuracy and efficiency of these tWo MI estimators (as Well as other
estimators (Belghazi et al., 2018; Ozair et al., 2019)) for infomax statistics learning is in the appendix.
With enough training samples and poWerful neural netWorks, We can obtain near-sufficient statistics
With either s = arg maxS maxT L(S, T) or s = arg maxS L(S), depending on the estimator. The
statistic s of data x is then given by
s = s(x).	(7)
In the above construction, We have not specified the form of the netWorks S and T. For S, any prior
knoWledge about the data x could in principle be incorporated into its design. For example, for
sequential data We can realize S as a transformer (VasWani et al., 2017), and for exchangeable data
We can realize S as a exchangeable neural netWork (Chan et al., 2018). Here We simply adopt a
fully-connected architecture for S, and leave the problem-specific design of S as future Work. For T,
we choose it to be a split architecture T (θ, S (x)) = T 0(H (θ), S (x)) where T 0(∙, ∙),H (∙) are both
MLPs. Therefore We separately learn loW-dimensional representations for x and θ before processing
3
Published as a conference paper at ICLR 2021
them together. This could be seen as that we incorporate the inductive bias into the design of the
networks that x and θ should not interact with each other directly, based on their true relationship
(for example, consider the likelihood function of exponential family: L(θ; x) 8 exp(H(θ)>S(x))).
We are left with the problem of how to select d, the dimensionality of the sufficient statistics. The
Pitman-Koopman-Darmois theorem (Koopman, 1936) tells us that sufficient statistics with fixed
dimensionality only exists for exponential family, so there is no universal way to select d. Here, we
propose to use the following simple heuristics to determine d:
d = 2K	(8)
where K is the dimensionality of θ (which typically satisfies K D). The rationale behind this
heuristics is that the dimensionality of the sufficient statistics in the exponential family is K , and
exponential family has been proven reasonably accurate for posterior approximation (see e.g. Thomas
et al., 2021; Pacchiardi & Dutta, 2020). By doubling the dimensionality of the statistics to 2K we are
likely to have a better representative power than the exponential family while still keeping d small.
Furthermore, we have the following proposition comparing our method to the existing posterior-
mean-as-statistic approaches (Fearnhead & Prangle, 2012; Jiang et al., 2017).
Proposition 2. Let θ 〜p(θ) and X 〜p(x∣θ). Let s(∙) be a deterministic function that satisfies
s = arg min Ep(θ,x) [kS(x) - θk22],
S:X→S
then s = s(x) is generally not a maximizer ofI(S(x); θ) and hence it is not a sufficient statistic.
Proof. We defer the proof to the appendix.	□
This proposition tells us that unlike our method, the existing (posterior-)mean-as-statistic approaches
widely used in likelihood-free inference community lose information about the posterior, and it is
only optimal for predicting the posterior mean (Fearnhead & Prangle, 2012; Jiang et al., 2017). When
using this statistics in inference, it may yield inaccurate estimates of e.g. the posterior uncertainty.
Nonetheless which statistics to use depends on the task, e.g. full posterior vs. point estimation.
3.2	Dynamic statistics-posterior learning
The above neural sufficient statistic could, in principle, be learned via a pilot run before the inference
starts, as, for example, done in the work by Drovandi et al. (2011); Fearnhead & Prangle (2012);
Jiang et al. (2017). Such a strategy requires extra simulation cost, and the learned statistic is kept
fixed during inference. We propose a dynamic learning strategy below to overcome these limitations.
Our idea is to jointly learn the statistic and the posterior in multiple rounds. More concretely, at round
j, We use the current statistic s(∙) to build the j-th estimate to the posterior: qj(θ∣s0) ≈ ∏(θ∣x0),
and at round j+1, this estimate is used as the new proposal distribution to simulate data: pj+ι(θ) J
qj(θ∣So),θi 〜pj+ι(θ), Xi 〜p(x∣θi). We then re-learn s(∙) and q(∙) with all the data up to the new
round. In this process, s(∙) and q(∙) refine each other: a good s(∙) helps to learn q(∙) more accurately,
whereas an improved q(∙) as a better proposal in turn helps to learn s(∙) more efficiently.
The theoretical basis of this multi-rounds strategy is provided by Proposition 1, which tells us that the
sufficiency of the learned statistics is insensitive to the choice of p(θ), the marginal distribution ofθ
in sampled data D = {xi, θi}in=j1. This means that we are indeed safe to use any proposal distribution
pl(θ) at any round l in multi-rounds learning, and in such case p(θ) after round j will be a mixture
distribution formed by the proposal distributions of the previous rounds, i.e. p(θ) = j Pj=ι Pl (θ).
4
Published as a conference paper at ICLR 2021
Algorithm 1 SMC-ABC+
Input: prior π(θ), observed data xo
Output: estimated posterior ∏(θ∣xo)
Initialization: D = 0,pι(θ) = π(θ)
for j in 1 to r do
repeat
sample θi 〜Pj (θ);
simulate Xi 〜p(x∣θi)；
until n samples
D-D∪{θi, Xi}n=ι
fit statistic net s(∙) with D by equation 4 ;
sort D according to ks(Xi) - s(Xo)k ;
fit p(θ∣So) with the top m θs in D;
qj(θ∣so) Z p(θ∣So)∏(θ)/ Pjpι(θ);
Pj+ι(θ) - qj (θlso);
end for
return ∏(θ∣x0) = q『(θ∣So)
Algorithm 2 SNL+
Input: prior π(θ), observed data Xo
Output: estimated posterior ∏(θ∣xo)
Initialization: D = 0,pι(θ) = π(θ)
for j in 1 to r do
repeat
sample θ 〜Pj (θ);
simulate Xi 〜p(x∣θi);
until n samples
D-D∪{θi, Xi}itι
fit statistic net s(∙) with D by equation 4;
convert D with the learned s(∙);
fit q(s∣θ) with converted D by equation 11;
qj(θ∣So) z π(θ) ∙ q(so∣θ);
pj + 1(θ) J qj(θlso);
end for
return ∏(θ∣x0) = qr(θ∣s0)
In practice, any likelihood-free inference algorithm that learns the posterior sequentially naturally fits
well within the above joint statistic-posterior learning strategy. Here we study two such instances:
Sequential Monte Carlo ABC (SMC-ABC) (Beaumont et al., 2009). This classical algorithm learns
the posterior in a non-parametric way within multiple rounds. Here, we consider a variant of it to
better make use of the above neural sufficient statistic, and to re-use all previous simulated data. The
new SMC-ABC algorithm estimates the posterior qj∙ (θ∣s0) at the j-th round as follows. We first sort
data in D = {Xi, θi}in=j1 according to the distances ks(Xi) - s(Xo)k. We then pick the top-m θs
whose corresponding distances are the smallest. The picked θs then follow θ 〜p(θ | So) as below:
j
p(θ | So) Z Xpι(θ) ∙ Pr(ks -Sok <e | θ),	⑼
l=1
where the threshold E is implicitly defined by the ratio m (which automatically goes to zero as
j → ∞). We then fit p(θ∣so) with the collected θs by a flexible parametric model (e.g. a Gaussian
copula), with which we can obtain the j-th estimate to the posterior by importance (re-)weighting:
j
qj(θ | So) Zp(θ | so)∏(θ)∕χPι(θ).	(10)
l=1
The whole procedure of this new inference algorithm, SMC-ABC+, is summarized in Algorithm 1.
Sequential Neural Likelihood (SNL) (Papamakarios et al., 2019). This recent algorithm learns the
posterior in a parametric way, also in multiple rounds. The original SNL method approximates the
likelihood function p(x∣θ) by a conditional neural density estimator q(x∣θ), which could be difficult
to learn if the dimensionality of X is high. Here, we alleviate such difficulty with our neural statistic.
The new SNL algorithm estimates the posterior qj∙ (θ∣so) at the j-th round as follows. At round j,
where we have nj simulated data D = {θi, Xi}rn= ι, we fit a neural density estimator q(s∣θ) as:
nj
q(S | θ) = arg max	log Q(s(Xi) | θi),	(11)
Q	i=1
where s(∙) is the current statistic network and Q is a neural density estimator (e.g. Durkan et al.
(2019); Papamakarios et al. (2017)). With nj being moderately large and Q flexible enough, this
would yield us q(s∣θ) ≈ p(s∣θ). We then obtain the j-th estimate of the posterior by Bayes rule:
qj(θ | So) z π(θ) ∙ q(so | θ).	(12)
The whole procedure of this new SNL algorithm, denoted as SNL+, is summarized in Algorithm 2.
5
Published as a conference paper at ICLR 2021
4	Related Works
Approximate Bayesian computation. ABC denotes techniques for likelihood-free inference which
work by repeatedly simulating data from the model and picking those similar to the observed data to
estimate the posterior (Sisson et al., 2018). Naive ABC performs simulation with the prior, whereas
MCMC-ABC (Marjoram et al., 2003; Meeds et al., 2015) and SMC-ABC (Beaumont et al., 2009;
Sisson et al., 2007) use informed proposals, and more advanced methods employ experimental design
or active learning to accelerate the inference (Gutmann & Corander, 2016; Jarvenpaa et al., 2019). To
measure the similarity to the observed data, it is often wise to use low-dimensional summary statistics
rather than the raw data. Here we develop a way to learn compact sufficient statistics for ABC.
Neural density estimator-based inference. Apart from ABC, a recent line of research uses a
conditional neural density estimator to (sequentially) learn the intractable likelihood (e.g SNL Papa-
makarios et al. (2019); Lueckmann et al. (2019)) or directly the posterior (e.g SNPE Papamakarios &
Murray (2016); Lueckmann et al. (2017); Greenberg et al. (2019)). Likelihood-targeting approaches
have the advantage that they could readily make use of any proposal distribution in sequential learning,
but they rely on low-dimensional, well-chosen summary statistic. Posterior-targeting methods on
the contrary need no design of summary statistic, but they require non-trivial efforts to facilitate
sequential learning. Our approach (e.g SNL+) can be seen as taking the advantages from both worlds.
Automatic construction of summary statistics. A set of works have been proposed to automatically
construct low-dimensional summary statistics. Two lines of them are most related to our approach.
The first line (Fearnhead & Prangle, 2012; Jiang et al., 2017; Chan et al., 2018; Wiqvist et al., 2019;
Dinev & Gutmann, 2018) train a neural network to predict the posterior mean and use this prediction
as the summary statistic. These mean-as-statistic approaches, as analyzed previously in Proposition
2, indeed do not guarantee sufficiency. Rather than taking the predicted mean, the works (Alsing
et al., 2018; Brehmer et al., 2020) take the score function Vθ logp(x∣θ)∣θ=θ* around some fiducial
parameter θ* as the summary statistic. However, these SCore-as-statistic methods are only locally
sufficient around θ*. Our approach differs from all these methods as it is globally sufficient for all θ.
MI and ratio estimation. It has been shown in the literature that many variational MI estimators
I(X; Y ) also estimate the ratio p(X, Y )/p(X)p(Y ) up to a constant (Nowozin et al., 2016; Nguyen
et al., 2010). Therefore our MI-based statistic learning method is closely related to ratio estimating
approaches to posterior inference (Hermans et al., 2020; Thomas et al., 2021). The differences are 1)
we decouple the task of statistics learning from the task of density estimation for LFI, which grants
us the privilege to use any infomax representation learning methods that are ratio-free (SzekeIy et al.,
2014; Ozair et al., 2019); and 2) even if we do estimate the ratio, we do this in the low-dimensional
space based on a sufficient statistics perspective, which is typically easier than in the original space.
5	Experiments
5.1	Setup
Baselines. We apply the proposed statistics to two aforementioned likelihood-free inference methods:
(i) SMC-ABC (Beaumont et al., 2009) and (ii) SNL (Papamakarios et al., 2019). We compare the
performance of the algorithms augmented with our neural statistics (dubbed as SMC-ABC+ and
SNL+) to their original versions as well as the versions based on expert-designed statistics (details
presented later; we call the corresponding methods SMC-ABC’ and SNL’). We also compare to the
sequential neural posterior estimate (SNPE) method1 which needs no statistic design, as well as
the sequential ratio estimate (SRE) method (Hermans et al., 2020) which is closely related to our
MI-based method2. All methods are run for 10 rounds with 1,000 simulations each. The results
presented below are for the JSD estimator; the DC estimator achieves similar accuracy (see appendix).
Evaluation metric. To assess the quality of the estimated posterior, we compare the Jensen-Shannon
divergence (JSD) between the approximate posterior Q and the true posterior P for each method
1More specifically, the version B. We compare with SNPE-B (Lueckmann et al., 2017) rather than the more
recent SNPE-C (Greenberg et al., 2019) due to its similarity to SRE shown in (Durkan et al., 2020).
2For fair comparison, we control that the neural network in SRE has a similar number of parameters/same
optimizer settings as in our method. See the appendix for more details about the settings of the neural networks.
6
Published as a conference paper at ICLR 2021
(a)
(b)	(c)
Figure 2: Ising model. (a) The 64D observed data xo ∈ {-1, 1}64. (b) The JSD between the true and
the learned posteriors. (c) The relationship between the learned statistics and the sufficient statistic.
SMC’	SMC+	SNL’	SNL+	SRE	SNPE
0.008 ± 0.006 0.046 ± 0.051 0.007 ± 0.002 0.015 ±0.011 0.083 ± 0.029 0.058 ± 0.039
Table 1:	Ising model. The JSD between the learned and true posterior with 10,000 simulations. Here
SMC’ and SNL’ utilize the ground-truth sufficient statistics guided by human prior knowledge.
(see appendix). For the problems we consider, the true posterior P is either analytically available, or
can be accurately approximated by a standard rejection ABC algorithm (Pritchard et al., 1999) with
known low-dimensional sufficient statistic (e.g S(X) ∈ %) and extensive simulations (e.g 106).
5.2 Results
We demonstrate the effectiveness of our method on three models: (a) an Ising model; (b) a Gaussian
copula model; (c) an Ornstein-Uhlenbeck process. The Ising model does not have an analytical
likelihood but the posterior can be approximated accurately by rejection ABC due to the existence of
low-dimensional, discrete sufficient statistic. The last two models have analytical likelihoods and
hence analytical posteriors. These models cover the cases of graph data, i.i.d data and sequence data.3
Ising model. The first model we consider is a mathematical model in statistical physics that describes
the states of atomic spins on a 8 × 8 lattice (see Figure 1(a)). Each spin has two states described by a
discrete random variable xi ∈ {-1, +1}, and is only allowed to interact with its neighbour. Given
parameters θ = {θ1 , θ2}, the probability density function of the Ising model is:
p(x∣θ) a exp(-H(x;θ)),
H(x; θ) = -θι X xixj - θ2 Xxi.
hi,ji	i
where hi, ji denotes that spin i and spin j are neighbours. H is also called the Hamiltonian of the
model. The likelihood function of this model is not analytical due to the intractable normalizing
constant Z(θ) = J^χ∈{-ι ι}m∙m exp[-H(x; θ)]. However, sampling from the model by MCMC is
possible. Note that the sufficient statistics are known for this model: s*(x) = {£〈, j XiXj, Ei x,}.
The true posterior can easily be approximated by rejection ABC with the low-dimensional sufficient
statistics and extensive simulations. Here, we assume that θ2 is known, and the task is to infer the
posterior of θι under an uniform prior θι 〜U(0,1.5) (in this case the sufficient statistic becomes
only 1D: s*(x) = Ehi ji XiXj). The true parameters are θ* = {0.3, 0.1}.
In Figure 1(c), we investigate whether the proposed statistic could achieve sufficiency. Ideally, if
the learned statistic S in our method does recover the true sufficient statistic s* well, the relationship
between S and s* should be nearly monotonic (note that both S and s* are here 1D). To verify this,
3We chose to conduct experiments on these models rather than common tasks like M/G/1 and Lotka-Volterra
since they lack a known true likelihood, making it hard to verify the sufficiency of the proposed statistics. How
to evaluate LFI methods on models without known likelihood is still an open problem (Lueckmann et al., 2021).
7
Published as a conference paper at ICLR 2021
(a)	(b)
Figure 3: Gaussian copula. (a) The observed data xo in this problem, which is comprised of a
population of 200 i.i.d samples. (b) The JSD between the true/learned posteriors. (c) The contours.
Truth	SMC	SMC+
SNL	SNL+
(c)
SMC’	SMC+	SNL’	SNL+	SRE	SNPE
0.183 ± 0.014 0.047 ± 0.009 0.054 ± 0.016 0.042 ± 0.006 0.052 ± 0.032 0.037 ± 0.018
Table 2:	Gaussian copula. The JSD between the learned and true posterior with 10,000 simulations.
Here SMC’ and SNL’ utilize the hand-crafted summary statistics guided by human prior knowledge.
We plot the relationship between s* and s. We see from the figure that S learned by our method does,
approximately, increase monotonically with s*, suggesting that S recovers s* reasonably well. In
comparison, the statistics learned with the widely-used posterior-mean-as-statistics approach only
weakly depends on the true sufficient statistic; it is nearly indistinguishable for different S*. In other
words, it loses sufficiency. The result empirically verifies our theoretical result in Proposition 2.
Figure 1(b) further shows the JSD between the true and learned posterior for different methods across
the rounds (the vertical lines indicates standard derivation, each JSD is obtained by calculating the
average of 5 independent runs. The results shown in the below experiments have the same setup).
It can be seen from the figure that for this model, likelihood-free inference methods augmented
with the proposed statistic (SMC-ABC+, SNL+) outperform their original counterparts (SMC-ABC,
SNL) by a large margin. In Table 1, we further compare our statistics with the expert designed
statistics, from which one can see their close performance (here the expert statistics is taken as the
true sufficient statistics s*). We further see that our method also outperforms SRE which directly
estimates the ratio t(x, θ) = p(x, θ)∕p(x)p(θ) ɑ L(θ; x) in high-dimensional space (note that the
true likelihood is of the form L(θ; x) = exp(θs*(x))∕Z(θ)) as well as SNPE (version B). The reason
why SNPE(-B) does not perform more satisfactorily might be that it relies on importance weights to
facilitate sequential learning, which can induce high variance that makes the training unstable.
Gaussian copula. The second model we consider is a 2D Gaussian copula model (Chen & Gutmann,
2019). Data x for this model can be generated with aid of a latent variable z as follows:
Z 〜N(Z; 0, ]θ1;, θ13]),
x1 = F1-1(Φ(z1); θ1),	x2 = F2-1(Φ(z2); θ2),
f1(x1; θ1) = Beta(x1; θ1, 2), f2(x2; θ2) = θ2N(x2; 1, 1) + (1 - θ2)N(x2; 4, 1/4).
where Φ(∙), F1(χ1; θι), F2(χ2; θ2) are the cumulative distribution function (CDF) of the standard
normal distribution, the CDF of f1(x1; θ1) and the CDF of f2(x2; θ2) respectively. We assume that a
total number of 200 samples are i.i.d drawn from this model, yielding a population X = {xi}i2=001
that serves as our observed data. Note that the likelihood of this model can be computed analytically
by the law of variable transformation. To perform inference, we compute a rudimentary statistic to
describe X, namely (a) the 20-equally spaced quantiles of the marginal distributions of X and (b) the
correlation between the latent variables z1 , z2 in X, resulting in a statistic of dimensionality 41. A
uniform prior is used: θι 〜U(0.5,12.5), θ2 〜U(0,1), θ3 〜U(0.4,0.8) and θ* = {6,0.5,0.6}.
In Figure 2(b), we demonstrate the power of our neural sufficient statistic learning method on the
Gaussian copula problem. Overall, we see that the proposed method improves the accuracy of
8
Published as a conference paper at ICLR 2021
(a)	(b)
Figure 4: OU process. (a) The observed time-series data xo = {xt}t5=0 1. (b) The JSD between the
true and the learned posteriors. (c) The contours of the true posterior and the learned posteriors.
Truth	SMC	SMC+
SNL	SNL+
(c)
SMC’	SMC+	SNL’	SNL+	SRE	SNPE
0.040 ± 0.006 0.044 ± 0.018 0.004 ± 0.001 0.009 ± 0.002 0.022 ± 0.013 0.019 ± 0.009
Table 3:	OU process. The JSD between the learned and the true posterior with 10,000 simulations.
Here SMC’ and SNL’ utilize the hand-crafted summary statistics guided by human prior knowledge.
existing likelihood-free inference methods, as well as their robustness, see e.g. the reduced variability
for SNL+ (the high variability in SNL may be due to the lack of training data required to learn the
41-dimensional likelihood function well). This is also confirmed by the contours plots in Figure 2(c).
In Table 2 we further compare the proposed statistic with the expert-designed low-dimension statistic
(here the expert statistic is taken to be the 5-equally spaced marginal quantiles and the correlations
between z1 , z2), from which we see that our proposed statistic achieves a better performance. For
this model, the average performance of our method is slightly worse than that of SNPE. However,
SNPE has a higher variability, so that the difference in performance is actually not significant.
Ornstein-Uhlenbeck process. The last model we consider is a stochastic differential equation (SDE).
Data x = {xt}tD=1 in this model is sequentially generated as:
xt+1 = xt + ∆xt,
∆xt = θ1(exp(θ2) — xt)∆t + 0.5e,	e ~ N(e; 0, ∆t).
where D = 50, ∆t = 0.2 and x0 = 10. This SDE can be simulated by the Euler-Maruyama method,
and has an analytical likelihood. It has a wide application in financial mathematics and the physical
sciences. Here, the parameters of interest are θ = {θ1, θ2}, and a uniform prior is placed on them:
θι ~ U(0,1), θι 〜U(—2.0, 2.0). The true parameters are set to be θ* = {0.5,1.0}.
Figure 3(b) compares the JSD of each method against the simulation cost. Again, we find that the
proposed neural sufficient statistics greatly improve the performance of both SMC-ABC and SNL. In
Table 3, we compare our statistics to expert statistics (here the expert statistics are taken as the mean,
standard error and autocorrelation with lag 1, 2, 3 of the time series). It can be seen that our statistics
perform comparably to the expert statistics. Our method also seems to outperform SRE and SNPE.
6 Conclusion
We proposed a new deep learning-based approach for automatically constructing low-dimensional
sufficient statistics for likelihood-free inference. The obtained neural approximate sufficient statistics
can be applied to both traditional ABC-based and recent NDE-based methods. Our main hypothesis
is that learning such sufficient statistics via the infomax principle might be easier than estimating
the density itself. We verify this hypothesis by experiments on various tasks with graphs, i.i.d and
sequence data. Our method establishes a link between representation learning and likelihood-free
inference communities. For future works, we can consider further infomax representation learning
approaches, as well as more principle ways to determine the dimensionality of the sufficient statistics.
9
Published as a conference paper at ICLR 2021
References
Justin Alsing, Benjamin Wandelt, and Stephen Feeney. Massive optimal data compression and density
estimation for scalable, likelihood-free inference in cosmology. Monthly Notices of the Royal
Astronomical Society, 477(3):2874-2885, 2018.
Ravi Bansal and Amir Yaron. Risks for the long run: A potential resolution of asset pricing puzzles.
The journal of Finance, 59(4):1481-1509, 2004.
Mark A Beaumont, Jean-Marie Cornuet, Jean-Michel Marin, and Christian P Robert. Adaptive
approximate Bayesian computation. Biometrika, 96(4):983-990, 2009.
Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeshwar, Sherjil Ozair, Yoshua Bengio, Aaron
Courville, and Devon Hjelm. Mutual information neural estimation. In International Conference
on Machine Learning, pp. 531-540. PMLR, 2018.
Michael GB Blum, Maria Antonieta Nunes, Dennis Prangle, Scott A Sisson, et al. A comparative
review of dimension reduction methods in approximate bayesian computation. Statistical Science,
28(2):189-208, 2013.
Johann Brehmer, Gilles Louppe, Juan Pavez, and Kyle Cranmer. Mining gold from implicit models
to improve likelihood-free inference. Proceedings of the National Academy of Sciences, 117(10):
5242-5249, 2020.
Jeffrey Chan, Valerio Perrone, Jeffrey Spence, Paul Jenkins, Sara Mathieson, and Yun Song. A
likelihood-free inference framework for population genetic data using exchangeable neural net-
works. In Advances in Neural Information Processing Systems, pp. 8594-8605, 2018.
Yanzhi Chen and Michael U Gutmann. Adaptive gaussian copula abc. In The 22nd International
Conference on Artificial Intelligence and Statistics, pp. 1584-1592. PMLR, 2019.
Matteo Chinazzi, Jessica T Davis, Marco Ajelli, Corrado Gioannini, Maria Litvinova, Stefano Merler,
Ana Pastore y Piontti, Kunpeng Mu, Luca Rossi, Kaiyuan Sun, et al. The effect of travel restrictions
on the spread of the 2019 novel coronavirus (covid-19) outbreak. Science, 368(6489):395-400,
2020.
Tm Cover, Ja Thomas, and J Wiley. Elements of information theory. Tsinghua University Pres, 2003.
Peter J Diggle and Richard J Gratton. Monte Carlo methods of inference for implicit statistical
models. Journal of the Royal Statistical Society. Series B, pp. 193-227, 1984.
Traiko Dinev and Michael U Gutmann. Dynamic likelihood-free inference via ratio estimation (dire).
arXiv preprint arXiv:1810.09899, 2018.
Christopher C Drovandi, Anthony N Pettitt, and Malcolm J Faddy. Approximate Bayesian computa-
tion using indirect inference. Journal of the Royal Statistical Society: Series C (Applied Statistics),
60(3):317-337, 2011.
Conor Durkan, Artur Bekasov, Iain Murray, and George Papamakarios. Neural spline flows. arXiv
preprint arXiv:1906.04032, 2019.
Conor Durkan, Iain Murray, and George Papamakarios. On contrastive learning for likelihood-free
inference. arXiv preprint arXiv:2002.03712, 2020.
Paul Fearnhead and Dennis Prangle. Constructing summary statistics for approximate Bayesian
computation: semi-automatic approximate Bayesian computation. Journal of the Royal Statistical
Society: Series B (Statistical Methodology), 74(3):419-474, 2012.
David Greenberg, Marcel Nonnenmacher, and Jakob Macke. Automatic posterior transformation
for likelihood-free inference. In International Conference on Machine Learning, pp. 2404-2414,
2019.
Michael Gutmann and Jukka Corander. Bayesian optimization for likelihood-free inference of
simulator-based statistical models. Journal of Machine Learning Research, 17(1):4256-4302,
2016.
10
Published as a conference paper at ICLR 2021
Joeri Hermans, Volodimir Begy, and Gilles Louppe. Likelihood-free mcmc with amortized approxi-
mate ratio estimators. In International Conference on Machine Learning, pp. 4239-4248. PMLR,
2020.
R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam
Trischler, and Yoshua Bengio. Learning deep representations by mutual information estimation
and maximization. In International Conference on Learning Representations, 2018.
M. Jarvenpaa, M.U. Gutmann, A. Vehtari, and P. Marttinen. Gaussian process modeling in approx-
imate Bayesian computation to estimate horizontal gene transfer in bacteria. Annals of Applied
Statistics, 2018.
M. Jarvenpaa, M.U. Gutmann, A. Vehtari, and P. Marttinen. Efficient acquisition rules for model-
based approximate Bayesian computation. Bayesian Analysis, 14(2):595-622, 2019. doi: doi:
10.1214/18-BA1121.
Bai Jiang, Tung-yu Wu, Charles Zheng, and Wing H Wong. Learning summary statistic for ap-
proximate bayesian computation via deep neural network. Statistica Sinica, pp. 1595-1618,
2017.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Bernard Osgood Koopman. On distributions admitting a sufficient statistic. Transactions of the
American Mathematical society, 39(3):399-409, 1936.
J. Lintusaari, M.U. Gutmann, R. Dutta, S. Kaski, and J. Corander. Fundamentals and recent
developments in approximate Bayesian computation. Systematic Biology, 66(1):e66-e82, January
2017.
T. Lopez-Guevara, N.K. Taylor, M.U. Gutmann, S. Ramamoorthy, and K. Subr. Adaptable pouring:
Teaching robots not to spill using fast but approximate fluid simulation. In Sergey Levine, Vincent
Vanhoucke, and Ken Goldberg (eds.), Proceedings of the 1st Annual Conference on Robot Learning
(CoRL), volume 78 of Proceedings of Machine Learning Research, pp. 77-86, November 2017.
Jan-Matthis Lueckmann, Pedro J Goncalves, Giacomo Bassetto, Kaan Ocal, Marcel Nonnenmacher,
and Jakob H Macke. Flexible statistical inference for mechanistic models of neural dynamics. In
Advances in Neural Information Processing Systems, pp. 1289-1299, 2017.
Jan-Matthis Lueckmann, Giacomo Bassetto, Theofanis Karaletsos, and Jakob H Macke. Likelihood-
free inference with emulator networks. In Symposium on Advances in Approximate Bayesian
Inference, pp. 32-53, 2019.
Jan-Matthis Lueckmann, Jan Boelts, David S Greenberg, Pedro J Gongalves, and Jakob H Macke.
Benchmarking simulation-based inference. arXiv preprint arXiv:2101.04653, 2021.
Vikash K Mansinghka, Tejas D Kulkarni, Yura N Perov, and Josh Tenenbaum. Approximate bayesian
image interpretation using generative probabilistic graphics programs. In Advances in Neural
Information Processing Systems, pp. 1520-1528, 2013.
Paul Marjoram, John Molitor, Vincent Plagnol, and Simon TaVar6. Markov chain Monte Carlo
without likelihoods. Proceedings of the National Academy of Sciences, 100(26):15324-15328,
2003.
Edward Meeds, Robert Leenders, and Max Welling. Hamiltonian abc. In Proceedings of the
Thirty-First Conference on Uncertainty in Artificial Intelligence, pp. 582-591, 2015.
XuanLong Nguyen, Martin J Wainwright, and Michael I Jordan. Estimating divergence functionals
and the likelihood ratio by convex risk minimization. IEEE Transactions on Information Theory,
56(11):5847-5861, 2010.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers
using variational divergence minimization. In Advances in neural information processing systems,
pp. 271-279, 2016.
11
Published as a conference paper at ICLR 2021
Sherjil Ozair, Corey Lynch, Yoshua Bengio, Aaron Van den Oord, Sergey Levine, and Pierre Sermanet.
Wasserstein dependency measure for representation learning. In Advances in Neural Information
Processing Systems,pp. 15604-15614, 2019.
Lorenzo Pacchiardi and Ritabrata Dutta. Score matched conditional exponential families for
likelihood-free inference. arXiv preprint arXiv:2012.10903, 2020.
George Papamakarios and Iain Murray. Fast ε-free inference of simulation models with bayesian
conditional density estimation. In Advances in Neural Information Processing Systems, pp. 1028-
1036, 2016.
George Papamakarios, Theo Pavlakou, and Iain Murray. Masked autoregressive flow for density
estimation. In Advances in Neural Information Processing Systems, pp. 2338-2347, 2017.
George Papamakarios, David Sterratt, and Iain Murray. Sequential neural likelihood: Fast likelihood-
free inference with autoregressive flows. In The 22nd International Conference on Artificial
Intelligence and Statistics, pp. 837-848. PMLR, 2019.
Jonathan K Pritchard, Mark T Seielstad, Anna Perez-Lezaun, and Marcus W Feldman. Population
growth of human y chromosomes: a study of y chromosome microsatellites. Molecular biology
and evolution, 16(12):1791-1798, 1999.
Oren Rippel and Ryan Prescott Adams. High-dimensional probability estimation with deep density
models. arXiv preprint arXiv:1302.5125, 2013.
Ohad Shamir, Sivan Sabato, and Naftali Tishby. Learning and generalization with the information
bottleneck. Theoretical Computer Science, 411(29-30):2696-2711, 2010.
S.A. Sisson, Y Fan, and M.A. Beaumont. Handbook of Approximate Bayesian Computation., chapter
Overview of Approximate Bayesian Computation. Chapman and Hall/CRC Press, 2018.
Scott A Sisson, Yanan Fan, and Mark M Tanaka. Sequential Monte Carlo without likelihoods.
Proceedings of the National Academy of Sciences, 104(6):1760-1765, 2007.
Torbjorn SjGstrand, StePhen Mrenna, and Peter Skands. A brief introduction to Pythia 8.1. Computer
Physics Communications, 178(11):852-867, 2008.
Carlos Oscar SdnChez Sorzano, Javier Vargas, and A Pascual Montano. A survey of dimensionality
reduction techniques. arXiv preprint arXiv:1403.2877, 2014.
Gdbor J SZekely, Maria L Rizzo, et al. Partial distance correlation with methods for dissimilarities.
Annals of Statistics, 42(6):2382-2412, 2014.
Owen Thomas, Ritabrata Dutta, Jukka Corander, Samuel Kaski, Michael U Gutmann, et al.
Likelihood-free inference by ratio estimation. Bayesian Analysis, 2021.
Aaron Van Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent neural networks. In
International Conference on Machine Learning, pp. 1747-1756. PMLR, 2016.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz
Kaiser, and Illia Polosukhin. Attention is all you need. arXiv preprint arXiv:1706.03762, 2017.
Anja Weyant, Chad Schafer, and W Michael Wood-Vasey. Likelihood-free cosmological inference
with type ia supernovae: approximate Bayesian computation for a complete treatment of uncertainty.
The Astrophysical Journal, 764(2), 2013.
Samuel Wiqvist, Pierre-Alexandre Mattei, Umberto Picchini, and Jes Frellsen. Partially exchangeable
networks and architectures for learning summary statistics in approximate bayesian computation.
In International Conference on Machine Learning, pp. 6798-6807, 2019.
Simon N Wood. Statistical inference for noisy nonlinear ecological dynamic systems. Nature, 466
(7310):1102, 2010.
Haozhe Xie, Jie Li, and Hanqing Xue. A survey of dimensionality reduction techniques based on
random projection. arXiv preprint arXiv:1706.04371, 2017.
12
Published as a conference paper at ICLR 2021
A	Theoretical proofs
A.1 Proof of Proposition 1
Proof. Firstly, assume s(∙) is a sufficient statistic. By the definition of sufficient statistic We know
p(x∣θ) = p(x∣s)p(s∣θ). Then we have the Markov chain θ → S → X for the data generating
process. On the other hand, since X 〜p(x∣θ) and S is a deterministic function we have the Markov
chain θ → X → s. By data processing inequality we have I(θ; s(X)) ≤ I(θ; X) for the first chain
and I(θ; X) ≤ I(θ; s(X)) for the second chain. This implies that I(θ; X) = I(θ; s(X)) i.e s is the
maximizer of I(θ; S (X)). For the other direction, since I(θ; s(X)) = maxS I(θ; S(X)), we have
I(θ; s(X)) = I(θ; X). Note that θ → X → s is a Markov chain, from Theorem 2.8.1 of Cover et al.
(2003) we can get θ and X is conditionally independent given s. This implies S is sufficient. □
A.2 Proof of Proposition 2
Proof. We can write the objective as Ep(θ,x) [kS(X) - θk22] = R p(θ, X) log ekS(x)-θk22 dXdθ. On the
other hand we have I(θ; S(X)) = ʃp(θ, x) logP(S(X) ∣θ)/P(S(X))dxdθ. By comparing them, we
see they are generally not equivalent. Equivalence only holds in special cases (e.g. Gaussians). □
B More Experimental details and results
B.1	Detailed experimental settings
Neural networks settings. For the statistic network S in our method (for both JSD and DC estima-
tors), we adopt a D-100-100-d fully-connected architecture with D being the dimensionality of input
data and d the dimensionality of the statistic. For the network H used to extract the representation of
θ, we adopt a K-100-100-K fully-connected architecture with K being the dimensionality of the
model parameters θ. For the critic network, we adopt a (d + K)-100-1 fully connected architecture.
ReLU is adopted as the non-linearity in all networks. For SRE, which is closely related to our method,
we use a (D + K)-144-144-100-1 architecture. This architecture has a similar complexity as our
networks. All these neural networks are trained with Adam (Kingma & Ba, 2014) with a learning
rate of 1 × 10-4 and a batch size of 200. No weight decay is applied. We take 20% of the data for
validation, and stop training if the validation error does not improve after 100 epochs. We take the
snapshot with the best validation error as the final result.
For the neural density estimator in SNL/SNPE, which is realized by a Masked Autoregressive Flow
(MAF) (Papamakarios et al., 2017), we adopt 5 autoregressive layers, each of which has two hidden
layers with 50 tanh units. This is the same settings as in SNL. The MAF is trained with Adam with a
learning rate of 5 × 10-4 and a batch size of 500 and a slight weight decay (1 × 10-4). Similar to the
case of MI networks, we take 20% of the data for validation, and stop training if the validation error
does not improve after 100 epochs. The snapshot with the best validation error is taken as the result.
Sampling from the approximate posterior/learnt proposal. For fair comparison, we adopt simple
rejection sampling for all LFI methods (ABC, SNL, SNPE, SRE) when sampling from the learnt
posterior, so that each LFI method only differs in the way they learn the posterior. No MCMC is used.
Empirical version of objective functions. Recall that in the JSD estimator, the statistic network
S(∙) is trained with the following objective together with the critic network T(∙):
maximizeS,T L(S,T) = Ep(θ,x) [- sp (-T (θ, S(X)))] - Ep(θ)p(x) [sp (T (θ, S (X))]
the mini-batch approximation to this objective is:
n
L(S,T) ≈ 1
[- sp (-T (θi, S(Xi)))] -
mn
mm n XX [sp(T (θji ,S(Xi))]
ji
n
where {j1, j2, ..., jn} is the j-th random permutation of the indexes {1, 2, ..., n} and the pair (θi, Xi)
are randomly picked from the data D = {θi, Xi}iN=1. Here we set m = 400 andn is the batch size.
In the DC estimator, the statistic network is trained by the following objective:
maximizeS L(S)
Ep(θ,x)p(θ0,x0)[h(θ, θ0)h(S(X), S(X0))]
√Ep(θ)p(θ0)[h2(θ,θ0)] ∙ VZEp(X)p(χ0)[h2(S(X),S(X0))]
13
Published as a conference paper at ICLR 2021
where h(a, b) = ka - bk - Ep(b0)[ka - b0k] - Ep(a0)[ka0 - bk] + Ep(a0)p(b0)[ka0 - b0k]. The
mini-batch approximation to this objective is:
L(S) ≈
pnnjn h(θi ,θ j)h(s (Xi),s (xj))
JPnjn h 2(θi ,θ)∙ JPnjn 后⑹(Xi),s (Xj))
where h(ai，bj ) = kai - bj k-n⅛ Pno kai-bj 0 k- n-2 Pn kai0 - bj k + (n-i)1(n-2) Pnj 0 kai0-
bj0 k. Here i,j, i0,j0 are the indexes in the mini-batch. n is again the batch size.
JSD calculation between true posterior and approximate posterior. The calculation of the Jensen-
Shannon divergence between the true posterior P and approximate posterior Q, namely JSD(P, Q)=
2KL[Pk (P + Q)/2] + 2KL[Qk (P + Q)/2], is done numerically by a Riemann sum over 30K equally
spaced grid points with K being the dimensionality of θ . The region of these grid points is defined by
the min and max values of 500 samples drawn from P. When we only have samples from the true
posterior (e.g. the Ising model), we approximate P by a mixture of Gaussian with 8 components.
B.2	Additional experimental results
Comparison of different MI estimators. We compare the performances of four MI estimator
for infomax statistics learning: Donsker-Varadhan (DV) estimator (Belghazi et al., 2018), Jensen-
Shannon divergence (JSD) estimator (Hjelm et al., 2018), distance correlation (DC) Szekely et al.
(2014) and Wasserstein distance (WD) (Ozair et al., 2019). We highlight that the last two estimators
(DC and WD) are ratio-free. We compare the discrepancy between the true posterior and the posterior
inferred with the statistics learned by each estimator, as well as the execution time per each mini-batch.
The results, which are averaged over 5 independent runs, are shown in the figure and the table below.
From the figure we see that the JSD estimator generally yields the best accuracy among the four
estimators. In terms of execution time, the DC estimator is clearly the winner, with its execution
time being only 1/15 of the other estimators. However, the accuracy of the DC estimator is still
comparable to the JSD estimator, especially when the number of training samples is large (e.g.
10,000). According to these results, we suggest using JSD in small-scale settings (e.g. early rounds
in sequential learning), and use DC in large-scale ones (e.g. later rounds in sequential learning).
(a) Ising model
(b) Gaussian copula	(c) OU process
Figure 5: Comparing the accuracy of different MI estimator for infomax statistics learning.
	Ising model			Gaussian copula		OU process		
DV	JSD	DC	WD	I DV JSD DC WD	I DV	JSD	DC	WD
115	124	6	230	I 154	167	10	288	I 143	158	13	256
Table 4: Comparing the execution time (ms) of different MI estimator for infomax statistics learning.
14
Published as a conference paper at ICLR 2021
Contrastive learning v.s. MLE. In the experiment in the main text, we discover that our method
does not always achieve the best performance; it does not work better than SNPE-B on the Gaussian
copula problem. Here we would like to investigate why this happens.
Upon a closer look, we discover that SRE, which is closely related to our method when used with
the JSD estimator, is outperformed by SNPE-B on the Gaussian copula problem. Remark that both
SRE and our method, when used with the JSD estimator, uses contrastive learning rather than MLE.
Since both of these two contrastive learning methods do not perform better than the MLE-based
SNPE-B, it makes us suspect the reason is due to imperfect contrastive learning. To verify this, we
further conduct experiments for SNPE-C, which shares the same loss function with SRE but with a
different parameterization to the density ratio (SRE: fully-connected network; SNPE-C: NDE-based
parameterization. This NDE is the same as in SNL). The result is as follows:
	Ising model				Gaussian copula				OU process		
SRE	SNPE-B	SNPE-C	SNL+	I SRE	SNPE-B	SNPE-C	SNL+	I SRE	SNPE-B	SNPE-C	SNL+
0.083	0.058	0.030	0.017	I 0.052	0.037	^^0.047^^	0.042	I 0.022	0.018	0.016	0.009
Table 5: Commparing the the JSD of contrastive learning-based methods (SRE, SNPE-C, SNL+) and
MLE-based method (SNPE-B) on the three models considered in the experiments in the main text.
Surprisingly, we find that SNPE-C also perform less satisfactorily than SNPE-B on the Gaussian
copula problem. This suggests that contrastive learning might be less preferable than MLE on the
Gaussian copula problem, which might also explain the less satisfactory performance of our method.
15