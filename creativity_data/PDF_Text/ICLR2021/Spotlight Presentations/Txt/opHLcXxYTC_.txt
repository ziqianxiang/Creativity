Published as a conference paper at ICLR 2021
Influence Estimation for Generative Adver-
sarial Networks
Naoyuki Terashita Hiroki Ohashi Yuichi Nonaka Takashi Kanemaru
Hitachi, Ltd.
Tokyo, Japan
Ab stract
Identifying harmful instances, whose absence in a training dataset improves model
performance, is important for building better machine learning models. Although
previous studies have succeeded in estimating harmful instances under super-
vised settings, they cannot be trivially extended to generative adversarial networks
(GANs). This is because previous approaches require that (i) the absence of a
training instance directly affects the loss value and that (ii) the change in the loss
directly measures the harmfulness of the instance for the performance of a model.
In GAN training, however, neither of the requirements is satisfied. This is because,
(i) the generator’s loss is not directly affected by the training instances as they are
not part of the generator’s training steps, and (ii) the values of GAN’s losses nor-
mally do not capture the generative performance of a model. To this end, (i) we
propose an influence estimation method that uses the Jacobian of the gradient of
the generator’s loss with respect to the discriminator’s parameters (and vice versa)
to trace how the absence of an instance in the discriminator’s training affects the
generator’s parameters, and (ii) we propose a novel evaluation scheme, in which
we assess harmfulness of each training instance on the basis of how GAN eval-
uation metric (e.g., inception score) is expected to change due to the removal of
the instance. We experimentally verified that our influence estimation method cor-
rectly inferred the changes in GAN evaluation metrics. We also demonstrated that
the removal of the identified harmful instances effectively improved the model’s
generative performance with respect to various GAN evaluation metrics.
1	Introduction
Generative adversarial networks (GANs) proposed by Goodfellow et al. (2014) are a powerful sub-
class of generative model, which is successfully applied to a number of image generation tasks
(Antoniou et al., 2017; Ledig et al., 2017; Wu et al., 2016). The expansion of the applications of
GANs makes improvements in the generative performance of models increasingly crucial.
An effective approach for improving machine learning models is to identify training instances that
harm the model performance. Traditionally, statisticians manually screen a dataset for harmful in-
stances, which misguide a model into producing biased predictions. Recent influence estimation
methods (Khanna et al., 2019; Hara et al., 2019) automated the screening of datasets for deep learn-
ing settings, in which the sizes of both datasets and data dimensions are too large for users to man-
ually determine the harmful instances. Influence estimation measures the effect of removing an
individual training instance on a model’s prediction without the computationally prohibitive cost of
model retraining. The recent studies identified harmful instances by estimating how the loss value
changes if each training instance is removed from the dataset.
Although previous studies have succeeded in identifying the harmful instances in supervised set-
tings, the extension of their approaches to GAN is non-trivial. Previous approaches require that (i)
the existence or absence of a training instance directly affects a loss value, and that (ii) the decrease
in the loss value represents the harmfulness of the removed training instance. In GAN training,
however, neither of the requirements is satisfied. (i) As training instances are only fed into the dis-
criminator, they only indirectly affect the generator’s loss, and (ii) the changes in the losses of GAN
1
Published as a conference paper at ICLR 2021
do not necessarily capture how the removed instances harm the generative performance. This is
because the ability of the loss to evaluate the generator is highly dependent on the performance of
the discriminator.
To this end, (i) we propose an influence estimation method that uses the Jacobian of the gradient
of the discriminator’s loss with respect to the generator’s parameters (and vice versa), which traces
how the absence of an instance in the discriminator’s training affects the generator’s parameters. In
addition, (ii) we propose a novel evaluation scheme to judge if an instance is harmful or not on the
basis of influence on GAN evaluation metric, that is, how a GAN evaluation metric (e.g., inception
score (Salimans et al., 2016)) changes if a given training instance is removed from the dataset. We
identify harmful instances by estimating the influence on GAN evaluation metric by leveraging our
influence estimation method.
We verified that the proposed influence estimation method correctly estimated the influence on GAN
evaluation metrics across different settings of the dataset, model architecture, and GAN evaluation
metrics. We also demonstrated that removing harmful instances, which were identified by the pro-
posed method, effectively improved various GAN evaluation metrics.1
Our contributions are summarized as follows:
•	We propose an influence estimation method that uses the Jacobian of the gradient of the dis-
criminator’s loss with respect to the generator’s parameters (and vice versa), which traces
how the absence of an instance in the discriminator’s training affects the generator’s pa-
rameters.
•	We propose a novel evaluation scheme to judge if an instance is harmful or not on the basis
of influence on GAN evaluation metrics rather than that on the loss value, and to leverage
the proposed influence estimation method to identify harmful instances.
•	We experimentally verified that our influence estimation method correctly inferred the in-
fluence on GAN evaluation metrics. Further, we demonstrated that the removal of the
harmful instances suggested by the proposed method effectively improved the generative
performance with respect to various GAN evaluation metrics.
2	Preliminaries
Notation For column vectors a, b ∈ Rp, we denote the inner product by ha, bi = Pip=1 aibi. For
a function f (a), We denote its gradient with respect to a by Vaf (a). We denote the identity matrix
of size p by Ip, the zero vector of length p by 0p, and the ones vector of length p by 1p.
Generative Adversarial Networks (GAN) For simplicity, we consider an unconditional GAN
that consists of the generator G : Rdz → Rdx and the discriminator D : Rdx → R, where dz and dx
are the number of dimensions of latent variable Z 〜p(z) and data point X 〜p (x) ,respectively. The
parameters of generator θG ∈ RdG and discriminator θD ∈ RdD are learned though the adversarial
training; G tries to sample realistic data while D tries to identify whether the data is real or generated.
Formulation of GAN Objectives For the generality, we adopt the formulation of Gidel et al.
(2019) in which G and D try to minimize LG and LD, respectively, to obtain the following Nash
equilibrium (θG, θD):
θG ∈ arg min LG (Θg, θD) and θD ∈ arg min LD (θG, Θd).	(1)
θG	θD
For the latter part of this paper, we use a coupled parameter vector θ := (θG, θD)> ∈ Rdθ=dG+dD
when we refer to the whole parameters of GAN.
In this paper, we assume that LG and LD have the following forms2:
LG (θ) :=	Ez〜p(z)	[fG	(z; θ)],	LD	(θ)	:= Ez〜p(z)	h店]	(z; θ)i	+ Ex〜p(x)	hfx] (x; θ)i	.⑵
1Code is at https://github.com/hitachi- rd- cv/influence- estimation- for- gans
2This covers the common settings of GAN objectives: the non-zero-sum game proposed by Goodfellow
et al. (2014), Wasserstein distance (Arjovsky et al., 2017), and the least squares loss (Mao et al., 2017).
2
Published as a conference paper at ICLR 2021
We can recover the original minimax objective by taking fG (z; θ) = log (1 - DθD (GθG (z))),
fDz] = -fG, and fDx] (x; θ) = - log Dθd (x).
Adversarial SGD (ASGD) To make our derivation easier to understand, we newly formulate the
parameter update of a GAN trained by stochastic gradient descent, which we call adversarial SGD
(ASGD). For simplicity, this paper considers simultaneous training, in which the generator and the
discriminator are simultaneously updated at a single step. We denote the dataset by DX := {xn 〜
p(x)}nN=1, which consists of N data points. Let St ⊂ {1, . . . , N} be a set of sample indices at
the t-th step. We assume that the mini-batch of the t-th step consists of instances {xi }i∈S and a
set of latent variables Zt ={z[t] 〜 p(z)}|lS=t1|, which are sampled independently at each step t.
We denote the mean of LG and LD across the mini-batch by LG(Z; θ):= 吉 Pz∈z /g (z； θ)
and LD(S, Z； θ) ：= ∣ZZ∣ (Pz∈Z fDz] (z； θ) + Pi∈S fx] 3； θ)), respectively. The t-th step of
ASGD updates the coupled parameters by θ[t+1] = θ[t] - Btg (St, Zt; θ[t]), where
Bt :=(修。[tO ∈ ∈ Rdθ×dθ, g (S, Z; θ) := QvθGLG (ZZθ∖ɔ ∈ Rdθ.⑶
∖ O	ηDIdD)	NeDLD (S, Z； θ))
ηG[t] ∈	R+ and ηD[t] ∈	R+ are the learning rates of the t-th step for θG and θD, respectively.
3	Proposed Method
This section explains the two main contributions of our paper: the influence estimation method for
GANs that predicts how the removal of a training instance changes the output of the generator and
the discriminator (Section 3.1), and two important parts of our instance evaluation scheme, that are,
the definition of influence on GAN evaluation metric and its estimation algorithm (Section 3.2).
3.1	Influence Estimation for GAN
We refer to influence estimation as the estimation of changes in a model’s output under a training
instance’s absence. As the model’s output changes through the changes in the model’s parameters,
we start with the definition of ASGD-Influence, which represents the changes in parameters, and
then formulate its estimator.
ASGD-Influence ASGD-Influence is defined on the basis of the following counterfactual ASGD.
Let θ-[t]j denote the parameters at t-th step trained without using j-th training instance. Counter-
factual ASGD starts optimization from θ-[1j] = θ[1] and updates the parameters of the t-th step by
θ-[t+j 1] = θ-[t]j -Btg St \ {j}, Zt； θ-[t]j . We define ASGD-Influence ∆θ-j as the parameter differ-
ence between counterfactual ASGD and ASGD at the final step t = T, namely ∆θ-j := θ-[Tj] - θ[T] .
Estimator of ASGD-Influence Our estimator uses an approximation of the mean of the gradi-
ent. Let (VθgLg(Z; θ), VθdLD (S, Z； θ)) be the joint gradient vector of the mini-batch. We
introduce the Jacobian of the joint gradient vector of the t-th mini-batch with respect to θ :
J := (JGG jGD、= (	vΘgLG (Zt； θ[t])
t := IJDG JDD/ = Ive。vθdLD (St, Zt； θ[t])
VθD VθGLG (Zt； θ团八
vθDLD (St, Zt； Θ[t])广
(4)
When we assume both LG (θ) and LG (θ) are second-order differentiable with respect to θ, the
first-order Taylor approximation gives g SStj Zt； θ-j) - g (St, Zt； θ[t]) ≈ Jt (θ-j - θ[t]). With
this approximation, we have
θ-+ 1] - θ[t+1] = (θ-]j - θ[t]) - Bt (g (St,Zt；θ-]j) - g (St, Zt； e[t]))
≈ (Idθ -BtJt) θ-[t]j - θ[t]	,∀j 6∈	St.	(5)
3
Published as a conference paper at ICLR 2021
For simplicity, we first focus on 1-epoch ASGD in which each instance appears only
once. Let π (j ) be the step where the j-th instance is used. Considering the absence of
VθD fD[x] (xj; θ[π(j)] ) in the π(j)-th step of counterfactual ASGD, we have θ-[πj(j)+1] - θ[π(j)+1] =
ηD∏(j)]
|Sn(j)|
(0dG, Vθn fDx](xj; θ∣πjX)) . By denoting Zt=〃-BtJt and recursively applying
the approximation (5), we obtain
η[π(j)]
δθ- ≈ IS)	| ZT-1ZT-2 ∙∙∙ Zπ(j) + 1
0dG
fDX] (Xj; θ[π(j)])7 .
(6)
For the practical situation of K-epoch ASGD, in which the j-th instance is sampled K times at
t = π1 (j) , . . . , πK (j), the estimator of the ASGD-Influence is given by
K	T-πk(j)-1
∆θ-j = Xl	Y	ZT-S
k=1	s=1
ηDπk(j)] (	OdG
∣s∏kj)l Be。fDχ] (xj；θ∣πkj)])
(7)
Linear Influence To estimate the influence on outputs, we introduce linear influence L[-Tj] (u) :=
hu, ∆θ-j i of a given query vector u ∈ Rdθ . If we take u = VθfG z； θ[T] , the linear influence
approximates the influence on the generator's loss L-j(u) ≈ /g (z; θ-j) 一 /g (z; θ[T]).
Let (uG]> ∈ RdG, u)> ∈ RdD) := UZT-1ZT-2 …Zt+ι. The linear influence of the j-th in-
stance is approximated by the proposed estimator:
[T]
-j
K	η[πk (j)]
(U) ≈ Du, ∆θ-j E = X 常高
(u斑叫 VθDfDx] (Xj; e[nk(j)])).
(8)
L
The estimation algorithm consists of two phases; training phase performs K-epoch ASGD
by storing information A[t] J (St, ηG],η)D], θ[t], Zt) and inference phase calculates (8) using
A[1] , . . . , A[T-1]. See Appendix A for the detailed algorithm.
3.2	Influence on GAN Evaluation Metric
This section explains our proposal ofanew evaluation approach for data screening for GANs. Firstly
we propose to evaluate harmfulness of an instance on the basis of influence on GAN evaluation
metrics. Secondly we propose to leverage the influence-estimation algorithm explained in Section
3.1 to identify harmful instances with respect to the GAN evaluation metrics.
Influence on GAN Evaluation Metric Let V (D) be a GAN evaluation metric that maps a set
of data points D := {Xm ∈ Rdx}M=ι into a scalar value that gives the performance measure of
G. Let generated dataset DG(Z; Θg) := {G(z; Θg)∣ Z ∈ Z}. Using a set of latent variables
Z := {Zm 〜p(z)}M=ι that is sampled independently from the training, We define the influence on
GAN evaluation metric by
∆V-T] := V (DG (Z; θ[T-j)) 一 V (DG (Z; θ[T])) ,	(9)
Where θG[T,]-j and θG[T] are the generator parameters of counterfactual ASGD and the ASGD of the
T -th step, respectively.
Estimation Algorithm In order to build the estimation algorithm of the influence on GAN evalu-
ation metric, We focus on an important property of some common evaluation metrics for Which the
gradient with respect to the element of their input Vxm V(D) is computable. For example, Monte
Carlo estimation of inception score has a form of exp(曲 PxE∈d KL(Pc(y∣Xm)∣∣Pc(y)) where Pc
is a distribution of class label y drawn by a pretrained classifier. When the classifier is trained using
back-propagation, Vxm V(D) is computable.
4
Published as a conference paper at ICLR 2021
Here, We assume V (D) is first-order differentiable with respect to Xm. From the chain rule, We have
a gradient of the GAN evaluation metrics with respect to θ :
Vθ V (DG(Z ； θ[T ]))= (Pn=I vθG Vxn V
G	0d
Our estimation algorithm performs the inference phase of linear influence taking u
VθV(DG(Z; θG[T])) in order to obtain the approximation L[-Tj] (VθV(DG (Z; θG[T]))) ≈ ∆V-[Tj] .
(10)
4	Related Studies
SGD-Influence Hara et al. (2019) proposed a novel definition of the influence called SGD-
Influence and its estimator, Which greatly inspired us to propose the influence estimation method
for GANs. Suppose a machine learning model With parameters φ ∈ Rdφ is trained to minimize
the mean of the loss -N PN=I L (Xn; φ) across the training instances χι,..., XN. Let the mean of
the loss of the mini-batch L(S; φ):= 仓 Pi∈s L(Xi； φ). They introduced two SGD steps with
learning rate η ∈ R+: SGD given by φ[t+1] = φ[t] 一 ηtVφL (St； φ[t]), and counterfactual SGD
given by φ-+ 1] = φ-j - ηtVφL (St \ {j} ; φ-j). Their estimator of SGD-Influence φ-j - φ[T]
is based on the following approximation:
φ-+ 1]-	φ[t+1]≈	(idφ-ηtVφL	(St； φ用))(φ-j- φ∣t])	,∀j∈st.	(11)
Hara et al. (2019) also identified harmful instances for classification based on linear influence of the
cross-entropy loss estimated using a validation dataset. Removing the estimated harmful instances
with their approach demonstrated improvements in the classification accuracy.
Our approach differs from Hara et al. (2019)'s work in two ways. Firstly, our approach uses the
Jacobian of the joint gradient vector Jt instead of the Hessian of the mean loss V2φL (St； φ[t]). As
long as LG 6= LD, Jt is asymmetric and inherently different from the Hessian. Moreover, a source
of the asymmetry JG[t]D plays an important role in transferring the effect of removal of a training
instance from the discriminator to the generator. Let θG[t],-j - θG[t] ∈ RdG and θD[t],-j - θD[t] ∈ RdD
be ASGD-Influence on θG and θD of the t-th step, respectively. The upper blocks of (5) can be
rewritten as
θG[t+,-1j] -	θG[t+1] ≈	(IdD	-	ηG[t]JG[tG]	(θG[t],-j - θG[t]+	ηG[t]JG[t]D(θD[t],-j - θD[t].	(12)
Note that JG[tD] transfers the t-th step of ASGD-Influence on θD to the next step of ASGD-Influence
on θG. The Hessian of Hara et al. (2019), which uses a single combination of the parameters and the
loss function, cannot handle this transfer between the two models. Secondly, we use the influence
on GAN evaluation metrics for identifying harmful instances rather than that on the loss value. This
alleviates the problem of the GAN’s loss not representing the generative performance.
Influence Function Koh & Liang (2017) proposed influence estimation method that incorporated
the idea of influence function (Cook & Weisberg, 1980) in robust statistics. They showed that
influences on parameters and predictions can be estimated with the influence function assuming
the satisfaction of the optimality condition and strong convexity of the loss function. They also
identified harmful instances on the basis of the influence on the loss value, assuming consistency of
the loss value with the task performance.
Our influence estimation method is designed to eliminate these assumptions because normally GAN
training does not satisfy the assumptions regarding the optimality condition, the convexity in the
loss function, and the consistency of the loss value with the performance.
5 Experiments
We evaluated the effectiveness of the proposed method in two aspects: the accuracy of influence es-
timation on GAN evaluation metrics (Section 5.1), and the improvement in generative performance
by removing estimated harmful instances (Section 5.2)
5
Published as a conference paper at ICLR 2021
GAN Evaluation Metrics In both experiments, we used three GAN evaluation metrics: aver-
age log-likelihood (ALL), inception score (IS), and Frechet inception distance (FID) (HeUsel et al.,
2017). ALL is the de-facto standard for evaluating generative models (Tolstikhin et al., 2017). Let
Z = {zn 〜p(z)}n= ι and Dx := {Xn 〜p(x)}N= ι, which is sampled separately from p(z) and
the training dataset Dx, respectively. ALL measUres the likelihood of the trUe data Under the distri-
bUtion that is estimated from generated data Using kernel density estimation. We calcUlated ALL of
Dx0 Under the distribUtion estimated from generated dataset DG(Z0; θG[T]). Recall Z0 is the set of la-
tent variables sampled independently from the training (Section 3.2). FID measures FreChet distance
between two sets of featUre vectors of real images Dx0 and those of generated images DG(Z0; θG[T]).
The feature vectors are calculated on the basis of a pre-trained classifier. Larger values of ALL and
IS and a smaller value of FID indicate the better generative performance. See Appendix C.1 for the
detailed setting of each GAN evaluation metric.
5.1	Experiment 1: Estimation Accuracy
We ran the influence estimation method on GANs to estimate influence on various GAN evaluation
metrics, and then compared the estimated influence with true influence. The detailed setup can be
found in Appendix C.2.
Setup ALL is known to be effective for low-dimensional data distributions (Borji, 2019) and both
FID and IS are effective for image distributions. We thus prepared two different setups: fully-
connected GAN (FCGAN) trained with 2D multivariate normal distribution (2D-Normal) for ALL,
and DCGAN (Radford et al., 2016) trained with MNIST (LeCun et al., 1998) for IS and FID. IS and
FID require classifiers to obtain class label distribution and feature vectors, respectively. We thus
trained CNN classifier of MNIST3 using Dx0 . We set N = 10k and N0 = |Dx0 | = |Z0| = 10k.
The experiment was conducted as follows. Firstly, we ran the K-epoch of the training phase of
linear influence with the training dataset Dx . We determined K = 50 since we observed the con-
vergence of GAN evaluation metrics at K = 50. For IS and FID, we trained the classifier using Dx0
and corresponding labels. We then randomly selected 200 target instances from Dx . We obtained
estimated influence on GAN evaluation metrics of each target instance by performing the inference
phase of linear influence with U = VθV(DG(Z0; θ[T])). The true influence of each target instance
was computed by running the counterfactual ASGD.
We used the same evaluation measures as the previous work (Hara et al., 2019): Kendall’s Tau and
the Jaccard index. Kendall’s Tau measures the ordinal correlation between the estimated and true
influence on GAN evaluation metrics. It has a value of 1 when the orders of the two sets of values
are identical. For the Jaccard index, we selected 10 instances with the largest positive and largest
negative influence values to construct a set of 20 critical instances. The Jaccard index is equal to 1
when a set of estimated critical instances is identical to that of true critical instances.
To investigate the relationship between a number of tracing back steps and the estimation accuracy,
we also evaluated the influence on GAN evaluation metrics of k-epoch ASGD. In k-epoch training,
both inference phase of linear influence and the counterfactual ASGD traced back only k ≤ K
epochs from the latest epoch K. We varied k = 1, 5, 10, 20, 50 and ran the experiment ten times for
each k by changing the random seeds of the experiments.
Results Figure 1 shows the average Kendal’s Tau and the Jaccard index of the repeated experi-
ments. Hereinafter, we use p < .05 to judge the statistical significance of the results. For all k,
Kendall’s Tau and the Jaccard index of estimated influence on ALL were statistically significantly
better than the result in which the order of estimated influence values were random (random case).
Even in the more difficult setups of IS and FID, which handled the high-dimensional dataset and
complex architecture, the results were statistically significantly better than that of the random case
except for Jaccard index of IS with k = 50. We also observed the estimation accuracy dropped as
k increased. This reflects the nature of our estimator that recursively performs linear approximation
3Although the original IS and FID use Inception Net (Szegedy et al., 2016) trained with ImageNet, we
instead adopted a domain-specific classifier as encouraged by several studies (Zhou et al., 2018; Liu et al.,
2018) to alleviate the domain mismatch with ImageNet.
6
Published as a conference paper at ICLR 2021
—Influence on ALL -Influence on IS —Influence on FID Random
ι.o-
nBls--BPUΦM
O	IO 20	30	40	50	O	10	20	30	40	50
# of tracing back epochs k	# Oftracing back epochs k
Figure 1: Average Kendall's TaU (±std) (left) and the Jaccard index (±std) (right) calculated from
true and estimated influence on ALL, IS, and FID.
as many times as the number of steps. We thus conclude that when the required number of tracing
back steps is small enough, our influence estimation method is effective and the estimated influence
on GAN evaluation metric is useful for identifying harmful instances.
5.2	Experiment 2: Data Cleansing
We investigated if removing identified harmful instances actually improved the generative perfor-
mance to evaluate the effectiveness of our proposed method for data cleansing. We define data
cleansing as an attempt to improve GAN evaluation metrics by removing a set of training instances.
See appendix C.3 for the detailed settings.
Setup We studied the data cleansing for the two setups explained in the previous section: 2D-
Normal with FCGAN and MNIST with DCGAN. We mostly followed the settings of Section 5.1
but set training dataset size N = 50k for both setups.
We identified harmful instances in 2D-Normal training dataset using estimated influence on ALL,
and those in MNIST using estimated influence on IS and FID. We considered a training instance
was harmful when it had negative (positive) influence on FID (ALL or IS).
For both setups, we also selected instances using baseline approaches: anomaly detection method,
influence on the discriminator loss, and random values. For anomaly detection, we adopted isolation
forest (Liu et al., 2008). Isolation forest fitted the model using the data points ofDx for 2D-Normal
and feature vectors of the classifier of Dx for MNIST. We adopted the selection based on the in-
fluence on the discriminator loss to verify our assumption that the influence on the loss does not
represent the harmfulness of the instances. Influence on the discriminator loss was calculated on
the expected loss of LD (θ) with DG(Z0; θG[T] ) and Dx0 . We considered instances with negative
influence were harmful.
We conducted the experiments as follows. After the training phase of K epoch, we determined
nh < N harmful instances with the proposed approach and baselines. Then, we ran counterfactual
ASGD with the determined harmful instances excluded. For the reliable estimation accuracy of
influence and reasonable costs of the computation and storage, the inference phase traced back only
1-epoch from the last epoch, and counterfactual ASGD only re-ran the latest epoch. We tested with
various nh .
We refer to the generator of the final model as the cleansed generator and denote its parameters by
θG? . We evaluated the cleansed generator with test GAN evaluation metrics V (DG (Ztest); θG? )), in
which a set of test latent variables Ztest was obtained by sampling Ntest times from p(z) indepen-
dently from Z0 and Zi,..., Zt. Test ALL and FID used a test dataset Dtest ：= {xtnSt ~ p(x)}N=St
that consists of instances newly sampled from 2D-Normal and instances in the original test dataset
of MNIST, respectively. We set Ntest = 10k and ran the experiment 15 times with different random
seeds.
7
Published as a conference paper at ICLR 2021
—Influence on ALL (Ours)
Influence on IS (Ours)
—Influence on FID (Ours)
—⅛- Isolation Forest
—Influence on Disc. Loss
▼ Random
---No Removal
⑶
(b)
Figure 2: Average test ALL (a), IS (b), and FID (c) after the data cleansing. Larger values in (a)
and (b), a smaller value in (c) indicate the better generative performance. Error bars and plots of too
large or small values are omitted for better visibility. See Appendix C.3 for full results.
(C)
Quantitative Results Figure 2 shows the average test GAN evaluation metrics of the repeated ex-
periments for each selection approach. For the data cleansing on 2D-Normal, the proposed approach
with influence on ALL showed statistically significant improvement from the original model and it
outperformed the baselines (Figure 2a). For the MNIST setup, our approach with influence on FID
and IS statistically significantly improved FID (Figure 2c) and IS (Figure 2b), respectively. They
also outperformed the baselines. In addition, the results indicate that data cleansing based on the
influence on a specific GAN evaluation metric is also effective for another metric that is not used
for the selection; removing harmful instances based on the influence on FID (IS) statistically signifi-
cantly improved IS (FID). However, we make no claim that the proposed method can improve all the
other evaluation metrics, such as Kullback-Leibler divergence. This is because all the current GAN
evaluation metrics have their own weaknesses (e.g., IS fails to detect whether a model is trapped
into one bad mode (Zhou et al., 2018)), and the proposed method based on those GAN evaluation
metrics cannot inherently avoid their weaknesses. These improvements thus can be observed only in
a subclass of GAN evaluation metrics. Further evaluation of data cleansing with our method should
incorporate the future improvements of the GAN evaluation metrics.
While the improvements were smaller than the proposed approach, we also observed that data
cleansing based on the influence on the discriminator loss improved all the GAN evaluation metrics.
This counter-intuitive result indicates that the discriminator loss weakly measures the performance
of the generator that is trained along with the discriminator.
Qualitative Results We examined the characteristics of instances that were evaluated to be harm-
ful by our method. Overall, we observed that our method tends to judge instances as harmful when
they belong to regions from which the generators sample too frequently compared to the true dis-
tribution. Figure 3 shows the estimated harmfulness of the training instances of 2D-Normal and
the distribution of the generated samples. The proposed approach with influence on ALL evaluated
the instances around lower-left and upper-right regions to be harmful (Figure 3a). These regions
correspond to the regions where the generated distribution has higher density than that of the true
distribution (Figure 3b “No removal” and “True”). Similar characteristics were seen in harmful
8
Published as a conference paper at ICLR 2021
(a) Harmful instances
(b) Generated distribution
O IO 20	30	40	50
Ranking of predicted harmful score [k th]
(lower are more harmful)
True
No removal
Cleansed
Figure 3:	Harmfulness of 2D-Normal instances suggested using influence on ALL (a) and changes
in the generator’s distribution (b). (b) includes plots of the true distribution (True) and generator’s
distributions before (No removal) and after (Cleansed) the data cleansing with nh = 5.0k.
(a) Harmful
(b) No removal
夕飞r∙ / %
N›y4/ Y
≠J ςr7马m
g¾g J 4
iN 3"Is
夕4y∙t)7 S
(c) Cleansed
Figure 4:	Top 36 harmful MNIST instances predicted on the basis of influence on FID (a), and the
test generated samples before (b) and after (c) the data cleansing with nh = 25.0k. (a) and (b) use
the same series of test latent variables in Ztest .
MNIST instances suggested by our approach with influence on FID. A large number of samples
from class 1 were regarded as harmful as shown in Figure 4a, when the generator sampled images
of the digit 1 too frequently (Figure 4b).
We also investigated how the data cleansing by our approach visually changed the generated sam-
ples. As seen from the distributions in Figure 3b, the probability density in the upper-right region
decreased after the data cleansing (from “No removal” to “Cleansed”). As a result, the generator
distribution moved closer to the true distribution. The same effect was observed in a visually more
interesting form in the data cleansing for MNIST. The generated samples originating from some
latent variables changed from the image of digit 1 to that of other digits after the data cleansing
based on the estimated influence on FID (highlighted samples in Figure 4c). We suppose this effect
improved the diversity in the generated samples, resulting in better FID and IS.
6 Conclusion
We proposed an influence estimation method for GAN that uses the Jacobian of the gradient of
the discriminator’s loss with respect to the generator’s parameters (and vice versa), which traces
how the absence of an instance in the discriminator’s training affects the generator’s parameters.
We also proposed a novel evaluation scheme to judge if an instance is harmful or not on the basis
of the influence on GAN evaluation metrics rather than that on the loss value, and to leverage the
proposed influence estimation method to identify harmful instances. We experimentally verified that
estimated and true influence on GAN evaluation metrics had a statistically significant correlation.
We also demonstrated removing identified harmful instances effectively improved the generative
performance with respect to various GAN evaluation metrics.
9
Published as a conference paper at ICLR 2021
References
Antreas Antoniou, Amos Storkey, and Harrison Edwards. Data augmentation generative adversarial
networks. arXiv preprint arXiv:1711.04340, 2017.
Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein generative adversarial networks.
In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 214-
223, 2017.
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint
arXiv:1607.06450, 2016.
Ashish Bora, Eric Price, and Alexandros G. Dimakis. AmbientGAN: Generative models from lossy
measurements. In International Conference on Learning Representations, 2018.
Ali Borji. Pros and cons of gan evaluation measures. Computer Vision and Image Understanding,
179:41-65, 2019.
Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and Jorg Sander. Lof: identifying density-
based local outliers. In Proceedings of the 2000 ACM SIGMOD international conference on
Management of data, pp. 93-104, 2000.
R Dennis Cook and Sanford Weisberg. Characterizations of an empirical influence function for
detecting influential cases in regression. Technometrics, 22(4):495-508, 1980.
Gauthier Gidel, Hugo Berard, Gaetan Vignoud, Pascal Vincent, and Simon Lacoste-Julien. A varia-
tional inequality perspective on generative adversarial networks. In International Conference on
Learning Representations, 2019.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information
processing systems, 27:2672-2680, 2014.
Satoshi Hara, Atsushi Nitanda, and Takanori Maehara. Data cleansing for models trained with sgd.
In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alche-Buc, E. Fox, and R. Garnett (eds.),
Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a two time-scale update rule converge to a local nash equilibrium. In Advances
in neural information processing systems, pp. 6626-6637, 2017.
Peter J Huber. Robust statistics, volume 523. John Wiley & Sons, 2004.
Takuhiro Kaneko and Tatsuya Harada. Noise robust generative adversarial networks. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8404-8414, 2020.
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyz-
ing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 8110-8119, 2020.
Rajiv Khanna, Been Kim, Joydeep Ghosh, and Sanmi Koyejo. Interpreting black box predictions
using fisher kernels. In The 22nd International Conference on Artificial Intelligence and Statistics,
pp. 3382-3390. PMLR, 2019.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio
and Yann LeCun (eds.), 3rd International Conference on Learning Representations, ICLR 2015,
San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015.
Pang Wei Koh and Percy Liang. Understanding black-box predictions via influence functions. In
International Conference on Machine Learning, pp. 1885-1894. PMLR, 2017.
Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
10
Published as a conference paper at ICLR 2021
Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro
Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, and Wenzhe Shi. Photo-
realistic single image super-resolution using a generative adversarial network. In Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.
Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. Isolation forest. In 2008 Eighth IEEE Interna-
tional Conference on Data Mining,pp. 413-422. IEEE, 2008.
Shaohui Liu, Yi Wei, Jiwen Lu, and Jie Zhou. An improved evaluation framework for generative
adversarial networks. arXiv preprint arXiv:1803.07474, 2018.
Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, and Stephen Paul Smolley.
Least squares generative adversarial networks. In Proceedings of the IEEE international confer-
ence on computer vision, pp. 2794-2802, 2017.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. In Yoshua Bengio and Yann LeCun (eds.), 4th
International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May
2-4, 2016, Conference Track Proceedings, 2016.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen, and
Xi Chen. Improved techniques for training gans. In D. D. Lee, M. Sugiyama, U. V. Luxburg,
I. Guyon, and R. Garnett (eds.), Advances in Neural Information Processing Systems 29, pp.
2234-2242. Curran Associates, Inc., 2016.
Bemhard Scholkopf, John C Platt, John ShaWe-Taylor, Alex J Smola, and Robert C Williamson.
Estimating the support of a high-dimensional distribution. Neural computation, 13(7):1443-1471,
2001.
C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture
for computer vision. In 2016 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 2818-2826, 2016.
Ilya O Tolstikhin, Sylvain Gelly, Olivier Bousquet, Carl-Johann Simon-Gabriel, and Bernhard
Scholkopf. Adagan: Boosting generative models. In Advances in Neural Information Processing
Systems, pp. 5424-5433, 2017.
Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum. Learning a prob-
abilistic latent space of object shapes via 3d generative-adversarial modeling. In D. D. Lee,
M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett (eds.), Advances in Neural Information
Processing Systems 29, pp. 82-90. Curran Associates, Inc., 2016.
Zhiming Zhou, Han Cai, Shu Rong, Yuxuan Song, Kan Ren, Weinan Zhang, Jun Wang, and Yong
Yu. Activation maximization generative adversarial nets. In International Conference on Learning
Representations, 2018.
11
Published as a conference paper at ICLR 2021
Algorithm 1 Training Phase
Initialize the parameter θ[1]
Initialize the sequence as null: A — 0
for t = 1, 2, . . . , T - 1 do
// sample latent variables
Zt = {z[t] ~p(Z)}l=t1
// store information
A[t] — St,ηG[t],ηD[t],θ[t],Zt
// update parameters
θ[t+1] = θ[t] - Btg(St, Zt； θ[t])
end for
Algorithm 2 Inference Phase
Require: U = (UG ∈ RdG, UD ∈ RdD)>
Initialize the influence: L[-Tj] (u) — 0
for t = T - 1, T - 2, . . . , 1 do
// load information
St,ηG[t],ηD[t],θ[t],Zt — A[t]
// update the linear influence of j th instance
if j ∈ St then
L-j∙ (u) += pl " NeD fDx(xj； θ[t])E
end if
// update u
U -= U>BtJt
end for
A Algorithm for Linear Influence
The proposed estimation algorithm for linear influence, which is explained in Section 3.1, is divided
into the training phase (Algorithm 1) and inference phase (Algorithm 2).
The training phase executes ASGD training while storing the mini-batch indices St, the learning
rate ηG[t], ηD[t], the parameters θ[t] and the sampled latent variable Zt into the information A[t] at each
step.
In the inference phase, L[-Tj] (U) is estimated by the recursive calculation. First, we set L[-Tj] (U)
to 0 and set the query vector U. The information A[t] , which is obtained in the training phase, is
read in the order of t = T - 1, T - 2, . . . , 1. When j ∈ St, L[-Tj] (U) is updated using (8). Let
Ut = U[Gt] , U[Dt]	. Each step updates U based on Ut+1 = Ut> Zt = Ut> (Idθ - BtJt). A naive
calculation of Ut>Jt requires O d2θ memory to store the matrix Jt, which can be prohibitive for
very large models. We can avoid this difficulty by directly computing Ut>Jt without the explicit
computation of Jt. Because u> Jt = Ve Mt,(N Θg L g, Nθd L D )>>，We need only to compute
the derivative of the inner product of Ut and the joint gradient vector.
Our algorithm also covers the alternating gradient descent, in Which the tWo models alternatively
update their parameters at each step. By taking ηG[t] and ηD[t] such that they alternatively take 0 at
each step, We can have ASGD and the estimator of ASGD-Influence for the alternating gradient
descent. The implementation of linear influence for the alternating gradient descent is available in
our repository4.
B	Other Related Works
Anomaly Detection A typical approach for identifying harmful instances is outlier detection. Out-
lier detection is used to remove abnormal instances from the training set before training the model
to ensure that the model is not affected by the abnormal instances. For tabular data, there are several
popular methods, such as One-class support vector machine (Scholkopf et al., 2001), local outlier
factor (Breunig et al., 2000), and isolation forest (Liu et al., 2008). Although these methods can find
abnormal instances, they are not necessarily harmful for the resulting models, as We shoWed in the
experiment.
Training GAN from Noisy Images One typical type of data that harm generative performance is
noisy images. AmbientGAN (Bora et al., 2018) and noise-robust GAN (Kaneko & Harada, 2020)
4https://github.com/hitachi- rd-cv/influence-estimation-for-gans
12
Published as a conference paper at ICLR 2021
Table 1: Model architecture of CNN classifier of MNIST in Section 5.1 and 5.2.
Stage	Operation	Stride	Filter Shape	Bias	Norm.	Activation	Output
0	Input	-	-	-	-	-	[28, 28, 1]
1	Conv2D	1	[5, 5]	X	-	Sigmoid	[25, 25, 8]
2	Conv2D	1	[5, 5]	X	-	Sigmoid	[12, 12, 8]
3	MaxPooling	2	[2, 2]	-	-	Sigmoid	[392]
4	Linear	1	-	X	-	Sigmoid	[128]
5	Linear	1	-	X	-	Sigmoid	[10]
are learning algorithms that make it possible to train a clean image generator from noisy images. The
difference between these studies and ours is that these studies assume that the noise (e.g., Gaussian
noise on pixels) given independently from the data distribution of the clean images is the only
problem. However, some instances can affect the performance even if the instances are drawn only
from the data distribution, which is the case robust statistics (Huber, 2004) typically focuses on. Our
experiment 5.2 indicates that the model performance depends not only on noisy images but also on
a non-negligible number of harmful instances in the original dataset.
C Detailed Experimental Settings and results
C.1 GAN evaluation metrics
We adopted Gaussian kernel with the band-width 1 for kernel density estimation used in ALL. The
architecture of CNN classifier of MNIST used for IS and FID can be found in Table 1. We selected
the output of the 4th layer for the feature vectors for FID.
C.2 Experiment 1: estimation accuracy
Setup In the experiment of Section 5.1, we adopted the hyper parameters shown in Table 2. We
trained fullly-connected GAN (FCGAN) for 2D multivariate normal distribution, in which the both
G and D has 1 hidden layer of hG and hD units, respectively (Table 3). 2D-Normal is given by
N(μ, Σ), in which the mean vector μ = I2 and the covariance matrix Σ = ((1,0.8), (0.8,1)).
DCGAN consists of transposed convolution (or deconvolution) layers and convolution layers (Ta-
ble 4). The channels of the both layers in G and D were determined by hG and hD, respectively.
We used Layer Normalization (Ba et al., 2016) for the layers shown in Table 4 for the stability of
the training. We also introduced the L2-norm regularization with the rate γ ∈ R+ for all the ker-
nels of both FCGAN and DCGAN. We used the non-zero-sum game objective of the original paper
(Goodfellow et al., 2014) in which G tries to minimize -DθD (GθG (z)) for both models.
C.3 Experiment 2: data cleansing
Setup We adopted the same architecture as the Section 5.1 (Table 3) for FCGAN and slightly
different architecture (Table 4) in which hG and hD are larger (Table 5) for DCGAN. Other hy-
per parameters followed Table 5. We also provide visual explanations of the data settings in the
experiments with influence on ALL, IS, and FID in Figure 5, 6, and 7, respectively.
Results Table 6-8 show the detailed results of Figure 2. And they clarify with which nh and
selection approach the test GAN evaluation metrics were statistically significantly improved.
13
Published as a conference paper at ICLR 2021
Table 2: Hyper parameters in Section 5.1.
	K	ηG[t]		ηD]	N		N0	St	γ	hG	hD
2D-Normal	50	10-3	10-3	10k	10k	100	10-3	32	64
MNIST	50	10-3	10-3	10k	10k	100	10-3	8	8
Table 3: Model Architecture of FCGAN in Section 5.1 and 5.2.
Net.	Stage	Operation	Bias	Activation	Output
-	0	Input	-	-	[10]
G	1	Linear	X	ReLU	[hG]
G	2	Linear	X	Tanh	[2]
D	3	Linear	X	ReLU	[hD]
D	4	Linear	X	Sigmoid	[1]
Table 4: Model Architecture of DCGAN in Section 5.1 and 5.2.
Net.	Stage	Operation	Stride	Filter Shape	Bias	Norm.	Activation	Output
-	0	Input	-	-	-	-	-	[32]
G	1	Deconv2D	1	[2, 2]	X	X	Sigmoid	[2, 2, hG]
G	2	Deconv2D	1	[3, 3]	X	X	Sigmoid	[4, 4, hG]
G	3	Deconv2D	2	[3, 3]	X	X	Sigmoid	[9, 9, hG]
G	4	Deconv2D	1	[2, 2]	X	X	Sigmoid	[10, 10, hG]
G	5	Deconv2D	1	[3, 3]	X	X	Sigmoid	[12, 12, hG]
G	6	Deconv2D	2	[3, 3]	X	X	Sigmoid	[25, 25, hG]
G	7	Deconv2D	1	[4, 4]	X	X	Sigmoid	[28, 28, hG]
G	8	Conv2D	1	[1, 1]	X	-	Tanh	[28, 28, 1]
D	9	Conv2D	1	[4, 4]	X	X	Sigmoid	[25, 25, hD]
D	10	Conv2D	2	[3, 3]	X	X	Sigmoid	[12, 12, hD]
D	11	Conv2D	1	[3, 3]	X	X	Sigmoid	[10, 10, hD]
D	12	Conv2D	1	[2, 2]	X	X	Sigmoid	[9, 9, hD]
D	13	Conv2D	2	[3, 3]	X	X	Sigmoid	[4, 4, hD]
D	14	Conv2D	1	[3, 3]	X	X	Sigmoid	[2, 2, hD]
D	15	Conv2D	1	[2, 2]	X	X	Sigmoid	[1, 1, hD]
D	16	Linear	-	-	X	-	Sigmoid	[1]
Table 5: Hyper parameters in Section 5.2.
	K	ηG]	ηD]	N			N0	Ntest	St	γ	hG	hD
2D-Normal	70	10-3	10-3	50k	10k	10k	100	10-3	32	64
MNIST	20	10-3	10-3	50k	10k	10k	100	10-3	32	32
14
Published as a conference paper at ICLR 2021
Figure 5: The data setting of data cleansing with the influence on ALL (2D-NOrmal) in Section 5.2.
15
Published as a conference paper at ICLR 2021
Figure 6: The data setting of data cleansing with the influence on IS (MNIST) in Section 5.2.
16
Published as a conference paper at ICLR 2021
Figure 7: The data setting of data cleansing with the influence on FID (MNIST) in Section 5.2.
17
Published as a conference paper at ICLR 2021
Table 6: Improvements of test average log-likelihood [10-2] (±std) after the data cleansing (2D-
Normal). The metric value is highlighted when the improvement is statistically significant with the
significant level 0.05
nh
	0.5k	1.0k	2.5k	5.0k	7.5k	10.0k	12.5k	15.0k	17.5k	20.0k
Influence	+0.09	+0.16	+0.31	+0.44	+0.40	+0.22	-0.10	-0.53	-1.07	-1.67
on ALL	(0.06)	(0.12)	(0.27)	(0.50)	(0.73)	(0.99)	(1.28)	(1.60)	(1.95)	(2.33)
Influence	+0.02	+0.04	+0.11	+0.19	+0.26	+0.32	+0.35	+0.35	+0.30	+0.22
on Disc. loss	(0.03)	(0.05)	(0.10)	(0.19)	(0.28)	(0.39)	(0.51)	(0.64)	(0.79)	(0.95)
Isolation	+0.03	+0.05	+0.09	+0.12	+0.12	+0.09	+0.02	-0.09	-0.25	-0.46
Forest	(0.05)	(0.11)	(0.27)	(0.54)	(0.79)	(1.05)	(1.31)	(1.58)	(1.86)	(2.16)
Random	+0.01	+0.02	+0.04	+0.07	+0.08	+0.06	+0.02	-0.05	-0.16	-0.31
	(0.04)	(0.08)	(0.19)	(0.39)	(0.61)	(0.83)	(1.07)	(1.34)	(1.61)	(1.91)
Table 7: Improvements of test inception score (±std) after the data cleansing (MNIST). The metric
value is highlighted when the improvement is statistically significant with the significant level 0.05
	nh									
	0.5k	1.0k	2.5k	5.0k	10.0k	15.0k	20.0k	25.0k	35.0k	45.0k
Influence	+0.03	+0.04	+0.04	+0.03	+0.04	+0.09	+0.10	+0.10	+0.04	-0.18
on FID	(0.07)	(0.09)	(0.17)	(0.25)	(0.24)	(0.13)	(0.12)	(0.13)	(0.17)	(0.28)
Influence	+0.04	+0.04	+0.05	+0.04	+0.08	+0.11	+0.12	+0.14	+0.09	-0.07
on IS	(0.05)	(0.08)	(0.14)	(0.23)	(0.15)	(0.13)	(0.14)	(0.14)	(0.25)	(0.24)
Influence	+0.01	+0.01	+0.02	+0.04	+0.04	+0.04	+0.04	+0.01	+0.00	-0.15
on Disc. Loss	(0.03)	(0.05)	(0.03)	(0.04)	(0.05)	(0.06)	(0.06)	(0.06)	(0.07)	(0.11)
Isolation	+0.00	+0.01	+0.01	+0.00	-0.01	-0.05	-0.13	-0.23	-0.67	-1.70
Forest	(0.02)	(0.02)	(0.04)	(0.05)	(0.06)	(0.08)	(0.13)	(0.18)	(0.33)	(0.75)
Random	+0.01	+0.00	+0.00	-0.01	+0.00	+0.00	-0.01	+0.00	-0.02	+0.00
	(0.02)	(0.01)	(0.02)	(0.04)	(0.04)	(0.05)	(0.09)	(0.06)	(0.07)	(0.10)
18
Published as a conference paper at ICLR 2021
Table 8: Improvements of test FID (±std) after the data cleansing (MNIST). The metric value is
highlighted when the improvement is statistically significant with the significant level 0.05
nh
	0.5k	1.0k	2.5k	5.0k	10.0k	15.0k	20.0k	25.0k	35.0k	45.0k
Influence	-0.10	-0.13	-0.18	-0.19	-0.25	-0.36	-0.38	-0.38	-0.23	+0.23
on FID	(0.13)	(0.18)	(0.28)	(0.46)	(0.45)	(0.35)	(0.36)	(0.37)	(0.46)	(0.60)
Influence	-0.07	-0.10	-0.14	-0.14	-0.26	-0.32	-0.34	-0.36	-0.22	+0.17
on IS	(0.10)	(0.14)	(0.22)	(0.37)	(0.28)	(0.29)	(0.30)	(0.30)	(0.45)	(0.49)
Influence	-0.03	-0.04	-0.07	-0.13	-0.18	-0.20	-0.19	-0.15	-0.06	+0.34
on Disc. Loss	(0.06)	(0.08)	(0.07)	(0.10)	(0.12)	(0.13)	(0.14)	(0.14)	(0.12)	(0.19)
Isolation	+0.01	+0.02	+0.05	+0.10	+0.24	+0.42	+0.73	+1.09	+2.56	+6.99
Forest	(0.03)	(0.03)	(0.06)	(0.08)	(0.15)	(0.22)	(0.37)	(0.54)	(0.85)	(3.57)
Random	-0.01	-0.01	-0.00	+0.01	+0.00	+0.01	+0.02	-0.01	+0.00	-0.13
	(0.04)	(0.02)	(0.04)	(0.06)	(0.07)	(0.08)	(0.16)	(0.09)	(0.13)	(0.18)
D	Detailed Discussion on Experiment 2
This section first discusses three aspects of the results in Section 5.2: Section D.1 explains the com-
mon characteristics of harmful instances suggested by our approach, Section D.2 discusses qual-
itative aspects of the data cleansing using generated samples, and Section D.3 discusses how the
characteristics of harmful instances and effect of the data cleansing are consistent among the train-
ings with different random seeds. Finally, we explain the limitation of our method and present the
future direction in Section D.4.
D.1 Characteristics of Harmful instance
In this section, we examine the characteristics of instances that are evaluated to be harmful or helpful
by our method. We regard a sample is helpful if its influence on a metric is opposite of harmful
instances.
Table 9 shows the estimated harmfulness of the training instances of 2D-Normal and the distribution
of the generated samples. The proposed approach with influence on ALL evaluated the instances
around lower-left and upper-right regions to be harmful (Table 9 (a, i)). These regions correspond to
the regions where the generated distribution has higher density than that of the true distribution; The
generator before the cleansing (Table 9 (a, ii, No removal)) sampled too frequently from lower-left
and upper-right regions compared to the true distribution (Table 9 (a, ii, True)). This characteris-
tics was not observed in the plots of baseline approaches. The approach based on influence on the
discriminator loss seems to ignore the difference in the density around the lower-left region (Ta-
ble 9 (b, i)) and isolation forest did not take the generator’s distribution into account (Table 9 (c, i)).
Similar characteristics were seen in harmful MNIST instances suggested by our approach with in-
fluence on IS and FID. When the generator over-sampled a specific digit (e.g., the digit 1 in Ta-
ble 10 (a, iii)), our approach tended to judge the images of the digit to be harmful (e.g., a large
number of 1 in Table 10 (b-c, i)). Similarly, our method judged instances of a specific digit as help-
ful (e.g., the digit 6 in Table 10 (b-c, ii)) when the generator failed to sample the digit (e.g., the
absence of 6 in Table 10 (a, iii)). On the contrary, harmful instances suggested on the basis of in-
fluence on the discriminator loss did not show the tendency (Table 10 (d, i)). The baseline approach
with isolation forest based on the classifier feature-space seems to have judged the images that were
difficult to be classified as harmful, rather than the over-sampled digit (Table 10 (e, i)). It regarded
that instances are helpful when they belong to a digit that seems to have been easy to be classified
(Table 10 (e, ii)).
19
Published as a conference paper at ICLR 2021
To summarize, our method tends to judge instances as harmful when they belong to regions from
which the generators sample too frequently compared to the true distribution.
D.2 Qualitative study of data cleansing
We then investigate how the data cleansing using the suggested harmful instances visually change
generated samples.
As seen from Table 9 (a, ii), the probability density in the upper-right region decreased after the data
cleansing (from “No removal” to “Cleansed”). As a result, the generator distribution got closer to the
true distribution. Although the baselines indicated the same direction of changes in the distributions
(Table 9 (b-c, ii)), these were not as significant as ours.
The same effect was observed in visually more interesting form in the data cleansing for MNIST. The
generated samples originating from some latent variables changed from the image of digit 1 to that
of other digits after the data cleansing based on the estimated influence on IS and FID (highlighted
samples in Table 10 (b-c, iii)). This implies that a certain amount of density that are over-allocated
for the digit 1 moved to the regions of other digits. We assume this effect improved the diversity in
the generated samples, resulting in better FID and IS. This characteristics was not clearly observed
in the baselines (highlighted samples in Table 10 (d-f, iii)).
These observations suggest that our method helps the GAN’s training so that the generator re-assigns
the densities that were over-allocated to certain regions to other regions.
D.3 Consistency of qualitative characteristics among different trainings
We show additional visual results to confirm the consistency of the findings on the characteristics
of harmful instances and generated samples after data cleansing, which we described in Section D.2
and Section D.3, respectively.
Table 11 shows the harmfulness of the training instances and the distribution of the generated sam-
ples obtained using 5 different random seeds in 2D-Normal case. As seen from the table, regardless
of which region a generator assigns high density to, our method consistently regards the training
samples around the region as harmful. In addition, the distributions of the generated samples get
closer to the true distribution by removing these harmful training instances in the data cleansing.
Table 12 visualizes the MNIST examples of harmful instances, helpful instances, and generated
images before and after the data cleansing. Different rows correspond to different random seeds.
We found the consistency in visual characteristics was moderate in MNIST case. A few results
demonstrated the common qualitative characteristics when the improvements in GAN evaluation
metrics were large (Table 12 (a) and (d)). In the training with the 4th random seed (d), the suggestion
of harmful instances showed some tendency; many instances of digit 7 were regarded as harmful
whereas those of digit 4 were not at all (Table 12 (d, i)). The data cleansing based on this suggestion
seems to have improved the diversity of the generated samples by reducing the samples of digit 7 and
increasing those of digit 4 (highlighted samples in Table 12 (d, iv)). This indicates the consistent
characteristics of the data cleansing discussed in the previous section to some extent; it helps the
GAN’s training so that the generator re-assigns the densities that were over-allocated to certain data
regions to other regions.
D.4 current Limitation and future direction
The limitation of our method is that it does not guarantee the harmful instances suggested on the
basis of influence on one GAN evaluation metric are not necessarily harmful from the viewpoint of
other metrics. For example, we have demonstrated that removing instances that predicted to have
negative influence on FID improved both test FID and IS (Figure 2) and increased visual diversity
in generated images (Table 10 and 12). However, it does not seem to have improved visual quality
(e.g., sharpness, reality, etc.) of the individual generated-samples. Therefore, it is possible that
these instances are harmful only for some particular aspects of generative performance, i.e. the
diversity in this case, and they are not harmful for the other aspect, i.e. the visual quality in this
case.
20
Published as a conference paper at ICLR 2021
We would argue that this limitation is closely tied with the limitation of the current GAN evaluation
metrics. For example, FID takes the diversity of generated samples into account, but they only partly
take the visual quality into account; e.g., FID based on Inception Net was shown to focus on textures
rather than shapes of the objects (Karras et al. (2020)). In this sense, we clarify that we never claim
our method can improve the “true” generative performance from all the aspects, considering the
situation that there is no “true” evaluation metric that measures all the aspects of the generative
performance.
The advantage of our method is that it does not have to care how the evaluation metrics are defined
as long as they are differentiable with respect to the generated samples. Furthermore, our evaluation
method makes no assumption about what the harmful characteristics of instances are. This means
that it is expected to be easily applied to another evaluation metric if better metric is developed
in the future. One of our main contributions in such sense is that we experimentally verified that
our method successfully improved the generative performance in terms of a targeted metric, using
limited but currently widely accepted metrics.
Our future work includes incorporating such future improvements in the GAN evaluation metric to
obtain better insights on the relationship between training instances and generative performance. In
addition, we would like to relax the current constraint on the optimizer. Our method is currently
applicable only to SGD but we would like to find a way to extend it to other optimizers such as
Adam (Kingma & Ba (2015)) to deal with the latest GAN models.
21
Published as a conference paper at ICLR 2021
Table 9: (i) harmfulness of 2D-Normal instances suggested by different approaches, (ii) changes in
the generator’s distribution, and (iii) test ALL after the data cleansing. (ii) includes plots of the true
distribution (True) and generator’s distributions before (No removal) and after (Cleansed) the data
cleansing with nh = 5.0k. The distributions of generated samples, that refer to DG(Ztest; θG[T]) (No
removal) and DG (Ztest ; θG? ) (Cleansed), are estimated with kernel density estimation.
(iii) ALL
(ii) Generated distribution
(i) Harmful instances
----True
----No removal
Cleansed
+1.24
+0.67
+0.73
+0.43
Ranking of predicted harmful score [k th]
(lower are more harmful)
(SjnO)
LLA no ecneuflnI
)a(
SSOa ∙3s.α UO əɔuənpui JSəjθ 工 UOHEOSl
)b( )c(
UloPUEX
)d(
22
Published as a conference paper at ICLR 2021
Table 10: (i) top 36 harmful and (ii) helpful MNIST instances predicted by the different approaches,
(iii) the test generated samples, and (iv) changes in test FID after the data cleansing with nh = 25.0k.
All the generated samples use the same series of test latent variables in Ztest .
+1.80
-0.21
-0.21
(iii) Generated
(iv) FID
±0
-0.71
-0.85
，r*f夕 / 夕
/ 4 ,。
g^g∕4>I3⅞bj61 3¾g>^CΓ-g¾ςo∕4>311>8∕4/
I Λ 3 ⅜∕-∕-o⅞ I N a -S IZ B 1f ɪ -S IZ%∙⅜f-/-o⅜ IZ 3 >∕-∕-⅞⅞
343D/q34 3U7S夕卒夕D7S夕4 ,O7<Γ3 4∕O∕<
3¾g，4>O/
12 B /-/-o⅞
, 4 7 D 7 ft>
(ii) Helpful
(i) Harmful
n/a
IEAouləj ON
)a(
7>G25lS 厂 <t4r6∕0 7 夕 >∕∕∕∕∕∕G36 V 9 /
6oc<3oCxJ 不乙rLΓn∕∕0A5c>∕∕∕∕∕∕G6 夕 4//
Go0，g/R¥76τNf 夕//Γr∕∕∕∕∕∕4rb,0Gq
gG/Gdo&XD^OGraγJEO^∕∕∕∕∕∕Q5q730
RQlx∙np夕 Oq67H∕CΓgl / / // // /736513
Q6>O3 78qgm∕6<t,1o/夕/ // // //aʒ/u/0√
/500方, 5 /。。，^/—5。7，户Γ7g Vufβσ∖7r3o3
5 / — 夕 sl>rCJ√087o I Sl7soubxUrft∕,qb 夕 q
e/ 7 —乙，。4 / 7∕∕qoyFO70 UGq C Nlag ' 40
∕5∕∕∕z5l / / / //方2 9∕q∕^a - u≡⅛⅜λr-r/ 夕J
/ P 7 / 7∕∕7∕o4o∖6r"√92 GA9¾Λ23qz>5'os
3IO∕1∕∕∕6∕∕∕⅛Z5HO>7Q70 厂 403/0〃。1
)sruO(
SI Uo əouənuuɪ
)b(
)sruO(
DIF no ecneuflnI
)c(
ijQ co əouənuuɪ
)d(
JSəjo H UOngOSI
)e(
UloPUEH
)f(
23
Published as a conference paper at ICLR 2021
Table 11: Comparison among different random seeds used in the training in 2D-Normal case. See
Table 9 for how the plots are generated.
	(i) Harmful instances	(ii) Generated distribution	(iii) ALL
	Ranking of predicted harmful score [k th] (lower are more harmful) J j∣p " :， 	1	1	1	1	 -2 0	2	4 xl		True —No removal 	Cleansed :彳 匾 / ：「Zd -2	0	2	4 Xl	+1.24
	。匚* ^3^∣——r-,—l—l—— -2	0	2	4 Xl	10 -2 0 2 4 Xl	+0.29
	[Jl 0- ..⅜y∙ -3~1 ： ：I	1	1	 -2 0 2 4 Xl	x2 I I I 32 IOl 2345	+0.54
	3-	•,嘉, W * 二 _3 一 — 	1	1	1	1	 -2	0	2	4 Xl	j l 1 1 J -2	0	2	4 Xl	+0.32
	6 - 4 -	•••.；」：. ,3⅛ ' o- -≡HBR- -2- -4~l 1	1	1	1	 -2 0	2	4 Xl	-4-l	1	1	1	1	 -2	0	2	4 Xl	+0.58
24
Published as a conference paper at ICLR 2021
Table 12: Comparison among different random seeds used in the training in MNIST case. The
generated samples from the model without cleansing (iii) and cleansed model (iv) in the same row
use the same series of test latent variables. See Table 10 for the detail of how the images are obtained.
(v)
FID
(iii)
Generated
(No removal)
(i)	(ii)
Helpful
Harmful
(iv)
Generated
(Cleansed)
3 Z7Γ¾3/
Z 7 g 1 / to、—
rr4p^1 7
ZK 息 sɔ/ 7
-0.85
-0.45
+0.09
-0.71
-0.12
2>¾s 夕幺 Jr / 7∆q0l¾,p∕zz∖cn√/Q
分/ q7弓mQ6"r⅛-夕乡& 5JIB 〃，
s¾g,∙4s3∕g>，/<∕2β夕。，7耳?，*-
IZB ?® St9 夕1? & A 夕rL %SAP 夕 3 —夕
34-Z-&7S060ScO63，/&.* V- 7 T 0 Λ ʃ
0，r。/牛夕5046R9i9cr4^2f<fs4 夕夕 3/af
2>rf∕q/ 7Δ⅛Γ*^lt>6P，ZZ∖1√4Δ7J7∕J-7∖
。/4 / 3 口 Qgdr Y⅛∙r5 吊 945N q3, λξz 7FND，
夕¾g∕4>1∕g-∖ 1J>P7ZΛ,。，75Z7 7/Sr
I- 3 ⅝∕-∕z- Ol 1»9夕— <*∙ Λo^^√- ⅛c fn 3 ɑɔ- ⅛0√⅛∕ j⅜ Z∖ -A* √r Vf
74yo7qo8QSoe3 7∕⅛-5,77 6 0人, ZK∕a53∕7
。夕厂ɪ/s 彳585837,3 701 7/
A7-L?Lcno61 ɛ 1) 7⅛65⅝∕^∙∕υ frl⅛70zτ*0J Ci
R¥76Tq,7∕2z377 队 r-7992.z5g»g，3/3 +
^CGr4夕夕？<?51y，e ?，^∖77<vg4F∕,∖⅛/
。夕。q∖3 7，/|2>3 夕 IH246 o∙4b,J∕9J-OS
QGM,64τfc5-737732/〃793夕夕夕。¥725/3
5∕s∙c*^os∕7 0、74/5?72,4。名「7//¥，6
/a j√cs72 36 户 4 7夕夕 g23∕770σ,r2S 9/4 f
0 4/ 7 / / 夕/7S /夕,—£377A 7∖∖6∕err-7γ83
5 1/ / / /o5∕∕73fllrku'927rNo^/?0?^2
∕7∕o4OG∕i2q4Λf d 7Avt32^a cγ*74i>∕%
∕f4∕J∕r*y/Q^L，<?〃 Γrf∕7b0<s7>70 15β二& ?/
dees.dnarts1)a(dees.dnardn2)b(dees.dnardr3)c(dees.dnarht4)d(dees.dnarht5)e(
25