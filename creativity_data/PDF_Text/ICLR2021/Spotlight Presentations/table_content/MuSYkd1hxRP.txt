Table 1: DARTS: Comparison with SOTA NAS methods on the DARTS search space, plus threeresults on different search spaces with a similar number of parameters reported at the top forcomparison. All evaluations and reported performances of models found on the DARTS search spaceuse similar training routines; this includes auxiliary towers and cutout but no other modifications,e.g. label smoothing (Muller et al., 2019), AutoAugment (Cubuk et al., 2019), SWish (Ramachandranet al., 2017), Squeeze & Excite (Hu et al., 2018), etc. The specific training procedure we use is thatof PC-DARTS, Which differs slightly from the DARTS routine by a small change to the drop-pathprobability; PDARTS tunes both this and batch-size. Our results are averaged over 10 random seeds.
Table 2: NAS-Bench-201: Results are separated into traditional hyperparameter optimization al-gorithms with search run on CIFAR-10 (top block), weight-sharing methods with search run onCIFAR-10 (middle block), and weight-sharing methods run directly on the dataset used for training(bottom block). The use of transfer NAS follows the evaluations conducted by Dong & Yang (2020);unless otherwise stated all non-GAEA results are from their paper. The best results in the transferand direct settings on each dataset are bolded.
Table 3: GAEA PC-DARTS Stage 3 Evaluation for 3 sets of random seeds.
Table 4: DARTS (CIFAR-10): Comparison with manually designed networks and those found bySOTA NAS methods, mainly on the DARTS search space (Liu et al., 2019). Results grouped by thetype of search method: manually designed, full-evaluation NAS, and weight-sharing NAS. All testerrors are for models trained with auxiliary towers and cutout (parameter counts exclude auxiliaryweights). Test errors we report are averaged over 10 seeds. “-” indicates that the field does notapply while “N/A” indicates unknown. Note that search cost is hardware-dependent; our resultsused Tesla V100 GPUs.
Table 5: DARTS (ImageNet): Comparison with manually designed networks and thosefound by SOTA NAS methods, mainly on the DARTS search space (Liu et al., 2019). Resultsare grouped by the type of search method: manually designed, full-evaluation NAS, andweight-sharing NAS. All test errors are for models trained with auxiliary towers and cutoutbutno other modifications, e.g. label smoothing (Muller et al., 2019), AutoAugment (Cubuket al., 2019), Swish (Ramachandran et al., 2017), squeeze and excite modules (Hu et al.,2018), etc. “-” indicates that the field does not apply while “N/A” indicates unknown. Notethat search cost is hardware-dependent; our results used Tesla V100 GPUs.
