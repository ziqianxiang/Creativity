Table 1: German credit: average results over 10 splits into 80% training and 20% test data.
Table 2: Adult: average results over 10 splits into 80% training and 20% test data. NN, SenSR andAdversarial Debiasing (Zhang et al., 2018) numbers are from Yurochkin et al. (2020).
Table 3: COMPAS: average results over 10 splits into 80% training and 20% test data.
Table 4: Optimal XGBoost parameters for German credit data set. For BuDRO, we also used apertubation budget of = 1.0.
Table 5: Results on German credit data set. We report the balanced accuracy in the second column.
Table 6: Optimal XGBoost parameters for the Adult data set. For BuDRO, we also used a perturbationbudget of = 0.4. The value of min_weight for BuDRO is computed relative to the size of an80% training set, which contains 36177 individuals.
Table 7: Results on Adult. We report the balanced accuracy in the second column.
Table 8: Optimal XGBoost parameters for COMPAS data set.
Table 9: Results on COMPAS data set. These results are based on 10 random splits into 80% trainingand 20% test data.
Table 10: Average runtime for training, including standard deviations. The number in parentheses isthe number of trials used to compute the average. In all trials, the hyperparameters (including thenumber of boosting steps) were examined during the generation of the data presented in Section 5.
