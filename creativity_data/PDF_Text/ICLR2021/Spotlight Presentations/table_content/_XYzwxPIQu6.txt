Table 1: Overview over the different models used for comparisonNAME	DESCRIPTIONRNN	Vanilla ReLU based RNNiRNN	RNN with initialization Wo = I and ho = 0 (Le et al., 2015)npRNN	RNN with weights initialized to a normalized positive definite matrix with largest eigenvalue of 1 and biases initialized to zero (Talathi & Vartak, 2016)PLRNN	PLRNN as given in eq. 1 (KoPPe et al., 2019)iPLRNN	PLRNN with initialization Ao = I, Wo = 0 and ho = 0rPLRNN	PLRNN initialized as illustrated in Fig. S1, with additional regular- ization term (eq. 3)LSTM	Long Short-Term Memory (Hochreiter & Schmidhuber, 1997)oRNN	ReLU RNN with W regularized toward orthogonality (WWT → I) (Vorontsov et al., 2017)L2RNN	Vanilla RNN with standard L2 regularization on all weightsL2pPLRNN	PLRNN with (partial) standard L2 regularization for proportion Mreg/M = 0.5 of units (i.e., pushing all terms in A and W for these units to 0)L2fPLRNN	PLRNN with (full) standard L2 regularization on all weights6.1.8	More details on single neuron modelThe neuron model used in section 4.2 is described by_ _________ _ 、 _______________ _ 、-CmVr = gL (V - EL) + gNam∞(V)(V - ENa)+ gK n(V - EK ) + gM h(V - EK)+ gNMDAσ(V)(V - ENMDA)	(55)；h∞(V) - h
