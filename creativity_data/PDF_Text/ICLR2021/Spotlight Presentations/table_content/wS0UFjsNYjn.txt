Table 1: The few-shot classification results (way, shot) on the Omniglot and Mini-ImageNet datasets. DCdenotes DeepCluster. We report the average of accuracies evaluated over 1000 episodes. All the values arebased on the reported performance in Hsu et al. (2019) and Khodadadeh et al. (2019), except for ours.
Table 2: Left: The results of the ablation study on Meta-GMVAE (O: 20-way 1-shot classification on Om-niglot, M: 5-way 1-shot classification on Mini-ImageNet). Right: The results of cross-way 1-shot experimentson Omniglot. The values in the parenthesis indicate that a model is trained based on the (way, shot) setting.
Table 3: Set-level variational posterior network used for Omniglot dataset. We refer the hyperpa-rameter notation of TransformerEncoder to Vaswani et al. (2017).
Table 4: Generative Network for pθ(x|z) for Omniglot dataset.
Table 5: The few-shot classification results (way, shot) with 95% confidence interval on the Omniglot.
Table 6: Feature Extractor trained on Mini-ImageNet dataset using SimCLR objective.
Table 7: Set-level variational posterior network used for Mini-ImageNet dataset. We refer the hy-perparameter notation of TransformerEncoder to Vaswani et al. (2017).
Table 8: Generative Network for pθ(x|z) for Mini-ImageNet dataset.
Table 9: The few-shot classification results (way, shot) with 95% confidence interval on the Mini-ImageNet.
Table 10: The comparison on the few-shot classification results (way, shot) using SimCLR.
