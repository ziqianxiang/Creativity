Table 1: Left: Performance when training on a three-object fast-mapping task with |G| = 30. mem:size of memory buffer/window R: with reconstruction loss. Right: Learning curves, each showingmean ± S.D. over 5 random seeds.
Table 2: Left: Architectures compared on DeepMind Lab after 5e8 timesteps of training. Data showmean accuracy (S.D) across 5 seeds in each condition. mem: the agent’s memory buffer size. R:with reconstruction loss. Right: Schematic of episode structure in the DeepMind Lab fast-bindingtasks.
Table 3: Agent hyperparameters (independent of specific architecture). The return cost (not dis-cussed in the main text) is used to weight the baseline estimate term in the V-trace loss.
Table 4: Hyperparameters for NGU.
