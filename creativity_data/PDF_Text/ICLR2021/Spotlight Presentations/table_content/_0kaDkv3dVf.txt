Table 1: Important details about the six hardware devices considered by our HW-NAS-Bench.
Table 2: Two types of correlation coefficients (larger means more correlated) between the real-measured hardware-cost of the whole architectures and the approximated hardware-cost based on100 randomly sampled architectures from the FBNet search space.
Table 3: Kendall Rank Correlation Coefficient between real-measured/estimated hardware-cost andtheoretical ones considering the NAS-Bench-201 search space, where coefficients <0.5 are bolded.
Table 4: Kendall Rank Correlation Coefficient between real-measured/estimated hardware-cost andtheoretical ones considering the FBNet search space, where coefficients <0.5 are bolded.
Table 5: Inference accuracy and latency comparison of the optimal architectures resulting fromHW-NAS-Bench when targeting different hardware devices.
Table 6: The differences of the hardware-cost estimation given by Accelergy (Wu et al.,2019)+Timeloop (Parashar et al., 2019) and DNN-Chip Predictor (Zhao et al., 2020b), consider-ing NAS-Bench-201 on 3 datasets.
Table 7: Left: the marco-architectures of the search space proposed in the FBNet (Wu et al., 2019)for the ImageNet classification; Right: our modified search space to fit the input image size of theCIFAR-100 dataset. In the tables, “TBS” means the layer type needs to be searched and “Stride”denotes the stride of the first block in the stage. Here the modified parameters are emphasized asbold characters.
Table 8: Our implemented FPGA accelerators for HW-NAS-Bench vs. SOTA FPGA accelerators,considering VGGl6 on the ImageNet dataset and using Zynq XC70Z45 as the FPGA device.
