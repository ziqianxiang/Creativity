Table 1: Percentage (%) of test tasks solved by different methods without and with data augmentation. The“wide”, “narrow”, and random grids are described in Figure 2. We report average performance across 100 runswith different random initializations, with standard deviation between parentheses.
Table 2: Ablating PSEs. Percentage (%) of test tasks solved whenwe ablate the similarity metric and learning procedure for metricembeddings in the data augmentation setting on wide grid. PSEs,which combine CMEs with PSM, considerably outperform otherembeddings. We report the average performance across 100 runs withstandard deviation between parentheses. All ablations except PSEsdeteriorate performance compared to just using data augmentation(RandConv), as reported in Table 1.
Table 3: Generalization performance with unseen distractions in the Distracting Suite at 500K steps. Wereport the average scores across 5 seeds ± standard error. All methods are added to SAC (Haarnoja et al., 2018).
Table G.1: Percentage (%) of test tasks solved when trainedon the “wide” grid with both red and green obstacles. Thenumbers we report are averaged across 100 runs. Standarderror is reported between parentheses.
Table G.2: Common hyperparameters acrossall methods for all jumping task experiments.
Table G.3: Optimal hyperparameters for reporting results in Table 1. These hyperparameters are selected usingthe “wide” grid by maximizing final performance on a validation set containing 56 unseen tasks. All gridconfigurations in Table 1 use these hyperparameters.
Table G.4: Optimal hyperparameters for reporting results in Figure 5.3. These hyperparameters are selectedusing the “wide” grid by maximizing final performance on a validation set containing 56 unseen tasks.
Table G.5: Optimal hyperparameters for reporting ablation results in Table 2. These hyperparameters are selectedusing the “wide” grid by maximizing final performance on a validation set containing 56 unseen tasks.
Table H.1: LQR generalization performance: Absolute error in LQR cost, w.r.t. the oracle solver (which hasaccess to true state), of various methods trained with nd distractors on N = 2 environments. The reported meanand standard deviations are across 100 different seeds. Lower error is better.
Table H.2: An overview of hyper-parameters for LQR.
Table I.1: Optimal hyperparameters for PSE auxiliary loss for reporting results in Table 3.
Table I.2: Hyper-parameters taken from Kostrikov et al. (2020) in the Distracting Control Suite experiments.
Table I.3: The action repeat hyper-parameter used for each task in the Distracting Control Suite benchmark.
