Figure 1: Our method RIDE outperforms SOTA by reducing both model bias and variance. a)These metrics are evaluated over 20 independently trained models, each on a random sampled set ofCIFAR100 with an imbalance ratio of 100 and 300 samples for class 0. Compared to the standardCE classifier, existing SOTA methods almost always increase the variance and some reduce the tailbias at the cost of increasing the head bias. b) The metrics are evaluated over CIFAR100-LT Liuet al. (2019). LDAM is more likely to confuse the tail (rather than head) classes with the hardestnegative class, with an average score of 0.59. RIDE with LDAM can greatly reduce the confusionwith the nearest negative class, especially for samples from the few-shot categories.
Figure 2: RIDE learns experts and their router in two stages. a) We first jointly optimize multipleexperts with individual classification losses and mutual distribution-aware diversity losses. b) Wethen train a router that dynamically assigns ambiguous samples to additional experts on an as-neededbasis. The distribution of instances seen by each expert shows that head instances need fewer expertsand the imbalance between classes gets reduced for later experts. At the test time, we collect thelogits of assigned experts to make a final decision. c) RIDE outperforms SOTA methods (i.e. LFME(Xiang et al., 2020) for CIFAR100-LT, LWS (Kang et al., 2020) for ImageNet-LT and BBN (Zhouet al., 2020) for iNaturalist) on all the benchmarks.
Figure 3: RIDE is a universal framework thatcan be extended to various long-tail recognitionmethods and obtain a consistent top-1 accuracyincrease. RIDE is experimented on CIFAR100-LT and applied to various training mechanisms.
Figure 4: Compared to SOTAs, RIDE improves top-1 accuracy on all three splits (many-/med-/few-shot). The absolute accuracy differences of RIDE (blue) over iNaturalist’s current state-of-the-art method BBN (Zhou et al., 2020) (left) and ImageNet-LT’s current state-of-the-art method cRT(Kang et al., 2020) (right) are shown. RIDE improves the performance of few- and medium-shotscategories without sacrificing the accuracy on many-shots, and outperforms BBN on many-shots bya large margin.
Figure 5: # experts vs. top-1 accuracy for eachsplit (AlL Many/MediUm/Few) of CIFAR100-LT. Compared with the many-shot split, whichis 3.8% relatively improved by adding more ex-perts, the few-shot split can get more benefits,that is, a relative improvement of 16.1%.
Figure 6: The proportion of the number of ex-perts allocated to each split of CIFAR100-LT.
Figure 7: Comparison between our method andmultiple LDAM models ensembled together. Inthe figure, ensembles of LDAM start from 1 en-semble (original LDAM) to 7 ensembles, andRIDE starts from 2 experts to 4 experts. Ourmethod achieves higher accuracy with substan-tially less computational cost compared to en-semble method.
Figure 8: t-SNE visualization of LDAM’s and our model’s embedding space of CIFAR100-LT. Thefeature embedding of RIDE is more compact for both head and tail classes and better separated.
