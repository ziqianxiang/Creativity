Figure 1: The Traveling Observer Model. (a) Tasks with disjoint input and output variable sets aremeasured in the same underlying 2D universe. The shape of each marker (i.e., ◦, □, 4, ?) denotesthe task to which that variable belongs; white markers denote input variables, black markers denoteoutput variables, and the background color shows the state of the entire universe when the currentsample is drawn. (b) The function f encodes the value of each observed variable xi given its 2Dlocation zi ∈ R2, and these encodings are aggregated by elementwise addition L; (c) The functiong decodes the aggregated encoding to a prediction for yj at its location zj . In general, the embeddedlocations z are not known a priori, but they can be learned alongside f and g by gradient descent.
Figure 2: Diagram of the TOM implementation used in the experiments. Encoder, Core, andDecoder correspond to f, gι, and g2 in Eq. 4, resp. The Encoder and Decoder are conditioned oninput and output VEs Z via FiLM layers. A CRB is simply an FRB without conditioning. Dropoutand trainable scalars α implement SkipInit as a substitute for BatchNorm. This residual structureallows the architecture to learn tasks of varying complexity in a flexible manner.
Figure 3: Variable embeddings learned for CIFAR unfold over iterations until they resemble Oracleexpectations (best viewed in color). The VE for each variable, i.e., pixel, is colored uniquely. TOMpeels the border of the CIFAR images (the upper loop of VEs at iteration 300K) away from theircenter (the lower grid). This makes sense, since CIFAR images all feature a central object, whichsemantically splits the image into foreground (the object itself) and background (the remaining ringof pixels around the object). See https://youtu.be/R_z-2SR2KpY for videos of VEs being learned.
Figure 4: Variable embeddings learned for daily temperature variables untangle over iterationsand converge on a 1D manifold ordered by time, as one would expect (neighboring time-steps areconnected to illustrate the order). TOM has embedded this 1D structure as a ring in 2D, which iswell-suited to the nonlinear encoder and decoder, since it mirrors an isotropic Gaussian distribution.
Figure 5:	(a) Tasks with disjoint input and output variable sets, whose variables are nonethelessmeasured in the same underlying space (dotted lines are samples). These tasks are drawn from theTransposed Gaussian Process problem in Section 5.2; (b) TOM can be applied to any task in thisspace: It predicts values at output locations, given values at input locations.
Figure 6:	Learned VEs capture underlying structure across tasks. (a) VEs of features for concentrichyperspheres encode the origin location, and (b) for classes encode the index of their annuli (lessprecisely for the more distant annuli, since they occur in fewer tasks); (c) VEs for UCI-121 (shownin 2D via t-SNE) neatly carve the space into features, common classes, and uncommon classes.
Figure 7: Pytorch code for the forward pass of the TOM implementation.
