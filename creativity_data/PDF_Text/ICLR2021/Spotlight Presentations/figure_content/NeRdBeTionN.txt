Figure 1: Samples generated by StyleGAN* and PGGAN trained on CelebaHQ. The quality ofimages generated by StyleGAN* is substantially higher.
Figure 2: The reference image is top-left denoted by a green frame, while 8 others constitute adiverse sample of images that have approximately the same embeddings as the reference one.
Figure 3: Samples generated by StyIeGAN*, PGGAN, RPGAN and COCO-GAN trained on Bed-room. The quality of images generated by StyleGAN* is substantially higher, while the quality ofthe images generated by RPGAN and COCO-GAN is approximately the same.
Figure 4: FID values for different samplesizes for StyleGAN2 on Church. Since FIDvalues for SwAV and InceptionV3 have dif-ferent scales, they normalized by the FIDvalue computed for a sample of size 100k.
Figure 5: Random sample of images generated by MSG without truncation and PGGAN trained onCelebaHQ dataset. One can see that the quality of images generated by MSG is substantially higher.
Figure 6: Examples of real images that are confidently covered by StyleGANv2 in terms of Incep-tionV3 embeddings, but not covered in terms of SwAV.
Figure 7: Examples of nearest neighbors in terms of SWAV and ALAE representations.
Figure 8: User interface for precision / recall agreement labeling (left) and top-5 neighbours labeling(right).
