Figure 1: Test accuracy and training loss, averaged in 5 runs.
Figure 2: Loss landscapes around the local minima of converged models trained on CIFAR-10 withsymmetric noise, visualized using the technique in Li et al. (2018). We show the z-axis on the samescale to compare the sharpness; and draw color bars separately to show the loss distribution aroundeach minimum. (a): The model trained with CE converges to a sharp minimum. (b): Trainingwith Eq. (1) yields a minimum with a higher loss, yet it is still sharp. (c)&(d): Consistent with ouranalysis, the model trained with Eq. (2) or Eq. (3) converges to a flat minimum.
Figure 3:	Samples density w.r.t. the prediction probabilities (the softmax outputs on the labeledclass). SLN reduces overconfidence mostly on noisy samples, while clean samples are less affected.
Figure 4:	Training samples are sorted in ascending order of loss, uniformly divided into 1000 sam-ples per interval, and dissected according to the correctness of the given label and the prediction.
Figure 5: Performance of SGD noise variants on CIFAR-10. The accuracy is averaged in 5 runs.
Figure 6: Test accuracy (mean±std in 5 runs) of SLN on CIFAR-10 w.r.t. σ. A small σ resultsoverfitting while a large σ yields underfitting. In Appendix C.2, we visualize the embedding ofoverfitting/underfitting. For results reported in Table 1 and Table 2, following Zhang & Sabuncu(2018); Chen et al. (2020b), we use 5k noisy samples as the validation to tune σ ∈ {0.1, 0.2, 0.5, 1}.
Figure 7: The t-SNE visualization of features on the model’s penultimate layer.
Figure 8: Test accuracy w.r.t. training efficiency (1/time) on CIFAR-10.
Figure 9: Training samples are sorted in ascending order of loss, uniformly divided into 1000 sam-ples per interval, and dissected according to the correctness of the given label and the prediction.
Figure 10: The test accuracy on CIFAR-10, averaged in 5 runs. We zoom in to focus on the effectsof label correction applied in the last 50 epochs. The open-set noise involves samples that do notbelong to any class considered in the task, for which label correction can not address.
