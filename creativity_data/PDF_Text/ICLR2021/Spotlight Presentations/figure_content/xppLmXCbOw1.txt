Figure 1: Our proposed SMORL architecture. Representations zt are obtained from observationsot through the object-centric SCALOR encoder qφ , and processed by the goal-conditional attentionpolicy ∏θ(at∣zt, Zg). During training, representations of goals are sampled conditionally on therepresentations of the first observation z1. At test time, the agent is provided with an external goalimage og that is processed with the same SCALOR encoder to a set of potential goals {zn}nN=1.
Figure 2: Multi-Object Visual Push and Rearrange envi-ronments with 2 objects and a Sawyer robotic arm.
Figure 3:	Average distance of objects to goal positions, comparing SMORL using ground truthrepresentations to SAC with ground truth representations in the Rearrange environment with differentnumber of objects. SAC struggles to improve performance when the combinatorial complexity of thescene rises. The dotted line indicates the performance of a passive policy that performs no movements.
Figure 4:	Average distance of objects to goal positions, comparing SMORL to Visual RL Baselines.
Figure 5: Out-of-distribution generalizationof SMORL agent training on Visual Rear-range with two objects and being tested withone object. Green line shows final perfor-mance when training with one object.
Figure 6: First and second PCA dimension of zwhat space of SCALOR trained on Visual Rearrangewith 3 objects. The plot shows 3000 random zwhat points collected from a random policy. Each pointis colored as the mean of the foreground pixels on the crop detected by SCALOR. For each cluster,the highlighted point shows an example crop. Dashed lines indicate the Voronoi partitions accordingto cluster centers found by running k-means clustering. Figure is best viewed on screen.
Figure 7: Comparison of VAE and SCALOR representations. (a) shows MIG scores of VAE andSCALOR representations on data obtained from running a random policy in the Visual Rearrangeenvironment with 3 objects (with whisker showing the standard deviation over 5 runs), (b) shows themutual information matrix for SCALOR representations on the same data.
Figure 8: Reconstructions of scene observations using learned SCALOR representation and decoder.
Figure 9: Ablation study of goal-conditioned attention policy on Visual Rearrange with two objects(left) and out-of-distribution testing on Visual Rearrange with one object (right). We compare variantsof the attention policy with only goal-conditional and only goal-unconditional attention heads, plusan alternative approach to aggregate sets of vector representations in the form of DeepSets (Zaheeret al., 2017). Our results demonstrate that both types of attention heads are necessary to achieve thebest results.
Figure 10: Performance of a SMORL agent trained for 106 timesteps on Visual Rearrange with 2objects.
