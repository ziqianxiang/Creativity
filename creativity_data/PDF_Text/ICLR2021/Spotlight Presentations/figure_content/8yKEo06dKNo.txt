Figure 1: Illustrative examples of the impact of Mixup on robustness and generalization. (a) Adversarial robustness on the SVHN data under FGSM attacks. (b) Generalization gap between test and
train loss. More details regarding the experimental setup are included in Appendix C.1, C.2.
Figure 2: Comparison of the original Mixup loss with the approximate Mixup loss function.
Figure 3: The behaviors of the values of R and Ri during training for linear models and artificial neural network with ReLU (ANN). The subplots (c) and (d) show the histogram of (R1, R2, . . . , Rn) for ANN before and after training. R and Ri control the radii of adversarial attacks that Mixup training protects for.
Figure 4: Comparison of the original adversarial loss with the approximate adversarial loss function.
Figure 5: Generalization: CIFAR-10.
Figure 6: Generalization: CIFAR-100.
Figure 7: Generalization: Fashion-MNIST.
Figure 8: Generalization: Kuzushiji-MNIST.