Table 1: Equations for deep network nodesNode Type		Function	A	Forward	h(l)	=Θ⑷ h(IT)A|	Backward	δ(l)	=Θ(I)I δ(1+1)Θ	Update	Θ(l)	= Θ0 - R0t h(l-1) × δ(l)dtΦ	Activation	h(l)	= φ(h(l-1))Φ0	Tangent	δ(l)	= φ0(h(l-1))	δ(l+1)X	Input*	x=	Xbt/aCY	Label	y(x)	L	Loss	L(h(D),y)		* {Xk 〜 X} is a sequence of random observa-tions of X. x(t) is piecewise constant.
Table 2: Hyper Parameters tested with Continuous PropagationMomentum	μ1∕2	half-life in epochs	[0, 0.10]Normalization	-	-	None, Normalization PropagationArpit et al.
