Figure 1: U-Net architecture Ronneberger et al. (2015) adopted in this work.
Figure 2: Examples stimuli. Parameters include number of objects, shape type, point density, object scale,rotation, and location. Parameter ranges are set to increase the chance of overlap among objects. (a) Stimuligenerated with shapes. Shapes include circle(filled), ring, square(filled), square ring, and bar. (b) Stimuligenerated with Gaussian distributions. Gaussian clusters are shown with different markers for the illustrationpurpose.
Figure 3: Sample images and the output of our clustering algorithm compared to other methods (A) in exper-iment three (3 clusters, 3 shapes) and (B) in experiment five (2 or 3 clusters, Gaussian mixtures).
Figure 4: Results of experiment 8. Sample outputs of the CNN trained with different number of images (n =200). A: for shapes and B: for Gaussian distributions.
Figure 5: (a) Results of experiment 9. Sample outputs of CNN,trained over noiseless data, over 3 images corrupted with {250,500, 1000} amount of noise. A: Shape clusters, B: Gaussian clus-ters. (b) A: Results of experiment 9, noise level versus pairwiseaccuracy. B: Results of experiment 8, number of training data sam-ples versus pairwise accuracy.
Figure 6: A) A sample trial in the user study, B)While our formulation is supervised, feeding the la-bels to the network is not always consistent. This iswhere our work differs from semantic segmentationand instance level segmentation. We exploited themean squared loss to train the network. It might bepossible to define other loss functions to teach thenetwork more efficiency using less number of train-ing data or even with weaker labels. One possibility Fraction of the cases where subjects chose modelsis the pairwise accuracy that we used here for eval- and break downs over clusters (all, 2, or 3), anduation. Instead of correctly classifying labels, the C) Performance of the models over the stimuli.
