Figure 1: Illustration of stepwise GANthusTD0(x|y) =XαtDD(x1...t|y)t=1D* =argmaχ Ey〜PR(y),χR〜PR(X |y) [log(DO (XR Iy))]	(7)+ Ey〜PR(y),xG〜PG(X|y) [log(I - D0(XGIy))],G* = arg max Ey〜PR(γ),χG〜PG (χ∣y) [D(XG Iy)],Gwhere αD is a weighted factor with PT=I αD = 1. In practice, We set αD = T1, but it is possibleto give different steps different weights. StepGAN not only considers terminated episodes but alsoassign scores for each prefix. Although we only use one way to train D , we think there are two waysto interpret the D’s scores, and different view points lead to different update formulations for G:• D(X1...tIy) evaluates the extra benefit of adding the word Xt into the sequence. The formu-lation for G’s parameter update isTΘg — Θg + ηαG(X D(xι…t Iy))▽ log(pG(XG ∣y, X1G...t-1)).	(8)t0 =tG has to increase the summation PtT0=tD(X1...t0 Iy). We call this stepGAN-Seq.
Figure 2: Sampled accuracy and coverage curvesTable 3: Human evaluation and BLEU score for dialogue generation. CoHS (%) is coherence humanscore. SHS (%) is sentence structure human score.
Figure 3: The variation of discriminators’ scores using different GAN algorithms during trainingiterations. The printed color is normalized throughout the generation steps (x-axis) for each algo-rithm. (a)(b) are given “how are you ?” as input, and (c)(d) are given “what ’s your name ?” asinput.
Figure 4: Illustration of energy-based stepwise GANsamples. The advantage of EBStepGAN is that we can initialize both generator and discriminatorwith the same pre-trained model using MLE. The optimization functions are written asTD* = arg max E(XR,y)〜PR(X,Y)[	log(PD (xtR|y,x1R...t-1))]t=1	T	(10)+maximum(0, β - Ey〜PR(Y),χG〜PG(χ∣y)[工 log(PD(XG∣y, xG..t-ι))])TG* =argmax Ey 〜P R(Y ),χG 〜P G (X |y) [] log (P D (XG ly,xG..t-I))],	(II)where PD(xtG|y, x1G...t-1) in Equation (11) is the probability of generating xtG given < y, x1G...t-1 >based on the current model D, and β in Equation (10) is the threshold for preventing the discrim-inator from distinguishing generated samples from real samples too easily. When the energy ofgenerated samples is too high, the threshold turns off the second term in (10). The results of EB-StepGAN is shown in Table 6. According to Table 6, EBStepGAN does not show better performancethan StepGAN in our current experiments.
