Figure 1: Transfer learning visualizationUse-specific modelVisualizing the learned knowledge of a neural network is CritiCal for interpretability and tuning of thenetwork Zeiler & Fergus (2013). While in the past deep neural nets were often Considered a blaCkbox, reCent Convolutional layers were suCCessfully visualized Zeiler & Fergus (2013). Visualizingtime-series data is different beCause we have numeriCal values instead of images. In seCtion 4.3 weprovide an attempt to interpret some of the learned features.
Figure 2: (a) Performance comparison of deep LSTM models between training with single timeseries and training with transfer learning. The x-axis is the training size; the y-axis is SMAPE.
Figure 3: The comparison of forecasting performance on M3 public dataset between the base deepLSTM model trained with only A1 (6-month time-series data of 58,000 PG&E customers) andother main-stream forecasters trained with time series of the same id with test time series in M3dataset. The transfer learned model has competitive performance (15.8% SMAPE) relative to otherspecialized models.
Figure 4: (a) Model performance with and without weekday interactions. (b) Training set of timeseries, visualized in the embedding space. Each point represents a 28-day segment, colored by theday of the week of the last day. We evaluate the cell states of the two LSTM layers, where the firstlayer with dimension 128 is plotted on the left, and second layer with dimension 32 is plotted on theright. PCA is used to project into 2D space for visualization.
Figure 5: The presented Transfer Learned Model excels in compute power savings relative to theperformance hit.
Figure 6: Our online forecasting tool will use the transfer learning technique for time-series todemocrotize the time-series forecasting process provide high quality forecasts for everyone withdramatically low computational cost.
