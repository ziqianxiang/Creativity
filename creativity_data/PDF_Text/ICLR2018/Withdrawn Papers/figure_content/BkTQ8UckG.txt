Figure 1: An illustration of typical positive pairs and the nearest negative samples. Here assumesimilarity score is the negative distance. Filled circles show a positive pair (i, c), while emptycircles are negative samples for the query i. The dashed circles on the two sides are drawn at thesame radii. Notice that the hardest negative sample c0 is closer to i in (a). Assuming a zero margin,(b) has a higher loss with the SH loss compared to (a). The MH loss assigns a higher loss to (a).
Figure 2: Analysis of the behavior of the MH loss on the Flickr30K dataset training with RC. Fig. (a)compares the SH loss to the MH loss (Table 3, row 3.9 and row 3.11). Notice that, in the first 5epochs the SH loss achieves a better performance, however, from there-on the MH loss leads tomuch higher recall rates. Fig. (b) shows the effect of the negative set size on the R@1 performance.
Figure 3: Examples of test images and the top 1 retrieved captions for VSE0 and VSE++ (ResNet)-finetune. The value in brackets is the rank of the highest ranked ground-truth caption. GT is a samplefrom the ground-truth captions.
