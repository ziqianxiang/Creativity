Figure 1: A simple stacking task including an obstacle that must be avoided. The robot must decidewhich blocks to pick up and move, and which block to put them on, taking into account its workspaceand the obstacle. The right side shows how predictions change as the robot moves.
Figure 2: Overview of the predictor network. The input image and features are passed through aseries of convolutional blocks in the Encoder and a spatial softmax extracts the hidden state repre-sentation. The dense layers in the Transform block compute a new world state, which is the inputinto the Decoder network.
Figure 3: Prediction Results from Husky Simulation.
Figure 4: An example of a bad prediction. Here, the algorithm clearly attempts to predict what hap-pens when it picks up the red block, but the blue block prevented the gripper from properly closing.
Figure 5: Predictions made using different levels of dropout to train the decoder network. On thetop, the decoder was trained with a dropout rate of 0.125; on the bottom, the network was trainedwith dropout of 0.5.
Figure 6: Concatenating a vector of random noise to the image allows individual transforms to bettercapture uncertainty in the resulting image. This results in crisper predicted images (bottom).
