Figure 1: An example of the Discrete Wasserstein GAN architecture. The tensor dimensions indicatea batch of samples. In the architecture, n, m, k , l denote the number of samples in a batch, thenumber of variables, the number of classes, and the number of noise variables respectively.
Figure 2: Examples of valid and non-valid board configurations of the generalized and simplifiedtic-tac-toe game with multiple players.
Figure 3: The example of maximum player’s gainfor three different board configurations.
Figure 4: Comparison between Discrete-WGAN (DWGAN) and the standard WGAN: (a) percent-age of valid samples for a 3-by-3 board with 2 players, (b) average if maximum player’s gain for a5-by-5 board with 8 players. The best results for both networks over several learning rates (lr) andthe number of iterations (it) for each learning rate decay are presented.
Figure 5:	Examples of mode collapse in Discrete-WGAN (DWGAN) on: (a) 5-by-5 board with 8players, (b) 3-by-3 board with 2 players and the effect of adding a norm penalty.
Figure 6:	An example of Discrete WGAN with binary values vs. Standard WGAN with continuous valuesapplied to generate MNIST handwritten digits. Both models feature 1 hidden layer for both the generatorand critic within a fully-connected network. Modeling complex discrete distributions with GANs still requiresfuture refinements in optimization, training, and stability.
