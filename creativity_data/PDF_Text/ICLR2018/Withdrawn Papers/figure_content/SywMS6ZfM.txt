Figure 1: The top 15 dimensions in the distributional inclusion vector embedding (DIVE) of theword core trained by the co-occurrence statistics of context words. The index of dimensions issorted by the embedding values. The words in each row of the table are sorted by its embeddingvalue in the dimension.
Figure 2: An example of AL1 distance. If the word pair indeed has the hypernym relation, thecontext distribution of hyponym (dq) tends to be included in the context distribution of hypernym(dp) after proper scaling according to DIH. Thus, the context words only appear beside the hyponymcandidate (adq[c] - dp[c]) causes higher penalty.
