title,year,conference
 Neural machine translation by jointlylearning to align and translate,2015, In Proceedings of ICLR Conference Track
 Distributions in text,2009, In Anke Ludeling and Merja Kyto (eds
 Strong systematicity in sentence processing by simple recurrentnetworks,2009, In Proceedings of CogSci
 Symbolically speaking: a connectionist model of sentence production,2002, CognitiveScience
 Empirical evaluationof gated recurrent neural networks on sequence modeling,2014, In Proceedings of the NIPS DeepLearning and Representation Learning Workshop
 Language to logical form with neural attention,2016, In Proceedings ofACL
 Finding structure in time,1990, Cognitive Science
 The Compositionality Papers,2002, Oxford University Press
 Getting real about systematicity,2014, In Paco Calvo and John Symons (eds
 Neural semantic parsing over multiple knowledge-bases,2017, InProceedings of ACL (Volume 2: Short Papers)
 Long short-term memory,1997, Neural computation
 Data recombination for neural semantic parsing,2016, In Proceedings of ACL
	Inferring algorithmic patterns withstack-augmented recurrent nets,2015,	In Proceedings of	NIPS
 Building machines thatlearn and think like people,2016, Behavorial and Brain Sciences
 Rethinking Eliminative Connectionism,1998, Cognitive Psychology
 The Algebraic Mind: Integrating Connectionism and Cognitive Science,2003, MIT Press
 Are feedforward and recurrent networks systematic? analysis and implications fora connectionist cognitive architecture,1998, Connection Science
 Lack of combina-torial productivity in language processing with simple recurrent networks,2004, Connection Science
 A Learning Algorithm for Continually Running Fully Recur-rent Neural Networks,1989, Neural Computation
 Generalisation towards combinatorial productivity in languageacquisition by simple recurrent networks,2007, In Proceedings of KIMAS
