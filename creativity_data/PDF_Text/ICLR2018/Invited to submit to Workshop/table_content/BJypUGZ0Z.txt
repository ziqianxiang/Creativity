Table 1: Performance Prediction Model Comparison: We report the coefficient of determinationR2 * 100 for four standard methods. Each model is trained with 100 samples on 25% of the learningcurve. We find that ν-SVR works best on average, though not by a large margin.
Table 2: Ablation Study on Feature Sets: We report the R2 * 100 metric for different combinationsof features. Time-series features (TS) refers to the partially observed learning curves, architectureparameters (AP) refer to the number of layers and number of weights in a deep model, and hyperpa-rameters (HP) refer to the optimization parameters such as learning rate. All results are with ν-SVR.
Table 3: Experimental State Space For MetaQNN. For each layer type, we list the relevantparameters and the values each parameter is allowed to take. The networks are sampled beginningfrom the starting layer. Convolutional layers are allowed to transition to any other layer. Poolinglayers are allowed to transition to any layer other than pooling layers. Fully connected layers are onlyallowed to transition to fully connected or softmax layers. A convolutional or pooling layer may onlygo to a fully connected layer if the current image representation size is below 8. We use this spaceto both randomly sample and simulate the behavior of a MetaQNN run as well as directly run theMetaQNN with early stopping.
Table 4: Range of hyperparameter settings used for the Hyperband experiment (Section 4.1)B Hyperparameter selection in Performance Prediction ModelsWhen training performance prediction models we divided the data into training and validation andused 3-fold cross validation to select optimal hyperparameters. The models were then trained on fulltraining data using the best hyperparameters. For random forests we varied number of trees between10 and 800, and varied ratio of number of features from 0.1 to 0.5. For ν-SVR, we perform a randomsearch over 1000 hyperparameter configurations from the space C 〜LogUniform(10-5, 10), V 〜Uniform(0, 1), and Y 〜LogUniform(10-5, 10) (when using the RBF kernel). For Bayesian linearregression, we perform random search over the hyperparameters of the gamma prior distribution overboth noise and weights in the range [10-7, 10-5].
Table 5: Summary of weights for a linear kernel ν -SVR SRM trained on configurations fromMetaQNN (CIFAR-10).
Table 6: Summary of weights for a linear kernel ν -SVR SRM trained on configurations fromLSTMs (Penn Treebank).
Table 7: Summary of weights for a linear kernel ν -SVR SRM trained on configurations fromDeep Resnets (TinyImagenet).
Table 8: Accuracy when splitting test and train set based on median values for hyperparameters fordifferent datasets.
