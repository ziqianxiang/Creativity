Table 1: Some examples of predictions by the Deep Fusion and Cold Fusion models.
Table 2: Dev set perplexities for character RNN language models trained on different datasets onsource and target domain. Note that i) the model trained on source domain does poorly on targetdomain and vice-versa indicating that the two domains are very different, and ii) the best model onboth domains is a larger model trained on a superset of both corpuses. We use the model trained onthe full dataset (which contains the source and target datasets along with some additional text) forall of the LM integration experiments.
Table 3: Speech recognition results for the various models discussed in the paper. The CTC modelis based on Deep Speech 2 (Amodei et al., 2015) architecture.
Table 4: Results from models trained on the publicly available Librispeech data. All of the acousticmodels were trained on Librispeech training data and evaluated on librispeech test-clean, WSJ test-92 and our proprietary target domain data. Results from the Wav2Letter model (Collobert et al.
Table 5: Effect of decoder dimension on themodelâ€™s performance. The performance of cold fu-sion models degrades more slowly as the decodersize decreases. This corroborates the fact that thedecoder only needs to learn the task not label gen-eration. Its effective task capacity is much largerthan without fusion.
Table 6: Results for fine tuning the acoustic model (final row from Table 3) on subsets of the targettraining data. *The final row represents an attention model that was trained on all of the targetdomain data.
