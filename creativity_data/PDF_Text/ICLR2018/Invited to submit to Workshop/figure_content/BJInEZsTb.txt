Figure 1: Reconstructions of unseen shapes from the test split of the input data. The leftmost imageof each pair shows the ground truth shape, the rightmost the shape produced after encoding anddecoding using our class-specific AEs.
Figure 2: Interpolating between different point clouds, using our latent space representation.
Figure 3: The CD distance is less faithful than EMD to visual quality of synthetic results; in thiscase it favors r-GAN results, due to the presence of high-density areas in the synthesized point sets.
Figure 4: Training trends for the various generative models, in terms of coverage / fidelity to theground truth test dataset. On the right, the curve markers indicate epochs 1, 10, 100, 200, 400, 1000,1500, 2000, with larger symbols denoting higher epochs. See text for more details.
Figure 5: Synthetic point clouds generated by samples produced with l-GAN (top) and 32-componentGMM (bottom), both trained on the latent space of an AE using the EMD loss.
Figure 6: Synthetic point clouds generated by samples produced with l-WGANs trained in the latentspace of an AE-EMD trained on a multi-class dataset.
Figure 7: Limitations: The AEs might fail to reconstruct shapes of uncommon/overly detailedgeometry (left four images). The r-GAN may synthesize noisy/unrealistic results, cf. a car (right).
Figure 8: Editing parts in point clouds using vector arithmetic on the AE latent space. Left to right:tuning the appearance of cars towards the shape of convertibles, adding armrests to chairs, removinghandle from mug.
Figure 9: Interpolating between different point clouds, using our latent space representation. Notethe interpolation between structurally and topologically different shapes.
Figure 10: Shape Analogies using our learned representation. Shape B0 relates to B in the same waythat shape A0 relates to A.
Figure 11: Point clouds extracted from synthetic voxel-based results, after isosurfacing and pointsampling. Note the missing components and appearance of noise.
Figure 12: Histograms of MMD-distances: EMD (left) and Chamfer (right), for a purely point-cloud-based generative model (GMM with 32 full-covariance components, in orange) and a voxel-basedmodel (a latent-GAN trained on a voxel-based AE of resolution 643 , in blue). Note the larger MMDvalues for the voxel based approach, indicating results of lower fidelity.
Figure 13: Confusion matrix for the SVM-based classification of Section 4.1, for the Chamfer loss onModelNet40. The class pairs most confused by the classifier are dresser/nightstand, flower pot/plant.
Figure 14: Synthetic results produced by the r-GAN. From left to right: airplanes, car, chairs, sofas.
Figure 15: The optimal bottleneck size was fixed at 128 by observing the reconstruction loss of theAEs, shown here for various bottleneck sizes.
Figure 16: Generalization error of the various GAN models, at various training epochs. Generalizationis estimated using the JSD (left) and MMD-CD (right) metrics, which measure closeness of thesynthetic results to the training resp. test ground truth distributions. The plots show the measurementsof various GANs.
Figure 17: GMM model selection. GMMs with a varying number of Gaussians and covariance typeare trained on the latent space learned by and AE trained with EMD and a bottleneck of 128. Modelswith a full covariance matrix achieve significantly smaller JSD than models trained with diagonalcovariance. For those with full covariance, 30 or more clusters seem sufficient to achieve minimalJSD. On the right, the values in a typical covariance matrix of a Gaussian component are shown inpseudocolor - note the strong off-diagonal components.
Figure 18: The 32 centers of the GMM fitted to the latent codes, and decoded using the decoder ofthe AE-EMD.
Figure 19: Training trends in terms of the MMD-CD metric for the various GANs. Here, we samplea set of synthetic point-clouds for each model, of size 3x the size of the ground truth test dataset, andmeasure how well this synthetic dataset matches the ground truth in terms of MMD-CD. This plotcomplements Fig. 4 (left), where a different evaluation measure was used - note the similar behavior.
