Figure 1: A generator produces candidate architectures by iteratively sampling the next node (eitherrandomly or using an RL agent trained with REINFORCE). Full architectures are processed by aranking function and the most promising candidates are evaluated. The results from running themodel against a baseline experiment are then used to improve the generator and the ranking function.
Figure 2: An example of generating an architecture from ht up. Nodes which have an empty child (0)are filled left to right. A source node such as xt can be selected at any time if max depth is exceeded.
Figure 3: Visualization of the language modeling architecture search over time. Lower log perplexity(y-axis) is better.
Figure 4: Distribution of operators over time. Initially the generator primarily uses the core DSL(faded colors) but begins using the extended DSL as the architecture representation stabilizes.
Figure 5: Operator frequency of architectures that out-perform LSTM on Multi30k (colored likeFig. 4). For every architecture with a BLEU score higher than LSTM, we count if an operator occursin its architecture. While variables xt and ht-1 are inherent to every architecture, the generator alsopicked up on the Gate3 - Sigmoid combination for every one of its top architectures. Intriguingly,even operators that are less commonly used in the field such as sine curves and positional encodingoccur in a large number of architectures and thus seem to contribute to successful architectures.
Figure 6: Visualization of the hidden state over time for a variety of different generated architectures.
Figure 7: This figure shows the progress of the generator over time, highlighting the switches betweenexploitation (increasing running average up to plateau) and exploitation (trying out new strategiesand thus decreasing running average at first). Only valid architectures are shown. Higher reward isbetter with the x-axis showing progress in time.
