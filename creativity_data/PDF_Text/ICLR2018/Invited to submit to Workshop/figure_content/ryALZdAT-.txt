Figure 1: Test accuracy and number of samples vs Features’ L2-norm on CIFAR10 test set, and the modelis trained with softmax loss. The test accuracy increases monotonically with the feature norm. e.g., the testaccuracy reaches 100% for samples with feature norm exceeding 400.
Figure 2: Comparison of Softmax loss with Softmax loss + Feature incay(i.e., Reciprocal Norm Loss, we willdefine it in Section 3) on test set of CIFAR10. (a) Average L2 -norm of feature vectors vs Iterations, (b) Softmaxloss vs Iterations, (c) Top-1 accuracy vs iterations. Figure (d), (e) and (f) illustrate different approaches usingbinary classification as an example, where yellow points are samples of class1 and green points are samplesof class2. The black dashed line represents the decision boundary between the two classes. The two bluedashed lines represent the hyperplanes that pass the points with minimal distances to the decision boundary.
Figure 3: Distribution of features, norm over correctly-classified / mis-classified examples.
Figure 4: The original data distribution is on the left of the black dashed line and the data distribution updatedaccording to the Reciprocal Norm Loss is on the right. The numbers 1-6 represent that the points are ofincreasing feature norm. The black point represents the original point. The lengths of the green bidirectionalarrows represent the maximal distance in the direction of the weight vectors within all the points of one class.
Figure 5: Illustration in 2-dimensional space. α and β are the radiuses of the two circles, which represent thelower bound and upper bound of the feature norm.
Figure 6: Histograms of Average L2-norm and Accuracy on CIFAR10, (a) the feature norm is increased overall the classes. e.g., the feature norm increases from 230 to 282 for class airplane. (b) the test accuracy isboosted over all the classes. e.g., the test accuracy increases from 95.4 to 96.0 for class ship.
Figure 7: Histograms for Weights’ distribution of different layers from model trained on CIFAR10. Here weconsider five methods: (1) Weights’ distribution after Initialization. (2) Weights’ distribution after trained withSoftmax loss where the weight decay chooses μ = 0.005(ClassifiCation accuracy is 91.16%). (3) Weights'distribution after trained with Softmax loss where the weight decay chooses μ = 0.00005(ClaSSifiCation accu-racy is 89.35%). (4) Weights’ distribution after trained with Softmax loss where the weight decay choosesμ = 0.0005(classification accuracy is 91.40%). (5) Weights, distribution after trained with RN + Soft-max(classification accuracy is 92.16%). The magnitude of the weight parameters is only slightly influencedby the feature incay. Besides, Softmax μ = 0.005 represents larger weigth decay while Softmax μ = 0.00005represents smaller weight decay compared with the standard settings.(e.g., μ = 0.0005). The weights parame-ters are very sparse within Softmax μ = 0.005 while very dense within Softmax μ = 0.00005, which induceeither underfitting or overfitting.
Figure 8: (a) Accuracy versus iterations with different choices of λ value on the test set of CIFAR10. TheRN Softmax achieves 92.04% when λ = 0.1 (b) The training/testing sets’ L2 norm vs iterations with differentchoices of the λ value on CIFAR10. The RN Softmax with different λ all achieve larger L2-norm. (c) Thetraining/testing sets’ loss vs iterations with different choices of the λ value on CIFAR10. The RN Softmaxachieves notable smaller loss value 0.1432 than the Softmax with 0.1498. The training loss is very small forall the methods, but RN + Softmax has significantly smaller testing loss.(It is best viewed by zooming thefigure.) (d) Accuracy vs iterations with Softmax/RN Softmax/L-Softmax/RN L-Softmax on CIFAR100. BothRN Softmax and RN + L-Softmax achieve better performance compared with baseline, where the best methodis RN + L-Softmax.
