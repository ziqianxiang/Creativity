Figure 1: Formalizing a final task intothe minimization of a statistical taskloss. One starts from a useful but ill-defined final task, and devises criteriathat characterize good solutions. Suchcriteria are integrated into the statisti-cal task loss, which is the generaliza-tion error in structured prediction, andthe adversarial divergence in the GANframework. The hope is that minimiz-ing the statistical task loss effectivelysolves the final task.
Figure 2: Images generated by the network after training with the Sinkorn-Autodiff algorithm on MNISTdataset (left) and CIFAR-10 dataset (right). One can observe than although the network succeeds in learningMNIST, it is unable to produce convincing and diverse samples on the more complex CIFAR-10.
Figure 3: Top (a) and (b): divergences between MNIST and rotated MNIST. Bottom (c): divergencesbetween MNIST and noisy MNIST. NonparametricW was estimated with Sinkhorn’s algorithm. ParametricWplots for each model were rescaled, but using the same scaling factor across plots. When comparing differentmodels/divergences, only the shape (but not the scale) of the curve matters, while for a same model the scaleacross different transformations does matter.
Figure 4: Samples from Thin-8 training set (top row), WGAN-GP (middle row) and Convolutional VAE(bottom row) with 16 latent variables. Resolutions are 32 × 32 (left column), 128 × 128 (middle column),and 512 × 512 (right column). Note how the GAN samples are always crips and realistic across all resolutions,while the VAE samples tend to be blurry with gray pixel values in high-resolution. We can also observe someaveraging artifacts in the top-right 512x512 VAE sample, which looks like the average of two “8”. Moresamples can be found in Section C.2 of the Appendix.
Figure 5: Histograms of the sums of digitsgenerated by VAE (red), WGAN-GP (green)and Independent Baseline (gray). The latterdraws digits independently according to theirempirical marginal probabilities, which corre-sponds to fitting independent multinomial dis-tributions over digits using maximum likeli-hood. WGAN-GP beats largely both VAE andIndepedent Baseline as it gives a sharper distri-bution centered in the target sum 25.
Figure 6: Some Prototypes learned using linear (left), dense (middle), and CNN discriminator(right). We observe that with linear discriminator, only the mean of the training set is learned,while using the dense discriminator yields blurry prototypes. Only using the CNN discriminatoryields clear prototypes. All 100 prototypes can be found in Figure 7.
Figure 7: All 100 Prototypes learned using linear (top), dense (middle), and CNN discriminator(bottom). We observe that with linear discriminator, only the mean of the training set is learned,while using the dense discriminator yields blurry prototypes. Only the CNN discriminator yieldsclear prototypes.
Figure 8: VAE (top) and GAN (bottom) samples with 16 latent variables and 32 × 32 resolution.
Figure 9: VAE (top) and GAN (bottom) samples with 16 latent variables and 128 × 128 resolution.
Figure 10: VAE (top) and GAN (bottom) samples with 16 latent variables and 512 × 512 resolution.
Figure 11: VAE (left) and GAN (right) samples with 200 latent variables. Each row represents asample of a combination of 5 digits generated by the model.
