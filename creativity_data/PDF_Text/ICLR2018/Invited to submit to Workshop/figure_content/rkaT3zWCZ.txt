Figure 2: Overview of our proposed models. Bottom part demonstrates the gated-LSTM model fordiscrete action while the top part shows the gated-CNN model for continuous action. The “GatedFusion” module denotes the gated-attention architecture.
Figure 3: Overall performance of various models trained on (a) Esmall (20 houses) with differentinput signals: RGB Only, RGB+Depth and Mask+Depth; (b) Elarge (200 houses) with input signals:RGB+Depth and Mask+Depth. In each group, the bars from left to right correspond to gated-LSTM,concat-LSTM, gated-CNN, concat-CNN and random policy respectively.
Figure 4: Pixel-level Augmentation: Test performances of various models trained with differ-ent input signals, including RGB+Depth on Esmall, RGB With Domain Randomization on Esmall,Mask+Depth on Esmall, Mask+Depth on EIarge. In each group, the bars represent gated-LSTM,concat-LSTM, gated-CNN and concat-CNN from left to right.
Figure 5: Task-Level Augmentation: Test performances ofLSTM models trained with and withoutauxiliary targets on both Esmall and Elarge. In each group, the bars represent gated-LSTM + RGB,Concat-LSTM + RGB, gated-LSTM + Mask and Concat-LSTM + Mask from left to right.
