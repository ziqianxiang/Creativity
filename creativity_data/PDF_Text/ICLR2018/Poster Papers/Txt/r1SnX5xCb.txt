Published as a conference paper at ICLR 2018
Deep Sensing: Active Sensing using Multi-
directional Recurrent Neural Networks
Jinsung Yoon	William R. Zame
Department of Electrical and Computer Engineering	Department of Mathematics
University of California, Los Angeles	Department of Economics
Los Angeles, CA 90095, USA	University of California, Los Angeles
jsyoon0823@g.ucla.edu	Los Angeles, CA 90095, USA
zame@econ.ucla.edu
Mihaela van der Schaar
Department of Engineering Science, University of Oxford, Oxford, UK
Alan Turing Institute, London, UK
mihaela.vanderschaar@eng.ox.ac.uk
Ab stract
For every prediction we might wish to make, we must decide what to observe
(what source of information) and when to observe it. Because making observa-
tions is costly, this decision must trade off the value of information against the
cost of observation. Making observations (sensing) should be an active choice. To
solve the problem of active sensing we develop a novel deep learning architecture:
Deep Sensing. At training time, Deep Sensing learns how to issue predictions at
various cost-performance points. To do this, it creates a different presentation at
each of a variety of different performance levels, each associated with a particular
set of measurement rates (costs). This requires learning how to estimate the value
of real measurements vs. inferred measurements, which in turn requires learning
how to infer missing (unobserved) measurements. To infer missing measurements,
we develop a Multi-directional Recurrent Neural Network (M-RNN). An M-RNN
differs from a bi-directional RNN in that it sequentially operates across streams
in addition to within streams, and because the timing of inputs into the hidden
layers is both lagged and advanced. At runtime, the operator prescribes a perfor-
mance level ora cost constraint, and Deep Sensing determines what measurements
to take and what to infer from those measurements, and then issues predictions.
To demonstrate the power of our method, we apply it to two real-world medical
datasets with significantly improved performance.
1	Introduction
Making observations is costly. Hence, for every prediction we might wish to make, we must decide
What to observe - i.e., What source of information to ConsUlt/use - and when to observe it. This
(joint) decision involves a trade-off between the value of the information that will/might be obtained
from the observation and the cost of making the observation. There is little reason to make an
observation if the result of that observation can already be confidently estimated on the basis of
What is already knoWn or if the result Would be of little value in any case; it Would be much better to
conserve the resources to make a different observation at a different time. Thus making observations
(sensing) should be an active choice (Yu et al. (2009)). The problem of active sensing has many
applications, from healthcare (the example We use here to illustrate our method) to neuroscience to
robotics to Wireless communications.
The central point of our approach is that We need to estimate the value of information. This must be
learned at training time. We learn the estimated value for a specified set of measurements by first
predicting on the basis of the information We have, then deleting the specified set of measurements,
inferring What We have deleted on the basis of the data that remains, making a neW prediction on
1
Published as a conference paper at ICLR 2018
the basis of the inferred measurements and the remaining data, and comparing the two predictions.
(Part of our architecture is designed specifically for these tasks.)
To infer missing data, we develop a novel architecture called a Multi-directional Recurrent Neural
Network (M-RNN). Like a bi-directional RNN (Bi-RNN) (Graves & Schmidhuber (2005)), an M-
RNN operates forward and backward in each data stream - in the intra-stream directions. Unlike
a Bi-RNN, an M-RNN also operates across streams - in the inter-stream directions. And unlike a
Bi-RNN, the timing of inputs into the hidden layers of an M-RNN is lagged in the forward direction
and advanced in the backward direction. (To the best of our knowledge, our architecture is the first
that operates in this way). Our M-RNN executes both interpolation (intra-stream) and imputation
(inter-stream) to infer missing data.
Because we need to trade off performance against cost, our neural network must learn - at training
time - how to issue predictions at various cost-performance points. To do this, it creates multiple
presentations (neural network parameters) at various performance levels associated with different
measurement rates (costs). Each presentation is learned on the basis of a particular set of missing
data; these sets are constructed recursively and adaptively.
An important aspect of our solution to the active sensing problem is that there are differences be-
tween the operation at training time and runtime. At training time we can use data at the current
time to infer missing data at an earlier time; i.e. we can operate non-causally. We cannot do so -
and do not do so - at runtime. However, after a new sample is received at runtime, we can and do go
back to improve the previous inferences (interpolations and imputations) which will in turn improve
both current and future predictions.
To demonstrate the power of our method, we apply it to two real-world medical datasets. We show
that our method yields significantly greater predictive power (measured as the Area Under the ROC
Curve (AUC)) per unit cost in comparison to other state-of-the-art methods. Because our inference
methods are of interest in themselves, we compare the root mean squared error (RMSE) and cor-
responding AUC for our method to that of state-of-the-art imputation methods in statistics such as
white et al. (2011); Rehfeld et al. (2011); Garcia-Laencina et al. (2010), RNN-based imputation
methods such as Choi et al. (2015); Lipton et al. (2016); Che et al. (2016); Futoma et al. (2017),
and interpolation methods such as Kreindler & Lumsden (2012); Mondal & Percival (2010). In all
cases, we demonstrate large and significant improvements.
2	Related Works
Previous works related to Deep Sensing fall into four areas: Active sensing, missing value inference,
Bayesian optimization and RNN methods. (Active sensing is related to both active learning and to
reinforcement learning, but actually rather different from both of them; see the discussion below.)
Active sensing As discussed in the Introduction, the focus of active sensing (Yu et al. (2009); Alaa
& van der Schaar (2016)) and of screening policies (Ahuja et al. (2017)) is to determine what and
when to measure; this is an important question whenever acquiring measurements is costly. Yu et al.
(2009) studies the problem of active sensing using a Bayesian approach with Gaussian processes.
This work models the data streams as Gaussian processes, so if the number of data streams is D then
the number of parameters is of order D2 and estimation accuracy decreases dramatically as D grows.
Moreover, this work creates only a single presentation for the entire data set and hence does not ef-
fectively trade off predictive gain against measurement cost, and cannot deal with a setting in which
there are different costs to sample different variables. Alaa & van der Schaar (2016) addresses the
problem of active sensing for a single data stream. That work assumes a specific stochastic process
to learn the optimal time to sample the next measurement, given the characteristics of the specific
stochastic process. Because this work treats only a single data stream and imposes a particular
model of the data, this approach cannot be applied to a general data stream and is ineffective in
active sensing across multiple data streams. Ahuja et al. (2017) proposes a methodology for person-
alized screening in the medical domain but the procedure for learning presentations is independent
of the screening policy.
A particular approach to active sensing (submodular optimization; see Iwata et al. (2001); Schrijver
(2000) for example) minimizes a submodular objective function as a proxy for minimizing the true
”cost - information gain”. Deep Sensing does not use a submodular objective function - or any
2
Published as a conference paper at ICLR 2018
other particular objective function - as a proxy; instead, Deep Sensing uses a greedy algorithm to
find the individual measurements that yield a positive ”information gain - cost”, and uses the set of
all such individual measurements as the set of measurements that should be performed. (If this set
is empty, Deep Sensing moves on to the next possible measurement date, and so forth.) The details
are discussed in Section 3.
Missing value inference: There are two standard methods to deal with missing information in time-
series data streams: interpolation and imputation. Interpolation methods (Kreindler & Lumsden
(2012); Mondal & Percival (2010)) attempt to capture the temporal relationships within each data
stream but not the relationships across streams. Imputation methods (White et al. (2011); Rehfeld
et al. (2011); Garcla-Laencina et al. (2010)) attempt to capture the synchronous relationships across
data streams but not the temporal relationships within streams. (Most of this work assumes a specific
model of the data, rather than learning a presentation from the data, as Deep Sensing does.) We are
not aware of any previous work that attempts to capture both the relationships within stream and the
relationships across streams.
Bayesian optimization: The problem of costly measurements has been studied in other areas as
well. Bayesian optimization (Pelikan et al. (1999); Snoek et al. (2012)) uses a Gaussian process
regression (GPR) to approximate the loss function for a given optimization problem (Seo et al.
(2000)). This approximation is then used to sequentially evaluate the true loss function at points
where the expected decrease in loss is the greatest. When function evaluations are computationally
costly (e.g. for hyper-parameter optimization in complex problems), this approach is a way of
identifying good minima given constraints on time.
There are significant differences between Bayesian optimization and Deep Sensing. Firstly, in
Bayesian optimization, “cost” is usually taken to be computation time, and optimization is per-
formed subject to a cost constraint - a maximum number of permissible evaluations. In traditional
settings, this cost is essentially treated as constant, and not explicitly considered in selecting points
during the optimization procedure. Deep Sensing, on the other hand, trades off cost against (pre-
dictive) gain. Secondly, in the active sensing setting we consider, measurements can be taken only
forwards in time; in the setting of Bayesian optimization, no restrictions are placed on the loca-
tion of function evaluations. Active sensing thus captures the problems in the healthcare setting,
in which causal predictions are needed to inform the actions of practitioners in a timely fashion.
Finally, Bayesian optimization uses GPR to approximate loss functions, which places limitations on
the types of functions which it can mimic. Because neural networks are ”universal approximators”
(Hornik et al. (1989)), the RNNs used in Deep Sensing allow it to model a richer set of functions
(and give rise to more complicated and interesting dynamics).
RNN methods: RNNs have been used successfully for prediction on the basis of time-series data
with missing data and irregular sampling. The approach of Gingras & Bengio (1996) is to first
replace all the missing information with a mean value and use the feedback loop from the hidden
states to update the imputed value while learning the classification problem using a standard RNN.
Tresp & Briegel (1998) uses the Expectation-Maximization (EM) algorithm to impute the missing
values and uses the reconstructed data streams as inputs to a standard RNN for prediction. As
with standard imputation methods, the imputation depends only on the synchronous relationships
across data streams and not on the temporal relationships within streams. Parveen & Green (2002)
use a linear model to estimate missing values from the latest measurement and the hidden state of
each stream. As with standard interpolation methods, the estimate depends only on the temporal
relationships within each stream and not on the relationships across streams.
More recent works address both missing values and irregularly sampled time-series data streams
(Choi et al. (2015); Lipton et al. (2016); Che et al. (2016); Kim et al. (2017)). These papers use
the sampling times to capture the informative missingness and time interval information to deal with
irregular sampling. They do this by concatenating the measurements, sampling information and time
intervals and using the concatenation as the input of an RNN. These papers differ in the replacements
they use for missing values. Choi et al. (2015); Lipton et al. (2016); Kim et al. (2017) replace the
missing values with 0, mean values or latest measurements - all of which are independent of either
the intra-stream or inter-stream relationships or both. Therefore, those methods cannot be extended
to our active sensing algorithm. Che et al. (2016) imputes the missing values using only the latest
measurements, the mean value of each stream, and the time interval. It is not bi-directional and so
cannot use information available at a given time to update estimates of information that is missing at
3
Published as a conference paper at ICLR 2018
an earlier time. Futoma et al. (2017) assume a Gaussian Process in order to learn the latent variables
from irregularly sampled longitudinal datasets, and use the outputs of this Gaussian Process as the
inputs of an RNN to deal with the irregular sampling of the dataset.
Active learning and reinforcement learning Active learning (e.g. MacKay (1992); Seung et al.
(1992)) and reinforcement learning both have something in common with active sensing, in that
they all have to do with the (possibly costly) acquisition of information. However active learning
focuses on the acquisition of labels, while active sensing focuses on the (costly) acquisition of
measurements. And reinforcement learning focuses on actions (which directly affect the state),
while active sensing focuses on observations (which do not affect the state).
3	Background
3.1	Notation
The training set consists of N arrays of data. It is convenient to use the language of healthcare and
to speak of the array n as the information of patient n, so that there are N patients in the training
set. For each patient n, we have a multivariate time-series data stream of length T (the length T and
the other components may depend on the patient n but for the moment we suppress the dependence
on n) that consists of three components: measurements X , labels Y and time stamps S.
Because measurements are not necessarily made at regular intervals, we distinguish between time
stamps and actual times. The time stamp t = 1, 2, . . . simply indexes the sequence of times at which
measurements were taken; st is the actual time at which the measurements xt were taken and the
label yt was realized. For convenience we normalize so that s1 = 0; we assume actual times are
strictly increasing: st+1 > st for 0 < t ≤ T - 1.
The label yt represents the outcome realized for patient n at time stamp t (actual time st). Labels
may be discrete or continuous. In the former case we are considering a classification problem (e.g.
prediction of an event, such as discharge, clinical deterioration, death); in the latter case, we are
considering a regression problem (e.g. prediction of value or family of values). If we are interested
explicitly in the estimation of missing data for its own sake, then yt would represent the actual
observed data at time stamp t. Y is the vector of outcomes for this patient. We normalize so that
labels and predictions lie in [0, 1].
There are D streams of measurements; each measurement is a real number, but not all measurements
may be observed at each time stamp. Hence we view the set of possible measurements at time stamp
t as R* = R ∪{*}. We interpret Xd = * to mean that the stream d was not measured at time stamp
t; otherwise xtd ∈ R is the measurement of stream d at time stamp t. X is the array of measurements
of all streams at all time stamps for the patient under consideration.
It is convenient to introduce some notation to keep track of what is measured/not measured (ob-
served/not observed). For each time stamp t and stream d, write mtd = 0 if xtd = * (not measured)
and mtd = 1 if xtd ∈ R (measured). Let δtd be the actual amount of time that has elapsed since the
stream d was measured last. δtd can be defined recursively as follows:
δd =	st -	st-1	+ δtd-1	ift > 1,	mtd-1	= 0.
t	st -	st-1	ift > 1,	mtd-1	= 1
where δ1d = 0. Write δt for the vector of elapsed times at time stamp t and ∆ = {δ1, δ2, ..., δT }.
The information available for patient n is the triple (Xn , Yn , Sn) The entire training set therefore
is the sets of triples D = {(Xn, Yn, Sn)}nN=1. We use functional notation to identify information
about each patient, so xtd(n) is the measurement of stream d at time stamp t for patient n, etc.
3.2	Problem Formulation
At time stamp T, we have an array of measurements (which may or may not include the current label
yT); we must decide the next time sT+1 at which to take new measurements and what measurements
to conduct at that time. We measure the information provided by new samples by the effect on the
label yT+1, so we define the predictive loss from not sampling as the increase in uncertainty of our
4
Published as a conference paper at ICLR 2018
prediction of yT+1 and the predictive gain as the decrease in uncertainty of our prediction of yT+1.
Our approach is to find the first actual time τ at which the (estimated) predictive gain provided
by new samples exceeds the cost of sampling (keeping in mind that the cost of sampling may be
different for different streams), and to make the set of measurements at time τ that maximizes the
(estimated) predictive gain minus the cost.
Our objective is to find the set of measurements that maximize (net) rewards, which we take as
”information gain - cost”; this formulation is common; see Stachniss et al. (2005); Visser & Slamet
(2008) for instance. Somewhat more formally, our objective is to solve the maximization problem:
CT +ι = arg max Information Gain(CT +1) - Cost(CT +ι)
+	CT+1 ⊂M
where M is the set of possible measurements. (For convenience, we assume here that the set of
possible measurements is the same at every time but there would be no difficulty in allowing for the
set of possible measurements to be different at different times. Note that the term ”measurement”
could actually encompass a panel of tests that can be made at the same cost.)
Solving this maximization problem presents two immediate problems. The first problem is that
cost is well-defined and observable in our setting, but we need to decide the appropriate measure of
information gain. Information gain is often defined Stachniss et al. (2005); Follmer (1973) as the
decrease in entropy. However, to properly compute the entropy, we should know the distribution of
predictions. Instead, We use the decrease in uncertainty of prediction - measured as the difference
between the upper and the lower bounds of the prediction - as our measure of information gain. The
second problem is that maximizing over all possible subsets of measurements presents a potentially
intractable problem; instead, we take a greedy approach that yields an approximation to the true
optimum. We discuss both of these issues below.
The actual error in sampling stream d at sT+1 = τ is the difference between the estimated val-
ues and the actual measurement e，十］=|X，十1-XT+/. We don,t know the actual error so we
must construct an estimated error ^T+「Assuming that the distribution of errors is approximately
normal (an assumption that is justified in the Appendix), the confidence intervals in the measure-
ment of XT十1are of the form CIx = (XT+］一λeT +「XT+1+ λeT +J; e.g. λ = 1.96 for the
95% confidence level Rothenberg (1984); Davison & Hinkley (1997); Efron & Tibshirani (1986);
Bartlett (1953). Note that the confidence intervals depend only on the estimates and not the true
values (which are of course unknown). Each vector of estimates (XT +J of measurements, together
with previous data (measured and inferred), can be used to produce a prediction yT十1(see below).
The confidence intervals for the stream measurements translate immediately into lower and upper
confidence estimates yT［ ι,^,+uι (respectively) for the label prediction:
yT,+1 =	min yd(XT +1, XT, ST)	yT+ι = max	yd(XT +1, XT, ST)	(1)
+	xT+ι∈CIχ	+	xT+ι∈CIχ
where XT and ST are previous measurements and measurement times until time stamp T . The
(estimated) predictive gain in stream d is therefore the difference yT+1 - yd,+「Note that, because
the minimization and maximization problems for each feature are independent each other, equation
(1) can be solved by one-dimensional gradient descent.
Having defined gain, we now define (estimated) predictive gain minus cost as F (CT+1, XT, ST). At
each time sT+1, we seek to find the subset CT+1 ⊂ M of measurements that maximizes predictive
gain minus cost; i.e. we wish to solve:
CT +1 = arg max F(CT +1, XT, ST)	(2)
+	CT+1 ⊂M
However, if the number of possible measurements is large (which is typical), and there are comple-
mentarities among measurements, then solving the optimization problem (2) requires examining all
possible subsets of measurements - which is intractable. Instead, we follow a greedy procedure:
we identify all the individual streams d with the property that the value of measuring that stream
(by itself) exceeds the cost Cd of sampling from that stream; we then take CT +1 to be that set of
measurements. This is a tractable optimization problem that yields an approximation to the actual
optimal set of measurements. (We note again that every set of tests that can be carried out as a single
panel at the same cost can be considered as a single test.) Hence we will actually solve the problem:
CT +1 = arg maxA/ X (^T+↑1Xτ, ST) - yT,+1(XT, ST) - cd)	(3)
CT+1⊂Md∈CT+1
5
Published as a conference paper at ICLR 2018

3-EJ‰IB3H
tnsstd POOI笛
‘	'	'	'__I__I__I__I__l_b.	T
ɪ	I	ɪ	ɪ	I	I	I	I	I ^
t
Interpolation &
Imputation Block
jɪsrae∙πbeok
Active Sensing
3JΠSS3JJ POOI°-EJ-JB3H
Active Sensing Block
Estimate
without sensing
--- Time t --------------------------------A *------------ Time t+1
Figure 1: Deep Sensing Paradigm
It is important to note that CT +ι might be empty; i.e., there might be no measurements for which the
information gain exceeds the cost. Because of this, Deep Sensing answers both the question ”when
to sample?” as well as the question ”what to sample?” At each time T, Deep Sensing asks whether
there are any measurements to be made at time T +1 for which the benefit outweighs the cost. If the
answer is“yes"(i.e. CT +ι = 0) then Deep Sensing recommends that those measurements should be
made at time T + 1. If the answer is ”no” (i.e. CT +ι = 0) then Deep Sensing asks whether there are
any measurements to be made at time T + 2 for which the benefit outweighs the cost, and so forth.
Predicting Labels: Given data (measured and inferred) until any time stamp T0 , we generate a
prediction yτ，. The prediction rule can be learned from training data by any of various machine
learning algorithms; we use a standard GRU-based RNN (Chung et al. (2014)). (See Prediction in
Section 4.)
Estimating the Values of New Measurements: We view the problem of estimating new measure-
ments as a special case of estimating missing measurements, so we begin by discussing our novel
methods for this problem.
Fix data D through time stamp T. Assume that Xd = *. There are two standard methods to form
an estimate Xd: interpolation and imputation. Interpolation uses only the measurements xd of the
fixed data stream d for other time stamps t0 (perhaps both before and after t). Interpolation ignores
the correlation with other data streams. Imputation uses only the measurements Xtd0 at the fixed time
t for other data streams d0. Imputation ignores the correlation with other times.
In principle, we could try to form the estimate Xd by using all the information in D. However, this
would require learning a vast number of parameters and hence a vast number of training instances,
so this is impractical. Instead, we propose an efficient hierarchical learning framework using a novel
RNN architecture that allows us to capture the correlations both within streams and across streams.
The entire process of Deep Sensing is illustrated in Fig. 1.
4	Deep Sensing: Algorithm
In this section, we describe the training and runtime stages of the Deep Sensing algorithm. Fig. 2
shows block diagrams of the two stages.
4.1	Training Stage
The training stage of Fig. 2 shows the block diagram of the entire 5 blocks of the training stage. The
first four blocks train the Interpolation block (Φ), the Imputation block (Ψ), the Error Estimation
block (Γ) and the Prediction block (Ω). The Adaptive Sampling block creates multiple presentations
based on different sets of missing data. (The importance of this will be explained below.)
Loss function: The objective of the interpolation and imputation blocks is to minimize the error
that would be made in estimating missing measurements. Evidently, we cannot estimate the error of
6
Published as a conference paper at ICLR 2018
When / Which measurements should be sensed
Figure 2: Block diagram of Deep Sensing
a measurement that is truly missing in the dataset. Instead we fix a measurement that was actually
made, remove that measurement, form an estimate for the measurement using only the data set
D - xtd (i.e. the data set with xtd removed), and then compute the error between the estimate and the
actual measurement (that was deleted). If Xd is an actual measurement and Xd is the estimate formed
when Xd is removed then the loss can be defined as the mean squared error (MSE) l(Xd Xd)=
(Xd - xd)2. The loss for the entire dataset D is defined as
N
L({Xd MD = X
n=1
PTnI PdtI mdS) × (Xds) — XKn))I2
PTnI PD=I md(n)	.
Interpolation: The objective of the interpolation block is to construct an interpolation function Φ
that operates within a stream. To emphasize that the estimate for Xtd depends on the data with Xtd
removed, We abuse notation and write Xd = Φ(D - Xd). (Keep in mind that We are actually only
using the data from stream d, not the data from other streams.) We construct the estimation function
Φ using a bi-directional recurrent neural network (Bi-RNN) with a Gated Recurrent Unit (GRU).
However, unlike a conventional Bi-RNN (Graves & Schmidhuber (2005)), the timing of inputs into
the hidden layer is lagged in the forward direction and advanced in the backward direction: at time
t, inputs of forward hidden states come from t - 1 and inputs of backward hidden states come from
t + 1. Mathematically, we have:
Ot = W→ t + W/ + Co,
→t = (1 - →t) Θ→t-1 + →t Θ h t,	Tt = (1 - ^Lt) G)Tt+1 + ⅛Tt Θ E t,
-→zt = σ(Wzxt-1	+	U z h t-1 + V z δt-1	+ -→c z),	/-zt = σ(Wzxt+1	+ U z	h t+1	+	V	zδt+1	+	/-c z),
E t = φ(W→hXt-ι	+	→h(→t Θ →t-1) +	V hδt-1	+ -→c h),
E t = Φ(WWhXt+ι	+	Th(T t OTt+1) +	V hδt+1	+ T-c h),
r t = σ(Wrxt-1	+	Ur h t-1 + V r δt-1	+ c r),	r t = σ(Wrxt+1	+	Ur	h t+1	+	V	r δt+1	+	c r)
where G is element-wise multiplication, σ is the sigmoid function, φ is tanh function, and arrows
indicate forward/backward direction. The output Ot is the interpolated value Xt. In this interpolation
block, we are only using/capturing the temporal correlation within each stream. As a consequence,
the matrices U, V, W are block-diagonal. Hence the total number of parameters that must be learned
is on the order of the number D of streams. (Recall that in a standard Bi-RNN, the number of
parameters to be learned will be on the order of the square D2 of the number of streams.) This
7
Published as a conference paper at ICLR 2018
FC
Layers
Outputs
↑
FC
Layers
FC
Layers
UOQ-o&aUI V
Outputs
↑ ↑
Figure 3: Diagram of the neural networks for M-RNN
avoids overfitting and leads to significant performance improvements as compared to a standard
Bi-RNN. (See the Interpolation part of Fig. 3.)
Imputation: The objective of the imputation block is to construct an imputation function Ψ that
operates across streams. Again, We abuse notation and write Xd = Ψ(D - xd). KeeP in mind that
now we are using only data at time stamp t, not data from other time stamps. We construct the
function Ψ to be independent of the time stamp t; so we construct it using fully connected layers
(FC); see Imputation part of Fig 3:
ot= Wht+co,
ht = U xt + V Xt + Qmt + Ch
where Ot = Xt and the block-diagonal entries of U are zero because we do not use Xd to estimate
Xd. We use multiple deeply stacked FC layers using linear activation functions.
We jointly learn the functions Φ and Ψ using the stacked networks of Bi-RNN and FC layers.
Φ*, Ψ* = argmin L({ψ({xd, φ({xd, md,δd}t=i：T),md}d=rD),xd})
We refer to the entire structure as a Multi-directional Recurrent Neural Network (M-RNN); see Fig.3.
Prediction: Now that we have a procedure to reconstruct (interpolate/impute) missing data, we use
the reconstructed data to predict the labels. We accomplish this in the prediction block. Note that for
prediction, we use actual measurements when available and estimated measurements when actual
measurements are missing (not available). We also use as an input the mask vector (the indicator of
missingness), which provides to the network the information as to whether measurements are actual
or estimated. Once again, we construct the function to minimize the prediction error when we predict
an observed label. The loss function is defined as L({yt, yt}) = N PN=I Pt=1(ytTn)-yt(n)) The
prediction block optimizes the function:
Ω* = argmΩn L({yt,yt}) = argmΩn L({Ω({xd,Xd,δd}t=rτ,d=i:D),yt})
Note that we use the time intervals δtd as inputs to the prediction function in order to deal with the
fact that the data streams are irregularly sampled. This optimization problem is a standard problem
for timely prediction so we can use a standard GRU-based RNN (Chung et al. (2014)) to solve it.
8
Published as a conference paper at ICLR 2018
Error Estimation: At runtime, we have to decide when/what to sample in the active sensing block.
We make this decision on the basis of predictive gain which is determined by the difference between
our estimate of a measurement and what the actual value of the measurement would be; the actual
error ed = |xd - xd|. Of course, We do not know What this will be because We do not know What
the actual value of the measurement would be. Hence we need an estimate ^ of the actual error.
As before, we construct this estimate on the basis of the actual training data that we have. For
tractability, we posit that this estimate depends on the pattern of missing data and on time intervals
of the measurements but not on actual measurements. We use the same mean square loss function:
一=X P=
Hence we need to solve for the function
Γ* = argmΓn L({ed,ed}) = argmΓn L({Γ {{m}}d=i：D, {δd, md}t=rτ), ed}).
Because this involves both inter-stream and intra-stream variables, we again use our M-RNN struc-
ture. However, the inputs and outputs are different: for the interpolation and imputation blocks, the
inputs are the measurements {xτd}, sensing information {mτd} and the time intervals {δtd} and the
output is the estimated measurement Xd. For the error estimation block, the inputs are the sensing
information {mT} and the time intervals {δd} and the output is the estimation error ed.
It is useful to understand the relationship between the mask vector (which indicates missing mea-
surements) and the three different categories of missingness of measurements. (1) If the measure-
ments in the dataset are Missing Completely At Random (MCAR) then the mask vector is indepen-
dent of the observable features/measurements. (2) If the measurements in the dataset are Missing At
Random (MAR) then the correlation between the mask vector can be completely explained by the
observable features/measurements. (3) If the measurements in the dataset are Missing Not At Ran-
dom (MNAR) then the mask vector (and the values of the missing features) cannot be completely
explained by the observable features/measurements.
We have focused on the MCAR and MAR settings because the values of missing measurements are
estimated based on the observable features. However, our approach also has something useful to say
in the MNAR setting as well, because we use the mask vector - which depends on both observed
and unobserved variables and therefore incorporates “informative missingness” 一 as an input for
both estimation of missing values and for prediction. We demonstrate this point in Section 5.4.
Adaptive Sampling: As pointed out in Section 3, the decision of what/when to sense arises from
trading off the cost of measurement against the predictive gain of measurement. To this point, we
have constructed a procedure that achieves a certain performance - predictive gain -ata prescribed
cost. If we are willing to settle for a lower level of performance, we can do so at lower cost by
sampling less often. To know how much less often to sample we need to know how much informa-
tion would be lost if we sampled less often, which we can determine by carrying out the previous
procedure to produce different presentations, each based on a different pattern of missing data. For
each presentation we need to train the functions Φ, Ψ, Ω, Γ on the appropriate training set, which is
smaller than the original training set.
To construct these presentations, we begin with the original training set and remove additional mea-
surements. We should not do this at random, but rather using the informational criteria we use
to decide on active sensing at runtime: remove measurements whose predictive gain is below a
given threshold. We call this adaptive sampling. This will yield a decreasing sequence of data sets
D0 ⊃ D1 ⊃ ... ⊃ DR (where D0 = D, the original dataset).
The training procedures for the functions Φ, Ψ, Ω, Γ are as follows. Fix thresholds ui,...,ur > 0.
(In practice, these would be specified by the user.) We begin with D0 . For each measurement
xd(n) ∈ Do we use the current functions Φ = Φ0, Ψ = Ψ°, Ω = Ω°, Γ = Γ0 to compute the
predictive gain from that measurement in the current dataset. We sequentially delete all the measure-
ments whose predictive gain (”information gain - cost”) is below the prescribed threshold u1 ; this
yields a resampled data set D1. We now retrain on D1 to obtain new functions Φ1, Ψ1, Ω1, Γ1 and
repeat the same procedure: for each measurement xtd(n) ∈ D1, we compute the predictive gain from
9
Published as a conference paper at ICLR 2018
that measurement in the current dataset and sequentially delete those measurements whose predic-
tive gain is below threshold u2, etc. We repeat the above procedures continuing through whatever
set of thresholds are chosen. (It is important to keep in mind that, in the active sampling process, if
the actual dataset is not complete, we only consider measurements that are actually recorded in the
dataset. Thus we are never confronted with the need to compare an estimate/prediction against data
that is actually missing.)
Note that if we increase the threshold ur , we delete more data and retain fewer samples, so the
expenditure on sampling is smaller. However because we have trained on fewer samples, our pre-
dictions will be less accurate. This creates the cost-performance trade-off. Fig. 2 illustrates the
entire block diagram of Deep Sensing. Fig 5 in the Appendix details the operation of Deep Sensing
in runtime. Pseudo-codes of Deep Sensing for the training and runtime stages are shown in the
Appendix.
5	Experiments
In this section, we evaluate the performance of Deep Sensing using two real-world medical datasets.
Our experimental results present three sets of comparisons: active sensing, prediction, and missing
value inference. The first comparison shows the performance gain of Deep Sensing (in compari-
son with benchmarks) in sensing the critical measurements for prediction. The second and third
comparisons show the performance gain of the M-RNN algorithm in estimating missing values and
the effect on prediction accuracy. We describe all configurations of the various algorithms in the
Appendix.
5.1	Data Description
We conducted our experiments using two real-world medical datasets. The first of these datasets is
MIMIC-III (Johnson et al. (2016)) which records data on patients in intensive care units (ICU). We
used 22,803 patients who admitted were to ICU after 2008. We use the 20 vital signs which were
most frequently measured and for which missing rates are lowest (e.g. heart rate, respiratory rate)
and 20 lab tests (e.g. creatinine, chloride). Thus we have 40 physiological data streams in all. Vital
signs were taken approximately every 1 hour; lab tests were taken approximately every 24 hours.
For this dataset, the adverse event we predict is death. The second of these datasets, which we call
Wards, was assembled and described by Alaa et al. (2017b). (We are grateful to the authors for
sharing this dataset with us.) The Wards dataset records 37 physiological data streams (vital signs
and lab tests) on 6,094 patients who were hospitalized in a major medical center in 2013-2015. Vital
signs were taken approximately every 4 hours; lab tests were taken approximately every 24 hours.
For this dataset, the adverse event we predict is admission to ICU as a result of clinical deterioration.
5.2	Simulation Setup
We randomly divided the dataset into a mutually exclusive training set (80%) and testing set (20%).
We conducted 10 independent experiments with different combinations of training/testing sets; we
report the mean and variance of the performance in the 10 experiments. In our experiments we are
trying to predict which patients will experience an adverse event (death for the MIMIC-III dataset
and ICU admission for the Wards dataset) within 24 hours from the current time. At each time, we
assign the label 1 to patients who experienced the relevant adverse event within 24 hours; for other
patients we assigned the label 0. (Formally: yt = 1 for st > ST - 24 and yt = 0 for st ≤ ST - 24
where ST is the time that the adverse event occurred. Of course the true label yt is not observed at
time stamp st.)
Active sensing: To evaluate the performance of Deep Sensing, We graph predictive accuracy - area
under the ROC curve (AUC) - against cost. (The cost of each possible measurement is well-defined
in the medical domain. If all measurements Were equally costly, We could simply identify the cost
with the observation rate. Because some measurements are most costly than others, we simply
weight those measurements more heavily when expressing the cost in terms of the observation rate.
In this case, we take the cost for lab tests to be 5 times the cost for taking vital signs so weight lab
tests accordingly.) We compare the predictive accuracy of Deep Sensing with multiple presentations,
Deep Sensing with a single presentation (using only the original dataset to train), Deep Sensing with
10
Published as a conference paper at ICLR 2018
CoSt= Observation Rate (%)
Figure 4: Active Sensing: AUC vs Cost for Different Solutions with MIMIC-III dataset (Lab test
cost = 5× Vital sign cost)
random sampling, and two benchmarks based on the method of Che et al. (2016) for prediction with
missing data (sampling either using the method of Deep Sensing or randomly).
Prediction: We also evaluate prediction given only the available observations. The prediction we
consider is the adverse event (death or clinical deterioration); we use AUC as the performance met-
ric. We compare the performance of Deep Sensing with four state-of-the-art RNN timely-prediction
models and a GRU-based RNN method using conventional estimation methods for interpolation
and imputation. To make the comparison fair, we use GRU-based RNNs for each benchmark. Deep
Sensing is compared with the benchmarks in two settings. In setting A, we sampled 60% of the
measurements; for Deep Sensing, we used the Deep Sensing algorithm, for the benchmarks, we
use random sampling. In setting B we sampled 60% of the measurements, using the Deep Sensing
algorithm everywhere.
Estimation of missing values: To evaluate the performance of the M-RNN algorithm (the combi-
nation of interpolation and imputation block) in estimating missing values, we compare with other
standard methods: interpolations (Spline and Cubic Kreindler & Lumsden (2012)), imputations
(MICE (White et al. (2011)), Kemel(Rehfeld et al. (2011)) and EM (GarcIa-Laencina et al. (2010))).
We randomly remove 30% of the observations and treat them as missing. We then estimate the miss-
ing observations values using our M-RNN algorithm and benchmarks. We use the root mean square
error (RMSE) between estimated values and actual observed values as the performance metric.
Runtime of Deep Sensing: Deep Sensing is computationally efficient. For instance, on the MIMIC-
III dataset (23,200 samples, 40 dimensions, 25 time stamps), Deep Sensing takes less than 1 hour on
a machine with i7-6900K CPU (3.2GHz x 16) and 64GB RAM. By comparison, the most common
imputation method, MICE (implemented in R packages) takes 11 hours on the same machine.
5.3	Simulation Results and Discussion
Active Sensing: As Fig. 4 illustrates, Deep Sensing predicts best for every specification of cost;
equivalently, Deep Sensing expends the least cost for every specified prediction accuracy. Fig. 4
also shows that the performance gains achieved by Deep Sensing come both from active sampling
and from better inference. As seen in Figure 4, if the observation rate were 100% (so there would be
no gain from active sensing), the AUC improvement would be limited. However, as the observation
rate decreases the AUC gain increases because Deep Sensing actively decides what to sample and
when to sample, thereby providing results that are much superior to random sampling.
Prediction: Tables 1 and 2 provide the mean, standard deviation, and performance gain (%) (in
terms of AUC) from Deep Sensing in comparison to the benchmarks for two real-world medical
datasets. Table 1 and 2 show that Deep Sensing provides significant gains of the prediction accuracy
for both datasets (around 30% in Setting A and 20% in Setting B for all the benchmarks). The
significant gains for prediction come from the combination of accurate missing value inference and
active sensing as seen in Figure 4.
11
Published as a conference paper at ICLR 2018
Table 1: AUC for Deep Sensing and Benchmarks with MIMIC-III dataset (See the text for descrip-
tions of Settings A, B). *: P-ValUe < 0.05
AUC (Mean ± Std (Gain %))		MIMIC-III (Setting A)	MIMIC-III (Setting B)
Proposed Model	Deep Sensing	0.8019 ± 0.0112 (-)	0.8019 ± 0.0112 (-)
RNN based	Choi etal. (2015)*	0.7112 ± 0.0134 (31.4 %)	0.7598 ± 0.0110(17.5 %)
	LiPton et al.(2016)*	0.7072 ± 0.0108 (32.3 %)	0.7551 ± 0.0115(19.1 %)
	Che etal. (2016)*	0.7133 ± 0.0111 (30.9 %)	0.7593 ± 0.0123 (17.7 %)
	FUtoma et al. (2017)*	0.7094 ± 0.0121 (31.8 %)	0.7579 ± 0.0129 (18.2 %)
InterPolation	SPline*	0.7045 ± 0.0137 (33.0 %)	0.7542 ± 0.0108 (19.4 %)
+ RNN	Cubic*	0.7012 ± 0.0129 (33.7 %)	0.7569 ± 0.0112(18.5 %)
ImPUtation	MICE*	0.7093 ± 0.0132 (31.9 %)	0.7571 ± 0.0121 (18.4 %)
+ RNN	Kernel*	0.7002 ± 0.0119 (33.9 %)	0.7534 ± 0.0139(19.7 %)
	EM*	0.7019 ± 0.0098 (33.5 %)	0.7531 ± 0.0107 (19.8 %)
Table 2: AUC for Deep Sensing and Benchmarks with Wards dataset (See the text for descriptions
of Settings A, B). *: P-valUe < 0.05
AUC (Mean ± Std (Gain %))		Wards (Setting A)	Wards (Setting B)
Proposed Model	Deep Sensing	0.8348 ± 0.0201(-)	0.8348 ± 0.0201 (-)
RNN based	Choi et al. (2015)*	0.7739 ± 0.0264 (26.9 %)	0.8028 ± 0.0184(16.2 %)
	LiPton et al. (2016)*	0.7893 ± 0.0237 (21.6 %)	0.8107 ± 0.0191 (12.7%)
	Che et al. (2016)*	0.7905 ± 0.0143 (21.1 %)	0.8159 ± 0.0160 (10.3%)
	FUtoma et al. (2017)*	0.7911 ± 0.0193 (20.9 %)	0.8177 ± 0.0147 (9.4 %)
InterPolation	SPline*	0.7829 ± 0.0085 (23.9 %)	0.8023 ± 0.0187 (16.4 %)
+ RNN	CUbic*	0.7712 ± 0.0084 (27.8 %)	0.7993 ± 0.0137 (17.7%)
ImPUtation	MICE*	0.7499 ± 0.0096 (33.9%)	0.7877 ± 0.0149 (22.2 %)
+ RNN	Kernel*	0.7397 ± 0.0155 (36.5 %)	0.7728 ± 0.0187 (27.3 %)
	EM*	0.7593 ± 0.0168 (31.4%)	0.7784 ± 0.0163 (25.5%)
Estimation of missing values: Table 3 shows the mean and standard deviation of the RMSE for
M-RNN and benchmarks for both the MIMIC-III and the Wards dataset. The RMSE of M-RNN is
less than half that of the best benchmark in MIMIC-III dataset and less than 70% that of the best
benchmark in Wards dataset. All the imProvements are statistically significant (P-valUe < 0.05).
Table 3: RMSE of Missing information for M-RNN and Benchmarks with MIMIC-III and Wards
datasets. *: P-valUe < 0.05
Datasets ∣	∣		I Interpolation				Imputation	
	I Metrics ∣	M-RNN	I Spline	Cubic	I MICE	Kernel	EM
MIMIC-III	I RMSE - Mean ∣	0.0137	I 0.0735*	0.0279*	I 0.0611*	0.0556*	0.0467*
	I RMSE-Std I	0.0013	I 0.0012	0.0013	I 0.0011	0.0011	0.0014
Wards	I RMSE - Mean ∣	0.0169	I 0.0314*	0.0211*	I 0.0554*	0.0627*	0.0761*
	I RMSE - Std I	0.0019	I 0.0011	0.0021	I 0.0013	0.0014	0.0017
5.4	Source of gains
OUr M-RNN architectUre consists of two comPonents: the interPolation block (with for-
ward/backward connection) and the imPUtation block). To Understand the soUrce of gains Provided
by the varioUs comPonents of oUr aPProach, we carry oUta series of exPeriments in which we restrict
12
Published as a conference paper at ICLR 2018
the operation of our architecture in various ways. In the first experiment, we restrict to interpolation
only (no imputation), in the second experiment, we restrict to imputation only (no interpolation), in
the third experiment we restrict to forward interpolation only (no backward interpolation), and in
the fourth experiment we replace the GRU based RNN with a standard RNN. Table 4 provides the
results of these experiments. As can be seen, both the interpolation and imputation blocks by them-
selves provide significant performance improvements. (Because the sampling frequencies are high
in both datasets, the performance gain of the interpolation block is higher than that of the imputation
block.) The backward connection also improves performance, but only marginally (approximately
10%). Finally, using the GRU-based RNN significantly improves performance by capturing long-
term dependencies in an efficient way.
As we have discussed above, and as is illustrated in Section 4, Deep Sensing can be applied if
data is missing completely at random (MCAR) or missing at random (MAR), but it can also be
applied if data is missing not at random (MNAR).1 To apply Deep Sensing in the MNAR setting,
we incorporate the mask vector (the indicator of the missingness) as an additional input to capture
”informative missingnes”. As can be seen in the last row in Table 4, doing so leads to a significant
improvement - approximately 30%.
Table 4: Source of gain analysis for M-RNN with MIMIC-III and Wards datasets. (Performance
metric: RMSE)___________________________________________________________________________
Benchmarks	I	MIMIC-III		Wards	
	I Mean ± Std ∣	Loss (%)	I Mean ± Std ∣	Loss (%) I
M-RNN	I 0.0137 ± 0.0013 I	(-)	I 0.0169 ± 0.0019 I	G) I
No Imputation	I 0.0188 ± 0.0011 I	27.1%	I 0.0201 ± 0.0016 I	15.9% I
No Interpolation	I 0.0285 ± 0.0018 ∣	51.9%	I 0.0278 ± 0.0024 ∣	39.2% I
No Backward Interpolation	I 0.0151 ± 0.0014 I	9.3%	I 0.0179 ± 0.0018 I	5.6% I
Standard RNN	I 0.0178 ± 0.0011 I	23.0%	I 0.0194 ± 0.0016 I	12.9% I
Without Mask Vector	I 0.0226 ± 0.0021 ∣	39.4%	I 0.0247 ± 0.0027 ∣	31.6% I
6	Conclusion
The problem of active sensing is a very important one but has not been thoroughly treated in the
literature. We present here a solution based on a novel deep learning architecture. As part of the
solution, we provide a new method for reconstructing missing data that exploits joint interpolation
within data streams and imputation across data streams. We demonstrate that Deep Sensing makes
large and statistically significant improvements in comparison with state-of-the-art benchmarks in
two real-world datasets.
Acknowledgments
This work was supported by the Office of Naval Research (ONR) and the NSF (Grant number:
ECCS1462245, ECCS1533983, and ECCS1407712).
1This setting is obviously important, but the literature dealing with it is small; see Alaa et al. (2017a).
13
Published as a conference paper at ICLR 2018
References
Kartik Ahuja, William R Zame, and Mihaela van der Schaar. Dpscreen: Dynamic personalized
screening. In Advances in Neural Information Processing Systems, 2017.
Ahmed M Alaa and Mihaela van der Schaar. Balancing suspense and surprise: Timely decision
making with endogenous information acquisition. In Advances in Neural Information Processing
Systems,pp. 2910-2918, 2016.
Ahmed M. Alaa, Scott Hu, and Mihaela van der Schaar. Learning from clinical judgments: Semi-
markov-modulated marked hawkes processes for risk prognosis. In Proceedings of the 34th In-
ternational Conference on Machine Learning, ICML 2017, pp. 60-69, 2017a.
Ahmed M Alaa, Jinsung Yoon, Scott Hu, and Mihaela van der Schaar. Personalized risk scoring for
critical care prognosis using mixtures of gaussian processes. IEEE Transactions on Biomedical
Engineering, 2017b.
Maurice S Bartlett. Approximate confidence intervals. ii. more than one unknown parameter.
Biometrika, 40(3/4):306-317, 1953.
Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and Yan Liu. Recurrent neu-
ral networks for multivariate time series with missing values. arXiv preprint arXiv:1606.01865,
2016.
Edward Choi, Mohammad Taha Bahadori, and Jimeng Sun. Doctor ai: Predicting clinical events via
recurrent neural networks. arXiv preprint arXiv:1511.05942, 2015.
Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation of
gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014.
Anthony Christopher Davison and David Victor Hinkley. Bootstrap methods and their application,
volume 1. Cambridge university press, 1997.
Bradley Efron and Robert Tibshirani. Bootstrap methods for standard errors, confidence intervals,
and other measures of statistical accuracy. Statistical science, pp. 54-75, 1986.
Hans Follmer. On entropy and information gain in random fields. Probability Theory and Related
Fields, 26(3):207-217, 1973.
Joseph Futoma, Sanjay Hariharan, Mark Sendak, Nathan Brajer, Meredith Clement, Armando
Bedoya, Cara O’Brien, and Katherine Heller. An improved multi-output gaussian process rnn
with real-time validation for early sepsis detection. arXiv preprint arXiv:1708.05894, 2017.
Pedro J Garcla-Laencina, Jose-Luis Sancho-Gomez, and AnIbal R Figueiras-Vidal. Pattern classifi-
cation with missing data: a review. Neural Computing and Applications, 19(2):263-282, 2010.
Francois Gingras and Y Bengio. Recurrent neural networks for missing or asynchronous data. In
Proc NIPS, volume 8, 1996.
Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural
networks. In Aistats, volume 9, pp. 249-256, 2010.
Alex Graves and Jurgen Schmidhuber. Framewise phoneme classification with bidirectional lstm
and other neural network architectures. Neural Networks, 18(5):602-610, 2005.
Kurt Hornik, Maxwell Stinchcombe, and Halbert White. Multilayer feedforward networks are uni-
versal approximators. Neural networks, 2(5):359-366, 1989.
Satoru Iwata, Lisa Fleischer, and Satoru Fujishige. A combinatorial strongly polynomial algorithm
for minimizing submodular functions. Journal of the ACM (JACM), 48(4):761-777, 2001.
Alistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad
Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii,
a freely accessible critical care database. Scientific data, 3, 2016.
14
Published as a conference paper at ICLR 2018
Han-Gyu Kim, Gil-Jin Jang, Ho-Jin Choi, Minho Kim, Young-Won Kim, and Jaehun Choi. Recur-
rent neural networks with missing information imputation for medical examination data predic-
tion. In Big Data and Smart Computing (BigComp), 2017 IEEE International Conference on, pp.
317-323.IEEE, 2017.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
David M Kreindler and Charles J Lumsden. The effects of the irregular sample and missing data in
time series analysis. Nonlinear Dynamical Systems Analysis for the Behavioral Sciences Using
Real Data, pp. 135, 2012.
Zachary C Lipton, David C Kale, and Randall Wetzel. Directly modeling missing data in sequences
with rnns: Improved classification of clinical time series. arXiv preprint arXiv:1606.04130, 2016.
David JC MacKay. Information-based objective functions for active data selection. Neural compu-
tation, 4(4):590-604,1992.
Debashis Mondal and Donald B Percival. Wavelet variance analysis for gappy time series. Annals
of the Institute of Statistical Mathematics, 62(5):943-966, 2010.
Shahla Parveen and Phil Green. Speech recognition with missing data using recurrent neural nets.
In Advances in Neural Information Processing Systems, pp. 1189-1195, 2002.
Martin Pelikan, David E Goldberg, and Erick Cantu-Paz. Boa: The bayesian optimization algorithm.
In Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation-Volume
1, pp. 525-532. Morgan Kaufmann Publishers Inc., 1999.
Kira Rehfeld, Norbert Marwan, Jobst Heitzig, and Jurgen Kurths. Comparison of correlation anal-
ysis techniques for irregularly sampled time series. Nonlinear Processes in Geophysics, 18(3):
389-404, 2011.
Thomas J Rothenberg. Approximate normality of generalized least squares estimates. Economet-
rica: Journal of the Econometric Society, pp. 811-825, 1984.
Alexander Schrijver. A combinatorial algorithm minimizing submodular functions in strongly poly-
nomial time. Journal of Combinatorial Theory, Series B, 80(2):346-355, 2000.
Sambu Seo, Marko Wallat, Thore Graepel, and Klaus Obermayer. Gaussian process regression: Ac-
tive data selection and test point rejection. In Neural Networks, 2000. IJCNN 2000, Proceedings
of the IEEE-INNS-ENNS International Joint Conference on, volume 3, pp. 241-246. IEEE, 2000.
H Sebastian Seung, Manfred Opper, and Haim Sompolinsky. Query by committee. In Proceedings
of the fifth annual workshop on Computational learning theory, pp. 287-294. ACM, 1992.
Jasper Snoek, Hugo Larochelle, and Ryan P Adams. Practical bayesian optimization of machine
learning algorithms. In Advances in neural information processing systems, pp. 2951-2959, 2012.
Cyrill Stachniss, Giorgio Grisetti, and Wolfram Burgard. Information gain-based exploration using
rao-blackwellized particle filters. In Robotics: Science and Systems, volume 2, pp. 65-72, 2005.
Volker Tresp and Thomas Briegel. A solution for missing data in recurrent neural networks with an
application to blood glucose prediction. Advances in Neural Information Processing Systems, pp.
971-977, 1998.
Arnoud Visser and Bayu A Slamet. Balancing the information gain against the movement cost for
multi-robot frontier exploration. In European Robotics Symposium 2008, pp. 43-52. Springer,
2008.
Ian R White, Patrick Royston, and Angela M Wood. Multiple imputation using chained equations:
issues and guidance for practice. Statistics in medicine, 30(4):377-399, 2011.
Shipeng Yu, Balaji Krishnapuram, Romer Rosales, and R. Bharat Rao. Active sensing. In Proceed-
ings of the Twelth International Conference on Artificial Intelligence and Statistics, pp. 639-646,
2009.
15
Published as a conference paper at ICLR 2018
Appendix
Justification of the approximate confidence interval in Section 3
Define X = X + n where X is a measurement and X is the estimated measurement. For the moment,
assume that n is Gaussian noise and that We can interpret the error e = |X - x| as the estimated
standard deviation of the Gaussian noise n. Then, (X - λe,X + λe) is the proper confidence interval
for x in the formal statistical sense.
The assumption of Gaussian noise is quite standard and probably needs no further comment. The
interpretation of the error (|X - x|) as the estimated standard deviation of Gaussian noise is not
standard but can be justified in the following way. Let us assume that our measurement X comes
from a Gaussian distribution N(μ, σ2). If our estimate X is the expected value of X (i.e. μ), then
we will have X = X + n, where X is the observed measurement from a Gaussian distribution,
X is the expected value of X and n is normal (Gaussian) distribution N(0, σ2). In that case, the
expected value of e = |X - x| = |n| is just the standard deviation of Gaussian noise, which is
,E[n2] = σ. Hence, we need two assumptions: (1) our estimate X is the expected value of χ; (2)
the observed measurement can be approximated as the sum of the expectation of X and Gaussian
noise (approximate normality [Rothenberg (1984); Davison & Hinkley (1997); Efron & Tibshirani
(1986); Bartlett (1953)]).
More formally, assume that the measurement X is sampled from an unknown distribution Pθ ; i.e.
χ ~ Pθ . If Pθ is itself normal (Gaussian), then it follows that.
x ~ Pθ ⇔ x = E[x] + n
where n 〜N(0, σ2). (This uses the observation that the expectation of the normal distribution is
the mean). In general, we cannot assume that Pθ is normal, but it will be enough if it is approxi-
mately normal, which is a common assumption in the literature (see [Rothenberg (1984); Davison
& Hinkley (1997); Efron & Tibshirani (1986); Bartlett (1953)] for instance.) In that case, following
the literature we can obtain
X ' E[X] + n
where n 〜N(0, E[(x - E[x])2]). From this we obtain that X = E[x]. (In practice, we use X as
the sample mean of X which converges to E[x]). In that case the distribution of the error e = |Xx|
coincides with the distribution of the absolute value of samples generated by the normally distributed
noise n:
E[e] = E[|X - x|] = E[√(X - x)2] = E[√n2] = E[√(x - E[x])2]).
Thus, estimating e can be interpreted as estimating the standard deviation of the measurements X.
16
Published as a conference paper at ICLR 2018
THE OPERATION OF DEEP SENSING IN RUNTIME
Figure 5: The operation of Deep Sensing in runtime
17
Published as a conference paper at ICLR 2018
Pseudo-codes of Deep Sensing
Algorithm 1 Deep Sensing - Training Stage
Input: Dataset D = {(Xn, Yn, Sn)}nN=1, multiple representations U = {u1 , u2, ..., uR}
For each representation ur ∈ U
Initialization:
Φι, Ψι, Ωι, Γι J Xavier Initialization, Di JD
Φr J— Φr-1, Ψr J— Ψr-1, Ωr J— Ωr-1, Γr J— Γr-1 and Dr J— Dr -1
Interpolation and Imputation: Using M-RNN and FC layers
Φr,亚；=argminφ,ψ L({φ({xT, ψ({xd,mdr,δd}τ =1：T),md}d=i：D),xT})
Error Estimation: Using M-RNN and FC layers
Γr = argminr L({r({mT}d=i：D, {δτd,mτd}τ=1:T , eτd})
Prediction: Using RNN with GRU
Ωr = argminΩ L({Ω({xd,xT,δd}τ =i：T,d=i：D),%})
Adaptive Sampling:
For all τ , s, n
If yU,l (n) — ^d,l (n) < Ur
Dr J Dr - xτs (n)
End If
End While
End For
Output: Four trained functions {Φr, Ψr, Ωr,「丁}丁=上R =0
Algorithm 2 Deep Sensing - Testing Stage
Input: cost C = {c1,c2,…,CD}, corresponding trained functions Φr, Ψr, Ωr, Γr, and λ
Fort ∈ {1, 2, ...,T}
Interpolation: Xd = Φ ({xT, md, δd}τ =i：t—i)
Imputation: Xd = Ψ ({xd, Xd, md}d=i：D^
Error Estimation: ed = γ ({mτ}d=1:D, {δd, mT}τ=1:t)
Compute the confidence interval of imputed value: CIx = (Xd — λed Xd + λed)
Prediction Interval: Compute the confidence interval of predictions: CIy = (yd,l,yd,u)
yd,l = min^d∈cl Ω({xd,xT,δd}τ =i：t,d=i：D)
yd,u =max^d∈ciχ Ω({xd,xT,δd}τ =i：t,d=i：D)
Active Sensing: Decision of sensing
ad = i(yd,u - yd,l > cd)
Prediction: yt = Ω ({xT,Xd, δd}τ=i：t,d=i：D)
End For
Output: Active sensing {ad}t=i：T,d=i：D, Prediction {yt}t=i：T =0
18
Published as a conference paper at ICLR 2018
Configurations of the Experiments
We used ”interp1” package in MATLAB for interpolation algorithms, and ”mice” and ”amelia”
packages in R for imputation algorithms. Table 5 illustrates the details of the prediction algorithm.
Table 5: Configurations of the Experiments
Blocks	Categories	Configurations
Interpolation	Model Initialization Optimization Batch size and iterations Depth Constraints	Modified Bi-RNN with GRU Xavier Initialization (Glorot & Bengio (2010)) Adam* Optimization (Kingma & Ba (2014)) (learning rate = 0.05) Batch size = 100, Iterations = 1000 5 The matrix parameters are block-diagonals
Imputation	Model Initialization Optimization Batch size and iterations Depth Constraints	Fully Connected Layers Xavier Initialization Adam Optimization (learning rate = 0.05) Batch size = 100, Iterations = 1000 10 (Activate function: Linear) The block-diagonal part of the matrix is zero.
Error Estimation	Model Initialization Optimization Batch size and iterations Depth Constraints	Multi-directional RNN (M-RNN) with GRU Xavier Initialization Adam Optimization (learning rate = 0.05) Batch size = 100, Iterations = 1000 5 for Bi-RNN, 10 for FC with linear activation function Block-diagonal matrix parameters for Bi-RNN
Prediction	Model Initialization Optimization Batch size and iterations Depth Constraints	RNN with GRU Xavier Initialization Adam Optimization (learning rate = 0.05) Batch size = 100, Iterations = 1000 10 None
Adam*: Adaptive Moment Estimation
19