Table 1: Perplexity on Penn Treebank word level language modeling task.
Table 2: Perplexity on WikiText-2 word level language modeling task.
Table 3: BLEU scores for the Microsoft COCO image captioning task. Using fraternal dropout isthe only difference between models. The rest of hyper-parameters are the same.
Table 4: Ablation study: Accuracy on altered (semi-supervised) CIFAR-10 dataset for ResNet-56based models. We find that our algorithm performs at par with Î -model. When unlabeled datais not used traditional dropout hurts performance while fraternal dropout provides slightly betterresults. It means that our methods may be beneficial when we lack data and have to use additionalregularizing methods.
Table 5: Ablation study: Importance of fine-tuning for AWD-LSTM 3-layer model. Perplexity forthe Penn Treebank and WikiText-2 language modeling tasks.
Table 6: Ablation study: Candidate hyper-parameters possible used in the grid search for comparingfraternal dropout and expectation linear dropout. U(a, b) is the uniform distribution on the interval[a, b]. For finite sets, each value is drawn with equal probability.
Table 7: Ablation study: Fraternal dropout and expectation linear dropout comparison. Perplex-ity on the Penn Treebank validation dateset. Fraternal dropout is more robust to different hyper-parameters choice as twice as much runs finished performing better than the baseline model (60.7).
Table 8: Appendix: Monte Carlo evaluation. Perplexity on Penn Treebank word level languagemodeling task using Monte Carlo sampling, fraternal dropout or average mask.
