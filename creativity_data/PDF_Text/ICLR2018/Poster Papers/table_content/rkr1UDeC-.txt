Table 1: Prediction ChurnModel	Validation Log Loss Mean Absolute Difference6Between RetrainsDNN	0.4480	±0.001	0.029 ±0.001Ensemble of TWo DNNs	0.4461	土	0.0002	0.022 土 0.002Two-way codistilled DNN	0.4458	±	0.002	0.019 ± 0.0023.5 Reducing prediction churn with codistillationUnlike linear models with convex loss functions, two neural networks with the same architecturethat are trained on the same data can achieve similar validation and test performance while makingvery different predictions, and mistakes. On large datasets with a stable training pipeline aggregatemetrics can be relatively consistent, but minor changes to the model architecture or even simpleretrains can cause comparatively dramatic changes in the predictions made by the network. Thenetwork will in general get different examples correct and the differences might be especially severeon atypical examples with rare features. The weights learned by stochastic gradient descent inthe non-convex setting will depend on the initialization, data presentation order, and the generalvicissitudes of the infrastructure, especially when parallelization is involved. It is not practical tocontrol all these nuisance variables and, even if it was, we would still see different solutions aftermaking slight changes to the input representation or model architecture. We will refer to the generalreproducibility problem where retraining a neural network after a minor (or even no) change causesa change to the predictions as prediction churn. Prediction churn can be a serious problem when
