Table 1: Comparison of the learned architectures and performance of the baselines from Louizoset al. (2017) and the proposed L0 minimization under L0hc. We show the amount of neurons leftafter pruning with the estimator in Eq. 13 along with the error in the test set after 200 epochs. Ndenotes the number of training datapoints.
Table 2: Results on the benchmark classification tasks of CIFAR 10 and CIFAR 100. All of thebaseline results are taken from Zagoruyko & Komodakis (2016). For the L0 regularized WRN wereport the median of the error on the test set after 200 epochs over 5 runs.
