Table 1: Performance on 2D grid world with simple obstacles: All models are tested on mapsgenerated via the same random process, and were not present in the training set. Episodes over 40(for a 16 × 16 wide map), 60 (for 32 × 32) and 80 (for 64 × 64) time steps were terminated andcounted as a failure. Episodes where the agent collided with an obstacle were also counted as failures.
Table 2: Performance on grid world with local minima: All models are trained on tunnels oflength 20 units. The success percentages represent the number of times the robot reaches the goalposition in the test set after exploring the tunnel all the way to the end. Maximum generalizationlength is the length of the longest tunnel that the robot is able to successfully navigate after beingtrained on tunnels of length 20 units.
Table 3: Performance on General Graph Search. Test error is not applicable for the reinforcementlearning models A3C and DQN(a) Robot Environment	(b) Laser Scan(c) Top Down View of EnvironmentFigure 8: Navigation in a 3D environment on a continuous control robot. a) The robot is spawnedin a 3d simulated environment. b) Only a small portion of the entire map is visible at any given pointto the robot c) The green line denotes ground truth and red line indicates the output of MACN.
Table 4: Performance on robot worldWe observe in Table 4 that the proposed architectureis able to find its way to the goal a large numberof times and its trajectory is close to the groundtruth. This task is more complex than the grid worldnavigation due to the addition of orientation. Thelack of explicit planning in the CNN + Memoryarchitecture hampers its ability to get to the goalin this task. In addition to this, as observed beforedeep reinforcement learning is unable to convergeto the goal. We also report some additional results in Fig 9. In Fig 9a we show that MACN convergesfaster to the goal than other baselines.
Table 5: Comparison to A*. G corresponds to grid world with simple obstacles with the size of theworld specified inside the parenthesis. L corresponds to grid worlds with local minima/tunnels withthe length of the tunnel specified inside the parenthesis. All ratios are computed during testing. Forthe worlds with tunnels, the network is trained on tunnels of length 20 units.
