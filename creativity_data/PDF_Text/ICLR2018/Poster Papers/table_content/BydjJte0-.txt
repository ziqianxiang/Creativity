Table 2: Comparison of metamodel methods. See table 1 for the full names of attributes. 100queries are used for every method below, except for kennen-i which uses a single query. The“Output” column shows the output representation: “prob” (vector of probabilities for each digitclass), “ranking” (a sorted list of digits according to their likelihood), “top-1” (most likely digit), or“bottom-1” (least likely digit).
Table 3: Normalised accuracies (see text) ofkennen-o and kennen-io on R and E sPlits.
Table 4: Transferability of ad-versarial examples within andacross families. We reportmisclassification rates.
Table 5: Black-box ImageNet classifier misclassi-fication rates (MC) for different approaches.
Table 6: Distribution of attributes in MNIST-NETS, and attribute-wise classification performance(on MNIST validation set). Observe that the attributes are evenly distributed and the correspondingclassification accuracies also do not correlate much with the attributes. We thus make sure that theclassification accuracy alone cannot be a strong cue for predicting attributes.
Table 7: Details of ImageNet classifiers. We describe each family Squeezenet, VGG, VGG-BatchNorm, ResNet, and DenseNet verbally, and show key model statistics for each member inthe family. We observe intra-family diversity (e.g. R) and inter-family similarity (e.g. between Vand B) in terms of the top-5 validation error and the number of trainable parameters.
