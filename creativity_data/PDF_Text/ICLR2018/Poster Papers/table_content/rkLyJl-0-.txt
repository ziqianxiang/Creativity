Table 1: Summary of Hyperparameters.
Table 2: Final Top-1 Validation Error	Baseline	Neumann	ImprovementInception-V3	21.7%	20.8 %	0.91%Resnet-50	23.9%	23.0 %	0.94 %Resnet-101	22.6%	21.7%	0.86 %Inception-Resnet-V2	20.3 %	19.5 %	0.84 %test error for Inception V3 as compared to the baseline RMSProp. The salient characteristics areSSo-IU0+j8≡sseω」0」」山 u°:IeP= e> I，doj.
Table 3: Scaling Performance of our Optimizer on Resnet-50Batch Size	# workers	Top-1 Validation Error	# Epochs	Param. updates1600	50	230%	226	181K4000	125	23.0 %	230	73.6K8000	250	23.1 %	258	41.3K16000	500	23.5 %	210	16.8K32000	1000	24.0 %	237	9.5K4.3	Effect of RegularizationWe studied the effect of regularization by performing an ablation experiment (setting α and β to 0).
Table 4: Effect of regularization - Resnet-50, batch size 4000Method		Top-1 ErrorBaseline	-24.3%-Neumann (without regularization)	23.5%Neumann (with regularization)	23.0%9Published as a conference paper at ICLR 20184.4	Negative result for sequence-to-sequence RNNsWe also tried our algorithm on a large-scale sequence-to-sequence speech-synthesis model calledTacotron (Wang et al. (2017b)), where we were unable to obtain any speedup or quality improve-ments. Training this model requires aggressive gradient clipping; we suspect the Neumann optimizerresponds poorly to this, as our approximation of the Hessian in Equation (7) breaks down.
