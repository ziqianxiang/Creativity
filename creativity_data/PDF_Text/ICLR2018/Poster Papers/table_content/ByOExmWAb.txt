Table 1: Conditional samples from PTB for both MaskGAN and MaskMLE models.
Table 2: Language model (unconditional) sample from PTB for MaskGAN.
Table 3: Conditional samples from IMDB for both MaskGAN and MaskMLE models.
Table 4: Language model (unconditional) sample from IMDB for MaskGAN.
Table 5: The perplexity is calculated using a pre-trained language model that is equivalent to thedecoder (in terms of architecture and size) used in the MaskMLE and MaskGAN models. Thislanguage model was used to initialize both models.
Table 6: Diversity statistics within 1000 unconditional samples of PTB news snippets (20 wordseach).
Table 7: A Mechanical Turk blind heads-up evaluation between pairs of models trained on IMDBreviews. 100 reviews (each 40 words long) from each model are unconditionally sampled andrandomized. Raters are asked which sample is preferred between each pair. 300 ratings were obtainedfor each model pair comparison.
Table 8: A Mechanical Turk blind heads-up evaluation between pairs of models trained on PTB. 100news snippets (each 20 words long) from each model are unconditionally sampled and randomized.
