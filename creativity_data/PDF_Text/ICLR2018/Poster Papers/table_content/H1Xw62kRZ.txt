Table 1: RL_beam optimization of program correctness results in consistent improvements in top-1generalization accuracy over supervised learning MLE, even though the exact match of recoveringthe reference program drops. The improved objective function results in further improvements.
Table 2: Top-k accuracies: MLEshows greater relative accuracy increasesas k increases than RL. Methods employ-ing beam search and diversity objectivesreduce this accuracy gap by encouragingdiversity in the beam of partial programs.
Table 3: Grammar prunes the space of possible pro-grams: On the full dataset, handwritten syntax check-ing MLE_handwritten improves accuracy over no gram-mar MLE, although MLE_large shows that simplyadding more parameters results in even greater gains.
Table 4: Importance of Syntax(a) Manual (b) Learned (c) DiffFigure 3: Syntax Comparisongrams for large training datasets. Our second contribution incorporates syntax checking as anadditional conditioning mechanism for pruning the space of programs during decoding. We showthat incorporating syntax leads to significant improvements with limited training datasets.
Table 5: Representation of the gridGrid Embedding	Input Grid	Output Grid	Conv2D, kernel size = 3, padding = 1,16 → 32 	ReLU		Conv2D, kernel size = 3, padding = 1, 16 -> 32 	ReLU	Residual Block 1	Conv2D, kernel size = 3, padding 1, 64 → 64 ReLU Conv2D, kernel size = 3, padding 1, 64 → 64 ReLU Conv2D, kernel size = 3, padding 1, 64 → 64 	ReLU		Residual Block 1	Conv2D, kernel size = 3, padding 1, 64 → 64 ReLU Conv2D, kernel size = 3, padding 1, 64 → 64 ReLU Conv2D, kernel size = 3, padding 1, 64 → 64 ReLU	Fully Connected	Linear, 20736 → 512	Table 6: Encoding of the Input/Output Pairsfor the Reinforce method and a beam size of 64 for methods based on the beam search. The value ofC used for the methods computing a loss on bags of programs was 5.
Table 6: Encoding of the Input/Output Pairsfor the Reinforce method and a beam size of 64 for methods based on the beam search. The value ofC used for the methods computing a loss on bags of programs was 5.
