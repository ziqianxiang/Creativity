Table 1: BLEU scores on official test sets (newstest2014 for WMT En-De and newstest2016for WMT En-Ro) or the development set for IWSLT. NAT models without NPD use argmax decod-ing. Latency is computed as the time to decode a single sentence without minibatching, averagedover the whole test set; decoding is implemented in PyTorch on a SinCIe NVTDIA TesIa piooPreparation for knowledge distillation We firsttrain all teacher models using maximum likelihood,then freeze their parameters. To avoid the redun-dancy of running fixed teacher models repeatedly onthe same data, we decode the entire training set onceusing each teacher to create a new training datasetfor its respective student.
Table 2: Ablation performance on the IWSLT development set. BLEU (T) refers to the BLEU scoreon a version of the development set that has been translated by the teacher model. An Ã— indicatesthat fine-tuning caused that model to get worse. When uniform copying is used as the decoderinputs, the ground-truth target lengths are provided. All models use argmax decoding.
