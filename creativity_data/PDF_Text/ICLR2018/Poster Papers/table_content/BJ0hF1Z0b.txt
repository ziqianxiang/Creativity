Table 1: Privacy for different total numbers of users K (all with equal weight), expected number ofusers sampled per round C, and the number of rounds of training. For each row, We set δ = κ1rτand report the value of for which (, δ)-differential privacy holds after 1 to 106 rounds. For largedatasets, additional rounds of training incur only a minimal additional privacy loss.
Table 2: Privacy (e at δ = 10-9) and accuracy af-ter 5000 rounds of training for models with dif-ferent σ and S from Figure 1. The e's are strictupper bounds on the true privacy loss given thedataset size K and C; ACCUraCyTop1 (ACCTI) isestimated from a model trained with the same σas discussed in the text.
Table 3: Count histograms recording how manyof a model’s (row’s) top 10 predictions are foundin the n = 10, 50, or 100 most frequent wordsin the corpus. Models that predict corpus top-nmore frequently have more mass to the right.
