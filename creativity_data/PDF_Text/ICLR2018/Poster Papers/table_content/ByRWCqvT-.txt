Table 1: Unsupervised cross-task transfer from Omniglotbg to Omnigloteval . The performance isaveraged across 20 alphabets which have 20 to 47 letters. The ACC and NMI without brackets havethe number of clusters equal to ground-truth. The "(100)" means the algorithms use K = 100. Thecharacteristics of how each algorithm utilizes the pairwise constraints are marked in the "Constraintsin" column, where metric stands for the metric learning of feature representation.
Table 2: Unsupervised cross-domain transfer (domain adaptation) on the Office-31 dataset. Thebackbone network used here is Resnet-18 (He et al., 2016) pre-trained with ImageNet.
Table 3: The list of datasets involved in each experiment. G learns the similarity function fromdataset A. The CCN* is optimized with dataset T or T∪S', while CCN* means CCN for cross-tasktransfer and CCN+/++ for cross-domain transfer. The rows for network initialization indicate whetherthe network has weights initialized by training a classification task with the specified dataset. Theweights are randomly initialized if not specified.
Table 4: The list of loss functions used for training networks. The similarity prediction function(network) G uses the cross-entropy (CE) loss with two classes (similar/dissimilar). The trainingof constrained clustering network (CCN*) involves the combinations of the learnable clusteringobjective (LCO), cross-entropy, and domain adaptation loss (DA).
Table 5: A breakdown of the results for each alphabet in Omnigloteval . The unsupervised crosstask transfer experiment is described in section 5.1. This table shows the clustering accuracy withK = 100 to SimUlate the SitUation of UnknoWn number of clusters.____________________Alphabet	K-means	LPNMF	LSC	ITML	SKMS	SKKm	SKLR	CSP	MPCK-means	CCNAngelic	24%	26%	27%	48%	78%	40%	38%	72%	50%	82%Atemayar_Qelisayer	19%	14%	17%	51%	61%	51%	44%	61%	50%	82%Atlantean	19%	15%	19%	57%	72%	55%	51%	77%	47%	72%Aurek_Besh	23%	18%	21%	45%	49%	44%	45%	76%	71%	90%Avesta	22%	18%	19%	47%	29%	39%	38%	65%	52%	76%Ge_ez	19%	17%	17%	56%	58%	47%	42%	72%	55%	82%Glagolitic	22%	19%	21%	42%	38%	58%	62%	66%	61%	85%Gurmukhi	15%	13%	15%	44%	26%	54%	48%	60%	56%	80%Kannada	18%	14%	16%	48%	37%	46%	53%	60%	48%	62%Keble	20%	14%	18%	44%	60%	46%	44%	75%	68%	90%Malayalam	18%	15%	16%	36%	24%	49%	52%	50%	54%	72%Manipuri	17%	15%	16%	49%	40%	53%	54%	66%	62%	85%Mongolian	18%	18%	19%	50%	40%	37%	48%	75%	57%	86%Old_Church_Slavonic_Cyrillic	19%	16%	19%	42%	41%	52%	67%	71%	67%	94%Oriya	15%	13%	14%	46%	40%	54%	45%	57%	52%	67%Sylheti	14%	13%	14%	49%	32%	35%	37%	59%	43%	64%
Table 6: Estimates for the number of characters across the 20 datasets in Omnigloteval . The boldnumber means the prediction has error smaller or equal to 3. The ADif is defined in section 5.1.2.
Table 7: The performance of the similarity prediction function used in section 5.1. We leverage theN-way test which is commonly used in one-shot learning evaluation. The similarity is learned withOmniglotbg and has N-way test with Omnigloteval and MNIST. The experimental settings followVinyals et al. (2016). The raw probability output (without binarization) from our G is used to find thenearest exemplar in the N-way test.
Table 8: Unsupervised cross-task transfer learning on ImageNet. The values are the average ofthree random subsets in ImageNet118. Each subset has 30 classes. The "ACC" has K = 30 whilethe "ACC (100)" sets K = 100. All methods use the features (outputs of average pooling) fromResnet-18 pre-trained with ImageN et882 classification.
Table 9: Performance of the similarity prediction function (G, trained with ImageNet882) appliedto three subsets of ImageNet118. Each subset contains 30 random classes of ImageNet118. Thepredictions are binarized at 0.5 to calculate the precision and recall. Random*: The expectedperformance when classes are uniformly distributed and make uniform random guess for similarity.
Table 10: The performance of unsupervised transfer across domains on Office-31 dataset. Thebackbone networks in the comparison have different numbers of convolutional layers. AlexNet has5 layers and the ResNets have 18〜50 layers. SO is the abbreviation for source-only, which simplytrains on S0 and directly applies the classifier on T . The first two rows are directly copied from Longet al. (2017). The features learned with deeper networks generalize better across domains.
Table 11: Performance of the similarity prediction function (G, trained with I mageN et882) appliedon three domains of the OffiCe-31 dataset. In total, 1.4M pairs are examined to calculate the table.
Table 12: Unsupervised transferring across domains (S’: SVHN, T: MNIST A: Omniglotbg) withoutpre-trained backbone network weights. Our setup is similar to Sener et al. (2016) and Ganin et al.
Table 13: Performance of the similarity prediction function (G, trained with Omniglotbg) applied onthe MNIST dataset. In total, 5M pairs are sampled to calculate the table.
