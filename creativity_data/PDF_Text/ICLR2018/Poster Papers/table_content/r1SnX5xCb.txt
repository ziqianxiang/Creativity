Table 1: AUC for Deep Sensing and Benchmarks with MIMIC-III dataset (See the text for descrip-tions of Settings A, B). *: P-ValUe < 0.05AUC (Mean ± Std (Gain %))		MIMIC-III (Setting A)	MIMIC-III (Setting B)Proposed Model	Deep Sensing	0.8019 ± 0.0112 (-)	0.8019 ± 0.0112 (-)RNN based	Choi etal. (2015)*	0.7112 ± 0.0134 (31.4 %)	0.7598 ± 0.0110(17.5 %)	LiPton et al.(2016)*	0.7072 ± 0.0108 (32.3 %)	0.7551 ± 0.0115(19.1 %)	Che etal. (2016)*	0.7133 ± 0.0111 (30.9 %)	0.7593 ± 0.0123 (17.7 %)	FUtoma et al. (2017)*	0.7094 ± 0.0121 (31.8 %)	0.7579 ± 0.0129 (18.2 %)InterPolation	SPline*	0.7045 ± 0.0137 (33.0 %)	0.7542 ± 0.0108 (19.4 %)+ RNN	Cubic*	0.7012 ± 0.0129 (33.7 %)	0.7569 ± 0.0112(18.5 %)ImPUtation	MICE*	0.7093 ± 0.0132 (31.9 %)	0.7571 ± 0.0121 (18.4 %)+ RNN	Kernel*	0.7002 ± 0.0119 (33.9 %)	0.7534 ± 0.0139(19.7 %)	EM*	0.7019 ± 0.0098 (33.5 %)	0.7531 ± 0.0107 (19.8 %)Table 2: AUC for Deep Sensing and Benchmarks with Wards dataset (See the text for descriptionsof Settings A, B). *: P-valUe < 0.05AUC (Mean ± Std (Gain %))		Wards (Setting A)	Wards (Setting B)Proposed Model	Deep Sensing	0.8348 ± 0.0201(-)	0.8348 ± 0.0201 (-)RNN based	Choi et al. (2015)*	0.7739 ± 0.0264 (26.9 %)	0.8028 ± 0.0184(16.2 %)	LiPton et al. (2016)*	0.7893 ± 0.0237 (21.6 %)	0.8107 ± 0.0191 (12.7%)	Che et al. (2016)*	0.7905 ± 0.0143 (21.1 %)	0.8159 ± 0.0160 (10.3%)
Table 2: AUC for Deep Sensing and Benchmarks with Wards dataset (See the text for descriptionsof Settings A, B). *: P-valUe < 0.05AUC (Mean ± Std (Gain %))		Wards (Setting A)	Wards (Setting B)Proposed Model	Deep Sensing	0.8348 ± 0.0201(-)	0.8348 ± 0.0201 (-)RNN based	Choi et al. (2015)*	0.7739 ± 0.0264 (26.9 %)	0.8028 ± 0.0184(16.2 %)	LiPton et al. (2016)*	0.7893 ± 0.0237 (21.6 %)	0.8107 ± 0.0191 (12.7%)	Che et al. (2016)*	0.7905 ± 0.0143 (21.1 %)	0.8159 ± 0.0160 (10.3%)	FUtoma et al. (2017)*	0.7911 ± 0.0193 (20.9 %)	0.8177 ± 0.0147 (9.4 %)InterPolation	SPline*	0.7829 ± 0.0085 (23.9 %)	0.8023 ± 0.0187 (16.4 %)+ RNN	CUbic*	0.7712 ± 0.0084 (27.8 %)	0.7993 ± 0.0137 (17.7%)ImPUtation	MICE*	0.7499 ± 0.0096 (33.9%)	0.7877 ± 0.0149 (22.2 %)+ RNN	Kernel*	0.7397 ± 0.0155 (36.5 %)	0.7728 ± 0.0187 (27.3 %)	EM*	0.7593 ± 0.0168 (31.4%)	0.7784 ± 0.0163 (25.5%)Estimation of missing values: Table 3 shows the mean and standard deviation of the RMSE forM-RNN and benchmarks for both the MIMIC-III and the Wards dataset. The RMSE of M-RNN isless than half that of the best benchmark in MIMIC-III dataset and less than 70% that of the bestbenchmark in Wards dataset. All the imProvements are statistically significant (P-valUe < 0.05).
Table 3: RMSE of Missing information for M-RNN and Benchmarks with MIMIC-III and Wardsdatasets. *: P-valUe < 0.05Datasets ∣	∣		I Interpolation				Imputation		I Metrics ∣	M-RNN	I Spline	Cubic	I MICE	Kernel	EMMIMIC-III	I RMSE - Mean ∣	0.0137	I 0.0735*	0.0279*	I 0.0611*	0.0556*	0.0467*	I RMSE-Std I	0.0013	I 0.0012	0.0013	I 0.0011	0.0011	0.0014Wards	I RMSE - Mean ∣	0.0169	I 0.0314*	0.0211*	I 0.0554*	0.0627*	0.0761*	I RMSE - Std I	0.0019	I 0.0011	0.0021	I 0.0013	0.0014	0.00175.4	Source of gainsOUr M-RNN architectUre consists of two comPonents: the interPolation block (with for-ward/backward connection) and the imPUtation block). To Understand the soUrce of gains Providedby the varioUs comPonents of oUr aPProach, we carry oUta series of exPeriments in which we restrict12Published as a conference paper at ICLR 2018the operation of our architecture in various ways. In the first experiment, we restrict to interpolationonly (no imputation), in the second experiment, we restrict to imputation only (no interpolation), inthe third experiment we restrict to forward interpolation only (no backward interpolation), and inthe fourth experiment we replace the GRU based RNN with a standard RNN. Table 4 provides theresults of these experiments. As can be seen, both the interpolation and imputation blocks by them-selves provide significant performance improvements. (Because the sampling frequencies are high
Table 4: Source of gain analysis for M-RNN with MIMIC-III and Wards datasets. (Performancemetric: RMSE)___________________________________________________________________________Benchmarks	I	MIMIC-III		Wards		I Mean ± Std ∣	Loss (%)	I Mean ± Std ∣	Loss (%) IM-RNN	I 0.0137 ± 0.0013 I	(-)	I 0.0169 ± 0.0019 I	G) INo Imputation	I 0.0188 ± 0.0011 I	27.1%	I 0.0201 ± 0.0016 I	15.9% INo Interpolation	I 0.0285 ± 0.0018 ∣	51.9%	I 0.0278 ± 0.0024 ∣	39.2% INo Backward Interpolation	I 0.0151 ± 0.0014 I	9.3%	I 0.0179 ± 0.0018 I	5.6% IStandard RNN	I 0.0178 ± 0.0011 I	23.0%	I 0.0194 ± 0.0016 I	12.9% IWithout Mask Vector	I 0.0226 ± 0.0021 ∣	39.4%	I 0.0247 ± 0.0027 ∣	31.6% I6	ConclusionThe problem of active sensing is a very important one but has not been thoroughly treated in theliterature. We present here a solution based on a novel deep learning architecture. As part of thesolution, we provide a new method for reconstructing missing data that exploits joint interpolationwithin data streams and imputation across data streams. We demonstrate that Deep Sensing makeslarge and statistically significant improvements in comparison with state-of-the-art benchmarks intwo real-world datasets.
Table 5: Configurations of the ExperimentsBlocks	Categories	ConfigurationsInterpolation	Model Initialization Optimization Batch size and iterations Depth Constraints	Modified Bi-RNN with GRU Xavier Initialization (Glorot & Bengio (2010)) Adam* Optimization (Kingma & Ba (2014)) (learning rate = 0.05) Batch size = 100, Iterations = 1000 5 The matrix parameters are block-diagonalsImputation	Model Initialization Optimization Batch size and iterations Depth Constraints	Fully Connected Layers Xavier Initialization Adam Optimization (learning rate = 0.05) Batch size = 100, Iterations = 1000 10 (Activate function: Linear) The block-diagonal part of the matrix is zero.
