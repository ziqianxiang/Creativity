Table 1: Comparing our semi-supervised learning approach with state-of-the-art ones on MNIST.
Table 2: Inception score and accuracy of different models on CIFAR-10Method	Supervised IS	Unsupervised IS	Accuracy(%)SteinGANs (Wang & Liu, 2016)	^^635	—	—DCGANs (Radford et al., 2015)	6.58	6.16 ± 0.07	—Improved GANs (Salimans et al., 2016)	8.09 ± 0.07	—	—AC-GANs (Odena et al., 2016)	8.25 ± 0.07	—	—GP-WGAN (Gulrajani et al., 2017)	8.42 ± 0.10	7.86 ± 0.07	91.85SGANs (Huang et al., 2016)	8.59 ± 0.12	—	—ALI (Warde-Farley & Bengio, 2016)	—	5.34 ± 0.05	—BEGAN (Berthelot et al., 2017)	—	5.62	—EGAN-Ent-VI (Dai et al., 2017)	—	7.07 ± 0.10	—DFM (Warde-Farley & Bengio, 2016)	—	7.72 ± 0.07	—Our CT-GAN	8.81±0.13	8.12±0.12	95.91Comparison of the inception scores. Finally, we compare our approach with GP-WGAN on thewhole training set for both unsupervised and supervised generative-purpose task using ResNet. Formodel selection, we use the first 50,000 samples to compute the inception scores (Salimans et al.,2016), then choose the best model, and finally report the “test” score on another 50,000 samples.
Table 3: Comparing our semi-supervised learning approach with state-of-the-art ones on CIFAR-10Method	Test error (%)Ladder (Rasmus et al., 2015)	20.40 ± 0.47VAT (Miyato et al., 2017)	10.55TE (Laine & Aila, 2016)	12.16 ± 0.24Teacher-StUdent (Tarvainen & Valpola, 2017)	12.31 ± 0.28CatGANs (SPringenberg, 2015)	19.58 ± 0.58Improved GANs (Salimans et al., 2016)	18.63 ± 2.32ALI (DUmoUlin et al., 2016)	17.99 ± 1.62CLS-GAN (Qi, 2017)	17.30 ± 0.50Triple GAN (Li et al., 2017a)	16.99 ± 0.36Improved semi-GAN (Kumar et al., 2017)	16.78 ± 1.80OUrCT-GAN	9.98 ± 0.21Semi-supervised learning. For the semi-supervised learning approach, we follow the standardtraining/test split of the dataset but use only 4,000 labels in the training. A regular data augmentationwith flipping the images horizontally and randomly translating the images within [-2,2] pixels is usedin our paper (No ZCA whitening). We report the semi-supervised learning results in Table 3. Themean and standard errors are obtained by running the experiments 5 rounds. Comparing to severalvery competitive methods, ours is able to achieve state-of-the-art results. Notably, our CT-GANoutperfroms all the GAN based methods by a large margin. Please see Appendix A for the network
Table 4: Networks for semi-supervised learning on MNISTClassifier CGenerator GInput: Labels y, 28*28 Images x,	Input: Noise 100 zGaUssian noise 0.3, MLP 1000, ReLU Gaussian noise 0.5, MLP 500, ReLU Gaussian noise 0.5, MLP 250, ReLU Gaussian noise 0.5, MLP 250, ReLU Gaussian noise 0.5, MLP 250, ReLU Gaussian noise 0.5, MLP 10, Softmax	MLP 500, Softplus, Batch norm MLP 500, Softplus, Batch norm MLP 784, Sigmoid, Weight normTable 5: Networks for semi-supervised learning on CIFAR-10Classifier CGenerator GInput: Labels y, 32*32*3 Colored Image x,	Input: Noise 50 z0.2 Dropout 3*3 conv. 128, Pad =1, Stride =1, lReLU, Weight norm 3*3 conv. 128, Pad =1, Stride =1, lReLU, Weight norm 3*3 conv. 128, Pad =1, Stride =2, lReLU, Weight norm	MLP 8192, ReLU, Batch norm Reshape 512*4*4 5*5 deconv. 256*8*8, ReLU, Batch norm0.5 Dropout 3*3 conv. 256, Pad =1, Stride =1, lReLU, Weight norm 3*3 conv. 256, Pad =1, Stride =1, lReLU, Weight norm 3*3 conv. 256, Pad =1, Stride =2, lReLU, Weight norm	5*5 deconv. 128*16*16, ReLU, Batch norm0.5 Dropout 3*3 conv. 512, Pad =0, Stride =1, lReLU, Weight norm 3*3 conv. 256, Pad =0, Stride =1, lReLU, Weight norm 3*3 conv. 128, Pad =0, Stride =1, lReLU, Weight norm	5*5 deconv. 3*32*32, Tanh, Weight normGlobal pool MLP 10, Weight norm, Softmax	Appendix B	Hyper-parameters and other training detailsFor the semi-supervised learning experiments, we set λ = 1.0 in Eq.(7) in all our experiments. ForCIFAR-10, the number of training epochs is set to 1,000 with a constant learning rate of 0.0003. For11Published as a conference paper at ICLR 2018Table 6: Generative model for MNISTDiscriminator	Generator
Table 5: Networks for semi-supervised learning on CIFAR-10Classifier CGenerator GInput: Labels y, 32*32*3 Colored Image x,	Input: Noise 50 z0.2 Dropout 3*3 conv. 128, Pad =1, Stride =1, lReLU, Weight norm 3*3 conv. 128, Pad =1, Stride =1, lReLU, Weight norm 3*3 conv. 128, Pad =1, Stride =2, lReLU, Weight norm	MLP 8192, ReLU, Batch norm Reshape 512*4*4 5*5 deconv. 256*8*8, ReLU, Batch norm0.5 Dropout 3*3 conv. 256, Pad =1, Stride =1, lReLU, Weight norm 3*3 conv. 256, Pad =1, Stride =1, lReLU, Weight norm 3*3 conv. 256, Pad =1, Stride =2, lReLU, Weight norm	5*5 deconv. 128*16*16, ReLU, Batch norm0.5 Dropout 3*3 conv. 512, Pad =0, Stride =1, lReLU, Weight norm 3*3 conv. 256, Pad =0, Stride =1, lReLU, Weight norm 3*3 conv. 128, Pad =0, Stride =1, lReLU, Weight norm	5*5 deconv. 3*32*32, Tanh, Weight normGlobal pool MLP 10, Weight norm, Softmax	Appendix B	Hyper-parameters and other training detailsFor the semi-supervised learning experiments, we set λ = 1.0 in Eq.(7) in all our experiments. ForCIFAR-10, the number of training epochs is set to 1,000 with a constant learning rate of 0.0003. For11Published as a conference paper at ICLR 2018Table 6: Generative model for MNISTDiscriminator	GeneratorInPUt: 1*28*28 Image X	Input: Noise z 1285*5 conv. 64, Pad = same, Stride = 2,lReLU 0.5 Dropout	MLP 4096, ReLU Reshape 256*4*45*5 conv. 128, Pad = same, Stride = 2, lReLU 0.5 Dropout	5*5 deconv. 128*8*8 ReLU, Cut 128*7*75*5 conv. 256, Pad = same, Stride = 2, lReLU 0.5 Dropout	5*5 deconv. 64*14*14 ReLUReshape 256*4*4 (D_)	5*5 deconv. 1*28*28
Table 6: Generative model for MNISTDiscriminator	GeneratorInPUt: 1*28*28 Image X	Input: Noise z 1285*5 conv. 64, Pad = same, Stride = 2,lReLU 0.5 Dropout	MLP 4096, ReLU Reshape 256*4*45*5 conv. 128, Pad = same, Stride = 2, lReLU 0.5 Dropout	5*5 deconv. 128*8*8 ReLU, Cut 128*7*75*5 conv. 256, Pad = same, Stride = 2, lReLU 0.5 Dropout	5*5 deconv. 64*14*14 ReLUReshape 256*4*4 (D_)	5*5 deconv. 1*28*28MLP 1 (D)	SigmoidTable 7: Generative model for CIFAR-10Discriminator	GeneratorInput: 3*32*32 Image x,	Input: Noise z 1285*5 conv. 128, Pad = same, Stride = 2, lReLU 0.5 Dropout	MLP 8192, ReLU, Batch norm Reshape 512*4*45*5 conv. 256, Pad = same, Stride = 2, lReLU 0.5 Dropout	5*5 deconv. 256*8*8 ReLU, Bach norm5*5 conv. 512, Pad = same Stride = 2, lReLU 0.5 Dropout	5*5 deconv. 128*16*16 ReLU, Batch normReshape 512*4*4 (D_)	5*5 deconv. 3*32*32MLP 1 (D)	TanhMNIST, the number of training epochs is set to 300 with a constant learning rate of 0.003. The otherhyper-parameters are exactly the same as in the improved GAN (Salimans et al., 2016).
Table 7: Generative model for CIFAR-10Discriminator	GeneratorInput: 3*32*32 Image x,	Input: Noise z 1285*5 conv. 128, Pad = same, Stride = 2, lReLU 0.5 Dropout	MLP 8192, ReLU, Batch norm Reshape 512*4*45*5 conv. 256, Pad = same, Stride = 2, lReLU 0.5 Dropout	5*5 deconv. 256*8*8 ReLU, Bach norm5*5 conv. 512, Pad = same Stride = 2, lReLU 0.5 Dropout	5*5 deconv. 128*16*16 ReLU, Batch normReshape 512*4*4 (D_)	5*5 deconv. 3*32*32MLP 1 (D)	TanhMNIST, the number of training epochs is set to 300 with a constant learning rate of 0.003. The otherhyper-parameters are exactly the same as in the improved GAN (Salimans et al., 2016).
Table 8: ResNet for CIFAR-10Discriminator	GeneratorInput: 3*32*32 Image X	Input: Noise bmz 128[3*3]*2 Residual Block, Resample = DOWN 128*16*16	MLP 2048 Reshape 128*4*4[3*3]*2 Residual Block, Resample = DOWN 128*8*8 0.2 Dropout [3*3]*2 Residual Block, Resample = None 128*8*8 0.5 Dropout [3*3]*2 Residual Block, Resample = None 	128*8*8 0.5Dropout	[3*3]*2 Residual Block, Resample = UP 128*8*8 [3*3]*2 Residual Block, Resample = UP 128*16*16 [3*3]*2 Residual Block, Resample = UP 128*32*32ReLU, Global mean pool (D_)	3*3 conv. 3*32*32MLP 1 (D)	Tanh12Published as a conference paper at ICLR 2018If we remove the CT term, the test error goes up to 14.98, signifying the effectiveness of the CTregularization.
Table 9: Ablation study of our semi-supervised learning methodMethod	Test Errorw/o CT	14.98±0.43W/o GAN	11.98±0.32w batch norm	一w/o D_(.,.) over the second-to-last layer 10.70±0.24Ours	9.98±0.21Appendix D	Examining the 1 -Lips chitz continuityNorm of gradient. In our experiments, we find that although the GP-WGAN (Gulrajani et al.,2017) has applied a Lipschitz constraint in the form of the gradient penalty over the input sampledbetween a real data point and a generated one, the actual effect on the `2 norm of the gradient isnot as good as our CT-GAN model in the real data points, as illustrated in Figure 1. We empiricallyverify this fact by Figure 8, which shows the `2 norms of the gradients of the discriminator withrespect to the real data points. The closer to 1 the norms are, the better the 1-Lipschitz continuity ispreserved. Figure 8 further demonstrates that our consistency (CT) regularization is able to improveGP-WGAN (Gulrajani et al., 2017).
