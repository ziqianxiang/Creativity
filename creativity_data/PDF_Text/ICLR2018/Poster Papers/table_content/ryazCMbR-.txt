Table 1: BER (at 4dB) of trained neural decoders with different number/type of RNN layers onrate-1/2 RSC codes (blocklength 100) at SNR 4dBBCJR-like RNN PerformanceModel	Number of	BCJR Val	Turbo BER	Hidden Unit	MSE	(Turbo 6 iters:			0.002)BD-1-LSTM	^tgo	0.0031	0.1666BD-1-GRU	100	0.0035	0.1847BD-1-RNN	100	0.0027	0.1448BD-1-LSTM	200	0.0031	0.1757BD-1-GRU	200	0.0035	0.1693BD-1-RNN	200	0.0024	0.1362SD-1-LSTM	100	0.0033	0.1656SD-1-GRU	100	0.0034	0.1827SD-1-RNN	100	0.0033	0.2078SD-1-LSTM	200	0.0032	0.137SD-1-GRU	200	0.0033	0.1603SD-1-RNN	200	0.0024	1462BD-2-LSTM	100	4.4176e-04	0.1057BD-2-GRU	100	1.9736e-04	0.0128
Table 2: MSE of trained neural models with different number/type of RNN layers in learning BCJRalgorithm with non-zero priorswith a knee. Before the threshold, it closely aligns with the 45-degree line SNRtrain = SNRtest .
