Table 1: Symbols in our grammar, i.e. the functions, variables, and constantsUnary functions, F1					Terminal, T		Binary, F2sin	cos	csc	sec	tan	0	1	+cot	arcsin	arccos	arccsc	arcsec	2	3	×arctan	arccot	sinh	cosh	csch	4	10	∧sech	tanh	coth	arsinh	arcosh	0.5	-1	arcsch	arsech	artanh	arcoth	exp	0.4	0.7						π	x	F1 → sin, cos, tan, . . .	(3)F2 → +, ∧, ×, . . .	(4)T → -1, 0, 1, 2, π, x, y, . . . , any number of precision 2 in [-3.14,+3.14]	(5)Table 1 presents the complete list of functions and symbols as well as examples of the terminalsof the grammar. Note that we exclude subtraction and division because they can be representedwith addition, multiplication and power, respectively. Furthermore, the equations can have as manyvariables as needed.
Table 2: Examples of generated equationsExamples of correct identities ∣ Examples of incorrect identities12 = x-1×0(arctan 10)22 = (arctan 10)3+1x × (-1 + x) = x × (x - 1)x1 = x + 00.5x+2 = sin(0.5)x+2π × csc(x) = - csc(x)-4 = -4x*2 ×√ = √Is it true? (θɔθ	θFigure 2: Tree-structured recursive neural model, for the trees in Figure 1a (left) and 1b (right)which is representable in our grammar. In order to make this clear, consider number 2.5. In order torepresent this number, we expand it into its decimal representation 2.5 = 2 × 100 + 5 × 10-1 andfeed this as one of the function evaluation expressions for training (Figure 1c). Therefore, we canrepresent floating point numbers of finite precision using integers in the range [-1,10].
Table 3: Generalization Results: the train and the test contain equations of the same depth [1,2,3,4].
Table 4: Extrapolation Evaluation to measure capability of the model to generalize to unseen depthon symbolic equationsApproach	Train depth:1,2,3; Test depth: 4			Train depth:1,3,4; Test depth: 2			Accuracy	Precision	Recall	Accuracy	Precision	RecallMajority Class	55.22	0	0	56.21	0	0RNN	65.15	68.61	75.51	71.27	82.98	43.27LSTM	76.40	71.62	78.35	79.31	75.27	79.31TreeNN	88.36	87.87	85.86	92.58	89.04	94.71TreeLSTM	93.27	90.20	95.33	94.78	94.15	93.90TreeNN + data	93.34	90.34	95.33	93.36	89.75	95.78TreeLSTM + data	96.17	92.97	97.15	97.37	96.08	96.868070s50302	4	6	8	10k(a) Symbolic equation completionFigure 3: Evaluating Equation Completion, Figure 3a shows the top-k accuracy of the symbolicdata for different methods, and Figure 3b illustrates the minimum MSE of the top-k predictions, forthe function evaluation data.
