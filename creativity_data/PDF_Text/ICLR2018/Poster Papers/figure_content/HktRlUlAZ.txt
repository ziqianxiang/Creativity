Figure 1: In the log-polar representation, rotations around the origin become vertical shifts, anddilations around the origin become horizontal shifts. The distance between the yellow and greenlines is proportional to the rotation angle/scale factor. Top rows: sequence of rotations, and the cor-responding polar images. Bottom rows: sequence of dilations, and the corresponding polar images.
Figure 2: Left: GrouP-ConVolutions in SO(2). The images in the left most column differ by 90°rotation, the filters are shown in the top row. Application of the rotational group-convolution withan arbitrary filter results is shown to Produce an equiVariant rePresentation. The inner-Product eachof filter orbit (rotated from 0 - 360°) and the image is plotted in blue for the top image and red forthe bottom image. Observe how the filter response is shifted by 90°. Right: Group-Convolutionsin SO(2) X R+. Images in the left most column differ by a rotation of π/4 and scaling of 1.2.
Figure 3: Network architecture. The input image passes through a fully convolutional network, thepolar origin predictor, which outputs a heatmap. The centroid of the heatmap (two coordinates),together with the input image, goes into the polar transformer module, which performs a polartransform with origin at the input coordinates. The obtained polar representation is invariant withrespect to the original object location; and rotations and dilations are now shifts, which are handledequivariantly by a conventional classifier CNN.
Figure 4: Left: The rows alternate between samples from SIM2MNIST, where the predicted originis shown in green, and their learned polar representation. Note how rotations and dilations of theobject become shifts. Right: Each row shows a different input and correspondent feature mapson the last convolutional layer. The first and second rows show that the 180° rotation results in ahalf-height vertical shift of the feature maps. The third and fourth rows show that the 2.4× dilationresults in a shift right of the feature maps. The first and third rows show invariance to translation.
Figure 5: Top: rotated voxel occupancy grids. Bottom: corresponding cylindrical representations.
Figure 6: ROTSVHN samples. Since the digits are cropped from larger images, no artifacts are in-troduced when rotating. The 6s and 9s are indistinguishable when rotated. Note that there are usuallyvisible digits on the sides, which pose a challenge for classification and PTN origin prediction.
