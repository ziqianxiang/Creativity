Figure 1: MGAN’s architecture with K generators, a binary discriminator, a multi-class classifier.
Figure 2: The comparison of our MGAN and GAN’s variants on 2D synthetic dataset.
Figure 3: Images generated by our proposed MGAN trained on natural image datasets. Due to thespace limit, please refer to the appendix for larger plots.
Figure 4: Images generated by our MGAN trained on the original 96×96 STL10 dataset.
Figure 5: Images generated by our MGAN trained on CIFAR10 at different epochs. Samples in eachrow from the top to the bottom correspond to a different generator.
Figure 6: Samples generated by MGAN models trained on synthetic data with 2, 3, 4 and 10 gener-ators. Data samples from the 8 Gaussians are in red, and generated data by each generator are in adifferent color.
Figure 7: Samples generated by MGAN models trained on synthetic data with different values ofdiversity coefficient β. Generated data are in blue and data samples from the 8 Gaussians are in red.
Figure 8: Observation of activate neuron rates and batch normalization centers in MGAN’s genera-tors trained on CIFAR-10.
Figure 9: Images generated by MGAN trained on the CIFAR-10 dataset.
Figure 10: Images generated by MGAN trained on the rescaled 48×48 STL-10 dataset.
Figure 11: Images generated by MGAN trained on the rescaled 32×32 ImageNet dataset.
Figure 12: Cherry-picked samples generated by MGAN trained on the 96×96 STL-10 dataset.
Figure 13: Incomplete, unrealistic samples generated by MGAN trained on the 96×96 STL-10dataset.
