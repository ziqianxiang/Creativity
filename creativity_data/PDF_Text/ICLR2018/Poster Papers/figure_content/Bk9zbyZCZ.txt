Figure 1: Left: Images showing the 2D maze environment. The left side (Fig. 1a) represents the fully ob-servable maze while the right side (Fig. 1b) represents the agent observations. The agent is represented by theyellow pixel with its orientation indicated by the black arrow within the yellow block. The starting positionis always the topmost position of the maze. The red bounding box represents the area of the maze that issubsampled for the agent observation. In “Goal-Search”, the goal of the agent is to find a certain color block(either red or teal), where the correct color is provided by an indicator (either green or blue). This indicatorhas a fixed position near the start position of the agent. Right: State observations from the “Indicator” Doommaze environment. The agent starts in the middle of a maze looking in the direction of a torch indicator. Thetorch can be either green (top-left image) or red (bottom-left image) and indicates which of the goals to searchfor. The goals are two towers which are randomly located within the maze and match the indicator color. Theepisode ends whenever the agent touches a tower, whereupon it receives a positive reward if it reached thecorrect tower, while a negative reward otherwise.
Figure 2: Top-down views showing succesful episodes in each of the 3 Doom maze tasks. The red linesindicate the path traveled by the agent. Indicator is shown in Fig. 2a, where the agent receives positive rewardwhen entering the corresponding tower that matches the torch color it saw at the start of the episode and anegative reward otherwise. The episode terminates once the agent has reached a tower. Repeating, shownin Fig. 2b, has the same underlying mechanics except (1) the episode persists for T time steps regardless oftowers entered and (2) the torch indicator is removed from the maze after the agent has reached a tower once.
Figure 3: Top: Noisy v.s. Groundtruth Position trajectory (quantized to a 15×15 grid). As time pro-gresses, the colors get lighter. Center: Neural Map cells addressed by the write operator under thenoisy positions. Bottom: Neural Map cells that would have been written to under perfect positionestimates.
Figure 4: A few sampled states from an example episode demonstrating how the agent learns to use thecontext addressing operation of the Neural Map. The top row of images is the observations made by the agent,the center is the fully observable mazes and the bottom image is the probability distributions over locationsinduced by the context operation at that step.
Figure 5: Three example episodes of the (allocentric) context addressing operator on Doom mazes. The top images of each row are the RGB inputs the agentsees, the center images are a top-down representation of the maze, and the bottom images are the α(tx,y) of the context operation.
Figure 6:19Three example episodes of the (egocentric) context addressing operator on Doom mazes. The top images of each row are the RGB inputs the agentsees, the center images are a top-down representation of the maze, and the bottom images are the (egocentric) α(tx,y) of the context operation.
