Figure 1: Illustrations of competitive environments we consider in our work: Run to Goal, You ShallNot Pass, Sumo, and Kick and Defend.
Figure 2: Opponent Sampling: Training rewards for two opponent sampling strategies.
Figure 3: Effect for exploration curriculum: win-rate of agents trained by annealing the explorationreward against agents which constantly receive the dense exploration reward. The agents which op-timized for the sparse competition reward benefit from the natural curriculum of multi-agent trainingand defeat the other agent by a margin.
Figure 4: Win-rate ofkicker vs iterations withfull randomizationFigure 5: % Win-rate of agents trained in ensemble vs agents trainedwith just a single policy. Humanoid Sumo (left) and Ant Sumo (right).
Figure 5: % Win-rate of agents trained in ensemble vs agents trainedwith just a single policy. Humanoid Sumo (left) and Ant Sumo (right).
