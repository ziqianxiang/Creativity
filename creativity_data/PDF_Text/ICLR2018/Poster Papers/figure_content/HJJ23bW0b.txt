Figure 1: PSRNN Update, displayed on the left as a neural network and on the right as an equation3.1 Two-stage Regression for PSRNNsPSRNNs can be initialized using the Two Stage Regression (2SR) approach of Hefny et al. (2015).
Figure 2: Common RBF kernels, the corresponding functions Ï†, and probability density functions(here: w = (w1, ..., wn)>).
Figure 3: MSE for Orthogonal RF vs Standard RF after two stage regressionMocap Data SetFigure 4: MSE for Orthogonal RF vs Standard RF after two stage regression and BPTT6.3	DiscussionThese results demonstrate the effectiveness of Orthogonal RF as a technique for improving the per-formance of downstream applications. First we have shown that Orthogonal RF can offer significantperformance improvements for kernel ridge regression, specifically in the context of the 2SR algo-rithm for PSRNNs. Furthermore we have shown that not only does the resulting model have lowererror, it is also a better initialization for the BPTT gradient descent procedure. In other words, usinga model initialization based on orthogonal RF results in BPTT converging to a superior final model.
Figure 4: MSE for Orthogonal RF vs Standard RF after two stage regression and BPTT6.3	DiscussionThese results demonstrate the effectiveness of Orthogonal RF as a technique for improving the per-formance of downstream applications. First we have shown that Orthogonal RF can offer significantperformance improvements for kernel ridge regression, specifically in the context of the 2SR algo-rithm for PSRNNs. Furthermore we have shown that not only does the resulting model have lowererror, it is also a better initialization for the BPTT gradient descent procedure. In other words, usinga model initialization based on orthogonal RF results in BPTT converging to a superior final model.
