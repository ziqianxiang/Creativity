Figure 1: Illustrating the behavior of classifier under different out-of-distribution training datasets.
Figure 2: For all experiments in (a), (b) and (c), we commonly use the SVHN dataset for in-distribution. Fraction of the maximum prediction value in softmax scores trained by (a) cross en-tropy loss and (b) confidence loss: the x-axis and y-axis represent the maximum prediction valueand the fraction of images receiving the corresponding score, respectively. The receiver operatingcharacteristic (ROC) curves under different losses are reported in (c): the red curve corresponds tothe ROC curve of a model trained by optimizing the naive cross entropy loss, whereas other onescorrespond to the ROC curves of models trained by optimizing the confidence loss. The KL diver-gence term in the confidence loss is optimized using explicit out-of-distribution datasets indicatedin the parentheses, e.g., Confident loss (LSUN) means that we use the LSUN dataset for optimizingthe KL divergence term.
Figure 3: The generated samples from original GAN (a)/(c) and proposed GAN (b)/(d). In (a)/(b),the grey area is the 2D histogram of training in-distribution samples drawn from a mixture of twoGaussian distributions and red points indicate generated samples by GANs.
Figure 4: Performances of the baseline detector (Hendrycks & Gimpel, 2016) under various traininglosses. For training models by the confidence loss, the KL divergence term is optimized usingsamples indicated in the parentheses. For fair comparisons, we only plot the performances forunseen out-of-distributions, where those for seen out-of-distributions (used for minimizing the KLdivergence term in (1)) can be found in Table 1.
Figure 5: Guided gradient (sensitivity) maps of the top-1 predicted class with respect to the inputimage under various training losses.
Figure 6: Detailed structure of VGGNet with 13 layers.
Figure 7: Performances of the baseline detector (Hendrycks & Gimpel, 2016) and ODIN detector(Liang et al., 2017) under various training losses.
