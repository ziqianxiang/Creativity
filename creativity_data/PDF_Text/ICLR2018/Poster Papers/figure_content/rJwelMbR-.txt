Figure 1: Average return and success rate learning curves of the global policy on Picking, Lobbing,Catching, Ant, and Stairs when partitioned into 4 contexts. Metrics are evaluated each iterationon the global policy distilled from the current local policies at that iteration. On all of the tasks,DnC RL achieves the best results. On the Catching and Ant tasks, DnC performs comparably to thecentralized variant, while on the Picking, Lobbing, and Stairs tasks, the full algorithm outperformsall others by a wide margin. All of the experiments are shown with 5 random seeds.
