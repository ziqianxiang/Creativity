Figure 1: Example of Max & Average Pooling with Stride of 2While max and average pooling both are effective, simple methods, they also have shortcomings.
Figure 2: Shortcomings of Max & Average Pooling using Toy ImageMax pooling(Yu et al., 2014). There is no set way to perform mixed pooling. This method is applied arbitrarilyin three different ways (1) for all features within a layer, (2) mixed between features within a layer,or (3) mixed between regions for different features within a layer (Lee et al., 2016; Yu et al., 2014).
Figure 3: Stochastic Pooling ExampleIn Figure 3, a region of activations are shown, and in the adjacent region, their corresponding proba-bilities based on Equation 4. In any given region, the activations with the highest probabilities havethe higher chance of selection. However, any activation can be chosen. In this example, the stochas-tic pooling method selects the midrange activation with a probability of 13%. By being based offprobability, and not deterministic, stochastic pooling avoids the shortcomings of max and averagepooling, while enjoying some of the advantages of max pooling (Zeiler & Fergus, 2013).
Figure 4: Wavelet Pooling Forward Propagation Algorithm4Published as a conference paper at ICLR 20183.2	BackpropagationThe proposed wavelet pooling algorithm performs backpropagation by reversing the process of itsforward propagation. First, the image feature being back propagated undergoes 1st order waveletdecomposition. After decomposition, the detail coefficient subbands upsample by a factor of 2to create a new 1st level decomposition. The initial decomposition then becomes the 2nd leveldecomposition. Finally, this new 2nd order wavelet decomposition reconstructs the image featurefor further backpropagation using the IDWT. Figure 5 details the backpropagation algorithm ofwavelet pooling:Figure 5: Wavelet Pooling Backpropagation Algorithm4	Results and DiscussionAll CNN experiments use MatConvNet (Vedaldi & Lenc, 2015). All training uses stochastic gradientdescent (Bottou, 2010). For our proposed method, the wavelet basis is the Haar wavelet, mainly forits even, square subbands. All experiments are run on a 64-bit operating system, with an Intel Corei7-6800k CPU @ 3.40 GHz processor, with 64.0 GB of RAM. We utilize two GeForce Titan XPascal GPUs with 12 GB of video memory for all training. All CNN structures except for MNISTuse a network loosely based on Zeilers network (Zeiler & Fergus, 2013). We repeat the experimentswith Dropout (Srivastava, 2013) and replace Local Response Normalization (Krizhevsky, 2009)
Figure 5: Wavelet Pooling Backpropagation Algorithm4	Results and DiscussionAll CNN experiments use MatConvNet (Vedaldi & Lenc, 2015). All training uses stochastic gradientdescent (Bottou, 2010). For our proposed method, the wavelet basis is the Haar wavelet, mainly forits even, square subbands. All experiments are run on a 64-bit operating system, with an Intel Corei7-6800k CPU @ 3.40 GHz processor, with 64.0 GB of RAM. We utilize two GeForce Titan XPascal GPUs with 12 GB of video memory for all training. All CNN structures except for MNISTuse a network loosely based on Zeilers network (Zeiler & Fergus, 2013). We repeat the experimentswith Dropout (Srivastava, 2013) and replace Local Response Normalization (Krizhevsky, 2009)with Batch Normalization (Ioffe & Szegedy, 2015) for CIFAR-10 and SHVN (Dropout only) toexamine how these regularization techniques change the pooling results. To test the effectiveness ofeach pooling method on each dataset, we solely pool with that method for all pooling layers in thatnetwork. All pooling methods use a 2x2 window for an even comparison to the proposed method.
Figure 6: Selection of Image Datasets5Published as a conference paper at ICLR 2018Figure 7: CNN MNIST Structure Block DiagramThe input training data and test data come from the MNIST database of handwritten digits. Thefull training set of 60,000 images is used, as well as the full testing set of 10,000 images. Table1 shows our proposed method outperforms all methods. Given the small number of epochs, maxpooling is the only method to start to overfit the data during training. Mixed and stochastic poolingshow a rocky trajectory, but do not overfit. Average and wavelet pooling show a smoother descentin learning and error reduction. Figure 8 shows the energy of each method per epoch.
Figure 7: CNN MNIST Structure Block DiagramThe input training data and test data come from the MNIST database of handwritten digits. Thefull training set of 60,000 images is used, as well as the full testing set of 10,000 images. Table1 shows our proposed method outperforms all methods. Given the small number of epochs, maxpooling is the only method to start to overfit the data during training. Mixed and stochastic poolingshow a rocky trajectory, but do not overfit. Average and wavelet pooling show a smoother descentin learning and error reduction. Figure 8 shows the energy of each method per epoch.
Figure 8: MNIST Pooling Method Energy Performance of Training & Validation SetsTable 1 shows the accuracy of each method:	Average	Max	Mixed	Stochastic	WaveletI Accuracy (%)	98.72	98.80	98.86	98.90	99.01Table 1: MNIST Performance of Pooling Methods4.2	CIFAR- 1 0We run two sets of experiments with the pooling methods. The first is a regular network structurewith no dropout layers. We use this network to observe each pooling method without extra regu-larization. The second uses dropout and batch normalization, and performs over 30 more epochsto observe the effects of these changes. Figure 9 shows our network structure for the CIFAR-10experiments:The input training and test data come from the CIFAR-10 dataset. The full training set of 50,000images is used, as well as the full testing set of 10,000 images. For both cases, with no dropout,and with dropout, Table 2 and Table 3 show our proposed method has the second highest accuracy.
Figure 9: CNN CIFAR-10 Structure Block Diagramtrend at a similar, but better rate than our proposed method. Average pooling shows the smoothestdescent in learning and error reduction, especially in the validation set. Figure 10 shows the energyof each method per epoch.
Figure 10: CIFAR-10 Pooling Method Energy Performance of Training & Validation SetsTables 2 and 3 show the accuracy of each method:	Average	Max	Mixed	Stochastic	WaveletI Accuracy (%)	76.51	71.42	73.77	73.03	74.42Table 2: CIFAR-10 Performance of Pooling Methods	Average	Max	Mixed	Stochastic	WaveletI Accuracy (%)	81.15	80.30	79.21	80.09	80.28Table 3: CIFAR-10 Performance of Pooling Methods + Dropout4.3	SHVNWe run two sets of experiments with the pooling methods. The first is a regular network structurewith no dropout layers. We use this network to observe each pooling method without extra regular-ization. The second uses dropout to observe the effects of this change. Figure 11 shows our networkstructure for the SHVN experiments:The input training and test data come from the SHVN dataset. For the case with no dropout, we use55,000 images from the training set. For the case with dropout, we use the full training set of 73,257images, a validation set of 30,000 images we extract from the extra training set of 531,131 images,as well as the full testing set of 26,032 images. For both cases, with no dropout, and with dropout,7Published as a conference paper at ICLR 20183x 1
Figure 11: CNN SHVN Structure Block DiagramTable 4 and Table 5 show our proposed method has the second lowest accuracy. Max and waveletpooling both slightly overfit the data. Our method follows the path of max pooling, but performsslightly better in maintaining some stability. Mixed, stochastic, and average pooling maintain a slowprogression of learning, and their validation sets trend at near identical rates. Figure 12 shows theenergy of each method per epoch.
Figure 12: SHVN Pooling Method Energy Performance of Training & Validation SetsTables 4 and 5 shows the accuracy of each method:	Average	Max	Mixed	Stochastic	WaveletI Accuracy (%)	89.83	88.09	89.25	89.97	88.51Table 4: SHVN Performance of Pooling Methods	Average	Max	Mixed	Stochastic	WaveletI Accuracy (%)	92.80	92.18	92.13	91.04	91.10Table 5: SHVN Performance of Pooling Methods + Dropout4.4 KDEFWe run one set of experiments with the pooling methods that includes dropout. Figure 13 shows ournetwork structure for the KDEF experiments:The input training and test data come from the KDEF dataset. This dataset contains 4,900 imagesof 35 people displaying seven basic emotions (afraid, angry, disgusted, happy, neutral, sad, andsurprised) using facial expressions. They display emotions at five poses (full left and right profiles,half left and right profiles, and straight).
Figure 13: CNN KDEF Structure Block DiagramThis dataset contains a few errors that we fix (missing or corrupted images, uncropped images, etc.).
Figure 14: KDEF Pooling Method Energy Performance of Training & Validation SetsTable 6 shows the accuracy of each method:	Average	Max	Mixed	Stochastic	WaveletI AccUracy (%)	76.5	75.6	72.6	72.7	75.9Table 6: KDEF Performance of Pooling Methods + Dropout4.5 Computational ComplexityOur construction and implementation of wavelet pooling is not efficient. We present this proposedmethods as a proof-of-concept, to show its potential and validity, and also to be open to massiveimprovements. The main area of improvement is computational efficiency. As a proof-of-concept,the code written to implement this method is not at its peak form. Additionally, we did not have9Published as a conference paper at ICLR 2018the time, space, or resources to optimize the code. We view the accuracy results and novelty as astarting point to spawn improvements, both from our own research as well as other researchers.
