Figure 1: Architecture of the proposed system. For each sentence in language L1, the systemis trained alternating two steps: denoising, which optimizes the probability of encoding a noisedversion of the sentence with the shared encoder and reconstructing it with the L1 decoder, andon-the-fly backtranslation, which translates the sentence in inference mode (encoding it with theshared encoder and decoding it with the L2 decoder) and then optimizes the probability of encodingthis translated sentence with the shared encoder and recovering the original sentence with the L1decoder. Training alternates between sentences in L1 and L2, with analogous steps for the latter.
