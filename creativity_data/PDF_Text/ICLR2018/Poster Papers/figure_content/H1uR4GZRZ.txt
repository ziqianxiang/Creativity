Figure 1: Accuracy plots of a variety of attacks against dense model and SAP models with differentperturbation strengths, λ. For the SAP τ % models, τ denotes the percentages of samples drawn fromthe multinomial distribution, at each layer. (a) SAP models tested against random perturbation. (b)SAP models tested against the FGSM attack, using MC sampling. (c) SAP-100 tested against aniterative adversarial attack, using MC sampling (legend shows defender vs. adversary). It is worthrestating that obtaining the iterative attack of SAP models is much more expensive and noisier thanthe iterative attack of dense models.
Figure 2: Robustness of dropout models, with different rates of dropout (denoted in the legends),against adversarial attacks, using MC sampling, with a variety of perturbation strengths, λ: (a)dropout is applied on the pre-trained models during the validations; (b) the models are trained usingdropout, and dropout is applied during the validations; (c) the models are trained using dropout, butdropout is not applied during the validations.
Figure 3: Accuracy plots of the dense, SAP-100, ADV and ADV+SAP-100 models, against adversar-ial attacks, using MC sampling, with a variety of perturbation strengths, λ.
Figure 4: Calibration plots of the dense, SAP-100, ADV and ADV+SAP-100 models, againstadversarial attacks, using MC sampling, with a variety of different perturbation strengths, λ. Theseplots show the relation between the confidence level of the model’s output and its accuracy.
Figure 5: Robustness of different pruning and noisifying strategies against their respective adversarialattacks (MC sampling used to estimate gradients of stochastic models).
Figure 6: Accuracy plots of adversarial attacks, with different perturbation strengths, λ. The legendshows defender vs. adversary models (used for gradient computation), and the number of MC samplesused to estimate the gradient.
