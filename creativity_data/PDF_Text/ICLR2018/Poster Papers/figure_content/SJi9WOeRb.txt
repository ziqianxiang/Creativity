Figure 1: A comparison between the two approximation schemes. Since in practice the optimiseronly visits finite number of locations in the parameter space, it can lead to over-fitting if the neu-ral network based functional approximator is not carefully regularised, and therefore the curvatureinformation of the approximated loss can be very different from that of the original loss (shown in(a)). On the other hand, the gradient approximation scheme (b) can be more accurate since it onlyinvolves estimating the sensitivity of the loss function to the parameters in a local region.
Figure 2: Kernel induced Hamiltonian flow compared with HMC. Top: samples generated from thedynamics, training data (in cyan), an the trajectory of a particle for T = 1 to 200 starting at the starlocation (in yellow). Bottom: statistics computed during simulations. See main text for details.
Figure 3: Generalisation performances for trained approximate posterior samplers.
Figure 4: Visualisation of generated images from trained BEGAN models.
Figure 5: Quantitative evaluation on entropy regularised BEGAN. The higher the better for the LHSpanels and the other way around for the RHS ones. See main text for details.
