Figure 1: (a-d) An illustration of a deep model trained on simulated source training data failing to segmenta real target domain image: (a) shows the target image, (b) is the ground truth segmentation into semanticcategories (car, road, etc), (c) is the output of the unadapted source model, (d) is the improved segmenta-tion obtained by our proposed ADR method. (e) Previous distribution matching methods do not consider thesource decision boundary when aligning source and target feature points. (f) We propose to use the boundaryinformation to achieve low-density separation of aligned points.
Figure 2: Overview of ADR. Left: We train G, C with classification loss on source and sample acritic consisting of two classifiers using dropout. The criticâ€™s sensitivity is measured as the diver-gence between the class predictions of C1 and C2 on the same input. Right: Adversarial trainingiterates two steps: the critic tries to maximize the sensitivity while the generator tries to minimize it.
Figure 3: (Best viewed in color) Toy Experiment. Top row: Model trained without adaptation. Columns 1-5show the decision boundary obtained by keeping one neuron in the last hidden layer and removing the rest.
Figure 4: Relationship between sensitivity loss on target (blue line), on source (yellow line), and accuracy(red: accuracy of C0 , green: accuracy of C) during training on digits.
Figure 5: Comparison of entropy of ours (blue line) with ENT (yellow line). The entropy is calculated ontarget samples by using the output of the classifier.
Figure 6: Visualization of VisDA-classification (12 classes) target features using T-SNE (Maaten & Hinton(2008)): (a) features obtained by the Imagenet-pretrained ResNext model not finetuned on VisDA; (b) featuresfrom the ResNext model fine-tuned only on VisDA source samples without any adaptation; (c) features obtainedby ResNext adapted by our ADR method.
Figure 7: Comparison of results on two real images segmented by ResNet50. Clockwise from upper left:Original image; Ground truth; Segmented image before adaptation; Segmented image after adaptation by ourmethod.
Figure 9: Example of results on segmentation experiments performed by DRN-105. From top to bottom,Original image; Ground truth; Segmented image before adaptation; Segmented image after adaptation by ourmethod.
Figure 8: Overview of architecture for se-mantic segmentationE	Semi-supervised learning using GANsIn this section, we demonstrate how to apply our method in training a Generative Adversarial Net-work (GAN) applied to semi-supervised learning. We follow the method proposed by (Springenberg(2015); Salimans et al. (2016)), who use a K-class classification network as a critic to train a GANin the semi-supervised setting.
Figure 10: Examples of generated images.
