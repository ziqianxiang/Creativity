Figure 1: Illustration of OT-GAN. Mini-batches from the generator and training data are embeddedinto a learned feature space via the critic. A transport cost matrix is calculated between the twomini-batches of features. Soft matching aligns features across mini-batches and aligned featuresare compared. The figure only illustrates the distance calculation between one pair of mini-batcheswhereas several are computed.
Figure 2: Results for consistency when fixing the critic on data generated from 8 Gaussian mixtures.
Figure 3: CIFAR-10 inceptionscore over the course of training for different batch sizes.
Figure 4: Samples generated by OT-GAN onCIFAR-10, without using labels.
Figure 5: Samples generated without usingoptimal transport.
Figure 6: ImageNet Dog subset samples generated by OT-GAN (left) and DCGAN (right).
Figure 7: Bird example images generated by conditional OT-GAN8Published as a conference paper at ICLR 20186	DiscussionWe have presented OT-GAN, a new variant of GANs where the generator is trained to minimizea novel distance metric over probability distributions. This metric, which we call mini-batch en-ergy distance, combines optimal transport in primal form with an energy distance defined in anadversarially learned feature space, resulting in a highly discriminative distance function with un-biased mini-batch gradients. OT-GAN was shown to be uniquely stable when trained with largemini-batches and to achieve state-of-the-art results on several common benchmarks.
Figure 8: CIFAR-10 Samples generated without adversarially learning the cost function.
Figure 9: Imagenet dog samples generated with DCGAN (left) after 900 epochs and OT-GAN (right)after 13000 epochs. When training long enough, DCGAN suffers from mode collapse as indicatedby the highlighted samples. We did not observe any mode collapse for OT-GAN, even when trainingfor many more epochs.
