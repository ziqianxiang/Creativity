Figure 1: Simplified example about counting the number of cats. The light-colored cat is detectedtwice and results in a duplicate proposal. This shows the conversion from the attention weights ato a graph representation A and the eventual goal of this component with exactly one proposal pertrue object. There are 4 proposals (vertices) capturing 3 underlying objects (groups in dotted lines).
Figure 2: Removal of intra-object edges by masking the edges of the attention matrix A with thedistance matrix D. The black vertices now form a graph without self-loops. The self-loops need tobe added back in later.
Figure 3: Removal of duplicate inter-object edges by computing a scaling factor for each vertex andscaling A0 accordingly. A0 is A With self-loops already added back in. The scaling factor for onevertex is computed by counting hoW many vertices have outgoing edges to the same set of vertices;all edges of the tWo proposals on the right are scaled by 0.5. This can be seen as averaging proposalsWithin each object and is equivalent to removing duplicate proposals altogether under a sum.
Figure 4: Accuracies on the toy task as side length l and noise q are varied in 0.01 step sizes.
Figure 5: Shapes of trained activation functions f1 (attention weights) and f2 (bounding boxdistances) for varying bounding box side lengths (left) or the noise (right) in the dataset, varied in0.01 step sizes. Best viewed in color.
Figure 6: Schematic view of a model using our counting component. The modifications made tothe baseline model when including the counting component are marked in red. Blue blocks markcomponents with trainable parameters, gray blocks mark components without trainable parameters.
Figure 7:	Shape of activation functions as l is varied for q = 0.5 on the toy dataset. Each line showsthe shape of the activation function when l is set to the value associated to its color. Best viewed incolor.
Figure 8:	Shape of activation functions as q is varied for l = 0.5 on the toy dataset. Each line showsthe shape of the activation function when q is set to the value associated to its color. Best viewed incolor.
Figure 9:	Shape of activation functions for a model trained on the train and validation sets of VQAv2 (thick black), compared against the shapes when parametrizing the toy dataset with q around 0.4(green), 0.7 (orange), or 1.0 (red) with fixed l = 0.2. Best viewed in color.
Figure 10: Example toy dataset data for varying bounding box side lengths l and noise q. Theground truth column shows bounding boxes of randomly placed true objects (blue) and of irrelevantobjects (red). The data column visualizes the samples that are actually used as input (dark bluesrepresent weights close to 1, dark reds represent weights close to 0, lighter colors represent weightscloser to 0.5). The weight of the ith bounding box bi is defined as ai = (1 - q) score + qz where thescore is the maximum overlap of bi with any true bounding box or 0 if there are no true boundingboxes and z is drawn from U(0, 1). Note how this turns red bounding boxes that overlap a lot with ablue bounding box in the ground truth column into a blue bounding box in the data column, whichsimulates the duplicate proposal that we have to deal with. Best viewed in color.
Figure 11: Selection of validation images with overlaid bounding boxes, values of the attentionmatrix A, distance matrix D, and the resulting count matrix C. White entries represent values closeto 1, black entries represent values close to 0. The count c is the usual square root of the sum over theelements of C. Notice how particularly in the third example, A clearly contains more rows/columnswith high activations than there are actual objects (a sign of overlapping bounding boxes) and thecounting module successfully removes intra- and inter-object edges to arrive at the correct predictionregardless. The prediction is not necessarily - though often is - the rounded value of c.
