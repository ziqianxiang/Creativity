Figure 1: Geodesic versus Eu-clidean distances in the case ofa non-zero curvature manifold(as the one of SPD matrices).
Figure 2: A gradient descent path for correlation alignment induces a gradient descent path forentropy minimization. Left column. We compare a baseline CNN trained on the source (SVHN) only(blue), with the same model where we applied either Euclidean (red) or geodesic alignment (orange)with λ = 0.1 using MNIST as target. We compare the target entropy (top) and the correlationalignment (bottom) with a KL divergence between source and target distribution. Right column.
Figure 3: Sampled images from the datasets involved in the domain adaptation experiments. Fromleft to right, SVHN (first column, digits 9, 9, 2 from top to bottom), SYN (second column, digits 3,9, 7 from top to bottom), NYUD RGB (third column, toilet, sink and garbage-bin classesacquires as RGB), NYUD depth (fourth column, different instances from the same previous classesacquired with the alternative modality) and the well known MNIST dataset (fifth column).
Figure 4: SVHN → MNIST: t-SNE [van der Maaten & Hinton (2008)] visualizations (64-dimensional features). Left: blue and red dots indicate SVHN (source) and MNIST (target) features,respectively. Right: different colors indicate the ten different classes. While source data (blue) isalways well clustered, target data (red) is not. Correlation alignment in (b) and (c) makes the targetdistribution increasingly more similar to the source one. As qualitatively shown in the plots, MECAprovides both better target clustering and domain similarity within the each cluster. This confirms thethe quantitative results of Table 1, where MECA discriminates better than Deep Coral.
