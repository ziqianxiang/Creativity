Figure 1: The main component of the i-RevNet and its inverse. RevNet blocks are interleaved withconvolutional bottlenecks Fj and reshuffling operations Sj to ensure invertibility of the architecture∙-vand computational efficiency. The input is processed through a splitting operator S, and output is∙-vmerged through M. Observe that the inverse network is obtained with minimal adaptations.
Figure 2: Illustration of theinvertible down-samplingSj X(u, λ) = X(Ψ(u, λ))where Ψ is some invertible mapping. In principle, any invert-ible downsampling operation like e.g. dilated convolutions (Yu &Koltun, 2015) can be considered here. We use the inverse of theoperation described in Shi et al. (2016) as illustrated in Figure 2,since it preserves roughly the spatial ordering, and thus permits toavoid mixing different neighborhoods via the next convolution. Sis similar, but also linearly increases the channel dimensionality, forexample by concatenating 0.
Figure 3: Training loss of the i-RevNet (b), com-pared to the ResNet, on ImageNet.
Figure 4: Normalized sorted singular values of∂Φx.
Figure 5: This graphic displays several reconstructed sequences {xt}t. The left image correspondsto x0 and the right image to x1.
Figure 6: Accuracy at depth j for a linear SVM and a 1-nearest neighbor classifier applied to thespatially averaged Φj .
Figure 7: Accuracy of a linear SVM and nearestneighbor against the number of principal compo-moves some information that can not be recov-ered by a linear classifier, therefore we observethat the classification accuracy only decreasessignificantly for d ≤ 200. This shows that thesignal indeed lies in a subspace much lower di- nents retained.
