Figure 1: TWo views of GCN. On the left (graph convolution view), each circle represents a graphvertex. On two consecutive rows, a circle i is connected (in gray line) with circle j if the two cor-responding vertices in the graph are connected. A convolution layer uses the graph connectivitystructure to mix the vertex features/embeddings. On the right (integral transform view), the embed-ding function in the next layer is an integral transform (illustrated by the orange fanout shape) of theone in the previous layer. For the proposed method, all integrals (including the loss function) areevaluated by using Monte Carlo sampling. Correspondingly in the graph view, vertices are subsam-pled in a bootstrapping manner in each layer to approximate the convolution. The sampled portionsare collectively denoted by the solid blue circles and the orange lines.
Figure 2: Prediction accuracy: uniform versus impor-tance sampling. The three data sets from top to bottomare ordered the same as Table 1.
Figure 3: Per-batch training time in seconds (left) and prediction accuracy (right). For timing,GraphSAGE refers to GraphSAGE-GCN in Hamilton et al. (2017). The timings of using other ag-gregators, such as GraphSAGE-mean, are similar. GCN refers to using batched learning, as opposedto the original version that is nonbatched; for more details of the implementation, see the appendix.
Figure 4: Training/test accuracy versus training time. From left to right, the data sets are Cora,Pubmed, and Reddit, respectively.
