Figure 1: Adversarial images and corresponding perturbations at five levels of normalized L2 -dissimilarity for all four attacks.
Figure 2: Illustration of total variance minimiza-tion and image quilting applied to an original andan adversarial image (produced using I-FGSMwith = 0.03, corresponding to a normalized L2 -dissimilarity of 0.075). From left to right, thecolumns correspond to: (1) no transformation, (2)total variance minimization, and (3) image quilt-ing. From top to bottom, rows correspond to: (1)the original image, (2) the corresponding adver-sarial image produced by I-FGSM, and (3) the ab-solute difference between the two images above.
Figure 3: Block diagram detailing the differences between the experimental setups in Section 5.2,5.3, and 5.4. We train networks (a) on regular images or (b) on transformed images; we test thenetworks on transformed adversarial images. For each of the three setups, dashed arrows indicatewhich model is used by the adversary and which model is used by the classification model.
Figure 4: Top-1 classification accuracy of ResNet-50 tested on transformed adversarial images pro-duced by four attacks using five image transformations in a gray-box setting: (1) cropping-rescaling,(2) bit-depth reduction, (3) JPEG compression, (4) total variance minimization, and (5) image quilt-ing. The dotted line shows the top-1 accuracy of the ResNet-50 model on non-adversarial images,providing an upper bound on the effectiveness ofa defense. An L2-dissimilarity of 0.00 correspondsto the classification accuracy on non-adversarial images. Higher is better.
Figure 5: Top-1 classification accuracy of ResNet-50 trained and tested on transformed adversar-ial images produced by four attacks using five image transformations in a black-box setting: (1)cropping-rescaling, (2) bit-depth reduction, (3) JPEG compression, (4) total variance minimization,and (5) image quilting. The dotted line represents the top-1 accuracy of the ResNet-50 model on non-adversarial images, providing an upper bound on the effectiveness of a defense. An L2-dissimilarityof 0.00 corresponds to the classification accuracy on non-adversarial images. Higher is better.
Figure 6: Top-1 classification accuracy of ResNet-50 trained and tested on transformed adversar-ial images produced by four attacks using five image transformations in a gray-box setting: (1)cropping-rescaling, (2) bit-depth reduction, (3) JPEG compression, (4) total variance minimization,and (5) image quilting. The dotted line represents the top-1 accuracy of the ResNet-50 model onnon-adversarial images, providing an upper bound on the effectiveness ofa defense. L2-dissimilarityof 0 corresponds to clean image accuracy. Higher is better.
