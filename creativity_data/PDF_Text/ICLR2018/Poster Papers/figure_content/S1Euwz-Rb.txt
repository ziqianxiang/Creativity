Figure 1: A sample im-age from the CLEVR dataset,with a question: “There is apurple cube behind a metalobject left to a large ball; whatmaterial is it?”stance in CLEVR is also accompanied by a tree-structured functional program that was both used toconstruct the question and reflects its reasoning procedure - a series of predefined operations - thatcan be composed together to answer it.
Figure 2: The MAC cell, which is a recurrent unit comprised of a Control Unit, Read Unit, andWrite Unit. Blue shows the control flow and red shows the memory flow. See section 3.2 for details.
Figure 3: The Control Unit (CU) of the MAC cell. See section 3.2.1 for details. Best viewed incolor.
Figure 4: The Read Unit (RU) diagram. Blue refers to control flow, purple to knowledge flow andred to memory flow. See section 3.2.2 for description.
Figure 5: The Write Unit (WU) diagram. Blue refers to control flow and red to memory flow. Seesection 3.2.3 for description.
Figure 6: Training curves and accuracies for MACs (our model), FiLM (Perez et al., 2017), PG+EE(Johnson et al., 2017) and stacked-attention (Yang et al., 2016; Johnson et al., 2017). (Note: PG+EEuses the supported CLEVR programs as strong supervision.) Left: Training curve (accuracy/epoch).
Figure 7: Ablations and variations of the MAC network. See text for full detail.
Figure 8: Three examples of attention maps for the image and the question. See text for full details.
