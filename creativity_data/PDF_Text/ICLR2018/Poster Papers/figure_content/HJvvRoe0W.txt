Figure 1: Hilbert Curve and cropped image2.2	Network architectureModern CNNs or other image classification systems mainly focus on gray-scale images and standardRGB images, resulting in channels of length 1 or 3, respectively, for each pixel. In our approach,each pixel in the generated image is assigned a one-hot vector representing a k-mer. For increasingk, the length of the vector and thus the image dimension increases. Here, we use k = 4 resulting in4Published as a conference paper at ICLR 2018Figure 2: A simplified version of HCNN with two computational blocks. BN is short for "Batch Normaliza-tion".
Figure 2: A simplified version of HCNN with two computational blocks. BN is short for "Batch Normaliza-tion".
Figure 3: Residual BlockFor the pooling layers p we used Average pooling. Average pooling outperformed Max poolingin terms of prediction accuracy by more than 2% in general, as it reduces the high variance of thesparse generated images. Cross entropy was used as the loss function.
Figure 4: HCNN with different mapping strategiesby Nguyen et al. (2016) and thus yields a huge number of parameters in the fully connected layer.
Figure 5: Space-filling curvesAs can be seen in Fig. 5, mapping a sequence to an image reduces the distance between two ele-ments that are far from one another in the sequence, while the distance between nearby elementsdoes not increase. Each of the curves does have a different effect on the distance between far-away elements. In order to assess these differences, we use a measure that is based on the dis-tance between two sequence elements as can be observed in the image. We denote this distance byLC (x,y) where x, y ∈ S, with S the sequence and C the curve under consideration. Then for thesequence S = {A,B,C,D,E, ∙∙∙ ,P} We obtain•	Lseq (A,P) = 15 for the sequence;•	Lreshape(A,P) = '3∖P2 for the reshape curve;•	Lsnakesnake(A,P) = 3 for the snake curve;•	Ldiag-Snake(A,P) = 3∖Γ2 for the diagonal snake curve.
Figure 6: Sequence to Image13Published as a conference paper at ICLR 2018C Details of alternative neural networksLayer	filter size	stride	output dimConvolution 1	7	2	60Activation			Max pooling	3	3	60Convolution 2	5	2	30Activation			Max pooling	3	2	30Dropout, 0.5			FC layer				100Activation			Dropout, 0.5			Classifier			2Table 7: The model architecture of seq-CNN (Nguyen et al.,	Table 8: Bir-Direction LSTM2016)Layer	DescriptionEmbedding	
