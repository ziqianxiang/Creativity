Figure 1: The architecture of the self-attention layers used in the T-DMCA model. Every attentionlayer takes a sequence of tokens as input and produces a sequence of similar length as the output.
Figure 2: ROUGE-L F1 for various extractive methods. The abstractive model contribution is shownfor the best combined tf-idf -T-DMCA model.
Figure 3: Shows perplexity versus L for tf-idf extraction on combined corpus for different modelarchitectures. For T-DMCA, E denotes the size of the mixture-of-experts layer.
Figure 4:	Shows predictions for the same example from different models. Example model input canbe found in the Appendix A.4translation is not merely copied from the source, such as example cases where the target language isthe incorrect one (e.g. translation of an English name into Ukrainian).
Figure 5:	Translation examples from the Transformer-ED, L = 500.
Figure 6:	An example decoded from a T-DMCA model trained to produce an entire Wikipediaarticle, conditioned on 8192 reference document tokens.
Figure 7:	Three different samples a T-DMCA model trained to produce an entire Wikipedia article,conditioned only on the title. Samples 1 and 3 are truncated due to space constraints.
Figure 8:	Screenshot of DUC-style linguistic quality human evaluation tool.
Figure 9:	Screenshot of side-by-side human evaluation tool. Raters are asked whether they prefermodel output on the left or right, given a ground truth Wikipedia text.
Figure 10:	Example extractive-output/abstractive-input for models in ”dewey & lebeouf” example.
