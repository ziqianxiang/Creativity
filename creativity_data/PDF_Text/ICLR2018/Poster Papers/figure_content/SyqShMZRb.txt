Figure 1: Illustration on left shows the hierarchy of the structured data decoding space w.r.t differentworks and theoretical classification of corresponding strings from formal language theory. SD-VAE,our proposed model with attribute grammar reshapes the output space tighter to the meaningful targetspace than existing works. On the right we show a case where CFG is unable to capture the semanticconstraints, since it successfully parses an invalid program.
Figure 3: On-the-fly generative process of SD-VAE in order from (a) to (g). Steps: (a) stochasticgeneration of attribute; (b)(f)(g) constrained sampling with inherited attributes; (c) unconstrainedsampling; (d) synthesized attribute calculation on generated subtree. (e) lazy evaluation of the at-tribute at root node.
Figure 4: On the left are best programs found by each method using Bayesian Optimization. Onthe right are top 3 closest programs found by each method along with the distance to ground truth(lower distance is better). Both our SD-VAE and CVAE can find similar curves, but our methodaligns better with the ground truth. In contrast the GVAE fails this task by reporting trivial programsrepresenting linear functions.
Figure 5: Best top-3 molecules and the corresponding scores found by each method using BayesianOptimization.
Figure 6: Latent Space visualization. We start from the center molecule and decode the neighbor-hood latent vectors (neighborhood in projected 2D space).
Figure 7: Example of cross-serial dependencies (CSD) that exhibits in SMILES language.
Figure 8: Visualization of reconstruction. The first column in each figure presents the targetmolecules. We first encode the target molecules, then sample the reconstructed molecules fromtheir encoded posterior.
