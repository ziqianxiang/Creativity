Figure 1: VADA improves upon domain adversarial training by additionally penalizing violationsof the cluster assumption.
Figure 2: DIRT-T uses VADA as initialization. After removing the source training signal, DIRT-T minimizes cluster assumption violation in the target domain through a series of natural gradientsteps.
Figure 3: Effect of applying instance normalization to the input image. In clockwise direction:MNIST-M, GTSRB, SVHN, and CIFAR-10. In each quadrant, the top row is the original image,and the bottom row is the instance-normalized image.
Figure 4:	Comparing model behavior with and without the application of the KL-term. At iteration0, we begin with the VADA initialization and apply the DIRT-T algorithm.
Figure 5:	T-SNE plot of the last hidden layer for MNIST (blue) → SVHN (red). We used the modelwithout instance normalization to highlight the further improvement that DIRT-T provides.
Figure 6:	T-SNE plot of the last hidden layer for Room A (blue) → Room B (red)0.990.000.∞0.∞0.000.000.010.001.000.∞0.∞0.000.000.000.000.000.990.∞0.00
Figure 7:	Confusion matrix between VADA and and DIRT-T prediction labels.
