Figure 1: Our contributions are techniques (Confident-GNMax) that improve on the original PATE(LNMax) on all measures. Left: Accuracy is higher throughout training, despite greatly improvedprivacy (more in Table 1). Middle: The ε differential-privacy bound on privacy cost is quartered,at least (more in Figure 5). Right: Intuitive privacy is also improved, since students are trained onanswers with a much stronger consensus among the teachers (more in Figure 5). These are resultsfor a character-recognition task, using the most favorable LNMax parameters for a fair comparison.
Figure 2: Overview of the approach: (1) an ensemble of teachers is trained on disjoint subsets of thesensitive data, (2) a student model is trained on public data labeled using the ensemble.
Figure 3: Some example inputs from the Glyph dataset along with the class they are labeled as.
Figure 4:	Tradeoff between utility and privacy for the LNMax and GNMax aggregators onGlyph: effect of the noise distribution (left) and size of the teacher ensemble (right). The LNMaxaggregator uses a Laplace distribution and GNMax a Gaussian. Smaller values of the privacy cost ε(often obtained by increasing the noise scale σ—see Section 4) and higher accuracy are better.
Figure 5:	Effects of the noisy threshold checking: Left: The number of queries answeredby LNMax, Confident-GNMax moderate (T =3500, σ1=1500), and Confident-GNMax aggressive(T =5000, σ1=1500). The black dots and the right axis (in log scale) show the expected cost of an-swering a single query in each bin (via GNMax, σ2=100). Right: Privacy cost of answering all(LNMax) vs only inexpensive queries (GNMax) for a given number of answered queries. The verydark area under the curve is the cost of selecting queries; the rest is the cost of answering them.
