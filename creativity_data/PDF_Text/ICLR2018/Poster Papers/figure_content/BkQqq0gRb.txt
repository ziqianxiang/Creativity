Figure 1: Schematics of the multi-head networks tested in the paper, including both the graphicalmodel (left) and network architecture (right). (a) A multi-head discriminative model showing hownetwork parameters might be shared during training. The lower-level network is parameterizedby the variables θS and is shared across multiple tasks. Each task t has its own “head network”θtH mapping to the outputs from a common hidden layer. The full set of parameters is thereforeθ = {θHτ, θs}. (b) A multi-head generative model with shared network parameters. The headnetworks generate the intermediate level representations from the latent variables z.
Figure 2: Average test set accuracy on all observed tasks in the Permuted MNIST experiment.
Figure 3:	Comparison of the effect of coreset sizes in the Permuted MNIST experiment.
Figure 4:	Test set accuracy on all tasks for the Split MNIST experiment. The last column shows theaverage accuracy over all tasks. The bottom row is a zoomed version of the top row.
Figure 5: Test set accuracy on all tasks for the Split notMNIST experiment. The last column showsthe average accuracy over all tasks. The bottom row is a zoomed version of the top row.
Figure 6: Generated images from each of the generators after training. Each of the columns showsthe images generated from a specific task’s generator, and each of the lines shows the generationsfrom generators of all trained tasks. Clearly the naive approach suffers from catastrophic forgetting,while other approaches successfully remember previous tasks.
Figure 7: Quantitative results for continual learning for DGMs. See main text for a discussion.
Figure 8: Performance of SI with different hyper-parameter values in Permuted MNIST experiment.
Figure 9: Performance of EWC with different hyper-parameter values in Permuted MNIST experi-ment.
Figure 10: Performance of LP with different hyper-parameter values in Permuted MNIST experi-ment.
Figure 11: Comparison of SI with different hyper-parameter values in Split MNIST experiment.
Figure 12: Comparison of EWC with different hyper-parameter values in Split MNIST experiment(top: multi-head model, bottom: single-head model).
Figure 13: Comparison of SI with different hyper-parameter values in Split notMNIST experiment.
Figure 14: Comparison of EWC with different hyper-parameter values in Split notMNIST experi-ment (top: multi-head model, bottom: single-head model).
Figure 15: Comparison of VCL and EWC on a toy 2D dataset. The first column shows the contoursof the prediction probabilities after observing the first task. The second and third columns show thecontours for the first and the second tasks respectively after observing the second task.
