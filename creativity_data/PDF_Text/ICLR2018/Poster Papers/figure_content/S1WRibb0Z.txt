Figure 1: Recurrent-type neural architecture that corresponds to the Tensor Train decomposition.
Figure 2: Representation of an image in the form of Eq. (1). A window of size 7 × 7 moves acrossthe image of size 28 × 28 extracting image patches, which are then vectorized and arranged into amatrix of size 49 × 16.
Figure 3: Nodes performing multilinear map of their inputs. d-linear unit is specified by a d + 1dimensional core G.
Figure 4: Examples of networks corresponding to various tensor decompositions.
Figure 5: Decision boundaries of the TT-NetWork on toy 2-D datasets.
Figure 6: Train accuracy on CIFAR-10 for the TT- and CP-Networks wrt rank of the decompositionand total number of parameters (feature size 4 was used). Note that with rank increase the CP-Networks sometimes perform worse due to optimization issues.
