Figure 1: Lp norm penalties for a parameter θ according to different values of p. It is easily observedthat both weight decay and Lasso, p = 2 and p = 1 respectively, impose shrinkage for large values ofθ. By gradually allowing p < 1 we observe that the shrinkage is reduced and at the limit of p = 0 weobserve that the penalty is a constant for θ 6= 0.
Figure 2: (a) The binary concrete distribution with location log α = 0 and temperature β = 0.5and the hard concrete equivalent distribution obtained by stretching the concrete distribution to(γ = -0.1, ζ = 1.1) and then applying a hard-sigmoid. Under this specification the hard concretedistribution assigns, roughly, half of its mass to {0, 1} and the rest to (0, 1). (b) The expected valueof the afforementioned concrete and hard concrete gate as a function of the location log α, obtainedby averaging 10000 samples. We also added the value of the gates obtained by removing the noiseentirely. We can see that the noise smooths the hard-sigmoid to a sigmoid on average.
Figure 3: Expected number of floating point operations (FLOPs) during training for the original,dropout and L0 regularized networks. These were computed by assuming one flop for multiplicationand one flop for addition.
Figure 4: (a, b) Expected number of FLOPs during training for the dropout and L0 regularized WRNsfor CIFAR 10 (a) and CIFAR 100 (b). The original WRN is not shown as it has the same practicalFLOPs as the dropout equivalent network. (c) Train (dashed) and test (solid) error as a function ofthe training epochs for dropout and L0 WRNs at CIFAR 10.
