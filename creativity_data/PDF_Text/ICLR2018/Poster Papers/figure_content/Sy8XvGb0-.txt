Figure 1: (a) Diagram of latent constraints for a VAE. We use one critic Dattr to predict whichregions of the latent space will generate outputs with desired attributes, and another critic Drealismto predict which regions have high mass under the marginal posterior, q(z), of the training data.
Figure 2: Typical VAEs use a pixel-wise data likelihood, N(μχ(z),σχl), with σ, = 1 to producecoherent samples at the expense of visual and conceptual blurriness (Row 3). Some reconstructions(Row 2) actually change attributes of the original data. Decreasing σx to 0.1 maximizes the ELBO(supplemental Table 4) and increases the fidelity of reconstructions (Row 4) at the cost of samplerealism (Row 5). Using an actor to shift prior samples to satisfy the realism constraint, we achievemore realistic samples without sacrificing sharpness (Row 6). The samples are mapped to the closestpoint in latent space that both satisfies the realism constraint and has the same attributes as theoriginal data.
Figure 3: Contour maps of the critic value functions for the marginal posterior (“realism”) constraint.
Figure 4: Conditional generation with a CGAN actor-critic pair acting in the latent space of a VAEwith σx = 0.1. Each row starts from a different prior sample and maps it to a new point in latentspace that satisfies both the attribute constraints and the realism constraint. The attribute constraintsare changed one at a time to produce as smooth a transition as possible from left to right. Thebottom CGAN is regularized during training to prefer small shifts in latent space (λdist = 0.1),while the top is not (λdist = 0.0). Compared to the images generated by the unregularized model,the images generated by the regularized model are much less diverse across columns, suggesting thatthe regularization does indeed enforce some degree of identity preservation. The regularized modelproduces images that are somewhat more diverse across rows, suggesting that the regularizationfights mode collapse (arguably at the expense of image quality). For each column, the complete listof attributes is given in supplemental Table 3.
Figure 5: Identity-preserving transformations with optimization. Two separate critics are trained,one for attributes and one for the realism constraint. Starting at the latent points corresponding tothe data reconstructions, we then perform gradient ascent in latent space on a weighted combinationof critic values (1.0 attribute, 0.1 marginal posterior), stopping when a threshold value is passed forboth critics. Images remain semantically close to the original because the pixel-wise likelihood ofVAE training encourages identity-preserving reconstructions, and the dynamics of gradient ascentare naturally limited to finding solutions close in latent space. Panels are black for attributes of theoriginal image, as the procedure just returns the original point in latent space.
Figure 6: Transformations from a prior sample for the Melody VAE model. In each 16-bar pianoroll,time is in the horizontal direction and pitch in the vertical direction. In the prior sample, notes fallingoutside of the C Major scale are shown in red. After transformation by GP=CMaj ,d=0, all samplednotes fall within the scale, without a significant change to note density. After transformation ofthe original z by GP=CMaj ,d=192, all sampled notes lay within the scale and the density increasesbeyond 192. Synthesized audio of these samples can be heard at https://goo.gl/ouULt9.
Figure 7: Additional generated CelebA faces by GCGAN with λdist = 0. Full attribute labels aregiven in supplementary Table 315Published as a conference paper at ICLR 2018Figure 8: Additional generated CelebA faces by GCGAN with λdist = 0.1. Full attribute labels aregiven in supplementary Table 316Published as a conference paper at ICLR 2018Figure 9: Optimization of samples drawn from the prior to satisfy both the realism constraint andattribute constraints (drawn from the test set). The optimization takes 100 steps, and images areshown at 0, 10, 30, 50 and 100 steps. D is trained with inner-loop optimization, Gopt, as describedin Section 9.217Published as a conference paper at ICLR 2018Figure 10: Identity-distorting transformations with CGAN actor-critic. Without a penalty to en-courage small moves in latent space, the actor maps the latent vectors of the original data pointsto generated images that have the correct attributes, but a different identity. Panels are black forattributes of the original image, as the procedure just returns the same image as the reconstruction.
Figure 8: Additional generated CelebA faces by GCGAN with λdist = 0.1. Full attribute labels aregiven in supplementary Table 316Published as a conference paper at ICLR 2018Figure 9: Optimization of samples drawn from the prior to satisfy both the realism constraint andattribute constraints (drawn from the test set). The optimization takes 100 steps, and images areshown at 0, 10, 30, 50 and 100 steps. D is trained with inner-loop optimization, Gopt, as describedin Section 9.217Published as a conference paper at ICLR 2018Figure 10: Identity-distorting transformations with CGAN actor-critic. Without a penalty to en-courage small moves in latent space, the actor maps the latent vectors of the original data pointsto generated images that have the correct attributes, but a different identity. Panels are black forattributes of the original image, as the procedure just returns the same image as the reconstruction.
Figure 9: Optimization of samples drawn from the prior to satisfy both the realism constraint andattribute constraints (drawn from the test set). The optimization takes 100 steps, and images areshown at 0, 10, 30, 50 and 100 steps. D is trained with inner-loop optimization, Gopt, as describedin Section 9.217Published as a conference paper at ICLR 2018Figure 10: Identity-distorting transformations with CGAN actor-critic. Without a penalty to en-courage small moves in latent space, the actor maps the latent vectors of the original data pointsto generated images that have the correct attributes, but a different identity. Panels are black forattributes of the original image, as the procedure just returns the same image as the reconstruction.
Figure 10: Identity-distorting transformations with CGAN actor-critic. Without a penalty to en-courage small moves in latent space, the actor maps the latent vectors of the original data pointsto generated images that have the correct attributes, but a different identity. Panels are black forattributes of the original image, as the procedure just returns the same image as the reconstruction.
Figure 11: Training curves for melody actor (G) and critic (D) pair for pitch class constraintcpitch (m, P = CMaj ).
Figure 12: Architecture for the (a) actors and (b) critics used in all experiments.
Figure 13: Architectures for the (a) feed-forward MNIST, (b) convolutional CelebA, and (c) hierar-chical LSTM melody VAEs. In (b), all convolutions have a stride of 2. In (c), LSTM cells shown inthe same color share weights and linear layers between levels are omitted.
Figure 14: Samples generated with smaller (3 ReLU layers of 256 units each) G and D models arecomparable quality despite having 85x fewer parameters, λdist = 0.0. Full attribute labels are givenin supplementary Table 3.
Figure 15: Latent constraints applied to a vanilla autoencoder with no latent prior. Samples aresimilar quality to VAEs with σx = 0.1, but with less diversity and more high-frequency visualartifacts. Full attribute labels are given in supplementary Table 3.
Figure 16: Smaller decoder standard deviations, σx, lead to lower-variance posteriors, σz (x) of theencoder q(z | x), averaged over the training set per a dimension. The x-axis is sorted from lowest tohighest variance. Tighter posteriors correspond to more utilization of the latent dimension, and wescale our distance regularization the square inverse on a per-dimension basis.
