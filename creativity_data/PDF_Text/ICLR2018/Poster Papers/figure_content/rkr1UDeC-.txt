Figure 1: Synchronous training on Common Crawl dataset.
Figure 2: Codistillation (abbreviated as “Cod” in the legend) results with Common Crawl.
Figure 3: Codistillation on ImageNetFigure 4: Reload intervals on Common Crawlthe 128 worker baselines and almost achieves the training curve of the two-way ensemble. Measur-ing at the best validation error achieved by the baseline, codistillation reaches the same error in 2Xfewer steps. Perhaps more importantly, codistillation reaches a lower final error so a 2X reductionin steps is likely an underestimate of the gains. In our implementation, for the model we trained,codistillation is free in terms of step time as the GPU is not fully utilized and our implementationautomatically overlaps the computation of the teacher and student models. In the worst case, for amodel that saturates the hardware that is implemented without quantization, prefetching predictionsusing the CPU, or other optimizations to compute the predictions, the extra forward pass might in-crease compute costs by nearly 50%. However, even with these worst case assumptions, networkcosts will be a substantial contributor to the total step time, easily 50%-80%, resulting in a modestincrease in time per step.
Figure 4: Reload intervals on Common Crawlthe 128 worker baselines and almost achieves the training curve of the two-way ensemble. Measur-ing at the best validation error achieved by the baseline, codistillation reaches the same error in 2Xfewer steps. Perhaps more importantly, codistillation reaches a lower final error so a 2X reductionin steps is likely an underestimate of the gains. In our implementation, for the model we trained,codistillation is free in terms of step time as the GPU is not fully utilized and our implementationautomatically overlaps the computation of the teacher and student models. In the worst case, for amodel that saturates the hardware that is implemented without quantization, prefetching predictionsusing the CPU, or other optimizations to compute the predictions, the extra forward pass might in-crease compute costs by nearly 50%. However, even with these worst case assumptions, networkcosts will be a substantial contributor to the total step time, easily 50%-80%, resulting in a modestincrease in time per step.
