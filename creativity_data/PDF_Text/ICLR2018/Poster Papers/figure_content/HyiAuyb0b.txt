Figure 1: Different levels of perceptual complexity in the health gathering task. (a) Map view of agrid world. (b) First-person view of a three-dimensional environment, fixed textures. (c) First-personview of a three-dimensional environment, random textures.
Figure 2: Effect of rollout length on TD learning for n-step Q and A3C. We report average health atthe end of an episode for health gathering and average frags in the Battle scenario. Higher is better.
Figure 3: Effect of reward properties. Left to right: reward type, reward delay, reward sparsity. Wereport the average health at the end of an episode. Higher is better. MC training (QMC, green)performs well on all environments.
Figure 4: Effect of perceptual complexity. We report average cumulative reward per episode for gridworlds and average health at the end of the episode for ViZDoom-based setups. Perception in bothgridworlds is trivial. The perceptual complexity in the multi-texture task is higher than in the basictask.
Figure S1: Performance of the QMC algorithm using different value prediction horizons.
Figure S2: Map of the health gathering labyrinth.
