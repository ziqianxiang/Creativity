Figure 1: The mappings between the domains A, B, and Z.
Figure 2: An illustrative example where the two domains are line segments in R2 . There are infinitelymany mappings that preserve the uniform distribution on the two segments. However, only two standout as “semantic”. These are exactly the two mappings that can be captured by a neural network withonly two hidden neurons and Leaky ReLU activations, i.e., by a function h(x) = σa(Wx + b), for aweight matrix W and the bias vector b.
Figure 3: Results for celebA Male to Female transfer (a) Input (b) The mapping obtained by theGAN loss without additional losses.
Figure 4: Same as Fig. 3 for black to blond hair conversion.
Figure 5: Same as Fig. 3 for eyeglasses to no eyeglasses conversion.
Figure 6: Same as Fig. 3 for handbag to shoes and shoes to handbag mapping.
Figure 7: Same as Fig. 3 for edges to shoes and shoes to edges conversion.
Figure 8: Results for celebA Male to Female transfer for networks with different number of layers.
Figure 9: Results for celebA Female to Male transfer for networks with different number of layers.
Figure 10: Results for celebA Blond to Black Hair transfer for networks with different number oflayers.
Figure 11: Results for celebA Black Hair to Blond transfer for networks with different number oflayers.
Figure 12: Results for celebA Eyeglasses to Non-Eyeglasses transfer for networks with differentnumber of layers.
Figure 13: Results for celebA Non-Eyeglasses to Eyeglasses transfer for networks with differentnumber of layers.
Figure 14:	Results for mapping Males to itself (B=A) using a DiscoGAN architecture and enforcingthat the mapping is not the identity mapping. The odd rows present the learned mapping h, and theeven rows present the full cycle h0 ◦ h.
Figure 15:	Results for mapping the Females to itself (B=A) using a DiscoGAN architecture andenforcing that the mapping is not the identity mapping. The odd rows present the learned mapping h,and the even rows present the full cycle h0 ◦ h.
Figure 16:	Results for mapping shoe edges to itself (B=A) using a DiscoGAN architecture andenforcing that the mapping is not the identity mapping. The odd rows present the learned mapping h,and the even rows present the full cycle h0 ◦ h.
Figure 17:	Results for mapping handbag edges to itself (B=A), using a DiscoGAN architecture andenforcing that the mapping is not the identity mapping. The odd rows present the learned mapping h,and the even rows present the full cycle h0 ◦ h.
Figure 18:	Results for mapping handbags to itself (B=A), using a DiscoGAN architecture andenforcing that the mapping is not the identity mapping. The odd rows present the learned mapping h,and the even rows present the full cycle h0 ◦ h.
Figure 19:	Results for mapping shoes to itself (B=A) using a DiscoGAN architecture and enforcingthat the mapping is not the identity mapping. The odd rows present the learned mapping h, and theeven rows present the full cycle h0 ◦ h.
Figure 20:	Results for Alg. 1 on Male2Female dataset for mapping male to female. Shown is aminimal complexity mapping g that has low discrepancy, and various mappings h obtained by themethod.
Figure 21:	Results for Alg. 1 on Male2Female dataset for mapping female to male. Shown is aminimal complexity mapping g that has low discrepancy, and various mappings h obtained by themethod.
Figure 22:	Results for Alg. 1 on celebA dataset for mapping blond to black. Shown is a minimalcomplexity mapping g that has low discrepancy, and various mappings h obtained by the method.
Figure 23: Results for Alg. 1 on celebA dataset for mapping black to blond. Shown is a minimalcomplexity mapping g that has low discrepancy, and various mappings h obtained by the method.
Figure 24:	Results for Alg. 1 on Eyeglasses dataset for mapping eyeglasses to no eyeglasses. Shownis a minimal complexity mapping g that has low discrepancy, and various mappings h obtained bythe method.
Figure 25:	Results for Alg. 1 on Eyeglasses dataset for mapping no eyeglasses to eyeglasses. Shownis a minimal complexity mapping g that has low discrepancy, and various mappings h obtained bythe method.
Figure 26:	Results for Alg. 1 on Edges2Handbags dataset for mapping edges to handbags. Shown isa minimal complexity mapping g that has low discrepancy, and various mappings h obtained by themethod.
Figure 27:	Results for Alg. 1 on Edges2Handbags dataset for mapping handbags to edges. Shownare a minimal complexity mapping g that has low discrepancy, and various mappings h obtained bythe method.
Figure 28:	Results for Alg. 1 on Edges2Shoes dataset for mapping edges to shoes. Shown are aminimal complexity mapping g that has low discrepancy, and various mappings h obtained by themethod.
Figure 29:	Results for Alg. 1 on Edges2Shoes dataset for mapping shoes to edges. Shown are aminimal complexity mapping g that has low discrepancy, and various mappings h obtained by themethod.
Figure 30: Results for celebA Male to Female transfer for WGAN with different number of layers.
Figure 31: Results for celebA Female to Male transfer for WGAN with different number of layers.
Figure 32: Results for celebA Blond to Black transfer for WGAN with different number of layers.
Figure 33: Results for celebA Black to Blond transfer for WGAN networks with different number oflayers.
Figure 34: Results for celebA Eyeglasses to Non-Eyeglasses transfer for WGAN with differentnumber of layers.
Figure 35: Results for celebA Non-Eyeglasses to Eyeglasses transfer for WGAN with differentnumber of layers.
Figure 36: Results for Aerial View Images to Maps transfer for CycleGAN with different number oflayers.	67Published as a conference paper at ICLR 2018Figure 37: Results for Segmentations to Images transfer for CycleGAN with different number oflayers.
Figure 37: Results for Segmentations to Images transfer for CycleGAN with different number oflayers.
