title,year,conference
 The security of machine learning,2010, MachineLearning
 Measuringneural net robustness With constraints,2016, In Advances in Neural Information Processing Systems(NIPS)
 Security evaluation of pattern classifiers under attack,2014, IEEETransactions on Knowledge and Data Engineering
 Poisoning be-havioral malware clustering,2014, In Workshop on Artificial Intelligence and Security (AISec)
 Defensive distillation is not robust to adversarial examples,2016, arXiv
 Adversarial examples are not easily detected: Bypassing ten detectionmethods,2017, arXiv
 Hiddenvoice commands,2016, In USENIX Security
 Ground-truth adversarial examples,2017, arXiv
 EAD: Elastic-net attacks to deep neural networksvia adversarial examples,2017, arXiv
 Parseval networks: Improvingrobustness to adversarial examples,2017, In International Conference on Machine Learning (ICML)
 Robustphysical-world attacks on machine learning models,2017, arXiv
 cleverhans v2,2016,0
 Explaining and harnessing adversarial examples,2015, InInternational Conference on Learning Representations (ICLR)
 Delving deep into rectifiers: Surpassing human-level perfor-mance on imagenet classification,2015, arXiv preprint arXiv:1502
 Formal guarantees on the robustness of a classifier against adver-sarial manipulation,2017, In Advances in Neural Information Processing Systems (NIPS)
 Safety verification of deep neural networks,2017, InComputer Aided Verification (CAV)
 Reluplex: An efficient SMT solver forverifying deep neural networks,2017, arXiv preprint arXiv:1702
 Towards proving the adversarialrobustness of deep neural networks,2017, arXiv
 Adam: A method for stochastic optimization,2014, arXiv preprint arXiv:1412
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2017, arXiv preprint arXiv:1711
 Adversarial examples in the physical world,2016, arXiv
 Practical evasion of a learning-based classifier: A case study,2014, In Symposiumon Security and Privacy
 YALMIP: A toolbox for modeling and optimization in MArLAB,2004, In CACSD
 rowards deep learning modelsresistant to adversarial attacks,2017, arXiv
 A time-dependent Hamilton-Jacobi formulation ofreachable sets for continuous dynamic games,2005, IEEE Transactions on Automatic Control
 Biologically inspired protection of deep networks from adversarial at-tacks,2017, arXiv preprint arXiv:1703
 Paragraph: rhwarting signature learning by training mali-ciously,2006, In International Workshop on Recent Advances in Intrusion Detection
 APEX: Autonomousvehicle plan verification and execution,2016, rechnical report
 On the construction of lyapunov functions using the sum ofsquares decomposition,2002, In IEEE Conference on Decision and Control
 Analysis of non-polynomial systems using the sum of squaresdecomposition,2005, Positive polynomials in control
 rowards the science of security and privacyin machine learning,2016, arXiv
 Semidefinite programming relaxations for semialgebraic problems,2003, Mathematicalprogramming
 Classes of recursively enumerable sets and their decision problems,1953, Transactions of theAmerican Mathematical Society
 Mastering the game of go with deep neuralnetworks and tree search,2016, Nature
 An experimental study of the learnabil-ity of congestion control,2014, In SIGCOMM
 Certified defenses for data poisoning attacks,2017, In Advances inNeural Information Processing Systems (NIPS)
 Intriguingproperties of neural networks,2014, In International Conference on Learning Representations (ICLR)
 Invariant funnels around trajectories usingsum-of-squares programming,2011, IFAC Proceedings Volumes
 Ensemble adversarial training:Attacks and defenses,2017, arXiv preprint arXiv:1705
 TCP ex machina: Computer-generated congestion control,2013, InSIGCOMM
 Achievinghuman parity in conversational speech recognition,2016, arXiv
