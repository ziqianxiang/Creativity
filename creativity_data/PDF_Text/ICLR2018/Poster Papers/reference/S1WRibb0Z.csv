title,year,conference
 Analysis of individUal differences in mUltidimensional scalingvia an N-Way generalization of Eckart-YoUng decomposition,1970, Psychometrika
 ConvolUtional rectifier netWorks as generalized tensor decom-positions,2016, In International Conference on Machine Learning
 On the expressive poWer of deep learning: A tensoranalysis,2016, In Conference on Learning Theory
 The poWer of depth for feedforWard neUral netWorks,2016, In Conferenceon Learning Theory
 Learning to forget: Continual predictionWith LSTM,1999, 1999
 Speech recognition With deep recur-rent neural netWorks,2013, In Acoustics
 Foundations of the parafac procedure: models and conditions for an ”ex-planatory” multimodal factor analysis,1970, 1970
 Multilayer feedforWard netWorks are uni-versal approximators,1989, Neural networks
 Learning multiple layers of features from tiny images,2009, 2009
 HandWritten digit recognition With a back-propagation net-Work,1990, In Advances in neural information processing systems
 Exten-sions of recurrent neural network language model,2011, In Acoustics
 Exponential machines,2016, arXiv preprintarXiv:1605
 Opening the black box of deep neUral networks via informa-tion,2017, arXiv preprint arXiv:1703
 SUpervised learning with tensor networks,2016, In D
 Going deeper with convolUtions,2015, InProceedings of the IEEE conference on computer vision and pattern recognition
 Long-term forecasting Using tensor-train RNNs,2017, arXiv preprint arXiv:1711
