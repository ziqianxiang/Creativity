title,year,conference
 Adversarial transformation networks: Learning to generate adver-sarial examples,2017, arXiv preprint arXiv:1703
 Evasion attacks against machine learning at test time,2013, In Joint EuropeanConference on Machine Learning and Knowledge Discovery in Databases
 Robust optimization in machine learning,2012, InSuvrit Sra
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 Parsevalnetworks: Improving robustness to adversarial examples,2017, In International Conference on MachineLearning (ICML)
 Robust physical-world attacks on machine learning models,2017, arXivpreprint arXiv:1707
 Analysis of classifiersâ€™ robustness to adversarialperturbations,2015, arXiv preprint arXiv:1502
 Robustness of classifiers: fromadversarial to random noise,2016, In Neural Information Processing Systems (NIPS)
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations (ICLR)
 Towards deep neural network architectures robust to adversarialexamples,2014, arXiv preprint arXiv:1412
 Deep residual learning for imagerecognition,2016, In IEEE Computer Vision and Pattern Recognition (CVPR)
 Universaladversarial perturbations against semantic image segmentation,2017, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Caffe: Convolutional architecture for fast feature embedding,2014, InACM International Conference on Multimedia (MM)
 Gradient-based learning applied to documentrecognition,1998, Proceedings of the IEEE
 Network in network,2014, In International Conference onLearning Representations (ICLR)
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In IEEE Conference on Computer Vision andPattern Recognition (CVPR)
 Universaladversarial perturbations,2017, In IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Fast feature fool: A data independentapproach to universal adversarial perturbations,2017, In British Machine Vision Conference (BMVC)
 Distillation as adefense to adversarial perturbations against deep neural networks,2015, arXiv preprint arXiv:1511
 Ex-ponential expressivity in deep neural networks through transient chaos,2016, In Advances In NeuralInformation Processing Systems
 Accessorize to a crime: Realand stealthy attacks on state-of-the-art face recognition,2016, In Proceedings of the 2016 ACM SIGSACConference on Computer and Communications Security
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations (ICLR)
 Exploring the space of adversarial images,2016, IEEE InternationalJoint Conference on Neural Networks
 A boundary tilting persepective on the phenomenon of adversarialexamples,2016, arXiv preprint arXiv:1608
 Adversarial perturba-tions of deep neural networks,2016, Perturbations
