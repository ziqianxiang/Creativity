title,year,conference
 High-dimensional dynamics of generalization error in neuralnetworks,2017, arXiv preprint arXiv:1710
 Spectrally-normalized margin bounds for neuralnetworks,2017, arXiv preprint arXiv:1706
 Imagenet: A large-scalehierarchical image database,2009, In Computer Vision and Pattern Recognition
 Implicit regularization in matrix factorization,2017, arXiv preprint arXiv:1705
 Identity matters in deep learning,2017, 2017
 Long short-term memory,1997, Neural computation
 Mobilenets: Efficient convolutional neural networks formobile vision aPPlications,2017, arXiv preprint arXiv:1704
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Extreme learning machine: theory andaPPlications,2006, Neurocomputing
 Binarizedneural networks,2016, In Advances in Neural Information Processing Systems 29 (NIPSâ€™16)
 Tying word vectors and word classifiers: Aloss framework for language modeling,2016, arXiv preprint arXiv:1611
 SPeeding uP convolutional neural networkswith low rank exPansions,2014, arXiv preprint arXiv:1405
 Learning multiPle layers of features from tiny images,2009, 2009
 Imagenet classification with deeP convo-lutional neural networks,2012, In Advances in neural information processing systems
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Network in network,2013, arXiv preprint arXiv:1312
 Pointer sentinel mixturemodels,2016, arXiv preprint arXiv:1609
 Regularizing and Optimizing LSTMLanguage Models,2017, arXiv preprint arXiv:1708
 Mixed precisiontraining,2017, arXiv preprint arXiv:1710
 Distributed tations ofwords and phrases and their compositionality,2013, In Advances in neural information processingsystems
 Exploring gener-alization in deep learning,2017, arXiv preprint arXiv:1706
 Universal approximation using radial-basis-function net-works,1991, Neural computation
 Using the output embedding to improve language models,2017, EACL 2017
 Weight normalization: A simple reparameterization to accel-erate training of deep neural networks,2016, In Advances in Neural Information Processing Systems
 Facenet: A unified embedding for facerecognition and clustering,2015, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Theoretical insights into the optimiza-tion landscape of over-parameterized shallow neural networks,2017, arXiv preprint arXiv:1707
 No bad local minima: Data independent training error guaranteesfor multilayer neural networks,2016, arXiv preprint arXiv:1605
 Exponentially vanishing sub-optimal local minima in multilayerneural networks,2017, arXiv preprint arXiv:1702
 The implicit bias of gradient descent on separabledata,2018, 2018
 Striving forsimplicity: The all convolutional net,2014, arXiv preprint arXiv:1412
 Revisiting unreasonable ef-fectiveness of data in deep learning era,2017, arXiv preprint arXiv:1707
 Going deeper with convolutions,2015, InProceedings of the IEEE conference on computer vision and pattern recognition
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Convolutional neural networks with low-rank regularization,2015, arXiv preprint arXiv:1511
 Attention is all you need,2017, 2017
 Diversity leads to generalization in neural networks,2016, arXivpreprint arXiv:1611
 Visualizing and understanding convolutional networks,2014, InEuropean conference on computer vision
 Understandingdeep learning requires rethinking generalization,2017, In ICLR
 Shufflenet: An extremely efficientconvolutional neural network for mobile devices,2017, arXiv preprint arXiv:1707
 Dorefa-net: Train-ing low bitwidth convolutional neural networks with low bitwidth gradients,2016, arXiv preprintarXiv:1606
