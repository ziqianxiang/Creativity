title,year,conference
 Robust optimization,2009, PrincetonUniversity Press
 Towards evaluating the robustness of neural networks,2016, arXivpreprint arXiv:1608
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, arXiv preprint arXiv:1705
 Adversarial classifica-tion,2004, In International Conference on Knowledge Discovery and Data Mining (KDD)
 Analysis of classifiersâ€™ robustness to adversarialperturbations,2015, arXiv preprint arXiv:1502
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Towards deep neural network architectures robust to adversarialexamples,2014, arXiv preprint arXiv:1412
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 A unified gradient regularization family foradversarial examples,2015, In Data Mining (ICDM)
 Deepfool: A simple andaccurate method to fool deep neural networks,2016, In 2016 IEEE Conference on Computer Vision andPattern Recognition
 Deep neural networks are easily fooled: Highconfidence predictions for unrecognizable images,2015, In IEEE Conference on Computer Vision andPattern Recognition
 On the effectiveness of defensive distillation,2016, arXivpreprint arXiv:1607
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 The limitations of deep learning in adversarial settings,2016, In IEEE EuropeanSymposium on Security and Privacy
 Towards robust deep neural networks withBANG,2016, arXiv preprint arXiv:1612
 Understanding adversarial training: Increasinglocal stability of neural nets through robust optimization,2015, arXiv preprint arXiv:1511
 Accessorize to a crime:Real and stealthy attacks on state-of-the-art face recognition,2016, In Proceedings of the 2016 ACMSIGSAC Conference on Computer and Communications Security
 Robust large margin deepneural networks,2016, arXiv preprint arXiv:1605
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Robust Large Margin Approaches for Machine Learning in AdversarialSettings,2016, PhD thesis
 Ensembleadversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 Thespace of transferable adversarial examples,2017, arXiv preprint arXiv:1704
 Contributions to the theory of statistical estimation and testing hypotheses,1939, TheAnnals of Mathematical Statistics
 Statistical decision functions which minimize the maximum risk,1945, Annals ofMathematics
 Statistical decision functions,1992, In Breakthroughs in Statistics
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
