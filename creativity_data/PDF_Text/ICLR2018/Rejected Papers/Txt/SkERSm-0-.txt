Under review as a conference paper at ICLR 2018
Preliminary theoretical troubleshooting in
Variational Autoencoder
Anonymous authors
Paper under double-blind review
Ab stract
Variational Autoencoder plays an important role in disentangled representation
learning. However, it is found facing posterior collapse problem and learning
multiple variants in one factor. What would be learned by variational autoen-
coder(VAE) and what influence the disentanglement of VAE? This paper tries to
preliminarily address VAE’s intrinsic dimension, real factor, disentanglement and
indicator issues theoretically in the idealistic situation and implementation issue
practically through noise modeling perspective in the realistic case. On intrinsic
dimension issue, due to information conservation, the idealistic VAE learns and
only learns intrinsic factor dimension. Besides, suggested by mutual information
separation property, the constraint induced by Gaussian prior to the VAE objec-
tive encourages the information sparsity in dimension. On disentanglement issue,
subsequently, inspired by information conservation theorem the clarification on
disentanglement in this paper is made. On real factor issue, due to factor equiva-
lence, the idealistic VAE possibly learns any factor set in the equivalence class. On
indicator issue, the behavior of current disentanglement metric is discussed, and
several performance indicators regarding the disentanglement and generating in-
fluence are subsequently raised to evaluate the performance of VAE model and to
supervise the used factors. On implementation issue, the experiments under noise
modeling and constraints empirically testify the theoretical analysis and also show
their own characteristic in pursuing disentanglement.
1	Introduction
Variational AutoEncoder(VAE)s (Kingma & Welling (2013), Rezende et al. (2014)) have shown
their powerful human-like abilities: modelling causal relationship, unsupervisedly extracting disen-
tangled factors/representation (Bengio et al. (2013)) and generating signals with abundant diversities
in a “latent-factor-controllable” way. Those capabilities enable the knowledge transferring through
shared causes/factors among different tasks/experiences, emphasized as the important human advan-
tages against the current machine by Lake et al. (2016) and compling with the ideal mental imagery
mechanism in memory and thinking. Benefitted from those capabilities, VAEs have been widely
applied to various applications, including disentangled representations learning of images and time
series (Higgins et al. (2016), Kulkarni et al. (2015), Mathieu et al. (2016), (Fabius & van Amersfoort
(2014)), few-shot and transfer learning (Rezende et al. (2016), Higgins et al. (2017b), Higgins et al.
(2017a)), causal relationships modeling (Louizos et al. (2017)), pixel trajectory predicting (Walker
et al. (2016)), joint multi-modal inference learning (Suzuki et al. (2016)), increasing diversity in
imitation learning (Wang et al. (2017)), generation with memory (Li et al. (2016)) and etc.
However, the lack of public theoretical study regarding the generating and inference procedure in-
duced by VAEs is tripping the research process:
•	Intrinsic Dimension Issue: Could the VAE learn the intrinsic number of factors underlying
the data?
•	Real Factor Issue: Could the VAE learn the real generating factors underlying the data or
just some fantasies?
•	Disentanglement Issue: What are the need and range induced by the word “disentangle-
ment”?
1
Under review as a conference paper at ICLR 2018
•	Indicator Issue: Could the effectiveness of current disentanglement metric be guaranteed?
All those lacks distillation would make researchers hard to effectively compute through their knowl-
edge from the experiments and incline to make some avoidable arguments and considerations.
This paper will first discuss the properties of the idealistic VAE 1 to target the aforemention issues
and then moving to
•	Implementation Issue: Could the aforemention analysis be instructive in real implemen-
tation?
For Intrinsic Dimension Issue, the information conservation theorem shows that idealistic VAE
learns and only learns the intrinsic factor dimension illustrated in Fig.(1). To Disentanglement Is-
sue, the clarification on disentanglement is subsequently made. For Real Factor Issue, the factor
equivalence properties shows that idealistic VAE possibly learns all factors in equivalent class rather
than exactly pre-specified real factors. For Indicator Issue, limitations of the current disentangle-
ment metric are analyzed and several new indicators are introduced.
After that, for Implementation Issue, we relax the discussion to the case that decoding procedure
are not deterministic through noise modeling perspective. The experiments empirically testify that
the knowledge derived form the idealistic case could be applied to the realistic sampling case and
demonstrate the behaviors of different noise assumptions as well as our indictors.
H Factor Z	Signal X	Factor Y P
Figure 1: Idealistic VAE learns and only learns the intrinsic factor dimension. The illustration of
the information conservation theorem 1. Suppose that the oracle data, denoted by random variable
x, is generated by y (with P independent unit Gaussian random variables) with a homeomorphism
mapping x = φ(y). Idealistic VAE will be forced to learn the factor z (with H independent unit
Gaussian random variables) that generates the x with a homeomorphism mapping x = ψ(z). It
yields z = ψ-1 ◦ φ(y) and y = φ-1 ◦ ψ(z). Then according to the information conservation
theorem, it must hold that H = P .
2	Gaussian-VAE Model
Gaussian-VAE (Kingma & Welling (2013), Rezende et al. (2014)) is an scalable unsupervised repre-
sentation learning model (Higgins et al. (2016)), and since Gaussian distribution can be continuously
and reversibly mapping to many other distributions, the theoretical analysis on it is also instructive
for other continuous latent factors VAE.
Gaussian-VAE assume that input x is generated by several independent Gaussian factors z, that
is pθ(Z) = N(z∣0,Ih). The generating/deCoding process is modeled as pθ(x|z) and the infer-
ence/encoding process qφ(z∣χ) is treated as the approximate posterior distribution. Both of them are
parameterized by the neural network with parameter θ and φ.
1That is, roughly, the VAE whose decoding procedure and encoding procedure are both deterministic.
2
Under review as a conference paper at ICLR 2018
In VAE setting, the approximate inference method is applied to maximizing the variational lower
bound of pθ(X) = ʃpθ(x∣z)pθ(z)dz,
L(q) =	E	logPθ(XIz)- DκL(qφ(z∣x)∣∣Pθ(Z)) ≤ logPθ(x).	⑴
Z 〜qφ(z∣χ)
2.1	Idealistic VAE
In order to get assess to aforemention issues, we will start the analysis from the idealistic situation:
An idealistic VAE model means that it can perfectly encode the signal into “used” factors and per-
fectly decode the “used” factors to original input signal and the factors follows i.i.d unit Gaussian
distribution.
The idealistic VAE discussed in this literature should also under the following the Deterministic
Assumption on qφ(XIz) andpθ(zIX). If the factors ofX are well understood, the generation process
should be deterministic, that is pθ(XIz) = δ(X = ψ(z)). We limit the consideration that qφ(zIX) =
δ(z = ψ-1 (X)) is also deterministic as well for simplicity of analysis in this paper. For more
complex situation, this consideration could be also basic and instructive.
We try to address aforemention issues by disregarding the training procedure and direct considering
the idealistic VAE’s behavior.
3	On Intrinsic Dimension Issue
In order to get asses to the intrinsic dimension issue, we will present the information conservation
theorem. It states some basic truths, e.g. two independent Gaussian and three independent Gaussian
cannot be the generating factor of each other under continuous mapping. The theorem thus further
illustrates that idealistic VAE learns and only learns the intrinsic factor dimension.
From the perspective of VAE objective, we will also show that the constraint induced by Gaussian
prior, plays the lasso on the mutual information which encourage to clip down the small informa-
tion dimension and promotes information sparsity in factors. In order to derive this perspective,
the mutual information separation theorem and objective decomposition theorem are subsequently
raised.
3.1	Information Conservation
Theorem 1 (Information Conservation). Suppose that z = (zι, ∙∙∙ , zH) and y = (yι, .…，yp)
are sets of H and P (H 6= P) independent unit Gaussian random variables, respectively, then these
two sets of random variables can not be the generating factor of each other. That is, there are no
continuous functions f : RH → RP and g : RP → RH such that
z = g(y) and y = f (z).
Proof in Appendix B. The principle of the theorem is visually illustrated in Fig. 1.
3.2	Separation of the Mutual Information
The mutual information regarding the factors learned by the inference/encoder network and the
signal X can be a good quantity for evaluating the generating influence. That is,
Iencoder (X; z) =	E	DKL (qφ (z IX)IIqφ (z)).	(2)
X 〜Pdata(X)
In order to understand and estimate which factor of the VAE was learnt and influenced the generating
process, IenCOder (x; zh) Can be taken as a rational indicator2. If We assume that z1,z2,…，zH is
conditional independent given X3, it can yield a useful result as the following.
2If Iencoder (x; zh) = 0, it yields x and zh are independent With each other. The bigger Iencoder (x; zh),
the more information zh conveys regarding x.
3It follows the real implementation assumption that ∑ζ∣χ (x) = diag(σzi(x), ∙∙∙ , σzH(x)).
3
Under review as a conference paper at ICLR 2018
Theorem 2	(Mutual Information Separation). Let zι, ∙∙∙ ,zh be independent unit Gaussian distri-
bution, and z1,z2,…,zh be Conditional independent g^ven X. Then
I(zι,…，ZH； x) = Ez(zh； x).	(3)
h=1
Proof in Appendix B. This theorem suggests that if the learnt q©(Z) can factorize and the qφ(z∣χ)
can factorize, then the consideration of each Iencoder (zh; x) won’t be excess or lose information.
Besides, when those term comes in the optimization objective, then it can start the negotiation be-
tween the information preservation and dimension reduction and play the role of lasso that clip down
the factor in dimension with small mutual information.
Theorem 3	(Objective Decomposition). The terminology follows the aforemention definitions and
if the involved KL-divergence and mutual information is well defined, then
E	DκL(qφ(z∖x)∖∖Pθ (Z)) = Iencoder(X； Z) + D KL(qφ(z)∣∣Pθ (，)).	(4)
X 〜Pdata(X)
Proof in Appendix B. The theorem demonstrates that the second term in variation lower bound in
Eq. (11) is capable of controlling both the mutual information of x and Z induced by the encoder
network as well as the similarity of the learnt qφ(Z) and the prior pθ (Z). Further, the theorem
suggests that it possesses the lasso capacity of clipping down the non-intrinsic factor dimension to
some extent, visually demonstrated in Fig.(2).
(Sle4NX)电。公
Thickness
Rotation
Round
Figure 2: The sparsity of mutual information occurs; IenCOder (x； Zh) determines the “used”
factors; disentangled VAE pursues the intrinsic factors dimensions; generating factor exists e-
quivalence class. Noise learning β-VAE (β = 10, equivalent σ2 = 0.112):IenCoder (x； Zh), σ22κ and
qualitatively influential factor traversals. The top pulse subgraph: IenCoder(x； Zh) of each factor. The
bottom reverse pulse subgraph: the estimated variance σz2 of each factor. The montages: influential
factor traversals. We select those factor traversals with visually most interpretable/comprehensive
effects to present and the whole influential factor traversals are listed in appendix 13. The phe-
nomenon of the multiple semantic change induced by the same learnt factor and the encoding of
same semantic among different learnt factor tallies with factor equivalence class theorem 4. The
similar plot of its counterpart with specified normalized noise can be found in Fig.(16) in Appendix.
80
60
Generating Factor Index
100	120
5
V
4 On Disentanglement Issue
Inspiration on Disentanglement: According to the information conservation theorem 1, the in-
dependent unit Gaussian factor assumption forms a strong inductive bias and facilitates the model
incline to achieve most efficient coding. Under this assumption, the number of the learnt “used” fac-
tors of idealistic VAE should be the same as the true factors number under some assumptions such
as the learnt qφ(Z) should equalpθ(Z) and decode/encode process is continuous and reversible. Em-
pirically, sometimes, though the number latent of factors sometimes is pre-specified larger, only a
4
Under review as a conference paper at ICLR 2018
small amount of unit Gaussian variables regarding the factors of VAE have been used while qφ(z∣x)
is close to deterministic. The theorem helps provide an interpretation to explain this phenomenon.
Here, in order to avoid the ambiguity of the terminology of disentanglement in this paper, we make
the following clarification.4
• The disentanglement of the learnt representation/factors in this literature refers to two parts
depicted in Theorem 1:
-the factors are closer to be independent with each other,
-the factors incline to be able to generate the oracle signal and to be inferred
perfectly from the oracle signal through a continuous procedure/mapping.
• The “disentanglement” refers to the closeness of the learnt factors to the pre-specified inde-
pendent factors/concpets that can generate the oracle signal and be perfect inferred through
a continuous procedure/mapping such as the independent semantic/visual factors.
Therefore, the estimation for DκL(qφ(z')∖∖pθ (Z)) that reflects the divergence of the learnt factor dis-
tribution and the i.i.d. unit Gaussian prior can be good a indicator to supervise the independence of
the factors and served to quantitatively assess the disentanglement of each extracted factor, while the
similarity regarding the original signal and reconstruction place another part of the disentanglement.
The “disentanglement” will be shown hard to be obtained in an unsupervised manner. Concretely,
even in the idealistic cases, the extracted factors tend to possess the intrinsic number of latent factors
of the model, while there are still possibly large variations of these factors due to it can be obtained
only in the equivalent class induced by the pre-specified factors as proved in the next section.
5 On Real Factor Issue
As for real factor issue, Gaussian Factor Equivalence theorem, (i.e. linear orthogonal transformation
of Gaussian factor set are still gaussian factor set.), and Linear Factor Equivalence Class will be pre-
sented. They states that idealistic VAE are possibly learns any factors set in the factors equivalence
class, and we should not expect “one-to-one” correspondence by disentanglement.
5.1	Factors Equivalence
Theorem 4 (Gaussian Factor Equivalence). Suppose that Z = (zι, ∙∙∙ , ZH) is a set of H indepen-
dent unit Gaussian random variables. Let Q ∈ RH ×H be an orthogonal matrix and then y = Qz is
also a set of H independent unit Gaussian random variables. Besides, Z and y can generate each
other through a linear homeomorphism mapping.
Proof in Appendix B. This theorem implies that there are a class of unit Gaussian random variables
which can generate each other and have equivalent conservation information, as indicated by the
following theorem.
Theorem 5 (Linear Gaussian Factor Equivalence Class).
[Z] = {y∖y = QZ, Q ∈ RH×Hbe the orthogonal mapping.}
Then ∀y ∈ [Z], y is a set of H independent unit Gaussian random variables and can generate Z
through an linear homeomorphism mapping.
The theorem clarifies that if Gaussian-VAEs have an linear matrix multiplication freedom degree of
learning the factors, then the factors in the equivalence class can all be possibly learnt.
The empirically results tally with the above analysis(see Fig. 3). Suppose the visu-
al semantic concepts can be viewed as a set of independent Gaussian variables (Z =
4Notice this clarification is based on the assumption that qφ(z∣x) is deterministic. If not, then continuous
and reversible mapping of encoder constrain should be loosen and also the reversibility of the decoder should be
loosen. If we further demand the enhancement of the pattern separation and completion ability, that is, to make
the hyperspheres induced by the observation points in the factor domain fully fill up the whole compact factor
ball, then some auxiliary constrains including the restriction on mutual information Iencoder (x; z) (defined in
Section 3.2) induced by the encoder network need to be introduced.
5
Under review as a conference paper at ICLR 2018

ΓkC，亡，■
H.r∖0' ・
(a)	(b)	(c)	(d)
Figure 3: We should not expect “one-to-one” correspondence by disentanglement. One-shot
traversal & generating factor equivalence class demonstration. The images are generated by MoG-
2 β(=40) VAE trained on CelebA. The seed image is obtained out from the datasets. Each block
represents the traversal of the generating factor from [-3 + zseedh , +3 + zseedh]. (a) corresponds
to face color white-yellow & female-male change. (b) corresponds to face color white to yellow
change. (c) corresponds to background yellow to blue change. (d) corresponds to hair color white to
black & face width change. It can be seen that changing one factor results in multiple semantic factor
changes in a comprehensible manner rather than the “one-to-one” correspondence which reflexed
analysis regarding generating factor equivalence.
(zrotation, Zgender /with-glass,…)T) Which are desired to be captured and learnt by VAEs, while
the model is also possible to learn the independent factor set y = (yι,…)T = Qz in the equiv-
alence class [z]. This explains why changing one factor like y1 sometimes empirically results in
change in multiple visual concepts.
This perspective suggests that it’s actually hard to obtain the “disentangled representation” that
exactly “one-to-one” corresponds to the “independent semantic representation” even though they are
in the same equivalence class. As a result, the idealistic VAE model just tend to learn the “entangle
representation” if we do preset “oracle generating factors” belonging to the equivalent class.
However, though those conclusions might be upsetting, it seems not be biology impossible. A
neuron in hippocampus of animals was suggested to combinatorially possess several representation
capabilities. E.g., Aronov et al. (2017) found that some neurons in rat’s hippocampus involved in
spatial representation also were involved in representing sound frequencies after training rats by a
tasks that required them to use a joystick to manipulate sound in frequency continuously.
6	On Indicator Issue
6.1	Limitation of the Existing Disentanglement Metic
Higgins et al. (2016) proposed a “simulated factor” based “disentanglement” metric on the simu-
lation datasets. However, according to Gaussian factor equivalence theorem 4 that even idealistic
VAE will still learn the factors in the equivalence class, their metric could be effective sometimes
for disentanglement but might suffer instability when evaluating the VAE in different trials (detailed
in Appendix C).
Further, this metric could be hardly calculated in the real datasets to provide direct feedback of the
“disentanglement”. The reason is that it must pre-know the generating factors expected to be learnt.
6.2	Proposed indicators
In order to quantify the disentanglement performance5 as well as the Iencoder (x; z), we assume that
q* (Z) is a factorized zero mean Gaussian estimation for qΦ(z).
5Visual recognition could also provide a way to get assess to the factors equivalent class and supervise the
disentanglement. If we assume that the most of the visual concept/factors follow the assumption regarding
the “disentanglement”, it is rational to qualitatively measure the interpretability of extracted latent factors by
human perception to infer the disentanglement. Besides, previous empirical evidences of VAE applications
6
Under review as a conference paper at ICLR 2018
We can then list the indicators for assessing latent factor disentanglement:
Definition 1 (Estimation for Ex〜Pdata(X) DκL(qφ(z∖x)∖∖pθ(Z))).
1M
DκL(qφ(z∖χ]∖∖pθ(Z)) = Mf DκL(qφ(z∖χm)∖∖pθ(Z)).	⑸
Definition 2 (Estimation for Iencoder(x; z)).
1	、“*/
I encoder (X; Z) = M)： DKL (qφ(z ∖xm) ∖∖q (Z)).	(6)
m=1
Definition 3 (Estimation for Iencoder(x; Zh) which quantifies the influence of each factor).
1M
Iencoder(x； Zh) = ME DKL(qφ(zh\Xm)\\qt(zh)').	⑺
Definition 4 (Estimation for DKL(qφ(Z)∖∖pθ(Z))).
DKL(qφ(Z)∖∖pθ(Z)) = DKL(qφ(Z∖x)∖∖pθ(Z)) - Iencoder(x; Z).	(8)
Note that the above indicators 2-4 need the value of q* (z), We now introduce how to calculate this
term based on Theorem 3. Through the minimization equivalence, we know that
min E	DKL(qφ(Z∖x)∖∖Q(Z)) ⇔ min DKL(qφ(Z)∖∖Q(Z))dZ,	(9)
the q* (Z ) can then be obtained by gradient method from solving the following optimization problem.
1M
q*(Z) = argmQn M E DκL(qφ(Z∖xm)∖∖Q(Z)).	(10)
7 Implementation Issue
7.1	VAE with Noise Modeling
In order to testify the idealistic consideration in real situation, we are not going to learn all the factors
or equivalently we assume that datasets have noise6(this situation correspond to that pθ(x∖Z) is not
deterministic since the major factors Z only forms a subset of the whole factors.7), we integrate the
noise modeling into our model:
pθ(x∖Z) = N(x∖G(Z),σ2Id),
where σ2 is either manually enumerated or adaptive learned. Noise modeling can be found crucial
in influencing disentanglement in experiment since it would actually define the factors aimed to be
learnt and subsequently influence the learnt intrinsic dimension suggested by information conserva-
tion property of VAE.
7.2	Noise Modelling With Auxiliary Constraint
The entangled representation can be caused by the over-large of searching space of qφ(Z∖x).
If the learned qφ(Z) = qφ(Z∖x)pdata(x)dx has a big divergence to pθ(Z), then the VAE model
tends to learn the entangle representation as it violates the one part of the disentanglement (clar-
ified in section 4). Actually, in the VAE model, what we want is to search in the space that
(Higgins et al. (2016), Higgins et al. (2017b), Larsen et al. (2015), Mathieu et al. (2016)) suggest it an effective
way.
6Noise can be viewed as the generating factor that we are not interested in.
7Notice the indeterministic pθ(x|z) could lead to the indeterministic pθ(z∣x), but since the minor factors
are supposed to have less influence on x, it could not bother the deduction using the knowledge we derived too
much.
7
Under review as a conference paper at ICLR 2018
qφ (z) is possibly similar to pθ (z) 8. By implementing this ideal, we add auxiliary upper bound
Ex〜Pdata(X) DκL(qφ(z∣x)l∣Pθ(Z)) (detailed in Theorem 3) of DκL(qφ(z)∣∣pθ(Z)) to the original
objective. This equivalently leads to the approach of β-VAE raised by Higgins et al. (2016).
sup E	L(qφ(z∣x)) - (β - 1)DκL(qφ(z∣x)∣∣Pθ(Z))
φ,θ X 〜Pdata(X)
=E E	log pθ (XIZ)- βDκL(qφ(z∣χ)l∣Pθ (Z))	(11)
X〜Pdata(X) Z〜qφ(z∣x)
where β > 1.
7.2. 1 RELATION OF VAE AND β-VAE UNDER GAUSSIAN NOISE ASSUMPTION WHEN σ2 IS
pre-specified
Equivalent objective of σ2 pre-specified Gaussian noise VAE:
E ∣∣x - G(z)∣∣2 - 2σ2DκL(qφ(Z∣x)∣∣pθ(z)).
Z 〜qφ(z∣X)
Equivalent objective of σ2 pre-specified as σP2re Gaussian noise β-VAE:
E l∣x - G(z)∣2 - 2βσpreDκL(qφ(Z∣x)∣∣Pθ(z)),
Z 〜qφ(z∣X)
where we call βσ2re the normalized variance.
Pre
It’s shown that when the σ 2 is pre-specified, manually tuning it is the same as manually tuning β
with a fixed σP2re (for example σP2re = 1) under Gaussian noise assumption. This equivalence saves
our time for extra experiment studying the behaviors of this two cases and we call those two case
noise specified β-VAE.
8 Experiment
8.1	Dataset
MNIST is a database of handwritten digits (Lcun et al. (1998)). CelebA (Liu et al. (2015)) is a large-
scale celebfaces attributes datasets and only its images are used in our experiments. More details
are in Appendix D. The extensive comparison of Gaussian-noise modeling β-VAE and Gaussian-
noise with specified variance (β)-VAE is made on MNIST based on our indicators to exploring the
disentanglement as well as to testify the theorem and analysis from the idealistic case to the realistic
sampling case. The experiments on CelebA will be auxiliary to further support the generating factor
equivalence class theorem9.
By setting β as different values, we compare the performance of β-VAE with and without pre-
specified noise on MNIST. We specifically listed the result of β(=1)-VAE in all cases. More details
can be found in Appendix D.2.
8.1.1	On Implementation Issue
•	Noise modeling/specification influence the disentanglement.
The noise specifications and modeling significantly influence the model evidence quantitatively and
reconstruction qualitatively, as clearly shown in Fig. (4).
The noise specifications significantly influence the divergence regarding qφ(Z) andpθ(Z) and noise
specified and noise learning β-VAE achieve similar disentanglement quantitatively based on the
similar indicator behaviours of DκL(qφ(Z)∣∣Pθ (Z)) m Fig. (5a) and the number of normal variance
factors Fig. (5b) in regard to the normalized variance.
8 Jensen Shannon Divergence and other integral probability metric which can be good choice and directly
be optimized through a adversarial format (Makhzani et al. (2015)) as well. However, in practice, we were
defeated by the unstability of training GAN-like model.
9The noise assumption is slightly changed into mixture of gaussian in Appendix A.2 for CelebA.
8
Under review as a conference paper at ICLR 2018
(SlBU) PUno8 ^φ⅛>01- -BUo4B∙⊂B> -Bz>≡dlu .
Variance(/"Equivalent Variance for P-VAE( β Cpre/扇「水)
1 O 1 2 3
,0,°,°,γw,γ
(Ssu) ((Z)d=(Z)b,*0 pφse=sj
Figure 4: Noise specification/modeling influence the learned hypothesis and the reconstruction.
Blue Line: the EVBL (defined in Appendix A.1) of different specified σ2 VAE [correspond to pre-
specified σp2re β-VAE illustrated in Section 7.2.1 with equivalent σ2 = βσp2re] . Green Line: the
EVLB of noise learning β-VAE with different specified β [normalized to σ2 = βσl2earnt for con-
venient comparing] . Green Pentagram: the EVLB of Gaussian noise learning VAE. Other Figures:
their reconstructions on the testing set. The bigger EVLB, the better hypothesis that model learnt.
Noise Specified VAE(Or Noise Specifiedl(J-VAE) [Vary <τ2]
Noise Learning ∕3-VAE[Vary 向	1
Noise Learning VAE
10-3	10-2	10-1	10o
r2yEqUivalentVarianCe for 0-VAE(∕3，3.用)
(a)
4 2 0 8 6 4 2
UA U) SJOeL -O」9qEn
, NOiSe Specified VAE(Or NOiSe SPeCifed 炉VAE) [Vary σ2]
SNOiSe Learning ,-VAE[Vary ,
Noise Learning VAE
10-4	10-3	10-2	10-1	10o
VarianCe(02)/EqUivalent Variance for f9-VAE(∕3 σ2rθ∕∣θarnt)
(b)
阍■日臼EB-
Figure 5: Noise SpeCification/modeling influence dιsentanglement∙(a) DκL(qφ(z)∣∣Pθ(Z)) of d-
ifferent VAE models & (b) Number of normal-variance factors of different VAE models (with 128
factors.)
•	Auxiliary constraints can influence the disentanglement in a different way.
The prominent difference induced by auxiliary constraints would be its stronger suppression on
Iencoder(x; z) and the number of influential factors although changing the noise level also possess
this capability indirectly. It’s somewhat obvious to see and compare value of different indictors under
the different β setting by sliding on the green/blue line. The bigger β, the lower DκL(qφ(z川pθ(Z))
and roughly the better reconstruction and hypothesis learnt. However, it’s more interesting that in re-
gard to the normalized variance, noise learning β-VAE enhances the suppression on Iencoder(x; Z),
as depicted in Fig. (6a) and that is comprehensible since β-VAE is minimizing the auxiliary con-
straints both Iencoder(x; Z) + DKL(q(Z)||p(Z)) based on Theorem 3.
8.1.2	On Intrinsic Dimension Issue
• Iencoder (x; Zh) effectively determines the “used” factors and VAEs incline to learn
the intrinsic factor dimension in realistic sampling case when the disentanglement
achieves in some extent.
9
Under review as a conference paper at ICLR 2018
(a)	(b)
Figure 6: β-VAE is more suppressive on the mutual information. (a) Iencoder(x; z) of different
VAE models & (b) Number of influential generators of different VAE models
As shown in Fig. (2) and (16), the indicator Iencoder(x; zh) determines the “used” factors. Accord-
ing to those figures, under the suitable noise assumption, VAEs automatically suppress the auxiliary
factors and learn the intrinsic factor dimension as it still capable to have good reconstruct abilities
and its DKL(qφ(z)∖∖pθ(Z)) closer to zero. This phenomenon has already suggested by the informa-
tion conservation theorem 1.
8.1.3 On Real Factor Issue
• Factor equivalence is generally hold and VAEs possibly learn any factor set in the
equivalence class.
The reflections of the generating equivalence properties 5.1, that is, single factor could result in
multiple semantic concepts change and same semantic concept could be encoded in different factors,
are again well demonstrated by Fig. (7), Fig. (2), Fig. (16) and Table 1.
Table 1: Variants and factors correspondence on CelebA ( MoG-2 β(=40)-VAE)
Variant	glass	height	blue to yellow*	black to white*	half bright half gloomy*
Factor	73	37,45	13,96,40,45,118	7	110
Variant	face(big to small)	lighting	face lighting	skin color(white to yellow)	
Factor	63,77,82	73,90	120,110		102,96,28,63,82
					
Variant	head direction neck length		hair color	gender	mouth open to close
Factor	26,31	102	120	-	28	8
* represents background change.
9	Future Work
From the perspective of representation learning:
•	It is interesting that the topology properties of oracle signal are used to obtain the proof for
the information conservation theorem. Other situations including that data owns several
connected components can be further considered and would uncover the efficient coding
properties of discrete factors.
•	When qφ(z∖x) is far from deterministic, the discussion would be crucial for many other
general purposes induced by word disentanglement. Those study may further extend to
the case that data containing different dimension manifolds and to the core VAEs’ pattern
separation/completion/generalization capabilities.
Acknowledgments
Thanks for Haodong Sun( Georgia Tech)’s twice greeting me after this paper being rejected.
一一 一∖∖. Here is the acknowledgment to memorize our relationship.;-)
10
Under review as a conference paper at ICLR 2018
References
Dmitriy Aronov, Rhino Nevers, and David W Tank. Mapping of a non-spatial dimension by the
hippocampal/entorhinal circuit. Nature, 543(7647):719, 2017.
Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new
perspectives. IEEE transactions on pattern analysis and machine intelligence, 35(8):1798-1828,
2013.
Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Info-
gan: Interpretable representation learning by information maximizing generative adversarial nets.
CoRR, abs/1606.03657, 2016. URL http://arxiv.org/abs/1606.03657.
Otto Fabius and Joost R van Amersfoort. Variational recurrent auto-encoders. arXiv preprint arX-
iv:1412.6581, 2014.
A.S. Georghiades, P.N. Belhumeur, and D.J. Kriegman. From few to many: Illumination cone
models for face recognition under variable lighting and pose. IEEE Trans. Pattern Anal. Mach.
Intelligence, 23(6):643-660, 2001.
Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Jimenez Rezende, and Daan Wierstra. Draw: A
recurrent neural network for image generation. arXiv preprint arXiv:1502.04623, 2015.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick,
Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a
constrained variational framework. 2016.
Irina Higgins, Arka Pal, Andrei A Rusu, Loic Matthey, Christopher P Burgess, Alexander Pritzel,
Matthew Botvinick, Charles Blundell, and Alexander Lerchner. Darla: Improving zero-shot trans-
fer in reinforcement learning. arXiv preprint arXiv:1707.08475, 2017a.
Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, Christopher P Burgess, Matthew
Botvinick, Demis Hassabis, and Alexander Lerchner. Scan: Learning abstract hierarchical com-
positional visual concepts. arXiv preprint arXiv:1707.03389, 2017b.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arX-
iv:1312.6114, 2013.
Diederik P Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, and Max Welling.
Improved variational inference with inverse autoregressive flow. In Advances in Neural Informa-
tion Processing Systems, pp. 4743-4751, 2016.
Tejas D Kulkarni, William F Whitney, Pushmeet Kohli, and Josh Tenenbaum. Deep convolutional
inverse graphics network. In Advances in Neural Information Processing Systems, pp. 2539-2547,
2015.
Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building
machines that learn and think like people. Behavioral and Brain Sciences, pp. 1-101, 2016.
Anders Boesen Lindbo Larsen, S0ren Kaae S0nderby, Hugo Larochelle, and Ole Winther. AUtoen-
coding beyond pixels using a learned similarity metric. arXiv preprint arXiv:1512.09300, 2015.
Yann Lcun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
K.C. Lee, J. Ho, and D. Kriegman. Acquiring linear subspaces for face recognition under variable
lighting. IEEE Trans. Pattern Anal. Mach. Intelligence, 27(5):684-698, 2005.
Chongxuan Li, Jun Zhu, and Bo Zhang. Learning to generate with memory. In International
Conference on Machine Learning, pp. 1177-1186, 2016.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild.
In Proceedings of the IEEE International Conference on Computer Vision, pp. 3730-3738, 2015.
11
Under review as a conference paper at ICLR 2018
Christos Louizos, Uri Shalit, Joris Mooij, David Sontag, Richard Zemel, and Max Welling. Causal
effect inference with deep latent-variable models. arXiv preprint arXiv:1705.08821, 2017.
Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, and Ian J. Goodfellow. Adversarial autoen-
coders. CoRR, abs/1511.05644, 2015. URL http://arxiv.org/abs/1511.05644.
Michael F Mathieu, Junbo Jake Zhao, Junbo Zhao, Aditya Ramesh, Pablo Sprechmann, and Yann
LeCun. Disentangling factors of variation in deep representation using adversarial training. In
Advances in Neural Information Processing Systems, pp. 5040-5048, 2016.
Deyu Meng and Fernando De La Torre. Robust matrix factorization with unknown noise. In IEEE
International Conference on Computer Vision, pp. 1337-1344, 2014.
Tobias Plotz and Stefan Roth. Benchmarking denoising algorithms with real photographs. CoRR,
abs/1707.01313, 2017. URL http://arxiv.org/abs/1707.01313.
Danilo Rezende, Ivo Danihelka, Karol Gregor, Daan Wierstra, et al. One-shot generalization in deep
generative models. In International Conference on Machine Learning, pp. 1521-1529, 2016.
Danilo Jimenez Rezende and Shakir Mohamed. Variational inference with normalizing flows. arXiv
preprint arXiv:1505.05770, 2015.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and
approximate inference in deep generative models. arXiv preprint arXiv:1401.4082, 2014.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.
Improved techniques for training gans. In Advances in Neural Information Processing Systems,
pp. 2234-2242, 2016.
Masahiro Suzuki, Kotaro Nakayama, and Yutaka Matsuo. Joint multimodal learning with deep
generative models. arXiv preprint arXiv:1611.01891, 2016.
Jacob Walker, Carl Doersch, Abhinav Gupta, and Martial Hebert. An uncertain future: Forecasting
from static images using variational autoencoders. In European Conference on Computer Vision,
pp. 835-851. Springer, 2016.
Ziyu Wang, Josh Merel, Scott Reed, Greg Wayne, Nando de Freitas, and Nicolas Heess. Robust
imitation of diverse behaviors. arXiv preprint arXiv:1707.02747, 2017.
Qian Zhao, Deyu Meng, Zongben Xu, Wangmeng Zuo, and Lei Zhang. Robust principal component
analysis with complex noise. In International Conference on Machine Learning, pp. 55-63, 2014.
Shengjia Zhao, Jiaming Song, and Stefano Ermon. Learning hierarchical features from generative
models. arXiv preprint arXiv:1702.08396, 2017.
A Appendix: Noise Modeling Deduction
A. 1 Gaussian Noise Deduction
The VAE objective (i.e., the variational lower bound) can be treated as function of the θ and φ where
noise variance parameters σ2 are contained in θ,
L(θ,φ,xm) =	E	logpθ(xm∣z) - DκL(qφ(z∣xm)∣∣Pθ(z)).	(12)
z^qφ(z∖xm)
Here the SGVB estimator in (Kmgma & Welling (2013)), LB(θ,φ,xm)	=
[L PL=Ilogpθ(χm∣zl)] - DκL(qφ(z∣χm)∣∣Pθ(Z)) is used. Note that the noise variance σ2
is also taken as an optimization variable in the model, making the model capable of better adapting
noise variation of data in practical cases in a totally automatic way, instead of a manually set
manner.
12
Under review as a conference paper at ICLR 2018
Given multiple data points from a dataset X, we can construct an estimator of the mean marginal
likelihood lower bound of the full dataset, based on minibatches
1M
LM(θ,φ,XM) = IM ELB(θ,φ,xm),	(13)
m=1
where the minibatch XM = {xm }mM=1 is a randomly drawn sample set of M datapoints from the
full dataset X. Such a lower bound also constitutes an important indicator for model evidence in
latter experiment. We call it the empirical variational lower bound (EVLB) in the following.
Note that LB (θ, φ, xm) ' L(θ, φ, xm) and we can deduce that
EM(θ,φ,XM) '	E	L(θ,φ,x)
XcJpdata(X)
≤ E	logpθ(x) ≤ E	log pdata (x).	(14)
Xcpdata(X)	Xcpdata(X)
The last inequality holds due to DKL (Pdata (x) ∣∣pθ (x)) ≥ 0.
The alternative optimization strategy can be readily utilized to design the algorithm for solving the
model by iteratively updating the noise parameter and the network ones. During the optimization
process, the objective can be monotonically increasing, and thus the algorithm can be guaranteed to
be convergent.
The algorithm is summarized as follows:
Optimization for parameters except σ2 :
Optimization for σ2: σ2 = P』1 Pm=IdML-G(Z，)k2. (Close form solution in regard to
LM (θ, φ,x m ).)
Direct gradient method to the transformed variable Iogsimga = log σ ∈ R can be implemented to
lift the lower bound LM as a result to increase the likelihood as well.
A.2 MoG Noise Deduction
The noise ε in real situation might be more complex than a simple Gaussian, like that existed in real
photographs (Plotz & Roth (2017)). We thus try to further ameliorate the noise setting as a mixture
of Gaussian(MoG) noise. Such noise modeling strategy has been widely verified to be effective
in applications, like matrix factorization (Meng & Torre (2014)) and robust principal component
analysis (Zhao et al. (2014)). That is, we assume that
K
ε 〜X∏kN(0,σ2).	(15)
k=1
Let cd ∈ {0, 1}K be the latent indicator random one-hot variable, PkK=1 cdk = 1, for the MoG-
noise component of pixel indexed by d. Let Π = [∏ι,…，∏k] and Σ = [σ2,…，σK] be the ratio
and variance of each component, respectively. Let Π, Σ be contained in θ . The conditional joint
distribution turns to be
K
Pθ(cd,Xd∣z) = Y ∏kdkN(xd∣G(z)d,σk)cdk.	(16)
k=1
The posterior distribution qφ(z, c|x) can be factorized as q@(z|x)q(c|x, z), where qφ(z∣χ) will be
direct learnt and the alternative of q(c|x, z), q(c|x, e) will be set to the last step pθ(c|x, e) in regard
to EM procedure. The lower bound of log pθ (x) is then reformulated as follows:
L(qφ(z, c∣x)) = E	E	logPθ(x,c∣z) + H(q(c∣x,z)) -DκL(qφ(z∣x)∣∣Pθ(z)). (17)
Z〜qφ(Z∣x) C〜q(W∣x,Z=z)
13
Under review as a conference paper at ICLR 2018
Similar to the Gaussian case, the reparamerization trick is implemented,
L(q(c|x, e), φ, θ, xm)
= E E	logPθ(x,c∣Z) + H(q(c∣x,Z))- DκL(qφ(z∖x)∖∖pθ(z)),	(18)
e〜N(0,1) C〜q(W∣x,e)
where Z = En(X) + ∑z∣χ1∕2(x)e.
By utilizing the SGVB estimator, we get,
LB(q(c∖x,e),φ,θ,xm) = B XT E	logpθ(Xm,c∖zm,)
L 1=1 C 〜q(W∣xm,e(I))
+H(q(c∖Xm, e(l)))] -DKL(qφ(z∖Xm)∖∖pθ(z)).	(19)
Given an input dataset X, we can then construct an estimator to the mean marginal likelihood lower
bound of the full dataset, based on minibatches, as follows:
1M
LM(q(c∖x,e),θ,φ,XM) = M 二 LB(q(c∖x,e),θ,φ,xm),	(20)
where zm,l = En(Xm) + ∑z∣χ1∕2(xm)e(I) and the minibatch XM = {xm}M=ιis a randomly drawn
sample of M datapoints from the full dataset X.
Then let
K
pθooldld(cd, Xd∖zold) = Y πkoldCdkN (Xd∖Gold(zold)d, σkold)Cdk,	(21)
k=1
where ZOld = Enold(X) + ∑0jX1∕2(x)e, and We can get
pθooldld(cd∖X,zold)
Poodd (cd,χd∖ Zold)
P Poodd (cd,χd∖Zold)
Cd
(22)
The EM algorithm can be naturally employed to solve the model. The implementation steps are
listed as follows:
Step 1. Expectation Step.
Set q(c∖xm, e(l)) = Poldd(c∖xm, Enold(Xm) + ΣolX(xm)e(l)) i = 1,…，m, l = 1,…，L.
Calculate the expectation of the latent variable c:
E(cdmlk ) = γdmlk
∏ N (XmIG(Zm,l)d,σ2)
PL=1 PM=1 TkN(XmG(ZmDd,σk
(23)
where Zm,l : Zmdl = EnoId(Xm) + ∑ZlX(Xm)e(l).
The Objective in Maximization Step is obtained as the following,
1M
LM(q(c∖X,e),θ,φ,Xm) = M- ^-DκL(qφ(Z∖Xm)∖∖pθ(Z))
M i=1
L	KD	m
+ L XH(qold(c∖Xm,e(l)))+ XXγdmlk [
l=1	k=1 d=1
+ 2 lοg(2π)σk +ln ∏k].
(24)
Step 2. Maximization Step:
14
Under review as a conference paper at ICLR 2018
Fix: q(c|x, e) determined in the Expectation Step.
M	LKD
Mm X -DκL(qφ(z∣xm)l∣Pθ (Z))+L XXXγdmlk [
ML
i=1	l=1 k=1 d=1
(xdm - G(zm,l)d)2	1	2
--------------L+2 log(2∏)σ2 +ln∏k].
2σ2
(25)
Update [Π, Σ] and {θ, Φ}∕[∏, ∑] by alternative optimization strategy.
Update Π, Σ: note here zm,l : Zmd = Enod(Xm) + ∑0jX(χm)e(l), and We can easily get the
closed-form updating formula for these parameters:
Nk = X Ydmlk	Kk = PKNk N	σ2 = N X Ydmlk (Xm - G(Zmdl)d)2∙	(26)
d,m,l	k=1 k	k d,m,l
Update {θ, φ}∕[Π, Σ]: gradient methods With respect to {θ, φ}∕[Π, Σ]. Note here Zm,l = En(Xm)+
∑z∣x(xm)eQ
The algorithm can then be summarized as folloWs:
1.	Initialize the coefficient of {θ, φ}∕[Π, Σ] and the coefficient of noise ε: Π,Σ.
2.	Sample e from N(0, IH) to obtain eι,…，eM [One for each element sample in the mini
batch in the next step (L here is set to 1)].
3.	Sample a mini batch XM from pdata (X).
4.	Implement EM algorithms as aforementioned (approximate inference for q(c, Z|X)):
Expectation: calculate Ydmk .
Maximization: update [Π, Σ], Update {θ, φ}∕[Π, Σ] With gradient methods.
5.	Goto 3: Until Trigger End-Criterion.
B Appendix: Proof
Proof. For theorem 1. Proof by Contradiction. Suppose those tWo function exist, and We Will shoW
that they Will be inverse mapping of each other and the homeomorphism mapping of RH and RP .
Since RH and RP have different topology structures (P 6= H), the homeomorphism mapping Will
not exist.
Z = g(y) = g(f (Z)) ∀Z ∈ RH ⇒ g ◦ f = IH
y = f(Z) = f (g(X)) ∀y ∈ RP ⇒ f ◦g = IP
Since both f and g are continuous, there is a homeomorphism mapping betWeen RH and RP and it
leads to the contradiction.	口
Proof. For theorem 4. We only need to test the mean and variance of y.
E(y) = E(QZ) = Q E(Z) =0
Cov(y, y) = QCov(Z, Z)QT = QIQT =I
Therefore, y is another set of H independent unit Gaussian random variables. Since X = QTy, Z
and y can generate each other with an linear homeomorphism mapping.	口
Proof. For theorem 2,
I(zι,…，ZH； X)= /p(zι,…，ZH,x)log PpZZI)-ZzHp(X) dzι ... dZHdx
15
Under review as a conference paper at ICLR 2018
/P(Z1, ∙ ∙
,ZH, x) log "hH1 P(zh⑻ dz1 …dzHdx =	Zp(zh, x) log P(Zh X dzhdx
h=1 p(zh)	h=1	p(zh)
H
I(Zh; x).
h=1
□
Proof. For theorem 3.
XJL(X) DKL(qφ(Z⑻帆(Z)) = ∕qφ(zlX)Pdata(X)⅛S⅛f dx
Zqφ(z∣χ)pdata(χ) qφφZZχpραaaaXχ) ⅛⅛ dx=Iencoder E ^+DK/。(Z)M(Z)).
(27)
□
B.1 Auxiliary Explanations for Indicators
Corollary 1. The terminology follows the aforemention definitions and if the involved KL-
divergence and mutual information be well defined then
E	DKL(qφ(Z∣x)∣∣q*(Z)) = Iencoder (x； Z) + DKL (q。(z) ||q* (z)) .	(28)
X 〜Pdata(X)
The proof of corollary 1 is the same as that of theorem 3. This corollary suggests that the estimation
in definition 2 provides another upper bound for the capacity of the encoder network. Empirically,
this estimation is a much tighter estimation than using the estimation in definition 1.
Corollary 2. The terminology follows the aforemention definitions and if the involved KL-
divergence and mutual information be well defined then
E	DKL(qφ(Z∣x)l∣Pθ(z)) - E	DKL(qφ(Z∣x)l∣q*(Z))
X 〜Pdata(X)	X 〜Pdata(X)
=DKL(q。(Z)||pe(Z))- DKL(q。(Z)||q*(Z)) ≤ DKL(qφ(Z)||Pe(Z)).	(29)
The corollary is an direct result of theorem 3 and corollary 1. It suggests that the estimation in
definition 4 is a lower bound for DKL(qφ(Z) ∣∣pθ(z)).
Definition 5 (Another Estimation for DKL (qφ(z)∣∣pθ (z))).
D KL(q。(Z)||Pe (z)) = DKL(q*(Z)||pe(Z)).	(3O)
Empirically, DKL(qφ(z)∣∣pθ(z)) and DKL(qφ(z)∣∣pθ(z)) shown the same estimation results on M-
NIST.
Definition 6 (Another estimation for Iencoder (x; Z)).
1M
Iencoder (x； Z) = -DKL (q* (z) ∣∣Pθ(z)) + ME DKL (qφ(z^m) ∣∣Pθ(z)) .	(31)
Definition 7 (Another estimation for Iencoder(x; Zh) which quantifies the influence of each factor).
1M
Iencoder (x； Zh) = -DKL(q (Zh) Mpθ(Zh)) + 'M7〉: DKL (qφ(ZhIXm) ||p6 (Zh)).	(32)
16
Under review as a conference paper at ICLR 2018
C Appendix: Analysis on the “Disentanglement” Metric raised in
β-VAE (HIGGINS ET AL. (2016))
The terminology inherits those in the β-VAE paper. The main idea of that “disentanglement” metric
is to create a statistic point zdiff relevant to the model for each simulated factor respectively and
then to use a linear classifier to project the statistic point to the corresponding index of the simulated
factor. If the statistic points induced by the model are easy to be separated then the model is thought
to learn “disentangled” representation.
Here, we will argue that even for the idealistic VAE model that follows the disentanglement condi-
tons 4 could still receive bad score under that performance metric in some situations.
Suppose that the true simulated factors v follows N (0, IH). Then the learnt “used”10 factor z can
be in the equivalence class [v] according to theorem 4. Concretely, there exists an orthogonal trans-
formation Q such that z = Qv.
Suppose that the simulated factors with index y of v is fixed. Suppose vy1-fixed and vy2-fixed are
two random variable representing the samples from the y-fixed v . Then the factors inferred by the
idealistic VAE turns to be z1 = Qvy1-fixed and z2 = Qvy2-fixed.
In order to calculate the statistic point zdiff (y) = E |z1 - z2|, we first calculate the mean and
variance of (z1 - z2).
E(z1 - z2) = Q E(vy1-fixed - vy2-fixed) = 0	(33)
V ar(z -z ) = V ar(Q(vy-fixed-vy-fixed)) = QCov(vy-fixed-vy-fixed, vy-fixed-vy-fixed)Q
=Qdiag(2 …，2,0y, 2, ∙∙∙ , 2)QT = 2I - Qdiage,…，。,Zy, 0,…，0)QT = 2I - 2qy .
(34)
Therefore, zdiff (y) can be obtained through the diagonal value of 2I - 2qyqyT. That is,
Zdiff (y) = E(|z1 - z2|) = 2 W(J (1 - q2ι),…，q∕(1 - qy2H ))T.	(35)
From the above equation, the location of statistic point is unique determined by (qyι, ∙∙∙ , qy2H).
When (q2ι,…，qy2H) is close to the vertex of the unit cubic for each y then all the statistic points
turn to be easily separated.
However, from the perspective of the objective, all the orthogonal Qs are with the same potential
to be learnt. It seems not to be with a small probability that statistic points of different indexes
(工 ɪ ʌ
take similar location. For instance, if H = 2 and Q =	λ12	then Zdiff (1) = Zdiff (2)
- - √2	√2 )
cannot be separated while the representation still follows the disentanglement conditions.
Among different trials, the Q might contribute to that “disentanglement” metric but also might not.
That explains why that metric is unstable.
D	Appendix: Experiment Details
We set L to 1, and minibatch size M to be 100 in all practices. All the pixels value have been linear
normalized in to [0,1].
D. 1 Clarification on the correction on results
We find in the last version that the code on calculating q*(z) is wrong. Concretely, the objective
of the KL-divergence of two Gaussian is incorrect calculated. That influences the estimation of
10 The auxiliary unused factor is innocuous for the subsequent analysis.
17
Under review as a conference paper at ICLR 2018
Iencoder(x； z), Iencoder(x； zh), Dkl®(z)∣∣Pθ(Z)) and。葭 but has little influence on the deter-
mination of the “used” factors. So we redo all the experiments on MNIST and delete the relevant
results regarding those wrong-calculated indictors on CelebA and Extended Yale Face B.
The new experiment results solve many our past confusions due to the wrong experiment. They are
•	Why σz2h is strongly correlated with I(x； zh)?
•	Why σz2 of the used factor is always relative small?
•	Why can VAE still learn the “disentangled” representation when the learn-
t DKL(qφ(z)∣∣Pθ(z)) is SUChbig?
Now we know that they are actually not the cases. Something better is that we find our experiment
results are more close to our theoretical analysis: when guaranteeing the reconstruction quality in
a tolerance range, the smaller DKL(qφ(z)∖∖pθ(Z)) the less “used” factors are learnt. That coincides
with information conservation theorem: the independent unit Gaussian of the factors assumption
facilitates the most efficient coding.
D.2 Mnist
We split randomly 7000 datapoints according to ratio [0.6 : 0.2 : 0.2] into training set, validation
set (no use), testing set. All the indicators and q*(z) are evaluated/calculated on 10000 datapoints
belonging to the testing set. All the seed images used to infer latent code and to draw the traversal
come from the testing set.
In all figures of latent code traversal each block corresponds to the traversal ofa single latent variable
while keeping others fixed to either their inferred ( β-VAE, VAE). Each row represents a different
seed image used to infer the latent values in the VAE-based models. β-VAE and VAE traversal is
over the [-3, 3] range.
The assumed variance σ2 of noise specified Gaussian of VAE models is enumerated from
[0.0005, 0.001 : 0.001 : 0.012, 0.02 : 0.01 : 0.11]. The β setting for the noise learning β-VAE
is enumerated from [0.1, 0.5, 1, 2 : 2 : 18].
D.3 Extended Yale Face B (Georghiades et al. (2001), Lee et al. (2005))
We split randomly 2424 datapoints according to ratio [0.8 : 0.1 : 0.1] into training set, validation
set (no use), testing set. The model is training on the training set. All the seed images used to infer
latent code and to draw the traversal come from the 100 datapoints from the testing set.
In all figures of latent code traversal each block corresponds to the traversal ofa single latent variable
while keeping others fixed to either their inferred ( β-VAE, VAE). Each row represents a different
seed image used to infer the latent values in the VAE-based models.
β-VAE and VAE traversal is over the [-3, 3] range.
The β setting for the noise learning β-VAE is enumerated from [1, 40, 80, 120, 160].
D.4 CelebA
We split randomly roughly 200000 datapoints according to ratio [0.8 : 0.1 : 0.1] into training set,
validation set (no use), testing set. The model is training on the training set. All the indicators and
q*(z) are evaluated/calculated on 10000 datapoints selected from testing set. All the seed images
used to infer latent code and to draw the traversal come from the 100 datapoints from the testing set.
In all figures of latent code traversal each block corresponds to the traversal ofa single latent variable
while keeping others fixed to either their inferred ( β-VAE, VAE). Each row represents a different
seed image used to infer the latent values in the VAE-based models.
β-VAE and VAE traversal is over the [-3, 3] range.
The β setting for the noise learning β-VAE is enumerated from [1, 30, 40].
18
Under review as a conference paper at ICLR 2018
D.5 Network Structure
Dataset	Optimiser	Architecture	
Mnist	Adam 1e - 3 Epoch 200	Input Encoder Latents Decoder	28x28x1 Conv 32x4x4,32x4x4 (stride 2). FC 256. ReLU activation. 128 FC 256. Linear. Deconv reverse of encoder. ReLU activation.
CelebA	Adam 1e - 4 Epoch 20	Input Encoder Latents Decoder	64x64x3 Conv 32x4x4,32x4x4,64x4x4,64x4x4 (stride 2). FC 256. ReLU activation. 128/32 FC 256. Linear. Deconv reverse of encoder. ReLU activation.
Extended Yale Face B	Adam 1e - 4 Epoch 2002	Input Encoder Latents Decoder	192x168x1 Conv 32x4x4,32x4x4,64x4x4,64x4x4 (stride 2). FC 256. ReLU activation. 128 FC 256. Linear. Deconv reverse of encoder. ReLU activation.
Extended Yale Face B (Network Parameterized Noise)	Adam 1e — 4 Epoch 1460	Input Encoder Latents Decoder	192x168x1 Conv 32x4x4,32x4x4,64x4x4,64x4x4 (stride 2). FC 256. ReLU activation. 128 FC 256. Linear. Deconv reverse of encoder. ReLU activation.
E Appendix: Auxiliary Generating Picture
Note that only the factors with Iencoder (x; zh) > 0.5 are shown.
F	Appendix: Related Work on Disentanglement
VAE was proposed by Kingma & Welling (2013) and Rezende et al. (2014) to implement the effi-
cient learning and inference in directed probabilistic models regarding continuous latent variables
with intractable posterior distributions and in scalable datasets. They introduced a network infer-
ence/recoginition model to represent the approximate posterior distribution and utilized reparameter-
ization trick for stochastic joint optimization of a variational lower bound containing the parameters
of both the generative/decoder and inference/recoginition/encoder models.
After being raised, many VAE variations have been proposed to boost VAE’s capabilities in genera-
tion quality and/or disentanglement of the learned representation. In these methods, multiple efforts
were made by improving the generative and inference network structures. Typical works along this
line include the convolution/de-convolution structure raised by Kulkarni et al. (2015) and ladder
structure raised by Zhao et al. (2017)). Some other works advanced the mechanism under the VAE
generation/inference processes. Typical works include the iterative attention generation/inference
mechanism raised by Gregor et al. (2015), normalizing flow proposed by Rezende & Mohamed
(2015) that enhanced the expressive ability of the approximate posterior and its variants (Kingma
et al. (2016)).
Despite the improvement to the VAE itself, some other efforts were made by the ensemble between
GAN with VAE. E.g., Larsen et al. (2015) unified GAN and VAE to obtain a better reconstruction
and a high-level abstracts visual features embedding. Mathieu et al. (2016) also unified GAN and
VAE but put emphasis on disentangling factors of variation. GANs without auxiliary design would
learn the data distribution disregarding its noise level though suffer from unstable training and mode
collapsing (Salimans et al. (2016)) while VAEs would assume a decomposition of the noise and
oracle clean datapoint regarding the noise data with an auxiliary prior on the distribution regarding
the factors.
19
Under review as a conference paper at ICLR 2018
Besides, many efforts were made by regularization on the factor distribution or factor generating
effect. E.g., Makhzani et al. (2015) introduced an adversarial loss into the latent space of the au-
toencoder which in idealistic case could learn any kind factor/lantent distribution including those
contributing to the disentangled factors/representation. InfoGAN, raised by Chen et al. (2016), in-
troduced the infomax principle to GAN by adding an auxiliary mutual information regularization
which enabled the inference of GANs and led to a better disentangled representation as well.
Recently, there is a new VAE variation is proposed by Higgins et al. (2016) who introduced the
β-VAE framework which enhanced the constraints regarding the KL-divergence of the posterior and
prior distribution of VAE and showd a novel disentanglement performance. This method has ob-
tained a better performance as compared with conventional VAE methods, especially on its flexible
tuning a compromising a parameter beta between the KL-divergence term and the likelihood term
(the variational lower bound).
20
Under review as a conference paper at ICLR 2018
factor 7
factor
factor 13
factor 19
factor 26
factor 28
factor 29
factor 31
factor 45
factor 37
factor 40
factor 56
factor 48
factor 63
factor 65
factor 73
factor 81
factor 82
factor 88
factor 90
factor 96
factor 102
factor 110
factor 118
factor 120
Figure 7: CelebA: Generating Factors Traversal of MoG-2 β(=40)-VAE.
21
Under review as a conference paper at ICLR 2018
0.02
0.018
0.016
0.014
0.012
0.01
0.008
0.006
0.004
0.002
0
Learning AVAErVary，
2	4	6	8	10	12	14	16	18
0.35 -
NoSe Learning JSVAElValy j⅝
0.3 -
0.25
Figure 9: βσ2 of different β setting
0.2
0.15
0.1
2	4	6	8	10	12	14	16	18
Figure 8: Learned σ2 of different β setting
40	60	80
Generating Factor Index
100
120
Figure 10: Noise learning β-VAE (β = 1, equivalent σ2 = 0.00248): estimation of IenCOder (x;，h),
σh.
Generating Factor Index
100
120
Figure 11: Noise learning β-VAE (β
Iencoder
(x; zh), σh.
0.5, equivalent σ2
0.00086):
estimation of
22
Under review as a conference paper at ICLR 2018
IaiaEIBllaEnaEKaIa ElEIEIElBjIEllaElMa
factor 2
factor 3
ElEIEI 向E向EEI iaiaɪa囱 ⅛i⅞iei回El
ħqo□bqqb□□ □q□bqq□□□□
∏∏∏∏∏∏∏∏∏∏ HHHiannnnnn
QQQDQQQQDQ DDQQQQQQBH
□O□E10E10E1E10 HHHH□H□ODI3
口切麴魏盟麴町魏巍粉切切切口口口功瞰口翳
□□□□□□□□□□ □□□□□□□oo□
ΠΠΠΠΠΠBΠΠH □□□□E1E]E1E]QΠ
HHBQΞHQHΞQ 麴器蠹遹爆CIEKlEn3
CT3P3CT⅞¾¾apaBa □□□E3QE3QBBH
ElEKKKIEIEKKKI EIElEEElEIlaiaIaia
factor 11
factor 12
EEEElElEliaBnn EIEIEIEIEIEIQQQB
ΞΞΞΞΞQHHHH ΠΠΠΠQQ□□□□
ΞΞΞBQBΠΠΠΠ E1E1ΠΠΠΠΠΠIlli
ΞΞBSQQDnnn ξξξξξħhqqq
因国阅倒ElEJElEKKl EIEl□El□n∏βHH
QQQE1E]E1C]□Q∏ EtElQDDDDElESQ
Ξ□□ΞΞSE3E1E1E1 ElElElElQElEiSQS
ΞΞΞΞQE3□HH□ ElEKiHHBQHHH
国以图囱回B3l¾¾3∏ EJISG功目图目度B⅞3
factor 16
factor 57
factor 21
factor 58
factor 33
factor 46
IatararaEiEitaiaiaia eiei切血向血向 ejejei
ππππππππππ ππππππππππ
QQQQQQDDQQ QQQQQQQQQQ
KlKllιlQDKlDDDD □□□□□□□□□□
□□□□□□□□□□
M国同1313万害同p⅞a E3E3QE3QE3E2QQE3
0H日也血⅛!I3Elt3!3 典EIEI¾!⅞⅛ll⅞I3!a∣jl
□□□□□bbbbħ qħππ□□□qqb
ααDDΠΠΠDΠΠ πdπddπdπππ
QQQQDQBBQQ DQaQDQQQQB
□□□□□□□□□El □□□□□□□□E1E1

日日目日目目口目目6nElElElElElElElElE]
Π□□□Π□QQE9Q nnnŋŋŋŋŋŋŋ
factor 59
factor 62
ElEIEɪ向面向Is■■物 E1QE⅛1向EI⅜∙!3!3
□□□□□QQQHQ ŋŋŋŋŋŋŋŋŋŋ
□□DΠDΠΠΠΠΠ DΠΠΠΠΠΠDDD
□□□□Q□QDQQ EaDQBQQQQQB
□□□□ElCin∏ΠΠ
口£]口目目目目目身目E3E3B目目目目目目目
胴BEB⅞⅞¾3B3Fa班 EJB⅞⅞3i3B¾3超超物 QQQQQQQQQQ 目四园园园BaBMCTa
factor 72
factor 84	factor 98
factor 123
factor 127
factor 108
Figure 12:	MNIST: Generating Factor Traversal of σ2 = 0.11 Pre-specified VAE
23
Under review as a conference paper at ICLR 2018
13131313131313131313
factor 16
factor 23
IHigBMaIala 血吻图目
ŋŋŋŋŋŋŋŋŋŋ
HHDΠΠΠΠΠΠΠ
Hbbsqqqdqq
后国为勿方方BEEIEI
j3ElElElElElΠIΠIΠI3
由 ElElEImBGH
Bssssqsqqq
2⑼27

SSSE3E3E3E3E3E3E3
国E!回血血囱庖目词词EIEIEI血血囱向El@烟
石目□E⅞¾⅞3CTa 以 BRmRR
BΠΠΠΠΠΠΠHΠ ∏∏∏∏∏∏∏∏∏∏
sqqqsddqqq Sqqqqqqqqq
囹目臼目©物Eet切勿上白，方嚓B3舞舞E¾
肥E!EII3I3E1EK1P1[?! CIEIElEIPinInEIEln
ΞΞΞSBE]E1E1E]E3 EiBBBSSSSSS
目日 13日己I3Γa∏C3l3 EI3CaMP3ΠCTΠCa
QBQQQQESEaQS QQQQQQQQBQ
factor 24
factor 39
血血El屯EIEIEKKIEI HHHEiraraiataBlBl
factor 57
factor 60
factor 52
factor 56
PMaBlI⅛⅞⅛wataCTa EIElIai⅞⅞⅛IEIlaIala

QEI□□□□□EIEIE1 HBHHHHHΠB0
BBΠE]E]E]E]E]E]E] EIEIEIEIEIEIEIEIHE]
qqGGQQQQBE3 Q□□DSE3E3E3SE3
ΠΠΠΠDΠΠΠΠΠ ππππππππππ
QQQQQQQDQQ QQDQQQQQQQ
Q□□□□□□□□□园园园园园Ba困因B3B3
factor 65
factor 74
factor 83
ħπeiek3E1∏eiqei EiEiiaiaEiraiaiarara E⅛∣E!EiijiEwa囱向囱
factor 91
ΠΠE1E1ΠΠΠQ□Q
ΠΠΠΠΠDQQQ□
ΠΠΠΠDQDDQS



≡≡≡≡ΞI□□□□□
□EIE1□□□QE2□Q
E3E]E]E]EiE]E]E]E]E]目目ElEl目EJEJEIEIE]
HΠHΠC3C3□C3□□ ŋŋŋŋŋŋŋnŋŋ
QQ□□E3E3□E3E30 ■R园e 园BgaCTJF3
□EIE1□E1□QΞΞΞ
ΠE1ΠΠE1E]H□HQ
EIEIIΠ□□□□□□Q
ΠDΠΠΠ□□□E3E3
factor 93
factor 121
factor 126
Figure 13:	MNIST: Generating Factor Traversal of Noise Learning β(=10)-VAE
24
Under review as a conference paper at ICLR 2018
factor 23
factor 52
factor 77
factor 88
factor 24
factor 37
factor 97
factor 80
H 烂LF.
factor 57
factor 58
factor 89
factor 85
factor 105
Pl	VG Q=∙ Z=FlT -i!?匕-*5fc
factor 123
Figure 14:	Extended Yale Face B: Generating Factor Traversal of Noise Learning β(= 120)-VAE .
Factor equivalence class properties are still hold.
25
Under review as a conference paper at ICLR 2018
Origin
MoG-2 VAE
Reconstruction
+
Gaussian 1 negative	Gaussian 2 negative
σ22 = 0.029 π2 = 0.37	σ12 = 0.003 π1 = 0.63
Gaussian 1 positive	Gaussian 2 positive
σ22 = 0.029 π2 = 0.37	σ12 = 0.003 π1 = 0.63
Figure 15:	MoG-2 β(=40)-VAE reconstruction and residual Gaussian components membership
- <u : -ðpovue
(Ssu)^Z") W -

ElElCinDDDI
□πππ□□sι
ππnnππ□ι
ΞΞΞΞΞΞΞI
l□□!
Thickness
Thickness
Rotation
Thickness
Thickness
Round
20	40
60	80	100	120
Generating Factor Index
Figure 16: Noise specified (β-)VAE with equivalent σ2 = 0.11: IenCoder (x; zh), σZ, and qualita-
tively influential factor traversals. The mutual information of “used” factor learnt by noise specified
β-VAE can be found more diverse than that in figure 2.
26