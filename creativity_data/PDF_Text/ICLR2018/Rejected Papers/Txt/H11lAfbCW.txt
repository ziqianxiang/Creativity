Under review as a conference paper at ICLR 2018
On Characterizing the Capacity of Neural
Networks Using Algebraic Topology
Anonymous authors
Paper under double-blind review
Ab stract
The learnability of different neural architectures can be characterized directly by
computable measures of data complexity. In this paper, we reframe the problem of
architecture selection as understanding how data determines the most expressive
and generalizable architectures suited to that data, beyond inductive bias. After
suggesting algebraic topology as a measure for data complexity, we show that the
power of a network to express the topological complexity of a dataset in its decision
boundary is a strictly limiting factor in its ability to generalize. We then provide the
first empirical characterization of the topological capacity of neural networks. Our
empirical analysis shows that at every level of dataset complexity, neural networks
exhibit topological phase transitions and stratification. This observation allowed
us to connect existing theory to empirically driven conjectures on the choice of
architectures for a single hidden layer neural networks.
1	Introduction
Deep learning has rapidly become one of the most pervasively applied techniques in machine learning.
From computer vision (Krizhevsky et al. (2012)) and reinforcement learning (Mnih et al. (2013)) to
natural language processing (Wu et al. (2016)) and speech recognition (Hinton et al. (2012)), the core
principles of hierarchical representation and optimization central to deep learning have revolutionized
the state of the art; see Goodfellow et al. (2016). In each domain, a major difficulty lies in selecting
the architectures of models that most optimally take advantage of structure in the data. In computer
vision, for example, a large body of work (Simonyan & Zisserman (2014), Szegedy et al. (2014), He
et al. (2015), etc.) focuses on improving the initial architectural choices of Krizhevsky et al. (2012) by
developing novel network topologies and optimization schemes specific to vision tasks. Despite the
success of this approach, there are still not general principles for choosing architectures in arbitrary
settings, and in order for deep learning to scale efficiently to new problems and domains without
expert architecture designers, the problem of architecture selection must be better understood.
Theoretically, substantial analysis has explored how various properties of neural networks, (eg. the
depth, width, and connectivity) relate to their expressivity and generalization capability (Raghu et al.
(2016), Daniely et al. (2016), Guss (2016)). However, the foregoing theory can only be used to
determine an architecture in practice if it is understood how expressive a model need be in order to
solve a problem. On the other hand, neural architecture search (NAS) views architecture selection
as a compositional hyperparameter search (Saxena & Verbeek (2016), Fernando et al. (2017), Zoph
& Le (2017)). As a result NAS ideally yields expressive and powerful architectures, but it is often
difficult to interperate the resulting architectures beyond justifying their use from their emperical
optimality.
We propose a third alternative to the foregoing: data-first architecture selection. In practice, experts
design architectures with some inductive bias about the data, and more generally, like any hyper-
parameter selection problem, the most expressive neural architectures for learning on a particular
dataset are solely determined by the nature of the true data distribution. Therefore, architecture
selection can be rephrased as follows: given a learning problem (some dataset), which architectures
are suitably regularized and expressive enough to learn and generalize on that problem?
A natural approach to this question is to develop some objective measure of data complexity, and
then characterize neural architectures by their ability to learn subject to that complexity. Then given
1
Under review as a conference paper at ICLR 2018
Output of postive label neuron
Figure 1: The positive label outptus of single hidden layer neural networks, h12 and h26, of 2 inputs
with 12 and 26 hidden units respectively after training on datasets D1 and D2 with positive examples
in red. Highlighted regions of the output constitute the positive decision region.
some new dataset, the problem of architecture selection is distilled to computing the data complexity
and chosing the appropriate architecture.
For example, take the two datasets D1 and D2 given in Figure 1(ab) and Figure 1(cd) respectively.
The first dataset, D1, consists of positive examples sampled from two disks and negative examples
from their compliment. On the right, dataset D2 consists of positive points sampled from two disks
and two rings with hollow centers. Under some geometric measure of complexity D2 appears more
’complicated’ than D1 because it contains more holes and clusters. As one trains single layer neural
networks of increasing hidden dimension on both datasets, the minimum number of hidden units
required to achieve zero testing error is ordered according to this geometric complexity. Visually in
Figure 1, regardless of initialization no single hidden layer neural network with ≤ 12 units, denoted
h≤12, can express the two holes and clusters in D2. Whereas on the simpler D1, both h12 and h26
can express the decision boundary perfectly. Returning to architecture selection, one wonders if
this characterization can be extrapolated; that is, is it true that for datasets with ’similar’ geometric
complexity to D1 , any architecture with ≥ 12 hidden learns perfectly, and likewise for those datasets
similar in complexity to D2, architectures with ≤ 12 hidden units can never learn to completion?
1.1	Our Contribution
In this paper, we formalize the above of geometric complexity in the language of algebraic topology.
We show that questions of architecture selection can be answered by understanding the ’topological
capacity’ of different neural networks. In particular, a geometric complexity measure, called persistent
homology, characterizes the capacity of neural architectures in direct relation to their ability to
generalize on data. Using persistent homology, we develop a method which gives the first empirical
insight into the learnability of different architectures as data complexity increases. In addition, our
method allows us to generate conjectures which tighten known theoretical bounds on the expressivity
of neural networks. Finally, we show that topological characterizations of architectures are possible
and useful for architecture selection in practice by computing the persistent homology of CIFAR-10
and several UCI datasets.
2	Background
2.1	General Topology
In order to more formally describe notions of geometric complexity in datasets, we will turn to
the language of topology. Broadly speaking, topology is a branch of mathematics that deals with
characterizing shapes, spaces, and sets by their connectivity. In the context of characterizing neural
networks, we will work towards defining the topological complexity of a dataset in terms of how that
dataset is ’connected’, and then group neural networks by their capacity to produce decision regions
of the same connectivity.
2
Under review as a conference paper at ICLR 2018
In topology, one understands the relationships between
two different spaces of points by the continuous maps
between them. Informally, we say that two topological
spaces A and B are equivalent (A = B) if there is a
continuous function f : A → B that has an inverse
f-1 that is also continuous. When f exists, We say
that A and B are homeomorphic and f is their home- Figure 2: A continuous deformation of a cof-
omorphism; for a more detailed treatment of general fee cup into a donut, shoWing that both are
topology see Bredon (2013). Take for example, the topologically equivalent (Kato et al. (2014)).
classic example of the coffee cup and the donut in
Figure 2. They are homeomorphic because one can define a continuous deformation of one into the
other Which shrinks, tWists, and morphs Without tearing or gluing, as in Figure 2. Note that if the
donut had tWo holes, it Would no longer be equivalent to the mug. LikeWise, in an informal Way,
D1 6== D2 in Figure 1 since if there Were a homeomorphism f : D1 → D2 at least one of the clusters
in D1 Would need to be split in order to produce the four different regions in D2 .
The poWer of topology lies in its capacity to differentiate sets (topological spaces) in a meaningful
geometric Way that discards certain irrelevant properties such as rotation, translation, curvature, etc.
For the purposes of defining geometric complexity, non-topological properties1 like curvature Would
further fine-tune architecture selection-say if D? had the same regions but with squigly (differentially
complex) boundaries, certain architectures might not converge-but as we will show, grouping neural
networks by ’topological capacity’ provides a powerful minimality condition. That is, we will show
that if a certain architecture is incapable of expressing a decision region that is equivalent in topology
to training data, then there is no hope of it ever generalizing to the true data.
2.2	Algebraic Topology
Algebraic topology provides the tools necessary to not only build the foregoing notion of topological
equivalence into a measure of geometric complexity, but also to compute that measure on real data
(Betti (1872), Dey et al. (1998), Bredon (2013)). At its core, algebraic topology takes topological
spaces (shapes and sets with certain properties) and assigns them algebraic objects such as groups,
chains, and other more exotic constructs. In doing so, two spaces can be shown to be topologically
equivalent (or distinct) if the algebraic objects to which they are assigned are isomorphic (or not).
Thus algebraic topology will allow us to compare the complexity of decision boundaries and datasets
by the objects to which they are assigned.
Although there are many flavors of algebraic topology, a powerful and computationally realizable
tool is homology.
Definition 2.1 (Informal, Bredon (2013)). If X is a topological space, then Hn(X) = Zβn is called
the nth homology group of X if the power βn is the number of ’holes’ of dimension n in X. Note
that β0 is the number of separate connected components. We call βn(X) the nth Betti number of X.
Finally, the homology2 of X is defined as H(X) = {Hn (X)}n∞=0 .
Immediately homology brings us closer to defining the complexity of D1 and D2. If we assume that
D1 is not actually a collection of N datapoints, but really the union of 2 solid balls, and likewise that
D2 is the union of 2 solid balls and 2 rings, then we can compute the homology directly. In this case
H0(D1) = Z2 since there are two connected components3; H1(D1) = {0} since there are no circles
(one-dimensional holes); and clearly, Hn(D1) = {0} for n ≥ 2. Performing the same computation
in the second case, we get H0(D2) = Z4 and H1(D2) = Z2 as there are 4 seperate clusters and 2
rings/holes. With respect to any reasonable ordering on homology, D2 is more complex than D1 . The
measure yields non-trivial differentiation of spaces in higher dimension. For example, the homology
of a hollow donut is {Z1, Z2, Z1, 0, . . . }.
1A topological property or invariant is one that is preserved by a homeomorphism. For example, the number
of holes and regions which are disjoint from one another are topological properties, whereas curvature is not.
2This definition of homology makes many assumptions on X and the base field of computation, but for
introductory purposes, this informality is edifying.
3Informally, a connected component is a set which is not contained in another connected set except for itself.
3
Under review as a conference paper at ICLR 2018
Surprisingly, the homology of a space contains a great deal of information about its topological
complexity1. The following theorem suggests the absolute power of homology to group topologically
similar spaces, and therefore neural networks with topologically similar decision regions.
Theorem 2.2 (Informal). Let X and Y be topological spaces. If X = Y then H (X) = H (Y).4
Intuitively, Theorem 2.2 states that number of ’holes’ (and in the case of H0(X), connected compo-
nents) are topologically invariant, and can be used to show that two shapes (or decision regions) are
different.
2.3	Computational Methods for Homological Complexity
In order to compute the homology of both D1 and D2 we needed to assume that they were actually
the geometric shapes from which they were sampled. Without such assumptions, for any dataset
D a H(D) = {ZN, 0, . . . } where N is the number of data points. This is because, at small enough
scales each data point can be isolated as its own connected component; that is, as sets each pair of
different positive points d1 , d2 ∈ D are disjoint. To properly utilize homological complexity in better
understanding architecture selection, we need to be able to compute the homology of the data directly
and still capture meaningful topological information.
Figure 3: Left: The local disconnectedness of datasets prevents direct computation of their homology.
Right: An illustration of computing persistent homology on a collection of points (Topaz et al. (2015))
Persistent homology, introduced in Zomorodian & Carlsson (2005), avoids the trivialization of
computation of dataset homology by providing an algorithm to calculate the homology of a filtration
of a space. Specifically, a filtration is a topological space X equipped with a sequence of subspaces
Xo ⊂ Xi ⊂ …⊂ X. In Figure 3 one such particular filtration is given by growing balls of size e
centered at each point, and then letting X be the resulting subspace in the filtration. Define βn (X) to
be the nth Betti number of the homology H(X) of X. Then for example at e = 1.5, β0(X) = 19
and β1 (X) = 0 as every ball is disjoint. At e = 5.0 some connected components merge and
β0(X) = 12 and β1(X) = 0. Finally at e = 7, the union of the balls forms a hole towards the
center of the dataset and β1(X) > 0 with β0(X) = 4.
All together the change in homology and therefore Betti numbers for X as e changes can be
summarized succinctly in the persistence barcode diagram given in Figure 3. Each bar in the
section βn(X) denotes a ’hole’ of dimension n. The left endpoint of the bar is the point at which
homology detects that particular component, and the right endpoint is when that component becomes
indistinguishable in the filtration. When calculating the persistent homology of datasets we will
frequently use these diagrams.
With the foregoing algorithms established, we are now equipped with the tools to study the capacity
of neural networks in the language of algebraic topology.
4Equality of H(X) and H(Y ) should be interpreted as isomorphism between each individual Hi (X) and
Hi(Y).
4
Under review as a conference paper at ICLR 2018
3	Homological Characterization of Neural Architectures
In the forthcoming section, we will apply persistent homology to emperically characterize the power
of certain neural architectures. To understand why homological complexity is a powerful measure for
differentiating architectures, we present the following principle.
Suppose that D is some dataset drawn from a joint distribution F with continuous CDF on some
topological space X × {0, 1}. Let X+ denote the support of the distribution of points with positive
labels, and X- denote that of the points with negative labels. Then let HS(f) := H[f-1 ((0, ∞))]
denote the support homology of some function f : X → {0, 1}. Essentially HS(f) is homology of
the set of x such that f (x) > 0. For a binary classifier, f, HS (f) is roughly a characterization of
how many ’holes’ are in the positive decision region of f. We will sometimes use βn (f) to denote
the nth Betti number of this support homology. Finally let F = {f : X → {0, 1}} be some family
of binary classifiers on X .
Theorem 3.1 (The Homological Principle of Generalization). If X = X- t X+ and for all f ∈ F
with HS(f) 6= H(X+), then for all f ∈ F there exists A ⊂ X+ so f misclassifies every x ∈ A.
Essential Theorem 3.1 says that if an architecture (a family of models F) is incapable of producing a
certain homological complexity, then for any model using that architecture there will always be a set
A of true data points on which the model will fail. Note that the above principle holds regardless of
how f ∈ F is attained, learned or otherwise. However, the principle does imply that no matter how
well some F learns to correctly classify D there will always be a counter examples in the true data.
In the context of architecture selection, the foregoing minimality condition significantly reduces
the size of the search space by eliminating smaller architectures which cannot even express the
’holes’ (persistent homology) of the data H(D). This allows us to return to our original question of
finding suitably expressive and generalizeable architectures but in the very computable language of
homological complexity: Let FA the set of all neural networks with ’architecture’ A, then
Given a dataset D, for which architectures A does there exist
a neural network f ∈ FA such that HS (f) = H (D)?
We will resurface a contemporary theoretical view on this question, and thereafter make the first steps
towards an emperical characterization of the capacity of neural architectures in the view of topology.
3.1	Theoretical Basis for Neural Homology
Theoretically, the homological complexity of neural network can be framed in terms of the sum of the
number of holes expressible by certain architectures. In particular, Bianchini et al. (2014) gives an
analysis of how the maximum sum of Betti numbers grows as FA changes. The results, summarized
in Table 1, show that the width, depth, and activation of a fully connected architecture effect its
topological expressivity to varying polynomial and exponential degrees. What is unclear from this
analysis is how these bounds describe expressivity in terms of individual Betti numbers. For example,
with a tanh activation function, n inputs, ` layers, and h hidden units, there is no description of
what the number of connected components maxf∈FA β0(f) or 1-dimensional holes maxf∈FA β1(f)
actually is. With regards to tighter bounds Bianchini et al. (2014) stipulate that improvements to their
results are deeply tied to several unsolved problems in algebraic topology.
Table 1: Upper bounds on homological expressivity of neural architectures (Bianchini et al. (2014).)
Inputs	Architecture A			maxf∈FA Pkn=1 βk(f)
	Layers Units		Activation	
n	3	h	threshold	O(hn)
n	3	h	arctan	O((n + h)n+2)
n	3	h	polynomial, deg. r	2 (2 + r)(1+ r)n-1
1	3	h	arctan	h
n	`	h	arctan	2h(2hT)O((n' + n)n+2h)
n	`	h	tanh	2h(I)/2O((n' + n)n+h)
n	`	h	polynomial, deg. r	2 (2 + r)(1+ r)n-1)
5
Under review as a conference paper at ICLR 2018
----1 hidden
—2 hidden
----3 hidden
----4 hidden
----5 hidden
----6 hidden
—7 hidden
----8 hidden
=9 hidden
10 hidden
----11 hidden
12 hidden
----13 hidden
14 hidden
15 hidden
Figure 4: Topological phase transitions in low dimensional neural networks as the homological
complexity of the data increases. The upper right corner of each plot is a dataset on which the neural
networks of increasing hidden dimension are trained.
3.2	Empirical Results
To understand how the homology of data determines expressive architectures we turn to an empirical
characterization of neural networks. In this setting, we can tighten the bounds given in Table 1 by
training different architectures on datasets with known homologies and then recording the decision
regions observed over the course of training.
3.2.1	Homological Capacity of Hidden Units.
In the most basic case, one is interested in studying how the number of hidden units in a single hidden
layer neural network affect its homological capacity. The results of Bianchini et al. (2014) say for
certain activation functions we should expect a polynomial dependence on the sum of Betti numbers
βn , but is this true of individual numbers? Having an individual characterization would allow for
architecture selection by computing the homology of the dataset, and then finding which architectures
meet the minimal criterion for each Betti number βn .
Restricting5 our analysis to the case of two in-
puts, n = 2, we characterize the capacities of ar-
chitectures with an increasing number of hidden
units to learn on datasets with homological com-
plexities ranging from {Z1, 0} to {Z20, Z20}. In
our experiment, we generate datasets of each par-
ticular homological complexity by sampling dif-
ferent combinations of balls, rings, and scaling,
twisting, and gluing them at random. After gen-
erating the foregoing datasets with N ≈ 90000
samples we train 100 randomly (truncated nor-
mal) initialized single hidden layer architectures
with hidden units h ∈ {1, . . . , 255} and tanh
activation functions for 106 minibatches of size
128. During training, every 2500 batches we
sample the decision boundary of each neural
network over a grid of 500 × 500 samples, pro-
ducing 1.02 × 106 recorded decision boundaries.
Using the resulting data, we not only character-
ize different architectures but observed interest-
ing topological phenomena during learning.
Figure 5: Several different views of the probabil-
ity of converging to zero-error for single hidden
layer neural networks on datasets with different
homological complexities.
sr、S⅛f1o≡SdnSB ajceqh
5Analysis of greater input dimension was not given due to space constraints (decision boundary samples
alone accounted for 18.55 TB), but in future work Monte Carlo samples of the decision boundary suffice to
perform the forthcoming analysis; see Chazal et al. (2015).
6
Under review as a conference paper at ICLR 2018
BOs3)
βo(h4)
βo(h5)
BoS6)
βo(h7)
-----βo(h8)
βθ(hg)
βo(hw)
βo(h11)
βo(h12)
βo(h13)
βo(h14)
βo(h15)
Correlation between β0(hi)l β0(hj)
Figure 6: An example of topological stratification for single hidden layer networks. (a) The number
of connected components in the decision regions during training. (b) Correlation of Betti numbers.
First, neural networks exhibit a statistically significant topological phase transition in their conver-
gence which depends directly on the homological complexity of the data. For any dataset in the
experiment and any random homeomorphism applied thereto, the best test error of architectures
with h hidden units is strictly ordered in magnitude and convergence time for h < hphase where
hphase is a number of hidden units required to express the homology of the data. In Figure 4
we plot the best performing test error of architectures h ∈ {1, . . . , 15} on some example datasets
D0,D1, and D2 withH(D0) ≈ {Z2,0}, H(D1) ≈ {Z3,0}, H(D2) ≈ {Z3,Z2}. In this example
hphase(D0) = 4, hphase(D1) = 6, and hphase(D2) = 10. Surprisingly, leading up to the phase
transition point, each different architecture falls into its own band of optimal convergence. This
suggests that additional hidden units do in fact add to the topological capacity of an architecture in a
consistent way.
Using topological phase transitions we now return to the original question of existence of expressive
architectures. In Figure 5, we accumulate the probabilities that neural networks of varying hidden
dimension train to zero-error on datasets of different homological complexities. The table gives
different views into how expressive an architecture need be in order to converge, and therefore we
are able to conjecture tighter bounds on the capacity of hidden units. Extrapolating from the first
view, if H0(D) = Zm then there exists a single hidden layer neural network with h = m + 2 that
converges to zero error on D. Likewise we claim that if H0(D) = Zm and H1 (D) = 1 then the same
holds with h ≥ 3m - 1. Further empirical analysis of convergence probabilities yields additional
conjectures. However, claiming converse conjectures about a failure to generalize in the view of
Theorem 3.1 requires exhaustive computation of decision boundary homologies.
By applying persistent homology to the decision boundaries of certain networks during training, we
observe that given sufficient data, neural networks exhibit topological stratification. For example,
consider the homologies of different architecture decision regions as training progresses in Figure 6(a).
At the beginning of training every model captures the global topological information of the dataset
and is homologically correlated with one another. However as training continues, the architectures
stratify into two groups with homological complexities ordered by the capacities of the models.
In this example, h3 , h4, and h5 are unable to express as many holes as the other architectures
and so never specialize to more complex and local topological properties of the data. Figure 6(b)
depicts topological stratification in terms of the correlation between Betti numbers. Topologically
speaking, networks with less than 6 hidden units are distinct from those with more for most of
training. Furthermore, this correlative view shows that stratification is consistent with topological
phase transition; that is, across all decision boundary homologies recorded during the experiment
stratification occurs just when the number of hidden units is slightly less than hphase .
4	The Topology of Real Data
We have thus far demonstrated the discriminatory power of homological complexity in determining
the expressivity of architectures. However, for homological complexity to have any practical use
in architecture selection, it must be computable on real data, and more generally real data must
have non-trivial homology; if all data were topologically simple our characterization would have no
7
Under review as a conference paper at ICLR 2018
Persistent Homology of 1CYT1 yeast
Figure 7: The persistent homology barcodes of classes in the CIFAR-10 and UCI Protein Localization
Datasets. Left: The bardcode for dimension 0 and 1 of the ’CYT’ class along side its local linear
embedding into R2. Right: The barcode for the dimensions 0 and 1 for the ’cars’ class along side
different samples thereof in CIFAR-10. Note how different orientations are shown.
predictive power. In the following section we will compute the persistent homologies up to dimension
2 of different real world datasets.
CIFAR-10. We compute the persistent homology of several classes of CIFAR-10 using the Python
library Dionysus. Currently algorithms for persistent homology do not deal well with high dimen-
sional data, so we embed the entire dataset in R3 using local linear embedding (LLE; Saul & Roweis
(2000)) with K = 120 neighbors. After embedding the dataset, we take a sample of 1000 points
from example class ’car’ and build a persistent filtration by constructing a Vietoris-Rips complex
on the data. The resulting complex has 20833750 simplices and took 4.3 min. to generate. Finally,
computation of the persistence diagram shown in Figure 7 took 8.4 min. locked to a single thread on
a Intel Core i7 processor. The one-time cost of computing persistent homology could easily augment
any neural architecture search.
Although We only give an analysis of dimension 2 topological features-and there is certainly higher
dimensional homological information in CIFAR-10-the persistence barcode diagram is rich with
different components in both H0(D) and H1(D). Intuitively, CIFAR contains pictures of cars rotated
accross a range of different orientations and this is exhibited in the homology. In particular, several
holes are born and die in the range ∈ [0.15, 0.375] and one large loop from ∈ [0.625, 0.82].
UCI Datasets. We further compute the homology of three low dimensional UCI datasets and attempt
to assert the of non-trivial , hphase . Specifically, we compute the persistent homology of the majority
classes in the Yeast Protein Localization Sites, UCI Ecoli Protein Localization Sites, and HTRU2
datasets. For these datasets no dimensionality reduction was used. In Figure 7(left), the persistence
barcode exhibits two seperate significant loops (holes) at ∈ [0.19, 0.31] and ∈ [0.76, 0.85], as
well as two major connected components in β0(D). The Other persistence diagrams are relegated to
the appendix.
Existing Data. Outside of the primary machine learning literature, topological data analysis yields
non-trivial computations in wide variety of fields and datasets. Of particular interest is the work of
Carlsson et al. (2008), which computes the homological complexity of collections of n × n patches
of natural images. Even in these simple collections of images, the authors found topologies of
Klein Bottles (H(∙) = {Z, Z2/2Z, 0 ... }) and other exotic topological objects. Other authors have
calculated non-trivial dataset homologies in biological (Topaz et al. (2015)), natural language (Michel
et al. (2017)), and other domains (Wu et al. (2017), Xia & Wei (2014)).
5	Related Work
We will place this work in the context of deep learning theory as it relates to expressivity. Since the
seminal work of Cybenko (1989) which established standard universal approximation results for
neural networks, many theorists have endeavored to understand the expressivity of certain neural
architectures. Pascanu et al. (2013) and MacKay (2003) provided the first analysis relating the
depth and width of architectures to the complexitity of the sublevel sets they can express. Motivated
therefrom, Bianchini et al. (2014) expressed this theme in the language of Pfefferian functions,
thereby bounding the sum of Betti numbers expressed by sublevel sets. Finally Guss (2016) gave an
account of how topological assumptions on the input data lead to optimally expressive architectures.
In parallel, Eldan & Shamir (2016) presented the first analytical minimality result in expressivity
theory; that is, the authors show that there are simple functions that cannot be expressed by two layer
8
Under review as a conference paper at ICLR 2018
neural networks with out exponential dependence on input dimension. This work spurred the work
ofPoole et al. (2016), Raghu et al. (2016) which reframed expressivity in a differential geometric
lense.
Our work presents the first method to derive expressivity results empirically. Our topological
viewpoint sits dually with its differential geometric counterpart, and in conjunction with the work of
Poole et al. (2016) and Bianchini et al. (2014), this duallity implies that when topological expression
is not possible, exponential differential expressivity allows networks to bypass homological constaints
at the cost of adversarial sets. Furthermore, our work opens a practical connectio nbetween the
foregoing theory on neural expressivity and architecture selection, with the potential to drastically
improve neural architecture search (Zoph & Le (2017)) by directly computing the capacities of
different architectures.
6	Conclusion
Architectural power is deeply related to the algebraic topology of decision boundaries. In this work
we distilled neural network expressivity into an empirical question of the generalization capabilities of
architectures with respect to the homological complexity of learning problems. This view allowed us
to provide an empirical method for developing tighter characterizations on the the capacity of different
architectures in addition to a principled approach to guiding architecture selection by computation of
persistent homology on real data.
There are several potential avenues of future research in using homological complexity to better
understand neural architectures. First, a full characterization of neural networks with many layers or
convolutional linearities is a crucial next step. Our empirical results suggest that the their are exact
formulas describing the of power of neural networks to express decision boundaries with certain
properties. Future theoretical work in determining these forms would significantly increase the
efficiency and power of neural architecture search, constraining the search space by the persistent
homology of the data. Additionally, we intend on studying how the topological complexity of data
changes as it is propagated through deeper architectures.
References
E Betti. Il nuovo cimento. Series, 2:7, 1872.
Monica Bianchini et al. On the complexity of shallow and deep neural network classifiers. In ESANN,
2014.
Glen E Bredon. Topology and geometry, volume 139. Springer Science & Business Media, 2013.
Gunnar Carlsson, Tigran Ishkhanov, Vin De Silva, and Afra Zomorodian. On the local behavior of
spaces of natural images. International journal ofcomputer vision, 76(1):1-12, 2008.
FrederiC ChazaL Brittany Fasy, Fabrizio Lecci, Bertrand Michel, Alessandro Rinaldo, and Larry
Wasserman. Subsampling methods for persistent homology. In Proceedings of the 32nd Interna-
tional Conference on Machine Learning (ICML-15), pp. 2143-2151, 2015.
George Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics of Control,
Signals, and Systems (MCSS), 2(4):303-314, 1989.
Amit Daniely, Roy Frostig, and Yoram Singer. Toward deeper understanding of neural networks:
The power of initialization and a dual view on expressivity. In Advances In Neural Information
Processing Systems, pp. 2253-2261, 2016.
TK Dey, H Edelsbrunner, and S Guha. Computational topology, invited paper in advances in
discrete and computational geometry, eds. b. chazelle, je goodmann and r. pollack. Contemporary
Mathematics, AMS, 1998.
Ronen Eldan and Ohad Shamir. The power of depth for feedforward neural networks. In Conference
on Learning Theory, pp. 907-940, 2016.
9
Under review as a conference paper at ICLR 2018
Chrisantha Fernando, Dylan Banarse, Charles Blundell, Yori Zwols, David Ha, Andrei A. Rusu,
Alexander Pritzel, and Daan Wierstra. Pathnet: Evolution channels gradient descent in super neural
networks. CoRR, abs/1701.08734, 2017. URL http://arxiv.org/abs/1701.08734.
Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http:
//www.deeplearningbook.org.
William H Guss. Deep function machines: Generalized neural networks for topological layer
expression. arXiv preprint arXiv:1612.04799, 2016.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. CoRR, abs/1512.03385, 2015. URL http://arxiv.org/abs/1512.03385.
Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep Jaitly,
Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. Deep neural networks
for acoustic modeling in speech recognition: The shared views of four research groups. IEEE
Signal Processing Magazine, 29(6):82-97, 2012.
Yasuyuki Kato, Daisuke Yamamoto, and Ippei Danshita. Quantum tricriticality at the superfluid-
insulator transition of binary bose mixtures. Phys. Rev. Lett., 112:055301, Feb 2014.
doi: 10.1103/PhysRevLett.112.055301. URL https://link.aps.org/doi/10.1103/
PhysRevLett.112.055301.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolu-
tional neural networks. In Advances in neural information processing systems, pp. 1097-1105,
2012.
David JC MacKay. Information theory, inference and learning algorithms. Cambridge university
press, 2003.
Paul Michel, Abhilasha Ravichander, and Shruti Rijhwani. Does the geometry of word embeddings
help document classification? a case study on persistent homology based representations. arXiv
preprint arXiv:1705.10900, 2017.
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan
Wierstra, and Martin Riedmiller. Playing atari with deep reinforcement learning. arXiv preprint
arXiv:1312.5602, 2013.
Razvan Pascanu, Guido Montufar, and Yoshua Bengio. On the number of response regions of deep
feed forward networks with piece-wise linear activations. arXiv preprint arXiv:1312.6098, 2013.
Ben Poole, Subhaneil Lahiri, Maithreyi Raghu, Jascha Sohl-Dickstein, and Surya Ganguli. Ex-
ponential expressivity in deep neural networks through transient chaos. In Advances In Neural
Information Processing Systems, pp. 3360-3368, 2016.
Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, and Jascha Sohl-Dickstein. On the
expressive power of deep neural networks. arXiv preprint arXiv:1606.05336, 2016.
Lawrence K Saul and Sam T Roweis. An introduction to locally linear embedding. unpublished.
Available at: http://www. cs. toronto. edu/ roweis川e/publiCations. html, 2000.
Shreyas Saxena and Jakob Verbeek. Convolutional neural fabrics. CoRR, abs/1606.02492, 2016.
URL http://arxiv.org/abs/1606.02492.
Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. CoRR, abs/1409.1556, 2014. URL http://arxiv.org/abs/1409.1556.
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed, Dragomir Anguelov,
Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions.
CoRR, abs/1409.4842, 2014. URL http://arxiv.org/abs/1409.4842.
Chad M Topaz, Lori Ziegelmeier, and Tom Halverson. Topological data analysis of biological
aggregation models. PloS one, 10(5):e0126383, 2015.
10
Under review as a conference paper at ICLR 2018
Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey,
Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine trans-
lation system: Bridging the gap between human and machine translation. arXiv preprint
arXiv:1609.08144, 2016.
Yu Wu, Gabriel Shindnes, Vaibhav Karve, Derrek Yager, Daniel B Work, Arnab Chakraborty, and
Richard B Sowers. Congestion barcodes: Exploring the topology of urban congestion using
persistent homology. arXiv preprint arXiv:1707.08557, 2017.
Kelin Xia and Guo-Wei Wei. Persistent homology analysis of protein structure, flexibility, and folding.
International journal for numerical methods in biomedical engineering, 30(8):814-844, 2014.
Afra Zomorodian and Gunnar Carlsson. Computing persistent homology. Discrete & Computational
Geometry, 33(2):249-274, 2005.
Barret Zoph and Quoc V. Le. Neural architecture search with reinforcement learning. 2017. URL
https://arxiv.org/abs/1611.01578.
11
Under review as a conference paper at ICLR 2018
A Proofs, Conjectures, and Formal Definitions
A.1 Homology
Homology is naturally described using the language of category theory. Let T op2 denote the category
of topological spaces and Ab the category of abelian groups.
Definition A.1 (Homology Theory, Bredon (2013)). A homology theory on the on Top2 is a function
H : Top2 → Ab assigning to each pair (X, A) of spaces a graded (abelian) group {Hp(X, A)},
and to each map f : (X,A) → (Y, B), homomorphisms f : Hp(X,A) → Hp(Y,B), together
with a natural transformation of functors ∂* : Hp(X,A) → Hp-I(X,A), called the Connecting
homomorphism (where we use H* (A) to denote H* (A, 0)) such that thefollowing five axioms are
satisfied.
1.	Iff'g : (X, A) → (Y,B)thenf* =g* : H*(X, A) → H*(Y,B).
2.	For the inclusions i : A → X and j : X → (X, A) the sequence sequence of inclusions
and connecting homomorphisms are exact.
3.	Given the pair (X, A) and an open set U ⊂ X such that cl(U) ⊂ int(A) then the inclusion
k : (X - U, A - U) → (X, A) induces an isomorphism k* : H*(X - U, A - U) →
H*(X, A)
4.	For a one point space P, Hi(P) = 0 for all i 6= 0.
5.	For a topological sum X = +αXα the homomorphism
M(iα)* : M Hn(Xα) → Hn(X)
is an isomorphism, where iα : Xα → X is the inclusion.
For related definitions and requisite notions we refer the reader to Bredon (2013).
A.2 Proof of Theorem 3.1
Theorem A.2. Let X be a topological space and X+ be some open subspace. If F ⊂ 2X such that
f ∈ F implies HS(f) 6= H(X+), then for all f ∈ F there exists A ⊂ X so that f(A ∩ X+) = {0}
and f (A ∩ (X \ X +)) = {1}.
Proof. Suppose the for the sake of contraiction that for all f ∈ F, HS (f) 6= H(X+ ) and yet
there exists an f such that for all A ⊂ X, there exists an x ∈ A such that f(x) = 1. Then take
A = {x}x∈X, and note that f maps each singleton into its proper partition on X. We have that for
any open subset of V ⊂ X+, f(V ) = {1}, and for any closed subset W ⊂ X \ X+, f(W) = {0}.
Therefore X+ = SA∈τ A ⊂ supp(f) as the subspace topology τX+∩X = τX+ ∩ τX where
τX+ = {A ∈ τX | A ⊂ X+} and τX denotes the topology ofX. Likewise, int(X-) ⊂ X\supp(F)
under the same logic. Therefore supp(f) has the exact same topology as X+ and so by Theorem 2.2
H(X+) = H(supp(f)) but this is a contradiction. This completes the proof.	□
A.3 The Neural Homology Principle
Conjecture A.3. If N is some neural network with ` layers and h hidden units, and HS(N) 6=
H (X+) then E[L(N, D)] > C for some fixed c(', h) > 0.
12
Under review as a conference paper at ICLR 2018
B Additional Topological Phase Transitions
200000 400000 600000 800000 1000000
1 hidden
-2 hidden
---3 hidden
---4 hidden
---5 hidden
---6 hidden
-7 hidden
---8 hidden
-9 hidden
10	hidden
11	hidden
12	hidden
13	hidden
14	hidden
15	hidden
Figure 8:	Topological phase transitions for datasets with β(D) ∈ {(2, 0), (2, 1), (3, 0), (3, 1)}
H(5) = (/,/, 0,…)
O 200000 400000 600000 800000 1000000
h(Di) = (z4,o,o, ...)
O 200000 400000 600000 800000 1000000
h(d2) = (z4,z1,o, ...)
H(7%) = (a4,∕,0,…)
O 200000 400000 600000 800000 1000000
O 200000 400000 600000 800000 1000000
----1 hidden
2 hidden
----3 hidden
----4 hidden
----5 hidden
----6 hidden
7 hidden
----8 hidden
9	hidden
10	hidden
----11 hidden
12 hidden
----13 hidden
----14 hidden
----15 hidden
----16 hidden
17 hidden
----18 hidden
19 hidden
----20 hidden
----21 hidden
22 hidden
----23 hidden
----24 hidden
----25 hidden
Figure 9:	Topological phase transitions for datasets with β(D) ∈ {(3, 2), (4, 0), (4, 1), (4, 2)}
13
Under review as a conference paper at ICLR 2018
0	200000 400000 600000 800000 1000000
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
H(D1) = (Z5,0l0l...)


0	200000 400000 600000 800000 1000000
----1 hidden
2 hidden
----3 hidden
----4 hidden
----5 hidden
----6 hidden
7 hidden
----8 hidden
9 hidden
10 hidden
----11 hidden
12 hidden
----13 hidden
----14 hidden
——15 hidden
----16 hidden
17 hidden
----18 hidden
19 hidden
----20 hidden
----21 hidden
----22 hidden
——23 hidden
----24 hidden
----25 hidden
Figure 10: Topological phase transitions for datasets with β(D) ∈ {(4, 3), (5, 0)}
C Example Topological Stratifications
----βo(h3) ------βι(h3)
一βo(h4) --------βι(h4)
I -	βo(h5) -----βι(h5)
----βo(h6) ------仇(仇)
——7)	---仇(卜7)
----βo(h8) ------βι(hs)
一βo(h9) --------βι(h9)
一βo(h1o) -------∕3ι(ħιo)
-jβo(hn) -------∕3ι(hιι)
一βo(h12)	 βι(h12)
-jβθ(hi3) ----∕3ι(ħι3)
一。0•4)	 /31(/714)
一βo(h15)	---BMhl5)
Figure 11: Topological stratification for {h3, . . . , h15} on a random dataset D with β0 (D) = 25,
β1 (D) = 16.
I — βo(h1)
一βo(h2)
一βo(h3)
一βo(h4)
一βo(h5)
(hlω2ω3(h4(∕75
Decision boundary homology over training
Figure 12:
β1 (D) = 0.
stratification for {h1 , . . . , h5} on
a random dataset D with β0 (D)
3,
14
Under review as a conference paper at ICLR 2018
一βo(h3) ------βι(h3)
—	60(64)	 ∕3ι(h4)
——βo(h5) ---∕3ι(h5)
-jβo(h6) -----81(仇)
一β0(h7)	 βι(h7)
E PUeogω,Je qujnuS① g
Minibatches
Figure 13: Topological stratification for {h3 , . . . , h7} on a random dataset D with β0 (D) = 3,
β1 (D) = 0.
D Additional Topology of Real Data
Figure 14: The persistence diagrams of other data.
E Example Sampled Datasets
15