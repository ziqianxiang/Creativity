Under review as a conference paper at ICLR 2018
Recurrent Relational Networks for Complex
Relational Reasoning
Anonymous authors
Paper under double-blind review
Ab stract
Humans possess an ability to abstractly reason about objects and their interac-
tions, an ability not shared with state-of-the-art deep learning models. Relational
networks, introduced by Santoro et al. (2017), add the capacity for relational rea-
soning to deep neural networks, but are limited in the complexity of the reasoning
tasks they can address. We introduce recurrent relational networks which increase
the suite of solvable tasks to those that require an order of magnitude more steps
of relational reasoning. We use recurrent relational networks to solve Sudoku puz-
zles and achieve state-of-the-art results by solving 96.6% of the hardest Sudoku
puzzles, where relational networks fail to solve any. We also apply our model to
the BaBi textual QA dataset solving 19/20 tasks which is competitive with state-
of-the-art sparse differentiable neural computers. The recurrent relational network
is a general purpose module that can augment any neural network model with the
capacity to do many-step relational reasoning.
1	Introduction
A central component of human intelligence is the ability to abstractly reason about objects and their
interactions (Spelke et al., 1995; Spelke & Kinzler, 2007). An abstract and relational framework is
required for problem-solving, often requiring a strictly methodical approach. This paper introduces
a composite function, the recurrent relational network, to serve as a modular component for higher-
level relational reasoning in artificially intelligent agents or systems.
The popular puzzle game Sudoku serves as an illustrative example of methodical and relational
problem solving. In it, 81 cells are arranged in a 9x9 grid, which must be filled with digits 1 to
9 so each digit appears exactly once in each row, column and 3x3 non-overlapping box. Sudokus
are harder when less initial clues, or filled cells, are given.1 To solve it, we would reason about
the puzzle in terms of its cells and inter-cell interactions over many steps, rather than the puzzle in
its entirety. Following Santoro et al. (2017) we use the term “relational reasoning” for this object-
and interaction-centric thinking. Note that relational reasoning is not strictly defined, and is not, for
instance equal to relational or first order logic. Sudoku shares properties with other problems that
also require complex, multi-step relational reasoning: evaluating game moves, logical deduction,
predicting the future of physical systems, and automated planning and resource allocation, like
creating timetables, scheduling taxis and designing seating plans.
State-of-the-art deep learning approaches fall short when faced with problems that require basic
relational reasoning (Lake et al., 2016; Santoro et al., 2017). The relational network of Santoro et al.
(2017) gave a first glimpse of how this kind of reasoning could be achieved. However, it is limited
to performing a single relational operation, and was evaluated on datasets that require a maximum
of three steps of reasoning. We focus on Sudoku as a main task, as it requires an order of magnitude
more steps of relational reasoning than has previously been considered. We show in this paper that
the recurrent relational network learns an iterative strategy that generalizes, that is, can solve any
unseen Sudoku.
One key insight by Santoro et al. (2017) is to split the problem into two components: a perceptual
front-end and a relational reasoning module. The task of the perceptual front-end is to recognize
1We invite the reader to solve the Sudoku in the appendix to appreciate the difficulty of solving a Sudoku in
which 17 cells are initially filled.
1
Under review as a conference paper at ICLR 2018
objects in the raw input and output a representation of them. The task of the relational reasoning
module is to reason about the objects and their interactions. Both modules are trained jointly end-
to-end, with the relational reasoning module requiring the perceptual front-end to recognize and
represent objects that it can reason about. In computer science parlance, the relational reasoning
module implements an interface; it operates on a set of objects described with real valued vectors,
and is differentiable. The abstraction that the interface provides allows us to consider and improve
each side of it in isolation. For many domains very good perceptual front-ends have already been
found. For example, for images or text, convolutional and recurrent neural networks respectively,
are natural choices. In this paper we focus on and improve the relational reasoning side of that
interface, as it is still in its infancy in state-of-the-art deep learning architectures. As long as the
interface is complied with, the recurrent relational module that is developed in this paper will be
compatible with any perceptual front-end. For a formal definition of the interface see the appendix.
Solving Sudokus computationally is in itself not a very laudable goal, as traditional symbolic and
hand-crafted algorithms like constraint propagation and search can solve any Sudoku in fractions of
a second. For a good explanation and code, see Norvig (2006). Many other symbolic algorithms
exist that can also solve Sudokus, like dancing links (Knuth, 2000) and integer programming. These
algorithms are superior in almost every respect but one: they don’t comply with the interface, as
they don’t operate on a set of vectors, and they’re not differentiable. As such they cannot be used in
a combined model with a deep learning perceptual front-end.
There is a rich litterature on logic and reasoning in artificial intelligence and machine learning.
Please see section 5 for a discussion of related work.
2	Recurrent Relational Networks
Figure 1: A recurrent relational network on a fully connected graph with 3 nodes. The nodes’
hidden states hit are highlighted. The dashed lines indicate the recurrent connections. Subscripts
denote node indices and superscripts denote steps t. For a figure of the same graph unrolled over 2
steps see the appendix.
Let’s consider what a relational reasoning module might need in order to implement an elimination
strategy to solve a Sudoku puzzle. Our intention is not to directly implement an elimination strategy,
nor to restrict the network to it, but it will serve as a minimal requirement. The elimination strategy
works by noting that if a certain cell is given as a “7”, one can safely remove “7” as an option from
other cells in the same row, column and box. If this is done for all cells, one might end up with cells
that only have a single possible digit left. This digit could then be removed from the possible cell
values in the same row, column and box, and so on. To implement this strategy, each cell needs to
send a message to each other cell in the same row, column and box saying “I’m a 7, hence you can’t
also be a 7”. Each cell should then consider all messages coming in, and update its own state. With
the updated state each cell should send out new messages, and so forth.
2
Under review as a conference paper at ICLR 2018
We will formalize this by considering the Sudoku as a graph. The graph has i ∈ {1, 2, ..., 81} nodes,
one for each cell in the Sudoku. Each node has an edge to and from all nodes that is in the same
row, column and box in the Sudoku. Each node has a feature vector xi . As per the interface this
set of feature vectors x = {x1, x2, ..., x81} are the inputs to our relational reasoning module and
would in general be the output of a perceptual front-end. For our Sudoku example each xi encodes
the initial cell content (empty or given) and the row and column position. At each step t each node
has a hidden state vector hit . We initialize this hidden state to the features, such that hi0 = xi . At
each step t, each node sends a message to each of its neighboring nodes. We define the message mtij
from node i to node j at step t by
mtj = f(ht-1,hjT),	⑴
where f, the message function, is a multi-layer perceptron (MLP). This allows the network to learn
what kind of messages to send. Since a node needs to consider all the incoming messages we sum
them with
m.tj = X mitj ,	(2)
i∈N(j)
where N (j) are all the nodes that have an edge into node j, i.e. the nodes in the same row, column
and box. Finally we update the node hidden state via
hj = g (hjT,xj,mtj),	⑶
where g, the node function, is another learned neural network. The dependence on the previous
node hidden state htj-1 allows the network to iteratively work towards a solution instead of starting
with a blank slate at every step. Injecting the feature vector xj at each step like this allows the node
function to focus on the messages from the other nodes instead of trying to remember the input.
The above equations for sending messages and updating node states define a recurrent relational
network’s core, and we now use itto train a neural network in a supervised manner to solve a Sudoku.
At every step each node outputs a probability distribution over the digits 1-9 and we minimize
the cross entropy between this output probability distribution and the target digit from the Sudoku
solution. The output probability distribution oit for node i at step t is given by
ot = Softmax (r (ht)) ,	(4)
where r is a MLP that maps the node hidden state to the output logits. Given the target digit yi (1-9)
for cell i, the cross-entropy node loss lit for node i at step t is
lit = - log oit [yi] ,	(5)
where the square brackets are used to indicate the yi’th element of the vector. For a single Sudoku
puzzle x = {x1, x2, ..., x81} and its solution y = {y1, y2, ..., y81} the total loss L (x, y) is the sum
of losses computed recurrently over all I = 81 nodes and T steps,
TI
L(x,y) = XXlit .	(6)
t=1 i=1
To train the network we minimize the total loss, with respect to the parameters of the functions f,
g and r using stochastic gradient descent. See figure 1 for an example of the recurrent relational
network on a fully connected graph with 3 nodes.
At test time we only consider the output probabilities at the last step, but having a loss at every step
during training is beneficial. Since the target digits yi are constant over the steps, it encourages the
network to learn a convergent algorithm. Secondly, it helps with the vanishing gradient problem.
One potential issue with having a loss at every step is that it might force the network to learn a greedy
algorithm that gets stuck in a local minima. However, the separate output function r allows the node
hidden states and messages to be different from the output probability distributions. As such, the
network could use a small part of the hidden state for retaining a current best guess, which might
remain constant over several steps, and other parts of the hidden state for running a non-greedy
multi-step algorithm.
Sending messages for all nodes in parallel and summing all the incoming messages might seem
like an unsophisticated approach that risk resulting in oscillatory behavior and drowning out the
3
Under review as a conference paper at ICLR 2018
important messages. However, since the receiving node hidden state is an input to the message
function, the receiving node can in a sense determine which messages it wishes to receive. As such,
the sum can be seen as an implicit attention mechanism over the incoming messages. Similarly the
network can learn an optimal message passing schedule, by ignoring messages based on the history
and current state of the receiving and sending node.
We have described our model from the example of solving Sudokus, but the model is in no way
limited to Sudokus. In general, as per the interface, it takes as input a set of objects described by
feature vectors and a set of edges detailing how the objects interacts. If the edges are unknown,
the graph can be assumed to be fully connected. In this case the network will need to learn which
objects interact with each other. If the edges have attributes, eij , the message function in equation 1
can be modified such that mtij = f hit-1, htj-1, eij . If the output of interest is for the whole graph
instead of for each node the output in equation 4 can be modified such that there’s a single output
ot = r (Pi hit). The loss can be modified accordingly.
3	Experiments
Code to reproduce the experiments can be found at redacted for peer review.
3.1	Sudoku
We generate a dataset of 216,000 puzzles with an equal number of 17 to 34 givens from the collection
of 49,151 unique 17-givens puzzles gathered by Royle (2014). We use the solver from Norvig
(2006) to solve all the puzzles first. Then we split the puzzles into a test, validation and training
pool. To generate the training, validation and test set, we sample puzzles from the respective pools,
add between 0 to 17 givens from the solution, and swap the digits according to a random map per
Sudoku, e.g. 1 → 5, 2 → 3, etc.
We consider each of the 81 cells in the 9x9 Sudoku grid a node in a graph, with edges to and
from each other cell in the same row, column and box. Denote the digit for cell j dj (0-9, 0 if
not given), and the row and column position rowj (1-9) and columnj (1-9) respectively. The node
features are then xj = MLP ([embed (dj) ; embed (rowj) ; embed (columnj)]) where each embed
is a separate 16 dimensional learnable embedding and [a; b] denotes the concatenation of a and
b. We don’t use any edge features and we don’t treat the cells with given digits in any special
way. The message from i to j is mitj = MLP hit-1; htj-1 . The node hidden state is given by
htj = LSTM MLP xj; m.tj where LSTM denotes a Long Short Term Memory cell (Hochreiter
& Schmidhuber, 1997). The LSTM cell and hidden state is initialized to zero. The output function
r is a linear layer with ten outputs to produce the output logits oit . All the MLP’s are four layers
with 96 nodes. The first 3 layers have ReLU activation functions and the last layer is linear. The
LSTM also has 96 nodes. We run the network for 32 steps. We train the model for 300.000 gradient
updates with a batch size of 252 using Adam with a learning rate of 2e-4 and L2 regularization of
1e-4 on all weight matrices.
Our network learns to solve 94.1% of even the hardest 17-givens Sudokus after 32 steps. For more
givens the accuracy quickly approaches 100%. Since the network outputs a probability distribution
for each step, we can visualize how the network arrives at the solution step by step. For an example
of this see figure 2. In the first step, the network uses the elimination strategy to reduce the number
of possible digits. For subsequent steps it assigns softer probabilities to the digits, and seems to try
a number of different configurations. Once the solution is found it locks onto it and doesn’t change.
To examine our hypothesis that multiple steps are required we plot the accuracy as a function of
the number of steps. See figure 3. We can see that even simple Sudokus with 33 givens require
upwards of 10 steps of relational reasoning, whereas the harder 17 givens continue to improve even
after 32 steps. Figure 3 also shows that the model has learned a convergent algorithm. The model
was trained for 32 steps, but seeing that the accuracy increased with more steps, we ran the model
for 64 steps during testing. At 64 steps the accuracy for the 17 givens puzzles increases to 96.6%.
We compare our network to the relational network (Santoro et al., 2017). We train two relational
networks: a node and a graph centric. The node centric corresponds exactly to a single step of
our network. The graph centric approach is closer to the original relational network. It does one
4
Under review as a conference paper at ICLR 2018
(a) Step 0				(b) Step 1				(c) Step 4				(d) Step 8				(e) Step 12		
4				I	2 4 τ	,	.				I	∙ 4 *	F	I				，	■	. 4 ■	F	I				♦	'	I 4 ■	F	I		
1	2	3		i		,		1	L			.		I		L		I
4	5	6		.	5	6		I	f	6			I	S			I	.
7	8	9		7	,	9		,	■	9		I	F	9		I	F	9
1	2	3		1	2	■		1		■		.	I	F		L		I
4	5	6		■	5	6		.	5	6			5	F			,	I
7	8	9		7	■	9		7	>	9		7	I	S		7	F	F
1	2	3		1	.	F		1	I	,		I	.	,		I		I
4	5	6		.	5	6		.	5	6		L	5	6			5	.
7	8	9		7	F	F		7	I	,		7	I	F		r	F	I
1	2	3		1	2	F		1	2			1	2	■		I	,	I
4	5	6		L	F	6		.	,	6		.	I	6			I	6
7	8	9		7	F	F		7	■	F		7	■	,		.	F	I
1	2	3		1	2	,		1	2	■		1	2	■		I	2	I
4	5	6		■	5	6		I	5	6		.	5	6			,	■
7	8	9		7	■	,		7	*	■		7	■	,		I	I	I
1	2	3		1	2	3		I	2	3		L		T		L	,	T
4	5	6		■	5	6		■	5	6			-	F			I	I
7	8	9		7	F	F		7	■	F		I	■	I			F	I
8				* . ■ ， ■ 8				I	-	F ■	I	F 8				ɪ	-	F ■	I	F 8				■	■	F ■	I	F 8		
1	2	3		ι	2	3		1	2	3		1	*	,		1	k	F
4	5	6			5	<		.	■	■			I	I			I	I
7	8	9		7	■	9		7	■	9			F					I
Figure 2: Example of how the trained network solves part of a Sudoku. Only the first column of a
full 9x9 Sudoku is shown for clarity. See appendix for the full Sudoku. Each cell displays the digits
1-9 with the font size scaled (non-linearly for legibility) to the probability the network assigns to
each digit. We only show steps 0, 1, 4, 8 and 12 due to space constraints. Notice how the network
eliminates the given digits 4 and 8 from the other cells in the first step. For this particular Sudoku
the network converges to the solution after approximately 20 steps. Animations showing how the
trained network solves Sodukos, including a failure case can be found at imgur.com/a/ALsfB.
step of relational reasoning as our network, then sums all the node hidden states. The sum is then
5
Under review as a conference paper at ICLR 2018
Figure 3: Accuracy of our trained network on Sudokus as a function of number of steps. Even
simple Sudokus with 33 givens require about 10 steps of relational reasoning to be solved. The
dashed vertical line indicates the 32 steps the network was trained for. The network appears to have
learned a convergent relational reasoning algorithm such that more steps beyond 32 improve on the
hardest Sudokus.
passed through a 4 layer MLP with 81 ∙ 9 outputs, one for each cell and digit. The graph centric
model has larger hidden states of 256 in all layers to compensate somewhat for the sum squashing
the entire graph into a fixed size vector. Otherwise both networks are identical to our network. We
could not get either of them to solve any Sudokus. Of the two, the node centric trained much faster
and got considerably lower loss. The only difference between the node centric relational network
and our model is the number of steps, yet the relational network fails to solve any Sudoku. This
shows that multiple steps are crucial for complex relational reasoning. The graph centric has over
4 times as many parameters as our model (944,874 vs. 201,194) but performs even worse than
the node centric. We also compare our network to other differentiable methods. See table 1. Our
network outperforms loopy belief propagation, with parallel and random messages passing updates
(Bauke, 2008). It also outperforms a version of loopy belief propagation modified specifically for
solving Sudokus that uses 250 steps, sinkhorn balancing every two steps and iteratively picks the
most probable digit (Khan et al., 2014). We also compare to learning the messages in parallel loopy
BP as presented in Lin et al. (2015). We tried a few variants including a single step as presented and
32 steps with and without a loss on every step, but could not get it to solve any 17 given Sudokus.
Finally we outperform Park (2016) which treats the Sudoku as a 9x9 image, uses 10 convolutional
layers, iteratively picks the most probable digit, and evaluate on easier Sudokus with 24-36 givens.
We also tried to train a version of our network that only had a loss at the last step. It was harder to
train, performed worse and didn’t learn a convergent algorithm.
3.2	BABI
BaBi is a text based QA dataset from Facebook (Weston et al., 2015) designed as a set of toy
prerequisite tasks for reasoning, and is widely used in the deep learning literature. It consists of
20 tasks including deduction, induction, spatial and temporal reasoning, etc. Each question, e.g.
“where is john?” is preceded by a number of facts in the form of short sentences, e.g. “john went to
the kitchen.”. A task is considered solved if a model achieves greater than 95% accuracy. The most
difficult tasks require three steps of relational reasoning. As such the relational reasoning required
is limited.
The relational reasoning module needs to reason about the facts, in context of the questions so
we consider each sentence a node in a fully connected graph. The sentences are encoded using a
LSTM with 32 hidden units. The question is also encoded using a LSTM with 32 hidden units. We
6
Under review as a conference paper at ICLR 2018
Method
Givens Accuracy
Recurrent Relational Network (this work)	17	96.6%
Loopy BP, modified (Khan et al., 2014)	17	92.5%
Loopy BP, random (Bauke, 2008)	17	61.7%
Loopy BP, parallel (Bauke, 2008)	17	53.2%
Deeply Learned Messages (Lin et al., 2015)	17	0%
Relational Network, node (Santoro et al., 2017)	17	0%
Relational Network, graph (Santoro et al., 2017)	17	0%
Deep Convolutional Network (Park, 2016)	24-36	70%
Table 1: Comparison of methods for solving Sudoku puzzles. Only methods that are differentiable
are included in the comparison.
concatenate the last hidden state of the sentence LSTM with the last hidden state of the question
LSTM and pass that through a MLP. The output is considered the node features xi . We set all
edge features eij to the question encoding following (Santoro et al., 2017). We only consider the
preceding 20 sentences to a question. Our message function f is identical to the Sudoku message
function, i.e. a MLP which feeds into a LSTM. We run our network for five steps. To get a graph
level output, we use a MLP over the sum of the node hidden states, with 3 layers, the final being
a linear layer that maps to the output dimensionality logits. Unless otherwise specified we use 128
hidden units for all layers and all MLPs are 3 ReLU layers followed by a linear layer. We train on
all the 10.000 training samples, using Adam with a batch size of 640, a learning rate of 2e-4 and L2
regularization with a rate of 1e-4.
Our trained network solves 19 of 20 tasks, which is competitive with state-of-the-art. Most tasks
are quickly and perfectly learned. The only task that the network cannot complete is number 16, the
induction task. See table 2 for the tasks where the model achieved less than 100% accuracy.
Task	2	3	5	14	16	18	19
Accuracy	99.7%	96.5%	99.6%	99.9% 45.1%	99.7%	99.9%
Table 2: BaBi results. The tasks that are not shown are all 100% accurate.
On the	BaBi task the	relational	network	solves 18/20 tasks, notably failing	on the 2	and	3	sup-
porting	fact tasks (Santoro et al.,	2017).	Training	the relational network on BaBi takes	millions	of
updates, and a couple of days on 10+ K80 GPUs (David Raposo, 2017, personal communication).
In comparison our network naturally perform multi-step relational reasoning, and requires around
half a million updates which takes approximately 12 hours on 4 Titan X GPUs. We hypothesize that
the relational network takes longer to train because it cannot naturally perform multi-step relational
reasoning.
End-to-end memory networks (Sukhbaatar et al., 2015) solves 14/20 tasks by using multiple re-
current hops of attention over the encoded sentences. The Sparse Differentiable Neural Computer
(SDNC) is a differentiable computer modeled on the Turing Machine (Rae et al., 2016). It has a
large external memory bank it updates by using sparse reads and writes. It solves 19/20 tasks which
is state-of-the-art. It also fails at the induction task. EntNet reports 20/20 tasks solved, but does so
training on each task independently. Trained jointly on all tasks EntNet solves 16/20 tasks (Henaff
et al., 2016).
4	Discussion
We have proposed a general relational reasoning model for solving tasks requiring an order of mag-
nitude more complex relational reasoning than the current state-of-the art. It can be added to any
deep learning model to provide a powerful relational reasoning capacity. We get state-of-the-art
7
Under review as a conference paper at ICLR 2018
results on Sudokus solving 96.6% of the hardest Sudokus with 17 givens. We also get results com-
petitive with state-of-the-art results on the BaBi dataset solving 19/20 tasks.
Many difficult problems require complex relational reasoning and we see several exciting applica-
tions where our model might improve on state-of-the-art. Silver et al. (2017) mastered the game of
Go with a deep residual network (He et al., 2016) with 79 convolutional layers in total that evalu-
ate game position values and proposes moves combined with a monte-carlo tree search algorithm.
It would be interesting to replace the deep residual network with our proposed model, and see if
the capacity for complex relational reasoning could improve on AlphaGo. In a similar manner it
might be possible to use it in a deep reinforcement learning setup and improve on the difficult Atari
games that require long term planning and reasoning, e.g. Montezuma’s revenge or Frostbite (Mnih
et al., 2013). Finally we hypothesize it could improve on deep image captioning models (Karpathy
& Fei-Fei, 2015) since reasoning about the people and objects involved in an image is essential to
describing it.
Loopy belief propagation is widely used for performing approximate inference in graphical mod-
els with loops (Murphy et al., 1999). For the Sudoku problem our network learned an inference
algorithm that outperforms loopy belief propagation, and it would be interesting to see if we could
likewise improve on other problems that rely on loopy belief propagation. One prominent example
of loopy belief propagation is in error correcting codes which everything from mobile phones to
satellites rely on for robust communication (Shannon, 1948; MacKay & Neal, 1996).
5	Related work
Relational networks (Santoro et al., 2017) and interaction networks (Battaglia et al., 2016) are the
most directly comparable to ours. They compare to using a single step of equation 3. Since it only
does one step it cannot naturally do complex multi-step relational reasoning. In order to solve the
tasks that require more than a single step it must compress all the relevant relations into a fixed size
vector, then perform the remaining relational reasoning in the last forward layers. Both relational
networks, interaction networks and our proposed model can be seen as an instance of Graph Neural
Networks (Scarselli et al., 2009), (Gilmer et al., 2017). Our main contribution is showing how these
can be used for complex relational reasoning.
Our model can be seen as a completely learned message passing algorithm. Belief propagation is
a hand-crafted message passing algorithm for performing exact inference in directed acyclic graph-
ical models. If the graph has cycles, one can use a variant, loopy belief propagation, but it is not
guaranteed to be exact, unbiased or even converge. Empirically it works well though and it is widely
used (Murphy et al., 1999). Several works have proposed replacing parts of belief propagation with
learned modules (Heess et al., 2013; Lin et al., 2015). Our work differs by not being rooted in loopy
BP, and instead learning all parts of a general message passing algorithm. Ross et al. (2011) pro-
poses Inference Machines which ditch the belief propagation algorithm altogether and instead train
a series of regressors to output the correct marginals by passing messages on a graph. Wei et al.
(2016) applies this idea to pose estimation using a series of convolutional layers and Deng et al.
(2016) introduces a recurrent node update for the same domain.
There is rich litterature on combining symbolic reasoning and logic with subsymbolic distributed
representations which goes all the way back to the birth of the idea of parallel distributed processing
McCulloch & Pitts (1943). See (Raedt et al., 2016; Besold et al., 2017) for two recent surveys.
Here we describe only a few recent methods. Serafini & Garcez (2016) introduces the Logic Ten-
sor Network (LTN) which describes a first order logic in which symbols are grounded as vector
embeddings, and predicates and functions are grounded as tensor networks. The embeddings and
tensor networks are then optimized jointly to maximize a fuzzy satisfiability measure over a set of
known facts and fuzzy constraints. In Donadello et al. (2017) the LTN is used to improve on a
Semantic Image Interpretation task by incorporating fuzzy prior constraints, e.g. cats usually have
tails. Sourek et al. (2015) introduces the Lifted Relational Network which combines relational logic
with neural networks by creating neural networks from lifted rules and training examples, such that
the connections between neurons created from the same lifted rules shares weights. Our approach
differs fundamentally in that we do not aim to bridge symbolic and subsymbolic methods. Instead
we stay completely in the subsymbolic realm. We do not introduce or consider any explicit logic,
aim to discover (fuzzy) logic rules, or attempt to include prior knowledge in the form of logical
8
Under review as a conference paper at ICLR 2018
constraints. The relational reasoning algorithm learned by our network is a black box to the extent
that any neural network is a black box.
Amos & Kolter (2017) Introduces OptNet, a neural network layer that solve quadratic programs
using an efficient differentiable solver. OptNet is trained to solve 4x4 Sudokus amongst other prob-
lems and beats the deep convolutional network baseline as described in Park (2016). Unfortunately
we cannot compare to OptNet directly as it has computational issues scaling to 9x9 Sudokus due to
an implementation error (Brandon Amos, 2018, personal communication).
References
Brandon Amos and J Zico Kolter. Optnet: Differentiable optimization as a layer in neural networks.
arXiv preprint arXiv:1703.00443, 2017.
Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, et al. Interaction networks
for learning about objects, relations and physics. In Advances in Neural Information Processing
Systems,pp. 4502-4510, 2016.
Heiko Bauke. Passing messages to lonely numbers. Computing in Science & Engineering, 10(2):
32-40, 2008.
Tarek R Besold, Artur d’Avila Garcez, Sebastian Bader, Howard Bowman, Pedro Domingos, Pas-
cal Hitzler, Kai-UWe KUhnberger, LUis C Lamb, Daniel Lowd, Priscila Machado Vieira Lima,
et al. Neural-symbolic learning and reasoning: A survey and interpretation. arXiv preprint
arXiv:1711.03902, 2017.
Zhiwei Deng, Arash Vahdat, Hexiang HU, and Greg Mori. StrUctUre inference machines: RecUrrent
neUral networks for analyzing relations in groUp activity recognition. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, pp. 4772-4781, 2016.
Ivan Donadello, LUciano Serafini, and ArtUr d’Avila Garcez. Logic tensor networks for semantic
image interpretation. arXiv preprint arXiv:1705.08968, 2017.
JUstin Gilmer, SamUel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. NeUral
message passing for qUantUm chemistry. arXiv preprint arXiv:1704.01212, 2017.
Kaiming He, XiangyU Zhang, Shaoqing Ren, and Jian SUn. Deep residUal learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
Nicolas Heess, Daniel Tarlow, and John Winn. Learning to pass expectation propagation messages.
In Advances in Neural Information Processing Systems, pp. 3219-3227, 2013.
Mikael Henaff, Jason Weston, ArthUr Szlam, Antoine Bordes, and Yann LeCUn. Tracking the world
state with recUrrent entity networks. arXiv preprint arXiv:1612.03969, 2016.
Sepp Hochreiter and JUrgen Schmidhuber. Long short-term memory. Neural computation, 9(8):
1735-1780, 1997.
Andrej Karpathy and Li Fei-Fei. Deep visUal-semantic alignments for generating image descrip-
tions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.
3128-3137, 2015.
Sheehan Khan, Shahab Jabbari, Shahin Jabbari, and Majid Ghanbarinejad. Solving sUdokU Using
probabilistic graphical models. data last retrieved January, 1, 2014.
Donald E KnUth. Dancing links. arXiv preprint cs/0011047, 2000.
Brenden M Lake, Tomer D Ullman, JoshUa B TenenbaUm, and SamUel J Gershman. BUilding
machines that learn and think like people. Behavioral and Brain Sciences, pp. 1-101, 2016.
GUosheng Lin, ChUnhUa Shen, Ian Reid, and Anton van den Hengel. Deeply learning the messages
in message passing inference. In Advances in Neural Information Processing Systems, pp. 361-
369, 2015.
9
Under review as a conference paper at ICLR 2018
David JC MacKay and Radford M Neal. Near shannon limit performance of low density parity
check codes. Electronics letters, 32(18):1645, 1996.
Warren S McCulloch and Walter Pitts. A logical calculus of the ideas immanent in nervous activity.
The bulletin Ofmathematical biophysics, 5(4):115-133,1943.
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wier-
stra, and Martin Riedmiller. Playing atari with deep reinforcement learning. arXiv preprint
arXiv:1312.5602, 2013.
Kevin P Murphy, Yair Weiss, and Michael I Jordan. Loopy belief propagation for approximate
inference: An empirical study. In Proceedings of the Fifteenth conference on Uncertainty in
artificial intelligence, pp. 467-475. Morgan Kaufmann Publishers Inc., 1999.
Peter Norvig. Solving every sudoku puzzle, 2006. URL http://norvig.com/sudoku.html.
Kyubyong Park. Can neural networks crack sudoku?, 2016. URL https://github.com/
Kyubyong/sudoku.
Jack Rae, Jonathan J Hunt, Ivo Danihelka, Timothy Harley, Andrew W Senior, Gregory Wayne,
Alex Graves, and Tim Lillicrap. Scaling memory-augmented neural networks with sparse reads
and writes. In Advances in Neural Information Processing Systems, pp. 3621-3629, 2016.
Luc De Raedt, Kristian Kersting, Sriraam Natarajan, and David Poole. Statistical relational artificial
intelligence: Logic, probability, and computation. Synthesis Lectures on Artificial Intelligence
and Machine Learning, 10(2):1-189, 2016.
Stephane Ross, Daniel Munoz, Martial Hebert, andJ Andrew Bagnell. Learning message-passing in-
ference machines for structured prediction. In Computer Vision and Pattern Recognition (CVPR),
2011 IEEE Conference on, pp. 2737-2744. IEEE, 2011.
Gordon Royle. Minimum sudoku, 2014. URL http://staffhome.ecm.uwa.edu.au/
~00013890/Sudokumin.php.
Adam Santoro, David Raposo, David GT Barrett, Mateusz Malinowski, Razvan Pascanu, Peter
Battaglia, and Timothy Lillicrap. A simple neural network module for relational reasoning. arXiv
preprint arXiv:1706.01427, 2017.
Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini.
The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61-80, 2009.
Luciano Serafini and Artur S dAvila Garcez. Learning and reasoning with logic tensor networks. In
AI* IA 2016 Advances in Artificial Intelligence, pp. 334-348. Springer, 2016.
CE Shannon. A mathematical theory of communication. The Bell System Technical Journal, 27(3):
379-423, 1948.
David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez,
Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. Mastering the game of go
without human knowledge. Nature, 550(7676):354-359, 2017.
Gustav Sourek, Vojtech Aschenbrenner, FiliP Zelezny, and Ondrej Kuzelka. Lifted relational neural
networks. In Proceedings of the 2015th International Conference on Cognitive Computation:
Integrating Neural and Symbolic Approaches-Volume 1583, PP. 52-60. CEUR-WS. org, 2015.
Elizabeth S SPelke and Katherine D Kinzler. Core knowledge. Developmental science, 10(1):89-96,
2007.
Elizabeth S SPelke, Grant Gutheil, and Gretchen Van de Walle. The develoPment of object PerceP-
tion. 1995.
Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al. End-to-end memory networks. In Advances
in neural information processing systems, PP. 2440-2448, 2015.
10
Under review as a conference paper at ICLR 2018
Shih-En Wei, Varun Ramakrishna, Takeo Kanade, and Yaser Sheikh. Convolutional pose machines.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4724-
4732, 2016.
Jason Weston, Antoine Bordes, Sumit Chopra, Alexander M Rush, Bart van Merrienboer, Armand
Joulin, and Tomas Mikolov. Towards ai-complete question answering: A set of prerequisite toy
tasks. arXiv preprint arXiv:1502.05698, 2015.
6	Appendix
h03
h02
x2
o01
m⅛
m3ι
m13
m2ι
m12
m13
o13
h13
h12
x2
2
m22
2
m31
2
m23
2
m21
2
m22
1
1
2
m23
h23
h22
x2
o21
h01
h11
h21
Recurrent relational network on a fully connected graph with 3 nodes. The same graph as in figure
1 unrolled over 2 steps. The node hidden states hit are highlighted. Subscripts denote node indices
and superscripts denote steps t. The dashed lines indicate the recurrent connections.
7	Neural Relational Reasoning Interface
Given a graph G specified by a set of n nodes described by d-dimensional real valued vectors,
N ∈ Rn×d and m directed edges E ∈ {1, 2, ..., n}m×2, any function f : {N, E} → R that is
almost-everywhere differentiable respects the interface.
Given that the edges have attributes described by p-dimensional real valued vectors A ∈ Rm×p any
function f : {N, E, A} → R that is almost-everywhere differentiable respects the interface.
Note that the functions map to a single real value. This might seem counter-intuitive. For the
Sudoko problem for instance, the function must output a probability distribution over the digits for
each of the 81 cells. But for the interface what matters is that the function output a single real valued
loss, and be differentiable, such that it can be trained end-to-end with a perceptual front-end using
stochastic gradient descent.
11
Under review as a conference paper at ICLR 2018
An example Sudoku. The full Sudoku from which the column in figure 2 is taken. Each of the 81
cells contain each digit 1-9, which is useful if the reader wishes to try to solve the Sudoku as they
can be crossed out or highlighted, etc. The digit font size corresponds to the probability our model
assigns to each digit at step 0, i.e. before any steps are taken. Subsequent pages contains the Sudoku
as it evolves with more steps of our model.
			1	2	3	1	2	3	1	2	3	1	2	3	1	2	3							1	2	3
4			4	5	6	4	5	6	4	5	6	4	5	6	4	5	6			6				4	5	6
			7	8	9	7	8	9	7	8	9	7	8	9	7	8	9						9	7	8	9
1	2	3	1	2	3			~3~		~Γ		1	2	3				1	2	3	1	2	3	1	2	3
4	5	6	4	5	6							4	5	6	4			4	5	6	4	5	6	4	5	6
7	8	9	7	8	9							7	8	9				7	8	9	7	8	9	7	8	9
1	2	3	1	2	3	1	2	3	1	2	3	1	2	3	i	2	3	1	2	3	1			1	2	3
4	5	6	4	5	6	4	5	6	4	5	6	4	5	6	4	5	6	4	5	6				4	5	6
7	8	9	7	8	9	7	8	9	7	8	9	7	8	9	7	8	9	7	8	9				7	8	9
1	2	3			T				1	2	3	1	2	3	1	2	3	1	2	3	i	2	3		T"	
4	5	6							4	5	6	4	5	6	4	5	6	4	5	6	4	5	6			
7	8	9						9	7	8	9	7	8	9	7	8	9	7	8	9	7	8	9			
1	2	3	1	2	3	1	2	3				1	2	3	1	2	3				1	2	3	1	2	3
4	5	6	4	5	6	4	5	6				4	5	6	4	5	6		5		4	5	6	4	5	6
7	8	9	7	8	9	7	8	9		8		7	8	9	7	8	9				7	8	9	7	8	9
1	2	3	1			1	2	3	1	2	3	1	2	3	1	2	3	1	2	3	1	2	3	1	2	3
4	5	6				4	5	6	4	5	6	4	5	6	4	5	6	4	5	6	4	5	6	4	5	6
7	8	9				7	8	9	7	8	9	7	8	9	7	8	9	7	8	9	7	8	9	7	8	9
1	2	3	i	2	3	1	2	3	1	2	3				T"			1	2	3	1	2	3	1	2	3
4	5	6	4	5	6	4	5	6	4	5	6							4	5	6	4	5	6	4	5	6
7	8	9	7	8	9	7	8	9	7	8	9			9				7	8	9	7	8	9	7	8	9
			1	2	3	1	2	3	1	2	3	1	2	3	1	2	3	1	2	3	1	2	3	1	2	3
			4	5	6	4	5	6	4	5	6	4	5	6	4	5	6	4	5	6	4	5	6	4	5	6
	8		7	8	9	7	8	9	7	8	9	7	8	9	7	8	9	7	8	9	7	8	9	7	8	9
1	2	3	1	2	3	1	2	3	1	2	3				1	2	3	1	2	3	1	2	3	1	2	3
4	5	6	4	5	6	4	5	6	4	5	6			6	4	5	6	4	5	6	4	5	6	4	5	6
7	8	9	7	8	9	7	8	9	7	8	9				7	8	9	7	8	9	7	8	9	7	8	9
12
Under review as a conference paper at ICLR 2018
Step 1
I		I	I	2	I	1	2	F	1	I	3	1	I	3	I	.	3		*			■		■		3
4	■	I	L	5	.	L	5		I	5	.	I	5		L	5	■		I	6		.	I	.	5	t
,	F	I	7	8	F	7	8	F	7	F	F	7	8	f	7	8	F	,	■		1	■	9	7	8	f
ι	.	F	I	.	F	ɪ			ɪ	2	I	1	.	f			I	ɪ	I	f	I	.	F	I	I	f
L	5	6	L	5	6		,	■		■	■	.	5	.	4	■	*	.	I	■	.	5	*	.	5	■
7	F	9	7	8	9	,	F	I	1	F	,	7	8	f	T	F	,	7	8	f	7	8	F	7	8	f
ɪ	2	F	I	2	F	1	2	■	ɪ	.	3	I	.	3	ɪ	I	3	ɪ	2	3	1	■	■	1	I	3
I	5	6	.	5	6	■	5	6	■	5	6	.	5	■	■	5	6	4	F	■			F	4	5	■
7	F	9	7	8	9	7	8	,	7	F	9	7	8	f	7	8	9	7	8	,	7	I	I	7	8	,
I	I	F			T	I		I	1	I	F	1	I		I	.	F	1	I	f	■		F	1	~	
L	5	6	I	f	t	.	,	<	4	5	6	4	5	.	.	5	6	4	I	■	4		6	■		■
7	F	F	I	F	I	,	■	9	7	F	F	7	F	f	7	F	F	7	8	f	7	8	F	,		
I	2	F	ɪ	2	F	ɪ	2	F	ɪ		F	1	2	3	ɪ	2	3	L		t	ɪ	.	3	1	I	3
I	I	6	4	F	6	4	F	6	.	I		4	,	■	I	,	6	I	5		4	f	6	4	■	6
7	I	I	7	F	F	7	F	F	I	8	,	7	F	,	7	F	9	I	1		7		F	7		9
I	2	F	1		I	1	2	I	1	I	3	I	2	3	ɪ	2	3	ɪ	.	3	I		3	I	k	3
.	5	6		■	.	4	5	6	4	5	6	4	5	■		5	6	4	F	*	4	f	6	4	.	6
7	F	F	T	■	I	7	8	,	7	,	9	7	F	,	7	■	9	7	8	9	7	8	F	7	8	9
I	2	3	■	2	F	I	2	F	I	I	3	I	k		T"	■	■	I	2	3	I	2	3	1	I	3
.	5	6	4	5	6	4	5	6	4	5	■	.	■			■	1	4	F	■	4	5	6	4	5	6
7	F	F	7	F	F	7	F	F	7	F	F	,	■	9	T	■	I	7	8	F	7	8	F	7	8	,
I	I	F	1	2	■	1	2		I	I	3	ɪ	2	3	ɪ	2	3	1	2	3	1	2	3	1	■	3
	,	■	4	5	6	4	5	6	4	5	■	4	5	*	■	5	■	4	,	■	4	5	6	4	5	6
I	8		7	F	9	7	■	I	7	F	F	7	F	,	7	F	,	7	F	9	7	■	I	7	■	9
1	2	3	ɪ	2	■	1	2		I	.	3	I	■		ɪ	2	3	1	2	3	1	2	3	1	*	3
I	5	■	4	5	■	4	5	■	4	5			■	6	I	5	■	4	,	■	4	5	■	4	5	<
7	F	9	7	F	9	7	,	,	7	F	F	T	I	I	7	8	,	7	8	9	7	8	I	7	8	9
13
Under review as a conference paper at ICLR 2018
Step 4
I	■	.		2	1 2	1	3	1 ■ ，	3	■ ■		♦	■	I	3
4		5	■	5		I	5 ■	6		■	I	I	，
~	F	I		7	8	7	∙	7	7	8	7 B .	■	F		9	， ∙
	■ '	■	■	I	一 Γ	2	1	,	,	I	I	1		1 . ，	， ■ ，
6		6	■ . ■	,	I	♦	5	■	4	.	L	,		5	5 ■
	9	9	,	I	I	- ，	7	S	■	I	I	7	8		7	8	7	8
	■ ■	■ ，	1 » ，		3	3	2^^		1	3
	5	6	5	6	5	6	6	5	1	6	« .		■ . .	4
	■，	7	8	7	8	.	9	7	8	，	»	9	~	F		■	F	I	■ .
	■ ，	" Γ	,	,	I	ι	ɪ . ,	* ■ ■	1		，一，	"^~2~"
	5	6	♦	F	I	♦	I	F	4	5	6	4	5	.	5	6	4		4	6	■	I	F
		■	F	I	9	7	，	7	,	■	7	7	8		7	8	■	■	I
	2	，	2	.	2	.	，	1	2	3	2	3	ɪ .		3	1 ■
	6	4	6	4	6	■	I	-		6	5		4	■	6	S
	. .	7	7	.	∙	8	7	.	,	，	9	~	I		7	.	■	9
	2	■	1	'	'	I	3	2	3	2	3	3		3	1 ■ ,
	5	6	♦	F	I	•	»	F	4	5	6	4	5	-	5	6	4		4	6	4	∙	6
	■ ■	■	F	I	8	1	.	9	7	7	-	9	7	-	9		7	，	7	，	9
	2	3	2	.	2	.	3	I	■	I	"1 ~'~"	2	3		2	3	，
	，	6	4	5	6	4	5	6	4	5	-	♦	-	I	■	I	I	4		4	5	6	，	5	6
7	.	.		7	7	.	■	7	9	' .	7	8		i 8	7	8
		*	2	.	1	Z	3	2	3	2	3	1 -		2	3	1 ，
■	I	F		4	5	6	4	5	6	4	5	■	4	5	■	5	■	，		4	5	6	*	5	6
8		7	9	7	■	∙	7	7	.	■	7	.	■	，	-	9		7	■	∙	7	■	9
1	，	3		2	∙	1	2	.	3	■	'	I	* ，	1	，	3		2	3	ι	，
'	F	F		4	5	■	4	5	■	4	5	■	6	，	4		4	5	■	4	5	■
，	■	9		7	.	9	7	■	7	■	F	I	8	7	e	9		7	■	∙	7 B 9
14
Under review as a conference paper at ICLR 2018
Step 8
'	'	I	2	1	ɪ	■	P	I	-	I	L		■	■	F	♦	■	F	3	
4	■	I	I	■	I	I	5 ∙	，	5		6	■ 1 -	■	I	
■	I	I	■ ■ .	■	F	I	7	■	8	7		■	F	I	9	'	I	
♦	■	I	,	,	I	- Γ	2	1			，	I	■	I	■ 1	
. ■	6	■	F	F	,	I	I	,	I	I	4	f	*	5 ■	5	
9	.	S	'	I	I	■	I	F	■	F	I	一	ψ	7	8	7	8	.	7	8	
♦	■	I	I	I	I	I	-	I	，	一 Γ	L	3	-^^2~^	1	I	-	
5	∙	，	5	6	，	L	6	'	I	I	'	-	I	4	
7	∙	8	， ■ ,	9	， ∙	I	9	■	F	I	■	F	I	■	F	
♦	'	F	Γ		1	■	if	1	,	1 ■	I	■	P	一_2-	
5 6	*	f	I	♦ ， ，	I	4	5	■			4	4	∙	6	■	I	
7	，	I	I	,	9	■	I	I	7	■	7	F	7	8	7	8	r	■	
2	1	■	f	2	.	I	.	,	2	I	3	ɪ	-	F	3	1	
6	4	■	4	6	,	I	I			■	5	，	6	■ .	
7	■	∙	7	■	7	■	8	7	■	I	9	■	1	F	7	■	，	■	
2	1	■	■	I	3	2 ≡	.	3	3	3	■ ■	
5 «	*	f	I	■ ■ .	4	›	6	4	5	■	■	«	4	4	■	«	■ .	
7	，	*	f	I	8	9	7	.	,	9	7	∙	9	7	-	■	7	.	9	
~~■ ~Γ	*	If	2	, ■ ，	一	I	I	-1-	.	* ■ ，	2	■ ■	
■	I	F	11	5	∙	*	>	6	4	5	■	■	F	I	■	I	4	4	5	6	s 6	
*	F	I	7	■	7	■	7	9	■	I	7	8	7	8	7	8	
■	■	I	I	I	■	ɪ	2	.	■	3	2	，	2	3		1	3	2	3	1	
■	I	-	4	5	∙	4	'	6	4	5	■	4	5	■	.	,	♦	4	5	6	5 6	
8	7	-	9	7	-	7	■	,	7	■	■	7	I	9	7	■	∙	，	-	9	
1	*	II	2	■ 3	■	■	I	■	■	3	2	3	I	■	
,	I	I	4	5	4	.	■	4	5	■	6	■	1	，	4	5	,	5	
，	7	-	9	7	■	7	■	∙	■	F	I	8		,	,	9	7	«	■	7	■	9	
15
Under review as a conference paper at ICLR 2018
Step 12
'	'	I 4 ■	I	I	2 ,	I	I ■	F	I	1 ♦	-	I ■	F	I	ɪ L 7	. , 5 - ■ ，	I	-	I ■	，	. 8	. I 7	I	I 5 •	■	■	F 6 ■	I	I	'	■	I ■	-	I 9	3 ■	-	I -	-	I
'	■	I		Γ	I	2	1		I	I	I	I	■		L	I	I
■	I	■	6	■	I	F	I	F	I		4	F	I	■ ， '	5 ∙	5
9	■	F	F	,	I	I	I	F	I	I	f	I		I	I	7	8	.	7	8	7	8
'	■	I		'	■	I	I		一 Γ	L	. ，	-^^2~-	1	I	-	I
■	F	I	■	F	-	5		6			6	♦	I	I	'	I	I	4
7	8	T	F	.		9	*	I	I	r	■	9	■	I	I	■	F	I	
,	,	I	Γ	,	,	I	T"		Iif	ɪ	■ ，	I	I	r	...	7~2~~
5	■ . .	■	.	I	.	. ■		.	，	6	4	4	6	. , ■
'	F	I	*	I	I	9	I	F	I	7	■	7	■	F	8	，	8	F	I	I
■ * .	I	1	■	*	k	p	I		2	.	I		I	.	■	- Γ	1
6	4	4	■	«		I	I	♦		I	I	5	■	-	I	f
'	F	I	7	■			8 ■			9	,	I	，	■	F	.	F	，
2~^	1	,	,	I	L	3	1 ，		-~Γ	，		1 . ，
■	F	■	■ . .	■ . .	4	■ 6	4	5	■		， ♦	4	4	■	6	6
'	I	I	'	F	I	8	.	■	9	T	■	l		F	F	■	9	7	∙	■	7	∙	9
~~ ~Γ	I	■	f	2	I	>		T"	I	,	， ∙ ，	2	ɪɪp
,	I	I	4	5	∙	-	6	4	5	■	. ■ ,		F	I	4	∙	,	4	5	6	5	6
■	F	I	7	7	∙	7	■ »	9		F	I	7	8	7	8	7	8
♦ ■ -		* ∙ ，	L	Γ	， ，	I	2	1 ，	* » ，	i	-	，
■	I	-	4	5	∙	4	.	6	4	，	4	5		， .	*	I	I	4	5	6	5	6
8	7	-	9	7	■	∙	T	■ 1	7	.	.	.	F	I	，	7	∙	∙	'- 9
1	， ♦ ，	2	■	3	,	,	I	I	■	I	-	3	2	3	ɪ ■ ■
,	I	I	4	5	■	4	■	■	4	5	-	6		■ 1	，	4	5	-	5	■
■	F	I	7	.	9	7	■	■	7	■ ∙	,	F	I	r	8	，	9	7	∙	，	9
16
Under review as a conference paper at ICLR 2018
Step 16
,	,	I 4 ■	I	I	2 ,	I	I ■	F	I		1 ,	I	I ■	F	I	■	■ 1 ■	， . 7	,	,	I ,	I	I 8	,	,	I 5 *	I	I	,	,	I 6 ,	I	I	,	,	I ,	I	I 9	3 ,	I	I ■	I	I	
,	,	I ,	I	I 9	6 ■	F	F		Γ ,	I	I ,	I	I	2 ,	I	I ,	I	I	1 ,	I	I ■	F	I	,	,	I 4 ,	I	I	,	,	I ■	I	I 7	5 8	Li) 5 ■	8	
,	,	I ,	I	I 7	■	F	I 8		,	,	I 5 ~	I	I	,	,	I ,	I	I 9	Γ ,	I	I ,	I	I	,	,	I 6 ,	I	I	2~^ ,	I	I ,	I	I	1 ,	I	I ■	-	I	4	
,	,	I 5 ,	I	I		3	,	,	I ,	I	I 9	-1 " ,	I	I ,	I	I	,	,	I 4 ~	I	I	'	■	I ■	I	I 7	,	,	I ♦	I	I 8	,	,	I 6 ■	■	.		I
,	,	I 6 ,	I	I	I 4 7	f f f	■	■	， 4	.	- 7	,	,	I ,	I	I 8	2 ♦	I	I '	I	I	■	■	F ,	I	I 9	■	■	I 5 ,	I	I	Γ ,	I	I ,	I	I	1	
2~^ ■	I	I ,	I	I	1		,	,	I ,	I	I 8	,	,	I 6 ,	I	I	,	,	I 5 ,	I	I	Γ ,	I	I ,	I	I	,	,	I ■	.	. 9	,	,	I 4 ■	F	.	I 7	f
~~'~Γ ,	I	I ■	F	I	L 7	f ,	2 6 7	.	.	'	■	F ，5 ɪ	F	I	,	,	I ,	I	I 9	"1 ~'~" ,	I	I ■	F	I	■	■	I 4 ɪ	■	.	2 ， ■ 7	8	L I	f 6
'	■	I ,	I	I 8	I 4 I	■ ■ 9	♦	■	F 4	6 ɪ	■	-	Γ ■	.	. ,	I	I	■	■	I ♦	F	I 7	2 ,	I	I ,	I	I	1 ■ . .	... 5 ， ，	I . r	I 6 9
1 ,	I	I ■	F	I	I 4 7	9	2 7	.	'	■	F 4	S *	F	I	,	,	I 6 '	I	I	■	■	I ,	I	I 8	- Γ ɪ	.. ■	F	I	2 5	∙ 7	■	L ,	F I 9
17
Under review as a conference paper at ICLR 2018
Step 20
,	,	I 4 ,	I	I	2 ,	I	I ,	I	I	1 ,	I	I ■	I	I	,	,	I ,	I	I 7	,	,	I ,	I	I 8	,	,	I 5 ,	I	I	,	,	I 6 ,	I	I	,	,	I ,	I	I 9	3 ,	I	I ,	I	I
,	,	I ,	I	I 9	,	,	I 6 ■	I	I	Γ ,	I	I ,	I	I	2 ,	I	I ,	I	I	1 ,	I	I ,	I	I	,	,	I 4 ,	I	I	,	,	I ,	I	I 7	■	■	I ■	I	I 8	,	,	I 5 ■	F	I
,	,	I ,	I	I 7	,	,	I ,	I	I 8	,	,	I 5 ,	I	I	,	,	I ,	I	I 9	Γ ,	I	I ,	I	I	,	,	I 6 ,	I	I	2~^ ,	I	I ,	I	I	1 ,	I	I ,	I	I	,	,	I 4 ,	I	I
,	,	I 5 ,	I	I	Γ ,	I	I ,	I	I	,	,	I ,	I	I 9	-1 " ,	I	I ,	I	I	,	,	I 4 ,	I	I	,	,	I ,	I	I 7	,	,	I ,	I	I 8	,	,	I 6 ,	I	I	2~~ ,	I	I ,	I	I
,	,	I 6 ,	I	I	'	■	I 4 ɪ	1	.	,	,	I *	I	I 7	,	,	I ,	I	I 8	2 ,	I	I ,	I	I	,	,	I ,	I	I 9	,	,	I 5 ,	I	I	Γ ,	I	I ,	I	I	1 ,	I	I '	I	I
2~^ ,	I	I ,	I	I	1 ,	I	I ,	I	I	,	,	I ,	I	I 8	,	,	I 6 ,	I	I	,	,	I 5 ,	I	I	Γ ,	I	I ,	I	I	,	,	I ,	I	I 9	,	,	I 4 ■	I	I	,	,	I ,	I	I 7
Γ ,	I	I ,	I	I	,	,	I ■	F	I 7	■	■	I 6 '	I	I	,	,	I 5 ,	I	I	,	,	I ,	I	I 9	-1 " ,	I	I ,	I	I	,	,	I 4 ■	F	I	2~~ ,	I	I ~	F	I	■	'	I ■	I	F 8
,	,	I ,	I	I 8	■	■	I ■	.	. 9	■	■	I 4 ■	F	I	Γ ,	I	I ,	I	I	,	,	I ,	I	I 7	2 ,	I	I ,	I	I	1 ,	I	I ,	I	I	■	'	I 5 *	I	I	'	■	I 6 -	I	，
1 ,	I	I ■	I	I	,	,	I 5 ，	2~^ ♦	I	I ,	I	I	,	,	I 4 ■	I	I	,	,	I 6 ,	I	I	,	,	I ,	I	I 8	Γ ,	I	I ,	I	I	■	■	I ■	-	I 7	'	■	F ■	F	I 9
18