Under review as a conference paper at ICLR 2018
Graph2Seq: Scalable Learning Dynamics for
Graphs
Anonymous authors
Paper under double-blind review
Ab stract
Neural networks are increasingly used as a general purpose approach to learn-
ing algorithms over graph structured data. However, techniques for representing
graphs as real-valued vectors are still in their infancy. Recent works have pro-
posed several approaches (e.g., graph convolutional networks), but as we show
in this paper, these methods have difficulty generalizing to large graphs. In this
paper we propose Graph2Seq, an embedding framework that represents graphs
as an infinite time-series. By not limiting the representation to a fixed dimension,
Graph2Seq naturally scales to graphs of arbitrary size. Moreover, through anal-
ysis of a formal computational model we show that an unbounded sequence is nec-
essary for scalability. Graph2Seq is also reversible, allowing full recovery of the
graph structure from the sequence. Experimental evaluations of Graph2Seq on
a variety of combinatorial optimization problems show strong generalization and
strict improvement over state of the art.
1	Introduction
Graphs are widely used to model pairwise relationships between objects in many real-world prob-
lems (e.g., gene interactions (OzgUr et al., 2008), social networks such as Facebook (Ugander et al.,
2011), etc.). Designing algorithms over graphs is therefore a topic of first order interest in many
fields and applications. Today, most graph algorithms are designed by human experts. Unfortu-
nately, in many problems, designing graph algorithms with strong performance guarantees is very
challenging. Problems often involve messy optimization tasks with many constraints, or the current
algorithmic understanding is simply limited (e.g., approximation gaps in CS theory literature).
In recent years, deep learning has emerged as a general-purpose toolbox for a variety of challenging
learning tasks, from object recognition to language translation to learning complex heuristics directly
from data. It is thus natural to ask whether we can apply deep learning to challenging graph-based
optimization problems. The main challenge, however, is that the graph-structured data first needs
to be embedded in a high dimensional Euclidean space before it can be used in a deep learning
framework. Graph representation refers to the problem of representing graphs in Euclidean spaces.
Recent works have proposed many representation techniques for graphs (Bruna et al., 2013; Monti
et al., 2016). Notable are a family of representations called graph convolutional neural networks
(GCNN), with spatial and spectral variants, that attempt a representation by drawing inspiration
from convolutional neural networks for images (Dai et al., 2017; Niepert et al., 2016; Defferrard
et al., 2016). Some GCNN representations are for signals on a specific graph and some for varying
sized graphs, but a deeper understanding of the similarities and differences between these repre-
sentations and what they capture is largely an open question, with no consensus on one accepted
technique (empirically or mathematically). Further, a key challenge is designing a representation
that can scale to graphs of arbitrary shapes and sizes (Bruna & Li, 2017; Bronstein et al., 2017).
In this paper we propose GRAPH2SEQ, a novel method that represents graphs as a time-series.
We show that our representation is a strict generalization over GCNNs, which typically represent
graphs using fixed-dimensional vectors. Further, we show that GCNN variants and Graph2Seq are
all examples of a new computation model over graphs that we call local-gather, providing
for a conceptual and algorithmic unification. Finally, we show that Graph2Seq is information-
theoretically lossless, i.e., the graph can be fully recovered from its time-series representation. We
do this by making mathematical connections between Graph2Seq and cause-effect relationship
1
Under review as a conference paper at ICLR 2018
studies among interacting entities by observing the dynamics of generated data (Granger, 1980;
Rahimzamani & Kannan, 2016; Quinn et al., 2015).
The main advantage of Graph2Seq is that one can harness the recent successes of recurrent neu-
ral network (RNN) architectures that make inferences on time-series data. We illustrate the power
of this approach by combining Graph2Seq with an appropriate RNN architecture and using it to
tackle three classical combinatorial optimization problems, minimum vertex cover, max cut and max-
imum independent set, using reinforcement learning. On these combinatorial problems of varying
complexity-theoretic hardness, we show that Graph2Seq performs very well compared to state-
of-the-art heuristics and shows significantly better performance and generalization than previous
GCNN representations in the literature.
Summary of Results.
(1)	GRAPH2SEQ framework. We propose a general invertible technique for representing arbitrary
graphs as an infinite time-series. Graph2Seq naturally combines with RNN architectures and re-
inforcement learning frameworks for downstream graph-optimization applications resulting in new
state-of-the-art empirical performance.
(2)	Fundamental limits. We define a formal computational model, that encapsulates GRAPH2SEQ as
well as various GCNN representations in the literature, and study its fundamental limits. We show
that fixed-length representations are fundamentally limited in their capabilities and are strictly infe-
rior to the infinite time-series representation.
(3)	Evaluations. We demonstrate the representation capability of GRAPH2SEQ in conjunction with
a learning architecture involving RNNs by computing the minimum vertex cover, max cut and max-
imum independent sets of a graph. These are well-known NP-hard problems with varying hardness
of approximations. We train on a single, adversarially chosen family of graphs of size 15, and
demonstrate generalization to graphs of much larger sizes (example: 800) and across diverse graph
structures. The adversarial choice of the training set and the dynamically varying testing architec-
ture are the key deep learning innovations of this paper and are perhaps of broader interest.
(4)	Semantics of representation and learning. We provide a coherent semantic understanding of
Graph2Seq’s dynamics, both during test and training stages and present techniques that help vi-
sualize the dynamics in the learned model.
2	Related Work
Our work is at the intersection of two topical areas of deep learning.
Neural networks on graphs. Early works to apply neural network based learning on arbitrary
graphs are Gori et al. (2005); Scarselli et al. (2009). They consider an information diffusion mech-
anism, in which nodes update their states until an equilibrium is reached. Li et al. (2015) propose
a variant that use gated recurrent units to perform the state updates, and has some similarity to our
representation dynamics; however the sequence length does not vary between training and testing
nor do the authors identify the sequence itself as a representation of the graph. The notion of con-
volutional networks for graphs as a generalization of classical convolutional networks for images
was introduced by Bruna et al. (2013); Henaff et al. (2015). A key contribution here is the defini-
tion of graph convolution in the spectral domain using graph Fourier transform theory. Since then
a number of works have focused on simplifying spectral convolutions to be localized (Defferrard
et al., 2016) and easy to compute (Kipf & Welling, 2016). However spectral approaches do not
generalize readily to different graphs due to their reliance on the particular Fourier basis they were
trained on. To address this, spatial convolution methods are considered in Dai et al. (2017); Monti
et al. (2016); Niepert et al. (2016); Such et al. (2017) for different applications. In Appendix A we
discuss these models in detail where we show that the local spectral GCNNs and spatial GCNNs are
mathematically equivalent, providing a unifying view of the variety of GCNN representations in the
literature.
Combinatorial optimization. Starting with the work Hopfield & Tank (1985), performing combi-
natorial optimization using neural networks, and traveling salesman problem in particular, has been
a topical subject in deep learning (Bello et al., 2016). More recently Vinyals et al. (2015); Bello et al.
(2016) consider the traveling salesman problem using reinforcement learning. However the papers
consider two-dimensional coordinates for vertices (e.g. cities on a map), without any explicit graph
structure. As a more general solution Graves et al. (2016) proposes a differential neural computer
2
Under review as a conference paper at ICLR 2018
that is able to perform tasks like finding the shortest path. The work of Dai et al. (2017) is closest to
ours in its empirical evaluation of spatial GCNN representation used with a reinforcement learning
framework on combinatorial optimization problems. Our empirical results are significantly stronger,
both in graph classes as well as graph sizes, than this very recent baseline.
3	Graphs as Dynamical Systems
3.1	Graph2Seq
The central idea behind Graph2Seq is that the trajectory of an appropriately chosen dynamical
system induced by a graph, is a good representation for the graph. Such a representation has the
advantage of progressively capturing more and more information about the graph as the trajectory
unfolds.
Consider a directed graph G(V, E) we seek to represent. Undirected graphs will be simply repre-
sented by having bi-directional edges between a pair of connected vertices. We create a discrete-time
dynamical system in which vertex v has a state of xv(t) ∈ Rd at time t ∈ N, for all v ∈ V , and d is
the dimension of the state space. In Graph2Seq, we consider an evolution rule of the form
xv(t + 1) = g({xu (t) : u ∈ Γ(v)}) + nv(t + 1),	∀v ∈ V,t ∈ N,	(1)
where g(∙) is a deterministic function that maps a set of vectors in Rd to another vector in Rd, and
nv(∙) is a d-dimensional Gaussian circular noise (mean 0, covariance I). U ∈ Γ(v) if there is a
(directed) edge from u to v in the (directed) graph G. Specifically, in this paper we consider a
transformation function g(∙) that results in the following update rule:
xv(t + 1) = ReLU(W0( X xu(t)) + b1) + nv(t + 1),	∀v ∈ V, t ∈ N,	(2)
u∈Γ(v)
where W0 ∈ Rd×d and b ∈ Rd×1 are trainable parameters. ReLU(x) = max(x, 0). Starting
with an initial value (e.g., random or all zero) for the vertex state vectors xv(0), Equation (2) above
defines a dynamical system, the (random) trajectory of which is the Graph2Seq representation.
More generally, graphs could have features on their vertices or edges (e.g., weights on vertices) and
they can be included in the evolution rule by appending them to the state vectors in a straight-forward
way; these generalizations are outside the scope of this paper.
GRAPH2SEQ = Seq2Graph. Our first main result is that the representation of GRAPH2SEQ allows
recovery of the adjacency matrix of the graph with arbitrarily high probability (here the randomness
is with respect to the inherent randomness in Graph2Seq due to the noise it adds). Specifically:
Theorem 1. For any directed graph G and associated (random) representation GRAPH2SEQ(G)
with sequence length t, there exists an inference procedure (with time complexity polynomial in t)
that produces an estimate Gt such that limt→∞ P[G 6= Gt] = 0.
Importance of randomization. Notice that GRAPH2SEQ’s evolution rule (Equation (2)) includes
a noise term that is added to the transformation function. The importance of randomization is high-
lighted by the following result (proof in Appendix B.2).
Proposition 1. Under any deterministic evolution rule, there exists a graph G which cannot be
reconstructed exactly from its GRAPH2SEQ representation.
The key point is that noise breaks symmetry in the (otherwise deterministic) dynamical system.
Observe that vertices in the graph, besides any intrinsic features they may have, are not explicitly
assigned unique identifiers. The deterministic evolution function, together with lack of identifying
labels on vertices make distinguishing vertices difficult. The proof of Proposition 1 illustrates this
for regular graphs.
3.2	Formal Computation Model
Although Graph2Seq is an invertible representation of a graph, it is unclear how it compares to
other GCNN representations in the literature. Below we define a formal computational model on
3
Under review as a conference paper at ICLR 2018
graphs, called local-gather, that includes Graph2Seq as well as a large class of GCNN repre-
sentations in the literature. Abstracting different representations into a formal computational model
allows us reason about the fundamental limits of these methods. We show that fixed-depth GCNNs
cannot fundamentally compute certain functions over graphs, where a sequence based representation
such as Graph2Seq is able to do so. For simplicity of notation we consider undirected graphs in
this section and in the rest of this paper.
LOCAL-GATHER Model. Consider an undirected graph G(V, E) (in which the vertices/edges can
have some features associated with them) on which we seek to compute a function f . In the k-
LOCAL-GATHER model, computations proceed in two rounds: In the local step, each vertex v com-
putes a representation r(v) that depends only on the subgraph of vertices that are at a distance of
at most k from v. Following this, in the gather step, the function f is computed by applying an-
other function g(∙) over the collection of aggregated representations {r(v) : V ∈ V}. We first note
that GRAPH2SEQ is an instance of the ∞-LOCAL-GATHER model. Further, GCNNs using localized
filters with a global aggregation (Kipf & Welling (2016); Dai et al. (2017), discussed in detail in
Section A) fit this model (proof in Appendix B.3).
Proposition 2. The spectral GCNN representation in Kipf & Welling (2016) and the spatial GCNN
representation in Dai et al. (2017) belong to the 4-LOCAL-GATHER model.
Fixed-length representations are insufficient. We show below that for a fixed k > 0, no algorithm
from the k-LOCAL-GATHER model can compute certain canonical graph functions exactly, with the
proof relegated to Appendix B.4.
Theorem 2. For any fixed k > 0, there exists a function f (∙) and an input graph instance G such
that no k-LOCAL- GATHER algorithm can compute f(G) exactly.
For the graph and instance we have in Theorem 2, we present in Appendix B.5 a sequence-based
representation (from the ∞-LOCAL-GATHER) that is able to asymptotically compute the function.
Such a demonstration shows that sequence-based representations are strictly better than fixed-length
graph representations in the local-gather model but also gives a sense for how sequential repre-
sentations potentially operate in trained neural networks.
3.3	Geometry of Graph2Seq Dynamics
Understanding how the graph structure is being encoded in the dynamics of Equation (2) involves
answering questions such as: Does Equation (2) have a fixed point? Are there values for parameters
W0 and b1 that recover some basic graph properties (e.g., the adjacency matrix)? While a full theo-
retical analysis of Equation (2) appears challenging partly due to the coupling of the x variables and
the nonlinearity of the ReLU, we report the following empirical observations that at least partially
help characterize the nature of the evolution.
We consider an experiment in which d = 16, and the entries of W0, b1 are drawn from an i.i.d.
uniform over [0,1]. The state vector xv is initialized to zero for all vertices. We consider graphs of
size between 10-50 and of four types: random Erdos-Renyi,random tree, random regular graphs and
random bipartite graph. In each case we perform the recursion of Equation (2) at least 10 times. The
following general observations hold with high probability with respect to both parameter values,
and the graph. Perhaps surprisingly, these observations also hold true on our model with trained
parameters (e.g., for finding minimum vertex covers), as we discuss in Appendix D.
(1)	Convergence. Depending on the variance of the initializing distribution forW0, the state vectors
either converge to zero (small variance), or blow up (large variance).
(2)	Dimension collapse. Roughly half the entries in the 16-dimensional state vector quickly become
zeros (in about 4 or 5 iterations) and stay at zero. The indices of these zeroed-out entries are the
same in state vectors across all the vertices.
(3)	Principal components’ alignment. We compute the principal component direction of the col-
lection of vertex state vectors at each iteration, and observe that it converges. Figure 1(c) shows the
absolute value of the inner product between the (normalized) principal component direction at each
iteration with the principal component direction at iteration 10, for the Erdos-Renyi graph shown in
Figure 1(a).
4
Under review as a conference paper at ICLR 2018
Figure 1: (a) Erdos-Renyi graph of size 10 considered in Figures (b) and (c), (b) vertex-wise principal com-
ponent scores at each iteration, and (c) projection of the principal direction at each iteration on the principal
direction of iteration 10. The vertex color and the line color in Figures (a) and (b) are matched.
(4)	Principal component scores and local connectivity. In each iteration, we compute the principal
score (projection along principal direction) of each vertex state vector. We observe that the principal
score for a vertex roughly corresponds to its ‘local connectivity’ in the graph. The stronger a vertex
is connected, the larger is the principal score. Fig. 1(b) shows this effect for the graph in Fig. 1(a) —
vertex 9 (bright blue) is strongly connected and has the largest principal score, while vertex 7 (dark
grey) has the least score.
4	Neural Network Design
We consider a reinforcement learning formulation for combinatorial optimization problems on
graphs. Reinforcement learning is well-suited to such problems since the true ‘labels’ (i.e., the
optimal solution) may be unavailable or hard to compute. Additionally, there are well-defined
objective functions in most graph problems that can naturally be set as reward signals in the re-
inforcement learning model. Such an approach has been explored in recent works Vinyals et al.
(2015); Bello et al. (2016); Dai et al. (2017) under different representation techniques. We use the
Graph2Seq representation in our learning setting which has key two features:
Length of GRAPH2SEQ output. The trajectories output by GRAPH2SEQ are subsequently fed
to sequence processing units (specifically RNN-LSTM). Henceforth we call the combination of
the Graph2Seq representation and the subsequent sequence processing units together as the
Graph2Seq neural network architecture. The key feature of this design is that the length of the
sequential representation is not fixed; it can vary depending on the input instance. We show that
our model is able to learn rules - for both generating the sequence and processing it With the LSTM
-that generalize to operate on arbitrarily long sequences. In turn, this translates to algorithmic
solutions that can scale to large graph sizes.
Adversarial training. Another important reason for GRAPH2SEQ’s generalization capability is our
careful adversarial choice of the training set. The combinatorial problems naturally alloW us to
present ‘hard examples’ for training. By choosing an adversarial set of example graphs, We demon-
strate the corresponding model generalizes much better both in terms of graph structure and graph
size, compared to GCNN methods in the literature.
4.1	Learning Algorithm and Network Architecture
Reinforcement learning model. We consider a reinforcement learning formulation in Which ver-
tices are chosen one at a time. Each time the agent chooses a vertex, it incurs a reWard. The goal
of training is to learn a policy such that cumulative reWard is maximized. To achieve this goal,
We use Q-learning to train the netWork. For input graph instance G(V, E), a subset S ⊆ V and
a ∈ V \S, this involves parametrically approximating a Q-function Q(G, S, a). Here S represents
the set of vertices already picked. Appendix C.1 has the precise definitions of our reinforcement
learning model and the Q-learning formulation. In the folloWing We discuss the neural netWork to
compute Q(G, S, a).
5
Under review as a conference paper at ICLR 2018
Network architecture. The neural network comprises of three modules:
(1)	Graph2Seq, that takes as input the graph G and set S of vertices chosen so far. It generates a
sequence of vectors as output for each vertex.
(2)	Seq2Vec reads the sequential representation produced by GRAPH2SEQ and summarizes it into a
vector (for each vertex).
(3)	Q-Network takes as input the vector summary of each vertex a ∈ V , and outputs the estimated
Q(G, S, a) value.
The overall architecture is illustrated in Fig. 2. To make the network practical, we truncate the
sequence outputs of Graph2Seq to a length of T . However the value of T is not fixed and will be
varied both during training and testing, according to the size and complexity of the graph instances
encountered. We discuss more on this in Section 4.2. For now let us suppose T has a fixed value.
We describe each module below.
Graph2Seq. We consider a d-dimensional state-space in which the dynamics of each vertex evolves.
At time-step t, let xv (t) denote the state of vertex v. Also, let cv (t) denote the binary variable that
is one if v ∈ S and zero otherwise. Then, the trajectory of each vertex v ∈ V evolves according to
xv(t+ 1) = ReLU(W1 X xu(t) +w2cv(t) + b3),	(3)
u∈Γ(v)
for t = 0, 1, . . . , T - 1. Here W1 ∈ Rd×d, w2 ∈ Rd, b3 ∈ Rd are trainable parameters. xv (0) is
initialized to all-zeros for each v ∈ V .
Seq2Vec. The sequence ({xv (t) : v ∈ V })tT=1 is processed by a gated recurrent network that se-
quentially reads Xv(∙) vectors at each time index for all V ∈ V. For time-step t ∈ {1,...,T}, let
yv(t) ∈ Rd be the d-dimensional cell state, iv(t) ∈ Rd be the cell input and fv(t) ∈ (0, 1)d be the
forgetting gate, for each vertex v ∈ V. Each time-step a fresh input iv (t) is computed based on the
current states Xu(t) of v’s neighbors in G. The cell state is updated as a convex combination of the
freshly computed inputs iv (t) and the previous cell state yv (t - 1), where the weighting is done
according to a forgetting value fv (t) that is also computed based on the current vertex states. The
update equations for the input vector, forgetting value and cell state are chosen as follows:
iv(t + 1) = ReLU(W4 X Xv(t) +w5cv(t) + b6)	(4)
u∈Γ(v)
fv(t + 1) = sigmoid(W7 X Xu(t) + b8)	(5)
u∈V
yv(t + 1) = fv(t + 1) iv(t + 1) + (1 - fv(t + 1)) yv (t),	(6)
where W4, W7 ∈ Rd×d and w5, b6, b8 ∈ Rd are trainable parameters, t = 0, 1, . . . , T - 1, and 1
denotes the d-dimensional all-ones vector, and is element-wise multiplication. yv (0) is initialized
to all-zeros for every v ∈ V. The cell state at the final time-step yv (T), v ∈ V is considered to be
the desired vector summary of the Graph2Seq sequence.
Q-Network. In this last step, the yv (T) for each vertex v is used to estimate the Q-values as
Q(G,S, V) = WTReLU(W10 X y“(T)) + WTIReLU (W12yv(T)),	(7)
u∈V
with W10, W12 ∈ Rd×d and W9, W11 ∈ Rd being learnable parameters. Notice that every transfor-
mation function in the network leading up to Equation (7) is differentiable. This makes the whole
network differentiable, allowing us to compute the (stochastic) gradients of the loss function in
Equation (23) for learning. Next we describe the general training and testing techniques used in the
evaluations.
4.2	Training and Testing
Training. During training, the length of the GRAPH2SEQ representation is truncated to five obser-
vations (i.e., T = 5, see Fig. 2). We train on synthetically generated graphs of size 15 from a certain
adversarially chosen graph family (we use different graph families for different optimization prob-
lems). We observe that training on a ‘feature-rich’ set of examples, can give a better performance
across a range of different graph types during testing, compared to training and testing within the
6
Under review as a conference paper at ICLR 2018
same graph type. For example, in the case of minimum vertex cover, training on (mismatched)
‘planted vertex cover’ examples (Section 5.1) has a much better generalization performance on
Erdos-Renyi graphs, than if the same heuristic had been trained on Erdos-Renyi graphs.
In each case, our model is trained for
100,000 iterations, though we found con-
vergence to occur typically much earlier.
We use experience replay in which during
each iteration we sample a random (state,
action, next state) tuple from that was
made previously, and use that to compute
the gradient update. We use a learning rate
of 10-3 with the Adam optimizer (Kingma
& Ba, 2014), and an exploration proba-
bility that is reduced from 1.0 initially to
a resting value of 0.05 over 10,000 itera-
tions. The amount of noise added in the
Figure 2: GRAPH2SEQ neural network architecture.
evolution (nv (t) in Equation 2) seemed to not matter; we have set the noise variance to zero in all
our experiments (training and testing).
Testing. Due to the recurrent nature of GRAPH2SEQ (and the LSTM units), we can use the trained
parameters to generate, and subsequently summarize, a sequential representation that is arbitrarily
long. For any fixed T > 0, let GRAPH2SEQ(T) denote the architecture obtained by restricting the
sequence length to T (Fig. 2). We run GRAPH2SEQ(T) for every T ∈ N over an interval [1, Tmax],
where Tmax is a hyper-parameter (we choose Tmax < 40 in our experiments). Notice for each fixed
T and input instance G(V, E), GRAPH2SEQ(T) outputs a solution set ST ⊆ V . Since our goal is to
maximize objective, we select the output of that T ∈ [1, Tmax] that has the largest objective function
value as our final output. This procedure is summarized in detail in Algorithm 2 in Appendix C.
We test generalization in graph structure and size. Using the same trained parameters, we test
Graph2Seq on the following broad graph classes: Erdos-Renyi graphs, bipartite graphs, regular
graphs and structured examples, while varying the graph sizes between 25-3200.
5	Evaluation: Minimum Vertex Cover
In this section we present evaluation results for the minimum vertex cover (MVC). Results for the
max cut and maximum independent set problems are in Appendix E.
The MVC of a graph G(V, E) is a set S ⊆ V of the lowest cardinality such that for every edge
(u, v) ∈ E at least one of u or v are in S . Approximation algorithms to within a factor 2 are
known for MVC, however it cannot be approximated better than 1.3606 unless P = NP . To model
this problem using RL, we define the set of vertices chosen as actions across iterations to be our
estimated vertex cover output. Each time a vertex v is chosen, the learning agent receives a reward
of —1 and We set Cv J 1 for all subsequent iterations. During each iteration We PiCk as action the
vertex with the highest Q-value that has not be chosen already (i.e., for which cv is 0). The algorithm
terminates when there is no more edge to be covered. Throughout our evaluations we have used state
vector dimension d = 16, although the empirical findings stay roughly the same for d ≥ 8.
5.1	Adversarial Training
We train our model on planted vertex-cover graph examples, in which a small graph is embedded
within a larger graph such that the vertices of the smaller graph constitute the optimal minimum
vertex cover. Such planted examples form a reasonably hard class of examples for MVC, and appears
essential to the superior generalization of our trained model. When trained on other graph families
(such as Erdos-Renyi graphs), the generalization (both with respect to size, and graph structure
including Erdos-Renyi itself) is much less pronounced than training with the planted examples.
To generate our examples, we first sample a random Erdos-Renyi graph Gi (to be planted) of size
5 and edge probability p = 0.15. Next, we define a second graph Go of size 10 in which all the
vertices are disjoint. The overall graph is formed by connecting each vertex of Go to each vertex
7
Under review as a conference paper at ICLR 2018
of Gi . Note that the vertices of Gi form the optimum vertex cover in these examples. With these
training examples, we follow the general training strategy described in Section 4.2.
5.2	Testing
We test generalization capability along two dimensions: graph structure and graph size.
Graph types and sizes. We consider graphs of the following four types:
(1)	Erdos-Renyi graph, with edge probability p = 0.15.
(2)	Random regular graph, with degree 4.
(3)	Random bipartite graph, both partites of equal size and edge probability p = 0.75.
(4)	Worst-case examples for Greedy. The Greedy algorithm is a well-known MVC heuristic in
which we sequentially select the vertex having the largest number of uncovered edges remaining in
the graph. This algorithm can be shown to have a O(log n) approximation for vertex cover, by means
of constructive examples where they perform poorly (Johnson, 1973). One popular construction is
a bipartite graph with n vertices on one side (say, partite P1), and Pin=2 bn/ic vertices on the other
partite (P2). For i = 2, . . . , n, bn/ic vertices from P2 have a degree of i and each vertex from P1 is
connected to at most one vertex of degree i.
For each type, We test on graphs of size ranging from 25-3200 in exponential increments. Crucially,
we use the same trained model on all of the test examples. We also limit the number of layers in
GRAPH2SEQ (i.e., the sequence length) to 15 in our evaluations.
Baseline. We compare our results against the folloWing baseline algorithms:
(1)	Greedy algorithm for vertex cover (described above).
(2)	Fixed-depth GCNN trained on Erdos-Renyi graphs. We consider a 5-layer GCNN in Which only
the outputs of the 5-th layer are fed to the Q-learning netWork. This algorithm is identical to Dai
et al. (2017). This netWork is trained on size-15 Erdos-Renyi graphs With p = 0.15.
(3)	Fixed-depth GCNN trained on planted vertex-cover graphs. This baseline is the same as above,
but trained on the adversarial planted-cover examples of Section 5.1.
(4)	Matching heuristic, a 2-approximation algorithm that selects an arbitrary edge in each round,
and includes both end-points in the cover. The selected vertices are then removed from the graph
and the process repeats.
(5)	List heuristic. We also compare against the algorithm proposed recently in Shimizu et al. (2016)
that outperforms previous vertex cover heuristics.
The ground truth is found via the Gurobi optimization package Which solves the MVC integer pro-
gram With a time cut-off of 240s. The solver found the optimal solution for all graphs up to size
200 before this time. We report our results via the approximation ratio of the values returned by the
baseline algorithms considered to the ground truth found by the Gurobi solver.
Results. Figure 3 plots results for the different baselines under each of four graph types con-
sidered in our experiment and We make the folloWing observations: (a) In general, We see that
Graph2Seq has a performance that is consistently Within 5% of the optimal (or the time-limited
IP solution Where applicable), across the range of graph types and sizes considered. The other base-
lines, hoWever, demonstrate behavior that is not consistent and have certain classes of graph types
and/or sizes Where they perform poorly. (b) The Greedy baseline has a near-optimal performance,
comparable to Graph2Seq, With Erdos-Renyi and random bipartite graphs. It is slightly Worse
than Graph2Seq on random regular graphs, and does very poorly (not surprisingly) on the Worst-
case examples. (c) The fixed-depth GCNN baselines behave remarkably differently from each other.
The one trained on Erdos-Renyi graphs, i.e., Dai et al. (2017), has a performance comparable to
Graph2Seq and Greedy With Erdos-Renyi and random regular graphs. HoWever With random bi-
partite graphs it does poorly at graph sizes 200 or less. Similarly, With the Worst-case example, the
heuristic does not do Well at graph sizes 50 or above. (d) The fixed-depth GCNN baseline trained
on planted-vertex cover examples demonstrates poor approximation ratio in all graph categories.
(e) Similarly the matching heuristic is also consistently poor in all categories. (f) The list heuristic
of Shimizu et al. (2016) has a comparable performance to Graph2Seq in most cases. HoWever in
large random regular graphs, We observe its performance degrading 10% above optimal.
Geometry and semantics of encoding. ToWards an understanding of What aspect of solving the
MVC is learnt, We conduct empirical studies on the dynamics of the state vectors as Well as present
techniques and semantic interpretations of Graph2Seq. First We observe that the same obser-
8
Under review as a conference paper at ICLR 2018
ιli
IOO 200 400 800 1600 3200
Graph size
(a)
Graph2Seq
Fixed-depth GCNN (ER)
Fixed-depth GCNN (PC)
Greedy
Matching
List heuristic
.86.42.0
ɪ ɪ ɪ ɪ ɪ
OAg UO-⅛luxo-Jdd<
25	50	100 200 400 800 1600 3200
Graph size
(b)

(c)	(d)
Figure 3: Minimum vertex cover in (a) random Erdos-Renyi graphs, (b) random regular graphs, (c) random
bipartite graphs, (d) greedy example. The error bars show one standard deviation.
vations (cf. Section 3.3) as for random parameter choices continue to hold. The most interesting
semantics are observed in the Q(∙) function which has two components (cf. Equation (7)). The first
term, denoted by Q1, is the same for all the vertices and includes a sum of all the y(∙) vectors. The
second term, denoted by Q2 (V) depends on the y(∙) vector for the vertex being considered.
We consider these two values at the end of the first round of the learning algorithm (with S = {}) for
a planted vertex cover graph of size 15. We make two observations: (a) the values of Q1 and Q2 (∙)
are close to being integers. Q1 has a value that is one less than the negative of the minimum vertex
cover size. (b) For a vertex v, Q2 (v) is binary valued from the set {0, 1}. Q2 (v) is one, if vertex
v is part of an optimum vertex cover, and zero otherwise. Thus the neural network, in principle,
computes the complete set of vertices in the optimum cover at the very first round itself. A detailed
description of these semantics and a visualization of the various phenomena is in Appendix D.
6	Conclusion
We have proposed Graph2Seq that represents graphs as infinite time-series of vectors, one for
each vertex of the graph. The time-series representation melds naturally with modern RNN ar-
chitectures that take time-series as inputs. We have demonstrated the strong synergistic benefits
towards solving three canonical combinatorial optimization problems on undirected graphs, rang-
ing across the complexity-theoretic hardness spectrum. Our empirical results best state-of-the-art
approximation algorithms for these problems on a variety of graph sizes and types. In particular,
Graph2Seq is strictly better in generalization capabilities than deep learning techniques in the
literature (GCNN methods). An open direction involves a more systematic study of the capabil-
ities of Graph2Seq across the panoply of graph combinatorial optimization problems, as well
as its performance in concrete (and myriad) downstream applications. Another open direction in-
volves interpreting key principles learnt by the neural network in solving any specific combinatorial
optimization problem. Traditional understanding of heuristic algorithms involves bounding their
worst-case approximation ratio, which appears impossible to conduct in the case of neural network
methods - exploring modern interpretability methods in machine learning (example: LIME Ribeiro
et al. (2016)) is of interest.
9
Under review as a conference paper at ICLR 2018
References
Spyros AngeloPoUlos and Allan Borodin. Randomized priority algorithms. In WAOA, pp. 27-40.
Springer, 2003.
Irwan Bello, HieU Pham, QUoc V Le, Mohammad NoroUzi, and Samy Bengio. NeUral combinatorial
optimization with reinforcement learning. arXiv preprint arXiv:1611.09940, 2016.
Allan Borodin, Morten N Nielsen, and Charles Rackoff. (incremental) priority algorithms. Algo-
rithmica, 37(4):295-326, 2003.
Allan Borodin, Joan Boyar, Kim S Larsen, and Nazanin Mirmohammadi. Priority algorithms for
graph optimization problems. Theoretical Computer Science, 411(1):239-258, 2010.
Michael M Bronstein, Joan BrUna, Yann LeCUn, ArthUr Szlam, and Pierre Vandergheynst. Geomet-
ric deep learning: going beyond eUclidean data. IEEE Signal Processing Magazine, 34(4):18-42,
2017.
Joan BrUna and Xiang Li. CommUnity detection with graph neUral networks. arXiv preprint
arXiv:1705.08415, 2017.
Joan BrUna, Wojciech Zaremba, ArthUr Szlam, and Yann LeCUn. Spectral networks and locally
connected networks on graphs. arXiv preprint arXiv:1312.6203, 2013.
HanjUn Dai, Elias B Khalil, YUyU Zhang, Bistra Dilkina, and Le Song. Learning combinatorial
optimization algorithms over graphs. arXiv preprint arXiv:1704.01665, 2017.
Michael Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks
on graphs with fast localized spectral filtering. In Advances in Neural Information Processing
Systems, pp. 3844-3852, 2016.
Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural
message passing for quantum chemistry. arXiv preprint arXiv:1704.01212, 2017.
Marco Gori, Gabriele Monfardini, and Franco Scarselli. A new model for learning in graph domains.
In Neural Networks, 2005. IJCNN’05. Proceedings. 2005 IEEE International Joint Conference
on, volume 2, pp. 729-734. IEEE, 2005.
Clive WJ Granger. Testing for causality: a personal viewpoint. Journal of Economic Dynamics and
control, 2:329-352, 1980.
Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-
Barwinska, Sergio Gomez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou,
et al. Hybrid computing using a neural network with dynamic external memory. Nature, 538
(7626):471-476, 2016.
Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In Proceedings
of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining,
pp. 855-864. ACM, 2016.
Mikael Henaff, Joan Bruna, and Yann LeCun. Deep convolutional networks on graph-structured
data. arXiv preprint arXiv:1506.05163, 2015.
John J Hopfield and David W Tank. Neural computation of decisions in optimization problems.
Biological cybernetics, 52(3):141-152, 1985.
David S Johnson. Approximation algorithms for combinatorial problems. In Proceedings of the fifth
annual ACM symposium on Theory of computing, pp. 38-49. ACM, 1973.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional net-
works. arXiv preprint arXiv:1609.02907, 2016.
10
Under review as a conference paper at ICLR 2018
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convo-
Iutional neural networks. In Advances in neural information processing Systems, pp. 1097-1105,
2012.
Fabian Kuhn, Thomas Moscibroda, and Roger Wattenhofer. Local computation: Lower and upper
bounds. Journal of the ACM (JACM), 63(2):17, 2016.
Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural
networks. arXiv preprint arXiv:1511.05493, 2015.
Xiaodan Liang, Xiaohui Shen, Jiashi Feng, Liang Lin, and Shuicheng Yan. Semantic object parsing
with graph lstm. In European Conference on Computer Vision, pp. 125-143. Springer, 2016.
Federico Monti, Davide Boscaini, Jonathan Masci, EmanueIe Rodoia, Jan Svoboda, and Michael M
Bronstein. Geometric deep learning on graphs and manifolds using mixture model cnns. arXiv
preprint arXiv:1611.08402, 2016.
Mathias Niepert, Mohamed Ahmed, and Konstantin Kutzkov. Learning convolutional neural net-
works for graphs. In International Conference on Machine Learning, pp. 2014-2023, 2016.
Alex Nowak, Soledad Villar, Afonso S Bandeira, and Joan Bruna. A note on learning algorithms for
quadratic assignment with graph neural networks. arXiv preprint arXiv:1706.07450, 2017.
Arzucan Ozgur, Thuy Vu, GuneS Erkan, and Dragomir R Radev. Identifying gene-disease associ-
ations using centrality on a literature mined gene-interaction network. Bioinformatics, 24(13):
i277-i285, 2008.
Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: Online learning of social repre-
sentations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge
discovery and data mining, pp. 701-710. ACM, 2014.
Christopher J Quinn, Todd P Coleman, Negar Kiyavash, and Nicholas G Hatsopoulos. Estimating
the directed information to infer causal relationships in ensemble neural spike train recordings.
Journal of computational neuroscience, 30(1):17-44, 2011.
Christopher J Quinn, Negar Kiyavash, and Todd P Coleman. Directed information graphs. IEEE
Transactions on information theory, 61(12):6887-6909, 2015.
Arman Rahimzamani and Sreeram Kannan. Network inference using directed information: The
deterministic limit. In Communication, Control, and Computing (Allerton), 2016 54th Annual
Allerton Conference on, pp. 156-163. IEEE, 2016.
Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. Why should i trust you?: Explaining the
predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, pp. 1135-1144. ACM, 2016.
Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini.
The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61-80, 2009.
Youngjoo Seo, Michael Defferrard, Pierre Vandergheynst, and Xavier Bresson. Structured sequence
modeling with graph convolutional recurrent networks. arXiv preprint arXiv:1612.07659, 2016.
Satoshi Shimizu, Kazuaki Yamaguchi, Toshiki Saitoh, and Sumio Masuda. A fast heuristic for
the minimum weight vertex cover problem. In Computer and Information Science (ICIS), 2016
IEEE/ACIS 15th International Conference on, pp. 1-5. IEEE, 2016.
Felipe Petroski Such, Shagan Sah, Miguel Dominguez, Suhas Pillai, Chao Zhang, Andrew Michael,
Nathan Cahill, and Raymond Ptucha. Robust spatial filtering with graph convolutional neural
networks. arXiv preprint arXiv:1703.00792, 2017.
Johan Ugander, Brian Karrer, Lars Backstrom, and Cameron Marlow. The anatomy of the facebook
social graph. arXiv preprint arXiv:1111.4503, 2011.
Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. Pointer networks. In Advances in Neural
Information Processing Systems, pp. 2692-2700, 2015.
11
Under review as a conference paper at ICLR 2018
A Background: Graph Convolutional Neural Networks
An ideal graph representation is one that captures all innate structures of the graph relevant to the task
at hand, and moreover can also be learned via gradient descent methods. However, this is challenging
since the relevant structures could range anywhere from local attributes (example: node degrees) to
long-range dependencies spanning across a large portion of the graph (example: does there exist a
path between two vertices) (Kuhn et al., 2016). Such broad scale variation is also a well-known issue
in computer vision (image classification, segmentation etc.), wherein convolutional neural network
(CNN) designs have been used quite successfully (Krizhevsky et al., 2012). Perhaps motivated by
this success, recent research has focused on generalizing the traditional CNN architecture to develop
designs for graph convolutional neural networks (GCNN) (Bruna et al., 2013; Niepert et al., 2016).
By likening the relationship between adjacent pixels ofan image to that of adjacent nodes in a graph,
the GCNN seeks to emulate CNNs by defining localized ‘filters’ with shared parameters.
Current GCNN filter designs can be classified into one of two categories: spatial (Kipf & Welling,
2016; Dai et al., 2017; Nowak et al., 2017), and spectral (Defferrard et al., 2016). For an integral
hyper-parameter K ≥ 0, filters in either category process information from a K-local neighborhood
surrounding a node to compute the output. Here we consider localized spectral filters such as pro-
posed in Defferrard et al. (2016). The difference between the spatial and spectral versions arises in
the precise way in which the aggregated local information is combined.
Spatial GCNN. For input feature vector xv at each node v ∈ V of a graph G, a spatial filtering
operation is the following:
where yv is the filter output, Wk , k = 1, . . . , K and b0 are learnable parameters, and σ is a non-
linear activation function that is applied element-wise. A = D-1/2 AD-1/2 is the normalized
adjacency matrix, and D is the diagonal matrix of vertex degrees. Use of un-normalized adjacency
matrix is also common. The k-power of the adjacency matrix selects nodes a distance of at most
k hops from v. ReLU is a common choice for σ. We highlight two aspects of spatial GCNNs:
(i) the feature vectors are aggregated from neighboring nodes directly specified through the graph
topology, and (ii) the aggregated features are summarized via an addition operation.
Spectral GCNN. Spectral GCNNs use the notion of graph Fourier transforms to define convolution
operation as the inverse transform of multiplicative filtering in the Fourier domain. Since this is a
non-local operation potentially involving data across the entire graph, and moreover it is computa-
tionally expensive to compute the transforms, recent work has focused on approximations to produce
a local spectral filter of the form
where L = I - A is the normalized Laplacian of the graph, (Lk)v,u denotes the entry at the row
corresponding to vertex V and column corresponding to vertex U in Lk, and Wk, b0 are parame-
ters (Defferrard et al., 2016; Kipf & Welling, 2016). As in the spatial case, definitions using un-
normalized version of Laplacian matrix are also used. σ is typically the identity function here.
Equation (9) is a local operation because the k-th power of the Laplacian, at any row v, has a sup-
port no larger than the k-hop neighborhood of v . Thus, while the aggregation is still localized, the
feature vectors are now weighted by the entries of the Laplacian before summation.
Spectral and Spatial GCNN are equivalent. The distinction between spatial and spectral convolution
designs is typically made owing to their seemingly different definitions. However we show that both
designs are mathematically equivalent in terms of their representation capabilities.
Proposition 3. Consider spatial and spectral filters in Equations (8) and (9), using the same non-
linear activation function σ and K. Then, for graph G(V, E), for any choice of parameters Wk
and b0 for k = 1, . . . , K there exists parameters Wk0 and b00 such that the filters represent the same
transformation function, and vice-versa.
12
Under review as a conference paper at ICLR 2018
Proof. Consider a vertex set V = {1, 2, . . . , n} and d-dimensional vertex states xi and yi at vertex
i ∈ V . Let X = [x1, . . . , xn] and Y = [y1, . . . , yn] be the matrices obtained by concatenating the
state vectors of all vertices. Then the spatial transformation function of Equation (8) can be written
as
Y = σ V WkXAk + bo1T ,
while the spectral transformation function of Equation (9) can be written as
Y = σ EWk XLk + b01T
σ VWkX(I- A)k+ b01T
σ
σ
WkXXX (k)(-1)k-iAi + b01T)
(XI Wi (k) (-1)i-k) XAk + b01T).
(10)
(11)
(12)
(13)
(14)
Equation (12) follows by the definition of the normalized Laplacian matrix, and Equation (13) de-
rives from binomial expansion. To make the transformation in Equations (10) and (14) equal, we
can set
K -1 i
W0i ki (-1)i-k = Wk,	∀0≤k≤K-1,	(15)
i=k
and check if there are any feasible solutions for the primed quantities. Clearly there are, with one
possible solution being b00 = b0 and
WK0 -1 = WK -1	(16)
K -1 i
Wk0 =Wk-	W0i ki (-1)i-k,	∀0≤k≤K-2.	(17)
i=k+1
Thus for any choice of values for Wk, b0 for k = 0, . . . , K - 1 there exists Wk0 , b00 for k =
0, . . . , K - 1 such that the spatial and spectral transformation functions are equivalent. The other
direction (when Wk and bo are fixed), is similar and straightforward.	□
Depending on the application, the convolutional layers may be supplemented with pooling and
coarsening layers that summarize outputs of nearby convolutional filters to form a progressively
more compact spatial representation of the graph. This is useful in classification tasks where the
desired output is one out of a few possible classes (Bruna et al., 2013). For applications requir-
ing decisions at a per-node level (e.g. community detection), a popular strategy is to have multiple
repeated convolutional layers that compute vector representations for each node, which are then
processed to make a decision (Dai et al., 2017; Bruna & Li, 2017; Nowak et al., 2017). The con-
ventional wisdom here is to have as many layers as the diameter of the graph, since filters at each
layer aggregate information only from nearby nodes. Such a strategy is sometimes compared to
the message passing algorithm (Gilmer et al., 2017), though the formal connections are not clear as
noted in Nowak et al. (2017). Finally the GCNNs described so far are all end-to-end differentiable
and can be trained using mainstream techniques for supervised, semi-supervised or reinforcement
learning applications.
Other lines of work use ideas inspired from word embeddings for graph representation (Grover &
Leskovec, 2016; Perozzi et al., 2014). Post-GCNN representation, LSTM-RNNs have been used to
analyze time-series data structured over a graph. Seo et al. (2016) propose a model which combines
GCNN and RNN to predict moving MNIST data. Liang et al. (2016) design a graph LSTM for
semantic object parsing in images.
13
Under review as a conference paper at ICLR 2018
B Section 3 Proofs
B.1 Proof of Theorem 1
Proof. Consider a GRAPH2SEQ trajectory on graph G(V, E) according to Equation (2) in which
the vertex states are initialized randomly from some distribution. Let Xv(t) (resp. xv(t)) denote the
random variable (resp. realization) corresponding to the state of vertex v at time t. For time T > 0
and a set S ⊆ V , let XTS denote the collection of random variables {Xv (t) : v ∈ S, 0 ≤ t ≤ T };
xTV will denote the realizations.
An information theoretic estimator to output the graph structure by looking at the trajectory XVT is
the directed information graph considered in Quinn et al. (2015). Roughly speaking, the estimator
evaluates the conditional directed information for every pair of vertices u, v ∈ V , and declares an
edge only if it is positive (see Definition 3.4 in Quinn et al. (2015) for details). Estimating conditional
directed information efficiently from samples is itself an active area of research Quinn et al. (2011),
but simple plug-in estimators with a standard kernel density estimator will be consistent. Since the
theorem statement did not specify sample efficiency (i.e., how far down the trajectory do we have
to go before estimating the graph with a required probability), the inference algorithm is simple and
polynomial in the length of the trajectory. The key question is whether the directed information
graph is indeed the same as the underlying graph G. Under some conditions on the graph dynamics
(discussed below in Properties 1-3), this holds and it suffices for Us to show that the dynamics
generated according to Equation (2) satisfies those conditions.
Property 1. For any T > 0, PXTV (xTV) > 0forallxTV.
This is a technical condition that is required to avoid degeneracies that may arise in deterministic
systems. Clearly Graph2Seq’s dynamics satisfies this property due to the additive i.i.d. noise in
the transformation functions.
Property 2. The dynamics is strictly causal, that is PXT (xVT ) factorizes as
Qt=0 Qv∈V PXv(t)|XtV-1(xv(t)|xtV-1).
This is another technical condition that is readily seen to be true for Graph2Seq. The proof also
follows from Lemma 3.1 in Quinn et al. (2015).
Property 3. G is the minimal generative model graph for the random processes Xv (t), v ∈ V .
Notice that the transformation operation Equation (2) in our graph causes XTV to factorize as
T
PXV(XV) = Y Y PXv(t)∣χr-v1)(Xv(t)lxΓ(v1))	(18)
t=0 v∈V
for any T > 0, where Γ(v) is the set of neighboring vertices of v in G. Now consider any other
graph G0(V, E0). G0 will be called a minimal generative model for the random processes {Xv (t) :
v ∈ V, t ≥ 0} if
(1)	there exists an alternative factorization of PXT (XTV) as
T
PXV(XV) = Y Y Pxv(t)∣xr-(ιv)(Xv(t)|xr0(V))	(19)
t=0 v∈V	v
for any T > 0, where Γ0(v) is the set of neighbors of v in G0, and
(2)	there does not exist any other graph G00(V, E00) with E00 ⊂ E and a factorization of PXT (XVT)
as QT=O Qv∈ν PX (t)∣χt-ι (xv (t)∣xΓ-0(v)) for any T > 0, where Γ00(ν) is the set of neighbors of
v in G00.
Intuitively, a minimal generative model is the smallest spanning graph that can generate the observed
dynamics. To show that G(V, E) is indeed a minimal generative model, let us suppose the contrary
and assume there exists another graph G0(V, E0) with E0 ⊂ E and a factorization of PXT (XVT) as
14
Under review as a conference paper at ICLR 2018
in Equation (19). In particular, let v be any node such that Γ0(v) ⊂ Γ(v). Then by marginalizing the
right hand sides of Equations (18) and (19), we get
PXv(1)Xr(V)(Xv ⑴1Xr(V)) = PXv ⑴呼(V)(Xv ⑴ lxΓ0(V)).	QO)
Note that Equation (20) needs to hold for all possible realizations of the random variables
Xv (1), X0Γ(v) and X0Γ0(0). However if the parameters Θ0 and Θ1 in Equation (2) are generic,
this is clearly not true. To see this, let U ∈ Γ(v)∖Γ0(v) be any vertex. By fixing the values of
Xv(1), xΓ(v)∖{u} it is possible to find two values for Xu(0), say aι and a2, such that
ReLU ∣Θo I X	Xi(0) + aj +ΘJ =ReLU ∣Θo ∣ X	Xi(0)+ a2∣ +θ).
∖	∖i∈Γ(v)∖{u}	)	)	∖	∖i∈Γ(v)∖{u}	))
(21)
As such the Gaussian distributions in these two cases will have different means. However the right
hand side Equation (20) does not depend on Xu (0) at all, resulting in a contradiction. Thus G is a
minimal generating function of {Xv(t) : v ∈ V, t ≥ 0}. Thus Property 3 holds as well. Now the
result follows from the following Theorem.
Theorem 3 (Theorem 3.6, Quinn et al. (2015)). If Properties 1, 2 and 3 are satisfied, then the
directed information graph is equivalent to the graph G.
□
B.2	Proof of Proposition 1
Proof. Consider 4-regular graphs R1 and R2 with vertices {0, 1, . . . , 7} and edges
{(0, 3), (0, 5), (0, 6), (0, 7), (1, 2), (1, 4), (1, 6), (1, 7), (2, 3), (2, 5), (2, 6), (3, 4), (3, 5), (4, 5),
(4, 7), (6, 7)} and {(0, 1), (0, 2), (0, 4), (0, 7), (1, 4), (1, 5), (1, 6), (2, 3), (2, 4), (2, 7), (3, 5), (3, 6),
(3, 7), (4, 6), (5, 6), (5, 7)} respectively. Then under a deterministic evolution rule, since R1 and
R2 are 4-regular graphs, the trajectory will be identical at all nodes across the two graphs. However
the graphs R1 and R2 are structurally different. For e.g., R1 has a minimum vertex cover size
of 5, while for R2 it is 6. As such, if any one of the graphs (R1 , say) is provided as input to be
represented, then from the representation it is impossible to exaclty recover RJs structure.	□
B.3	Proof of Proposition 2
Proof. Kipf & Welling (2016) use a two layer graph convolutional network, in which each layer
uses convolutional filters that aggregate information from the immediate neighborhood of the ver-
tices. This corresponds to a 2-local representation function r(∙) in our computational model. Fol-
lowing this step, the values at the vertices are aggregated using softmax to compute a probability
score at each vertex. Since this procedure is independent of the structure of the input graph, it is a
valid gathering function g(∙) in local-gather and the overall architecture belongs to a 2-local-
gather model.
Similarly, Dai et al. (2017) also consider convolutional layers in which the neurons have a spatial
locality of one. Four such convolutional layers are cascaded together, the outputs of which are
then processed by a separate Q-learning network. Such a neural architecture is an instance of the
4-local-gather model.	□
B.4	Proof of Theorem 2
Proof. Consider a family G of undirected, unweights graphs. Let f : G → Z denote a function
that computes the size of the minimum vertex cover of graphs from G . For k > 0 fixed, let ALG
denote any algorithm from the k-local-gather model, with a representation function rALG(∙) and
aggregating function gALG(∙).1 We present two graphs Gi and G? such that f (Gι) = f (G2), but the
set of computed states {rALG(v) : v ∈ Gi} is the same for both the graphs (i = 1, 2). Now, since the
1See beginning of Section 3 for explanations of r(∙) and g(∙).
15
Under review as a conference paper at ICLR 2018
(a)	(b)
Figure 4: Example to illustrate k-LOCAL-GATHER algorithms are insufficient for computing certain
functions. Corresponding vertices in the two trees above have similar local neighborhoods, but the
trees have minimum vertex cover of different sizes.
gather function gALG(∙) operates only on the set of computed states (by definition of our model), this
implies ALG cannot distinguish between f(G1) and f (G2), thus proving our claim.
For simplicity, we fix k = 2 (the example easily generalizes for larger k). We consider the graphs
G1 and G2 as shown in Fig. 4(a) and 4(b) respectively. To construct these graphs, we first consider
binary trees B1 and B2 each having 7 nodes. B1 is a completely balanced binary tree with a depth
of 2, whereas B2 is a completely imbalanced binary tree with a depth of 3. Now, to get G1 and G2 ,
we replace each node in B1 and B2 by a chain of 3 nodes (more generally, by an odd number of
nodes larger than k). At each location in Bi (i = 1, 2), the head of the chain of nodes connects to
the tail of the parent’s chain of nodes, as shown in Fig. 4.
The sizes of the minimum vertex cover of G1 and G2 are 9 and 10 respectively. However, there
exists a one-to-one mapping between the vertices of G1 and the vertices of G2 such that the 2-
hop neighborhood around corresponding vertices in G1 and G2 are the same. For example, in
Fig. 4(a) and 4(b) the pair of nodes shaded in red have an identical 2-hop neighborhood (shaded in
yellow). As such, the representation function rALG(∙) - which for any node depends only on its k-hop
neighborhood - will be the same for corresponding pairs of nodes in G1 and G2.
Finally, the precise mapping between pairs of nodes in G1 and G2 is obtained as follows. First
consider a simple mapping between pairs of nodes in B1 and B2 in which (i) the 4 leaf nodes in
B1 are mapped to the leaf nodes in B2, (ii) the root of B1 is mapped to the root of B2 and (iii) the
2 interior nodes of B1 are mapped to the interior nodes of B2 . We generalize this mapping to G1
and G2 in two steps: (1) mapping chains of nodes in G1 to chains of nodes in G2, according to
the B1 - B2 map, and (2) within corresponding chains of nodes, we map nodes according to order
(head-to-head, tail-to-tail, etc.).	□
B.5	Sequential Heuristic to Compute MVC on Trees
Consider any unweighted, undirected tree T . We let the state at any node v ∈ T be represented
by a two-dimensional vector [xv , yv]. For any v ∈ T, xv takes values over the set {-, +1} while
yv is in {-1, 0, }. Here is a parameter that we choose to be less than one over the maximum
degree of the graph. Semantically xv stands for whether vertex v is ‘active’ (xv = +1) or ‘inactive’
(xv = -). Similarly yv stands for whether v has been selected to be part of the vertex cover
(yv = +), has not been selected to be part of the cover (yv = -1), or a decision has not yet been
made (yv = 0). Initially xv = - and yv = 0 for all vertices. The heuristic proceeds in rounds,
wherein at each round any vertex v updates its state [xv , yv] based on the state of its neighbors as
shown in Algorithm 1.
The update rules at vertex v are (1) if v is a leaf or if at least one of v’s neighbors are active, then v
becomes active; (2) if v is active, and if at least one of v’s active neighbors have not been chosen in
16
Under review as a conference paper at ICLR 2018
Algorithm 1: Sequential heuristic to compute minimum vertex cover on a tree.
Input: Undirected, unweighted tree T; Number of rounds NumRounds
Output: Size of minimum vertex cover on T
Xv(0)《----E for all V ∈ T	//	Xv(i)	is	Xv	at round i
yv(0)— 0 for all V ∈ T	//	yv(i)	is	yv	at round i
/* Computing the representation r(v) for each v ∈ T	*/
for i from 1 to NumRounds do
At each vertex V :
if Pu∈Γ(v) Xu(i - 1) ≥ -E then
xv(i) <-+1
if Pu∈Γ(v) yu(i - 1) < 0 then
I yv (i) - e
else
I yv (i) V-1
end
else
I xv(i) V———E and yv(i) V— 0
end
end
/* Computing the aggregating function g({r(V) : V ∈ T})	*/
yv J (PN=IRounds(yv(i) + 1)/(1 + E)) /NumRounds
return Pv∈τ yv
the cover, then V is chosen to be in the cover; (3) if all of V’s neighbors are inactive, then V remains
inactive and no decision is made on yv .
At the end of the local computation rounds, the final vertex cover size is computed by first averaging
the yv time-series at each V ∈ T (with translation, and scaling as shown in Algorithm 1), and then
summing over all vertices.
17
Under review as a conference paper at ICLR 2018
Algorithm 2: Testing procedure of GRAPH2SEQ on a graph instance.
Input: graph G, trained parameters, objective f : G → R we seek to maximize, maximum
sequence length Tmax
Output: solution set S ⊆ V
SoPt - {}, VoPt J 0	// initialize
for T from 1 to Tmax do
S J solution returned by GRAPH2SEQ(T)
if f(S) > voPt then
SoPt — S
Vopt J f (S)
end
end
return SoPt
C Section 4 Details
C.1 Reinforcement Learning Formulation
Let G(V, E) be an input graph instance for the optimization problems mentioned above. Note that
the solution to each of these problems can be represented by a set S ⊆ V . In the case of the minimum
vertex cover (MVC) and maximum independent set (MIS), the set denotes the desired optimal cover
and independent set respectively; for max cut (MC) we let (S, Sc) denote the optimal cut. For the
following let f : 2V → R be the objective function of the problem (i.e., MVC, MC or MIS) that we
want to maximize, and let F ⊆ 2V be the set of feasible solutions.
Dynamic programming formulation. Now, consider a dynamic programming heuristic in which
the subproblems are defined by the pair (G, S), where G is the graph and S ⊆ V is a subset of
vertices that have already been included in the solution. For a vertex a ∈ V \S let Q(G, S, a) =
maxS0⊇S∪{a},S0∈F f(S0) - f(S ∪ {a}) denote the marginal utility gained by selecting vertex a.
Such a Q-function satisfies the Bellman equations given by
Q(G, S, a) = f(S ∪ {a}) - f(S) + max	Q(G,S∪ {a}, a0).	(22)
a0 ∈V ∖S∪{a}
It is easily seen that computing the Q-functions solves the optimization problem, as
maxS∈F f(S) = maxa∈V Q(G, {}, a). However exactly computing Q-functions may be com-
putationally expensive. One approach towards approximately computing Q(G, S, a) is to fit it to
a (polynomial time computable) parametrized function, in a way that an appropriately defined er-
ror metric is minimized. This approach is called Q-learning in the reinforcement learning (RL)
paradigm, and is described below.
State, action and reward. We consider a reinforcement learning policy in which the solution set
S ⊆ V is generated one vertex at a time. The algorithm proceeds in rounds, where at round t the
RL agent is presented with the graph G and the set of vertices St chosen so far. Based on this state
information, the RL agent outputs an action At ∈ V \St . The set of selected vertices is updated
as St+1 = St ∪ {At}. Initially S0 = {}. Every time the RL agent performs an action At it also
incurs a reward Rt = f(St ∪ {At}) - f(St). Note that the Q-function Q(G, St, a) is well-defined
only if St and a are such that there exists an S0 ⊇ St ∪ {a} and S0 ∈ F. To enforce this let
Ft = {a ∈ V \St : ∃ S0 s.t. S0 ⊇ St ∪ {a} and S0 ∈ F} denote the set of feasible actions at time t.
Each round, the learning agent chooses an action At ∈ Ft. The algorithm terminates when Ft = {}.
Policy. The goal of the RL agent is to learn a policy for selecting actions at each time, such that the
cumulative reward incurred Pt≥0 Rt is maximized. A measure of the generalization capability of
the policy is how well it is able to maximize cumulative reward for different graph instances from a
collection (or from a distribution) of interest.
Q-learning. Let Q(G, S, a; Θ) denote the approximation of Q(G, S, a) obtained using a
parametrized function with parameters Θ. Further let ((Gi, Si, ai))iN=1 denote a sequence of (state,
18
Under review as a conference paper at ICLR 2018
action) tuples available as training examples. We define empirical loss as
L = XX(Q(Gi, Si, ai； Θ) - f(Si ∪{ai}) + f (Si) -	max	Q(Gi, Si ∪{ai}, a0; Θ)),
a∈ a	α0∈V∖Si∪{ai}	J
i=1
(23)
and minimize using stochastic gradient descent. The solution of the Bellman equations (22) is a
stationary point for this optimization.
Remark. Heuristics such as ours, which select vertices one at a time in an irreversible fashion
are studied as ‘priority greedy’ algorithms in computer science literature (Borodin et al., 2003; An-
gelopoulos & Borodin, 2003). The fundamental limits (worst-case) of priority greedy algorithms for
minimum vertex cover and maximum independent set has been discussed in Borodin et al. (2010).
19
Under review as a conference paper at ICLR 2018
(a)
(b)
(c)
Figure 5: (a) Erdos-Renyi graph of size 10 considered in Figures (b) and (c), (b) vertex-wise princi-
pal component scores at each layer, and (c) projection of the principal direction at each iteration on
the principal direction of iteration 10. These experiments are performed on our trained model.
D	Geometry of Encoding and Semantics of Graph2Seq
Towards an understanding of what aspect of solving the MVC is learnt by Graph2Seq, we conduct
empirical studies on the dynamics of the state vectors as well as present techniques and semantic
interpretations of Graph2Seq. This is done in the same spirit as in Section 3.3.
In the first set of experiments, we investigate the vertex state vector sequence. We consider graphs
of size up to 50 and of types discussed in Section 5.2. For each fixed graph, we observe the vertex
state x(∙) (Equation 2) evolution to a depth of 10 layers.
(1)	Dimension collapse. As in the random parameter case, we observe that on an average more than
8 of the 16 dimensions of the vertex state become zeroed out after 4 or 5 layers.
(2)	Principal components’ alignment. The principal component direction of the vertex state vec-
tors at each layer converges. Fig. 5(c) shows this effect for the graph shown in Fig. 5(a). We plot the
absolute value of the inner product between the principal component direction at each layer and the
principal component direction at layer 10.
(3)	Principal component scores and local connectivity. The component of the vertex state vectors
along the principal direction roughly correlate to how well the vertex is connected to the rest of the
graph. We demonstrate this again for the graph shown in Fig. 5(a), in Fig 5(b). One significant
difference here, from the random parameters case, is that the value of the principal score in the
trained model do not rise as sharply as the random case (Fig. 1(b)) with increasing number of layers.
(4)	Optimal depth. We study the effect of depth on approximation quality on the four graph types
being tested (with size 50); we plot the vertex cover quality as returned by Graph2Seqas we vary
the number of layers up to 25. Fig. 6(a) plots the results of this experiment, where there is no
convergence behavior but nevertheless apparent that different graphs work optimally at different
layer values. While the optimal layer value is 4 or 5 for random bipartite and random regular graphs,
the worst case greedy example requires 15 rounds. This experiment underscores the importance of
having a flexible number of layers is better than a fixed number; this is only enabled by the time-
series nature of Graph2Seq and is inherently missed by the fixed-depth GCNN representations in
the literature.
(5)	Q-function semantics. Recall that the Q-function of Equation (7) comprises of two terms. The
first term, denoted by Q1, is the same for all the vertices and includes a sum of all the y(∙) vectors.
The second term, denoted by Q2(v) depends on the y(∙) vector for the vertex being considered. In
this experiment we plot these two values at the very first layer of the learning algorithm (on a planted
vertex cover graph of size 15, same type as in the training set) and make the following observations:
(a) the values of Q1 and Q2(∙) are close to being integers. Q1 has a value that is one less than the
negative of the minimum vertex cover size. (b) For a vertex v, Q2 (v) is binary valued from the set
{0, 1}. Q2(v) is one, if vertex v is part of an optimum vertex cover, and zero otherwise. Thus the
20
Under review as a conference paper at ICLR 2018
(a)
Figure 6: (a) Approximation ratio of GRAPH2Seq with varying number of layers, (b) y (∙) vectors
of Graph2Seq in the intermediate layers seen using the Q-function, (c) x(∙) vectors of the fixed-
depth model seen using the Q-function. Figure (b) and (c) are on planted vertex cover graph with
optimum cover of vertices {0, 1, 2, 3, 4}.
layer number
(b)
(c)
neural network, in principle, computes the complete set of vertices in the optimum cover at the very
first round itself.
(6)	Visualizing the learning dynamics. The above observations suggests to ‘visualize’ how our
learning algorithm proceeds in each layer of the evolution using the lens of the value of Q2(∙). In
this experiment, we consider size-15 planted vertex cover graphs on (i) Graph2Seq, and (ii) the
fixed-depth GCNN trained on planted vertex cover graphs. Fig. 6(b) and 6(c) show the results of this
experiment. The planted vertex cover graph considered for these figures has an optimal vertex cover
comprising vertices {0,1, 2, 3, 4}. We center (subtract mean) the Q2(∙) values at each layer, and
threshold them to create the visualization. A dark green color signifies the vertex has a high Q2(∙)
value, while the yellow means a low Q2(∙) value. We can see that in Graph2Seq the heuristic is
able to compute the optimal cover, and moreover this answer does not change with more rounds.
The fixed depth GCNN has a non-convergent answer which oscillates between a complementary set
of vertices. Take away message: having an upper LSTM layer in the learning network is critical to
identify when an optimal solution is reached in the evolution, and “latch on” to it.
21
Under review as a conference paper at ICLR 2018
(a)
Figure 7: Max cut in (a) Erdos-Renyi graphs, (b) Grid graphs.
(b)
E	Evaluation: Max Cut and Maximum Independent Set
In this section we test and compare Graph2Seq on the maximum cut and the maximum indepen-
dent set problems. As in the MVC case, our results demonstrate a consistently good performance of
Graph2Seq across different graph types and sizes.
E.1 Max Cut
In the maximum cut problem, for an input graph instance G(V, E) we seek a cut (S, Sc) where S ⊆
V such that the number of edges crossing the cut is maximized. This problem can be approximated
within a factor 1.1383 of optimal, but not within 1.0684 unless P = NP. The RL model chooses
vertices one at a time, with cv set to 1 whenever vertex v is chosen. Supposing St is the set of vertices
chosen at the beginning of the t-th iteration. Then the reward Rt for choosing a vertex a ∈ V \St
is given by Rt = |{u : (u, a) ∈ E, u ∈ V \St}| - |{u : (u, a) ∈ E, u ∈ St}|, i.e., the number of
edges added to the cut because of moving a from V \St less the number of edges lost. The vertex
chosen At is restricted to be in the set of feasible vertices Ft ⊆ V \St for which the potential reward
is non-negative. The algorithm terminates when Ft = {}.
Training. We train our neural network model on size 15 random Erdos-Renyi graphs with an edge
probability of 0.15. The technique for training and hyper-parameters are chosen to be the same as
in Section 5.1.
The testing procedure is described below.
Graph sizes and types. We test on the following graphs.
(1)	Erdos-Renyi graph, with edge probability p = 0.15.
(2)	Two-dimensional grid graph, in which the sides contain equal number of vertices.
For each graph type, We vary the number of vertices in the range 25 - 800, and USe the same trained
model in all of the tests. The number of layers in Graph2Seq is limited to 15.
Heuristics compared. We compare GRAPH2SEQ With the folloWing tWo heuristics.
(1)	Greedy, a simple algorithm that is a 2-approximation to the optimal. This algorithm proceeds
in rounds, Where in each round the value of the cut is strictly increased. Supposing (St, V \St) is
the cut at round t (initially St = {}). We choose an arbitrary vertex in either St or V \St that,
if sWitched to the other set strictly increases the value of the cut, and sWitch it. Note that in this
algorithm a vertex could be selected and move betWeen the sets more than once. In contrast our
learning algorithm selects vertices at most once.
(2)	Fixed-depth GCNN. We consider a depth-5 netWork, similar to the one considered in MVC, and
train it on size-15 Erdos Renyi graphs With p = 0.15.
We report our results relative to an integer program solved using Gurobi, With a time cut-off of
22
Under review as a conference paper at ICLR 2018
240s. Since this is a maximization problem, we divide the Gurobi baseline solution to the heuristics
compared in order to keep the approximation ratio greater than 1.
Results. The results of our tests are presented in Fig. 7. We notice that for both graph types
GRAPH2SEQ is able to achieve an approximation less that 1.04 times the (timed) integer program
output. In Erdos-Renyi graphs of size greater than 400, it is even better than the integer program
solution (due to the time cut-off).
The Greedy heuristic performs well on large size (≥ 400) Erdos-Renyi graphs, where it even beats
Graph2Seq by a small margin. However at small sizes itis at least 5% worse than Graph2Seq in
terms of approximation ratio. On the other hand, in grid graphs Greedy is consistently worse having
an approximation ratio at least 15% above baseline values.
Fixed-depth GCNN also demonstrates a graph structure dependent behavior. On grid graphs it is
similar to Graph2Seq and achieves a consistent performance close to optimal. However on Erdos-
Renyi graphs, starting with a good approximation ratio at size 25, it quickly worsens to more than
25% above optimal at size 100. This is surprising considering that the heuristic is also trained on
Erdos-Renyi graphs.
E.2 Independent Set
For an unweighted graph G(V, E) the maximum independent set denotes a set S ⊆ V of maximum
cardinality such that for any u, v ∈ S, (u, v) ∈/ E. The maximum independent set is complementary
set of vertices to the minimum vertex cover, i.e., if S is a maximum independent set of G, then V \S
is the minimum vertex cover. However, from an approximations point-of-view maximum indepen-
dent set is hard to approximate within n1- for any > 0, despite constant factor approximation
algorithms known for minimum vertex cover.
We follow a similar reinforcement learning model, as in the other evaluations. Let St ⊆ V denote the
set of vertices selected before the t-th round (initially S1 = {}). Let Ft = {u : u ∈ V \St , (u, v) ∈/
E ∀v ∈ St } denote the set of vertices that can be added to St without violating the independent set
property of St . The learning model chooses a vertex a ∈ Ft having the largest Q-value, as action
at round t. This incurs a reward of Rt = +1 and St is updated as St+1 = St ∪ {a}. The algorithm
terminates when Ft = {}.
Training. As in max cut, we train on size-15 Erdos-Renyi graphs with edge probability of 0.15.
The other hyper-parameters are set to be the same as in the minimum vertex cover evaluation (Sec-
tion 5.1).
Heuristics compared. We compare GRAPH2SEQ with the following heuristics.
(1)	Greedy. This is a simple heuristic which achieves a ∆ + 1 approximation on unweighted graphs
with maximum degree of ∆. As with the other greedy heuristics, the heuristic proceeds in rounds
selecting one vertex in each round. Let St ⊆ V denote the vertices chosen before round t (S1 = {}).
For input graph G, we first construct a graph Gt which is the same as G but with St and its neighbor-
ing vertices removed. The Greedy heuristic chooses as its selection a vertex having the least degree
in Gt in round t. The heuristic terminates when Gt is empty.
(2)	Fixed-depth GCNN, with 5 layers and trained on size-15 Erdos-Renyi graphs with an edge prob-
ability p = 0.15. The training is performed the same way as in minimum vertex cover and max cut
evaluations.
As baseline we use the Gurobi optimization package to compute the optimal integer programming
solution with a time cut-off of 240s. We divide the Gurobi baseline solution to the heuristics com-
pared in order to keep the approximation ratio greater than 1 as in max cut.
Graph types and sizes. The following graphs are considered.
(1)	Erdos-Renyi graphs generated with edge probability p = 0.15.
(2)	Structured bipartite graphs. We construct an adversarial class of bipartite graphs for the Greedy
heuristic. For a parameter m ∈ 2N we will describe a construction having 3m/2 + 2 vertices.
The maximum independent set size is m, while Greedy chooses a set of size m/2 + 2 giving an
approximation ratio close to 2. Note that the construction below can be easily modified to generate
arbitrarily high (> 2) constant approximation ratios for Greedy. The first partite consists of m
vertices {u1, . . . , um} and the second partite consists of m/2 + 2 vertices {v1, . . . , vm/2+2}. For
23
Under review as a conference paper at ICLR 2018
Figure 8: Maximum independent set in (a) Erdos-Renyi graphs, (b) structured bipartite graphs (de-
scribed under graph types in Section E.2).
i = 1, . . . , m/2 each vi is connected to u2i-1 and u2i. Whereas vm/2+1 and vm/2+2 are connected
to all of {u1, . . . , um}.
For both graph types, We vary the total number of vertices in the range 25 - 800. The number of
layers in Graph2Seq is restricted to 15 for Erdos-Renyi graphs, and 40 for the structured bipartite
graph.
Results. We present our results in Fig. 8. In Erdos-Renyi graphs, GRAPH2SEQ shoWs a reasonable
consistency in Which it is alWays less than 1.10 times the (timed) integer program solution. The
highest approximation ratio occurs with moderate graph sizes (100 - 400). But even in this regime
it is comparable to the other tWo heuristics. In the bipartite graph case We see a performance Within
8% of optimal across all sizes.
Greedy heuristic does very well on Erdos-Renyi graphs, with comparable performance to
GRAPH2SEQ up to moderate sizes, and even beating GRAPH2SEQ at large (> 400) sizes. How-
ever, on the bipartite graphs it does poorly as expected.
The fixed-depth heuristic also does moderately well on Erdos-Renyi graphs (though it is worse than
both Graph2Seq and Greedy at all sizes). However as with Greedy, it progressively becomes
worse (close to an approximation ratio of 2) on the bipartite graphs.
24