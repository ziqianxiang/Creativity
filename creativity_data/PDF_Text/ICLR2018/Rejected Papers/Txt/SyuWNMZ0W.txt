Under review as a conference paper at ICLR 2018
Directing	Generative	Networks	with
Weighted Maximum Mean Discrepancy
Anonymous authors
Paper under double-blind review
Ab stract
The maximum mean discrepancy (MMD) between two probability measures P
and Q is a metric that is zero if and only if all moments of the two measures
are equal, making it an appealing statistic for two-sample tests. Given i.i.d. sam-
ples from P and Q, Gretton et al. (2012) show that we can construct an unbiased
estimator for the square of the MMD between the two distributions. If P is a
distribution of interest and Q is the distribution implied by a generative neural
network with stochastic inputs, we can use this estimator to train our neural net-
work. However, in practice we do not always have i.i.d. samples from our target
of interest. Data sets often exhibit biases—for example, under-representation of
certain demographics—and if we ignore this fact our machine learning algorithms
will propagate these biases. Alternatively, it may be useful to assume our data has
been gathered via a biased sample selection mechanism in order to manipulate
properties of the estimating distribution Q.
In this paper, we construct an estimator for the MMD between P and Q when we
only have access to P via some biased sample selection mechanism, and suggest
methods for estimating this sample selection mechanism when it is not already
known. We show that this estimator can be used to train generative neural net-
works on a biased data sample, to give a simulator that reverses the effect of that
bias.
1	Introduction
Neural networks with stochastic input layers can be trained to approximately sample from an ar-
bitrary probability distribution P based on samples from P (Goodfellow et al., 2014). Generating
simulations from complex distributions has applications in a large number of fields: We can auto-
matically generate illustrations for text (Zhang et al., 2017) or streams of video (Vondrick et al.,
2016); we can simulate novel molecular fingerprints to aid scientific exploration (Kadurin et al.,
2017); and, we can synthesize medical time-series data that can be shared without violating patient
privacy (Esteban et al., 2017).
In this paper, we consider the setting of a feedforward neural network (referred to as the generator)
that maps random noise inputs z ∈ Rd to some observation space X . The weights of the neural
network are trained to minimize some loss function between the resulting simulations and exemplars
of real data. The general form of the resulting distribution Q over simulations G(z) is determined
by the architecture of the generator—which governs the form of the mapping G—and by the loss
function used to train the generator. Generative adversarial networks (Goodfellow et al., 2014)
use dynamically varying, adversarially learned loss functions specified in terms of the output of
a classifier. Other generative networks use a loss function defined using a distributional distance
or divergence between the simulation distribution Q and a target distribution P (Arjovsky et al.,
2017; Nowozin et al., 2016; Zhao et al., 2017a), requiring the generator to mimic the variance in a
collection of data points rather than simply converge to a single mode. In particular, the maximum
mean discrepancy (Gretton et al., 2012) has demonstrated good performance as a loss function in
this setting (Sutherland et al., 2016; Li et al., 2017; Sutherland et al., 2017), since it reduces to zero
if and only if all moments of two distributions are equal, requiring the generator to reproduce the
full range of variation found in the data.
1
Under review as a conference paper at ICLR 2018
These approaches, like most machine learning methods, assume our data is a representative sample
from the distribution of interest. If this assumption is correct, minimizing the distributional distance
between the simulations and the data is equivalent to learning a distribution that is indistinguishable
under an appropriate two-sample test from our target distribution. However, we run into problems if
our data is not in fact a representative sample from our target distribution—for instance, if our data
gathering mechanism is susceptible to sample selection bias. The problem of machine learning algo-
rithms replicating and even magnifying human biases is gathering increasing awareness (Bolukbasi
et al., 2016; Zhao et al., 2017b), and ifwe believe our dataset suffers from such biases—for example,
if our audio dataset contains primarily male speakers or our image dataset contains primarily white
faces - We will typically want to take steps to correct this bias.
Even if our data is representative of the underlying distribution, we might want to generate samples
from a modified version of this distribution. For example, we might want to alter the demographics
of characters in a scene to fit a story-line. In this setting, we can treat our desired modified distri-
bution as our target distribution, and treat our data as if they were sampled from this distribution
subject to an appropriately biased sample selection mechanism.
If we know the form of our sample selection bias, we can reformulate our loss function to penal-
ize the generator based on the difference between simulated data and the unbiased distribution of
interest, which we will refer to as our target distribution. After a review of relevant background in-
formation in Section 2, we show in Section 3 that, given a function that describes how our observed
data deviates from this target distribution, we can construct an estimator of the MMD between the
generator and the target distribution.
In practice, we will not know the function linking the target distribution and the empirical data
distribution. However, we can approximate this function based on user-provided examples of data
points that are over- and under-represented. In Section 4, we discuss ways to estimate this function,
and in Section 5 we discuss related work in survey sampling statistics and bias reduction. We
demonstrate the efficacy and applicability of our approach in Section 6.
2	Background
2.1	Generative networks
Generative networks are a class of models which take a collection of data lying in some observation
space X as input, and aim to generate simulations that are similar to that data - or more generally,
whose empirical distribution is close to the distribution underlying the data. These models do not use
or require an explicit probability distribution for the data, but instead rely on the fact that sufficiently
complex neural networks have the capacity to approximate any arbitrary function (Hornik et al.,
1989). We can therefore construct a method of simulating from an arbitrarily complex probability
distribution Q on X by using a neural network generator G : Rd → X to transform random d-
dimensional inputs z into simulations G(z) ∈ X . In order to minimize the difference between the
probability distribution Q over simulations G(z) and the target distribution P, we train the neural
network to minimize a loss function between simulations G(Z)〜Q and data X 〜P
The most common forms of generative network are generative adversarial networks (GANs, Good-
fellow et al., 2014), so called because the loss function is dynamically defined in terms of the output
ofan adversarially learned classifier. This classifier—itself a neural network—is trained to differen-
tiate between two classes, data and simulations, and for a given observation returns a score under the
two classes (loosely corresponding to a probability of belonging to that class). The generator’s loss
function is a function of the score assigned to simulations under the true data class, so that reducing
the loss function leads to an increased chance of fooling the classifier.
While this adversarial framework has the advantage of a dynamically evolving and increasingly
discriminative loss function, a disadvantage is that the generator can successfully minimize this
loss function by mimicking only a subset of the data, leading to a phenomenon known as mode
collapse (Salimans et al., 2016; Che et al., 2017). To avoid this, recent works have incorporated esti-
mators of distributional distances between P and Q, that consider the overall distributions rather than
just element-wise distances between samples. For example, the maximum mean discrepancy (Gret-
ton et al., 2012; Sutherland et al., 2016; Li et al., 2017; Sutherland et al., 2017) between two dis-
2
Under review as a conference paper at ICLR 2018
tributions, which we explore further in Section 2.2, reduces to zero if and only if all moments of
the two distributions are the same. Other distributional distances that have been used include the
Wasserstein distance and the Cramer distance (Arjovsky et al., 2017; Bellemare et al., 2017). In
some cases, these distance-based generative networks include adversarial components in their loss
functions; for example the MMD-GAN of Li et al. (2017) adversarially learns parameters of the
maximum mean discrepancy metric.
2.2	Maximum mean discrepancy between two distributions
The maximum mean discrepancy (MMD, Gretton et al., 2012) projects two distributions P and
Q into a reproducing kernel Hilbert space (RKHS) H, and looks at the maximum mean distance
between the two projections, i.e.
MMD[P, Q] := sup (Ex〜p[f (x)] - Ey〜Q[f(y)]).
f∈H
If We specify the kernel mean embedding μp of P as μp = J k(x, ∙)dP(x), where k(∙, ∙) is the
characteristic kernel defining the RKHS, then we can write the square of this distance as
MMD2[P, Q] = ∣∣μp - μQ∣∣H = Ep[k(x,x0)] - 2Ep,Q[k(x,y)] + EQ[k(y,y0)].
Since we have projected the distributions into an infinite-dimensional space, the distance between
the two distributions is zero if and only if all their moments are the same.
In order to be a useful loss function for training a neural network, we must be able to estimate the
MMD from data, and also take derivatives of this estimate with respect to the network parameters.
We can construct an unbiased estimator of square of the MMD (Gretton et al., 2012) using m samples
Xi 〜 P and n samples y% 〜 Q as
1	mm	1 n n
\ [P，Q]= m(m-i) XXk(χi,xj) + n(nɪi) XXk(y@)
2	mn
-mn XX k(xi,yj).
mn i=1 j=1
(1)
If P is the distribution underlying our data and Q is an approximating distribution represented using
a neural network, we can differentiate the individual kernel terms in Equation 1 with respect to
the simulated data yi , and hence (via the chain rule) with respect to the parameters of the neural
networks.
The MMD has been successfully used as a loss function in several generative adversarial networks.
Dziugaite et al. (2015) and Li et al. (2015) propose training a feedforward neural network to mini-
mize the MMD between simulations and data; Li et al. (2015) also propose minimizing the MMD
between simulations and data that has been encoded using a pre-trained autoencoder. The genera-
tor in the MMD-GAN of Li et al. (2017) also aims to reduce the MMD between simulations and
data, but learns the characteristic kernel in an adversarial manner by combining the kernel with a
dynamically learned autoencoder.
3	Weighted MMD
If we have unbiased samples from two distributions P and Q, the estimator described in Equation 1
gives an unbiased estimate of the MMD between those two distributions. In a generative network
context, we can therefore use this estimator as a loss function in order to modify the generator
associated with Q so that the MMD between the two distributions is minimized.
However, this relies on having access to unbiased samples from our target distribution P. In practice,
our data may have been gathered using biased sampling practices: A dataset of images of faces may
over-represent white faces; datasets generated from medical experiments may over-represent male
patients; datasets generated from on-campus studies may over-represent college-aged students. If
3
Under review as a conference paper at ICLR 2018
our data is a biased sample of our target distribution, this estimator will estimate the difference
between our simulations and the biased empirical distribution, so our simulations will recreate the
biases therein.
In this section, we propose an estimator for the MMD between two distributions P and Q when
we have access to P only via some biased sample selection mechanism. Concretely, we assume
that P is our target of interest, but our observed data are actually sampled from a related distribution
T (x)P(x). We can think ofT(x) as an appropriately scaled “thinning function” T(x) = ZT (x) that
characterizes the sample selection mechanism. In other words, we assume that candidate samples
x* are sampled from P, and these candidates are selected into our pool With probability T(x*);
the normalizing constant Z ensures that T(X)P(X) = T(X)P(X) is a valid probability distribution.
While in the remainder of this paper We Will continue to use the language of biased sample selection
mechanisms, We note that this frameWork can also be used if our data are unbiased samples but
We Want to explicitly modulate our target distribution via some function F(x) so that We generate
simulations from F (x)P(x); in this setting We can treat the transformed target as P and let T(x) =
1/F (x).
For noW, We assume that our thinning function T(x) is knoWn; We discuss Ways to estimate or
specify it in Section 4. Our estimation problem becomes an importance sampling problem: We
have samples from T(∙)P(∙), and we want to use these to estimate MMD2 [P, Q], which is a function
of the target distribution P. Importance sampling provides a method for constructing an estimator
for the expectation of a function φ(x) with respect to a distribution P, by taking an appropriately
weighted sum of evaluations of φ at values sampled from a different distribution P0 . If we knew the
normalizing constant Z, we could construct an unbiased estimator of the MMD between P and Q
by weighting each function evaluation associated with sample x from T (x)P(x) with the likelihood
ratio P(x)/T (x)P(x) = 1/T (x), i.e.
1 mm 1	1 n n
Cu= m(m-ɪ) X j EEy Mx 叼)+ Ey X j k(yi, yj)
2mn	1
-mn XX T(x)k(xi,yj).
i=1 j=1 i
(2)
However, the normalizing constant Z depends on both T and P. We will not, in general, know an
analytic form for P, so we will not be able to calculate Z. Since we will only be able to evaluate T(x)
up to a normalizing constant, we cannot work with Equation 2 directly. Instead, we can construct a
biased estimator Md by using self-normalized importance weights,
mm
Mcb=
w(xi )w(xj)k(xi , xj) +
1
n(n-1)
nn	mn
ΣΣk(yi,yj)- nΣΣw(xi )k(xi , yj) (3)
where w(xi )
.~ , .
ι∕τ(χ1)
Pm=ιi∕T(Xj).
We refer to the estimator
Mcb in Equation 3
as the weighted MMD estimator. While this estimator
is biased due to the self-normalized weights, this bias will decrease as 1/m where m is the number
of samples from T(∙)P(∙). Further, this biased estimator will often have lower variance than the
unbiased estimator in Equation 2 (Robert & Casella, 2004).
4	LEARNING THE THINNING FUNCTION T(x)
In Section 3, we assumed that our target distribution P is only accessible via a biased sample se-
lection mechanism characterized by a thinning function T (x), so that our samples are actually dis-
tributed (up to a normalizing constant) according to T (x)P(x). If we know the thinning function
T(x) that describes our sample selection mechanism, we can use Equation 3 directly in the loss
function of our generator.
4
Under review as a conference paper at ICLR 2018
However, in practice we will not have access to this thinning function. Rather, we are likely to be in
a situation where a practitioner has noticed that one or more classes is over- or under-represented,
either in the dataset or in simulations from a generative network trained on the data. If our dataset
is fully labeled, we could either manually re-balance our dataset to match the target distribution, or
use these labels to estimate T by comparing the number of data points in various subsets of X with
the expected number under our target distribution.
Even if we do not have a fully labeled dataset, we might be able to label a subset of examples and
use these to estimate T (x). For example, assume we have an image dataset with more pictures of
men than women, and that we select and label a random subset of this dataset. A reasonable estimate
for our thinning function would be to set T (men) = 1 and approximate T (women) by the sample
ratio of men to women in our labeled subset. In this simple two-class setting, to extrapolate values
of T across our observation space X we can run a logistic regression using the labeled subset.
In a more complicated problem, we may need to deploy more sophisticated regression tools, but the
problem remains one of function estimation from labeled data. Given a set of labeled exemplars and
user-specified estimates of the thinning function evaluated at those exemplars (which could be based
on demographic statistics or domain knowledge, or desired statistics of the simulation distribution),
we could learn a thinning function T(x) using techniques such as neural network function estimation
or Gaussian process regression.
5	Related work
While it has received little attention in the deep learning literature, the problem of correcting for
biased sample selection mechanisms is familiar in the field of survey statistics. Our estimator is
related to inverse probability weighting (IPW), originally proposed by Horvitz & Thompson (1952)
and still in wide use today (e.g. Mansournia & Altman, 2016). IPW is used in stratified random
sampling study designs to correct parameter estimates for intentional bias in sampling. Under IPW,
each data point is assigned a weight proportionate to the inverse of its selection probability, so that
samples from classes which are disproportionately unlikely to be seen in the sample are assigned
increased weights to counteract the undersampling of their classes. This is the same form as the
weights in our sampling scheme, and serves a similar purpose, although it is not placed in the context
of the MMD between two distributions and assumes that the probability of selection is known for
each observation.
This work also follows increased awareness of the effects of biased data on machine learning out-
comes, and interest in mitigating these effects. For example, Caliskan et al. (2017) and Bolukbasi
et al. (2016) explore how biases and prejudices expressed in our language manifest in the word em-
beddings and representations found. Zhao et al. (2017b) find that popular image labeling datasets
exhibit gender stereotypes and that algorithms trained on these datasets tend to amplify these stereo-
types.
6	Evaluation
We consider two experimental settings: One where the form of the sampling bias is known, and one
where it is estimated from data.
6.1	Correcting for biased sample selection with a known thinning function
In Section 3, we discussed how, for a given thinning function T (x), we can construct an estimator
for the MMD between the distribution Q implied by our generator and the underlying unbiased data
distribution P. To demonstrate the efficacy of this in practice, we assume P to be a mixture of two
Gaussians (Figure 1a), and let T = i+exp0.5(x—i))+ 0.5 be a scaled logistic function as shown in
Figure 1b. The resulting data is distributed according to Figure 1c.
We construct a simple generator network taking univariate random noise as input, and consisting of
six fully-connected layers, each with three nodes and exponential linear unit activations, and with a
univariate output with no activation. We train this network using both the standard unbiased MMD
5
Under review as a conference paper at ICLR 2018
(a) Target distribution
X 〜P(X) = 0.5N(0, 0.5) +
0.5N (2, 0.5)
(b) Thinning function
T(X) = 1+exp0.5(x-1)) + 0.5
(c) Observed distribution
一,、一, 、 、一, 、
X 〜T(X)P(X) & T(X)P(X)
(d) Simulations using standard
MMD estimator (with PDF of
T (X)P(X) for comparison)
(e) Simulations using weighted
MMD estimator (with PDF of
P(X) for comparison)
Figure 1: Output of GANs trained on data sampled according to T (x)P(x). Simulation plots PDFs
are computed using NumPy’s random normal sampler, mixed to create the appropriate mode ratios.
estimator of Equation 1, and the weighted MMD estimator proposed in Equation 3, using ADAM
optimization with a learning rate of 0.001.
Figures 1e and 1d show histograms of samples generated using the two estimators. We see that,
as expected, the standard MMD estimator does a good job of replicating the empirical distribution
of the data presented to it. The weighted MMD estimator, however, is able to replicate the target
distribution P, even though it only has access to samples from T (x)P(x).
6.2 Learning and correcting for a biased sample selection mechanism
In practice we are unlikely to know a functional form for T (x), the function that describes the form
of the sampling bias. Here we consider the case where we must estimate this function from data. We
consider as an example a dataset containing zeros and ones from the MNIST dataset. We assume our
target distribution contains 50% zeros and 50% ones, but that due to a biased selection procedure
our data contains 80% zeros and 20% ones.
We hypothesise that the practitioner using this dataset is aware that there is a discrepancy, but does
not know how to translate this into a functional form for T. Instead, the practitioner labels examples
of each class, and supplies an estimate of how much each class is under-represented. In our example,
we assume the practitioner has labeled 800 zeros and 200 ones, and estimates that ones are under-
sampled according to a thinning probability of 0.75. We note that this number can easily be estimated
from a data sample if the practitioner knows the global ratio of zeros and ones.
Table 1: Comparison of different estimators on the proportion of generated images classified as
ones.
Standard MMD	Weighted MMD	Weighted MMD
(initialized to standard MMD) (random initialization)
0.2201 ± 0.0027	0.3316 ± 0.0028	0.3888 ± 0.0027
6
Under review as a conference paper at ICLR 2018
b I /匕 OOOO
。。GooIlo
0/0。///。
s。。OC。。〃
，。O O I 〃 O I
UooZ>U0 0d
006/0000
t> ð O I ∖ O o {
)IQO》 ∖
ZDoOOQ OO
0 I O f >	6 /
/ O a go DM
I / < O O ð 0 V
Ooo 0 ( ( 20
6 1 √ O / (JO
/ O L J G O。O
(a)	Subset of real images used to train
GANs (50 zeros, 14 ones)
(b)	Simulations from GAN trained with
weighted MMD, randomly initialized (40
zeros, 24 ones)
o∕oa0^0/
0。∕oz)0/0
a O O / ð / O
。0。。。。。0
/006〃。。。
OfOOG∙0D
'IOOOOOo
。。/0〃40,
/。O3〃。。1
。—分①。”/D
IlooOo。6
00/0〃/0/
o∕oαoco/
D4∕qz)0/0.
/oo/ð^/o
(c)	Simulations from GAN trained with
MMD (53 zeros, 11 ones)
(d)	Simulations from GAN trained with
weighted MMD, initialized to MMD (47
zeros, 17 ones)
Figure 2: Data used to train the GANs, and simulations from GANs trained using unweighted and
weighted MMD.
SSe-ɔ do」d
Figure 3: Proportion of images classified as ones, over time, for a network initially learned using the
standard MMD estimator. The loss function switches to the weighted MMD estimator at iteration
10000, leading to an increase in the proportion of images classified as ones.
7
Under review as a conference paper at ICLR 2018
We use an architecture based on the MMD-GAN of Li et al. (2017), which incorporates an autoen-
coder, and trains a generator based on the MMD between the encoded representations of the data and
of the simulations. The autoencoder is simultaneously learned in an adversarial manner, and serves
to optimize the kernel used in MMD to maximally discriminate between the two distributions. Our
experiments are run on an adapted version of the original MMD-GAN Torch code, which will be
made available after publication.
Since the autoencoder provides a low-dimensional embedding of our images, we specify our thin-
ning function T (x) on the space spanned by the encoder. After each update of the autoencoder,
we estimate T with the labeled set, using appropriately scaled logistic regression. We then replace
the standard MMD estimator in the loss function with our weighted estimator, calculating using the
estimated T .
One could imagine using the weighted estimator in two scenarios. We might be already aware
of the bias in our data, in which case we would simply train our GAN using the weighted MMD
estimator. Alternatively, we might only become aware of the bias after already training a GAN using
the standard estimator, in which case we might initialize our network weights to the resulting pre-
trained values. To simulate these scenarios, we trained two networks using the weighted estimator:
one initialized to a pre-trained MMD-GAN, and one randomly initialized.
Figure 2a shows a random subset of the data used to train the GANs. Due to the biased sample
selection method, there are significantly more zeros than ones. Figure 2c shows simulations gener-
ated by minimizing the standard MMD estimator using this biased data; as expected, it reflects the
greater proportion of zeros compared to ones. By contrast, the simulations trained by minimizing
the weighted MMD estimator, which estimates the MMD from the underlying target distribution as
estimated by our thinning function, shows a marked increase in the number of ones, without any
obvious difference in simulation quality. All networks were trained for 10,000 iterations.
To further quantify these results, we used the (unscaled) logistic regression used to specify the thin-
ning function to classify the simulated images as zeros or ones. Table 1 shows the proportion of ones
obtained using the three scenarios (standard MMD estimator, weighted MMD estimator initialized
with a pre-trained network, and weighted MMD estimator with random initialization). We see that,
as expected, the network trained using the standard MMD estimator produces around 20% ones,
reflecting the proportion in the dataset. The networks trained using the weighted MMD estima-
tor achieve a significanly higher percent of ones, with the randomly initialized network performing
better than the pre-trained network.
While both the networks trained using the weighted MMD estimator simulate a higher proportion of
ones than is present in our dataset, neither reaches the 50:50 ratio in our assumed target distribution.
We believe this is due to inability of the network to fully converge to a solution that gives zero
loss. This interpretation is supported by the fact that the randomly initialized network converges to a
better solution than the pre-initialized network, despite the architecture and objective function being
the same in both cases. To visualize the changes introduced by using the weighted MMD estimator,
in Figure 3 we plot the proportion of ones on a network that is trained for 10,000 iterations using
the standard MMD estimator, then for 10,000 iterations using the weighted MMD estimator. We see
that the proportion quickly rises after the loss function is altered.
7 Discussion and future work
We have presented an asymptotically unbiased estimator for the MMD between two distributions P
and Q, for use when we only have access to P via a biased sampling mechanism. This mechanism
can be specified by a known or estimated thinning function T (x), where samples are then assumed
to come from a distribution T (x)P(x)/Z. We show that this estimator can be used to manipulate the
distribution of simulations learned by a generative network, in order to correct for sampling bias or
to explicitly change the distribution according to a user-specified function.
When the thinning function is unknown, it can be estimated from labeled data. We demonstrate
this in an interpretable experiment using partially labeled images, where we jointly estimate the
thinning function alongside the generator weights. An obvious next step is to explore the use of
more sophisticated thinning functions appropriate for complex, multimodal settings.
8
Under review as a conference paper at ICLR 2018
References
M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein GAN. arXiv:1701.07875, 2017.
M.G. Bellemare, I. Danihelka, W. Dabney, S. Mohamed, B. Lakshminarayanan, S. Hoyer, and
R. Munos. The Cramer distance as a solution to biased Wasserstein gradients. arXiv:1705.10743,
2017.
T. Bolukbasi, K.-W. Chang, J.Y. Zou, V. Saligrama, and A.T. Kalai. Man is to computer programmer
as woman is to homemaker? debiasing word embeddings. In NIPS, 2016.
A. Caliskan, J.J. Bryson, and A. Narayanan. Semantics derived automatically from language corpora
contain human-like biases. Science,356(6334):183-186,2017. doi: 10.1126∕science.aal4230.
T. Che, Y. Li, A.P. Jacob, Y. Bengio, and W. Li. Mode regularized generative adversarial networks.
In ICLR, 2017.
G.K. Dziugaite, D.M. Roy, and Z. Ghahramani. Training generative neural networks via maximum
mean discrepancy optimization. In UAI, 2015.
C. Esteban, SL Hyland, and G. Ratsch. Real-valued (medical) time series generation with recurrent
conditional GANs. arXiv:1706.02633, 2017.
I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and
Y. Bengio. Generative adversarial nets. In NIPS, 2014.
A. Gretton, K.M. Borgwardt, M.J. Rasch, B. Scholkopf, and A. Smola. A kernel two-sample test.
JMLR, 13(Mar):723-773, 2012.
K. Hornik, M. Stinchcombe, and H. White. Multilayer feedforward networks are universal approxi-
mators. Neural Networks, 2(5):359-366, 1989.
D.G. Horvitz and D.J. Thompson. A generalization of sampling without replacement from a finite
universe. JASA, 47(260):663-685, 1952.
A. Kadurin, A. Aliper, A. Kazennov, P. Mamoshina, Q. Vanhaelen, K. Khrabrov, and A. Zha-
voronkov. The cornucopia of meaningful leads: Applying deep adversarial autoencoders for
new molecule development in oncology. Oncotarget, 8(7):10883, 2017.
C.-L. Li, W.-C. Chang, Y. Cheng, Y. Yang, and B. Poczos. MMD GAN: Towards deeper under-
standing of moment matching network. In NIPS, 2017.
Y. Li, K. Swersky, and R. Zemel. Generative moment matching networks. In ICML, 2015.
M.A. Mansournia and D.G. Altman. Inverse probability weighting. BMJ, 352:i189, 2016.
S.	Nowozin, B. Cseke, and R. Tomioka. f-GAN: Training generative neural samplers using varia-
tional divergence minimization. In NIPS, 2016.
C. Robert and G. Casella. Monte Carlo Statistical Methods. Springer Texts in Statistics. Springer, 2
edition, 2004.
T.	Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and X. Chen. Improved techniques
for training GANs. In NIPS, 2016.
D.J. Sutherland, H.-Y. Tung, H. Strathmann, S. De, A. Ramdas, A. Smola, and A. Gretton. Genera-
tive models and model criticism via optimized maximum mean discrepancy. In ICLR, 2016.
D.J. Sutherland, H.-Y. Tung, H. Strathmann, S. De, A. Ramdas, A. Smola, and A. Gretton. Genera-
tive models and model criticism via optimized maximum mean discrepancy. In ICLR, 2017.
C. Vondrick, H. Pirsiavash, and A. Torralba. Generating videos with scene dynamics. In NIPS,
2016.
H. Zhang, T. Xu, H. Li, S. Zhang, X. Huang, X. Wang, and D. Metaxas. Stackgan: Text to photo-
realistic image synthesis with stacked generative adversarial networks. In ICCV, 2017.
J. Zhao, M. Mathieu, and Y. LeCun. Energy-based generative adversarial network. In ICLR, 2017a.
J. Zhao, T. Wang, M. Yatskar, V. Ordonez, and K.-W. Chang. Men also like shopping: Reducing
gender bias amplification using corpus-level constraints. In EMNLP, 2017b.
9