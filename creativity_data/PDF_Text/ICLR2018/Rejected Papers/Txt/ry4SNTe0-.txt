Under review as a conference paper at ICLR 2018
Improve Training Stability of Semi-supervised
Generative Adversarial Networks with Col-
lab orative Training
Anonymous authors
Paper under double-blind review
Ab stract
Improved generative adversarial network (Improved GAN) is a successful method
of using generative adversarial models to solve the problem of semi-supervised
learning. However, it suffers from the problem of unstable training. In this paper,
we found that the instability is mostly due to the vanishing gradients on the gener-
ator. To remedy this issue, we propose a new method to use collaborative training
to improve the stability of semi-supervised GAN with the combination of Wasser-
stein GAN. The experiments have shown that our proposed method is more stable
than the original Improved GAN and achieves comparable classification accuracy
on different data sets.
1	Introduction
Generative adversarial networks (GANs) (Goodfellow et al., 2015) have been recently studied inten-
sively and achieved great success in deep learning domain(Salimans et al., 2017; Mao et al., 2016;
Springenberg, 2015; Arjovsky & Bottou, 2017; Arjovsky et al., 2017). A typical GAN simulates a
two-player minimax game, where one aims to fool the other and the overall system is finally able to
achieve equilibrium.
Specifically speaking, we have a generator G to generate fake data G(z) from a random variable z
whose distribution density is p(z), and also we have a discriminator D(x) to discriminate the real x
from the generated data G(z), where X 〜Pr (x) and Pr is the distribution density of real data. We
optimize the two players G(z) and D(x) by solving the following minimax problem:
G*,D* =arg min max Ex〜pr(χ) {log(D(x))}
+ Ez〜p(z){log(1- D(G(Z)))}.
(1)
This method is so called as the original GAN (Goodfellow et al., 2015). After this, many different
types of GANs have been proposed, e.g., least-squared GAN (Mao et al., 2016), cat-GAN (Springen-
berg, 2015), W-GAN (Arjovsky & Bottou, 2017; Arjovsky et al., 2017), Improved GAN (Salimans
et al., 2017), so on and so forth, focusing on improving the performance of GANs and extending the
GAN idea to other application scenarios.
For instance, the original GAN is trained in a completely unsupervised learning way (Goodfellow
et al., 2015), along with many variants, such as LS-GAN and cat-GAN. It was later extended to
semi-supervised learning. In (Salimans et al., 2017), Salimans et al. proposed the Improved GAN
to enable generation and classification of data simultaneously. In (Li et al., 2017), Li et al. extended
this method to consider conditional data generation.
Another issue regarding the unsupervised learning of GANs is the lack of training stability in the
original GANs, mostly because of dimension mismatch (Arjovsky & Bottou, 2017). A lot of efforts
have been dedicated to solve this issue. For instance, in (Arjovsky & Bottou, 2017; Arjovsky et al.,
2017), the authors theoretically found that the instability problem and dimension mismatch of the
unsupervised learning GAN was due to the maxing out of Jensen-Shannon divergence between
the true and fake distribution and therefore proposed using the Wasserstein distance to train GAN.
However, to calculate the Wasserstein distance, the network functions are required to be 1-Lipschitz,
1
Under review as a conference paper at ICLR 2018
which was simply implemented by clipping the weights of the networks in (Arjovsky et al., 2017).
Later, Gulrajani et. al. improved it by using gradient penalty (Gulrajani et al., 2017). Besides
them, the same issue was also addressed from different perspectives. In (Roth et al., 2017), Roth et
al. used gradient norm-based regularization to smooth the f-divergence objective function so as to
reduce dimension mismatch. However, the method could not directly work on f-divergence, which
was intractable to solve, but they instead optimized its variational lower bound. Its converging rate is
still an open question and its computational complexity may be high. On the other hand, there were
also some efforts to solve the issue of mode collapse, so as to try to stabilize the training of GANs
from another perspective, including the unrolled method in (Metz et al., 2016), mode regularization
with VAEGAN (Che et al., 2016), and variance regularization with bi-modal Gaussian distributions
(Karan Grewal, 2017). However, all these methods were investigated in the context of unsupervised
learning. Instability issue for semi-supervised GAN is still open.
In this work, we focus on investigating the training stability issue for semi-supervised GAN. To the
authors’ best knowledge, it is the first work to investigate the training instability for semi-supervised
GANs, though some were done for unsupervised GANs as aforementioned. The instability issue of
the semi-supervised GAN (Salimans et al., 2017) is first identified and analyzed from a theoretical
perspective. We prove that this issue is in fact caused by the vanishing gradients theorem on the
generator. We thus propose to solve this issue by using collaborative training to improve its training
stability. We theoretically show that the proposed method does not have vanishing gradients on
the generator, such that its training stability is improved. Besides the theoretical contribution, we
also show by experiments that the proposed method can indeed improve the training stability of the
Improved GAN, and at the same time achieve comparable classification accuracy.
It is also worth to note that (Li et al., 2017) proposed the Triple GAN that also possessed two dis-
criminators. However, its purpose is focused on using conditional probability training (the original
GAN uses unconditional probability) based on data labels to improve the training of GAN, but not
on solving the instability issue. Therefore, the question of instability for the Triple GAN is still un-
clear. More importantly, the method, collaborative training, proposed for exploring the data labels
with only unconditional probability in this paper , can also be applied to the Triple GAN to improve
its training stability, in the case of conditional probability case.
The rest of the paper is organized as follows: in Section 2, we present the generator vanishing
gradient theorem of the Improved GAN. In Section 3, we propose a new method, collaborative
training Wasserstein GAN (CTW-GAN) and prove its nonvanishing gradient theorem. In Section 4,
we present our experimental results and finally give our conclusion in Section 5.
2	Training instability of Improved GAN
The improved GAN (Salimans et al., 2017) combines supervised and unsupervised learning to solve
the semi-supervised classification problem by simulating a two-player minmax game with adver-
sarial training. The adversarial training is split into two steps. In the first step, it minimizes the
following objective function for discriminator D for data x and labels y:
D* = argmin E(χ,y)〜Pr (χ,y)kD(X) - yk2
D	(2)
+ Ex~pr (x),z 〜Pg (Z) [D(X) - D(G(Z))] .
In the second step, it minimizes the distance of feature matching to optimize the generator G:
G* =argmin Lg (G)	(3)
where
Lg(G)= Ez〜p(z),xpr(x)kD(-3)(G(Z))- D(-3)(x)k2,	(4)
and D(-3) (X) are the outputs from the (n - 3)-th layer for a net with n layers.
2.1	Generator vanishing gradient theorem for Improved GAN
In this subsection, we prove the theorem of vanishing gradients on the generator for Improved GAN.
This explains why the Improved GAN lacks training stability, as showed on some datasets, such as
MNIST (cf. Section 4).
2
Under review as a conference paper at ICLR 2018
Theorem 2.1 (Vanishing gradients on the generator for Improved GAN) Let gθ : Z → X be a
differentiable function that induces a distribution Pg. Let Pr be the real data distribution. Let D be
a differentiable discriminator bounded by T, i.e., kD(x)k2 ≤ T. If the discriminator is trained to
converge, i.e., kD — D*k2 < e, andEz〜「(『)" Jθgθ(z)k2] ≤ M2, then
l∣VθE (Dx〜Pr(X)- Dz〜p(z)(gθ(Z)))2 k2
≤ 8(T + e)2 ∙M2 γ2	(5)
→ 0.
Proof 2.1 See Appendix A.1.
This theorem implies that the generator gradients vanish when the discriminator is trained to con-
verge. In this case, the generator training saturates, which explains the training instability phe-
nomenon of the Improved GAN. The way to solve this problem is our next question.
3	Collab orative training of Improved GAN with Wasserstein
GAN (CTW-GAN)
In this section, we propose a new method to solve the instability issue of the Improved GAN by using
collaborative training between two GANs. These two GANs contribute to the adversarial training
from two different perspectives, which may help avoid the drawbacks of each one. This is the basic
idea behind the proposed method. The detailed procedure of CTW-GAN can be summarized as a
minimax game carried out in two steps:
At the first step, the discriminators Dc and Dw are optimized simultaneously:
DC,DW = arg	min	L(Dc,Dw),
c w	Dc,Dw,kDwkL≤1	c w
(6)
where lDw lL ≤ 1 means Dw is 1-Lipschitz and
L(Dc,Dw) = E(x,y)〜Pr(x,y)∣Dc(χ) - yk2
+ ExZPr(x),zzpg(z) {DC(X) - DC(G(Z))}	⑺
+ Ez〜Pg(z) {Dw(G(z))}- Ex〜Pr(x) {Dw(x)}
At the second step, the generator G is then optimized by applying the optimized two discriminators
Dc , Dw to G:
G* = arg minLg(G),
where
Lg(G) = λ ∙ Ezζp(z),xζpr(x)kDC-3)(G(z)) - D(-3)(x)k2
-(I- λ) ∙ EzZPg (Z)DW(G(Zy).
(8)
(9)
The overall architecture for CTW-GAN is described by Figure 1, where Xr and Xu stand for labeled
and unlabeled data respectively:
Figure 1: Architecture for CTW-GAN
3
Under review as a conference paper at ICLR 2018
3.1	Nonvanishing gradients theorem for CTW- GAN
Bearing in mind the generator vanishing gradients theorem for Improved GAN, we may ask if a
similar problem exists for our proposed CTW-GAN. In the following, we prove that our proposed
method does not have the vanishing gradients issue on the generator, which therefore improves the
training stability of the original Improved GAN.
Theorem 3.1 Let Pr be any distribution. Let Pθ be the distribution of gθ(z) with z being a random
variable with a density p and gθ a continuous function with respect to θ. Then there is a set of
solutions Dc , Dw to the problem
min	L(Dc, Dw)	(10)
Dc,Dw,kDwkL≤1
and we have
RBLg = (λ -I)Ez~p(z)Vθ Dw (gθ (Z))].	(11)
where the last term is the gradients of the Wasserstein distance W (Pr, Pθ), i.e.,
Ez~p(z)[Rθ Dw(gθ (z))] = Vθ W (Pr ,Pθ )	(12)
when the term L(Dc, Dw ) is well-defined.
Proof 3.1 see Appendix A.2.
Remark: the above kDw kL ≤ 1 is required to be 1-Lipschitz. The constraint can be realized by
weight clipping (Arjovsky et al., 2017) or gradient penalty (Gulrajani et al., 2017).
The proposed algorithm is described as follows:
Algorithm 1 CTW-GAN with gradient penalty:
Require: Gradient penalty λp = 10, generator Weightλg, and Adam hyperparameter α = 0.0001
Require: Initial parameter θw for Dw , θc for Dc and θg for G.
while θg does not converge do
for i = 1 …m do
Sample a real data X 〜Pr and a noisy data Z 〜P(Z)
LCi 一 kDc(χ) - yk2 + (Dc(χ) - Dc(G(z)))
end for
θc — Adam(R θc mm Pm=I Lc), α)
for t = 1 . . . ncritic do
for i = 1 …m do
Sample a real data X 〜Pr, a noisy data Z 〜P(Z) and a random variable E 〜U(0,1)
X — Gθg(Z)
X J EX +(1 — E)X
Lw) J (Dw (X)- Dw (G(Z))) + λp(∣∣Rx(Dw (X))Il2 - 1)2
end for
θw J Adam(Rθc m Pm=I Lci, α)
sample a batch of latent variables {Z(i) }m==I 〜P(Z)
θg J Adam(Rθg {λg* PzI(DC(X)- DC(G(Z))2 - (1 - λg)* PZIDw(G(Z))}, α)
end for
end while
4	Experiments
In this section, we shall present the experiments to evaluate the proposed method. Our evaluation
goals are twofold. On one hand, we evaluate the stability of CTW-GAN in comparison to that of
the original Improved GAN to see whether our proposed method improves the training stability or
not. On the other hand, we evaluate whether the proposed method achieves comparable classifica-
tion performance to the original Improved GAN. To this end, we run experiments on two datasets:
MNIST and CIFAR-10.
4
Under review as a conference paper at ICLR 2018
4.1	Experiments on MNIST
MNIST includes 50, 000 training images, 10, 000 validation images and 10, 000 testing images,
which contain handwritten digits with size 28 × 28.
Following (Salimans et al., 2017), we randomly select a small set of labeled data from the 60, 000
training and validation set to perform semi-supervised learning with the selection size of 20, 50, 100,
and 200 labeled examples. We run our experiments 9 times by giving the program different seeds.
We use the seeds from 1 - 9. For each seed, the labeled data is selected so as to have a balanced
number of examples from each class. The rest of the training images are used as unlabeled data.
In our method, we use three networks whose architectures are described in Figure 2. We use batch
normalization and add Gaussian noise to the output of each layer of the two discriminators as the
original Improved GAN does (Salimans et al., 2017).
(a) Generator G
(b) Discriminator Dw
(c) Discriminator Dc
Figure 2: Network architectures used for MNIST
We only tune the parameter λ = 0.1, 0.5 from two values on the MNIST dataset. We do not tune
any other parameters, such as learning rate, step size, etc.: we keep these as in the original Improved
GAN. The results shown in Table 1 are reported with λ = 0.1, the threshold for gradient penalty is
10 and ncritic = 5:
From the results, we can easily see that the original improved GAN has one or two out of nine
runs for training failure (unexpected high error rates and poor generate image quality). However,
for our proposed method, no training failure occurs. This shows that our method improves the
training stability indeed. On the other hand, besides making the training process more stable, our
proposed method does not reduce the classification accuracy at all, which is beyond our original
purpose of avoiding training instability of the Improved GAN. Reasoning it, it may imply that the
information explored by the two discriminators may be very different, thus reflecting a distinct
5
Under review as a conference paper at ICLR 2018
Method	n=50	n=100	n=200
DGN (Kingma et al., 2014)	= Virtual Adversarial (Miyato et al., 2015) Cat-GAN (SPringenberg, 2015) Skip Deep Generative Model (Maal0e et al., 2016) Ladder network (Rasmus et al., 2015) Auxiliary Deep Generative Model (Maal0e et al., 2016) Improved-GAN (including failure cases) Improved-GAN (only success cases) Ours	6.46 (±6.95)(1F1) 4.15(±2.49) 2.47(±1.37)(0F)	3.33(±0.14) 2.12 1.91 (±0.10) 1.32 (±0.07) 1.06 (±0.37) 0.96 (±0.02) 3.73(±5.62)(2F) 1.01(±0.31) 0.85(±0.12)(0F)	1.96(±3.11)(1F) 0.92(±0.13) 0.80(±0.05)(0F)
Table 1: Number of incorrectly classified test examples for the semi-supervised setting on permuta-
tion invariant MNIST. Results are averaged over 9 seeds. Here “nF” means the number of training
failure, i.e., instable training, occur during the training of Improved GAN.
Method	Error rates
Cat-GAN (SPringenberg, 2015)	20.40 (±0.47)
Ladder network (Rasmus et al., 2015)	19.58 (±0.46)
Improved-GAN	0.1726 (±0.0032)
Ours	0.1713 (±0.0014)
Table 2: Test errors on semi-supervised CIFAR-10. Results are averaged over three splits of data.
There is no failure case found in three runs for the original GAN on CIFAR-10. We use 4000 labeled
samples.
source of information for data representation. Utilizing those different information sources may
help to improve classification accuracy, as long as the source of information is meaningful to some
extent, or at least not noise. In our method, we use a very simple network for Dw with only two
layers. It may be possible to further improve classification performance if a network with more
layers is used. We leave it for future work.
4.2	Experiments on CIFAR- 1 0
In this section, we test our proposed method on the data set of CIFAR-10. CIFAR-10 consists of
colored images belonging to 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship
and truck. There are 50,000 training and 10,000 testing samples with the size of 32 × 32. We split
5,000 training data of CIFAR-10 for validation if needed. Following (Salimans et al., 2017), we use
a 9 layer deep convolutional network with dropout and weight normalization for the discriminator
Dc . The generator G is a 4 layer deep CNN with batch normalization. We use a very simple
network with three layers for the discriminator Dw , due to the limiting GPU resource. The network
architectures are given in Figure 3.
Table 2 summarizes our results on the semi-supervised learning task.
On CIFAR-10 dataset, it is interesting to see that there is no failure case found for the Improved
GAN in three runs at the moment. From the theoretical viewpoint, this may be due to the abundant
richness of the image features in color being much harder to be modeled by the neural nets than that
of MNIST in grayscale. Thus, the discriminator Dc trained on CIFAR-10 does not as easily converge
as the one trained on MNIST, such that the gradients on the generator do not vanish. However, it does
not mean that this possibility is avoided. In certain cases, as long as the discriminator is trained to
converge., e.g., running more iterations than the generator, the gradients on the generator will surely
vanish, as theoretically guaranteed by Theorem 2.1. On the other hand, our proposed method is still
able to achieve comparable results to the original Improved GAN, besides providing a theoretical
guarantee to the training stability. Due to the limiting GPU resource, we use a very simple network
for Dw. In this sense, the characteristics captured by this network may not be rich enough. However,
the results showed that even with the very simple network, the classification performance obtained
6
Under review as a conference paper at ICLR 2018
Figure 3: Network architectures used for CIFAR-10: The left net (Dc); the top right (G); the bottom
right (Dw).
is roughly comparable to that of the Improved GAN. We expect that it would be possibly improved
further if we have more GPU resources and are able to train a deeper network for Dw .
5	Conclusion
In the paper, we study the training instability issue of semi-supervised improved GAN. We have
found that the training instability is mainly due to the vanishing gradients on the generator of the
Improved GAN. In order to make the training of the Improved GAN more stable, we propose a col-
laborative training method to combine Wasserstein GAN with the semi-supervised improved GAN.
Both theoretical analysis and experimental results on MNIST and CIFAR-10 have shown the effec-
tiveness of the proposed method to improve training stability of the Improved GAN. In addition, it
also achieves the classification accuracy comparable to the original Improved GAN.
Acknowledgments
We would like to thank National Natural Science Foundation of China (61471205) for previously
supporting the authors to prepare for the knowledge and skills demanded by this work.
7
Under review as a conference paper at ICLR 2018
A Appendix
A.1 Proof of Theorem 2.1
We only want the differentiation to the parameter θ. For this, we can throw away the first term and
only focus on the second term.
	k 5 E (Dx〜Pr (X)- Dz〜p(z)(gθ(Z)))2 k2 ≤ E {2∣∣Dx〜pr(x)(x) - Dz〜p(z)(gθ(z))k2 ∙k 5θ D[gθ(z)]∣∣2} ≤ E {2∣∣Dx〜pr(x)(x) - Dz〜p(z)(gθ(z))k2 ∙k 5x D[gθ(z)]k2 ∙kJθ gθ (Z)图 (13) ≤ 2 ∙ e1 [|口〜Pr(x)(X) + 〜Ik2 + kDz〜p(z)(g弘Z)) + 〜I k2]2 ∙k5x D 就(Z)]+ 〜I k2 ∙kJθ gθ (z)k2} ≤ 8(T + e)2 ∙M2 ∙ e2.
The proof is done!
A.2 Proof of Theorem (3.1)
According to eq. (6), we can rewrite the optimization into two parts:
	L(Dc,Dw)=Lc+Lw	(14)
Where	Lc =	min ll E E(x,y)~Pr(x,y)kDc(X) - yk2 Dc,Dw,kDw kL ≤1	(15) + Ex 〜Pr (x),z 〜Pg (z) {Dc(X)- Dc(G(Z))}
and	Lw =	min	∕x〜Pz {Dw(G(z))}- Ex 〜Pr {Dw(X)}	(16) Dc,Dw,kDwkL≤1
By Eq.(2), we know the optimization of Lc is equivalent to optimizing Eq. (3) in the Improved GAN
and we only need to optimize Lw. By Theorem 3 in W-GAN (Arjovsky & Bottou, 2017), we know
that
Ez 〜p(z)Vθ Dw(gθ (z))] = Vθ W (Pr ,Pθ )
(17)
By applying Theorem 2.1, we know the first term of G goes to zero and the second term is given by
VW (Pr, Pg) Then We derive the desired result. The proof is done.
References
M. Arjovsky and L. Bottou. ToWards principled methods for training generative adversarial netWork.
In ICLR 2017, 2017.
M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein gan. In NIPS 2015. https://arxiv.org /pdf
/1701.07875.pdf, 2017.
Tong Che, Yanran Li, Athul Paul Jacob, Yoshua Bengio, and Wenjie Li. Mode regularized generative
adversarial netWorks. CoRR, abs/1612.02136, 2016. URL http://arxiv.org/abs/1612.
02136.
J. GoodfelloW, J. P.Abadie, M. Mirza, B. Xu, D. W. Farley, S. Ozair, A. Courville, and Y. Bengio.
Generative adversarial netse. In NIPS 2015. https://arxiv.org /pdf / 1406.2661.pdf, 2015.
8
Under review as a conference paper at ICLR 2018
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville. Im-
proved training of wasserstein gans. arXiv e-prints, 1704.00028, March 2017. URL https:
//arxiv.org/abs/1704.00028.
Yoshua Bengio Karan Grewal, R Devon Hjelm. Variance regularizing adversarial learning.
https://arxiv.org /abs/ 1707.00309, 2017.
Diederik P. Kingma, Danilo Jimenez Rezende, Shakir Mohamed, and Max Welling. Semi-
supervised learning with deep generative models. CoRR, abs/1406.5298, 2014. URL http:
//arxiv.org/abs/1406.5298.
C. Li, K. Xu, J. Zhu, and B. Zhang. Triple generative adversarial networks. https://arxiv.org /pdf
/1703.02291.pdf, 2017.
L. Maal0e, C. Kaae S0nderby, S. Kaae S0nderby, and O. Winther. Auxiliary Deep Generative
Models. ArXiv e-prints, February 2016.
Xudong Mao, Qing Li, Haoran Xie, Raymond Y. K. Lau, and Zhen Wang. Multi-class generative
adversarial networks with the L2 loss function. CoRR, abs/1611.04076, 2016. URL http:
//arxiv.org/abs/1611.04076.
Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein. Unrolled generative adversarial
networks. CoRR, abs/1611.02163, 2016. URL http://arxiv.org/abs/1611.02163.
T. Miyato, S.-i. Maeda, M. Koyama, K. Nakae, and S. Ishii. Distributional Smoothing with Virtual
Adversarial Training. ArXiv e-prints, July 2015.
Antti Rasmus, Harri Valpola, Mikko Honkala, Mathias Berglund, and Tapani Raiko. Semi-
supervised learning with ladder network. CoRR, abs/1507.02672, 2015. URL http://arxiv.
org/abs/1507.02672.
Kevin Roth, Aurelien Lucchi, Sebastian Nowozin, and Thomas Hofmann. Stabilizing training of
generative adversarial networks through regularization. CoRR, abs/1705.09367, 2017. URL
http://arxiv.org/abs/1705.09367.
T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Redford, and X. Chen. Improved techniques
for training gans. https://arxiv.org /pdf /1606.03498.pdf, 2017.
Jost Tobias Springenberg. Unsupervised and semi-supervised learning with categorical generative
adversarial networks. CoRR, abs/1511.06390, 2015. URL http://arxiv.org/abs/1511.
06390.
9