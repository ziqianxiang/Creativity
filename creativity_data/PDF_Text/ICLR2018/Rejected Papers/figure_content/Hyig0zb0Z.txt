Figure 1: Overview of our acoustic model, which computes MFSC features which are fed to aGated ConvNet. The ConvNet output one score for each letter in the dictionary, and for each MFSCframe. At inference time, theses scores are fed to a decoder (see Section 2.4) to form the most likelysequence of words. At training time, the scores are fed to the ASG criterion (see Figure 2) whichpromotes sequences of letters leading to the transcrition sequence (here “c a t”).
Figure 2: (a) The CTC graph which represents all the acceptable sequences of letters for thetranscription “cat” over 6 frames. (b) The same graph used by ASG, where blank labels have beendiscarded. (c) The fully connected graph describing all possible sequences of letter; this graph is usedfor normalization purposes in ASG. Un-normalized transitions scores are possible on edges of thesegraphs. At each time step, nodes are assigned a conditional un-normalized score, output by the GatedConvNet acoustic model.
Figure 3: LibriSpeech Letter Error Rate (LER) and Word Error Rate (WER) for the first trainingepochs of our Low Dropout architecture. (a) is on dev-clean, (b) on dev-other.
