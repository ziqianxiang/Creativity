Figure 1: Left: Trust region experiment, we use solid lines to indicate iterations inside the sphereand dash lines to indicate iterations on the sphere. By changing λ we can modify the functioncurvature. Middle: #Iteration it takes to reach sphere under different λ's, We also fit the curve bymodel T = lθg([C1λ) derived in Lemma 6. Right: Comparing ReLU with SReLU (see definitionin Section 4.2), as α closes to zero, SReLU looks more like ReLU.
Figure 2: Training/Testing error with both time and epoch. The first row is CIFAR10 dataset(batchsize B = 512) and the second row is STL10 dataset(batch size B = 1024). We find TR method hasbetter test accuracy on both datasets, although the running time is 2〜3x longer.
Figure 3: We choose batch size from {64, 128, 256, 512, 1024, 2048}, for each batch size and eachalgorithm, we independently run 5 times to gather mean accuracy and deviation (in order to showsignificance). The experiment is conducted on VGG16+CIFAR10.
Figure 4: Loss(blue lines) and accuracy(red lines) curve of interpolated models, the x-label is αdefined in (11), y-label in the left is the averaged loss and y-label in the right is accuracy. We alsocalculate the distance of models between α = 0 and α = 1 in the titles.
Figure 5: Illustration of imaginary process of Track 1(left) and Track 2(right). Note that we usesubsampled Hessian and gradient, so the iterate of trust region method will fluctuate around localminimum.
Figure 6: Experiments on two tracks as described in Table 2, we display training loss and test errorw.r.t epochs, the batch size is B = 2048.
Figure 7: Experiments on two tracks as described in Table 3, we display training loss and test errorw.r.t epochs, the batch size is B = 1024.
