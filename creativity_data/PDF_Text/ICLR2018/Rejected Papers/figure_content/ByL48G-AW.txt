Figure 1: A screen shot of eachenvironment considered in theexperiments.
Figure 2: The success rate ofeach environment over trajec-tory collection. At each iter-ation we evaluate the perfor-mance of NN policies on 100episodes. Each iteration consistof 100 training episodes.
Figure 3: The action norms of the pro-posed NN-1 and NN-2 policies as wellas the parametrized policy. For eachtask, the action norms were scaled sothat the largest one is 1. RL refers tothe parametrized policies.
Figure 4: The average returnsby the NN-1 policy with dif-ferent values of threshold Ï„ onReacher and Half Cheetah withdense rewards. In the case ofHalf Cheetah, as a reference,we use the dashed line to in-dicate the return achieved by aparametrized policy reported re-cently by Houthooft et al. (2016).
