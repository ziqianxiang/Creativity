Figure 1: Trajectories of the two dictionary elements, Ψm, trained on point pairs on a swiss roll.
Figure 2:	(a) Left column: True embedding of 400 swiss roll points. Middle column: Isomap em-bedding of swiss roll points for neighborhoods defined by k-nearest neighbors with k = 11. Theembedding is distorted due to the large neighborhoods which include shortcuts. Right column: Em-beddings after the transport operator objective function is used to identify and eliminate shortcuts.
Figure 3:	(a) The dark gray shaded area shows the training domain and the blue shaded area showsthe testing domain. (b) The transport operators trained using only the black points in the grayshaded region and are applied with random sets of coefficients to the black ’x’ points at the edge ofthe training domain to extrapolate to points outward.
Figure 4: Example estimates of paths on the manifold between points from the testing set in atransfer learning setting. The transport operator path follows the manifold much more closely thanpath estimates from the other algorithms. Ground truth is the geodesic path between the points.
Figure 5: Path deviation from the manifold as a function of number of training points when thepoint pairs (a) are chosen from the training domain or (b) in a transfer setting when point pairs areselected from the testing domain which is distinct from the training domain. (c) Path deviation inthe transfer learning task as a function of true path distance.
Figure 6: (a) An example of manifold transformations trained on ‘8’ digits being applied to the letter‘M’. (b) Convolutional neural network classifiers are tested on rotated USPS digits. The classifiersare trained on USPS digits in four variations: the original data, data trained with true rotations of3,6,10,30°, and data augmented through transfer learning using transport operators and LSMLmanifold approximations based on only seeing rotated ‘8’ digits.
Figure 7: The center image shows the neutral facial landmark points. The left column shows theresult of applying a single transport operator that qualitatively creates ”happiness” and the rightcolumn shows the result of applying a transport operator that qualitatively creates ”surprise.”inal USPS digits each rotated by 3, 6, 10, and 30 degrees (oracle classification), 3) the USPS digitstransformed many times by using random coefficients with the transport operator that was learnedonly on rotated ‘8’ digits, and 4) the USPS digits transformed by the LSML tangent vector learnedonly on rotated ‘8’ digits.
Figure 8: Examples of images with generated expressions. The neutral image (left column) andthe landmark points (middle column) are input into a conditional GAN which outputs the generatedface with the expression specified by the landmark points (right column). (a) Example of happinessexpression generation. (b) Example of sadness expression generationinference requires landmarks from an image at the apex of the expression (x1) and landmarks froma neutral image in the same sequence (x0). Once the coefficients are obtained for expression i, wehave a dynamics matrix, Ai = PmM=1 Ψmci,m, the can be applied to any set of neutral landmarkpoints to create expression i.
Figure 9: The boxes represent the classification accuracy distribution when the classifier is trainedusing the transport operator-augmented dataset (transport operator), using only one example perexpression without data augmentation (single example), and using landmarks from the expressionframes in all of the training sequences from the CK+ database (CK+).
