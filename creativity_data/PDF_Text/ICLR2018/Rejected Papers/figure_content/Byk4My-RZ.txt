Figure 1: A data induced prior distribution is learned using a secondary GAN named PGAN. Thisprior is then used to further train the original GAN.
Figure 2:	Generator reversal on a sample of 1024 MNIST digits. Projections of data points with an untrained(left) and a fully trained GAN (right). Colors represent the respective class labels. The ratios of between-clusterdistances to within-cluster distances are 0.1 (left) and 1.9 (right).
Figure 3:	Prior-data-disagreement samples. We visualize samples for which the likelihood underthe GAN prior is high, but low under the data-induced prior. Note that most of these samples are ofpoor visual quality and contain numerous artifacts.
Figure 4: Best / worst selection of samples (by visual inspection) from a number of different GANmodels. We also report the PAG and Inception Scores (when available). Note that the PAG scoreagrees with the Inception Score, but does not require labeled data to be evaluated.
Figure 5: Samples before (left) and after (right) training with the data induced prior. Note theincreased level of diversity in the samples obtained from the induced prior.
Figure 6: Reconstruction loss in generator net-works with random weights.
Figure 7: Reconstruction quality using generatornetworks with random weights. The left columnis the original image, followed by reconstructionsafter 5, 20 and 400 steps.
Figure 8: Distribution of singular values (in GANs using d latent dimensions) used in calculation of the PAGscores. For comparison, singular values of a sample of normally distributed latent codes in 100 dimensions areshown.
