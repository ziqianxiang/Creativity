Figure 1: This diagram shows an execution of a search with M = 4. (Top) The evolution of the search tree rootedat s0 after each simulation, with the last simulation path highlighted in red. (Bottom) The computation graph inMCTSnet resulting from these simulations. Black arrows represent the application of the embedding network(s) to initialize h at tree node s. Red arrows represent the forward tree traversal during a simulation using thesimulation policy (based on last memory state) and the environment model until a leaf node is reached. Bluearrows correspond to the backup network β, which updates the memory statistics h along the traversed simulationpath based on the child statistic and the last updated parent memory (in addition to transition information such asreward). The diagram makes it clear that this backup mechanism can skip over simulations where a particularnode was not visited. For example, the fourth simulation updates hB based on hB from the second simulation,since sB was not visited during the third simulation. Finally, the readout network ρ, in green, outputs the actiondistribution based on the last root memory hA. An expanded view of simulations is available in the appendix.
Figure 2: Evolution of success ratio in Sokoban during train-ing using a continuous evaluator. MCTSnet (with M = 25)against two model-free copy-model baselines. In one case(M = 2), the copy-model has access to the same numberof parameters and the same subnetworks. When M = 25,the baseline also matches the amount of computation. Wealso provide performance of MCTS with UCT with variablenumber of simulations.
Figure 3: a) Comparison of backup network architectures. b) Typical evolution of the average gate value in thegated residual backup network. Initially, the gate prefers to minimize the influence of the memory update, it latergradually increases to take into account information from the subtree.
Figure 4: a) Comparison of different simulation policy strategies in MCTSnet with M = 25 simulations. b)Effect of different values of γ in our approximate credit assignment scheme.
Figure 5: Performance of MCTSnets trained with differ-5 Discussion	ent number of simulations M (nsims). Generally, largersearches achieve better results with less training steps.
Figure 6: This diagram represents three simulations in MCTSnet that visit the tree node marked x. The leftmostsimulation shows the first simulation m during search to visit node x — when the memory statistic hxm isinitialized by the embedding network. The middle simulation is the second simulation to traverse x, which maynot immediately follow the leftmost simulation. The rightmost simulation is the third simulation to traverse x; itis also the final simulation overall, the readout network is employed to output the action distribution from theroot memory statistic. This view showcases the skip-connection across simulation times to update the memoryvectors. A diagram for a search with only two simulations is presented below.
Figure 7:	Diagram illustrating a MCTSnet search with exactly two simulations, using the same color codes forsubnetworks as in Fig. 6.
Figure 8:	The different elements composing a Sokoban frame.
