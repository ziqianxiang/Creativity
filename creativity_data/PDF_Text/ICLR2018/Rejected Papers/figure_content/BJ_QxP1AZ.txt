Figure 1: Visualizations of VCs. Each group consists of patches from original images closest to aVC. In general, these patches roughly correspond to semantic parts of objects, e.g., the cushion ofa sofa (a), the side windows of trains (b) and the wheels of bicycles (c). All VCs are referred to bytheir indices (e.g., VC139). We stress that VCs are learned in an unsupervised manner and termslike“sofa cushion” are inferred by observing the closest image patches and are used to describe theminformally.
Figure 2: Key terms in the VC formalization. On the left is the n-th input image, defined on imagelattice L0n , with height H0 and width W0 . In the middle is the lattice at the kth layer of the CNNfor the n-th image, noted by Lkn, with height Hk and width Wk . On the right is a feature vector atposition p in Lkn, noted by fpn, with dimensionality Ck .
Figure 3: Properties of VCs. In (a), We illustrate three VCs by their closest patches and theiroccurrence distributions over 6 object categories out of the 12 in PASCAL3D+ showing categorysensitivity of VC-Encoding. In (b), we visualize the closest patches to VC_42 in the top green box.
Figure 4: The green grid on the left is p. Theblue grids on the right are n(p).
Figure 5: Visualizing the inference procedure of the factorizable likelihood model (using 1 VC forexample). The original image is processed by part of VGG-16, and represented by its VC-Encoding.
Figure 1: Visualizations of VCs. Each group consists of patches from original images closest to aVC. In general, these patches roughly correspond to semantic parts of objects, e.g., the cushion ofa sofa (a), the side windows of trains (b) and the wheels of bicycles (c). All VCs are referred to bytheir indices (e.g., VC139). We stress that VCs are learned in an unsupervised manner and termslike“sofa cushion” are inferred by observing the closest image patches and are used to describe theminformally.
