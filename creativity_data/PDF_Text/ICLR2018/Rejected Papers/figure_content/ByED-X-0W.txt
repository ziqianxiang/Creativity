Figure 1: A directed graphical representation of a PIB of two bottlenecks. The neural networkparameters θ = (θ1 , θ2, θ3). The dashed blue arrows do not denote variable dependencies butthe relevance decoders for each bottleneck. The relevance decoder ptrue(y|zi), which is uniquelydetermined given the encoder pθ(z∕x) and the joint distribution PD(x,y), is intractable. We usePθ(y ∣Zi) as a variational approximation to each intractable relevance decoder Ptrue(y∣Zi).
Figure 2: A comparison of Monte-Carlo averaging and deterministic prediction of PIB.
Figure 3: The learning dynamic of PIB (left) and SFNN (right) in a decision problem are presentedin the information plane. Each point represents a hidden layer while the color indicate epochs.
Figure 4: Samples drawn from the prediction of the lower half of the MNIST test data digits basedon the upper half for PIB (left, after 60 epochs) and SFNN (right, after 200 epochs). The leftmostcolumn is the original MNIST test digit followed by the masked out digits and nine samples. Therightmost column is obtained by averaging over all generated samples of bottlenecks drawn fromthe prediction. The figures illustrate the capability of modeling structured output space using PIBand SFNN.
