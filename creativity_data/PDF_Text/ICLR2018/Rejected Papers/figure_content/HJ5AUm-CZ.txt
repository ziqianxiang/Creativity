Figure 1: Single step of gradient training in various models. A VAE treats all datapoints as indepen-dent, so only a single random element need be encoded and decoded each step. A Neural Statisticianinstead feeds a full set of elements X through both encoder and decoder networks, in order to sharea latent variable c. In a VHE, we bound the full likelihood p(X) using only random subsamples Dand x for encoding/decoding. Optionally, p(x|c) may be defined through a local latent variable z.
Figure 2: Application of VHE framework to hierarchical (left) and factorial (right) models. Givenan element x such that x ∈ X1 and x ∈ X2 , an approximate posterior is constructed for thecorresponding shared latent variables c1 , c2 using subsampled sets D1 ⊂ X1 , D2 ⊂ X2may be applied to data with factorial or hierarchical category structure. For the hierarchical case,this objective may be further modified to infer layers sequentially, as in Supplementary Material 6.2.
Figure 3: Comparison of models trained using Neural Statistician and VHE objectiVes. |D | is thenumber of encoder inputs during training. Top row: Mean encoded information DKL [q(c; D) kp(c)]; Second row: ∣D∣-shot generation loss - Ec〜q(c;D) logp(x0∣c); Third row: |D∣-shot binaryclassification error, classified by minimising conditional NLL Bottom row: Joint NLL (per element)of full test set, calculated by importance weighting on 200 samples from q(c; X);6Under review as a conference paper at ICLR 20184.2	Handwritten Character ClassesTo validate our claim that the VHE objective can facilitate learning with more expressive generativenetworks, we trained a variety of models on the Omniglot dataset to explore the interaction betweenmodel architecture and training objective. We consider two model architectures: a standard decon-volutional network based on Edwards & Storkey (2016), and a hierarchical PixelCNN architectureinspired by the recently proposed PixelVAE (Gulrajani et al., 2016). For each, we compare modelstrained with the Variational Homoencoder objective against three alternative objectives.
Figure 4: Autoregressive VariationalHomoenCoder for Omniglot characters.
Figure 5:	One-shot same-class samples generated byour model. Cues images were drawn at random frompreviously unseen classes.
Figure 6:	5-shot samples generated by each model (more in Supplement 6.4.2). With a PixelCNNarchitecture, both NS and Resample underutilise the latent space and so produce unfaithful samples.
Figure 8: Previously unseen characters redrawn inFigure 7: Conditional samples from both a style inferred from another image. Top two imagescharacter (top) and alphabet (bottom) levels denote the content (left) and style (right).
Figure 7: Conditional samples from both a style inferred from another image. Top two imagescharacter (top) and alphabet (bottom) levels denote the content (left) and style (right).
Figure 9: Comparison of models trained simple 1D distributions using various alternate objec-tives. |D | is the number of encoder inputs during training. Top row: Mean encoded informationDKL[q(c; D) k p(c)]; Second row: ∣D∣-shot generation loss — Ec〜q(c;D) log p(x0∣c); Third row:|D |-shot binary classification error, by minimising conditional NLL Bottom row: Joint NLL (perelement) of full test set, calculated by importance weighting on 200 samples from q(c; X);6.4 PixelCNN Omniglot Architecture6.4. 1 MethodologyOur architecture uses a 8x28x28 latent variable c, with a full architecture detailed below. For ourclassification experiments, we trained 5 models on each of the objectives (VHE, Rescale only, Re-sample only, NS). Occasionally we found instability in optimisation, causing sudden large increasesin the training objective. When this happened, we halted and restarted training. All models weretrained for 100 epochs on 1000 characters from the training set (the remaining 200 have been used asvalidation data for model selection). Finally, for each objective we selected the parameters achievingthe best training error.
Figure 10: 10-shot alphabet generation samples from the hierarchical model.
