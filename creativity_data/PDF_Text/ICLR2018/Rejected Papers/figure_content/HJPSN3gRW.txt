Figure 1: The agent (blue incolor) should learn to readthe instruction and navigateto green apple.
Figure 2: Example state of environment.
Figure 3: Our network architecture consisting of all three phases.
Figure 4: Multimodal fusion phase: each vector obtained from FC layer is used as 1x1 filterperform convolution over visual representation.
Figure 5: Performance analysis of our attention mechanism and comparison with other baselinemethods.
Figure 6: Visualization of attention maps for sentence: ”Go to small red car.
Figure 7: Visualization of attention maps for sentence: ”There are multiple tree. Go to smaller one.
Figure 8: Two-dimensional PCA projection of instruction embedding learnt by the GRU.
Figure 9: Agent’s trajectory as it navigates to the small green tree.
Figure 10: Agent’s trajectory as it navigates to the medium green tree.
Figure 11: Comparison of our attention based fusion mechanism with the fusion mechanism byChaplot et al. (2017) for 3d environment.
Figure 12: Some different objects used for experiments in our environment.
