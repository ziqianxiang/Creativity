Figure 1: ImageNet128 reconstructions from z1 and z2 . Odd columns corresponds to examples from thevalidation set while even columns are the model’s reconstructionsFigure 2: Samples from 128 × 128 CelebA and ImageNet128 datasets(b) ImageNet1286Under review as a conference paper at ICLR 2018	Mean	Std	# BestData	77.13	12.48	VAE	81.28	10.50	5ALI	84.60	5.73	3HALI z1	91.35	5.62	27HALI z2	86.28	5.64	3Table 1: Summary of CelebA attributes classification from reconstructions for VAE, ALI and the two levels ofHALI. The data row is the summary for the VGG classifier and the other scores have been normalized by it.
Figure 2: Samples from 128 × 128 CelebA and ImageNet128 datasets(b) ImageNet1286Under review as a conference paper at ICLR 2018	Mean	Std	# BestData	77.13	12.48	VAE	81.28	10.50	5ALI	84.60	5.73	3HALI z1	91.35	5.62	27HALI z2	86.28	5.64	3Table 1: Summary of CelebA attributes classification from reconstructions for VAE, ALI and the two levels ofHALI. The data row is the summary for the VGG classifier and the other scores have been normalized by it.
Figure 3: Comparison of average reconstruction error over the validation set for each level of reconstructionsusing the Euclidean (a) and discriminator embedded (b) distances. Using both distances, reconstructions errorsfor X 〜TX∣zι are uniformly below those for X 〜TX.. The reconstruction error using the Euclidean distanceeventually stalls showing that the Euclidean metric poorly approximates the manifold of natural images.
Figure 4: Inpainting on center cropped images on CelebA, SVHN and MS-COCO datasets (left to right).
Figure 5: Real CelebA faces (right) and their corresponding innovation tensor (IT) updates (left). For instance,the third roW in the figure features Christina Hendricks folloWed by hair-color IT updates. Similarly, the first tWoroWs depicts usage of smile-IT and the 4th roW glasses-plus-hair-color-IT.
Figure 6: (a) and (b) showcase z2 vector variation. We sample a set of z2 vectors from the prior. We repeatedlyreplace a single relevant entry in each vector by a scalar ranging from -3 to 3 and decode. (c) and (d) followsthe same process using the z1 latent space.
Figure 7: Reconstructions for SVHN and CIFAR10 from z1 and reconstructions from z2 . Odd columnscorresponds to examples from the validation set while even columns are the model’s reconstructions(d) CIFAR10 from z2Ex〜Pd(x)[Ll(x)] - H(X | Zl) ≤ KDJS(p(x, Zl) || q(x, Zl)))The Jensen-Shanon divergence being f-divergence, using Lemma 1, we concludeEx〜Pd(x) [L (X)] ― H(X | Zl) ≤ KDJS(P(X, z1, . . ., ZL) || q(X, z1, . . . , ZL))).
