Figure 1: Speedup when performing matrix multiplication using an n Ã— n weight matrix and batchsize 100. (Left) Speedup when performing only one forward matrix product. (Right) Speedup whenperforming all three matrix products involved in the forward and backward pass in gradient descent.
Figure 2: Time/Accuracy results using Lenet-5 on MNIST with batch size 64. (Left) For each innerproduct layer: forward runtimes of block diagonal and CSR sparse formats, combined forward andbackward runtimes of block diagonal format. (Right) Accuracy versus total number of nonzeroentries in the inner product layers after 10000 training iterations using block diagonal method 1.
Figure 3: Time/Accuracy results of cuda-convnet on CIFAR10 with batch size 100. (Left) For eachinner product layer: forward runtimes of block diagonal and CSR sparse formats, combined forwardand backward runtimes of block diagonal format. (Right) Accuracy versus total number of nonzeroentries in the inner product layers after 9000 training iterations using block diagonal method 1.
Figure 4: Time/Accuracy results using alexnet on imagenet with batch size 256. (Left) For eachinner product layer: forward runtimes as well as combined forward and backward runtimes of blockdiagonal format. (Right) Accuracy versus total number of nonzero entries in the inner product layersafter 360000 training iterations using block diagonal method 1.
