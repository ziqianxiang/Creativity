Figure 2: Siamese architectures (left) map pix-els into high-quality vector representations. Oursimilarity network (right) learns a similarityfunction on top of the vector representations.
Figure 1: System overview. The feature extrac-tion block computes visual representations ofimages whereas the visual similarity block esti-mates a similarity score using a neural network.
Figure 3: Misclassified pairs. (Upper) Lowerrow: (dissimilar) similar images in which thenetwork score is (lower) higher than the cosinesimilarity.
Figure 4: mAP versus âˆ†. Rigid lines are Deep-SimH scores, dashed lines are cosine similarityscores.
Figure 5: mAP when using different number of target samples in the training set.
Figure 6: t-SNE plot for a subset of 500 Ox5k images when using RMAC and cosine similarity.
Figure 7: t-SNE plot for a subset of 500 Ox5k images when using RMAC and DeepSim.
Figure 8: End-to-End architecture. The feature extraction part consists on a VGG16 network fol-lowed by a max-pooling and a l2-normalization layers. In the Visual similarity part, two compactVectors are concatenated and forwarded to the DeepSim network to obtain a similarity score.
