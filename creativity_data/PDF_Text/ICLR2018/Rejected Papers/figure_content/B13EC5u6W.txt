Figure 1: Classifier used for ChestX-ray8 datasetTo evaluate the usefulness of the generated visual rationales, we conduct an experiment where wecompare visual rationales generated by a classifier to one which is contaminated. We train theclassifier directly on the testing examples and over train until almost perfect accuracy on this set isachieved. We reason that the contaminated classifier will simply memorize the testing examples andhence will not be able to produce useful rationales.
Figure 3: Columns A: Original images. Columns B: reconstructed imagesIn the heart failure classification task, we threshold the known BNP values at 100ng/L to get bi-nary labels as suggested by Lokuge et al. (2009). Our semi-supervised model achieves an AUC of0.837 using a linear regressor as our final classifier with an ROC curve as shown in Fig 4. This iscomparable to the AUC obtained by a multilayer perceptron.
Figure 4: ROC plot for BNP predictionIn Fig 5 we demonstrate an example of the algorithm’s reconstruction of a chest radiograph from apatient with heart failure, as well as the visualization of the same patient’s chest radiograph withoutheart failure. We subtract the visualization of the radiograph without heart failure from the originalreconstructed image and superimpose this as a heatmap on the original image to demonstrate thevisual rationale for this prediction.
Figure 5: Top left: original image. Top right: reconstructed image. Bottom left: image visualizedwithout heart failure. Bottom right: superimposed visual rationale on original imageFor the same image, we apply the saliency map method, integrated gradients, the occlusion sensitiv-ity method with a window size of 8, as well as LIME to obtain Fig. 6 for comparison. All of thesemethods yield noisy and potentially irrelevant features as compared to our method of generatingvisual rationales.
Figure 6: Comparison of other methods - top left to bottom right: Saliency map, saliency map over-laid on original image, heatmap generated via occlusion sensitivity method, Integrated gradients,integrated gradients overlaid on original image, LIME outputWe apply our classifier as described above to the chest radiograph dataset released by the NIHrecently and achieve results similar to or exceeding that of the baseline results reported in the originaldataset. ROC curves are demonstrated in Fig 7. Comparison AUC results are reported in Table 1. Weshow that even without repeating the autoencoder or GAN training process on the new dataset, weare able to classify encoded representations of these chest radiographs with an accuracy comparableto or exceeding the performance of the published baseline network, which utilizes various state ofthe art network architectures as well as higher resolution images.
Figure 7: ROC curves for Chest X-Ray8 dataset	OUrs	(Wang, 2017)Atelectasis	0.7546	0.7069Cardiomegaly	0.8589	0.8141EffUsion 一	0.8243	0.7362Infiltration	0.6945	0.6128Mass	0.6958	0.5644NodUle	06247	0.7164Pneumonia	0.7346	0.6333Pneumothorax	0.8164	07891	—Table 1: Comparison AUC results for ChestX-ray8 datasetWe apply our method to the MNIST dataset and demonstrate class switching between digits from 9to 4 and 3 to 2. Figure 8. demonstrates the visual rationales for why each digit has been classifiedas a 9 rather than a 4, as well as the transformed versions of each digit. As expected, the top hor-izontal line in the digit 9 is removed to make each digit appear as a 4. Interestingly, the algorithm7Under review as a conference paper at ICLR 2018failed to convert several digits into a 4 and instead converts them into other digits which are presum-ably more similar to that instance, despite the addition of the weighted term encouraging the latentrepresentation to prefer the target class.
Figure 8: From left to right: original images with visual rationale overlaid, transformed digits8Under review as a conference paper at ICLR 2018We compare this with the occlusion sensitivity and saliency map method demonstrated in Fig. 9.
Figure 9: From left to right: visual rationale generated by our method, saliency map, occlusionsensitivityFigure 10: Left: Rationales from contaminated classifier. Right: rationales from normally trainedclassifierLastly, we contaminate our heart failure classifier as described in the methods section and comparevisual rationales generated by the contaminated classifier with those generated previously. Fig 10.
Figure 10: Left: Rationales from contaminated classifier. Right: rationales from normally trainedclassifierLastly, we contaminate our heart failure classifier as described in the methods section and comparevisual rationales generated by the contaminated classifier with those generated previously. Fig 10.
