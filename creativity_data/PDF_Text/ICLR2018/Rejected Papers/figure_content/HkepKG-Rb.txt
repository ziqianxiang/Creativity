Figure 1: Outputs of a neural network feed into semantic loss functions for constraints representinga one-hot encoding, a total ranking of preferences, and paths in a grid graph.
Figure 2: Binary classification toy example: a linear classifier without and with semantic loss.
Figure 3: FASHION pictures grouped by how confidently the supervised base model classifies themcorrectly. With semantic loss, the final semi-supervised model predicts all correctly and confidently.
