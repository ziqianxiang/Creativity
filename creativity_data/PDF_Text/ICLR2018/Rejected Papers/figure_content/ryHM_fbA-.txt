Figure 1: CNN embedding model diagram. Multiple layers of convolutions are applied to the dis-tributed representation of the word sequence where each word is represented by an m dimensionalvector. The first convolutional layer contains kernels of size m Ã— d that are applied to d words ata time. Fully connected layers combine all activations from convolutions and map them to an mdimensional embedding.
Figure 2: t-SNE representation of document em-beddings produced by our model for the IMDBtest set. Points are colored according to the sen-timent label.
