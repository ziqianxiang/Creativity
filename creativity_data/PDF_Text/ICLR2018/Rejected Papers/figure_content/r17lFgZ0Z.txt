Figure 1: Encoder of the hld-scLSTM modelvt=1,1vt=1,2The decoder is described in Figure 2. It is thesame as in the “ld-sc-LSTM” model. At eachtime-step, it takes as input the encoder output E,the DA vector, and the word-embedding of theword generated at the previous time-step. TheDA vector is also additionally provided to the sc-LSTM cell in order for it to be regulated by itsreading gate as described in Wen et al. (2015b).
Figure 2:	Decoder of the hld-scLSTM model5.1	DecodingDuring training, at each time-step, we use the ground truth word from the previous time-step. Themodel thus learns to generate the next word given the previous one. On the other hand, to generatesentences during test time, we use beam search. The first word input to the generator is a specialtoken < bos > which indicates the beginning of the sequence. Decoding is stopped if we reach aspecified maximum number of time-steps or if the model outputs a special token < eos > whichindicates the end of the sequence. We also use a slot error rate penalty, similarly to Wen et al.
Figure 3:	Scatter plots for correlation of some automated metrics with human evaluation for (a) theDSTC2 dataset, and (b) the Restaurants dataset. Random gaussian noise N (0, 0.1) has been addedto data points along the human score axis and N (0, 0.02) has been added to the automated metricscore’s axis to aid visualization of overlapping data points. Transparency has been added for thesame effect.
