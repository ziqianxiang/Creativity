Figure 1: The Pac-Boy game:Pac-Boy is yellow, the corridorsare in black, the walls in grey, thefruits are the white dots and theghosts are in red.
Figure 2: The MAd-RL architecturef : Rn×lAl → A, which maps the received qj∙ = Qj (Xj, • ) values into an action of A. This articlefocuses on the analysis of the way the local Qj -functions are computed. From the values qj , one candesign a f function that implements any aggregator function encountered in the Ensemble methodsliterature (Dietterich, 2000b): voting schemes (Gibbard, 1973), Boltzmann policy mixtures (Wiering& Van Hasselt, 2008) and of course linear value-function combinations (Sun & Peterson, 1999;Russell & Zimdars, 2003; van Seijen et al., 2017b). For the further analysis, we restrict ourselvesto the linear decomposition of the rewards: R(x, a) = j wjRj (xj , a), which implies the samedecomposition of return if they share the same γ. The advisor’s state representation may be locallydefined by φj : X → Xj, and its local state is denoted by xj = φj (x) ∈ Xj. We define the aggregatorfunction fΣ(x) as being greedy over the Qj -functions aggregation QΣ(x, a):3Under review as a conference paper at ICLR 2018QΣ(x, a) =	wjQj(xj, a),jfΣ(x) = argmax QΣ (x, a).
Figure 3: Attractor example.
Figure 4: 3-fruitattractor.
Figure 5: Experiment results.
