Figure 1: Illustration of how the different neural networks interact with each other. CNN layers aredepicted in light gray. The flow of data is shown in green, while the generation of the filters by thegenerative model is shown in red. The discriminator part of the GAN is shown in blue. Note thatthe discriminator does not have direct access to the generated filters, but can only observe the dataafter it has passed through them. The CNN is fixed, while G, D and Q are trained jointly.
Figure 2: Learned filters of the CNN’s 4th layer. We summed one third of the orignal channelstogether in order to visualize the learned filters.
Figure 3: Invariance transformations extracted from the CNN’s 4th layer. The middle sample ofeach grid represents the original data sample, while the rest of the grid are found by matching theoriginal sample’s activation profile.
Figure 4: Invariance transformations extracted from the CNN’s 2nd layer. The middle sample ofeach grid represents the original data sample, while the rest of the grid are found by matching theoriginal sample’s activation profile.
Figure 5: Multi-Dimensional Scaling for the filters produced by the GAN. Individual colors rep-resent different samples for the same filter of the true CNN. The large cluster sizes shows that theGAN is producing a wide variety of different filters for each corresponding real filter.
Figure 6: Invariance transformations extracted from the CNN’s 4th layer. The middle sample ofeach grid represents the original data sample, while the rest of the grid are found by matching theoriginal sample’s activation profile.
Figure 7: Invariance transformations extracted from the CNN’s 4th layer. The middle sample ofeach grid represents the original data sample, while the rest of the grid are found by matching theoriginal sample’s activation profile.
