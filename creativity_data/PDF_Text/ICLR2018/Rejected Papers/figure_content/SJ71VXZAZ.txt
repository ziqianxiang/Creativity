Figure 1: The mLSTM converges faster andachieves a better result within our time budget com-pared to a standard LSTM with the same hiddenstate size4	Experimental Setup and ResultsOur model processes text as a sequence of UTF-8 encoded bytes (Yergeau (2003)). For each byte, themodel updates its hidden state and predicts a probability distribution over the next possible byte. Thehidden state of the model serves as an online summary of the sequence which encodes all informationthe model has learned to preserve that is relevant to predicting the future bytes of the sequence. Weare interested in understanding the properties of the learned encoding. The process of extracting afeature representation is outlined as follows:•	Since newlines are used as review delimiters in the training dataset, all newline charactersare replaced with spaces to avoid the model resetting state.
Figure 2: Performance on the binary version of SST as a function of labeled training examples. Thesolid lines indicate the average of 100 runs while the sharded regions indicate the 10th and 90thpercentiles. Previous results on the dataset are plotted as dashed lines with the numbers indicating theamount of examples required for logistic regression on the byte mLSTM representation to match theirperformance. RNTN (Socher et al. (2013)) CNN (Kim (2014)) DMN (Kumar et al. (2015)) P-SL999LSTM (Wieting et al. (2015)) NSE (Munkhdalai & Yu (2016)) CT-LSTM (Looks et al. (2017))4.1 Text Classification and Sentiment AnalysisTable 1 shows the results of our model on 4 standard text classification datasets. The performanceof our model is noticeably lopsided. On the MR (Pang & Lee (2005)) and CR (Hu & Liu (2004))sentiment analysis datasets we improve the state of the art by a significant margin. The MR andCR datasets are sentences extracted from Rotten Tomatoes, a movie review website, and Amazonproduct reviews (which almost certainly overlaps with our training corpus). This suggests that ourmodel has learned a rich representation of text from a similar domain. On the other two datasets,SUBJ’s subjectivity/objectivity detection (Pang & Lee (2004)) and MPQA’s opinion polarity (Wiebeet al. (2005)) our model has no noticeable advantage over other unsupervised representation learningapproaches and is still outperformed by a supervised approach.
Figure 3: Histogram of cell values for the senti-ment unit on IMDB reviews.
Figure 4: Performance on the binary version of theYelp reviews dataset as a function of labeled train-ing examples. The model’s performance plateausafter about ten labeled examples and only slowimproves with additional data.
Figure 5: Visualizing the value of the sentiment unit’s cell state as it processes six randomly selectedhigh contrast IMDB reviews. Red indicates negative sentiment while green indicates positivesentiment. Best seen in color.
