Figure 1: (a) Illustration of the decomposition and transferability of the adversarial perturba-tion Vf A. (b) Visualization of decision boundaries. Each point represents an image: X +U VfA/k VfAI∣2 + V VfA/k VfA ∣∣2, and the same color indicates the same predicted label. Moredetails can be found in Section 6.3.
Figure 2: Visualization of the gradient with respect to input for resnet152. The leftmost is theoriginal image, and the rest three images are the visualization of the gradients.
Figure 3: (a) The sensitivity of the hyper parameter σ. (b) Success rates for nr-FGSM attacks withdifferent m.
Figure 4: Destruction rates of adversarial examples for various methods. For NRG methods, wechoose m = 20, σ = 15. The distortion ε is set to 15.
Figure 5: Decision boundaries of various models. The first one is the source model resnet34 and theothers are the target models examined. The horizontal axis represents sign (Vfk) of resnet34, andthe vertical axis indicates sign (Vf⊥). For each figure, the same color indicates the same predictedlabel. The origin represents the clean image x, whose label is table lamp with ID in ILSVRC2012validation set being 26 ( shown in Figure 8 of Appendix C ).
Figure 6: Top-1 success rates of FGSM and IGSM (k = 20,α = 5) attacks against vgg19bn forvarious models. The annotated value is the percentage of adversarial examples that can transfer to thevgg19. Here, the models of vgg-style have been removed, since the contribution from architecturesimilarities is not in our consideration. The distortion is chosen as ε = 15. The plots of attackingresnet152 are similar and can be found in Appendix C (Figure 9).
Figure 7: Average success rates over three ensembles for different step size α and number of iterationk. The three ensembles are the same with those in Table 3(b). Distortion ε = 20.
Figure 8: The image used to perform decision boundary analysis. Its ID in ILSVRC2012 validationset is 26, with ground truth label being table lamp.
Figure 9: Top-1 success rates of FGSM and IGSM (k = 20, α = 5) attacks against resnet152 forvarious models. The annotated value is the percentage of adversarial examples that can transferto the resnet152. Here, the models of resnet-style have been removed, since the contribution fromarchitecture similarities is not in our consideration. The distortion is chosen as ε = 15.
