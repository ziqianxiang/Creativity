Figure 1: Sample adversarial images of Gradient Estimation attacks on Clarifai’s Content Moderationmodel. Left: original image, classified as ‘drug’ with a confidence of 0.99. Right: adversarial samplewith = 32, classified as ‘safe’ with a confidence of 0.96.
Figure 2: Effectiveness of various single step black-box attacks on Model A (MNIST) andResnet-32 (CIFAR-10). The y-axis for both figures gives the variation in adversarial success asis increased. The most successful black-box attack strategy in both cases is the Gradient Estimationattack using Finite Differences with the logit loss (FD-logit), which coincides almost exactly with thewhite-box FGS attack with the logit loss (WB FGS-logit). Also, the Gradient Estimation attack withquery reduction using PCA (GE-QR (PCA-k, logit)) performs well for both datasets as well.
Figure 3: Adversarial success rates for query-reduced attacks. is set to 0.3 for Model A onMNIST and 8 for Resnet-32 on CIFAR-10. Model Aadv-0.3 and Resnet-32 adv-8 are adversariallytrained variants (ref. Section B) of the models. All attacks use roughly 8000 queries per sample forboth datasets.
Figure 4: Untargeted adversarial samples on Model A on MNIST and Resnet-32 on CIFAR-10.
Figure 5: Adversarial success rates for Gradient Estimation attacks with query reduction (FD-QR (Technique, logit)) on Model A (MNIST) and Resnet-32 (CIFAR-10), where Techniqueis either PCA or RG. ‘None’ refers to FD-logit, the case where the number of queries is 2d, where dis the dimension of the input.
Figure 6:	Effectiveness of various single step black-box attacks against adversarially trainedmodels. On the MNIST model, Model Aadv-0.3 the attack with the highest performance up till = 0.3is the Gradient Estimation attack using Finite Differences with initially added randomness. Beyondthis, the Transferability attack (single local model) using samples from Model B performs better. Onthe CIFAR-10 model ReSnet-32 adv-8, the best performing attack is the Transferability attack (singlelocal model) using samples from ReSnet-28-10.
Figure 7:	Increasing the effectiveness of FD-logit attacks on Model Aadv-0.3, Model Aadv-ens-0.3and Model Aadv-iter-0.3 (MNIST) by adding an initial L∞ constrained random perturbation ofmagnitude 0.01.
