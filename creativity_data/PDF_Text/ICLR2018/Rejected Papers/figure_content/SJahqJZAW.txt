Figure 1: Overview of our approach. We train a single generator against an array ofdiscriminators, each of which receives lower-dimensional projections—chosen randomly priorto training—as input. Individually, these discriminators are unable to perfectly separatereal and generated samples, and thus provide stable gradients to the generator throughouttraining. In turn, by trying to fool all the discriminators simultaneously, the generatorlearns to match the true full data distribution.
Figure 2: Training Stability. We plot the evolution of the “generator loss” across training—against a traditional single discriminator (DC-GAN), and the average and individual lossesagainst multiple discriminators (K = 48) in our setting. For the traditional single dis-criminator, this loss rises quickly to high value, indicating that the discriminator saturatesto rejecting generated samples with very high confidence. In contrast, the loss in our caseremains lower, allowing our discriminators to provide meaningful gradients to the generator.
Figure 3: Evolution of sample quality across training iterations. With our approach, thegenerator improves the visual quality of its samples quickly and throughout training. Mean-while, the generator trained in the traditional setting with a single discriminator showsslower improvement, and indeed quality begins to deteriorate after a point.
Figure 4: Random sets of generated samples from traditional DC-GAN and the proposedframework. For DC-GAN, we show results from the model both at 40k iterations (whenthe samples are qualitatively the best) and at the end of training (100k iterations). Forour setting, we show samples from the end of training for generator models trained withK = 12, 24, 48 pro jections. Our generator produces qualitatively better samples, with finerdetail and fewer distortions. Quality is worse with subtle high-frequency noise when K issmaller, but these decrease with increasing K to 24 and 48.
Figure 5: Interpolating in latent space. For selected pairs of generated faces (with K = 48),we generate samples using different convex combinations of their corresponding noise vectors.
Figure 6: Examples from training on canine images from Imagenet. We show manuallyselected examples of 128 × 128 images produced by a generator trained on various canineclasses from Imagenet. Although not globally plausible, the samples contain realistic low-level textures, and reproduce rough high-level composition.
