Figure 1: (a) Summary of proposed method. Each convolutional layer of a base network is modifiedby re-combining its weights through a controller module. A set of controllers is added for eachnewly learned task. A binary switching vector α controls the output of the network by switching thecontroller modules on or off. a can be determined either manually or via a sub-network (“DatasetDecider”) which determines the source domain of the image, switching accordingly between differ-ent sets of control parameters. Other layers (e.g, non-linearities, batch-normalization, skip layers)not shown for presentation purposes. (b) Transferability of various datasets to each other (ft-last)fine tuning only the last layer (full) fine-tuning all layers (ft-full-bn-off) fine tuning all layers whiledisallowing batch-normalization layers, weights to be updated. Overall, networks tend to be moreeasily transferable to problems from related domain (e.g., natural / drawing). Zoom in to see num-bers. It is recommended to view this figure in color on-line.
Figure 2: (a) Controller initialization schemes. Mean loss averaged over 5 experiments for differ-ent ways of initializing controller modules, overlaid with minimal and maximal values. Randominitialization performs the worst (random). Approximating the behavior of a fine-tuned network isslightly better (linear_approx) and initializing by mimicking the base network (diagonal) performsthe best (b) Predictability of a control network’s overall accuracy average over all datasets, givenits transferability measure. (c) Shifting Representations. Using a single base network Nsketch, wecheck the method’s sensitivity to varying values of α by varying it in the range [0, 1]. Increasing αshifts the network away from the base representation and towards learned tasks - gradually loweringperformance on the base task (diamonds) and improving on the learned ones (full circles). The rela-tively slow decrease of the performance on sketch (blue diamonds) and increase in that of Plankton(blue circles) indicates a similarity between the learned representations.
Figure 3:	(a) Accuracy vs. learning method. Using only the last layer (feature extractor) performsworst. finetune: vanilla fine-tuning. Diagonal : our controller modules with a diagonal combinationmatrix. Linear: our full method. On average, our full method outperforms vanilla fine tuning. (b)Accuracy vs. quantization: with as low as 8 bits, we see no significant effect of network quantizationon our method, showing they can be applied together.
Figure 4:	(a) Mean classification accuracy (normalized, averaged over datasets) w.r.t no. parameters.
