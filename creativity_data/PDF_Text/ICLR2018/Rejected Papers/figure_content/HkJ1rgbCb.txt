Figure 1: Our model makes sequential selections of atoms (light blue) in the molecule and is speci-fied by two networks, the Q-Network and the P-Network. The former constitutes the reinforcementlearning agent that assigns a Q-value to each atom, and the latter takes the atom selections of theQ-Network and trains a classifier to predict based solely on those atoms. This prediction is used asa reward that is fed back to the Q-Network.
Figure 2: Two examples of rationales selected by the reinforcement learning model. The selectedatoms are highlighted in large light blue circles. In both cases, we see that the model selects thetertiary nitrogen motif, highlighted in small green circles, which is implicated in many inhibitors ofthe hERG channel.
Figure 3: From left to right, example rationales generated for the dataset altered based on the pres-ence of aromatic diazo group, polyhalogenation, and aromatic nitro group. The selected atoms arehighlighted in large light blue circles; the predefined toxicophores are highlighted in small greencircles.
