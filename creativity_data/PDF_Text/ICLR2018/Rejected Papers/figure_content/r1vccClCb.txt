Figure 1:	Visualizing the learned representation versus the raw time series on PAMAP2 (humanphysical activity) data set (Reiss & Stricker, 2012a;b) using t-SNE (Maaten & Hinton, 2008) witheither Euclidean or dynamic time warping (DTW) distance (Nguyen et al., 2017). If We manuallyselect 27 dimensions of the time series that are clean and relevant (acceleration, gyroscope, magne-tometer, etc.), the representation learned by both autoencoder and neighbor-encoder achieves betterclass separation than raw data. However, if the data include noisy and/or irrelevant dimensions (heartrate, temperature, etc.), neighbor-encoder outperforms autoencoder noticeably.
Figure 2:	Various encoder-decoder configurations for training autoencoder and neighbor-encoder:a) autoencoder, b) neighbor-encoder, and c) k-neighbor-encoder with k decoders.
Figure 3: Intuition behind neighbor-encoder comparing to autoencoder. a) A simple 2D data setwith two classes, b) the nearest neighbor graph constructed for the data set (arrowheads of the edgesare removed for clarity), and c) an example of how neighbor-encoder would generate representationwith smaller intra-class variation for highlighted data points. The neighbor-encoder learns similarrepresentation for closely located data points by forcing these data points to reconstruct the samedata point as these data points are most likely sharing the same nearest neighbor (shown by thearrows).
Figure 4: Network architecture for the decoder and decoder. 64-Conv-5-1 denotes 2D convolutionallayer with 64 5 X 5 kernels and stride of 1. ReLU denotes rectified linear unit. BN denotes batchnormalization. TConv denotes transposed 2D convolutional layer.
Figure 5: The classification error rate with linear SVM versus various training data size using dif-ferent variants (i.e., vanilla, denoising, variational) of autoencoder and neighbor-encoder. Neighbor-encoder constantly outperforms autoencoder.
Figure 6:	The clustering adjust Rand index versus the proximity of the neighbor using variousneighbor-encoder variations (i.e., vanilla, denoising, variational). The proximity of a neighbor is de-fined as its ranking when query with the input. All three neighbor-encoder variations roughly reachtheir peak performance when the 24 neighbor is used as the decoder target, and the performancedeclined afterward.
Figure 7:	Outputs of the decoders for different autoencoder (AE) and neighbor-encoder (NE) varia-tions.
Figure 8:	Network architecture for the decoder and decoder. 64-Conv-5-1 denotes 2D convolutionallayer with 64 5 X 5 kernels and stride of 1. ReLU denotes rectified linear unit. BN denotes batchnormalization. TConv denotes transposed 2D convolutional layer.
Figure 9: The classification accuracy with linear SVM versus various training data size using dif-ferent variations (i.e., vanilla, denoising, variational) of autoencoder and neighbor-encoder (withfeature space neighbor definition).
Figure 10: The classification accuracy with linear SVM versus various training data size usingdifferent variations (i.e., vanilla, denoising, variational) of either autoencoder or neighbor-encoder(with side information neighbor definition). The side information is added to the autoencoder byadding the contrastive loss to the objective function.
Figure 11: Network architecture for the encoder and the decoder. 64-Conv-9-1 denotes 1D convolu-tional layer with 64 sized 9 kernels and sized 1 stride. ReLU denotes rectified linear unit. Max-3-1denotes max pooling layer with sized 3 pooling window and sized 1 stride. TConv denotes trans-posed 1D convolutional layer. ndim is the number of dimension for the input multidimensional timeseries.
Figure 12: The classification accuracy with linear SVM versus various labeled training data sizeusing different variants (i.e., vanilla, denoising, variational) of either autoencoder and k-neighbor-encoder. Both vanilla neighbor-encoder and denoising neighbor-encoder outperform their corre-sponding autoencoder while both variational neighbor-encoder and variational autoencoder performpoorly when number of labeled training data is small.
Figure 13: Network architecture for the decoder and decoder. 64-Conv-(5, 7)-(1, 2) denotes a 2Dconvolutional layer with 64 5 X 7 kernels and stride of (1,2). ReLU denotes rectified linear unit.
Figure 14: The classification accuracy with linear SVM versus various training data size usingdifferent variations (i.e., vanilla, denoising, variational) of autoencoder and neighbor-encoder.
Figure 15: Neighbor pairs under different proximity setting.
