Figure 1: Randomly selected samples from unsupervised models trained on 32×32 CIFAR10images: (a) IAF-VAE Kingma et al. (2016), (b) pixelCNN++ Salimans et al. (2017), and (c) ourhybrid AGAVE model. For our model, we show the intermediate high-level representation based onlatent variables (left), that conditions the final sample based on the pixelCNN decoder (right).
Figure 2: Schematic illustration of our auxiliary guided autoregressive variational autoencoder(AGAVE). The objective function has three components: KL divergence regularization, per-pixelreconstruction with the VAE decoder, and autoregressive reconstruction with the pixelCNN decoder.
Figure 3: Effect of the regularization parameter λ. Reconstructions (a) and samples (b) of the VAEdecoder (VR and VS, respectively) and corresponding conditional samples from the pixelCNN (PS).
Figure 4: Bits per dimension of the VAE decoder and pixelCNN decoder, as well as decompositionin KL regularization and reconstruction terms.
Figure 6: Samples from models trained with 32×32 auxiliary images with 256 (a) and 32 (b) colorlevels, and at reduced resolutions of 16×16 (c) and 8×8 pixels (d) with 256 color levels. For eachmodel the VAE sample is displayed above the corresponding conditional pixelCNN sample.
Figure 5: Impact of the color quantization in the auxiliary image. (a) Reconstructions of the VAEdecoder for different quantization levels (λ = 8). (b) BPD as a function of the quantization level.
Figure 7: The column labeled f(z) displays auxiliary representations, with z sampled from the unitGaussian prior p(z), accompanied by ten samples of the conditional pixelCNN.
Figure 8: Auxiliary reconstructions obtained after dropping the auxilliary loss. (GT) denotes groundtruth images unseen during training, f (z) is the corresponding intermediate reconstruction, (PS)denotes pixelCNN samples, conditionned on f (z).
Figure 9:	f (z) denotes auxiliary representations obtained after dropping the auxiliary loss, wherez is sampled from the prior p(z), and 4 corresponding samples from the pixelCNN componentconditioned on f(z).
