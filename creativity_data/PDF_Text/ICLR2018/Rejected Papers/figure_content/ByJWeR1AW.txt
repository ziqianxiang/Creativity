Figure 1: Random images from CIFAR10 transformed according to the augmentation schemes usedin our experiments, choosing extreme values from the augmentation parameters. Note that theseimages are very unlikely to be used during training.
Figure 2: Test accuracy of the networks All-CNN and WRN on CIFAR-10 and CIFAR-100, trainedwithout any explicit regularization (upper groups of bars) and with both dropout and weight decay(lower groups), as in the original papers. The different bars represent different models (original,deeper and shallower) and different percentage of training images (100, 50 and 10 %). The differentshades within each bar show the result of training with each data augmentation scheme (none, lightand heavier). In most cases, the models trained without regularization achieve the same performanceas the explicitly regularized models, or even significantly higher accuracy, as is the case of theshallower and deeper models and when training with fewer examples.
