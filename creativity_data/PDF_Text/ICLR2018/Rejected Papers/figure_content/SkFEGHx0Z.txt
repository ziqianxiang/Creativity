Figure 1: Overview of our radial basis function solver.
Figure 2: Effect of embedding size on NMI score on the test set of Cars196 (left) and Birds200(right). The NMI of our RBF approach improves with increasing embedding size, while performancedegrades or oscillates for triplet (Weinberger et al., 2006; Schroff et al., 2015) and lifted structuredembedding (Song et al., 2016a).
Figure 3: Recall of our RBF solver at 1, 2, 4 and 8 nearest neighbours on the test set of Cars196 (left)and Birds200 (right). Recall performance of our approach increases with embedding size.
Figure 4: Visualisation of the Birds200 test set embedding space, using the t-SNE algorithm (van derMaaten & Hinton, 2008). Despite not being trained on the test classes, bird species are well clustered.
Figure 5: Effect of the number of training samples per class on the test set accuracy of Birds200,using a VGG16 architecture. Note that the final data point in the plot refers to the entire training set;while most classes have 24 training samples per class, some have only 23.
Figure 6: (a) The effect of the number of nearest neighbours considered during training. (b) Theaverage distance from training samples to their nearest RBF centres. (c) The average RBF valuebetween training samples and their nearest RBF centres.
Figure 7: Attribute precision and recall on the 312 binary attributes of Birds200. The attributesare propagated from neighbouring test embeddings and the curves are generated by sweeping theclassification discrimination threshold. The ideal standard deviation is found for the RBF and softmaxapproaches separately. No training was carried out on the attribute labels.
