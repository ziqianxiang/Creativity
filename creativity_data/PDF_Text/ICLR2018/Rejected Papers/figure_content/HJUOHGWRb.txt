Figure 1: (a) An illustration of CEN for arrhythmia risk diagnosis. Shades of red denote the strength ofassociation between the variables. (b) A graphical model for CEN with context encoder and CRF-basedexplanations. The model is parameterized by w. (c) A graphical model for CEN with context autoencoding viathe inference network, qw (θ | C), generator network, pu (C | θ), and CRF-based explanations.
Figure 2: An example of CEN architecture. The context is represented by an image and transformed by a convnetencoder into an attention vector, which is used to construct a contextual hypothesis from a dictionary of sparseatoms. MoE uses a similar attention mechanism but for combining predictions of each model in the dictionary.
Figure 3: (a) Validation error vs. the size of the dictionary. (b) Training error vs. iteration (epoch or batch) forbaselines and CENs. (c) Test error for models trained on random subsets of data of different sizes.
Figure 4: The effect of feature quality on explanations. (a) Explanation test error vs. the level of the noise addedto the interpretable features. (b) Explanation test error vs. the total number of interpretable features.
Figure 5: Qualitative results for the Satellite dataset: (a) Weights given to a subset of features by the two models(M1 and M2) discovered by CEN. (b) How frequently M1 and M2 are selected for areas marked rural or urban(top) and the average proportion of Tenement-type households in an urban/rural area for which M1 or M2 wasselected. (c) M1 and M2 models selected for different areas on the Uganda map. M1 tends to be selected formore urbanized areas while M2 is picked for the rest. (d) Nightlight intensity of different areas of Uganda.
Figure 6: Weights of the CEN-generated CRF explanations for two patients from SUPPORT2 dataset fora set of the most influential features: dementia (comorbidity), avtisst (avg. TISS, days 3-25), slos(days from study entry to discharge), hday (day in hospital at study admit), ca_yes (the patient had cancer),sfdm2_Coma or Intub (intubated or in coma at month 2), sfdm2_SIP (sickness impact profile score atmonth 2). Higher weight values correspond to higher feature contributions to the risk of death after a given time.
Figure 7: CEN-predicted survival curvesfor 500 random patients from SUP-PORT2 test set. Color indicates deathwithin 1 year after leaving the hospital.
Figure 8: CEN architectures used in our survival analysis experiments. Context encoders were time-distributedsingle hidden layer MLP (a) and LSTM (b) that produced inputs for another LSTM over the output time intervals(denoted with h1, h2, h3 hidden states respectively). Each hidden state of the output LSTM was used to generatethe corresponding θt that were further used to construct the log-likelihood for CRF.
Figure 9: Explanations generated by CEN for the 3 top classes and the corresponding attention vectors for (a)correctly classified, (b) misclassified, and (c) adversarially constructed images. Adversarial examples weregenerated using the fast gradient sign method (FGSM) (Papernot et al., 2016). (d) Elements from the learned32-element dictionary that correspond to different writing styles of 0 digits. (e) Histogram of the attentionentropy for correctly and incorrectly classified test instances for CEN-pxl on MNIST and CEN-tpc on IMDB.
Figure 10: Histograms of test weights assigned by CEN to 6 topics: Acting- and plot-related topics (uppercharts), genre topics (bottom charts). Note that acting-related topics are often bi-modal, i.e., contributing eitherpositive, negative, or zero weight to the sentiment prediction in different contexts. Genre topics almost alwayshave negligible contributions. This allows us to conclude that the learned model does not have any particularbiases towards or against any a given genre.
Figure 11: Visualization of the model dictionary learned by CEN on MNIST. Each row corresponds to adictionary element, and each column corresponds to the weights of the model voting for each class of digits.
Figure 12: The full dictionary learned by CENtpc model: rows correspond to topics and columns correspond todictionary atoms. Very small values were thresholded for visualization clarity. Different atoms capture differentprediction patterns; for example, atom 5 assigns a highly positive weight to the [kid, child, disney,family] topic and down-weighs [sexual, violence, nudity, sex], while atom 11 acts in anopposite manner. Given the context of the review, CEN combines just a few atoms to make a prediction.
Figure 13: Additional visualizations for CENs trained on the Satellite data.
