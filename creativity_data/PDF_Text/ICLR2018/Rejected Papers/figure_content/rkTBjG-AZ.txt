Figure 1: (a) A simple search space with 24 different models. (b) A path through the search spaceencoding a convolutional module with 64 filters of size 3 Ã— 3, with stride 1, followed by batchnormalization, ReLU and affine modules. The model does not use dropout. Branches encodinghyperparameters with a single choice were omitted.
Figure 2: (a) A tree encoding an hyperparameter and its five possible values. MCTS applied to thistree is sample-inefficient as there is no sharing of information between the different child nodes.
Figure 3: (a, b) Average maximum validation score achieved as a function of the number of eval-uation across five repetitions. The error bars indicate standard error. The range of 64 evaluationsis split into two plots for clearer visualization. (c) Percentage of models above a given validationthreshold performance. MCTS with bisection and SMBO outperform random search. The error barshave size equal to the standard error.
Figure 4:	Specification of the model search space used in Section 7 in LISP-like pseudocode. SeeFigure 5 for the corresponding runnable Python code.
Figure 5:	Runnable specification of the model search space used in Section 7 in our Python im-plementation of the framework. See Figure 4 for the specification of the same search space in theLISP-like pseudocode used throughout this paper.
Figure 6: (a) The performance profile of the 16 sampled models in decreasing order of their vali-dation accuracy. The model with the highest validation accuracy (99.80%) has also the highest testaccuracy (99.72%). (b) The best performing model found from sampling 16 models of search spacein Figure 5 with a random model searcher. The hyperparameters of UserHyperparams are as inthe search space in Figure 5. The hyperparameters of the layers are as described in Appendix B. Theparameters of the Affine and Conv2d modules were initialized according to Glorot & Bengio(2010) and He et al. (2015), respectively.
Figure 7: Module interface used by all modules irrespective if they are basic or composite. Toimplement a new type of module, the human expert only needs to implement the module interface.
Figure 8: A module with many signal paths from input to output. To implement a module, thehuman expert only needs to implement its module interface. M1, M2, M3, and M4 are arbitrarysingle-input single-output modules; g1 and g2 are arbitrary transformations that may have additionalhyperparameters. The hyperparameters of g1 and g2 can be managed internally by NewModule.
