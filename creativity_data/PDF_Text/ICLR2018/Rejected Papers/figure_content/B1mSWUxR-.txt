Figure 1: Average reward relative to the temperature parameter τ, ranging from 0.1 to 3.0, onvalidation and test sets, respectively.
Figure 2: Average reward relative to a wide range of τ (from 1.0 to 10,000) on validation and testsets, respectively.
Figure 3: Testing examples from MSCOCO image captioning taskaverage reward. We hypothesize that this is due to the fact that the reference captions for each imageare largely different, making it highly non-trivial for the model to predict a “consensus” captionthat agrees with multiple references. As an example, we randomly sampled 300 images from thevalidation set and compute the averaged sentence-level BLEU between two references, which isonly 10.09. Nevertheless, through case studies we still found some interesting examples, whichdemonstrate that SQDML is capable of generating predictions that match with multiple candidates.
Figure 4: Decision boundaries of different models, together with the Bayes decision rule in (a). (b)display the decision boundary of ML. (c), (d), (e) are the decision boundaries of RAML with τ = 0.5,τ = 10000 and the one achieves the best performance τ = 2.4. (f), (g), (h) are the correspondingboundaries of SQDML. The best performance is achieved with τ = 1.1B Cost-sensitive Multi-class ClassificationTo better illustrate the properties of ML, RAML and SQDML, we display the decision boundaryof the learned models in Figure 4. Figure 4a gives the boundary of the Bayes decision rule, andFigure 4b is the boundary of ML. We can see that, as expected, ML gives “unbiased” boundarybecause it does not incorporating any information of the task-specific reward.
