Figure 1: Integrated gradients and Deep Taylor Decomposition determine input attribution relativeto a chosen reference point. This choice determines the vantage point for all subsequent attribution.
Figure 2: Evaluation of gradient and signal method sensitivity using MNIST with a [0,1] encodingfor network f1 and a [-1,0] encoding for network f2 . Both gradients and signal methods produceidentical saliency heatmaps for both networks.
Figure 3: Evaluation of attribution method sensitivity using MNIST with a [0,1] encoding for net-work f1 and a [-1,0] encoding for network f2 . Gradient x Input, IG and DTD with a zero referencepoint, which is equivalent to LRP (Bach et al., 2015; Montavon et al., 2017), are not reliable andproduce different attribution for each network. IG with a black image reference point and DTD witha PA reference point are not sensitive to the transformation of the input.
Figure 4: Smoothgrad inherits the invariance properties of the underlying attribution method. SGis not sensitive to the input transformation for gradient and signal methods (SG-PA and and SG-GB). SG lacks input invariance for integrated gradients and deep taylor decomposition when a zerovector refernce point is used, but is not sensitive when PatternAttribution (SG-PA) or a black image(SG-Black) are used. SG is not input invariant for gradient x input.
Figure 5: Evaluation of attribution method sensitivity using MNIST. Gradient x Input, IG with botha black and zero reference point and DTD with a LRP reference point, do not satisfy input invarianceand produce different attribution for each network. DTD with a PA reference point are not sensitiveto the transformation of the input.
Figure 6: Evaluation of attribution method sensitivity using MNIST. Gradient x Input, IG with botha black and zero reference point and DTD with a LRP reference point, do not satisfy input invarianceand produce different attribution for each network. DTD with a PA reference point are not sensitiveto the transformation of the input.
