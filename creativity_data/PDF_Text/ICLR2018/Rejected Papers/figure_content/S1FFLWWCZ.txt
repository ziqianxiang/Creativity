Figure 1: The illustration of the current pipeline for object centric navigation. The stacked imagesare passed to the network and the network has to decide whether to navigate or classify the object.
Figure 2: The proposed architecture for learning the object centric navigation. We used AlexNet andcombined it with our novel hierarchical actions to simultaneously navigate and recognize the object.
Figure 3: Moving Average Reward vs. Iteration (left) shows the mean reward calculated over asliding window per iteration. Policy Entropy Loss vs. Iteration (right) shows the negative log of themax policy value per iteration.
Figure 4: We show a qualitative evaluation of our algorithm on4 different instances of the environmentwhich took 4 steps before classifying. The first column shows the initial input images and the finalimage in the sequence classify the object into its respective category.
