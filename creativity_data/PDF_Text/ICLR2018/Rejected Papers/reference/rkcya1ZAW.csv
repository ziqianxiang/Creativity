title,year,conference
 Wasserstein GAN,2017, Technical Report arXiv:1701
 Stochastic gradient descent tricks,2012, Technical report
 On the convergence of stochastic gradient MCMC algorithms withhigh-order integrators,2015, In NIPS
 Density estimation using real nvP,2017, ICLR
 An analysis of stochastic flows,2014, Communications onStochastic Analysis
 Learning to draw samPles with amortized Stein variational gradientdescent,2017, In UAI
 Amortized inference in Probabilistic reasoning,2014, In AnnualConference of the Cognitive Science Society
 A class of wasserstein metrics for Probability distributions,1984, MichiganMath
 Generative adversarial nets,2014, In NIPS
 Flow-GAN: Bridging imPlicit and Prescribed learning ingenerative models,2017, Technical RePort arXiv:1705
 ImProved training of Wasser-stein GAN,2017, Technical RePort arXiv:1704
 Reinforcement learning with deeP energy-basedPolicies,2017, In ICML
 Training Products of exPerts by minimizing contrastive divergence,2002, Neural Computation
 Variational inference using implicit distributions,2017, Technical Report arXiv:1702
 Improving variational inference with inverse autoregres-sive flow,2016, In NIPS
 Auto-encoding variational Bayes,2014, In ICLR
 Approximate inference with amortised MCMC,2017, Technical ReportarXiv:1702
 Stein variational gradient descent: A general purpose Bayesian inferencealgorithm,2016, In NIPS
 Learning in implicit generative models,2017, Technical ReportarXiv:1610
 Stein variational autoencoder,2017, Technical ReportarXiv:1704
 Vae learning via stein variational gradientdescent,2017, In NIPS
 Unsupervised representation learning with deep convolutionalgenerative adversarial networks,2016, Technical Report arXiv:1511
 Operator variational inference,2016, In NIPS
 Variational inference with normalizing flows,2015, In ICML
 Stochastic backpropagation and approximate inferencein deep generative models,2014, In ICML
 Markov chain Monte Carlo and variational inference:Bridging the gap,2015, In ICML
 Improved techniquesfor training GANs,2016, Technical Report arXiv:1606
 Consistency and fluctuations for stochastic gradientLangevin dynamics,2016, JMLR
 The variational gaussian process,2016, In ICLR
 Pixel recurrent neural networks,2016, In ICML
 Learning to draw samples: With application to amortized MLE for generativeadversarial learning,2017, In ICLR workshop
 Bayesian learning via stochastic gradient Langevin dynamics,2011, In ICML
 Energy-based generative adversarial networks,2017, In ICLR
