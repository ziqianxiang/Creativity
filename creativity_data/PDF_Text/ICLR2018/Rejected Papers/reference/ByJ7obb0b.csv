title,year,conference
 Greedy layer-wise trainingof deep networks,2007, In Advances in neural information processing systems
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Sub-sampled cubic regularization for non-convex opti-mization,2017, arXiv preprint arXiv:1705
 Learning multiple layers of features from tiny images,2009, 2009
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Estimating the Hessian by back-propagatingcurvature,2012, In Proceedings of the 29th International Coference on International Conference onMachine Learning
 A linearly-convergent stochastic L-BFGSalgorithm,2016, In Artificial Intelligence and Statistics
 Cubic regularization of Newton method and its global perfor-mance,2006, Mathematical Programming
 Numerical optimization,2006, Springer
 A stochastic quasi-Newton method for onlineconvex optimization,2007, In Artificial Intelligence and Statistics
 Adadelta: an adaptive learning rate method,2012, arXiv preprint arXiv:1212
