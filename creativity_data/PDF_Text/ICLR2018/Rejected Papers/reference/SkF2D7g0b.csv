title,year,conference
 Towards evaluating the robustness of neural networks,2017, In IEEESymposium on Security and Privacy
 Evading classifiers by morphing in the dark,2017, 2017
 Analysis of classifiersâ€™ robustness to adversarialperturbations,2015, arXiv preprint arXiv:1502
 Deep learning,2016, MIT Press
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Towards deep neural network architectures robust to adversarialexamples,2014, arXiv preprint arXiv:1412
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Learning multiple layers of features from tiny images,2009, 2009
 The MNIST database of handwritten digits,1998, 1998
 Delving into transferable adversarial examplesand black-box attacks,2017, In ICLR
 Deepfool: a simple andaccurate method to fool deep neural networks,2015, arXiv preprint arXiv:1511
 Universaladversarial perturbations,2016, arXiv preprint arXiv:1610
 Fast feature fool: A data independentapproach to universal adversarial perturbations,2017, arXiv preprint arXiv:1707
 Simple black-box adversarial perturbations fordeep netWorks,2016, arXiv preprint arXiv:1612
 Practical black-box attacks against deep learning systems using adversarial examples,2017, InProceedings of the 2017 ACM Asia Conference on Computer and Communications Security
 Accessorize to a crime: Realand stealthy attacks on state-of-the-art face recognition,2016, In Proceedings of the 2016 ACM SIGSACConference on Computer and Communications Security
 A tutorial on principal component analysis,2014, arXiv preprint arXiv:1404
 Multivariate stochastic approximation using a simultaneous perturbation gradientapproximation,1992, IEEE transactions on automatic control
 Intriguing properties of neural netWorks,2014, In International Conference on LearningRepresentations
 Ensembleadversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 The space oftransferable adversarial examples,2017, arXiv preprint arXiv:1704
 Numerical optimization,1999, Springer Science
 Automatically evading classifiers,2016, In Proceedings of the2016 Network and Distributed Systems Symposium
 Wide residual networks,2016, arXiv preprint arXiv:1605
1 Baseline attacksRandom perturbations,2015, With no knowledge of f or the training set
