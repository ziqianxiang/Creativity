title,year,conference
 Gradient descent for general reinforcement learning,1999, InAdvances in neural information processing systems
 Temporal-difference methods and markov models,1993, IEEE Transactions on Systems
 Neuronlike adaptive elements that cansolve difficult learning control problems,1983, IEEE transactions on systems
 The arcade learning environ-ment: An evaluation platform for general agents,2013, 2013
 Convergent temporal-difference learning with arbitrary smooth function approxi-mation,2009, In Advances in Neural Information Processing Systems
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Finite-sampleanalysis of proximal gradient td algorithms,2015, In UAI
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 Should one compute the temporal difference fix point or minimize the bellmanresidual? the unified oblique projection view,2010, arXiv preprint arXiv:1011
 Masteringthe game of go with deep neural networks and tree search,2016, Nature
 Fast gradient-descent methods for temporal-difference learningwith linear function approximation,2009, In Proceedings of the 26th Annual International Conferenceon Machine Learning
 Lecture 6,2012,5â€”RmsProp: Divide the gradient by a running average of itsrecent magnitude
