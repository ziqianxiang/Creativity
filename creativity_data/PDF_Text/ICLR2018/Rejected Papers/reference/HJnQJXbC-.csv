title,year,conference
 TensorFlow: Large-scale machine learning on heterogeneous distributed systems,2016, arXiv preprintarXiv:1603
 Theano: A python framework for fast computation of mathematical expressions,2016, arXiv preprintarXiv:1605
 Dataflow architectures,1986, Annual Review OfCOmpuier Science
 A fast unified model for parsingand sentence understanding,2016, arXiv preprint arXiv:1603
 A cloud-scale acceleration architecture,2016, In MicrOarchitecture (MICRO)
 Hierarchical memory networks,2016, arXivpreprint arXiv:1605
 Pipelined back-propagation for context-dependent deep neuralnetworks,2012, In Interspeech
 Project Adam: Building an efficient and scalabledeep learning training system,2014, In OSDI
 Empirical evaluation of gated recurrent neural networks onsequence modeling,2014, arXiv preprint arXiv:1412
 Largescale distributed deep networks,2012, In Advances in neural infOrmatiOn prOcessing systems
 Large-scaleFPGA-based convolutional networks,2011, Scaling up Machine Learning: Parallel and Distributed ApprOaches
 Spatially adaptivecomputation time for residual networks,2016, arXiv preprint arXiv:1612
 Neural message passing for quantumchemistry,2017, arXiv preprint arXiv:1704
 Learning task-dependent distributed representations by backpropagation throughstructure,1996, In Neural NetwOrks
 Adaptive computation time for recurrent neural networks,2016, arXiv preprint arXiv:1603
 Node coloring in wireless networks: Complexity results and grid coloring,0920, 092012
 Decoupled neuralinterfaces using synthetic gradients,2016, arXiv preprint arXiv:1608
 In-datacenter performance analysis of a tensor processing unit,2017, arXiv preprint arXiv:1704
 Adam: A method for stochastic optimization,2014, CORR
 Gated graph sequence neural networks,2015, arXiv preprintarXiv:1511
 Dynet: The dynamic neural network toolkit,2017, arXiv preprint arXiv:1701
 On-the-fly operation batching in dynamic computation graphs,2017, arXivpreprint arXiv:1705
 Learning multilingual named entityrecognition from wikipedia,2013, Artificial Intelligence
 Quantum chemistry structures and propertiesof 134 kilo molecules,2014, Scientific Data
 Hogwild: A lock-free approach to parallelizing stochastic gradientdescent,2011, In Advances in Neural Information Processing Systems
 Neural programmer-interpreters,2015, arXiv preprint arXiv:1511
 The graph neural network model,2009, IEEETransactions on Neural Networks
 Recurrent dropout without memory loss,2016, arXiv preprintarXiv:1603
 Outrageously large neuralnetworks: The sparsely-gated mixture-of-experts layer,2017, arXiv preprint arXiv:1701
 Recursive deepmodels for semantic compositionality over a sentiment treebank,2013, In Proceedings of the conference onempirical methods in natural language processing (EMNLP)
 Improved semantic representations from tree-structured long short-termmemory networks,2015, arXiv preprint arXiv:1503
