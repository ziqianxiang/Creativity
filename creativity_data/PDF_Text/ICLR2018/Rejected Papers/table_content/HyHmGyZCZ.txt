Table 1: a. Example of a question with wrong answer in TOEFL (the correct answer is cushion, ouranswer is scrape). b. Set of possible questions with the same question word and different correctanswers.
Table 2: State of the art results for TOEFL and ESL test setsBUninaria &Levy (2012) Osterlund et al. (2015)	100.0%	66.0%Jarmasz & SzPakoWicz (2012)	79.7%	82.0%LUetaL(2011)	97.5%	86.0%question word with a set of four candidate answers. It is worth pointing out, that the context givenby a set of possible answers often defines the question (a selection of a sense of a word appearing inthe question). Answering these tests does not require finding the most similar word out of the wholedictionary but only from multiple choice candidates; therefore TOEFL and ESL are less demandingthan SIMLEX-999. A question example in Table 1 highlights the problem. In the first question, allof possible answers are building materials. Wood should be rejected as there is more appropriateanswer. In second question, out of possible answers, only wood is a building material which makesit a good candidate for the correct answer. This is a basis for applying a differential analysis in thesimilarity measure. Table 2. illustrates state of the art results for both test sets. The TOEFL test setwas introduced in Landauer & Dumais (1997); the ESL test set was introduced in Turney (2001).
Table 3: Accuracy of various methods on TOEFL and ESL test sets. *cosRETRO+ is trained onall relations from PPDB(Equivalence, Exclusion, ForwardEntilement, ReverseEntilement, Other-Relation, Independent), while cosRETRO is trained on Equivalence from PPDB as synonyms andExclusion from PPDB with Antonyms from WordNet as antonyms).
