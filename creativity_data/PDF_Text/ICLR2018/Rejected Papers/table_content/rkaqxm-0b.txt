Table 1: Results for Short Questions: Performance of our model compared to baseline models onthe Short Questions test set. The LSTM (No KG) has accuracy close to chance, showing that thequestions lack trivial biases.Our model almost perfectly solves all questions showing its ability tolearn challenging semantic operators, and parse questions only using weak end-to-end supervision.
Table 2: Results for Complex Questions: All baseline models fail to generalize to questionsrequiring longer chains of reasoning than seen during training. Our model substantially outperformsthe baselines, showing its ability to perform complex multi-hop reasoning, and generalize from itstraining data. Analysis suggests that most errors from our model are due to assigning incorrectstructures, not mistakes by the composition modules.
