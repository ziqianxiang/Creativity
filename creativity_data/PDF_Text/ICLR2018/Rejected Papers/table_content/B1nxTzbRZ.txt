Table 1: Score of the models, and of the best baseline for each task (in F1). See Table 2 in Appendixfor full details. The absolute difference metric is measured only on the true positives of the model, sowe subtract the best baseline to each model score, because a high precision low recall score will havea weaker cost and baseline cost than a high recall model. Thus, as the baseline is different for eachmodel, to give an order of magnitude, we display the lowest (i.e. best of) the best baselines on theeponym line. These abs_diff numbers can only compare the models (who beat all the baselines asthey are all negatives). More negative is better than baseline. * We could not train a single model todo well on both the regression and classification heads, so we display results for op_b from a stridingmodel with slightly different weights on each head.
Table 2: Score of the models, and of the best baseline for each task (in F1). The absolute differencemetric is measured only on the true positives of the model, so we subtract the best baseline. Thus, thebaseline is different for each model, so we do not display it. More negative is better than baseline.
