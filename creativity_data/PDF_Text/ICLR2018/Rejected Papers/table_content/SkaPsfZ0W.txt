Table 1: Dataset used for experiments. For citation datasets, 20 training nodes per class are observed,with |VL| = 20 × CMethod		Citeseer	Cora	Pubmed	PPI(a)	ManiReg (Belkin et al., 2006b)	60.1	59.5	70.7	-(b)	SemiEmb (Weston et al., 2012)	59.6	59.0	71.1	-(c)	LP (Zhu et al., 2003)	45.3	68.0	63.0	-(d)	DeepWalk (Perozzi et al., 2014)	43.2	67.2	65.3	-(e)	ICA (Lu & Getoor, 2003)	69.1	75.1	73.9	-(f)	Planetoid (Yang et al., 2016)	64.7	75.7	77.2	-(g)	GCN (Kipf & Welling, 2017)	70.3	81.5	79.0	-(h)	SAGE-LSTM (Hamilton et al., 2017)	-	-	-	61.2(i)	SAGE (Hamilton et al., 2017)	-	-	-	60.0(j)	DCNN (our implementation)	71.1	81.3	79.3	44.0(k)	GCN (our implementation)	71.2	81.0	78.8	46.2(l)	SAGE (our implementation)	63.5	77.4	77.6	59.8(m)	N-GCN (OurS)	72.2	83.0	79.5	46.8(n)	N-SAGE (ours)	71.0	81.8	79.4	65.0Table 2: Node classification performance (% accuracy for the first three, citation datasets, and f1micro-averaged for multiclass PPI), using data splits of Yang et al. (2016); Kipf & Welling (2017)and Hamilton et al. (2017). We report the test accuracy corresponding to the run with the highest
Table 2: Node classification performance (% accuracy for the first three, citation datasets, and f1micro-averaged for multiclass PPI), using data splits of Yang et al. (2016); Kipf & Welling (2017)and Hamilton et al. (2017). We report the test accuracy corresponding to the run with the highestvalidation accuracy. Results in rows (a) through (g) are copied from Kipf & Welling (2017), rows(h) and (i) from (Hamilton et al., 2017), and (j) through (l) are generated using our code since we canrecover other algorithms as explained in Section 3.6. Rows (m) and (n) are our models. Entries with“-"indicate that authors from Whom We copied results did not run on those datasets. Nonetheless,we run all datasets using our implementation of the most-competitive baselines.
Table 3: Node classification accuracy (in %) for our largest dataset (Pubmed) as we vary size oftraining data |C| ∈ {5,10,20,100}. We report mean and standard deviations on 10 runs. Weuse a different random seed for every run (i.e. selecting different labeled nodes), but the same 10random seeds across models. Convolution-based methods (e.g. SAGE) work well with few trainingexamples, but unmodified random walk methods (e.g. DCNN) work well with more training data.
Table 4: N-GCNa results on Citeseer dataset, with A0 disabled. Top-left entry corresponds to vanillaGCN. Left column corresponds to ensemble of GCN models.
Table 5: N-GCNa results on Citeseer dataset, with A0 enabled.
Table 6: N-GCNfc results on Citeseer dataset, with A0 disabled. Left column corresponds to ensem-ble of GCN models.
Table 7: N-GCNfC results on Citeseer dataset, with A0 enabled.
Table 8: N-SAGEa results on Citeseer dataset, with A0 disabled. Top-left entry corresponds tovanilla SAGE. Left column corresponds to ensemble of SAGE models.
Table 10: N-SAGEfC results on Citeseer dataset, with A0 disabled. Left column corresponds toensemble of SAGE models.
Table 11: N-SAGEfC results on Citeseer dataset, with A0 enabled.
Table 12: N-GCNa results on Cora dataset, with A0 disabled. Top-left entry corresponds to vanillaGCN. Left column corresponds to ensemble of GCN models.
Table 13: N-GCNa results on Cora dataset, with A0 enabled.
Table 14: N-GCNfc results on Cora dataset, with A0 disabled. Left column corresponds to ensembleof GCN models.
Table 15: N-GCNfC results on Cora dataset, with A0 enabled.
Table 16: N-SAGEa results on Cora dataset, with A0 disabled. Top-left entry corresponds to vanillaSAGE. Left column corresponds to ensemble of SAGE models.
Table 18: N-SAGEfC results on Cora dataset, with A0 disabled. Left column corresponds to ensem-ble of SAGE models.
Table 19: N-SAGEfC results on Cora dataset, with A0 enabled.
Table 20: N-GCNa results on Pubmed dataset, with A0 disabled. Top-left entry corresponds tovanilla GCN. Left column corresponds to ensemble of GCN models.
Table 21:	N-GCNa results on PUbmed dataset, with A0 enabled.
Table 22:	N-GCNfc results on Pubmed dataset, with A0 disabled. Left column corresponds toensemble of GCN models.
Table 23: N-GCNfC results on Pubmed dataset, with A0 enabled.
Table 24: N-SAGEa results on Pubmed dataset, with A0 disabled. Top-left entry corresponds tovanilla SAGE. Left column corresponds to ensemble of SAGE models.
Table 25: N-SAGEa results on Pubmed dataset, with A0 enabled.
Table 26: N-SAGEfC results on Pubmed dataset, with A0 disabled. Left column corresponds toensemble of SAGE models.
Table 27: N-SAGEfC results on Pubmed dataset, with A0 enabled.
