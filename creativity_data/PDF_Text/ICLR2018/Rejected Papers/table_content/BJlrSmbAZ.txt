Table 1: Properties of the eight regression datasets used to evaluate MCBN. N is the dataset sizeand Q is the n.o. input features. Only one target feature was used. In cases where the raw datasetscontain more than one target feature, the feature used is specified by target feature.
Table 2: Uncertainty quality measured on eight datasets. MCBN, MCDO and MNF are comparedover 5 random 80-20 splits of the data with 5 different random seeds each split. Reported valuesare uncertainty metrics CRPS and PLL normalized to a lower bound of constant variance and upperbound that maximizes the metric. CRPS and PLL are expressed as a percentage, reflecting howclose the model is to the upper bound. We check to see if CRPS and PLL significantly exceed thebaseline using a one sample t-test (significance level indicated by *â€™s). Best performer versus theirbaseline for each dataset and metric is marked by bold. See text for further details.
Table 3: CRPS measured on eight datasets over 25 random 80-20 splits of the data. Mean valuesfor MCBN and MCDO are reported along with standard error. A significance test was performed tocheck if CRPS significantly exceeds the baseline. The p-value from a one sample t-test is reported.
Table 4: PLL measured on eight datasets over 25 random 80-20 splits of the data. Mean values forMCBN and MCDO are reported along with standard error. A significance test was performed tocheck if PLL significantly exceeds the baseline. The p-value from a one sample t-test is reported.
Table 5: CRPS and PLL measured on eight datasets over 25 random 80-20 splits of the data. Meanvalues and standard errors are reported for MCBN and MCDO. Marked in bold is the best performingmethod for each metric.
Table 6: RMSE measured on eight datasets over 25 random 80-20 splits of the data. Mean values andstandard errors are reported for MCBN and MCDO as well as conventional non-Bayesian modelsBN and DO. Marked in bold is the best performing method overall.
