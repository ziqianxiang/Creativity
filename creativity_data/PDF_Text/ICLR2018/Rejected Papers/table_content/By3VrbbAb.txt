Table 1: Character-level language model categorical-entropy for the LSTM on AOL search datasetTrain/test split	Train loss	Validation lossPrefix splitting	-1.5454	1.4342Time splitting	1.5566	1.4254the total of these optimizations further reduces the running time to 75ms. By further parallelizing theupdates via 8 OpenMP threads brings completion time down to 25 ms.
Table 2: The speedups from different optimizationsOptimization	Resulting runtimeNaive beam search implementation	>1secTree-based beam search	250msAdding MKL BLAS	75msOpenMP parallelization	25msCustom LSTM implementation	13.3msAdding prefix edit distnace	16.3 msStochastic search	40 msTable 3: Completion negative log likelihood for stochastic search vs. beam search (lower is better)Train/test split	Beam search	Stochastic SearchPrefix splitting Time splitting	2537 2.703	3.284 3.6055.2	Runtime evaluationAlthough we mentioned the timing results in the main text, we summarize the speedups achievedby the different optimizations in Table 2, which reports the time to give 16 suggestions for a prefix.
Table 3: Completion negative log likelihood for stochastic search vs. beam search (lower is better)Train/test split	Beam search	Stochastic SearchPrefix splitting Time splitting	2537 2.703	3.284 3.6055.2	Runtime evaluationAlthough we mentioned the timing results in the main text, we summarize the speedups achievedby the different optimizations in Table 2, which reports the time to give 16 suggestions for a prefix.
Table 4: Performance of our language model based methods versus trie-based prefix lookup.
