Table 1: Test error rates of FGSM and IFGSM attacks on an undefended convolutional neural net-work for MNIST. These attacks can cause perfect misclassification for the given range of η.
Table 2: Error rates of FGSM and IFGSM attacks on adversarially-trained classifiers for MNIST.
Table 3: Error rates of different attacks on various adversarially-trained classifiers for MNIST.
Table 4: Error rates of FGSM vs learning-based attack network (AttNet) on various adversarially-trained classifiers for MNIST. FGSM-curr/AttNet-curr means they are computed/trained for the spe-cific classifier on the leftmost column. Note that FGSM fails to attack hardened networks (AdvFGSM80 and Sens FGSM), whereas AttNet can still attack them successfully.
Table 5: Error rates of Minimax-, Alt-, and adversarially-trained (Sens FGSM) classifiers forMNIST. Minimax is overall better than Alt against AttNet-curr, and is also moderately robust againstthe out-of-class attack (FGSM-curr).
Table 6: Error rates of FGSM and IFGSM attacks on the original classifier for cifar10. These attackscan cause large misclassification for the given range of η .
Table 7: Error rates of FGSM and IFGSM attacks on the adversarially-trained classifiers for CIFAR-10. This defense can significantly lower the errors from the attacks, although not as low as theMNIST problem.
Table 8: Error rates of different attacks on various adversarially-trained classifiers for CIFAR-10.
Table 9: Error rates of FGSM vs learning-based attack network (AttNet) on various adversarially-trained classifiers for CIFAR-10. FGSM-curr/AttNet-curr means they are computed/trained for thespecific classifier on the leftmost column. Note that FGSM fails to attack against the ‘hardened’networks (Adv FGSM80 and Sens FGSM), but AttNet can still attack them successfully.
Table 10: Error rates of Minimax-, Alt-, and adversarially-trained (Sens FGSM) classifiers forMNIST. While Minimax and Alt are both vulnerable to AttNet attacks, Minimax is much less vul-nerable than Alt at η = 0.2.
