Table 1: Iteration Required for Every TaskFigure 1: ReacherValue function. The value function Vπ can be conveniently fitted off-policy. Different from DDPG,the gradient estimator for Vπ is fitted using importance sampling, thus the objective is consistent.
