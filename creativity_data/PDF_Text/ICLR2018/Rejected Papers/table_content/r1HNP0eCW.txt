Table 1: Example of similarity relationship for Japanese words (translated)Toyota			Sony	TOP	word	Similarity	word	Similarity1	Honda	0.612	PlayStation	0.6122	Toyota corp	0.546	Entertainment	0.5463	Hyundai corp	0.536	SonyBigChance	0.5364	Chrysler	0.524	Game console	0.5245	Nissan	0.519	Nexus	0.5196	motor	0.511	X-BOX	0.5117	LEXUS	0.506	spring	0.5068	ACura	0.493	Windows	0.4939	Mazda	0.492	Compatibility	0.49210	Ford	0.486	application software	0.486Thomson Reuters news 4 is a worldwide news agency providing worldwide news in multiple lan-guages. Most of the reports are originally written in English and translated and edited into other2Google Translation Web API could be accessed from https://github.com/aditya1503/Siamese-LSTM3The open source code for Siamese LSTM can be accessed from https://github.com/aditya1503/Siamese-LSTM4Official websites of Thomson Reuters: http://www.reuters.com/5
Table 2: Example of similarity relationship for English wordslexus			Ienovo	TOP	word	Similarity	word	Similarity	acura	-0.636-	huawei	-0.636-2	corolla	0.588	Zte	0.5883	Camry	0.571	xiaomi	0.5714	2002-2005	0.570	dell	0.5705	Sentra	0.541	handset	0.5416	PriUs	0.539	smartphone	0.5397	2003-2005	0.537	hannstar	0.5378	sedan	0.533	thinkpad	0.5339	mazda	0.530	tcl	0.53010	altima	0.524	medison	0.524As discussed in the section 2.1, the word2vec could build relationships among words based on theiroriginal context. We could find several most similar words when given a query word by calculatingtheir cosine similarity. The table 2 and 1 demonstrate examples to find the most similar wordswhen given a word query in English and in Japanese respectively. All these results suggest theeffectiveness of word2vec algorithms and successful of the training processes.
Table 3: Summary of in terms of TOP-N benchmarkTOP-10						SHORT				LONG		method	TEST-IS	TEST-2S	TEST-1L	TEST-1LLSTM		4995	^456	T32baseline	243		-	302		-TOP-5						SHORT				LONG		method	TEST-1S	TEST-2S	TEST-1L	TEST-1LLSTM	^39	138	^284	^278baseline	134		-	192		-TOP-1						SHORT				LONG		method	TEST-1S	TEST-2S	TEST-1L	TEST-1LLSTM	^0	106	^61	^58baseline	39		-	50		-is twice of the baseline. When the baseline method calculating the similarity of two sentences,no matter whether there are different types of word arrangement for the two input, or there aredifferent words used referring to the same meaning, which proves the effectiveness of encoding (i.e.
