Table 1: MNIST. Previously reported test accuracies followed by semantic loss results (± stddev)Accuracy % with # of used labels	100	1000	ALLAtlaSRBF (PiteliS et al., 2014)	91.9(± 0.95)	96.32 (± 0.12)	-98.69Deep Generative (Kingma et al., 2014)	96.67(± 0.14)	97.60(± 0.02)	99.04Virtual Adversarial (Miyato et al., 2016)	97.67	98.64	99.36Ladder Net (Rasmus et al., 2015)	98.94 (±0.37)	99.16 (±0.08)	99.43 (± 0.02)Baseline: MLP, Gaussian Noise	78.46 (±1.94T=	94.26 (±0.31)=	99.34 (±0.08F=Baseline: Self-Training	72.55 (±4.21)	87.43 (±3.07 )	99.34 (±0.08)MLP with Semantic Loss (our)	98.38 (±0.51)	98.78 (±0.17)	99.36 (±0.02)4.1	MethodOur proposed method intends to be generally applicable and compatible with any feedforward neuralnetwork. The semantic loss is simply another regularization term that can directly be plugged intoan existing loss function. More specifically, for some weight w, the new overall loss becomesexisting loss + W ∙ semantic loss.
Table 2: FASHION. Test accuracy comparison between MLP with semantic loss and ladder nets.
Table 3: CIFAR. Test accuracy comparison between CNN with semantic loss and ladder nets.
Table 4: Grid shortest path test results: coherent, incoherent and constraint accuracy.
Table 5: Preference prediction test results: coherent, incoherent and constraint accuracy.
Table 6: Specifications of CNNs in Ladder Net and our proposed method.
