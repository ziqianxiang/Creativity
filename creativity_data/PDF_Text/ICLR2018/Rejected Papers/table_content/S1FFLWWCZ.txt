Table 1: Environment output conditioned on action at (all the possible environment output afteraction at in state st)We created a novel Gym (Brockman et al., 2016) environment from the dataset by simulating anenvironment with classification and navigation actions with multiple possible configurations. Whenan agent in state st takes an action at , the environment would read in the next logical image andreturn the appropriate outputs. The environment outputs a state, reward, and terminal boolean whichcan be varied depending on the predetermined parameters of the environment, as shown in Table 1.
Table 2: Comparison with other object classification tasks on ModelNet40 with different types ofinput. Image(s) means the image(s) of the 3D model vs. the full 3D model. Pose is the angle of theobjectâ€™s view. Depth is the depth images of the object.
Table 3: The number of views encountered i.e. number of steps taken with the number of objectscorrectly and wrongly classifiedanother baseline and fair comparison to our method, we trained the same method on the ModelNetenvironment, but the agent was not allowed to take any movement actions. The baseline methodachieved 64.3% accuracy. As seen in Table 2, our method increased in 17.1% accuracy compared tonaive classification network.
