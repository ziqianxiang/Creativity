Table 1: Comparison of attention architectures of competing approaches: BIDAF (Seo et al., 2017),RNET (Wang et al., 2017), MReader (Hu et al., 2017), and PhaseCond (our proposed model).
Table 2: Performance comparison of single models on the development set. Each setting containsfive runs trained consecutively. Standard deviations across five runs are shown in the parenthesis forsingle models. Daggers indicate the level of significance.
Table 3: The performance of our models and published results of competing attention-based archi-tectures. To perform a fair comparison as much as possible, we collect the results of BiDAF (Seoet al., 2017) and RNET (Wang et al., 2017) from their recently published papers instead of using theup-to-date performance scores posted on the SQuAD Leaderboard. Our directly available baselineis one implementation of MReader, re-named as Iterative Aligner which has very similar results asthose of MReader (Hu et al., 2017) posted on the SQuAD Leaderboard on Jul 14, 2017.
Table 4: Varying number of question-passage attention layers and self-attention layers. We set layernumber in PhaseCond for question-passage attention model (denoted as QPAtt) and self-attentionmodel (denoted as SelfAtt) respectively. L1 means a single layer and L2 means two stacking layers.
