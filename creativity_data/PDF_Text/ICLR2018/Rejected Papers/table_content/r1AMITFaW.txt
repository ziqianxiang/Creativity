Table 1:	Comparison of Parameter Numbers.
Table 2:	Network and training detailsInPUt/output sequence fixed lengthNumber of RNN layersEmbedding layer vector sizeNumber of RNN cellsBatch sizeTraining stepsLearning rateTraining optimizerMaximum gradient norm100/1001512512201400000.5AdaGrad(Duchi, 2011)5The input is first fed into a trainable embedding layer (Bengio et al., 2003) before it is sent to the
Table 3: POS tagging test accuracy, It = Xt (%)	LSTM	ELSTM-I	ELSTM-IIBASIC RNN	85.38	85.30	84.35BRNN (Schuster & Paliwal, 1997)	88.49	82.84	79.14Seq2seq (Sutskever et al., 2014)	25.83	24.87	31.43Seq2seq with Attention (Vinyals et al., 2015)	27.97	78.98	42.05DBRNN Combined	89.16	83.69	81.08DBRNN Forward	88.93	83.54	81.08Table 4: POS tagging test accuracy, ItT = [XtT , htT-1] (%)	LSTM	GRU	ELSTM-I	ELSTM-IIBASIC RNN	86.98	87.09	85.57	85.56BRNN	88.94	89.26	83.48	82.57Seq2seq	24.73	33.79	34.09	52.96Seq2seq with Attention	34.10	73.65	80.90	54.53DBRNN Combined	89.67	89.74	84.25	84.41DBRNN Forward	89.46	89.53	84.05	84.44The results of the DP problem with It = Xt and ItT = [XtT, htT-1] are shown in Tables 5 and 6,respectively. The ELSTM-I and ELSTM-II cells perform better than the LSTM and the GRU cells.
Table 4: POS tagging test accuracy, ItT = [XtT , htT-1] (%)	LSTM	GRU	ELSTM-I	ELSTM-IIBASIC RNN	86.98	87.09	85.57	85.56BRNN	88.94	89.26	83.48	82.57Seq2seq	24.73	33.79	34.09	52.96Seq2seq with Attention	34.10	73.65	80.90	54.53DBRNN Combined	89.67	89.74	84.25	84.41DBRNN Forward	89.46	89.53	84.05	84.44The results of the DP problem with It = Xt and ItT = [XtT, htT-1] are shown in Tables 5 and 6,respectively. The ELSTM-I and ELSTM-II cells perform better than the LSTM and the GRU cells.
Table 5: DP test accuracy, It = Xt (%)	LSTM	ELSTM-I	ELSTM-IIBASIC RNN	15:14	38.36	42.52BRNN	14.74	39.24	35.78Seq2seq	24.37	30.04	35.67Seq2seq with Attention	21.56	60.19	45.15DBRNN Combined	25.26	54.39	53.80DBRNN Forward	25.71	53.67	52.61Table 6: DP test accuracy, ItT = [XtT , htT-1] (%)	LSTM	GRU	ELSTM-I	ELSTM-IIBASIC RNN	44.12	47.49	54.52	56.02BRNN	32.46	27.83	54.14	47.72Seq2seq	27.67	29.94	40.85	48.73Seq2seq with Attention	31.47	53.70	66.72	51.24DBRNN Combined	56.89	51.32	60.30	58.28DBRNN Forward	58.30	53.17	59.81	58.05Bi-attention (Cheng et al., 2016) 1		61.29		We see from Tables 3 - 6 that the two DBRNN models outperform both BRNN and sequence-to-sequence (without attention) in both POS tagging and DP problems regardless of used cells. Thisshows the superiority of introducing the expert opinion pooling from both the input and the predicted
Table 6: DP test accuracy, ItT = [XtT , htT-1] (%)	LSTM	GRU	ELSTM-I	ELSTM-IIBASIC RNN	44.12	47.49	54.52	56.02BRNN	32.46	27.83	54.14	47.72Seq2seq	27.67	29.94	40.85	48.73Seq2seq with Attention	31.47	53.70	66.72	51.24DBRNN Combined	56.89	51.32	60.30	58.28DBRNN Forward	58.30	53.17	59.81	58.05Bi-attention (Cheng et al., 2016) 1		61.29		We see from Tables 3 - 6 that the two DBRNN models outperform both BRNN and sequence-to-sequence (without attention) in both POS tagging and DP problems regardless of used cells. Thisshows the superiority of introducing the expert opinion pooling from both the input and the predictedoutput.
