Table 1: Description of the DatasetsTrue Labels“airlines andairplanes”,“hijacking”,“terrorism”“armament,defense andmilitaryforces”, “civilwar andguerrillawarfare”,“politics andgovernment”LEML“airlines and airplanes”(0.34),“terrorism” (0.30), “united statesinternational relations” (0.27), “elections”(0.22), “armament, defense and military
Table 2: Examples of label prediction from the NYTimes dataset. The numbers in parenthesis arethe scores for the top 10 labels. The scores of LEML and MoM have different ranges.
Table 3: Training TimeWe computed AUC for every test documents and performed a macro-averaging across the docu-ments, and repeated the experiments for K = {50,75,100,125,150} (Figure 2). Both LEML andMethod of Moments perform very similarly, but the memory footprint of MoM is significantly lessthan LEML. MoM takes longer to finish for the small datasets since tensor factorisation takes muchmore time compared to the LEML iterations. However, as the size of the datasets grows, the LEMLiterations become more and more costly. For the medium and large datasets, MoM takes a fractionof the time taken by LEML. For WikiLSHTC, LEML takes more than two days to finish, whileMoM finishes within a few hours. The training times of LEML and MoM for different datasets arelisted in Table 3.
