Table 1: Architecture of the baseline generator. Mg = 4 for CIFAR-10 and Mg = 6 for STL-10.
Table 2: Architecture of AdaGAN. Mg = 4 for CIFAR-10 and Mg = 6 for STL-10. Kadaptive foreach AdaConvBlock are not specified.
Table 3: Unsupervised Inception scores on CIFAR-10 of the baseline generator versus our architec-tures.
Table 4: Unsupervised Inception scores on CIFAR-10 and STL-10Method	CIFAR-10	STL-10Real Data (Warde-FarIey & Bengio, 2016)	11.24 ± OB	26.08 ± 0.2FDFM (Warde-Farley & Bengio, 2016)	7.72 ± 0.13	8.51 ± 0.13Spectral Norm GAN Miyato et al. (2017)	7.42 ± 0.08	8.69 ± 0.09Splitting GAN ResNet-A Grinblat et al. (2017)	7.90 ± 0.09	9.50 ± 0.13AdaGAN-3x3	7.96 ± 0.08	9.19 ± 0.08AdaGAN-5x5	8.06 ± 0.12	9.67 ± 0.10AdaGAN-7x7		9.89 ± 0.205.4	STL-10For STL-10 experiments, we train on the unlabeled set and downsample the images from 96 × 96 to48 × 48, following Warde-Farley & Bengio (2016). As STL-10 has bigger image size than CIFAR-10, a larger Kadaptive maybe helpful. Thus, we train an AdaGAN-7x7 model on this dataset aswell. Our architectures converge much slower on STL-10 therefore we train our models for 400000iterations. The two AdaGAN-5x5 and AdaGAN-7x7 models achieve state-of-the-art performancewhile the AdaGAN-3x3 model is just behind the work of Grinblat et al. (2017). Table 4, thirdcolumn, shows the unsupervised Inception scores of our models against other methods. Figure 4, 5and 6 in appendix A show the samples generated by our models.
