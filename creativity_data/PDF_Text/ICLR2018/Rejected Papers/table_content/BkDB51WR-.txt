Table 1: NRMSE of the mean and standard deviation of the next-step prediction. The DE-RNN re- sults are compared with the first-order autoregressive model (AR), Kalman filter (KF), and Gaussian process (GP).							CE	RCE	CCE	AR(1)	KF	GPeμ	0.238	0.0549	0.149	0.029	0.029	0.831eσ	0.066	0.017	0.038	0.228	0.228	0.095The experiments are performed for two different bin sizes, dy = 0.08 and 0.04. The DE-RNN has64 LSTM cells. Figure 1 shows the errors in the expectation and the standard deviation with respectto the analytical solution;Ey~pτ [yt+ι |yt ] = yt eχp(-0.5δt),	Sdy 〜PT[yt+1 |yt ] = √(0.5+ ∣yt∣)δt.	(22)Here, pT denotes the true distribution of the CIR process. The normalized root mean-square errors(NRMSE) are defined ash(Ey~PL [yt+1 |yt] - Ey〜PT [yt+1|yt])2i1/2h(yt- Ey 〜PT [yt+1 |yt])2 i1/2h(sdy~Pl [yt+ι|yt] - Sdy〜PT[yt+1|yt])2i1/2sd[y](24)in which〈•〉denotes an average over the testing data, PL is the distribution from the LSTM, andSd[y] denotes the standard deviation of the data. The error in the expectation is normalized againsta zeroth-order prediction, which assumes yt+1 = yt .
Table 2: NRMSEs of the Mackey-Galss time series. DE-RNN results are compared with autoregres-SiVe integrated moving average (ARIMA), Kalman filter (KF), and GauSSian process (GP) models.
Table 3: l∞ error for RCE, CCE and regression LSTM in ° C.
Table 4: Normalized errors of the Lorenz time series. DE-RNN results are compared with vectorautoregressive (VAR) and Gaussian process (GP) models.
