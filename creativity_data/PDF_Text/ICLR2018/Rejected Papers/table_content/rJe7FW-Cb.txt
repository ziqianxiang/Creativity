Table 1: Performance of WRN and our approach (WRA) on the Adience benchmark for Age, Gender(Gend); CUB200-2011 (Birds); Stanford cars (Cars); Stanford dogs (Dogs); and UEC Food-100(Food). The absolute accuracy improvement (in %) is marked as ∆. Bold performance indicatesoutperforming the state of the art. The augmented network consistently outperforms the baseline upto a relative 18% relative error decrease on Cars.
Table 2: Comparison of Attention models in the Computer Vision Literature. Single Stream: inputdata is fed through a single CNN tower. Single pass: train and inference outputs are obtained ina single pass trough the model. SGD Trainable: the model can be trained end-to-end with SGD.
Table 3: Average performance impact across datasets on (in accuracy %) of the attention depth(AD), attention width (AW), and the presence of gates (G) on WRN.
Table 4: Performance on the adience dataset. DSP indicates Domain-Specific Pre-training, i.e. pre-training on millions of faces.
Table 5: Performance on Caltech-UCSD Birds 200. High Res. indicates whether training is per-formed with images with resolution higher than 224 × 224.
Table 6: Performance on Stanford Cars. High res. indicates that resolutions higher than 256 × 256are used.
Table 7: Performance on Stanford Dogs. High res. indicates that resolutions higher than 256 × 256are used.
Table 8: Performance on UEC Food-100.
