Table 1:	Recognition error rates on MNIST task of state-of-the-art systemsMethodError rateWan et al. (2013)	0.21%Ciregan et al. (2012)	0.23%Sato et al. (2015)	0.23%Chang & Chen (2015)	0.24%2.2 FASHIONMNISTXiao et al. (2017) presents the FashionMNIST dataset. It consists of images from the assortmenton Zalandos website. As given out by name, the configuration of the FashionMNIST dataset com-pletely parallels the configuration of the MNIST dataset. FashionMNIST consists of a training setof 60,000 images and a test set of 10,000 images. Each image is a 28 × 28 grayscale image as-sociated with a label from 10 classes. FashionMNIST poses a more challenging classification taskthan the MNIST digits data. A leaderboard for FashionMNIST has been created and maintained athttps://github.com/zalandoresearch/fashion-mnist.
Table 2:	Image examples of MNIST-like datasetsMNIST	FashionMNIST NotMNISTclass example class example class example0123456789QUΞ目Q9B蕊0HT-Shirt/TopTrouserPulloverDressCoatSandals
Table 3: Image recognition accuracy rates for MNIST tasks with multi-task learningdataset single-task F+N M+F M+N F+N+MMNIST	99.56%	-	99.71%	99.70%	99.70%NotMNIST	97.22%	97.38%	-	97.40%	97.46%FashionMNIST	94.32%	95.20%	95.18%	-	95.25%different classes. The bi-task learning systems are always better than the single-task systems. Fur-thermore, the tri-task learning systems are the best, except for the MNIST (0.01% difference). Therelative reduction in error rates by tri-task learning are respectively 31.8% for MNIST (99.56%to 99.70%), 16.4% for FashionMNIST (94.32% to 95.25%), and 8.6% for NotMNIST (97.22% to97.46%). The results confirm that multi-task learning is able to learn representation which is univer-sal and robust to different tasks.
