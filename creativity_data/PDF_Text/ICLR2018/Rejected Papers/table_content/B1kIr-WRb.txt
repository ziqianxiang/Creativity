Table 1: Best tensor factorization hyperparameter values found(Hyperparam)	Tensor value shift	Negative sample percentCP-S	-39	025JCP-S (second order)	0	0.15JCP-S (third order)	-3.9		015	slower than the training of order-2 equivalents such as SGNS. Explicitly, our GPU trained CBOWvectors (using the experimental settings found below) in 3568 seconds, whereas training CP-S andJCP-S took 6786 and 8686 seconds respectively.
Table 2: Outlier Detection scores across all embeddings(Method)	OD2 OPP	OD2 acc	OD3 OPP	OD3 accRandom	-0.5828-	0.2504	-05076-	0.1823SGNS	0.6219	0.3483	0.6109	0.32CBOW	0.6012	0.3178	0.6014	0.3014NNSE	0.6603	0.3467	0.5486	0.2214GloVe	0.6550	0.3500	0.5990	0.2456CP-S	0.6671	0.3628	0.6738	0.3358JCP-S	0.7069	0.4181	06606	0.3247Outlier Detection results. The results are shown in Table 2. As we can see, the tensor factorizationbased methods outperform the other non-tensor based baselines for all the formulations of this task.
Table 3: Supervised sentiment analysis scores across all embeddings(Method)	10% training data	30% training data	50% training data	100% training dataRandom	0.6999	0.7254	0.7311	0.7337SGNS	0.7348	0.7590	0.7643	0.7696CBOW	0.7322	0.7537	0.7591	0.7644NNSE	0.7233	0.7476	0.7531	0.7572GloVe	0.7310	0.7564	0.7622	0.7670CP-S	0.7214	0.7454	0.7514	0.7575JCP-S	0.7460	0.7681	0.7732	0.7774Sentiment analysis results. The results are shown in Table 3. In this task, JCP-S is the dominantmethod across all levels of training data, further showing that exploiting both second and third orderco-occurrence data leads to higher quality semantic information being encoded in the embedding.
Table 4: Word Similarity Scores (Spearman’s ρ)(Method)	MEN	MTurk	RW	SimLex999Random	0.04147	-0.0382	-0.0117	-00053-SGNS	0.5909	0.5342	0.3704	0.2264CBOW	0.5537	0.4225	0.3444	0.2727NNSE	0.5055	0.5068	0.1993	0.1263GloVe	0.4914	0.4733	0.1750	0.1403CP-S	0.4723	0.4738	0.0875	0.0399JCP-S	0.6158	0.5343	0.3546	0.2272We show the word similarity results in Table 4. As we can see, our embeddings perform competi-tively with the state-of-the-art at these tasks. It is worth including these results as the word similaritytask is a very common way of evaluating embedding quality in the literature. However, due to themany intrinsic problems with evaluating word embeddings using word similarity (Faruqui et al.
Table 5: Nearest neighbors (in cosine similarity) to elementwise products of word vectorsComposition	Nearest neighbors (CP-S)	Nearest neighbors (JCP-S)	Nearest neighbors (CBOW)star * actor	oscar, award-winning, supporting	roles, drama, musical	DNA, younger, tipstar + actor	stars, movie, actress	actress, trek, picture	actress, comedian, starredstar * planet	planets, constellation, trek	galaxy, earth, minor	fingers, layer, armstar + planet	sun, earth, galaxy	galaxy, dwarf, constellation	galaxy, planets, earthtank * fuel	liquid, injection, tanks	vehicles, motors, vehicle	armored, tanks, armouredtank + fuel	tanks, engines, injection	vehicles, tanks, powered	tanks, engine, dieseltank * weapon	gun, ammunition, tanks	brigade, cavalry, battalion	persian, age, rapidtank + weapon	tanks, armor, rifle	tanks, battery, batteries	tanks, cannon, armoredTo motivate why this works, recall that the values in a third order PPMI tensor M are given by:Rmijk = PPMI(wi, wj , wk) ≈	virvjrvkr = hVi * Vj , Vki,r=1where Vi is the word vector for wi. If words wi, wj , wk have a high PPMI, then hVi * Vj , Vki willalso be high, meaning Vi * Vj will be close to Vk in the vector space by cosine similarity.
