Figure 1: Both VAE and WAE minimize two terms: the reconstruction cost and the regularizer penal-izing discrepancy between PZ and distribution induced by the encoder Q. VAE forces Q(Z|X = x)to match PZ for all the different input examples x drawn from PX . This is illustrated on picture(a), where every single red ball is forced to match PZ depicted as the white shape. Red balls startintersecting, which leads to problems with reconstruction. In contrast, WAE forces the continuousmixture QZ := Q(Z|X)dPX to match PZ, as depicted with the green ball in picture (b). As aresult latent codes of different examples get a chance to stay far away from each other, promoting abetter reconstruction.
Figure 2: VAE (left column), WAE-MMD (middle column), and WAE-GAN (right column) trainedon MNIST dataset. In “test reconstructions” odd rows correspond to the real test points.
