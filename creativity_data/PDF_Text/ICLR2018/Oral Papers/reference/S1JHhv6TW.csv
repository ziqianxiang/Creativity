title,year,conference
 Deep simnets,2016, IEEE Conference on Computer Vision andPattern Recognition (CVPR)
 Boosting dilated convolutional networks with mixed tensordecompositions,2017, arXiv preprint arXiv:1703
 Deep residual learning for image recognition,2015, arXivpreprint arXiv:1512
 Densely connected convolutionalnetworks,2016, arXiv preprint arXiv:1608
 Deep networks with stochasticdepth,2016, In European Conference on Computer Vision
 Caffe: Convolutional architecture for fast feature embedding,2014, In Proceedings ofthe 22nd ACM international conference on Multimedia
 Neural machine translation in linear time,2016, arXiv preprint arXiv:1610
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 ImageNet Classification with Deep ConvolutionalNeural Networks,2012, Advances in Neural Information Processing Systems
 Deep learning,2015, Nature
 Learning real and boolean functions: When is deepbetter than shallow,2016, arXiv preprint arXiv:1603
 On the number of linear regions ofdeep neural networks,2014, In Advances in Neural Information Processing Systems
 On the number of inference regions of deep feedforward networks with piece-wise linear activations,2013, arXiv preprint arXiv
 I-theory on depth vs width: hierarchical functioncomposition,2015, Technical report
 Exponential ex-pressivity in deep neural networks through transient chaos,2016, In Advances In Neural Information ProcessingSystems
 Training input-output recurrent neural networks through spectral meth-ods,2016, arXiv preprint arXiv:1603
 Tensorial mixture models,2016, arXiv preprintarXiv:1610
 Going Deeper with Convolutions,2015, CVPR
 Representation benefits of deep feedforward networks,2015, arXiv preprint arXiv:1509
