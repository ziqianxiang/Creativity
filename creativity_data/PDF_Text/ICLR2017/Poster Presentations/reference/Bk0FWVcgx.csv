title,year,conference
 Convex relaxations of structured matrix factorizations,2013, arXiv preprintarXiv:1309
 Theloss surfaces of multilayer networks,2015, In Proc
 Identifying and attacking the saddle point problem in high-dimensional non-convex op-timization,2014, In Advances in Neural Information Processing Systems
 Compressed sensing,2006, IEEE Transactions on information theory
 Recovery of sparse translation-invariant signals with continuous basis pursuit,2011, IEEE transactions on signal processing
 Qualitatively characterizing neural networkoptimization problems,2014, arXiv preprint arXiv:1412
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, arXiv preprint arXiv:1502
 Deep learning without poor local minima,2016, arXiv preprint arXiv:1605
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Gradient descent convergesto minimizers,2016, University of California
 Explorations on high dimen-sional landscapes,2014, arXiv preprint arXiv:1412
 Exact solutions to the nonlinear dynam-ics of learning in deep linear neural networks,2013, arXiv preprint arXiv:1312
 Distribution-specific hardness of learning neural networks,2016, arXiv:1609
 No bad local minima: Data independent training error guaranteesfor multilayer neural networks,2016, arXiv preprint arXiv:1605
 Local minima in training ofneural networks,2016, arXiv preprint arXiv:1611
 Compressed sensingoff the grid,2013, IEEE Transactions on Information Theory
 Symmetry-breaking convergence analysis of certain two-layered neural networkswith relu nonlinearity,2017, ICLR Workshop 2017
 Introduction to the non-asymptotic analysis of random matrices,2010, arXiv preprintarXiv:1011
