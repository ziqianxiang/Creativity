title,year,conference
 Layer normalization,2016, arXiv:1607
 Neural machine translation by jointly learning to align andtranslate,2015, ICLR
 Learning long-term dependencies with gradient descent isdifficult,1994, Neural Networks
 Hierarchical multiscale recurrent neural net-works,2016, arXiv:1609
 Generating sequences with recurrent neural networks,2013, arXiv:1308
 Untersuchungen zu dynamischen neuronalen netzen,1991, Master’s thesis
 Long short-term memory,1997, Neural computation
 Adam: A method for stochastic optimization,2014, arXiv:1412
 Regularizing rnns by stabilizing activations,2016, ICLR
 Zoneout:Regularizing rnns by randomly preserving hidden activations,2016, arXiv:1606
 Batch normalized recurrent neuralnetworks,2016, ICASSP
 A simple way to initialize recurrent networks of rectified linearunits,2015, arXiv:1504
 Large text compression benchmark,2009, 2009
 Building a large annotated corpus of english:The penn treebank,1993, Comput
 Learning recurrent neural networks with hessian-free optimization,2011, InICML
 Subword languagemodeling with neural networks,2012, preprint
 Persistent contextual neural networks for learning symbolic data sequences,2013, CoRR
 On the difficulty of training recurrent neuralnetworks,2012, arXiv:1211
 Lecture 6,2012,5—RmsProp: Divide the gradient by a running average of itsrecent magnitude
 Describing videos byexploiting temporal structure,2015, In ICCV
 Architecturalcomplexity measures of recurrent neural networks,2016, arXiv:1602
