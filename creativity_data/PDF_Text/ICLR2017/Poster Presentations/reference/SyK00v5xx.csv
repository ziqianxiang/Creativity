title,year,conference
 A latent variablemodel approach to PMI-based word embeddings,2016, Transaction of Association for ComputationalLinguistics
 A comparison of vector-based representations for semanticcomposition,2012, In Proceedings of the 2012 Joint Conference on Empirical Methods in NaturalLanguage Processing and Computational Natural Language Learning
 A large anno-tated corpus for learning natural language inference,2015, In Proceedings of the 2015 Conference onEmpirical Methods in Natural Language Processing (EMNLP)
 A unified architecture for natural language processing: Deepneural networks with multitask learning,2008, In Proceedings of the 25th International Conference onMachine Learning
 Word embeddings as metricrecovery in semantic spaces,2016, Transactions of the Association for Computational Linguistics
 Long short-term memory,1997, Neural computation
 Skip-thought vectors,2015, In Advances in neural information processingsystems
 Distributed repre-sentations of words and phrases and their compositionality,2013, In Advances in Neural InformationProcessing Systems
 Linguistic regularities in continuous spaceword representations,2013, In Proceedings of the Conference of the North American Chapter of theAssociation for Computational Linguistics: Human Language Technologies
 Vector-based models of semantic composition,2008, In Association forComputational Linguistics
 Composition in distributional models of semantics,2010, Cognitivescience
 Ppdb 2,2015,0: Better paraphrase ranking
 Glove: Global vectors for wordrepresentation,2014, Proceedings of the Empiricial Methods in Natural Language Processing
 Dy-namic pooling and unfolding recursive autoencoders for paraphrase detection,2011, In Advances inNeural Information Processing Systems
 Recursive deep models for semantic compositionality over a sentimenttreebank,2013, In Proceedings of the conference on empirical methods in natural language processing(EMNLP)
 Improved semantic representationsfrom tree-structured long short-term memory networks,2015, arXiv preprint arXiv:1503
 Cse: Conceptualsentence embeddings based on attention model,2016, In Proceedings of the 54th Annual Meeting of theAssociation for Computational Linguistics (Volume 1: Long Papers)
 Towards universal paraphrasticsentence embeddings,2016, In International Conference on Learning Representations
 Predicting response to political blog posts withtopic models,2009, In Proceedings of Human Language Technologies: The 2009 Annual Conferenceof the North American Chapter of the Association for Computational Linguistics
