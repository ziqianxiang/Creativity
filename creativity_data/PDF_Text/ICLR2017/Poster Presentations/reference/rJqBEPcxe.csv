title,year,conference
 Layer normalization,2016, CoRR
 Learning with pseudo-ensembles,2014, In Advancesin Neural Information Processing Systems
 Learning long-term dependencies with gradientdescent is difficult,1994, Neural Networks
 Estimating or propagating gradientsthrough stochastic neurons for conditional computation,2013, CoRR
 Recurrentbatch normalization,2016, arXiv preprint arXiv:1603
 Learning to forget: Continual predictionwith LSTM,2000, Neural Computation
 Deep residual learning for imagerecognition,2015, arXiv preprint arXiv:1512
 Untersuchungen zu dynamischen neuronalen netzen,1991, Masterâ€™s thesis
 Long short-term memory,1997, Neural computation
 Deep networks withstochastic depth,2016, arXiv preprint arXiv:1603
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 A clockwork rnn,2014, arXivpreprint arXiv:1402
 Regularizing rnns by stabilizing activations,2015, arXiv preprintarXiv:1511
 A simple way to initialize recurrent networks ofrectified linear units,2015, arXiv preprint arXiv:1504
 Building a large annotatedcorpus of english: ThePenntreebank,1993, Computational linguistics
 Rnndrop: A novel dropout for rnns inasr,2015, Automatic Speech Recognition and Understanding (ASRU)
 Surprisal-driven zoneout,2016, CoRR
 Blocks and fuel: Frameworks for deep learning,2015, CoRR
 Fast dropout training,2013, In Proceedings of the 30th InternationalConference on Machine Learning
 Recurrent neural network regularization,2014, arXivpreprint arXiv:1409
