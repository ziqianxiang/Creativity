title,year,conference
 Theano: new features and speed improvements,2012, Deep Learning andUnsupervised Feature Learning NIPS 2012 Workshop
 Model compression,2006, In KDD
 Approximation by superpositions of a sigmoidal function,1989, Mathematics of Control
 Big neural networks waste capacity,2013, arXiv:1301
 Understanding deep architectures using a recursiveconvolutional network,2014, In ICLR (workshop track)
 Scheduled denoising autoencoders,2015, In ICLR
 Blending LSTMs into CNNs,2015, arXiv:1511
 Distilling the knowledge in a neural network,2015, arXiv:1503
 Learning small-size dnn with output-distribution-basedcriteria,2014, In INTERSPEECH
 Zero-bias autoencoders and the benefits of co-adaptingfeatures,2015, In ICLR
 Actor-mimic: Deep multitask and transfer reinforce-ment learning,2016, In ICLR
 Regularizing neuralnetworks by penalizing output distributions,2017, ICLR
 Policy distillation,2016, In ICLR
 Conversational speech transcription using context-dependent deep neuralnetworks,2011, In INTERSPEECH
 Practical bayesian optimization of machine learningalgorithms,2012, NIPS
 Scalable bayesian optimization using deep neural networks,2015, In ICML
 Training very deep networks,2015, In NIPS
 80 million tiny images: A large data set fornonparametric object and scene recognition,2008, TPAMI
 Understanding deep learningrequires rethinking generalization,2016, arXiv preprint arXiv:1611
