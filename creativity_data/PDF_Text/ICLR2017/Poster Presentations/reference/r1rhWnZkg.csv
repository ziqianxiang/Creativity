title,year,conference
 Compressing NeuralNetworks with the Hashing Trick,2015, In 32nd International Conference on Machine Learning
 Learning Phrase Representations using RNN Encoder-Decoder for Statis-tiCal MaChine Translation,2014, In 2014 Conference on Empirical Methods in Natural Language Processing
 A TheoretiCally Grounded AppliCation of Dropout in ReCurrent Neural Networks,2015, arXiv preprintarXiv:1512
 CompaCt Bilinear Pooling,2016, In IEEE Conferenceon Computer Vision and Pattern Recognition
 Deep Residual Learning for Image ReCognition,2016, InIEEE Conference on Computer Vision and Pattern Recognition
 Long Short-Term Memory,1997, Neural ComPUtation
 TrimZero: A Torch Recurrent Modulefor Efficient Natural Language Processing,2016, In KIIS SPring Conference
 Multimodal Residual Learning for Visual QA,2016, arXiv PrePrint arXiv:1606
 Skip-Thought Vectors,2015, In Advances in Neural Information Processing Systems 28
 rnn : Recurrent Library for Torch,2015, arXivPrePrint arXiv:1511
 Bilinear CNN Models for Fine-grained VisualRecognition,2015, In IEEE International Conference on ComPuter Vision
 Learning to represent spatial transformations with factored higher-order Boltzmann machines,2010, Neural computation
 Fast and scalable polynomial kernels via explicit feature maps,2013, In 19th ACMSIGKDD International Conference on Knowledge Discovery and Data Mining
 Bilinear classifiers for visual recognition,2009, InAdvances in Neural Information Processing Systems 22
 Separating style and content with bilinear models,2000, Neuralcomputation
 Feature hashing forlarge scale multitask learning,2009, In 26th International Conference on Machine Learning
 On MultiplicativeIntegration with Recurrent Neural Networks,2016, arXiv preprint arXiv:1606
