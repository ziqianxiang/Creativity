Published as a conference paper at ICLR 2017
Filter Shaping for Convolutional Neural Net-
WORKS
Xingyi Li, Fuxin Li, Xiaoli Fern & Raviv Raich
School of Electrical Engineering and Computer Science
Oregon State University
Corvallis, OR 97331, USA
{lixin,lif,xfern,raich}@eecs.oregonstate.edu
Ab stract
Convolutional neural networks (CNNs) are powerful tools for classification of
visual inputs. An important property of CNN is its restriction to local connections
and sharing of local weights among different locations. In this paper, we consider
the definition of appropriate local neighborhoods in CNN.We provide a theoretical
analysis that justifies the traditional square filter used in CNN for analyzing natural
images. The analysis also provides a principle for designing customized filter
shapes for application domains that do not resemble natural images. We propose an
approach that automatically designs multiple layers of different customized filter
shapes by repeatedly solving lasso problems. It is applied to customize the filter
shape for both bioacoustic applications and gene sequence analysis applications. In
those domains with small sample sizes we demonstrate that the customized filters
achieve superior classification accuracy, improved convergence behavior in training
and reduced sensitivity to hyperparameters.
1	Introduction
In recent years, deep learning approaches have seen tremendous successes. They have redefined
the state-of-the-art for a variety of challenging domains including computer vision and natural
language processing. A particularly appealing property of deep learning is that it eliminates the need
for feature engineering on complex inputs such as natural images and raw texts. For the task of
image classification, deep convolutional neural networks (CNN) have rapidly become the standard
approach. CNN builds upon many sequential convolutional and pooling layers. They are capable of
automatically extracting highly discriminative features from raw pixel inputs without prior domain
knowledge, leading to impressive performances even surpassing that of humans on the challenging
ImageNet dataset (He et al., 2016). One of the key reasons for the success of CNNs is that the
network is only connected locally. Traditional CNN designs use small square filters, which have been
quite successful in analyzing and classifying natural images. Also, translation invariance in natural
images allow the local filter weights to be shared among image locations. These two constructs
greatly reduce the number of parameters and make the learning process easier.
The success of CNN inspires us to consider the application of CNN to other domains that do not
necessarily resemble natural images, and do not have millions of labeled training examples to learn
from. Such domains are abundant in natural and biomedical sciences, where the cost of collecting
and annotating data can be high and small-sample performance is important. In order to extend
CNN to such domains, we start by examining the definition of locality and the use of square filters
in CNN. We introduce a novel correlation analysis methodology that analyzes the cross-correlation
between neighboring pixels across the whole dataset. A theoretical justification based on Gaussian
complexities is provided to demonstrate why such statistics can lead to a natural design methodology
of filter shapes for CNN. When applied to natural images, it justifies the use of square filters in image
classification tasks.
We believe that multiple layers in a deep network do not have to use the same filter shapes since they
may capture different types of information. Spectrograms present one such example, where local
filters tend to capture variations within one frequency region, while global filters could capture the
1
Published as a conference paper at ICLR 2017
relationships between different harmonics and syllables (each syllable indicates a single utterance of
a bird). We propose a data-driven filter design algorithm that automatically derives multiple levels of
different convolutional filter shapes based on the correlation analysis of the data. We believe that
the generalization capability of CNNs, especially on small training samples, would improve if those
customized data-dependent filter designs are adopted rather than standard square filters, since they
capture more of the correlation structure in the data.
We evaluate our proposed method in two diverse domains, bioacoustic spectrograms and gene
sequence data. Empirical results suggest that by customizing the filter designs, the proposed approach
not only significantly outperforms traditional CNN approaches in classification accuracy, but also
demonstrates superior robustness to hyperparameter tuning, especially with a small training set size.
While we have only considered two application domains, we expect the contribution to go beyond
these specific application domains. In particular, the proposed method is generally applicable to a
variety of other data analysis applications where data is scarce and demonstrate spatial autocorrelation
patterns that differ from natural images.
2	Correlation analysis
2.1	The Correlation Analysis Methodology and Natural Images
We focus on examining the use of locality in CNN. Itis well-known that locality makes strong intuitive
sense in natural images - the computer vision domain is dependent on building from low-level to
high-level features, where the low-level features, such as edges and corners, can be determined within
a local neighborhood. Intuitively, local patterns such as edges and corners are discriminative even in
a 3 × 3 box in the image, because normally, the values between each pixel and its neighboring pixels
are highly correlated. If a pixel is white, it is very likely that all the pixels in its 8-neighborhood are
also white. This makes boundaries significant patterns as some of the pixels behave significantly
differently from such a strong prior.
In other words, we could think of such strong correlation as a natural description of a neighborhood:
a CNN neighborhood can be defined as the pixels that have the highest correlations with each pixel.
To capture this intuition, we introduce the following correlation analysis procedure:
Let X = [X1, . . . , XN] be a dataset with N examples where the dimensions of each Xi, i = 1, . . . , N
has an integer lattice structure, i.e., Xi = {Xi (k), k ∈ Zp} where k is a p-dimensional index vector.
Let Xi[k] denote Xi shifted k indices, i.e. Xi[k1] = {Xi(k + k1), k ∈ Zp} then
C(k) = PN=IcoMxMxJ
PN=1 cov(Xi ,Xi)
(1)
where cov(A,B) = 5Zi∈zp(A(i) - μa)(B(i) - μB) is the covariance function, and μA,μB is
the average value across the corresponding dataset. In practice, we collect the tensor only with
k ∈ Rp ⊂ Zp with R being a short range (e.g. {-50, 50}). We also exclude data that represent
obvious noise in the computation, such as background white noise in the spectrogram data. These
white noise do not contain signals yet show strong correlation within local regions, hence can bias C
towards a regular ball shape.
Fig. 1 shows the results of such correlation analysis on 1, 000 images from the PASCAL VOC
dataset (Everingham et al.). It can be seen that each pixel is correlated the most with the pixels in
its 4-neighborhood, followed by ones in its 8-neighborhood and bigger. This corresponds well with
the common filter designs in natural images such as 3 × 3 (Simonyan & Zisserman, 2014), 5 × 5
(Szegedy et al., 2014) and 7 × 7 (Krizhevsky et al., 2012).
2.2	Theoretical Justification of the Correlation Analysis Approach
The insight we developed in the previous section has justifications from machine learning theory.
The capability of generalization from neural networks can be characterized using Rademacher
complexities (Bartlett & Mendelson, 2002):
2
Published as a conference paper at ICLR 2017
Theorem 1.	(Theorem 18, (Bartlett & Mendelson, 2002)) Suppose that σ : R 7→ [-1, 1] has Lipschitz
constant L and satisfies σ(0) = 0. Define the class computed by a two-layer neural network with
1-norm weight constraints as:
F = {x I X viσ(wi ∙ x): ∣∣v∣∣ι ≤ 1,1IWikI ≤ b}.
For any x1 , . . . , xN ∈ Rd, we have
^	“ CLB(Ind)1/2
GN(F) ≤------N-----Imax t
N
(xij - xij0)2,
i=1
(2)
(3)
E supf∈F N PL gif(g)]
where GN (F)
is the empirical Gaus-
sian complexity of the function class F, with gi being independent
standard normal random variables. The Gaussian complexity (and
the closely-related Rademacher complexity) measures the capacity of
the function class and is linked to the generalization capability of the
learner. The learner from a function class F with a smaller Gaussian
complexity is potentially able to generalize better (Bartlett & Mendel-
son, 2002), but has less capacity to fit the training data well. Thus a
trade-off is required for practical learners.
Convolutional neural networks are neural networks with locally-
defined connections hence similar results as above hold for CNNs,
with the change that maxj,j 0 is now defined within the range of each
single filter, as well as a change from the L1 norm to the L2 norm:
-40	-30	-20	-10	0	10	20	30	40	50
Figure 1: Covariance analy-
sis on natural images
Theorem 2.	Suppose that σ : R 7→	R is a contraction mapping.
Define the class computed by a two-layer convolutional neural network with one convolutional layer
and one fully-connected layer with 2-norm weight constraints as:
F
{x→ X Viσ(wi * x) : kv∣2 ≤ 1, ∣W∣1 ≤ b}.
(4)
For any x1 , . . . , xN ∈ Rd, we have
G N(F) ≤ CB(In d) / . max. ʌ X ∣∣χiCj) - χi Cj0)k2,	⑸
N	j-j0∈N
i=1
where N ⊂ Zp defines the shape of the convolution filter, i.e.
(wi *x)(k) = Xwi,jx[k](j)	(6)
j∈N
The proof can be found in the appendix.
EI ∙	1 ,	,	,1	, ∙	1	∙	M / T^l∖ l' ,1	1	1	1
This result suggests that in order to minimize GN (F) of the learner, one needs to select a convo-
lutional filter that minimizes maxj∈N,j0 ∈N
,P3 ∣Xi(j) - Xi(j0)k2. This requires to select only
dimensions that are highly correlated to each other (ones that maximize Cov(xi(j), xi(j0))) and avoid
having dimensions that are less correlated in the same convolutional filter. In natural images, this
justifies selecting 3 × 3, 5 × 5 or 7 × 7 squares in natural images since those are neighborhoods that
maximize the correlation within them.
3	Customize the Shape of CNN Filters
3.1	Filter Shaping Methodology
Our intuition for filter design is that the filters for a CNN framework should be capable of representing
the correlation image obtained from the covariance analysis, hence trading-off between learner
3
Published as a conference paper at ICLR 2017
capacity and its Gaussian complexity. If the CNN filter allows data dimensions with little correlation
in the same filter, it will make the bound in (5) worse, hence increasing the Gaussian complexity and
negatively impact generalization, especially in small-sample scenarios.
In one layer, the solution can be obtained via the following LASSO optimization problem:
mink C — fι * CokF + λ∣∣fι∣∣ι	⑺
f1
where C is the correlation tensor computed from the analysis in (1), C0 is an initial correlation tensor
with a 1 at the center location and 0s at all other locations, and λ is a nonnegative regularization
parameter trading off the representation error with the sparsity of the filters.
The LASSO optimization will attempt to convolve the C0 tensor so that it is most similar to C.
With this setup, the solution would be selecting the locations with the highest correlations to the
center location, i.e. finding the ∆js maximizing PiN=1 xi (j + ∆j)xi (j), directly corresponding to
the theorem. By controlling λ, one can control how many nonzeros will be in f1 . Since CNN is more
appropriate than the unsupervised LASSO for learning the exact filter weights, we will not keep the
weights learned by the LASSO. Instead, only the shape of f1 will be used, in the sense that only the
locations with values in f1 that are above a threshold will be accepted in the shape of the filter, and
the rest will have their weights fixed to 0.
With more than one layer, the theory is less clear about what would be the shape of the convolutional
filter. We propose a simple approach that repeatedly uses the previous convolution result to reconstruct
C. We assume that the next layers CNN filter fi convolve with fi-1 * (fi-2 . . . f1(C0)) would be
more similar to the correlation tensor. Hence, we can solve again the same LASSO problem to
approximate the full correlation tensor. Repeatedly applying this would amount to solve:
minkC-fi*Ci-1k2F+λkfik1	(8)
fi
where Ci-1 = fi-1 * (fi-2 . . . f1(C0)) is the solution from all the previous filters. The filter shape
is then determined by the same approach as before. With appropriate parameters, this methodology
can fully recover multiple levels of 3 × 3 squared filters in natural images.
3.2	Filter Shaping for Discrete Data
The above theory and computation works for continuous data. For discrete data where the minus
operator is not defined, we could use an analogous approach to (8) with group LASSO instead of
LASSO. Suppose again the dimensions of each Xi has an integer lattice structure and each element
comes from a categorical distribution, i.e. Xi(k) ∈ {1, . . . , K}, k ∈ Zp.
In this case, the discrete correlation tensor is defined as
C(A,B,k)=
Ei∈{i,...,N},j∈zp[I(Xi[k](j) = A)I(Xiej) = B)] - P(A)P(B)
PP(A)(1- P(A))P(B)(I- P(B))
(9)
where P(A) is the probability of any entry in the dataset attaining a value of A.
After collecting a similar covariance tensor as in the continuous case, one can solve a group LASSO
problem instead of a LASSO problem in order to handle the discrete entries in the covariance:
minkC-fi*Ci-1k2F+λkfk2,1	(10)
fi
where fi is a K × K × Zp filter, kfk2,1 = Pj∈Zp JPK=I PK=I f (A, B, j)2 regularizes on all the
entries at position j. The optimization allows the optimization to set all entries f(A, B,j) to 0 for a
certain j, which is then equivalent with filter shaping in the continuous case. In the discrete case, the
optimization starts with C0(A, B, 0) = 1, ∀A = B ∈ {1, . . . , K} and other entries equal to 0.
3.3	Accounting for Max-Pooling by Average Pooling
Max-pooling layers are essential to the performance of deep neural networks. Therefore, we need
an approach to account for max-pooling layers in our filter shaping algorithm. However, directly
4
Published as a conference paper at ICLR 2017
max-pooling on the solved correlation will destroy the symmetry of the Ci matrix. Therefore, as a
compromise we utilize average pooling in C instead of max-pooling. Suppose a max-pooling layer is
after fi . We will resize both Ci and C according to the max-pooling size reduction, and populate
the values with bilinear interpolation (average over all the items that max-pooling is supposed to
consider). One potential justification of using average pooling instead of max is that, each small
box considered by max pooling in each example may attain the maximal value at a separate location.
One can assume that the chance of each location attaining the max is equal, hence the expectation of
max-pooling will be average pooling to resize Ci and C.
4	Problem Domains
4.1	Bio-Acoustics
One special problem domain we consider is bird bio-acoustics, where the images we analyze are
spectrograms. A spectrogram is a 2-dimensional image where the x-axis indicates time and the
y-axis indicates frequency. The brighter a “pixel” is, the higher the energy at this time and frequency.
Spectrograms are commonly used for sound classification (Stowell & Plumbley, 2011) (Ranjard &
Ross, 2008) (Lasseck, 2013). Fig. 2 shows an example spectrogram of a recording of hummingbird
wingbeats. Our goal is to predict the species of the bird based on in-situ recording of wingbeats
(for hummingbirds) or bird-songs (for song birds). Consider Fig. 2(a), we notice that the wingbeats
are reflected as a collection of bright wavy lines at the low frequency range. The lines are regularly
spaced, revealing a clear harmonic structure. From the figure, it is reasonable to conclude that the
pixels that are horizontally closer to each other tend to be more similar when viewed on the local
scale. On a global scale, there are strong correlations between harmonics even they are separated
about 25Hz apart. Such correlation patterns appear to be highly different from natural images.
Figure 2: From left to right: (a) Sample spectrogram of bird wingbeats; (b) Sample spectrogram of
bird song; (c) Correlation image of bird wingbeats; (d) Correlation image of bird song.
We performed the correlation analysis on wingbeat spectrograms and bird-song spectrograms sep-
arately based on formula 1. Fig. 2(c) and 2(d) are resultant correlation images for wingbeats and
bird-song respectively. One can see significant differences w.r.t. the pattern in natural images.
4.2	Gene Sequence analysis: rSNP prediction
In this domain, our data are gene sequences, each describing a genetic variation in human genome
called Single-Nucleotide Polymorphism (SNP). Human genome contains millions of SNPs and most
of them reside in non-coding region of the genome and there is limited biological knowledge about
their functionality. There is great interest in the biomedical community to use machine learning
to help identify what non-coding SNPs are regulatory. Given a database of SNPs that have been
annotated by experts based on prior biological knowledge as regulatory or non-regulatory, the goal is
to learn a model to predict whether a SNP serves any regulatory function based on the gene sequence
around it. Each SNP is represented as a 2001 base-pair gene sequence centered at the SNP location.
Because gene sequences are discrete data, we use formula 9 to calculate the correlations. The
computed Cgene is shown in Fig. 3. It indicates that there are strong correlations in every other
column near the center of the gene covariance. Those patters will disappear after the first pooling
layer. In other words, the customized filter CNN only differ with the baseline model in the first
convolutional layer.
5
Published as a conference paper at ICLR 2017
5	Related work
There has been significant work on CNN net-
work design.For example, AlexNet (Krizhevsky
et al., 2012), VGG (Simonyan & Zisserman,
2014), GoogLeNet (Szegedy et al., 2014) and
ResNet (He et al., 2016) all involved significant
redesign process of the network structure. How-
ever, they all work on natural images hence their
filter designs are mainly selecting the size for
the square filters. Xie et al. (2016) proposed a
customized shape for CNN filters by making a
3 by 3 hole in a 7 by 7 convolutional filter to
tackle the structured labeling problems that fo-
cus on modeling object and context separately.
-40	-30	-20	-10	0	10	20	30	40
Figure 3: The correlation image for gene se-
quences.
This specific filter shape is designed manually and not learned from the data. (Bruna et al., 2014;
Henaff et al., 2015) explored defining CNN on a graph via a hierarchical clustering approach and a
harmonic analysis approach. Their approach can be used to recover a CNN on a lattice, however its
sparsity is mostly in the frequency domain, and usually cannot achieve sparsity in the original domain
as our approach. (Wen et al., 2016) adopted group lasso methodology to make the convolutional
layer sparse. Our experiments showed that L1 regularization could improve the performance due to
the sparsity but not as significant as our proposed model.
Convolutional neural networks are suitable for a wide range of application problem domains beyond
natural images. Kalchbrenner et al. (2014) proposed a Dynamic Convolutional Neural Network
(DCNN) on the problems of semantic modelling of sentences, which reduced at least 25% error
reduction comparing with the strongest baseline framework. Also in the domain of Natural Language
Processing (NLP), Ma et al. (2015) built a dependency tree between words within a sentence in order
to capture the words that highly correlated with each other but located further apart within the sentence.
Instead of concatenating successive words within a sequence, they concatenated words based on
the dependency tree which redefined the state-of-the-art performance in both sentiment analysis
and question classification. Shen et al. (2014) used convolutional neural network to learn semantic
representations for search queries and Web documents, and the proposed frame work outperforms
the previous state-of-the-art by a significant margin. Zbontar & LeCun (2015) successfully applied
convolutional neural network to predict the degree that two image patches match for stereo matching.
CNNs have also seen tremendous success in analyzing human speech (Abdel-Hamid et al. (2014)).
Recently, there are increasing interest in applying CNNs for analyzing bird songs for the species
prediction problem (GoeaU et al., 2016). But to the best of our knowledge, there has been no prior
study that focuses on classifying hummingbird species based on the sound of wingbeats.
In R-SNP prediction for gene sequences, a related work that we know of utilizes CNN is by Zhou
& Troyanskaya (2015). They use CNN to extract high level features from gene sequences based on
relevant domain knowledge in order to perform functional-variant predictions. We aim to predict the
R-SNP directly from sequence-based data without integrating any domain knowledge.
In other related work, (Zhang & LeCun, 2015) uses the similar Rademacher complexity as in this
work to characterize the sample complexity of CNN, but focus on a different research problem that
creates an abstain option for the classifiers.
6	Experiments
6.1	Filter Shapes and Network Design
Experiments are conducted on three different tasks, two in the bird-bioacoustics domain and one for
sequence-based rSNP prediction.
The first task is to identify the species of hummingbirds based on recorded wingbeats. This dataset
contains 434 labeled recordings from a total of 16 species, where each recording is 20 - 30 seconds
long. Since the wingbeat signals almost exclusively reside in the low frequency range of the
spectrogram, we only consider the frequency range 0Hz - 300H z . Note that although every
6
Published as a conference paper at ICLR 2017
recording contains some wingbeats, the signal may only occupy part of the recording. We apply a
pre-processing step to extract wingbeat regions with high energy in the low frequency range. We then
apply a sliding window to the resulting spectrograms and each window is considered as a separate
instance. This process results in a total of 5922 labeled instances.
For the second task, our goal is to recognize the species of song-bird based on recorded bird songs.
In this case, our data contains a total of 122 segments that have been manually extracted from
spectrograms and are labeled with species. Each segment is a spectrogram in a short interval which
contains some vocalization from a single bird and is labeled with its species. Similarly, a sliding
window is applied to the segment and each window is treated as a separate instance for classification.
In total we have 14 species and 1177 labeled instances.
The last task is to predict whether a non-coding Single-Nucleotide Polymorphism (SNP) serves any
regulatory function. Our data contains 4300 SNPs that have been annotated as either positive (serving
regulatory function) or negative (no known regulatory function). The data contains roughtly the same
number of positive and negative instances.
The covariance analysis procedure is applied to all datasets. We do not directly work with the
regularization parameter λ in (7). Instead, we specify the maximum number of nonzero elements
(namely DFMax) in the Lasso solution. For all datasets, we selected the DFmax values from 9, 11
and 13, and picked the smallest value that allowed for non-degenerate filters across all layers. The
selected value is 13 for the wingbeat data, 9 for the bird-song data and the gene sequencing data.
A stability study for a wider range of DFMax values (3-15) was conducted and the results were
shown in the appendix. Fig. 4 shows the filter shapes learned from the wingbeat data where eight
convolutional layers are used. The first 4 filters primarily capture local horizontal patterns, whereas
the last 4 filters capture more of the global harmonic structure in the data. More details and filter
shapes in the other two datasets can be found in the appendix.
Layers 1-4:	≡			ɪ
Layers 5-8:		I . I	□	
Figure 4: The derived filter shapes for the wingbeat data
6.2	Wingbeats classification results
We consider three baselines: 3 × 3, 3 × 5, 5 × 5 convolutional filters. These are selected since 3 × 3
filter have roughly equal number of parameters compared to our customized filters, and 3 × 5 covers
the domain of the customized filter in the first 3 levels. In the baseline of 5 × 5 filters, we added L1
regularization on the weights, in order to test whether the same effect of filter shaping can be learned
directly from sparsity priors on the weights. The swipe range for the L1 regularization parameter is
from 10-3 to 10-10, and we selected the one that generated best performance. 5-fold cross-validation
is conducted at the recording level. Thus, no validation example comes from the same recording as
any of the training examples. For training, we set the batch size to 20 for all designs and the learning
7
Published as a conference paper at ICLR 2017
rate to 10-4 for the customized filters and 10-5 and 10-6 for the 3 × 3 and 3 × 5 filters respectively.
Fig. 5(a) shows the cross-validated performance as a function of training epochs. As can be seen
from the figures that the cross-validation accuracy of our customized filter significantly outperforms
that of the traditional filters, and L1 regularization cannot achieve the same effect as filter shaping.
In order to further illustrate the robustness of our model in small-sample situations, we conducted an
experiment with half of the instances from each recording, resulting 2961 instances in total. As shown
in Fig. 5(b), the performance gap between the customized filter and in 3 × 3 widened significantly.
More results on parameter sensitivity can be found in the appendix.
Figure 5: Accuracy on the wingbeats dataset
6.3	Bird song classification results
For the bird song dataset, we compare to a baseline of 3 × 3 filter as well as a 5 × 5 filter with L1
regularization, and the swipe range for the L1 regularization parameter is from 10-3 to 10-10 as well.
5-fold recording-level cross validation is performed and the averaged cross-validation accuracies are
plotted in Fig. 6(a) as a function of the number of training epochs. From the figures, we observe
that the customized filter achieves ( 5%) higher validation accuracy compared to the 3 × 3 filter. L1
regularization on the weights negatively impacted performance for the 5 × 5 filter, perhaps because
that there are not enough data to learn the sparsity structure of the weights.
Figure 6: Validation accuracy on the birdsong and gene datasets
6.4 rSNP Prediction Results
For the gene dataset, we compare with a baseline that is similar with the framework used by Zhou &
Troyanskaya (2015), which contains several layers of CNN with 1 × 9 shape filters. 5-fold cross-
validation was performed and the results are shown in Fig. 6(b). The customized model was 0.8%
better than the baseline. The performance gap is not as significant as in the bird-bioacoustics data,
mainly because that the solved filters are not different with traditional ones after max-pooling (see
8
Published as a conference paper at ICLR 2017
appendix for details). Due to the fact that we apply no domain knowledge, our performance may not
be comparable with some recent papers which have used additional domain knowledge. However, it
demonstrates the strength of the customized filter design over traditional ones.
7	Conclusion
In this paper, we introduced a theoretically justified correlation analysis approach to reveal the
neighborhood structure in image-like domains. We proposed an algorithm that automatically designs
multiple levels of filters in a CNN by solving repeated lasso problems. Experiments show that
our approach significantly outperforms traditional fixed-size filters and exhibit higher robustness to
parameters, especially on smaller datasets. In future work we would like to extend this methodology
to other domains such as computational astronomy and biomedical imaging, as well as work on the
theory in the discrete and multi-layer cases.
Acknowledgments
This work is partially supported by the National Science Foundation grants IIS-1464371, CCF-
1254218, and DBI-1356792 and IIS-1055113.
References
Ossama Abdel-Hamid, Abdel-rahman Mohamed, Hui Jiang, Li Deng, Gerald Penn, and Dong Yu.
Convolutional neural networks for speech recognition. Audio, Speech, and Language Processing,
IEEE/ACM Transactions on, 22(10):1533-1545, 2014.
P. L. Bartlett and S. Mendelson. Rademacher and gaussian complexities: risk bounds and structural
results. Journal of Machine Learning Research, 3:463-482, 2002.
J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun. Spectral networks and locally connected networks
on graphs. In International Conference on Learning Representations, 2014.
M. Everingham, L. Van Gool, Chris Williams, J. Winn, and A. Zisserman. The pascal visual object
classes challenge 2012. www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html.
Herve Goeau, Herve Glotin, Willem-Pier Vellinga, Robert Planque, and Alexis Joly. Lifeclef bird
identification task 2016: The arrival of deep learning. In Working Notes of CLEF 2016-Conference
and Labs ofthe Evaluation forum, Evora, Portugal, 5-8 September 2016. ,pp. 440^49, 2016.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In IEEE Conference on Computer Vision and Pattern Recognition, 2016.
Mikael Henaff, Joan Bruna, and Yann LeCun. Deep convolutional networks on graph-structured data.
arXiv preprint arXiv:1506.05163, 2015.
Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. A convolutional neural network for
modelling sentences. arXiv preprint arXiv:1404.2188, 2014.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolu-
tional neural networks. In Advances in Neural Information Processing Systems, pp. 1097-1105,
2012.
Mario Lasseck. Bird song classification in field recordings: winning solution for nips4b 2013
competition. In Proc. of int. symp. Neural Information Scaled for Bioacoustics, sabiod. org/nips4b,
joint to NIPS, Nevada, pp. 176-181, 2013.
Michel Ledoux and Michel Talagrand. Isoperimetry and Processes in Probability in Banach Spaces.
Springer, 1991.
Mingbo Ma, Liang Huang, Bing Xiang, and Bowen Zhou. Dependency-based convolutional neural
networks for sentence embedding. arXiv preprint arXiv:1507.01839, 2015.
9
Published as a conference paper at ICLR 2017
Louis Ranjard and Howard A Ross. Unsupervised bird song syllable classification using evolving
neural networks. The Journal of the Acoustical Society ofAmerica,123(6):4358-4368, 2008.
Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng, and Gregoire MeSniL Learning semantic
representations using convolutional neural networks for web search. In Proceedings of the 23rd
International Conference on World Wide Web, pp. 373-374. ACM, 2014.
Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556, 2014.
Dan Stowell and Mark D Plumbley. Birdsong and c4dm: A survey of uk birdsong and machine
recognition for music researchers. 2011.
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Du-
mitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions.
arXiv:1409.4842, 2014.
Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Learning structured sparsity in
deep neural networks. In Advances in Neural Information Processing Systems, pp. 2074-2082,
2016.
Saining Xie, Xun Huang, and Zhuowen Tu. Convolutional pseudo-prior for structured labeling. In
European Conference on Computer Vision, 2016.
Jure Zbontar and Yann LeCun. Computing the stereo matching cost with a convolutional neural
network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.
1592-1599, 2015.
Xiang Zhang and Yann LeCun. Universum prescription: Regularization using unlabeled data. arXiv
preprint arXiv:1511.03719, 2015.
Jian Zhou and Olga G Troyanskaya. Predicting effects of noncoding variants with deep learning-based
sequence model. Nature methods, 12(10):931-934, 2015.
10
Published as a conference paper at ICLR 2017
Appendices
A Proof of Theorem
The proof of the theorem follows from various Slepian-type variance comparison theorems. We
state a couple of them here without proof. For proofs see Bartlett & Mendelson (2002); Ledoux &
Talagrand (1991).
Theorem 3. Ledoux & Talagrand (1991) Let X and Y be Gaussian random vectors in Rd such that
for every i, j,
E|Yi-Yj|2 ≤ E|Xi - Xj|2	(11)
, then for every non-negative convex increasing function F on R+,
EF (max |Yi - Yj |) ≤ EF (max |Xi - Xj |).	(12)
Lemma 1. Bartlett & Mendelson (2002) For x ∈ Rd, define
F1 = {x 7→ w>x : w ∈ Rd, kwk1 ≤ 1}.
where ∙ represents an inner product. For any xι,..., Xn ∈ Rd, we have
Gn(FI) ≤ C(ln d)1/2 max (X(Xj - Xj')2)	.	(13)
where Gn(F) is the Gaussian complexity of the function class F, cis a constant.
This lemma characterizes the Gaussian complexity of simple inner product functions. Convolutional
operators are also inner product functions, albeit they share weights over the entire domain (image)
they are defined. Hence, this lemma can be used to bound the Gaussian complexity of each individual
convolutional filter. In the proof, we convert the result of the convolutional operation into a number
of inner product operations, and utilize Lemma 1 to bound the Gaussian complexity of each inner
product operation.
Proof. (of Theorem ) Without loss of generality, the result of the convolution operator with parameters
W = [wι,..., wd] *Xi can be written as
fw(Xi) = W * Xi = [wi ∙ Xi1, W1 ∙ Xi2,..., W1 ∙ Xim, ..., WD ∙ Xi1, WD ∙ Xi2 ... WD ∙ xim]
(14)
where Xij represents a part in Xi equivalent to the size of the convolutional filter and m represents
the number of such parts (size of the image). Let
N
XvW = Xgi(v ∙σ(fw(Xi)))	(15)
i=1
where gi 〜N(0,1) are Gaussian random variables, so that
NN
kXvW - Xv,W0 k2 ≤ kvk2k X giσ(fW) - X giσ(fW0)k2	(16)
i=1	i=1
D	Nm	Nm
≤ Ilvk2XkWk ∙ XgiXXj-Wk∙ XgiXXjk2	(17)
The first inequality is Cauchy-Schwarz, and the second inequality is because σ is a contraction
mapping Ledoux & Talagrand (1991).
Now, if we define Ywk = Wk ∙ PN=I gi Pm=I Xj then according to SlePian's lemma Bartlett
& Mendelson (2002); Ledoux & Talagrand (1991) there exist constants c and B so that
11
Published as a conference paper at ICLR 2017
E[supv,W (Xvw)] ≤ cB Pik=1 E[supf (Ywk)], and according to Lemma 1,
E[sup(γWk)]	≤ c-(In d)1/2 max
f	N	t,t0
2	1/2
Nm	m
X(X Xtj- X Xtj)
(18)
Putting those together and noting GN (F) = E[supv W XvW] (F as defined in Theorem 2) finishes
the proof of the theorem.
B	Filter Shapes and Network Structure for Birdsong and Gene
Expression
Fig. 4 and Fig. 7 show the filter shapes that are learned from the covariance images of the wingbeat
data and the birdsong data respectively.
Similarly, for the birdsong data, filters in Fig.7(1) to 7(4) are long in the vertical direction and capture
local vertical patterns, whereas filters in Fig.7(5) to 7(8) are stretched along the horizontal direction,
which accounts for longer temporal patterns that occur at a more global scale.
Layers 1-4:	+	■	L	I
Layers 5-8:	□	□ i □	二	二
Figure 7: The derived filter shapes for the bird song data
■ ■ ■ ■	
1, Filter shape of first layer for gene data	2, Filter shape of second and third Layer for gene data
Figure 8: The derived filter shapes for gene data
Tables 1, 2 and 3 describes the network structure for the wingbeats, birdsong and gene data,
respectively. Every convolutional layer is followed by a ReLU layer.
12
Published as a conference paper at ICLR 2017
Layer name	Layer description
Input	307 × 49 spectrogram
Conv1	Fig. 4(1) (or 3 × 3) conv. 64
Conv2	Fig. 4(2) (or 3 × 3) conv. 64
Maxpool	2 × 2 stride (2, 2)
Conv3	Fig. 4(3)(or 3 X 3)conv.128
Conv4	Fig. 4(4)(or 3 × 3) conv.128
Maxpool	2 × 2 Stride(2, 2)
Conv5	Fig. 4(5) (or 3 × 3) conv. 256
Conv6	Fig. 4(6) (or 3 × 3) conv. 256
Maxpool	2 × 2 stride(2, 2)
Conv7	Fig. 4(7)(or 3 × 3) conv.512
Conv8	Fig. 4(8)(or 3 × 3) conv. 5Γ万"
FC-1024	fully connected layer
FC-1024	fully connected layer
SoftmaX layer	
Layer name	Layer description
Input	256 × 46 spectrogram
Conv1	-Fig. 7(1)(or 3 × 3) conv. 32-
Conv2	-Fig. 7(2)(or 3 × 3) conv. 32-
MaXpool	2 × 2 Stride (2, 2)
Conv3	Fig. 7(3) (or 3 × 3) conv. 64
Conv4	Fig. 7(4) (or 3 × 3) conv. 64
MaXpool	2 × 2 stride (2, 2)
Conv5	Fig. 7(5)(or 3 × 3) conv. !28一
Conv6	Fig. 7(6) (or 3 × 3) conv. 128
MaXpool	2 × 2 Stride(2, 2)
Conv7	Fig. 7(7) (or 3 × 3) conv. 256
Conv8	Fig. 7(8)(or 3 × 3) conv. 256~~
FC-512	fully connected layer
FC-512	fully connected layer
Softmax layer	
Table 1: The structure of the CNN for the wing-Table 2: The structure of the CNN for the bird
beat dataset.	song dataset.
Layer name	Layer description
Input	4 × 2001 one-hot gene sequence
Conv1	4 × 9 conv. 64
Maxpool	1 × 4 stride (1,4)
Conv2	1 × 9 conv. 128
Maxpool	1 × 4 stride (1,4)
Conv3	1 × 9 conv. 256
Maxpool	1 × 4 stride (1,4)
Sigmoid layer	
Layer name	Layer description
Input	4 × 2001 one-hot gene sequence
Conv1	Fig. 8(1) conv. 64
Maxpool	1 × 4 stride (1,4)
Conv2	Fig. 8(2) conv.128
Maxpool	1 × 4 stride (1,4)
Conv3	Fig. 8(2) conv. 256
Maxpool	1 × 4 stride (1,4)
Sigmoid layer	
Table 3: The structure of the CNN baseline for Table 4: The structure of the CNN for the bird
the gene dataset.	song dataset.
C Sensitivity test on Parameters
""Customized Filter
- 3*3 Filter
1e-4	1e-5	1e-6
Learning Rate
Figure 9: Sensitivity to the learning rate on
the bird song data.
In our experiments, we have observed that CNNs with
customized filters are more robust to the choices of
hyperparameter compared to those using 3 × 3 filters,
especially on smaller datasets. To illustrate this effect,
a separate experiment is designed where we train
different networks with the learning rate varying from
10-3 to 10-6. To measure the performance of a
network with each learning rate, we randomly sample
80% of the data for training and test on the remaining
20%. We repeat this five times and report the average
testing accuracy achieved by CNN with customized
filter and the traditional 3 × 3 filter. Fig. 9 shows the
results on the smaller bird song dataset, and it can
be seen that with the customized filter we are able
to obtain good learning results with a much wider
range of learning rates. On bigger datasets such as
wingbeats such trends also exist, but not as significant
as in a smaller dataset such as birdsong.
13
Published as a conference paper at ICLR 2017
D DFMax Stability
Figure 10: Stability of DFMax
Instead of controlling the parameter λ in LASSO, we
introduce another parameter DFMax to limit the
maximum number of nonzero solutions in LASSO. It
is shown that different DFMax values can generate
different sets of customized convolutional filters. In
order to investigate the relation between DFMax
and performance, we swipe DFMax from 3 to 15
and perform 5-fold cross validation on wingbeats
dataset. Fig. 10 shows that the performance of our
framework is stable for a wide range of DFMax
values. When DF Max equals to 3, all customized
convolutional filters are in shape 1 × 3, it is reasonable
for its performance is not as high as the framework
with higher DF Max values.
14