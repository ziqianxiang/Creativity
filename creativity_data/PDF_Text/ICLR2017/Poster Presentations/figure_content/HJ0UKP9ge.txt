Figure 1: BiDirectional Attention Flow Model (best viewed in color)query-aware context representation (the output of the attention layer). It also allows the attentionat each time step to be unaffected from incorrect attendances at previous time steps. Our experi-ments show that memory-less attention gives a clear advantage over dynamic attention. Third, weuse attention mechanisms in both directions, query-to-context and context-to-query, which providecomplimentary information to each other.
Figure 2: (a) t-SNE visualizations of the months names embedded in the two feature spaces. The contextualembedding layer is able to distinguish the two usages of the word May using context from the surrounding text.
Figure 3: Attention matrices for question-context tuples. The left palette shows the context paragraph (correctanswer in red and underlined), the middle palette shows the attention matrix (each row is a question word, eachcolumn is a context word), and the right palette shows the top attention points for each question word, above athreshold.
