Figure 1: Comparison of A3C and GA3C architectures. Agents act concurrently both in A3C andGA3C. In A3C, however, each agent has a replica of the model, whereas in GA3C there is only oneGPU instance of the model. In GA3C, agents utilize predictors to query the network for policieswhile trainers gather experiences for network updates.
Figure 2:	Automatic dynamic adjustment of NT, NP, and NA, to maximize TPS for BOXING (left)and PONG (right), starting from a sub-optimal configuration (NA =NT =NP = 1)Hence, in a balanced configuration, PPS ≈ TPS × tmax . Since each action is repeated four times asin (Mnih et al., 2016), the number of frames per second is 4×PPS.
Figure 3:	TPS of the top three configurations of predictors NP and trainers NT for several settings ofagents NA, while learning PONG on System I from Table 1. TPS is normalized by best performanceafter 16 minutes. Larger DNN models are also shown, as described in the text.
Figure 4: The average training queue size (left) and prediction batch size (right) of the top 3 per-forming configurations of NP and NT, for each NA, with PONG and the System I in Table 1.
Figure 5: Effect of PPS on convergence speed. For each game, four different settings of GA3C areshown, all starting from the same DNN initialization. Numbers on the right show the cumulativenumber of frames played among all agents for each setting over the course of3 hours. Configurationsplaying more frames converge faster. The dynamic configuration method is capable of catching upwith the optimal configuration despite starting with a sub-optimal setting, NT =NP =NA = 1.
Figure 6:	Training curves for GA3C on five Atari games. Each training has been performed threetimes for each of two learning rates (0.0003 and 0.0001) on System IV in Table 1.
Figure 7:	Training GA3C with a range of minimum training batch sizes. Increasing the minimumtraining batch size from 1 to 40 reduces the effect of the policy lag (delay k in Eq. (4)), leading toconvergence that is faster and more stable. GA3C achieved the overall best results with a minimumbatch size between 20 and 40. Increasing beyond this threshold dramatically reduces convergencespeed for some games, especially those inclined to unstable learning curves.
