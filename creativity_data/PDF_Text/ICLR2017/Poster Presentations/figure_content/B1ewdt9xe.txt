Figure 1: Predictive Coding Network (PredNet). Left: Illustration of information flow within twolayers. Each layer consists of representation neurons (Rl), which output a layer-specific prediction ateach time step (Al), which is compared against a target (Al) (Bengio, 2014) to produce an error term(El), which is then propagated laterally and vertically in the network. Right: Module operations forcase of video sequences.
Figure 2: PredNet next-frame predictions for sequences of rendered faces rotating with two degreesof freedom. Faces shown were not seen during training.
Figure 3: Information contained in PredNet representation for rotating faces sequences. Left: De-coding of latent variables using a ridge regression (αpan : pan (out-of-frame) angular velocity, θpan :pan angle, PC-1: first principal component of face, αroll: roll (in-frame) angular velocity). Right:Orientation-invariant classification of static faces.
Figure 4: PredNet predictions for car-cam videos. The first rows contain ground truth and the secondrows contain predictions. The sequence below the red line was temporally scrambled. The modelwas trained on the KITTI dataset and sequences shown are from the CalTech Pedestrian dataset.
Figure 5: Steering angle estimation accuracy on the Comma.ai dataset (Biasini et al., 2016). Left:Example steering angle curve with model estimations for a segment in the test set. Decoding wasperformed using a fully-connected readout on the PredNet representation trained with 25K labeledtraining examples. PredNet representation was trained for next-frame prediction on Comma.ai train-ing set. Right: Mean-squared error of steering angle estimation.
Figure 6: Extrapolation sequences generated by feeding PredNet predictions back into model. Leftof the orange line: Normal t + 1 predictions; Right: Generated by recursively using the predictionsas input. First row: Ground truth sequences. Second row: Generated frames of the original model,trained to solely predict t +1. Third row: Model fine-tuned for extrapolation.
Figure 7: MSE of PredNet predictions as a function of number of time steps ahead predicted. Modelwas fine-tuned for up to t + 5 prediction.
Figure 8:	Steering angle estimation accuracy as a function of the number of input frames.
Figure 9:	Next-frame predictions of PredNet Lall model on the rotating faces dataset and comparisonto L0 version. The ”ErrorLall-L0” visualization shows where the pixel error was smaller for the L0model than the Lall model. Green regions correspond to where L0 was better and red correspondsto where Lall was better.
Figure 10:	Next-frame predictions of PredNet Lall model on the CalTech Pedestrian dataset andcomparison to L0 version. The ”Error Lall - L0” visualization shows where the pixel error wassmaller for the L0 model than the Lall model. Green regions correspond to where L0 was better andred corresponds to where Lall was better.
