Figure 1: Simplified representation of a recurrent neural network (left) and an unrolled recurrentneural network (right). xi is a single element in an input sequence x, hi is an output after a singlepass through the recurrent unit. Adapted from Olah (2015).
Figure 2: Architectures of (a) Simple RNN, (b) LSTM, and (c) GRU units. xt : a single element inan input sequence being considered in the current iteration, ht-1 , ht: the output from the previousand current iterations, ct-1 , ct: the cell states of the previous and current iterations. Adapted fromOlah (2015).
Figure 3: Recurrent (left) and feed-forward (right) neural network architectures. Arrows indicate theflow of information. Input for both models is sequence of billing code observations e and sequence ofcorresponding timestamps t. A code observation ei passes through an embedding layer, producingan embedding vector xi , which is then appended with time t. The processed matrix then passesthrough either recurrent layers or feed-forward layers. The output in both cases is a single vector yof label probabilities.
Figure 4: Medication predictions for a complicated patient. Each vertical bar represents the pre-diction for a single medication class, with the height of the bar representing the confidence of theprediction. Black labels with arrows indicate ATC therapeutic classes for medications the patientwas actually taking. Colors and letters below the axis indicate organ system groups. More detail inAppendix C.
Figure 5: A t-SNE representation of our final embedding. The insets highlight two groups of codes(diabetes mellitus and kidney failure) that are strongly related clinically, and a third group that isnot. Codes are colored by whether their nearest neighbor in the embedding space (which may bedifferent from the nearest neighbor in this t-SNE space) is strongly related (blue), loosely related(orange), or unrelated (gray) from a clinical perspective.
Figure 6: Semantic relatedness of nearest neighbors vs. the distance between them. Solid linesare the conditional probabilities P (m|d) for the three values of m, dashed line is the marginalprobability P (d) of nearest neighbor distances d. Surprisingly, nearest neighbors that are fartheraway (but still the nearest neighbor) are more strongly related than nearest neighbors that are closerin the embedding space. Shaded regions, colored to correspond to the three values ofm, are the 95%CI for empirically estimated P(m) under random pairings, and represent the expected null result.
