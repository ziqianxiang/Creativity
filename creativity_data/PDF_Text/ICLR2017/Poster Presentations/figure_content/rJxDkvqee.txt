Figure 1: Illustration of our embedding architecture and contrastive multi-view approach.
Figure 2: Development set AP for several objec- Table 1: Word discrimination performancetives on acoustic word discrimination.	with different objectives.
Figure 3: Visualization via t-SNE of acoustic word embeddings (colored markers) and CorresPond-ing character sequence embeddings (text), fora set of development set words with at least 15 acoustictokens. Words seen in training are in lower-case; unseen words are in uPPer-case.
Figure 4: Visualization via t-SNE of character sequence embeddings for words with the suffixes“-ly” (blue), “-ing” (red), and “-tion” (green).
Figure 5: Precision-recall curve (left: two-layer bidirectional LSTM trained with obj0 + obj2 forword discrimination task) and scatter plot of embedding distances vs. orthographic distances (right:cost-sensitive margin model for word similarity task), for our best embedding models.
