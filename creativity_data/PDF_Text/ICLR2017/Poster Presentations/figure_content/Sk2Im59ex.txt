Figure 1: The Domain Transfer Network. Losses are drawn with dashed lines, input/output withsolid lines. After training, the forward model G is used for the sample transfer.
Figure 2: Domain transfer in two visual domains. Input in odd columns; output in even columns.
Figure 3: A random subset of the digit ’3’ from SVHN, transferred to MNIST. (a) The input images.
Figure 5: Style transfer as a specific case of Domain Transfer. (a) The input content photo. (b) Anemoji taken as the input style image. (c) The result of applying the style transfer method of Gatyset al. (2016). (d) The result of the emoji DTN. (e) Source image for style transfer. (f) The result, onthe same input image, of a DTN trained to perform style transfer.
Figure 6: All 80 identities of the Facescrub dataset. The even columns show the results obtained forthe images in the odd column to the left. Best viewed in color and zoom.
Figure 7: Maintaining expression in the domain transfer. In order to support a smiling expression,random smiling emoji were added to set of unlabeled samples from the domain T and the DTN wasre-trained. Each quadruplet include two pairs of {face, emoji} of the same identity in the two modesrespectively: not-smiling and smiling. Odd columns are input; Subsequent even columns are output.
Figure 9: The emoji visualization of the standard basis vectors in the space of the face representa-tion, i.e., g(e1),...,g(e256), where ei is the i standard basis vector in R256.
Figure 10: Domain transfer in the other direction (see limitations in Sec. 6).
