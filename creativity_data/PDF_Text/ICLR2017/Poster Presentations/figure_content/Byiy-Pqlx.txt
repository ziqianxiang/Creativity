Figure 1: Retrieval of value from memory via a key. Weightings with unit sum are assigned to differentmemories depending on the distances from the addresses to the read key. Linear smoothing over values is usedto emit the final read value. Both inverse-square and softmax schemes follow this method, but differ in theircomputations of the weightings.
Figure 2:	Analysis of the LANTM model. (a) PCA projection from key space R2 to 1D for the memories Σand read heads q of LANTM for the unary 8 -PRIORITY SORT task. In this task, the encoder reads a priority,encoded in unary, and then a value; the decoder must output these values in priority order. In this examplethe sequence is [@, @, 79, @, @, @, @, 98, @, 5, @, @, @, 107, @, 119], where the special symbol @ is a unaryencoding of the priority. From top to bottom, each row indicates the movement of the encoder write head q(w)as it is fed each input character. Fill indicates the strength si of memory write (black indicates high strength).
Figure 3:	Analysis of the SLANTM model. (a) PCA projection from the spherical key space S2 to 2D of thememories Σ and read heads q of SLANTM for the task of 7-REPEAT COPY. Here the model is to repeatedlyoutput the sequence 10 times. Input is 10 repetitions of special symbol @ followed by [28, 74, 43, 102, 88, 39,... ]. Left: the positions of write head q(w) during the encoding phase. Fill indicates strength si (black meanshigh strength); number indicates the character stored. SLANTM traverses in a circle clockwise starting at point28, and stores data at regular intervals. Right: the positions of read head q during the decoding phase. Startingfrom the blue dot, the reads move clockwise around the sphere, and end at the red dot. For the sake of clarity,read positions are indicated by bends in the blue line, instead of by dots. Intriguingly, the model implementsa cyclic list data structure, taking advantage of the spherical structure of the memory. (b) Raw coordinates inkey space S2 of writes (red) and reads (blue) from SLANTM on a non-unary encoded variant of the prioritysort task. Red line indicates the movements of the write-head q(w) to place points along a sub-manifold of K(an arc of S2) during the encoding phase. Notably, this movement is not sequential, but random-access, so asto store elements in correct priority order. Blue line indicates the simple traversal of this arc during decoding.
Figure 4: Memory access pattern of LANTM on 6-ODD FIRST. Left: In the middle of training. LANTMlearns to store data in a zigzag such that odd-indexed items fall on one side and even-indexed items fall on theother. However reading is only half correct. Right: After training. During reading, the model simply reads theodd-indexed items in a straight line, followed by the even-indexed items in a parallel line.
