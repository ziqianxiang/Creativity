Figure 1: Samples from hierarchical PixelVAE on the LSUN bedrooms dataset.
Figure 2: Our proposed model, PixelVAE, makes use of PixelCNN to model an autoregressive de-coder for a VAE. VAEs, which assume (conditional) independence among pixels, are known to sufferfrom blurry samples, while PixelCNN, modeling the joint distribution, produces sharp samples, butlack a latent representation that might be more useful for downstream tasks. PixelVAE combines thebest of both worlds, providing a meaningful latent representation, while producing sharp samples.
Figure 3: We generate top-down through a hierarchical latent space decomposition. The inferencenetwork generates latent variables by composing successive deterministic functions to compute pa-rameters of the stochastic random variables. Dotted lines denote contributions to the cost.
Figure 4: (a) Comparison of Negative log-likelihood upper bound of PixelVAE and NLL for Pixel-CNN as a function of the number of PixelCNN layers used. (b) Cost break down into KL divergenceand reconstruction cost.
Figure 5: Visualization of the MNIST test set in the latent space of (a) convolutional VAE and (b)PixelVAE with two latent dimensions. PixelVAE separates classes more completely than VAE.
Figure 6: We visually inspect the variation in image features captured by the different levels ofstochasticity in our model. For the two-level latent variable model trained on 64 × 64 LSUN bed-rooms, we vary only the top-level sampling noise (top) while holding the other levels constant,vary only the middle-level noise (middle), and vary only the bottom (pixel-level) noise (bottom).
Figure 7: Samples from hierarchical PixelVAE on the 64x64 ImageNet dataset.
Figure 8: Reconstructions for (a) LSUN Bedrooms and (b) 64×64 ImageNet. Left-most columnsare images from the test set, and the following 5 columns are top-down generations from the highestlevel of latent variables. We see that the reconstructions capture high-level semantic properties ofthe original images while varying in most of the details. We also visualized similar reconstructionsby generations from the lower level of latent variables, and in this case the reconstructions werevisually indistinguishable from the original images.
Figure 9: Samples from a PixelVAE with a receptive field of 7 pixels (left), a PixelCNN with an11-pixel receptive field (middle; roughly the same computational complexity as the PixelVAE), anda PixelCNN with a 7-pixel receptive field (right).
Figure 10: Reconstructions from the MNIST test set. Alternate columns are original (left) andreconstructed images (right).
Figure 11: More examples for visualizations of the variation in image features captured at differentlevels of stochasticity. Holding the other levels constant, we vary only the top-level sampling noise(top), only the middle-level noise (middle), and only the bottom (pixel-level) noise (bottom).
