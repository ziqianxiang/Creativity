Figure 1: Example model architectures. (A) Shared LN model. The past few frames of the stimulusimages are presented as inputs which are spatiotemporally filtered and passed through a nonlinearityto produce a firing rate, which drives a Poisson spiking process. (B) Two-layer RNN. The currentframe of the stimulus feeds into a sequence of RNN layers (history dependence is implicit in thehidden unit activations) and a Poisson GLM draws weighted inputs from the activations of the hiddenunits of the last RNN layer and outputs predicted spike trains. Thus the last RNN layer represents ashared feature pool that all the RGCs can draw from.
Figure 2: Model performance. (A) Mean ± std. err. of the fraction of explainable variance forcriteria-passing subset of OFF and ON cells for various model architectures. (B) Scatter plots showindividual neural performance from LN and RNN model; each dot corresponds to one cell. NegativeFV values are shown on relevant axis as FV=0 (C) Hybrid model performance, quantified by the ratiobetween the multitask LN to multitask hybrid performance gap and the multitask LN to multitaskRNN performance gap (one high outlier not pictured for both Exp 1 ON and Exp 2 ON )Shared LN: In this model, the architecture is similar to the individual LNs but all cells of a giventype (OFF or ON) share the same temporal and spatial filters (Figure 1A; note that the spatial filtersare displaced to the RF center of each individual RGC). All other parameters are individually tunedfor each observed neuron. There is an additional gain term that weights the output of the filteringindividually for each observed neuron.
Figure 3: (A,B) Rasters showing spiking responses for 57 trials (each row corresponds to a singletrial) for an OFF and ON cell from experiment 1 for 10 seconds of a novel natural scenes movie.
Figure 4: Model predictive performance on held-out data as a function of the amount of training data.
Figure 5: Shared vs individual fits for LN model (A) and RNN model (B). 10 OFF and 10 ON cellsfrom each experiment are pictured (Light blue = exp 1, dark blue = exp 2). Negative FV values arepictured as FV = 0.
Figure 6: Multiple different types of RNN architectures lead to similar levels of performance (Lightblue = exp 1, dark blue = exp 2). We compare (from left to right): 1) 2 layer RNN with 50 units/layer,2) 1 layer RNN with 100 units, 3) 3 layer RNN with 33 units/layer, 4) LSTM architecture as detailedin Hochreiter & Schmidhuber (1997)Poof-①>1一-l—tloo_lP ①Z=BE」ON1.00.80.60.40.20.01.00.80.60.40.20.0OFF cellsON cellsS
Figure 7: RNNs with added spike history filters outperform GLMs and LNs according to a normalizedlog-likelihood metric. RNNs without spike history filters underperformed GLMs in some cases: log-likelihood metrics are calculated using spike history filters generated by actual spikes so these filterscan improve log-likelihood without improving the fraction of explainable variance. The parametersof a multitask 2 layer RNN trained with a sigmoid nonlinearity were held fixed while the parametersof the last layer, including spike history filters, were trained. The normalized LL term was computedas detailed in Heitman et al. (2016) except the ideal model was trained using MSE.
Figure 8: Filters from image to Layer 1 RNN units in 2 layer RNN. Interpretable structures, includingOFF and ON centers and surrounds, are visible051015202530Shared LN Exp 1 OFF Spatial Filter0.0-0.2-0.4-0.6-0.8-1.0-1.2-1.40	5	10	15	20	25	30Figure 9: The 31x31 shared LN spatial filter is pictured. The white rectangle indicates the boundary
Figure 9: The 31x31 shared LN spatial filter is pictured. The white rectangle indicates the boundaryof the smaller 15x15 patchZ UO4PZ=B≡ΞInitialization 1Figure 10: Comparison of two different initializations of a 2 layer RNN trained on Exp 1 OFF cells.
Figure 10: Comparison of two different initializations of a 2 layer RNN trained on Exp 1 OFF cells.
