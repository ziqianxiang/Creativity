Table 1: Character error rate of different methods on the spelling correction task. In the table L is thelength of input strings, η is the probability of replacing a character with a random one. LL standsfor the log-likelihood training, AC and RF-C and for the actor-critic and the REINFORCE-criticrespectively, AC+LL and RF-C+LL for the combinations of AC and RF-C with LL.
Table 2: Our IWSLT 2014 machine translation results with a convolutional encoder compared tothe previous work by Ranzato et al. Please see 1 for an explanation of abbreviations. The asteriskidentifies results from (Ranzato et al., 2015). The numbers reported with ≤ were approximately readfrom Figure 6 of (Ranzato et al., 2015)Decoding methodgreedy searchbeam search17.74≤ 20.3LL*ModelMIXER*	LL	RF	RF-C	AC20.73	19.33	20.92	22.24	21.66≤ 21.9	21.46	21.35	22.58	22.45out of four settings. In the fourth case, actor-critic and REINFORCE-critic have similar performance.
Table 3: Our IWSLT 2014 machine translation results with a bidirectional recurrent encodercompared to the previous work. Please see Table 1 for an explanation of abbreviations. The asteriskidentifies results from (Wiseman & Rush, 2016).
Table 4: Our WMT 14 machine translation results compared to the previous work. Please see Table 1for an explanation of abbreviations. The apostrophy and the asterisk identify results from (Bahdanauet al., 2015) and (Shen et al., 2015) respectively.
Table 5: Results of an ablation study. We tried varying the actor update speed γθ, the critic updatespeed γφ, the value penalty coefficient λ, whether or not reward shaping is used, whether or nottemporal difference (TD) learning is used for the critic. Reported are the best training and validationBLEU score obtained in the course of the first 10 training epochs. Some of the validation scoreswould still improve with longer training. Greedy search was used for decoding.
