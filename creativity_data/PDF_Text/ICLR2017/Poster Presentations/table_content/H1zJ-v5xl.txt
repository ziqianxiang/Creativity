Table 1: Accuracy comparison on the IMDb binary sentiment classification task. All of our modelsuse 256 units per layer; all layers other than the first layer, whose filter width may vary, use filterwidth k = 2. Train times are reported on a single NVIDIA K40 GPU. We exclude semi-supervisedmodels that conduct additional training on the unlabeled portion of the dataset.
Table 2: Single model perplexity on validation and test sets for the Penn Treebank language model-ing task. LoWer is better. “Medium” refers to a tWo-layer netWork With 640 or 650 hidden units perlayer. All QRNN models include dropout of 0.5 on embeddings and betWeen layers. MC refers toMonte Carlo dropout averaging at test time.
Table 3: Translation performance, measured by BLEU, and train speed in hours per epoch, for theIWSLT German-English spoken language translation task. All models were trained on in-domaindata only, and use negative log-likelihood as the training criterion. Our models were trained for 10epochs. The QRNN model uses k = 2 for all layers other than the first encoder layer.
