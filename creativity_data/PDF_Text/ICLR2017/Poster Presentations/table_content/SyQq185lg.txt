Table 1: Wall Street Journal test eval92 Word Error Rate (WER) varying the n sized word piecevocabulary without any dictionary or language model. We compare Latent Sequence Decomposi-tions (LSD) versus the Maximum Extension (MaxExt) decomposition. The LSD models all learnbetter decompositions compared to the baseline character model, while the MaxExt decompositionappears to be sub-optimal.
Table 2: Wall Street Journal test eval92 Word Error Rate (WER) results across Connectionist Tem-poral Classification (CTC) and Sequence-to-sequence (seq2seq) models. The Latent Sequence De-composition (LSD) models use a n = 4 word piece vocabulary (LSD4). The Convolutional NeuralNetwork (CNN) model is with deep residual connections, batch normalization and convolutions.
Table 3: Top hypothesis Comparsion between seq2seq character model, LSD word piece model and MaxExt word piece model.
