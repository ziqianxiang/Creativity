Table 1: Test accuracy on sentiment analysis. See section 5.2 for further descriptions of the models.
Table 2: Test results on WikiMovies, measured in % hits@1. See Section 5.3.4 for further descrip-tions of the models.
Table 3: Results broken down by question category. See section 5.3.4 for further descriptions of themodels.
Table 4: Selected top patterns using cell decomposition scores, ENT denotes an entity placeholder7Published as a conference paper at ICLR 2017Sentiment	Pattern	SentenceNegative	gets the job done	Still, it gets thejob done — a sleepy afternoon rentalNegative	is a great	This is a great subject for a movie, but Hollywood has squandered the opportunity, using is as a prop for a warmed-over melodrama and the kind of choreographed mayhem that director John Woo has built his career on.
Table 5: Examples from Stanford sentiment treebank which are correctly labelled by our LSTM andincorrectly labelled by our rules-based classifier. The matched pattern is highlighted6.2	Approximation error between LSTM and pattern matchingAlthough our approach is able to extract sensible patterns and achieve reasonable performance,there is still an approximation gap between our algorithm and the LSTM. In Table 5 we presentsome examples of instances where the LSTM was able to correctly classify a sentence, and ouralgorithm was not, along with the pattern used by our algorithm. At first glance, the extractedpatterns are sensible, as ”gets the job done” or ”witty dialogue” are phrases you’d expect to seein a positive review of a movie. However, when placed in the broader context of these particularreviews, they cease to be predictive. This demonstrates that, although our work is useful as a first-order approximation, there are still additional relationships that an LSTM is able to learn from data.
Table 6: Comparison of importance scores acquired by three different approaches, conditioning onthe question ”the film west is west starred which actors?”. Bigger and darker means more important.
