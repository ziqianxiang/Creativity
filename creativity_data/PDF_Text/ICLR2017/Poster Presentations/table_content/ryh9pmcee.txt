Table 1: Grid search specsSettings	Description	EBGANs	GANsnLayerG	number of layers in G	[2, 3, 4, 5]	[2, 3, 4, 5]nLayerD	number of layers in D	[2, 3, 4, 5]	[2, 3, 4, 5]sizeG	number of neurons in G	[400, 800, 1600, 3200]	[400, 800, 1600, 3200]sizeD	number of neurons in D	[128, 256, 512, 1024]	[128, 256, 512, 1024]dropoutD	if to use dropout in D	[true, false]	[true, false]optimD	to use Adam or SGD for D	adam	[adam, sgd]optimG	to use Adam or SGD for G	adam	[adam, sgd]lr	learning rate	0.001	[0.01, 0.001, 0.0001]#experiments:	-	512	6144Digits generated from the configurations presenting the best inception score are shown in figure 4.
Table 2: The comparison of LN bottom-layer-cost model and its EBGAN extension on PI-MNISTsemi-supervised task. Note the results are error rate (in %) and averaged over 15 different randomseeds.
