Table 1: Results on the Omniglot dataset. Although our model uses only a simple convolutionalneural network, the addition of our memory module allows it to approach much more complexmodels on 1-shot and multi-shot learning tasks.
Table 2: Results on the synthetic task. We report the percentage of fully correct sequences from thetest set, which contains 10000 random examples. See text for details.
Table 3: Results on the WMT En-De task. As described in the text, we split the test set in two(odd lines and even lines) to evaluate the model on one-shot learning. Given the even test set, themodel can perform better on the odd test set. We also see a dramatic improvement when the modelis provided with the whole test set, validating that the memory module is working as intended.
