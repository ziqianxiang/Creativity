Figure 1: System architecture composed of three steps. (a) A sequence autoencoder learns a featurespace from unlabeled data, representing each sequence by a context vector (C). (b) Data is encodedto context vectors and augmented by adding noise, interpolating, or extrapolating (here we depictinterpolation). (c) The resulting context vectors can either be used directly as features for supervisedlearning with a static classifier, or they can be decoded to reconstruct full sequences for training asequence classifier.
Figure 2:	Sinusoids with various transformations applied in feature space. (a) Random noise addedwith γ = 0.5. (b) Interpolation between two sinusoids for values of λ between 0 and 1. (c) Extrap-olation between two sinusoids for values of λ between 0 and 1. Best viewed in colour.
Figure 3:	Interpolation (a) and extrapolation (b) between handwritten characters. Character (0,i) isinterpolated/extrapolated with character (j,0) to form character (i,j), where i is the row number and jis the column number. Original characters are shown in bold.
Figure 4: A new motion capture sequence can be generated by interpolating between samples. Bycombining the ”step front” action (a) with the ”step left” action (b) we can generate a new sequenceof a character stepping diagonally forward and the to left (c).
