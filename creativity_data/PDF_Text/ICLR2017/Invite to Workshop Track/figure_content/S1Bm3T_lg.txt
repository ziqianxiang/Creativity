Figure 1: Simplified illustration of the SPF Sc(xq) architecture with max-sum semiring used inexperiments (using ORB features as elements, |Exq | ≈ 100). Red dots depict elements Exq of queryinstance xq. Blue dots show training set elements ei,j ∈ E, duplicated with each query element forclarity. A boxed KL shows the leaf kernel with lines descending to its two element arguments. The㊉ nodes are labeled with their scopes. Weights and cost functions (arguments omitted) appear nextto 0 nodes. Only a subset of the unary and binary scope ㊉ nodes are drawn. Only two of the Ptop-level 0 nodes are fully detailed (the children of the second are drawn faded).
Figure 2: Images from NORB Compositions3.4	NORB SymmetriesComposition is a useful tool for modeling the symmetries of objects. When we see an image of anobject in a new pose, parts of the image may look similar to parts of images of the object in poses wehave seen before. In this experiment, we partition the training set of NORB jittered-cluttered into a7Under review as a conference paper at ICLR 2017new dataset with 10% withheld for each of validation and testing. Training and testing on the samegroup of toy instances, this measures the ability to generalize to new angles, lighting conditions,backgrounds, and distortions.
Figure 3: Number of training instances versus accuracy on unseen symmetries in NORB4 ConclusionThis paper proposed compositional kernel machines, an instance-based method for object recog-nition that addresses some of the weaknesses of deep architectures and other kernel methods. Weshowed how using a sum-product function to represent a discriminant function leads to tractablesummation over the weighted kernels to an exponential set of virtual instances, which can mitigatethe curse of dimensionality and improve sample complexity. We proposed a method to discrimina-tively learn weights on individual instance elements and showed that this improves upon uniformweighting. Finally, we presented results in several scenarios showing that CKMs are a significantimprovement for IBL and show promise compared with deep methods.
