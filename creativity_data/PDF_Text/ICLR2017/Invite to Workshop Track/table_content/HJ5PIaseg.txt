Table 1: Statistics of thedialogue response evaluationdataset. Each example is inthe form (context, model re-sponse, reference response, hu-man score).
Table 2: Median κ inter-annotator agreement scoresfor various questions askedin the survey.
Table 3: Correlation between metrics and human judgements, with p-values shown in brackets.
Table 4: System-level cor-relation, with the p-value inbrackets.
Table 5: Correlation for adem when various model responses are removed from the training set.
Table 7: Examples of scores given by the adem model.
Table 6: In 60/146 cases, adem scoresgood responses (human score > 4)highly when word-overlap metrics fail.
Table 9: Examples where both human and adem score the model response highly, while BLEU-2and ROUGE do not. These examples are drawn randomly (i.e. no cherry-picking) from the exampleswhere adem outperforms BLEU-2 and ROUGE (as defined in the text). adem is able to correctlyassign high scores to short responses that have no word-overlap with the reference response. Thebars around |metric| indicate that the metric scores have been normalized.
Table 8: Effect of differences in responselength on the score, ∆w = absolute differ-ence in #words between the reference re-sponse and proposed response. BLEU-1,BLEU-2, and METEOR have previouslybeen shown to exhibit bias towards similar-length responses (Liu et al., 2016).
Table 10: Correlations between word-overlap metrics and hUman jUdgementson the dataset from LiU et al. (2016), af-ter removing the speaker tokens at thebeginning of each Utterance. The corre-lations are even worse than estimated inthe original paper, and none are signifi-cant.
Table 11: EvalUationtime on the test set.
Table 12: Examples where a human and either BLEU-2 or ROUGE (after normalization) score themodel response highly (> 4/5), while the ADEM model scored it poorly (< 2/5). These examplesare drawn randomly (i.e. no cherry-picking). The bars around |metric| indicate that the metric scoreshave been normalized.
Table 13: Examples where a human and either BLEU-2 or ROUGE (after normalization) score themodel response low (< 2/5), while the ADEM model scored it highly (> 4/5). These examples aredrawn randomly (i.e. no cherry-picking). The bars around |metric| indicate that the metric scoreshave been normalized.
Table 14: adem correlations when trained on different amounts of data.
