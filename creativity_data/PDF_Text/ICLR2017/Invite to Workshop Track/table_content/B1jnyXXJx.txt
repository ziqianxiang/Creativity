Table 1: Hyper-parameters for Toy-ProblemAlgorithm						CPN			LR Momentum	P	β1	β2	α	β	λSGD	0.01	0	NA	NA	NA	0.1	1.0	0.1SGD Accelerated	0.01	0.9	NA	NA	NA	0.1	1.0	0.1AdaGrad	0.01	NA	NA	NA	NA	.5	1.0	0.001AdaDelta	1.00	NA	0.95	NA	NA	.5	1.0	0.001Adam	0.01	NA	NA 一	0.9	0.999	.5	10~	0.001	Table 2: Final Loss After 120 Iterations for Toy-Problem								Non-CPN		CPN				SGD	-2.00428E -	12	-8.192E9				SGD Accelerated	-2.04018E -	12	-8.192E9				AdaGrad	-1.75024E -	11	-0.00463				AdaDelta	-2.46194E -	12	-2.22216				Adam	-12.8413		-12.9671			Below are two figures. The first one shows the behavior of a five common gradient descent al-gorithms starting at a point near the saddle point (point: (x = 0.0001, y = -0.0001)) (Zeiler,2012), (Duchi et al., 2010). The next figure shows the same algorithms starting at the same point bututilizing CPN. All visualization were done using the matplotlib library (Hunter, 2007).
