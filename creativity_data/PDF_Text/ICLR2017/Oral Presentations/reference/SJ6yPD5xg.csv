title,year,conference
 Successor features for transfer inreinforcement learning,2016, arXiv preprint arXiv:1606
 The openarena manual,2005, 2005
 Improving generalization for temporal difference learning: The successor representa-tion,1993, Neural Computation
 Learning to forget: Continual predictionwith lstm,2000, Neural computation
 Viz-doom: A doom-based ai research platform for visual reinforcement learning,2016, arXiv preprintarXiv:1605
 Skill discovery in continuous reinforcement learning do-mains using skill chaining,2009, In Advances in Neural Information Processing Systems
 Deep successorreinforcement learning,2016, arXiv preprint arXiv:1606
 Playing FPS games with deep reinforcement learn-ing,2016, CoRR
 Recurrentreinforcement learning: A hybrid approach,2015, arXiv preprint arXiv:1509
 Memory approaches to reinforcement learning in non-markoviandomains,1992, Technical report
 Human-level control through deep reinforcementlearning,2015, Nature
 Hip-pocampal place cells constrUct reward related seqUences throUgh Unexplored space,2015, Elife
 Incremental mUlti-step q-learning,1996, Machine Learning
 Prioritized experience replay,2015, arXivpreprint arXiv:1511
 Compositional planning using optimal option models,2012, arXivpreprint arXiv:1206
 Masteringthe game of go with deep neural networks and tree search,2016, Nature
 Policy gradientmethods for reinforcement learning with function approximation,1999, In NIPS
 A deep hierar-chical approach to lifelong learning in minecraft,2016, arXiv preprint arXiv:1604
 Dueling Network Architectures for Deep ReinforcementLearning,2016, In Proceedings of the 33rd International Conference on Machine Learning (ICML)
 Learning from delayed rewards,1989, PhD thesis
 Model-based reinforcement learning with parametrized physical models and optimism-driven explo-ration,2015, CoRR
 Graying the black box: Understanding dqns,2016, InProceedings of the 33rd International Conference on Machine Learning
 The cropped region was subdivided into a 20 × 20 grid of non-overlapping 4 × 4 cells,2016, Theinstantaneous reward in each cell was defined as the average absolute difference from the previousframe
