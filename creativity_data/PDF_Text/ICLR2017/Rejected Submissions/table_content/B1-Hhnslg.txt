Table 1: Omniglot few-shot classification accuracy. *Note that the Neural Statistician used non-standard class splits.
Table 2: miniImageNet classification accuracy4.3	CUB Zero-shot ClassificationIn order to assess the suitability of our approach for zero-shot learning, we also run experiments onthe Caltech-UCSD Birds (CUB) 200-2011 dataset (Welinder et al., 2010). In the zero-shot setting,the goal is to classify query images in the absence of any support examples. Instead, class metadata(such as attributes or a textual description) is provided for each of the test classes. We adapt our5Under review as a conference paper at ICLR 2017Method	Image Features	Top-1 Acc (50-way)ALE (Akata et al., 2013)	Fisher Vectors	26.9%SJE (Akata et al., 2015)	AlexNet	40.3%Sample-Clustering (Liao et al., 2016)	AlexNet	44.3%SJE (Akata et al., 2015)	GoogLeNet	50.1%DS-SJE (Reed et al., 2016)	GoogLeNet	50.4%DA-SJE (Reed et al., 2016)	GoogLeNet	50.9%Prototypical Networks	GoogLeNet	54.6%Table 3: CUB-200 zero-shot classification accuracy for methods utilizing attribute vectors as classmetadata.
Table 3: CUB-200 zero-shot classification accuracy for methods utilizing attribute vectors as classmetadata.
