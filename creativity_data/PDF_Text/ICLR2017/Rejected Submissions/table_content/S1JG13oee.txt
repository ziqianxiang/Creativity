Table 1: Relation among GAN, f-GAN and b-GAN.
Table 2: The summary of objective functionalpha	D-step	G-step1 (KL divergence)	Ex-q(x) [rθD (X),- 1] - Ex-p(x) [log rrθD (X)]	Eχ~q3θG)[r(X) log r(X)- r(f) + 1]3 (Pearson divergence)	Ex-q(x) [0∙5rθD (X) - 0.5] - Eχ~p(χ)卜6勺(X) - 1]	Eχ~q3θG)[0.5(r(X) - 1)2]	--1 (Reversed KL divergence)	Ex~q(x)[log rθD (X)] - Ex~p(x)[-rg ^⑺]	Eχ~qgθG) [- log(r(X)) + r(X) - 1]•	α = -1 In this case, α-divergence is a Kullback-Leibler (KL) divergence. Densityratio estimation via the KL divergence corresponds to the Kullback-Leibler ImportanceEstimation Procedure (Sugiyama et al., 2012). In the G-step of an f-GAN-like update, theobjective function is Ex~q(x；©G)[- logr(x)] or Eχ^q(χ；θG)[1 - r(x)].
