Table 1: Test Perplexity: Left: Baselines Results on the 20newsgroups and RCV1-v2 dataset Legend: LDA(Blei et al., 2003), Replicated Softmax (RSM) (Hinton & Salakhutdinov, 2009), Sigmoid Belief Networks (SBN)and Deep Autoregressive Networks (DARN) (Mnih & Gregor, 2014), Neural Variational Document Model(Miao et al., 2016). K denotes the latent dimension in our notation. Right: DLGMs on text data with K = 100.
Table 2: Qualitative evaluation of Jacobian Vectors : In Table 2a and 2b, we evaluate the embeddings ofwords. In Table 8b and 2c we evaluate embeddings of medical diagnosis codes.
Table 3: Semantic Similarity in Words: The baseline results are taken from (Huang et al., 2012). C&W usesembeddings from the language model of (Collobert & Weston, 2008). Glove corresponds to embeddings by(Pennington et al., 2014). The learning algorithm for our embeddings does not use local context.
Table 4: Medical Relatedness Measure: Evaluating the quality of embedding using medical (NDF-RT andCCS) ontologies. Each column corresponds to a measure of how well the embedding space is amenable toperforming analogical reasoning (NDF-RT) or clusters meaningfully (CCS). A higher number is better. SCUIscorresponds to the application of the method developed by (Choi et al., 2016) on data released by (Finlaysonet al., 2014). The learning algorithm for our embeddings does not use local context.
Table 5: Train and Test Perplexity on RCV2: The tables herein show the train and held out bounds onperplexity obtained while varying the structure of the inference network. The top table depicts results for M = 1and the bottom table for M = 100. The values along the rows and columns depict different parameters for theinference network.
Table 6: Qualitative Evaluation of Movie Embeddings: We evaluate Jmloegan using 100 Monte-Carlo samplesto perform the evaluation in Tables 6a and 6b.
Table 7: Semantic Similarity in Words: The baseline results are taken from (Huang et al., 2012).
Table 9: Medical Relatedness Measure: Evaluated using the NDF-RT and CCS ontologies. For the evaluationon NDF-RT, there is a choice of s (Eq 7) to be made. The results are reported both by averaging across all pairsof drugs-diseases used to form s (avg-seed) and the best drug-disease pair (max-seed). SCUIs corresponds to theapplication of the method developed by (Choi et al., 2016) on data released by (Finlayson et al., 2014)Models	MRMNDF-RT (May Treat)	MRMNDF-RT (May Prevent)	MRMCCS (Fine Grained)	MRMCCS (Coarse Grained)(De Vine et al., 2014)	31.34/53.21	-^34.47/57.14^^	22.63	24.56(Choi et al., 2016)	36.62/59.40	28.02/55.71	44.80	47.43SCUI	34.89/52.75	30.95/48.57	34.16	37.311-M1 Jmloegan	4.08/54.36	^^19.90/34.29^^	30.82	34.041-M1 Jmpreoabn	33.87/56.19	22.41/34.29	31.76	35.071-M1 Jmpoetan	27.45/59.63	15.02/32.86	31.58	33.881-M100 Jmloegan	33.32/54.82	^^19.02/35.71^^	33.04	35.781-M100 Jmpreoabn	30.70/53.90	21.66 / 34.29	32.86	35.661-M100 Jmpoetan	28.49/55.73	15.56/31.43	32.87	35.093-M1 Jmloegan	33.21/52.29	^^23.84/42.86^^	32.80	37.583-M1 Jmpreoabn	12.12/30.28	7.62 / 17.14	23.42	26.853-M1 Jmpoetan	33.30/51.61	23.47/41.43	33.02	37.843-M100 Jmloegan	37.00/61.47	^^23.70/42.86^^	37.54	40.523-M100 Jmpreoabn	9.79/21.33	4.39 / 11.43	7.82	8.603-M100 Jmpoetan	36.11/60.32	22.26/38.57	37.77	40.87
