Table 1: Existing lipreading datasets and the state-of-the-art accuracy reported on these. The sizecolumn represents the number of utterances used by the authors for training. Although the GRIDcorpus contains entire sentences, Gergen et al. (2016) consider only the simpler case of predictingisolated words. LipNet predicts sequences and hence can exploit temporal context to attain muchhigher accuracy. Phrase-level approaches were treated as plain classification.
Table 2: Performance of LipNet on the GRID dataset compared to the baselines, measured on twosplits: (a) evaluating on only unseen speakers, and (b) evaluating on a 255 video subset of eachspeakersâ€™ sentences.
Table 3: LiPNet architecture hyPerParameters.
Table 4: Phoneme to viseme clustering of Neti et al. (2000).
