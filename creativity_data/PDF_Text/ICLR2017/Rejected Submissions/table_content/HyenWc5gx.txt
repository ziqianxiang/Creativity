Table 1: Evaluation of target task tuning methodologies for a distilled rule model to the task ofSemEval 2016 Task 4 Subtask A.
Table 2: Evaluation of knowledge transfer from three source tasks to the task of SemEval 2016Task 4 Subtask A.
Table 3: Evaluation of accuracy on the source task after integration with the target task data ofSemEval 2016 Task 4 Subtask A. The accuracy after only source task training prior to integrationwith the target task is included for reference as a baseline.
Table 4: Some transfer learning examples from each knowledge source to SemEval 2016 where theGRU model successfully predicts sentiment when using the forgetting cost paradigm, but not withfine-tuning based integration.
Table 5: Empirical three way sentiment classification results on the SemEval 2016 Task 4 SubtaskA test set.
Table 6: Logical rule engine distillation performance and SemEval 2016 Task 4 Subtask A accuracyas a function of the number of hidden units in the GRU and the number of training examples. The50 hidden unit and 50,000 training example model performs the best on the SemEval training set.
