Figure 1: Features extracted by HCN. Left: from multiple images. Right: from a single image.
Figure 2: Factor graph of the HCN model when connected to multiple images Xn . The weights arethe only variables that entangle multiple images. The top variables are clamped to 1 and the bottomvariables are clamped to Xn. Additional details of each layer type are given in Fig. 4.
Figure 3: Unsupervised analysis of image X by a standalone convolutional feature layer of HCN.
Figure 4: Diagrams of binary convolution and factor graph connectivity for 1D image.
Figure 5: Features extracted by HCN and NOCA and image reconstructions for several datasets. Bestviewed on screen with zoom.
Figure 6: Online learning. (a) and (b) show two sample input images; (c) and (d) show the featureslearned by batch and online HCN using 30 input images and 100 epochs; (e) shows the featureslearned by online HCN using 3000 input images and 1 epoch.
Figure 7: Samples from synthetic data and results from unsupervised learning tasks.
Figure 8: Discriminative vs. generative training and supervised vs. unsupervised generative training.
Figure 9: First layer of weights learned by HCN and CNN on the preprocessed MNIST dataset.
Figure 10: Results of training a modified HCN on a grayscale image. A filter bank is convolved withthe input image to provide the bottom up messages to each channel of HCN. The filter bank sizes inthis simple example are adapted to match those of generation. As a benchmark, Wu et al. (2010) isused on the same data and is also given knowledge of the filter bank in use. Top row: 3 Ã— 3 filter size.
Figure 11:	Factors and variable labeling used in the message update equations.
Figure 12:	Different types of noise corruption used in Section 4.4.
