Figure 1: Diagram of the 3D semi-supervised architecture. Parentheses denote subset of total dimen-sion shown. Only two (2) feature maps per layer shown for ease of visualization in encoder-decoder.
Figure 2: Feature maps for the 16 channels in a select image in the training set (left) versus theirreconstructions from the 2D convolutional autoencoder (right).
Figure 3: Bounding box predictions shown on 2 consecutive (6 hours in between) simulation frames(integrated water vapor column). Green = ground truth, red = high confidence predictions (confi-dence above 0.8, (Left) 3D Fully supervised model, (Right) 3D Semi-supervised model.
Figure 4: t-SNE visualisation of the first 7 days in the training set for both 3D supervised (top) andsemi-supervised (bottom) experiments. Each frame (i.e. time step) in the 7 days has 12x18 = 216vectors of length 640 (i.e. the number of feature maps in the final encode layer) in the coding layer(where each pixel in the 12x18 patch corresponds to a 64x64 patch in the original frame). Thesevectors are then fed to t-SNE and reduced to two dimensions for visualization. For both supervisedand semi-supervised, we have zoomed into two clusters and sampled 64x64 patches from thoseclusters. Grey = unlabelled, yellow = tropical depression (not shown), green = hurricane, blue =ETC, red = AR. (The same t-SNE parameters were used for both experiments.)5	Conclusions and Future WorkWe have explored semi-supervised methods for object detection and bounding box prediction using3D CNNs. These architectures and approaches are motivated by finding extreme weather patterns;9Under review as a conference paper at ICLR 2017Table 4: Accuracy Results: Mean Average Precision (mAP) for the modelsModel	Mode	Parameters (millions)	Î»	mAP (%) (IOU=0.1)	mAP (%) (IOU=0.5)2D	Supervised	66.53	0	51.42	16.982D	Semi-Supervised	66.53	10	48.85	9.242D	Semi-Supervised	66.53	1	51.11	6.212D	Supervised	16.68	0	49.21	15.492D	Semi-Supervised	16.68	1	44.01	7.71
