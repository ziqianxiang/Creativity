Figure 1: 128×128 resolution samples from 5 classes taken from an AC-GAN trained on the ImageNet dataset.
Figure 2: A comparison of several GAN architectures with the proposed AC-GAN architecture.
Figure 3: Generating high resolution images improves discriminability. Top: Training data and synthesized im-ages from the zebra class resized to a lower spatial resolution (indicated above) and subsequently artificiallyresized to the original resolution. Inception accuracy is shown below the corresponding images. Bottom Left:Summary of accuracies across varying spatial resolutions for training data and image samples from 64 × 64 and128 × 128 models. Error bar measures standard deviation across 10 subsets of images. Dashed lines highlightthe accuracy at the output spatial resolution of the model. The training data (clipped) achieves accuracies of24%, 54%, 81% and 81% at resolutions of 32, 64, 128, and 256 respectively. Bottom Right: Comparison ofaccuracy scores at 128 × 128 and 32 × 32 spatial resolutions (x and y axis, respectively). Each point representsan ImageNet class. 84.4% of the classes are below the line of equality. The green dot corresponds to the zebraclass.
Figure 4: Examples of different MS-SSIM scores. The top and bottom rows contain AC-GAN samples andtraining data, respectively.
Figure 5: (Left) Comparison of the mean MS-SSIM scores between pairs of images within a given class forImageNet training data and samples from the GAN (blue line is equality). The horizontal red line marks themaximum MS-SSIM value across all ImageNet classes. Each point is an individual class. The mean standarddeviation of scores across the training data and the samples was 0.06 and 0.08 respectively. Scores belowthe red line (84.7% of classes) arise from classes where GAN training largely succeeded. (Right) Intra-classMS-SSIM for selected ImageNet classes throughout a training run. Classes that successfully train tend to havedecreasing mean MS-SSIM scores, to a point.
Figure 6: Inception accuracy vs MS-SSIM for all 1000 ImageNet classes (r2 = -0.16). Samples from AC-GAN models do not achieve variability at the expense of discriminability.
Figure 7: Nearest neighbor analysis. (Left) Samples from a single ImageNet class. (Right) Correspondingnearest neighbor (L1 distance) in training data for each sample.
Figure 8: (Left) Latent space interpolations for selected ImageNet classes. Left-most and right-columns showthree pairs of image samples - each pair from a distinct class. Intermediate columns highlight linear interpola-tions in the latent space between these three pairs of images. (Right) Class-independent information containsglobal structure about the synthesized image. Each column is a distinct bird class while each row correspondsto a fixed latent code z .
Figure 9: Mean pairwise MS-SSIM values for 10 ImageNet classes plotted against the number of ImageNetclasses used during training. We fix everything except the number of classes trained on, using values from 10to 100. We only report the MS-SSIM values for the first 10 classes to keep the scores comparable. MS-SSIMquickly goes above 0.25 (the red line) as the class count increases. These scores were computed using 9 randomrestarts per class count, using the same number of training steps for each model.
