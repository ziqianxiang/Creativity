Figure 1: Atari 2600 and SNES game screen comparison: Left: ”Boxing” an Atari 2600 fightinggame , Right: ”Mortal Kombat” a SNES fighting game. Note the exceptional difference in theamount of details between the two games. Therefore, distinguishing a relevant signal from noise ismuch more difficult.
Figure 2: DQN, DDQN and Duel-DDQN performance. Results were normalized by subtracting thea random agent’s score and dividing by the human player score. Thus 100 represents a human playerand zero a random agent.
Figure 3: Left: The game Super Mario with added bonus for moving right, enabling the agent tomaster them game after less training time. Right: The game F-Zero. By granting a reward for speedthe agent was able to master this game, as oppose to using solely the in-game reward.
Figure 4: Averaged action-value (Q) for Super Mario trained with reward bonus for moving right(blue) and without (red).
