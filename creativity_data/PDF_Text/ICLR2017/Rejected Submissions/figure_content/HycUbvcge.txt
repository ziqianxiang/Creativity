Figure 1: A schematic of DGCCA with deep networks for J views.
Figure 2: Synthetic data used in in Section 4.1 experiments.
Figure 3: The matrix G learned from applying (linear) GCCA or DGCCA to the data in Figure 2.
Figure 4: Outputs of the trained input neural networks in Section 4.1 applied to the data in Figure 2.
Figure 5: The confusion matrix for speaker-dependent GCCA and DGCCADGCCA rectifies the frequent misclassification of V as P , R and B by GCCA. In addition, com-monly incorrect classification of phonemes such as S and T is corrected by DGCCA, which enablesbetter performance on other voiceless consonants such as like F , K and SH. Vowels are classifiedwith almost equal accuracy by both the methods.
Figure 6: Tuning reconstruction error against Recall at 1000 for the hashtag prediction task. Eachpoint corresponds to a different setting of hyperparameters.
