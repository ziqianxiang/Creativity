Figure 1: Pixel importance using gradients at the image.
Figure 2: Saturation in InceptionInput image and trend of the pixel importance scores obtained from interior gradients.
Figure 3: Visualization of interior gradients. Notice that the visualizations at lower values of thescaling parameter (α) are sharper and much better at surfacing important features of the input image.
Figure 4: Comparing integrated gradients with gradients at the image. Left-to-right: originalinput image, label and softmax score for the highest scoring class, visualization of integrated gradi-ents, visualization of gradients at the image. Notice that the visualizations obtained from integratedgradients are better at reflecting distinctive features of the image.
Figure 5: AOPC (Samek et al. (2015)) for integrated gradients and gradients at image.
Figure 6: Interior gradients of misclassified images. Left-to-right: Original image, Softmax scorefor the top label assigned by the Inception network and the groundtruth label provided by ImageNet,visualization of integrated gradients w.r.t. Inception label, visualization of integrated gradients w.r.t.
Figure 7: Attribution for a molecule under the W2N2 network (Kearnes et al. (2016)). Themolecules is active on task PCBA-58432.
Figure 8: Softmax scores of the next word in the LSTM language model (Section 3.2)In Table 9 and Table 10 we show two comparisons of gradients to integrated gradients. Due tosaturation, the magnitudes of gradients are so small compared to the prediction scores that it isdifficult to make sense of them. In comparison, (approximate) integrated gradients have a totalamount close to the prediction, and seem to make sense. For example, in the first example, theintegrated gradients attribute the prediction score of “than“ to the preceding word “more”. Thismakes sense as “than” often follows right after “more“ in English. On the other hand, standardgradient gives a slightly negative attribution that betrays our intuition. In the second example, inpredicting the second “ual”, integrated gradients are clearly the highest for the first occurrence of15Under review as a conference paper at ICLR 2017Sentence	the	shareholders	claimed	more	than	$ N millions in lossesIntegrated gradients	-0.1814	-0.1363	0.1890	0.6609		Gradients	0.0007	-0.0021	0.0054	-0.0009		Figure 9: Prediction for than: 0.5307, total integrated gradient: 0.5322Sentence	and	N	minutes	after	the	ual	tradingIntegrated gradients (*1e-3)	0.0707	0.1286	0.3619	1.9796	-0.0063	4.1565	0.2213Gradients (*1e-3)	0.0066	0.0009	0.0075	0.0678	0.0033	0.0474	0.0184Sentence (Cont.)	halt	came	news	that	the	ual	groupIntegrated gradients (*1e-3)	-0.8501	-0.4271	0.4401	-0.0919	0.3042		
Figure 9: Prediction for than: 0.5307, total integrated gradient: 0.5322Sentence	and	N	minutes	after	the	ual	tradingIntegrated gradients (*1e-3)	0.0707	0.1286	0.3619	1.9796	-0.0063	4.1565	0.2213Gradients (*1e-3)	0.0066	0.0009	0.0075	0.0678	0.0033	0.0474	0.0184Sentence (Cont.)	halt	came	news	that	the	ual	groupIntegrated gradients (*1e-3)	-0.8501	-0.4271	0.4401	-0.0919	0.3042		Gradients (*1e-3)	-0.0590	-0.0059	0.0511	0.0041	0.0349		Figure 10: Prediction for ual: 0.0062, total integrated gradient: 0.0063“ual”, which is the only word that is highly predictive of the second “ual”. On the other hand,standard gradients are not only tiny, but also similar in magnitude for multiple words.
Figure 10: Prediction for ual: 0.0062, total integrated gradient: 0.0063“ual”, which is the only word that is highly predictive of the second “ual”. On the other hand,standard gradients are not only tiny, but also similar in magnitude for multiple words.
Figure 11: More visualizations comparing integrated gradients with gradients at the image.
Figure 12: Saturation in intermediate layers of Inception. For each layer we plot the L2 andCosine distance between the activation vector for a scaled down image and the actual input image,with respect to the scaling parameter. Each plot shows the trend for 30 randomly chosen imagesfrom the ImageNet dataset. Notice that trends in all plots flatten as the scaling parameter increases.
Figure 13: Saturation in the W2N2 network (Kearnes et al. (2016)). Plots for the softmax scorefor task PCBA-58834, and the sum of the feature gradients w.r.t. the same task for twenty molecules.
Figure 14: Attributions for two functionally equivalent networks. The figure shows attributionsfor two functionally equivalent networks f(x1, x2) and g(x1, x2) at the input x1 = 3, x2 = 1using integrated gradients, DeepLift (Shrikumar et al. (2016)), and Layer-wise relevance propa-gation (LRP) (Binder et al. (2016)). The reference input for Integrated gradients and DeepLift isx1 = 0, x2 = 0. All methods except integrated gradients provide different attributions for the twonetworks.
