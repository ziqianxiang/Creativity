Figure 1: Schematic of the latent space of a generative model. In the general case, a generative modelincludes an encoder to map from the feature space (here images of faces) into a high dimensionallatent space. Vector space arithmetic can be used in the latent space to perform semantic operations.
Figure 2: DCGAN (Radford 15) interpolation pairs with identical endpoints and uniform prior. Ineach pair, the top series is linear interpolation and the bottom is spherical. Note the weak generationsproduced by linear interpolation at the center, which are not present in spherical interpolation.
Figure 3: J-Diagram. The three corner images are inputs to the system, with the top left beingthe “source” (A) and the other two being “analogy targets” (B and C). Adjacent to each is thereconstruction resulting from running the image through both the encoder and decoder of the model.
Figure 4: Same J-Diagram repeated with different model type. To facilitate comparisons (anddemonstrate results are not cherry-picked) inputs selected are the first 3 images of the validation set.
Figure 5: Example of local VAE manifold built using the 30k CelebA validation and test images as adataset of out of sample features. The resulting MINE grid represents a small contiguous manifold ofthe larger latent space. (model: VAE from Lamb 16 on CelebA)3	Attribute VectorsMany generative models result in a latent space that is highly structured, even on purely unsuperviseddatasets (Radford et al., 2015). When combined with labeled data, attribute vectors can be computedusing simple arithmetic. For example, a vector can be computed which represents the smile attribute,which by shorthand we call a smile vector. Following (Larsen et al., 2016), the smile vector can be5Under review as a conference paper at ICLR 2017computed by simply subtracting the mean vector for images without the smile attribute from themean vector for images with the smile attribute. This smile vector can then be applied to in a positiveor negative direction to manipulate this visual attribute on samples taken from latent space (Figure 6).
Figure 6: Traversals along the smile vector. (model: GAN from Dumoulin 16 on CelebA)3.1	Correlated LabelsThe approach of building attribute vectors from means of labeled data has been noted to suffer fromcorrelated labels (Larsen et al., 2016). While many correlations would be expected from groundtruths (eg: heavy makeup and wearing lipstick) we discovered others that appear to be from samplingbias. For example, male and smiling attributes have unexpected negative correlations because womenin the CelebA dataset are much more likely to be smiling than men. (Table 1).
Figure 7: Initial attempts to build a smile vector suffered from sampling bias. The effect was thatremoving smiles from reconstructions (left) also added male attributes (center). By using replicationto balance the data across both attributes before computing the attribute vectors, the gender bias wasremoved (right). (model: VAE from Lamb 16 on CelebA)In an online service we setup to automatically add and remove smiles from images1, we discoveredthis gender bias was visually evident in the results. Our solution was to use replication on the trainingdata such that the dataset was balanced across attributes. This was effective because ultimately thevectors are simply summed together when computing the attribute vector (Figure 7).
Figure 8: Decoupling attribute vectors for smiling (x-axis) and mouth open (y-axis) allows for moreflexible latent space transformations. Input shown at left with reconstruction adjacent. (model: VAEfrom Lamb 16 on CelebA)3.2	Synthetic AttributesIt has been noted that samples drawn from VAE based models is that they tend to be blurry (Goodfel-low et al., 2014; Larsen et al., 2015). A possible solution to this would be to discover an attributevector for “unblur”, and then apply this as a constant offset to latent vectors before decoding. CelebAincludes a blur label for each image, and so a blur attribute vector was computed and then extrapolatedin the negative direction. This was found to noticeably reduce blur, but also resulted in a number ofunwanted artifacts such as increased image brightness.
Figure 9: Zoomed detail from training images (top) and computed blurred images (bottom) were bothencoded in order to determine a non-biased blur attribute vector.
Figure 10: Zoomed detail of images from the validation set (top) are reconstructed (second row).
Figure 11: Example of using an attribute vector for classification. A smile vector is first constructedin latent space from labeled training data. By taking the dot product of this smile vector with theencoded representation of any face, a scalar smile score is generated (a). This score can be the basisfor a binary classifier. The histogram shows the distribution of positive (green) and negative (red)scores on the CelebA validation set (b). The ROC curve for a smile vector based binary classifier isalso shown (c).
