Figure 1: An example reference problem (with the query 7 and the answer red) and intermediateattention maps using our progressive attention model. It shows that attention is gradually refinedthrough the network layers for resolving the reference problem. Distracting patterns at smaller scalesare suppressed at earlier layers while those at larger scales (e.g. 9) are suppressed at later layers withlarger receptive fields. All attended images are independently rescaled for the visualization.
Figure 2: Overall procedure of progressive attention. Attentive processes are repeatedly applied tofeature maps at multiple layers and the resulting attended feature maps are used as input featuremaps for the next convolution layers in CNN. Attention probabilities αl are estimated from featuremaps and input query. In the last attention layer, the attended feature maps are aggregated to a singlefeature vector (by sum pooling) and fed to the final attribute classifier.
Figure 3: Attention estimation (a) without local context and (b) with local context. In (a), α"∙ ispredicted from f" only while its spatially adjacent features are also used to estimate a" in (b).
Figure 4: Example of the MREF datasets.
Figure 5: Detailed illustration of network architectures on MNIST Reference experiments.
Figure 6: Analysis of algorithms on MREF (left), MDIST (middle), and MBG (right).
Figure 7: Qualitative results of SAN, HAN and PAN-CTX. (a) Input images faded by attendedfeature map (c). (b) Magnitude of activations in feature maps fil,j before attention: the activations aremapped to original image space by spreading activations to their receptive fields. (c) Magnitude ofactivations in attended feature maps 儿 which shows the effect of attention in contrast to (b). (d)Magnitude of activations of the attended feature maps f∣,j in its original resolution of the featuremap. For PAN-CTX, only last three attention layers are visualized and attentions of ealier layersare accumulated for visualizing higher attention layers. For HAN, (c) and (d) represent attentionprobability because attended feature map is not available. Every image except for input image isrescaled into [0,1] by (X — min)/(max — min).
Figure 8: Visualization of example attentions of HAN and PAN-CTX on VG dataset. Attention mapspresent magnitude of attended features and red boxes show ground truth bounding boxes of query.
Figure 9: Detailed illustration of network architectures on Visual Genome experiments.
Figure 10: The qualitative results of SAN, HAN and PAN-CTX on the MREF and MDIST datasets.
Figure 11: More qualitative results of SAN, HAN and PAN-CTX on the MBG dataset.
Figure 12: Two common failure cases of attention models on the MBG dataset. (a) The models attendto a part of a larger structure which resembles the target object. (b) The models are confused bybackground distractors that are similar to the target object. Although failed, the examples show thatthe results of PAN-CTX are more visually interpretable (attended to query-like structures).
Figure 13: The qualitative results of SAN, HAN and PAN-CTX on the VG dataset. For each example,the attended images are presented in the first row while their attended feature maps are shown in thesecond row. In the case of the PAN, last two attention maps are visualized where the attention mapsat deeper layers reveal the evidence of aggregation of attention information over previous layers. Thered boxes within the final attended images represent the ground truth bounding boxes for the queryobject annotated in the VG dataset. Each object may have multiple bounding boxes annotated bydifferent annotators. The annotated answer is presented in the first column. The percentage for eachmethod means the probability of the GT answer for corresponding method.
Figure 14: More qualitative results of SAN, HAN and PAN-CTX on the VG dataset.
