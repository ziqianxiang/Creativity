Figure 1: The architecture of LeNet-5The CNN extracts the features in hierarchy and creates a spectrum of input pattern upon the outputlayer; the obtain spectrums help to categorize the input facts. The learning method of the CNNconcentrates upon extracting features of the pattern automatically.
Figure 2: The convolution map and subsample of LeNet-5 (Duffner, 2007).
Figure 4: The TICA Filters with dimensions 16×161.3	NSGA-II AlgorithmOne way for obtaining the answers of equivalent to minimize or maximize exploits theevolutionary algorithms; thus, the evolutionary algorithms to be applied instead of derivativecalculations. In the implemented algorithms, the answers instead of gene in chromosome and thechromosome called individual and finally the individual formed a population.
Figure 5: Flow chart of NSGA-II algorithm1 https://www.mathworks.com programmed by S. Mostapha Kalami Heris4Under review as a conference paper at ICLR 2017f2Pareto-FrontInfeasibleanswerdistrictAQc∙	、\d∙	∖-------------------1~► fl(b)Figure 6: Pareto-Front in NSGA-II algorithm: the (a) shows the districts of C member; the (b)shows the set optimal answers Pareto-Front in on border; the (c) shows the Pareto-Front in nextiterations for maximization problems.
Figure 6: Pareto-Front in NSGA-II algorithm: the (a) shows the districts of C member; the (b)shows the set optimal answers Pareto-Front in on border; the (c) shows the Pareto-Front in nextiterations for maximization problems.
Figure 7: Stages of the proposal.
Figure 8: Up: Digit 1 in output of LeNet-5 model and digit 1 in label. Down: Table of digit labels.
Figure 9: The five TICA filters form left to right of the TICA filters in section 1.2that resize into Dimension of 5×57Under review as a conference paper at ICLR 2017TICA filterswith5×5 dimensional25Chromosome 1BiasnπBiasNote I: TICAfilters with 5×5dimensional usedin Chromosomeof GA to insertinto the weightsof The LeNet-5'smaps in layer1
Figure 10: Showed relevance between chromosome of the NSGA- IIalgorithm and weights of layers in LeNet-5 Neural network at Pre-training stage of initializing.
Figure 11: Compare the selected RMSE (in percentage) values from table 3in experiments of iterationsIn figure 12, circumstances of the results for the practices 3 up to 7 imply plenty of errors in theMCR error. Figure 13 depicted the outcomes in the proposal in second stage from original values.
Figure 12: Compare the selected MCR (in percentage) values from table 4 in experimental initerationsTable 5: The selected MCR (in percentage) values in experiments for 10,000 samplesNo Experiments	MCR	DataSet	Number of	Number of Error	sample used	sample used for for training	final test	1	The LeNet-5 in our approach 2	LeNet-5 with backpropagation algorithm	35	MNIST	50	10,000 55	MNIST	50	10,000Finally, the novelties in the proposal were listed below:1)	The TICA filters dimension of 16×16 resized to dimension of 5×5 without being requiredof learning them for LeNet-5 scheme. It means researcher can apply TICA filters in theirconvolutional neural network with resizing them in desired condition directly; asdimension of 16×16 to 5×5.
Figure 13: The second stage in our proposal from original values without select the best them: thenominate points in fine-tuning stage shows in (a) in the last iteration for multi-objectiveoptimization in NSGA-II algorithm (the f1 axis determines the RSME and f2 axis determines theMCR); the RSME in 1000 iterations in fine-tuning stage shows in (b); the (c) shows the MCR (inpercentage) in 1000 iterations in fine-tuning stage.
