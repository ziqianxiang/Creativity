Under review as a conference paper at ICLR 2017
b-GAN: Unified Framework of Generative Ad-
versarial Networks
Masatosi Uehara, Issei Sato, Masahiro Suzuki, Kotaro Nakayama, Yutaka Matsuo
The University of Tokyo
uehara-masatoshi136@g.ecc.u-tokyo.ac.jp
sato@k.u-tokyo.ac.jp
{masa, nakayama, matsuo}@weblab.t.u-tokyo.ac.jp
Ab stract
Generative adversarial networks (GANs) are successful deep generative models.
They are based on a two-player minimax game. However, the objective function
derived in the original motivation is changed to obtain stronger gradients when
learning the generator. We propose a novel algorithm that repeats density ratio
estimation and f-divergence minimization. Our algorithm offers a new unified
perspective toward understanding GANs and is able to make use of multiple
viewpoints obtained from the density ratio estimation research, e.g. what divergence
is stable and relative density ratio is useful.
1	Introduction
There have been many recent studies about deep generative models. Generative adversarial networks
(GAN) (Goodfellow et al., 2014) is the variant of these models that has attracted the most attention. It
has been demonstrated that generating vivid, realistic images from a uniform distribution is possible
(Radford et al., 2015; Denton et al., 2015). GANs are formulated as a two-player minimax game.
However, the objective function derived in the original motivation is modified to obtain stronger
gradients when learning the generator. GANs have been applied in various studies; however, few
studies have attempted to reveal their mechanism (Goodfellow, 2014; Huszar, 2015).
Recently, f-GAN, which minimizes the variational estimate of f-divergence, has been proposed
(Nowozin et al., 2016). The original GAN is a special case of f-GAN.
In this study, we propose a novel algorithm inspired by GANs from the perspective of density ratio
estimation based on the Bregman divergence, which we refer to as b-GAN. The proposed algorithm
iterates density ratio estimation and f-divergence minimization based on the obtained density ratio.
This study make the following two primary contributions:
1.	We derive a novel unified algorithm that employs well-studied results regarding density ratio
estimation (Kanamori et al., 2012; Sugiyama et al., 2012; Menon & Ong, 2016).
2.	In the original GANs, the value function derived from the two-player minimax game does
not match the objective function that is actually used for learning the generative model. In
our algorithm, the objective function derived from the original motivation is not changed for
learning the generative model.
Table 1: Relation among GAN, f-GAN and b-GAN.
Name	D-SteP (updating Θd )	G-step (updating Θg)
GAN	Z	EStimate 二P= 	' ~ p+q		Adversarial update
f-GAN	EStimate f0(P) when f = X log X — (X + 1) log(x + 1), it is a GAN	Minimize a part of variational Estimate of f-divergence
b-GAN (this work)	Estimate p = r(x) Dual relationwith f-GAN	mine Ex〜q(x；e)[f(r(x))] Minimize f-divergence directly
1
Under review as a conference paper at ICLR 2017
The remainder of this study is organized as follows. Section 2 describes related work. Section 3
introduces and analyzes the proposed algorithm in detail. Section 4 explains the proposed algorithm
for specific cases. Section 5 reports experimental results. Section 6 summarizes our findings and
discusses future work.
2	Related work
In this study, we denote an input space as X and a hidden space as Z. Let p(x) be the distribution of
training data over X and q(X) be the generated distribution over X.
GANs (Goodfellow et al., 2014) were developed based on a game theory scenario, where two model,
i.e., a generator network and a discriminator network, are simultaneously trained. The generator
network GθG (z) produces samples with a probability density function of q(X; θG). The discriminator
network TθD (X) attempts to distinguish the samples from the training samples and that from the
generator. GANs are described as a zero-sum game, where the function v(G, T) determines the
pay-off of the discriminator and the function -v(G, T) determines the pay-off of the generator.
The discriminator TθD (X) and generator GθG (z) play the following two-player minimax game
minθG maxθD v(G, T), where v(G, T) can be expressed as follows:
Ex 〜p(x)[log TθD (X)] + Ex 〜q(x”G)[log(I - tΘd (X))].
The discriminator and generator are iteratively trained by turns. For fixed G, the optimal T(x)
is p(X)+q(x). This suggests that training the discriminator can be formulated as a density ra-
tio estimation. The generator is trained to minimize v(G, T) adversarially. In fact, maximizing
Ex〜q(x；6G)[log Tθd (x)] is preferable instead of minimizing Ex〜q(x”G)[log(1 - T⅛d (x))]. Although
this does not match the theoretical motivation, this heuristic is the key to successful learning. We
analyze this heuristic in Section 3.4.
f-GAN (Nowozin et al., 2016) generalizes the GAN concept. First, we introduce f-divergence (Ali &
Silvey, 1966). The f-divergence measures the difference between two probability distributions p and
q and is defined as
Df (p||q) = q(X)f
dX =	q(X)f (r(X)) dX,
(1)
where f(X) is a convex function satisfying f(1) = 0. Note that in the space of positive measures,
i.e., not satisfying normalized conditions, f-divergence must satisfy f0(1) = 0 due to its invariance
(Amari & Cichoki, 2010).
The function v(G, T) of f-GAN is given by
Ex〜p(x) [TθD (x)] - Ex^q(x；θG)[f * (TθD (x))],
where f* is a Fenchel conjugate of f (Nguyen et al., 2010). In Eq. 2, v(G, T) comes from,
/ q(X)f (q(χ) ) dx = * * SUP Ex 〜p[T (X)] - Ex 〜q [f *(T (X))].
(2)
(3)
Following GANs, θD is trained to maximize Eq. 2 in order to estimate the f-divergence. In contrast,
θG is trained to adversarially minimize Eq. 2 to minimize the f-divergence estimate. However, as
in GANs, maximizing Ex〜q[T(x)] is used rather than minimizing Ex〜q[-f *(T(x))]. The latter
optimization is theoretically valid in their formulation; however, they used the former heuristically.
Similar to GANs, f-GAN also formulates the training discriminator as a density ratio estimation. For
a fixed G, the optimal T(x) is f0(P), where f denotes the first-order derivative of f. When f (x) is
2
Under review as a conference paper at ICLR 2017
x logx - (x + 1) log(1 + x), f-GANs are equivalent to GANs. Table 1 summarizes GAN and f-GAN.
We denote the step for updating θD as D-step and the step for updating θG as G-step.
3	Method
As described in Section 2, training the discriminators in the D-step of GANs and f-GANs is regarded
as density ratio estimation. In this section, we further extend this idea. We first review the density
ratio estimation method based on the Bregman divergence. Then, we explain and analyze a novel
proposed b-GAN algorithm. See appendix E for recent research related to density ratio estimation.
3.1	Density ratio matching under the Bregman divergence
There have been many studies on direct density ratio estimation, where a density ratio model is fitted
to a true density ratio model under the Bregman divergence (Sugiyama et al., 2012). We briefly
review this method.
Assume there are two distributions p(x) and q(x). Our aim is to directly estimate the true density
ratio r(x) = P(X) without estimating p(x) and q(x) independently . Let r& (x) be a density ratio
model. The integration of the Bregman divergence Bf [r(x)krθ(x)] between the density ratio model
and the true density ratio with respect to measure q(x)dx is
BDf⑺lrθ)
Bf [r(x)krθ (x)]q(x)dx
(f (r (x)) - f (rθ(x)) - f0 (rθ(x)) (r(x) - rθ(x))) q(x)dx.
(4)
We define the terms related to r in BDf (r ||r&) as
BRf(rθ)
(f0(rθ(x))rθ(x) - f(rθ(x))) q(x)dx -	f0 (rθ(x)) p(x)dx
f0(rθ(x)) (rθ(x)q(x) - p(x)) dx - Df (qrθ kq).
(5)
(6)
Thus, estimating the density ratio problem turns out to be the minimization of Eq. 5 with respect to θ.
3.2	Motivation
In this section, we introduce important propositions required to derive b-GAN. Proofs of propositions
are given in Appendix C. The following proposition suggests that the supremum of the negative of
Eq. 5 is equal to the f-divergence between p(x) and q(x).
Prop 3.1. The following equation holds:
Eq hf(P≡) i
=SUpEx〜p[f (rθ(x))] — Ex〜q[(f0(rθ(x))rθ(X)- f(rθ(x)))]∙
rθ
(7)
The right side of Eq. 7 reaches the supremum when rθ (x) = r(x) is satisfied.
It has been shown that the supremum of negative of Eq. 5 is equivalent to the supremum of Eq. 2.
Interestingly, the negative of Eq. 5 has a dual relation with the objective function of f-GAN, i.e., Eq.
2.
Prop 3.2. Introducing dual coordinates TθD = f 0 (rθ)(Amari & Cichoki, 2010) yields the right side
of Eq. 5 from Eq. 2.
Prop 3.2 shows that the D-step of f-GAN can be regarded as the density ratio estimation because Eq.
5 expresses the density ratio estimation and Eq. 2 is a value function of f-GAN.
3
Under review as a conference paper at ICLR 2017
3.3	B-GAN
Our objective is to minimize the f-divergence between the distribution of the training data p(x) and
the generated distribution q(x). We introduce two functions constructed using neural networks:
rθD (x) : X → R parameterized by θD, and GθG (z) : Z → X parameterized by θG. Measure
q(x; θG)dx is a probability measure induced from the uniform distribution by GθG (z). In this case,
rθD (x) is regarded as a density ratio estimation network and GθG (z) is regarded as a generator
network for minimizing the f-divergence between p(x) and q(x).
Motivated by Section 3.2, we construct a b-GAN using the following two steps.
1.	Update θD to estimate the density ratio between p(x) and q(x; θG). To achieve this, we
minimize Eq. 5 with respect to rθ (x). In this step, the density ratio model rθ (x) in Eq. 5
can be considered as rθD (x) in this step.
2.	Update θG to minimize the f-divergence Df (p||q) between p(x) and q(x; θG) using the
obtained density-ratio. We are able to suppose that q(x; θG)rθ (x) is close to p(x). Instead
of Df(p∣∣q),we update Θg to minimize the empirical approximation of Df(qr ||q).
The b-GAN algorithm is summarized in Algorithm 1, where B is the batch size. In this study, a
single-step gradient method (Goodfellow et al., 2014; Nowozin et al., 2016) is adopted.
Algorithm 1: b-GAN
for number of training iterations do
sample X = {x1, ..., xB} from p(x) and Z = {z1, ..., zB} from an uniform distribution.
D-step: Update θD :
θD	+1 = θD - RoD (B X f 0 (rθD (G(Zi) ArΘd (G(Ziy)- f(rrθD (G(Zi))) - f0(rθD (Xi)))
G-step: Update θG:
θtt+1 = θG - JG(B X f (r(Gθc(Zi)))).
end for
In the D-step, the proposed algorithm estimates P toward any divergence; thus, it differs slightly from
the D-step of f-GAN because the estimated values, i.e., f 0(P), are dependent on the divergences. We
also introduce an f-GAN-like update as follows. As mentioned in Section 2, we have two options in
the G step.
1.	D-step: minimize Ex〜p(χ)[-f0(3 (x))] + Ex〜q(x)[f'(‰ (x))rθD (x) — f(rθD (x))] w.r.t
θD .
2.	G-step: minimize Ex〜q(x*G)[-f 0(r(x))] or Ex〜q(x”G)[—f0(r(x))r(x) + f(r(x))] w.r.t
θG.
3.4	Analysis
Following Goodfellow et al. [2014], we explain the validity of the G-step and D-step. We then
explain the meaning of b-GAN. Finally, we analyze differences between b-GAN and f-GAN.
The density ratio is estimated in the D-step. The estimator of r(x) is an M-estimator and is asymptot-
ically consistent under the proper normal conditions (Appendix E.1).
In the G-step, we update the generator as minimizing Df (p||q) by replacing p(x) with rθ(x)q(x).
We assume that q(x; Θg) is equivalent to P(X) when Θg = θ*, q(x; Θg) is identifiable, and the
optimal r(X) is obtained in the D-step. By our assumption, the acquired value in the G-step is θ,
which minimizes the empirical approximation of Df(r(x)q(x; θG)kq(x; Θg)) = Ex〜q(x；0G)[r(x)].
4
Under review as a conference paper at ICLR 2017
When Θg is equal to θ*, this equation is equal to 0. The estimator θ can be considered as a kind of
Z-estimator.
Usually, we cannot perform only a G-step because we do not know the form of p(x) and q(x). In
b-GAN, Df (p||q) can be minimized by estimating the density ratio r(x) without estimating the
densities directly.
In fact, the r(x) obtained at each iteration is different and not optimal because we adopt a single-step
gradient method (Nowozin et al., 2016). Thus, b-GAN dynamically updates the generator to minimize
the f-divergence between p(x) and q(x). As mentioned previously, f(x) must satisfy f0(1) = 0 in
this case because we cannot guarantee that rθ (x)q(x) is normalized.
Similar to GANs, the D-step and G-step work adversarially. In the D-step, rθ (x) is updated to fit the
ratio between p(x) and q(x). In the G-step, q(x) changes, which means rθ (x) becomes inaccurate in
terms of the density ratio estimator. Next, rθ(x) is updated in the D-step so that it fits the density
ratio of p(x) and the new q(x). This learning situation is derived from Eq. 6 , which shows that θD is
updated to increase Df (qrθ kq) in the D-step. In contrast, θG is updated to decrease Df (qrθ kq) in
the G-step.
In Section 3.3, we also introduced a f-GAN-like update. Three choices can be considered for the
G-step:
⑴Ex〜q(x%)[f(r(x))],⑵Ex〜q3θG)[-f0(r(x))],⑶Ex〜q(xg)[-f0(r(x))r(x)+ f(r(x))].
Note that f is a convex function, f(1) = 0, and
f0(1) = 0. It is noted in (Nowozin et al., 2016) that
case (2) works better than case (3) in practice. We also
confirm this. The complete reason for this is unclear.
However, we can find a partial reason by differentiating
objective functions with respect to r. The derivatives
of the objective functions are
(1)f 0(r), (2) - f 00(r), (3) - rf 00(r).
All signs are negative when r(x) is less than 1. Usu- Figure 1: The graph of (1), (2), (3) when f
ally, when x is sampled from q(x), r(x) is less than 1. is Pearson divergence
Therefore, we speculate that r(x) is less than 1 during
most of the learning process when x is sampled from
q(x). When r(x) is small, the derivative is also small in (3) because the term r(x) is multiplied.
Therefore, the derivative tends to be small in (3). The mechanism pulling r(x) to 1 does not work
when r(x) is small. Thus, the case of (3) does not work well. A similar argument was proposed by
Goodfellow et al. (2014) and Nowozin et al. (2016).
In our experimental case of (1) and (2) work properly (Section 5). The reason case (2) works is that
function -f 0(r) behaves like an f-divergence and the derivative is large when r(x) is small. However,
we cannot guarantee that -f 0(r) satisfies the conditions of f-divergence between positive measures,
i.e, -f 0(r) is a convex function and -f 00 (1) = 0. If the derivatives in case (2) are negative when r(x)
is greater than 1, there is a possibility that the mechanism pulling r(x) to 1 does not occur. In contrast,
in case (1), when r(x) is greater than 1, the derivatives are positive, therefore, the mechanism pulling
r(x) to 1 occurs. This prevents generators from emitting the same points. We can expect the same
effects as -minibatch discrimination- (Salimans et al., 2016).
Throughout the analysis, we can easily extend the algorithm of b-GAN by using different divergences
in the G-step and D-step. The original GAN can be regarded as one of such algorithms.
4	Algorithms for specific cases
We adopt α-divergence in the positive measure space as the f-divergence (Amari & Cichoki, 2010).
Here, we explain specific algorithms when f is α-divergence. Then, we explain some heuristics used
in b-GAN.
5
Under review as a conference paper at ICLR 2017
4.1	ALGORITHMS WITH α-DIVERGENCE
In α-divergence, f(r) in Eq. 1 is
I 1-4α2 (1-r 1+2α) + 1⅛ (r- 1)	(α = ±1)
fα(r) = r logr - r + 1	(α = 1)
I — log r + r _ 1	(α = - 1).
(8)
The objective function derived from α-divergence is summarized as follows.
Table 2: The summary of objective function
alpha	D-step	G-step
1 (KL divergence)	Ex-q(x) [rθD (X),- 1] - Ex-p(x) [log rrθD (X)]	Eχ~q3θG)[r(X) log r(X)- r(f) + 1]
3 (Pearson divergence)	Ex-q(x) [0∙5rθD (X) - 0.5] - Eχ~p(χ)卜6勺(X) - 1]	Eχ~q3θG)[0.5(r(X) - 1)2]	-
-1 (Reversed KL divergence)	Ex~q(x)[log rθD (X)] - Ex~p(x)[-rg ^⑺]	Eχ~qgθG) [- log(r(X)) + r(X) - 1]
•	α = -1 In this case, α-divergence is a Kullback-Leibler (KL) divergence. Density
ratio estimation via the KL divergence corresponds to the Kullback-Leibler Importance
Estimation Procedure (Sugiyama et al., 2012). In the G-step of an f-GAN-like update, the
objective function is Ex~q(x；©G)[- logr(x)] or Eχ^q(χ；θG)[1 - r(x)].
•	α = 3 Density ratio estimation via the Pearson divergence corresponds to the Least-
Squares Importance Fitting (Yamada et al., 2011). Itis more robust than under KL divergence
(Yamada et al., 2011; Dawid et al., 2015). This is because Pearson divergence does not
include the log term. Hence the algorithm using Pearson divergence should be more stable.
In the G-step of f-GAN-like update, the objective function is Eχ^q(χ；θG)[1 — r(x)] or
Eχ~q3θG)[0.5 — 0.5r(x)2].
•	α = -1 Estimating the density ratio using reversed KL divergence seems to be unstable
because reversed KL-divergence is mode seeking and the generated distribution changes
at each iteration. However, it is preferable to use reversed KL divergence when generating
realistic images (Huszar, 2015). In the G-step of an f-GAN-like update, the objective
function is Eq(x”G)[志]or Eq(x；6G)[— logr(x)].
4.2	Heuristics
We describe some heuristic methods that work for our experiments. The heuristics introduced here
are justified theoretically in Appendix C.
In the initial learning process, empirical distribution p and generated distribution q are completely
different. Therefore, the estimated density ratio r(χ) = P(X) is enormous when X is taken from P
and tiny when x is taken from q . It seems that the learning does not succeed in this case. In fact, in
our setting, when the final activation function of rθD (x) is taken from functions in the range (0, ∞),
b-GAN does not properly work. Therefore, we use a scaled sigmoid function such as a two-times
sigmoid function. A similar idea has also been used in (Cortes et al., 2010).
As mentioned, density ratio P(I) is extremely sensitive. To avoid this problem, in the D-step of the
KL-divergence, We also conducted experiments wherein We estimated ɑp+(P-α)q (where α is small.)
rather than p(∣). The same idea is introduced in the covariate shift situation (Sugiyama et al., 2013).
A similar idea has also been used for GAN learning (Salimans et al., 2016) and class probability
estimation (Reid & Williamson, 2010).
6
Under review as a conference paper at ICLR 2017
5 Experiments
We conducted experiments to establish that the proposed algorithm works properly and can success-
fully generate natural images. The proposed algorithm is based on density ratio estimation; therefore,
knowledge regarding the density ratio estimation can be utilized. In the experiments, using the
Pearson divergence and estimating the relative density ratio is shown to be useful for stable learning.
We also empirically confirm our statement in Section 3.4, i.e., f-divergence is increased when learning
θD and decreased when learning θG.
5.1	Settings
We applied the proposed algorithm to the CIFAR-10 data set (Krizhevsky, 2009) and Celeb A data
set (Liu et al., 2015) because they are often used in GAN research (Salimans et al., 2016; Goodfellow
et al., 2014). The images size are 32 × 32 pixels. All results in this section are analyzed based on the
results of the CIFAR-10 data set. The results for the Celeb A data set are presented in Appendix B.
Our network architecture is nearly equivalent to that of previous study (Radford et al., 2015) (refer to
the appendix A,B for details). Note that unless stated otherwise, the last layer function of rθD (x) is a
sigmoid function multiplied by two. We used the TensorFlow for automatic differentiation (Abadi
et al., 2015). For stochastic optimization, Adam was adopted (Kingma & Ba, 2014).
5.2	Results
Figure 2: Comparative results: estimated density ratio values rθD (x) from the training data (red), the
estimated density-ratio values rθD (x) from the generated distribution (green), generator losses taken
in the D-step and G-step (blue). The top, second, and bottom rows show rθD (x) and the losses of
b-GAN with the Pearson divergence, KL divergence, modified KL divergence (relative density ratio
estimation version, α = 0.2), and reversed KL divergence, respectively.
Figure 2 shows the density ratio estimate rθD (x) and loss values of the generators. For each
divergence, we conducted four experiments with 40,000 epochs, where the initial learning rate value
was fixed (5 × 10-5) with the exception of reversed KL divergence. These results show that the
b-GANs using Pearson divergence are stable because the learning did not stop. The same results
have been reported in the research into density ratio estimation (Yamada et al., 2011). In contrast,
b-GANs using the KL divergence are unstable. In fact, the learning stopped between the 20,000th
and 37,000th epoch when the learning rate was not as small. When we use a heuristic method, i.e.,
7
Under review as a conference paper at ICLR 2017
Figure 3: Density ratio value rθD (x) and generator losses of b-GAN when the last output function is
a sigmoid function multiplied by 5.
Figure 4: Divergence differences between D-step and G-step: b-GAN with Pearson divergence (left),
b-GAN with KL divergence (right) .
estimating the relative density ratio as described in Section 4.2, this problem is solved. For reversed
KL divergence, the learning stopped too soon if the initial learning rate value was 5 × 10-5. If the
learning rate was 1 × 10-6, the learning did not stop; however, it was still unstable.
In Figure 2, the last layer activation function of the b-GANs is a twofold sigmoid function. In Figure
3, we use a sigmoid function multiplied by five. The results indicate that the estimated density ratio
values approach one. We also confirm that the proposed algorithm works with sigmoid functions at
other scales.
Figure 4 shows the estimated f-divergence Df(qr ||q) before the G-SteP subtracted by Df(qr ||q)
after the G-step. Most of the values are greater than zero, which suggests f-divergence decreases at
every G-steP iteration. This observation is consistent with our analysis in Section 3.4.
Note that learning is successful with an f-GAN-like uPdate when minimizing Eq [-f0(r)]. However,
the learning f-GAN-like uPdate when minimizing Eq [f(r) - rf0 (r)] did not work well for our
network architecture and data set.
6 Conclusions and future work
We have ProPosed a novel unified algorithm to learn a deeP generative model from a density ratio
estimation PersPective. Our algorithm Provides the exPerimental insights that Pearson divergence and
estimating relative density ratio are useful to imProve the stability of GAN learning. Other insights
regarding density ratio estimation would also be also useful. GANs are sensitive to data sets, the form
of the network and hyPer-Parameters. Therefore, Providing methods to imProve GAN learning is
meaningful.
Related research to our study that focuses on linking density ratio and a GAN, has been Performed by
exPlaining sPecific algorithms indePendently (Mohamed & Lakshminarayanan, 2016). In contrast,
our framework is more unified.
In future, the following things should be considered.
•	What is the oPtimal divergence? In research regarding density ratio estimation, the Pearson
divergence (α = 3) is considered robust (Nam & Sugiyama, 2015). We emPirically and
theoretically confirmed the same ProPerty when learning deeP generative models. It is also
rePorted that using KL-divergence and reversed KL-divergence is not robust as scoring rules
(Dawid et al., 2015). For generating realistic images, the reversed KL divergence (α = -1)
is Preferred because it is mode seeking (Huszar, 2015). However, if α is small, the density
ratio estimation becomes inaccurate. For a robust density ratio, using Power divergence has
also been ProPosed (Sugiyama et al., 2012). The determination of the oPtimal divergence is
a Persistent Problem (APPendix E).
8
Under review as a conference paper at ICLR 2017
•	What should be estimates in D-step? In the D-step of b-GAN, r(x) is estimated. However,
in the original GAN, r(x)/(1 + r(x)) is estimated. As unnormalized models, the latter is
more robust than estimating r(x) (Pihlaja et al., 2010) (Appendix E.7).
•	We can consider algorithms that use different divergences in the G-step and D-step. In that
case, choice of the divergences are more diverse. Original GANs are described in such
algorithms as mentioned in Section 3.5.
•	We can consider algorithms that use multiple divergences. This may improve the stability of
learning.
•	When sampling from q(x), if the objective is sampling from real data p(x), r(x) should be
multiplied. Hence, the density ratio is also useful when using samples from q(x). How to
use samples obtained from generators meaningfully is an remaining important problem.
Acknowledgements
The authors would like to thank Masanori Misono for technical assistance with the experiments. We
are grateful to Masashi Sugiyama, Makoto Yamada, and the members of the Preferred Networks
team.
References
M. Abadi, A. Agarwal, and P Barham. TensorFlow: Large-scale machine learning on heterogeneous
systems, 2015. URL http://tensorflow.org/. Software available from tensorflow.org.
M. Ali and S. Silvey. A general class of coefficients of divergence of one distribution from another.
Journal Royal Statistical Society Series B, pp. 131142, 1966.
S. Amari and A. Cichoki. Information geometry of divergence functions. Bull. Polish. Acad. Sci., 58:
183-195, 2010.
P.L. Bartlett, M. I. Jordan, and J.D. McAuliffe. Convexity, classification and risk bounds. Journal of
the American Statistical Association, 101(473):138156, 2006.
A. Basu, I. R. Harris, N. L. Hjort, and M. C. Jones. Robust and efficient estimation by minimising a
density power divergence. Biometrika, 85:549559, 1998.
C. Cortes, Y. Mansour, and M. Mohri. Learning bounds for importance weighing. In Advances in
Neural Information Processing System (NIPS), 2010.
A. P. Dawid and M. Musio. Theory and applications of proper scoring rules. Metron, 72:169183,
2014.
A. P. Dawid, M. Musio, and L. Ventura. Minimum scoring rule inference. Scandinavian Journal of
Statistics, 2015.
E. Denton, S. Chintala, A. Szlam, and R. Fergus. Deep Generative Image Models using a Laplacian
Pyramid of Adversarial Networks. In Advances in Neural Information Processing Systems (NIPS),
June 2015.
G. K. Dziugaite, D. M. Roy, and Z. Ghahramani. Training generative neural networks via maximum
mean discrepancy optimization. In Proc. Conf. on Uncertainty in Artificial Intelligence (UAI),
2015.
K. Fukumizu, F. Bach, and M. Jordan. Dimensionality reduction for supervised learning with
reproducing kernel hilbert spaces. Journal of Machine Learning Research, 5:7399, 2004.
I. Goodfellow, M. Pouget-Abadie, J.and Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and
Y. Bengio. Generative adversarial nets. In In Advances in Neural Information Processing Systems
(NIPS), pp. 2672-2680. 2014.
I. J. Goodfellow. On distinguishability criteria for estimating generative models. ArXiv e-prints, 2014.
URL https://arxiv.org/pdf/1412.6515v4.pdf.
A. Gretton, K. Borgwardt, M. Rasch, B. Schoelkopf, and A. Smola. A kernel two-sample test. Journal
of Machine Learning Research,, 13:723773, 2012.
M. Gutmann and A. Hyvarinen. Noisecontrastive estimation: A new estimation principle for
unnormalized statistical models. In Artificial Intelligence and Statistics Conference (AISTATS),
2010.
M.U. Gutmann and J. Hirayama. Bregman divergence as general framework to estimate unnormalized
statistical models. In Uncertainty in Artificial Intelligence (UAI 2011), 2011.
F. Hayashi. Econometrics. Princeton University Press, 1997.
P. J. Huber and E. M. Ronchetti. Robust statistics. John Wiley & Sons, 2009.
9
Under review as a conference paper at ICLR 2017
F. Huszar. How (not) to Train your Generative Model: Scheduled Sampling, Likelihood, Adversary?
ArXiv e-prints, 2015. URL http://arxiv.org/pdf/1511.05101v1.pdf.
T. Kanamori, T. Suzuki, and M. Sugiyama. Divergence estimation and two-sample homogeneity test
under semiparametric density-ratio models. IEEE Trans. Inform. Theory, 58(2):708720, 2012.
T. Kanamori, T Suzuki, and M. Sugiyama. Divergence estimation and two-sample homogeneity
test under semiparametric density-ratio models. IEEE Transactions on Information Theory, 58:
708-720, 2012.
D. Kingma and J. Ba. Adam: A Method for Stochastic Optimization. In International Conference on
Learning Representations (ICLR), 2014.
A. Krizhevsky. Learning multiple layers of features from tiny images. 2009.
Y. Li, K. Swersky, and R. Zemel. Generative moment matching networks. In International Conference
on Machine Learning (ICML), 2015.
Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning face attributes in the wild. In Proceedings of
International Conference on Computer Vision (ICCV), 2015.
A.K. Menon and C.S. Ong. Linking losses for density ratio and class-probability estimation. In In
International Conference on Machine Learning (ICML), 2016.
S. Mohamed and B. Lakshminarayanan. Learning in Implicit Generative Models. ArXiv e-prints,
October 2016.
M. Mohri, A. Rostamizadeh, and A. Talwalkar. Foundation of Machine Learning. The MIT press,
2012.
H. Nam and M. Sugiyama. Direct density ratio estimation with convolutional neural networks with
application in outlier detection. IEICE Transactions, 98:1073-1079, 2015.
X. Nguyen, M Wainwright, and M. Jordan. Estimating divergence functionals and the likelihood
ratio by convex risk minimization. IEEE Transactions on Information Theory, 2010.
S.	Nowozin, B. Cseke, and R. Tomioka. f-GAN: Training Generative Neural Samplers using
Variational Divergence Minimization. ArXiv e-prints, 2016. URL https://arxiv.org/
pdf/1606.00709v1.pdf.
M. Pihlaja, M.U. Gutmann, and A Hyvarinen. A family of computationally efficient and simple esti-
mators for unnormalized statistical models. In Proc. Conf. on Uncertainty in Artificial Intelligence
(UAI2010), 2010.
J. Qin. Inferences for case-control and semiparametric two-sample density ratio models. Biometrika,
85(3):619639, 1998.
A. Radford, L. Metz, and S. Chintala. Unsupervised Representation Learning with Deep Convolu-
tional Generative Adversarial Networks. In International Conference on Learning Representations
(ICLR), 2015.
M.D Reid and R.C Williamson. Composite binary losses. Journal of Machine Learning Research,
11:23872422, 2010.
M.D Reid and R.C Williamson. Information, divergence and risk for binary experiments. Journal of
Machine Learning Research, 12:731817, 2011.
T.	Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and X. Chen. Improved Techniques
for Training GANs. ArXiv e-prints, June 2016.
I.	Sergey and S. Christian. Batch normalization: Accelerating deep network training by reducing
internal covariate shift. 2015. URL https://arxiv.org/pdf/1502.03167v3.pdf.
I Steinwart. On the influence of the kernel on the consistency of support vector machines. Journal of
Machine Learning Research, 2:6793, 2011.
M. Sugiyama, T. Suzuki, and T. Kanamori. Density ratio matching under the bregman divergence: a
unified framework of density ratio estimation. Annals of the Institute of Statistical Mathematics,
64:1009-1044, 2012.
M. Sugiyama, M. Yamada, and M.C. du Plessis. Learning under non-stationarity:covariate shift and
class-balance change. WIREs Computational Statistics, 5:465-477, 2013.
M. Yamada, T. Suzuki, T. Kanamori, H. Hachiya, and M. Sugiyama. Relative density-ratio estimation
for robust distribution comparison. In Advances in Neural Information Processing Systems (NIPS),
pp. 594-602, 2011.
J.	Zhao, M. Mathieu, and Y. LeCun. Energy-based Generative Adversarial Network. ArXiv e-prints,
September 2016.
10
Under review as a conference paper at ICLR 2017
A Cifar- 1 0 dataset
Figure 5 shows samples generated randomly using b-GANs. These results indicate that b-GANs can
create natural images successfully. We did not conduct a Parzen window density estimation for the
evaluations because of Theis et al., [2016].
Figure 5: (Left) original images set, (middle) a set of images generated based on Pearson divergence,
and (right) a set of images based on the KL divergence.
Here, we describe the network architecture of rθD (x) and GθG (z) used in the b-GAN. BN is the
batch normalization layer (Sergey & Christian, 2015).
A.1 rθD (x)
x→ Conv(3, 64) → lRelu → Conv(64, 256) →BN→ lRelu → Conv(256, 512) → BN → lRelu →
Reshape(4 × 4 × 512) → Linear(4 × 4 × 512, 1) → 2 × Sigmoid
A.2 GθG (z)
z → Linear(100,4 × 4 × 512) → BN → Relu → Reshape(4, 4, 512) → Conv(512, 256) → BN →
Relu → Conv(256, 64) → BN → Relu → Conv(64, 3) → tanh
B Celeb A dataset
We also applied our algorithm to the Celeb A data set. The images are resized and cropped to 64 × 64
pixcels. Figures 6 and 7 show samples randomly generated using b-GANs. The Network architecture
is as follows.
B.1	rθD (x)
x→ Conv(3, 64) → lRelu → Conv(64, 128) →BN→ lRelu → Conv(128, 256) → BN → lRelu →
Conv(256, 512) → BN → lRelu → Reshape(4 × 4 × 512) → Linear(4 × 4 × 512, 1) → 2×Sigmoid
B.2	GθG (z)
z → Linear(64, 4 × 4 × 512) → BN → Relu → Reshape(4, 4, 512) → Conv(512, 256) → BN →
Relu → Conv(256, 128) → BN→ Relu → Conv(128, 64) →BN→Relu → Conv(64, 3) → tanh
11
Under review as a conference paper at ICLR 2017
Figure 6: Pearson divergence
Figure 7: KL divergence
C Proof of propositions in Section 3
C.1 Proof of Prop 3.1
From Eq. 4, the following equation holds,
Ex~p [f 0 (rθ (X))] - Ex~q [(f 0(rθ (X))rθ (X)- f (rθ (X)))] = -BDf (rllrθ ) + Eq hf (P(X)) i . (9)
Using BDf (r∣∣rθ) ≥ 0 yields Eq. 7. We have BDf (r∣∣rθ) = 0 When r is equal to re. Thus, the
equality holds if and only if r is equal to rθ .
C.2 Proof of Prop3. 2
r.h.s of Eq.2 = Eχ~p(χ)[f(re(x))] - Eχ~q(χ)[f* (f(r(x)))]	(10)
=Ex~p(x)[f0Crθ(X))] - Ex~q(x)[fCrθ (X))rθ (X)- f (rθ (X))]
=Ex~p(x)[f0 (re(x))] - Ex~q(x)[(f0(re(/))re(x) - f(r (x)))]
= the negative of Eq. 5
In the derivation, we have used the following equation f * (f0(re(X))) = f (re(X))re(x) - f (re(x)).
D	Explanation of heuristics using Rademacher complexity
Here, we justify three points using Rademacher complexity. All techniques used are described in the
literature (Mohri et al., 2012).
•	Pearson divergence is preferable to KL divergence in density ratio estimation.
•	Relative density ratio is useful (introduced in Sec 4.2).
•	The meaning of bounding the last output functions of discriminators (introduced in Sec 4.2).
Our objective is estimating r(∕) = P(X). We define hypothesis sets as H. In Section 3.4, we assume
H as parametric models for simplicity. In this section, we do not restrict H to parametric models. We
define r0 and rs as
12
Under review as a conference paper at ICLR 2017
r0	= argminh∈HBRf (h)
rs = argminh∈HBRf (h),
where BR is an empirical approximation of BR. Note that BRf (h) reaches minimum values if and
only if r = h holds. We want to analyze BRf (rs) - BRf (r). The regret, i.e., BRf (rs) - BRf (r)
can be bounded as follows:
BRf(rs)-BRf(r) = BRf(rs)-BRf(r0)+BRf(r0)-BRf(r)
._ _ , _ . _>— ,. . _ , 、 _ _ ,.
≤ 2sup ∣BRf(h) — BRf (h) + BR∕(r0) — BRf (r).	(11)
h∈H
The first term of Eq. 11 is bounded by uniform law of large numbers. To do that, assume that
all elements in H are bounded by constant C . First, we consider the case when f is the Pearson
divergence. In that case, BRf (h) is
Ex 〜p(x) [0.5h(x)2] — Ex 〜q(χ) [h(x)].	(12)
We denote the Rademacher complexity of H as Rm,q when x is sampled from q(x) and the sample
size is m. The first term of Eq. 12 is upper bounded by Talagrand’s lemma. For any δ with probability
as least 1 — δ, we have
SuP |Ex〜p(x)[0.5h(x)2]—
h∈H
ɪ X 0.5h(xi)21 ≤ CRm,p(H) + 0.5C2
(13)
where samples are taken from p(x) independently. the fact that 0.5h(x)2 is C-Lipchitz over the
interval (0, C) is used (C is a constant real number). The first term of Eq. 12 is upper-bounded by
Talagrand’s lemma. For any δ with probability at least 1— δ, we have
SuP |Ex〜q(x)[h(x)]—
h∈H
m X h(Xi) l≤ Rm,q
(H)+C
(14)
where samples are taken from q(x) independently. By combining Eq. 13 and Eq. 14, for any δ with
probability as least 1 — δ, the first term of Eq. 11 is bounded by
2CRm,p(H)+2Rm,q(H)+(C2+2C)
(15)
When f is the KL-divergence, BRf (h) is
Ex 〜q(x) [h(x)] — Ex 〜p(x) [log h(x)].	(16)
The second term of Eq. 16 cannot be bounded because log(x) is no longer Lipchitz continuous
over (0, C). This explains why Pearson divergence is preferable to KL divergence in density ratio
estimation. However, if h(x) is lower-bounded by the constant real number C, the problem is solved.
Using the relative density ratio has the same effect.
In our setting, r(x) is a sigmoid function multiplied by C. If C is large, the approximation error,
i.e., BRf (r0) — BRf (r) is small. However, there is a possibility that the estimation error increases
according to Eq. 15, which may lead to the learning instability.
13
Under review as a conference paper at ICLR 2017
E S ummary of density ratio estimation research
In this section, we review researches related to density ratio estimation, entangling them to b-GAN.
The Eq. 4 has also been used in class probability density estimation and unnormalized models
research. We briefly describe research that is closely connected to density ratio estimation and extract
ideas that can also be applied to b-GAN.
E.1 Notation
We summarize notations frequently used in this section.
•	r(x) = p(x)/q(x) Density ratios between p(x) and q(x). In b-GAN, p(x) is the probability
density function of ”real data” and q(x) is the probability density function of ”generated
data”.
•	xi(n) Samples taken from p(x).
•	xi(d) Samples taken from q(x).
•	D = (p, q, π) The joint distribution of X and Y . The variable X has the the mixture
distribution of πp + (1 - π)q and Y is a binary label taking values in {-1, +1} which
satisfies π = P(Y = 1); thus, (p, q) = (P(X|Y = 1),P(X|Y = -1)) holds.
•	η The Bayes optimal estimator P(Y = 1|X) for binary classification.
•	l : {-1, 1} × [0, 1] → R Loss function
•	h1 : X → [0, 1] An element of hypothesis sets. In this case, the objective is estimating
P(Y = 1|x).
•	hg : X → V An element of hypothesis sets. V is a subset of R. Note that h1 is a special
case of hg .
•	Ψ : [0, 1] → V A link function.
•	k(χ, ∙) A positive definite and characteristic (Fukumizu et al., 2004) kernel on the measurable
space of R.
•	Hk A reproducing kernel Hilbert space with a kernel k (Steinwart, 2011). An inner product
in Hk is〈•，•).
•	Φ : R → Hk A characteristic function:X → k(x, ∙).
•	Xp A random variable with probability density function p.
•	Bf [pkq] Bregman divergence with f between p and q.
E.2 Theoretical aspects of density ratio estimation
Following Kanamori et al. (2012), we expand the explanation of density ratio estimation. As noted in
Section 3, the objective function of density ratio estimation is
nn
BR (rθ) =—x f(rθ (Xy)))rθ (Xy))-f(rθ (Xy))))-—X f 卜°(X(n))),
n i=1	n i=1
(17)
which is an empirical approximation of Eq. 5. The estimator θn is obtained by minimizing Eq. 17.
The estimator θn is an M-estimator because Eq. 17 is a form of 1 PZi m(∕), where m is a function
of X and X 〜(婢,Xn holds. The estimator θn satisfies consistency under mild conditions (see Prop
7.4. (Hayashi, 1997)). The essential condition is the expectation of Eq. 17 is uniquely minimized
when rθ is equivalent to the true density ratio r. We have proved that proposition in Appendix D.
Asymptotic normality also holds under suitable conditions (see Prop 7.8. (Hayashi, 1997)).
14
Under review as a conference paper at ICLR 2017
By differentiating Eq. 17 with respect to θ, the above method can be regarded as a type of moment
matching as follows:
aBfr) = 1 X f 00(rθ (Xicr))rθ (Xdd)rθ (Xy))-1X f 00Crθ (Xn))rθ(X(n)).	(18)
n i=1	n i=1
The estimator θn is attained when Eq.18 is equal to 0. By substituting f0(rθ(xi)rθ(Xi) with S(Xi),
Eq. 18 is reduced to be
nn
n X S(Xid))rθ(Xid)) - n X S(Xin)).	(19)
n i=1	n i=1
The above Eq. 18 is a form of moment matching.1 What is the optimal S(X)? Here, we focus on the
variance of the estimator (efficiency). It is known that the Eq. 17 derived from the logistic model
is known to be optimal (Qin, 1998). It is a natural consequence because the logistic model can
be considered as a maximum likelihood and maximum likelihood reaches the Cramer-Rao bound
asymptotically. Typically, general moment matching (GMM) achieves the lower bound when the
estimating equation is the score of observations, i.e., when GMM is identical to maximum likelihood.
Efficiency is not the absolute criterion for choosing losses. For example, when there are many outliers
in the data, robustness is more important than efficiency. In reality, an M estimator was introduced in
the contest of robust statistics (Huber & Ronchetti, 2009).
E.3 Class probability estimation
We have explained density ratio estimation, starting with the Bregman divergence. Importantly,
density-ratio estimation is equivalent to class probability estimation. For details, see (Reid &
Williamson, 2011; 2010; Dawid & Musio, 2014; Menon & Ong, 2016).
As in Section E.1, we introduce the variable Y . The joint distribution of X and Y is denoted as
D = (p, q, π). Class probability estimation can be regraded as a minimization problem of the
empirical estimation of the full risk E(χ,γ)〜d[1(Y, h1)], which is denoted L(h1; D,l) (h1 is a
hypothesis element). When the hypothesis h1, which minimizes E(χ,γ)〜D [l(Y, h1)], is the Bayes
optimal estimator η(X) uniquely, such a loss is called a proper loss.
A proper loss is naturally extended to a composite proper loss by introducing a link function Φ. In this
case, the objective is estimating Φ(η(X)) correctly. The estimator is obtained by the empirical mini-
mization of full risk E(χ,γ)〜D [lφ(Y, hg)] when lφ(Y, hg) means l(Y, Φ-1(hg(X))) and Φ(A1(x))
is the same as hg(x). When the hypothesis hg(x), which minimizes E(χ,γ)〜D[lφ(Y, hg)], is the
Bayes optimal estimator Φ(η(X)) uniquely, such a loss is called a proper composite loss with a link
function Φ.
The conditional risk (conditioned on x) EY〜η [lφ(Y, hg)] can be decomposed to
EY〜η[lφ(Y, hg)] = ηLι(hg) + (1 - η)L-i(hg).	(20)
The conditional Bayes risk is
ηL1(Φ(η(X))) + (1 - η)L-1(Φ(η(X))) = ηλ+1 (η) + (1- η)λ-1(η),	(21)
where λ+1(X) = L1(Φ(X)) and λ-1(X) = L-1(Φ(X)). We set Eq. 21, i.e., Xλ+1(X)+(1-X)λ-1(X)
as c(X). The regret of the composite proper loss can be written using Bregman divergence
L(hg； D,l) — L(Φ ◦ n； D,l) = EX [Bc[η(X)kΦ-1(hg(X))]] .	(22)
1In usual moment matching, s(x) is not be dependent on the form of probability density function. However,
it depends on the form of rθ in this case.
15
Under review as a conference paper at ICLR 2017
The problem of minimizing the composite proper loss turns out be the density ratio estimation
problem by setting Φ(x) as u/(1 - u) and π = 0.5 (Menon & Ong, 2016). In this case, the LHS of
Eq. 22 can be written as EX〜q [B* [Φ(η(X))∣Ihg (X)]](Φ(η(X)) = r(x)), where c0 is given by
C : X → (1 + x)c( —x-).
1+x
The equation EX〜q [B* [r(X)∣hg(X)]] corresponds to Eq. 4 by substituting c0 with f and hg with
rθ.
What loss is the optimal loss? The above loss can be written in another form using weight by
transforming Eq. 22 further. Determining what loss is better has been analyzed from the perspective
of weight. For example, Reid & Williamson (2010) proposed the ”minimal symmetric convex
proper loss” for surrogate loss. Regarding density ratio, Menon & Ong (2016) suggest that Pearson
divergence is robust because the weight of Pearson divergence is uniform. However, according to their
covariate shift experiment, Pearson divergence was not significantly superior to other divergence.
What is the difference between density ratio estimation (class probability estimation) and classifica-
tion? The objective and assumption differ. As for assumption, in density ratio, the situation where
p(x) and q(x) are overlapping would be preferable. However, in classification, the situation where
p(x) and q(x) separate would be preferable. In addition, the objective of classification is slightly
different from estimating a Bayes rule correctly. Margin loss is widely used in classification rather
than zero-one loss. The theoretical guarantee of using margin loss for classification is that it is
included in class calibrated loss (Bartlett et al., 2006). However, the margin loss is not equivalent to a
proper loss, i.e, it is often not suitable for estimating η. The condition whereby margin loss is a proper
loss is explained by Reid & Williamson (2010). A GAN using margin loss has been proposed (Zhao
et al., 2016). Note that using margin loss is not supposed in b-GAN. They succeeded in generating
high resolution images.
E.4 Robust loss and divergence
What is robust loss and divergence? Basu et al. (1998) proposed a robust divergence called power
divergence (Basu et al., 1998), which is given as Bνβ [pIq], where νβ is
Ve (X) = β(β+ I)(Xe+1 — (β + 1)x + β).	(23)
This is also called β-divergence (Amari & Cichoki, 2010). The robust estimation equation is derived
from power divergence compared to maximum likelihood. By setting f as νβ, robust density
ratio estimation has been proposed (Sugiyama et al., 2012). In this case, the objective function is
Ex〜q(x) BVe [rkrθ]].
Dawid et al. (2015) analyze robust proper loss from the perspective of influence function. They
proposed a concept of B-robustness from the perspective of influence function. It is stated that using
KL divergence and reversed KL divergence is not robust because the second derivative of f is not
bounded at 0. That is a similar conclusion to our analysis in Appendix D.
E.5 Kernel methods
We assume that k(x, ∙) is a positive definite kernel. When X is a random variable taking values in R
and Ψ(X) is a random variable taking values in Hk with a characteristic map Ψ : X → k(∙,x), we
can think of the mean of random variable Φ(X) denoted as mkX taking values in Hk, which satisfy
hf,mXi = E[hf, Ψ(X)i] = E[f (x)](∀f ∈ Hk) and mX(y) = (mX,k(∙,y)i = E[k(X,y)].
If the kernel is characteristic, the bijective from all measures on R to Hk exists such that a measure
p(X)dX corresponds to the mean mkX (Fukumizu et al., 2004). When there are random variables Xp
and Xq, we can measure the distance between Xp and Xq by calculating ImkXp - mkXq I2Hk.
As the density ratio estimation methods using kernels, the objective function is the empirical approxi-
mation of ImkX - mkX I2H . As generative moment matching networks (GMMN), the objective
16
Under review as a conference paper at ICLR 2017
function is kmkX - mkX k2H (Dziugaite et al., 2015; Li et al., 2015). GMMNs seem to be superior to
b-GAN because they can be trained without density ratio. However, the choice of kernels is difficult.
In addition, an autoencoder appears to be required for generating complex data.
E.6 f-divergence estimation and two sample test
We consider the problem of f-divergence estimation between p(x) and q(x). This is applied straight-
forwardly to a two-sample test. Variational f-divergence estimation using Eq. 3 is proposed (Nguyen
et al., 2010). In addition, the two step method, i.e., first estimating density ratio and then estimating
f-divergence, is proposed (Kanamori et al., 2012). This method is also applied to a two-sample
test. The latter method is similar to b-GAN. A kernel two sample test is also introduced calculating
kmkX - mkX k2H in (Gretton et al., 2012).
E.7 Unnormalized models
When the model p0(xm; φ) is unnormalized, the unified method including noise contrastive estimation
was proposed in (Pihlaja et al., 2010; Gutmann & Hirayama, 2011; Gutmann & Hyvarinen, 2010).
In this case, the objective is estimating θ = {φ, C} when the log-likelihood of normalized model
log p(x; θ) is equal to log p0 (x; φ) + C and C is a normalizing constant. Compared to b-GAN, the
auxiliary distribution q(x) is known. The parameter θ can be estimated as a minimization problem of
Eq. 17 by replacing r (x) with p(x; θ)∕q(x) (Pihlaja et al., 2010). As similar algorithm, the method
estimating rθ first, then estimating p(x; θ) as rθ(x)q(x) is suggested by Gutmann & Hirayama (2011).
Note that the latter method is similar to b-GAN.
Pihlaja et al. (2011) analyzed what loss is better by differentiating loss. They experimentally
confirmed that noise contrastive estimation is robust with respect to the choice of the auxiliary
distribution.
17