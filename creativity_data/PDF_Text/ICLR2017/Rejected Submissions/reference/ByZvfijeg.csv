title,year,conference
 Improving continuous space language modelsusing auxiliary features,2015, In Proceedings of the 12th International Workshop on Spoken LanguageTranslation
 Neural machine translation by jointly learning to align andtranslate,2014, In arXiv:1409
 Learning long-term dependencies with gradient descent isdifficult,1994, IEEE Transactions on Neural Networks
 Gated feedback recurrent neural networks,2015, InProceedings of International Conference on Machine Learning (ICML)
 Generating sequences with recurrent neural networks,2013, In arXiv:1308
 Deep residual learning for image recognition,2015, InarXiv:1512
 Long short-term memory,1997, Neural computation
 Character-aware neural language models,2015, InarXiv:1508
 Deeply supervised nets,2014, In arXiv:1409
 Statistical Language Models based on Neural Networks,2012, PhD thesis
 Extensions of recurrentneural network language model,2011, In Proceedings ICASSP
 Learning longer memory in recurrentneural networks,2014, In arXiv 1412
 Gated word-character recurrent language model,2016, arXivpreprint arXiv:1606
 Highway networks,2015, In Proceedings of NeuralInformation Processing Systems (NIPS)
 End-to-end memory networks,2015, In Proceedingsof Neural Information Processing Systems (NIPS)
 Sequence to sequence learning with neural networks,2014, InProceedings of Neural Information Processing Systems (NIPS)
 gen cnn: A convolutionalarchitecture for word sequence prediction,2015, arXiv preprint arXiv:1503
 Backpropagation through time: what it does and how to do it,1990, Proceedings of theIEEE
 Recurrent neural network regularization,2014, InarXiv:1409
 The fixed-size ordinally-forgetting encoding methodfor neural network language models,2015, In Proceedings of ACL
