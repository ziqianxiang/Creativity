{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The reviewers have improved their scores after the rebuttal, and I agree that the work has value. It proposes a model-driven data augmentation approach to environment-invariant graph representation. Just like most data augmentation works in graph representation learning, the approach relies on graph proposal generator. The work has an implicit mechanism hidden in the graph generator (the authors' reply to a reviewer that \"we target the extrapolation via a new invariant learning approach that is agnostic to specific GNN models\" is a misunderstanding of why & how these types of methods work). The submission could significantly improve the introduction by properly describing the work w.r.t. other OOD efforts in graph representation learning. While the tasks of different works may be different (e.g., graph classification vs node classification), it is important to emphasize what each different approach brings to the table (rather than just state that the tasks are different). I hope the authors take this opportunity to improve the introduction. This work is more similar to the former OOD graph representation works than IRM & REX, since (without modeling assumptions) both IRM and REX require the support of the environments in test to be a subset of the ones in training. The present work does not need this support assumption since it uses an implicit mechanism in the graph generator.\n\nThe toy example in Section 3.1 is informative, thank you. The theory looks solid and easy to understand. The technical novelty is limited, since once the input graph has been decomposed into a set of ego-graphs the definitions, formulations, and theory are all straightforward adaptations from the respective versions for IID data. \n\nMinor:\n- In Assumption 2, m() should be defined inside the assumption."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper studies the problem of distribution shifts as out-of-distribution generalization. Specifically, it formulates the OOD problem as invariant risk minimization under different environments. The relation between these two has been extensively discussed in the paper. Multiple environment is done by graph editing using policy gradient. Experiments on three different kind of distribution shifts are presented and the effectiveness of EERM is validated.",
            "main_review": "## Strength\n1. **Overall, the idea is new to me and experiments are comprehensive.**\n2. **The theorem proposed are rigorously proved in the appendix.**\n\n## Weaknesses\n1. **Missing some related work.** \nBesides OOD on graph and other domain, there are couple of work [1,2] study the generalization from non-I.I.D training data in GNNs. Some discussion on this is necessary.\n1. **Technical writing is dense and hard to follow**\nIn Figure 1, the context generator is actually not generating a new graph, which instead augment the input graph. The terminology used here is confusing. \n\n1. **Assumption 1 seems to be unrealistic.**\nIn practice, do we really have the invariance property? Any kind of study supports this. I feel this assumption is the foundation of the paper that tries to bridge OOD and invariant risk minimization. For example, after graph editing, it would be hard to obtain invariant property. If we remove several author and add authors from different domain, the paper category will probably change. \n\n[1] Ma, Jiaqi, Junwei Deng, and Qiaozhu Mei. \"Subgroup Generalization and Fairness of Graph Neural Networks.\" NeurIPS 2021.\n\n[2] Zhu, Qi, et al. \"Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training Data.\" NeurIPS 2021.",
            "summary_of_the_review": "After reading this paper several times, I start to understand the underlying connection between OOD and invariant property. I think the readability of the paper can be greatly improved by introducing the connection first then talk about their implementation. However, the creation of multiple environment while keeping the invariant property is unclear to me. I might misunderstand this part. Currently, I think it is marginally below the acceptance.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper adapts a recently proposed invariant risk minimization approach for tackling distribution shift on node-level predictions on graphs. The main idea is to decompose the graph into a set of ego-graphs rooted at each node, thus incorporating structural information. Since the learning objective requires data from different environments they authors introduce auxiliary context generators trained to maximize the variance loss. ",
            "main_review": "The paper is well written, polished, and easy to follow. The problem that is studied is important and relevant for the community. The proposed approach is well motivated. The theory is sound, however, the technical novelty is limited. The experiments are well executed and mostly convincing, however, an ablation/sensitivity study is missing. \n\nComments:\n- The discussion in terms of a BFS tree rooted at node v is a bit convoluted. Note, the very general and large class of recursive message-passing GNNs [1] subsumes this. Since the message-passing framework is well established in the literature rephrasing some of the discussions and the assumptions (e.g. Assumption 1) in this framework/language will significantly improve readability. At the very least the relation to message-passing GNNs should be discussed and a citation is warranted.\n- The theory is sound, however, the technical novelty is limited. Once the input graph has been decomposed into a set of ego-graphs the definitions, formulations and theory are all straightforward adaptions from the respective versions for IID data. Nonetheless, there is some value in doing this.\n- It is not clear how much of the apparent benefit is due to the new objective (i.e. the addition of the variance term) vs. the (inherent) benefit of data augmentation. An ablation study should be performed where: (i) first the auxiliary context generators are not trained to maximize the variance (e.g. instead delete/add edges randomly with different probabilities), and (ii) the variance term in the Eq. 5 is removed training only on the K augmented graphs (e.g. again using random context generators). In any case, a comparison with existing data augmentation techniques for graphs (e.g. [2, 3]) is prudent. Similarly, different \"ground-truth\" environments can be used to train the generators (see question below). \n- Relatedly, the sensitivity w.r.t. the hyperparameters should be studied, at least for key hyperparameters such as L, K, and \\beta.\n- The are only few details provided about the graph generators even though they are an important component of the proposed approach. For example, as far as I can tell there are no constraints on the generated graphs, which can lead to highly unrealistic graphs. Is this the case in practice? Moreover, for the generator the parametrized matrix P_k requires O(N^2) memory which severely limits scalability, how is this issue handled, e.g. for OGB-Arxiv? In addition, using the REINFORCE algorithm to optimize the generator might be suboptimal since the gradients can suffer from high variance. How sensitive are the generators to hyperparameters?\n- It is not clear which results are statically significant (especially in Table 2 and 3).\n\nQuestions:\n- What is the accuracy of EERM when there is no distribution shift? For example if we train a GCN with ERM vs. EERM on Cora using random train/val/test split without introducing an artificial distribution shift how big is the gap in accuracy? In other words, is there a price for using EERM? Relatedly, how well does EERM perform on the standard OGB-Arxiv split and how do these results compared to the OGB leaderboard (using the original transductive setting)? \n- Why is the performance on GAT significantly lower compared to GCN and SGC on Figure 2c? Is GAT more sensitive to distributions shift? If yes, can you provide some insight why? If not, is it an orthogonal issue such as not properly tuning the hyperparameters?\n- When training with multiple graphs is the assumption that we have a single environment? What happens if we treat the nodes in each graph as belonging to a separate \"ground-truth\" environment? This would remove the need for context generators and can directly show the benefits of using the variance term in the objective. Similarly, on OGB-Arxiv each year (or set of years) can be considered a separate environment, using multiple for training and one or two for testing.\n\nReferences:\n1. Gilmer et al. \"Neural message passing from quantum chemistry\"\n2. Wang et al. \"NodeAug: Semi-Supervised Node Classification with Data Augmentation\"\n3. Rong et al. \"DropEdge: Towards Deep Graph Convolutional Networks on Node Classification\"\n",
            "summary_of_the_review": "The paper is well written, polished, and easy to follow. The problem that is studied is important and relevant for the community. The proposed approach is well motivated. The theory is sound, however, the technical novelty is limited. The experiments are well executed and mostly convincing, however, an ablation/sensitivity study is missing.  I am willing to increase my score if the authors address the issues with the experimental evaluation that I raised in the main review. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The importance of out-of-domain (OOD) generalization has emerged, and there is much research for out-of-domain generalization [1,2,3,4].\nHowever, the related works on the graph-structured datasets are not explored well.\nOOD generalization of the graph is not trivial because the graph has the interconnection among nodes and the existence of structural information.\nTo solve the problems, this paper proposes a new method, multiple contexts explore that are adversarially trained to maximize the variance of risk.\nThe proposed model is validated on many diverse datasets, Cora, Amazon-Photo, Twitch-explicit, and so on.\n\n[1] Arjovsky, Martin, et al. \"Invariant risk minimization.\" arXiv preprint arXiv:1907.02893 (2019).\n\n[2] Sagawa, Shiori, et al. \"Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization.\" arXiv preprint arXiv:1911.08731 (2019).\n\n[3] Krueger, David, et al. \"Out-of-distribution generalization via risk extrapolation (rex).\" International Conference on Machine Learning. PMLR, 2021.\n\n[4] Creager, Elliot, JÃ¶rn-Henrik Jacobsen, and Richard Zemel. \"Environment inference for invariant learning.\" International Conference on Machine Learning. PMLR, 2021.",
            "main_review": "< Strength >\n1. OOD generalization for graph neural networks is important, but it is a relatively unexplored research area.\nThis paper will be attractive for many graph-related machine learning researchers.\n\n2. OOD for graph dataset are not trivial because of their own unique characteristic of the graph-structured dataset (for example, there are only one graph), but the proposed approach, \"Explore-to-Extrapolate Risk Minimization\",  that adopts K context generators solve the problems in a smart way. \n\n3. The proposed method is validated empirically and theoretically. \n\n< Weakness and Questions >\n1. There are some related graph OOD works [1,2]. Additional discussion will be helpful for the audience. Especially, this paper seems similar to [1], and a detailed discussion will be needed.\n\n2. The baseline methods for experimental results are not enough. For example, Table 3 reports the quantitative results for the OGB-Arxiv dataset, but the baseline is only ERM.\n\n3. In [3], they provide the benchmark settings and some results for OGBN-Arxiv. The quantitative results for normal OGBN-Arxiv experimental settings will be interesting.\n\n[1] Bevilacqua, Beatrice, et al. \"On Single-environment Extrapolations in Graph Classification and Regression Tasks.\" (2020).\n\n[2] Bayer, Jens, David MÃ¼nch, and Michael Arens. \"Image-based OoD-Detector Principles on Graph-based Input Data in Human Action Recognition.\" arXiv preprint arXiv:2003.01719 (2020).\n\n[3] Hu, Weihua, et al. \"Open graph benchmark: Datasets for machine learning on graphs.\" arXiv preprint arXiv:2005.00687 (2020).",
            "summary_of_the_review": "Please see the weakness and questions section.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "- This paper tackles the out-of-distribution problem for node-level prediction on graphs from the invariance perspective. It presents a novel approach in which the whole graph is divided into n ego-graphs where n is the number of nodes. All the ego-graphs can be treated as a set of IID. Based on this division, the model can be trained to defend the adversarial attack from multiple environments. \n- This work extends the discussion of the OOD problem to node-level tasks on graphs. A new learning approach is proposed and theoretically proven to be correct. In empirical experiments on multiple datasets, the approach (EERM) outperforms its counterpart baseline ERM.\n",
            "main_review": "Strength:\n- Provided a new approach to retrieve invariance information among different environments.\n- Presented the theoretical foundations and the proposed approach separately in a clear and persuading manner.\n\nWeakness:\n- The contribution of adversarial attack or resilient GNN beyond prior work is not fully discussed. Simply list a few at the bottom.\n- The OOD problem has been discussed in graph neural network adversarial robustness literature and causal inference literature. Although this paper did a fairly good job in tackling this problem from a different perspective, the novelty is not as great as claimed.\n- The experiment only considered one baseline which is ERM. Other competing methods such as structural risk minimization didn't get enough attention. The experimental design looks good otherwise.\n- The function in equation 1 doesn't look right. Should be [l(f(x), y)|e].\n- Fig 1(b) lack detailed explanation.\n- Baselines do not include \n\n\n- TDGIA: Effective Injection Attacks on Graph Neural Networks. Zou Xu, Zheng Qinkai, Dong Yuxiao, Guan Xinyu, Kharlamov Evgeny, Lu Jialiang, Tang Jie. KDD 2021.\n- Adversarial Attacks on Graph Neural Networks via Node Injections: A Hierarchical Reinforcement Learning Approach. Sun Yiwei, Wang Suhang, Tang Xianfeng, Hsieh Tsung-Yu, Honavar Vasant. WWW 2020.\n- All You Need Is Low (Rank) Defending Against Adversarial Attacks on Graphs. Entezari Negin, Al-Sayouri Saba A, Darvishzadeh Amirali, Papalexakis Evangelos E. WSDM 2020.\n- Gnnguard: Defending graph neural networks against adversarial attacks. Zhang Xiang, Zitnik Marinka. arXiv preprint arXiv:2006.08149 2020.\n- Graph Random Neural Networks for Semi-Supervised Learning on Graphs. Feng Wenzheng, Zhang Jie, Dong Yuxiao, Han Yu, Luan Huanbo, Xu Qian, Yang Qiang, Kharlamov Evgeny, Tang Jie. Advances in Neural Information Processing Systems 2020.\n",
            "summary_of_the_review": "I recommend a reject. This paper developed a new approach to tackle a problem that has already been discussed. Although the presentation is well organized and easy to read, the limited novelty and the lack of excitement bring me to this recommendation.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}