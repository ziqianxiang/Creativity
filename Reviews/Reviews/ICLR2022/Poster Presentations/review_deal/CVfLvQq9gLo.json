{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "Reviewers viewed the proposed approach to image retrieval as both simple and effective, the manuscript as well written and well motivated, and the presented experiments as relatively compressive (spanning three datasets). There was some discussion about novelty -- all reviewers viewed the approach as simple, but one had concerns about the approach's novelty relative to past work. This concern, as well as some concerns about experimental evaluation, were adequately addressed in author response."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper presents a method for the task special kind of multi-modal retrieval: image search with free-form text modifiers, where image is used as a query and accompanied text specifies the differences with respect to the given query image which target image should satisfy. It is practically important problem for which several benchmark datasets exist. The paper proposes to use the representation of text modifier to attend (modulate) both to query and target image representations, and to use these modulated representations to obtain image and text matching scores, which are then averaged to obtain final score for each target image, as displayed in Figure 2. The proposed model architecture is conceptually simple and lightweight, allowing thus scalable retrieval system, while outperforming several recent baselines on three challenging benchmarks: Fashion IQ, Shoes and CIRR dataset. The paper also presents qualitative results of attention via Grad-CAM. \n",
            "main_review": "**Strengths**\n- The motivation and exposition of the problem and the solution is very clear.\n- The paper proposes simple yet effective and practically applicable method.\n- The experimental evaluation is solid, ablation experiments are through and limitations are discussed, albeit in supplementary material \n\n**Weaknesses**\n- Not sure how much the improvement is significant, if results are reported as average over three runs why there is no variance?\n- Explicit complexity analysis would help understand the advantage of the method against more computationally complex (e.g. cross-attention) methods.\n- “We select the best performing model on the validation set to report results on the test set and vice-versa” is not comparable to other reported methods since they didn’t have access to test set. The comparison with TIRG is valid, assuming that the protocol was the same for both ATERMIS and TIRG.",
            "summary_of_the_review": "The paper presents a simple method for important problem that outperforms recently proposed methods on three challenging benchmarks. The paper is clearly written, backed with experimental evaluation and ablations, where it shows good performance.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper focuses on the task of image retrieval using a sample image combined with text modifiers. It does this by the use of two modules that compute the implicit similarity (image-image similarity) and explicit matching (image-text similarity) scores. The modules computing both these scores use attention mechanisms so as to be conditioned on the text modifier. The scores are summed for the final retrieval. The efficiency of this architecture is shown quite clearly by comparing it with other state-of-the-art architectures on 3 different datasets. Ablations and qualitative analysis further highlights the utility of the architecture and its different components.\n\n",
            "main_review": "Strengths\n-------\n\n* Extremely well written and well motivated\n* A simple but novel idea/architecture\n* Comprehensive experiments showing the proposed approach achieves state-of-the-art performance on 3 datasets\n* The ablations clearly show the utility of each of the parts of the already simple architecture\n\nSuggestions and Questions\n-----\n\n* How were heat maps shown picked? Were the images and queries picked at random, and then the heat maps visualized? Or visualized first and then picked after?\n* I think the attention mechanism (such as $\\mathcal{A}_{IS}\\(.\\)$) used here isn't really an attention mechanism in the true sense. It seems a little closer to gating the different image and text embeddings based on the modifier text than attending over them (which would use the modifier text _and_ the image, for example, to generate the attention maps).\n\nMinor comments\n-----\n\n* Page 2: \"conciliates\" -> \"conciliate\" (the word itself sounds incorrect in this context though, did you mean combine?)",
            "summary_of_the_review": "Based on all the strengths (extremely well written and well motivated; clear; a simple but novel architecture; comprehensive experiments and good ablations; great results), I'd recommend this paper be accepted.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper aims to tackle the problem of image search with free-form text modifiers and proposes to combine the implicit similarity and explicit matching score. The implicit similarity module utilizes the textual modifier as a filter to compute the similarity between the query and the target image, and the explicit matching module computes the similarity between the text and the filtered target image. This work combines the image-text similarity and text-guided image-image similarity in a unified framework, and experiments on the Fashion IQ, Shoes and CIRR dataset demonstrates the effectiveness of the proposed strategy. ",
            "main_review": "- Strengths: \n\n  1. It is somewhat interesting to consider the image retrieval with text modifiers in a unified framework, and the strategy of directly combining image-image similarity and image-text similarity seems easy but effective.\n\n  2. This paper is well presented, with clear organization and detailed visual demonstration in experiments.\n\n- Weaknesses: \n\n  1. The attention mechanism has been widely utilized for image-text matching/VQA such as [1,2, 3], and the proposed element-wise product in IS and EM may not provide many insights. \n  [1] Person Search with Natural Language Description, CVPR 2017.\n  [2] Hierarchical Question-Image Co-Attention for Visual Question Answering, NIPS 2016.\n  [3] Deep Attention Neural Tensor Network for Visual Question Answering, ECCV 2018.\n\n  2. The explanations on the proposed IS and EM module are not clear enough. It would be better to provide more detailed explanations on the insights/function/effect of the specifically designed architecture.\n\n  3. Another concern might be the framework itself. Different from CoSMo which learns feature embeddings for fast retrieval, this paper requires to inference each query-target-text triplet online, which would be much slower. It would be better to give more comparisons on efficiency and performance with different frameworks.\n\n",
            "summary_of_the_review": "Overall, this paper proposes the ARTEMIS for image-search with free-form text modifiers. Although simple and effective, the methodology may not be novel enough: it is more like a simple combination of matching scores and does not provide many insights.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}