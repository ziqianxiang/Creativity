{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper presents a new method for clustering multiple graphs, without vertex correspondence, by combing existing approaches on graphon estimation and spectral clustering. All reviewers agree that this is a neat paper with new theoretical and empirical results. The main concerns were also properly addressed during rebutal. Overall, it is a good paper."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "Motivated by the sort-and-smooth graphon estimator of Chan and Airoldi, 2014, this paper proposes two new clustering algorithms (graph distance based spectral clustering and similarity based semidefinite programming) for multiple graphs observed without vertex correspondence. The idea is to use the graphon approximation method to obtain a histogram estimator with the same number of bins for each graph and subsequently apply an existing spectral clustering approach on the graphon based distance matrix.\nTheoretical properties of their approach are studied (under reasonable smoothness assumptions on the generating process i.e. graphon) and consistency is established. The graph distance metric is applied to test for similarity of two collections of graphs. \n",
            "main_review": "Strengths:\n- Deals with the issue of vertex correspondence for clustering of a population of graphs. A large proportion of existing methods developed for clustering assume vertex matched collection of graphs. Thus the idea is to first employ graph matching algorithms and subsequently use these techniques. As a consequence, these existing works do not provide clarity on the actual performance of clustering methods which may vary depending on the choice of graph matching algorithm used in the first step. This paper studied the clustering problem exactly as encountered in practice.\n\n- Theoretical guarantees are provided for the proposed clustering algorithms and testing framework\n\nWeaknesses:\n- The Bernoulli exchangeable model for graph only allows dense graphs (as the probability of edges does not depend on the number of nodes n). Most real world networks are sparse and thus I find this model restrictive. \n- Assumption of strict degree monotonicity is a restrictive one which is not satisfied in many real data examples. It appears that other existing histogram methods for graphon estimation such as by Airoldi, Costa and Chan, 2013 or Olhede and Wolfe, 2014 might be better suited for the clustering task given this practical concern. \n- Number of clusters K is assumed to be known for the numerical experiments whereas in practice this must be suitably determined from the data itself\n-Simulation study does not report performance for the case of sparse networks\n- Not clear how robust the techniques are to the assumption on strict monotonicity of the degree not being satisfied and to the choice of metric used to define the graph distance\n- A discussion on the consequences of Assumptions 2 and 3 specifically wrt clustering (the main objective of the paper) would have been helpful \n\nOther minor comments:\n- From reading the introduction it was not clear what 'clustering' meant exactly : in general for a  population of graphs, it could mean clustering of nodes in each graph or clustering across graphs or both. \n .- What sort of graphs are considered? Directed/self-loops? Not mentioned in the paper. \n- What exactly is Assumption 3? Is it assuming that each w_i is an element of an equivalence class unrelated to the equivalence class of w_j? How is the equivalence class defined?",
            "summary_of_the_review": "Overall, the proposed idea combines existing approaches on graphon estimation and spectral clustering to lead to the proposed clustering and testing approach. It is a neat idea and comes with theoretical guarantees, however, I find the setting of dense networks and the strict assumptions on degree sequence as required for graphon estimation, restrictive. The performance of the clustering algorithms and the testing approach when these assumptions fail and when the number of clusters is unknown, is not clear from the paper. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a graph distance based on graphons that can operate on the small sample size regime; this is possible by exploiting a large number of nodes.\nThe proposed paper is meant to address two shortcomings that the authors have found in the literature: \n- a lack of study of current graph processing methods beyond graph-level classification, and \n- a lack of theoretically sound methods.  \n\nThe paper also shows theoretical guarantees associated with two existing clustering methods and a two-sample statistical tests when operating with the proposed distance.\n\n",
            "main_review": "__Strengths__:\n\nThe paper is easy to read and follow, well-grounded, and theoretically sound in most of its parts. \nThe authors also try to give intuition about the choices they made.\nThe developed method is applicable and effective to small samples of graphs and it appears novel to me.\n\n__Weaknesses__:\n1. The authors claim there are no studies beyond network classification and a lack of theoretical support for the available methods. In my opinion, the claim is not correct. Many papers include different graph-level tasks in their experiments and several of them provide also theoretical support about the proposed architecture; I can refer the authors to some of them below. The authors also claim \"the efficacy of these methods [on graph matching] in learning from network-valued data remains unexplored\". The authors should be more precise about what remains unexplored. Nevertheless, I may agree that extra studies and theoretical analyses can positively contribute to the research in this field, and I recognize the value of considering the small sample size setting.\n    * https://ogb.stanford.edu/\n    * Dwivedi, Vijay Prakash, et al. 2020. Benchmarking graph neural networks\n    * Bouritsas, Giorgos, et al. 2020. Improving graph neural network expressivity via subgraph isomorphism counting.\n    * Zambon, D., Alippi, C., & Livi, L. 2020. Graph Random Neural Features for Distance-Preserving Graph Representations.\n    * Sato, Ryoma. 2020. A survey on the expressive power of graph neural networks. \n    * Maron, Haggai, Heli Ben-Hamu, and Yaron Lipman. 2019. Open problems: Approximation power of invariant graph networks.\n    * Loukas, Andreas. 2019. What graph neural networks cannot learn: depth vs width.\n    * Kriege, Nils M., et al. 2018. A Property Testing Framework for the Theoretical Expressivity of Graph Kernels.\n    * Chen, Hao, and Jerome H. Friedman. 2017. A new graph-based two-sample test for multivariate and object data.\n2. The graph transformation of G to G^\\sigma seems to be ill-defined. Although the graphon can have unique node degrees, graphs sampled from it can result in nodes with the same degree, so 1) there might not exist a monotonically _increasing_ permutation but only _non-decreasing_, and 2) the permutation is not unique, in general. \n3. The claim \"NCLM is the only known clustering strategy for graphs of different sizes\" is incorrect. Basically, any kernel-based and distance-based clustering method that does not require explicit vector embeddings can be applied to graphs. It is customary to choose the most appropriate distance or kernel that better fits the problem at hand; a simple example is k-means. The claims seem unjustified to me also because, as far as I can tell, NCLM constructs vector representations of graphs.\n4. The methods chosen for the comparison can give only limited insights. The considered methods appear to be more or less arbitrarily chosen combinations of graph functions with clustering methods. For example, this approach does not allow us to understand whether it is the proposed distance or the considering clustering method that brings the most advantages. I might be wrong, but it seems to me that there is no limitation in performing experiments with the proposed graphon-based distance with other clustering methods, and the considered clustering methods with other distances/kernels.\n5. Regarding the two-sample hypothesis test, it is unclear how a critical region of a given significance level can be constructed without having knowledge about the underlying graphons. From what I see, in the paper, the critical region is computed by sampling from the original graphons. I would to have some clarifications in this respect.\n\n\nQuestions and unclear parts:\n- The sorting-and-smoothing estimator is mentioned even in the abstract, but never introduced in the paper. Why is it the only one that can meet the above requirements? Moreover, the above requirements (I guess the authors refer to Assumptions 1-3) are about the graphons, not their estimators.\n- Theorem 1. It is counterintuitive for me that for a bounded number of nodes, the more graphs we have, the larger the _rate_ of erroneous clustered graph increases. I would expect that for m -> infinity, the rate of misclustered graphs converges to the optimal value (which is not necessarily zero), and the variance of such observed rate decreases. Could you comment on that? \n- It is not clear to me to what extent the discussed clustering methods had to be adapted to work with the proposed distance. It is also unclear whether or not these clustering methods would be consistent regardless of the specific graph distance, provided that the graph distance is sufficiently expressive (eg, it is metric).\n- Because the considered method is based on edge histograms, I wonder if there are known limitations or important differences when considering sparse graphs instead of denser ones. Are there different best practices to operate in the two regimes? \n\n__Other comments and suggestions__:\n- Say explicitly that graphs are symmetric and without node or edge attributes (if this is the case).\n- Expand the comment about indistinguishable inhomogeneous random graph models. What is the argument to show that although different, they are indistinguishable? What are we losing by ignoring such graphs, in what cases are we interested in considering also them?\n- Prop 1. Please, expand the discussion about the variable n which seems to be undefined.\n- Cor 1. Shouldn't it be: given m, n_0 and |w-w'|, we need to find a _small_ enough constant C?\n",
            "summary_of_the_review": "Overall the paper is well written. The proposed solutions are novel to me and address an extremely challenging problem related to the small sample size regime. However, a few negative aspects are present: there seem to be incorrect claims, the graph transformation appears not well-defined, and the experimental setup does not bring decisive conclusions.\nGiven the points raised in the main review section and unless it turns out I misunderstood those parts of the paper, I am afraid to say that the paper is ready for publication in its current state. However, I encourage the authors to carry on the research in this direction, because it appears promising and only few (yet, important) aspects need to be improved.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "\nThis paper presents an interesting approach to clustering of graphs sampled from graphons.  The papers presents a number of guarantees for the quality of obtained clusterings and a few preliminary experiments.\n",
            "main_review": "\nThe paper is very interesting, well written and understandable.\n\nThe proposed heory only works when graphs are sampled from graphons and the vertices are kept in the same order.  On the one hand, I understand that anything involving graph isomrophisms (and hence vertex permutations) will be untractable.  On the other hand, in practical applications we don't know the order of the vertices, hence there is a lot of work on graph isomorphism, graphon cut norms, and other tools to deal with that issue.  Assuming instead 'ordered' graph sampling with L2 graphon norms is interesting from a theory point of view but is quite far from practical applications where clustering and testing becomes relevant.\n\nThe experimental section could devote more attention to the runtime of the algorithms and experiments.\n\nNevertheless, the paper has some original ideas which could form a first step into more mature results.\n\n\nSome details:\n* Assumption 2: I dislike the term \"degree distribution\" in this context.  Usually, \"degree distribution\" is used for a probability distribution f which gives for a input degree d the probability f(d) that a randomly selected vertex has degree d.\n\n* In Equation (1), it seems the index i of A_{i,j} starts from 0 until n_0-1 rather than from 1 to n_0 as usual.  Alos, vertices with index larger than n_0*\\lfloor n/n_0 \\rfloor aren't taken into account.\n\nat some places articles are missing, e.g.,\n* page 5 first line: Davis-Kuhan theorem -> the Davis-Kuhan theorem\n* Sec 3.2 second line: Gaussian kernel -> the Gaussian kernel\n\n\n\n",
            "summary_of_the_review": "\n\nThe paper is interesting and sound, while the result on itself is not yet very practical it could form a good first step.\n\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}