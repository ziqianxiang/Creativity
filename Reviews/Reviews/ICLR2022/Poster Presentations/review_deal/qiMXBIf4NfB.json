{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper studies self-training for a one hidden-layer architecture, showing that with proper initialization self-training will improve over standard supervision. The reviewers appreciated the analysis and thought the results make sense. However, they did comment that the paper does not provide sufficient insight about the effectiveness of self-training and this should be discussed in the final version. There were additionally comments about the architecture choice (e.g., fixed output weights), and the authors should also address this."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper theoretically analyzes self-training in neural networks with one hidden layer. Self-training is a popular semisupervised learning algorithm where a model uses large unlabeled data by training on pseudolabels generated by a teacher model trained on some small set of labels. The paper studies the generalization performance of self-training on a two-layer network under a Gaussian assumption on the inputs, and has some synthetic and CIFAR-10 experiments to show that the predicted theoretical rates (1/\\sqrt{ size unlabeled data}) roughly match empirical performance. ",
            "main_review": "EDIT: After the discussion, I have raised my score to 6. Thanks to the authors for patiently addressing the various concerns and adding required appendices.\n\n\nThe paper studies an important problem of theoretically understanding how and why self-training works. The paper makes a genuine attempt to connect theory and practical insights and tries to distill some main takeaways from their analysis in  order to simplify understanding. However, I find that the paper in its current form does not push the boundaries on our understanding of self-training.\n\n(1) My main criticism stems from the fast that several works have studied self-training in the linear setting (as rightly mentioned in the paper). This paper claims to study two-layer networks which are more challenging due to non-convexities. However, the assumptions of the theorem (which the proof heavily relies on) essentially study the problem in a \"locally linear\" region around the optimal solution. The paper claims novelty in introducing the quantity \\lambda (weighting between the loss on the labels and pseudolabels while self-training) and an associated bound on the weighted objective to enable analyses. However, I really struggled with understanding the quantity \\lambda and what it implies (more details below). \n(2) The main self-training description (Table 1) does not mention \\lambda. It is only described in-text in equation 1. How does one set \\lambda in practice? I saw that the CIFAR-10 experiments used the same heuristic as in Carmon et al., but how does that relate to the analysis?\n(3) The setting of the paper is slightly weird to me as well. (a) model family: they claim to study a two layer network but essentially freeze the top layer weights such that they are ones and there's only one matrix being learnt. I understand that the problem is still non-convex due to the non-linearities but this restriction of all ones seems to be pretty strong to me and its unclear how to generalize to multiple layers. One of the main complications in studying multilayer networks is the interaction between the parameters of each layer which the current version of the paper doesn't deal with. (b) Regression instead of classification: this paper really analyzes regression and not classification (square loss is analyzed both at train and test). I believe this significantly makes the analysis easier since one doesn't have to deal with training only on confident predictions and so on---one single \\lambda factor can balance things out. In classification, we typically need some other kind of regularization\n(4) Related works: The paper also seems to be missing some important related works  such as \n[1] Y. Grandvalet and Y. Bengio. Entropy regularization. In Semi-Supervised Learning, 2005.\n[2] P. Rigollet. Generalization error bounds in semi-supervised classification under the cluster\nassumption. Journal of Machine Learning Research (JMLR), 8:1369–1392, 2007.\n[3] A. Singh, R. Nowak, and J. Zhu. Unlabeled data: Now it helps, now it doesn’t. In Advances in\nNeural Information Processing Systems (NeurIPS), 2008.\nMore generally, self-training has a very rich literature and the current draft doesn't situate this work well in terms of connections to previous work. The main claim of dealing with non-convex two layer networks is not very satisfying to me for reasons above. Are there any other additional insights or takeaways from this work?\n\n(5) In terms of writing, I found the paper generally well-written except for routinely talking about terms that are introduced later. For example, the highlights of the theory section was very difficult to follow because all the main quantities were defined later. \n\n",
            "summary_of_the_review": "Overall, the paper studies an important problem (self-training on multilayer networks) and tries to connect some theoretical takeaways to practice. However, both in terms of theory and experiments, I found that the paper does not broaden our conceptual understanding of the method, nor does it introduce interesting theoretical tools for analysis. However, I believe there is a lot of scope to build on this work (relaxing assumptions, choosing the right model family and loss functions) to get a more convincing publication. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper theoretically analyzes the iterative self-training algorithm with 1-hidden layer neural network. When the labeled and unlabeled data is generated from zero-mean Gaussian distributions with variances of different scales, it is shown that both the convergence rate and the generalization error decreases at a rate of $1/\\sqrt{M}$ where $M$ is the number of unlabeled data. Experiments on synthetic data and augmented CIFAR-10 corroborate theoretical findings.",
            "main_review": "Strengths:\n1. The theoretical analysis is rigorous and contains novel technical contributions.\n2. The empirical findings evaluate many interesting predictions of the theory.\n3. The exposition of the proof sketch is clear and informative.\n4. Comparisons with previous works are clear.\n\nWeaknesses:\n1. Self-training can hurt accuracy in some settings (confirmation bias). I wish the theory discusses when this happens.\n2. I wish the theory offers guidance on how to improve self-training algorithms in practice.\n3. Section 3.3 talks about '0 generalization error'. I'm confused by this term since there is always estimation error.",
            "summary_of_the_review": "This paper is theoretical rigorous and has novel technical contributions.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents the first theoretical analysis of self-training on one hidden-layer neural network with gaussian input. The paper shows that under certain conditions (e.g., the initialization is neither too far or too close to the optimal), iterative self-training on the aformentioned setting can provably recover the ground truth labeling matrix and offers improvement in sample complexity over supervised learning with only labeled data. Experiments validate the theoretical results.",
            "main_review": "**Pros**\n\n- This paper tackles an interesting and important theoretical question behind the success of self-training where the model is repeatedly retrained on pseudo-labels generated on unlabeled data.\n- The experimental results seem to support the theoretical claims extremely well, and the preliminary experiments on realistic models and data also agree with some of the theoretical predictions.\n\n**Cons**\n\n- There may be significant technical flaws in the proof. Both the proof for theorem 1 and the proof for theorem 2 hinge on what the paper referred to as the “intermediate value theorem” (eq 36 and later eq 56). However, the theorem being invoked here seems to be a vector version of the *mean value theorem* applied to $\\nabla f$. Had it just been a naming mistake, it would be ok, but I believe that this particular MVT might not exist. I was able to find a version for functions of scalar input and vector output in Rudin [1] which can also be found on the wikipedia page (https://en.wikipedia.org/wiki/Mean_value_theorem#Mean_value_theorem_for_vector-valued_functions), but this is actually an *inequality* instead of an equality. Incidentally, the same wikipedia section states \"There is no exact analog of the mean value theorem for vector-valued functions.\" I also found another version of the theorem on stackexchange (​​https://math.stackexchange.com/questions/1397248/mean-value-theorem-for-vector-valued-multivariable-function) which is an equality but requires an additional vector $a$ and still does not apply to the vector version that is shown in the proof. If there is a reference for this particular version of MVT, it would be nice to have it in the paper since it is, in my opinion, highly non-trivial if it does exist. This error could be plausibly fixed by using Taylor expansion instead of MVT but the it would require some changes to the proofs.\n- Aside from the problem above, the paper also makes a somewhat strong assumption that makes the result much weaker than it appears. Specifically, the paper assumes that the nework is of the form $g(x) = \\frac{1}{k} \\sum_{i=1}^k \\phi(w_i \\cdot x)$. Note that this function is **convex** in $W$! This is not what we conventionally call a *one-hiden-layer neural network* but rather just a convex function which is much less expressive.  In contrast, [2] uses $g(x) = \\sum_{i=1}^k v_i \\phi(w_i \\cdot x)$ which is actually a neural network. Although the optimization land scape with squared loss is still non-convex, the function class is much less expressive than a neural network. I am not sure if this function class is representative of non-linear models' behaviors on much more complex data. Although the experiments seem to suggest that it somewhat predicts behaviors of actual models, I think this discrepancy is misleading to say the least, if not overclaiming.\n- some notations are not defined. For example, I cannnot find the definition of $c(\\kappa)$. If I missed it, please let me know.\n\n**Questions**\n- In the appendix, shouldn't the population risk function $f$ use squared difference?\n- The results suggest the unlabeled data can be drawn from different distribution with some constraints (i.e., $\\tilde{\\delta}$) but what do those constraints translate to for real world data?\n\n**Reference**\n\n[1] Principles of Mathematical Analysis. Rudin, Walter.\n\n[2] Recovery Guarantees for One-hidden-layer Neural Networks. Zhong et al.\n\n\n-------\n**Update**\n\nI thank the authors for the detailed response.\n\nMy concern regarding MVT has been fixed and that part of the paper is now technically sound.\n\nFurther, I believe that the authors' extension for two-layer models is technically sound insofar as you believe the tensor initialization method is indicative of what happens in the training dynamics of real models. On the other hand, personally, I am not convinced by the tensor initialization argument and I do not feel the analysis is adequate for explaining what happens in the self-training procedure of actual models. \n\nIn the light of these changes, I believe the paper is now sufficient for publication and I am increasing my score to 6.\n",
            "summary_of_the_review": "The paper tackles a challenging and important problem. While the experimental results seem to match the theoretical predictions, there are potential significant flaws in the proofs of the main theoretical results. The paper would have been a pretty strong paper, but due to these potential errors, I unfortunatley cannot recommend acceptance.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "In this paper, the authors make first forrays into the study of the theoretical properties of the following iterative self-training algorithm in a semi-supervised regression setting where we have N labeled samples and M unlabeled samples (and the ground truth is realisable):\n\n(1)  train the model on the labeled data, obtain pseudo labels for the unlabeled data by feeding them through the trained model \n(2)  train an auxiliary loss (see equation (1)) on the augmented dataset the includes the unlabeled data with the corresponding pseudolabels (the loss is a convex combination of the empirical loss on the labelled and unlabeled datasets), and \n(3) iteratively apply step (2) until convergence. \n\nIt is assumed that the ground truth is realisable (though without overparametrization assumptions), the labels are observed exactly (without noise), the model is a simple two-layer neural network with the second layer weights all fixed to one, and the labeled and unlabeled datapoints come from two isotropic Gaussian distributions of variances $\\delta$ and $\\tilde{\\delta}$. \n\nIn theorem 2, the following surprising result is shown: under some reasonable assumptions on the initial point and the number of unlabeled datapoints, for a suitable choice of the convex combination parameter $\\lambda$, the model converges towards the ground truth with an assumption on the number of samples which is weaker (by a constant factor at best) than what is required in the case where no unlabeled data is provided (which is a particular case of the case studied in [1])\n\nIn the more general Theorem 1, it is shown that under much weaker condition (without a requirement on the number of labelled samples), the model still converges towards a given convex combination of the ground truth and the initial point, and is guaranteed to outperform the initial model. \n\n\nThe main idea of the proofs is to define an auxiliary loss referred to as the population risk function (which estimates the risk taking as \"labels\" the images of the points by a convex combination of the ground truth and the initial point, cf. equation (17)) and to show (1) that the optimization lanscape of this functions is mild  (mainly proved in Lemmas 1 and 11), and (2) that this auxiliary function is close to the empirical risk which is minimized by the model (mainly proved in Lemma 2). The proofs of the techincal content of lemmas 1 and 2 rely both on computational geometry arguments and on existing results from [1]. \n\n\nExperiments are provided which show: \n(1) an excellent match between the dependence of the bounds and that of the observed generalisation gaps on various parameters and\n(2) that the unlabeled data indeed improves performance in data-sparse regimes on some real data. \n\n\n\n=======================\nReference:\n=======================\n\n\n[1] Kai Zhong, Zhao Song, Prateek Jain, Peter L. Bartlett, Inderjit S. Dhillon. \"Recovery Guarantees for One-hidden-layer Neural Networks\", JMLR 2017\n",
            "main_review": "This is an impressive, technically solid and well-written paper with some intriguing results. The authors take particular care in explaining the general strategy of their proof, not just in the main paper, but also in various parts of the supplementary. There may be some things to improve (that I would like to see in the camera ready version), but overall this paper is of significantly above average quality amongst accepted papers. There are a couple of typos but far fewer than average for papers published at top tier conferences. \n\n/\n============================================\nComments/questions on the general mathematical content.\n============================================\n\n\n1. I think the results presented are a mathematical curiousity highly worthy of further study: it is worth noting that the number of labelled samples is assumed to be greater than a multiple of the number of parameters, and the paper studies a regime which is not data-sparse *statistically*, but which is data-sparse from the *optimization* standpoint. A priori, it is reasonable to assume that the global optimum of the supervised learning problem that ignores the unlabelled data would still approach the ground truth and perhaps outperform the current model. Furthermore, note that both the labelled and the unlabelled datapoints are assumed to come from gaussian distributions, with different variances, thus there is almost no statistical information coming from the unlabelled data (the only possible information it could contain is about the mean (0) or about the fact that the data is isotropic. Thus the self-training strategy appears to function only as an optimization trick that relies on some form of self regularisation/momentum. \n\nQuestions for the authors related to comment [1]: \n\n1.1. Do you agree that the effect is only on optimization, or do you believe that the mean of the data or the isotropicity being communicated by the unlabelled data play a role? \n\n1.2. Do you think the result would still hold if the unlabelled data was chosen from a different non istropic gaussian distribution? \n\n1.3.  Honestly, do you think it may actually be possible to show the same convergence rates for the *supervised* learning problem (without relying on the unlabelled data at all) by borrowing from your techniques and doing away with the unlabelled data altogether? \n\n1.4. Did you try applying such a model on real data (e.g. image data) where instead of also picking real data for the unlabelled dataset, you draw samples from a suitable Gaussian? \n\n\n2.   I guess it would be nice to go into more details about the relationship between the results here and those in reference [2]: it is briefly mentioned at the top of page 2, but more details about the proof techniques in the appendix would be nice. It seems that in that reference, the authors study a completely different effect: they study classification assuming the classes are well-separated. In particular, there unambiguously is statistical information contained in the unlabelled data in this case.  It would be nice to have a one page summary of the results and proof techniques in [2] in the supplementary. \n\n\n3. You mention in Lemma 3 that although your main theorem 2 requires an assumption about the initial guess not being too far away from the ground truth, any initial point chosen with the \"tensor method\" satisfies this assumption with high probability. Trying to understand this method requires going through the very long paper [1] and parts of other papers (including [3]). It would be nice to have an extra section in the appendix which explains the \"tensor method\" from first principles, with suitable pointers to the relevant results. \n\n//\n =================================\nSmall issues with the maths/presentation\n==================================\n\n\n1. I think there is a slight problem with the proof of lemma 1: I guess the lower bound only holds for any constant strictly less than 1/11, but doesn't necessarily hold for the constant 1/11 as is claimed here. Indeed, first of ll on page 26, equation (76), I think there should be a minus sign instead of a plus at the second line. Then on a related note, I agree that combining equation (79) with Lemma 11 yields equation (80) (with the \\simless sign indicating there is an unstated constatant which can be arbitrarily small since one chooses it in the interpretation of the condition on p in equation (19), but combining this with equation 76 only shows the a lower bound of the type \"$a-o(a)$\" where \"$a$\" is the lower bound claimed. Hence the constant  should be anything slightly smaller than 1/11. \n\n2. On page 27, you use Lemma D6 from [1]. It would probably be better to write down the lemma in full and announce its role in advance at the beginning of the proof of Lemma 1. \n\n\n3. Question: I am not sure I get how you go from the third line to the fourth line in equation (78). Could you elaborate? (I agree only that with an extra factor of 2 it would be trivial).\n\n\n4. $\\kappa$ used extensively in the main paper (starting on page 4) but is only defined in the appendix. Even the fact that $c(\\kappa)$ denotes \"a constant that is allowed to depend on $\\kappa$\" (I presume) is worth mentioning explicitly (currently not even mentioned in the supplementary). \n\n\n5. I think the definition of the population risk function (equation (17)) has squares missing (the rest of the calculations are indeed consistent with the formula with the squares present). \n\n\n6. The proof of Lemma 10 includes statements about the properties of $\\mu$ which are not stated in the lemma statement (though they are mentioned in the main paper with a pointer to the supplementary). The lemma statement should be enriched. \n\n7. A little bit after equation (94) on page 31,  there is a $\\bar{\\omega}_j$ which is not defined. \n\n8 At the second line of equation (95) on page 31, there is a $\\phi'(x)$ which should be $\\phi'$ $([w_{j_1}^{[p]}]^\\top x)$.\n\n9. On page 32, on the line that starts with \"Also, since $x\\sim....$ it is claimed that $z$ is an isotropic normal distribution with variance $\\delta^2\\|a\\|^2$. I guess this is only true if you force $b,c,...a_d^\\perp$ to be normed, and also replace the \"a\" in the basis by a normalised version (currently it is not even stated that the vectors are orthonormal). I mean it is clear what you are doing here but there are minor corrections to make in the notation. \n \n\n10. I think there are minus signs missing inside the exponents in the equation  between equations (97) and (98). Furtheremore I guess $x_1,x_2,x_3$ should be$ z_1,z_2,z_3$. \n\n\n11. Question: How do you go from the third to the fourth line inside equation (98)? I know it is just computation but still, I would like to see details. \n\n12.  Question: In the main paper at the bottom of page 6, \"the lower bound on p means that $W^0$ cannot be too faraway from $W^*$\" \nDo you mean the *upper* bound on p? It seems lower bounds on the distance between $W^0$ and $W^*$ correspond to upper bounds on p and vice versa. \n\n\n\n13.  I guess at the top of page 27 one shouldn't write \"for any $\\\\|\\alpha\\\\|=1$\" since $\\alpha$ runs in the min in the equations below. It would also be nice to remind people that $\\\\|\\alpha\\\\|^2=1$ refers inside the norm to the flattened version of $\\alpha$. \n\n\n14 . Page 25, equation (71): should the last two (out of three) right hand sides be swapped ?It seems that $H_2^2(\\delta)$ is $O(\\delta^4)$ so it is the second expression on the LHS that should be in $\\Theta(\\delta^2)-\\Theta(\\delta^4)$. \n\n\n\n//\n===================================\nMinor typos/minor grammatical errors\n===================================\n\n1. Title: =====>  \"How *does* unlabeled data improve...\"\n\n2. Beginning of section 2: \"the objective function is to find a neural network...\"  ====> \"the aim is to find a neural network...\"\n\n\n3. Bottom of page 8: \"the block in white depicts all the trials are successful...\" =====>\" the white blocks correspond to succesful trials, while...\"\n\n\n4. The typography of the title for the appendix could be improved. \n\n5. In point 2 at the top of page 15, \"Then, utilising lemma 11...to obtain...\" (there is no verb) =====> \"Then, we utilize lemma 11 to obtain...\"\n\n6. Statement of lemma 4 on page 18: \"suppose ...be a matrix\" ===> \"let....be a matrix\"\n\n\n7. Bottom of page 19 (beginning of the last paragraph): \"by intermediate value theorem\" ====>\"by the  intermediate value theorem\"\n\n8. Bottom of page 19: \"Final, by...\" ====> \"Finally, by...\"\n\n\n9.Beginning of section E on page 22: \"by intermediate value theorem\" ====>\"by the  intermediate value theorem\"\n\n10. Beginning of section F on page 25: ...\"check that ReLU activation function satisfies the conditions\" =====>\"check that the ReLU activation function satisfies the conditions\"\n\n11. page 25, last line: \"\\mu is strictly decreasing function\"===> \"\\mu is a strictly decreasing function\"\n\n12. First sentence of section G2. \"The error bound between $....$ is dividing into bounding $....$, $...$, $...$, and $...$.\"\n=====>\"The task of bounding of the quantity  $....$ is divided into bounding $....$, $...$, $...$, and $...$.\"\n\n\n\n\n\n//===============After Rebuttal============\n\nI am happy that the authors tried hard to address all of my concerns, I will keep my original score.\n\n\n\nHere are my takeaways by theme: \n\nTensor Method:   In particular, I am very glad to see that they have taken the trouble to write a general explanation of the tensor initialisation method. The simplification by introducing the Psi_i etc. is particularly useful to understand the main point (as opposed to the precise definition of the constants given in the reference). \nThat is very helpful. However, it could be made even better by introducing the method from Kuleshov et al 2015, which is currently missing. \n\n\nMVT:   I am very happy with the response from the authors regarding the MVT. \n\n\n\n\nSecond layer weights: I am reasonably happy with the answer in appendix K. However, more details are needed. The analysis given here only successfully explains how to fix the proof of Lemma 2, not lemma 1 (which contains second order terms. I think the authors should also redact the relevant part of the paper and appendix better. Currently, it is not unambiguously stated at the top of appendix K that the extension proposed does not actually suggest *training* the second layer weights. I know it is explained (defensively) at the end of the appendix, but things should be explained more straightforwardly from the beginning. \n\n\n\n\n\n\n\n// =====After rebuttal: minor typos introduced in the revision=============\n\nP 27: Typiclly, for Relu function ====> TypicAlly, for THE Relu function\n\nP 28: when phi is THE Relu function\n\nP 37 =====> The expectation of THE objective function \n.... Is THE squarE loss\n\n\nP 39 ...can BE estimated exactly through.... (Missing verb)\n\n\n\nP 40 Conclusions does not change at al ======> conclusions DO not change at all.\n\n\n\n\n\n\n\n\n\n\n//\n===============================\nReferences: \n===============================\n\n\n[1] Kai Zhong, Zhao Song, Prateek Jain, Peter L. Bartlett, Inderjit S. Dhillon. \"Recovery Guarantees for One-hidden-layer Neural Networks\", JMLR 2017\n\n[2] Colin Wei, Kendrick Shen, Yining Chen, Tengyu Ma. \"Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data\", ICLR 2021\n\n[3] Volodymyr Kuleshov, Arun Chaganty, Percy Liang. Tensor Factorization via Matrix Factorization. AiStats 2015. \n\n\n\n",
            "summary_of_the_review": "This is an impressive, technically solid and well-written paper with some intriguing results. There are only very minor issues. \nThe paper could perhaps be made even better by adding further reader-friendly discussions of some of the related works to make it appeal to a wider audience, as well as perhaps by discussing the main results and their implications in more details. \n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}