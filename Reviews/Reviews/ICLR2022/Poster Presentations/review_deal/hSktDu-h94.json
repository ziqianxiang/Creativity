{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper studies the problem called \"Predict, then Optimize (PTO)\", where the goal is to predict some unknown parameters in the objective function and then optimize the function. The paper focus on special case of PTO where the goal is to learn the unknown parameters corresponding to some combinatorial ordering of the data. The paper argues that traditional methods which perform the ranking after minimizing the objective can be very unstable, and proposes a new alternative loss called ATGP loss. The goal of the loss is to ensure that the total group preorder of the learned solution is as consistent with the observation as possible after fitting the data. \n\nThe paper shows some property of the new loss and claims that it can be better than naive regression then ranking approach on learning to rank with linear regression problem, however, the theorem only shows that the robustness bar of TGP loss is larger or EQUAL to that of the naive approach, not exactly higher -- Thus, such an argument is not really convincing.  The authors also proposed a heuristic algorithm to minimize a smoothed version of the proposed loss. \n\nHowever, the proposed objective is still interesting on its own, and the experimental result looks promising. Thus, this paper is a borderline accept paper at this conference."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper aims to solve combinatorial optimization problems with unknown parameters that need to be predicted from observations. It proposed a total group preorder loss and its differential version approximated total group preorder loss for predict-then-optimize (PTO) problems with strong ranking property. It studied a very interesting problem. ",
            "main_review": "My main comments are listed as follows:\n\n1.\tRegarding Definition 1 (Total group preorder): TGP© defines all pairs that satisfy the priority order with parameter c. The definition makes sense for the ranking problem. However, how does this definition fit into the shortest path/knapsack problem? That is, most combinatorial problems are constrained, then how to consider this group preorder? If we consider one feasible path as an element, then the number of elements increases exponentially. This is related to the comment below Definition 3. How can the curse of dimensionality be avoided?\n\n2.\tMore details are needed for Algorithm 1: \na.\tWhat is the intuition behind Equation (6) and (7)? \nb.\tAre there any connections between these two equations? Under what circumstances should Equation (6) be applied? \nc.\tWhat is CLIP in Equation (7)? \nd.\tIn Section 4.1, how to determine D (the number of DoG filters used)? \ne.\tHow to choose \\gamma and \\sigma? How is \\sigma related to the problem itself?\n\n3.\tHow to avoid the overfitting problem in the TGP/ATGP framework?\n\n4.\tIn the numerical experiments, Table 1 reports the SPO losses with baseline algorithms on the three PTO problem. Could you also report the computational time for different algorithms?\n\nMinor: \n\n1.\tIn the proof of Lemma 1, “.” is missing in the last sentence.\n\n2.\tIn the proof of Theorem 1, to make the notation consistent, I suggest to use A_{i,:} to denote its i-th row.\n\n3.\tIn the proof of Theorem 1, change the notation for loss function $l$ to $\\ell$;\n\n4.\tI am a bit confused by the proof of Lemma 2: the first term of X\\hat{H}^{l_2} is XX^+ C^*. From the derivation, it gets that XX^+ C^* = XH^*=C^*, which implies that P_X C^* = C^*. If C^* is full rank, then P_X= I. Is it a reasonable conclusion? Why?\n\n5.\tThe proof of Lemma 3 seems not rigorous. Could you use mathematical equation to prove this conclusion?\n\n",
            "summary_of_the_review": "Overall, this is an interesting paper. It may help to understand the paper if adding one or two examples other than ranking (constrained optimization problems such as shortest path/knapsack in the modeling section), to illustrate how the new notion of total group preorder and algorithm can be applied. The proofs need to be written in a clearer way.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this paper, the authors propose a novel loss function called the approximated total group preorder (ATGP) loss function, which aims to address the potential limitations of l2 loss in predict-then-optimize (PTO) problems.\nThe authors argue that the use of l2 loss in the prediction phase is \"misaligned\" with the final goal when the ultimate objective is to make discrete decisions in a combinatorial optimization setting.\nWhile the so-called SPO (smart PTO) loss, recently proposed by Elmachtoub and Grigas (2021) provides a remedy, the authors note that it cannot be used with gradient-based learning algorithms.\nThe authors aim to rectify this issue by proposing a novel loss function called the total group preorder (TGP) loss - for better alignment - and then an algorithm for automatically searching for an approximate TGP (ATGP) loss function so that it is differentiable and therefore can take advantage of efficient gradient-based learning schemes.",
            "main_review": "Overall, the paper is well-written.\nThe proposed ideas are reasonable and they are presented in a logical manner.\nPerformance evaluation based on three examples - energy cost-aware scheduling based on historical energy price data, portfolio optimization based on SP500 data, and shortest path finding in Twitter ego network - demonstrate that the proposed ATGP loss and the APOC  (Automatic Prediction and Optimization Connector) algorithm may have potential advantages over other loss functions and algorithms.\n\nOne major concern regarding the paper is that the authors do not consider the rich literature on optimal decision making - especially, decision making under uncertainty - that has a very long history in operations research and other fields.\nFor example, the SPO loss shown on page 3 is conceptually identical to what is known as \"regret\" in decision theory.\nRegret estimates the expected performance loss due to using a suboptimal predictor (or operator) instead of the optimal predictor (or operator), typically due to the fact that the true model parameters or the optimal predictor/operator are unknown (e.g., due to aleatoric and/or epistemic uncertainties).\n\nFurthermore, if the predictor (or operator) is optimized to minimize the regret (or the SPO loss shown on page 3) over a class of possible predictors/operators, that leads to the so-called MOCU (mean objective cost of uncertainty) that quantifies the operational cost induced by model uncertainties.\nBoth regret and MOCU have been widely studied in problems such as optimal decision making, optimal experimental design, and active learning - especially in the presence of uncertainty.\nHowever, the authors, unfortunately, do not discuss the relation of the presented work with the existing studies based on regret or MOCU.\n\nAnother concern is the limited performance validation of the proposed approach presented in the current paper.\nFor example, it is unclear whether the ablation study in Figure 4 clearly shows the advantage of the DoG wavelet for automatic search of ATGP, as the improvement does not seem to be significant when compared to the fully-connected network.\nThe results in Table 1 also show that the performance of the ATGP via APOC significantly depends on the choice of the optimization scheme (e.g., REINFORCE vs PPO2), since in most cases, not both schemes outperform the other alternatives.\n\nAdditional performance assessment results are needed to further validate the advantages of the proposed scheme and the above points should be clearly discussed with mentions about the potential limitations of the current method.\n",
            "summary_of_the_review": "The paper deals with an interesting problem and the proposed method is well-motivated and presented in a logical manner.\nThe experimental results based on three different datasets show that the proposed method may have potential advantages over other existing schemes.\nHowever, despite the conceptual similarity between SPO loss (which the TGP/ATGP tried to improve) and regret/MOCU in decision theory, the authors do not discuss the relation of their work to the rich existing literature on regret and MOCU.\nFurthermore, additional performance evaluation results are needed to clearly demonstrate the robustness and benefits of the proposed scheme.\nIncluding discussions on potential limitations of the current method (if any) would strengthen the paper.\n\n---\n\nThe evaluation has been updated after reviewing the authors' response.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper studies a problem where the goal is to solve an optimization problem, but key parameters of the optimization problem (like a road network’s edge weights) are unknown and can only be predicted from historical data. This line of research is called “predict then optimize.” For the prediction step, the first thing one might try would be to minimize a standard loss function like the l2 loss, but this loss function may not necessarily lead the downstream optimization problem to return the highest quality solutions. This paper studies a way to learn a good loss function for the downstream optimization problem at hand.\n\nTo give an example, if the optimization problem is to rank a set of elements, even if one can predict the elements’ values with low l2-error, the resulting ranking might be totally incorrect.\nMotivated by this example, this paper’s results apply to combinatorial optimization problems that satisfy a “strong ranking property,” which essentially means that the optimization problem’s solution only depends on group-wise comparisons of the problem’s parameters (rather than on the specific values of the parameters themselves).\n\nLet $c \\in R^d$ be the true parameters and $\\hat{c}$ be the learned parameters. The authors propose that the loss function one should optimize should ideally have the form $||sign(L\\hat{c}) - sign(Lc)||$, where $L$ is a matrix of size ${2^d \\choose 2} \\times d$ that allows for all $2^d \\choose 2$ group-wise comparisons between all groups of parameters. Since this ideal loss function is computationally intractable, the authors propose replace $sign$ with $\\tanh$. Then, they propose fixing the number of rows of $L$ and parameterizing the matrix using a set of discretized Derivative-of-Gaussian filters, which they optimize using the reinforcement learning algorithm REINFORCE [Williams ‘92] (the details here are a bit unclear to me).\n\nThey evaluate their algorithm for three problems: a scheduling problem, portfolio optimization, and shortest path. They compare against a number of different predict-then-optimize algorithms from prior research and show that their algorithm has much better losses on the problems studied.",
            "main_review": "Here are some of the paper’s strengths and weaknesses:\n\n(+) I thought that the motivation and the illustration with Figure 2 was compelling. Combinatorial optimization problems can be very sensitive: perturbing the problem’s parameters by just a little bit can cause the solution to change by a lot. Therefore, naively optimizing a standard loss function to predict the problem’s parameters can lead to poor downstream results for the optimization task.\n\n(+/-) I think that the “strong ranking property” is promising, but it could be fleshed out. When it is first described in Section 1, it’s very abstract and hard to grasp what it means. The ranking example in Section 3.1 helps, but I think that it comes too late. Moreover, it’s never really explained why certain combinatorial problems have this property, so the reader has to trust that it’s a useful property and that the problems in the experiments section satisfy the property. A few fleshed-out examples and explanations would be helpful.\n\n(-) The theoretical results leave something to be desired, since they show that for a very specific example, optimizing using the proposed approach is weakly better than optimizing using the l2 loss. This would, of course, be more compelling if the authors could provide an example where the proposed approach is better than using the l2 loss by some non-zero margin.\n\n(-) The applied approach to representing $L$ using discretized Derivative-of-Gaussian filters seemed a bit ad hoc and I didn’t really understand the deeper intuition behind why this might be a good approach.\n\nMore detailed comments:\n- Figure 2: It was a little hard to tell where the stars and triangles lie on the x-y axes.\n- Definition 3: At first, it was a bit hard to grasp what L is supposed to represent. Maybe this could be explained earlier, and with an example.\n- Equation (3): Should sign be tanh?",
            "summary_of_the_review": "Overall, my recommendation is “weak accept” because I think the motivation is compelling and the “strong ranking property” seems to open up this predict-then-optimize framework to important combinatorial optimization problems (though I’m not very familiar with prior research on this specific topic). As I mentioned in the main review, there are a lot of ways the paper could be fleshed out to increase it’s potential impact.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}