{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper is close to the borderline, but I think it is good enough that I recommend its acceptance. Although there were some problems raised by the reviewers, the authors managed to successfully address a majority of them. Having said that, I still recommend that the authors carefully analyze the reviews again and make sure that they incorporated reviewers' comments in the final version of the paper. A lot of them were constructive and might improve the quality of the paper."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "THis paper proposes a special version of AutoAugment to search class-wise data augmentation policies for EEG data. The main contribution of this paper is a novel differentiable relaxation algorithm on EEG data (ADDA) that significantly efficiency of policy search. Through the EEG sleep staging task, the paper shows they achieved SOTA with 40% speed on efficiency and 1.4% accuracy increase. \n",
            "main_review": "Strengths: \n\n1) The paper provides a strong foundation of related work and solid experiments to validate the improvement from their idea. \n2) The way of using AutoAugment in EEG data is interesting and novel. \n\nWeakness:\n\n1) This paper is very hard to follow. The writing will require significant reorganization. It seems Section 3-5 are all of their proposed methods, but it also contains a significant amount of content of former work. I think it would be really great to have a method/approach section to talk about the proposed method. Also, section 4 also includes some evaluation details, which makes me very confused to understand. Please cluster all the evaluation details into Section 6. I think the main contribution of this paper should be from section 5, please try to highlight it. \n\n2) There is only a little accuracy gain in this paper (1.4%). Could you please provide more justification for this? \n",
            "summary_of_the_review": "This is an interesting paper in machine learning and healthcare. The approach introduces novelty in ML and has a potential to broader healthcare applications. However, the paper requires more work to improve writing quality. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes an automatic differentiable data augmentation algorithm for EEG data that outperforms existing methods. They also propose novel augmentations for EEG that help the model to train better in low-labeled data regimes. They also show preliminary results showcasing that class-wise augmentation can be better than class agnostic augmentations for EEG data.",
            "main_review": "Strengths:\n1. The work done by authors in the field of data augmentation for EEG data is novel and interesting. The improvement achieved by these augmentations is significant and could be important for building robust models. Especially, the frequency shift augmentation can be important for building models that can overcome the domain-shift problem due to inter-subject variability. The proposed augmentations are also given high weights by the automatic algorithms (Fig. F.2) which are interesting.\n\n2. Authors' preliminary experiments on investigating the usefulness of class-wise augmentations are also interesting. As mentioned by the authors, the field is relatively less explored (even more so for EEG data). Hence, the first steps taken in this direction are significant.\n\nAreas of improvement:\n1. Authors shows experimental results only for two datasets which are not standard. To alleviate our concerns about the quality of computational experiments and to strengthen authors' claims, it would be great if the authors can provide results on standard datasets (Imagenet, SVHN, CIFAR-100, or CIFAR-10) and show an improvement over previous methods.\n\n2. Model architecture details are missing. It would be great if the authors can include these details. Additionally, previous works like DADA have shown that their method performed well irrespective of model architecture or downstream tasks. It would be great if authors can include additional experiments to show that their method also performs well for different model architectures and downstream tasks (classification, segmentation, object detection, etc.)\n\n3. As per the authors, the core difference between their method and DADA is that DADA only samples the whole sub-policies whereas they sample operations within each sub-policy. But, according to my quick overview of DADA, in addition to sampling whole sub-policy, they do sample operations within each sub-policy (see sections 3.2 and 3.4 of [DADA](https://arxiv.org/pdf/2003.03780.pdf)). It would be helpful for the readers if authors can concretely differentiate their method from DADA using mathematical equations for both methods. They can include it in the appendix. I think this would help to understand the novelties of (C)ADDA over DADA.\n\n4. Some other algorithms like PBA and OHL-AA are missing from the comparisons. I would encourage authors to include them to strengthen their claims. Additionally, instead of keeping Randomsearch in the appendix plot (Fig F.3), I would include it in the plot in the main text (Fig. 4(a)) so that readers can get some baseline reference. A related question, why was Fast AutoAugment (pink in Fig. F.3) not shown in the main plot? It has better performance in terms of computation time and accuracy than DADA.\n\n5. Since the difference in the performance of different methods is small (~1%), I would like to see 95% confidence intervals for the performance measure (by bootstrapping the test set).\n\n6. For CW methods, just like CW-FastAuto Augment and CW-Auto Augment, what happens if we implement CW-DADA? \n\n7. Fig 2. b shows improvements only for two augmentations, what happens for other augmentations? \n\n8. As mentioned in the strengths, although the idea of class-wise augmentation is interesting, CADDA does not outperform ADDA and many other methods. So should this paper be titled based on CADDA? Wouldn't it be misleading for the readers as they would expect to see a Class-wise algorithm that outperforms all other methods?",
            "summary_of_the_review": "Although the paper has some great (but minor) contributions in terms of the novel augmentation for EEG data, there are still many aspects in which the paper can be improved. As per the current state of the paper, my recommendation would be a score of 5 (marginally below the acceptance threshold). If the authors address the above-mentioned concerns and strengthen their claims with additional experiments, I will be happy to update my score.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studies gradient-based automatic data augmentation algorithms amenable to class-wise policies with exponentially larger search spaces. It presents a method, called  CADDA, to address the problem of automatic data augmentation with application on EEG signals. The proposed method achieves good results for EEG sleep stage classification.",
            "main_review": "- This paper investigates gradient-based automatic data augmentation algorithms amenable to class-wise policies with exponentially larger search spaces.\n\n- The idea of the proposed method, CADDA, is interesting. Indeed, the paper shows that the exploration of gradient-based search approaches allows to select policies more efficiently in a huge search space.\n\n- The novelty of the proposed method is on the novel operations relaxation and the estimation of the augmentation policy gradient.\n",
            "summary_of_the_review": "The paper is clear and well presented. The idea of the proposed method seems interesting. The experimental results show the effectiveness of the proposed method. A supplementary material was given to show more detail and results.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The work explores the problem of automatic data augmentation beyond images which is still rarely considered in the literature. The authors provided novel transforms for EEG data, and a state-of-the-art search algorithm.",
            "main_review": "Pros:\n\n+ This is an interesting work. The examples of object recognition and sleep staging are very intuitive and demonstrates the motivation of exploring the CW data augmentation approaches.\n\n+ The authors designed some data enhancement methods for EEG. The new EEG data augmentation **frequency shift** introduced in Section 3 makes sense, as Figure 1 illustrates the fact that applying a 0.5 Hz frequency shift transform to one subject can lead a power spectrum density more similar to another.\n+ The paper shows adequate experiments and provides detailed supplementary material.\n\nCons:\n\n+ It is mentioned that the three new EEG data augmentations, namely time reverse, sign flip and frequency shift, are operations acting on the time, space and frequency, respectively. But I'm confused about why sign flip can be categorized as a spatial operation. Please clarify it.\n\n+ Since data augmentation is usually employed to solve the class imbalance problem, which is a great challenge for sleep stage classification, macro- and micro-F1 score should also be presented in the performance comparison experiments.\n\n+ The performance of ADDA and CADDA are compared, which shows that CADDA does not improve over ADDA. But why the comparison of class-wise(CW) and class-agnostic(CA) settings of other baselines is not conducted? I wonder whether the CW setting of other methods can contribute to a better performance than the CA setting.\n\n+ It is mentioned that \"For each run, when the final retraining validation accuracy improves compared to previous retraining, we report the new test accuracy obtained by the retrained model (otherwise, we keep the previous value)\", but the 5th point of ADDA in Figure 4(a) is lower than the 4th point, which seems to be contradictive. Please clarify it.\n\n+ More recent methods, especially the ones work on time-series data augmentation (e.g. [1]), should be compared with the proposed method. \n\n+ Although the author focuses on solving problems in the field of data enhancement. But sleep staging is an important application of the author. I hope that the method proposed by the author can be compared with some of the latest sleep staging methods, such as [2] and [3].\n\n  [1] Fons E, Dawson P, Zeng X, et al. Adaptive Weighting Scheme for Automatic Time-Series Data Augmentation[J]. arXiv preprint arXiv:2102.08310, 2021.\n\n  [2] Perslev M, Jensen M H, Darkner S, et al. U-time: A fully convolutional network for time series segmentation applied to sleep staging[J]. arXiv preprint arXiv:1910.11162, NeurIPS, 2019.\n\n  [3] Jia Z, Lin Y, Wang J, et al. SalientSleepNet: Multimodal Salient Wave Detection Network for Sleep Staging[J]. IJCAI, 2021.\n\n\n",
            "summary_of_the_review": "They propose a new differentiable relaxation of the problem. Some details of the evaluation and comparison of experiments need to be explained or clarified.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}