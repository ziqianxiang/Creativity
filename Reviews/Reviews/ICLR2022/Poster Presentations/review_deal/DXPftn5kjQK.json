{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper analyses theoretically the 'Matthew effect' (disparate impact) in the setting \nof the semi-supervised learning and its effect on fairness and performance. \n\nAll reviewers agree that the paper deals with a very interesting topic and important problem. \nThe paper discusses and presents a thorough and convincing analysis of the effect.\nThere were multiple concerns raised mainly around the lack of clarity at parts of the paper.\nThe authors did a very good job at resolving those and bringing their submission to a good standard. \nIn the rebuttal I was glad to see a great dialog evolving among the authors and reviewers. \nI congraultate both sides. \n\nHappy to recommend acceptance."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents the disparate impact on semi-supervised learning, where the sub-population that has a higher baseline accuracy tends to benefit more from SSL. The paper targets an important problem to ensure the fairness of machine learning algorithms. The authors also proposed a new metric benefit ratio to facilitate the evaluation of SSL. They also suggested two methods to mitigate the disparate, balancing the labeled data or collecting more labeled data.",
            "main_review": "The paper studies the sources of disparate impact on SSL from both theoretical and experimental demonstrations. Theoretically, the SSL problem was transformed to supervised learning with noisy labels by assigning pseudo labels. Both theoretical and empirical work show that the major source of the disparity comes from the low supervised error.\n\nThe paper has high ethical value. The theoretical proof and experiments are sound and support the conclusion of the paper.  I have a few minor comments for clarification. \n- Could you please clarify why figure3(a) shows a range of the benefit ratio, not the other figures?\n- How is the ideal ground truth label a_ideal(P) calculated in the experiments? How robust is that, and how will it affect the calculation of BR?\n",
            "summary_of_the_review": "In general, the paper is well written. The task is novel and well supported by theoretical proof and experimental evaluations. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper analyzes the discriminative performances of semi-supervised learning (SSL) on different subgroups, based on the key message that the already accurate group gets more benefits from the SSL. The paper first proposes a unified loss for analyzing the SSL frameworks. Then, the theoretical analyses show how the SSL produces discriminative performances on the different groups. In addition, a metric called benefit ratio is suggested to measure how much the learning benefits a certain subgroup. Experiments show overall consistent results with the main message from the theory. \n",
            "main_review": "\nStrengths:\n\n- The paper provides meaningful analyses to investigate the disproportionate performance of semi-supervised learning (SSL) on different subgroups. \n- The theoretical results show that the SSL frameworks possibly provide discriminative benefits to the subpopulations, which is consistent with the intuition. \n- In addition, experiments are performed with three representative SSL methods on several datasets for vision and natural language processing tasks. The experimental results confirm that the discrimination of the SSL frameworks can be a problem in various datasets.\n\nConcerns:\n\n- It would be better to clarify the term “disparate impact.” Disparate impact is used in many model fairness papers as a specific category of unfairness or a group fairness metric [1, 2]. Thus, if the paper used “disparate impact” as a broader term to explain the bias in SSL, it would be nice to explain the difference from the language in the previous papers.\n\n- In Figure 1, several “poor” classes seem to get enough accuracy gain. The intuition for “the rich get richer, and the poor get poorer” is convinced, but not sure why Figure 1 can be the best example for this message. For example, “bird, cat, and deer classes” in the left subfigure and “horse class” in the right subfigure initially have poor accuracy, but the performance adequately increases during SSL. Thus, I am not sure this figure clearly shows the main message. It would be nice if the paper clarifies these phenomena and connect them to the main takeaway.\n\n- It would be helpful if the paper gives more details on Section 3. For example, $\\eta$ is considered the disparity due to baseline and the major source of disparity, but it is not clearly explained. Also, the warm-up paragraph says the range of Term-1 becomes [1-2$\\epsilon$, 1]. However, if the range changes to the corresponding bound, $\\eta$ and $e$ should become 1, which is unclear. Such details might help to strengthen the paper.\n\n- When evaluating the training by the benefit ratio, how can we get the ideal accuracy (i.e., the first term of the denominator)? Since the ideal accuracy is defined as the accuracy from fully-supervised learning with the ground truth labeled dataset, it seems hard to get the value in the real scenarios. Also, is there any reason why the existing group fairness metrics (e.g., demographic parity and equalized odds) cannot be applied in the SSL scenario? These might provide other intuitions on the SSL frameworks.\n\n- Some experimental settings are unclear. For example, why are the experiments assumed that the labeled data are balanced, but the unlabeled data are imbalanced  (Figures 2 & 3)? It would be better to explain why the current setting is a suitable and natural choice for observing fairness in SSL.\n\nReferences\n\n[1] Zafar et al., Fairness Constraints: Mechanisms for Fair Classification, AISTATS 2017.\n\n[2] Bellamy et al., AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias, IBM J. Res. Dev. 2019.\n\n",
            "summary_of_the_review": "This paper provides useful analyses on the fairness issue in the semi-supervised setting. Although I have some comments as described above, the paper is overall well-written.\nThus, I believe that this paper is worth publishing after clarifying several parts.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Please see main review.",
            "main_review": "This paper aims to theoretically study the 'Matthew effect' (or disparate impact) of semi-supervised learning (SSL). The authors consider the consistency regularization-based approaches with either explicit or implicit pseudo labels. The authors first show that both types could be unified into one framework that is related to empirical risk minimization, where the pseudo labels are served as the noisy labels. Then the source of the Matthew effect is studied by deriving the generalization bound of the expected risk. A new metric named benefit ratio is further proposed to theoretically understand the Matthew effect of SSL with consideration of the derived generalization bounds. Experimental results shows that (1) popular SSL methods almost all suffer from this effect, and (2) the mitigation strategies guided by analyzing benefit ratio could reduce such Matthew effect.\n\nOverall, I think this paper is studying a very interesting and important problem. Theoretically analyzing the varied performance over different sub-populations may help design a better SSL method so that certain sub-populations are taken care of, which might also improve the overall performance. Please see my concerns regarding the submission as follows.\n\nConcerns\n- Usually in algorithmic fairness, disparate impact is more concerned about the acceptance rate rather than accuracy (though it may not be correct in legal support area). I think it would be better to have a few sentences to explicitly clarify the difference between the 'disparate impact' in this paper and the 'disparate impact' usually used in algorithmic fairness.\n\n- Some key references are missing, which study the varied classification accuracy among different sub-populations. Please see these papers at the end of my comment. And I believe the authors should discuss whether the existing works can be used in SSL setting. If yes, some analysis on their performance are needed; if not, some sentences on discussing why they cannot work are needed. My hunch is that, if we can view SSL as supervised learning with noisy labels, some of these works should work.\n\n- In RHS of Eq. (2), do we really need the average over the expectation? I thought the average should be absorbed into the expectation. I hope the authors could clarify it.\n\n- In proof of Lemma 3, the denominator in the square root has a coefficient 2 while the results in the main body does not have this coefficient, so at least one place is wrong.\n\n- Again, in proof of Lemma 3, is it possible for the authors to provide more details on how the first inequality (<= 0 + 2max|...|) is derived? \n\n- In figure 2, the correlation between baseline accuracy and benefit ratio is not clear for UDA on Yahoo dataset. Some analysis are needed. Also, the authors might want to correct their claim 'We consistently observe that the class labels with higher baseline accuracies have higher benefit ratios on both CIFAR-10 and Yahoo! Answers datasets.' because results of UDA on Yahoo does not reveal such observation.\n\n- Just out of my curiosity (this may be out of the scope of this paper), I wonder whether similar analysis can be generalized to SSL on graphs.\n\nReferences\n* Hashimoto, T., Srivastava, M., Namkoong, H., & Liang, P. (2018, July). Fairness without demographics in repeated loss minimization. In International Conference on Machine Learning (pp. 1929-1938). PMLR.\n* Kim, M. P., Ghorbani, A., & Zou, J. (2019, January). Multiaccuracy: Black-box post-processing for fairness in classification. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society (pp. 247-254).\n* Lahoti, P., Beutel, A., Chen, J., Lee, K., Prost, F., Thain, N., ... & Chi, E. H. (2020). Fairness without demographics through adversarially reweighted learning. arXiv preprint arXiv:2006.13114.\n* Diana, E., Gill, W., Kearns, M., Kenthapadi, K., Roth, A., & Sharifi-Malvajerdi, S. (2021). Multiaccurate Proxies for Downstream Fairness. arXiv preprint arXiv:2107.04423.\n* Martinez, N., Bertran, M., & Sapiro, G. (2020, November). Minimax pareto fairness: A multi objective perspective. In International Conference on Machine Learning (pp. 6755-6764). PMLR.",
            "summary_of_the_review": "This paper studies an interesting problem. But some key references are missing, which should be discussed in related work and (potentially) evaluated as baseline methods.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper claims semi-supervised learning (SSL) does not uniformly improve performance on all the constituent (latent) sub-population of the group. \nMore alarmingly, they claim that the SSL improves the performance most on the groups that already fare well (before SSL) with deteriorates on groups that are already worse.\nThey argue intuitively and theoretically for the likely cause.\nWith text, image datasets and three SSL algorithms, they provide empirical evidence that can support their main claim.\nFinally, they briefly discuss strategies that could avoid such disparate impact of SSL. ",
            "main_review": "## Strength\n- Disparate impact on the constituent sub-population when training through SSL is an important problem. \n- Their theoretical analysis is sound. \n\n## Weakness  \n\n**Matthew effect: Rich getting richer and poor getting poorer**   \nI do not see the poor getting poorer part of their claim. \nIf poor gets poorer we should see the test accuracy of *dog* only decreasing with SSL in Fig 1 (b).\nBesides the 'dog' class, no other \"poor\" sub-population got worser with training in the same figure, for e.g. see *horse, ship, truck* classes. \nSimilarly, in Fig 2, 3, we should have seen negative BR for the poor population if poor gets poorer, but that is not the case in any of the sixteen plots; all the BR values are positve.\nAlthough, I agree that SSL does not benefit all the sub-population equally, and that \"rich\" sub-population gain owing to lower label noise in the induced labels on the unsupervised data.\n \n**What is the fairness concern here?**   \nSSL training benefit some/rich sub-population more than the others.\nAs a result, it improves the average accuracy without hurting the worst group accuracy (since BR>=0 for all groups). \nI would not call out SSL as unfair unless the poor population gets even worser, i.e. the rich groups get richer at the expense of poor groups.\nThe authors should be more formal when discussing the fairness aspect and explain depreciating population disparity in the context of a fairness metric. \n\n**Analysis**   \nIs not $\\bar\\eta'(\\hat f_{D_L})$ simply the risk with clean data, i.e. $R_{D}(\\hat f_{D_L})$? This is so because both measure the expected disagreement of the prediction to the label (in the confident case of Lemma 2).   \nReplacing $\\eta$ with $R_D$ in Thm 2, we have:\n\n$$\nR_D(\\hat f_{D_L\\cup D_U}) \\leq \\frac{N_U}{N}R_D(\\hat f_{D_L}) + \\text{<other terms>} \n$$\n\nWhen $N_U\\rightarrow \\infty, i.e. N_U\\approx N$, we have $R_D(\\hat f_{D_L\\cup D_U}) \\leq R_D(\\hat f_{D_L}) + \\Pr(\\tilde Y\\neq \\tilde Y^*)$, and as a result the upper bound for SSL case is worse than the usual case.\nThe generalization error bound of Thm 2 therefore cannot explain the improved performance on a subset of population. \nPlease clarify if I am missing something. \n\nSince the generalization upper bound of Thm. 2 is used for qualitative judgment on the effect of SSL, its sanity should be established I believe. \n\n**More technical details needed**   \nI found Section 5.2 hard to understand even after consulting the Appendix. \nDescription for Table 1 numbers is unclear. \nWhat does each of the settings mean? What is balanced: group population or label population? Where is the balancing, in labeled or unlabeled?\n\nSomewhere in the intro, the authors mention BR could even be greater than 1, and we also see that in some of the BR plots (Fig 2 a,b), for the richer classes. I do not understand how. \nIf the ideal population size is at least N_L+N_U, any BR value greater than one is only due to the empirical error in accuracy estimation. Please clarify. \n\n\n## Minor\n- In the last line of A.3, Hoeffding's ineq. does not give uniform deviation bound unlike what was stated there. \n- The upper bound of Thm 1 contains constants that go with the $1/\\sqrt{n}$ term, such as the maximum possible value of loss. But the order remains the same. \n- In Tab.3 of appendix B.4, need to explain what 1:2 Benefit ratio, 1:5 accuracy etc. mean.\n",
            "summary_of_the_review": "The prime objective of the paper is to demonstrate the Matthew effect of SSL and its fairness consequences.  \nAs described in more detail above, I have concerns regarding both the aspects of their contribution.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}