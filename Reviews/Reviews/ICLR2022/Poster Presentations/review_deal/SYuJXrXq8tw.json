{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper focuses on leveraging static and dynamic sparsity in efficient robust training. The proposed methods can significantly mitigate the robust generalization gap while retaining competitive performance (standard/robust accuracy) with substantially reduced computation budgets. The philosophy behind sounds quite interesting to me, namely, sparsity allevating overfitting and improving training efficiency simultaneously. This philosophy leads to two novel algorithms design, i.e., static Robust Bird training, and dynamic Flying Bird training.\n\nThe clarity and novelty are clearly above the bar of ICLR. While the reviewers had some concerns on the significance, the authors did a particularly good job in their rebuttal. Thus, most of us have agreed to accept this paper for publication! Please include the additional experimental results in the next version."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper deals with the problem of training a neural network so that it generalizes well over data unseen at training time. Namely, they address the particular case where a network is trained over an adversarial scheme. This paper proposes two methods for learning a sparse architecture called robust and flying bird. These methods aim at identifying sparse subnetworks arising during early training stages, so to get a pruning mask that eventually yields a sparse architecture (RobustBird). FlyingBird improves over Robust Bird in teh sense that the learning mask can be dynamically adjusted over time, i.e. pruned params may be recovered later on. The authors then experiment at training multiple architectures over different datasets in the experimental section, showing better generalization abilities and lower computational complexity (MACs) for their proposed methods Robust and Flying Birds. the authors conclude that sparsity help networks to generalize better, and as a byproduct it slashes computational complexity.\n",
            "main_review": "\nIt is well known that sparsity helps generalizing: from example, already Han 2015 in Fig 5 shows that pruning (simple L2 regularization + thresholding) helps the network generalizing over unseen data. Similarly, the same article shows that refining the surviving parameters after pruning yields better performance, and according to my personal experience it is also true that allowing parameters to enter and exit the pruning pool, i e allowing the pruning mask to evolve, improves performance under multiple points. So, in general those \"findings\" claimed by the article are not that novel according to the existing literature.\nConcerning the experiments, the authors compare with a number of different reference strategies for pruning ratios of 80% and 90%. While I do not put into question the tradeoff between sparsity and performance, the performance corresponding to the sparsity ratio selected by the authors is so low and far beyond typical useful accuracy numbers for unpruned architecture that I cannot avoid questioning the meaningfulness of the reported results. In other words, it is inconclusive for the reader to see  that the proposed method performs x% better than the closest reference when you are in the 40/50% accuracy range for cifar 10.  I would suggest the authors to compare for a sparsity so that the  performance is  closer to more typical values for unpruned architectures.\nIn this context, it is not clear how a reference strategy based on simple L2 regularization without pruning would perform in term of generalization ability and that would be an interesting extra reference to consider.\n\n\n\n[Han 2015] Song Han, Jeff Pool, John Tran, and William Dally. Learning both weights and connections for efficient neural network. In Advances in neural information processing systems, pp. 1135–1143,\n2015b",
            "summary_of_the_review": "This paper addresses a relevant issue, however the main conclusions they draw didn't exactly make me jump on my seat, and while the proposed method may have some originality, the experimental results leave quite a question open about their significance given the considered sparsity/performance tradeoff point the authors consider. I would recommend the authors to revisit their claims under the light of the existing literature dealing with the relationship between sparsity and generalization ability, and to present their experimental results at a higher accuracy target.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "Recent studies demonstrate adversarial training suffers from severe overfitting besides getting very expensive. This paper proposes to handle the two problems organically altogether, with the tool of sparse training. \n\nThe authors show that injecting appropriate sparsity forms in training could substantially shrink the robust generalization gap and alleviate the robust overfitting, meanwhile significantly saving training and inference FLOPs.\n",
            "main_review": "It is known that good sparsity can help prevent overfitting as well as reduce inference costs. The main barrier of making sparsity practical for (adversarial) training is the good sparsity pattern itself can be expensive to retrieve. This paper lays out a series of options to mitigate that barrier for adversarial training (AT).\n\nThe authors first demonstrate that good sparse subnetworks can be identified at the very early AT training stage with one-shot pruning, and the remaining stage could focus on training that very compact subnetwork. While similar observations were already drawn by You et. al. 2020 in the standard training, a notably progress made by the authors is that the mask can be located from just the cheap standard training, and it will still incur almost no performance loss when being re-used towards adversarial re-training.  I find it quite intriguing and meaningful.\n\nThe authors continue to investigate the role of sparsity when the sparse connections of subnetworks are on the fly. It allows more flexibility for the network to lower the training loss more, by tweaking not only weights but also topology. The authors further relaxed it to dynamically adjust the network capacity/sparsity to pursue superior robust performance, at a minor sacrifice of training efficiency.\n\nThe authors reported a variety of experiments using two backbones and three datasets. Their proposed methods are found to reduce robust generalization gap and overfitting by 34.44% and 4.02%, with comparable robust/standard accuracy boosts and 87.83%/87.82% training/inference FLOPs savings on CIFAR-100 with ResNet18; and similar competitive performance on other settings. Their proposed approaches can be combined with existing regularizers to yield new state-of-the-art results. The authors also carefully examined their robustness gains against adaptive and transferred attacks. \n\n\n\nHere I have only two nitpicks. First, it would be better if the authors can give some theoretical insights why their strategy works, even with simplified assumptions. Currently the rationales offered are a bit vague. Second, while the FLOPS reduction is impressive, no actual hardware measurements were reported like in the Early Bird paper. Discussing the practical hardware benefits of the proposed strategy would enhance this work’s impact.\n\n=================== post rebuttal ====================\n\nI have read the rebuttal and the rebuttal addresses my concerns.",
            "summary_of_the_review": "I am inclined to recommend acceptance, owing to the paper’s novel angle and solid experiment evaluations. I have no major critique.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors proposed to leverage static and dynamic sparsity in efficient robust training. The proposed methods can significantly mitigate the robust generalization gap while retaining competitive performance (standard/robust accuracy) with substantially reduced computation budgets.",
            "main_review": "Strength:\n-\tThe motivation for introducing sparsity to adversarial training for both generalization and efficiency gains are valuable and novel. The paper investigates two sparsity forms: static and dynamic.\n-\tFor the static form, the paper extends the early-bird idea by You et. al. 2020, and show the phenomenon also exists in the adversarial training scheme. So in general the novelty of this paper is only fair, except a surprise finding that even in adversarial training, EB tickets can still be drawn from a cheap standard pre-training stage.\n-\tFor the dynamic form, the authors presented a vanilla version plus an advanced variant capable of adaptively adjusting the sparsity levels. \n-\tExperiments are solid and convincing. Besides PGD, the authors also used Auto-Attack (Croce & Hein, 2020) and CW Attack (Carlini & Wagner, 2017) for a more rigorous evaluation. The authors also carefully excluded obfuscated gradients using transferred unseen attacks\n-\tAttention visualization is another interesting and novel angle to compare different pruning methods.\n-\tPaper is structured well and easy to follow. I especially like that rationale is always clearly presented in company with the algorithms\n-\tAll codes are included, and the reproducibility looks good to me.\n\nWeakness:\n-\tI would appreciate if the authors could elaborate more on why the sparse mask found from a non-robust model could be reused to training a robust model. If that is true, I wonder whether or not there indeed exists any tight coupling between sparse mask structure and robustness.\n-\tTable 1 only have two sparsity levels: 80% and 90%. Why only this two, are they specifically cherry-picked? It would be better if the authors could demonstrate some more sparsity levels.\n-\tTable 1 should also have compared with Early Bird (You et al. (2020) ) and existing dynamic sparse training methods (Evci et al. (2020a); Liu et al. (2021b))\n-\tThis paper does not provide any theoretical analysis on why the proposed strategy should work for efficient adversarial training. It is unclear which factor is the main performance booster: sparsity regularizing the adversarial overfitting, or sparsity for efficient “lottery”-style training. Despite this work being mainly empirical, some theory probing would have improved it.\n-\tTypos: “much more flatter” -> much flatter, and more. Proofreading is required.\n",
            "summary_of_the_review": "This is an interesting work with solid execution. More experimental clarification and analysis would be welcome.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper studies an important topic of improving adversarial training with different sparsity forms, and the authors made positive discoveries that injecting sparsity properly would make a win-win between efficiency and generalization. \n\nAll findings are not too surprising, but the authors’ effort of presenting a particularly comprehensive empirical study is acknowledged. \n",
            "main_review": "(+) The idea is very interesting and promising. It is reasonable to find sparsity helps both reduce overfitting and improve training efficiency. For adversarial training, that could lead to very significant cost reduction. \n  \n(+) The authors’ study on how to inject sparsity is very comprehensive. They considered two alternatives for sparse adversarial training: a static Robust Bird (RB) training, and a dynamic Flying Bird (FB) training. The former identifies critical mask structure at early training stage, while the latter continues to optimize the mask throughout the entire training. \n\n(+) It is great the authors show that their proposed methods can be combined to boost previous SOTAs. That definitely amplifies their work’s value. \n\n(+/-) Experiments are a bit limited, using only two models (VGG and Res18). However, the aspects being evaluated as well as the ablations are very thorough, and I kinda agree the results mostly suffice to validate their points. \n\n(-) However, the biggest issue I have with experiments is: they did not compare with latest efficient adversarial training methods, such as “Adversarial training for free!”, NeurIPS 2019; and “Towards practical lottery ticket hypothesis for adversarial training” in arXiv 2020. The latter one is also based on sparsity and has certain overlap with Robust Bird. The authors did compare with Fast AT, but that was placed in the Appendix only.\n\n(-) Furthermore, even standard adversarial training or adversarial pruning methods could have been made cheaper, by either early-stopping with less epochs, or using fast/free-AT to replace their more expensive AT sub-modules. The authors need to discuss whether those methods can become their competitive baselines, in a convincing way, not ignoring it. \n\n(-) It is unclear to me whether the final robustness gain comes from the good mask structure or just sparsity itself. In particular, random pruning in Table 1 performs better than I would expect, inviting the aforementioned question. \n\n(-) More sparsity levels should have been tried.\n",
            "summary_of_the_review": "My biggest reservation currently lies in lacking comparison with SOTA efficient adversarial training methods. The value of this work cannot be solely established without that comparison. Overall, I’m currently rating as borderline and would decide my final rating based on the authors’ rebuttal.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}