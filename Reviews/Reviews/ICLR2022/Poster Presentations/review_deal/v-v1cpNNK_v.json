{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper proposes an efficient training-free NAS method, NASI, which exploits Neural Tangent Kernels (NTK)’s ability to estimate the performance of candidate architectures. Specifically, the authors provide a theoretical analysis showing that NAS can be realizable at initialization, and propose an efficient approximation of the trace norm of NTK that has a similar form to gradient flow, to alleviate the prohibitive cost of computing NTK. Since the method is training-free, NASI is also label- and data-agnostic. The experimental validation shows that NASI either outperforms or performs comparably to existing training-based and training-free NAS methods, while being significantly more efficient.\n\nThe below is the summary of pros and cons of the paper, after :\n\nPros\n- The idea of using NTK to predict the performance of candidate neural architectures is both novel and promising, and the proposed analysis and efficient approximation are non-trivial.\n- The paper provides sufficient theoretical proof of its claims, including the assumptions made.\n- The method is highly efficient in terms of search cost, and the searched architectures obtain good performance on benchmark datasets.\n- The method is data/label free and thus allows transfer architectures across tasks.\n- The paper is well-written.\n\nCons\n- There is no result on ImageNet obtained by directly applying NASI on it. \n\nThe initial reviews were split, due to other concerns regarding whether the proposed method finds good architectures, missing comparison against certain training-free baselines, and some unclear descriptions. However, they were addressed away by the authors during the rebuttal period which led to a consensus to accept the paper. \n\nIn sum, this is a strong paper that proposes a novel idea for training-free NAS, and the proposed method seems to be both effective, efficient, and generalizes well across tasks. One remaining concern is the computational cost of running the method on larger datasets, such as ImageNet, and I suggest the authors report the results and the running time in the final paper.\n\nAnother suggestion is to include discussion of, or comparison to other efficient NAS methods based on meta-learning, such as MetaD2A [Lee et al. 21], which is not training-free but is more efficient than the proposed NASI. \n\n[Lee et al. 21] Rapid Neural Architecture Search by Learning to Generate Graphs from Datasets, ICLR 2021"
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a new training-free NAS method, where it is not necessary to optimize the weight parameters of target networks for architecture search. To achieve this, the paper exploits the capability of NTK for estimating the performance of candidate architectures at weight initialization. Thus, the proposed method can avoid network training during the search and achieve a much efficient architecture search. The experimental results show that the proposed method achieves competitive performance with existing methods and also can adapt to the label- and data-agnostic scenarios. ",
            "main_review": "+ The proposed method does not require the model training for architecture search, thus it is much more efficient than the previous NAS method.\n+ In addition to the efficiency, the proposed method can adapt to the label- and data-agnostic situations. \n\nConcerns:\n- Although NTK assumes infinite-depth DNNs, the proposed method does not seem to meet the condition. It would be nice to provide the reason why the proposed method can work. Also, I am interested in the lower bound of the network depth where the proposed method can work well.\n\n- The main concern about this method is whether the proposed method finds good architectures. Firstly, recent studies have claimed that NAS methods find architectures showing good performance but the rank of the found architecture is far from the best [Yu+, ICLR'20]. This comes from the fact that many candidates of CNN architectures in the search space can achieve good performance on the benchmark dataset such as CIFAR-10. In that sense, even though the proposed method achieves good performance on the benchmark datasets, I am wondering if the found architectures are really good or not. To check the rank of the architectures, it would be nice to use NAS-Bench-101 [Ying+, ICML'19]. Secondly, a recent study has argued that training protocols (e.g. data augmentation, training epochs) affect more on performance rather than search algorithms [Yang+, ICLR'20]. In fact, the training protocol affects a lot on the performance of DNNs, so I am wondering if the training protocol affects the estimation of the performance of candidate architectures by the proposed method or not.\n\n- The proposed method is inferior to another training-free method according to Table 4 in the appendix but shows better in the main paper. It would be nice to provide its cause and deeper analysis to better understand the proposed method.\n\n- Is it possible to directly apply the proposed method to a large dataset such as ImageNet?\n\n[Yu+, ICLR'20] Evaluating the Search Phase of Neural Architecture Search, ICLR'20.\n\n[Ying+, ICML'19] NAS-Bench-101: Towards Reproducible Neural Architecture Search, ICML'19.\n\n[Yang+, ICLR'20] NAS evaluation is frustratingly hard",
            "summary_of_the_review": "The proposed method shows promising results. My major concern is about the empirical and theoretical analysis (see concerns above). Hopefully, the authors can address my concern in the rebuttal period.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a training-free NAS method called NASI, which exploits the Neural Tangent Kernel (NTK) to characterize the performance of the candidate architectures at initialization. To alleviate the costly evaluation for NTK, the authors apply a similar form to gradient flow to approximate NKT. Moreover, they combined their NTK trick with gradient-based NAS algorithm via Gumbel-Softmax to solve NAS problem efficiently. The experiment results on various benchmarks illustrate the effect of NASI.",
            "main_review": "Strengths:\nTraining-free NAS method is interesting and arouses a lot of interests in NAS field. Based on the unchanged characteristic of NTK, this paper utilizes NTK to evaluate the candidate architectures at initialization. NASI is well-supported by the theorem of NTK and achieves competitive results empirically.\n\nWeakness:\nThe main concern is the approximations in the paper. Since NTK has a certain assumption about the neural network, the unchanged characteristic may not be satisfied for some neural architectures. To calculate the trace norm of NTK and to solve the NAS problem efficiently, the authors both apply approximations here. Since three approximations are applied, the final results may have a large deviation.\n\nBesides, I also have the following questions about the paper\n1. NASI is based on the theory of NTK, which has the infinity-width assumption. Also, there are approximations in Section 3.2 and Section 3.3. Can you discuss the bound of the approximation? Or just verify it empirically?\n2. In Proposition 1, you discuss the upper bound of the training loss. However, when the architecture convergences, we focus on the minimum value of the training loss. I am confused about the claim “we can simply minimize the upper bound of $\\mathcal{L}_t$” below the Proposition 1. \n3. There are some other training-free NAS methods (e.g., [1]). Can you compare NASI with them in a fair manner?\n\n[1] Mellor, Joe, et al. \"Neural architecture search without training.\" International Conference on Machine Learning, 2021.\n",
            "summary_of_the_review": "NASI applies approximations for neural architecture search at initialization based on NTK. However, some of them are not convincing to me (see the main review above). If the authors can provide detailed explanations about that, I would consider raising my score. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work proposes to search for good candidate neural architectures at initialization (NASI) so that we can completely avoid model training during the search.",
            "main_review": "Strengths:\nThe targeting problem of searching neural architectures at initialization is important and promising.\nThe paper finds that such NASI is guaranteed to be label- and data-agnostic under mild conditions, which demonstrates that the searched architecture can be transferred to different datasets or tasks.\nThe retrained accuracy is promising and comparable or even better than other gradient-based searching methods.\n\n\nWeakness:\nThe authors claim competitive effectiveness on both CIFAR and ImageNet, while I only find CIFAR results in Table 1 and ImageNet-16-200 in Table 4 (also 16 and 200 are not defined).\nHow comparable are the achieved accuracy to other NAS methods, e.g., FBNetv3, EfficientNet?\n",
            "summary_of_the_review": "This work proposes to search for good candidate neural architectures at initialization (NASI) so that we can completely avoid model training during the search. The theoretical analysis is also provided to analyze the optimization via NTK tools.\n\nThe authors replied my previous major concern with clarity, so I raised my score to 6. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper casts the problem of NAS into a training-free evaluation process by using neural tangent kernel (NTK). Specifically, the paper argues that the training dynamics and the performance of a DNN can be determined by the constant NTK of its linearization. Moreover, to efficiently evaluate the constant NTK of any network architectures, the paper proposes to use  the trac norm of NTK at initialization as an approximation. Using the NAS method proposed in this paper, one can search high-quality architectures with little GPU-hours. Interestigly, the proposed method is robust when applied in a data-/label-free search setting. Extensive experiments show that the searched networks have good performance and can be well-transferred to other datasets.",
            "main_review": "Pros\n++ The idea of using NTK as a network performance predictor for NAS is interesting, and the detailed method is non-trivial and plausible (including the relaxation and sampling to solve intractable optimization).\n++ The paper is well-written and easy to follow.\n++ The paper provides sufficient theoretical proof of its claim, including the assumptions made.\n++ The search costs are very appealing and the performance of the searched architectures are good.\n++ The proposed method can be data-/label-free, which is a good property that most NAS methods do not have.\n\nCons\n-- The performance of NASI is worse than TE-NAS on NAS-Bench-201 (Table 4).\n-- The advantage of NASI on ImageNet is not significant comparing to SOTA (Table 5).\n-- How about the results if NASI is directly applied on ImageNet, instead of transferring the best architectures searched on CIFAR-10?",
            "summary_of_the_review": "In general, this paper is of good quality and exceed the bar of being accepted by ICLR. Although I have some minor concerns about the performance, I think the paper has great contributions to the NAS community and should be recommended.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}