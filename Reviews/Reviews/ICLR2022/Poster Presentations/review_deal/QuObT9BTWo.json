{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper develops a ``preference-conditioned” approach to approximate the Pareto frontier for Multi-Objective Combinatorial Optimization (MOCO) problems with a single model (thus dealing with the thorny problem that there can be exponentially-many Pareto-optimal solutions). It appears to provide  flexibility for users to obtain various preferred tradeoffs between the objectives without extra search. The basic idea is to use end-to-end RL to train the single model for all different preferences simultaneously. \n\nThe technical soundness and practical performance are strong. This work's approximation guarantee depends on the ability to approximately solve several (weighted) single-objective problems. This may be challenging due to the NP-hardness of the latter. However, this limitation seems to also apply to other end-to-end learning-based approaches. \n\nOne area where the novelty is somewhat limited is that the paper borrows some number of ideas from neural single-objective optimization. The contribution overall seems noteworthy for hard multi-objective problems."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes an approach for neural multi-objective combinatorial optimization. This approach uses a preference-agnostic encoder along with a weight-dependent decoder to generate approximate Pareto optimal solutions for any arbitrary set of weights of a weighted Tchebyshev scalarization at virtually no additional cost. This is in contrast with existing approaches, which require a significant amount of computation for every new set of weights. Several numerical experiments are conducted, showing favorable results for the proposed method when compared with several other existing evolutionary and learning-based methods.",
            "main_review": "Strengths\n\n1. The proposed approach is technically sound and exhibits very competitive performance.\n2. The empirical evaluation is thorough as it considers multiple test problems and a broad range of benchmark methods.\n\nWeaknesses\n\n1. The description of the proposed approach is hard to follow. In particular, I am having a hard time understanding how the decoder is defined when the problem instance is not a graph. In general, I would recommend the authors explain their approach in a general fashion by introducing appropriate notation and then explaining it in the context of a particular problem.\n\n2. The use of the term \"preference\" is confusing. The title and abstract suggest that the proposed approach allows the incorporation of user preferences to focus the search on especific regions of the Pareto front, but that does not seem to be the case. I would suggest the authors to clarify this earlier (and even drop the term preference from their title).\n\n3. Since the proposed method relies on scalarizations, it suffers from several well-known issues of this kind of approaches. In particular, scalarization-based approaches are prone to explore the Pareto front unevenly. The points generated in Figures 2 and 5 are well distributed accross the Pareto front, but I think occurs because the front in this particular case is fairly symmetric. I wonder how an analogous figure would look for a more irregular front. I would also like the authors to explain how the weights that give rise to the points in Figures 2 and 5 were chosen.\n\n4. The novelty in this paper is limited, as it reuses several ideas from single-objective neural combinatorial optimization. The only novel (but key) idea is to make the decoder weight-dependent.",
            "summary_of_the_review": "This paper proposes a novel approach for neural multi-objective combinatorial optimization. The novelty of the proposed approach is limited as it reuses several ideas from single-objective neural combinatorial optimization. However, it is technically sound and exhibits a very competitive performance in a broad range of problems. The description of the method is hard to follow but, in general, the paper is well-written. The use of the term \"preference\" is confusing, so I would recommend the authors explain more clearly that their approach does not incorporate preference information.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a novel preference-conditioned method to approximate the whole Pareto front for Multi-Objective Combinatorial Optimization (MOCO) problems with a single model. According to the authors, this method provides extra flexibility for decision-makers to directly obtain arbitrary trade-off solutions without any extra search, which is a more principled way to deal with MOCO.",
            "main_review": "The paper is well-written and presents an interesting approach to solving MOCO problems. The structure is appropriate, there is a very good review of related works, clear problem formulation, a good description of the method, experiments, and results. There are also extensive supplementary materials. The introduced method is novel, might be significant, and the quality of this article seems to be on-par with other papers applying ML techniques to solve TSP published at top-tier conferences (which are also cited in this paper). I don't see significant weaknesses. There are some minor typos (e.g., \"a exceptionally\" -> \"an exceptionally\", p. 4), so I recommend revising the paper before the final publication, but from the methodological point of view, the paper seems to be good enough to be accepted.",
            "summary_of_the_review": "The paper is well-written and presents an interesting approach to solving MOCO problems. The structure is appropriate, there is a very good review of related works, clear problem formulation, a good description of the method, experiments, and results. There are also extensive supplementary materials. The introduced method is novel, might be significant, and the quality of this article seems to be on-par with other papers applying ML techniques to solve TSP published at top-tier conferences (which are also cited in this paper). I don't see significant weaknesses. There are some minor typos (e.g., \"a exceptionally\" -> \"an exceptionally\", p. 4), so I recommend revising the paper before the final publication, but from the methodological point of view, the paper seems to be good enough to be accepted.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This submission treats multi-objective combinatorial optimization problems and aims to approximate the pareto set. The idea is to build a single ML model that represents the pareto set by providing a pareto set solution for any desired trade-off. The model is build using reinforcement learning and may either be used to find singular solutions with fixed trade-off, or to approximate the pareto set with uniform samples. The authors prove that the pareto set is approximated well if individual trade-offs are approximated well. ",
            "main_review": "In my opinion, the authors provide an interesting and novel approach to multi-objecive optimization problems. Even representing the potentially exponentially large pareto set is a challenge, and is interesting that this can be done via an ML model. A concern could be that in order to achieve a good approximation of the pareto set, it seems that learning the single objective problem well is required (which often is a difficult problem in itself). Would it be possible to solve the single-objective variants with a traditional combinatorial algorithm? The theoretical contribution of this submission is limited.\n\nThe approach is evaluated for three very relevant problems: the multi-objective traveling salesperson problem, the multi-objective capacitated vehicle routing problem and the capacitated knapsack problem. \n\nA minor concern is that I found the tables with the experimental results hard to read. Could you please add a short explanation for the meaning of the table/column headers?",
            "summary_of_the_review": "I feel this is an interesting contribution concerning a difficult and relevant problem, whose well-made practical part makes up for a more limited theoretical study. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents a learning approach for multi-objective combinatorial optimization (MOCO), which is a challenging problem but not well-studied by previous machine learning researchers. The proposed model is capable of predicting approximate Pareto optimal solutions from various preferences by a single model, via attention networks, and by a so-called \"hypernetwork\". Experiment result on the multi-objective versions of TSP, VRP, and KP shows the effectiveness of the proposed approach.",
            "main_review": "### Strengths\n1. Multi-objective combinatorial optimization is a family of important problems but is really challenging to solve by traditional methods. The efforts of introducing deep reinforcement learning to this direction are appealing and novel. This paper may inspire more ML researchers in this interesting direction.\n1. The experiment results seem detailed and sound. The proposed neural network MOCO method outperforms traditional approaches and other single-objective deep learning baselines.\n\n### Weaknesses\n1. The theoretical part of this paper (Section 6 and appendix A) does not seem sound to me. The assumption that the model can generate $\\epsilon$-dominate solutions for any preference seems to be non-trivial for models with small enough $\\epsilon$. \n\n### Other comments\n1. The hypervolume (HV) metric should be discussed in the main paper instead of in the supplementary material to ensure the main paper is self-contained.",
            "summary_of_the_review": "In general, this paper is novel and sound, and the experiment results are convincing. I am suggesting a borderline accept of this paper, and it will be better if the authors could update the theoretical part of this paper and rearrange some materials to make this paper self-contained.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}