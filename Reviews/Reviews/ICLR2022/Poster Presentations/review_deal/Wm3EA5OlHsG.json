{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper shows interesting and discussion inspiring results on multi-agent trajectory prediction, as needed, for instance, in autonomous driving. Among the key technical ideas is a “conditional scene transformer” approach for flexible predictions for different agents.  Results on two  public benchmarks are impressive. Some reviewers are a bit torn about the significance of the technical contributions and the analyses of the results. Nevertheless, on average, the reviewers vote the paper to be above the acceptance threshold."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper presents a unified architecture to predict future motion trajectories of all agents in the scene, while interactions between agents are captured. A Transformer based architecture is designed. It also uses a masking strategy as a query, enabling one to condition on hypothetical agent futures during the inference time, and achieves conditional motion prediction or goal conditioned prediction. The model was tested on two standard datasets, and achieves state of the art performance.",
            "main_review": "Strengths: \n1. The scene transformer has its flexibility to switch between different prediction tasks by using different masking strategies.\n2. The model has proved to generate competitive results on both marginal and joint predictions compared to recent SOT algorithms.\n\nWeakness:\nSince model flexibility using the mask is the highlighted benefit of this model, I was expecting more experiments and discussion for the other prediction modes, such as conditional motion prediction and goal conditioned prediction. They are more interesting part of the paper that may lead a new direction for prediction model. However, the current result are still too preliminary. It would be better to provide more quantitative results to justify the advantage of such a unified model on CMP or GCP.\n\nSeveral design choices on components are described, such as factorized self attention and cross attention. An ablation study to summarize these findings would be better to review for the readers.",
            "summary_of_the_review": "Overall this is a strong paper with sufficient novelty in its model architecture in the context of motion prediction for autonomous driving. The experiment results on standard prediction tasks on popular benchmarks are convincing. Despite some minor issues in presentation, the paper is above the acceptance bar.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The manuscript proposes the use of a factorized attention mechanism and a masked transformer-based architecture, for conditional trajectory forecasting. Experiments on Argoverse and the Waymo Open Motion Dataset are provided.",
            "main_review": "Section: Abstract, Introduction: Issue with novelty. The manuscript \"[combines] a scene-centric approach, agent permutation equivariant model, and a sequence masking strategy...\". The first element (specifically, understanding the agent-to-scene interactions, through various attention mechanisms) has been considered, ad nauseum, by several trajectory forecasting works — in the last year alone. The second element is an inherent property of the chosen model class (that remains unsupported/uncited in the text, by the way) and, thus, cannot be used to strengthen the manuscript's contribution. The final element is a well-known practice related, again, to the chosen model architectural class: while it is true that the last element (sequence masking) has not been explored sufficiently in the context of trajectory forecasting (despite the already broad usage, now, of transformer-based architectures), I am hard-pressed to regard this as a strong standalone contribution to the community.\n\nSection: Introduction: The manuscript claims a \"unified architecture for prediction and planning\". I assert that this not appropriate. The manuscript itself cites Liu et al., (2021a) in reference to the goal-conditioned prediction (GCP) sub-task; however, *that* work is actually performs planning: they actually optimize with respect to a cost formulation, their model includes an inductive bias to learn the transition dynamics of the environment (online), and they evaluate their work in CARLA (an urban driving simulator, for evaluation of online planning and control). In this work, planning-related experiments are not shown: it is another conditional trajectory prediction approach with a transformer-based architecture. I would suggest that this manuscript removes all references to the term 'planning' and claims of the two prediction/planning paradigms being 'unified'.\n\nSection 2: The Related Works section is well-written, save for a couple issues. (1) In most places, the manuscript summarizes the related works and neglects to explain the differences between those works and the present manuscript, let alone explain why the differences are significant. For example, the manuscript states that \"LaneGCN (Liang et al., 2020) is agent-centric yet representations are in a global frame – ... the only other work to do so.\" The manuscript should explain, then, the notable differences that makes the present work uniquely more performant. (2) some concepts and properties are left undefined or unsupported. For example, the manuscript states that \"... models that reason in the agent-coordinate frame (Mercat et al., 2020; Zhao et al., 2020; Khandelwal et al., 2020) are intrinsically pose-invariant, but scale linearly with the number of agents, or quadratically with the number of pairwise interactions between agents.\" Through what mechanism does the present manuscript claim pose-invariance, and what scaling order does the approach in the present manuscript enjoy?\n\nSection 2: \"Representing multi-agent futures\": The manuscript states that \"A common way to represent agent futures is via a weighted set of trajectories per agent... We argue in this work that modeling joint futures in a multi-agent environment (Figure 1, right) is an important concept that has been minimally explored in prior work.\" One could argue that the implicit weighting for those weighted set of trajectories (for each agent) is a function of other agents’ historical trajectories and the scene context; and, in the case of flow-based approaches, the weighting is also conditioned on a prior density over diverse and admissible trajectories (see Park et al., 2020). Is the manuscript asserting that the implicit weighting, then, does not capture as effectively the same multi-agent/agent-scene interactions as that which is proposed? More discussion is needed to understand why.\n\nSection 3.2: The manuscript attempts to claim as its main novelty the use of masked self-attention for joint prediction in trajectory forecasting problems. If the manuscript wishes to do this, then this inductive bias should be compared with those of other model classes, such as normalizing flow- and CVAE-based approaches. This would provide the community with insights as to why we might choose one over the other; and this work could then claim as a contribution the investigation of these differences, just as [1] did in their discussion of flow (see Figure 9 for comparisons w.r.t RNN-, CVAE-, and GAIL-based configurations).\n\nSection 3.2: \"Cross-attention\": Not novel. The paper cannot both claim primary novelty from its attention mechanisms and simultaneously ignore similar attention mechanisms as components in other works, as applied to the same tasks. The manuscript should discuss why this \"cross-attention\" mechanism is better than the plethora of other agent-to-scene attention mechanisms, which have been popular in robot navigation, planning, and trajectory forecasting.\n\nSection 3.2: The manuscript says \"Finally, in order to capture both time and agent dependencies, the model simply alternates attention across agents and time in subsequent layers (Figure 2, right panel).\" Why interleave? Why not calculate both attention distributions — across both agent and time dimensions — serially?\n\nSection 3.4: The referenced 'Figure 7' appears to be missing.\n\nSection 4.4: The manuscript asserts that \"...the multi-task model matches the performance of our MP-only trained joint model on both joint (Table 3) and marginal metrics (see also Appendix, Table 10), indicating that the addition of tasks does not degrade standard motion prediction performance.\" This claim is not really apparent from the provided results: throughout the tables, the performance of the multi-task models are always subpar or inconclusive, especially since no standard error calculations are given to contextualize the numerical results.\n\nSections 4, B: Results of the various ablations are very sensitive to the model instance's training objective (marginal, joint, multi-task) and the trajectory lengths (t={3, 5, 8}). To me, this renders such claims as \"we [produce] consistent futures that account for interactions between agents\" (Abstract, Intro) somewhat inconclusive, still.\n\nSection 4: The manuscript states: \"Although no quantitative benchmarks are available in the community for quantifying GCP predictions, we take these results as positive indication that the model is responding appropriately and save further exploration of counterfactual analysis for future work.\" Consider evaluation in online urban-driving settings, like the CARLA benchmarks: Original, NoCrash, Anyweather, CARNOVEL [2], or CARLA Challenge. See also Liu et al., (2021a), which this manuscript even cites.\n\n----\n\n[1] Rhinehart, Nicholas, Kris M. Kitani, and Paul Vernaza. \"R2p2: A reparameterized pushforward policy for diverse, precise generative path forecasting.\" In Proceedings of the European Conference on Computer Vision (ECCV), pp. 772-788. 2018.\n\n[2] Filos, Angelos, Panagiotis Tigkas, Rowan McAllister, Nicholas Rhinehart, Sergey Levine, and Yarin Gal. \"Can autonomous vehicles identify, recover from, and adapt to distribution shifts?.\" In International Conference on Machine Learning, pp. 3145-3153. PMLR, 2020.",
            "summary_of_the_review": "I have some issues with the novelty of the work presented, the accuracy of the claims made, and the somewhat lacking comparison with the related work and key ablation experiments. See main review, above. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper proposes a new Transformer-based trajectory forecasting model that can predict multiple agents in a scene. It can be used for goal-directed trajectory forecasting as well. Experiments on Argoverse and Waymo with good results. Related work is sufficient. Technical novelty is low. Paper is clearly written.",
            "main_review": "**Strengths:**\n1. Paper is well written and clear.\n2. The problem statement is justified and relevant in autonomous driving.\n3. Results are good.\n4. I like the flexibility that the model offers in terms of use cases.\n\n**Weaknesses:**\n\nWhile the problem statement is important, the technical novelty and the analysis is lacking. The autonomous driving community has started to move beyond rudimentary metrics like ADE/FDE to include more analysis on “interesting behaviors”. For instance, see [0]. Waymo, in fact, even has included such labels in their Open Motion dataset for more challenging scenarios (See Section 3.1 in https://arxiv.org/pdf/2104.10133.pdf). \n\nFrom a research contribution perspective, it is not enough to simply rack up higher numbers on the leaderboard. There needs to be analysis that advances the field forward. The future of the field lies in challenging scenarios like intersections, unprotected left turns etc. The proposed work currently does not present any such analysis. Therefore, in its present form, the current work in my opinion is not of high technical quality and novelty enough to be published in ICLR.\n\n**What I would like to see in a revised version:**\n\nTo improve its novelty this paper needs to include a section in Section 4 on analysis of the proposed method on more challenging and interesting scenarios in the WOMD. Such a section should include:\n\n1. ADE/FDE results for the scenarios that WOMD labels as challenging or interesting.\n2. Explanations for where the model particularly is successful and also the cases where the model fails (if so).\n3. Furthermore, there is past research on this [1,2,3,4]. The authors should compare and contrast the technical details with these methods in this section.\n\n[0] Ivanovic, Boris, and Marco Pavone. \"Rethinking trajectory forecasting evaluation.\" arXiv preprint arXiv:2107.10297 (2021).\n\n[1]  Deo, Nachiket, and Mohan M. Trivedi. \"Trajectory forecasts in unknown environments conditioned on grid-based plans.\" arXiv preprint arXiv:2001.00735 (2020).\n\n[2] Bhattacharyya, Apratim, Mario Fritz, and Bernt Schiele. \"Long-term on-board prediction of people in traffic scenes under uncertainty.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.\n\n[3] Chandra, Rohan, et al. \"Traphic: Trajectory prediction in dense and heterogeneous traffic using weighted interactions.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n\n[4] Chandra, Rohan, et al. \"Forecasting trajectory and behavior of road-agents using spectral clustering in graph-lstms.\" IEEE Robotics and Automation Letters 5.3 (2020): 4882-4890.\n",
            "summary_of_the_review": "Without the required analysis as requested in the revised version, the present work lacks research rigor, technical novelty, and is simply an impressive engineering effort. If no revision is made, I would defer it to a workshop publication.\n\nIf authors provide **strong** analysis on challenging, rare, and interesting examples as provided in WOMD, I may recommend acceptance (pending additional review of the provided analysis).\n\n============= POST AUTHOR-DISCUSSION =============================\n\nThe authors have made good faith attempt in addressing my concern and engaging in discussion. \n\nWhile I wouldn't fight for it's acceptance, I have no problems if it is published in ICLR. I have updated my score accordingly. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a transformer-style architecture, Scene Transformer, for joint trajectory prediction of multiple agents (including the autonomous vehicle). The key representation of Scene Transformer is a 3D tensor [A, T, D], with the dimensions being agent, time step, and feature dimension, and we mask out the entries that to be predicted. The output is [F, A, T, 7], where F is the number of future predictions. The model outputs 7 values for each waypoint, x/y position and uncertainty in 3D space and heading. The model uses factorized self-attention applied on the A axis and T axis separately to transform the [A, T, D] representation tensor, and uses a cross attention to fuse in the static map features. The model can be trained to predict either marginal predictions or joint predictions depending on the loss function. Also, based on what entries in the input tensor are masked out, Scene Transformer can perform motion prediction, conditioned motion prediction, and goal-conditioned motion prediction all in the same model.\n\nThe Scene Transformer model was evaluated on Argoverse and Waymo Open Motion Dataset (WOMD), and its marginal prediction achieves the state-of-the-art performance on both datasets. The evaluation also shows that the model is able to perform joint prediction for the WOMD Interaction Prediction task and achieves better performance on the scene-level metrics compared to the baselines. The evaluation also shows that the Scene Transformer model is able to do conditional motion prediction and goal-conditioned motion prediction.",
            "main_review": "--- Strengths\n\n- This is a very thought-provoking paper with many interesting novel ideas. It uses a transformer architecture to translate the input [A, T, D] tensor into the prediction output [F, A, T, 7] tensor. With this design, it can perform motion prediction, conditioned motion prediction, and goal-conditioned motion prediction all in the same model. It also proposes a factorized self-attention approach to reduce the computational cost.\n\n- The result is quite impressive. It achieves state-of-the-art performance on both Argoverse and Waymo Open Motion Dataset (WOMD).\n\n\n--- Issues and suggestions\n\n- This paper proposes a method to model the joint distribution of the trajectories of all agents in the scene, and this is listed as one of its three contributions. However, I don't think this is a significant contribution of this paper because 1) the idea is fairly straightforward and 2) the performance is questionable. The difference between training a marginal model vs. a joint model is the loss function. The loss of a marginal model is sum_A(min_F(sum_T(error))), while the loss of a joint model is min_F(sum_A(sum_T(error))). This loss function design is actually fairly straightforward, and every model that predicts trajectories of all agents in the scene can do that. What makes joint trajectory prediction hard is not this loss function design but the challenge of scaling with the number of agents in the scene. A crowded scene can easily have up to 100 agents, and simply modeling the joint prediction this way won't work in practice because it requires F to be very large. I expected this paper to tackle this challenge, but I don't see it in the paper. The WOMD Interaction Prediction task only requires the model to predict the joint prediction of two agents, so this simple approach works there, but I just don't see how this approach can work in an actual autonomous driving software stack. Also, in Figure 4 in the appendix, the prediction error of the joint model looks terrible even with a few (e.g., four) agents.\n\n- The appendix mentions that the model was trained with some data augmentation. So it's not very clear to me how much of the performance improvement comes from the Scene Transformer design and how much of it comes from data augmentation. It will be useful to also show the performance numbers without data augmentation.\n\n- It would be helpful to show some inference latency numbers for people to understand whether the proposed model can be used in practice. Also, this paper mentions using the factorized self-attention to save computation, so it will be helpful to show some numbers on that as well.\n\n- A few statements in this paper are pretty confusing and hard to understand. I believe there is some room for writing improvements there.  I will give a few examples below.\n\n- I don't understand why \"two agents of the same type hidden at the same future location will have identical input representations\". Don't they already have different past positions unless they are on top of each other?\n\n- The paper argues that it uses a scene-centric representation while the prediction space is agent-centric, but I find a lot of statements around this to be quite confusing. For example, in Section 2, it says, \"Some models do a majority of modeling in a global, scene-level coordinate frame, such as work that employs a rasterized top-down image\". However, I believe most of the rasterization-based prediction methods are actually agent-centric. They center the raster around the agent-of-interest (e.g., in Cui et al., 2019). Actually, there are a lot more works than just LaneGCN that predict trajectories in agent-centric frame from scene-centric features, such as MultiXNet (Djuric el al. 2020) and SPAGNN (Casas el al. 2020). In Section 3.1, the sentence \"We use a scene-centric embedding where we use an agent of interest’s position as the origin, and encode all roadgraph and agents with respect to it.\" is quite confusing. People will wonder why it is not agent-centric when you use the agent of interest as the origin. I think what the authors are trying to say is that they use the ego vehicle as the origin in Waymo Open Motion Dataset (WOMD), so it's scene-centric. But I think for Argovese dataset, it is still agent-centric. On the WOMD dataset, where the ego vehicle is the origin, do you predict trajectory waypoints of an agent with respect to the ego vehicle or the agent? I think the trajectory waypoints should also be with respect to the ego vehicle if you want to model agent-agent interactions, but this seems to contradict the statement of \"agent-centric representations\". This part is very unclear in the paper, and please clarify this.\n\n- The paper says the 7 output values of each waypoint are x/y position and uncertainty in 3D space and heading. But if we want to model the output waypoints in 3D space, shouldn't the heading be 3D yaw/pitch/roll heading? The appendix says the losses and uncertainties are defined in lateral and longitudinal coordinates, and this will only make sense if it's a 2D space. This really makes me wonder whether the output space is 3D or 2D. Also, I don't think it's a good idea to represent the heading with just one value, because, for example, when the model predicts a 179 deg heading while the ground-truth heading is -179 deg, it will get a very high loss. I doubt how this can work.\n\n- In the appendix, the paper says, \"We append on a one-hot encoding to the final dimension where a 1 indicates which of the F futures is the ground truth trajectory resulting in a tensor of shape [F, A, T, D + F].\" This can only be done at training time, and I don't get how we can get the [F, A, T, D + F] tensor at inference time.\n",
            "summary_of_the_review": "Overall, I think this is a very thought-provoking paper with many interesting novel ideas and impressive results. The performance of the marginal prediction is a bit questionable, and there is also room for some writing improvement. I recommend this paper to be accepted, but I hope the authors can clarify my questions in the final version of the paper.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}