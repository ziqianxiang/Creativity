{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This work is on stochastic convex optimization (SCO) in shuffle differential privacy (DP) models. In SCO, a learner receives a convex loss function L: Theta x X -> Reals, where Theta is a d-dimensional vector of parameters and X is a set of data points. The objective is to use samples x1, x2, …, xn to find a parameter theta that minimizes the loss E_{x ~ D}[L(theta,x)], where the distribution D on X is unknown. The shuffle models considered are a ``sequential\" model where the analyzer operates in rounds (and where a new set of users participate in a local DP protocol in every round), and a new, stronger \"full\" model in which the analyzer can request a specific subset of users to participate in a round, which in particular allows users' data to be queried more than once. This work shows that in the full model, one can develop excess population loss bounds matching the known best-possible bounds in centralized DP; it is also shown that even the weaker sequential model offers improved excess population loss bounds over the best-possible bound of sqrt(d/n) in the local setting.\n\nThe reviewers appreciated the novelty and technical depth of this work (despite concerns about part of the work being taking “off the shelf” results)."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper studies stochastic convex optimization in the shuffle model of privacy. They claim a new non-interactive algorithm for privately computing \\ell_2 norm, which would be useful in the stochastic gradient descent algorithm. ",
            "main_review": "The main contribution of the paper is the non-interactive mechanism to compute \\ell_2 norm of a given vector. This in turn builds on the mechanism given by Balcer and Cheu for privately scalar sum. The algorithm for SGD is pretty straightforward and the analysis is also standard in the literature. In total, the \"proposed\" new contribution of the paper is the scalar sum protocol. \n\nThe scalar sum protocol is a generalization of Balcer and Cheu. The difference between the two protocols is that the randomizer of this protocol also uses how many random copies of both 0s and 1s should be sent. Each of these numbers is itself a random variable. The sampling probability for both Bernoulli and Binomial samples itself depends on the input! I found this rather surprising that they were able to prove privacy for such a protocol. However, I feel that the protocol itself reduces to the binomial mechanism proposed in Dwork et al. 2006 when we set $g \\approx \\sqrt{n}$. I would like to know what is the difference? In particular, when all $x$ are close to 0, then step 5 with high probability would not add anything to $\\bar x$ and all we are left with is the Binomial mechanism. In particular, step 5 is more of a randomized rounding and I can see as post-processing. I do not see why it helps in privacy, and if it does not, then the mechanism is just the Binomial mechanism of \"Our data, ourselves: Privacy via distributed noise generation.” If there is no difference then there is nothing new in this paper!\n\nApart from this, I have some serious questions about the applicability of this paper:\n1. The choice of $g$ defines how many bits everyone has to send. That means, that every user has to send $\\sqrt{n}$ bits, where $n$ are the participating parties. Now, in the setting where the shuffle model would be used in practice is where we try to train an ML model using private federated learning. There, in practice, we will never know in advance what is the value of $n$. How would the user know how many bits he has to send?\n2. Second, and this is also a glaring problem with Balcer and Cheu, is that the randomizer sends a certain number of copies of 1s and 0s. This number is a random variable that depends on the privacy noise. An architecture for shuffler would need to know what is the input size to design the permutation. Oblivious permutation itself takes $O(m \\log m)$ time, where $m$ is the input, but it crucially depends that we know the number $m$. If you want to implement a permutation where the size of the permutation matrix is a random variable, you would need to impose some more trust assumptions. This has been studied in the security and crypto community and easy deanonymization is possible. That is one reason why the IKOS 2006 assumed $m$ is known.  \n3. The authors give an algorithm and analyze it under various settings for SGD. However, they fail to compare it \"Practical and Private (Deep) Learning Without Sampling or Shuffling\" (ICML 21) That paper does a very good job of arguing why sampling and shuffling are problematic in large-scale deployment. However, more importantly, they give an algorithm that meets the bounds one get by shuffling or sampling (up to $\\log n$ factor; which I think can be improved using better data structure). Their privacy guarantee more crucially does not depend on convexity, a significant departure from previous work in this area starting with Song et al. What this paper throws under the rug is the fact that epsilon when you are training or using convex optimization would never be less than $1$. So, after getting the terms which is true for any epsilon, they always make the assumption that $\\epsilon$'s are small! In practice, using Honaker's improvement on binary tree mechanism, I would not be surprised that the ICML 21 paper would be better than the submission in all axis once the privacy budget is reasonable for where we use any private convex optimization. \n4. Finally, the proof of the composition theorem is essentially the proof of composition theorem from \"Boosting and DP\" paper. The current paper can appeal to Chernoff while the Boosting and DP paper required Azuma as they had to deal with a martingale (and their composition was more general). \n\nI have a few more small questions that I will leave to ask during the reviewer-author engagement. \n\n\nPost author's response phase: The authors have answered most of my questions in a timely manner. I really appreciate their response. It helped me better understand the paper. I would ideally like to give a paper an accept (a rating of 7), which I cannot find. So, I would request the AC to consider this remark over the score given in the Recommendation section.",
            "summary_of_the_review": "The paper studies stocastic convex optimization in shuffle model; however, to my understanding, most of the results are known or are folklore. Also, they fail to compare with the most relevant and recent already published work. \n\nI have studied the proof and they are correct (more so, because most of them follow the standard ideas or the results follow from previous works).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors deal with the stochastic convex optimization problem under the shuffle differential privacy constraint. They extend the existing non-interactive shuffle privacy model to the interactive ones, sequential and full interactive models. Under these interactive models, they propose the shuffle private SCO algorithms with the analyses of the excess error bounds. To construct their algorithms, they introduce a novel shuffle private estimation mechanism for the sum of the vectors. ",
            "main_review": "Strength:\n- The proposed interactive models are reasonable extensions of the non-interactive shuffle privacy model.\n- The paper reveals non-trivial bounds on the excess errors of the shuffle private stochastic convex optimizations.\n- The error bound in the convex and fully interactive case matches the known best error in the central model.\n\nWeakness:\n- The tightness of the bounds in the sequential model is unclear.\n\n\nOverall, I recommend acceptance. This paper is well-written and has significant advances in the field of shuffle differential privacy. \n\nThe sequential and fully interactive models in the shuffle privacy are natural and reasonable extensions from the non-interactive model as well as the interactive models in the local privacy. I guess these models are acceptable even in real-world situations (particularly the sequential interactive model).\n\nThe authors introduce a novel analysis for the scalar sum, revealing the instance-specific privacy guarantee. This technique enables us to obtain the lower dimensional dependency on the error of the vector sum protocol. \n\nThe excess error bounds on the shuffle private stochastic convex optimization seem to be significant contributions to the related fields. \n\nOne possible drawback is the unclarity in the tightness of the bounds. In all cases, the first terms in the error bounds match the lower bound on the non-private first-order stochastic convex optimization. The second terms in the strongly convex and smooth case in the sequential model and all cases in the full model match the known best result in the central model. It is likely to be tight in these cases. The other cases, however, are unclear. The discussions about the tightness of these bounds are helpful for the reader.",
            "summary_of_the_review": "Overall, I recommend acceptance. This paper is well-written and has significant advances in the field of shuffle differential privacy. One possible weakness is unclearly in the tightness of bounds in the sequential model.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This papers considers stochastic convex optimization (SCO) in the shuffle-DP model. In particular, the authors consider two models for shuffle-DP: A \"sequential\" model where the analyzer operates in rounds, and in each round a new set of users participate in a local-DP protocol, and a new \"full\" model in which the analyzer can request a specific subset of users to participate in each round, which allows users' data to be queried more than once. The authors show that in the full model, one can retrieve excess population loss bounds matching the best possible bounds in the central DP setting. Furthermore, they show even the sequential model offers improved excess population bounds over the best possible bound of sqrt(d/n) in the local setting. \n\nThe key technical ingredient is a shuffle-DP randomizer for estimating the sum of vectors, each stored by a user, when the vectors have bounded $\\ell_2$-sensitivity (which corresponds to a Lipschitz assumption on each loss function in SCO), in contrast with existing work which focused on $\\ell_1$-sensitivity. The authors build off a scalar sum estimator and then use a composition theorem to prove privacy of the vector sum estimator as composition of scalar sum estimators, and then bound the variance of this estimator, and then use it to compute batch gradients in existing optimization algorithms such as gradient descent, stochastic gradient descent, and the accelerated stochastic approximation algorithm. For some of these results, a variance bound on the batch gradient immediately gives an excess empirical loss bound. In some other settings there is no plug-and-play error bound, so instead they need appeal to arguments/reductions similar to those appearing before in the central DP SCO literature, but with some elements specialized to their setting.",
            "main_review": "The main strength of this paper is that, to the best of my knowledge, it is the first paper to show that there is a non-central DP setting (the full shuffle-DP setting described earlier) in which one can achieve the same excess population bounds as are possible in the central DP setting for SCO. The authors also show that in the weaker sequential model, one can still get improved excess population loss compared to the local setting. In summary, these results nicely and newly fill the gap between what is possible in the (non-shuffled) local and central settings for private SCO. I also think it is very nice that the same vector sum estimator is able to be slotted into a variety of different algorithms, and view this as a strength of the paper - it is possible that for other SCO algorithms which have been tried in the central DP literature that improve over SGD under various assumptions, one can slot in the vector sum estimator of this paper and get shuffle-DP error bounds that are not much worse \"for free\". If so I could see this paper having a sizeable impact on both the theoretical literature, and on how models are trained using DP in practice. As far as the writing itself, I felt the paper was nicely organized and easy to read. The authors build up the results nicely, progressing slowly from scalar sums, to vector sums, to algorithms using vector sums to arrive at their main results, and the analysis is intuitively presented. The authors also do a good job in the introduction with explaining the setting and comparing to past results to highlight the novelties of their paper in what is a quickly growing area.\n\nI don't feel the paper has any real major weaknesses, but for completeness sake I'll address some parts of the paper that may be viewed as weaknesses. For one, there is no experimental work in the paper to show how well the algorithms do in practice. However, in some sense experiments may not be necessary - the only real difference from DP-SGD from a utility perspective is the noise being added to the gradients, which is from a near-normal distribution, so if my understanding is correct it is likely the performance of the algorithms in this paper would compare to the performance of DP-SGD but with a different scale of noise depending on the dimension/number of samples. Another possible weakness is that once one has the vector sum estimator, which follows from a composition theorem constructed by the authors, many of the SCO results are just \"plug-and-play\" or variants of existing analyses, i.e. most of the technical novelty is in the vector sum estimator. However, I wouldn't mark down the paper for this aspect; I think the vector sum estimator is by itself a very nice contribution for the reasons mentioned before, and I think it is also a nice \"story\" that in the shuffle model, we can apply algorithms/analyses that are very similar to what is used in the central model, just with added variance due to the local randomizers.",
            "summary_of_the_review": "Overall I greatly enjoyed reading the paper and think the results have a lot of potential for impact, both theoretically and practically. In particular the vector sum estimator provided by the authors is a tool that I could easily see being used by other papers to establish results in the shuffle-DP setting, and even just focusing on the error bounds, the optimal excess loss in the full shuffle model is quite a nice result, and the results for the sequential shuffle model also nicely improve on the results for SCO in the standard local DP model. In addition, the paper is nicely written and easy-to-read, and in turn ready for presentation at a major conference. For these reasons I recommend accepting the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper provides shuffle DP algorithms and population loss upper bounds for stochastic convex optimization (SCO). They include both sequentially interactive and fully interactive algorithms. Their fully interactive upper bounds match the central DP lower bounds. They propose a private protocol for vector summation that serves as the privacy workhorse of their algorithms; they combine this protocol with variants of (accelerated) gradient descent and SGD to obtain their results. ",
            "main_review": "Strengths: \n\n-The privacy mechanism for vector summation is interesting. It differs from the standard use of additive noise (usually Gaussian or Laplace) in DP optimization. It is also somewhat novel, as most prior works were for vectors with bounded $L_1$ sensitivity instead of $L_2$ (or used privacy amplification, c.f. Girgis et al (2021)). \n\n-The problem is interesting, considering the practical relevance of shuffle DP (as an intermediate trust model between local and central DP) and the importance of SCO. In light of the work of Erlingsson et al. (2020) and Girgis et al. (2021) on shuffle DP ERM, SCO is a natural next step. \n\n-The bounds seem good, especially Theorem 4.9 since it shows optimality. \n\n-The paper is well-written and the results seem correct.   \n\nWeaknesses: \n-For me, the weakest link of the paper is Section 4.1 (sequentially interactive SCO). The results are suboptimal as they stand, so one wonders why they are useful. The authors do mention that in practice, sometimes only one query per user is possible, which provides some motivation for sequentially interactive algorithms. Can the authors provide references and practical examples to support this claim? I would also like to see other arguments motivating the importance of sequentially interactive protocols. In addition, the paper would be greatly strengthened by either improving the bounds in Section 4.1 (to match the existing central DP lower bounds) or adding nearly tight lower bounds for sequentially interactive algorithms to show a separation between sequential and full interactivity for this problem and establishing near optimality of their bounds. Joseph et al. (2019) seems like a relevant work for this. \n\n-Missed related work: 1. There is a very relevant contemporaneous work that should be cited/discussed in the final version of the paper by Lowy & Razaviyayn (2021)  https://arxiv.org/abs/2106.09779. They cover a more general problem of federated learning, but setting $n=1$ and $M=N$ in their Theorem 4.1 recovers your Theorem 4.9. They use different protocols and only have fully interactive algorithms. They also use acceleration and smoothing for some of their results. I don't hold this one against the authors since it is concurrent, but a discussion of this work should be added to the Related Work section of the final version of the paper. 2. Erlingsson et al. (2020) (\"ESA Revisited..\") should also be referenced with Girgis et al (2021) in the context of shuffle DP ERM. 3. Smith et al. (2017) (\"Is interaction necessary...\") uses acceleration (Theorem 20), as does Lowy & Razaviyayn (2021)--these should be discussed, and the sentence \"we are not aware of previous private SCO results relying on acceleration\" in Contribution 3 should be removed. \n\n-Intro: $O(\\sqrt{d}/\\epsilon \\sqrt{n})$ is optimal in the local model is true, but I think Duchi et al (2013) only proves it for sequentially interactive pure DP algorithms, right? However, Lowy & Razaviyayn (2021) show that the same optimal loss bound holds for approximate DP fully interactive algorithms. \n\n-Definition 2.7 seems unnecessarily abstract; would be good to explain intuitively \n\n-\"allow the analyzer to adaptively choose which subset of users to query..\" is not the main/important difference between full and sequential interactivity; sequential algorithms also choose which subset of users to query in each round (but not adaptively). I would either delete this part of the sentence or emphasize \"adaptively\"; the main distinction is in the second part of the sentence (repeated querying). \n\n-Lemma 3.1: y is never explicitly defined; you should define it and say it lives in $[0,1]^{g+b}$; \"$P_{1D}(S(y))$ is an unbiased estimate...\" is not technically correct (as it is a tuple)--I think you mean \"$A_{1D}(S(y))$ is an unbiased estimate...\"? \n\n-Algorithms 3 and 5: it looks like you are doing gradient ascent instead of descent\n\n-Section 4.1 initial paragraph: include $\\epsilon$ in these loss bounds\n\n-Restriction on epsilon should be included in statements of all theorems in Section 4. You require $\\epsilon \\leq 1$ for privacy of your vector summation protocol, right? Also, for advanced composition in Theorem 4.9, you need some restriction (even if very mild and possibly subsumed by the restriction needed for vector summation) to bound $e^{\\epsilon'} \\leq 2 \\epsilon'$. Also, I think you may need to shrink the inputs to your vector summation protocol by constant factor (something like $2\\sqrt{2}$) to get exactly $(\\epsilon, \\delta)$-DP in Theorem 4.9. \n\n-Clarify wording in \"combining it with acceleration to attain a better guarantee\": the guarantee is not better than that attained in Bassily et al. (2019). \n\n-\"optimization trajectory\": what does this mean? \n\n-Theorem 4.9: I think you are missing a $lambda$ in the denominator of the second term? (Or the units are wrong.); also, you should include runtime and/or communication complexity guarantees (and do the same for results in Section 4.1.)\n\n-Proof of Lemma 3.1. Clarify/highlight where/how shuffling is used to provide privacy (if at all). It wasn't clear to me. Would same privacy guarantee hold without shuffling? Also, explain why $Var(\\eta_1) \\leq 1/4.$ ",
            "summary_of_the_review": "The paper is interesting, well-written, and seems correct. It is a solid work, but would be greatly strengthened by providing *tight* bounds for sequentially interactive algorithms and/or strengthening the motivation for sequentially interactive algorithms. Additionally, there are a number of minor issues (described above) that should be addressed. I consider the paper marginally below acceptance threshold in its current form, but would be open to recommending acceptance upon satisfactory revision. \n\n__\n\nEdit: The authors have addressed my concerns and revised the manuscript. I recommend acceptance. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}