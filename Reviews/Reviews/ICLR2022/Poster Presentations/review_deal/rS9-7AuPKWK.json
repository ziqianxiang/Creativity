{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The main contribution is a way of analyzing the generalization error of neural nets by breaking it down into bias and variance components, and using separate principles to analyze each of the two components. The submission first proves rigorous generalization bounds for overparameterized linear regression (motivated in a general sense by the NTK); there are settings where this improves upon existing bounds. It extends the case to a matrix recovery model, showing that it's not limited to the linear regime. Finally, experimental results show that the risk decomposition holds empirically for neural nets.\n\nThe numerical scores would place this paper slightly below the cutoff. The reviewers feel that the paper is well written and have not identified anything that looks like a critical flaw. They have a variety of concerns, mostly centered around whether the results apply to practical situations. Specifically, they're worried about (1) the theory not applying directly to neural nets, (2) the high-noise setting being less relevant for modern deep learning, and (3) whether there's a realistic situation where it improves over past bounds. Regarding (1), the theory covers not only the linear regime, but also the nonlinear matrix recovery regime; combined with the empirical results, this seems pretty solid by the standards of a DL theory paper. Regarding (2), even though the most common benchmarks indeed have low label noise, the high-noise regime still seems worth understanding (after all, we'd like our nets to work in domains like medicine). I haven't dug deeply enough to properly evaluate (3), but the author response seems believable to me.\n\nOverall, the paper strikes me as creative and well-executed. Regardless of whether the theory is easily extendable to neural nets, this seems like an interesting paper that can be built on in future work. I recommend acceptance."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "In this paper, the authors propose to decompose the excess risk into the variance excess risk (VER) and bias excess risk (BER). Based on this decomposition, the authors derive the generalization bound for overparameterized linear regimes and matrix recovery regimes. ",
            "main_review": "I believe decomposing the excess risk into the variance excess risk and bias excess risk intuitively makes sense, which aligns well with the empirical observation that neural networks converge fast when fitting signal but converge relatively slowly when fitting noise. Especially, the authors first pointed out two flaws in stability-based bounds, i.e., \n\n- stability-based bound depends heavily on the gradient norm\n- stability-based bound usually does not work well under general non-convex regimes.\n\nThese two flaws make stability-based bound cannot handle well with neural networks, where the gradient norm at initialization is usually large, and the optimization path is highly-nonconvex. By decomposing the excess risk into BER and VER, the authors can hopefully get a better bound. For VER, they apply the stability-based bound on it, as the gradient norm of variance training is usually smaller than that of standard training at initialization and the optimization of VER is closer to convex. Whereas for BER, they adopt the uniform convergence to bound it. \nIn addition, the theorems cover both the linear regimes and the non-linear regimes as well as accompanied with some empirical verifications. Even though, I have the following concerns:\n\n- Both the linear regime and diagonal matrix recovery regime are too different from the neural network case, as the optimization of neural networks is highly non-convex. Although the NTK theory indicates that the neural network at the infinite-width limit is equivalent to kernel methods, it is still far away from explaining the generalization/optimization property of practical neural networks. Therefore, I believe the claims in the paper about neural networks are not well-supported. I would suggest the authors apply their framework to analyze, for example, two-layer relu networks.\n\n- It is unclear to me how does the new decomposition lead to improvements over the original stability bound quantitatively, or the improvement seems quite marginal?  For example, on page 6, you mentioned that \"the bound in Theorem 1 outperforms the stability-based bound when $\\|θ^\\star\\|^2$ is\nlarge compared to V (namely, large signal-to-noise ratio)\". However, there is also a $\\|θ^\\star\\|^2$ in Theorem 1, and both bounds are approximately $\\tilde{\\mathcal{O}}(1/\\sqrt{n})$.  I believe a more concrete comparison between your bound and the original stability bound is necessary (e.g., a bound depends on the signal-to-noise ratio?). Otherwise, I am not convinced that your decomposition will indeed improve the original bound.\n\n\n- The following paper is very relevant to your work, it would be great if you can discuss it in the related work.\n-- The Deep Bootstrap: Good Online Learners are Good Offline Generalizers, Preetum Nakkiran, Behnam Neyshabur, Hanie Sedghi International Conference on Learning Representations (ICLR), 2021.",
            "summary_of_the_review": "Overall, the idea in the paper is well-motivated. However, the results in the paper are mostly about overparameterized linear regression and matrix recovery, but the many of the claims in the paper are about understanding the generalization of neural networks. Besides, I am not convinced that the derived bounds in the paper really improve over the original bounds. Therefore, I am currently leaning towards a weak rejection. If the authors can address my concerns, I will consider increasing my rating. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This work proposes a new bound for the excess risk based on a decomposition into a bias and variance term. The authors use a stability-based analysis to bound the bias excess risk, and uniform convergence to bound the variance excess risk. They illustrate their framework in two contexts: overparametrised linear regression with SGD and low-rank diagonal matrix recovery with gradient flow. ",
            "main_review": "As a non-specialist in this topic, I found the paper hard to follow. While the idea of decomposing the excess risk and combining the best of stability and uniform techniques to produce a better bound is very interesting and clear, the writing is confusing. Moreover, the quantity of typos and confusing sentences (some of which I list below) don't help.\n\n**Questions**\n\n1. The authors should explicit better what is the setting considered in the non-linear regime. While in the linear regime it is very clear what is the model of data and the loss, there is a conceptual jump between Sec. 3 and Sec. 4 which makes it confusing to understand how general are the results in Sec 4. Does theorem 2 holds for any model and any data distribution as long as assumptions 1 and 2 are valid? If yes, could the authors provide an intuition of how much these assumptions are constraining?\n\n2. For the real data experiments, how is the noise component estimated?\n\n**Comments / Suggestions**\n\n- In the second paragraph in the introduction, both shortcomings of stability-based bounds refereed by the authors are due to non-convexity. The first is due to the norm of the gradient, but it is not clear what the second is due to. The authors should precise better to what aspect of non-convexity the second obstruction comes from.\n\n- On the related work, \"Bias-variance decomposition\": [1] proceeded [2] in the investigation of the bias-variance decomposition for the double descent in random features regression.\n\n- *Besides, recent works (e.g., Jacot et al. (2018)) show that neural networks converge to overparametrized linear models (with respect to the parameters) as the width goes to infinity under some regularity conditions*. The authors could be more precise on what they mean by *regularity* here. As it is, the sentence seems to suggest that almost all infinite-width network is lazy.\n\n- The notation of vectors should be consistent. As it is, vectors with latin letters are denoted with bold characters, while vectors with greek letters (such as the weights $\\theta$) are not bold. \n\n- The authors speak about neural networks in the abstract, and present two plots in Fig. 2 and Fig. 3 related to neural networks. However, these networks are never defined or refereed to in the main manuscript. The authors should either detail the setting they are plotting in the main, or leave these results to the appendix.\n\n**Minor typos**\n\n- Abstract: *As alternative approaches, techniques based on stability analyze the training dynamics and drive algorithm-dependent generalization bounds.*. This sentence is confusing.\n\n- Abstract: *[...] (a) stability-based bound*. \n\n- Introduction, first paragraph: *which takes (the) supremum*. \n\n- Introduction, second paragraph: *Stability-based bound(s)* or *(The) Stability-based bound*. Appears three times in this paragraph.\n\n- Introduction, footnote: *In this paper, we refer the signal to the clean data without the output noise, and the noise to the output noise.* This sentence is confusing. Maybe: \"we refer to the clean data without the output noise as the signal\" would be clearer. \n\n- Introduction, third paragraph: *component(s)*\n\n- Introduction, third paragraph: *on both synthetic and real-world dataset(s)* or *on both (a) synthetic dataset and (a) real-world dataset* (the first option is better).\n\n- Introduction, fourth paragraph: *via (a) bias-variance decomposition*.\n\n- Introduction, contributions: *into (a) variance and bias component*.\n\n- Introduction, contributions: *provides interesting insights into the generalization community.*. into -> for?\n\n- Introduction, related work: *Oymak et al. (2019) applied bias-variance decomposition on (the) Jacobian of neural networks to explain their different performances on clean and noisy data.*\n\n- Section 2, third paragraph: *Let $\\mathcal{A}_{t}$ denote the optimization algorithm which takes (the) dataset $\\mathcal{D}$ as (an) input and return(s) the trained parameter $\\hat{\\theta}^{\u0012t}$ at time $t$*\n\n- Section 2, fourth paragraph: *Although the minimizer (might not) be unique*\n\n- Section 2, fifth paragraph: spilt -> split\n\n- Section 3, page 5: *The notation $B$ in Theorem 1 denote(s)*\n\n- Section 4, page 6: *the only way to reach the* or *the only way of reaching the*\n\n- Section 4, page 6: *minimizer $\\theta^{\\star}$ of (the) excess risk*\n\n[1] Stéphane D'Ascoli, Maria Refinetti, Giulio Biroli, Florent Krzakala, Double Trouble in Double Descent: Bias and Variance(s) in the Lazy Regime, arXiv:2003.01054 [cs.LG]\n\n[2] Ben Adlam, Jeffrey Pennington, Understanding Double Descent Requires a Fine-Grained Bias-Variance Decomposition, arXiv:2011.03321 [stat.ML]\n",
            "summary_of_the_review": "The work has some interesting new ideas that, to the best of my knowledge, are original. However, the results are presented in a confusing manner, making it hard to understand the scope of applicability of these results to a non-expert. Therefore, I believe this work could benefit from a rewriting. \n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a new approach to characterize the excess risk by decomposing the risk into two parts, the risk of learning the exact response and the risk of fitting the noise signal. Under the linear regression setting, the learning dynamic can be decomposed exactly into the proposed two parts. Stability and uniform convergence arguments are applied to two parts respectively. Similar results are shown under the more general setting, though additional assumptions are made to guarantee a reasonable dynamic decomposition. ",
            "main_review": "This paper is written clearly and easy to follow. Under the linear regression setting, the decomposition makes a lot of sense because the dynamics can be split exactly into two parts. Compared with directly applying the stability arguments, the decomposition removes the reliance on the norm of the parameter $\\theta^*$.\n\nThe first concern is, how better is Theorem 1 compared to directly using uniform convergence to characterize the excess risk of linear regression, especially under the high signal-noise-ration scenario. It is argued that Theorem 1 is better than directly applying stability results under the high signal-noise-ration scenario, which makes sense. But I wonder if the proposed decomposition really improves the state-of-the-art risk bounds. Some added discussion may help.\n\nThe next concern is the applicability of this decomposition. For the decomposition to make sense in general regimes, some very strong assumptions are made. For example, Assumption 2 directly assumes the training dynamics can be decomposed into two parts, which I believe can hardly happen in most cases.\n\nI also have concerns with whether this decomposition is meaningful for modern deep learning tasks. In my opinion, this decomposition is meaningful typically under a setting where the 'bias training' is easy and the noise plays a nonnegligible role in the training dynamics. In modern deep learning tasks, usually, the 'bias training' task is the most complicated one, and to characterize this learning dynamic rather than the noise is of the most interest. Therefore, even if the decomposition is approximately correct for deep learning tasks, it could be such a case that how to characterize the 'bias training' dynamic is still unknown, while the 'variance training' dynamic is not important at all.\n\n",
            "summary_of_the_review": "The decomposition proposed in this paper makes sense in some specific settings like linear regression. However, it is very unclear for me to see how this decomposition can be extended to a more general regime and how it helps understand the learning dynamics of deep learning. There are also no new technical tools developed. Given that I believe the decomposition's applicability and significance are questionable, and the technical contribution seems incremental, I recommend a weak reject.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studies the generalization performance of learning algorithms. The basic idea is to decompose the training dynamics into noise and signal components, and then consider separately the behavior of models trained with noise and signals. The authors then proposed to use the stability approach to tackle the noise components, and the uniform convergence approach to tackle the signal part. The authors consider two specific algorithms: overparameterized linear regression and diagonal matrix recovery. Experimental results are also reported.",
            "main_review": "The idea of decomposing excess risk dynamics seems to be novel and interesting. However, there are some issues.\n\n- The advantage of the results is not quite clear. For example, the authors indicated that Thm 1 outperforms the existing stability analysis by replacing $B'$ with $B$. However, this improvement is minor as both two quantities are unknown to us and it is not clear which one would be significantly larger. While the authors mentioned that $B$ is independent of $\\|\\theta^* \\|$. This seems not important since the excess risk bound already involves $\\|\\theta^* \\|$.\n\n- The decomposition theorem requires Assumption 1 and Assumption 2, which may be restrictive. While the authors mentioned that they hold for some specific cases, in general cases these conditions are difficult to check in practice and may not hold.\n\n- Assumption 1 on the uniform bound is imposed for $\\theta$ and $P$. However, in the proof of Thm 2, the authors also useed the uniform bound assumption for $(\\theta^{(t)}_b,P_b)$ and $(\\theta^{(t)}_v,P_v)$. The authors should indicate these assumptions clearly in Assumption 1.\n\n- The stability approach has a drawback of not yielding good bounds for nonconvex problems, while the uniform convergence approach has a drawback of yielding dimension-dependent bounds. The authors proposed to use stability approach and uniform convergence approach to tackle the noise and signal separately. The theoretical results therefore may inherit the drawbacks of both stability and uniform convergence: not appealing for nonconvex problems and yielding dimension-dependent bounds.\n\n- The analysis seems not rigorous. In particular, the authors proved in page 19 that $\\ell(\\theta^{(t)},P_v^n)\\leq \\ell(\\theta^*,P_v^n)$. This is not quite intuitive since this result holds for all $t$. In particular, in the first few iterations the performance of gradient descent may not be good and it is unlikely that they have smaller training errors than $\\theta^*$. Furthermore, the notation $\\epsilon$ in page 19 is not clear. It should be a vector according to the norm there. This causes confusion since $\\epsilon$ is a real-valued random variable in Thm 1.\n\nTypos:\n- page 17: $E[\\epsilon x^\\top\\theta^{(t)}]$ should be $-2E[\\epsilon x^\\top\\theta^{(t)}]$\n- page 18: $x_i^\\top\\theta_v+\\theta_b$ should be $x_i^\\top(\\theta_v+\\theta_b)$\n- proof of Lemma 7: some $\\theta$ should be $\\hat{\\theta}$. $\\theta_0$ should be $\\theta^{(0)}$\n- page 23: $M_u^{1/s}/m_u$ should be $(M_u/m_u)^{\\frac{1}{s}}$. There is also a missing factor of $m_u^{1/s}$ ",
            "summary_of_the_review": "The idea seems to be novel. However, the advantage of the decomposing excess risk dynamics is not well justified. There are also some issues on the correctness of the deduction.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "There are no ethics concerns.",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}