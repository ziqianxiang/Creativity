{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper points out how set equivariant functions limit the types of functions that can be represented on multisets. They develop an new notion of multiset equivariance to address this limitation. The paper improves an existing multi-set equivariant Deep Set Prediction Network through implicit differentiation, which is an area of rising interest. The reviewers and I note that the paper is well written."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The authors examine the problem of building multiset-equivariant neural networks, and note that there exists multiset-equivariant functions which are not set-equivariant. Given this observation, using set-equivariant models for multiset prediction tasks may be limiting. The authors propose a strategy to construct multiset-equivariant functions (which are not set-equivariant) through the Deep set prediction network framework. The authors propose to improve upon that framework by making use of implicit differentiation to compute a backwards mode gradient without backpropagating through the optimization process which is memory- and compute- intensive. Some empirical results are provided for a simulated toy dataset, as well as a simulated object property prediction problem.\n",
            "main_review": "The authors consider an interesting problem in the construction of neural network models designed to be applied on set objects. The contribution of the authors is two-fold: 1) the authors formalize a discussion on multiset-equivariance and the limits of set-equivariance, and 2) the authors propose an improvement upon deep set prediction networks through the use of implicit gradients. In general, I found the treatment of (1) to be interesting, but somewhat inadequate as there appears to be remaining mathematical issues (see details below). Additionally, I was not convinced that multiset-equivariance is of practical importance in general problems of interest. On the other hand, I found the treatment of (2) to be a valuable contribution, with promising empirical results.\n\n**On the treatment of multiset-equivariance**\nI was confused by some claims on multiset-equivariant (but non-set-equivariant) functions made in the paper, as not all the constructions used in the paper appear well-defined. For example, the construction in Appendix A (Jacobian of sorting) appears particularly ill-defined, as the authors refer to “the permutation matrix”, which is not unique whenever there are equal elements. One possibility here would be to e.g. consider a stable sort, which breaks ties in the sequential order of the input, but this is a function on tuples and not sets, and I believe would be set-equivariant in any case.\n\nI was also uncertain about the treatment of element labels in the context of multiset-equivariant functions where equal elements may take different values. In particular, when we have labels attached to each input element, allowing non set-equivariant functions then would require a further permutation invariant matching step to reconcile labels of equal elements (as the outputs for equal elements are produced in arbitrary order). Given this, it would be great if the authors could address how this problem is tackled in their applications to counting equal elements in a multiset, and also provide a generic framework for tackling this important issue in using non set-equivariant functions.\n\n**On the empirical importance of multiset-equivariance**\nIt is not clear to me that typical set prediction problems are particularly constrained by the set-equivariance assumption used in the model. Indeed, as the authors note, slot attention (which is set-equivariant) performs better than DSPN on some of the tasks at hand. Perhaps a comparison of a set-equivariant and a strictly multiset-equivariant iDSPN architecture on a variety of tasks could help demonstrate the importance of being able to assign different values to identical inputs.\n\n**On the empirical results**\nI generally found the empirical results promising, although I believe it could be improved by including some of the following. 1) In table 2, a natural question would be if the apparent gap in required sample size could be mitigated or closed through data augmentation for non-equivariant models. 2) In table 3, it would be helpful to also include a like-for-like comparison of the iDSPN model with the same number of iterations as the DSPN model, to assess the potential degradation due to inaccurate gradient, and also compare the speed-up in a like-for-like scenario.\n",
            "summary_of_the_review": "The authors tackle an intriguing problem in modelling functions on multi-sets. The paper is overall promising, and I would be in favor of accepting if the authors could clarify some issues on the theory and add some more details in the empirical results.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper the discusses the conceptual improvements of exclusive multiset-equivariance over set-equivariance in the context of set prediction networks. Deep Set Prediction Networks (DSPN) are identified as the only used architectures for set prediction that satisfy exclusive multiset-equivariance with a specific choice of encoder that employs sorting. As an answer to DSPN not being the leading architecture in terms of performance on set prediction benchmarks, iDSPN is proposed as an improved version of DSPN, which still satisfies exclusive multiset-equivariance and builds on implicit differentiation to employ better optimizers and reduce memory usage and computation time. The experiments highlight the benefits of exclusive multiset-equivariance in toy tasks and demonstrate that iDSPN significantly outperforms the state-of-the-art on the CLEVR object property prediction benchmark.",
            "main_review": "# Strengths\n- The paper is well-written and understandable.\n- Implicit DSPN leads to very strong performance and is a good application of the recent progresses in deep learning with implicit differentiation.\n- The identification of the conceptual advantages of exclusive multiset-equivariance could serve as guidance towards which models future research will focus on. However, some issues have to be resolved, see weaknesses.\n\n# Weaknesses & Open Questions\n- Questions regarding importance of exclusive multiset-equivariance:\nIs exclusive multiset-equivariance really a deciding property in practice? The authors make the following two points: \n1) Set-equivariant networks cannot separate duplicate elements. This raises the question how often this happens in practice. The authors mention smoothing in graph problems (this is probably unlikely to produce exact duplicates), duplicates in the data (this is clearly the case in the toy experiment by design, but not obviously the case for the CLEVR benchmark), zeros from relu activations (to the best of my knowledge relu is not often used as the final nonlinearity) and duplicates from projections. It would be interesting to see how often duplicate elements actually show up, e.g. by reporting the percentage of instances for which this happens during the forward pass of a trained model on the CLEVR benchmark.\n2) ‘set-equivariance […] places a limitation on [the set prediction models] modeling capacity even if exact duplicates are never encountered’. I agree that very similar elements will be a problem for many set-equivariant networks that try to approximate functions such as push-apart, however, there are also set-equivariant networks for which this is not the case. An example would be to employ a sorting operation that instead of randomly breaking ties outputs the mean of the duplicate elements multiple times, which I believe makes the jacobian set-equivariant but is still able to separate arbitrarily similar (non-equal) elements. A version of DSPN/iDSPN with this modified sorting operation (possibly with noise added to inputs to break exact ties) would be an interesting comparison in the experiments as well, as it is the closest related architecture that breaks exclusive multiset-equivariance. If (even with added noise) this modified architecture fails to achieve similar performance this would really show the advantage of the exclusive multiset-equivariant architecture. \n\n- While producing impressive results, the technical contribution of iDSPN in itself is not very strong, as it is a straightforward application of implicit differentiation to DSPN. ",
            "summary_of_the_review": "The conceptual advantage of exclusive multiset-equivariance is interesting but lacks some additional comparisons in order to demonstrate that it is the deciding property in practice.\nImplicit DSPN works very well but on its own is just an application of existing methods to a new task, which is not necessarily bad but limits the technical novelty of this part of the contribution. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes the usage of multiset equivariance as a weaker constraint for deep sets. The authors then modify DSPN to be multiset equivariant and introduce the usage of Jacobian-free implicit differentiation to speed up computation. Finally, the authors compare on two test tasks and show general improvements.",
            "main_review": "## Strengths\n\n* The proposed methodology of using multiset equivariance makes sense and is a meaningful difference from standard set equivariance. This is a very good catch, as the difference is subtle but meaningful.\n* The empirical results are very strong. In particular, the results in the tables 2 and 3 show that the proposed model is able to actually learn (instead of being stuck at 0)\n* The contribution of using implicit differentiation for the DSPN is very useful for the field.\n\n## Weaknesses\n\n* The motivation for multiset equivariance is often confusing and/or very handwavy. Specifically, the push_apart function only serves to show what multiset equivariance is, but I'm not sure how this motivates any real world example. If possible, having a more real-world example would be much better. Similarly, the \"the problem with set-equivariance\" paragraph also suffers from a lack of specificity. A simple toy experiment here would be very helpful.\n\n## Nitpicks\n\n* The figures should be ordered correctly and stretch across too many pages. Currently, the text talks about, in order, the results in figure 1, table 2, and table 3. However, the actual figures appear in the order of table 2, figure 1, table 3. Furthermore, the figures do not necessarily all need to be at the top of a new page, especially as table 2 pushes too far away from its source text.\n* The paper should include a related work section discussing more implicit differentiation works. In addition to classical deep implicit layers works like [1, 2], I also recommend implicit layers work on other non-Euclidean domains beyond sets such as [3, 4].\n* The difference between the two \"Slot Attention\" rows in table 3 is not made clear.\n\n## References\n[1] https://arxiv.org/abs/1607.05447\n\n[2] https://arxiv.org/abs/1910.12430\n\n[3] https://arxiv.org/abs/2003.00335\n\n[4] https://arxiv.org/abs/2009.06211",
            "summary_of_the_review": "Overall, I found the paper to be a strong addition to the deep sets literature with many important contributions. However, I did have some overall complaints about the general structure given in the weaknesses and nitpicks sections above. As such, I am a bit reticent to accept. If these issues are resolved, I am more than happy to increase my rating.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper \"Multiset-equivariant set prediction with approximate implicit differentiation\" points out a difference between typically looked at set equivariance and multiset equivariance, the latter being able to produce different outputs for identical inputs. It is further shown that a method from the literature (DSPN) is multiset equivariant; to make this method perform better, this method is improved with an implicit differentiation approach. The superiority of the method is demonstrated on toy data, and also on CLEVR.",
            "main_review": "- The paper is very well written and easy to understand. It is also correct as far as I can tell (apart from a tiny thing I noticed below).\n- Technically, it builds on top of the nicely carved out, yet somewhat subtle difference of multiset-equivariance and set-equivariance. The proposed improvement of DSPN with implicit differentiation is somewhat incremental: it combines existing ideas from implicit differentiation with an existing method, i.e. DSPN.\n- The experimental section illustrates large improvements in sample efficiency (e.g. vs. BiLSTMs or Transformers) on designed toy data. Also on already used data (CLEVR as in Locatello et al), significant improvements are demonstrated. As this is the only more realistic dataset where improvements are shown, it would be great to extend the analysis to another dataset.\n\nMinor Issues.\n- in eqs 8,9,10 : \\nabla_Y L(Y*,...) is trivially zero; what is meant is likely either \\nabla_{Y*} or L(Y,...) ?\n- pg. 8 Results. \"Slot Attention\\dagger\" is not clear what is meant from the main text. Please refer to Table 3.",
            "summary_of_the_review": "The paper is well written, nicely connects a novel theoretical observation with a modeling improvement idea, which then culminates into a clear empirical improvement. More empirical investigations would be great, but I feel the paper is well rounded as is.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}