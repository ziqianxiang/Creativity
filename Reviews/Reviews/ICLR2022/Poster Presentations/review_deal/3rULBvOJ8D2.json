{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "After carefully reading all reviews and rebuttal, I actually think the paper provides sufficient new insight in understanding MAML that is worth being accepted. I want to thank the authors for actively engaging with the reviewers, and providing sufficient changes to the paper in order to clarify and improve its contributions. \n\nTheoretical results tend to be harder to judge, as they often need to happen under assumptions that make them tractable. Nevertheless they provide intuitions and understanding of the underlying principle that end up having an impact even in more realistic scenarios where these assumptions might not hold. I think this is such a scenario, and I think better understanding the relationship between ERM and approaches as meta-learning is important for the field moving forward."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper studies the MAML problem. In particular, authors consider mixed linear regression problem and provide two sets of results:\n- First, they characterize the optimal learning rate for test time, i.e., the stepsize that is used for updating the model at test time, when the number of tasks goes to infinity. More formally, they show that the optimal learning rate depends on the distribution of the feature vector. \n- Second, the authors characterize the gain obtained from MAML in comparison with ERM. The obtained bound matches with basic intuitions. For instance, it increases with the test time learning rate up to some $\\bar{\\alpha}$ and also decreases as the number of deputation steps increases. ",
            "main_review": "The paper provides new insights into the theory of MAML. I have two main concerns/questions, which are listed below:\n\n- First, the authors assume in equation (4) that the datasets used for updating the model and validating it are the same. This is an unusual assumption to me: if you know the true label to update the model, then validating the model on it might not make sense. I appreciate it if the authors explain how much the analysis depends on this assumption and whether it can be relaxed or not.\n\n- Theorem 2 on ERM vs. MAML seems very similar to what (Collins et al., 2020) studied in their paper. I appreciate it if the authors explain how their results differ from the results of that paper. \n\n",
            "summary_of_the_review": "Overall, I find the paper's attempt to shed light on the theory of MAML interesting. I have two main concerns on the test set/validation set separation and comparison with another result in the literature. I am open to raising my score based on the authors' responses.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper explores a question of how to theoretically derive a form of optimal MAML inner-learning rate and how to interpret its meaning. In order to do this, the authors assumes that the given problem is linear regression with some possibly nonlinear feature transformations. Then they derive the form of optimal MAML inner-learning rate (alpha). Further, they demonstrate that MAML with proper inner-learning rate stabilizes the meta-learning of the shared initialization, such that the shared initialization can generally minimize the distance from all the given task predictors, whereas the baseline ERM is sensitive to the density of the task distribution. The experimental results also demonstrate their derivation and intuition.",
            "main_review": "[Pros]\n\n1. This paper is well written with numerous theoretical findings supported by derivations in the appendix.\n\n2. Their method of how to properly set the inner-learning rate and their implication can benefit the meta-learning community.\n\n\n[Cons]\n\n1. As far as I understand, the derivation is based on the assumption that the adaptation only takes place at the last linear layer. This is clearly different from original MAML where adaptation takes place at all the layers. Also, as far as I understand, the analysis is only valid for regression problems, so I wonder how to make use of the findings to help classification problems.\n\n2. Similarly, the experimental results are done only under the synthetic environment, which limits the practical impact of this paper. Can you extend the experiment to more realistic scenario such as miniImageNet few-shot classification?\n\n3. In my opinion, the intuition behind their theoretical findings is a little bit straightforward, although understanding the phenomena is very important. For example, it is seems easy to imagine how nonzero inner-learning rate can help the shared initialization to stay robust against different task sampling. Of course it is always good to formalize such an intuition, but I just wonder how significant the importance is.\n\n[Simple questions (minor)]\n\n1. From reading the paper, I understood that how alpha=0 (ERM) can fail in Figure 1, but I do not understand why too large alpha fails as well, in terms of staying robust against the biased task sampling (the red circle). Can you provide an intuition in relation to the derivation?",
            "summary_of_the_review": "The submission formalizes the MAML inner-learning rate theoretically, and it can benefit meta-learning community to some extent. However, I'm not fully convinced if the finding is practically important, or something new (in terms of intuition) as well.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper put effort to understand the adaptation learning rate alpha. It gave a principled way to estimate the optimum alpha* minimizing MAML population risk. It showed the relation between alpha* and data distribution (variance of features). It also showed that alpha in MAML, compared to ERM, helped to minimize the total distance to all the tasks’ optima.\n\n",
            "main_review": "Strong points: \nThe paper is well structured, experiments make sense and well coordinated with the hypothesis \n\nFor the part that is hard to prove the hypothesis strictly in mathematic method, the paper put much effort to design meaningful experiments to illustrate and ‘prove’ those points \n\nThough coro1 is weak (since the reverse relation with variance of features rather than data points themselves is intractable), the authors tried to reveal it by several concrete examples (i.e. example1) and experiments. \n\nThe first result offered a method to get a better initialized value for alpha, which is valuable both in theoretical way and in practical use.\n\nWeak points \n\nSome of the results are not surprising and inspiring, lack of novelty.\n\nThe first result offered a method to get a better initialized value for alpha, which is valuable both in theoretical way and in practical use. But the latter two, i.e. the interpretation of alpha are not inspiring enough. Intuitively, alpha has relation with data(or say task) distribution. And the geometric interpretation is another way to formulate the goal of MAML. \n\n",
            "summary_of_the_review": "I don't think those results well pass the bar of ICLR conference. According to the above, I would suggest a weak reject (barely below the bar). PS: I am not sure if result one (find the better alpha) could be applied in practical tasks. My confidence is mostly on the theoretical part of the paper",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work analyzes the model-agnostic meta-learning (MAML) algorithm in the linear regression setting. It first derives an estimator for the optimal inner-loop learning rate for one inner-loop update. The authors analyze the statistical properties of the optimal inner-loop learning rate in order to try to obtain insights applicable to settings that go beyond restrictive assumptions in the theoretical analysis, finding an inverse relationship between the estimator and regressor variance. As a second contribution, the authors analyze the geometric properties of MAML and characterize the distance between adapted parameters and true task optima, giving an expression for the deviation of this distance in expectation between MAML and empirical risk minimization (ERM). The authors validate their optimal learning rate estimator with simulations across a variety of feature mappings, and also corroborate the estimator's inverse relationship with the regressor variance.",
            "main_review": "Strengths\n- The paper was largely well-written.\n- The theoretical results were validated by simulations (albeit toy), even when the assumptions were slightly violated.\n\nWeaknesses\n- Missing loosely related works in meta-learning as hierarchical Bayes [A] and Bayesian linear regression with learned priors [B].\n- The large gap between the setting studied in the paper and meta-learning in practice limits my confidence in how impactful this work will be. Even works that limit adaptation to be optimizing a linear model (e.g. Raghu et al. (2020)) atttribute the success of meta-learning to representation learning; this work does not consider representation learning.\n\nQuestions\n- Can we not think of MAML in this mixed linear regression setting as learning the mean of a Gaussian prior over $w$, and the choice of $\\alpha$ as implicitly specifying the variance of the prior?\n- Why is ERM a valid algorithm to consider for mixed linear regression? How can a single $w$ possibly fit multiple tasks, e.g. consider two tasks with the same $\\Phi(X)$ but different $a$? Why not consider task-specific ERM, in which a different $w$ is fit to each task?\n- Is there any way the estimator for $\\alpha^*$ can be leveraged in a typical meta-learning experiment? E.g. with ANIL, using online estimation of the representation statistics?\n- Given the emphasis in modern empirical deep learning on activation normalization, is the derived relationship between regressor variance and $\\alpha$ practically significant? \n\nReferences\n- [A] Grant et al., Recasting gradient-based meta-learning as hierarchical Bayes, 2018, https://arxiv.org/pdf/1801.08930.pdf.\n- [B] Harrison et al., Meta-Learning Priors for Efficient Online Bayesian Regression, 2018, https://arxiv.org/abs/1807.08912",
            "summary_of_the_review": "The theoretical contributions of this work are somewhat interesting but are also of dubious practical relevance.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper considers the popular MAML algorithm, and provide more theoretical understanding of (1) the optimal inner loop learning rate and (2) how the MAML initialization compares to that learned by empirical risk minimization. They consider the mixed linear regression setting when analyzing these questions.\n\nFirstly, to estimate the optimal inner loop learning rate (adaptation rate), the authors pose this as a problem of minimizing MAML's population risk, and develop an estimator for this optimal learning rate. \n\nThey then aim to understand how the initialization learned by MAML compares to that from empirical risk minimization (ERM), finding that on average that MAML's initialization is closer to the optimal per-task initializations than the one learned by ERM.\n\nThe two main theoretical results (optimal adaptation and comparing the meta-initialization of MAML to that of ERM) are validated in synthetic experiments with different data generating distributions.",
            "main_review": "## Strengths\n\nThe questions investigated by the paper are interesting and are well-positioned in relation to prior work. The contributions appear to develop on closely related studies such as Bernacchia et al, ICLR 2021. Supporting the theoretical results with empirical studies also provides some intuition and further insights.\n\n ## Weaknesses\n\nI am not familiar enough with the methods and related work to gauge the significance of the theoretical results. However, a couple points on clarity that came up when reading:\n\n- For clarity, the estimator of optimal LR in Eq 145 could be included in the main paper, since this is used in the experimental sections.\n- Fig 5 was a little hard to understand as a standalone -- could thetwo differences in loss/solution distance be defined in the caption or in the figure itself to help with this?\n",
            "summary_of_the_review": "Overall this work is well-motivated and appears to provide new insight about the inner loop adaptation of MAML and the significance of the meta-initialization learned by MAML, so I would consider recommending acceptance. However, as stated, I am not familiar with related theoretical works so have selected my confidence score in accordance with that. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
        }
    ]
}