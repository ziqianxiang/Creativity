{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper addresses a few very important points on sequential latent-variable models, and introduce a different view on meta-RL.  Even  though the methods that this paper poses are incremental, it is such a hot-debated topic that I would prefer to see this published now."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a method to learn a probabilistic recurrent state-space model for time-varying dynamics. The proposed method combines the Kalman filtering-based update rule with deep network-based encoder and decoder model. Effectively, the method can be used to replace RNN cells in a recurrent model, and is shown to outperform baseline models in modeling various robotic tasks.",
            "main_review": "The core idea leverages the model specification of a hidden-parameter-MDP (HiP-MDPs)  such that the hidden parameter encodes the time-varying aspect of the dynamics.  If I understand it right, the model considered overall consists of a latent variable (for e.g., motor friction, which is perhaps globally changing but locally fixed), a true underlying state (for e.g., exact location of the robot which changes locally as well), and an observation (for e.g., image of where the robot is).\n\n\n- Why are permutation invariant deep models used for encoding the history of past N steps? Why is it useful to discard the temporal information?\n\n- Section 3.2.2: It is mentioned that $z_{t-1},l, a$ are independent of each other as $z_t$ is unobserved. How are $z_{t-1}$ and $l$ independent. From Figure 2, does not $l$ directly influences $z_{t-1}$?\n\n- Section 3.2.2: what is the random variable being sampled from the third Gaussian distribution? Is it supposed to be $y$ instead of $v$?\n\n- Section 3.2.3: It might be better to provide some information in the main paper about how inverse on the term that depends on H is being done in a computationally efficient manner. \n\n\n- The key idea of the proposed work is to provide a wrapper around the Kalman filter. Exploiting the fact that the hidden-parameter is fixed throughout the task, the proposed method used deep nets to infer the hidden-parameter. This inferred hidden parameter is then used along with the standard state-space model, where the next state changes linearly in the past state, action, and the hidden parameter. \n\n- If I understand it right, in the proposed setup, deep nets were possible for inferring the hidden-parameter as the hidden parameters never change and thus do not need any posterior updates. Whereas, the state does evolve and thereby necessitating linear evolution structure. \n\n- Further, because the method builds around Kalman filtering, it is assumed that all the noises are isotropic Gaussian, such that covariances are zero and Kalman updates can be done easily. I am not sure why this assumption is reasonable in general.\n\n\n- As the paper title says \"changing dynamics scenario\", perhaps it is only reasonable to assume that the proposed method will handle that. While it is fine to assume that locally the hidden parameter is fixed (implying dynamics is fixed), ultimately it needs to be shown how at the global level the method can track the changing dynamics parameter as well. \n\n  - Currently, both in the model setup and the experiments, this setup is missing. The model assumes that the hidden parameter value is fixed throughout and does not consider at all _how the current hidden parameter influences the next value of the hidden parameter_. \n\n  - If I understand it right, even in the experiments constructed, each observation sequence is generated using a fixed value of the hidden parameter. Notice that this is not a fair comparison with the baseline methods. For example, even the basic GRU and LSTM models are more general as they can consider the latent variable to be a part of state-space that is evolving with time.\n\n- Further, the paper misses out on recent works by Xie et al. (2020) that build upon the work by Nagabandi et al. (2018a;b) and Finn et al. (2017). They look at a very similar HiP-MDP setup (and also goes beyond just modeling the time-varying dynamics and tries to do control). While they make the assumption of dynamics having a locally fixed hidden parameter like this work, they also consider how the hidden parameter is evolving more globally.\n\nDeep Reinforcement Learning amidst Lifelong Non-Stationarity.\nAnnie Xie, James Harrison, Chelsea Finn.\nInternational Conference on Machine Learning (ICML), 2021. \n\n- Under related works, it is mentioned that existing deep state-space models assume stationarity but their proposed method does not. I do not think this is true. If one considers the latent variable to be sampled from a starting distribution and held fixed throughout the episode (as what the proposed method has done both in experiments and the methodology), then it can be seen that everything is just stationary as well and warrants comparison with the existing deep state-space methods.\n\n-----\nMinor\n\n- The preliminary section builds up the notations as if arbitrary non-linear functions will be used later to model the dynamics, which is not completely true. \n\n- I think the paper can benefit a lot by clarifying the relations between $x$, $w$, $o$, and also between $\\eta$, $z$, $l$, \n\nTypos  Section 3.2.2: \n- Figure 1 => Figure 2?\n- Should $z_t^{-}$ depended on $z_{t-1}^-$ instead of $z_{t-1}$?\n- Is the matrix A time-varying or fixed? Notations are used inter-changeably.\n\n\n ",
            "summary_of_the_review": "Overall, the proposed method claims to be designed for environments that are dynamically changing over time, but actually assumes the latent variable to be fixed throughout the entire episode (not just locally for a small part of the episode). As such it contradicts the main claim.\n\nLet me know if my understanding of the work is not accurate and I will be happy to reconsider the score.",
            "correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper introduces a state-space model for non-stationary environments (where in this formulation the latent dynamics are changing while the observation model is fixed), which they call Hidden Parameter Recurrent State Space Models (HiP-RSSMs). In HiP-RSSMs, a context variable is inferred which is used to modify the latent dynamics to adapt towards the new setting. ",
            "main_review": "# Strengths \n\nI am a huge fan of this work as I think a lot of nifty tricks are used. Firstly, I thought the introduction and the motivation of this work is top-notch! Secondly, the form of the generative model is very elegant as it allows for a global dynamics model to be learned that can be shared across tasks/environments while the context variable allows for specialization within a task (and is also very easy to compute at test-time). \nThe use of \"linear\" (I will have comments on this later) dynamics allows for everything to computed in closed-form as well. To avoid issues with likelihoods that are parameterized by NNs, the authors also use a pseudo-like likelihood where a separate encoder is used to project the observations to some feature space that is used to inform the latent states and while retaining the closed-form updates of Kalman filtering.\n\n# Weaknesses\n\nI think there are very important details that are swept under the rug. \nFirstly, the authors use a locally-linear transition model\n$$ A_{t-1} = \\sum_{k=1}^K \\alpha(z_{t-1}) A^{k} $$\nwhere $\\alpha(\\cdot)$ is a softmax parameterized by a NN. \nNote that while Kalman filtering can handle time-varying linear dynamics, they have to be *indepedent* of $z_{t-1}$.\nThis parameterization *prevents* the use of Kalman filtering as now $z_t$ nonlinearly depends on $z_{t-1}$! This is a well-known problem that has been attempted to be addressed in the switching linear dynamical systems literature i.e.,  (https://proceedings.mlr.press/v54/linderman17a.html, https://arxiv.org/abs/1811.12386). \n\nSecondly, the marginalization of the context variable, $l$, is only available in closed form if the $z_t$ depends linearly on $l$. But in some of the experiments, the authors pass the context variable through a NN, preventing closed-form marginalization; they instead take an approximation, passing in the mean and variance of the through the NN instead (I'm somewhat confused by the passing the variance through the NN. By the principle of propagation of uncertainty, it should be something like the derivative squared times the variance, https://en.wikipedia.org/wiki/Propagation_of_uncertainty).\nWhile I'm somewhat fine with these two approximations as it allows for ease of computations, the authors should explicitly state this and avoid the use of \"exact inference\". Moreover, I would love to see some sort of empirical evidence that taking these approximations is okay i.e. comparing their KF to an extended KF.\n\nLastly, one other detail that is missing is the discussion of the context sets. The description is somewhat confusing. On page 3, the authors state \"We also make the additional assumption that the parameter vector $l$ is fixed for the duration of the task, and thus the latent task parameter has no dynamics\".\nBut on page 4, the parameterization and description of the context set makes it seem that one is inferring a sequence of $l$'s, \n\"for any time series $\\mathcal{T} = (o_t, a_t, o_{t+1}, ..., o_{t+N}, a_{t+N})$, the context set $C_l$ consists of tuples of\nthe current state/observation, current action and next state/observation for the previous N time steps, i.e. $C_l = (o^l_{t-n}, a_{t-n}^l, o_{t-n+1}^l)_{n=1}^N $\".\nWhat I am assuming is happening is that the data is split a priori into a context set and another set used for performing the Kalman filtering updates. \nI suggest using a separate subscript for the context sets.\nAlso, the constructions of the context sets don't seem to be discussed: what is $N$, how were the context sets collected, etc.\n\n# Comments/Questions\n1. On equation &, it should be $z_t^- = A_{t-1} z_{t-1} + Ba_t + C\\mu_l$\n2. Many models can perform decently well on 1-step ahead prediction (for instance, an LDS can perform well at one-step ahead prediction if the dynamics are slow, see Figures 2 and 3 in https://arxiv.org/abs/1811.12386). Have you investigated how your model fares on multi-step ahead prediction?\n\n\n------------------------\n# Update\nI think the authors have done a good job responding to my concerns and the concerns of the other reviewers. As such, I have raised my score to an 8.",
            "summary_of_the_review": "I think the idea presented in the paper is great and well-motivated. The approach is elegant and the empirical results are compelling. Most of my concerns are in--important--missing details and details that are swept in the appendix, which I think can be easily fixed with some rewriting. For this reason, I will give a marginal acceptance. I am more than happy to increase my score if the authors address my concerns. \nAlso, if I misunderstood/missed something please let me know!",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work proposes to extend latent state-space models (SSMs) with a latent variable that changes the dynamics. Update equations akin to Kalman filtering are provided, along with a training loss and method. Experiments on several robotics tasks appear to indicate that the method performs well relative to alternative methods that do not consider latent dynamics differences (up to the points below).",
            "main_review": "### Strengths\nExtending current state-space models to handle changing dynamics is important and the problem being addressed in this work is relevant to the community. The paper describes the approach reasonably well (up to the points below). A plus point is that the authors conducted experiments using real robots to demonstrate their approach can be applied to these settings.\n\n### Weaknesses\nAt present, technical novelty is unclear in that HiP-RSSM appears to be a variation of existing models. The primary equations are derived from the standard Kalman filter and there doesn't appear to be new insights or technical advances in the method's derivation. The experiments are not clearly described in the main text, which makes it difficult to validate the main claim that HiP-RSSM works better than existing approaches. Please see below for details. \n\n- The proposed model bears resemblance to the Kalman VAE (KVAE) [Fraccaro et al. 2017] which is not cited but highly related. The key difference is the introduction of the latent variable $l$. Initially, I expected that the transition matrices $A_t$ or control function to be dependent on $l$ but the variable enters only as an additive term in the updates. As an aside, I suggest that B.5 be brought forward into the main text since it is a core part of the method. \n- The proposed model is also rather confusing since the mean $\\mu_l$ is used in these updates rather than $r^l_n$? Can the authors better motivate the need to introduce the latent variable in this manner? How would it compare to a simple baseline that modifies the latent representation with an extra bias dimension and learns a time-varying transition matrix $A_t$? \n- The literature review also misses out on related work on switching dynamical systems, e.g., state-dependent or explicit duration models, which can capture the change in dynamics. This work appears to be a special case whereby the switching is not explicitly captured and technically contribution appears limited. \n- Is the training in the experiments done using RMSE or using eqn (9)? If I understand the paper, it seems like the method is training solely using RMSE which makes the proposed probabilistic setup appear unnecessary. \n- The prediction experiments results are for a one time-step prediction (only explained in the supplementary) and it's unclear how meaningful the results are. Typically, we are interested in predictions over long horizons, e.g., for MPC. This also motivates the need for capturing the change in dynamics (e.g., in the switching models) that is modelled by the HiP-RSSM.  \n\nReferences:\n\nFraccaro, Marco, et al. \"A disentangled recognition and nonlinear dynamics model for unsupervised learning.\" NeurIPS (2017).",
            "summary_of_the_review": "While I do believe that the paper has some merits, the technical contribution appears limited and I am unable to recommend an accept. It would be helpful if the authors clarify differences to existing models, especially KVAE and switching state-space models.",
            "correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors extend the recurrent Kalman networks with hidden parameters and context set features to model changing dynamics. The authors demonstrate the performance of the proposed method with a series of experiments on robot learning.",
            "main_review": "\n#### Pros\n- Moderate extension of existing recurrent state space models for changing dynamics for well-motivated problems.\n- Detailed experimental configurations are in the appendix.\n- Applications on different robot learning problems and settings are evaluated.\n\n#### Cons\n- For the experiments with partial observations and missing values, the authors may need to compare with some RNN baselines designed for handling partial observations/missing values.\n- The definition and scope of the context set $C_l$ and some related contents are quite ambiguous to the readers, which disrupts the understanding and evaluation of the proposed method. \n  - Based on the definition in Section 3.2.1, $C_l$s are different for different time step $t$; Meanwhile, $l$ is fixed for the duration of the task.\n  - In Section 3.2.1: $T$ has $N$ time steps. While in Section 3.3 $T$ is of length $M$. Please explain the differences between these variables.\n  - $t \\in T \\in R^{B \\times M \\times D}$. What is $t$?\n\n#### Details\n- In the second paragraph of the introduction, the authors motivate this work by listing both time-invariant (\"similar but not identical\") dynamics and time-variant dynamics (such as the friction changes and wear and tear). How are these two different types of dynamics captured in the proposed model, in the same way or with varying model formations? The experiments conducted in Section 5.1 are assumed to be for the time-variant dynamics, but more evidence about this assumption is needed.\n- However, the proposed model seems only to handle the former ones. Also, the experiments are not conducted with the time-changing dynamical systems.\n- It is unclear what the concept of latent task refers to (could the authors provide some examples?) and why multi-task models are suitable to compare as baselines.\n\n- Some definitions and concepts in Section 2.2 are not clear until the readers reach Section 3.2. Content rearrangements or clarifications are needed.\n- Similarly, it would be suggested to elaborate more model details about, e.g., locally linear transition.\n\n- Minur issues: \n  - Introduction: \"... like images was ...\" -> \"... like images and was ...\"\n  - Section 3.2: \"Each of these are three stages ...\" -> \"Each of these three stages ...\"\n  - Section 3.2.3: \"this a Gaussian conditioning layer\" -> \"this is a ...\"",
            "summary_of_the_review": "This paper provides plausible and moderate extensions to the existing model to solve problems in a new setting. However, some necessary clarifications and important baselines are missing. Therefore, I'd like to put it borderline and am willing to adjust my scores if more information from the rebuttal and discussion phases is provided.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}