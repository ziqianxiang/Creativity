{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper proposes a method for learning to optimize (L2O) by distilling a numerical L2O optimization rule into a simple mathematical rule, mathematical equation, using special-purpose student learning algorithm.  The motivation for using a symbolic distillation is to provide interpretability and scalability of the trained optimizers. \n\nPros\n - The paper addresses an important problem (better understanding learned optimizers).\n - The experiments give good evidence that learned black-box optimizers can be mapped to mathematical rules.\n\nCons\n - The symbolic regression student learning algorithm, and many details of the experimentation, remain hard to understand.\n\nOverall, after discussion, the paper was viewed as a solid contribution by the reviews, with some slight disagreement about whether the clarity was sufficient after revisions.  However, I believe that the main points of the paper and the general approach are quite clear, and that the details of the experiments and student learner are sufficiently well-explained for other researchers to build on, at least given the appendix and the supplementary material."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This is an ambitious paper that tackles an important problem: how to train general-purpose and data-driven optimization frameworks. The main idea of the paper is to explore symbolic learning to optimize (L2O) by distilling a numerical L2O optimization rule into a symbolic rule. The motivation for using a symbolic distillation is to provide interpretability and scalability of the trained optimizers. The contributions of the paper are as follows: introduction of the idea of symbolic distillation in the L2O literature; tools to interpret trained optimizers; results on larger-scale optimization tasks.",
            "main_review": "# Stengths\n\n* The paper tackles and important problem with a sound approach, which is presented well overall.\n* The paper improves tuned optimizers on  ResNet50 + CIFAR10 and MobileNetV2 + CIFAR100.\n* It is great to see that an optimizer on a toy task can transfer well to CIFAR10/100.\n\n# Weaknesses\n\n* What is the distilled symbolic rule (before tuning the constants) that you use in Section 4.3? Can you provide its explicit form (perhaps masking some constants would make sense for clarity purposes).\n* I'd expect more interpretability analysis about the symoblic rule used in Section 4.3.\n*  In my opinion, the paper needs experiments on other datasets to make a convincing case for scaling the method in the paper. One suggestion is to try to finetune a BERT-like architecture on GLUE, starting from the distilled symbolic rule used in Section 4.3.\n* What's the intuition behind TPF and MC? Do we want them to be large or small? From Table 3, it seems like you want them to be small for better transferability; that makes sense to me.\n* How important is the toy task to the results in section 4.3? Was it crucial that you used $\\mathcal{P}_{2,3}$ to select the best symbolic distillation? I'd expect some ablations here.\n\n## Minor.\n\n* page 3: You should use \\citet in \"(Chen et al., 2017) takes the optimizees'...\"\n* Figure 1: make the green arrows longer and reposition the \"Symbolic Regression\" and \"Meta Tuning\" texts, so that it's clear to what arrow the texts correspond ot.\n* Broken equation link in Table 2.\n* page 8: \"better performance better performance\" <- \"better performance\"\n* Table 3: can you report standard deviations as well?\n* No evidence in the main text that \"RP models generally have better performance\". Can you provide detailed results to convince the reader?\n* page 9: learn <- learning; distill <- distilling\n* It seems like the authors were not able to complete the appendix. Completing the appendix is an important task, because for this empirical paper hyperparameters and other details about the L2O methods, and ablation studies, would be very useful.",
            "summary_of_the_review": "My recommendation is 5: marginally below the acceptance threshold. I like the idea of the paper, and overall the execution looks promising. However, I think that some important details and experiments are needed before the paper is published. If the authors address most of my questions/ comments, and if no obvious red flags appear, I would be very happy to update my recommendation.\n\n--post rebuttal\n\nThank you for the clarifications and the new experiments. I will raise my score to 6. However, I recommend better tuning of AdamW for the GLUE experiments, because the baselines are rather weak, i.e. not all tasks match the results in Table 1 of the BERT paper (https://arxiv.org/pdf/1810.04805.pdf). I would also suggest that the authors add the new experiments in the appendix and fix the typos in the blue text, e.g. missing space before citation and missing closing parenthesis. Also, in the appendix when you discuss the interpretability of the equation from P_1, I think you mean \"asihn\" instead of \"sihn\".\n\nFinally, I would like to note that the paper seems acceptable only after extensive experimental details were made available in the Appendix and the blue text. It's unfortunate these details were missing originally, but I am glad they are available now :).",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposed symbolic learning to optimize (L2O), in which a neural optimizer will be trained and then distilled into a symbolic form via symbolic regression. This symbolic optimizer will then be applied to solve large problems, with some adaptation and fine-tuning.\n\nThis paper also proposed two metric called TPF and MC to understand the behavior of the optimizers.",
            "main_review": "The two main ideas in this paper are:\n(1) One can train the neural optimizer on small problems and distill it into symbolic form. Then apply it to large problems with adaptation. This can help the interpretability and scalability of the learned optimizer.\n(2) TPF and MC are proposed as two metrics to understand the optimizer.\n\nThe ideas and the overall framework are sound. However, the major issue of this paper is that the proposed method and the claims are not well-supported by the experiments.\n\nExperiments in Sec 4.1:\n- The sanity check is a good experimental setting to verify the correctness of symbolic regression. This set of experiments are meaningful but symbolic regression is not the main contribution of this paper. The main paper didn't even describe the concrete algorithm for symbolic regression. Apart from the distilled equations for known optimizers, we are more interested in seeing more examples of distill equations for the neural optimizers (such as the symbolic L2O in Section 4.3).\n\nExperiments in Sec 4.2:\n- The reported numbers seem to be insufficient to support the claims. The authors try to show that the metrics TPF and MC are linked to optimizers behavior such as the convergence and transferability. However, why are the metrics TPF and MC reported only without numbers measuring the model accuracy, convergence, generalization abilities are reported along with these metrics?\n- To support some claims such as 'larger TPF will help converge faster' and 'models with smaller TPF and larger MC will be more transferable', one needs to measure the convergence and transferability of different optimizers and see whether such a linkage is true.\n\nExperiments in Sec 4.3:\n- What is the symbolic form of the distilled optimizer? This very important result is missed.\n- Although the authors said RP_si model is the best performing one so they choose to distill this model. It will be also interesting to see what's the performance of distilling other neural optimizers and also the expressions of those symbolic optimizers. Otherwise, we only see one example.\n- Table 4 says 'ResNet152 on Cifar10'. Is this a typo? Should it be 'ResNet50 on Cifar10'?\n- Since the symbolic optimizer is meta-fine-tuned on ResNet-50 on Cifar10, it is better to compare what is the performance before and after the adaptation in order to get an idea of how much the adaptation is needed.\n- Furthermore, it is also good to know what is the performance of training the symbolic optimizer from scratch on ResNet-50 on Cifar10. This can verify the necessity of distilling the optimizer from a neural optimizer. Especially, when the neural optimizer is trained on a different smaller problem, it is difficult to see whether there will be a performance drop if one trains the symbolic optimizer directly on large target problems.\n- It seems the symbolic L2O does not perform the best on ResNet152 on Cifar100. Could the authors elaborate on this?\n- Finally, as mentioned that the LSTM based methods require more memory so a comparison is not shown. I think for research interest it is beneficial to make such a comparison on smaller problems to see how large the performance gap is.",
            "summary_of_the_review": "The overall framework and concept are sound. This will be a good paper if the experiments can support the arguments. However, the current experiments have left out too many details and results for validating the effectiveness of the proposed method.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a symbolic L2O framework that aims to improve the scalability and the interpretability over the numeral L2O methods. The proposed framework uses symbolic regression to turn a snapshot of the numerical method into a surrogate symbolic optimizer. The resulting optimizer can be further fine-tuned with less computational costs and has a certain degree of interpretability.\n",
            "main_review": "While I'm not very familiar with the L2O literature, I find the paper is difficult to read not due to my lack of domain knowledge but due to the writing and presentation. I suggest the authors re-organize the paper and address the following concerns:\n - Technical preliminaries should be put into section 3 as related work does not involve any formal definitions\n - Symbolic regression is the most critical component of the proposed method. I suggest the authors provide formal definitions of the algorithm and other details (figures, pseudo-code) to show how this algorithm fits into the framework. If it is borrowed from the previous work then this part should go to preliminaries.\n - Experimental results and technical details should be put into separate sections: they are tangled up in the current draft. For example:\n  - Section 3.3, \"We conduct a proof-of-concept experiment\"\n  - Section 3.4, \"Extensive results will be reported in Section 4, from which we conclude a few hypotheses, including\"\n\t\nTerms and notations are used without explanation/definitions:\n - What is a Finite Impulse Response filter?\n - What is R^2 score in Table 1?\n\t\nMixed-use of technical terms:\n - Meta-pre-train vs meta-fine-tune vs meta-tuned vs meta-training\n\nThe faithfulness of SR:\n - Since SR learns a surrogate optimizer from a fixed snapshot of a numerical optimizer, it is critical to show that SR with the proposed operators is sufficient and accurate to recover the original optimizer.\n - However, this is demonstrated only with simple known equations in Table 1, instead of real numerical L2O models\n\nI'm also concerned about the methodology:\n - While I agree with the motivation of improving the interpretability of the L2O model, the resulting symbolic equation is difficult to understand as well. For example, in Eq.2, why hyper-parameters are set to these values? What does T=20 mean vs. setting T to other values e.g. 30?\n - To learn the symbolic surrogate optimizer, one must first pre-train a numerical L2O model. If the pre-trained model is fully trained, doesn't the pre-training phase have the same computational cost as the traditional method?\n - If only consider the inference phase, the author claims the optimizer can be further meta-tuned for better performance. It is unclear how well does it compare with directly fine-tuning the pre-trained L2O model, as the latter is more flexible.\n\n\nExperiments:\n - What does the number mean in Table 4? How can this table show that the proposed method is more scalable than the numerical ones?\n - The author could provide the running time of the proposed method showing the computational cost of all its components: L2O pre-training, SR, meta-tuning, TPF and MC computing.",
            "summary_of_the_review": "In summary, this paper needs an overhaul of its writing and presentation. The proposed method is not well-justified and the important technical details are missing. The experiments are lacking and cannot support the claims made by the paper. That said, I recommend rejection.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes using symbolic regression for making simpler, more interpretable learned optimizers.\n\nThey do this by first training a neural-network parameterized learned optimizer, and then fitting a set of symbolic equations to capture its behavior using symbolic regression. The paper shows that the method recovers aspects of the ground truth rule when applied to baseline optimizers. Then, the paper applies their technique to learn symbolic optimizers for large scale neural network training problems.",
            "main_review": "## Section 2.2\n\nI think the paper should really discuss some of the other symbolic optimizer papers in this section. A number of these are listed in section 3.2, but should really be discussed here as prior work.\n\nAlso, this [paper](https://arxiv.org/abs/2011.02159) on interpreting learned optimizers seems worth discussing.\n\n## Section 3.1\n\n(Minor point) Section 3.1 states that an optimizer can be either represented through a “symbolic” rule or by “numeric” computation. Ultimately, isn’t every optimizer (whether parameterized by a neural network or not) symbolic on paper, but numeric when instantiated by a computer? For example, an LSTM optimizer, if I understand correctly, would be characterized as “numeric” by this paper. But the LSTM is made up of symbolic equations! Moreover, “symbolic” optimizers such as gradient descent or momentum are numerical methods when implemented using finite precision arithmetic in a computer.\n\nSection 3.1 also claims that “numerical predictors, especially RNN-based ones, limit L2O scalability through severe memory bottlenecks”. This paragraph confusingly discusses both memory limitations of meta-training an optimizer (the T copies of the model required for unrolled backprop), as well as the memory cost of running the optimizer itself (which depends on how the optimizer is parameterized, it is unclear to me whether this is a severe memory bottleneck). The difficulties of carrying out unrolled backprop over long sequences has been discussed in other papers (e.g., Metz et al 2019, [Understanding and correcting pathologies in the training of learned optimizers](http://proceedings.mlr.press/v97/metz19a.html); or Wu et al, [Understanding short-horizon bias in stochastic meta-optimization](https://arxiv.org/abs/1803.02021)), I think some discussion of this prior work is appropriate here.\n\nThis paper proposes scaling up learned optimizers by a multi-step process: training a neural-net-parameterized optimizer using unrolled backprop on small problems, simplifying that optimizer using symbolic regression, and then finally tuning the symbolic regression weights on larger scale problems. This implicitly assumes a hypothesis is true: that whatever algorithm a learned optimizer implements on small problems will be appropriate for large problems. I think this hypothesis should be clearly stated, and perhaps the authors could also comment on what _types_ of small optimization problems might be best for getting a good learned optimizer that yields symbolic regression rules that work well on larger scale problems.\n\n## Section 3.2\n\nSection 3.2 claims that symbolic optimizers are: (1) white-box functions that enable interpretability, and (2) are much lighter. I would push back against these claims, these points do not seem unique to symbolic optimizers, but rather, they seem unique to _simple_ optimizers. I can easily make up a complicated, heavy, uninterpretable symbolic optimizer.\n\n## Section 3.3\n\nWe need much more detail about the experiments performed in section 3.3. Details of the symbolic regression algorithm? How is a “complexity level” chosen? How does the performance of the symbolic regression optimizer compare against the original, for a range of different complexity values? How sensitive are these results to random seeds? These questions could be much more thoroughly answered in the paper.\n\n## Section 4.1\n\nIn section 4.1, how is the complexity level chosen to get these results? How much data do you need (how many optimization runs)? Can you provide more details about the optimization problem (ResNet on Cifar10, but what was the batch size / number of epochs)?\n\nTable 1 does provide some interesting results. For example, it looks like you often get spurious hyperbolic trig functions (tanh, asinh, etc.). Could you comment more on why you think those occur? If the symbolic regression is _not_ given hyperbolic trig functions as symbols, do the r^2 values improve?\n\nPerhaps the authors could also comment on the choice of forcing the symbolic regression to mimic the optimizer without access to _any_ state variables. This makes, for example, mimicking things like momentum much more difficult. With a state variable, momentum only needs access to the current gradient. But to approximate this, the symbolic version needs to approximate the exponential decay of coefficients for some number of gradient steps. Is it possible to give the symbolic regression access to some state variable, to make the resulting equations even more accurate and interpretable?\n\n## Section 4.2\n\nTable 2: How is the “temporal perception field” of Adam zero?\n\nIt would be nice to see a 2D scatter plot with mapping complexity on one axis (perhaps on a log scale), and the performance of the optimizer on the other (also perhaps on a log scale, depending on how you compute it).\n\n## Section 4.3\n\nMany more details are needed:\nWhy is pre-training done on P_1, as opposed to P_2 or P_3? If I understand correctly, P_2 and P_3 are more similar to the large scale problems (they also involve training neural networks).\nWhy is the performance of Adam at chance? Is there a bug, or is something badly tuned?\nAre you picking the best baseline over the grid of hyperparameters, or plotting just one example from that grid in Figure 2? The text is a little unclear\nResults would be more convincing with a more thorough baseline hyperparameter search.\nWhat is the stopping criterion for the different optimizers? Are they not all trained for a fixed number of epochs?\n\nWhat happens if you take one of these symbolic optimizers, and test them on a whole bunch of other different optimization problems? Do they generalize at all?\n\nFinally, what are the symbolic rules learned after meta-tuning on the large scale problems?!? Are they interpretable? Seems like a big opportunity is missed by not showing any of the learned symbolic rules after Table 1. If the rules are interpretable, can you explain why they have good performance?",
            "summary_of_the_review": "Overall, this paper addresses an important problem (better understanding what learned optimizers are doing) and does so by proposing  a new technique: using symbolic regression to fit interpretable equations to pre-trained learned optimizers.\n\nI think the paper could be greatly improved by:\n- Adding many more details about the experiments and methods. In particular, the \"complexity\" regularization of the symbolic rules seems like an important parameter. It's worth showing results as this parameter is swept across different values, as (presumably) there is a simplicity-vs-performance tradeoff that occurs.\n- Show us the learned symbolic equations for the optimizers in section 4.3! The whole point is to have interpretable equations that we can stare at. Showing that these have good performance is one thing, but it would be much more interesting to tie that performance to particular parts of the symbolic equations.\n\n[[ UPDATE AFTER REBUTTAL ]]\nAfter reviewing the author response and updated manuscript, I have chosen to increase my score.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposed to learn a symbolic interpretable L2O model from the common numerical L2O methods. The key idea is to select the proper function class for the symbolic updating function and apply the symbolic regression to distal a light, interpretable, symbolic L2O model. In their experimental results, they first demonstrate the capability of symbolic regression for some know functions and then \nthey show the good distilling performance of their proposed symbolic regression method on empirical evaluation, where the learned symbolic L2O method is better than existing baseline optimization methods.\n\n",
            "main_review": "strengths: \n1. Learning a symbolic L2O model from a numerical L2O model looks novel to me.\n2. The paper shows appealing results in the comparison of other rule-based optimizers. \n\nweakness:\n1. It seems like we need to manually define a \"suitable\" function class for the symbolic regression.\n2. I think the only reason people would first train a numerical L2O model and then distill it into a symbolic version is to apply this rule to other datasets. However, the paper lacks an experiment of the generalization of the learned symbolic L2O update rule. Moreover, I also expect a comparison (I don't see it anywhere) between the performance of numerical L2O and the distilled one. ",
            "summary_of_the_review": "I lean to accept this paper since it is nice and appealing to distill the complicated numerical L2O model into a symbolic optimizer.\nHowever, I think the paper would be improved dramatically by showing the generalization performance of the symbolic L2O model as well as the performance difference between the numerical L2O model and the distilled symbolic one.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}