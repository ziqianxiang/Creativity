{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The reviewers agree that the paper introduces an interesting approach for estimating Shaley values in real run-time. The effectiveness of the method is well demonstrated across different tasks/datasets."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper works on improving the runtime for estimating Shapley values. The work introduces FastSHAP that estimates Shapley values with a learned explainer model. The method is validated on tabular and image datasets (CIFAR10 and Imagenette).",
            "main_review": "Strengths\n- The paper proposes an effective method for estimating Shapley values that is much faster than existing works.\n- The method is validated on structure and image datasets.\n- The running time for different methods is well presented.\n\nWeaknesses\n- Besides the image classification tasks, could the proposed method work on other tasks, such as segmentation or NLP-related tasks?\n- Compared with the FastSHAP, other methods can achieve better Exclusion AUC and Inclusion AUC for both CIFAR10 and Imagenette in Table 1. Could the authors explain more on why other methods can obtain better results?",
            "summary_of_the_review": "Overall, the paper introduces an interesting approach for estimating Shaley values in real run-time. The effectiveness of the method is well demonstrated across different tasks/datasets.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduced FastSHAP, a new method for estimating Shapley values, reducing runtime significantly. ",
            "main_review": "This paper proposes a significant idea of reducing the runtime for estimating the Shapley value. I really love the extensive simulations that the authors conducted. \n\nHere are some comments: \n1. (\"... how to remove features\") on page 2. I don't think that the goal of the works of (Aas et al., 2019, Janzing et al., 2020, etc.) is to remove features. Instead, these papers aim to choose the set function such that the resultant Shapley values have causal interpretation when there is a feature dependence.\n\n2. In Eq. (4), Unif(y) seems undefined.\n\n3. I think the paper should explicitly compare the computational complexity of the existing approximation methods, including the permutation-based algorithm [Štrumbelj and Kononenko, 2014], kernel-SHAP [Lundberg and Lee, 2017], etc., to see how the orders-of-magnitude speedup was achieved. \n\n4. I am not sure what the authors want to tell from the simulation results in Figs. (2,3). I think the authors intend to tell that FastSHAP has higher performances compared to other works. However, I don't think this observation can be generalized because FastSHAP values are approximations of true Shapely Values onto the predefined function space. In other words, FastSHAP projects the solution of Eq. (3)  (i.e., the true Shapley) onto the predefined functional space. Then, we cannot make a general statement that FastSHAP achieves higher accuracy than other Shapley values because the functional space does not confine them. \n\n5. For the practical benefit, I recommend adding the guideline for choosing the functional class for \\phi_{fast}(x,y,\\theta). \n\n--- \n## Updated comments. \n\nThe authors addressed all the comments that I raised. \n\nI agree that this paper provides a substantial empirical benefit for the XAI literature. However, I raised some issues on the novelty because I expected a theoretical guarantee for the outstanding performance of FastSHAP. Nevertheless, I decided to appreciate the paper's importance because it is evident that the proposed method can significantly reduce computational complexity. \n\nI updated the scores toward acceptance because I believe the proposed approach will help the XAI community. Specifically, the scores are \n* Technical Novelty And Significance: 2 -> 3\n* Empirical Novelty And Significance: 2 -> 4\n* Recommendation: 5 -> 8 \n\n### Some minor note \n* Is \"Single forward pass\" broadly used words? I couldn't understand the contribution in the Introduction Section because \"Single forward pass\" looks exotic to me. I could grasp the contribution by seeing Eq. (4). It would be great if the contribution can be explained in simpler terms.\n\n ",
            "summary_of_the_review": "- Overall, I think there should be an explicit comparison of the computational complexities of FastSHAP and other algorithms. \n\n- Instead of comparing the performance, a more extensive comparison of the runtime is needed. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "For fast estimation of Shapley values, a new method is proposed, based on a single forward pass using a learned explainer model. On tabular and image datasets, accurate and fast estimation of feature attributions are demonstrated.",
            "main_review": "The FastSHAP method is elegant and provides an effective solution to the computational bottleneck of Shapley value estimation. However, there are concerns and questions below about the paper:\n\n- Why is the loss function in L2 form? Why don't you use other norm functions?\n\n- How can one pick the learning rate of the method? What type of validation reward would be used?\n\n- It is unclear how to optimally pick the loss coefficient for the efficiency gap objective. \n\n- What are the approximations that the optimal solution for Eq. (7) is given by Eq. (8)? It should be explained better. \n\n- In Fig. 4, the competitor models have very poor explanation quality, compared to the original papers that proposed them. How did you optimize their hyperparameters? Could there be unfairness in regenerating the results by those methods? Also, why doesn't it show results with the exact Shapley values?\n\n- The gap with KernelSHAP is still somehow noticeable in Fig. 5 that reduces the impact of the contribution. \n\n- Parallelization constitutes an important aspect of the runtime, but there is not much discussion on it. How can one parallelize different algorithmic operations, especially for the GPU implementation?\n\n- What is the impact of dataset size on the accuracy of explanations? Some discussions on it would be needed. ",
            "summary_of_the_review": "Overall, the paper makes an important contribution for post-hoc explanation of ML models, in computationally efficient ways. The paper is well written with strong results, but there is further room for improvement. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes FastSHAP to efficiently estimate the Shapley value in a single forward pass using a learned explainer model. Since there is no label to train the Shapley value estimator, stochastic gradient optimization using a weighted least squares-like objective function is applied to train FastSHAP. The experimental results and the deployment efficiency shows the superiority of the presented method.\n\n",
            "main_review": "Post-rebuttal:\nThe response partly addresses my concerns. However, I think the organization needs to be improved. The core contribution should be highlighted and the connection between sections should be strenthened.\n-------------------------------------------------\nPros:\n1. Efficiently estimating the Shapley value without groundtruth label is highly demanded, and the motivation is very clearly and in high significance.\n\n2. The experimental results including the exclusion and inclusion curve show the approximation accuracy of the proposed method. Meanwhile, the runtime is competitive with the SOTA method.\n\nCons:\n1. The main problem is the writing, and the organization of this paper should be improved. Since the presented method is based on the prior work KernelSHAP, the detailed information of KernelSHAP should be explained well. For example, what is $v_{x,y}(0)$ and $v_{x,y}(s)$? Meanwhile, the connection between Section 3.1 and 3.2 is not strong although the subtitle is connected.\n\n2. The novelty is also concerned. Eq. (6)-(8) all comes from prior works and the authors seem to combine the results without obvious modification. I think the contribution of extending other theoretical results to the efficient Shapley value estimation should be clarified clearly.\n\n3. The discussion for the experimental results are not sufficient. For example, FastSHAP outperforms all listed baselines in the exclusion curve but underforms KernelSHAP-S in the inclusion curve. What is the reason for the counter-intuitive phenomenon? Meanwhile, the bold results in Table 1 is confusing.",
            "summary_of_the_review": "Please see the Cons in the main review.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}