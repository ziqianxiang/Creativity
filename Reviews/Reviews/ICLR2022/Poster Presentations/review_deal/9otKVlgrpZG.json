{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "Three knowledgeable referees recommend Accept. Reviewer eyrZ's concerns have been addressed by the authors in the rebuttal, in my opinion.  Therefore I recommend Accept. I ask the authors to 1) rename the title of their paper and their model to the more specific name Multi-task Neural Processes (MTNP). I agree with both reviewers F6YH and ACBa that the name \"Multi-task Processes\" does not make justice to the many other models out there that also provide ways to model several stochastic processes simultaneously. Make sure you propagate the name of the new model through the paper. 2) include a discussion in the main paper about the variability of the new results provided in the rebuttal. Only mean NLL and MSE are provided which can be misleading without standard deviations and potential tests for statistical significance."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper presents a novel model for multi-task learning with missing data based on Neural Processes (NP). Inter-task correlations are modelled via a shared latent variable. The model has been tested on 1 synthetic and 2 real-world datasets and is experimentally shown to perform better against 4 baselines including 2 naive extensions of NP to the multi-task setting and 2 multi-output Gaussian process models (with spectral kernels).",
            "main_review": "The model is an extension of Neural Processes (NP) to the multi-task learning case. This work is valuable to the community, providing a new probabilistic multi-task learning model that is able to handle incomplete (missing) data. \nThe paper is generally well-written.\n\n**Meta-learning, multi-task, and GP baselines**\n\nThe work extends a meta-learning method (NP) to multi-task. This means that is it targeted at meta-learning and not applicable to the more classic multi-task setting (i.e. one set of test tasks). Hence, comparisons to GP baselines are not really fair (multi-task vs meta-learning). MTP uses much more data (training) while GP methods are given only a test set. \n\nHow do you train GP-based models? Is it only using test data? Why were those baseline chosen? \n\nTrain tasks could be used to pretrain kernel parameters in the models you chose. While in MOGPs where correlations are modelled via latent variables, for example [1], those variables could be pretrained and later used as a prior correlation on test tasks.\n\nGiven that you are using GP baselines there is some missed related work on meta-learning in GP:  [2], [3].\n\nAs it is done now, the GP baselines do not seem like a fair comparison.\n\nThe naive NP-based models are performing worse than MTP, but this is quite natural since they fundamentally lack the ability to model cross-correlation (in incomplete data).\n\n**Sloppy notation/language around VI, errors in the supplement**\n\nI found the notation and language about the Variational Inference part to be quite sloppy and confusing. \n\nIn 2.1 the conditional prior $p(z|C_t)$ is called both \"posterior\" and \"prior\". What do you mean by intractable prior? It makes sense that the posterior $p(z|C, D)$ is intractable and approximated with $q(z|D)$, but not so much for $p(z|C_t)$ (according to the graphical model).  Maybe just parameterize  $p(z|C_t)$ with the same NN model instead of using $q(z|C_t)$. It will not make a practical difference, but the explanation would be more clear.\n\nThe derivations in A.3 of the supplement are not accurate. While the end result is correct, the derivation is very misleading. Eq(31) is not = eq(32).  The denominator in (32) should be $q(z|D)$ and instead of $=$ it is $\\geq$. Same for eq(36) and eq(37). \n\n**Training on multiple sets of tasks**\n\nIf I understand correctly, the latent variable $z$ is shared within a set of tasks, but independent between sets of tasks. Is this correct? This is not clear from the text.\n\n**Minor comments**\n\nConsider renaming to Multi-task Neural Processes (MTNP), it would be much more clear.\n\nThe cubic complexity of GPs is correct in the naive case. However, given the wide use of much more data-efficient sparse GP methods, I think it is misleading to simply state \"cubic complexity\".\n\nSec.1 \"Then we define MTPs over the combined function space by extending the conditional Latent Variable Model (LVM) of NPs\". Rephrase this sentence to be more general. It is unclear what the \"conditional Latent Variable Model (LVM)\" is without checking Garnelo et al., 2018b.\n\nBetter is in eq(10) and (11) you write explicitly that it is q(z|C) and q(v_t|z, C_t).\n\nSec. 4 \"MTPs learn inter-task correlation from multiple context and target pairs through meta-training, which enables accurate inference with a few observations. In contrast, MOGPs learn the correlation only from the context data given at inference time, thus require a lot of observations to produce accurate predictions.\" This is misleading since you could use \"training tasks\" in MOGPs to either pretrain the kernel parameters or even include them as different tasks.\n\nSec. 5 no error bars in the tables, only means. Would be good if you can squeeze std in the tables. At least explicitly refer to the supplement for this information. \n\nFigures 3 and 4 are of low resolution, which is particularly problematic when it comes to reding the legend. \n\n[1] Dai, Zhenwen, Mauricio A. Álvarez, and Neil D. Lawrence. \"Efficient modeling of latent information in supervised learning using gaussian processes.\" *arXiv preprint arXiv:1705.09862*(2017).\n\n[2] Fortuin, Vincent, and Gunnar Rätsch. \"Deep mean functions for meta-learning in gaussian processes.\" *arXiv preprint arXiv:1901.08098* (2019).\n\n[3] Titsias, Michalis K., et al. \"Information Theoretic Meta Learning with Gaussian Processes.\" *arXiv preprint arXiv:2009.03228*(2020).\n",
            "summary_of_the_review": "Overall the method is novel and useful. However, the chosen baselines are quite weak. The explanation of the inference part needs correction and clarifications.\n\nUPDATE: I have increased my recommendation from 5 to 6, given the clarifications and extra experiments provided in the rebuttal. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work proposes a multi-task learning architecture for neural processes termed the Multi-task process (MTP). The MTP model conditions task-specific latent variables on a global latent variable that is responsible for information sharing between the tasks, and is able to handle both the isotopic and the heterotopic cases. The model was instantiated with an attentive neural process architecture and the generative model of the MTP was shown to correspond to a stochastic process by a Kolmogorov Extension Theorem argument.",
            "main_review": "**Strengths:** \nThe manuscript is well-written and easy to follow. The motivations for why such a model is needed are clearly laid out and the model is differentiated from the STP and JTP formulations. \n\nThe proposed formulation was supplemented with theoretical results to show that the MTP generative model corresponds to a stochastic process. I think that this is an important contribution; however, I did not verify the correctness of the proof.\n\nIt was also useful to include the details of the specific architecture that was used in the experiments.\n\nThe experiments were well-constructed and were able to showcase some of the properties of the MTP such as its sensitivity to task-relatedness (Figure 3b) and its ability to transfer information from other tasks (Figure 4). \n\n\n**Weaknesses:**\nOne of the important considerations for the success of this method is the selection of the context set. More specifically, in many multi-task datasets, it is very rare that two tasks have observed outputs for the same input location. How robust is this method to such a scenario? This point could be nicely added to the toy example as an ablation exercise. More generally, how sensitive is the performance of the MTP to the size and quality of the context set? Are there any methods or heuristics to choosing a good context set?\n\nThe paper had no discussion of the possibility of negative transfer with this model. Conditioning all task-specific latents on a global latent variable might cause such an issue if the tasks were not related. Can the authors comment on the MTP’s ability to deal with this issue? \n\nThe ELBO in equation (7) has nested expectations in it. I suspect that the Monte Carlo estimate of its gradient might have higher variance than that of STP and JTP due to this. Is this a problem in practice? How does the computational overhead of the MTP compare to the other two methods?\n\nMinor point: Although aesthetically pleasing, I found the different colours representing the different tasks in the figures confusing. I suggest either adding a legend or a comment to explain the difference in the colours.  \n\nReproducibility: Although the experimental details were given in the appendix, there was no indication that the source code is going to be released.\n",
            "summary_of_the_review": "In my opinion, this work is original and well-presented. The paper managed to discuss the proposed method in detail and the experimental evaluation was well-constructed. I think this is overall an impactful work and is significant to the probabilistic ML community.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduced multi-task processes (MTPs), a new variant of neural processes, which jointly infers multiple heterogeneous functions to given possibly incomplete data. The authors conducted thorough experiments on several tasks to demonstrate the effectiveness of the proposed MTPs.",
            "main_review": "Strengths:\n\n(1) In the theoretical aspect, it is interesting the hierarchical architecture to incorporate both task-specific and task-agnostic functional representations.\n\n(2) Experiments on the real-world tasks demonstrate the advantages of the proposed methods in a practical. \n\n(3) This paper is well written and easy to follow. \n\nWeaknesses:\n\n(1) In this paper, the motivation for introducing NPs to multi-task learning is not clear. Why it’s necessary to design the model based on NPs, especially ANPs? \n\n(2) The paper lacks important baselines. \n\n-The proposed method applies the ANPs as the backbone, which has the deterministic encoder and the latent encoder. \nMTP/STP/JTP has a totally different module for the deterministic encoder. To show the effectiveness of the designed hierarchical latent model in the latent encoder, it’s necessary to compare with a) MTP/STP/JTP without deterministic encoder and b) MTP without latent encoder.\n\n-For MTP, the hidden layers of the encoder and the decoder are shared by all tasks; For STP, the hidden layers of encoders and decoders are task-specific without any shared mechanism. To investigate the models’ ability of incorporating correlation across tasks, it would be convincing to have a comparison with such baselines: a) STP with the shared encoder and decoder for all tasks and b) MTP with the task-specific hidden layers/ deterministic encoder/decoder.\n\n(3) What is the motivation of introducing the learnable task-embedding \\exp^t? It seems to add task-level information for each sample. Could the authors visualize the difference between the learned task-embeddings of different tasks? Is it possible to utilize a fixed one-hot vector with the corresponding task label?\n\n(4) Why add a learnable task embedding \\exp^t for MTP but not for STP or JTP? It does not seem to be a fair comparison.\n\n(5) During training, the prior in the ELBO is approximated by the posterior conditioned on context samples. There are no theoretical guarantees on the bound defined by the approximation prior. This bound could not be tight enough to be practical in practice.\n\n(6) In the experiments, are results of all tasks obtained simultaneously? It would be better to add the average results to show the overall performance of multiple tasks.\n",
            "summary_of_the_review": "My main concerns are about the motivation of introducing NPs for multi-task learning, the lack of important baselines, and the tightness of the bound.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a hierarchical latent variable model based on deep neural processes to model multiple functions jointly from incomplete data.",
            "main_review": "Strengths:\n\n(1) The paper gives a novel perspective on improving neural processes for multi-task learning.\n\n(2) This paper has comprehensive evaluations about the effects of the number of the context data, the various missing rates, task correlation and so on.\n\nWeaknesses:\n\n(1) In the implementation of the latent encoder, what’s the role of self-attentions before the pool operations? \nBesides MSE, could the author provide some visualization results to demonstrate the difference between latent encoder with self-attention and without self-attention?\n\n(2) It’s unclear to me about the motivation of replacing the average pooling operation in the stochastic path with a Pooling by Multihead Attention (PMA) layer. Could the author provide more information about the seed vector in the PMA? Is it also task-specific? What’s the advantage of the parametric pooling over the non-parametric pooling?\n\n(3) In Figure3, why we cannot observe a similar conclusion as NPs/ ANPs/DSVNP, the lower variance around the context points?\n\n(4) What’s the functional correlation captured by a global variable z for multi-task learning? \n\n(5) To make the results convincing, more than two previous approaches should be compared in the experiments.\n",
            "summary_of_the_review": "The advantages of NPs for multi-task learning should be further interpreted.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}