{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper compared different architectures of deep neural nets for learning full 3D turbulence simulations.  On coarse grids, the proposed method predicts more accurately than the classical solvers, especially on preserving the high-frequency information.  The reviews think the paper is clearly written with strong experiments. Pls include the suggested references in the final version."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The authors evaluate some different architectures of neural nets for learning turbulence. They showcase the results for four different systems and in terms of several metrics. The main conclusion is that a learned simulator can indeed be good even for turbulence and possibly improved with additional mechanisms such as additional noise and constraints.",
            "main_review": "I would like to applaud the authors' effort to perform extensive experiments on different systems with different models. I think the experimental results well support a general claim that a learned simulator is indeed promising for some turbulence phenomena.\n\nThat being said, I feel that the main claim of the paper is somewhat vague. Is it on the goodness of the proposed architecture, called dilated ResNets? If it is, then I would like to know more about the difference from the baseline methods. Since such a comparison result is shown only in a small subsection, as the authors also acknowledged (\"... although most learned models were able to provide a good qualitative match ...\"), I could hardly understand the overly notable superiority of the dilated ResNets. Figures B.3 and B.4 also provide some comparison, but to me, they were not really clear, either. Maybe it would be helpful if the authors can add some more explanations about the quantitative and qualitative differences between the architectures if any. If the authors think that the inter-architecture difference is not necessarily significant, then the main claim of the paper should be emphasized in a different way.\n\nA small question on the training set. In the last two datasets, are the training sets generated with Athena++ 128 (and then downscaled)? If so, maybe it should be stated more clearly in the main text (sorry if there's already such a statement).\n\nIt would be kind if the semantics of \"predicted Energy Field and the Log Energy Spectrum\" are presented somewhere in the main text. I think many machine learners are not familiar with such notions.\n\nOn page 8, \"We found that training with prevents this in some cases: ...\" --> with what? Maybe a word is dropped.",
            "summary_of_the_review": "The work seems to be valuable in the sense that it conducts extensive experiments on simulator learning for turbulence. Meanwhile, the main claim of the paper is somewhat vague because the difference between the proposed architecture and the baseline architectures is not explained in full detail.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper aims to learn a simulator that predicts large-scale turbulent dynamics of a known system. As shown in the results, on coarse grids, the proposed method predicts more accurately than the classical solvers, especially on preserving the high-frequency information. ",
            "main_review": "This paper uses the existing modeling architecture on predicting turbulent flows. This paper shows several advantages of the proposed model: Compared with the classical solvers, using the same small resolution, the proposed model can produce more accurate results. It can also produce as accurate (or more accurate) results when using larger timesteps. The smaller grid, larger timestep, and the ability to utilize GPUs make this model more efficient than the classical solver. \nThis paper also compares different network architectures, which shows the best result is from using Dilated ResNet.\nThere are also certain discussions of the results, including the experiments of tuning training noise and temporal downsampling to solve the unstable issues, using different timesteps, evaluating longer rollouts, using different initial conditions, and using different box sizes.\n\nOther questions:  \nFor the CNN padding, can it deal with the scenarios of non-periodic and non-fixed boundary conditions?  \nWhen /Delta t changed, does the model need to be re-trained?  \nUsing classical solvers, as the resolution increases, the results would gradually converge to the ground-truth value. Does this property hold true for the proposed model?  \nIf we want to get more accurate results (for example, as accurate as using 256^3 Athena++, can the proposed model still out-performs the classical solver?  ",
            "summary_of_the_review": "Although using some existing learning models, there are certain contributions of this paper in applying the ml models on predicting the turbulent flows, which shows some advantages over the classical solvers.\n\n===============\nUpdates: I thank the authors for the response. The response addresses my concern about the contributions of the paper. I would agree that  the empirical work of this paper is impressive. I decide to change my score towards acceptance. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper present a  neural network-based model by training learned simulators at low spatial and temporal resolutions to capture turbulent dynamics generated at high resolution. It also shows that the proposed model can simulate turbulent dynamics more accurately than classical numerical solvers at the same low resolutions across various scientifically relevant metrics. Finally, a series of numerical examples including one-dimensional, two-dimensional, and three-dimensional nonlinear equations are used to demonstrate the feasibility of the algorithm. I reviewed this paper in NeurIPS 2021, which was titled “Learned Simulators for Astrophysical Turbulence”. The authors revised the paper based on previous reviews. Thanks for the efforts the authors have made.",
            "main_review": "The demonstration doesn’t clearly show the benefits of this method. What’s the difference between the three blue lines in figs 2b and 2d? Where is the red line that is supposed to denote the ground truth? Isn’t the error is larger in Dil-ResNet in fig 2b? What’s the point of t=1000 for a simulation that is already imprecise at t=1? Is it t=1 or t=1000 in figs 2f-2i? There are similar issues in other figs, like figs 4 and 5. It’s hard to show significant advantages with these low-accuracy simulations.  \n\nAs I said before, it would be more convincing if the authors can demonstrate some standard examples, such as Taylor Vortex, Karman Vortex, Frog-leaping, etc. For some turbulent flows that are chaotic themselves, the solutions at the resolution of 32 are meaningless, and the results are even worse than some large-eddy simulations. \n",
            "summary_of_the_review": "The authors do make efforts on this paper, however, only some statistical presentation of some low-precision turbulence simulation data is not convincing enough to make it attractive.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a method to predict turbulent dynamics of coarse simulations. To achieve this, a modified ResNet architecture is proposed, which the authors call Dilated ResNet (dResNet). This dResNet is combined with an encoder/decoder model inspired by graph networks. Unfortunately, the details of this architecture are not made very clear, but I hope this is something the authors can adress in future revisions of their work. Beyond the proposed architecture, the paper presents an interesting range of test cases from 1D KS to 3D compressible turbulence.\n",
            "main_review": "The authors compare a variety of models to the proposed dResNet, with a simpler Unet, the TF net, and a Fourier-Op network. It was, e.g., interesting to see that the latter does fairly badly in some of the tests. They also evaluate how introducing noise in the predictions helps to stabilize the rollouts. \n\nThe results contain a nice variety, and it is impressive to see predictions of full 3D turbulence simulations. The resolutions are not huge, with 32^3, but nonetheless contain complex dynamics.\n\nThe paper also contains an interesting evaluation of generalization for different initial conditions and simulation domain sizes. The longer rollouts are also an important point to study in this context. Here I found the presentation of the paper unclear: how many steps did the NN actually perform? The captions often give conflicting information: e.g., in Fig. 2, the time axis goes from 0 to 4, and the caption talks about t=992. It would be important to specify these durations more clearly, such that readers know how many steps the models predicted independently.\n\nMinor, but for divergence constraints I'd recommend to cite the Tompson et al. 2018 paper \"Accelerating eulerian fluid simulation with convolutional networks\". Also, the title of the website and on OpenReview differ. \"Efficient turbulence\" sounds very generic to me, being more specific in the title is a good idea.\n\nHere are a few additional points which I hope the authors can clarify in the rebuttal:\n\n- For the proposed dResNet architecture, what is the role of the encoder decoder? If it's just a single linear layer, why is it so important? Are there comparisons showing the usefulness of the encoding-decoding step?\n\n- The graphs in Fig. 3 (and others) are confusing - time is shown as 0 to 1, but the caption claims time steps of \\Delta t = 1, and on the right up to 128. What are the real sizes, and how many time steps were evaluated?\n\n- In Table A1, no model sizes are given. How many parameters did the different models have?\n",
            "summary_of_the_review": "In summary, the paper represents an interesting read, and contains a variety of very interesting results. There are a few open points, but, giving the authors the benefit of doubt, I hope that these can be cleared up during the rebuttal. Given my current understanding of the work I would argue for accepting the paper to ICLR.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}