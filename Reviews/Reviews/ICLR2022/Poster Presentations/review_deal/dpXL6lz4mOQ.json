{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper shows that (under some parameter range) graph convolutional networks learns communities in the stochastic block model. The result is clean, the proof techniques rely on partitioning neurons of three types and seems applicable to more general settings. The reviewers agree that the main theorems are interesting. There are some concerns among reviewers about the presentation of the paper, but many of them seem to be already addressed in the revised version, and I would recommend the authors to continue to improve the writing. There are also some concern about experiments, but the experiments are mostly used to validate the theorems, so clarifying how they are related would suffice. Overall the paper seems to have an interesting theoretical result on GCN."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper presents a theoretical analysis of two-layer graph convolutional networks (GCN). The main goal is to study the behaviors of GCNs when the inputs are random graphs generated by stochastic block models. The stochastic block models are constructed by three components: the number of vertices, intra-connection probability, and cross-connection probability. The paper assumes that intra-connection probability, and cross-connection probability should be functions of the number of vertices. The paper tries to establish the error bound w.r.t the number of vertices for the case that GCNs have the number of hidden features bounded by the number of vertices.",
            "main_review": "The paper presents an interesting technical approach studying the concentration or separation of GCN outputs by understanding the dynamics of three parameter settings (good, bad, harmless). However, currently, the paper faces two major issues:\n\nThe main result is not informative enough and may contain erroneous claims. The probability $1 - O(1/h)$ is implicit and does not depend on $\\epsilon$. It’s hardly (or impossible) to represent $h$ under both $n$ and $\\epsilon$. It is because $n \\geq A^2/\\epsilon^2$ and $h \\leq B n $ ($A, B are some constants$), we cannot say anything about the relation between $h$ and $\\epsilon$. For example, given that $n$ is very big, $1/\\epsilon^2$ is very small, we can pick $h$ any value that is either greater or smaller than $1/\\epsilon^2$ but still smaller than $n$. Therefore, without establishing the result in PAC manners, the claim can not be convincing.\n\nThe experiments cannot justify the theoretical results. Clearly, the assumption states that $a, b$ are constant, $p, q$ are the function of $n$. It is expected to fix $a, b$ and consider multiple settings of $n$.  However, the experiment setup varies both $a$ and $b$ and seems to keep $p, q$ similar between configurations.",
            "summary_of_the_review": "The main theorem seems interesting but can be problematic in the way it is interpreted. The experiments are designed in a way that does not support the theoretical claims. Since authors corrected the statement which fixes the condition of n and (especially) h, I raise the score to 5.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors provide guarantees (in term of the probability of correctly labelling any given vertex) regarding the learning of communities in the stochastic block model.  The proof technique relies on the analysis of three types of neurons : the so-called \"good\" neurons which contribute positively to the correct labelling, the so-called \"harmless\" neurons, whose effect on the classification can be neglected and the \"bad\" neurons which contribute negatively to the classification. The authors show that when initializing the paramters from a standard normal distribution, the number of neurons of the good type is sufficiently large to guarantee exact recovery of the missing label with high probabilty. ",
            "main_review": "\nThe contribution is interesting although some of the aspects of the paper could be improved (see my comments below). Not all the sections are clear (e.g. the need for coordinate descent could be better explained). All in all, I think it can get published after some minor revisions.  ",
            "summary_of_the_review": "===============================\nGeneral comment\n===============================\n\nThe transition between the general result of Theorem connecting the values of the neurons and the prediction accuracy on the one hand, and the result of Theorems 7.1 and 7.2 could be made more clear. It would be better to explain in plain english somewhere that you are interested in (1) deriving a bound on the prediction accuracy based on the value of the neurons and (2) show how that bound can be controled from the initialization. As an example, instead of section 4, which is useless and does not clearly introduce section 7, I would put a short paragraph, in the general introduction explaining the two aforementioned steps. In a few lines, I think that would clarify the whole paper. \n\n===============================\nDetailed comments \n===============================\n\nAbstract:\n- I would be careful (remove or expand) with the sentence “This state of affairs is in contrast with the steady progress on the theoretical underpinnings of traditional dense and convolutional neural networks ”. It is not clear to me that a lot of progress has been made on the understanding of traditional convolutional neural networks\n\nIntrodution:\n \n- Perhaps provide a word of explanation on the “Weisfeiler-Leman hierarchy” \n\nSection 2:\n\n- Your definition of the SBM is not very clear. I would say something like “In the setting of the SBM, the graph is built as follows. Two communities C_0 and C_1 are first created. , For any two vertices v_i and v_j, those vertices are then connected with probability q they belong to different communities and p if the belong to the same community”\n- When you introduce b_0 and b_1 you should introduce b as well. In particular, the notations of section 3 (or at least some of those notations such as b) should already appear in section 2 when you introduce the model of the GNN. \n- In section 2, page 3, when you discuss the balanced loss, the connection between the average of the derivative of the loss with respect to each of the b_0 and b_1 weights and the averages of Z over the vertices labeled as 0 and 1 is not clear.\n- In your definition of Z, g0 and g1 are not defined. Are g_0 and g_1 defined as in section 3? then those definitions should appear earlier\n- You initially mention parameters W^{(0)}, W^{(1)} and b as the trainable parameters but then only discuss coordinate descent for b0 and b1 which are not defined. This is not clear\n- In Theorem 2.2, when you describe the accuracy, as correctly predicting the label of a single sample, I would recall the definition of lambda. In fact, lambda should be defined in the statement of Theorem 2.2\n- The sentence “bigger λ generates bigger gap” is unclear. What do you mean? remove or expand\n- generally speaking, the definition of g_0 and g_1 is not very clear. I would start by saying that g_j is defined from f_j and b_j. Then you can say g_0(x) denote the logit so that g_0(x) = log(p_0) + c  and  g_1(x) = log(p_1) +c  where p_0 and p_1 denote the probabilities of the vertex being classified in either of the two classes C_0 or C_1\n- Don’t you make your life overly complicated by taking the softmax while you only have two communities ? Why not take the sigmoid with a single output p_0=p, assuming p_1 = 1-p ?\n\nSection 4 : \n\n- it does not really make sense to have a whole section to describe the paper structure. Put section 4 as the last paragraph of section 3, or add it as a subsection in 5\n\nSection 5\n\n- It would be good to have some additional intuition on conditions G_1 to H_2\n- What if p=q in Corollary 5.3. Is that the reason why you take a>b in assumption 2.1. You should state that clearly. Why is that a problem ?\n- The third remark is not very clear to me. I understand that we don’t want mu_0 and mu_1 to have the same sign as this would mean that the network is unable to discriminate between the classes but the output to the network is encoded in Delta not in mu so it is not clear to me that a small loss necessarily implies a small difference mu_0 - mu_1\n\nSection 7\n\n- In the statement of Theorem 7.1 I would explain the condition on mu_0 - mu_1 by adding a sentence of the form : “provided that the difference mu_0-mu_1 is large enough”, …\n- The distinction between Theorem 7.2 and Corollary 5.3 is not clear. In particular, I want to make sure I understand the following: What do Theorem 5.1 and Corollary 5.3 assume in terms of the training ? Do they assume a 0 loss. This should be stated somewhere. The ambiguity also comes from the fact that you say that Theorem 7.2 refines Corollary 5.3. in what sense is Theorem 7.2 a refinement of Corollary 5.3? From what I understand Theorem 7.2 is just the application of corollary 5.3 to the dynamics of the neurons. \n-  The sum in the second probability in the statement of lemma 7.3 is unclear. I guess you mean the sum over all neurons whose initialization satisfies G1 and G2 ?\n- Proof of Theorem 2.2. Why can you assume that P(\\ell(x) = 0) is 1/2 ? doesn’t that depend on the probabilities p and q ?\n\nSection 8\n- Figure 3 is not very intuitive. Why not add axes labels? Also why not indicate on the figure that n increases with the rows and h with the columns\n\nA couple of additional typos and comments \n\n- page 3, right above Theorem 2.2: “It is easy to see that Z > 1 if prediction is wrong “ —> “if the prediction is wrong”\n- page 3, right above Theorem 2.2: “Then we update other parameters” —> “Then we update the other parameters”\n- In the statement of corollary 5.3, you should replace the “i-the” neuron in each line with ”ith neuron”\n- section 7: “In this section, we prove our main result that with high probability ” should be replaced with something like “In this section, we prove our main result which states that …” or “according to which ..”\n- Section 8, first paragraph: “is able to recovery” —> “to recover”\n\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "In this paper, the authors present the first provable guarantees for Graph Convolutional Networks (GCNs) for semi-supervised\ncommunity detection tasks. The authors demonstrate that with high probability over the initialization and training data used, a GCN will efficiently learn to detect communities on graphs drawn from a stochastic block model (SBM). Empirical results demonstrate the efficacy of their results.",
            "main_review": "Strengths :-\n1) The problem the authors address in this work is highly significant. They provide the first provable guarantees for GCNs for semi-supervised community detection tasks. This paper can accelerate much needed theoretical work in the graph neural networks.\n\nWeaknesses :-\n1) The presentation of the paper is bad and really hard to follow. \ni) The same variable name is used in multiple avenues to mean different meanings which makes it hard to ascertain what it means when used i.e. b. \nii) The notation about stochastic block models (SBMs) is unclear. SBMs are specified via providing the partition of nodes which I could not find in the description. \niii) Some of the references were confusing. \nThe authors should have added a table for their notations which would have it much easier to follow. In case they were short on space. they could have added it in the appendix/supplementary materials. The current version of the draft needs some work to make it more digestible and easier to follow. \n\n2) The experiments were unclear to me i.e. why did the authors choose the values of a and b and where did they get these values from. Will any values of a and b work as long as a > b i.e. Assumption 2.1 or are there only specific values we can use. \n3) The experiments lack any discussion or analysis with regards to the results and how they are tied to the theory introduced in the paper.\n",
            "summary_of_the_review": "In this work, the authors provide the first provable guarantees for the performance of GCNs for semi-supervised community detection tasks, which is highly significant. The presentation and notations used in the paper requires quite a bit of work to make them easier to follow for readers. The experiments were unclear to me as well as lack discussion or analysis. My recommendation was split between 5: marginally below the acceptance threshold and 6: marginally above the acceptance threshold and ultimately I decided to go with the former.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper presents a theoretical result on performing label propagation in a stochastic block model (SBM) using a trained graph convolutional neural network (GCN). The idea is that by training a GCN to learn the community labels on several graphs drawn from an SBM, one can then claim some theoretical guarantees on the semi-supervised problem of determining the community labels of the nodes on a new graph (drawn from the same model) where only a subset of the nodes is labeled.\n",
            "main_review": "The result is quite interesting and leveraging well-established graph models to provide guarantees for graph neural networks is certainly a promising direction.\n\nI have the following comments for the authors:\n1) The notation and presentation can be improved. For example:\n- in page 3, the term $b$ is used first to determine the probabilities of the SBM and then to denote the bias.\n- b_0 and b_1 are not introduced in page 3.\n- The function $g$ is used in page 3 but introduced in page 4.\n- A “bad type” neuron is mentioned in page 5 as satisfying B1 or B2 … what is B3 then?\n\n2) Relation with classical detectability limits in SBMs.\nThe authors mention a few times that the problem of recovering the communities in an SBM has been well studied, but there are not direct connections between the regime of $p$ and $q$ studied here and what are the classical results for that case. Moreover, here the setting is different since in the classical setting one is given only a single SBM realization and here we are training with many realizations and then solving a semi-supervised problem. In principle, this means that a GCN could go beyond the classical detectability limits because the problem being solved is actually different. This is similar to the discussion in Section VII-C of “Exact Blind Community Detection from Signals on Multiple Graph” by Roddenberry et al. (although there are no GCNs involved there and indirect measurements of the topology are observed).\n\n3) The main body of the paper is not self-contained.\nTo follow the logical flow of the paper one has to flip multiple times between appendix and the main text. The main text has corollaries of results in the appendix, there are several references to equations in the appendix, in page 6 there is even a reference to the fact that some of the results are stated in the \"full version of the paper\", and is unclear to me what the authors are referring to here.\n\n4) In the experiments, the choices for $a$ and $b$ seem to be quite specific, is there any reason for these?\nAlso, in figure 3, from the description it looks like these histograms should sum up to 40, but they don't, what is going on here? E.g., for the center column, if we sum the are under the curve in the the top and middle plots these are very different, what is exactly being plot here then?",
            "summary_of_the_review": "The main result of the paper is interesting, novel, and can motivate follow-up work. The presentation, on the other hand, should be improved.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}