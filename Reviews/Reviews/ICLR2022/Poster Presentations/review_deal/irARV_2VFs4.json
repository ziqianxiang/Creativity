{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The manuscript proposes a method for addressing spurious correlations and sub-population (group) shift problem by modelling intergroup interactions. Past work (GroupDRO) focuses on the worst group which is subject to failure when groups have heterogeneous levels of noise and transfer. This work focuses on the group whose gradient leads to largest decrease in average training loss over all groups. The manuscript presents insights on why the proposed method called CGD may perform better than GroupDRO by studying simple synthetic settings. The manuscript also provides empirical evaluation on seven real-world datasetsâ€“which include two text and five image tasks with a mix of sub-population and domain shifts.\n\nThere are several positive aspects of the manuscript, including:\n1. The idea of training on the group which leads to largest overall decrease in loss is natural and interesting;\n2. The synthetic examples presented in the manuscript clearly bring out the use cases of the method proposed and comparison with GroupDRO;\n3. The empirical results presented lead to improved results on a variety of benchmark tasks.\n\nThere are also several major concerns, including:\n1. More discussion on why the proposed method works for the chosen real world datasets by connecting them to the synthetic setups presented in the manuscript;\n2. The proposed algorithm does not minimize a specific loss function;\n3. The standard benchmarks are altered. For example, the CivilComments dataset is shown as a 2 group when it is originally a 8-group task (the groups being the demographics of the users) as shown in the WILDS dataset paper.\n\nAuthors clarified, among others, that the proposed approach optimizes the macro-average loss function, and the standard benchmarks are not modified and the experiment setup is exactly like GroupDRO evaluation on the CivilComments-WILDS dataset. Reviewers noted that the generative model has not added anything new since it is essentially the synthetic example and it just shows what every robust machine learning method is supposed to do, i.e., don't rely on e_s (group-specific components) but on e_c (common components) while making predictions. It doesn't justify the procedure of choosing to focus on the group that minimizes the error for the group that decreases all other groups' errors. \n\nThe revised manuscript includes a clearer motivation, and more discussion on how the synthetic examples connect to the real world datasets. Based on that, I put an accept recommendation."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper gives a new algorithm for the setup where the test distribution is different from the train distribution. The setup includes multiple groups whose information is present during the training time but not during test time and the relative proportion of these groups change during test. The most commonly used method group-DRO does distributionally robust optimization or finds a classifier which performs well on the group with worst loss. This paper proposes to focus instead on the group which leads to maximum decrease in the loss while training instead of the group which has the maximum loss. The paper present several synthetic toy cases where their approach could be useful and concludes with experiments on a variety of benchmarks for this setup and shows improved results.",
            "main_review": "Pros \n\n- I feel the idea of training on the group which leads to largest overall decrease in loss is natural and interesting. The use case of one group having larger noise and thus the issue of group DRO focusing on that too much is interesting. The idea is a natural solution to that issue.\n- The synthetic examples presented in the paper are interesting and clearly bring out the use cases of the method proposed and comparison with group DRO.\n- The empirical results presented lead to improved results on a variety of benchmark tasks.\n\nCons\n\n- I understand the synthetic examples presented but it is still hard for me to understand why this method also works better for the benchmark datasets. For example, in the simple spurious correlation setting with majority and minority groups, I would expect the spurious feature to also have a large reduction in the loss due to the imbalance between majority and minority groups. For group DRO, it makes sense the any large correlation with the spurious feature would hurt one of the groups and thus, the worst loss amongst groups can increase. But, the intuition is not so clear for the method proposed in this paper. Since, the gradient method is not minimizing any fixed loss function, it is hard to understand what is going on. For the real world datasets, it would have been nicer is the paper included some results on why the proposed method did better as it is hard to see why the benchmark datasets reflect the structure proposed in the toy setups.\n\nQuestions/Clarifications/Suggestions\n\n- It would be helpful for the readers if the synthetic examples were presented more clearly. For example, I am guessing that the groups are formed randomly in each of the synthetic examples by fixing their sizes. Some figures on how the data actually looks using figures would be helpful for the readers. \n- The authors mention their method does not optimize any particular loss function. Is it possible that there exists a loss function which their method optimizes but that is hard to find? What is the precise statement that the authors mean here? \n- The authors mention that they have to scale the gradient on page 3 because the norm of the gradient can get very small close to convergence. Can the authors comment more on why scaling by l_i(\\theta^t)^p is the right thing to do and how do they choose p=0.5? Why does the scaling need to depend on the loss value at all? Does the analysis in Theorem 1 take into account this scaling or is this an implementation detail? ",
            "summary_of_the_review": "I would make a recommendation for accepting this paper.\n\nOverall, I think the idea of the paper is interesting and also leads to improved results on benchmark datasets. The main concern is that there could have been more discussion  on why this method works for these real world datasets by connecting them to the synthetic setups presented in the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a new method for robust ML under distribution shifts. Past work has looked at formulations that minimize the worst group error. This paper adds a new twist on it and instead argues for focusing on the group that leads to the greatest decrease in average training error for all the groups. This intuition is combined into an algorithm and the paper proves that though their proposed algorithm doesn't minimize a specific loss function, it still finds first-order-stationary points. The results are shown on several synthetic datasets as well as on the WILDS Robust ML benchmark that show the superior performance of the proposed algorithm over several baselines.\n\n\n\nMain Contributions: \n\n1). The paper proposes a new approach for robust ML under distribution shifts that performs gradient descent not on the group with worst error but on the group which decreases the average error of all other groups.\n\n2). Results are shown on synthetic and real-world datasets which show the superior performance of the proposed method in achieving group robustness.\n",
            "main_review": "Originality & Quality: While I like the simplicity of the proposed approach, there are a couple of glaring weaknesses in the paper: \n\n\n\n1). The idea that we shouldn't minimize the worst-group error but rather minimize the error on the group that decreases all other groups' errors is intriguing! Definitely, the extant approach of minimizing the worst group error has generalization problems and hence doesn't perform best on all the benchmarks. However, the alternative proposed in the paper is not motivated, but rather comes across as an \"ad-hoc\" idea that \"just seems to work\". This is also corroborated by the fact that the proposed algorithm doesn't perform gradient descent on a particular loss function. That's the biggest weakness of this paper, especially in times when we want to infuse more *science* and *rigor* into deep learning. Sure, the paper tries to motivate the algorithm by saying that the \"worst group\" approach doesn't model inter-group similarity, but that intuition is nebulous at best. \n\n\n2). The results on the synthetic datasets seem contrived, but that's OK as one can design synthetic dataset to make their point. However, the standard benchmarks shown in Table 3 are also altered. For example, the CivilComments dataset is shown as a 2 group when it is originally a 8-group task (the groups being the demographics of the users) as shown in the WILDS dataset paper. Similarly, the MultiNLI dataset contains 2-groups that seem contrived. \n\n\nClarity: The paper is well written and puts itself nicely in context of previous work. The overall presentation of the paper is good.\n\nSignificance: The paper addresses an important problem of robust ML and proposes a new method for improving the \"group\" robustness.\n",
            "summary_of_the_review": "The paper provides an intriguing idea to improve group distributional robustness, but at its heart it is just an *ad-hoc algorithm* that *seems to work*. It is unclear what really is being optimized since there is no clear loss function that is minimized. The results also seem a little unconvincing since some of the real-world datasets are altered and not used in their original form, e.g., CivilComments, which raises questions regarding if the approach even works at all, irrespective of the issues regarding lack of theory behind the algorithm.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a novel ERM-based method for classification task with group annotated training data. The goal is to be group distributionally robust while enhancing the minority performance. The authors make an improvement to an existing method named Group-DRO by modifying the focus on the group with the highest regularized loss to focus on the group that leads to the largest decrease in average training loss. They analyze the convergence and present detailed comparisons with Group-DRO.",
            "main_review": "PROS:\n\n- Building an ERM-based method that performs well on the whole dataset without sacrificing the prediction accuracy on the group-level worse case really makes sense to me, especially when different groups have different amounts of label noise.\n- The paper is well written, with a clear presentation style, and well-supported contributions, and easy to follow with good details on the experimental setup.\n- The theoretical analyses and empirical understanding provide additional insight into this new algorithm. \n\nConcerns:\n\n- In some scenarios, the group annotations are available. Should we directly discard this information?\n- What is the computational complexity of the algorithm? \n- Is this method vulnerable to label noise?\n\n\n*** Post Rebuttal: After reading the authors' response and the updated components of the manuscript, I thank the authors for addressing nearly all of my concerns. The inclusion of a clearer motivation, more discussion w.r.t. CGD and datasets, all enhance my understanding of the contributions of the paper beyond my original review. I decide to vote for acceptance. ***",
            "summary_of_the_review": "Overall, I think this is an interesting and solid paper.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper provides an efficient method to generalize to all groups in the presence of sub-population shifts and domain adaptation. The paper conducts extensive simulations to derive insights and also numerical experiments on the benchmark dataset to demonstrate the performance. The proposed method is intuitive, easily implemented, and has good performance.",
            "main_review": "The proposed method is easily understood and implemented. It also has good performance empirically. The writing is clear and the intuition behind the method is clearly conveyed in the simulation study. The intuition of inter-group interactions seems reasonable to me.\n\nWeakness:\nFor the detailed algorithm, There is somewhere that is unclear to me.\n1. Close to convergence, the statement that the gradient $\\nabla ||\\ell_i( \\theta_t)||$ can be much smaller than the loss value $\\ell_i(\\theta_t)$ is unclear to me. In fact, consider $\\ell(\\theta) = ||\\theta ||^2_2$. It should be $\\ell(\\theta_t) << ||\\nabla \\ell(\\theta_t)||$ when close to the convergence. In Appendix A, why ||nabla \\ell(\\theta_t)|| could be as small as $\\sqrt{\\underline{\\sigma} \\ell_i(\\theta)}$. And why is $\\underline{\\sigma}$ close to zero?\n\n2. When $<g_i,g_j> = 0$, it does not exactly match the group-DRO update steps mentioned at the bottom of Page 2, since there is regularization between consecutive time steps.\n3. Please formally define $cos(g_i,g_j)$.\n3. At the end of paper 3, the author mentioned: \" The corrected loss values simply replace the $\\ell_i$ of Line 5 in Algorithm 1\". However, the correction $\\ell_i = \\ell_i + C/\\sqrt{n}$ does affect $\\nabla \\ell_i(\\theta)$. I think the author should refer to updating step (4).\n\nFor the simulations and experiments:\n1. At Page 6, \"y, 1-y on the third group, and set to y or 1-y w.p. 0.6\" should be set to y w.p 0.6\n2. For the datasets, what are population types \"Label * Group\" or Group? Why does the worst ratio refect loosely the strength of the spurious correlation?",
            "summary_of_the_review": "This paper provides a practical algorithm to the broad field of distributional shifts, domain adaptation, and fairness.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}