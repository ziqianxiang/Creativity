{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper presents an unsupervised method for learning Full-Waveform Inversion in geophysics, by combining a differentiable physics simulation with a CNN based inversion network.\n\nThe reviewers agreed that the paper was well written and described an important advance but were concerned about limited novelty and a potential sim2real gap. The authors responded to their critique with significant new experiments and clarified the novelty of their method relative to prior work.\n\nBased on the author responses, I recommend acceptance."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper presents a method for full-waveform inversion (an inverse problem in seismic imaging) that combines a convolutional neural network (CNN) with a physics-based forward modeling operator. As opposed to other work which directly learns the inverse mapping from measurements to the sought-after velocity parameter, the authors propose an \"unsupervised\" approach. Here, the CNN takes the seismic measurements as input and predicts a velocity field. Then, the physics-based forward operator produces measurements which can be compared to the original measurements to train the network. The authors evaluate their method on a new simulated dataset and show that it can outperform other supervised approaches.\n",
            "main_review": "**Strengths**\n- Combining the CNN with the physics-based model helps to alleviate the need for ground truth velocity maps, which is convenient.\n\n- The authors introduce a new large-scale dataset which could be of interest to the community working on data-driven solutions to full-waveform inversion (FWI).\n\n- The authors compare to other learning-based approaches and perform an ablation study to evaluate their proposed method.\n\n**Weaknesses**\n\n- There is already a very large body of work on combining neural networks (e.g., CNNs) and physics-based models for solving PDEs, including for FWI. Yet, in the introduction the authors cite only a single paper to put their work in context. I recognize that there is a more extensive review in the related work (at the end), but reading the paper I was confused if the authors are actually claiming the method as a contribution or if they are only applying it to FWI.\n\n- Indeed there are a few papers that ought to be cited which also combine a neural network with the physics-based model for FWI. For example, Mosser et al. (2020) combine a generative model with a physics-based model in order to improve FWI inversion, and He and Wang propose a very similar approach that uses a CNN to output the velocity field, and then they optimize the CNN through the physics-based forward model. This is actually extremely close to what the authors propose; the main difference seems to be that He and Wang perform test-time optimization to overfit to a single scene (so also unsupervised) while the authors propose to train across a dataset. This works should also be discussed, and the authors should clarify what the novelty of the proposed approach is.\n\n    He, Qinglong, and Yanfei Wang. \"Reparameterized full-waveform inversion using deep neural networks.\" Geophysics 86.1 (2021): V1-V13.\n\n    Mosser, Lukas, Olivier Dubrule, and Martin J. Blunt. \"Stochastic seismic waveform inversion using generative adversarial networks as a geological prior.\" Mathematical Geosciences 52.1 (2020): 53-79.\n\n- As with any other learned approach, generalization is likely a challenge with the proposed method. How does the method perform on slightly different datasets? For example can the model that is trained on CurvedFault generalize to FlatFault? Or can these models generalize to standard FWI datasets like the Marmousi dataset or the 2004 BP model (ref below)? These are standard datasets and so these results would likely be of interest to the FWI community.\n\n    Billette, F. J., and Sverre Brandsberg-Dahl. \"The 2004 BP velocity benchmark.\" 67th EAGE Conference & Exhibition. European Association of Geoscientists & Engineers, 2005.\n\n**Typos/Misc.**\n\n\nSection 1\n- It should be clarified that the proposed dataset is a simulated 2D dataset.\n\n- It's not clear what supervised method is being referred to here: \"...26.77% smaller than that of the supervised method\"\n\n- Full Waveform Inversion or Full-Waveform Inversion? Both are used (title, intro text, Section 2 header)\n\nSection 3\n\n\"Physics-informed\", but in section 1 \"Physical-informed\"\n",
            "summary_of_the_review": "Overall I lean slightly negative on the paper. My main criticism is that the novelty of the approach seems to be low. Moreover, the closest related work that I am aware of does not appear to be cited or discussed. Finally, while the method performs well in simulation, there are no results that clearly evaluate generalization and/or performance on more challenging datasets. I would be open to revising my score if the authors can clearly address these concerns.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This article studies the Full-Waveform Inversion (FWI) problem. The major contributions of this article could be summarized as\n\n(1) Formulate the FWI in an unsupervised way\n\n(2) Propose a learning strategy with perceptual loss\n\n(3) Introduce a dataset for benchmark\n",
            "main_review": "Strength:\nPropose an unsupervised formulation for FWI\n\nWeakness:\n\n**(1) Sim2Real gap between OpenFWI and seismic inversion:**\n\nOpenFWI obtains the velocity map and raw shot signals through simulation.  In this simulation, OpenFWI assumes uniform acquisition geometry, where the receivers are positioned at each grid with an interval of 15 meters. In real seismic inversion for exploration, the acquisition geometry may be non-uniform. Moreover, dataset such as (Yang & Ma, 2019) includes velocity maps with more complicated salt bodies.  It seems that OpenFWI provides more simplified velocity maps.  Therefore, it remains unknown how models trained on OpenFWI generalize to real scenarios.\n\n**(2) Convolution on raw seismic traces:**\n\nAs shown in the paper, the raw seismic traces could be simulated through forward modeling of PDE. Under the irregular acquisition geometry, the raw seismic traces are not image-like as we do not have receivers in a grid. In these scenarios, convolution operations that require matrix input could not be applied. Therefore, the convolution networks may be restricted to synthetic datasets.\n\n**(3) The role of PDE forward modeling:**\n\nIt seems that the PDE forward modeling is regarded as a blackbox during unsupervised training. Is there any illustration of how the forward modeling helps the training of CNN?\n\n**(4)The novelty of the unsupervised learning paradigm:**\n\nIs the proposed learning paradigm model-agnostic? How does it perform when we switch the backbone model to transformer (Dosovitskiy et al 2020) or MLP (Tolstikhin et al 2021)?\n\n\n\n\nFangshu Yang and Jianwei Ma. Deep-learning inversion: A next-generation seismic velocity model building method. Geophysics, 84(4):R583–R599, 2019.\n\nDosovitskiy A, Beyer L, Kolesnikov A, et al. An image is worth 16x16 words: Transformers for image recognition at scale[J]. arXiv preprint arXiv:2010.11929, 2020.\n\nTolstikhin I, Houlsby N, Kolesnikov A, et al. Mlp-mixer: An all-mlp architecture for vision[J]. arXiv preprint arXiv:2105.01601, 2021.\n",
            "summary_of_the_review": "The topic is of general interest and the paper is mostly well written. However, there exist concerns about a lack of novelty and incremental improvements.\n\nThe authors are strongly encouraged to address these shortcomings by:\n\ni) provide a better justification of the OpenFWI dataset, especially on how OpenFWI bridges the gap between simulation and real seismic inversion\n\nii) motivate the idea Neural Network+PDE  better\n\niii) improve the experimental section by studying if the proposed method is model-agnostic\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper introduces a novel way to solve Full-Waveform Inversion problem which is a common problem in geological surveys. Their method is based on CNN, giving a reconstruction of velocity field for measured seismic data, and the loss function which connects CNN to a discretized version of the governing partial differential equations (the wave equation). The power of the method lies in unsupervised learning which allows one to use more data without expensive data labelling. This is demonstrated using numerical results using their simulated seismic dataset.\n",
            "main_review": "Overall, I find their approach very interesting. The paper is also well structured and well written. However, I have some comments and points that I feel authors could consider.\n\nGeneric comments:\n\n- The dataset is generated for fixed measurement setup. Would this be practical or can it be extended for practical measurement procedures? They mention that physics driven approaches can be slow, but a data driven approach is very slow if a new neural network (and possibly dataset) should be generated for each measurement. \n\n- Have authors considered extending their work for semi-supervised setting? Would labels of some samples improve results if included to the loss function?\n\n- The improvement in their results seems to come from the fact that more samples are used (48K vs 24K). This is reasoned as this is unsupervised approach. But still it makes me wonder if somehow the other half has \"better\" more representative samples, i.e. more similar sample to the ground truths in their tests? To verify this, ave authors e.g. tried to switch the unlabelled part to be the labelled part (should be possible as this is simulation)?\n\n\nMore specific comments:\n\n- The wave equation employed in their study assumes elastic medium and does not hold, for example, for porous materials. This is fine for this study, but could be commented. \n\n- Introduction: it could be mentioned that OpenFWI is a simulated dataset \n\n- Introduction, ending: MSE and SSIM values are mentioned, but especially MSE values do not have so much meaning to a reader if there is no comparison, information about typical scale etc. Relative improvement should be fine there. \n\n- Eq (8) and (9): the loss function compares the measurement (/label) to modelled pressure signals. For \"perfect models\", the difference is noise. I am wondering if noise distribution could be somehow taken into account? \n\n- It is not mentioned how dense discretization was used (spatially and temporally)? Did authors check that numerical scheme has converged (e.g. denser discretization does not change results)? Is the same discretization used both in training and test sets? Also to avoid, inverse crime type of thing, it could be beneficial to use different discretization level in training and test sets. This would avoid, for example, a case in which the neural network learns artefacts of the numerical scheme. \n\n- Experiments: Is there any noise included to the numerical results?\n\n- Experiments: how lambdas in Eqs (8) and (9) are chosen?\n\n- Experiments: \"batch size 16\" this sounds quite small especially if 8 GPUs are used for training. Or is this per GPU batch size (in which case total batch size would be 8*16)?\n\n- Discussion mentions \"challenging velocity\", which has not commented in results section. This is bit odd.\n",
            "summary_of_the_review": "I am very positive about the paper and would recommend acceptance, but authors could also considers comments/points mentioned above. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}