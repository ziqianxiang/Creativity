{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper presents a method to turn a pretrained unconditional VAE into a conditional VAE by training an encoder to predict the unconditional VAE latents given conditional input. On a variety of image tasks, the method is shown to perform competitively with GANs, yielding good sample quality and diversity, and resulting in training time that improves on direct conditional generation approaches. While the technical novelty is limited, the strong empirical results and relevance given the growing availability of pretrained unconditional models lead me to recommend accepting this paper.\n\nEthics concerns have been raised for this paper. In particular, there were concerns with respect to the application of generative models, which inherit biases from the dataset, to guide medical imaging. It would be good to discuss this issue in more depth. A second point that was raised by the ethics committee is the fact that chest X-rays are usually not taken in a sequential manner. We ask the authors to either provide evidence that X-rays can be taken sequentially (one can think of situations where that's the case, e.g., X-rays of teeth in the mouth), preferably in the context of chest X-rays; if that's not possible, please highlight that the application, as described in the paper, is unrealistic (at the moment), and that it only serves as an illustration.\n\nThe key point we therefore ask the authors to address is to ensure that the paper clearly states how realistic the application is and what potential problems may arise when using generative models in this particular domain."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a method, IPA, that converts an unconditional VAE to a conditional one by reusing the pretrained weights and training a partial encoder. Experiments on the image completion task show favorable results compared to GAN-based approach. The authors also explored an application in Bayesian optimal experimental design which takes advantage of the the posterior estimation of IPA. ",
            "main_review": "Strong Points:\n\n1. Reusing pretrained models that cost huge amount of computing is a well-motivated problem, especially for models like VAEs that take a very long time to train\n2. The experiments contain enough details and the comparisons to the baselines are comprehensive. The results also support the claim that the proposed method could achieve descent performance given a tight computation budget\n3. The comparisons to CoModGAN on completion tasks with very little observed input area are very interesting\n\nWeak Points:\n\n1. The model is based on the hierarchical VAE framework, therefore, it should be made clear that it is not directly minimizing the KL divergence of $r(z|y;\\phi)$ and $\\hat{q}(z|y;\\hat{\\phi}))$, rather, it should be the KL divergence of $r(z_i|y;\\phi)$ and $\\hat{q}(z_i|y;\\hat{\\phi}))$ since $\\hat{q}(z|y;\\hat{\\phi}))$ is a multiplication of a chain of Gaussian distributions which itself is intractable as well. An example in the unconditional case could be found in equation 1 in [a]\n2. The adopted diversity metric, LPIPS-GT, is not ideal here. LPIPS-GT would be a good metric for measuring the mode coverage of the training targets, but cannot capture diversity that well. Consider a case of generating 100 samples, having 1 sample far away (e.g. LPIPS distance 0.1) and 99 close to the target (e.g. LPIPS distance 0.01) vs. generating 100 samples whose distances are uniformly spread across a given range (e.g. LPIPS distance 0.01 ~ 0.1). Clearly, the latter is more diverse but the two scenarios will have the same LPIPS-GT score.  Alternative diversity measurement: LPIPS diversity score [b], faithfulness-weighted variance [c]\n3. The formulation of partial VAE whose decoder does not depend on the conditional input $y$ is not new [d]. Though the authors pointed out    that the focus in that paper is different, the novelty in the technical formulation is not significant. Therefore, I gave a 2 on \"Technical Novelty And Significance\"\n4. In appendix B2: how do you get from equation (16) to (17)?\n5. In appendix B4, equation (33), the second Expectation should be $\\hat{q}(z|y)$ instead of $\\hat{q}(z|x)$?\n\n\nReferences\n\n[a] Arash Vahdat and Jan Kautz. Nvae: A deep hierarchical variational autoencoder. *arXiv preprint\narXiv:2007.03898*, 2020.\n\n[b] Zhu, Jun-Yan, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A. Efros, Oliver Wang and Eli Shechtman. “Toward Multimodal Image-to-Image Translation.” *NIPS* (2017).\n\n[c] Li, Ke, Shichong Peng, Tianhao Zhang and Jitendra Malik. “Multimodal Image Synthesis with Conditional Implicit Maximum Likelihood Estimation.” *International Journal of Computer Vision*(2020): 1-22.\n\n[d] Chao Ma, Sebastian Tschiatschek, Konstantina Palla, Jose ́ Miguel Herna ́ndez-Lobato, Sebastian Nowozin, and Cheng Zhang. Eddi: Efficient dynamic discovery of high-value information with partial vae. arXiv preprint arXiv:1809.11142, 2018.",
            "summary_of_the_review": "This paper is well-structured and contains enough detail overall. The problem setting is well-motivated and the proposed method showed promising results towards addressing the issue. However, the concerns listed above should be addressed to make the submission sound and complete. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "In this paper, the authors focus on training conditional variational autoencoders. They propose an architecture and training objective which leverages pretraining an initial unconditional VAE. The approach effectively infers the latent variables of the original unconditional VAE given the new conditioning input. They demonstrate the method on a number of datasets, specifically focusing on image completion. They show competitive performance with adversarial approaches. They also demonstrate an application in the realm of medical imaging. ",
            "main_review": "Strengths:\n\n1. The paper has strong conceptual and mathematical motivation and has firm theoretical foundations.\n\n2. The approach makes intuitive sense; it follows that pieces of an unconditional generative model can be used to build a conditional one.\n\n3. The method demonstrates promising applications. Image completion is crucial for computational photography, and application to medical imaging is an additional route to wide applications in society.\n\nWeaknesses:\n\n1. Technical and empirical novelty is limited; this is effectively a small modification to unconditional VAEs to create a conditional version. In addition, while quantitative results are competitive with respect to GANs, the performance margin is not particularly exceptional. \n\n2. The structure and flow of the paper could be improved. For example, the related works section is on one of the last pages of the paper. \n\n3. The choice of datasets is fairly simplistic (CIFAR-10, FFHQ-256, Edges2Shoes, Edges2Handbags). While there is pretraining on the ImageNet dataset, it would strengthen the paper to evaluate on the ImageNet dataset in a manner like CIFAR-10 and FFHQ-256.",
            "summary_of_the_review": "The authors propose a modification to variational autoencoders which improve them in a conditional setting. The show promising results on image completion on a number of datasets and also in the area of medical imaging. However, the paper suffers from a few drawbacks. First, the technical and empirical novelty is limited. Second, the choice of datasets used for evaluation is simplistic. \n\nIn light of the other reviewers concerns and the response from the authors, I upgrade my score. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a method of leveraging state-of-the-art VAE decoders (foundational models) to create new conditional VAEs by training a new encoder for prior of the latent space.  The authors demonstrate quite convincingly that the new conditional VAE can generate images with more variation than a state-of-the-art GAN while achieving a comparable quality of image.  The advantage of the approach is that it substantially reduces training times (a drawback of traditional VAEs).  They then propose a task in the domain of X-ray imaging where the improved variation leads to improved performance in targetted X-ray measurements.",
            "main_review": "The paper presents a simple, but nice idea.  Being able to leverage foundational models clearly saves a huge amount of computer time.  The evaluation carried out is very extensive and the results persuasive.  The use case scenario seems reasonable.\n\nI struggled with understanding how the conditional encoder is trained in such a way that the generated image is both diverse and accurate.  It clearly works and I may have just missed the explanation, but it is rather unclear to me what the objective described in Equation (7) does.  I am therefore going to score this lower than I would otherwise.  If you can clarify this either by showing me the explanation that I have over-read or by adding a short explanation (which given the page limit could be in the supplementary material), then I would be happy to reconsider and increase my score.\n\nAs a side remark, even the improved training times appear rather excessive.  Maybe this just a consequence of the difficulties of the problem.  It is though a bit sad.",
            "summary_of_the_review": "Overall this is a strong paper.  I am supportive of seeing this published.  I am missing an explanation of the authors' objective function and why it should find a diverse, but accurate prior.  This may just be my stupidity, but I think a clear explanation of this might be helpful to other readers (apologies, if I just read over this, but it wasn't obvious to me reading the main paper).  I am happy to increase my score if I can be satisfied on this point.\n\nIn view of your answer I have increased your score.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents a CVAE-based approach for conditional image generation, in which a pretrained VAE is utilized to speed-up the training process. The paper clearly demonstrates the benefit of using a pretrained artifact in terms of time/resource of training as well as the image generation quality and diversity.",
            "main_review": "- Motivation is clear. I especially like the third note in the introduction on the importance of this work: I believe that research that benefits from publicly-available pretrained weights (which are initially extremely costly to train) is a nice direction.\n- A minor comment on the discussion in Section 3: Defining an expressive conditional model in which the decoder is capable of generating a plausible output without requiring the explicit contribution of the condition has an additional benefit of avoiding posterior collapse when the conditioning signal is strong enough such that the decoder can generate \"a\" good sample that minimizes the reconstruction loss.\n- Regarding the Theorem 3.2, which only applies if the artifact are learned on the same dataset as the conditional VAE is trained on: Although it has been empirically shown that pretraining on a different dataset is still \"useful\", experiment in Fig. 4 suggests that the gap to the scenario where IPA pretrained on same dataset and on ImageNet is large, especially for the datasets that the domain gap to ImageNet is large. It would be great to have authors' view on feasible ways to bridge such gap when using pretrained artifacts?\n\nGenerally,\n- Results are impressive, given the training budget; the method achieves near state-of-the-art performance in terms of visual fidelity and even better in terms of diversity.\n- The paper is well-written and easy to follow",
            "summary_of_the_review": "The paper presents a simple but well-articulated approach for conditional image generation, where one wants to avoid training the entire network from scratch. I believe the idea of using existing publicly available models is good, and this method neatly utilizes such available models to achieve impressive performance (and to avoid complication and challenges of training the full model).",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}