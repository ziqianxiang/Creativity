{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This is an interesting paper on improving score-based conditional sampling and its use in solving inverse problems. The current method of sampling from NCSNv2 is somewhat inefficient and the authors propose a different SDE that seems to work better for conditional generation. \n\nThe paper is applied to Computational imaging and MRI and shows very good results and reasonable comparisons with the recent state of the art. One limitation is that the measurement process is artificial and ignores specifics of MRI (real measurements and multi-coils would strengthen the paper). In any case since this is a fundamental methods paper with a solid technical innovation on score-based sampling, I recommend acceptance."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper provides an unsupervised approach to solve the inverse problem for reconstructing medical CT and MRI scans using score-based generative models. The proposed method was evaluated on the LIDC and BraTS datasets. Compared to existing supervised and unsupervised approaches, the proposed method demonstrates comparable or better performances in terms of PSNR and SSIM. ",
            "main_review": "Strengths: \n1) The paper targets an interesting, important, but challenging problem in medical image reconstruction, which could be attractive to ICLR participants. \n\n2) Although I do not fully understand the proposed method (see the weaknesses below), it seems to be technically sound and efficient. \n\n3) The experimental results demonstrate the effectiveness of the proposed method, which shows comparable or even better results compared to supervised methods. \n\nWeaknesses:\n1) The writing of the method section could be improved to make it easier to understand. What is the connection between Section 3.1 and 3.2? How to obtain T? Predfined transformations? How to compute P(\\Lambda)? T and P(\\Lambda) are essential to calculate A, while they are not clearly explained in the paper. \n\n2) Maybe I missed the point, but what is the main difference between GAN-based methods and the score-based generative models? In the SDE model, is there a time-step size that should be predefined? If so, will it affect the generation result? How about the proposed method? How to set the step size? 1/N? how to choose N? \n\n3) The paper claims the efficiency of the method, then what is the computational cost of the proposed method? ",
            "summary_of_the_review": "Although the paper has some limitations, it presents good technical contributions. Therefore, I recommend the weak acceptance for this paper. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper introduces a method to use score-based generative model as a powerful prior when solving linear inverse problems in medical imaging. Compared to previous work that applied score models to inverse problems, this paper proposes a new conditional sampling approach.",
            "main_review": "The paper establish a new approach approach to solve linear inverse problems with score based generative models. In particular, given an unconditional score based generative model it is diffucult to sample directly from the conditional distribution $p(x_t|y)$ as it requires solving the conditional backward SDE. Instead, the authors propose to utlize the linear relationship between $x$ and $y$, and introduce a coupled stohcastic process $y_t$. Sampling can be done by adding an additional step that enforcing the linear relation between $x_t$ and $y_t$ at each sampling step.\n\nThe paper is well written and the idea is concise and novel. In current form it can only be applied to linear inverse problems, but I think there are certainly important applications of linear inverse problems so the contribution of this paper is substantial. I am not very familiar with the experimental evaluation of medical imaging, but I do see the paper making significant improments over previous methods based on paired training or generative models.\n\nI have several concerns:\n\n1. I think the biggest issue of the paper is lacking an motivation for the method. The method part of the paper can be re-organize a little bit to make the presentation clear. For example, the proposition 1 is somewhat absurd, as at the begining I do see why we need such a decomposition. The purpose of the extra iteration function is clear after reading it carefully, but I find it difficult to read at first look. I would suggest to first give a high level overview of the approach before section 2.1, that briefly introduces all the components of this approach and how to make them work, and them go through the details.\n\n2. Since score-based model also has the probability flow ODE formulation, and it can be sampled by solving the ODE where the randonmess only come from initialization. Can the probability flow ODE formulation be used in this task? In addition, maybe you can also discuss previous approch that uses normalizing flow as prior for the solving inverse problems such as [1]. \n\n3. Let me know if I missed anything, but what is the sampling formuation for the item \"Score SDE\" in table 1? Do you train an explicit conditional score based model? In general I think more detailed introduction to each item in the table is needed, espeically for the item \"Score SDE\" which is highly related. \n\n4. Also, do you include a study on if the result is sensitive to $\\lambda$, the coefficient for the linear constraint? \n\n[1] Invertible generative models for inverse problems: mitigating representation error and dataset bias. https://arxiv.org/abs/1905.11672",
            "summary_of_the_review": "The paper is well written, with a clean idea and strong empirical results. There are some issues with the presenttaion. I will give a weak accept.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The manuscript applies denoising score matching to linear inverse problems to solve compressed sensing problems in medical imaging, such as angular-undersampled CT and accelerated MRI reconstruction. Throughout the paper, the observed measurements $y$ are considered noise-free, which is reflected by a Dirac measurement distribution. To train a score function, a variance exploding SDE is considered as in previous works, e.g. Song et al. (2021). \nDuring inference, the authors incorporate a weighted projection onto measurement samples unlike previous approaches, which consider the gradient of the data distribution. This projection can be implemented in various sampling approaches such as annealed Langevin dynamics or predictor-corrector schemes. \nThe numerical results indicate that unsupervised score matching methods are well suited for inverse problems in imaging and yield superior generalization performance.",
            "main_review": "Strengths:\n\nThe overall idea - combine diffusion-based generative models with inverse problems - is well presented and the paper is easy to read. Compared to existing methods in this research direction, there is some novelty, mainly in the adapted sampling approaches.\n\nThe experimental results of the paper suggest that the proposed combination of unsupervised denoising score matching of a variance exploding SDE along with the novel sampling approach yields superior results and even outperforms supervised methods on some problems such as metal artifact removal.\n\nWeaknesses:\n\nThe definition of inverse problems in section 2.1 is quite restrictive. The Dirac delta measurements distribution prevents any incorporation of real-world noise typically observed in inverse problems in medical imaging. For instance, in MRI frequently a Gaussian measurement noise is assumed, while the electron and photon noise in CT measurement can be described by a mixture of Gaussian and Poisson noise. Hence, real-world problems do not fit this restrictive definition of inverse problems.\n\nAll proofs (Proposition 1,  Lemma 1, and Theorem 1) are trivial and do not yield new theoretical insights.\n\nAs already mentioned above, the core novelty of the proposed paper is the additional sampling step performed in Eq. (5) and defined in Theorem 1. From an optimization point of view, the update rule in Theorem 1 implements a proximal mapping, which is very frequently used in MRI reconstruction [1]. This proximal mapping minimizes the quadratic energy\n$$\n\\min_z \\frac{1}{2}\\Vert z-x\\Vert_2^2 + \\frac{\\tau}{2}\\Vert\\text{diag}(\\Lambda) T z - y\\Vert_2^2\n$$\nfor $\\tau>0$ and reads as\n$$\nz = T^\\top \\left(\\frac{Tx + \\tau \\text{diag}(\\Lambda) y}{I + \\tau \\text{diag}(\\Lambda)}\\right),\n$$\nusing the assumption $T^\\top T=I$, which is fulfilled for a proper choice of $T$ in MRI and CT reconstruction problems. The equivalence of the proximal mapping and the mapping defined in Theorem 1 can be shown by using $I = (I-\\Lambda)+\\Lambda$ and the fact that $\\frac{1}{1+\\tau}+\\frac{\\tau}{1+\\tau}$ is a convex combination. Clearly, the proximal map minimizes an energy that employs a quadratic penalization of the data fidelity, which implicitly leads to a Gaussian noise assumption of the measurement process. Consequently, the limited assumptions discussed in the first weakness are actually not relevant.\n\nThe general approach is motivated by an explicit discretization scheme of the backward SDE. However, proximal maps are related to implicit discretizations schemes. So, is the resulting algorithm a mixed discretization (semi-explicit)? What is the corresponding forward SDE? More details w.r.t. this regard would clearly improve the quality of the paper since the SDE perspective is an integral part of the entire work. \n\nSince the choice of $\\lambda$ often influences the reconstruction quality strongly, more details on determining this hyperparameter would be helpful.\n\nIn section 3.2 at the end of the second paragraph, the dimensions of $A\\in\\mathbb{R}^{m\\times n}$ and $z\\in\\mathbb{R}^{m}$ do not match in the proposed sampling. Please, correct this.\n\nThe paper misses many implementation details. For instance, the learning problem (model, loss, optimization) is not explicitly defined.\n\n[1] Hammernik, K., Schlemper, J., Qin, C., Duan, J., Summers, R. M., & Rueckert, D. (2021). Systematic evaluation of iterative deep neural networks for fast parallel MRI reconstruction with sensitivity‐weighted coil combination. Magnetic Resonance in Medicine.",
            "summary_of_the_review": "Overall I think the manuscript is marginally below the acceptance threshold due to unnecessary limitations of the approach and missing theoretical justification of the proposed discretization scheme of the reverse SDE despite the outstanding numerical results. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}