{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper introduces an idea that was found interesting by all reviewers (including Gxxe who recommends a marginal reject). A majority of the reviewers also point out a few weaknesses of the paper, notably in terms of clarity of several statements that were found to be hand-wavy (see the reviews of Gxxe and oSPE for more precise details). The area chair agrees with those statements, but overall, the originality of the idea introduced in this paper outweighs these weaknesses, and the experimental study is conducted in a reasonably convincing manner.\n\nEven though there is room for improvements, the area chair is happy to recommend an accept, but encourages the authors to follow the constructive feedback provided by the reviewers for the camera-ready version."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a novel approach to using deep networks for image deblurring. Since training with simply reconstruction losses usually leads to oversmoothed results, recent works have looked at using perceptual and adversarial losses.\n\nThe paper proposes an approach similar to an adversarial loss. If an image is not de-blurred entirely, it leaves within itself some tell-tale signs of the original blur. The paper proposes learning a “reblurring” network that given a “deblurred” image should yield the original “blurry” image, while given a true sharp image should output the image itself. The deblurring network is then trained in a sense to fool the re-blurring network, by generating images that would be left untouched by the reblurring network. The paper also proposes a “test time adaptation” approach.",
            "main_review": "This is an interesting idea. For the task of deblurring, it represents a logical and novel formulation of the “adversary”: rather than just saying whether the input is truly sharp or the output of a deblurring network, the reblurring network has to reproduce the original blurry image in the latter case.\n\nWhile the results are encouraging, there are a number of issues with the paper:\n\nThe paper needs to do a much better job in clearly and systematically establishing the benefit of the proposed method against a standard adversarial loss and other perceptual losses (which are much simpler and more straightforward than the proposed reblurring loss). In particular, the efficacy of the network WITHOUT test-time adaptation should be established. This is because TTA is expensive, and it is not clear whether other methods couldn’t also be improved with TTA (for example, those based on standard adversarial losses) or by just having slower but deeper networks.\n\nTable 4 seems to suggest minimal additional benefit of the reblur loss (without TTA). There is some benefit in NIQE, none in LPIPS, and PSNR and SSIM get worse. This comparison is also to a specific weight on the adversarial loss. Did the authors sweep for different loss weights to find the optimal one for training only with an adversarial (+ VGG) loss? This is what I mean by a systematic evaluation: the paper should find the optimal hyperparameters for training with only a regular adversarial loss and compare to the optimal setting for the proposed method — without TTA and using a comparable architecture for the discriminator as the proposed MR.\n\n\nThe paper also needs more comprehensive results reported for comparisons to state-of-the-art. There are no quantitative results, and the qualitative results are only with TTA. Visually, the improvement of the proposed method with TTA over DeblurGAN is relatively small. It would be natural to wonder if that improvement disappears without TTA, and if infact, the proposed method does worse than DeblurGAN. As noted, TTA is expensive, and an orthogonal approach that could potentially be applied to other adversarially trained deblurring networks.\n\nThe paper, especially the introduction, could be a lot clearer in explaining the basic idea. Figure 1 is great in terms of layout, but the captions / legend is not informative making it very unintuitive.  The caption should at the very least explain what L, S, \\hat{S}, and B are without having readers to dig through the text in section 3. The “shared” is confusing — one would anyway assume that all M_R’s are the same, but the fact there’s shared lines only among pairs on the left and right makes us question if the two pairs are different from each other. Having (a) and (b) in Figure 1 with the corresponding headings is also confusing. They each respectively describe the training loss for M_R and M_D, and if I understand correctly, each iteration involves doing an update step of each. This does not come across from the figure. And finally, some more details of the test-time adaptation should be included in the main paper. Most of the text in the main paper in that section gives “intuition” — but is very confusing to read since the reader doesn’t know exactly what is being optimized and what is being updated (image or network weights).\n\n\nA lot of the explanations in the paper are very hand-wavy, and not at all clear to the reader. This is especially true about the use of a pseudo sharp image instead of a sharp image: for example, I don’t understand what the authors mean by “In contrast to S that differ from the deblurred image L by the realness, \\hat{S} can avoid being MR distracted by such an unintentional difference, focusing on image sharpness.” I’m actually not sure why using S-hat doesn’t just cause a degenerate solution where MD produces oversmoothed outputs all the time to prevent MR from figuring out if the original image was blurry or not.",
            "summary_of_the_review": "Given the issues with the experiments and presentation above, I don't think the paper is ready for publication.\n\n### Post-rebuttal\n\nIncreasing score from reject to borderline/marginal  reject. I think the paper still needs a bit more work, but would not object to it being accepted. Please see detailed comment in response to rebuttal below.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "A novel deblurring method is proposed by introducing the concept of reblurring loss. Conventional techniques deblur blurry images to some extent however there are some unremoved blur contents, where it can be used to reconstruct (reblur) blurry images. On the other hand, cleanly deblurred images have only sharp contents and it is difficult to reblur the images since no blurry cues are left. By using such observation, a reblurring module and a deblurring module with reblurring loss are proposed. Experimental results show that the proposed framework outperforms SOTA quantitatively and qualitatively on the GOPRO and REDS dataset. ",
            "main_review": "1. Technical novelty\nThe observation that the \"clean images are hard to reblur\" is quite novel. \nFollowing the observation, the proposed reblurring loss is logical and experimental results are consistent. \nI'm concerned that the concept of deblur-reblur is similar to the GANs, but the authors well addressed the issue in the introduction. \n\n2. Writing\nOverall it is well-written and easy to read. However, more proofreading and re-arranging figures are needed before publication. \nIn Figure 1, the sharp image (supposed to be ground truth) and deblurred images are located in the top row. It may be a reasonable arrangement since they are seemingly similar. However since they have different meanings, there should be a better arrangement for easier understanding. \nReaders may be familiar with the blurry and deblurred image, but not the reblurred image since it is quite a new concept. So additional figures explaining and emphasizing such concepts would help the understanding. \nIn Figure 2, there are B and S in both of Figure 2 (a) and (b), where the arrangement is somewhat confusing. \nTable 1 is mentioned just below the equation (1) but there is no explanation about M_D before Table 1. \n\n3. Experimental results\nExperimental results improve SOTA in perceptual measures such as LPIPS and NIQE. However, it did not improve PSNR and SSIM, which gives the impression that the deblurred image may distort the original image and obtain better perceptual measures by sharpening. ",
            "summary_of_the_review": "The paper introduces an interesting observation and proposes novel modules based on the observation where the development is very logical. Overall, the paper is easy to read, however more proofreading is required. Experimental results improve the SOTA but there should be justification for some results. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work addresses the problem of image deblurring by training a deep model in an end-to-end fashion. Similar to recent work, the method makes use of large paired (blurry,sharp) training datasets to train the deblurring network.\n\nThe main idea of the work is that a correctly deblurred image should not contain any information about the original blur. The method exploits this observation by using an auxiliary network that tries to re-blur the deblurred image so it has the same blur as the original one. If the deblurred image was perfectly deblurred this shouldn't be possible.\n\nThese two networks end up having a \"similar\" role as a generator-discriminator on a GAN set-up. But even if there's this superficial connection with GANs the formalism is completely different. Here the reblurring network outputs an image that is compared to another image (i.e., reference-based).\n\nThe work introduces three different loss terms: L_blur, L_sharp and L_reblur as long as the typical regression loss L1 between deblurred and sharp images.\n\n- L_blur: is mainly used to train the re-blurring module;\n- L_sharp: is used to avoid the re-blurring module to just apply the average blurring;\n- L_reblur: is used as a regression loss on the space of re-blurred images.\n\nAdditionally, the paper proposes a test time adaptation where the reblurring network is used to boost the deblurring results on a given image. This is done by approximately inverting the re-blurring network using gradient descent. \n\nThe work presents several experiments including ablation studies with two of the popular (synthetic) datasets used in image/video deblurring (GoPro and REDS). Several comparisons with SOTA methods and some results on a real image dataset (Lai et al. 2016). Different quantitative metrics are given (PSNR,SSIM, LPIPS, NIQE) as well as several figures showing visual comparisons.",
            "main_review": "The main idea of the paper is based on an interesting observation. The proposed formulation/implementation seems to take advantage of the observation.\n\nStrengths:\n- The main idea of the paper is interesting and the proposed formulation seems to take advantage of the observation.\n- Empirical results show that the method produces better results than the compared methods\nThe idea of using the re-blurring network to mitigate the out-of-distribution problems seems interesting.\n\nWeaknesses:\n- To implement the idea, the method introduces several loss terms that seem to be needed to avoid degenerate cases and other issues. In this sense, it feels that the formulation could be a little more elegant. The overall idea is that a deblurred image should be close to the target and also shouldn't have information about the original blur. In the end, the whole system seems to be doing this but I wonder if all the components are needed.\n\n- The paper idea seems to be limited to deblurring. But in many parts the paper claims that the ideas are \"applicable to general learning-based approaches\" If this is one of the claims, there needs to be evidence supporting this.\n\n- Analysis. There are many experiments but there's not too much analysis. From the exposition it is hard to claim that the method is actually improving over more classical losses like content loss (vgg loss, as shown in Table 4). So the question is more like if this method is better than simpler approaches? Also, if the issue is remaining blur, can't we just re-iterate the deblurring model till we reach a fixed-point?\n\n\nOther comments:\n\n- \"inherent limitation of PSNR-oriented solutions\" Do you mean the \"regression-to-mean\" problem that happens when we train with reference-based losses? This needs to be better discussed. \n\nThere are other reference based perceptual losses and relevant work that could be added to the overall discussion (not asking for more experiments but this could help improving the related work section):\n\nMechrez, R., Talmi, I., Shama, F. and Zelnik-Manor, L., 2018, December. Maintaining natural image statistics with the contextual loss. In Asian Conference on Computer Vision (pp. 427-443). Springer, Cham.\n\nM. Delbracio, H. Talebei and P. Milanfar,  \"Projected Distribution Loss for Image Enhancement,\" in 2021 IEEE International Conference on Computational Photography (ICCP), Haifa, Israel, 2021\n\nTariq, T., Tursun, O.T., Kim, M. and Didyk, P., 2020, August. Why Are Deep Representations Good Perceptual Quality Features?. In European Conference on Computer Vision (pp. 445-461). Springer, Cham.\n\nCzolbe, S., Krause, O., Cox, I. and Igel, C., 2020. A Loss Function for Generative Neural Networks Based on Watson’s Perceptual Model. Advances in Neural Information Processing Systems, 33.\n\n- Figure 1. This figure is unclear, please include an explanation for what is given on the top and bottom rows for each of the methods.\n\n- \"From a deblurred output, the reblurring module tries to make the reblurred image close to the original\" So in practice this reblurring network is the inverse of the deblurring module. Why not present this module in this way?\n\n- Writing is a little disorganized. For example in the introduction when referring to the \"reblurring loss\" it is unclear what is \"the difference\" that is mentioned. One of the listed contribution depends on this \"reblurring loss\" so this needs to be better explained in the introduction.\n\n- The need for the pseudo-sharp image \\hat{S}. The argument for using \\hat{S} and not S seems to be rather empirical so this should be supported by evidence. In the current presentation there's a lot of emphasis on measuring sharpness but not realism, but then later for evaluating the quality perceptual metrics such as LPIPS and NIQE are used. So, there seems to be a mismatch between what is claimed and what is actually happening. \n\n- The test-time adaptation inverts the re-blurring network. This needs more analysis in terms of: \nWhat happens if we minimize this loss (gradient descent till convergence)? How many gradient descent steps are needed. This is not discussed much in the paper and I found it to be an interesting contribution. It will be also helpful to show cross-datasets performances (trained with GoPro and evaluated with a different dataset, e.g. HIDE, Real-Blur or REDS).\n\n- Perceptual Distortion tradeoff. The perceptual distortion trade-off balances a reference based metric against a non-reference metric (e.g., distance to the natural image manifold). PSNR and LPIPS are both reference based metrics so it doesn't make sense (formally) to refer to this type of plot as a distortion-perception trade-off. Maybe the plot should be made with NIQE instead of LPIPS.\n",
            "summary_of_the_review": "This paper introduces an interesting idea for improving image deblurring models: the deblurred image should not contain information/traces about the original blur.  This is a bold statement. The paper crystalizes this idea using two networks (deblurring and re-blurring network) that are co-trained with different loss terms. The implementation seems (a little) too complex with many terms that try to avoid different types of artifacts/degenerative cases. But in the end this seems like a valid implementation of the initial idea. The current analysis didn't convince me that the method is doing much better or better than other methods that just compare the restored and sharp images on a pre-computed feature space (is this a matter of tuning the contributions of each loss term?). I think the paper needs to better discuss and analyze this. Additionally, the idea seems to be specific for dealing with blur. Can the same idea apply to other (restoration) tasks?",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}