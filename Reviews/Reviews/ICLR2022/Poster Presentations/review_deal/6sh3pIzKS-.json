{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper uses chemical reaction data as a means to help train molecule embeddings, by requiring embeddings to satisfy known reaction equations. The idea is nice and clear, and the paper includes strong empirical evaluation. All four reviewers agreed the paper could be accepted, with two of them raising their scores after a detailed author rebuttal and discussion, which included additional experiments."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a molecule representation learning method which is guided by chemical reactions. \nIn particular, it leverages chemical reaction equations by forcing the sum of reactant embeddings and the sum of product embed- dings to be equal for each chemical equation. \nThis idea is simple and useful, sharing the spirit of Word2Vec and TransE. \n\n\n\n",
            "main_review": "Overall, this is an insightful paper. \nAlthough the method is simple (only 0.5 page), it makes sense and works well.\nThe motivation, the solution and the results are convincing. The paper is clearly written. \nIn particular, the paper presents several fail cases and tries to explain them. \n\nPlease consider and discuss the following:\n- In experiments, USPTO which contains 478,612 chemical reactions is used. Did you screen out useless reactions? Or If you directly consider all reactions?\n- Report the computation cost. \n- Other choices of (5)? Like more complicated pooling methods? \n- Discuss the difference and related w.r.t. other papers which consider taking chemical reaction equations as prior knowledge [1,2]\n\n[1] GENERATING MOLECULES VIA CHEMICAL REACTIONS, ICLR 2019 workshop.\n[2] A generative model for molecule generation based on chemical reaction trees, ArXiv 2021.\n",
            "summary_of_the_review": "This paper is insightful, clearly written and presents good empirical results. \nI vote for acceptance. If the concerns mentioned above are addressed, it can be better. \n\n\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors describe a novel pre-training method to learn molecular representation based on the formal relationship between molecules given by chemical reactions (the reactants are related to the products of a chemical reaction)\n\nThe performance of the new embedding is evaluated on several chemical tasks.",
            "main_review": "\n### strengths\n- I like the idea of using the relationship of reactants to products for pretraining. \n- the paper is well explained\n- the experimental results are reasonable (but see comment below)\n\n### weaknesses\n\nThe experiments that the authors ran are reasonable to showcase the new method, but are maybe not the most obvious ones I would have expected. The chemical property prediction experiment is good, however, the product ranking experiment (I am a bit reluctant to call it reaction prediction, because no novel product structure is actually predicted), and the graph edit distance prediction are a bit \"non-standard\".\n\nI would suggest to consider a \"proper\" reaction prediction task, for example either to use the input representation for template prediction, or have a GNN-to-SMILES-seq transformer model and compare to a SMILES-to-SMILES transformer.\n\nanother stronger experiment would be reaction classification, or yield prediction. here, it might be instructive to compare to the work of Schwaller et al. e.g.\nhttps://iopscience.iop.org/article/10.1088/2632-2153/abc81d/meta\nhttps://www.nature.com/articles/s42256-020-00284-w\nin this context it also make sense to compare to reaction fingerprints such as the one by Probst and Schneider\nhttps://chemrxiv.org/engage/chemrxiv/article-details/60e358fb379e8d3ba9f92d15\nhttps://pubs.acs.org/doi/abs/10.1021/ci5006614\n\nIn my opinion, with these additional experiments the paper would stronger. In the currently form I would only recommend weak accept because I like the concept.\n\n\n\n### notes, questions and comments:\n1. I found the observation that bond types are not needed in the GNN quite interesting.\n2. is the assumption that the reactants and products are sets sufficient, or would a more general assumption that reactants and products are multi-sets (ie. unordered collections where a reactant or product can occur not just once, e.g. in an Ullmann coupling Ph-Br + Br-Ph -> Ph-Ph \n) be more expressive?\n3. in the derivation it seems that balanced reactions are required, but USPTO is (I believe) not balanced (e.g. leaving groups are disappearing from the right side). would that be a problem?\n4. suggested additional references: Merkwirth 2005 for GNNs for molecules https://doi.org/10.1021/ci049613b ; Segler et al 2017  https://doi.org/10.1002/chem.201605499 for reaction prediction with neural nets ",
            "summary_of_the_review": "Creative use of data for pretraining, experiments could be stronger\n\n\n_________\nafter author answer:\nScore adjusted to 8",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper is about learning a vector representation of molecules in a way that the learned representation preserves the equivalence of molecules with respect to chemical reactions. They do so by forcing the sum of reactant embeddings and the sum of product embeddings to be equal for each chemical equation.  They have also shown experimentally that such embeddings can improve the performance of downstream tasks such as chemical reaction prediction, molecule property prediction, and graph edit distance prediction problems. ",
            "main_review": "The strength: the idea of the paper using the reaction to embed molecules in a space where the summation of reactant embeddings is equal to the summation of product embeddings is very interesting. And the experimental results also seem to be promising. I just have a few concerns as follows:\n\n1.  \"The reaction center of R → P is defined as an induced subgraph of reactants R, in which each atom has\nat least one bond whose type differs from R to P (“no bond” is also seen as a bond type)\" this sounds bit confusing, I did not really get what does it mean, I can understand in terms of graph edit distance, \"a reaction center is a minimal set of graph edits needed to transform reactants to products.\" but still very confused.\n\n2. It is not clear to me how the current model can learn the reaction template.\n\n3. figure 3 is not really clear to me\n",
            "summary_of_the_review": "The idea presented in the paper is novel, interesting, simple, and direct.  The results seem to be promising. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes to use chemical reactions to pretrain molecular graph representations by 1) considering the reactants and products to be positive samples in the contrastive learning 2) pretraining using USPTO-479k reaction dataset.  The result is a pertaining method that outperforms a variety of baseline methods on reaction prediction and molecular property prediction tasks. ",
            "main_review": "Strength\n1.\tThe idea of using chemical reactions to perform contrastive learning for molecular representation is novel, which offers alternative solutions to the problem by leveraging domain knowledge from the synthetic perspective. This formulation avoids the unjustified masking of molecular graphs in previous works (as a small modification of molecular structure may result in a series of changes in chemical properties). The provided benchmarks open a new avenue for the molecular contrastive learning community.\n2.  The paper is generally well written with minor typos.\n\nWeakness\n1.\tSome of the experiments' decisions make the experimental results are not convincing for me: 1) taking R->P as positive samples potentially cause ambiguity. For example, if there are two reactions, OHCH2CHOHCH2OH -> CH2CHOHCH2OH + OH and OHCH2CHOHCH2OH -> OHCH2CHCH2OH, the MolR would force h_{OHCH2CHCH2OH} and h_{CH2CHOHCH2OH} to be similar. This is unreasonable as the position of a functional group will influence their molecular properties significantly. \n2.\tThe authors did not clarify what kind of splits are used for training/validation/test split. If the molecular properties data are randomly split, the results of D-MPNN are significantly lower than the values reported in its original paper and other SOTA GNN models (e.g.[1][2][3]). \n3.\tThe authors should report the accuracy of the original methods (GCN, GAT, SAGE, TAG); therefore, we can make a clear comparison of how many improvements we can expect by using MolR \n4.\tOther graph contrastive learning methods (GraphCL[4], GraphLoG[5]) should also be compared. \n\nReference\n[1] Xiong Z, Wang D, Liu X, et al. Pushing the boundaries of molecular representation for drug discovery with the graph attention mechanism[J]. Journal of medicinal chemistry, 2019, 63(16): 8749-8760.\n\n[2] Li Z, Yang S, Song G, et al. Conformation-Guided Molecular Representation with Hamiltonian Neural Networks[C]//International Conference on Learning Representations. 2020.\n\n[3] Song Y, Zheng S, Niu Z, et al. Communicative Representation Learning on Attributed Molecular Graphs[C]//IJCAI. 2020: 2831-2838.\n\n[4] You Y, Chen T, Sui Y, et al. Graph contrastive learning with augmentations[J]. Advances in Neural Information Processing Systems, 2020, 33: 5812-5823.\n\n[5] Xu M, Wang H, Ni B, et al. Self-supervised Graph-level Representation Learning with Local and Global Structure[J]. arXiv preprint arXiv:2106.04113, 2021.\n",
            "summary_of_the_review": "The motivation for this research area is strong and there have been several papers addressing similar problems at previous top-tier machine learning conferences. I think ICLR is a good venue for this manuscript.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}