{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper proposes a novel approach for estimating the high-dimensional intensity function of a Poisson process. The proposed approach builds on generalized additive models, using lower-dimensional projections. \n\nThe reviewers noted that, although the paper is well written, the position of this paper compared to earlier related work is unclear, and the empirical evaluation of the method should be strenghtened. The authors clarified some points in their response, but the paper would still require some more modifications to be ready for publication. I therefore recommend this paper to be rejected."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a method to estimate the multi-dimensional intensity function of a Poisson process with a lower-dimensional projection. The proposed method is motivated by perspectives of information geometry and generalized additive models in statistics. The performance of the proposed method is extreme through synthetic examples and a real data analysis.",
            "main_review": "The paper is overall well written and I read it with interest. The major issue I have with this paper is that the proposed approach has long existed in the statistics literature for decades, under the context of generalized additive models. In particular, in chapter 5.6 of  [1], the tensor product bases are more flexible than the approach proposed in this paper. In my opinion, the lower-dimensional approximation proposed in this paper is essentially a piecewise constant approximation of the intensity function (in lower dimension), which is a special case of the tensor product basses.  If comparisons should be made, it should be between the proposed method and the GAM with tensor product bases, instead of the RKHS formulation. \n\nIn addition, the partial order in the formulation (7) seems to rely on the assumption that all dimensions have the same common support [0, T], which is not the case for the spatial-temporal processes considered in this paper. How is this issue addressed?\n\nFor the proposed method, the most difficult task should be to determine the value of hyper-parameters M and h. If M is too large, it can easily lead to overfitting. If M is too small, there will be a large bias in the estimated intensity functions. Please provide more details on how cross-validation is performed to choose an optimal combination of h and M.\n\nAnother difficult task with the proposed method is how to justify the use of lower-dimensional approximation. For example, is it justifiable to assume that there is no need to consider the spatial and temporal interaction in a spatial-temporal point process? In GAM, one can do this by performing an analysis of variance (ANOVA), see, e.g., section 5.6.3 of [1]. Could this be done with the proposed approach?\n\nMinor points: \n1. In the motivating example, the time coordinate is the day of the week, which is discrete. Such an example is not coherent with the definition of the Poisson process, which should be with continuous coordinates.\n2.  in equation (6), should it be $t_i^{(I)}$ instead of $t^{(I)}$ inside the function f_{I}?\n\nReference:\n\n[1]. Wood, S.N., 2017. Generalized additive models: an introduction with R. CRC Press. (2nd Edition)",
            "summary_of_the_review": "I think the paper is well written, but I do not see the methodology proposed to be better than the existing ones. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper considers the problem of estimating the intensity function of a multi-dimensional Poisson process. Inspired by the generalized additive model, the authors propose a certain non-parametric form for the log-likelihood of the intensity function, involving multiple functions of groups of dimensions. Further, the higher-order interactions among the dimensions of the Poisson process are restricted to be within a small order k, so only functions of up to k of the dimensions are considered. Considering lower-order interactions naturally leads to a partial order, and hence the authors propose a log-linear model. For each element in the discretized state space, there is a parameter to be estimated. In turn, searching for the parameters amounts to solving a KL divergence minimization problem, which can be solved using convex optimization. Experiments on synthetic data as well as real data (New York taxis) are included. The experiments investigate the performance of the new approach, compared with three existing methods from the literature.",
            "main_review": "•\tThe idea of restricting your model to lower-order interactions is well-motivated and flexible. \n\n•\tThe paper is well written (I only found one typo!). \n\n•\tIn synthetic data experiments, why not compare \\lambda with the estimators directly? \n\n•\tIn Figure 2 (a), why does it read \\eta = \\hat{\\eta}? I thought the purpose of the figure was to show that the parameters for order-3 or -4 interactions were set to zero?\n\n•\tCould you please give a real-life example of a four-dimensional (or higher) Poisson process? It seems to me like most real-life examples are at most three-dimensional.\n\n•\tYou said that KDE is too slow for d >= 4. How does it do for d = 3?\n\n•\tHow was the bandwidth chosen in the taxi experiment?\n\n•\tI like how you related the GAM to your estimation problem. It is helpful to include the Kolmogorov-Arnold representation theorem to explain how the restricted functional form is qualitatively approximating the form given in Theorem 1. However, given that this relationship is not quantified, statements like “Based on the Kolmogorov-Arnold representation theorem, generalized additive models …” (pg 4) should be scaled back. There is a similar statement in the conclusion.\n\n•\tFrom Figure 3, one could argue that KDE is a better method than APP for two-dimensional processes, despite its sensitivity to the kernel bandwidth.\n\n•\tIn Figure 4, I can’t tell which method has the best performance. It would be helpful to give a numeric comparison, perhaps some norm of \\lambda - \\hat{\\lambda}.\n\n•\tPlease define t^{j}.\n\n•\tPlease justify the use of the exponential function in the functional prior on \\lambda(t) in Equation (2).\n\n•\tPlease give some indications of computation time.\n\n•\tTypo on pg. 9: “The third-order method is able to period better”\n",
            "summary_of_the_review": "The idea to decompose the function f into lower-order contributions appears to be novel, and the link to GAM’s is interesting. From the empirical evaluation, I am not convinced that the APP approach is better than existing methods for d = 2, 3, while higher-dimensional applications are not motivated.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a new model, called additive Poisson process, for estimating the intensity of a high dimensional Poisson process. By representing the intensity as a sum of lower dimensional projections, the method can deal with sparse data while allowing for an efficient inference scheme based on the information geometric structure of the distribution space. The assumed intensity form is motivated by the Kolmogorov-Arnold theorem while the estimation procedure has some formal guarantees of convergence.",
            "main_review": "I found the main idea of the paper novel and interesting. I believe the paper is well written and easy to read even for someone not familiar with information geometry. I particularly appreciated the theoretical guarantees that come with this model and inference scheme. The experimental section is extensive but could be improved (see comments below). Addressing the following comments could help clarify the benefits and contributions of the proposed approach:\n\n1) It seems to me that the point of this paper is not to model multiple correlated poisson processes but rather to learn the intensity of a single poisson process by “decomposing” it into sub processes over lower dimensional input spaces. Can you confirm this is correct?\n2) The authors speak about general high dimensional input spaces in the introduction also making the example of space-time locations. However, the input definition is not clear in Section 2. From Section 2, the authors speak only about timestamps where each time step seems to have a D dimensionality. This is confusing. It would be useful to repeat your initial example when you define $\\mathbf{t}_1, …. \\mathbf{t}_N$ to give examples of what these time stamps are. Ultimately it seems to me that you could just call $\\mathbf{x}_i = [x_i^1, …., x_i^{D-1}, t_i ] $ the input vector in a D dimensional space which also includes the time stamp. \n3)Section 2.3. In terms of computational complexity, what is generally the cardinality of $\\mathcal{S}$? Is this not given by the number of terms considered in Eq (6)? In other words the number of lower dimensional projections in Eq 4? If this is the case it does not seem the computational complexity is significantly lower compared to the methods mentioned in Section A.1 in the appendix. \n4) I believe the authors should comment an important approximation introduced when discretising the input space thus getting rid of the intractable integral in the likelihood? There are indeed approaches in the literature that avoid that and despite resorting to variational inference (thus no guarantees) are scalable and seem to be working fine in experimental settings (see [1] and [2] below).\n5) Figure 4. It seems like there is a typo in the captions. For the sparse case N should be 1000? Also it does not seem like the observations are sparse in the two left plots of the second row.   \n6) Experimental comparison. Given the number of approaches existing in the literature and using GP to model the intensity function (and same link function used in Eq (2)) I think the authors should compare the proposed method to one of them (one example could be the LGCP model) especially cause for some of them the approximated inference scheme is fast and stochastic gradient descent method can be used to reduce the computational complexity. In addition there exist out of the box tools that can be used to train such models making it a fast default choice. They would probably fail in sparse settings but I think the paper would significantly benefit from that comparison. \n\n\n**Minor comments**\n1) Just above Eq (6) I believe the authors refer to Eq (3) and not Eq (1)\n2) The figures are very scatters in the paper and I would prefer to have them reorganised in order to have them closer to the point where they are discussed in the text. In addition it would be useful to see Fig 4 together with fig 3 and fig 5 together with fig 6 as they refer to the same experiment. \n\n[1] Aglietti, Virginia, et al. \"Structured variational inference in continuous cox process models.\" arXiv preprint arXiv:1906.03161 (2019).\n\n[2] Lloyd, Chris, et al. \"Latent point process allocation.\" Artificial Intelligence and Statistics. PMLR, 2016.\n",
            "summary_of_the_review": "I found the main idea of the paper novel and interesting. I believe the paper is well written and I particularly appreciated the theoretical guarantees that come with this model and inference scheme. However there are some parts of the paper that are confusing, even in the basic formulation section. Therefore, I believe the paper is borderline and could be significantly improved by clarifying the points above. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper propose to apply generalized additive models (GAM) to learn the intensity of the multi-dimensional Poisson processes (PP). ",
            "main_review": "This approach is interesting but it would deserve more works to further develop the idea. The paper is not motivated and clear enough which leaves the reader perplexed. Here are some remarks: \n\n\n- Several statements in the paper are not well-justified by references, e.g. on KDE in the introduction.\n\n- More details should be added on how GAM approximates the Kolmogorov-Arnold representation and how well it performs. For example, 'based on the K-A representation theorem, GAM are able to learn the intensity of the higher-order interaction between Poisson processes' It would be nice to add references and examples since it is the key of the paper.\n\n- Motivations for introducing APP are not well explained. Background on Poisson Processes are not clear enough and do not give any insight about PP.\n\n- The presentation of APP, in Section 2.2, should be clarified. It is not clear how to match the log-linear model (8) and the intensity defined in Sections 2 and 2.1, e.g. the taxi toy example at the top of page 5 makes things even more confusing. \n\n- I would like to see experiments on the computation time of the approach compared to existing methods as it could be an advantage of this approach.\n\nMinor comments:\n\n- The notation \\mathbf{t}_i in Section 2 is very confusing. \n\n- Figure 2 is cited in the text before Figure 1.\n\n- Section 2.2 The symbol $\\bot$ should be defined before, or just after,  using it. Furthermore,  $\\bot$ denotes the least element in the partial order structure but is used before 'partial order' definition. Also, I think $J$ belongs to $ 2^{|[D]|}$.\n\n- Equation (5) is weird since you basically inverse log-function on equation (4) but the index $k$ disappears and appears again in (6). \n\n- Figures are too small, it is difficult to see anything.\n\n- \"to arrive at\": \"to converge to\"",
            "summary_of_the_review": "The paper is not motivated and clear enough. Furthermore, the proposed approach is empirically poorly studied while no theoretical guarantees are investigated. Several claims are not supported by references or proof.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}