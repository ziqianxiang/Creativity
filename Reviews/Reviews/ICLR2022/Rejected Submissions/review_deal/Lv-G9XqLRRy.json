{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper proposes a technique to efficiently retrain a model when a small number of classes are required to be removed. \nReviewers in general like the paper, but the key issue is motivation for the problem. The motivating examples in the rebuttal are not very good because a. authors do not provide any evidence that such situations are critical or commonplace, b. the data points that are available for retraining might be very biased. \nA more careful grounding of the work would be important to motivate the ICLR community and the ML community in general to further study this problem. But for now, unfortunately the paper does not seem ready for publication at ICLR."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper tackles the problem of restricted class unavailability after a deep learning model has already been trained on such restricted classes and the aim is to remove any information pertaining to the restricted classes from the model parameters so that the model will not be able to correctly classify the restricted classes in the future. The approach presented includes identifying the model parameters that are most relevant to the restricted classes and removing the restricted class information from these parameters (gradient ascent) while ensuring that these parameters can still be used for accurately classifying other non-restricted classes. With the need to correctly assess the utility of the proposed approach, several baseline methods have been proposed. Empirical results on the CIFAR-100 and ImageNet-1K datasets illustrate how the proposed approach can be used. ",
            "main_review": "Positives:\n1. The paper studies an important problem of tackling with restricted classes.\n2. The presented approach displays an ability to remove restricted class information from model parameters.\n\nNegatives:\n1. The paper is not very clearly written, with concepts repeated several times and not clear description on some others that are mentioned below.\n2. While the problem is interesting indeed, the motivation for the proposed solution is not clearly presented. Instead of repeating the ideas, it would be helpful to have a few clear examples that illustrate the need to solve this problem, as well as a clear description of the behavior of the said approach. While an example about the company logo is stated, it would be helpful to have a few more clear examples from real-world settings to help the reader. One such example, a model trained to predict which treatment would be beneficial for the patient would need to be altered if the treatment cannot be offered in the future due to ethical or resource constraints. \n3. While empirical results on the CIFAR-100 and ImageNet-1K datasets seem promising, it would be helpful to study this in the real-world dataset. Issues such as generalizability due to distribution shifts in the future and fairness considerations when certain labels are dropped are potential directions. \n\nAdditional comments:\n1. The notation for the excluded and non-excluded classes is a bit confusing as $C_e, C_r$ can both mean excluded or restricted. I would suggest to change this. ",
            "summary_of_the_review": "The paper studies an important problem. However, there are some challenges with respect to the writing, motivation of the solution and potentially several important directions that can be addressed. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a new learning setting of fine-tuning a pretrained model to forget some specific categories which is motivated by class-level privacy. The solution to this challenge is firstly detecting the most related model parameters that significantly affect model performance on restricted classes and then tuning on a small number of examples with the losses of desired classification capability. The proposed method is experimentally demonstrated effective than possible baselines.",
            "main_review": "This paper proposes a new learning setting of fine-tuning a pretrained model to forget some specific categories which is motivated by class-level privacy. The solution to this challenge is firstly detecting the most related model parameters that significantly affect model performance on restricted classes and then tuning on a small number of examples with the losses of desired classification capability. The proposed method is experimentally demonstrated effective than possible baselines.\n\nI mainly have the following concerns.\n1. The motivation of the new setting is not strong. In introduction, the class-level privacy is specified by violated privacy concerns and corresponding examples. However, they are not quite convincing to me, and I feel more practical instances are needed to clarify the significance of studying class-level privacy. In particular, in what situation there would be only a few training examples available when considering removing information of restricted class from model concerned with privacy? \n\n2. In related work, individual data deletion (Ginart et al 2019) is cited but not properly evaluated. Following the work of data deletion, I feel there also exists an important problem which is ignored. That is, making model forget some examples or some classes does not mean zero classification accuracy or random classification accuracy (i.e., 1/N). In data deletion work, Ginart et al tune the pretrained model by only compensating the impact of deleted samples instead of forcing model have large error on them. As a result, the tuned model turns out to be never seeing the deleted examples. This work obviously cannot guarantee it from the loss shown as Eq. 1. For example, a 3-way classifier on dog, cat, and leopard and leopard is the restricted class. It is predicted a classifier training on dog and cat only would intend classify leopard to cat because of their natural similarity. Thus, a careful clarification about this point is required in this paper, especially from the view of class-privacy.\n\n3. The process of identifying parameters related to restricted classes seems quite empirically, as a transformation component is needed from some prior knowledge. The authors have mentioned it for images. However, many data privacy related data are also tabular. In this case, how to apply a proper transformation? If this component is quite related to data format, any workaround for this issue?\n\n4. From Figure 3, KD is defined for remaining classes only, but the KD loss also includes restricted classes.\n\n5. It is interesting to see the model performance comparison with the original training in term of remaining classes only (also related to concern 2,  the model performance on the original raining data of remaining classes only may be a good reference point for evaluation), although original training data might be inaccessible in the proposed setting. \n",
            "summary_of_the_review": "The paper has a weak motivation for the new setting. The proposed method seems too heuristic and the evaluation for the new setting is not appropriate.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this paper, the authors present a new method to remove information about specific classes from a trained model without reducing the performance of the remaining classes. After the information is removed, the model should not be able to identify the class anymore. Instead of retraining the complete model from scratch without the restricted classes, the presented method only needs a few examples of the restricted classes and the remaining classes. In terms of speed, the presented method is ~200 times faster on ImageNet than a new model training without the restricted classes. Furthermore, they present a method for identifying model parameters that are mainly relevant to the restricted classes. The evaluation of the model is performed on the CIFAR-100, ImageNet-1k, and the CUB-200 dataset. For a detailed comparison, eight baseline methods were designed and evaluated. An ablation study is performed on the class relevant parameters and the number of classes that are excluded. The presented method achieves an accuracy close to the original model on the remaining classes in terms of accuracy. Also, the forgetting prototype accuracy is close to the model trained only on the remaining classes.\n",
            "main_review": "Introduction:\nThe paper is well written, and the evaluation is very detailed. It is an interesting idea to remove class information from the model with a limited amount of data. However, from the description in the paper, it is not clear why this is a real-world problem. It would be beneficial to rate the importance of this application if the authors had provided sources for such cases or a more detailed description of a specific scenario. \n\nMethod:\nThe re-training procedure of the model with only a limited amount of training data is very detailed. The description of the identification of the relevant parameters for the restricted classes is missing some details. For example, it is not defined what other transformation besides the grayscale transformation is used. If other transformations are optional, it would be good to know what type of transformations are used in the experiments. Furthermore, it is not clear how the parameters with the highest gradients are selected. Is a fixed threshold used? What is the minimum number of parameters of each layer that are selected? Is this a fixed number for each class? Does it depend on the number of excluded classes?\n\nEvaluation:\nThe evaluation is very detailed, with eight baseline methods to show the performance of the presented method. However, the results of the FDR model are not shown in Table 1, only mentioned in the text. Is there a reason for this? Adding the results of the FDR to Table 1 would be beneficial. It would be very interesting to see how the parameter selection influences the accuracy of the model. Unfortunately this is not part of the evaluation.\n",
            "summary_of_the_review": "The presented method of re-training a model to forget a specific class is very interesting. However, the part for identifying the most relevant model parameter is missing some essential details. For example, how the parameters are selected (manually or automatic) or the number of selected parameters. This information is essential to understand the method. Moreover, the influence of the parameter selection method is not studied in the evaluation part.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a novel and practical problem called RCRMR-LD, aiming to removel restricted categories from model representations with limited data. They first give some direct solutions and analyze their weaknesses. Then, they propose their own solution to discard the restricted class information from the restricted class relevant parameters. Experiments verify that this approach not only performs similar to FDR but also is faster than it.",
            "main_review": "Pros:\n\n1. The problem RCRMR-LD seems interesting and practical, which addresses the specific class-level restriction by removing corresponding model representations. This setting also save time and computational resource for large scale datasets.\n\n2. Experiments in this paper are solid and convincing enough. They design 5 basic baselines and perform corresponding ablation study. Considering RCRMR-LD is a new problem, if there exists, comparing some related works will be better.\n\n################################################\n\nCons:\n\n1. From my point of view, the transformation $f$ plays a key role in identifying the parameters that are highly relevant to the\nrestricted classes. However, they seem only try the grayscale transformation and do not give more discussion about $f$. If the model is just trained by grayscale images, will this method fail? For natural language tasks, what transformation are you going to use? I suggest that the authors make more discussion and comparison of the various transformations.\n\n2. From Table 1, I find all the FPA$_e$ of ERwP are relatively high, indicating that the feature representations of the model still contain much restricted category information. Although they indeed remove restricted category from class-level, attackers still can use some model inversion techniques (e.g., [1]) to restore the restricted class data with few owned ones, leading to privacy leakage.\n\n3. Identifying those parameters that are relevant to the restricted classes through ERwP is still heuristic. I admit that ERwP seems to make sense, but some verifications about this claim need to be included.\n\n4. Except for \"Related work\", I do not find any references in this paper. At least in the \"Introduction\", you should cite some related works to support your claims.\n\n5. Colloquial expressions and grammar issues are common, thus the writting needs further improvement.\n\n#########################################################\n\nTypo:\n1. \"Baseline 4 - Training of Original model on Limited Non-Restricted Class data with (TOLNRC):\" -- missing words?\n\n2. \"$N_e$ and $N_r$ refer to the number of excluded classes, respectively.\" -- missing words?\n\n and so on...\n\n############################################################\n\nQuestions during rebuttal period:\n\nPlease address and clarify the cons above.\n\n##############################################################\n\nReferences:\n\n[1] Zhang Y, Jia R, Pei H, et al. The secret revealer: Generative model-inversion attacks against deep neural networks. CVPR, 2020.",
            "summary_of_the_review": "The setting proposed by this paper is novel and practical. However, there exists some technical flaws that need to bu further solved.\n\nPlease see the \"Main Review\" for details.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}