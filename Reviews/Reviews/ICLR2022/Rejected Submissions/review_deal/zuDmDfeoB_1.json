{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper compares MAML and NAL for meta-learning, and provides theoretical explanations on some very simple models when MAML can be significantly better than NAL, related to a definition of task hardness. The findings are also supported by experimental results.\nWhile the results are plausible and can mark the starting point of a useful analysis, the models analyzed in the paper are too simplistic to warrant publication at ICLR. The authors are encouraged to extend their methodology to more complicated task models, as well as to, e.g., multi-step versions of MAML (since the considered version of MAML makes a single step, the proposed problem hardness may not be applicable in more general situations). It is also not clear how the derived insights can guide the practical applications of MAML."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper analytically compares the excess risk of two meta-learning methods: MAML and NAL. NAL is the simple baseline where the initialization for optimizing the test tasks is learned as parameter which minimizes the average loss of train tasks. \n\n1. For a particular simple setting of linear regression, authors show that MAML achieves lower excess risk than NAL when (1) there is a considerable difference in hardness of the tasks, and (2) if the true parameter of the hard tasks are closer together relative to the distance between the mean of the hard and easy tasks. \n2. For another case of simple neural network, where the output is the sum of many neurons outputs, authors show that MAML achieves smaller gradient for harder tasks than easier tasks under some condition.\n",
            "main_review": "## Strengths\n1. Gain of MAML over NAL based on the dispersion of hard tasks is interesting. However, I have concerns that the assumptions are too strong (see below).\n2. Experimental comparison of MAML and NAL on real datasets is interesting. Particularly, it is interesting to see that MAML gets smaller error on hard tasks under some conditions from the theoretical results. However, this is not entirely surprising as NAL is never used in practice.\n3. This is also validates the popular notion that MAML is better at adapting to hard tasks than baselines.\n\n## Weaknesses\n1. Sec 3.1: \na. $\\rho_H/\\rho_E(1-\\rho_H/\\rho_E)^2 \\gg d/m$ is a very strong condition, even if $d$ is the effective dimension. This seems like a negative result (not that there is anything wrong with negative results), because when $d/m=o(1)$, each of the tasks may be separately solved using standard linear regression algorithm. For example, in Fig 1(b) with $d=10$ and $m=2000$, it would be interesting to know the average Excess risk of separately solving each of the tasks. This is an important baseline missing from all analysis and the experiments. I hope the authors can provide these in the next revision.\n\nb. It is not clear what the hardness means. Why can’t we use different stepsize for each task during adaptation?\n\nc. Why isn’t the main result collected into a well-defined theorem?\n\nd. It is not clear if the same conclusion holds true when first coordinate of $\\Sigma_i$ is $\\alpha^{-1}$. In that case, for large $m$, $a_H = \\rho_H (1-\\alpha \\rho_H)^2$, $a_E = \\rho_E (1-\\alpha \\rho_E)^2$. \n\ne. The problem considered seems too simple. For example, when the eigenvalues of covaraince matrices are different, or if the eigenvectors of the tasks do not match, the conclusions will differ.\n\n\n2. Sec 4: \na. Thm 1: It is not clear why, when $m=\\infty$, we have to use MAML instead of standard regression. This assumption on $m$ is too strong for the results to be interesting. \n\nb. Interpretation: Since hard tasks have smaller Lipschitz constant than strong convexity of easy tasks, it is not too surprising that the gradient of the hard tasks are smaller than gradient of the easy tasks.\n\nc. Interpretation: How are they the strong convexity and smoothness of the function? This needs to be derived.\n\nd. What happens here when there are multiple tasks? Can we make similar comparison between MAML and NAL then?\n\ne. Fig 4: Specific experimental details are missing. \n\nf. Fig 4: Why does the Thm 1 and Fig 4 use different notion of hardness. In Thm 1, $\\Sigma_i$ are identical, but later $W_i$ controls the hard\n\n3. Sec 5: Current theory seems too simplistic to capture the reality of non-convex MAML. The non-convex experiment shows huge improvement of MAML over NAL, which is expected and known. However, in convex theory and experiments it is not clear whether the simple baseline of separately learning the tasks could be better or comparable to MAML.\n\n4. Overall it is not clear why NAL is the only baseline that is compared with MAML.\n\n## Minor comment\n1. Pg 5, after eqn (8): Value of $a_H$ when settiing $\\alpha$ is wrong.\n2. Fg 2(c): Is $m=500$ or $m=100$?\n3. Fig 1: What are the values of $R$, $r_H$, $r_E$ used?\n4. Sec 4: Is the neural mapping a sum of activations or activation of the sum?\n5. Interpretation: For ease of reading please prove that NAL gradients are the same for hard and easy tasks. \n",
            "summary_of_the_review": "Although the motivation of the paper is valid, it is not clear if the conclusion is interesting due to strong assumptions.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper is about finding the conditions under which MAML outperforms standard multi-task learning. In particular, the authors focus on a linear regression setting and show that MAML outperforms NAL under the following two conditions: (i) there must be some discrepancy in hardness among the tasks, and (ii) the optimal solutions of the hard tasks must be closely packed with the center far from the center of the easy tasks optimal solutions. The authors also give numerical and analytical results in two-layer neural networks.\n",
            "main_review": "MAML is a widely-used meta-learning method that can quickly adapt to new tasks via one or a few stochastic gradient descent steps, so it is interesting and important to understand on which conditions MAML works well, and based on which, it may be further improved. The conditions provided in this paper are well supported by both numerical and analytical results in the linear regression setting. Since, in most scenarios, deep neural networks (DNNs) are used, the conditions would be more practically useful if the authors could provide more experimental results in the case where DNNs are applied.\n\nOne more suggestion: the analysis is based on the ratio of excess risk. It would be more convincing if the authors could explain why this measure is used and what are the other possible measures.\n",
            "summary_of_the_review": "Interesting problem, solid numerical and analytical results in the linear regression setting, need more experimental results in the case where DNNs are used",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper analyzes the performance of MAML algorithm under linear regression setting and compares that with the NAL under the same tasks. The authors show that the excess risk is smaller if there is more discrepency in the hardness of tasks and if the optimal solutions of hard tasks locate close to each other while those for easy tasks are far away. Related analysis and simulation results are also available for two-layer neural networks.",
            "main_review": "**Strengths:**\n- The authors analyze the effect of the hardness of task loss on the solution of MAML algorithm, and suggested situations where MAML gains advantage over NAL.\n- The paper shows that MAML is going to pay more attention to the hard tasks to facilitate the boost of overall performance.\n- The paper shows how the geometry of optimal solutions can have impact the effectiveness of MAML, which is novel\n\n**Weaknesses:**\n- The hardness of tasks is characterized by the eigenvalue of Hessian, which is a local quantity. This notion of task hardness seems to be difficult to generalize to other tasks with rough landscape and varying Hessian.\n- The analysis shows that having the optimal solutions of hard problems packed together would benefit more from MAML, and in practice we do not get to know where are the optimal solutions for each task. The theoretical result does not seem to be able to guide practical applications of MAML effectively.\n- It is not convincing enough why NAL is made into comparison as we do not often use NAL for meta learning.\n\n**Correctness:**\n- There is no false claims to the best of my knowledge.\n\n**Clarity:**\n- The arrangement of the paper is clear and structured.\n\n**Additional Comments:**\n- What are the possible suggestions that this theoretical conclusion could be able to make on applications of MAML tasks, given that the pool of tasks is often determined not by their hardness of each task but their usefulness in practice? Would adding more simple tasks beyond target tasks help the learning?",
            "summary_of_the_review": "The conclusions of this paper are interesting, and some of the analyses come from a novel perspective. However, the contribution of this paper still remains in doubt as it is unclear how the insights can prove to be useful in practical applications.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors aim to compare theoretically and empirically the ability of MAML and Non-Adaptive Learning (NAL) to different tasks in a multi-task setting, where tasks are sampled independently from the same distribution. They argue that MAML is better suitable for adapting to hard tasks, while NAL is unable to do so. Task hardness is measured by the noise of the samples in each task. ",
            "main_review": "# Strengthes \n1. I think the research topic is interesting and valuable. Understanding adaptive learning methods and their relationships/tradeoffs with the tasks/data is important. The topic is certainly relevant to the ICLR audience.\n\n2. The text is clear and I can easily follow the story.\n\n3. The authors provide the code and a comprehensive appendix for reproducibility.\n\n4. I think the analysis of MAML at the beginning of Section 3.1 is interesting. I would be interested to see it extended for multiple tasks, with different degrees of hardness and possibly orthogonal relationships between them (i.e., $w_i$ orthogonal to $w_j$). \n\n# Weaknesses\n1. The setting seems to be a bit oversimplified. I believe that the authors should explain/justify why a linear setting is a useful framework to validate their ideas and to justify their theory. Why wouldn't it fail in a more complicated setting?\n\n2. I suspect there might be an unfair advantage for the MAML model in the demonstrated comparison. It stems from the problem definition described at the beginning of Section 3. In this section, it is mentioned that each task $y_i$ is concentrated around a dot product $\\langle w_{i,\\*},xi\\rangle$, where $w_{i,\\*}$ is some ground-truth parameter associated with the $i$'th task. In addition, the MAML setting allows each task ($i$) to be solved by a function with a different parameter that depends on the data of the specific task. On the other hand, the NAL model does not enjoy the same degree of freedom and all of the tasks share the same solution w that is not dependent on the data of a specific task, rather the aggregation of all data. For instance, in the NAL case, we expect w to converge to their mean (assuming that $\\Sigma_i=I$ for all $i$). In particular, if $w_{i,\\*}$ are very far from each other, then, we do not really learn anything useful. It stems from the fact that NAL tries to model a function $h(x,i)=\\langle w_{i,\\*},x\\rangle$ that depends on the tasks using a function that is not dependent on $i$. \n\nSuggestions: \na. Emphasize why it is a fair/interesting comparison between the two models. \nb. Reconsider the comparison with NAL and compare it with an adaptive method instead. For instance, in a typical transfer/meta-learning setting, we have a function $f:\\mathbb{R}^d\\to \\mathbb{R}^k$ that is shared between the tasks and a specific classifier $g_i:\\mathbb{R}^k\\to\\mathcal{Y}$ for each task individually (e.g., $g_i$=linear). Would it be possible to replace w in the NAL case with a function of the form $\\langle v,Wx\\rangle$, where $W$ is a matrix shared between tasks and v is solved using linear regression on $(Wx_{ij},y_{ij})^{n}_{j=1}$? If so, would the theory change? how?\n\n4. Maybe I am missing something, in the proof of Lemma 1, what are $g_1$ and $g_2$? It seems that only $g_1(w_{MAML})$ and $g_2(w_{MAML})$ are defined but not $g_i(w)$. It makes it very hard to judge the soundness of this proof.\n\n5. The $O(\\alpha^2)$ in Theorem 1 (and Lemma 1) measures the scale w.r.t. alpha. Does it depend also on $\\|w_1\\|$ and $\\|w_2\\|$? If it may depend on these, the argument that $\\|\\nabla f_1(w_1)\\| \\leq \\|\\nabla f_2(w_2)\\|$ could be false. This should be explained.\n\n6. It seems that the task hardness is measured by the variance of the samples in the given task. Why is it referred to as the 'rate at which gradient descent converges to the optimal solution for the task'? I think it should be explained at least intuitively.\n\n7. What does it mean: \"NAL is trained equivalently to MAML with no inner loop\"?\nIn MAML, we have a shared model $f_{w}$ and for each task we adapt w given the corresponding data. \nHow do we compute the predictions for each one of the tasks with NAL?\nSuppose we have two binary classification tasks $T_1$ and $T_2$ that are exactly the same but the labels are switched, how $f_{w}$ handles them? \n\n8. \"The terms ‘Large’ and ‘Small’ describe the hypothesized size of $r_H$ in each experiment: the optimal solutions of hard tasks drawn\nfrom ten (train and test) different alphabets are presumably more dispersed than hard tasks drawn from only two (train and test) similar alphabets. By our previous analysis, we expect MAML to achieve more gain over NAL in the Small $r_H$ setting.\"\nAre there any experiments supporting this statement?\n\n# Clarity/minor comments\n1. \"has large *energy* for easy tasks and small energy for hard tasks\". -- what does energy mean here?\n2. \"after one step of gradient descent *from far away*, which is not true for hard tasks\". -- unclear to me.\n3. Maybe I am missing something, but I am not sure what is $\\| \\dots \\|_{Q^{(m)}_i}$ in (6-7).\nIt seems to be a non-standard notation, which needs to be defined before the statements of (6-7).\n4. What is the difference between $w_{i,\\*}$ in the definition of $y_i$ and $w^*_i$ in (5)?\n5. I think that the term 'geography' might not be the best choice. As far I as know, it is not a standard mathematical term. \n6. What is the inequality in (29) standing for? Is it smaller up to multiplicative constant? If so, why do you need $O(\\alpha)$ instead of $\\alpha$?\n7. Several undefined notations: $\\sigma_{\\min}, \\tilde{\\Omega}, \\tilde{O}$.\n8. In Theorem 2: is there a reason why you chose prob $\\geq 0.96$ instead of a parameter delta as we typically see in standard generalization/concentration bounds? What would be the dependence on such delta?\n",
            "summary_of_the_review": "I believe that the overall direction is interesting and there is room to study which kind of adaptive learning method is better suitable for a different set of tasks (having many similar tasks/multiple hard and multiple easy tasks/etc). In addition, the paper makes an effort for laying some definitions of task hardness and tries to demonstrate different tradeoffs between adaptivity and hardness. \n\nHowever, I believe that the comparison itself is not in the right place and MAML should be compared within a set of adaptive methods. I do not think it is impressive that MAML is more adaptive than the non-adaptive learning method, which does not seem to be practical. I also think that the definition of hardness is a bit oversimplistic (or at least not sufficiently motivated) as it measures the variance of the samples in the task.    ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethical concerns.",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}