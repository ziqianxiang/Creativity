{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper links OOD generalization with adversarial training and argues that adversarial training can help address the problem of OOD generalization. Based on all responses and reviews, there still are novelty concerns in this paper. In the meantime, this paper lacks theoretical justifications. More importantly, DAT only considers very limited situations regarding DG, which also reflects on its experimental results. In the following, I summarize the drawbacks of this paper for the possible revision in the future.\n\n1. It seems not novel to link AT with OOD generalization since two reviewers show some references related to using AT to address DG.\n\n2. From Eq. (9), DAT is based on perturbations rather than transformations. This means that DAT only considers very limited situations regarding DG. In the ordinary DG, source and target domains are from the same meta-distribution, which is clearly a more general case compared to the case considered in this paper. DAT-based AT might mislead the research direction of DG. It would be better to consider smart ways to generate adversarial examples, such as \"Pixeldefend: Leveraging generative models to understand and defend against adversarial examples\" (ICLR2018).\n\n3. Eqs. (7), (8) and (10) are not rigours. It is not convincing to propose a method based on these formulas.\n\n4. The method doesn't show substantial improvements compared to ERM in most tasks (CMNIST dominates the average), which implies the limitations of DAT (see 3).\n\n5. There are no theoretical contributions regarding DG. This paper does not mention the key assumption behind the DAT. For example, DG can be a well-defined problem if source and target domains are from the same meta-distribution. However, this paper does not clarify what assumptions it assumes and does not show how DAT can address DG in theory.\n\nBased on the above drawbacks, I recommend rejection for this paper."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper tackles the problem of out-of-distribution (OOD) generalization of deep learning models with a novel adversarial training formulation (DAT) that introduces a shared adversarial perturbation per training domain. \nThe paper further establishes a connection between DAT, Invariant Risk Minimization (IRM), and standard adversarial training (AT). \nThe authors posit that DAT inherits the advantages of IRM (which is effective for correlation shift while it performs more poorly on diversity shift) and AT, which improves upon Empirical Risk Minimization (ERM) for diversity shift.\nExperiments on several OOD benchmark datasets show that DAT outperforms prior works and ERM on average. ",
            "main_review": "Strengths:\n- The proposed method is novel and an interesting modification/mix of the existing per-sample adversarial training and universal adversarial training (UAT). \n- The connection between IRM and the proposed method is interesting, and the derivation/exposition of the connection is elegant\n- The paper is well written, and the method is well presented\n- The approach outperforms ERM and prior methods on several OOD benchmarks\n\nWeaknesses:\n- The authors claim that adversarial training can handle diversity shift well, but experiments in Table 1 do not support this (AT is worse than ERM in most benchmarks). It is also not easily decipherable if other adversarial methods listed in Table 1 could verify this claim (it might be good to indicate adversarial methods). \n- Given that DAT is a “mix” between AT and UAT, I was missing a comparison to UAT in Table 1\n- The comparison in Table 1 spans only a subset of the datasets used in either Ye et al. (2021) or (Gulrajani & Lopez-Paz, 2021). It would be good to know if the method performs less well on the other tasks or the rationale to limit the comparison to the chosen datasets. \n- I found the experiment in Section 4.2 sounded interesting, but I could not find any results other than Figure 2. Though having some visualization is nice, a quantitative evaluation would be important there.  \n- Although I found the connection to IRM interesting, I was missing insights into why/how the differences in both methods could explain the benefit of DAT. For example, Proposition 1 suggests that IRM is an instance-reweighed version of DAT. It is unclear what the implications of this are on the performance of DAT compared to IRM.",
            "summary_of_the_review": "The paper tackles a vital problem (OOD generalization) with a novel adversarial training approach. The paper also illustrates an interesting connection to Invariant Risk Minimization. The method is supported by good performance on four OOD benchmark datasets, where it outperforms both IRM and standard adversarial training. Additional insights into the benefits of DAT compared to IRM (given the similarity) and a more extensive quantitative evaluation would strengthen the paper. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper explores the relationship between Invariant Risk Minimization and Adversarial Training and proposes Domain-wise Adversarial Training, an adaptation of UAT designed specifically as a data augmentation layer for Domain Generalization settings.\nExperiments on four benchmark datasets suggest that the proposed approach might be beneficial for DG when target domains suffer correlation/diversity shifts.",
            "main_review": "Strengths:\n- The paper is well written and explores the challenging Domain Generalization settings.\n- The paper highlights a relationship between IRM and AT\n- Empirical results show that the method might be better than ERM for Domain Generalization settings.\n\nWeaknesses:\nNovelty.\n- DAT is a trivial adaptation of UAT to DG settings.\n- Furthermore, UAT is not compared to DAT in the experiments. \nEmpirical results.\n- The advantage of the proposed DAT algorithm on diversity shift tasks is minimal compared to ERM.\n- The aggregated performance improvements are mostly due to improvements in the CMNIST task. CMNIST is a synthetic digits dataset whose practical interest could be regarded as inferior compared to images datasets.\n- Lack of results on domain splits. These could have been useful to get an high level insight on which scenarios the method is working best.\n- Related to the above comment: there is no discussion on failure cases. Despite improving over ERM, it is hard to believe that the proposed method is improving in every split. A discussion on the potential downsides could have been as valuable as the method itself.",
            "summary_of_the_review": "Although the inquired relationship between IRM and AT is interesting, the proposed approach is only marginally novel, as it is a simple adaptation of UAT to Domain Generalization settings. UAT acts as data augmentation, so it is not surprising that it is beneficial in DG settings. \n\nFurthermore, I am not convinced by experimental results: there is only a limited insight on favorable scenarios, as domain split results are not presented, and improvements are mostly due do very good performance on a single dataset consisting of synthetic digits.\n\nStill I am looking forward for the authors' response, and I hope that they can address my concerns (see Weaknesses).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper focuses on domain generalization (DG). It proposes a method based on adversarial training (AT): the main idea is learning universal adversarial perturbations at domain level (domain adversarial perturbations, DAT), and rely on those within a standard AT routine. The relation between the proposed DAT and invariant risk minimization (IRM) is provided, and the method is empirically tested on standard domain generalization benchmarks.",
            "main_review": "**Strengths**\n\n- The idea of performing universal adversarial training at domain level for domain generalization is new and interesting. It is reasonable to assume each domains will be biased towards specific nuisances that result in biased classifiers, and I believe that tackling those at domain level instead of dataset or sample level is promising. Results suggest the efficacy of this approach.\n\n- The paper is overall well written and pleasant to read.\n\n- The GradCAM analysis (Figure 3) is very effective, and supports the paper's claims. I would encourage the Authors to include more of those in the supplementary material - they are very informative. \n\n**Weaknesses**\n\n- *Experimental analysis.* The numbers in Table 1 are not from (Gulrajani and Lopez-Paz, ICLR 2021). Such work provides a fair way of reporting consistent, statistically significant results across the literature, and it has been widely accepted by the community. If there is any reason not to use the baselines from this work, it should be explained. Also, more difficult datasets are missing - the most important being DomainBed. Related to Table 1, some bold numbers are not really superior to baseline results in a statistically significant fashion - for example, on NICO and Terra Incognita overall superiority of the proposed method over ERM cannot be claimed.\n\n- *Missing baselines/related work.* (Shankar et al. ICLR 2018) and (Volpi et al. NeurIPS 2018), which are the two main works exploring adversarial training for domain generalization (multi-source and single source, respectively) are not cited. These are the two main references that address AT for DG, and given the nature of the proposed method they should be included in the experimental analysis.\n\n- *Relationship between DAR and IRM.* I cannot understand the connection provided in Section 3.3. While I see the similarity between the two regularizers (Sec. Eq. 10 and 8) - the two are fundamentally different: the DAT one penalizes large gradients wrt to the input, whereas the IRM one penalizes large gradients wrt the classifier parameters. I cannot understand how the two derivatives are compared in Eq. 11 and 13. Can the Authors comment more on this? On a different and more subjective note, I do not believe that an analysis based on a single-sample domain assumption if informative for the paper (Remark 1).\n\n**Clarity/writing:**\n\n- The description of correlation-shift and diversity-shift in my opinion is not clear: a figure and/or a concrete example would help.\n\n- A better reference for AT - when introduced - would be (Goodfellow et al. ICLR 2015), which actually propose it. (Madry et al., ICLR 2018) propose methods to do it more effectively.\n\n- (Gilmer et al., ICML 2019) explore the connection between AT and OOD robustness, opening several questions; (Taori et al., NeurIPS 2020) discuss the impact of AT to OOD robustness in a variety of conditions. These work should be at least mentioned.\n\n- When introducing DRO in the contenxt of AT/DG, (Sinha et al., ICLR 2018) and (Volpi et al., NeurIPS 2018) better fit as references in my opinion, since they indeed propose to use AT for DRO (the former for adversarial robustness, the latter for DG).\n\n- I am assuming that also standard data augmentation is performed, as suggested in (Gulrajani and Lopez-Paz, ICLR 2021). Does it happen after Step 1 in Algorithm 1? This should be clarified.",
            "summary_of_the_review": "I think the idea of treating every domain independently while performing AT for DG is very interesting. It is indeed reasonable to assume that each domain will rely on different nuisances that are not relevant for the task at hand, and removing those at domain level seem to be indeed effective.\n\nYet, I'm not fully convinced by the experimental analysis and the connection with IRM (in order of importance, in my assessment). (Gulrajani and Lopez-Paz, ICLR 2021) provide clear guidelines to compare DG methods in a fair fashion, and this benchmark has been widely accepted in the community (cf. recent works on DG). Since this benchmark is embraced in this submission, I do not understand why Table 1 i) provides worse performing baselines and ii) does not include results related to all the benchmarks.\n\nI look forward reading the Author response and participating in the follow-up discussions.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper investigates whether adversarial training (AT) could be used for extracting domain-invariant features, and whether AT can benefit OOD generalization.  The paper first shows the relationship between AT and IRM (invariant risk minimization).  A new version of AT is proposed -- called \"Domain-wise Adversarial Training (DAT)\"; with IRM being a version of DAT.  Results suggest that DAT can outperform ERM under correlation-shift and diversity shift.",
            "main_review": "# Strengths\n- The paper is (in my knowledge) one of the first to study the connections between methods for adversarial robustness and OOD generalization, whereas previous work has studied the connection between robustness vs in-domain accuracy, and OOD generalization vs in-domain accuracy.\n- The structure and writing is clear (apart from minor grammatical errors) and the main idea of the paper is well stated.\n\n# Weaknesses\n1. The theoretical derivations in Section 3 assume that multiple environments are available for training.  The proposed method (DAT) also relies on this assumption.  While this may be a useful assumption for settings in which multiple environments are indeed available (eg. PACS), it does not hold for benchmarks such as \"DIGITS\" (train on MNIST, test on 4 other datasets) where only a single environment is available (aka single-source domain generalization).  On the other hand, standard adversarial training makes no such assumption. It would be useful if the authors can shed light on whether the connection between IRM and DAT exists for single-source domain generalization. \n2. The introduction and abstract mentions domain-invariant features and distribution shift/OOD generalization.  But the paper only deals with the special case of \"multi-source\" or multi-environment domain generalization.  It is not clear whether DAT (and IRM) would also work for single-source domain generalization.  The theory and empirical results in this paper do not provide any insights into this.  I would recommend making this distinction clear. \n3. The presentation of the experiments and results could be improved substantially.  Critical details about the datasets, which environment/domains are used for training/testing are missing.  This makes it hard to interpret the results.  \n4. Details about other baselines from Table 1 are missing (what type of training do they use, do some of these fall under AT/IRM/ERM?). Why is RSC the best model under diversity-shift? What is the difference between RSC and DAT that could be the reason?\n5. There is little analysis of why DAT is better than IRM on some domains and worse on others.  While the visualizations in Figure 2 and 3 are useful, they are anecdotal and do not provide analysis at scale.\n\n# Questions\n- From Algorithm 1 it seems that N domains , N different values of $\\delta_e$ are updated and stored (one for each domain).  One could also think of adversarial training separately on each domain, thereby obtaining N different values of $\\theta$. These can be ensembled to get a prediction.  How does DAT compare with such an \"ensembling\" of AT applied separately to each domain?\n- From Table 1, it appears that sample-wise AT is worse than ERM for all 4 benchmarks\n    - On CMNIST:  AT < ERM < DAT < IRM\n    - On NICO:  IRM < AT < ERM < DAT\n    - On PACS:  AT < IRM < ERM < DAT\n    - On TerraInc:  IRM < ERM~=AT < DAT\n\n    This means that while the while the comparative relation between IRM and DAT is somewhat clear, that between IRM and AT is mixed.  \n    What is the insight here?  Why is IRM better than AT in some case, and worse in others?\n-  It is stated that colored backgrounds are more realistic than colored digits.  Why is it so?  Why is it more \"realistic\" to have spurious correlations in the background?  For instance, the SVHN digits dataset contains digits with both colored backgrounds and colored content (digits).  Perhaps this additional benchmark could be used to substantiate the statements that hypothesize why DAT < IRM for CMNIST.\n\n# Feedback\n- Footnote 1 is very important, and with the growing number of papers on adversarial robustness, ood generalization, domain shift, etc., it is prudent to point out conflicting/equivalent terminology, as is done by the authors here.\n- Page 1. Paragraph 1. \"carefully designed perturbations\" -- I would advise the authors to distinguish between \n    1. perturbations optimized for each image (i.e. using gradient descent like in Madry et al.) \n    2. universal adversarial perturbations (Moosavi-Dezfooli et al. CVPR 2017 https://arxiv.org/abs/1610.08401 among others) and \n    3. \"common corruptions/perturbations\" (Hendrycks et al. ICLR 2019 https://arxiv.org/abs/1903.12261)\nPerhaps it would be useful to state which of these are designed, and which of these are simply learnt.\n- To add to Strengths #1, although a principled study has not been done to connect robustness and OOD generalization, there are some papers that do use adversarial training (adversarial data augmentation) to improve OOD performance or some aspects of distribution shift. For example:\n    1. Volpi et al. NIPS 2018, https://arxiv.org/abs/1805.12018\n    2. Qiao et al. CVPR 2020, https://arxiv.org/abs/2003.13216 \n    3. Gokhale et al. AAAI 2021, https://arxiv.org/abs/2003.13216 \n- Section 3 uses $\\beta$, $\\phi$ for the classifier, while Algorithm 1 uses $\\theta$ -- please make this consistent.\n- It would be better to show the heatmaps from DAT in Figure 1 (similar to Figure 2).\n\n\n# Minor\n## Terminology\n- This is probably pedantic, but in many places the terminology \"diversity-shift task\" or \"correlation-shift task\" is used.  I believe that this should be changed to \"performance under diversity shift\" or \"image classification task under diversity shift\", since *shift is not a task*, but rather a situation for evaluating robustness/generalization.\n\n## Grammar / Typos\n- Page 1. \"are proposed\" --> \"have been proposed\", \"IRM attracts significant attention\" --> \"IRM has attracted signification attention\"\n- Page 1. Para 3. \"promising\" --> promise\n- many instances of subject-verb agreement errors. please run a grammar check when updating this version.\n\n# Review Summary\nThe paper introduces DAT -- a version of adversarial training specifically designed for training datasets containing multiple environments.  Connections between DAT, AT, IRM are derived formally.  While the motivation and theory behind the paper is sound, empirical results are not conclusive and the paper is lacking in terms of analysis and interpretation of results.  Additionally, it is not clear if DAT would also apply for broader cases of domain generalization where there may not be \"known\" environments (i.e. domain labels are not available) or only a single environment/domain is available for training.\n\nDuring discussions with authors, more empirical evidence was provided and most of my questions were addressed.  I am leaning towards acceptance.\n",
            "summary_of_the_review": "Well motivated idea that derives connections between IRM and AT; experiments are found lacking.\nDuring discussions with authors, more empirical evidence was provided and most of my questions were addressed.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethical concerns to report.",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}