{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper modifies the loss of supervised contrastive (SupCon) learning by adding a self-contrastive loss. Utilizing a multi-exit network and contrasting the multiple outputs of this network, the proposed self-contrastive (SelfCon) learning removes the requirement of additional data augmentation samples for creating positive pairs. The proposed SelfCon loss is theoretically connected to the lower bound of a label conditional mutual information between the intermediate and last feature. The paper focuses its study on SupCon & SelfCon-M, which are multi-batch variates that first augment the images, and then contrast the views between both augmented and non-augmented samples of the same class, and on SupCon-S and SelfCon-S, which are single-batch variates that only contrast between the samples of the same class and do not require additional data augmentations. A wide variety of experiments have been done on CIFAR-10, CIFAR-100, TinyImageNet, ImageNet-100, and ImageNet, but mostly with relatively small networks. \n\nThe ratings for the paper were mixed [3,5,5,8 before rebuttal; 5,5,6,8 after rebuttal]. All four reviewers had provided detailed initial reviews, pointing out a long list of issues. The authors had incorporated these reviews to make a large number of improvements to their initial submission. After the author rebuttal period, while one reviewer raised the score from 5 to 6, two reviewers maintained their negative positions: Reviewer ZiPE is clearly concerned about the risk of accepting a method that may break as soon as a slightly larger model (ResNet50 instead 18) is used, the model is trained a bit longer, or the baselines are tuned, while Reviewer MBzi is unsatisfied with how the paper motivates its empirical construction from the perspective of mutual information maximization. \n\nGiven the disagreements between the reviewers, the AC has carefully read the paper to provide an additional review. Some concerning observations of the AC are summarized as follows:\n\n1. Echoing the concern of Reviewer ZiPE, the performance gain of SelfCon-S over SupCon diminishes in ImageNet with ResNet-18, as shown in Table 13, making it become even more important for the authors to conduct experiments following more standard settings (e.g., ResNet-50 on ImageNet).\n\n2. The main paper seems to suggest SelfCon-S outperforms SelfCon-M and SupCon outperforms SupCon-S, while Table 13 in the Appendix suggests the opposite. \n\n3. Table 3 that compares SelfCon-S with SupCon appears very misleading, as SupCon consumes more memory and computation than SelfCon-S simply because it has used data augmentations. If SupCon-S is used, it would take less memory and computation than SelfCon-S.\n\n4. SelfCon-S adds a subnetwork to the backbone to boost its performance, so technically, it has more parameters than the backbone. Comparing it with a baseline that only uses a backbone model does not seem to be that fair. This point has not been discussed in the paper. \n\n5. Last but not least, echoing the concerns of Reviewer ZiPE and MBzi, the paper seems to try to validate the motivating of the added loss with mutual information maximization.  However, establishing the causal relationship between maximizing the mutual information of the intermediate and last layers and the classification performance needs much more than the correlation analysis provided in the paper. \n\nGiven the above-mentioned concerns, the AC does not consider the paper to be ready for publication at its current stage."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The authors propose an improved algorithm for supervised contrastive learning, which they term “self-contrastive learning”. Instead of only contrasting representations at one point in the network, self-contrasting uses readouts at multiple stages in the network (remapped into an appropriate feature space by an additional readout network). This makes it possible to propose two variants: A “multi-batch” variant that first augments the images, and then contrasts views between samples of the same class, both augmented and non-augmented, and a “single-batch” variant that only contrasts between samples of the same class. Improvements are shown for CIFAR-10,100, TinyImageNet, as well as a smaller version of ImageNet with 100 classes, referenced as ImageNet-100.",
            "main_review": "The paper is mostly well-written and nicely structured. The motivation is clearly outlined, and the discussion of related work is extensive. I liked how the contributions are clearly linked to sections in §1, and the use of color to highlight important parts in the equations throughout the text. A major strength is the possibility of *supervised* contrastive learning without additional augmentations (and I think this could be highlighted more prominently as a strength).\n\nA major shortcoming of the paper is a lack of full ImageNet results, and the small batch sizes considered in the paper. I should note, while the numerous analyses added to the paper are nice, a few well-executed experiments including the “gold standard” models for self supervised learning would have made the paper much stronger (and a clear accept).\n\nI will discuss some additional weaknesses worth addressing / commenting on below.\n\n### Weaknesses\n\nI have the following concerns about the experiments:\n\n* The batch size in the supervised contrastive learning paper was 6144 --- how do you justify the must smaller considered batch size in the paper? How would you rule out that a larger batch size could diminish the gains from your method?\n* The supervised contrastive papers outlines a technique for training with batch size 256 (I think effectively 512 due to the augmentation) on a 8 GPU system 79.1% for full ImageNet. If compute was a limiting factor, could the authors comment why they didnt use this setup? There is also a range of methods (like MoCo and related methods) with momentum buffers or other methods that make it possible train CL models on ImageNet scale on 8 GPU setups.\n* Any reason why Table 3 does not include measurements for full-scale images, i.e., ImageNet-100? For practitioners, this would be by far the most relevant result. \n* Fair comparisons: Why does the result for SupervisedContrastive learning in Table 4 gets worse with a larger batch size? Might this be due to suboptimally tuned hyperparameters (especially the learning rate)?\n\nSome weaknesses about the interpretation of results:\n\n* The paper contains a lot of causal statements about a link between quality of MI estimation and the performance in downstream classification performance. Yet, the only evidence is Figure 2, which is a correlation analysis with a few point estimates. What common confounders could alternatively explain this result, and why did you think that there was no additional need to run more control experiment? What happens e.g. when different hyperparameter setups for Self/SupCon are compared; does the correlation between MI and Test Acc hold?\n* Table 2: Since this is a new dataset (as far as I am aware of), could you minimally provide mean and standard deviations across three seeds? I find it hard to judge the variance and what constitutes progress on this task without seeing CIs; also, were hyperparameters selected fairly between the baseline and the tested CL models? To make this result more stronger, what about evaluating the existing full imagenet trained checkpoints of SupCon and including this as a comparison?\n\nThe method section 3 needs work (but please correct me if I am misinterpreting anything here):\n\n* In Eq. 1, could you verify that $1[F(x_i) \\neq F(x_p)]$ is equal to 1 for all cases, i.e. you included this to make the equation consistent with Eq 2? If this is the case, what was the motivation? Why did you not just use $\\omega \\neq \\omega’$ in Eq 2? Could you please clarify if I am missing something? If I am correct that something is off, I would appreciate it if you could let me know what the revised equations would look like. The same concern applies to Eq. 2.\n* “We dropped the dividing term of sums for brevity” -> Could you clarify and re-write this sentence? I do not get the reference.\n* The notation is incomplete; it should be made clear that $P$ depends on $i$. Suggestions: Call it $P_i$ or $P(i)$. Also, $(i, p) \\in I \\times P$ does not work because of this, it should be $i \\in I, p \\in P_i$ (for example). The same applies to $J$, which contains all images except the anchor. Write this explicitly: $J \\setminus\n \\{i\\}.\n\nA few additional minor points, not sorted by priority:\n\n* Use of barplots: Figure 2 and Figure 3 show barplots with truncated y axis, which is a bad practise. Much better and also more informative is an interaction plot (i.e., just plot a dot, along with an error bar). This is a major concern, because strong results are concluded from these plots.\n* In Figure 2, the different points for NWJ, MINE and InfoNCE should not be connected --- the x axis is categorical, not continuous. Also, a much better of getting the point across would be a scatterplot between MI and Test Accuracy.\n* Figure 6: Do not use the jet colormap. It is widely recognized that it distorts the visual perception of results. Please use viridis (as in Figure 5), or a similar variant with less issues. Especially for the dog images, the results conveyed by the jet map are misleading.\n* Table 1, column “single view”: I would e.g. use checkmarks ✓ instead of the current O/X --- I would rather associate the “X” with “yes” then the “O”. So I suggest to disambiguate this.\n* In the text, you wrote $P = i + B \\mod 2B$ --- while this might be technically correct, I recommend to write $P = (i + B) \\mod 2B$, especially readers with a programming background might be confused on a quick pass through the paper since operator precedence in e.g. Python would interpret the original statement as  $P = i + (B \\mod 2B)$\n* I find the distinction between “single view” and “multi view” a bit misleading / counter-intuitive. Could you comment whether you feel this is a standard term used in popular related work?\n* It would be nice to actually include the image sizes in Table 3, for example after a linebreak in the first column (e.g. “CIFAR-100<linebreak>32x32$)\n* Table 3:\n   * It would be more interesting to show time / step, vs. time / epoch; otherwise you need to adapt for the fact that higher batch sizes mean “shorter epochs” due to less batches / epoch.\n   * Why does the cost per training step go up? Is there an issue with data-loading in the implementation? ",
            "summary_of_the_review": "The paper proposes an interesting addition to supervised contrastive learning, which removes the lack for data augmentations during training and yields improved results. The results look compelling to me, although I generally have the impression that they were executed under a lack of computational ressources (seen, e.g. by relatively small batch sizes although large batch sizes are known to improve performance, lack of multiple seeds for some experiments, etc.), and hence I am worried about the significance of them (how well baselines were tuned, etc.).\n\nThat being said, I am willing to improve the assigned score the paper. To consider an accept, the authors need to minimally show a proof of concept result on ImageNet (for example in a very controlled setup, reproducing the SubContrast result, adding their method and showing an improvement with no special additional tuning, to make the comparison as fair as possible.\n\nAs I see it, the method already works on full-scale images. What is the blocker for running a full scale experiment? Are you confident that the improvements hold on full scale ImageNet training? From the data in the paper right now, it is not clear that the improvement will hold in the regime simCLR-like loss functions are typically evaluated on (large batch sizes, ResNet50 models, full ImageNet).\n\nWithout full ImageNet results, the paper in my opinion does not meet the bar for ICLR, as the one crucial experiment that would contribute to adoption of the method is missing.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposed a contrastive learning framework to remove the requirement for additional data augmentation techniques for creating positive pairs, by leveraging the idea of multi-exit network and conduct \"self-contrasts\" among multiple outputs of the model. Theoretical analysis on the designed loss shows that the proposed SelfCon loss is a lower bound of MI between the intermediate and last feature. Extensive experiments and ablation studies demonstrate that the proposed method has better performance than than the supervised contrastive baseline.",
            "main_review": "Strengths: The paper propose an interesting idea to employ a multi-exit network for conducting contrastive representation learning without using augmentation techniques to create positive pairs. The method has the potential of addressing the various issues of the multi-viewed contrastive learning such as requiring domain knowledge for augmentation and increased memore/computation. Besides, I also appreciate various ablation studies in the experiments and appendix investigating aspects such as gradient norm, the structure/position/number of subnetworks, different encoder structures, etc.\n\nBelow are some of my concerns/questions:\n- There are two versions of the self-contrastive loss, the single-view and multi-view version. In the discussion below Eq (2), the paper defines SelfCon-M loss as exactly Eq (1)? I wonder if this is the best design of the loss since with the multi-exit network (different from previous method that only has one network output), when facing multi-view batch, there could be a similar multi-exit extension for the multi-batch setting and should not be just Eq (1)? Also I think even with multi-exit network, the multi-view setting does not just provide redundant information as inductive bias from data augmentation and inductive bias from encouraging similarity within multiple outputs should be different. Thus I am also confused why SelfCon-M, a \"generalization\" of SelfCon-S with additional information, is mostly worse than SelfCon-S. Is overfitting to each instance the only reason and is there any way to fix it for scenarios where we indeed have prior knowledge for doing augmentation?\n- What is the conclusion for using more than one subnetworks (i.e. multi-exit network instead of just 2-exit network)? It seems the current observation is changing the structure will increase the computation a lot but does not really help?\n- The theoretical analysis is mainly that the proposed loss provides a lower bound for the MI between intermediate features and last features. I think intuitively this is straightforward since if we maximize MI between the two outputs of the network, and the second output totally depends on the intermediate representation, then the intermediate representation has to be closely correlated with the last output such that the second head also contains similar information as the first head. That being said, I think it is still not clear that why such a theoretical result can explain an improved classification performance or better representation learning. A degrade case is, if we put an identity mapping between the intermediate layer and the last output of the backbone, the MI is also very large but it will not help for the downstream task. \n- There are many recent advances in representation learning. For example, BYOL has received a lot of attention for a SOTA performance without using negative pairs. Any discussion and comparison to these methods? Also in section 2.1, BYOL is introduced following \"with negative pairs\", which is not accurate?\n- At the beginning of sec 2.2, \"Mutual information is a measure to quantify the amount of information held in a random variable\" - I think what you are describing is entropy not MI.  MI is a measure of the mutual dependence between two random variables.\n- Overall, I think the method derivation/description (section 3) is hard to follow and not clear enough. An algorithm box may also be helpful. I think the presentation can be significantly improved for better readability. For example, there is no appropriate explanation for the key equations like eq 2 and a formal definition of SelfCon-M. It takes me some time to parse it.\n\n---------------After rebuttal-----------------------  Thanks for the detailed response to my feedback. I appreciate the efforts on updating the paper and I think some of my concerns have been addressed. I thus raised my score to weak accept.",
            "summary_of_the_review": "In summary, I think this paper propose an interesting idea with some potential of improving contrastive learning by removing the requirement of data augmentation. Nevertheless, after reading the paper, I also have a number of concerns/questions on some statements, method derivation, theoretical analysis and empirical evaluation. Overall, I think the presentation can be improved to make it easier to follow.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper provides a new way of supervised contrastive learning which does not require multi-views. The main idea is to use different functions for contrastive pairs which allows the usage of single views in contrastive learning.",
            "main_review": "Strength:\n1. The idea of not using multi-views in contrastive learning is important. Good quality of data augmentation is an issue in contrastive learning.\n2. The authors did a lot of analysis and qualitative experiments to explain their method and motivations.\n\nWeakness:\n1. The main theoretical contribution which is self-con can maximize the mutual information between intermediate and last feature is incorrect. To prove this claim (prop 4.3), the authors use the inequality that $I(F(x), G(x)) \\leq I(F(x), T(x))$. Then the authors claim that the negative self-con loss is a lower bound of $I(F(x), T(x))$. Therefore, minimizing the self-con loss can increase the mutual information between $F(x)$ and $T(x)$. However, the equity may not hold. Especially, in the authors' prop, maximize negative self-con loss can only increase $I(F(x), G(x))$ but not $I(F(x), T(x))$. There is a gap between $I(F(x), G(x))$ and $I(F(x), T(x))$.  Maximizing $I(F(x), G(x))$ does not imply maximizing $I(F(x), T(x))$. \n2. On the other hand, since $F(x)$ is a function of $T(x)$, the mutual information of $I(F(x), T(x))$ is either zero or infinity. (https://stats.stackexchange.com/questions/465056/mutual-information-between-x-and-fx) I am not sure why the authors want to maximize it.\nThe authors somehow shows that the mutual information between the intermediate layer and the last layer is finite in figure. I think this is the problem of the estimation.\n3. In Table 2, why does the authors only report one seed? Multiple seeds are needed. Confidence interval needs to be reported.\n4. In Table 4, why does single view benefits from larger batch size? What about batch size 512?\n5. It seems that you use labels when building self-contrastive learning. If you already use the labels, why do not you compare with fully-supervised approaches? What's the motivation of not using fully-supervised approaches?\n\nMinor:\n1. The usage of \"Markov chain\" in the proof of prop 4.3 may be inaccurate. The arrows should be $F \\leftarrow T \\rightarrow G$.\n\n-----------------------\nUpdates:\nI thank the authors for detailed rebuttal and answer further questions. I increased my overall score from 3 to 5 and empirical novelty from 2 to 3. The authors add results for more batch sizes and explain that they post a new empirical method and not a theoretical understanding. However, in the original paper, the authors explain their method from the prop 3. Prop 3 does not tell the readers more than minimizing the mutual information between $G(x)$ and $F(x)$. I am against motivating the method from an invalid theoretical statement. So I am still against accepting the paper. The followup motivations like distilling good information from last layer to the intermediate layer also sounds vague. The authors may rewrite the paper in a fully empirical way without any vague theoretical motivation.\n",
            "summary_of_the_review": "The authors propose a new method which does not require multiple views in contrastive learning. It has the potential to motivate follow-up works. However, the theoretical motivation seems to be incorrect. The author does not consider the gap in the lower bound. So I vote for rejection. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Recent contrastive learning-based algorithms proposed various ways to make representations from semantically similar (positive) samples closer and those from semantically different (negative) samples farther. While they have shown remarkable performance improvement, they usually require a multi-viewed batch for defining the positive samples. In this paper, the authors proposed Self-Contrastive (SelfCon) Learning which self-contrasts within multiple outputs from the different levels of a multi-exit model. The authors theoretically demonstrated that SelfCon loss guarantees the lower bound of label-conditional mutual information (MI) between the intermediate and the last features. Then, they empirically showed the proposed method significantly outperforms the cross-entropy and Supervised Contrastive Learning (SupCon) baselines.",
            "main_review": "-\tTo the best of my knowledge, this is the first work to propose self-contrastive learning via sub-networks. The paper holds significant methodological contributions and provides both theoretical and empirical grounds to support the effectiveness of the proposed model. While I believe the paper is clearly above the acceptance threshold, I have a few comments to clarify or supplement some points.\n-\tWhile the authors state that SelfCon has also potentials for an unsupervised setting (Appendix D.2.), the current version is still mostly focused on the supervised setting. I think it will be better if it is more clearly stated both in the abstract and introduction.\n-\tIn the 3rd paragraph of the introduction, the authors stated that “the multi-exit framework already generates positive pairs from a single image, making the data augmentation redundant.” However, I think this is not entirely correct considering that SupCon-S outperforms SupCon even without the multi-exit framework (Table 1). Section 5.3 seems to provide more logical explanations that multi-view might cause the overfitting to each instance. \n-\tCan you provide additional explanations for why increasing the lower bound of label-conditional MI between the intermediate and the last features is desirable and improved the classification performance of the encoder network? It might be unclear considering that “good representations should get rid of redundant input information.” (Section 4). In addition, can you also explain why increasing the “influence of T(x)” on the amount of shared information between the last feature and the label? (cf. increasing the MI btw the last feature and the label).\n-\tCan you clarify the meaning of the indicator functions I(F(x_i) != F(x_p)) from the equations? I could not quite understand (1) why the indictor functions contain F or G rather than the labels and (2) why those in the numerators have inequalities rather than equalities. To define the positive pairs as samples with the same ground-truth labels, shouldn’t the indicator functions in the numerators be something like I(y_i == y_p)?\n",
            "summary_of_the_review": "While I believe the paper is clearly above the acceptance threshold, I have a few comments to clarify or supplement some points in terms of the supervised settings, the rationale for increasing the label-conditional MI, and the proposed loss equations. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}