{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper provides an interesting method to address the CTDE problem in MARL. While the experiments are promising, the theory is either insufficient or not rigorous. One of the reviewers believe that there is a flaw in the paper. There was an extensive discussion among the authors and the reviewer. The authors could not convince the reviewer for the apparent flaw."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "In this paper, the authors proposes a novel scheme named ECAQ for learning an explicit credit-assignment scheme for CTDE tasks, which in its theoretical form should converge to the optimal solution and also empirically evaluates the DNN form. The main idea is to use maximizing Q_{total} as a criterion for realizing efficient credit assignment for  for multi-agent joint Q-learning. The authors conducted experiments to demonstrate that the proposed ECAQ technique achieves interpretable credit assignment and superior performance compared to several advanced baselines.",
            "main_review": "Overall speaking, I think this paper is written clearly and easy to follow, and I think it is quite valuable to the research area of Multi-agent Cooperative Learning.\n\nThe authors introduced a simple but very helpful idea of \"explicit credit assignment\" into existing IGM-based joint Q-learning studies, by using maximizing Q_{total} as a criterion for realizing efficient credit assignment. To the best of my knowledge the proposed technique is novel, and the empirical experiment evaluation results appear to be convincing and demonstrate that the proposed method achieve superior performance compared to several advanced SOTA baselines (e.g., WQMIX, DOP). \n\nOn the other hand, although the current experimental results are already somewhat exciting, it would be better and even more convincing if we could see it scaled up (to the extent possible) in the other envs, to make sure the NNs don't break anything at scale. Such scale testing of the proposed approach would be more valuable to understand better the power and limits of the proposed novel method.\n\nMoreover, for better clarity and fair comparison as well as better replicatibility,  it would be good to for the authors to explicitly clarify in the paper how much tuning efforts (e.g., tune the architecture) were spent there to get these results, for the proposed ECAQ method as well as other baseline methods.\n\n\n\n",
            "summary_of_the_review": "Briefly speaking, I think the paper is well-written and easy to follow, and he results seems to be technically solid based on my check. The ideas and contents in the paper seems to be interesting and novel, and the experimental results are also providing some reasonable justification of the values of the proposed new approach.\n\nThere are some minor areas that might be improved about the empirical experiment evaluations part, as described in the main review section, but generally speaking, I think the paper is valuable to the research community of  of Multi-agent Cooperative Learning, and I don't have too much concern about accepting the paper for publication on ICLR.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper studies the credit assignment problem in multi-agent reinforcement learning (MARL), focusing on the centralized training with decentralized executing paradigm. The paper introduces a new MARL method based on value function factorization, and it experimental showcases its benefits over existing approaches. This new method aims to more explicitly account for agents' contributions to the joint performance, and the paper aims to justify its components using a simple theoretical analysis. The core evaluation is experimental, and it is based on standard MARL experimental testbeds from prior work. ",
            "main_review": "Overall, the paper is interesting to read, and it advances the state-of-the-art multi-agent RL literature by introducing a new MARL method that considers a novel form of credit assignment. That said, I have several concerts about the current results and their exposition, listed below together with the strengths of the paper. \n\n**Strengths:**\n\n- *The paper studies an important problem.* It explores one of the fundamental challenges in multi-agent RL, the credit assignment problem, and it contributes novel ideas relevant for making cooperative multi-agent RL more effective. It studies an explicit approach to the multi-agent credit assignment problem, in which agents estimate their contributions to the joint performance. \n\n- *The novel algorithmic approach outperforms baselines in standard multi-agent RL testbeds.* Based on the presented results, the proposed method, ECAQ, seems to outperform baselines from prior work. More specifically, ECAQ's performance is either comparable to or better than recent MARL methods. The proposed MARL design (NN architecture in Figure 1) seems novel. \n\n- *Related work is covered well and the paper explains how its main algorithmic contribution is grounded in theory.* The paper extensively surveys the prior work on the credit assignment problem in  MARL, providing satisfactory explanations for the most important references. It also develops the proposed MARL method by reasoning about the exact solutions to the *explicit* credit assignment problem for simple domains.    \n\n**Weaknesses:** \n\n- *The contributions of the paper are somewhat incremental, while the paper could be considerably improved in terms of presentation.* It is hard to disentangle the core novel ideas that the paper introduces from existing works. While I believe I understood  the main contributions of the paper, I generally found the details hard to follow. In my opinion, the paper is not written very well and it contains quite a few typos. \n\n- *Theoretical results are not rigorous enough.* For example, the proof of Proposition 1 is actually not a formal proof. This is best demonstrated by the sentence: *...it is easy to prove that $Q_{total}$ will also be convex given a specific weighting vector;...*. Generally, some of the theoretical claims look quite informal and/or are not rigorously stated. For example,  in Proposition 2, what does *the same effect* mean? Some of the modeling assumptions are not clearly explained. For example, in Eq. 7, we have that policy parameters $\\theta_i$ are updated based on the policy parameters of other agents, i.e., $\\theta_j$, but this update rule does not seem to be justified in the text.   \n \n- *Experimental results are not clearly explained and look somewhat incomplete.* Regarding the experiments, I've found the main results interesting, but this whole section could be considerably improved. a) There are quite a few formatting issues. For example, the exact meaning of the bold numbers in Table 1 does not seem to be explained, or in Figure 2, x and y axis are barely visible.  b) It is not clear what the baselines selection procedure is for different environments. For example, in Figure 3, the results are obtained for a cooperative environment from Lowe et al. 2017. How does the approach from Lowe et al. 2017 perform compared to the proposed approach? Why are some baselines (QPLEX, WQMIX, LICA, etc.) missing in Figure 3?  c) Some of the  paragraphs in the experimental section are ambiguous. For example, the game from the last paragraph in Section 5.2 is taken from Son et al. 2019. However, the 3 settings mentioned in this paragraph are not clearly explained; perhaps explaining how these results relate to the ones in Son et al 2019 could help. It is also not clear why these results show *the good credit assignment ability* of ECAQ, especially since the discussion is not focused on comparing ECAQ to other approaches. \n",
            "summary_of_the_review": "The paper contains interesting contributions, however its theoretical and experimental results could be improved: formal claims should be more rigorously stated, while experimental results could be expanded. The presentation of the paper could be considerably improved. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper aims to establish an explicit multi-agent credit assignment approach with interpretability.\n\nThe proposed method, Explicit Credit Assignment joint Q-learning (ECAQ), is an end-to-end solution to the designed problem formulation. It can leverage the advanced deep-learning-based implementation of MARL based on CTDE.",
            "main_review": "I believe this paper aims to tackle a fundamental problem for MARL, i.e., the credit assignment problem. However, I find that most discussions and presentations in this paper are rather vague, which is very hard to understand for me.\n\nI have many questions on the main content:\n\n- Eq.(4) is a VDN-like value factorization. Why do the citations refer to QTRAN and QPLEX?\n\n- In Eq.(4), why $Q_{total}\\geq Q_{joint}$?\n\n- The ground-truth objective is $Q_{joint}$. Why do we need to maximize $Q_{total}$ in Eq.(5)?\n\n- I do not understand the constraint $\\sum_{i=1}^N \\alpha_i=1$. When all agents have full observations, the value of $\\alpha$ seems to be a one-hot vector (i.e., a greedy maximization).\n\n- I do not understand why we need to introduce GEM. A trivial maximization solution of Eq.(5) seems to be $Q_i\\equiv\\infty$.\n\n- Given that $\\alpha$ represents an explicit credit assignment, why these values are generated by a VAE? Proposition 2 definitely ignores the reconstruction loss.",
            "summary_of_the_review": "I vote for rejection since I cannot capture the main ideas of the proposed method from the current version. Most presented arguments do not make sense for me.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper tries to tackle the multi-agent credit assignment problem by an explicit method. Specifically, the method is based on individual-global-max criteria for value decomposition methods for MARL, whereby the joint $Q$-value depends on a weighted sum of individual $Q_i$. The method interprets the individual weight $\\alpha_i$ as the \"credit\" (i.e, \"importance\") of agent $i$, then lets each agent $i$ have its own guess $\\alpha^l_i$ of the importance of another agent $l$, then proposes an update rule to achieve consistency among all agents' guesses. This is first formulated for the stateless case, and then extended to the temporal setting with function approximation. Experiments were conducted on the StarCraft micromanagement benchmark and cooperative navigation to show performance versus baselines, and in matrix games to show the dependence of weights $\\alpha$ on payoff asymmetry.",
            "main_review": "My score is completely based on the fact that the proposed method does not optimize credit assignment in any way for the MARL objective. If the authors can convince me otherwise, I would be glad to change my review.\n\nThe paper gives the impression that it aims to do optimal credit assignment. The abstract says \"we formulate an explicit credit assignment problem where each agent gives its suggestion about how to weight individual Q-values to explicitly maximize the joint Q-value,\". This is then formally written as the optimization problem in equation (5), where the weighs $\\alpha$ are supposed to be optimized so as to maximize $Q_{\\text{total}}$. But then, in the proposed solution in equations (6) and (7), the $\\alpha$ update does not depend on any notion of performance. The $\\theta_i$ update depends on $Q$, but the $\\alpha$ updates are not affected by $Q$ at all. Even if the initial set of $\\alpha^l_i$ converge to some consistent values, they are not the \"optimal\" weights since the update rule doesn't explicitly optimize any objective. This discrepancy between the intention of the method and what it actually does is also shown later in writing, where the paper says \"the Consistency Network is proposed to optimize the weighting vectors $[\\alpha_i]_{i=1}^N$ to the same converged value\". Creating a process for a set of values to converge doesn't mean that the process optimizes anything. A possible counterargument is that the updates (6) and (7) causes the \"optimality\" to be contained in the $Q_i$ weights $\\theta_i$ rather than in $\\alpha_i$. But that is not at all explicit.\n\nAnother flaw is that the so-called 'explicit multi-agent credit assignment criterion\" in equation (5) is problematic. Essentially, part of it says: given a fixed functional form of $Q_{\\text{total}}$, which is some function of $\\theta_i$ via the $Q_i$ but not a function of the Markov dynamics (since that is absent in the expressions), find $\\theta_i$ that maximizes $Q_{\\text{total}}$. So one can just choose $\\theta_i = \\pm \\infty$, depending on signs. Perhaps the authors meant to use an RL objective, like the expected cumulative return, but that is not what equation (5) says.\n\nI do like the overall intention to do explicit multi-agent credit assignment. I believe that some adjustments to the approach will make this work suitable for another submission.\n\nMinor points:\n- grammar, e.g. \"Besides, the extracted parameter w is usually lack of interpretability\"\n- \"First, this “decentralized negotiation” will be more robust to the weighting disagreement among agents compared to a centralized weighting mechanism.\" In a centralized weighting scheme, there is no such thing as \"disagreement\", so what is being compared? The decentralized one has non-zero disagreement.\n- equation (9), is the \"L2\" supposed to be the $l_2$ error norm? How is this equivalent to maximizing the first term in equation (8)? Why wasn't the standard VAE reconstruction loss used?\n- The colorbars in the legend in Figure 2 are too thin, I can't distinguish them and match them to the curves easily even at 200% magnification.",
            "summary_of_the_review": "This paper purports to optimize credit assignment for the MARL objective but the method does not do so.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}