{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "Strength\n* The paper is relatively clearly written.\n* A new method is proposed.\n\nWeakness\n* The evaluation is weak.  The experimental setup is not clear enough.  More quantitative evaluation is necessary. There are strong and new baselines that need to be compared with.\n* Relation with existing work needs to be more clearly described.\n* The novelty of the work is limited.  It is a combination of existing methods.\n* Justification of the proposed method needs to be provided.\n* The writing of the paper can be improved."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper focuses on learning document embeddings, presenting a topic-document embedding (TDE) method employing syntactic and semantic properties by jointly learning topic and word embedding in a single framework. The proposed TDE approach follows corruption mechanism to create the global context and randomly select topic-specific word embeddings in learning document vectors, thus employing word, topic and document information in learning document vectors.\n\nThe experimental results have shown improved performed in terms of document classification, topic coherence and word embedding similarity evaluations.",
            "main_review": "Strengths:\n+ introduced a single framework that jointly learns topically-aware word embeddings and document vectors where topic-embeddings are learning using global content and each word embedding can be part of different underlying topics of the document. On top, document vectors are computed by averaging topic word embeddings. \n+ clear problem statement \n+ paper is well written  \n+ sound qualitative evaluation of word embedding visualization \n\nWeaknesses:\n- missing empirical comparison to related works in compositional models [1, 2, 3] of jointly learning topic and word embeddings \n- experimental setup is unclear for document classification task: How is classification task performed? First LM-based objective then using the document representation into classification?  \n- related works section is weak, missing several related works [1, 2, 3]\n- quantitative evaluation is limited (missing key baselines and requires additional data sets in comparative analysis) \n- Document classification is performed on a single (large) data set.  Would be interesting to validate the methodology using at least 2-3 datasets and in sparse data settings. \n- Document classification should be further evaluated on standard data sets for example 20newsgroups, Reuters, TMN, etc.\n- Empirical evaluation is incomplete for document and word embedding evaluation: missing comparison with several strong and most related baselines such as [1, 2, 3] etc. that jointly learns topic and word embeddings\n- please include a case study and/or comparison/differences to related works [1, 2, 3] in terms of:\n\t- jointly learning topic and word embeddings in a single framework \n\t- captures both the syntactic and semantic linguistic structure \n\t- combines both local and global contextual information from word, topic and document\n\t- incorporates both: topic and word embedding spaces in language modeling based training objective (loss function)\n\nQuestions:\n1. Since the Document vector is computed by averaging its word vectors, therefor the averaging scheme may not consider the syntactic structure e.g. word ordering. However, the methods such as [1, 2] employs LSTM to compute document vectors and globsl context considering linguistic structures.\n2. In equation 3, does the global context \\~{x} include w_{i+1} ? Unclear. \n3. In qualitative evaluation of topics, why are the topics of bigram words only? Please also include qualitative topics analysis of unigram words?\n\nMissing references:\n1. Gupta et al., 2019. textTOvec: DEEP CONTEXTUALIZED NEURAL AUTOREGRESSIVE TOPIC MODELS OF LANGUAGE WITH DISTRIBUTED COMPOSITIONAL PRIOR. ICLR 2019.\n2. Lau et al., 2017. Topically driven neural language model.  ACL 2017.\n3. Dieng et al., 2016. TopicRNN: A recurrent neural network with long-range semantic dependency.",
            "summary_of_the_review": "- quantitative evaluation is weak \n- missing related works and quantitative comparison \n- incremental work",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Jointly learning word embeddings and document embeddings while taking into account topical information is somewhat interesting. The paper presents an improved skip-gram model where each individual word is associated with two matrices (e.g., the input projection matrix and the output projection matrix) which is designed to capture the topical aspect of words. In other words, each word is associated with K topic embeddings. While computing the predictive probability, the proposed model further considers a global context, i.e, a document embedding computed with the idea of document corruption. Basically, this paper simply combines the work of Shi et al. 2017 and Chen 2017, Both the innovation and experimental improvement are mariginal.",
            "main_review": "The proposed Skip-gram model contains two major parts that are different from the standard Skip-Gram model:\n\n* One is to assume each word has a different representation under each individual topic. In such a way, the topic assignment of a word can be factored in the computation of the skip-gram probability. In other words, the probability of a context word will depend on not only the centre word but also their topic assignments. However, this idea is from the Skip-gram topical embeddings by Shi et al, 2017. \n\n* The other is the use of a document vector as the global context, which originates from Chen 2017. The proposed model simply injects this context vector into the Skip-gram topical word embedding.  If one compares eq (4) in Shi et al, 2017 and eq (3) of this paper, the only difference is the term $\\frac{1}{T} U_{\\tilde{x}_d}$, constructed similarly to Eq (2) of Chen 2017. This simple modification makes the learning algorithm naturally follow the algorithm design discussed in Section 3.2 of Shi et al, 2017.\n\nThere is nothing wrong with combining the idea of two models together. However, it makes one have doubt about the innovation of this work unless the proposed model is very effective in terms of performance, which is not really the case.\n\nIn regards to the experiments, the proposed model is compared mainly compared with the models in Shi et al, 2017. The experimental methodology follows closely that used by Shi et al, 2017, i.e. document classification, topic coherence, word embedding. The classification performance is only marginally better than STE-same, much worse than STE-diff. Meanwhile, the paper claims that the proposed model is capable of dealing with polysemy, which however is only insufficiently demonstrated by Figures 3 and 4.\n\nThe writing of this paper could be further improved, particularly those notations.\n\nBesides, I have the following questions\n* Should the two project matrices be in $\\mathcal{R}^{k \\times s}$?  If that is the case, most likely, then it column is not a word embedding. I understand if you follow the notation of Chen 2017, then the column should be word embeddings, However, the equations tell us that U has a topic dimension. Let me know if I was wrong.\n* By Eq (4), do the authors mean that the skip-gram probability conditions on both $w_t$ and $\\tilde{x}$? And presumably, the first probability of the left term in Eq (5) is computed based on Eq (3). \n* Eq (1): $\\tilde{x}$ is scalar. The sum in Eq (2) will be scalar, won't it? According to Chen 2017,  Eq(1) will generate a word masking vector for  a document. The masking vector is then used to generate the document representation via averaging. Right?\n\n\n",
            "summary_of_the_review": "As discussed above, the proposed method simply inject the idea of the global context in Chen 2017 into the Skip-gram topical embeddings by Shi et al, 2017, which is very incremental. Even regardless of that, the performance gain of the proposed model is very marginal, even worse than STM-diff. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes Topical Document Embedding, TDE,  to obtain document vectors on during the jointly learning process of the topical word embeddings,\nwhere it captures syntactic and semantic properties by utilizing three levels of knowledge (i.e., word, topic, and document).\nExperiments demonstrate better topical word embeddings using document vector and better document classification results on the obtained document embeddings by the proposed method over the recent related models.",
            "main_review": "strengths\n1) This paper is well written and easy to read.\n2) TDE follows the previous work and aims to learn three different level embeddings.\n3) This paper shows visualization of the interaction between words and latent topics in the embedding space.\n\nweaknesses\n1) Approaches are straightforward and lack originality. This approach is simple combination of  Doc2Vec and STE.\n2) Baselines are old and weak in now.\n3) The experimental results reported are validated on a single dataset,\nand no human evaluation and error analysis.",
            "summary_of_the_review": "Now, the mainstream of representation learning is attention based models or Transformer based models, \nso we would like to see a comparison with these and discussion.\nFor example, we use BERT and then get a similar expression from [CLS] token.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "Yes, Discrimination / bias / fairness concerns"
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "- This paper presents a document-embedding method called Topical Document Embedding (TDE) which utilizes Document Vector through Corruption (Doc2VecC) proposed by (Chen 2017) as the basic framework and combines the idea of Skip-gram Topical word Embedding (STE) proposed by (Shi et al., 2017) for further enhancement.\n\n- The authors claimed that the proposed TDE demonstrates better topical word embeddings using document vector as a global context and better document classification results on the obtained document embeddings.\n",
            "main_review": "- The proposed TDE method is just a simple mix of the ideas of Doc2VecC proposed by (Chen 2017) and STE proposed by (Shi et al., 2017). \n\n- Although the paper clearly explains the motivation and the related work section has a good collection of references on conventional word embeddings and document embeddings, most references (including two baselines) are publications of 4 or 5 years ago and completely misses recent major progresses of contextual sentence/document embeddings since ELMO and BERT.\n\n- What's the advantage of the proposed TDE over the recent contextual embedding methods for representation of sentences and documents? \n\n-  Both Doc2VecC (Chen 2017) and STE (Shi et al., 2017) conducted extensive experiments on the quality of the embeddings and performance on the downstream application of document classification. But this paper only presents very limited experiments and is lack of clear interpretation of experimental results. For example, there are only 2 base lines (STE and Doc2VecC) studied in the experiments, but why STE is still missing Table 1, and Doc2VecC is missing in Table 5? What's the key observations and insights from Table 4?\n\n- It seems there is lack of basic check and proof reading\n    - Typos: for example, \"Tow popular complementary\" in Page 1 and \"flowing objectives\" in Page 1\n    - error on major equation: for example: I guess “d/1-q” should be \"x_d/1-q\" in equation (1) \n    - Missing definition: for example, \"PV\" in Page 1 and other pages (I guess \"PV\" means \"paragraph vector\")\n    - Poor Notations and writings, hard to read and follow, for example, section 3.1\n",
            "summary_of_the_review": "In general, this paper has not been carefully checked and well organized, and the experimental evaluations are not solid. This paper needs some major updates for future improvements.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}