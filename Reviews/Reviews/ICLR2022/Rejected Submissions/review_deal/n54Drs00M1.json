{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This work presents a new sentiment representation method with the use of affect control theory and BERT. Reviewers pointed out several major concerns towards the insufficient experiments and results, as well as the lack of ablation studies and related work discussion. I would like to encourage the authors to take into account the comments from reviewers to further improve their work for a stronger version for future submissions."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "In this paper, the authors propose using BERT embedding as an alternative to shallow word embeddings to find affective lexicons and also show that fine-tuning the model achieves state-of-the-art in estimating affective meaning.",
            "main_review": "Strengths and Weakness:\n(1) The authors tackle the problem of extending affective vocabulary through a fine-tuning approach and overcoming the drawbacks of the traditional approach of vocabulary collected from surveys. Results obtained from the paper shows that the fine-tuned model achieves shows a high correlation between the estimated values and affective dictionary values for identities and behavior\n(2) The method is pretty simple for fine-tuning the BERT model and is not explained properly. The authors also provide no information about the parameters used for training which makes it impossible to reproduce the results of the paper. \n(3) The evaluation section is pretty weak and there are no baselines or other approaches that are being compared for this task.\n(4) The data processing and preparing the training and test set to describe an ABO event is unclear and needs to be explained properly.\n(5) The authors make a lot of claims that are unsubstantiated in this paper especially about extending the affective dictionaries. There are no results to demonstrate those. ",
            "summary_of_the_review": "In this paper, the authors fine-tune BERT to find affective lexicons and show high correlations between estimated values and dictionary values. However, the paper is filled with a lot of drawbacks from methodology, style of writing, and results. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": " This paper uses a fine-tuned Bidirectional Encoder Representations from Transformers (BERT) model for finding affective lexicons based on ACT theory.",
            "main_review": "Strengths:\n\nThe idea of using a pre-trained model to  aid in finding a sentiment lexicon based on ACT theory is interesting.\n\nWeaknesses:\n\nThe experimental analysis is clearly insufficient.：\n-The data set used for the experiments was not presented.\n-The parameters involved in the methods, such as learning rate, batch-size, etc., are not described\n- No relevant work of others was cited.\n-The analysis about the experimental results are too superficial.\n\nThe figures and tables of the article obviously need to be redrawn, e.g. Table 2 and Figure 4.\n",
            "summary_of_the_review": "This paper contains too much background knowledge up front, while the experimental part is too little and the analysis is too superficial.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this paper, the authors propose a deep learning architecture to estimate the affective meaning of words in terms of their EPA (Evaluation, Potency, and Activity) scores. Their methodology achieves notable performance improvements over the approaches in the existing literature, and this is due to the contextual embeddings derived from the BERT model.",
            "main_review": "Comments on Methodology:\n\nFirstly, the authors state they use a regression model to finetune the output of their neural network, the details of which are unclear. The authors need to elaborate on how finetuning was done with the model.\n\nSecondly, the methodology suggested in the paper looks relatively straightforward in the following sense:  embeddings from BERT were used in a feed-forward neural network, and certain aspects of this were finetuned.  \n\nFinally, a few gaps that could strengthen the paper quite a bit are left out. For instance, the authors could also compare the model's performance using shallow word embeddings as well as contextual embeddings from advanced transformer-based architectures. They could further include the data preprocessing and implementation details for the experiments in a separate section.\n\nComments on Writing:\n\nThe grammar and sentence structure of many sentences in the paper could be significantly improved. Below, a few grammatical errors and sentences from the paper are listed for reference below.\n\n - Page 3, Line 5: \"following two ones\" should be \"following two\"\n\n - Page 5, Line 8: \"But we have to feet the dataset so that it can understand in which category we are working.\" The context of this sentence is unclear. \n\n - Page 5, Line 10: \"To use BERT as a contextual word-embedding, we should have the following processing.\" \nThe sentence may need rewording (aren't the embeddings derived from the BERT model?). \n\n - Page 7, Line 2: \"In this paper, an approach to make training and test sentences that describe an ABO event.\" This line is incomplete.\n\n - please be consistent in wording (e.g., data-set vs dataset) ",
            "summary_of_the_review": "There are clear gaps in both the proposed ideas and the writing/presentation of results.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a new sentiment representation method by using Affect Control Theory (ACT) and BERT model. Using ACT could capture the social interactions and sentiment changes. The main contribution of this paper is the usage of ACT and the whole process. According to the experimental results, the BERT model shows good performance.",
            "main_review": "This paper proposes a new sentiment representation method by using Affect Control Theory (ACT) and BERT model. Using ACT could capture the social interactions and sentiment changes. The main contribution of this paper is the usage of ACT and the whole process. According to the experimental results, the BERT model shows good performance.\n\n+Ves\n+ The usage of Affect Control Theory is very interesting and the first work.\n+ The paper is a nice effort with visualizations and nice structure. \n\n-Concerns\n\n-The ablation studies and some experiments should be expanded. For instance, changing different numbers of NN layers, adding other word embedding comparative experiments to show the effectiveness of BERT model.\n\n-Many experimental details are insufficient, such as parameters.\n\n-How to use this model to extend affective dictionaries? The authors should add some examples or explain clearly.\n\n-For the input dataset, how to distinguish the different categories of words, like identity or behavior.\n\n-In Method, the authors use One affective dictionary, which dictionary, please give the reference.\n\n-When a word is polysemous, like apple (fruit or company), how to do in this model.\n \nMinor comments: \n\n*The figures are a bit blurry, please replace them with vector diagrams.\n",
            "summary_of_the_review": "The idea is interesting and results show the effectiveness. However, something is not clear and some ablation studies are missing.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}