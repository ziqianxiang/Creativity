{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper investigates the performance of low-precision Stochastic Gradient Langevin Dynamics (SGLD). While similar low-precision techniques have been widely used in optimization, much less is known for Markov Chain Monte Carlo (MCMC) methods. The paper develops a new quantization function to make SGLD suitable for low-precision setups and argues for its use in deep learning. \n\nThe main concerns among the reviewers were related to the paper presentation (separation and comparison between optimization and sampling), comparison to Dalalyan-Karagulyan'19 and overview of this work, technical depth, and numerical experiments. The authors have adequately responded to the reviewers' comments and addressed them to the extent possible. However, there was ultimately not enough support to lead this paper to acceptance.\n\nI find low-precision sampling a worthy topic of study and the contributions of the paper are interesting. The authors are encouraged to revise the paper based on the reviewers' comments, more clearly highlight the contributions, and resubmit."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a low-precision version of SGLD which makes use of low-bit arithmetic. In particular, since low-precision gradient accumulators might lead to divergence of SGLD, the authors propose a new quantization function to preserve the correct variance in each update step. ",
            "main_review": "I think the idea of applying low-precision optimization to SGLD is a direction worth exploring, but the overall presentation of the paper seems to be vague to me. While SGLD is viewed as an optimization algorithm particularly for nonconvex optimization problem which aims to minimize an objective function $U$ (see e.g., Raginsky et al., 2017), Langevin Monte Carlo (LMC), which takes exact the same algorithmic form as SGLD, is intrinsically a sampling algorithm which aims to sample the stationary distribution $\\exp(-U)$. The authors has been mixing up the tasks of optimization and sampling in the theoretical and experimental results, making it hard to understand what the task the proposed algorithm wants to solve. In the theoretical results of this paper, the authors leverage results in Dalalyan and Karagulyan (2019) to provide a (sampling) bound on the Wasserstein distance between the distribution generated by the low-precision SGLD and the target distribution, but compare this with an optimization bound in Yang et al. (2019), which is the distance between the SGD estimation and the optimum. This seems very weird to me since I think these are not comparable. \n\nThen, in the experiments, I think the authors are applying the proposed low-precision SGLD as a training (i.e., optimization) algorithm instead of a sampling algorithm. The metric used (test error) also does not seem to measure the accuracy of the sampled distribution using low-precision SGLD. Thus, because of this ambiguity between applying SGLD as a sampling algorithm versus an optimization (training) algorithm, the current results in this work are quite questionable to me. \n\nSome mathematical statements and notation in this paper are also unclear. In the assumption, the authors did not mention that the third condition is that the function $U$ needs to have a Lipschitz Hessian. Representation of the stochastic gradient of $U$ by $\\nabla\\tilde{U}$ is also weird since you actually did not change the function $U$ to $\\tilde{U}$, but the gradient to a stochastic gradient. A more commonly used notation should be $\\nabla\\widetilde{U}$. Also $\\mu_0$ is not defined in Theorem 1 (and typed as $\\nu_0$ in Theorem 2 which must be a typo). The derivation in Section 4.3 must be wrong as well, since $\\theta_{k+1}$ is a vector-valued random variable, its variance must be matrix-valued. Thus, the bottom part of page 5 is wrong. Also, using $\\theta_{k+1}$ to represent both the updates with and without quantization have been leading to much confusion during my review. \n\n\n---\nRaginsky, Maxim, Alexander Rakhlin, and Matus Telgarsky. \"Non-convex learning via stochastic gradient Langevin dynamics: a nonasymptotic analysis.\" Conference on Learning Theory. PMLR, 2017.\n",
            "summary_of_the_review": "The idea of  applying low-precision optimization to SGLD is a direction worth exploring, but the ambiguity between applying SGLD as a sampling algorithm versus an optimization (training) algorithm in this paper has made the current results in this work quite questionable. Some mathematical statements and notation in this paper are also unclear. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper investigate posterior sampling of weight-quantized neural networks with SGLD. The paper gives the convergence of SGLD under Wasserstein distance with quantized weights and gradients. It also considers the situation when the accumulator is also in low precision, and proposes a variance correction strategy to deal with the additional quantization noise. ",
            "main_review": "Posterior sampling of quantized neural networks is an important problem to study. While the optimization of quantized neural networks are relatively well studied, this paper is the first to consider the sampling of such networks. The technical quality of the is nice. It presents reasonable convergence results for the proposed SGLDLP algorithms. The idea of utilizing the quantization noise for sampling and variance correction makes sense.\n\nIn terms of weakness, I think the assumptions in the paper are worth considering:\n1. the gradient quantizer assumes that we first have a full-precision gradient, and then quantize it, maybe for reducing the communication cost for distributed training. The formulation does not support applications such as mixed precision training, where the gradient itself is computed in an approximate way. Is distributed training the case the authors want to address?\n2. While the convergence result presented in Theorem 1 is good, it relies on a non-converging term relates to Delta_w. It is curious to compare with the following post-training quantization algorithm:\na' generate full precision samples {theta_k} with full-precision SGLD\nb' use the quantized version {Q(theta_k)} as the low-precision samples;\nWe can imagine that the posterior distribution given by this algorithm is also close enough to the true posterior, where the distance is controlled by Delta_w. It would be better if we can show the proposed SGLDLP is better than the post-training quantization algorithm.\n\nPost rebuttal\n====\n\nThanks for addressing my concerns. I am tending to keep my score since I think it is an interesting paper with some novelties, but the novelty is limited, as commented by other reviewers. ",
            "summary_of_the_review": "A novel paper with reasonable techniques. The results might be improved by tightening the assumptions. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper discusses using the stochastic gradient Langevin dynamics with low-precision implementation. The authors present convergence results in Wasserstein distance norm for three implementation cases, which distinguish specific low-precision thresholding schemes and different quantization techniques. The authors also report simulation outcome of proposed low-precision SGLD algorithms and show their convergence in actual application.",
            "main_review": "Strengths:\n- The narrative is fluent and flow of statement is smooth and natural. In general, the writing of the manuscript is well done.\n- The authors have tried their proposed algorithms in multiple classic application scenarios.\n\nWeaknesses:\n- The submission does not appear to be a major contribution to the field, as the main novel point is the analysis of the variance of low-precision gradient estimator.\n\nSpecifics:\n- page 3, section 3.2, paragraph 3, line 3: $l = -2^{W-F-2}$, why the power is $-2$ instead of $-1$ when computing the upper bound of presentable number?\n\n- page 5, section 4.2, the line below the statement of theorem 2: I think theorem 2 does not suggest \"SGLDLP-L diverges from the target distribution\", but instead, it shows the bound becomes loose when stepsize $\\alpha$ decreases. \n\n- page 4 and 5: schemes SGLDLP-F shown in equation (1) and SGLDLP-L shown in equation (2) essentially only differs in whether the noise $\\xi_{k}$ is low-precision thresholded, doesn't it? \n\n- The main theorems are proved with the results from Dalalyan and Karagulyan's work. The author should explicitly cite the specific theorem in [DK19] and explain why the argued variance of low-precision gradient estimator renders the conditions of the cited theorem satisfied and thus the theorem applicable.",
            "summary_of_the_review": "In light of the specifics in the main review, the discussion of low-precision SGLD in this submission is not significant enough and there are some places in the argument that are not clear.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The author proposed a comprehensive study of low-precision Stochastic Gradient Langevin Dynamics (SGLD). They proposed the convergence analysis of low-precision Stochastic Gradient Langevin Dynamics on strongly log-concave distributions.  Motivated by the diverging fact of SGLDLP-L with small stepsizes, they proposed a variance-corrected quantization function to ensure a bounded bias. Empirical experiments based on large-scale DNN examples are evaluated.",
            "main_review": "\n\nPros: the authors conducted some bias analysis for low-precision SGLD based on [Dalalyan and Karagulyan 19]'s result.\n\nCons: \n\n1. **Limited novelty in methodology**: the novelty in terms of methodology is limited and is not very interesting. Simply extending quantization results from SGD to SGLD with further indications is not that interesting. \n\n2. **Limited depth in theory**: the theoretical novelty is limited and has limited depth; although I am very familiar with Dalalyan's work, the authors don't even bother to write down Theorem 4 and the relevant background in  [Dalalyan and Karagulyan 19].\n\n3. **Inconsistencies between experiments and theories**: The experiments are mainly running in non-convex settings, which don't match the theoretical claim in strongly convex scenarios. If I were the authors, I would only run MNIST experiments based on logistic regression; unless I have theoretical results that extend to non-convex settings. Because the theory only claims these contributions in strongly-convex settings. \n\n4. **Incomplete experiments**: Running SGLD for reproducing purely optimization results seems to be not interesting and uncertainty estimations would also be appreciated.",
            "summary_of_the_review": "The paper proposed some analysis for low-precision SGLD but the novelties or depths in terms of methodology and theory are both limited. In addition, the experiments don't match the theoretical analysis and don't have the results for uncertainty estimations, which leads me to suspect why to bother to use SGLD (I believe SGD with fine-tuning parameters can also achieve the claimed results). Based on these evaluations, I tend to reject this paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}