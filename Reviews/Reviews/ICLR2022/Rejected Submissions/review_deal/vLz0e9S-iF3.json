{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper uses quasi-potential theory to analyze the escape behavior of SGD. Although this is a topic of interest to the ML community, the reviewers found a critical issue with the paper, which the authors admit can not be fixed during this submission. I, therefore, do not think there is a need for a longer discussion."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper uses the quasi potential theory to formalize the escape behavior of SGD happening while training a deep neural network. The quasi potential is defined based on the steepness of a trajectory and is the smallest steepness to go from the minimizer to another point. Utilizing this they analyze both continuous and discrete SGD and show that the average exit time for a trajectory of SGD to move out of the neighborhood of minima depends exponentially on the mini-batch size, the sharpness of the minima, the radius of the neighborhood, and the inverse of learning rate. ",
            "main_review": "1- The paper is well written and easy to follow. The experimental results are confirming the theoretical results. \n\n2- The assumptions 2,3 are still strong and unlike the Xi et al 2020 paper, the covariance C(\\theta) depends on the Hess of minimizer and is independent of \\theta.  \n\n3- In Xi et. al 2020 the exit time depends on the inverse of sharpness but in your results, it depends on it directly. How can one explain this discrepancy? \n\n4- The analysis just considers the SGD with fixed step size however in practice we use decreasing step size to train DNNs. What are the challenges of analyzing this scenario? \n\n5- The exit time depends exponentially on the sharpness. Now, if at the minimum \\lamba=0 and we have wide minima then based on your results the trajectory should jump out of that region instantly which contradicts our observation in practice. How can we explain this based on your theoretical results? \n",
            "summary_of_the_review": "The analysis just considers the SGD with fixed step size however in practice we use decreasing step size to train DNNs. What are the challenges of analyzing this scenario? ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper under review gives mean exit time rates in the small step-size limit of SGD under some quadratic approximation of the loss. The analysis rests on standard results of Freindlin -Wentzell large deviation theory.",
            "main_review": "I am not absolutely familiar with the literature of escape time theory for SGD. And, first, I would like to state two important points about this approach: \n - it is not clear for me how it really relates to the explainability of good generalization properties of SGD as stated in the introduction on page 1 in italic center-text. I would have liked more motivation on this fact in the main text. Maybe with some concrete examples that such phenomena exist in practice (escaping bad local minima very fast for example).\n- it is also not clear for me how Assumptions 1 and 2 are good models for what happens in practice. Especially for Assumption 2, for which it has been importantly remarked in S.Wojtowytsch [ https://arxiv.org/abs/2106.02588 ] and Pesme et al. [ https://arxiv.org/abs/2106.09524 ] that the covariance is degenerate near optima and hence cannot be equal to $H^*$ (except if one adds some random noise intentionally in the data set or if one considers the infinite data limit -which is not explained in the article). \n\nI truly understand that these are share problems with already published literature, but still, I am not very convince about these results for the reasons above. \n\nLeaving this discussion on the side, let us now comment a bit more the precise results of the paper under review.\n\nFirst, I have to say that the paper is not very clearly written: for exemple important paragraphs such as the end of the abstract or the exposition of the main contributions are \n fuzzy. It makes the reader confused as it is difficult to know *what results* are going to be proven, *what* is the new contribution of the article, and *why* it is interesting. An archetypal example of this fact is that the authors claim to have developed a \"novel quasi-potential theory that rigorously describes the escape of SGD\": in fact, quasi potential theory is a *theoretical methodology* that helps in exhibiting escape rates, whereas it is often presented as a contribution in itself in the article (even if obviously large deviations is an important theory that should help understanding some of the behavior of SGD).\n\nSecond, it is very troubling that Table 1 offers comparison with some similar studies without explaining precisely the difference in the assumption and/or the results. More importantly, as results of the present article go sometimes in opposite directions with the bounds of Table 1, it is very weird to have almost zero comments on it. Is the bound of the present article in contradiction with the other ones ? stated in a much restricted setting ? only valid in some limit ? For this reason, comparison is, under the current form, almost impossible to make.\n\nThirdly, and maybe more importantly, the content appears to be mathematically not very precise if not sometimes incorrect: a mild example of this fact is that theorems are stated as equality whereas is seems obvious that they are in fact asymptotic first order developments with respect to parameter $\\eta/B$ at the exponential scale (as it is always the case in large deviation theory). Another example is that the well known Hamilton-Jacobi equation Eq (4), is not clearly introduced: no name, no references, no mention of the fact that there is under general assumption no unicity...\n\nFinally, the statements of the theorems are not enough put in perspective with practice and precise SGD dynamics behavior. Do we really see this dynamical phenomenon *during the training of SGD* (and not, as the experiments show, if initialized near a minimum) ?\n\n\n\n ",
            "summary_of_the_review": "To conclude, the results of the presented paper may be of great interest, but under the current form, without any proper mathematical formulation, more rigorous comparison, or further perspectives with SGD behavior, I consider that this paper should be revised before resubmission.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work proposes to use the notion of quasi-potential to analyze the dynamics and escape properties of SGD from local minima. Authors expect to use the quasi-potential theory to obtain a quantitative criteria for the ability of escape from local minima.",
            "main_review": "There is a deep inconsistency while using the quasi-potential theory to study the escape properties of such dynamical processes as SGD. The point is that quasi-potential, or in general the Freidlin-Wentzell type large deviations theory, handles \"large scale\" or \"global\" deviations from equilibrium positions. However, in the computable cases the authors must make assumptions on the local properties of the loss landscape, such as their Assumption 1, which essentially says that the loss function is quadratic. Such quadratic approximations can only hold near the equilibrium point (by Morse theory). Thus at a large scale, explicit analytical calculations based on quasi-potential for quadratic loss landscape is not applicable to the escape from local minima of SGD, since such escape is about the \"far from equilibrium\" situation. There is also an inadequacy of citing references, since very similar approaches and even the same examples of quadratic loss landscape have already been considered in Hu et al (2019). The major reason why the authors of Hu et al (2019) did not formally publish their work, but remains it as a preprint, is somehow mainly due to the same inconsistency issue pointed out here.",
            "summary_of_the_review": "There is a deep inconsistency in the theory proposed in this paper.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}