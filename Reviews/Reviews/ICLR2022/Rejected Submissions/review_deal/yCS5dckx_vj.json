{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper furthers recent work by Tian et al. 2021 to explain how representation learning with non-contrastive self-supervision works. The paper accomplishes this by analyzing a family of algorithms in which DirectPred from Tian et al. (2021) is a special case. Their theoretical analysis is performed with linear networks. Overall, the reviewers questioned the added value relative to Tian et al. 2021, noting that\n\n\"The analysis of DirectSet and DirectCopy succeeds at proving that it can successfully learn a projection matrix onto an invariant feature space subspace, but essentially boils down to a similar approach as DirectPred (albeit more efficient)\"\n\nThe authors in their reply state \"how the representation is related to the data distribution and augmentation process,\" however the relative contribution and why its important isn't transparent."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper provides a new method for self-supervised learning (SSL), called DirectCopy, based on a previous work DirectPred. An important contribution of this work is theoretical analyses on DirectSet($\\alpha$), a theoretical model on linear neural networks that work with arbitrary $\\alpha$. The authors prove that the weight decay coefficient $\\eta$ has the ability to filter out unnecessary features and hence helps learn useful representations. DirectCopy is a special case of DirectSet($\\alpha$) when $\\alpha=1$. The new algorithm does not require to compute the burdensome eigen-decomposition while enjoying similar empirical performance as DirectPred. ",
            "main_review": "\\textbf{Originality & Novelty}: The motivation of the paper is to understand why non-contrastive SSL can learn meaningful representations. The paper does provide a new view point on this question by highlighting the importance of the weight decay coefficient. So far as I know, the analyses and the algorithm is novel. At least the paper is a reasonable improvement over DirectPred. \n\n\\textbf{Strength}: (1) The paper argues that the weight decay coefficient is the key factor that makes ncSSL learns meaningful representations. This argument is very interesting and deserves more investigation in the future. (2) The paper carefully examines nearly all aspects of DirectCopy with experiments.\n\n\\textbf{Weakness}: I think the paper is overall in good shape, with a few minor points: (1) In Fig. 2, even when weight decay is 0, the curves show that some of the eigenvalues are very small after training, and there still exists a 'drop' in the figure, though not as sharp as when weight decay > 0. I wonder why this happens. (2) Basically the analyses are based on SGD. I wonder whether the phenomena will change if other optimizers, like Adam, are used. (3) Another interesting empirical analysis overlooked by the authors is evaluation on more down-stream tasks, like object detection. ",
            "summary_of_the_review": "The paper is solid in both theory and experiments. The argument of this paper that the weight decay coefficient is responsible for learning powerful representations, is valuable and intriguing. To summarize, I recommend acceptance of the paper. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "In this paper, the authors make theoretical progress on understanding non-contrastive self-supervised learning (ncSSL).  ncSSL has previously demonstrated strong empirical performance, even outperforming contrastive learning, but the theory behind it is still unclear.  In this work, the authors build off of prior analysis by [1], and showcase the role weight decay has in learning a desirable representation; it acts as a threshold that discards noisy features with high variance introduced by the data augmentation, and keeps stable features with low variance.  \n\n[1] Tian et al., Understanding Self-Supervised Learning Dynamics without Contrastive Pairs, 2019.",
            "main_review": "Positives:\n- The work highlights the important role weight decay plays in learning a good representation.\n- The work replaces an existing algorithm, DirectPred, with DirectSet and DirectCopy, which has comparable performance while being cheaper and more efficient.\n- This work has strong theoretical proofs that support their arguments.\n\nWhereas the proofs are sound, I struggle with appreciating the intended novelty of this work.  The work performed in this paper seems heavily preoccupied with two parts: 1) analyzing DirectCopy, which seems to be a cousin of a previously proposed algorithm DirectPred, as well as the DirectSet family as a whole, and 2) using DirectCopy to show the importance of weight decay.\n\nThe analysis of DirectSet and DirectCopy succeeds at proving that it can successfully learn a projection matrix onto an invariant feature space subspace, but essentially boils down to a similar approach as DirectPred (albeit more efficient).  Regarding weight decay, explaining its role, as well as that of other hyperparameters, and why they are important for ncSSL has already been previously explored in [1], and specifically for the BYOL model in prior work.\n\n[1] Tian et al., Understanding Self-Supervised Learning Dynamics without Contrastive Pairs, 2019.",
            "summary_of_the_review": "Overall, I appreciate the incremental theoretical analysis the authors supply to try to understand non-contrastive self-supervised techniques.  I believe their work is sound and thorough, but would welcome more novel insights in this direction.  I would therefore recommend a weak rejection.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper attempts to investigate the reasons behind why non-contrastive SSL methods such as BYOL and Sim-Siam do not collapse to trivial solutions, how they learn representations that are related to the data distribution and augmentation process, and how these reduce the sample-complexity of downstream tasks. It heavily draws upon DirectPred (Tian et al) and generalizes the method for directly setting the weights of the predictor network via a parameter that seems to be tied to the strength and distinguishability of the learnt features. \n\nTian et al: https://arxiv.org/abs/2102.06810",
            "main_review": "*Contributions*:\n\nThe authors present a generalized formulation, which they call DirectSet(ꭤ), for setting the weights of the predictor network along the lines of DirectPred (Tian et al) and show that there exists an implicit threshold that governs what features are learnt, based on the weight decay 'η'. They show that for the special case with ꭤ = 1, we can obtain higher top-1 accuracy than BYOL on Imagenet, learn more distinguishable features in polynomial number of samples, and reduce the sample complexity on downstream tasks.\n\n*Strengths*:\n\nThe authors present an interesting take on the evolution of invariant and nuisance features throughout training, and how this is acutely affected by the weight decay. Their findings are also well backed-up by experiments: they demonstrate the performance of their method on three different datasets (STL-10, CIFAR-10/100, and Imagenet) along with ablations of important parameters on STL-10 and CIFAR-10. Overall, the paper is well-structured.\n\n*Weaknesses*:  \n- *Major*: The paper seems to be a derivative of previous work (Tian et al) and hence lacks novelty in my opinion. \n\n*Relevance and impact*:\n\nI think this work presents some interesting analysis with the proposed method DirectSet(ꭤ): how it learns useful features, and reduces sample complexity on downstream tasks, but it is not very clear why it doesn’t collapse to a trivial solution. Moreover, it is unclear how their analysis extends more generally to other non-contrastive SSL methods such as BYOL or Sim-Siam. Based on the above reasoning, in my opinion, the paper doesn’t seem to have a strong impact.\n\n*Comments/Questions*:\n\n1. In the ablation study with varying weight decay, the authors also test out ꭤ = 2, which should learn features that are stronger and more distinguishable (as claimed in section 4). Is this the case? Or do such features not translate to better downstream performance? Why aren’t more cases with ꭤ > 1 explored?\n2. Is there some intuition behind why DirectCopy doesn’t perform as well on CIFAR-100, as seen in Table 1?\n3. The authors mention in Section 6 that whether the nuisance features come back or not is related to the downstream task performance. Why is this the case?\n4. The paper is not well-written and is peppered with multiple typos (including the method being called DirectPred in Theorem 1 instead of DirectSet. Also, the related works section could have been a bit more extensive for better context. Figures can be more informative as well with some labels for the regions demarcated by the basins.\n\n",
            "summary_of_the_review": "I think the paper itself can benefit from clearer writing and some emphasis on how their analysis scales up to explain other non-contrastive SSL methods.\n\nHowever, if I am to evaluate it in a broader context, I think in its current state it lacks novelty to be seen as a standalone piece of work. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper \"Towards demystifying representation learning with non-contrastive self-supervision\" presents and analyzes a family of algorithms, DirectSet(\\alpha), for non-conctrastive self-supervised learning with only positive pairs. The theoretical analysis assumes linear layers, and focuses on a special data distribution assumption, where the input space is separated in two linear subspaces, one invariant under the 'data augmentations', the other being the complement. It is then shown that the proposed algorithm converges to the projection matrix onto the invariant sub-space. Further it is shown theoretically that this has the down-stream advantage reduced sample complexity for learning on this representation. Empirically, it is shown that the method performs on par, or sometimes slightly better, than the previously proposed closely related method DirectPred (Tian et al. 2021). ",
            "main_review": "- the main paper seems correct. Technically it is strongly inspired by the analysis in Tian et al. 2021. In chapter 2 their algorithm is generalized by the additional exponent of the correlation matrix F. From reading the paper it remains a bit elusive why this is done (apart from the nice consequence that for alpha=1 the method is simpler). It would be great to have add an intuition why this was/is done.\n- I see the main contribution of the paper in the analysis of the representation learning on the simple toy data with linear invariant & nuisance spaces, which is nice and novel to my knowledge. This result is not surprising - as all nc-ssl methods are designed to perform exactly this separation. But it's great to have a mathematical analysis on this.\n- the empirical analyses follow the same experiments as in Tian et al. 2021, with comparable results. The results of Section 4.2. on ImageNet should be put into a table (and the best methods bolded). Like this it feels like the results are hidden.\n\n\nMinor Issues.\n- I find the point in the abstract \"why these methods do not collapse to the trivial solutions\" quite strong, as Tiang et al have made quite a good analysis on this. So, I'd suggest to rephrase and focus instead on your contribution (the 2nd point), and refer to this point being already analyzed (instead of having an enumeration).\n- Figure 2: please add X axes labels on the leftmost plots. On the rightmost plots: can the eigenvalues corresponding to eigenvectors in the invariant subspace and the ones from the nuisance subspace be visually separated? Right now, one has to assume, instead of know, that the smaller ones are the nuisance ones.\n- Theorem 2: eps is overloaded, which might be confusing to the reader. It's already been used as the regularization parameter in the description of the algorithm.\n- please check again all verb forms throughout the paper, also singular and plurals are often wrong. Some sentences are very long and could be reduced in length for better readability (a style taste issue of course).",
            "summary_of_the_review": "The paper seems overall technically correct. It presents a nice analysis that illustrates how the representation learning happens in a toy data setting and proposes a slightly more simple algorithm than in previous work. This is great, though not a major step forward (as ssl methods are designed to do this, the results are expected IMHO). Further, the experimental analyses indicate no significant improvements over previous work.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}