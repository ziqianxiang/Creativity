{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper discusses an empirical scaling law in terms of samples needed for pretraining for effective downstream transfer. The reviewers liked the premise but had major concerns with the evaluation and some clarifications about empirical choices made. The paper initially received reviews tending towards rejection. The authors provided a thoughtful rebuttal that addressed some of the questions. The paper was discussed heavily and all the reviewers updated their reviews in the post-rebuttal phase. In conclusion, all reviewers still believed that their concerns regarding empirical evaluation like why evaluate only sim2real transfer, etc. still stand. AC agrees with the reviewers' consensus and encourages the authors to take the feedback into account for future submissions."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper postulates a scaling law for pre-training and transfer learning via fine-tuning. They empirically postulate a law and also theoretically show that in a simpler setting with assumptions, a similar law should hold. The paper is written and experiments are done in a synthetic to real transfer setting. Experiments are done by pre-training on a synthetic dataset made using BlenderProc and transferring to real data ranging classification, object detection and semantic segmentation. They find that parameters of their scaling law can be estimated to find very good fits to empirical error across all the different transfer tasks.",
            "main_review": "Idea/Method\n-----------------\nStudying the existence of a scaling law for syn-to-real as a function of irreducible domain discrepancy error and data size is important and has great practical benefits. A well fit scaling law would help make informed decisions about whether pre-training data needs to be scaled or diversified for downstream performance improvements. The assumptions leading to the inductive scaling law formulation are sound and it empirically fits real transfer errors very well. \n\nI wasn't able to tell why the authors decided to focus only on syn-to-real transfer since the theoretical derivation does not distinguish between real-to-real or syn-to-real transfer. This is a key question that goes completely undiscussed. Were there negative results with real-to-real transfer? Was syn-to-real chosen so pre-training data complexity could be controlled? \n\nExperiments\n-----------------\nOverall, I feel the experiments are minimal to justify the paper's claims\n- In Fig. 1 there is no extrapolation. The curve is fit to all the points shown. A key feature of a useful scaling law is the ability to extrapolate findings. Fig. 5 and Section 4.4. show results with larger pre-training data sizes but it is unclear whether the curves are extrapolated from Fig. 1 or were the result of fitting parameters again to the new data. In both cases, it'd also be good to compare the estimated values on extrapolated points to show whether the fit curve generalizes (and also show how many points are needed to get a good generalizable fit)\n- The authors use different error metrics for different tasks to fit the scaling law. Why does this work? This is especially counterintuitive for object detection, where 1 - mean average precision is used as the error metric. Is there anything beyond empirical justification for why this works?\n- The error rates for all tasks are in the high 80s and 90s. These are significantly far away from the current best syn-to-real generalization results. The irreducible error term C is estimated to be in the high 80s, which is nowhere close to realistic settings that a practitioner would be in. It would be interesting if the authors did one experiment with a more realistic syn-to-real setting, for example doing GTA-V -> ADE20K/Cityscapes semantic segmentation\n- In all cases, the authors use only 1% of real data, so that the effect of pre-training can be shown. This is again an artificial constraint that could be relieved by using more realistic synthetic data (such as GTA-V data), where the effect of pre-training is visible while using much higher % of real data\n\nRelated Work\n-------------------\nRelated work is generally well written. In one part, the authors say, \"Theoretical analysis was also attempted [Hutter, 2021][Bahri et al., 2021]\". It'd be nice to discuss the differences there instead of just mentioning the papers. \n\nDomain Adversarial Learning (https://arxiv.org/abs/1505.07818), a recent follow-up called f-Domain Adversarial Learning (https://arxiv.org/abs/2106.11344) and papers of similar flavour are quite related. They provide bounds on target domain risk as a function of source domain risk and domain discrepancy. They also provide practical algorithms for syn-to-real training. These works are missing in the related work discussion and I believe they warrant a discussion.\n\nWriting\n---------\nOverall, the paper is well written. Minor typos here and there, such as in the 3rd line of the last para of related work. Figure 2. caption is opposite of the figure. ",
            "summary_of_the_review": "Overall, I am positive about this paper. The method is well motivated and justified. I believe the experiments could be much stronger, especially since the experiments with real datasets would still be considered toy experiments due to the choice of pre-training data and % of real data used. It is hard to say whether these results would generalize, but I believe they warrant a discussion by the community.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper describes a scaling law for approximating the number of samples needed for pre-training to reach a certain performance on a downstream task. The experimental protocol evaluates the method by fitting the scaling law's parameters to a set of observation with least squares, though no quantitative evaluation is performed.",
            "main_review": "Strengths:\n- The paper explores an interesting relationship between pre-training dataset size and final accuracy on a downstream task after finetuning.\n\nWeaknesses:\n- The scaling law is derived by empirical observation.\n- The fine-tuning dataset size is kept fixed in all experiments. This is, in my opinion, an oversimplification of the scaling law.\n- The paper provides is no measurable quantitative evaluation of its results. The plots just show that the predicted points are \"close\" to the fitted line. How will the method compare with a different scaling law if these results are not provided?\n- Applicability might be limited due to the possibility of just increasing the synthetic training set size until desired performances are reached.\n\nOther:\n- Figure 2 is not a log-log plot, as stated in sec. 3.1.",
            "summary_of_the_review": "The paper tries to answer an interesting question (though practical interest might be limited) in estimating the number of samples needed for pre-training, however there are many simplifications (as also stated by the authors) and the empirical evaluations, on which the claim is based, lack measurable results.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a scaling law for transfer learning that takes into account  the size of both the pretraining and finetuning datasets. They showed the parameters of the scaling law can be  estimated and this can be used to approximate the performance of the model given the amount of pretraining data. The authors experiments are focused on the scenario where the pretranining dataset is synthetically generated.",
            "main_review": "Strenght\n\n- The paper proposes a scaling law for transfer learning that takes into account the size of the pretraining dataset.\n- The experimental analysis is very good and cover very important tasks for the CV community  (e.g.  object detecction, segmentation, normal estimation)\n- The authors provide some justification of the derived law.\n\n> Updated after rebuttal.\n\nWeakness.\n- Major Concern #1. I consider the sim2real aspect of this paper to be a bit overstated. In my understanding, the dervied scaling law can be used in any transfer learning  setting that involves pretraining and finetuning. Why is it limited to sim2real or what does it make it specific to the sim2real scenario? I understand the experiments are conducted with a synthetic source dataset but this shouldnt be the only reason.\n\n>After rebuttal. This concern  remains. I agree of the tremendous importance of the sim2real transfer, but the derivations presented here are not specific to the sim2real scenario. The narrowing of the scope seems still a bit artificial and not necessary. \n\n- Major Concern #2. Several times in the paper the authors refers to the coeficient C as the transfer gap (introduced in sec 3.3 without explanation). It is further mentioned than this is related to the rendering settings (also in sec 3.3). I didnt find anywhere any justification or intuition for this relationship. Just stating that C is the transfer gap seems a bit artifical, same for saying that this is related to the rendering settings. I could imagine two real datasets that are dissimilar (e.g. different camera parameters or black-white vs color) and this C may also be big (no rendering involved).\n\n>After rebuttal. The concern partially remains. I agree that C is induced by the dissimilarity between pre-training and fine-tuning tasks, but attributing that to the rendering setting without further justification is not proper. There are many component that may be having a role in what  “ dissimilarity between pre-training and fine-tuning tasks” is. Without further justification, the claim seems very abstract.   \n\n- I am not completely sure what can we get from section 3.2 and Theorem 1 since the law was empirically determined, and again, in my understanding, nothing in this section is specific to the sim2real scenario.  Is there anything we can use from this theorem to justify C is the transfer gap and it is related to the rendering settings? This section is also introduced in a very fast mode with most of the material defer to the suppl. It also introduces a lot of notation in a very fast pace that could be confusing. I recommend the authors to explain better the connection between this and eq (2). Particularly with respect to the exponents \\alpha and \\beta. Is there anything else that we can get out of this theorem which was not  obtained experimentally? I also recomend the authors to add a regression task to their experimental setting since this is the one used to motivate this section.\n\n> After rebuttal. This concern remains, I agree it is not trivial, but  in my opinion this is required to claim the connection between this section and the sim2real scenario. The paper title reads \"A Scaling Law for Syn-to-Real Transfer\" and this section goal seems to theoretically suport this claim, however,  in my understanding, nothing in this section is specific to the sim2real scenario. I am still not getting much  from section 3.2 and Theorem 1. \n\n- More intuition on the exponents on the derived law (eq 2) should be provided \\alpha, \\betta \\delta. We know that they are coeficient for sure, and that they are bounded below, but what are the pretraining and finetuning rates? What's the intuitive and/or theoretical interpretation of them?\n> After rebuttal. Solved.\n\n- I think the paper will also benefit from more discussion in section 3.1. For example, could the authors discussed other choices of g(n), showed the limitation and motivate why the chosen one is the most resonable one. Is there a way to \"strongly connect\" the choice of g(n) to the theoretical results from 3.2? Also will a better parametrization here help with the numerical inestability issues.\n> After rebuttal. Solved.\n\n- Major Concern #3 . I  feel what we can get out of this paper may be a bit limited. The idea of the transfer gap(or disimilarity between the source and target domains) being very important for transfer learning is not new. This has been extensively studied and also shown rigorously and experimental in more general settings. Similarly, it is well known than usually bigger models generalize better.\n\n>After rebuttal. Partially remains. I agree on the importance but my concern is that the main take away here might be a bit limited. We know from before (without having the scaling law) that key for successful  transfer learning is the dissimilarity between source vs target. This is not new. ",
            "summary_of_the_review": "Overall, I consider the paper contains some nice ideas and the experimental analysis to be interesting although  I  feel what we can get out of this paper may be a bit limited. I also believe that presentation of the work should be improved and the work would benefit from a major revision. I also recomend the authors to focus on the more general transfer learning scenario since the narrowing of the scope to a \"sim-to-real scaling law\" may seem a bit artificial.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}