{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper addresses open-set DA, where samples from novel classes in the target domain get clustered \ninto new (unlabeled) classes. A key novelty in the learning setup is that it is assumed that one \nhas access to a knowledge graph over classes (both source and target). That KG is used for grouping \ntarget samples into novel classes. \n\nReviewers were concerned that the method is not explained with sufficient \ndetails and the experiments lacked comparisons with openset DA baselines. \nNo rebuttal was submitted. \n\nThe paper cannot be accepted to ICLR."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper formulates a novel problem in open-set domain adaptation and aims to classify the unknown classes in the target domain. This is different from the traditional open-set domain adaptation problem setting. To do this, additional knowledge of inter-class relations are employed and embedded so that knowledge learned from the shared classes can be transferred to the unknown classes.",
            "main_review": "This paper formulates a novel problem by stepping one step further from the open-set domain adaptation to classifying the unknown classes. Overall, the problem is interesting and can be practically useful. However, the work does not seem to be solid enough for a publication in ICLR.\n\nSome of my concerns are as follows:\n\nIn the last sentence of 3.2, the authors claim \"...but also provides mor general classifiers of the known ones.\", is there any empirical evidence for this statement?\n\nIn eq (4) and (5), it is confusing to use t for both the \"boundary\" and the subsript for the target domain. And I don't understand the meaning of eq (4) and (5)\n\nI don't see how the domain adaptation module can align two domains from the objective in eq (10) and (11). L_s make sure the classification accuracy on source-domain known classes, L_adv enables the separation of known and unknown classes in the target domain, and L_GCN learns a mapping from the knowledge graph node v to the classifier weight w. How is the domain adaptation done?\n\nThe knowledge graph should also be mentioned in the problem definition in section 3.1.\n\nI believe the knowledge graph is important for good zero-shot learning, however, this information is not mentioned in the experiments.\n\nExperiments on more datasets would be helpful to validate the benefit of the proposed method.\n\nThere are some language issues to fix, e.g., \"To align the domain gap\" should be \"to bridge the domain gap\" or something else;",
            "summary_of_the_review": "In summary, the paper provides a solution to a practically useful problem but the novelty is limited and the presentation is not clear enough to understand.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "They propose a new setting in open-set domain adaptation, where the goal is to classify known classes into their classes as well as cluster unknown classes well.  A difference from an existing open-set domain adaptation is that it does only require separating unknown instances from known ones whereas this paper aims to cluster unknown instances. For this goal, they propose a model for open set domain adaptation with zero-shot learning on the unknown classes. They combine adversarial learning to align the two domains, and the knowledge graph is introduced to generate the classifiers for the unknown classes with the employment of the graph convolution network (GCN).\nThey provide experiments on digits dataset and show the gain over baselines. ",
            "main_review": "*Strong Points*\n1. Their proposed setting is interesting and realistic. \n2. The idea of using graph structure in the target domain sounds reasonable. \n\n*Weak Points* \n1. Though the high-level idea of leveraging a graph in the target domain sounds reasonable, their description of the method is not clear and not convincing enough. In Eq. 3, it is not clear where $w^{inf}$ comes from. Also, what are $M$ in Eq. 3 and Eq. 1? In addition, in Eq. 3, the objective is just to predict known classifier weights. But, why it is enough to get discriminative features for unknown samples? \n\n2. Where is the attribute $v$ come from? This is missing in both method and experiments section. \n\n3. Their evaluation is not enough to support the validity of their method. First, they perform experiments only on digits dataset, but this is clearly not enough. Second, they are lacking several baselines in open-set domain adaptation utilizing clustering methods such as \"Do We Really Need to Access the Source Data\" and \"Universal Domain Adaptation through Self Supervision\".  ",
            "summary_of_the_review": "Considering the weak points, I recommend rejecting this paper. There are many missing parts in methods and they need more experiments to justify their ideas. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper considers the problem of open-set domain adaptation where the target domain has additional group of unknown classes and domain-shift with source domain. One interesting aspect of the paper is that the method utilizes a Knowledge Graph for zero-shot learning on the unknown classes. Further, the method utilizes an adversarial learning approach to align the source and target domain.",
            "main_review": "\n### Strengths\n\ns1. Knowledge graph for learning classifiers: Unlike prior works, the paper aims at learning the classes present even in unknown bucket by using a zero-shot learning\n\ns2. The paper tackles the open-set domain adaptation by generating classifiers that work well for unknown classes by utilizing Graph learning methods.\n\n-------\n\n### Weaknesses\n\nw1. Motivation for a zero-shot learning and a clarification: Typically, Open-Set Domain-Adaptation focussed on \"rejecting\" unknown classes rather than modeling for the same explicitly [ref 1]. Therefore, these methods are useful in rejecting images even it they are not present in the pre-determined group of unknown classes. There are definitely some interesting use-cases such as incremental learning where the model adapts continually and learns new classes. So, it would be interesting to include some additional motivation for the zero-shot learning (on unknown classes) in real world with domain gap.\n\nw2. Limited novelty of the proposed approach: The domain adaptation module and adversarial training procedure is not novel. This idea has been utilized in several papers. [ref 2, 4 etc.]. For ex, [ref 4] utilized $t$-parameter to separate the unknown classes from source class boundaries. So, the novelty of the paper is limited to utilization of GCN for unknown classes. \n\nw3. Evaluation of the method and comparison against recent methods: The experiments are limited to  evaluation of the method on digits datasets such as MNIST. Although the results are encouraging, more experimental validation would be required across datasets that have richer attribute information (for Knowledge Graph). Further, the authors need to include additional comparisons from recent literature such as STA [ref 1], Inheritable models [ref 5] and closely related works such as [ref 3] (one-shot learning). \n\nw4. Experimental protocol: It would be more interesting to consider an evaluation protocol that shows accuracy of unknown classes both as a \"binary-classification\" problem and \"multi-class classification\" problem. \n\n-----\n\n### Other aspects\n\na1. In my opinion, the paper considers an interesting problem but the idea of using exactly $n_t-n_s$ classes is unreasonable for practical reasons. First, there is already a domain shift among source and target distributions. Second, the target dataset is unlabeled. Therefore, it is hard to anchor out a strong distribution in this scenario. This problem has been addressed in a related work by utilizing prototypical learning [ref 3]. \n\na2. As suggested in the above sections, the evaluation protocol should reflect the efficacy of method and its novel elements. This often requires providing additional metrics that have typically not been considered in literature. \n\na3. Including t-SNE plots would help the reader understand the qualitative performance of the proposed approach for the unknown classes.\n\n-----\n\n### Questions\n\nq1. (Approach - Training strategy) Is there a prescribed way to alternate between the two stages for training the model to gain higher performance? Or is this a heuristic that yields higher performance.\n\nq2. (Experiments - Settings section) How long does the model take to converge? The paper mentions that the model has been trained for 1200 epochs for digits dataset. I wonder if this is practical and if it would scale for larger datasets. \n\nq3. (Experiments - Comparison section) It is not clear what the domain invariance means in the context of feature alignment for unknown classes. \n\n-----\n\n** Minor Typos **\n\nm1. Closed-set domain adaptation and not \"close\"-set.\n\nm2. There are few grammatical errors make the paper little hard  to follow.\n\n----\n\n**References**\n\n[ref 1] Separate to Adapt: Open Set Domain Adaptation via Progressive Separation, CVPR'19\n\n[ref 2] Adversarial Discriminative Domain Adaptation, CVPR'17\n\n[ref 3] Class-Incremental Domain Adaptation, ECCV'20\n\n[ref 4] Open Set Domain Adaptation by Backpropagation, ECCV'18\n\n[ref 5] Towards inheritable models for open-set domain adaptation, CVPR'20",
            "summary_of_the_review": "I have provided the review for the paper in the previous sections. Although, the paper considers an interesting problem setting, more experimental validation would be required to judge its claims. Further, the novelty is limited to application of an already existing ideas. I'm happy to take the discussion with authors in the post-review phase to hear their thoughts. At the moment, the paper is simply not in acceptable state. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}