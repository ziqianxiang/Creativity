{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "Although this paper is on an interesting topic, there is a consensus that this paper is below the bar for acceptance. My advice is to take take criticisms of the reviewers seriously, add the extra experiments, rewrite the paper and then submit it to a different conference. If the authors feel that the reviewers misunderstood their paper, please remember that the level to which they were able to understand it is also a function of how the paper is written."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a user-guided training for CNN to focus more on casual features which are based on human perspective and termed as casually focused convolutional neural network. Human guidance is used to make a rough binary segmentation mask of foreground objects/pixels.  \n\nFor an input image, mask and label are both utilized to compute final loss. Final loss is composed of 1) activation loss which is computed using the binary mask and last convolution layer features and 2) cross-entropy loss which is calculated using predicted probability and class label of the input image. Images for which binary mask is not available, dummy mask is created as all foreground pixel. Two types of networks, all convolutional layers (CFCN-C) and fully-connected classifiers (CFCN-F) are utilized with the proposed methodology.\n\nExperiments are performed on a total of 4 datasets of natural and medical images. Accuracy and visual activations are compared with baseline CNN, GAIN [1], and both CFCN-C and CFCN-F.\n",
            "main_review": "Strength:\n1> The proposed method is very simple to understand and adapt. \n\n2> A small percent of images with binary mask labels can be used to make this work as shown in experiments.\n\n3> The proposed method can be beneficial for application areas such as medical imaging where “why” matters equally as “what”.\n  \nWeakness:\n\n1> Method requires some user intervention which might be possible for simple applications as natural images but not possible without expertise in some applications such as medical. \n\n2> Sometimes relative features are also important such as the correlation between background and foreground. For example, a foreground with a completely irrelevant background does not make sense (a cat flying in outer space).\n\n3> Authors have experimented with near-to-good masks but in reality, masks could be noisy (partially or completely wrong). No study is done.\n\n4> The proposed method is closely related to explainable artificial intelligence (XAI) methods but there is no comparison with XAI method. \n\n5> Authors claim for the proposed method to work better on the small dataset: A small dataset with less number of classes is not very difficult for a model to learn. The model difficulty associated with dataset difficulty such as a high number of classes with a small number of images in each class, intra-class variations, inter-class similarity, etc. are factors of dataset difficulty, not just small dataset. I believe the degraded performance on the Oxford pet dataset is because of dataset difficulty with a large number of classes and similarity between different classes. \n\nComments and suggestions:\n\n1> Authors Could try with soft masks instead of hard binary masks for background relation factor and compare the results.\n\n2> Also some noisy masks ablation studies will be interesting to see. \n\n3> It is not clear from the paper that if all the classes (at least a few images per class) in the dataset have binary masks for training or some classes have zeros masked training. It will be good to see if some classes are left with zero masks, how they perform during testing and how they adapt knowledge from other-classes mask training. \n\n3> Intrinsic XAI models can be good candidates to check model performance and activation/heatmaps for better comparison. \n\n4> Authors should try the proposed method on a difficult dataset such as any fine-grained dataset with a large number of classes (e.g., Stanford-cats, cub-200). However, this is rare in medical imaging which authors claim to be the main objective of the proposed method. Still, it would be better to see the method’s low points (if any in this regard) for clear future use.  \n\n5> It is interesting that how model focus (heatmap) are reduced in the smallest area (which might be responsible for a particular class) irrespective of providing full foreground as binary mask (fig 4 and 5). Any comments on this?  \n\n6> How is proposed method is different from the extension version of GAIN [1] (pixel wise and bbox masks) is not explained anywhere. \n\n[1] Li et al. Guided attention inference network. IEEE TPAMI, 42(12):2996–3010, 2019.\n",
            "summary_of_the_review": "1> Difference between GAIN and the proposed method is not clear. What are the technical improvement over GAIN and how are they working? \n\n2> Experimental section is weak and could be improved as per suggestions. Also, there is no comparison with intrinsic XAI methods. Proper evaluation can make things more clear.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work aims at improving the classification tasks via segmentation learning. The methodology and experiments are problematic. ",
            "main_review": "In this work, the authors design a causally focused CNN framework through human guidance. By utilizing the auxiliary guidance, the proposed method can particularly focus on the information useful for the classification tasks. Extensive experiments on several datasets have indicated the effectiveness of the proposed method.\n\nStrength:\n+ The proposed method can achieve appealing performance compared with normal classification framework without guidance.\n+ Several feature visualization results have been presented to indicate the effective of the proposed method.\n\nWeakness:\n- There lack discussions on the potential guidance which can be used to improve the model performance on learning causal features. It seems that only segmentation masks are introduced in the manuscript.\n- The potential effect of the proposed method is questionable. As introduced in Section 4.3, the coarse mask boundaries are obtained by a simple regression algorithm. However, the region of interest (ROIs) in the images are sometimes hard to segment. For example, segmenting Multiple Sclerosis lesions in brain MRI is challenging, even a well-trained CNN framework cannot always produce accurate segmentation masks. Under this situation, can the proposed framework still work?\n- The overall methodology design lacks novelty. The causally-focus loss in Equation 1 is similar to the Dice loss, which is widely used for medical image segmentation, such as:\nF. Milletari, N. Navab, S.A. Ahmadi, “V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation”, 3DV2016, pp565-571, 2016.\n- For each dataset, there lacks an introduction on the specific classification task, and the data split details.\n- Introducing an auxiliary segmentation task learning might induce computational cost. Given the unstable performance gain in Table 3, it is questionable whether the proposed framework is worthwhile to use in real practice.\n\nQuestions:\n(1) What if replacing the causally-focus loss in Equation 1 with the normal cross-entropy loss and dice loss?\n(2) Compared with the model without the auxiliary segmentation task learning, how much auxiliary computational cost will the proposed method bring?\n",
            "summary_of_the_review": "As discussed in the review comments, I think this manuscript lacks technique novelty, has potential limits to more challenging tasks, and has less practical usages. In addition, the overall manuscript is not clearly written. Therefore, I recommend rejecting the paper.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes to alternate the loss of classification CNNs by adding additional loss term that focuses the model's attention on the object present in the image rather than on the background. To do so, the model is provided with an additional input (a binary mask) that is used to guide the learning of the model. The approach is validated on four datasets showing some benefits in terms of classification performance on small-scale datasets while decreasing the classification performance on larger scale datasets.",
            "main_review": "**General comments:**\n\nThe masking approach is very similar to binary segmentation (e.g. foreground vs background). How well the model would work if the current \"masking loss\" would be substituted by a binary segmentation loss? Such approaches have been extensively studied in the literature, see e.g. https://arxiv.org/pdf/2004.07054.pdf\n\nIt is unclear why the authors decided to use grad-cam given a large body of explainability work (see e.g. https://medium.com/analytics-vidhya/cnns-explainability-papers-review-5ed380577c64)?\n\nThe limitations of Grad-Cam are not discussed either. Is Grad-Cam the best tool to detect causal features?\n\nWould the approach work with multiple objects?\n\nThe limitations to the model are not discussed. Adding discussion of limitations would make the paper stronger.\n\nWould similar approach work with non-CNN based models, e.g. ViT?\n\n\n**Specific comments:**\n\n_Introduction:_\n\n\"... these systems are expected to be justifiable...\" Could the authors clarify this statement? Do the authors mean the decision to be explainable or interpretable? Is it always the case that this expectation is in place for all scenarios discussed in this paragraph?\n\n\"... and often extract features greedily following that principle..\" What do the authors mean by greedily in this context? It is also a bit unclear to which principle the authors are referring to.\n\n\"In order to eliminate the effect of non causal correlations, CNNs need to be trained on huge datasets...\" Could the authors provide a citation for this statement? Can we always remove non causal correlations just by scaling up the dataset?\n\n\"... minimal human guidance.\" Is providing a binary mask really a minimal human guidance? Would it be easier to just provide yes no answers, e.g. is this gradCAM visualization respecting the causal relations for his object?\n\n\n_Methodology:_\n\nFig. 3: It is a bit unclear at which point the binary mask are applied in the CNN pipeline. The figure could be improved by depicting explicitly at which point the multiplication of features with binary mask is performed.\n\nFrom the current description, it is unclear how the model works at inference time. Do we still need binary masks at inference time?\n\nEq. 1 lacks explanation. In particular, why this particular loss is beneficial for the task? Could we design the loss differently? What makes this particular formulation important?\n\n_Experiments:_\n\nIt would be nice to see the effect of how exact the mask has to be in order to notice the described effect, eg. how precisely the object has to be segmented to provide meaningful causal features?\n\nFig. 4: It is interesting to notice that the highlighted features do not capture the whole plane, only some parts of the plane seems to be causally relevant. Adding a discussion on why some pixels are more relevant than others would be beneficial. \n\nTab 3. There is no measure of std or variance.\n\nFig 6. The convergence claim (the modified loss does not affect convergence) is not supported by the plot. To support the claim, the convergence plot of vanilla CNN should be depicted. It would also be nice to state which dataset split has been used to obtain them.\n\nFig 8. It is unclear what AM stands for. This figure also indicates that the ablation was run on the test set, it would be more principled to run all ablations on the validation set.\n",
            "summary_of_the_review": "The paper tackles an interesting problem of making the model more robust to spurios correlations. Although the reviewer finds the problem interesting and relevant for the ICLR community, the reviewer thinks that the paper in its current state is below the acceptance threshold. \nThe methodological contribution is rather minor. The approach requires collections of binary masks that might not be available for all datasets. It is also a bit unclear what the community learns from this paper -- it is expected to have more object centered gradCAM activations by using object binary masks. Moreover, the presentation of the paper could be significantly improved. For details see main review.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}