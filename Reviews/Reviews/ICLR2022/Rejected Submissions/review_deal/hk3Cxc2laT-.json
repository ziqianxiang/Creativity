{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper proposed a cluster-based task-aware meta-learning (CTML) approach with task representation learned from its own learning path. Based on the prior work of feature-based task characterization, it integrates the rehearsed task gradient descent trajectory into task representation, and further improves computational efficiency by learning a different network to estimate the rehearsed task-trajectory characterization from the feature representation. Experiments were conducted on few-shot image classification (meta dataset and miniimagenet) and cold-start recommendation tasks. \n\nReviewers had raised various concerns about the work including technical novelty, the shortcut-tunnel assumption, empirical comparison, scalability issue, more ablations for in-depth analysis, etc. The reviewers and AC appreciate authors for putting good efforts in the rebuttal by replying the review questions carefully and making changes to improve their experiments and paper. \n\nOverall, this paper is a borderline case, where reviewers agree some clear merits (well-written, easy to follow, good execution of an interesting idea with code provided, etc). Despite the improvements during rebuttal, some major concerns on the weaknesses still remain (e.g., technical novelty, more convincing justification on the assumption, significance of empirical gains). Therefore, I cannot recommend it for acceptance at its current form, but I hope to see it accepted in the near future after these issues are fully addressed."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a clustered task-aware meta-learning algorithm. The proposed algorithm firstly collects the learning path and uses the path to train a sequence module. The sequence module output is combined with the task feature. The task feature is derived from the weighted sum of the soft cluster centers. The combination is then used as initialization of the model parameter for task adaptation. Experiments on image classification and cold-start recommendation demonstrate superior performance compared to baseline algorithms.",
            "main_review": "The proposed idea that adopts a learning path to improve the parameter initialization is interesting. Code is provided and experiment results look persuasive.\n\nSome of the critical technical points are not sufficiently justified, e.g.\n(1)\twhy is using the trajectory of rehearsed path helpful to learn a good parameter initialization? \n(2)\tin section 4.2, the reason for modeling task representation is explained as encoding the predictive distribution. But I can't see the connection between them.\n  I would like the author to use several sentences to explain the insights of these points.\n",
            "summary_of_the_review": "The proposed algorithm is interesting and well-supported by experiments. My concerns are that a more intuitive description should be added to make the motivation, rationality, and insight of algorithm design easy to follow.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a meta-learning approach based on MAML but with a task-conditioned initialization, which takes into account both information extracted from the features of the task (support set) data, as well as geometric information from a “rehearsed” learning path (obtained by gradient descent on the support set). The geometric information includes the parameters, loss, gradient and fisher matrix for different steps of the task adaptation process. They propose a GRU architecture to process this information across the different steps, yielding a path embedding. For both the feature and path embeddings, they utilize clustering, motivated by the need to share knowledge across similar tasks. They then combine the path and feature embeddings via an additional neural network to generate the final task-specific initialization. Computing the path embedding requires rehearsing which is computationally expensive (it’s akin to training twice on the task, once for rehearsing, and then training from the task-conditioned initialization). To amend this at inference time, they meta-learn a ‘tunnel’ connection that predicts the path embedding from the feature embedding. At test time, only a forward pass through this meta-learned connection is required instead of rehearsing. They experimentally evaluate their approach on few-shot classification and cold-start recommender problems and show performance gains over similar MAML-based approaches. They also perform ablation studies and analyses to understand the contribution of different parts of this system to downstream performance.",
            "main_review": "Utilizing feature embeddings jointly with path embeddings drawn from several steps of the inner-loop optimization is novel to the best of my knowledge, and an interesting direction. The authors do a good job of motivating the need to consider geometric information from more than just the initialization point. The paper is also nicely written, well organized and for the most part easy to follow. However, I have a few concerns, primarily relating to the placement of this work into the previous literature. More details below.\n\n- Limited comparisons with state-of-the-art methods. The experimental comparisons are only against similar MAML-based meta-learning methods. These are not state-of-the-art for few-shot classification, so considering only these in the table (though indeed they are most relevant to the proposed method) is misleading. In fact, it was recently shown that transfer learning approaches can match or surpass the performance of meta-learning methods [4,5], especially when using larger architectures than a 4-layer-convnet, while also having the advantage of being simpler and more computationally efficient. On mini-ImageNet, according to the results presented in the Appendix, there is a large gap between the proposed approach and recent work e.g. [4], which isn’t included in that table. Despite the nice ideas presented in this paper, the significance of the work is low if the results aren’t comparable with conceptually simpler and computationally more efficient baselines.\n\nRelationship to related work:\n- [1,2] should also be cited in the context of task-conditioned meta-learners (non-MAML-like in this case)\n- It is unfortunate that the authors construct a new collection of datasets and name it Meta-Dataset, since Meta-Dataset is already the name of a few-shot classification benchmark [3] which actually has high overlap with the datasets chosen here. In fact, Meta-Dataset [3] is a good evaluation benchmark for approaches that deal with task heterogeneity like the one proposed here.\n- “Though task-specific methods have been developed to tailor the initialization, they overlook generalization among similar tasks” - I would argue that this isn’t necessarily the case. Approaches that use a network to predict a task encoding, and then condition on that encoding (like Oreshkin et al, and [1], [2], etc) *do* consider relationships between tasks implicitly, since similar tasks are likely to cluster close to each other in the learned task embedding space, even if an explicit clustering objective isn’t employed. I would revise this sentence to more fairly describe previous work.\n\nScalability considerations\n- The architecture considered for few-shot learning is a small 4-layer convnet. Is this method easy to scale up to larger ones like the resnet-12 and resnet-18 that are commonly used more recently [3,4,5]?\n- How many steps of gradient descent were performed in these experiments? It seems that this method would not scale well to large numbers of steps which might be more appropriate for larger support set sizes? The evaluation here is constrained to 1-shot and 5-shot tasks.\n\nAdditional ablation\n- It would be good to also ablate the effect of the clustering, for both the path and feature embeddings.\n\nLess important comments and typos \n- ‘The amount of information contained in the task-specific data about a “probe” network can be seen as a good representation of the task itself’. It should be explained what a “probe” network is\n- ‘while the interaction between task data and the base-learner (e.g., gradients) is often not neglected.’ – I think you meant “is often neglected” here (without the not).\n- ‘However, these methods utilize gradients only at a single point in parameter space’ - I would say ‘only at the initialization’, to make it clearer what the single point is, compared to what is proposed in this work.\n- ‘we first elaborate task representation learning’ - the word ‘on’ missing after ‘elaborate’\n\nSuggestion: I encourage the authors to consider the methodology of [1], which meta-learns the task-conditioning networks that are used to predict task-specific parameters for a pre-trained (and now frozen) feature extractor. This combination of pre-training and meta-learning is very effective and competitive with state-of-the-art in Meta-Dataset. Can some of the ideas presented here be used in the context of a meta-learning phase on a pre-trained feature extractor too? In contrast to the proposed method of this work, [1] only uses feature embeddings and doesn’t consider path embeddings (in fact there is no gradient descent adaptation in that work, it’s an amortized model).\n\nReferences\n- [1] Fast and Flexible Multi-Task Classification Using Conditional Neural Adaptive Processes. Requeima et al. NeurIPS 2019.\n- [2] Improved Few-shot Visual Classification. Bateni et al. CVPR 2020.\n- [3] Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples. Triantafillou et al. ICLR 2020.\n- [4] Rethinking Few-Shot Image Classification: a Good Embedding Is All You Need? Tian et al.\n- [5] A Closer Look at Few-shot Classification. Chen et al. ICLR 2019.\n",
            "summary_of_the_review": "Overall, while the paper presents some nice ideas, is technically novel, well-organized and easy to follow, I have some concerns primarily about the relationship to prior work that make me lean towards rejection at this stage. \n\n########\nEdit after rebuttal:\nDuring the discussion with the authors, they have addressed some of my concerns by running additional ablations (removing the clustering component), comparisons to transfer learning methods, and experimenting with deeper backbones. They also have commented on the scalability of their approach, and discussed pros and cons w.r.t efficiency at training time vs deployment for transfer learning vs meta-learning methods. Overall, my view is that test-time efficiency is important for certain applications, which makes meta-learning methods a good candidate, and the particular variant proposed here seems especially suited at the important problem of handling heterogeneous data and outperforms previous MAML-based meta-learning methods that were designed for this. Based on these, I updated my score from a 5 to a 6 to reflect that the paper is slightly above the publication bar in my opinion.\n\nTo strengthen the work further, I recommend comparing against recent methods developed for heterogeneous data on common benchmarks. Some examples are the following:\n- Fast and Flexible Multi-Task Classification Using Conditional Neural Adaptive Processes. Requeima et al. NeurIPS 2019.\n- Selecting Relevant Features from a Multi-domain Representation for Few-shot Classification. Dvornik et al. ECCV 2020.\n- A Universal Representation Transformer Layer for Few-Shot Image Classification. Liu et al. ICLR 2021.\n- Learning a Universal Template for Few-shot Dataset Generalization. Triantafillou et al. ICML 2021.\n- Universal Representation Learning from Multiple Domains for Few-shot Classification. Li et al.\n- Memory Efficient Meta-Learning with Large Images. Bronskill et al. NeurIPS 2021.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper looks at the problem of meta-learning with heterogeneous tasks.\nThis is an interesting problem that is receiving increasing attention in the past two or three years.\nSeveral previous work address this problem by clustering task representations and let the meta-learner exploit the information about task cluster.\nThe authors claim that, for the first time, they cluster tasks not only at the level of the input representation (features), but also at the level of the optimization trajectory in parameter space.\n",
            "main_review": "My opinion is that the work has some significant positives, for example:\n\n- The paper is well written, mostly clear besides some small details (see \"Minor points\" below)\n- The authors report experiments on several benchmarks and several ablation studies. \n- Visualization of the rehearsed learning paths (figure 3b) is nice.\n\nHowever, there are some problems with the study that make it fall slightly short, in particular:\n\n1) It is actually not true that this is the first meta-learning work doing clustering on multi-step optimization trajectories. The work of https://arxiv.org/abs/2103.04691 is conceptually very similar, they run gradient descent in the inner loop for a few steps and they cluster the resulting trajectories across tasks. There are several differences with the author's work, trajectories are not processed by a RNN, and the method is applied to a very different context (multi-language inferece), but is otherwise very similar conceptually.\n\n2) I'm not entirely convinced that the 1% or 2% gains with respect to other methods reported in table 1 and table 2 are due to the superiority of the proposed architecture. Is the capacity (e.g. number of parameters) of the different models taken into account? Furthermore, some of the performances reported in table one falls within the standard deviation of other methods, so it is not clear whether differences are significant. \n\n3) In section 4.4., while deriving the \"shortcut tunnel\", the authors justify their method by stating that \"tasks with similar feature assignments will also have similar path assignments.\" If that is true, then the entire motivation of the study breaks, since the method is formulated under the assumption that path representations actually add significant information that is not avaiable in the feature representations.\n\nMinor points:\n- Why talking about Natural gradient in section 4.1.1? That seems completely out of context. Besides, it is not true that the Fisher is equivalent to the Hessian for cross entropy loss in general, that is true only for very special models.\n- It is unclear to me why \"learning path can be interpreted as encoding the predictive distribution\"\n- Along the entire paper it remains unclear what the authors mean by \"lower order\" and \"higher order geometric quantities\"\n- There is actually a dataset that is called \"Meta-dataset\" (http://arxiv.org/abs/1903.03096), which is different from the one the authors define. It would be great to do some effort to avoid confusion between the two. \n ",
            "summary_of_the_review": "Given the above points 1, 2 and 3 I think the paper is marginally below the acceptance threshold",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes to apply the task-aware-modulation on global Meta-learning for learning on tasks sampled from heterogeneous distributions. This paper builds on prior work on the feature-based task characterization to integrate the rehearsed task gradient descent trajectory into task representation. As the rehearsal task is computationally expensive, the authors learn a different network to estimate the rehearsed task-trajectory characterization from the feature representation. The proposed framework is tested on few-shot image classification (meta dataset and miniimagenet) and cold-start recommendation tasks.\n",
            "main_review": "Strengths\n\nCharacterizing a task using the trajectory is an interesting perspective. The authors provide sufficient intuition and motivation behind the proposed characterization (the four entities in the tuple given as input to the GRU) of the task using trajectory information. \n\nThough superficial, the analysis on trying to demystify the GRU’s learnings is interesting. \n\nThe paper is well written. \n\nConcerns\n\nThe assumption behind the shortcut tunnel is that the tasks with similar feature assignments will also have identical path assignments. If that is the case, why does one have to rely on path characterization? Isn’t it going against the basic premise of the paper?\n\nThe improvements over the current state-of-the-art approaches on meta-dataset and the miniimagenet (in the appendix) are marginal at best. The goal of the meta-learning framework, such as the one used in the paper, is to learn a well-generalizable meta-model. Recent works have demonstrated significant improvements in the performances by using deep architectures. The gain on miniimagenet for both 5.1 and 5.5 settings is over 10% (Liu et al. 2020). Furthermore, it appears that CTML does not yield even the marginal gains when the number of shots increases (based on the results from the miniimagenet dataset). Thus, I am not convinced about the utility of such a complex method to squeeze out the last drop in performance when better models are readily available. It would be interesting to see the results of these deeper networks-based meta-learning models on the meta-dataset curated by the authors. \n",
            "summary_of_the_review": "Overall, it is a well-written paper with interesting and, at times, conflicting ideas. I deeply appreciate the amount of work invested by the authors. However, I am not convinced about the approach’s utility.\n\n---post rebuttal update\n\nThank you for the clarification on the 'shortcut tunnel assumption. The assumption results in estimating the path cluster assignments through feature cluster assignments. This means that the information related to the path cluster assignments is already present (linear or non-linear relationship) in the feature cluster assignments. Thus, I am not entirely convinced that the model is getting any additional information to justify the improvement in the results because of the addition of the path cluster assignments.\n\nThe additional experiments using the heavier backbone strengthen the result.  I agree that on the curated 'meta-data set the proposed approach has an edge over prior methods. The authors have incorporated these results in the updated draft.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}