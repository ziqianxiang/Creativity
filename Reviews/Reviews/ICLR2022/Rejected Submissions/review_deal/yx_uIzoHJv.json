{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This work presents a proposal for increasing the compositionality of emergent languages that uses a measure of topographic similarity as an auxiliary loss function on the communication game. The authors find that in certain cases this loss indeed results in increased generalization but overall the authors do not find a strong relation between high weights for weighting loss and and generalization.\nAll reviewers agree that the of compositionality is very important and the idea of explicitly optimizing for compositionality (through the topographic similarity metric) is also novel. At the same time a number of concerns are raised by reviewers: \n\na) B3Jo and WEY2 raise the point that more evidence is required to establish the robustness of the current findings, e.g., by controlling whether topsim is merely inducing a regularization behaviour and providing more confidence on the current presented results (e.g., Figure 2 currently provides a somewhat perplexed pictured as the additional loss doesn't seem to improve across the board).\n\nb) The relation between compositionality and generalization is not a new one and it is not clear what exactly the current paper is adding on this discussion and, as zB6g and  B3Jo point, this makes it seem rather incremental.\n\nc) the paper is currently somewhat hard to follow with numerous results reported in a somewhat raw format, little to no examples and important details being presented only in Appendix (e.g., the loss function is only given in p12 and the actual format of L_{C} is never provided)\n\nAs such, I cannot recommend acceptance at this time but, given the importance of the topic, I sincerely hope the authors will work on incorporating reviewers' feedback for a later resubmission."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The authors create a language game in which one neural agent describes an item to another.  They study what happens to the language that emerges if an explicit parameter promoting compositionality is altered, considering a range of different environmental factors. The results show an impact of this parameter on the speed at which communication converges and the degree of generalisation of the language",
            "main_review": "I don't understand the purpose of the paper. It seems to fit into the emergence of language field but I cannot work out what the authors are saying. Do they propose such a mechanism was present in the evolution of human language? Or are they finding evidence that rejects this? Are they suggesting it be used in evolving communications in multi-agent environments? To be clear, I cannot see what research question is being asked, and I cannot see what the authors conclude about this question from the evidence they obtain.\n\nThe abstract and introduction introduces the general field and makes clear what the experiments involve. As noted above, this fails to articulate what issue the experiments are contributing to.\n\nThe relationship to past work is good. There is a sensible quantity of material cited throughout and the material referenced shows how the work fits into the existing material in the area. The bibliography contains a large proportion of papers from arXiv. This is not a peer reviewed source - we have no way of knowing whether claims in these papers meet normal professional criteria. I would guess most of this work actually has been published somewhere - please cite the published version.\n\nThe description of the method appears to contain all the necessary details. It is sometimes a little hard to follow. It would be useful to have a non-technical overview in which the basic idea is described without getting bogged down in the details of the networks or using algebra. I didn't follow section 3 very well - I think more detail is needed on Chaabouni et al's measure of compositionality, as it is key to the approach and the paper cannot be fully understood without it.\n\nThe experiments seem fine: there is nothing weird in the parameter choices; the factors studied make sense; graphs are clear. There is no comparison to other approaches but this is fine in this work, as it makes no real sense to compare to other methods.\n\nThe conclusions do not conclude anything. They are a summary of the experiments and results. They don't tell us what the results mean in terms of any research question.",
            "summary_of_the_review": "I understand what experiments the authors have done and what the results are. I don't understand what the purpose of performing the experiments is, or what conclusions we should draw based on the results. The research question really needs to be made explicit.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes to use a well-studied compositionality metric as an additional auxiliary loss function in a reconstruction task used to study language emergence. In certain cases, this loss function allows for improved generalization. The paper additionally finds that there is no simple correlation in increased weighting of this loss and increased generalization.",
            "main_review": "**Strengths:**\n\n- The paper uses the topological similarity metric [1, 3, 4] commonly used in the emergent communication literature to evaluate compositionality of emergent languages. The key contribution in this paper being the fact that it is used as an additional loss function to explicity tune the pressure for compositionality. To my knowledge, directly optimizing the topological similarity metric has not been studied before which is interesting.\n- The paper also includes some evidence that explicitly optimizing this compositionality metric can improve generalization. This insight could be very useful in other NLP settings.\n- For the most part, the paper is easy to follow.\n\n**Weaknesses:**\n\nI have included actions that can be taken to strengthen this paper as it stands. However, even with these improvements, it is unlikely that I would recommend the paper to be accepted without drastic changes like including other emergent communication tasks or effects of other types of pressures on emergent languages. \n\n- **Novelty and Motivation:**\n    - Although, to my knowledge, directly optimizing the topological similarity metric has not been studied before, the metric itself is well studied. I am not fully convinced that directly optimizing this metric tells us very much (as is apparent in the experimental section). The paper also bears a lot of similarity to parts of [1].\n- **Language Emergence Game and Setup:**\n    - The experimental setup is not clear. What are some examples from this dataset? What are some examples of attributes and values? How is it related to other tasks in the literature? Comparisons to the reconstruction task in [2] is made but this does not seem like the same task. It looks similar/identical to the reconstruction task used in [1] but no comparison to that task is made in the paper.\n        - **Action:** Improve clarity of the experimental task being used in this paper. Include comparisons to [1].\n- **Experiments:**\n    - **Figure 1:** The paper claims that carefully tuning the topological similarity metric improves the speed of convergence and generalization. However, this claim is not fully supported due the usage of only 1 learning rate. In particular, 4/6 settings in Figure 1, adding no additional loss performs among the best. In figure 1, a), d), there is evidence that different $C_t$ values performs better but unless additional learning rates and more seeds are used, this claim is not fully supported.\n        - **Action:** Run experiments with more learning rates and more seeds.\n    - **Figure 2:** I don't this that these plot adds much towards the paper. It only seems to work as a sanity check to see if the implementation is accurate. Optimizing a separate loss would naturally improve that loss. It would be more interesting if a different compositionality metric than what was used during training is used instead.\n        - **Action:** Use other compositionality metrics like **positional disentanglement [1].**\n    - **Table 1, Table 2:** These tables are missing descriptions and does not depict the metrics being measured. The tables are also missing confidence intervals which makes drawing any conclusion from these tables misleading.\n        - **Action:** Add descriptions to the tables and include confidence intervals.\n- **Overall:**\n    - Paper has numerous typos and punctuation mistakes that make the paper a little difficult to follow in some places.\n    - For example, in section 2.1:\n        - discreet → discrete.\n        - Similar to inputs, each symbols ... → .... symbol ...\n    - In section 4.3:\n        - ... lower $C_t$ coefficient than $10^6$ → ... $10^{-6}$ ...\n    - **Action:** Fix typos and errors\n\n[1] Chaabouni, R., Kharitonov, E., Bouchacourt, D., Dupoux, E., & Baroni, M. (2020). Compositionality and generalization in emergent languages. *arXiv preprint arXiv:2004.09124*.\n\n[2] Gupta, A., Resnick, C., Foerster, J., Dai, A., & Cho, K. (2020, July). Compositionality and Capacity in Emergent Languages. In *Proceedings of the 5th Workshop on Representation Learning for NLP* (pp. 34-38).\n\n[3] Ren, Y., Guo, S., Labeau, M., Cohen, S. B., & Kirby, S. (2020). Compositional languages emerge in a neural iterated learning model. *arXiv preprint arXiv:2002.01365*.\n\n[4] Lazaridou, A., Hermann, K. M., Tuyls, K., & Clark, S. (2018). Emergence of linguistic communication from referential games with symbolic and pixel input. *arXiv preprint arXiv:1804.03984*.",
            "summary_of_the_review": "This paper proposes to use a well-studied compositionality metric as an additional auxiliary loss function in a reconstruction task used to study language emergence. Due to the lack of rigor in the experimental sections, the claims made in the paper are not well supported. The paper's novelty is also highly incremental to existing works, particularly compared to [1]. As such, I would recommend that the paper is rejected.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper is an incremental study that tries to go beyond some\nexisting baseline in the generalization ability of language learned\nthrough message exchanges between two neural agents (sender and listener).\n\nThe proposed method is to add to the optimization objective of the\nagents the effect of compositional pressure using a metric called\ntopological similarity, under a set-up of the game where the primary\nobjective is reconstruction.  Senders are said to sample from some\nmessage space a certain representation about an object.  The listener\ntries to decode the message and reconstruct the object.\n\nUsing some synthetic experiments, it is shown that though in some cases\nthe method has an advantage on generalization, the advantage is not\nconsistent but depends substantially on the agent architecture,\nstructure of input data, and parameters of the game environment.",
            "main_review": "The paper is motivated by an ambitious objective of capturing some\nobserved advantages of leveraging composition in natural language learning.\nIt also cites many references in the area for prior art.\n\nOn the other hand the paper cannot be read and understood standing\nalone as a self-contained piece of work.  The entire discussion is\nheavily dependent on assumed\nknowledge of the topic, the broader area, and the usual practices of\nsuch simulation experiments.  It does not try to explain what is the\npurpose of training, what is supposed to happen in testing, and what\ncomposition and generalization mean in this context.  Therefore the results, even if\nit is strong enough to be useful, appeal only to those closely\nfollowing the topic. \n\nThe pairing between the object space and the message space is said to\nbe done with some matrices but it is not clear how such matrices are constructed.\n\nOne other issue with the paper is that there are no examples at all throughout.\nThe entire discussion about setup, experiments, results is abstract.\nEven if the objects, attributes, messages, etc. are all synthetic and\nsymbolic, there should still be a way to show what a message looks\nlike.  Without that, the reader has no way to get an intuitive sense\nof what messages are being exchanged, what language emerges, what it\nmeans by generalizing, and how far off the results are.  To better\nconvey the ideas, an example should be give as early as in Section\n2.1, and followed through in the discussions.\n\nThe fact that the entire work uses only synthetic objects with no\nconnection to the real-world is also a weakness.  Given that the\neffects depend on the structure of the input data, environmental\nparameters, etc., there should at least be some discussion on what\ntype of real-world scenarios would best match the conditions that the\nmethod requires to work well.   \n",
            "summary_of_the_review": "The work is a small incremental experiment that probes for the advantage of a perturbed objective in language learning, with some weak results.  It took inspirations from natural language learning but idid not try to connect back to any natural learning scenarios.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper introduces a novel loss term, which encourages high topological similarity, in the context of emergent communication. The paper hypothesizes that increasing the topological similarity of utterances from the two agents will increase the generalization ability of the agents to unseen inputs.\n\nThe paper presents evidence that mmoderate amounts of compositional pressure do improve the generalization ability, but large amounts of compositional pressure negatively affect the generalization ability.\n\nThe paper goes on to show evidence that the correlation between topological similarity of utterances and the generalization ability is complex and not always clear-cut.",
            "main_review": "## Good points\n\n- investigates the use of topological similarity as a loss term, in the context of emergent communication, which loss term might be novel\n- presents additional data points showing that the link between topological similarity and generalization is tenuous\n\n## Bad points\n\n- adding topological similarity as a loss term seems to me to fly in the face of the goals of emergent communication, which is to allow the agents to freely generate their own language, and then to evaluate the resulting language? This is not to say that the approach espoused is not useful, but I feel the motivation provided seems unclear to me?\n- no code provided\n- experiments do not appear to me to eliminate the possibility that the role of the compositional pressure is purely as a regularizer. e.g. can the results be reproduced by using other regularizers such as dropout, L1 weight reg, or L2 weight reg?\n\n## Notes\n\nI wrote the following notes whilst reading through the paper\n\n### Abstract\n\ninteresting idea to incorporate metric of compositionality into learning\n- doesnt this go against the idea of letting languages emerge naturally, and then evaluating them?\n- what is the intention of doing this?\n- as far as generatlization vs compositoinality, there is existing work that shows this, eg baroni, kharitonov, andreas\n\n### 1. Introduction\n\nobverter reference seems incorrect to me: I believe you are thinking of Choi et al 2018, not Lazararidou et al 2016?\n\nThe introduction seems to me well-written, and fairly complete, on the whole.\n\nHowever, given the clear knowledge of prior work expressed in the introduction, I'm unclear why the observation that there is no simple correlation between generalization and compositionality is novel? There are multiple works (eg Chaabouni et al 2020, which you cited), which show this already?\n\nContributions 2 and 3 appear to be highly related to contribution 4.\n\nUsing a compositional metric to guide learning seems to me to be novel, but also seems to me to be somewhat against the spirit of emergent communication? i.e. the goal of emergent communication appears to me to be to let languages emerge, and then see what kinds of languages emerge; rather than to add our opinion of ideal languages into the loss function? Nevertheless, it does appear to me to be novel to add the compositional metric into the loss function. Measuring the same metric as our output seems somewhat circular, but measuring generalization ability seems a plausibly reasonable thing to do, to me.\n\n### 2. Language emergence game\n\nI thought the paragraphs were going in the direction of using non-symbolic input, so I was a bit disappointed to find their arguing in favor of symbolic inputs.\n\n#### 2.1 setup\n\nNice that you are using the recommended notation for sets for ICLR :)\n\n#### 2.2 agents\n\nI don't understand what you are pairing. You suddnely talk about it, out of nowhere. From my understanding, for each example, we take a single object, x, which is sampled from N_A attributes, each with N_V possible values. We feed this through our network, which predicts what was the original x. There is no negative sampling involved. I'm not sure I understand what the pairs relate to. Please could you explain the pairing motivation more clearly?\n\n## 3. Pressure for compositionality\n\n### 3.1 Metrics for compositionality\n\nOk, this bit explains taht the pairwise is for topological similarity. However, I feel the ordering of the explanation wrt the text in 2.2 makes the text in 2.2 challenging to understand. I feel it might be good to rethink the ordering of these texts a little?\n\nInteresting observation that Pearson correlation is differentiable.\n\n## 4. Experiments\n\nFigure 1: I feel that 1e-6 should be in between 0.0 and 0.1 in the legend?\n\nWhy are the random seeds 1,3,5,7,11,13? why not just choose 1,2,3,4,5,6?\n\nI'm not sure what it means for an exampoe to be 'up to five times the size of the input space'?\n\nI believe 'thrive' might be intended to be 'strive'?\n\nFigure 1: you are dnoeted message space size as eg (10,4), but I believe per your notation, defined in 2.1, this hsould be written M(10, 4)? This would alo reduce my confusion, since I initially assumed taht (10,4) was input space size, not message space size.\n\n$C_t$ is not defined in the text. It's implicitly defined in algorithm 1. It's obviously the coefficient in front of the topological similarity regularization term, however I think it would be good to state this explicitly in the text?\n\nI find figure 1 hard to read: I think we care about seeing the effect of $C_t$? Therefore, strong preference for the x axis to be $C_t$. and for the runs, rather than showing training curves, why not use early stopping somehow (or just train always for 100 epochs, as you state in the text), and report the value either at early stopping, or at 100 epochs? Then you can draw a single curve of test accuracy vs C_t. And you can put all six curves, for each different message space, on the same set of axes. I believe this would be much more intuitive for me to understand/read.\n\n### 4.1 Generalization\n\nWhy do you test with both recurrent and linear architecture for hte listener? Why not just choose one, to keep things simple?\n\n\"It is evident from the plots that there is no clear winner for Ct, which is suitable for all the scenarios.\" => not obvious at all to me tbh. Not without looking really carefully. Please consider redoing the plots ,as alluded to above, so that it is in fact really obvious :)\n\nThe graphs are all for linear listener. In reality, in emergent communication literature, almost all listeners I've ever seen are some kind of RNN. I think it might be more meaningful then to just use an RNN listener, and move linear listener results into the appendix?\n\n### 4.2 Compositionality\n\nYou compare your compositional loss term to other regularization techniques. How do you know that the term is not functioning simply as a regularization term? For example, what happens if you flip the compositionality term, so that it encourages low compositionality. This would also act as a regularizer, by increasing entropy. Does this also increase test accuracy too.\n\n\"Excessive compositional pressure\" implies that the compositional pressure is bad, but if I understand correctly, in this context the high compositional pressure is actually good, for test accuracy? So, perhaps use \"High compositional pressure\" instead of \"Excessive compositional pressure\"?\n\nDon't your results at M(50,2) align with a hypothesis that the compositionality loss could be acting uniquely as a regularizer, rather than by improving something concrete that correlates with generalization?\n\n\"However there is more than enough evidence to accept advantage of the compositional pressure on generalization\" => I feel this is overly strong. There is some small amount of evidence, but nuanced by at least 1. high compositional pressure reduces test accuracy, and 2. the hypothesis that it is acting purely as any other regularizer. e.g. what happens if you use other regularizers such as L1 weight norm, L2 weight norm, or dropout? Can you reproduce similar graphs as for using compositional pressure?",
            "summary_of_the_review": "The paper investigates the use of topological similarity as a loss function to improve the generalization ability of agents, in the context of emergent communication. I feel that this approach is sort of the opposite direction of other emergent communication research, which allows the agents to freely emerge their own language, and then evaluates the resulting language. Thus, I feel it is important to motivate clearly what the goal of the additional loss function is.\n\nThe paper does give an additional data point showing that the link between compositionality, as measured by topological similarity, and generalization is tenuous. However, there already exist multiple works that present such evidence, as alluded to in the Related Work section of this work.\n\nThe paper shows that the compositional pressure does improve generalization ability, but only in moderation, and that the amount to be used is an empirical question, which depends on many factors, in a complex way. Thus, is it different from any other regularizer? Could a similar effect be observed by using other regularizers such as dropout, or weight decay?\n\nOverall, I feel that I'd like to see the paper delve in a little deeper somehow. For example, comparing to other regularizers, comparing with applying negative compositional pressure. How do agents with naturally high compositionality compare with those which had high compositionality under conditions of high compositional pressure? How do other metrics of compositionality change? Can we apply compositional pressure using other metrics, such as Resnick's residual entropy?\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}