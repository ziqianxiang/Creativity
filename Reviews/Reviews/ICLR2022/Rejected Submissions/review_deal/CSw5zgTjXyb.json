{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper proposes a model of agent collaboration to improve outcomes for any participating agent in a setting where every agent does not always benefit from collaborating with all other agents. The reviewers did find some of the theoretical results interesting, however, in its current (revised) form, they still argued during the discussion post-rebuttal that: (i) the game theoretic formulation of this problem is not entirely new and has been studied in various forms before and (ii) the particular application of the results to federated learning comes after making various (questionable) assumptions. I would encourage the authors to take into account (i-ii) for preparing a revised version of their paper and resubmit to another conference."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper considers the problem of federated learning where different clients/entities share their datasets with other clients in order to obtain a model that performs best for the local loss functions. Standard federated learning setting usually share all datasets together to obtain a central model and might not be the best choice for each client separately. The authors propose a notion of collaboration equilibrium where each client shares data with a subset of all the available clients. In particular, a coalition of agents belong to a collaboration equilibrium if each agent gets maximum benefit by collaborating with all the agents in the subset, and the subset is maximal.\n\nIn order to obtain such a collaboration equilibrium the authors propose an iterative algorithm which under certain assumptions, is equivalent to finding strongly connected components in the graph. Finding the collaboration equilibrium requires identifying the benefit graph among the client. Under a very specific model of agents' utility functions, a pareto optimization based algorithm is proposed to find the graph. Finally, though experiments, the authors show that finding collaboration equilibrium does provide improvement compared to standard federated learning based methods.\n",
            "main_review": "Strengths:\n- The authors consider an interesting problem as negative transfer is a real concern in federated learning and building a local model to avoid this phenomenon seems like a good direction.\n- I like the notion of collaboration equilibrium where a group of agents share their data only within clients in a given coaltion.\n\nWeaknesses:\n- My main concern about the proposed iterative algorithm is that it works only when assumption 1 holds and I believe this is not a realistic assumption in practice.\n- Although the definition is proposed for a general utility model, the authors assume a particular utility model in subsection 4.2. I have some concerns about this choice which I mention below.\n- I don't think the proposed definition properly captures the negative transfer phenomenon we observe in federated learning. For example, negative transfer also happens when a client shares too much data from another client as opposed to a small amount of data.\n- This paper talks about collaboration equilibrium but such notions of collaboration have been studied in cooperative game theory, probably in different context. I was surprised to see that the related work section doesn't have any mention of related work from game theory literature.\n\nQuestions for the authors:\n- Regarding the example shown in figure 1, it is not clear that you will always be able to find an initial coalition from the graph. It was later clear that under assumption 1, this problem boils down to finding a strongly connected component but this was not clear in the introduction.\nIn particular, I wonder how the iterative algorithm would start when assumption 1 fails.\n\n- Although the definition of optimal collaborator set is intuitive I am not sure how this captures the negative transfer phenomenon the authors talked about in the introduction. Negative transfer should imply that whenever I add a (harmful) client, the utility of the local model always drops. I don't think definition (1b) captures it exactly.\n\n- How realistic is assumption 1 in practice? I understand that this assumption simplifies the iterative algorithm as you don't have to recompute the benefit graph after eliminating each coalition. But if this assumption fails, recomputing the benefit graph shouldn't be computationally hard.\n\n- In section 4.2, I didn't understand the particular modeling assumptions about the clients' utility functions. In particular, it seems that the goal is to find a hypothesis that is at the pareto frontier. But why care about such a universal function if each agent wants to build their own local model? Additionally, how do the agents determine their weights?",
            "summary_of_the_review": "I thought the authors consider an interesting problem in this paper. Negative transfer in federated learning is a challenging problem and if you can avoid this issue by building a local model, that would be great! However, there seems to be several issues with the proposed definition. Moreover, the methods work under certain assumptions and I am not sure the assumptions are realistic.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors propose a model of collaboration to improve outcomes for any participating agent.   In their setting, the authors assume that every agent does not benefit from always collaborating with all other agents because of heterogeneity of the underlying data distributions.",
            "main_review": "The main aspect of the proposed solution in the paper is the notion of maximum achievable utility (MAU) and optimal collaborator set (OCS) which each agent must derive.  These are well-studied principles in cooperative game theory and concepts like 'core' and 'stable coalition' are analogous to the definitions used in this work.  Similarly, the approach of using a 'benefit graph' to compute coalitions satisfying the proposed axioms also has an equivalent approaches.  See , for example, literature on \"stable group formation\" (Y. Bachrach, V. Syrgkanis, and M. Vojnovic, 2013; Arkin et. al., Geometric Stable Roommates, 2009; Aauman and Dreze, Cooperative games with coalition structures, 1974; Hart and Kurz, Stable Coalition Structures, 1982).\n\nFurther, the authors have not motivated clearly why this should be a learning problem and why it cannot be solved by using other techniques (example, in the literature mentioned above).  In its current form, I think the paper needs more work to distinguish itself from prior art and how it can use the federated learning framework to 'learn' the OCS instead of computing it directly.",
            "summary_of_the_review": "There is a lot of related work in the cooperative game theory and federated learning literature.  I think the authors need to do a much better comparison with the existing literature and propose why their work is different from it and carry out clear comparisons (in their experiments) to show the efficacy of their approach. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "Given a network of clients each with his own private dataset, the locally learned model can be improved by obtaining data from other clients (assuming no domain mismatch). The paper models this problem by introducing the benefit graph which models how each client may benefit another. The concept of collaboration equilibrium is introduced and optimization algorithms to solve it are given. Some theoretical guarantees are shown along with experimental results.  ",
            "main_review": "I think the paper solves an interesting and important problem and that the model introduced is interesting and detailed. My main issue is that it does not appear that the introduced model captures the problem. Here are some points:\n\n1-The authors mention that privacy concerns are the main reason why a client would not share his data. But I don't see how the privacy cost is being modelled in the problem. For example, the number of individuals the client has to share his data with.\n\n2-Following point 1: I don't think the paper mentions this, but is it not possible for clients to share portions of their datasets instead, perhaps the portions that lead to positive transfer. This would further complicate things and also make it more meaningful to consider the amount of lost privacy. \n\n3-Similarly, the benefit graph does not include weights. But it seems plausible that a client would only benefit little from others datasets.\n\n4-Assumption 1: is there a motivation behind this assumption? do we expect real instances to satisfy it or it is only introduced to make the algorithm less time consuming? Also given the benefit graph can we verify that the assumption holds? \n\n5-Section 4.2 discusses how the benefit graph is obtained. It is not clear to me however, that the Pareto solution gives the actual benefit graph. I realize that the exhaustive search for the benefit graph would be infeasible. The issue is if this is an approximation of the benefit graph, then the error should be characterized and the algorithms and theorems in section 4.1 should be modified to reflect that they operate on a noisy estimate of the benefit graph. \n\n6-Unrelated to the model, but the number of clients in the experiments seems to be small (at most 9) even on the synthetic dataset. ",
            "summary_of_the_review": "The introduced model does not seem to be complicated enough to capture the real details of the problem. Further, the algorithms and guarantees introduced do not seem to be rigorously justified. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper considers the problem of agents sharing training data to improve the accuracy of the model obtained on their own population.  The high-level goal is to find \"stable\" collaboration patterns where no agents want to deviate (e.g., stop sharing or form their own groups of sharing).  The authors first consider an abstract formulation where each agent has a utility function over all sets of other agents to collaborate with.  Assuming that one can find the most beneficial set of collaborators for each agent, the authors present an efficient algorithm to divide agents into groups that form a stable collaboration pattern (aka a collaboration equilibrium).  Since the problem of finding this optimal set of collaborators for each agent is nontrivial in general, the authors come back to the setting of sharing training data, where they propose a theoretically principled approach to build the benefit graph (which encodes most beneficial collaborators) by optimizing on the Pareto frontier of hypotheses / models of accuracy of all agents.  The authors then evaluate their approach on synthetic and real data, and compare that against several benchmark methods for personalized federated learning.  Empirical results suggest that the collaboration equilibrium behaves roughly as one would expect.  Also, the model found by optimizing on the Pareto frontier appears to achieve remarkable performance, often comparable to or better than the best benchmark.  The accuracy at collaboration equilibria is somewhat worse, which is natural given that there might be a \"price of stability\".",
            "main_review": "### Strengths\n\nThe notion of collaboration equilibria appears natural, and the algorithm for computing such equilibria insightful.  Together with the SPO part, this provides a quite complete solution for personalized federated learning problems, and in particular, the equilibrium solutions take into consideration the incentives of self-interested agents, which is of potential practical importance.  The experiments appear to support the main claims of the paper.\n\n\n### Weaknesses\n\nSome parts of the overall approach lacks theoretical foundations (although they make sense).  The writing could be improved, e.g., by unifying terminologies and better connecting different parts of the paper.  Also, (this is not necessarily a weakness, but) I'm not familiar with the literature on federated learning, so I can't say much about the novelty of the method.\n\n\n### Detailed comments\n\nProblem setup, set of coalitions: since C^1, ... C^K partition I, isn't C^0 necessarily empty?\n\nAxioms 1 and 2: these are conceptually quite similar to the notion of the core in cooperative game theory.  The authors may want to discuss the relation between the two.\n\nTheorem 2: this claim is technically fine, but I think you still want to discuss why Algorithm 1 terminates, which isn't totally trivial (since very superficially it's possible that none of the components are stable so the algorithm gets stuck).  Indeed it does terminate, because after the SCC decomposition the new graph (over SCCs) is acyclic, which means it can be topologically ordered, and there exists a component which doesn't have incoming edges from other components.  That is a stable coalition that can be removed from C to make progress.\n\nDefinition 5: I'd say \"Pareto-efficient (or Pareto-optimal) solution\" instead of \"Pareto solution\"\n\nFootnote 1: \"(for) more information\"\n\n\"Learning a best model\" paragraph: what's a \"model\"?  What's a \"Pareto model\"?  From what I understand, a \"model\" is the same as a \"solution\" (which is a hypothesis), and a \"Pareto model\" is a solution or a hypothesis on the Pareto frontier.  Is that right?  In any case it would help to clarify these terms and unify them if they are in fact the same thing.",
            "summary_of_the_review": "Overall I think this paper proposes a novel theoretically principled method for computing stable outcomes of data sharing or collaboration in general, which can also be applied to personalized federated learning.  Some of the theoretical results appear quite insightful.  The experiments are quite informative and support the main claims of the paper.  (Since I'm not familiar with the literature on federate learning, my evaluation regarding the novelty could be misled.)",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}