{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The authors propose a novel operator splitting method for solving convex relaxations of neural network verification problems, and develop and validate an optimized implementation of the same on large scale networks, focusing on the problem of verifying robustness to norm bounded adversarial perturbations.\n\nThe reviewers agree that the paper contains interesting ideas that are worthy of further development and that these ideas may prove useful eventually in pushing the envelope of what is possible in neural network verification. However, in its current form, the paper misses some key experimental evidence to rigorously evaluate the value of the contributions made:\n1) Comparison against SOTA incomplete verifiers: The authors do not provide detailed and rigorous comparisons against well-known baselines (for example the incomplete verifiers from Fast-and-complete (Xu et al., 2021), Beta-CROWN(Wang et al. 2021)) \n2) Incorporating tighter relaxations: It would be valuable for the community to understand whether the proposed algorithm is compatible with tighter relaxations like those of (Tjandraatmadja et al., 2020). Even if they are not, it would be interesting to understand the comparison against standard solvers for these tighter relaxations compared against the advanced solver developed by the authors applied to the weaker relaxation.\n3) Showing performance in the context of complete verification: While this is not a requirement, it would be great to see how the method performs in the conjunction with a branch and bound search, as this sometimes reveals surprising tradeoffs or weaknesses of incomplete verifiers (as observed in the results of Beta-CROWN(Wang et al. 2021)).\n\nI encourage the authors to strengthen the paper adding these experiments and resubmit to a future venue."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes an operator splitting method which solves a convex relaxation of a learge-scale nonconvex optimization problem for analyzing the worst-case performance of deep neural networks against input perturbations. The proposed method is modular, scalable and parallelizable. Experimentally, the authors demonstrate that the proposed method has tighter bounds on the worst-case performance of large CNNs in image classification and RL settings. ",
            "main_review": "While this paper is well-written and has proposed quite an interesting idea to improve the scalability of the neural network verification problem, the idea of applying operator or variable splitting to neural networks is definitely not novel, although neural network training and verification might be differet tasks. However, due to their highly similar problem formulations, I woule expect the authors to discuss the similarities and difference between the proposed method and such related papers, e.g., Taylor et al. (2016), Cui et al. (2019), Zeng et al. (2019, 2021). I would raise my score if the authors can explain the above in their response and include such details in the revision of the paper. \n\n---\nCui, Y., He, Z., & Pang, J. S. (2020). MultiComposite nonconvex optimization for training deep neural networks. SIAM Journal on Optimization, 30(2), 1693--1723. \n\nZeng, J., Lau, T. T. K., Lin, S., & Yao, Y. (2019). Global convergence of block coordinate descent in deep learning. In ICML. \n\nZeng, J., Lin, S. B., Yao, Y., & Zhou, D. X. (2021). On ADMM in deep learning: Convergence and saturation-avoidance. Journal of Machine Learning Research, 22(199), 1--67.\n",
            "summary_of_the_review": "This paper has proposed an interesting idea (i.e., operator splitting) to improve the scalability of neural network verification, but this idea is not novel for its applications to neural networks (e.g., neural network training). The paper will better position itself if more detailed comparisons are made with such methods in the existing literature. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a novel method for the neural network verification problem. The authors use variable splitting and Lagrangian relaxation to relax the verification problem, which is then solved with ADMM. The method is GPU friendly (similar to previous work like Dvijotham et al. 2018 and Bunel et al. 2020a), and claims to solve the relaxation to optimality.",
            "main_review": "Strengths\n1. The method uses variable splitting and Lagrangian relaxation which have been used in previous verification works. However, the proposed variable splitting is novel as it allows closed-form updates for the primal variables. Thus enjoying faster convergence than Bunel et al. 2020a. \n\n2. The authors have done a good job at discussing the differences with previous related works like Dvijotham et al. and Bunel et al. in section 3.\n\nConcerns\n1. Incomplete verification experiments not thorough:\n* Are the different methods using the same intermediate bounds? I found in the supplementary that you computed intermediate bounds for Bunel et al, using KW. How are intermediate bounds computed for your method?\n* The table and details are not very clear. Do the different rows correspond to the same network tested with different epsilon values?\n\n2. Missing baselines in incomplete verification experiments:\n* The paper is using weaker baselines. The authors should compare with [A] (which is a published work at ICLR21). They use a tighter relaxation (Tjandraatmadja et al., 2020) and solve it using a Lagrangian relaxation and active set based approach. Furthermore, they are outperforming solvers from Bunel et al. 2020 which has been used as a baseline in this paper.\n* This also brings into question the relevance of this work. Because [A] outperforms Bunel et al. 2020. Can your method be extended to the relaxation from Tjandraatmadja et al., 2020? It is not clear that this work can outperform [A] or work with tighter relaxations. \n* The authors should also compare with Fast-and-complete (Xu et al., 2021), Beta-CROWN(Wang et al. 2021) as they use the same LP relaxation as this paper, and are very effective. This should be done in both Table 1 and the scalability section, as these methods can scale to such networks.\n\n3. Missing complete verification experiments:\n* Complete verification experiments are missing. This has been done in works that have been used by the authors as a baseline (Bunel et al. 2020). Even the recent propagation-based solvers provide results on complete verification (see Xu et al., 2021 and Wang et al. 2021). \n* They are quite important to judge the practical relevance of the algorithm. Branch-and-bound takes memory, speed and accuracy all into account, thus is crucial to see the relevance of the work.\n* See VNN-comp [B] for recent developments in this space. The authors should use a branch-and-bound framework from the open-sourced codes from VNN-comp and plug DeepSplit into them.\n* You should also add these b&b baselines in the speed-comparison experiment. b&b solvers can be used as incomplete verifiers, and that should be possible here since the network size is small.\n\n4. Scalability experiments representation:\n* Can you provide verified accuracy here? This will help in checking if the method can in fact verify this size networks or if the bounds are too large to be relevant.\n\n5. Overclaiming\n* 'focus on networks whose convex relaxations were previously impossible to solve exactly due to their size.' in Introduction seems to be an overclaim, since LirPA seems to be not doing that bad. And LirPA is not even the state-of-the-art baseline. Is this statement corresponding to experiments in Table 1 or the scalability experiment?\n\nI am willing to update my rating depending on the authors' response to these concerns.\n\n[A] Scaling the Convex Barrier with Active Sets Alessandro De Palma, Harkirat Behl, Rudy R Bunel, Philip Torr, M. Pawan Kumar, ICLR 2021\n\n[B] https://sites.google.com/view/vnn20/vnncomp",
            "summary_of_the_review": "The authors have proposed a novel method for the neural network verification problem. It is better than Bunel et al 2020. However, authors have not compared against recent state-of-the-art published baselines. Also, complete verification experiments are missing.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes an efficient solver for computing the convex relaxation of Neural Networks, which is an important component of verification methods. The method is based on ADMM, with the authors proposing a novel decomposition of the optimization problem, which allows them to get closed form solutions of all the intermediate steps of the algorithm, The proposed method also improves on the guaranteed convergence rate and is shown to scale to larger networks than the ones considered in other works.\n\nEvaluation is performed on robustness verification on Cifar10 and on Reinforcement learning models.",
            "main_review": "# Strengths\n* The paper is very clearly written, with a clear narrative explaining how the algorithm is derived (Equation 3 to 13) with a helpful summary in Algorithm 1 on how things tie together. The appendix is very detailed and provide clear explanations for how to implement each component of the algorithm efficiently.\n* The contribution is clearly framed with regards to previous work. The Introduction and Related work are a good summary of the current state of neural network verification, and Section 3 does a great job at highlighting the differences between the proposed methods and the most closely related published work, highlighting why this results in significant improvements.\n* The significance of the contribution is also quite important. The authors give convergence guarantees and show good convergence empirically with the optimization curves in the appendix, which previous methods could not offer. They even show that this results in improved certified accuracy (for a given time budget),\n* The evaluation is done quite rigorously, on several domains (Vision / RL) and at different scales (comparison to Gurobi on small models, evaluation against related methods on Cifar10 network of a standard size, and evaluation of scalability against fast linear bound on ResNet models).\n\n# Weaknesses\nA potential improvement that this paper could benefit from is a comparison to methods such as the OptimizedLirpa bounds from the Fast and Complete paper, which the authors cite. This would not need to include comparison to the branch and bound aspect of it, but simply to the bound computation, which rely on fast linear bounds, but iteratively optimizes the slope of the relaxation. This is equivalent to solving the same problem and has been empirically shown to be quite efficient. \nA comparison of the tightness / speed tradeoff that would result would be extremely useful. (The method described in this paper are valuable even if they are slower, as they provide convergence guarantees, which OptimizedLirpa bounds do not.)",
            "summary_of_the_review": "Very well written paper, with interesting and significant contributions, and which provide a great summary of the state of the field.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes ADMM for neural network verification problems. Experiments are demonstrated to show its effectiveness and scalability.",
            "main_review": "This paper proposes an operator splitting method (i.e. ADMM) to deal with neural network verification problems. This is because the ADMM is scalable to large datasets. Specifically, they solve the convex relaxations of problems analytically. Extensive experiments on network verifications demonstrate outstanding performance as well as excellent scalability.  This paper has several limitations, which are discussed as follows:\n1.\tSome statements in the paper are unclear. For example, in the introduction, the authors state that neural networks lack formal guarantees. However, the meaning of formal guarantees is unclear, and how does it relate to safety-critical applications should be explained better. As another example,  the background of the neural network verification problem is missing. It is unclear what are potential applications of this problem, and examples should be provided to better understand required properties.  \n2.\tThe novelty of this paper should be justified better. The authors just utilize an existing optimization framework ADMM to relax nonconvex problems into convex ones, which lead to analytic solutions. As they mentioned, several papers consider similar ideas, but the difference seems subtle. it is unclear how ADMM resolves the incomplete problem (i.e. methods are guaranteed to detect all false negatives but also produce false positives). Moreover, the ADMM usually converges slowly to the solution, how do authors address this issue?\n3.\tExperimental details are missing.  Even though the authors show many experimental results,  the background of problems in the experiments is missing, and little information such as architectures and hyperparameter settings is provided.  So it is difficult to reproducible experimental results.\n",
            "summary_of_the_review": " This paper addresses an important problem. However, the unclear presentation, the lack of novelty justification, and missing experimental details should be improved to make it an acceptable paper in ICLR.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethics concerns",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors present DeepSplit, a novel solver for a popular neural network convex relaxation. Relying on ADMM and on a careful problem re-formulation, the authors achieve both a O(1/T) converge rate and closed-form solutions for the inner problems, differently from previously presented solvers for the same relaxation. Computational results are presented for incomplete neural network verification, showing that DeeSplit scales to a ResNet18 and achieves better bounds in the same time compared to relevant baselines.",
            "main_review": "---- Pros ----\n\nAs implied in section 3, DeepSplit is an improvement on two closely-related dual solvers for the same relaxation (the convex hull of element-wise activation functions):\n- (Dvijotham et al. 2018) presented a dual solver based on the Lagrangian relaxation of problem (3), which converges to the same bounds as DeepSplit, with a rate of O(1/sqrt(T)).\n- (Bunel et al. 2020a) first employed variable splitting and an Augmented Lagrangian on the same relaxation, improving upon the dual solver from (Dvijotham et al. 2018). While the Augmented Lagrangian is differentiable, the inner problems require the use of an iterative optimisation algorithm.\n- DeepSplit adds a second variable split to the formulation from (Bunel et al. 2020a) so that the inner problems enjoy a closed-form solution. This results in faster empirical convergence, and attains the O(1/T) rate.\n\nSuggestion: perhaps inverting the ordering of sections 3 and 2 could improve the paper's readability.\n\n---- Cons ----\n\nThe paper repeatedly claims that DeepSplit solves the considered relaxation *exactly*, seemingly contrasting this with other approaches. However, the methods from (Dvijotham et al. 2018) and (Bunel et al. 2020a) enjoy the same property, the only difference being a slower empirical convergence rate. As a consequence, I believe the authors should tone down claims such as that they compute bounds for \"networks whose convex relaxations were previously impossible to solve exactly due to their size\".\n\nFurthermore, in neural network verification, one is typically concerned with verifying the largest number of properties in the smallest possible time, rather than solving a given relaxation exactly. Suboptimal yet inexpensive bounds are then potentially preferable to solving a given relaxation to optimality, especially considering that running a fixed small number of branch and bound steps will significantly tighten the bounds (see for instance (Wang et al. 2021)). In other words, methods based on branch and bound can be employed as incomplete verifiers, if they are terminated early. The cost of running recent branch-and-bound methods to termination is nevertheless significantly smaller than what the authors claim: BaDNB from (De Palma et al. 2021) verifies a large number of properties in under 10s for a network of 50k activations. Similar (or better) results were obtained by the participants of VNN COMP 2020, or VNN COMP 2021. I believe this is in the same order of magnitude as the network size employed for Table 1, for which the reported runtime of DeepSplit (in the appendix) is around 10s as well.\n\nIn addition, recent works such as (Xu et al. 2021), and [Bunel et al. non-convex 2020] have shown that non-convex reformulations (lacking convergence guarantees to the exact solution of the relaxation, for ReLUs) obtain significantly better speed-accuracy trade-offs (on the same relaxation) than (Dvijotham et al. 2018) and (Bunel et al. 2020a). These newer works seemingly scale quite well with network sizes: I hence doubt that the only applicable method to a ResNet18 is non-optimized LiRPA, as claimed by the authors.\n\nI am willing to significantly increase my score if the authors address the following points:\n- Table 1 should report the average runtime in addition to the certified test accuracy. Preferably, different speed-accuracy trade-offs should be reported for iterative algorithms.\n- The certified accuracy for \"Dual Decomp Adam\" should not be lower than the one for \"Linear\", as the latter can be used an initializer to the dual problem in (Bunel et al. 2020a). Are the authors taking this into account? Could DeepSplit enjoy the same initialization?\n- Compare against the more recent bounding algorithms from [Bunel et al. non-convex 2020] and (Xu et al. 2021). While introduced in the context of branch and bound, the \"alpha-CROWN\" method, or LiRPA with optimized slopes, is a valid incomplete verifier, and the global optimum of its optimization problem coincides with DeepSplit's. Furthermore, it might yield tigther bounds than DeepSplit in case of joint optimization over intermediate bounds. The code of both algorithms is available online.\n- Compare speed-accuracy trade-offs against works operating on tighter relaxations, such as [Active Set].\n- Considering that the memory footprint of alpha-CROWN with fixed intermediate bounds is only marginally larger than the one for LiRPA, the authors should add this to the ResNet18 experiments.\n- Complete verification performance is tightly linked to the quality of the speed-accuracy trade-offs of an incomplete verifier. It would be quite informative if the authors could provide complete verification experiments on the model from Table 1.\n\n---- Minor comments ----\n- End of page 1 \"these relaxations must typically be further relaxed\": this statement does not apply to (Dvijotham et al. 2018) and (Bunel et al. 2020a)\n- section 1.1, typo in reference, \"de2\"\n- Sec 3.2 \"When stopping early, the primal minimization must be solved to convergence in order to compute the dual function and produce a valid bound.\": this is incorrect, as a valid bound can be obtained in closed-form by minimising the Lagrangian, rather than Augmented Lagrangian.\n\nReferences:\n[Bunel et al. non-convex 2020] - An efficient nonconvex reformulation of stagewise convex optimization problems, NeurIPS 2020\n[Active Set] - Scaling the Convex Barrier with Active Sets, ICLR 2021",
            "summary_of_the_review": "DeepSplit is an improvement upon two closely-related solvers for the same convex relaxation: (Dvijotham et al. 2018) and (Bunel et al. 2020a).  The work focuses on solving the relaxation exactly. However, as shown in a variety of recent papers (Xu et al. 2021), [Active Set],  [Bunel et al. non-convex 2020], (Wang et al. 2021), heuristics and switching to tighter relaxations (possibly considering branching) might verify more properties in the same time (both in incomplete and complete verification). These developments have been somewhat ignored by the authors.\n\nThe authors should put their work in perspective with more recent and scalable optimizers for the same relaxation: (Xu et al. 2021), [Bunel et al. non-convex 2020]; and with works on tighter relaxations [Active Set]. Furthermore, as commonly done for solvers of the considered relaxation, complete verification experiments are needed to fully assess the quality of DeepSplit's speed-accuracy trade-offs.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}