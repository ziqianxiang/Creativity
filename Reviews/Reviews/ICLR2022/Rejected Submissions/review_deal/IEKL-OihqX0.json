{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper introduces a way of making Ratio Matching (RM) scale better to high-dimensional data when training energy-based models (EBMs). The main idea is to estimate the sum over the datapoint dimensions in the RM objective with importance sampling (IS), achieving computational savings by using fewer samples than dimensions. A key part of the method is a proposal that uses gradient information w.r.t. discrete variables to efficiently approximate the optimal (minimum variance) proposal, resulting in much better performance compared to uniform sampling. The authors also introduce a biased version of the estimator that samples from the same proposal but drops the importance weights when averaging over the samples, which, somewhat surprisingly, outperforms the unbiased version.\n\nThe idea of using Monte Carlo estimation based on importance sampling to speed up Ratio Matching is novel and sound. The use of gradient information to approximate the optimal IS proposal is also novel in this context, though the idea of using gradients this way to reduce the number of EBM energy function evaluations comes from Grathwohl et al. (2021), where it was used to speed up Gibbs sampling.\n\nWhile the method is well described, the paper is insufficiently rigorous in several places, most importantly in claiming that Eq. 4 corresponds to Ratio Matching, which is not true. Eq. 4 is instead equivalent to the objective for Generalized Score Matching (GSM) given by Eq. 17 in (Lyu, 2009). Crucially, while both GSM and RM recover the true model if the model class is nonparametric/unconstrained, as is stated in (Lyu, 2009) (and thus agree with each other as well as with maximum likelihood estimation) ), they do not yield the same solution for constrained model classes such as neural networks. This means that the method in the paper implements GSM and not RM. Unlike RM, which has been used widely in the literature, GSM is essentially empirically unproven and thus is a less interesting choice. The main difference between the GSM and RM objectives is the presence of the squashing function g(u) = 1/(1+u) around the probability ratios in RM to avoid division by zero, when the probability in the denominator is vanishingly small (as is explained above Eq. 12 in (Hyvarinen, 2007)). This means GSM is likely to be prone to stability issues due to using probability ratios directly. This is one possible explanation for the puzzling empirical results in the paper, where the proposed sampling-based methods outperform the exact method they are supposed to approximate, with the biased method clearly performing best. The intuition-based arguments made in the paper to explain these results are not convincing and need to be improved upon. While, as the authors pointed out in their response, it is possible to apply the strategy in the paper to RM by applying IS to Eq. 3 instead of Eq. 4, that would be essentially a different paper.\n\nOne example of puzzling experimental results is Figure 3, which shows that the base method (\"Ratio Matching\") does not find the correct solution while the proposed approximate methods do. This suggests that there is something wrong either with the method (e.g. with the objective, as mentioned above) or with the experimental setup. In either case, the cause needs to be thoroughly investigated.\n\nCurrently the empirical evaluation is primarily MMD based, relying on sampling from the model using MCMC. Ensuring that MCMC chains mix sufficiently well to sample from the true distribution by visiting all of its modes is difficult, and it is important to provide some evidence that this was done. As suggested by a reviewer, the results would be substantially strengthened by reporting the log-likelihoods for the models, estimated e.g. using AIS, even if that requires including scaled-down versions of some of the experiments.\n\nThe title of the paper is misleading and should be changed because the proposed method is specific to EBMs for binary data, even if the intent is to extend it to other types of discrete data in the future.\n\nThe clarification and additional results provided by the authors to the reviewers and the AC were appreciated, but unfortunately the outstanding issues with the paper are too major to allow acceptance at this point. The main idea of the paper has substantial promise however, and the authors are encouraged to develop it to its full potential by addressing the points from this meta-review as well as the additional ones from the reviewers.\n\nBibliography correction: Hyvarinen is the solo author of \"Estimation of Non-Normalized Statistical Models by Score Matching\". Peter Dayan was the editor of that paper and not a co-author. Please correct your bibliography."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a more efficient version of ratio matching (RM) for training discrete energy-based models. The proposed method subsamples the dimensions to use in the original RM objective and then uses importance sampling to reduce variance. The importance sampling distribution is based on a Taylor-series approximation to the target energy function which approximates the minimal-variance importance sampling distribution. The authors show that this estimator is considerably more efficient than standard RM and enables RM to be applied to training EBMs in higher dimensions. The authors demonstrate their estimator on some toy datasets and to fit EBMs on graph data. The method is evaluated using MMD.",
            "main_review": "Strengths:\n\nTraining EBMs on discrete data is a difficult task and few methods currently exist to do so in high dimensions. RM is an appealing option because it avoids the MCMC sampling typically used to train EBMs at scale. The method appears to be a clear win on top of RM (when it can be applied -- not all energy discrete functions can be differentiated). \n\nBeyond this, the method appears correct and valid. My main concerns lie in the method’s ability to scale to higher-dimensional settings than demonstrated in the paper.\n\nWeaknesses:\n\nThe main weakness of this work is in its empirical evaluation. The authors only validate the method in two settings; toy datasets and small graph datasets. Further, their only evaluation is via MMD. Evaluation of EBMs is difficult, but in small-scale settings likelihood can be estimated with AIS. Likelihood-based evaluation would allow comparison to autoregressive models or VAEs, for example.\n\nI am concerned with the comparison to Gibbs-With-Gradients training. How was this done? Did you use PCD? If so, what were your buffer size, refresh rate, and the number of steps per training iteration? PCD can be sensitive to these parameters and if not set properly the results could be very bad. The authors should include these experimental details in the paper (at least in the appendix).\n\nI am not convinced by the scale of the experiments as well. Prior work [1,2] has successfully trained discrete EBMs on datasets with thousands of dimensions. The results in this work are much smaller-scale. Does the method have difficulties scaling to these settings? If so then that is certainly a weakness of the method and it should be mentioned. You could compare results to the MNIST/Potts/Ising training experiments in [1] (no need to do all, but at least one experiment demonstrating scaling ability would be good to have). This would give a better context for the performance of this method relative to other recent approaches. \n\n----------Post Author Response-------------\nI thank the authors for their response to my feedback. I appreciate the new experiments. I think they give additional clarity on how the method performs and scales to higher-dimensional data. I am convinced the method has merits and I will raise my score to a 6. I am still concerned that the method will have difficulties scaling to more complicated problems/models and the current results do not demonstrate that. Having said that, this method is generally applicable and could be a valuable contribution to the community. \n",
            "summary_of_the_review": "The paper proposes an interesting and novel variant of RM that enables it to get around the memory/compute constraints of the original method. The method appears valid and appears to work but the empirical evaluation is lacking likelihood evaluation, experimental details, comparison to recent approaches and does not demonstrate that the method can scale to relevant problems. Unless these issues can be rectified, I cannot argue for the paper's acceptance. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper propose a Monte Carlo approximation for the expensive ratio matching method for learning discrete energy-based models. The key idea is to first write the ratio matching objective as an expectation wrt a uniform distribution, then use importance sampling for a more efficient estimation, where the optimal proposal distribution can be approximated by the gradient of the energy wrt the data space. Empirically, such an approximation shows even better results than the original expensive objective, possibly due to regularization from stochasticity and more focus on neighbors with low energies.",
            "main_review": "Strengths: \n- The paper is well written and contains detailed method derivation and discussions. Overall, it is easy to follow.\n- Nice discussions to related works.\n- The method derivation is sound and the proposed solution is a reasonable way to alleviate the expensive computation/memory requirement of the original ratio matching approach.\n- Although motivated from computational perspective for fast approximation of an expensive quantity, the proposed method even achieves a better performance than original method in most tasks, which is a surprising result and achieves both computation and performance improvement. The intuitive explanations look reasonable to me.\n\nWeakness/Questions:\n- The proposed approach seems to heavily rely on the assumption that the data is binary, which is not applicable to more realistic data such as natural language modeling (or even graph with different types of nodes and edges?). Indeed, an efficient and effective generalization of ratio matching to non-binary discrete data seems more challenging, interesting and useful.\n- The taylor approximation in eq (8) may not be accurate enough since the difference between x and x_-i is not close to zero. So the approximation error might be larger depending on the structure of the energy function (e.g. non-smooth) and the number of dimension (for d=2, x and x_-i may be very different in the sample space).\n- In table 1, there is no standard deviation calculated from multiple random seeds. Also why biased version is better than unbiased version in most experiments?\n- After obtain the energy function, how do you generate graphs? (I suppose using Gibbs sampling?)\n- Potential issue with Table 2: I think you are using the same s (number of proposal samples) for various data dimension from 32 to 2048. However, we typically need larger s for larger dimension d to ensure good performance, and in this case, the speedup/memory saving may not be that large?\n- All experiments are \"toy\" data, possibly because the method is limited to model binary data.",
            "summary_of_the_review": "Please see the detailed comments section.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The authors propose a new gradient-based importance sampling scheme, applied to learn parameter in energy-based models (EBMs).",
            "main_review": "The paper seems to contain interesting material. Some point must be clarified.\n\n- How to draw samples from your proposal n(x)? this is the main issue in your method.\n\n- Please clarify the relationship with the papers:\n\nV. Elvira, L. Martino, D. Luengo, J. Corander, \"A Grandient Adaptive Population Importance Sampler\", IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2015.\n\nIngmar Schuster, Gradient Importance Sampling, arXiv:1507.05781, 2015.\n\n",
            "summary_of_the_review": "The paper seems to contain interesting material, however the degree  of novelty seems to be a bit incremental.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes ratio matching with gradient-guided importance sampling (RMwGGIS) as an attempt to address the expensive computation and excessive memory requirement of ratio matching in learning discrete energy-based models, and demonstrates the advantages of RMwGGIS over ratio matching with experiments on density modeling and graph generation.",
            "main_review": "## Strength:\n\nThe paper is well motivated, clearly written, and seems technically sound. The paper does a good job in analyzing the limitations of ratio matching in expensive computation and excessive memory requirements, and in describing how it can leverage the gradient of the energy w.r.t. the discrete data space to address these limitations. The idea is simple, but can potentially be very useful in making ratio matching more practical for learning discrete energy-based models.\n\n## Weaknesses:\n\n- While the paper demonstrates improvements over vanilla ratio matching, it lacks comparison with other types of methods for learning discrete energy-based models. For example, maximum-likelihood training with MCMC sampling (e.g. with Gibbs sampling or the more advanced Gibbs-with-gradients, which the authors acknowledge is a big inspiration for RMwGGIS), can be easily applied to the same problems, and should be included as additional baselines. While the improvements over ratio matching are nice, if RMwGGIS cannot outperform other readily available methods, then it picked the wrong method to improve upon, and its improvements over ratio matching cannot be justified.\n- I am not convinced by the current arguments in the section **Better optimization?** in Sec. 3.3, and I don't think this point is verified empirically as the authors claim. As the authors mention at the end of page 2, the estimator given by Eq. (3)/(4) is consistent, and if Eq. (3)/(4) is minimized perfectly, the obtained model distribution will capture the data distribution exactly. The authors claim that RMwGGIS, with a biased estimator, performs better than ratio matching due to better optimization. Does that mean that the theta learned with the biased objective function (12) actually results in lower value for the objective function in Eq. (3)/(4)? I.e. somehow optimizing a different objective function (Eq. (12)) leads to better optimization of Eq. (3)/(4) than directly optimizing Eq. (3)/(4)? I would like to see this confirmed in experiments (which is a very simple evaluation). If it's really the case, I would like to see some analysis on why this is the case, since Eq. (12) is picked somewhat randomly, without theoretical justification as Eq. (7). If this is not the case, then there is no better optimization, which means Eq. (3)/(4) is not a good objective function, and the paper should rethink its foundation, or explain where the better performance comes from.\n",
            "summary_of_the_review": "While the paper is promising, given the two major concerns above, I don't think the paper can be accepted in its current form, and recommend weak reject.\n\n---------------------------\n\nWhile the authors clarified certain points, after the discussions I still have concerns over the overall presentation. Although the method demonstrates promising results, I don't feel the theory is properly explaining the improved performance, and more analysis/investigation is needed to clarify the claimed hard sample mining perspective. I still recommend rejection.\n\nThe authors have repeatedly tried to force their conclusions on me in their response. I want to emphasize that I still don't find the presentation to be convincing, and I believe the paper in its current form hasn't sufficiently analyzed an important point it touched upon.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}