{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "Thank you for your submission to ICLR.  There is some disagreement about this paper, and several of the reviews are of relatively low confidence.  While I appreciate the effort that the authors have put into addressing the concerns of the reviewers, after going through the paper and the responses myself, I'm ultimately coming down on the side of the less positive reviews.  My reasoning, honestly, is that I think the authors are vastly overestimating the knowledge that the ICLR audience will have about numerical methods for PDE solutions.  Reading through the paper, I honestly have very little idea about how the actual numerical techniques are carried out, and it's unclear to me precisely where this method falls in between a traditional numerical solver an actual neural network.  Reading through the reviews, even the more positive ones, I don't think I'm alone in this perception (and the authors will hopefully believe me that these reviewers _are_ indeed emblematic of the subgroup of ICLR that is most experience with differential equations).  I really feel like either a substantial rewrite of the paper is needed, to make clear the full extent of the numerical methods being applied; or alternatively, the work may really be better suited for a numerical methods venue."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "In this work, the authors propose the finite volume neural network to solve advection-diffusion partial differential equations. The authors define a flux kernel as the sum of sub-kernel f_i on each element. And the authors define specific modules \\phi_D, \\phi_A, \\phi_N according to the form of the advection-diffusion equation. The model requires very few parameters to achieve the state of art results.",
            "main_review": "This is a very concrete paper with solid experiments. \nTo better assess this work, I would like to ask several questions:\n\n1. I find it misleading to call this model \"compositional neural network\", which usually refers to composing neural network as f \\cdot g = f(g). If I understand correctly, it is not what the paper does.\n\n2. If I understand correctly, the FINN model computes the derivative using the finite-difference method. It can be understood as a learn FDM/FVM stencil. I wonder how it compared to other learned FDM methods such as Machine learning–accelerated computational fluid dynamics by Brenner et. al.?\n\n3. If there is a spectrum of ML models vs conventional numerical solvers, I think this FINN method lies closer to the end of numerical solvers (which is nothing bad). Solver-like methods usually require fewer parameters and generalize better. Therefore, I think it could be valuable if the authors can add some numerical experiments comparing against the numerical solver. Are there any advantages (speed, accuracy, etc) to using the learn FVM vs the original FVM/FDM?\n\n4. Standard advection-diffusion equations are relatively easy to solve. I wonder if the idea proposed in this paper can be generalized and transferred to other PDEs?\n",
            "summary_of_the_review": "I think the paper is above the threshold. If the authors can provide evidence that the proposed method outperforms (or has some relative advantage) compared to standard FVM solvers, I will be happy to raise the score.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper presents a compositional physics-aware neural network (FINN) for learning spatiotemporal advection-diffusion processes. It claims that the FINN outperforms pure machine learning and other state-of-the-art physics-aware models in all cases—often even by multiple orders of magnitude. However, the design of the network depends too much on the form of the equation, which leads to a very narrow application of the method.",
            "main_review": "Strengths\n\nThis method can not only deal with smooth solutions of general PDE but also can deal with weak solutions of hyperbolic problems, which is a good point; It is also compared with many recent SOTA methods and is significantly ahead of recently published methods\n \nWeaknesses\n\nThe method limits the form of the equation, which will greatly increase the training complexity when it is extended to higher-dimensional problems\n\nThe problems studied by this method are relatively simple and are the fitting of some linear problems or low-order nonlinear problems. I am wondering if polynomial fitting will get better results.\n\nSome test examples can be supplemented. Such as equations containing an exponential function, the fitted coefficient containing singularity, or can this method be used for fluid equations, etc. \n\nThe robustness test of this method is absent. Can this method be used for noisy data?\n\nThe discussion of method limitation is absent.\n",
            "summary_of_the_review": "The demonstration of this method is pretty good, but there are too many restrictions on the problem. If the form of the equation is fixed, a simple polynomial fitting may achieve a better fitting effect than the neural networks. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper introduces Finite Volume neural network for modelling fluid dynamics inspired by the finite volume method. The paper models the velocity and the spacial derivatives as the neural networks. The work demonstrates more precise fluid simulation than the related physics-inspired models.",
            "main_review": "**Strong points:**\n\nThe paper provides significant improvement in performance in comparison to other models in a few orders of magnitude using 3-5 times less parameters than related models.\n\nThe results also suggest that modelling the spacial derivatives du / dx with the neural network directly results in better generalisation than modelling u(x,t and taking the derivative with respect to x (similar to PINN and other similar works). This is an interesting and counter-intuitive conclusion and worth of further exploration.\n\n**Weak points:**\n\nThe paper requires more explanation on the structure of the model. What is the input to phi_N, phi_A  and phi_D? How is R computed (it is not part of the equation in figure 1)? In Figure 1, why does phi_N signify both the first and the second spacial derivatives of u?\n\nIf the neural networks phi take only the values u, how are u(x,t) computed at the first time step? \n\nBased on figure 1, the right-hand side of the equation is a combination of four neural network outputs. Do you think it is equivalent to replacing phi_D phi_N - phi_A phi_N with a single neutral network taking all u_{i-1}, u_i, u_{I+1} (which essentially turns it into a Neural ODE model)?\n\nIt would be helpful to emphasise the differences between FINN, PINN and PhyDNet and other models in the methods section. Some of this explanation is provided in section 4.1, but it is worth emphasising and explaining more how the models differ, what exactly is modelled by a neural network and the motivation why FINN performs better than other models.\n\n\n**Questions:**\n\nPage 7: “PINN requires complete knowledge of the modelled system in form of the equation”. In this case, I am puzzled by a worse performance of PINN in figures 6 and 7 compared to FINN, if PINN closely follows the PDE that generated the data. Can you provide some insight why FINN performs better than PINN in this case? \n\nSimilarly, can you clarify why PINN requires more parameters than FINN (table 1)? Is it due to the fact that PINN also models the function u(x, t) or because of the bigger network?\n\n",
            "summary_of_the_review": "The results in comparison to other models are compelling, particularly the model comparison on figures 6 and 7. However, the methods section of the paper needs more clarification and justification of the modelling choices in comparison to other papers. As the paper requires a significant re-write, I suggest a reject.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors propose to model advection-diffusion partial differential equations as a composition of multiple neural networks. According to the authors, this leads to better generalization over different initial and boundary conditions for the physics system, and also the ability to learn different factors of the process as modeled by the terms in the PDE. Extensive experimental results are presented to support the author’s claims that their framework performs better than state-of-the-art.",
            "main_review": "Strong points:\n1.\tThe authors propose very detailed experimental results, with both synthetic and real data\n2.\tThe background is provided in detail as well\n\nWeak points:\n1.\tThe authors claim in section 3 that convolution layers can only accommodate single types of boundary conditions. However, this is not correct since convolution layers at present can also handle cases I.e. periodic boundary conditions, this sentence may need rewriting\n2.\tIn figure 1, phi_N is shown to be both first and second-order derivatives, which may create confusion for the reader.\n3.\tThe training process is not completely clear, the authors describe the forward process, one would assume backpropagation of error for updating the neural network, but this is not explicit in the text. A figure demonstrating the whole training process, including the feedback loop might be helpful\n4.\tAt the end of section 3, the authors claim to use NODE in place of Euler for the reason of numerical stability, however, NODE also used Euler and does not mention anything about adaptive time-stepping, more details on this part would help to clear things up\n\n",
            "summary_of_the_review": "The paper has very thorough experimental results and good descriptions of the methods. However, the claims made in the paper may need a second look/ need some rewriting.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}