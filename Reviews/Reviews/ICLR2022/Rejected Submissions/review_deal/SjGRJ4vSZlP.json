{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper studies an interesting problem, but as pointed out by reviewers, the presentation of the problem statement and contributions need to be improved."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The authors consider the incremental autonomous exploration problem. That is, the agent faces an MDP and wants to learn near-optimal goal-conditioned policies to reach the states that are L-controllable, i.e. incrementally reachable from an initial state s_0 within L steps in expectation. The learning procedure is the following: the agent collects transition by interacting with the MDP, decides to stop, and outputs a set of states (that should be the L-controllable states) and a policy for each state ( that should be the associated near-optimal goal-conditioned policy). The authors propose the Value-Aware Autonomous Exploration (VALAE) algorithms. It works in 3 phases: in the first one a sub-algorithm Value-Optimistic Incremental State Discovery (VOISD) aims at identifying the set of  L-controllable states then sub-algorithm Reduce Autonomous Exploration to Multi-Goal SSP (Re-MG-SSP) as burn-in sample collector, finally a procedure close to the one of UCBExplore by Lime and Auer (2012). They prove a bound on the sample complexity ( the number of steps before the algorithm stops) of order O(L S_{2L} A / \\epsilon^2 ) where S_L is the number of  L-controllable states, A the number of actions, \\epsilon the error tolerated for the goal-conditioned policy. This bound improves prior results by Lim and Auer (2012) and Tarbouriech et al. (2020) with respect to the dependence on \\epsilon or L. The authors also proved a lower bound of order  \\Omega(L S_{L} A / \\epsilon^2 )  implying that  VALAE is nearly minimax optimal if S_L grows polynomially with L.",
            "main_review": "The paper is globally well written (see specific comments). I suggest defining at the beginning the learning framework, the (\\epsilon,\\delta) conditions for the different criteria and the sample complexity. I am not convinced by the proofs (see specific comments): some proofs are missing and some points are not clear (see specific comments about the proof of Lemma 9 and Theorem 1). I did not check the proofs of the lower bound. I think that the characterization of the rate for the incremental autonomous exploration problem is a valuable contribution. On the other hand, I find the proposed algorithm a bit involved (see specific comment).\n\nI could increase my score if my concerns about proofs are cleared up.\n\nMain comments: \n-The algorithm is somewhat involved and not very natural. I think that the authors could have put more effort in the description of the algorithm and in providing intuition.\n\n-Can you provide preliminary experiments to illustrate how the proposed algorithms behave on very simple MDP?\n\n-Can you provide the time complexity and space complexity of VALAE algorithm? \n\nSpecific comments:\n-Introduction: the sentence \"This procedure also resembles some biological learning processes\" is a bit cryptic.\n\n-P1, note 1: It seems that there is an extra L in the big O.\n\n-P4, end of the page: the learning framework is not completely clear: how does the agent interact with the MDP? when does the agent stop and output the policies (is T chosen by the agent)? \n\n-P5, end of the page: the sentence \"Then for each action [..] \\hat{c}(s,a)\" is not clear at all.\n\n-P6, Alg2, L5: typo \"where x is defined\".\n\n-P8, top of the page: The first paragraph is hard to follow since we do not know at this point what are Lemma 15 and 16.\n\n-P9, above Definition 3: maybe you could have defined an algorithm for AX/* before in the introduction.\n\n-P11, Lemma 2: Which concentration inequalities? This lemma should be proved even if it is a classical proof.\n\n-P12, Lemma 4: You need an extra assumption on the \\tau_k such that independence to be able to apply Hoeffding inequality.\n\n-P15, end of the proof of Lemma 9: Can you detail why | P_{s,a,s'}  - \\tilde{P}_{s,a,s'} | \\leq \\frac{c_min \\epsilon} {6(L+1)}, it is not \ncompletely obvious for me. And to apply Lemma 3 you need a control in norm 1 and not in infinite norm so there is a S factor missing here?\n\n-P17, proof of Theorem 1: can you detail why on \\cG_2 you get \\hat{P}_{s,a,g} \\geq 3/4 L if \\P_{s,a,g} \\geq1/ L? Typo \"previous paragraph\". \n\n-P17, end of the proof of Theorem 1: can you write explicitly what is the event that happens with probability 1-\\delta/4 to collect the sample? Because a priori for a given state s the policy used to reach s is random. Furthermore to use that V^\\pi \\leq L you used Lemma 9 that is you conditioned by the event \\cG. Thus it is not clear that conditioned don this event the samples remain independent/ have the same distribution in order to apply Lemm 3.  Thus you cannot do a simple union bound over the state as it seems to be done also over policies. Maybe you should rather concentrate a well-chosen martingale.\n\n-P18, proof of Theorem 2: same remark as above.\n\n-P19, Lemma 14,15: can you provide proof for Lemma 14 and 15? In particular, in Algorithm 3 the Visgo procedure is called with \\epsilon_VI = 2^-j... and to prove these two lemma you need according to the proof of Lemma 9 and 10 a lower bound on the number of visits of all state-action pairs that scales with \\epsilon_VI .",
            "summary_of_the_review": "See the main review",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No concerns",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studies the autonomous exploration problem and multi-goal SSP problem, and proposes three algorithms with improved cumulative costs on 4 learning objectives. The authors also construct a hard instance and show the lower bound of the cumulative cost. Their bounds are optimal in terms of $L, A, \\epsilon$. The main technical contributions are a new series construction of $\\mathcal{K}$, the connection between autonomous exploration and multi-goal SSP, and the construction of the hard instance.\n\n",
            "main_review": "For the positive side, the expression and organization of the paper is good. It is comfortable to read the paper and understand the critical points made by authors. The series construction argument and the connection between AX and multi-goal SSP is also very interesting. The proposed lower bound complements the AX theory largely. \n\nFor the negative side, I have a few concerns:\n1.\tIt appears to me that the VALAE algorithm is a simple extension of EB-SSP from single point SSP to multi-goal SSP on the MDP induced by the first two algorithms. This somehow reduces the novelty of the paper. \n2.\tThe data collection procedure of the algorithms rely heavily on the RESET action, as if there are a generative model. I wonder if we can design some algorithms to direct the agent from any state back to $s_0$, rather than relying on a RESET action. As far as I’m concerned, such reliance drops a lot of data\n3.\tThere are many examples and detailed explanations, reducing the readability of the paper. This makes readers miss the important conclusions, but stick to those descriptive sentences.\n4.\tI am not sure about the technical novelty of the hard instance constrcution. It appears that the construction is much similar to the one proposed by Rosenberg et al. (2020). You both follow the novel construction proposed in the paper of UCRL2. The constrcution also looks similar. Please make it clear if there is any new idea.",
            "summary_of_the_review": "The paper is generally well written, though some paragraphs need shorten. The technical contributions are a little confusing to me, so I recommend the boardline reject.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studies the sample complexity of learning algorithms for autonomous explorations (AX). Theoretical results showed that the proposed algorithm (VOISD, VOISD+Re-MG-SSP, VALAE) achieved better sample complexities than the existing two studies. The authors compared the methods by setting the uniform cost. Further, the proposed algorithm seems to have more general performance.",
            "main_review": "# Pros and Cons\n\n## Pros\n\n- Proposed algorithms achieved better sample complexities on different criteria, as summarized in Table 1.  As I understand correctly, the four criteria are based on the existing literature but more clearly discussed and summarized in the four columns. Further, a restriction on the cost $c$ is relaxed by $c_\\mathrm{min}$; that is, the authors generalize the problem settings.\n- The proposed algorithm is well described (it is as complete and interpretable as those in two existing works UcbExplore and DisCo).\n\n## Cons\n\n- Some knowledge about autonomous exploration is used before the definition or references (i.e., Sec 1 is a bit complex without Sec 2 and reference papers).\n- Readers are hard to follow all the details of theoretical proofs (much longer than the main content).\n- No experimental results (cf., [Tarbouriech et al. 2020] contains some experimental evaluations)\n\n# Comments\n\n(I) A part of the statement in this paper is unclear for me.\n\nIn [Tarbouriech et al. 2020], the authors seem to say that the sample complexity is $\\tilde{O}\\left(L^5 S_{L+\\epsilon}\\Gamma_{L+\\epsilon}A/\\epsilon^2\\right)$ under the definition of $\\mathrm{AX}^\\star$ of $\\forall s\\in\\mathcal{K}, v_{\\pi\\_s}(s\\_0\\to s) \\leq V^\\star\\_{\\mathcal{S}^{\\to}\\_L}(s\\_0\\to s) + \\epsilon$ (I copied this equation from Def.5 of [Tarbouriech et al. 2020]).\n\nThis definition is a slight different from the submitted paper (i.e., $(1+\\epsilon)L$ vs $L + \\epsilon$ or $\\epsilon$ vs $\\epsilon L$ or ?). Then, I cannot follow the part of Table 1 (it says $\\tilde{O}(L^3+S^2_{(1+\\epsilon)L}A/\\epsilon^2)$). I feel that such correspondence could be explained a bit more clearly because the complexity statements are core contributions of the paper for possible readers.\n\n(II) Please clarify the assumption of algorithms.\n\nIn Alg.1, the input is an MDP $M=\\langle\\mathcal{S, A}, P, c, s_0\\rangle$. However, from the _Learning Objective_ part, an agent has no prior knowledge of $P$ and $c$, then I wonder how we can input such an $M$ to Alg.1. I guess I misunderstand some parts of the algorithms.\n\n[Just a comment] The mathematical notations (Sec 1.2) are used prior to the definition (Sec 2). This makes readers hard follow the 'overview' of the paper. One approach to mitigate this issue is the paper stats with Sec.2 (i.e., a similar way of Tarbouriech et al. 2020), but I can also understand the current form of the structure.\n\nSome minor comments and questions.\n- p2. $P_{s,a}$ and $\\hat{P}_{s,a}$ are the true and estimated transitions. Are these evaluated for all $s, a$? or partially discovered states on $\\mathcal{K}$?\n- p3. $z\\in \\{0,1,\\dots,Z-1\\}$ to incrementally define $\\mathcal{K}_z$?\n- p3. notation $\\max_{s\\in\\mathcal{S}} |X(S)| \\to \\max_{s\\in\\mathcal{S}} |X(s)|$ as |S| means the number of states\n- p3. Please describe the semantics of $\\mathbb{V}(X, Y)$. I wonder, is it $X(s)^2 Y(s)^2$? (why the square is only for $Y(s)$?).\n- p18. Notation $A[n(s,a)]$ is not defined?",
            "summary_of_the_review": "The statement of the problem is clearly stated, and good theoretical results are reported with substantial proof. As I read and check, algorithms seem to work. Then, I feel that the proposed result is valuable for the field.\n\nA disadvantage of this paper is that most proofs are included in the appendix, and therefore it is hard to follow and validate the correctness of the paper. To be honest, I cannot validate the correctness of all proof. I feel that the paper should be published as a journal article (e.g., Theoretical Computer Science).",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studies the incremental autonomous exploration problem and introduces algorithms with improved sample complexity.\nIt also provides the first lower bound for the problem.",
            "main_review": "The paper studies an interesting topic and makes a significant contribution by presenting the first lower bound and improved upper bounds.\nHowever, I have many problems with its presentation and technical novelty:\n1. The authors did not provide the appendix in the supplementary material. Instead it is attached to the main paper in the same pdf file.\n2. The multi-goal SSP problem is not presented clearly. In fact, I am not sure if I understood it correctly. Is this problem simply the autonomous exploration problem where all of the states of the MDP are $L$-controllable? If so, then this is not really an interesting problem since the authors (and previous work) already solve a more general problem. Moreover, I don't  understand why the name multi-goal SSP suits this problem since it does not seem like a generalization of SSP. Isn't this problem simply reward-free RL?\n3. The authors refer to SSP quite a lot, but they never introduced it properly. The introduction of the multi-goal SSP problem is not clear, but maybe it could be clearer if the authors presented the standard SSP problem first. Furthermore, the authors use many techniques from SSP (e.g., Tarbouriech et al. 2021) so they should really dedicate at least one paragraph to discussing the algorithmic ideas behind SSP algorithms and give the relevant references (all of these references can be found in Tarbouriech et al. 2021).\n4. The technical novelty in the algorithms is not clear to me. Algorithms 1 and 2 look exactly like the algorithms of Tarbouriech et al. 2020, and the only difference is that they use a tighter optimistic planning algorithms (the VISGO algorithm of Tarbouriech et al. 2021). Are there any other new features or difficulties in the analysis? It makes sense that the upper bound is better than Tarbouriech et al. 2020 by a factor of $S$ (actually I think it should also save a factor of $L$) but it does not seem like there is anything new here. If there are technical difficulties then the authors must highlight them and present the ways that they deal with them. In addition, I think that algorithm 3 does not have any real benefits. It trades a factor of $L^2 S_{(1+\\epsilon)L}$ for a factor of $S_{2L}$, but is it really better? To me it looks like (in most actual applications) $S_{2L}$ would be at least of order $(S_L)^2$ and definitely larger than $L$.\n5. The lower bound sketch is not clear at all. In my opinion it should have a lot more focus since this is the first lower bound for the problem. After reading the proof in the appendix, the construction looks almost the same as the lower bound for SSP in \"Near-optimal regret bounds for stochastic shortest path\" (Rosenberg et al. 2020). Are there real differences here? Is the required analysis different? I am having a hard time understanding why this lower bound does not simply arise from the SSP lower bound.\n6. The authors claim that Tarbouriech et al. 2020 study uniform cost of 1, but it looks like section 4.3 in their paper they extend the results to non-uniform cost. Can the authors please comment on that? I would also be interested in the authors opinions regarding costs that may be zero (i.e., $c_{min}=0$). In SSP, strictly positive costs are a much easier case (almost similar to uniform cost of 1), so I wonder how can zero costs be handled in autonomous exploration.",
            "summary_of_the_review": "The paper studies an interesting topic and give improved sample complexity guarantees. However, the authors fail to present their contributions, novelties, difficulties and techniques clearly.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}