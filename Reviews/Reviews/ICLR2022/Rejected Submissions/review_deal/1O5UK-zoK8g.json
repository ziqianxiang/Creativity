{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This submission presents a technique to improve generalization of urban scenes segmentation.  Based on a pre-trained deep net on synthetic data, the approach aims at adapting statistics on real target domain such as Cityscapes, BDD or IDD datasets using an Instance-adaptive Batch Normalization (IaBN) at test time. Results are reported on several synthetic to real scenarios.\n\nMost of the reviewers were not convinced by the approach and have raised several issues. After rebuttal and discussion, no one really changed her/his mind. The novelty of the proposed method is limited to the use of the existing IaBN in this context except the one-sample adaptation.  Although the proposed method is effective on some benchmarks, the extra processing time may be a significant limitation. Additional comparisons are necessary. We encourage the authors to consider the reviewers feedbacks for future publication."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents a method on generalization of segmentation from synthetic data to real street scene data. To adapt the model pre-trained with synthetic source domain data such as GTA and SYNTHIA to target domain such Cityscapes, BDD and IDD, the authors proposes Instance-adaptive Batch Normalization (IaBN). In addition, as a method to learn from a single sample, TT-SEG was proposed\nin which a pseudo GT mask is estimated from augmented images with the initial model and the last parts of the network are finetuned with the pseudo GT mask. In the experiments, the proposed method which employs both IaBN and TT-SEG successfully outperformed all the baselines, which indicated the effectiveness of the proposed method.\n\n",
            "main_review": "Pros)\n\nThe paper is well written and easy to understand. The experiments including comparison to baselines and ablation studies seem to be comprehensive.\n\nCons)\n\nThe idea on combining BN and IN has been proposed before. The novelty is limited. In addition, in this work, the hyperparameter, alpha, has to be decided by validation data.\n\nTT-SEG is a simple method for test-time finetuning. Although the effectiveness was shown by the experiments, the novelty seems to be limited.\n\nThe description on baselines such as ASG and CSG in Related Work is too brief to understand the principle difference to the proposed method and among them. \n\nTaking six seconds is too much from practical point of view. As the authors mentioned, the proposed method is unpractical for road scene analysis.\n\nComment)\n\nWhy was ECE used only for Table1(b) without showing MIoU ? Is MIoU also improved by introducing MC-Dropout ?\n ",
            "summary_of_the_review": "The novelty of the proposed method is limited, since IaBN is an existing method and the method on one-sample adaptation is straight-forward. Although the effectiveness of the proposed method regarding performance was shown by the experiments, the required processing time was too much. From these points, this paper is regarded as being around the border.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper contributes two techniques to improve generalization of semantic segmentation networks. The first technique is an adaptation of the test-time behaviour of batch normalization, where the statistics of the sample under consideration are blended into the training-time statistics of the batch-norm layer. The second technique is to use test time augmentations to first derive a pseudo-labeling from the sample and then to update parts of the weights to maximize the probability of the pseudo-labels. The paper additionally contributes a multi-dataset evaluation procedure and shows favorable performance of the proposed techniques on this evaluation protocol.",
            "main_review": "Strengths\n\n- Test-time training is an interesting concept and the paper spans a nice logical bridge from the first, technical rather minor conribution, that improves calibration of the prediction to leverage areas that are likely predicted correctly to further improve th inference results.\n\n- Interesting, but a bit heuristic, combination of test-time training and pseudo-labeling.\n\n- Good results and broad evaluation.\n\nWeaknesses:\n\n- Inference speed: Test-time training is by definition rather costly and the proposed approach increases runtime by more than an order of magnitude when compared to the baseline. It is unclear how to improve the practicality of the approach.\n\n- When comparing to Wang 2021a it is not clear to me how much improvement actually comes from using multi-scale predictions and augmentations. It would be great to have an experiment along these lines.\n\n- No comparison to (offline) pseudo-labeling approaches (a recent example would be [A]). The overall strategy would also be applicable without test-time training in principle. I.e. one could derive pseudo-labels for the whole target dataset and adapt the classifier once on the full target dataset. While the assumption here is that only a single image from the target domain is available, the setting seems to be rather artificial as a few unlabeled images from the target domain should almost always be available (and test-time training might help on top of such a transfer procedure).\n\nOther questions:\n\n- It would be interesting to see some failure cases (if any). Does test-time training always improve results?\n\n[A] Zou et al., PseudoSeg: Designing Pseudo Labels for Semantic Segmentation, ICLR 2021\n\n",
            "summary_of_the_review": "I think the overall approach is interesting, but ad-hoc in its design. It would be great to see some comparisons to existing pseudo-labeling approaches as I think that the setting with only a single image from the target domain artificial.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The article proposes two techniques for test-time adaptation. The first is instance-adaptive bn, to combine statistics from source data with each single test sample.  The second is test-time training, based on pseudo labeling of the test sample. The two parts lead to promising results.",
            "main_review": "Pros:\n1.\tThe writing is good, making the paper very easy to understand.\n2.\tBoth the two modules are conceptually simple. \n3.\tExtensive experiments have been performed for evaluation.\n4.\tCode is provided.\n\nCons:\n1.\tMy major concern goes to the novelty of the paper. The proposed normalization technique is incremental. Instance-level normalization is a smart way for test-time adaptation, which has been well studied [1][2][3]. For the test-time training part, it is also hard to claim a unique contribution since it mostly follows a pseudo labeling-based segmentation paradigm. \n\n  [1] Test-time adaptable neural networks for robust medical image segmentation\n  [2] Autoencoder based self-supervised test-time adaptation for medical image analysis\n  [3] Tent: Fully Test-Time Adaptation by Entropy Minimization\n\n2.\tIt is not clear to me the advantage to learn \\alpha using a validation set, rather than online learning during test-time finetuning. \n3.\tThe necessity to use an independent development set for model/parameter selection needs more studies. It is also not clear to me how to select a universe development set that can fit any target domain, or should we find a unique dev set for each target domain.\n4.\tThe model is currently evaluated using relatively lightweight backbones (Res50, HRNet18), and it is not clear whether the method can work well for larger models (e.g., Res101, HRNet48) and lead to consistent improvements.\n",
            "summary_of_the_review": "Overall, the paper has some merits (e.g., good writing, promising results). However, the technical contributions seems to be minor. I am concerning that the paper may be still under the level of ICLR.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studies an existing problem - domain generalization for semantic segmentation of urban scenes. The technique keys of this work has two main points: instance-adaptive batch normalization and testing-time training using pseudo labels. Instance-adaptive batch normalization aims to bias to the data distribution of individual testing examples, which is a tradeoff of previous t-BN and p-BN. This paper generate pseudo labels for test-time training, which is not quite novel. To evaluate the effectiveness of the proposed method, this paper conducts experiments on GTA5/SYNTHIA -> Cityscapes, BDD100k and IDD, and shows better results.\n",
            "main_review": "There are strengths of this paper: \n+ The paper is overall well-written and the reviewer can easily follow the whole draft and get the key points of this paper. \n\n+ This paper shows consistent better than previous method. Besides, this paper also analyze two components of this work to demonstrate the effectiveness of their work. According to the experiments  and ablation study using GTA5, Cityscapes, BDD100k, IDD, their method achieves more favorable results than some previous methods including t-BN and p-BN, where their method is a tradeoff between them.  Besides, this paper also shows better results than previous test-time training method. \n\nThe weakness of this paper are as follows:\n- The novelty of this work is the main drawback. The first point instance-adaptive normalization is a trivial solution, which is the tradeoff of previous t-BN and p-BN. Second, there are a lot of work applying pseudo labels in semantic segmentation, such as Naive-students [ECCV2020]. Even though this work leverages pseudo labels for a different application, the technique contribution is not strong.\n\n- Comparison to more previous work [a,b,c] in domain generalization in semantic segmentation is needed. \n[a] RobustNet: Improving Domain Generalization in Urban-Scene Segmentation via Instance Selective Whitening, CVPR, 2021.\n[b] FSDR: Frequency Space Domain Randomization for Domain Generalization, CVPR, 2021.\n[c] Domain Randomization and Pyramid Consistency: Simulation-to-Real Generalization without Accessing Target Domain Data, ICCV, 2019.\n\n- In instance-adaptive batch normalization paragraph, the authors use \\head{u}_{c}^{s}, but in Eq (4), the authors use u_{c}^{s}. Need to confirm the notations in the paragraph.\n\n- In the experiments, the paper uses 0.1, 0 and 1 for the alpha in Eq 4, where 0 and 1 are the baseline method. Is the method sensitive to alpha in acheving good results, more analysis is needed. For various target datasets, they have different levels of domain gap, it is unclear how to choose the parameter for \\alpha.\n\n\nQuestion:\n1. What is the motivation to test on the expected calibration error with a combination  of MCDropout ?\n2. How to choose alpha for Eq. 4? \n\n\n",
            "summary_of_the_review": "This paper presents a new model and pipeline for domain generalization in semantic segmentation. Although this work shows better results than previous work. Lacking of novelty and insights is the main drawback of this work. Besides, the experiments can be improved, that more comparisons with previous work is helpful. Therefore, the reviewer rates this paper marginally below the acceptance threshold. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I don't have any ethics concerns.",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}