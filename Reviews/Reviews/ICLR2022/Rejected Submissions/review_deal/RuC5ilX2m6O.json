{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper proposed an approach to search image augmentation policies. The paper formulates this problem as a cooperative multi-agent decision-making problem, which is interesting. The paper received 3 borderline accept and 1 borderline reject ratings. The reviewers originally had multiple concerns regarding the necessity of RL-based approach, lacking references, and additional experiments, and the authors responded to some of the concerns of the reviewers reasonably. However, none of the reviewers ended up strongly supporting the paper, staying with their ratings.\n\nThe RL formulation of the problem is interesting, but it requires multiple rounds of the target network training due to its nature (i.e., it is not an end-to-end approach). The paper misses some details on how exactly the patch-wise RL-based augmentation works and it requires additional hyperparameters for the selection of patch size and shape. It is also unclear how this RL-based method is conceptually superior to previous augmentation approaches and the empirical results are not strong enough, as some of the reviewers also pointed out.\n\nAlthough the paper has interesting ideas and the AC also think the paper has some merit, the senior AC finds the technical contribution of the paper weaker than the others. We unfortunately need to recommend the rejection of the paper."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper target the task of automatically determining the best augmentation method to obtain improved accuracy. While the previous related studies focus on the image-level augmentation and ignore the semantic information of the augmented images, the proposed algorithm augments the grid-wise patches of the given input with the preserved semantic information. To overcome the enlarged number of combinations to consider all the patches, the algorithm utilizes the MARL algorithm with the unified reward function. By MARL algorithm, the number of parameters can be reduced and the training speed can be much improved, compared to the previous auto-augmentation methods. Through the image classification and fine-grained image recognition tasks, the proposed algorithm was validated, and it shows the state-of-the-art performance among the compared methods.",
            "main_review": "Strengths\n+ It seems effective to utilize the MARL algorithm to reduce the computational complexity for the multiple patches.\n+ As a result, the computation cost of the proposed algorithm becomes much reduced when it is compared to the previous auto-augmentation algorithms. Furthermore, the algorithm can select the optimal combinations at every epoch without any additional computations, which can improve its generality across the various tasks.\n\nWeaknesses & Questions\n- About state and observation. In the proposed algorithm, the state and the observation are obtained by the deep feature from the trained model. My question is the image to obtain the deep feature. When the image is the original image before the determined augmentation, the state and the observation are not affected by the selected action. Then, the best action can be determined just by one simple simulation, and no reinforcement learning algorithm is necessary to find the optimal augmentation. If the augmented images are fed into the model again, the computation cost cannot be reduced as shown in the experiments. What is the detailed sequence to obtain the deep feature?\n- Since the deep feature is utilized, its invariant property can affect the determination of the optimal augmentation. In other words, when the trained model is robust to the translation shift, the deep features from the model would be similar even after various translation shifts. Then, the training loss becomes also similar, which results in no selection of translation augmentation. This means that the algorithm would select only the augmentation method that is not considered in the initial model, and this can work as one of the biased optimizations for the optimal augmentation methods. Is there any analysis about the robustness of the initial model for the deep features?\n- In the experiments, the proposed algorithm is only compared with the out-of-date algorithms, so its performance cannot be validated well. I recommend the authors add the state-of-the-art studies related to auto-augmentation and the learning-based augmentation algorithms, which include Saliency-mix[1] and Co-mixup[2].\n- What would be the limitation of the proposed algorithm?\n\n[1] Uddin et al. \"SaliencyMix: A Saliency Guided Data Augmentation Strategy for Better Regularization\", ICLR2021\n[2] Kim et al. \"Co-Mixup: Saliency Guided Joint Mixup with Supermod-ular  Diversity\", ICLR2021\n",
            "summary_of_the_review": "As I said above, I have some questions about the necessity of the reinforcement learning-based algorithm in the framework. In addition, the comparison with the state-of-the-art algorithms should be added for the validation. I will change my score when I solve the above issues.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposed a fine-grained automated data augmentation approach, Patch AutoAugment (PAA), which tries to increase diversity in local regions by divide an image into a grid of patches and search for the joint optimal augmentation policies for the patches. The proposed PAA considers the task as a multi-agent reinforcement learning problem,  and adopt a multi-agent reinforcement learning\nalgorithm to automatically search for the optimal augmentation policies by considering the contextual relationship between the patches. They verify the proposed method on many classification and fine-grained recognition dataset(CIFAR10, CIFAR-100, ImageNet, CUB-200-2011, Stanford Cars and FGVC-Aircraft). The experiments show a good result and visualization results provide some insights that the PAA  help the target network to localize more class-related cues.\n",
            "main_review": "Over all, this paper is well written and technically sound, the experimental evaluation is comprehensive and the results are compelling, but I have several concerns:\n1. The most important contribution of this paper in my mind is the new search space focus on image patches for data augmentation. It seems like an incremental job relative to mixup series or cutout series.\n2. The proposed PPA formulate the task as a multi-agent reinforcement learning problem, and the results show it can find better policy than random, but [1] demonstrate that only use reinforcement learning can not get better policy than random baseline. The two experimental results are contrary.\n3.The calimed SOTA results is inappropriate, methods with better experimental results were not compared. For example, the paper  compare with AdvAA on the  computational cost, but not coapre on the accuracy.\n4.Another question is that recent work [2] with careful designed augmentation policy and advanced training strategy can get much better results, It is better to compare with it to give more insights.\n\n[1] Cubuk E D, Zoph B, Shlens J, et al. Randaugment: Practical automated data augmentation with a reduced search space\n[2] Wightman R, Touvron H, Jégou H. ResNet strikes back: An improved training procedure in timm",
            "summary_of_the_review": "According to above analysis and concerns, I suggest borderline. If the author can solve my concerns, I will consider change the score.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "  The paper proposes an evolution of the traditional\n  pipeline of image data augmentation used to reduce ML\n  model overfitting.\n\n  Instead of applying transformations such as shear,\n  rotate, CutOut, etc. at the image level, the proposed\n  technique divides the images into a fixed grid and\n  applies a potentially different transformation to each\n  cell. The problem of selecting a transform for each cell\n  is cast as a multi-agent RL (MARL) task, and the agents\n  learn as the main network trains within a (multi-agent)\n  Advantage Actor Critic framework.\n\n  The agents use a shared reward mechanism, with the reward\n  defined as the difference between the loss on the\n  augmented sample and the original loss.\n\n  The regular grid is fixed for a dataset and\n  hyperparameters like the magnitude of the augmentations\n  follow a fixed schedule; the agents only pick _which_\n  augmentation to apply on a patch.\n\n  Experiments performed on CIFAR-{10,100}, ImageNet,\n  CUB-200-2011, Stanford Cars, and FGVC-Aircraft show\n  relatively small but very consistent improvements in\n  terms of image classification accuracy. Different design\n  choices (MARL vs. single-agent vs. random, grid size,\n  etc.) are ablated and discussed in detail.\n",
            "main_review": "## Strengths\n\n  - S1: Ablation studies and theoretical explanations\n    motivate the choice for multi-agent reinforcement\n    learning reasonably well.\n  - S2: The efficiency of the proposed method is\n    investigated very clearly in Section 4.3. It seems\n    considerably more efficient than many other\n    learning-based DA methods.\n  - S3: The patch-wise data augmentation is a powerful idea\n    which can spark a large body of interesting follow-up\n    research.\n\n\n## Limitations\n\n  - L1: While this is not the main focus of the paper, the\n    empirical improvement over RL baselines like Fast\n    AutoAugment and non-RL baselines like RandAugment is\n    relatively small.\n  - L2: (Minor) While multiple datasets are used for\n    evaluation, only two Resnet variants are investigated\n    for ImageNet. It would be nice to see an evaluation of\n    the proposed data augmentation procedure on other NN\n    architectures as well on ImageNet, but I also\n    understand that the computational costs of this can be\n    quite large, so it may not always be possible.\n  - L3: (Minor) The agents rely on a pre-trained ResNet to\n    produce features to be used as observations.\n\n\n## Suggestions (Per-Section)\n\n### Related Work\n\n  - This is minor, but it may be worth briefly mentioning\n    [hong2019patch]. While their work doesn't do patch\n    level data augmentation, and instead \"patches\" objects\n    from an existing bank onto training samples, it still\n    has connections to things like CutMix that make it\n    relevant.\n  - Some recent papers on automatic augmentation are\n    missing and would be worth discussing. This includes\n    [DADA], [DDAS], [hendrycks2019augmix] and\n    [mueller2021trivialAugment]. In particular, Mueller and\n    Hutter's paper highlights an interesting limitation of\n    their otherwise robust baseline, which is that it\n    doesn't work too well for object detection, an area\n    where the current method may have the upper hand!\n  - Similarly, there are some further papers, such as […]\n    that perform a kind of \"local\" (though not strictly\n    patch-based) data augmentation by \"pasting in\" objects\n    into the 3D point cloud.\n\n\n### Method\n\n  - \"directly applying reinforcement learning (RL)\n    algorithm to …\" => \"algorithms\"\n  - \"In MARL configuration\" => \"In the MARL configuration\"\n  - Towards the end of Section 3.2, it may make more sense\n    to replace the \"Until all patches\" to \"Once all\n    patches…\" or maybe \"After\".\n  - Q1: Can an agent output more than one augmentation for\n    a patch? Would it be possible for a patch to, e.g., get\n    rotated AND colorized?\n  - Q2: Given the more \"local\" nature of this augmentation\n    method, have you considered evaluating it on more\n    \"local\" tasks, such as object detection and semantic\n    segmentation. Perhaps it could make a bigger impact\n    there.\n  - Q3: Given that the parameters of actor networks of all\n    agents are shared (see above Eq. (5)), does that mean\n    that each actor's policy is identical, and the only\n    difference between the actors is what observation each\n    one gets (the local patch features)?\n\n\n### Experiments\n\n  - At the start of Section 4.1, \"Exactly, we focus\" =>\n    \"Specifically, we focus\"\n  - In \"Policy Visualization\", \"important levels\" ->\n    \"importance levels\"\n  - In Section 4.3 I would say the \"main methods for\n    reducing the computational cost\", since what you next\n    describe are methods for reducing the cost, not what\n    one would typically call reasons.\n  - Table 3 is a little hard to follow because of the\n    different hardware employed by each column. After\n    staring at it for a while it's becoming a bit clearer,\n    but at first glance it was a bit confusing.\n  - Q4: Do the times from Table 3 include the inference\n    time required to compute the agent state and\n    observations with the auxiliary ResNet-18?\n\n\n### Conclusion\n\n  - The parallels to vision transformers are very\n    interesting and help give the reader a broader\n    perspective on possible applications of the current\n    paper.\n  - (Minor) The word \"Furthermore\" is repeated for two\n    almost consecutive sentences. Using something like\n    \"additionally\" to start one of the sentences can\n    improve the flow of the paragraph a little.\n\n\n## References\n\n  - [hong2019patch]: Hong, Sungeun, Sungil Kang, and\n    Donghyeon Cho. \"Patch-level\n  augmentation for object detection in aerial images.\"\n  Proceedings of the IEEE/CVF International Conference on\n  Computer Vision Workshops. 2019.\n  - [cubuk2020randaugment]: Cubuk, Ekin D., et al.\n    \"Randaugment: Practical automated\n  data augmentation with a reduced search space.\"\n  Proceedings of the IEEE/CVF Conference on Computer Vision\n  and Pattern Recognition Workshops. 2020.\n  - [DDAS] Liu, Aoming, et al. \"Direct Differentiable\n    Augmentation Search.\" arXiv preprint arXiv:2104.04282\n    (2021).\n  - [DADA] Yonggang Li, Guosheng Hu, Yongtao Wang, Timothy\n    M. Hospedales, Neil Martin Robertson, and Yongxing\n    Yang. DADA: differentiable automatic data augmentation.\n    CoRR, abs/2003.03780, 2020.\n  - [mueller2021trivialAugment]: Müller, Samuel G., and\n    Frank Hutter. \"TrivialAugment: Tuning-free Yet\n    State-of-the-Art Data Augmentation.\" ICCV 2021.\n  - [hendrycks2019augmix]: Hendrycks, Dan, et al. \"Augmix:\n    A simple data processing method to improve robustness\n    and uncertainty.\" arXiv preprint arXiv:1912.02781\n    (2019).\n",
            "summary_of_the_review": "  The paper proposes a new way of looking at the classic\n  task of image augmentation for classification. Instead of\n  learning an image-level augmentation policy using RL, the\n  proposed approach uses multi-agent RL to learn\n  patch-specific augmentations. While the benefit of\n  multi-agent RL is relatively small, it seems significant\n  and the general idea of learning to apply different\n  augmentations to different parts of the image is\n  interesting and, to the best of my knowledge, new. The\n  idea to apply image augmentations at a local level is the\n  core contribution of this paper, in my opinion.\n\n  While it would be interesting to see how this technique\n  works on tasks which, unlike image-level classification,\n  are themselves more \"local\", such as semantic\n  segmentation or detection, overall the proposed approach\n  is evaluated thoroughly.\n\n  The writing is clear and while the authors don't\n  explicitly mention an intent to publish their source\n  code, it should be possible to implement the proposed\n  approach just based on the description from the paper. As\n  such, I recommend accepting the paper to ICLR.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "n/A",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes an automatic data augmentation approach. Different from existing works, they proposed to augment patches in the image rather than the whole image. The approach is formulated as a multi-agent reinforcement learning problem. They empirically show the effectiveness of their approach across several image classification datasets.",
            "main_review": "### Strengths:\n- 1.\tThe paper conducted a comprehensive evaluation of their approach over several datasets. They achieve gains over the compared baseline method validating the efficacy of their proposed approach.\n- 2.\tThe approach considers patched based augmentation, which is sufficiently different/novel from existing work.\n\n### Weaknesses:\n- 3.\tThe motivation of the approach is somewhat lacking. For example, it is unclear why MARL on patches is much faster. I think the paper could benefit from motivating more on why MARL and what is its benefit with respect to the task. \n- 4.\tThe paper did not reference or compared to a key related work, “Differentiable automatic data augmentation” [A]. Based on its relevance, the paper should discuss and contrast with this work, as they also have minimal search time. Specifically, comparison in Table 2 and Table 3 would strengthen the paper.\n- 5.\tHow is the model architecture of the actor/critic network determined? Also, what ranges of hyperparameters for MADDPG are considered? I saw the hyperparameters for the target model but not MADDPG. RL is known to be sensitive to hyperparameters, I wonder if the authors will release the code and pre-trained models for reproducibility. \n- 6.\tAblation with independent agents as a baseline would be interesting. It would further motivate the use of MADDPG and the multi-agent setting.\n \n### References\n[A] Li, Yonggang, et al. \"Differentiable automatic data augmentation.\", Proc. ECCV, 2020.\n\n\n",
            "summary_of_the_review": "The main concern with the paper is with the motivation and missing reference/comparison with a key existing work. \nCurrently, I recommend a weak reject. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}