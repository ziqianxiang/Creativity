{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper proposes BitRand, a bit-aware randomized response algorithm, to preserve local differential privacy in federated learning. The main idea is to take into account the bit indices and prioritise higher order bits focussed towards achieving a utility which is higher than other algorithms which are oblivious to the floating point bit representation. Additionally, the analysis allows the bit randomization probabilities not to be affected too much by the dimension of the data.\n\nOverall, the paper lay right at the borderline of acceptance. The paper's core idea, their development and experiments were all liked by the reviewers. The main issue the reviewers brought up was the writing and structuring of the paper and the presentation of the overall results. Most reviewers agreed that the paper presentation was not ready to match the bar for ICLR. There are multiple suggestions that reviewers have made - through their questions and direct comments and addressing those and rewriting the paper to highlight these aspects better will significantly improve the paper."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper tries to address the question whether we can have different noise scale for different bits for a high dimensional vector and still preserves privacy. They propose a method to do that. ",
            "main_review": "The idea of this paper is to introduce a bit-aware randomization technique. That is a randomized response algorithm that flips a bit based on its position in the binary representation of the scalar (or naturally extend to a vector). I found the paper a bit hard to read because of clutter and too many notional changes. I have some clarifying questions from the authors:\n\n1. What is the notation $i$%$\\ell$ used in the definition of the bit-aware term? It needs to be defined more explicitly. \n\n2. Is the decoding function $\\mathcal E$ the averaging of the gradient? I would rather have the author clearly state that in the first 8 pages than point to the lines in the algorithm. I do not understand why the authors call it a decoding function to begin with. Decoding is a specific technical term in coding theory. \n\n3. What is $f^\\theta$? There is no such notation in the Algorithm. Is it a function taken from a set of functions parameterized by the model?\n\n4. After equation (6), why is the ratio of the probabilities the worst case?\n\n5. How does equation (6) happen? Why can you decompose the probability like that? If we change the binary vector by adding $1$, more than one coordinate gets affected; hence, the probability of seeing a bit in different coordinates is dependent. Am I missing something here? The same form of independence is claimed in the guarantee of Theorem 7. \n\n6. Am I correct in understanding that $\\epsilon_X$ is the privacy budget in the embedded space?\n\n7. Coming to the proof of Theorem 2, we have $\\mathbb E[ \\cdot]$ in equation (13). This does not make sense in any practical setting. This pretty much means that the privacy bound is in the average case, which is weird!! From what I see, the end result would be some kind of average-case DP, which has its own pitfalls! Can the author clarify this?\n\n8. What is the notion of neighboring dataset? It is very essential to know that before I can make a reasonable comparison with the previous work. \n\n9. Randomized response does not give an unbiased estimate. On the other hand, to do SGD, we need unbiased estimate of the gradient while ensuring that the variance is bounded. So, I feel there should be some form of bias correction, which is not in this paper. ",
            "summary_of_the_review": "There are a lot of clarifying question that I do not understand in this paper. \n\nThe authors have answered most of the clarification questions I had during the author's response phase. I still feel the paper is cluttered and not ready for ICLR and at maximum is a borderline accept mainly due to the strength of the problem studied. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a randomized-response algorithm that takes into the bit indices and prioritises higher order bits. As a result, the utility is higher than other competitive algorithms. Additionally, the analysis allows the bit randomization probabilities not to be affected too much by the dimension of the data.",
            "main_review": "+ The paper provides a simple but useful trick of tweaking the bit randomization probabilities based on the bit-index that results in \"dimension-elastic\" privacy/utility gains. \n+ The paper is in general well written and easy to follow. \n+ The comparison with prior research is very comprehensive along with strong experimental evaluation.\n\nComments.\n1. I am a bit confused as to why is the privacy analysis is performed w.rt the encoding/decoding $\\mathcal{E}$ instead of just $f-RR$.As  mentioned, the sensitivity of $f-RR$ is lower - 1 and since $\\mathcal{E}$ is applied to the output of f-RR,  by post-processing guarantee, LDP would still hold. Is the reason for choosing to analysis for $\\mathcal{E}(f-RR)$ the fact that the gradient computations require the decoding process and hence, this results in better utility by directly analysing w.r.t to $\\mathcal{E}$?\n2. Could the authors provide some details about motivation/purpose of the embedding step? Is it a smarter approach for dimensionality reduction or the embedded features carry some intrinsic meaning? Also, how integral is the embedding step to the proposed scheme - would the privacy/utility gains hold true if Alg.1 is applied directly on the input $x$? \n3. How is the proposed different label-RR scheme different from the RR techniques showcased by Ghazi et al. 2021? Also , why is the evaluation baseline  Label-Laplace instead of Ghazi et al.?\n4. Why is the sign bit valued at 2^{m+1} and not 2^m (since the MSB integer bit is 2^{m-1})? Also, is there any specific reason why the sign bit is assigned the highest weightage?\n5. Why is $\\epsilon_i$ intractable (just below Eq. 6)? Is it not a user defined privacy parameter whose value is an input to the algo?\n6.  Is not $|\\mathcal{E}(f-RR(v_a,i)-\\mathcal{E}(f-RR(v_{a|i},i)|$ randomized (since f-RR is)? How does this imply $|\\mathcal{E}(f-RR(v_a,i)-\\mathcal{E}(f-RR(v_{a|i},i)| < |f-RR(v_a,i)-f-RR(v_{a|i},i)|$?\n7. I could not understand why $P(f-RR(v_{a}(i)=v_z(i)))/P(f-RR(v_{a|i}(i))=v_z(i)) )\\geq 1$ is the worst case?\n8. I could not understand how is the anonymization work by Sun et a.l applied in the evaluation - exactly what is being compared against?\n9. Anonymization (shufflers) can be also implemented by cryptographic techniques such as mixed nets. Additionally, most of the work on shuffling DP provide amplification results that can work with using the same randomization mechanism for all. So I would suggest toning down the relevant sentences in Page 2. ",
            "summary_of_the_review": "Overall, the paper provides an effective technique for improved utility for RR. However, I have a few confusions regarding the solution setting (see comments above). ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The importance of rigorously taking care of privacy leakage in a DP algorithm on the bit level is well-know, see e.g.\n\nMironov, Ilya. On significance of the least significant bits for differential privacy. In: Proceedings of the 2012 ACM conference on Computer and communications security. 2012. p. 650-661.\n\nThis paper considers locally differentially private (LDP) mechanisms for binary representations of floating point numbers. The technique seems like a natural thing to do: the individual bits are flipped with a probability that scales with their importance.\n",
            "main_review": "\nPros:\n\nI think the idea seems natural and as far as I see the LDP mechanism that takes into account the signifigance of the digit in the noise variance of the randomiser has not been considered before (good discussion of related literature).\n\nThe paper is well written and all the math that I checked seems correct.\n\n\nCons: \n\nI find the paper a bit difficult to read, everything seems to be discussed on a very low level. That is of course not a deficit per se, but a bit more higher level view on the problem would help, I think.\n\nExample: It is totally possible I missed something, but it is unclear to me, why do you only consider the LDP mechanism for the embedding and then observe the error in the decoded representation (that mathcal(E) representing the decoder) ? I mean, if the gist of the paper is that bit-aware LDP randomiser, why not to also have utility comparisons for that (more) directly ?\n\nI think the presentation could be improved. Examples:\nIn Section 5, Figure 3: This figure is not referred to anywhere, nor are the labels of the figure. You mean that you measure the expected error of the decoded features so that f-RR is replaced by Gaussian mechanism etc.?\nIn Figure 3, what is the sensitivity for the Gaussian mechanism, for example? sqrt(r) ?\nAnd for the Laplace mechanism? How do you use the Gaussian mechanism for the binary r-vector?\n\nOther:\n\n-The figures are quite small and thus a bit hard to read. \n-Would it be clearer if Fig. 7 had logarithmic y-axis?\n-When talking about bit-wise DP, I think it would be good to mention also the paper \nMironov, Ilya. On significance of the least significant bits for differential privacy. In: Proceedings of the 2012 ACM conference on Computer and communications security. 2012. p. 650-661.\n\nEDIT: I think the paper has its merits and the bit-wise mechanism is an interesting approach, however I think the paper is not yet mature for publication in ICLR. Some of my concerns regarding the presentation (e.g. why is only the privatisation of the embedded representation studied) seem to be shared also by other reviewers. Thus, I have decided to keep my score. ",
            "summary_of_the_review": "An interesting LDP randomiser that takes into account the significance of bits in binary encoding of floating point numbers (and vectors). However, I think the presentation should be improved to meet the bar of ICLR. Currently, I think this paper will not be easily understandable to anyone else than those working close to this i.e. practical algorithms for LDP and federated learning.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes an $\\epsilon$-LDP mechanism, termed $f$-RR, to privatize a real number. The mechanism first maps $v$ into its binary representation (with a sign bit) and then flips each bit with probability $p_i$. The authors then extend their mechanism to privatize a $r$-dimensional vector by sequentially performing the (scalar version) algorithm for each of the $r$ coordinates. By picking proper parameters, the proposed mechanism preserves $\\epsilon$-LDP. Finally, several experimental results compared with other previous methods are provided.",
            "main_review": "1. Though the authors name their mechanism as $f$-RR and claim its novelty, it is indeed an asymmetric version of RAPPOR that has been studied previously in the context of frequency estimation (see [WBLJ 2019] for instance). The only difference is the specific choice of parameters.\n\n\n2. This paper tries to apply frequency estimation techniques (such as RR or RAPPOR), which are usually designed for categorical data, into privatizing continuous data. Therefore the proposed mechanism can be viewed as first quantizing the data (i.e., mapping a vector $v \\in \\mathbb{R}^r$ to $r$ binary strings), and then applying RAPPOR on it. However, recent works have shown that such a naive two-stage approach is usually highly sub-optimal (at least in several canonical tasks such as mean estimation, see [CKO 2020]). Therefore I highly doubt the optimality of the proposed algorithm.\n\n\n3. The authors claim that the proposed solution resolves the curse of privacy composition; however, from the main utility guarantee Theorem 4, I don't think the problem is solved. Theorem 4 only gives an error bound on a single coordinate, so when applying the algorithm to a $r$-dim vector, there should be an additional $r$ factor. In general, I don't think it is possible to improve the state-of-the-art LDP mechanisms (such as [BDFKR 2019]) as performance guarantees of these mechanisms (order-wisely) match the information-theoretic lower bounds. It would also be good if the authors can provide standard error guarantees for their algorithm (e.g. the $\\ell_1/\\ell_2$ error for mean estimation) and compare them with previous works.\n\n\n4. I also doubt the correctness of the experimental results. For instance, upon a quick look at the codes, the \"Duchi Mechanism\" (which, I believe, should be the privUnit mechanism in [BDFKR 2019]) is indeed implemented as [DJW 2013]. Note that [DJW 2013] is a weaker version of privUnit and is only optimal when $\\varepsilon = O(1)$. It would be good if the authors can include more implementation details in the appendix.\n\n\n\n[WBLJ 2019] Locally differentially private protocols for frequency estimation\n\n[CKO 2020] Breaking the Communication-Privacy-Accuracy Trilemma\n\n[BDFKR 2019] Protection Against Reconstruction and Its Applications in Private Federated Learning\n\n[DJW 2013] Minimax optimal procedures for locally private estimation",
            "summary_of_the_review": "In general, the proposed privatization scheme is not novel, and the analysis seems not optimal. I appreciate the authors' efforts in conducting extensive experiments, but there might be some issues when comparing the proposed algorithm with previous works, which I hope the authors can clarify.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}