{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This manuscript proposes an adversarial method to address non-IID heterogeneity on federated learning. Distinct from existing methods, the mitigation is implemented by training and local communicating learned representations, so the metric of success is indistinguishability of representations across devices. \n\nThere are four reviewers, all of whom agree that the method addresses an interesting and timely issue. However, reviewers are mixed on the paper score, and many raised concerns about communication overhead, apparent privacy costs, and convergence concerns with the adversarial methods. There is also some limited concern of novelty compared to existing methods. The authors provide a good rebuttal addressing these issues -- either based on experimental evidence (adding differential privacy), comparing communication overhead tradeoffs as it varies with model and sample size, and some existing convergence analysis. However, after reviews and discussion, the reviewers are unconvinced that the method is sufficiently robust to the concerns outlined. Authors are encouraged to address the highlighted technical concerns in any future submission of this work."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper focuses on federated learning on non-IID features. This is a crucial problem when applying federated learning. The authors propose a new federated learning scheme, called ADCOL (Adversarial Collaborative Learning) for non-IID features. Specifically, the server is designed to train a discriminator to distinguish the local representations from local parties. While the local parties train the local models and expect the representations not to be distinguished by the discriminator. Authors conduct experiments on multiple parties where the data have heterogeneous features but share the same labels and label distribution and the results clearly show the effectiveness.",
            "main_review": "### strengths:\n1. The motivation of ADCOL (Adversarial Collaborative Learning) is both clear and reasonable. Indeed, the features in real-world scenarios are usually non-IID and how to apply federated learning on the non-IID data has always been an important question in practice. Therefore, it is quite necessary and challenging to design a thorough federated framework. \n2. The experimental evaluation seems to be convincing. Authors choose several typical fundamental tasks (digits, office-caltech-10, DomainNet) for experimental evaluation. The results demonstrated the effectiveness of the proposed ADCOL method.\n\n### weaknesses:\n1. In ADCOL, parties deliver representations of data instead of local models. It may lead to more serious privacy breaches. It needs more work to protect the local data.\n2. The advantage of communication size is not persuasive. In fact, smaller models than used in SOLO are often used\n3. The statements in this paper are not complete, especially in the experiment sections. There is a lot of confusion here, such as the statics of all the datasets,  the method for averaging results from different data sources (arithmetic average or weighted average according to data volume)  and methods for adjusting consistent label distribution but non-IID feature distribution, and the final distribution of label and feature.\n",
            "summary_of_the_review": "As shown in the Main Review, the motivation of the paper is clear and reasonable, and also, the experimental evaluations are convincing. While there are also some issues that need further refinement to be accepted, especially the statements in the experiment.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes an adversarial training method for learning from non-iid data in federated learning. Both a theoretical and an experimental analysis of the method are provided.",
            "main_review": "Pros:\n\n- The paper addresses an important problem, namely the one of federated learning that accounts for the fact the real-world data for collaborative learning is often non-iid in the features.\n- The paper is well-written and motivated, comparison to prior work is very well-done.\n- The proposed adversarial training method is intuitive and seems to perform well in practice.\n- The issues of communication complexity and privacy are discussed, even if those can in some situations be limitations of the proposed method.\n\nCons:\n\n- It is indeed possible that for certain modes (for example the local sample sizes being large as compared to the number of users N), the proposed method can be communication-inefficient.\n\n- Similarly, privacy can be seen as an issue. It is true that classic FL is also prone to privacy problems, however the proposed method sends multiple features, of the same input data, to the server at every round. Intuitively, it should be easier to infer information about the original data with so much information, rather than just with sharing (one) locally updated model at every round.\n\nSuggestions:\n\n- The paper will benefit from further explanation on why the proposed method (finding representation that obfuscates the differences of the distributions of the local datasets) is expected to work. The idea is intuitive and is in lines with classic domain adaptation techniques. However, expanding the discussion on that will be beneficial.\n\n- Similarly, equation (1) and the KL distance come a bit out of nowhere in the text. It will be nice to justify using the KL, as opposed to other distance measures.\n\n- In Section 3.1, it will be useful to repeat again the assumption that only the input distribution changes, since this is where you formally introduce the studied problem.\n\n- The conclusion (and in some sense the comparison to standard FL throughout the paper) seems to suggest that the method is more computationally efficient than other FL methods. The validity of this claim clearly depends on the values of multiple parameters of the problem, such as n, N, d etc. In this sense, the technical discussion is Section 3.5 is much more helpful to the reader and I would recommend against overselling the merits of the proposed method.\n\n- Related to the last point, perhaps the authors could comment on the possibility of communicating the representations of only a subset of the local data of each client at every round?",
            "summary_of_the_review": "Overall, this is a very well-written paper that studies an important topic and proposes an interesting new idea. While there are some limitations, they are quite well-discussed (although improvements such as those mentioned in the \"Suggestions\" section are desirable) and I think that the paper will spark some interesting discussions and new ideas in the context of FL.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work presented an adversarial collaborative learning named ADCOL for federated learning on non-IID features. It learns the invariant feature representations for all parties.",
            "main_review": "Strengths:\n(1) It proposed a novel adversarial collaborative learning for federated learning on non-IID features.\n(2) It provided the convergence state of the training process.\n(3) Experiments showed it outperformed baselines.\n\nWeaknesses:\n(1) The overall idea is marginally novel, as it simply adapts the training procedures of “domain-adversarial neural network” [ref 1] into the federated learning. This idea has also been explored in previous work [ref 2]. In this case, [ref 2] also focused on the non-IID features in FL. It is more convincing to use [ref 2] as one of the baselines in the experiments.\n[ref 1] Ganin, Yaroslav, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky. \"Domain-adversarial training of neural networks.\" The journal of machine learning research 17, no. 1 (2016): 2096-2030.\n[ref 2] Peng, Xingchao, Zijun Huang, Yizhe Zhu, and Kate Saenko. \"Federated Adversarial Domain Adaptation.\" In International Conference on Learning Representations. 2020.\n(2) One major concern of this method is to the privacy issue. It suffers much more seriously from the privacy leakage by sharing the hidden representations, compared to sharing only parameters in FedAvg. This might break the privacy constraint of federated learning. The communication cost also significantly increases due to the shared representations.\n(3) The theoretical results provided the convergence state of the training process, but it is not clear whether the proposed FL method can achieve the convergence result.\n(4) The train/test split for each client is not given.\n",
            "summary_of_the_review": "The novelty of the proposed model is incremental, and the privacy issue of sharing features is not solved.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper studies federated learning when different devices have non-iid features. To address the heterogeneity problem,  it proposes a federated learning scheme called ADCOL based on adversarial learning.  In ADCOL, the devices transfer local representations to the server while sending the discriminator to the devices. The server aims to distinguish the devices' local representations, while the devices aim to train local models that generate non-distinguishable representations. To make the representations non-distinguishable, ADCOL adds an additional regularization term to the devices' loss functions. This practice aims to maximize the probability that the discriminator cannot distinguish the local representations. The experimental results show that the proposed method has some advantages over several baselines.",
            "main_review": "Strengths:\n1). This paper studies an important problem -- the non-iid features problem in federated learning. The authors have some good ideas to tackle the problem.\n2). The paper presents both theoretical and numerical results. The experiments show that the proposed method has some advantages over some baselines.\n3). The paper is well-written in general.\n\nWeaknesses:\n1).  Using adversarial learning to add the non-iid features problem in federated learning is not new. The proposed method is similar to the FedUFO algorithm in  \"Federated Learning for Non-IID Data via Unified Feature Learning and Optimization Objective Alignment\" [Zhang et al. ICCV'21] (not cited). The authors might want to compare the proposed method with FedUFO. \n\n2). The proposed method requires the server to distinguish the devices' local representation.  In practice, only a small number of devices are selected for each round of federated learning. In addition, the number of the selected devices might also be different. It is questionable whether the devices can learn a common representation efficiently under these scenarios. Even if they can, these dynamics might significantly degrade the performance of the ADCOL algorithm. The authors might want to explain why the proposed method can be applied to these scenarios. The appendix has shown some results related to device sampling, but it only has one large sampling rate (0.4). In practice, the sampling rate is much lower (e.g., below 0.2).\n\n3). While the experiments appear to be comprehensive, there is a lack of study on how different degrees of non-iid influence the proposed algorithm's performance. Besides, the authors might want to increase the number of devices and adjust the device sampling rate.\n",
            "summary_of_the_review": "While this paper has some nice ideas to address the non-iid feature problems in federated learning, its contributions are limited due to novelty and practicability issues. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}