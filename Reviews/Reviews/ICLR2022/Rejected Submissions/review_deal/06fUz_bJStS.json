{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper provides a new differentially private training method. The key idea is sparse gradient updates---that is, their variant of differentially private SGD (DP-SGD) only updates on a random subset of the parameters in each iteration. The authors argued that their method has a benefit in terms of memory and communication efficiency. The reviews suggested that the paper may require further evidence to motivate and justify the novelty of the proposed method. First, the reviewers are not fully convinced that the proposed method reduced both memory and communication. In particular, would the technique of random freeze require running DP-SGD for more iterations? Even though the authors added a new theoretical result (mostly adapted from Chen et al.), the newly added Theorem 2 does not explain the benefits of the freezing technique. Thus, the paper can benefit from more extensive theoretical analyses or justification. The authors should also consider including the additional related work brought up by the reviewers. In summary, the paper is not ready for publication at ICLR."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper considers the problem of differentially privately learning deep neural networks. In order to improve the accuracy and reduce the communication cost, this paper proposes to randomly freeze a progressively increasing subset of parameters, which results in sparse gradient updates. Empirical results also show that the new algorithm can largely reduce the communication cost, while maintaining the performance. Furthermore, the extra computation cost is negligible.",
            "main_review": "I think this paper has made the following contributions:\n1. This paper proposes a new algorithm of differentially privately training neural networks, which randomly freezes a progressively increasing subset of parameters. This light-weight algorithm can be easily implemented, which dramatically reduces the communication cost while maintaining the accuracy. The idea of gradual cooling and inversely proportional scaling rule are also very interesting.\n2. The paper justifies its statement with detailed experiments.\n\nI think the paper can be improved in the following ways:\n1. First, the idea of the random freezing is not complex. Therefore, I am not sure how much algorithmic contribution it has made. Besides, this idea is not fully novel, at least it has appeared in other papers. For example, in this paper (https://arxiv.org/pdf/2103.01294.pdf), I remember they also used some similar approach in the experiment section.\n2. Personally I am very curious about the performance comparison between random freeze and ranked freeze, which is not provided in this paper. The paper justifies why they do not adopt the ranked freeze in section 2.3, which I do not fully follow. I do not think it is enough to just show they have a similar histogram. Consider the following example, in each iteration, each coordinate is 1 with prob 0.5; else 0. Note that the random freeze and ranked freeze with constant gamma = 0.5 give you exactly the same histogram. However, there is much more information left in the ranked freeze.\n3. Some related work is missing, at least the paper I just mentioned, and this paper (https://scholar.google.com/citations?view_op=view_citation&hl=en&user=m8NUgw0AAAAJ&sortby=pubdate&citation_for_view=m8NUgw0AAAAJ:u_35RYKgDlwC).\n\n",
            "summary_of_the_review": "Overall, I think it is a borderline paper. So I am fine with either accepting or rejecting this paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper aims to improve the effectiveness of deep learning under differential privacy. It proposes a simple dimension reduction method that could potentially improve model accuracy as well as mitigate the computational and memory overhead of some previous power method. ",
            "main_review": "This paper proposes a dimension reduction technique for private machine learning called random freeze. The basic idea is to randomly select a subset of model parameters and zero out corresponding gradients during the training process. Another contribution is a method to counter the residual effect of added noise when momentum is used for gradient updates.\n\nStrength: \n+ The problem the paper aims to address is an important one. Machine learning with differential privacy is a very active research area, and this paper is a valuable addition to the literature in this field.\n\n+ The proposed method is simple to understand and implement. It is also general and applicable to all types of neural networks. If proven effective, it could be adopted into many existing frameworks to improve the utility private machine learning.\n\nWeakness:\n- The experiments do not sufficiently demonstrate the benefits of the proposed method. As a dimension reduction technique, random freeze could be compared with other similar techniques (e.g., [1]) for private learning in terms of utility. Among the four models used in the experiments, only one (GEP) is a belongs to this category, and random freeze shows a drop in utility (from 73.5 to 73.4, third row of table 1). As such, it is unclear if random freeze can be used in place of, or together with other dimension reduction techniques. \n\n- The proposed scaling of gradient clipping bound is not convincing. The paper argues that, because of the use of momentum in gradient updates, the noise added in previous iterations has residual effects in later iterations. Therefore, the noise scale needs to be adjusted to counter this effect. In the paper, the way to adjust the noise is to use a single constant to scale all noises, and this constant is inverse to the cumulative effect when the number of iterations go to infinity. However, this method for adjusting the noise does not make sense to me. For example, the noise added in the first iteration of training would have much more cumulative effect than the noised added in the final interaction. Also, due to random freeze, fewer and fewer (and different) parameters are receiving updates as the training progress. Thus, while the concern raised by the paper is a valid one, I am not sure the proposed method is the right solution.\n\n- The paper claims (in Section 1.2, Our Contribution) that the proposed method “reduce the computational cost and memory footprint induced by the power method”. However, this claim is neither theoretically analyzed nor empirically demonstrated using experiments.\n\n- Discussion on related work is missing.\n\n\nTypos:\nPage 8 footnote: “There exist too ways…”-> “There exist two ways…”\nPage 9 last paragraph: “It is interested to observe…” -> “It is interesting to observe…”\n\nReferences:\n[1] LoRA: Low-Rank Adaptations of Large Language Models.\n",
            "summary_of_the_review": "This paper has two core contributions: a dimension reduction technique (random freeze) and a method to scale gradient clipping norm. However, as mentioned in the discussion on weakness, this paper does not sufficiently demonstrate the benefits of the proposed methods. Therefore, it does not meet the standard for publication at a top conference like ICLR in my opinion.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work introduces the idea of randomly pruning gradients in order to reduce the dimensionality, which, in turn, results in greater efficiency for DP-SGD. The work provides an empirical analysis to support the method.",
            "main_review": "Strengths:\nThe method boasts empirical success \nPaper is well-written \n\nWeakness:\nThe proposed method, although reasonable, seems rather ad hoc. Thus, without a guiding first-principles motivation for the method, one should wonder how generally the method works and why it works.\nThe paper does not do a sufficiently thorough job at the systems considerations of the work.\n",
            "summary_of_the_review": "Overall, this method seems purely heuristic. Without a theoretical or first-principles explanation, this paper relies mostly on an empirical analysis. Theorem 1 is included, but the Gaussian assumption for SGD is extremely limiting and deviates from the accepted standards of analysis for SGD, which generally assume unbiased estimates with bounded variance, but not Gaussian shape in particular. Furthermore, the connection between Theorem 1 and the proposed method of random freezing does not seem that solid.\n\nFor the systems analysis, the authors do not report two key quantities: (1) the memory consumption (in bytes) of the method and (2) the runtime of the method. For (1), sparse representations must generally pay a memory overhead because an index is also required. A sparsity % of X% does not imply X% of the memory used. For (2), it seems that although a sparse representation can reduce memory, I am not sure how the runtime of the sparse gradient computations might also be affected here in the DP-SGD. It is important to also benchmark and report this, or at least mention that the runtime is not significantly affected if that is the case.\n\nTo summarize, the work is neither a complete systems analysis nor provides a sufficient fundamental analysis. I feel that at least one of these two aspects should be present.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes to use sparse gradients in combination with differential privacy techniques in order to mitigate performance drop that comes from applying DP to a large number of parameters. ",
            "main_review": "Strengths: \n- A relevant problem is addressed in this work. \n- The idea is simple but interesting and shows potential. \n\nWeaknesses:\n- The appendix proves a result for the MSE, but there is no insight or discussion into how this result would look for the proposed method.\n- The \"curse of dimentionality\" is not explored in detail (i.e. performance of the method for different numbers of parameters). Relatedly, the conclusion mentions \"... random freeze can reduce the computational cost and memory footprint of the power method in GEP\" but this is not explored in much detail in the results. \n- While the inversely proportional scaling rule is mentioned, more results would be beneficial about the choices of hyperparameters and also how robust the method is to certain parameter choices. Similarly: how many gradients can we drop before we start losing accuracy? \n- In the results in Table 1 the proposed method does not improve on the accuracy and a significant accuracy improvement is also only shown for one model. It thus remains unclear if a higher DP-guarantee be obtained with higher/similar accuracy. Test accuracy as a function of privacy loss would be interesting to see. \n\nComments: \n- A very minor comment: I am not sure I understand the positioning of section 2.5; if you see it as numerical, better to have it in the numerical section; if it is part of the discussion then let it be in the discussion. ",
            "summary_of_the_review": "Interesting idea but numerical experiments are not yet fully convincing and a lack of theory and discussion",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}