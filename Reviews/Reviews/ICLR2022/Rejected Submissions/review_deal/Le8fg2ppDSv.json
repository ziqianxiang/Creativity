{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper is well motivated and tackles a hard and long-standing problem with seq2seq models: diversity and controllability.\nThe authors propose simple architecture for controllable text summarization. They use multiple decoders controlled by a gating mechanism which can be learnt or controlled manually. They control mostly the abstractiveness and specificity properties of the model.\n\nPros\n+ the proposed approach is somewhat novel (several earlier work have proposed multiple decoder models to control the generation -- as pointed by the reviewer team) \n+ the proposed modifications are motivated well, the approach is simple and easy to understand. \n+ the paper is well written and easy to read.\n+ the authors made an effort to address most of the reviewers comments even added human evaluation scores (which was asked by reviewers)\n+ It seems a highly flexible way of enriching existing models in a simple way for additional control behavior in output summary generation of documents.\n\nCons\n+ During discussions, reviewers have circled around the novelty and continued to raise concerns about the weaknesses of benchmarks and comparison to related work and the fact that the proposed model has more parameters is potential advantage over other models that might contribute to the performance gains. Thus, the paper could be made stronger with further evaluations that could possibly make it stand out."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper propose using a multidecoder architecture to to control the style of output summarization. In the designed model, each decoder learns and generates stylisticall-distinct summaries. The contribution of each experts are controlled by a gating mechanism. This multidecoder model can be trained without supervision or with guidance. This model is tested on CNN, NEWSROOM and XSum. When trained unsupervised, different decoders learn to produce summaries with different abstractiveness and specificity. The guided training shows the capability of asigning certain styles to a specific encoder. ",
            "main_review": "==== strengths ==== \n\nThe task of controllable generation for summarization is well motivated. The finding that different decoders indeed capture different level of abstractiveness and specificity is interesting. The paper is clearly written and the methods are experiments are easy to understand. \n\n==== weaknesses ==== \n\nMy biggest concern with this work is lacking of good evaluation metrics. For the same text input, the model is supposed to control all high-quality summaries with distinct styles. To achieve that, a summarization dataset with multiple stylistically distinct references are needed. Lacking such a dataset, human evaluation would shine some light, which is missing in this work. In the guided training session, what is the rouge score of generated summaries? ",
            "summary_of_the_review": "The paper presented a novel architecture for style control in abstractive summarization. However, without evaluating the model on a dataset where each input is associated with multiple references of different styles or running human evaluation, the effectiveness of the style control and the quality of generated summaries are not clear. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a neural sequence-to-sequence (Seq2Seq) model, called HYDRASUM for text summarization. HYDRASUM incorporates multiple decoders where each decoder learns and generates stylistically distinct summaries along dimensions such as abstractiveness, specificity, and others. HYDRASUM is fundamentally built upon the notion of mixture-of-experts (MoE), where a gating mechanism decides the contribution of each expert (individual decoder) to the next token's output probability distribution. The paper demonstrates that HYDRASUM automatically learns to generate contrasting summary styles using each decoder. The paper further proposes a \"guided\" training scheme that explicitly govern which summary style is partitioned between decoders, e.g. high abstractiveness vs. low abstractiveness or high specificity vs. low specificity, and also increase the stylistic differences between individual decoders. The paper also show that HYDRASUM is flexible, during inference, it can be controlled to generate a diverse set of summaries by sampling from individual decoders or mixtures of different subsets of the decoders.",
            "main_review": "**Novelty**\n\nThe fundamental idea of the paper to use multiple decoders and a gating mechanism to improve abstractiveness in model generated summaries is previously explored in [1]. However, the \"guided\" training scheme is interesting, specially the way the training data is partitioned based on different features.\n\n[1] Improving Abstraction in Text Summarization, EMNLP 2018.\n\n**Strengths**\n\n- Good writing. I enjoyed reading the paper.\n- Thorough experiments; the paper covered a broad range of aspects to evaluate the proposed model.\n- Overall the findings of the paper is interesting, and it will help push future works in this direction.\n\n**Weaknessess**\n\n- Limited technical novelty.\n- As the Table 1 suggests, the overall performance of the proposed model does not surpass the baseline in 2 out of 3 evaluation dataset. This raises a key question, in what scenarios, the proposed model would be valuable? Are there any particular use cases of this model? I do not see any discussion on that.\n\n**Questions**\n\n- Why 2-gram overlapping is used as a measure for abstractiveness? What is the motivation?\n- If the feature refers to specificity (as in section 3.2), what is the criteria to split the training dataset?\n- Is it possible to perform human evaluation to judge the diversity of the generated summaries?\n",
            "summary_of_the_review": "The novelty of the proposed method is thin. However, the paper presents rigorous experiments and evaluation to validate the main claim. Performing human evaluation to judge the quality of the generated summaries would be beneficial.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a new architecture for controllable text summarization, leveraging multiple decoders (with the bottom decoder layers  shared across decoders) with the contributions of each decoder controlled by a gating mechanism. This model is studied in two gating settings: unguided (where the network learns the gating weights) and guided (where gating is controlled manually). The networks are shown to allow some stylistic controllability, most notably in terms of abstractiveness and specificity.\n",
            "main_review": "Strengths:\n- the paper is well motivated and tackles a hard and long-standing problem with seq2seq models: diversity and controllability.\n- the approach is fairly simple, interesting and to the best of my knowledge, novel. \n- the paper is well structured, clearly explained and free of orthographic/grammatical issues.\n\nWeaknesses:\n- It is surprising to use beam search as the only baseline algorithm for generating >1 summaries as it is a poor way to generate diverse outputs. It would have been more interesting to compare with diverse beam search, nucleus sampling, etc, possibly in addition to beam search. Can these algorithms be added to the analysis? Even if metric increases are more modest, the proposed approach still provides better controllability which is interesting in its own right.\n- Can the guided setting allow the model to manage gating? Otherwise, this makes the guided setting dependent on manual inputs while not letting the model learn dataset-specific gating. Given the authors used heuristics to partition the datasets, could these partitions be used as a supervision signal for gating? If not, why not?\n- The proposed approach has a non-negligible computational cost, compared to using a single decoder, that it would have been interesting to discuss. \n- The literature review is fairly short and to the point. Diversity and controllability have been large research areas in the past few years and it would have been helpful to, at the very least, provide more details on the cited papers and contrast them with the proposed approach.\n\nNits:\n- In Figure 1, the baseline summaries are likely generated using beam search. It would be good to mention it explicitly.\n- In Table 2, it would be clearer to mention R1/R2/RL as was done in Table 1.\n- In Table 2, R2 for XSum is lower than that of the baseline, so it should probably not be written in bold.",
            "summary_of_the_review": "Overall this is an interesting paper proposing a new approach to stylistic controllability for neural text summarization. To the best of my knowledge, this approach is novel. I believe this work is interesting as is, but were surprised by some of the experimental settings that I would like to see clarified by the authors.\n\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes an architecture for controlled summarization, allowing some type of aspect-based summarization, as in - for example - \"I want long/detailed summary\". The control proposed here is on what the authors call _stylistic_ features (which also includes _quality_, arguably not a stylistic aspect) and not other aspect (as in for example: give a summary of Darius the Great focusing on his earlier years).\n\nThey obtain this by using a Transformer (BART-like) seq2seq model, but where the last layers of the decoder are multiplied and considered as independent expert which are combined in the end. That combination consists in a weighted average (no non-linearity) of the last softmax layers.\n\nThe proposed solution is simple (good!) although not very elegant. The analysis focuses on evaluating the control capacity and diversity with respect to other (smaller) architectures.",
            "main_review": "Strengths:\n1. This provides an alternative to controlled generation. Standard solutions so far include control tokens (not cited, see eg [1]) or a-posteriori filtering (cited) which have drawbacks (less flexibility for the former, very expensive for the latter). \n2. The idea is simple (Methodology section takes just over 1 page)\n3. The paper has an in-depth analysis part, showing convincingly that stylistic features are indeed captured and can be used for control. Most importantly (I consider this the main novelty of this approach), they can be combined. Unfortunately, there is not much space left for detailed analysis on this generalization capacity of the proposed approach.\n\nWeaknesses.\n1. The proposed solution only acts on the single token level, as it intervenes by combining experts that predict individual tokens. This is an inherent weakness of auto-regressive models, although recent alternatives have been proposed (see [2] and references therein)\n2. The compared baselines do not include any of the existing approaches (like those mentioned in Strength1). Comparing one controlled model against other non-controllable models and not considering how the problem was tackled so far is a pity. The compared models are (probably) much smaller as they do not incur in the extra cost of the additional adapter layers. For fair comparisons, the model sizes should be equivalent\n\n\nAs a potential upper bound for ROUGE (page 6), instead of picking topK, one possibility would be to select for each document the decoder which obtains the best summary.\n\n[1] Self-Supervised and Controlled Multi-Document Opinion Summarization. EACL 2021\n[2] A Step-Wise Weighting Approach for Controllable Text Generation. ICLR 2022 submission (K8HF8tTQ-4i)",
            "summary_of_the_review": "A valuable contribution to controlled generation. The evaluation focuses on the strong point of the models (more diversity) and is somehow unfair (against non-controllable models that are smaller). In this sense it is not clear if it is better or just different than existing methods.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}