{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper proposes improving human interpretability and manipulability of neural representations by obtaining syntactic roles (here, subject, object, prepositional object, and main verb) without supervision by means of them becoming linked to latent variables in a novel proposed attention-driven VAE (ADVAE) model, which provides cross attention between a language transformer and latent variables. The paper argues that syntactic roles are quite central to meaning interpretation and that the ADVAE recovers them better than LSTM or Transformer (with mean pooling) VAEs.\n\nThis is a quite interesting direction and paper. There was active discussion with the reviewers, one of whom (9pDc) moved their rating from reject to quite strong support, while the other reviewers either sat on the fence or raised from reject to borderline. Nevertheless, I overall tend to agree that the paper is still lacking in empirical support, a view clearly shared by reviewers WuPD and 7uFL. The SNLI data is very simple descriptive sentences, nearly all in the form of S V O or S V PP. Would this work on more complex data, in other languages, or with more word order variation? There isn't very much investigation, but the new results added during reviewing based on Yelp data seem to offer more concerns than confidence. These are also very short sentences but with more varied structure and some complementation. It seems like D_{dec} is now very low (much lower than for the sequence VAE), the ability to distinguish out grammatical roles seems limited to {subj} vs. {dobj, pobj} in the encoder and none at all in the decoder (Figure 6/7). And then for the examples in Appendix D, the disentanglement abilities barely seem stronger than being able to pick out subjects, though when there are sentences with subordinate clauses, it is perhaps random which subject you get. The resampled realizations in appendix H also seem to show limited disentanglement: resampling the subject usually seems to change the object as well, often markedly. No convincing downstream applications are shown. As such, while I agree that disentanglement is at the heart of representation learning, I can't get on board with reviewer 9pDc feeling that this paper now has convincing results. Reviewer 7uFL also emphasizes that there is no strong reason that the latent variables have to align with syntactic roles. In particular, the motivation in NMT whereby constituents clump and reorder together does not exist here. It may only work for the very simple and regular sentences of SNLI.\n\nHence, overall, I feel that this method needs more extensive validation on harder, more varied data sets before it becomes a convincing contribution, and so I propose rejecting the paper at this point in time. Nevertheless, I do think the topic is interesting and this approach has the potential to be good."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper propose a framework to obtain the disentanglement of syntactic roles as latent variables for sentence representations. The model is an attention-driven VAE which maps syntactic roles to separate latent variables using an encoder-decoder framework. In the second part of the paper, the authors introduce an evaluation protocol to quantify disentanglement between latent variables and spans both in the encoder and in the decoder, which includes syntactic role extraction, latent variable influence on decoder, encoder influence on latent variables and disentanglement metrics.",
            "main_review": "Strengths:\n- Learning the syntactic disentanglement in an unsupervised way.\n- Providing a series of evaluation protocol aimed at measuring the disentanglement of syntactic roles, which can be used by other work focus on syntactic disentanglement for sentence representations.\n\nWeakness:\n- The paper is hard to follow.\n- The evaluation protocol only contains intrinsic evaluation, but how these learned latent variables can help the downstream tasks is not clear. For example, whether this can help unsupervised dependency parsing?\n\nOverall, I think the paper provides an interesting perspective for learning syntactic disentanglement. However, I really suggest the authors to reorganize the paper. I cannot understand the main problem settings until I read the paper twice. To help the reader get the background knowledge, the authors can provide some related work in learning disentangled representations at the very beginning of the introduction (basically just remove some part in Section 6). Another issue is Figure 2, the caption does not indicate what is the input and output of the framework, which is illustrated in the following section instead, and the reader need to refer to the next part of the paper to understand the figure. There are some essential information in the appendix that really need to be moved in to the main body, e.g., some analysis of the latent variables and syntactic roles.\n\nSome questions:\n- How to determine the value of N_z? Is this related to the number of syntactic roles?\n- The syntactic roles used in evaluation protocol are from a dependency parsing instead of gold standard one.  Have you considered testing on texts that have annotated dependency structures?\n- What does the predicative structure in Figure 1 do with the syntactic roles discussed in the paper?",
            "summary_of_the_review": "As a final comment, this work does some contribution for learning and evaluating syntactic disentanglement for sentence representations, and will be helpful to the community. However, the writing of the paper should be improved. For detailed comments please refer to the main review.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "## Summary\n\n- This paper proposes a probabilistic model called Attention-Driven Variational Autoencoder (ADVAE). This model is another instance of $\\beta$-VAE whose encoder and encoders are composed of Transformers rather than previous neural architectures such as RNN.\n- The authors aim to disentangle the semantics of latent variables according to some syntactic roles (e.g., nouns and verbs) defined by syntax. To achieve this goal, they suggest employing the combination of Transformer and the existing $\\beta$-VAE framework which is known to be effective for disentangling the role of each latent variable in VAE.\n- Moreover, this work presents a new way of quantifying syntactic disentanglement between latent variables, relying on the information obtained from the attention matrices of the Transformer architecture.\n- The experiments show that the proposed method is quantitatively better than the normal VAE, and that swapping the value of a specific latent variable can impact the generation of the target word (decided by the syntactic role of the latent variable we choose).",
            "main_review": "\n## Strengths (Reasons to accept)\n- The paper is generally well-formed.\n- It proposes a new protocol that can be utilized for estimating the extent to which each latent variable is mapped to a specific syntactic role.\n\n## Weaknesses (Reasons to reject)\n\n- I'm not sure this work is the first that attempts to combine Transformers into the VAE framework. For instance, Li et al. (https://arxiv.org/pdf/2004.04092.pdf) already proposed a model consisting of pre-trained Transformer encoders and decoders.\nConsidering that the main novelty of this paper comes from the fact that the authors suggest exchanging the previous RNN to Transformer, it is doubtful this work has a meaningful novelty.\n- It is encouraged for the paper to self-contain the specification of the exact Transformer architecture (one with co-attention, Lu et al (2019)) utilized in this work.\n- There is no (theoretical) guarantee that the proposed method is specialized for assigning specific syntactic roles to latent variables, except that the method (by relying on the existing $\\beta$-VAE) encourages the latent variables to \"generally\" represent different aspects of sentences. Please explain why the proposed framework should be decent for disentangling \"syntactic roles\" rather than other linguistic or semantic properties.\n\n",
            "summary_of_the_review": "To summarize, even though this paper demonstrates that Transformers with $\\beta$-VAE can be an attractive option for generating latent variables representing some syntactic roles, its novelty is generally limited to the fact that it proposed a new evaluation protocol aimed at estimating the extent to which each latent variable is mapped to a specific syntactic role.\nTherefore, my suggestion is a weak reject.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a method for unsupervised disentanglement of text components and shows its ability to identify semantic roles.\nTo this end, a neural network is trained to compress the input into a fixed number of independent latent variables which are regularized to be standard Gaussians via the VAE framework. The inference network consists of a Transformer encoder-decoder network, where the decoder inputs correspond to the latent variables, which cross-attend to the outputs of the Transformer encoder, i.e., the encoded sentence. The idea behind this architecture is that attention-based seq2seq architectures align source and target sequences with each other.\n\nThe model is evaluated on disentanglement of semantic roles. To this end, they investigate how resampling of individual latent variables impacts the semantic roles in the text generated by the decoder, and how syntactic roles are aggregated into latent vectors via attention. They find that their proposed architecture is more successful at disentangling semantic roles into the latent variables than standard VAEs.",
            "main_review": "Strengths:\n\n* The paper studies a research question that is at the heart of representation learning, which could potentially be very impactful\n* The model is based on an intuitive and simple idea\n* The results are convincing and well presented\n\nWeaknesses:\n\n* No ablation studies. In my opinion, the results are not actually conclusive about what model components are responsible for the improvements. For example, the VAE baseline is based on LSTM encoder-decoder models, whereas the proposed model employs Transformers. Moreover, the VAE baseline seems to be significantly smaller than the Tranformer. Are these two models really comparable enough to conclude that the improvements are due to the product of Gaussians formulation? I think a fairer comparison with minimal changes between the baseline and proposed model could be made as follows: Pool the outputs of 2b) before estimating a single Gaussian distribution, which can then be used as a standard VAE.\n\n* The concrete architecture is not well motivated: It is not clear to me why the inference network architecture has to look the way it does in 2b). Does the model actually use co-attention (i.e., sentence representations and latent variables serve as queries for each other)? Figure 2b) looks like a vanilla Transformer encoder-decoder architecture to me, which uses cross-attention, not co-attention. Moreover, it is not clear that the model actually needs self-attention to refine the latent variables. Wouldn't the model still work if the learnable $e_{z_i}^{enc}$ functioned merely as queries to a single additional attention function on top of the Transformer encoder (followed by a linear layer and softplus)?\n\n* Some related work is not discussed. Specifically, Behjati and Henderson (2021) propose a very similar architecture for learning meaningful units in text: They train an autoencoder with a fixed number of latent vectors via slot attention, which are supposed to capture morphemes. Could their model be applied to disentangle semantic roles, too? In general, how does your work compare to slot attention (Locatello et al. (2020))\n\nMinor:\n* Table captions should appear above the table according to the style guide\n\nLocatello et al. (2020): https://arxiv.org/abs/2006.15055\n\nBehjati and Henderson (2021): https://arxiv.org/pdf/2102.01223.pdf",
            "summary_of_the_review": "While the research presented in this study is very exciting, it is not quite convincing enough yet for me to trust that the results are actually due to the modeling decisions presented. Moreover, a similar work (Behjati and Henderson (2020)) is not discussed, which casts doubt on the novelty of the approach. I therefore recommend to reject the paper in its current state, but I am happy to change my scores upwards if my concerns above can be resolved.\n\n* UPDATE:  I raised my score slightly as a consequence of the rebuttal phase, where authors conducted an ablation study that now more clearly shows that the improvements over standard VAEs are due to multi-vector nature of the representation rather than just because of using Transformers.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a new model ADVAE, which uses a sequence of latent variables which are constructed using cross-attention, which are then used to condition the inference model. The findings show that certain latent variables correlated with different syntactic roles (measured using a dependency parser).  The work claims that the latent variables, in this case, are able to disentangle content effectively, which I am inclined to agree with, however, I feel that the experimental setup is lacking to solidly support this hypothesis (which I detail in the “cons” and “questions” section). ",
            "main_review": "Pros:\n- The insight that cross-attention disentangles content automatically in Transformers is interesting, and I feel that this insight could be exploited for a variety of controllable text generation tasks. \n\nCons:\n- The baseline VAE is not a proper comparison, given that an LSTM is used (versus a Transformer in the proposed model). Please either make the proposed model LSTM-based or the baseline a Transformer.\n- I feel that the ADVAE, while explained relatively clearly in the figure, could benefit from a step-by-step explanation in the text. I found it slightly confusing to follow section 3, which could benefit from a re-organization: for example, 1st introduce the operations happening in Fig 2b, describe the latent variable generation procedure, and then what happens in Fig 2c (reconstruction). An example of a paper that I feel does this well is Zhang et al., 2016.\n- I also feel that the impact of increasing/decreasing N_z is not discussed enough (e.g. if you increase the N_z to become the maximum sequence length, what happens, etc…).\n- Overall, I feel it would be pertinent to test how well different aspects (not just syntactic roles) are disentangled. Rather than the method per se, I feel that this insight into unsupervised disentanglement is interesting, however, constraining the method to syntactic roles can be limiting. For example, for the “low complexity” datasets (e.g. sentiment analysis), it would be interesting to see when running your method, is there a vector that emerges that can control sentiment, or is it able to both disentangle syntactic roles and sentiment, etc….? (As far as I know, John et al. 2019, did this in a supervised manner).\n\nMinor comments/missing references:\n- Machine Translation/MT Transformer -> Transformer encoder-decoder models (as this architecture is widely used, even in non-MT tasks)\n- Sentence representations have been extracted from sequence-to-sequence Transformer models before (Lewis et al., 2020, Raffel et al., 2020, Siddhant et al., 2020)\n- The [CLS] representation is generally the default sentence representation in BERT (not [SEP])\n- p_r (the dependency parser?) is not defined.\n\nQuestions/Other comments:\n- It would be interesting to compare the variational model to a denoising AE (seq2seq masked language model; Lewis et al., 2020), in which the input is corrupted and the prior distribution is removed). This could make the method more generally applicable, even to large pre-trained models.\n- Furthermore, I am sceptical of the use of self-attention when computing the mean and standard deviation vectors (Fig 1b). I would be curious what would happen if only cross-attention would be used. If that is the case, then the argument could be made that the original e^{enc} vectors correspond to a syntactic role (or other factors) themselves.\n- Also, it would be curious if this emerges in machine translation (given the motivation stated as such), where the source and target represent the same sentence in different languages.\n---\n\nLewis, Mike et al. “BART: Denoising Sequence-to-Sequence Pre-Training for Natural Language Generation, Translation, and Comprehension.” Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (2020): n. pag. Crossref. Web.\n\nSiddhant, Aditya et al. “Evaluating the Cross-Lingual Effectiveness of Massively Multilingual Neural Machine Translation.” Proceedings of the AAAI Conference on Artificial Intelligence 34.05 (2020): 8854–8861. Crossref. Web.\n\nJohn, Vineet et al. “Disentangled Representation Learning for Non-Parallel Text Style Transfer.” Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (2019): n. pag. Crossref. Web.\n\nRaffel, Colin et al. “Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.” ArXiv abs/1910.10683 (2020): n. pag.\n\nZhang, Biao et al. “Variational Neural Machine Translation.” Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (2016)",
            "summary_of_the_review": "Overall, although I like intuition and motivation, however, I feel the empirical support is lacking. I would be willing to raise my score if experiments on other aspects or in other languages were done. I believe this would further reinforce the claims made in the paper regarding unsupervised disentanglement.\n\n---\nPost rebuttal:\n\nI appreciate the additional experiments the authors provided and their time and effort in writing the rebuttal. This has clarified some of my concerns and added extra evidence to the paper. For this reason, I will raise my score to a 5. Despite this, I still feel that a more general approach, able to disentangle different factors, or in different languages would add more substance that I feel this paper is lacking.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}