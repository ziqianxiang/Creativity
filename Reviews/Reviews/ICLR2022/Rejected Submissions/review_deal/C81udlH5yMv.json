{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The reviewers are in consensus. I recommend that the authors take their recommendations into consideration in revising their manuscript."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "- The paper claims to provide a unifying causal framework for invariance-based algorithms.\n- It uses the graphical model in figure 1 to derive some conditions for achieving invariance.\n- It also develops a new algorithm for invariance-based representation learning. The idea is based on conjecture 4.3, which hypothesizes that one can create new domains using mixtures of existing ones.\n",
            "main_review": "- There are several fundamental misconceptions in this paper. \n    -  Invariance is a property of causality that has been well established.\n        - The invariance literature is in fact motivated and established through the causal graphs. \n        - See [1] for a survey. For a textbook treatment, see chapter 2 of [2].\n    -  Causal and Anti-causal\n        - Factor models are different from causal models. Figure 1 is not a causal graph. It is a graphical model. A causal graph reflects the true data generating process in the world. \"Background color\" is not a variable in the world. \n        - If I were to interpret figure 1 charitably, it is plausible that it actually means a human's perceiving process. However, that argument was not made in the paper.\n        - The difference between how the world works and how humans perceive is the central debate between causal and anti-causal. It is not whether the task is image classification or not. The arguments such as the work like IRM is only about causal but not anti-causal are plainly wrong.\n- The algorithm is reframing the IRM algorithm. The theorems are all tautological\n    - Theorem 3.1 is just a conditional independent statement.\n    - Theorem 4.1 and theorem 4.2 are circular statements. Invariance is defined (in def 3.2) with respect to total causal effect & conditional independence.  \n    - Conjecture 4.3 is factually correct. Those mixture environments are just environments/domains induced by soft intervention. It's also the setting of IRM. However, there is no argument for why that would increase OOD performance.\n    - the algorithm in eq 1 is just reframing eq 1 in IRM.\n\n- Writing \n    - The authors did not introduce many concepts that are essential to their theoretical analysis. Examples include the do notation and the causal graph. The total causal effect is critical to the results, but it's only briefly introduced in the footnote.\n\n- references\n    - [1] \n@article{scholkopf2021toward,\n  title={Toward causal representation learning},\n  author={Sch{\\\"o}lkopf, Bernhard and Locatello, Francesco and Bauer, Stefan and Ke, Nan Rosemary and Kalchbrenner, Nal and Goyal, Anirudh and Bengio, Yoshua},\n  journal={Proceedings of the IEEE},\n  volume={109},\n  number={5},\n  pages={612--634},\n  year={2021},\n  publisher={IEEE}\n}\n  -  [2]\n@book{peters2017elements,\n  title={Elements of causal inference: foundations and learning algorithms},\n  author={Peters, Jonas and Janzing, Dominik and Sch{\\\"o}lkopf, Bernhard},\n  year={2017},\n  publisher={The MIT Press}\n}\n\n   -  IRM \n@article{arjovsky2019invariant,\n  title={Invariant risk minimization},\n  author={Arjovsky, Martin and Bottou, L{\\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},\n  journal={arXiv preprint arXiv:1907.02893},\n  year={2019}\n}",
            "summary_of_the_review": "The paper has several fundamental issues, including a misunderstanding of the existing work.\nNotably, the algorithm proposed in this paper is very similar to the algorithm in IRM.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper considers a causal framework for invariant representation learning, with some analysis about the invariance and independences based on the proposed causal graph. An algorithm is then proposed based on the above analysis and empirical result validates the performance of the proposed algorithm. The paper is well written.",
            "main_review": "For the causal analysis part, authors propose a causal graph, which is a slight modification of the causal generative process proposed by Suter et al.(2019). Authors claimed “our proposal naturally captures most of the existing invariant representation learning tasks and datasets”, but I did not find much content showing how this causal graph could do so. Recent works have proposed different causal graphs for similar tasks (DG, fairness, etc.) and each has certain reasoning about the causal graph. Note that causal graph is untestable from data, so I keep neutral on this part. \n\nThe rest of the analysis, e.g., theorems, is based on the proposed causal graph, which is somewhat straightforward. Theorem 4.2 is misleading: a number of domains are firstly given but the statements do not specify what the are the domains. Indeed, after checking the proof, it really means all the possible domains or interventions. Then this is a trivial result according to the definition. \n\nConjecture 4.3 is not sufficiently motivating for the algorithm. Recall group DRO. The minimax problem is defined wrt the mixture of availability domains or distributions, but the optimum can be achieved by only considering the finite available domains, so there is no need to consider the mixture into optimization. Similarly, if the given domains satisfy the so called independence constraint, then any mixture does and vice versa. Thus, in theory, there is no need to consider the mixture processing in the algorithm. Please correct me I am wrong here.\n\nExperiments show some improvement, but not very strong; see,e.g., the DG tasks. But that is OK from my side.\n\n",
            "summary_of_the_review": "Overall, the theoretical part (analysis, foundation for the algorithm) is weak. Given that the empirical results are not very strong, I cannot recommend an acceptance. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work provides a causal perspective and new algorithm for learning invariant representations from multiple domain datasets. This work introduces the notion of style variables and shows theoretically that being invariant to the domain index actually leads to invariance to the style variables. The extensive experiments demonstrate the usefulness of the proposed algorithm in various tasks.\n",
            "main_review": "The paper is well-written and easy to read. The proposed algorithm is pretty straightforward. \nI am however not sure if the proposed algorithm would be successful in learning invariant representations. As a toy example, imagine two datasets from different domains with only two features: x1 and x2. Now let’s say the distribution of x1 is the same for both datasets but not for x2. In other words, x2 is the style variable that should be eliminated from the learned representation. Now if we sample from these two datasets and create two mixed datasets (following the proposed algorithm) we would have two datasets with almost identical distributions (likely multi-modal). I can’t see how minimizing the distance between the distributions of these two mixed datasets would eliminate the style variable.\n",
            "summary_of_the_review": "The toy example described above shows that the proposed algorithm should not be able to learn invariant representations. There is however the possibility that I have misunderstood parts of the paper. I’m willing to increase my score should the authors address the above-mentioned issue.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}