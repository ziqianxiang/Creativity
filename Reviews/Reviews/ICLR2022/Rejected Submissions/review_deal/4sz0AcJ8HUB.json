{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper tackles a very important problem of detecting depression on Twitter. As the reviewers expressed in their reviews. this paper will be of interest for the community of researchers applying ML models to mental health domain. It is unfortunate that the authors did not respond to the reviewers' concerns and questions. I strongly encourage the authors to improve the paper based on the authors comments and questions and resubmit to a future venue."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a concatenation approach to combine multiple social media texts through a stacked embedding layer and demonstrates its effect in depression prediction based on text.",
            "main_review": "The motivation and the results of the paper are very interesting and definitely will be of importance in a more applied community focused on NLP or ML for mental health. However, the technical novelty for a venue such as ICLR is somewhat limited. All network components used exist already and while the different pre-training embedding models used appear to be effective, they do not teach us anything new about deep learning.\n\nI would suggest to the authors to consider a different venue that appreciates this kind of findings.",
            "summary_of_the_review": "(see above)",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a deep learning approach, called SERCNN, for depression detection from social media data (tweets). The proposed approach is flexible and stacks different embeddings (Glove pretrained model,  and a learned embedding vector from LSTM) for robust and richer tweets representation. Overall, the contributions of this approach are third folds: i) leveraging social media as a valuable source of information for depression detection; ii) the authors employ stacked-embeddings is a good technique to handle out-of-vocabulary words; and iii) Using a few training examples (e.g., 10 tweets per user), the proposed approach showed a remarkable performance (78% accuracy) in depression prediction.  Further, the authors conduct a set of experiments on a public Twitter dataset for depression detection and compare it with different baselines. ",
            "main_review": "**Strong Points:** \n* In general, the paper is clearly written and easy to follow. The problem of depression detection is well-motivated, the overall presentation is good.\n* The authors discussed adequately different related works to the problem of depression detection. They stated the gap of the existing approaches, which rely on handcraft features to detect depression.\n* The authors describe well the preprocessing steps and create a balanced version of the dataset for training the model. \n\n**Weak Points:**\n\nWhile most of the paper is easy to understand, there are some points in the paper that lack clarity for the novelty and significance.\n\n* The authors propose a flexible concatenation of different embeddings for a robust and rich tweet representation. However, the novelty of this method is inadequate compared with state-of-art contextualized embeddings such as BERT.  For example, the research work [1] addresses the same problem and considers contextualized embeddings (e.g., BERT, Roberta) as state-of-art-embeddings baselines. Here, I suggest the author benchmark their approach against BERT embeddings. For example, the authors can use BERTweet [2] as a baseline to SERCNN . \n* In table 2, the authors show the hyperparameters optimized for the proposed approach and baselines. This is not clear to me that all models are optimized by the same hyperparameter values, given that these models have different architectures.\n* Some details about the experiment's setup are missed. For example, how the authors split the data for training, validation, and testing the models (e.g., train-test split ratio). Is there overfitting during the model’s training? \n* Further, stacking embeddings is also not memory efficient. I find the advantage of stacked embeddings is addressing out-of-vocabulary words. Here, I suggest the authors conduct more experiments to highlight this contribution in their experiments as well.  \n* Since the authors didn’t specify the test data used, It would be better to evaluate their approach on a different dataset (see [3]), which may contain out-vocabulary words, and can show the efficiency of the proposed approach. \n* Also, I wonder if stacking embedding is efficient for this task only? Or It’s a generic, richer representation that can achieve good performances with very little data. \n* In section 5, The authors analyzed the performance of their approach with little training data (e.g., 10, 30, 100, 500, etc.) I wonder how do you sample these tweets from the dataset, randomly?. Here, I recommend obtaining multiple samplings and performing a standard statistical test to benchmark how significant are the outperforming results.\n* Although, this study lacks the explainability of depression detection, and the authors name it as future work. I find some studies [4] in 2020 that address depression detection with an explainable approach. \n\n\n[1] Zhang, Yipeng, et al. \"Monitoring depression trend on Twitter during the COVID-19 pandemic.\" arXiv preprint arXiv:2007.00228 (2020).\n[2] https://github.com/VinAIResearch/BERTweet \n[3] https://github.com/swcwang/depression-detection   \n[4] Zogan, Hamad, et al. \"Explainable Depression Detection with Multi-Modalities Using a Hybrid Deep Learning Model on Social Media.\" arXiv preprint arXiv:2007.02847 (2020).\n\n\n\n",
            "summary_of_the_review": "Overall, I rate this paper as marginally below the acceptance threshold (5). The problem is interesting, however, the proposed approach lacks a comprehensive evaluation with state-of-the embedding models to ensure the efficiency of the approach. For example, the authors can employ BERT embedding as a baseline to evaluate to which extent SERCNN approach is good. Further, I suggest the authors, clarify how do they perform sampling (e.g., 10 tweets) to assess their approach with little data.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper develops a SERCNN, which consists of stacked embeddings and Recurrent CNN (RCNN), for depression detection from Twitter text. The key idea of stacked embeddings is to concatenate two embeddings, based on two different word embeddings models (pre-trained on Twitter and Wikipedia copora), into a single embedding vector, which is fed into RCNN. Experimental results on the Twitter Depression dataset show reasonable performance when trained on 10 posts from each user, which was further improved when trained on more data. \n",
            "main_review": "### Strength\n\n- (S1) SERCNN shows solid improvements over existing solutions on the Twitter depression detection dataset. \n\n\n### Weaknesses\n\n- (W1) Novelty and technical contributions are not significant. \n- (W2) The paper lacks comparisons against pre-trained Transformer-based language models. \n- (W3) No insights about depression are provided.\n\n\n### Major comments\n\n(W1)\nSERCNN is a straightforward combination of existing techniques. Essentially, the paper combines 2x GloVe word embeddings into a single vector (without using any learning mechanism) for each input word and then uses the concatenated vector as input to an RCNN model. \n\n\n(W2)\n\nThe author(s) mention the reason why they prefer RCNN over RNN is to capture context information over a long sequence, which can be addressed by using the self-attention mechanism.\n\nThe paper does not compare with any Transformer-based models, especially pre-trained Transfomer-based language models (e.g., BERT or more recent models,) which are considered more label efficient than conventional word embedding models (e.g., GloVe) + RNNs (technically, this paper uses RCNN.)\n\nIn fact, pre-trained language models were already used in the context of emotional detection from text. Thus, it is not natural to disregard the technique for depression detection. For example, \n\n- [1] Yen-Hao Huang, Ssu-Rui Lee, Mau-Yun Ma, Yi-Hsin Chen, Ya-Wen Yu, Yi-Shin Chen, EmotionX-IDEA: Emotion BERT – an Affectional Model for Conversation, SocialNLP 2019. (https://arxiv.org/abs/1908.06264)\n- [2] Kisu Yang, Dongyub Lee, Taesun Whang, Seolhwa Lee, Heuiseok Lim, EmotionX-KU: BERT-Max based Contextual Emotion Classifier, SocialNLP 2019. (https://arxiv.org/abs/1906.11565)\n\n\n(W3)\n\nI would expect to see new findings of depression detection on Twitter. The paper simply presents a technique (which has issues with respect to novelty and technical significance, as commented above) and claims the contribution by showing the numbers. This point may not be the main scope of ICLR (i.e., which may put more emphasis on technical contributions,) but I believe it is very important for application-oriented papers. \n\n\n### Minor comments\n\n- (Presentation style) Figure 2 is misleading. The figure looks like a linear layer is applied on top of the concatenated vector, which is not (i.e., the concatenation.)\n",
            "summary_of_the_review": "Although the paper tackles an important problem, it does not have a sufficient level of novelty and technical contribution. SERCNN is a straightfoward combination of existing methods. SERCNN relies on pre-trained word embedding models. Pre-trained Transformer-based language models should be compared. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a stacked embedding recurrent neural network, named SERCNN, to detect depression from Twitter. First, the authors use stacked meta-embedding to gain the stacked word information. Then, the RCNN structure is utilized to capture contextual features. The experimental results show the effectiveness of the proposed model.",
            "main_review": "+Ves\n+ The depression detection application is valuable, and the method achieves good performance.\n+ The whole structure is nice. \n\n-Concerns\n\n-The key concern about the paper is the lack of novelty. The RCNN method is classic, and the word embedding concatenation is also very common. So, the novelty of this paper is not enough.\n\n-The motivation is not clear. The reason why the authors use RCNN and what problem the authors want to solve should be explained, rather than only for getting better results. \n\n-The paper says “Instead of using the recent transformer model”, Why not use transformer-based methods, like BERT? The authors should explain it and add comparative experiments.\n\n-In the experimental results, why does the EHAN achieve the best results and not the proposed ERCNN? In addition, the paper says that the ERCNN can achieve best performance when using a few posts, but there are no comparative results that contain results of other methods with 10 posts or 100 posts.\n\n-The authors should add ablation studies to show the effectiveness of stack embedding.\n\n-The related works are not sufficient and many latest literature are missing.\n\nMinor comments: \n\n* Different evaluation metrics should not be put in one figure (Fig. 4).\n\n* Some references should be added for background.\n",
            "summary_of_the_review": "The novelty is not enough, and many experiments are missing.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}