{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper proposes a method for predicting stock market crises using a deep learning approach which combines time series stock market data with text from news articles. Their experiments show that the proposed method works better than the same model using only news or only stock price data, and a couple of deep learning baselines. All the reviewers pointed out that this paper is lack of novelty and significant technical contributions. The experiments are performed on a single dataset with incomplete baselines, and hence insufficient to support the claimed advantages of the proposed method. The writing quality is not up to the standards of an ICLR papers, with too many grammatical mistakes, typos, and unjustified arguments/claims.  The clarity of the writing is poor.\n\nThe authors did not provide their rebuttal."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a method for predicting stock market crises using a deep learning approach which combines time series stock market data with text from news articles.  Experiments find that the method works better than the same model using only news or only stock prices, and a couple of deep learning baselines.",
            "main_review": "Strong points:\n\n- The combination of text and financial data is a worthy area of study (although this work is not the first to try to do this).  Using BERT is a promising approach here.\n\n- An ablation study showed that both the news and stock portions of the model were important to get the best performance.\n\nWeak points:\n\n- The proposed model is not particularly novel, as far as it is explained.  Surely the authors are not the first to combine text and financial data, and the precise novelty is not well argued.\n\n- The fusion aspect of the approach is fairly pedestrian and does not consider how text and stock prices interact and change over time.\n\n- The details of the proposed TS-BERT model are a bit unclear in the paper. Figure 2 is helpful but it does not suffice. There needs to be equations in the paper describing the precise details of the model. I definitely could not replicate the authors' method based on what is included in the paper.\n\n- It is unclear why keyword extraction was performed based on the BERT embeddings, instead of simply using the BERT embeddings.  There would be a loss of information in this step.  If this step is useful, experiments should be provided which show it. Similarly, the role of N-grams in Figure 2 is unclear.\n\n- The training algorithm for the model needs more explanation.  What is the loss function, what is the optimization algorithm, and how is fine-tuning used?\n\n- Only one dataset is used in the experiments.\n\n- There are insufficient baselines.  Other state of the art text + stock price models, and published models considering these aspects separately, should be compared to (e.g. models which were mentioned in the related work section).\n\n- Both of baselines which were used are a bit strange and unclearly explained.  The GCN method represents word and stock features as a graph, but this data is not naturally graph structured, and it is unclear how the graph was constructed or what the rationale was.  The use of TF-IDF in this context is also very unclear.  Similarly, it is not clear why the CNN model also includes an LSTM component, or how these two were put together.  I don't know why there weren't simply separate LSTM and CNN baselines.\n\n- There are numerous grammatical errors throughout the manuscript.  There are other clarity and framing issues as well, e.g. the paper goes back and forth between saying that the task is stock forecasting (i.e. predicting stock price), and predicting the occurrence of crises.\n\nAdditional feedback / minor suggestions:\n\n- The equation regarding BERT doesn't seem to be the right one. Or at best, it does not capture the unique aspects of BERT, such as the transformer-based architecture, bidirectional representations, and the masked language model and next sentence prediction training objectives. \n\n- There needs to be a citation for the MCB method. What does the acronym stand for? Including equations to explain it would help as well, if space allows.\n\n- \"table1\", \"table2\" - should be \"Table 1\", \"Table 2\".\n\n- The Acknowledgments stub from the conference template was left in the paper.\n\n- The title is not consistent in its use of capitalization.\n\n- BERT is not consistently capitalized throughout.\n\n- Section 3.2.3 heading has inconsistent capitalization. Below it, \"Embedding connection\" looks like it should be a heading, instead of the first two words of a different sentence.\n\n- Many citations should be put inside parentheses, especially when they occur at the end of sentences. E.g. \"Sezer et al. (2020)\" should be \"(Sezer et al., 2020)\" in its use on page 1. Use the Natbib \\citep{} command.\n\n- Is MTGNN the method which is referred to as GCN in Section 4.2? Name it consistently.",
            "summary_of_the_review": "While the combination of text and financial stock data via BERT is an interesting task, the paper presently has multiple serious issues in novelty, clarity, and experimental rigor.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper introduces a method that combines the representation of text and time series to make financial crisis predictions. The proposed methods outperform all the baseline methods.",
            "main_review": "Strengths:\n- The method is well-motivated and the problem is interesting.\n- The proposed method achieves the best performance in the empirical study,\n\nWeaknesses:\n- There are too many apparent and fundamental mistakes in this paper:\n    - Though it looks similar, this paper does not follow ICLR's official format. For example, the title of each subsection is in lower case and the citations are in the wrong format.\n    - There are some outstanding drafts at the end of the paper (see Page 7 before the acknowledge section).\n    - The authors did not hide the acknowledge section in this submission, though there is no information leak.\n    - There are grammatical errors in most of the paragraphs.\n- The technical contribution and novelty are relatively limited or not well presented.\n- Minor problems/suggestions:\n    - Please add a link or reference to the Kaggle dataset you use.\n    - What does MCB mean. Please cite the paper which proposes it or briefly explain it.\n    - This picture is so unclear. It would be much better if using a PDF version.\n",
            "summary_of_the_review": "This paper proposes a new and powerful method to solve an intersting problem. However, the technical contribution is limited and the presentation quality needs to be greatly improved to meet the bar of ICLR.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors propose a model for stock prediction by aggregating the embeddings of automatically mined news keywords and the embeddings of stock series. The authors evaluate their model in a large dataset and show that it outperforms a TF-IDF based model and a CNN based model.",
            "main_review": "Reasons to accept:\n\n-\n\nReasons to reject:\n\nI appreciate the authors’ effort. I am certain that they have made a great effort to develop the model and prepare the paper. I’d like to also remind that my task, as a reviewer, is to provide a helpful review so that the authors can receive an outsider view.\n\n- In my opinion this article is more like a blog post which is *badly* formatted in a scientific paper. More specifically: The language is below standard, the related work coverage is very limited, the claims are contradictory, the model is too naive, the experiments are insufficient, the baselines are weak, and the analysis is superficial.\n\n- The paper has no contribution in my opinion. The main idea of the paper has been proposed before [1], and is not cited in the paper.\n\n- The authors neither in the introduction nor in the related work mention their actual contribution compared to existing works. The reader should infer this himself.\n\n- There are a number of contradictory claims in the paper. The authors state:\n“The trend of stocks is entirely random.”\nIf it is random, then why would you make an attempt to predict it?\nAgain the authors state that their baselines are weak:\n“Since these models do not have multi-modal application cases similar to our text-time series data, this result could not be considered as the best performance of the model on such tasks.”\nIf they are weak, why you didn’t use better baselines?\n\n- BERT already has a document vector representation called [CLS]. There is no need to take average of words.\n\n\n[1] Fune et al., Stock prediction: Integrating text mining approach using real-time news. CIFEr 2003.",
            "summary_of_the_review": "The presentation of the paper is below standard, it has no contributions, and the experimental setup is not convincing.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}