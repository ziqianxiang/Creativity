{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper analyses generalization ability of graph neural network from the aspect of the distance between the test data point and the training data point, where the labels of a part of the vertexes are observed as the training data and a test data point is selected from the remaining vertexes. The theoretical result indicates that if the training data \"cover\" the whole vertexes of the graph, then the test accuracy will be better. This theoretical finding is supported by some numerical experiments. \n\nThe problem this paper considers is interesting and would be worth investigation. However, the theoretical results presented in the paper are based on quite strong assumptions, and the statement of the theorem is not well exposed.  \n- First, the paper assumes that a distortion map is obtained by training and the training procedure can produce zero training errors. Although these assumptions are far from obvious in practice, the paper lacks justification of these assumption. Hence, these assumptions seem to be made only for the sake of proof.  \n- Second, the constants appeared in the theorems are not correctly specified. How different constants are correlated is not properly exposed.  \n\nAs for the experiments, they are not so strong: only Cora is experimented and training data size is small.  \nFor these reasons, this paper is not sufficiently matured to appear in ICLR."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper aims at providing a theoretical understanding of GNNs. Specifically, in terms of how the training set in theinput graph effects the performance of GNN on the testing set. \n",
            "main_review": "This paper studies the problem of understanding GNNs, which is of great interest and importance. Following are some questions that need to be clarified and addressed:\n\n1. The major result Theorem 1 is proved under assumptions 1-3 and can only be applied to GNNs ``distance-preservation property of p = 1 as given in Definition 1.'' However, the reviewer found these assumptions too strong to be applied to GNNs.\nFor example, assumption 2 does not hold for any training dataset that cannot be perfectly separated for a classification task, which is the typical case. Also, it is not clear why GNNs would satisfy distance preservation with prob 1, since GNN is a highly nonlinear mapping. To improve the usefulness of the analysis, it should be provided with a certain probability value, instead of only p=1.\n\n2. Both Proposition 1 and Theorem 1 depend on several constants:r_v, B, and delta.  However, these constants are actually related to the graph, and such relationships are intertwined in the proof. For example, in Appendix B, it is claimed delta=S-S' and delta>(\\beta-1)S, where S and S' are some quantities related to graph and testing data.  Hence, it seems to the reviewer delta is actually not a constant. Also, these \"constants\" seem to be intertwined, hence it is not clear whether they actually \"exist\". Please clarify all these constants and how they are related to the data and each other for the reviewer to better evaluate the generality and usefulness of the theory.\n\n3. The analysis only considers the case where the testing sets are already revealed in the training stage (transductive setting), it would be great if the authors could provide some insight on the inductive setting as well.\n\n",
            "summary_of_the_review": "While the paper considers an important theoretical problem, the reviewer finds the assumptions not justified and the constants claimed to exist not well-defined. The reviewer already went through the appendix to find the definition of the constants, but failed to understand why they are constants, and why they exist. Hence, the reviewer considers the submission not good enough at this stage.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper draws connection between performance of GNN and training set coverage in the graph. Specifically, it proposes theoretical study towards structural relation between them in terms of graph distance and empirical classification loss. A set of experiments are designed to validate the theory and assumption on three graph dataset. Further, the proposed idea is used in active learning as guidance.",
            "main_review": "## Strength\n1. **The illustration of the paper is clear, especially Fig.2 and 3.**\n2. **The experiments on active learning with the proposed theory is interesting and promising.**\n\n## Weaknesses\n1. **Missing some important references.** The author claims there is no existing study on dependency of the data samples and performance of GNN models. However, there are couple of work [1,2] study the generalization from non-I.I.D training data. See next point for more details.\n1. **I.I.D. condition can not hold in the analysis.**\nMost of the plot and experiments are conducted via multiple random sampling with small training size (35 on Cora, which is 5 per class). However, as theorem 1 states, the average distance can not guarantee the vertexes closer to $D$ than $D'$. Moreover, as we all know, smaller sample size brings more variance to the uniform sampling. Hence, I believe I.I.D training data is not robust during author's presentation, which makes this work more comparable with [1,2] in a generalized non I.I.D analytical setting.\n1. **The writing is hard to follow and lack of theoretical justifications**\nIn section 3.2, the technical contributions are scattered. Mentioning Loss Landscape and Network homophily makes me distracted from the main focus of the paper. Instead, I expect to see more discussion on node features, since the $M$ in theorem lack discussion of node features $X$, which I deem essential in analysis of any neural networks. Both [1] and [2] specifically include $X$ in discussion. In other words, this paper use assumption to avoid discussion on node features makes me a bit uncomfortable. I don't think you can let $\\epsilon=0$ from universal approximation of GNNs.\n1. **The experiment section is weak, the extreme small number training seeds leads to bad generalization already.**\nBased on my understanding, the main outcome of the theorem 1 is to study the correlations in Figure 4,5,6, which is quite similar with [1,2]. Specifically, you can see correlations from [1,2] is much more clear, partially because they use the embedding distance as the main measurement. However, the usage of graph distance here, again, do not consider the node features. Also, the performance of Table 1 and 2 can not align with existing semi-supervised GNN because it only uses 5 per class training seeds while 20 per class is more common. Fewer training seeds make the model worse generalization on testing and not convincing. I suggest you can use more biased samples and larger sample size (as of PPR-sampler in [2]). I also think experiments on three small benchmark is not sufficient for the significance of the study. \n\n[1] Ma, Jiaqi, Junwei Deng, and Qiaozhu Mei. \"Subgroup Generalization and Fairness of Graph Neural Networks.\" NeurIPS 2021.\n\n[2] Zhu, Qi, et al. \"Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training Data.\" NeurIPS 2021.",
            "summary_of_the_review": "Overall, I think the problem this paper studied is interesting and exciting. However, there are already bunch of studies on this \"localized training data\". So I expect more new results and observations. This paper is not directly improving the generalization performance under arbitrary samples while more useful in active learning when you have the luxury to select training samples. I would like to see a more comprehensive version in the future considering more justifications on current assumptions and experiments. Therefore, I lean towards reject this time.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper considers the problem of training set selection for graph neural network training. It shows that the generalization from the training to the test set in a well-trained graph neural network is closely tied to the shortest path distance in the graph, which motivates training strategies that \"cover\" the graph in this sense. The authors apply these ideas in a subset selection program, and verify their results with numerical experiments.",
            "main_review": "I enjoyed this paper quite a bit. The presentation was (for the most part) clear and simple, and experiments were carefully chosen. Some technical details weren't satisfactory, and some comparisons were lacking, as I explain below.\n\nDefinition 1: It is unclear at what point in this statement the proper context is in place to make a probabilistic claim about some map. Is there some probability measure on the metric space according to which the points were sampled? Please explain why the probability $p$ is needed in this definition.\n\nProposition 1: I don't have a critique of the technicality of this result, but it would be helpful to the reader to clarify that this does not relate to distances between nodes in the graph at this point. Perhaps it would be useful to add a line emphasizing that claim is only made for abstract points in the embedding space, and not for embedded nodes in that space.\n\nAssumption 3: I appreciated the empirical validation of this assumption, and I do think it would be too hard to show this holds purely theoretically. However, I do not find the justification of \"the assumption seems to hold empirically\" to be a useful explanation of this assumption. Please provide some insight into *why* you think a well-trained graph neural network would satisfy this property. In particular, it is currently unclear what kind of assumptions on the data are necessary, or at least suggestive, for this to be true.\n\nTheorem 1: My confusion here ties back to my question about Definition 1. Why are we dealing with probabilities $p$, particularly when we put $p=1$ here? And if $M$ is a GNN with distance preservation, do we mean as a map from the set of nodes with the shortest path distance to the embedding space? Your choice to use $d$ for many different metric spaces has made this confusing. Please clarify the reasoning behind this. It is also strange that you used the double bars to refer to what I think is the cardinality of the set of nodes in $B \\leq ||V||/2$: did you mean to do this?\n\nExperiments: I found the experiments in this paper quite convincing. Although I had a complaint about it earlier, Figure 4 is illustrative in showing the relationship between graph distances and embedding distances in Assumption 3. I also found Figure 5 convincing, as it clearly showed that those nodes located far away from the training set had high loss, due to unpredictability of the GNN acting on those regions of the graph. It would have been nice to see comparisons to some more GNN architectures, such as ChebNets, for instance.\n\nSection 4: I found this application of your results quite pleasant. This section does a good job demonstrating the broader scope of your results, and how they can be used to motivate graph sampling strategies. I found the experimental comparisons lacking, though. For instance, there are many better sampling methods one could imagine that would probably fare better in finding a good set of nodes. One good one would be selecting most important nodes according to their eigenvector centrality, or betweenness centrality. These approaches reflect the role of a node in the global graph better, and would make for a stronger comparison with the proposed program. Additionally, spectral methods from the graph signal processing literature ought to be included, such as [1].\n\n[1] Anis, Aamir, Akshay Gadde, and Antonio Ortega. \"Efficient sampling set selection for bandlimited graph signals using graph spectral proxies.\" IEEE Transactions on Signal Processing 64.14 (2016): 3775-3789.",
            "summary_of_the_review": "I found this paper to be well-written, focused in its approach, and convincing in its argument. I do have some issues that I hope the authors will address, so I will give this paper a weak accept for now.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper derives theoretical results showing that, in node classification problems, GNN performance is negatively correlated to the distance of the nodes in the training set to the other nodes of the graph. Numerical results are presented to validate these findings.",
            "main_review": "Technical novelty and significance:\nThis paper misunderstands generalization, as it proposes a node sampling scheme for the training set based on a fixed test set of nodes. The test set is a construct, hence, the accuracy results obtained on the test set should be seen as a proxy to measure generalization. In practice, we want to have good classification accuracy for all nodes, so picking training nodes according to their distance to a given test set skews the GNN to only perform well on this specific choice of test nodes. The authors should rethink their sampling approach. It might also be a good idea to refer to the literature of graph signal sampling, e.g. (Anis, 2016).\n\nCorrectness:\nThe theoretical results are undermined by the fact that Assumption 3 is unreasonable. This assumption is problem-dependent and unrealistic in general. It is very strong to assume that just because two nodes are close on the graph they will have the same embedding. For instance, in movie recommendation on a user similarity network, which can be modeled as a node classification problem, you may have two users (nodes) that are similar because they tend to like the same movies of the comedy genre, but that will disagree in their ratings of the horror movie under consideration because they have a different taste for horror movies. This type of relationship will typically not be learned through locality, but through permutation equivariance which allows exploiting symmetries between this node neighborhood and other node neighborhoods with the same preference makeup (i.e., neighbors who like the same comedy movies, but dislike the same horror movies) where ratings are available. The assumption that the GNN model has the distance preservation property in Theorem 1 is also too strong and hard to verify in practice.\n\nEmpirical novelty and significance:\nThe experiments are restricted to the Cora dataset, and the improvements reported in Tables 1 and 2 are marginal. The authors should run experiments on other node classification datasets.\n\nOther comments:\n- Related work is typically presented in Section 2. The authors should cite papers discussing other mathematical properties of GNNs such as permutation invariance and stability.\n- The notation in 2.1 is confusing. X and Y are used to denote vertices, representations and sets.\n",
            "summary_of_the_review": "This paper misunderstands generalization, as it proposes a node sampling scheme for the training set based on a fixed test set of nodes. The test set is a construct, hence, the accuracy results obtained on the test set should be seen as a proxy to measure generalization. In practice, we want to have good classification accuracy for all nodes, so picking training nodes according to their distance to a given test set skews the GNN to only perform well on this specific choice of test nodes. The authors should rethink their sampling approach. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}