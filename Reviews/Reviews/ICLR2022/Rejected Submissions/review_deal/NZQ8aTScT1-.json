{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper shows that deep convolutional neural networks in the kernel regime restructure the eigenspaces of the inducing kernels, which leads to some insights regarding the range of space-frequency combinations learned by such networks.\n\nThe reviewers identified a number of problems with the current submission. For instance, they found that the paper is hard to follow, it lacks clarity and the theorem statements are hard to understand. The authors also use a somewhat non-standard experimental setup.\n\nDespite an extensive discussion with the authors which cleared out a few minor problems, the bulk of the concerns of the reviewers were not successfully adressed. I am therefore not able to recommend acceptance. The authors need to improve the clarity of the paper and provide more discussions of the theorems in a resubmission, as well as potentially reconsider their experimental setup."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The authors show that deep convolutional networks restructure the eigenspaces of the inducing kernels,\nwhich empowers them to learn a dramatically broader class of functions, covering a wide range\nof space-frequency combinations.",
            "main_review": "Strengths:\n\nThis paper evaluates the success of deep neural networks by running extensive experiments that show the tradeoff between space and frequency. \n\nWeakness:\n\nThe meaning of the word frequency is unclear in the context of this paper.\n\nThe main idea behind theorem \"eigenspace restructuring\" which replaces one eigenvector/value computation with a set of part based eigenvalue/eigenvectors  has limited novelty.  The novelty is in its use in neural network architecture analysis.\n\nThe authors might want to consider evaluating the performance of a system based on the amount of data employed and based on how data was acquired (observational vs experimental studies).  Systems that employ data from observational studies are known to be susceptible to selection bias and spurious correlations, as opposed to data from experimental studies that are employed in objective causal inference.  \n\n\nMissing reference:\nAs the authors might recall, Vasilescu etal. in their ICPR 2020 paper have advocated replacing the SVD computation with a set of part based SVDs for which they provided a closed form mathematical derivation.  Based on this mathematical derivation, they developed  the Incremental Hierarchical M-mode Block SVD which was demonstrated experimentally. \n\n@inproceedings{Vasilescu20,\n\nauthor={Vasilescu, M. Alex O. and Kim, Eric and Zeng, Xiao S.}, booktitle={2020 25th International Conference of Pattern Recognition (ICPR 2020)}, title={Causal{X}: {C}ausal e{X}planations and {B}lock {M}ultilinear {F}actor {A}nalysis}, year={2021}, location={Milan, Italy}, month={Jan}, pages={10736--10743} }\n\n\n\n",
            "summary_of_the_review": "The authors evaluate deep convolutional networks through the lens of hierarchical locality. The paper evaluates the performance of deep neural networks by performing extensive experiments that show the tradeoff between space versus frequency.  The eigenspace restructuring theorem has a well-chosen name.  However, eigenspace restructuring is a well-known concept and the novelty of the theorem is limited. \n\nClarity of the writing and its overall organization needs improvement.  The word frequency needs to be better defined.  It is not clear if there are any novel insights.  \n\n\n----\nUpdate:  My original score was too generous and it was in anticipation that any mathematical inconsistencies or ambiguities would be addressed.  \n\n\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper shows how the topological of convolutional neural network restructures the eigenspace of the neural kernel. ",
            "main_review": "Strength:\nThe theorem statements are simple and clear. \n\nWeakness:\nIt is hard to decipher what is happening with just the theorem statements alone. \n\nClarity: The paper is clear till Section 3, then most part of Section 4 is confusing. The theorem statements are simple and clear. However, it is hard to decipher what is happening with just the theorem statements alone. \n\n\nThe following are not clear and need to be discussed explicitly:\n\n* How is the cardinality of $\\Lambda_{\\mathcal{G}}$ related to the architecture?\n\n* Does condition (1) on Assumption-G place a restriction?\n\n* Is the weight $w_{uv}$associated to the edge $uv\\in\\varepsilon^{(d)}$ a constant, since it is said that $w_{uv}\\equiv \\alpha_u$. Looks like $w_{uv}= \\alpha_u$ is used in Definition 1. However, it is confusing because $w_{uv}$ is also being used in Section 3.1 equations (14), (17-20). Please clarify, i.e, are the $w_{uv}$ in Section 3.1 and Section 4 the same, if not is it possible to use a different notation?\n\n* Is $\\sum_{v\\in\\mathcal{N}_0} d_v =d$?\n\n* What is the intuition behind spatial distance?\n\n* What are the activations that satisfy Assumption-$\\phi$?\n\n* $\\mathbf{t}^{\\mathbf{r}}$ is defined, but it is not clear where it is used.\n\n* Is ${n(\\mathbf{r})}$ equal to the set of input nodes for all $\\mathbf{r}$ such that $\\mathbf{r}>0$? Or put differently what happens if one of the $r_v$ is equal to zero and one of the input nodes get left out?\n\n* Is there an example of $n(\\mathbf{r})$ without a common ancestor $u$ such that $\\phi_u$ is admissible?\n\n* Is there an example of an $\\mathbf{r}\\notin\\mathcal{A}(\\mathcal{G}^{(d)})$, i.e., an $\\mathbf{r}$ that is not learnable?\n\n* In Section 5, (S-CNNs and SRHF Interactions), \n\n   + it is said that since the activation function of the last layer is identity we have $\\mathcal{A}(\\mathcal{G}^{(d)})=\\{\\mathbf{r}\\in \\mathbb{N}^{|\\mathcal{N}_0^{(d)}|}, n(\\mathbf{r}) = 0 \\text{ or } 1\\}$. However, it seems that the same argument applies to MLPs as well (page 4, last paragraph mentions \"the activations of the input/output nodes be the identity function\"), yet, in equation (29) $\\mathcal{A}(\\mathcal{G}^{(d)})=\\mathbb{N}^d$. It is not clear why there is a difference.\n   + How can $|n(\\mathbf{r})|$ be $1$ or $0$? Given that there are $w$ input nodes, which node gets chosen for $|n(\\mathbf{r})|=1$?\n   \n* How is $|\\mathbf{r}|$ defined?\n\n\n* What is the meaning of short (long) range interaction?\n\n* It is not clear what the dotted lines in Figure 2 mean. Especially, what is the point of highlighting the left most branches alone. Same goes with the Figure 4 (Figure Zoo) in the appendix.\n\nOverall: \n1. It is not clear what is meant by space and the space frequency trade off?\n\n2. Given that there are too many constants, $\\alpha_u$, $\\alpha_v$, $\\alpha_w$, $\\alpha_p$, it might be great to give some template networks to illustrate. While the paper indeed talks about, MLP, S-CNN, D-CNN etc, the discussion about how the specific constant were arrived at in equations (29-31) is very rushed and is the major cause of confusion.\n\n",
            "summary_of_the_review": "The current score is mainly due to the issues related to clarity.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper categorizes architectural biases from a frequency point of view through the lens of NTKs and NNGPs. The two main quantities are the frequency index (FI) and the spatial index (SI) which are calculated from the DAGs. The authors claim that these two quantities capture what type of functions (in terms of frequency and space) can be learned by specific architectures: i.e., MLPs learn LRLF functions, s-CNNs learn SRHF functions, and so on. The main theoretical contribution is Theorem 1: the authors give an architecture-dependent spectral decomposition formula for the NTK and NNGP Kernels using DAGs. ",
            "main_review": "Strengths: The paper sounds very interesting! As far as I know, it proposes a unique perspective to capture architectural biases finely. \n\nWeaknesses: The paper is very hard to follow partially because it is non-standard. Some parts lack rigor. Figures need a much better explanation.\n\nIn my opinion, the biggest issue is the interpretation of the main results (Section 5). I cannot follow how the authors created the DAG of the s-CNN network for example and from there arrived at the equation (30). \n\nExperiments are only made for a particular and somehow peculiar type of synthetic data. \n\nI would also appreciate some explanation on what Conv(p^2)^2 (and so on) corresponds to in terms of standard ConvNet architectures. \n\nDetailed feedback:\n- In figure 1, it was not clear to me what the black line represents. Can you study what kind of architectural changes make the family of learnable functions bigger (for example making the network wider or deeper in the case of MLPs)?\n- \"The amount of time needed to learn the j-th eigenfunction is about 1/K(j)\" (page 3) -- can the authors elaborate on this point? \n- Figure 2 is not comprehensible as it stands. Why not include a nice & explanatory caption?  \n- Page 5, at the beginning of the main results: \"the goal is ... non-asymptotic characterization as the input dimension $d \\to \\infty$\": here I'm confused about what does non-asymptotic refer to. \n- Why is the spatial index defined twice both in Def 1 and Def 2? \n\nMinor feedback/typos:\n- Although I liked the color code in general, I found the color code for finer interpolations confusing. (In Figure 1 caption and bullet point 3 the color codes do not match). \n- At the end of page 2, where the MSE is defined, it seems that the index for the summation should be (x, y) \\in (X, Y)\n- Page 2, .... the gradient dynamics is describe'd' ('d' is missing) \n- It is not clear what \"concrete\" input spaces refer to on page 3. \n- Page 6, It describe's' a connection .... ('s' is missing) ",
            "summary_of_the_review": "Although the paper looks very interesting, I found it very hard to follow. I think there is substantial room for making the paper more accessible (see the detailed comments above). But also, my lack of familiarity with the tools used in the paper (i.e., graph computations) may have made it difficult to read for me. I could not follow how the authors arrived at the LRLF-SRHF- and similar interpretations. Therefore, I can not recommend acceptance. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper provides new insights to understanding the mechanism behind neural networks, thanks to a space-frequency through the so-called eigenspace restructuring.\n",
            "main_review": "The paper provides solid foundations to understand the mechanism behind neural networks, including deep neural networks. This is done thanks to recent theoretical advances of neural network Gaussian process and neural tangent kernels. This work seems very interesting. However, this work only explore the architecture of neural networks to understand their behaviors. While the conducted analysis is carried on the model of the neural network, we find that it is missing some in-depth analysis on the other two basic ingredients of machine learning methods, namely the data and the optimization algorithm. It is worth noting that different optimization algorithms are used in the paper, namely SGD+ Momentum (used for finite-width networks) and kernel regression (used for infinite-width networks), but nothing is said about the influence of the algorithms. This is also the case about missing analysis on the influence of the training dataset.\nThere are some spelling and grammatical errors in the paper, such as “An demonstration”, “It describe a”, “our theorem justify”, “spherial harmonics”...\n-------------------------------------------------------\nRebuttal\nThe authors reply is off the mark, as they did not tackle our concerns, neither address comments from the other reviews. After reading all the reviews and the authors' replies, I have downgraded my score.",
            "summary_of_the_review": "The paper provides solid foundations to understand the mechanism behind (deep) neural networks.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}