{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper proposes a data imputation method for MCAR and MAR data by combining EM and normalizing flows.  The paper is clearly written.  The idea is interesting and they show better performance compared to MCFlow and competing methods on ten multivariate UCI data, MNIST and CFAR10 image data.\n\nIssues regarding limited novelty compared to MCFlow was raised.\nIssues regarding the validity of Assumption 2 on the dependencies in the latent space and observation space was also raised."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents a novel imputation method for high-dimensional datasets that typically serve as benchmarks for machine learning methods. This method (EMFlow) innovates by training a normalizing flow network to map input data samples to a multivariate Gaussian, where imputation is performed via an online version of expectation-maximization (EM), which is commonly used for missing data imputation. EMFlow is applied across regression tasks in datasets in the UCI machine learning dataset repository, and standard image classification datasets, MNIST and CIFAR-10. Empirical results show strong performance for missing data imputation, as well as downstream classification from these imputations, and the model design choices and well-constructed architecture make for easy training and fast optimization convergence.",
            "main_review": "EMFlow builds most closely upon MCFlow, mentioned in the paper. Both models use normalizing flows (NF) to capture the input data distribution, and MCFlow uses a standard MLP to find a latent vector maximizing the log-likelihood of the missing data. EMFlow uses NFs with EM to maximize the probability of the latent vector (under a probabilistic model — a multivariate normal) corresponding to the missing data. EMFlow has strong empirical results compared to the baseline of MCFlow. While the paper does not compare to GAN-based imputation methods, which might outperform simpler architectures, the lack of comparison seems fair given the ease of training EMFlow relative to a GAN-based method. Particularly looking at convergence traces in Figure 2. Overall the text is clear, well-organized, and easy to follow; there are only minor typos.\n\nMain strengths:\nThe architecture presented here is relatively straightforward, and does not have many hyperparameters, leading to relatively easy training and implementation. The choice of a multivariate gaussian latent space distribution leads easy conditioning and marginalization, and thus lends itself well to the online EM algorithm presented for imputation. The empirical results are strong, and the methodology is appealing for the reasons listed above. While not far from MCFlows, it provides enough of a conceptual and performance improvement to be a significant contribution to that work.\n\nMain weaknesses and areas to address:\nThe tasks in the empirical section, while not trivial, are not the most difficult examples. MisGAN, for instance, highlights results on CelebA, a more complicated learning task, as well as a higher-dimensional dataset than any listed in the paper. It might strengthen the paper to present results on a higher-dimensional dataset like CelebA or others. Towards this point, it might also be worth evaluating the FID score of imputed images on a dataset like CelebA, rather than just reporting classification accuracy or RMSE.\n\nThe dimensionality and general dataset descriptions are missing from the text and should be included. Particularly of importance is to include the dimensionality of the various datasets analyzed to support the claim that EMFlow works well for high-dimensional data.\n\nThe nearest neighbor imputation in MNIST and CIFAR-10 to seed EMFLow is quite reasonable. However, this should be compared to as a baseline as well. It is not clear the difference this warm-start makes in practice. Furthermore, EMFlow is able to be seeded with NN imputation, whereas MCFlow is not. EMFlow produces much better looking and smoother images than MCFlow, which contains far more noise, on CIFAR-10, and these differences should be due to algorithm changes in EMFlow and not NN imputation. The concrete suggestion here is to either report NN imputation as a baseline method on it’s own, or seed EMFlow with a random imputation as a form of ablation experiment. A third type of ablation experiment different from the two mentioned can be left up to the authors. Finally, to what degree is the fast convergence a result of the warm-start imputation?\n\nHigh-dimensional image data are thought to lie on lower-dimensional manifolds. It is unlikely that the covariance matrix ($\\Sigma$) learned in Z-space has full rank. As the data dimensionality continues to scale, it seems this methodology of estimating the empirical covariance will likely not scale as well, even with the robust estimator in (31). Could EMFlow be adapted to work with low-rank covariance estimators? Or perhaps the authors could show further analysis of convergence of the covariance matrix estimation during optimization.\n\nCan EMFLow be adapted to impute categorical data?",
            "summary_of_the_review": "Imputation is a key and general ML problem. EMFlow is an intuitive framework methodologically and in practice seems easy to train and performs well on real data. It is principled in its approach — relying on the rigorous EM algorithm as its base. However, EMFlow (albeit fairly due to training complexity) does not compare to what might be state-of-the-art GAN-based imputation methods. It is also unclear how EMFlow would scale to even higher-dimensional datasets given the modeling assumptions.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper presents a model named EMFlow, which performs data imputation in the latent space using the online EM algorithm together with the normalizing flow models. The normalizing flow models aim to capture the complete data density $p_X$ and the bidirectional mapping between the data space and the latent space, even when the data is only partially observed. The parameters in the latent space are updated using an online EM algorithm. Thanks to the feature-wise mapping, the dependency between features in the data space is carried over to the latent space and hence the imputation can be done. Evaluation using ten UCI datasets, MNIST, and CIFAR-10 datasets show impressive improvement against baseline models and the convergence is faster than MCFlow.",
            "main_review": "The quality of the paper is generally good. The proposed model combines the online EM and flow models to do imputation, which looks to me a quite reasonable design. The model is evaluated using a number of UCI multi-variable datasets and two image datasets (MNIST and CIFAR-10). The performance is generally better than baselines including MCFlow. Because sampling is avoided by using EM, it converges faster than MCFlow.\n\nThe presentation of the paper is quite clear. It is organized, well-written, and quite easy to follow. However, my main concern is that the novelty of the paper seems to be limited, especially when compared with MCFlow; it seems to me that the major difference is that this paper replaces the sampling with the EM algorithm. It is a very reasonable extension, yet it has already been widely studied in various domains and applications.\n\nThe authors claim in the introduction section that EM can be applied in an interpretable way, which motivates the authors to use EM in this paper, but this point is not further discussed in the paper. I would be very interested to see discussions about how interpretability can be enhanced by this proposed model.\n\nAnother minor typo: in the line below Eq. (2), should it be $\\subseteq$ instead of $\\in$ between $\\mathcal{X}^\\prime_i$ and $\\mathcal{X}$?",
            "summary_of_the_review": "The presentation is clear, the model is theoretically sound, and experiments show impressive improvement against baseline models for most of the dataset and missing rates. However, the novelty is somewhat limited, especially when compared with MCFlow.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper aims at imputing missing data which are MCAR and MAR. \nFor modeling the observed data distribution, it utilizes the framework of normalizing flow of which the latent variable/source variable space is Gaussian.\nBy assuming the consistency of inter-feature dependencies in the latent/source variable space, it applies online EM for the imputation of the latent space variables.\nIn the experiments, the proposed method, EMFlow is compared with GAIN, MisGAN, and MCFlow.",
            "main_review": "Although the imputation of MCAR and MAR scenarios has been studied for decades and in theory is not a problem, its applications in high-dimensional and real-world data with complicated distributions can be interesting from a practical perspective.\n\nThe work adapts the online EM algorithm for the missing data imputation. I quickly go through the online EM extension, which seems sound and no problem.\n\nHowever, I have some concerns regarding the assumptions of NF.\nIt would be necessary to justify the assumptions, especially, why the two assumptions are reasonable to believe.\n\nFirstly, inter-feature dependencies in the observation space are different from the inter-feature dependencies in the latent space. According to the studies in factor analysis and nonlinear ICA, the latent representation is not identifiable. So it is not straightforward to believe that the dependencies in the latent space are consistent with the dependencies in the observation space. Then, why would it be reasonable to do imputation in the latent space?\n\nSecondly, note that according to the property of the change of variable formulation used by NF, the neighbors in the latent/source variable space are not necessary to be the neighbors in the observation space.\nAnother fact about NF is that even though the covariance matrix of NF is an identity matrix, it can still model the data distribution well. Then what are the dependencies modeled by the covariance of the multivariate Gaussian distribution in the latent space? Why we could believe that they are corresponding to inter-feature dependencies in the observed data?\n\nA final minor concern is about the experiments. To have a better view of the comparison and the benefits of the proposed method, more comparison in the experiment section would be required, especially, the works using VAE and the methods without using generative models.\n",
            "summary_of_the_review": "The work focuses on MCAR and MAR cases and extends NF and online EM for the missing data problem, which can be interesting for applications from a practical perspective. But the assumptions and main idea of the work can be lack justification, i.e., the relationship between the dependencies in the latent space and observation space needs to be elaborated and clarified. Moreover, a more thorough comparison with other related works would be helpful to better evaluate the proposed method.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors propose a novel architecture EMFlow for missing data imputation. The authors also show the results of various experiments with multivariate and image datasets. Finally, the authors report the accuracy of post-imputation classification on image datasets.",
            "main_review": "The study is well designed. however, there are few limitations that needs to be acknowledged.\n\nThe data structure is using imaging data as example. This kind of dataset having high neighborhood correlation and imputation using EM with latent space will be less challenging comparing to time series dataset which also have additional layers of correlation between time points. Perhaps need to show the performance on those datasets.\n\nThe author did not show the performance in MNAR. Therefore the novelty remains limited.\n\nThe author also need to realize the limitation for all EM method comparing to FCS multiple imputation which considering the uncertainty of the imputed value.",
            "summary_of_the_review": "The study and the expected results are acceptable; however, this framework was tested on imaging dataset, which has unique characteristics. for example, one can not assume similar performance when the method is tested on longitudinal clinical data, unless tested systematically on actual data. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}