{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper presents a decentralized version of the CEM technique, where an ensemble of CEM instances run independently from one another and each performs a local improvement of its own sampling distribution. The paper shows that the proposed technique can alleviate the problem of centralized CEM related to converging to a local optimum. The paper includes a theoretical analysis and simulation experiments that show some benefits of the proposed technique over centralized CEM.\n\nThe key criticisms from the reviewers include the straightforward nature of the proposed idea, which limits the technical contribution of the paper, as well as the limited improvements over centralized CEM in the simulation experiments. \n\nIn summary, this is a borderline paper. While the paper is well-written and the proposed approach is clearly explained, the lack of strong empirical results that show a pronounced improvement of decentralized CEM coupled with the incremental nature of the idea of decentralized CEM makes me lean toward a rejection."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes an extension of the Cross-Entropy Method (CEM) for optimisation that consists in an ensemble of multiple standard CEM instances, each one being optimised independently, and the solution at each step is the output of the top performer CEM at that step. Simulation results in a continuous control benchmark show that the proposed algorithm matches or outperforms previous CEM variants. The authors also use a toy problem to illustrate how using an ensemble can help to escape local minimum. \n",
            "main_review": "Strengths:\n- Using an ensemble of optimisers is a powerful idea that can help to explore the solution space more efficiently, and should be explored further.\n- The continuous control benchmark is relevant for this task, and the baselines are sensible. In particular, having included SAC as a reference is appreciated.\n- Simulation results show similar or better performance to other CEM variants in most of the environments.\n- The paper is generally well written and easy to follow.\n\nWeaknesses:\n- Training curves are stopped before convergence for many environments. This makes difficult to evaluate the stability and final performance of the proposed approach, especially for those environments in which the final performance of SAC (black dashed line) is much higher than that achieved by the proposed approach(es).\n- Although the presented algorithm is novel, the idea of using ensembles of optimisers is not. Comparison with other ensemble-based approaches, like the decentralised CEM introduced in [1] or the ensemble method proposed in [2], would be appreciated. \n\n\nQuestions:\n- What is the practical benefit of using CEM over other model-free approaches like SAC? Is it much faster in terms of actual time (i.e., the training time per step is smaller)? \n- Why is not the covariance matrix learnt? Is it because the large dimensionality of the parameter space?\n- I understand that each step in the training curves correspond to a single state-transition, but that the points are actually represented per episode (which can be finished after a max number of state transitions), is my understanding correct?\n\nMinor comments:\nSince the state space is introduced as a subset of the real vector space, I assumed it is not countable. Hence, the transition probability distribution should be in Re^+, instead of [0, 1].\n\n[1] S. V. Macua, S. Zazo and J. Zazo, \"Distributed black-box optimization of nonconvex functions,\" 2015.\n[2] S. Khadka, S. Majumdar, T. Nassar, Z. Dwiel, E. Tumer, S Miret, Y. Liu and K. Tumer, \"Collaborative Evolutionary Reinforcement Learning\", 2019.\n",
            "summary_of_the_review": "The algorithmic idea is interesting, well executed for RL and probably useful for optimisation in general, but comparison with other ensemble approaches is missing in the related work to better understand its novelty.\nSimulation results are promising but not fully convincing as it shows similar training performance to previous methods, but it is not clear the final performance of the proposed approach for many of the most interesting environments. \nI lack a clear practical motivation for the CEM approach.\n ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper studies a novel CEM method for model-based RL. While previous approaches used a centralized method (based on a unimodal Gaussian or Gaussian mixture), they propose a decentralized CEM, where each instance independently tracks its own data and top-k estimates. They first test their new method on a 1D toy task, showing better convergence to the global optimum. They then test their method on several model-based RL tasks, outperforming previous methods in some tasks, while being on par or inferior in others. ",
            "main_review": "Strong:\n* The idea is straightforward, but good, and the toy example indeed suggest that a GMM cannot handle the multimodality in the optimization landscape. \n* The paper is well written, very clear, equations are concise. The appendix is really detailed as well, with full hyperparameter settings. I am convinced another researcher could replicate these experiments. \n* I really like the 1D toy example. It gives a good visual illustration of the method and what is happening. \n\nWeak:\n* I think your MBRL results are not super strong: I see quite some noisy curves, and in some of them your method indeed comes up, but in some others it is actually below the alternatives. I would say the real improvement is mostly for DecentCEM-A on Acrobot, Reacher, Ant and Reacher, but given that is below on Hopper and Walker2D, we may doubt how much signal there really is. I do like that you show all results (including negative), but you may slightly rephrase the statement that your method ‘either matches or outperforms their counterparts’. \n* Toy experiment: I find it suprising that CEM-GMM looses the global optimum. My main issue is that you do not report on the number of mixture components in the GMM? This seems to be really crucial. Looking at the appendix results, it seems that the CEM-GMM is unlucky on iteration 0 (having few samples on the right), but with enough mixture components this should still be fine. And what is the number of instances in DecentCEM? (I hope the same as the number of mixtures) Did you tune both? In short, I lack some hyperparameter choices you make in the toy experiment.\n* End of 4.3: I have some trouble understanding why the amount of data goes up per environment interaction. Each instance has a different distribution over policies right, and I can only evaluate one of these policies per environment interaction? I might be missing something here, but I would need some clarification here.\n* I think Related Work has a major omission, since it only focuses on other MBRL work, but does not discuss any related work from CEM literature. Has this decentralized approach already been tried there, or something similar. Then, it can still be relevant to MBRL, but you should note and discuss this. \n* The paper has no Discussion and Future work, which I think should always be there. \n* The graphs are quite small and in some cases just unclear. For example, in Figure 6 the colour coding is far from optimal, I really have a hard time figuring out which line is which on my printed version (in colour), since you e.g. have red and pink. On a black and white print, if would really be completely infeasible. Figure 8 is also really small, and needs an more extensive caption. If you cannot increase the plot size, at least increase the axis labels in size. \n* Your methodology was really clear, but a few things I did not get: 1) Is the v_th in Eq. 3 a threshold per CEM instance (then I would write v_th^I), 2) Is the k of CEM-GMM the same as the k for each instance of DecentCEM (i.e., does Decent CEM get more top-k samples, and should you correct for this?).",
            "summary_of_the_review": "I find it really hard to judge this paper, since it has strong and weak points. As mentioned above, I like the idea (it is straightforward and easy to grasp, yet well motivated), the paper is very clearly written, has clear notation, and gives good intuitive illustration of the idea. On the downside, I do not think the results are really convincing (although there is some signal), I lack hyperparameters on the number of mixtures in the toy experiment (and the sensitivity of results to varying it), I completely miss related work from the CEM literature, there is no Discussion and Future work, and the graphs are not easy to read. Individually, all these downsides can be overlooked, but with all of them together I get in doubt. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes DecentCEM which uses parallel instances of CEM to learn optimal policies for problems that contain multi-modal optimal actions. Instead of using a single policy as sampling distribution and optimizing the actions in the vicinity of this action trajectory, the DecentCEM method uses parallel with multiple policies and cem optimizers. Therefore, the proposed algorithm can learn multi-modal actions and should improve sample efficiency. The algorithm is evaluated on the standard OpenAI benchmark tasks.  ",
            "main_review": "The paper wants to solve the problem that CEM cannot handle multi-modal action distributions within the top-k samples. In this case, CEM averages over the multiple modes and requires more samples to converge. While this problem theoretically exists and one can describe a motivational example where this problem is relevant, the problem is not relevant for the performed model-based RL experiments on the OpenAI tasks. The algorithms have sufficient entropy to break the multiple solutions and converge to a single solution during a few replannings. The difference in reward is usually not significant. As shown by Pinneri et. al. using the argmax (which also avoids averaging over modes) instead of the mean can improve run-time and marginally increase the reward, but the differences are not essential. From my personal experience with CEM, using the argmax over the mean operation can potentially increase performance in some environments but the increase is not significant. The performed experiments of the authors do not show much of an improvement of DecentCEM over the other methods. The authors also do not provide an evaluation that evaluates whether the computation time decreases with their parallel structure of CEM & policies. Furthermore, the computational complexity during training most likely increases as one needs to train N policies. Therefore, the proposed algorithm does not improve the empirical performance of Poplin. For more complex environments, the proposed approach might be beneficial, but for the OpenAi benchmark tasks, the parallel structure is not necessary to achieve a good performance. \n\nThe paper also does not provide new theoretical insights or has a good motivation. Using n-parallel policies + CEM is a trivial extension of Poplin with uncertain benefits. If one wants to address the uni-modal Gaussian assumption of CEM, one should invest in sequential Monte Carlo methods which can handle multi-modal solutions.\n\nBesides the poor motivation of the approach and limited experimental results, the paper is well-written and easy to follow. Unfortunately, only the idea is not sufficient to be presented at ICLR. ",
            "summary_of_the_review": "The advantage of the proposed algorithm is unclear and there are no theoretical insights within the paper. The algorithm is a trivial extension of POPLIN and has little relevance. Therefore, I recommend rejecting the paper.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}