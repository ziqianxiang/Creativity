{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "This paper adopts the recently developed MLP-based architectures for image classification to Automatic Speech Recognition with 3 different modifications to handle variable length sequences. The three architectural modifications are: C-MLP (w/ depthwise convolution), TS-MLP (w/ shift operator), and F-MLP (w/ Fourier transform and w/o gating). The approaches are then evaluated on the Librispeech-100h and Tedlium-2 corpora and are compared to baselines from the literature. The proposed approaches are shown to yield better performance than Transformer-based models.\n\nAs pointed by the reviewers, there are 3 major concerns:\nclarity: the initial version of the paper needed more improvement in writing, the authors did improve the writing a lot, which led to increased ratings by the reviewers;\nreproduction: many experimental details were missing in the initial version, but the authors added those in the revision and shared the code\nnovelty: as agreed by all the reviewers that The novelty of the paper is somewhat weak. It is mainly an application of a known technique to a new use-case and the modifications are commonly used in ASR. \n\nThe decision is mainly due to the limited novelty."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents an approach for Automatic Speech Recognition based on MLP architectures. Those architectures were recently proposed for image classification and yielded promising results. In this paper, three new MLP-based architectures able to handle variable length sequences are proposed. The approaches are then evaluated on the Librispeech and Tedlium corpora and are compared to baselines from the literature. The proposed approaches are shown to yield better peformance than the baseline while keeping a low complexity. ",
            "main_review": "Strengths:\n - The approach is novel and significant. The MLP approach for image classification is very promising and it's a important step to make it work on sequential data and speech-related tasks.\n- The evaluation is thorough, clearly showing the capability of the proposed approaches. The model scaling analysis is a very nice addition and clear showcases the potiental of the MLP architectures.\n\nWeaknesses:\n- The clarity of the paper is quite bad. Section 2 especially is hard to read and hard to understand (see detailed comments below). Section 3 is also not very clear. They also are a lot ot typos. The author should improve the writing, as these sections are critical to understand the paper. The experimental setup section is also missing important details about data split, training details and model hyper-parameters.\n- I am not convinced about the use of the terms \"channel\" and \"token\" for the two dimensions of the input. These keywords are use mainly in CV for the first one and in NLP for the second one. For speech, these two dimensions already have a name: the temporal dimension and the spectral (or cepstral depending on the features) dimension. Moreover, \"token\" can be misleading as it usually refers to words, but in this case the input is an audio signal segmented by duration, so there are no word boundaries involved. I thus encourage the authors to revisit the naming scheme.\n\nDetailed comments:\n- Section 2:\n    - \"The long range dependencies The latter allows to model ...\" -> \"The latter allows to model ...\"\n    - Figure 2: \"Linear_toekn\" -> \"Linear_token\"\n    - Equation (1) is using \"Linear_channel()\" but the text mentioned \"Linear_token()\", which one is correct?\n    - SGU is used in Section 2.1 but only explained in Section 2.2. It's confusing. \n- Section 4.4:\n    - Table 1 should be Table 2\n- The term \"sandwiched\" is used several time, it's not wrong but there are better ways to write that, like \"in between\" for instance.\n- I am a bit confused about the FNet and GFNet baselines in Table 1: according to Section 2 and 3, these two approaches are not suitable for variable length input (which is the key motivation of the paper), so how did the author make them work for ASR? please clarify. ",
            "summary_of_the_review": "The proposed approaches are novel and significant, and clearly evaluated. They are shown to be a promising new approach for ASR. However the clarity and quality of writing of the paper are quite below the standards.  Hence in the current shape i cannot recommend acceptance, it's just below the threshold. I will be happy to increase my score if the writing is improved.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper deals with the problem of having variable length inputs in deep neural network architecture using only MLPs. Recently, there has been interest in these architectures because they could reduce the number of parameters in deep NN models. However, these architectures have so far only been applied to images with a fixed size input. In order to apply them to sequences such as speech recognition or NLP, these models must be able to deal with variable input size. This paper presents 3 different solutions to allow MLB based deep NN to cope with variable input. The proposed solutions are based on either a modification of the gating mechanism or replace the gating mechanism with FFT. The proposed models are tested for a speech recognition task on 2 standard databases. Compared to transformer-based models, the proposed models obtain comparable performance with less parameters, and better performance with similar number of parameters.",
            "main_review": "The paper contains many typos and ungrammatical sentences which make it difficult to read. Therefore, even if the experiments seem rigorous,  the lack of rigor in the writing casts a doubt on the results. The reference to previous or related work is scarce and the results of a standard ASR methods that can deal with variable input length should be reported for comparison.\nThe experiments are not easily reproductible due to the lack of details and errors in the description of proposed models. \n\nThe quality of the paper is not sufficient for publication in ICLR.\n",
            "summary_of_the_review": "The paper contains many typos and ungrammatical sentences which make it difficult to read. To list a few:\n* Page 2: \"The long range dependencies The latter allows to model long-range dependencies just like self-attention would.\n* Page 3:  \"MLP-Mixer simply applies the MLP across the token dimension gMLP has a module called Spatial Gating Unit (SGU)\"\n* Page 6: \"For Librispeech, We tokenize\"\n\n\n* The related work section is very short, focuses only on models for images and gives no reference to ASR. \n\n* Section 2\n    * Equation 1, `Linear_{channel}` is referenced in the following sentence as `Linear_{token}`\n    * Equations in 2.1 are wrong or wrongly written. Some variable are not explained, and the dimensions don't add up when you consider all the projections.\n    * SGU is presented in section 2.2 but has been used in equations of section 2.1\n* Section 3\n  *  C-MLP', which will be the best model, is not clearly descibed (only equation 8)\n  *  \"This operation to obtain filter HCGU is independent of the channel dimension.\" : this is unclear\n* Section 4\n  * In the text, reported WER seem to have been copied from one to another, and don't match the table.\n  * `C-MLP achieves competitive performance with Transformer-based model with only 57.1 % of its parameters`, but after computing the value, it seems to be `57.4 %`\n  * Should be `Table 2` not `Table 1` in section 4.4\n  * C-MLP' is the best model based on table 1 but is not presented in  table 2\n  * In table 5, RTF is not defined\n  * In the claims (abstract), it is said that the proposed architecture reduces WER by 1.9/3.4 % but this result seems to be mainly due to the tiny attention module, which is not clearly stated.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes three architectural modifications on recently introduced MLP-based neural networks, such as MLP-Mixer or gMLP. These networks could not handle the variable-length input because the token-level mixing was performed by MLP. The proposed three modifications are: C-MLP (w/ depth-wise convolution), TS-MLP (w/ shift operator), and F-MLP (w/ Fourier transform and w/o gating). The authors evaluated their model on two ASR datasets, LibriSpeech-100h and TedLium-2, and achieved better WER compared to Transformer-based models with a similar number of parameters.",
            "main_review": "(1)\tThe novelty of the paper is somewhat weak. C-MLP, which exploits a depth-wise convolution for time-axis feature aggregation, is a commonly used approach in ASR. (Convolution module in Conformer, or Time-Depth Separable Convolution) TS-MLP seems to bring an idea from S^2-MLP. An additional tiny-attention module is also taken from gMLP.\n\n(2)\tFor the baseline performance, is there any reason for using only a clean-100h subset of LibriSpeech? I’m not sure the performance is in a sufficient range; it would be clear if you could provide some references that also trained the Transformer only on clean-100h.\n\n(3)\tNot enough experimental/architectural details are provided. For example, the embedding dimension, the number of heads in Transformer, convolution kernel size, frontend subsampling stride, type of activation function, STFT window size, optimizer, learning rate, etc., are missing.\n",
            "summary_of_the_review": "Although the problem that this paper tries to solve is an important problem, the novelty of the proposed solutions seems to be weak. Experiments could be more powerful with commonly used benchmarks (LibriSpeech-960h), and details are missing.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes three mlp based structures to deal with sequences of variable size. The experiments are conducted on two datasets and campare to transformer based models some improvements are reported.",
            "main_review": "Please revise the paper in terms of writing. Equation 1 seems to have typo. In section 2, please correct the repetition \"the long range dependencies\"\nIt is mistakenly referred to Table 1 instead of Table 2.\n- how do we split the dimension in SGU? Randomly?\n- you may want to elaborate more on the term \"tiny attention\"\n- have you run the conventional CTC model? Would be good to see that result as baseline too.",
            "summary_of_the_review": "While it seems the paper presents technically interesting topics, it requires major revision in terms of writing. It includes many grammatical errors, wrong references and punctuation are not respected. Unfortunately, it makes the paper difficult to follow.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}