{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "*Summary:* Study generalization in kernel regression discussing the NTK case and experiments on finite width nets. \n\n*Strengths:* \n- Mix of theoretical and empirical results in an important topic. \n- Advances a promising recent line of work. \n\n*Weaknesses:* \n- Concerns about novelty and lack of comparison with existing works. \n- Concerns about insufficient contextualization of new notion of learnability. \n- Concerns about scope of results in relation to claims. \n\n*Discussion:* \n\nReviewer gb7t (3) found their concerns about lack of novelty and comparison with prior works not sufficiently addressed in the authors’ responses. 7tiq (6) found the line of investigation promising, but also issues with presentation and found the theoretical results incremental. Mosm (5) finds that the theoretical part pertaining kernels does not offer much novelty and that the paper should have focused on the empirical study that links the NTK spectrum to generalization. q2g8 (8) confidently considers this a good paper. In their view it provides a nice theoretical analysis of generalization in the setting of kernel regression and the metric of learnability intuitive. However, they also found that the detests of the experiments are very artificial and problematic the desire of the article to extend the regime of the results to make claims about deep learning. \n\nA the end of the discussion period, the official reviewer ratings are mixed 3,5,6,8, indicating various strengths and weaknesses (also in case of the most favorable reviews). From the reviews and discussion, I infer that the topic is worthwhile and relevant, but at the same time that the paper might not be sufficiently convincing in its current form. Therefore I lean to reject the paper. To arrive at a clear conclusion, I consulted two additional researchers. \n\n*Additional assessment 1:* \n\nThe first additional assessment found the work 'underwhelming' but admitted there is a chance they might not have fully understood the work. \n\n*Additional assessment 2:*  \n\nThe second additional assessment provided following comments: The paper's first contribution (conservation law), I didn't see it elsewhere but I think it's quite expected. The testing performance of low-frequency target functions and high-frequency target functions are averaged. Thus the average performance is constant which is independent on the kernel. However, in practice, kernel learning performs well because real target functions have low frequency. And the very high-frequency functions are unrealistic. \n\nAbout the paper's second contribution, I think the paper needs to explain how the result is different from Bordelon et al. (2020). I noticed that the method they use is different but the result seems quite similar. The paper also consider noiseless case and gives an approximation for MSE. \n\nAlso the paper should explain more about the approximation being used. For example, how much error the approximation introduce and how the approximation is different from Bordelon's approximation. I see that in the proof Φ is approximated by a matrix where each element is standard Gaussian. For me I can't understand why the approximation is reasonable. \n\nI read through the reviews and rebuttals. I didn't see the discussion of the issue of approximation. But I think it's a major issue and the approximation is a very strong assumption. The appendix states: \"we have made an approximation using the central limit theorem assuming that Φ is random with entries sampled i.i.d. from N (0, 1)\". Here Φ is the matrix of eigenfunctions. Hence it is not clear how to apply the central limit theorem. \n\n*Conclusion:* \n\nI conclude that although the paper presents some interesting ideas on a relevant subject, it still has much room for improvement. Hence I recommend to reject this article. I encourage the authors to revise taking the above comments into consideration."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper studies generalization capability of deep neural networks by the eigensystem of Neural Tangent Kernel (NTK). The findings of this paper include (1) target functions corresponding to fewer leading eigenfunctions of NTK are easier to learn (these target functions are learned faster); (2) a new “no-free-lunch” theorem characterizing a fundamental tradeoff in the inductive bias of wide neural networks: improving a network’s generalization for a given target function must worsen its generalization for orthogonal functions.",
            "main_review": "Strength\n\nThis paper studies generalization of deep neural networks, a central topic of theoretical research in deep learning. This paper is written well and easy to follow.\n\nWeakness\n\nMy major concern is that the key findings of this paper are either not novel which have been revealed in previous works, or lack comparison with existing works so it is unclear how significant the results are. \n\nIn particular, (1) the finding that target functions corresponding to fewer leading eigenfunctions of NTK are easier to learn have been revealed by the generalization bound in [a] (Theorem 5.1 of [a]). In addition, [b] shows that the empirical (training) loss drops fast when the target function lies on the subspace spanned by top-k eigenfunctions of the linear integral operator corresponding to the neural tangent kernel. \n\n(2) The “no-free-lunch” theorem presented as Theorem 1 is based on the new notation of “learnability” defined in equation (2), and it would be important to connect this new notation to existing works so that one could understand the significance of the results. For example, the pessimistic result of Theorem 1 could be connected to the result in Section 3.2 of [c], where it was proved that there exists a difficult test data set which fails the trained ReLU neural network (the difficult test data and the training data can be generated from the same target function).\n\nThere are some other issues, for example, only asymptotic analysis (the width of the neural network goes to infinity) is presented. Note that all the referenced works [a-c] are based on neural networks with finite width, which is the case closer to the practice.\n",
            "summary_of_the_review": "While this paper studies an important topic of deep learning, generalization capability of deep neural networks, the key findings of this paper are either not novel or lack comparison with existing works. I suggest the authors perform a thorough literature review in the recent progress of theoretical research in deep learning, and then carefully place their work under the context of the literature.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper examines the eigenvalues of a neural network’s “Neural Tangent Kernel” to analyze its generalization performance in the infinite-width regime. It conjectures that the same results will also apply in the finite width regime as well. By analyzing kernel regression and by defining a measure as the “learnability” of a given target function, the paper proves a “no-free-lunch” theorem which implies that improving a network’s or kernel's generalization for a given target function must worsen its generalization performance for its \"orthogonal functions\". The paper then analytically predicts two phenomena: worse than chance generalization for hard functions and non-monotonic error curves in a small data regime. It also provides some simulations to corroborate the analytic results.",
            "main_review": "The topic of the paper which is on the NTK approach of analyzing generalization error of neural networks is interesting. The paper continues the line of work of Bordelon et al 2020 which seems a promising direction. Moreover, the paper is well structured and has plenty of simulation results. However, on the theoretical aspect, I believe the paper can be improved.\n\nI especially found the problem setup section of the paper and its notation hard to read. I think the theoretical results of the paper is a bit incremental with respect to the Bordelon et al. 2020 and Canatar et al. 2021. In particular, Theorems 1 and 2 demonstrate simple facts and have very short proofs. Moreover, the setup of the paper is for finite set $\\mathcal{X}$ with $M=|\\mathcal{X}|<\\infty$ with data sampled from a uniform measure. Although in page 2 it is promised that for non-uniform measures and continuous sets $\\mathcal{X}$ results will later be explained, no such analytical explanation is provided except for a note in the simulations section in page 8. The justification for the reduction of output dimension to m=1 in page 3 is also not entirely clear. \n\nIn the conclusion section, it should be noted that the results of the paper concern the generalization property of neural networks in the “infinite width” regime, and that the paper merely conjectures that the same theory holds for finite width networks as well.",
            "summary_of_the_review": "I am not very familiar with the recent prior work that this paper cites and builds upon its approach and I have not completely checked the mathematical correctness of the claims of the paper. But, overall, given the importance of the problem analyzed by the paper, i.e. generalization performance of neural networks using NTK approach, and due to mix of theoretical results of the paper with empirical results, I am inclined towards accepting the paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper aims at characterizing the generalization ability of a neural network via the spectral properties of the neural tangent kernel. ",
            "main_review": "- Section 2.1: In the opening part there is no assumption about independence of outputs (m of them). Judging by the claim on page 3 (the last paragraph), the paper does assume outputs are independent? Otherwise, I fail to see how the problem simplifies to m = 1. To see that these kernel-based problems are quite different, please check out \"On learning vector-valued functions\" by Micchelli and Pontil (2003).\n- Figure of merit: The inner product in Eq. (2) is cosine similarity and should be in [-1, 1]. Unless one takes the absolute value, I fail to see how this quantity is bounded in [0, 1]?\n- Section 2.3: This section appears to be a review of kernel methods rather than a novel theoretical contribution. In particular, it does not appear to depend on any assumptions or specifics of neural tangent kernels. If so, then this should be contrasted relative to prior work on kernels and eigendecomposition of kernel operators. For example, \"On the mathematical foundations of learning\" by Cucker & Smale (2002) or \"Reproducing kernel Hilbert spaces in Probability and Statistics\" by Berlinet & Thomas-Agnan.\n- Section 2.5: The discussion immediately after Lemma 2. This is about the dependence on the sample size and, thus, not sure why this is specific to neural tangent kernel? In kernel methods the hypothesis will concentrate around the target as the sample size increase. There are numerous bounds on this and prior work has also covered the spectral tail, interpolation, etc (see \"Just Interpolate: Kernel Ridgeless Regression Can Generalize\" by Liang & Rakhlin or \"Optimal Rates for the Regularized Least-Squares Algorithm\" by Caponnetto & de Vito). \n\nThe empirical analysis is interesting and should have been the main focus of the work. In this regard, the ablation study with input spaces that have the closed form expressions for eigenfunctions is quite informative. The observation that even for networks with only 20-unit widths the correlations persist is promising.",
            "summary_of_the_review": "The paper should have focused on its strengths which is the empirical study that links the NTK spectrum to generalization in neural networks. The theoretical results apply to kernels in general and, thus, do not see much novelty in this regard. The related work does not adequately cover prior developments in kernel methods and fails to place the claimed theoretical contributions within this scope.\nI would recommend a major revision with a proper review of prior work on kernels. The focus of the paper should be empirical and presentation of its empirical findings should receive more attention/pages. I also fail to see sufficient theoretical contribution relative to prior work on kernel methods.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper provides a novel theoretical account of generalization for kernel regression. To do so, the authors study a matrix built out of the kernel eigensystem evaluated on the training set that they call the \"learning transfer matrix,\" and which relates the decomposition of the true function in the eigenbasis to the decomposition of the learned function in the eigenbasis. In other words, this matrix characterizes the kernel regression solution in the eigenbasis. By making a number of approximations, they are able to find a closed-form expression for this matrix and study its first and second order statistics. A main conclusion from this analysis is that functions are more learnable by kernel regression if they have more weight in higher eigenvalue modes.\n\nMoreover, the authors also introduce a new metric, which they call \"learnability,\" that they use to prove a new no-free-lunch theorem whose content is that when averaging over a complete basis of functions the learnability is independent of the kernel. This means that the choice of kernel should be tailored to the details of the function being learned in order for kernel regression to succeed. A related result is that there are some functions for which the kernel regression solution generalizes worse than simply outputting \"0\" on data outside the training set, i.e. for which the solution fails to generalize at all.\n",
            "main_review": "This paper provides a really nice theoretical analysis of generalization in the setting of kernel regression. The metric of \"learnability\" is intuitive *and* useful, and the new no-free-lunch theorem provides new insight into the relationship between the size of the training set and the success of regression. In particular, it explains how the inductive bias of the kernel relates to the properties of the function that is trying to be learned.\n\nI think a major weakness of the paper is the desire to extend the regime of these results to make claims about deep learning. In particular, deep neural neural networks are only kernel machines at infinite width, and we expect deviations from this limit for realistic finite width networks. It's well known that the kernel for finite width networks is not fixed and evolves during training, so it's rather hard to assess the relevance of the paper's results for the models that the authors really want their results to apply to (namely, neural network models). In addition, for these finite width networks, the eigenspectrum also would shift, and thus the notion of which modes are large may also become complicated.\n\nRelatedly, the specific experiments performed are on very artificial datasets. That certainly can be fine -- the results illustrate the validity of the kernel regression results(!) -- but it also gives me pause with the claims made about deep learning in general. One particular problem is that the spectrum of eigenvalues for realistic data often obeys a power law. (See e.g. some discussion in [Explaining Neural Scaling Laws](https://arxiv.org/abs/2102.06701), or just check it explicitly on MNIST or FMNIST with a few lines of code.) This seems to be an essential inductive bias of realistic datasets. Presumably, given the no-free-lunch theorem, to make claims about realistic deep learning scenarios we'd need to understand (a) what an eigendecomposition of typical functions we want to learn looks like and (b) how kernel regression solutions behave when the data has a power law spectrum. I suspect that there are important differences as compared to learning an eigenfunction on an artificial dataset. Along these lines, it seems that the most relevant question is why is the inductive bias of fully-connected networks, which could be assessed by looking at the particular combinations of parameters and activations that make up the NTK, often useful for learning and generalizing the datasets and functions that we typically care about for AI function approximation tasks.\n\nFinally, I am particularly bothered by the discussion finite width networks in the abstract, introduction, and final paragraph before the conclusion. Since finite-width neural networks are not kernel machines,  the first-principles theory of this paper can only approximately apply to them. I think the experiments at finite width in this paper -- primarily in Figure B2 of the supplement -- are not sufficient to support the various claims made about finite-width networks. First, as described above, it's not clear that the learning tasks are particularly realistic. Second, it's now pretty well known that the relevant quantity with which to compare the width of the network to assess the validity of the infinite-width limit is the depth of the network. Thus, simply stating that their experiments agree for \"networks as narrow as width 20\" is not particularly helpful or scientifically accurate. A width 20 network of 1 layer might be very much like kernel regression and be in a regime of applicability of their results, but a width 20 network of 20 layers will definitely not be. Of course, the relevant question is whether for typical width and depth combinations whether their results are still useful. But I think this is really hard to assess given the experiments are also on unrealistic data and learning tasks.\n\nOne minor comment: I wish the authors would compare their results more directly to the analysis of the Canatar et al. 2021 paper they cite. I understand that the no-free-lunch theorem, the learnability measure, and the analysis of the learning transfer matrix are new here, but both works purport to give a first-principles theory of generalization by studying the kernel eigenspectrum, and I would appreciate a deeper discussion of the connection.\n\nA tiny comment: It would be nice to have more discussion of what Theorem 2 means after giving it. (But I know that space constraints makes things difficult.)",
            "summary_of_the_review": "On the one hand, this is a really nice theoretical paper about generalization for kernel regression. I think the results are useful, intuitive, correct, and bring new insight that let us understand better how kernel regression works. On the other hand, I do not think the analysis supports that this is a first-principles theory of generalization in deep learning. The results may very well be relevant for explaining generalization in deep neural networks, but the theoretical analysis and experimental evidence for that are not particularly convincing as of yet.\n\nMy recommendation that this is marginally below the acceptance threshold is based on the framing of the paper and statements that about deep learning that are not as careful as the really nice analysis of kernel regression is. If some of these statements are revised (or perhaps supported with more evidence), and/or if there's more discussion of when they expect their results to apply to DNNs and when they expect it to break down, I will substantially increase my score and recommend an acceptance.\n\n### After Author Responses\n\nThe authors have addressed a number of my concerns, and I have updated my score accordingly.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}