{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The reviews end up split. The most positive reviewer notes that the paper may be useful broadly to researchers and practitioners. That is the main promise of the work. However as another reviewer points out, the authors fall short of convincingly explaining how the said practitioners and researchers would benefit from the work. And, also as noted in a review, the paper does not quite go deep enough into the discussion of what saliency means for different methods analyzed. \nContrary to the positive reviewers comment, I do not think that a paper must provide \"novel work to built upon\", but for a paper that doesn't, there is a significant threshold on how convincing it must be regarding the potential impact of the work. I think the paper in its current state, even after the rebuttal/revision, does not meet this threshold."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper describes a new framework for characterizing and analyzing saliency methods. Nine dimensions are defined, grouped into three high-level categories, with some form of quantification in each dimension to enable comparative measures. The dimensions are used to formulate saliency scorecards, concise 1-page summaries of the saliency attributes of a particular algorithm that should help a user determine which algorithm is best for their needs. A set of ten recent algorithms are analyzed and compared using the framework, revealing that some have gaps in their assessments that could be address with future work. Compelling, illustrative examples are used throughout to convey understanding of the dimensions and the differences between them.",
            "main_review": "Strengths\nThe underlying idea of framing saliency methods as abstractions that provide an approximate view of a model’s behavior is insightful. This viewpoint sidesteps the philosophical arguments about which measure is best, and instead acknowledges that different aspects of saliency methods, measured in different ways, are useful for characterizing the algorithms. One can argue about the specifics of the framework, i.e. whether the three categories are the best ones, or the nine dimensions similarly, but the underlying concept remains sound and produces a very useful analysis.\n\nThe paper format of introducing each dimension, providing its rationale, and a concrete example with a result is very effective at clearly communicating the definition and utility of the dimensions. Overall the paper is very clearly written.\n\nThe saliency cards, Fig. 4, are an excellent snapshot of each saliency algorithm. These types of cards have proved to be useful in other domains, as the authors state, and should be quite useful for user-facing algorithms such as saliency.\nThe analysis summary in table 1A is a compelling example of how the framework can comparatively reveal strengths, weaknesses and gaps in particular algorithms. \n\nIt is more than a survey paper, through its careful definition of the nine dimensions, many of which are new to this work. The concepts of perceptual correspondence and semantic directness seem particularly unique; the latter attempts to quantify the inherently squishy notion of the ease of user understanding of a method’s results.\n\nWeaknesses\nAll of the highlighted saliency methods are from 2017 or earlier, except one from 2019. While it is reasonable to focus on those that have established themselves over time as impactful, it would be helpful to incorporate a few more recent methods to ensure that they still fit into the framework.\n\nWhile the paper should be quite useful for researchers and practitioners of saliency algorithms, it does not present novel work to build upon. Some may find this insufficient for ICLR.\n",
            "summary_of_the_review": "Papers like this one tend to be rejected from highly selective conferences, but they can be very useful and impactful for researchers and practitioners alike in popular areas, such as saliency algorithms. This paper is thoughtful, well positioned with respect to previous attempts to characterize saliency algorithms, and should be an excellent resource for the saliency research community.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No concerns.\n",
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This article proposes a review of \"saliency\" methods in deep neural networks and rates them according to 9 dimensions: Computational efficiency, determinism, hyperparameters, model agnosticism, input sensitivity, minimality, perceptual correspondence and semantic directness. The author's claim is that this new taxonomy provides a better way for choosing between saliency approaches for the end-user. \n\nNote: What is meant by saliency in this paper is methods, such as Grad-CAM to determine which inputs were more prevalent in a network's decision (the word has different meanings in other sub-fields). ",
            "main_review": "The article is well written and provides a clear overview of some of the relevant works. It would have been interesting for the literature review to discuss in more detail the difference between the chosen approaches, as they calculate notably different values. \n\nThis leads to the main question from reading this article: Is it the case that the proposed taxonomy is an improvement on the state of affairs, by providing a clearer view of the pros and cons of competing approaches, or is it instead likely to obfuscate further the fact that most of those approaches compute distinctly different quantities. The paper does not provide actual evidence (for example, use case or user feedback) of this added value. \n\nSimilarly, saliency is defined as an abstraction in the introduction, but an abstraction to what is not clearly discussed, nor is the fact that there may be a disconnection between the expectations of the user and the actual quantities being calculated by different methods. ",
            "summary_of_the_review": "\nIn summary, this article provides 1) a review of so-called saliency approaches for neural networks and 2) a new taxonomy for rating the properties of those approaches. \n- The article would benefit from a more in-depth discussion of the fundamental differences between the approaches considered and what it means for the term \"saliency\". \n- The article would benefit from some sort of evidence that the produced taxonomy is of value to the end users. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a framework to evaluate saliency-based explanations for neural network decisions. The framework evaluates each method along a number of different dimensions (for example, reporting whether the saliency map output is fixed or stochastic, or the degree to which the output depends on hyperparameters). The proposed framework is not actually implemented or tested in this paper.",
            "main_review": "The paper is entirely a survey/review of existing methods; it does not propose any new XAI algorithms. However, I found the proposed dimensions and comparison of the saliency methods along these dimensions very interesting and informative. I could see this framework being useful to researchers in XAI as well as end users. The paper is also very well written and clear.\n\nThe main weakness of the paper in my opinion are:\n\n(1) The methodology is not entirely transparent -- it's not clear how the models are ranked on these dimensions or how a \"score\" would be computed for a given dimension. The authors note that some dimensions like \"perceptual correspondence\" are difficult to measure and may require large-scale user studies; other dimensions may be measured in multiple different ways and different methods could give different ranking results. It's not clear how this would be handled, but it seems to undermine the usefulness of this framework.\n\n(2) Since the proposed framework hasn't actually been implemented, there is no evaluation of how it works or whether it helps end users choose better models and make better decisions.",
            "summary_of_the_review": "This paper proposes a useful framework for evaluating and comparing saliency-based explanations for neural network results. However, it is entirely theoretical/speculative -- the framework has not actually been implemented or tested.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}