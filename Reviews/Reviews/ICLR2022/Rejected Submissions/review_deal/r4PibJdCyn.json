{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "Reviewers are in agreement that the paper is below the acceptance threshold. Main concerns focus around novelty, experiments, and justification of the paper's main claims."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "This paper jointly considers the problems of recommender systems (RS) and advertising systems (AS) as it is a coin’s two sides. The key is to model the joint probability of (user, item) instead of conditional probabilities (user | item) and (item | user) independently. The proposed model adapts an existing large-vocabulary loss function to the optimization objective. Experiments on real-world datasets are conducted to compare with both Matrix Factorization and Sequential Modeling methods.",
            "main_review": "++ It is a good try to consider RS and AS together.\n\nHowever, there are major flaws in the current forms of the paper.\n\n-- The motivation is not strong. Why we should consider RS and AS jointly; what are the benefits and what are the challenges. Motivation should be stated more clearly.\n\n-- The technical contribution is not enough. Comparing the objective of the proposed model (see Eq. (3)), it is a direct expansion of the existing loss functions (see Eq. (1)) from uni-loss to bi-loss (user & item). \n\nSmaller ones:\n\n-- The organization and writing can be improved. The mathematical notations are not correct in some places (both in the body text and in the Appendix).\n\n-- For evaluating advertising systems, the MovieLens dataset is not a suitable one and the CTR (click-through rate) metric should be reported. \n\n-- many typos:\nIn Abstract: Amazaon -> Amazon, generation compare to strong baselines -> generation compared to strong baselines.\nIn Contributions: with higher accuracy compare to other methods -> with higher accuracy compared to other methods.\nLines before Eq. (2): find that l2-normalize u and i and then rescale the dot product -> find that l2-normalizing u and i and then rescaling the dot product.\n",
            "summary_of_the_review": "Lacking motivation, contribution weak, evaluation not solid.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a method for both user2item and item2user candidates generation in recommender systems. The main idea is to employ infoNCE loss for optimizing the two tower model. To achieve bidirectional candidates generation, the authors propose to do negative sampling in batch from both user side and item side, and use the Bi-InfoNCE loss for optimization.",
            "main_review": "Strengths:\n1. The paper is well-organized and clearly-written. The main idea is clear and easy to understand.\n2. The proposed Bi-InfoNCE loss helps to model the joint distribution for bidirectional candidates generation.\n3. The authors conduct experiments on several public datasets.\n\nWeakness:\n1. The idea of introducing InfoNCE loss to recommender system is not novel, which has been used in existing works. The main contribution of this paper is the design of Bi-InfoNCE loss to optimize the joint distribution $p_{data}(u,i)$. However, it is not demonstrated why modeling $p_{data}(u,i)$ would be better than separately modeling $p_{data}(u|i)$ and $p_{data}(i|u)$ for u2i or i2u candidate generation. From the results in Table 2, Uni-InfoNCE u2i performs even better than Bi-InfoNCE, which further weakens the motivation of the Bi-InfoNCE loss.\n2. Besides, in Table 2, ComiRec methods perform significantly better than the proposed methods for Taobao dataset, but no discussion is provided. In this way, it is not approporiate to say ''TR achieves much better results by a large margin''.\n3. The comparison results to MF in Figure 2 and Table 1 are not promising. TR performs better for Pinterest but MF achieves better HR for Movielens. Results at other truncated top values are not provided. The overall improvement over MF with point-wise loss is not significant.",
            "summary_of_the_review": "The advantage of the proposed Bi-InfoNCE loss is neither clear demonstrated nor well supported by the experimental results. Thus I tend to reject this paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes to address candidate generations of users and items for recommender and advertising systems simultaneously by a single proposed model. The proposed model provides two ideas for existing two-tower recommendation models: it introduces a normalization of the score function and a bidirectional version of the InfoNCE loss. This paper evaluated the proposed method through several experiments.\n",
            "main_review": "Pros:\n\nThe overall architecture seems to be novel in the literature to my knowledge. This paper has tried to evaluate the proposed method from various aspects through several experiments.\n\nCons:\n\nOne of the claims will be that jointly addressing recommendations and advertising is effective in e-commerce services. However, it seems this paper did not sufficiently motivate the claim. Although Sec. 1 and Sec. 2.2 cite several related studies, those studies lack a discussion of situations in which both recommendation and advertising are performed in one e-commerce platform. I think it would help the reader's understanding if this paper explains how such platforms do recommendations and advertising and how the proposed joint approach is helpful for them in more detail. Also, if any previous studies perform both recommendation and advertising simultaneously, I recommend citing them.\n\nWhile the proposed method will contain some promising ideas, it seems that its technical novelty is somewhat weak. For example, SimCLR (Chen et al., 2020) has considered the idea of using the l2 normalization and temperature parameter of a similar score function. The Bi-InfoNCE loss is an appealing idea but does not seem to be completely novel. Similar ideas have already been proposed in different contexts [1,2,3]. Since those papers have recently been made available, I perceive them as contemporaneous work of this paper. However, considering them, I feel the derivation of the Bi-InfoNCE loss is reasonable but fairly straightforward, and the uniqueness and technical contribution is somewhat weak.\n\nMoreover, this paper did not explain well how the proposed method is effective in Sec. 3. For example, this paper calls the proposed method 'TotalRecall.' I interpreted the proposed method takes care of the improvement of recall, but Sec. 3 did not provide any implications. Also, this paper claims that the proposed method was effective in terms of convergence speed and diversity in the experiments. However, Sec. 3 did not clearly explain what part of the proposed method induces such effectiveness. I feel that the contribution of the proposed method is somewhat weak if it just happens to perform well in the experiments. For example, in Sec. 3.2.2, this paper claims modeling s_u can 'boost the converging speed a lot.' I recommended presenting the reason more quantitatively in Sec. 3 rather than just showing experimental results.\n\nWhile the experiments tried to evaluate the proposed method from various perspectives, the results do not always strongly support the effectiveness of the proposed method. For example, the performance of the Uni-InfoNCE outperformed the one of the Bi-InfoNCE in Table 2. In Fig. 4, the 'bi_nce_temp' method does not significantly improve the results compared to the 'ssm_temp' method for HR and recall. Also, there are many parts where noteworthy experimental results are missing. In Sec. 4.1, the experiments did not show the results for Uni-InfoNCE. There are two variants of Uni-InfoNCE (u2i and i2u), but the results of i2u are not shown in Table 2. Although many missing results may not work out so well, I recommend presenting more comprehensive and consistent results for all experiments.\n\nThe clarity of the paper appears to be somewhat poor. This paper has so many unclear parts about the proposed method and experiments. Please see the comments below.\n\n- The notation 'N' is used many times with different meanings in the whole paper. I recommend consistently using it throughout the manuscript.\n- In the experiments, how many negative samples were used for all the methods in each experiment? I interpreted this paper used 100 negative samples in Sec. 4 according to the description of A.4.1. Did the TR methods also use 100 samples in Sec. 5? If so, it means that the TR methods used much larger samples than MF_b methods. Why?\n- In the experiments, this paper refers too much to the figures in the appendix to explain the main experimental results. The appendix would be a material to support the main part, and I think it would be better to put the main results in the appendix much more sparingly.\n- In the experiments, why was the effect of different sizes of negative samples only evaluated in Sec. 5? It would be more consistent to do the same assessment in Sec. 4.\n- In the experiments, please ensure what the bold and underline highlighting means for all tables. Table 4 appears to have duplicate underlines.\n- Sec. 1: this paper mentions 'Theoretically we show that the superiority is due to the modeling of joint probability of u and i.' However, I did not find any theoretical claims to show the superiority of the joint distribution.\n- Sec. 2.3: I recommend specifying x and y of Eq. (1).\n- Sec. 3.1: what exactly is y_{u,t}? Is this an indicator variable of a specific item that was clicked on by u at time t?\n- Sec. 3.2.2 and A.1: I did not know what the variable s_u indicates. According to the text, s_u is drawn from the multinomial distribution Mult(N_u, p_u), which means that s_u is a K-dimensional count vector where s_{u, i} (i=1, ..., K) denotes the i-th element of s_u and corresponds to the number of interactions between u and i. However, Eq. (5) refers to s_u as an indicator of item i. Also, if S_{u, i} is a binary matrix, s_u will result in a binary vector. As in (Liang et al., 2018), the observation of s_u may happen to be binary, but this paper fixes the variable to be binary in the problem definition of Sec. 3.1.\n- Sec. 3.4.1: I did not understand why this paper chose a classical two-tower architecture. It seems that the presented two reasons do not exclude other possible architectures.\n- Sec. 3.4.1: 'in online serving .' -> 'in online serving.'\n- Sec. 3.4.1: the notation of f_{\\theta}(u) is confusing since it quite overlaps the notation of f_{\\theta}(u, i) in Eq. (1). Also, f_{\\theta}, g_{\\theta}, and \\phi_{\\theta} are also confusing since they share the same parameter \\theta. I recommend using different variables or specifying the detail of \\theta.\n- Sec. 3.4.1: \\phi_{\\theta} is used for both unnormalized and normalized score functions, which are confusing a little. For both functions, it is not clear what \\theta is.\n- Sec. 3.4.2: the definition of |S_{u, i}| seems unclear in Eq. (3). S_{u, i} is defined as a matrix, and the notation of |S_{u, i}| is not specified.\n- Sec. 4.1: 'NCF' of the caption of Figure 2 is not defined in this paper.\n- Sec. 4.1 and Sec. 5.2: this paper claims the TR methods converge faster than compared methods from the results of Fig. 3 and Fig. 7, but their x-axis denotes the number of processed data samples. I recommend showing the results with actual runtime on the x-axis.\n- Sec. 4.1: it would be better to explain what distinct items are before introducing Fig. 3. The term 'distinct items' is first explained in A.4.2.\n- Sec. 4.2: I didn't understand how to make the data for next-n-item prediction, which should be explained in Sec. 3.1. Also, this paper should ensure that using such data leads to fair comparison for all methods.\n- Sec. 4.2: why did not the experiment report the NDCG as in (Cen et al., 2020)?\n- Sec. 4.2: the difference of four (TR-)Youtube methods in Table 2 seems to be not explained.\n- Sec. 4.2: why did not Table 2 report the result of 'TR-Youtube [next-7-prediction]' for the Taobao dataset?\n- Sec. 4.2: how does each method in Fig. 4 correspond to the method in Table 2? Also, I did not fully understand the meaning of '_temp' in the caption of Fig. 4.\n- Sec. 4.2: what is the coherent vector? How is it induced by Eq. (3) and how does it improve diversity?\n- Sec. 5: in the first paragraph, please provide more specific examples that motivate mining for a group of similar items in real E-commerce services.\n- Sec. 5: in the first paragraph, this paper mentions 'Previously, ... so many models.' However, in the experiment of Sec. 5, only 54 item groups were used. I think binary classification approaches are also applicable for item groups.\n- Sec. 5.1: this paper mentions that 'We use Movielens-1m because it is also used in MFb of RS.' However, the Pinterest dataset was also used in the experiment of Sec. 4. Why was only the Movielens-1m dataset used?\n- Sec. 5.2: this paper mentions 'TR uses the same training data and model configurations for both RS and PUMS.' However, the procedure for creating the datasets appears to be different in Sec. 4 and Sec. 5. I didn't know if this paper used the same TR models for both experiments.\n- Sec. 5.2 and Sec. 5.3: I recommend showing all the scores of the distinct users even if the accuracies are very low.\n- Sec. 5.3: 'For small dataset' -> 'For small datasets'?\n- Sec. 5.3: I recommend showing all the results of aggregation methods: several results with max and sum are missing in Table 4.\n- A.1: did s_{u, i} follow the Gauss distribution even if it is a binary random variable?\n- A.2: S -> S_{u,i}?\n- A.2: what is exactly N in Eq. (8)? Intuitively, I think Eq. (8) should be divided by M * K.\n- A.3: I did not understand the claim of this section. I recommend providing more formal proofs to show the convergence of the score function.\n- A.4: I think this section is not well-structured. Although the titles of subsections indicate the considered methods, they explain the evaluation metrics.\n\n\n[1] Nguyen et al., Contrastive Learning for Natural Language-Based Vehicle Retrieval, CVPR 2021 Workshop.\n\n[2] Bai et al., Connecting Language and Vision for Natural Language-Based Vehicle Retrieval, CVPR 2021 Workshop.\n\n[3] Lee et al., Compressive Visual Representations, arXiv:2109.12909.\n\n==========\n\nI appreciate that the authors have responded to my concerns one by one. While some of the responses are convincing and have been reflected in the manuscript, it appears that not all the responses have been considered in the revision yet. I would like to see the completed version. In the following, I have two suggestions for the revised version.\n\nThe revision has added Sec. 3.6 to explain additional motivation. However, I wonder if the contents should be presented before explaining the proposal method, such as Sec. 1 or the first half of Sec. 3. Discussing motivation at the end of Sec. 3 makes the presentation feel like it is not progressing seamlessly. Also, it seems the response claims that the motivation is to save computational resources. Since it becomes a key claim of this paper, it will be better to show the results of computational efficiency in the experiments compared to the approach with separate models. Please note that the efficiency is not trivial: the resources for separate models could be smaller than the proposed joint approach for achieving enough performance in practice. Also, if the proposed method is running on an actual platform, I think the paper would be more convincing if this paper show the results of deploying it. If a method makes profits, showing those results is often seen as an influential contribution to the studies about online platforms (e.g., [4]).\n\nThe response often mentioned that the reason why some of the experimental results are missing is that those results were not so good and readers may be overwhelmed. I don't believe that not showing the results is an appropriate manner to report experiments. If this paper does not show the results, readers cannot know how good or bad the results are. Even if the results are not so good, reporting all the results will provide valuable information for subsequent studies. In the first place, readers will not be overwhelmed even if this paper shows the missing results. Bolding and underlining should be used for the readers who only want to know a summary of the results.\n\n[4] McMahan et al., Ad Click Prediction: a View from the Trenches, KDD 2013.\n",
            "summary_of_the_review": "While this paper addresses an interesting problem, the significance is not sufficiently discussed in the paper. The novelty and effectiveness of the proposed method will be quite weak. The clarity needs to be improved.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work proposes a bidirectional candidate generation framework for both recommender system (which provides items for a user) and advertising system (which provides users for an item). Specifically, the authors conduct a Bi-InfoNCE loss on the classical two-tower architecture to jointly learn both user and item representations. The Bi-InfoNCE loss considers each (u, i) pair as a positive instance, and selects both users and items as negative instances in InfoNCE. In experiments, the authors find that the proposed TR model outperforms MF in both recommender system and advertising system datasets.",
            "main_review": "The main strengths of this work are listed as follows:\n\n1.\tThe proposed Bi-InfoNCE loss is easy to deploy.\n\n2.\tTR has improvements on both accuracy and diversity.\n\nHowever, this work has the following weaknesses:\n\n1.\tIt seems that the main contribution of this work is the proposed Bi-InfoNCE loss. However, similar contrastive learning (Uni-InfoNCE) method [1] has been proposed and verified in candidate generation module. It is straightforward that both users and items could be used as negative samples if we attempt to jointly provide results for recommender system (which provides items for a user) and advertising system (which provides users for an item). Therefore, the technical novelty is limited.\n\n2.\tRelated recommendation models [1] should be compared.\n\n3.\tIn PUMS, the authors only conduct evaluations on MovieLens-1M, which is not a real widely-used advertising dataset. Moreover, the baseline MF is also not sufficient and competitive enough in advertising. I suggest that the authors should conduct PUMS evaluations on real advertising datasets with SOTA advertising models.\n\n4.\tThe universality of TR is not verified. The authors should deploy TR on different real-world recommendation and advertising models for comprehensive comparisons.\n\n5.\tIn Table 2, why not use the original next-item-prediction task in evaluation?\n\n6.\tIn Table 3, will more negative users help to improve the performance of MF (e.g., MF_b[16:0]).\n\n7.\tIn Eq. (3), The Bi-InfoNCE loss further considers negative users compared to the Uni-InfoNCE loss used in [1]. However, does the improvements of Bi-InfoNCE mainly derive from more negative samples? Since larger batch sizes may improve the performance given in [2]. The authors can select two negative user sets in Eq. (3), or just double the batch size of the Uni-InfoNCE loss for more comparisons.\n\n\nReferences:\n\n[1] Zhou C, Ma J, Zhang J, et al. Contrastive learning for debiased candidate generation in large-scale recommender systems[C]//Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining. 2021: 3985-3995.\n\n[2] Chen T, Kornblith S, Norouzi M, et al. A simple framework for contrastive learning of visual representations[C]//International conference on machine learning. PMLR, 2020: 1597-1607.\n",
            "summary_of_the_review": "The technical novelty is limited. Moreover, the improvements and universality of TR are not perfectly verified.\n\nIn conclusion, I will vote for Reject.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}