{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a new fast and accurate CWS framework by using a distilled encoder and a PCRF inference layer. The paper tried to distill the BERT as the encoder and uses perplexity to improve the PCRF. The paper verifies the effectiveness of the proposed model through low-resource and scalability experiments. The paper also creates two industrial datasets for future research. The main contribution of the paper is the improved PCRF.",
            "main_review": "Strength\n1. The paper proposes a light-weighted CWS system for industrial scenarios. The motivation behind such methods is clearly written. The paper first uses a distilled encoder to reduce parameters. The paper then improves the conventional  CRF decoder to deal with the unseen words by incorporating label consistency. \n\n2. The paper shows the effectiveness of distilled encoder, PCRF, coefficient lambda with different settings in the experiment. \n\n3. The paper also creates two CWS datasets extracted from e-commerce and video sharing social network. Since the paper focuses on industrial application, the scores on those two datasets are pretty useful.\n\n Weakness\n1. Some part of the paper is not clearly written.  I don't quite understand where the labeling consistency is applied. What is the criteria/threshold of distance to choose the related dataset for replenishing the current dataset? Such a process remains unclear in the experiment sections too.\n\n2.  In Table 3, it would be more convincing to list the speed of each model. Figure 2 is not good enough to compare with all the baselines. It only compares the distilled-bert with bert. However, it's highly possible that LSTM based methods in Table 3 have higher speed. The baselines such as THULac need to be explained for better understanding. The paper also needs to show the number of parameters for each model. ",
            "summary_of_the_review": "Overall, although this paper provides an interesting framework to improve the lightweight CWS framework, I recommend rejection for this paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper addresses the problem of Chinese word separation (CWS). The authors argue that existing methods are either simple and fast but not accurate enough or based on neural networks, accurate but not fast enough. They propose a small neural network + CRF approach, where the neural network is small and obtained by knowledge distillation from a bigger BERT model. The main contribution of the paper is the inclusion of the perplexity from an external language model in the computation of the segmentation score in the CRF. They also present two new datasets for CWS for industrial applications.",
            "main_review": "The paper is relatively clear although some passages are a bit hard to read or to fully understand. The goals and challenges are clearly stated. The technical contributions are small (knowledge distillation to reduce model size, inclusion of the perplexity of an external LM in the CRF score) and the experiments do not provide a thorough analysis although they are numerous and show several advantages of the proposed method.\n\nIn particular, it is not completely clear whether the perplexity of the external LM is used during training or only for inference. Also, no details are provided about the estimation of the LM (corpus, etc). It could have been interesting to see the impact of the LM choice on the performance.\n\nThe mathematical equations are not always consistent or well-explained. For example:\n  - $e$ is not defined, and $X$ do not appear in sec. 2.2 (even if the reader will figure out what is meant)\n  - how the equations if 2.3 and 3.2 are related? The notation seem to change without enough explanation of what the symbols refer to\n  - in 3.1, what is $y$ ? What does \"hard label predicted\" mean? \n  - it is unclear how the equation of page 5 is used\n\nFor industrial applications, the authors propose a baseline speed in Table 1, that looks like a target speed, to illustrate that several neural network-based approaches fail to reach that speed constraint. They propose a much faster method, but it would be interesting in industrial setups to also aim for the best accuracy at the target speed. Moreover, regarding the speed, it probably depends a lot on the hardware but there is no mention of hardware specifications.\n\nThe contribution of two new datasets, representative of industrial applications is quite nice. The experiments are validated on a lot of datasets, but some choices are not clear. For example, how are the hyper-parameters chosen? how robust are the results to that choice? what is the best choice of LM for the proposed PCRF?\n\nThe results are presented without much analysis. It could have been interesting to illustrate more where the LM helps and how, to experiment with different choices of language models, since that is the main contribution of the paper. \n\nFinally, the starting point of the paper is that existing methods are either too slow or not accurate enough, so one expects to at least see in the experiments a full comparison with the state-of-the-art including a comparison of model sizes, speed and accuracy.\n\nMinor comments:\n - The algorithm (page 5) is not completely clear and does not seem to bring much to the paper.\n - It is briefly mentioned in the text that the metrics for evaluation is the F1 score. The caption of the tables should mention that again to make the reading easier.\n - The statement \"Transformer is recognized to have an advantage over RNN and CNN\" would be more powerful with a citation.\n - What is \"the average divergence\" (p7), how is it computed?",
            "summary_of_the_review": "This paper propose a NN+CRF approach to Chinese word segmentation which seems like a standard approach nowadays. It addresses the challenge of designing a fast and accurate system for industrial applications. The first contribution (reducing the size of the NN through knowledge distillation) is common and seems to already be proposed by Huang et al (2019). The main contribution is the inclusion of a perplexity score in the CRF but this contribution is not sufficiently analyzed and the presentation in section 3.2 is very light and the equations are not sufficiently clear.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper focuses on improving the inference speed and accuracy of Chinese Word Segmentation(CWS) on industrial application scenarios, especially in a low-resource setting. To improve the inference speed, the paper proposes to train a smaller student via knowledge distilling from original pretrained language models such as BERT. To make the CWS model work better in a low resource setting, the paper proposes incorporating the perplexity score of the preceding sequence produced by a language model into the CRF score. Results on eight CWS datasets, including four low resource ones, validate the effectiveness of the proposed methods, including both speed and accuracy when training data is rare.",
            "main_review": "The main drawback of the paper is its limitation of contribution.\n\n- Improving inference speed by distilling a small model is not new and has been standard practice in recent years, e.g. [2], [3]. There are also many works that share the same goal using techniques other than knowledge distilling, such early-exit [1]. Relations between the proposed method and these works should be discussed.\n\n- Regarding the PCRF layer, it is not clear to me why this method would help the model perform better when there is not too much training data. An n-gram LM can also be inaccurate when computed from a rather small dataset, for example, when the dataset size is only 1% of the original dataset. A more convincing and reasonable way is to utilize the language model pretrained on the large-scale corpus to compute the perplexity, which may improve model performance in a low resource setting.\n\n\nExperiments:\nThe main problem of the experiment part is the lack of comparison with relevant works such as [1],[2]. Also, a more informative discussion should be provided to help understand the method; for example, is PLM a better choice to mitigate the low resource problem?\n\n\nWriting:\nThe writing of the paper is not good enough for publication on ICLR. For example, the discussion before the Algorithm 1 part is confusing: how is the distance measure metric used? How to \"replenish the current dataset with available datasets that are adjacent to it\"?",
            "summary_of_the_review": "Overall, I do not think this paper meets with the acceptance standard of the ICLR conference, thus recommending a rejection.\n\n\nReference:\n1. Li X, Shao Y, Sun T, et al. Accelerating BERT Inference for Sequence Labeling via Early-Exit[J]. arXiv preprint arXiv:2105.13878, 2021.\n2. Jiao X, Yin Y, Shang L, et al. Tinybert: Distilling bert for natural language understanding[J]. arXiv preprint arXiv:1909.10351, 2019.\n3. Liu W, Zhou P, Zhao Z, et al. Fastbert: a self-distilling bert with adaptive inference time[J]. arXiv preprint arXiv:2004.02178, 2020.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a Chinese Word Segmentation framework including a light-weight distilled Transformer encoder and a CRF module. In experiments, this framework shows high performance on multiple datasets with reduced time consumption. This framework performs especially well in low-resource settings.\n\nThe contributions of this paper include:\n\n- A model training technique that builds a fast, light-weight segmenter suitable for industrial application.\n- An improved CRF (PCRF) module.\n- Two new CWS datasets.",
            "main_review": "**Strengths**\n\n- Extensive experiments. \n- Clear description of the proposed methodology.\n- The CWS problem in industrial setting is an important research direction.\n- The performance improvements in low-resource setting is helpful for researchers and engineers.\n- The new datasets would be beneficial for future researchers on similar questions.\n\n**Weaknesses**\n\n- Comparison benchmarks for the inference speeds can be stronger. Figure 2 only compares the speed to the baseline BERT. Distilled BERT definitely outperforms the original BERT in speed, but how about other CWS systems (e.g., Jieba and PKUSeg in Table 1), on the different batch sizes? In addition, the conditions of the inference speed need to be specified in greater detail. Are the experiments run on a single computer or a cluster? What CPU does it have? Does it have GPU?\n\n- How much is the CWS performance differ from the existing CWS tools on large datasets? This paper only shows the comparison results in low-data settings. Would be great to also include the results (e.g., in Appendix), so that the future users will know when the proposed CWS system is suitable.\n- More importantly, this paper intends to propose a new methodological framework about model distillation. How does this new method compare to other methods involving distillation, in terms of speed and performance? There are a lot of experiments, but they do not really show how useful the proposed methodological framework is.\n- The writing can be improved by fixing some typos. Please refer to my comments below.\n\n**Misc. comments**\n\nSome recommended modifications towards typos:\n\n- Abstract & many other locations: light-weighted -> light-weight  \n- Page 2 before Table 1: \"the original query comes from ...\" do you mean \"the query\" instead of \"the original query\"?\n- Page 2 the paragraph after Table 1: \"we can ease the problem\": what does \"the problem\" refer to? \n- Page 2 \"Model accelerating technique\" -> \"Model acceleration technique\"\n- Page 2, second last paragraph: \"The original corpus\" -- This appears out of context. What is the corpus?\n- Page 2, \"corpora, include eight ...\". \"include\" -> \"including\"\n- Page 3 \"the CWS model in industrial\" -> \"the CWS model in industrial scenarios\"\n- Page 3 \"deploy it in the system\" -> \"deploy it\"\n- Page 3 \"millisecond speed needs\": how much data is supposed to be segmented within a millisecond? Please be more precise in describing the required time.\n- Page 3 \"dissatisfied\" -> \"unsatisfying\". Someone is adj (ending with \"ed\"); Something is adj (ending with \"ing\").\n- Page 3: \"Feature extraction is the necessary step\" -> \"... a necessary step\"\n- Page 4: \"it can be troublesome if lacks of\": The clause sentence does not have a predicate.\n- Page 4 \"we believe that it relies ... are insufficient ...\" -> \"we believe that relying ... is insufficient\"\n- Page 4 \"Note that there is a key point\" -> \"Note that\"\n- Page 4 \"chicken-and-egg problem\": What is this problem? Please elaborate a bit.\n- Page 5 \"conventional way, we use the adscititious datasets ...\": what is the conventional way, and what are the adscititious datasets?\n- Various locations: What does PCRF stand for? e.g., Probabilistic CRF or perplexity-enhanced CRF?\n- Page 5 \"We collected eight standard benchmark CWS datasets\" -> \"We use eight standard benchmarking CWS datasets\".\n- Page 6 \"We use Adam\" -> What is Adam? If you refer to a certain algorithm, please cite the paper that proposed this algorithm.\n- Page 6 second last paragraph: its -> their\n- Page 7 \"meets the requirement of segmentation response\". Again, what is the requirement?\n- Page 7 \"... to make the equal size of the two datasets\" -> \"to make the two datasets have equal sizes\"\n- Page 9 \"... well demonstrate the effectiveness of our method\" -> \"demonstrate the effectiveness ... well\"\n\n",
            "summary_of_the_review": "Proposes a method that improves performance in industrial setting. The comparison benchmarks should be stronger. The reporting and presentation can be improved. Also provides some new datasets.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}