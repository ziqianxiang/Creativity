{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper sits in the line of works that uses reinforcement learning to solve combinatorial optimization problems. It addresses the a variant of the traveling salesman problem (TSP) called TSP with drones, where a truck and a drone collaborate in traversing the nodes of a graph. \n\nThe technical contribution, in my opinion, is a new encoder-decoder architecture which replaces the attention-based decoder in Kool et al. 2018 with an LSTM-based decoder.",
            "main_review": "Strengths\n\nS1: The writing is good -- the paper is in general well written and easy to follow. The formulas seem to be correct and sound. The structure of the paper is well organized. The formulation is well illustrated. \n\nS2: The formulation of the new TSP-D problem is a contribution, though it would be more significant if the formulation could be extended to cover a broader range of problems (e.g., multiple trucks & drones).\n\nS3: The paper presents a reasonable effort in doing empirical evaluations of the proposed HM method and the baselines. It shows promising results in the TSP-D experiments with both synthetic datasets from random positions, and a more realistic scenario where the simulator is built from real world data. The visualization in Figure E.7 is appreciated.\n\n\nWeaknesses\n\nW1: The setting seems to be limited and not well justified. 1) It only consider ONE truck and ONE drone. Would it be easy to extend to multiple trucks and drones? This seems to be a more interesting and practical setting. 2) What is the difference of this setting versus settings where there are multiple trucks? Are there methods solving this setting, and why are they not working in TSP-D? 3) In the second paragraph of section 2.1, the two assumptions that \"we allow the drone to fly for an unlimited distance\" and that, \"Only customer nodes and the depot can be used to launch, recharge, and load the drone.\" seem to be contradicting? If you allow unlimited distance, why would the drones still need to be recharged? Am I misunderstanding something? \nBecause of the limited setting, it may not be of interest to a large audience. \n\nW2: It is not clear why exactly an LSTM-decoder is better than an attention-based decoder. The paper justifies that \"AM loses its strong competency in routing multiple vehicles in coordination\". However, AM decoder still conditions \"on the current location of\nthe vehicle and the current state of nodes\". Thus, I don't think it overlooks the interaction between different vehicles. It depends more on how you design the decoder. Compared to attention, an LSTM essentially adds to the historical decisions to the policy, not  the interactions between vehicles. Therefore, it is not clear why exactly LSTM-decoder is better, and the justification is quite vague in the paper. \n\nW3: Except for AM, NM by Nazari et al. (2018) has also been an important counterpart of the proposed HM. However, it is not compared as a baseline. Whereas I understand that not every baseline should be compared, but NM is mentioned a few times throughout. If historical information is important in decoding an action, why is it not important in encoding a state? Because of this, the empirical evaluation is not totally convincing to me. ",
            "summary_of_the_review": "The paper is in general well written and easy to follow. The authors have made a reasonable effort in formulating the TSP-D into an MDP and working on empirical comparisons of the proposed HM method vs AM and heuristic methods in the operations research literature. My main concerns, though, are that 1) the scenario being studied is too narrow to raise a broad interest from the neural combinatorial optimization folks, 2) the novelty of a hybrid model is limited, and the use of LSTM decoder is not well justified, and 3) evaluation is not totally convincing to support the claims. \n\nThe paper has its value, but given the above considerations, I am leaning towards rejection.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposed a method based on encoder-decoder architecture for solving TSP-D problems. The major contribution is the use of LSTM to model past information for future cooperation of trucks and drones. ",
            "main_review": "Strengths:\n1. The paper is well written; the formulation of TSP-D is easy to follow. \n2. Conducted experiments with real world data. \n\nWeaknesses:\n1. My major concern is that the contribution of the methodology is minor. Similar networks have been proposed. This paper adds LSTM for the decoder part to include historical information.  \n\n2.  Have you considered generating the solution in generative style instead of autoregressive. In this case, maybe the LSTM part  is not needed since all the information are used  together once",
            "summary_of_the_review": "The contribution is minor. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "An RL algorithm is proposed to solve the routing problem when a drone is available in addition to the truck to deliver orders. To get the policy, an encoder and decoder model based on the multi-head attention model and LSTM is proposed. The algorithm is compared with a heuristic and an RL-based method. ",
            "main_review": "I have few questions and concerns which are listed below: \nQ0- Since no decision is taken when the vehicle is in transit between two nodes, what is the point of having the \"remaining to arrive to at destination\" $r_t$ in the state? The only place that the $r_t$ has a considerable value is when the drone is at a node and the truck is in transit, which also in this case there is no decision since the drone has to go to the same node that the truck is heading to. Can you please clarify? \n\nQ1- \"the time taken until the next step, which happens when at least one vehicle arrives at the destination, will be the minimum of the two.\" which is the definition of $C_t$. I am not sure how the overall objective, the makespan is derived from this? In the scheduling terminology, the makespan is the time that all tasks are finished, i.e., it is $\\max{completion_time_i} [1]. Can you please clarify this? \n\n\nQ3- \"although AM is the state-of-the-art end-to-end learning method for single-vehicle routing problems.\" is not correct, there are several improvements over this paper. See [2, 3, 4, 5, 6, 7, 8, 9]. Given that, using AM as a baseline invalidates your claim about the performance of the algorithm and you need to use the latest algorithms in this area. Among those [7, 8] obtain one of the best results compared to classic benchmarks, so you may want to choose one of them. \n\n\nminor comments: \n\nM1- \"While AM is shown to be effective for CVRP, which involves multiple routes, it still only considers a single vehicle; the objective of CVRP—to minimize the total distance traveled—enables AM to route a single vehicle multiple times to obtain multiple routes.\" This is true that AM only considers a single vehicle to obtain the path, but you can run the outcome in multi-vehicle settings. For doing so, if you have $n$ vehicles and AM suggests $m$ cycles, you allocate $int(m/n)$ cycle to each vehicle, and the rest of the cycles can be allocated to other vehicles. \n\n\n[1] Pinedo, Michael. Scheduling. Vol. 29. New York: Springer, 2012.\n[2] Lu, H., Zhang, X., & Yang, S. (2019, September). A learning-based iterative method for solving vehicle routing problems. In International Conference on Learning Representations.\n[3] Peng, B., Wang, J., & Zhang, Z. (2019, November). A deep reinforcement learning algorithm using dynamic attention model for vehicle routing problems. In International Symposium on Intelligence Computation and Applications (pp. 636-650). Springer, Singapore.\n[4] Hottung, A., & Tierney, K. (2019). Neural large neighborhood search for the capacitated vehicle routing problem. arXiv preprint arXiv:1911.09539.\n[5] Gao, Lei, Mingxiang Chen, Qichang Chen, Ganzhong Luo, Nuoyi Zhu, and Zhixin Liu. \"Learn to design the heuristics for vehicle routing problem.\" arXiv preprint arXiv:2002.08539 (2020).\n[6] Xin, L., Song, W., Cao, Z., & Zhang, J. (2021, May). Multi-decoder attention model with embedding glimpse for solving vehicle routing problems. In Proceedings of 35th AAAI Conference on Artificial Intelligence.\n[7] Kool, W., van Hoof, H., Gromicho, J., & Welling, M. (2021). Deep Policy Dynamic Programming for Vehicle Routing Problems. arXiv preprint arXiv:2102.11756.\n[8] Kwon, Y. D., Choo, J., Kim, B., Yoon, I., Gwon, Y., & Min, S. (2020). POMO: Policy Optimization with Multiple Optima for Reinforcement Learning. arXiv preprint arXiv:2010.16011.\n[9] Li, J., Ma, Y., Gao, R., Cao, Z., Lim, A., Song, W., & Zhang, J. (2021). Deep Reinforcement Learning for Solving the Heterogeneous Capacitated Vehicle Routing Problem. IEEE Transactions on Cybernetics.\n",
            "summary_of_the_review": "The current benchmarks on the numerical experiment do not support the claims of the paper about the quality of the algorithm. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a deep reinforcement learning method to solve the hybrid TSP problem with a drone and a truck. The authors formulate the problem as a Markov Decision Process (MDP) and propose a attention LSTM-based deep learning framework to learn a policy function. Experimental evaluation results on real-world datasets show that the proposed method achieve good performance. ",
            "main_review": "+ The paper studies an important problem. \n+ The model can be generalized to different datasets and graphs. \n+ Real-world datasets are used in the experiments\n\n- The main contributions of the work need more justifications. \n\nA major related work (Nazari 2018) seems to follow the same idea (encode-decode with RNN). The proposed solution changed the RNN to LSTM. Also a graph embedding component is added. However, graph embedding techniques are well studied and there are many different techniques to choose from. The authors must demonstrate (1) what is new and (2) why the proposed method (mean of all node embeddings) is a good way to embed the input graph. \n\nThe difference compared to AM seems also minor. \n\n- The key technical challenges moving from a single-vehicle TSP to the TSP-D problem is not sufficiently justified. \n\nThe authors define the problem as an MDP, which assumes the Markov property (actions independent of of past actions and states). However, the authors justify the LSTM design by arguing that the memoryless property is a challenge for the TSP-D problem. Why not adjusting the MDP formulation and including historical information as part of the state then? The proposed method seems to violate the problem formulation itself. \n\nThe proposed solutions seem to be able to address the traditional DSP problem as well. It is unclear what is special about the new problem from RL formulation perspective other than saving some additional information in each state. \n\n- Other results such as training time, cost with more than one drone/truck, and different network topologies should be discussed. It is unclear how the proposed solution can effectively handle graphs with different structures. Also training time should be reported. Only comparing the inference time does not seem to be fair. The training time could be amortized to each test case on the same graph. ",
            "summary_of_the_review": "Overall this paper studies an important and interesting question. The formulation is reasonable. The proposed solution appear to have some novelty, including the graph embedding part and the use of LSTM for policy prediction. However, the overall novel contributions appear to be somewhat incremental. \n\nThere are several key issues that the authors could kindly address, such as the key difference/technical challenges compared to the traditional DSP problem that justify the new design, the new contributions compared to prior work such as AM and Nazari 2018. Finally, experimental results should be enhanced. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}