{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This work aims to solve the address some challenges of incremental learning for semantic segmentation. One major challenge is the modeling of unlabelled classes. This work proposes to use Evidential deep learning to adress this problem. Specifically, the foreground class probability is calculated by the expected value of the Dirichlet distribution, and an unknown class probability is estimated by  the uncertainty score. ",
            "main_review": "1. The application of evidential learning to this specific background and foreground modeling is new. The modeling is convincing. Clearly, this novelty is application-based rather than theoritical breakthrough. \n2. Experimental results show the performance improvement is marginal (Table 1 and 2).  The comparisons in  Fig. 1 are not convincing. It is not obvious that (c) is better than (b).\n3.  The presentation has much room to improve.\n     (1) The introduction section directly uses the concept of evidential learning, e.g. belief mass, uncertainty mass. You cannot assume all the   reviews  are familiar with evidential learning, in particular, the reviewers from the field of segmentation. Thus, you should add one section of preliminaries to introduce evidential learning in Section 3. \n     (2) Some maths symbols are used before they are defined. For example, some symbols in the 1st paragraph of Section 4 are used in Section 3. \n     (3) There are so many grammatical errors. ",
            "summary_of_the_review": "It is inspiring that this paper introduces evidential learning to model the background for segmentation task. However, there remain many weaknesses in the paper as mentioned above. It is not ready for publication.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors produce an approach to class-incremental learning in the scenario of semantic segmentation. Their main base loss, using Type II Maximum Likelihood, is the same as the one used by Sensoy et al., with the use of R´enyi-Dirichlet Divergence in place of the common KL Divergence. Using this loss, based on the Theory of Evidence view, enables the authors to meld the “uncertainty” often used in class-incremental learning and the catch-all background class in semantic segmentation, which they consider to be the unlabelled pixels. The standard knowledge distillation loss is added in order to properly classify newly-added classes from the uncertainty class. The authors also propose the use of a new evaluation metric which weights the performance equally of each incremented class. Results achieve state of the art performance,",
            "main_review": "The overall approach is very strong. The authors utilize a loss derived for a very different scenario and adapt it to class-incremental semantic segmentation in an intelligent manner. The performance is also impressive, with state-of-the-art in most portions of each dataset analyzed, although improvements on the overall (“all”) accuracy were marginal. The new evaluation metric, Increment Averaged mIoU, was not terribly different in the change of performance across different approaches, and doesn’t add too much information to the already present “new” evaluation metric, but does tend to show the strength of the given approach.\n\nSome recommendations would include adding a visual describing the approach - some useful visuals might combine the loss, learning the distributions of the classes + unlabelled category, and latent representations including newly added classes. Figure 1 is presented in a strange location in the paper - right at the beginning before any concepts of the approach have been laid out. Additionally, image 1. (a) seems unnecessary, and the results from t-SNE are fairly difficult to distinguish, and may not be showing what the authors are expecting to see. A further description of the Incremented Averaged mIoU would be useful - it is briefly presented and then never expounded upon afterward. The writers might also consider refocusing the related work more on the methods used in their approach - sections 2.1-2.3 expounding on different approaches in class-incremental learning could be combined into a singular section, while 2.4 and 2.5 could provide a more in-depth introduction of class-incremental semantic segmentation and more specifically, evidential deep learning. This would also be a great place to introduce more of the background mathematics utilized. One major issue this paper faces is a lack of description of these details - in fact, although many of the equations provided seem appropriate and correct, there is often little to no description of many of the terms used in the equations.\n\nA better description of considering the background and uncertain classes as the “unlabelled” category would be really valuable - I see this as a main component of the paper which likely contributes to the high performance, and this isn’t immediately obvious to the reader.\n\nFinally, there are too many errors in spelling, grammar, and sentence structure to count. A few examples are as follows, and are only taken from a singular section:\n“Both methods (are) relatively computationally heavy” in Sec. 2.1\n“…vary greatly between different different increments” in Sec. 2.2\n“…different variations on distillation has been proposed…” in Sec. 2.3\n“…we show that SDR also benefit(s) (from) our method.” In Sec 2.4\nThe second paragraph in Sec. 2.5 states the same information as the first sentence of the third paragraph, and is therefore best if removed.\nMore important errors include the ones found in the table captions (additionally, the descriptions of tables 1 and 2 are lacking to someone without knowledge of these particular datasets). There are also clear errors where it is obvious the authors did not do much proofreading - for instance, there is a randomly added, unrelated set of sentences in the description of the “New” metric found in Sec. 4.1.\n",
            "summary_of_the_review": "The authors present a very interesting approach, which provides state-of-the-art performance on the given task. However, the paper itself is the main detriment to the research, as the paper is difficult to parse, misses much of the description of the background details used, and in a few places, makes the results difficult to understand. The paper has solid potential, but in its current state would require a lot of effort in order to be at the level of acceptance.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper adopts evidential deep learning to tackle the problem of incremental semantic segmentation. The proposed method predicts a set of belief scores for the labeled semantic classes and maintains a uncertainty measure for unlabeled background. For each incremental step, the author combines several losses to learn the new classes and avoid forgetting old ones, including a log-likelihood loss, a regularization term, and a distillation loss. The paper evaluates this method on the PASCAL VOC and ADE20k benchmarks with comparisons to two prior works. ",
            "main_review": "Pros:\n- The proposed method achieves competitive results on the Pascal VOC benchmark. \n\nConcerns:\n- The paper is poorly written and difficult to follow. \n  1) Many notations are used before proper explanation and some of them are not defined at all. \n   e.g., K and e_i on page 4, K^t in Eqn (2), \\hat{p} in Eqn(4), L_{ML+FL} in Eqn (5) etc. and uncertainty is used without proper introduction. \n  2) in many places, the sentences are broken or incomplete. \n   e.g., the second paragraph in Sec 2.5 seems redundant/repetitive; the last sentence before Sec 3.1 is broken. \nIt seems that the entire paper should be re-written.  \n\n- The novelty of this work is mediocre. It is simply apply the evidential deep learning without much justification and the catastrophic forgetting challenge is still handled by distillation, which is well-understood.  \n\n- The motivation of using uncertainty estimation in this task is unclear. In particular, the model basically predicts K+1 scores, which is trained with a log-loss plus a regularization. How does this design cope with background drift?\n\n- The experimental evaluation is not convincing due to the following reasons:\n 1) The Inc. mIOU metric is biased as it provide smaller weights to the incremental step with larger number of classes. This would typically contradict with the real-world requirement which treats each class equally. \n 2) While the proposed method works well on the Pascal VOC benchmark, its performance on the ADE20k is disappointing. The mean IOU is significantly lower than the SOTA methods. As a result, it indicates the method cannot generalize well to more challenging cases. ",
            "summary_of_the_review": "The paper is not ready for publication due to its poor writing, lack of motivation, and inferior experimental results on challenging benchmarks. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "\nThe paper proposes a new semantic segmentation training method to handle class incremental problem setup, where objects class are incrementally added and should deal with the catastrophic-forgetting problem. The paper expresses the foreground class probability by the Dirichlet distribution and an unknown class probability using the estimate's uncertainty. The authors validated the efficiency of the work using public datasets: Pascal VOC and ADEK.",
            "main_review": "**Strength of the paper**\n\n(1) The paper proposes a new method to model the background through the evidential deep learning method, which is mathematically well-organized.\n\n(2) Modeling of the uncertainty seems to have more potential to be applied in various applications.\n\n**Weakness of the paper**\n\nThe main concerns of the reviewers are in the experiments part.\n\n(1) The paper omitted an essential state-of-the-art reference, PLOP. The reviewer agrees that the simple missing of the new paper cannot be the significant queue of judging the rating. However, the reviewer thinks that the author should include the quantitative, qualitative, and theoretical differences between PLOP by following reasons:\n- PLOP achieved the superior (or at least comparable) performance in both pascal VOC 15-5, 15-1, and ADEK testing setup.\n- We can also find the proposed mIOU metric in equation (7) in PLOP (`avg' in the experiment in PLOP. At least similar).\n- PLOP: Learning without Forgetting for Continual Semantic Segmentation (CVPR 2021)\n\n(2) Also, the reviewer feels that the study of the hyper-parameter: background prior ($p_{bgk}$) is not fully revealed by the experiments. \n- According to the paper, this prior is different from dataset to dataset, 0.7 for PASCAL and 0.3 fo ADE20K. Can the author give some guidelines to set this prior for an arbitrary dataset? \n- The paper's suggestion will be much stronger if the author provides an analysis of its effect and ablation study.\n\n(3) The reviewer feels that the paper would be much better if it contained harder CIL setups, such as VOC 10-1, 5-5, or 2-1 to validate the effectiveness of the paper.\n\n(4) In Table 3 of the paper, the performance in ADE20K dataset is not impressive not just compared to PLOP but other comparative methods like MiB and SDR in the paper. Did the reviewer falsely understand the table? If so, the reviewer welcomes the detailed explanation and analysis of the result.\n\n(5) The reviewer thinks the ablation study of loss terms in equation 5 will be required to see the effect of each term.\n\n(6) If the qualitative visualization of hard cases in the proposed method (at least in supplementary material section) will be helpful to understand the paper's strong-point and limitations.\n\n**Summary**\n\nThe reviewer is especially concerned about the experiments of the paper, listed above, and expects detailed responses of the author to discuss the paper's contribution in this field.\n\n",
            "summary_of_the_review": "Please see the main review section for the review.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}