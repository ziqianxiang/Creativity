{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "In this work, the authors set up a new task for scene text detection. Instead of detecting individual text units (such as characters or words), in the proposed contextual text detection task contextual text blocks should be detected and formed to convey continuous and complete textual information in natural scenes. To facilitate future research, the authors label and release two new datasets for the task of contextual text detection, based on SCUT-CTW and ReCTS. Moreover, an algorithm for contextual text detection called Contextual Text Detector (CUTE) is proposed.",
            "main_review": "Pros:\n\n1.The proposed contextual text detection task is different from the conventional text detection task, brings new technical challenges and could be useful in real-world applications (for instance, picture-based scene text translation). Overall, it might be beneficial to the community.\n\n2.Two new datasets for assessing methods for contextual text detection are annotated and released, which might facilitate future research.\n\n3.The authors also devised a method for contextual text detection (named CUTE) and compared it with different baselines.\n\n\n\nCons:\n\n1.Though the new task is valuable, the novelty of the proposed CUTE is quite limited, as it simply assemblies multiple existing techniques (i.e., DETR, Multi-Head Attention, Feature Embedding). Moreover, the performances of CUTE on SCUT-CTW-Context and ReCTS-Context are not promising and its robustness in challenging scenarios (for example, complex text layouts and text blocks with different orientations) is unknown.\n\n2.The choice of the Integral Text Detector in the proposed CUTE is questionable. The authors adopted the Transformer-based generic object detector DETR (Carion et al., 2020) as the Integral Text Detector. However, according to the results from Table 6, the performance of DETR is not as competitive as LINK (Xue et al., 2021b) and MSR (Xue et al., 2019). Considering that the authors claimed in the paper “the performance of CUTE depends heavily on the detection of each integral text unit”, why did not the authors choose LINK and MSR (or other text detectors) as the basic Integral Text Detector in the CUTE framework? \n\n3.To fully demonstrate the strength and weakness of the proposed CUTE, in addition to successful examples, the authors should show several typical failure cases of the proposed method and analyze the reasons behind them.\n\n\n\nMinor Issues:\n\n1.In the caption of Table 5: “SCUT-CTW” should be “SCUT-CTW-Context”?",
            "summary_of_the_review": "Overall, this work proposed a valuable task for text detection. The authors should resolve the issues regarding the novelty, effectiveness and robustness of the CUTE method.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper addresses an important aspect of unstructured text detection - the order of the text, using contextual information on integral text units. The proposed ContextUal Text dEtector (CUTE) has primarily 2 components:\n1. It first detects integral text units using an Integral Text Detector. This is achieved by learning 3 embeddings: \na. Feature embeddings: that are the flattened and linearly projected cropped visual features for each detected integral text unit\nb. Index embeddings: using sinusoidal positional encodings common in transfomers\nc. Spatial embeddings: encoding spatial information to each integral text unit\n\n2. Contextual text block generator that uses the above embeddings to model the relationships between each pair of integral text units, predicts their indices and generates a graph.\n\nThe datasets cover both the simpler (char-level) and harder (word-level) cases. The availability of the datasets with annotations is another big contribution to the field.\n\nThe results are compared with the state-of-the-art algorithms (CLUSTERING, CRAFT and LINK), and show marginal improvement in case of  simpler character-level dataset, and impressive (in some cases doubling the accuracies) for harder word-level datasets.",
            "main_review": "Strengths:\n1. The paper clearly demonstrates an integrated approach to unstructured text detection, and more importantly, providing the ordering of the text based on the contextual information. This is key to any downstream tasks like machine translation or image search, where the right context is the key to higher accuracy.\n2. The approach to divide the model into text detector and text ordering is intuitive and novel. In particular, the embeddings used: feature, index and spatial are in the right direction. \n3. The math appears decent\n4. The datasets cover both the simpler (char-level) and harder (word-level) cases. The availability of the datasets with annotations is another big contribution to the field.\n5. The experiments compare the CUTE algorithm with the state-of-the-art and showcases impressive (nearly doubling the accuracy in some cases) for the complex dataset\n\nWeaknesses:\n1. It is hard to differentiate the improvement in text detection alone. The metrics used are solely focused on the ordering of the text. Even the Global Accuracy (GA) metrics is based on contextual text block detection AND the correct reading order. This means, we do not know how the paper works in terms of text detection recall only. It would be good to understand if the proposed ordering scheme hurts the text detection recall. In that context, there is a lot of literature and datasets on which the proposed algorithm should be compared against.\n2. Since the experiments are done on the new dataset, it is not clear how good the text detection 'only' (with no ordering) is on known datasets, where ordering is not available.\n3. Given the paper is heavily focused on the ordering of the text in the blocks, I propose a better, more explanatory title to the paper. Contextual Text Detection is too generic and does not bring out the essence of the approach.\n4. CUTE abbreviation seems very forced\n5. Few other smaller corrections:\n- use of 'text messages' is incorrect. Please consider revising the wordings\n- summarize the results in Abstract and Conclusions\n- the last paragraph of section 1 is contradictory to the one previous to it. CUTE is the overall system, yet it states as if its a new contribution to the first one. There are two contributions only - CUTE and datasets\n- Equation 6: Bottom-right vertex is not needed if you have the top-left vertex and w,h\n- Wordings: In final --> Finally\n- 4.3 section: Index prediction head, consider revision on v^{ik}_token line\n- Table 6 needs more context and the procedure on how it was done.\n6. References have the following issues:\n- pp is not consistent for pages. It is missing for many\n- Consistency in upper cases for first character of conference names\n\n",
            "summary_of_the_review": "Given an integrated approach to the ordering in unstructured text detection, the availability of two new dataset annotations, and impressive results on word-level dataset compared to state-of-the-art algorithms, this is a good contribution to the field.\n\nHowever, one thing that sticks out is that the metrics compare the accuracy in terms of only the ordering of the text blocks. This means, CUTE cannot take advantage of numerous other datasets and algorithms that solely aim for text detection. I would love to first establish the baseline where the precision and recall are measured on text detection alone (on standard datasets, against known algorithms), and as a next step, the proposed metrics compares the ordering aspect of the algorithm. This is because, adding extra constraints (like ordering) could have led to a poorer recall in text blocks, and comparing the approach with only ordering-based algorithms may hide that aspect.\n\nJust like Table 6 shows false-positive removal in different detectors using CUTE, it would be interesting to know how it compares on text detection with them on both precision and recall.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper introduces contextual text detection, a new task in the area of scene text detection and recognition. The goal is to detect blocks of text, understanding a block as a group of related words or characters, instead of detecting individual words as most previous works do. For that, the paper introduces two new datasets, based on existing ones, but annotated at block level, and new evaluation measures to evaluate the task of block detection. It also proposes a specific text detection architecture that integrates a contextual block generator that is capable of grouping indivual words or characters into blocks. Experimental results show that the proposed architecture outperforms previous methods that also try to group words into text lines. ",
            "main_review": "STRENGTHS:\n- The new task, contextual text detection, covers an exisiting need in the area of scene text detection and recognition that, up to now, has mainly focused at word level. Being able to group detected words into meaningful text blocks is necessary for correct text recognition and further use of the recognized text in more high-level image understanding tasks. In that sense, the definition of the new task and the release of new datasets and metrics is a useful contribution that can boost research in that direction.\n- The paper proposes a novel specific architecture to integrate the spatial context of detected words and use that to predict the sequence of text units into a block. This architecture can be used in combination with any method that generates text units (words or characters).\n- Experimental evaluation shows that the proposed architecture works well to group text units into blocks, better than other state-of-the-art methods that also group words into text lines. It also includes an ablation study showing the contribution of the different embeddings used for grouping words into blocks. It also includes additional experiments showing how grouping text into blocks can improve both detection and recognition.\n\nWEAKNESSES:\n- The paper does not take into account previous datasets with text line annotation (for instance, MSRA-TD500 and LSVT). Although it is true that the concept of block used in the paper is more generic and includes multiline text, I consider that the proposed work should be discussed in the context of these previous works. Actually, the proposed architecture could be applied to these previous datasets allowing for a better comparison with existing state-of-the-art. \n- Results in table 6 suggest that the choice of DETR as backbone to detect words could not be the best option. I missed some discussion and results on the influence of the backbone word detector on the proposed datasets",
            "summary_of_the_review": "\nThe paper introduces a new task that covers an existing gap in the area of scene text detection proposing new datasets, metrics and a novel architecture to address this new task that it is shown to be effective and better than baseline methods. The paper lacks some comparison with related tasks and datasets, at the level of line detection. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a new setup that detects contextual text blocks in natural images. Specifically, the new setup is a dual detection task that first detects integral text units and then groups them into a contextual text block. Moreover, the authors will release two datasets with the corresponding text blocks annotations. Three evaluation metrics were defined in the paper for this setup. In addition, the paper also proposes a method for the new setup named CUTE. In this method, which builds upon DETR as the detection architecture, initial text boxes predictions are obtained, then visual features are extracted from the backbone, and spatial position embeddings (as in LayoutLM) are added. Finally, the arbitrary length sequence of features is fed into several multi-head attention layers and a graph generator produces the final index classification prediction which can be translated into reading order and text blocks. The proposed methods achieve the best performance out of the methods that were considered as baselines.",
            "main_review": "Paper strengths:\n1. The paper presents for the first time a setup that incorporates text blocks and reading order into scene text detection. This is an important task that so far has been neglected by previous work, and has a big impact in real-world scenarios. As the paper mentioned, reading order and text block are key factors for downstream tasks.\n2. The authors will publish two datasets that will contain contextual text blocks and reading order annotations.\n3. The authors propose the first baseline for the task, which is based on the DETR architecture and a novel method to obtain reading order and text blocks prediction from the DETR’s output. In addition, the added gradient flow from the reading order/text blocks text was shown to improve detection performance.\n\nPaper weaknesses:\n1. I am not confident that this paper is relevant to ICLR, it may be better suited to other venues.\n2. The proposed CUTE method is limited in its novelty, mostly since it is simply a few transformer layers used for a simple index prediction task.\n3. The chosen \"state-of-the-art\" methods used as the baseline in the paper are not sufficient, especially for SCUT-CTW. Those methods were not built for text block detection and, as evidence, they are significantly underperforming. I would suggest performing two experiments to improve that. The first is aimed at obtaining a better baseline using a simple FRCNN which predicts two types of boxes (words and text blocks). Secondly, as also mentioned in the paper, performance depends heavily on the detection of each integral text unit. As such, why not display the performance of word-level LINK + the CUTE mechanism for text blocks using the proposed metrics (LA,LC,GA) to isolate just the effect of CUTE?.\n\nMinor issues:\n1. When extracting the feature embeddings from the CNN backbone, it is unclear why crop & resize is used rather than ROI align which is the natural choice. \n2. It is unclear what is the effect of the initial indexing embeddings, which are randomly assigned. Will performing an initial sort by right-to-left and top-to-bottom help? Is it deterministic, or they can change between the same image in different batches during training?\n3. In table 6 presented are results on SCUT-CTW for text detection, what metric is used? Fscore? If so the results are very far from the results reported in each paper (for example MSR and LINK reports 81.5 and 82.7, respectively on CTW). In addition, if the claim is that the CUTE method reduces false detection, please show precision-recall metrics to back it up.\n4. In table 5 presented is an ablation study over SCUT-CTW-Context to identify the contribution of each embedding. As the transformer model itself doesn’t have any sense of position/order for each token in the sequence, I don’t understand the logic of trying to run the proposed method without indexing embeddings when the task is modeled as an index prediction task.\n5. For completion, please mention which loss is used.\n6. For the additional spatial embeddings, it is worth adding the relevant citations (such as LayoutLM).",
            "summary_of_the_review": "Overall, the technical contribution of this work is not significant, with lack of novelty, and the inadequate state-of-the-art comparison make this work not solid enough for ICLR. I do believe that the new setup proposed in the paper is of value, however, I do recommend submitting it to a more relevant venue with improved experiments. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}