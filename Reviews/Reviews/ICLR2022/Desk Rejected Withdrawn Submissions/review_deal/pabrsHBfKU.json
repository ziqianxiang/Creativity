{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "**Algorithmic contribution**: This paper provides a new algorithm APPLE to learn personalized models in the setting of cross-silo federated learning. The algorithm assumes that each client has a core model, and that the server maintains the core models from all clients. For each client, its personalized model is a linear combination of the core models from all the clients. The algorithm works as follows: in each round, each client downloads all (or a subset of) the core models from the server; updates the client’s own core model and the linear combination coefficients; the updated core model is then sent back to the server. \n\n**Empirical contribution**: The paper compares the proposed algorithm to eight related algorithms over four datasets (under two non-IID distribution settings), and shows that the proposed algorithm achieves better or comparable performance.",
            "main_review": "**Strengths**\n\n1. Overall the paper is well written and easy to read.\n\n**Weaknesses**\n\n1. **Privacy concerns**: Privacy is a natural desired feature in the setting of cross-silo federated learning, because a client (in this case a data silo, such as a bank or a hospital) usually wants to ensure that the training process does not reveal too much information about its own local data to other clients (or an external adversary). One nice property about the standard FedAvg algorithm [1] is that it can be used with techniques such as differential privacy (DP) [2] and secure aggregation [3] to protect the privacy of a client’s local data against untrusted parties (see, e.g., Section 4-5 in [4]). Unlike the standard FedAvg algorithm, the proposed APPLE algorithm allows every client to download other clients’ core models in each round, which means that each client has access to other clients’ local model updates in each iteration and as a result, more information leakage from one client to other clients. While DP techniques may still be used with APPLE (note that secure aggregation [3] is not compatible with APPLE) to train the core models, I am worried that APPLE has a worse privacy-utility tradeoff than FedAvg (i.e., to achieve similar DP guarantee, APPLE needs to add more noise and hence, results in worse accuracy). \n\n2. **Concerns on the empirical comparisons**:\n  - How do you tune the hyperparameters? There is no validation set (Each dataset is only split into a train and test set according to Appendix B.3). \n  - The accuracies in Table 1 and Table 2 do not have standard deviations. Do you run each algorithm only once?\n  - The results of FedFomo shown in Table 1 are lower than what is reported by the FedFomo paper [5]. Specifically, for the pathological non-IID setting, Table 1 in [5] shows that FedFomo achieves ~92.73 accuracy on CIFAR10 which is higher than the 91.96 accuracy shown in Table 1 of this paper.\n  - The number of clients are set to be 12 in all experiments. Will you achieve similar performance with more clients (e.g., 100 clients in the FedFomo paper [5])?\n\n3. **Concerns on the technical novelty**: The idea of representing each client’s model updates as a linear combination of all the clients’ local models, and reducing communication by downloading a subset of core models with highest correlation, is similar to FedFomo [5]. It would be nice to clearly state the difference between the two algorithms and explain why the proposed algorithm is better.\n\n[1] Reddi et al., Adaptive Federated Optimization, https://arxiv.org/abs/2003.00295\n\n[2] McMahan et al., Learning Differentially Private Recurrent Language Models, https://arxiv.org/abs/1710.06963 \n\n[3]  Bonawitz et al., Practical secure aggregation for privacy-preserving machine learning, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, 2017.\n\n[4] Kairouz et al., Advances and Open Problems in Federated Learning, https://arxiv.org/abs/1912.04977 \n\n[5] Zhang et al., Personalized Federated Learning with First Order Model Optimization, https://arxiv.org/abs/2012.08565 ",
            "summary_of_the_review": "I have concerns on the privacy issue, the process of empirical study, and the technical novelty compared to previous work, so I decided to reject the paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes an approach to learn personalized models as a linear combination of a set of core models. There exists one core model for each client which is updated using the gradient of the current personalized model, the weights of the core model are learned using this gradient as well. The local loss function (of which the gradient is computed) consists of the standard loss plus a proximal term that promotes an equal weighting of core models. Communication can be reduced by updating only a subset of core models in each round (the subset is chosen individually by each client).  The approach is empirically evaluated on a set of benchmark datasets with two different degrees of non-iid-ness.",
            "main_review": "The idea of combining a set of core models is not novel, but the proposed trick of using a proximal term to avoid overfitting on the local model is neat. The paper is well written and clear, the empirical evaluation shows that the proposed approach performs very well, compared to the selected baselines, which include some state-of-the-art methods, such as FedProx and FedFOMO. \n\nGiven that such mixtures of models is not novel, as shown in the papers related work (e.g., multi-task learning, or FedFOMO), them main contribution seems to be the proximal term. However, the necessity for this term is not well motivated. The argument that the off-diagonal entries in the model weights matrix should be close to zero seems reasonable for very heterogeneous datasets, but it remains unclear whether this happens in many real-world cases. Quantifying this theoretically or analyzing this empirically would help support this claim. The lack of theoretical support for the proposed method further weakens the contribution. The empirical evaluation shows that the proposed method outperforms the baselines (here it would be interesting to not only analyze label-wise non-iid-ness, but also other forms of heterogeneity, such as feature shift [1]). However, it is surprising that all methods perform poorly on the practical non-iid setting since in this setting clients have samples of more classes available. Since the advantage of the proposed method over baselines seems to be significant only in this case, for the results to be convincing it would be necessary to show that this advantage holds for different settings of the practical non-iid case as well. \n\nTherefore, I do not think this paper is ready for publication, yet. \n\nDetailed comments:\n\n- The proposed method is fairly similar to the method proposed in Marfog, et al., 2021 [1], however, in [1] the approach has a clear theoretical foundation. I ask the authors to clarify the relation to this work.\n- Why do you need two parameters lambda and mu? For every setting of mu and lambda, we could subsume mu in lambda.\n- How exactly does the performance of the proposed method depend on the parameters lambda and mu? For a given (good) state of core models, can you show the dependency of local performance on a particular value of mu and lambda?\n- Can a small lambda in the end lead to overfitting, despite having well-training models? \n- How is the interplay between a scheduler for lambda and the learning rate of the training algorithm (eta)?\n- Why do you use exactly 12 clients? Limited computation power would be a reasonable argument, but without any reason this number seems to be odd.\n\n[1] Marfoq, O., et al. \"Federated Multi-Task Learning under a Mixture of Distributions\", Advances in Neural Information Processing Systems, 2021.",
            "summary_of_the_review": "The paper proposes to learn personalized models in federated learning as linear combinations of a set of core models. The approach is empirically evaluated on a set of benchmark datasets. The contribution is interesting, but the proposed method lacks theoretical foundation and the empirical evaluation is not entirely convincing. Thus, the paper is not ready for publication, yet.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes APPLE, a new algorithmic framework for personalized federated learning. Instead of taking averages of local models with a fixed weight (as done by FedAvg), APPLE learns the weights adaptively from the data, thus incorporating the relationship among client-wise data distributions. The authors apply APPLE to various kinds of benchmarking datasets and show that APPLE achieves state-of-the-art result.",
            "main_review": "Strengths: The idea of adaptively learning the weights is simple to implement, gives a non-trivial amount of performance boost, and can potentially serve as a general-purpose plug-in to other more sophisticated personalized FL algorithms.\n\nWeaknesses: \n- The idea of learning the weights is not entirely new. It has appeared in earlier works on transfer learning and multi-task learning (e.g., [1, 2]).\n- The paper does not give any theoretical justification of why APPLE would work. For example, why would doing plain SGD on the weights (Eq. 6) converge? It makes more sense to me to model the weights as vectors on the probability simplex and thus doing mirror descent on the weights might be a more sensible choice here? \n\n[1] Jiang, Jing, and ChengXiang Zhai. \"Instance weighting for domain adaptation in NLP.\" Proceedings of the 45th annual meeting of the association of computational linguistics. 2007.\n\n[2] Cortes, Corinna, Yishay Mansour, and Mehryar Mohri. \"Learning Bounds for Importance Weighting.\" Nips. Vol. 10. 2010.",
            "summary_of_the_review": "Given the simplicity and its empirical performance, I think APPLE could serve as a strong baseline for personalized FL. Thus, I vote for 6: marginally above the acceptance threshold.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents APPLE, an algorithm for personalized federated learning. Apple's main addition over existing personalized FL approaches is the decomposition of a personalized model into a \"core model\" and \"directed relationship vector;\" only the former is transmitted to a centralized server and other clients during training, while the latter allows a client touse a convex combination of a subset of other client models during its training. The authors illustrate their method with a series of experiments on simulated siloed datasets.",
            "main_review": "\n## Major Comments\n\n* I find the BMCTA to be a somewhat limited metric for performance evaluation for the datasets in this paper. The \"best\" clients already achieve accuracy > 95% for even the baseline models, and APPLE achieves a lift over the nearest personalized FL method of less than 1% accuracy for most datasets. Given that the benefits of personalized FL would likely go to more aberrant groups anyway, I would be more interested to see \"WMCTA\" (Worst Mean Client Test Accuracy), since this would perhaps more clearly measure the benefits of personalization for the clients that need it most; a glance at bottom row of Fig. 2 suggests that this measure might also favor APPLE, but it is hard to tell precisely.\n\n* If I understand correctly, \\mu=0 (i.e. in Table 1) is \"pure\" personalization (no proximal term in Eq (7)). Based on the results shown there, the benefit of the proximal term is small and inconsistent, particularly in the \"practical\" case (2/4 experimsnts shown \\mu=0 has better accuracy). This raises some doubt over whether this term is necessary; this is of course linked to the authors' claim that \"chances for similar distributions among clients are slim\" which I think is far too strong a claim. Please provide furhter motivation for the proximal term, or expand the empirical results to explain its usefulness.\n\n\n## Minor Comments\n\n* I would suggest to include DR vectors in Fig 1.\n\n* \"Core model\" needs to be clearly defined *much* earlier in the paper (it is called \"a constructing compone to fhte personalized model\" in Sec. 3, but that isn't very informative). Really, the core model is simply w_i; please clearly state this early in the paper.\n\n* Despite the decomposition of models into \"core\" and DR vectors, I do not think that all privacy issues are eliminated; an adversary could probably learn a great deal from the w_i's (which are transmitted to each client). This is worth commenting on, at least briefly.\n\n* The \"sharding\" process described in 4.1 is unclear.\n\n* Why is train, not test, loss shown in Fig. 2? Test loss would be a useful metric in my opinion.\n\n## Typos etc.\n\nThere are *many* typos in the paper, particularly in the introduction. I list a few here, but would recommend a through revision and check for grammar.\n\nSec. 1: \n\n* \"from the convergence challenges brought by the statistical data heterogeneity\" --> from convergence challenges brought on by statistical data heterogeneity\n\n* \"and that may lose\" --> that may lose\n\n* \"the number of the trained model(s)\" --> the number of trained model(s)\n\nSec 2:\n\n* \"numerous work has been focusing on\" --> numerous works have focused on\n\nSec 3:\n\n* \"progresses in round\" --> progresses in rounds",
            "summary_of_the_review": "This paper is mostly well-written and the methods are well-described. The experiments suggest a consistent, but marginal, advantage to APPLE over most existing methods. The main benefit to this approach, however, is only a small performance gain, particularly among the best-off clients (measured by the BMCTA metric). I would more strongly support this paper if either (a) there were clearer performance gains, for example among the *worst*-off clients or when using real (as opposed to simulated) siloed datasets (there are many \"genuine\" federated datasets openly available now); or (b) the authors were able to more clearly motivate their approach or explain exactly why it works better than other personalized FL methods, and under which conditions. As is, I consider this a borderline paper -- compelling and interesting, but possibly not a major enough contribution to warrant acceptance in its current form.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}