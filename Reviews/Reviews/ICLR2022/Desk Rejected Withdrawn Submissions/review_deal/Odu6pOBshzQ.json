{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper presents a sublinear least-squares value iteration (LSVI) and LSVI-UCB  via LSH. The main result from the paper is that it reduces the value iteration complexity of LSVI from linear to sublinear in action space. While reducing this complexity, the total regret is preserved as before. The section 5 presents various technique to make use of LSH based approximate Max-IP algorithm for sublinear runtime LSVI and LSVI-UCB in RL. \n",
            "main_review": "Strengths\n1. The paper presents a sublinear least-squares value iteration (LSVI) and LSVI-UCB  via LSH. \n2.  The paper provide several techniques in Section 5 to make use of LSH based approximate Max-IP algorithm for sublinear runtime LSVI and LSVI-UCB in RL. \n\n\nWeaknesses\n1. The paper is not well written and it has several typos and grammatical mistakes which makes it hard to follow, especially the first two pages. \n2. The citations are also hard to decipher from the text, it will be good to use different formating to clearly separate out the citations from the main text of the paper. \n3. The paper has no results or discussion around the application of the proposed approach. Will the theoretical guarantees hold in practice? Also, will the results in this paper improve the applications where  LSVI and LSVI-UCB via LSH are used?   ",
            "summary_of_the_review": "I'm on the fence on this paper as the paper has no discussion around the applicability of this approach and the paper has several typos and grammatical mistakes. Having said that, the paper does presents a sublinear least-squares value iteration (LSVI) and LSVI-UCB  via LSH with Theorem 4.3. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper tackles an important problem: reducing the computational complexity of RL methods. The authors show that their utilization of Locality Sensitive Hashing allows for sublinear per iteration time complexity for several different variants of Least-Squares Value Iteration. They provide theoretical guarantees on the regret incurred by their algorithms, and show that they achieve orderwise optimal performance.",
            "main_review": "Strengths:\n1. Importance of problem: modern RL methods are bottlenecked by large per iteration complexities, and algorithms that can improve this can be extremely useful.\n2. Tools: Locality-Sensitive Hashing is a very versatile and useful tool, and introducing it to a new field, RL, can lead to important advances in the community. \n3. Broad applicability: the authors show that their analysis extends to 4 common variants of Least-Squares Value Iteration, showing promising signs towards the generality of this approach for RL algorithms that can be formulated as a maximum inner product search.\n\nWeaknesses:\n1. Novelty: the paper opens by claiming that “It is unknown to give a provable guarantee for the impact of LSH over the total number of iterations and per cost iteration of iterative-type algorithms”. This sentence, aside from needing to be reworded, is incorrect. Both Mongoose [Chen et al ICLR 2020] and “Linear Bandit Algorithms with Sublinear Time Complexity” [Yang et al, arxiv 21], which the authors cite, utilize LSH in exactly this manner. Additionally, the algorithm design, setting, and regret analysis seem extremely similar to Yang et. al, where the authors establish the connection between the theory of approximate maximum inner product search and the regret analysis of linear bandits (RL with one state). Additionally, the quantization analysis for handling adaptive queries in LSH looks extremely similar. While this paper does extend these results to the reinforcement learning setting where rewards are state dependent, this work needs to be placed properly in the context of the existing literature.\n2. Not self contained: the authors never define regret, nor critical details of LSVI. Many important definitions are reIegated to the appendix, further hindering the readability of this paper. Variables and terms should be defined prior to their usage, or at latest in the subsequent paragraph.\n3. Regret: the regret guarantees provided in Table 1 only hold with constant probability, and so this parameter doesn’t appear in the orderwise analysis. In order to fairly compare results, the dependence on this failure probability p should be elucidated, as it would appear as though the dependence of the proposed LSH-based schemes on p scales as $\\log^2 (1/p)$ as opposed to the $\\log(1/p)$ scaling of existing schemes.\n4. Practicality; the authors do not simulate (even on synthetic data) their proposed algorithms, so it is difficult to tell if these schemes yield improvements in practice, or if the parameters required for LSH are prohibitive. Algorithmically, the authors utilize big Oh notation in their definition of algorithm parameters, which is confusing and doesn’t yield itself to practical utility. For example, it is unclear how the Max-IP parameter of $c=1-\\Theta(\\sqrt{\\iota/n})$ and the number of “uniform samples” $n$ should be set to run the algorithm. Further discussion on how to choose parameters as well as numerical simulations showing the practicality of this algorithm would greatly strengthen the paper.\n5. Clarity: There are many typos and grammatical issues throughout the paper, which detract from the readability and overall message.\n- Two general comments:\n    - A significant fraction of the notation (e.g. $A,S,n$) appear to only be defined in the caption of Table 1, which is very difficult to parse.\n    - Recurring typo: “Let x denotes y” should be “Let x denote y”\n- Minor Errata:\n    - Consistency in formatting of “Locality-Sensitive Hashing”\n    - “This iterative natural causes the training of RL algorithms to be expensive” -> “This iterative nature…”\n    - Before section 2 “Furthermore, we identify… and proposes a series of techniques”. data structures and algorithms should be plural, and proposes->propose\n    - bichromatic Max-IP: set -> sets\n    - Def 3.1: proprieties -> properties\n    - Last paragraph of Sec 3.1: “reinforcement algorithm” -> “RL algorithms”, sublinear time cost -> “sublinear time cost per iteration”\n    - In the MDP framework, a policy is defined as *a* sequence\n    - In equation 1 for example, A_core is not yet defined, and it should be specified what least-squares problem $\\hat{w}_h$ solves. \n    - Section 4.2 first paragraph: duplicate “by”\n    - Section 5.1: equation typo, should be $|V_h^{*}(s) - \\hat{V}_h(s)| \\le \\epsilon$\n    - Tables 1,3-5: # is unnecessary in titles\n    - Notation table: K is defined incorrectly in table 2 as the “length of episode”. \n    - Alg 1: $\\Lambda_h$ and $\\Lambda$ appear to be used interchangeably\n    - Overloaded notation for $\\mathcal{B}$: used as both convex hull and ball\n    - duplicate “is” in sentences prior to Lemma D.4\n\nWhile this paper does tackle an important problem, LSH has in fact been previously used to speed up iterative algorithms. The paper requires considerable revisions to improve clarity, and reorganization and rewriting to ensure that it is self-contained. Theoretically, the dependence on the error probability p is neglected, and practically, the algorithm is not simulated to show improved empirical performance. Overall I think this paper is a weak reject (4), and am rounding my score up to 5 due to the enforced granularity.",
            "summary_of_the_review": "This paper tackles an important problem: reducing the computational complexity of RL methods. The authors show that their approach extends to several different variants of Least-Squares Value Iteration. However, LSH has in fact been previously used in this manner to speed up iterative algorithms. The paper requires considerable revisions to improve clarity, and reorganization and rewriting to ensure that it is self-contained. Theoretically, the dependence on the error probability p is neglected, and practically, the algorithm is not simulated to show improved empirical performance. Overall I think this paper is a weak reject (4), and am rounding my score up to 5 due to the enforced granularity.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this paper, the authors focus on applying the theoretical Locality-Sensitive Hashing (LSH) techniques to reduce the training time of the iterative-type Q-learning algorithm in Reinforcement Learning (RL). They introduce the first provable Least-Squares Value Iteration (LSVI) algorithm such that its runtime complexity is sublinear to the number of actions. To do so, they adopt the linear Markov Decision Process (linear MDP) and relax the value function estimation procedure in LSVI as a maximum inner product search (Max-IP) problem, so that they can use LSH type data structure to get sublinear time. They show that with appropriate approximation factor, the Sublinear LSVI algorithm has the same order regret as the original LSVI algorithm. Moreover, the authors also show that their technique with proper relaxations could be extended to three LSVI variants. Finally, they discuss how to apply LSH-based approximate Max-IP algorithms to Sublinear LSVI and its variants in practice.\n",
            "main_review": "Overall, the article is well-organized, well-thought, and of significance. The authors explained in detail the prior work, background, solutions, and techniques. \n\n1. The problem of value function iteration they studied is fundamental and vital in RL. It is unproductive to linear scan all the actions, especially considering that there exist many value iteration steps. In order to make the training of RL feasible on small GPU clusters, it is essential to design a sublinear time algorithm for acceleration. \n\n2. The authors did a great job bridging the gap between the iterative-type problems in RL and the theory of the LSH type data structure. They propose the first provable Sublinear LSVI and Sublinear LSVI-UCB algorithms with sublinear running time in the number of actions and the same regret as the original algorithms. This job might be insightful and inspire other researchers to develop more sublinear algorithms for other iterative-type problems in RL and deep learning. \n\n3. This work is technically sound. The authors provide rigorous theoretical analysis to demonstrate the sublinear time-bound and the same regret as the original algorithm. Many background knowledge, strict theorem statements, and proof details are provided in the appendix. \n\n4. The article is clearly written with a reasonable structure. The authors separated the theorem and corollary statements and the implementation details for the practical issues, summarizing the main results in a table while delaying the proofs to the appendix. This might be common but indeed helpful to understand the whole picture. ",
            "summary_of_the_review": "In summary, this paper is promising and well-written and tackles an important problem. I am happy to accept this paper. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studies linear RL (or RL with linear function approximation), with a particular focus on the computational issue, instead of the statistical / sample complexity issue. Classical algorithms have achieved near-optimal regret /sample complexity bounds for various linear RL settings, but few related work focuses on the computational issue in linear RL, except for the few papers that study RL with low switching cost. Least-Squares Value Iteration (LSVI) is an important value function-based method for RL with linear function approximation. LSVI-UCB is an important optimistic linear RL algorithm that incorporates the UCB-type exploration in linear RL. Local sensitivity hashing (LSH) is a classical algorithm that solves nearest neighbor search / MaxIP problems, and was previously well-studied by the theoretical computer science community.\n\nThis paper focuses on the time complexity of optimistic action selection in value iteration (which is, to select the best action according to estimated Q function). This paper creatively formulates the value iteration step in linear RL (both LSVI and LSVI-UCB) as an max matrix norm problem, and solves it via LSH. As such, this paper gives the first algorithm whose action-selection complexity scales sublinearly in the number of actions. This paper also extends the results to the low-switching-cost RL setting. The LSH-equipped algorithms provide in this paper could still achieve regret bounds similar to those achieved by the original algorithms. ",
            "main_review": "\n#### Strengths\n1. It is interesting to combine LSH with LSVI. This perhaps sets up a new research direction in linear RL.\n2. The paper's algorithms do not sacrifice the regret.\n\n#### Weakness\n1. It is strange to study the action-selection complexity in RL with function approximation.\n    * Basically, the improvement on action-selection becomes important only when the action set is discrete, or is continuous with weird shape. However, empirical RL settings (mujoco-py, gym with atari, etc.) usually have either small number of discrete actions, where action-selection complexity is not important, or the action set is well-shaped ($\\ell_2$ or $\\ell_\\infty$ ball, etc.), where best action can be found using better algorithms.  \n    * The action-selection complexity contributes a tiny part in the overall time complexity in practical RL. Usually, the most time-consuming part is related to how to compute the value function or its back-propagation. \n2. Using LSH only slightly improves the action-selection complexity compared to low-switching-cost RL techniques. The latter could make the action-selection complexity scale only with $O(\\log K)$, but the LSH-equipped algorithm requires $O(K)$ preprocessing time. I would emphasize that we must assume $K \\ge AH$ in this paper's setting, otherwise the regret bound would become useless, and arbitrary algorithm would achieve optimal regret. Therefore, the algorithm would have no improvement upon low-switching-cost RL, even for $H=O(1)$.\n1. The technical contribion of this paper seems incremental and this paper seems to be a straightforward combination of LSH and RL. \n\n#### Typos\n\n1. Page 6: the authors said the complexity is reduced to $O(HK d^2 A) \\cdot o(A)$. I think their should not be the $O(A)$ term?\n2. Page 44: at Eq. (40), there are an extra $)$ and an extra $|$.\n",
            "summary_of_the_review": "\nI went through the proof in Appendix D and did not find fatal error. The proof in Appendix C is similar and simpler, so I am confident of its correctness.\n\nGiven concerns in the significance and technical novelty in this paper, I am afraid that I would recommend reject.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}