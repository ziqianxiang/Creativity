{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "In this paper the authors propose D^2SDK (Dynamically Decoding Source Domain Knowledge), a method for domain generalization for computer vision tasks. In D^2SDK, one input first goes through a CNN backbone, then several CNN-based branches for domain-specific and domain-agnostic representations. These representations are later fed into a cross-domain transformer to create a final representation for classification. The cross-domain transformer supposedly captures the domain relations and thus better generalize to unseen domains. The proposed method achieves strong performance on PACS, Office-Home, and VLCS dataset.",
            "main_review": "Strength\n* A novel model architecture using both CNN and transformer for domain generalization problem.\n* Strong performance on three domain generalization datasets.\n\nWeakness\n* The paper lacks some essential information:\n  * Although domain generalization is a common problem setting, it is still necessary to explicitly state the problem setting (perhaps before Section 3).\n  * The authors list 10+ models for comparison; however the descriptions are very brief and I cannot identify the major difference between the proposed method and previous methods. To start with, which prior method is closest to the proposed method and how are they different?\n* I feel Sec 3.1 has significant overlap with the original transformer paper (Vaswani et al., 2017); this paragraph may be shortened. Also, the second paragraph in Sec 3.2 (which introduces recent advances of transformers in computer vision) is not directly relevant to this paper, and can also be shortened.\n* Lack of ablation study: Why is cross-domain transformer necessary for your purpose? How much does the performance change when this part is replaced with other architectures (e.g., some simple pairwise operations between the domain-agnostic query and the domain-specific representations)? Alternatively, what happens if there is only the transformer decoder? What happens if the domain-specific and domain-agnostic representations are concatenated and fed into an encoder-only transformer?\n\nClarification Questions\n* I'm confused with the motivation (\"we apply transformer to model domain relationships and decode useful information ...\" / \"photo domain is more similar to the art-painting domain than others in the PACS dataset\") -- since the target domain is unseen until inference time, how does the cross-domain transformer accurately model the domain relationships between a seen and an unseen domain? Does the cross-attention weights in the decoder reflect the preference for similar source domains?\n* The loss term in Eq. 4 is quite vague -- is $\\mathcal{L}_i^D$ (i.e., domain expert loss) used to classify whether the example belongs to one domain, or to classify whether $x$ belongs to category $y$?\n* As stated in Sec 3.2, the transformer decoder has a self-attention block in the beginning. Does that mean the block takes in a _1d domain-agnostic representation_ for self-attention? Am I understanding this correctly? Is this self-attention layer necessary?\n* Is the cross-domain transformer randomly initialized or are pre-trained weights used? How many parameters are there in the cross-domain transformer?",
            "summary_of_the_review": "Strength: Novel architecture with strong performance;\n\nWeakness: Motivation of using transformer is unclear and not well-defended. Details of the method and ablation studies are missing. A lot of clarification is needed, and the paper presentation needs much more work.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors proposed a method for unseen domain generalization by dynamically decoding source domain knowledge. Specifically, from a shared CNN representation, the authors build a domain-specific feature representation for each source domain and a domain-agnostic query representation. Then they apply a transformer encoder over the domain-specific feature representations to compute interactions between the source domains. Finally, a transformer decoder is applied (with the query representation as the input) to predict the final label. Experiment results on PACS, Office-Home and VLCS demonstrate the effectiveness of the proposed approach.",
            "main_review": "**Disclaimer**: I am not very familiar with DG in computer vision.\n\nStrength:\n+ Strong empirical performance on public benchmarks\n\nWeakness:\n+ The motivation of the approach is not very clear to me. Further analysis of the model will improve the quality of the paper.\n  + Why does reasoning across the source domains help to improve generalization on unseen domain? \n  + The domain experts are expected to compute domain-specific representations. How does it behave when the input is from an unseen domain? For example, in PCAS, for the photo-specific expert, how will it encode examples from art-painting and cartoon?\n  + What is learned from the query? If you just remove the query and do mean-pooling over the source domain representations, how does it perform?",
            "summary_of_the_review": "The authors proposed a method for domain generalization. Across three public benchmarks, the method shows strong performance over the baselines. On the negative side, the method is not very well-motivated. It is unclear to me why is the proposed approach able to extrapolate to unseen domains.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper addresses the domain generalization task of training on multiple domains, and testing on a new domain without training. They propose to learn domain specific models that share a backbone CNN model (they used ResNet as this shared model). They stack domain specific CNN layers on this shared backbone as the encoder, and further stack transformer encoder and decoder layers, before a final FC layer for classification loss.\n ",
            "main_review": "Strengths:\n- The proposed approach outperformed a number of recent work on 3 data sets, PACS, Office-Home and VLCS.\n\nWeaknesses:\n- The proposed approach is basically ensembling domain specific classifiers for domain adaptation, and the authors claimed novelty over previous such work (e.g., Zhou et al., 2020) for having a domain agnostic feature input. This seems like a minor deviation from previous work.\n\n- The proposed model stacked CNN and transformer layers on top of ResNet. This might have resulted in a substantially larger model size than the baselines it is comparing against. \n\n- The authors did not do any ablation to analyze how much of the improvements achieved is due to the stacking of transformer layers, and how much is due to domain generalization.",
            "summary_of_the_review": "I would not recommend to accept this paper due to\n- limited novelty over ensembling domain specific classifiers, and \n- insufficient ablation to analyze if the improvements over baselines are due to a bigger model, or due to domain generalization. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a new architecture called cross-domain Transformer for domain generalization. The architecture is mainly composed of two parts: a CNN and an encoder-decoder Transformer. The CNN has domain-specific branches for extracting domain-specific features, as well as a domain-agnostic branch. The main idea is to use the Transformer encoder to encode source domain-specific features into key and value features, which are then used to interact with domain-agnostic query features in the Transformer decoder. The results on three datasets show that the approach outperforms the baselines.",
            "main_review": "**Strengths**\n\nIn the context of domain generalization, the proposed architecture is new. The design is also sensible, i.e., using source domain features as the keys and values in Transformer to interact with queries from the target domain.\n\n**Weaknesses**\n\n- The paper is unclear in several places and lacks insights. (1) The keys and values are generated from source domain images during training, but it is unclear how they are obtained during inference. The paper mentions there is a memory, but does not explain how it is constructed. (2) It is unclear how images flow in the model. Fig.2 suggests images from different domains are processed separately by the domain-specific branches, but Eq.4 indicates that each image will go through the entire model. (3) There is no explanation nor evaluation for why positional encodings are necessary given that the input is a sequence of images rather than image patches as in a typical vision Transformer model. (4) Sec.3.2 suggests the three matrices, i.e., Q, K and V, are equal to each other, which is conceptually wrong. Maybe it’s a typo?\n\n- The paper has some overclaim issues. (1) The encoder and the decoder work together to facilitate interactions between source and target features, which should be viewed as one design and shouldn’t be listed as two separate contributions. (2) The selected baselines are weak and the results cannot justify the proposed approach. The SOTA performance on PACS is around 85% [a] while on OfficeHome it is around 65% [b].\n\n[a] Huang, Z., Wang, H., Xing, E. P., & Huang, D. (2020). Self-challenging improves cross-domain generalization. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part II 16 (pp. 124-140). Springer International Publishing.\n\n[b] Zhou, K., Yang, Y., Hospedales, T., & Xiang, T. (2020, August). Learning to generate novel domains for domain generalization. In European Conference on Computer Vision (pp. 561-578). Springer, Cham.",
            "summary_of_the_review": "Though the concept of using Transformers to tackle domain generalization is novel, the paper lacks many details and evaluations that are essential for understanding why the proposed approach brings improvements. Therefore, I vote for rejecting the paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}