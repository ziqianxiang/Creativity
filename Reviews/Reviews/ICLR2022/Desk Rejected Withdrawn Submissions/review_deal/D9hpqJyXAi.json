{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper aims to use out-of-distribution data to augment training data for long-tailed recognition. \n\n(1) From a Bayesian perspective, the authors observed that \n     the prediction of the Bayes classifier is unchanged after augmenting the training dataset with auxiliary out-of-distribution data when the labels of the instances are uniformly sampled from the in-distribution label space.\n\n(2) Based on the observation, one open-sampling strategy is proposed for the trade-off between re-balancing the class priors and keeping the non-toxicity of the added noisy labels.\n\n(3) Experiments on long-tailed CIFAR and CelebA-5 are conducted. some improvements are observed.",
            "main_review": "(1) The paper has a strong theoretical motivation from a Bayesian perspective to make better use of out-of-distribution data.\n\n(2) The proposed open-sampling strategy is simple and easy to implement.\n\n(3) The paper writes clearly and is easy to understand.\n\n(4) Though some improvements are obtained when compared with CB-Focal, CB-RW, LDAM, the baseline methods are old. \nRecently, many new methods [1,2,3] are proposed and the performance has already been significantly improved.\nThe authors should confirm the improvements on strong baselines.\n\nAlso, in related work, only re-sampling and re-weighting methods, which are published in a very early stage, are introduced. \nRecently many two-stage methods and contrastive-learning-based methods are developed for high performance.\n\n(5) In the field of long-tailed recognition, ImageNet-LT, iNaturalist2018 are usually adopted for comparison. \nExperimental results on these datasets are expected.\n\n(6) Some important ablations are missed. In addition to the proposed open sampling strategy, the paper also proposed to use a class-dependent weighting factor in training. Ablations for each component should be verified.\n\n[1] \"Decoupling Representation and Classifier for Long-Tailed Recognition\".  Kang et al.\n\n[2] \"Improving Calibration for Long-Tailed Recognition\". Zhong et al.\n\n[3] \"Parametric Contrastive Learning\". Cui et al.\n",
            "summary_of_the_review": "The theoretical motivation is interesting. However, the experiments are not sound enough due to the weak baselines.\nIf the authors can address the concerns mentioned above, I'm glad to raise my rating.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper tried to leverage OOD data to augment minority classes in class-imbalanced problem, which called \"Open-sampling\". For each OOD sample, the label is sampled from the predefined distribution which is complementary to the original priors. They theoretically prove that OOD data can help to rebalance by Bayesian perspective. ",
            "main_review": "1. First, I can not totally understand the analyses statement you proposed: \"Complementary Distribution is superior to the commonly used Class Balanced distribution since the uniformity of the former reduces the harmfulness of the open-set noisy labels\", so what is the uniformity of Complementary Distribution? Is it same with the proposed idea from Class-balanced loss [1]\n\n\n2. In my best knowledge, I agree the proposed claim: \"we are the first to explore the benefits of OOD instances in learning from long-tailed datasets\". I think to dig out imbalanced problem with Open dataset is a new and valuable branch in the community.\n\n\n3. From the proposed experiments, it's good to see leveraging from open dataset seems can be an orthogonal branch with SOTA methods, LDAM and Balanced softmax. However, not evaluated on large-scale dataset like ImageNet-LT would be somehow weak.\n\n\n4. It's a nice opening to discuss why leveraging open dataset as augmentation can further regularize model.\n\n\n\n\n\n[1] Class-balanced loss based on effective number of samples, CVPR 2019.\n",
            "summary_of_the_review": "Since this paper first leverages out-of-distribution data as minority augmentation, and gives simple bayesian theory to prove non-toxicity of open-set instances. I would give a positive score for recommondation.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper focuses on long-tailed recognition which aims to train on class-imbalanced data for high accuracy across the imbalanced classes. The paper is motivated to exploit out-of-distribution (OOD) data to augment the minority classes. It proposes Open-sampling to do so, which utilizes the OOD data with noisy labels to re-balance the class priors of the training set. The paper further generates class-dependent weights to provide stronger regularization on the minority classes than on the majority classes. The paper claims that Open-sampling not only re-balances the class prior, but also encourages the neural network to learn separable representations. The paper reported improved performance over existing data-rebalancing methods for long-tailed recognition.",
            "main_review": "The idea of exploiting OOD data for long-tailed recognition makes sense and interesting. The paper has several major weaknesses as detailed  below.\n\nThe authors use \"non-toxicity\" frequently in the paper. If it is a common term in the literature, can authors add a citation? If not, can authors formally define it when it appears at the first time (page-2)? \n\nThe authors interchangeably use \"out of distribution data\" and \"open-set data\". However, the two terms have special technical meanings in the literature. They often refer to detecting unknown or anomaly during testing. The paper has an obviously different focus which is to use out-of-domain data to help long-tailed recognition. Therefore, I suggest authors use \"out of domain\" data instead.\n\nThe section of related literature is unsatisfactory. Because the paper focuses on addressing long-tailed recognition (LTR), the related literature should introduce representative prior work for LTR. Currently, the paper exclusively focus on data resampling techniques for LTR. It is not clear how this special technique compares against others such as loss reweight, transfer learning, and expert models. Authors should show awareness of the literature.\n\nIn Section 3, the authors state that \"the class prior of the test distribution is usually class-balanced\". This contradicts to what stated earlier in the paper that \"in real-world applications like autonomous driving and medical diagnosis, large-scale datasets naturally exhibit imbalanced and long-tailed distributions\". It seems that the authors did not have a thoughtful understanding of the long-tailed problem.\n\nBecause the paper positions itself as exploiting OOD data for long-tailed recognition, did authors consider other ways to use them for LTR? For example, can authors self-supervised pretrain the network on OOD data and then supervised finetune the network on the long-tailed data? This should be the very first baseline to compare provided the mature self-supervised learning techniques.\n\nI cannot understanding Theorem 1 and I find it confusing when authors use \"Bayes classifier\" without explaining what the classifier is.\n\nIn Section 3.3, I don't follow \"dynamic labels\". Can authors clarify this concept? To clear confusion and improve readability, I suggest authors draw an algorithm box to clearly explain what the proposed method does.\n\nThe datasets used in this paper is rather small in scale. For example, CelebA-5 contains only five classes (202k * 1/20 = 10K images), even smaller than the CIFAR-10 dataset. It is not clear whether the conclusion still holds in realistic settings or reasonably large-scale training. Authors should consider other better datasets such as iNaturalist and ImageNet-LT.\n\nThe authors claim \"we are the first to explore the benefits of OOD instances in learning from long-tailed datasets.\" This is not ture. A recent paper [R1] extensively studies how to exploit OOD data for long-tailed recognition.\n\n[R1] A Realistic Evaluation of Semi-Supervised Learning for Fine-Grained Classification, CVPR, 2021",
            "summary_of_the_review": "I vote to reject this paper with the following reasons. \n\n(1) The readability of the paper is poor, for example it is unclear what the concept \"non-toxicity\" and \"dynamic labels\" mean. (2) The paper does not sufficiently review related work in long-tailed recognition, which is the focus of the paper. (3) The technical contribution is confusing and unclear; authors should draw an algorithm box to clearly demonstrate what the proposed method does. (4) The experiments are quite limited, e.g., it uses very small-scale datasets. (5) It misses important baselines such as self-supervised pretraining on OOD data. (6) Authors made incorrect claims such as \"we are the first to explore the benefits of OOD instances in learning from long-tailed datasets\" which is not true because paper [R1] has already studied this idea.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper shows that, for long-tailed datasets, out-of-distribution data could be leveraged to augment the minority classes. Based on the motivation, the paper proposes Open-Sampling, which utilizes open-set noisy labels to re-balance the class prior of the training dataset. For each open-set instance, the label is sampled from the pre-defined distribution that is complementary to original class priors. Extensive experiments show the proposed method outperforms existing long-tailed methods.",
            "main_review": "Strengths\n1. This paper is the first to explore the benefits of Out-of-distribution (OOD) in learning from long-tailed datasets. And the experiments show the effectiveness of OOD samples. Combining with OOD may shed some light on long-tailed area. \n2. The paper is well organized and easy to follow.\n\nWeaknesses\n1. The basic idea is to find a balance between uniform sampling and class balanced sampling. The idea is very common in long-tailed tasks [1]. Considering this, the novelty is limited. \n2. The paper proposes to use OOD samples with noisy labels. However, there are other ways to use OOD data. For example, like [2], using the unlabeled OOD samples to pretrain the network with self-supervised strategy. The paper should compare the proposed method with other related methods that using open-set data to improve the performance.  \n3. Some details are missed. The main innovation is to use OOD samples. However, the paper did not specify what data is used as OOD for CIFAR and CelebA-5. And how to select open-set samples for a specific dataset?\n4. The evaluation is not comprehensive. The recent state-of-the-art long-tailed works [3,4,5] are not discussed and compared. \n5.  ImageNet-LT and iNaturalist2018 datasets are popular datasets for long-tailed recognition. These datasets need to be evaluated to better verify the validity of the method.\n\n[1] Class-balanced loss based on effective number of samples, CVPR 2019.\n\n[2] Rethinking the Value of Labels for Improving Class-Imbalanced Learning, NeurIPS 2020.\n\n[3] LONG-TAILED RECOGNITION BY ROUTING DIVERSE DISTRIBUTION-AWARE EXPERTS, ICLR 2021.\n\n[4] Distribution Alignment: A Unified Framework for Long-tail Visual Recognition, CVPR 2021.\n\n[5] Parametric Contrastive Learning, ICCV 2021.\n\n",
            "summary_of_the_review": "More analysis about how to select and use OOD samples should be added; common datasets and recent state-of-the-arts should also be added. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}