{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper introduces a method for survival analysis by recasting the problem as a differential equation. Subsequently, the authors apply neural ordinary differential equations to learn the solution to this ODE using neural networks. \nThe method is extended by a local smoothness constraints so as to ensure that the solution does not vary too much. \n\nExperimental results show that the methods performs very well on common datasets. ",
            "main_review": "__Strengths:__\n- The paper is mostly well written and clearly explains the proposed methodology. \n- The approach to use neural ODEs to carry out survival analysis is a reasonable idea.  \n- Regularizing the solution to be smooth is a good idea in principle, since one would expect hazards not to vary strongly. In addition, this could make the ODE easier to solve with numerical techniques. \n- The experiment results are overall well carried out and show strong performance. \n\n\n__Weaknesses:__\n- The comparison to previous work is unfortunately not very detailed. As mentioned below, the ODE approach is just a special case of earlier work. \n- There is not comparison to this prior work. \n- The authors only report metrics for steps, t, instead of the common time averages. This makes it difficult to compare, for example, to the summary paper by Kvamme: _Time-to-Event Prediction with Neural Networks\nand Cox Regression_, 2019\n\n_Minor:_\n- Punctuation around equations is often wrong.\n\n__Originality:__\n\nThe authors state, that \n> \"Applying Neural ODEs to the ODE defined in equation 3 is simple yet effective. However, to our\n surprise, our work is the first to apply Neural ODEs in this way.\"\n\nI was surprised by this statement since multi-sate models are well known to generalize single state survival models. While the authors state a relationship to Groha et.al. 2020, they do not mention that the proposed method is a __special case__ of the multi-sate model. Indeed, this generalization is why researchers consider Markov jump processes. \nTo facilitate the discussion, I have added the mathematical details below, however, the results are well known. \n\nAnother related paper _also_ using neural ordinary differential equations for survival is:\n- Tang et.al.: SODEN: A Scalable Continuous-Time Survival Model through Ordinary Differential Equation Networks\n\n\n__Recommendation__:\n\nThis is vey difficult. The ODE model makes sense in principle and the results are promising. However, the main contribution (the proposed ODE framework) is unfortunately not new and has been investigated before. Since the main aspect of the methods exists already I cannot recommend acceptance at the moment. It would be interesting to see an ablation comparing to Groha et.al 2020 and seeing how the smoothness prior affects the outcome. Perhaps this idea can be extended upon. \n\n__Derivation of the 2-state setting:__\n\nLet us consider the ODE (3) that the authors suggest to solve:\n$$\n    -h(t|x) = \\frac{1}{S(t | x)} \\frac{d}{dt} S(t | x) \\Leftrightarrow \\frac{d}{dt} S(t | x)= -h(t|x)S(t | x),\n$$\nwhere $S(t | x) = 1 - F(t | x) = P(T > t | x)$, where $T$ is a random variable denoting the time of the outcome. \nGroha et. al. solve the Kolmogorov forward equations\n$$\n \\frac{d}{dt} P(0, t | x) =  P(0, t | x)Q(t),\n$$\nwhere $P(0, t | x)$ is the transition matrix, and $Q(t)$ the [transition rate/hazard rate matrix](https://en.wikipedia.org/wiki/Transition_rate_matrix).\nApplied to a survival model with states 0 (alive) and 1 (dead) this would mean learning the matrix of hazards\n$$  Q(t) = \n\\begin{bmatrix}\n     -h_{0 \\rightarrow 1}(t | x) & h_{0 \\rightarrow 1}(t | x) \\\\\\\\\n                                          0 &                                     0\n\\end{bmatrix}\n$$\nbecause $1$ is absorbing. In addition,\n$$\n  P(0, t | x) = \n\\begin{bmatrix}\n     p_{0 \\rightarrow 0}(t | x) & p_{0 \\rightarrow 1}(t | x) \\\\\\\\\n     p_{1 \\rightarrow 0}(t | x) & p_{1 \\rightarrow 1}(t | x)\n\\end{bmatrix} \n= \n\\begin{bmatrix}\n     1 - F(t | x) & F(t | x) \\\\\\\\\n                                          0 &                                   1\n\\end{bmatrix}.\n$$\nTherefore the Kolmogorov forward equations solve\n$$\n \\frac{d}{dt} P(0, t | x) =  P(0, t | x)Q(t) = \n\\begin{bmatrix}\n   -h_{0 \\rightarrow 1}(t | x)(1 - F(t | x) ) &  -h_{0 \\rightarrow 1}(t | x) F(t | x) + h_{0 \\rightarrow 1}(t | x) \\\\\\\\\n                                                          0  & 0\n\\end{bmatrix}\n= \n\\begin{bmatrix}\n   -h_{0 \\rightarrow 1}(t | x)(1 - F(t | x) ) &  h_{0 \\rightarrow 1}(t | x)( 1- F(t | x) \\\\\\\\\n                                                          0  & 0.\n\\end{bmatrix}\n$$\nConsequently, we get the two equations\n$$\n\\begin{aligned}\n  \\frac{d}{dt}( 1- F(t | x)) &=  -h_{0 \\rightarrow 1}(t | x)(1 - F(t | x) ) = -h_{0 \\rightarrow 1}(t | x)S(t | x)  \\\\\\\\\n  \\frac{d}{dt}( F(t | x))     &=  h_{0 \\rightarrow 1}(t | x)( 1- F(t | x) = h_{0 \\rightarrow 1}(t | x)S(t | x)\n\\end{aligned}.\n$$\nObviously, both equations amount to the same $d/dt S(t | x) = -h_{0 \\rightarrow 1}(t | x)S(t | x)$ which is exactly equation (3) that is targeted here. Thus, both approaches are identical for the standard survival case. \n",
            "summary_of_the_review": "Albeit its qualities, the proposed method is a known special case of prior work. The paper needs to focus towards what is new (the smoothness prior.) Hence, I recommend rejecting the paper. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a new survival analysis model that uses neural ODEs. Specifically, by using the well-known relationship that the hazard function is related to a derivative of the negative log survival function, one could use neural ODEs to model this relationship directly. However, such a model by itself does not prevent the hazard function from being extremely \"wiggly”. To encourage the hazard function to be smooth, the paper also proposes a local regularization strategy. In experimental results, the paper demonstrates that the proposed method generally outperforms various baselines.",
            "main_review": "Overall, I found the paper easy to understand and the proposed model to be quite elegant and simple. By main concerns are related to thoroughness of the paper, both in literature review and experiments, and also on calling the proposed approach \"assumption-free\".\n\nMy largest concern--not enough discussion of and no comparison to the most related baselines: To me, it seems that the most obvious/most related existing work are the ones by Groha et al (2020) that you already cite and also SODEN (Tang et al 2020). Note that the model by Groha et al supports the standard right-censored survival analysis setup as a special case (and in fact they use 2 of the datasets that you're also using). I think it would be helpful to explore this special case of their model (focused on the standard right-censored survival analysis setup, corresponding to a simple two-state system in their model) in more detail and explain precisely how it differs from what you’re proposing (update: after I had written my review, reviewer 9AD5 showed that actually what is proposed in the paper is identical to the special case of Groha et al that I had also pointed out, so my original question here has been addressed: the proposed method is doing the same thing as the special case of the Groha et al model). A comparison to SODEN is important as well. Basically I'm left wondering: which neural ODE survival analysis approach should one use? When should we favor the Groha et al approach (specialized to the two-state standard survival analysis case) vs SODEN?\n\nMy next concern--I disagree with calling your model \"assumption-free\": I think it would be helpful actually being precise about where there are assumptions. For instance, equation (3) in your paper is standard in survival analysis textbooks but it does have an assumption: it requires $\\log S(t|x)$ to be differentiable. Classical results on when nonparametric estimators of survival curves are consistent (e.g., Dabrowska 1989) rely on either differentiability or smoothness conditions of different survival-related functions (there's also a more recent paper by Chen 2019 on finite-sample guarantees of some nonparametric survival analysis methods that also uses smoothness assumptions that are not as strict as differentiability). Neural ODEs themselves also have assumptions (e.g., they model deterministic dynamics unlike SDEs) and limitations (e.g., Dupont et al (2019) show examples of functions neural ODE's cannot represent). From a theoretical standpoint, it's also unclear when precisely your method actually would work. Can we get away with non-iid data? Can you handle censoring models beyond standard random censoring in which survival and censoring times conditionally independent given covariates? What sort of time dynamics can your model actually handle? If your model truly is assumption-free, it can handle all these possible scenarios.\n\nIn your related work section, there are also two issues I see:\n- The statement \"However, the methods need expert knowledge for selecting Gaussian process prior and kernel functions\" is not true; these can be automatically learned in a neural net framework (Wu et al 2021 show this for survival analysis, but the framework for doing this is older and is called Deep Kernel Learning, e.g., Wilson et al 2015). Basically the kernel function is specified in terms of a deep neural net that is learned.\n- Given how you emphasize the \"assumption-free\" nature of your proposed method, I would suggest discussing in your related work section other survival estimators that are arguably just as assumption-free, namely nonparametric survival estimators such as random survival forests (which I know you already benchmark against but didn't discuss in Section 4), conditional Kaplan Meier estimators (Beran 1981), and deep kernel survival analysis (Chen 2020).\n\nLastly, as a minor writing quality comment, there are little English wording issues here and there. Please proofread.\n\nReferences:\n- Rudolf Beran. Nonparametric regression with randomly censored survival data. UC Berkeley tech report 1981.\n- George H. Chen. Nearest Neighbor and Kernel Survival Analysis: Nonasymptotic Error Bounds and Strong Consistency Rates. ICML 2019.\n- George H. Chen. Deep Kernel Survival Analysis and Subject-Specific Survival Time Prediction Intervals. MLHC 2020.\n- Dorota M. Dabrowska. Uniform consistency of the kernel conditional Kaplan-Meier estimate. The Annals of Statistics 1989.\n- Emilien Dupont, Arnaud Doucet, Yee Whye Teh. Augmented Neural ODEs. NeurIPS 2019.\n- Weijing Tang, Jiaqi Ma, Qiaozhu Mei, Ji Zhu. SODEN: A Scalable Continuous-Time Survival Model through Ordinary Differential Equation Networks. arXiv 2020.\n- Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, Eric P. Xing. Deep Kernel Learning. AISTATS 2016.\n- Zhiliang Wu, Yinchong Yang, Peter A. Fasching, Volker Tresp. Uncertainty-Aware Time-to-Event Prediction using Deep Kernel Accelerated Failure Time Models. MLHC 2021.",
            "summary_of_the_review": "Currently, this paper lacks a comparison to the most related baselines (Groha et al 2020, Tang et al 2020), has gaps in its literature review, and does not adequately justify why the proposed approach is \"assumption-free\". In my original review, I wanted to understand the difference between the proposed method and the method of Groha et al specialized to the standard survival analysis case. Reviewer 9AD5 pointed out that these two are in fact identical, so the proposed method is *not* new at all (aside from the smoothness prior, which is straightforward enough and constitutes a rather limited technical contribution). This sort of connection should have been pointed out by the authors of the paper.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper introduces an approach for time-to-event modelling which leverages neural ODEs to estimate the survival function without making restrictive assumptions. The proposed model is in addition, explicitly regularised by assuming a locally smooth survival function. The method is compared to a few related approaches on three publicly available tabular benchmarking datasets. Empirical results suggest superior predictive performance of the model, as well as the usefulness of the presented smoothness regulariser.",
            "main_review": "This paper addresses a pertinent problem and presents a technique that seems to be sufficiently differentiated from the majority of previous work on neural-network-based survival analysis. However, I have several major concerns regarding the choice of baseline methods, comparison with the related work, experimental setup, and the novelty.\n\nStrengths:\nThe proposed model (AFreeSurv) is reasonable and the smoothness prior regulariser seems to be a natural fit to survival analysis.\nEmpirical and qualitative results appear to support a need for a more flexible survival analysis technique, such as the one proposed by the authors.\nThe empirical comparison is conducted w.r.t. a range of evaluation metrics ($C^{td}$, AUC, Brier score) offering a well-rounded overview of performance.\n\nWeaknesses:\nThroughout the paper the authors claim that their model is assumption-free. It would be useful for the reader if the authors were more explicit about what assumptions are made by the related work and why is their model free of these assumptions? E.g. I believe this model still assumes noninformative censoring; and the smoothness regulariser naturally reflects an assumption of a smooth survival function.\nThe authors acknowledge that the Deep Adversarial Time-to-Event (DATE) model by Chapfuwa et al. (2018), as an adversarial approach, does not make strict assumptions on the survival distribution either. Yet, the authors do not compare to DATE in any of their experiments. This would have been a logical and competitive baseline. Another good option could be to compare with the survival cluster analysis (SCA) by Chapfuwa et al. (2020).\nThe reported performance of AFreeSurv+ (Table 2) in most datasets and w.r.t. most metrics is higher than that of the DSM. It is not clear, however, whether the difference in performance is significant? Are the reported numbers averaged across multiple runs or train-test splits? Could the authors provide standard deviations / confidence intervals for the results in Table 2?\nIt is not clear to me that the method is completely novel and the literature was surveyed sufficiently thoroughly. Are the authors aware of the work by Tang et al. (2020)? The SODEN model proposed by them also utilises ordinary differential equation networks to model the cumulative hazard function and is thus, highly similar to AFreeSurv. According to the webpage of one of the authors of the SODEN paper, \nit has been accepted by JMLR. Could the authors elaborate on the differences between AFreeSurv and SODEN, except for the local smoothness regularisation?\n\nMinor Points & Further Questions:\nIt is not clear to me what is the difference between the two panels in Figure 4? I guess, the lower panel is supposed to have a smoother w.r.t. colour than the upper one? This is not obvious at all, since the plot is overcrowded and the marker size is too large.\nWhat is the difference between Figure 5 in the Supplementary and Figure 3 in the main text? Were these obtained on different datasets? I am asking, since in Figure 5 DSM seems to produce survival curves not worse than AFreeSurv.\nSimilar to the concern above, the differences in Tables 3 & 4 are not considerable, could the authors comment on the significance and report standard deviations?\n\nReferences:\n\nChapfuwa, P., Tao, C., Li, C., Page, C., Goldstein, B., Duke, L.C. &amp; Henao, R.. (2018). Adversarial Time-to-Event Modeling. Proceedings of the 35th International Conference on Machine Learning, 80:735-744.\n\nChapfuwa, P., Li, C., Mehta, N., Carin, L., & Henao, R. (2020). Survival cluster analysis. In Proceedings of the ACM Conference on Health, Inference, and Learning (pp. 60-68).\n\nTang, W., Ma, J., Mei, Q., & Zhu, J. (2020). SODEN: A Scalable Continuous-Time Survival Model through Ordinary Differential Equation Networks. arXiv:2008.08637.\n",
            "summary_of_the_review": "While the proposed AFreeSurv model and the local smoothness regulariser are reasonable, and the experimental results seem to suggest their utility, I have major concerns regarding the novelty of this work and particularly, its similarity to another model not cited by the paper, the choice of baseline methods (lack of comparison with adversarial techniques), and the reproducibility of the results (standard deviations are not reported and performance differences do not appear to be considerable). Given all of these concerns, I recommend rejecting the paper, unless the authors address raised points by providing additional discussion, results or counterarguments. It is particularly important to elaborate on the novelty over the SODEN model by Tang et al. (2020).",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The repurposes neural ODEs and adversarial perturbations for continuous-time and locally smooth survival function predictions for right-censored datasets. Experimental results on three datasets show some performance gains per metrics concordance index (C-Index), the area under the curve (AUC), and the Brier score.",
            "main_review": "The paper is well written and easy to follow. Additionally, the application of Neural ODEs and adversarial perturbations to survival analysis is interesting.\n\n**Below are the key weaknesses:**\n- The technical contributions are limited to a combination of existing approaches (with minor modifications) applied to survival analysis. Moreover, applying Neural ODEs to the standard survival function ODE relationships (Eq. 3) has been proposed in [1]. Therefore, the paper should be positioned w.r.t [1] and the proposed approach benchmarked against [1].\n- While the reviewer appreciates the illustration in Figure 2, for clarity, the paper needs to provide an additional section focusing on how they model the dynamics (Eq. 3). For instance:\n   - What is the solver?  \n   - At test time, do they input $[0, T_{\\rm max}]$ (where $T_{\\rm max}$ is data-specific) as illustrated in Figure 3? \n   - What are the actual functions that map $(x, t) \\rightarrow h(t|x) \\rightarrow \\log S(t|x)$ ?\n-  Figure 3: \n   - The survival function predictions $S(t|x)$ should be a monotonically decreasing function. Some predictions from AFreeSurv and all predictions from DeepHit consistently violate this property? However, if the plots indicate $p(t|x)$ then alternative box plots would be more informative. \n    - Are the examples representative of the test set? How were they chosen?\n    - For clarity, the paper should provide a Y-axis label\n- Additionally, for continuous-time models metrics that evaluate temporal predictions summaries (*e.g.*, mean of $p(t|x)$) against the ground truth $t$, including the relative absolute error, would be informative\n- The empirical results from AFreeSurv seem comparable to baselines. Moreover, the paper needs to strengthen the argument for adversarial perturbation regularizer in AFreeSurv+ (beyond t-SNE plots). AFreeSurv+ introduces additional complexity for marginal performance gains. For instance,  are there empirical differences in the learned $\\log S(t|x)$ between AFreeSurv and AFreeSurv+?\n- The paper should provide additional details on how $\\frac{d \\log S(t|x)}{dx}$ (Eq. 8) is computed in practice?\n\n**Minor Issues**\n-  Should be $log S(t|x)$ instead of $S(t|x)$ between Eq. 4 and Eq. 5\n\n**Missing references**\n\n[1] Tang et al., \"SODEN: A Scalable Continuous-Time Survival Model through Ordinary Differential Equation Networks\", arXiv 2020",
            "summary_of_the_review": "While the proposed approach is interesting,  the technical novelty is limited. For instance, Neural ODEs for survival analysis have been proposed in [1]. Also, the argument for adversarial perturbation regularizer (also previously proposed in semi-supervised literature) needs further strengthening. As is, the additional complexity does not justify the marginal performance gains.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}