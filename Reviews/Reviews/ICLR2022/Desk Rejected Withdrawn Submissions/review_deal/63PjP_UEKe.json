{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper targets reducing the gap of domain features to obtain the generalized prediction even for the unseen target domains. For the task, the ensemble distillation method was proposed, which utilizes the multiple erroneous predictions from the multiple source domains. Instead of the conventional feature generalization method like adversarial learning and reducing the MMD, the proposed method utilizes the averaged prediction from the ensemble model, which is distilled into the model for the target domain. In addition to the ensemble-based distillation method, the de-stylization module was also proposed. By applying the de-stylization module, the diverse distribution of the features from the different domains can be standardized as a unified feature distribution. Based on the two major modules, the proposed algorithm shows the state-of-the-art performance in the PACS dataset, and its effectiveness was validated by several multi-source datasets. Furthermore, through the multi-domain experiments using re-ID datasets, the proposed algorithm shows its generality.",
            "main_review": "Strengths\n+ The proposed algorithm shows the state-of-the-art performance in every combination of domains in PACS datasets.\n+ The derivation for the theoretical interpretation was reasonable.\n\nWeaknesses & Questions\n- In the introduction, the authors said \"it is unclear whether the target data will be mapped to the aligned features, ...\" I agree that the proposed algorithm can overcome the high risk of overfitting issue since the proposed algorithm can utilize the ensemble model with multiple source domains. However, it is hard to understand that the proposed algorithm solves that the aligned feature clearly represents the target data yet. What would be the guessing effectiveness of the algorithm in the aspect of the validation for the alignment?\n- In the introduction and framework, the authors insisted that the prediction from the ensemble model is meaningful for the domain generalization since the model can learn the meaningful wrong prediction from multi-source domains. However, it is not certain what the \"meaningful wrong prediction\" means. As the authors point, the wrong prediction would be possible, but among the variety of wrong predictions, which information is \"meaningful\" for the domain generalization? Even though the meaningful wrong prediction is the key intuition of the proposed algorithm, its exact definition is not given in the paper.\n- The technical novelty looks very limited. Through many studies of machine learning, the ensemble model has been one of the most conventional tools to generalize the prediction and the features. Thus, the usage of ensemble prediction cannot be the new discovery for the research of domain generalization. The de-stylization module can be understood as a kind of standardization algorithm, which has been widely used to reduce the feature distribution in many tasks. As a result, the empirical analysis for the ensemble model and the de-stylization module work as just the re-validation of the well-known tools. I hope to listen to which insight we can acquire from the analysis and where the technical novelty can be found from the conventional tools.\n- The proposed algorithm showed the state-of-the-art performance just in CMNIST and PACS. Except for CMNIST that is not related to real-world applications, the algorithm shows the best performance only for the PACS dataset. What would be the reason why the proposed algorithm shows limited performance at the other datasets?\n- In the experiments of Re-ID, the proposed algorithm surprisingly improves the domain generalization for the datasets. I hope to know which component of the algorithm affects the generalization of the domains in the re-ID task. If possible, I hope to check that the component-wise ablation tests for the re-ID experiments to validate the effectiveness of each component.",
            "summary_of_the_review": "Even with the state-of-the-art performance for PACS dataset, it is hard to find new insight for the domain generalization since the ensemble model and the standardization have been widely used for the task already. In that aspect, it is hard to find the technical contribution and meaningful insights yet.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The proposed approach consists of two components, which are complementary to each other and together show strong performance against SOTA baselines on domain generalization and cross-dataset person re-identification. Specifically, the first component, called cross-domain ensemble distillation (XDED), is based on the idea of self-distillation, which trains the model to match the ensemble predictions (also made by the model itself) over images of the same class but from different source domains. The second component, called UniStyle, standardizes CNN feature maps to zero means and unit variances at multiple intermediate layers, with a goal to remove style bias.",
            "main_review": "**Strengths**\n\nFrom the technical point of view, the proposed self-distillation and style standardization via UniStyle bring new ideas to the domain generalization literature.\n\nWhat interests me more is UniStyle, which shows comparable performance with the existing MixStyle despite being designed with a very different purpose: MixStyle diversifies image styles while UniStyle aims for the opposite (to remove image styles). From this perspective, the paper provides new insights that could inspire future research into the use of CNN feature statistics for domain generalization.\n\nAs correctly identified in the paper, most existing studies have been focused on domain alignment. Therefore, new research with a different angle and perspective, and especially with strong empirical performance as presented in the paper, could be inspiring and beneficial to the field.\n\n**Weaknesses**\n\n- The coverage in the topic of knowledge distillation and ensemble methods in the second part of the related work section is inaccurate and not comprehensive enough. The idea of ensemble learning has been investigated for domain generalization in the literature, such as exemplar SVMs [a], ensemble of domain-specific neural networks [b] or BN layers [c], but the paper fails to acknowledge existing studies. In particular, the ensemble distillation method proposed in [b], which has been cited in the paper, is similar to the proposed XDED but discussions on their similarities and differences are missing.\n\n- The paper mentions in several places that the proposed self-distillation works by \"learning meaningful wrong predictions,\" which I find is inaccurate and might cause misperception. A well-known benefit of using knowledge distillation is the \"dark knowledge\" encoded in the soft probability distributions that contain meaningful relationships between classes. Fig.1 also suggests the predictions made on different images are all correct despite having different distributions and confidences. So the explanation of \"learning meaningful wrong predictions\" is misleading.\n\n- In Sec.3.3, the theorem proposed by Cha et al. (2021a) applies to the worst-case formulation, which is however not adopted in this paper. Cha et al. used the theorem to explain the benefit of finding a flat minimum, which is their method. I do not see any connection between the proposed approach here and that of Cha et al., and therefore, the interpretation seems inappropriate.\n\n- The results in Table 5, which aim to justify the importance of soft targets, are not convincing because UniStyle is not separated out from the evaluation. This part is supposed to only evaluate the self-distillation component.\n\n- Some important results and observations that help understand the approach, such as the ablation study on the two proposed components (Table 7), are supposed to be put in the main paper but instead they appear in the supplementary.\n\n**Questions**\n\nI'd like to hear from the authors regarding the following questions.\n\n1. In the distillation part, why not use the ensemble of the output probability distributions as the targets? Why ensemble the logits?\n\n2. The curve for \"Ours\" seems incomplete in Fig.7. Why?\n\n3. The ablation study in Table 7 only shows that UniStyle works and the two components are complementary, but doesn't show whether using XDED alone is helpful?\n\n4. The proposed approach achieves 86.4 on PACS, but when combined with JiGen, the performance drops to 84.9 (in Table 8). Why?\n\n5. Why is the theorem in Sec.3.3 related to the proposed approach?\n\n**Suggestions**\n\n- Revise the paper to address the weakness points mentioned above.\n\n- The title seems to only indicate the XDED component but not UniStyle. Maybe change the title to cover the whole ideas proposed in this work?\n\n- The paper misplaces the reference of MixStyle, which was proposed in [d] rather than [b].\n\n- The \"review of knowledge distillation\" part is unnecessary and could be removed to save space for some results in the supplementary. If the theorem in Sec.3.3 is irrelevant, it could also be removed to save space.\n\n[a] Xu, Z., Li, W., Niu, L., & Xu, D. (2014, September). Exploiting low-rank structure from latent domains for domain generalization. In European Conference on Computer Vision (pp. 628-643). Springer, Cham.\n\n[b] Zhou, K., Yang, Y., Qiao, Y., & Xiang, T. (2021). Domain adaptive ensemble learning. IEEE Transactions on Image Processing, 30, 8008-8018.\n\n[c] Seo, S., Suh, Y., Kim, D., Kim, G., Han, J., & Han, B. (2020). Learning to optimize domain specific normalization for domain generalization. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXII 16 (pp. 68-83). Springer International Publishing.\n\n[d] Zhou, K., Yang, Y., Qiao, Y., & Xiang, T. (2021). Domain generalization with mixstyle. In Proc. International Conference on Learning Representations.",
            "summary_of_the_review": "I am inclined to vote for accepting the paper given that the proposed ideas are novel and have been proved effective. However, the weaknesses mentioned above are also notable. I will reconsider and finalize the rating after the rebuttal.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper works on the domain generalization tasks. In order to overcome the overfitting to the source domains, the author proposed a self-distillation method to improve the robustness of the model to the unseen domains. The method was tested on multiple datasets varying from image classification to People Re-ID. The experimental results indicate the superiority of the proposed method compared to the SOTAs.",
            "main_review": "This paper proposed to solve the domain generalization problem from two aspects. First, the author tries to improve the robustness of the model to the unseen target domains by applying a cross domain ensemble distillation (XDED) across images with the same classes but from different domains. Second, a de-stylization method- UniStyle was designed to ease the domain discrepancy. I like the XDED, which successfully alleviates the overfitting problem to the source domains from the view of both theoretical analysis and experimental results. The main concerns I have about this paper are as follows.\n\n1. The XDED is not ablated very well. I notice there is only one ablation shown in the supplementary. In the main paper, it only shows XDED lowers the robust empirical loss but I have no idea whether XDED really overcomes the overfitting issue or not clearly. Maybe a test on source domains' test set is a potential option to justify the hypothesis. \n2. The proposed XDED can only be applied on the multi-source cases. I wonder whether the author can expand its working area to singe source domain generalization, since sometimes we lack domain IDs even though the source domain is a mixture of multiple sub-domains. Perhaps, the authors can try to use clustering techniques on the source domain and view each cluster as a sub-domain to implement XDED.\n3. I doubt the novelty of UniStyle. Acutally, I have seen Equation (9) since many years ago in style transfer papers. It is fine to leverage it to achieve some gains. But I can hardy regard it as a new method. Furthermore, if the \\mu_w and \\sigma_w are set to 0 and 1, isn't Equation (9) just downgraded to instance normalization? ",
            "summary_of_the_review": "For this paper, it has both interesting parts and some space for further improvement. It is a little hard for me to make a correct decision at this moment. So I will go with bordline accpet and make the final decision based on the author's reponse and other reviews.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}