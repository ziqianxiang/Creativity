{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes using Fourier features (FFs) as a preprocessing step for deep RL tasks. They investigate both the full set of FFs (which is exponential in the original dimension) as well as a “light” version which only contains a linear number of such features. Various properties such as robustness to hyperparameters, activation sparsity,  proportion of dead neurons, rank of the learned feature matrix and smoothness of the learned network are studied. The tasks considered are OpenAI gym tasks such as Cartpole, Acrobot, Lunar Lander, MountainCar and 3 Mujoco tasks. ",
            "main_review": "Strengths:\n- the proposed method is very simple\n- it seems robust, i.e. improves sensitivity to hyperparameters and does not ever do worse than the standard encoding.\n- Paper is well-written\n\nWeaknesses:\n- the method as it is discussed is only applicable to tasks whose states are continuous feature vectors. It is unclear how this method would work on images and it would help. \n- the method is evaluated on very simple tasks, and not that many of them. Cartpole, Acrobot, Mountaincar are very toy, and the 3 Mujoco tasks are among the simpler ones (Humanoid, which is considerably harder, is not included). \n- although the FFs do not appear worse than the identity encoding, the gains are limited. There little to no improvement on Acrobot, Cartpole, LunarLander and InvertedDoublePendulum. In MountainCar the gains are unclear due to large error bars. \n\nThe idea of using FFs as a preprocessing step is not new (as the authors point out), and has been used in classical RL. However, it can be worth revisiting classical methods in modern settings if they are supported by compelling empirical results. While the results in this paper are somewhat encouraging, I do not thing they are strong enough yet, and the paper feels more like a work in progress than a finished work. Section 3, which reports different measurements of the learned representations (such as the sparsity, dead neurons, smoothness) feels more exploratory and the takeaway for the reader is unclear. For example, it is not obvious which (if any) of the measurements in Table 1 influence performance. On Acrobot and Lunar Lander, the performance of the different methods is almost identical, but there is a significant difference in the instance sparsity and normalized overlap. This would suggest that these do not correlate with performance. The fact that more sparsity, less overlap and less dead neurons is better is taken as a given (which intuitively makes sense), but the results do not seem to indicate that “better” scores lead to better performance. It could be interesting to plot the performance vs. {sparsity, dead neurons, overlap} and see if there are any correlations to be seen, and these can also be tested for statistical signficance. The same holds true for the other metrics (rank and smoothness).\n\nIn Section 4/Figure 7, it’s hard to see which differences are significant or not due to the overlapping shaded regions indicating the error bars. \n\nHow do these methods compare in wallclock time? The FLFs are faster, but how much faster, and how do they compare to the identity encoding? Please include plots for this in the main paper somewhere.\n\nMy suggestions for improving the paper are the following:\n\n- To evaluate the proposed method on many more continuous control tasks and showing aggregated results using the RLiable library (https://arxiv.org/abs/2108.13264). This will make the plots much easier to read, and also give an idea how statistically significant the results are. I would suggest something like the DeepMind Control Suite which has many tasks available using the same interface. \n- Compute correlations between the different measures (sparsity, overlap etc) and performance, and see if this relationship is significant. Include these results in the paper only if it is. There needs to be a clearer takeaway from Section 3. \n\nMinor:\n\n-Results for Catcher-v1 are shown in Table 1 but not in the previous figures. Is this environment part of the evaluation?\n",
            "summary_of_the_review": "While the results are tentatively encouraging, this feels more like a work in progress than a finished work. Therefore, I suggest the authors improve the paper by extending the evaluation to more (and harder) control tasks and assessing aggregate improvements using something like the RLiable library. If these improvements end up being significant, I think this paper would make a strong submission to a future conference. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper empirically studies the benefits from using Fourier features to preprocess inputs of Q value network in deep RL. Compared to previous RL methods based on Fourier features, this paper investigates Fourier features for RL using neural networks as the value function approximator. To remedy the exponential growth of the number of basis in traditional Fourier features, this paper proposed light Fourier features (LFF) that significantly reduces the number of basis with negligible performance loss. This paper shows that LFF and standard FF improve sample efficiency and robustness compared to DQN/PPO in several discrete or continuous control tasks. This paper monitors the training process and shows Fourier features can bring several desired neural net properties including better smoothness, less interference, better sparsity and increased expressivity.",
            "main_review": "The strengths of the paper: \n       + The writing of the paper is clear and it’s easy to extract main ideas.\n        + This paper empirically explains the advantages of Fourier features by investigating several desired neural net criteria. Such efforts are novel since currently most DRL papers focus on algorithmic aspects.\n\t+ This paper evaluates Fourier features across a wide variety of continuous and discrete control tasks.\n\nThe weaknesses of the paper:\n       - Since standard FF is used in most experiments in this paper, it seems that the exponential growth of basis in standard FF is not a severe issue for tasks considered in the paper. As a result, the motivation and necessity of proposing LFF needs more elaboration. \n        - Although this paper shows Fourier features bring neural net training benefits, the reason why these benefits convert to better sample efficiency remain missing. Considering how these benefits improve Q value function estimation accuracy is a possible way to bridge such gaps.\n       - Most continuous control experiments are performed on simple and low-dimensional tasks, such as cartpole or mountain car. To fully demonstrate the scalability of LFF, it’s important to show LFF can also help to solve more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids.\n       - The PPO algorithm considered in this paper is a policy optimization algorithm, not originally designed to work together with value-based DQN methods. My suggestion is to add similar discussions for some actor-critic like algorithms, such as soft actor critic (SAC), A3C, etc. For such algorithms, improvement of DQN training efficiency should bring more performance gains.\n      - It's better to add a related work section to systematically review previous feature-based methods in DRL or classic RL scenarios.",
            "summary_of_the_review": "My suggestions are summarized as follows:\n(1) The motivation and necessity of adopting LFF rather than standard Fourier features needs more elaboration.\n(2) How those observed benefits of Fourier features connect to performance-level criteria, such as value function estimation accuracy?\n(3) Are Fourier features scalable and practical in more challenging continuous control tasks with higher input dimensionality?\n(4) I suggest to also investigate some actor-critic like algorithms besides PPO.\n(5) I suggest to add a related work section for reviewing previous feature-based methods in RL.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper performs a systematic and extensive empirical investigation into the impact of fourier features (FF) as a preprocessing step to the DQN and PPO algorithms. This investigation is performed on a handful of small discrete action control domains as well as a few continuous action domains. The paper provides a heuristic for subselecting the frequencies used by FF to reduce the exponential-growth in state dimension to a linear growth, and shows empirically that this heuristic captures much of the performance gain of FF. Finally, the paper empirically concludes that FF induce several interesting properties of the learned representation, including sparsity, expressiveness, and lower interference.",
            "main_review": "I am recommending to reject this paper because (W1) many of the observed properties---especially the performance gains---are most likely due to the increase in learnable parameters from the state-transformation, (W2) many of the observational discoveries are incremental from the prior literature, and (W3) there was a critical missing baseline.\n\nHowever, the paper has an exceptional literature review and captures many of the relevant works. The observational/experimental study of a small and self-contained modification to popular algorithms is refreshing, and is a highly scientific approach to algorithm development. And many of the generated hypotheses are interesting and worth further randomized-controlled experimental investigation.\n\n---\n\n**Details for (W1):**\n\nThe extensive hyperparameter sweep used to tune the three compared algorithms included several choices of hidden layer size. However, for *every* domain the largest hidden layer size was selected. Because the fourier feature transform is exponential in the state dimension, this implies that the FF-NN algorithm received exponentially more learnable parameters than its competitors. Similarly, the proposed FLF-NN received $m+1$ times as many inputs as the standard NN with $m$ being a tunable parameter selected with extensive hyperparameter search. The observational studies investigate many properties of the learned representation, however it is not possible to isolate whether these observed properties are due to the FF transform itself, or if they are due simply to representations of differing sizes. In order for these findings to be impactful (e.g. to drive further algorithmic development), it is critical that this difference is controlled for. \n\n**Details for (W2):**\n\nThere is significant prior work in understanding both that the FF transform allows learning representations which better capture high-frequency information (Rahimi and Recht, 2007) and that fixed-basis feature transformations induce interesting properties of the representation learned from NNs in RL (Ghiassian et al. 2020, Pan et al. 2020). I acknowledge that this paper fills an open gap --- FF transform + RL --- but given the observational nature of the study, the current paper does not provide significant clarity as to the contribution of the FF transform.\n\nIn order to fill this gap, I would like to see some improvements of the empirical analysis (or perhaps its presentation). Currently, the empirical setup consists of finding 3 algorithms (NN, FF-NN, and FLF-NN) and observing properties of these algorithms for 30 random seeds. After these measurements are observed, _then_ the paper provides some hypotheses about what occurred. This is known as HARKing (hypothesis after results known). As a form of preliminary analysis, these observational studies are excellent tools, but in order to draw robust conclusions requires first forming a hypothesis (preferably informed by some theory [not necessarily mathematical theory]), then performing a careful randomized-controlled trial to validate that hypothesis. A simple fix would be providing some justification for _why_ each property was measured, along with some justification for the expected outcome. A more complete fix would be relegating the observational study to the appendix and forming verifiable hypotheses from the outcomes of that initial study; then verifying these hypotheses experimentally with a new set of experiments.\n\n**Details for (W3):**\n\nThere are rather 2 baselines that I would like to see, but only one of those I would consider critical. Currently, it is unclear what is the motivation to use both a fixed-basis representation _and_ a neural network. Using a linear function approximator directly on top of the FF transformed states is a necessary baseline. As motivation, consider the proposed FLF transformation. This transformation reduces the number of features by ignoring non-orthogonal frequency directions. That is, the FLF transformation can be considered a minimal basis in the m-order frequency spectrum while the FF transformation considers all pairwise combinations of those basis vectors. A single hidden-layer neural network effectively can learn pairwise combinations of inputs, so it is not surprising then that FLF and FF perform similarly when fed to a neural network. The FF transformation is feeding many colinear features, requiring the hidden layer to do very little work, while the FLF transformation requires the hidden layer to compute the necessary pairwise interactions. This relationship is supported by the sparsity measurements reported in the paper as well. Consider the case that the hidden layer is simply acting as a filter to remove spurious colinear relationships for FF. If this is occurring, then FF+linear function approximation should perform equally or better than FF+NN. If so, then why using FF+NN?\n\nOne possible reason to use FF+NN is that we would like hierarchical abstractions provided by _deep_ NNs. If this is a motivation, though, it should be the use-case studied in the paper. As such, I would like to additionally see results using multiple hidden layer neural networks in the empirical analysis.\n\nAs an aside, I believe it should be possible to tune the $c$ direction vector using gradient-based approaches (i.e. this could be a learned parameter). I wonder if this would be a more effective approach to obtain linear-in-state-dimension growth as opposed to creating a large exponentially-sized lattice covering the entire space.",
            "summary_of_the_review": "(Repeated from the above \"main review\" block)\n\nI am recommending to reject this paper because (W1) many of the observed properties---especially the performance gains---are most likely due to the increase in learnable parameters from the state-transformation, (W2) many of the observational discoveries are incremental from the prior literature, and (W3) there was a critical missing baseline.\n\nHowever, the paper has an exceptional literature review and captures many of the relevant works. The observational/experimental study of a small and self-contained modification to popular algorithms is refreshing, and is a highly scientific approach to algorithm development. And many of the generated hypotheses are interesting and worth further randomized-controlled experimental investigation.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposed to use Fourier features (FF) as a preprocessing input before feeding into the neural networks in deep reinforcement learning. The authors showed empirically that combining FFs with deep RL can improve performance, when compared to the baseline DQN and PPO algorithms. They further tried to explain why it works, from the perspective of sparsity, expressiveness, and smoothness. Finally, a comparison with other types of preprocessed inputs is provided to show the better performance of the proposed method.\n",
            "main_review": "Strength:\n1. This paper shows empirically that combining Fourier features with deep RL can be beneficial, on certain tasks with raw states as input.\n\n2. The authors have conducted extensive experiments to explain the benefits Fourier features may bring, although arguably it's difficult to rigorously justify.\n\nWeakness:\n1. This paper is a bit over empirical, as most of the paper (from Page 3) just tries to explain from experiments on possible reasons. It's true that using Fourier features as a preprocessing input can improve scores for deep RL agents, based on the experiments. However, the explanation is not well connected with key metrics in RL. For example, does increasing sparsity lead to more accurate Q-value estimates in DQNs?  \n\n2. Another issue is related to the extension of the current work to real, high dimensional problems. Even though the authors claimed that one drawback from previous work \"is that they do not scale to high-dimensional inputs\", I was not able to locate any experiments on problems with images as raw input, e.g., Atari games. From the definition in Equation (1), it's unclear to me how to extend Fourier features in this case, as \"n\" can be quite large here.\n\n3. Some claims and conclusions seem to be problematic in this paper. A few examples are as follows.\n\n    (1) I am not sure why the total number of features in order-m FLF equals n(m + 1). When all elements in c^i are zeros, there is one features. When there is only one of the elements of c^i is zero, there should be n \\times m features.\n\n    (2) The authors claimed in Page 3 that for \"In all tasks, FLF significantly improve upon the baseline (DQN/PPO), in both cumulative rewards and sample efficiency\". This is not true for Acrobat as all methods seem to converge to the same point.\n\n    (3) I doubt that the experiments only on MountainCar and CartPole in Figure 7 are sufficient to draw the conclusion that preprocessing using Fourier features is superior, when compared with other types of input.\n",
            "summary_of_the_review": "This paper shows by experiments that using Fourier features as a preprocessing input can be beneficial. However, the proposed approach is over empirical and it remains unclear how to extend the method to high dimensional problems, even from a practical perspective. Furthermore, some claims and conclusion lack rigor and more work is necessary to further improve the current version. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}