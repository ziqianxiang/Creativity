{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes to train deep generative models via MAP estimation on both the parameters of the decoder and the latent variables themselves in contrast to amortized variational inference as it is done in VAEs. The authors state the motivation behind this work as the problem caused by the approximation gap as well as the additional complexity of adding an encoder. The authors then discuss ways to incorporate an encoder to the proposed model for the purpose of initializing the latent code for later optimization. The authors then perform some experiments on CIFAR-10, as well as models with a GMM prior, where they compare against standard VAEs.",
            "main_review": "**General Comment**\n\nI am 100% behind the idea of trying to address the problems caused by the variational inference (e.g. approximation gap) and/or researching alternative methods to learn a generative model $p_\\theta(x,z)$. However, while the proposed approach is certainly reasonable to consider, I am not sure if it is the right way to approach this problem as it seems like it is causing its own set of problems with higher complexity and not much evidence of gains in terms of results. First, I think the authors should provide a better discussion regarding the fact that by not modelling the posterior, we are losing the notion of uncertainty in the model which is part of the reason people consider DGMs to begin with. I think some of the other weaknesses of the paper are (1) Lack of novelty and significance (2) The additional complexity (in terms of run-time etc.) of DGD and the lack of discussion on this topic (3) Lack of strong empirical evidence. I discuss these points further below. Overall, while I think there is room of exploration on this topic, I think the current draft is not ready for an ICLR submission. \n\n\n**Clarity** \n\nThe paper is reasonably well-written for the most part I would say in terms of what the proposed model is.  Also I appreciate the authors for trying to avoid using bold language when describing the model/contributions. The one part I think was not very clear was Section 2.2. I failed to understand the latter approach (estimating the posterior). How does this become different from a VAE in that case? Could you state the equations for learning the encoder in the section?  \n\nI think the authors are miss-using the term 'amortization gap’. Amortization gap is the gap between $KL[q||p]$ with $q$ being amortized and non-amortized (standard VI). Check [3] again. \n\nAnother point that I think requires clarification is the motivation stated in the introduction. The authors state that VAEs are problematic because of the variational approximation error. While it is clear that high approximating error means a poor approximation of the posterior, however it is less clear why this is a problem in terms of learning the generative model. I am not entirely sure if this is what the authors are trying to say, but it is a valid argument I believe. See [4] for mode details. \n\nAlso please consider adding a background Section.   \n\n**Novelty & Significance**\n\nThe proposed approach is indeed very simple and trivial to implement (which I see as an advantage). However I would say it is way too close to both [1,2]. As far as I can see, [2] already does this in a fully deterministic way and [1] also does in a probabilistic way with the difference being that they use SGLD instead of GD. While I appreciate the authors citing both papers sufficiently, I’m afraid the edit distance of DGD to each of these works is very small.\n\n**Complexity**\n\nOne of the most important things that I think was missed in the paper was regarding runtime complexity and computational cost of training. The authors state the lack of needing a separate inference network as in VAEs to optimize as an advantage of DGD. However, they fail to mention we have added $N \\times d$ new parameters to be optimized. While the gradients w.r.t $z$ can be computed from the gradients w.r.t $\\theta$, it still requires a lot more computation and also it is not clear to me at all how much this would matter in modern deep learning libraries. Furthermore, unlike VAEs, we now have to run gradient descent at test time for every example.\n\n**Minor Comments**\n\n- It seems like the paper is trying to solve two problems at once: (1) Addressing the problems caused by optimizing the ELBO (2) Having more flexible inductive biases such as GMM included in the prior. I would maybe drop the discussion on (2), as it is not so relevant and also there are *many* VAEs with structured priors in the literature. \n- In the Introduction, contrary to what the authors state I would argue, VAEs with a GMM inductive bias have been proposed with inference just requiring a forward pass. See [5,6]\n- In the Introduction, the authors state “Thirdly, the model estimation is more complicated than that of regular neural networks, requiring the “reparametrization trick” and choice of parameters are often found to be difficult.”. Could the authors elaborate on this sentence? In what sense are they more complicated? I’m not sure the reparametrization trick, which is a very simple and common technique in inference literature, counts as complicated. Do the authors have something else in mind? Also what do the authors mean by “the choice of parameters are often found to be difficult”? \n- Could the authors elaborate on why this is called ‘explaining away inference’? There are no variables with shared children here so what is being ‘explained away’ here? \n- You are using a lowercase p in eq.3 in $p(\\theta)$.\n\n\n**References**\n\n[1] Tian Han, Yang Lu, Song-Chun Zhu, and Ying Nian Wu. Alternating back-propagation for generator network. In Satinder P. Singh and Shaul Markovitch (eds.), Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, February 4-9, 2017, San Francisco, California, USA, pp. 1976–1984. AAAI Press, 2017. URL http://aaai.org/ocs/index.php/AAAI/ AAAI17/paper/view/14784.\n\n[2] Schuster, Viktoria, and Anders Krogh. \"A manifold learning perspective on representation learning: Learning decoder and representations without an encoder.\" Entropy 23.11 (2021): 1403.\n\n[3] Cremer, Chris, Xuechen Li, and David Duvenaud. \"Inference suboptimality in variational autoencoders.\" International Conference on Machine Learning. PMLR, 2018.\n\n[4] Shekhovtsov, Alexander, Dmitrij Schlesinger, and Boris Flach. \"VAE Approximation Error: ELBO and Conditional Independence.\" arXiv preprint arXiv:2102.09310 (2021).\n\n[5] Jiang, Zhuxi, et al. \"Variational deep embedding: An unsupervised and generative approach to clustering.\" arXiv preprint arXiv:1611.05148 (2016).\n\n[6] Tomczak, Jakub, and Max Welling. \"VAE with a VampPrior.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2018.\n",
            "summary_of_the_review": "- Lack of discussion about the trade-off between MAP and modelling the full posterior\n- Novelty and Significance; The work is very close to [1,2]\n- Lack of discussion on the computational complexity of adding $N \\times d$ parameters (dimension of $Z$) for optimization.  \n- Lack of strong evidence of whether DGD helps. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethical concerns",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a VAE variant, where the encoder is removed and the latent codes are learned as non-parametric parameters for each example, along with a regular decoder. It is argued that this approach is simpler than standard VAE formulation and achieves better reconstruction and image generation quality. ",
            "main_review": "Pros:\n1. The proposed technique is technically correct and simple. The sample quality on MNIST is reasonably good. \n\nCons:\n1. The novelty is very limited. As a matter of fact, similar techniques have been explored in the literature, eg in [1, 2]. Although there are minor differences, the nature combing a NN based decoder with non-parametric representations is a well known technique. \n2. The empirical evaluations are also pretty weak and unconvincing. For example, although the proposed method outperforms VAE and beta-VAE wrt FID on CIFAR10, all the results are considerably lower than modern VAE models, eg, NVAE [3]. \n\n\nReferences\n[1] Efficient Learning of Sparse Representations, Ranzato et al. \n[2] DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation, Park et al. \n[3] NVAE: A Deep Hierarchical Variational Autoencoder, Vahdat et al.",
            "summary_of_the_review": "Overall, I think this paper does not meet the bar for publication. The authors are encouraged to work on improving the novelty and empirical results. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work proposes Deep Generative Decoder (DGD) a generative model without an encoder and where the latent representations of each datapoint are obtained with maximum-a-posteriori inference (MAP) instead of, e.g., variational inference in the case of variational auto encoders (VAEs). This essentially leads to seeking point estimates for the latent representations of each datapoint, which the authors obtain via back propagation on a randomly initialized per-datapoint latent variable. The authors argue for the simplicity and ease of use of this approach and demonstrate on several tasks reasonable performance compared to both vanilla VAEs and $\\beta$-VAEs.",
            "main_review": "Overall, this work proposes a simple optimization procedure for latent variable generative models, where the latent variable is being optimised over rather than integrated over. This subsequently allows for both a simpler approach and less hassle in the optimization procedure of the decoder parameters. \n\nHaving said that, similar ideas have been proposed before, e.g., the reference Bojanowski et. al., 2018 from this submission and a more recent one [1]. While [1] does still have an encoder, removing it is trivial and, furthermore, the authors there were able to get much better generation performance. Therefore I believe that the extra novelty of this work is minimal.\n\nIn addition, I believe that the authors are missing critical baselines in their evaluation, i.e., a VAE without an encoder but rather a vector of means and variances to be optimised directly according to the ELBO. Such a procedure doesn’t suffer from the amortisation gap that the authors mention. It also allows for a “fairer” comparison, as essentially in DGD the latent variable of the test point is “optimized” for test-reconstruction (due to not having an encoder) thus it is expected to lead to lower reconstruction errors. Did the authors properly fine-tune the initial distribution given by the VAE encoder to ensure that a similar procedure is performed by their baselines as well?\n\nAs for other comments:\n- The authors discuss about adding an encoder in the main text, however no experiments are being shown with a procedure. Besides that, the authors propose to train the encoder in a peculiar way that involves sampling the model itself; such a procedure will not work well, especially when the model distribution $p(x|\\theta) = \\int p(z)p(x|z, \\theta)dz$ is not representative of the true data distribution $\\tilde{p}(x)$. \n- I did not entirely follow how the authors calculate the scores for Figure 1.D.b as it was unclear from the text; could they perhaps formally write it out?\n- The authors argue about balancing the terms of VAEs but they also include $\\beta$-VAE in their results; is the VAE in the results one that has no balancing of the two losses (i.e., equal contribution of the reconstruction / KL)? $\\beta$-VAEs already change the balance of the reconstruction / KL objectives by tuning $\\beta$.\n\n[1] From Variational to Deterministic Auto-encoders, Ghosh et al., 2019\n",
            "summary_of_the_review": "This is an incremental work with very small novelty given prior art. Furthermore, the experimental sections needs quite a bit of work with more baselines and fairer comparisons against existing ones. These issues lead me towards recommending rejection. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper proposes a latent optimisation method, Deep Generative Decoder (DGD), where latent representations are learned directly by gradient descent together with the weights of a decoder. Differently from previous approaches in this area, the authors introduce a parametric distribution over the latent vectors, which allows for the inclusion of inductive biases over the structure of the latent space in a Bayesian fashion. The model is trained by maximising the joint probability over the inputs, latent vectors and distribution parameters, which amounts to a straightforward MAP inference procedure. Albeit not achieving state-of-the-art results, DGD outperforms VAEs and $\\beta$-VAEs while offering easier and more stable optimisation.",
            "main_review": "### Strengths\n- The proposed method is simple and principled, offering flexibility on how to define the distribution over the latent space. This is important if one wants to introduce inductive biases in the learning process.\n- DGDs are also shown to be easier to optimise than Vanilla VAEs and $\\beta$-VAEs, while improving reconstruction and sample quality.\n- The paper is well written and easy to read. The authors are also very upfront about the limitations of their methods, which is quite refreshing.\n\n### Weaknesses\n- The main contribution of the paper is the introduction of a parametric distribution over the latent space in a latent optimisation framework. This is an interesting and, to the extent of my knowledge, new contribution, but one could argue it is a bit incremental. Moreover, one can already define complex priors (as done in section 4 of the paper), over the latent space of a regular VAE as well. \n- While the comparisons against VAE and $\\beta$-VAE are quite illustrative, I think the paper misses a comparison to other latent optimisation methods, like [1, 2]. In particular, it would be useful to evaluate how the parametric distribution over the latent space affects the results.\n\n### Questions\n- In the experiments, how are the reconstructions computed? Do you implement an encoder in any of the experiments, or the latent vectors are always found via gradient descent (with the rest of the parameters fixed)?\n- Why does Vanilla VAEs have smaller latent dimensions than $\\beta$-VAEs and DGDs in the experiments?\n\n[1] Bojanowski, Piotr, et al. \"Optimizing the Latent Space of Generative Networks.\" International Conference on Machine Learning. PMLR, 2018.\n\n[2] Han, Tian, et al. \"Alternating back-propagation for generator network.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 31. No. 1. 2017.",
            "summary_of_the_review": "This is a nicely executed paper introducing a new method for latent optimisation in generative models. In particular, the parametric distribution over the latent space is a relevant addition, facilitating the integration of inductive biases or prior knowledge about the data. I believe this is a relatively small but very valid contribution to the literature that inches us closer to more robust and user-friendly generative model.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}