{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "Recent advances of deep generative models opened up a new horizon for de novo drug discovery. However, a well-known problem of existing works on molecule generation is that the generated molecules highly resemble those in the training set. Models that do not require training molecules such as RL-based models circumvent this problem, but they lack information about existing molecules. The authors propose Molecular Out-of-distribution Generation (MOG), a novel framework that explicitly generates OOD molecules with respect to given molecules by combining two aspects of energy-based models. The proposed MOG is capable of generating high-quality OOD molecules in such a manner that they can be easily differentiated from the given samples. Furthermore, unlike most existing methods, MOG can generate OOD samples at any desired energy bound. They illustrate the effectiveness of MOG through a structure-based drug design scenario and a molecular generation benchmark experiment.",
            "main_review": " Strengths: \nMOG overcomes the limitation of existing methods where generated molecules resemble those in the training set. It can generate OOD samples at any desired energy, which is not possible for most current generative models that require training molecules. Furthermore, it is more versatile than most previous generative models by generating either latent representations or specific data properties.\n\nWeaknesses: The main weakness of MOG is the function utilized for optimization. The authors state that docking is a proxy for wet-lab affinity prediction. This unfortunately is an invalid assumption. While docking may be better than other affinity predictions, it has many drawbacks including the additive nature of the score. It is therefore a suggestion that the authors use a metric that normalizes the score by the molecular weight of the molecules generated.",
            "summary_of_the_review": "In this work, the authors present a novel framework called Molecular Out-of-distribution Generation (MOG) that explicitly generates OOD molecules with respect to given molecules by combining two aspects of energy-based models. In the proposed method, an objective function that combines an entropy term and a deep generator model is optimized so as to maximize the diversity of generated samples while satisfying certain constraints on molecule similarity. The objective function encodes how well each generated sample is represented by the learned model, where the entropy term describes how diverse are samples. MOG is optimized by a docking score, however, the author fail to disclose issues related to docking score correlation with experimentally defined affinity measurements. The introduction and methods should be updated to disclose this drawback.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Based on energy-based models, this work proposes to utilize OOD generation in deep drug discovery to resolve the problem of poor exploration in existing molecule generation methods.",
            "main_review": "## Strength:\nThe introduced energy pivot seems to encourage OOD distribution. \n\n## Weakness:\n1. In Eq. 11, what is $P_\\phi$? How is it constructed? And how to choose the energy-pivots since the energy values are usually unbounded?\n\n2. I think the model is supposed to not only generate in-distribution samples but also generalize to out-of-distributions. But in Figure 3, it only shows out-of-distribution samples with energy values close to the pivot that can be generated. Is it expected?\n\n3. I am also concerned about the theoretical guarantee since Eq. 11 modifies the LD process. That means the model is not trained to learn the ground truth distribution anymore but leans towards some `average` or balance point between the expected distribution and the shifted one. As a result, the model definitely can be trained to generate something that doesn't resemble the ground truth distribution. It will be helpful to know how the generated distribution differs from the target distribution, e.g. on MNIST, which is much easier to observe.\n\n4. Then, the novelty of this paper reduces to regularization in Eq. 11 only。\n\n5. Some important relevant EBM works are missing:\n\n[1] Learning Descriptor Networks for 3D Shape Synthesis and Analysis, in CVPR 2018.\n\n[2] Learning Energy-Based Generative Models via Coarse-to-Fine Expanding and Sampling, in ICLR 2021.\n\n[3] A Theory of Generative ConvNet, in ICML 2016. ",
            "summary_of_the_review": "Though the paper seems to work on the OOD generation problem, I have concerns about the novelty and theoretical guarantee.  ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a new method for out-of-distribution generation of de novo molecules/drugs. The method tackles a key challenge of current deep generative models in producing samples that are too similar to the training samples, which result in limited applicability in practice. Instead of strictly minimizing the energy in the Langevine dynamics formulation to explore/sample the energy landscape the method proposes to maximize the energy function by means of a new loss function which has two parts: 1) a term which instead of minimizing the energy, penalizes the L2 distance to multiple hand-designed energy pivots and 2) another loss term which maximizes the property of interest (e.g., docking, etc.). The premise of the algorithms it to reach to regions of higher likelihood by virtue of maximizing the energy and therefore \"passing the valleys\" in order to explore better local minimas in the energy function. Experimental validations on some data sets demonstrates the performance of the method compared to some baseline algorithms in generating novel samples.",
            "main_review": "Positives: \n1) The paper tackles an important problem which is the out-of-distribution sample generation in energy-based models\n2) The approach of maximizing energy via pivots seems to be novel and interesting that results in improved sample generation\n3) The paper has extensive experimental validation \n\nNegatives:\n1) The exposition of ideas and the writing can be improved. In many places some acronyms are used before defining them or even not defined at all (see e.g., the abbreviations used in the abstract). \n2) I think the paper has not invested sufficient details on how the energy pivots are set even-though that seems to be the key step of the algorithm. It would be beneficial to expand on that.\n3) Also a discussion can be made on why it makes sense to maximize the energy in equation (11): while its is intuitive that the term helps the Langevine dynamic to pass some local energy maximas to enter a region of higher likelihood, the fact that the term should stay even after exploring those new regions seem to be counter intuitive as we mostly like to generate samples of low energy in physics.\n4) While the results are extensive, they are mostly centered around quality score such as novelty and diversity measures. One suggestion is to pick some of the most novel generated samples and explicitly show and combated them with the other baselines similar to what has been plotted in Figure 1.\n5) Is the code to reproduce the results available online?\n\n\n",
            "summary_of_the_review": "I think overall the paper addresses an important problem with a novel approach however the paper can be improved in the way key ideas and algorithm procedures are presented and also the comparisons to the baselines methods can be improved by showing some practical novel molecules being generated as compared to the baselines.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "* This paper is interested in the problem of designing new molecules that both (a) do well on a particular task and (b) are different to those in the training set (i.e. are sufficiently novel).  \n* To do this the authors propose MOG (Molecular Out-of-distribution Generation), an energy based model that instead of minimizing the energy when generating new molecules, tries to design molecules that maximize the energy (to encourage novelty) -- see Figure 2 and Eqn. 11. (For optimization, the approach additionally minimizes a property loss in the usual manner.)\n* The authors show how their method can produce more novel molecules than previous approaches while also obtaining better results on docking scores (Tables 3-5).\n* The authors also show how their model can be added as an additional component to existing methods (in particular Xie et al (2020)'s MARS model) to improve the novelty of molecules produced (see Section 4.3). \n",
            "main_review": "#  Positives\nP1. The authors tackle an important problem: designing new models that are able to generate molecules that are both different to those trained on *and* useful.   \n\nP2. The method appears to achieve impressive results on docking tasks (a more sensible evaluation than the older metrics used) -- see e.g. Tables 3-5. Furthermore, not only is the method able to obtain better docking scores than previous works, it also finds a more diverse set of molecules.  \n\nP3. The idea of increasing the energy towards particular targets is a fairly simple component that can be added to existing molecular optimization/sampling techniques, as the authors show in Section 4.3.  \n\n#  Negatives\nN1. The paper does not check whether the generated molecules are \"sensible\" (by sensible I mean are the molecules realizable in practice, i.e., are they stable, synthesizable, etc.?). This is a particular worry as by focusing on generating high energy molecules, I worry that MOG will generate less sensible molecules than previous approaches. If so, then the molecules it finds will not actually be useful even if they are \"novel\".   \nTo address this the authors could: (i) plot some of the molecules that they find, (ii) plot the synthetic accessibility/QED scores (Ertl and Schuffenhauer, 2009; Bickerton el al.2012) of the molecules suggested, (iii) evaluate whether CASP tools are able to propose synthesis plans for the generated molecules (Gao and Coley, 2020), or (iv) evaluate how many of the generated molecules pass commonly-used quality filters, e.g. those of Brown et al. (2019).\n\n> Ertl, P. and Schuffenhauer, A. (2009) ‘Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions’, Journal of cheminformatics, 1(1), p. 8.\nhttps://github.com/rdkit/rdkit/blob/master/Contrib/SA_Score/sascorer.py\n\n> Gao, W. and Coley, C. W. (2020) ‘The Synthesizability of Molecules Proposed by Generative Models’, Journal of chemical information and modeling, 60(12), pp. 5714–5723.\n\n> Brown, N., Fiscato, M., Segler, M. H. S. and Vaucher, A. C. (2019) ‘GuacaMol: Benchmarking Models for de Novo Molecular Design’, Journal of chemical information and modeling, 59(3), pp. 1096–1108.\n\nN2. The issue of how to choose the values of the energy pivots  is barely mentioned. It seems that the values chosen are important (see footnote in p.6) for obtaining good results and so it would have been nice to have seen some discussion/analysis of this. \n\nN3.  Currently, no code is provided and even though the main hyperparameters are described in the appendix, I would have a hard time reproducing the results exactly. For instance, how do the authors go back from the continuous node feature matrix/adjacency matrix to one that is discrete and describes a valid molecule?\n\n# Questions to authors\n\nQa. I liked Figure 3 for gaining intuition about how the approach was meant to work -- so thanks for this! One thing I'm a bit confused about, however, is why when you increase the energy pivot value all the samples move to the middle, should they not go outwards as well?\n\nQb. What was the reason behind quoting the results from Popova et al. (2019) for the JT-VAE's uniqueness in Table 2? I believe that result has been obtained from 30k samples, so is it directly comparable to the other values quoted in this table?\n\nQc. I assume you used the validity correction of Zang and Wang (2020, Section 4.4) in your approach for producing the final molecules from the node feature matrix/adjacency tensor? (Hence the 100% validity results?). Given this correction, would it be possible to compare to a random baseline in Tables 1 & 2, i.e. randomly sample the node feature and adjacency tensors from uniform distributions, correct them using the validity corrector, and then compute the uniqueness and novelty scores?\n\nQd. In Table 6, the diversity of MARS+OOD is similar to the original MARS method, is this expected? I'm surprised that your new loss did not increase the diversity too.\n\n\n\n# Minor Comments (easily fixable)\nMa. The resolution of Figure 1 is pretty low.\n\nMb. A few typos/grammar issues to fix, e.g.:\n- p.1 \"The target properties encompass from relatively simple chemical statistics to complex scores that depend on three-dimensional interaction.\" --> \"The target properties _range_ from relatively simple chemical statistics to complex scores that depend on three-dimensional interactions.\"\n- p.1 \"In this respect, we target to construct a generative model that optimizes docking scores in this paper.\" --> \"In this respect, we ~target to~ construct a generative model that optimizes docking scores in this paper.\"\n- p.2 \"Different from these works, MOG exploits training molecules but generate molecules that do not follow the training distribution.\" --> \"Different from these works, MOG exploits training molecules but _generates_ molecules that do not follow the training distribution.\"\n\nMc. On p.7 using different novelty thresholds to previous work is justified: \"0.4 is clearly too generous to determine whether generated molecules are novel enough. We set x = 0.3 and x = 0.2 for the QM9 and ZINC250k datasets, respectively\". Although this seems reasonable, it would be nice to include the results under the previously used thresholds in the appendix for completeness.\n\nMd. How were the hyperparameters listed on p.14 arrived at?\n",
            "summary_of_the_review": "This paper tackles an important problem: generating molecules that optimize particular properties and are distinct to those in the training set. Moreover, the authors proposed method, MOG, seems to do better than previous approaches on both of these metrics at the same time. However, the authors do not currently properly evaluate whether the molecules they generate are sensible (point N1 above). As the authors approach is based on generating molecules different to those likely under the initial training data, I worry that it might not do so well here, which would limit its practical value. This along with the fact that some details are only described at a high level (see N2 and N3) means that I currently have gone with a lower overall score.\n\n## Technical vs Empirical Novelty & Significance Scores \nI have given this paper a low empirical novelty score as it makes use of standard benchmarks/baselines. (The poor novelty of many existing methods has already been pointed out -- as the authors themselves acknowledge -- for instance in Walters and Murcko, 2020). \n\nI have given the paper a higher novelty score for its technical contribution; this is due to the new loss proposed to encourage more diverse/novel molecules, in particular through the use of \"energy pivots\". While simple it appears novel and seems to work effectively.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Not applicable.",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}