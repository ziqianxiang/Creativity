{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper highlights the importance of a well-tuned PGD 2-step adversarial training baseline, which has lower computational complexity when compared to the gradient regularization based single-step adversarial training method, GradAlign while achieving better performance. The authors hypothesize that a PGD 2-step attack can be considered as a combination of 2 single-step attacks, and hence the claims that FGSM-RS AT has for $\\epsilon$/2 would apply to PGD 2-step training at $\\epsilon$. They further propose to add random noise from $\\mathcal{U}(-\\epsilon/2,\\epsilon/2)$ in both attack steps to achieve improved performance across existing single-step training methods at a lower computational cost. ",
            "main_review": "Strengths:\n\n- The key strength of the paper is in highlighting the importance of the simple baseline, PGD-2 AT with proper tuning of the noise added before attack generation and attack step size. This simple baseline outperforms GradAlign in terms of both computational complexity and performance. \n- The authors hypothesize and show using experimental results that PGD 2 step training on attack magnitude $\\epsilon$ is analogous to FGSM AT at attack magnitude $\\epsilon/2$\n- Inspired by this, the proposed Qusai-PGD-2-RS AT introduces the addition of noise in the second attack step as well, and achieves improved results on CIFAR-10, SVHN and ImageNet datasets at attack magnitudes upto $16/255$, $12/255$ and $8/255$ respectively. \n\nWeaknesses/ Suggestions/ Questions for the rebuttal -\n\n- The importance of attack step size and noise added in single-step AT has already been highlighted in [1]. This paper merely extends this to 2-step training, and thus has limited novelty. \n-  The results could be compared with GAT [2] which has a computational cost of $(3c1 + 2c2)N$ and achieves clean accuracy of $80.49%$ and robust (under AutoAttack) accuracy of $47.30%$ on ResNet-18 architecture, which is 1.6% better than the results of Qusai-PGD-2-RS AT in Table-3. \n- It would be helpful to show results of CIFAR-10 on WRN-34-10 architecture as well, which is a challenging setting in single-step AT. This could be compared with the GAT [2] performance of 85.17% clean and 50.27% accuracy under AutoAttack. \n- Could the authors share the variance of the proposed method when compared to baselines at $\\epsilon=8/255$ and $16/255$ in a tabular format (same as what is reported in Fig.2 of the Appendix). \n- Results are reported for 30 epoch cyclic LR training on CIFAR-10. Could the authors share results of training for more epochs such as 50, 75 and 100 with a cyclic learning rate schedule? One of the limitations of single-step AT methods is the gradient masking issue when trained for higher epochs, and this limits the accuracy that can be achieved using these methods. Stability of training could be reported across 3 random reruns as well. \n- From Table-8 in the Appendix, it can be seen that training for more epochs (and step LR schedule) does not improve results when compared to the 30-epoch cyclic LR schedule. \n-  Could the authors clarify the meaning of Qusai and check whether it was intended to be Quasi instead.\n-  While the proposed method Qusai-PGD-2-RS AT achieves improved results, it is not clear whether this is a result of reducing the magnitude of noise initially added from $\\mathcal{U}(-\\epsilon, \\epsilon)$ to $\\mathcal{U}(-\\epsilon/2, \\epsilon/2)$ or because of adding the same noise before the second attack step as well. Could the authors share ablation results of skipping the addition of noise before the second attack step?\n- While the addition of noise before the first attack step is well justified in preventing gradient masking at the original data sample, addition of noise in the second step cannot have the same reasoning as the starting point of the second attack is not always the same, and is already randomized based on the first attack step. It could possibly only help in avoiding local maxima. Since gradient masking would not occur at $\\epsilon/2$ radius from the data sample, it is not clear why this noise addition helps. \n- Does the addition of noise before every attack step (and not only before the first step) also help for training with higher PGD steps shown in Table-7? In this case, should the initially added noise depend on the number of steps $n$ as $\\epsilon/n$? This would make the noise too less for a large number of steps. \n-  Imagenet results are better for the PGD-2-RS AT when compared to Qusai-PGD-2-RS AT, hinting at the fact that noise in the second attack step may not be important. \n- It would be helpful to include PGD-2-RS AT and FGSM-RS AT as well in Table-7 for easy reference. \n\n\n\n\n[1] Eric Wong, Leslie Rice, and J Zico Kolter. Fast is better than free: Revisiting adversarial training. In International Conference on Learning Representations, 2019\n\n[2] Sriramanan et al., Guided Adversarial Attack for Evaluating and Enhancing Adversarial Defenses, NeurIPS 2020",
            "summary_of_the_review": "This paper highlights the importance of the simple baseline PGD-2-RS AT with well-tuned hyperparameters. I believe the novelty of the paper is limited, given that this was already highlighted in [1] earlier for single-step AT. Moreover, the importance of adding noise in the second attack step, which is the key change introduced in the paper, has not been well justified empirically and otherwise. The results are not compared with GAT [2] which achieves better results. I would therefore recommend rejecting the paper. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper studies PGD-2 Adversarial Training (AT) as a replacement to Fast Adversarial Training [[1](https://openreview.net/forum?id=NGBY716p1VR)] and GradAlign [[2](https://arxiv.org/abs/2007.02617)].\nThis study is motivated by stating the fact that Fast Adversarial Training and GradAlign both suffer from _catastrophic overfitting_ (a sudden drop of robust accuracy to almost 0) for large perturbation sizes in the $\\ell_\\infty$ setting.\nIt is empirically shown that PGD-2 AT with random initialization and proper step size ($\\alpha = 1.25\\epsilon/2$) can mitigate this phenomenon even for large perturbation sizes.\nThis mitigation of catastrophic overfitting is achieved while reducing the time complexity by a factor of 2 compared to GradAlign.\nThen, arguing that PGD-2 with random start is approximately equal to a two-step FGSM, a different initialization scheme for PGD-2 is proposed.\nIn this new variant, named Quasi-PGD-2, instead of initializing the perturbation with uniform random noise $\\mathcal{U}(-\\epsilon, \\epsilon)$ in the beginning, they are initialized with $\\mathcal{U}(-\\epsilon/2, \\epsilon/2)$ at _each step_.\nExtensive experimental results on CIFAR-10, SVHN, and ImageNet indicate that PGD-2 and Quasi-PGD-2 can mitigate catastrophic overfitting for large perturbation radius while having half the computational cost of GradAlign.",
            "main_review": "### Strengths and Weaknesses:\n\n+ The empirical findings of the paper are interesting.\nIn particular, these studies show that existing methods such as PGD-2 are a better way of resolving catastrophic overfitting compared to newly proposed ones such as GradAlign [[2](https://arxiv.org/abs/2007.02617)].\n\n+ The experiments are comprehensive.\nThey include three different datasets (CIFAR-10, SVHN, and ImageNet) and the results are compared with several state-of-the-art baselines (such as Fast [[1](https://openreview.net/forum?id=NGBY716p1VR)] and Free [[3](https://arxiv.org/abs/1904.12843)] Adversarial Training, GradAlign [[2](https://arxiv.org/abs/2007.02617)], and Stable Single Step AT [[4](https://arxiv.org/abs/2010.01799)]).\nFor all of these settings, several models with different perturbation sizes are evaluated.\n\n+ While these findings are interesting, several concerns need to be addressed:\n\n\t1. The reasons behind choosing the fixed step-size of $\\alpha = 1.25\\epsilon/2$ are not obvious.\nFrom the beginning, this step size is stated as the primary hyperparameter of training.\nHowever, the reasons behind this choice are not explained.\nIn particular, how/why this number is chosen?\nMore importantly, what happens if the step-size is changed?\n\n\t2. The reasons behind the success of PGD-2 in mitigating catastrophic overfitting are not presented.\nWhile the empirical study shown in Figure 1 indicates that the PGD-2 AT loss evolves similarly to PGD-10, it does not answer the question asked in section 4.2 \"Why does PGD-2-RS with $\\alpha = 1.25\\epsilon/2$ work?\" \n\n\t3. The motivation behind the introduction of Quasi-PGD-2 is not presented.\nSpecifically, it is first empirically shown that PGD-2 is working for large $\\ell_\\infty$ perturbations.\nThen, from the resemblance of PGD-2 with a two-step FGSM, the Quasi-PGD-2 is introduced.\nAt this point, the reader might ask: why this step is necessary?\nBecause the experiments show that the differences between PGD-2 and Quasi-PGD-2 are negligible (Quasi-PGD-2 has slightly higher robust accuracy while obtaining slightly lower clean accuracy in all the cases).\n\n\t4. While the paper is well-written in general, to this reviewer the connections between the sections are not quite understandable.\nFor instance, right after the problem overview, the reader enters section 3 which is on the time complexity of PGD-2.\nHowever, why this section needs to be there, and what piece of the puzzle it is supposed to solve is not clear.\nTo address this, this reviewer believes that the sections need to be well-motivated so that the readers understand why they are reading a particular section.\n\n### Minor Comments/Suggestions:\n\n+ What the mean and standard deviation in Table 1 correspond to is missing from its description.\nLike the other tables please add the information that they are the mean and standard deviation of accuracy taken for 5 seeds.\n \n+ Please add different line styles to your figures to help with readability for the color-blind.",
            "summary_of_the_review": "While the empirical findings of the paper seem interesting, to this reviewer the motivations/explanations behind them are not well presented.\nThis issue needs to be addressed so that the readers can understand why certain actions (such as fixed step-size $\\alpha = 1.25\\epsilon/2$ or introduction of Quasi-PGD-2) are taken.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper empirically studies several aspects of PGD-2 AT: 1) PGD-2-RS AT with attack step size $\\alpha=1.25\\epsilon/2$ can alleviate catastrophic overfitting for large $\\ell_\\infty$ perturbations with less computational cost. 2) Regarding PGD-2-RS as two-step FGSM-RS, the auther hypothesizes the scenario where PGD-2-RS are capable of avoiding catastrophic overfitting. 3) Change the distribution of random start in PGD-2, the auther proposed Qusai-PGD-2-RS and shows both the effectiveness and efficiency on CIFAR-10 and SVHN.",
            "main_review": "1. Poor writing and structure. For example, too many repeated expressions like 'catastrophic overfitting' in the abstract; reference should not exist in the abstract; also the abstract needs to high-level summarize the insight and novelty of this paper rather than present details like $\\alpha$ and $\\epsilon$ values. \n\n2. The motivation isn't well elaborated. Specifically, what motivates the authors to investigate PGD-2? Personally, I think this manuscript is more like a technical report than a conference paper.\n\n3. The method used is just about turning some hyper-parameters in PGD-2. Although it's effective in terms of alleviating catastrophic overfitting, the approach doesn't provide any new insight or ideas to this community. ",
            "summary_of_the_review": "Generally, I tend to reject this paper. Although the paper shows some interesting results by turning hyper-parameters in PGD-2, the motivation is unclear and the novelty is limited.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}