{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes an online algorithm called Adaptive Recursive Markov Chain Monte Carlo (ARMCMC). The algorithm is used to sample model parameters theta and is designed to trade-off exploration and exploitation by leveraging on a variable jump distribution and a temporal forgetting factor. ",
            "main_review": "The presented algorithm performs well on Hunt-Crossley model and it is easy to understand the proposed strategy. \n\nMy main concern with this paper is that it does not come across as being widely applicable. The literature review and the simulations focus on a specific model called Hunt-Crossley. It is possible that this is an important model, but I had never heard about it before and I think ICLR papers should have a broader scope. Let me briefly discuss these two aspects in more detail: \n\n1.  The fact that the literature review appears to focus on paper that deal with Hunt-Crossley models is problematic. For instance, there is a rich literature on adaptive MCMC which is essentially ignored. It would be useful to have a separate section in the paper on related work. At the moment, your discussion of related work is essentially limited to the first three paragraphs in the introduction, which is not enough. \n\n2.   The proposed algorithm contains elements that prevents it from being widely applicable. For instance, one of the key components in the algorithm is (8), which assumes that the empirical mean and variance of the data makes up a reasonable proposal. Among the models that I normally work with, data and parameters have a much more complicated relationship, and certainly do not have the same dimensions, which makes it unreasonable to use such properties to design a proposal distribution. \n\nA third weakness is that the algorithm also comes across as somewhat ad hoc, with several design variables that are selected manually. I am curious if the algorithm is sensitive to these choices and if the same values can be used in different problems. It would have been desirable if additional experiments could be provided, perhaps in an appendix, where you demonstrate the applicability of your model to other problems. \n\n",
            "summary_of_the_review": "Considering that the main review is already quite short, I do not think it needs to be summarised. ",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors develop a new algorithm for online MCMC sampling (ARMCMC). The main innovation is switching from sampling the previous posterior to sampling from a normal distribution in an automated adaptive manner. The choice is a function of how well the new data batch fits the previous model, and two thresholds. The authors prove that this approach requires fewer samples than conventional MCMC for the same precision and reliability. They demonstrate their approach on two models. \n",
            "main_review": "The adaptive method makes sense. Simply going with the normal distribution is slow, but simply going with the distribution from the previous time window will lead to issues if the model changes substantively. More classic adaptive MCMC methods simply change the variance of the normal distribution. The approach is simple and speeds up on-line sampling. This is a relatively modest innovation, but it is a contribution.\n\nThe authors prove a result regarding the trade-off between precision and reliability and note that it is favorable to what they call conventional MCMC, which is basically their method without consulting the previous time window model for samples, and solely using the normal distribution. (For me, it is all MCMC. What is different is only the proposal distribution, which is adaptive). \n\nWeaknesses\n\nThe impact of ARMCMC method seems a bit oversold, or at least, not so well demonstrated. If sampling the previous PDF is going well, then I can see that the method is likely fast. But there seems a limited sweat spot where you can learn the model from scratch fast enough. And if you can do that, then is the time needed by regular MCMC so big? The discussion just before the conclusion suggests that ARMCMC is twice as fast as MCMC, which is a solid increment, but, since one has to be prepared for learning the model from scratch perhaps the real saving is energy? Also, the authors compare their method to (very) conventional MCMC and a least squares method. But are these the toughest comparison methods? How about a particle filter?\n\nThe authors are often using MCMC for MAP estimation, but sometimes they care about the distribution. For this purpose, the algorithm might be wrong in that when samples are rejected you should emit the previous sample. Perhaps a small oversight, if that is how it is coded, then it could affect some of the results (not MAP ones).\n\nIt is not a big issue for me, but the topic is on the very periphery of the topic of learning representations. This method is about fast parameter fitting for a given model. \n\nThe exposition could be improved (see comments). \n\nComments\n\nI found the proof a bit hard to read because I had to keep scrolling to the lemma (perhaps it could be nearby), as well as the other formulas (perhaps being a bit more pedantic about how they are used would help). \n\nIts been a long day, but I don't get the counting in equation one. I would have thought N_s + 1 would be N_s -1.\n\nFor (4), perhaps clarify one-step-ahead and explain the formula slightly more. \n\nAfter (5), I don't get Remark 1, and looking at page 128 (thanks for trying to provide the page number in the references) of PRML did not help. Perhaps 128 is a typo. \n\nFor (8), I don't think \\lambda_k got defined. Also, \\lambda^t is referred to as a hyper parameter, but it is a function of other things (including two hyperparameters). \n\nTheorem 3.1: \"enough number of evaluations\" --> \"sufficiently many evaluations\"\n",
            "summary_of_the_review": "A modest but sensible innovation with a proof regarding the number of samples needed as a function of precision and reliability. Stretching the scope of ICLR a bit. \n",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes an MCMC algorithm that uses a proposal distribution designed to improve the sample efficiency to estimate distributions in real-time. The introduced proposal distribution reduces the number of samples required to achieve a desired level of accuracy for which a proof is provided. The method is compared to standard MCMC and recursive least squares on two tasks involving dynamics models.",
            "main_review": "This review is an updated version of the one I provided for the same paper submitted to NeurIPS 2021. From a semi-thorough comparison of the submissions, I can not make out any difference in content between these two submissions. If there is, I would be happy for the authors to point these out so I can take them into account in the review.\n\nThe paper's main contribution appears to be the proposal distribution and the proof about the minimum number of samples required by that proposal distribution. If this is correct, I am not convinced that there is enough novelty in this, as coming up with a proposal distribution is a large portion of what practitioners of MCMC do, as it has a significant impact on the performance and quality of the results, as evidenced by the experimental results. A big aspect of proposal distribution design is to ensure that it still leads to a valid MCMC scheme. Thus I was surprised not to find an analysis of this via the detailed balance condition.\n\nThe proof leaves certain questions open. For one, it provides a number with respect to the minimum number of samples required. Does this mean that the desired precision and reliability will be achieved after that many samples or that at least that many points have to be sampled, but it could also be more to achieve the desired values? Another aspect worth discussing is that the Chernoff bound usually requires independence between samples, which is always a concern in MCMC methods.\n\nA focus of the paper is the computational efficiency of the method by reducing the number of samples required. As such, I would have expected the mention of other methods that fall into this domain, including variational inference and stochastic gradient Langevin dynamics [1]. An additional aspect that is not detailed is that for control problems, which are alluded to in the introduction, usually multi-modality is not desirable, but a unimodal estimate that can be estimated at 100Hz or more is desired.\n\nThe experiments evaluate the proposed method on two dynamics model examples. While the results show that the proposed method works better than the other methods used in the comparison, there is no real discussion of the results. Furthermore, the other methods used seem to fail completely to solve the tasks, making it hard to pass any judgment. As the problems seem to be parameter estimation setups, methods such as extended Kalman filters would have been a good fit for comparison. From the description, it appears that the MCMC method was never run with the expected minimum number of samples required, which would have made for an excellent addition to the results. Finally, with the paper focusing on real-time estimation, I would have expected to see information about the runtime of the methods, yet this is absent from the paper.\n\nWhile there are quite a few interesting plots, including Figure 5 and Figure 7, there is little description of them. Figure 5 is unimodal but time-varying, which means one of the big strengths of MCMC is not being utilized. Figure 7 simply plots too many things at once, making it impossible to see what is going on.\n\n[1] Welling, Max, and Yee W. Teh. \"Bayesian learning via stochastic gradient Langevin dynamics.\" *Proceedings of the 28th international conference on machine learning*. 2011.",
            "summary_of_the_review": "While the method seems correct and achieve its goals the novelty appears limited and the experimental evaluation lacks important aspects.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper claims to provide an online Markov chain Monte Carlo which requires less number of samples compared to other MCMC methods. It is claimed that this paper addresses limitation with other MCMC methods such as not being limited to Gaussian noise, being applicable for a wide range of parameter constraints while it requires less number of samples to provide the same reliability compared to its counterparts. To do so, it introduces a jump variable to regulate the expiration-explotation tradeoffs. This paper also provides some experiments to support their claims.  ",
            "main_review": "+ This paper is easy to follow.\n+ sufficient literature review and background are provided.\n+ Experiments seem to be reproducible, even though the models are borrowed from other papers. \n- It seems like this paper does not provide sufficient mathematical guarantee as to the convergence of the algorithm nor do the statistical properties of the algorithm. \n- In lemma 1, the used version of Chernoff bound seems to be true if the samples are independent (the reference authors provided specifically attest to that).  Samples in MCMC are highly correlated. There are bounds for dependent samples which there is an adjustment in the statement. \n- Could authors please justify their proof of theorem 1? It seems as though this is also valid for independent samples.\n- This paper suffers from the lack of statistical proof or at least enough experiments to justify different aspects of the algorithm and make comparisons to the existing methods. It is expected to see more experimental results to support all their claims. It is also worth mentioning that, often making an estimate on how long to run a chain requires an understanding of the mixing properties of the chain. For instance, there are some upper bounds for mixing time based on coupling methods that authors could take advantage of. \n- As mentioned above the main question in MCMC is the convergence and the speed of convergence of an algorithm which this paper is not providing any sort of support for those. In addition, some discussion as to how this algorithm can explore the entire state-space is necessary. \n",
            "summary_of_the_review": "- Lack of theoretical guarantees for their claims\n- Lack of experimental results \n- This paper may have some merits, suggest authors add some simulation results to account for different scenarios or provide a more rigorous mathematical guarantees and resubmit it. I recommend rejection. ",
            "correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}