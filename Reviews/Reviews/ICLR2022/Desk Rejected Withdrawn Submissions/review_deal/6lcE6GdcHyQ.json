{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a model for processing of audio and visual signals by training it to perform audiovisual speech recognition tasks. ",
            "main_review": "Following are the strengths and weaknesses of the paper in my opinion.\n\nStrengths: \nThe problem statement is interesting.\n\nWeaknesses:\n- The paper is, unfortunately, riddled with grammatical and presentation issues, to the point that the points barely come across. I had a very hard time understanding it and it needs a thorough revision.\n- The paper tries hard to base the work on notions such as \"the brain\", \"deaf/blind\", etc. These analogies are quite a stretch as the learning and fusion strategies that the authors are referring to are very rudimentary and nothing like what happens in the human brain. \n- New terms are invented with no prior description or references, e.g. the paper talks about \"weak multi-modality robustness\" such that it appears to be a well-known problem. However, no prior works have defined/discussed this.\n- The proposed method is not reproducible as most details are missing.\n- The proposed method is quite simple. Moreover there are so many advanced fusion strategies that the paper ignores.\n- The experiments are not deep enough, especially comparisons to state of the art are missing. ",
            "summary_of_the_review": "-",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper proposes a neural network which solves an input deprivation problem, specifically CNN and GRU-based models are compared and analyzed. Different adaptation settings are studied using audio and visual inputs in a lip reading task. In addition, modality mix and gated fusion techniques are used to further improve the accuracy of the proposed solution. ",
            "main_review": "The presented work is interesting and important for future enhancements of the multi-modal data analytics. Various datasets are used to prove the robustness of the solution. The paper is well structured and flows logically. \n\nThe main limitation of the work is poor explanation of the proposed innovations. It is not clear how the Modality Mix differs from the referenced work proposed by Gijs van Tulder, Marleen de Bruijne, in which 'the network is only given the selected input modalities to compute the central representation' and they use a subset of modalities, because their input consists of 4 modalities (the modality Mix technique proposed here operates on 2 modalities only, so after zeroing out one of them, only one is left.). Modality dropout is used to replace the averaging of all modalities, as this will still allow the network to learn the modality-specific features. I don't see how the Modality Mix technique is different. If there is a significant difference in both approaches, please include experimental analysis of both techniques and provide quantitative analysis. \nThe Gated Fusion approach sounds interesting. It would be beneficial to include the architecture diagram of the technique and provide more details about this gating mechanism, including attention mechanism and used parameters. Without more details it is not clear how it differs from already published works, e.g., the referenced one (Cheng, et al., 2019). It seems like the gated fusion mechanism used here is the same as existing ones, but applied to a new task. \nMore details should be also provided about the training procedure used to determine generalization abilities. A fine tuning should be applied to determine generalization abilities, but it's not clear if models were trained from scratch or not. \n\nResults for audio and visual models are also not consistent. In Table 3, Born Blind is better than Acquired Blind, while Acquired Deaf is better than the Born Deaf. in general, VO results are much worse than AO. It's also mentioned that he acquired blind models with gated fusion have much better accuracy than those using the concat fusion, but the opposite is true for the deaf models and no comments on that were provided.\n\nPlease explain what AV, AO, VO mean. I can understand it from the context, but it should be clearly explained. Some parts of the paper are difficult to understand, Please have the manuscript proofread again. To improve the clarity of the work, you can also reuse some name conventions across tables, e.g., A, B1, B2 in a first column of Table 2. \n",
            "summary_of_the_review": "The proposed idea is interesting, however more work is needed to improve its quality. The introduced concepts are only briefly described and it's not clear what the novelty is compared to concepts existing in prior studies. Results differ across various modalities what was not discussed. I don't recommend publishing this work in a current form.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper investigates the impact of missing modalities on audio-visual speech recogntition. It proposes the use of modality mix and gated fusion in order to alleviate this issue. It also presents results on LRW and OuluVS2 datasets.",
            "main_review": "Strengths\n\nThe paper explores an interesting problem.\n\nWeaknesses\n\nIt is not clear what the contribution of the paper is. The paper first presents results showing that when a modality is missing in an audio-visual model for speech recognition then the performance of the present modality is much worse. This is expected and known. Then it proposes the use of modality mix and gated fusion as a potential solution. Both approaches have been proposed in the past, e.g., Multimodal deep learning, Ngiam et al. ICML 2011 for modality mix, and Audio-visual recognition of overlapped speech for the lrs2 dataset, Yu et al. ICASSP 2020 for gated fusion. Finally, it shows that it’s better to train a model with a missing modality from the beginning rather than training an audio-visual model first and then fine-tuning it while one modality is missing. It’s not clear why such an experiment is needed, why not training a model on one modality only?\n\nThe paper would benefit if the authors put less emphasis on how the brain performs audio-visual fusion and how it deals with missing modalities. The focus of the paper should be dealing with missing modalities in an audio-visual setting. The solutions proposed, modality mix and gated fusion, are not really inspired by how the brain works, but even if they were it’s not necessary for such a large portion of the paper to be devoted on this. I think it distracts the reader from the actual contribution.\n\nIt would be very helpful if a figure explaining the different terms, born/acquired deaf/blind, is added.\n\nIt is not clear what the purpose of section 5.3 is. It would have been better if the paper focused more on LRS2 rather than OuluVS2, which is an easy dataset, and the results are so high which makes it difficult to draw any conclusions.\n\nTables 1, 2, 3. It is never defined what AO and VO stand for. It would be good to have a comparison with an audio-only and video-only models.\n\nThe paper would benefit if more information on how exactly the mouth ROI is extracted.\n\nLegend in Fig. 4 is too small.\n\nThe paper needs proof-reading, there are several sentences that need to be re-written/re-phrased and this has an impact on readability.\n\nA non-exhaustive list can be found below:\n\nFig. 4, wrong true and wrong false -> this probably refers to false positive and false negative?\n\n- networks has draw more attention\n- we find a interesting\n- if another modal data are masked\n- As humane beings\n- Models capable of receiving different kinds of information has proved\n- the video inputs are replaced with zeroed-outed inputs\n- only audio data are gated because the purpose of the network\n- We further analysis the error patterns\n- as researches like Aytar et al. (2016) and Arandjelovic & Zisserman (2017) have shown some promotion\n",
            "summary_of_the_review": "The paper explores a very interesting topic but as explained above it is not clear what the contribution is. It also over-emphasises the link between the proposed solution and how the brain works, e.g., the title says brain-like compensation but there is nothing to suggest that modality mix or gated fusion are brain mechanisms for audio-visual fusion. The paper would benefit if it was presented as an investigation\non missing modalities for audio-visual speech recognition. Then taking into account the comments from the section above, and clearly explaining the contribution, it would be more focused and might have greater impact. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}