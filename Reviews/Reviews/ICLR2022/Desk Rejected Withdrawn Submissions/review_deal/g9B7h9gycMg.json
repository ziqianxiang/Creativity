{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper aims to address the problem of long-tailed classification based on data augmentation. The main contribution is that it exploits category-agnostic latent features that are shared across head and tail classes. To this end, it learns a pool of latent features at sub-category levels, in a way that the latent features are semantically meaningful and are also able to reconstruct the original object features. Since the latent features are independent of categories, they are not constrained by the imbalanced data distributions. Based on these latent features, semantic data augmentation is used to produce diverse examples for tail categories by transferring the sample diversity of the head categories. The approach is tested on standard long-tailed classification setups, including CIFAR-10-LT, CIFARF-100-LT, ImageNet-LT, iNaturalist, and Places-LT, and compared with state-of-the-art results.",
            "main_review": "Paper Strengths:\n\nThe authors tackle an important and challenging problem of long-tailed classification. The proposed approach is simple and intuitive. Experimental evaluations clearly demonstrate the effect by introducing the latent categories and use them to guide data augmentation for tail categories\n\nPaper Weaknesses:\n\n1) The proposed approach in this paper can be viewed as directly operating the semantic data augmentation method ISDA on top of the latent features. The novelty is somehow limited.\n\n2) There is a lack of comparison with directly operating ISDA on top of the original feature instead of the latent features.\n\n3) The main contribution of this paper is learning category-shared latent features. However, following the previous comment and based on the ablation study in Table 4, it seems that only using latent categories achieves basically the same performance as the baseline. This casts doubt on the performance improvement – it seems that the key source of improvement comes from the ISDA data augmentation.\n\n4) While it is claimed that the latent features are category-agnostic, there seems no mechanism to guarantee this. The only loss function is the reconstruction loss. However, it is possible that only some latent features are used to reconstruct the head categories, while other latent features are used to reconstruct the tail categories. In this case, the learned latent features would be still biased to different categories.\n\n5) From Table 3, it seems that the performance is sensitive to the number of latent classes for different datasets. In practice, how should we determine the appropriate number of latent classes? \n \n6) It would be interesting to visualize the learned latent features, and analyze how the object-level features are decomposed into the latent features.\n\n7) How is the compared baseline performance when they also use the ISDA data augmentation?\n\n8) How is the sensitivity of the hyper-parameters in Eqn. 7.",
            "summary_of_the_review": "This paper exploits category-agnostic latent features and semantic data augmentation to address long-tailed classification. However, it seems that the performance mainly comes from the semantic data augmentation method ISDA. Some important comparisons and ablation studies are missing.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper introduced a data augmentation method for long-tailed recognition by using latent categories. However, the method lacks novelty, and the description of the method is hard to understand.",
            "main_review": "In my opinion, this paper is a replay of ISDA in \"latent category\". However, the design of ISDA should be improved when it is used in latent categories, but this paper does not discuss it. In result, there are a lot of questions in the method section, and some of the designs make no sense to me. I will list them below.\n\n1. the use of \"class\" and \"category\". There are several definitions of term \"class\" (or \"category\") in the paper. I suggest that the author should define them clearly before use them, or even use different terms to avoid confusion. I can get two of them: the \"class\" for the recognition problem and the \"latent class\" for the latent features. But it seems there is a third one below Eq. 4., which I can not get.\n\n2. In section 3.1, I can not get why we need a \"1 x 1 convolutional layer FC\". All the latent features are learned end-to-end. Without the FC layer, all features should be learned as those after FC, and it makes no difference to other parts of the model. Besides, the term \"1 x 1 convolutional layer\" is confusing. There is no feature map, so it is just a fully-connected layer.\n\n3. I do not understand Eq. 4. First of all, there is no need to introduce $C_f$, the loss only uses the correlations of each feature. Then, it defines j as the index of classes. But they are just different spatial positions on feature maps. And why is t_j the ground-truth? I can not see where we can get this ground-truth, and what it means.\n\n4. In Section 3.3, \"we calculate the co-variance matrices for each latent class by updating the latent features $f'_m$ at each iteration\". How can you do that? I do not know how to calculate a covariance matrix by updating features.\n\n5. Below 4, \"$y'_m$ indicates the groundtruth of the M latent categories\". Why do you have the groundtruth of latent categories?",
            "summary_of_the_review": "Overall, I do not think this paper is ready to publish. But I could misunderstand the method. I will be happy to change my mind if the author can answer my questions in main review and show the importance of the work upon existing methods.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes to learn latent features for long-tailed recognition. The latent features are learned from the activation maps during training in an end-to-end fashion. They are learned such that each latent feature represent a different sub-category and their semantics do not overlap. Furthermore, the authors apply a semantic feature augmentation technique to further diversify their latent features. The proposed approach is evaluated on well-known long-tailed recognition benchmarks.",
            "main_review": "Pros:\n- The paper proposes an interesting idea. The latent features are learned in an end-to-end fashion during training. The goal is that they can combine characteristics of other classes to represent a tail class. As far as I know, this is a novel approach, and significantly different than most of the existing work in the literature for long-tailed recognition.\n\n- Figures 2 and 3 are very useful for demonstrating the overall idea of the paper. \n\n- The experiments show good performance in terms of accuracy.\n\nCons:\n- While the idea of learning latent features is interesting and original, I find applying feature augmentation on them counter-intuitive. More specifically, the latent features are interesting because we can \"control\" them. So, ideally, one would be able to get more distinct latent features by increasing M (the number of latent features). However, this work seems to imply that the latent features have limited benefits, and one would have to apply existing augmentation methods to achieve a good performance. \n\n- If feature augmentation is indeed a must, then the paper is a missing a crucial baseline comparison. What happens if the feature augmentation is applied directly to the \"real\" features, rather than the latent features. This is essential for better understanding the role of latent features. \n\n- Experiments are not well detailed and unclear. For example, iNaturalist numbers between Table 2 and Table 4 are not consistent. What is responsible for 2% difference between two tables? In the Ablation Studies, the authors show that the number of latent features (M) might have a significant impact on the performance. How is M chosen for the final SOTA comparisons? Did the authors fix M across all datasets or choose a different M for each dataset? If latter, I would argue that this is overfitting to the test set.\n\n- Figure 4 is nice, but a more informative figure would be to visualize the latent features (e.g., with t-SNE ) in 2D space and show their distribution. It would be interesting to show the class means of the \"real\" features in the same plot, so we can see how close the latent features are to the classes. ",
            "summary_of_the_review": "This paper proposes an interesting idea of learning latent features. However, I find the second component of the framework (feature augmentation) counter-intuitive, and the necessity of such a component might suggest that the learned latent features are limited. The paper would benefit from discussing the limitation of the learned feature vectors and the need for feature augmentations. The experiments also need to be improved and made clearer for the reader. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors present a semantic augmentation based method for long-tail data recognition. In the paper, the authors propose to learn the common features that share across both head and tail classes. The latent features are used to generate augmented training samples. The proposed method is tested on long-tailed CIFAR, ImageNet-LT, Place-LT and iNaturalist datasets. ",
            "main_review": "The proposed method achieves promising results on the tested dataset. \n\nThe second contribution the authors claimed is the semantic data augmentation. The proposed latent implicit semantic data augmentation seems to be similar to the one in the Wang, 2019. The author should provide more comparisons or ablations to contrast the two.\n\nThe authors use different ResNet backbones on different datasets. It is interesting to see the ablations of how different backbones affect the performance on the same dataset. \n",
            "summary_of_the_review": "Overall, I think the way of learning latent features through similarity maps and reconstruction loss is interesting. But authors need to provide more comparison to contrast with existing works. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}