{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The authors provide a technique for detecting rare images by providing a generative model of image patches similar to topic models in NLP using a concept of rate visual words which can be used to provide a hint to MCMC inference.\n",
            "main_review": "The description of the novelty in the paper is very hard to figure out. The authors claim that their novelty is that certain visual words are specified as rare and this \"remain fixed throughout the finding of posterior inference.\" (paragraphs around Equation 7). What does this mean exactly? If a random variable is fixed to 1 then how is it different from an observed random variable? And if the variable is not observed then what is the guarantee that MCMC would keep it at a fixed value.\n\nEquations 2 and 3 and the surrounding text have a technical flaw. A Dirichlet distribution has to have non-zero concentration parameters. However, the dot product in the definition of the concentration parameters (with a vector of Bernoulli random variables) will make some of them zero.\n\nI'm not familiar with some of the related work described in the paper, but one would naturally ask why some standard method using Deep Learning is not applied. For example, create an embedding of the images using a pre-trained imagenet model and cluster them using DBSCAN. Finally, label the rare clusters by looking for a cluster with a preponderance of the rare visual words. This is completely unsupervised and uses the same minimal information used in the paper.\n\nThere are a number of language issues in this paper. Far too numerous and obvious to enumerate. I would highly recommend to hire an editor to help review them. I would also suggest to adopt a more technical rather than an informal tone.\n\n",
            "summary_of_the_review": "There is no novelty in either initializing a random variable or setting it to a fixed value with MCMC.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors provide a method for rare event detection, based on hierarchical Bayesian models.  Rare events are detected by calculated by associating particular topics with such events, while ensuring that this association is made via special initialization and proposal distributions during MCMC sampling, and evaluating the posterior of these topics (for any patch in an image) at test time.  The method is tested on real and synthetic data, and displays good performance as the rarity of the detection event increases.",
            "main_review": "The model is well explained, and the derivation of the training and inference algorithms appears to be correct.  The experimentation also appears to show promising performance of the method relative to baselines, although I'm unsure of the difficulty of the datasets used.\n\nSome aspects of the method raised questions for me:\n\n1. It seems that the method shouldn't be described as being 'sans labeled data', since labels of the rare events are used to initialize and guide the MCMC process.  I would say it was more appropriately described as 'semi-supervised'.\n\n2. In sections 4.2 and 4.3 it was unclear to me whether the rare 'labels' were providing constraints during training.  In Sec. 4.4 it states that 'Due to the structure of the model, the position remains unchanged throughout the MCMC procedure', but the objective in (4) doesn't appear to depend on the known rare 'labels', and so it seems that the \\xi variables associated with an image can change during training.  I notice that there isn't a prior on the \\xi's in (4) - should these not have a prior in order to infer their values in new images?\n",
            "summary_of_the_review": "While I'm not sure about some aspects of the description of the model, it appear technically correct, and to give promising results.  The novel aspects of the method though seem low, since these are essentially a method of initialization in an LDA-style model where particular topics are associated with rare events, and a method for enforcing sparsity during inference (which, as the authors note in Eqs. 2 and 3, is equivalent to modifying the strength of the Dirichlet prior).",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper introduces a Bayesian model to detect rare events named guided MCMC. This paper utilizes experts' knowledge as the input to a hierarchal Bayesian model and take advantage of MCMC methods, Gibbs sampling, to make inference by competing the posterior distribution of rare events.  With the use of importance sampling for sparse model, importance to the rare events is emphasized. ",
            "main_review": "+ Sufficient literature review and background are provided. \n- Sometimes their notation can be confusing as they are not properly defined (equations 2,3) for instance. \n- This paper is highly incremental. It seems like the authors combined results from topic modeling and mapping between visual words and patches with common techniques in Bayesian statistics to compute the posterior. \n- Following the previous point, there is a lot of reducncay in the paper. And some basic information about Bayesian statistics could have been replaced by more important information such as how this is method drastically different from LDA. As this paper highly overlaps with the LDA, computing the posterior distribution has been done and with a minor adjustment, the results in this paper can be derived. \n- Regarding sparsity, even though, sparsity is the way to emphasize on rare events, I am not convinced this is the best way to enforce sparsity. The spike and slab prior to enforcing the sparsity have been employed in the literature that can beautifully enforce the sparsity for rare events. I understand that with high probability Dirichlet($\\alpha$) provides sparse distribution if $\\alpha<1$, but was wondering if the authors could justify their method (basically equation 2 and 3). \n- Not convinced that this model works better compared to other exciting methods such as zero-shot learning or Bayesian techniques. \n- Also, I am not convinced that their method outperforms the state-of-the-art. I believe their experimental results cannot provide enough evidence to justify this claim. Could authors please justify how they support this claim?\n- Since it is claimed that this method outperforms other approaches, it is expected to see much more experimental results and comparison to most of the algorithms that are mentioned in the related work. \n- I am unable to verify the experimental results. \n",
            "summary_of_the_review": "- Paper is highly incremental and the contribution is very minor. Basic techniques in Bayesian statistics are employed to introduce a prior and thus to compute the posterior. \n- This paper does not provide enough evidence to support its claims.\n- Lack of experimental results. \nThus, I recommend rejection. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper presents a rare event detection method applied for the image data. Specifically, the problem of unsupervised rare event detection is tackled. The authors modeled the rare event detection problem as a hierarchical Bayesian model and the MCMC is utilized. The experiments are conducted on the solar spectrograph (burst) dataset, the fruit datasets, and the aeroplane sky datasets.",
            "main_review": "* Strength of the paper\n- The proposed method achieves superior performance compared to other baseline methods in the experiments.\n\n\n* Weakness of the paper\n- Although the thorough derivation of the formulas in this paper resembles theoretically sound topic models, the difficulty(easiness) of the datasets can't stop one from thinking of other simpler approaches.\n- The 3 baseline papers (SCAN, RUC, NNM) are all basically proposed for the clustering problem. Considering that the clustering algorithms are inherently weak for very small clusters or rare events unless specially designed for it, direct comparison is not fair.",
            "summary_of_the_review": "My recommendation of this paper is weak negative because this paper seems to be overly pedantic to a simple dataset problem and unfair comparison.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
        }
    ]
}