{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a semantic-aware cropping strategy in place of RandomCrop, which is commonly used in both supervised and unsupervised learning settings. The proposed cropping scheme is model-agnostic and aims to optimize the positive pairs sampled in various self-supervised representation learning methods. It tries to better the cropping pipeline from two perspectives: (1) an object localization heuristic based on the heatmaps from the features of the last conv layer, and (2) a center-suppressed sampling scheme based on (1) to avoid easy positive pairs. (1) is used to constrain the cropped images to contain meaningful objects within the images instead of backgrounds(false positives). And (2) is used to compensate (1) with a larger variance of sampled crops in order to avoid being too object-centric.\n\n",
            "main_review": "Strength: this paper is novel in that it tries to tackle and brings new perspectives to a commonly-used data augmentation scheme, namely the pipeline for generating crops of images, in the setting of self-supervised representation learning. The designs of positives/negatives are very essential in SSL and this paper can possibly bring insights into what makes good positive examples. Besides, the proposed method is generic and can be directly applied to different frameworks as a plug-and-play component, which might encourage more applications of it into different flavors of SSL(e.g. SSLs for dense downstream tasks).\n\nWeakness:\n(1) Some reported improvements over the baselines are relatively small(e.g. 0.25% for SimCLR). It would be more persuasive if the author could provide variances of the reported numbers.\n(2) Fig. 3 did a qualitative comparison of the proposed schemes with RandomCrop, which exemplified the visual results of the proposed ContrastiveCrop. In Sec 3.4 the paper tried to show the effectiveness of the method by presenting statistical results from the feature space. To better correlate the performance gains with the proposed cropping scheme, a quantitative analysis of the cropping qualities coupled with Fig. 3 in the raw data image space would be more convincing. \n\n",
            "summary_of_the_review": "This paper brings insights into design choices for making good positive pairs for SSL frameworks, with a focus on generating random crops of images that are more friendly to SSL. With a more detailed documentation of the results and experiments to justify the correlation between the proposed improvement and performance gain, this paper is recommended for acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper presents a semantic aware method (ContrastiveCrop) of cropping to get better views for contrastive learning. Earlier works generated positive samples by adding standard augmentations to the image and taking random crops which did not consider the semantic structure of objects in the image. This Random cropping could lead to easy or unwanted positive samples, that can hurt training and the quality of representations learnt. ContrastiveCrop is an add-on to self-supervised learning methods based on siamese representation learning to get semantically reasonable and diverse crops with the help of Semantic-Aware localization scheme and Center-Suppressed sampling scheme.\n\nThe work demonstrates the effectiveness of proposed ContrastiveCrop via means of comprehensive experiments, where ContrastiveCrop outperforms RandomCrop on most tasks. The authors show usefulness of method on both pre-training tasks as well as downstream tasks on standard datasets, comparing the method with prior state-of-the-art models.",
            "main_review": "###########################Positives##########################\n\n1. Overall the paper is well written and easy to understand.\n2. The proposed method Contrastive crop combines Semantic Information which is learned in an unsupervised manner during training, and Center-suppressed sampling to get diverse crops.\n3. The method can be easily added (plug and play) to existing frameworks and training protocols. Also the method is easy to use.\n4. The authors provide quantitative experiments to demonstrate effectiveness of the work (although the improvements are marginal in some cases)\n\n###########################Weakness########################\n\n1. The first concern I have is regarding the parameters K and alpha used. Although the authors show ablations of selecting the best K and alpha, however this is an added step that is required. Finding the best K would require running a exhaustive search on the values of K and alpha, thus increasing the effort and compute requirements.\n\nAlso it would be useful to see ablations for this across different datasets. This would show if the values of selecting K / alpha on one dataset translate to others as well?\n\n2. Secondly, for the Center-Suppressed sampling currently uses a Beta-distribution to sample crop locations. The authors mention that other schemes could also be used. However, it is not clear on how selecting this sampling distribution / scheme would impact performance. It would also be non-trivial to select such a scheme without more experimentation. \nI would wish to see a comparison for such different sampling methods.\n\n3. Regarding the update of the localization of boxes during training, the authors mention that it was updated 5 times during training for 500 epochs: \"localization boxes are updated 5 times in the whole training of 500 epochs, adding negligible training overhead.\". \n\nHow was this number 5 selected is not clear? Is this another parameter to keep track of? It should be made explicit in the paper. How does this update affect the performance? \n\n4. Finally when presenting results for Table1, where ContrastiveCrop is compared with RandomCrop, the results for only a single run are reported. It would be more valuable to see the mean performance score across multiple runs and the standard deviation for both the methods. That would show true effectiveness and robustness of the method.\n\n5. A comment: these sampling methods are tested on datasets like CIFAR, ImageNet, where there is a single object of interest. How effective will this method be in case of multiple objects, and especially in crowded images.\nWould be nice to see how the visualization of feature maps changes for such images / datasets.  \n\n\n\n",
            "summary_of_the_review": "Overall the work is nice and experiments show effectiveness. However I feel there are a few things mentioned in weakness above, that have to be made more clear to make this work useful in practice and adopted. \nClarifications to the above points, might help improve the paper and increase my confidence in the work.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes the ContrastiveCrop method for self-supervised learning. Specifically, a semantic-aware object localization strategy is proposed within the training process in a fully unsupervised manner. Meanwhile, a center-suppressed sampling is further designed to enlarge the variance of crops. Experiments are conducted on several existing self-supervised learning methods for empirical evaluations.",
            "main_review": "Paper strengths:\n- The problem studied in this paper is a fundamental task that deserves further study.\n- The proposed method is simple to implement.\n\nPaper weaknesses:\n- The proposed method is intuitive and lacks technical novelty, e.g., the threshold-like approach for localization in Eq. (2) was explored in the literature (cf. [Ref1]). Moreover, the hyper-parameter $k$ seems tricky w.r.t. the final accuracy.\n- The proposed method requires a two-stage training process, i.e., training with RandCrop firstly and then performing ContrastiveCrop. Thus, the improvements are straightforward, since RandCrop brings good initialization. Meanwhile, the two-stage training process is complicated compared with existing self-supervised methods.\n- Lacking comparison methods. Except for the RandCrop, it should involve other methods for comprehensive comparisons (due to the simplicity of the proposed approach), e.g., max-pooling based crop, etc.\n- As shown in Fig. 6, different values of these hyper-parameters produce quite different accuracies, which shows that the proposed method is unstable and robust.\n\n[Ref1] Selective Convolutional Descriptor Aggregation for Fine-Grained Image Retrieval. IEEE TIP.",
            "summary_of_the_review": "Due to the low novelty and tricky hyper-parameters, I lean to borderline reject this paper. Moreover, more comprehensive comparisons are encouraged.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes ContrastiveCrop for self-supervised learning. ContrastiveCrop improves regular RandomCrop by semantic-aware localization and center-suppressed sampling. Different datasets and SSL baselines are used for evaluation. ",
            "main_review": "Pros:\n+ The paper is easy to read.\n+ The proposed method of ContrastiveCrop is very simple and well-motivated.\n+ I like the experimental part of comparisons with other transformations.\n\nCons:\n- The technical novelty is limited. The semantic-aware localization scheme is common and straightforward. I also wonder how it works for hard images containing multiple objects. Moreover, although the goal is not precise localization, it would be better to conduct comparison experiments using ground-truth bounding boxes and other possible localization methods. That would show how the localization affects the final performance. The center-suppressed sampling is also a simple sampling method. Similarly, other choices should be compared to better understand its effect.\n- The performance is not strong to support the contribution. The evaluation on small datasets is less useful compared to ImageNet-1K and downstream tasks as the significance of self-supervised learning methods is learning from unlabeled large-scale datasets and benefiting downstream tasks. Can the authors provide full results of four SSL baselines for ImageNet-1K in Table 2 and 4? Why are the results of MoCo v1 in Table 2 and 4 are different? In Table 2, It seems the reproduced results of baselines are worse than the original paper (e.g., in original paper, Moco v1: 60.6, SimCLR: 69.3, SimSiam: 68.1). The low baselines can not well support the effectiveness of the proposed method. \n- For ablation study, Figure 6 shows the high sensitivity of hyper-parameters. \n- How can ContrastiveCrop improve other positive selection methods mentioned in section 2.2 which are based on RandomCrop?\n- It lacks specific training time comparing baselines and ContrastiveCrop.\n\n",
            "summary_of_the_review": "This paper proposes a simple idea to improve RandomCrop in self-supervised learning. However, the technical novelty is limited, the proposed method is not well compared with other possible choices, and the experiments are not strong to support the contribution.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}