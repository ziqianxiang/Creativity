{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper analyses speedup of variational quantum algorithms by a data-parallel architecture that distributes data over a set of NISQ quantum computers. The data are quantum-encoded using amplitude coding and a standard neural net ansatz is trained using gradient backpropagation. The noise model of a depolarizing quantum channel is used. The experiments are performed in a simulator using a classical computer. The QNN is trained on a small subset of low-resolution MNIST dataset.  The experiments suggest that increasing data parallelism speeds up computation linearly for NISQ  QC but for idealized QC the speedup is only sub-linear. ",
            "main_review": "The authors consider a straightforward extension of the data-parallel neural net training with error backpropagation to quantum neural nets. \nThe description of the problem setup is technically sound and quite lucid despite somewhat improvised English grammar. The experimental results on speeding up QNN training to a criterion accuracy are somewhat confusing though: the disparate results for the ideal (sublinear speedup) vs noisy (depolarization channel) case seem to be due to communication overhead for the NISQ case. This seems to imply that in ideal case computations take less time resulting in greater relative contribution of communication to the total compute wall clock time. If that's the case, there's nothing quantum-specific about this finding. This needs to be expressed more clearly. \nThe test accuracy dependence on the number of processors is puzzling since it increases with the number of nodes but suddenly drops for W=32. This needs explanation.\nONly one form of quantum noise is considered (depolarizing channel) while other important sources of NISQ quantum noise (qubit, correlated XOR gate noise) has not been addressed. This and the fact that only one very small dataset is used in experiments does not lend credibility to the sweeping generalizations that the authors claim. \n",
            "summary_of_the_review": "While the authors do great job with the problem exposition, their approach and results do not support strong claims they're making.  \nSpecifically, my biggest concern is that one really interesting observation (linear speedup for the NISQ case) is actually an outcome of the  classical part of the considered architecture. If that's really the case, these results do not shed light on specifically quantum effects on parallelization of quantum computing. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper studies the problem of distributed training of variational quantum algorithms. It proposes a quantum distributed optimization scheme (QUDIO) to partition the training data into multiple parts and then perform parameter training on multiple machines with different data. The parameters are then averaged with a centralized server. In this way, the training process can be accelerated.",
            "main_review": "Strength:\n1. The paper proves an asymptotic convergence between the proposed scheme with conventional VQAs on a single quantum machine. \n2. The paper provides empirical results on the QNN task to show the speedup achieved by distributed training.\n\nWeakness:\n1. Major. The idea of distributed training of VQA is not new and the proposed scheme is similar to a standard distributed training protocol in classical NN training. What is the major difference between this work and [1][2][3][4]?\n2. Major. If the major contribution is the proof of the convergence of QNN distributed training, what is the difference between the work to the convergence proofs in previous classical noisy distributed training work such as [5]?\n3. Major. The paper assumes depolarizing error, how to justify the proof of coverage can be applied to different kinds of noise, such as thermal relaxation errors.\n4. Minor. Is there any assumption on how the gradients are obtained? Do you require precise gradients? As we know, backpropagation can not be performed on quantum machines and parameter shift is very costly. \n5. Minor. The paper says \"decomposing the given problem in Q parts\" is a little misleading. It makes readers think that QIDIO is performing model parallel training but it actually only performs data-parallel training.\n6. Minor. The empirical results can be further improved. Currently, only one task is considered. More importantly, there are no experiments on real quantum machines such as on public available IBMQ machines.\n7. Minor: the citations should use \\citep so that there will be parenthesis.\n8. Minor: page 3 \"The source code of QUDIO is available at the Github repository xxx.\"\n\n\n[1] Narottama, Bhaskara, and Soo Young Shin. \"Quantum Federated Learning for Wireless Communications.\" Journal of the Korean Institute of Communication Sciences (2020).\n\n[2] Chehimi, Mahdi, and Walid Saad. \"Quantum Federated Learning with Quantum Data.\" arXiv preprint arXiv:2106.00005 (2021).\n\n[3] Chen, Samuel Yen-Chi, and Shinjae Yoo. \"Federated quantum machine learning.\" Entropy 23.4 (2021): 460.\n\n[4] Li, Weikang, Sirui Lu, and Dong-Ling Deng. \"Quantum federated learning through blind quantum computing.\" Science China Physics, Mechanics & Astronomy 64.10 (2021): 1-8.\n\n[5] Adilova, Linara, Nathalie Paul, and Peter Schlicht. \"Introducing noise in decentralized training of neural networks.\" Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, Cham, 2018.\n",
            "summary_of_the_review": "The quantum distributed training idea is not new; the theoretical proof is important, but the authors need to justify the novelty of it compared with the proof of convergence of classical distributed training and how it will be generalized to arbitrary quantum noise. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a distributed model of variational quantum algorithms, a quantum computing counterpart of classical neural networks. In theory, the paper proved a convergence result for their model under near-term quantum computers with depolarization noise channel. In experiment, the paper conducted various experiments for image classification and learning the ground energy of hydrogen molecules.",
            "main_review": "From my perspective, the main contribution of this paper is the proposal of a distributed computing model of variational quantum algorithms. As claimed by the paper, the model QUDIO is the first distributed scheme of variational quantum algorithms with theoretical guarantee. In addition, on the one hand, the theory guarantee of this paper, Theorem 1, even considers some near-term attributes, especially noise. On the other hand, the experiments of the paper cover both applications in quantum computing (VQE) as well as machine learning (image classification). In all, the contribution of this work is worth noting to both the general community of quantum computing and classical computing.\n\nNevertheless, although this work is a nice start of the potential line of research of combining quantum computing and distributed computing, I feel that it does not make much effort in further exploitation. To be more specific, perhaps the following points can be better explained:\n\n- The foremost issue I can think of is the connection to the machine learning community. Since ICLR 2022 is a top conference in deep learning and AI in general, the authors may want to think more about how the machine learning community can benefit from this work. To me, the perspective of this result is too much on the quantum computing side. Why does this paper suit better to ICLR rather than a journal in quantum physics? The authors should give a better answer to this. In particular, speaking of Algorithm 1, the idea is very straightforward by replacing each classical core by variational quantum algorithms when doing SGD. The application of image classification is indeed quantum, but I don’t see immediately how this can be better than the state-of-the-art tools in CV. (If there’s evidence that VQA can be better than say ResNet, that would be super interesting, but I doubt that’s the situation. It’s more like this model QUDIO can run image classification, but the advantage from the machine learning perspective is unclear to me.)\n\n- In general, the authors might find better connection to ML by answering my question above. Note that the model might also have connection to some popular models such as federated learning, so it would be interesting to discuss how it generalizes there. I notice that the authors had some discussion at the end of Section 2 that their proposal is inconsistent with classical optimization methods, but this is a bit too passive to me because I feel that distributed NN results should be helpful for QUDIO. At least, SGD is quite vanilla and there might be better ways for training models. \n\n- In the quantum computing side, I also feel that some technical details can be further explained. On the one hand, the paper mentions that “the deployed quantum processors are allowed to be any type of quantum hardware such as linear optical, ion-trap, and superconducting quantum chips”, maybe this can get into a bit more details? I’m asking because the implementation of quantum computers is developing fast but still only have dozens of qubits for now, maybe experimentalists have thought about the practical issues of working with distributed computing? On the other hand, in Theorem 1 the paper mainly focuses on the depolarization channel, why not consider other kinds of noise channels that may happen in practice? How does that influence the theoretical guarantee in Theorem 1?\n\n-  Some typos:\n-- In many places throughout the paper, there should be brackets for the references. For instance, the first line of Section 1 should be (Goodfellow et al. (2016)) instead of Goodfellow et al. (2016).\n-- In the second-but-last line in Page 1, maybe it looks better to write (Huang et al. (2021a;b)) instead of Huang et al. (2021b;a)?\n-- At the very end of Section 1, xxx should be replaced by the link in Footnote 1.\n",
            "summary_of_the_review": "Based on the points I mentioned above, I recommend weak acceptance for this paper at ICLR 2022. On the one hand, the proposal of distributed models of variational quantum algorithms is natural and the paper provides both theoretical and experimental guarantees. But on the other hand, the paper should seek for tighter connection to the machine learning community as well as better explanation of some details.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The authors propose a distributed scheme for performing optimization for variational quantum algorithms such as VQE and QAOA. In essence, the strategy to perform optimization is to start the central server with an initial guess, distribute these initial parameters to Q workers, have each worker independently perform W optimization steps, then aggregate the results in the central server and perform a simple averaging. This process can be iterated until convergence. They conduct simulated experiments to verify that the proposed scheme improves the convergence rate.",
            "main_review": "Concerns and comments:\n\n\t- In Contribution 3, \"QUDIO realizes sublinear and even superlinear speedups.\" This is awfully confusing, superlinear and sublinear are very different things. The sentence sounds like QUDIO either gains a worse-than-linear speedup, or greater-than-linear, but not linear.\n\n\t- In basic notations, Psi indexes from i = 1, but then the normalization restriction indexes from i = 0.\n\n\t- The kets |0> and |1> are explicitly defined but the notation |psi><psi| isn't. I'm not sure who the audience of this paper is if they're expected to know bra-ket notation but aren't expected to know the meanings of |0> and |1>.\n\n\t- No intuition is provided for what a depolarizing channel means. The equation for such is shown, but p is not defined as far as I know . This makes me think the audience is intended to be specifically experts in the field of quantum physics, rather than the average audience member of ICLR.\n\n\t- Quantum neural networks: \"X \\is in R^{D_c}\". D_c is not defined as far as I found.\n\n\t- Equation 1, triple equals can mean several things in mathematics, so it could use some clarification. Furthermore, the notation \"d_Q parameters\" is used, is Q still the number of quantum backend nodes? What is lower case d, and why is it indexed by Q? Furthermore, explaining the notation [d_Q] up front would be useful.\n\n\t- Minor: shifted parameters are mentioned without a clear motivation for them. Perhaps this is another instance where expert knowledge in QM is assumed.\n\n\t- Section 3, bullet #2, \"with slight abuse of notation\". To me, this indicates that I don't really have a solid grasp on the notation by this point, since I didn't recognize it as an abuse of notation.\n\n\t- Is there any reason at all to think that plainly averaging together parameters is good to do? If the problem is convex, perhaps it makes some sense. For a non-convex problem however, I'd imagine running simultaneous optimization steps and averaging together the result would result in worse-than-unaveraged update steps. I'd be happy with more justification on this simple average. Could a weighted average work better where the weights are (inversely) proportional to the cost for each independent node?\n\n\t- Section 4 first paragraph primarily seems to be repeated information from previous sections.\n\n\t- Eq. (6) seems like a repeat of Eq. (4), at this point I'm no longer clear on the difference, possibly due to notation. For example, \\pm j I think indicates shifts? But see the previous comments, the shifts were never explained.\n\n\t- Eq. (7) what does \\cal{L} with an overbar mean, as opposed to no overbar?\n\n\t- Theorem 1, defining what \"the smooth constant of L\" is would be helpful. A Lipschitz constant is pretty standard, but I'm not sure what the smooth constant of L is in comparison to a Lipschitz constant. Nonetheless, I personally can't confirm the correctness of this theorem given the time constraints.\n\n\t- Dataset has 756 images, 256 training and 500 test, then they \"downsample them to 8x8, vectorize, and normalize\". I'm curious to see what MNIST looks like after doing so, I imagine the difference between a 5 and 6 and an 8 and 0 would be quite subtle after a downsampling and normalization.\n\n\t- Physics: Only depolarization is considered. Other noise sources exist and go unaccounted/unmentioned.\n\n\nTypesetting/Typos:\n\n\t- In main contribution 1, \"But also motive us\".\n\n\t- In basic notation, \"are applied to formalize the evolving of qubit states instead of unitary\".\n\n\t- Typesetting Eq. (4). The exponent is (t.+j). Is it different that the power (t,-j)? Regardless, there may be a better way to denote things.\n\n\t- Its mentioned multiple times that eta is the learning rate.\n\n\t- Its mentioned multiple times that (x,y) are data samples.\n\n\t- Depolarizing noise is first denoted \\cal{E}_p(\\rho), then it gets changed in section 4 to be \\cal{N}_p(\\rho). Overall, it seems like multiple things get redefined throughout, sometimes without notice.\n\n        - Notation. Caligraphy font means \"channel, unitary group, data set, loss function, individual quantum backends (nodes)\" at different points throughout. Sometimes vectors are bold, sometimes in regular font, sometimes in bra-ket notation. Greeks mean \"density matrix, quantum state vector, learning rate, bounding constant\". Unit vector notation switches throughout. Uppercase might mean an integer, operator, observed quantum state, and the list goes on. There's seemingly no consistency (and see the previous comment on redefining things without notice) and this makes the paper very hard to follow for me.\n\n\nQuestions:\n\n \t- Why use a l_2 regularization penalty for the parameters of the ansatz? Regularization is used in NN learning to prevent overfitting. I don't think the magnitude of quantum circuit parameters (all in [0,2pi)) has anything at all to do with overfitting. This regularizer will bias the optimization.\n\n        - If I'm understanding correctly, 32 * 8 qubits are used for some experiments. That's an unrealistic number of qubits. Finding a single reliable NISQ device with 8 qubits is possible, finding >5 of these? Probably not. Even if multiple quantum computers with 8 qubits are found, the overall reliability and individual differences in error profiles would make any computation with them hard-or-impossible to interpret. This feels unrealistic.\n\n        - This overall scheme appears to get blocked if any device gets hung up. For example, access to real quantum backends typically requires submitting jobs to a queue. If one node's queue is long, it seems like the distributed scheme is blocked until the slowest node finishes its computation. Is that correct? If so, its unclear to me if distributed would have any advantage over non-distributed since the user would be subject to the mercy of many queues, which at least in 2021 are the most significant bottlenecks in any variational quantum optimization.\n",
            "summary_of_the_review": "I didn't really understand why there is no communication overhead other than the size of the problems (number of parameters) being very small. I may have missed something critical, but as far as I got, this communication overhead will worsen as problems and quantum hardware scale. Furthermore, I'd expect that queueing in real devices would ruin any distributed scheme, since waiting in multiple queues would be the most significant bottleneck in any optimization. As far as the actual experiments go, they are all performed in simulation and therefore are missing many of the realistic challenges that NISQ devices face today. For example, depolarizing noise is not the only noise source in real devices, and the number of simulated qubits used outpaces the scale of reliable NISQ devices available today. The notation was an impediment to my understanding as it lacks in consistency and explanation. The overall relevance to this conference is unclear. The closest category would be \"other applications\", but the work submitted has virtually no link to \"learning representations\" or associated problems.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}