{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper aims to study the roles of neurons in neural machine translation and explore how the neurons influence sentence structures. Specifically, it firstly creates a dataset consisting of paraphrase pairs and matching references. Based on the dataset, it then applies a method to visualize the correlation patterns of the network activations between a source sentence and its structural paraphrase. The results imply that sentence structure is captured by the model in a decentralized way. \n\n\n",
            "main_review": "Strength:\n1. The paper is well-written, and some of findings sound interesting. \n2. The dataset used in the experiments may be helpful to understanding nmt in future. \n\n\n\nWeakness:\n\n1. The experiments are conducted on a single translation task, and thus it is not clear whether the observations are consistent across different translation tasks. \n\n2. The novelty of this paper is limited. This work extends previous work (Bau et al., 2019) to analyze how the neurons influence source sentences, although it differs from previous work in that it focuses on the sentence structures rather than individual words. In addition, the analysis method is similar to that in previous work. \n\n3. Although the findings obtained from the experiments sound interesting, their practical contributions to MT community are not clear. For example, how can we improve the NMT models based on the findings?  \n",
            "summary_of_the_review": "Although some of findings in this paper sound interesting, the overall contribution is limited compared with the previous work.  ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper is on analyzing the neuron activation in NMT models. It has an intriguing idea that is worth investigating to enhance our understanding of these deep models. The authors curate a new paraphrase-based translation set in the English-German direction and use for evaluating the NMT model in terms of correlation between neural activations while generating different outputs. The analysis has interesting results.\n\n\n\n\n\n\n\n",
            "main_review": "The main problem of the paper is that it misses a definition as well as formulation of the research question and the hypotheses tested. Many of the claims and statements contain undefined metrics and terms and there seems to be a large amount of confusion in terms of mathematical and linguistic terminology, which makes the claims in the paper difficult to follow and consequently assess. (e.g. terms such as ‘similar’ positional embeddings vs. ‘correlated’ paraphrases. Such phrasing makes any claim very difficult to follow since even defining the meaning of ‘similarity’ in linguistics is an open question, as well as correlation being an ‘indicator’ - not equivalent of similarity in mathematical terms.) Clarity in each reasoning and formulation step is crucial to be able to propose and then support such claims in any scientific paper.\n\nThe first two sections play an important part in presenting the motivation and objectives of the study as well as any formulations/assumptions related to the research question. There are similarly many terms difficult to follow, e.g.\n- “neuron activation over paraphrases are explained by shallow features, the positional and token embeddings” the fact that information is correlated with some features does not necessitate that the phenomenon is explained by these, the authors should beware the limitations in their experimental design and findings before reaching generic conclusions, since the internal dynamics of functions operating in a high-dimensional vector space may not be captured easily by a correlation study \n- Invariant semantics: invariance is a mathematical term, and it means insensitivity to change. similar meaning is clear enough, if preferred can be extended to explain what is considered semantic similarity\n\nThere are some open questions about the experimental design, e.g. the choice of correlation metric and why it should explain high-level dynamic behavior in the neurons was never discussed. There are a lot of studies that perform pruning and dynamic analysis with network activations, so it is worth at least to mention why such approaches were discarded. Another question is on the positional embeddings, since the authors use the constant embeddings what is the real extent of measuring the similarity of these? The authors claim paraphrases must have similar length and therefore encode exactly the same position information, but is there any proof on the data set at least that this is true?\n\nIn overall the paper presents an interesting experiment but seems to fail in acknowledging its limits and point-of-view in a fair and sound fashion. I would really suggest rethinking the main motivation of doing this study and what are important things to learn from these findings.",
            "summary_of_the_review": "The paper presents an interesting point-of-view but requires rewriting the definition and formulation of its research questions and revising the claims to ensure it's scientifically sound.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper studies the activation pattern of neurons of a Transformer translation model for two controlled meaning-preserving tasks. To this end, the authors have created two machine translation datasets to be used for their study. In one dataset they change sentences from active voice to passive voice in a meaning-preserving way. In the second dataset, they paraphrase the sentences by changing the adverbial clauses to a meaning-preserving noun phrase. They use the correlation between neurons for different sets of controlled inputs to detect the neurons that are the most sensitive to the manually controlled change. For example, they compute the correlation between neurons for active sentences and their corresponding passive forms to detect the neurons that attribute for the voice of translation. They use these correlations to change the activation of the detected set of neurons to control the voice of translation. For example, translate active sentences to their passive counterparts ( and vice versa).\nThey empirically show that by changing the detected neurons, they can control the voice of the translation from active to passive (vice versa) for most of the sentences.",
            "main_review": "I like the idea and the way that correlations are used to detect the neurons. Especially the way that \"PosCorr\" and \"TokenCorr\" are used to dissect the correlation patterns. I also find the created datasets quite useful for similar studies if they will be made available to the community. It's also very nice that they empirically show that the idea of controlling the form of translation by changing the neurons works in the cases under the study. I found the paper also clear for the most part. \n\nHowever, although the contribution of the paper is nice, I find it a bit marginal for the ICLR conference. This is because the idea of using correlations to detect and manipulate the neurons is introduced and used earlier in other works, for example by Bau et al. (2019). One difference I noticed is that this study is conducted on Transformers whereas theirs is on LSTM encoder-decoder models. Another difference is the way that the correlation pattern is dissected by the other two introduced correlations. \n\nI also found it a bit difficult to understand some of the parts.   \n     \nBefore getting into the clarity issue, I think it would be better to change \"+\" to \"&\" in Figure 5. I assume that \"pos+para\" means neurons that exist in both sets of top neurons of \"pos\" and \"para\". However, Figure 5 is still very difficult to interpret. It is not clear how it has been produced. For example, let's say we select the first 20 percent of the top neurons in the \"para\" set. In what percent of the top neurons of the \"pos\" set the neurons are looked up to compute the intersecting percentage? How this percentage changes for other amounts of the top neurons of the \"para\" set.\n\nThe authors truly mention that BLEU may not be a good metric to measure the change in the form (active vs passive) of translation and good or bad the meaning is preserved. To this end, they introduce a passive score to measure the change in the forms. However, this score is not clearly and sufficiently discussed. It is not clear for the reader how (in)significant is the reported change of this score in Figure 3b. As a result, it is not clear to the reader that how effective the manipulation towards generating passive translation is. I suggest making it clear for the reader what exactly this score means and how meaningful is the change made to it as a result of manipulation of the neurons. This also shows to the reader how meaningful is the difference between \"top\" and \"bottom\" cases in Figure 3b and whether the \"top\" case of manipulation is meaningfully better than the \"bottom\" case.\n\nAuthors report the percentage of passive sentences in the case of baseline (no manipulation) for active and passive input. However, It is not clear why they do not report this percentage in the case of manipulated translation. This could have provided a good comparison with the baseline (no manipulation) translation. I suggest that the percentage of passive sentences be reported at least for the case of manipulated translation of active voice to passive voice.  \n\nsome minor issues:\n\nIn section 7, it is said that Yamagishi et al. 2016 has controlled voice in Transformer translation. This is while Transformers were first introduced in 2018. Yamagishi et al. 2016 explicitly say that they use the attentional encoder-decoder model by Bahdanau et al. (2015).\n\nIn the introduction, it is said that the strongest correlations are not due to high-level abstractions while in the conclusion, exactly the opposite is said.\nFrom the introduction: \"This suggests that the strongest correlations are incurred by similar input encoding and not by high-level abstractions learned by the model\"\nFrom the conclusion: \"Our results imply that the strongest correlations observed are due to the input representation, and to high-level abstraction\"",
            "summary_of_the_review": "In general, I found it a nice paper. However, I think the contributions are still a bit marginal. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper analyzes neurons responsible for two syntactic phenomenon and manipulate them to achieve a desired output. They compile a paraphrase dataset consisting of active/passive voice examples and adverbial clause/noun phrase examples. Given a certain property say, active/passive voice, they identified salient neurons by calculating correlation between activations of neurons.\nThe authors analyzed the correlation pattern in comparison to the positional encoding and lexical identity and found that these factors are the main contributors to the correlation between paraphrases. Further experiments are conducted to control translation output by manipulating the selected neurons.",
            "main_review": "The contribution of the paper, in my opion, is the creation of paraphrase pairs and performing sentence-level manipulation. Since the paper is mainly building on the previous work's methodology, I would like to see more in-depth discussion on either selected neurons or manipulation. The paper touches both of them and while reading it, I felt that it is not doing justice to either of them.\n\nQuestions and comments:\n\nSalient neurons related:\n- I would like to see more information on the salient neurons.  How many neurons did you find salient to the paraphrasing task?\n- From which layer did authors observe the most salient neurons?\n- The comparison of correlated neurons with positional encoding is done for first layer only right? Did you see similar findings for the higher layers? What about decoder?\n- Although taking the last sub-word token activation is supported by literature, I don't know why it makes sense for the transformer models and taking the average activation of subwords sound more logical. AFAIK, the last sub-word activation was mainly motivated from the LSTM models.\n\nManipulation related:\n- did authors change the activations of neurons for a particular word or for the full input sequence? \n- How many neurons need to be manipulated on average?\n- Does manipulation performance differ for lower layers and for higher layers?\n- What about manipulating neurons of the decoder?\n- Figure 2c, any idea why random and controlled selected neurons have similar behavior?",
            "summary_of_the_review": "The paper is interesting. The paper has very limited technical contribution. The dataset is one contribution, although it is not an extremely challenging dataset to make and the size of the dataset is quite small to consider it as a major contribution of the paper. I am generally okay with limited technical contribution if paper has in-depth and detailed analysis which unfortunately is missing. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a framework to understand NMT models by identifying and controlling the important neurons. The main idea is to examine the correlation of activations within the model on different paraphrased sentences. The paper generates and filters a dataset from the WMT test set that changes active to passive voice or adverbial clause to noun phrase. Using this dataset, the authors are able to modify the neurons that are more correlated to active/passive voice and somewhat control the translation result.",
            "main_review": "The paper proposes an interesting study that aims to understand the NMT models. The strengths are\n1. the paper is reasonably well organized and follow. The paper also proposes a method for collecting paraphrase dataset that might be valuable to other scenarios\n2. There are good analysis on whether one can control the neurons to affect the syntactic structure, and whether one can select a subset of neurons to improve the quality of control.\n\nWeakness\n1. Seems like the authors use a set of sentences to compute the correlation value, then modify the model and evaluate on the same set of sentences? I wonder if this counts as seeing your own test data? Should you consider compute the correlation value use a \"train set\" and control the syntactic structure on a separate \"test set\"?\n2. Would the method extend to more complicated scenarios, such as controlling the domain of the test sentence? Although the given results are already interesting for understanding, it might make the proposed method more useful in practice.\n",
            "summary_of_the_review": "I think the paper is interesting but there might be some issues that the authors need to clarify regarding the evaluation.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}