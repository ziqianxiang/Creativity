{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper studies out-of-distribution (OOD) generalization of GNNs by conducting comparative experiments on various datasets. The main conclusion of the paper is that: (1) most previous OOG generalization algorithms do not suit graph scenarios; (2) choosing appropriate GNN models and augmentation techniques help OOD generalization.",
            "main_review": "Pros:\n(+) OOD generalization for graphs is a critical problem yet only begins to draw research attention.\n(+) This paper conducts extensive experiments, and the authors prepare to release them as an open-source package.\n(+) The paper is generally well-written and easy to follow.,\n\nCons:\n(-) The technical contribution of the paper is severely limited. Specifically, though I appreciate the extensive experimental efforts, this paper provides no theoretical or methodological justification for the conclusions, making the pure empirical results susceptible. Besides, many of the experimental settings and/or results are studied in the literature (e.g., see OGB paper and some references below) and therefore should not be considered the contribution of this paper.\n(-) Some experimental designs are flawed or inconclusive. First, for the GossipCop dataset, the authors wrote in the appendix that “multi-layer perceptron (MLP) can achieve 0.948 accuracy which is even higher than the accuracy of a GIN” and therefore “replace all node features with random integers.” It seems that this dataset is not suitable for considering OOD generalization for graphs. Besides, the authors do not consider most representative GNNs such as GCN, GAT, SAGE, etc. Therefore, it is unclear whether the conclusions drawn in this paper apply to these most basic GNNs.\n(-) Many related works are missing. For example, considering generalization of MNIST within GNN scopes is originated from [1]. Besides, theoretical understandings for GNN generalization are also studied in [2][3]. \n\n[1] Understanding Attention and Generalization in Graph Neural Networks, NeurIPS 2019.\n[2] Generalization and Representational Limits of Graph Neural Networks, ICML 2020.\n[3] How Neural Networks Extrapolate from Feedforward to Graph Neural Networks, ICLR 2021.\n\n",
            "summary_of_the_review": "In summary, this paper provides some empirical evidence for OOD generalization of GNNs, but the lack of technical novelty, flaws in experiments, and missing of related works makes the current paper not strong enough for acceptance.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper develops a framework to conduct graph-distribution-shift experiments on several datasets with distribution shifts across training and testing graphs. Some classical domain generalization algorithms are realized in this framework with GNN backbone model. The authors conclude that most domain generalization algorithms fail to improve the generalization performance when applied to the diverse types of domain shifts. The optimal combinations of GNN models with strong graph augmentation can achieve SOTA performance.",
            "main_review": "This paper focuses on an important research problem, i.e., domain generalization on graph distribution shift. It develops an open-source framework GDS consisting of several datasets with distribution shifts across training and testing graphs. Some classical domain generalization algorithms are realized in the proposed framework. Many evaluation experiments are conducted for comparison.\n\nHowever, I have the following concerns:\n\n1. The novelty of the method is limited. The classical domain generalization algorithms in this work have been proposed by the existing works for general situations. The main extension of the method is to use these algorithms in the graph setting. The technical contributions are sound but too limited.\n\n2. The paper is not well-motivated and many details are missing, which could lead to some confusions. For example, the formal problem definition is not described clearly. The motivations to choose these domain generalization algorithms in the experiments should be well explained. Some important baseline methods (domain generalization, generalization on graphs) are missing in related works. \n\n3. Some necessary analyses and evaluations are not well present, leading that some of the main claims of this paper are not convincing enough. The hyper-parameters of some domain generalization algorithms have a significant influence on the performance (just as the authors show in experiments), so these hyper-parameters should be carefully tuned to achieve good performance. However, the settings of some hyper-parameters are somewhat arbitrary (e.g., Is 500 times iteration for IRM penalty annealing good enough?). If the hyper-parameters are chosen arbitrarily, it is normal for the results to be worse than ERM. And the reasons that the generalization algorithms fail should be analyzed more deeply. Moreover, the settings of experiments are not discussed in detail, leading to the concern for a fair comparison. More explanations for the experimental results should also be introduced to the readers for better understanding. Some baselines (domain generalization, generalization on graphs) are also missing in the experiments, which is of great importance for the released benchmark.  I think the main claims should be supported more adequately by both intuitive descriptions and empirical results.\n\n4. The writing needs improvements for clarity. There are many puzzling expressions or grammar errors, e.g., the last sentence in Page 4, the first sentence in Sec. 3, the last sentence in IRM paragraph in Sec. C.1.1, the first sentence in DANN-GRAPH paragraph in Sec C.1.2 (“as it use”), etc. I strongly suggest the authors to proofread the manuscript thoroughly.\n\nMore suggestions:\n1. The authors say they provided an open-source package GDS benchmark, but I do not locate it in supplementary material or a link to the code repository. (If I missed it, please let me know.) Because of the important role of the experiments in this work, it is necessary to allow reviewers to check the code at least superficially to confirm the correctness.\n2. It is interesting to consider automated graph augmentation for structural augmentation in “Graph Contrastive Learning Automated (You et al. 2021, ICML)” besides the strategies in (You et al. 2020) as the authors do. One of the two conclusions in this paper is about the optimal combinations of GNN models and strong graph augmentation techniques. Could this automated graph augmentation that is more strong and flexible augmentation potentially lead to better performance?\n\n\n",
            "summary_of_the_review": "This paper focuses on an interesting problem and develops an experimental framework for graph domain generalization. The main weaknesses are from the novelty, clarity, and insufficient analyses.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper studies out of distribution generalization problem of graph classification/regression empirically and proposes datasets, base models, and domain adaptation algorithms. ",
            "main_review": "Strengths:\n1. Generalization ability of GNN is a hard and important problem, this paper designs a starting platform to test generalization abilities of existing GNNs and domain adaptation algorithms. Future researchers may found their code useful.\n2. Extensive experiments are conducted, and data augmentation seems perform best which can motivate more work along data augmentation on graphs. \n\nWeaknesses\n1. Lack novelty. To me this work only combines several parts together without much *organization* and interesting research questions. All experiments are run without much guideline and useful conclusions. This work looks more like an empirical evaluation of existing algorithms for out-of-distribution generalization problem on graph. All I learned from the paper is all these numbers (without much meaning) without any insight for solving generalization problem. \n2. Lack organization. The writing style is more like an empirical report: present datasets, baselines, and then present numbers. I feel reading all these pieces without organization is *too easy to lost*. If the author can organize all experiments by important research questions for OOD generalization problem that would be more interesting. So far the work is more like a workshop paper and is not ready to publish. \n3. Lack of deeper analysis of OOD generalization. OOD generalization (also extrapolation) is a very hard and important problem in graph area which deserves a lot analysis and thinking in future. I would expect the author can analyze the problem essentially and then design experiments.  ",
            "summary_of_the_review": "I vote for rejection: the paper studies OOD generalization problem on graph empirically, without much new insight for future researchers. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}