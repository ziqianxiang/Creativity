{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper studies the problem of label noise in long-tailed multi-class classification datasets which degrades the performance of learnt classifiers. Here, label noise refers to the phenomenon where a sample is sometimes mislabeled to belong to an incorrect class in the ground truth of a dataset. A prominant approach for mitigating label noise is based on the assumption that correctly labeled samples incur smaller classification losses relative to mislabeled samples according to a learnt ERM classifier and therefore the noise can be successfully recognized and denoised based on a global loss threshold. \n\nThis paper observes that such global threshold based \"small-loss trick\" fails on long-tailed datasets where ERM classifier often underfits on tail labels with few training samples. As a fix, this paper proposes an alternative distance-based thresholding strategy which instead relies on \"relative\" distances of correct and mislabeled samples for any given label. The proposed RoLT technique for denoising is demonstrated to outperform a diverse range of both prevalent long-tail classification techniques and existing small-loss based denoising techniques. Experiments are performed on datasets with both simulated and real noise settings for thoroughness of results.",
            "main_review": "Strengths:\n1) The motivation of this paper is well-grounded. Noise in long-tailed real-world datasets is a pervasive phenomenon. It is also fairly easy to appreciate that small-loss trick in ill-suited for long-tail and hence needs a fix\n2) Main experimental results are conducted using a wide-range of datasets and baselines. The proposed RoFL approach consistently attains signficant gains over all baselines on the simulated datasets, especially in the high-noise settings. This provides reasonable evidence for the main claims of this paper\n\nWeaknesses:\n1) This paper heavily relies on combining multiple ideas from previous papers. This makes me question the significance of novel ideas originating in this paper. The ablation studies largely seem to demonstrate that these borrowed ideas are crucial for the success of RoFL which further weakens the contributions of this paper.\n    * DivideMix also uses Gaussian mixture model for separated the noise similar to RoFL. It is unclear how different is RoFL from DivideMix algorithmically\n    * A major portion of RoFL gains are due to \"pseudo-labeling\" augmentation. However, the methods used for this (e.g. ERM/NCM etc.) are already well-known\n    * For final results, the Deferred Re-Weighting (DRW) trick from Cao et.al. is also used which accounts for 1-2% of final RoFL gains\n2) There is substantial scope for improving the clarity of presentation in the introduction and method sections\n    * Figure 1 and 2: experimental setting and explanations for observed behaviour are missing\n    * Citations should be inside brackets to avoid confusion\n    * \"As many previous literature, it is reasonable to assume clean examples tend to be clustered around their prototypes even when\n    training with noisy labels\": provide clear references\n    * \"More importantly, many existing methods can be easily integrated into our framework, leading to\n    noticeable performance improvement\": this claim is not adequately demonstrated or explained later on\n    * Important terms such as \"label noise\", \"small-loss trick\", \"many,medium,few\" as well the basic setting of \"multi-class classification\" are utilized in the first few sections but defined much later in the paper. As a result, the first half of this paper is hard to understand\n    * What is \"RoFL+\" ?\n3) Experimental results are inadequate at demonstrating the utility of the proposed technique: \n    * RoFL shows major gains in only simulated noise based experiments (Section 4.1). However, the used model for simulating noise is a new one which gives higher importance to frequent labels. No clear scientific justification is provided for this new model. No results have been provided with the original, and more widely adopted, uniform-noise model. As a results these major gains cannot be fully trusted.\n    * The gains on real-world WebVision and ImageNet datasets are not significant relative the main competing baseline DivideMix (Table 4). Note that Table 5 again uses simulated noise and hence is not \"real\" in true sense\n4) The main terchnical arguments of this paper need additional justifications:\n    * If the main argument of this paper is about the limitations of \"global threshold based small-loss trick\", then an obvious baseline would have been \"adaptive threshold\" based small-loss trick where the thresholds for tail labels are differently set to be smaller than those of popular labels. Such simple variants are not considered in this paper\n    * The proposed multi-stage approach for GMM optimization, based on prototype initialization, GMM fitting, prototype refinement (Algorithm 1), is not compared against standard algorithms for GMM optimization such as expectation-maximization with random initialization etc. Since this is a main algorithmic contribution, such comparisons are critical\n5) Minor errors:\n    * closed to their corresponding prototypes: \"closed\" -> \"close\"\n    * we aims to refine: \"aims\" -> \"aim\"",
            "summary_of_the_review": "The paper addresses an important problem of handling noisy ground truth in long-tailed multi-class classification tasks. The RoFL approach proposed in this paper is well-motivated and the authors conduct a wide range of experiments to validate their claims. However, the paper has significant drawbacks such as limited technical novelty, insufficient experimental justification and unclear presentation. These limitations are severe and therefore the paper is not yet ready for acceptance at a venue like ICLR. \n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this work, the authors aim to tackle the class-imbalanced problem under label noise. First, the authors propose a new noise detection method based on prototypes of classes. Then they propose a framework called RoLT to handle the problem of noisy labels on tail classes. Experiments on both simulated and real-world datasets are conducted to validate the efficacy of the proposed method.",
            "main_review": "Strengths :  \n\n1. As far as I am concerned, this work is the first to consider noisy label problems in long-tailed datasets, although there have been many works on learning with noisy labels or class-imbalanced learning.\n2. The proposed noise detection method is novel and effective in this problem setting. In particular, the authors propose to detect noisy labels in tailed classes by the distance between the class prototype and the feature representation of each sample.\n3. The performance improvement of the proposed method is impressive compared to existing works on learning with noisy labels or class-imbalanced learning. \n\nWeaknesses :\n\n1. In this work, the authors only consider symmetric noisy labels under long-tailed settings. Generally, asymmetric noisy labels would be closer to the real-world noisy label problem and are more difficult to handle compared with symmetric noisy labels. It would be better if the authors could verify the effectiveness of the proposed detection method and the robust framework under asymmetric noisy labels.\n2. The writing of the paper should be improved. For example, the first sentence in subsection 3.2 is very strange since “this commonly used method” is not introduced.\n3. Both the proposed detection method and the framework are heuristic and do not provide extra insight for the community, although the proposed method could achieve impressive performance as reported.\n4. Considering the new problem setting in this work is a combination of label noise and class imbalance, a natural baseline is to simply combine the methods in learning with label noise and class-imbalanced learning, such as Dividemix + LDAM loss. Comparing the proposed method with Dividemix or LDAM separately is not fair.\n",
            "summary_of_the_review": "Overall, the problem setting in this work is new and the method could achieve impressive performance. However, the method is not interesting since it does not provide extra insight for the community. In addition, the comparison in experiments is not fair. In this concern, the contribution of this work is limited so that I recommend a score marginally below the acceptance threshold",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper revisits the long-tailed learning by considering a more practical scenario where there exist mislabeled data samples. Compared to the classical noisy-label setting, the authors show that the commonly adopted small-loss trick fails in long-tailed learning. To detect noisy labels in long-tailed data, the author proposes to use the distance-based prototypical noise detection method. The authors then proceed to build the framework RoLT to learn from long-tailed noisy data. Extensive experiment designs demonstrate the effectiveness of the proposed noise detection method and the robustness of the RoLT framework.",
            "main_review": "$\\textbf{Strengths}$\n\n- The authors introduce an interesting observation: the distance distribution between data samples and the class prototype differs in clean and noisy labels.\n\n- The authors give a prototypical noise detection method in long-tailed learning with noisy labels.\n\n- The authors propose a robust framework RoLT, which results in promising empirical performances on various benchmark datasets.\n-----------------\n$\\textbf{Weaknesses}$\n* **Missing discussion about several prototype-related works** I would strongly recommend authors to discuss or compare with several closely prototype-related works. For example, \n    * In the long-tailed learning, [1] proposed to use prototype strategies, and explored the idea of feature prototypes to handle long-tailed recognition.\n    * In the self-supervised learning literature, [2] also shows its amazing performances on semi-supervised and self-supervised learning tasks where the low-quality pseudo labels may shed some light on the scenario where the labels are pseudo labeled and wrongly labeled. \n\nIt would be better if the authors can highlight the differences between the proposed methods and these two related works. Otherwise, it would be unclear for reviewers to evaluate the novel contributions of this work. \n\n* **Experiment designs and missing relevant baselines**  To show the effectiveness of the proposed methods, the authors mainly adopt the following two families of baselines: (1) Methods targeting long-tailed learning with clean data. (2) Methods targeting learning with noisy labels (only DivideMix).  To me, I feel like the performance degradation for all baselines is not very surprising. Since their designs are not specifically targeting long-tailed noisy data. It would be better if authors could discuss or compare with some other closely related works which have shown robustness in long-tailed (class-imbalanced) noisy data, for example:\n     * ELR+, strictly speaking, this method may be viewed as another SOTA method like DivideMix.\n     * [3] showed impressive performance on class imbalance and noisy label problems where only a small amount of clean validation data is available.\n     * [4] adopted unequal treatment for head and tail data when learning with long-tailed noisy data.\n     * I am super interested in the performance comparison between the proposed work and [5]. Since both papers share a similar problem formulation and experiment designs.\n     * Another relevant work [6] which considers the same setting as implemented in your work.\n\nAs listed above, this paper missed the introduction/discussion (or comparison) with these closely-related works. And most compared/selected baselines suffer from two points: not designed for learning with noisy labels; not designed for the long-tailed data.\n\n* **Other issues and concerns**  I listed several other issues and concerns below while reviewing this work:\n     * **Problem formulation** In section 3.1, the authors define the imbalance ratio w.r.t. classes of max/mix prior distributions. It would be better if authors could characterize the prior distribution of other classes.\n     * Not clear about the sentence ''we propose to inspect the distance statistics in a class-independent manner'' at the end of page 3. Since the assumption for the likelihood of example $\\mathbf{x}$ includes $dist(c_k, \\mathbf{x})$, which contains the class information?\n     * It would be better if authors could add some definitions/explanations on ''Many'', ''Medium'', ''All'', so that readers won't have to read until Page 8.\n     * **Definition of $d$** It would be much better if authors could define the symbol $d$ with example $\\mathbf{x}$ and class $k$ included, i.e., $d_k(\\mathbf{x}):=dist(c_k, \\mathbf{x})$ or some other choices. \n     * **Extracted feature representation $f_{\\theta}(x)$**  How do authors extract feature representations in practice? The pre-trained model obtained from the warm-up stage or a public pre-trained model?\n     *  It would be better if authors could specify the full name of a classifier for its first-time appearance, i.e., NCM (Nearest Class Mean).\n     * An example of Equation (4) would be more easily for readers to follow.\n     * How does the weight $\\alpha$ in Equation (5) influence the model performance in practice? \n     * In equation (6) and (7), should it be $\\mathbf{x_i}\\in \\mathcal{X}$ and $\\mathbf{x_i}\\in \\mathcal{S}$ in the summation?\n     * In table 1, note that most baselines are not designed to address label noise, it would be better if authors could show the performance results on the clean setting.\n     * It looks a little bit weird in the experiment designs of Tables 2 and 3. In other words, most baselines in Table 2 are not specifically designed for learning with noisy labels, but there are only 2 imbalance ratios while 5 noise levels. Similarly, for Table 3, DivideMix is a SOTA method in noisy-label learning, but here the authors adopt 2 noise levels while 5 imbalance ratios. It would be better if authors could unify the experiment designs.\n     * **Comparisons with other label noise detection methods** In Figure 4, the authors did not compare the detection performance of the proposed methods with other label noise detection methods, i.e., TracIn [7], Confident Learning [8], AUM [9], etc. It is not straightforward for readers to evaluate the effectiveness of label noise detection.\n\n--------------\n$\\textbf{References}$\n\n[1] Large-Scale Long-Tailed Recognition in an Open World. (CVPR, 2019)\n\n[2] Prototypical contrastive learning of unsupervised representations. (ICLR, 2021)\n\n[3] Learning to Reweight Examples for Robust Deep Learning. (ICML, 2018)\n\n[4] Unequal-training for Deep Face Recognition with Long-tailed Noisy Data. (CVPR, 2019)\n\n[5] Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting. (NeurIPS, 2019)\n\n[6] Learning from long-tailed data with noisy labels. (ArXiv)\n\n[7] Estimating training data influence by tracing gradient descent. (NeurIPS, 2020)\n\n[8]  Confident learning: Estimating uncertainty in dataset labels. (Journal of Artificial Intelligence Research, 2021)\n\n[9] Identifying Mislabeled Data using the Area Under the Margin Ranking. (ArXiv)",
            "summary_of_the_review": "This is an overall interesting paper and introduces some novel observations in the problem of long-tailed learning with noisy labels. However, the experiment designs of two major contributions (label-noise detection and a robust framework) are not fully convincing to me. My current score is a little bit low. But **I am willing to increase the score if some of my above-mentioned issues are well addressed.** Also, missing discussions of several crucial related works make me find it hard to evaluate the contritbuions.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}