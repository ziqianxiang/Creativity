{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The authors attempt to address current issues with controllable disentangled methods--which is that current disentangled methods do not ensure comprehensive disentanglement, and convexity of the latent space is not guaranteed. To do so, the authors first propose an abstract framework around such issues, then propose a form of regularization to address them. The authors then experimentally verify their approach in a variety of settings. ",
            "main_review": "**Main comments**\n\n- The paper is well-organized and clear. The CIR approach in Section 3.3 is quite clever and appears to be very novel. \n\n- The experimental results seem very convincing and systematic. However, it would be even better if code was provided for the experiments so verification of the results could be performed.\n\n- There is not much contribution in this paper as far as theory goes, besides Definition 1 and Equations (1) and (2), none of which are used or explicitly enforced in the proposed CIR method. Therefore I view this work as purely an empirical method. \n\n\n**Minor comments**\n\n- There are some typos, for example page 9, four lines before the appendix: \"use D^B. then\".\n\n- It seems as though $\\lambda_{CIR}$ may require lots of tuning, and even uses a schedule e.g. for GZS-Net, but the authors only state that it is used to balance with other loss terms. It would be helpful if the authors clarify exactly what they mean and why the specific schedule was chosen, for reproducibility purposes. ",
            "summary_of_the_review": "Overall, I lean towards accepting the paper. Despite some issues with reproducibility of the experiments (e.g. missing code), the approach is very novel and has a very strong experimental results. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The main idea of this paper is a loss term that convexifies the support of latent representations in disentanglement tasks. The loss term requires that convex combinations of latent codes (when one attribute is kept fixed), are reconstructed well after decoding and encoding. Experiments show this loss is helpful when added to several image translation architectures.",
            "main_review": "Strengths:\n* The motivation of the proposed loss is well explained\n* Experiments show that when the loss is combined with a few existing frameworks it provides a boost to performance.\n* Experiments on other application such as fairness.\n* The paper is generally well written\n\nWeaknesses:\nNovelty: the idea is not particularly new. Mixup regularisation is commonly used, it has also been done at the latent code level (e.g. AlignMix, Venkataramanan et al.) . Latent code cycle constraint is used in MUNIT and DRIT. So in light of the two popular techniques, their combination, namely, mixup for the latent cycle constraint is not a big leap forward in my opinion. \n\nExperiments: the experiments are not performed on the methods that are currently most popular. It would have been more interesting to see a comparison against more recent methods like StarGAN-v2 or FUNIT which are SOTA methods for image translation. If it helped advance the SOTA, I'd have been more liberal on the limited technical contribution. \n\nWriting: although the paper is attractively formatted, it is not very clearly written. I would have appreciated a clearer explanation of Elegant or I2I, including the training procedure and all the loss terms. This requires going back to the original papers, and makes the paper incomplete.  Given the unlimited appendices, I think this is a fair request.\n\n\"Perfect\" disentanglement might be a little too strong a name - the task remains challenging and methods imperfect even after the presentation of this work.",
            "summary_of_the_review": "The paper makes a relatively small technical contribution, and does not evaluate against the SOTA in the related tasks. I think its significance is not enough for acceptance. Comparisons showing improvement against the SOTA in disentanglement for image translation (StarGANV2, FUNIT, OverLORD) can increase the significance.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes two new losses that improve controlled (C) disentangled (Dis) representation learning (RL) in a generative fashion. The first loss is made of intra-/inter-attribute mutual information, to encourage improved disentanglement. The second loss is to encourage the convexity of the encoded space. The loss is a task-/dataset-related metric, where the input encoded feature is interpolated (two possible interpolations: linear and boundary random). The two losses can be seamlessly incorporated into existing C-Dis-RL methods such as GSL-Net and ELEGANT. Besides positive experimental results on benchmark datasets, the authors also show improved downstream tasks such as augmentation and debiasing. ",
            "main_review": "Strength:\n1. The proposed convexity loss is novel in C-Dis-RL.\n2. Extensive experimental results.\n\nWeakness:\n1. The first proposed loss seems like an ad-hoc trick rather than a novel and formal scientific approach. The inter-/intra-class loss has been widely adopted in many supervised learning tasks. In addition, experimental results do not completely \"disentangle\" the contributions brought by the first and the second losses.\n2. Convexity. \n1) As the authors mentioned in the related work, convexity itself has no theoretical guarantee that it can improve disentanglement. In fact, based on my understanding, disentanglement itself does not need any convexity at all. The interpolation operation in the feature space is only our user-level defined binary operation, which does not necessarily correspond to the operation in the pixel-level space. So, even if you have perfect convexity, it has nothing to do with the definition of disentanglement.\n2) with the above being said, I don't understand why the first loss and second loss are claimed to be reciprocal.\n3) The convexity loss relies on task/dataset-related metrics. This makes me suspect that the reason why the loss is useful is merely due to an additional task-specific loss. So, is it possible that any feature-level augmentation method may work? such as MixUp, adding a Gaussian noise?\n3. In recent years, the disentanglement community becomes to embrace the fact that \"disentanglement\" does not necessarily mean \"independence\" [R1]. Therefore, the proposed loss is based on independence and thus may over-penalize disentanglement, such as if two attributes are indeed more semantically relevant than others. The authors are encouraged to consider a more trending disentanglement definition such as [R2] and [R3], and more comprehensive evaluation metrics in [R4].\n4. In debiasing experiments, what are the performances of using only GSL-Net? w/ and w/o the two proposed losses?\n\n[R1] Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations.\n[R2] Towards a Definition of Disentangled Representations.\n[R3] Counterfactuals uncover the modular structure of deep generative models.\n[R4] Measuring Disentanglement: A Review of Metrics.",
            "summary_of_the_review": "The reason why convexity can improve C-Dis-RL is unclear and unconvincing, especially for the conditional-based controlled generation proposed in this paper: combine the Attribute A of image 1 with the rest attributes of image 2, which needs no interpolation at all. Therefore, my initial rating is 3.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "n.a.",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}