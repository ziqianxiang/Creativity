{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a parameter-based influence function which can be applied to explore the influence of any combination of parameters disturbance on the model whether they belong to the same layer or whether they are related.\n\nThe contributions mainly focus on the following aspects: \n1. The existing work is based on the disturbance of datasets, but this paper gives us a new perspective. They apply the influence function to the disturbance of parameters for the first time, which is helpful for us to understand the model better.\n2. They propose a flexible method which can be applied to explore the influence of any combination of parameters disturbance on the model whether they belong to the same layer or whether they are related. In the experiment, they also cited possible application scenarios of parameters in different dimensional combinations. They explored the influence of parameters on the model grouped by random selection, layer, channel, etc.\n3. They apply their method to different kinds of tasks and various fields. Their method has potential wide application.\n",
            "main_review": "Advantages:\n1. This paper starts from mathematical derivation, which provides a good theoretical guarantee for the application.\n2. The perspective of this paper is very novel. All the existing researches are focused on predicting the effects of removing training points on the model. This paper firstly proposes a parameter-based influence function which can be applied to explore the influence of any combination of parameters disturbance.\n3. This paper has given many possible applications through various experiments. They give the application of constructing a group with different granularity, which proves that the method can evaluate the impact of any combination of parameters on the model at any level, without ignoring the correlation between the parameters.\n4. This method is very flexible and has a wide range of potential applications. The method can be used to explore the influence of parameter combination interference on the model, whether they belong to the same layer or related. As we all know, we often need to understand the behavior of the model in various tasks, and the method of calculating the influence of flexibly combined parameters can help us better understand the model. Therefore, this method has a wide range of potential applications in the community.\n\nWeaknesses:\n1. The paper should talk more about the difference between optimal brain damage (OBD) and optimal brain surge (OBS).\n2. It would be better to compare this paper with other gradient based model interpretability methods (such as [1]).\n[1]. How to explain individual classification decisions\n",
            "summary_of_the_review": "In summary, this paper starts from mathematical derivation. It is novel and has a wide range of potential applications in machine learning. They propose a flexible parameter-based influence function which can be applied to explore the influence of any combination of parameters disturbance on the model whether they belong to the same layer or whether they are related, which provides a useful tool for our community to understand the model from another perspective.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes the idea of *parameter influence*.\nIn the standard training with $L_2$-regularization, we obtain the model parameter $\\theta$ that minimizes\n$$\n\\theta_1 = \\arg\\min_{\\theta \\in \\mathbb{R}^m} \\frac{1}{n}\\sum_{i=1}^n \\ell(x_i, y_i; \\theta) + \\frac{\\lambda}{2} \\|\\theta\\|^2 .\n$$\nBy contrast, if we force some of the parameters to be zeros by the mask $w \\in \\\\{0, 1\\\\}^m$, we have\n$$\n\\theta_w = \\arg\\min_{\\theta \\in \\mathbb{R}^m} \\frac{1}{n}\\sum_{i=1}^n \\ell(x_i, y_i; (1 - w) \\odot \\theta) + \\frac{\\lambda}{2} \\|(1 - w) \\odot \\theta\\|^2 ,\n$$\nwhere the $k$-th dimension of the parameter $\\theta_k$ is masked, i.e., $\\theta_k = 0$, when $w_k = 1$.\nThe authors provided an estimator of the parameter difference $\\theta_w - \\theta_1$, namely *parameter influence*, without computing $\\theta_w$ explicitly.\nThe authors also showcased several applications of the parameter influence.",
            "main_review": "## Strength\n### [Strength1] The applications of the parameter influence for understanding model structure and for model pruning are interesting.\n\nIn Section 5.2, the authors showcased that the convolution layers in deeper networks have less influences by using the parameter influence.\nIn Section 5.3, the authors demonstrated that we can reduce model parameters by pruning parameters with small influences while keeping the model accuracy.\nThese results will be of interest who want to design efficient architectures of deep neural networks.\n\n\n## Weakness\n### [Weakness1] The proposed estimator seems to be flawed.\n\nThe proof in Appendix A and its subsequent proposed estimator seem to be flawed.\nThat is, the estimator of the parameter influence, which is the main contribution of the paper, is flawed.\nAlthough the authors demonstrated that the proposed estimator highly correlates with the ground truth, the fact that the authors used a flawed estimator raises a concern regarding the validity of all the experimental results in the paper.\n\nBelow, I present the original derivation by the authors, and how it is flawed.\nI also provide a possible way to correct the flaw.\n\n*The original derivation*\n\nIn (10), the authors defined the following Lagurangian.\n$$\n\\mathcal{L}=R\\left(\\theta_{w}\\right)+\\psi^\\top\\left(w \\odot \\Delta \\theta+w \\odot \\hat{\\theta}_1\\right). \\qquad (10)\n$$\n\nThe authors claimed that its gradient are given as follows in (11).\n\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\theta} =\\nabla_{\\theta} R\\left(\\theta_{w}\\right)+\\psi^\\top w  \\qquad (11-a)\n$$\n$$\n=\\nabla_{\\theta} R\\left(\\hat{\\theta}_{1}\\right) + \\frac{1}{n} H_\\lambda \\Delta \\theta+\\psi^\\top w   \\qquad (11-b)\n$$\n$$\n=\\frac{1}{n} H_\\lambda \\Delta \\theta+\\psi^\\top w=0 , \\qquad (11-c)\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\psi} =\\Delta \\theta+w \\odot \\hat{\\theta}_1=0 . \\qquad (11-d)\n$$\n\nThe authors finally concluded that the parameter influence is given as follows in (12).\n$$\n\\Delta \\theta=-H_\\lambda^{-1}\\left[\\hat{\\theta}_1 \\odot\\left(H_\\lambda^{-1} w\\right)^{\\odot-1} \\odot w\\right]. \\qquad (12)\n$$\n\n*Flaws*\n\nThe first flaw is in (11), where the correct expressions should be\n\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\theta} =\\frac{1}{n} H_{\\lambda} \\Delta \\theta+w \\odot \\psi=0 , \\qquad (11-c^*)\n$$\n\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\psi} =w \\odot \\Delta \\theta+w \\odot \\hat{\\theta}_{1}=0 . \\qquad (11-d^*)\n$$\nThe major flaw is in (12) where the derivation of (12) from (11) is completely omitted.\nThe following is my guess on how the authors derived (12).\n\nFirst, from $(11-c^*)$ and $(11-d)$, \n\n$$\n\\Delta \\theta = n H_\\lambda^{-1} w \\odot \\psi = - w \\odot \\hat{\\theta}_1,  \\qquad (\\dagger1)\n$$\n\nand obtained \n\n$$\n\\psi = - w \\odot \\hat{\\theta}_1 \\odot (n H_\\lambda^{-1} w)^{\\odot -1}.  \\qquad (\\dagger2)\n$$\n\nThen, by plugging-in $\\psi$ to $(11-c^*)$,\n\n$$\n\\frac{1}{n} H_\\lambda \\Delta \\theta - w \\odot \\hat{\\theta}_1 \\odot (n H_\\lambda^{-1} w)^{\\odot -1}=0\n$$\n\nand obtained\n$$\n\\Delta \\theta = H_{\\lambda}^{-1} [w \\odot \\hat{\\theta}_1 \\odot (H_\\lambda^{-1} w)^{\\odot -1}].\n$$\n\nThe apparent flaws are that (i) the authors used the wrong expression $(11-d)$ instead of the correct one $(11-d^*)$, and (ii) the derivation of $\\psi$ in $(\\dagger2)$ was wrong confusing the matrix product and Hadamard product.\nIn more detail, even if $(11-d)$ is correct (although it is not), the correct expression of $(\\dagger1)$ is\n$$\n\\Delta \\theta = n H_\\lambda^{-1} (w \\odot \\psi) = - w \\odot \\hat{\\theta}_1.  \\qquad (\\dagger1^*)\n$$\nHence, we cannot obtain the expression $(\\dagger2)$ and its subsequent results because $H_\\lambda^{-1} (w \\odot \\psi) \\neq (H_\\lambda^{-1} w) \\odot \\psi$.\n\n*Possible Correction*\n\nOne may be able to obtain the correct estimator from $(11-c^*)$ and $(11-d^*)$.\nLet $S = \\mathrm{supp}(w) = \\\\{i \\mid w_i = 1\\\\}$ be the support of $w$, and $\\bar{S}$ be its complement.\nFrom $(11-d^*)$, it is apparent that\n\n$$\n(\\Delta \\theta)_S = - (\\hat{\\theta}_1)_S ,\n$$\n\nwhere $(\\cdot)_S$ denotes the subvector indexed by $S$.\n\nThe task is therefore to determine the remaining component $(\\Delta \\theta)_{\\bar{S}}$.\nFrom $(11-c^*)$, we have\n\n$$\n\\frac{1}{n}\n\\begin{bmatrix}\n    (H_\\lambda)_{SS} & (H_\\lambda)\\_{S\\bar{S}} \\\\\\\\ (H_\\lambda)\\_{\\bar{S}S} & (H_\\lambda)\\_{\\bar{S}\\bar{S}} \n\\end{bmatrix}\n\\begin{bmatrix}\n    - (\\hat{\\theta}_1)_S \\\\\\\\ (\\Delta \\theta)\\_{\\bar{S}}\n\\end{bmatrix} = \\begin{bmatrix}\n\\- (w \\odot \\psi)_S \\\\\\\\ 0\n\\end{bmatrix},\n$$\n\nwhere $(\\cdot)\\_{S\\bar{S}}$ denotes the submatrix indexed by $S$ and $\\bar{S}$ ($(\\cdot)\\_{SS}$, $(\\cdot)\\_{\\bar{S}S}$, $(\\cdot)\\_{\\bar{S}\\bar{S}}$ are defined accordingly).\n\nBy extracting the second row, we have\n\n$$\n(H_\\lambda)\\_{\\bar{S}\\bar{S}} (\\Delta \\theta)_{\\bar{S}} = (H_\\lambda)\\_{\\bar{S}S} (\\hat{\\theta}_1)\\_S .\n$$\n\nHence,\n\n$$\n(\\Delta \\theta)\\_{\\bar{S}} = (H_\\lambda)\\_{\\bar{S}\\bar{S}}^{-1} (H_\\lambda)\\_{\\bar{S}S} (\\hat{\\theta}\\_1)\\_S .\n$$\n\n\n### [Weakness2] The paper lacks large body of related studies on hyper-gradient and implicit differentiations.\n\nIn the paper, the authors mentioned that \n> However, all the existing researches (on influence functions) are focused on predicting the effects of removing training points on the model.\n\nThis would be true.\nHere, I would like to remind that the influence function is one specific variation of hyper-gradient computed by implicit differentation.\nI would suggest the authors to look at [Ref1, Sec5.1] where the influence function of each training instance is considered as a gradient of its weight (i.e., a hyper-parameter), where the detailed reviews on computing hyper-gradient using implicit differentation can be found in [Ref2].\n\nThe current paper misses these large body of prior studies on hyper-gradient and implicit differentiation.\nThe parameter influence considered in this paper is one specific variation of hyper-gradient where the weight of each parameter is treated as a hyper-parameter.\n\n* [Ref1] Forward and Reverse Gradient-Based Hyperparameter Optimization, ICML 2017.\n* [Ref2] Optimizing Millions of Hyperparameters by Implicit Differentiation, AISTATS 2020.",
            "summary_of_the_review": "As I detailed in the weakness above, the proposed estimator seems to be flawed.\nThe use of a flawed estimator raises a concern regarding the validity of all the experimental results in the paper.\n\nIn addition, the current paper misses the large body of prior studies on hyper-gradient and implicit differentiation.\nThe parameter influence considered in this paper is one specific variation of hyper-gradient where the weight of each parameter is treated as a hyper-parameter.\n\nOverall, I have to conclude that the current paper cannot be accepted as is.\nThe estimator of the parameter influence needs to be corrected, and its connection and novelty over the existing literatures of hyper-gradient and implicit differentation need to be discussed in detail.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper extends influence functions to understand the effect of perturbation of parameters primarily (and also features) to improve model pruning.",
            "main_review": "Influence functions, a classical technique for robust statistics is generally used to identify important training examples for a given model. In this work, the authors extend influence functions to understand (i) the effect of features; (ii) the effect of parameters. Majority of the papers focuses on (ii) with some analyis on (i). In (ii), the authors derive an influence function which captures the effect of downweighting (or removing) certain model parameters. Identifying unimportant model parameters can be useful for model pruning or in general understanding model structure. The authors apply their technique to linear models as well as some deep models. \n\nThe paper is a nice take on using second-order information to identify model parameters for pruning. The derived influence function for perturbing model parameters is a marginally new result, however note that it's not significantly non-trivial to derive it extending from [1].\n\nAlthough the proposed influence function is novel, there are certain areas which can be improved:\n\n(a) Writing: The quality of writing in general can be improved and the different sections can be made more connected. It seems that the \nprimary result of the paper is to use IF for model pruning (which in itself) is a significant direction. The authors should emphasize more on those  results with a more thorough analysis which brings me to the second point in the next part(b).\n\n(b) Experiments: The experiments are primarily on linear models and small deep networks such as AlexNet with 5 layers. In a realistic scenario, one would want to prune more complex networks (e.g., ResNets). It will be beneficial to present experiments on more complex architectures and datasets to make the paper complete. More realistic datasets such as CIFAR-10, CIFAR-100, ImageNet (or subsets of ImageNet) can be used for this purpose. While influence functions are accurate for linear models (due to convexity), for large overparameterized networks, influence functions might not be entirely accuracy. Some recent works such as [2],  investigate this phenomenon. To understand the true effectiveness of second order information, it's important to investigate the proposed framework with more realistic datasets and networks. The authors also should compare their pruning techniques with simple baselines (e.g, pruning via just the gradient information, Lottery ticket hypothesis) at different levels of sparsity.  Considering influence function is expensive to compute, understanding the trade-offs with existing pruning techniques is extremely crucial. \n\nI feel the work is in the right direction and is interesting, however I am not yet convinced with the experimental section. I would urge the \nauthors to work on more experiments (with more complex networks, datasets and comparisons to existing pruning work) as suggested and submit a more polished draft to an upcoming conference. \n\n[1]. Understanding black-box predictions using influence functions, ICML 2017\n\n[2]. Influence Functions in Deep Learning are Fragile, ICLR 2021",
            "summary_of_the_review": "The review appreciates the new influence function, but suggests more empirical study to understand the effectiveness of the proposed IF for more realistic models and datasets. Also comparison with other model pruning methods is necessary for completeness.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}