{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes Robust Network Architecture Search to consider architecture robustness of DNNs.\nSpecifically, the authors develop a network vulnerability metric and propose a novel algorithm to solve the optimization problem via adversarial training and projection approximation.\n",
            "main_review": "Strengths:\n-\tIt is interesting to analysis DNN robustness through the influence of network structures.\n-\tIt seems intuitive to use the KL divergence between adversarial samples and clean samples as the network vulnerability.\n-\tThe proposed optimization algorithm is suitable and effective.\n\nWeeknesses:\n-\tIt would be better if the authors provide more theoretical proof or empirical analysis for the design of vulnerability metric.\n-\tThe novelty of this paper serves as my main concern. Robnets [1] also utilize adversarial training and define a robustness constraint for the distance between adversarial samples and clean samples. \n-\tThere exist some typos, e.g, the word ‘novel’ is mistakenly written as ‘noval’ in the second summarized contribution.\n\n[1] Guo, Minghao, et al. \"When nas meets robustness: In search of robust architectures against adversarial attacks.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.\n",
            "summary_of_the_review": "See above.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": " Most of the existing methods improve the robustness of the model from weights optimization, such as adversarial training and regularization. However, the architecture of DNNs is also a key factor to robustness, which is often neglected or underestimated. The authors propose a Robust Network Architecture Search (RNAS) to address this problem. In the method, they define a network vulnerability metric based on the features’ deviation between clean examples and adversarial examples.",
            "main_review": "Strengths:\n\n1. The empirical evaluations are comprehensive.\n\nCons:\n\n1. More theoretical analysis should be added to make this work more convincing.\n2. How does the method perform in NAS-bench-101?\n\n",
            "summary_of_the_review": "Some confusion exists both empirically and theoretically. I recommend weak-reject at this stage.\n\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper utilizes DARTS to find robust architecture. This paper suggests deviation between clean and adversarial examples as vulnerability and applying the metric to additional constrain for robust architecture search.",
            "main_review": "**Strong points**\n\n1. This paper is well written and easy to follow.\n2. This paper can achieve high robust performance on CIFAR10, CIFAR100, and SVHN compared to previous robustness-targeted NAS.\n\n**Weak points**\n\n- The proposed method differs only by the functions formulation of evaluating robustness metrics (KL divergence of feature map), compared to previous work.\n\n- The paper utilizes the expectation of the KL divergence to measure the deviation between adversarial examples and clean examples on the feature map. However, there is no theoretical explanation or reference for why such divergence on the feature map can interpret as vulnerability. \n\n- Paper claimed that RNAS achieves state-of-the-art performance in robust accuracy. However, I hope the authors can test it with the following settings [1] (Train: total epoch: 110 , learning rate: 0.1, lr decay at 100, 105 epoch, weight decay: 5*10-4). As referred to [1], ResNet18 CIFAR10 robust accuracy is 48.51 which is much higher than the reported performance.\n\n- Paper conduct experiment with RNAS on CIFAR100 and SVHN that is searched from CIFAR10 dataset. Is there any reason why the author didn't find CIFAR100 network and SVHN network? How does robust performance change with RNAS from CIFAR100 and RNAS from SVHN?\n\n- Paper demonstrates the performance of RNAS that is trained with PGD adversarial training. However, can RNAS also show superior performance in TRADES adversarial training?\n\n- There is missing experimental detail about the value of different H in RNAS-H and RNAS-L.\n\n[1] Pang et al., BAG OF TRICKS FOR ADVERSARIAL TRAINING, ICLR 2021",
            "summary_of_the_review": "Overall, I recommend weak reject for this paper. I think the proposed method is lacks of novelty. Moreover, the explanation about claimed robustness metric is not sufficient. The evaluation and training setting seems incorrect as I mentioned in the previous section.\n\nHowever, if all my concerns resolve properly, I will increase my score.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}