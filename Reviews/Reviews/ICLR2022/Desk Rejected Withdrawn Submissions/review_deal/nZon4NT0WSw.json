{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper considers generalization of FL model to unseen clients with non-iid data from a casual perspective. Authors form an SCM to explain the challenge of such a problem and then propose a simple and effective method with test-specific BN. Experiments validate the performance of the proposed method. The paper is well written. ",
            "main_review": "My major concerns are on the causality analysis part.\n\n-\tSince a contribution of this work is to propose SCM to understand and to propose new algorithms for the generalization problem in FL. I would like to suggest to give more details justifying the causal graph. In particular, I did not understand why the non-iid data is a confounder to X and R? Can you give more details?\n-\tAbout: “The performance degeneration is induced by the non-iid data distribution D_k^s , which is exactly known as the confounder that brings spurious correlations in the causality”: in domain generalization, spurious correlation usually refers to the one between some non-causal feature (or non-invariant) of the input X and the outcome Y. Here, it is hard to understand what spurious correlation means here, as the confounder is between X and R. Can you explain more here, in particular, how this spurious correlation cause a problem in this setting? \n-\tAbout “For domain generalization, a central solution is to learn domain-invariant features from multiple distributions (domains) by gathering a set of centralized non-iid datasets. Such domain-invariant feature learning can be viewed as the back-door adjustment in our training SCM” and Eqn (3): perhaps similar to the above one, why do we need do(X) here? If I understand correctly, X is just the regular input or image, which contain both causal and non-causal features. Also, the P(Y|do(X)) should be summed over all possible domains, not just 1…k, the finitely many observed ones.\n-\tAbout the infeasibility discussion in Appendix B: after Theorem B.3, the two conditions are indeed sufficient conditions, but not necessary ones. Thus, we can also estimate P(Y|do(X)) without knowing Pa(X). Also, since we only need some summary statistics to calculate the sum, so we need not access the locally private data?\n-\tFinally, the proof of showing P(Y|do(F)) = P(Y|do(S)) is problematic to me. In equation (8), rule 2 only reduces the do intervention to the observed data, but not removes the variable. Thus, the main theorem 3.1 is also questionable. Please pay special attention to this question.  \n\n\n",
            "summary_of_the_review": "Apart from the causality part, the paper simply uses the test data to calibrate the BN part in the considered domains, and it is expected that this may reduce certain distance between trained and test-domain distributions. The causality analysis part is clearly important and I look forward to authors’ response. I am willing to increase my score if my concern on the causality part is adequately addressed. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a new batch normalization trick to improve domain generalization in federated learning settings. The motivation makes sense. The problem is setup using assumptions of a structural causal model, with the new batch normalization posed as an intervention in the test domain's causal model. Theoretical analysis includes lower bound on the generalization error and expertiments demonstrate improvement in empirical performance on benchmark datasets. ",
            "main_review": "1. Clarification: What is meant here (Introduction 2nd para last line): \"FL privacy-preserving, however would unavoidably affect the well-established FL paradigm and complicate the training process\". \n\n2. Confusion in problem setup. Authors say SCM is known. Does it mean a fixed and known neural network is used to extract raw features to model X-> R edge? Knowledge of SCM implies knowledge of functional relationships between edges. Also they need to be the same across all environments. That is R := f_X(X, U) where f_X is the same and prior distribution over U is the same for all environments. Is that the case here? Or separate CNNs are being learned? If the latter then the problem setup is not appropriate. I have a similar concern about assumptions regarding the edge R->F. Since Sec 3.2 suggests that one estimator is learned, but the text seems to suggest the graphical assumption only makes sense due to batch normalization, I think there are lots of implicit assumptions that are not clearly written or stated. Please clarify the above in setup.\n\n3. Why are the graphs different in train and test? If confounding factors aka domains do not actually affect the batch normalized representations, it is not clear that the arrow and the corresponding intervention in Figure 1(a) is doing (in test domain).\n\n4. Also do(X) operation in Eq 3 removes parents the influence of domains on X. The intervention cannot cut any influence to F, its unclear why it exists to me in the first place. Also R and F are latents, they are not observed in the data and are learned. This distinction needs to be clearer. Also do(F) removes influence from ALL parents of F, which means R, domain and S.\n\n5. Sec 3.3. I am unsure how one can `achieve an intervention' by adding a surrogate node. \n\n\n6. My main suggestion for the paper is to remove the causal analogy and describe the whole paper without making any causal assumptions.",
            "summary_of_the_review": "I have several concerns that I raise above regarding the technical problem setup and the motivation of the solution. In particular, I strongly believe the causal formulation is incorrect and incomplete. The theoretical (Sec 3.4) and empirical results (Sec 4) can be justified even without the causal formulation. I strongly urge the authors to present the contributions without forcing the causal formulation.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The basic goal of this paper, as stated by the authors, is to effectively generalize to new \"clients\" in a federated learning setting, when the data is not guaranteed to be IID.\n\nThe main algorithmic contribution of this paper is a feature normalization scheme called \"TsmoBN\", which shifts and scales the features using location and scale estimators that are computed using a momentum-based update given multiple mini-batches. The authors further motivate this method with a causal interpretation, and carry out a series of empirical tests to evaluate the efficacy of their method.",
            "main_review": "While the issue of generalizing to unseen clients with non-IID data is assuredly important, the quality of the writing in this paper is so poor that I cannot possible recommend acceptance in the present form. There are many problems, and I will only list a few representative ones:\n\n- *The problem setting is unclear.* Both the \"FL\" and \"non-IID\" parts of this paper are not explained clearly. \n  - Regarding FL, in eqn (1) the authors say that with $K$ clients, the training objective is to minimize the weighted average of the empirical expected loss on each client. In talking about FL, I would have expected each client $k=1,\\\\ldots,K$ to produce its own $f\\_{k}$ trained on its local data, and then the hope would be that by cleverly aggregating $\\\\{f\\_{1},\\\\ldots,f\\_{k}\\\\}$, we could get a \"good\" final candidate that generalizes well. Furthermore, despite all the talk of generalization, the ultimate objective is not stated clearly at all. I would assume that it is to find an $f$ such that the left-hand side of (2) is minimized, but again this is not stated clearly.\n  \n  - Regarding \"non-IID\", the authors frequently use this term, but all the data is actually *independent*, correct? Of course independent data with different distributions is not IID, but if the authors just want to be able to deal with covariate/feature shift, then they should say that explicitly and concisely.\n  \n  - Finally, notions of domain adaptation and non-IID federated learning are all mixed up in this paper. The authors themselves say \"the issue of generalizing to an unseen client is independent of the federated setup.\" If so, why is FL even discussed at all in this paper?\n  \n- *The method and idea is unclear.* The authors state that they are trying to generalize to unseen clients, but their algorithm assumes access to samples from the test distribution. In addition, their brief summary of \"TsmoBN\" in equation (4) is a mess. Let me explain this briefly by highlighting a few points.\n\n  - While $\\\\mathbb{E}[\\\\mu\\_{u}]$ and $\\\\mathbb{E}[\\\\sigma\\_{u}\\^{2}]$ are not clearly defined and are notationally very strange (one does not expect $\\\\mu\\_{u}$ to refer to a random object, yet its expectation is being taken), I think almost any reader would assume that they refer to the true mean and variance of the unseen client features. In any case, expectation over the true distribution is being taken, so these are ideal quantities, yet they are given as part of the output of $\\\\mathrm{TsmoBN}(r\\_{i,k}\\^{u})$, which is something we compute in practice.\n  \n  - The features here have the subscript $k$, which was the known client index - this should not be used with the superscript $u$. Extremely confusing.\n  \n  - $\\\\mathrm{TsmoBN}(r\\_{i,k}\\^{u})$ in the main paper works on an individual point, whereas $\\\\mathrm{TsmoBN}(\\\\cdot)$ in Algorithm 1 in the appendix works on a dataset. This is inconsistent.\n\n- *The theory is unclear.* I have no idea what the authors are saying in section 3.3, so I will leave that part alone. As for 3.4, a generalization bound is \"extended\" from prior work, considering a very specialized situation of Gaussian data and a neural network model with finite VC dimension, but Theorem 3.2 itself is a mess. A few points:\n  - The result is a bound on the expected *absolute* error. What happened to classification? No comment from the authors here.\n  - The bound is for $h\\_{\\\\mathcal{N}\\_{u}}$, given in terms of the average risk incurred by $h\\_{\\\\mathcal{N}\\_{k}}$ for $k=1,\\\\ldots,K$. However, critically, neither of these quantities is defined anywhere that I can see. How does this relate to the batch normalization proposed by the authors? Theory is meaningless unless it has some relation to the method of interest being proposed/studied.\n  - The authors say $\\\\forall \\\\, \\\\alpha$ and \"for each $h \\\\in \\\\mathcal{H}$, but neither $h$ nor $\\\\alpha$ appears in the main inequality of Theorem 3.2.\n  - $h\\^{\\\\ast}$ is defined with $\\\\mathcal{N}\\_{i}$ on the right-hand side; shouldn't this be $h\\^{\\\\ast}\\_{i}$ then?\n  - $\\\\lambda\\_{k}$ is defined with $\\\\mathcal{N}\\_{i}$ on the right-hand side; shouldn't this be $\\\\mathcal{N}\\_{k}$?\n\nI could go on with this, but I think my point is clear.",
            "summary_of_the_review": "The authors clearly have a lot of ideas which are potentially interesting, and have clearly put some effort into their empirical analysis, but the exposition in this paper is far below what I would deem necessary for acceptance, and thus I vote to reject.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}