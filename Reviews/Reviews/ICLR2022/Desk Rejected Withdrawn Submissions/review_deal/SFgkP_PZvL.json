{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a checkpointing scheme for Neural ODE models in order to reduce the memory footprint of the discrete-time adjoint recursion. The discrete time recursion itself is motivated from the viewpoint that it yields the mathematically correct derivative of a time-discretized ODE solver.",
            "main_review": "Strengths:\n- This is an important topic to study since stability of forward/adjoint ODEs can have drastic implications on the solver and step-sizes, and consequently the gradient computation method (continuous-time vs discrete-time adjoint solver).\n\nWeaknesses:\n- The paper is quite poorly written with several instances of incorrect math and rather confusing explanations. See below:\n\nEq (3), transpose missing on $\\partial f/\\partial u$.\n\nEq (5), taking gradient of stage-cost w.r.t. $\\theta$, when in eq (2), stage-cost is independent of $\\theta$ — check consistency.\n\nEq (7), $\\psi$ is undefined. Presumably, this is $\\phi$ from eq (2)?\n\nIn Eq (7), the stage-cost has disappeared, so there is an entire term missing in the adjoint equations. \n\nTable 1, the formulas again have lost the stage-cost terms.\n\nIn general, the equations need to be double-checked and made consistent between CT and DT. Derivation in the Appendix is a mix of random terminology used without context, e.g., eq (7) is the Lagrangian for what optimization problem? Furthermore, where is the dependence on $\\theta$? The correct statement needs to define the DT optimization problem, formally as a function of initial state $\\eta$, and “control” $\\theta$. The correct expressions can then be derived straightforwardly from any optimal control textbook - see e.g., Bertsekas. \n\nProof of Prop 1, eq (4) —> eq (5):  $\\|| A * b \\|| \\neq \\|| A \\|| * \\|| b \\||$, where A is the difference in the two Jacobian transposes, and b  = $\\lambda_{n+1}$. One may however upper bound this quantity by the product of the two norms by invoking the sub-multiplicative property. Further eq (6) in the Appendix as written is ill-defined, given that $f$ is a vector-valued function, and thus the Hessian is in fact a 3rd order tensor. Furthermore, the difference in times has been completely ignored in the Taylor expansion! In summary, the proof is quite sloppily written with erroneous math everywhere.\n\nThe conclusion that CT and DT adjoints are the same for linear systems should also be immediate from the fact that the Jacobian is constant. Notice however that this may not be true for Linear-Time-Varying systems — once again highlighting the erroneous Prop 1.\n\nAppendix C.2 is also riddled with errors: in eq (12), given the definition (13), the compound state $\\underline{u}$ should include the growing integral of $q$, and thus the dynamics of this sub-vector would be $q$; not the other way around. Consequently, formulas in Appendix C.3 are also likely compromised. \n\nSections 3.1–3.2 are quite confusing; ‘primitives’ are undefined; presumably the idea is to store the state solution $u_n$ at some set of time-steps during the discrete-time forward pass. Then, in order to realize the DT adjoint recursion the solution $u_n$ at non-recorded steps is re-computed from the closest preceding recorded step. However, this idea seems to be borrowed from an existing work (cited in Prop. 2); therefore the novelty is not apparent. \n\nStatement after Prop 2: if state solution is stored at all time-steps, where did the computational cost of back-propagating through the $f$ network go? One still has to compute a Jacobian-vector product using the Jacobian of the dynamics.\n\nSection 3.4 is equally cryptic and relies on erroneous formulas from the Appendix. Further, it is unclear how Appendix C.3 formulas relate to the discrete adjoint exposition in Section 2.2, the latter highlighting the need to differentiate through the nonlinear forward solve for implicit integrators.",
            "summary_of_the_review": "While the paper addresses an important issue in the computational aspects of Neural ODE models, the lack of clarity in novelty & the writing along with a plethora of math errors suggest that the work is not as yet ready for publication.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors proposed PNODE, which is an ODE solver framework with adaptive checkpointing strategy to save memory, meanwhile keep the numerical accuracy in reverse-time trajectory hence the accuracy in gradient estimation.",
            "main_review": "Strengths\nThe paper is in general well-written and easy to follow. The authors also provided extensive analysis and details in the appendix.\n\nWeakness\n1. The idea of PNODE is very similar to ACA, in fact Table2 has wrong statements about ACA. The general idea of ACA is similar to PNODE, both use the checkpoint strategy to same some intermediate-time states, and the trajectories between these states can be deleted to save memory. During backward pass, the trajectory can be reconstructed from these saved checkpoints **chunk by chunk**. ACA has a backprop memory cost of $O(N_s N_f)$ rather than $O(N_t N_s N_f)$, similar to PNODE, this is a major misunderstanding.\n\n2. In theory ACA support implicit ODE solvers, but the authors did not implement it in the package. Considering these points, I think the contribution of PNODE would be the support of implicit solvers in implementation and a more flexible checkpoint strategy. But the memory saving and reverse-accuracy issue has already been tackled by the literature [1,2,3].\n\n3. Speaking of the literature, the authors should also discuss [2] which proposed Symplectic-Adjoint and reduces the memory cost of ACA by a constant factor, and the constant is non-trivial in practice. [3] proposed MALI, which does not need checkpoints at all, so the total memory is $O(N_f)$.\n\n4. The baseline results are tricky. For example, Table 3 results for ACA give a positive loss, which basically means ACA does not train at all. I would suggest the authors refer [2] for performances of ACA and Symlplectic-Adjoint on the flow models on Tableau data, and refer to [3] for results on flow models on Cifar and ImageNet, at least [2] reported a far better result on BSDS300.\n\n[1] Zhuang, Juntang, et al. \"Adaptive checkpoint adjoint method for gradient estimation in neural ode.\" International Conference on Machine Learning. PMLR, 2020.  \n[2] Matsubara, Takashi, Yuto Miyatake, and Takaharu Yaguchi. \"Symplectic Adjoint Method for Exact Gradient of Neural ODE with Minimal Memory.\" arXiv preprint arXiv:2102.09750 (2021).    \n[3] Zhuang, Juntang, et al. \"MALI: A memory efficient and reverse accurate integrator for Neural ODEs.\" arXiv preprint arXiv:2102.04668 (2021).",
            "summary_of_the_review": "This paper has a wrong statement about a baseline method hence the contributions in memory-reducing is not novel. The experiments on flow models are tricky, and baseline methods seem to not train, while the same baseline has reported reasonable results in the literature.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This study proposes PNODE, which provides a memory-efficient checkpointing strategy for neural ODE by interfacing PETSc to PyTorch. The backpropagation offers the lowest computational complexity, but the memory usage is problematic. Several previous studies resolved this problem by checkpointing and recomputing. Because the best schedule depends on the available memory, PNODE may reduce the memory and computational cost by using the optimal strategy.\n",
            "main_review": "**Positives**\n\nThe memory cost is a practical problem for neural ODE.\n\nCombined with PETSc, PNODE provides more solvers, extends target problems, and extends available computer architectures compared with the implementations of previous neural ODE studies.\n\nAccording to Figure 3, PNODE certainly reduces the memory cost compared to ANODE.\n\n**Concerns**\n\n*1. Cost for previous studies*\n\nZhuang et al. (2020) and Gholami et al. (2019) claimed that the memory that ACA and ANODE need is $\\mathcal{O}(N_t)$ for checkpoints and $\\mathcal{O}(N_f)$ for backpropagation. However, in Table 2, the authors summarized that the memory that ACA ana ANODE need is $\\mathcal{O}(N_t)$ for checkpoints and $\\mathcal{O}(N_t N_s N_f)$ for backpropagation. The reviewer understands that the previous studies did not use the notion $N_s$, but even then, the memory cost of ACA or ANODE for backpropagation is $\\mathcal{O}(N_sN_f)$. Please correct my misunderstanding or revise the explanations.\n\n*2. Novelty*\n\nThe improvement from Zhang and Constantinescu (2019a, 2021) is unclear. The algorithm that obtains the best checkpointing schedule, mentioned in (8), is proposed by Zhang and Constantinescu (2021). The authors explain the advantages of PNODE in Section 3.6, but all of them are based on PETSc. So, in my understanding, PNODE is just an interface of PETSc to PyTorch. The interface is very useful, but the scientific contribution is limited.\n\n*3. Cost for PNODE*\n\nIt is unclear to the reviewer why the memory cost is reduced. NODE naive gets the gradient of ODE itself, so the memory cost is $\\mathcal{O}(N_t N_s N_f)$. ANODE and ACA get the gradient of a time step and integrate it, so the memory cost is $\\mathcal{O}(N_s N_f)$ (in my understanding). PNODE gets the gradient of $f$ and integrates it (via the transposed Jacobian product, as mentioned in Section 3.3), so the memory cost is $\\mathcal{O}(N_f)$. As a self-explanatory paper, detailed explanations are needed. Does this hold for any methods or under some conditions?\n\nJust after Proposition 2, the authors stated that\n\n> this checkpointing strategy allows us to balance between the recomputation cost and the memory cost for checkpointing. In an ideal case where memory is sufficient for saving all stages at each time step, no recomputation is needed. Then the computational cost of PNODE becomes $\\mathcal{O}(N_t N_s)$.\n\nIn this case, the memory cost for backpropagation is the same as NODE naive, that is, $\\mathcal{O}(N_t N_s N_f)$; the complexity in Table 2 is not true. The memory cost and computational complexity in all possible scenarios should be provided. Moreover, results in Table 3 may vary depending on server specs; when and how does PNODE outperform others?\n\nIn Conclusion, the authors stated that\n\n> We successfully reduce the memory cost of neural ODEs to $\\mathcal{O}(N_c ) + \\mathcal{O}(N_f )$ , and $\\mathcal{O}(N_t N_s ) + \\mathcal{O}(N_f )$ in the worse case when checkpointing all intermediate states (including ODE solutions and stage vectors)\n\nAccording to this sentence, the reviewer imagines that PNODE saves every stages of every time step, right? The reviewer did not understand this by reading previous sections. Please identify the sentence that clarifies this or add explanations.\n\n*4. Advantages from continuous version*\n\nAccording to the second paragraph of Section 3.6, PNODE can work with adaptive time-stepping solvers, but such experiments are not provided in Table 3. Comparison with NODE cont and ACA are needed.\n\nThe authors stated in Introduction that\n\n> the continuous adjoint method may lead to inaccuracy in the gradient and instability during training.\n\nThis is true with non-adaptive solvers as shown in Figure 2 and Table 3, but not demonstrated with adaptive solvers. The reviewer thinks that NODE cont is accurate and stable if using adaptive solvers. A comparison with NODE cont using adaptive solvers is needed.\n\n**Minor Comments**\n\nOn 2nd paragraph, Section 1, \"Chen et al. Chen et al. (2018)\"\n\nThe jacobian matrix in (3) and the right hand side of (4) may lack the transpose operation.\n\n$\\psi$ in (7) is unclear. $\\mathcal L$?\n\nThe last sentence of page 4; Nota -> Note.\n",
            "summary_of_the_review": "According to the results, the proposed framework is practically useful and promising. However, the theoretical background is still unclear and presumably highly dependent on the other publications. The novelty might be just to interface PETSc to PyTorch. Due to the both concerns, the reviewer recommends \"5: marginally below the acceptance threshold\".\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}