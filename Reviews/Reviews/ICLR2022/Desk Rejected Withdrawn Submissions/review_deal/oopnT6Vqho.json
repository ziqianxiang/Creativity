{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper studies online learning with DNN. In particular, the authors investigate the regret behavior of online episodic control over LTV systems where DNN is adopted as a controller. Performance guarantees are established.",
            "main_review": "Overall I find the work interesting and fill an intellectual gap in terms of online learning with DNN as controller. I do not see many issues with this work, but I'm not from this field so I might miss certain things that are well-known. I have a few comments regarding the current work.\n\n(1) The work claims that the derived regret bounds can apply to any OCO algorithm. An interesting consequence of this statement is how is the regret bound dependent on the chosen OCO algorithm? Other than OGD, what else can you show in terms of the regret bound?\n\n(2) I would like to see more explanation of the theory. The derived regret bounds are difficult to interpret. \n\n(3) It would be great to highlight related theoretical analysis for online learning with DNN as controller, and position this work against the SOTA. In particular, is there any existing theoretical analysis that can be applied to the considered problem with a provable theoretical guarantee?",
            "summary_of_the_review": "I feel that this work has a strong theoretical contribution, and I'm suggesting acceptance. However, given that I do not work on this specific topic, I might have missed some things in the paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors propose a regret analysis for the use of deep neural networks for the task of online episodic control. They start from the decomposition of this regret into the one provided by the approximation given by the NN and the one incurred by OCO algorithm on a simple case with a single hidden layer. Then, they built on these results to provide guarantees also on Deep architecture.",
            "main_review": "I think that the paper is clear but an overall proofreading and rephrasing might improve the readability. I think that some of the results presented in the main paper are not properly commented, therefore leaving to the reader the task to interpret the meaning and their relationship with the other results presented.\n\nMy first concern is that the paper uses more than 3 pages to outline the background used for the actually proposed analysis. Even if I agree with the authors that the topic is complex and builts on multiple elements, I think that the authors should try to get to the main results they proposed as soon as possible. Maybe adding some summary of the results at the beginning may help to clarify the overall goal of the paper.\n\nI think that adding some comments on the assumptions you required would improve the readability of the paper.\n\nI would like to know how hard is the assumption that the dynamics of the process follows Equation 2.3. I am not completely familiar with this assumption, therefore I would like to know how this is motivated. Moreover, do you think that assuming a more complex dynamics can be still handled by your analysis?\n\nFinally, even if this is not a practical paper, I would have appreciated some synthetic experiments to validate the bounds you provided.\n\n\n\nMinor:\n-add references to the introduction to strengthen your claims, e.g., examples of the application of RL to portfolio selection\n-\"The accepted framework\" by whom?\n-\"were done in isolation\" please clarify\n- nonstochastic control literature : -> nonstochastic control literature:",
            "summary_of_the_review": "An interesting paper, but it requires to improve its readability and add more comments on the results provided.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studied deep online learning and control and made the following contributions.\n1. This paper gave a reduction from any online convex optimization algorithm to online deep learning with a class of deep neural networks and a class of two layers neural networks. Moreover, the corresponding regret bounds are derived.\n2. This paper extended the above reduction to online nonstochastic control and established regret bounds for deep controllers in the episodic setting.",
            "main_review": "Deep online learning (and online control) studied in this paper is a natural and practical combination of deep learning and online optimization (and online control). Moreover, theoretical guarantees established in this paper are new to me and may have some value for understanding deep online learning (and online control). However, I have the following concerns about this paper. \n\n1. The main contribution of this paper should be the reduction from any online convex optimization algorithm to online learning with neural networks. However, it seems that this reduction for deep online learning is trivially extended from an existing reduction for deep learning (not online) in Gao et al. (2019). Specifically, the main difficulty of this reduction for deep online learning is to quantify the margin of near-convexity for neural networks. But the neural networks studied in this paper are very similar to those studied in Gao et al. (2019), and the near-convexity derived in this paper (Lemmas 3.3 and 3.5) are very similar to existing results in Gao et al. (2019).\n2. This paper studied a class of deep neural networks and a class of two layers neural networks. For the deep neural networks, this paper required that parameters $A, a$ are fixed after initialization. Note that $a$ can be regarded as the weight of the last layer in deep neural networks. However, according to this paper, each entry of $a$ is drawn i.i.d. from $\\mathcal{N}(0,1)$, which makes me doubt the actual performance of these deep neural networks. Similarly, for two layers neural networks, the authors initialize parameters $a_{i,r}$ to be randomly drawn from $\\{\\pm 1\\}$ and fix them throughout training.\n3. On page 4, the authors said \"... in Section 3 we study the tradeoff between the two properties and choose an optimal $b$ ...\". But, in Section 3, the authors did not clearly explain why is the selected $b$ optimal? \n4. The authors did not provide any experiment to verify their theoretical results. It is very interesting to study the practical effect of the network width $m$ and the number of iterations $T$.\n\nThere are some minor comments.\n1. The notations $\\Pi_{\\mathcal{K}}$ and $\\Pi_{\\text{dnn}}$ may make reading difficult due to the common part $\\Pi$.\n2. In Definition 2.1, what does $w$ mean? \n3. In Definition 2.1, how to derive the equation about $K_{\\sigma}(x,y)$?",
            "summary_of_the_review": "The main contribution of this paper is to present theoretical guarantees for deep online learning. However, it seems to be a straightforward extension of an existing work (Gao et al., 2019). Moreover, I doubt the actual performance of the neural networks studied in this paper and the authors did not provide any experiment to verify their theoretical results. So, I tend to reject this paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper extends the online convex optimization framework to the more general deep online learning setting. It shows that under several assumptions, the reduction from online convex optimization to deep online learning is possible and has provable regret guarantee. It also applies this reduction idea to the online non-stochastic episodic learning control over linear time-varying dynamics.\n",
            "main_review": "The paper is well-written and easy to read. And extending the current online convex optimization framework to the general online deep learning setting is very meaningful. \nHowever, while examining the paper's results, I have several concerns.\n1. The provable regret guarantee resulted from the reduction from OCO to online deep learning is not a challenging problem, which could be seen from the main lemmas proof (Lemma 3.3 and Lemma 3.4) that follows Gao et al. (2019) a lot and not much new. Thus, the novelty is a big concern.\n2. The setting for the time-varying control problem is a bit strange. In page 6 above Section 3, it uses \\Theta to be the set of permissible parameters, but it also allows the system matrix A_k to change arbitrarily for different episodes. Is there a way to find the permissible \\Theta set given this condition?\n3. The result from Theorem 3.2 needs to take the radius R of the permissible set to be equal to the order of H^{-1.5}m^{-1.5}. As shown in the paper, to have average regret bounded by \\epsilon, m = O(\\epsilon^{-2}), which will make R = O(\\epsilon^3). This seems pretty small, which will make the competing best fixed solution to have limited space and result in large cumulative loss. ",
            "summary_of_the_review": "Based on my above reviews, I think the problem is interesting, but the results are not significant enough to be published yet.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}