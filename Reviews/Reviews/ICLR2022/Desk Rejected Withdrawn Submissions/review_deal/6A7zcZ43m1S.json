{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper deals with graph neural networks for multi-relational graphs.\nThe authors propose a network design at a high level and a model that embodies each of the components, R-GSN.\nThe proposed R-GCN is a method that does not rely on metapaths, which most of the existing powerful baseline methods employ, and its effectiveness is shown using a real dataset.",
            "main_review": "The authors' proposal is at two levels: network design at a high level (which they call \"paradigm\"), and a model (R-GSN) that embodies each of the components. At each level, the proposed method is carefully designed from a practical point of view, and its structure makes a certain amount of sense, and these are positive points.\n\nOn the other hand, this work does not seem to point out problems that are difficult to solve with previous approaches to learning to deal with heterogeneous graphs, nor does it provide key ideas to solve them.\nThe fact that it is not based on metapaths is an important appealing point of the proposed method, but due to the lack of a clear discussion of the problems with metapaths, the proposal seems to simply investigate new combinations of DL techniques, and hence lacks conviction about its contribution and novelty.\nEven after reading the Related Work section in the appendix, the novelty was not clear to the reviewers. At the very least, the section in the appendix should have been included in the main text and the differences from existing studies should have been clearly discussed.\n\nThe idea of intra-relation aggregation followed by inter-relation aggregation in macroscopic network design itself may not be exactly the same as what has been proposed in the past. However, this design itself is so natural that its novelty is unknown. If this design is a novel idea that strikes at an essence that has been overlooked, please emphasize it.\n\nEach component of the network does not seem to be a key idea to solve the difficulties of GNNs that deal with multiple relations, and seems to be a slight modification of what has been used in previous GNN research. What are the possible reasons for the components that were found to contribute to the improved prediction accuracy as a result of the ablation study?\n\nThe current manuscript does not appear to be well-prepared. The writing could be improved.",
            "summary_of_the_review": "This paper needs a more explicit discussion and justification of novelty and contribution.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposed a unified framework for heterogeneous graph neural networks, utilizing attention and multiple normalization techniques. Without the usage of the meta-path, this paper achieves better scalability. The empirical results presented in the paper validate the superiority on the ognb-mag dataset and outperform the baselines in IMDB and DBLP datasets.\n\n",
            "main_review": "The paper demonstrates a new approach on  heterogeneous graph neural networks. Though the experimental results show the promising of the proposed approach; there are lack of study/insights on why the proposed approach performs better than other approaches. Some other issues are listed below: \n\nPaper organization and presentation remain to be improved. For instance, Appendix A.1 is fundamental to understanding the background and notation, it would be better to put in the main context. There are a few redundant expressions in section 2, which can be more concise.\n\nNeed more experiments on other datasets.  Since this paper is established from R-GCN, It would be more convincible to conduct the experiments on the datasets used in the R-GCN paper and compare the results. As to the extending part (section 3.5), two more datasets (IMDB, DBLP) are used, the proposed model indicates better performance consistently. Since this model abandons the meta-path strategy, it would be better to emphasize the strength (complicity, speed) to the other class model.\n\nThe technique contribution of this paper is fairly low. This paper tries to unify the framework of heterogeneous neural networks established on the R-GCN model. It’s more like an empirical incremental work that adds the attention mechanism and  layer normalization to the intermediate steps of the existing model.\n\nMinor Problems:\nFigure 3, circle of “t” seems like a handwriting format.\n\n\n",
            "summary_of_the_review": "In general, the technical contribution of the paper is quite incremental as it basically introduces the existing techniques like attention and normalization mechanism into the R-GCN model. The experimental results  as well as the paper presentation can be improved. \n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a node embedding method for heterogeneous graph that does not rely on meta-paths. The proposed R-GSN improves upon R-GCN by modifying several components of R-GCN. The model is evaluated on both heterogenous and homogeneous graphs, and various ablations are demonstrated.",
            "main_review": "Pros\n- The proposed R-GSN showed improvements over R-GCN by simple modifications to the architecture.\n\nCons\n- The paper lacks justifications for the model design. All the model designs seem to be very empirical.\n\t- Why is L2 better than Leakey ReLU? \n\t- Why are the proposed designs that are different from GAT beneficial for the model performance?\n\n- The difference between target and source node is not described, which makes it hard to understand the last paragraph of section 2.2.2.\n\n- Since FT and FLAG are not the main contribution of R-GSN, but they can be plugged into any baseline methods, Table 1 should report the results for R-GCN(3+) from Table 2 in place of R-GCN in Table 1.\n\n- Concerns regarding the experiments\n\t- Why is HAN not compared in Table 1? Since R-GCN is compared in Table 1, it should be possible to compare HAN as well.\n\t- The performance gain is marginal.\t\n\n- Minor comments\n\t- There are many places where the first letter of a sentence is not capitalized.\n\t- we conducte -> we conduct\n\t- It concludes the following -> It includes the following",
            "summary_of_the_review": "Overall, I find the paper too empirical, and the performance gain is very marginal. I understand that this method have shown good performance on a public leaderboard, however, this paper contributes little to the research community, due to its lack of justifications on the model designs.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}