{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a transformer-based abstractive multi-document summarization approach conditioned on attribute classification models, which check for sentiment and polarity attributes to ensure consistency of the generated summaries across multiple documents. The attribute conditioning classification models are built in a modular fashion to guide summary viewpoint consistency throughout the various stages of the summarization process and trained on different datasets than the dataset for which the downstream summarization task is evaluated on. Experiments and ablation study show the effectiveness of the decomposable conditioning component compared to several baselines without the conditioning component via using both automatic evaluation (ROUGE) and human evaluation.",
            "main_review": "Overall the paper is well-written and the main ideas are clear. I have a few comments:\n\n- It was difficult to follow the related work as I was not able to find the reference citations in the paper (some formatting issue?), which made it hard to evaluate the technical merit of the paper. \n\n- The paper builds on several existing work and architectures with limited incremental/alternate additions and combinations, e.g. the related opinion polarity-based conflict resolution model uses pointer generator network, whereas the proposed approach leverages BART. \n\n- It was not clear why ROUGE scores were higher due to the proposed addition of sentiment and polarity attribute conditioning component. Some insights with examples would be helpful. \n\n- It would have been nice to see an end-to-end example of how conditioning helped generating better summaries. At least I was expecting to see some sort of relevant criteria for judging the proposed benefit in the human evaluation. Also, it was not clear how many human evaluators were there and what was their qualification. Moreover, I would be curious to know what would be the inter-annotator agreement like since judging abstractive summaries is a subjective task.\n\n- Experiments have been conducted on news datasets; I would be curious to know how the proposed approach would work on a different or specialized domain e.g. healthcare or financial, where ensuring consistency across multiple documents would be beneficial. \n\n- The paper has numerous typos and grammatical errors that need to be corrected. ",
            "summary_of_the_review": "Overall, lack of novelty and clarity for some parts of the paper are my key concerns.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper present a novel abstractive multi-document  summarization method.\nThe methods is based on BART encoder decoder architecture that with graph conditional weighting layer, and a dedicated attribute conditioning module based on XLNet. ",
            "main_review": "The paper present a model with impressive ROUGE results and show sound evaluation.\nThe paper is lacking on clarity in the explanation of the different modules used for the method, it is difficult to understand what is the actual input/output of each module, especially the attribute conditioning module.",
            "summary_of_the_review": "The paper shows a promising novel model with sounds evaluation but lack clarity.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "To  make the generated summary be little affected by the conflicting information among documents, this paper introduces an attribute conditioned module for the task of abstractive multi-document summarization, which aims to generate a summary of the given multiple documents. The proposed module first applies an external classifier, i.e., XLNet, to predict the attribute of the input, and then improves the state-of-the-art model, i.e., GraphSum, for both the encoder and the decoder. For the encoder, the attribute score of each paragraph is computed and then used to measure the consistency among paragraphs for better learning the graph-based representation of the input. For the decoder, the attribute is predicted based on the partial predicted sequence generated so far for better generating the next token. The module is evaluated on both automatic and human metrics, and the experimental results show the effectiveness of the proposed module.",
            "main_review": "Strengths:\n- The paper proposes an attribute conditioned module for abstractive multi-document summarization, which improves the learning ability of both the encoder and the decoder of the original model, i.e., GraphSum.\n- Both automatic and human metrics are adopted to make the evaluation more comprehensive.\n\nWeaknesses:\n- Little description on the drawbacks of previous methods working on removing inconsistent information for abstractive multi-document summarization. Section 2.3 mentioned a method which incorporates an opinion polarity module to the pointer generator network for multi-document summarization. However, the drawbacks of this method and why the proposed method surpasses it are not illustrated in the paper. Moreover, the comparison between it and the proposed method is also not given in the Experiment section.\n- The model the authors propose doesn’t seem to satisfy the criterion they laid out. Specifically, the attribute conditioned module aims to make the generated summary have a consistent viewpoint. However, the viewpoints are predicted at both the graph-based learning layer of the encoder and each step of the decoder. There is not any explicit constraint to make the predicted viewpoints be consistent. Therefore, is it still possible that the generated summary expressed the conflicting information?\n- Some important experiments are missing. 1) For the human evaluation, not all the mentioned baselines, i.e., BART, BART+Longformer, and GraphSum, are evaluated on the human metrics. Therefore, it is not clear whether the proposed module outperforms all the baselines on the human metrics. 2) For the ablation study, why are the ablations designed on the BART and BART+Longformer, instead of the original model, i.e., GraphSum? 3) The external classifier of XLNet introduces additional computation. What are the memory and time costs of the proposed model during inference compared to the previous methods?\n- The presentation of the paper should be improved. Specifically, all the references in the paper are not shown, and there are some grammatical issues and typos that should be fixed.",
            "summary_of_the_review": "The paper proposes an attribute conditioned module to solve the issue of inconsistent information among documents for abstractive multi-document summarization, and examine the effectiveness of the proposed module on both automatic and human metrics. However, the presentation of the model is not clear and there are questions about whether the model encourages consistent viewpoints. Additionally, the experiment is not comprehensive to show the effectiveness of the model. In sum, there is still room for improvement and I tend to reject the paper.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper presents a method for multi-document summarization that considers contradictory information present in the source documents. The presented method is an extension of GraphSum with attribute conditioning modules in the encoder and decoder. Attribute discriminators are incorporated into the model so that it can predict attributes when generating a summary. This study reports ROUGE scores, human evaluation, and ablation study on MultiNews dataset.",
            "main_review": "## Strength\n+ The experiments report superior performances of the proposed method over the baselines.\n\n## Weakness\n\n+ The description of the proposed method is insufficient.\n    + It is impossible to understand the proposed method without the external paper of GraphSum\n    + The decoder architecture shown in Figure 1 is different from that shown in Figure 1 of Li et al. (2020). I'm not sure whether the authors deliberatively dropped hierarchical graph attention or made a mistake in drawing a diagram.\n    + In Figure 2, the attribute classifier models $P(a|x_{1:n})$, but outputs a probability/score distribution of words.\n+ The quality of the presentation is not satisfactory.\n    + This paper has no reference section.\n    + All citations in the body are marked as \"?\"\n    + Section 3.1: \"diagram2\" -> \"Figure 1\" probably\n    + The third equation of P5: I think $\\prod_i$ is necessary because $i$ is undefined in the scope\n    + The second line of P6: \"is taken to A diagram\" -> \"is taken to a diagram\"\n    + P6: \"AllTheNews consists of a body of In order\": another sentence starts without completing the sentence.\n    + Table 2: I'm wondering why Rouge-L scores of GraphSum, ACMs with Sentiment and Polarity are so high compared with those in Table 4.\n    + P8: \"This ablation study shows that This analysis showed that MDS\": another sentence starts without completing the sentence\n+ The novelty and justification of the proposed method are unclear.\n    + Novelty of the proposed method as controlled abstractive summarization is unclear.\n    + An alternative approach to this study would be to cluster source documents into several non-conflicting groups before generating a summary. This paper did not explain the advantage of incorporating the attribute conditioning module in the GraphSum model.\n    + This paper did not mention studies related to 'stance' ",
            "summary_of_the_review": "I do not think this paper is ready for publication.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes an attribute (sentiment or polarity) conditioned multi-document summarization framework to address of issue of conflicting information in input documents. Attribute classifiers are trained in the pre-stage and then are used to get the attribute information of the content. Experimental results show that the proposed framework can obtain better ROUGE than the baseline BART.",
            "main_review": "Strength:\n\n-  Issue of conflicting information in MDS is investigated.\n\nWeakness:\n\n-  Cites and References are missing. This is a serious bug for a submitted version.\n-  It seems that there are no experiments designed to support and verify the claim on the point of “conflicting information”.\n-  The experimental comparisons are not sufficient, and more beeline methods need to be introduced.\n-  Paper writing need to be improved carefully.\n",
            "summary_of_the_review": "To sum up, considering the weakness of the paper, I suggest the authors improve the paper carefully.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}