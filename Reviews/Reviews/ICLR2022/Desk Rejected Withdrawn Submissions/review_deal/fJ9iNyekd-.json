{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper studies the problem of federated learning when some clients' data is unlabeled. In addition, some of the classes are unlabeled while others are positive classes. The paper proposes an algorithm called FedPU and the authors provide an alaysis to obtain the generalization bound for the proposed algorithm.",
            "main_review": "The problem which is studied in this paper is interesting and important.\n\nsuggestions/ weaknesses/ questions:\n\n1- The paper states that \"Note that different clients have different set of positive classes, and all of the positive classes should\ncover the whole classes in the dataset.\" This assumption is quite restrictive which does not necessarily hold in practical scenarios.\n\n2- The paper studies the problem that positive classes can be different across different clients. In such cases, one idea is to personalize the federated learning algorithm to better deal with this issue. However, in the paper this issue does not discuss that why it is necessary to train a global model on the server. The other question in this regard is that is it possible to simply combine existing personalized federated learning algorithms with semi-supervised federated learning algorithms? Have the authors tried to compare their algorithm with such combined algorithms? It would be great if authors can add such comparisons to the paper.\n\n3- The mathematical proofs of the paper is hard to follow. Many notations has not been defined in the paper. The most important one is the definition of $P_U(f(\\mathbf{x}) \\neq m)$ in (6). I could not obtain the equation (6) and this makes the correctness of this paper questionable for me. I could not understand what is the exact definition of $P_U(f(\\mathbf{x}) \\neq m)$. Furthermore, it is recommended to provide the explicit definition of surrogate loss function $l(\\cdot)$ in the paper.",
            "summary_of_the_review": "To sum up, the paper studies an interesting and important problem in federated learning. However, the proofs provided in the paper is not well written and this makes the paper hard to follow. Also, it is recommended that the authors discuss the personalized federated learning and its relations to their work.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "In most of the federated learning problems, one assumes that datasets in each client are fully labeled and if there are some unlabeled datasets, they regard them as a single class. Different form the conventional settings, this paper studies a federated learning problem where each client has some labeled and unlabeled data coming from multiple classes and if a client has unlabeled data coming from a specific class, there exist other clients that have labeled data from that particular class.\n\nBy proposing a new framework for this setting, this paper proves a generalization bound which is no worse than C\\sqrt{C}  times the fully-supervised model where C is the total number of classes. They also show empirically that the proposed method achieves a better performance than the methods only using data that can be labeled by clients which is called positive data. ",
            "main_review": "-This paper considers a practical setting which has not been studied very well in the literature of federated learning which enables it to be applied to a broad practical problems. \n\n- This paper provides a variety of empirical results on different datasets with different settings such as i.i.d. and non-i.i.d. and actives better performance compared to previous methods.\n\n-A major weakness of the paper is its writing format which consists of many math expressions without providing intuitions and insights.  Moreover, it states the theorems without interpreting the terms appear in them. Furthermore, the novelty of this work is limited as it seems the results are just simple extensions of classical generalization bounds.\n\n",
            "summary_of_the_review": "I would recommend that authors may move most of the mathematical derivations to the appendix and in place of them they can add more interpretations and insights to the final results, which can enhance the quality of the paper a lot. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper considers the federated learning framework where each client has access to labeled data from some classes (positive data) and unlabeled data from all the classes, which they call multiple-positive-multiple-negative positive-unlabeled (MPMN-PU) federated learning. They reformulate the expected classification error w.r.t. fully labeled data and propose a learning objective that can be estimated from the MPMN-PU data. In the paper, they also provide some generalization analysis and experimental results of their proposed method.",
            "main_review": "# Pros\n-The authors firstly consider the MPMN-PU problem in the federated learning framework, which is a more realistic setting compared to the classical federated learning setting that assumes fully labeled data at each client.\n\n-In the experiment part, comparing their method with the existing semi-supervised federated learning approaches is also a positive point.\n\n# Cons\n-In the experiments (Sections 4.1-4.4), comparing with only two baseline methods (one baseline uses only labeled positive data, the other uses fully labeled data) is not convincing. In addition to the semi-supervised federated methods, I feel that FedAwG [Yu et al., 2020] should also be included as a baseline. In FedAwG, each client only has access to labeled data from one single class, which can be seen as a special case of the MPMN-PU setting and can be compared in this case.\n\n-In this paper, the authors only consider FedAvg to aggregate all the clients. It seems that the proposed method does not add any constraints on optimization, considering other federated aggregation methods, such as FedProx [Li et al., 2018], can make the results stronger.\n\n# Detailed comments and questions\n-In the introduction, paragraph 3, it may not be appropriate to say this paper considers the most general setting of federated learning with unlabeled data, because this paper does assume some labeled data (positive data) are available. \n\nActually, there is another line of federated learning research that considers only unlabeled data which should also be included in the related work section, e.g.,\n\nAn Efficient Framework for Clustered Federated Learning, NeurIPS 2020.\n\n-In Section 3.2, it seems that the class priors are necessary for applying the proposed method. How can the class priors be estimated in practice? Is the proposed method sensitive to the class priors, since it is often the case that they cannot be accurately estimated?\n\n-Eq. 8 seems a bit weird to me. In classical federated learning, each client uses the **same** objective function but has different local data. In Eq. 8, each client has a **different** expected risk (objective function), in this case, how can we guarantee that updating the server model by aggregating the local gradients (given that local objective functions are **different**) makes sense? Adding more analysis or explanations may be necessary.\n\n-Eq. 10 is quite misleading to me. The authors claim that we use labeled samples from class j in client k2 to help calculate the risk of class j in client k1. But in federated learning, it is common sense that each client’s data are stored locally and **cannot** be exchanged, so that we employ a server to coordinate the training process (aggregate the local gradients, update itself, and broadcast). Could the authors explain more on Eq 10 and how can we obtain information on C_{P_{k_q}} (k_q \\neq k) since each client only has labeled data C_{P_k}?\n\n-In the theoretical analysis, is it implicitly assumed that the aggregation method is FedAvg? Otherwise, the proposed method may not be guaranteed to converge.\n\n",
            "summary_of_the_review": "Overall, the paper considers a practical federate learning problem and has some interesting contributions. But the current presentation has some unclear parts and needs to be clarified.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a framework of federated learning with positive-unlabeled data (FedPU). In the federated learning setting, since negative samples may consist of multiple classes which are unknown to a client, it requires careful design to develop a PU learning method for the federated learning setting. For the proposed risk estimator, it was proved that the generalization bound is no worse than C\\sqrt{C} times of the fully-supervised learning risk, where C denotes the number of classes. Through empirical evaluation, the FedPU was shown to achieve better performance than conventional learning methods.",
            "main_review": "The mathematical exposition of this paper has several problems (no definition, ambiguous usage, etc.). So, I put several assumptions to read/understand this paper. But even so, some equations are not clear. \n\nIt seems that the proposed method requires some information sharing between clients (maybe, and the central server). Such a requirement might break the assumption in the federated learning setting. But, that issue is not discussed in this paper.\n\n---\n\nIs Eq. (5) equal to Eq. (7) and Eq. (8)? Probably, Eq. (5) and Eq. (7) are R^k(f).\n\nl( f(x) \\neq i ) is not clear. Could you please provide examples of l by equation?\n\nm \\notin C_{P_k} is ambiguous. Probably, does that mean m \\in C \\ C_{P_k}?\n\nWhat is l(R^k(f)) in Eq. (9)?\n\nWhat is L(f(w)) in Eq. (12)?\n\nIn Eq. (12), 1/n_i^k and 1/n_U^k might be ignored. These terms are necessary. Otherwise, Eq. (12) is not a sample approximation of Eq. (11). \n\nCould you explain one-by-one how to obtain the statement \"the proposed method is no worse than C\\sqrt{C} times\" in Theorem 5?\n\nIt seems that the portion of information of client k_2 sends to client k_1 in Eq. (10). That is, the information exchange occurs between client k_1 and k_2. Is it OK in the federated learning setting? Based on Eq. (2), the weight of a hypothesis is sent to the central server. But, Eq. (10) indicates that the local samples of clients need to be sent to other clients or the central server. Is this understanding correct? If so, the authors would need to justify the data exchange in the federated learning setting.",
            "summary_of_the_review": "This paper considers an interesting application of PU learning. However, there are several issues in the presentation. Moreover, it seems that the proposed method requires data sharing between clients, resulting in the violation of the privacy-preserving assumption in the federated learning setting.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}