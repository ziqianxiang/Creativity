{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper focuses on the problem of active feature acquisition and proposes a robust approach to feature acquisition and out-of-distribution detection. The framework presents several novelties including a hierarchical acquisition policy. ",
            "main_review": "Strengths:\n- The paper claims a more efficient framework compared to other approaches in the literature. \n\nWeaknesses:\n- Lack of clarity. I had difficulties understanding and following the paper and its novelties. \n- empirical results do not support the claims. For instance, the scalability to a larger pool of candidate features. ",
            "summary_of_the_review": "My main two concerns are:\n- Lack of clarity in the presentation. The paper starts suggesting the relevance of AFA. However, there are only a couple of references (and some are from Arxiv). That is not very encouraging. Then, in terns of organization, section 2 and 3 seem to be very hard to follow. Would be likely better to have a single related work section and a short section describing the problem (AFA). The current approach is way too long. \n- Method section is also very convoluted. I still can not understand the entire process. There is an acquisition step, where? how? I would appreciate a small diagram or an algorithm describing the process. \n\n- The experiments and comparisons to other methods are based on the clustering output of this approach. Is that a fair comparison? Using a part of the proposed algorithm to evaluate other approaches does not seem fair. \n\n\nSome additional comments:\n- Equation 1: I would have rephrased that. At the moment, the groundtruth is $y$ and then, the prediction is something represented by $\\hat{y}(x_0)$. I guess the prediction should be $\\hat{y} = f(x_0)$. Also, maybe use different notation for $x_o$ as it is a group of features (defined by $o$). \n\n\n- Fig 9: text claims this figure support larger dimensionalities. I think I do not follow. Fig. 9 shows the same results as a function of the number of acquisitions when using or not using grouping. \n- Figure 5 (and others). Please, improve caption. What is the map shown in green/black/white? What is represented there? Why different colors? Are those the position of the features acquired? Same for Fig. 6. Captions should contain some explanation.\n\n\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors develop a method to address two issues with current active feature acquisition (AFA) algorithms. First, to resolve the issue that existing AFA methods have trouble scaling to datasets with a large feature space, the authors propose instead to acquire features over a pre-computed hierarchical clustering of the features using a mutual information based objective. Second, to resolve the issue that existing AFA methods could perform poorly on out-of-distribution inputs, the authors augment a previously proposed unsupervised OOD detection method to allow for partially observed inputs, and use the output of this model as a reward signal for their RL agent. The authors conduct experiments on various components of their proposed model (reconstruction, classification accuracy, OOD detection) and find that their method outperforms the RL baseline.",
            "main_review": "Strengths:\n\n- The paper is well-motivated, and the proposed methods make sense in solving the problems that the authors bring up.\n- The authors demonstrate the advantage of their method on several datasets, though the performance gains seem to be quite marginal.\n\n\nWeaknesses:\n- The authors need to report confidence intervals in all figures shown in the paper. As the metrics shown are already averaged over 5 runs of the method, it should be trivial to plot standard deviations or show the minimum and maximum over the runs.\n\n- It does not seem like the authors currently evaluate the OOD robustness of their acquisition agent, only the performance of the OOD detector. To do this, the authors should consider an experiment showing OOD classification accuracy of an agent trained on the ID dataset.\n\n- The authors should add more data points to all of the figures in the paper -- having only three data points does not show the trend sufficiently well.\n\n- In order to definitively establish that their hierarchical clustering method improves acquisition speed, the authors should report some runtime statistics in the appendix (e.g. on the downsampled MNIST dataset).\n\n- The overall organization and presentation of the paper could be improved. The authors should consider moving the first paragraphs of 3.1 and 3.2 into the background section. The authors should also explicitly define the equations for $r_m$, $r_e$, $r_d$ from Algorithm 1 somewhere in the paper, instead of having to infer them from other equations. There are also several spelling and grammar mistakes within the paper (e.g. \"limits\" -> \"limit\" in the abstract, \"Base\" -> \"Based\" on page 3, \"an reward\" -> \"a reward\" on page 7).\n\n- The authors should describe how they select hyperparameters for their model (e.g. how different rewards are scaled when summed in Algorithm 1). \n\n- In Figure 4c, the random baseline far outperforms GSMRL - is this a typo?",
            "summary_of_the_review": "The paper presents interesting solutions to two well-motivated problems in active feature acquisition, but is held back by some fixable issues in the experimental evaluations. I believe that the paper is borderline, pending these fixes.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents a novel method for active feature acquisition (AFA) and active instance recognition (AIR) called \"Robust AFA\".\n\nAFA is the task of predicting target values for a given input datapoint while being efficient in the number of (expensive) feature value acquisitions.\nIn more detail, the following assumptions are made by AFA:\n* There exists a training set of complete feature and target observations on which we can train the AFA method.\n* Then at test time, we make predictions of target values given a test datum.\n* For the test datum, initially, all feature values are unknown but can be acquired at a cost. \n* AFA acquires feature values that are informative for target prediction while minimising the overall cost incurred.\n\nIn AIR, input datapoints do not have a dedicated target value.\nInstead the task is to reconstruct the input, i.e. make a good prediction for those feature values in the input that we have not observed.\n\nRobust AFA extends previous work in AFA/AIR called GSMRL (Li et al., 2020) which presents a reinforcement learning approach (based on PPO) to AFA/AIR.\nGSMRL learns a policy that predicts a distribution over the next feature acquisition index, given all previously observed features.\n\n*Concretely, Robust AFA extends GSMRL with the following two components:*\n\n(1) \"Action Space Grouping\": Robust AFA clusters features into groups to reduce the effective size of the feature space (which is the action space for the policy network). Features are clustered by stratifying/histogram binning them according to the mutual information between the target value and feature of interest. That is, features that are part of the same group will have similar mutual information. This is performed once per dataset and in advance of any acquisitions.\n\n(2) \"PO-MSMA\": Robust AFA adds an OOD detection component to GSMRL. For this,  MSMA (Mahmood et al., 2021) is extended to work with partially observed inputs. MSMA requires training of an additional model, the score network, whose score predictions are used to perform OOD detection. Additionally, an additional reward proportional to the log likelihood estimates is added to the acquisition procedure in order to incentivise feature acquisitions to account for the OOD detection task.\n\n*In the experiments*, the authors apply Robust AFA to AFA/AIR on various image datasets (MNIST, FMNIST, SVHN) and they explore OOD detection by contrasting these datasets (e.g. MNIST is in domain and Omniglot is out of domain).\nThey show that their method performs on par with GSMRL for AFA/AIR and outperforms it for the task of OOD detection.\n\nFurther, the paper shows an ablation study where they compare Robust AFA for AFA with and without the action grouping, study different versions of possible clustering mechanisms, and compare the performance of PO-MSMA to MSMA on fully observed data.\nThe action grouping does not degrade performance and the mutual information–based grouping outperforms the alternatives they study.",
            "main_review": "## Strengths\n\nI agree with this paper in claiming that both large input feature spaces and OOD detection are relevant problems when considering the application of AFA/AIR methods to practical scenarios.\nA grouping/clustering of the features to reduce the effective size of the feature space seems like a simple and sensible solution to this problem.\nFurther, it makes sense to extend AFA/AIR to be able to detect OOD inputs.\nWhen considering OOD detection, it seems sensible to build on previously published OOD work (MSMA).\n\n## Weaknesses\n\nNot all parts of Robust AFA are explained well (enough) in the current draft of the paper.\nWhile this could potentially be excused – given that the method does have an usual amount of moving parts – there are some important design choices that specifically relate to the novel parts of Robust AFA for which I believe the authors do not give sufficient explanation or justification.\n\nFurther, I find the experimental evaluation somewhat lacking: I am not fully convinced that \"action space grouping and \"partially observed OOD detection\" meaningfully improve results for AFA/AIR and OOD detection.\n\nI will next (1) ask for some concrete clarifications relating to the exposition of the method, (2) give a critique of choices in the Robust AFA architecture, (3) question the experimental evaluation.\n\n*Below, I will highlight points that are particularly important to me by bolding their first sentence.*\n\nI hope the authors take my criticism as constructive and I look forward to fruitful discussion during the rebuttal period.\n\n### 1. Clarifications Needed in The Exposition\n\n(A) In the abstract you write that \"current AFA methods lack robustness in two key areas\". However, it is unclear to me how scaling to large feature spaces falls under the umbrella of \"robustness\".  I would say that scaling and robustness are usually used as terms for two distinct challenges, and I think it's probably better for you to say something like \"current AFA methods lack robustness to OOD inputs and they do not scale to large feature spaces\" instead of claiming that scaling is part of robustness.\n\n(B) This paper may benefit from explaining the assumptions made in AFA more clearly. In particular, the fact that Robust AFA assumes the existence of a fully observed set of training data, on which all models, including the policy network and OOD detector, are trained in advance is not made clear. This also distinguishes the setup here from previous works in AFA such as Icebreaker (Gong et al., 2019) or active learning more generally – although Robust AFA shares this setup with GSMRL. \n\n**(C) The paper does not fully explain how all components fit together, and it feels like there is a significant amount of guesswork to be done by the reader.** Algorithm 1 would be a good place to give this overview. However, most of the notation of Algorithm 1 is entirely novel. \n* What is `aux=M.query(x_o, o)`? Is this the 'side information'  from Eq.~4? If so, why is this not referenced. Or does this contain further terms such as those mentioned in the text after Eq. 4?\n* What is `action=agent.act(x_o, o, aux)` ? Reading the appendix it sounds like there is an additional model that predicts actions $p(x_j | x_o)$. From the main text, I would have guessed you use the 'arbitrary conditional model' here as well. Why can't you do that? Is the surrogate model only used for intermediate rewards and clustering?\n* (For fairness: the intermediate reward $r_m$ mentioned in Alg. 1 *is* defined in the main text and appendix but an explicit reference would still be nice here.)\n* Similarly, how exactly  `ood_likelihood = D.log_prob(xo, o)` is computed is unclear to me. I would guess this is a log estimate of the likelihood from PO-MSMA, which uses some (?) density model to fit a distribution over the noise contrastive scores. But no equations are referenced and the level of detail is far from sufficient for me to really know what's going on. The appendix also does not provide the missing details.\n\n(D) Why do you (sometimes) call the arbitrary conditional model the 'surrogate' model? Is this not also the model which you use to make predictions $p(y|x_o)$? To me a surrogate model is something you use on top of the main task of making predictions (e.g. the OOD model is a surrogate model).  (Sometimes, the surrogate model is confusingly called the \"dynamics model\".) \n\n**(E) How are the probabilities in Eq. 6 calculated?** I assume that both $p(k|s)$ and $p(n|k, s)$ are derived from the mutual information $I(x_i, y)$ (Eq. 5) but this is never spelt out. So is $p(k|s)$ proportional to the average MI of the cluster (normalised by the sum over all other clusters)? And similarly, is $p(n|k, s)$ then proportional to the MI inside the cluster (normalised by the sum over all other features in only that cluster)? Why is this not spelled out?\n\n(F) Is it fair to call Robust AFA an extension of GSMRL that does action space grouping and has an OOD component? The current draft of the paper hides this a bit, which I don't think is beneficial for clarity.\n\nI hope my questions illustrate that there may indeed be a lack of detail in the exhibition of Robust AFA.\n\n### 2. A Critique of Robust AFA\n\n**(G) You present Robust AFA as dealing with a general cost $\\mathcal{C}(o)$ but cost is not discussed at all for the action space grouping.** I suspect that grouping purely by MI (Eq. 5) is suboptimal if different features have different costs. (I don't want to acquire costly features, even if they have high MI. At the same time, I do want to acquire features with small MI, if they are cheap. I believe this scenario is also relevant in practice, e.g. for the health care applications you give.) In the current draft, I believe the experiments assume equal cost over all features (but this is also not mentioned explicitly).\n\n**(H)  Why can you not use the log likelihoods from the 'surrogate model' to do the OOD detection?** Especially given that you have this nice 'arbitrary conditional model' that seems pretty broadly applicable. Have you tried this and it does not work? Right now, I am unconvinced that the introduced additional complexity is needed to perform the OOD detection step.\n\n**(I) I am not convinced by the discussion of the auxiliary OOD reward (Alg.1, l. 12).** Specifically, this sentence: \"This encourages the agent to acquire features that more closely resemble the in-distribution ones, and thus reduces the false positive detection.\" I appreciate that, in the appendix, you then discuss how a *negative* log likelihood award reduces false negative detection for the opposite reason. \nFirstly, I am not sure the argument holds up to scrutiny. Imagine I have an input image that is OOD because some of its input features are corrupted. Why would it ever make sense for me to try to maximise the likelihood estimates? Isn't this encouraging the model to turn a blind eye to features that could lead to believing the model is OOD? And how does that help OOD detection?\nSimilarly,  the negative reward will encourage the model to skew its belief towards the data being OOD.\n(In other words,  are you sure the current strategies reduces false positives/negatives in targeted fashion, or does it just achieve this by trivially reducing positives/negatives overall? I.e. I can trivially reduce the number of false positives by reducing the number of positives overall.)\nShould a principled approach to this not aim to reduce *uncertainty* over whether an input is OOD or ID?\nSecondly, it would be great if you could provide empirical proof of the behavior of this acquisition strategy (e.g. by simply plotting false negative/positive rates for Figure A. 6).\n*In any case, I think this is a crucial aspect of the OOD component of the paper (because this is the only way in which the OOD component interfaces with the AFA/AIR aspect) that is neither discussed nor evaluated sufficiently.*\n\n\n### 3. Experimental Evaluation\n\nI have a couple of general questions/concerns regarding the experimental evaluation (J-O),  which is lacking important details that are also not provided in the supplement.\nThen, I have some more specific points addressing the experiments in detail (P-.\n\n(J) How large are the training sets used to train the policies?\n\n(K) How large is the validation set used to perform the action group clustering?\n\n**(L) What do you mean by \"The random policy is repeated for 5 times and the metrics are averaged from different runs.\"** For how many different 'runs' are the results for GSMRL and Robust AFA averaged? What is a run – Is it just evaluating the same policy on a new test sample, or is it retraining the whole thing?\n\n(M) How do you decide the samples for which you apply Robust AFA for the plots? (How can I be sure that these figures are not cherry-picked?)\n\n**(N) How computationally expensive is a run? Naively, it would seem like more than 5 repetitions should be computationally feasible.**\n\n**(O) What are the standard deviations/errors on the results – are the differences roughly statistically significant or not?**\n\n**(P) You claim that prior work, including GSMRL, does not work on larger action spaces,** which is why you compare to a modified version of GSMRL that uses your action space grouping.  \n*However, in the original GSMRL paper, the authors do in fact apply their model to full resolution MNIST images (Figure D.8).*\n*So your claim that \"current AFA approaches cannot be applied directly\" seems to be wrong.* \n*Further, it seems your claim that you demonstrate scaling of AFA to larger action spaces than prior work also seems to be wrong.*\nPlease do correct me if I'm wrong here.\nHow does your approach compare to the full-action space version of GSMRL?\n(By the way, I think you should maybe make clear in the legends of the plot that this is not the original GSMRL, e.g. by calling the modified approach \"GSMRL*\".)\n\n**(Q) Consequently, it seems you do not actually provide any evidence that you can scale to significantly larger action spaces than what was previously possible / or that you improve performance over previous work in large action space scenarios.**\nYou only show evidence that you do not degrade performance, which is a weird thing to do. I thought the point was to improve performance in large action space scenarios (cf. Fig. 9, which is not at full scale)?\n\n**(R) How do you perform OOD detection for GSMRL?**  I almost cannot believe this isn't part of the paper/appendix (maybe I've missed it) but I cannot find anything in the paper about how the OOD detection for GSMRL works. OOD detection is not discussed in the original GSMRL publication either. Similarly, how is OOD detection performed for the RAND baseline? (What is the RAND baseline exactly?)\n\n**(S) An obvious baseline seems to be missing from Fig. 10, where you compare clustering mechanisms:** Just pick a random subset of features and then do not cluster them, but instead apply Robust AFA without clustering (so simply drop all other features).\n\n**(T) I would be interested to know how useful the actual policy is.**  Specifically, how does a simple baseline that just acquires points by (pre-computed and fixed in advance) mutual information (Eq. 5) compare?\n\n(U) Why would PO-MSMA beform better on fully observed data than MSMA? This seems worth a discussion in the paper. (Maybe the last sentence in 3.2 goes in that direction?) (And why does it work badly only for CIFAR 10 - SVHN? This seems odd.)\n\n**(V) A baseline for OOD detection seems to be missing. How well does it work if I apply PO-MSMA and acquire features with a random acquisition strategy?** In other words, is OOD detection improved by the OOD reward? (Is there a benefit to intertwining them?) Similarly, what do the OOD figures look like if I remove the OOD reward during training of the policy? (Granted, PO-MSMA is a contribution of yours. However, I would be highly interested to know how well this baseline performs, given that the integration of PO-MSMA into Robust AFA is important to this approach.)\n\n\n## Small Stuff\n\n* \"A possible approach is to use the uncertainty of prediction, since the prediction for OOD inputs are expected to have higher uncertainty\" → Would be good to clarify that this is strictly about epistemic uncertainty/model uncertainty (e.g. Kendall & Gal (2017)) and not just \"uncertainty\", which includes noise in the data/aleatoric uncertainty.\n* The following might be a good additional (and earlier) citation for work on experimental design: Lindley, Dennis V. \"On a measure of the information provided by an experiment.\"_The Annals of Mathematical Statistics_(1956): 986-1005. \n* Further, I would suggest you clarify that the experimental design framework allows for non-greedy/non-myopic experimental design, and that this is also (sometimes) used in practice, e.g. González, Javier, Michael Osborne, and Neil Lawrence. \"GLASSES: Relieving the myopia of Bayesian optimisation.\" Artificial Intelligence and Statistics. PMLR, 2016. and Adam Foster, Desi R Ivanova, Ilyas Malik, Tom Rainforth Proceedings of the 38th International Conference on Machine Learning, PMLR 139:3384-3395, 2021.\n\n## Language & Style\n\n* Abstract: propose \"several techniques\" → Maybe replace with something like \"solutions to these two problems\"  as this otherwise makes it sound like you propose a lot more things.\n* \"Base*d* on this observation, [...]\"\n* \"retrieving the nearest neighbors from *the* training set\"\n* I found the first sentence of 2.2 confusing. The \"while\" is maybe not the best choice there.  How about \"[...] prediction of a target variable. However, some applications do not have an explicit target. In active instance recognition (AIR), the goal is,  [...]\"\n* \"show that *this* is not the case for high dimensional distributions\"\n* \"We propose a robust AFA framework to acquire feature*s* actively\"\n* Figures 6, 7, and 8 appear before Figure 5, which is confusing.\n* The hyperlink to Figure A.3 does not work.\n",
            "summary_of_the_review": "I believe that both large feature spaces and OOD detection are problems that are worthwhile studying for AFA/AIR.\nThe solutions proposed in this paper are interesting.\nHowever, the exposition of Robust AFA is lacking in clarity, and I believe that two crucial design choices (OOD reward and MI grouping) are not discussed sufficiently. Based on my current understanding, I believe that they are flawed.\n\nFurther, the experimental evaluation leaves too much to be desired. Both in terms of being able to trust the results (details of the setup, number of repetitions, setup of OOD for GSMRL) as well as in terms of the experiments that were performed (don't show scaling to higher action spaces than previous work, missing baselines for OOD, missing baselines (or details) for clustering, missing baseline for usefulness of PPO acquisition over simple (fixed) MI acquisition).\n\nAdditionally, a reproducibility statement (as strongly recommended by the conference organisers) or available code, would be be really beneficial for this submission, given the many open questions that I am left with.\n\nBased on the above reservations, I cannot currently recommend acceptance of the draft in its current version. I look forward to the authors reply and hope to engage them in a discussion of these points. I am willing to change my opinion given that they sufficiently address my concerns.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studies the problem of active feature acquisition, where features are sequentially acquired to improve prediction of a target variable. In particular, a framework is proposed to handle a large number of features using a hierarchical acquisition policy to address the issue of scalability to large feature spaces. Furthermore, to overcome issues with out-of-distribution inputs, a detector is proposed for partially observed data.The proposed framework is evaluated on 3 image datasets (MNIST, FashionMNIST, SVHN) and compared with two baselines, a modified GSRML algorithm and a simple random acquisition method. The experimental results suggest that the accuracy achieved by the proposed framework is competitive with respect to the selected baselines.",
            "main_review": "Strengths:\n+ The proposed approach can reduce the action space for active feature acquisition by appropriately clustering features and operating on the clusters.\n+ An out-of-distribution detection algorithm is proposed and incorporated into the proposed active feature acquisition framework.\n\nWeaknesses:\n- Important related state-of-the-art work on this area is missing (see below). Furthermore, the last reference shows how to scale active feature acquisition in feature spaces with more than 1 million features. In that sense, comparing with such a method instead of GSMRL would make the claims of the paper regarding scalability to large feature spaces stronger.\n\n    (a) G. Dulac-Arnold, L. Denoyer, P. Preux, and P. Gallinari, “Datum-wise classification: A sequential approach to sparsity,” in Proc. Joint Eur. Conf. Mach. Learn. Knowl. Discovery Databases, 2011, pp. 375–390.\n\n    (b) J. Janisch, T. Pevný, and V. Lisý, “Classification with costly features using deep reinforcement learning,” in Proc. AAAI Conf. Artif. Intell., 2019, vol. 33, pp. 3959–3966.\n\n    (c) J. Janisch, T. Pevný, and V. Lisý, “Classification with costly features as a sequential decision-making problem,” Mach. Learn., vol. 109, pp. 1587–1615, 2020.\n\n   (d) Y. Liyanage, D.-S. Zois, and C. Chelmis, \"Dynamic Instance-Wise Joint Feature Selection and Classification,\" IEEE Transactions on Artificial Intelligence, April 2021.\n\n- It is not clear why a termination action is not used in the proposed framework. Why does it complicate evaluation of OOD performance?\n\n- The discussion of the proposed clustering approach can be improved. Specifically, how does one choose the number of clusters? How does such a choice affect performance? I do not believe there were any experiments included in the paper to analyze the effect of this parameter. Furthermore, how do you handle the case where the feature space cannot be split into equally-sized clusters?\n\n- The feature acquisition process is not clearly described. Assuming K distinct clusters, how does an agent select between clusters? If a cluster is selected, then how does an agent select between the features? What is the form of the reward of the agent in these two cases?\n\n- The discussion of the proposed partially observed out-of-distribution detection is quite condensed. The paper extends MMSA by modifying the score network to output scores of arbitrary marginal distributions. To accomplish this, Eq. (7) is modified appropriately. What is the intuition behind this? Why Eq. (8) takes this form?\n\n- How does the auxiliary reward is constructed from the likelihood of score norms?\n\n- Fig. 2 is very generic. It can be improved by clearly defining the different rewards, i.e., detection reward, intermediate reward.\n\n- The proposed method is only validated in image datasets, thus not justifying its generalizability. Furthermore, the number of features considered is low (i.e., <= 1,024). Even though there is a rich literature on active feature acquisition, including the references mentioned above, the paper compares with the modified GSMRL and a simple random acquisition baseline.\n\n- The classification accuracy of the proposed approach practically overlaps with the one of the modified GSMRL. Why should one prefer the proposed approach instead of GSMRL, excluding the ability of OOD detection? How does the time complexity of the proposed approach compare with respect to the one of the modified GSMRL?\n\n- In Table 1, why there is a dash in the case of MSMA for the MNIST-Omniglot dataset? Also, how one can explain the low AUROC of PO-MSMA for CIFAR10-SVHN?\n\n- The definition of positive and negative likelihood in the Appendix is not provided. \n\n- Given that one of the goals of the paper is to provide a solution for large feature spaces, the time complexity and/or runtime of the proposed approach and the selected baselines (i.e., rand, GSMRL, WolpDDPG) should be provided. \n\nSome minor issues follow:\n1) pg. 2: \"application\" -> \"applications\"\n2) Fig. 1: \"current observed\" -> \"currently observed\"\n3) pg. 4: \"apriori\" -> \"a priori\"\n4) Some of the material in Section 3.1 can move up to Section 2.1 to decrease repetition.\n5) Most of the figures are very small and thus, hard to parse.\n6) pg. 9: \"do not flag\" -> \"does not flag\"",
            "summary_of_the_review": "Overall, I recommend the rejection of the paper. My major concerns are: (1) important related work on a very well studied topic is missing, (2)   details that can help understand the proposed method are not provided, and (3) the experimental study is limited to images, small feature spaces, and there is no comparison between the proposed work and existing methods that scale up to more than 1 million features.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}