{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "In this paper, the authors jointly consider the data privacy and Byzantine robustness issues in a federated learning system. The authors combine two techniques, sharded secure aggregation and FilterL2, to respectively address these two issues.",
            "main_review": "0. The investigated problem is of practical importance to federated learning.\n1. This paper combines two existing techniques, so that the main contribution seems to be the numerical experiments.\n2. Throughout the paper, the authors emphasize dimension-free error. Even if the claim holds true, the credit belongs to the FilterL2 paper.\n3. The authors should carefully check the claim of dimension-free error. In the thesis of Steinhardt, the stochastic gradients are assumed to have bounded variance \\sigma^2, which is essentially dependent with the dimension.\n4. The analysis is from the existing papers and not new.\n5. A federated learning system often only activates a subset of clients at each iteration. This paper assumes that all the clients are activated. It is fine but the authors should comment on this.\n6. This paper needs more polishing. For example: bidirectional and bi-directional are used interchangeably; m clients must be n clients in the FL pipeline paragraph; the notations in the analysis are confusing.\n",
            "summary_of_the_review": "Overall, the contributions of this paper seem to be limited.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a secure robust method for federated learning, where there is a trade-off between the security of clients and the robustness of the global model. The general idea is straight-forward: the clients are split into multiple *shards*, individual client updates are hidden by secure-aggregation within each *shards*, and then the global server uses a robust mean estimator to estimate the mean from each *shards* updates. The robustness and security are theoretically analyzed, and the performance of the proposed method is empirically evaluated.",
            "main_review": "The main strength of the paper, in my opinion, is the general framework than can potentially be applied with different methods in a plug-and-play style. The general framework is: (1) split clients into groups; (2) secure aggregation of client updates within each group; (3) robust mean estimation from the group aggregated updates. I can image many ways to instantiate this framework, i.e., using different aggregation methods and using different robust mean estimation methods.\n\nThere are mainly four questions/complaints came to my mind after reading the paper. \n\n1.\tI’m not sure about the novelty of this paper. It seems to me that the paper is an instantiation of the framework, where the secure aggregation is the standard secure aggregation method, and the robust mean estimator is the FilterL2 (Steinhardt, 2018). Therefore, the two components are not novel. But since the general framework may be straight-forward by itself, I’m wondering if the general framework is novel? \n2.\tI think the ‘dimension-free’ claim is overclaimed. The dimension-free error of the robust mean estimator is one of the main claimed contributions of this paper. As shown in the Theorem 1, the error depends on the $\\sigma$, the operator norm of the covariance matrix. However, the $\\sigma$ can depend on the dimension, if I understand correctly. I can construct simple examples where the $\\sigma$ is not dimension-free. For example, consider a data sample $x\\in \\mathbb{R}^d$ where each dimension of the sample $x$ is sampled i.i.d. from a distribution with zero mean and non-zero variance. Given a dataset $D=\\\\{x,-x \\\\}$, the covariance matrix is $xx^\\top$, and its operator norm is $||x||_2$ which clearly depends on the dimension $d$. Therefore, I think the “dimension-free” claim is overstated.  \n3.\tI think the “security” claim is not well-supported. Especially the claim of “…server can infer zero information about individual clients from the aggregated updates alone”. Since the gradient calculated from a client is the average of sample gradient, and the gradient calculated from a shard is also the average of sample gradient (with more samples), the difference between a client’s update and a shard’s averaged update seems to be quantitative but not qualitative. For example, model inversion attack may infer individual data from the trained model. Therefore, I doubt that only secure aggregation within shards leaks zero information about individual data, and I don't think I am convinced about the security guarantee the paper claims.\n4.\tIt is not clear to me how the hyper-parameters are chosen. The proposed method relies on the parameters $\\sigma$ and $\\eta$. As shown in the appendix, in the experiments $\\sigma=1e-6$ and $\\eta=20$. Is the performance of the proposed method sensitive to the choice of the hyperparameters? Can those parameters be used on different datasets? It would be great if there are ablation studies about the parameters. \n\nOther comments: \n* The paper overall is well-written and easy to follow. \n* I appreciate that the authors discuss some of its limitations, e.g., the choice of $p$ and the $O(d^2)$ computation cost of the FilterL2 ($d$ is the dimension). \n* Just above Corollary it says that the proof is omitted. But the proof is actually there right after the Corollary.\n\n",
            "summary_of_the_review": "Although I appreciate the value of the general idea, I am not clear about the novelty of the paper, and I think some key claims are over-stated, especially the “dimension-free error”. Moreover, I am curious to see ablation studies regarding the parameters of the proposed method. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper considers the problem of federated learning where some of the clients may be Byzantine, and the server is honest but curious (“semi-honest”). Steinhardt’s robust mean estimator, FilterL2, is adopted to guard against the former. A secure aggregation scheme is proposed to guard against the semi-honest server. At each training round, the server announces a set of shards (disjoint groups). Members within each group generate random masks that are exchanged; specifically member k generates mask u_{kj} for member j in the group; the masks are not required to be specific. The masks are used to obfuscate the client’s update, and a quantization scheme is also proposed. The proposed scheme is evaluated on MNIST and Fashion MNIST dataset, with several attacks that are agnostic / unaware of the proposed mean estimator, and compared against other robust mean estimators. ",
            "main_review": "The paper is organized well and reads well. Contributions are well articulated. \n\nThe paper articulates the tension between robustness against malicious clients, and aggregation that is secure against a curious server. A (time-varying) shard (or client grouping) and security via addition of \"cryptographic\" noise are proposed. The schemes are evaluated against different attacks, and compared with robust estimators. \n\nWhile the paper makes an interesting contribution, several issues remain to be clarified. \n\n\nA key question is the number of shards, and this is not discussed well. A figure showing performance for varying number of shards is provided, but no insights (quantitative or qualitative) are provided on how to choose it. Would the shard size depend upon the complexity of the classification problem (e.g. #classes)? \n\nThe scheme assumes perfect communications. Further, unless every member in a group sends its updates, the updates will be inconsistent. This is not discussed. Presumably the robust estimator might throw out such a group; but this was not demonstrated through simulations. In addition, the paper says that a shortcoming of the works of So et al. and He et al. is that they require clients to be online consistently. That appears to be the case here as well.\n\nThere is insufficient discussion of the complexity, and of communications overhead of the proposed scheme vs. the schemes used in the comparison. What is the overhead in generating and exchanging masks with members in the group? What is the overhead in quantizing the updates with L = 100,000? \n\nInconsistent notation is used to denote the fraction of malicious clients: \\epsilon or \\eta? \n\nAssume that the masks are also integer valued? This is not explicitly stated \n\nCorollary 2: The iid assumption must be part of the statement of the corollary, not buried in the proof. \n\nInsufficient details are provided about the attacks and their strengths. \n\nIt is not possible to assess the additional advantage of SHARDFL over FilterL2 alone, since they are done in different settings (20 clients, 5 malicious vs. 100 clients, 10 malicious).\n\nFigures 2 and 4 provide curves of attack success vs. #epochs (not clear why the vs. #epochs is important; since we care about the performance of the trained model). Absent was a curve showing performance vs. attack strength (beyond # malicious clients). \n\nThe paper does not provide sufficient discussion of the results in Figures 2 and 3. It is clear that ShardFL is not always the best choice. Additionally, it is hard to distinguish the different curves; please use different markers particularly when the colors are very similar. \n\nFigure 1 was blank - only the caption could be seen. \n\nTypos & such: \nTop of p 5: “The smaller the shard size, the more information the server reveals”: this sentence is unclear; what info does the server reveal? \n\nLine 4 of Sec 4.2: ‘rest’ should be ‘remaining’ \n",
            "summary_of_the_review": "The paper proposes a time-varying grouping of clients, and obfuscation of client updates by the addition of noise, so as to offer protection against malicious clients (via robust averaging), and against curious servers (via the addition of noise). The idea is interesting, but several issues remain to be clarified as noted in the detailed review. These relate to communications overhead, assumption of perfect communications, assumption of all members in a group responding, attack strengths, and discussion of results. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}